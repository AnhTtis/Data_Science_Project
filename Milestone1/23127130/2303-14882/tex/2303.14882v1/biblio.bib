@article{nas_google,
  author    = {Barret Zoph and
               Quoc V. Le},
  title     = {Neural Architecture Search with Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1611.01578},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.01578},
  archivePrefix = {arXiv},
  eprint    = {1611.01578},
  timestamp = {Mon, 13 Aug 2018 16:46:24 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ZophL16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{russel2010,
  added-at = {2020-02-01T18:23:11.000+0100},
  author = {Russell, Stuart and Norvig, Peter},
  biburl = {https://www.bibsonomy.org/bibtex/20533b732950d1c5ab4ac12d4f32fe637/mialhoma},
  edition = 3,
  interhash = {53908a52dd4c6c8e39f93f4ffc8341be},
  intrahash = {0533b732950d1c5ab4ac12d4f32fe637},
  keywords = {ties4530},
  publisher = {Prentice Hall},
  timestamp = {2020-02-01T18:23:11.000+0100},
  title = {Artificial Intelligence: A Modern Approach},
  year = 2010
}



@inproceedings{vaswani,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
 booktitle = {Proc. Int. Conf. Neural Information Processing Systems},
 pages = {5998--6008},
 title = {Attention is All you Need},
 volume = {30},
 year = {2017}
}

@inproceedings{ru2020neural,
  title={Neural Architecture Generator Optimization},
  author={Ru, Robin and Esperan{\c{c}}a, Pedro and Carlucci, Fabio Maria},
  booktitle={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@book{kochenderfer2019algorithms,
  title={Algorithms for optimization},
  author={Kochenderfer, Mykel J and Wheeler, Tim A},
  year={2019},
  publisher={Mit Press}
}

@article{tuli2021cosco,
  author={Tuli, Shreshth and Poojara, Shivananda R. and Srirama, Satish N. and Casale, Giuliano and Jennings, Nicholas R.},
  journal={IEEE Trans. Parallel and Distributed Systems}, 
  title={{COSCO}: Container Orchestration Using Co-Simulation and Gradient Based Optimization for Fog Computing Environments}, 
  year={2021},
  volume={33},
  number={1},
  pages={101-116},
  doi={10.1109/TPDS.2021.3087349}
}

@inproceedings{pham2018efficient,
  title={Efficient neural architecture search via parameters sharing},
  author={Pham, Hieu and Guan, Melody and Zoph, Barret and Le, Quoc and Dean, Jeff},
  booktitle={Proccedings of the 35th International Conference on Machine Learning},
  pages={4095--4104},
  year={2018}
}

@inproceedings{yao2021adahessian,
  title={{ADAHESSIAN: An} Adaptive Second Order Optimizer for Machine Learning},
  author={Yao, Zhewei and Gholami, Amir and Shen, Sheng and Mustafa, Mustafa and Keutzer, Kurt and Mahoney, Michael},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={12},
  pages={10665--10673},
  year={2021}
}

@inproceedings{vit_2021,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={Proc. Int. Conf. Learning Representations},
year={2021}
}

@article{nasbench_301,
  author    = {Julien Siems and
               Lucas Zimmer and
               Arber Zela and
               Jovita Lukasik and
               Margret Keuper and
               Frank Hutter},
  title     = {{NAS-Bench-301} and the Case for Surrogate Benchmarks for Neural Architecture
               Search},
  journal   = {CoRR},
  volume    = {abs/2008.09777},
  year      = {2020},
  url       = {https://arxiv.org/abs/2008.09777},
  archivePrefix = {arXiv},
  eprint    = {2008.09777},
  timestamp = {Fri, 28 Aug 2020 12:11:44 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2008-09777.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proc. IEEE Conf. Computer Vision and Pattern Recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{vgg,
  author    = {Karen Simonyan and
               Andrew Zisserman},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  booktitle = {Proceedings of the International Conference on Learning Representations},
  year      = {2015},
  url       = {http://arxiv.org/abs/1409.1556},
}

@inproceedings{glue,
    title = "{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
    author = "Wang, Alex  and
      Singh, Amanpreet  and
      Michael, Julian  and
      Hill, Felix  and
      Levy, Omer  and
      Bowman, Samuel",
    booktitle = "Proc. {EMNLP} Workshop on {B}lackbox{NLP}: Analyzing and Interpreting Neural Networks for {NLP}",
    year = "2018",
    doi = "10.18653/v1/W18-5446",
    pages = "353--355"
}


@InProceedings{shufflenet,
author = {Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},
title = {{ShuffleNet: An} Extremely Efficient Convolutional Neural Network for Mobile Devices},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
month = {June},
year = {2018}
}

@inproceedings{schubert,
    title = "schu{BERT}: Optimizing Elements of {BERT}",
    author = "Khetan, Ashish  and
      Karnin, Zohar",
    booktitle = "Proc. 58th Annual Meeting of the Association for Computational Linguistics",
    month = july,
    year = "2020",
    doi = "10.18653/v1/2020.acl-main.250",
    pages = "2807--2818",
}

@inproceedings{hat_mit,
    title = "{HAT}: Hardware-Aware Transformers for Efficient Natural Language Processing",
    author = "Wang, Hanrui  and
      Wu, Zhanghao  and
      Liu, Zhijian  and
      Cai, Han  and
      Zhu, Ligeng  and
      Gan, Chuang  and
      Han, Song",
    booktitle = "Proc. 58th Annual Meeting of the Association for Computational Linguistics",
    month = July,
    year = "2020",
    doi = "10.18653/v1/2020.acl-main.686",
    pages = "7675--7688"
}

@InProceedings{nasbench,
  title = 	 {{NAS}-{B}ench-101: Towards Reproducible Neural Architecture Search},
  author =       {Ying, Chris and Klein, Aaron and Christiansen, Eric and Real, Esteban and Murphy, Kevin and Hutter, Frank},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {7105--7114},
  year = 	 {2019},
  volume = 	 {97},
  month = 	 {09--15 Jun},
  pdf = 	 {http://proceedings.mlr.press/v97/ying19a/ying19a.pdf},
  url = 	 {
http://proceedings.mlr.press/v97/ying19a.html
}
}

@inproceedings{bananas,
  title={{BANANAS}: Bayesian Optimization with Neural Architectures for Neural Architecture Search},
  author={White, Colin and Neiswanger, Willie and Savani, Yash},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={12},
  pages={10293--10301},
  year={2021}
}


@inproceedings{interspeech,
  title={Improving Keyword Spotting and Language Identification via Neural Architecture Search at Scale},
  author={Hanna Mazzawi and X. Gonzalvo and A. Kracun and P. Sridhar and Niranjan Subrahmanya and I. Lopez-Moreno and H. Park and Patrick Violette},
  booktitle={Proceedings of Interspeech},
  pages = 	 {1278--1282},
  year={2019}
}

@inproceedings{nasgem,
  title={{NASGEM}: Neural Architecture Search via Graph Embedding Method},
  author={Cheng, Hsin-Pai and Zhang, Tunhou and Zhang, Yixing and Li, Shiyu and Liang, Feng and Yan, Feng and Li, Meng and Chandra, Vikas and Li, Hai and Chen, Yiran},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={8},
  pages={7090--7098},
  year={2021}
}

@inproceedings{mpnet,
 author = {Song, Kaitao and Tan, Xu and Qin, Tao and Lu, Jianfeng and Liu, Tie-Yan},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {16857--16867},
 title = {{MPNet}: Masked and Permuted Pre-training for Language Understanding},
 url = {https://proceedings.neurips.cc/paper/2020/file/c3a690be93aa602ee2dc0ccab5b7b67e-Paper.pdf},
 volume = {33},
 year = {2020}
}

@inproceedings{fnet,
    title = "{FN}et: Mixing Tokens with {F}ourier Transforms",
    author = "Lee-Thorp, James  and
      Ainslie, Joshua  and
      Eckstein, Ilya  and
      Ontanon, Santiago",
    booktitle = "Proc. Conf. North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    year = "2022",
    pages = "4296--4313"
}
@inproceedings{mobilebert,
    title = "{M}obile{BERT}: {A} Compact Task-Agnostic {BERT} for Resource-Limited Devices",
    author = "Sun, Zhiqing  and
      Yu, Hongkun  and
      Song, Xiaodan  and
      Liu, Renjie  and
      Yang, Yiming  and
      Zhou, Denny",
    booktitle = "Proc. 58th Annual Meeting of the Association for Computational Linguistics",
    year = "2020",
    doi = "10.18653/v1/2020.acl-main.195",
    pages = "2158--2170"
}

@inproceedings{
gin,
title={How Powerful are Graph Neural Networks?},
author={Keyulu Xu and Weihua Hu and Jure Leskovec and Stefanie Jegelka},
booktitle={Proceedings of the International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=ryGs6iA5Km},
}

@ARTICLE{bo,
  author={B. {Shahriari} and K. {Swersky} and Z. {Wang} and R. P. {Adams} and N. {de Freitas}},
  journal={Proceedings of the IEEE}, 
  title={Taking the Human Out of the Loop: A Review of Bayesian Optimization}, 
  year={2016},
  volume={104},
  number={1},
  pages={148-175},
  doi={10.1109/JPROC.2015.2494218}}
  
@InProceedings{chamnet,
author = {Dai, Xiaoliang and Zhang, Peizhao and Wu, Bichen and Yin, Hongxu and Sun, Fei and Wang, Yanghan and Dukhan, Marat and Hu, Yunqing and Wu, Yiming and Jia, Yangqing and Vajda, Peter and Uyttendaele, Matt and Jha, Niraj K.},
title = {{ChamNet}: Towards Efficient Network Design Through Platform-Aware Model Adaptation},
booktitle = {Proc. IEEE/CVF Conference on Computer Vision and Pattern Recognition},
month = {June},
year = {2019}
}


@InProceedings{evolved_txf,
  title = 	 {The Evolved Transformer},
  author =       {So, David and Le, Quoc and Liang, Chen},
  booktitle = 	 {Proc. Int. Conf. Machine Learning},
  pages = 	 {5877--5886},
  year = 	 {2019},
  volume = 	 {97}
}



@article{nasnet,
  author    = {Barret Zoph and
               Vijay Vasudevan and
               Jonathon Shlens and
               Quoc V. Le},
  title     = {Learning Transferable Architectures for Scalable Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1707.07012},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.07012},
  archivePrefix = {arXiv},
  eprint    = {1707.07012},
  timestamp = {Mon, 13 Aug 2018 16:48:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ZophVSL17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{hyperband,
  author  = {Lisha Li and Kevin Jamieson and Giulia DeSalvo and Afshin Rostamizadeh and Ameet Talwalkar},
  title   = {Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization},
  journal = {Journal of Machine Learning Research},
  year    = {2018},
  volume  = {18},
  number  = {185},
  pages   = {1-52},
  url     = {http://jmlr.org/papers/v18/16-558.html}
}

@article{wl_kernel,
  author  = {Nino Shervashidze and Pascal Schweitzer and Erik Jan van Leeuwen and Kurt Mehlhorn and Karsten M. Borgwardt},
  title   = {{Weisfeiler-Lehman} Graph Kernels},
  journal = {Journal of Machine Learning Research},
  year    = {2011},
  volume  = {12},
  number  = {77},
  pages   = {2539-2561},
  url     = {http://jmlr.org/papers/v12/shervashidze11a.html}
}

@article{graph2vec,
  author    = {Annamalai Narayanan and
               Mahinthan Chandramohan and
               Rajasekar Venkatesan and
               Lihui Chen and
               Yang Liu and
               Shantanu Jaiswal},
  title     = {graph2vec: Learning Distributed Representations of Graphs},
  journal   = {CoRR},
  volume    = {abs/1707.05005},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.05005},
  archivePrefix = {arXiv},
  eprint    = {1707.05005},
  timestamp = {Mon, 15 Jul 2019 14:17:42 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/NarayananCVCLJ17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{word2vec,
 author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {3111-3119},
 title = {Distributed Representations of Words and Phrases and their Compositionality},
 url = {https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf},
 volume = {26},
 year = {2013}
}



@Inbook{rasmussen_gp,
author="Rasmussen, Carl Edward",
editor="Bousquet, Olivier
and von Luxburg, Ulrike
and R{\"a}tsch, Gunnar",
title="Gaussian Processes in Machine Learning",
bookTitle="Advanced Lectures on Machine Learning: ML Summer Schools 2003, Canberra, Australia, February 2 - 14, 2003, T{\"u}bingen, Germany, August 4 - 16, 2003, Revised Lectures",
year="2004",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="63--71",
abstract="We give a basic introduction to Gaussian Process regression models. We focus on understanding the role of the stochastic process and how it is used to define a distribution over functions. We present the simple equations for incorporating training data and examine how to learn the hyperparameters using the marginal likelihood. We explain the practical advantages of Gaussian Process and end with conclusions and a look at the current trends in GP work.",
isbn="978-3-540-28650-9",
doi="10.1007/978-3-540-28650-9_4",
url="https://doi.org/10.1007/978-3-540-28650-9_4"
}

@conference{gp_limit,
  author = {Krauth, Karl and  Bonilla, Edwin V and  Cutajar, Kurt and  Filippone, Maurizio},
  title = {Auto{GP}: Exploring the capabilities and limitations of Gaussian process models},
  booktitle = {UAI 2017, Conference on Uncertainty in Artificial Intelligence, August 11-15, 2017, Sydney, Australia},
  year = {2017},
  editor = {EURECOM},
  address = {Sydney},
  note = {© EURECOM. Personal use of this material is permitted. The definitive version of this paper was published in UAI 2017, Conference on Uncertainty in Artificial Intelligence, August 11-15, 2017, Sydney, Australia and is available at :},
}

@misc{heteroscedastic_gpr,
      title={Gaussian Process Regression with Heteroscedastic or Non-Gaussian Residuals}, 
      author={Chunyi Wang and Radford M. Neal},
      year={2012},
      eprint={1212.6246},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@techreport{mdn_bishop,
title = "Mixture density networks",
abstract = "Minimization of a sum-of-squares or cross-entropy error function leads to network outputs which approximate the conditional averages of the target data, conditioned on the input vector. For classifications problems, with a suitably chosen target coding scheme, these averages represent the posterior probabilities of class membership, and so can be regarded as optimal. For problems involving the prediction of continuous variables, however, the conditional averages provide only a very limited description of the properties of the target variables. This is particularly true for problems in which the mapping to be learned is multi-valued, as often arises in the solution of inverse problems, since the average of several correct target values is not necessarily itself a correct value. In order to obtain a complete description of the data, for the purposes of predicting the outputs corresponding to new input vectors, we must model the conditional probability distribution of the target data, again conditioned on the input vector. In this paper we introduce a new class of network models obtained by combining a conventional neural network with a mixture density model. The complete system is called a Mixture Density Network, and can in principle represent arbitrary conditional probability distributions in the same way that a conventional neural network can represent arbitrary functions. We demonstrate the effectiveness of Mixture Density Networks using both a toy problem and a problem involving robot inverse kinematics.",
keywords = "NCRG sum-of-squares cross-entropy error function classifications problems coding scheme conditional probability distribution network models neural network mixture density model Mixture Density Network inverse kinematics",
author = "Bishop, {Christopher M.}",
year = "1994",
language = "English",
isbn = "NCRG/94/004",
publisher = "Aston University",
type = "WorkingPaper",
institution = "Aston University",
}


@inproceedings{glove,
    title = "{G}lo{V}e: Global Vectors for Word Representation",
    author = "Pennington, Jeffrey  and
      Socher, Richard  and
      Manning, Christopher",
    booktitle = "Proceedings of the Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2014",
    url = "https://www.aclweb.org/anthology/D14-1162",
    doi = "10.3115/v1/D14-1162",
    pages = "1532--1543",
}

@Article{kruskal_mds_1964,
author={Kruskal, J. B.},
title={Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis},
journal={Psychometrika},
year={1964},
month={Mar},
day={01},
volume={29},
number={1},
pages={1-27},
abstract={Multidimensional scaling is the problem of representingn objects geometrically byn points, so that the interpoint distances correspond in some sense to experimental dissimilarities between objects. In just what sense distances and dissimilarities should correspond has been left rather vague in most approaches, thus leaving these approaches logically incomplete. Our fundamental hypothesis is that dissimilarities and distances are monotonically related. We define a quantitative, intuitively satisfying measure of goodness of fit to this hypothesis. Our technique of multidimensional scaling is to compute that configuration of points which optimizes the goodness of fit. A practical computer program for doing the calculations is described in a companion paper.},
issn={1860-0980},
doi={10.1007/BF02289565},
url={https://doi.org/10.1007/BF02289565}
}

@book{hamilton_2020, place={San Rafael, CA}, title={Graph representation learning}, publisher={Morgan & Claypool Publishers}, author={Hamilton, William L.}, year={2020}}

@book{scholkopf_warmuth_2003, place={Berlin, Heidelberg}, title={Computational Learning Theory and Kernel Machines: 16th Annual Conference on Computational Learning Theory and 7th Kernel Workshop, COLT/Kernel 2003, Washington, DC, August 24-27, 2003, Proceedings}, publisher={Springer Berlin Heidelberg}, author={Schölkopf, Bernhard and Warmuth, Manfred K}, year={2003}}

@inproceedings{bert,
  title={{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proc. Conf. North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  volume={1},
  pages={4171--4186},
  year={2019}
}

@inproceedings{gpt_3,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Proc. Int. Conf. Neural Information Processing Systems},
 pages = {1877--1901},
 title = {Language Models are Few-Shot Learners},
 volume = {33},
 year = {2020}
}

@inproceedings{xlm,
 author = {Conneau, Alexis and Lample, Guillaume},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {7059--7069},
 title = {Cross-lingual Language Model Pretraining},
 url = {https://proceedings.neurips.cc/paper/2019/file/c04c19c2c2474dbf5f7ac4372c5b9af1-Paper.pdf},
 volume = {32},
 year = {2019}
}

@inproceedings{bart,
  title={{BART}: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},
  author={Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Veselin and Zettlemoyer, Luke},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={7871--7880},
  year={2020}
}

@article{bort,
  author    = {Adrian de Wynter and
               Daniel J. Perry},
  title     = {Optimal Subarchitecture Extraction For {BERT}},
  journal   = {CoRR},
  volume    = {abs/2010.10499},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.10499},
  archivePrefix = {arXiv},
  eprint    = {2010.10499},
  timestamp = {Mon, 26 Oct 2020 15:39:44 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-10499.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{convbert,
 author = {Jiang, Zi-Hang and Yu, Weihao and Zhou, Daquan and Chen, Yunpeng and Feng, Jiashi and Yan, Shuicheng},
 booktitle = {Proc. Int. Conf. Neural Information Processing Systems},
 pages = {12837--12848},
 title = {Conv{BERT}: Improving {BERT} with Span-based Dynamic Convolution},
 volume = {33},
 year = {2020}
}

@article{perf_predictors,
  author    = {Colin White and
               Arber Zela and
               Binxin Ru and
               Yang Liu and
               Frank Hutter},
  title     = {How Powerful are Performance Predictors in Neural Architecture Search?},
  journal   = {CoRR},
  volume    = {abs/2104.01177},
  year      = {2021},
  url       = {https://arxiv.org/abs/2104.01177},
  archivePrefix = {arXiv},
  eprint    = {2104.01177},
  timestamp = {Mon, 12 Apr 2021 16:14:56 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2104-01177.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{lstm,
author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
title = {Long Short-Term Memory},
year = {1997},
issue_date = {November 15, 1997},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {9},
number = {8},
issn = {0899-7667},
journal = {Neural Comput.},
pages = {1735--1780},
numpages = {46}
}

@inproceedings{shaw2018selfattention,
  title={Self-Attention with Relative Position Representations},
  author={Shaw, Peter and Uszkoreit, Jakob and Vaswani, Ashish},
  booktitle={Proc. Conf. North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  volume={2},
  pages={464--468},
  year={2018}
}

@inproceedings{kim_cnn_nlp,
    title = "Convolutional Neural Networks for Sentence Classification",
    author = "Kim, Yoon",
    booktitle = "Proceedings of the Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D14-1181",
    doi = "10.3115/v1/D14-1181",
    pages = "1746--1751",
}

@inproceedings{roberta,
    title = "A Robustly Optimized {BERT} Pre-training Approach with Post-training",
    author = "Zhuang, Liu  and
      Wayne, Lin  and
      Ya, Shi  and
      Jun, Zhao",
    booktitle = "Proc. Chinese National Conference on Computational Linguistics",
    year = "2021",
    pages = "1218--1227"
}


@article{xlnet,
  author    = {Zhilin Yang and
               Zihang Dai and
               Yiming Yang and
               Jaime G. Carbonell and
               Ruslan Salakhutdinov and
               Quoc V. Le},
  title     = {{XLNet: Generalized} autoregressive pretraining for language understanding},
  journal   = {CoRR},
  volume    = {abs/1906.08237},
  year      = {2019},
  url       = {http://arxiv.org/abs/1906.08237},
  archivePrefix = {arXiv},
  eprint    = {1906.08237},
  timestamp = {Mon, 24 Jun 2019 17:28:45 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1906-08237.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{automl_survey,
title = {Auto{ML}: A survey of the state-of-the-art},
journal = {Knowledge-Based Systems},
volume = {212},
pages = {106622},
year = {2021},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2020.106622},
url = {https://www.sciencedirect.com/science/article/pii/S0950705120307516},
author = {Xin He and Kaiyong Zhao and Xiaowen Chu},
keywords = {Deep learning, Automated machine learning (autoML), Neural architecture search (NAS), Hyperparameter optimization (HPO)}
}

@article{nas_al,
  author    = {Yonatan Geifman and
               Ran El{-}Yaniv},
  title     = {Deep Active Learning with a Neural Architecture Search},
  journal   = {CoRR},
  volume    = {abs/1811.07579},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.07579},
  archivePrefix = {arXiv},
  eprint    = {1811.07579},
  timestamp = {Sun, 25 Nov 2018 18:57:12 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1811-07579.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Hanneke_2011,
   title={Rates of convergence in active learning},
   volume={39},
   ISSN={0090-5364},
   url={http://dx.doi.org/10.1214/10-AOS843},
   DOI={10.1214/10-aos843},
   number={1},
   journal={The Annals of Statistics},
   publisher={Institute of Mathematical Statistics},
   author={Hanneke, Steve},
   year={2011},
   month={Feb}
}

@inproceedings{ged_networkx,
author = {Abu-Aisheh, Zeina and Raveaux, Romain and Ramel, Jean-Yves and Martineau, Patrick},
title = {An Exact Graph Edit Distance Algorithm for Solving Pattern Recognition Problems},
year = {2015},
isbn = {9789897580765},
url = {https://doi.org/10.5220/0005209202710278},
doi = {10.5220/0005209202710278},
booktitle = {Proceedings of the International Conference on Pattern Recognition Applications and Methods - Volume 1},
pages = {271–278},
numpages = {8},
keywords = {Classification., Graph Matching, Pattern Recognition, Graph Edit Distance},
location = {Lisbon, Portugal}
}

@article{reinforce,
author = {Williams, Ronald J.},
title = {Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
year = {1992},
issue_date = {May 1992},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {3–4},
issn = {0885-6125},
url = {https://doi.org/10.1007/BF00992696},
doi = {10.1007/BF00992696},
journal = {Mach. Learn.},
month = may,
pages = {229–256},
numpages = {28},
keywords = {mathematical analysis, Reinforcement learning, connectionist networks, gradient descent}
}

@inproceedings{evolutionary_search,
  title={Regularized evolution for image classifier architecture search},
  author={Real, Esteban and Aggarwal, Alok and Huang, Yanping and Le, Quoc V},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={4780--4789},
  year={2019}
}

@inproceedings{nsga,
author = {Lu, Zhichao and Whalen, Ian and Boddeti, Vishnu and Dhebar, Yashesh and Deb, Kalyanmoy and Goodman, Erik and Banzhaf, Wolfgang},
title = {{NSGA-Net}: Neural Architecture Search Using Multi-Objective Genetic Algorithm},
year = {2019},
isbn = {9781450361118},
url = {https://doi.org/10.1145/3321707.3321729},
doi = {10.1145/3321707.3321729},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {419–427},
numpages = {9},
keywords = {neural architecture search, multi objective, {B}ayesian optimization, image classification, deep learning},
location = {Prague, Czech Republic}
}

@inproceedings{gp_bo,
 author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
 pages = {2951--2959},
 title = {Practical {B}ayesian Optimization of Machine Learning Algorithms},
 url = {https://proceedings.neurips.cc/paper/2012/file/05311655a15b75fab86956663e1819cd-Paper.pdf},
 volume = {25},
 year = {2012}
}

@inproceedings{bookcorpus,
  title={Aligning books and movies: Towards story-like visual explanations by watching movies and reading books},
  author={Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={19--27},
  year={2015}
}

@inproceedings{CC_news,
  title={{CC-News-En}: A large English news corpus},
  author={Mackenzie, Joel and Benham, Rodger and Petri, Matthias and Trippas, Johanne R and Culpepper, J Shane and Moffat, Alistair},
  booktitle={Proceedings of the 29th ACM International Conference on Information \& Knowledge Management},
  pages={3077--3084},
  year={2020}
}

@misc{OpenWebtext,  
	title={OpenWebText Corpus},
	author={Aaron Gokaslan and Vanya Cohen},
	howpublished={\url{http://Skylion007.github.io/OpenWebTextCorpus}}, 
	year={2019}
}

@inproceedings{optuna_2019,
    title={Optuna: A Next-generation Hyperparameter Optimization Framework},
    author={Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
    booktitle={Proceedings of the 25th {ACM} {SIGKDD} International Conference on Knowledge Discovery and Data Mining},
    year={2019}
}

@inproceedings{transformer_xl,
    title = "Transformer-{XL}: Attentive Language Models beyond a Fixed-Length Context",
    author = "Dai, Zihang  and
      Yang, Zhilin  and
      Yang, Yiming  and
      Carbonell, Jaime  and
      Le, Quoc  and
      Salakhutdinov, Ruslan",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    url = "https://aclanthology.org/P19-1285",
    doi = "10.18653/v1/P19-1285",
    pages = "2978--2988"
}

@inproceedings{npn,
author = {Wang, Hao and Shi, Xingjian and Yeung, Dit-Yan},
title = {Natural-Parameter Networks: A Class of Probabilistic Neural Networks},
year = {2016},
isbn = {9781510838819},
booktitle = {Proceedings of the 30th International Conference on Neural Information Processing Systems},
pages = {118–126},
numpages = {9},
}

@inproceedings{wma,
    title = "Effective Approaches to Attention-based Neural Machine Translation",
    author = "Luong, Thang  and
      Pham, Hieu  and
      Manning, Christopher D.",
    booktitle = "Proc. Conf. Empirical Methods in Natural Language Processing",
    year = "2015",
    doi = "10.18653/v1/D15-1166",
    pages = "1412--1421",
}

@inproceedings{huang2018music,
  title={Music Transformer: Generating Music with Long-Term Structure},
  author={Huang, Cheng-Zhi Anna and Vaswani, Ashish and Uszkoreit, Jakob and Simon, Ian and Hawthorne, Curtis and Shazeer, Noam and Dai, Andrew M and Hoffman, Matthew D and Dinculescu, Monica and Eck, Douglas},
  booktitle={Proceedings of the International Conference on Learning Representations},
  year={2018}
}


@InProceedings{mc_dropout,
  title = 	 {Dropout as a {B}ayesian Approximation: Representing Model Uncertainty in Deep Learning},
  author = 	 {Gal, Yarin and Ghahramani, Zoubin},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {1050--1059},
  year = 	 {2016},
  editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume = 	 {48},
  month = 	 {20--22 Jun},
  pdf = 	 {http://proceedings.mlr.press/v48/gal16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/gal16.html}
}

@article{turc2019,
  author    = {Iulia Turc and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {Well-Read Students Learn Better: The Impact of Student Initialization
               on Knowledge Distillation},
  journal   = {CoRR},
  volume    = {abs/1908.08962},
  year      = {2019},
  archivePrefix = {arXiv},
  eprint    = {1908.08962},
  timestamp = {Thu, 29 Aug 2019 16:32:34 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1908-08962.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{fastformer,
    title = "{F}ast{F}ormers: Highly Efficient Transformer Models for Natural Language Understanding",
    author = "Kim, Young Jin  and
      Hassan, Hany",
    booktitle = "Proc. SustaiNLP Workshop on Simple and Efficient Natural Language Processing",
    year = "2020",
    pages = "149--158"
}

@article{infinitytransformer,
  author={Pedro Henrique Martins and Zita Marinho and André F. T. Martins},
  title={$\infty$-former: Infinite Memory Transformer},
  journal   = {CoRR},
  volume    = {abs/2109.00301},
  year      = {2021},
  url       = {https://arxiv.org/abs/2109.00301},
  eprinttype = {arXiv},
  eprint    = {2109.00301},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{performer,
  author    = {Krzysztof Choromanski and
               Valerii Likhosherstov and
               David Dohan and
               Xingyou Song and
               Andreea Gane and
               Tam{\'{a}}s Sarl{\'{o}}s and
               Peter Hawkins and
               Jared Davis and
               Afroz Mohiuddin and
               Lukasz Kaiser and
               David Belanger and
               Lucy J. Colwell and
               Adrian Weller},
  title     = {Rethinking Attention with Performers},
  journal   = {CoRR},
  volume    = {abs/2009.14794},
  year      = {2020},
  url       = {https://arxiv.org/abs/2009.14794},
  eprinttype = {arXiv},
  eprint    = {2009.14794},
  timestamp = {Wed, 23 Jun 2021 10:58:18 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2009-14794.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{tran_generalization,
  author={R\'obert Csord\'as and Kazuki Irie and Jürgen Schmidhuber},
  title={The Devil is in the Detail: Simple Tricks Improve Systematic Generalization of Transformers}, 
  journal   = {CoRR},
  volume    = {abs/2108.12284},
  year      = {2021},
  url       = {https://arxiv.org/abs/2108.12284},
  eprinttype = {arXiv},
  eprint    = {2108.12284},
  timestamp = {Wed, 23 Jun 2021 10:58:18 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2108-12284.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{longformer,
  author    = {Iz Beltagy and
               Matthew E. Peters and
               Arman Cohan},
  title     = {Longformer: The Long-Document Transformer},
  journal   = {CoRR},
  volume    = {abs/2004.05150},
  year      = {2020}
}

@inproceedings{bigbird,
 author = {Zaheer, Manzil and Guruganesh, Guru and Dubey, Kumar Avinava and Ainslie, Joshua and Alberti, Chris and Ontanon, Santiago and Pham, Philip and Ravula, Anirudh and Wang, Qifan and Yang, Li and Ahmed, Amr},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {17283--17297},
 publisher = {Curran Associates, Inc.},
 title = {Big Bird: Transformers for Longer Sequences},
 url = {https://proceedings.neurips.cc/paper/2020/file/c8512d142a2d849725f31a9a7a361ab9-Paper.pdf},
 volume = {33},
 year = {2020}
}

@inproceedings{lambda_network,
title={LambdaNetworks: Modeling long-range Interactions without Attention},
author={Irwan Bello},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=xTJEN-ggl1b}
}

@inproceedings{pubmed,
    title = "A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents",
    author = "Cohan, Arman  and
      Dernoncourt, Franck  and
      Kim, Doo Soon  and
      Bui, Trung  and
      Kim, Seokhwan  and
      Chang, Walter  and
      Goharian, Nazli",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-2097",
    doi = "10.18653/v1/N18-2097",
    pages = "615--621"
}

@inproceedings{wikitext,
  author    = {Stephen Merity and
               Caiming Xiong and
               James Bradbury and
               Richard Socher},
  title     = {Pointer Sentinel Mixture Models},
  booktitle={International Conference on Learning Representations},
  year={2016},
  url={https://openreview.net/forum?id=Byj72udxe}
}


@InProceedings{scan,
  title = 	 {Generalization without Systematicity: On the Compositional Skills of Sequence-to-Sequence Recurrent Networks},
  author =       {Lake, Brenden and Baroni, Marco},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {2873--2882},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/lake18a/lake18a.pdf},
  url = 	 {https://proceedings.mlr.press/v80/lake18a.html}
}


@inproceedings{cfq,
  author    = {Daniel Keysers and
               Nathanael Sch{\"{a}}rli and
               Nathan Scales and
               Hylke Buisman and
               Daniel Furrer and
               Sergii Kashubin and
               Nikola Momchev and
               Danila Sinopalnikov and
               Lukasz Stafiniak and
               Tibor Tihon and
               Dmitry Tsarkov and
               Xiao Wang and
               Marc van Zee and
               Olivier Bousquet},
  title     = {Measuring Compositional Generalization: {A} Comprehensive Method on
               Realistic Data},
  booktitle={International Conference on Learning Representations},
  year={2020},
  https://openreview.net/forum?id=SygcCnNKwr
}

@inproceedings{pcfg,
  title     = {Compositionality Decomposed: How do Neural Networks Generalise? (Extended Abstract)},
  author    = {Hupkes, Dieuwke and Dankers, Verna and Mul, Mathijs and Bruni, Elia},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Christian Bessiere},
  pages     = {5065--5069},
  year      = {2020},
  month     = {July},
  doi       = {10.24963/ijcai.2020/708},
  url       = {https://doi.org/10.24963/ijcai.2020/708},
}

@inproceedings{cogs,
    title = "{COGS}: A Compositional Generalization Challenge Based on Semantic Interpretation",
    author = "Kim, Najoung  and
      Linzen, Tal",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.731",
    doi = "10.18653/v1/2020.emnlp-main.731",
    pages = "9087--9105"
}

@inproceedings{squad,
    title = "{SQ}u{AD}: 100,000+ Questions for Machine Comprehension of Text",
    author = "Rajpurkar, Pranav  and
      Zhang, Jian  and
      Lopyrev, Konstantin  and
      Liang, Percy",
    booktitle = "Proc. Int. Conf. Empirical Methods in Natural Language Processing",
    year = "2016",
    doi = "10.18653/v1/D16-1264",
    pages = "2383--2392",
}

@InProceedings{imdb,
  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},
  title     = {Learning Word Vectors for Sentiment Analysis},
  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {142--150},
  url       = {http://www.aclweb.org/anthology/P11-1015}
}

@inproceedings{mind,
    title = "{MIND}: A Large-scale Dataset for News Recommendation",
    author = "Wu, Fangzhao  and
      Qiao, Ying  and
      Chen, Jiun-Hung  and
      Wu, Chuhan  and
      Qi, Tao  and
      Lian, Jianxun  and
      Liu, Danyang  and
      Xie, Xing  and
      Gao, Jianfeng  and
      Wu, Winnie  and
      Zhou, Ming",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.331",
    doi = "10.18653/v1/2020.acl-main.331",
    pages = "3597--3606",
}

@INPROCEEDINGS{imagenet,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  volume={},
  number={},
  pages={248-255},
  doi={10.1109/CVPR.2009.5206848}}
  
@inproceedings{reformer,
title={Reformer: The Efficient Transformer},
author={Nikita Kitaev and Lukasz Kaiser and Anselm Levskaya},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rkgNKkHtvB}
}

@inproceedings{darts,
title={{DARTS}: Differentiable Architecture Search},
author={Hanxiao Liu and Karen Simonyan and Yiming Yang},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=S1eYHoC5FX},
}

@inproceedings{tinybert,
    title = "{T}iny{BERT}: Distilling {BERT} for Natural Language Understanding",
    author = "Jiao, Xiaoqi  and
      Yin, Yichun  and
      Shang, Lifeng  and
      Jiang, Xin  and
      Chen, Xiao  and
      Li, Linlin  and
      Wang, Fang  and
      Liu, Qun",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.372",
    doi = "10.18653/v1/2020.findings-emnlp.372",
    pages = "4163--4174"
}

@ARTICLE{sze_dnn_mapper,
  author={Chen, Yu-Hsin and Emer, Joel and Sze, Vivienne},
  journal={IEEE Micro}, 
  title={Using Dataflow to Optimize Energy Efficiency of Deep Neural Network Accelerators}, 
  year={2017},
  volume={37},
  number={3},
  pages={12-21},
  doi={10.1109/MM.2017.54}}
  
@INPROCEEDINGS{gamma_mapper,
  author={Kao, Sheng-Chun and Krishna, Tushar},
  booktitle={2020 IEEE/ACM International Conference On Computer Aided Design (ICCAD)}, 
  title={GAMMA: Automating the HW Mapping of DNN Models on Accelerators via Genetic Algorithm}, 
  year={2020},
  volume={},
  number={},
  pages={1-9},
  doi={}}
  

@BOOK{sze_dnn_book,
  author={Sze, Vivienne and Chen, Yu-Hsin and Yang, Tien-Ju and Emer, Joel S.},
  booktitle={Efficient Processing of Deep Neural Networks},
  year={2020},
  volume={},
  number={},
  pages={},
  doi={}}
  
@ARTICLE{spring,
  author={Yu, Ye and Jha, Niraj K},
  journal={IEEE Trans. Emerging Topics in Computing}, 
  title={{SPRING: A} Sparsity-Aware Reduced-Precision Monolithic {3D CNN} Accelerator Architecture for Training and Inference}, 
  year={2022},
  volume={10},
  number={1},
  pages={237-249},
  doi={10.1109/TETC.2020.3003328}}
  
@article{skip_conn_types,
  author    = {Fenglin Liu and
               Xuancheng Ren and
               Zhiyuan Zhang and
               Xu Sun and
               Yuexian Zou},
  title     = {Rethinking Skip Connection with Layer Normalization in Transformers
               and ResNets},
  journal   = {CoRR},
  volume    = {abs/2105.07205},
  year      = {2021},
  url       = {https://arxiv.org/abs/2105.07205},
  eprinttype = {arXiv},
  eprint    = {2105.07205},
  timestamp = {Tue, 18 May 2021 18:46:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2105-07205.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{mobilevit,
  title={{MobileViT}: Light-weight, General-purpose, and Mobile-friendly Vision Transformer}, 
  author={Sachin Mehta and Mohammad Rastegari},
  year={2021},
  journal   = {CoRR},
  volume    = {abs/2110.02178},
  year      = {2021},
  url       = {https://arxiv.org/abs/2110.02178},
  eprinttype = {arXiv},
  eprint    = {2110.02178},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2110-02178.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{flexibert,
  author    = {Shikhar Tuli and Bhishma Dedhia and Shreshth Tuli and Niraj K. Jha},
  title     = {{FlexiBERT}: Are current Transformer Architectures too Homogeneous and Rigid?},
  journal   = {CoRR},
  volume    = {abs/2205.11656},
  year      = {2022},
  eprinttype = {arXiv},
  eprint    = {2205.11656}
}

@inproceedings{squeezebert,
    title = "{S}queeze{BERT}: What can computer vision teach {NLP} about efficient neural networks?",
    author = "Iandola, Forrest  and
      Shaw, Albert  and
      Krishna, Ravi  and
      Keutzer, Kurt",
    booktitle = "Proc. SustaiNLP: Workshop on Simple and Efficient Natural Language Processing",
    month = Nov,
    year = "2020",
    doi = "10.18653/v1/2020.sustainlp-1.17",
    pages = "124--135",
}

@inproceedings{autotinybert,
    title = "{A}uto{T}iny{BERT}: Automatic Hyper-parameter Optimization for Efficient Pre-trained Language Models",
    author = "Yin, Yichun  and
      Chen, Cheng  and
      Shang, Lifeng  and
      Jiang, Xin  and
      Chen, Xiao  and
      Liu, Qun",
    booktitle = "Proc. 59th Annual Meeting of the Association for Computational Linguistics",
    year = "2021",
    pages = "5146--5157",
}

@inproceedings{ftrans, author = {Li, Bingbing and Pandey, Santosh and Fang, Haowen and Lyv, Yanjun and Li, Ji and Chen, Jieyang and Xie, Mimi and Wan, Lipeng and Liu, Hang and Ding, Caiwen}, title = {{FTRANS}: Energy-Efficient Acceleration of Transformers Using {FPGA}}, year = {2020}, isbn = {9781450370530},  doi = {10.1145/3370748.3406567}, booktitle = {Proc. ACM/IEEE Int. Symp. Low Power Electronics and Design}, pages = {175--180}, numpages = {6} }

@InProceedings{nas-bert, 
    author = {Xu, Jin and Tan, Xu and Luo, Renqian and Song, Kaitao and Li, Jian and Qin, Tao and Liu, Tie-Yan}, 
    title = {{NAS-BERT: T}ask-Agnostic and Adaptive-Size {BERT} Compression with Neural Architecture Search}, 
    year = {2021}, 
    booktitle = {Proc. 27th ACM SIGKDD Conf. Knowledge Discovery \& Data Mining}, 
    pages = {1933--1943}, numpages = {11}, 
}

@article{turing_nlg,
  author    = {Shaden Smith and
               Mostofa Patwary and
               Brandon Norick and
               Patrick LeGresley and
               Samyam Rajbhandari and
               Jared Casper and
               Zhun Liu and
               Shrimai Prabhumoye and
               George Zerveas and
               Vijay Korthikanti and
               Elton Zheng and
               Rewon Child and
               Reza Yazdani Aminabadi and
               Julie Bernauer and
               Xia Song and
               Mohammad Shoeybi and
               Yuxiong He and
               Michael Houston and
               Saurabh Tiwary and
               Bryan Catanzaro},
  title     = {Using {DeepSpeed} and {Megatron} to Train {Megatron-Turing} {NLG} {530B},
               {A} Large-Scale Generative Language Model},
  journal   = {CoRR},
  volume    = {abs/2201.11990},
  year      = {2022},
  eprinttype = {arXiv},
  eprint    = {2201.11990},
  timestamp = {Wed, 02 Feb 2022 15:00:01 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2201-11990.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{bit,
author="Kolesnikov, Alexander
and Beyer, Lucas
and Zhai, Xiaohua
and Puigcerver, Joan
and Yung, Jessica
and Gelly, Sylvain
and Houlsby, Neil",
title="{Big Transfer (BiT)}: General Visual Representation Learning",
booktitle="Proc. European Conference on Computer Vision",
year="2020",
pages="491--507",
isbn="978-3-030-58558-7"
}


@InProceedings{micronet,
  title = 	 {{MicroNet} for Efficient Language Modeling},
  author =       {Yan, Zhongxia and Wang, Hanrui and Guo, Demi and Han, Song},
  booktitle = 	 {Proc. Int. Conf. Neural Information Processing Systems},
  pages = 	 {215--231},
  year = 	 {2020},
  volume = 	 {123},
  pdf = 	 {http://proceedings.mlr.press/v123/yan20a/yan20a.pdf},
}

@INPROCEEDINGS{naas,
  author={Lin, Yujun and Yang, Mengtian and Han, Song},
  booktitle={Proc. 58th ACM/IEEE Design Automation Conference}, 
  title={{NAAS: N}eural Accelerator Architecture Search}, 
  year={2021},
  volume={},
  number={},
  pages={1051-1056},
  doi={10.1109/DAC18074.2021.9586250}}


@article{codebench,
  author    = {Shikhar Tuli and Chia Hao Li and Ritvik Sharma and Niraj K. Jha},
  title     = {{CODEBench}: A Neural Architecture and Hardware Accelerator Co-Design Framework},
  journal   = {ACM Trans. Embedded Computing Systems},
  url = {https://doi.org/10.1145/3575798},
  month = {Dec.},
  doi = {10.1145/3575798},
  year      = {2022},
}

@ARTICLE{nest,
  author={Dai, Xiaoliang and Yin, Hongxu and Jha, Niraj K.},
  journal={IEEE Trans. Computers}, 
  title={{NeST}: A Neural Network Synthesis Tool Based on a Grow-and-Prune Paradigm}, 
  year={2019},
  volume={68},
  number={10},
  pages={1487-1497},
  doi={10.1109/TC.2019.2914438}}
  
@inproceedings{mcunet,
 author = {Lin, Ji and Chen, Wei-Ming and Lin, Yujun and Cohn, John and Gan, Chuang and Han, Song},
 booktitle = {Proc. Int. Conf. Neural Information Processing Systems},
 pages = {11711--11722},
 title = {{MCUNet}: Tiny Deep Learning on {IoT} Devices},
 volume = {33},
 year = {2020},
}

@book{random_number_generation,
  title={Random number generation and quasi-Monte Carlo methods},
  author={Niederreiter, Harald},
  year={1992},
  publisher={SIAM}
}

@Article{diversity_measures,
author={Tang, E. K.
and Suganthan, P. N.
and Yao, X.},
title={An analysis of diversity measures},
journal={Machine Learning},
year={2006},
month={Oct},
day={01},
volume={65},
number={1},
pages={247-271},
abstract={Diversity among the base classifiers is deemed to be important when constructing a classifier ensemble. Numerous algorithms have been proposed to construct a good classifier ensemble by seeking both the accuracy of the base classifiers and the diversity among them. However, there is no generally accepted definition of diversity, and measuring the diversity explicitly is very difficult. Although researchers have designed several experimental studies to compare different diversity measures, usually confusing results were observed. In this paper, we present a theoretical analysis on six existing diversity measures (namely disagreement measure, double fault measure, KW variance, inter-rater agreement, generalized diversity and measure of difficulty), show underlying relationships between them, and relate them to the concept of margin, which is more explicitly related to the success of ensemble learning algorithms. We illustrate why confusing experimental results were observed and show that the discussed diversity measures are naturally ineffective. Our analysis provides a deeper understanding of the concept of diversity, and hence can help design better ensemble learning algorithms.},
issn={1573-0565},
doi={10.1007/s10994-006-9449-2},
}

@inproceedings{dynabert,
 author = {Hou, Lu and Huang, Zhiqi and Shang, Lifeng and Jiang, Xin and Chen, Xiao and Liu, Qun},
 booktitle = {Proc. Int. Conf. Neural Information Processing Systems},
 pages = {9782--9793},
 title = {{DynaBERT}: Dynamic {BERT} with Adaptive Width and Depth},
 volume = {33},
 year = {2020}
}

@inproceedings{adabert, author = {Chen, Daoyuan and Li, Yaliang and Qiu, Minghui and Wang, Zhen and Li, Bofang and Ding, Bolin and Deng, Hongbo and Huang, Jun and Lin, Wei and Zhou, Jingren}, title = {{AdaBERT}: Task-Adaptive {BERT} Compression with Differentiable Neural Architecture Search}, year = {2021}, isbn = {9780999241165}, booktitle = {Proc. Int. Joint Conference on Artificial Intelligence}, articleno = {341}, numpages = {7} }

@article{autobertzero,
  author    = {Jiahui Gao and
               Hang Xu and
               Han Shi and
               Xiaozhe Ren and
               Philip L. H. Yu and
               Xiaodan Liang and
               Xin Jiang and
               Zhenguo Li},
  title     = {{AutoBERT-Zero}: Evolving {BERT} Backbone from Scratch},
  journal   = {CoRR},
  volume    = {abs/2107.07445},
  year      = {2021},
  eprinttype = {arXiv},
  eprint    = {2107.07445},
  timestamp = {Wed, 01 Sep 2021 12:22:22 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2107-07445.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{gobo,
  author={Zadeh, Ali Hadi and Edo, Isak and Awad, Omar Mohamed and Moshovos, Andreas},
  booktitle={Proc. 53rd Annual IEEE/ACM International Symp. Microarchitecture (MICRO)}, 
  title={{GOBO}: Quantizing Attention-Based {NLP} Models for Low Latency and Energy Efficient Inference}, 
  year={2020},
  volume={},
  number={},
  pages={811-824},
  doi={10.1109/MICRO50266.2020.00071}}

@article{efficient_txf_survey, author = {Tay, Yi and Dehghani, Mostafa and Bahri, Dara and Metzler, Donald}, title = {Efficient Transformers: A Survey}, year = {2022}, publisher = {Association for Computing Machinery}, journal = {ACM Comput. Surv.} }

@INBOOK{rnn,
  author={Rumelhart, David E. and McClelland, James L.},
  booktitle={Parallel Distributed Processing: Explorations in the Microstructure of Cognition: Foundations}, 
  title={Learning Internal Representations by Error Propagation}, 
  publisher = {MIT Press},
  year={1987},
  volume={},
  number={},
  pages={318-362}, 
  doi={}}

@ARTICLE{eyeriss,
  author={Chen, Yu-Hsin and Krishna, Tushar and Emer, Joel S. and Sze, Vivienne},
  journal={IEEE J. Solid-State Circuits}, 
  title={{Eyeriss: An} Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks}, 
  year={2017},
  volume={52},
  number={1},
  pages={127-138},
  doi={10.1109/JSSC.2016.2616357}
}

@BOOK{VivienneSzeBook,
  author = {Vivienne Sze and Yu-Hsin Chen and Tien-Ju Yang and Joel Emer},
  title = {Efficient Processing of Deep Neural Networks},
  year = {2020},
  publisher = {Morgan and Claypool Publishers}
}

@inproceedings{a3,
  title={A$^3$: Accelerating attention mechanisms in neural networks with approximation},
  author={Ham, Tae Jun and Jung, Sung Jun and Kim, Seonghak and Oh, Young H and Park, Yeonhong and Song, Yoonho and Park, Jung-Hun and Lee, Sanghee and Park, Kyoung and Lee, Jae W and others},
  booktitle={Proc. Int. Symp. High-Performance Computer Architecture},
  pages={328--341},
  year={2020}}

@INPROCEEDINGS{spatten,
  author={Wang, Hanrui and Zhang, Zhekai and Han, Song},
  booktitle={Proc. Int. Symp. High-Performance Computer Architecture}, 
  title={{SpAtten}: Efficient Sparse Attention Architecture with Cascade Token and Head Pruning}, 
  year={2021},
  volume={},
  number={},
  pages={97-110},
  doi={10.1109/HPCA51647.2021.00018}}

@ARTICLE{energon,
  author={Zhou, Zhe and Liu, Junlin and Gu, Zhenyu and Sun, Guangyu},
  journal={IEEE Trans. Computer-Aided Design of Integrated Circuits and Systems}, 
  title={Energon: Towards Efficient Acceleration of Transformers Using Dynamic Sparse Attention},
  year={2022},
  volume={},
  number={},
  pages={1-14},
  doi={10.1109/TCAD.2022.3170848}}

@inproceedings{optimus,
 author = {Park, Junki and Yoon, Hyunsung and Ahn, Daehyun and Choi, Jungwook and Kim, Jae-Joon},
 booktitle = {Proc. Machine Learning and Systems},
 pages = {363--378},
 title = {{OPTIMUS}: OPTImized matrix MUltiplication Structure for Transformer neural network accelerator},
 volume = {2},
 year = {2020}
}

@INPROCEEDINGS{fpga_accelerator_1,
  author={Lu, Siyuan and Wang, Meiqi and Liang, Shuang and Lin, Jun and Wang, Zhongfeng},
  booktitle={Proc. Int. System-on-Chip Conference}, 
  title={Hardware Accelerator for Multi-Head Attention and Position-Wise Feed-Forward in the Transformer}, 
  year={2020},
  volume={},
  number={},
  pages={84-89},
  doi={10.1109/SOCC49529.2020.9524802}}

@INPROCEEDINGS{fpga_accelerator_2,
  author={Peng, Hongwu and Huang, Shaoyi and Geng, Tong and Li, Ang and Jiang, Weiwen and Liu, Hang and Wang, Shusen and Ding, Caiwen},
  booktitle={Proc. Int. Symp. Quality Electronic Design}, 
  title={Accelerating Transformer-based Deep Learning Models on {FPGA}s using Column Balanced Block Pruning}, 
  year={2021},
  volume={},
  number={}, 
  pages={142-148},
  doi={10.1109/ISQED51717.2021.9424344}}

@INPROCEEDINGS{plasticine,
  author={Prabhakar, Raghu and Zhang, Yaqi and Koeplinger, David and Feldman, Matt and Zhao, Tian and Hadjis, Stefan and Pedram, Ardavan and Kozyrakis, Christos and Olukotun, Kunle},
  booktitle={Proc. ACM/IEEE Int. Symp. Computer Architecture}, 
  title={Plasticine: A reconfigurable architecture for parallel patterns}, 
  year={2017},
  volume={},
  number={},
  pages={389-402},
  doi={10.1145/3079856.3080256}}
  
@ARTICLE{monolithic_3d_rram,
  author={Yu, Ye and Jha, Niraj K.},
  journal={IEEE Trans. Nanotechnology}, 
  title={Energy-Efficient Monolithic Three-Dimensional On-Chip Memory Architectures}, 
  year={2018},
  volume={17},
  number={4},
  pages={620-633},
  doi={10.1109/TNANO.2017.2731871}}
  
@inproceedings{
bert_nmt,
title={Incorporating {BERT} into Neural Machine Translation},
author={Jinhua Zhu and Yingce Xia and Lijun Wu and Di He and Tao Qin and Wengang Zhou and Houqiang Li and Tieyan Liu},
booktitle={Proc. Int. Conf. Learning Representations},
year={2020}
}

@inproceedings{compressing_bert,
    title = "Compressing {BERT}: Studying the Effects of Weight Pruning on Transfer Learning",
    author = "Gordon, Mitchell  and
      Duh, Kevin  and
      Andrews, Nicholas",
    booktitle = "Proc. Workshop on Representation Learning for NLP",
    year = "2020",
    pages = "143--155"
}

@inproceedings{movement_pruning,
 author = {Sanh, Victor and Wolf, Thomas and Rush, Alexander},
 booktitle = {Proc. Int. Conf. Neural Information Processing Systems},
 pages = {20378--20389},
 title = {Movement Pruning: Adaptive Sparsity by Fine-Tuning},
 volume = {33},
 year = {2020}
}

@article{linformer,
  author    = {Sinong Wang and
               Belinda Z. Li and
               Madian Khabsa and
               Han Fang and
               Hao Ma},
  title     = {Linformer: Self-Attention with Linear Complexity},
  journal   = {CoRR},
  volume    = {abs/2006.04768},
  year      = {2020},
  eprinttype = {arXiv},
  eprint    = {2006.04768}
}

@article{distillbert,
  author    = {Victor Sanh and
               Lysandre Debut and
               Julien Chaumond and
               Thomas Wolf},
  title     = {{DistilBERT}, a distilled version of {BERT:} smaller, faster, cheaper
               and lighter},
  journal   = {CoRR},
  volume    = {abs/1910.01108},
  year      = {2019},
  eprinttype = {arXiv},
  eprint    = {1910.01108},
  timestamp = {Tue, 02 Jun 2020 12:48:59 +0200}
}

@electronic{dc,
 title     = {{Synopsys Design Compiler (2022)}},
 url       = {https://www.synopsys.com/implementation-and-signoff/rtl-synthesis-test/dc-ultra.html},
}

@ARTICLE{14nm,
  author={Guler, Abdullah and Jha, Niraj K.},
  journal={IEEE Trans. Very Large Scale Integration Systems}, 
  title={Hybrid Monolithic {3-D} {IC} Floorplanner}, 
  year={2018},
  volume={26},
  number={10},
  pages={1868-1880},
  doi={10.1109/TVLSI.2018.2832607}}
  
@inproceedings{capo, author = {Roy, Jarrod A. and Papa, David A. and Adya, Saurabh N. and Chan, Hayward H. and Ng, Aaron N. and Lu, James F. and Markov, Igor L.}, title = {Capo: Robust and Scalable Open-Source Min-Cut Floorplacer}, year = {2005}, booktitle = {Proc. Int. Symp. Physical Design}, pages = {224--226}, numpages = {3} }

@INPROCEEDINGS{fincacti,
  author={Shafaei, Alireza and Wang, Yanzhi and Lin, Xue and Pedram, Massoud},
  booktitle={Proc. Computer Society Annual Symp. VLSI}, 
  title={{FinCACTI}: Architectural Analysis and Modeling of Caches with Deeply-Scaled {FinFET} Devices}, 
  year={2014},
  volume={},
  number={},
  pages={290-295},
  doi={10.1109/ISVLSI.2014.94}}

@ARTICLE{nvsim,
  author={Dong, Xiangyu and Xu, Cong and Xie, Yuan and Jouppi, Norman P.},
  journal={IEEE Trans. Computer-Aided Design of Integrated Circuits and Systems}, 
  title={{NVSim}: A Circuit-Level Performance, Energy, and Area Model for Emerging Nonvolatile Memory}, 
  year={2012},
  volume={31},
  number={7},
  pages={994-1007},
  doi={10.1109/TCAD.2012.2185930}}
  
@ARTICLE{nvmain,
  author={Poremba, Matthew and Zhang, Tao and Xie, Yuan},
  journal={IEEE Computer Architecture Letters}, 
  title={{NVMain} 2.0: A User-Friendly Memory Simulator to Model (Non-)Volatile Memory Systems}, 
  year={2015},
  volume={14},
  number={2},
  pages={140-143},
  doi={10.1109/LCA.2015.2402435}}

@article{bert_nlg,
    title = "Leveraging Pre-trained Checkpoints for Sequence Generation Tasks",
    author = "Rothe, Sascha  and
      Narayan, Shashi  and
      Severyn, Aliaksei",
    journal = "Trans. Association for Computational Linguistics",
    volume = "8",
    year = "2020",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    pages = "264--280"
}

@article{layer_norm,
  author    = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  title     = {Layer normalization},
  journal   = {CoRR},
  volume    = {abs/1607.06450},
  year      = {2016},
  archivePrefix = {arXiv},
  eprint    = {1607.06450},
}

@article{gelu,
  author    = {Dan Hendrycks and
               Kevin Gimpel},
  title     = {Bridging Nonlinearities and Stochastic Regularizers with {Gaussian}
               Error Linear Units},
  journal   = {CoRR},
  volume    = {abs/1606.08415},
  year      = {2016},
  eprinttype = {arXiv},
  eprint    = {1606.08415}
}

@inproceedings{tiling_gpu, author = {Niu, Yuyao and Lu, Zhengyang and Ji, Haonan and Song, Shuhui and Jin, Zhou and Liu, Weifeng}, title = {{TileSpGEMM}: A Tiled Algorithm for Parallel Sparse General Matrix-Matrix Multiplication on {GPU}s}, year = {2022}, isbn = {9781450392044},  booktitle = {Proc. 27th ACM SIGPLAN Symp. Principles and Practice of Parallel Programming}, pages = {90--106}, numpages = {17} }

@INPROCEEDINGS{miv,
  author={Batude, P. and Sklenard, B. and Fenouillet-Beranger, C. and Previtali, B. and Tabone, C. and Rozeau, O. and Billoint, O. and Turkyilmaz, O. and Sarhan, H. and Thuries, S. and Cibrario, G. and Brunet, L. and Deprat, F. and Michallet, J-E. and Clermidy, F. and Vinet, M.},
  booktitle={Proc. Int. Interconnect Technology Conference}, 
  title={{3D} sequential integration opportunities and technology optimization}, 
  year={2014},
  volume={},
  number={},
  pages={373-376},
  doi={10.1109/IITC.2014.6831837}}

@electronic{rpi,
 title     = {{Raspberry Pi 4 Model-B}},
 url       = {https://www.raspberrypi.com/products/raspberry-pi-4-model-b/},
}

@electronic{ncs,
 title     = {{Intel Neural Compute Stick 2}},
 url       = {https://www.intel.com/content/www/us/en/developer/tools/neural-compute-stick/overview.html},
}

@inproceedings{bert_overparameterized,
    title = "Visualizing and Understanding the Effectiveness of {BERT}",
    author = "Hao, Yaru  and
      Dong, Li  and
      Wei, Furu  and
      Xu, Ke",
    booktitle = "Proc. Int. Conf. Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    year = "2019",
    doi = "10.18653/v1/D19-1424",
    pages = "4143--4152",
}

@INPROCEEDINGS{binning,
  author={Sartori, John and Pant, Aashish and Kumar, Rakesh and Gupta, Puneet},
  booktitle={Proc. Int. Symp. Quality Electronic Design}, 
  title={Variation-aware speed binning of multi-core processors}, 
  year={2010},
  volume={},
  number={},
  pages={307-314},
  doi={10.1109/ISQED.2010.5450442}}

@INPROCEEDINGS{cnvlutin,
  author={Albericio, Jorge and Judd, Patrick and Hetherington, Tayler and Aamodt, Tor and Jerger, Natalie Enright and Moshovos, Andreas},
  booktitle={Proc. ACM/IEEE Int. Symp. Computer Architecture}, 
  title={Cnvlutin: Ineffectual-Neuron-Free Deep Neural Network Computing}, 
  year={2016},
  volume={},
  number={},
  pages={1-13},
  doi={10.1109/ISCA.2016.11}
}

  
@INPROCEEDINGS{dadiannao,
  author={Chen, Yunji and Luo, Tao and Liu, Shaoli and Zhang, Shijin and He, Liqiang and Wang, Jia and Li, Ling and Chen, Tianshi and Xu, Zhiwei and Sun, Ninghui and Temam, Olivier},
  booktitle={Proc. IEEE/ACM Int. Symp. Microarchitecture}, 
  title={{DaDianNao: A} Machine-Learning Supercomputer}, 
  year={2014},
  volume={},
  number={},
  pages={609-622},
  doi={10.1109/MICRO.2014.58}}
  
@INPROCEEDINGS{cambricon-x,
  author={Zhang, Shijin and Du, Zidong and Zhang, Lei and Lan, Huiying and Liu, Shaoli and Li, Ling and Guo, Qi and Chen, Tianshi and Chen, Yunji},
  booktitle={Proc. IEEE/ACM Int. Symp. Microarchitecture}, 
  title={{Cambricon-X: An} accelerator for sparse neural networks}, 
  year={2016},
  volume={},
  number={},
  pages={1-12},
  doi={10.1109/MICRO.2016.7783723}
}
  
@INPROCEEDINGS{cambricon-s,
  author={Zhou, Xuda and Du, Zidong and Guo, Qi and Liu, Shaoli and Liu, Chengsi and Wang, Chao and Zhou, Xuehai and Li, Ling and Chen, Tianshi and Chen, Yunji},
  booktitle={Proc. IEEE/ACM Int. Symp. Microarchitecture}, 
  title={{Cambricon-S: Addressing} Irregularity in Sparse Neural Networks through A Cooperative Software/Hardware Approach}, 
  year={2018},
  volume={},
  number={},
  pages={15-28},
  doi={10.1109/MICRO.2018.00011}}
  
@INPROCEEDINGS{duet,
  author={Liu, Liu and Qu, Zheng and Deng, Lei and Tu, Fengbin and Li, Shuangchen and Hu, Xing and Gu, Zhenyu and Ding, Yufei and Xie, Yuan},
  booktitle={Proc. IEEE/ACM Int. Symp. Microarchitecture}, 
  title={{DUET}: Boosting Deep Neural Network Efficiency on Dual-Module Architecture}, 
  year={2020},
  volume={},
  number={},
  pages={738-750}}
  
@inproceedings{stochastic_rounding, author = {Gupta, Suyog and Agrawal, Ankur and Gopalakrishnan, Kailash and Narayanan, Pritish}, title = {Deep Learning with Limited Numerical Precision}, year = {2015}, booktitle = {Proc. Int. Conf. Machine Learning}, pages = {1737--1746}, numpages = {10}, location = {Lille, France} }

@inproceedings{block_pruning,
    title = "Block Pruning For Faster Transformers",
    author = "Lagunas, Fran{\c{c}}ois  and
      Charlaix, Ella  and
      Sanh, Victor  and
      Rush, Alexander",
    booktitle = "Proc. Int. Conf. Empirical Methods in Natural Language Processing",
    year = "2021",
    pages = "10619--10629"
}

@inproceedings{one_proxy_device,
author = {Lu, Bingqian and Yang, Jianyi and Jiang, Weiwen and Shi, Yiyu and Ren, Shaolei},
title = {One Proxy Device Is Enough for Hardware-Aware Neural Architecture Search},
year = {2021},
volume = {5},
number = {3},
booktitle = {Proc. ACM Meas. Anal. Comput. Syst.},
articleno = {34},
numpages = {34}
}

@ARTICLE{hw_sw_co-exp,
  author={Jiang, Weiwen and Yang, Lei and Sha, Edwin Hsing-Mean and Zhuge, Qingfeng and Gu, Shouzhen and Dasgupta, Sakyasingha and Shi, Yiyu and Hu, Jingtong},
  journal={IEEE Trans. Computer-Aided Design of Integrated Circuits and Systems}, 
  title={Hardware/Software Co-Exploration of Neural Architectures}, 
  year={2020},
  volume={39},
  number={12},
  pages={4805-4815},
  doi={10.1109/TCAD.2020.2986127}}
  
@ARTICLE{imtransformer,
  author={Laguna, Ann Franchesca and Sharifi, Mohammed Mehdi and Kazemi, Arman and Yin, Xunzhao and Niemier, Michael and Hu, X. Sharon},
  journal={Front. Electron.}, 
  title={Hardware-Software Co-Design of an In-Memory Transformer Network Accelerator}, 
  year={2022},
  volume={3},
  number={847069},
  pages={1--21}}
  
@article{powers2011evaluation,
  title={Evaluation: From Precision, Recall and {F}-Measure to {ROC}, Informedness, Markedness \& Correlation},
  author={Powers, David},
  journal={J. Machine Learning Technologies},
  volume={2},
  number={1},
  pages={37--63},
  year={2011}
}

@INPROCEEDINGS{rram_14nm,
  author={Yang, Jianguo and Xue, Xiaoyong and Xu, Xiaoxin and Wang, Qiao and Jiang, Haijun and Yu, Jie and Dong, Danian and Zhang, Feng and Lv, Hangbing and Liu, Ming},
  booktitle={Proc. Int. Solid-State Circuits Conference}, 
  title={A 14nm-{FinFET} {1Mb} Embedded {1T1R RRAM} with a 0.022µm$^2$ Cell Size Using Self-Adaptive Delayed Termination and Multi-Cell Reference}, 
  year={2021},
  volume={64},
  number={},
  pages={336-338}}
  
@article{technology_norm,
title = {Scaling equations for the accurate prediction of {CMOS} device performance from 180nm to 7nm},
journal = {Integration},
volume = {58},
pages = {74-81},
year = {2017},
issn = {0167-9260},
author = {Aaron Stillmaker and Bevan Baas}
}

@article{dall-e,
  author    = {Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  title     = {Hierarchical Text-Conditional Image Generation with {CLIP} Latents},
  journal   = {CoRR},
  volume    = {abs/2204.06125},
  year      = {2022},
  eprinttype = {arXiv},
  eprint    = {2204.06125}
}

@INPROCEEDINGS{txf_robotics,
  author={Kim, Heecheol and Ohmura, Yoshiyuki and Kuniyoshi, Yasuo},
  booktitle={Proc. IEEE/RSJ Int. Conf. Intelligent Robots and Systems}, 
  title={Transformer-based deep imitation learning for dual-arm robot manipulation}, 
  year={2021},
  volume={},
  number={},
  pages={8965--8972},
  doi={10.1109/IROS51168.2021.9636301}}
  
@inproceedings{
txf_proof,
title={Proof Artifact Co-Training for Theorem Proving with Language Models},
author={Jesse Michael Han and Jason Rute and Yuhuai Wu and Edward Ayers and Stanislas Polu},
booktitle={Proc. Int. Conf. Learning Representations},
year={2022}
}

@InProceedings{txf_hi,
    author    = {Zhou, Desen and Liu, Zhichao and Wang, Jian and Wang, Leshan and Hu, Tao and Ding, Errui and Wang, Jingdong},
    title     = {Human-Object Interaction Detection via Disentangled Transformer},
    booktitle = {Proc. IEEE/CVF Conf. Computer Vision and Pattern Recognition},
    year      = {2022},
    pages     = {19568--19577}
}

@article{txf_forecasting,
title = {Temporal Fusion Transformers for interpretable multi-horizon time series forecasting},
journal = {Int. J. Forecasting},
volume = {37},
number = {4},
pages = {1748--1764},
year = {2021},
issn = {0169-2070},
author = {Bryan Lim and Sercan {\"O}. Arık and Nicolas Loeff and Tomas Pfister}
}

@article{edgetran,
  author    = {Shikhar Tuli and
               Niraj K. Jha},
  title     = {{EdgeTran}: Co-designing Transformers for Efficient Inference on Mobile Edge Platforms}, 
  year={2023},
  journal   = {CoRR},
  volume    = {abs/2303.13745},
  year      = {2023},
  eprinttype = {arXiv},
  eprint    = {2303.13745}
}

@article{acceltran,
  author    = {Shikhar Tuli and
               Niraj K. Jha},
  title     = {{AccelTran}: {A} Sparsity-Aware Accelerator for Dynamic Inference with
               Transformers},
  journal   = {CoRR},
  volume    = {abs/2302.14705},
  year      = {2023},
  eprinttype = {arXiv},
  eprint    = {2302.14705}
}

@INPROCEEDINGS{qi_iccad_21,
  author={Qi, Panjie and Sha, Edwin Hsing-Mean and Zhuge, Qingfeng and Peng, Hongwu and Huang, Shaoyi and Kong, Zhenglun and Song, Yuhong and Li, Bingbing},
  booktitle={Proc. IEEE/ACM Int. Conf. Computer Aided Design}, 
  title={Accelerating Framework of Transformer by Hardware Design and Model Compression Co-Optimization}, 
  year={2021},
  volume={},
  number={},
  pages={1-9},
  doi={10.1109/ICCAD51958.2021.9643586}}
  
@inproceedings{peng_dac_22,
author = {Peng, Hongwu and Huang, Shaoyi and Chen, Shiyang and Li, Bingbing and Geng, Tong and Li, Ang and Jiang, Weiwen and Wen, Wujie and Bi, Jinbo and Liu, Hang and Ding, Caiwen},
title = {A Length Adaptive Algorithm-Hardware Co-Design of Transformer on {FPGA} through Sparse Attention and Dynamic Pipelining},
year = {2022},
booktitle = {Proc. 59th ACM/IEEE Design Automation Conference},
pages = {1135--1140},
numpages = {6}
}

@inproceedings{bobw,
author = {Abdelfattah, Mohamed S. and Dudziak, {\L}ukasz and Chau, Thomas and Lee, Royson and Kim, Hyeji and Lane, Nicholas D.},
title = {Best of Both Worlds: {AutoML} Codesign of a {CNN} and Its Hardware Accelerator},
year = {2020},
isbn = {9781450367257},
booktitle = {Proc. ACM/EDAC/IEEE Design Automation Conference},
articleno = {192},
numpages = {6}
}

@online{apple_m1,
  author = {Apple},
  title = {Apple unleashes {M1}},
  year = 2020,
  url = {https://www.apple.com/newsroom/2020/11/apple-unleashes-m1/},
  urldate = {2022-03-23}
}

@electronic{nano,
 title     = {{NVIDIA Jetson Nano Developer Kit}},
 url       = {https://developer.nvidia.com/embedded/jetson-nano-developer-kit},
}

@article{al_survey,
author = {Ren, Pengzhen and Xiao, Yun and Chang, Xiaojun and Huang, Po-Yao and Li, Zhihui and Gupta, Brij B. and Chen, Xiaojiang and Wang, Xin},
title = {A Survey of Deep Active Learning},
year = {2021},
publisher = {Association for Computing Machinery},
volume = {54},
number = {9},
issn = {0360-0300},
doi = {10.1145/3472291},
journal = {ACM Comput. Surv.},
articleno = {180},
numpages = {40}
}

@book{dft_book,
  title={The Transform and Data Compression Handbook},
  author={Rao, Kamisetty Ramam and Yip, Patrick C},
  year={2018},
  publisher={CRC press}
}

@ARTICLE{fct,
  author={Makhoul, J.},
  journal={IEEE Trans. Acoustics, Speech, and Signal Processing}, 
  title={A fast cosine transform in one and two dimensions}, 
  year={1980},
  volume={28},
  number={1},
  pages={27-34},
  doi={10.1109/TASSP.1980.1163351}}
  
@article{fft,
  title={An algorithm for the machine calculation of complex {Fourier} series},
  author={Cooley, James W and Tukey, John W},
  journal={Mathematics of Computation},
  volume={19},
  number={90},
  pages={297--301},
  year={1965},
  publisher={JSTOR}
}

@inproceedings{sst2,
    title = "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    author = "Socher, Richard  and
      Perelygin, Alex  and
      Wu, Jean  and
      Chuang, Jason  and
      Manning, Christopher D.  and
      Ng, Andrew  and
      Potts, Christopher",
    booktitle = "Proc. Int. Conf. Empirical Methods in Natural Language Processing",
    year = "2013",
    pages = "1631--1642"
}
@inproceedings{mnli,
    title = "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
    author = "Williams, Adina  and
      Nangia, Nikita  and
      Bowman, Samuel",
    booktitle = "Proc. Conf. North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    year = "2018",
    pages = "1112--1122"
}

@inproceedings{qqp_qnli_mrpc,
    title = "Automatically Constructing a Corpus of Sentential Paraphrases",
    author = "Dolan, William B.  and
      Brockett, Chris",
    booktitle = "Proc. Int. Workshop on Paraphrasing",
    year = "2005"
}

@article{cola,
    title = "Neural Network Acceptability Judgments",
    author = "Warstadt, Alex  and
      Singh, Amanpreet  and
      Bowman, Samuel R.",
    journal = "Trans. Association for Computational Linguistics",
    volume = "7",
    year = "2019",
    pages = "625--641"
}

@inproceedings{stsb,
    title = "{S}em{E}val-2017 Task 1: Semantic Textual Similarity - Multilingual and Cross-lingual Focused Evaluation",
    author = "Cer, Daniel  and
      Diab, Mona  and
      Agirre, Eneko  and
      Lopez-Gazpio, I{\~n}igo  and
      Specia, Lucia",
    booktitle = "Proc. Int. Workshop on Semantic Evaluation",
    year = "2017",
    pages = "1--14"
}

@InProceedings{rte,
author="Dagan, Ido
and Glickman, Oren
and Magnini, Bernardo",
title="The {PASCAL} Recognising Textual Entailment Challenge",
booktitle="Proc. Int. Conf. Machine Learning Challenges",
year="2006",
pages="177--190"
}

@inproceedings{wnli,
  title={The {Winograd} schema challenge},
  author={Levesque, Hector and Davis, Ernest and Morgenstern, Leora},
  booktitle={Proc. Int. Conf. Principles of Knowledge Representation and Reasoning},
  year={2012}
}

@Article{lbfgs,
author={Liu, Dong C.
and Nocedal, Jorge},
title={On the limited memory {BFGS} method for large scale optimization},
journal={Mathematical Programming},
year={1989},
day={01},
volume={45},
number={1},
pages={503-528},
issn={1436-4646}
}

@INPROCEEDINGS{moo_rram,
  author={Yang, Xiaoxuan and Belakaria, Syrine and Joardar, Biresh Kumar and Yang, Huanrui and Doppa, Janardhan Rao and Pande, Partha Pratim and Chakrabarty, Krishnendu and Li, Hai Helen},
  booktitle={Proc. IEEE/ACM Int. Conf. Computer Aided Design}, 
  title={Multi-Objective Optimization of {ReRAM} Crossbars for Robust {DNN} Inferencing under Stochastic Noise}, 
  year={2021},
  volume={},
  number={},
  pages={1--9},
  doi={10.1109/ICCAD51958.2021.9643444}}

@inproceedings{sanger, author = {Lu, Liqiang and Jin, Yicheng and Bi, Hangrui and Luo, Zizhang and Li, Peng and Wang, Tao and Liang, Yun}, title = {Sanger: A Co-Design Framework for Enabling Sparse Attention Using Reconfigurable Architecture}, year = {2021}, booktitle = {Proc. IEEE/ACM Int. Symp. Microarchitecture}, pages = {977--991}, numpages = {15}, keywords = {sparse, attention, hardware-software co-design, systolic array, Transformer, reconfigurable architecture}}

@ARTICLE{nsga2,
  author={Deb, K. and Pratap, A. and Agarwal, S. and Meyarivan, T.},
  journal={IEEE Trans. Evolutionary Computation}, 
  title={A fast and elitist multiobjective genetic algorithm: {NSGA-II}}, 
  year={2002},
  volume={6},
  number={2},
  pages={182-197},
  doi={10.1109/4235.996017}}
