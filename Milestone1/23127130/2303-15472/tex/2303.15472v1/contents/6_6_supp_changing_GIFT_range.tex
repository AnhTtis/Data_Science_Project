


 
\section{Changing the rotation range of the GIFT} \label{sec:changing_gift_rotation_range}
\begin{table}[h!]
\centering
\begin{tabular}{c|cc|c}
\multirow{2}{*}{method} & \multicolumn{3}{c}{Roto-360}                                       \\ \cline{2-4}
                  & 5px                  & 3px                  & pred.                \\ \hline
ours                                  & \textbf{91.35}                & \textbf{90.18}                & 688.3                \\
GIFT                                  & 42.05                & 41.59                & 589.2                \\
GIFT*                                 & 40.71 &	40.27 &	564.2
\end{tabular}
\caption{\textbf{The result of re-training the GIFT~\cite{liu2019gift} model by replacing the rotation group with 360-degree cyclic.} GIFT* denotes a retrained model by extending the rotation sampling interval from -180$\degree$ to 180$\degree$. }\label{tab:changing_range}
\end{table}
Table~\ref{tab:changing_range} shows that GIFT* does not improve performance on the Roto-360 dataset because the bilinear pooling of GIFT does not guarantee invariance for rotation.
This is because our group aligning computes invariant features without breaking any equivariance, in contrast to GIFT~\cite{liu2019gift} whose bilinear pooling violates group equivariance due to their inter-group interaction from the $3\times 3$ convolution across the group dimension, which makes invariance not guaranteed either.
While GIFT and ours both use rotation-equivariant CNNs to finally yield an invariant descriptor, 
our architecture based on equivariant \textit{kernels} guarantees cyclic rotation-equivariance \textit{by construction},
unlike GIFT which relies on rotation augmentations to approximate equivariance.  

