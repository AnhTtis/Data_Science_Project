\input{_constants}
\cameraready % \review OR \arxiv OR \cameraready

\pdfoutput=1
\documentclass[10pt,twocolumn,letterpaper]{article}
\input{cvpr_header}
\begin{document}
%% TITLE
\title{Physics-Driven Diffusion Models for Impact Sound Synthesis from Videos}
\author{\authorBlock}

% \twocolumn[{
% \renewcommand\twocolumn[1][]{#1}
\maketitle
% \vspace{-0.55in}
% \begin{center}
% %\centering
%     \includegraphics[width=0.75\linewidth]{figs/teaser.png}
%     % \vspace{-0.15in}
%     \captionof{figure}{teaser figure}\label{fig:teaser}
% \end{center}
% }]


%%

\input{00_abstract}
\input{01_intro}
\input{02_related}

\input{03_method}

\input{04_experiment}

\input{10_conclusion}

{\small
\bibliographystyle{ieee_fullname}
\begin{thebibliography}{10}\itemsep=-1pt

    \bibitem{albanie2018emotion}
    Samuel Albanie, Arsha Nagrani, Andrea Vedaldi, and Andrew Zisserman.
    \newblock Emotion recognition in speech using cross-modal transfer in the wild.
    \newblock In {\em Proceedings of the 26th ACM international conference on
      Multimedia}, pages 292--301, 2018.
    
    \bibitem{anderson2018vision}
    Peter Anderson, Qi Wu, Damien Teney, Jake Bruce, Mark Johnson, Niko
      S{\"u}nderhauf, Ian Reid, Stephen Gould, and Anton Van Den~Hengel.
    \newblock Vision-and-language navigation: Interpreting visually-grounded
      navigation instructions in real environments.
    \newblock In {\em Proceedings of the IEEE conference on computer vision and
      pattern recognition}, pages 3674--3683, 2018.
    
    \bibitem{arandjelovic2017look}
    Relja Arandjelovic and Andrew Zisserman.
    \newblock Look, listen and learn.
    \newblock In {\em Proceedings of the IEEE International Conference on Computer
      Vision}, pages 609--617, 2017.
    
    \bibitem{aytar2016soundnet}
    Yusuf Aytar, Carl Vondrick, and Antonio Torralba.
    \newblock Soundnet: Learning sound representations from unlabeled video.
    \newblock {\em Advances in neural information processing systems}, 29, 2016.
    
    \bibitem{chen2018visually}
    Kan Chen, Chuanxi Zhang, Chen Fang, Zhaowen Wang, Trung Bui, and Ram Nevatia.
    \newblock Visually indicated sound generation by perceptually optimized
      classification.
    \newblock In {\em Proceedings of the European Conference on Computer Vision
      (ECCV) Workshops}, pages 0--0, 2018.
    
    \bibitem{chen2017deep}
    Lele Chen, Sudhanshu Srivastava, Zhiyao Duan, and Chenliang Xu.
    \newblock Deep cross-modal audio-visual generation.
    \newblock In {\em Proceedings of the on Thematic Workshops of ACM Multimedia
      2017}, pages 349--357, 2017.
    
    \bibitem{chen2021self}
    Nuo Chen, Chenyu You, and Yuexian Zou.
    \newblock Self-supervised dialogue learning for spoken conversational question
      answering.
    \newblock In {\em INTERSPEECH}, 2021.
    
    \bibitem{chen2020generating}
    Peihao Chen, Yang Zhang, Mingkui Tan, Hongdong Xiao, Deng Huang, and Chuang
      Gan.
    \newblock Generating visually aligned sound from videos.
    \newblock {\em IEEE Transactions on Image Processing}, 29:8292--8302, 2020.
    
    \bibitem{chen2021grounding}
    Zhenfang Chen, Jiayuan Mao, Jiajun Wu, Kwan-Yee~Kenneth Wong, Joshua~B
      Tenenbaum, and Chuang Gan.
    \newblock Grounding physical concepts of objects and events through dynamic
      visual reasoning.
    \newblock {\em arXiv preprint arXiv:2103.16564}, 2021.
    
    \bibitem{dhariwal2021diffusion}
    Prafulla Dhariwal and Alexander Nichol.
    \newblock Diffusion models beat gans on image synthesis.
    \newblock {\em Advances in Neural Information Processing Systems},
      34:8780--8794, 2021.
    
    \bibitem{gan2020foley}
    Chuang Gan, Deng Huang, Peihao Chen, Joshua~B Tenenbaum, and Antonio Torralba.
    \newblock Foley music: Learning to generate music from videos.
    \newblock In {\em European Conference on Computer Vision}, pages 758--775.
      Springer, 2020.
    
    \bibitem{gan2020music}
    Chuang Gan, Deng Huang, Hang Zhao, Joshua~B Tenenbaum, and Antonio Torralba.
    \newblock Music gesture for visual sound separation.
    \newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
      Pattern Recognition}, pages 10478--10487, 2020.
    
    \bibitem{gan2020threedworld}
    Chuang Gan, Jeremy Schwartz, Seth Alter, Martin Schrimpf, James Traer, Julian
      De~Freitas, Jonas Kubilius, Abhishek Bhandwaldar, Nick Haber, Megumi Sano,
      et~al.
    \newblock Threedworld: A platform for interactive multi-modal physical
      simulation.
    \newblock {\em arXiv preprint arXiv:2007.04954}, 2020.
    
    \bibitem{gan2020look}
    Chuang Gan, Yiwei Zhang, Jiajun Wu, Boqing Gong, and Joshua~B Tenenbaum.
    \newblock Look, listen, and act: Towards audio-visual embodied navigation.
    \newblock In {\em 2020 IEEE International Conference on Robotics and Automation
      (ICRA)}, pages 9701--9707. IEEE, 2020.
    
    \bibitem{gan2019self}
    Chuang Gan, Hang Zhao, Peihao Chen, David Cox, and Antonio Torralba.
    \newblock Self-supervised moving vehicle tracking with stereo sound.
    \newblock In {\em Proceedings of the IEEE/CVF International Conference on
      Computer Vision}, pages 7053--7062, 2019.
    
    \bibitem{gao2018learning}
    Ruohan Gao, Rogerio Feris, and Kristen Grauman.
    \newblock Learning to separate object sounds by watching unlabeled video.
    \newblock In {\em Proceedings of the European Conference on Computer Vision
      (ECCV)}, pages 35--53, 2018.
    
    \bibitem{gao2020listen}
    Ruohan Gao, Tae-Hyun Oh, Kristen Grauman, and Lorenzo Torresani.
    \newblock Listen to look: Action recognition by previewing audio.
    \newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
      Pattern Recognition}, pages 10457--10467, 2020.
    
    \bibitem{griffin1984signal}
    Daniel Griffin and Jae Lim.
    \newblock Signal estimation from modified short-time fourier transform.
    \newblock {\em IEEE Transactions on acoustics, speech, and signal processing},
      32(2):236--243, 1984.
    
    \bibitem{gu2022vector}
    Shuyang Gu, Dong Chen, Jianmin Bao, Fang Wen, Bo Zhang, Dongdong Chen, Lu Yuan,
      and Baining Guo.
    \newblock Vector quantized diffusion model for text-to-image synthesis.
    \newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
      Pattern Recognition}, pages 10696--10706, 2022.
    
    \bibitem{hershey1999audio}
    John Hershey and Javier Movellan.
    \newblock Audio vision: Using audio-visual synchrony to locate sounds.
    \newblock {\em Advances in neural information processing systems}, 12, 1999.
    
    \bibitem{ho2020denoising}
    Jonathan Ho, Ajay Jain, and Pieter Abbeel.
    \newblock Denoising diffusion probabilistic models.
    \newblock {\em Advances in Neural Information Processing Systems},
      33:6840--6851, 2020.
    
    \bibitem{ho2022cascaded}
    Jonathan Ho, Chitwan Saharia, William Chan, David~J Fleet, Mohammad Norouzi,
      and Tim Salimans.
    \newblock Cascaded diffusion models for high fidelity image generation.
    \newblock {\em J. Mach. Learn. Res.}, 23:47--1, 2022.
    
    \bibitem{huang2022prodiff}
    Rongjie Huang, Zhou Zhao, Huadai Liu, Jinglin Liu, Chenye Cui, and Yi Ren.
    \newblock Prodiff: Progressive fast diffusion model for high-quality
      text-to-speech.
    \newblock In {\em Proceedings of the 30th ACM International Conference on
      Multimedia}, pages 2595--2605, 2022.
    
    \bibitem{izadinia2012multimodal}
    Hamid Izadinia, Imran Saleemi, and Mubarak Shah.
    \newblock Multimodal analysis for identification and segmentation of
      moving-sounding objects.
    \newblock {\em IEEE Transactions on Multimedia}, 15(2):378--390, 2012.
    
    \bibitem{jeong2021diff}
    Myeonghun Jeong, Hyeongju Kim, Sung~Jun Cheon, Byoung~Jin Choi, and Nam~Soo
      Kim.
    \newblock Diff-tts: A denoising diffusion model for text-to-speech.
    \newblock {\em arXiv preprint arXiv:2104.01409}, 2021.
    
    \bibitem{kong2020diffwave}
    Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, and Bryan Catanzaro.
    \newblock Diffwave: A versatile diffusion model for audio synthesis.
    \newblock {\em arXiv preprint arXiv:2009.09761}, 2020.
    
    \bibitem{lee2021nu}
    Junhyeok Lee and Seungu Han.
    \newblock Nu-wave: A diffusion probabilistic model for neural audio upsampling.
    \newblock {\em arXiv preprint arXiv:2104.02321}, 2021.
    
    \bibitem{li2019neural}
    Naihan Li, Shujie Liu, Yanqing Liu, Sheng Zhao, and Ming Liu.
    \newblock Neural speech synthesis with transformer network.
    \newblock In {\em Proceedings of the AAAI Conference on Artificial
      Intelligence}, volume~33, pages 6706--6713, 2019.
    
    \bibitem{li2020behrt}
    Yikuan Li, Shishir Rao, Jos{\'e} Roberto~Ayala Solares, Abdelaali Hassaine,
      Rema Ramakrishnan, Dexter Canoy, Yajie Zhu, Kazem Rahimi, and Gholamreza
      Salimi-Khorshidi.
    \newblock Behrt: transformer for electronic health records.
    \newblock {\em Scientific reports}, 10(1):1--12, 2020.
    
    \bibitem{lin2019tsm}
    Ji Lin, Chuang Gan, and Song Han.
    \newblock Tsm: Temporal shift module for efficient video understanding.
    \newblock In {\em Proceedings of the IEEE International Conference on Computer
      Vision}, 2019.
    
    \bibitem{liu2021aligning}
    Fenglin Liu, Xian Wu, Chenyu You, Shen Ge, Yuexian Zou, and Xu Sun.
    \newblock Aligning source visual and target language domains for unpaired video
      captioning.
    \newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
      2021.
    
    \bibitem{liu2021auto}
    Fenglin Liu, Chenyu You, Xian Wu, Shen Ge, Xu Sun, et~al.
    \newblock Auto-encoding knowledge graph for unsupervised medical report
      generation.
    \newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.
    
    \bibitem{long2018attention}
    Xiang Long, Chuang Gan, Gerard De~Melo, Jiajun Wu, Xiao Liu, and Shilei Wen.
    \newblock Attention clusters: Purely attention based local feature integration
      for video classification.
    \newblock In {\em Proceedings of the IEEE conference on computer vision and
      pattern recognition}, pages 7834--7843, 2018.
    
    \bibitem{long2018multimodal}
    Xiang Long, Chuang Gan, Gerard Melo, Xiao Liu, Yandong Li, Fu Li, and Shilei
      Wen.
    \newblock Multimodal keyless attention fusion for video classification.
    \newblock In {\em Proceedings of the AAAI Conference on Artificial
      Intelligence}, volume~32, 2018.
    
    \bibitem{mittal2021symbolic}
    Gautam Mittal, Jesse Engel, Curtis Hawthorne, and Ian Simon.
    \newblock Symbolic music generation with diffusion models.
    \newblock {\em arXiv preprint arXiv:2103.16091}, 2021.
    
    \bibitem{nagrani2018seeing}
    Arsha Nagrani, Samuel Albanie, and Andrew Zisserman.
    \newblock Seeing voices and hearing faces: Cross-modal biometric matching.
    \newblock In {\em Proceedings of the IEEE conference on computer vision and
      pattern recognition}, pages 8427--8436, 2018.
    
    \bibitem{nichol2021improved}
    Alexander~Quinn Nichol and Prafulla Dhariwal.
    \newblock Improved denoising diffusion probabilistic models.
    \newblock In {\em International Conference on Machine Learning}, pages
      8162--8171. PMLR, 2021.
    
    \bibitem{o2001synthesizing}
    James~F O'Brien, Perry~R Cook, and Georg Essl.
    \newblock Synthesizing sounds from physically based motion.
    \newblock In {\em Proceedings of the 28th annual conference on Computer
      graphics and interactive techniques}, pages 529--536, 2001.
    
    \bibitem{o2002synthesizing}
    James~F O'Brien, Chen Shen, and Christine~M Gatchalian.
    \newblock Synthesizing sounds from rigid-body simulations.
    \newblock In {\em Proceedings of the 2002 ACM SIGGRAPH/Eurographics symposium
      on Computer animation}, pages 175--181, 2002.
    
    \bibitem{owens2016visually}
    Andrew Owens, Phillip Isola, Josh McDermott, Antonio Torralba, Edward~H
      Adelson, and William~T Freeman.
    \newblock Visually indicated sounds.
    \newblock In {\em Proceedings of the IEEE conference on computer vision and
      pattern recognition}, pages 2405--2413, 2016.
    
    \bibitem{owens2016ambient}
    Andrew Owens, Jiajun Wu, Josh~H McDermott, William~T Freeman, and Antonio
      Torralba.
    \newblock Ambient sound provides supervision for visual learning.
    \newblock In {\em European conference on computer vision}, pages 801--816.
      Springer, 2016.
    
    \bibitem{radford2021learning}
    Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
      Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
      et~al.
    \newblock Learning transferable visual models from natural language
      supervision.
    \newblock In {\em International conference on machine learning}, pages
      8748--8763. PMLR, 2021.
    
    \bibitem{ren2013example}
    Zhimin Ren, Hengchin Yeh, and Ming~C Lin.
    \newblock Example-guided physically based modal sound synthesis.
    \newblock {\em ACM Transactions on Graphics (TOG)}, 32(1):1--16, 2013.
    
    \bibitem{ronneberger2015u}
    Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
    \newblock U-net: Convolutional networks for biomedical image segmentation.
    \newblock In {\em International Conference on Medical image computing and
      computer-assisted intervention}, pages 234--241. Springer, 2015.
    
    \bibitem{rouditchenko2019self}
    Andrew Rouditchenko, Hang Zhao, Chuang Gan, Josh McDermott, and Antonio
      Torralba.
    \newblock Self-supervised audio-visual co-segmentation.
    \newblock In {\em ICASSP 2019-2019 IEEE International Conference on Acoustics,
      Speech and Signal Processing (ICASSP)}, pages 2357--2361. IEEE, 2019.
    
    \bibitem{saharia2022photorealistic}
    Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily
      Denton, Seyed Kamyar~Seyed Ghasemipour, Burcu~Karagol Ayan, S~Sara Mahdavi,
      Rapha~Gontijo Lopes, et~al.
    \newblock Photorealistic text-to-image diffusion models with deep language
      understanding.
    \newblock {\em arXiv preprint arXiv:2205.11487}, 2022.
    
    \bibitem{senocak2018learning}
    Arda Senocak, Tae-Hyun Oh, Junsik Kim, Ming-Hsuan Yang, and In~So Kweon.
    \newblock Learning to localize sound source in visual scenes.
    \newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
      Pattern Recognition}, pages 4358--4366, 2018.
    
    \bibitem{sohl2015deep}
    Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
    \newblock Deep unsupervised learning using nonequilibrium thermodynamics.
    \newblock In {\em International Conference on Machine Learning}, pages
      2256--2265. PMLR, 2015.
    
    \bibitem{su2020audeo}
    Kun Su, Xiulong Liu, and Eli Shlizerman.
    \newblock Audeo: Audio generation for a silent performance video.
    \newblock {\em Advances in Neural Information Processing Systems},
      33:3325--3337, 2020.
    
    \bibitem{su2021does}
    Kun Su, Xiulong Liu, and Eli Shlizerman.
    \newblock How does it sound?
    \newblock {\em Advances in Neural Information Processing Systems},
      34:29258--29273, 2021.
    
    \bibitem{tian2018audio}
    Yapeng Tian, Jing Shi, Bochen Li, Zhiyao Duan, and Chenliang Xu.
    \newblock Audio-visual event localization in unconstrained videos.
    \newblock In {\em Proceedings of the European Conference on Computer Vision
      (ECCV)}, pages 247--263, 2018.
    
    \bibitem{van2001foleyautomatic}
    Kees Van Den~Doel, Paul~G Kry, and Dinesh~K Pai.
    \newblock Foleyautomatic: physically-based sound effects for interactive
      simulation and animation.
    \newblock In {\em Proceedings of the 28th annual conference on Computer
      graphics and interactive techniques}, pages 537--544, 2001.
    
    \bibitem{wang2019performancenet}
    Bryan Wang and Yi-Hsuan Yang.
    \newblock Performancenet: Score-to-audio music generation with multi-band
      convolutional residual network.
    \newblock In {\em Proceedings of the AAAI Conference on Artificial
      Intelligence}, volume~33, pages 1174--1181, 2019.
    
    \bibitem{xu2019recursive}
    Xudong Xu, Bo Dai, and Dahua Lin.
    \newblock Recursive visual sound separation using minus-plus net.
    \newblock In {\em Proceedings of the IEEE/CVF International Conference on
      Computer Vision}, pages 882--891, 2019.
    
    \bibitem{yamamoto2020parallel}
    Ryuichi Yamamoto, Eunwoo Song, and Jae-Min Kim.
    \newblock Parallel wavegan: A fast waveform generation model based on
      generative adversarial networks with multi-resolution spectrogram.
    \newblock In {\em ICASSP 2020-2020 IEEE International Conference on Acoustics,
      Speech and Signal Processing (ICASSP)}, pages 6199--6203. IEEE, 2020.
    
    \bibitem{yi2018neural}
    Kexin Yi, Jiajun Wu, Chuang Gan, Antonio Torralba, Pushmeet Kohli, and Josh
      Tenenbaum.
    \newblock Neural-symbolic vqa: Disentangling reasoning from vision and language
      understanding.
    \newblock {\em Advances in neural information processing systems}, 31, 2018.
    
    \bibitem{you2021mrd}
    Chenyu You, Nuo Chen, and Yuexian Zou.
    \newblock {MRD-N}et: {M}ulti-{M}odal {R}esidual {K}nowledge {D}istillation for
      {S}poken {Q}uestion {A}nswering.
    \newblock In {\em Proceedings of the Thirtieth International Joint Conference
      on Artificial Intelligence, {IJCAI}}, pages 3985--3991, 2021.
    
    \bibitem{you2022mine}
    Chenyu You, Weicheng Dai, Fenglin Liu, Haoran Su, Xiaoran Zhang, Lawrence
      Staib, and James~S Duncan.
    \newblock Mine your own anatomy: Revisiting medical image segmentation with
      extremely limited labels.
    \newblock {\em arXiv preprint arXiv:2209.13476}, 2022.
    
    \bibitem{you2023rethinking}
    Chenyu You, Weicheng Dai, Yifei Min, Fenglin Liu, Xiaoran Zhang, Chen Feng,
      David~A Clifton, S~Kevin Zhou, Lawrence~Hamilton Staib, and James~S Duncan.
    \newblock Rethinking semi-supervised medical image segmentation: A
      variance-reduction perspective.
    \newblock {\em arXiv preprint arXiv:2302.01735}, 2023.
    
    \bibitem{youclass}
    Chenyu You, Ruihan Zhao, Fenglin Liu, Siyuan Dong, Sandeep~P Chinchali,
      Lawrence~Hamilton Staib, James s Duncan, et~al.
    \newblock Class-aware adversarial transformers for medical image segmentation.
    \newblock In {\em Advances in Neural Information Processing Systems}.
    
    \bibitem{yu2022coca}
    Jiahui Yu, Zirui Wang, Vijay Vasudevan, Legg Yeung, Mojtaba Seyedhosseini, and
      Yonghui Wu.
    \newblock Coca: Contrastive captioners are image-text foundation models.
    \newblock {\em arXiv preprint arXiv:2205.01917}, 2022.
    
    \bibitem{zagoruyko2016wide}
    Sergey Zagoruyko and Nikos Komodakis.
    \newblock Wide residual networks.
    \newblock {\em arXiv preprint arXiv:1605.07146}, 2016.
    
    \bibitem{zhao2018sound}
    Hang Zhao, Chuang Gan, Andrew Rouditchenko, Carl Vondrick, Josh McDermott, and
      Antonio Torralba.
    \newblock The sound of pixels.
    \newblock In {\em Proceedings of the European conference on computer vision
      (ECCV)}, pages 570--586, 2018.
    
    \bibitem{zhou2019vision}
    Hang Zhou, Ziwei Liu, Xudong Xu, Ping Luo, and Xiaogang Wang.
    \newblock Vision-infused deep audio inpainting.
    \newblock In {\em Proceedings of the IEEE/CVF International Conference on
      Computer Vision}, pages 283--292, 2019.
    
    \bibitem{zhou2018visual}
    Yipin Zhou, Zhaowen Wang, Chen Fang, Trung Bui, and Tamara~L Berg.
    \newblock Visual to sound: Generating natural sound for videos in the wild.
    \newblock In {\em Proceedings of the IEEE conference on computer vision and
      pattern recognition}, pages 3550--3558, 2018.
    
    \bibitem{zhu2021deep}
    Hao Zhu, Man-Di Luo, Rui Wang, Ai-Hua Zheng, and Ran He.
    \newblock Deep audio-visual learning: A survey.
    \newblock {\em International Journal of Automation and Computing},
      18(3):351--376, 2021.
    
    \end{thebibliography}
    
}

\clearpage \input{12_appendix}

\end{document}
