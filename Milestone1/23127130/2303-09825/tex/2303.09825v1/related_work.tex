\section{Related Work}
\label{sec:related_work}

\begin{figure*}[t]
  \centering
  \includegraphics[width=0.85\textwidth]{figure/methodology/overview_method.png}
  \caption{Block diagram illustrating the full pipeline of the proposed LCE-Calib method.
    The method first processes raw sensor measurements (see Section \ref{sec:measure_process}) to extract features and then initializes as well as refines sensors' extrinsics (see Section \ref{sec:ext_calibration}).}
  \label{fig:methodology_overview}
\end{figure*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Sensor calibration is a fundamental problem in robotics.
% Extensive works are available with the similar topics.
This section briefly reviews calibration results on the LiDAR-camera sensor suite and event cameras.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{LiDAR-Camera Calibration}
Related approaches are mainly divided into marker-based and marker-less approaches, depending on whether artificial targets are used or not during the process.

\subsubsection{Marker-based Methods}
Although marker-based calibration requires artificial targets to be observable in the scene and sometimes needs manual intervention, such methods are still prevalent due to the higher accuracy and robustness compared with nontarget-based calibration \cite{huang2018geometric}.
They benefit from the known geometry information of the target, imposing sufficient and reliable geometric constraints to estimate extrinsics.

Geometric solids \cite{guennebaud2010eigen}, checkerboards \cite{wu2021simultaneous,zhou2018automatic}, and polygons \cite{liao2018extrinsic} are the widely used targets.
But among them, checkerboards are the most common targets since they also help the cameras' intrinsic calibration \cite{zhang2000flexible}.
Zhang and Pless \cite{zhang2004extrinsic} first introduced the checkerboard into the extrinsic calibration of a perspective camera and a 2D laser rangefinder. They placed the checkerboard at multiple poses to gather sufficient constraints induced by plane-line correspondences.
Unnikrishnan \textit{et al.} \cite{unnikrishnan2005fast} extended this method to the extrinsic calibration with a 3D LiDAR.
They estimated the planar parameters of the board from the LiDAR and camera. They used plane-plane correspondences to initialize rotation and translation decoupled while minimizing the point-plane distance to refine the LiDAR-camera transformation.
Our method also employs this way to initialize extrinsics.
Pandey \textit{et al.} \cite{pandey2010extrinsic} addressed the omnidirectional camera-LiDAR calibration problem,
Mirzaei \textit{et al.} \cite{mirzaei20123d} additionally investigated the LiDAR intrinsic model,
and Koo \textit{et al.} \cite{koo2020analytic} analytically derived the uncertainty of plane parameters and explored its effect in calibration.

Besides plane information, the boundaries of objects and corner features also offer strong constraints.
Sim \textit{et al.} \cite{sim2016indirect} determined lines from two non-coplanar surfaces of a V-shaped target and exploited linear constraints to estimate extrinsics.
Moghadam \textit{et al.} \cite{moghadam2013line} extracted natural linear features in the scene,
while Zhou \textit{et al.} \cite{zhou2018automatic} jointly exploited 3D line-to-line and point-to-plane correspondences to establish constraints.
Finally, Huang \textit{et al.} \cite{huang2020improvements} extracted corner features that are the intersections of two boundaries from an Apriltag \cite{olson2011apriltag} and then solved the PnP problem \cite{lepetit2009epnp}.

Our checkerboard-based approach presents several new features from following aspects:
\textit{1)} features from images and point clouds are automatically extracted;
\textit{2)} board points are continuously tracked to improve the detection success rate and reduce processing time at the next frame;
\textit{3)} both planar and line features are fully utilized in different stages of calibration;
\textit{4)} an event camera is also extrinsically calibrated with the LiDAR;
\textit{5)} the uncertainty information is represented with the Lie group-based formulation \cite{barfoot2014associating}; and
\textit{6)} a new globally optimal solver is introduced.

\subsubsection{Marker-less Methods}
Marker-less calibration methods search for correspondences between geometric features found in natural environments, such as lines, edges, and planar regions. They do not rely on explicit shapes from known targets, having great flexibility for field robots.

Levinson \textit{et al.} \cite{levinson2013automatic} put forward the first online calibration approach for a LiDAR-camera system by optimally aligning 3D edge points with image contours.
Different metrics based on the planar information \cite{chen2022pbacalib}, edges \cite{yuan2021pixel}, and semantic constraints \cite{yoon2021targetless} were also proposed.
Meanwhile, Shi \textit{et al.} \cite{shi2020calibrcnn} proposed an end-to-end neural network to calibrate the extrinsics.
However, the accuracy of markerless methods is commonly inferior to marker-based methods if calibration scenes are non-ideal.
In our approach, we show that the checkerboard benefits the intrinsic calibration of cameras. We also investigate the checkerboard-based calibration with an extension to event cameras.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Event Camera Calibration}
The unique characteristics of event cameras raise the demand for novel solutions to address the calibration problem.
Preliminary works on event cameras have designed blinking LED patterns \cite{dominguez2019bio}, or screens \cite{mueggler2014event} as the calibration target.
The rapid illumination change triggers events and the patterns can be detected even if the cameras are static.
Once features are extracted, traditional optimization-based calibration backends can be used.
Nevertheless, these approaches may have large motion blur and noisy events \cite{muglikar2021calibrate}.
Recent works are able to replace the custom-built calibration checkerboards with the standard ones by implementing one of two techniques:
\textit{1)} several event cameras output synchronous frame images \cite{gallego2020event};
\textit{2)} high-quality frame images are reconstructed from event streams by utilizing the sensing characteristics of event cameras \cite{muglikar2021calibrate}.
The latter approaches should be more applicable to more types of event cameras that only have an event output. They also benefit from recent advancements in image reconstruction from events \cite{rebecq2019high}.

Our method follows the second technique in event-based calibration.
We further propose a unified method to calibrate extrinsics between a LiDAR and an event camera based on these works. The method is shown with high accuracy under detailed evaluation.
