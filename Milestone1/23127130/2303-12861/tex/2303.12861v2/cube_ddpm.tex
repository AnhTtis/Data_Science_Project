\documentclass[runningheads]{llncs}
\usepackage{amsmath,amsfonts}
\usepackage[ruled]{algorithm2e}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{bm}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{dsfont}
\usepackage{cite}

\begin{document}
	
\title{Sub-volume-based Denoising Diffusion Probabilistic Model for
Cone-beam CT Reconstruction from Incomplete Data}

\author{Wenjun Xia, Chuang Niu, Wenxiang Cong, Ge Wang
}

\institute{Department of Biomedical Engineering\\ Rensselaer Polytechnic Institute\\ Troy, NY 12180 USA\\
\email{\{xiaw4, niuc, congw, wangg6\}@rpi.edu}
}



\maketitle

\begin{abstract}
	Deep learning (DL) has emerged as a new approach in the field of computed tomography (CT) with many applicaitons.  A primary example is CT reconstruction from incomplete data, such as sparse-view image reconstruction. However, applying DL to sparse-view cone-beam CT (CBCT) remains challenging. Many models learn the mapping from sparse-view CT images to the ground truth but often fail to achieve satisfactory performance. Incorporating sinogram data and performing dual-domain reconstruction improve image quality with artifact suppression, but a straightforward 3D implementation requires storing an entire 3D sinogram in memory and many parameters of dual-domain networks. This remains a major challenge, limiting further research, development and applications. In this paper, we propose a sub-volume-based 3D denoising diffusion probabilistic model (DDPM) for CBCT image reconstruction from down-sampled data. Our DDPM network, trained on data cubes extracted from paired fully sampled sinograms and down-sampled sinograms, is employed to inpaint down-sampled sinograms. Our method divides the entire sinogram into overlapping cubes and processes them in parallel on multiple GPUs, successfully overcoming the memory limitation. Experimental results demonstrate that our approach effectively suppresses few-view artifacts while preserving textural details faithfully.

    \keywords{Cone-beam CT (CBCT), sinogram completion, denoising diffusion probabilistic model (DDPM), sub-volume, parallel computing, distributed computing}
\end{abstract}



\section{Introduction}
Cone-beam computed tomography (CBCT) has important  and diverse clinical applications, including cardiac angiography, cancer imaging, dental and breast scans. It enjoys fine spatial resolution, large volume coverage, and fast scanning speed. However, CBCT inevitably suffers from radiation risks. Therefore, sparse-view CBCT has attracted significant attention as a means to reduce radiation dose. Consequently, many medical imaging researchers are striving to eliminate image artifacts caused by down-sampling and enhance image quality for CBCT at minimal radiation dose.

Current commercial CBCT algorithms primarily employ the Feldkamp-Davis-Kress (FDK) algorithm for a circulr scanning trajectory~\cite{feldkamp1984practical} and extended FDK algorithms for a spiral scanning trajectory \cite{wang1993general,wang2007approximate}. For sparse-view CBCT, images reconstructed using a FDK-type algorithm are plagued with streak artifacts, unable to meet  clinical requirements for imaging quality. Iterative reconstruction algorithms, such as the algebraic reconstruction technique (ART)\cite{gordon1970algebraic}, simultaneous algebraic reconstruction technique (SART)\cite{andersen1984simultaneous}, and expectation maximization (EM)~\cite{dempster1977maximum}, are based on linear systems and exhibit higher tolerance for data incompleteness and noise. However, they still struggle to reconstruct high-quality CBCT images with down-sampled sinograms.

Model-based iterative reconstruction (MBIR) algorithms can produce higher quality CBCT images. From a Bayesian perspective, the statistical model in MBIR algorithms includes an observation model for sinogram data and a prior model for CBCT images. Inspired by compressed sensing theory~\cite{candes2006robust, donoho2006compressed}, sparsity and low-rank prior is introduced into CBCT reconstruction. A classic sparsity prior is total variation (TV), which has demonstrated promising results~\cite{yu2005total, jia2010gpu}. Subsequently, a series of TV variants were proposed to enhance the performance of MBIR algorithms~\cite{lohvithee2017parameter, zeng2013iterative, niu2014sparse, sohn2020analytical}. While MBIR algorithms can achieve promising results through fine-tuning model parameters, their reliance on the experience and skills makes adapting MBIR algorithms to complex clinical applications tedious and expensive.

Since 2016 \cite{wang2016perspective}, deep learning-based CT reconstruction methods are rapidly developed. Leveraging numerous parameters of neural networks and big data, these methods can learn an optimal tomographic map from data under complicated distributions, overcoming the limitations posed by the need for specific parameters for different datasets in traditional MBIR algorithms. Among these deep learning approaches, a representative category is image improvement via post-processing, which use a neural network to map from degraded CT images to high-quality CT images. For instance, Chen \textit{et al.} proposed using an autoencoder to remove noise and artifacts~\cite{chen2017lowdose}. Inspired by the residual structure~\cite{he2016deep}, Chen \textit{et al.} and Jin \textit{et al.} independently proposed two U-shaped residual networks to learn the residuals between degraded and high-quality CT images, achieving higher training efficiency and reconstruction quality~\cite{chen2017low, jin2017deep}. To address the blur resulting from the use of MSE and MAE, Yang \textit{et al.} coupled the Wasserstein generative adversarial network (WGAN)\cite{arjovsky2017wasserstein} with the perceptual loss\cite{johnson2016perceptual}, enhancing visual quality signficantly~\cite{yang2018low}. Zhang \textit{et al.} incorporated the transformer in a dual-domain network to process high- and low-frequency components in parallel~\cite{zhang2021transct}. While post-processing methods are simple to train and effectively remove noise and artifacts, they are unable to recover information lost in the reconstruction process. Consequently, introducing sinogram information to networks is an important opportunity for better image reconstruction.

Chen \textit{et al.} unrolled the gradient descent algorithm and replaced empirical regularization with a learned convolutional neural network (CNN), ensuring the accuracy of reconstructed CT images~\cite{chen2018learn}. Adler and {"O}ktem unrolled the primal-dual hybrid gradient (PDHG) algorithm into a neural network, further refining the sinogram~\cite{adler2018learned}. Gupta \textit{et al.} trained a neural network as a denoiser and embedded it into the iterative scheme of the MBIR algorithm~\cite{gupta2018cnn}. Similarly, He \textit{et al.} integrated a neural network with the standard alternating direction method of multipliers (ADMM) framework. In the same spirit, various MBIR-based optimization methods were adapted to deep learning versions~\cite{wu2017iterative, xiang2021fista, wu2021drone, chun2020momentum}. Another effective approach to utilizing sinogram data is to let a dual-domain network process the sinogram and image separately, and synergize the workflows via differentiable back-projection. Hu \textit{et al.} trained two U-Nets~\cite{ronneberger2015u} connected with the FDK algorithm~\cite{hu2020hybrid}. Zhang \textit{et al.} trained a similar network architecture via adversarial reconstruction~\cite{zhang2021clear}. While these methods delivered good results, their adaptation to clinical applications remains challenging in general scenarios. These methods inevitably require storing the entire sinogram and its features in memory, making directly training a deep model infeasible for ultra-high-resolution CBCT image reconstruction.

Over the past two years, the denoising diffusion probabilistic model (DDPM) was actively adapted for image generation~\cite{ho2020denoising, song2020score}. DDPM supports the process of gradually transforming normally distributed noise into an image, which can be considered as a generalization of the variational autoencoder (VAE)\cite{kingma2013auto}. The transformation in the latent space at each step in DDPM is subtle but collectively these subtle steps leads to a final output that surpasses the quality of VAE. Moreover, DDPM models are more stable than generative adversarial networks (GANs)\cite{goodfellow2020generative} and less prone to mode collapse. Consequently, DDPM overcame the limitations of the previous generative models and quickly became a hottest topic in the imaging field. DDPM was already applied to various applications in image/video processing and computer vision, such as image super-resolution~\cite{rombach2022high, saharia2022image}, image inpainting~\cite{lugmayr2022repaint}, image editing~\cite{meng2021sdedit}, image translation~\cite{saharia2022palette, choi2021ilvr}, and more.

In this paper, we focus on reconstructing ultra-high resolution CTBCT images from incomplete data. To address the memory limitation and long computing time, we divide the three-dimensional sinogram dataset into overlapped cubes and inpaint the missing data in each of the cubes in parallel. Methods based on projection domain processing require high inference accuracy of the trained model, because subtle errors in the projection domain could spread to the image domain globally . To reduce inference errors, we introduce DDPM for enhanced accuracy. During training, we extract cubes from paired complete and incomplete sinograms, add noise to the complete cubes, and then feed them into the network. For inference, we divide the incomplete sinogram into overlapping cubes, feed these cubes into the network as conditions to obtain high-quality cubes, and finally assemble these cubes to form a complete sinogram. Clearly, these cubes can be processed in parallel across multiple GPUs to improve efficiency. Our proposed method resolves memory limitations while producing high-quality sinograms at high speed to be reconstructed into an image volume for further refinement in the image domain. The remainder of this paper is organized as follows. The next section details the methodology, the third section presents experimental results. The final section offers discussions and draw a conclusion.

\begin{figure*}[tbp]
	\centering
	\includegraphics[width=1.0\textwidth]{figures/fig1.png}
	\caption{Conditional DDPM for sparse-view CBCT.}
	\label{fig:1}
\end{figure*}

\section{Methodology}
We denote a complete CBCT sinogram dataset as $ \bm{Y} \in \mathbb{R}^{N_v \times N_r \times N_c} $, where $ N_v $ is the number of projection views, $ N_r $ and $ N_c $ are the numbers of rows and columns of the detector array respectively. The sparse-view version of the sinogram can be formulated as
\begin{equation}
\bm{Z} = P(\bm{M} \odot \bm{Y}),
\label{eq:1}
\end{equation}
where $ \bm{Z} \in \mathbb{R}^{N_v'\times N_r \times N_c} $ represents an incomplete sinogram dataset, $ \bm{M} \in \mathbb{R}^{N_v} $ is a projection mask, with an entry $ \bm{M}{i} = 1 $ if and only if the $ i $-th view is sampled; otherwise $ \bm{M}{i} = 0 $, and $ \odot $ is for broadcasting view-wise multiplication. $ P: \mathbb{R}^{N_v\times N_r \times N_c} \rightarrow \mathbb{R}^{N_v'\times N_r \times N_c} $ is the operation that extracts the sampled view data from the original complete sinogram.

To provide prior for the missing information, we use the incomplete sinogram to generate the pseudo-complete sinogram. First, the noisy CBCT image $ \bar{\bm{X}} $ is reconstructed using the FDK algorithm from $ \bm{Z} $. Then, the noisy complete sinogram $ \bar{\bm{Z}} $ is obtained by performing the Radon transform on $ \bar{\bm{X}} $. Finally, the pseudo-complete sinogram $ \tilde{\bm{Z}} $ is obtained by inserting the known data $ \bm{Z} $ into the noisy complete sinogram $ \bar{\bm{Z}} $:
\begin{equation}
\tilde{\bm{Z}} = P^{-1}(\bm{Z}) \odot \bm{M} +\bar{\bm{Z}} \odot (1-\bm{M}),
\label{eq:2}
\end{equation}
where $ P^{-1}: \mathbb{R}^{N_v'\times N_r \times N_c} \rightarrow \mathbb{R}^{N_v\times N_r \times N_c} $ is the operation that reshapes the incomplete data into the fully sampled counterpart by zeroing the pixels corresponding to the discarded views.

To perform the sub-volume-based diffusion, we randomly extract a cube pair $ {\bm{y}, \tilde{\bm{z}}} \subset \mathbb{R}^{d \times d \times d} $ at the same location in the paired complete sinogram $ \bm{Y} $ and pseudo-complete sinogram $ \tilde{\bm{Z}} $. As shown in Fig.~\ref{fig:1}, the conditional DDPM consists of a forward process and a reverse process. Given a time series $ {1, 2, ...,t,...T} $, the forward process of DDPM gradually adds Gaussian noise to the high-quality cube $ \bm{y} $. The data distribution at each time step only depends on the previous moment, satisfying the Markov property:
\begin{equation}
	q(\bm{y}_{1:T}|\bm{y}_{0}) = \prod_{t=1}^T q(\bm{y}_t|\bm{y}_{t-1}),
	\label{eq:3}
\end{equation}
where
\begin{equation}
	q(\bm{y}_t|\bm{y}_{t-1}) = \mathcal{N} (\bm{y}_t| \sqrt{1 - \beta_t}\bm{y}_{t-1}, \beta_t \bm{I}),
	\label{eq:4}
\end{equation}
 $ q(\bm{y}_{0}) = q(\bm{y}) $, and $ \bm{\beta} = \{\beta_1, \beta_2, \cdots, \beta_T \} $ is a predefined variance schedule. We can also directly obtain the data distribution at a certain timestamp without iteration:
\begin{equation}
	q(\bm{y}_t|\bm{y}_{0}) = \mathcal{N} (\bm{y}_t| \sqrt{\bar{\alpha}_t}\bm{y}_0, 	(1-\bar{\alpha}_t) \bm{I}),
	\label{eq:5}
\end{equation}
where $\alpha_t = 1-\beta_t$ and $ \bar{\alpha}_t = \prod_{i=1}^t \alpha_i $. When the given number of steps is large enough, the noised cube will gradually approach the standard normal distribution, i.e. $ \bm{y}_T  \sim \mathcal{N}(0,\bm{I}) $. Knowing the conditional probability $ q(\bm{y}_t|\bm{y}_{t-1}) $ and given $ \bm{y}_{t} $ and $ \bm{y}_0 $, we can get the posterior distribution of $ \bm{y}_{t-1} $:
\begin{equation}
	\left\lbrace 
	\begin{aligned}
		&q(\bm{y}_{t-1}|\bm{y}_{t}, \bm{y}_0) = 	\mathcal{N}(\bm{y}_{t-1}|\tilde{\mu}_t(\bm{y}_{t}, \bm{y}_{0}), \sigma_t^2 \bm{I}),\\
		&\tilde{\mu}_t(\bm{y}_{t}, \bm{y}_{0}) = 	\frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1- \bar{\alpha}_t} \bm{y}_t + \frac{\sqrt{\bar{\alpha}_{t-1}}(1-\alpha_t)}{1- \bar{\alpha}_t} \bm{y}_0, \\
		&\sigma_t^2 = \frac{(1-\bar{\alpha}_{t-1})(1-\alpha_t)}{1- \bar{\alpha}_t}.
	\end{aligned}
	\right.	
	\label{eq:6}
\end{equation}

% \begin{equation}
% q(\bm{y}{t-1}|\bm{y}{t}, \bm{y}{0}, \tilde{\bm{z}}) = \mathcal{N}(\bm{y}{t-1}|\tilde{\mu}t(\bm{y}{t}, \bm{y}{0}, \tilde{\bm{z}}), \sigma_t^2 \bm{I}),
% \label{eq:7}
% \end{equation}
% where $\tilde{\mu}t(\bm{y}{t}, \bm{y}{0}, \tilde{\bm{z}})$ is the output of the trained neural network, which takes the current noised cube $\bm{y}_{t}$, the initial cube $\bm{y}0$, and the pseudo-complete cube $\tilde{\bm{z}}$ as inputs. The network is designed to predict the mean of the posterior distribution of $\bm{y}{t-1}$ given the inputs.

The reverse process starts from the final noisy cube $\bm{y}_T$ and moves backward step-by-step. At each step, the network takes the current cube $\bm{y}_t$, and the pseudo-complete cube $\tilde{\bm{z}}$ as inputs, then predicts the mean of the posterior distribution of $\bm{y}_{t-1}$, which is used as the denoised cube for the next step. The process continues until it reaches the initial time step, producing the final denoised cube $\bm{y}_0$.
The Markov chain-based conditional probability distribution of the reverse process can be formulated as
\begin{equation}
	p_{\theta} (\bm{y}_{0:T}|\tilde{\bm{z}})=p(\bm{y}_{T})\prod_{t=1}^T 	p_{\theta}(\bm{y}_{t-1}|\bm{y}_{t}, \tilde{\bm{z}}),
	\label{eq:7}
\end{equation}
where
\begin{equation}
	p_{\theta}(\bm{y}_{t-1}|\bm{y}_{t}, \tilde{\bm{z}}) = 	\mathcal{N}(\bm{y}_{t-1}|\mu_{\theta}(\bm{y}_{t}, \tilde{\bm{z}}, t), \sigma_t^2 \bm{I}),
	\label{eq:8}
\end{equation}
where  $ \mu_{\theta} $ is the trained model. Therefore, the loss function of the network is expressed as
\begin{equation}
	\mathcal{L} = \mathbb{E}_{\bm{y}, \tilde{\bm{z}}}\mathbb{E}_{t} \left[ \left\| 	\tilde{\mu}_t(\bm{y}_{t}, \bm{y}_{0}) - \mu_{\theta}(\bm{y}_{t}, \tilde{\bm{z}}, t) \right\|_2^2 \right].
	\label{eq:9}
\end{equation}
In the specific implementation of the forward process $ \bm{y}_t = \sqrt{\bar{\alpha}_t}\bm{y}_0 + \sqrt{1-\bar{\alpha}_t} \bm{\epsilon} $, $ \bm{\epsilon}\sim \mathcal{N}(0, \bm{I}) $, the expectation $ \tilde{\mu}_t(\bm{y}_{t}, \bm{y}_{0}) $ can be further simplified into
\begin{equation}	
	\tilde{\mu}_t(\bm{y}_{t}, \bm{y}_{0}) = \tilde{\mu}_t\left(\bm{y}_{t}, 	\frac{1}{\sqrt{\bar{\alpha}_t}}\left(\bm{y}_t-\sqrt{1-\bar{\alpha}_t}\bm{\epsilon}\right)\right)
	=\frac{1}{\sqrt{\bar{\alpha}_t}}\left(\bm{y}_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\bm{\epsilon}\right).
	\label{eq:10}
\end{equation}
Then, the network can be changed to predict the noise $ \bm{\epsilon} $ instead of predicting the expectation:
\begin{equation}
	\mathcal{L} = \mathbb{E}_{\bm{y}, \tilde{\bm{z}}}\mathbb{E}_{\bm{\epsilon},t} 	\left[ \left\| \bm{\epsilon} - \bm{\epsilon}_{\bm{\theta}} (\sqrt{\bar{\alpha}_t}\bm{y}_0 + \sqrt{1-\bar{\alpha}_t} \bm{\epsilon}, \tilde{\bm{z}}, t) \right\|_2^2 \right].
	\label{eq:11}
\end{equation}
Finally, the sampling process of $ \bm{y}_{t-1} \sim p_{\theta}(\bm{y}_{t-1}|\bm{y}_{t})$ can be computed as follows:
\begin{equation}
	\bm{y}_{t-1} = 	\frac{1}{\sqrt{\bar{\alpha}_t}}\left(\bm{y}_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\bm{\epsilon}_{\bm{\theta}} (\bm{y}_t, \tilde{\bm{z}}, t)\right) +\sigma_t \bm{\xi}, \ \bm{\xi}\sim \mathcal{N}(0,\bm{I}).
	\label{eq:12}
\end{equation}

In summary, the conditional DDPM incorporates the pseudo-complete cube $\tilde{\bm{z}}$ as a condition, which provides additional information to guide the denoising process, leading to a more accurate reconstruction of the missing sinogram data. The pseudo codes for training and inference are shown in Algorithms \ref{alg:1} and \ref{alg:2}, respectively.

\begin{algorithm}[t]
	\caption{Training of the denoising model $ \bm{\epsilon}_{\bm{\theta}} $.}
	\label{alg:1}
	\KwIn{Number of time steps $T$; Variance schedule $\{\beta_t|t=1,2,...,T\}$; under-sampling mask $ \bm{M} $;}
	\KwOut{Trained model $ \bm{\epsilon}_{\bm{\theta}} $}
	\BlankLine
	Initialize $\bm{\epsilon}_{\bm{\theta}}$ randomly;
	
	\While{\textnormal{not converged}}{
		$ (\bm{Y}, \bm{Z}) \sim p(\bm{Y}, \bm{Z}) $
		
		$ \bar{\bm{X}} = \mathrm{FBP}(\bm{Z}) $;
		$ \bar{\bm{Z}} = \mathrm{Radon}(\bar{\bm{X}}) $;
		$ \tilde{\bm{Z}} = P^{-1}(\bm{Z})  \odot \bm{M} +\bar{\bm{Z}} \odot (1-\bm{M}) $
		
		Randomly extract paired patches $ (\bm{y}_0, \tilde{\bm{z}}) $ from $  (\bm{Y}, \tilde{\bm{Z}}) $
		
		$ t\sim \mathrm{Uniform}(\{1,2,...,T\}) $
		
		$ \bm{\epsilon} \sim \mathcal{N}(0, \bm{I}) $
		
		Update $\bm{\theta}$ with the gradient $\nabla_{\theta} \left\| \bm{\epsilon} - \bm{\epsilon}_{\bm{\theta}} (\sqrt{\bar{\alpha}_t}\bm{y}_0 + \sqrt{1-\bar{\alpha}_t} \bm{\epsilon}, \tilde{\bm{z}}, t) \right\|_2^2$
	}
\end{algorithm}

\begin{algorithm}[!tbp]
	\caption{Inference with the trained denoising model $ \bm{\epsilon}_{\bm{\theta}} $.}
	\label{alg:2}
	\KwIn{Number of time steps $T$; Variance schedule $\{\beta_t|t=1,2,...,T\}$; under-sampling mask $ \bm{M} $;}
	\KwOut{$\bm{Y}$}
	\BlankLine
	
	Load $ \bm{\epsilon}_{\bm{\theta}} $;
	
	$ \bm{Z} \sim p(\bm{Z}) $
	
	$ \bar{\bm{X}} = \mathrm{FBP}(\bm{Z}) $;
	$ \bar{\bm{Z}} = \mathrm{Radon}(\bar{\bm{X}}) $;
	$ \tilde{\bm{Z}} = P^{-1}(\bm{Z})  \odot \bm{M} +\bar{\bm{Z}} \odot (1-\bm{M}) $
	
	Extract patches $\{\tilde{\bm{z}}^i\}_{i=1}^{N} $
	
	
	
	\ForPar{$ i = 1,2,...,N $}{
		$ \bm{y}^i_T \sim \mathcal{N}(0, \bm{I})$
		
		\For{$t=1,2,...,T$}{
			$\bm{\xi} \sim \mathcal{N}(0, \bm{I})$ if $t>1$ else $\bm{\xi}=0$
			
			$\bm{y}^i_{t-1} = \frac{1}{\sqrt{\bar{\alpha}_t}}\left(\bm{y}^i_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\bm{\epsilon}_{\bm{\theta}} (\bm{y}^i_t, \tilde{\bm{z}}^i, t)\right) +\sigma_t \bm{\xi}$
		}
	}
	
	Obtain $\bm{Y}$ by assembling patches $\{\bm{y}^{i}_0\}_{i=1}^{N} $ into a full projection dataset.	
\end{algorithm}

\begin{figure*}[htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{figures/fig2.png}
	\caption{Breast CT sinogram successfully inpainted by DDPM. (a) A
 complete sinogram (as the standard to compute PSNR), (b) the pseudo-complete sinogram (PSNR=20.40), (c) our inpainted sinogram with cube size 16$ ^3 $ (PSNR=44.51) and (d) our sinogram with cube size 32$ ^3 $ 
 (PSNR=42.96). The PSNRs of the entire 3D sinogram are (b) 20.02, (c) 44.87 and (d) 45.05 respectively.}
	\label{fig:2}
\end{figure*}

\section{Experiments and Results}
We evaluated our proposed method using five volumes of breast CT data, with four volumes utilized for training and the remaining one used for testing. Each volume consists of 300 projection views. The detector array has $768 \times 1,024$ detector elements, $0.3880 \times 0.3880$ mm$^2$ per element. The  breast CT image volume was reconstructed into an array of $1024 \times 1024 \times 512$ voxels, with voxel size $0.2734$ mm. The incomplete dataset consists of 100 projection views, extracted uniformly from the original dataset of 300 views. We set the number of time steps for diffusion to 
1,000, and the beta schedule was determined according ton~\cite{ho2020denoising}.

Our model architecture was adapted from an improved U-Net~\cite{ho2020denoising} for 3D processing. We trained the model using the AdamW optimizer~\cite{loshchilov2017decoupled} with an initial learning rate of $1 \times 10^{-4}$, which is gradually reduced to $1 \times 10^{-5}$ over $5 \times 10^5$ iterations. The training process employed four Nvidia Tesla V100 (32GB) GPUs, while the inference was performed in parallel on 128 Nvidia Tesla V100 (32GB) GPUs.

We trained two models with cube sizes of 16x16x16 and 32x32x32, respectively. When extracting the cubes, the overlap coefficient was set to 0.5, meaning that the stride was set to 8 and 16 for the two cube sizes, respectively. 

Figs.\ref{fig:2} and\ref{fig:3} display the synthesized sinograms and their corresponding reconstructions. It can be observed in Fig.~\ref{fig:2} that there are artifacts in the pseudo-complete sinogram, as indicated by the red arrow. These artifacts have been effectively removed in the results generated by our DDPM model. 
The peak signal-to-noise ratios (PSNRs) also indicate that the inpainted sinograms have high accuracy.
Fig.~\ref{fig:3} presents the regions of interest (ROIs) in the breast CT reconstruction. There are noticeable artifacts in the sparse-view CBCT results. In the region marked by the red arrow, some detailed structures were obscured by artifacts. The reconstructed images with the sinograms synthesized by our DDPM models have successfully removed most of the artifacts and restored the subtle structure as indicated by the red arrow. The PSNR values also demonstrate that our results exhibit significant improvement.

\begin{figure*}[tbp]
	\centering
	\includegraphics[width=1.0\textwidth]{figures/fig3.png}
	\caption{ROI-based visualization of the breast CT reconstruction from the sinogram inpainted by DDPM, (a) The ground truth, (b) a sparse-view reconstruciton (PSNR=21.12), 
 (c) our result with cube size 16$ ^3 $ 
 (PSNR=27.81) and (d) our result with cube size 32$ ^3 $ (PSNR=27.15). The display window is [-100, 550] HU. The PSNRs of the entire 3D breast CT image are (b) 19.8, (c) 27.14 and (d) 26.5, respectively.}
	\label{fig:3}
\end{figure*}

\section{Discussions and Conclusion}

In this paper, we have presented a sub-volume-based 3D conditional DDPM model for sparse-view high-resolution CBCT reconstruction, with breast CT as a primary example. The results demonstrate that the synthesized sinograms have high accuracy, and artifacts can be effectively removed in the  images reconstructed from the synthesized sinograms. The performance of our proposed method highlights its potential in overcoming the challenges associated with high-resolutoin large-volume medical CT imaging.

Nevertheless, there is still room for improvement. Although the synthesized sinograms deliver good visual and quantitative results, the reconstructed images are not perfect, and some details are still compromised. This issue arises from subtle errors in the sinogram domain that spread out in the  image domain. In the future, we plan to introduce a dual-domain DDPM approach to further enhance breast CT images.

Another aspect worth discussion is the efficiency of our proposed method. Due to the thousands of iterations, the DDPM sampling efficiency is low. Particularly in our method, the sinogram is divided into redundant cubes for separate processing, further increasing the computational cost. For the model trained with a cube size of 32$^3$, it took 2 hours and 47 minutes to obtain the synthesized sinogram using 128 Nvidia Tesla V100 GPUs. In the case of training with a size of 16$^3$, it took 3 hours and 10 minutes. To accelerate the process, we could use our previous work~\cite{xia2022low} to achieve clinically acceptable efficiency.

Moreover, 3D DDPM is sensitive to the input data size. The network struggles to converge effectively when training with larger cubes, such as 64$^3$, leading to mean shift in the synthesized results. In the presented results, the network trained for a cube size of 16$^3$ outperforms the one for 32$^3$. This implies that smaller data sizes allow more stable DDPM  training. In the popular latent diffusion approach~\cite{rombach2022high}, images are compressed into low-dimensional embeddings to achieve better training stability. However, this approach is not suitable for medical imaging, as compression may degrade clinically important structures.
Therefore, as a future topic we will explore ways to improve the stability of DDPM training for larger data sub-volumes for more contextual 
information.

In conclusion, we have proposed a sub-volume-based DDPM approach that uses the divide-and-conquer strategy to address the memory limitation (only sub-volumes are stored) and the inference speed (sub-volumes can be processed faster than the whole volume) in the parallel fashion.  This work opens a door to perform DDPM-based dual-domain tomographic inversions on a large number of GPUs on cloud. This capability is essential for high-resolution CBCT reconstruction such as breast CBCT reconstruction. Further evaluation and optimization are in progress toward clinical translation.


\bibliographystyle{unsrt} 
\bibliography{ref}
\end{document}