\documentclass[runningheads]{llncs}
\usepackage{amsmath,amsfonts}
\usepackage[ruled]{algorithm2e}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{bm}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{dsfont}
\usepackage{cite}

\begin{document}
	
\title{Cube-Based 3D Denoising Diffusion Probabilistic Model for Cone Beam Computed Tomography Reconstruction with Incomplete Data}

\author{Wenjun Xia, Chuang Niu, Wenxiang Cong, Ge Wang
}

\institute{Department of Biomedical Engineering\\ Rensselaer Polytechnic Institute\\ Troy, NY 12180 USA\\
\email{\{xiaw4, niuc, congw, wangg6\}@rpi.edu}
}



\maketitle

\begin{abstract}
	Deep learning (DL) has been extensively researched in the field of computed tomography (CT) reconstruction with incomplete data, particularly in sparse-view CT reconstruction. However, applying DL to sparse-view cone beam CT (CBCT) remains challenging. Many models learn the mapping from sparse-view CT images to ground truth but struggle to achieve satisfactory performance in terms of global artifact removal. Incorporating sinogram data and utilizing dual-domain information can enhance anti-artifact performance, but this requires storing the entire sinogram in memory. This presents a memory issue for high-resolution CBCT sinograms, limiting further research and application. In this paper, we propose a cube-based 3D denoising diffusion probabilistic model (DDPM) for CBCT reconstruction using down-sampled data. A DDPM network, trained on cubes extracted from paired fully sampled sinograms and down-sampled sinograms, is employed to inpaint down-sampled sinograms. Our method divides the entire sinogram into overlapping cubes and processes these cubes in parallel using multiple GPUs, overcoming memory limitations. Experimental results demonstrate that our approach effectively suppresses few-view artifacts while preserving textural details faithfully.
\end{abstract}

\section{Introduction}
Cone beam computed tomography (CBCT) has long held significant clinical applications, including dental radiography and breast CT scans. It is characterized by high ray utilization, spatial resolution, and scanning efficiency. However, CBCT inevitably faces radiation risks. Therefore, sparse-view CBCT reconstruction has garnered widespread attention as a means to effectively reduce radiation doses. Consequently, numerous medical imaging researchers are striving to eliminate artifacts caused by down-sampling and enhance image quality, ultimately enabling lower ionizing radiation levels in CBCT scans.

Current commercial CBCT imaging algorithms primarily employ the Feldkamp-Davis-Kress (FDK) algorithm~\cite{feldkamp1984practical}, which demands high integrity and purity of the collected sinogram data. For sparse-view CBCT, images reconstructed using the FDK algorithm are plagued with streak artifacts, failing to meet the clinical requirements for imaging quality. Iterative reconstruction algorithms, such as the algebraic reconstruction technique (ART)\cite{gordon1970algebraic}, simultaneous algebraic reconstruction technique (SART)\cite{andersen1984simultaneous}, and expectation maximization (EM)~\cite{dempster1977maximum}, are based on linear systems and exhibit higher tolerance for data incompleteness and noise. However, they still struggle to reconstruct high-quality CBCT images with down-sampled sinograms.

Model-based iterative reconstruction (MBIR) algorithms can produce high-quality CBCT images by establishing a statistical model and performing iterative optimization. From a Bayesian perspective, the statistical model in MBIR algorithms includes an observation model for sinogram data and a prior model for CBCT images. Inspired by compressed sensing theory~\cite{candes2006robust, donoho2006compressed}, sparsity prior is introduced into CBCT reconstruction. A classic sparsity prior is total variation (TV), which has demonstrated promising results~\cite{yu2005total, jia2010gpu}. Subsequently, a series of TV variants were proposed to further enhance the performance of MBIR algorithms~\cite{lohvithee2017parameter, zeng2013iterative, niu2014sparse, sohn2020analytical}. While MBIR algorithms can achieve promising results through fine-tuning of model parameters, their reliance on the experience and skills of operators makes adapting MBIR algorithms to complex clinical applications challenging.

In recent years, deep learning-based CT reconstruction methods have emerged \cite{wang2016perspective}. Leveraging the numerous parameters of neural networks, these methods can process data from different distributions, overcoming the limitations posed by the need for specific parameters for different data in traditional MBIR algorithms. Among these deep learning approaches, a representative category is post-processing methods, which use neural networks to learn the mapping from degraded CT images to high-quality CT images. For instance, Chen \textit{et al.} proposed using an autoencoder to remove noise and artifacts~\cite{chen2017lowdose}. Inspired by the residual structure~\cite{he2016deep}, Chen \textit{et al.} and Jin \textit{et al.} independently proposed two U-shaped residual networks to learn the residuals between degraded and high-quality CT images, achieving better training efficiency and reconstruction quality~\cite{chen2017low, jin2017deep}. To address the blurriness resulting from MSE and MAE, Yang \textit{et al.} introduced the Wasserstein generative adversarial network (WGAN)\cite{arjovsky2017wasserstein} and perceptual loss\cite{johnson2016perceptual}, enhancing visual performance~\cite{yang2018low}. Zhang \textit{et al.} incorporated the transformer and proposed a dual-domain version to process high- and low-frequency components in parallel~\cite{zhang2021transct}. While post-processing methods are simple to train and effectively remove noise and artifacts, they risk being unable to recover missing information. Consequently, introducing sinogram information to networks has remained an important concern for researchers. 
Chen \textit{et al.} unrolled the gradient descent algorithm and replaced manual regularization with a learned convolutional neural network (CNN), ensuring the accuracy of the reconstructed CT images~\cite{chen2018learn}. Adler and {"O}ktem proposed unrolling the primal-dual hybrid gradient (PDHG) algorithm into a neural network, further refining the sinogram~\cite{adler2018learned}. Gupta \textit{et al.} trained a neural network as a denoiser and embedded it into the iterative scheme of the MBIR algorithm~\cite{gupta2018cnn}. Similarly, He \textit{et al.} integrated a neural network with the standard alternating direction method of multipliers (ADMM) framework. Based on similar principles, various MBIR-based optimization methods have been adapted to deep learning versions~\cite{wu2017iterative, xiang2021fista, wu2021drone, chun2020momentum}. Another effective approach to introducing sinogram data is training a dual-domain network to process the sinogram and image separately, connecting them using differentiable back-projection. Hu \textit{et al.} trained two U-Nets~\cite{ronneberger2015u} connected with the differentiable FDK algorithm~\cite{hu2020hybrid}. Zhang \textit{et al.} trained a similar network architecture in a more comprehensive manner using adversarial reconstruction~\cite{zhang2021clear}. While these methods can achieve promising results and data consistency guarantees, their adaptation to clinical applications remains challenging in certain special scenarios. These methods inevitably require storing the features of the entire sinogram in memory, making training models for ultra-high-resolution CBCT images a significant challenge.

In the past two years, the denoising diffusion probabilistic model (DDPM) has been proposed for image generation~\cite{ho2020denoising, song2020score}. DDPM describes the process of gradually transforming normally distributed noise into an image, which can be considered as a subdivision of variational autoencoder (VAE)\cite{kingma2013auto} into thousands of steps. The transformation in the latent space at each step in DDPM is subtle, resulting in a final generated output that surpasses the quality of VAE. Moreover, training DDPM is more stable than generative adversarial networks (GAN)\cite{goodfellow2020generative} and less prone to mode collapse. Consequently, upon its introduction, DDPM overcame the limitations of the other two generative models and quickly became the focal point of the image processing field. DDPM has been applied to various applications in image/video processing and computer vision, such as image super-resolution~\cite{rombach2022high, saharia2022image}, image inpainting~\cite{lugmayr2022repaint}, image editing~\cite{meng2021sdedit}, image translation~\cite{saharia2022palette, choi2021ilvr}, and more.

In this paper, we focus on reconstructing ultra-high resolution breast CT images with incomplete data. To introduce observation data information while addressing the memory problem, we divide the three-dimensional sinogram into overlapping cubes and inpaint the missing data in the cubes in parallel. Methods based on projection domain processing require high inference accuracy from the trained model, as subtle errors in the projection domain can spread to the global image domain. To reduce inference errors, we introduce DDPM for enhanced accuracy. During training, we extract cubes from paired complete and incomplete sinograms, add noise to the complete cubes, and then feed them into the network. For inference, we divide the incomplete sinogram into overlapping cubes, feed these cubes into the network as conditions to obtain high-quality cubes, and finally assemble these cubes to form the complete sinogram. Furthermore, these cubes can be processed in parallel across multiple GPUs to improve efficiency. Our proposed method resolves memory limitations while producing high-quality sinograms for further image domain processing. The remainder of this paper is organized as follows: the next section details the methodology, the third section presents experimental results, and the final section offers conclusions and further discussion.

\begin{figure*}[tbp]
	\centering
	\includegraphics[width=1.0\textwidth]{figures/fig1.png}
	\caption{Conditional DDPM for sparse-view CBCT.}
	\label{fig:1}
\end{figure*}

\section{Methodology}
We denote a complete sinogram data of CBCT as $ \bm{Y} \in \mathbb{R}^{N_v \times N_r \times N_c} $, where $ N_v $ is the number of projection views, $ N_r $ and $ N_c $ are the rows and columns of the detector array, respectively. The sparse-view version of the sinogram can be formulated as
\begin{equation}
\bm{Z} = P(\bm{M} \odot \bm{Y}),
\label{eq:1}
\end{equation}
where $ \bm{Z} \in \mathbb{R}^{N_v'\times N_r \times N_c} $ represents the incomplete sinogram data, $ \bm{M} \in \mathbb{R}^{N_v} $ is the mask, with the entry $ \bm{M}{i} = 1 $ if the $ i $-th view is sampled, otherwise $ \bm{M}{i} = 0 $, and $ \odot $ denotes the broadcasting view-wise multiplication. $ P: \mathbb{R}^{N_v\times N_r \times N_c} \rightarrow \mathbb{R}^{N_v'\times N_r \times N_c} $ is the operation that extracts the sampled view data from the original complete sinogram.

To provide prior for the missing information and obtain better conditioning, we use the incomplete sinogram to generate the pseudo-complete sinogram. First, the noisy CBCT image $ \bar{\bm{X}} $ is reconstructed using the FDK algorithm from $ \bm{Z} $. Then, the noisy complete sinogram $ \bar{\bm{Z}} $ is obtained by performing the full Radon transform on $ \bar{\bm{X}} $. Finally, the pseudo-complete sinogram $ \tilde{\bm{Z}} $ is obtained by inserting the known data $ \bm{Z} $ into the noisy complete sinogram $ \bar{\bm{Z}} $:
\begin{equation}
\tilde{\bm{Z}} = P^{-1}(\bm{Z}) \odot \bm{M} +\bar{\bm{Z}} \odot (1-\bm{M}),
\label{eq:2}
\end{equation}
where $ P^{-1}: \mathbb{R}^{N_v'\times N_r \times N_c} \rightarrow \mathbb{R}^{N_v\times N_r \times N_c} $ is the operation that reshapes the incomplete data into the fully sampled counterpart by inserting zeros into the pixels corresponding to the discarded views.

To perform the cube-based diffusion, we randomly extract a cube pair $ {\bm{y}, \tilde{\bm{z}}} \subset \mathbb{R}^{d \times d \times d} $ from the same location of the paired complete sinogram $ \bm{Y} $ and pseudo-complete sinogram $ \tilde{\bm{Z}} $. As shown in Fig.~\ref{fig:1}, the conditional DDPM consists of a forward process and a reverse process. Given a time series $ {1, 2, ...,t,...T} $, the forward process of DDPM gradually adds Gaussian noise to the high-quality cube $ \bm{y} $. The data distribution at each time step only depends on the previous moment, which conforms to the Markov property:
\begin{equation}
	q(\bm{y}_{1:T}|\bm{y}_{0}) = \prod_{t=1}^T q(\bm{y}_t|\bm{y}_{t-1}),
	\label{eq:3}
\end{equation}
where
\begin{equation}
	q(\bm{y}_t|\bm{y}_{t-1}) = \mathcal{N} (\bm{y}_t| \sqrt{1 - \beta_t}\bm{y}_{t-1}, \beta_t \bm{I}).
	\label{eq:4}
\end{equation}
where $ q(\bm{y}_{0}) = q(\bm{y}) $, and $ \bm{\beta} = \{\beta_1, \beta_2, \cdots, \beta_T \} $ is a predefined variance schedule. We can also directly obtain the data distribution at a certain timestamp without iteration:
\begin{equation}
	q(\bm{y}_t|\bm{y}_{0}) = \mathcal{N} (\bm{y}_t| \sqrt{\bar{\alpha}_t}\bm{y}_0, 	(1-\bar{\alpha}_t) \bm{I}),
	\label{eq:5}
\end{equation}
where $\alpha_t = 1-\beta_t$ and $ \bar{\alpha}_t = \prod_{i=1}^t \alpha_i $. When the given number of steps is large enough, the noised cube will gradually approach the standard normal distribution, i.e. $ \bm{y}_T  \sim \mathcal{N}(0,\bm{I}) $. Knowing the conditional probability $ q(\bm{y}_t|\bm{y}_{t-1}) $, and given $ \bm{y}_{t} $ and $ \bm{y}_0 $, we can get the posterior distribution of $ \bm{y}_{t-1} $:
\begin{equation}
	\left\lbrace 
	\begin{aligned}
		&q(\bm{y}_{t-1}|\bm{y}_{t}, \bm{y}_0) = 	\mathcal{N}(\bm{y}_{t-1}|\tilde{\mu}_t(\bm{y}_{t}, \bm{y}_{0}), \sigma_t^2 \bm{I}),\\
		&\tilde{\mu}_t(\bm{y}_{t}, \bm{y}_{0}) = 	\frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1- \bar{\alpha}_t} \bm{y}_t + \frac{\sqrt{\bar{\alpha}_{t-1}}(1-\alpha_t)}{1- \bar{\alpha}_t} \bm{y}_0, \\
		&\sigma_t^2 = \frac{(1-\bar{\alpha}_{t-1})(1-\alpha_t)}{1- \bar{\alpha}_t}.
	\end{aligned}
	\right.	
	\label{eq:6}
\end{equation}

% \begin{equation}
% q(\bm{y}{t-1}|\bm{y}{t}, \bm{y}{0}, \tilde{\bm{z}}) = \mathcal{N}(\bm{y}{t-1}|\tilde{\mu}t(\bm{y}{t}, \bm{y}{0}, \tilde{\bm{z}}), \sigma_t^2 \bm{I}),
% \label{eq:7}
% \end{equation}
% where $\tilde{\mu}t(\bm{y}{t}, \bm{y}{0}, \tilde{\bm{z}})$ is the output of the trained neural network, which takes the current noised cube $\bm{y}_{t}$, the initial cube $\bm{y}0$, and the pseudo-complete cube $\tilde{\bm{z}}$ as inputs. The network is designed to predict the mean of the posterior distribution of $\bm{y}{t-1}$ given the inputs.

The reverse process starts from the final noisy cube $\bm{y}_T$ and moves backward step-by-step. At each step, the network takes the current cube $\bm{y}_t$, and the pseudo-complete cube $\tilde{\bm{z}}$ as inputs, then predicts the mean of the posterior distribution of $\bm{y}_{t-1}$, which is used as the denoised cube for the next step. The process continues until it reaches the initial time step, producing the final denoised cube $\bm{y}_0$.
The Markov chain-based conditional probability distribution of the reverse process can be formulated as
\begin{equation}
	p_{\theta} (\bm{y}_{0:T}|\tilde{\bm{z}})=p(\bm{y}_{T})\prod_{t=1}^T 	p_{\theta}(\bm{y}_{t-1}|\bm{y}_{t}, \tilde{\bm{z}}),
	\label{eq:7}
\end{equation}
where
\begin{equation}
	p_{\theta}(\bm{y}_{t-1}|\bm{y}_{t}, \tilde{\bm{z}}) = 	\mathcal{N}(\bm{y}_{t-1}|\mu_{\theta}(\bm{y}_{t}, \tilde{\bm{z}}, t), \sigma_t^2 \bm{I}),
	\label{eq:8}
\end{equation}
where  $ \mu_{\theta} $ is the trained model. Therefore, the loss function of the network is:
\begin{equation}
	\mathcal{L} = \mathbb{E}_{\bm{y}, \tilde{\bm{z}}}\mathbb{E}_{t} \left[ \left\| 	\tilde{\mu}_t(\bm{y}_{t}, \bm{y}_{0}) - \mu_{\theta}(\bm{y}_{t}, \tilde{\bm{z}}, t) \right\|_2^2 \right].
	\label{eq:9}
\end{equation}
Depending on the specific implementation of the forward process $ \bm{y}_t = \sqrt{\bar{\alpha}_t}\bm{y}_0 + \sqrt{1-\bar{\alpha}_t} \bm{\epsilon} $, $ \bm{\epsilon}\sim \mathcal{N}(0, \bm{I}) $, the expectation $ \tilde{\mu}_t(\bm{y}_{t}, \bm{y}_{0}) $ can be further simplified into
\begin{equation}	
	\tilde{\mu}_t(\bm{y}_{t}, \bm{y}_{0}) = \tilde{\mu}_t\left(\bm{y}_{t}, 	\frac{1}{\sqrt{\bar{\alpha}_t}}\left(\bm{y}_t-\sqrt{1-\bar{\alpha}_t}\bm{\epsilon}\right)\right)
	=\frac{1}{\sqrt{\bar{\alpha}_t}}\left(\bm{y}_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\bm{\epsilon}\right).
	\label{eq:10}
\end{equation}
Then the network can be changed to predict the noise $ \bm{\epsilon} $ instead of predicting the expectation:
\begin{equation}
	\mathcal{L} = \mathbb{E}_{\bm{y}, \tilde{\bm{z}}}\mathbb{E}_{\bm{\epsilon},t} 	\left[ \left\| \bm{\epsilon} - \bm{\epsilon}_{\bm{\theta}} (\sqrt{\bar{\alpha}_t}\bm{y}_0 + \sqrt{1-\bar{\alpha}_t} \bm{\epsilon}, \tilde{\bm{z}}, t) \right\|_2^2 \right].
	\label{eq:11}
\end{equation}
Finally, the sampling process of $ \bm{y}_{t-1} \sim p_{\theta}(\bm{y}_{t-1}|\bm{y}_{t})$ can be computed as follows:
\begin{equation}
	\bm{y}_{t-1} = 	\frac{1}{\sqrt{\bar{\alpha}_t}}\left(\bm{y}_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\bm{\epsilon}_{\bm{\theta}} (\bm{y}_t, \tilde{\bm{z}}, t)\right) +\sigma_t \bm{\xi}, \ \bm{\xi}\sim \mathcal{N}(0,\bm{I}).
	\label{eq:12}
\end{equation}

In summary, the conditional DDPM incorporates the pseudo-complete cube $\tilde{\bm{z}}$ as a condition, which provides additional information to guide the denoising process, leading to a more accurate reconstruction of the missing sinogram data. The pseudo codes for training and inference are shown in Algorithms \ref{alg:1} and \ref{alg:2}, respectively.

\begin{algorithm}[t]
	\caption{Training of the denoising model $ \bm{\epsilon}_{\bm{\theta}} $.}
	\label{alg:1}
	\KwIn{Number of time steps $T$; Variance schedule $\{\beta_t|t=1,2,...,T\}$; under-sampling mask $ \bm{M} $;}
	\KwOut{Trained model $ \bm{\epsilon}_{\bm{\theta}} $}
	\BlankLine
	Initialize $\bm{\epsilon}_{\bm{\theta}}$ randomly;
	
	\While{\textnormal{not converged}}{
		$ (\bm{Y}, \bm{Z}) \sim p(\bm{Y}, \bm{Z}) $
		
		$ \bar{\bm{X}} = \mathrm{FBP}(\bm{Z}) $;
		$ \bar{\bm{Z}} = \mathrm{Radon}(\bar{\bm{X}}) $;
		$ \tilde{\bm{Z}} = P^{-1}(\bm{Z})  \odot \bm{M} +\bar{\bm{Z}} \odot (1-\bm{M}) $
		
		Randomly extract paired patches $ (\bm{y}_0, \tilde{\bm{z}}) $ from $  (\bm{Y}, \tilde{\bm{Z}}) $
		
		$ t\sim \mathrm{Uniform}(\{1,2,...,T\}) $
		
		$ \bm{\epsilon} \sim \mathcal{N}(0, \bm{I}) $
		
		Update $\bm{\theta}$ with the gradient $\nabla_{\theta} \left\| \bm{\epsilon} - \bm{\epsilon}_{\bm{\theta}} (\sqrt{\bar{\alpha}_t}\bm{y}_0 + \sqrt{1-\bar{\alpha}_t} \bm{\epsilon}, \tilde{\bm{z}}, t) \right\|_2^2$
	}
\end{algorithm}

\begin{algorithm}[!tbp]
	\caption{Inference with the trained denoising model $ \bm{\epsilon}_{\bm{\theta}} $.}
	\label{alg:2}
	\KwIn{Number of time steps $T$; Variance schedule $\{\beta_t|t=1,2,...,T\}$; under-sampling mask $ \bm{M} $;}
	\KwOut{$\bm{Y}$}
	\BlankLine
	
	Load $ \bm{\epsilon}_{\bm{\theta}} $;
	
	$ \bm{Z} \sim p(\bm{Z}) $
	
	$ \bar{\bm{X}} = \mathrm{FBP}(\bm{Z}) $;
	$ \bar{\bm{Z}} = \mathrm{Radon}(\bar{\bm{X}}) $;
	$ \tilde{\bm{Z}} = P^{-1}(\bm{Z})  \odot \bm{M} +\bar{\bm{Z}} \odot (1-\bm{M}) $
	
	Extract patches $\{\tilde{\bm{z}}^i\}_{i=1}^{N} $
	
	
	
	\ForPar{$ i = 1,2,...,N $}{
		$ \bm{y}^i_T \sim \mathcal{N}(0, \bm{I})$
		
		\For{$t=1,2,...,T$}{
			$\bm{\xi} \sim \mathcal{N}(0, \bm{I})$ if $t>1$ else $\bm{\xi}=0$
			
			$\bm{y}^i_{t-1} = \frac{1}{\sqrt{\bar{\alpha}_t}}\left(\bm{y}^i_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\bm{\epsilon}_{\bm{\theta}} (\bm{y}^i_t, \tilde{\bm{z}}^i, t)\right) +\sigma_t \bm{\xi}$
		}
	}
	
	Obtain $\bm{Y}$ by assembling patches $\{\bm{y}^{i}_0\}_{i=1}^{N} $ into a full projection dataset.	
\end{algorithm}

\begin{figure*}[htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{figures/fig2.png}
	\caption{A Slice of the breast CT sinogram inpainted by DDPM, (a) Complete sinogram (PSNR), (b) Pseudo-complete sinogram (20.40), (c) Ours with cube size 16$ ^3 $ (44.51) and (d) Ours with cube size 32$ ^3 $ (42.96). The PSNR of the entire 3D sinogram is as follows: (b) 20.02, (c) 44.87 and (d) 45.05. }
	\label{fig:2}
\end{figure*}

\section{Experiments and Results}
We evaluate our proposed method using five volumes of breast CT data, with four volumes utilized for training and the remaining volume used for testing. Each volume consists of 300 projection views obtained from scans. The detector array size is $768 \times 1024$, with each element having an area of $0.3880 \times 0.3880$ mm$^2$. The reconstructed breast CT images have dimensions of $1024 \times 1024 \times 512$, and each voxel has a length of $0.2734$ mm. The incomplete data consists of 100 projection views, extracted uniformly from the original 300 views. We set the number of time steps for diffusion to 1000, and the beta schedule is determined by the linspace between $0.0001$ and $0.02$, as suggested in~\cite{ho2020denoising}.

Our model architecture is based on an improved version of U-Net~\cite{ho2020denoising}, adapted for 3D convolution. We train the model using the AdamW optimizer~\cite{loshchilov2017decoupled}, with an initial learning rate of $1 \times 10^{-4}$, which is gradually reduced to $1 \times 10^{-5}$ over $5 \times 10^5$ iterations. The training process employs four Nvidia Tesla V100 (32GB) GPUs, while the inference is performed in parallel on 128 Nvidia Tesla V100 (32GB) GPUs.

We trained two models using cube sizes of 16x16x16 and 32x32x32, respectively. When extracting the cubes, the overlap coefficient is set to 0.5, meaning that the stride is set to 8 and 16 for the two cube sizes, respectively. Figs.\ref{fig:2} and\ref{fig:3} display the synthesized sinograms and their corresponding reconstructions. In Fig.~\ref{fig:2}, it can be observed that there are artifacts in the pseudo-complete sinogram, particularly in the area indicated by the red arrow. These artifacts are effectively removed in the results generated by our DDPM model. The peak signal-to-noise ratio (PSNR) scores also indicate that the inpainted sinograms have high accuracy.

Fig.~\ref{fig:3} presents the region of interest (ROI) of the breast CT reconstruction. It is evident that there are noticeable artifacts in the sparse-view CBCT results. In the region marked by the red arrow, some detailed structures are obscured by artifacts. The reconstructed images with sinograms synthesized by our DDPM models successfully remove most of the artifacts and restore the structure in the area indicated by the red arrow. The PSNR values also demonstrate that our results exhibit significant improvement in terms of signal-to-noise ratio.




\begin{figure*}[tbp]
	\centering
	\includegraphics[width=1.0\textwidth]{figures/fig3.png}
	\caption{A cropped ROI from the breast CT reconstruction with sinogram inpainted by DDPM, (a) Ground truth (PSNR), (b) Sparse-view (21.12), (c) Ours with cube size 16$ ^3 $ (27.81) and (d) Ours with cube size 32$ ^3 $ (27.15). The display window is set to [-100, 550] HU. The PSNR of the entire 3D breast CT image is as follows: (b) 19.8, (c) 27.14 and (d) 26.5.}
	\label{fig:3}
\end{figure*}

\section{Discussion and Conclusion}

In this paper, we proposed a cube-based 3D conditional DDPM model for sparse-view breast CBCT reconstruction. The results demonstrate that the synthesized sinograms exhibit high accuracy, and artifacts are effectively removed in the reconstructed images using the synthesized sinograms. The performance of our proposed method highlights its potential for overcoming challenges associated with ultra-large size medical data processing.

Nevertheless, there is still room for improvement. Although the synthesized sinograms deliver good visual and quantitative results, the reconstructed images are not perfect, and some details are missing. This issue arises from subtle errors in sinograms that spread throughout the global image domain. In future work, we plan to introduce a dual-domain DDPM approach to further enhance breast CT images.

Another aspect worth discussing is the efficiency of our proposed method. Due to the thousands of iterations, the DDPM processing efficiency is low. Particularly in our method, the sinogram is divided into redundant cubes for separate processing, further increasing the computational cost. For the model trained with a cube size of 32$^3$, it took 2 hours and 47 minutes to obtain the synthesized sinogram using 128 Nvidia Tesla V100 GPUs. The redundancy is higher for cubes with a size of 16$^3$, resulting in a processing time of 3 hours and 10 minutes. In future work, we will also focus on accelerating this method based on our previous work~\cite{xia2022low} to achieve clinically acceptable efficiency.

Moreover, we discovered that 3D DDPM is sensitive to the input data size. The network struggles to converge effectively when training with larger cubes, such as 64$^3$, leading to mean shift in the synthesized results. In the presented results, the network trained for a cube size of 16$^3$ outperforms the one for 32$^3$. This implies that smaller data sizes can provide more stable DDPM model training. In the popular latent diffusion approach~\cite{rombach2022high}, images are compressed into low-dimensional features to achieve better DDPM training stability. However, this approach is not suitable for medical image processing, as compression may result in the loss of clinically important structures.
Therefore, in future work, exploring ways to improve the stability of DDPM training for large data is an essential research direction.


\bibliographystyle{unsrt} 
\bibliography{ref}
\end{document}