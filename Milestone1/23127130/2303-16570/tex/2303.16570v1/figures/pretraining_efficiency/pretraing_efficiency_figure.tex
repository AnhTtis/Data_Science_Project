\begin{figure}[t!]

\definecolor{darkorange25512714}{RGB}{255,127,14}
\definecolor{darkslategray38}{RGB}{38,38,38}
\definecolor{lightgray204}{RGB}{204,204,204}
\definecolor{steelblue31119180}{RGB}{31,119,180}

\begin{center}
\footnotesize
\begin{tabular}{cc}
{\color{darkorange25512714}\large \textbf{---}} Point-MAE\,\cite{pang2022pointmae} & {\color{steelblue31119180}\large \textbf{---}}  \textbf{\name{}} (Ours)
 \\
\hspace{2cm}&\hspace{2cm}
\end{tabular}
\end{center}
\vspace{-25px}
\hspace{-17px}

\subcaptionbox{ModelNet40\,\cite{wu2015modelnet40}}{\input{figures/pretraining_efficiency/modelnet40_efficiency.tex}}%
\hfill
\subcaptionbox{ScanObjectNN\,\cite{uy2019scanobjectnn}}{\input{figures/pretraining_efficiency/scanobjectnn_efficiency.tex}}%

\caption{
\textbf{Pre-training Data Efficiency.}
Irrespective of the quantity of pre-training data used from ShapeNet, \name{} consistently achieves better results than Point-MAE\,\cite{pang2022pointmae} on ModelNet40 (with voting) and the most difficult test split of ScanObjNN.
}
\label{fig:pretraining_data_efficiency}
\vspace{-20pt}
\end{figure}