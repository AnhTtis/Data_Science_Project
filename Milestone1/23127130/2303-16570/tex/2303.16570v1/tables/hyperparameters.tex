\begin{table}
    \centering
    \caption{
        \textbf{Hyperparameters for \datavec{} and \name{}.}
        \emakefirstuc{\datavec{}} denotes our adaptation of data2vec to the point cloud modality.
        We report the best performing hyperparameters for both \datavec{} and \name{}.
        LN: layer normalization. AVG: average pooling over layers.
    }
    \label{tab:hyperparameters}
    \begin{tabular}{lll}
        \toprule
        & \textbf{\datavec}                   & \textbf{point2vec}                        \\
        \midrule
        Steps                   & $800$ epochs                               & $800$ epochs                                \\
        Optimizer                                          & AdamW                                     & AdamW                                     \\
        Learning rate        & $2 \times 10^{-3}$                                & $1 \times 10^{-3}$                                \\
        Weight decay        & $0.05$                                      & $0.05$                                      \\
        LR Schedule  & cosine                                    & cosine                                    \\
        LR Warm-Up       & $80$ epochs                       & $80$ epochs                       \\
        Batch size            & $2048$                                      & $512$                              \\
        Encoder layers         & $12$                                        & $12$                                        \\
        Encoder dimension       & $384$                                       & $384$                                       \\
        Decoder layers           & --                                         & $4$                                         \\
        Masking strategy            & random                                    & random                                    \\
        Masking ratio                       & $65\%$ & $65\%$ \\
        \arrayrulecolor{black!10}\midrule\arrayrulecolor{black}
        $\tau_0$ (EMA start)  & $0.9998$                            & $0.9998$                              \\
        $\tau_e$ (EMA end)     & $0.99999$     & $0.99999$     \\
        $\tau_n$ (EMA warm-up)  & $200$ epochs                     & $200$ epochs                       \\
        $K$ (layers to average) & $6$                                         & $6$                                         \\
        Target normalization &     \small LN$\rightarrow$AVG$\rightarrow$LN         & \small LN$\rightarrow$AVG$\rightarrow$LN         \\
        \bottomrule
    \end{tabular}
\end{table}