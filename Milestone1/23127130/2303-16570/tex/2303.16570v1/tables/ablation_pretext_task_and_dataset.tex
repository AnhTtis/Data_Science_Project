\begin{table}
    \centering
    \setlength{\tabcolsep}{2pt}
    \caption{
        \textbf{Pretext Tasks.}
        After pre-training with a classification objective on ShapeNet, fine-tuning on ModelNet40 leads to no performance gains over directly training \emph{from scratch} and significantly worse performance on the most difficult test split of ScanObjectNN.
        However, \name{} already brings performance gains when pre-trained with the much smaller ModelNet40 dataset and significant improvements when pre-trained with the large ShapeNet dataset.        
    }
    \label{tab:pretext_tasks}
    \begin{tabular}{lccc}
    	\toprule
    	         & \multicolumn{3}{c}{Overall Accuracy}                                \\
    	\cmidrule(lr){2-4}
    	         & \multicolumn{2}{c}{\textbf{ModelNet40}} & \textbf{ScanObjNN}        \\
    	\cmidrule(lr){2-3} \cmidrule(lr){4-4}
    	Pretext Task & $+$Voting                               & $-$Voting          &   \small \texttt{PB-T50-RS}   \\
    	\midrule
            none / from scratch & $93.3$ & $93.0$ & $84.3$ \\
            classification (ShapeNet) & $93.2$                                    & $93.0$ & $82.9$ \\
            \arrayrulecolor{black!10}\midrule\arrayrulecolor{black}
            \name{} (ModelNet40) & $93.9$ & $93.6$ & $84.4$ \\
    	\name{} (ShapeNet) & $\mathbf{94.8}$ & $\mathbf{94.7}$ & $\mathbf{87.5}$ \\
            \bottomrule
    \end{tabular}
\end{table}
