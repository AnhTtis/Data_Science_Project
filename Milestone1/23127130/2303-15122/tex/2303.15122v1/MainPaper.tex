% CVPR 2023 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
% \usepackage[review]{cvpr}      % To produce the REVIEW version
\usepackage{cvpr}              % To produce the CAMERA-READY version
%\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{times}
\usepackage{epsfig}
\usepackage{enumitem}
\usepackage{breqn}
\usepackage{mathtools}
\usepackage{textcomp}
\usepackage{gensymb}
% \usepackage{authblk}
% \usepackage{multicol}
\usepackage{multirow}
% \usepackage{todonotes}
\usepackage{mathrsfs}
% \pagenumbering{arabic}
\newcommand{\OURNAME}{FP-LIIF\xspace}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{7933} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2023}


\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Parameter Efficient Local Implicit Image Function Network for Face Segmentation}

% \author[1]{Mausoom Sarkar}
% \author[2]{Nikitha SR}
% \author[1]{Mayur Hemani}
% \author[1]{Rishabh Jain}
% \author[1]{Balaji Krishnamurthy}

% \affil[1]{Media and Data Science Research Lab, Adobe}
% \affil[2]{IIT Madras}
\author{Mausoom Sarkar\\
MDSR Lab, Adobe\\
% {\tt\small msarkar at adobe dot com}
\and
Nikitha SR\thanks{Work done during internship at Adobe}\\
IIT Madras\\
% {\tt\small be18b011 at smail dot iitm dot ac dot in }
\and
Mayur Hemani\\
MDSR Lab, Adobe\\
\and
Rishabh Jain\\
MDSR Lab, Adobe\\
\and
Balaji Krishnamurthy\\
MDSR Lab, Adobe\\
}
\maketitle

%%%%%%%%% ABSTRACT
\begin{abstract}
Face parsing is defined as the per-pixel labeling of images containing human faces. The labels are defined to identify key facial regions like eyes, lips, nose, hair, etc. In this work, we make use of the structural consistency of the human face to propose a lightweight face-parsing method using a Local Implicit Function network, \OURNAME. We propose a simple architecture having a convolutional encoder and a pixel MLP decoder that uses $1/26^{th}$ number of parameters compared to the state-of-the-art models and yet matches or outperforms state-of-the-art models on multiple datasets, like CelebAMask-HQ and LaPa. We do not use any pretraining, and compared to other works, our network can also generate segmentation at different resolutions without any changes in the input resolution. This work enables the use of facial segmentation on low-compute or low-bandwidth devices because of its higher FPS and smaller model size. 
\end{abstract}

%%%%%%%%% BODY TEXT
\input{02introduction}
\input{03related_work}
\input{04approach}
\input{05experimentation}
\input{06results}

\input{07conclusion}


%-------------------------------------------------------------------------

%-------------------------------------------------------------------------

%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}
\input{Supplementary}
\end{document}
