\section{Experiments}

\begin{table*}[!ht]
    \centering
    \scalebox{0.93}{
    \begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|l|}
    \hline
        Method/Class & Skin & Hair & Nose & I-Mouth & L-Eye & R-Eye & L-Brow & R-Brow & U-Lip & L-Lip & Mean \\ \hline
        Wei et al.\cite{afip} & 96.1 & 95.1 & 96.1 & 89.2 & 88.9 & 87.5 & 86 & 87.8 & 83.1 & 83.8 & 89.36 \\ \hline
        EAGR\cite{eagrnet} & 97.3 & 96.2 & 97.1 & 90 & 89.5 & 90 & 86.5 & 87 & 88.1 & 89 & 91.07 \\ \hline
        FARL$^{Scratch}$\cite{farl} & 97.2 & 93.1 & 97.3 & 89.4 & 91.6 & 91.5 & 90.1 & 89.7 & 87.2 & 89.1 & 91.62 \\ \hline
        AGRNET\cite{agrnet} & \textbf{97.7} & \textbf{96.5} & 97.3 & \textbf{90.7} & 91.6 & 91.1 & 89.9 & 90 & \textbf{88.5} & \textbf{90.1} & 92.34 \\ \hline
        DML\_CSR\cite{dml_csr} & 97.6 & 96.4 & \textbf{97.3} & 90.5 & 91.8 & 91.5 & 90.4 & 90.4 & 88 & 89.9 & 92.38 \\ \hline
        Ours & 97.6 & 96 & 97.2 & 90.3 & \textbf{92} & \textbf{92.2} & \textbf{90.9} & \textbf{90.6} & 87.8 & 89.5 & \textbf{92.41} \\ \hline
Ours$^{512}$ & 97.5 & 95.9 & 97.2 & 90.3 & \textbf{92} & \textbf{92.2} & \textbf{90.9} & \textbf{90.6} & 87.7 & 89.5 & \textbf{92.38} \\ \bottomrule
Ours$^{192\rightarrow256}$ & 97.5 & 96 & 97.2 & 90.3 & \textbf{92} & \textbf{92.1} & \textbf{90.8} & \textbf{90.5} & 87.7 & 89.4 & 92.35 \\ \bottomrule
Ours$^{128\rightarrow256}$ & 97.5 & 96 & 97.2 & 90.2 & {91.6} & \textbf{91.8} & \textbf{90.8} & \textbf{90.4} & 87.5 & 89.3 & {92.23} \\ \bottomrule
Ours$^{96\rightarrow256}$ & 97.4 & 95.9 & 97.2 & 90.0 & 90.1 & 90.5 & \textbf{90.5} & 90.2 & 87 & 88.9 & {91.76} \\ \bottomrule
Ours$^{64\rightarrow256}$ & 97.1 & 95.8 & 97 & 89.4 & 85.5 & 86.2 & 88.8 & 88.6 & 85 & 87.8 & {90.12} \\ \bottomrule

    \end{tabular}
    }
    \caption{Results on Lapa: F1 score comparison with baselines. Ours$^{512}$ denotes the result of generating output at 512 resolution without changing the input resolution of 256$\times$256. Ours$^{192\rightarrow256}$,Ours$^{128\rightarrow256}$,Ours$^{96\rightarrow256}$ and Ours$^{64\rightarrow256}$ denote results of upsampling from output resolution 192,128,96 and 64 respectively to a resolution of 256.}
    \label{table:lapa_results}
\end{table*}



\begin{table*}[th]
\centering
\scalebox{0.93}{
\begin{tabular}{@{}l|lllllllll|l@{}}
\toprule
\multirow{2}{*}{Method/Class} & Skin  & Nose        & E-glasses & L-Eye & R-Eye & L-Brow  & R-Brow   & L-Ear & R-Ear & \multirow{2}{*}{Mean}       \\ \cmidrule(lr){2-10}
                              & Mouth & U-Lip       & L-Lip      & Hair  & Hat   & Earring & Necklace & Neck  & Cloth &                             \\ \cmidrule(r){1-11} \cmidrule(l){11-11} 
\multirow{2}{*}{Wei et al.\cite{afip}}    & 96.4  & 91.9        & 89.5       & 87.1  & 85    & 80.8    & 82.5     & 84.1  & 83.3  & \multirow{2}{*}{82.05} \\
                              & 90.6  & 87.9        & 91         & 91.1  & 83.9  & 65.4    & 17.8     & 88.1  & 80.6  &                             \\ \cmidrule(r){1-11}
\multirow{2}{*}{FARL$^{Scratch}$\cite{farl}}         & 96.2  & 93.8        & 92.3       & 89    & 89    & 85.3    & 85.4     & 86.9  & 87.3  & \multirow{2}{*}{84.77} \\
                              & 91.7  & 88.1        & 90         & 94.9  & 82.7  & 63.1    & 33.5     & 90.8  & 85.9  &                             \\ \cmidrule(r){1-11}
\multirow{2}{*}{EAGR\cite{eagrnet}}         & 96.2  & 94          & 92.3       & 88.6  & 88.7  & \textbf{85.7}    & 85.2     & 88    & 85.7  & \multirow{2}{*}{85.14} \\
                              & \textbf{95}    & 88.9        & 91.2       & 94.9  & 87.6  & 68.3    & 27.6     & 89.4  & 85.3  &                             \\ \cmidrule(r){1-11}
\multirow{2}{*}{AGRNET\cite{agrnet}}       & 96.5  & 93.9        & 91.8       & 88.7  & 89.1  & 85.5    & 85.6     & 88.1  & \textbf{88.7}  & \multirow{2}{*}{85.53} \\
                              & 92    & 89.1        & 91.1       & 95.2  & 87.2  & 69.6    & 32.8     & 89.9  & 84.9  &                             \\ \cmidrule(r){1-11}
\multirow{2}{*}{DML\_CSR\cite{dml_csr}}     & 95.7  & 93.9        & \textbf{92.6}       & 89.4  & 89.6  & 85.5    & \textbf{85.7}     & \textbf{88.3}  & 88.2  & \multirow{2}{*}{\textbf{86.07}} \\
                              & 91.8  & 87.4        & 91         & 94.5  & \textbf{88.5}  & \textbf{71.4}    & 40.6     & 89.6  & 85.7  &                             \\ \cmidrule(r){1-11}
\multirow{2}{*}{Ours}          & \textbf{96.6}  & \textbf{94} & 92.4       & \textbf{89.6}  & \textbf{89.7}  & 85.2    & 84.9     & 86.7  & 86.6  & \multirow{2}{*}{\textbf{86.07}} \\
                              & 92.6  & \textbf{89.1}        & 91.1       & \textbf{95.2}  & 86.8  & 66.9    & \textbf{43.9}     & \textbf{91.3}  & \textbf{86.7}  &                             \\ \cmidrule(r){1-11}
\multirow{2}{*}{Ours$^{512}$} & \textbf{96.6}  & \textbf{94}    & 92.5       & \textbf{90}    & \textbf{90.1}  & 85.6    & 85.4     & 86.8  & 86.7  & \multirow{2}{*}{\textbf{86.14}} \\
                        & 92.7  & \textbf{89.4}  & \textbf{91.3 }      & \textbf{95.2}  & 86.7  & 67.2    & \textbf{42.2}     & \textbf{91.4}  & \textbf{86.8}  & \\ \bottomrule
\multirow{2}{*}{Ours$^{192\rightarrow256}$}  & \textbf{96.6}  & \textbf{94} & 92.4       & \textbf{89.6}  & \textbf{89.7}  & 85.2    & 84.9     & 86.7  & 86.6  & \multirow{2}{*}{86.05} \\
                              & 92.5  & \textbf{89.1}        & 91.1       & \textbf{95.2}  & 86.8  & 66.9    & \textbf{43.8}     & \textbf{91.3}  & \textbf{86.6}  &                             \\ \cmidrule(r){1-11}
\multirow{2}{*}{Ours$^{128\rightarrow256}$}  & \textbf{96.6}  & \textbf{93.9} & 92.4       & \textbf{89.6}  & \textbf{89.6}  & 85.2    & 84.9     & 86.7  & 86.6  & \multirow{2}{*}{86.03} \\
                              & 92.5  & 88.9        & 91       & \textbf{95.2}  & 86.8  & 66.9    & \textbf{43.9}     & \textbf{91.3}  & \textbf{86.6}  &     
                              \\ \cmidrule(r){1-11}
\multirow{2}{*}{Ours$^{96\rightarrow256}$}  & \textbf{96.5}	& \textbf{93.9}	& 92.3	& 89.3 & 89.3	& 85.1 & 84.8 & 86.7 & 86.5 &\multirow{2}{*}{85.90} \\
& 92.4	& 88.6	& 90.9	& 95.1	& 86.7	& 66.7	& \textbf{43.6}	& \textbf{91.3}  &  \textbf{86.6} & 
                            \\ \cmidrule(r){1-11}
\multirow{2}{*}{Ours$^{64\rightarrow256}$}  & \textbf{96.4}	&93.7	&92.1	&88.5	&88.5	&84.5	&84.3	&86.4	&86.3 &\multirow{2}{*}{85.52} \\
& 92.1	&87.5	&90.3	&95.1	&86.6	&65.7	&\textbf{43.7}	&\textbf{91.2}	&\textbf{86.5} &   
                              \\ \bottomrule 
\end{tabular}
}
\caption{Results on CelebAMask-HQ: F1 score comparison with baselines. Ours$^{512}$ denotes the result of generating output at 512 resolution without changing the input resolution of 256$\times$256. Ours$^{192\rightarrow256}$,Ours$^{128\rightarrow256}$,Ours$^{96\rightarrow256}$ and Ours$^{64\rightarrow256}$ denote results of upsampling from output resolution 192,128,96 and 64 respectively to a resolution of 256.}
    \label{table:celeba_results}
\end{table*}

% \begin{table}[!ht]
%     \centering
%     \begin{tabular}{|l|l|l|l|}
%     \hline
%         Dataset & CelebA MIoU $\uparrow$& LaPa MIoU $\uparrow$ \\ \hline
%         DML\_CSR & 77.81 & 87.13 \\ \hline
%         Ours$^{128}$ & \textbf{77.98} & \textbf{87.17} \\ \hline
%         Ours & \textbf{77.92} & \textbf{87.15} \\ \hline
%         Ours$^{512}$ & \textbf{78.11} & \textbf{87.13} \\ \hline
%     \end{tabular}
%     \caption{MeanIoU scores for CelebA and LaPa: Comparison of scores with DML\_CSR shows our models achieves comparable or better MIoU on both datasets while being $26$ times smaller in parameter count }
%     \label{meaniou}
% \end{table}
\begin{table}[!ht]
\centering
\scalebox{0.9}{

\begin{tabular}{|c|c c c c|c|}
\toprule
\multirow{2}{*}{Model/Class} & Skin  & Nose &U-lip & I-mouth & \multirow{2}{*}{Overall}       \\ \cmidrule(lr){2-5}
                              & L-Lip  & Eyes  & Brows   & Mouth &                             \\ \cmidrule(r){1-6} \cmidrule(l){6-6} 
\multirow{2}{*}{EAGR} & 94.6 & 96.1 & 83.6  & 89.8 & \multirow{2}{*}{93.2} \\ \cmidrule(lr){2-5}
&91    & 90.2 & 84.9  & 95.5  &     
\\ \cmidrule(lr){1-6}
\multirow{2}{*}{DML-CSR} & 96.6 & 95.5 & 87.6  & 91.2  & \multirow{2}{*}{93.8} \\ \cmidrule(lr){2-5}
& 91.2  & 90.9 & 88.5  & 95.9  &     
\\ \cmidrule(lr){1-6}
\multirow{2}{*}{Ours} & 95.1 & 94   & 79.7  & 86.3  & \multirow{2}{*}{91.2} \\ \cmidrule(lr){2-5}
& 87.6  & 89.1 & 81    & 93.6   &     
\\ \bottomrule 
% DML-CSR      & 96.6 & 95.5 & 87.6  & 91.2    & 91.2  & 90.9 & 88.5  & 95.9  & 93.8    \\ \hline
% Ours         & 95.1 & 94   & 79.7  & 86.3    & 87.6  & 89.1 & 81    & 93.6  & 91.2    \\ \hline
\end{tabular}
}
\caption{Results on Helen: F1 score comparison with baselines.Our results on non aligned Helen face data set are comparable to SOTA.} 
\label{table:helen_results}
\end{table}

\begin{table}[!ht]
    \centering
    \scalebox{0.86}{
    \begin{tabular}{|c|c|c|c|c|}
    \hline
        Model & Params $\downarrow$  & $\times$\OURNAME $\downarrow$ &GFlops $\downarrow$ &FPS$\uparrow$ \\ \hline
        DML\_CSR & $59.67$ M & $26$ & $253$ & $76$\\ \hline
        EAGR & $66.72$ M & $29$ &$235$ & $71$\\ \hline
        FARL & $150$ M & $65$ & $370$ & $26$\\ \hline
        \OURNAME(ours) & $\textbf{2.29}$ M & $\textbf{1}$ & $\textbf{85}$ & $\textbf{110}$ \\ \hline
    \end{tabular}
    }
    \caption{Model size comparison: The table shows the parameter count, GFlops, and FPS for each of the models and the relative size of each model compared to \OURNAME}
    \label{modelsize}
\end{table}
\begin{figure}
\begin{center}
  \includegraphics[width=0.9\linewidth]{images/celeb-gt-wrong.png}

\end{center}
\vspace{-0.5cm}
\caption{Few test samples from CelebAMask-HQ dataset illustrating noisy ground truth data and our prediction for the same. In the top row headgear has been marked as hair and in the bottom row strands of hair are not clearly segmented in the ground truth mask.} 
\vspace{-0.5cm}
\label{fig:gt-worse}

\end{figure}

\subsection{Datasets} We use three face datasets to perform our experiments, LaPa\cite{lapa}, CelebAMask-HQ \cite{celebAmaskHQ} and Helen \cite{helen}. LaPa is a face dataset with more in-the-wild photos having varying poses and occlusions. It has 22,168 images, of which 18,176 are for training, 2000 are for validation, and 2000 are for testing. The segmentation masks in LaPa have 11 categories: skin, hair, nose, left/right eyes, left/right brows, and upper/lower lips. The CelebAMask-HQ dataset contains 30k face images split into 24,183 training, 2993 validation, and 2824 test samples. It has a total of 19 semantic labels, including labels for accessories like eyeglasses, necklaces, earrings, etc., in addition to the labels in LaPa. Helen is the smallest of these three with 11 categories and has 2330 images with 2000, 230, and 100 in the training, validation, and test samples respectively. 

\subsection{Implementation Details} We implement our training and evaluation pipeline on PyTorch\cite{pytorch} version 1.10.0 with the CUDA 11.1 backbone on Python 3.8.5. We train \OURNAME on 4 Nvidia A-100 GPUs with a mini-batch size of 33 and 64 for CelebAMask-HQ and LaPa respectively. The network is optimized for 400 epochs using Adam \cite{kingma2014adam} with an initial learning rate of 5e-4. The learning rate is decreased by a factor of 10 after every 20 epochs. The $\lambda$ for edge-cross-entropy was set to 10 and 40 for CelebA and Lapa, respectively. Temperature scaling of softmax is also done with $\tau=0.5$. The images and masks in the datasets were resized to $256 \times 256$ using bicubic sampling before being used for training and evaluation. During training various data augmentations are applied like random affine transformations of rotation by 30\degree, shear between 0 to 20, scaling between 0.5 to 3 followed by random cropping. Color jitter is also applied to the input image with a brightness between [0.5,1.5], contrast [0,2], saturation [0.5,1.5], and hue [-0.3,0.3]. 

\subsection{Evaluation Metrics} 
To keep our evaluation consistent with other works, we primarily use a class-wise F1 score and a mean F1. In addition to that, we use mean intersection over union (mIoU) to compare with DML\_CSR. The background class is ignored in all these metrics.

\subsection{Baselines}
We compare our \OURNAME performance with several baselines, like Wei et al. \cite{afip} (figures taken from \cite{farl}), AGRNET\cite{agrnet}, EAGR\cite{eagrnet}, DML\_CSR\cite{dml_csr}, FARL\cite{farl} from scratch, i.e., no pre-training. The results on LaPa are reported in Table \ref{table:lapa_results}, results comparing performance on CelebAMask-HQ are in Table \ref{table:celeba_results} and results on Helen are in Table \ref{table:helen_results}. Finally, a comparison of model size, Gflops and FPS is made in Table \ref{modelsize}.
% To have a fair comparison with FARL we only compare with the $scratch$ version reported in FARL\cite{farl}, that doesn't use their image-text-caption pretraining. 


% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% \usepackage{multirow}



