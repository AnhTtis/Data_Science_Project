\documentclass[runningheads]{llncs}
% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
%


\usepackage{templates/mainpreambel}

\input{references/commands}
\input{references/constants}

\makeglossaries
\loadglsentries[acronym]{./references/glossary.tex}

% \DeclareLanguageMapping{american}{american-apa}

% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

% \loadglsentries[acronym]{./references/glossary.tex}
\graphicspath{{figures/}}


\usepackage{subfiles} 

% %%% xlu : added to shrink space between figure and text
% % This changes the margin between the figures/tables and the text
% % DO NOT make this space even smaller
% \setlength{\textfloatsep}{8pt}
% \setlength{\intextsep}{6pt}
% \setlength{\floatsep}{6pt}


\begin{document}
%
\title{CREATED: Generating Viable Counterfactual Sequences using an Evolutionary Algorithm for Event Data
% \title{CREATED: The Generation of viable Counterfactual Sequences using an Evolutionary Algorithm for Event Data of Complex Processes
% \thanks{Supported by organization x.}
}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Olusanmi Hundogan\inst{1}\and
Xixi Lu\inst{1}\orcidID{0000-0002-9844-3330} \and
Yupei Du\inst{1}\orcidID{2222--3333-4444-5555} \and
Hajo A. Reijers\orcidID{0000-0001-9634-5852}}
%
\authorrunning{O. Hundogan et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Utrecht University, 3584 CS Utrecht, The Netherlands 
% \and
% Springer Heidelberg, Tiergartenstr. 17, 69121 Heidelberg, Germany
% \email{lncs@springer.com}\\
% \url{http://www.springer.com/gp/computer-science/lncs} \and
% ABC Institute, Rupert-Karls-University Heidelberg, Heidelberg, Germany\\
% \email{\{abc,lncs\}@uni-heidelberg.de}
}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
    % Within the field of Process Mining, deep recurrent networks (such as LSTM) have been used to predict the next state or the outcome of a multivariate sequence. However, these models tend to be complex and are difficult for users to understand of the underlying process model. Counterfactuals answer "what-if" questions, which are used to understand the reasoning behind the predicted outcome of a process. Current methods to generate counterfactual explanations do not take the structural characteristics of multivariate discrete sequences into account. In this work we propose a framework that uses evolutionary methods to generate counterfactuals, while incorporating criteria that ensure their viability. Our results show that it is possible to generate counterfactuals that are viable and automatically align with the factual. The generated counterfactuals outperform baseline methods in viability and yield comparable results compared to other methods in the literature.
    

Predictive process analytics %is an emerging research field in process mining that 
focuses on predicting the future outcome or following states of running process cases. These techniques often use Machine Learning models or deep learning models (such as LSTM) to learn to make predictions. 
%
However, these deep models are complex and difficult for users to understand, also known as the unexplainable issue of AI.
%
% \emph{Counterfactuals} are alternative execution  of a case that lead to a different outcome, help to understand the reasoning of the predictions of the deep models.
%
Counterfactuals answer ``what-if'' questions, which are used to understand the reasoning behind the predictions. For example, what if instead of emailing customers, calling customers is executed? Would this alternative led to a different outcome? 
%
Current methods to generate counterfactuals do not take the process behavior into account, leading to generating invalid or infeasible counterfactual process instances. Another state-of-the-art method heavily relies on domain knowledge and assumes a normative process model consisting of milestones is made available. 
%
In this work, we propose a general framework that uses evolutionary methods to generate counterfactual sequences. In addition, our approach does not require domain knowledge about process behavior. Instead, we propose to learn a Markov process to estimate the feasibility of counterfactual sequences. The feasibility measure is incorporated in the proposed measures that ensure the viability of counterfactual sequences. Our results show that it is possible to generate counterfactual sequences that are viable without domain knowledge. Furthermore, the generated counterfactuals outperform baseline methods in viability and yield equally good results when compared to the state-of-the-art method that requires domain knowledge. 
\keywords{First keyword  \and Second keyword \and Another keyword.}
\end{abstract}
%
%
%
% TODO: Put all the thesis content in the paper
% TODO: Change chapters to sections
% NOTE: Technical papers describe original solutions (theoretical, methodological or conceptual) in the field of IS Engineering. A technical paper should clearly describe the situation or problem tackled, the relevant state of the art, the position or solution suggested and its potential‚ as well as demonstrate the benefits of the contribution through a rigorous evaluation.
% NOTE: Limit is 16 pages

% XIXI: Change cite_author to cite.
\section{Introduction}
\label{ch:intro}
\input{files/01intro}

\section{Related work}
\label{ch:relatedwork}
\input{files/02relatedwork}

% REMOVED Background sections on Process Mining, Multivariate Times-series and Counterfactuals
% \section{Background}
% \label{ch:prereq}
% This chapter explores the most important concepts for this work. Hence, we focus on the problem domain, starting with an overview about \Gls{PM}. Afterwards, we discuss the nature of the data, we handle in this thesis by discussing \emph{Multivariate Discrete Time-Series}. Next, we introduce counterfactuals and establish how we characterise \emph{viable} counterfactuals. 

% \subsection{Process Mining}
% \label{sec:process}
% This thesis focuses on processes and the modelling of process generated data. Hence, it is important to establish a common understanding for this field.
% \subfile{content/sections/sec_pm}

% \subsection{Multivariate Time-Series Modeling}
% \label{sec:sequences}
% The temporal and multivariate nature of \gls{instance} often turns \Gls{PM} into a Multivariate Time-Series Modeling problem. Therefore, it is necessary to establish an understanding for this type of data structure.
% \subfile{content/sections/sec_mlts}


% \subsection{Counterfactuals}
% \label{sec:counterfactuals}
% Counterfactuals are an important explanatory tool to understand a models' cause for decisions. Generating counterfactuals is main focus of this thesis. Hence, we establish the most important chateristics of counterfactuals in this section.

% \subsubsection{What are Counterfactuals?}
% \subfile{content/sections/sec_counterfactuals_criterions}

% % \subsection{Other Criteria}
% % \label{sec:other}
% % \subfile{content/sections/sec_viability_other}

% \subsubsection{The Challenges of Counterfactual Sequence Generation}
% \subfile{content/sections/sec_counterfactuals_challenges}

\section{Background}
% \subsection{Formal Definitions}
\label{sec:formulas}
% Before diving into the rest of this thesis, we have to establish preliminary definitions, we use in this work. With this definitions, we share a common formal understanding of mathematical descriptions of every concept used within this thesis. 

% XIXI: Make much shorter like the example but add your new concepts
% \subsection{Process Logs, Cases and Instance Sequences}
\textbf{Definition 1: Case, Event and Log}
We start by formalising the event log and its elements. An event log is denoted as $L$. 
Let $\mathcal{E}$ be the universe of  these event identifiers and $E \subseteq \mathcal{E}$ a set of events. 
Let $C$ be a set of case identifiers and $\pi_\sigma : E \mapsto C$ a surjective function that links every element in $E$ to a case $c \in C$ in which $c$ signifies a specific case. 
For a set of events $E \subseteq \mathcal{E}$, the shorthand $s^c$ denotes a particular sequence $s^c = \langle e_1, e_2, \ldots, e_t \rangle$ with $c$ as case identifier and a length of $t$. Each $s$ is a trace of the process log $s \in L$.  
Let $\mathcal{T}$ be the time domain and $\pi_t : E \mapsto \mathcal{T}$ a non-surjective linking function which strictly orders a set of events. 
% Let $\mathcal{A}$ be a universe of attribute identifiers, in which each identifier maps to a set of attribute values $\overline{a}_i \in \mathcal{A}$. 
% Let $\overline{a}_i$ correspond to a set of possible attribute values by using a surjective mapping function $\pi_A : \mathcal{A} \mapsto A$. 
Each event $e_t$ consists of a set $e_t = \{ a_1 \in A_1, a_2 \in A_2, \ldots, a_I \in A_I\}$ with the size $I = |A|$, in which $A_i$ is an attribute and $a_i$ represents a possible value of that attribute. 
% We define a mapping from an attribute value to its respective attribute identifier $\pi_{\overline{a}} : A \mapsto \mathcal{A}$. Hence, we can map every event attribute value back to its attribute identifier. 

% \subsection{Representation}
\noindent\textbf{Definition 2: Attribute Representation}
Let $\pi_d : A_i \mapsto \mathbb{N}$ be a surjective function, which determines the dimensionality of $a_i$ and also $F$ be a set of size $I$ containing a representation function for every attribute. Let $f_i \in F$ be mapping functions to a vector space $f_i : a_i \mapsto \mathbb{R}^d_i$, in which $d$ represents the dimensionality of an attribute value $d = \pi_d(A_i)$. 
We denote any event $e_t \in s^c$ of a specific case $c$ as a vector, which concatenates every attribute representation $f_i$ as $\mathbf{e}_t^{c} = [f_1; f_2; \ldots; f_I]$. Therefore, $\mathbf{e}_t^{c}$ is embedded in a vector space of size $D$ which is the sum of each individual attribute dimension $D = \sum_i \pi_d(A_i)$. In other words, we concatenate all representations, whether they are scalars or vectors to one final vector representing the event. Furthermore, if we refer to a specific attribute $A_i$, we use the shorthand $\overline{a}_i$. 

% \autoref{fig:representation} shows a schematic representation of a log $L$, a case $c$ and an event $e$.


% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=0.9\textwidth]{figures/Graphics/Slide4.PNG}
%     \caption{This figure shows the representation of a log $L$ which contains a number of cases $s$. Case $s^2$ contains a number of events $e_t$. Each events has attribute values $a_i$, which are mapped to vector spaces of varying dimensions. At last, all of the vectors are concatenated.}
%     \label{fig:representation}
% \end{figure}


% REMOVED state space models formal description

% \subsection{Representation}
% \label{sec:representation}
% \subfile{content/sections/sec_representation}

\section{Methods}
\label{ch:methods}
% In this chapter, we describe details of our framework and discuss advantages and limitations. 
% Therefore, we provide a more detailed overview and additionally describe all components. As the framework resembles the work of \cite{hsieh_DiCE4ELInterpretingProcess}, we also discuss differences and similarities between both solutions. 

\subsection{Methodological Framework: CREATED}
\label{sec:framework}
% \subsubsection{Architecture}
% \subfile{content/sections/sec_framework}
To generate counterfactuals, we need to establish a conceptual framework consisting of three main components. The three components are shown in \autoref{fig:approach}. 

% \attention{Change the names of the measures.}
\begin{figure}[htb]
    \centering
    \includegraphics[width=0.99\textwidth]{figures/framework.png}
    \caption{The CREATED framework: the input is the process log; the log is used to train a predictive model (Component 1) and the generative model (Component 2). This process produces a set of candidates which are subject to evaluation via the validity metric (Component 3).}
    \label{fig:approach}
\end{figure}

The first component is a predictive model. As we attempt to explain model decisions with counterfactuals, the model needs to be pretrained. We can use any model that can predict the probability of a sequence. This condition holds for models trained for process outcome classification and next-activity prediction. The model used in this paper is a simple LSTM model using the process log as an input. The model architecture is inspired by \cite{hsieh_DiCE4ELInterpretingProcess_2021}. The model is trained to predict the next action given a sequence. 

The second component is a generative model. The generative model produces counterfactuals given a factual sequence. 
% In our approach, each generative model should be able to generate a set of counterfactual candidates given one factual sequence. 
Specifically, we compare an evolutionary approach against 3 different generative baseline approaches. The baselines do not iteratively optimise towards viability criteria. All approaches allow us to use a factual sequence as a starting point for the generative production of counterfactuals. Furthermore, they also generate multiple variations of the final solution. 

The generated candidates are subject to the third major component's scrutiny. 
To select the most \emph{viable} counterfactual candidate, we evaluate their viability score using a custom metric. 
The metric incorporates four criteria for viable counterfactuals. 
We measure the \emph{similarity} between two sequences using a multivariate sequence distance metric. The \emph{delta} between the likelihood of the factual and the counterfactual. For this purpose, we require the predictive model, which computes a prediction score reflecting the likelihood. 
We measure \emph{sparsity} by counting the number of changes in the features and computing the edit distance. Lastly, we need to determine the \emph{feasibility} of a counterfactual. This requires splitting the feasibility into two parts. First, the likelihood of the sequence of each event and second, the likelihood of the features given the event that occurred.
As we heavily rely on evolutionary algorithms to generate our counterfactuals, we refer to this framework as CREATED. The name describes the \textbf{C}ounte\textbf{R}factual Sequence generation with \textbf{E}volutionary \textbf{A}lgori\textbf{T}hms on \textbf{E}vent \textbf{D}ata. The name reflects how our model CREATEs new counterfactuals.



% \subsection{Semi-Structured Damerau-Levenshtein \\ Distance}
% \label{sec:ssdld}
% Before discussing the viability function, we have to introduce an edit-distance for sequences. An edit-distance is used to compute distance between two sequences. Therefore, they take their \emph{structural} patterns like the length or deletions or inserts into account. However, most approaches tend to focus on the sequence of items (letters or words) without taking into account that each item may have additional attributes. Therefore, we propose a custom edit-distance measure. 
% 
% \subsubsection{Semi-Structured Damerau-Levenshtein}
% % \subfile{content/sections/sec_viability_ssdld}
% \noindent In order to reflect these differences in attribute values, we introduce a modified version of the \gls{damerau_levenshtein}, that not only reflects the difference between two process instances, but also the attribute values. We achieve this by introducing a cost function $\editCost$, which applies to a vector-space. Concretely, we formulate the modified \gls{damerau_levenshtein} as shown in \autoref{eq:modified_dl}. For the remainder, we refer to this edit-distance as \gls{SSDLD}.
% % TODO: Introduce a with a dash above to compare activities instead of the vector
% % Make zero thicker to indicate a null vector
% \begin{align}
%     \label{eq:modified_dl}
%     d_{a, b}(i, j) & =\min
%     \begin{cases}
%         \editDistance{i-1}{j  }+\editCostFunctionNoA & \text { if } i>0                                            \\
%         \editDistance{i  }{j-1}+\editCostFunctionNoB & \text { if } j>0                                            \\
%         \editDistance{i-1}{j-1}+\editCostFunctionBoth & \text { if } i, j>0   \\ & \text { \& } \overline{a}_i=\overline{b}_j                                       \\
%         \editDistance{i-1}{j-1}+ \editCostFunctionNoB +\editCostFunctionNoA  & \text { if } i, j>0  \\ & \text { \& } \overline{a}_i \neq \overline{b}_j                                       \\
%         \editDistance{i-2}{j-2}+\editCostFunction{a_i}{b_{j-1}} + \editCostFunction{a_{i-1}}{b_j} & \text { if } i, j>1 \\ 
%         & \text { \& } \overline{a}_i=\overline{b}_{j-1} \\ 
%         & \text { \& } \overline{a}_{i-1}=\overline{b}_j \\
%         0                                 & \text { \& } i=j=0                                          
%     \end{cases} 
% \end{align}

% \noindent Here, $d_{a, b}(i, j)$ is the recursive form of the Damerau-Levenshtein-Distance. $a$ and $b$ are sequences and $i$ and $j$ specific elements of the sequence. $cost(a,b)$ is a cost function which takes the attribute values of $a$ and $b$ into account. 
% The first two terms correspond to a deletion and an insertion from $a$ to $b$. The idea is to compute the maximal cost for that the wrongfully deleted or inserted event. 
% The third term adds the difference between two events with identical activities $\overline{a}_i$ and $\overline{b}_j$. As mentioned earlier, two events that refer to the same activity can still be different due to event attributes. The distance between the event attributes determines \emph{how} different these events are. 
% The fourth term handles the substitution of two events. Here, we compute the substitution cost as the sum of an insertion and a deletion. 
% The fifth term computes the cost after transposing both events. This cost is similar to term 3 only that we now consider the differences between both events after they were aligned. The last term relates to the stopping criterion of the recursive formulation of the \gls{damerau_levenshtein}.  

% \subsubsection{Discussion}
% % \subfile{content/sections/sec_viability_ssdld_discussion}
% Given the current viability measure, we can already determine the optimal counterfactual:
% \begin{displayquote}
%     The optimal counterfactual flips a model's strongly expected factual outcome to the desired outcome, maintaining the same trajectory as the factual in terms of events, with minimal changes in its event attributes, while remaining feasible according to the data.
% \end{displayquote}

% \noindent The elements that fulfil these criteria make up the Pareto surface of this multi-valued viability function. If each value is scaled with a range between 0 and 1, the theoretical ceiling is 4. This value is only possible if we flip a factual sequence's outcome without changing it. As this is naturally impossible for deterministic model predictions, the viability has to be lower than 4. 

% Furthermore, we can already postulate that a viability of 2 is a critical threshold. If we score the viability of a factual against itself, a normalised sparsity and similarity value have to be at its maximal value of 1. In contrast, the improvement has to be 0. The feasibility is 0 depending on whether the factual were used to estimate the data distribution or not. With these observations in mind, we determine that any counterfactual with a viability of at least 2 is already better than the factual. 


% XIXI: For viability functions its not important to explain existing methods or discuss them. Sparsity function is a good example. Shorten the delta function section a bit and refer to the thesis.
% XIXI: Shorten SSDLD to explain that it is a damerau-levenshstein modification but instead of dealing with atomic symbols (cost of 1) it uses as cost similarity functions for vector sequences. Weighted Damerau Levenshstein where weight is cost function for vectors






\subsection{Counterfactual Generators}
\label{sec:model_generation}
\textbf{Generative Model: Evolutionary Algorithm}
\label{sec:model_evolutionary}
% \subfile{content/sections/sec_model_evolutionary}
% We introduced most operator types in \autoref{sec:evo}.
In this section, we describe the concrete set of operators and select a subset that we want to explore further.

For our purposes, the \emph{gene} of a sequence consists of the sequence of events within a \gls{instance}. Hence, if an offspring inherits one parent gene, it inherits the activity associated with the event and its event attributes. Our goal is to generate candidates by evaluating the sequence based on our viability measure. Our measure acts as the fitness function. The candidates that are deemed fit enough are subsequently selected to reproduce offspring. This process is explained in \autoref{fig:example-inheritance}. The offspring is subject to mutations. Then, we evaluate the new population and repeat the procedure until a termination condition is reached. We can optimise the viability measure established in \autoref{sec:viability}.

\begin{figure}[t]
    \begin{tikzpicture}[>=stealth,thick,baseline]
        \matrix [matrix of math nodes, left delimiter=(,right delimiter=)](m1){
            a   & b    & a    \\
            0.6 & 0.25 & 0.70 \\
            0   & 0    & 1    \\
            1.2 & 4.5  & 2.3  \\
        };
        \node[draw,  blue!80, dashed, thin, inner sep=2mm,fit=(m1-1-1.west) (m1-4-2.east)] (attbox) {};
        \node[above = 2mm of m1](rlbl) {Parent 1};
        \node[below = 2mm of attbox, blue!80](lb1) {\tiny Genes passed on};


        \node[right = 2mm of m1](cr){+};

        \matrix [matrix of math nodes,left delimiter=(,right delimiter=), right = 2mm of cr](m2){
            a   & b    & a    & c    \\
            0.6 & 0.75 & 0.64 & 0.57 \\
            0   & 0    & 1    & 0    \\
            1.2 & 4.5  & 3.3  & 3.0  \\
        };
        \node[draw,  red!80, dashed, thin, inner sep=2mm,fit=(m2-1-3.west) (m2-4-4.east)] (attbox-m2) {};
        \node[above = 2mm of m2](rlbl) {Parent 2};
        \node[below = 2mm of attbox-m2, red!80](lb2) {\tiny Genes passed on};


        \node[right = 2mm of m2](eq){=};

        \matrix [matrix of math nodes,left delimiter=(,right delimiter=), right = 2mm of eq](m3){
            a   & b    & a    & c    \\
            0.6 & 0.25 & 0.64 & 0.57 \\
            0   & 0    & 1    & 0    \\
            1.2 & 4.5  & 3.3  & 3.0  \\
        };

        \node[draw,  blue!80, dashed, thin, inner sep=2mm,fit=(m3-1-1.west) (m3-4-2.east)] (attbox-m3-1) {};
        \node[draw,  red!80, dashed, thin, inner sep=2mm,fit=(m3-1-3.west) (m3-4-4.east)] (attbox-m3-2) {};
        \node[below = 2mm of attbox-m3-1, blue!80](lb2) {\tiny Inherited};
        \node[below = 2mm of attbox-m3-2, red!80](lb2) {\tiny Inherited};

        \node[above = 2mm of m3](rlbl) {Offspring};
        % \draw[->, outer] (m2.east) -- (m3.west);
    \end{tikzpicture}
    \caption{A newly generated offspring inheriting genes in the form of activities and event attributes from both parents.}
    \label{fig:example-inheritance}
\end{figure}



\newcommand{\cf}{\text{counterfactuals}}
\newcommand{\cfp}{\text{cf-parents}}
\newcommand{\cfo}{\text{cf-offsprings}}
\newcommand{\cfm}{\text{cf-mutants}}
\newcommand{\cfs}{\text{cf-survivors}}


\begin{algorithm}[b]
    \caption{The basic structure of an evolutionary algorithm.}
    \begin{algorithmic}
        \Require{factual, configuration, sample-size, population-size, mutation-rate, termination-point}
        % \Require{}
        % \Require{}
        % \Require{}
        % \Require{}
        % \Require{}
        \Ensure{The result is the final counterfactual sequences}

        \State $counterfactuals \gets initialize(\text{factual})$
        \While{not $termination$}
        \State $\cfp \gets select(\cf, \text{sample-size})$
        \State $\cfo \gets crossover(\cfp) $
        \State $\cfm \gets mutate(\cfo, \text{mutation-rate})$
        \State $\cfs \gets recombine(\cf, \cfm, \text{population-size})$
        \State $termination \gets determine(\cfs, \text{termination-point})$
        \State $\cf \gets \cfs$
        \EndWhile
    \end{algorithmic}
    \label{alg:my-evolutionary}
\end{algorithm}

\noindent\textbf{Operators}
We implemented several different evolutionary operators. Each one belongs to one of five categories. The categories are initiation, selection, crossing, mutation and recombination.

% XIXI: Shorten many of the descriptions by describing a standard reference book.
% XIXI: Likes the images for OPC, TPC and UPC

\begin{table}
\begin{center}
% \begin{small}
\begin{tabular}{ | m{0.75cm} | m{2.5cm}| m{8cm} | } 
\hline
    Label & Name & Description\\
    
    \hline
    % \hline
    \multicolumn{3}{|l|}{Initiation}\\
    \hline
    RI & Random Initialisation & Generates an initial population with event attributes drawn from a normal distribution. \\ 
    SBI & Sampling-Based Initialisation & Generates an initial population by sampling from a data distribution estimated from the data directly. \\ 
    CBI & Case-Based Initialisation & Samples initial population directly from the Log. \\ 
    \hline
    % \hline
    \multicolumn{3}{|l|}{Selection}\\
    \hline
    RWS & Roulette-Wheel-Selection & Selects individuals randomly in proportion to their fitness value  \\
    TS & Tournament-Selection & Selects pairs of individuals and compares each pair. The better individual between both pairs has a higher chance of being selected.\\
    ES & Elitism-Selection & Selects individual with the highest fitness. \\
    \hline
    % \hline
    \multicolumn{3}{|l|}{Crossover}\\
    \hline    
    UCx & Uniform Crossover & uniformly choose a fraction of genes of one individual (\emph{Parent 1}) and overwrite the respective genes of another individual (\emph{Parent 2}).\\
    OPC & One-Point Crossover & Chooses a point in the sequence and overwrites the genes of \emph{Parent 2} by the genes \emph{Parent 2} from that point onward.\\
    TPC & Two-Point Crossover & Chooses two points in the sequence and overwrites the sequence in between the two points from \emph{Parent 2} with the sequence from \emph{Parent 1}.\\
    \hline
    % \hline
    \multicolumn{3}{|l|}{Mutation}\\

    \hline    
    RM & Random-Mutation & Inserts, changes or deletes activities randomly. Event attributes are drawn from a normal distribution.\\
    SBM & Sampling-Based Mutation & Inserts, changes or deletes activities randomly. Event attributes are drawn from an estimated data distribution.\\
    \hline
    % \hline
    \multicolumn{3}{|l|}{Recombination}\\
    \hline   
    % 
    FSR & Fittest-Survivor Recombination & Strictly determines the survivors among the mutated offsprings and the current population by sorting them in terms of viability\\
    BBR & Best-of-Breed Recombination & Determines offsprings that are better than the average within their generation and adds them to survivors of past generations.\\
    RR & Ranked Recombination & selects the new population differently than the former recombination operators. Instead of using the viability directly, we sort each individuum by every viability component separately. This approach allows us to select individuals regardless of the scales of every individual viability measure.\\
    \hline
\end{tabular}
% \end{small}
\end{center}
\end{table}




% \paragraph{Inititation}
% \begin{enumerate}
%     % \item[RI:] The \emph{Random-Initiation} . The activity is just a randomly chosen integer, and each event attribute is drawn from a normal distribution.
%     \item[SBI:] The \emph{Sampling-Based-Initiation} 
%     \item[CBI:] \emph{Case-Based-Initiation} samples individuals from a subset of the Log (\emph{Case-Based-Initiation}). Those individuals are used to initiate the population.
%           % \item[FI:] \emph{Factual-Initiation} Uses the factual itself. 
% \end{enumerate}
% The initiation procedure might be the most important operation in terms of computation time. The reason is that we expect more sophisticated initiation procedures like Sampling-Based-Initiation and Case-Based initiation to start with much higher viability and reach their convergence much sooner.


% \paragraph{Selection \& Crossing}
% For selection we use operators that are widely known within the literature of evolutionary algorithms\cite{DBLP:journals/gpem/Popyack16}. In particular, we use \emph{Roulette-Wheel-Selection} (RWI), \emph{Tournament-Selection} and \emph{Elitism-Selection} for the selection step. Likewise, for the crossover step we use \emph{Uniform-Crossover} (UC), \emph{One-Point-Crossover} (OPC) and \emph{Two-Point-Crossover} (TPC).
% \begin{enumerate}
%     \item[RWI:] \emph{Roulette-Wheel-Selection} Selects individuals randomly. However, we compute each individual's fitness in the population and choose a random sample proportionate to their fitness values. Hence, sequences with high fitness values have a higher chance to crossover their genes, while fewer fit individuals also occasionally get their chance.
%     \item[TS:] \emph{Tournament-Selection} compares two or more individuals and selects a winner among them. We choose two competing individuals we randomly sample with replacement. Hence, some individuals have multiple chances to compete. The competing individuals are randomly chosen as winners in proportion to their viability. Hence, if an individual with a viability of 3 is pitted against an individual with a viability of 1, then there's a 3:1 chance that the first individual will move on to crossover its genes.
%     \item[ES:] \emph{Elitism-Selection} selects each individual solely on their fitness. In other words, only a top-k amount of individuals are selected for the next operation. There is no chance for weaker individuals to succeed. This approach is deterministic and, therefore, subject to getting stuck in local minima.
% \end{enumerate}

% \paragraph{Crossing}
% \begin{enumerate}
%     \item[UCx:] We can uniformly choose a fraction of genes of one individual (\emph{Parent 1}) and overwrite the respective genes of another individual (\emph{Parent 2}). The result is a new individual. We call that (\emph{Uniform-Crossover}).
%           \autoref{fig:crossover_uniform} shows a simple schematic example. By repeating this process in the opposite direction, we create two new offsprings that share both individuals' characteristics.
%           The number of inherited genes can be adjusted using a rate factor. The number of selected positions is determined by a crossing rate between 0 and 1. The higher the crossover rate, the higher the risk of disrupting possible sequences. If we turn to \autoref{fig:crossover_uniform} again, we see how the second child has 2 repeating genes at the end. If a process does not allow the transition from \emph{activity 8} to another \emph{activity 8}, then the entire \gls{instance} becomes infeasible.
%     \item[OPC:] \emph{One-Point-Crossing} is an approach suitable for sequential data of the same lengths. We can choose a point in the sequence and pass on genes of \emph{Parent 1} onto the \emph{Parent 2} from that point onwards and backwards (\emph{One-Point-Crossover}).
%           Thus, creating two new offsprings as depicted in \autoref{fig:crossover_onepoint}.
%     \item[TPC:] \emph{Two-Point-Crossing} resembles its single-point counterpart. However, this time, we choose two points in the sequence and pass on the overlap, and the disjoints to generate two new offsprings. Again, \autoref{fig:crossover_twopoint} describes the procedure visually. We can increase the number of crossover points even further. However, this increase comes at the risk of disrupting sequential dependencies.
% \end{enumerate}

% \input{./content/diagrams/evo_uc.tex}
% \input{./content/diagrams/evo_opc.tex}
% \input{./content/diagrams/evo_tpc.tex}



% \paragraph{Mutation}
% Before elaborating on the details, we have to briefly discuss four modification types we can apply to data sequences. Reminiscent of edit distances, which were introduced earlier in this thesis, we can either insert, delete, change and transposition a gene. These edit types are the fundamental edits we use to modify sequences. For a visual explanation of each edit-type we refer again to \autoref{fig:dl_example} in \autoref{sec:damerau}.

% However, we can change the extent to which each operation is applied over the sequence. We call these parameters \emph{mutation-rates}. In other words, if the delete rate equals 1, every individual experiences a modification which results in the deletion of a step. The same applies to other edit types.

% As we chose the hybrid encoding scheme, we must define what an insert or a change means for the data. Aside from changing the activity, we also have to choose a new set of data attributes. This necessity requires defining two ways to produce them. We can either choose the features randomly or choose to take a more sophisticated approach.

% \begin{enumerate}
%     \item[RM:] \emph{Random-Mutation} creates entirely random features for inserts and substitution. The activity is just a randomly chosen integer, and each event attribute is drawn from a normal distribution.
%     \item[SBM:] \emph{Sampling-Based-Mutation} creates sampled features based on data distribution for inserts and substitution. We can simplify the approach by invoking the \emph{Markov Assumption} and sample the feature attributes given the activity in question (\emph{Sample-Based-Mutation}).

% \end{enumerate}
% Here, we apply only one of the two operations. However, the extent to which these mutations are applicable can still vary.

% There are still two noteworthy topics to discuss.

% First, these edit types are disputable. One can argue that change and transpose are just restricted versions of delete-insert compositions. For instance, if we want to change the activity \emph{Buy-Order} with \emph{Postpone-Order} at timestep 4, we can first delete \emph{Buy-Order} and insert \emph{Postpone-Order} at the same place. Similar holds for transpositions, albeit more complex. Hence, these operations naturally occur over repeated iterations in an evolutionary algorithm. However, these operations follow the structure of established edit distances like the \gls{damerau_levenshtein}.
% Furthermore, they allow us to restrict their effects efficiently. For instance, we can restrict delete operations to steps that are not padding steps. In contrast, insert operations can be limited to padding steps only.

% Second, we can apply different edit rates for each edit type. However, this adds additional complexity and increases the search space for hyperparameters.

% Third, using the random sampler automatically disrupts the feasibility for most offspring if either of the two conditions is met. First, if the log contains categorical/binary event attributes, Gaussian samples cannot reflect these types of random variables. Second, if the vector space with which event attributes are represented is too large, it becomes less and less likely to sample something within the correct bounds.
% For instance, let us again consider the example on \autoref{alg:my-evolutionary}.
% However, instead of having 3 event attributes, each event had 100. Then, it becomes extremely difficult to randomly sample a set that fits the event attribute vectors.

% \paragraph{Recombination}
% \begin{enumerate}
%     \item[FSR:] \emph{Fittest-Survivor-Recombination} strictly determines the survivors among the mutated offsprings and the current population by sorting them in terms of viability.
%     The operator guarantees that the population size remains the same across all iterations.
%     Nonetheless, this approach is subject to getting stuck in local maxima. This is mainly because this recombination scheme does not allow for the exploration of unfavourable solutions that may evolve into better ones in the long run.
%     \item[BBR:] \emph{Best-of-Breed-Recombination} Determines mutants that are better than the average within their generation and adds them to the population. The operator only removes individuals after the maximum population size is reached. Afterwards, the worst individuals are removed to make way for new individuals.
%     \item[RR:] \emph{Ranked-Recombination} selects the new population differently than the former recombination operators. Instead of using the viability directly, we sort each individuum by every viability component separately. This approach allows us to select individuals regardless of the scales of every individual viability measure. We refer to this method as \emph{Ranked-Recombination}. In our order, we choose to favour feasibility first. Feasibility values are by far the lowest as they are joint probability values that become smaller with every multiplication. Second, we favour delta, then sparsity and at last similarity. Mainly because it is more important to flip the outcome than to change as little as possible, and it is more important to change as little as event attributes as possible than to become more similar to the factual.
% \end{enumerate}

\noindent\textbf{Naming-Conventions}
We use abbreviations to refer to them in figures, tables, appendices, etc. For instance, \emph{CBI-RWS-OPC-RM-RR} refers to an evolutionary operator configuration that samples its initial population from the data, probabilistically samples parents based on their fitness, crosses them on one point and so on. For the \emph{Uniform-Crossing} operator, we additionally indicate its crossing rate using a number. For instance, \emph{CBI-RWS-UC3-RM-RR} is a model using the \emph{Uniform-Crossing} operator. The child receives roughly 30\% of the genome of one parent and 70\% of another parent.

\noindent\textbf{Hyperparameters}
The evolutionary approach comes with a number of hyperparameters. 
We first discuss the \emph{model configuration}. As shown in this section, there are a \NumEvoCombinations ways to combine all operators. Depending on each operator combination, we might see very different behaviours. 
% For instance, it is obvious that initiating the population with a random set of values can hardly converge at the same speed as a model which leverages case examples. Similarly, selecting only the fittest individuals is heavily prone to local optima issues. 
The decision of the appropriate set of operators is by far the most important in terms of convergence speed and result quality.
The next hyperparameter is the \emph{termination point} which determines the duration of the search. 
% Eventually, most correctly implemented evolutionary algorithms will converge to a local optimum. Especially if only the best individuals are allowed to cross over. If we choose the termination point too early, the generated individual most likely underperforms. In contrast, selecting a termination point too far in the future might yield optimal results at the cost of time performance. Furthermore, the existence of local optima may result in very similar solutions in the end. 
Optimally, we find a termination point, which is not too early but not too late, too.
The \emph{mutation rate} is another hyperparameter. It signifies how much a child can differ from its parent.
% Again, choosing a rate that is too low does not explore the space as much as it could. In turn, a mutation rate that is too high significantly reduces the chance to converge. The optimal mutation rate allows for exploring novel solutions without immediately pursuing suboptimal solution spaces. Our case is special, as we have four different mutation rates to consider. The change rate, the insertion rate, the deletion rate and the transposition rate. Naturally, these strongly interact. For instance, if the deletion rate is higher than the insertion rate, there's a high chance that the sequence will be shorter, if not 0, at the end of its iterative cycles. Mainly because we remove more events than we introduce. However, we cannot assume this behaviour across the board as other hyperparameters interplay. Most prominently, the fitness function. Let us assume we have a high insertion rate, but the fitness function rewards shorter sequences. Subsequently, both factors cancel each other out. Hence, the only way to determine the best set of mutation rates requires an extensive search.
\subsection{Baseline Models}
We use three baseline models and compare them to the evolutionary models. The first baseline generates a random sequence of events and event attributes. Hence, we refer to this approach as \textbf{Random baseline}. We expect most models to perform better than this baseline. Otherwise, it would indicate that a random search would generate better counterfactuals than a guided one. The second resembles the random baseline. However, we use the data likelihood to guide the random search for the generation of counterfactuals. We first generate a random seed of possible starting events ($\prob{e_0}$). Afterwards, we randomly sample subsequent events by iteratively sampling new activities according to the transition probabilities we gathered from the data ($\prod_1^T \cprob{e_t}{e_{t-1}}$). Given the sequence, we simply sample the features per event from $\cprob{f_t}{e_t}$. We call this baseline \textbf{Sample-Based}. In contrast to both sampling-based baselines, the last baseline leverages actual examples of the data. We refer to this case-based approach as \textbf{Case-Based baseline}. The idea is to randomly pick traces from the log and evaluate them using the viability measure.

% \subsubsection{Baseline Model: Random Generator}
% % \subfile{content/sections/sec_model_random.tex}
% This model acts as one of the baseline methods. Here, we generate a random sequence of events. Afterwards we generate event attributes, randomly. This approach is reasonably fast, but expected to perform poorly.

% As explained earlier, any possible sequence of events becomes more and more unlikely the longer the sequence is. One generally has a chance of $\frac{\#UniqueTraces}{A^T}$ to randomly find an event sequence, that is the process log. The chances decrease even more if one also generates event attributes randomly. Therefore, we expect most models to perform better that this model. If a model happens to be worse, it would indicate that it is more likely to just randomly pick numbers and get a better counterfactual. 

% \subsubsection{Baseline Model: Sample-Based Generator}
% % \subfile{content/sections/sec_model_samplebased.tex}
% This baseline resembles the random baseline. However, we use the feasibility model to guide the random search for the generation of counterfactuals. We refer to the model specified in \autoref{eq:feasibility_measure}. The sampling procedure utilises the model structure for the sampling process. We first generate a random seed of possible starting events ($\prob{e_0}$). Afterwards, we randomly sample subsequent events by iteratively sampling new activities according to the transition probabilities we gathered from the data ($\prod_1^T \cprob{e_t}{e_{t-1}}$). Given the sequence, we simply sample the features per event from $\cprob{f_t}{e_t}$. 


% \subsubsection{Baseline Model: Case-Based Generator}
% % \subfile{content/sections/sec_model_casebased.tex}
% Case-based techniques leverage the data by using example instances. The idea is to find suitable candidates that best fulfil the counterfactual criteria. We treat this model as a baseline. Therefore, we keep this approach simple. We find candidates by searching by randomly sampling cases from the log and then evaluating them using the viability measure.

% Inherently, this approach is restricted by the \emph{representativeness} of the data. It is not possible to generate counterfactuals that have not been seen before. This method works for cases where the data hold enough information about the process. If this condition is not met, it is impossible to produce suitable candidates.

% Note that this approach will automatically fulfil the criterion of being feasible, as the counterfactuals are drawn from the log directly. Hence, we expect their feasibility to be often higher than other methods.
\subsection{Viability Measure}
\label{sec:viability}

\subsubsection{Feasibility-Measure}
\label{sec:feasibility}
% \subfile{content/sections/sec_viability_feasibility}
To determine the feasibility of a counterfactual trace, it is important to recognise two components. 

First, we have to compute the probability of the sequence of event transitions. This is a difficult task, given the \emph{Open World assumption}. In theory, we cannot know whether or not any event \emph{can} follow after another event. However, if the data is representative of the process dynamics, we can make simplifying assumptions. For instance, we can compute the first-order transition probability by counting each transition. However, the issue remains that longer sequences tend to have a zero probability if they have never been seen in the data. 

Second, we have to compute the feasibility of the individual feature values given the sequence. We can relax the computation of this probability using the \emph{Markov Assumption}. In other words, we assume that each event vector depends on the current activity but none of the previous events and features. Meaning, we can model density estimators for every event and use them to determine the likelihood of a set of features.


\noindent Here, $e_t$ represents the transition from one event state to another. Likewise, $f$ represents the emission of the feature attributes. Hence, the probability of a particular sequence is the product of the transition probability multiplied by the state emission probability for each step. Note that this is the same as the feasibility measure in \autoref{eq:feasibility_measure}. 

\begin{align}
    \prob{e_{0:T},f_{0:T}} & = \prob{e_0}\cprob{f_0}{e_0}\prod_1^T \cprob{e_t}{e_{t-1}} \cprob{f_t}{e_t}
    \label{eq:feasibility_measure}
\end{align}



\subsubsection{Delta-Measure}
\label{sec:delta}
% \subfile{content/sections/sec_viability_delta}
For this measure, we evaluate the likelihood of a counterfactual trace by determining whether a counterfactual leads to the desired outcome or not. For this purpose, we use the predictive model, which returns a prediction for each counterfactual sequence. As we are predicting process outcomes, we typically predict a class. However, forcing a deterministic model to produce a different class prediction is often difficult. Therefore, we can relax the condition by maximising the prediction score of the desired counterfactual outcome\cite{molnar2019}. If we compare the difference between the counterfactual prediction score with the factual prediction score, we can determine an increase or decrease. Ideally, we want to increase the likelihood of the desired outcome. We refer to this value as \emph{delta}. For the binary outcome prediction case we define the function as shown in \autoref{eq:delta}.

\begin{align}
    \label{eq:delta}
%     d_{a, b}(i, j) & =\min
    delta &= 
    \begin{cases}
            |p(o|s^*)-p(o|s)| &  \text{if }  p(o|s) > 0.5 \text { \& }  p(o|s) > p(o|s^*) \\                 
            -|p(o|s^*)-p(o|s)| &  \text{if }  p(o|s) > 0.5 \text { \& }  p(o|s) < p(o|s^*) \\                 
            |p(o|s^*)-p(o|s)| &  \text{if }  p(o|s) < 0.5 \text { \& }  p(o|s) > p(o|s^*) \\                 
            -|p(o|s^*)-p(o|s)| &  \text{if }  p(o|s) < 0.5 \text { \& }  p(o|s) < p(o|s^*) \\                 
    \end{cases} 
\end{align}

\subsubsection{Similarity-Measure}
\label{sec:similarity}
% \subfile{content/sections/sec_viability_similarity}
We use a function to compute the distance between the factual sequence and the counterfactual candidates. To incorporate structural differences, such as the length of both sequences, we use a weighted version of Damerau-Levenshstein distance\cite{damerau_TechniqueComputerDetection_1964}. Concretely, we formulate the modified \gls{damerau_levenshtein} as shown in \autoref{eq:modified_dl}. For the remainder, we refer to this edit-distance as \gls{SSDLD}.

\begin{align}
    \label{eq:modified_dl}
    d_{a, b}(i, j) & =\min
    \begin{cases}
        \editDistance{i-1}{j  }+\editCostFunctionNoA & \text { if } i>0                                            \\
        \editDistance{i  }{j-1}+\editCostFunctionNoB & \text { if } j>0                                            \\
        \editDistance{i-1}{j-1}+\editCostFunctionBoth & \text { if } i, j>0   \\ & \text { \& } \overline{a}_i=\overline{b}_j                                       \\
        \editDistance{i-1}{j-1}+ \editCostFunctionNoB +\editCostFunctionNoA  & \text { if } i, j>0  \\ & \text { \& } \overline{a}_i \neq \overline{b}_j                                       \\
        \editDistance{i-2}{j-2}+\editCostFunction{a_i}{b_{j-1}} + \editCostFunction{a_{i-1}}{b_j} & \text { if } i, j>1 \\ 
        & \text { \& } \overline{a}_i=\overline{b}_{j-1} \\ 
        & \text { \& } \overline{a}_{i-1}=\overline{b}_j \\
        0                                 & \text { \& } i=j=0                                          
    \end{cases} 
\end{align}

\noindent Here, $d_{a, b}(i, j)$ is the recursive form of the Damerau-Levenshtein-Distance. $a$ and $b$ are sequences and $i$ and $j$ specific elements of the sequence. $cost(a,b)$ is a cost function which takes the attribute values of $a$ and $b$ into account. 

% OLU: Add a reference to the thesis

For similarity, a low distance corresponds to a small change. Henceforth, we use the previously established. As a cost function we use the euclidean distance.

\subsubsection{Sparsity-Measure}
\label{sec:sparcity}
% \subfile{content/sections/sec_viability_sparsity}
Sparsity refers to the number of changes between the factual and counterfactual sequence. We typically want to minimize the number of changes. As with similarity, we incorporate structural differences between the two sequences by using the previously established \gls{SSDLD}. However, instead of using the euclidian distance, we simply count the differences between the event attributes.


\section{Evaluation}
\label{ch:evaluation}
% In this section, we discuss the datasets, the preprocessing pipeline, and the final representation for each of the algorithms.  
% There, you will find instructions on how to install and run the experiments yourself.


\subsection{Datasets}
\label{sec:dataset_description}
% \subfile{content/sections/sec_dataset_stats}
% XIXI: Reference the dataset for outcome prediction and say we used this publically available benchmark datasets
In this paper, we use ten event logs of three real-life processes, also used in~\cite{teinemaa_OutcomeOrientedPredictiveProcess_2019}. Each dataset consists of events and contains labels that signify a process instance's outcome. We focus on binary outcome predictions. 
We include a variation of the BPIC dataset. It is the dataset which was used by \cite{hsieh_DiCE4ELInterpretingProcess_2021}. The difference between this dataset and the original dataset is two-fold. First, \cite{hsieh_DiCE4ELInterpretingProcess_2021} omit most variables except two. Second, it is primarily designed for next-activity prediction and not outcome prediction. We modified the dataset to fit the outcome prediction model.
%
For more information about these datasets we refer to the comparative study by \cite{teinemaa_OutcomeOrientedPredictiveProcess_2019}. We list all the important descriptive statistics in \autoref{tbl:dataset-stats}.

% \begin{enumerate}
%     \item[BPIC12:] The first dataset is the popular BPIC12 dataset. This dataset was originally published for the Business Process Intelligence Conference and contains events for a loan application process. Each case relates to one loan application process and can be accepted (regular) or cancelled (deviant).
%     \item[Sepsis:] The next dataset is the Sepsis-Dataset. It is a medical dataset that records patients with life-threatening sepsis conditions. The outcome describes whether the patient returns to the emergency room within 28 days from initial discharge.
%     \item[TrafficFines:] Third, we apply our approach to the Traffic-Fines-Dataset. This dataset contains events related to notifications sent related to a fine. The dataset originates in a log from an Italian local police force.
%     \item[DiCE4EL:] Lastly, we include a variation of the BPIC dataset. It is the dataset which was used by \cite{hsieh_DiCE4ELInterpretingProcess_2021}. The difference between this dataset and the original dataset is two-fold. First, \cite{hsieh_DiCE4ELInterpretingProcess_2021} omit most variables except two. Second, it is primarily designed for next-activity prediction and not outcome prediction. We modified the dataset to fit the outcome prediction model.
% \end{enumerate}

\begin{table}[t]
    % \begin{adjustbox}{center}
        \makebox[\linewidth]{
            \input{./tables/generated/dataset_stats.tex}
            }
            % \end{adjustbox}
            \caption{All datasets used within the evaluation. DiCE4EL is used for the qualitative evaluation, and the remaining are used for quantitative evaluation purposes.}
            \label{tbl:dataset-stats}
\end{table}


% \subfile{content/sections/sec_dataset_preds}
\begin{table}[b]
    % \begin{adjustbox}{center}
        \makebox[\linewidth]{
            \input{./tables/generated/dataset-preds.tex}
            }
            % \end{adjustbox}
            \caption{The evaluation metrics for the prediction component on all datasets. Includes precision, recall and f1 score for test, training and validation data.}
            \label{tbl:dataset-preds}
\end{table}

We list the predictions of our prediction component in \autoref{tbl:dataset-preds}. The F1-Scores on the test sets are generally higher for the BPIC dataset. Furthermore, in the case of the BPIC datasets, the length of the dataset determines whether the prediction model always predicts correctly or not. It is fair to assume that the length of a loan application process determines the chance of getting rejected or not. 



\subsection{Preprocessing}
\label{sec:preprocessing}
% \subfile{content/sections/sec_dataset_preprocessing}
% XIXI: Remove parts that are extremely typical for this type of work (data-split)
% XIXI: The issue of using maximum 25 seq-len is a limitation that should be discussed again.
To prepare the data for our experiments, we employed basic tactics for preprocessing. First, we split the log into a training and a test set. 
% The test set will act as our primary source for evaluating factuals entirely unknown to the model. We split the training set into a training set and a validation set. This procedure is a common tactic to employ model selection techniques. In other words, Each dataset is split into 25\% Test and 75 remaining, and from the remaining, we take 25\% validation and 75\% training data.
Then, we filter out every case whose' sequence length exceeds 25. We keep this maximum threshold for most experiments focusing on the evolutionary algorithm. The reason is the polynomial computation time of the viability measure. The similarity and sparsity components of the proposed viability measure have a run time complexity of at least $N^2$. Hence, limiting the sequence length saves a substantial amount of temporal resources.
Next, we extract time variables if they are provided in the log. Then, we normalise the values. 
% For a time format, we encode all information from seconds to a year. If the complete log occurs within one time unit only, e.g. every event that happened within a year, drop the extracted column—afterwards, we standard scale all remaining time features.
Each categorical variable is converted using binary encoding. 
% Binary encoding is very similar to one-hot encoding. However, it is still distinct. The binary encoding uses a binary representation for each class encoded. % This representation saves a lot of space as binary encoded variables are less sparse than one-hot encoded variables.
% We also add an offset of 1 to binary and categorical columns to introduce a symbol which represents padding in the sequence. All numerical columns have a zero mean and a standard deviation of 1.
% We omit the case id, the activity and the label column from this preprocessing procedure for reasons explained in \autoref{sec:representation}. 
The activity is label-encoded. Hence, every category is assigned to a unique integer. The label column is binary encoded, as we focus on outcome prediction.
Lastly, we pad each sequence towards the longest sequence in the dataset.


\subsection{Experimental Setup}
\label{sec:experimental_setup}
% \subfile{content/sections/sec_experimental_setup}
% Counterfactual generation is notorious for lacking a standardised evaluation procedure. Nonetheless, we try to address our research questions with the following experiments. 
All the experiments were run on a Windows machine with 12 processor cores (Intel Core i7-9750H CPU 2.60GHz) and 32 GB Ram. The main programming language was python. 
The models were mostly developed with Tensorflow~\cite{abadi2016tensorflow} and NumPy~\cite{2020NumPy-Array}. 
We provide the full code and instructions on Github~\cite{hundogan_ThesisProjectCode_2022}.

\textbf{Experiment 1: Model Selection}
The first set of simulations is dedicated to choosing among a subset of operator combinations and selecting appropriate hyperparameters. 
First, we reduce the number of models that we compare against the baseline approaches in later experiments. In terms of operators, we introduced three initiators, three selectors, three crossers, two mutators and three recombiners. Hence, we compare all \NumEvoCombinations evolutionary operator combinations. We compute all possible configurations without changing any hyperparameter.
% We refer to each unique operator combination as a model configuration to avoid confusion. 
% For instance, one model configuration would consist of \emph{a Sampling-Based-Initiator, an Elitism-Selector, a One-Point-Crosser, Sampling-Based-Mutator and a Fittest-Survivor-Recombiner}. For the sake of brevity, we refer to a specific model configuration in terms of its abbreviated operators. For instance, the earlier example is denoted as \emph{SBI-ES-OPC-SBM-FSR}.
% Afterwards, we explore the hyperparameters of the model.
% We start with the termination point. This will inform us of a stopping criterion which yields reasonably good counterfactuals while reducing the computation time. We will only consider the number of iterative cycles as a stopping criterion. 
% We refer to each different criterion as a termination point. 
% Hence, a termination point at 5 means the algorithm will not proceed to optimise its results further after reaching the fifth iteration. 
% We can choose the termination point by inspecting how the average population viability evolves across each cycle. 
% We keep every other experimental setting as established beforehand.
% \optional{We determine an appropriate number of individuals we generate in every iterative cycle and population size. We test both together, as they are dependent on each other. We keep every other experimental setting as before and only experiment on the model configurations selected prior. We aim to find the optimal ratio between children generated and population size.}
% For determining the mutation rate, we choose the best evolutionary algorithms and run the configuration with six rates from 0 to 0.5 in steps of 0.1. We omit everything beyond 0.5 to preserve information about the parent. 
% For instance, if we use a change rate of 0.9, we mutate 90\% of the genes the child inherited. This would defeat the purpose of evolving better counterfactuals through breeding. 
% We use the termination point established in the prior experiment. We keep every other experimental setting as set beforehand. 
After executing all preliminary simulations, we choose the best evolutionary generators and compare them with all baseline models in all subsequent experiments.






\textbf{Experiment 2: Comparing with Baseline Generators}
In this experiment, we assess the viability of all the chosen evolutionary and baseline generators. We sample 10 factuals and use the models and baselines to generate 50 counterfactuals. We determine the median viability across the counterfactuals. 
% With this experiment, we show that a model that optimises counterfactual quality criteria produces better results than models that do not. 
% Hence, we expect the evolutionary algorithm to perform best, as it can directly optimise multiple viability criteria. We move on with the best-performing models.
\noindent We expect the evolutionary algorithms to outperform the baselines when it comes to viability.


% XIXI?: Throw out?
% \subsubsection{Experiment 3: Comparing with alternative Literature}
% % The model comparison is not enough to establish the validity of our solution, as we defined the viability measure ourselves. Therefore, 
% We also assess each model based on the evaluation criteria of an alternative work. More precisely, we quantify the viability of our models using the metrics employed by \cite{hsieh_DiCE4ELInterpretingProcess_2021}. Hence, we measure the sparsity by computing the average Levenshstein difference and proximity using the L2-Norm. Furthermore, we compute the average intra-list-diversity and plausibility. % and the model's capability of changing the prediction to a desired one. 
% % Similar to \cite{hsieh_DiCE4ELInterpretingProcess_2021}, we focus on the \emph{activities} that are generated by each model and its accompanying \emph{resource} event-attribute. For diversity and plausibility, we remain close to the original evaluation protocol by \cite{hsieh_DiCE4ELInterpretingProcess_2021} as we also treat each counterfactual trace sequence as a symbol. Hence, a sequence \emph{ABC} is treated as a completely different symbol than \emph{ABCD}.
% The goal is to show that models, which optimise viability criteria, perform better, even if viability is assessed differently, as stated in \emph{RQ2-H1} of our research question (\autoref{sec:rq}). 

\textbf{Experiment 3: Qualitative Assessment}
For the last assessment, we follow \cite{hsieh_DiCE4ELInterpretingProcess_2021}'s procedure of assessing the models qualitatively. We use the dataset as the authors do. However, as we focus on outcome prediction, we attempt to answer one of two questions. First, \emph{what would I have had to change to prevent the cancellation/rejection of the loan application process}. Second, \emph{what would I have had to change to cause a cancelled/rejected loan application process}.
The goal is to show that the results are viable despite not having a standardised protocol to measure their viability.



\section{Results}
\label{ch:results}
% This section presents the results of each evaluation step. Furthermore, we analyse the results.


\subsection{Experiment 1: Model Selection}
\label{sec:experiment1}
% \subfile{content/sections/sec_experiment_1_configuration_results}
% \subsubsection{Model Configuration}
% \label{sec:exp1}
% As there are many ways to combine each configuration, we select a few configurations by examining them through simulations.  

We examined a set of model-configurations containing \NumEvoCombinations elements. 
We choose to run each model configuration for 100 evolution cycles. 
For all model configurations, we use the same four factual \glspl{instance} randomly sampled from the test set. We ensure that the outcomes of these factuals are evenly divided. 
We decide to limit the population size to a maximum of 1000 counterfactuals. Within each evolutionary cycle, we generate 100 new offsprings. We keep the mutation rate at 0.01 for each mutation type. Hence, across all cases that are mutated, the algorithm deletes, inserts, and changes 1\% of events per cycle. We collect the mean viability and its components across the iterative cycles of the model.
\autoref{fig:average-viability} shows the bottom and top-5 model configurations based on the viability after the final iterative cycle. We also show how the viability evolves for each iteration. 
% The results reveal a couple of patterns. 
% First, all top-5 algorithms use either \optional{Case-Based-Initiator} as initiation operation. In contrast, the bottom-5 use \optional{Random-Initiator} as initialisation. Hence, the initialisation appears to be majorly important for the algorithm.
% The complete table of results is in \autoref{app:avg-viability}.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.65\textwidth]{figures/generated/exp1_effect_on_viability_top10_last10.png}
    \caption{This figure shows the average viability of the five best and worst model configurations. The x-axis shows how the viability evolves for each evolutionary cycle.}
    \label{fig:average-viability}
\end{figure}

According to \autoref{fig:average-viability}, \emph{CBI-ES-UC3-SBM-RR}, \emph{CBI-RWS-OPC-SBM-BBR}, and \emph{CBI-RWS-OPC-SBM-FSR} are the best model configurations. For the next experiment we run each evolutionary algorithm for 200 iterative cycles and set the mutation rate to 0.01.  



\subsection{Experiment 2: Comparing with Baseline Generators}
\label{sec:experiment2}
% In this section we examine the results of each model's average viability across all datasets. 
% \subsubsection{Results}
% \subfile{content/sections/sec_experiment_4}
In this comparison, we employ the baseline models mentioned in \autoref{sec:model_generation} and examine their results across all datasets. 
% Namely, we compare the \emph{Case-Based Generator}, the \emph{Sample-Based Generator} and the \emph{Random Generator}. 
We randomly sample \optional{20} factuals from the test set and use the same factuals for every generator. We ensure that the outcomes are evenly divided. The remaining procedure follows the established practice of previous experiments. 


\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.75\textwidth]{figures/generated/exp4_winner_overall_mod.png}
    \caption{This figure shows boxplots of the viability of each model's generated counterfactual.}
    \label{fig:exp4-winner}
\end{figure}
The results shown in \autoref{fig:exp4-winner} show that the evolutionary algorithm \optional{CBI-ES-UC3-SBM-RR} slightly returns better results when it comes to the median viability. The worst model is the randomly generated model. 
The Case-Based model appears to be evenly and normally distributed at a viability of \optional{2.25}. The \optional{CBI-RWS-OPC-SBM-FSR} has outliers that far exceed and underperform against other evolutionary algorithms on both ends.  
% \autoref{fig:exp4-winner} also displays the vast difference in computation time for the evolutionary algorithms. Only the model using the \optional{Ranking-Recombination} seems slightly faster than the ones using \optional{Best-Breed} and \optional{Fittest-Survivor} as recombination methods.
% \autoref{tbl:exp4-winner} shows the detailed results.
% \begin{table}
%     \caption{The result of Experiment 2. The names indicate the model configurations that were examined. The results are based on the average viability over each counterfactual a model produces across all factuals that were tested.}
%     \label{tbl:exp4-winner}
% \makebox[\linewidth]{
% \input{./tables/generated/exp4_winner_overall.tex}
% }
% \end{table}
% \subfile{content/sections/sec_experiment_5}
\autoref{fig:exp5-winner} displays the results of running each algorithm on a set of different datasets. The figure shows a clear dominance of the evolutionary models across all datasets. 
Here, \emph{CBI-ES-UC3-SBM-RR} and \emph{CBI-RWS-OPC-SBM-FSR} display a higher median of viability across all datasets. 
This is unsurprising as the evolutionary algorithm uses initiators based on the baselines. 
However, it is surprising that the evolutionary models consistently outperform the \ModelCBG (green) across all datasets. In 6 out of 9 datasets, we see an improvement of at least 0.15. 
% From \autoref{app:exp5-winner-datasets} we see that the gap often occurs because of much higher similarity and sparsity scores. 
The highest median is reached for \emph{CBI-RWS-OPC-SBM-FSR} at 2.94. 
The \ModelRNG never manages to come even close to the case-based model. Except for the BPIC12-100 dataset, the \ModelRNG has a median below 2. 

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{figures/generated/exp5_winner_overall.png}
    \caption{Boxplots of the viability of each model's generated counterfactuals across a heterogeneous collection of datasets.}
    \label{fig:exp5-winner}
\end{figure}


% \begin{table}
%     \centering    
%     \resizebox{\linewidth}{!}{
%     \input{./tables/counterfactuals/CBG-CBGW-IM-49-4.tex}}
%     \caption{A comparison between the \ModelCBG and D4EL}
%     \label{tbl:cf-cbg}
% \end{table}
% \begin{table}
%     \centering    
%     \resizebox{\linewidth}{!}{
%         \input{./tables/counterfactuals/ES-EGW-CBI-ES-UC3-SBM-RR-IM-49-4.tex}}
%         \caption{A comparison between the CBI-ES-UC3-SBM-RR and D4EL}
%         \label{tbl:cf-rr}
% \end{table}
% \begin{table}
%     \centering    
%     \resizebox{\linewidth}{!}{
%     \input{./tables/counterfactuals/ES-EGW-CBI-RWS-OPC-SBM-FSR-IM-49-4.tex}}
%     \caption{A comparison between the CBI-RWS-OPC-SBM-FSR and D4EL}
%     \label{tbl:cf-fsr}
% \end{table}
% \begin{table}
%     \centering    
%     \resizebox{\linewidth}{!}{
%     \input{./tables/counterfactuals/RG-RGW-IM-49-4.tex}}
%     \caption{A comparison between the \ModelRNG and D4EL}
%     \label{tbl:cf-rng}
% \end{table}

% In tables \ref{tbl:cf-cbg}, \ref{tbl:cf-rr}, \ref{tbl:cf-fsr} and \ref{tbl:cf-rng} we show generations of all models and compare them to DiCE4EL. We see that all models return reasonable counterfactuals, except the \ModelRNG. This model does not seem to follow any pattern.  


% \subsubsection{Analysis}
% \subfile{content/sections/sec_experiment_5_analysis}
The results for \autoref{fig:exp5-winner} show that both evolutionary algorithms outperform the competition across all datasets and against all baselines. The fact that sparsity and similarity are the main drivers for this consistent improvement indicates a higher structural alignment between counterfactual and factual. 
This remarkable result shows that the algorithm can outperform baselines regardless of the process log and its length.
% The underperformance of the random model was expected. In \autoref{sec:viability}, we indicated that viable algorithms must at least reach a viability of 2. 
% Furthermore, we expected the search space for the \ModelRNG is too vast to find viable results. 
% The fact that 8 of 9 datasets showed that the random model cannot exceed the threshold of two supports this claim. Additional support is the observation that every \ModelCBG reaches at least 2.

% XIXI?: Throw out?
% \subsection{Experiment 3: Evaluation under a different Viability Measure}
% \label{sec:experiment3}
% \subsubsection{Results}
% % \subfile{content/sections/sec_experiment_6}
% \begin{table}
%     \centering    
%     \resizebox{\linewidth}{!}{
%         \input{./tables/counterfactuals/exp6-tbl.tex}
        
%     }
% \caption{A comparison between our model and D4EL}
% \label{tbl-exp6}
% \end{table}

% \autoref{tbl-exp6} shows how each model performs under the evaluation metrics chosen by \cite{hsieh_DiCE4ELInterpretingProcess_2021}. All of them apply separately to the sequence of resources and the sequence of activities. Each evaluation metric is the mean across all counterfactual results per model.

% First, plausibility measures whether the sequence of activities or resources was found in the data—next, proximity is the normalised euclidian similarity between two sequences. The third is sparsity, computed using the normalised Levenshtein similarity. 

% We see that the evolutionary models are often comparable and sometimes even better than the DiCE4EL solution by \cite{hsieh_DiCE4ELInterpretingProcess_2021}. We see that, for instance, for proximity. If the proximity of our model is lower than the proximity of the DiCE4EL solution, we can say that our models are, on average, closer to the factual. Similar holds for sparsity. We see this behaviour for both evolutionary generators. However, the \ModelCBG also displays better proximity and sparsity scores than DiCE4EL. Only the \ModelRNG appears to show worse results. 


% \subsubsection{Analysis}
% % \subfile{content/sections/sec_experiment_6_analysis}
% Based on these results, we can see that our model does seem to optimize properly under our viability function. If we compare our results with a different set of results, we see they often compare or even outperform the alternative solution. 
% Unsurprisingly, the \ModelCBG achieves the highest plausibility as all the counterfactuals were drawn from the data. 

\subsection{Experiment 3: Qualitative Assessment}
\label{sec:experiment4}
% \subsubsection{Results}
% \subfile{content/sections/sec_experiment_7}
\autoref{fig:exp7-FSR} shows the generation of the model-configuration \optional{CBI-RWS-OPC-SBM-FSR} and the model of \cite{hsieh_DiCE4ELInterpretingProcess_2021}. Both models also return reasonable counterfactuals. The counterfactual sequence of events of both approaches are almost identical. However, in contrast to \cite{hsieh_DiCE4ELInterpretingProcess_2021}, we did not require the use of any domain specific knowledge. 

% However, \optional{CBI-ES-UC3-SBM-RR} appears to be more consistent with the counterpart of \cite{hsieh_DiCE4ELInterpretingProcess_2021}. Especially in terms of the activity sequence. 
For instance, our counterfactual and the D4EL counterfactual recognize that after O-SENT, there appears at least one \emph{W-Completeren aanvraag} and one \emph{W-Nabellen offertes} that eventually leads to an acceptance of the counterfactual.
% Both generate the latter activity correctly aligned with the factual. 
We also see that both evolutionary algorithms start the process with the correct sequence of A-SUBMITTED, A-PARTLYSUBMITTED and A-PREACCEPTED. These are strictly the same across all cases. If our generative model had not recognised these, one could question its utility.

% \begin{table}[t]
%     \centering    
%     \resizebox{\linewidth}{!}{
%     \input{./tables/counterfactuals/ES-EGW-CBI-ES-UC3-SBM-RR-IM-49-2.tex}
%     }
%     \caption{A comparison between the CBI-ES-UC3-SBM-RR and D4EL}
%     \label{fig:exp7-RR}
% \end{table}
\begin{table}[b]
    \centering    
    \resizebox{\linewidth}{!}{
    \input{./tables/counterfactuals/ES-EGW-CBI-RWS-OPC-SBM-FSR-IM-49-2.tex}
    }
\caption{A comparison between the CBI-RWS-OPC-SBM-FSR and D4EL}
\label{fig:exp7-FSR}
\end{table}

% Furthermore, our model appears to be much closer in terms of sequences than the model by \cite{hsieh_DiCE4ELInterpretingProcess_2021}. \optional{CBI-RWS-OPC-SBM-FSR} (the model that only chooses the fittest survivors) has gaps. These gaps indicate that the model also attempts to align toward the correct structure of the factual model. We do not see that in \optional{CBI-ES-UC3-SBM-RR}, as it ranks feasibility above similarity and sparsity. The introduction of gaps in the sequence automatically reduces the feasibility of the model. 
% We also see that the value for \emph{Amount} fluctuates for the evolutionary generators. Similar holds for the resource field. The model focuses on event structure first and event attributes second. This might be seen as a limiting factor when it comes to event attributes. However, one could argue that the most revealing information the counterfactuals provide for sequences is within the sequence structure and less the event attributes. 
% \subsubsection{Analysis}
% \subfile{content/sections/sec_experiment_7_analysis}
% The models did not create counterfactuals that are much shorter than their factual counterparts. 
% In fact, most of \cite{hsieh_DiCE4ELInterpretingProcess_2021}'s counterfactuals are shorter in length. This characteristic can be an advantage for use cases, such as medicine. 
% The fluctuations in the loan amount were expected, as well. We did not implement any safeguard option to keep certain attributes fixed. 
% The values our generative models produce are more or less an indication of what the prediction model deems as a useful change to turn over the outcome at a specific step in the process. 
% All models manage to capture the first few activities. 
All models successfully flip the outcome of the prediction model and are surprisingly close to the factual. In contrast, the model by \cite{hsieh_DiCE4ELInterpretingProcess_2021} does propose a number of changes to the sequence. However, we must remember that these observations tell us more about the prediction model than the true process. More specifically, our generative model shows which events and attributes have to be present or not present to flip the outcome of the prediction model. 
   

All in all, we claim that the generator model can teach us more about the prediction model primarily. Further improvement might show even more nuance in the model's behaviour. We discuss some of them in the discussion chapter.

\section{Discussion}
\label{ch:discussion}
% In this chapter, we are going to reexamine many of the past decisions we made. We critically assess the results of experiments and how we interpret them. We also propose possible improvements and opportunities for future research.

\subsection{Interpretation of Results}
% \subfile{content/sections/sec_discussion_interpretation}
In the following, we discuss the results along three aspects. First, the quality in terms of the viability of the counterfactual sequences generated by our models. Second, their quality compared to two baseline approaches and the state-of-the-art DICE4EL approach. Third, their implications in terms of the general utility of our solution.

% \begin{enumerate}
%     \item The quality in terms of the viability of the counterfactual sequences generated by our models.
%     \item Their quality compared to two baseline approaches and the state-of-the-art DICE4EL approach.
%     \item Their implications in terms of the general utility of our solution.
% \end{enumerate}

Our first two experiments show that we can optimise towards viability successfully. We defined four criteria for the viability of counterfactuals (similarity, sparsity, feasibility, and delta in likelihood) and showed that a model optimising towards those criteria can return superior results. Furthermore, we created models capable of optimising complicated operationalisations of these criteria without the limitation of a function with a clearly defined gradient. 

% We highlight how it is possible to modify the counterfactual generation based on the decision criterion someone uses to optimise them. Specifically, the model that selected iteration survivors based on an explicit sorted ranking created more feasible results. Those results reflected patterns within our log far more than the model that exclusively focused on improving the viability measure. In contrast, this model showed that structure can play a crucial role in understanding why a counterfactual might change the outcome of a process. 

Based on the results, we have seen in the latter experiments that we can confidently say the models can generate viable counterfactuals. Compared to other methods in the literature, we show that our counterfactuals attempt to be closer to the factual we desire to understand. We have to note that these counterfactuals are primarily a reflection of the underlying prediction model. One might argue that this does not translate to a real-world scenario. 
% However, a model never truly does. 
If our framework attempts to explain how a prediction model behaves, then its applicability to real-world scenarios depends on that model's viability. But regardless of the prediction model's performance, we can clearly gain an understanding of its internal reasoning pattern.

The viability measure we proposed shows that structural difference can help us better understand when and where we must apply counterfactual changes. Other approaches often seem to overlook the importance of the sequence structure. However, the \optional{CBI-RWS-OPC-SBM-FSR} model shows that it may be reasonable to incorporate structural differences in our viability measures. Especially, if we talk about sequences and processes. The gaps within the counterfactuals our models produced clearly indicate that. If a model attempts to align sequences, it becomes much easier to compare them side-by-side.  

In contrast to the closest alternative approach by Hsieh et al.~\cite{hsieh_DiCE4ELInterpretingProcess_2021}, we show that we can create these counterfactuals without incorporating domain-specific knowledge such as an understanding of milestone patterns. Domain knowledge can always help us create better solutions. However, we do not always have access to them. We believe that showing it is possible to create viable counterfactuals without domain-specific knowledge is our most significant contribution. Furthermore, our models can generate solutions not currently present within the data. Case-based solutions often overlook this aspect, as they are heavily biased towards the data input. Second, they can fail to deliver the necessary structural nuance when understanding sequences.


\subsection{Limitations}
% \subfile{content/sections/sec_discussion_limitations}
There were also several limitations to our approach. We begin with the most obvious flaw. The generation of counterfactuals is always hard to gauge when it comes to their usefulness. There is no standardised way to evaluate the viability of a counterfactual. In fact, this is still an open research question\cite{hsieh_DiCE4ELInterpretingProcess_2021,mothilal_ExplainingMachineLearning_2020}. Therefore, we often have to evaluate the counterfactuals in some subjective and qualitative way. In this paper, we decided to compare the counterfactuals with another approach in the literature and the factual themselves. Because our counterfactuals did not produce nonsensical results, we deemed them viable. A domain expert might strongly disagree. Therefore, we advise also to incorporate experts to evaluate such an approach. The lack of domain expertise is a clear limitation of our approach, and we must acknowledge it. 

Next, we introduced a novel way to measure the viability of a multivariate sequence. However, we did not compare its result to other approaches in the literature. Mainly because very few researchers have touched upon this topic. This lack of good multivariate sequence distances needs to be explored further. However, our viability measure does introduce new ideas to this sphere of research. Mainly the idea of incorporating structure. We believe that this might benefit disciplines such as \emph{Process Mining} the most. 

The viability components we chose showed they can lead to an optimised solution, but there are most likely better ways to operationalise viability criteria. However, what makes an excellent counterfactual and how we can quantify that is still a subject of debate. Many researchers fall back on defining their custom evaluation methods. However, we believe a good approach is a direct and qualitative comparison between two different approaches.
Furthermore, we did not take diversity into account. Our models strictly optimize towards the optimization goal. However, as we discussed, diversity can help us better understand factuals.

% When it comes to the evolutionary algorithm, we have to admit that there are most likely more advanced and more efficient algorithms that utilise the notion of evolution. Our approach mainly followed the basic structure of an evolutionary algorithm. However, there are methods such as CMA-ES capable of improving the efficiency of the evolutionary generation. 


% \noindent \textbf{Future Work.}
% % \subfile{content/sections/sec_discussion_improvements}
% There are several improvements we propose. First, the feasibility metric often resulted in far lower values than other metrics. The small probabilities we saw are emblematic of the probabilistic sphere. However, it would undoubtedly help to find ways to operationalise feasibility and make it comparable to other viability components. Our ranking-based method showed that it is possible to overcome this issue. However, a less opinionated solution would be more beneficial. 

% Furthermore, we would like to stress that our approach is only as good as the prediction model it attempts to explain. To gain further insights into \emph{true} process models, one must make sure that the prediction model accurately reflects the real world. Again, a domain expert might help to deduce which model is the best reflection of natural phenomena.

% % \subsection{}
% % \subfile{content/sections/sec_discussion_future}
% Regarding future directions, it is worth pointing out whether employing other components of the viability structure is beneficial. The measure described here clearly operationalised a set of criteria. However, there may be more aspects to consider and generate even better counterfactuals. A good example would be diversity. In terms of other evolutionary approaches, applying modern state-of-the-art methods with the same viability measure would be interesting.



\section{Conclusion}
\label{ch:conclusion}
% \subfile{content/sections/sec_conclusion}
In this paper, we proposed an evolutionary algorithm to generate counterfactual sequences. In addition, we adapted the well-established viability measures (i.e., sparsity, similarly, feasibility, delta) to assess the counterfactual sequences when compared to a factual sequence. The evaluation shows the evolutionary algorithms allow us to generate better counterfactual sequences that are unseen in the input data.
% We showed it is possible to use a viability measure and incorporate structural differences. We can also use an evolutionary algorithm to optimise this viability measure. 
% Concerning RQ1\footnotemark[1], we can design a \Gls{SSDLD} that can compute distances even if the semi-structured data is multivariate. We employ an evolutionary model to achieve this goal in Experiment 1 (\autoref{sec:experiment1}).
% For RQ2\footnotemark[2], we see the extent to which our counterfactuals fulfill viability. 
% We show that by conducting Experiment 2 (\autoref{sec:experiment2}), which confirms the hypothesis that our models outperform both random-based (RQ1-H1) and case-based approaches (RQ1-H2). 
% For RQ3\footnotemark[3], we showed that our counterfactuals are viable. 
% We confirm that in Experiment 3 (\autoref{sec:experiment4}). 
% XIXI: Throw out?
% and Experiment 4 (\autoref{sec:experiment4}).
The qualitative evaluation show that our counterfactuals are not only comparable to existing work in the literature but also align with factual to make both more comparable.
%
% To summarize, we answered all research questions and confirmed all hypotheses. Domain experts can still contest the viability of the counterfactuals. However, we believe that 
Moreover, the generated counterfactuals can be used to explain the model we attempt to understand. Therefore, they provide a valid and transparent reflection of a particular model. 
% Furthermore, we show it is worth pursuing more research and insights into the counterfactual generation of processes. 
% Examples within this paper showed that processes are a ubiquitous part of our life. Many things can be understood as a process. Hence, shying away from complicated problems like multivariate sequence problems heavily limits our progress and understanding of the cause and effect relations within our daily lives. 



% \subfile{content/sections/sec_discussion_improvements}
In future work, we aim to investigate the feasibility metric. The current feasibility metric tends to return lower values than other metrics and is very sensitive to trace length. Recent development in stochastic process models may be an interesting direction to explore. Furthermore, we would like to extend the approach and viability to better assess both case- and event-attributes. 

% The small probabilities we saw are emblematic of the probabilistic sphere. However, it would undoubtedly help to find ways to operationalise feasibility and make it comparable to other viability components. Our ranking-based method showed that it is possible to overcome this issue. However, a less opinionated solution would be more beneficial. 

% Furthermore, we would like to stress that our approach is only as good as the prediction model it attempts to explain. To gain further insights into \emph{true} process models, one must make sure that the prediction model accurately reflects the real world. Again, a domain expert might help to deduce which model is the best reflection of natural phenomena.

% \subsection{}
% \subfile{content/sections/sec_discussion_future}
% Regarding future directions, it is worth pointing out whether employing other components of the viability structure is beneficial. The measure described here clearly operationalised a set of criteria. However, there may be more aspects to consider and generate even better counterfactuals. A good example would be diversity. In terms of other evolutionary approaches, applying modern state-of-the-art methods with the same viability measure would be interesting.


% \footnotetext[1]{How can we employ existing methods to compute viability so that its optimization incorporates information about the structure of the sequence?}
% \footnotetext[2]{To what extent can we generate counterfactuals that fulfill the criteria to be viable?}
% \footnotetext[3]{How does an algorithm which optimizes multiple viability quality metrics perform against other approaches?}


% \section{First Section}
% \subsection{A Subsection Sample}
% Please note that the first paragraph of a section or subsection is
% not indented. The first paragraph that follows a table, figure,
% equation etc. does not need an indent, either.

% Subsequent paragraphs, however, are indented.

% \subsubsection{Sample Heading (Third Level)} Only two levels of
% headings should be numbered. Lower level headings remain unnumbered;
% they are formatted as run-in headings.

% \paragraph{Sample Heading (Fourth Level)}
% The contribution should contain no more than four levels of
% headings. Table~\ref{tab1} gives a summary of all heading levels.

% \begin{table}
% \caption{Table captions should be placed above the
% tables.}\label{tab1}
% \begin{tabular}{|l|l|l|}
% \hline
% Heading level &  Example & Font size and style\\
% \hline
% Title (centered) &  {\Large\bfseries Lecture Notes} & 14 point, bold\\
% 1st-level heading &  {\large\bfseries 1 Introduction} & 12 point, bold\\
% 2nd-level heading & {\bfseries 2.1 Printing Area} & 10 point, bold\\
% 3rd-level heading & {\bfseries Run-in Heading in Bold.} Text follows & 10 point, bold\\
% 4th-level heading & {\itshape Lowest Level Heading.} Text follows & 10 point, italic\\
% \hline
% \end{tabular}
% \end{table}


% \noindent Displayed equations are centered and set on a separate
% line.
% \begin{equation}
% x + y = z
% \end{equation}
% % Please try to avoid rasterized images for line-art diagrams and schemas. Whenever possible, use vector graphics instead (see Fig.~\ref{fig1}).

% \begin{figure}
% % \includegraphics[width=\textwidth]{fig1.eps}
% % \caption{A figure caption is always placed below the illustration. Please note that short captions are centered, while long ones are justified by the macro package automatically.} \label{fig1} 
% \end{figure}

% \begin{theorem}
% This is a sample theorem. The run-in heading is set in bold, while
% the following text appears in italics. Definitions, lemmas,
% propositions, and corollaries are styled the same way.
% \end{theorem}
% %
% % the environments 'definition', 'lemma', 'proposition', 'corollary',
% % 'remark', and 'example' are defined in the LLNCS documentclass as well.
% %
% \begin{proof}
% Proofs, examples, and remarks have the initial word in italics,
% while the following text appears in normal font.
% \end{proof}
% For citations of references, we prefer the use of square brackets
% and consecutive numbers. Citations using labels or the author/year
% convention are also acceptable. The following bibliography provides
% a sample reference list with entries for journal
% articles~\cite{ref_article1}, an LNCS chapter~\cite{ref_lncs1}, a
% book~\cite{ref_book1}, proceedings without editors~\cite{ref_proc1},
% and a homepage~\cite{ref_url1}. Multiple citations are grouped
% \cite{ref_article1,ref_lncs1,ref_boo1},
% \cite{ref_article1,ref_book1,ref_proc1,ref_url1}.

% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
% \addbibresource{}
% \printglossary
\bibliographystyle{splncs04}
% \bibliographystyle{splncs04nat}
% \bibliography{./references/bibliography.bib}
\bibliography{./references/autoupdated.bib}
%
% \begin{thebibliography}{8}
% \bibitem{ref_article1}
% Author, F.: Article title. Journal \textbf{2}(5), 99--110 (2016)



% \bibitem{ref_lncs1}
% Author, F., Author, S.: Title of a proceedings paper. In: Editor,
% F., Editor, S. (eds.) CONFERENCE 2016, LNCS, vol. 9999, pp. 1--13.
% Springer, Heidelberg (2016). \doi{10.10007/1234567890}

% \bibitem{ref_book1}
% Author, F., Author, S., Author, T.: Book title. 2nd edn. Publisher,
% Location (1999)

% \bibitem{ref_proc1}
% Author, A.-B.: Contribution title. In: 9th International Proceedings
% on Proceedings, pp. 1--2. Publisher, Location (2010)

% \bibitem{ref_url1}
% LNCS Homepage, \url{http://www.springer.com/lncs}. Last accessed 4
% Oct 2017
% \end{thebibliography}

% XIXI Comments on Structure
% XIXI: After the architecture follow with the evolutionary framework and then viability function.
% XIXI: LSTM-Prediction model into the architecture section.

% XIXI
% Intro 3-4 pages
% Background 0.5 pages
% Approach 5 pages
% - Architecture 1 pages
% - Evolutionary 2 pages
% - Viability 2 page
% Evaluation 5 pages



\end{document}
