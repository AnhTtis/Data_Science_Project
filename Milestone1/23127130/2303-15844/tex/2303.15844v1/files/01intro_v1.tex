

%XL: storyline following the abstract
% Predictive process monitoring is ... and uses deep recurrent networks (such as LSTM) to predict next activity or process outcome. 
% The models tend to be complex and are difficult to explain. 
% 

% \subfile{content/sections/sec_motivation}


Predictive process analytics is an emerging research field in the Process Mining discipline that focuses on predicting the future states or outcome of running cases of business processes. The proposed techniques often use Machine Learning (ML) models (such as LSTM). These predictive models are trained on historical executions of business processes (i.e.,~\emph{event logs}) to make predictions of future states or outcomes. 
%
Many existing researches have shown that the predictive models can forecast the outcome of processes from various domains well~\cite{klimek_Longtermseriesforecasting_2021, tax_PredictiveBusinessProcess_2017}. For instance, in the medical domain predictive model are applied to predict the outcome or trajectory of a patient's condition~\cite{mannhardt_Analyzingtrajectoriespatients_2017}. %In the private sector, predictive models are used to detect faults or outliers~\cite{}. 
% The research discipline \gls{DL} has shown promising results within domains that have been considered difficult for decades. The Moravex Paradox\cite{agrawal_studyphenomenonMoravec_2010}, which postulates that machines are capable of doing complex computations easily while failing in tasks that seem easy to humans such as object detection or language comprehension, does not hold anymore. Meaning that with enough data to learn, machines are capable of learning highly sophisticated tasks better than any human. The same holds for predictive tasks. 
% While many predictive models can predict certain outcomes, it remains a difficult challenge to understand their reasoning. 

While these ML models are very powerful, they are usually complex and difficult to comprehend. Therefore, they are also known as \emph{blackbox models}~\cite{}. This lack of comprehension is undesirable for many application fields like medical or finance domains. For example, not knowing why a mortgage loan was given makes it impossible to rule out possible biases. In critical domains like medicine, the reasoning behind decisions becomes more crucial. For instance, if we know that a treatment process of a patient reduces the chances for survival, we want to know which treatment step is the critical factor we ought to avoid. 
% To summarise, knowing the outcome of a process often leads us to questions on how to change it. Formally, we would like to change the outcome of a process instance by making it maximally likely with as little interventions as possible~\cite{molnar2019}. 
% \autoref{fig:desired_outcome} is a visual representation of the desired goal.

% \begin{figure}[htb]
%     \centering
%     \includegraphics[width=0.99\textwidth]{figures/counterfactual_goal.png}
%     \caption{This figure illustrates a model, that predicts a certain trajectory of the process. However, we want to change the process steps in such a way, that it changes the outcome.}
%     \label{fig:desired_outcome}
% \end{figure}

% One way to better understand the \gls{ML} models lies within the \gls{XAI} discipline. XAI focuses the developments of theories, methods, and techniques that help explaining \glspl{bbm} to humans. Most of the discipline's techniques produce explanations that guide our understanding. Explanations can come in various forms, such as IF-THEN rules~\cite[p.90]{molnar2019} or feature importance~\cite[p.45]{molnar2019}.%, but some are more comprehensible for humans than others. 

To understand the underlying reasoning of these ML models, a human-friendly approach known as \emph{counterfactuals} is proposed within the eXplaibale AI (XAI) discipline~\cite[p. 221]{molnar2019}. Counterfactuals within the AI framework can help us answer hypothetical "what-if" questions. In other words, if we know \emph{what} would happen \emph{if} we changed the execution of a process instance, we could change it for the better. For example, what if instead of emailing customers, calling customers is executed? Would this alternative execution led to a different outcome (e.g., the customer accepting the offer, instead of rejecting the offer).



% In this paper, we raise the question how we can use counterfactuals to change the trajectory of a process models' prediction towards a desired outcome. Knowing the answers not only increases the understanding of \glspl{bbm}, but also help us avoid or enforce certain outcomes.
Existing counterfactual methods, such as DICE~\cite{}, focus on static, tabular data. Such methods aim to minimize the changes of feature values and use the predictive model to check whether the outcome prediction is flipped. For example, the methods may find that one change to the loan amount of a mortgage application would led to the predictive model flipping from an acceptance to a rejection. %\textcolor{red}{\textbf{TODO: maybe some challenges can be moved here.}}

However, little research has focused on counterfactuals for dynamic data, in particular for event logs of business processes.
Applying these existing methods directly to event logs may lead to generating invalid or infeasible counterfactual sequences. For example, a normative business process may specify that a loan application, if cancelled, then it cannot be accepted by the customer. Without taking the normative process behavior into account, the counterfactual methods may propose an invalid sequence, namely first cancelling a loan application, then immediately accept the offer.  

A state-of-the-art approach adapts the DICE method for counterfactual generations of event logs, referred to as DICE4EL~\cite{}. The DICE4EL approach, however, relies on domain knowledge and assumes that a process models documenting the normative flows between milestones are made available. Such a process model is used to limit the counterfactual explorations to those sequence allowed by the process model. Furthermore, such explorations are done manually by hand editing the input sequences. In reality, such normative process models are difficult to obtain, requiring intensive manual work, extensive knowledge about the process of interest, and skills in process modeling. 

% \subsection{Problem Space}
% \label{sec:challenges}
% \subfile{content/sections/sec_challenges}
% In this paper, we approach the problem of generating counterfactual sequences for processes without domain knowledge. 

% The literature has provided a multitude of techniques to generate counterfactuals for AI models, that are derived from static, tabular data.
% \footnote{With static data, we refer to data that does not change over a time dimension.}. 

%\footnote{With dynamic data, we refer to data that has a temporal relationship as a major component, which is also inherently sequential}.  

% For process data, the literature often uses terms like structured and semi-structured, as they are related to the staticity and dynamicity. Both, structuredness and semi-structuredness, often relate to the data model, in which we structure the information at hand. 
% As static data neither changes over time nor changes its structure, we can use structured data-formats such as tables to capture the information where each data point is an independent entity. We can take the MNIST dataset\cite{deng_MNISTDatabaseHandwritten_2012} or Iris dataset\cite{anderson_SpeciesProblemIris_1936,fisher_UseMultipleMeasurements_1936} as examples for structured and static data. 
% In both datasets, all data points are independent and have the same amount of attributes. In contrast, semi-structured data does not have to follow these strict characteristics. Here, data points often belong to a group of data points which constitutes the full entity. Furthermore, the attributes of each data point may vary. The grouping mechanism could take the form of associative links, class associations or temporal cause-effect relationships. Examples of these are Part-of-Speech datasets like Penn Treebank set\cite{marcus_Buildinglargeannotated_1993}. 
% Here, we often associate each data point with a sentence. However, the temporal relationship between words is debatable and hence, whether the data is \emph{dynamic}, as well. So, not all semi-structured datasets are dynamic and vice versa. However, structured data will almost always be static, with the exception of time-series. 
% Lastly, there is also unstructured data, which does not incorporate any specific data model. Corpora like the Brown dataset\cite{francis79browncorpus}, for instance, are collections of text heavy unstructured information. In \autoref{fig:example_structure}, we show various examples of data.


% \begin{figure}
%     \centering
%     \begin{subfigure}[c]{0.49\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{figures/Graphics/Slide1.png}
%         \caption{An excerpt of the MNIST dataset. This is a structured dataset.}
%         \label{fig:structured}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[c]{0.49\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{figures/Graphics/Slide3.png}
%         \caption{A number of heterogenous documents. A dataset like this is unstructured.}
%         \label{fig:unstructured}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[c]{0.7\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{figures/Graphics/Slide2.png}
%         \caption{Multiple seqeuences of words. Each word forms a sentence of different lengths. Therefore, this data is semi-structured.}
%         \label{fig:semistructured}
%     \end{subfigure}
%       \caption{Schematic examples of static structured, dynamic semi-structured data and unstructured data.}
%       \label{fig:example_structure}
% \end{figure}


% A major reason, why there has not been much research on counterfactuals for dynamic semi-structured data, emerges from a multitude of challenges, when dealing with counterfactuals and sequences. Three of these challenges are particularly important. 

% There are several challenges when dealing with counterfactuals of sequences. 
% %
% First, counterfactuals within AI attempt to explain outcomes which never occured. \emph{What-if} questions often refer to hypothetical scenarios. Therefore, there is no evidential data from which we can infer predictions. Subsequently, this lack of evidence further complicates the evaluation of generated counterfactuals. In other words, you cannot validate the correctness of a theoretical outcome that has never occured. 
% %
% Second, sequential data is highly variable in length, but process steps have complicated factors, too. The sequential nature of the data impedes the tractability of many problems due to the combinatorial explosion of possible sequences. 
% %A sequence with 10 possible elements at each position will have a 100, 1000 and 10.000 possible combinations, if they have a sequence length of 2, 3 and 4, respectively. 
% Moreover, the data generated is seldomly one-dimensional or discrete. Henceforth, each dimension's contribution can vary in dependance of its context, time and magnitude. 
% %Each element in a sequence can have additional information attached to it.
% %
% Third, process data often requires knowledge of the causal structures that produced the data in the first place. However, these structures are often hidden and it is a NP-hard problem to elicit them\cite{wang_Efficientrecoverymissing_2013}. 
% %
% These challenges make the field, in which we can contribute, a vast endeavor. 




% \subsection{Research Question}
% \label{sec:rq}
% As we seek to make data-driven process models interpretable, we have to understand the exact purpose of this paper. Hence, we establish the open challenges and how this paper attempts to solve them. 
% \subfile{content/sections/sec_rq}
% Having discussed the previous work on counterfactual sequence generation, a couple of challenges emerge.
% First, we need to generate on a set of criteria and therefore, require complex loss and evaluation metrics, that may or may not be differentiable. Second, they cannot to be logically impossible, given the dataset.
% Hence, we have to restrict the space to counterfactuals of viable solutions, while being flexible enough to not just copy existing data instances.
% Third, using domain knowledge of the process significantly reduces the practicality of any solution. Therefore, we have to develop an approach, which requires only the given log as input while not relying on process specific domain knowledge. This begs the question, whether there is a method to generate sequential counterfactuals that are viable, without relying on process specific domain knowledge. In terms of specific research questions we try to answer:

% \begin{itemize}
%     \item[RQ:] How do we generate counterfactual sequences while incorporating structural differences between the factual sequence and the counterfactual sequence?
%           \begin{itemize}
%             \item[RQ1:] How can we employ existing methods to compute viability so that its optimization incorporates information about the structure of the sequence?
%               \item[RQ2:] To what extent can we generate counterfactuals that fulfill the criteria to be viable?
%               \item[RQ3:] How does an algorithm, which optimizes multiple viability quality metrics, perform against other approaches?
%           \end{itemize}
% \end{itemize}

% We propose a general framework which allows the exploration of several independent components. 
% \autoref{fig:framework-simplified} shows the conceptual framework of the base approach visually.
% \begin{figure}[htb]
%     \centering
%     \includegraphics[width=0.9\textwidth]{figures/framework_simplified.png}
%     \caption{A simplified schematic representation of the framework which is explored in this thesis.}
%     \label{fig:framework-simplified}
% \end{figure}
% \noindent 
In this paper, we approach the problem of generating counterfactual sequences for process outcome prediction without domain knowledge. In particular, we propose a general framework built on evolutionary algorithms to generate sequences. The framework contains three components. The first component is a pre-trained predictive model, which we aspire to explain using counterfactuals. We assume that the prediction model \emph{accurately} predicts the outcome of a process at any step~\footnote{\scriptsize The accuracy-condition is favorable, but not necessary. If the component is accurately modelling the real world, we can draw real-world conclusions from the explanations generated. If the component is inaccurate, the counterfactuals only explain the prediction decisions and not the real world.}. The second component implements the evolutionary algorithm, which generates counterfactual sequences that should be of high quality. To quantity and estimate the quality of counterfactual sequences, we define the \emph{viability} measure, built on the established measures, while taking four measures into account, namely (1) feasibility of a counterfactual sequence, (2) the delta flipped in the outcome prediction, (3) the similarity between factual and counterfactual, and (4) the sparsity counting the number of changes. To ensure the generated counterfactuals are viable and to rank and select the most viable counterfactuals, the third component implements the evaluation measures. 

% A plausible counterfactual is one whose outcome can be predicted by the predictive component. If the predictive component cannot predict the counterfactual sequence, we can assume that the generative model is \emph{unfaithful} to the predictive component that we want to explain. The third component is the evaluation metric upon which we decide the viability of the counterfactual candidates.

% We implemented our framework as follows. We used a LSTM model for the predictive component. For the generative component, we propose an evolutionary algorithm, while

% For the evaluation, we have to show the following:
% \begin{itemize}
%     \item[RQ2-H1:] If we use a viability function which incorporates multiple criteria to determine counterfactuals, we consistently retrieve more viable counterfactuals, than choosing the counterfactuals the at random.
%     \item[RQ2-H2:] The generated counterfactuals consistently outperform the most viable counterfactuals among examples in the dataset.
%     \item[RQ3-H1:] The results of the counterfactual are comparable to other existing literature.
%           % \item[RQ2-H1:] The counterfactual generation consistently identifies the most viable counterfactual in the dataset faster than a random search.
% \end{itemize}

% \subsection{Outline}
% \subfile{content/sections/sec_outline}
The remainder of the paper is structured as follows. Section~\ref{ch:methods} presents our approach. Section~\ref{ch:evaluation} explains the evaluation set-up. 
Section~\ref{ch:results} discusses the results, and Section~\ref{ch:conclusion} concludes the paper. 

% In \autoref{ch:prereq}, we introduce all of the important concepts that are crucial to this thesis. Most importantly, we introduce the main research discipline \Gls{PM} and the subject of our research: \emph{Counterfactuals}. Furthermore we cover some necessary background required to understand the methods, we employ.
% The \autoref{ch:methods}, introduces our methodological framework in further detail. The chapter explains all the important components and methods, we apply, to answer the research question. Among these methods, we introduce the methodological architecture, a modified version of the \Gls{damerau_levenshtein}.
% \autoref{ch:evaluation} covers the main approach behind our experimental setup. We discuss how we attempt to answer our research questions and introduce the datasets we are using and how we conduct the preprocessing. 
% In \autoref{ch:results} we report on the results and insights we gain from executing our research approach. 
% All the results are summarised in \autoref{ch:discussion}. Here, we summarize and interpret our results. We discuss limitations and possible improvements. We also discuss implications for future research endeavors. 
% The \autoref{ch:conclusion} summarizes the thesis and the implications for the \Gls{PM} research field.
