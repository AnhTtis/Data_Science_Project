\section{Introduction}
\label{sec:intro}

\subsection{Motivation}
\label{sec:motivation}

%XL: storyline following the abstract
% Predictive process monitoring is ... and uses deep recurrent networks (such as LSTM) to predict next activity or process outcome. 
% The models tend to be complex and are difficult to explain. 
% 

% \subfile{content/sections/sec_motivation}
Many processes, often medical, economical, or administrative in nature, are governed by sequential events and their contextual environment. Many of these events and their order of appearance play a crucial part in the determination of every possible outcome\cite{vanderaalst_ProcessMiningManifesto_2012}. With the rise of AI and the increased abundance of data in recent years, several techniques emerged that help to predict the outcomes of complex processes in the real world. A field that focuses on modelling processes is \gls{PM}.

Research in the Process Mining discipline has shown that it is possible to predict the outcome of a particular process fairly well\cite{tax_PredictiveBusinessProcess_2017a,klimek_Longtermseriesforecasting_2021}.

For instance, in the medical domain, models have been shown to predict the outcome or trajectory of a patient's condition\cite{mannhardt_Analyzingtrajectoriespatients_2017}. In the private sector, process models can be used to detect faults or outliers. The research discipline \gls{DL} has shown promising results within domains that have been considered difficult for decades. The Moravex Paradox\cite{agrawal_studyphenomenonMoravec_2010}, which postulates that machines are capable of doing complex computations easily while failing in tasks that seem easy to humans such as object detection or language comprehension, does not hold anymore. Meaning that with enough data to learn, machines are capable of learning highly sophisticated tasks better than any human. The same holds for predictive tasks. However, while many prediction models can predict certain outcomes, it remains a difficult challenge to understand their reasoning. 

This difficulty arises from models, like neural networks, that are so-called \emph{\glspl{bbm}}. Meaning, that their inference is incomprehensible, due to the vast amount of parameters involved. This lack of comprehension is undesirable for many fields like IT or finance. Not knowing why a loan was given, makes it impossible to rule out possible biases. Knowing what will lead to a system failure will help us knowing how to avoid it. In critical domains like medicine, the reasoning behind decisions becomes crucial. For instance, if we know that a treatment process of a patient reduces the chances for survival, we want to know which treatment step is the critical factor we ought to avoid. To summarise, knowing the outcome of a process often leads us to questions on how to change it. Formally, we want to change the outcome of a process instance by making it maximally likely with as little interventions as possible\cite{molnar2019}. \autoref{fig:desired_outcome} is a visual representation of the desired goal.

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.99\textwidth]{figures/counterfactual_goal.png}
    \caption{This figure illustrates a model, that predicts a certain trajectory of the process. However, we want to change the process steps in such a way, that it changes the outcome.}
    \label{fig:desired_outcome}
\end{figure}

\noindent One way to better understand the \gls{ML} models lies within the \gls{XAI} discipline. XAI focuses the developments of theories, methods, and techniques that help explaining \glspl{bbm} models to humans. Most of the discipline's techniques produce explanations that guide our understanding. Explanations can come in various forms, such as IF-THEN rules\cite[p.90]{molnar2019} or feature importance\cite[p.45]{molnar2019}, but some are more comprehensible for humans than others. 

A prominent and human-friendly approach are \emph{counterfactuals}\cite[p. 221]{molnar2019}. Counterfactuals within the AI framework help us to answer hypothetical "what-if" questions. Basically, if we know \emph{what} would happen \emph{if} we changed the execution of a process instance, we could change it for the better. In this thesis, we raise the question how we can use counterfactuals to change the trajectory of a process models' prediction towards a desired outcome. Knowing the answers not only increases the understanding of \glspl{bbm}, but also help us avoid or enforce certain outcomes.

\subsection{Problem Space}
\label{sec:challenges}
% \subfile{content/sections/sec_challenges}
In this thesis, we approach the problem of generating counterfactuals for processes. The literature has provided a multitude of techniques to generate counterfactuals for AI models, that are derived from static data\footnote{With static data, we refer to data that does not change over a time dimension.}. However, little research has focussed on counterfactuals for dynamic data\footnote{With dynamic data, we refer to data that has a temporal relationship as a major component, which is also inherently sequential}.  

For process data, the literature often uses terms like structured and semi-structured, as they are related to the staticity and dynamicity. Both, structuredness and semi-structuredness, often relate to the data model, in which we structure the information at hand. 
As static data neither changes over time nor changes its structure, we can use structured data-formats such as tables to capture the information where each data point is an independent entity. We can take the MNIST dataset\cite{deng_MNISTDatabaseHandwritten_2012} or Iris dataset\cite{anderson_SpeciesProblemIris_1936,fisher_UseMultipleMeasurements_1936} as examples for structured and static data. 
In both datasets, all data points are independent and have the same amount of attributes. In contrast, semi-structured data does not have to follow these strict characteristics. Here, data points often belong to a group of data points which constitutes the full entity. Furthermore, the attributes of each data point may vary. The grouping mechanism could take the form of associative links, class associations or temporal cause-effect relationships. Examples of these are Part-of-Speech datasets like Penn Treebank set\cite{marcus_Buildinglargeannotated_1993}. 
Here, we often associate each data point with a sentence. However, the temporal relationship between words is debatable and hence, whether the data is \emph{dynamic}, as well. So, not all semi-structured datasets are dynamic and vice versa. However, structured data will almost always be static, with the exception of time-series. 
Lastly, there is also unstructured data, which does not incorporate any specific data model. Corpora like the Brown dataset\cite{francis79browncorpus}, for instance, are collections of text heavy unstructured information. In \autoref{fig:example_structure}, we show various examples of data.


\begin{figure}
    \centering
    \begin{subfigure}[c]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/Graphics/Slide1.png}
        \caption{An excerpt of the MNIST dataset. This is a structured dataset.}
        \label{fig:structured}
    \end{subfigure}
    \hfill
    \begin{subfigure}[c]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/Graphics/Slide3.png}
        \caption{A number of heterogenous documents. A dataset like this is unstructured.}
        \label{fig:unstructured}
    \end{subfigure}
    \hfill
    \begin{subfigure}[c]{0.7\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/Graphics/Slide2.png}
        \caption{Multiple seqeuences of words. Each word forms a sentence of different lengths. Therefore, this data is semi-structured.}
        \label{fig:semistructured}
    \end{subfigure}
       \caption{Schematic examples of static structured, dynamic semi-structured data and unstructured data.}
       \label{fig:example_structure}
\end{figure}


A major reason, why there has not been much research on counterfactuals for dynamic semi-structured data, emerges from a multitude of challenges, when dealing with counterfactuals and sequences. Three of these challenges are particularly important.
 
First, counterfactuals within AI attempt to explain outcomes which never occured. \emph{What-if} questions often refer to hypothetical scenarios. Therefore, there is no evidential data from which we can infer predictions. Subsequently, this lack of evidence further complicates the evaluation of generated counterfactuals. In other words, you cannot validate the correctness of a theoretical outcome that has never occured.

Second, sequential data is highly variable in length, but process steps have complicated factors, too. The sequential nature of the data impedes the tractability of many problems due to the combinatorial explosion of possible sequences. 
%A sequence with 10 possible elements at each position will have a 100, 1000 and 10.000 possible combinations, if they have a sequence length of 2, 3 and 4, respectively. 
Furthermore, the data generated is seldomly one-dimensional or discrete. Henceforth, each dimension's contribution can vary in dependance of its context, time and magnitude. 
%Each element in a sequence can have additional information attached to it.

Third, process data often requires knowledge of the causal structures that produced the data in the first place. However, these structures are often hidden and it is a NP-hard problem to elicit them\cite{wang_Efficientrecoverymissing_2013}.

These challenges make the field, in which we can contribute, a vast endeavor. 


\subsection{Related Literature}
\label{sec:literature}
Many researchers have worked on counterfactuals and \Gls{PM}. 
Here, we combine the important concepts and discuss the various contributions to this thesis.
% \subfile{content/sections/sec_literature}
\subsubsection{Generating Counterfactuals}
The topic of counterfactual generation as explanation method was introduced by \citeauthor{wachter_CounterfactualExplanationsOpening_2018} in \citeyear{wachter_CounterfactualExplanationsOpening_2018}\cite{wachter_CounterfactualExplanationsOpening_2018}. The authors defined a loss function which incorporates the criteria to generate a counterfactual which maximizes the likelihood for a predefined outcome and minimizes the distance to the original instance. However, the solution of \citeauthor{wachter_CounterfactualExplanationsOpening_2018} did not account for the minimisation of feature changes and does not penalize unrealistic features. Furthermore, their solution cannot incorporate categorical variables.

A newer approach by \citeauthor{dandl_MultiObjectiveCounterfactualExplanations_2020} incorporates four main criteria for counterfactuals (see \autoref{sec:counterfactuals}) by applying a genetic algorithm with a multi-objective fitness function\cite{dandl_MultiObjectiveCounterfactualExplanations_2020}. This approach strongly differs from gradient-based methods, as it does not require a differentiable objective function. However, their solution was only tested on static data.

\subsubsection{Generating Counterfactual Sequences}
When it comes to sequential data most researchers work on ways to generate counterfactuals for natural language. This often entails generating univariate discrete counterfactuals with the use of \gls{DL} techniques. \citeauthor{martens_Explainingdatadrivendocument_2014} and later \citeauthor{krause_InteractingPredictionsVisual_2016} are early examples of counterfactual NLP research\cite{martens_Explainingdatadrivendocument_2014,krause_InteractingPredictionsVisual_2016}. Their approach strongly focuses on the manipulation of sentences to achieve the desired outcome. However, as \citeauthor{robeer_GeneratingRealisticNatural_2021} puts it, their counterfactuals do not comply with \emph{realisticness}\cite{robeer_GeneratingRealisticNatural_2021}.

Instead, \citeauthor{robeer_GeneratingRealisticNatural_2021} showed that it is possible to generate realistic counterfactuals with a \gls{GAN}\cite{robeer_GeneratingRealisticNatural_2021}. They use the model to implicitly capture a latent state space and sample counterfactuals from it. Apart from implicitly modelling the latent space with \glspl{GAN}, it is possible to sample data from an explicit latent space. Examples of these approaches often use an encoder-decoder pattern in which the encoder encodes a data instance into a latent vector, which will be peturbed and then decoded into a similar instance\cite{melnyk_ImprovedNeuralText_2017,wang_Controllableunsupervisedtext_2019}. By modelling the latent space, we can simply sample from a distribution conditioned on the original instance. \citeauthor{bond-taylor_DeepGenerativeModelling_2021} provide an overview of the strengths and weaknesses of common generative models.

Even though, a single latent vector model can theoretically produce multivariate sequences, it may still be too restrictive to capture the combinatorial space of multivariate sequences. Hence, most of the models within \gls{NLP} were not used to produce a sequence of vectors, but a sequence of discrete symbols. For process instances, we can assume a causal relation between state vectors in a sequential latent space. We call models that capture a sequential latent state-space, which has causal relations, \emph{dynamic}\cite{leglaive_RecurrentVariationalAutoencoder_2020}. Early models of this type of dynamic latent state-space models are the well-known \emph{Kalman-Filter} for continuous states and \gls{HMM} for discrete states. In recent literature, many techniques use \gls{DL} to model complex state-spaces. The first models of this type were developed by \citeauthor{krishnan_StructuredInferenceNetworks_2017}\cite{krause_InteractingPredictionsVisual_2016, krishnan_StructuredInferenceNetworks_2017}. Their \gls{DKF} and subsequent \gls{DMM} approximate the dynamic latent state-space by modelling the latent space given the data sequence and all previous latent vectors in the sequence. There are many variations\cite{chung_RecurrentLatentVariable_2016,fraccaro_Sequentialneuralmodels_2016,leglaive_RecurrentVariationalAutoencoder_2020} of \citeauthor{krishnan_StructuredInferenceNetworks_2017}'s model, but most use \gls{ELBO} of the posterior for the current $Z_{t}$ given all previous $\{Z_{t-1},\ldots,Z_{1}\}$ and $X_{t}$\cite{girin_DynamicalVariationalAutoencoders_2021}.

\subsubsection{Generating Counterfactual Time-Series}
Within the \emph{multivariate time-series} literature two recent approaches yield ideas worth discussing.

First, \citeauthor{delaney_InstanceBasedCounterfactualExplanations_2021} introduce a case-based reasoning to generate counterfactuals\cite{delaney_InstanceBasedCounterfactualExplanations_2021}. Their method uses existing counterfactual instances, or \emph{prototypes}, in the dataset. Therefore, it ensures, that the proposed counterfactuals are \emph{realistic}. However, case-based approaches strongly depend on the \emph{representativeness} of the prototypes\cite[p. 192]{molnar2019}. In other words, if the model displays behaviour, which is not captured within the set of prototypical instances, most case-based techniques will fail to provide viable counterfactuals. The likelihood of such a break-down increases due to the combinatorial explosion of possible behaviours if the \emph{true} process model has cycles or continuous event attributes. Cycles may cause infinite possible sequences and continuous attributes can take values on a domain within infinite negative and positive bounds. These issues have not been explored in the paper of \citeauthor{delaney_InstanceBasedCounterfactualExplanations_2021}, as it mainly deals with time series classification\cite{delaney_InstanceBasedCounterfactualExplanations_2021}. However, despite these shortcomings, case-based approaches may act as a valuable baseline against other sophisticated approaches.

The second paper within the multivariate time series field by \citeauthor{ates_CounterfactualExplanationsMultivariate_2021} also uses a case-based approach\cite{ates_CounterfactualExplanationsMultivariate_2021}. However, it contrasts from other approaches, as it does not specify a particular model but proposes a general framework instead. Hence, within this framework, individual components could be substituted by better performing components. Describing a framework, rather than specifying a particular model, allows to adapt the framework, due to the heterogeneous process dataset landscape. In this paper, we also introduce a framework that allows for flexibility depending on the dataset. 
% \optional{The framework will be evaluated in two steps. The first step aims to compare various model types against eachother based on the countefactual viability. The second step scrutinizes the best framework configurations from step one, by presenting its results to a domain expert.}

\subsubsection{Generating Counterfactuals for Business Processes}
So far, none of the techniques have been applied to process data.

Within \gls{PM}, \gls{causalinference} has long been used to analyse and model business processes. Mainly, due to the causal relationships underlying each process. However, early work has often attempted to incorporate domain-knowledge about the causality of processes in order to improve the process model itself\cite{shook_assessmentusestructural_2004,baker_ClosingLoopEmpirical_2017,hompes_DiscoveringCausalFactors_2017,wang_CounterfactualDataAugmentedSequential_2021}.
Among these, \citeauthor{narendra_CounterfactualReasoningProcess_2019} approach is one of the first to include counterfactual reasoning for process optimization\cite{narendra_CounterfactualReasoningProcess_2019}.
\citeauthor{oberst_CounterfactualOffPolicyEvaluation_2019} use counterfactuals to generate alternative solutions to treatments, which lead to a desired outcome\cite{oberst_CounterfactualOffPolicyEvaluation_2019}.
Again, the authors do not attempt to provide an explanation of the models outcome and therefore, disregard multiple viability criteria for counterfactuals in \gls{XAI}. \citeauthor{qafari_CaseLevelCounterfactual_2021} published the most recent paper on the counterfactual generation of explanations\cite{qafari_CaseLevelCounterfactual_2021}. The authors use a known \gls{SCM} to guide the generation of their counterfactuals. However, this approach requires a process model which is as close as possible to the \emph{true} process model. For our approach, we assume that no knowledge about the dependencies are known.

Within the \gls{XAI} context, \citeauthor{tsirtsis_CounterfactualExplanationsSequential_2021} develop the first explanation method for process data\cite{tsirtsis_CounterfactualExplanationsSequential_2021}. However, their work closely resembles the work of \citeauthor{oberst_CounterfactualOffPolicyEvaluation_2019} and treat the task as \gls{MDP}\cite{oberst_CounterfactualOffPolicyEvaluation_2019}. This extension of a regular \gls{MP} assumes that an actor influences the outcome of a process given the state. This formalisation allows the use of \gls{RL} methods like Q-learning or SARSA. However, this often requires additional assumptions such as a given reward function and an action-space. For counterfactual sequence generation, there is no obvious choice for the reward function or the action-space. 

Nonetheless, both \citeauthor{tsirtsis_CounterfactualExplanationsSequential_2021} and \citeauthor{oberst_CounterfactualOffPolicyEvaluation_2019} contribute an important idea. The idea of incrementally generating the counterfactual instead of the full sequence. \citeauthor{hsieh_DiCE4ELInterpretingProcess_2021} has recently published an approach that builds on the same notion of incremental generation. Their approach has a very similar structure to our approach and appears to be the only one that we can compare our counterfactuals against. 

For this reason, this thesis highlights some key differences and similarities. However, to understand the differences and similarities, we first have to establish some core concepts.  In this section, we only discuss their approach, briefly.

The authors recognised that some processes have critical events which govern the overall outcome. Hence, by simply avoiding the undesired outcome from critical event to critical event, it is possible to limit the search space and compute viable counterfactuals. They use an extension of DiCE\cite{mothilal_ExplainingMachineLearning_2020} to generate counterfactuals. However, their approach requires concrete knowledge about these critical points. We propose a Framework that avoids this constraint. 

To our knowledge, the authors are also the first authors that try to optimize their counterfactual process generation based on criteria that ensure their viability. However, in our approach, we use different operationalisations to quantify the criteria.

\subsection{Research Question}
\label{sec:rq}
As we seek to make data-driven process models interpretable, we have to understand the exact purpose of this thesis. Hence, we establish the open challenges and how this thesis attempts to solve them. 
% \subfile{content/sections/sec_rq}
Having discussed the previous work on counterfactual sequence generation, a couple of challenges emerge.
First, we need to generate on a set of criteria and therefore, require complex loss and evaluation metrics, that may or may not be differentiable. Second, they cannot to be logically impossible, given the dataset.
Hence, we have to restrict the space to counterfactuals of viable solutions, while being flexible enough to not just copy existing data instances.
Third, using domain knowledge of the process significantly reduces the practicality of any solution. Therefore, we have to develop an approach, which requires only the given log as input while not relying on process specific domain knowledge. This begs the question, whether there is a method to generate sequential counterfactuals that are viable, without relying on process specific domain knowledge. In terms of specific research questions we try to answer:

\begin{itemize}
    \item[RQ:] How do we generate counterfactual sequences while incorporating structural differences between the factual sequence and the counterfactual sequence?
          \begin{itemize}
            \item[RQ1:] How can we employ existing methods to compute viability so that its optimization incorporates information about the structure of the sequence?
              \item[RQ2:] To what extent can we generate counterfactuals that fulfill the criteria to be viable?
              \item[RQ3:] How does an algorithm, which optimizes multiple viability quality metrics, perform against other approaches?
          \end{itemize}
\end{itemize}

\noindent We approach these questions, by proposing a framework which allows the exploration of several independent components. 
% \autoref{fig:framework-simplified} shows the conceptual framework of the base approach visually.
% \begin{figure}[htb]
%     \centering
%     \includegraphics[width=0.9\textwidth]{figures/framework_simplified.png}
%     \caption{A simplified schematic representation of the framework which is explored in this thesis.}
%     \label{fig:framework-simplified}
% \end{figure}
\noindent The framework contains three parts. First, we need a pre-trained predictive component, which we aspire to explain. The component should \emph{accurately} predict the outcome of a process at any step. The accuracy-condition is favorable, but not necessary. If the component is accurately modelling the real world, we can draw real-world conclusions from the explanations generated. If the component is inaccurate, the counterfactuals only explain the prediction decisions and not the real world. The second part requires a generative component. The generative component needs to generate viable sequential counterfactuals which are logically \emph{plausible}. A plausible counterfactual is one whose outcome can be  predicted by the predictive component. If the predictive component cannot predict the counterfactual sequence, we can assume that the generative model is \emph{unfaithful} to the predictive component that we want to explain. The third component is the evaluation metric upon which we decide the viability of the counterfactual candidates.

For the evaluation, we have to show the following:
\begin{itemize}
    \item[RQ2-H1:] If we use a viability function which incorporates multiple criteria to determine counterfactuals, we consistently retrieve more viable counterfactuals, than choosing the counterfactuals the at random.
    \item[RQ2-H2:] The generated counterfactuals consistently outperform the most viable counterfactuals among examples in the dataset.
    \item[RQ3-H1:] The results of the counterfactual are comparable to other existing literature.
          % \item[RQ2-H1:] The counterfactual generation consistently identifies the most viable counterfactual in the dataset faster than a random search.
\end{itemize}

\subsection{Outline}
% \subfile{content/sections/sec_outline}
The remainder of the thesis is outlined as follows: In \autoref{ch:prereq}, we introduce all of the important concepts that are crucial to this thesis. Most importantly, we introduce the main research discipline \Gls{PM} and the subject of our research: \emph{Counterfactuals}. Furthermore we cover some necessary background required to understand the methods, we employ.
The \autoref{ch:methods}, introduces our methodological framework in further detail. The chapter explains all the important components and methods, we apply, to answer the research question. Among these methods, we introduce the methodological architecture, a modified version of the \Gls{damerau_levenshtein}.
\autoref{ch:evaluation} covers the main approach behind our experimental setup. We discuss how we attempt to answer our research questions and introduce the datasets we are using and how we conduct the preprocessing. 
In \autoref{ch:results} we report on the results and insights we gain from executing our research approach. 
All the results are summarised in \autoref{ch:discussion}. Here, we summarize and interpret our results. We discuss limitations and possible improvements. We also discuss implications for future research endeavors. 
The \autoref{ch:conclusion} summarizes the thesis and the implications for the \Gls{PM} research field.
