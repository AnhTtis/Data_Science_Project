%% Created for Prasanta Ghosh on -01-20


@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={12449--12460},
  year={2020}}
  
@article{chung2021w2v,
  title={W2v-bert: Combining contrastive learning and masked language modeling for self-supervised speech pre-training},
  author={Chung, Yu-An and Zhang, Yu and Han, Wei and Chiu, Chung-Cheng and Qin, James and Pang, Ruoming and Wu, Yonghui},
  journal={arXiv preprint arXiv:2108.06209},
  year={2021}
}

@article{chen2021wavlm,
  title={Wavlm: Large-scale self-supervised pre-training for full stack speech processing},
  author={Chen, Sanyuan and Wang, Chengyi and Chen, Zhengyang and Wu, Yu and Liu, Shujie and Chen, Zhuo and Li, Jinyu and Kanda, Naoyuki and Yoshioka, Takuya and Xiao, Xiong and others},
  journal={arXiv preprint arXiv:2110.13900},
  year={2021}
}

@article{hinton2014distilling,
  title={Distilling the knowledge in a neural network. nips deep learning workshop},
  author={Hinton, G and Vinyals, O and Dean, J},
  journal={arXiv preprint arXiv:1503.02531},
  year={2014}
}

@inproceedings{li2020towards,
  title={Towards fast and accurate streaming end-to-end ASR},
  author={Li, Bo and Chang, Shuo-yiin and Sainath, Tara N and Pang, Ruoming and He, Yanzhang and Strohman, Trevor and Wu, Yonghui},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6069--6073},
  year={2020},
  organization={IEEE}
}

@article{wong2016sequence,
  title={Sequence student-teacher training of deep neural networks},
  author={Wong, Jeremy HM and Gales, Mark},
  year={2016},
  publisher={International Speech Communication Association}
}

@inproceedings{takashima2019investigation,
  title={Investigation of sequence-level knowledge distillation methods for CTC acoustic models},
  author={Takashima, Ryoichi and Sheng, Li and Kawai, Hisashi},
  booktitle={ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6156--6160},
  year={2019},
  organization={IEEE}
}

@article{singh2020large,
  title={Large scale weakly and semi-supervised learning for low-resource video ASR},
  author={Singh, Kritika and Manohar, Vimal and Xiao, Alex and Edunov, Sergey and Girshick, Ross and Liptchinsky, Vitaliy and Fuegen, Christian and Saraf, Yatharth and Zweig, Geoffrey and Mohamed, Abdelrahman},
  journal={arXiv preprint arXiv:2005.07850},
  year={2020}
}

@inproceedings{parthasarathi2019lessons,
  title={Lessons from building acoustic models with a million hours of speech},
  author={Parthasarathi, Sree Hari Krishnan and Strom, Nikko},
  booktitle={ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6670--6674},
  year={2019},
  organization={IEEE}
}

@article{cao2021improving,
  title={Improving Streaming Transformer Based ASR Under a Framework of Self-supervised Learning},
  author={Cao, Songjun and Kang, Yueteng and Fu, Yanzhe and Xu, Xiaoshuo and Sun, Sining and Zhang, Yike and Ma, Long},
  journal={arXiv preprint arXiv:2109.07327},
  year={2021}
}

@inproceedings{hentschel2021making,
  title={Making punctuation restoration robust and fast with multi-task learning and knowledge distillation},
  author={Hentschel, Michael and Tsunoo, Emiru and Okuda, Takao},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7773--7777},
  year={2021},
  organization={IEEE}
}

@article{peng2021shrinking,
  title={Shrinking bigfoot: Reducing wav2vec 2.0 footprint},
  author={Peng, Zilun and Budhkar, Akshay and Tuil, Ilana and Levy, Jason and Sobhani, Parinaz and Cohen, Raphael and Nassour, Jumana},
  journal={arXiv preprint arXiv:2103.15760},
  year={2021}
}

@article{yang2021knowledge,
  title={Knowledge Distillation for Neural Transducers from Large Self-Supervised Pre-trained Models},
  author={Yang, Xiaoyu and Li, Qiujia and Woodland, Philip C},
  journal={arXiv preprint arXiv:2110.03334},
  year={2021}
}

@article{baevski2021unsupervised,
  title={Unsupervised speech recognition},
  author={Baevski, Alexei and Hsu, Wei-Ning and Conneau, Alexis and Auli, Michael},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{hsu2021hubert,
  title={HuBERT: How much can a bad teacher benefit ASR pre-training?},
  author={Hsu, Wei-Ning and Tsai, Yao-Hung Hubert and Bolte, Benjamin and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6533--6537},
  year={2021},
  organization={IEEE}
}

@phdthesis{povey2005discriminative,
  title={Discriminative training for large vocabulary speech recognition},
  author={Povey, Daniel},
  year={2005},
  school={University of Cambridge}
}

@inproceedings{vesely2013sequence,
  title={Sequence-discriminative training of deep neural networks.},
  author={Vesel{\`y}, Karel and Ghoshal, Arnab and Burget, Luk{\'a}s and Povey, Daniel},
  booktitle={Interspeech},
  volume={2013},
  pages={2345--2349},
  year={2013}
}

@inproceedings{povey2016purely,
  title={Purely sequence-trained neural networks for ASR based on lattice-free MMI.},
  author={Povey, Daniel and Peddinti, Vijayaditya and Galvez, Daniel and Ghahremani, Pegah and Manohar, Vimal and Na, Xingyu and Wang, Yiming and Khudanpur, Sanjeev},
  booktitle={Interspeech},
  pages={2751--2755},
  year={2016}
}

@inproceedings{hadian2018end,
  title={End-to-end Speech Recognition Using Lattice-free MMI.},
  author={Hadian, Hossein and Sameti, Hossein and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={Interspeech},
  pages={12--16},
  year={2018}
}

@article{tian2021consistent,
  title={Consistent Training and Decoding For End-to-end Speech Recognition Using Lattice-free MMI},
  author={Tian, Jinchuan and Yu, Jianwei and Weng, Chao and Zhang, Shi-Xiong and Su, Dan and Yu, Dong and Zou, Yuexian},
  journal={arXiv preprint arXiv:2112.02498},
  year={2021}
}

@article{vyas2021comparing,
  title={Comparing CTC and LFMMI for out-of-domain adaptation of wav2vec 2.0 acoustic model},
  author={Vyas, Apoorv and Madikeri, Srikanth and Bourlard, Herv{\'e}},
  journal={arXiv preprint arXiv:2104.02558},
  year={2021}
}

@inproceedings{manohar2018semi,
  title={Semi-supervised training of acoustic models using lattice-free MMI},
  author={Manohar, Vimal and Hadian, Hossein and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={4844--4848},
  year={2018},
  organization={IEEE}
}

@article{baevski2019effectiveness,
  title={Effectiveness of self-supervised pre-training for speech recognition},
  author={Baevski, Alexei and Auli, Michael and Mohamed, Abdelrahman},
  journal={arXiv preprint arXiv:1911.03912},
  year={2019}
}

@inproceedings{graves2006connectionist,
  title={Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks},
  author={Graves, Alex and Fern{\'a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={369--376},
  year={2006}
}

@inproceedings{chen2021developing,
  title={Developing real-time streaming transformer transducer for speech recognition on large-scale dataset},
  author={Chen, Xie and Wu, Yu and Wang, Zhenghao and Liu, Shujie and Li, Jinyu},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5904--5908},
  year={2021},
  organization={IEEE}
}

@inproceedings{panayotov2015librispeech,
  title={Librispeech: an asr corpus based on public domain audio books},
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5206--5210},
  year={2015},
  organization={IEEE}
}

@article{chen2021gigaspeech,
  title={Gigaspeech: An evolving, multi-domain asr corpus with 10,000 hours of transcribed audio},
  author={Chen, Guoguo and Chai, Shuzhou and Wang, Guanbo and Du, Jiayu and Zhang, Wei-Qiang and Weng, Chao and Su, Dan and Povey, Daniel and Trmal, Jan and Zhang, Junbo and others},
  journal={arXiv preprint arXiv:2106.06909},
  year={2021}
}

@inproceedings{panchapagesan2021efficient,
  title={Efficient knowledge distillation for rnn-transducer models},
  author={Panchapagesan, Sankaran and Park, Daniel S and Chiu, Chung-Cheng and Shangguan, Yuan and Liang, Qiao and Gruenstein, Alexander},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5639--5643},
  year={2021},
  organization={IEEE}
}


@article{swaminathan2021codert,
  title={CoDERT: Distilling encoder representations with co-learning for transducer-based speech recognition},
  author={Swaminathan, Rupak Vignesh and King, Brian and Strimel, Grant P and Droppo, Jasha and Mouchtaris, Athanasios},
  journal={arXiv preprint arXiv:2106.07734},
  year={2021}
}

@inproceedings{moriya2020self,
  title={Self-Distillation for Improving CTC-Transformer-Based ASR Systems.},
  author={Moriya, Takafumi and Ochiai, Tsubasa and Karita, Shigeki and Sato, Hiroshi and Tanaka, Tomohiro and Ashihara, Takanori and Masumura, Ryo and Shinohara, Yusuke and Delcroix, Marc},
  booktitle={INTERSPEECH},
  pages={546--550},
  year={2020}
}

@article{jiao2019tinybert,
  title={Tinybert: Distilling bert for natural language understanding},
  author={Jiao, Xiaoqi and Yin, Yichun and Shang, Lifeng and Jiang, Xin and Chen, Xiao and Li, Linlin and Wang, Fang and Liu, Qun},
  journal={arXiv preprint arXiv:1909.10351},
  year={2019}
}

@inproceedings{kim2019knowledge,
  title={Knowledge distillation using output errors for self-attention end-to-end models},
  author={Kim, Ho-Gyeong and Na, Hwidong and Lee, Hoshik and Lee, Jihyun and Kang, Tae Gyoon and Lee, Min-Joong and Choi, Young Sang},
  booktitle={ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6181--6185},
  year={2019},
  organization={IEEE}
}ƒ

@article{pang2018compression,
  title={Compression of end-to-end models},
  author={Pang, Ruoming and Sainath, Tara and Prabhavalkar, Rohit and Gupta, Suyog and Wu, Yonghui and Zhang, Shuyuan and Chiu, Chung-Cheng},
  year={2018}
}

@inproceedings{sheikh2020semi,
  title={On semi-supervised LF-MMI training of acoustic models with limited data},
  author={Sheikh, Imran and Vincent, Emmanuel and Illina, Irina},
  booktitle={INTERSPEECH 2020},
  year={2020}
}

@article{yu2020dual,
  title={Dual-mode asr: Unify and improve streaming asr with full-context modeling},
  author={Yu, Jiahui and Han, Wei and Gulati, Anmol and Chiu, Chung-Cheng and Li, Bo and Sainath, Tara N and Wu, Yonghui and Pang, Ruoming},
  journal={arXiv preprint arXiv:2010.06030},
  year={2020}
}

@article{dawalatabad2022two,
  title={Two-Pass End-to-End ASR Model Compression},
  author={Dawalatabad, Nauman and Vatsal, Tushar and Gupta, Ashutosh and Kim, Sungsoo and Singh, Shatrughan and Gowda, Dhananjaya and Kim, Chanwoo},
  journal={arXiv preprint arXiv:2201.02741},
  year={2022}
}

@article{kurata2019guiding,
  title={Guiding CTC posterior spike timings for improved posterior fusion and knowledge distillation},
  author={Kurata, Gakuto and Audhkhasi, Kartik},
  journal={arXiv preprint arXiv:1904.08311},
  year={2019}
}
@inproceedings{takashima2018investigation,
  title={An investigation of a knowledge distillation method for CTC acoustic models},
  author={Takashima, Ryoichi and Li, Sheng and Kawai, Hisashi},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5809--5813},
  year={2018},
  organization={IEEE}
}

@article{yu2021dual,
  title={Dual-mode ASR: Unify and improve streaming ASR with full-context modeling},
  author={Yu, Jiahui and Han, W and Gulati, A and Chiu, Chung-Cheng and Li, Bo and Sainath, Tara N and Wu, Yonghui and Pang, Ruoming},
  journal={Proceedings of ICLR},
  year={2021}
}

@article{kojima21_interspeech,
  author={Atsushi Kojima},
  title={Knowledge Distillation for Streaming Transformer–Transducer},
  year={2021},
  booktitle={Proc. Interspeech 2021},
  pages={2841--2845},
  doi={10.21437/Interspeech.2021-175}
}

@article{moritz2021dual,
  title={Dual Causal/Non-Causal Self-Attention for Streaming End-to-End Speech Recognition},
  author={Moritz, Niko and Hori, Takaaki and Roux, Jonathan Le},
  journal={arXiv preprint arXiv:2107.01269},
  year={2021}
}

@inproceedings{manohar2018teacher,
  title={A teacher-student learning approach for unsupervised domain adaptation of sequence-trained ASR models},
  author={Manohar, Vimal and Ghahremani, Pegah and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2018 IEEE Spoken Language Technology Workshop (SLT)},
  pages={250--257},
  year={2018},
  organization={IEEE}
}

@article{sun2019patient,
  title={Patient knowledge distillation for bert model compression},
  author={Sun, Siqi and Cheng, Yu and Gan, Zhe and Liu, Jingjing},
  journal={arXiv preprint arXiv:1908.09355},
  year={2019}
}


@inproceedings{kurata2018improved,
  title={Improved knowledge distillation from bi-directional to uni-directional LSTM CTC for end-to-end speech recognition},
  author={Kurata, Gakuto and Audhkhasi, Kartik},
  booktitle={2018 IEEE Spoken Language Technology Workshop (SLT)},
  pages={411--417},
  year={2018},
  organization={IEEE}
}

@inproceedings{kurata2020knowledge,
  title={Knowledge Distillation from Offline to Streaming RNN Transducer for End-to-End Speech Recognition.},
  author={Kurata, Gakuto and Saon, George},
  booktitle={Interspeech},
  pages={2117--2121},
  year={2020}
}

@inproceedings{lu2017knowledge,
  title={Knowledge distillation for small-footprint highway networks},
  author={Lu, Liang and Guo, Michelle and Renals, Steve},
  booktitle={2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={4820--4824},
  year={2017},
  organization={IEEE}
}

@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={29},
  pages={3451--3460},
  year={2021},
  publisher={IEEE}
}

@article{baevski2022data2vec,
  title={Data2vec: A general framework for self-supervised learning in speech, vision and language},
  author={Baevski, Alexei and Hsu, Wei-Ning and Xu, Qiantong and Babu, Arun and Gu, Jiatao and Auli, Michael},
  journal={arXiv preprint arXiv:2202.03555},
  year={2022}
}

@inproceedings{chang2022distilhubert,
  title={DistilHuBERT: Speech representation learning by layer-wise distillation of hidden-unit BERT},
  author={Chang, Heng-Jui and Yang, Shu-wen and Lee, Hung-yi},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7087--7091},
  year={2022},
  organization={IEEE}
}

@article{lee2022fithubert,
  title={FitHuBERT: Going Thinner and Deeper for Knowledge Distillation of Speech Self-Supervised Learning},
  author={Lee, Yeonghyeon and Jang, Kangwook and Goo, Jahyun and Jung, Youngmoon and Kim, Hoirin},
  journal={arXiv preprint arXiv:2207.00555},
  year={2022}
}
@article{wang2022lighthubert,
  title={LightHuBERT: Lightweight and Configurable Speech Representation Learning with Once-for-All Hidden-Unit BERT},
  author={Wang, Rui and Bai, Qibing and Ao, Junyi and Zhou, Long and Xiong, Zhixiang and Wei, Zhihua and Zhang, Yu and Ko, Tom and Li, Haizhou},
  journal={arXiv preprint arXiv:2203.15610},
  year={2022}
}
@INPROCEEDINGS{9688009,
  author={Deng, Keqi and Cao, Songjun and Zhang, Yike and Ma, Long},
  booktitle={2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)}, 
  title={Improving Hybrid CTC/Attention End-to-End Speech Recognition with Pretrained Acoustic and Language Models}, 
  year={2021},
  volume={},
  number={},
  pages={76-82},
  doi={10.1109/ASRU51503.2021.9688009}}
