%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%\documentclass[referee,sn-basic]{sn-jnl}% referee option is meant for double line spacing

%%=======================================================%%
%% to print line numbers in the margin use lineno option %%
%%=======================================================%%

%%\documentclass[lineno,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%======================================================%%
%% to compile with pdflatex/xelatex use pdflatex option %%
%%======================================================%%

%%\documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%\documentclass[sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style
\documentclass[sn-mathphys]{sn-jnl}% Math and Physical Sciences Reference Style
%%\documentclass[sn-aps]{sn-jnl}% American Physical Society (APS) Reference Style
%%\documentclass[sn-vancouver]{sn-jnl}% Vancouver Reference Style
%%\documentclass[sn-apa]{sn-jnl}% APA Reference Style
%%\documentclass[sn-chicago]{sn-jnl}% Chicago-based Humanities Reference Style
%%\documentclass[sn-standardnature]{sn-jnl}% Standard Nature Portfolio Reference Style
%%\documentclass[default]{sn-jnl}% Default
%%\documentclass[default,iicol]{sn-jnl}% Default with double column layout

%%%% Standard Packages
%%<additional latex packages if required can be included here>
%%%%

%%%%%=============================================================================%%%%
%%%%  Remarks: This template is provided to aid authors with the preparation
%%%%  of original research articles intended for submission to journals published
%%%%  by Springer Nature. The guidance has been prepared in partnership with
%%%%  production teams to conform to Springer Nature technical requirements.
%%%%  Editorial and presentation requirements differ among journal portfolios and
%%%%  research disciplines. You may find sections in this template are irrelevant
%%%%  to your work and are empowered to omit any such section if allowed by the
%%%%  journal you intend to submit to. The submission guidelines and policies
%%%%  of the journal take precedence. A detailed User Manual is available in the
%%%%  template package for technical guidance.
%%%%%=============================================================================%%%%

\jyear{2021}%

%% as per the requirement new theorem styles can be included as shown below
\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}%  meant for continuous numbers
%%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
\newtheorem{corollary}[theorem]{Corollary}%
%%\newtheorem{proposition}{Proposition}% to get separate numbers for theorem and proposition etc.

\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%

\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}%

%\theoremstyle{thmstylefour}%
%\newtheorem{corollary}{Corollary}

\raggedbottom
%%\unnumbered% uncomment this for unnumbered level heads

\begin{document}

\title[Barycentric Interpolation Based on Equilibrium Potential]{Barycentric Interpolation Based on Equilibrium Logarithmic Potential}

%%=============================================================%%
%% Prefix	-> \pfx{Dr}
%% GivenName	-> \fnm{Joergen W.}
%% Particle	-> \spfx{van der} -> surname prefix
%% FamilyName	-> \sur{Ploeg}
%% Suffix	-> \sfx{IV}
%% NatureName	-> \tanm{Poet Laureate} -> Title after name
%% Degrees	-> \dgr{MSc, PhD}
%% \author*[1,2]{\pfx{Dr} \fnm{Joergen W.} \spfx{van der} \sur{Ploeg} \sfx{IV} \tanm{Poet Laureate}
%%                 \dgr{MSc, PhD}}\email{iauthor@gmail.com}
%%=============================================================%%

\author [1]{\fnm{Kelong} \sur{Zhao}}\email{clonezhao.1994@gmail.com}

\author *[2]{\fnm{Shuhuang} \sur{Xiang}}\email{xiangsh@mail.csu.edu.cn}

\affil[1]{\orgdiv{School of Mathematics and Statistics}, \orgname{Central South University}, \orgaddress{\city{Changsha}, \postcode{410083}, \state{Hunan}, \country{People's Republic of China}}}

\affil[2]{\orgdiv{School of Mathematics and Statistics}, \orgname{Central South University}, \orgaddress{\city{Changsha}, \postcode{410083}, \state{Hunan}, \country{People's Republic of China}}}

%%==================================%%
%% sample for unstructured abstract %%
%%==================================%%

\abstract{A novel barycentric interpolation algorithm with a
specific exponential convergence rate is designed for analytic functions defined on the complex plane, with singularities located near the interpolation region, where the region is compact and can be disconnected or multiconnected. The core of the method is the efficient computation of the interpolation nodes and poles using discrete distributions that approximate the equilibrium logarithmic potential, achieved by solving a Symm's integral equation.
It takes different
strategies to distribute the poles for isolated singularities and branch points, respectively.
In particular, if poles are not considered, it derives a polynomial interpolation with exponential convergence.
Numerical experiments illustrate the superior performance of the proposed method. }

%%================================%%
%% Sample for structured abstract %%
%%================================%%

% \abstract{\textbf{Purpose:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
%
% \textbf{Methods:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
%
% \textbf{Results:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
%
% \textbf{Conclusion:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.}

%%\keywords{barycentric interpolation formula, rational approximation, polynomial approximation, potential theory}

%%\pacs[JEL Classification]{D8, H51}

\pacs[MSC Classification]{30C10, 30E10, 41A20, 65E05}

\maketitle
%==============================================================================================================
\section{Introduction} \label{sec:int}
Interpolation is one of the most fundamental and commonly used tools in scientific computing, and polynomial interpolation serves as a basic method of approximation across a wide range of numerical analysis \cite{Dah2007,Trefethen2013}. The barycentric polynomial interpolation formula of the second kind with degree $n$,
\begin{equation} \label{eq:1.1p}
  p(x)={\sum\limits_{k=0}^{n}\dfrac{w_k}{x-x_k}f(x_k)}\Big/{\sum\limits_{k=0}^{n}\dfrac{w_k}{x-x_k}}, \,\, w_k=C/\prod_{j=0,j\ne k}^n(x_k-x_j),\,\, C\not=0
\end{equation}
provides a fast and stable algorithm in approximation \cite{Berrut2004,Higham2004}.
Here, $f$ represents the function being approximated,  $\{w_k\}_{k=0}^n$ and distinct points $\{x_k\}_{k=0}^n$ are two sets associated with the weights and nodes, respectively.

The barycentric interpolant (\ref{eq:1.1p}) is uniquely determined by $\{(x_k,f(x_k))\}_{k=0}^n$ and can be done in a few lines of code by
Chebfun \cite{Driscoll2014} to get exponential convergence if $f$ is analytic in a neighborhood of the
interpolation region $E$ when $E$ is an interval and $\{x_k\}_{k=0}^n\subset E$ are chosen to be the roots of orthogonal polynomials \cite{XCW2010,STW2011,Trefethen2013,X2012,WX2012,XWZ2013,WHV2014,X2016}.
However, when the interpolation region $E$ is not a line segment, or the singularities of $f$ are close to $E$, the choice of the interpolation nodes may become difficult, and in these cases, barycentric rational interpolation may provide much faster convergence rates when compared to the polynomial analogues.%polynomial approximation.

From the barycentric polynomial formula \eqref{eq:1.1p}, it is easy to obtain a rational interpolation form
\begin{equation} \label{eq:1.1a}
r(x)={\sum\limits_{k=0}^{n}\dfrac{w_kf_k}{x-x_k}}\Big/{\sum\limits_{k=0}^{n}\dfrac{w_k}{x-x_k}},\quad f_k=f(x_k), \quad w_k\ne 0,
\end{equation}
which was first proposed by Schneider and Werner in 1986 \cite{Schneider1986}\footnote{If $w_k=C/\prod_{j=0,j\ne k}^n(x_k-x_j)$, the interpolant $r(x)$ \eqref{eq:1.1a} degenerates to a polynomial interpolant.}. From \eqref{eq:1.1a}, we see that the weights $\{w_k\}$ can be independent of $\{x_k\}$. Thus, the rational case has $n$ additional degrees of freedom and is more flexible and robust compared with the polynomial case \eqref{eq:1.1p}.

The initial exploration of barycentric rational interpolation started with special weights
to avoid poles as well as unreachable points in the interpolated region, see Berrut \cite{Berrut1988}.
Another  efficient approach is the Floater-Hormann scheme \cite{Floater2007,Guttel2012}  by blending local approximations to form a global
one to obtain high orders for smooth functions.
These methods only rely on the choice of $\{x_k\}$ in the interval $E$, where $\{w_k\}$ are selected in special ways \cite{Berrut2014}.

For analytic function $f(x)\in \mathcal{A}([-1,1])$ with singularities near the interpolation interval,
more targeted methods are available if these singularities are known.
Tee and Trefethen \cite{Tee2006} constructed
a conformal mapping to handle the case where there are a pair of conjugate singularities.
For functions with more singularities, Hale and Tee \cite{Hale2009} utilized the special geometry
of the slit regions to enable the use of the Schwarz-Christoffel mapping.
These methods expand the Bernstein ellipse of $f\circ g$  by constructing a conformal
mapping $g$, then the rational interpolation at nodes $\{g(x_k)\}$ satisfies
$O(\lvert r[f]-f\rvert)=O(\lvert p[f\circ g]-f\circ g\rvert)$ \cite{Baltensperger1999}, which ensures faster
exponential convergence. The poles play an important role in these methods.

To make better use of the extra $n$ degrees of freedom,
an extremely powerful AAA (adaptive-Antoulas-Anderson) method  has been recently developed \cite{Nakatsukasa2018}
 for interpolation region $E$ in the complex plane.
Given a finite sample set $Z\subseteq\mathbb{C}$ and $f(z)$ for all $z\in Z$,
the AAA method selects some of these points as interpolation nodes in a greedy manner,
while the remaining points are used as support points to determine the weights $\{w_k\}$.
Since this method is without any restriction on the sample set $Z$, it can be
applied to various cases on the complex plane. However, the AAA method does not provide guidance
on how to choose the sample points. Therefore, to obtain a better approximation of the function $f$ as
a whole, a large number of sample points may be required.

It is worthy of noting that
the rational function $r_{n,m}$ ($m\le n$)
can always be rewritten as $r_{n,m}(x)=p_n(x)/q_m(x)$ with $q_m(x)=\prod_{i=1}^m(x-z_i)$ if the poles $\{z_i\}_{i=1}^m$ are given. In addition,
the numerator and the denominator can be
expressed as $n$-degree barycentric polynomial forms
\begin{align*}
  &p_n(x)=\dfrac{\sum\limits_{k=0}^{n}\dfrac{\lambda_k}{x-x_k}p_n(x_k)}{\sum\limits_{k=0}^{n}\dfrac{\lambda_k}{x-x_k}},\,
  q_m(x)=\dfrac{\sum\limits_{k=0}^{n}\dfrac{\lambda_k}{x-x_k}q_m(x_k)}{\sum\limits_{k=0}^{n}\dfrac{\lambda_k}{x-x_k}}, \,
  \lambda_k=\prod_{j=0,j\ne k}^n\dfrac{1}{x_k-x_j},
\end{align*}
then $r_{n,m}$ can be represented as
\begin{align*}
  r_{n,m}(x)
  ={\sum\limits_{k=0}^{n}\dfrac{\lambda_k p_n(x_k)}{x-x_k}}\Big/{\sum\limits_{k=0}^{n}\dfrac{\lambda_k q_m(x_k)}{x-x_k}}
  ={\sum\limits_{k=0}^{n}\dfrac{w_k}{x-x_k}r_{n,m}(x_k)}\Big/{\sum\limits_{k=0}^{n}\dfrac{w_k}{x-x_k}},
\end{align*}
where
\begin{equation*} \label{eq:1.1b}
  w_k = C \dfrac{\prod_{i=1}^m(x_k-z_i)}{\prod_{j=0,j\ne k}^n(x_k-x_j)}
\end{equation*}
and $C$ is a non-zero constant \cite{Berrut1997}. If the interpolation nodes $\{x_j\}$ and poles $\{z_i\}$  are determined and $r_{n,m}(x_k)=f_k$,
then the rational interpolation can be represented as
\begin{equation} \label{eq:1.1c}
  r_{n,m}(x)=\sum\limits_{k=0}^{n}\dfrac{w_kf_k}{x-x_k}\Big/{\sum\limits_{k=0}^{n}\dfrac{w_k}{x-x_k}},
  \,\,  w_k = C \dfrac{\prod_{i=1}^m(x_k-z_i)}{\prod_{j=0,j\ne k}^n(x_k-x_j)},\,\, C\not=0.
\end{equation}
The rational interpolant \eqref{eq:1.1c} degenerates to a polynomial if the poles $\{z_i\}$ are not considered.

The effectiveness of (\ref{eq:1.1c}) is contingent on the provision of $n+1$ interpolation nodes and $m$ poles, distributed in a thoughtful manner. An arbitrary placement of these nodes and poles could result in a build-up of rounding errors and sluggish convergence.

In this paper, we introduce a novel method for efficiently and directly determining the nodes and poles of the rational interpolation \eqref{eq:1.1c}. The new approach is established by  utilizing a particular discrete density approximation  based on the equilibrium logarithmic potential, which involves solving a Symm's integral equation.
The new method guarantees exponential convergence when approximating analytic
functions
$f\in\mathcal{A}(E)$, where $E$ is a compact set in the complex plane with a piecewise-smooth boundary $\partial E$.

Figure \ref{fig:3.1} depicts the proposed method's application to approximate  $f\in\mathcal{A}(E)$  without accounting for poles (i.e., \eqref{eq:1.1c} is an interpolation polynomial) in the `lollipop' and `ice cream cone' regions, respectively. The first row of Figure \ref{fig:3.1} displays the distribution of the $201$ polynomial interpolation nodes, while the second row shows the absolute errors of the polynomial interpolation for analytic functions $f(z)=e^{z^2}$, $\frac{1}{2+z^2}$, and $\frac{1}{3+2z^2}$ in the `lollipop', and $f(z)=e^{z^2}$, $\frac{1}{1-z^2}$, and $\frac{1}{z^2}$ in the `ice cream cone', respectively.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.9\linewidth]{fig1.eps}
  \caption{Potential contours of the nodes ($n=200$) and absolute errors of polynomial interpolation are shown for $n=5:5:200$ in the `lollipop' (left column) and `ice cream cone' (right column) domains.}
  \label{fig:3.1}
\end{figure}

For $f\in\mathcal{A}(E)$ with singularities near $E$, rational interpolation with prescribed poles is much better than polynomial interpolation, especially when the location and type of singularities near $E$ are known. To construct the rational interpolant (\ref{eq:1.1c}) with exponential convergence, we set a compact region $F$ that is disjoint with $E$, then obtain a discrete distribution that approximate the equilibrium logarithmic
potential and   find the interpolated nodes on $\partial E$ and poles on the piecewise-smooth boundary $\partial F$. See Figure \ref{fig:0.1b} for illustrations.
\begin{figure}[hpbt]
  \centering
  \includegraphics[width=0.55\linewidth]{fig2.eps}
  \caption{By our method, the nodes (blue) and poles (red) are selected on $\partial E$ and $\partial F$, respectively. These nodes $\{x_i\}_{i=0}^n$ and poles $\{z_j\}_{j=1}^m$ make the discrete potential $U(z)=\frac{1}{n+1}(\sum_{i=0}^{n}\log\frac{1}{\left\lvert z-x_i\right\rvert}-\sum_{j=1}^{m}\log\frac{1}
  {\left\lvert z-z_j\right\rvert})$ almost constant on $E$ and $F$. Therefore, the interior of $E$ and $F$ is almost blank in the contour map of the potential $U$.}
  \label{fig:0.1b}
\end{figure}

Figure \ref{fig:8} illustrates the rational interpolation approximation of $f(z) = [(z^2-0.25)/(z^2-0.01)]^{0.5}$ using the proposed method in a disconnected region $E$. We compare the results with the AAA method using $10^4$ random sample points and the polynomial interpolation \eqref{eq:1.1c} without consideration of $F$. The region $E$ is comprised of a circle and a trapezoid, with the center and radius of the circle being $-0.25+0.16i$ and $0.15$, respectively. The four vertices of the trapezoid are $[0.4-0.4i,-0.02i,-0.4-0.02i,-0.4-0.4i]$, and $f$ has four branch points and two branch cuts, one of which is between the circle and the trapezoid. For the rational interpolation \eqref{eq:1.1c}, we select $F=[-0.5, -0.1]\cup[0.1, 0.5]$.

The convergence of the three methods are presented on the left side of Figure \ref{fig:8}, while the nodes, poles, and corresponding potential contours for the rational interpolation based on equilibrium potential are shown on the right side, with $n=200$. With the proposed method, $f$ can be approximated to machine precision.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.95\linewidth]{fig3.eps}
  \caption{Left: Absolute errors for $n=5:5:200$. Right:
   The local potential contour with nodes (blue) and poles (red) of $n=200$.
  }
  \label{fig:8}
\end{figure}

In addition, the family of interpolation point sets $\{x_i^{(n)}\}_{i=0}^n\subseteq \partial E$ ($n=1,2,\ldots$)  obeys a density function $w$\,$(w>0)$ of a unit measure $\mu$ on $\partial E$ and satisfies
\[
  \lim_{n\to\infty}\max_{1\leq i\leq n}\lvert x_{i-1}^{(n)}-x_i^{(n)}\rvert = 0.
\]
Moreover, the corresponding discrete density measure $\mu_{n+1}$ fulfils
\[
  \lim_{n\to\infty}\int g \, \mathrm{d}\mu_{n+1}=\int g \, \mathrm{d}\mu
\]
for arbitrary continuous function $g$ on $\partial E$, where $\mu_{n+1} = 1/(n+1)\sum_{i=0}^{n}\delta_{x_i}$ and
$\delta_{z}$ denotes the Dirac measure at $z$.
%a prerequisite for the stability of rational interpolation. Precisely, the equilibrium potential generated by the interpolated nodes and poles must remain unchanged throughout the interpolation region $E$. Otherwise, the Lebesgue constant will experience exponential growth.

The rest of this paper is organized as follows.
In Section \ref{sec:theory}, we analyze the exponential convergence of the rational interpolation method consistent with the equilibrium potential. Section \ref{sec:algorithm} details the implementation and algorithms of the rational interpolation, while Section \ref{sec:experiments} demonstrates the effectiveness of the method through various numerical examples.
%From a theoretical perspective, Section \ref{sec:stable} presents necessary conditions for slow growth of the Lebesgue constant.
We further discuss on the choice of $F$
in Section \ref{sec:discu}, and present some concluding remarks in Section \ref{sec:conclusion}.

The numerical examples throughout this paper are implemented using Matlab on a laptop with an Intel(R) Core(TM) processor and 8 GB of RAM, and
the absolute error refers to the uniform norm error $\|f-r_{n,m}\|_{\infty}$ over a sufficiently large number of representative sample points on $E$.
Specifically, these points used to estimate the error are mainly distributed on the boundary of $E$ and more points
will be placed on the boundary near the singularities. Except for the simplest case $E=[-1,1]$, we test the error
on $-1:0.00001:1$.
%===============================================================================================================
\section{Potential theory and convergence} \label{sec:theory}

\subsection{Potential theory in polynomial approximation} \label{sec:2.1}

To avoid the Runge phenomenon, polynomial interpolation is made consistent with equilibrium potential \cite{Berrut2004,Trefethen2013}.
For Lagrange interpolation, the error is expressed as an integral via the Hermite integral formula.
\begin{theorem}[Hermite integral formula \cite{Walsh1965, Trefethen2013}] \label{thm:phif}
  Let $P_n$ be a polynomial interpolation of function $f$
  on distinct points $x_0,x_1,...,x_n\in E$, and $E$ is a compact set. If $f$ is
  analytic in the region $\Omega$ including $E$, then for any closed
  curve $\Gamma$ in $\Omega$ strictly containing $E$, and $x$ is enclosed by $\Gamma$, the following identity is satisfied
  \begin{equation} \label{eq:1a}
    f(x)-P_n(x) = \frac{1}{2\pi i} \int_{\Gamma} \frac{l_{n+1}(x)}{l_{n+1}(t)} \frac{f(t)}{(t-x)}\, \mathrm{d}t,
  \end{equation}
  where $l_{n+1}(x) = \prod_{i=0}^{n}(x-x_i)$.
\end{theorem}

At the right-hand side of (\ref{eq:1a}), ${l_{n+1}(x)}/{l_{n+1}(t)}$ is related to the choice of interpolation points and independent of $f$. If the analytic function $f$ is given and define
\begin{equation*}
\left\lVert g\right\rVert _{\Delta}=\sup_{t\in\Delta}\left\lvert g(t)\right\rvert,\quad \Delta\subseteq \mathbb{C},
\end{equation*}
then the asymptotic error of its polynomial interpolation can be completely controlled by the value of the ratio
\begin{equation} \label{eq:1b}
\left\lvert f(x)-P_n(x)\right\rvert \leq M \left\lVert l_{n+1}\right\rVert _E \left\lVert\frac{1}{l_{n+1}}\right\rVert _{\Gamma},\ x\in E,
\end{equation}
where $M = 1/(2\pi)\sup_{x\in E}\int\left\lvert f(t)/(t-x)\right\rvert\, \mathrm{d}\nu_\Gamma(t)$, $\nu_\Gamma$ is a measure that satisfies $\nu_\Gamma(S)=\left\lvert S\cap\Gamma\right\rvert _L$ for all $S\subseteq\mathbb{C}$, and $\left\lvert S\cap\Gamma\right\rvert _L$ denotes the length of $S\cap\Gamma$.
For simplicity of expression, we use $\int_{\Gamma} \,\lvert\mathrm{d}t\rvert$ to denote $\int\,\mathrm{d}\nu_\Gamma(t)$ if it does not create confusion.

From \eqref{eq:1b}, the interpolation error can be estimated by a logarithmic potential \cite{Trefethen2013,Levin&Saff2006,Saff1997}.

\begin{definition}[Logarithmic Potential \cite{Levin&Saff2006}]
  Let $\mathcal{M}(E)$ be the set of all unit measures on the region $E$.
  For any measure $\mu \in \mathcal{M}(E)$,  $U^{\mu}(z) = \int_E-\log{\left\lvert z-t\right\rvert }\, \mathrm{d}\mu(t)$
  is the logarithmic potential function with respect to $\mu$.
\end{definition}

Let  $\mu_{n+1}$ be defined by $\mu_{n+1} = 1/(n+1)\sum_{i=0}^{n}\delta_{x_i}$.
Then it follows
\[
  \left\lvert l_{n+1}(x)\right\rvert = [\exp(-U^{\mu_{n+1}}(x))]^{n+1},\, x\in E;\, \left\lvert l_{n+1}(t)\right\rvert = [\exp(-U^{\mu_{n+1}}(t))]^{n+1},\,t\in \Gamma,
\]
and from (\ref{eq:1b}), we have
\begin{equation} \label{eq:1c}
  \left\lvert f(x)-P_n(x)\right\rvert \leq
  M[\exp(\left\lVert U^{\mu_{n+1}}\right\rVert _\Gamma -\inf_{x\in E} \lvert U^{\mu_{n+1}}(x)\rvert)]^{n+1}.
\end{equation}
Thus, suppose that $\mu_E\in \mathcal{M}(E)$ is an equilibrium measure and  $U^{\mu_E}(x)=C$ for $x\in E$, and that $\mu_{n+1}\Rightarrow \mu_E$, i.e.,
$\lim_{n\to\infty}\int_E g d\mu_{n+1}=\int_E g d\mu$ for all continuous function $g$ on $E$,
then it indicates
\begin{equation*}
\limsup _{n\to\infty} \left\lvert f(x)-P_n(x)\right\rvert^{\frac{1}{n+1}}\leq \exp(\left\lVert U^{\mu_{n+1}}\right\rVert _\Gamma -C), \quad x\in E,
\end{equation*}
and deduces
\begin{equation} \label{eq:1d}
\limsup _{n\to\infty} \left\lvert f(x)-P_n(x)\right\rvert^{\frac{1}{n+1}}\leq \rho, \quad x\in E,
\end{equation}
where $\rho = \exp(\inf\limits_\Gamma\left\lVert U^{\mu_E}\right\rVert _\Gamma-C)$.
Interestingly, the equilibrium potential $U^{\mu_E}(z)$ takes the maximum value $C$ on $E$ \cite{Levin&Saff2006,Saff1997}. In
particular, from the definition of $U^{\mu_E}(z)$, the farther $z$ is from $E$, the smaller is the value of its potential function $U^{\mu_E}(z)$.
Then $\rho <1$ and the polynomial interpolation satisfying $\mu_{n+1}\Rightarrow \mu_E$ converges at an exponential rate.

%===============================================================================================================
\subsection{Exponential convergence of rational interpolation of type (n, m)}\label{sec:2.2}
Analogous to the polynomial interpolation, we present an exponential convergence of rational interpolation that is consistent with equilibrium potential via Hermite integral.
Hermite integral formula for rational interpolation was introduced in Walsh \cite[$\aleph 8.1$, Chapter 8]{Walsh1965}.

\begin{theorem}(Hermite intergral formula for rational \cite[Theorem 2, P. 186]{Walsh1965})
  Let $\mathcal{C}$ be a closed limited region or several  closed limited regions whose boundary   $\Gamma $ consists of a finite number of
  non-intersecting rectifiable Jordan curves, let the points $x_0,\cdots,x_n$ lie interior to $\mathcal{C}$,
  and let $f$ be analytic in $\mathcal{C}$. If  $r(z)$ denotes the rational function of degree $n$ whose poles  lie in the points
   $z_1,\dots,z_n$, and which interpolates to $f(z)$ in  $\{x_i\}_{i=0}^n$, distinct from $\{z_i\}_{i=1}^n$. Then we have for any $x\in \mathcal{C}$ and $x\not= z_i$,
  \begin{equation}\label{eq:2a0}
    f(x)-r(x)=\frac{1}{2\pi i}\int_{\Gamma} \frac{\prod_{i=0}^n(x-x_i)\prod_{j=1}^n(t-z_i)}{\prod_{i=0}^n(t-x_i)\prod_{j=1}^n(x-z_i)}\frac{f(t)}{t-x}\, \mathrm{d}t.
  \end{equation}
\end{theorem}

In \eqref{eq:2a0}, points  $z_i$ may lie in $\mathcal{C}$ and of course points  $z_i$  may be infinite; in the latter case, the factors containing $z_i$   in \eqref{eq:2a0}
are simply to be omitted \cite[P. 186]{Walsh1965}. Then it directly leads to the following result.

\begin{corollary}\label{thm:rhif}
  Let $E$ be a compact set in $\mathbb{C}$ whose boundary   $\partial E $ consists of a finite number of
  non-intersecting rectifiable Jordan curves and is piecewise-smooth, strictly bounded by a closed curve $\Gamma $,
  and let $f$ be analytic in $E$ and  can be extended continuously to $\Gamma$. Suppose $r_{n,m}$ \eqref{eq:1.1c} is the rational function with simple poles
  at $\{z_j\}_{j=1}^m$ ($m\le n$) that interpolates $f$ at distinct points $\{x_i\}_{i=0}^n$. Then for any $x\in E$,
  \begin{equation}\label{eq:2a}
    f(x)-r_{n,m}(x)=\frac{1}{2\pi i}\int_{\Gamma} \frac{\phi_{n+1,m}(x) }{\phi_{n+1,m}(t)}\frac{f(t)}{t-x}\, \mathrm{d}t,
  \end{equation}
  where
  \[
    \phi_{n+1,m}(x) = \prod\limits_{i=0}^n(x-x_i)/\prod\limits_{j=1}^m(x-z_j).
  \]
\end{corollary}

Similar to (\ref{eq:1b}), we have
\begin{equation}\label{eq:2b}
	\left\lvert f(x)-r_{n,m}(x)\right\rvert \leq M \left\lVert\phi_{n+1,m}\right\rVert _{E} \left\lVert\frac{1}{\phi_{n+1,m}}\right\rVert _{\Gamma}
	, \quad  x\in E.
\end{equation}


To get exponential convergence of the rational interpolation \eqref{eq:1.1c}, we will choose a compact set $F$ with piecewise smooth boundary $\partial F$ such that $E$ and $F$ are disjoint.

Suppose $\mu_E$ and $\mu_F$ are two positive measures on $E$ and $F$, respectively, and satisfy $\mu_E(E)=1$ and $\mu_F(F)=\gamma$, where $0<\gamma<1$. Define a signed measure $\mu[E,F,\gamma]$ on $(E, F)$ as $\mu[E,F,\gamma](S) = \mu_E(S)-\mu_F(S)$ for all $S\subseteq\mathbb{C}$,
and the logarithmic potential of the signed measure as
\[
	U^{\mu[E,F,\gamma]}(z) = \int\log\frac{1}{\left\lvert z-t\right\rvert}\, \mathrm{d}\mu_E(t)-\int\log\frac{1}{\left\lvert z-t\right\rvert}\, \mathrm{d}\mu_F(t).
\]
Let the discrete measure $\mu_{n+1,m}=\mu[\{x_k^{(n)}\}_{k=0}^n,\{z_i^{(n)}\}_{k=1}^m,\frac{m}{n+1}]$ be defined by
\begin{equation}\label{eq:2c}
  \mu_{n+1,m} = \frac{1}{n+1}\sum_{k=0}^n\delta_{x_k^{(n)}}-\frac{1}{n+1}\sum_{k=1}^m\delta_{z_k^{(n)}}
\end{equation}
with $\{x_k^{(n)}\}_{k=0}^n\in \partial E$ and $\{z_k^{(m)}\}_{k=1}^m\in \partial F$, respectively.
It is easy to show that $\left\lvert \phi_{n+1,m}(z)\right\rvert^{\frac{1}{n+1}} = \exp(-U^{\mu_{n+1,m}}(z))$,
and the error (\ref{eq:2b}) can be expressed as
\begin{equation}\label{eq:2d}
  \left\lvert f(x)-r_{n,m}(x)\right\rvert \leq M \left[\exp(\left\lVert U^{\mu_{n+1,m}}\right\rVert _{\Gamma} -\inf_{x\in E}\lvert U^{\mu_{n+1,m}}(x)\rvert)\right]^{n+1},\ x\in E.
\end{equation}

Suppose $\mathrm{supp}(\mu_E)=\partial E$, $\mathrm{supp}(\mu_F)=\partial F$, and $\mu[E,F,\gamma]$ satisfies
\begin{equation}\label{eq:2e}
  U^{\mu[E,F,\gamma]}(z) = \begin{cases}
    c_1, & z\in E\\
    -c_2, & z\in F
  \end{cases},\quad c_1>-c_2,
\end{equation}
and
\begin{equation}\label{eq:2h}
  \mu_{n+1,m}=\mu\left[\{x_k^{(n)}\}_{k=0}^n,\{z_k^{(m)}\}_{k=1}^m,\frac{m}{n+1}\right]\Rightarrow \mu[E,F,\gamma],\ \frac{m}{n+1}\to\gamma,\ n\to\infty,
\end{equation}
then by (\ref{eq:2d}), we have for $x\in E$ that
\begin{equation*}
  \limsup_{n\to\infty} \left\lvert f(x)-r_{n,m}(x)\right\rvert^{\frac{1}{n+1}} \leq {\exp\left(\left\lVert U^{\mu[E,F,\gamma]}(t)\right\rVert _{\Gamma}-c_1\right)},
\end{equation*}
and consequently
\begin{equation}\label{eq:2f}
  \limsup_{n\to\infty} \left\lvert f(x)-r_{n,m}(x)\right\rvert^{\frac{1}{n+1}} \leq {\exp\left(\inf_{\Gamma}\left\lVert U^{\mu[E,F,\gamma]}(t)\right\rVert _{\Gamma}-c_1\right)}.
\end{equation}

\begin{itemize}
\item In the case that $f$ can be continued analytically to $\mathbb{C}\backslash F$:
From $\left\lvert\phi_{n+1,m}(z)\right\rvert\to+\infty$ as $\left\lvert z\right\rvert\to\infty$, we have
$U^{\mu_{n+1,m}}(z)\to-\infty$ as $\left\lvert z\right\rvert\to\infty$. Consequently, for sufficiently large $n$,
we can always find $\Gamma$ around $E$ disjoint $F$ satisfying $U^{\mu[E,F,\gamma]}$
equal to $\varepsilon-c_2$ on $\Gamma$ for arbitrary $\varepsilon>0$.
Then it yields $\inf_{\Gamma}\left\lVert U^{\mu[E,F,\gamma]}(t)\right\rVert _{\Gamma}=-c_2$ and
\begin{equation}\label{eq:2g}
  \limsup_{n\to\infty} \left\lvert f(x)-r_{n,m}(x)\right\rvert^{\frac{1}{n+1}} \leq {\exp(-c_2-c_1)}.
\end{equation}

\vspace{0.16cm}
\item In the case that $f$ is not analytic over a set $\chi$ with $E\subseteq \chi\subseteq\mathbb{C}\backslash F$, the exponential convergence (\ref{eq:2f})
still holds, but where $\inf_{\Gamma}\left\lVert U^{\mu[E,F,\gamma]}(t)\right\rVert _{\Gamma}=\sup\{U^{\mu[E,F,\gamma]}(z):\, z\in(\chi\cup F)\}$.
\end{itemize}

Here, the rational functions $\{r_{n,m(n)}\}_{n=0}^\infty$ is called a ray sequence if $m(n)/n\to\theta\in(0,1]$ as $n\to\infty$.
For a rigorous treatment of the ray sequence, the reader is referred to \cite{Prokhorov1999}.

Note that the desired non-zero measure is confined to the boundaries of $E$ and $F$ due to the fact that the
potentials inside $E$ and $F$ are fully determined by the boundary potentials. As a result, the nodes and poles
must be selected on the boundaries of $E$ and $F$, respectively.

To achieve the exponential convergence of the rational interpolation \eqref{eq:1.1c} that is consistent with the equilibrium potential, we must solve three key problems:

\begin{itemize}
\item[(i)] How should $F$ be chosen?
\item[(ii)] How to evaluate $\mu[E,F,\gamma]$ or the density function $w$ of the equilibrium potential?
\item[(iii)] How can the point distribution that satisfies \eqref{eq:2h} be obtained?
\end{itemize}

It is worthy of noticing that if $F$ is not considered,
the rational interpolant degenerates to a polynomial interpolant.
In the following section, we will thoroughly address these issues.

%=============================================================================================================
\section{Algorithms of the rational interpolation}\label{sec:algorithm}
We will discuss how to obtain a family of point sets $\{\{x_k^{(n)}\}_{k=0}^n:n=1,2,\cdots\}\subseteq \partial E$ such that
$\mu_{n+1} = 1/(n+1)\sum_{i=0}^{n}\delta_{x_i}\Rightarrow\mu$ for a given $\mu \in \mathcal{M}(E)$ satisfying $\mathrm{supp}(\mu)=\partial E$,  where $\mu_{n+1}$ is also a unit measure corresponding to the point
set $\{x_k^{(n)}\}_{k=0}^n$. These discussions can also be applied
to region $F$.

Suppose $w$ is the density function of  unit positive measure $\mu$ (i.e.,
$\int_{\partial E} w(t)\, \lvert\mathrm{d}t\rvert=1$) and $w(t)>0$  for all $t\in\partial E$.

\begin{definition}
A family of point sets $\{\{x_k^{(n)}\}_{k=0}^n:n=1,2,\cdots\}$ obeys the density function $w(t)>0$  for all $t\in\partial E$ if for any segment
$\partial E[\widehat{a,b}] \subseteq \partial E$, the family of point sets satisfies
	\begin{equation} \label{eq:3a}
		\lim\limits_{n\to\infty}\frac{n_{\partial E[\widehat{a,b}]}}{n+1}=\int_{\partial E[\widehat{a,b}]}w(t)\,\lvert\mathrm{d}t\rvert,
	\end{equation}
where $a$ and $b$ are the two endpoints of the segment $\partial E[\widehat{a,b}]$ and
$n_{\partial E[\widehat{a,b}]}$ denotes the number of the points on $\partial E[\widehat{a,b}]$.
\end{definition}


\begin{theorem}\label{thm:den}
If $\partial E$ is a bounded  piecewise simply smooth boundary and a family of point sets $\{x_i^{(n)}\}_{i=0}^n\subseteq \partial E$
obeys a positive density function $w$ of a unit measure $\mu$ on $\partial E$,  then it holds
\begin{equation}\label{eq:pdis}
    \lim_{n\to\infty}\max_{1\leq i\leq n}\lvert x_{i-1}^{(n)}-x_i^{(n)}\rvert = 0
\end{equation}
and $\mu_{n+1}\Rightarrow \mu$, i.e.,
\begin{equation}\label{eq:A2}
  \lim_{n\to\infty}\int g \, \mathrm{d}\mu_{n+1}=\int g \, \mathrm{d}\mu
\end{equation}
for arbitrary continuous function $g$ on $\partial E$, where $\mu_{n+1} = 1/(n+1)\sum_{i=0}^{n}\delta_{x_i^{(n)}}$.
\end{theorem}

For consistency of the implementation of the rational interpolation, we sketch Theorem \ref{thm:den} in Appendix A.

In this paper, the family of the point sets is chosen such that
for any two adjacent points $x_i^{(n)},x_{i+1}^{(n)}\in\{x_k^{(n)}\}_{k=0}^n$, it holds
\[\int_{\partial E[\widehat{x_i^{(n)},x_{i+1}^{(n)}}]}w(t)\,\lvert\mathrm{d}t\rvert= \begin{cases}
	1/(n+1), & \partial E \ is\ a\ closed\ curve,\, i = 0,1,\cdots,n \\
	1/n, & \partial E\ is\ a\ curve\ segment,\, i = 0,\cdots,n-1
\end{cases},\]
where $x_{n+1}^{(n)}=x_0^{(n)}$ for $\partial E$ is a closed curve.
It is easy to verify that $\{x_i^{(n)}\}_{i=0}^n$ satisfies (\ref{eq:3a}).
Then the above equation can be expressed as
\begin{equation} \label{eq:3b}
	\int_{\partial E[\widehat{x_0^{(n)},x_i^{(n)}}]}w(t)\,\lvert\mathrm{d}t\rvert = \begin{cases}
		i/(n+1), & \partial E \ is\ a\ closed\ curve \\
		i/n, & \partial E\ is\ a\ curve\ segment
	\end{cases},\ i = 0,1,\cdots,n.
\end{equation}
If $\partial E$ is a closed curve, $x_0^{(n)}$ could be any point on $\partial E$.
If $\partial E$ is a curve segment, $x_0^{(n)}$ is an endpoint of the curve segment.

As an example, we consider the density function $w(t)=(\pi \sqrt{1-x^2})^{-1}$ on $E=[-1,1]$.
Suppose a family of point sets $\{\{x_k^{(n)}\}_{k=0}^n:n=1,2,\cdots\}$ on $E$
satisfies (\ref{eq:3b}). It yields
\begin{equation} \label{eq:ChebLob}
	x_i^{(n)} = \cos\left(\frac{n-i}{n}\pi\right),
\end{equation}
and we obtain the Chebyshev-Lobatto points.

However, getting an explicit formula for the density function $w$ of the equilibrium measure can be challenging,
especially for general regions $E$ and $F$ with various shapes and relative positions. Moreover, even if an analytical
expression for the density function is obtained, it may not be possible to explicitly express the point distribution
from (\ref{eq:3b}). To overcome these challenges, we will apply a step function $\hat{w}(t)$ to approximate
the density function $w(t)$ by solving a Symm's integral equation.

%------------------------------------------------------------------------------------------------------------
\subsection{Polynomial interpolation based on equilibrium potential} \label{sec:3.1}
The most straightforward scenario is polynomial interpolation with poles situated at infinity in the complex plane. In this case, we can obtain an estimation of the equilibrium potential's density function, $\hat{w}$, by solving Symm's integral equation \cite{Kythe1998}%. Symm's equation is a Fredholm integral equation of the first kind, which has a logarithmic singular kernel .
\begin{equation} \label{eq:3c}
  \int_{\partial E} \log\frac{1}{\lvert z-t\rvert}w(t)\,\lvert\mathrm{d}t\rvert=c_1,\ z\in E,
\end{equation}
where $w$ is the density function of the equilibrium measure and satisfies
\begin{equation} \label{eq:density}
  \int_{\partial E} w(t)\,\lvert\mathrm{d}t\rvert=1.
\end{equation}
Here $E$ could be a finite union of simply connected compact regions with piecewise-smooth boundaries.

Numerous numerical methods have been developed to solve Symm's integral equations \cite[Chapter 9]{Kythe1998}. In this work, we utilize the constant element method to
solve (\ref{eq:3c}) and (\ref{eq:density}). This method is straightforward to implement and provides an approximation in the form of a step function.

We partition $\partial E$ into $N$ segments, $\partial E_1,\cdots,\partial E_N$, using $t_1,\cdots,t_{N+1}$ as the dividing points. If the curve is closed, the first and last points coincide. It is noteworthy that $N$ does not depend on $n$, but increasing $N$ enhances the precision of the density function approximation, yielding more precise discrete points.
In our examples, we choose $N=500$ for simply connected $E$ and $F$ while $N=3000$ for other cases.

Let $\hat{w}_i(\approx w(t))$ for $t\in \partial E_i$. Taking a point $t_{i+1/2}\in \partial E_i$ in each
subinterval $\partial E_j$, Eq. (\ref{eq:3c}) is simplified to
\begin{equation} \label{eq:3d}
  \sum_{j=1}^{N}\hat{w}_j\int_{\partial E_j}\log\frac{1}{\lvert t_{i+1/2}-t\rvert}\,\lvert\mathrm{d}t\rvert=c_1,\  i=1,\cdots,N.
\end{equation}
Then (\ref{eq:3d}) can be represented as $\mathbf{A}\mathbf{\hat{w}}=\mathbf{c_1}$ where
$\mathbf{\hat{w}}=[\hat{w}_1;\cdots;\hat{w}_N]$, $\mathbf{c_1}=[c_1;\cdots;c_1]$, and the $a_{i,j}$ of $\mathbf{A}$ denotes
\[
  a_{i,j}\approx\int_{\partial E_j}\log\frac{1}{\lvert t_{i+1/2}-t\rvert}\, \lvert\mathrm{d}t\rvert,\ i=1,\cdots,N,\ j=1,\cdots,N.
\]
For $i\ne j$, $a_{i,j}$ is evaluated by
\begin{equation}\label{eq:linapp1}
  a_{i,j}=-\frac{\lvert\partial E_i\rvert _L}{6}(\log\lvert t_{i+\frac{1}{2}}-t_{j}\rvert
  +4\log\lvert t_{i+\frac{1}{2}}-t_{j+\frac{1}{2}}\rvert+\log\lvert t_{i+\frac{1}{2}}-z_{j+1}\rvert),
\end{equation}
while for $i=j$,
\begin{equation}\label{eq:linapp2}
	a_{i,i}=\lvert t_{i+\frac{1}{2}}-t_{i}\rvert(\log\lvert t_{i+\frac{1}{2}}-t_{i}\rvert-1)
  +\lvert t_{i+\frac{1}{2}}-t_{i+1}\rvert(\log\lvert t_{i+\frac{1}{2}}-t_{i+1}\rvert-1)
\end{equation}
(see  \cite[P. 241]{Kythe1998}), where $\lvert\partial E_i\rvert _L$ denotes the length of $\partial E_i$.
Then equations \eqref{eq:3c} and \eqref{eq:density} are jointly expressed as
\begin{equation} \label{eq:3e}
  \left( \begin{array}{ccc|c}
    a_{1,1} & \cdots & a_{1,N} & -1 \\
    \vdots  & \ddots & \vdots  & \vdots \\
    a_{N,1} & \cdots & a_{N,N} & -1\\ \hline
    \lvert\partial E_1\rvert _L& \cdots & \lvert\partial E_N\rvert _L & 0 \\
  \end{array} \right)
  \left( \begin{array}{c}
    \hat{w}_{1}\\
    \vdots\\
    \hat{w}_{N}\\ \hline
    c_1\\
  \end{array} \right) =
  \left( \begin{array}{c}
    0\\
    \vdots\\
    0\\ \hline
    1\\
  \end{array} \right).
\end{equation}
The approximate density $\mathbf{\hat{w}}$ and the potential $c_1$ can be obtained from \eqref{eq:3e}.

Thereafter, we can obtain the nodes from (\ref{eq:3b}) using the approximate density function $\hat{w}(t)=\hat{w}_i$ for $t\in\partial E_i$.
Without loss of generality, we consider a distribution of $n$ points
$\{x_i^{(n)}\}_{i=1}^n$ on $\partial E$. Suppose $\{x_i^{(n)}\}_{i=1}^n$
and the approximate density function $\hat{w}(t)$ satisfies (\ref{eq:3b}) (Note that it is $n$ points here for notational simplicity).

We replace $x_0^{(n)}$ in (\ref{eq:3b}) with $x_1^{(n)}$ and set $x_1^{(n)}=t_1$, and define
\[
  h_{n,i}=  \begin{cases}
		(i-1)/n, & \partial E \ is\ a\ closed\ curve \\
		(i-1)/(n-1), & \partial E\ is\ a\ curve\ segment\\
	\end{cases},
\]
and $s_j = \sum\limits_{i=1}^j \lvert\partial E_i\rvert _L\hat{w}_i$ for $j=0,1,\cdots,(N-1)$ $(s_0=0)$.
If $s_{k-1}\leq h_{n,i}<s_{k}$, then $x_i^{(n)}\in \partial E[\widehat{t_{k-1},t_k}]$,
and  (\ref{eq:3b}) can be approximated by
\begin{equation}\label{eq:3f}
  \sum\limits_{j=1}^{k-1}\lvert\partial E_j\rvert _L\hat{w}_j+
  \lvert\partial E[\widehat{t_k,x_i^{(n)}}]\rvert _L\hat{w}_k = h_{n,i}, \quad i = 1,\cdots,n.
\end{equation}
This allows us to express the length of $x_i^{(n)}$ from the starting point $x_1^{(n)}=t_1$ on $\partial E$ as
\[
  \lvert\partial E[\widehat{t_1,x_i^{(n)}}]\rvert _L=\sum\limits_{j=1}^{k-1} \lvert\partial E_j\rvert _L + \varepsilon_{i,k},\quad \varepsilon_{i,k} = (h_{n,i}-s_{k-1})/\hat{w}_{k}.
\]

Define matrix $\mathbf{B} = [b_{i,j}]$ ($1\leq i\leq n$,\ $1\leq j\leq N$) with
\begin{equation}\label{eq:3g}
  b_{i,j} = \begin{cases}
    1 , & \hat{b}_{i,j} \geq 1 \\
    \hat{b}_{i,j} , & 0 < \hat{b}_{i,j} < 1 \\
    0 , & \hat{b}_{i,j} \leq 0 \\
  \end{cases}, \quad
  \hat{b}_{i,j}=\frac{h_{n,i}-s_{j-1}}{\lvert\partial E_{j}\rvert _L\hat{w}_{j}}.
\end{equation}
It holds
\begin{equation}\label{eq:3h}
  [\lvert\partial E[\widehat{t_1,x_1^{(n)}}]\rvert _L,\cdots,\lvert\partial E[\widehat{t_1,x_n^{(n)}}]\rvert _L]^T
  = \mathbf{B}[\lvert\partial E_1\rvert _L,\cdots,\lvert\partial E_N\rvert _L]^T.
\end{equation}

Given a reference point $t_1$, the nodes $\{x_i^{(n)}\}_{i=1}^n$ can be obtained from the curve lengths ${\lvert\partial E[\widehat{t_1,x_i^{(n)}}]\rvert _L}$, where $\partial E[\widehat{t_1,x_i^{(n)}}]$ denotes the part of the boundary of $E$ that connects $\widehat{t_1}$ and $x_i^{(n)}$. Using these nodes, we can perform the barycentric polynomial interpolation using (\ref{eq:1.1p}).

Algorithm \ref{alg:A} summarizes the above process, while Algorithm \ref{alg:B} outlines the procedure for obtaining the corresponding discrete points from the density function.
It is worth noting that when $E$ is a union of simply connected regions, we tend to divide the boundary of $E$ into multiple parts and use \texttt{den2pts} separately for each part, where the ratio of the number of the points in each part approximates the ratio of the integrals of the density function $\hat{w}$ over these parts.
\begin{algorithm}
  \caption{Barycentric polynomial interpolation with equilibrium potential}\label{alg:A}
  \begin{algorithmic}[1]
  \State $\mathbf{function}$ BPIEP($f \in \mathcal{A}(E)$, $n\in \mathbb{N}$)
  \State \quad Discrete $\partial E$;
  \State \quad Get approximately density function $\hat{w}$ by (\ref{eq:3e});
  \State \quad The nodes $X=\{x_i^{(n)}\}_{i=0}^n\leftarrow$den2pts($\hat{w}$,$n+1$);
  \State \quad Return $P_n[f]$ from the polynomial case of (\ref{eq:1.1p}) with the nodes $X$.
  \State $\mathbf{end\ function}$
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}
  \caption{Generate points from density function $\hat{w}$}\label{alg:B}
  \begin{algorithmic}[1]
  \State $\mathbf{function}$ den2pts($\hat{w}$,$n\in \mathbb{N}$)
  \State \quad Normalize $\hat{w}$ and define column vectors $L = [\lvert\partial E[t_i,t_{i+1}]\rvert _L]$, $W = [\hat{w}_i]$;
  \State \quad Set $S = [0;\lvert\partial E_1\rvert _L\hat{w}_1;\cdots ;\sum_{i=1}^{N-1} \lvert\partial E_i\rvert _L\hat{w}_i]$;
  \State \quad Compute matrix $\mathbf{B}$ by (\ref{eq:3g});
  \State \quad Return points $\{x_i^{(n)}\}_{i=1}^n$ by (\ref{eq:3h});
  \State $\mathbf{end\ function}$
  \end{algorithmic}
\end{algorithm}



Figure \ref{fig:poly} displays several examples of the polynomial interpolation discussed above in an L-shaped region. The six vertices of this L-shaped region are $\exp(-i\pi/4)[0,1,1+0.5i,0.5+0.5i,0.5+1i,1i]$. The interpolated functions are $f(z)=\sqrt{z+0.2}$ with a branch singularity at $-0.2$, $f(z)=1/(z^2+0.04)$ with isolated singularities at $\pm 0.2i$, and $f(z)=1/(z-1)$ with an isolated singularity at $1$. The left of Figure \ref{fig:poly} shows the singularities of the interpolated functions and the contours of the discrete potential $U$ generated by the nodes when $n=300$. The discrete potential $U$ has a value of about $0.1937$ at $-0.2$ (red+), $0.3868$ at $\pm 0.2i$ (blue+), and $0.5002$ at $1$ (black+). The right of Figure \ref{fig:poly} shows the convergence rates of the polynomial interpolation of these functions, which are consistent with their theoretical convergence rates.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=1\linewidth]{fig4.eps}
  \caption{Left: Interpolation nodes (blue) and the discrete potential $U$ generated by the nodes when $n=300$. Right:
  The convergence rates compared with the theoretical convergence rates $\rho^n$,
  $\rho=\exp(-0.4180)$ (blue dashed), $\rho=\exp(-0.2248)$ (green dashed) and $\rho=\exp(-0.1115)$ (rosy dashed), respectively.}
  \label{fig:poly}
\end{figure}

%------------------------------------------------------------------------------------------------------------
\subsection{Rational interpolation based on equilibrium potential} \label{sec:3.2}

To approximate an analytic function $f\in\mathcal{A}(E)$ with singularities near $E$, rational interpolation
is much better than the corresponding polynomial interpolation.
This is because rational interpolation can introduce poles in the vicinity of the singularities of $f$, which can accelerate the convergence.

We introduce a region $F$ for distributing the poles of the rational interpolation \eqref{eq:1.1c} to approximate analytic functions $f\in\mathcal{A}(E)$ with singularities near $E$.
For specific singularities, we can use simple strategies for selecting $F$.
\begin{itemize}
\item When the singular point $Z$ is isolated, such as a pole or essential singularity, we cover it with a small disk $F=D(Z,r)$ to avoid intersection with $E$ and ensure a lower potential on $F$.

\item For branch singularities, if the two endpoints of a branch cut are $Z_1$ and $Z_2$, and $Z_1$ is close to $E$ but $Z_2$ is far from $E$, we make a line segment from $Z_1$ in the direction away from $E$. We find that a length between $1$ and $4$ is often acceptable when the diameter of $E$ is between $1$ and $2$. For example, set $f(z)=\sqrt{x+0.1}$ and $E=[0,1]$. The branch cut is $[Z_2,Z_1]=[-\infty,-0.1]$ and we select $F=[-1.1,-0.1]$.


\item For branch singularities, if the two ends of the branch cut $[Z_1, Z_2]$ are both near $E$, we typically use the line segment $[Z_1, Z_2]$ as $F$ if it does not intersect $E$. For example, let $f(z) = [(z^2-0.25)/(z^2-0.01)]^{0.5}$, which has  four branch points and two branch cuts. Then we choose $F=[-0.5, -0.1]\cup[0.1, 0.5]$ (see  Figure \ref{fig:8}).
In some cases, it may be useful to use a curved segment as $F$ to avoid intersection with $E$. See Section \ref{sec:discu} for more discussion on the length of $F$.
\end{itemize}

Similar to the previous subsection, we still start with the potential.
From the properties of the equilibrium potential
and (\ref{eq:2g}), we get
\begin{equation} \label{eq:3i}
  \int_{\partial E}\log\frac{1}{\left\lvert z-t\right\rvert}w_E(t)\,\lvert\mathrm{d}t\rvert-
  \int_{\partial F}\log\frac{1}{\left\lvert z-t\right\rvert}w_F(t)\,\lvert\mathrm{d}t\rvert= \begin{cases}
   c_1, & z\in \partial E\\
   -c_2, & z\in \partial F\\
 \end{cases},
\end{equation}
and
\begin{equation}\label{eq:3j}
\int_{\partial E} w_E(t)\,\lvert\mathrm{d}t\rvert=1,\, \int_{\partial F} w_F(t)\,\lvert\mathrm{d}t\rvert=\gamma,
\end{equation}
where $w_{S}(t)> 0$, and $S$ denotes $E$ or $F$.
For the more general case, $\partial E$ and $\partial F$ may consist of multiple simple boundaries.

Let $\partial E$ be divided into $I$ subintervals $\{\partial E_k\}_{k=1}^{I}$ and $\partial F$ be divided
into $J$ subintervals $\{\partial F_k\}_{k=1}^J$. For convenience, $\{\partial E_k\}_{k=1}^{I}$ and
$\{\partial F_k\}_{k=1}^J$ are noted as $\{\partial S_k\}_{k=1}^N\, (N=I+J)$.
Similar to the polynomial case, let $\hat{w}_{E_k}(\approx w_E(t))$ for $t\in\partial E_k$ and $\hat{w}_{F_k}(\approx w_F(t))$ for $t\in\partial F_k$,
then \eqref{eq:3i} and \eqref{eq:3j} are jointly expressed as
\begin{equation} \label{eq:3k}
  \left( \begin{array}{ccc|ccc|cc}
    a_{1,1} & \cdots & a_{1,I} & -a_{1,I+1} & \cdots & -a_{1,N} & -1 & 0 \\
    \vdots & \ddots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots \\
    a_{I,1} & \cdots & a_{I,I} & -a_{I,I+1} & \cdots & -a_{I,N} & -1 & 0 \\ \hline
    a_{I+1,1} & \cdots & a_{I+1,I} & -a_{I+1,I+1} & \cdots & -a_{I+1,N} & 0 & 1 \\
    \vdots & \ddots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots \\
    a_{N,1} & \cdots & a_{N,I} & -a_{N,I+1} & \cdots & -a_{N,N} & 0 & 1\\ \hline
    \lvert \partial E_1\rvert _L & \cdots & \lvert \partial E_I\rvert _L & 0 & \cdots & 0 & 0 & 0\\
    0 & \cdots & 0 & \lvert \partial F_1\rvert _L & \cdots & \lvert \partial F_J\rvert _L & 0 & 0\\
  \end{array} \right)
  \left( \begin{array}{c}
    \hat{w}_{E_1}\\
    \vdots\\
    \hat{w}_{E_I}\\ \hline
    \hat{w}_{F_1}\\
    \vdots\\
    \hat{w}_{F_J}\\ \hline
    c_1\\
    c_2\\
  \end{array} \right) =
  \left( \begin{array}{c}
    0\\
    \vdots\\
    0\\ \hline
    0\\
    \vdots\\
    0\\ \hline
    1\\
    \gamma\\
  \end{array} \right)
\end{equation}
where $a_{i,j}$ is generated for ordered pairs $(\partial S_i,\partial S_j)$ by the rules of $a_{i,j}$ in Subsection
\ref{sec:3.1}. Therefore, we can derive the approximate density function $\hat{w}_S$ used to generate the discrete points and
the parameters $c_1$ and $c_2$ used to estimate the convergence rate \eqref{eq:2f}.

Using the \texttt{den2pts} (Algorithm \ref{alg:B}), we can obtain the interpolation nodes $\{x_i^{(n)}\}_{i=0}^n$ and poles $\{z_j^{(n)}\}_{j=1}^m$ from the density
function $\hat{w}$. Subsequently, we can obtain the rational interpolation using (\ref{eq:1.1c}). We summarize the rational interpolation with equilibrium potential in Algorithm \ref{alg:C}.
\begin{algorithm}
  \caption{Barycentric rational interpolation with equilibrium potential}
  \label{alg:C}
  \begin{algorithmic}[1]
  \State $\mathbf{function}$ BRIEP($f \in\mathcal{A}(E)$, singularities $[q_i]$ of $f$, $n\in\mathbb{N}$, $\gamma\in(0,1)$)
  \State \quad Select the regions $F$ to cover $[q_i]$;
  \State \quad Discrete $\partial E$ and $\partial F$;
  \State \quad Get approximately density functions $\hat{w}_E$ and $\hat{w}_F$ by (\ref{eq:3k});
  \State \quad The nodes $X=\{x_i^{(n)}\}_{i=0}^n\leftarrow$den2pts($\hat{w}_E$,$n+1$);
  \State \quad The poles $Z=\{z_j^{(n)}\}_{j=1}^m\leftarrow$den2pts($\hat{w}_F$,$m=\lfloor\gamma (n+1)\rfloor $);
  \State \quad Barycentric weights $\{w_k\}$ from (\ref{eq:1.1c}) with $X$ and $Z$;
  \State \quad Return $r_{n,m}[f]$ from (\ref{eq:1.1c}) with weights $\{w_k\}$ and nodes $X$.
  \State $\mathbf{end\ function}$
  \end{algorithmic}
\end{algorithm}

%=============================================================================================================
\section{Experimental results}\label{sec:experiments}
To demonstrate the rapid convergence of the proposed rational interpolation method, we focus on function $f\in\mathcal{A}(E)$ with singularities near $E$.

%In some examples, we illustrate the convergence rate of \eqref{eq:2g}.
%------------------------------------------------------------------------------------------------------------

\subsection{On the interval [-1,1]}
\label{sec:4.1}
In this subsection, we study the interpolation of analytic functions that have singularities near $E=[-1,1]$.
We compare our method with the conformal mapping method proposed by Tee and Trefethen \cite{Tee2006}, as well as the Floater-Hormann method that interpolates at equidistant nodes \cite{Floater2007}. For the latter, we use the implementation \emph{Chebfun(f(X),'equi')} within Chebfun \cite{Driscoll2014}. We compare $\|f-r_{n,m}\|_{\infty}$ of the absolute error of the corresponding interpolants in $-1:0.00001:1$.

For $f(x) = \exp(1/(1+10^4 x^2))$ with essential singularities at $\pm 0.01i$, we demonstrate the absolute errors of the rational interpolation \eqref{eq:1.1c} by selecting $F=D(-0.01i,0.0001)\cup D(0.01i,0.0001)$ and various degrees $n$, as shown on the left of Figure \ref{fig:3}. On the right of Figure \ref{fig:3}, we present the local potential map around the singularities, where the nodes and poles attract each other to cluster closely, leading to a uniformly high potential for $E$ and a uniformly low potential for $F$. As the degree $n$ increases, the convergence rate of our method gradually approaches the theoretical asymptotic rate, which is consistent with the analysis in Section \ref{sec:theory}. We also note that our method outperforms the conformal mapping method \cite{Tee2006} and Floater-Hormann method \cite{Floater2007} in terms of absolute errors, as shown in the numerical experiments.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=1\linewidth]{fig5.eps}
  \caption{Left: Absolute errors for $n=1:1:120$ together with predicted error slope $0.0807^n$ (red) obtained by (\ref{eq:2g}). Right:
   The local potential contour with nodes and poles of our method for $n=120$.}
  \label{fig:3}
\end{figure}

Figure \ref{fig:4} depicts the convergence behavior of our proposed method with various values of the parameter $\gamma$
for two different functions: $f(x)=\exp(1/(1+100x^2))$ with essential singularities at $\pm 0.1i$ ($F=D(-0.1i,0.0001)\cup D(0.1i,0.0001)$), and
$f(x) = \exp(1/(1+10^6 x^2))$ with singularities at $\pm 0.001i$ ($F=D(-0.001i,0.0001)\cup D(0.001i,0.0001)$). The figure illustrates that when $\gamma$ is small,
the error decreases in a stepwise manner since $m= \lfloor\gamma (n+1)\rfloor$. The results agree with the theoretical asymptotic errors.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=1\linewidth]{fig6.eps}
  \caption{Left: Absolute errors for $n=1:1:100$  together with  predicted error slope $0.0231^n$ (blue)
  and $0.1419^n$ (red), respectively. Right: Absolute errors for $n=1:1:100$  together with
  predicted error slope $0.2273^n$ (blue) and $0.4729^n$ (red).}
  \label{fig:4}
\end{figure}

Figure \ref{fig:5} illustrates the interpolation approximations of two functions with branch singularities: $f(x)=\exp((1+100x^2)^{-0.5})$ with $F=[-0.1i,-2.1i]\cup[0.1i,2.1i]$ (left) and $f(x)=\exp((1+10^4 x^2)^{-0.5})$ with $F=[-0.01i,-2.51i]\cup[0.01i,2.51i]$ (right).
The proposed method exhibits faster convergence compared to the two methods.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=1\linewidth]{fig7.eps}
  \caption{Left: Absolute errors for $n=2:2:150$. Right: Absolute errors for $n=2:2:150$.}
  \label{fig:5}
\end{figure}

%------------------------------------------------------------------------------------------------------------
\subsection{On the complex plane region}
\label{sec:4.2}
In this subsection, we present two numerical examples on a square region and an annulus, respectively. We compare the results with the AAA method \cite{Nakatsukasa2018}, which is based on randomly sampled points within the region of interest and can produce varying performances. To account for this variability, we conduct five tests and use the median result for comparison.

The first example is on the square region $[-0.5,0.5]\times[-0.5,0.5]$ with $f(z)=\exp(1/(5.1^2+(10z)^2))$, which has two essential singularities at $\pm 0.51i$. In Figure \ref{fig:6}, the AAA method converges rapidly and reaches the error tolerance of $10^{-10}$ with $10^4$ random sample points. However, the method does not accurately represent the drastic local changes near the singularities with only $10^{4}$ random sample points. In contrast, the rational interpolation with $F = D(0.510001i,10^{-6})\cup D(-0.510001i,10^{-6})$ converges exponentially as $n$ increases.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=1\linewidth]{fig8.eps}
  \caption{Left: Absolute errors for $n=4:4:160$. Right: The potential contour of the nodes (blue)
  and poles (red): $n=160$ and $m=80$.}
  \label{fig:6}
\end{figure}

The second example concerns an analytic function on a multiconnected region. Such regions are of interest when approximating an analytic function with isolated singularities in the hole. Here, we consider the function $f(z) = \exp(1/(100(z-0.09)^{-1}(z-0.51i)^{-1}))$ defined on the annulus $E=\{re^{2\pi i\theta}:0.1\leq r\leq0.5,0\leq\theta<2\pi\}$. This function has two essential singularities at $0.51i$ and $0.09$, and we cover these singularities with $F=D(0.51i,10^{-6})\cup D(0.09,10^{-6})$. Since some poles of rational interpolation are distributed inside the hole, the interpolation nodes must gather on the inner boundary of $E$ to make the potential on $E$ constant. As shown in Figure \ref{fig:9}, both methods perform similarly to the previous examples.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=1\linewidth]{fig9.eps}
  \caption{Left: Absolute errors for $n=4:4:400$. Right: The potential contours of the nodes (blue) and poles (red): $n=400$ and $m=200$.
  }
  \label{fig:9}
\end{figure}

While we used the AAA method for comparison, the two have their respective strengths and can complement each other. The former requires prior knowledge about the location and type of singularities of the function $f$ to determine the region $F$, which can be difficult to obtain in some cases. On the other hand, the AAA method can determine the singularities' location and type and can assist in setting the region $F$. Then we can use the poles obtained from the AAA method to help determine the region $F$.

%==============================================================================================================
\section{Further discussions on the rational interpolation}\label{sec:discu}
In Section \ref{sec:algorithm}, the parameter that may need to be specified is the length of $F$ for branch singularities. Here, we illustrate this with an example of interpolating the function $f(z) = 1/\sqrt{z}$ on the quadrilateral $[0.1, -0.2 + 0.5i, 0.7, -0.2 - 0.5i]$. Figure \ref{fig:12} shows the potential maps when the length of $F$ is $0.5$, $2$, $4$, and $8$, from top to bottom.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.65\linewidth]{fig12.eps}
  \caption{Potential contours of the nodes (blue) and poles (red) for $n=100$.
  }
  \label{fig:12}
\end{figure}

It is worth noting the changes in potential along the path from the left endpoint of $F$ to $-10$. The first image clearly shows a significant rise in potential along this path. When compared to other cases with lengths of $2$, $4$, and $8$, respectively, the maximum potential on $\Gamma$ of (\ref{eq:2f}) will be much larger since $\Gamma$ cannot cross $[-\infty,0]$. When the length of $F$ is between $1$ and $8$, the difference in convergence rate is very slight. This phenomenon is illustrated on the left side of Figure \ref{fig:13}. From the right side of Figure \ref{fig:13}, this phenomenon is even more evident when we set $\gamma = 0.85$.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.85\linewidth]{fig13.eps}
  \caption{Absolute errors for $n=4:4:100$ with $\gamma=0.99$ (left) and $\gamma=0.85$ (right).}
  \label{fig:13}
\end{figure}

Although the convergence rate is not very sensitive to the length of $F$, a criterion is still needed
to determine whether $F$ is appropriate. Figure \ref{fig:14} shows the density functions for the four
different lengths of $F$ at $\gamma = 0.99$ and $0.85$, respectively. If the length of $F$ is appropriate,
then the end near $E$ will have more poles than the other end. When the approximate density function $\hat{w}_F$
differs by at least one order of magnitude at both ends, the convergence rate is often acceptable.
\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\linewidth]{fig14.eps}
\caption{Left: Density function $\hat{w}$ when $\gamma=0.99$ (left) and $\gamma=0.85$ (right).
When $\gamma = 0.85$, the density function is negative around $-8$ if we set the length of $F$ to be $8$.
Here we just ignore the part where the density function is negative.
}
\label{fig:14}
\end{figure}

We consider an example with both isolated singularities and branch points. The boundary curve
of the interpolation region $E$ is $z(\theta)=(0.6+0.3\cos(4\theta+\pi))\exp(i\theta)$, ($0\leq\theta\leq\pi$).
The function $f(z)=\sqrt{z+0.5}/((z^2+0.25)(z-0.5))\in\mathcal{A} (E)$ has a branch cut $[-\infty,-0.5]$ and three isolated singularities.
We use $[-1,-0.5]$ or $[-2,-0.5]$ for the branch cut. The three isolated singularities
are covered by $D(0.5i,0.01)\cup D(0.5,0.01)\cup D(-0.5i,0.01)$ in all cases.
The left side of Figure \ref{fig:15} shows the error results and the number of iterations for different $F$ and different $\gamma$, respectively.
\begin{figure}[hbpt]
\centering
\includegraphics[width=1\linewidth]{fig15.eps}
\caption{Left: Absolute error for $n=3:3:150$.
 Right: Potential contour of nodes(blue) and poles(red) of $\gamma=0.75$.
 }
 \label{fig:15}
\end{figure}

%=============================================================================================================
\section{Conclusion}\label{sec:conclusion}
This paper presents an efficient algorithm for the rational interpolation \eqref{eq:1.1c} that approximates an analytic function $f\in\mathcal{A}(E)$ or $f\in\mathcal{A}(E)$ with singularities near $E$ with exponential convergence. The interpolation nodes and poles are determined based on the equilibrium logarithmic potential with a specific discrete density approximation obtained by solving a Symm's integral equation.

The method we have presented in this paper has potential applications beyond the realm of rational interpolation with singularities. It can be extended to solve other problems such as the Zolotarev problem on the complex plane or to determine the optimal parameters for the alternating direction implicit (ADI) method \cite{Istace1995, Bailly2000}. Further research will be conducted in future work.


%============================================================================================================
%\begin{appendices}
\section*{Appendix A}\label{secA}
{\bf Proof of Theorem \ref{thm:den}}: We will first prove \eqref{eq:pdis}. Assume that  for any positive integer $K$,
there exists $n>K$ such that $\max_{1\leq i\leq n}\lvert x_{i-1}^{(n)}-x_i^{(n)}\rvert>2d$ for some positive constant $d$. Divide $\partial E$ into
$m=\left\lceil \lvert\partial E\rvert _L/d \right\rceil$ parts $\Gamma_1,\Gamma_2,\cdots,\Gamma_m$ with equal length, where $\left\lceil z\right\rceil$ denotes the smallest integer greater than or equal to $z$.
Then, for any positive integer $K$, there exists $n(>K)$ and some $i(n)$ with $1\leq i(n)\leq m$ such that
$n_{\Gamma_{i(n)}}=0$. Since $\{\Gamma_i\}_{i=1}^m$ are a finite set, thus there is $i_0$ with $1\leq i_0\leq m$ and a subsequence such that $n_{\Gamma_{i(n_k)}}=n_{\Gamma_{i_0}}=0$ for $k=1,2,\ldots$, which implies that (\ref{eq:3a}) does not hold, i.e., $\{x_i^{(n)}\}_{i=0}^n$ does not
obey $w(t)$ on $\partial E$ since $\lim_{k\rightarrow \infty}\frac{n_{\Gamma_{i(n_k)}}}{n_k}=\int_{\Gamma_{i_0}}w(t)\,\lvert\mathrm{d}t\rvert=\lim_{k\rightarrow \infty}\frac{n_{\Gamma_{i_0}}}{n_k}=0$, which is contradicted with $\int_{\Gamma_{i_0}}w(t)\,\lvert\mathrm{d}t\rvert>0$. Then the identity \eqref{eq:pdis} holds.

Next we will show that
\begin{equation}\label{eq:A2}
  \lim_{n\to\infty}\int g \, \mathrm{d}\mu_{n+1}=\int g \, \mathrm{d}\mu
\end{equation}
for arbitrary continuous function $g$ on $\partial E$, where $\mu_{n+1} = 1/(n+1)\sum_{i=0}^{n}\delta_{x_i^{(n)}}$.


Suppose $E$ is a union of  simply or multicoonencted sets and $\partial E = \bigcup_{i\in I} \partial E^{i}$, where $\partial E^i$ is close and smooth
and $I$ is a finite index set. Then we just need to prove that (\ref{eq:A2}) holds on every $\partial E^i$.

Denote $\max_{t\in\partial E^i}\lvert g(t)\rvert=G_i$.
Let the parametric curve of the smooth curve $\partial E^i$ about the arc length $s$ be $T_i(s)$
($0\leq s\leq S_i=\lvert\partial E^i\rvert _L$). Then we have
\[
  \int_{\partial E^{i}} g(t)\, \mathrm{d}\mu(t) = \int_{\partial E^{i}} g(t)w(t)\,\lvert\mathrm{d}t\rvert
  = \int_{0}^{S_i} g(T_i(s))w(T_i(s))\, \mathrm{d}s.
\]
Let $0=s_0<s_1<\cdots<s_m=S_i$ satisfy
\begin{equation} \label{eq:A3}
  \int_{s_{k-1}}^{s_{k}} w(T_i(s)) ds=\frac{W_i}{m},\quad W_i=\int_{0}^{S_i} w(T_i(s))\, \mathrm{d}s\leq 1 .
\end{equation}
Since $w>0$, we have $\lim_{m\to\infty}\max_{1\leq k\leq m}\lvert s_k-s_{k-1}\rvert=0$ from Identity  \eqref{eq:pdis}.

Note that $g(T_i(s))$ is continuous for $s\in[0,S_i]$. Then for arbitrary $\varepsilon>0$, there exists $K$ such that
\begin{equation}\label{eq:A4}
  \max_{s\in[s_{k-1},s_k]}g(T_i(s))-\min_{s\in[s_{k-1},s_k]}g(T_i(s))<\frac{\varepsilon}{2},\quad 1\leq k\leq m,\quad m\geq K.
\end{equation}
Given an $m$  ($\geq M$), by applying the mean value theorem of integration, there exists $\xi_k\in[s_{k-1},s_k]$ such that
\begin{equation} \label{eq:A5}
  \int_{0}^{S_i} g(T_i(s))w(T_i(s))\, \mathrm{d}s = \frac{W_i}{m}\sum_{k=1}^{m} g(T_i(\xi_k)).
\end{equation}
Furthermore, from
\[
  \int_{s_{k-1}}^{s_k} g(T_i(s))\, \mathrm{d}\mu_{n+1}(T_i(s))=\frac{\sum_{x\in X_i} g(x)}{n+1}
\]
where $X_i=\{x_i^{(n)}\}_{i=0}^n\cap T_i([s_{k-1},s_k])$,
there  exists $\zeta_k\in[s_{k-1},s_k]$ such that
\[
  \frac{\sum_{x\in X_i} g(x)}{n+1}=g(\zeta_k)\frac{n_{\partial E[\widehat{t_{k-1}^i,t_{k}^i}]}}{n+1}
\]
and
\begin{equation} \label{eq:A8}
  \lvert g(T_i(\xi_k))-g(T_i(\zeta_k))\rvert <\frac{\varepsilon}{2},
\end{equation}
where $t_{k-1}^i=T_i(s_{k-1})$ and $t_{k}^i=T_i(s_{k})$.

In addition, from (\ref{eq:3a}), there  exists a positive integer $N$ such that for $n>N$
\begin{equation} \label{eq:A6}
  \left\lvert\frac{n_{\partial E[\widehat{t_{k-1}^i,t_{k}^i}]}}{n+1}-\int_{s_{k-1}}^{s_{k}} w(T_i(s))\, \mathrm{d}s \right\rvert
  \leq \frac{\varepsilon m}{2G_i W_i},\, k=1,2,\ldots,m,
\end{equation}
which, together with (\ref{eq:A3}) and (\ref{eq:A6}), deduces
\begin{equation} \label{eq:A7}
  \frac{n_{\partial E[\widehat{t_{k-1}^i,t_{k}^i}]}}{n+1}\Big/\int_{s_{k-1}}^{s_{k}} w(T_i(s))\, \mathrm{d}s
  \in [1-\frac{\varepsilon}{2G_i},1+\frac{\varepsilon}{2G_i}].
\end{equation}
Thus, together with (\ref{eq:A5}), (\ref{eq:A8}) and (\ref{eq:A7}),  we have for $n>N$ that
\begin{align*}
 \left\lvert\int_{\partial E^{i}}g\, \mathrm{d}\mu_{n+1}-\int_{\partial E^{i}}g\, \mathrm{d}\mu\right\rvert
 &=\left\lvert \sum_{k=1}^{m}g(T_i(\zeta_k))\frac{n_{\partial E[\widehat{t_{k-1}^i,t_{k}^i}]}}{n+1}-\frac{W_i}{m}\sum_{k=1}^{m} g(T_i(\xi_k))\right\rvert\\
 &\leq\frac{W_i}{m}\sum_{k=1}^{m}(\left\lvert g(T_i(\xi_k))-g(T_i(\zeta_k))\right\rvert+\frac{\varepsilon}{2G_i}\left\lvert g(T_i(\zeta_k))\right\rvert)\\
 &\leq \frac{W_i}{m}\sum_{k=1}^{m}(\frac{\varepsilon}{2}+\frac{\varepsilon}{2})\\
 &\leq \varepsilon.
\end{align*}
This completes the proof.

%%=============================================%%
%% For submissions to Nature Portfolio Journals %%
%% please use the heading ``Extended Data''.   %%
%%=============================================%%

%%=============================================================%%
%% Sample for another appendix section			       %%
%%=============================================================%%

%% \section{Example of another appendix section}\label{secA2}%
%% Appendices may be used for helpful, supporting or essential material that would otherwise
%% clutter, break up or be distracting to the text. Appendices can consist of sections, figures,
%% tables and equations etc.

%\end{appendices}

%%===========================================================================================%%
%% If you are submitting to one of the Nature Portfolio journals, using the eJP submission   %%
%% system, please include the references within the manuscript file itself. You may do this  %%
%% by copying the reference list from your .bbl file, paste it into the main manuscript .tex %%
%% file, and delete the associated \verb+\bibliography+ commands.                            %%
%%===========================================================================================%%


\vspace{0.66cm}
\noindent {\bf Funding}\\
\noindent This work was supported by the National Natural Science Foundation of China (No. 12271528). 
%The first author is supported by the Fundamental Research Funds for the Central Universities of Central South University (No.2020zzts030).

%\vspace{0.16cm}
%\noindent {\large\bf Declarations}\\
%\noindent {\bf Conflict of interest} The authors declare no competing interests.

\bibliography{references}% common bib file
%% if required, the content of .bbl file can be included here once bbl is generated
%%\input sn-article.bbl

%% Default %%
%%\input sn-sample-bib.tex%

\end{document}
