\section{Discussion}

\paragraph{Sub-task 1:} Four of the top 5 teams used ensemble learning to maximize the F1 score for the NER task. While this is a great technique for competitions like \textsc{NL4Opt} that only consider performance metrics, it drastically increases the complexity which makes the training and inference more computationally expensive and less transparent. When considering methods from this competition for real-world time-sensitive applications, methods such as the Student-Teacher learning framework \citep{Wang_2022} could be explored. Other successful techniques included simple augmentation and preprocessing. Some methods also included adversarial training, or training through a two-step approach (i.e., fine-tuning using a global pointer then switch to the multi-head decoder). It is also worth pointing out that many winning teams used the transformer-based language model, DeBERTa, often as part of an ensemble. These winning methods resulted in a 2.3 to 3.3\% increase in F1 scores compared to baseline with the highest F1 score of 0.939 by \textsc{Team Infrrd AI Lab} \citep{Infrrd}.

\paragraph{Sub-task 2:} The improvements from the winning teams primarily resulted from preprocessing and data augmentation. Every winning team implemented some data augmentation or alterations to the input. The top two submissions replaced BART-base with BART-large which was responsible for higher top accuracy but a higher standard deviation was also reported. This sub-task highlights the importance of the input prompt design. We will continue to explore different input representations and the impact it has on performance. We are also interested in further exploring methods of data augmentation and training methods (i.e., ensemble learning, adversarial learning, etc.). The results of these winning submissions were encouraging as we saw a 17 to 29\% increase in declaration-level accuracy from the winning submissions with the highest accuracy of 0.899 by \textsc{Team UIUC-NLP} \citep{UIUC}.


\paragraph{Comparison with large language model}
Although ChatGPT was not trained or fine-tuned on our training set, it outperformed the winning submission of sub-task 2 by 2 percentage point. The common errors made by ChatGPT, in order of frequency of occurrence, include incorrect variable coefficients in constraints, extraneous constraints, wrong constraint directions, extra variables, missing constraints, and incorrect variable coefficients in the objective. 

The datasets used in this competition have had a lower level of complexity compared to real-world problems. As a result, it remains unclear how ChatGPT would perform when faced with more realistic and challenging problem descriptions that are frequently encountered in practical scenarios. Therefore, further research is required to examine the generalizability of large language models across a more extensive range of problem descriptions with varying levels of complexity and realism. Furthermore, it is crucial to explore methods for enhancing the trustworthiness and robustness of these models to extend their usefulness in practical applications.
