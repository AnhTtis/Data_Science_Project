@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{halevy2009unreasonable,
  title={The unreasonable effectiveness of data},
  author={Halevy, Alon and Norvig, Peter and Pereira, Fernando},
  journal={IEEE intelligent systems},
  volume={24},
  number={2},
  pages={8--12},
  year={2009},
  publisher={IEEE}
}

@article{sogaard2021revisiting,
  title={Revisiting methods for finding influential examples},
  author={S{\o}gaard, Anders and others},
  journal={arXiv preprint arXiv:2111.04683},
  year={2021}
}

@book{fujishige2005submodular,
  title={Submodular functions and optimization},
  author={Fujishige, Satoru},
  year={2005},
  publisher={Elsevier}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{rajpurkar2016squad,
  title={Squad: 100,000+ questions for machine comprehension of text},
  author={Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
  journal={arXiv preprint arXiv:1606.05250},
  year={2016}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{wu2018learning,
  title={Learning to teach with dynamic loss functions},
  author={Wu, Lijun and Tian, Fei and Xia, Yingce and Fan, Yang and Qin, Tao and Jian-Huang, Lai and Liu, Tie-Yan},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{cook1980characterizations,
  title={Characterizations of an empirical influence function for detecting influential cases in regression},
  author={Cook, R Dennis and Weisberg, Sanford},
  journal={Technometrics},
  volume={22},
  number={4},
  pages={495--508},
  year={1980},
  publisher={Taylor \& Francis}
}

@article{hoerl1970ridge,
  title={Ridge regression: Biased estimation for nonorthogonal problems},
  author={Hoerl, Arthur E and Kennard, Robert W},
  journal={Technometrics},
  volume={12},
  number={1},
  pages={55--67},
  year={1970},
  publisher={Taylor \& Francis}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{shazeer2018adafactor,
  title={Adafactor: Adaptive learning rates with sublinear memory cost},
  author={Shazeer, Noam and Stern, Mitchell},
  booktitle={International Conference on Machine Learning},
  pages={4596--4604},
  year={2018},
  organization={PMLR}
}

@article{hampel1974influence,
  title={The influence curve and its role in robust estimation},
  author={Hampel, Frank R},
  journal={Journal of the american statistical association},
  volume={69},
  number={346},
  pages={383--393},
  year={1974},
  publisher={Taylor \& Francis}
}

@article{shapley1953value,
  title={A value for n-person games},
  author={Shapley, Lloyd S and others},
  year={1953},
  publisher={Princeton University Press Princeton}
}

@article{kim2018screenernet,
  title={Screenernet: Learning self-paced curriculum for deep neural networks},
  author={Kim, Tae-Hoon and Choi, Jonghyun},
  journal={arXiv preprint arXiv:1801.00904},
  year={2018}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@book{pole2018applied,
  title={Applied Bayesian forecasting and time series analysis},
  author={Pole, Andy and West, Mike and Harrison, Jeff},
  year={2018},
  publisher={Chapman and Hall/CRC}
}

@book{hamilton2020time,
  title={Time series analysis},
  author={Hamilton, James Douglas},
  year={2020},
  publisher={Princeton university press}
}

@inproceedings{bengio2009curriculum,
  title={Curriculum learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={41--48},
  year={2009}
}

@article{fan2017learning,
  title={Learning what data to learn},
  author={Fan, Yang and Tian, Fei and Qin, Tao and Bian, Jiang and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:1702.08635},
  year={2017}
}

@inproceedings{swayamdipta-etal-2020-dataset,
    title = "Dataset Cartography: Mapping and Diagnosing Datasets with Training Dynamics",
    author = "Swayamdipta, Swabha  and
      Schwartz, Roy  and
      Lourie, Nicholas  and
      Wang, Yizhong  and
      Hajishirzi, Hannaneh  and
      Smith, Noah A.  and
      Choi, Yejin",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.746",
    doi = "10.18653/v1/2020.emnlp-main.746",
    pages = "9275--9293",
}

@inproceedings{jiang2018mentornet,
  title={Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels},
  author={Jiang, Lu and Zhou, Zhengyuan and Leung, Thomas and Li, Li-Jia and Fei-Fei, Li},
  booktitle={International conference on machine learning},
  pages={2304--2313},
  year={2018},
  organization={PMLR}
}

@article{wang2021survey,
  title={A survey on curriculum learning},
  author={Wang, Xin and Chen, Yudong and Zhu, Wenwu},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={44},
  number={9},
  pages={4555--4576},
  year={2021},
  publisher={IEEE}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@article{liu2022tfew,
  title={Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning},
  author={Liu, Haokun and Tam, Derek and Muqeeth, Mohammed and Mohta, Jay and Huang, Tenghao and Bansal, Mohit and Raffel, Colin},
  journal={arXiv preprint arXiv:2205.05638},
  year={2022}
}

@article{Pruthi,
  author    = {Garima Pruthi and
               Frederick Liu and
               Mukund Sundararajan and
               Satyen Kale},
  title     = {Estimating Training Data Influence by Tracking Gradient Descent},
  journal   = {CoRR},
  volume    = {abs/2002.08484},
  year      = {2020},
  url       = {https://arxiv.org/abs/2002.08484},
  eprinttype = {arXiv},
  eprint    = {2002.08484},
  timestamp = {Mon, 02 Mar 2020 16:46:06 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2002-08484.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Koh,
  title={Understanding black-box predictions via influence functions},
  author={Koh, Pang Wei and Liang, Percy},
  booktitle={International conference on machine learning},
  pages={1885--1894},
  year={2017},
  organization={PMLR}
}

@article{sanh2022multitask,
  title={Multitask prompted training enables zero-shot task generalization},
  author={Sanh, Victor and Webson, Albert and Raffel, Colin and Bach, Stephen H. and Sutawika, Lintang and Alyafeai, Zaid and Chaffin, Antoine and Stiegler, Arnaud and Scao, Teven Le and Raja, Arun and Dey, Manan and Bari, M Saiful and Xu, Canwen and Thakker, Urmish and Sharma, Shanya Sharma and Szczechla, Eliza and Kim, Taewoon and Chhablani, Gunjan and Nayak, Nihal and Datta, Debajyoti and Chang, Jonathan and Jiang, Mike Tian-Jian and Wang, Han and Manica, Matteo and Shen, Sheng and Yong, Zheng Xin and Pandey, Harshit and Bawden, Rachel and Wang, Thomas and Neeraj, Trishala and Rozen, Jos and Sharma, Abheesht and Santilli, Andrea and Fevry, Thibault and Fries, Jason Alan and Teehan, Ryan and Bers, Tali and Biderman, Stella and Gao, Leo and Wolf, Thomas and Rush, Alexander M.},
  keywords = {Machine Learning (cs.LG), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  year={2022}
}

@inproceedings{lester-etal-2021-power,
    title = "The Power of Scale for Parameter-Efficient Prompt Tuning",
    author = "Lester, Brian  and
      Al-Rfou, Rami  and
      Constant, Noah",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.243",
    doi = "10.18653/v1/2021.emnlp-main.243",
    pages = "3045--3059",
    abstract = "In this work, we explore {``}prompt tuning,{''} a simple yet effective mechanism for learning {``}soft prompts{''} to condition frozen language models to perform specific downstream tasks. Unlike the discrete text prompts used by GPT-3, soft prompts are learned through backpropagation and can be tuned to incorporate signals from any number of labeled examples. Our end-to-end learned approach outperforms GPT-3{'}s few-shot learning by a large margin. More remarkably, through ablations on model size using T5, we show that prompt tuning becomes more competitive with scale: as models exceed billions of parameters, our method {``}closes the gap{''} and matches the strong performance of model tuning (where all model weights are tuned). This finding is especially relevant because large models are costly to share and serve and the ability to reuse one frozen model for multiple downstream tasks can ease this burden. Our method can be seen as a simplification of the recently proposed {``}prefix tuning{''} of Li and Liang (2021) and we provide a comparison to this and other similar approaches. Finally, we show that conditioning a frozen model with soft prompts confers benefits in robustness to domain transfer and enables efficient {``}prompt ensembling.{''} We release code and model checkpoints to reproduce our experiments.",
}

@inproceedings{dagan2006pascal,
  title={The pascal recognising textual entailment challenge},
  author={Dagan, Ido and Glickman, Oren and Magnini, Bernardo},
  booktitle={Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment: First PASCAL Machine Learning Challenges Workshop, MLCW 2005, Southampton, UK, April 11-13, 2005, Revised Selected Papers},
  pages={177--190},
  year={2006},
  organization={Springer}
}

@inproceedings{roemmele2011choice,
  title={Choice of Plausible Alternatives: An Evaluation of Commonsense Causal Reasoning.},
  author={Roemmele, Melissa and Bejan, Cosmin Adrian and Gordon, Andrew S},
  booktitle={AAAI spring symposium: logical formalizations of commonsense reasoning},
  pages={90--95},
  year={2011}
}

@article{sakaguchi2021winogrande,
  title={Winogrande: An adversarial winograd schema challenge at scale},
  author={Sakaguchi, Keisuke and Bras, Ronan Le and Bhagavatula, Chandra and Choi, Yejin},
  journal={Communications of the ACM},
  volume={64},
  number={9},
  pages={99--106},
  year={2021},
  publisher={ACM New York, NY, USA}
}


@article{yang2023remove,
  doi = {10.48550/ARXIV.2302.02169},
  url = {https://arxiv.org/abs/2302.02169},
  author = {Yang, Jinghan and Jain, Sarthak and Wallace, Byron C.},
  title = {How Many and Which Training Points Would Need to be Removed to Flip this Prediction?},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{koh2019accuracy,
  title={On the accuracy of influence functions for measuring group effects},
  author={Koh, Pang Wei W and Ang, Kai-Siang and Teo, Hubert and Liang, Percy S},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{
basu2021influence,
title={Influence Functions in Deep Learning Are Fragile},
author={Samyadeep Basu and Phil Pope and Soheil Feizi},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=xHKVVHGDOEk}
}

@article{akyurektowards,
  title={Towards Tracing Factual Knowledge in Language Models Back to the Training Data},
  author={Aky{\"u}rek, Ekin and Bolukbasi, Tolga and Liu, Frederick and Xiong, Binbin and Tenney, Ian and Andreas, Jacob and Guu, Kelvin},
  year={2022}
}

@book{cook1982residuals,
  title={Residuals and influence in regression},
  author={Cook, R Dennis and Weisberg, Sanford},
  year={1982},
  publisher={New York: Chapman and Hall}
}

@article{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{schioppa2022scaling,
  title={Scaling up influence functions},
  author={Schioppa, Andrea and Zablotskaia, Polina and Vilar, David and Sokolov, Artem},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={8},
  pages={8179--8186},
  year={2022}
}

@inproceedings{guo2021fastif,
  title={FastIF: Scalable Influence Functions for Efficient Model Interpretation and Debugging},
  author={Guo, Han and Rajani, Nazneen and Hase, Peter and Bansal, Mohit and Xiong, Caiming},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={10333--10350},
  year={2021}
}

@inproceedings{han2020explaining,
  title={Explaining Black Box Predictions and Unveiling Data Artifacts through Influence Functions},
  author={Han, Xiaochuang and Wallace, Byron C and Tsvetkov, Yulia},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={5553--5563},
  year={2020}
}

@article{han2022orca,
  title={Orca: Interpreting prompted language models via locating supporting data evidence in the ocean of pretraining data},
  author={Han, Xiaochuang and Tsvetkov, Yulia},
  journal={arXiv preprint arXiv:2205.12600},
  year={2022}
}

@inproceedings{pezeshkpour2022combining,
  title={Combining Feature and Instance Attribution to Detect Artifacts},
  author={Pezeshkpour, Pouya and Jain, Sarthak and Singh, Sameer and Wallace, Byron C},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2022},
  pages={1934--1946},
  year={2022}
}

@inproceedings{yeh2018representer,
  title={Representer Point Selection for Explaining Deep Neural Networks},
  author={Chih-Kuan Yeh and Joon Sik Kim and Ian En-Hsu Yen and Pradeep Ravikumar},
  booktitle={Proc. NeurIPS},
  year={2018}
}

@inproceedings{han-tsvetkov-2021-influence-tuning,
    title = "Influence Tuning: Demoting Spurious Correlations via Instance Attribution and Instance-Driven Updates",
    author = "Han, Xiaochuang  and
      Tsvetkov, Yulia",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-emnlp.374",
    doi = "10.18653/v1/2021.findings-emnlp.374",
    pages = "4398--4409",
    abstract = "Among the most critical limitations of deep learning NLP models are their lack of interpretability, and their reliance on spurious correlations. Prior work proposed various approaches to interpreting the black-box models to unveil the spurious correlations, but the research was primarily used in human-computer interaction scenarios. It still remains underexplored whether or how such model interpretations can be used to automatically {``}unlearn{''} confounding features. In this work, we propose influence tuning{---}a procedure that leverages model interpretations to update the model parameters towards a plausible interpretation (rather than an interpretation that relies on spurious patterns in the data) in addition to learning to predict the task labels. We show that in a controlled setup, influence tuning can help deconfounding the model from spurious patterns in data, significantly outperforming baseline methods that use adversarial training.",
}