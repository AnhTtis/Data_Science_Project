{
    "arxiv_id": "2303.10774",
    "paper_title": "Cross-GAN Auditing: Unsupervised Identification of Attribute Level Similarities and Differences between Pretrained Generative Models",
    "authors": [
        "Matthew L. Olson",
        "Shusen Liu",
        "Rushil Anirudh",
        "Jayaraman J. Thiagarajan",
        "Peer-Timo Bremer",
        "Weng-Keen Wong"
    ],
    "submission_date": "2023-03-19",
    "revised_dates": [
        "2023-03-21"
    ],
    "latest_version": 1,
    "categories": [
        "cs.LG",
        "cs.CV"
    ],
    "abstract": "Generative Adversarial Networks (GANs) are notoriously difficult to train especially for complex distributions and with limited data. This has driven the need for tools to audit trained networks in human intelligible format, for example, to identify biases or ensure fairness. Existing GAN audit tools are restricted to coarse-grained, model-data comparisons based on summary statistics such as FID or recall. In this paper, we propose an alternative approach that compares a newly developed GAN against a prior baseline. To this end, we introduce Cross-GAN Auditing (xGA) that, given an established \"reference\" GAN and a newly proposed \"client\" GAN, jointly identifies intelligible attributes that are either common across both GANs, novel to the client GAN, or missing from the client GAN. This provides both users and model developers an intuitive assessment of similarity and differences between GANs. We introduce novel metrics to evaluate attribute-based GAN auditing approaches and use these metrics to demonstrate quantitatively that xGA outperforms baseline approaches. We also include qualitative results that illustrate the common, novel and missing attributes identified by xGA from GANs trained on a variety of image datasets.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.10774v1"
    ],
    "publication_venue": "CVPR 2023. Source code is available at https://github.com/mattolson93/cross_gan_auditing"
}