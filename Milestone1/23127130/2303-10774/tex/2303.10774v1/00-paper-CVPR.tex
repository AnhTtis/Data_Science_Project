% CVPR 2023 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)
\documentclass[10pt,twocolumn,letterpaper]{article}
%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
%\usepackage[review]{cvpr}      % To produce the REVIEW version
%\usepackage{cvpr}              % To produce the CAMERA-READY version
\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{graphicx}
\usepackage{algorithm}
%\usepackage{algorithmic}
%\usepackage{svg}
%\usepackage{tikz}
\usepackage{comment}
\usepackage{amsmath,amssymb} % define this before the line numbering.
%\newcommand*{\xdash}[1][3em]{\rule[0.5ex]{#1}{0.55pt}}
%\newcommand{\sZ}{\ensuremath{\scalebox{.86}{Z}
%\kern-.41em\raisebox{.07em}{$\xdash[.3em]$}}}
%\newcommand{\sz}{\ensuremath{{z}
%\kern-.4em\raisebox{-.045em}{$\xdash[.3em]$}}}
\newcommand{\myparagraph}[1]{\vspace{.01ex} \noindent  \textbf{#1}}
\usepackage{dsfont}
\usepackage{booktabs}
\usepackage{color}
\usepackage{bm}



% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


\newcommand{\ours}[0]{xGA}

%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{3939} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2023}


\begin{document}


\title{Cross-GAN Auditing: Unsupervised Identification of Attribute Level Similarities and Differences between Pretrained Generative Models}


\author{Matthew L. Olson\textsuperscript{\rm 1}, Shusen Liu\textsuperscript{\rm 2}, Rushil Anirudh\textsuperscript{\rm 2}, Jayaraman J. Thiagarajan\textsuperscript{\rm 2}, Peer-Timo Bremer\textsuperscript{\rm 2}, \\ and Weng-Keen Wong\textsuperscript{\rm 1} \\
\textsuperscript{\rm 1} Oregon State University - EECS, \textsuperscript{\rm 2}Lawrence Livermore National Laboratory 
 - CASC\\
{\tt\small \{olsomatt,wongwe\}@oregonstate.edu, \{liu42,anirudh1,jayaramanthi1,bremer5\}}@llnl.gov \\
}



\twocolumn[{%
\renewcommand\twocolumn[1][]{#1}%
\maketitle
\begin{center}
        \centering
        \includegraphics[width=0.90\linewidth]{figures/teaser.pdf}
        \captionof{figure}{
        We introduce (\textbf{xGA}) an approach for fully unsupervised cross-GAN auditing and validation. Given two pre-trained GANs (Reference \& Client), xGA evaluates the client by identifying three types of semantic attributes -- (a) Common: those that exist in both models, (b) Novel: those only present in the client and (c) Missing: those that only exist in the reference.  On the right, we show results across multiple studies, that among others include notable shifts in distribution between the Reference (CelebA) to Client (Toon, Disney, Met Faces). xGA also lends itself easily to comparing models with different properties on the same dataset as shown on the bottom right for StyleGAN3-T vs.\ StyleGAN-R. And CelebA-M is a control dataset we create that does not contain glasses, ties and smiles.
        }
        \label{fig:teaser}
\end{center}%
}]




\begin{abstract}
Generative Adversarial Networks (GANs) are notoriously difficult to train especially for complex distributions and with limited data. This has driven the need for tools to audit trained networks in human intelligible format, for example, to identify biases or ensure fairness. Existing GAN audit tools are restricted to coarse-grained, model-data comparisons based on summary statistics such as FID or recall. In this paper, we propose an alternative approach that compares a newly developed GAN against a prior baseline. To this end, we introduce \emph{Cross-GAN Auditing} ({x}GA) that, given an established ``reference" GAN and a newly proposed ``client" GAN, jointly identifies intelligible attributes that are either \emph{common} across both GANs, \emph{novel} to the client GAN, or \emph{missing} from the client GAN. This provides both users and model developers an intuitive assessment of similarity and differences between GANs. We introduce novel metrics to evaluate attribute-based GAN auditing approaches and use these metrics to demonstrate quantitatively that {x}GA outperforms baseline approaches. We also include qualitative results that illustrate the common, novel and missing attributes identified by {x}GA from GANs trained on a variety of image datasets\footnote{Source code is available at \url{https://github.com/mattolson93/cross_gan_auditing}}.  
\end{abstract}

%%%%%%%%%%%%%%%%%
%
%   Approach it from data 
%
%%%%%%%%%%%%%%%%%%



\input{documentBody/01-intro}
\input{documentBody/02-background}
\input{documentBody/03-methodology}
\input{documentBody/04-results-modified}
\input{documentBody/05-discussion}

%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{00-references}
}
\newpage
\input{supplement/000-supplement}

\end{document}
