\section{Related Work}
\label{sec:related}

\myparagraph{Attribute Discovery} 
Several approaches have been successful in extracting attribute directions in StyleGAN's latent space in the past few years. %
InterfaceGAN~\cite{shen2020interfacegan} used an external classifier and human annotations to label sampled images in order to build a simple linear model that captures the attribute direction in a GAN's latent space. GANSpace~\cite{harkonen2020ganspace} applies PCA to these intermediate representations to find the large factors of variation and then reprojects these directions onto a GAN's latent space. Similarly, SeFa~\cite{shen2021closed} directly captures these directions via matrix factorization of the affine mapping weights in styleGAN, which identify directions of large changes without the need to sample the latent space. An alternative strategy is to directly learn the interpretable directions through a jointly-trained predictive model by assuming that the more predictive variations are more likely to be semantically meaningful \cite{voynov2020unsupervised}-- or that using a Hessian penalty \cite{peebles2020hessian}, or Jacobian \cite{wei2021jacobian}, in the image space enables learning of directions.  LatentCLR \cite{yuksel2021latentclr} used a similar optimization framework, but instead of training a separate predictive model, it leveraged the GAN's internal representation and adopted a contrastive loss \cite{chen2020simple} for attribute discovery. 


\myparagraph{Model Auditing } With increased awareness of the societal impact of machine learning models, there is an increased interest in characterizing and criticizing model behavior under the broad umbrella of auditing \cite{yan22c-fairness-auditing, raji2020closing}. There has been relatively less work in auditing generative models. For example, \cite{alaa2022faithful} introduce a new performance metric for generative models that measures fidelity, diversity, and generalization. Another related work is from Bau et al., \cite{bau2019seeing} who investigate what a GAN cannot generate, whereas our interest is in distinguishing a client GAN from a reference GAN.

\myparagraph{Interpretation of Domain Shift } 
Some of the most related work comes from methods that aim for characterizing domain shift \cite{olson2021unsupervised, olson2021contrastive}, but these methods are limited to specific settings: either relying on human intervention \cite{olson2021unsupervised} or needing a disentangled generator in the input \cite{olson2021contrastive}. An indirect way to obtain aligned attributes is via \emph{aligned GANs}-- GANs where one is fine-tuned from the other ~\cite{wu2021stylealign}, \cite{pinkney2020resolution}. In this setting, the attribute direction will be inherent to the children models, eliminating the need to do joint discovery to identify similar attributes. However, obtaining an \emph{aligned GAN} through a separate fine-tuning process for attribute discovery across distributions is neither practical or even feasible.

