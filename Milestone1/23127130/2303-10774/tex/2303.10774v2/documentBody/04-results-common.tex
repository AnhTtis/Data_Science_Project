\subsection{Evaluation: Common Attribute Discovery}
We begin by evaluating the ability of xGA in recovering common attributes across reference and client models. As mentioned earlier, for effective alignment, the choice of the feature extractor is critical. More specifically, $\mathcal{F}$ must be sufficiently expressive to uncover aligned attributes from both client and reference models. Furthermore, it is important to handle potential distribution shifts across the datasets used to train the GAN models. Hence, a feature extractor that can be robust to commonly occurring distribution shifts is expected to achieve effective alignment via \eqref{eq:xent_1}. In fact, we make an interesting observation that performing attribute discovery in such an external feature space leads to improved disentanglement in the inferred latent directions. For all results reported here, we used a robust variant of ResNet that was trained to be adversarially robust to style variations~\cite{shu2021encoding}. Please refer to the ablation in Section \ref{sec:subsec_ablation} for a comparison of different choices.

\myparagraph{Qualitative results } In Figure \ref{fig:metface}, we show several examples of common attributes identified by xGA for different client-reference pairs, we observe that xGA finds non-trivial attributes. For example, the ``sketchify'' attribute which naturally occurs in Met Faces (a  dataset of paintings), is surprisingly encoded even in the reference CelebA GAN (which only consists of photos of people). We also show examples of other interesting attributes such as ``orange fur'' in the case of dog-GAN $\times$ cat-GAN or ``blonde hair'' in the case of Disney-GAN $\times$ CelebA-GAN.
%In Figure \ref{fig:teaser}, we show other examples across client and reference models that include a large distribution shift (Toon, CelebA) where the attribute corresponds to change in hair color across both domains. Finally, in Figure \ref{fig:cats_vs_dogs}, we show that this works even across seemingly unrelated datasets like Cats and Dogs.
These results indicate that our proposed alignment objective, when coupled with a robust feature space, can effectively reveal common semantic directions across the client and reference models. We include several additional examples in the supplement. 

\myparagraph{Quantitative results }
To perform more rigorous quantitative comparisons, we setup a controlled experiment using $7$ client models corresponding to different CelebA subsets (obtained by excluding images pertinent to specific characteristics). As discussed earlier, we use a standard CelebA StyleGANv2 as the common reference model across all $7$ experiments. Next, we introduce a score of merit for common attribute discovery based on the intuition that images perturbed along the same attribute will result in similar prediction changes, when measured through an ``oracle" attribute classifier \cite{liu2015faceattributes}. 

We first generate a batch of random samples from the latent spaces of client and reference GANs, and manipulate them along a common attribute direction $(\delta_n, \bar{\delta}_n)$ inferred using xGA. In other words, we synthesize pairs of original and attribute-manipulated images from the two GANs and for each pair, we measure the discrepancy in the predictions from an ``oracle' attribute classifier. Mathematically, this can be expressed as $\mathrm{a}^n_i = |\mathcal{C}(\mathcal{G}_c(\mathrm{z}_i, \delta_n)) - \mathcal{C}(\mathcal{G}_c(\mathrm{z}_i))|$ and $\bar{\mathrm{a}}^n_j = |\mathcal{C}(\mathcal{G}_r(\bar{\mathrm{z}}_j, \bar{\delta}_n)) - \mathcal{C}(\mathcal{G}_r(\bar{\mathrm{z}}_j))|$, where $\mathcal{C}$ is the attribute classifier trained using the labeled CelebA dataset. Finally, we define an alignment score that compares the expected prediction discrepancy across the two GANs using cosine similarity (higher value indicates alignment).
\begin{align}
\label{eq:cocosine}
\mathcal{A}_{\text{score}} = & \mathbb{E}_n \bigg[\cos\bigg(\mathbb{E}_i[\mathrm{a}^n_i], \mathbb{E}_j [\bar{\mathrm{a}}^n_j] \bigg)\bigg],
%\bm{\bar{a}}_{(n,1)}, \bm{\bar{a}}_{(n,2)}
%=  \frac {\bm{\bar{a}}_{(n,1)} \cdot \bm{\bar{a}}_{(n,2)}}{||\bm{\bar{a}}_{(n,1)}|| \cdot ||\bm{\bar{a}}_{(n,2)}||}
\end{align}where the inner expectations are w.r.t. the batch of samples and the outer expectation is w.r.t. the $N_c$ common attributes.
\begin{figure}[!htbp]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/common.pdf}
    \caption{Visualizing common attributes discovered using xGA for different client-reference GAN pairs. For each case, we illustrate one common attribute (indicated by our description in green) with two random samples from the GAN latent space. } 
    \label{fig:metface}
\end{figure}


We implement $5$ baseline approaches that apply state-of-the-art attribute discovery methods to the client and reference GANs (independently), and subsequently peform greedy, post-hoc alignment. In particular, we consider SeFa \cite{shen2021closed}, Voynov \cite{voynov2020unsupervised}, LatentCLR \cite{yuksel2021latentclr}, Jacobian \cite{wei2021jacobian}, and Hessian \cite{peebles2020hessian} methods for attribute discovery. Given the attributes for the two GANs, we use predictions from the ``oracle'' attribute classifier to measure the degree of alignment between every pair of directions. For example, the pair with the highest cosine similarity score is selected as the first common attribute. Next, we use the remaining latent directions to greedily pick the next attribute, and this process is repeated until we obtain $N_c=12$ attributes. We compute the alignment score from \eqref{eq:cocosine} for all the methods and report results from the $7$ controlled experiments in Table \ref{tbl:celeba_metrics_common_novel}. Interestingly, we find that, despite using the ``oracle'' classifier for alignment, the performance of the baseline methods is significantly inferior to xGA. This clearly evidences the efficacy of our optimization strategy.

\input{tables/celeba_scores_common_novel}
