\section{Methods}
We approach GAN auditing as performing attribute-level comparison to a reference GAN. For simplicity, we consider the setup where there is a single reference and client model to perform auditing, though xGA can be used even with multiple reference or client models (see experiments). Let us define the reference and client generators as $\mathcal{G}_r: \mathcal{Z}_r \mapsto \mathcal{X}_r$ and $\mathcal{G}_c: \mathcal{Z}_c \mapsto \mathcal{X}_c$ respectively. Here, $\mathcal{Z}_{r}$ and $\mathcal{Z}_{c}$ refer to the corresponding latent spaces and the generators are trained to approximate the data distributions $P_r(\mathrm{x})$ and $P_c(\mathrm{x})$. Our formulation encompasses the scenario where $P_r(\mathrm{x}) = P_c(\mathrm{x})$ but the model architectures are different, or the challenging setting of $P_r(\mathrm{x}) \neq P_c(\mathrm{x})$ (e.g., CelebA faces vs Met Faces datasets). 


\begin{figure}[t]
\centering
         
         \includegraphics[width=1.00\linewidth]{figures/xga_explained.png}
        \caption{
        A table showing the proposed xGA modifications to typical contrastive loss with a simple two attribute model.  
        }
        \label{fig:pos_neg_table}
\end{figure}

The key idea of xGA is to audit a client model $\mathcal{G}_c$ via attribute (i.e., directions in the latent space) comparison to a reference model, in lieu of computing summary scores (e.g., FID, recall) from the synthesized images. In order to enable a fine-grained, yet interpretable, analysis of GANs, xGA performs automatic discovery and categorization of latent attributes: (i) \textit{common}: attributes that are shared by both the models; (ii) \textit{missing}: attributes that are captured by $\mathcal{G}_r$, but not $\mathcal{G}_c$; (iii) \textit{novel}: attributes that are encoded in $\mathcal{G}_c$ but not observed in the reference model. We express this new categorization scheme in figure \ref{fig:pos_neg_table}. Together, these latent attributes can provide a holistic characterization of GANs, while circumventing the need for customized metrics or human-centric analysis.

\noindent \textbf{Latent attributes}: Following state-of-the-art approaches such as LatentCLR \cite{yuksel2021latentclr}, we define attributes as direction vectors in the latent space of a GAN. For any sample $\mathrm{z} \in \mathcal{Z}_c$ and a direction vector $\mathrm{\delta}_n$, we can induce attribute-specific manipulation to the corresponding image as
\begin{equation}
\label{eq:direction}
    \mathcal{D}: (\mathrm{z}, \mathrm{\delta}_n)\rightarrow \mathrm{z} + \alpha \mathrm{\delta}_n,\mbox{ where }\mathrm{\delta}_n = \frac{\mathbf{M}_n\mathrm{z}}{\lVert \mathbf{M}_n\mathrm{z}\rVert},
\end{equation}for a scalar $\alpha$, and a learnable matrix $\mathbf{M}_n$. In other words, we consider the attribute change to be a linear model defined by the learnable direction $\mathrm{\delta}_n$. The manipulated image can then be obtained as $\mathcal{G}_c(\mathcal{D}(\mathrm{z},\mathrm{\delta}_n))$, or in shorter notation $\mathcal{G}_c(\mathrm{z},\mathrm{\delta}_n)$. Note that these latent attributes are not pre-specified and are discovered as part of the auditing process.


\subsection{Common Attribute Discovery}
Identifying common attributes between the client and reference GAN models is challenging, since it requires that the latent directions are \emph{aligned}, i.e., the exact same semantic change must be induced in unrelated latent spaces. When distilling from a parent model, i.e., training Toons from  Faces, attributes appear to align naturally, even under severe distribution shifts~\cite{wu2021stylealign}.
However, this does not hold true when the two models are trained independently, which requires us to  solve the joint problem of identifying the attributes as well as explicitly aligning them.

Formally, for a common attribute, we want the semantic change (in the generated images) induced by manipulating any sample $\mathrm{z} \in \mathcal{Z}_c$ along a direction $\delta$ in the client GAN's latent space to match the change in the direction $\bar{\delta}$ from the reference GAN's latent space for any $\bar{\mathrm{z}} \in \mathcal{Z}_r$. In other words, $\mathrm{S}(\mathcal{G}_c(\mathrm{z},\delta), \mathcal{G}_c(\mathrm{z})) \approx \mathrm{S}(\mathcal{G}_r(\bar{\mathrm{z}}, \bar{\delta}),\mathcal{G}_r(\bar{\mathrm{z}})), \forall~z \in \mathcal{Z}_c, \bar{\mathrm{z}} \in \mathcal{Z}_r$. Here, $\mathrm{S}$ denotes an \textit{oracle} detector (e.g., human subject test) which measures the semantic changes between the original sample and that obtained by manipulating the common attribute.

However, in practice, such a semantic change detector is not accessible and we need to construct a surrogate mechanism to quantify the alignment, i.e., 
\begin{multline}
\label{eq:alignment_1}
     \min_{\mathrm{\delta}_n, \bar{\mathrm{\delta}}_n} \mathcal{L}\bigg(\mathcal{G}_c(\mathrm{z},\mathrm{\delta}_n), \mathcal{G}_r(\bar{\mathrm{z}}, \bar{\mathrm{\delta}}_n)\bigg), \forall \mathrm{z}\in \mathcal{Z}_c, \forall \bar{\mathrm{z}}\in \mathcal{Z}_r,
\end{multline}for a common attribute pair $(\mathrm{\delta}_n,\bar{\mathrm{\delta}}_n)$. Any choice of the loss function $\mathcal{L}$ must satisfy two key requirements: (a) identify high-quality, latent 
directions within each of the latent spaces; 
(b) encourage cross-GAN alignment such that similar attributes end up being strongly correlated under the loss function. For example, in the case of a single GAN, the LatentCLR~\cite{yuksel2021latentclr} approach learns distinct directions using a contrastive objective that defines positive samples as those that have all been perturbed in the same direction, while manipulations in all other directions are considered negative\footnote{Other single GAN methods could be adapted, but LatentCLR's flexible loss requires less computation without the need to enforce orthogonality at every learning step.}. However, this approach is not suitable for our setting because of a key limitation -- alignment requires us to operate in a common feature space so that semantics across the two models are comparable. To address this, we first modify the objective  to operate in the latent space of an external, pre-trained feature extractor $\mathcal{F}$. In order to support alignment even in the scenario where $P_c(\mathrm{x}) \neq P_r(\mathrm{x})$, we can choose $\mathcal{F}$ that is robust to commonly occurring distributional shifts. 

Our approach works on mini-batches of size $B$ samples each, randomly drawn from $\mathcal{Z}_c$ and $\mathcal{Z}_r$ respectively. For the $i^{\text{th}}$ sample in a mini-batch from $\mathcal{Z}_c$, let us define the vector $\mathrm{h}_i^n$ as the divergence between the output of the GAN before and after perturbing along the $n^{\text{th}}$ latent direction, computed in the feature space of $\mathcal{F}$, \textit{i.e.}, 
$h_i^n = \mathcal{F}(\mathcal{G}_c(\mathrm{z}_i,\mathrm{\delta}_n)) - \mathcal{F}(\mathcal{G}_c(\mathrm{z}_i)).$ Similarly, we define the divergence $\bar{\mathrm{h}}_j^n = \mathcal{F}(\mathcal{G}_r(\bar{\mathrm{z}}_j,\bar{\mathrm{\delta}}_n)) - \mathcal{F}(\mathcal{G}_r(\bar{\mathrm{z}}_j))$ for the reference GAN. Next, we measure the semantic similarity between the divergence vectors as 
$g(\mathrm{h}_i^n,\bar{\mathrm{h}}_j^n) = \exp(\mathrm{cos}(\mathrm{h}_i^n,\bar{\mathrm{h}}_j^n)/\tau),$ where $\tau$ is the temperature parameter, and $\mathrm{cos}$ refers to cosine similarity. Now, the loss function for inferring a common attribute can be written as

\begin{equation}
\begin{split}
\label{eq:xent_1}
    \displaystyle &\mathcal{L}_{\text{xent}}(\mathrm{\delta}_n,\bar{\mathrm{\delta}}_n, \lambda_a) = \\ 
    & -\log \frac{\sum\limits_{i=1}^B \sum\limits_{j\neq i}^B 
    g(\mathrm{h}_i^n,\mathrm{h}_j^n) + g(\bar{\mathrm{h}}_i^n,\bar{\mathrm{h}}_j^n)  + \lambda_{\text{a}}g(\bar{\mathrm{h}}_i^n,\mathrm{h}_j^n)
    }{\sum\limits_{
    \substack{
       i=1 \\
       j=1
      }
    }^B\sum\limits_{l=1}^{N}\mathds{1}_{[l\neq n]}\bigg( 
    g(\mathrm{h}_i^l,\mathrm{h}_j^n) + g(\bar{\mathrm{h}}_i^l,\bar{\mathrm{h}}_j^n) + g(\bar{\mathrm{h}}_i^l,\mathrm{h}_j^n) \bigg)}
\end{split}
\end{equation}
Here $N$ denotes the total number of attributes. While the first two terms in the numerator are aimed at identifying distinct attributes from $\mathcal{G}_c$ and $\mathcal{G}_r$, the third term enforces the pair $(\delta_n, \bar{\delta}_n)$ to induce similar semantic change. When the $\lambda_a$ parameter is set to $0$, this optimization reinforces self-similarity of the attributes, without cross-similar semantics.  The terms in the denominator are based on the negative pairs (divergences from different latent directions) to enable contrastive training.

\subsection{Novel \& Missing Attribute Discovery}
A key component of our GAN auditing framework is the discovery of interpretable attributes that are unique to or missing from the client GAN's latent space. This allows practitioners to understand the novelty and limitations of a GAN model with respect to a well-established reference GAN. To this end, we exploit the key intuition that images synthesized by manipulating an attribute specific to the client model can manifest as out-of-distribution (OOD) to the reference model (and vice versa).

In order to characterize the OOD nature of such realizations, we define a likelihood score in the feature space from $\mathcal{F}$, which indicates whether a given sample is out of distribution. More specifically, we use the Density Ratio Estimation (DRE) \cite{sugiyama2012density,Nam15} method that seeks to approximate the ratio: $\mathrm{\gamma}(\mathrm{x}) = \frac{P(\mathrm{x})}{Q(\mathrm{x})}$ for any sample $\mathrm{x}$. When the ratio is low, it is likely that $\mathrm{x}$ is from the distribution $Q$ and hence OOD to $P$. We choose DRE, specifically the Kullbeck-Liebler Importance Estimation Procedure (KLIEP) \cite{sugiyama2008}, over other scoring functions because it is known to be highly effective at accurately detecting outliers \cite{menon16}.

\begin{figure}[t]
\centering
         
         \includegraphics[width=1.00\linewidth]{figures/xga_diagram_detailed.png}
        \caption{
        A diagram of our xGA model. $\mathcal{G}_{r}$, $\mathcal{G}_{c}$, and $\mathcal{F}$ are fixed pretrained models. $\delta_n$ and $\bar{\delta}_n$ are direction models trained to learn aligned attributes between the two Generators using the features of $\mathcal{F}$, and $f_{dre}$ are regularization models for unique attributes. 
        }
        \label{fig:latentCLR}
\end{figure}


We pre-train two separate DRE models to approximate $\mathrm{\gamma}_c(\mathrm{z})$, and $\mathcal{\gamma}_r(\bar{\mathrm{z}})$, wherein we treat data from $\mathcal{F}(\mathcal{G}_c(\mathrm{z}))$ as $P$ and $\mathcal{F}(\mathcal{G}_r(\bar{\mathrm{z}}))$ as $Q$ for the former, and vice versa for the latter. These DRE models are implemented as 2-layer MLP networks, $f^c_{\text{dre}}(.), f^r_{\text{dre}}(.)$, such that 
\begin{equation}
\label{eq:DRE_models}
    \hat{\mathrm{\gamma}}_c(\mathrm{z}) = f^c_{\text{dre}}(\mathcal{F}(\mathcal{G}_c(\mathrm{z}))) \mbox{ and }  \hat{\mathrm{\gamma}}_r(\bar{\mathrm{z}}) = f^r_{\text{dre}}(\mathcal{F}(\mathcal{G}_r(\bar{\mathrm{z}}))),
\end{equation}where $\mathcal{F}$ is the same feature extractor from \eqref{eq:xent_1}. We pass the output of the MLPs through a softplus ($\varphi(\mathrm{x}) = \log(1+e^{\mathrm{x}})$) function to ensure non-negativity. As stated previously, we use the KLIEP method to train DRE models. Using Section 4.1 of \cite{menon16}, the KLIEP loss used for training is defined as:
\begin{equation}
\label{eq:dre_train}
\mathcal{L}^c_{\text{KLIEP}} = \frac{1}{T_{2}} \sum_{j=1}^{T_{2}} \hat{\mathrm{\gamma}}_c\left(\mathrm{\bar{\mathrm{z}}}_j\right) - \frac{1}{T_{1}} \sum_{i=1}^{T_{1}} \ln \hat{\mathrm{\gamma}}_c(\mathrm{z}_i),
\end{equation}where $\bar{\mathrm{z}}_j$ and $\mathrm{z}_i$ are random samples drawn from the latent spaces $\mathcal{Z}_r$ and $\mathcal{Z}_c$ respectively (with $T_1$ and $T_2$ total samples). Similarly, we can define the KLIEP loss term for the reference model as:
\begin{equation}
\label{eq:dre_train2}
\mathcal{L}^r_{\text{KLIEP}} = \frac{1}{T_{1}} \sum_{i=1}^{T_{1}} \hat{\mathrm{\gamma}}_r\left(\mathrm{\mathrm{z}}_i\right) - \frac{1}{T_{2}} \sum_{j=1}^{T_{2}} \ln \hat{\mathrm{\gamma}}_r(\bar{\mathrm{z}}_j).
\end{equation}

We also investigated using log-loss functions to train the DRE model, but found it to be consistently inferior to the KLIEP losses (see supplement for details). Finally, we use the pre-trained DRE models from the client and reference GAN data to identify novel and missing attributes, where for a given attribute $n$ in the reference GAN, we can enforce its uniqueness by utilizing the client DRE model to give us 
$ \mathcal{L}_{\text{Unique}}^r(\mathrm{\delta}_n) = \hat{\mathrm{\gamma_c}}(\mathrm{z}, \mathrm{\delta}_n ) $ 
and similarly for the client GAN we can use the reference DRE model 
$\mathcal{L}_{\text{Unique}}^c(\mathrm{\bar{\delta}}_n) = \hat{\mathrm{\gamma_r}}(\mathrm{\bar{z}}, \mathrm{\bar{\delta}}_n ) $ 
Note, we interpret the novel attributes from the reference GAN as the missing attributes for the client GAN. 

\subsection{Overall Objective}
We now present the overall objective of xGA to identify $N_c$ common, $N_n$ novel and $N_m$ missing attributes simultaneously. Denoting the total number of attributes $N = N_c + \text{max}(N_n, N_m)$, the total loss can be written as:
\begin{equation}
\begin{split}
\label{eq:full_xga}
    \nonumber \mathcal{L}_{\text{xGA}} = & \sum_{n=1}^{N} \mathcal{L}_{\text{xent}}(\delta_n, \bar{\delta}_n, \mathds{1}_{[n\leq N_c]} \lambda_a) \\
        \nonumber & + \lambda_b \bigg[ 
        \sum_{p=N_c+1}^{N_c + N_n} 
        \mathcal{L}_{\text{Unique}}^c(\mathrm{\bar{\delta}}_p)  
          + \sum_{q=N_c + 1}^{N_c + N_m} \mathcal{L}_{\text{Unique}}^r(\mathrm{\delta}_q)  
          \bigg] 
\end{split}
\end{equation}
Here, the hyper-parameter $\lambda_b$ is the penalty for enforcing the attributes between the two latent spaces to be disparate (missing/novel). And we set $g( . , . )=0$ in $L_{xent}$ if one of the directions vectors does not exist (i.e. when $N_n \neq N_m$).




 

