\appendix

\section{Ablation study}
First, we investigate the effect of the $\lambda_b$ parameter on KLIEP loss that allows us to discover novel attributes. In addition to KLIEP loss presented in the main text, we analyze a model trained with simple log loss used to train binary classifiers to predict the likelihood of a given sample. 

\subsection{Log Loss Model}
 This model, we denote as LOG, is nearly identical to the DRE models except instead of a softplus final activation, it uses a sigmoid function $\sigma(x) = \frac{1}{1 + e^{-x}}$. 
These models are used to classify whether a given feature belongs to $\mathcal{G}_c(z)$ or $\mathcal{G}_r(\bar{z})$.  We pre-train two separate LOG models to approximate $\hat{\gamma}_c(x) = \hat{p}_c(x)$, and $\hat{\gamma}_r(x) =  \hat{p}_r(x)$, where we treat $\mathcal{G}_c$ as $P(\mathrm{x} | Y = 1)$ and  $\mathcal{G}_r$ as $P(\mathrm{x} | Y = 0)$. These LOG models are learned using simple 2-layer MLPs, $f^c_{LOG}(~), f^r_{LOG}(~)$, such that 
\begin{equation}
\label{eq:log_models}
    \hat{\mathrm{\gamma}}_c(\mathrm{z}) = f^c_{\text{LOG}}(\mathcal{F}(\mathcal{G}_c(\mathrm{z}))) \mbox{ and }  \hat{\mathrm{\gamma}}_r(\bar{\mathrm{z}}) = f^r_{\text{LOG}}(\mathcal{F}(\mathcal{G}_r(\bar{\mathrm{z}}))),
\end{equation} where $\mathcal{F}$ is the same Encoder model used in main paper's equation 3.

The loss used for training the LOG models is defined as follows:
\begin{equation}
\mathcal{L}^c_{\text{Log}} = \frac{1}{T_{2}} \sum_{j=1}^{T_{2}} - \log (1 - \hat{\gamma}_c\left(\mathrm{\bar{z}}_j\right) )
                           + \frac{1}{T_{1}} \sum_{i=1}^{T_{1}} - \log (\hat{\gamma}_c\left(\mathrm{z  }_i)\right)
\end{equation}



where $\mathrm{\bar{z}}_j$ and $\mathrm{z}_i$ are random samples drawn from the latent space of each generator. The loss term for the second model LOG model is 
\begin{equation}
\mathcal{L}^r_{\text{Log}} = \frac{1}{T_{1}} \sum_{j=1}^{T_{1}} - \log (1 - \hat{\gamma}_r\left(\mathrm{\bar{z}}_j\right) )
                           + \frac{1}{T_{2}} \sum_{i=1}^{T_{2}} - \log (\hat{\gamma}_r\left(\mathrm{z  }_i)\right)
\end{equation}

The LOG models $f^1_{LOG}(~), f^2_{LOG}(~)$ are  trained to minimize $\mathcal{L}^1_{\text{Log}},\mathcal{L}^2_{\text{Log}}$ respectively. 

Finally, the trained LOG models are used to minimize the loss in equation 7 (rather than DRE models); the objective in equation 7 remains the same.



\input{tables/dre_lambda_ablation}
\subsection{Missing attribute ablation study results} 

Table \ref{tbl:dre_lambda_abl} illustrates the missing attribute discovery score for each CelebA split versus full CelebA. With $\lambda=0$ (i.e. ignoring the DRE loss), the attribute discovery process has difficulty capturing some missing attributes. When using a regularization model trained with Log-loss, the results are consistently worse than DRE, sometimes even worse than with $\lambda=0$. The KLIEP loss model, on the other hand, performs consistently better for all lambda values $>0$.




\section{Same dataset, different architecture}
\begin{figure}[!tb]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/pggan_v_gansformer.pdf}
    \caption{An example of applying our method to two generative models trained on the same dataset (FFHQ). We find ProgGAN and GANformer are able to find some alignment, and that the newer model (GANformer) is better at capturing the full data distribution of FFHQ (Missing) whereas ProgGAN is prone to generating non-realistic images (Novel).}
     \label{fig:proggan_v_gansformer}
\end{figure}

\begin{figure}[!tb]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/sg3.pdf}
    \caption{A few examples from our experiment applying xGA between two StyleGAN3 models, both trained on FFHQ, but with different model configurations. As expected both models having translation equivarience, and the rotation equivariance is missing from the translation model. }
     \label{fig:sg3}
\end{figure}

To verify the effectiveness of xGA at comparing models trained on the same dataset with different configurations, we perform two sets of experiments. We use Prog-GAN \cite{karras2017progressive} (client) and GANformer \cite{hudson2021ganformer2} (reference) trained on the FFHQ dataset. Figure \ref{fig:proggan_v_gansformer} shows an example of how these two GANs can be aligned, and how the novel/missing attribute reflects each GAN's capacity to learn the data distribution. 
We also use two configurations of a StyleGAN3 \cite{karras2021alias} trained on FFHQ. Figure \ref{fig:sg3} shows how translation equivarience is preserved in both models, whereas only the StyleGAN3-r model is rotationally equivarient.



\begin{figure}[!tb]
     \centering
     \includegraphics[width=0.99\linewidth]{figures/1gan_example.pdf}
     \caption{Comparing xGA on single GAN attribute discovery with existing approaches, we find that more diverse and novel attributes can be found simply by using an external feature space. We exploit this for effective alignment across two GAN models. Complete examples for all methods are provided below. 
     }
     \label{fig:1gan_examples}
 \end{figure}


\section{Single GAN results}
Here we present the full training of all learned directions for each of our methods using the same starting point from CelebA GAN.
Figure \ref{fig:1gan_examples} visualizes a shortened example of the top $3$ attributes (induce most changes in the ``oracle'' classifier predictions) and it is clear that xGA identifies the most diverse semantic changes. Complete results can be seen as follows:
\begin{enumerate}
    \item Sefa \cite{shen2021closed}: Figure \ref{fig:supp-singlegan-sefa}
    \item LatentCLR \cite{yuksel2021latentclr}: Figure \ref{fig:supp-singlegan-latentclr}
    \item Voynov \cite{voynov2020unsupervised}: Figure \ref{fig:supp-singlegan-voynov}
    \item Hessian \cite{peebles2020hessian}: Figure \ref{fig:supp-singlegan-hessian}
    \item Jacobian \cite{wei2021jacobian}: Figure \ref{fig:supp-singlegan-jacobian}
    \item xGA (ImageNet ResNet-50): figure \ref{fig:supp-singlegan-resnet}
    \item xGA (advBN ResNet-50): figure \ref{fig:supp-singlegan-advbn}
    \item xGA (CLIP ResNet-50): figure  \ref{fig:supp-singlegan-clip}
\end{enumerate}
We visualize both positive and negative directions for every model. Even though xGA and LatentCLR are not directly trained for negative directions, we find these attributes to be semantically meaningful and interesting.


Next we present an example where we compare two LatentCLR models trained on different GANs where the reference GAN is CelebA and client GAN is CelebA without Hats. We sort all the directions by most similar (as described in the main paper) and show an example of the results in Figure \ref{fig:supp-2singleGANs-sorted}, finding many similarities, but no dedicated Hat attribute in the reference GAN. Showing how without the dedicated constraint of the DRE models, finding missing attributes is difficult.

\section{Expanded Qualitative Results}
Here we present many additional examples of shared directions between two GANs,
and novel/missing directions from a few different GAN pairs that contain subset of the CelebA dataset. 
We introduce a new GAN (anime), as it produces interesting common, missing, and novel attributes, though the GAN itself produces lower quality images than other models, and as such we leave it here in the supplement.
The figures are arranged as follows:
\begin{enumerate}
    \item Common attributes: CelebA (reference) and Metface (client) sketch (\ref{fig:supp-metface_sketch}), formal (\ref{fig:supp-metface_formal}), and curly hair  (\ref{fig:supp-metface_curly})
    \item Common attributes: Anime (client) and Toon (reference) purple hair (\ref{fig:supp-anime_purplehair}), orange/brown hair (\ref{fig:supp-anime_orangehair}), open mouths (\ref{fig:supp-anime_mouths}), and smiling (\ref{fig:supp-anime_smiles}); missing attributes of green hair / lipstick (\ref{fig:supp-anime_uniques})
    \item Common attributes: CelebA (reference) and Disney (client) blonde hair (\ref{fig:supp-disney_blonde}), and brown hair (\ref{fig:supp-disney_brown}); novel Disney attributes of turning green / cartoonish eyes (\ref{fig:supp-disney_uniques})
    \item Additional missing attributes from different CelebA client GANs, with CelebA reference GAN (\ref{fig:supp-celeba_uniques})
\end{enumerate}

\section{Expanded Quantitative Results}

First we present the results for using ViT-based feature extractors in table \ref{tbl:supp-vit-experiments}. We include 3 different pretrained models: one original trained on ImageNet, CLIP, and MAE. While ViT does well for entropy metric, it performs poorly for cross model based experiments.

Next, we present the entire results for our missing attribute quantitative experiments. To recap these experiments, we use the $7$ controlled CelebA models which are missing one or more attributes (hat, glasses, male, female, beard, beards|hats, and smiles|glasses|ties) and treat them as the client model; we audit these models with respect to the reference CelebA GAN. The $7$ missing attribute experiments are shown in table \ref{tbl:supp-full-recovery}, where we can see xGA performs well (e.g., easily finding the missing glasses attribute). The $7$ attribute alignment experiments are shown in table \ref{tbl:supp-full-alignment}, where again we see xGA with a robust resnet performs well, especially when the client GAN is missing multiple attributes (e.g., client GAN is missing beards and hats).

For completion's sake, we run pairwise experiments between each GAN, treating each GAN as reference versus the other $7$ GANs, which results in a total of $56$ client/reference paired experiments. We report these comprehensive results in the following tables (where rows are reference GAN and columns are the client): \ref{tbl:supp-unique-voynov}, \ref{tbl:supp-unique-latentclr}, \ref{tbl:supp-unique-hessian}, \ref{tbl:supp-unique-jacobian}, \ref{tbl:supp-unique_vanilla} , \ref{tbl:supp-unique_att} ,  \ref{tbl:supp-unique_robust} ,  \ref{tbl:supp-unique_rnclip} ,  \ref{tbl:supp-unique_vit} ,  \ref{tbl:supp-unique_clipvit} , and  \ref{tbl:supp-unique_mae}. 
We also compute the the common attribute results experiments in the following tables: \ref{tbl:supp-cosine-voynov},\ref{tbl:supp-cosine-latentclr},\ref{tbl:supp-cosine-hessian},\ref{tbl:supp-cosine-jacobian},  \ref{tbl:supp-cosine-vanilla}, \ref{tbl:supp-cosine-att}, \ref{tbl:supp-cosine-robust}, \ref{tbl:supp-cosine-clipRN}, \ref{tbl:supp-cosine-vit}, \ref{tbl:supp-cosine-clipvit}, and \ref{tbl:supp-cosine-mae}.

\begin{table*}[!tb]\centering
\begin{tabular}{llllllll}
                       & Female & Male  & No Hats & No Glasses & No Beards & \begin{tabular}[c]{@{}l@{}}No Beard\\ No Hats\end{tabular} & \begin{tabular}[c]{@{}l@{}}No Glasses\\ No Smiles\\ No Ties\end{tabular} \\ \hline
SeFa                    & 0.143  & 0.143 & 0.045   & 0.111      & 0.063     & 0.278       & 0.189  \\
jacobian                & 0.478  & 0.536 & 0.086   & 0.390      & 0.388     & 0.120       & 0.287  \\
Hessian                 & 1.000  & 1.000 & 0.056   & 0.167      & 0.167     & 0.096       & 0.407  \\
LatentCLR               & 1.000  & 1.000 & 0.250   & 0.333      & 0.200     & 0.153       & 0.537  \\
Voynov                  & 0.500  & 1.000 & 0.333   & 0.050      & 0.500     & 0.153       & 0.259  \\
xGA (ResNet-50)         & 1.000  & 1.000 & 0.333   & 0.500      & 0.200     & 0.167       & 0.465  \\
xGA (Clip ResNet-50)    & 1.000  & 1.000 & 1.000   & 0.200      & 0.200     & 0.108       & 0.383  \\
xGA (advBN ResNet-50)   & 1.000  & 1.000 & 0.250   & 1.000      & 0.063     & 0.183       & 0.401  \\ \hline
\end{tabular}
\caption{The full results for the recovery scores ($\mathcal{R}_{\text{score}}$), where CelebA GAN is the reference.}
 \label{tbl:supp-full-recovery}
\end{table*}




\begin{table*}[!tb] \centering
\begin{tabular}{llllllll}
              & Female & Male  & No Hats & No Glasses & No Beards & \begin{tabular}[c]{@{}l@{}}No Beard\\ No Hats\end{tabular} & \begin{tabular}[c]{@{}l@{}}No Glasses\\ No Smiles\\ No Ties\end{tabular} \\ \hline
SeFa                    & 0.413  & 0.458 & 0.372   & 0.374      & 0.314     & 0.387    & 0.355  \\
Hessian                 & 0.475  & 0.489 & 0.652   & 0.598      & 0.618     & 0.615    & 0.525  \\
LatentCLR               & 0.519  & 0.511 & 0.556   & 0.533      & 0.512     & 0.593    & 0.579  \\
Voynov                  & 0.566  & 0.477 & 0.567   & 0.555      & 0.570     & 0.562    & 0.513  \\
Jacobian                & 0.523  & 0.452 & 0.505   & 0.528      & 0.519     & 0.491    & 0.495  \\
xGA (ResNet-50)         & 0.457  & 0.403 & 0.740   & 0.792      & 0.461     & 0.643    & 0.489  \\
xGA (Clip ResNet-50)    & 0.753  & 0.451 & 0.772   & 0.791      & 0.894     & 0.580    & 0.656  \\
xGA (advBN ResNet-50)   & 0.615  & 0.357 & 0.750   & 0.825      & 0.619     & 0.803    & 0.649  \\ \hline
\end{tabular}
\caption{The full results for the alignment scores ($\mathcal{A}_{\text{score}}$), where CelebA GAN is the reference}
 \label{tbl:supp-full-alignment}
\end{table*}

\begin{table*}[!tb]
\centering
\begin{tabular}{llll}
Method / Model      &   $\mathcal{H}_{\text{score}}$ ($\downarrow$)    &  $\mathcal{A}_{\text{score}}$ ($\uparrow$) & $\mathcal{R}_{\text{score}}$ ($\uparrow$) \\ \hline
xGA + ViT         &   $1.988 \pm{0.068}$    & $0.377 \pm{0.090} $    & $0.249 \pm{0.217}$          \\
xGA + ViT + MAE   &   $2.102 \pm{0.035}$    & $0.349 \pm{0.089}$          & $0.194 \pm{0.197}$         \\ 
xGA + ViT + Clip  &   $2.091 \pm{0.041}$    & $0.397 \pm{0.122}$          & $0.268 \pm{0.195}$          \\ 
\hline
\end{tabular}
\caption{ ViT-based extractors results. The average entropy scores for all 8 CelebA experiments, the average alignment scores ($\mathcal{A}_{\text{score}}$) for the CelebA pairwise experiments, and the average recovery scores ($\mathcal{R}_{\text{score}}$) for the CelebA pairwise leave-attribute-out experiments ($\pm{\text{ std}}$)} 
\label{tbl:supp-vit-experiments}
\end{table*}


\input{supplement/006-supp-1gan.tex}

\input{supplement/003-supp-metface}
\input{supplement/004-supp-anime}
\input{supplement/002-supp-disney}
\input{supplement/005-supp-celeba-unique}
\newpage
\input{supplement/001-supplement-tables}