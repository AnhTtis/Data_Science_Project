\section{Introduction} \label{intro_section}

Digital tree models have many applications, such as biomass estimation \cite{fan2020adqsm,kankare2013individual,fan2020new}, growth modelling \cite{tompalski2021estimating,spalding2013image,chaudhury2018machine}, forestry management \cite{white2013utility,molina2022operationalizing,calders2020terrestrial}, urban microclimate simulation \cite{xu20213d}, and agri-tech applications, such as robotic pruning \cite{zahid2021technological,botterill2017robot}, and fruit picking \cite{arikapudi2021robotic}. 

A comprehensive digital tree model relies on the ability to extract a skeleton from a point cloud. In general, a skeleton is a thin structure that encodes an object's topology and basic geometry \cite{chaudhury2020skeletonization}.
Skeleton extraction from 3D point clouds has been studied extensively in computer vision and graphics literature \cite{saha2016survey} for understanding shapes and topology. Applied to tree point clouds, this is a challenging problem due to self-occlusions, complex geometry, touching branches, and varying point densities.

There are many existing approaches for recovering tree skeletons from point clouds (recent survey \cite{cardenas2022modeling}). These approaches can be categorized as follows; neighbourhood graph, medial axis approximation, voxel and mathematical morphology, and segmentation. 

Neighbourhood graph methods use K-nearest neighbours (usually within a search radius) or Delaunay triangulation to create an initial graph from the point cloud. Multiple implementations \cite{verroust1999extracting,xu2007knowledge,delagrange2014pypetree,hackenberg2015simpletree}, then use this graph to quantize the points into bins based on the distance from the root node. The bin centroids are connected based on constraints to create a skeleton.  
Livny et al. \cite{livny2010automatic} use the neighbourhood graph to perform global optimizations based on a smoothed orientation field. 
Du et al. \cite{du2019adtree} use the graph to construct a Minimum Spanning Tree (MST) and perform iterative graph simplification to extract a skeleton. A disadvantage of these methods is that gaps in the point cloud (for example, due to occlusions) may result in a disconnected neighbourhood graph. False connections are also problematic, in particular when branches pass nearby.

Medial axis approximation works by estimating the medial surface and then thinning it to a medial axis. An approach in the \emph{L1-Medial Skeleton} method \cite{huang2013l1} was proposed for point clouds by iterative sampling and redistributing points to the sample centre. Similarly, Cao et al. \cite{cao2010point} proposed using Laplacian-based contraction to estimate the medial axis. The main disadvantage of these methods is the sensitivity to irregularities in the point cloud and the requirement for a densely sampled object as input. 

Voxel and mathematical morphology were implemented in \cite{gorte2004structuring} and later refined in \cite{gorte2006skeletonization}. The point cloud is converted into a 3D voxel grid and then undergoes opening and closing, resulting in a thinned voxel model.
The voxel spatial resolution is a key parameter, as a too-fine resolution will lead to many holes. In contrast, a larger resolution can lose significant detail as multiple points become a single voxel (different branches may all become connected). A further limitation of this method is the required memory and time, which increases with the third power of the resolution. This method only aims to find prominent structures of trees rather than finer branches.

Segmentation approaches work by segmenting points into groups from the same branch. Raumonen \cite{raumonen2013fast} et al. create surface patches along the tree and then grow these patches into branches. The main disadvantage of this method is that it assumes local areas of the tree have a uniform density. 

Recently a deep learning segmentation approach was proposed in TreePartNet \cite{liu2021treepartnet}. This method uses two networks, one to detect branching points and another to detect cylindrical representations. It requires a sufficiently sampled point cloud as it relies on the ability to detect junctions accurately and embed local point groups. However, it cannot work on larger point clouds due to the neural network memory constraints of PointNet++ \cite{qi2017pointnet++}. Numerous network architectures can process point clouds \cite{guo2020deep}; however, point clouds in general, but in particular, trees are spatially large and sparse, containing fine details - for this reason, we utilise submanifold sparse CNNs \cite{graham2017submanifold,spconv2022,tang2022torchsparse,choy20194d}. 

We propose a deep-learning-based method to estimate the medial axis of a tree point cloud. A neighbourhood graph approach then extracts the skeleton. This method mitigates the effects of errors commonly caused when neighbouring branches get close or overlap, as well as improving robustness to common challenges such as varying point density, noise and missing data.

We make the following contributions:
\begin{enumerate}
     
    \item We developed a synthetic point cloud generation tool for creating a wide range of labelled tree point clouds.
    \item We demonstrate how a sparse convolutional neural network can effectively predict the position of the medial axis.
    \item We implement a skeletonization algorithm that can use the information from the neural network to perform a robust skeletonization.
    \item We evaluate our method against the state-of-the-art automatic skeletonization method.
    \item We demonstrate the method's ability to generalize by applying it to real data.
\end{enumerate}


% \subsection{Point Cloud Deep Learning}
% Deep learning on point clouds has a wide range of applications such as autonomous vehicle navigation, depth estimation, scene classification and object segmentation. However deep learning on  point clouds is particularly challenging due to the unstructured nature, density variance and sparsity. Nevertheless, point cloud research has seen the implementation of various successful network architectures. Existing methods can be divided into point-based, projection-based, voxel-based and hybrid methods \cite{su2022multi}. 
% PointNet was the pioneering point-based architecture \cite{qi2017pointnet}. PointNet utilizes a symmetry function to make the input permutation invariant, and T-Nets to make the input and feature space transformation invariant. PointNet++ was built upon PointNet and hierarchically applies PointNet to adaptively combine features from multiple scales  \cite{qi2017pointnet++}. Many recent works \cite{zhao2019pointweb,zhang2019shellnet,lin2020adaptive} have been inspired by PointNet++, however, they often fail to scale to large point clouds due to high computational and memory costs. Projection-based methods \cite{tatarchenko2018tangent,lawin2017deep,milioto2019rangenet++} work by mapping 3D data back into 2D images. Thereby allowing well-studied 2D convolutions to occur.  However, projection-based methods are sensitive to occlusion \cite{su2022multi}.  Dense-voxel \cite{tchapmi2017segcloud,rethage2018fully} based methods, begin by first voxelizing the point cloud and then applying 3D convolutions. The voxelization stage leads to quantization and loss of information. Therefore it is important to choose a grid size with the appropriate trade-off between network performance and resource requirements. Sparse convolutions \cite{liu2015sparse,tang2022torchsparse,choy20194d,jiang2020pointgroup} accelerate computation speeds and reduce memory requirements by removing unnecessary computation on empty voxels.  Hybrid methods \cite{liu2019point} work by using a combination of approaches, for example, PVCNN extracts low-resolution features from voxels and higher-level features from points. This helps to reduce memory consumption whilst still maintaining a strong ability to identify small features. 
%\cite{seidel20113d,fan2020adqsm}