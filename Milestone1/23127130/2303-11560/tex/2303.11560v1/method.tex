
\section{Method} \label{method_section}

\subsection{Dataset}
We use synthetic data for two reasons. First, it has a known ground truth skeleton for quantitative evaluation. Second, we can efficiently label the point clouds - allowing us to generate data for a broad range of species. 
We create Synthetic trees using a tree modelling software called SpeedTree \cite{speedtree}. For evaluation, we generate the tree meshes without foliage, which otherwise increase the level of occlusion. In the general case, we remove foliage using a segmentation step. Generating point clouds from the tree meshes is done by emulating a spiral drone flight path around each tree and capturing RGBD images at a resolution of 2.1 megapixels (1920 x 1080 pixels). 

We randomly select a sky-box for each tree for varying lighting conditions. The depth maps undergo augmentations such as jitter, dilation and erosion to replicate photogrammetry noise. We extract a point cloud from the fused RGBD images. We remove duplicate points by performing a voxel downsample at a 1cm resolution. The final point clouds have artefacts such as varying point density, missing areas (some due to self-occlusion) and noise.  

We select six species with SpeedTree models. We produce 100 point clouds (600 total) for each of the six tree species, which vary in intricacy and size. Of these, 480 are used for training, while 60 are reserved for validation and 60 for testing. We show images of the synthetic point cloud dataset in the results section (Section \ref{results_section}). Future revisions will include point clouds with foliage and a wider variety of species.


\subsection{Skeletonization Overview}
Our skeletonization method comprises several stages shown in Figure \ref{fig:pipeline}. We use labelled point clouds to train a sparse convolutional neural network to predict each input pointâ€™s radius and direction toward the medial axis (ground truth skeleton). Using these predictions, we then translate surface points to estimated medial axis positions and construct a constrained neighbourhood graph. We extract the skeleton using a greedy algorithm to find paths from the root to terminal points. The neural network predictions help to avoid ambiguities with unknown branch radii and separate points which would be close in proximity but from different branches. 


% \begin{figure}
% \centering
% \begin{tabular}{cccccc}
%   \includegraphics[height=22mm, trim={10cm 0 10cm 0},clip]{images/species-point-clouds/cherry.png} &  
%   \includegraphics[height=22mm, trim={10cm 0 10cm 0},clip]{images/species-point-clouds/walnut.png} &
%   \includegraphics[height=22mm, trim={10cm 0 10cm 0},clip]{images/species-point-clouds/pine.png} \\
%   \includegraphics[height=22mm, trim={10cm 0 10cm 0},clip]{images/species-point-clouds/eucalyptus.png} &
%   \includegraphics[height=22mm, trim={10cm 0 10cm 0},clip]{images/species-point-clouds/apple.png} &
%   \includegraphics[height=22mm, trim={10cm 0 10cm 0},clip]{images/species-point-clouds/ginkgo.png} \\
% \end{tabular}
% \caption{Synthetic Point Clouds (clockwise): Cherry (a), Walnut (b), Pine (c), Eucalyptus (d), Apple (e), Ginkgo (f).}
% \label{fig:synthetic-pcds}
% \vspace*{-0.5cm}
% \end{figure}


%A summary of the dataset is shown in Table \ref{dataset-statstics}
% \begin{table}[h]
% \centering
% \caption{Dataset Statistics}
% \label{dataset-statstics}
% %\vspace{0.5cm}
% \begin{tabular*}{\textwidth}{    
%     P{0.25\textwidth}  |               
%     P{0.25\textwidth}  |        
%     P{0.25\textwidth}  |             
%     P{0.25\textwidth}                
% }
% Species & Height & Number of Points & Complexity \\
% \hline
% Cherry & 0.95 & 0.86 & 0.90 \\
% Eucalyptus & 0.98 & 0.99  & 0.98 \\
% Apple & 0.98 & 0.99  & 0.98 \\
% Walnut & 0.98 & 0.99  & 0.98 \\
% Pine & 0.98 & 0.99  & 0.98 \\
% Ginkgo & 0.98 & 0.99  & 0.98 \\
% \end{tabular*}
% \end{table}

\subsection{Neural Network}
Our network takes an input set of $n$ arbitrary points $\left\{Pi | i = 1, ..., n \right\}$, where each point $Pi$ is a vector of its $(x, y, z)$ coordinates plus additional features such as colour $(r, g,b)$. Our proposed network will then, for each input point, learn an associated radius $\left\{Ri | i = 1, ..., n \right\}$ where $Ri$ is a vector of corresponding radii and a direction vector $\left\{Di | i = 1, ..., n \right\}$ where $Di$ is a normalized direction vector pointing towards the medial axis. 

The network is implemented as a submanifold sparse CNNs using SpConv \cite{spconv2022} and PyTorch\cite{paszke2019pytorch}. The architecture comprises a UNet backbone \cite{ronneberger2015u} with residual connections, followed by two smaller fully connected networks to extract the radii and directions. A ReLU activation function and batch normalization follow each submanifold convolutional layer. We can add a fully-connected network head when branch-foliage segmentation is required.  


A high-level overview of the network architecture is shown in Figure~\ref{fig:model}. 
\begin{figure*}[hbtp]
\centering
\includegraphics[width=\textwidth]{model}
\caption{High-level Smart-Tree medial-axis network architecture diagram.}
\label{fig:model}
\end{figure*}

A block sampling scheme ensures the network can process larger trees. During training, for each point cloud, we randomly sample a $4m^{3}$ block and mask the outer regions of the block to avoid inaccurate predictions from the edges. We tile the blocks during inference, overlapping the masked regions.

We estimate a log radius due to the branch radii varying over several orders of magnitude \cite{dassot2019assessing}.
The loss function (Equation \ref{Loss_Function}) comprises two components. Firstly we use the L1-loss for the radius (Equation \ref{Radius_Loss}) and the cosine similarity (Equation \ref{Direction_Loss}) for the direction loss.
We use the Adam optimizer, a batch size of $16$, and a learning rate of $0.1$. The learning rate decays by a factor of $10$ if the validation data-set loss does not improve for $10$ consecutive epochs. 

\begin{tabular}{p{6cm}p{5cm}}
\begin{equation} \label{Direction_Loss}
L_{D} = \sum_{i = 0}^n \frac{Di \cdot \tilde{Di}}{max(||Di||_2\cdot ||\tilde{Di}||_2)} 
\end{equation}
  &
\begin{equation} \label{Radius_Loss}
L_{R} = {\sum_{i = 0}^n |Ri - \ln(\tilde{Ri})|}
\end{equation} 
\end{tabular}

\begin{equation} \label{Loss_Function}
Loss = L_{R} + L_{D}
\end{equation} 

\subsection{Skeletonization Algorithm}
\vspace{-0.75cm}

\begin{figure}[H]
\centering
\subfloat[]{
  \includegraphics[width=0.23\textwidth, trim={5cm 1cm 2cm 5cm},clip]{images/skeleton-steps/skeleton_steps-01.png}
  \label{fig:pipeline_a}
}
\subfloat[]{
  \includegraphics[width=0.23\textwidth, trim={5cm 1cm 2cm 5cm},clip]{images/skeleton-steps/skeleton_steps-02.png}
  \label{fig:pipeline_b}
}
\subfloat[]{
  \includegraphics[width=0.23\textwidth, trim={5cm 1cm 2cm 5cm},clip]{images/skeleton-steps/skeleton_steps-03.png}
  \label{fig:pipeline_c}
}
\subfloat[]{
  \includegraphics[width=0.23\textwidth, trim={5cm 1cm 2cm 5cm},clip]{images/skeleton-steps/skeleton_steps-04.png}
  \label{fig:pipeline_d}
}
\hspace{0mm}
\\[-3ex]

\subfloat[]{
  \includegraphics[width=0.23\textwidth, trim={5cm 1cm 2cm 5cm},clip]{images/skeleton-steps/skeleton_steps-05.png}
  \label{fig:pipeline_e}
}
\subfloat[]{
  \includegraphics[width=0.23\textwidth, trim={5cm 1cm 2cm 5cm},clip]{images/skeleton-steps/skeleton_steps-06.png}
  \label{fig:pipeline_f}
}
\subfloat[]{
  \includegraphics[width=0.23\textwidth, trim={5cm 1cm 2cm 5cm},clip]{images/skeleton-steps/skeleton_steps-07.png}
  \label{fig:pipeline_g}
}
\subfloat[]{
  \includegraphics[width=0.23\textwidth, trim={5cm 1cm 2cm 5cm},clip]{images/skeleton-steps/skeleton_steps-08.png}
  \label{fig:pipeline_h}
}
\hspace{0mm}
\\[-3ex]
\subfloat[]{
  \includegraphics[width=0.23\textwidth, trim={5cm 1cm 2cm 5cm},clip]{images/skeleton-steps/skeleton_steps-09.png}
  \label{fig:pipeline_i}
}
\subfloat[]{
  \includegraphics[width=0.23\textwidth, trim={5cm 1cm 2cm 5cm},clip]{images/skeleton-steps/skeleton_steps-10.png}
  \label{fig:pipeline_j}
}
\subfloat[]{
  \includegraphics[width=0.23\textwidth, trim={5cm 1cm 0cm 5cm},clip]{images/skeleton-steps/skeleton_steps-11.png}
  \label{fig:pipeline_l}

}
\subfloat[]{
  \includegraphics[width=0.23\textwidth, trim={5cm 1cm 0cm 5cm},clip]{images/skeleton-steps/skeleton_steps-12.png}
  \label{fig:pipeline_m}
}
\caption{Skeletonization Algorithm: (a) Input points, (b) Medial axis approximation, (c) Neighbourhood radius search, (d) Neighbourhood graph, (e) $B_0$ Farthest point, (f) $B_0$ Trace path,(g) $B_0$ Allocated points, (h) $B_1$ Farthest (unallocated) point, (i) $B_1$ Trace path and allocated points, (k)  Branch skeletons, (i) Corresponding surface points.}
\label{fig:pipeline}

\end{figure}



% \begin{figure}[H]
% \centering
% \begin{tabular}{cccc}
%   \includegraphics[width=0.21\textwidth, trim={5cm 1cm 2cm 5cm},clip]{images/skeleton-steps/skeleton_steps-01.png} &   
%   \includegraphics[width=0.21\textwidth, trim={5cm 1cm 2cm 5cm},clip]{images/skeleton-steps/skeleton_steps-02.png} &
%   \includegraphics[width=0.21\textwidth, trim={5cm 1cm 2cm 5cm},clip]{images/skeleton-steps/skeleton_steps-03.png} &
%   \includegraphics[width=0.21\textwidth, trim={5cm 1cm 2cm 5cm},clip]{images/skeleton-steps/skeleton_steps-04.png} \\  
%   (a) & (b) & (c) & (d) \\[5pt]
%   \includegraphics[width=0.21\textwidth, trim={5cm 1cm 2cm 5cm},clip]{images/skeleton-steps/skeleton_steps-05.png} &
%   \includegraphics[width=0.21\textwidth, trim={5cm 1cm 2cm 5cm},clip]{images/skeleton-steps/skeleton_steps-06.png} &
%   \includegraphics[width=0.21\textwidth, trim={5cm 1cm 2cm 5cm},clip]{images/skeleton-steps/skeleton_steps-07.png} & 
%   \includegraphics[width=0.21\textwidth, trim={5cm 1cm 2cm 5cm},clip]{images/skeleton-steps/skeleton_steps-08.png} \\ 
%   (e) & (f) & (g) & (h) \\[5pt]
%   \includegraphics[width=0.21\textwidth, trim={5cm 1cm 2cm 5cm},clip]{images/skeleton-steps/skeleton_steps-09.png} &
%   \includegraphics[width=0.21\textwidth, trim={5cm 1cm 2cm 5cm},clip]{images/skeleton-steps/skeleton_steps-10.png} &  
%   \includegraphics[width=0.21\textwidth, trim={5cm 1cm 0cm 5cm},clip]{images/skeleton-steps/skeleton_steps-11.png} & 
%   \includegraphics[width=0.21\textwidth, trim={5cm 1cm 0cm 5cm},clip]{images/skeleton-steps/skeleton_steps-12.png} \\
%   (i) & (j) & (k) & (l) \\[5pt]
% \end{tabular}
% \caption{Input point cloud (a), Network approximated medial axis (b), Neighbourhood search radii (c), Neighbourhood graph (d), Start and end points of $B_0$'s path (e), Shortest path for $B_0$ (f), Points lying within radii of path $B_0$ (g), Start and end points for $B_1$'s path (h), $B_1$'s path and allocated points (i), Final branch skeletons (k), Corresponding surface points (i).}
% \label{fig:pipeline}
% \end{figure}
% \vspace{-1cm}

Once $\left\{Ri\right\}$ and $\left\{Di\right\}$, have been predicted by the network. We use this information to project the input surface points $\left\{Pi\right\}$ (\ref{fig:pipeline_a}) onto the medial axis  (\ref{fig:pipeline_b}).

We form a neighbourhood graph  (\ref{fig:pipeline_d}) where points are connected to neighbours with weight equal to the distance between points and restricted to edges with a distance less than the predicted radius (\ref{fig:pipeline_c}). 

As the point cloud has gaps due to self-occlusion and noise, we end up with multiple connected components. Each connected component we call a sub-graph. We process each sub-graph sequentially. For each sub-graph:

\begin{enumerate}
    \item A distance tree is created based on the distance from the root node (the lowest point in each sub-graph - shown in red in (\ref{fig:pipeline_e})) to each point in the sub-graph.
    \item We assign each point a distance based on a Single Source Shortest Path  (SSSP) algorithm. A greedy algorithm extracts paths one by one until all points are marked as allocated (steps $e$ to $j$).
    \item  We select a path to the furthest unallocated point and trace its path back to either the root (\ref{fig:pipeline_e}) or an allocated point (\ref{fig:pipeline_i}). 
    \item We add this path to a skeleton tree (\ref{fig:pipeline_f}).
    \item We mark points as allocated which lie within the predicted radius of the path (\ref{fig:pipeline_g}).
    \item We repeat this process until all points are allocated (\ref{fig:pipeline_i}, \ref{fig:pipeline_j})
\end{enumerate}


% Next, we form a neighbourhood graph but constrain the neighbourhood graph to only create valid edges with an edge length less than the predicted radius (Figure \ref{fig:pipeline}c). As the point cloud has gaps due to self-occlusion and noise, we end up with multiple connected components. Each connected component we refer to as a sub-graph. We process each sub-graph sequentially. A distance graph is then created based on the distance from the root node (the lowest point in each sub-graph) to each point in the sub-graph. We then trace the shortest path from the farthest point towards the sub-graph's root node whilst allocating all medial points within the predicted radius at each point in the path to be part of the same "branch" (Fig~\ref{fig: pipeline}d).  We iteratively repeat this process by taking the distance of the farthest unallocated point and tracing its path back to the root node or until it converges with points already allocated to a "branch" (Fig~\ref{fig:skeleton-algorithm}e,f). % Figure \ref{fig:skeleton-pipeline} shows the branch allocation of each medial point. Figure \ref{fig:skeleton-pipeline}e shows the corresponding surface points. 
% The final skeleton is generated by connecting each branch path (Figure \ref{fig:pipeline}g).
% %The pseudo code for the algorithm is given in algorithm \ref{alg:MYALG}.

% \begin{figure}
% \centering
% \begin{tabular}{ccc}
%   \includegraphics[width=27.5mm]{images/input-pcd.png} &   \includegraphics[width=27.5mm]{images/medial-points.png} & \includegraphics[width=27.5mm]{images/nn-graph.png} \\
% % (a) & (b) & (c) \\[5pt]
% \includegraphics[width=27.5mm]{images/medial-pcds.png} &  \includegraphics[width=27.5mm]{images/surface-points.png} &   \includegraphics[width=27.5mm]{images/skeleton.png} \\
% % (d) & (e) & (f) \\[5pt]
% \end{tabular}
% \caption{Clockwise Order: Input point cloud (a), Network approximated medial axis (b), Variable-radius NN-graph (c), Allocated branch medial points (d), Allocated branch surface points (e), Skeleton output (f).}
% \label{fig:skeleton-pipeline}
% \vspace{-1cm}

% \end{figure}

% \begin{figure}
% \centering
% \begin{tabular}{ccc}
%   \includegraphics[width=32mm, trim={0 0 0 150px},clip]{images/skeleton-toy/1.png} &   
%   \includegraphics[width=32mm, trim={0 0 0 150px},clip]{images/skeleton-toy/3.png} &  \includegraphics[width=32mm, trim={0 0 0 150px},clip]{images/skeleton-toy/4.png}  \\
% \end{tabular}
% \caption{2D Skeletonization Algorithm Visualisation: Surface Points being translated using neural network estimate (a), Furthest unallocated point (blue) tracing path back to root point (red) (b), Furthest unallocated point (blue) tracing path back to root point (red), but stopping once converged with an allocated point (c).}
% \label{fig:skeleton-algorithm}
% \vspace{-1cm}
% \end{figure}


% \begin{figure}
% \centering
% \includegraphics[width=\linewidth]{images/overview/Skeleton Pipeline.png} 
% \caption{Pipeline overview. (a) The input point cloud, (b) estimated medial axes, (c) the neighbourhood graph (d) illustrates the first path added, (e) the complete skeleton tree and (g) the extracted surface points.}
% \label{fig:pipeline}
% \end{figure}