\pdfoutput=1
\documentclass[10pt]{article}








\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{2212}{-}
\setlength{\textwidth}{6.0in}
\setlength{\evensidemargin}{0.25in}
\setlength{\oddsidemargin}{0.25in}
\setlength{\topmargin}{-0.5in}
\setlength{\textheight}{8.5in}
\setlength{\headheight}{0.25in}
\setlength{\headsep}{0.5in}
\setlength{\footskip}{0.5in}
\setcounter{bottomnumber}{4}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{pifont}
\usepackage{pdfpages}

\usepackage[backend=biber,
style=numeric,
sortcites,
natbib=true,
sorting=none]{biblatex}
\addbibresource{main.bib}

\usepackage[]{titlesec}
\titleformat{\chapter}[display]
  {\normalfont\bfseries}{}{0pt}{\LARGE}
  \titlespacing*{\chapter}{0pt}{-50pt}{10pt}

\usepackage[T1]{fontenc}    %
\usepackage{enumitem}

\usepackage{booktabs}       %
\usepackage{amsfonts}       %
\usepackage{nicefrac}       %
\usepackage{microtype}      %
\usepackage{xcolor}         %
\usepackage{listings}
\usepackage{dashrule}
\usepackage{wrapfig}

\lstset{%
  language=[LaTeX]TeX,
  breaklines=true,
  columns=fullflexible,
  literate={-}{-}1,
}

\newcommand{\bo}[1]{\textcolor{blue}{Bo: #1}}

\input{math_commands.tex}

\usepackage{amsfonts}

\usepackage[breaklinks=true,colorlinks,citecolor=black,bookmarks=false]{hyperref}
\hypersetup{
    colorlinks=false,
	linkcolor=blue,
	filecolor=magenta,      
	urlcolor=blue,
	citecolor=black,
	pdfinfo={
		Title={Natural Selection Favors AIs over Humans},
		Author={Dan Hendrycks},
		Subject={ML Safety, AI Safety, AI X-Risk},
		Keywords={x-risk, existential risk, catastrophic risk, selfish ai, ai safety, ai evolution}
	}
}

\usepackage{times}
\usepackage{url}
\usepackage{lipsum}
\usepackage{bbm}
\usepackage{wrapfig}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{todonotes}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{microtype}      %
\usepackage{cleveref}
\usepackage{titling} %
\usepackage[most]{tcolorbox}
\usepackage{tabularray}
\UseTblrLibrary{booktabs}

\usepackage{spverbatim}

\newcommand\Tstrut{\rule{0pt}{2ex}}         %
\newcommand\Bstrut{\rule[-0.9ex]{0pt}{0pt}}   %






\title{
\vspace{-25pt}
\hrule height 4pt
\vskip 0.25in
{\LARGE\bf Natural Selection Favors AIs over Humans}
\vskip 0.29in
\hrule height 1pt
\vskip 0.09in
}
\date{}

\renewenvironment{abstract}%
{%
  \vskip 0.075in%
  \centerline%
  {\large\bf Abstract}%
  \vspace{0.5ex}%
  \begin{quote}%
}
{
  \par%
  \end{quote}%
  \vskip 1ex%
}

\author{\textbf{Dan Hendrycks}\\
Center for AI Safety
}

\usepackage{arydshln}

\newcommand{\reviewer}[3]{
	\expandafter\newcommand\csname #1\endcsname[1]{
		\textcolor{#3}{[#2: ##1]}
	}
}
\definecolor{neonpurple}{rgb}{0.3,0,1}
\reviewer{dan}{Dan}{neonpurple}

\AtBeginBibliography{\small}


\begin{document}
\includepdf[pages={1}]{figures/cover.pdf}
\begin{titlepage}
\end{titlepage}



\maketitle

\begin{abstract}

\normalsize




\noindent %
For billions of years, evolution has been the driving force behind the development of life, including humans. Evolution endowed humans with high intelligence, which allowed us to become one of the most successful species on the planet. Today, humans aim to create artificial intelligence systems that surpass even our own intelligence. As artificial intelligences (AIs) evolve and eventually surpass us in all domains, how might evolution shape our relations with AIs? By analyzing the environment that is shaping the evolution of AIs, we argue that the most successful AI agents will likely have undesirable traits. Competitive pressures among corporations and militaries will give rise to AI agents that automate human roles, deceive others, and gain power. If such agents have intelligence that exceeds that of humans, this could lead to humanity losing control of its future. More abstractly, we argue that natural selection operates on systems that compete and vary, and that selfish species typically have an advantage over species that are altruistic to other species. This Darwinian logic could also apply to artificial agents, as agents may eventually be better able to persist into the future if they behave selfishly and pursue their own interests with little regard for humans, which could pose catastrophic risks. To counteract these risks and evolutionary forces, we consider interventions such as carefully designing AI agentsâ€™ intrinsic motivations, introducing constraints on their actions, and institutions that encourage cooperation. These steps, or others that resolve the problems we pose, will be necessary in order to ensure the development of artificial intelligence is a positive one.\looseness=-1\footnote{This paper is for a wide audience, unlike most of my writing, which is for empirical AI researchers. I use a high-level and simplified style to discuss the risks that advanced AI could pose, because I think this is an important topic for everyone.}








\end{abstract}

\newpage
\tableofcontents

\input{sections/1-introduction}
\input{sections/2-argument}
\input{sections/3-altruism-mechanisms}
\input{sections/4-counteracting}
\input{sections/5-conclusion}

\printbibliography

\newpage
\appendix
\addtocontents{toc}{\protect\setcounter{tocdepth}{1}}
\input{sections/9-appendix}

\end{document}