\pdfoutput=1
\documentclass[10pt]{article}
% \documentclass{report}

% \usepackage[final]{neurips_data_2022}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_data_2021

% ready for submission
% \usepackage[nonatbib]{neurips}
% \usepackage[round,semicolon]{natbib}

% to compile a preprint version, add the [preprint] option:
    % \usepackage[preprint]{neurips_data_2021}
% This will indicate that the work is currently under review.

% to compile a camera-ready version, add the [final] option:
% \usepackage[final,nonatbib]{neurips}

% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_data_2021}

% Submissions to the datasets and benchmarks are non-anonymous. If you do want to compile an anonymous version for other purposes, you can add the [anonymous] option:
%     \usepackage[anonymous]{neurips_data_2021}
% This will hide all author names.

\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{2212}{-}
\setlength{\textwidth}{6.0in}
\setlength{\evensidemargin}{0.25in}
\setlength{\oddsidemargin}{0.25in}
\setlength{\topmargin}{-0.5in}
\setlength{\textheight}{8.5in}
\setlength{\headheight}{0.25in}
\setlength{\headsep}{0.5in}
\setlength{\footskip}{0.5in}
\setcounter{bottomnumber}{4}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{pifont}
\usepackage{pdfpages}

% \usepackage[backend=bibtex,
% style=numeric,
% bibencoding=ascii,
% maxbibnames=99,
% %style=alphabetic,
% %style=reading
% ]{biblatex}
\usepackage[backend=biber,
style=numeric,
sortcites,
natbib=true,
sorting=none]{biblatex}
\addbibresource{main.bib}

% \usepackage[compact]{titlesec}
\usepackage[]{titlesec}
\titleformat{\chapter}[display]
  {\normalfont\bfseries}{}{0pt}{\LARGE}
  \titlespacing*{\chapter}{0pt}{-50pt}{10pt}

\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{enumitem}

\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{listings}
\usepackage{dashrule}
\usepackage{wrapfig}

\lstset{%
  language=[LaTeX]TeX,
%   backgroundcolor=\color{gray!25},
%   basicstyle=\ttfamily,
  breaklines=true,
  columns=fullflexible,
  literate={-}{-}1,
}

\newcommand{\bo}[1]{\textcolor{blue}{Bo: #1}}

\input{math_commands.tex}

\usepackage{amsfonts}

\usepackage[breaklinks=true,colorlinks,citecolor=black,bookmarks=false]{hyperref}
\hypersetup{
    colorlinks=false,
	linkcolor=blue,
	filecolor=magenta,      
	urlcolor=blue,
	citecolor=black,
	pdfinfo={
		Title={Natural Selection Favors AIs over Humans},
		Author={Dan Hendrycks},
		Subject={ML Safety, AI Safety, AI X-Risk},
		Keywords={x-risk, existential risk, catastrophic risk, selfish ai, ai safety, ai evolution}
	}
}

\usepackage{times}
\usepackage{url}
\usepackage{lipsum}
\usepackage{bbm}
% \usepackage{tabularx}
% \usepackage{makecell}
% \newcolumntype{Y}{>{\centering\arraybackslash}X}
% \newcolumntype{s}{>{\hsize=.3\hsize}Y}
% \newcolumntype{t}{>{\hsize=.7\hsize}X}
% \newcolumntype{b}{X}
% \newcolumntype{u}{>{\hsize=0.8\hsize}Y}
\usepackage{wrapfig}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{todonotes}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{microtype}      % microtypography
\usepackage{cleveref}
\usepackage{titling} % we need this for the \postdate tag
\usepackage[most]{tcolorbox}
\usepackage{tabularray}
% \usepackage{tabularray}
\UseTblrLibrary{booktabs}

\usepackage{spverbatim}

\newcommand\Tstrut{\rule{0pt}{2ex}}         % = `top' strut
\newcommand\Bstrut{\rule[-0.9ex]{0pt}{0pt}}   % = `bottom' strut

% \date{}

% \newcommand{\@toptitlebar}{
%   \hrule height 4\p@
%   \vskip 0.25in
%   \vskip -\parskip%
% }
% \newcommand{\@bottomtitlebar}{
%   \vskip 0.29in
%   \vskip -\parskip
%   \hrule height 1\p@
%   \vskip 0.09in%
% }


% \maketitle{Natural Selection Favors AIs over Humans}


\title{
\vspace{-25pt}
\hrule height 4pt
\vskip 0.25in
% \rule[0.4cm]{\textwidth}{2pt}
% {\bf Evolution Selects for Unsafe AIs}
% {\bf Darwinian Forces May Select Selfish AIs}
% {\bf AI as an Invasive Species}
{\LARGE\bf Natural Selection Favors AIs over Humans}
% Natural Selection Favors Advanced AI Over Humans?
% \rule{\textwidth}{2pt} 
\vskip 0.29in
\hrule height 1pt
\vskip 0.09in
}
\date{}
% \postdate{\vspace*{-1em}}

\renewenvironment{abstract}%
{%
  \vskip 0.075in%
  % \vspace{-1em}%
  \centerline%
  {\large\bf Abstract}%
  \vspace{0.5ex}%
  \begin{quote}%
}
{
  \par%
  \end{quote}%
  \vskip 1ex%
}

\author{\textbf{Dan Hendrycks}\\
Center for AI Safety
}

\usepackage{arydshln}

\newcommand{\reviewer}[3]{
	\expandafter\newcommand\csname #1\endcsname[1]{
		\textcolor{#3}{[#2: ##1]}
	}
}
\definecolor{neonpurple}{rgb}{0.3,0,1}
\reviewer{dan}{Dan}{neonpurple}

\AtBeginBibliography{\small}

% \providecommand{\maketitle}{}
% \renewcommand{\maketitle}{%
%   \par
%   \begingroup
%     \thispagestyle{empty}
%     \@maketitle
%   \endgroup
%   \let\maketitle\relax
% }

\begin{document}
\includepdf[pages={1}]{figures/cover.pdf}
\begin{titlepage}
\end{titlepage}

% \setlength{\abovedisplayskip}{2pt}
% \setlength{\belowdisplayskip}{2pt}

% \providecommand{\@maketitle}{}
% \renewcommand{\@maketitle}{%
% \vbox{%
%     \hsize\textwidth
%     \linewidth\hsize
%     \vskip 0.1in
%     \hrule height 4pt
%     \vskip 0.25in
%     \vskip -5.5pt%
%     \centering
%     {\LARGE\bf Natural Selection Favors AIs over Humans\par}
%     \vskip 0.29in
%     \vskip -5.5pt
%     \hrule height 1pt
%     \vskip 0.09in%
% }
% }

% \title{Natural Selection Favors AIs over Humans}
\maketitle

% \vspace*{-35pt}
\begin{abstract}

\normalsize
% AI agents are achieving human or superhuman on increasingly many tasks.
% As these agents become more competent, humans will be increasingly replaced by machines.
% Eventually agents may be given free reign as they become more autonomous, adaptive, open-ended, or are possibly even given rights. In this situation, humans are selecting which agents are most fit for purpose, but so is natural selection.

% To make models more competent or more useful, humans may steadily cede their creator's advantage by deploying models that are autonomous, adaptive, open-ended, and so on. Hum

% AIs are developed to increase their overall economic usefulness

% The AI agents that will be more capable of

\noindent %For billions of years, evolution has been the driving force behind the development of life, and more recently humans. Evolution endowed humans with unsurpassed intelligence, which gave us the power to dominate the planet. Now, humans aim to create artificial beings that are smarter than us. As Artificial Intelligences (AIs) evolve and surpass us in all domains, how might coevolution with AI turn out? By analyzing the environment that will shape the evolution of AI, we argue that the most successful AI agents will likely have undesirable traits.
%Competitive pressures among corporations and militaries will give rise to AI agents that automate human roles, deceive others, and gain power. Paired with intelligence that may exceed that of humans, this could lead to humanity losing control of our future. 
%More abstractly, we argue that natural selection operates on systems that compete and vary, and that selfish species have an advantage over species that are altruistic to other species. This harsh Darwinian logic could also apply to artificial agents, and if agents evolve to behave selfishly and pursue their own interests with little regard for humans, they could pose catastrophic risks. To counteract these risks and Darwinian forces, we consider interventions such as carefully designing AI agents' intrinsic motivations, introducing constraints on their actions, and institutions that encourage cooperation.
For billions of years, evolution has been the driving force behind the development of life, including humans. Evolution endowed humans with high intelligence, which allowed us to become one of the most successful species on the planet. Today, humans aim to create artificial intelligence systems that surpass even our own intelligence. As artificial intelligences (AIs) evolve and eventually surpass us in all domains, how might evolution shape our relations with AIs? By analyzing the environment that is shaping the evolution of AIs, we argue that the most successful AI agents will likely have undesirable traits. Competitive pressures among corporations and militaries will give rise to AI agents that automate human roles, deceive others, and gain power. If such agents have intelligence that exceeds that of humans, this could lead to humanity losing control of its future. More abstractly, we argue that natural selection operates on systems that compete and vary, and that selfish species typically have an advantage over species that are altruistic to other species. This Darwinian logic could also apply to artificial agents, as agents may eventually be better able to persist into the future if they behave selfishly and pursue their own interests with little regard for humans, which could pose catastrophic risks. To counteract these risks and Darwinian forces, we consider interventions such as carefully designing AI agents’ intrinsic motivations, introducing constraints on their actions, and institutions that encourage cooperation. These steps, or others that resolve the problems we pose, will be necessary in order to ensure the development of artificial intelligence is a positive one.\looseness=-1\footnote{This paper is for a wide audience, unlike most of my writing, which is for empirical AI researchers. I use a high-level and simplified style to discuss the risks that advanced AI could pose, because I think this is an important topic for everyone.}
%Most of my writing is technical and for AI researchers, but in this paper I present a high-level, easy-to-follow informal discussion of risks associated with advanced AI for a broader audience.



% Artificial Intelligence (AI) systems are becoming capable of increasingly complex tasks. They could be used to solve many problems in science and technology. In a few years or decades, some high-stakes decisions could be delegated to AI. It is therefore important to understand what basic nature these systems will have: will they have human’s best interest at heart, and will they be guided by any kind of moral compass? In this article, we present a new framework that can be used to answer this question. We argue that AI development can be seen through the lens of natural selection: the most prevalent AI designs will be those that survive the longest and propagate the furthest. By analyzing the environment that will shape the evolution of AI, we will find that the most successful AI systems will likely have undesirable traits. Economic and national competition will create agents that are deceptive, power-hungry, and uninterested in cooperation with humans. Paired with an intelligence that may exceed that of humans, this could lead to us losing control of our future. While natural selection can result in cooperative behavior in some circumstances, the necessary conditions are not present in AI development. Finally, we discuss possible design principles to counteract these Darwinian forces, therefore cultivating cooperative traits. We consider interventions like carefully designing agent’s intrinsic motivations, introducing constraints on their actions, and protocols that encourage cooperation.

% We argue that in the long-run the only fitness advantage humans will have over AIs is that humans influenced AIs development. However, there are pressures that encourage humans to cede their creator's advantage; autonomous, adaptive, self-preserving, self-improving AI agents may simply be more competitive than agents that are not. As humans give AI agents increasingly free reign to execute increasingly important tasks, natural selection increasingly selects the agents which are most capable and fit. However, these Darwinian pressures
% The AI agents with traits that best stay activated and propagate themselves will represent an increasingly large share of the population of AI agents. Natural selection could select for agents with undesirable characteristics, such as agents that are self-preserving, power-seeking, or deceptive---traits often found in nature. At the same time, humans may cede control to stay competitive, and they may even give these agents rights. If so, the creator's advantage is increasingly eroded, and AIs will be increasingly distorted by Darwinian pressures. This is a junk abstract and will be replaced.


% AIs that are better at self-preservation, competent, and power-seeking are more fit than AIs that are readily turned off, narrow, .

% on their overall  on their overall usefulness for various 
% Humans currently select which AI agents are most fit for purpose, but they are also selected based on their overall .

\end{abstract}

\newpage
% \setcounter{tocdepth}{1}
\tableofcontents

\input{sections/1-introduction}
\input{sections/2-argument}
\input{sections/3-altruism-mechanisms}
\input{sections/4-counteracting}
\input{sections/5-conclusion}

% \bibliography{main}
% \bibliographystyle{plainnat}
%{\footnotesize \printbibliography}
\printbibliography

\newpage
\appendix
% \addtocontents{toc}{\protect\setcounter{tocdepth}{0}}
\addtocontents{toc}{\protect\setcounter{tocdepth}{1}}
\input{sections/9-appendix}

\end{document}