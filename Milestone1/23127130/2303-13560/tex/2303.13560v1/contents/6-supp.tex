\section{Appendix}

% \subsection{LiDAR-based detector}

% \weidi{Here, we start by .... then .....}
Here, we start with dataset details, including generation and qualitative samples, then give out more implementation details.

\subsection{Datasets}
\subsubsection{OPV2V+}
\noindent
\textbf{Data generation.} We extend the original OPV2V~\cite{xu2022opv2v} with more collaborative agents ($10$). Our OPV2V+ is co-simulated by OpenCDA~\cite{xu2021opencda} and CARLA~\cite{dosovitskiy2017carla}. Figure.~\ref{fig:opv2v_env} shows the simulation environment. OpenCDA provides the driving scenarios which ensure the agents drive smoothly and safely, including the vehicle's initial location and moving speed. CARLA provides the maps, and weather and controls the movements of the agents. We replay the simulation logs of OPV2V and equip more vehicles with camera and depth sensors. Figure.~\ref{Fig:opv2v_single_sample} shows the four views (front, left, right, back) of the same agent. Figure.~\ref{Fig:opv2v_sample} shows a randomly selected data sample with 10 collaborative agents, the collected front view images in the same timestamp.

\noindent
\textbf{Agent distribution. } We provide more statistical analysis of the distance distribution between agents to objects. 1) The distance between objects and their closest agents decreases as the number of agents increases, see Fig.~\ref{fig:dis_distribution}. Given 10 agents, this distance is mostly within 20m, see Fig.~\ref{fig:dis_hist}. 2) Distribution of agents is uniform w.r.t objects, instead of the field of view (0-280m). Fig.\ref{fig:agent_hist} shows that the distribution of agents is same with all objects.


\begin{figure}[!h]
\centering
\noindent
% \hspace{1mm}
\centering
    \begin{subfigure}{0.7\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Supp/Ablation_AgentDist.png}
    % \vspace{-6mm}
    \caption{Distance (1-10)}
    \label{fig:dis_distribution}
  \end{subfigure}
  \begin{subfigure}{0.8\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Supp/Observing_distance_10agents.png}
    % \vspace{-6mm}
    \caption{Distance histogram(10 agents)}
    \label{fig:dis_hist}
  \end{subfigure}
    \begin{subfigure}{0.8\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Supp/Object_distance_10agents.png}
    % \vspace{-6mm}
    \caption{Agent distribution(10 agents)}
    \label{fig:agent_hist}
  \end{subfigure}
  % \vspace{-3mm}
  \caption{Object distance distribution.}
\label{fig:agent_dist}
\vspace{-6mm}
\end{figure}

\begin{figure*}[!t]
\vspace{-7mm}
\centering
\noindent
% \hspace{1mm}
\centering
    \begin{subfigure}{0.32\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Supp/UAV_Ablation_Noise_UAV_AP50.png}
    % \vspace{-5mm}
    \caption{CoPerception-UAV+}
    \label{fig:noise_uav}
  \end{subfigure}
    \begin{subfigure}{0.32\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Supp/OPV2V_Ablation_Noise_UAV_AP50.png}
    % \vspace{-5mm}
    \caption{OPV2V+}
    \label{fig:noise_opv2v}
  \end{subfigure}
  \begin{subfigure}{0.32\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Supp/Ablation_AgentNumber_Noise_OPV2V_AP50.png}
    % \vspace{-5mm}
    \caption{OPV2V+}
    \label{fig:noise_opv2v_agentnum}
  \end{subfigure}
  % \vspace{-4mm}
  \caption{CoCa3D is as robust as SOTA where2comm (NeurIPS 22) to pose errors.}
% \vspace{-9mm}
\end{figure*}

\subsubsection{CoPerception-UAVs+}
\noindent
\textbf{Data generation.} We extend the original  CoPerception-UAVs~\cite{hu2022where2comm} with more collaborative agents ($10$). Our CoPerception-UAVs+ is co-simulated by AirSim~\cite{Airsim} and CARLA~\cite{dosovitskiy2017carla}. We use CARLA to generate complex simulation scenes and traffic flow, and AirSim to simulate drones flying in the scene and taking images. And we carefully design the drones' flying route to ensure safety as more agents increase the collision possibility. Figure.~\ref{fig:uav_env} shows the simulation environment. For CoPerception-UAVs+, we simulate more UAVs in AirSim and additionally equip depth sensors for each UAV at the same coordinate with the camera sensor. Figure.~\ref{Fig:uav_sample} shows a randomly selected data sample.



\subsection{Implementation details}
For the camera-only 3D object detection for cars, we implement the detector following the LSS~\cite{philion2020lift} and CaDDN~\cite{CaDDN} for OPV2V+ and DAIR-V2X datasets. We uniformly space the depth into 50 categories. For the training strategy, we first train the single agent detector for 50 epochs with an initial learning rate of $1.5$e-$3$, and decay by 0.1 at epoch 30. Then we load the single pre-trained model and train the whole model with collaboration for another 20 epochs with a learning rate of $1$e-$3$. 

For the camera-only 3D object detection for drones, we implement the detector following the 3D aerial object detection DVDET~\cite{Hu2022AM3D}. We uniformly space the depth into 10 categories. For the training strategy, we train the model for 140 epochs with an initial learning rate of $5$e-$4$, and decay by 0.1 at epoch 80 and 120.

\begin{figure}[!t]
    \centering
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/scene.png}
  \vspace{-2mm}
  \caption{OPV2V+ is co-simulated by OpenCDA~\cite{xu2021opencda} and CARLA~\cite{dosovitskiy2017carla}.}
  \label{fig:opv2v_env}
  \vspace{-2mm}
\end{figure}

\begin{figure}[!t]
\centering
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/Simulation_Environment.png}
  \caption{CoPerception-UAVs+ is co-simulated by CARLA~\cite{dosovitskiy2017carla} and AirSim~\cite{Airsim}.}
    \label{fig:uav_env}
\end{figure}

\begin{figure}[!t]
    \centering
    \begin{subfigure}{0.48\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1045_000068_camera0.png}
    \caption{Camera 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.48\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1045_000068_depth0.png}
    \caption{Depth 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.48\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1045_000068_camera1.png}
    \caption{Camera 1}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.48\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1045_000068_depth1.png}
    \caption{Depth 1}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.48\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1045_000068_camera2.png}
    \caption{Camera 2}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.48\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1045_000068_depth2.png}
    \caption{Depth 2}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.48\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1045_000068_camera3.png}
    \caption{Camera 3}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.48\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1045_000068_depth3.png}
    \caption{Depth 3}
  \end{subfigure}
  \vspace{-2mm}
  \caption{Each agent is equipped with 4 cameras and 4 depth sensors in OPV2V+.}
  \label{Fig:opv2v_single_sample}
  \vspace{-2mm}
\end{figure}

\begin{figure*}[!t]
  \centering
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1075_000068_camera0.png}
    \caption{Agent 0: Camera 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1075_000068_depth0.png}
    \caption{Agent 0: Depth 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1064_000068_camera0.png}
    \caption{Agent 1: Camera 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1064_000068_depth0.png}
    \caption{Agent 1: Depth 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1067_000068_camera0.png}
    \caption{Agent 2: Camera 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1067_000068_depth0.png}
    \caption{Agent 2: Depth 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1069_000068_camera0.png}
    \caption{Agent 3: Camera 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1069_000068_depth0.png}
    \caption{Agent 3: Depth 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1071_000068_camera0.png}
    \caption{Agent 4: Camera 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1071_000068_depth0.png}
    \caption{Agent 4: Depth 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1073_000068_camera0.png}
    \caption{Agent 5: Camera 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1073_000068_depth0.png}
    \caption{Agent 5: Depth 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1076_000068_camera0.png}
    \caption{Agent 6: Camera 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1076_000068_depth0.png}
    \caption{Agent 6: Depth 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1079_000068_camera0.png}
    \caption{Agent 7: Camera 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1079_000068_depth0.png}
    \caption{Agent 7: Depth 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1080_000068_camera0.png}
    \caption{Agent 8: Camera 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1080_000068_depth0.png}
    \caption{Agent 8: Depth 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1082_000068_camera0.png}
    \caption{Agent 9: Camera 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/OPV2V_sample/1082_000068_depth0.png}
    \caption{Agent 9: Depth 0}
  \end{subfigure}
  \vspace{-2mm}
  \caption{Data sample with 10 agents of OPV2V+.}
  \label{Fig:opv2v_sample}
  \vspace{-2mm}
\end{figure*}



\begin{figure*}[!t]
    \centering
    \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/UAV_sample/Front0_1657903246898708992.png}
    \caption{Agent 0: Camera 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/UAV_sample/Front0_1657903246898708992_depth.png}
    \caption{Agent 0: Depth 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/UAV_sample/Front1_1657903246898708992.png}
    \caption{Agent 1: Camera 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/UAV_sample/Front1_1657903246898708992_depth.png}
    \caption{Agent 1: Depth 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/UAV_sample/Front2_1657903246898708992.png}
    \caption{Agent 2: Camera 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/UAV_sample/Front2_1657903246898708992_depth.png}
    \caption{Agent 2: Depth 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/UAV_sample/Front3_1657903246898708992.png}
    \caption{Agent 3: Camera 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/UAV_sample/Front3_1657903246898708992_depth.png}
    \caption{Agent 3: Depth 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/UAV_sample/Front4_1657903246898708992.png}
    \caption{Agent 4: Camera 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/UAV_sample/Front4_1657903246898708992_depth.png}
    \caption{Agent 4: Depth 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/UAV_sample/Front5_1657903246898708992.png}
    \caption{Agent 5: Camera 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/UAV_sample/Front5_1657903246898708992_depth.png}
    \caption{Agent 5: Depth 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/UAV_sample/Front6_1657903246898708992.png}
    \caption{Agent 6: Camera 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/UAV_sample/Front6_1657903246898708992_depth.png}
    \caption{Agent 6: Depth 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/UAV_sample/Front7_1657903246898708992.png}
    \caption{Agent 7: Camera 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/UAV_sample/Front7_1657903246898708992_depth.png}
    \caption{Agent 7: Depth 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/UAV_sample/Front8_1657903246898708992.png}
    \caption{Agent 8: Camera 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/UAV_sample/Front8_1657903246898708992_depth.png}
    \caption{Agent 8: Depth 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/UAV_sample/Front9_1657903246898708992.png}
    \caption{Agent 9: Camera 0}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.24\linewidth}
    \includegraphics[width=0.99\linewidth]{Figs/Dataset/UAV_sample/Front9_1657903246898708992_depth.png}
    \caption{Agent 9: Depth 0}
  \end{subfigure}
  \vspace{-2mm}
  \caption{Data sample with 10 agents of CoPerception-UAVs+.}
  \label{Fig:uav_sample}
  \vspace{-2mm}
\end{figure*}

\subsection{Robustness to pose error}
In the paper, we assume collaborative agents' poses are accurate as practical agents should have strong self-localization ability. 
We further assess the model's robustness to agent pose errors. Encouragingly, {\bf CoCa3D still performs well even pose errors appear}. Following the same pose-error setting in Where2comm~\cite{hu2022where2comm} (Gaussian noise with 0 mean and 0m-0.6m standard deviation), our experiments validate CoCa3D's robustness and find: 1) CoCa3D outperforms Where2comm under various pose errors, see Fig.~\ref{fig:noise_uav} and~\ref{fig:noise_opv2v}.
2) CoCa3D still outperforms LiDAR under large pose error 0.5m/0.2m on Co-UAV+/OPV2V+. 3) CoCa3D's performance steadily increases with agent number even with pose errors, see Fig.~\ref{fig:noise_opv2v_agentnum}. Moreover, CoCa3D can integrate customized alignment methods, such as [1,2], to further tackle pose errors.
% , as the pose error is less than 0.2m in most cases
% \textbf{A1}: We indeed assume collaborative agents' poses are accurate as practical agents should have strong self-localization ability. To validate CoCa3D's robustness when pose errors appear, we conduct additional experiments by following the pose-error setting in Where2comm (Gaussian noise with 0 mean and 0m-0.6m standard deviation), encouragingly, we find that {\bf CoCa3D performs equally well}: i) CoCa3D outperforms previous SOTA under various pose-error levels, see Fig.~\ref{fig:noise_uav} and~\ref{fig:noise_opv2v};


% \clearpage

