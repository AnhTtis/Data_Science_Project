
\section{CXL-Memory-aware Dynamic \\ Page Allocation Policy}
\label{sec:policy}
%We have demonstrated that \cxlmem can also serve as a bandwidth expander to improve the performance of bandwidth-intensive applications (\S\ref{sec:app:throughput}).
We have demonstrated a potential of \cxlmem as a bandwidth expander, which can improve the performance of bandwidth-intensive applications (\S\ref{sec:app:throughput}).
% check
If the throughput of a given application is limited by the bandwidth, allocating a higher percentage of pages to \cxlmem may alleviate bandwidth pressure on DDR memory, and hence reduce average memory access latency.
% check
Intuitively, such a percentage should be tuned for different \cxlmem devices given their distinct bandwidth capabilities (\S\ref{sec:app:throughput}).
% check
By contrast, if a given application is not memory-bandwidth-bounded, allocating a lower percentage of pages to \cxlmem may lead to lower average memory access latency and thus higher throughput.
% check
That stated, to better utilize auxiliary memory bandwidth provided by \cxlmem, we present \policy, a dynamic page allocation policy.
% check
\policy automatically tunes the percentage of new pages to be allocated by the OS to \cxlmem based on three factors: (1) bandwidth capability of \cxlmem, (2) memory intensiveness of co-running applications, and (3) average memory access latency.
% check
Note that \policy, focusing on the page allocation ratio between DDR memory and \cxlmem, is orthogonal and complementary to \texttt{TPP}. 
% check

\begin{figure} % [b]
    \centering
%    \vspace{-9pt}
    \includegraphics[width=0.92\linewidth]{figs/Caption_overview.pdf}
    \vspace{-3pt}
    \caption{Overview of \policy. The components in dotted boxes can be used for better performance.}
    \label{fig:policy-overview}
    \vspace{-6pt}
\end{figure}

\subsection{Policy Design}
\label{sec:policy:design}
\policy consists of three runtime \textbf{\underline{M}}odules (\figref{fig:policy-overview}).
% check
\textbf{(M1)} periodically monitors some CPU counters related to memory subsystem performance, and then \textbf{(M2)} estimates memory-subsystem performance based on values of the counters. 
% check
When a given application requests an allocation of new pages, (M3) tunes the percentage of the new pages allocated to \cxlmem, aiming to improve the throughput of the application. 
% check
Subsequently, \texttt{mempolicy}~\cite{mn_il_patch} sets the page allocation ratio between DDR memory and \cxlmem based on the percentage guided by (M3), and instructs the OS to allocate the new pages based on the ratio.  
% check

\begin{table}[b]
\centering
    \vspace{-6pt}
    \caption{CPU counters pertinent to memory-subsystem perf.}
    \vspace{-6pt}
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{ccc}
        \toprule
        \textbf{Metric} & \textbf{Tool} & \textbf{Description} \\ 
        \midrule
        L1 miss latency & pcm-latency & Average L1 miss latency (ns)\\
        DDR read latency & pcm-latency & DDR read latency (ns)\\
        IPC & pcm & Instructions per cycle \\
        \bottomrule
    \end{tabular}
    }
    \label{table:model-metric}
\end{table}



\niparagraph{(M1) Monitoring CPU counters related to memory subsystem performance.} 
%
We use Intel PCM~\cite{intel-pcm} % and PMU~\cite{pmu-tools} 
to periodically sample various CPU counters related to memory subsystem performance, as listed in Table~\ref{table:model-metric}.
% check
These CPU counters allow (M2) to estimate overall memory-subsystem performance.
% check
In \figref{fig:correlation}, we run \texttt{DLRM}, of which the throughput is bounded by memory bandwidth.
% check
Then we observe correlations between \texttt{DLRM} throughput and values of those counters, as we vary the percentage of pages allocated to \cxlmem.
% check

\figref{fig:correlation:bandwidth} shows that \texttt{DLRM} throughput is proportional to the consumed memory bandwidth.
% check
Yet, as the consumed memory bandwidth exceeds a certain amount, the memory access latency rapidly increases due to contention and resulting queuing delay at the memory controller~\cite{tootoonchian2018resq}, which, in turn, decreases the \texttt{DLRM} throughput.
% check

Meanwhile, \figref{fig:correlation:latency} shows that
\texttt{DLRM} throughput is inversely proportional to L1 miss latency.
% check
The L1 miss latency is an important memory-subsystem performance metric that simultaneously captures both the cache friendliness and bandwidth intensiveness (\ie, queuing delay at the memory controller) of given (co-running) applications at the same time. 
% check
At first, allocating more pages to \cxlmem reduces pressure on the DDR memory controller, thereby decreasing the latency of accessing DDR memory and handling L1 misses.
% check
However, at some point, the long latency of accessing \cxlmem begins to dominate that of handling L1 misses, and the application throughput begins to decrease.
% check
Finally, IPC is another important metric that implicitly measures the efficiency of the memory subsystem for the applications. 
% check

\begin{figure}[t!]
    \centering
    \begin{subfigure}[b]{0.517\columnwidth}
        \includegraphics[width=\linewidth]{figs/dlrm_perf_system_bw.pdf}
        \vspace{-12pt}
        %\caption{Throughput vs. System BW}
        \caption{System bandwidth}
        \label{fig:correlation:bandwidth}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.463\columnwidth}
        \includegraphics[width=\linewidth]{figs/dlrm_perf_l1_miss_latency.pdf}
        \vspace{-12pt}
        %\caption{Throughput vs. L1 miss latency}
        \caption{L1 miss latency}
        \label{fig:correlation:latency}
    \end{subfigure}
    \vspace{-3pt}
    \caption{Correlations between throughput and various counter values, as we increase the percentage of pages allocated to \cxlmem for \texttt{DLRM}. 
    The system bandwidth is 
    %the total memory bandwidth provided by both DDR and \cxlmem, and 
    %normalized to 
    the total consumed memory bandwidth, and
    %given by only DDR. 
    The throughput is normalized to DDR 100\%.%the case allocating all the pages to DDR. 
    %\nskim{for x-axis, we can show the absolute values? For System BW, you can put a dotted vertical line, and label as DDR max bandwidth. BTW, this plot can be taller and use only one y-axis label as both plots shows DLRM throughput.}
    }
    \label{fig:correlation}
    \vspace{-6pt}
\end{figure}

\niparagraph{(M2) Estimating system throughput.} To build a model that estimates the system performance, we collect CPU counter values at various DDR:CXL ratios while running \texttt{DLRM} with 24 threads. 
% check
We then build a linear-regression model that correlates these counter values with \texttt{DLRM} throughput. 
% check
Taking these counter values from (M1), \policy periodically estimates (or infers) memory-subsystem performance at runtime. 
% check
In our current implementation of \policy, (M1) samples the counters every 1 second. To reduce the noise among the values, we collect a moving average of the past 5 samples for each counter. The averaged value is then fed into (M2) for performance estimation.
% check
Although we may use a machine-learning (ML) model, we use the following simple linear model for the current implementation of \policy:
% check

\begin{equation}\label{eq:2}
%\begin{aligned}
Y = \beta_{0} + \beta_1 X_1 + \beta_2 X_2 + ...
%\end{aligned}
\end{equation}


\noindent where $Y$ represents the estimated memory-subsystem performance, $X_n$ represents a counter value listed in Table~\ref{table:model-metric}, and $\beta_n$ represents the $X_n$'s weight obtained through multiple linear regression steps. 
% check
This linear model is simple enough to be used by the OS at a low performance cost, yet effective enough to estimate the memory-subsystem performance. %, which is proportional the throughput of memory-bandwidth-intensive applications. 
% check
In the current implementation of \policy, we find that using \texttt{PCM} toolkit is sufficient.
% check
Nonetheless, we may use PMU tools and eBPF~\cite{ebpf} to access more diverse counters, facilitating a more precise estimation of memory-subsystem performance.
% check

\SetKwComment{Comment}{/* }{ */}
\RestyleAlgo{ruled}

\setlength{\textfloatsep}{10pt}% Modify \textfloatsep
\setlength{\textfloatsep}{10pt}% Modify \textfloatsep
\begin{algorithm}[t]
\DontPrintSemicolon
\caption{\policy tuning algorithm. \texttt{state}, \texttt{step} and \texttt{ratio} represent memory subsystem performance, unit of tuning page allocation ratio, and ratio of page allocation between DDR and \cxlmem.} \label{alg:tune}
%\tcp*[l]{take reverse direction}
    \While {$true$} {
        $curr\_state\gets estimator()$\;
        \If{$curr\_state < prev\_state$} {
            $curr\_step\gets prev\_step \times (-0.5)$ \tcp*[l]{reverse}
        } 
        $curr\_ratio\gets prev\_ratio + curr\_step$\;
        $check\_ratio\_bound()$\;
        $set\_ratio(curr\_ratio)$\;
        \If{new allocations} {
            $prev\_state\gets curr\_state$\;
            $prev\_step\gets curr\_step$\;
            $prev\_ratio\gets curr\_ratio$\;
        }
        $sleep(tune\_interval)$
    }
\end{algorithm}
% \begin{algorithm}[t]
%     \DontPrintSemicolon
%     \caption{\policy tuning algorithm. \texttt{c}, \texttt{s} and \texttt{r} represent memory-subsystem performance, unit of tuning page allocation, and ratio of page allocation between DDR and \cxlmem. \texttt{H\textsubscript{reset}} and \texttt{H\textsubscript{idle}} are empirically determined thresholds for tuning.} \label{alg:tune}
%     \While {$true$} {
%         $c$ append(Estimator())\;
%         \If{new allocations} {
%             $c_{avg1} = $ average($c$)\;
%             $\Delta = c_{avg1} - c_{avg0}$\;
%             \If{abs($\Delta$) $< H_{idle}$} {
%                 continue\;
%             }
%             \If{abs($\Delta$) $> H_{reset}$} {
%                 reset\_ratio()\;
%                 continue 
%             }
%             \ElseIf{$\Delta < 0$} {
%                 $s_1 = s_0 \times - \frac{1}{2}$ \tcp*[l]{reverse}

%             }
%             $r_1 = r_0 $ + $ s_1 $\;
%             $r_1 = $ check\_ratio\_bound($r_1$)\;
%             set\_ratio($r_1$)\;
            
%             $r_0 = r_1$\;
%             $s_0 = s_1$\;
%             $c_{avg0} = c_{avg1}$\;
%             clear $c$
%         }
%         sleep(tune\_interval)\;
%     }
% \end{algorithm}

\niparagraph{(M3) Tuning the percentage of pages allocated to CXL memory.} 
%
When a given application demands allocation of memory pages, \policy (Algorithm~\ref{alg:tune}) first compares the estimated memory-subsystem performance value from the past period (line: 9--11) with the current period (line: 3).
% check
If the memory-subsystem performance in the current period has increased compared to the previous period, \policy assumes that its previous decision, \ie, increasing (or decreasing) the percentage of pages allocated to \cxlmem, was correct.
% check
Then it continues to incrementally increase (or decrease) the percentage by a fixed amount (line: 5). 
%
Otherwise, it will begin to reverse the step by half (line: 4), which decreases (or increases) the percentage and evaluate the decision in the future period to determine a favorable percentage of pages allocated to \cxlmem. Note that the absolute value of the step variable has the minimum limit (\eg, 9\% in our evaluation) to prevent it from being close to zero.
% check
Lastly, inspired by conventional control theory, \policy implements mechanisms to efficiently handle very small or sudden large changes in memory subsystem performance, even though they are not described in Algorithm~\ref{alg:tune}.
% check

%\vspace{-0.05in}
\subsection{Evaluation}
\label{sec:policy:eval}
We have developed \policy after analyzing the various performance characteristics and memory subsystem statistics of \texttt{DLRM}.
% check
However, we expect that \policy should work well for other applications because the monitored L1 miss latency, DDR read latency, and IPC counters are fundamental memory subsystem performance metrics that are strongly correlated with the throughput of memory-bandwidth-intensive applications; 
% check
we believe CXL memory access latency and bandwidth statistics are also useful for estimating memory subsystem performance, but we currently cannot access the corresponding counters.
% check
To demonstrate this, we evaluate the efficacy of \policy by co-running (1) \texttt{SPEC-Mix}, various mixes of memory-intensive SPECrate CPU2017 benchmarks, and (2) \texttt{Redis} and \texttt{DLRM} without measuring their performance characteristics and memory-subsystem statistics in advance.
% check


\figref{fig:linear-model-throughput} shows normalized measured throughput (\texttt{Throughput}), normalized estimated memory-subsystem performance (Eq. (\ref{eq:2}), \texttt{Model Output}), and Pearson correlation coefficient values. %, as we vary the percentage of pages allocated to \cxlmem over time.
For \texttt{DLRM} we simply sweep the percentage of pages allocated to \cxlmem over time.
% check
For \texttt{SPEC-Mix}, we let \policy automatically tune the percentage of pages allocated to \cxlmem whenever a benchmark completes its execution.
% check
The Pearson correlation method allows us to quantify synchrony between time-series data~\cite{benesty2009pearson}.
% check
The coefficient value can range from -1 and 1, indicating that both sets of data trend the same direction when it is positive.
% check
We calculate the Pearson correlation coefficient values to assess the effectiveness of the  estimation model, as Algorithm~\ref{alg:tune} depends on precisely determining only the direction of performance changes after tuning the percentage of pages allocated to \cxlmem.
%
\figref{fig:linear-model-throughput} demonstrates that the Pearson correlation coefficient values mostly remains positive for both \texttt{DLRM} and \texttt{SPEC-Mix}. 
% check
This indicates that the estimation model is adequate  for Algorithm~\ref{alg:tune} to effectively tune both \texttt{DLRM} and \texttt{SPEC-Mix}. 
% check
It is important to note that the estimation model is based on the weight values derived by fitting counter values from \texttt{DLRM} exclusively in this paper. 
% check
However, it has the potential for further improvement by fitting counter values from a more diverse range of applications.
% check


\begin{figure} %[!b]
    \centering
    %\vspace{-12pt}
    \begin{subfigure}[b]{\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figs/tune_runtime_1.pdf}
        \vspace{-12pt}
        \caption{DLRM}
        \vspace{6pt}
        \label{fig:linear-model-throughput:dlrm}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figs/tune_runtime_2.pdf}
        \vspace{-12pt}
        \caption{SPEC-Mix}
        \label{linear-model-throughput:spec}
    \end{subfigure}
    \hfill
    \vspace{-18pt}
    \caption{Estimated memory-subsystem performance, measured application throughput, and Pearson coefficient values over time. 
    %For \texttt{DLRM} we simply sweep the percentage of pages allocated to \cxlmem. 
    %For \texttt{SPEC-Mix} we let \policy automatically tune the percentage whenever a benchmark is launched. 
    The numbers represent the percentage values of pages allocated to \cxlmem.
    }
    %after completing the execution of the previous one.} 
    %We use the total instruction per second (IPS) of all the co-running benchmark programs as throughput for \texttt{SPEC-Mix}. We take the throughput value of the first 1~s period to normalize throughput values over time. We sample CPU counters every 1~s which limited by the minimum sampling period allowed by the PCM tool.    }
    \label{fig:linear-model-throughput}
    \vspace{-6pt}
\end{figure}



\figref{fig:tune-improvement} evaluates the efficacy of \policy for 16 instances of individual \texttt{SPEC} benchmarks, two different \texttt{SPEC-Mix}, and a mix of \texttt{Redis} and \texttt{DLRM}.
% check
For all the evaluation cases, \policy outperforms both 100\% and 50\% allocations to DDR memory while allocating substantial percentages of pages to \cxlmem.  
% check
Specifically, \policy offers 19\%, 18\%, 8\%, and 20\% higher throughput values for \texttt{fotonik3d}, \texttt{mcf}, \texttt{roms}, and \texttt{cactuBSSN}, respectively, than the best static allocation policy (\ie, 100\% or 50\% allocation to DDR memory), allocating 29\%--41\% of pages to \cxlmem in a steady state.
% check
For the mixes of \texttt{mcf} and \texttt{roms}, \texttt{cactuBSSN} and \texttt{roms}, and  \texttt{Redis} and \texttt{DLRM}, \policy provides 24\%, 1\%, and 4\% higher throughput values than the best static allocation policy, allocating 33\%--41\% of pages to \cxlmem.
%
Since \texttt{DLRM} and \texttt{Redis} use different throughput metrics, we show a geometric mean value of normalized throughput values of \texttt{DLRM} and \texttt{Redis} as a single throughput value. 
%
These demonstrate that \policy captures the immense memory pressure from co-running applications and tunes to the percentage of pages to \cxlmem that yields higher throughput than the static allocation policies.
%

\begin{figure}[t]
    \centering
    %\vspace{10pt}
    \includegraphics[width=\linewidth]{figs/caption_improvement_rev.pdf}
    \vspace{-16pt}
    \caption{Throughput of each evaluated benchmark or mix, normalized to that with the default static policy allocating 50\% of pages to \cxlmem. A number atop each bar is the percentage of pages allocated to \cxlmem by \policy.}
    \label{fig:tune-improvement}
    \vspace{-6pt}
\end{figure}

In \figref{fig:tune-improvement}, we do not compare \policy with the static allocation policy for \texttt{DLRM} and \texttt{Redis} individually.
%
This is because we have derived the estimation model after running \texttt{DLRM} (\S\ref{sec:policy:design}) and demonstrated that allocating all the pages to DDR memory is best for \texttt{Redis} (\S\ref{sec:app:throughput}).
%
However, our evaluation shows that \policy presents 80\% higher and 4\% lower throughput values than allocating 100\% and 50\% of pages to DDR memory, respectively, for \texttt{DLRM}.
% check
For \texttt{Redis}, \policy is able to identify that allocating more memory to low-latency DDR memory is beneficial, and thus offers 3.2\% higher throughput than allocating 50\% of pages to DDR memory but 8.6\% lower throughput than allocating 100\% of pages to DDR memory.
%
Albeit not perfect, \policy demonstrates its capability of searching near-optimal percentage values of pages allocated to \cxlmem without any guidance from users and/or applications for several workloads with notably different characteristics.
%
Lastly, one of our primary goals is to emphasize the need for a dynamic page allocation policy and show a potential of such a policy. Hence, we leave further enhancement of \policy as future work.

%This improvement is \textcolor{red}{X\%} smaller than the maximum improvement that we observed in \figref{fig:ycsb_max_qps}. but it demonstrates that. 