\section{Experiments and Results}
\subsection{Datasets}
\label{sec:braindata}
\noindent\textbf{Brain MRI Datasets.} We include 2,421 (1,163 T1w) brain MRI scans acquired from newborn to toddler in this study. Among them, 2,306 are unannotated scans dedicated for the 3D multi-scale MAE pretraining. These MRI scans are acquired from multiple sites with different sequence parametrization and scanner types. All scans are preprocessed with skull stripping~\cite{hoopes2022synthstrip} and bias-field correction~\cite{tustison2010n4itk}. These MRI brain scans were acquired worldwide, and detailed descriptions can be found in Appendix \cref{sec:datadetail}. 

To evaluate cross-sequence/site/age UDA segmentation for seven subcortical regions (\ie, hippocampus (HC), amygdala (AD), caudate (CD), putamen (PT), pallidum (PD), thalamus (TM), and accumbens (AB)), our analysis include manual segmentation of 115 scans. They comprise independent subjects from the BCP cohort (\textit{BCP50}) with private expert segmentation for both T1w and T2w scans (acquired from 0 to 24 months postnatal age); 5 newborn scans from the ECHO cohort (\textit{ECHO5}) with private expert segmentation; and 10 newborn scans from the M-CRIB project (\textit{MCRIB10}) with publicly available segmentation~\cite{mcrib}.

\noindent\textbf{Cardiac CT-MRI Dataset.}
Following the previous studies~\cite{8988158, Chen_Dou_Chen_Qin_Heng_2019}, we include 40 independent scans (20 CT and 20 MRI) of cardiac regions from Multi-Modality Whole Heart Segmentation (MMWHS) Challenge 2017 dataset~\cite{ZHUANG201677, 9965747, 8458220} with ground truth labels of ascending aorta (AA), left atrium blood cavity (LAC), left ventricle blood cavity (LVC), and myocardium of the left ventricle (MYO). Similarly, we apply bias-field correction to the MRI scans.

%-------------------------------------------------------------------------
\begin{table}
    \caption{Performance of centralized UDA on brain MRI segmentation.}
    \vspace{-1em}
    \centering
    \begin{center}
        \resizebox{0.88\linewidth}{!}{%
            \begin{tabular}{c|cccccccc}
                \toprule
                \multicolumn{9}{c}{\textbf{Cross-Sequence}}\\	
                \hline
                \multirow{2}{*}{Method} &\multicolumn{8}{c}{Dice(\%) $\uparrow$} \\
                \cline{2-9}
                &HC &AD &CD &PT &PD&TM &AB &Avg \\
                
                \hline
                AdvEnt\cite{8954439} &56.7&52.7&66.7&66.1&61.8&74.1&40.1&59.8\\
                DAFormer\cite{daformer}&40.5&53.3&62.2&64.7&45.9&61.8&39.9&52.6\\
                HRDA\cite{hrda}&42.6&37.7&66.5&71.9&0.0&67.6&0.3&40.9\\
                MIC\cite{Hoyer_2023_CVPR}&40.3&47.0&72.5&52.9&0.0&62.1&0.0&39.3\\
                DAR-UNet\cite{9741336} &61.3&65.2&76.7&75.8&68.1&82.0&48.4&68.2\\
                \textbf{MAPSeg (Ours)} &\textbf{70.3}&\textbf{73.2}&\textbf{81.4}&\textbf{83.9}&\textbf{76.5}&\textbf{89.6}&\textbf{69.2}&\textbf{77.7}\\
                \bottomrule

                \multicolumn{9}{c}{\textbf{Cross-Site}}\\	
                \hline
                \multirow{2}{*}{Method} &\multicolumn{8}{c}{Dice(\%) $\uparrow$} \\
                \cline{2-9}
                &HC &AD &CD &PT &PD&TM &AB &Avg \\
                
                \hline
                AdvEnt\cite{8954439} &27.1&6.7&21.0&23.1&12.5&36.0&20.5&21.0\\
                DAFormer\cite{daformer}&40.0&45.8&75.3&70.0&68.4&64.0&51.3&59.3\\
                HRDA\cite{hrda}&30.9&44.3&80.8&79.8&66.4&83.0&53.4&62.7\\
                MIC\cite{Hoyer_2023_CVPR}&48.1&36.2&67.7&82.8&\textbf{69.5}&66.8&52.3&60.5\\
                DAR-UNet\cite{9741336} &51.9&43.6&69.8&55.2&55.5&81.2&45.8&57.6\\
                \textbf{MAPSeg (Ours)} &\textbf{70.0}&\textbf{53.5}&\textbf{85.6}&\textbf{85.4}&67.9&\textbf{88.1}&\textbf{61.4}&\textbf{73.1}\\
                \bottomrule
                \multicolumn{9}{c}{\textbf{Cross-Age}}\\	
                \hline
                \multirow{2}{*}{Method} &\multicolumn{8}{c}{Dice(\%) $\uparrow$} \\
                \cline{2-9}
                &HC &AD &CD &PT &PD&TM &AB &Avg \\
                
                \hline
                AdvEnt\cite{8954439} &58.7&54.1&44.0&63.8&56.9&78.0&30.9&55.2\\
                DAFormer\cite{daformer}&30.2&65.7&72.7&55.8&38.4&88.8&57.3&58.4\\
                HRDA\cite{hrda}&48.6&66.6&81.9&67.7&35.7&74.1&56.0&61.5\\
                MIC\cite{Hoyer_2023_CVPR}&61.3&66.0&80.9&\textbf{73.4}&44.3&76.1&51.0&64.7\\
                DAR-UNet\cite{9741336} &58.8&56.3&64.4&64.5&53.6&82.6&28.6&58.8\\
                \textbf{MAPSeg (Ours)} &\textbf{75.8}&\textbf{76.7}&\textbf{83.1}&71.4&\textbf{58.2}&\textbf{90.7}&\textbf{70.1}&\textbf{75.2}\\
                \bottomrule
            \end{tabular}}
    \end{center}
    \label{tab:centralizedUDA}
    \vspace{-1em}
\end{table}

\subsection{Dataset Partition}

\noindent\textbf{Pretraining.} For multi-scale MAE pretraining on brain MRI scans, we have four models pretrained on different amounts of data to investigate the influence of pretraining data size. The model pretrained on large-scale data takes advantage of all 2,306 unannotated scans introduced in \cref{sec:braindata}. Since there is no overlapping with the annotated scans, the pretrained model can be directly applied to all downstream UDA tasks (\ie, cross-site/age/sequence). We also pretrain the model solely relying on source and target training data of each task.

For multi-scale MAE pretraining on cardiac CT-MRI scans, the model is only pretrained on training scans of source (16 CT scans) and target (16 MRI scans) domains, following the partition adopted by previous studies.

\noindent\textbf{Cross-Sequence UDA segmentation of brain.}
The model is trained on T1w MRI scans (source domain) and tested on T2w MRI scans (target domain). 
The \textit{BCP50} dataset is randomly split into two non-overlapping subsets of 25 subjects per each. The model is trained on T1w scans of the first group (source domain 18 scans for training and 7 for validation) and T2w scans of the second group (target domain 15 for training and 10 for testing). The best validation model is then applied to the T2w testing scans. 

\noindent\textbf{Cross-Site UDA segmentation of brain.}
The model is trained on a single site (\textit{BCP50}, source domain) and tested on two other sites (\textit{MCRIB10} and \textit{ECHO5}, target domains). Utilizing 50 T2w MRI scans from BCP as the source domain, we randomly select 40 scans for training and 10 for validation. Six scans from \textit{MCRIB10} and three scans from \textit{ECHO5} are used for UDA training, and remaining scans are used for testing. 

\noindent\textbf{Cross-Age UDA segmentation of brain.}
We also conduct experiments in cross-age segmentation using longitudinal scans from \textit{BCP50}. We set the 24 T2w MRI scans of 12-24 month-old infant as the source domain and 14 T2w MRI scans of 0-6 month-old infants as the target domain. For the source domain, 19 scans are randomly sampled for training and remaining 5 scans are used for validation. For the target domain, 8 scans are used for UDA training and 6 scans are used for testing. 

\noindent\textbf{Cross-Modality UDA segmentation of cardiac.}
For the cardiac scans, for a fair comparison, we follow the same partition employed by the previous studies. We set CT as the source domain and MRI as the target domain, and use 16 CT scans and 16 MRI scans for training, 4 CT scans for validation, and the remaining 4 MRI scans for testing.  

\subsection{Results}

\noindent\textbf{Centralized Domain Adaptation.}
\label{sec.CUDA}
To assess MAPSeg's performance in different UDA tasks for infant brain MRI segmentation, we compare it with methods utilizing adversarial entropy minimization~\cite{8954439}, image translation~\cite{9741336}, and pseudo-labeling~\cite{daformer,hrda, Hoyer_2023_CVPR}. The results are reported in \hyperref[tab:centralizedUDA]{Tab.1}. MAPSeg consistently outperforms its counterparts across all tasks. DAR-UNet ranks second in the cross-sequence task but shows degraded performance in others, partially due to translation error (details in Appendix). Among pseudo-labeling approaches, HRDA and MIC achieve the second best performance in cross-site and cross-age tasks, respectively. However, they fail to segment pallidum and accumbens in the cross-sequence task. A major challenge here is the small size of subcortical regions (accounting for approximately 2\% of overall voxels) and significant class imbalance (\eg, thalamus comprises about 0.8\% of overall voxels, while accumbens accounts for only 0.03\%). This imbalance poses a significant challenge for previous pseudo-labeling methods. Additional visualizations and discussions are available in Appendix \cref{sec:appendixvis}.

\begin{table}
    \caption{Performance of federated UDA on brain MRI segmentation.}
    \vspace{-1em}
    \centering
    \begin{center}
        \resizebox{0.8\linewidth}{!}{%
            \begin{tabular}{c|ccc}
                \toprule
                \multirow{2}{*}{Method} & \multicolumn{3}{c}{Dice(\%) $\uparrow$} \\
                \cline{2-4} & Cross-Sequence & Cross-Site & Cross-Age \\
                \hline
                FAT\cite{DBLP:conf/isbi/MushtaqBDA23} & 27.6 & 63.8 & 69.0 \\
                DualAdapt\cite{fmtda} & 28.4 & 66.1 & 54.8 \\
                \hline
                \textbf{Fed-MAPSeg (ours)} &\textbf{69.9} &\textbf{73.6} &\textbf{71.0} \\
                \bottomrule
            \end{tabular}}
    \end{center}
    \label{exp:fl}
    \vspace{-1em}
\end{table}

\noindent\textbf{Federated Domain Adaptation.}
\label{sec:results_FLUDA}
To evaluate our framework in the federated domain adaptation setting, we designate the labeled source-domain dataset as the server dataset and the unlabeled target-domain datasets as the client datasets. In the cross-sequence setting, the 25 T1w scans of the first group are considered as the server dataset, and the 25 T2w scans of the second group are split roughly equally into three disjoint client datasets. In the cross-site setting, the \textit{BCP50} is considered as the server dataset, and the \textit{ECHO5} and \textit{MCRIB10} naturally serve as two different client datasets. In the cross-age setting, we treat the scans from the first age group as the server dataset, and split the scans from the second age group equally into two client datasets.

\begin{table}
    \caption{Comparison between centralized and test-time UDA on brain MRI segmentation. Performance of source domain are reported on source validation set.}
    \vspace{-1em}
    \centering
    \begin{center}
        \resizebox{0.86\linewidth}{!}{%
            \begin{tabular}{c|cccc|cc}
                \hline
                \multirow{2}{*}{Task} &\multicolumn{2}{c|}{Centralized UDA}&\multicolumn{2}{c|}{Test-time UDA}&\multirow{2}{*}{$\Delta_{Source}$}&\multirow{2}{*}{$\Delta_{Target}$}\\
                \cline{2-5}
                
                &\multicolumn{1}{c}{Source}&\multicolumn{1}{c|}{Target}&\multicolumn{1}{c}{Source} &\multicolumn{1}{c|}{Target} \\
                
                \hline
                X-seq &84.0&77.7&79.2&75.9&-4.8&-1.8\\
                X-age & 85.8 &75.2& 84.2&72.9&-1.6&-2.3\\
                X-site &85.7&73.1& 79.9& 70.3&-5.8&-2.8\\
                \bottomrule

        \end{tabular}}
    \end{center}
    \label{tab:testtime}
    \vspace{-1em}
\end{table}

We compare our Fed-MAPSeg with two other related work, \textit{FAT}~\cite{DBLP:conf/isbi/MushtaqBDA23} and \textit{DualAdapt}~\cite{fmtda}. To our best knowledge, there is no direct comparison from the literature that addresses this challenging federated multi-target unsupervised domain adaptation for 3D medical image segmentation. \textit{FAT}~\cite{DBLP:conf/isbi/MushtaqBDA23} proposes an alternating training scheme between the labeled and unlabeled data silos and adopts a mixup approach to augment the unlabeled input data for self-supervised learning with pseudo-labels. \textit{DualAdapt}~\cite{fmtda} considers a similar single-source to multi-target unsupervised domain adaptation setting, except that it only reports segmentation performance for 2D image datasets such as the DomainNet~\cite{peng2019moment} and CrossCity~\cite{cross_city}. Implementation details for our Fed-MAPSeg as well as the baselines are included in Appendix \cref{sec:baseline}. We report our results in \hyperref[exp:fl]{Tab.2}. Fed-MAPSeg not only outperforms the two baselines by a large margin (esp. in the the cross-sequence setting), it also maintains a fairly close performance compared to the centralized UDA.

\label{sec.ttdaresults} \noindent\textbf{Test-Time Domain Adaptation.} We further extend MAPSeg to Test-time UDA, and the results for different tasks are reported in \hyperref[tab:testtime]{Tab.3}. With decentralized data and asynchronous training, MAPSeg still performs very well in all tasks, with performance drop smaller than 3\% in the target domain. However, we observe a slightly more performance degradation in the source domain (\hyperref[tab:testtime]{Tab.3}), particularly in cross-sequence and cross-site tasks, suggesting that the model suffers from forgetting of the source domain knowledge during test-time UDA. 

\noindent\textbf{Cross-Modality Segmentation of Cardiac.} 
To evaluate the generalizability of MAPSeg, we further conduct experiment for cross-modality cardiac segmentation and the results are reported in \hyperref[tab:cardiac]{Tab.4}. MAPSeg surpasses all previously reported results. Results of MRI $\rightarrow$ CT segmentation can be found in Appendix \cref{sec:mri2ctresult}.

\begin{table}
    \caption{Performance of centralized UDA on cardiact CT$\rightarrow$ MRI segmentation. Underline indicates the target labels are not used for validation.}
    \vspace{-1em}
    \centering
    \begin{center}
        \resizebox{0.78\linewidth}{!}{%
            \begin{tabular}{c|cccccccc}
                \toprule
                \multicolumn{6}{c}{Cardiac CT $\rightarrow$ MRI segmentation}\\	
                \hline
                \multirow{2}{*}{Method} &\multicolumn{5}{c}{Dice(\%) $\uparrow$} \\
                \cline{2-6}
                &AA &LAC &LVC &MYO &Avg \\
                \hline
                PnP-AdaNet\cite{8764342} &43.7&47.0&77.7&48.6&54.3 \\
                SIFA-V1\cite{Chen_Dou_Chen_Qin_Heng_2019} &67.0&60.7&75.1&45.8&62.1 \\
                SIFA-V2\cite{8988158} &65.3&62.3&78.9&47.3&63.4 \\
                DAFormer\cite{daformer} &75.2&59.4&72.0&57.1&65.9 \\
                MPSCL\cite{9672690} & 62.8&76.1&80.5&55.1&68.6\\
                MA-UDA\cite{10273225} &71.0&67.4&77.5&57.1&68.7 \\
                SE-ASA\cite{Feng_Ju_Wang_Song_Zhao_Ge_2023} &68.3&74.6&81.0&55.9&69.9 \\
                FSUDA-V1\cite{Liu_Yin_Qu_Wang_2023} &62.4&72.1&81.2&66.5&70.6\\
                PUFT\cite{10021602} &69.3&77.4&83.0&63.6&73.3\\
                SDUDA\cite{Cui_structure_driven}&72.8&79.3&82.3&64.7&74.8\\
                FSUDA-V2\cite{10261458} &72.5&78.6&82.6&68.4&75.5\\
                
                \hline
                \multirow{2}{*}{\textbf{MAPSeg (Ours)}}
                &\underline{\textbf{78.5}}&\underline{\textbf{81.8}}&\underline{92.1}&\underline{68.8}&\underline{80.3}\\
                 &78.2&\textbf{81.8}&\textbf{92.9}&\textbf{72.0}&\textbf{81.2}\\
                \bottomrule

        \end{tabular}}
    \end{center}
    \label{tab:cardiac}
    \vspace{-1em}
\end{table}
\begin{table}
    \caption{Ablation studies of MAPSeg components on cross-sequence brain MRI segmentation.}
    \vspace{-1em}
    \centering
    \begin{center}
        \resizebox{0.5\linewidth}{!}{%
            \begin{tabular}{cccccc|c}
                \toprule
                \multicolumn{6}{c|}{Components}&\multicolumn{1}{c}{Performance}\\
                    \hline
                \cline{1-7}
                \multicolumn{2}{c|}{MAE} &\multicolumn{2}{c|}{GLC} &\multicolumn{2}{c|}{MPL} &Dice(\%) $\uparrow$\\
                
                \hline
    \multicolumn{2}{c|}{} &\multicolumn{2}{c|}{} &\multicolumn{2}{c|}{} &31.6  \\
     \multicolumn{2}{c|}{\checkmark} &\multicolumn{2}{c|}{} 
     &\multicolumn{2}{c|}{} &51.3 \\
     \multicolumn{2}{c|}{} &\multicolumn{2}{c|}{\checkmark} &\multicolumn{2}{c|}{} &53.0  \\
     \multicolumn{2}{c|}{} &\multicolumn{2}{c|}{} &\multicolumn{2}{c|}{\checkmark} &39.5  \\
     \multicolumn{2}{c|}{} &\multicolumn{2}{c|}{\checkmark} &\multicolumn{2}{c|}{\checkmark} & 59.0  \\
     \multicolumn{2}{c|}{\checkmark} &\multicolumn{2}{c|}{\checkmark} &\multicolumn{2}{c|}{} &71.3  \\
     \multicolumn{2}{c|}{\checkmark} &\multicolumn{2}{c|}{} &\multicolumn{2}{c|}{\checkmark} &75.3  \\
     
     \multicolumn{2}{c|}{\checkmark} &\multicolumn{2}{c|}{\checkmark} &\multicolumn{2}{c|}{\checkmark} &77.7  \\
					
                \bottomrule
        \end{tabular}}
    \end{center}
    \label{tab:ablation}
    \vspace{-1em}
\end{table}
\noindent\textbf{Ablation Studies.}
\label{sec:ablation}
To further investigate each component of MAPSeg, we conduct ablation studies focusing on MAE, GLC, MPL, masking ratio, masking patch size of local patch, and pretraining data size in the context of cross-sequence segmentation. From \hyperref[tab:ablation]{Tab.5}, it is clear that directly applying MPL only brings a minor improvement, suggesting using MPL alone suffers from pseudo-label drifts. By incorporating GLC to leverage global-local contexts, MPL yields better results. MAE pretraining significantly boosts the performance from using MPL alone (39.5 to 75.3), justifying MAE and MPL are complementary parts in MAPSeg. Combining MAE, MPL, and GLC together yields the optimal performance. 

The impact of masking ratio and local patch size is reported in \hyperref[fig:ablation]{Fig.3}. The masking ratio and patch size remain the same in MAE and MPL. The results indicate that MAPSeg is more sensitive to patch size. A patch size of 4 or 16 decreases the performance significantly. For the masking ratio, MAPSeg achieves optimal performance when 70\% of the regions are masked out. Additionally, we evaluate model's performance using only source and target training data ($<$ 50 scans) for MAE pretraining, much fewer than the large-scale pretraining ($>$ 2,000 scans). This suggests that, even with dozens of scans involved in MAE, MAPSeg still delivers comparable performance. Another benefit of large-scale pretraining is its immediate applicability to new target domains; the pretrained encoders can be directly employed for MPL, bypassing the need for training from scratch. Additional analyses about sensitivity to other hyperparameters can be found in Appendix \cref{sec:additionres}.

\begin{figure}[t!]
  \centering
     \includegraphics[width=0.9\linewidth]{./figs/ablation-10.pdf}
  \caption{Ablation studies on masking ratio, patch size, and pretrain data. Experiments on masking ratio and patch size are conducted on cross-sequence task.}
  \label{fig:ablation}
  \vspace{-1em}
\end{figure}