% Template for PLoS
% Version 3.6 Aug 2022
%
% % % % % % % % % % % % % % % % % % % % % %
%
% -- IMPORTANT NOTE
%
% This template contains comments intended 
% to minimize problems and delays during our production 
% process. Please follow the template instructions
% whenever possible.
%
% % % % % % % % % % % % % % % % % % % % % % % 
%
% Once your paper is accepted for publication, 
% PLEASE REMOVE ALL TRACKED CHANGES in this file 
% and leave only the final text of your manuscript. 
% PLOS recommends the use of latexdiff to track changes during review, as this will help to maintain a clean tex file.
% Visit https://www.ctan.org/pkg/latexdiff?lang=en for info or contact us at latex@plos.org.
%
%
% There are no restrictions on package use within the LaTeX files except that no packages listed in the template may be deleted.
%
% Please do not include colors or graphics in the text.
%
% The manuscript LaTeX source should be contained within a single file (do not use \input, \externaldocument, or similar commands).
%
% % % % % % % % % % % % % % % % % % % % % % %
%
% -- FIGURES AND TABLES
%
% Please include tables/figure captions directly after the paragraph where they are first cited in the text.
%
% DO NOT INCLUDE GRAPHICS IN YOUR MANUSCRIPT
% - Figures should be uploaded separately from your manuscript file. 
% - Figures generated using LaTeX should be extracted and removed from the PDF before submission. 
% - Figures containing multiple panels/subfigures must be combined into one image file before submission.
% For figure citations, please use "Fig" instead of "Figure".
% See http://journals.plos.org/plosone/s/figures for PLOS figure guidelines.
%
% Tables should be cell-based and may not contain:
% - spacing/line breaks within cells to alter layout or alignment
% - do not nest tabular environments (no tabular environments within tabular environments)
% - no graphics or colored text (cell background color/shading OK)
% See http://journals.plos.org/plosone/s/tables for table guidelines.
%
% For tables that exceed the width of the text column, use the adjustwidth environment as illustrated in the example table in text below.
%
% % % % % % % % % % % % % % % % % % % % % % % %
%
% -- EQUATIONS, MATH SYMBOLS, SUBSCRIPTS, AND SUPERSCRIPTS
%
% IMPORTANT
% Below are a few tips to help format your equations and other special characters according to our specifications. For more tips to help reduce the possibility of formatting errors during conversion, please see our LaTeX guidelines at http://journals.plos.org/plosone/s/latex
%
% For inline equations, please be sure to include all portions of an equation in the math environment.  For example, x$^2$ is incorrect; this should be formatted as $x^2$ (or $\mathrm{x}^2$ if the romanized font is desired).
%
% Do not include text that is not math in the math environment. For example, CO2 should be written as CO\textsubscript{2} instead of CO$_2$.
%
% Please add line breaks to long display equations when possible in order to fit size of the column. 
%
% For inline equations, please do not include punctuation (commas, etc) within the math environment unless this is part of the equation.
%
% When adding superscript or subscripts outside of brackets/braces, please group using {}.  For example, change "[U(D,E,\gamma)]^2" to "{[U(D,E,\gamma)]}^2". 
%
% Do not use \cal for caligraphic font.  Instead, use \mathcal{}
%
% % % % % % % % % % % % % % % % % % % % % % % % 
%
% Please contact latex@plos.org with any questions.
%
% % % % % % % % % % % % % % % % % % % % % % % %

\documentclass[10pt]{article}
\usepackage[top=0.85in,left=2.75in,footskip=0.75in]{geometry}

% amsmath and amssymb packages, useful for mathematical formulas and symbols
\usepackage{amsmath,amssymb}

% Use adjustwidth environment to exceed column width (see example table in text)
\usepackage{changepage}

% textcomp package and marvosym package for additional characters
\usepackage{textcomp,marvosym}

% cite package, to clean up citations in the main text. Do not remove.
\usepackage{cite}

% Use nameref to cite supporting information files (see Supporting Information section for more info)
\usepackage{nameref,hyperref}

% line numbers
%\usepackage[right]{lineno}

% ligatures disabled
\usepackage[nopatch=eqnum]{microtype}
\DisableLigatures[f]{encoding = *, family = * }

% color can be used to apply background shading to table cells only
\usepackage[table]{xcolor}

% my own imports

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{algorithm2e}
\usepackage{tikz}

\usetikzlibrary{matrix,shapes,arrows,positioning}
\usetikzlibrary{shapes.geometric, arrows, fit}

\tikzstyle{blockblue} = [rectangle, draw, fill=blue!50, text width=9em, text centered, rounded corners, minimum height=3em]
\tikzstyle{blockdarkblue} = [rectangle, draw, fill=blue!80, text=white, text width=9em, text centered, rounded corners, minimum height=3em]
\tikzstyle{blockwide} = [rectangle, draw, fill=blue!80, text=white, text width=21em, text centered, rounded corners, minimum height=3em]
\tikzstyle{line} = [draw, -latex']


\usepackage{import}
\usepackage{adjustbox}
\usepackage{comment}
\usetikzlibrary{positioning,matrix, arrows.meta}
\usetikzlibrary{shapes,arrows}
\tikzstyle{block} = [draw, rectangle, 
        minimum height=3em, minimum width=6em,fill=blue!30]
\tikzstyle{circ} = [draw, circle, node distance=1cm,fill=red!30]
\tikzstyle{input} = [coordinate]



% array package and thick rules for tables
\usepackage{array}

% create "+" rule type for thick vertical lines
\newcolumntype{+}{!{\vrule width 2pt}}

% create \thickcline for thick horizontal lines of variable length
\newlength\savedwidth
\newcommand\thickcline[1]{%
  \noalign{\global\savedwidth\arrayrulewidth\global\arrayrulewidth 2pt}%
  \cline{#1}%
  \noalign{\vskip\arrayrulewidth}%
  \noalign{\global\arrayrulewidth\savedwidth}%
}

% \thickhline command for thick horizontal lines that span the table
\newcommand\thickhline{\noalign{\global\savedwidth\arrayrulewidth\global\arrayrulewidth 2pt}%
\hline
\noalign{\global\arrayrulewidth\savedwidth}}


% Remove comment for double spacing
%\usepackage{setspace} 
%\doublespacing

% Text layout
\raggedright
\setlength{\parindent}{0.5cm}
\textwidth 5.25in 
\textheight 8.75in

% Bold the 'Figure #' in the caption and separate it from the title/caption with a period
% Captions will be left justified
\usepackage[aboveskip=1pt,labelfont=bf,labelsep=period,justification=raggedright,singlelinecheck=off]{caption}
\renewcommand{\figurename}{Fig}

% Use the PLoS provided BiBTeX style
\bibliographystyle{plos2015}

% Remove brackets from numbering in List of References
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother



% Header and Footer with logo
\usepackage{lastpage,fancyhdr,graphicx}
\usepackage{epstopdf}
%\pagestyle{myheadings}
\pagestyle{fancy}
\fancyhf{}
%\setlength{\headheight}{27.023pt}
%\lhead{\includegraphics[width=2.0in]{PLOS-submission.eps}}
\rfoot{\thepage/\pageref{LastPage}}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrule}{\hrule height 2pt \vspace{2mm}}
\fancyheadoffset[L]{2.25in}
\fancyfootoffset[L]{2.25in}
\lfoot{\today}

%% Include all macros below

\newcommand{\lorem}{{\bf LOREM}}
\newcommand{\ipsum}{{\bf IPSUM}}

%% END MACROS SECTION


\begin{document}
\vspace*{0.2in}

% Title must be 250 characters or less.
\begin{flushleft}
{\Large
\textbf\newline{Exploring the interplay between colorectal cancer subtypes genomic variants and cellular morphology: a deep-learning approach} % Please use "sentence case" for title and headings (capitalize only the first word in a title (or heading), the first word in a subtitle (or subheading), and any proper nouns).
}
\newline
% Insert author names, affiliations and corresponding author email (do not include titles, positions, or degrees).
%\\
Hadar Hezi\textsuperscript{1},
Daniel Shats\textsuperscript{2},
Daniel Gurevich\textsuperscript{3,4},
Yosef E. Maruvka\textsuperscript{3,4},
Moti Freiman\textsuperscript{1*}

%\\
\bigskip
\bigskip
\textbf{1} Faculty of Biomedical Engineering, Technion - Israel Institute of Technology, Haifa, Israel
\\
\textbf{2} Faculty of Computer Science, Technion - Israel Institute of Technology, Haifa, Israel
\\
\textbf{3} Faculty of Biotechnology and Food Engineering, Technion - Israel Institute of Technology, Haifa, Israel
\\
\textbf{4} Lokey Center for Life Science and Engineering, Technion - Israel Institute of Technology, Haifa, Israel
\\
\bigskip

% Insert additional author notes using the symbols described below. Insert symbol callouts after author names as necessary.
% 
% Remove or comment out the author notes below if they aren't used.
%
% Primary Equal Contribution Note
%\Yinyang These authors contributed equally to this work.

% Additional Equal Contribution Note
% Also use this double-dagger symbol for special authorship notes, such as senior authorship.
%\ddag These authors also contributed equally to this work.

% Current address notes
%\textcurrency Current Address: Dept/Program/Center, Institution Name, City, State, Country % change symbol to "\textcurrency a" if more than one current address note
% \textcurrency b Insert second current address 
% \textcurrency c Insert third current address

% Deceased author note
%\dag Deceased

% Group/Consortium Author Note
%\textpilcrow Membership list can be found in the Acknowledgments section.

% Use the asterisk to denote corresponding authorship and provide email address in note below.
* moti.freiman@technion.ac.il

\end{flushleft}
% Please keep the abstract below 300 words
\section*{Abstract}
Molecular subtypes of colorectal cancer (CRC) significantly influence treatment decisions. While convolutional neural networks (CNNs) have recently been introduced for automated CRC subtype identification using H\&E stained histopathological images, the correlation between CRC subtype genomic variants and their corresponding cellular morphology expressed by their imaging phenotypes is yet to be fully explored. The goal of this study was to determine such correlations by incorporating genomic variants in CNN models for CRC subtype classification from H\&E images. We utilized the publicly available TCGA-CRC-DX dataset, which comprises whole slide images from 360 CRC-diagnosed patients (260 for training and 100 for testing). This dataset also provides information on CRC subtype classifications and genomic variations. We trained CNN models for CRC subtype classification that account for potential correlation between genomic variations within CRC subtypes and their corresponding cellular morphology patterns. We assessed the interplay between CRC subtypes' genomic variations and cellular morphology patterns by evaluating the CRC subtype classification accuracy of the different models in a stratified 5-fold cross-validation experimental setup using the area under the ROC curve (AUROC) and average precision (AP) as the performance metrics. The CNN models that account for potential correlation between genomic variations within CRC subtypes and their cellular morphology pattern achieved superior accuracy compared to the baseline CNN classification model that does not account for genomic variations when using either single-nucleotide-polymorphism (SNP) molecular features (AUROC: 0.824$\pm$0.02 vs. 0.761$\pm$0.04, p$<$0.05, AP: 0.652$\pm$0.06 vs. 0.58$\pm$0.08) or CpG-Island methylation phenotype (CIMP) molecular features (AUROC: 0.834$\pm$0.01 vs. 0.787$\pm$0.03, p$<$0.05, AP: 0.687$\pm$0.02 vs. 0.64$\pm$0.05). Combining the CNN models account for variations in CIMP and SNP further improved classification accuracy (AUROC: 0.847$\pm$0.01 vs. 0.787$\pm$0.03, p$=$0.01, AP: 0.68$\pm$0.02 vs. 0.64$\pm$0.05). The improved accuracy of CNN models for CRC subtype classification that account for potential correlation between genomic variations within CRC subtypes and their corresponding cellular morphology as expressed by H\&E imaging phenotypes may elucidate the biological cues impacting cancer histopathological imaging phenotypes. Moreover, considering CRC subtypes genomic variations has the potential to improve the accuracy of deep-learning models in discerning cancer subtype from histopathological imaging data.

% Please keep the Author Summary between 150 and 200 words
% Use first person. PLOS ONE authors please skip this step. 
% Author Summary not valid for PLOS ONE submissions.   
%\section*{Author summary}
%Lorem ipsum dolor sit amet, consectetur adipiscing elit. %Curabitur eget porta erat. Morbi consectetur est vel gravida %pretium. Suspendisse ut dui eu ante cursus gravida non sed sem. %Nullam sapien tellus, commodo id velit id, eleifend volutpat %quam. Phasellus mauris velit, dapibus finibus elementum vel, %pulvinar non tellus. Nunc pellentesque pretium diam, quis maximus %dolor faucibus id. Nunc convallis sodales ante, ut ullamcorper %est egestas vitae. Nam sit amet enim ultrices, ultrices elit %pulvinar, volutpat risus.

%\linenumbers

% Use "Eq" instead of "Equation" for equation citations.
\section*{Introduction}
\label{sec:introduction}
Colorectal cancer (CRC) stands as the second leading cause of cancer-related deaths, resulting in approximately 0.9 million fatalities worldwide each year \cite{sung2021global}.
CRC is a heterogeneous disease as evident at multiple levels, including genetic, molecular, cellular, and histopathological variations. The heterogeneity of CRC makes disease management complex and diverse. Recognizing and understanding this heterogeneity is crucial for personalized medicine approaches, guiding treatment decisions, and developing new therapeutic strategies. Specifically, molecular subtyping of CRC into microsatellite instability (MSI) and microsatellite stability (MSS) subtypes is critical in selecting an appropriate immunotherapy protocol to achieve the best treatment response \cite{Hu2021PersonalizedStand, le2017mismatch}.

 
The gold standard for CRC subtyping into MSI and MSS is DNA sequencing using a Polymerase Chain Reaction (PCR) test \cite{Baudrin2018-tq}.  However, this test is expensive, time-consuming, and has limited availability to patients.

Recently, convolutional neural networks (CNNs) \cite{he2016deep,simonyan2014very} have been proposed for automatically determining CRC subtypes from common Hematoxylin and Eosin (H\&E) stained histopathological images \cite{Kather2019DeepCancer,kuntz2021gastrointestinal,wagner2023fully,altini2023role,lou2022ppsnet,liang2023interpretable,Bilal2021DevelopmentStudy}. By leveraging images already produced in regular clinical practices, this method holds promise as a cost-effective and precise solution for identifying CRC subtypes within the existing clinical framework.

However, CNN models to date have primarily focused on CRC subtype classification such as MSI or MSS, essentially assuming a strong correlation between CRC subtypes of MSI and MSS and their histopathological imaging phenotype. Yet, within subtype genomic heterogeneity might be associated with variations in cellular morphology as expressed in the imaging phenotypes. For instance, Zheng et al. \cite{Zheng2020} proposed that DNA methylation patterns might be discernible from whole slide images, given their impact on cellular morphology in several aspects, such as chromatin organization \cite{Zhang2017} and the determination of cell identity \cite{Lokk2014}. However, the correlation between CRC subtype genomic variants and their corresponding cellular morphology as expressed imaging phenotypes is yet to be fully explored. 


In this study, we aim to leverage CNN-based classification models to investigate the interplay between molecular and morphological levels. Our main hypothesis is that genomic variations within CRC subtypes of MSI and MSS may impact the H\&E image phenotype. We examined this hypothesis by developing and evaluating ``biologically-primed'' CNN classification models that account for the potential correlation between the genomic variations and the imaging phenotype. This is in contrast to previously proposed models for CRC subtype classification which considered only the CRC subtypes as potential classes, ignoring the heterogeneity within each subtype. To better reflect this, we term our model ``biologically-primed,'' as it integrates biological variations within subtypes, leading to a more comprehensive and precise understanding of CRC subtypes.


In this study, we particularly focused on single-nucleotide-polymorphism (SNP) and CpG-Island methylation phenotype (CIMP) within the MSI and MSS CRC subtypes because of their significant heterogeneity observed within the MSI subtype as indicated by Liu et al. \cite{Liu2018ComparativeAdenocarcinomas}.
We then compared the performance of these models to a baseline CNN classification model that does not account for potential correlation between the gnomic variations and the imaging phenotype using the publicly available TCGA-CRC-DX dataset \cite{crc-data} with a stratified 5-fold cross-validation experimental setup. 

Our experiments indicate that accounting for potential correlation between genomic variations within CRC subtypes and their imaging phenotype improved CRC subtypes classification accuracy compared to the baseline CNN classification model that does not account for such correlations when considering either SNP or CIMP. These results suggest a correlation between genomic variations within CRC subtypes of MSI and MSS and the tumor morphology and microenvironment as depicted by the H\&E images. Further, accounting for genomic variations within CRC subtypes has also the potential to improve the accuracy of deep-learning-based methods for cancer subtypes classification.

It is important to highlight that our model does not directly use genomic data as input. Instead, we represent the CRC subtype class as two distinct classes based on their genomic variations. The genomic variation information is utilized during model training to label the MSI patches as either MSI$_1$ or MSI$_2$. Therefore, while our training phase incorporates molecular subtype information, the inference process depends exclusively on the H\&E images, with no additional data used. 

The main contributions of the paper are summarized as follows:
\begin{itemize}
    \item Revealing the correlation between CRC subtypes genomic variations such as SNP and CIMP and cellular morphology expressed by H\&E imaging phenotype.  
    \item Introducing CNN models for CRC subtype classification that consider the potential correlation between CRC subtype genomic heterogeneity and cellular morphology as expressed by H\&E imaging phenotype.
    \item Improved accuracy for CNN-based CRC subtype classification 
    
\end{itemize}


\section*{Related work}
\label{sec:related}
During the past few years, a plethora of CNN-based methods were proposed for CRC subtype classification from H\&E stained images. Kather et al. \cite{Kather2019DeepCancer} were the first to infer CRC molecular sub-types MSI and MSS from H\&E images. They divided the images into small patches, performed patch-level classification with CNN, and aggregated the classification results to cope with the giga-pixel size of the images. Their approach achieved moderate success on the TCGA-CRC-DX \cite{crc-data} database (Area under the Receiver operating characteristic (AUROC) per patient of 0.77, n=360, 18\% MSI). Echle et al. \cite{Echle2020}, used a similar method but further improved the overall classification accuracy by increasing the dataset size through the combination of several databases. 


Multiple Instance Learning approaches (MIL) were also proposed to tackle the giga-pixel size of the CNNs. These approaches aim to extract meaningful patches representing the whole slide H\&E image. For instance, Bilal et al. \cite{Bilal2021DevelopmentStudy} employed an iterative 'draw and rank' technique to exclude less informative patches in CRC subtype classification, integrating patch selection during the preprocessing phase. Zhang et al. \cite{zhang2022dtfd} enhanced classification by clustering patches into various bags followed by bag distillation. Lin et al. \cite{lin2023interventional} introduced interventional bag learning for deconfounded bag-level predictions. Liang et al. \cite{liang2023interpretable} integrated spatial locations of adjacent instances for each patch, aiming to minimize both false negatives and positives through an inter-patch messaging mechanism.
In the specific context of CRC subtype classification, Lou et al. \cite{lou2022ppsnet} unveiled a parameter partial sharing network (PPsNet) that merges tumor patch detection with subtype classification, and Schirris et al. \cite{schirris2022deepsmile} combined contrastive self-supervised learning for feature extraction with a variability-aware deep multiple instance learning for classification. 
For a comprehensive analysis of recent techniques utilizing deep learning for the classification of CRC subtypes from standard H\&E stained histopathological images, we refer to the study by Kuntz et al. \cite{kuntz2021gastrointestinal}. 

Yet, until now, CNN models have predominantly targeted the classification of CRC subtypes, like MSI or MSS, implicitly suggesting a marked correlation between MSI and MSS CRC subtypes and their histopathological imaging characteristics. However, intrinsic genomic variations within these subtypes such as significant heterogeneity in SNP rates and CIMP types observed within the MSI subtype    \cite{Liu2018ComparativeAdenocarcinomas} could influence cellular morphology as expressed in their imaging phenotypes. Therefore, this study aims to determine potential correlations between genomic variants of CRC subtypes and cellular morphology as expressed by their H\&E imaging phenotype by assessing the benefits of accounting for such potential correlations in  CNN models for CRC subtype identification from H\&E images.

\section*{Materials and methods}
\label{sec:methods}



\subsection*{Data and pre-processing}
\begin{figure}[ht!]
    \centering
    %\import{./}{figures/data_split.tex}
    \begin{adjustbox}{width=\linewidth}  
\begin{tikzpicture}[font=\normalsize,thick]
% Start block
\node[draw,
    minimum width=2.5cm,
    minimum height=1cm] (block2) {Entire Cohort - n=430};
    

% Power and voltage variation
\node[draw,
    align=center,
    below=of block2,
    minimum width=3.5cm,
    minimum height=1cm
] (block3) {Pre-processed by Kather et al. - n=360};


% Conditions test
\node[draw,
    align=center,
    circle,
    below right=of block3,
    minimum width=2.5cm,
    text width=2cm,
    inner sep=0,fill=red!30] (block4) {Test - n=100, p=98,904};
    
\node[draw,
    align=center,
    circle,
    below left=of block3,
    minimum width=2.5cm,
    text width=2cm,
    inner sep=0,fill=red!30] (block5) {Train - n=260, p=93,408};
   


\node[draw=black,
    below left=of block4,
    minimum width=2.5cm,
    text width=2.5cm,
    minimum height=1cm, fill=green!30] (block6) 
    { MSI: \\ n=26, p=28,335};
    

\node[draw=black,
    below right=of block4,
    minimum width=2.5cm,
    text width=2.7cm,
    minimum height=1cm,fill=green!30] (block7) 
    { MSS: \\ n=74, p=70,569};
   

    
\node[draw=black,
    below left=of block5,
    minimum width=2.5cm,
    text width=2.5cm,
    minimum height=1cm, fill=green!30] (block8) 
    { MSI: \\ n=39, p=46,704};
    


\node[draw=black,
    below right=of block5,
    minimum width=2.5cm,
    text width=2.8cm,
    minimum height=1cm,fill=green!30] (block9)  { MSS: \\ n=221, p=46,704};


    
% Arrows
\draw[-latex] 
    (block2) edge (block3)
    (block3) edge (block4);

\draw[-latex] (block3) -- (block5)
    node[pos=0.25,fill=white,inner sep=0]{};
\draw[-latex] (block4) -| (block6)
 node[pos=0.25,fill=white,inner sep=0]{};
    
\draw[-latex] (block4) -| (block7)
    node[pos=0.25,fill=white,inner sep=0]{};
\draw[-latex] (block5) -| (block8)
 node[pos=0.25,fill=white,inner sep=0]{};
    
\draw[-latex] (block5) -| (block9)
    node[pos=0.25,fill=white,inner sep=0]{};
    




\end{tikzpicture}

\end{adjustbox}

\caption{Summary of the TCGA COAD and READ datasets application: The total cohort encompasses n=632 patients. Some patients were excluded due to technical reasons, resulting with n=430 patients. Out of this, Kather et al. \cite{Kather2019DeepCancer} pre-processed and published data for n=360 patients, segmenting them into a training and a testing set. The training set was balanced at the patch (p) level. For our research, we used stratified cross-validation folds at the patient level. The partitioning into these folds was informed by the novel sub-labels based on SNP rates and CIMP classifications. }
\label{fig:data_split}
\end{figure}

We utilized the TCGA-CRC-DX dataset \cite{crc-data} for all our experiments. This dataset comprises N=360 patients diagnosed with Colorectal Cancer (CRC-DX). The samples in the dataset are formalin-fixed paraffin-embedded (FFPE) diagnostic slides, stained with H\&E. The dataset includes DNA mutations, RNA expressions, and clinical annotations, alongside the H\&E images. The dataset was preprocessed as detailed by Kather et al. \cite{Kather2019DeepCancer}. The MSI/MSS labels were assigned as per the criteria detailed by Liu et al. \cite{Liu2018ComparativeAdenocarcinomas}, referenced in Supplementary Table 2 of Kather et al. \cite{Kather2019DeepCancer}. The genomic information including the SNP rates, CIMP types, and Copy number variation (CNV) values was provided by Liu et al. \cite{Liu2018ComparativeAdenocarcinomas}.

The distribution of patients is illustrated in Figure \ref{fig:data_split}. Initially, from a cohort of 360 patients, Kather et al. \cite{Kather2019DeepCancer} randomly selected 100 patients to form the test set. Image patches were extracted from each H\&E image following the procedure detailed in their study. To achieve a balanced training set at the patch level, MSS patches were randomly discarded. The composition of the training set is as follows: 39 MSI patients (comprising 15\% of the set), represented by 46,704 patches, and 221 MSS patients, also depicted by 46,704 patches. The test set includes 26 MSI patients (accounting for 26\% of the set) and 28,335 patches, alongside 74 MSS patients symbolized by 70,569 patches.


 



\subsection*{CNN architectures for CRC subtype classification}

\subsubsection*{Baseline model}
Drawing inspiration from Kather et al. \cite{Kather2019DeepCancer}, we developed a baseline Convolutional Neural Network (CNN) for patch-level CRC subtype classification into the MSI and MSS classes. Utilizing a transfer learning strategy, we adopted the Inception-v3 network \cite{DBLP:journals/corr/SzegedyVISW15} as our primary feature extraction model. Originally trained on the ImageNet dataset, we fine-tuned this model by retraining its last three inception blocks along with the fully connected layers on our dataset.



We averaged the classification probabilities of the patches produced by the baseline model to obtain a patient-level classification. Formally, given a classifier $F$, the output for a specific patch $x$ is the probability of being classified as MSI or MSS, denoted as $0 \leq F(x) \leq 1$. For an H\&E image $W$ with $N$ extracted patches 
$((x_1,x_2, \ldots, x_N) \in W)$, we compute the patient-level MSI probability as follows:
\begin{equation}
P_w(MSI) = \frac{\sum_{i=1}^{N}F(x_i)}{N}
\label{eq:agg}
\end{equation}
Figure \ref{fig:net_arch}(a) illustrates the architecture of the baseline model used in our research.

\begin{figure}[ht!]
\tikzstyle{circ} = [draw, circle, node distance=1cm,minimum size=1.5 cm, fill=red!30]
  \centering
  %\begin{tabular}[t]{c}
  % \input{figures/patient-agg}\\
    \scalebox{0.75}{
    \begin{tikzpicture}
    \node [input, name=input] {};
    \node [block] (inception) at (0,0) {Feature extractor};
    \node [block] (mlp) at (3.7,0) {classifier};
    \node(D) at(1,3) {Patch level};
    \node [circ, above right=of mlp] (msi) {MSI};
    \node(C) [above=0.4cm of msi]{Softmax};
    \node [circ, below right=of mlp] (mss) {MSS};
    \matrix (A) [matrix of nodes, right=2cm of msi, nodes={draw, minimum size=8mm},column sep=-\pgflinewidth]
    {    $p_1$\\$p_2$\\\vdots\\$p_N$\\};
    \node(B)[right=of A]{
        \(P_w(MSI) = \frac{\sum_{i=1}^{N}p_i(MSI)}{N}\)};
    \node(C) [above=of B]{Patient aggregation};
    \draw [->] (inception.east) -- (mlp.west);
    \draw [->] (mlp.east) -- (msi.west);
    \draw [->] (mlp.east) -- (mss.west);
    \draw [->] (msi.east) -- (A.west);
    \draw[->] (A.east) -- (B.west);
    \end{tikzpicture}
    } \\
(a)\\
  
  %\input{figures/sub_label_agg}
  \scalebox{0.75}{
  \begin{tikzpicture}
\node [input, name=input] {};
\node [block] (inception) at (0,0) {Feature extractor};
\node [block] (mlp) at (3.7,0) {classifier};
\node(D) at(1,3) {Patch level};
\node [circ, above right=of mlp] (msi1) {$MSI_1$};
\node(C) [above=0.4cm of msi]{Softmax};
\node [circ, below right=of mlp] (mss) {MSS};
\node [circ, right=0.4cm of mlp] (msi2) {$MSI_2$};
\matrix (A) [matrix of nodes, right=3cm of msi1, nodes={draw, minimum size=8mm},
    column sep=-\pgflinewidth]{
    $p_1$\\$p_2$\\\vdots\\$p_N$\\};
\node(B)[right=of A]{
    \(P_w(MSI) = \frac{\sum_{i=1}^{N}p_i(MSI)}{N}\)};
\node(C) [above=of B]{Patient aggregation};
\draw [->] (inception.east) -- (mlp.west);
\draw [->] (mlp.east) -- (msi1.west);
\draw [->] (mlp.east) -- (msi2.west);
\draw [->] (7.5,1) -- (9.2,1) node[midway,above]{max($MSI_1$,$MSI_2$)};
\draw [->] (mlp.east) -- (mss.west);
\draw[->] (A.east) -- (B.west);
\end{tikzpicture}
}
  \\ (b)
  %\end{tabular}
    \caption{ Model Architectures. (a) Baseline Model Architecture: Patches are input into the Inception-Net \cite{DBLP:journals/corr/SzegedyVISW15} for feature extraction, with the last two layers acting as fully connected classifier layers. Outputs are propagated to a softmax layer for determining probabilities. N represents the number of patient patches, while $P_i$ denotes the MSI probability for each patch. The MSI score for each patient, $P_w$, is the average of its corresponding MSI probabilities. (b) Biologically-Primed Model Architecture: Similar to the baseline model, the softmax layer outputs class probabilities at the patch level. However, the MSI probability here is calculated as the maximum value between $MSI_1$ and $MSI_2$ outputs. The calculation of $P_w$ remains the same as in the baseline model.}
  \label{fig:net_arch}
\end{figure}



\subsubsection*{Genomic variations analysis}
We delved into the possible presence of phenotypic variations within classes, theorizing that such diversity might hinder the learning and generalization proficiency of the CNN. Our exploration centered on two dominant attributes: SNPs and the CIMP. Drawing from Liu et al. findings \cite{Liu2018ComparativeAdenocarcinomas}, SNP mutations are highly frequent in MSI patients due to their deficiency in the DNA mismatch-repair mechanism. However, MSI samples exhibit significant disparities in SNP density, ranging dramatically from 10 to 17,000, with a median of 1,432. Additionally, the CIMP rate, which influences gene silencing \cite{moore2013dna}, is typically high in MSI patients. Specifically, 60\% of MSI patches are categorized as CIMP-High (CIMP-H), while the remaining 40\% are non-CIMP-H and categorized as CIMP-low and non-CIMP. This led us to speculate that such intrinsic variances could find reflection in the H\&E imaging phenotypes. To maintain a consistent benchmark, we used CNV as a control variable due to its stable nature within MSI tumors.

By charting the biological attribute frequencies from the patch results of our baseline model, our objective was to discern potential characteristic patterns for misclassified patches. We observed that such inaccurately classified patches either aligned closely with the contrasting class or spanned a diverse set of feature values. This observation paved the way for the hypothesis that CNN might have acquired a confined phenotypic spectrum for the classes. To enhance this spectrum for the CNN, we suggested segregating the classes based on these characteristic patterns.


\begin{figure}
\centering
\resizebox{.75\linewidth}{!}{
\tikzstyle{blockblue} = [rectangle, draw, fill=blue!50, text width=9em, text centered, rounded corners, minimum height=3em]
\tikzstyle{blockdarkblue} = [rectangle, draw, fill=blue!80, text=white, text width=9em, text centered, rounded corners, minimum height=3em]
\tikzstyle{blockwide} = [rectangle, draw, fill=blue!80, text=white, text width=21em, text centered, rounded corners, minimum height=3em]
\tikzstyle{line} = [draw, -latex']
\centering
    \begin{tikzpicture}[node distance = 1.5cm and 1cm, auto]

        % Place nodes
        \node [blockblue, ] (split) {DATA SPLIT};
        \node [blockblue, left of=split, xshift=-4cm] (data) {TCGA-CRC DATA\\(N=360)};

        \node [blockblue, right of=split, xshift=4cm] (baseline) {BASELINE MODE};
        
        \node [blockdarkblue, below of=split] (feature) {Molecular feature analysis};
        \node [blockdarkblue, below of=feature] (class) {BP class definitions};
        
        \node [blockdarkblue, below left of=class, node distance=3cm, xshift=-2.5cm] (bp_cimp) {BP-CNN$_\text{CIMP}$};
        \node [blockdarkblue, below of=class, node distance=3cm, yshift=1cm] (bp_snp) {BP-CNN$_\text{SNP}$};
        \node [blockdarkblue, below right of=class, node distance=3cm, xshift=2.5cm] (bp_cnv) {BP-CNN$_\text{CNV}$};
        
        \node [blockdarkblue, 
            below of=class, 
            node distance=5.5cm, 
            xshift=-2cm
        ] (bp_combined) {BP-CNN$_\text{Combined}$};

        \node [blockwide, below of=bp_combined, node distance=2cm, yshift=-4cm,
            fit={(bp_cimp) (bp_cnv)}] (evaluation) {Evaluation};
        

        
        % Draw edges
        % \path [line] (data) -- (feature);
        % \path [line] (split) -- (feature);
        \path [line] (baseline) -- ++(3cm,0cm)  |- (evaluation);
        \path [line] (feature) -- (class);
        \path [line] (class) -- (bp_cimp);
        \path [line] (class) -- (bp_snp);
        \path [line] (class) -- (bp_cnv);
        \path [line] (bp_cimp) -- (bp_combined);
        \path [line] (bp_snp) -- (bp_combined);
        % \path [line] (bp_cnv) -- (bp_combined);
        \path [line] (bp_cimp) -- ++(0cm,-5.2cm) (evaluation) ;
        \path [line] (bp_cnv) |- ++(0cm,-5.2cm) (evaluation);
        \path [line] (bp_snp) -- (evaluation);
        \path [line] (bp_combined) |- ++(0cm,-1.8cm) (evaluation);  
                % Draw top rectangle
        \node [draw, fit=(data)(split)(baseline)](top) {};
        \path [line] (top) -- (feature);

    \end{tikzpicture}}






    \caption{Experimental flow for our exploration of the interplay between CRC subtypes genomic variants and cellular morphology. The TCGA-CRC dataset, pre-processed by Kather et al. \cite{Kather2019DeepCancer} (N=360) is split into different sets for analysis. A baseline model is trained, and based on its results, a molecular feature analysis is performed. Based on the analysis we choose to define our data classes based on the ranges and categories of SNP, CIMP and CNV (the BP class definitions step). After the definition, we divide the classes into five stratified folds. Next, three models are trained: BP-CNN\(_\text{CIMP}\), BP-CNN\(_\text{SNP}\), and BP-CNN\(_\text{CNV}\) to evaluate the interplay between genomic variations and cellular morphology. The BP-CNN\(_\text{CIMP}\), BP-CNN\(_\text{SNP}\), and BP-CNN\(_\text{CNV}\) models classify the data based on CIMP, SNP, and CNV features, respectively. Based on their results, BP-CNN\(_\text{CIMP}\) and BP-CNN\(_\text{SNP}\) are further combined into BP-CNN\(_\text{Combined}\) to incorporate the entire set of genomic variations identified as influencing cellular morphology.}
    \label{fig:enter-label}
\end{figure}



\subsubsection*{Biologically-primed models}
Our biologically-primed classification models were developed in the following manner. Instead of a binary classification layer as used in the baseline model, we accounted for potential correlations between genomic variants of CRC subtypes and cellular morphology as expressed by their H\&E imaging phenotype by replacing the binary classification layer with a three-class classification layer. This layer identifies one class for MSS and the other two classes for distinct subclasses within the MSI group, based on specific genomic variations. The subclassification generation process is detailed in Alg.~\ref{alg:snp}. Importantly, while molecular subtype details are utilized during training, the inference step remains largely similar to the baseline model. The only difference is the class count. For inference, solely the H\&E images are needed, categorizing them into three sets: two MSI subclasses based on the target genomic variation, and MSS. For patient-level classification, we aggregate patch probabilities, considering the higher probability between the MSI subclasses as the MSI probability. Figure \ref{fig:net_arch}(b) presents our BP-CNN model.

\begin{algorithm}[t]
%\RestyleAlgo{ruled}
 \TitleOfAlgo{Decision of sub-label}
%\SetAlgoRefName{Sub label decision}
\KwIn{$y_1, \ldots, y_n, s_1, \ldots, s_n$,threshold}
\KwOut{$y'$, new labels}
\For{$i\leftarrow 1$ \KwTo $n$}{
   \If{$y_i == MSI$}{
        \eIf{$s_i > threshold$}{
            $y'_i \gets MSI_2$\;
        }{
            $y'_i \gets MSI_1$\;
        }
   }
}
\caption{Procedure for Generating MSI Sub-class Labels. In this process, $y_i$ represents the original labels provided by the database. $s_i$ refers to the selected feature rates for each patient, as provided by the database. $y'_i$ denotes the newly inferred labels, which are determined based on the feature threshold. }
\label{alg:snp}
\end{algorithm}




 

We engineered three distinct biologically-primed models for our study. The first, BP-CNN\textsubscript{SNP}, partitions MSI patients into two subgroups according to their SNP rate. A range of SNP thresholds from 800 to 1500 were tested on the first fold of the training data to establish an optimal split, and the threshold yielding the highest AUROC on the first training fold's validation dataset was selected. Our second model, BP-CNN\textsubscript{CIMP}, bifurcates the MSI group into CIMP-H and non-CIMP-H subcategories.
These subcategories were chosen based on an analysis of patches that were misclassified. 
Given the low prevalence of CIMP-H patches within the MSS class (5\% in the training set and 1\% in the test set), we excluded MSS patches exhibiting CIMP-H from the training set. This decision was made with the expectation that it would improve the CNN's ability to recognize the typical MSS phenotype.
The BP-CNN\textsubscript{CIMP} model classifies the patches into three classes: MSS, MSI-CIMP-H, and MSI-NON-CIMP-H.

To confirm that any improvement in classification accuracy was not merely a product of random division, we also implemented a third model, BP-CNN\textsubscript{CNV}. This model segments the MSI group based on each patient's CNV rate, determined through a qualitative evaluation of the CNV distribution.

Lastly, building upon the performance of the individual BP-CNN models exploiting single genomic variation (BP-CNN\textsubscript{SNP} and BP-CNN\textsubscript{CIMP}), we assembled a combined model that leverages the uncorrelated improvements offered by BP-CNN\textsubscript{SNP} and BP-CNN\textsubscript{CIMP}. This structure merges the results of the BP-CNN\textsubscript{SNP} and BP-CNN\textsubscript{CIMP} through a multi-layer perceptron model (BP-CNN\textsubscript{combined}).



\begin{figure}[ht!]
    \centering
        \includegraphics[width=0.9\textwidth]{images/combined_pic.pdf}
    \caption{Our BP-CNN\textsubscript{Combined} model. Models A and B represent biologically-primed models informed by two distinct genomic variations. The network outputs from trained and fixed models A and B are concatenated, fed into a linear layer, and then propagated to a softmax layer to yield probabilities. `N' represents the number of patches for each patient, and $P_i$ indicates the corresponding MSI probabilities for these patches. The MSI score for each patient denoted as $P_w$, is derived from averaging its respective MSI probabilities.}.
    
   
    \label{fig:combined}
\end{figure}

Specifically, the class probabilities were extracted using BP-CNN\textsubscript{SNP} and BP-CNN\textsubscript{CIMP}. These were used as input to train a multi-layer perceptron (MLP) with a six-dimensional input vector (comprising three class probabilities from each model) for binary classification into MSI or MSS categories. The architecture of this combined model is depicted in Figure~\ref{fig:combined}.

The MLP carries out patch-level classification, while patient-level aggregation is achieved by calculating the average of the respective patch probabilities as described above (Eq.~\ref{eq:agg}).



 \subsubsection*{Training details}
We trained all models using the cross-entropy loss function, employed the Adam optimizer with an initial learning rate of $10^{-4}$, and conducted training over 15 epochs using batches of 64 images. We saved the best model based on validation AUROC. We divided the cross-validation folds using Scikit-learn's stratified folds. To achieve balance at the patch level, we used a random weighted sampler. We implemented the code in PyTorch 1.9 and executed it on Nvidia A100 GPUs using a version 21.04 container image.

\subsection*{Statistical analysis}
We utilized a 5-fold cross-validation experimental setup on the TCGA-CRC-DX training cohort for model development. Given that the distribution of genomic variations is neither consistent nor identical for each type of variation (be it SNP or CIMP), we adopted a stratified k-fold cross-validation method. This ensures a consistent distribution of the CRC subtypes and their internal genomic variations across each fold. Consequently, the composition of the folds varies based on the model under scrutiny. To ensure an equitable comparison, for each experiment (namely, comparing SNP with baseline, CIMP with baseline, and CNV with baseline), we retrained the baseline model using the identical dataset that trained the model of focus.
The different models were then tested on the TCGA-CRC-DX test cohort. The performance of the various models in distinguishing between MSI and MSS patients was conducted by utilizing the AUROC metric, along with the average precision (AP) represented as the area beneath the Precision-Recall (PR) Curve and F1-score. We calculated the AUC for each model out of the 5 models developed using the 5-fold cross-validation approach. To determine significant differences in the performance of these models, we applied the Student's paired t-test, setting p$<$0.05 as the level of significance over the different models. 



\section*{Results}
\label{sec:results}
\subsection*{Baseline model}
\begin{figure}[ht!]
    \centering
    \begin{tabular}[t]{cc}
        \includegraphics[width=0.45\textwidth]{images/roc_test_base.png} &
        \includegraphics[width=0.45\textwidth]{images/ap_test_vs_base.png}\\
        (a) & (b)\\
    \end{tabular}
    \caption{Baseline model results for per-patient classification of the test set validated over 5-folds. Average and 95\% CI curves: (a) ROC curve, (b) PR curve.}
    \label{fig:roc_test_baseline}
\end{figure}

Figure \ref{fig:roc_test_baseline} presents our baseline model. It achieved an average AUROC of 0.8 (95\% CI, 0.78-0.81) and AP of 0.66 (95\% CI, 0.61-0.7) on the 100-patient test set.  This outcome is comparable to that reported by Kather et al. \cite{Kather2019DeepCancer}, who found a median bootstrapped AUROC of 0.77 (95\% CI: 0.62â€“0.87). The slight difference between our model and Kather et al. \cite{Kather2019DeepCancer} results could be attributed to several variations between our study and Kather's, including the utilization of a Python implementation instead of Matlab\textsuperscript{\textregistered}, patient-level aggregation based on MSI probabilities as proposed by Echle et al \cite{Echle2020} rather than the predicted label, and the employment of the Inception v3 model \cite{szegedy2015going} as opposed to Resnet18 \cite{he2016deep}.

\begin{figure}[ht!]
 \centering
     \begin{tabular}[t]{ccc}
  \includegraphics[width=0.3\linewidth]{images/boxplot_SNP.png} &
  \includegraphics[width=0.3\linewidth]{images/cimp_diagram.png} &
   \includegraphics[width=0.3\textwidth]{images/boxplot_CNV.png} \\
   (a) & (b) & (c)
  
    \end{tabular}
    \caption{The distribution of patient-level molecular features in the test set, categorized based on the patch-level classification by the baseline model. The x-axis indicates the classification of patches, while the y-axis denotes the molecular level determined at the patient level. Here, \textbf{MSI} serves as the \textbf{positive} class and \textbf{MSS} as the \textbf{negative} class:
(a) A boxplot illustrating SNP rates for each patch. The y-axis quantifies the cumulative count of SNPs throughout the DNA sample.
(b) A bar plot depicting the methylation types for each patch. The y-axis showcases the distribution of various methylation types across classification categories.
(c) A boxplot highlighting the CNV rates for patches, with the y-axis measuring the proportion of the DNA sample that manifests CNV. }
 \label{fig:feature_boxplot}
\end{figure}

\subsection*{Genomic variations analysis}
The number of SNPs and the CIMP category are extracted from a patient's DNA sample in the TCGA. The range of SNPs among patients varied from 10 to 17000.

Figure~\ref{fig:feature_boxplot} presents three molecular features of our CRC patients at the patient level, plotted against the patch classification from our baseline model. In this figure, the MSI class is denoted as the positive class, and the MSS class is denoted as the negative class.
The boxplot of the SNP rates concerning the test set's baseline classification results is displayed in Figure~\ref{fig:feature_boxplot}a. The MSS class consistently shows a low SNP rate, regardless of the model classification outcome. This aligns with prior research indicating that MSS patients usually lack a deficiency in the DNA mismatch repair mechanism \cite{Liu2018ComparativeAdenocarcinomas}. Conversely, for the MSI class, there's a noticeable difference in the SNP distribution between true-positive (TP) and false-negative (FN) classifications. The TP group has a marginally higher median with limited variance, whereas the FN group demonstrates a wider range of variation.
The threshold of the optimal split for our BP-CNN\textsubscript{SNP} model was found to be 1200.
Figure~\ref{fig:feature_boxplot}b showcases the distribution of methylation types based on the baseline classification of the test set. Highly methylated (CIMP-H) samples are rare in MSS, present in only 1\% of the MSS patches, but are prevalent in MSI, accounting for 59\% of the MSI patches. Notably, among the MSI patches that are non-CIMP-H, a substantial portion (76\%) was incorrectly classified as MSS (negative class).
Therefore we chose to distinguish 2 MSI sub-categories: CIMP-H and non-CIMP-H. 
Figure~\ref{fig:feature_boxplot}c presents the CNV distribution in patches as classified by the baseline model. MSS patches display elevated CNV rates with notable variability, in contrast to the MSI patches which exhibit consistently low CNV rates with slight deviations. We chose a threshold of 0.005, determined through a qualitative evaluation of the CNV
distribution.



\subsection*{Biologically-primed models}


The BP-CNN\textsubscript{SNP} model outperformed the baseline model, achieving an AUROC of 0.824$\pm$0.02 (95\% CI 0.79-0.86) compared to 0.761$\pm$0.04 (95\% CI 0.68-0.8) on a test set of 100 patients across 5 stratified folds sessions. This increase was statistically significant (paired t-test, p$<$0.05). The AP for the model was 0.652$\pm$0.06 (95\% CI 0.58-0.72), whereas the baseline's was 0.58$\pm$0.08 (95\% CI 0.46-0.67). The F1 scores for the model and baseline were 0.65$\pm$0.04 and 0.61$\pm$0.05, respectively. However, differences in AP and F1 scores did not reach the statistical significance level. Figure~\ref{fig:roc_test_vs}a presents the ROC and PR curves (average and the 95\% CI) for the test set across different 5 stratified fold sessions.  Figure~\ref{fig:roc_boxplot} depicts the distribution of the AUROC, AP, and F1 on the test set across the different training sessions. 

 \begin{figure}[ht!]
    \centering
    \begin{tabular}[t]{ccc}
        \includegraphics[width=0.3\textwidth]{images/roc_test_vs_snp.png} &
        \includegraphics[width=0.3\textwidth]{images/roc_test_vs_cimp.png} &
        \includegraphics[width=0.3\textwidth]{images/roc_test_vs_cnv.png} \\
         %(a) & (b) & (c)\\
         \includegraphics[width=0.3\textwidth]{images/ap_test_vs_snp.png} &
         \includegraphics[width=0.3\textwidth]{images/ap_test_vs_cimp.png} &
        \includegraphics[width=0.3\textwidth]{images/ap_test_vs_cnv.png} \\
         (a)  & (b) & (c)
       
    \end{tabular}
    \caption{Average and 95\% CI ROC and PR curves for per-patient classification using: (a) the BP-CNN\textsubscript{SNP} model compared to its corresponding baseline model, (b) the BP-CNN\textsubscript{CIMP} model compared to its corresponding baseline model, and (c) the BP-CNN\textsubscript{CNV} model compared to its corresponding baseline model.
    }
    \label{fig:roc_test_vs}
\end{figure}

  \begin{figure}[ht!]
    \centering
    \begin{tabular}[t]{ccc}
        \includegraphics[width=0.3\textwidth]{images/boxplot_auc.png} &
           \includegraphics[width=0.3\textwidth]{images/boxplot_ap.png} &
        \includegraphics[width=0.3\textwidth]{images/boxplot_f1.png} \\
        (a) & (b) & (c)
    \end{tabular}
    \caption{Box-plot visualization of (a) AUROC results, (b) AP results and (c) F1-scores for per-patient classification, comparing the biologically primed models with their corresponding baseline model on the test set over different training sessions. It's worth noting that due to the stratified k-fold approach used to partition the training data across sessions, the performance of the baseline model can vary between experiments.  } 
    \label{fig:roc_boxplot}
\end{figure}

 \begin{figure}[ht!]
    \centering
    \begin{tabular}[t]{cc}
    \includegraphics[width=0.45\textwidth]{images/cm_Baseline_snp.png} &
    \includegraphics[width=0.45\textwidth]{images/cm_Baseline_cimp.png} \\
     (a)  & (b)\\
        \includegraphics[width=0.45\textwidth]{images/cm_SNP.png} &
        \includegraphics[width=0.45\textwidth]{images/cm_CIMP.png}\\
        (c) & (d) \\         
    \end{tabular}
    \caption{Confusion matrices of the patient-level predictions for the different models. Each matrix represents an average from the test set over various training sessions. The threshold for MSI prediction is determined by the best F1 score over the folds. (a) Baseline model corresponding to the BP-CNN\textsubscript{SNP} folds. (b) Baseline model corresponding to the to BP-CNN\textsubscript{CIMP} folds. (c) BP-CNN\textsubscript{SNP} model. (d) BP-CNN\textsubscript{CIMP} model.   }
    \label{fig:confusion}
\end{figure}



Similarly, the BP-CNN\textsubscript{CIMP} model achieved a significantly higher AUROC than its corresponding baseline model on the 100 patient test set over the five stratified fold training sessions (0.834$\pm$0.01 (95\% CI 0.81-0.85) vs. 0.787$\pm$0.03 (95\% CI 0.72-0.81), paired t-test, p$<$0.05), a higher AP score (0.687$\pm$0.02 (95\% CI 0.65-0.72) vs. 0.64$\pm$0.05 (95\% CI 0.55-0.71)) and a higher F1 score compared to the baseline model (0.71$\pm$0.03 vs. 0.63$\pm$0.06). Yet, the difference did not reach the pre-defined significant level. Figure~\ref{fig:roc_test_vs}b showcases the ROC and PR curves (average and 95\% CI) for the test set over the various training sessions. Figure~\ref{fig:roc_boxplot} depicts the distribution of the AUROC, AP and F1 on the test set across different training sessions.

Conversely, the BP-CNN\textsubscript{CNV} model lagged behind its corresponding baseline model on the 100-patient test set over five stratified fold training sessions (AUROC: 0.793$\pm$0.03 (95\% CI 0.75-0.85) vs. 0.801$\pm$0.02 (95\% CI 0.75-0.83), AP: 0.63$\pm$0.09 (95\% CI 0.51-0.76) vs. 0.64$\pm$0.07 (95\% CI 0.51-0.72)). The BP-CNN\textsubscript{CNV} model's F1 score was slightly higher than its baseline model's (0.64$\pm$0.03 vs. 0.62$\pm$0.04). Figure~\ref{fig:roc_test_vs}c presents the ROC and PR curves (average and 95\% CI) for the test set over various training sessions and Figure~\ref{fig:roc_boxplot} presents the AUROC, AP, and F1 distribution on the test set across these sessions. All the differences were not statistically significant. 


Figure~\ref{fig:confusion} presents the confusion matrices for per-patient classification on the test set, averaged over the training sessions, for the BP-CNN\textsubscript{SNP}, the BP-CNN\textsubscript{CIMP} and their corresponding baseline models. The BP-CNN\textsubscript{SNP} model was more proficient at classifying MSI patients, while the BP-CNN\textsubscript{CIMP} model excelled at classifying MSS patients.


\subsection*{BP-CNN\textsubscript{Combined} model}
The BP-CNN\textsubscript{combined} outperformed the baseline model significantly on the 100 patient test set over five stratified fold training sessions, achieving an AUROC of 0.847$\pm$0.01 (95\% CI 0.82-0.87) versus 0.787$\pm$0.03 (95\% CI 0.72-0.81), as shown by a paired t-test with p$<$0.01. The AP score was 0.68$\pm$0.02 (95\% CI 0.63-0.71) versus vs. 0.64$\pm$0.05 (95\% CI 0.55-0.71). The average F1 score on the test set, across the different training sessions for the BP-CNN\textsubscript{combined}, was 0.71$\pm$0.02, compared to 0.63$\pm$0.06 for the baseline model.  Yet, the difference of the AP nor the F1 did not reach the pre-defined significance level. Figure \ref{fig:res_combined} displays the ROC and PR curves and the boxplots of the AUROC, AP and F1 scores of the test set over the various training sessions.

Figure \ref{fig:histograms} presents the histograms of the patch-level probabilities of selected patients, misclassified by the baseline model but accurately classified by our proposed models. The patches' distributions produced by our proposed models were more aligned with the patient-level reference classification compared to the distributions computed by the baseline models.

\begin{figure}[ht!]
    \centering
    \begin{tabular}[t]{cc}
        \includegraphics[width=0.45\textwidth]{images/roc_test_vs_comb.png} &
        \includegraphics[width=0.45\textwidth]{images/ap_test_vs_comb.png} \\
        (a) & (b)\\
        \end{tabular}
        \begin{tabular}{ccc}
        \includegraphics[width=0.3\textwidth]{images/boxplot_auc_comb.png} &
        \includegraphics[width=0.3\textwidth]{images/boxplot_ap_comb.png} &
         \includegraphics[width=0.3\textwidth]{images/boxplot_f1_comb.png} \\
        (c) & (d) & (e)\\   
        \end{tabular}

    \caption{Average and 95\% CI ROC and PR curves for per-patient classification using the BP-CNN\textsubscript{Combined} model compared to the baseline model. (a) ROC curve. (b) PR curve. (c), (d) and (e) are the 5-fold results comparison of the AUROC, AP, and F1 results respectively.}
    \label{fig:res_combined}
\end{figure}

\begin{figure}[t]
    \centering
    \begin{tabular}[t]{ccc}
        \raisebox{1.75cm}{(a)} &
        \includegraphics[width=0.4\textwidth]{images/hist_TCGA-AG-3892_snp.png} &
        \includegraphics[width=0.4\textwidth]{images/hist_TCGA-D5-6540_snp.png}\\ 
        \raisebox{1.75cm}{(b)} &
        \includegraphics[width=0.4\textwidth]{images/hist_TCGA-AA-3968_cimp.png} &
        \includegraphics[width=0.4\textwidth]{images/hist_TCGA-AA-3877_cimp.png} \\
        \raisebox{1.75cm}{(c)} &
        \includegraphics[width=0.4\textwidth]{images/hist_TCGA-A6-2685_comb.png} &
        \includegraphics[width=0.4\textwidth]{images/hist_TCGA-AA-3833_comb.png} \\
    \end{tabular}
    \caption{A histogram showcasing the MSI scores for patches from selected patients, misclassified by the baseline model but accurately classified by our proposed models. The x-axis represents the patch MSI probabilities given by the CNN, while the y-axis denotes the count of patches, normalized to the total number of patches for each patient. The comparisons are between (a) the Baseline and BP-CNN\textsubscript{SNP} model, (b) the Baseline and BP-CNN\textsubscript{CIMP} model, and (c) the Baseline and BP-CNN\textsubscript{Combined} model.}
    \label{fig:histograms}
\end{figure}


Figure~\ref{fig:classification_examples} illustrates patches from patients that were misclassified by the baseline model but accurately classified by our BP-CNN\textsubscript{Combined} model (top row) and those misclassified by both models (bottom row). Patches (a, b), correctly identified as MSI by our BP-CNN\textsubscript{Combined} model but mislabeled as MSS by the baseline, display pronounced nuclear pleomorphism and prominent nucleoliâ€”hallmarks of MSI. This suggests that the BP-CNN\textsubscript{Combined} model is more adept at detecting these subtle yet crucial variations than the baseline model. Conversely, patches (c, d) that were correctly identified as MSS by our BP-CNN\textsubscript{Combined} model but misclassified as MSI by the baseline likely exhibit characteristics such as poor gland formation and high intra-tumoral lymphocytes, which are typically indicative of MSI, demonstrating that our BP-CNN\textsubscript{Combined} model can correctly interpret these complex features, where the baseline model fails.

The patches misclassified by both models (bottom row) likely exhibit mixed features or subtle signs that pose classification challenges, including moderate gland formation with irregularities and characteristics that straddle the line between MSI and MSS, such as moderate nuclear pleomorphism and visible but subdued nucleoli. These ambiguous features contribute to the confusion in model classifications.



\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{images/figure.PNG}
    \caption{Patches of patients that were miss-classified by our models. Top row: patches of patients that were misclassified by the Baseline model and correctly classified by the BP-CNN\textsubscript{Combined} model. (a) TCGA-AA-3833, Baseline: MSS, BP-CNN\textsubscript{Combined}: MSI, reference: MSI (SNP$<$1200), (b) TCGA-AY-6197, Baseline: MSS, BP-CNN\textsubscript{Combined}: MSI, reference: MSI (CIMP-low), (c) TCGA-A6-2685,  Baseline: MSI, BP-CNN\textsubscript{Combined}: MSS, reference: MSS, (d) TCGA-NH-A6GC, Baseline: MSI, BP-CNN\textsubscript{Combined}: MSS, reference: MSS. Bottom row: patches of patients that were misclassified by both the Baseline model and the BP-CNN\textsubscript{Combined} model. (e) TCGA-A6-2686,  Baseline: MSS, BP-CNN\textsubscript{Combined}: MSS, reference: MSI, (f) TCGA-AG-A02N, Baseline: MSS, BP-CNN\textsubscript{Combined}: MSS, reference: MSI, (g) TCGA-AG-3881, Baseline: MSI, BP-CNN\textsubscript{Combined}: MSI, reference: MSS, (h) TCGA-DC-6682, Baseline: MSI, BP-CNN\textsubscript{Combined}: MSI, reference: MSS.  }

   
    \label{fig:classification_examples}
\end{figure}



\section*{Discussion}
Differentiating between CRC subtypes using H\&E stained histopathological image analysis is paramount for the cost-effective, widespread implementation of personalized treatment plans for patients \cite{Hu2021PersonalizedStand}. Recently, the employment of CNN-based techniques has emerged as an automated method for classifying H\&E stained histopathological images of CRC \cite{Kather2019DeepCancer,kuntz2021gastrointestinal,wagner2023fully,altini2023role,lou2022ppsnet,liang2023interpretable,Bilal2021DevelopmentStudy}. Thus far, CNN models have mainly concentrated on classifying CRC subtypes like MSI or MSS, presuming a robust correlation between MSI and MSS CRC subtypes and their histopathological imaging characteristics. However, genomic heterogeneity within subtypes could correlate with differences in cellular morphology as expressed in the H\&E imaging phenotypes.

The present study reveals the correlation between the SNP and CIMP genomic variants of CRC subtypes and their cellular morphology as expressed by their H\&E imaging phenotype. Our experimental results show a significant enhancement in the AUC results for differentiating CRC into MSI and MSS subtypes when utilizing our BP-CNN approach along with CNNs compared to baseline models. This enhancement suggests that the SNP and CIMP genomic variations influence the tumor cellular morphology as expressed in the H\&E stained histopathological imaging phenotype, whereas the CNV does not. A fascinating observation is that the inclusion of the SNP molecular feature in the CNN bolsters the classification of MSI patients, while the addition of the CIMP molecular feature improves the classification of MSS patients. This suggests that the integration of both SNP and CIMP into a unified model could lead to superior overall accuracy in classifying CRC subtypes. 

However, the direct inclusion of multiple genomic variations in the BP-CNN approach can be challenging due to the overlap of patients across classes. We therefore merged the classification outcomes of the SNP and CIMP-based models using a feed-forward multi-layer perceptron model. Our experiments corroborate that the combined model excels over the baseline model in the accurate classification of CRC subtypes. It's worth mentioning that although there are various methods to aggregate the results from the SNP and CIMP-based models, our primary concern was to investigate the link between genomic variations and the imaging phenotype. Therefore, the precise technique of model integration is secondary to our main objective, rather than aiming for the optimal CRC subtype classification.



It is also vital to emphasize that although our training phase incorporates molecular subtype information, the inference process depends solely on H\&E images, without the need for any additional data. Hence, our methodology is in alignment with prior methods \cite{Kather2019DeepCancer,Bilal2021DevelopmentStudy} when it comes to predicting MSI/MSS status from H\&E images alone.





This study is subject to several limitations. Firstly, we relied exclusively on the CRC TCGA dataset as pre-processed by Kather et al. \cite{Kather2019DeepCancer}. Consequently, the extrapolation of these findings to other datasets should be approached with caution. Additionally, the use of different pre-processing methodologies could also impact the study outcomes.

A further limitation is our examination of a limited number of molecular features. Drawing inspiration from Liu et al. work \cite{Liu2018ComparativeAdenocarcinomas}, we focused on two specific features, SNP and CIMP, as potential factors influencing the appearance of H\&E stained histopathological images of CRC. CNV was also included as a control feature. It would be advantageous to explore the impact of additional molecular features on the phenotype of H\&E stained histopathological images of CRC.

Moreover, factors such as age, gender, and tumor location might also influence the appearance of H\&E images. Integrating these aspects could enhance the ability of CNN-based models to effectively classify CRC subtypes using these images.



Finally, we showcased the interaction between genomic variations in CRC subtypes and the H\&E imaging phenotype by gauging the enhancement in CRC subtype classification accuracy using rudimentary CNNs \cite{Kather2019DeepCancer}. However, these CNN methods aggregate patch-level classifications rather than employing advanced MIL techniques \cite{Bilal2021DevelopmentStudy,zhang2022dtfd,lin2023interventional,liang2023interpretable,lou2022ppsnet,schirris2022deepsmile}. While using a simple CNN approach increases the robustness of our findings, an intriguing avenue for future research would be to investigate the added-value of leveraging this interplay in improving MIL models for CRC subtype classification.


\section*{Conclusion}
Our study highlighted the influence of SNP and CIMP variations on the tumor cellular morphology as expressed by their H\&E images by evaluating the classification accuracy of Biologically Primed Convolutional Neural Networks (BP-CNN) that considers the potential impact of genomic variations on the appearance of H\&E stained histopathological images of colorectal cancer (CRC) in comparison to baseline CNN classification models. The results and approach of this study could be invaluable to researchers investigating the connection between genetic mutations and image characteristics in various types of cancer. Furthermore, these findings can be leveraged by engineers striving to enhance the accuracy of CNN-based methods for classifying cancer subtypes using H\&E stained histopathological images.

\section*{Acknowledgments}
M.F. acknowledges funding from the Israel Innovation Authority (grant number 73249). Y.E.M. acknowledges funding from the Israel Science Foundation (ISF, grant number 2794/21) and from the Israel Cancer Association (ICA, grant number 20210132). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.


%\nolinenumbers


\begin{thebibliography}{10}

\bibitem{sung2021global}
Sung H, Ferlay J, Siegel RL, Laversanne M, Soerjomataram I, Jemal A, et~al.
\newblock Global cancer statistics 2020: GLOBOCAN estimates of incidence and
  mortality worldwide for 36 cancers in 185 countries.
\newblock CA: a cancer journal for clinicians. 2021;71(3):209--249.

\bibitem{Hu2021PersonalizedStand}
Hu LF, Lan HR, Huang D, Li XM, Jin KT.
\newblock Personalized immunotherapy in colorectal cancers: where do we stand?
\newblock Frontiers in oncology. 2021;11:769305.

\bibitem{le2017mismatch}
Le DT, Durham JN, Smith KN, Wang H, Bartlett BR, Aulakh LK, et~al.
\newblock Mismatch repair deficiency predicts response of solid tumors to PD-1
  blockade.
\newblock Science. 2017;357(6349):409--413.

\bibitem{Baudrin2018-tq}
Baudrin LG, Deleuze JF, How-Kit A.
\newblock Molecular and computational methods for the detection of
  microsatellite instability in cancer.
\newblock Frontiers in oncology. 2018;8:621.

\bibitem{he2016deep}
He K, Zhang X, Ren S, Sun J.
\newblock Deep residual learning for image recognition.
\newblock In: Proceedings of the IEEE conference on computer vision and pattern
  recognition; 2016. p. 770--778.

\bibitem{simonyan2014very}
Simonyan K, Zisserman A.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In: 3rd International Conference on Learning Representations (ICLR
  2015). Computational and Biological Learning Society; 2015.

\bibitem{Kather2019DeepCancer}
Kather JN, Pearson AT, Halama N, J{\"a}ger D, Krause J, Loosen SH, et~al.
\newblock Deep learning can predict microsatellite instability directly from
  histology in gastrointestinal cancer.
\newblock Nature medicine. 2019;25(7):1054--1056.

\bibitem{kuntz2021gastrointestinal}
Kuntz S, Krieghoff-Henning E, Kather JN, Jutzi T, H{\"o}hn J, Kiehl L, et~al.
\newblock Gastrointestinal cancer classification and prognostication from
  histology using deep learning: Systematic review.
\newblock European Journal of Cancer. 2021;155:200--215.

\bibitem{wagner2023fully}
Wagner SJ, Reisenb{\"u}chler D, West NP, Niehues JM, Zhu J, Foersch S, et~al.
\newblock Transformer-based biomarker prediction from colorectal cancer
  histology: A large-scale multicentric study.
\newblock Cancer Cell. 2023;41(9):1650--1661.

\bibitem{altini2023role}
Altini N, Marvulli TM, Zito FA, Caputo M, Tommasi S, Azzariti A, et~al.
\newblock The role of unpaired image-to-image translation for stain color
  normalization in colorectal cancer histology classification.
\newblock Computer Methods and Programs in Biomedicine. 2023;234:107511.

\bibitem{lou2022ppsnet}
Lou J, Xu J, Zhang Y, Sun Y, Fang A, Liu J, et~al.
\newblock PPsNet: An improved deep learning model for microsatellite
  instability high prediction in colorectal cancer from whole slide images.
\newblock Computer Methods and Programs in Biomedicine. 2022;225:107095.

\bibitem{liang2023interpretable}
Liang M, Chen Q, Li B, Wang L, Wang Y, Zhang Y, et~al.
\newblock Interpretable classification of pathology whole-slide images using
  attention based context-aware graph convolutional neural network.
\newblock Computer Methods and Programs in Biomedicine. 2023;229:107268.

\bibitem{Bilal2021DevelopmentStudy}
Bilal M, Raza SEA, Azam A, Graham S, Ilyas M, Cree IA, et~al.
\newblock Development and validation of a weakly supervised deep learning
  framework to predict the status of molecular pathways and key mutations in
  colorectal cancer from routine histology images: a retrospective study.
\newblock The Lancet Digital Health. 2021;3(12):e763--e772.

\bibitem{Zheng2020}
Zheng H, Momeni A, Cedoz PL, Vogel H, Gevaert O.
\newblock Whole slide images reflect DNA methylation patterns of human tumors.
\newblock NPJ genomic medicine. 2020;5(1):11.

\bibitem{Zhang2017}
Zhang L, Xie WJ, Liu S, Meng L, Gu C, Gao YQ.
\newblock DNA methylation landscape reflects the spatial organization of
  chromatin in different cells.
\newblock Biophysical journal. 2017;113(7):1395--1404.

\bibitem{Lokk2014}
Lokk K, Modhukur V, Rajashekar B, M{\"a}rtens K, M{\"a}gi R, Kolde R, et~al.
\newblock DNA methylome profiling of human tissues identifies global and
  tissue-specific methylation patterns.
\newblock Genome biology. 2014;15:1--14.

\bibitem{Liu2018ComparativeAdenocarcinomas}
Liu Y, Sethi NS, Hinoue T, Schneider BG, Cherniack AD, Sanchez-Vega F, et~al.
\newblock Comparative molecular analysis of gastrointestinal adenocarcinomas.
\newblock Cancer cell. 2018;33(4):721--735.

\bibitem{crc-data}
Kather JN. {Histological image tiles for TCGA-CRC-DX, color- normalized, sorted
  by MSI status, train/test split}; 2020.
\newblock Available from: \url{https://doi.org/10.5281/zenodo.3832231}.

\bibitem{Echle2020}
Echle A, Grabsch HI, Quirke P, van~den Brandt PA, West NP, Hutchins GG, et~al.
\newblock Clinical-grade detection of microsatellite instability in colorectal
  tumors by deep learning.
\newblock Gastroenterology. 2020;159(4):1406--1416.

\bibitem{zhang2022dtfd}
Zhang H, Meng Y, Zhao Y, Qiao Y, Yang X, Coupland SE, et~al.
\newblock DTFD-MIL: Double-tier feature distillation multiple instance learning
  for histopathology whole slide image classification.
\newblock In: Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition; 2022. p. 18802--18812.

\bibitem{lin2023interventional}
Lin T, Yu Z, Hu H, Xu Y, Chen CW.
\newblock Interventional bag multi-instance learning on whole-slide
  pathological images.
\newblock In: Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition; 2023. p. 19830--19839.

\bibitem{schirris2022deepsmile}
Schirris Y, Gavves E, Nederlof I, Horlings HM, Teuwen J.
\newblock DeepSMILE: contrastive self-supervised pre-training benefits MSI and
  HRD classification directly from H\&E whole-slide images in colorectal and
  breast cancer.
\newblock Medical Image Analysis. 2022;79:102464.

\bibitem{DBLP:journals/corr/SzegedyVISW15}
Szegedy C, Vanhoucke V, Ioffe S, Shlens J, Wojna Z.
\newblock Rethinking the inception architecture for computer vision.
\newblock In: Proceedings of the IEEE conference on computer vision and pattern
  recognition; 2016. p. 2818--2826.

\bibitem{moore2013dna}
Moore, L. D., Le, T., Fan, G. 
\newblock DNA methylation and its basic function. 
\newblock Neuropsychopharmacology, 38(1), 23--38. 



\bibitem{szegedy2015going}
Szegedy C, Liu W, Jia Y, Sermanet P, Reed S, Anguelov D, et~al.
\newblock Going deeper with convolutions.
\newblock In: Proceedings of the IEEE conference on computer vision and pattern
  recognition; 2015. p. 1--9.

\end{thebibliography}


\end{document}








