
\subsection{Outline of the proof}\label{sec:proofoutline}

In the following, we will give an outline of our proof.
As we will, see our proof consists of the following three steps.
\begin{enumerate}
    \item \textbf{Symmetrization:}
    First, we will show how the asymmetric matrix sensing problem in equation  can be equivalently reformulated as a matrix sensing problem with symmetric matrices.
    With this reformulation, we will be able to use some of the tools developed in \cite{stoger2021small} in the next two steps.
    However, while on a first glance this reformulated problem might resemble the one in \cite{stoger2021small}, there is a key difference.
    Namely, in \cite{stoger2021small}, it was assumed that both the ground truth and the learned matrices are positive semidefinite.
    Instead, in the scenario in this paper the ground truth matrix will have both positive and negative eigenvalues and we train one positive definite and one negative definite matrix.
    The dynamics of this two matrices are coupled with each other, which will lead to important changes in the proof as we will point out below.  
    \item \textbf{Decomposition of the learned matrices into signal and nuisance part:}
    In the second step, we will discuss how to decompose both training matrices into a signal and nuisance part.
    As in \cite{stoger2021small} the idea is that in the third step we then can show the signal matrices, which have rank $r$, will converge (approximately) to the positive definite part, respectively the negative definite part, of the ground truth matrix,
    whereas the nuisance terms will stay small.
    \item \textbf{Three-Phase Analysis:}
    To analyse the dynamics of gradient descent we will utilize the three-phase-analysis introduced in \cite{stoger2021small}.
    In the first phase, the \textit{alignment/spectral phase},
    we will show how, similar to a spectral initialization, the subspaces spanned by the signal parts of the learned get gradually more aligned with the subspace spanned by the ground truth matrix.
    In the second phase, the \textit{saddle avoidance phase}, we will show how the singular values of the signal parts are growing until they reach a certain basin of attraction of the ground truth matrices.
    In the third phase, the \textit{local convergence phase}, we will prove that the signal parts of the learned matrices converge linearly to the ground truth matrix.

    As already pointed out in the description of the first step,
    the key difficulty will be to deal with the fact that the dynamics of the two learned matrices are coupled with each other. 
    In Section \ref{sec:threephase} we will describe in detail how we deal with this.
\end{enumerate}