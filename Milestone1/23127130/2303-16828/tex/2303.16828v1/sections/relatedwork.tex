This section provides some background on Myanmar's political history and the evolution of hate speech targeted explicitly against the Rohingya community. We broadly discuss hate speech detection algorithms and datasets in resource-rich and low-resource languages and highlight Burmese natural language processing work.

\subsection{Social Media in Myanmar and Hate Speech}
After gaining independence in January 1948, Myanmar's over 14 years-long democratic government was interrupted by a military coup and subsequent dictatorship in 1962 that lasted almost 50 years. The military at the time pushed against calls for autonomy by non-Burman ethnic groups, which they labeled as anti-nationalist and anti-unity. For most of its years post-independence, Myanmar has faced many ethnic and religious conflicts and wars. When Myanmar re-transitioned to democratic rule in 2011, these conflicts remained persistent~\cite{zin2015anti}. The government was dominated by the majority Bamar Buddhists who had exclusive control of military and civilian institutions, despite the country's cultural and linguistic diversity. This unequal power share led to the marginalization of ethnic minority groups resulting in both armed conflict and non-violent political actions~\cite{smith1991burma, thawnghmung2011beyond}. 

An estimated 1 million Rohingyas living in the Rakhine state have historically faced discriminatory practices from the military government, including but not limited to restricted access to education, employment, and citizenship identity cards~\cite{zin2015anti, fink2018dangerous}. These practices appeared to have worsened since the transition to democracy. Lee~\cite{lee2016dark} pointed to the liberalization of media and political freedom stemming from the transition as a motivating factor that amplified political polarization, which fuelled the agendas of ultra-nationalist anti-Rohingya Buddhist groups.

McLaughlin~\cite{mclaughlin2018facebook} discusses how violence against the Rohingya was preceded by the viral spread of hateful rhetoric and disinformation on Facebook primarily targeted against Muslims. Facebook experienced massive growth in adoption between 2016 and 2017 through its ``free basics'' program, which allowed users to sign up for a free, limited Facebook version without a mobile internet plan~\cite{best2014internet, mclaughlin2018facebook}. According to Fink ~\cite{fink2018dangerous}, Facebook ignored several warnings by local rights and technology civil society organizations to act on dangerous speech posted on the platform calling on Buddhists to pick up arms in preparation for Muslim attacks and vice versa in 2017. The United Nation's independent fact-finding mission on Myanmar confirmed the significant negative role of hate speech and disinformation spread on Facebook played in heating the polity~\cite{un2018report}. The platform has struggled to effectively moderate content in Myanmar's context due to the non-locally resident nature of its moderation system. The escalation of conflict in August 2017 lasted more than two months and led to over 750,000 fleeing as refugees~\cite{un2018report}. 

As Myanmar geared for its national election in late 2020, observers were concerned about the possibility of online actors exploiting existing distrust of the government and media in the country to foster violent responses to election results. This worry prompted opportunities for local and international civil society organizations to explore localized hate speech tracking and mitigation projects. It is within this socio-political context that this work is situated.

\subsection{Automated Hate Speech Detection}
Earlier works in hate speech detection have mostly leveraged a keyword-based approach that relied on the presence of a derogatory term typically used in hate speech to make decisions about whether a post is hate speech or not, e.g.~\cite{kontostathis2013detecting}. However, keyword-based approaches have been shown to offer little performance value \cite{saleem2017web, macavaney2019hate}. More sophisticated computational approaches for tackling online hate speech have gained attention in recent years, and machine learning techniques have since been applied to hate speech detection~\cite{schmidt2017survey, waseem2016you, saleem2017web}. Prior work have explored bag-of-words, word-, and character-level n-grams features~\cite{mehdad2016characters, nobata2016abusive, waseem2016hateful} and TF/IDF weighted embedding methods~\cite{davidson2017automated}, with algorithms such as support vector machines~\cite{malmasi2018challenges}, balanced random forests\cite{burnap2015cyber}, and logistic regression models~\cite{davidson2017automated}. Recent works have adopted neural network-type approaches such as convolutional neural networks (CNNs)~\cite{gamback2017using}, CNNs combined with a Gated Recurrent Unit (GRU) network~\cite{zhang2018detecting}, and Transformer-based models such as the Bidirectional Encoder Representations from Transformers (BERT)~\cite{mozafari2019bert, mozafari2020hate}.

Data is a critical resource for determining performance, robustness, and scalability in machine learning systems~\cite{halevy2009unreasonable}. To this end, hate speech datasets have been released by researchers in this area~\cite{burnap2016us, waseem2016hateful, waseem2016you, davidson2017automated, founta2018large}. In their survey of the hate speech detection literature, Fortuna and Nunes~\cite{fortuna2018survey} found the majority of the datasets to be in English, with few exceptions in Dutch~\cite{tulkens2016dictionary}, German~\cite{ross2017measuring}, and Italian~\cite{del2017hate}. These datasets range in size from as small as 36 tweets~\cite{benikova2017does} to as large as 150,000 multimodel (image-text) tweets~\cite{gomez2020exploring} sourced from publicly available internet data. 

A large proportion of the works mentioned earlier (e.g., ~\cite{chatzakou2017mean, founta2018large}) leverage crowdsourcing platforms like Figure-Eight (formerly Crowdflower)~\cite{appen2021} or use publicly sourced comments online as ground truth (e.g., Warner and Hirschberg~\cite{warner2012detecting} used several thousand comments from Yahoo!). In some cases, the research team labels the data themselves. We note that several of these resources may not be available in many low-resource contexts. First, crowdsourcing platforms do not have universal coverage across languages and geographic regions. Even if they did, finding the right annotators for a hate speech task that requires knowledge of social contexts can be challenging. There is also not a broad diversity of web platforms in low-resource language settings to scrape potential ground truth data. Most times, people who understand the language and the socio-political context may not be the researchers themselves, thus requiring the kind of collaboration we explore in this paper. 

\subsubsection{Low-Resource Hate Speech Detection Data}
We refer to low-resource strictly within the context of limited availability of technical resources such as labeled training data; linguistic tools for tasks such as semantic analysis, named-entity recognition, and parts of speech tagging; or digitized texts that can serve as supervised/unsupervised training data for language models. Researchers have also explored the task of hate speech detection in these contexts. Mubarak et al.~\cite{mubarak2017abusive} studied the use of abusive language in the Arabic language on Twitter. Ishmam and Sharmin~\cite{ishmam2019hateful} explored machine learning approaches for classifying public Facebook posts in the Bengali language. Similar studies have been conducted in Amharic~\cite{mossie2018social}, Indonesian~\cite{alfina2017hate}, Hindi~\cite{sreelakshmi2020detection}, and Vietnamese~\cite{van2019hate}. Our investigation into these works shows that none point to the relevance of working with context experts as central to scaling hate speech detection in low-resource contexts. The authors also offered limited visibility into the data curation process, making it difficult to replicate it in new environments. 

In their critical analysis of existing hate speech detection datasets, Madukwe et al.~\cite{madukwe2020data} highlight that several works do not make their data publicly available, making it difficult to benchmark. When provided on request, the data may suffer from data degradation---a case where a dataset re-generated on demand by the researcher no longer produces the same amount or quality of data as at the time of publication. While data collection and sharing are vital for scientific progress, we acknowledge that authors cannot often do so for several reasons, including privacy concerns, platform restrictions, and the potential dissemination of harmful content. Anane-Sarpong et al.~\cite{anane2018you} discuss how various structural, organizational, cultural, and ethical complexities influence a researcher's decision to share their data. For instance, according to CrowdTangle's terms of use, we do not have Facebook's permission to share our dataset from Myanmar. However, we detail our steps for the hate speech dataset curation and provide materials for future use in new contexts and possible replication studies. 

\subsection{Burmese Language Processing}
Burmese is the official language of Myanmar and the native language of the Bamar people. It is a largely monosyllabic and analytic language with subject-object-verb word ordering and belongs to the Sino-Tibetan family. Like Chinese, Burmese morphemes can be combined freely with no changes~\cite{jenny2017burmese}. Ding et al.~\cite{ding2016word} describes a challenge that arises for Burmese language processing because the boundaries of what implies a ``word'' are not clearly defined. This challenge emerges because Burmese has no specific rule or convention on how spaces separate words. Traditional Burmese does not use white spaces to mark word boundaries. However, modern variants of Burmese do use white spaces between phrases to improve readability. 

Another significant challenge is the lack of consistent, standardized font encoding. The most widely-used Burmese font for reading and writing on modern computers and smartphones is the Zawgyi font. Zawgyi is not defined as a standard character encoding and is not part of the standard Unicode character set. As a result, it is not typically built into major operating systems. Nonetheless, Facebook supports Zawgyi as an optional encoding on their app and website, and this option is widely used in Myanmar.

The Burmese language is referred to as part of a class of low-resource languages due to the limited availability of tools, datasets, and studies focused on the language. A series of recent works have been published, laying the groundwork for Burmese natural language processing. These include morphological analyses such as syllable-based tokenization~\cite{ding2019towards}, part-of-speech tagging~\cite{ding2018nova}, word segmentation~\cite{ding2016word}, named-entity transliteration~\cite{mon2020myanmar}, and the development of a Burmese treebank~\cite{ding2020burmese} as part of the Asian Language Treebank Project~\cite{riza2016introduction}. Burmese has also been featured as a constituent language in monolingual~\cite{jiang2021pre} and multilingual~\cite{conneau2019unsupervised} learning tasks for language models. This work provides an early look into downstream classification tasks for automatic hate speech detection in the Burmese language using classical and neural network-based machine learning models. 