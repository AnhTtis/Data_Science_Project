% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\DeclareRobustCommand{\bbone}{\text{\usefont{U}{bbold}{m}{n}1}}
\DeclareMathOperator{\EX}{\mathbb{E}}
\usepackage{color}

% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\newcommand{\repeatthanks}{\textsuperscript{\thefootnote}}

\begin{document}
%
\title{Multi-view Cross-Modality MR Image Translation for Vestibular Schwannoma and Cochlea Segmentation}
\titlerunning{Multi-view Cross-Modality MR Image Translation}
\author{
Bogyeong Kang \and
Hyeonyeong Nam \and
Ji-Wung Han \and
\\Keun-Soo Heo \and
Tae-Eui Kam\thanks{Corresponding author.}
}
%
\authorrunning{B. Kang et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{
Department of Artificial Intelligence, Korea University, Seoul, Republic of Korea \\ \email{\{kangbk,kamte\}@korea.ac.kr}}
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
In this work, we propose a multi-view image translation framework, which can translate contrast-enhanced $\text{T}_1$ (ce$\text{T}_1$) MR imaging to high-resolution $\text{T}_2$ (hr$\text{T}_2$) MR imaging for unsupervised vestibular schwannoma and cochlea segmentation. We adopt two image translation models in parallel that use a pixel-level consistent constraint and a patch-level contrastive constraint, respectively. Thereby, we can augment pseudo-hr$\text{T}_2$ images reflecting different perspectives, which eventually lead to a high-performing segmentation model. Our experimental results on the CrossMoDA challenge show that the proposed method achieved enhanced performance on the vestibular schwannoma and cochlea segmentation.

%
\keywords{Multi-view image translation \and Cross-modality \and MRI segmentation \and Unsupervised domain adaptation.}

\end{abstract}

\input{chapters/Introduction.tex}

\input{chapters/RelatedWorks.tex}

\input{chapters/Methods.tex}

\input{chapters/ExperimentsandResults.tex}

\newpage
\input{chapters/Discussion.tex}

\input{chapters/Conclusion.tex}

\newpage
\subsubsection{Acknowledgment.}
This work was supported by Institute of Information \& communications Technology Planning \& Evaluation (IITP) grant funded by the Korea government (MSIT) (No. 2019-0-00079, Artificial Intelligence Graduate School Program (Korea University)), and the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. 2020R1C1C1013830, No. 2020R1A4A1018309).

\bibliographystyle{splncs04}
\bibliography{ref}

\end{document}
