\section{Introduction}
Vestibular schwannoma (VS) is a benign tumor that occurs in the nerve membrane cells of the vestibular nerve~\cite{dorent2022crossmoda,shapey2021segmentation}. For diagnosis and treatment of VS, it is necessary to segment the VS and its surrounding organs, especially the cochleas~\cite{dorent2022crossmoda,shapey2021segmentation}. In general, VS is diagnosed through contrast-enhanced $\text{T}_1$ (ce$\text{T}_1$) MR imaging but there are concerns about side effects such as allergy to gadolinium-containing contrast agents~\cite{dorent2022crossmoda,shapey2021segmentation}. As an alternative, high-resolution $\text{T}_2$ (hr$\text{T}_2$) MR imaging, a non-contrast imaging technique, has shed light on VS segmentation~\cite{dorent2022crossmoda,shapey2021segmentation}. However, it is very time-consuming and expensive to manually annotate newly released data. For this reason, the lack of annotated data can be a big problem for applying deep learning techniques in the medical domain. This issue can be solved by applying unsupervised domain adaptation, which allows a model trained in one domain to be adapted in another unseen domain without supervision~\cite{chen2019synergistic,dorent2020scribble,huo2018synseg}. Recently, some studies~\cite{shin2022cosmos,dong2021unsupervised,choi2021using} have been conducted based on cross-modality domain adaptation for VS and cochlea segmentation in unseen hr$\text{T}_2$ scans. Previous studies~\cite{shin2022cosmos,dong2021unsupervised,choi2021using} achieved outstanding performance on VS and cochlea segmentation utilizing image translation models such as CycleGAN~\cite{zhu2017unpaired} or CUT~\cite{park2020contrastive}. Of note, CycleGAN employs pixel-level consistent constraints, while CUT adopts patch-level contrastive constraints. The former constraint can better reflect the intensity and the texture of VS through cycle-consistency loss, but the structure of VS and cochleas could be distorted. Besides, the latter constraint uses contrastive loss, having an advantage in preserving the structure of VS and cochleas, but could ignore the detailed characteristics such as intensity and texture. Based on these considerations, we believe that we can obtain diverse pseudo-hrT2 images, which can help to improve the segmentation model performance by using the two aforementioned constraint models together.

Therefore, we design a multi-view image translation framework to obtain the pseudo-hr$\text{T}_2$ images with different perspectives by adopting two image translation models in parallel, CycleGAN~\cite{zhu2017unpaired} and QS-Attn~\cite{hu2022qs}. CycleGAN employs a pixel-level consistent constraint, and QS-Attn is an advanced patch-level contrastive constraint method that focuses on domain-relevant features~\cite{hu2022qs}. To our best knowledge, QS-Attn~\cite{hu2022qs} is first adopted for image translation from ce$\text{T}_1$ to hr$\text{T}_2$ images in this work. Based on our multi-view image translation framework, the following segmentation model can learn both structure and texture of VS and cochleas.