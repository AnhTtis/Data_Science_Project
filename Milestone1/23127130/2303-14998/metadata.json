{
    "arxiv_id": "2303.14998",
    "paper_title": "Multi-view Cross-Modality MR Image Translation for Vestibular Schwannoma and Cochlea Segmentation",
    "authors": [
        "Bogyeong Kang",
        "Hyeonyeong Nam",
        "Ji-Wung Han",
        "Keun-Soo Heo",
        "Tae-Eui Kam"
    ],
    "submission_date": "2023-03-27",
    "revised_dates": [
        "2023-03-28"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV",
        "cs.AI"
    ],
    "abstract": "In this work, we propose a multi-view image translation framework, which can translate contrast-enhanced T1 (ceT1) MR imaging to high-resolution T2 (hrT2) MR imaging for unsupervised vestibular schwannoma and cochlea segmentation. We adopt two image translation models in parallel that use a pixel-level consistent constraint and a patch-level contrastive constraint, respectively. Thereby, we can augment pseudo-hrT2 images reflecting different perspectives, which eventually lead to a high-performing segmentation model. Our experimental results on the CrossMoDA challenge show that the proposed method achieved enhanced performance on the vestibular schwannoma and cochlea segmentation.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.14998v1"
    ],
    "publication_venue": "9 pages, 4 figures"
}