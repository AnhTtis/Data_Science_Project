\documentclass{article}
% \usepackage[nonatbib, preprint]{neurips_2021} and removing \usepackage{biblatex}
\usepackage[nonatbib, final]{nips_2017}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx}

\title{Vibration Signal Denoising Using Deep Learning} % Exploration of Vibration Signal Denoising Methods

\author{
Yuyan Wu \\
  Department of Civil and Environmental Engineering\\
  Stanford University\\
  \texttt{wuyuyan@stanford.edu} \\
  %% examples of more authors
  \And
  Senyang Jiang \\
  Department of Computer Science \\
  Stanford University \\
  \texttt{senyangj@stanford.edu} \\
  \AND
  Yousef Liang \\
  Department of Computer Science \\
  Stanford University \\
  \texttt{youzhil@stanford.edu} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}

\author{
  Yuyan Wu\thanks{SUNet ID: wuyuyan, Department of Civil and Environmental Engineering, Stanford University, \texttt{wuyuyan@stanford.edu}}
  \and
  \textbf{Senyang Jiang}\thanks{SUNet ID: senyangj, Department of Computer Science, Stanford University, \texttt{senyangj@stanford.edu}}
  \and
  \textbf{Youzhi Liang}\thanks{SUNet ID: youzhil, Department of Computer Science, Stanford University, \texttt{youzhil@stanford.edu}}
}


\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

% \begin{abstract}
% The abstract should consist of 1 paragraph describing the motivation for your paper and a high-level explanation of the methodology you used/results obtained.
% \end{abstract}

\section{Introduction}	
% Introduction: this section introduces your project, why it’s important or interesting.

Structure vibration signals induced by footsteps are widely used for tasks like occupant identification ~\cite{pan2017footprintid}, localization ~\cite{mirshekari2018occupant}, human activity inference~\cite{pan2018characterizing}, structure health monitoring ~\cite{montalvao2006review} and so on. The vibration signals are collected as time series with amplitude values. However, the collected signals are always noisy in practice due to the influence of environmental noise, electromagnetic interference and other factors. The presence of noise affects the process of signal analysis, thus affecting the accuracy and error of the final tasks. 
%Current works mostly use conventional methods which applies the linear filters including low-pass filters, Wiener filers, Butterworth filter, spectral subtraction to reduce the noise part. However, these methods work poorly in non-stationary noise environments ~\cite{mirbagheri2013speech}. Thus, we are investigating into using deep neural networks, both supervised and unsupervised, for denoising the vibration signals and compare its performance with other conventional algorithms.
\subsection{Related Works}
\label{section:relatedworks}
%Currently, there are a lot of previous works related to signal denoising. These denoising methods are widely used to the denoising for speech signals, bioacoustic signals and electrocardiogram (ECG) signals. The methods can be divided into conventional methods and deep learning methods. The conventional methods includes linear filtering, spectrum subtraction and statistical-based approaches for noise removal such as wiener filtering. These conventional methods does not require a large amount of data and require few computational resources. However, these methods are not so effective for non-stationary noises. Deep learning-based signal denoising are popular in recent years for its ability to model non-stationary noise environments. There are many neural network structures proposed in previous works. In 2017, Jean-Marc Valin proposed the RNNoise model which is a deep recurrent neural network which achieves better quality than the traditional methods~\cite{valin2018hybrid}. Alexandre Défossez et al. proposed a novel waveform-to-waveform model, Demucs, which reached good result in source separation for music~\cite{defossez2019music}. Yanxin Hu et al. designed Deep Complex Convolution Recurrent Network (DCCRN), which ranked first for the real-time-track in the Interspeech 2020 Deep Noise Suppression (DNS)~\cite{hu2020dccrn}. Many deep learning methods are tried for structure vibration signals denoising in previous researches. Qingsong Xiong et al. proposed a denoising approach based on deep convolutional image-denoiser networks (DCIMN) for the strcture vibration signals used for structure health monitoring~\cite{xiong2023novel}. Gao Fan et al. proposed a
% vibration signal denoising approach for SHM based on a specialized Residual Convolutional Neural Networks (ResNet)~\cite{fan2020vibration}. These works demonstrate the superiority of deep learning for signal denoising tasks.

Currently, there are a lot of previous works related to signal denoising. These denoising methods are widely used for the denoising of speech signals, bioacoustic signals and electrocardiogram (ECG) signals. The methods can be divided into conventional methods and deep learning methods. The conventional methods include linear filtering, spectrum subtraction and statistical-based approaches for noise removal such as wiener filtering. Deep learning-based signal denoising are popular in recent years for its ability to model non-stationary noise environments. There are many neural network structures proposed in previous works like RNNoise~\cite{valin2018hybrid}, Demucs~\cite{defossez2019music}, DCCRN\cite{hu2020dccrn}. Many deep learning methods are tried for structure vibration signals denoising in previous research like ~\cite{xiong2023novel} and ~\cite{fan2020vibration}. These works demonstrate the superiority of deep learning for signal-denoising tasks.

Our task is to reduce the noise from the footstep-induced vibration signals. In this project, we are considering two kinds of noises. One is the stationary noise due to circuit interference, which includes Gaussian-distribution noise, white noise and so on. Another is the non-stationary noises such as the vibrations caused by items dropping, door closing, music noise, etc.
\section{Dataset}
% Describe your dataset: how many training/validation/test examples do you have? Is there
% any preprocessing you did? What about normalization or data augmentation? What is the
% resolution of your images? How is your time-series data discretized? Include a citation on
% where you obtained your dataset from. Depending on available space, show some examples
% from your dataset. You should also talk about the features you used. If you extracted
% features using Fourier transforms, word2vec, PCA,
% ICA, etc. make sure to talk about it. Try to include examples of your data in the report
% (e.g. include an image, show a waveform, etc.). 

% Proposal:
% For supervised learning, the dataset needs to include both the noisy signal (input) and the filtered clean signal (output). In real world, the collected signal always contains some noise, hence we need to synthesize the clean signal for our dataset. We opt to use ABAQUS software to simulate vibration signals under varied conditions. We will use this software to simulate clean vibration signals as the target signal, and then add some common noise distributions to the generated clean signal to produce synthetic noisy signal as the input. The noisy signals from this synthetic dataset can also be used as input to the unsupervised neural network model.
We cannot directly get the vibration signal without the noise because there always exists electrical noise when collecting data. So we consider using the simulation method to get a clean signal and add the common distribution of noises to it for training and testing. To get the noise distribution from item dropping, we collected the floor vibration signals caused by item dropping to the ground.


\subsection{Abaqus Synthetic Dataset}
We used Abaqus to build a model to simulate the vibration signal generated by the floor after applying an impact force. We change the sensing location, the thickness of the plate, and the force and generated a series of signals. The model built and the signal simulated is shown in Fig. ~\ref{fig:abacus_simu} (a).
\begin{figure}[!ht]
  \includegraphics[width=\linewidth]{Figs/simulation_v4.png}
  \centering
  \caption{(a) The Abaqus model and the generated vibration signal (b) Clean signal from Abacus vs. noisy signal after applying Gaussian noise (c) An example of the signals generated based on Eqn.~\ref{eqn:ODE}, displacement overlaid with a supplemental Gaussian noise, $w(t)$ as a function of time, $t$ [s].}
  \label{fig:abacus_simu}
\end{figure}
%However, since the FEA method requires more arithmetic power and longer computation time, our current simulation can only get 80 sets of signals.

Using the synthetic clean signal from Abaqus, we can apply noise on top of it to simulate the noisy signals we would get in real scenarios. For this paper, we start with Gaussian noises. For each set of the signal, we generate a Gaussian noise signal of the same length, with a scale selected uniformly between 0.001 and 0.002.

Each set of signals has nearly 1,000,000 data points, which is too long to be used as input to the RNN model. As a result, we split each set of signals into multiple segments of length 500, and use these segments as inputs to the RNN model. The size of data we have at the end is 112224 segments of length 500. Fig. ~\ref{fig:abacus_simu} (b) is an example of a segment of clean signal and its corresponding noisy signal after applying the generated Gaussian noise.
% \begin{figure}[h!]
%   \includegraphics[width=120mm]{Figs/abacus_cleanvsnoisy.png}
%   \centering
%   \caption{clean signal from Abacus vs. noisy signal after applying Gaussian noise}
%   \label{fig:abacus_gaussian_noise}
% \end{figure}

% \begin{figure}
%   \includegraphics[width=120mm]{Figs/pdesignal.png}
%   \centering
%   \caption{An example of signal generated based on Eqn.~\ref{eqn:ODE}, displacement overlaid with a supplemental Gaussian noise, $w(t)$ as a function of time, $t$ [s]. }
%   \label{fig:pdesignal}
% \end{figure}
\subsection{PDE/ODE Synthetic Dataset}
In light of the high expense of experiments and numerical simulation using Abacus, we utilized PDE/ODE solver (\href{https://docs.scipy.org/doc/scipy/reference/integrate.html#module-scipy.integrate}{scipy.integrate}) to generate 100k synthetic time series ($\mathcal{R}^{100,000 \times 500})$ with supplementary noise. 

The dynamics of structural vibrations induced by footsteps can be simplified as the impulse response of a Kirchhoff-Love plate subject to Dirichlet boundary conditions. Under the assumption of linearity for isotropic plates, we model the induced vibrations as the solutions of a system of PDEs~\cite{nguyen2021stable}:

\begin{equation}
    \label{eqn:ODE}
    D_i \nabla ^2 \nabla^2 w_i(\mathbf{x}, t) - T_i \nabla ^2 w_i(\mathbf{x}, t) = \delta(\mathbf{x}, t) - \rho_i h_i \ddot{w}_i(\mathbf{x}, t) - K_i \dot{w}_i(\mathbf{x}, t),
\end{equation}

where $w_i(\mathbf{x}, t)$ is the transverse deflection, $D_i \sim \mathcal{N}(\mu_D, \sigma_D)$, $T_i \sim \mathcal{N}(\mu_T, \sigma_T)$, $\rho_i h_i \sim \mathcal{N}(\mu_{\rho h}, \sigma_{\rho h})$ and $K_i \sim \mathcal{U}(a_U, b_U)$ are all parameters of the structure, governing the dynamical response subject to impulse $\delta(\mathbf{x}, t)$. Each synthetic time series is obtained by $\sum w_j(\mathbf{x}, t) + \epsilon_j(t)$, where $\epsilon_jS(t)$ represents the supplementary noise, simulating the sensor noise aforementioned, with an example shown in Fig.~\ref{fig:abacus_simu} (c).

% \begin{center}
%     \begin{figure}
%       \includegraphics[scale=0.4]{Figs/[CS230-project-milestone]ODE3.png}
%       \centering
%       \caption{An example of signal generated based on Eqn.~\ref{eqn:ODE}, displacement overlaid with a supplemental Gaussian noise, $w(t)$ as a function of time, $t$ [s]. }
%       \label{fig:ODE}
%     \end{figure}
% \end{center}

\subsection{Experimental Dataset}
\label{senction:dataset}
We collected 900 floor vibration signals caused by item dropping to the ground and 900 floor vibration signals induced by the footstep. The sample of the signal is shown in the input of Fig ~\ref{fig3}. This dataset is used for the task of reducing the noise caused by item dropping.

In addition, we collected 300s' floor vibration signal of music noise as a non-stationary noise dataset. This dataset is achieved by placing a speaker on the floor near the sensor that plays music continuously. We constituted a dataset for signal separation. The source signal is generated by superimposing the music noise of a random section with the floor vibration signal induced by footsteps. The footstep-induced floor vibration signal before adding the music noise is set as the target signal. This dataset totally contains 3430 samples.

% \begin{figure}
%   \includegraphics[width=120mm]{Figs/experiemnt.png}
%   \centering
%   \caption{The vibration signals induced by footstep and item drop}
%   \label{fig2}
% \end{figure}
% \section{Baseline} This can be included in the results part.
% [Classic Denoising Filters?]

% [Deep-Learning Denoising Methods]

\section{Tasks, Methods and Results}
\subsection{Task 1: Noise Reduction for Stationary Noises}
%\subsubsection{Modular Modeling using CNN?}

%\subsubsection{End-to-End Modeling using RNN}
% Since we have two datasets, PDE/ODE Synthetic Dataset and Abaqus Synthetic Dataset, we plan to train a separate end-to-end RNN model on each dataset.  Below are our current results.

\textbf{a. PDE/ODE Synthetic Dataset}

We built a 'many-to-many' LSTM model with a 0.2 drop-out to filter the signal with Gaussian noise, using a mean square error as the cost function. As shown in Fig.~\ref{fig:RNN_result1} (a), the loss reduces from 0.37 to 0.16 at the epoch of 100. The inset shows an example of a filtered and actual signal, suggesting a well-filtered signal using RNN for the regime of large amplitudes. To further examine the error, Fig.~\ref{fig:RNN_result1} (b) shows a discrete prediction for larger positive amplitudes (around 5 to 7.5) and mild heteroskedasticity due to a larger observed error for small amplitudes (around -2.5 to 2.5). 

\begin{figure}[ht]
  \includegraphics[width=120mm]{Figs/cs230_RNN_result.JPG}
  \centering
  \caption{(a) Training loss versus epoch. (Inset) At epoch = 100, an example in test set illustrating the unfiltered, filtered, and actual signal (b) Signal with noise versus actual signal. (Inset) Histogram of the error distribution. Bi-LSTM Fourier denotes the bi-directional LSTM with additional frequency-domain input using FFT.}
  \label{fig:RNN_result1}
\end{figure}

Aiming for higher prediction accuracy of filtered signals, we further explore feature engineering techniques and alternative RNN architectures, serving as an alternative to 1D-CNN for biometric signal processing~\cite{bai2019mental}. In light of a time series representing vibrational signals, features presented in the frequency domain captures the underlying physics governed by the fundamental structures. We extract the magnitude and phase using a Fast Fourier Transform to serve as additional inputs into a bi-directional LSTM neural network (see Fig.~\ref{fig:RNN_Architecture1}). As shown in Fig.~\ref{fig:RNN_result1}, the loss vs epoch and error distributions show an over 50\% error reduction using the new architecture, which agrees with the quantitative metrics, including RMSE, MAE and $R^2$-score listed in Table.1. 

\begin{figure}[ht]
  \includegraphics[width=115mm]{Figs/cs230_LSTM_Architecture.JPG}
  \centering
  \caption{(a) Architecture for bi-directional LSTM with additional frequency-domain input. (b) Table for metrics used to evaluate the unfiltered signal and filtered signal using two LSTM architectures. Bi-LSTM Fourier denotes the bi-directional LSTM with additional frequency-domain input using FFT.}
  \label{fig:RNN_Architecture1}
\end{figure}

%\subsubsection{other methods?}
\subsection{Task 2: Noise Reduction for Non-Stationary Noises }
\subsubsection{Situation 1: Interference vibration noises do not overlap with the effective signal (Take Item Dropping as an Example)}
To simplify the question, we first assume that floor vibration signal pulses caused by footstep and item dropping do not overlap with each other. So our task becomes recognizing the item-dropping-induced vibration signal pulses. Firstly, we extract features using wavelet transform. This method was chosen because the wavelet transform has a different time-frequency resolution for the low-frequency region and the high-frequency region. We build a simple convolutional neural network as shown in Fig. ~\ref{fig3}, using Categorical Crossentropy as the loss function to recognize these two kinds of signals. We shuffled the dataset and divided it into a training set and a test set in a 9:1 ratio. The recognition result reaches 99\%. This shows that our model performs well in the task of distinguishing between the footstep-induced and item dropping-induced floor vibration signals.
\begin{figure}
  \includegraphics[width=\linewidth]{Figs/Cnn_overview.png}
  \centering
  \caption{The CNN structure used for classification of footstep-induced and item dropping-induced floor vibrations}
  \label{fig3}
\end{figure}
\subsubsection{Situation 2: Interference vibration noises overlap with the effective signal (Take Music Noise as an Example)}
Now, we are considering the situation when the non-stationary noises are overlapped with the effective signals. In this task, we use the dataset with music noise described in ~\ref{senction:dataset}. The network used here is the U-Net. We use the wandb package for hyperparameter selection. We select the hyperparameter with the best result. (num filters = 16, kernel size = 5, batch size = 16, epoch =100) The structure of the network is described in ~\ref{fig4} (a). Finally, the mean absolute error (MAE) after denoising by U-Net is 0.028. (Before Denoising: 0.06). The denoising result is shown in ~\ref{fig4} (c). We can see that the network is capable of separating the vibration signal from the music noise
\begin{figure}[ht]
  \includegraphics[width=\linewidth]{Figs/Unet-reult.png}
  \centering
  \caption{(a) The U-Net Structure used for signal separation task. (b) Validation Set MAE value for different hyperparameter settings. Our final structure is set according to the green line's setting (The line with the minimum validation loss) (c) Signal denoising result }
  \label{fig4}
\end{figure}

\subsection{Task 3: General Noise Reduction using RNNoise}

As described in related works ~\ref{section:relatedworks}, RNNoise~\cite{valin2018hybrid} is a neural network architecture used for enhancing human voice from background noises. It combines classical signal processing with modern deep learning methods. In this paper, we explore the effectiveness of RNNoise in reducing both stationary and non-stationary noises, possibly using it as a baseline to compare with other end-to-end deep learning architectures presented in this paper. \\
The source code repo \footnote[1]{Github link: \textbf{https://github.com/xiph/rnnoise}} for the RNNoise paper provides us with a tool for generating the training data. Using the dataset we created previously, We prepared 27 minutes of clean structural vibration signals and 30 minutes of Gaussian noises and pure music, and the tool from RNNoise repo will mix the clean signal and noises to create the training data. \\
We test the trained RNNoise model with signals with either Gaussian noises or Music noises. Fig.~\ref{fig:RNNoise} shows a segment of the noisy, filtered, and clean signal on the same diagram. 

\begin{figure}[ht]
  \includegraphics[width=120mm]{Figs/rnnoise.png}
  \centering
  \caption{unfiltered, filtered, actual signal with (a) Gaussian Noise (b) Music Noise}
  \label{fig:RNNoise}
\end{figure}

We also calculated the RMSE (root mean squared error) between the model output and the ground truth clean signal on Gaussian and Music noises. The RMSE for Gaussian noise removal is $0.0228$, and the RMSE for music noise removal is $0.0310$. In comparison, when classical low-pass filters are used for removing the Gaussian noises and music noises, it can only reach an RMSE value of 0.014 and 0.16 for the Gaussian noises and music noises correspondingly. For stationary noises like Gaussian noise, the classical low-pass filter has a better performance than RNNoise. However, for music noise which is non-stationary, the classical filter performs a lot worse than RNNoise. This shows that the classical filters are not suitable for filtering non-smooth noise.\\
RNNoise is more effective in reducing Gaussian noise than music noise. This is expected since the pattern of music is less predictable than Gaussian noises. Lastly, we convert the output signal to playable .wav format. By listening to the output signal, we found Gaussian noises are imperceptible anymore, but we can still hear the background music, even though its volume has been reduced.
% \section{Future Work}
% For task 1, upon CS230 covering RNN materials, we will further fine-tune the RNN architecture and explore the other RNN variations, including but not limited to GRU, bi-directional RNN. We may also consider modular modeling incorporating RNN or ensemble methods for accuracy at a cost of computation complexity. So far we have only trained the RNN model on gaussian noises, but other noise types needs to be taken into account to improve the robustness of our model.

% For task 2, we will try to separate the footstep-induced and item dropping-induced floor vibration signals in the situation that they are overlapped with each other. Also, we will consider adding other common environment noises such as floor vibration caused by closing the door.
\section{Summary and Conclusion}
In this project, we mainly explore the denoising methods for footstep-induced vibration signals. We have considered different kinds of noise including stationary noises such as gaussian noises and non-stationary noises such as item-dropping vibration noise and music noises.

For the non-stationary noises, we are considering 2 situations. In the first situation, we are considering some instant noises, taking item-dropping induced vibration signals as the example. A simple CNN is built to classify the vibration signals induced by item dropping and footsteps. In this task, the accuracy we got is 99$\%$. Going further, we are considering the non-stationary noises that overlaps with the footstep-induced vibration signals, taking music noise as an example. In this task, we built a U-Net structure and successfully reduced the music noise from the footstep-induced vibration signals. The MAE loss drops from 0.06 to 0.028 after denoising using U-Net.

For stationary noises, we further investigate the LSTM architecture using ODE/PDE synthetic data with Gaussian noise. A LSTM model with dropout reduces the noise by approximately 70\% based on RMSE/MAE metrics. Bi-Directional LSTM with additional frequency-domain features demonstrates much higher denoising performance with an $R^2$-score over 0.996 and further reduced the heteroskedasticity over the magnitude of signal. 

Finally, we explored using popular denoising architecture (RNNoise) to perform filtering for both stationary and non-stationary noises. Even though this model is mainly used for enhancing human voices, through retraining the model from scratch using our data, we are able to obtain pretty low errors on removing Gaussian and music noises. By converting the output signal to audio file, we are able to qualitatively verify that the model is able to filter out Gaussian noises, and increase signal-to-noise ratio on music noises.
% \section{Project Novelty}
% To the best of our knowledge, this is the first work focusing on the denoising of footstep-induced floor vibration signals using deep learning. Different from other denoising works on vibration signals, we  consider not only the stationary noise, but also the nonstationary noises like the item dropping and music noise. 
% \section{Team Member Contributions}
% Yuyan Wu: Investigated and wrote the related work; Finished Abaqus simulation and generated the simulation dataset; Collected the experiment dataset (item-dropping signals and music noises); Built the CNN model for recognizing the footstep-induced and item-dropping-induced vibration signals; Built the U-Net Model for denoising for the music noises.

% Yousef Liang: Explored prior arts using RNN architecture; Generated synthetic dataset using systems of PDE/ODEs; Built and trained an LSTM model, bi-directional LSTM model and bi-directional LSTM model leveraging frequency-domain features with error analysis. 

% Senyang Jiang: Processed Abaqus simulation dataset by applying Gaussian noises. Trained RNNoise model from scratch using prepared training dataset and evaluated its performance on test dataset.
%\section{(make sure to follow rubics on Ed)}

%\section{Code}
% previous proposal
% We intend to try both supervised and unsupervised learning methods for this task. \\
% For the supervised learning experiments, we will use the simulated clean vibration signals as the target signal and the signal with added noise as the input signal to train and evaluate the deep learning models. We will first apply deep learning methods like Autoencoders, Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), Long-Short Term Memory (LSTM) to capture the information of the vibration signals to achieve good denoising reults. Then, we will try to fine-tune the architecture of the models based on the characteristics of vibration signals. \\
% For the unsupervised learning part, we will try to use only the signal with noise to train and test. The variational autoencoders (VAEs) models and other unsupervised models used in speech denoising tasks will be tried on vibration signal denoising. Using the same test dataset, We will compare and analyze the results of supervised learning models and unsupervised learning models. 

% \section{Evaluation}
% You should also give details about what (hyper)parameters you chose (e.g. why did you
% use X learning rate for gradient descent, what was your mini-batch size and why) and how
% you chose them. What your primary metrics are: accuracy, precision,
% AUC, etc. Provide equations for the metrics if necessary. For results, you want to have a
% mixture of tables and plots. If you are solving a classification problem, you should include a
% confusion matrix or AUC/AUPRC curves. Include performance metrics such as precision,
% recall, and accuracy. For regression problems, state the average error. You should have
% both quantitative and qualitative results. To reiterate, you must have both quantitative
% and qualitative results! If it applies: include visualizations of results, heatmaps,
% examples of where your algorithm failed and a discussion of why certain algorithms failed
% or succeeded. In addition, explain whether you think you have overfit to your training set
% and what, if anything, you did to mitigate that. Make sure to discuss the figures/tables in
% your main text throughout this section. Your plots should include legends, axis labels, and
% have font sizes that are legible when printed.

% Previous Proposal
% We will use signal-to-noise ratio (SNR), Mean Square Error (MSE), Peak Signal-to-Noise Ratio (PSNR) and other evaluation metrics to evaluate the effectiveness of the model. We will compare the denoising results from the deep learning models with the results from conventional denoising methods like Wiener Filter, Low-pass Filter and so on.

% \section{Main Tasks and Challenges}
% You should find existing papers, group them into categories based on their approaches,
% and discuss their strengths and weaknesses, as well as how they are similar to and differ
% from your work. In your opinion, which approaches were clever/good? What is the stateof-the-art?
% Do most people perform the task by hand? You should aim to have at least
% 5 references in the related work. Include previous attempts by others at your problem,
% previous technical methods, or previous learning algorithms. Google Scholar is very useful
% for this: https://scholar.google.com/ (you can click “cite” and it generates MLA, APA,
% BibTeX, etc.)

% Previous Proposal:
% Our tasks and possible challenges includes:
% \begin{enumerate}
%     \item We need to use finite element analysis (FEA) software to simulate credible vibration signal results for different cases as the dataset.
%     \item We need to consider different noise types in our dataset, such as gaussian noise, white noise, etc. We can start with creating synthetic data with simple noises first and train the network. Then we can add training data with more complicated noises later, in order to see how it improves the performance of the network.
%     \item We need to build some common supervised learning networks and improve them for the characteristics of vibration signals.
%     \item We need to build some unsupervised learning networks for denoising. The difficulty of this method is that the network can not get the information of clean signal, but can only extract the distribution of noise from the noisy signal and remove it.
% \end{enumerate}

% \section{Conclusion/Future Work }
% Summarize your report and reiterate key points. Which algorithms were the highestperforming?
% Why do you think that some algorithms worked better than others? For
% future work, if you had more time, more team members, or more computational resources,
% what would you explore?

% \section{Contributions}
% The contributions section is not included in the 5 page limit. This section should describe
% what each team member worked on and contributed to the project.

% \section*{References}
% This section should include citations for: (1) Any papers mentioned in the related work
% section. (2) Papers describing algorithms that you used which were not covered in class.
% (3) Code or libraries you downloaded and used. This includes libraries such as scikit-learn, Tensorflow, Pytorch, Keras etc. Acceptable formats include: MLA, APA, IEEE. If you
% do not use one of these formats, each reference entry must include the following (preferably
% in this order): author(s), title, conference/journal, publisher, year. If you are using TeX,
% you can use any bibliography format which includes the items mentioned above. We are excluding
% the references section from the page limit to encourage students to perform a thorough
% literature review/related work section without being space-penalized if they include more
% references. Any choice of citation style is acceptable
% as long as you are consistent. 

% \medskip
% \small
% [1] Alexander, J.A.\ \& Mozer, M.C.\ (1995) Template-based algorithms
% for connectionist rule extraction. In G.\ Tesauro, D.S.\ Touretzky and
% T.K.\ Leen (eds.), {\it Advances in Neural Information Processing
%   Systems 7}, pp.\ 609--616. Cambridge, MA: MIT Press.

% [2] Bower, J.M.\ \& Beeman, D.\ (1995) {\it The Book of GENESIS:
%   Exploring Realistic Neural Models with the GEneral NEural SImulation
%   System.}  New York: TELOS/Springer--Verlag.

% [3] Hasselmo, M.E., Schnell, E.\ \& Barkai, E.\ (1995) Dynamics of
% learning and recall at excitatory recurrent synapses and cholinergic
% modulation in rat hippocampal region CA3. {\it Journal of
%   Neuroscience} {\bf 15}(7):5249-5262.
\bibliographystyle{unsrt}
\bibliography{reference}

\end{document}