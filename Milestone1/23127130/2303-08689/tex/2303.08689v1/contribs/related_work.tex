

Accurate segmentation of plants in the field enables a range of tasks, from field or crop monitoring~\cite{Halstead2021} through to precise weeding~\cite{Ahmadi2022a}.
To achieve this, current state-of-the-art approaches have to be trained in a supervised manner which requires a large number of images to be annotated with a label for each pixel, however, these pixel-wise annotations are expensive and labour intensive to acquire \cite{Zhang2022}.
An alternative is to perform semi-supervised training by using sparse labels for each object~\cite{Dai2015,Khoreva2017}, we refer to this as weak labelling.

In this section we review literature with a primary focus on weakly labelled segmentation, and then briefly outline semi-supervised learning, as well as its use within the agricultural domain.
Finally, as our novel approach leverages panoptic vision for one-click segmentation we briefly review panoptic segmentation.

\subsection{Weakly Labelled Segmentation} 
\label{sec:related:weak_seg_baselines}

Weakly labelled segmentation is a method where segmentation networks are trained to obtain pseudo-labels from less than pixel-wise annotations.
A major benefit of weak labelling is that sparse labels can be obtained much quicker than annotating each pixel of that object.
There are a range of approaches for weak label based segmentation which can differ in terms of the target setting~\cite{Xu2016,Majumder2021}, type and amount of user input~\cite{Maninis2018,Majumder2021}, input processing~\cite{Xu2016,Lin2021a}, or network structures \cite{Xu2016,Forte2020}.
Despite this diversity, many of these weak labelling approaches share similarities while using different input types as is the case of~\cite{Xu2016} which uses clicks as input whereas~\cite{Xu2017} use bounding boxes as their input.
And yet, even using clicks is a diverse area as the clicks can be from anywhere in the object~\cite{Xu2016} or there can be a series of clicks placed on specific locations to contain the object~\cite{Maninis2018}.
Therefore, weak labelling is becoming an extensive area of research with many varying methods for obtaining pseudo-labels.


One of the earliest deep learning-based approaches for click-based segmentation was proposed in 2016 by Xu et al.~\cite{Xu2016}.
Each click was transformed to a map using the Euclidean distance of a pixel from the click, we term this a click transform map.
The click transform map was then used as a fourth channel in addition to the image (three channels for R, G, \& B) as input for a fully convolutional segmentation network (FCN)~\cite{Long2015}.
Such an approach can be used for a single click or for multiple clicks when used in the context of interactive segmentation; the clicks could be both positive (in the object) and negative (outside the object) clicks.


Subsequent works typically build upon this initial work and its click map guidance approach.
Maninis et al.~\cite{Maninis2018} made use of clicks on the extremity of objects, termed DEXTR.
Aside from using clicks in predefined positions, this work also made use of an improved network architecture consisting of an encoder-decoder structure rather than an FCN structure.
Further, their method uses a 2D Gaussian transform instead of the Euclidean distance.
A similar approach was proposed in~\cite{Zhang2020c}, likewise with predefined click positioning consisting of the object center as well as the opposite corners of an enclosing bounding box (which are negative clicks).


Other recent work has considered clicks explicitly as a sequence in an interactive segmentation paradigm similar to \cite{Xu2016}.
Mahadevan et al.~\cite{Mahadevan2018} incorporated masks from previous iterations for refinement as an additional input channel, using DeepLabV3+~\cite{Chen2018} and obtaining click maps by using a 2D Gaussian transform.
Forte et al.~\cite{Forte2020} also exploited the click sequence by treating the sequential clicks in a separate processing stream.
They used a UNet~\cite{Ronneberger2015} style architecture with further adaptions and aimed at obtaining the highest quality segmentation (finest possible detail).
In all of these approaches the authors generate pseudo-labels which could be used for training semi-supervised systems.


\subsection{Semi-supervised Applications}

Semi-supervised segmentation is any approach that trains using a proportion of pseudo-labels (not manually annotated) or on a percentage of data that is less than the fully annotated data.
In this case we outline techniques that are based on pseudo-labels produced by weak labelling techniques.
Using their weak segmentation method on objects in the PASCAL VOC 2012 dataset~\cite{pascal-voc-2012}, Dai et al. \cite{Dai2015} generate pseudo-labels from bounding box priors.
They find that performance is not impacted when training semantic segmentation with 90\% of pseudo-labels and only 10\% of hand labelled data.
Similarly, \cite{Khoreva2017} was able to achieve 95\% and 99\% of the fully supervised results on PASCAL and PASCAL/COCO~\cite{Lin2014} (combined) datasets respectively.
In our work, we use a similar data split, generating pseudo-labels from models trained on 10\% of our datasets, predicted on the remaining 90\%.


\subsection{Agricultural Applications}

There have been few attempts at applying weak or semi-supervised learning techniques to the agricultural domain.
In viticulture~\cite{CasadoGarcia2022} Casado-Garcia et al. compare various approaches to leverage label information from just 20\% of their data and generate pseudo labels for the remaining 80\% unlabelled data which they combine to train semi-supervised semantic segmentation.
In~\cite{Ciarfuglia2022} Ciarfuglia et al. use bounding boxes obtained through a grape detector trained on a source dataset to then produce pseudo-labels for other data which are then applied to train an instance segmentation network.
To our knowledge, there is no prior work that uses click annotations to obtain pseudo-labels as well as use those for semi-supervised instance segmentation within the agricultural domain.


\subsection{Panoptic Segmentation}

Panoptic segmentation is a technique that aims to combine both semantic and instance segmentation.
It assigns each pixel in an image to either a \textit{stuff} or \textit{things} category~\cite{Kirillov2019}.
The \textit{stuff} category is for regions of similar texture or material such as grass, sky, road, or the ``background'' whereas the \textit{things} category relates to countable objects such as plants and fruit.
Additionally, it discriminates between instances of \textit{things} to enable the association of each pixel to a particular instance.
In this work we use Panoptic-Deeplab~\cite{Cheng2020} which uses a three head technique: semantic segmentation; center regression; and center offset.
At inference time the results of these three heads are used to produce the panoptic segmentation output using post-processing techniques.



