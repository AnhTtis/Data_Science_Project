\documentclass[a4paper,pdflatex]{llncs}
\pagestyle{plain}

\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb}
\usepackage{theorem}
\usepackage{algorithmicx}
\usepackage[ruled,vlined,titlenumbered,linesnumbered]{algorithm2e}
\usepackage{mathrsfs}
\usepackage[table]{xcolor}
\usepackage[colorlinks=true,citecolor=blue,linkcolor=blue,urlcolor=blue,breaklinks=true]{hyperref}
\usepackage{bm}
\usepackage{xspace}
\usepackage{scalerel}
\usepackage{cite}
\usepackage{url}
\usepackage{array}
\usepackage{pgfplots}
\usetikzlibrary{plotmarks,patterns}
\usepackage[nolist]{acronym}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{orcidlink}
\usepackage{tabto}

\let\normalunderbrace=\underbrace
\usepackage{mathtools}
\let\underbrace=\normalunderbrace
\mathtoolsset{showonlyrefs}

\usepackage[margin=3.8cm]{geometry}

\pgfplotsset{
  compat=1.17,
    every axis/.append style={
        scale only axis,
  width=0.55\columnwidth,
  height=0.4\columnwidth,
  label style={inner sep=0, font=\normalsize},
  tick label style={font=\scriptsize},
  legend style={font=\scriptsize},
  mark size=3,
  major grid style={dashed},
  line width=0.8pt,
  axis line style = thin}
}

\tikzstyle{SB}    = [color=black, solid]
\tikzstyle{LRS} = [color=red, dash pattern=on 2pt off 4pt on 6pt off 4pt, mark=x, mark options={solid}]
\tikzstyle{FLRS}   = [color=blue, dashed, mark=diamond, mark options={solid}]
\tikzstyle{HRFLRS} = [color=teal, dashed, mark=o, mark options={solid}]
\tikzstyle{divergence_1} = [color=purple]
\tikzstyle{divergence_2} = [color=teal]
\tikzstyle{divergence_3} = [color=blue]
\tikzstyle{distribution} = [color=black, mark options={scale=.1, draw=black, fill=black}, mark=*]

\newcolumntype{M}[1]{>{\centering\arraybackslash}m{#1}}

\renewcommand{\sectionautorefname}{Section}
\renewcommand{\subsectionautorefname}{Section}
\renewcommand{\algorithmautorefname}{Algorithm}
\newcommand{\definitionautorefname}{Definition}
\newcommand{\exampleautorefname}{Example}
\newcommand{\remarkautorefname}{Remark}
\newcommand{\problemautorefname}{Problem}
\newcommand{\lemmaautorefname}{Lemma}
\newcommand{\propositionautorefname}{Proposition}

\newcommand{\Fx}[1]{\ensuremath{\F{#1}[x]}}
\newcommand{\Fxq}{\Fx{q}}
\newcommand{\Z}[1]{\ensuremath{\mathbb{Z}_{#1}}}
\newcommand{\Zq}{\ensuremath{\mathbb{Z}_{q}}}
\newcommand{\ZQ}{\ensuremath{\mathbb{Z}_{Q}}}
\newcommand{\Fqm}{\ensuremath{\mathbb F_{q^m}}}
\newcommand{\Fqms}{\ensuremath{\mathbb F_{q^{ms}}}}
\newcommand{\Fqmh}{\ensuremath{\mathbb F_{q^{mh}}}}
\newcommand{\Fqn}{\ensuremath{\mathbb F_{q^n}}}
\newcommand{\Fqs}{\ensuremath{\mathbb F_{q^s}}}
\newcommand{\Fqd}{\ensuremath{\mathbb F_{q^d}}}
\newcommand{\Fq}{\ensuremath{\mathbb F_{q}}}
\newcommand{\Fp}{\ensuremath{\mathbb F_{p}}}
\newcommand{\F}{\ensuremath{\mathbb F}}
\newcommand{\ZZ}{\ensuremath{\mathbb{Z}}}
\newcommand{\NN}{\ensuremath{\mathbb{N}}}

\newcommand{\set}[1]{\ensuremath{\mathcal{#1}}}
\newcommand{\myset}[1]{\mathcal{#1}}
\newcommand{\intervallincl}[2]{\ensuremath{[#1,#2]}}
\newcommand{\intervallexcl}[2]{\ensuremath{[#1,#2-1]}}
\newcommand{\setelements}[2]{\ensuremath{\{#1_0,#1_1,\dots, #1_{#2-1}\}}}
\newcommand{\setvector}[2]{\ensuremath{\left\{#1^{(1)},#1^{(2)},\dots, #1^{(#2)}\right\}}}
\newcommand{\spannedBy}[1]{\ensuremath{\langle #1\rangle_q}}

\newcommand{\Basis}{\ensuremath{\boldsymbol{\beta}}}
\newcommand{\Dualbasis}{\myset{B}^{\perp}}
\newcommand{\Normbasis}{\myset{B}_N}
\newcommand{\NormbasisOrdered}{\boldsymbol{\Normelement}}
\newcommand{\NormbasisDualOrdered}{\boldsymbol{\Normelement}^{\perp}}
\newcommand{\Normbasisdual}{\myset{B}_N^{\perp}}
\newcommand{\Normelement}{\beta}
\newcommand{\Normelements}{\beta_s}
\newcommand{\Normdualelement}{{\beta^{\perp}}}
\newcommand{\NormdualelementUnderline}{\beta^{\perp}}
\newcommand{\Multtable}{\Mat{T}_m}

\newcommand{\qreciproc}[1]{\overline{#1}}
\newcommand{\qtrafo}[1]{\widehat{#1}}
\newcommand{\Polyring}{\ensuremath{\Fqm[x]}}
\newcommand{\Linpolyring}{\mathbb{L}_{q^m}\![x]}
\newcommand{\LinpolyringK}{\mathbb{L}_{q^m}[x]_{<k}}
\newcommand{\LinpolyringNox}{\mathbb{L}_{q^m}}
\newcommand{\Linpolyringmulti}{\mathbb{L}_{q^m}[x,y_1, \dots, y_s]}
\newcommand{\Stoppingdegree}{d_{stop}}
\newcommand{\aut}{\ensuremath{\sigma}}
\newcommand{\der}{\ensuremath{\delta}}
\newcommand{\derPar}{\ensuremath{z}}
\newcommand{\frob}{\ensuremath{\theta}}
\newcommand{\frobPar}{\ensuremath{u}}
\newcommand{\SkewPolyring}{\ensuremath{\Fqm[x;\aut,\der]}}
\newcommand{\SkewPolyringZeroDer}{\ensuremath{\Fqm[x;\aut]}}
\newcommand{\MultSkewPolyringZeroDer}{\ensuremath{\Fqm[x,y_1,\dots,y_\intOrder,\aut]}}
\newcommand{\MultSkewPolyring}{\ensuremath{\Fqm[x,y_1,\dots,y_\intOrder;\aut,\der]}}
\newcommand{\SkewPolyringZeroDerAny}[1]{\ensuremath{#1[x,\aut]}}
\newcommand{\remev}[2]{{#1}\!\left[#2\right]}
\newcommand{\opev}[3]{\ensuremath{{#1}(#2)_{#3}}}
\newcommand{\opfull}[2]{\ensuremath{\mathcal{D}_{#1}^{\aut,\der}(#2)}}
\newcommand{\op}[2]{\ensuremath{\mathcal{D}_{#1}(#2)}}
\newcommand{\opexp}[3]{\ensuremath{\mathcal{D}_{#1}^{#3}(#2)}}
\newcommand{\conj}[2]{\ensuremath{{#1}^{#2}}}
\newcommand{\IPop}[1]{\mathcal{I}_{#1}^{\mathrm{op}}}
\newcommand{\minpolyOp}[2]{\ensuremath{M^\text{op}_{#1}(x)_{#2}}}
\newcommand{\minpolyOpNoX}[1]{\ensuremath{M^\text{op}_{#1}}}

\newcommand{\MABin}{\A}
\newcommand{\MABinhat}{\hat{\A}}
\newcommand{\MABout}{\B}
\newcommand{\MABouthat}{\hat{\B}}
\newcommand{\MABoutentry}{B}

\newcommand{\algoname}[1]{{\normalfont\textsc{#1}}}


\newcommand{\MABnameFull}[3]{$#2$-ordered weak-Popov approximant basis of $#1$ of order $#3$}
\newcommand{\MABnameFullStandard}{\MABnameFull{\MABin}{\s}{d}}
\newcommand{\RMABnameShort}[3]{\mathsf{owPopovApprox}_{\mathsf{R}}(#1,#2,#3)}
\newcommand{\RMABnameShortStandard}{\RMABnameShort{\MABin}{\s}{d}}
\newcommand{\LMABnameShort}[3]{\mathsf{owPopovApprox}_{\mathsf{L}}(#1,#2,#3)}
\newcommand{\LMABnameShortStandard}{\LMABnameShort{\MABin}{\s}{d}}

\newcommand{\mymap}[1]{\textup{{#1}}}
\newcommand{\extsmallfield}{\ensuremath{\mymap{ext}_{\NormbasisOrdered}}}
\newcommand{\extsmallfieldInverse}{\ensuremath{\mymap{ext}^{-1}_{\NormbasisOrdered}}}
\newcommand{\extsmallfieldinput}[1]{\ensuremath{\mymap{ext}_{\NormbasisOrdered}\left(#1\right)}}
\newcommand{\extsmallfieldinputInverse}[1]{\ensuremath{\mymap{ext}^{-1}_{\NormbasisOrdered}\left(#1\right)}}
\newcommand{\liftmap}[1]{\mymap{lift}(#1)}
\newcommand{\ext}{\ensuremath{\text{ext}}}
\newcommand{\extInv}{\ensuremath{\text{ext}^{-1}}}

\newcommand{\piInv}{\pi^{-1}}

\makeatletter
\patchcmd{\@algocf@start}
  {-1.5em}
  {0pt}
{}{}
\makeatother

\newcommand{\OCompl}[1]{\ensuremath{\mathcal{O}({#1})}}
\newcommand{\printalgofloat}[1] {\begin{algorithm}[htb]#1\end{algorithm}}

\DeclareMathOperator{\defi}{def}
\newcommand{\defeq}{:=}
\newcommand{\defequiv}{\overset{\defi}{\equiv}}

\renewcommand{\bar}{\overline}
\DeclareMathOperator{\newmod}{mod}
\renewcommand{\mod}{\; \textnormal{ mod } \;}
\newcommand{\modq}{\ensuremath{\; \textnormal{mod}_q} \ }

\newcommand{\modl}{\; \mathrm{mod}_\mathrm{l} \;}
\newcommand{\modr}{\; \mathrm{mod}_\mathrm{r} \;}

\DeclareMathOperator{\divides}{|}

\newcommand{\Indfunc}{\mathbf{1}}
\newcommand{\expect}[1]{\mathbb{E}[#1]}
\DeclareMathOperator{\Id}{\textrm{Id}}

\DeclareMathOperator{\wt}{wt}
\DeclareMathOperator{\rk}{rk}
\DeclareMathOperator{\Tr}{Tr}
\DeclareMathOperator{\free}{free}
\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\comp}{comp}
\DeclareMathOperator{\ord}{ord}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\col}{col}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\unif}{unif}
\DeclareMathOperator{\RREF}{RREF}
\DeclareMathOperator{\RCEF}{RCEF}
\DeclareMathOperator{\Ind}{\textrm{Ind}_y}
\DeclareMathOperator{\lcm}{lcm}
\newcommand{\LT}[1]{\textrm{LT}(#1)}
\newcommand{\LM}[1]{\textrm{LM}(#1)}
\newcommand{\LC}[1]{\textrm{LC}(#1)}
\newcommand{\mystack}[2]{\ensuremath{\genfrac{}{}{0pt}{}{#1}{#2}}}

\renewcommand{\vec}[1]{\ensuremath{\bm{#1}}}
\newcommand{\mat}[1]{\ensuremath{\bm{#1}}}
\newcommand{\Mat}[1]{\ensuremath{\bm{#1}}}
\newcommand{\vecelements}[1]{\ensuremath{(#1_0 \ #1_1 \ \dots \ #1_{n-1})}}
\newcommand{\vecelementsm}[1]{\ensuremath{(#1_0 \ #1_1 \ \dots \ #1_{m-1})}}
\newcommand{\vecelementss}[1]{\ensuremath{(#1_0 \ #1_1 \ \dots \ #1_{s-1})}}
\newcommand{\vecelementsArb}[2]{\ensuremath{(#1_0 \ #1_1 \ \dots \ #1_{#2-1})}}

\newcommand{\veceval}[2]{\ensuremath{\left(#1(#2_0) \ #1(#2_1) \ \dots \ #1(#2_{n-1})\right)}}
\newcommand{\vecevalm}[2]{\ensuremath{\left(#1(#2_0) \ #1(#2_1) \ \dots \ #1(#2_{m-1})\right)}}
\newcommand{\vecevals}[2]{\ensuremath{(#1(#2_0) \ #1(#2_1) \ \dots \ #1(#2_{s-1}))}}

\newcommand{\Matrow}[2]{\ensuremath{(#1_{#2,0} \ #1_{#2,1} \ \dots \ #1_{#2,n-1})}}
\newcommand{\Matcol}[2]{\ensuremath{(#1_{0,#2} \ #1_{1,#2} \ \dots \ #1_{m-1,#2})}}
\newcommand{\MatcolInpLeng}[3]{\ensuremath{(#1_{0,#2} \ #1_{1,#2} \ \dots \ #1_{#3-1,#2})}}

\newcommand{\Mattotal}[3]{\begin{pmatrix}
#1_{0,0} & #1_{0,1} & \dots & #1_{0,#3-1}\\
#1_{1,0} & #1_{1,1} & \dots & #1_{1,#3-1}\\
\vdots &\vdots&\ddots& \vdots\\
#1_{#2-1,0} & #1_{#2-1,1} & \dots & #1_{#2-1,#3-1}\\
\end{pmatrix}}

\newcommand{\Mooremat}[2]{\Mat{M}_{#1}( #2 )}
\newcommand{\MoorematNoInput}{\mymap{qvan}}
\newcommand{\qVan}{\emph{q-Vandermonde} }

\newcommand{\MoormatExplicit}[3]{
\begin{pmatrix}
#1_{0} & #1_{1} & \dots& #1_{#3-1}\\
#1_{0}^{[1]} & #1_{1}^{[1]} & \dots& #1_{#3-1}^{[1]}\\[-4pt]
\vdots &\vdots&\ddots& \vdots\\[-2pt]
#1_{0}^{[#2-1]} & #1_{1}^{[#2-1]} & \dots& #1_{#3-1}^{[#2-1]}\\
\end{pmatrix}}

\newcommand{\undermat}[2]{\makebox[0pt][l]{$\smash{\underbrace{\phantom{\begin{matrix}#2\end{matrix}}}_{#1}}$}}

\newcommand{\Prk}{\ensuremath{\mathrm{Prk}}}

\newcommand{\MSP}[1]{\ensuremath{\mathcal{M}_{#1}}}
\newcommand{\MSPop}{\mathcal{M}^{\mathrm{op}}}
\newcommand{\MSPrem}{\mathcal{M}^{\mathrm{rem}}}
\newcommand{\IP}[1]{\mathcal{I}_{#1}}
\newcommand{\IPrem}[1]{\mathcal{I}_{#1}^{\mathrm{rem}}}
\newcommand{\wtB}{\mathrm{wt}_{\Omega}}
\newcommand{\skewDist}{\mathrm{d}}
\newcommand{\skewVandermonde}[2]{\ensuremath{\mat{V}^{\aut,\der}_{#1}(#2)}}
\newcommand{\opVandermonde}[3]{\ensuremath{\mathfrak{m}_{#1}(#2)_{#3}}}
\newcommand{\opMoore}[3]{\ensuremath{\mathfrak{M}_{#1}(#2)_{#3}}}
\newcommand{\genNorm}[2]{\ensuremath{\mathcal{N}_{#1}(#2)}}
\newcommand{\gcrd}{\ensuremath{\mathrm{gcrd}}}
\newcommand{\lclm}{\ensuremath{\mathrm{lclm}}}

\let\ced\c

\renewcommand{\a}{\mathbf a}
\renewcommand{\b}{\mathbf b}
\renewcommand{\c}{\mathbf c}
\renewcommand{\d}{\mathbf d}
\newcommand{\e}{\mathbf e}
\newcommand{\f}{\mathbf f}
\newcommand{\g}{\mathbf g}
\newcommand{\m}{\mathbf m}
\newcommand{\n}{\mathbf n}
\newcommand{\p}{\mathbf p}
\newcommand{\q}{\mathbf q}
\renewcommand{\r}{\mathbf r}
\newcommand{\s}{\mathbf s}
\renewcommand{\t}{\mathbf t}
\renewcommand{\u}{\mathbf u}
\renewcommand{\v}{\mathbf v}
\newcommand{\w}{\mathbf w}
\newcommand{\x}{\mathbf x}
\newcommand{\y}{\mathbf y}
\newcommand{\z}{\mathbf z}

\newcommand{\A}{\mathbf A}
\newcommand{\B}{\mathbf B}
\newcommand{\C}{\mathbf C}
\newcommand{\D}{\mathbf D}
\newcommand{\E}{\mathbf E}
\newcommand{\G}{\mathbf G}
\newcommand{\I}{\mathbf I}
\renewcommand{\H}{\mathbf H}
\renewcommand{\L}{\mathbf L}
\newcommand{\M}{\mathbf M}
\newcommand{\N}{\mathbf N}
\renewcommand{\P}{\mathbf P}
\newcommand{\Q}{\mathbf Q}
\newcommand{\R}{\mathbf R}
\renewcommand{\S}{\mathbf S}
\newcommand{\U}{\mathbf U}
\newcommand{\X}{\mathbf X}
\newcommand{\Y}{\mathbf Y}
\renewcommand{\Z}{\mathbf Z}
\newcommand{\0}{\mathbf 0}
\newcommand{\vecalpha}{\ensuremath{\boldsymbol{\alpha}}}
\newcommand{\vecbeta}{\ensuremath{\boldsymbol{\beta}}}
\newcommand{\vecgamma}{\ensuremath{\boldsymbol{\gamma}}}
\newcommand{\veczeta}{\ensuremath{\boldsymbol{\zeta}}}
\newcommand{\vecxi}{\ensuremath{\boldsymbol{\xi}}}

\newcommand{\mycode}[1]{\ensuremath{\mathcal{#1}}}
\newcommand{\mycodeReordered}[2]{\ensuremath{\mathcal{#1}_{#2}}}

\newcommand{\codeArb}[1]{\ensuremath{(#1)}}
\newcommand{\codelinearArb}[1]{\ensuremath{[#1]}}

\newcommand{\code}[1]{\ensuremath{(#1)_R}}
\newcommand{\codelinear}[1]{\ensuremath{[#1]_R}}

\newcommand{\MRD}[1]{\ensuremath{\mycode{MRD}(#1)}}
\newcommand{\MRDlinear}[1]{\ensuremath{\mycode{MRD}[#1]}}
\newcommand{\Gab}[1]{\textrm{Gab}\ensuremath{[#1]}}
\newcommand{\IntGab}[1]{\ensuremath{\mathrm{I}\mathrm{Gab}[#1]}}
\newcommand{\IntGabstar}[1]{\ensuremath{\mathrm{I}\mycode{Gab}^*[#1]}}
\newcommand{\IntGabNoInput}{\ensuremath{\mathrm{I}\mycode{Gab}}}
\newcommand{\IntSub}[1]{\ensuremath{\mathrm{I}\mathrm{Sub}[#1]}}
\newcommand{\FGab}[1]{\ensuremath{\mathrm{F}\mathrm{Gab}[#1]}}
\newcommand{\FSub}[1]{\ensuremath{\mathrm{F}\mathrm{Sub}[#1]}}
\newcommand{\skewRS}[1]{\ensuremath{\mathrm{SRS}[#1]}}
\newcommand{\intSkewRS}[1]{\ensuremath{\mathrm{I}\mathrm{SRS}[#1]}}
\newcommand{\puncSkewRS}[1]{\ensuremath{\mathrm{P}\mathrm{SRS}[#1]}}
\newcommand{\linRS}[1]{\ensuremath{\mathrm{LRS}[#1]}}
\newcommand{\intLinRS}[1]{\ensuremath{\mathrm{I}\mathrm{LRS}[#1]}}
\newcommand{\liftedIntLinRS}[1]{\ensuremath{\mathrm{LILRS}[#1]}}
\newcommand{\foldedLinRS}[1]{\ensuremath{\mathrm{F}\mathrm{LRS}[#1]}}
\newcommand{\foldedSkewRS}[1]{\ensuremath{\mathrm{FSRS}[#1]}}

\newcommand{\CRC}[1]{\ensuremath{\mycode{CR}_{q^m}(#1)}}

\newcommand{\CDC}[1]{\ensuremath{\mycode{CD}(#1)_q}}

\newcommand{\codeHamming}[1]{\ensuremath{(#1)_H}}
\newcommand{\codelinearHamming}[1]{\ensuremath{[#1]_H}}

\newcommand{\RS}[2]{\ensuremath{\mycode{RS}[#1,#2]}}
\newcommand{\VIRS}[1]{\ensuremath{\mycode{VIRS}[n,k,#1]}}
\newcommand{\MIRS}[2]{\ensuremath{\mycode{MIRS}[n,k,#1,#2]}}
\newcommand{\IRS}[1]{\ensuremath{\mycode{IRS}[n,k,#1]}}


\newcommand{\UM}[1]{\ensuremath{\mycode{UM}(#1)}}
\newcommand{\PUM}[2]{\ensuremath{\mycode{PUM}(#1|#2)}}

\newcommand{\cpum}{\mycode{PUM}}

\newcommand{\dhalffrac}{\left\lfloor \frac{d-1}{2}\right\rfloor}
\newcommand{\dRhalffrac}{\left\lfloor \frac{d_R-1}{2}\right\rfloor}
\newcommand{\dhalfnicefrac}{\left\lfloor \nicefrac{(d-1)}{2}\right\rfloor}
\newcommand{\dRhalfnicefrac}{\left\lfloor \nicefrac{(d_R-1)}{2}\right\rfloor}
\newcommand{\dhalf}{\left\lfloor (d-1)/2\right\rfloor}
\newcommand{\nkhalffrac}{\left\lfloor \frac{n-k}{2}\right\rfloor}
\newcommand{\nkhalfnicefrac}{\left\lfloor \nicefrac{(n-k)}{2}\right\rfloor}
\newcommand{\nkhalf}{\left\lfloor (n-k)/2\right\rfloor}
\newcommand{\npluskhalffrac}{\left\lfloor \frac{n+k}{2}\right\rfloor}
\newcommand{\npluskhalfnicefrac}{\left\lfloor \nicefrac{(n+k)}{2}\right\rfloor}
\newcommand{\npluskhalf}{\left\lfloor (n+k)/2\right\rfloor}

\newcommand{\taujohnson}{n-\sqrt{n(n-d)}}

\newcommand{\dintfrac}{\left\lfloor \frac{s}{s+1}(d-1)\right\rfloor}
\newcommand{\dintnicefrac}{\left\lfloor \nicefrac{s(d-1)}{(s+1)}\right\rfloor}
\newcommand{\nkintnicefrac}{\left\lfloor \nicefrac{s(n-k)}{(s+1)}\right\rfloor}

\newcommand{\HammingWeight}{\ensuremath{\wt_{H}}}
\newcommand{\RankWeight}{\ensuremath{\wt_{R}}}
\newcommand{\SumRankWeight}{\ensuremath{\wt_{\Sigma R}}}
\newcommand{\SkewWeight}{\ensuremath{\wt_{skew}}}

\newcommand{\SubspaceDist}{d_S}
\newcommand{\SumSubspaceDist}{d_{\ensuremath{\Sigma}S}}

\newcommand{\RankDist}{d_R}
\newcommand{\SumRankDist}{d_{\ensuremath{\Sigma}R}}

\newcommand{\SkewDist}{d_{skew}}

\newcommand{\Uniquecorrcap}{\ensuremath{\tau_0}}


\newcommand{\numbRowErasures}{\varrho}
\newcommand{\numbColErasures}{\gamma}

\newcommand{\decRadIS}{\tau}

\newcommand{\myspace}[1]{\mathcal{#1}}
\newcommand{\Rowspace}[1]{\ensuremath{{\left\langle #1 \right\rangle}_{q}}}
\newcommand{\RowspaceFqm}[1]{\ensuremath{{\left\langle #1 \right\rangle}_{q^m}}}
\newcommand{\RowspaceNoInput}{\myspace{R}_q}
\newcommand{\RowspaceHuge}[1]{\ensuremath{\scaleleftright[3ex]{\Biggl\langle}{\!\!\!#1\!\!\!}{\Biggr\rangle}\!\!\!\!\raisebox{-21pt}{\scriptsize{q}}}}
\newcommand{\RowspaceHugeFqm}[1]{\ensuremath{\scaleleftright[3ex]{\Biggl\langle}{\!\!\!#1\!\!\!}{\Biggr\rangle}\!\!\!\!\raisebox{-21pt}{\scriptsize{$q^m$}}}}
\newcommand{\Colspace}[1]{\myspace{C}_q\left(#1\right)}
\newcommand{\Grassm}[1]{\myspace{G}_q(#1)}
\newcommand{\Projspace}{\myspace{P}_q(n)}
\newcommand{\ProjspaceAny}[1]{\myspace{P}_q(#1)}

\newcommand{\Ball}[2]{\mathcal{B}_R^{(#1)}(#2)}
\newcommand{\Sphere}[2]{\mathcal{S}_R^{(#1)}(#2)}
\newcommand{\BallAny}[2]{\mathcal{B}^{(#1)}(#2)}
\newcommand{\SphereAny}[2]{\mathcal{S}^{(#1)}(#2)}
\newcommand{\BallHamming}[2]{\mathcal{B}^{(#1)}_H(#2)}
\newcommand{\SphereHamming}[2]{\mathcal{S}^{(#1)}_H(#2)}
\newcommand{\volSubBall}[1]{\ensuremath{V_S(#1)}}
\newcommand{\numSubShell}[1]{\ensuremath{N_S(#1)}}
\newcommand{\volSumRankBall}[2]{\ensuremath{\textsf{Vol}_{#1}(#2)}}
\newcommand{\volSumRankSphere}[2]{\ensuremath{\mathcal{N}_{#1}(#2)}}

\newcommand{\List}{\ensuremath{\mathcal{L}}}

\newcommand{\avgListSizeIS}[1]{\ensuremath{\bar{L}_\text{I}(#1)}}
\newcommand{\avgListSizeISstar}[1]{\ensuremath{\bar{L}'_\text{I}(#1)}}
\newcommand{\avgListSizeFS}[1]{\ensuremath{\bar{L}_\text{F}(#1)}}
\newcommand{\avgListSizeFSstar}[1]{\ensuremath{\bar{L}'_\text{F}(#1)}}

\newcommand{\MinSubspacePoly}[1]{m_{#1}(x)}
\newcommand{\minpoly}[1]{\ensuremath{\text{minpoly}\left\{#1\right\}}}

\newcommand{\quadbinom}[2]{\ensuremath{
{#1
\brack
#2}
}}

\newcommand{\oh}[1]{\bnd{O}{#1}}
\newcommand{\softoh}[1]{\bnd{\widetilde{\mathcal{O}}}{#1}}
\newcommand{\softO}{\tilde{O}}
\newcommand{\bnd}[2]{\ensuremath{#1\mathopen{}\left(#2\right)\mathclose{}}}
\newcommand{\mycomment}[1]{\textcolor{blue}{{#1}}}
\newcommand{\OMul}[1]{\mathcal{M}(#1)}

\newcommand{\nTransmit}{\ensuremath{n_t}}
\newcommand{\nReceive}{\ensuremath{n_r}}
\newcommand{\insertions}{\ensuremath{\gamma}}
\newcommand{\deletions}{\ensuremath{\delta}}
\newcommand{\deviations}{\ensuremath{\varkappa}}
\newcommand{\erasures}{\ensuremath{\rho}}
\newcommand{\txSpace}{\ensuremath{\myspace{V}}}
\newcommand{\rxSpace}{\ensuremath{\myspace{U}}}
\newcommand{\errSpace}{\ensuremath{\myspace{E}}}
\newcommand{\txSpaceVec}{\ensuremath{\vec{\txSpace}}}
\newcommand{\rxSpaceVec}{\ensuremath{\vec{\rxSpace}}}
\newcommand{\errSpaceVec}{\ensuremath{\vec{\errSpace}}}

\newcommand{\shot}[2]{\ensuremath{{#1}^{(#2)}}}
\newcommand{\nTransmitShot}[1]{\ensuremath{n_t^{(#1)}}}
\newcommand{\nReceiveShot}[1]{\ensuremath{n_r^{(#1)}}}
\newcommand{\insertionsShot}[1]{\ensuremath{\shot{\insertions}{#1}}}
\newcommand{\deletionsShot}[1]{\ensuremath{\shot{\deletions}{#1}}}
\newcommand{\deviationsShot}[1]{\ensuremath{\shot{\deviations}{#1}}}
\newcommand{\erasuresShot}[1]{\ensuremath{\shot{\erasures}{#1}}}
\newcommand{\txSpaceShot}[1]{\ensuremath{\shot{\txSpace}{#1}}}
\newcommand{\rxSpaceShot}[1]{\ensuremath{\shot{\rxSpace}{#1}}}
\newcommand{\errSpaceShot}[1]{\ensuremath{\shot{\errSpace}{#1}}}
\newcommand{\rankErrShot}[1]{\ensuremath{\shot{\rankErr}{#1}}}

\newcommand{\intPoly}{\ensuremath{Q\left(x,y_1,\dots,y_\intOrder\right)}}
\newcommand{\kwDeg}{\ensuremath{(1,k-1,\dots,k-1)}}
\newcommand{\kwDegHet}{\ensuremath{(1,k^{(1)}\!-\!1,\dots,k^{(\intOrder)}\!-\!1)}}
\newcommand{\pe}{\ensuremath{\alpha}}
\newcommand{\RecBasis}[1]{\ensuremath{\mathcal{A}(#1)}}
\newcommand{\minDim}{\ensuremath{\mu}}
\newcommand{\lenFG}{\ensuremath{N}}
\newcommand{\degConstraint}{\ensuremath{D}}
\newcommand{\intOrder}{\ensuremath{s}}

\newcommand{\foldPar}{\ensuremath{h}}
\newcommand{\foldParShot}[1]{\ensuremath{\foldPar_{#1}}}
\newcommand{\foldParVec}{\ensuremath{\h}}

\newcommand{\foldOp}[1]{\mathcal{F}_{#1}}
\newcommand{\foldOpInv}[1]{\mathcal{F}_{#1}^{-1}}

\newcommand{\intDim}{\ensuremath{s}}
\newcommand{\shots}{\ensuremath{\ell}}
\newcommand{\delOp}[1]{\ensuremath{\mathcal{H}_{#1}}}
\DeclareMathOperator{\cdeg}{cdeg}
\DeclareMathOperator{\rdeg}{rdeg}
\newcommand{\IntParam}{\intOrder'}

\newcommand{\lenFLRS}{\ensuremath{N}}
\newcommand{\lenFLRSVec}{\ensuremath{\N}}
\newcommand{\lenFLRSshot}[1]{\ensuremath{\lenFLRS_{#1}}}
\newcommand{\len}{\ensuremath{n}}
\newcommand{\lenVec}{\ensuremath{\n}}
\newcommand{\lenShot}[1]{\ensuremath{\len_{#1}}}

\newcommand{\height}{o}
\newcommand{\heightShot}[1]{\height_{#1}}
\newcommand{\heightVec}{\mathbf \height}

\newcommand{\qRev}[1]{\ensuremath{\bar{#1}}}
\newcommand{\ELP}{\ensuremath{\lambda}}
\newcommand{\ELPrev}{\ensuremath{\qRev{\lambda}}}
\newcommand{\ELProwRev}{\ensuremath{\qRev{\lambda}}}
\newcommand{\ELPcolRev}{\ensuremath{\qRev{\lambda}_\text{C}}}
\newcommand{\ELPcol}{\ensuremath{\ELP_\text{C}}}
\newcommand{\ELProw}{\ensuremath{\ELP_\text{R}}}
\newcommand{\ELPrank}{\ensuremath{\ELP_\text{F}}}

\newcommand{\ESP}{\ensuremath{\sigma}}
\newcommand{\ESPrev}{\ensuremath{\qRev{\ESP}}}
\newcommand{\ESProwRev}{\ensuremath{\qRev{\ESP}_\text{R}}}
\newcommand{\ESPcolRev}{\ensuremath{\qRev{\ESP}_\text{C}}}
\newcommand{\ESPcol}{\ensuremath{\ESP_\text{C}}}
\newcommand{\ESProw}{\ensuremath{\ESP_\text{R}}}
\newcommand{\ESPrank}{\ensuremath{\ESP_\text{F}}}

\newcommand{\errEvalPoly}{\ensuremath{\omega}}
\newcommand{\erasureEvalPoly}{\ensuremath{\psi}}

\newcommand{\qTransMat}{\ensuremath{\boldsymbol{\Phi}}}
\newcommand{\qTransMatInv}{\ensuremath{\boldsymbol{\Phi}^{-1}}}

\newcommand{\rowErasures}{\ensuremath{\rho}}
\newcommand{\colErasures}{\ensuremath{\gamma}}
\newcommand{\rankErr}{\ensuremath{t}}
\newcommand{\rankErrTotal}{\ensuremath{w}}
\newcommand{\errLoc}{\ensuremath{X}}

\newcommand{\ar}{\ensuremath{\vec{a}_R}}
\newcommand{\af}{\ensuremath{\vec{a}_F}}

\newcommand{\Br}{\ensuremath{\mat{B}_R}}
\newcommand{\Bc}{\ensuremath{\mat{B}_C}}
\newcommand{\Bf}{\ensuremath{\mat{B}_F}}

\newcommand{\liftedLinRS}[1]{\ensuremath{\mathrm{LLRS}[#1]}}

\DeclareMathOperator{\sumDim}{\ensuremath{\dim_{\Sigma}}}

\newcommand{\LODecMat}{{\vec L}}
\newcommand{\RFmat}{\ensuremath{\Q_R}}
\newcommand{\RFvec}{\ensuremath{\f_R}}
\newcommand{\intMat}{\ensuremath{\R_I}}
\newcommand{\h}{\vec{h}}
\newcommand{\T}{\vec{T}}

\newcommand{\Qspace}{\mathcal{Q}}

\newcommand{\ispecial}{j}
\newcommand{\ispecialTwo}{y}

\newcommand{\FSRSoffset}{\ensuremath{\omega}}

\begin{acronym}
 \acro{BMD}{bounded minimum distance}
 \acro{SRS}{skew Reed--Solomon}
 \acro{ISRS}{interleaved skew Reed--Solomon}
 \acro{FSRS}{folded skew Reed--Solomon}
 \acro{FRS}{folded Reed--Solomon}
 \acro{lclm}{least common left multiple}
 \acro{RS}{Reed--Solomon}
 \acro{LRS}{linearized Reed--Solomon}
 \acro{LLRS}{lifted linearized Reed--Solomon}
 \acro{ILRS}{interleaved linearized Reed--Solomon}
 \acro{LILRS}{lifted interleaved linearized Reed--Solomon}
 \acro{FLRS}{folded linearized Reed--Solomon}
 \acro{MSRD}{maximum sum-rank distance}
 \acro{KL}{Kullback--Leibler}
\end{acronym}

\begin{document}

\title{Interpolation-Based Decoding of Folded Variants \\ of Linearized and Skew Reed--Solomon Codes}

\author{
    Felicitas HÃ¶rmann$^{1,2}$\,\orcidlink{0000-0003-2217-9753} \and
    Hannes Bartz$^{1}$\,\orcidlink{0000-0001-7767-1513}\\
    \email{$\{$felicitas.hoermann, hannes.bartz$\}$@dlr.de}
}

\institute{
    \centering
    $^1$Institute of Communications and Navigation\\
    German Aerospace Center (DLR)\\
    Oberpfaffenhofen-Wessling, Germany
    \\[10pt]
    \centering
    $^2$School of Computer Science\\
    University of St. Gallen\\
    St. Gallen, Switzerland
}

\maketitle

\begin{abstract}
    The sum-rank metric is a hybrid between the Hamming metric and the rank metric and suitable for error correction in multishot network coding and distributed storage as well as for the design of quantum-resistant cryptosystems.
    In this work, we consider the construction and decoding of \ac{FLRS} codes, which are shown to be \ac{MSRD} for appropriate parameter choices.
    We derive an efficient interpolation-based decoding algorithm for \ac{FLRS} codes that can be used as a list decoder or as a probabilistic unique decoder.
    The proposed decoding scheme can correct sum-rank errors beyond the unique decoding radius with a computational complexity that is quadratic in the length of the unfolded code.
    We show how the error-correction capability can be optimized for high-rate codes by an alternative choice of interpolation points.
    We derive a heuristic upper bound on the decoding failure probability of the probabilistic unique decoder and verify its tightness by Monte Carlo simulations.
    Further, we study the construction and decoding of \acl{FSRS} codes in the skew metric.
    Up to our knowledge, \ac{FLRS} codes are the first \ac{MSRD} codes with different block sizes that come along with an efficient decoding algorithm.
\end{abstract}

\keywords{folded linearized Reed--Solomon codes, folded skew Reed--Solomon codes, interpolation-based decoding, sum-rank metric, skew metric}

\noindent
\textbf{MSC Classification:} 94B35, 94B05

\acresetall


\section{Introduction} \label{sec:introduction}

The sum-rank metric was first considered in~\cite{lu2005unified} in the context of space-time coding and covers the
Hamming metric as well as the rank metric as special cases.
Alternative decoding metrics as the sum-rank metric are of great interest to the field of code-based
cryptography (see e.g.~\cite{puchinger2020generic}).
Other applications range from error control in multishot network coding as described in~\cite{martinez2019reliable}
and~\cite{nobrega2010multishot} to the construction of locally repairable codes~\cite{martinez2019universal}.

Mart{\'\i}nez-Pe{\~n}as introduced \acf{LRS} codes, which generalize the well-studied families of \ac{RS} and Gabidulin
codes, in~\cite{martinez2018skew}.
\ac{LRS} codes are \acf{MSRD} codes, that is their minimum distance achieves the Singleton-like bound with equality.

While codewords of sum-rank-metric codes are commonly defined as tuples containing matrices of arbitrary sizes, most known constructions
use the same number of rows for every matrix in the tuple.
Some examples of \ac{MSRD} codes with different numbers of rows for the matrices can be found
in~\cite{byrne2021fundamental,camps2022optimal}.
Another construction for \ac{MSRD} codes with this property is given in~\cite{chen2022linear,chen2022new}.
However, no efficient decoding algorithm has been developed for such codes up to our knowledge.
We address this by presenting the family of \ac{FLRS} codes along with an efficient interpolation-based decoding
algorithm that can be used for list and probabilistic unique decoding.

We further apply our results to the skew-metric regime where we fold \ac{SRS} codes.
\ac{SRS} codes were introduced and studied in~\cite{boucher2014linear,liu2015construction} with respect to
Hamming metric and rank metric.
The work~\cite{martinez2018skew} defined the skew metric and analyzed \ac{SRS} codes in this new context.
In fact, it was shown that the sum-rank metric and \ac{LRS} codes are the linearized version of the skew metric and
\ac{SRS} codes, respectively.

The idea of folding constructions in coding evolved in the Hamming-metric context with Parvaresh--Vardy
codes~\cite{parvaresh2005correcting} and \acl{FRS} codes~\cite{Guruswami2008Explicit,brauchle2015}.
Folded Gabidulin codes and their efficient decoding in the rank metric were studied
in~\cite{bartz2017algebraic,BartzSidorenko_FoldedGabidulin2015_DCC,bartz2015list}.

\paragraph{Contributions}
Note that parts of this work were presented at WCC 2022: The Twelfth International Workshop on Coding and Cryptography
(see~\cite{hoermann2022efficient}).

We define the family of \ac{FLRS} codes and derive an interpolation-based decoding framework for these codes.
In contrast to~\cite{hoermann2022efficient}, we allow
different block sizes in the underlying unfolded code as well as the usage of different folding parameters.
This yields codes whose codewords are matrix tuples consisting of matrices having not the same size.
We further lift the restriction to skew polynomials with zero derivation and also deal with nonzero derivations.

As in~\cite{hoermann2022efficient}, we show how the decoding scheme can be used for list and probabilistic unique
decoding and give bounds on the list size and the failure probability, respectively.
We have performed several Monte Carlo simulations that verify the heuristic upper bound on the failure probability
empirically.
Moreover, new simulations show the reasonability of an assumption which is needed to obtain the heuristic bound.

A Justesen-like approach, which yields an improved interpolation-based decoding scheme for high-rate \ac{FLRS} codes,
and the discussion of implications for the skew metric are completely new topics in this work.
More precisely, we introduce \ac{FSRS} codes in the skew metric in a similar fashion as \ac{FLRS} codes and show how the proposed \ac{FLRS} decoding scheme can be applied.

\paragraph{Outline}
We start by giving some preliminaries in~\autoref{sec:preliminaries} before defining \ac{FLRS} codes and studying
their minimum distance in~\autoref{sec:flrs-codes}.

The main part of this paper is~\autoref{sec:decoding} in which we present and investigate an interpolation-based
decoding scheme for \ac{FLRS} codes.
The decoder consists of an interpolation step and a root-finding step which are explained in detail
in~\autoref{subsec:interpolation-step} and~\autoref{subsec:root-finding-step}, respectively.
\autoref{subsec:list-and-probabilistic-decoding} shows how the presented scheme can be used for list and probabilistic
unique decoding.
In particular, we derive an upper bound on the list size in the first case and on the failure probability in the latter.
\autoref{subsec:improved_high_rate} introduces a variant of the decoding scheme that is tailored to high-rate codes by
using a different set of interpolation points.
Since the bound on the failure probability for probabilistic unique decoding
from~\autoref{subsec:list-and-probabilistic-decoding} is heuristic, we empirically verify its validity by simulations in
SageMath in~\autoref{subsec:simulation_results}.

\autoref{sec:implications-fsrs} deals with the implications of our results for the skew-metric setting.
We give some background on the remainder evaluation of skew polynomials and the skew metric
in~\autoref{subsec:preliminaries-on-remainder-evaluation} and introduce \ac{FSRS} codes
in~\autoref{subsec:skew-metric-folded}.
\autoref{subsec:decoding-of-fsrs-codes} shows how the presented decoder for \ac{FLRS} codes in the sum-rank metric can
be applied to \ac{FSRS} codes in the skew metric.

Finally,~\autoref{sec:conclusion} concludes the paper by summarizing our work and giving open problems and directions
for further research.


\section{Preliminaries} \label{sec:preliminaries}

Let $q$ be a prime power and let $\Fq$ be a finite field of order $q$.
For any $m \in \NN^{\ast}$, let $\Fqm \supseteq \Fq$ denote an extension field with $q^m$ elements.
We call $\pe \in \Fqm$ \emph{primitive} in $\Fqm$ if it generates the multiplicative group
$\Fqm^{\ast} \defeq \Fqm \setminus \{0\}$.

An \emph{(integer) composition} of $\len \in \NN^{\ast}$ into $\shots \in \NN^{\ast}$ parts, which is also called an
\emph{$\shots$-composition} for short, is a vector $\lenVec = (\lenShot{1}, \dots, \lenShot{\shots}) \in \NN^{\shots}$ with
$\lenShot{i} > 0$ for all $1 \leq i \leq \shots$ that satisfies $\len = \sum_{i=1}^{\shots} n_i$.
We use the notation $\Fq^{\lenVec} \defeq \Fq^{\lenShot{1}} \times \dots \times \Fq^{\lenShot{\shots}}$ to describe the
space of $\Fq^{\len}$-vectors that are divided into $\shots$ blocks with respect to a given $\shots$-composition
$\lenVec$ of $\len$.
Similarly, we write $\Fq^{\heightVec \times \lenVec} \defeq \Fq^{\heightShot{1} \times \lenShot{1}} \times \dots
\times \Fq^{\heightShot{\shots} \times \lenShot{\shots}}$ for $\shots$-compositions $\heightVec$ of $\height$ and
$\lenVec$ of $\len$.
In the following, we always assume $\heightVec \leq \lenVec$ with respect to the product order on $\NN^{\shots}$, that is
$\heightShot{i} \leq \lenShot{i}$ holds for each $i = 1, \dots, \shots$.
\begin{definition}[Sum-Rank Metric]
    The \emph{sum-rank weight} of a tuple
    $\X = ( \shot{\X}{1}, \dots,\allowbreak \shot{\X}{\shots} ) \in \Fq^{\heightVec \times \lenVec}$ is
    \begin{equation}
        \SumRankWeight(\mat{X}) \defeq \sum_{i=1}^{\shots} \rk_q\left(\mat{X}^{(i)}\right)
    \end{equation}
    and the vector $\t = (t_1, \dots, t_{\shots}) \in \NN^{\shots}$ with $t_i \defeq \rk_q \left( \mat{X}^{(i)} \right)$
    for all $i = 1, \dots, \shots$ is called the \emph{weight decomposition} of $\X$.

    The \emph{sum-rank metric} $\SumRankDist$ is defined as
    \begin{equation}
        \SumRankDist(\X, \Y) \defeq \SumRankWeight(\X - \Y)
    \end{equation}
    for two elements $\X, \Y \in \Fq^{\heightVec \times \lenVec}$.
\end{definition}

A \emph{linear sum-rank-metric code} $\mycode{C}$ is an $\Fq$-linear subspace of the metric space
$(\Fq^{\heightVec \times \lenVec},\allowbreak \SumRankDist)$.
Its \emph{minimum (sum-rank) distance} is
\begin{align}
    \SumRankDist(\mycode{C}) &= \min \{\SumRankDist(\C_1, \C_2): \C_1, \C_2 \in \mycode{C}, \C_1 \neq \C_2 \}
    \\
    &= \min \{ \SumRankWeight(\C) : \C \in \mycode{C}, \C \neq 0 \}.
\end{align}

If $\heightVec = (m, \dots, m)$ for some $m \in \NN^{\ast}$, we sometimes write codewords
as $(m \times \len)$-matrices over $\Fq$ instead of matrix tuples from $\Fq^{\heightVec \times \lenVec}$.
Moreover, a code $\mycode{C}$ in this ambient space has a vector-code representation $\mycode{C}_{vec} \defeq
\{ \extInv_{\vecgamma}(\C): \C \in \mycode{C} \} \subseteq \Fqm^{\len}$ over $\Fqm$.
Here, the map $\extInv_{\vecgamma}$ is the inverse of the \emph{extension map} $\ext_{\vecgamma}$ that extends
a vector $\a \in \Fqm^{\len}$ to a matrix $\A \in \Fq^{m \times \len}$ with respect to a fixed ordered $\Fq$-basis $\vecgamma
= (\gamma_1, \dots, \gamma_m)$ of $\Fqm$.
Namely,
\begin{align}
    \ext_{\vecgamma}: \quad \Fqm^{\len} &\to \Fq^{m \times \len},
    \\
    \a = (a_1, \dots, a_{\len}) &\mapsto \A =
    \begin{pmatrix}
        a_{1 1} & \dots & a_{1 \len} \\
        \vdots & \ddots & \vdots \\
        a_{m 1} & \dots & a_{m \len}
    \end{pmatrix}
    \text{ with } a_i = \sum_{j=1}^{m} a_{j i} \gamma_j \text{ for } 1 \leq i \leq \len.
\end{align}
Note that we omit the index $\vecgamma$ if the particular choice of the basis is irrelevant.


The \emph{Frobenius automorphism} of the field extension $\Fqm / \Fq$ is the map $\frob: \Fqm \to \Fqm$ with $\frob(x) = x^q$ for all
$x \in \Fqm$.
It is $\Fq$-linear, fixes $\Fq$ elementwise, and generates the group of all $\Fq$-linear automorphisms on $\Fqm$ with respect to function composition.
We focus on an arbitrary $\Fq$-linear automorphism $\aut$ on $\Fqm$ in the following.
In particular, $\aut = \theta^{\frobPar}$ holds for a $\frobPar \in \{0, \dots, m-1\}$.
A \emph{$\aut$-derivation} is a map $\der: \Fqm \to \Fqm$ satisfying
\begin{equation}
    \der(a + b) = \der(a) + \der(b)
    \quad \text{and} \quad
    \der(ab) = \der(a)b + \aut(a)\der(b)
    \quad \text{for all } a, b \in \Fqm.
\end{equation}
Since we work over finite fields, any $\aut$-derivation is an \emph{inner derivation} which means that $\der = \derPar (\Id - \aut)$
for a $\derPar \in \Fqm$ and the identity $\Id$ (see~\cite[Prop.~44]{martinez2018skew}).

Two elements $a, b \in \Fqm$ are called \emph{$(\aut, \der)$-conjugate} if there is a $c \in \Fqm^{\ast}$ such that
$\conj{a}{c} \defeq \aut(c) a c^{-1} + \der(c) c^{-1} = b$.
This is an equivalence relation and $\Fqm$ is hence partitioned into \emph{conjugacy classes}
$\set{C}(a) \defeq \left\{ a^c : c \in \Fqm^{\ast} \right\}$ for $a \in \Fqm$ (see~e.g.~\cite{lam1985general,lam1988vandermonde}).
A counting argument shows that there are $q^{\gcd(\frobPar, m)}$ distinct conjugacy classes and all except
$\set{C}(\derPar)$ are called nontrivial.
If $\der = 0$ (i.e., $\derPar = 0$) and $\aut = \theta$, the powers $1, \pe, \dots, \pe^{q-2}$ of a primitive element $\pe \in \Fqm^{\ast}$
are representatives of all $q^{\gcd(1,m)}-1 = q-1$ distinct nontrivial conjugacy classes.

The \emph{skew polynomial ring} $\SkewPolyring$ is defined as the set of polynomials $\sum_i f_i x^i$ with finitely many
nonzero coefficients $f_i \in \Fqm$.
It forms a non-commutative ring with respect to ordinary polynomial addition and multiplication determined by the rule
$x f_i = \aut(f_i) x + \der(f_i)$ for all $f_i \in \Fqm$.
We define the \emph{degree} of a skew polynomial $f(x) = \sum_i f_i x^i$ as $\deg(f) \defeq \max \{i : f_i \neq 0\}$ and
write $\SkewPolyring_{<k} \defeq \{ f \in \SkewPolyring: \deg(f) < k \}$ for the set of skew polynomials
of degree less than $k \geq 0$.

We further introduce the operator $\op{a}{b} \defeq \aut(b) a + \der(b)$ for any $a, b \in \Fqm$ and we write
$\opexp{a}{b}{i} \defeq \op{a}{\opexp{a}{b}{i-1}}$ for its $i$-th power with $i \in \NN^{\ast}$.
Let $\lenVec = (\lenShot{1}, \dots, \lenShot{\shots}) \in \NN^{\shots}$ be an $\shots$-composition of $\len \in \NN^{\ast}$.
For a vector $\x = \left(\x^{(1)}, \dots, \x^{(\shots)}\right) \in \Fqm^{\lenVec}$, a vector
$\a = (a_1, \ldots, a_\shots) \in \Fqm^{\shots}$, and a parameter $d \in \NN^{\ast}$ the \emph{generalized Moore matrix}
$\opMoore{d}{\x}{\a}$ is defined as
\begin{align}\label{eq:def_gen_moore_mat}
    \opMoore{d}{\x}{\a} &\defeq
    \left( \opVandermonde{d}{\x^{(1)}}{a_1}, \dots, \opVandermonde{d}{\x^{(\shots)}}{a_\shots} \right)
    \in \Fqm^{\d \times \lenVec},
    \\
    \text{where }
    \opVandermonde{d}{\x^{(i)}}{a_i} &\defeq
    \begin{pmatrix}
        x^{(i)}_1 & \cdots & x^{(i)}_{\lenShot{i}}
        \\
        \op{a_i}{x^{(i)}_1} & \cdots & \op{a_i}{x^{(i)}_{\lenShot{i}}}
        \\[-4pt]
        \vdots & \ddots & \vdots
        \\
        \opexp{a_i}{x^{(i)}_1}{d-1} & \cdots & \opexp{a_i}{x^{(i)}_{\lenShot{i}}}{d-1}
    \end{pmatrix}
    \quad \text{for } 1 \leq i \leq \shots
    \notag
\end{align}
and $\d \defeq (d, \dots, d) \in \NN^{\shots}$.
If $\a$ contains representatives of pairwise distinct nontrivial conjugacy classes of $\Fqm$ and $\rk_{q}\left(\x^{(i)}\right) =
\lenShot{i}$ for all $1 \leq i \leq \shots$, we have by~\cite[Thm.~2]{martinez2018skew}
and~\cite[Thm~4.5]{lam1988vandermonde} that $\rk_{q^m}\left(\opMoore{d}{\x}{\a}\right) = \min(d, \len)$.

The \emph{generalized operator evaluation} of a skew polynomial $f \in \SkewPolyring$ at $b \in \Fqm$ with respect to
the evaluation parameter $a \in \Fqm$ is defined as $\opev{f}{b}{a} = \sum_{i} f_i \opexp{a}{b}{i}$ and can be written in vector-matrix form
using the generalized Moore matrix from~\eqref{eq:def_gen_moore_mat}.
For $\a = (a_1, \dots, a_{\shots}) \in \Fqm^\shots$ and $\x = (\shot{\x}{1}, \dots,
\shot{\x}{\shots}) \in \Fqm^\lenVec$ we use the shorthand notation
\begin{equation}
    \opev{f}{\x}{\a} \defeq (\opev{f}{\shot{\x}{1}}{a_1}, \dots, \opev{f}{\shot{\x}{\shots}}{a_\shots}) \in \Fqm^\lenVec.
\end{equation}
Let $a_1, \dots, a_{\shots}$ be representatives of distinct nontrivial conjugacy classes of $\Fqm$ and consider
$\lenShot{i}$ $\Fq$-linearly independent elements $\zeta_1^{(i)}, \dots, \zeta_{\lenShot{i}}^{(i)} \in \Fqm$ for each
$i = 1, \dots, \shots$.
Then any nonzero $f \in \SkewPolyring$ satisfying $\opev{f}{\zeta_j^{(i)}}{a_i} = 0$ for all $1 \leq j \leq \lenShot{i}$
and all $1 \leq i \leq \shots$ has degree at least $\sum_{i=1}^{\shots} \lenShot{i}$ (see
e.g.~\cite{caruso2019residues}).
\begin{definition}[\Acl{LRS} Codes~{\cite[Def.~31]{martinez2018skew}}]
    \label{def:lrs-codes}
	Let $\a = (a_1, \dots,\allowbreak a_\shots) \allowbreak \in \Fqm^{\shots}$ contain representatives of pairwise distinct
	nontrivial conjugacy classes of $\Fqm$ and consider an $\shots$-composition
    $\n \defeq (n_1, \dots, n_\shots) \in \NN^{\shots}$ of $n \in \NN$.
    Let the vectors $\vecbeta^{(i)} = (\beta_1^{(i)}, \dots, \beta_{n_i}^{(i)}) \in \Fqm^{n_i}$ contain $\Fq$-linearly
    independent elements for all $i = 1, \dots, \shots$ and define
    $\vecbeta \defeq (\vecbeta^{(1)}, \dots, \vecbeta^{(\shots)}) \in \Fqm^{\lenVec}$.
    A \emph{\acl{LRS} code} of length $n$ and dimension
    $k \leq n$ is defined as
    \begin{equation}
        \linRS{\vecbeta,\a;\n,k} \defeq \left\{
        \opev{f}{\vecbeta}{\a}
        : f \in \SkewPolyring_{<k} \right\} \subseteq \Fqm^{\lenVec}.
    \end{equation}
\end{definition}

Observe that the parameter restrictions in~\autoref{def:lrs-codes} also imply restrictions on the length that \ac{LRS} codes can achieve.
Since the evaluation parameters $a_1, \dots, a_{\shots}$ have to belong to distinct nontrivial conjugacy classes, the number of blocks $\shots$
is upper bounded by the number of these classes.
As we know from~\autoref{sec:preliminaries}, $\Fqm$ has $q^{\gcd(u,m)}-1$ distinct nontrivial conjugacy classes, where
$u \in \{0, \dots, m-1\}$ is
defined by the equality $\aut = \theta^u$ for the Frobenius automorphism $\theta$ of $\Fqm/\Fq$.
Thus, $\shots \leq q^{\gcd(u,m)}-1$ has to apply.
At the same time, the code locators $\shot{\vecbeta}{i}$ of the $i$-th block have to contain $\Fq$-linearly
independent elements for all $i = 1, \dots, \shots$ which implies $\lenShot{i} \leq m$.
This means that the length $n$ of an \ac{LRS} code is always bounded by $n \leq (q^{\gcd(u,m)}-1) \cdot m$.

The next lemma is taken from~\cite[Lemma~III.12]{byrne2021fundamental} and lays the foundation for a Singleton-like
bound for sum-rank-metric codes with different block sizes.

\begin{lemma} \label{lem:maximize_elementwise_product}
    Consider an $\shots$-composition $\n = (\lenShot{1}, \dots, \lenShot{\shots})$ of $\len \in \NN$ and a vector
    $\heightVec = (\heightShot{1}, \dots, \heightShot{\shots}) \in \NN^{\shots}$ with $\heightShot{1} \geq \dots \geq \heightShot{\shots} > 0$ and
    $\lenVec \leq \heightVec$.
    Define the set
    \begin{equation}
        \set{U}_z \defeq \left\{ \z = (z_1, \dots, z_{\shots}) \in \NN^{\shots} : \z \leq \lenVec \text{ and }
        \sum_{i=1}^{\shots} z_i = z \right\}
    \end{equation}
    for each $z \in \{0, \dots, \len\}$.
    If we denote by $\ispecial \in \{1, \dots, \shots\}$ and $\lambda \in \{0, \dots, \lenShot{\ispecial} - 1\}$ the unique
    integers that satisfy $\sum_{i=1}^{\ispecial - 1} \lenShot{i} + \lambda = z$,
    then it holds
    \begin{equation}
        \max \left\{ \sum_{i=1}^{\shots} \heightShot{i} z_i : (z_1, \dots, z_{\shots}) \in \set{U}_z \right\}
        = \sum_{i=1}^{\ispecial - 1} \heightShot{i} \lenShot{i} + \heightShot{\ispecial} \lambda.
    \end{equation}
\end{lemma}

We can think about this result in the context of a matrix tuple from $\Fq^{\m \times \n}$ where we are allowed to mark
$z$ columns.
Our goal is then to maximize the number of marked entries which is given as $\sum_{i=1}^{\shots} \heightShot{i} z_i$.
Since the matrices are sorted descendingly with respect to their number of rows, the logical strategy is to mark the
first $z$ columns.
The index $\ispecial$ then corresponds to the first block for which we cannot mark every column anymore.

\begin{theorem}[Singleton-like Bound~{\cite[Thm.~III.2]{byrne2021fundamental}}] \label{thm:singleton_bound}
    Let $\heightVec = (\heightShot{1}, \dots, \heightShot{\shots})$ and $\lenVec = (\lenShot{1}, \dots,
    \lenShot{\shots})$ be integer vectors with $\heightShot{1} \geq \dots \geq \heightShot{\shots} > 0$ and
    $0 < \lenShot{i} \leq \heightShot{i}$ for all $i \in \{1, \dots, \shots\}$.
    Consider a sum-rank-metric code $\mycode{C} \subseteq \Fq^{\heightVec \times \lenVec}$ with
    $\vert \mycode{C} \vert \geq 2$ and $\SumRankDist(\mycode{C}) = d$.
    Then,
    \begin{equation} \label{eq:singleton_bound}
        \vert \mycode{C} \vert
        \leq q^{\sum_{i = \ispecial}^{\shots} \heightShot{i} \lenShot{i} - \heightShot{\ispecial} \lambda},
    \end{equation}
    where $\ispecial \in \{1, \dots, \shots\}$ and $0 \leq \lambda < \lenShot{\ispecial}$ are the unique integers
    such that $d - 1 = \sum_{i=1}^{\ispecial - 1} \lenShot{i} + \lambda$ holds.
\end{theorem}

Note that~\autoref{thm:singleton_bound} generalizes the statements~\cite[Prop.~34]{martinez2018skew} and~\cite[Cor.~2]{martinez2019universal}
that were derived for codes with $\heightShot{1} = \dots = \heightShot{\shots}$.


\section{Folded Linearized Reed--Solomon Codes} \label{sec:flrs-codes}

Code classes obtained by a folding construction have been considered starting from \ac{RS} and Gabidulin codes
in~\cite{Guruswami2008Explicit} and~\cite{BartzSidorenko_FoldedGabidulin2015_DCC,bartz2017algebraic}, respectively.
Let us describe the folding process for a codeword $\c$ of length $n$ and a folding parameter $h$ that divides $n$.
We obtain the folded codeword by subdividing $\c$ into $\frac{n}{h}$ pieces of length $h$ and using them as columns of a
matrix of size $h \times \frac{n}{h}$.
The folded code is simply the collection of all folded codewords.

The folding operation can be expressed by means of the \emph{folding operator}
\begin{align}
    \foldOp{\foldPar}: \qquad \qquad \qquad \Fqm^{\len} &\to \Fqm^{\foldPar \times \lenFLRS} \\
    (x_1, \dots, x_{\len}) &\mapsto
    \begin{pmatrix}
        x_1 & x_{\foldPar + 1} & \dots & x_{\len - \foldPar + 1} \\
        x_2 & x_{\foldPar + 2} & \dots & x_{\len - \foldPar + 2} \\
        \vdots & \vdots & \ddots & \vdots \\
        x_{\foldPar} & x_{2 \foldPar} & \dots & x_{\len}
    \end{pmatrix}
\end{align}
where $\len, \lenFLRS \in \NN^{\ast}$ denote the length of the unfolded and folded vector, respectively, and where the
folding parameter $\foldPar \in \NN^{\ast}$ divides $\len$ with $\lenFLRS = \frac{\len}{\foldPar}$.
Its inverse allows to \emph{unfold} a matrix and is denoted by $\foldOpInv{\foldPar}$.

This paper focuses on folding \ac{LRS} codes which are a generalization of both \ac{RS} and Gabidulin codes.
Since \ac{LRS} codes are naturally equipped with a block structure, we apply the described folding mechanism blockwise
to obtain \ac{FLRS} codes.
Observe that since the length of the blocks may vary, we may choose a different folding parameter
for each block.
This produces sum-rank-metric codes whose codeword tuples consist of matrices with different numbers of rows and columns.
A visual representation of the folding construction for a particular block of an \ac{LRS} codeword is given
in~\autoref{fig:folding}.
A formal description is the following generalization of the above discussed folding operator:
\begin{align}
    \foldOp{\foldParVec}: \qquad \qquad \qquad \Fqm^{\lenVec} &\to \Fqm^{\foldParVec \times \lenFLRSVec} \\
    \left( \shot{\x}{1}, \dots, \shot{\x}{\shots} \right) &\mapsto
    \left( \foldOp{\foldParShot{1}}(\shot{\x}{1}), \dots, \foldOp{\foldParShot{\shots}}(\shot{\x}{\shots}) \right).
\end{align}
Here, vectors of length $\len$ are divided into $\shots$ blocks according to the $\shots$-composition $\lenVec$ and the
vector $\foldParVec = (\foldParShot{1}, \dots, \foldParShot{\shots})$ contains the different folding parameters for the
blocks.
The corresponding inverse map, i.e. the blockwise \emph{unfolding operation}, is denoted by $\foldOpInv{\foldParVec}$.

\begin{definition}[Folded Linearized Reed--Solomon Codes]
    \label{def:flrs-codes}
    Consider an \ac{LRS} code $\mycode{C} \defeq \linRS{\vecbeta,\a;\n,k}$ with $\shot{\vecbeta}{i} \defeq
    (1, \pe, \dots, \pe^{\lenShot{i}-1}) \in \Fqm^{\lenShot{i}}$ for a primitive element
    $\pe$ of $\Fqm$ and all $i = 1, \dots, \shots$.
    Choose a vector $\foldParVec = (\foldParShot{1}, \dots, \foldParShot{\shots}) \in \NN^{\shots}$ of folding
    parameters satisfying $\foldParShot{i} \divides \lenShot{i}$ and $\lenFLRSshot{i} \defeq \frac{\lenShot{i}}{\foldParShot{i}} \leq \foldParShot{i}$ for all $1 \leq i \leq \shots$ and write
    $\N \defeq (\lenFLRSshot{1}, \dots, \lenFLRSshot{\shots})$.
    The $\foldParVec$-folded variant of $\mycode{C}$ is the \emph{$\foldParVec$-folded \acl{LRS} code}
    $\foldedLinRS{\pe, \a, \foldParVec; \lenFLRSVec, k}$ of length $\lenFLRS \defeq \sum_{i=1}^{\shots} \lenFLRSshot{i}$
    and dimension $k$ defined as
    \begin{equation}
        \left\{
        \foldOp{\foldParVec}( \opev{f}{\vecbeta}{\a} )
        = \left(
        \foldOp{\foldParShot{1}}( \opev{f}{\vecbeta^{(1)}}{a_1} ), \dots,
        \foldOp{\foldParShot{\shots}}( \opev{f}{\vecbeta^{(\shots)}}{a_\shots} )
        \right) : f \in \SkewPolyring_{<k} \right\}.
    \end{equation}
\end{definition}

The ambient space of this code is $\Fqm^{\foldParVec \times \lenFLRSVec}$
and we can interpret the folded code as vector code of length $\lenFLRS$ over the field $\Fqd$ with extension degree
$d \defeq m \cdot \lcm (\foldParShot{1}, \dots, \foldParShot{\shots})$ over $\Fq$.
However, linearity is only guaranteed with respect to the subfield $\Fqm$ and due to the $\Fqm$-linearity of the unfolded
\ac{LRS} code.

To make the above definition more explicit, note that there is a message polynomial $f \in \SkewPolyring_{<k}$ for
every codeword $\C \in \foldedLinRS{\pe, \a, \foldParVec; \lenFLRSVec, k} \subseteq
\Fqm^{\foldParVec \times \lenFLRSVec}$ with
\begin{equation}
    \C = \left( \C^{(1)}(f), \dots, \C^{(\shots)}(f) \right)
\end{equation}
\begin{equation}\label{eq:defFLRScodeblock}
    \text{and }
    \C^{(i)}(f) \defeq
    \begin{pmatrix}
        \opev{f}{1}{a_i} & \opev{f}{\pe^{\foldParShot{i}}}{a_i} & \cdots
        & \opev{f}{\pe^{\lenShot{i}-\foldParShot{i}}}{a_i}
        \\
        \opev{f}{\pe}{a_i} & \opev{f}{\pe^{\foldParShot{i}+1}}{a_i} & \cdots
        & \opev{f}{\pe^{\lenShot{i}-\foldParShot{i}+1}}{a_i}
        \\
        \vdots & \vdots & \ddots & \vdots
        \\
        \opev{f}{\pe^{\foldParShot{i}-1}}{a_i} & \opev{f}{\pe^{2\foldParShot{i}-1}}{a_i} & \cdots
        & \opev{f}{\pe^{\lenShot{i}-1}}{a_i}
    \end{pmatrix}
    \in \Fqm^{\foldParShot{i} \times \lenFLRSshot{i}}
\end{equation}
for all $i \in \{1, \ldots, \shots\}$.

We can further draw conclusions about the maximum length of \ac{FLRS} codes, similar to the \ac{LRS} case.
Let us therefore assume that the parameters of the unfolded code are maximal.
In other words, choose an \ac{LRS} code $\mycode{C}$ in~\autoref{def:flrs-codes} with $\shots = q^{\gcd(u,m)} - 1$
same-sized blocks of length $m$ and resulting overall code length $\len = (q^{\gcd(u,m)} - 1) \cdot m$ (see~\autoref{sec:preliminaries} for the definition of $u$ and the derivation of this statement).
Since we want to maximize the length of the folded code, we choose $\foldParShot{i}$ for each $i = 1, \dots, \shots$ as small as possible such that
$\foldParShot{i} \divides \lenShot{i}$ and $\lenFLRSshot{i} \defeq \frac{\lenShot{i}}{\foldParShot{i}} \leq \foldParShot{i}$ hold.
As all blocks have the same length, we select the same folding parameter $h$ for each block and it has to satisfy
$h \divides m$ and $m \leq h^2$.
We cannot get any better than $h = \sqrt{m}$ and thus obtain the upper bound $\lenFLRS \leq (q^{\gcd(u,m)} - 1) \cdot \sqrt{m}$
on the total length $\lenFLRS$ of \ac{FLRS} codes.

\begin{remark}
    Note that we only consider a subclass of \ac{LRS} codes for folding.
	Namely, we choose the code locators as powers of a primitive element $\pe \in \Fqm^{\ast}$.
	This turns out to be crucial for the interpolation-based decoder that we present in~\autoref{sec:decoding}.
\end{remark}

\begin{figure}
    \centering
    \begin{subfigure}[b]{.48\textwidth}
        \centering
        \resizebox{\textwidth}{!}{%
\begin{tikzpicture}
	\foreach \x [count=\i] in {0,...,11} {
		\node (node\x) at (.5*\x, 0) {$c_{\i}$};
	}

	\foreach \b in {1,4,7,10} {
		\node (block\b) at (.5*\b, 0) [draw, minimum width=1.5cm, minimum height=.5cm] {};
	}
\end{tikzpicture}
        }
        \caption{Codeword block $\shot{\c}{i} = (c_1, \dots, c_{12})$ cut into blocks of length $h_i=3$.}
        \label{fig:folding-2}
    \end{subfigure}
    \vspace*{.3cm}
    \hfill
    \begin{subfigure}[b]{.48\textwidth}
        \centering
        \resizebox{\textwidth}{!}{%
\begin{tikzpicture}
	\foreach \y [count=\i] in {0,1,2} {
		\node (node\y) at (.5, -\y/2+.5) {$c_{\i}$};
	}
	\foreach \y [evaluate=\y as \i using int(\y+1)] in {3,4,5} {
		\node (node\y) at (2.5, -\y/2+2) {$c_{\i}$};
	}
	\foreach \y [evaluate=\y as \i using int(\y+1)] in {6,7,8} {
		\node (node\y) at (4.5, -\y/2+3.5) {$c_{\i}$};
	}
	\foreach \y [evaluate=\y as \i using int(\y+1)] in {9,10,11} {
		\node (node\y) at (6.5, -\y/2+5) {$c_{\i}$};
	}

	\foreach \b in {.5,2.5,4.5,6.5} {
		\node (block\b) at (\b, 0) [draw, minimum width=.5cm, minimum height=1.5cm] {};
	}

	\draw [blue] (.5, 1) -- (.5, -1) -- (2.5, 1) -- (2.5, -1) -- (4.5, 1) -- (4.5, -1) -- (6.5, 1) -- (6.5, -1);
\end{tikzpicture}
        }
        \caption{$3$-folded version of $\shot{\c}{i}$. The blue line illustrates the terminology ``folding''.}
        \label{fig:folding-5}
    \end{subfigure}
    \caption{
        Illustration of the folding construction for a block $\c^{(i)} = (c_1, \ldots, c_{12})$ of an \ac{LRS}
        codeword $\c = (\shot{\c}{1}, \dots, \shot{\c}{\shots})$ using folding parameter $h_i=3$.
    }
    \label{fig:folding}
\end{figure}

\begin{theorem}[Minimum Distance]\label{thm:minimum_distance_flrs}
    Let $\mycode{C} \defeq \foldedLinRS{\pe, \a, \foldParVec; \lenFLRSVec, k}$ be an \ac{FLRS} code and assume without
    loss of generality that $\foldParShot{1} \geq \dots \geq \foldParShot{\shots}$ applies.
    The minimum sum-rank distance of $\mycode{C}$ is
    \begin{equation}
        \SumRankDist(\mycode{C}) = \sum_{i=1}^{\ispecial} \lenFLRSshot{i}
        - \left\lceil \frac{k - \sum_{i=\ispecial + 1}^{\shots} \foldParShot{i} \lenFLRSshot{i} - 1}
        {\foldParShot{\ispecial}} \right\rceil + 1,
    \end{equation}
    where $\ispecial \in \{1, \dots, \shots\}$ is the unique choice that satisfies
    \begin{equation}
        0 \leq \SumRankDist(\mycode{C}) - \sum_{i=1}^{\ispecial - 1} \lenFLRSshot{i} - 1 <
        \lenFLRSshot{\ispecial}.
    \end{equation}
    In particular, $\mycode{C}$ achieves the Singleton-like bound~\eqref{eq:singleton_bound} with equality if and only if
    $\foldParShot{\ispecial}$ divides both $k$ and $\foldParShot{i} \lenFLRSshot{i}$ for all
    $i = \ispecial + 1, \dots, \shots$.
\end{theorem}

\begin{proof}
    Let $\C = (\shot{\C}{1}, \dots, \shot{\C}{\shots})\in \mycode{C}$ be the nonzero codeword corresponding to the message polynomial $f \in \SkewPolyring_{<k}$.
    Then there are $z, z_1, \dots, z_{\shots} \geq 0$ with $z = \sum_{i=1}^{\shots} z_i$ such that
    $\SumRankWeight(\C) = \lenFLRS - z$ and $\rk_q(\C^{(i)}) = \lenFLRSshot{i} - z_i$ for $i = 1, \dots, \shots$.
    Let us denote by $\RCEF(\C) \in \Fqm^{\foldParVec \times \lenFLRSVec}$ the blockwise-reduced column-echelon form of
    $\C$ which is obtained by bringing each block $\shot{\C}{i}$ independently in its reduced column-echelon form with
    respect to $\Fq$ as follows:
    first obtain a matrix $\shot{\C}{i}_q \in \Fq^{m \foldParShot{i} \times \lenShot{i}}$ by replacing each row of the
    block $\shot{\C}{i}$ with its extended matrix that is obtained via $\ext_{\vecgamma}$ for an arbitrary
    $\Fq$-basis $\vecgamma$ of $\Fqm$.
    Next, bring $\shot{\C}{i}_q$ in reduced column-echelon form (e.g. by Gaussian elimination) and finally apply the
    inverse operation $\extInv_{\vecgamma}$ to the matrix blocks and get back a
    $(\foldParShot{i} \times \lenShot{i})$-matrix over $\Fqm$.
    Since $\extInv_{\vecgamma}$ preserves the zero columns and $\rk_q(\C^{(i)}) = \lenFLRSshot{i} - z_i$,
    the number of nonzero columns in the $i$-th block of $\RCEF(\C)$ is $\lenFLRSshot{i} - z_i$.
    Thus, the overall number of nonzero entries is certainly upper-bounded by
    $\sum_{i=1}^{\shots} \foldParShot{i} (\lenFLRSshot{i} - z_i)$.
    We further obtain an upper bound on the last result by finding the vector $\z = (z_1, \dots, z_{\shots})$ that realizes
    \begin{equation}
        \max \left\{ \sum_{i=1}^{\shots} \foldParShot{i} (\lenFLRSshot{i} - z_i) : \lenFLRSVec - \z \leq \lenFLRSVec
        \text{ and } \lenFLRS - z = \sum_{i=1}^{\shots} z_i \right\}
    \end{equation}
    for a fixed $z$.
    With~\autoref{lem:maximize_elementwise_product}, the maximum equals
    $\sum_{i=1}^{\ispecialTwo - 1} \foldParShot{i} \lenFLRSshot{i} + \foldParShot{\ispecialTwo} \varepsilon$,
    where $\ispecialTwo \in \{1, \dots, \shots\}$ and $0 \leq \varepsilon < \lenFLRSshot{\ispecialTwo}$ are the unique
    integers such that $\lenFLRS - z = \sum_{i=1}^{\ispecialTwo - 1} \lenFLRSshot{i} + \varepsilon$.
    When we shift the focus to the zero entries of $\RCEF(\C)$, we naturally obtain the lower bound
    $\sum_{i=\ispecialTwo}^{\shots} \foldParShot{i} \lenFLRSshot{i} - \foldParShot{\ispecialTwo} \varepsilon$ with $y$
    and $\varepsilon$ as before,
    since the number of zero and nonzero entries adds up to $\sum_{i=1}^{\shots} \foldParShot{i} \lenFLRSshot{i}$.

    Note that the $\Fqm$-semilinearity of the generalized operator evaluation ensures that for each $1 \leq i \leq
    \shots$ the entries of the $i$-th block of $\RCEF(\C)$ are still $\Fq$-linearly independent and can be expressed as
    evaluations of $f$ with respect to the evaluation parameter $a_i$.
    Since the number of $\Fq$-linearly independent roots of $f$ with respect to evaluation parameters from distinct
    nontrivial conjugacy classes is bounded by its degree and $\deg(f) \leq k - 1$, we get
    \begin{equation} \label{eq:min_dist_proof_lower_bound}
        \sum_{i=\ispecialTwo}^{\shots} \foldParShot{i} \lenFLRSshot{i}
        - \foldParShot{\ispecialTwo} \varepsilon \leq k - 1
        \quad
        \begin{gathered}
            \text{for } \ispecialTwo \in \{1, \dots, \shots\}, \varepsilon \in \{0, \dots, \lenFLRSshot{\ispecialTwo} - 1\} \\
            \text{unique with } \lenFLRS - z = \sum\nolimits_{i=1}^{\ispecialTwo - 1} \lenFLRSshot{i} + \varepsilon.
        \end{gathered}
    \end{equation}
    On the other hand, the Singleton-like bound for $\Fq$-linear sum-rank-metric codes (see \autoref{thm:singleton_bound}) yields
    \begin{equation} \label{eq:min_dist_proof_upper_bound}
        k \leq \sum_{i = \ispecial}^{\shots} \foldParShot{i} \lenFLRSshot{i}
        - \foldParShot{\ispecial} \lambda
        \quad
        \begin{gathered}
            \text{for } \ispecial \in \{1, \dots, \shots\}, \lambda \in
            \{0, \dots, \lenFLRSshot{\ispecial} - 1\} \\
            \text{unique with } \SumRankDist(\mycode{C}) - 1 =
            \sum\nolimits_{i=1}^{\ispecial - 1} \lenFLRSshot{i} + \lambda.
        \end{gathered}
    \end{equation}
    As we can choose a minimum-weight codeword $\C$ in the above reasoning, we can replace $\lenFLRS - z$ by
    $\SumRankDist(\mycode{C})$ in~\eqref{eq:min_dist_proof_lower_bound}.
    But then there are only two possibilities for the relationship between the indices $\ispecialTwo$ and $\ispecial$
    and the parameters $\varepsilon$ and $\lambda$.
    Namely,
    \begin{enumerate}
        \item $\ispecial = \ispecialTwo$, \tabto{2.5cm} $\varepsilon \in \{1, \dots, \lenFLRSshot{\ispecialTwo} - 1\}$,
                \tabto{6.5cm} and \tabto{8cm} $\lambda = \varepsilon - 1$ \tabto{11cm} or
        \item $\ispecial = \ispecialTwo - 1$, \tabto{2.5cm} $\varepsilon = 0$, \tabto{6.5cm} and
                \tabto{8cm} $\lambda = \lenFLRSshot{\ispecialTwo - 1} - 1$.
    \end{enumerate}
    Let us focus on the first case.
    We get
    \begin{gather}
        \label{eq:min_dist_proof_transformation_start_lower_bound}
        \sum_{i=\ispecialTwo}^{\shots} \foldParShot{i} \lenFLRSshot{i}
        - \foldParShot{\ispecialTwo} \left( \SumRankDist(\mycode{C})
        - \sum_{i=1}^{\ispecialTwo - 1} \lenFLRSshot{i} \right) + 1 \leq k
    \end{gather}
    by substituting $\varepsilon$ for the equality condition in~\eqref{eq:min_dist_proof_lower_bound}.
    We then shift the first summand $\foldParShot{\ispecialTwo} \lenFLRSshot{\ispecialTwo}$ of the first sum into
    the second sum, do some transformations, and finally use the integrality of the left-hand side as well as the fact
    $\lfloor x \rfloor = \lceil x - 1 \rceil$ for any real number $x$ to obtain
    \begin{equation} \label{eq:min_dist_proof_transformed_lower_bound}
        \sum_{i=1}^{\ispecialTwo} \lenFLRSshot{i} - \SumRankDist(\mycode{C}) + 1
        \leq \left\lceil \frac{k - \sum_{i=\ispecialTwo + 1}^{\shots} \foldParShot{i} \lenFLRSshot{i} - 1}
        {\foldParShot{\ispecialTwo}} \right\rceil.
    \end{equation}
    Similarly, substituting $\lambda$ for the equality condition in~\eqref{eq:min_dist_proof_upper_bound} yields
    \begin{gather}
        k \leq
        \sum_{i = \ispecial}^{\shots} \foldParShot{i} \lenFLRSshot{i}
        - \foldParShot{\ispecial} \left( \SumRankDist(\mycode{C}) - 1
        - \sum_{i=1}^{\ispecial - 1} \lenFLRSshot{i} \right)
        \\
        \label{eq:min_dist_proof_transformed_upper_bound}
        \iff
        \left\lceil \frac{k - \sum_{i = \ispecial + 1}^{\shots} \foldParShot{i} \lenFLRSshot{i}}
        {\foldParShot{\ispecial}} \right\rceil
        \leq \sum_{i=1}^{\ispecial} \lenFLRSshot{i} - \SumRankDist(\mycode{C}) + 1.
    \end{gather}
    As $\ispecial = \ispecialTwo$ holds, the right-hand side of~\eqref{eq:min_dist_proof_transformed_lower_bound} is
    less than or equal to the left-hand side of~\eqref{eq:min_dist_proof_transformed_upper_bound}.
    But since the left-hand side of~\eqref{eq:min_dist_proof_transformed_lower_bound} and the right-hand side
    of~\eqref{eq:min_dist_proof_transformed_upper_bound} are equal, all inequalities in the chain must be equalities and
    we get
    \begin{equation} \label{eq:min_dist_proof_result}
        \SumRankDist(\mycode{C}) = \sum_{i=1}^{\ispecial} \lenFLRSshot{i}
        - \left\lceil \frac{k - \sum_{i=\ispecial + 1}^{\shots} \foldParShot{i} \lenFLRSshot{i} - 1}
        {\foldParShot{\ispecial}} \right\rceil + 1,
    \end{equation}
    where $\ispecial \in \{1, \dots, \shots\}$ is unique with $0 \leq
    \SumRankDist(\mycode{C}) - \sum\nolimits_{i=1}^{\ispecial - 1} \lenFLRSshot{i} - 1 <
    \lenFLRSshot{\ispecial}$.

    Let us move on to the second case and recall that $\varepsilon = 0$.
    Therefore, we can replace the factor $\foldParShot{\ispecialTwo}$ of $\varepsilon$ (i.e.\ of
    $\SumRankDist(\mycode{C}) - \sum_{i=1}^{\ispecialTwo - 1} \lenFLRSshot{i}$)
    in~\eqref{eq:min_dist_proof_transformation_start_lower_bound} with $\foldParShot{\ispecialTwo - 1}$.
    Similar transformations as above and again the integrality of the left-hand side yield
    \begin{equation} \label{eq:min_dist_proof_differently_transformed_lower_bound}
        \sum_{i=1}^{\ispecialTwo - 1} \lenFLRSshot{i} - \SumRankDist(\mycode{C}) + 1
        \leq \left\lceil \frac{k - \sum_{i=\ispecialTwo}^{\shots} \foldParShot{i} \lenFLRSshot{i} - 1}
        {\foldParShot{\ispecialTwo - 1}} \right\rceil.
    \end{equation}
    Since we have $\ispecial = \ispecialTwo - 1$ in this case, the right-hand side
    of~\eqref{eq:min_dist_proof_differently_transformed_lower_bound} is less than or equal to the left-hand side
    of~\eqref{eq:min_dist_proof_transformed_upper_bound}.
    But, as in the first case, the left-hand side of~\eqref{eq:min_dist_proof_differently_transformed_lower_bound} and
    the right-hand side of~\eqref{eq:min_dist_proof_transformed_upper_bound} are equal.
    Hence, the inequalities are in fact equalities and we obtain~\eqref{eq:min_dist_proof_result}.

    The Singleton-like bound is met if and only if $\foldParShot{\ispecialTwo}$ divides
    $k - \sum_{i=\ispecialTwo + 1}^{\shots} \foldParShot{i} \lenFLRSshot{i}$, which is equivalent to
    $\foldParShot{\ispecialTwo}$ dividing $k$ as well as $\foldParShot{i} \lenFLRSshot{i}$ for each
    $i = 1, \dots, \shots$.
    This concludes the proof.
\end{proof}

\begin{remark}
    \autoref{thm:minimum_distance_flrs} needs an \ac{FLRS} code to satisfy $\foldParShot{1} \geq \dots \geq
    \foldParShot{\shots}$ for technical reasons.
    However, this is not a restriction since we can simply reorder the blocks of a sum-rank-metric code without changing
    its weight distribution or its minimum distance.
    Formally speaking, we choose a permutation $\pi$ from the symmetric group $\set{S}_{\shots}$ for which
    $\foldParShot{\piInv(1)} \geq \dots \geq \foldParShot{\piInv(\shots)}$ holds and consider
    \begin{equation}
        \tilde{\mycode{C}} = \{ (\shot{\C}{\piInv(1)}, \dots, \shot{\C}{\piInv(\shots)}) :
        (\shot{\C}{1}, \dots, \shot{\C}{\shots}) \in \mycode{C} \}.
    \end{equation}
\end{remark}


\section{Interpolation-Based Decoding of Folded Linearized Reed--Solomon Codes} \label{sec:decoding}

In this section we derive an interpolation-based decoder for \ac{FLRS} codes that is based on the Guruswami--Rudra decoder for \ac{FRS} codes~\cite{Guruswami2008Explicit} and the Mahdavifahr--Vardy decoder for folded Gabidulin codes~\cite{Mahdavifar2012Listdecoding}.
As channel model we consider an additive sum-rank channel that relates the input $\C \in \Fq^{\foldParVec \times \lenFLRSVec}$
to the received output $\R \in \Fqm^{\foldParVec \times \lenFLRSVec}$ by adding an error $\E \in
\Fqm^{\foldParVec \times \lenFLRSVec}$, that is $\R = \C + \E$.
The addition in $\Fqm^{\foldParVec \times \lenFLRSVec}$ is performed componentwise.

We denote the sum-rank weight of the error $\E = (\shot{\E}{1}, \dots, \shot{\E}{\shots}) \in
\Fqm^{\foldParVec \times \lenFLRSVec}$ by $\SumRankWeight(\E) = t$
and its weight decomposition by $\t = (t_1, \dots, t_{\shots})$ with $t_i = \rk_{q} (\shot{\E}{i})$ for all
$i = 1, \dots, \shots$.
$\E$ is chosen uniformly at random from the set of all tuples in $\Fqm^{\foldParVec \times \lenFLRSVec}$ having a fixed
weight $t$ as well as a weight decomposition belonging to a prescribed set of decompositions.

Suppose we transmit a codeword $\C \in \foldedLinRS{\pe, \a, \foldParVec; \lenFLRSVec, k}$ and we receive the word $\R = (\shot{\R}{1}, \dots, \shot{\R}{\shots})$ with
\begin{equation} \label{eq:R_notation}
    \shot{\R}{i} =
    \begin{pmatrix}
        r_1^{(i)} & r_{\foldParShot{i}+1}^{(i)} & \cdots & r_{\lenShot{i}-\foldParShot{i}+1}^{(i)}
        \\
        \vdots & \vdots & \ddots & \vdots
        \\
        r_{\foldParShot{i}}^{(i)} & r_{2\foldParShot{i}}^{(i)} & \cdots & r_{\lenShot{i}}^{(i)}
    \end{pmatrix}
    \in \Fqm^{\foldParShot{i} \times \lenFLRSshot{i}}
    \quad \text{for all } i \in \{1, \ldots, \shots\}.
\end{equation}

Note that the decodability of a specific error will in general depend on its weight decomposition and not only on the
chosen code, the error weight $t$, and the decoder's parameters (see~\autoref{thm:decodingRadius}).
When we consider codes using the same folding parameter $\foldPar \in \NN^{\ast}$ for all blocks, only the error weight
$t$ decides if an error is decodable for the chosen code and decoder.

As is typical for interpolation-based decoding, our decoder consists of two steps that we will describe in the following:
interpolation and root finding.
In the first phase, we construct interpolation points from the received word $\R$ and obtain a multivariate skew
polynomial $Q$ that satisfies certain conditions.
In the second phase, we use the interpolation polynomial $Q$ to find candidates for the message polynomial and hence for
the transmitted codeword.


\subsection{Interpolation Step} \label{subsec:interpolation-step}

We first choose an interpolation parameter $\intDim \in \NN^{\ast}$ satisfying
\begin{equation}\label{eq:intDimConstraint}
    \intDim \leq \min_{i \in \{1, \dots, \shots\}} \foldParShot{i},
\end{equation}
where the constraint arises from the selection method of the interpolation points.
The latter are elements of $\Fqm^{\intDim + 1}$ whose last $\intDim$ entries are obtained from the received word $\R$
using a sliding-window approach.
Namely, we place a window of size $\intDim \times 1$ on the top left corner of $\R$ and slide it down one position at a
time as long as each position of the window covers an entry of $\R$.
Then the window is moved to the next column, starting the same process again from the top.
The first entry of an interpolation point obtained in this way is the code locator corresponding to the window's
starting position, that is a power of the primitive element $\pe$.

Formally speaking, we consider for each $i = 1, \dots, \shots$ the two sets
\begin{gather}\label{eq:intPointDef}
    \begin{aligned}
         \set{W}_i &\defeq \left\{ (j-1) \foldParShot{i} + l :
         j \in \{1, \ldots, \lenFLRSshot{i}\}, l \in \{1, \ldots, \foldParShot{i} - \intDim + 1\} \right\}
         \\
        \text{and} \quad
        \set{P}_i &\defeq \left\{ \left( \pe^{w-1}, r_{w}^{(i)}, r_{w+1}^{(i)}, \dots, r_{w+\intDim-1}^{(i)} \right):
        w \in \set{W}_i \right\},
    \end{aligned}
\end{gather}
where $\set{P}_i$ contains all interpolation points corresponding to the $i$-th block $\shot{\R}{i}$ of $\R$.
The index set $\set{W}_i$ consists of all eligible starting positions for the sliding window within $\shot{\R}{i}$ and
each interpolation point can be naturally identified with a tuple $(w,i)$ with $w \in \set{W}_i$ and $i \in
\{1, \dots, \shots\}$.
Note that, by construction, the set of all interpolation points $\set{P} \defeq \bigcup_{i=1}^{\shots} \set{P}_i$ has
cardinality
\begin{equation}
    \vert \set{P} \vert = \sum_{i=1}^{\shots} \lenFLRSshot{i} (\foldParShot{i} - s + 1).
\end{equation}

\begin{example} \label{ex:int_points}
    Consider an \ac{FLRS} code with folding parameters $\foldParVec = (3, 2)$ and folded block lengths
    $\lenFLRSVec = (2, 2)$.
    Choose $\intDim = 2$ and denote $\R$ according to~\eqref{eq:R_notation}, i.e.\
    \begin{equation}
        \R =
        \left(
        \begin{pmatrix}
            r_1^{(1)} & r_4^{(1)} \\
            r_2^{(1)} & r_5^{(1)} \\
            r_3^{(1)} & r_6^{(1)}
        \end{pmatrix}
        ,
        \begin{pmatrix}
            r_1^{(2)} & r_3^{(2)} \\
            r_2^{(2)} & r_4^{(2)}
        \end{pmatrix}
        \right).
    \end{equation}
    Then the set of interpolation points is the union of
    \begin{align}
        \set{P}_1 &= \Big\{ (1, r_1^{(1)}, r_2^{(1)}), (\pe, r_2^{(1)}, r_3^{(1)}), (\pe^3, r_4^{(1)}, r_5^{(1)}),
        (\pe^4, r_5^{(1)}, r_6^{(1)}) \Big\}
        \\
        \text{and} \quad \set{P}_2 &= \Big\{ (1, r_1^{(2)}, r_2^{(2)}), (\pe^2, r_3^{(2)}, r_4^{(2)}) \Big\}.
    \end{align}
\end{example}

We wish to find a multivariate skew interpolation polynomial $Q$ that satisfies certain interpolation constraints and
has the form
\begin{equation}\label{eq:mult_var_skew_poly_FLRS}
    Q(x, y_1, \dots, y_{\intDim}) = Q_0(x) + Q_1(x) y_1 + \dots + Q_{\intDim}(x) y_{\intDim},
\end{equation}
where $Q_r(x) \in \SkewPolyring$ for all $r \in \{0, \ldots, \intDim\}$.
The \emph{generalized operator evaluation} of such a polynomial $Q \in \MultSkewPolyring$ at a given interpolation point
$\p = (p_0, \dots, p_{\intDim}) \in \Fqm^{\intDim + 1}$ with respect to an evaluation parameter $a \in \Fqm$ is defined
as
\begin{equation}
    \label{eq:defFuncGenOpFLRS}
    \mathscr{E}_{Q}(\p)_{a} \defeq
    \opev{Q_0}{p_0}{a} + \opev{Q_1}{p_1}{a} + \dots + \opev{Q_\intDim}{p_{\intDim}}{a}.
\end{equation}

\begin{problem}[Interpolation Problem] \label{prob:intProblemFLRS}
    Let a parameter $\degConstraint \in \NN^{\ast}$, a set $\set{P} = \bigcup_{i=1}^{\shots} \set{P}_i$
    of interpolation points and evaluation parameters $a_1, \dots, a_{\shots}$ be given.
    Find a nonzero $(s+1)$-variate skew polynomial $Q$ of the
    form~\eqref{eq:mult_var_skew_poly_FLRS} satisfying
    \begin{enumerate}
        \item
            $\mathscr{E}_{Q}(\p)_{a_i} = 0$ for all $\p \in \set{P}_i$ and $i \in \{1, \ldots, \shots\}$ as well as
        \item
            $\deg(Q_0) < D$ and $\deg(Q_r) < D - k + 1$ for all $r \in \{1, \ldots, \intDim\}$.
    \end{enumerate}
\end{problem}
Note that the evaluation parameters $a_1, \dots, a_{\shots}$ are the entries of $\a$ of the considered \ac{FLRS} code
$\foldedLinRS{\pe, \a, \foldParVec; \lenFLRSVec, k}$.

\autoref{prob:intProblemFLRS} can be solved using skew KÃ¶tter interpolation from~\cite{liu2014kotter}
(similar as in~\cite[Sec.~V]{bartz2014efficient}) requiring at most $\OCompl{\intDim \len^2}$ operations in $\Fqm$ in the zero-derivation case.
There exist fast interpolation algorithms~\cite{bartz2022fast, bartz2022knh} that can solve~\autoref{prob:intProblemFLRS} requiring at most $\softoh{\intDim^\omega \OMul{\len}}$ operations in $\Fqm$ in the zero-derivation case, where $\softoh{\cdot}$ denotes the \emph{soft}-O notation (which neglects log factors), $\OMul{n}\in\OCompl{n^{1.635}}$ is the cost of multiplying two skew-polynomials of degree at most $n$ and $\omega < 2.37286$ is the matrix multiplication exponent~\cite{le_gall_powers_2014}.

Since the second condition of the interpolation problem allows us to write
\begin{equation}
    \label{eq:Qcoefficients}
    Q_0(x) = \sum_{j=0}^{\degConstraint-1} q_{0, j} x^j
    \quad \text{and} \quad
    Q_r(x) = \sum_{j=0}^{\degConstraint-k} q_{r, j} x^j
    \quad \text{for} \quad
    r \in \{1, \ldots, \intDim\}
\end{equation}
with all coefficients from $\Fqm$, we can also solve~\autoref{prob:intProblemFLRS} by solving a system of $\Fqm$-linear
equations whose coefficient matrix describes the
first condition of the interpolation problem.
We collect all interpolation points from $\set{P}_i$ as rows in a matrix $\P_i \in
\Fqm^{\lenFLRSshot{i}(\foldParShot{i} - \intDim + 1) \times (\intDim + 1)}$ for each $1 \leq i \leq \shots$ and denote
its columns by $\p_{i, 0}, \ldots, \p_{i, \intDim}$.
Define further $\p_r = (\p_{1, r}^{\top} \ | \ \cdots \ | \ \p_{\shots, r}^{\top})$ for $0 \leq r \leq \intDim$.
Then,~\autoref{prob:intProblemFLRS} can be written as
\begin{gather}\label{eq:intSystem}
    \S\q_I^{\top} = \0 \\
    \text{with} \quad
    \S = \left(
    \begin{array}{c|c|c|c}
        \left(\opMoore{D}{\p_0}{\a}\right)^{\top} &
        \left(\opMoore{D-k+1}{\p_1}{\a}\right)^{\top} &
        \cdots &
        \left(\opMoore{D-k+1}{\p_s}{\a}\right)^{\top}
    \end{array}
    \right)
    \notag \\
    \text{and} \quad
    \q_I = \left(
    q_{0, 0} \cdots q_{0, D-1} \ | \ q_{1, 0} \cdots q_{1, D-k} \ | \ \cdots \ | \
    q_{\intDim, 0} \cdots q_{\intDim, D-k}
    \right).
    \notag
\end{gather}

\begin{example} \label{ex:int_matrix}
    Let us continue~\autoref{ex:int_points} with $k = 2$ and derive the corresponding interpolation matrix for the choice
    $\degConstraint = 3$.
    As we will see shortly in~\autoref{lem:degConstraintForExistence}, this choice guarantees the existence of a nonzero
    solution of~\eqref{eq:intSystem}.
    We get
    \begin{equation}
        \P_1 =
        \begin{pmatrix}
            1 & r_1^{(1)} & r_2^{(1)} \\
            \pe & r_2^{(1)} & r_3^{(1)} \\
            \pe^3 & r_4^{(1)} & r_5^{(1)} \\
            \pe^4 & r_5^{(1)} & r_6^{(1)}
        \end{pmatrix}
        \qquad \text{ and } \qquad
        \P_2 =
        \begin{pmatrix}
            1 & r_1^{(2)} & r_2^{(2)} \\
            \pe^2 & r_3^{(2)} & r_4^{(2)} \\
        \end{pmatrix}
    \end{equation}
    and hence the interpolation matrix $\S$ is given by
    \begin{gather}
        \left(
        \begin{array}{c|c|c}
            \opMoore{3}{\p_0}{\a}^{\top}
            & \opMoore{2}{\p_1}{\a}^{\top}
            & \opMoore{2}{\p_2}{\a}^{\top}
        \end{array}
        \right)
        =
        \left(
        \begin{array}{c|c|c}
            \opVandermonde{3}{\p_{1, 0}}{a_1}^{\top}
            & \opVandermonde{2}{\p_{1, 1}}{a_1}^{\top}
            & \opVandermonde{2}{\p_{1, 2}}{a_1}^{\top}
            \\
            \opVandermonde{3}{\p_{2, 0}}{a_2}^{\top}
            & \opVandermonde{2}{\p_{2, 1}}{a_2}^{\top}
            & \opVandermonde{2}{\p_{2, 2}}{a_2}^{\top}
        \end{array}
        \right),
        \\
        \text{i.e.\ } \quad
        \S = \left(
        \begin{array}{ccc|cc|cc}
            1 & \op{a_1}{1} & \opexp{a_1}{1}{2} &
            r_1^{(1)} & \op{a_1}{r_1^{(1)}} &
            r_2^{(1)} & \op{a_1}{r_2^{(1)}}
            \\
            \pe & \op{a_1}{\pe} & \opexp{a_1}{\pe}{2} &
            r_2^{(1)} & \op{a_1}{r_2^{(1)}} &
            r_3^{(1)} & \op{a_1}{r_3^{(1)}}
            \\
            \pe^3 & \op{a_1}{\pe^3} & \opexp{a_1}{\pe^3}{2} &
            r_4^{(1)} & \op{a_1}{r_4^{(1)}} &
            r_5^{(1)} & \op{a_1}{r_5^{(1)}}
            \\
            \pe^4 & \op{a_1}{\pe^4} & \opexp{a_1}{\pe^4}{2} &
            r_5^{(1)} & \op{a_1}{r_5^{(1)}} &
            r_6^{(1)} & \op{a_1}{r_6^{(1)}}
            \\
            \hline
            1 & \op{a_2}{1} & \opexp{a_2}{1}{2} &
            r_1^{(2)} & \op{a_2}{r_1^{(2)}} &
            r_2^{(2)} & \op{a_2}{r_2^{(2)}}
            \\
            \pe^2 & \op{a_2}{\pe^2} & \opexp{a_2}{\pe^2}{2} &
            r_3^{(2)} & \op{a_2}{r_3^{(2)}} &
            r_4^{(2)} & \op{a_2}{r_4^{(2)}}
        \end{array}
        \right).
    \end{gather}
\end{example}

\begin{lemma}[Existence]\label{lem:degConstraintForExistence}
    A nonzero solution to~\autoref{prob:intProblemFLRS} exists if
    \begin{equation} \label{eq:deg_constraint}
        \degConstraint = \left\lceil
        \frac{\sum_{i=1}^{\shots} \lenFLRSshot{i} (\foldParShot{i} - \intDim + 1) + \intDim (k - 1) + 1}{\intDim + 1}
        \right\rceil.
    \end{equation}
\end{lemma}

\begin{proof}
    A nontrivial solution of~\eqref{eq:intSystem} exists if less equations than unknowns are involved.
    The number of equations corresponds to the number of interpolation points and hence the condition on the existence
    of a nonzero solution reads as follows:
    \begin{align}
        \sum_{i=1}^{\shots} \lenFLRSshot{i} (\foldParShot{i} - s + 1) &< \degConstraint (\intDim + 1) - \intDim (k - 1)
        \label{eq:degConstraintIneq}
        \\
        \iff \degConstraint &\geq
        \frac{\sum_{i=1}^{\shots} \lenFLRSshot{i} (\foldParShot{i} - s + 1) + \intDim (k - 1) + 1}{\intDim + 1}.
    \end{align}
    Since $\degConstraint$ is integral, the statement follows.
\end{proof}

If the same folding parameter is used for each block, that is if there is a $h \in \NN^{\ast}$ such that
$\foldPar = \foldParShot{i}$ holds for all $1 \leq i \leq \shots$, this reduces to
\begin{equation}
    \degConstraint=\left\lceil\frac{\lenFLRS(\foldPar-\intDim+1)+\intDim(k-1)+1}{\intDim+1}\right\rceil,
\end{equation}
which coincides with~\cite[Lemma~2]{hoermann2022efficient}.
Note that this is still true for different numbers of columns $\lenFLRSshot{1}, \dots, \lenFLRSshot{\shots}$.

\begin{lemma}[Roots of Polynomial]\label{lem:decConditionFLRS}
    Define the univariate skew polynomial
    \begin{equation} \label{eq:def_univariate_skew_poly}
        \begin{aligned}
            P(x) &\defeq Q_0(x)+Q_1(x)f(x)+Q_2(x)f(x)\pe+\dots+Q_\intDim(x)f(x)\pe^{\intDim - 1} \\
            &= Q(x, f(x), f(x)\pe, \dots, f(x)\pe^{\intDim-1}) \in \SkewPolyring
        \end{aligned}
    \end{equation}
    and write $t_i \defeq \rk_q(\mat{E}^{(i)})$ for $1 \leq i \leq \shots$.
    Then there exist $\Fq$-linearly independent elements
    $\zeta_1^{(i)}, \dots, \zeta_{(\lenFLRSshot{i} - t_i)(\foldParShot{i} - \intDim + 1)}^{(i)} \in \Fqm$ for each
    $i \in \{1, \dots, \shots\}$ such that $\opev{P}{\zeta_j^{(i)}}{a_i} = 0$ for all $1 \leq i \leq \shots$ and all
    $1 \leq j \leq (\lenFLRSshot{i} - t_i) (\foldParShot{i} - \intDim + 1)$.
\end{lemma}

\begin{proof}
    Since $\rk_q(\mat{E}^{(i)}) = t_i$, there exists a nonsingular matrix $\mat{T}_i \in
    \Fq^{\lenFLRSshot{i} \times \lenFLRSshot{i}}$ such that $\mat{E}^{(i)}\mat{T}_i$ has only $t_i$ nonzero columns for
    every $i \in \{1, \ldots, \shots\}$.
    Without loss of generality assume that these columns are the last ones of $\mat{E}^{(i)}\mat{T}_i$ and define
    $\veczeta^{(i)} = \L \cdot \mat{T}_i$ with $\L \in \Fqm^{\foldParShot{i} \times \lenFLRSshot{i}}$ containing the
    code locators $1, \dots, \pe^{\lenShot{i}-1}$ (cp.~\eqref{eq:defFLRScodeblock}).
    Note that the first $\lenFLRSshot{i} - t_i$ columns of $\R^{(i)} \mat{T}_i = \C^{(i)}\mat{T}_i + \E^{(i)}\mat{T}_i$
    are noncorrupted leading to $(\lenFLRSshot{i} - t_i)(\foldParShot{i} - \intDim + 1)$ noncorrupted interpolation
    points according to~\eqref{eq:intPointDef}.
    Now, for each $1 \leq i \leq \shots$, the first entries of the
    $(\lenFLRSshot{i} - t_i)(\foldParShot{i} - \intDim + 1)$ noncorrupted interpolation points (i.e.\ the top left
    submatrix of size $(\lenFLRSshot{i} - t_i) \times (\foldParShot{i} - \intDim + 1)$ of $\zeta^{(i)}$) are by
    construction both $\Fq$-linearly independent and roots of $P(x)$.
\end{proof}

\begin{theorem}[Decoding Radius] \label{thm:decodingRadius}
    Let $Q(x,y_1,\dots,y_\intDim)$ be a nonzero solution of \autoref{prob:intProblemFLRS}.
    If the error-weight decomposition $\t = (t_1, \dots, t_{\shots})$ satisfies
    \begin{equation}\label{eq:listDecRegionFLRS}
        \sum_{i=1}^{\shots} t_i (\foldParShot{i} - \intDim + 1)
        < \frac{\intDim}{\intDim+1} \left( \sum_{i=1}^{\shots} \lenFLRSshot{i} (\foldParShot{i} - s + 1) - k + 1 \right),
    \end{equation}
    then $P \in \SkewPolyring$ defined in~\eqref{eq:def_univariate_skew_poly} is the zero polynomial, that is for all $x \in \Fqm$
    \begin{equation}\label{eq:rootFindingEquationFLRS}
        P(x)=Q_0(x)+Q_1(x)f(x)+\!\cdots\!+Q_\intDim(x)f(x)\pe^{\intDim-1}=0.
    \end{equation}
\end{theorem}

\begin{proof}
    By~\autoref{lem:decConditionFLRS}, there exist elements
    $\zeta_1^{(i)}, \dots, \zeta_{(\lenFLRSshot{i} - t_i)(\foldParShot{i} - \intDim + 1)}^{(i)}$ in $\Fqm$ that are
    $\Fq$-linearly independent for each $i \in \{1, \dots, \shots\}$ such that $\opev{P}{\zeta_j^{(i)}}{a_i} = 0$ for
    $1 \leq i \leq \shots$ and $1 \leq j \leq (\lenFLRSshot{i} - t_i)(\foldParShot{i} - \intDim + 1)$.
    By choosing
    \begin{equation} \label{eq:degConstExceedsBound}
        \degConstraint \leq \sum_{i=1}^{\shots} (\lenFLRSshot{i} - t_i)(\foldParShot{i} - \intDim + 1),
    \end{equation}
    $P(x)$ exceeds the degree bound from~\cite[Prop.~1.3.7]{caruso2019residues} which is possible only if $P(x)=0$.
    Together with inequality~\eqref{eq:degConstraintIneq}, we get
    \begin{align}
        &\phantom{\iff}
        \frac{\sum_{i=1}^{\shots} \lenFLRSshot{i} (\foldParShot{i} - s + 1) + \intDim (k - 1)}{\intDim + 1}
        < \degConstraint
        \leq \sum_{i=1}^{\shots} (\lenFLRSshot{i} - t_i)(\foldParShot{i} - \intDim + 1)
        \\
        &\iff
        \sum_{i=1}^{\shots} \lenFLRSshot{i} (\foldParShot{i} - s + 1) + \intDim (k - 1)
        < (\intDim + 1) \sum_{i=1}^{\shots} (\lenFLRSshot{i} - t_i)(\foldParShot{i} - \intDim + 1)
        \\
        &\iff
        \sum_{i=1}^{\shots} t_i (\foldParShot{i} - \intDim + 1)
        < \frac{\intDim}{\intDim+1} \left( \sum_{i=1}^{\shots} \lenFLRSshot{i} (\foldParShot{i} - s + 1) - k + 1 \right).
    \end{align}
\end{proof}

Note that the left-hand side equals the number of erroneous interpolation points.
Intuitively speaking, a rank error in a block with many rows is worse than one in a block with a small folding parameter
because it creates more corrupted interpolation points.
This is due to the fact that we can interpret a rank error in the $i$-th block as a symbol error over the extension
field $\F_{q^{\foldParShot{i}}}$ corresponding to $\foldParShot{i}$ $\Fq$-errors.

Even though~\autoref{thm:decodingRadius} describes the admissible decoding radius, the derived condition does not only
depend on the sum-rank weight $t$ of the error but also on its weight decomposition $\t = (t_1, \dots, t_{\shots})$.
If we focus on the simpler special case of using the same folding parameter $h \in \NN^{\ast}$ for all blocks,
formula~\eqref{eq:listDecRegionFLRS} simplifies to the same inequality as in~\cite[Thm.~1]{hoermann2022efficient} that
only depends on the error weight $t$.
Namely,
\begin{equation} \label{eq:decoding_region_same_h}
    t < \frac{\intDim}{\intDim+1} \left(\frac{\lenFLRS(\foldPar-\intDim+1)-k+1}{\foldPar-\intDim+1}\right).
\end{equation}
This yields the desirable property that we can characterize all decodable errors simply as the ones lying in a sum-rank
ball.

In this case, we derive the normalized decoding radius $\tau \defeq \frac{t}{\lenFLRS}$
from~\eqref{eq:decoding_region_same_h} as
\begin{equation} \label{eq:normalized_decoding_radius}
    \begin{aligned}
        \tau = \frac{t}{\lenFLRS} &< \frac{\intDim}{\intDim+1} \left( \frac{\lenFLRS (\foldPar - \intDim + 1) - k + 1}
        {\lenFLRS (\foldPar - \intDim + 1)} \right) \\
        &= \frac{\intDim}{\intDim+1} \left( 1 - \frac{\foldPar R - \frac{1}{\lenFLRS}}{\foldPar - \intDim + 1} \right)
        \xrightarrow{\lenFLRS \to \infty}
        \frac{\intDim}{\intDim+1} \left( 1 - \frac{\foldPar}{\foldPar - \intDim + 1} R \right)
    \end{aligned}
\end{equation}
where $R \defeq \frac{k}{\foldPar \lenFLRS}$ denotes the code rate.

In the more general case, we can imagine the set of decodable error patterns as a sum-rank ball with some additional
bulges.
We can derive from~\eqref{eq:normalized_decoding_radius} that all errors with sum-rank weight $t$ satisfying
\begin{equation} \label{eq:decoding_region_worst_case}
    t < \frac{\intDim}{\intDim+1}
    \frac{\sum_{i=1}^{\shots} \lenFLRSshot{i} (\foldParShot{i} - s + 1) - k + 1}{\foldParShot{max} - \intDim + 1}
\end{equation}
for $\foldParShot{max} \defeq \max_{i \in \{1, \dots, \shots\}} \foldParShot{i}$ can be decoded for sure.
This corresponds to the ball.
On the other hand, the buldges represent specific decodable error-weight decompositions having larger sum-rank weight.
However, the worst-case bound
\begin{equation} \label{eq:decoding_region_best_case}
    t < \frac{\intDim}{\intDim+1}
    \frac{\sum_{i=1}^{\shots} \lenFLRSshot{i} (\foldParShot{i} - s + 1) - k + 1}{\foldParShot{min} - \intDim + 1}
\end{equation}
with $\foldParShot{min} \defeq \min_{i \in \{1, \dots, \shots\}} \foldParShot{i}$ shows that the code can definitely
not correct error patterns of weight $t$ exceeding its right-hand side.
\autoref{tab:decodable_error_patterns} contains some examples for codes and the error patterns they can decode.

{
\rowcolors{2}{lightgray}{white}

\begin{table}
    \centering
    \setlength{\tabcolsep}{4pt}
    \caption{Decodable error-weight decompositions for codes of dimension $k = 2$ and decoder parameter $\intDim = 2$.}
    \label{tab:decodable_error_patterns}
    \begin{tabular}{|c|c||M{.9cm}|M{.9cm}|M{.9cm}|M{.9cm}|M{.9cm}||c|c|c|}
        \hline
        $\lenVec$ & $\foldParVec$ & \multicolumn{5}{c||}{number of decodable error patterns} & decoding & minimum \\
        & & $t = 1$ & $t = 2$ & $t = 3$ & $t = 4$ & $t = 5$ & radius$^{\ast}$ & distance \\
        \hline
        \hline
        $(6, 6)$ & $(3, 3)$ & 2 / 2 & 3 / 3 & none & none & none & 2.33 & 4 \\
        & $(2, 2)$ & 2 / 2 & 3 / 3 & none & none & none & 3.33 & 6 \\
        & $(3, 2)$ & 2 / 2 & 2 / 3 & 1 / 3 & none & none & 2.0~$\vert$~4.0 & 5 \\
        \hline
        \hline
        $(6, 6, 6)$ & $(3, 3, 3)$ & 3 / 3 & 6 / 6 & 7 / 7 & none & none & 3.67 & 6 \\
        & $(2, 2, 2)$ & 3 / 3 & 6 / 6 & 10 / 10 & 12 / 12 & 12 / 12 & 5.33 & 9 \\
        & $(3, 3, 2)$ & 3 / 3 & 6 / 6 & 8 / 8 & 5 / 8 & none & 3.33~$\vert$~6.67 & 7 \\
        & $(3, 2, 2)$ & 3 / 3 & 6 / 6 & 9 / 9 & 7 / 10 & 2 / 9 & 3.0~$\vert$~6.0 & 8 \\
        \hline
    \end{tabular}
    \\
    $^{\ast}$~\eqref{eq:decoding_region_same_h} for codes with the same folding parameter for all blocks,
    ~\eqref{eq:decoding_region_worst_case}~$\vert$~\eqref{eq:decoding_region_best_case} in all other cases.
\end{table}
}

\subsection{Root-Finding Step} \label{subsec:root-finding-step}

By~\autoref{thm:decodingRadius}, the message polynomial $f \in \SkewPolyring_{<k}$
satisfies~\eqref{eq:rootFindingEquationFLRS} if~\eqref{eq:listDecRegionFLRS} holds for the error-weight decomposition
$\t = (t_1, \dots, t_{\shots})$.
Therefore, we consider the following root-finding problem.
\begin{problem}[Root-Finding Problem] \label{prob:rootFinding}
    Let $Q \in \MultSkewPolyring$ be a nonzero solution of~\autoref{prob:intProblemFLRS} and let the error-weight
    decomposition $\t = (t_1, \dots, t_{\shots})$ satisfy constraint~\eqref{eq:listDecRegionFLRS}.
    Find all skew polynomials $f \in \SkewPolyring_{<k}$ for which~\eqref{eq:rootFindingEquationFLRS} applies.
\end{problem}
Condition~\eqref{eq:rootFindingEquationFLRS} is equivalent to all coefficients of the polynomial on the left-hand side
of~\eqref{eq:rootFindingEquationFLRS} being zero.
Multiple application of $\aut^{-1}$ to the equations resulting from the coefficients allows to
express~\autoref{prob:rootFinding} as an $\Fqm$-linear system of equations in the unknown
\begin{equation}
    \f \defeq (f_0, \aut^{-1}(f_1), \ldots, \aut^{-k+1}(f_{k-1}))^{\top}.
\end{equation}

As e.g.\ in~\cite{wachter2013decoding,BartzSidorenko_FoldedGabidulin2015_DCC}, we use a basis of the interpolation
problem's solution space instead of choosing only one solution $Q$ of system~\eqref{eq:intSystem}.
This improvement is justified by the following result.
\begin{lemma}[Number of Interpolation Solutions] \label{lem:intSolutionDim}
    For $d_I \defeq \dim_{q^m} (\ker(\S))$ with $\S$ defined in~\eqref{eq:intSystem}, it holds
    \begin{equation}
        d_I \geq \intDim (\degConstraint - k + 1) - \sum_{i=1}^{\shots} t_i (\foldParShot{i} - \intDim + 1).
    \end{equation}
\end{lemma}

\begin{proof}
    The first $\degConstraint$ columns of $\S$ are given as $\left(\opMoore{\degConstraint}{\p_0}{\a}\right)^{\top}$.
    Since the $\shots$ blocks of $\p_0$ consist of pairwise distinct powers of $\pe$, the elements of a single block are
    $\Fq$-linearly independent.
    Hence $\rk_{q^m}\left(\opMoore{\degConstraint}{\p_0}{\a}\right)
    = \min (\degConstraint, \sum_{i=1}^{\shots} \lenFLRSshot{i} (\foldParShot{i} - \intDim + 1)) = \degConstraint$,
    where the last equality follows from equation~\eqref{eq:degConstExceedsBound}.
    In the absence of an error, the remaining columns consist of linear combinations of the first $\degConstraint$ ones
    and do not increase the rank.
    If an error $\E$ with $\SumRankWeight(\E) = t$ is introduced, at most
    $\sum_{i=1}^{\shots} t_i (\foldParShot{i} - \intDim + 1)$ interpolation points are corrupted according
    to~\autoref{lem:decConditionFLRS}.
    As a consequence, these columns can increase the rank of $\S$ by at most
    $\sum_{i=1}^{\shots} t_i (\foldParShot{i} - \intDim + 1)$.
    Thus, $\rk_{q^m}(\S) \leq \degConstraint + \sum_{i=1}^{\shots} t_i (\foldParShot{i} - \intDim + 1)$ and the
    rank-nullity theorem directly yields
    \begin{align}
        d_I &\defeq \dim_{q^m} (\ker(\S)) = \degConstraint (\intDim + 1) - \intDim (k-1) - \rk_{q^m}(\S) \\
        &\geq \degConstraint (\intDim + 1) - \intDim (k-1) -
        \left( \degConstraint + \sum_{i=1}^{\shots} t_i (\foldParShot{i} - \intDim + 1) \right) \\
        &= \intDim (\degConstraint - k + 1) - \sum_{i=1}^{\shots} t_i (\foldParShot{i} - \intDim + 1).
    \end{align}
\end{proof}

Again we get a simpler bound when we consider the same folding parameter $h \in \NN^{\ast}$ for each block
(cp.~\cite[Lemma~4]{hoermann2022efficient}):
\begin{equation}
    d_I \geq \intDim (\degConstraint - k + 1) - t (\foldPar - \intDim + 1).
\end{equation}

Let now $Q^{(1)}, \ldots, Q^{(d_I)} \in \MultSkewPolyring$ form a basis of the solution space
of~\autoref{prob:intProblemFLRS} and denote the coefficients of $Q^{(u)}$ by $q_{i,j}^{(u)}$ for all $1 \leq u \leq d_I$
(cp.~\eqref{eq:Qcoefficients}).
In other words, we write for all $u \in \{1, \ldots, d_I\}$
\begin{equation}
    Q^{(u)}(x, y_1, \ldots, y_\shots)
    = \sum_{j=0}^{\degConstraint-1} q_{0, j}^{(u)} x^j
    + \Bigg( \sum_{j=0}^{\degConstraint-k} q_{1, j}^{(u)} x^j \Bigg)y_1 + \ldots
    + \Bigg( \sum_{j=0}^{\degConstraint-k} q_{\intDim, j}^{(u)} x^j \Bigg)y_\intDim.
\end{equation}
Define further the ordinary polynomials
\begin{equation}\label{eq:rf_polys}
    B_j^{(u)}(x) = q_{1, j}^{(u)} + q_{2, j}^{(u)} x + \cdots + q_{\intDim, j}^{(u)} x^{\intDim-1} \in \Polyring
\end{equation}
for $j \in \{0, \ldots, \degConstraint-k\}$ and $u \in \{1, \ldots, d_I\}$ as well as the additional notations
\vspace*{-5pt}
\begin{align}
    \b_{j,a} &= \left( \aut^{-a}\left(B_j^{(1)}(\aut^{a}(\pe))\right), \ldots,
    \aut^{-a}\left(B_j^{(d_I)}(\aut^{a}(\pe))\right) \right)^{\top} \\
    \text{and} \qquad
    \q_a &= \left( \aut^{-a}\left(q_{0,a}^{(1)}\right), \ldots, \aut^{-a}\left(q_{0,a}^{(d_I)}\right) \right)^{\top}
\end{align}
for $0 \leq j \leq \degConstraint-k$ and $0 \leq a \leq \degConstraint-1$.
Then the root-finding system is given as
\begin{gather}\label{eq:improvedRootFindingSystemFLRS}
    \B \cdot \f = -\q
    \\
    \text{with }
    \B \defeq
    \begin{pmatrix}
        \b_{0,0} & & & \\
        \b_{1,1} & \b_{0,1} & & \\[-3pt]
        \vdots & \b_{1,2} & \ddots & \\[-3pt]
        \b_{\degConstraint-k,\degConstraint-k} & \vdots & & \b_{0,k-1} \\
        & \b_{\degConstraint-k,\degConstraint-k+1} & & \b_{1,k} \\
        & & \ddots & \vdots \\[-3pt]
        & & & \b_{\degConstraint-k,\degConstraint-1}
    \end{pmatrix}
    \text{ and }
    \q \defeq
    \begin{pmatrix}
        \q_0 \\
        \vdots \\
        \q_{\degConstraint-1}
    \end{pmatrix}.
    \notag
\end{gather}
The root-finding system~\eqref{eq:improvedRootFindingSystemFLRS} can be solved by back substitution in at most
$\OCompl{k^2}$ operations in $\Fqm$ since we can focus on (at most) $k$ nontrivial equations from different blocks of
$d_I$ rows.
Observe that the transmitted message polynomial $f \in \SkewPolyring_{<k}$ is always a solution of~\eqref{eq:improvedRootFindingSystemFLRS}
as long as $\t = (t_1, \dots, t_{\shots})$ satisfies the decoding radius in~\eqref{eq:listDecRegionFLRS}.

\begin{example}
    Let us set up the root-finding problem for the \ac{FLRS} code considered in \autoref{ex:int_points}
    and~\autoref{ex:int_matrix}.
    We obtain
    \begin{align}
        P(x) &= \underbrace{q_{0, 0} + q_{0, 1}x + q_{0, 2}x^2}_{Q_0(x)}
        + \underbrace{(q_{1, 0} + q_{1, 1}x)(f_0 + f_1 x)}_{Q_1(x)f(x)}
        \\
        &\phantom{=} + \underbrace{(q_{2,0} + q_{2, 1}x)(f_0\pe + f_1\aut(\pe)x)}_{Q_2(x)f(x)\pe}
        \\
        \text{with} \quad Q_1(x)f(x) &= q_{1, 0}f_0 + \left( q_{1, 0}f_1 + q_{1, 1}\aut(f_0) \right)x
        + q_{1, 1}\aut(f_1) x^2
        \\
        \text{and} \quad Q_2(x)f(x)\pe &= q_{2, 0}f_0\pe
        + \left( q_{2, 0}f_1\aut(\pe) + q_{2, 1}\aut(f_0)\aut(\pe) \right)x + q_{2, 1}\aut(f_1)\aut^2(\pe) x^2.
    \end{align}
    Now we define $B_j(x) \defeq q_{1, j} + q_{2, j}x \in \Polyring$ for $j \in \{0, 1, 2\}$ and write the coefficients
    of $P(x) = p_0 + p_1 x + p_2 x^2$ as follows:
    \begin{align}
        p_0 &= q_{0, 0} + f_0(q_{1, 0} + q_{2, 0} \pe)
        = q_{0, 0} + f_0 B_0(\pe) \\
        p_1 &= q_{0, 1} + f_1(q_{1, 0}+ q_{2, 0} \aut(\pe)) + \aut(f_0)(q_{1, 1} + q_{2, 1} \aut(\pe)) \\
        &= q_{0, 1} + f_1 B_0(\aut(\pe)) + \aut(f_0) B_1(\aut(\pe)) \\
        p_2 &= q_{0, 2} + \aut(f_1)(q_{1, 1} + q_{2, 1} \aut^2(\pe))
        = q_{0, 2} + \aut(f_1) B_1(\aut^2(\pe))
    \end{align}
    Because $p_i = 0$ for all $i \in \{0, 1, 2\}$, application of $\aut^{-i}$ to the equation belonging to $p_i$ does
    not change the solution space of the above system of equations.
    Hence, we can equivalently solve the root-finding system
    \begin{equation}
        \begin{pmatrix}
            B_0(\pe) & \\
            \aut^{-1}\left( B_1(\aut(\pe)) \right) & \aut^{-1}\left( B_0(\aut(\pe)) \right) \\
            & \aut^{-2}\left( B_1(\aut^2(\pe)) \right) \\
        \end{pmatrix}
        \cdot
        \begin{pmatrix}
            f_0 \\
            \aut^{-1}(f_1)
        \end{pmatrix}
        = -
        \begin{pmatrix}
            q_{0, 0} \\
            \aut^{-1}(q_{0, 1}) \\
            \aut^{-2}(q_{0, 2})
        \end{pmatrix}.
    \end{equation}
\end{example}


\subsection{List and Probabilistic Unique Decoding} \label{subsec:list-and-probabilistic-decoding}

The interpolation-based scheme from above is summarized in~\autoref{alg:decoder} and can be used for list decoding or as
a probabilistic unique decoder.
In the first case, all solutions of~\eqref{eq:improvedRootFindingSystemFLRS} are returned as a list of candidate message
polynomials.
Note that this list contains all message polynomials corresponding to codewords having sum-rank distance less than the
decoding radius from the actually sent codeword.
However, there may also be some candidates in the list that lie outside of the sum-rank ball around the sent codeword.
In the second case, the decoder returns the unique solution of~\eqref{eq:improvedRootFindingSystemFLRS} or declares a
decoding failure if there are multiple candidates.
Let us investigate the usage of our decoding scheme as list decoder and bound its output size as follows:

\begin{algorithm}[ht!]
    \caption{\algoname{Interpolation-Based Decoding of \ac{FLRS} Codes}}
    \label{alg:decoder}
    \begin{algorithmic}[1]
        \State{Choose $s \leq \min_{i \in \{1, \dots, \shots\}} \foldParShot{i}$ and $\degConstraint$ according to~\eqref{eq:deg_constraint}}
        \State{Compute the sets $\set{P}_{1}, \dots, \set{P}_{\shots}$ of interpolation points according to~\eqref{eq:intPointDef}}
        \State{Find a basis $(Q^{(1)}, \dots, Q^{(d_I)})$ of the solution space of~\autoref{prob:intProblemFLRS}}
        \State{Find a basis $(f^{(1)}, \dots, f^{(d_{RF})})$ of the solution space of~\autoref{prob:rootFinding} with respect to all \newline skew polynomials $Q^{(1)}, \dots, Q^{(d_I)}$}
    \end{algorithmic}
\end{algorithm}

\begin{lemma}[Worst-Case List Size] \label{lem:worstCaseListSize}
    The list size is upper bounded by $q^{m(\intDim-1)}$.
\end{lemma}

\begin{proof}
    With $d_{RF} \defeq \dim_{q^m}(\ker(\B))$, the list size equals $q^{m \cdot d_{RF}}$ and $d_{RF} = k - \rk_{q^m}(\B)$
    due to the rank-nullity theorem.
    Let $\B_{\triangle}$ denote the lower triangular matrix consisting of the first $d_I k$ rows of $\B$.
    Then, $\rk_{q^m}(\B) \geq \rk_{q^m}(\B_{\triangle})$ and the latter is lower bounded by the number of nonzero vectors
    on its diagonal.
    These vectors are $\b_{0,0}, \ldots, \b_{0,k-1}$ and we focus on their first components while neglecting application
    of $\aut$.
    Observe that each of them is given as the evaluation of $B_0^{(1)}$ at another conjugate of $\pe$.
    Since $B_0^{(1)}$ can have at most $\intDim - 1$ roots, it follows that at most $\intDim - 1$ of the vectors on the
    diagonal can be zero.
    Thus, $\rk_{q^m}(\B) \geq k - \intDim + 1$ and, as a consequence, $d_{RF} \leq \intDim - 1$.
\end{proof}

Note that, despite the exponential worst-case list size, an $\Fqm$-basis of the list can be found in polynomial time.
\autoref{thm:listDecoding} summarizes the results for list decoding of \ac{FLRS} codes.

\begin{theorem}[List Decoding] \label{thm:listDecoding}
    Consider an \ac{FLRS} code $\foldedLinRS{\pe, \a, \foldParVec; \lenFLRSVec, k}$ and a codeword
    $\C$ that is transmitted over a sum-rank channel.
    Assume that the error has weight $t$ and that its weight decomposition
    $\t = (t_1, \dots, t_{\shots})$ satisfies
    \begin{equation}
       \sum_{i=1}^{\shots} t_i (\foldParShot{i} - \intDim + 1)
        < \frac{\intDim}{\intDim+1} \left( \sum_{i=1}^{\shots} \lenFLRSshot{i} (\foldParShot{i} - s + 1) - k + 1 \right)
    \end{equation}
    for an interpolation parameter $1 \leq \intDim \leq \min_{i \in \{1, \dots, \shots\}} \foldParShot{i}$.
    Then, a basis of an at most $(\intDim - 1)$-dimensional $\Fqm$-vector space that contains candidate message polynomials
    satisfying~\eqref{eq:rootFindingEquationFLRS} can be obtained in at most $\OCompl{\intDim \len^2}$ operations in $\Fqm$.
\end{theorem}


Recall that the decoding radius can be described by~\eqref{eq:decoding_region_same_h} if the same folding parameter
$\foldPar$ is used for all blocks.

A different concept is probabilistic unique decoding where the decoder either returns a unique solution or declares a
failure.
In our setting, a failure occurs exactly when the root-finding matrix $\B$ is rank-deficient.
Similar to~\cite{BartzSidorenko_FoldedGabidulin2015_DCC}, we now derive a heuristic upper bound on the probability
$\mathbb{P}\left( \rk_{q^m}(\B) < k \right)$.

\begin{lemma}[Decoding Failure Probability] \label{lem:failureProbabilityBound}
    Assume that the coefficients of the polynomials $B_0^{(u)}(x) \in \Polyring$ from~\eqref{eq:rf_polys} for
    $u \in \{1, \ldots, d_I\}$ are independent and have a uniform distribution among $\Fqm$.
    Then it holds that
    \begin{equation}\label{eq:heuristic_upper_bound}
        \mathbb{P}\left( \rk_{q^m}(\B) < k \right) \lesssim k \cdot \left( \frac{k}{q^m} \right)^{d_I},
    \end{equation}
    where $\lesssim$ indicates that the bound is a heuristic approximation.
\end{lemma}

\begin{proof}
    Let $\B_{\triangle}$ denote the matrix consisting of the first $d_I k$ rows of $\B$ as in the proof
    of~\autoref{lem:worstCaseListSize}.
    Note that
    \begin{equation}
        \mathbb{P}\left( \rk_{q^m}(\B) < k \right) \leq \mathbb{P}\left( \rk_{q^m}(\B_{\triangle}) < k \right)
    \end{equation}
    holds and we can focus on finding an upper bound for the right-hand side.
    As lower triangular matrix, $\B_{\triangle}$ has rank $k$ if and only if $\b_{0, 0}, \ldots, \b_{0, k-1}$ are
    nonzero.
    Instead of these vectors, we investigate
    $\tilde{\b}_{0,a} = \left( B_0^{(1)}(\aut^{a}(\pe)), \ldots, B_0^{(d_I)}(\aut^{a}(\pe)) \right)^{\top}$ for
    $a \in \{0, \ldots, k-1\}$ because application of $\aut$ can be neglected.
    Following ideas from~\cite[Lemma 8]{BartzSidorenko_FoldedGabidulin2015_DCC}, we can now interpret the vector
    consisting of the $u$-th entries of $\tilde{\b}_{0,0}, \ldots, \tilde{\b}_{0,k-1}$ for each $1 \leq u \leq d_I$ as
    a codeword of a Reed--Solomon code $\mycode{C}_{RS}$ of length $k$ and dimension $s$.
    These $d_I$ codewords have a uniform distribution with respect to the codebook of $\mycode{C}_{RS}$ due to our
    assumption on the distribution of the polynomial coefficients.
    Thanks to~\cite[eq. (1)]{cheung1989weightDistribution}, we can approximate the probability that a random codeword
    has full weight $k$ as
    \begin{equation}
     \frac{|\{ \c \in \mycode{C}_{RS} : \HammingWeight(\c) = k \}|}{|\mycode{C}_{RS}|} \approx
     \frac{|\{ \v \in \Fqm^k : \HammingWeight(\v) = k \}|}{|\Fqm^k|} = \left( 1 - \frac{1}{q^m} \right)^k.
    \end{equation}
    Let us fix an $a \in \{0, \ldots, k-1\}$ and consider $\tilde{\b}_{0,a}$.
    Then, any full-weight codeword induces a nonzero entry in $\tilde{\b}_{0,a}$ and conversely, the probability that
    one entry of $\tilde{\b}_{0,a}$ is zero is upper bounded by
    \begin{equation} \label{eq:failureProbProofOneEntryZero}
     1 - \left( 1 - \frac{1}{q^m} \right)^k < \frac{k}{q^m},
    \end{equation}
    where the estimation uses the binomial theorem.
    Due to our independence assumption for the coefficients of $B_0^{(u)}(x)$ for $u \in \{1, \ldots, d_I\}$, the
    entries of $\tilde{\b}_{0,a}$ are also independent and the probability that the whole vector is zero for a fixed
    $a$ is bounded by the $d_I$-th power of the right-hand side of~\eqref{eq:failureProbProofOneEntryZero}.
    Finally, the union bound deals with the probability that at least one vector is zero and yields
    \begin{equation}
     \mathbb{P}\left( \bigcup_{a=0}^{k-1} (\tilde{\b}_{0,a} = \0) \right)
     \leq \sum_{a=0}^{k-1} \mathbb{P}\left( \tilde{\b}_{0,a} = \0 \right)
     \lesssim \sum_{a=0}^{k-1} \left( \frac{k}{q^m} \right)^{d_I}
     = k \cdot \left( \frac{k}{q^m} \right)^{d_I}.
    \end{equation}
\end{proof}

\autoref{subsec:simulation_results} presents results that empirically verify the heuristic upper bound by Monte Carlo
simulations.
Moreover, further simulations show that the assumption that the coefficients of $B_0^{(u)}(x)$ for
$u \in \{1, \ldots, d_I\}$ are uniformly distributed is reasonable.

Let us now introduce a threshold parameter $\mu \in \NN^{\ast}$ and enforce $d_I \geq \mu$ by adapting the proof
of~\autoref{lem:degConstraintForExistence} which results in the new degree constraint
\begin{equation} \label{eq:new_deg_constraint}
    \degConstraint =
    \left\lceil \frac{\sum_{i=1}^{\shots} \lenFLRSshot{i} (\foldParShot{i} - \intDim + 1) + \intDim (k - 1) + \mu}
    {\intDim + 1}
    \right\rceil.
\end{equation}
We incorporate this threshold into the results we have shown so far and obtain \autoref{thm:probabilisticUniqueDecoding}
which provides a summary for probabilistic unique decoding of \ac{FLRS} codes.

\begin{theorem}[Probabilistic Unique Decoding] \label{thm:probabilisticUniqueDecoding}
    For an interpolation parameter $1 \leq \intDim \leq \min_{i \in \{1, \dots, \shots\}} \foldParShot{i}$ and a
    dimension threshold $\mu \in \NN^{\ast}$, transmit a codeword $\C$ of an \ac{FLRS} code $\foldedLinRS{\pe, \a, \foldParVec; \lenFLRSVec, k}$ over a sum-rank channel.
    Assume that the error weight $t$ has a weight decomposition $\t = (t_1, \dots, t_{\shots})$ satisfying
    \begin{equation} \label{eq:prob_unique_decoding_radius}
        \sum_{i=1}^{\shots} t_i (\foldParShot{i} - \intDim + 1)
        \leq \frac{\intDim}{\intDim+1}
        \left( \sum_{i=1}^{\shots} \lenFLRSshot{i} (\foldParShot{i} - \intDim + 1) - k + 1 \right)
        - \frac{\mu}{\intDim + 1}
    \end{equation}
    and that the coefficients of the polynomials $B_0^{(u)}(x)$ for $u \in \{1, \ldots, \mu\}$ are independent and uniformly distributed among $\Fqm$.
    Then, $\C$ can be uniquely recovered with complexity $\OCompl{\intDim \len^2}$ in $\Fqm$ and with an approximate
    probability of at least
    \begin{equation}
        1 - k \cdot \left( \frac{k}{q^m} \right)^{\mu}.
    \end{equation}
\end{theorem}

\begin{proof}
    The decoding radius follows when inequality~\eqref{eq:degConstraintIneq} is replaced by
    \begin{equation}
        \sum_{i=1}^{\shots} \lenFLRSshot{i} (\foldParShot{i} - s + 1)
        \leq \degConstraint (\intDim + 1) - \intDim (k - 1) - \mu
    \end{equation}
    in the proof of~\autoref{thm:decodingRadius}.
    Since the degree constraint~\eqref{eq:new_deg_constraint} enforces $d_I \geq \mu$, the heuristic upper bound on
    the failure probability from~\autoref{lem:failureProbabilityBound} attains the worst-case value for $d_I = \mu$.
    The success probability of decoding is hence at least $1 - k \cdot \left( \frac{k}{q^m} \right)^{\mu}$.

    The total complexity of $\OCompl{\intDim \len^2}$ follows since at most $\OCompl{\intDim \len^2}$ $\Fqm$-operations
    are needed to solve the interpolation problem and the solution of the root-finding problem can be computed in $\OCompl{k^2}$ operations.
\end{proof}

For the same folding parameter $\foldPar$ for each block, we get the simplified degree constraint
\begin{equation}
    \degConstraint =
    \left\lceil \frac{\lenFLRS(\foldPar - \intDim + 1) + \intDim (k - 1) + \mu}{\intDim + 1} \right\rceil
\end{equation}
and, as in~\cite[Thm.~3]{hoermann2022efficient}, the description of the decoding radius reads as
\begin{equation}
    t \leq \frac{\intDim}{\intDim + 1}
    \left( \frac{\lenFLRS(\foldPar - \intDim + 1) - k + 1}{\foldPar - \intDim + 1} \right)
    - \frac{\mu}{(\intDim + 1)(\foldPar - \intDim + 1)}.
\end{equation}

\subsection{Improved Decoding of High-Rate Codes} \label{subsec:improved_high_rate}

The normalized decoding radius $\tau \defeq \frac{t}{\lenFLRS}$ of the interpolation-based decoder for codes using the same folding parameter for all blocks, which is given in~\eqref{eq:normalized_decoding_radius}, is positive only for code rates $R < \frac{\foldPar - \intDim + 1}{\foldPar}$.
This is our motivation to now consider an interpolation-based decoder for \ac{FLRS} codes that allows to correct sum-rank errors beyond the unique decoding radius for any code rate $R > 0$.
The main idea behind this decoder is inspired by Justesen's decoder for \ac{FRS} codes~\cite[Sec.~III-B]{Guruswami2008Explicit},~\cite{brauchle2015} and the Justesen-like decoder for high-rate folded Ga\-bi\-du\-lin codes~\cite{bartz2015list,BartzSidorenko_FoldedGabidulin2015_DCC,bartz2017algebraic}.
Compared to the Guruswami--Rudra-like decoder from~\autoref{sec:decoding}, the proposed Justesen-like decoder uses additional interpolation points to improve the decoding performance for higher code rates.
In particular, we allow the sliding window of size $\intDim+1$ to wrap around to the neighboring symbols (except for the last symbol in each block).

As before we choose an interpolation parameter $\intDim \in \NN^{\ast}$ satisfying~\eqref{eq:intDimConstraint}.
Then for each $i = 1, \dots, \shots$ we get the index set $\set{W}_i^\text{HR}$ and the corresponding interpolation-point set $\set{P}_i^\text{HR}$ as
\begin{gather}\label{eq:intPointDefJustesen}
    \begin{aligned}
         \set{W}_i^\text{HR} \defeq &\left\{ (j-1) \foldParShot{i} + l :
         j \in \{1, \ldots, \lenFLRSshot{i}-1\}, l \in \{1, \ldots, \foldParShot{i}\} \right\}
         \\
         \cup
         &\left\{ (\lenFLRSshot{i}-1) \foldParShot{i} + l :
         l \in \{1, \ldots, \foldParShot{i} - \intDim + 1\} \right\}
         \\
        \text{and} \quad
        \set{P}_i^\text{HR} \defeq &\left\{ \left( \pe^{w-1}, r_{w}^{(i)}, r_{w+1}^{(i)}, \dots, r_{w+\intDim-1}^{(i)} \right):
        w \in \set{W}_i^\text{HR} \right\}.
    \end{aligned}
\end{gather}

\begin{remark}
    The additional interpolation points for each block $i = 1, \dots, \shots$ compared to the Guruswami--Rudra-like
    decoder can be easily deduced by the equality
    \begin{equation}
        \set{W}_i^\text{HR} = \set{W}_i \cup \left\{ (j-1) \foldParShot{i} + l :
        j \in \{1, \ldots, \lenFLRSshot{i} - 1\}, l \in \{\foldParShot{i} - \intDim + 2, \ldots, \foldParShot{i}\} \right\}.
    \end{equation}
\end{remark}

\begin{example}
    When we consider the code from~\autoref{ex:int_points}, the interpolation points for the high-rate decoder are
    \begin{equation}
        \set{P}_1^\text{HR} = \set{P}_1 \cup \Big\{ (\pe^2, r_3^{(1)}, r_4^{(1)}) \Big\}
        \qquad \text{and} \qquad
        \set{P}_2^\text{HR} = \set{P}_2 \cup \Big\{ (\pe, r_2^{(2)}, r_3^{(2)}) \Big\}.
    \end{equation}
\end{example}

\begin{problem}[High-Rate Interpolation Problem] \label{prob:intProblemFLRSjustesen}
    Solve~\autoref{prob:intProblemFLRS} with the input sets $\set{P}_1^\text{HR}, \allowbreak \dots,\allowbreak \set{P}_{\shots}^\text{HR}$,
    where the $i$-th set is associated to evaluation parameter $a_i$.
\end{problem}

Since the interpolation point set $\set{P}^\text{HR} \defeq \bigcup_{i=1}^{\shots} \set{P}_i^\text{HR}$ contains
\begin{equation*}
    \vert \set{P}^\text{HR} \vert = \sum_{i=1}^{\shots} \left(\lenFLRSshot{i}\foldParShot{i} - (\intDim - 1)\right)
    = \len - \shots(\intDim - 1)
\end{equation*}
interpolation points, we get the following condition for the existence of a nonzero solution of the high-rate
interpolation problem:

\begin{lemma}[Existence]\label{lem:degConstraintForExistenceJustesen}
    A nonzero solution to~\autoref{prob:intProblemFLRSjustesen} exists if
    \begin{equation} \label{eq:deg_constraint_existence_justesen}
        \degConstraint = \left\lceil
        \frac{\sum_{i=1}^{\shots} \lenFLRSshot{i}\foldParShot{i} - \shots(\intDim-1) + \intDim (k-1) + 1}{\intDim + 1}
        \right\rceil.
    \end{equation}
\end{lemma}

\begin{proof}
    \autoref{prob:intProblemFLRSjustesen} forms a homogeneous linear system of $\sum_{i=1}^{\shots} \left(\lenFLRSshot{i}\foldParShot{i} - (\intDim - 1)\right)$ equations in $\degConstraint(\intDim + 1) - \intDim(k - 1)$ unknowns, which has a nontrivial solution if less equations than unknowns are involved.
    This is satisfied for~\eqref{eq:deg_constraint_existence_justesen}.
\end{proof}

The new choice $\set{P}^{\text{HR}}$ of interpolation points yields at least as many uncorrupted interpolation points as $\set{P}$.
Hence, we also get at least as many $\Fq$-linearly independent zeros of the corresponding univariate polynomial $P$.

\begin{lemma}[Roots of Polynomial]\label{lem:decConditionFLRSjustesen}
    Define the univariate skew polynomial
    \begin{align}
        P(x) &\defeq Q_0(x)+Q_1(x)f(x)+Q_2(x)f(x)\pe+\dots+Q_\intDim(x)f(x)\pe^{\intDim - 1} \\
        &= Q(x, f(x), f(x)\pe, \dots, f(x)\pe^{\intDim-1}) \in \SkewPolyring
    \end{align}
    and write $t_i \defeq \rk_q(\mat{E}^{(i)})$ for $1 \leq i \leq \shots$.
    Then there exist $\Fq$-linearly independent elements
    $\zeta_1^{(i)}, \dots, \zeta_{\lenFLRSshot{i} \foldParShot{i} - (\intDim-1) - t_i(\foldParShot{i} + \intDim - 1)}^{(i)} \in \Fqm$ for each
    $i \in \{1, \dots, \shots\}$ such that $\opev{P}{\zeta_j^{(i)}}{a_i} = 0$ for all $1 \leq i \leq \shots$ and all
    $1 \leq j \leq \lenFLRSshot{i} \foldParShot{i} - (\intDim-1) - t_i(\foldParShot{i} + \intDim - 1)$.
\end{lemma}

\begin{proof}
    Since $\rk_q(\mat{E}^{(i)}) = t_i$, there exists a nonsingular matrix $\mat{T}_i \in \Fq^{\lenFLRSshot{i} \times \lenFLRSshot{i}}$ such that $\mat{E}^{(i)}\mat{T}_i$ has only $t_i$ nonzero columns for every $i \in \{1, \ldots, \shots\}$.
    Without loss of generality assume that these columns are the last ones of $\mat{E}^{(i)}\mat{T}_i$ and define $\veczeta^{(i)} = \L \cdot \mat{T}_i$ with $\L \in \Fqm^{\foldParShot{i} \times \lenFLRSshot{i}}$ containing the code locators $1, \dots, \pe^{\lenShot{i}-1}$ (cp.~\eqref{eq:defFLRScodeblock}).
    Note that the first $\lenFLRSshot{i} - t_i$ columns of $\R^{(i)} \mat{T}_i = \C^{(i)}\mat{T}_i + \E^{(i)}\mat{T}_i$ are noncorrupted leading to $\lenFLRSshot{i} \foldParShot{i} - (\intDim-1) - t_i(\foldParShot{i} + \intDim - 1)$ noncorrupted interpolation points according to~\eqref{eq:intPointDefJustesen}.
    Now, for each $1 \leq i \leq \shots$, the first entries of the $\lenFLRSshot{i} \foldParShot{i} - (\intDim-1) - t_i(\foldParShot{i} + \intDim - 1)$ noncorrupted interpolation points (i.e.\ the top left submatrix of size $(\lenFLRSshot{i} - t_i) \times (\foldParShot{i} - \intDim + 1)$ of $\zeta^{(i)}$) are by construction both $\Fq$-linearly independent and roots of $P(x)$.
\end{proof}

This results in a different decoding radius, which is shown below.

\begin{theorem}[Decoding Radius] \label{thm:decodingRadiusJustesen}
    Let $Q(x,y_1,\dots,y_\intDim)$ be a nonzero solution of~\autoref{prob:intProblemFLRSjustesen}.
    If the error-weight decomposition $\t = (t_1, \dots, t_{\shots})$ satisfies
    \begin{equation}\label{eq:listDecRegionFLRSjustesen}
        \sum_{i=1}^{\shots} t_i (\foldParShot{i} + \intDim - 1)
        < \frac{\intDim}{\intDim+1} \left( \sum_{i=1}^{\shots} \lenFLRSshot{i}\foldParShot{i} - \shots(\intDim - 1) - k + 1 \right),
    \end{equation}
    then $P \in \SkewPolyring$ is the zero polynomial, that is for all $x \in \Fqm$
    \begin{equation}\label{eq:rootFindingEquationFLRSjustesen}
        P(x)=Q_0(x)+Q_1(x)f(x)+\!\cdots\!+Q_\intDim(x)f(x)\pe^{\intDim-1}=0.
    \end{equation}
\end{theorem}

\begin{proof}
    By~\autoref{lem:decConditionFLRSjustesen}, there exist elements $\zeta_1^{(i)}, \dots, \zeta_{\lenFLRSshot{i} \foldParShot{i} - (\intDim-1) - t_i(\foldParShot{i} + \intDim - 1)}^{(i)}$ in $\Fqm$ that are $\Fq$-linearly independent for each $i \in \{1, \dots, \shots\}$ such that $\opev{P}{\zeta_j^{(i)}}{a_i} = 0$ for all $1 \leq i \leq \shots$ and $1 \leq j \leq \lenFLRSshot{i} \foldParShot{i} - (\intDim-1) - t_i(\foldParShot{i} + \intDim - 1)$.
    By choosing
    \begin{equation} \label{eq:degConstExceedsBoundJustesen}
        \degConstraint \leq \sum_{i=1}^{\shots} \left(\lenFLRSshot{i} \foldParShot{i} - (\intDim-1) - t_i(\foldParShot{i} + \intDim - 1)\right)
    \end{equation}
    $P(x)$ exceeds the degree bound from~\cite[Prop.~1.3.7]{caruso2019residues} which is possible only if $P(x)=0$.
    By combining~\eqref{eq:degConstExceedsBoundJustesen} with~\eqref{eq:deg_constraint_existence_justesen} we get
    \begin{align*}
        \sum_{i=1}^{\shots} \left(\lenFLRSshot{i}\foldParShot{i} - (\intDim - 1)\right) + \intDim (k - 1)
        &< (\intDim + 1) \left(\sum_{i=1}^{\shots} \left(\lenFLRSshot{i} \foldParShot{i} - (\intDim-1) - t_i(\foldParShot{i} + \intDim - 1)\right)\right)
        \\
        \iff \qquad
        \sum_{i=1}^{\shots} t_i (\foldParShot{i} + \intDim - 1)
        &< \frac{\intDim}{\intDim+1} \left( \sum_{i=1}^{\shots} \lenFLRSshot{i}\foldParShot{i} - \shots(\intDim - 1) - k + 1 \right).
    \end{align*}
\end{proof}

For the same folding parameter $h \in \NN^{\ast}$ for all blocks the decoding radius in~\eqref{eq:listDecRegionFLRSjustesen} simplifies to
\begin{equation} \label{eq:decoding_region_justesen_same_h}
    t < \frac{\intDim}{\intDim+1} \left(\frac{\lenFLRS \foldPar -\shots(\intDim - 1)-k+1}{\foldPar+\intDim-1}\right)
\end{equation}
which for $\shots=1$ coincides with the result for high-rate folded Gabidulin codes from~\cite{bartz2015list,BartzSidorenko_FoldedGabidulin2015_DCC,bartz2017algebraic}.

Similar to~\eqref{eq:normalized_decoding_radius}, we also derive the normalized decoding radius $\tau \defeq
\frac{t}{\lenFLRS}$ for codes with the same folding parameter $\foldPar$ for each block
from~\eqref{eq:decoding_region_justesen_same_h} and obtain
\begin{align} \label{eq:normalized_decoding_radius_Justesen}
    \tau = \frac{t}{\lenFLRS} &< \frac{\intDim}{\intDim+1} \left( \frac{\lenFLRS \foldPar - \shots (\intDim - 1) - k + 1}
    {\lenFLRS (\foldPar + \intDim - 1)} \right)
    \\
    &\xrightarrow{\lenFLRS \to \infty}
    \frac{\intDim}{\intDim+1} \frac{\foldPar}{\foldPar + \intDim - 1} \left( 1 - R \right)
\end{align}
for the code rate $R \defeq \frac{k}{\foldPar \lenFLRS}$.

\autoref{thm:decodingRadiusJustesen} shows that if the weight decomposition $\t$ of the error satisfies~\eqref{eq:listDecRegionFLRSjustesen}, a list containing the message polynomial $f \in \SkewPolyring_{< k}$ can be obtained by finding all solutions of~\eqref{eq:rootFindingEquationFLRSjustesen}.
This coincides with the root-finding problem from~\autoref{subsec:root-finding-step} and we can hence summarize the list decoder for high-rate \ac{FLRS} codes as follows:

\begin{theorem}[List Decoding] \label{thm:listDecodingJustesen}
    Consider an \ac{FLRS} code $\foldedLinRS{\pe, \a, \foldParVec; \lenFLRSVec, k}$ and a codeword
    $\C$ that is transmitted over a sum-rank channel such that the error has weight $t$ and its weight decomposition
    $\t = (t_1, \dots, t_{\shots})$ satisfies
    \begin{equation}
       \sum_{i=1}^{\shots} t_i (\foldParShot{i} + \intDim - 1)
        < \frac{\intDim}{\intDim+1} \left( \sum_{i=1}^{\shots} \lenFLRSshot{i}\foldParShot{i} - \shots(\intDim - 1) - k + 1 \right)
    \end{equation}
    for an interpolation parameter $1 \leq \intDim \leq \min_{i \in \{1, \dots, \shots\}} \foldParShot{i}$.
    Then, a basis of an at most $(\intDim - 1)$-dimensional $\Fqm$-vector space that contains candidate message polynomials
    satisfying~\eqref{eq:rootFindingEquationFLRSjustesen} can be obtained in at most $\OCompl{\intDim \len^2}$ operations in $\Fqm$.
\end{theorem}


By following the ideas of~\autoref{lem:intSolutionDim} we observe that the dimension of the $\Fqm$-linear solution space of the interpolation system for the Justesen-like decoder satisfies
\begin{equation*}
    d_I \geq \intDim(\degConstraint - k + 1) - \sum_{i=1}^{\shots} t_i(\foldParShot{i} - \intDim + 1).
\end{equation*}
Imposing the threshold $d_I \geq \mu$ yields to the degree constraint
\begin{equation}
    \degConstraint = \left\lceil \frac{\sum_{i=1}^{\shots}\lenFLRSshot{i} \foldParShot{i} - \shots(\intDim -1) - \intDim(k - 1) + \mu}{\intDim + 1} \right \rceil
\end{equation}
which lets us provide a summary for probabilistic unique decoding of \ac{FLRS} codes in~\autoref{thm:probabilisticUniqueDecodingJustesen}.

\begin{theorem}[Probabilistic Unique Decoding] \label{thm:probabilisticUniqueDecodingJustesen}
    For an interpolation parameter $1 \leq \intDim \leq \min_{i \in \{1, \dots, \shots\}} \foldParShot{i}$ and a dimension threshold $\mu \in \NN^{\ast}$, transmit a codeword $\C$ of an \ac{FLRS} code $\foldedLinRS{\pe, \a, \foldParVec; \lenFLRSVec, k}$ over a sum-rank channel.
    If the coefficients of the polynomials $B_0^{(u)}(x)$ for $u \in \{1, \ldots, \mu\}$ are independent and uniformly distributed among $\Fqm$ and the error-weight decomposition
    $\t = (t_1, \dots, t_{\shots})$ satisfies
    \begin{equation}
       \sum_{i=1}^{\shots} t_i (\foldParShot{i} + \intDim - 1)
        \leq \frac{\intDim}{\intDim+1} \left( \sum_{i=1}^{\shots} \lenFLRSshot{i}\foldParShot{i} - \shots(\intDim - 1) - k + 1 \right)
        - \frac{\mu}{\intDim + 1},
    \end{equation}
    $\C$ can be uniquely recovered with complexity $\OCompl{\intDim \len^2}$ in $\Fqm$ with an approximate probability of at least
    \begin{equation}
        1 - k \cdot \left( \frac{k}{q^m} \right)^{\mu}.
    \end{equation}
\end{theorem}

For the same folding parameter $\foldPar$ for each block, we get the decoding radius
\begin{equation}
    t \leq \frac{\intDim}{\intDim + 1}
    \left( \frac{\lenFLRS\foldPar - k + 1 - \shots(\intDim - 1)}{\foldPar + \intDim - 1} \right)
    - \frac{\mu}{(\intDim + 1)(\foldPar + \intDim - 1)}
\end{equation}
which for $\shots = 1$ coincides with the probabilistic unique decoding radius for folded Gabidulin codes (cf.~\cite[Thm.~3]{BartzSidorenko_FoldedGabidulin2015_DCC}).

\autoref{fig:radiusFLRSopt} illustrates the normalized decoding radii of the presented Gu\-ru\-swa\-mi--Ru\-dra- and Justesen-like decoders for \ac{FLRS} codes.
In particular, the significant improvement upon unique decoding is shown.

\begin{figure}[ht!]
    \centering
\begin{tikzpicture}

\begin{axis}[%
scale=1.27,
xmin=0,
xmax=1,
xlabel={Code Rate R},
xmajorgrids,
ymin=0,
ymax=1,
ylabel={Fraction of correctable errors $\tau$},
ymajorgrids,
legend style={legend cell align=left,align=left,draw=white!15!black}
]
\addplot [style=SB]
  table[row sep=crcr]{%
0	1\\
0.05	0.95\\
0.1	0.9\\
0.15	0.85\\
0.2	0.8\\
0.25	0.75\\
0.3	0.7\\
0.35	0.65\\
0.4	0.6\\
0.45	0.55\\
0.5	0.5\\
0.55	0.45\\
0.6	0.4\\
0.65	0.35\\
0.7	0.3\\
0.75	0.25\\
0.8	0.2\\
0.85	0.15\\
0.9	0.1\\
0.95	0.05\\
1	0\\
};
\addlegendentry{Singleton-like Bound}

\addplot [style=LRS]
  table[row sep=crcr]{%
0 0.5\\
0.05  0.475\\
0.1 0.45\\
0.15  0.425\\
0.2 0.4\\
0.25  0.375\\
0.3 0.35\\
0.35  0.325\\
0.4 0.3\\
0.45  0.275\\
0.5 0.25\\
0.55  0.225\\
0.6 0.2\\
0.65  0.175\\
0.7 0.15\\
0.75  0.125\\
0.8 0.1\\
0.85  0.075\\
0.9 0.05\\
0.95  0.025\\
1 0\\
};
\addlegendentry{Unique (F)LRS Decoder}

\addplot [style=FLRS]
  table[row sep=crcr]{%
0.0 0.9615384615384616 \\
0.05 0.8406593406593407 \\
0.1 0.7676470588235295 \\
0.15 0.7037037037037037 \\
0.2 0.6447368421052632 \\
0.25 0.5892857142857143 \\
0.3 0.5357142857142857 \\
0.35 0.4861111111111111 \\
0.4 0.4365079365079365 \\
0.45 0.39090909090909093 \\
0.5 0.34545454545454546 \\
0.55 0.3016304347826087 \\
0.6 0.2608695652173913 \\
0.65 0.22010869565217392 \\
0.7 0.18055555555555555 \\
0.75 0.14583333333333334 \\
0.8 0.1111111111111111 \\
0.85 0.0763888888888889 \\
0.9 0.05 \\
0.95 0.025 \\
1.0 0.0 \\
};
\addlegendentry{Guruswami--Rudra-like\\FLRS Decoder~\eqref{eq:normalized_decoding_radius}}

\addplot [style=HRFLRS]
  table[row sep=crcr]{%
0.0 0.7183908045977011 \\
0.05 0.682471264367816 \\
0.1 0.646551724137931 \\
0.15 0.610632183908046 \\
0.2 0.5747126436781609 \\
0.25 0.5387931034482758 \\
0.3 0.5028735632183907 \\
0.35 0.46695402298850575 \\
0.4 0.43103448275862066 \\
0.45 0.39511494252873564 \\
0.5 0.35919540229885055 \\
0.55 0.32327586206896547 \\
0.6 0.28735632183908044 \\
0.65 0.25143678160919536 \\
0.7 0.21551724137931036 \\
0.75 0.17959770114942528 \\
0.8 0.1436781609195402 \\
0.85 0.10775862068965518 \\
0.9 0.0718390804597701 \\
0.95 0.03591954022988509 \\
1.0 0.0 \\
};
\addlegendentry{Justesen-like\\FLRS Decoder~\eqref{eq:normalized_decoding_radius_Justesen}}

\end{axis}
\end{tikzpicture}%
    \caption{
        Normalized decoding radius $\tau \defeq \frac{t}{\lenFLRS}$ vs. code rate $R \defeq \frac{k}{\lenFLRS \foldPar}$
        for an \ac{FLRS} code with the same folding parameter $\foldPar = 25$ for each block and optimal decoding
        parameter $\intDim \leq \foldPar$ for each code rate.
    }
    \label{fig:radiusFLRSopt}
\end{figure}

\subsection{Simulation Results} \label{subsec:simulation_results}

We ran simulations\footnote{The underlying data can be shared upon reasonable request.} in SageMath~\cite{sage} to empirically verify the heuristic upper bound for probabilistic unique
decoding that we derived in~\autoref{thm:probabilisticUniqueDecoding}.
We designed the parameter sets to obtain experimentally observable failure probabilities.
Therefore, we considered codes with parameters
\begin{equation}
    q = 3, \qquad m = 6, \qquad k = 2, \qquad \lenVec = (6, 6),
\end{equation}
and with two different vectors $\foldParVec \in \{ (3, 3), (3, 2) \}$ of folding parameters.
The code using $\foldParVec = (3, 3)$ has minimum distance $4$ which implies a unique-decoding
radius of $1.5$.
In contrast, the proposed probabilistic unique decoder with $\intDim = 2$ allows to correct errors of weight $t = 2$ for $\mu
\in \{1, 2\}$.
Namely, the bound~\eqref{eq:prob_unique_decoding_radius} yields $t \leq 2.17$ for $\mu = 1$ and $t \leq 2$ for $\mu = 2$.
We investigated the case $\mu = 1$ by means of a Monte Carlo simulation and collected $100$ decoding failures within
about $4.23 \cdot 10^7$ transmissions with randomly chosen error patterns of fixed sum-rank weight $t = 2$.
This gives an observed failure probability of about $2.36 \cdot 10^{-6}$, while the heuristic yields an upper bound of
$5.49 \cdot 10^{-3}$.

For $\foldParVec = (3, 2)$, the code has the higher minimum distance $5$
and a unique-decoding radius of $2$.
Its decodable error-weight decompositions with respect to the probabilistic unique decoder with $\intDim = 2$ and
$\mu \in \{1, 2, 3\}$ are
\begin{itemize}
    \item $(0, 1)$ and $(1, 0)$, i.e.\ all possible patterns for weight $t = 1$,
    \item $(0, 2)$ and $(1, 1)$, i.e.\ two out of three possible patterns for weight $t = 2$,
    \item and $(0, 3)$, i.e.\ one out of three possible patterns for weight $t = 3$.
\end{itemize}
Note that the error patterns are not equally likely.
For example, being able to correct one out of two error-weight decompositions for a given weight does not necessarily
mean that half of all errors of the given sum-rank weight can be corrected.
We ran two Monte Carlo simulations for $t = 2$ and $t = 3$ and collected in both cases $100$ failures for $\mu = 1$.
The errors were chosen uniformly at random from the set of all vectors having the prescribed sum-rank weight as well as
a decodable weight decomposition.
The observed failure probability was $1.11 \cdot 10^{-3}$ for $t = 2$ ($100$ failures in about $9.03 \cdot 10^{4}$ runs)
and $2.11 \cdot 10^{-5}$ for $t = 3$ ($100$ failures in $4.73 \cdot 10^{6}$ runs).
In both scenarios, the heuristic upper bound is $5.49 \cdot 10^{-3}$ as for the first code.

Similar to results in~\cite{wachter2013decoding,BartzSidorenko_FoldedGabidulin2015_DCC}, our heuristic upper bound is based on the assumption that the coefficients of the polynomials $B_0^{(u)}(x)
\in \mathbb{F}_{729}[x]$ with $1 \leq u \leq \mu$ defined in~\eqref{eq:rf_polys} are uniformly distributed among
$\F_{729}$.
Unfortunately, this assumption was not backed by evidence in former work.
We thus decided to investigate experimentally observed distributions and compare them with the uniform distribution
by means of the \emph{\ac{KL} divergence}.
The \ac{KL} divergence (or \emph{relative entropy},
see~\cite[Sec.~2.3]{cover2006elementsOfInformationTheory}) is a tool to measure the distance between two probability
distributions, that is often used in coding and information theory.
Note that it is not a metric in the mathematical sense but provides sufficient insights for our purpose.
In particular, it is an upper bound for other widely used statistical distance measures as e.g.~the total variation distance~\cite{Gibbs2002probabilityMetrics}.

The \ac{KL} divergence of two probability mass functions $u(x)$ and $v(x)$, that are defined over a finite
alphabet $\set{A}$, is defined as
\begin{equation}
    D_{KL}(u \,||\, v) \defeq \sum_{x \in \set{A}} u(x) \log \left( \frac{u(x)}{v(x)} \right).
\end{equation}
We understand $0 \cdot \log( \frac{0}{q} ) \defeq 0$ for any $q$ and $p \cdot \log( \frac{p}{0} ) \defeq \infty$ for any
nonzero $p$ by convention.
We follow the common approach and consider the logarithm with base 2 and thus measure the \acl{KL} divergence in bits.
Note that the divergence is always nonnegative and it equals zero if and only if the two considered probability mass
functions are equal (see e.g.~\cite[Thm.~2.6.3]{cover2006elementsOfInformationTheory})).

Denote the observed probability mass function of the coefficients of the polynomials $B_0^{(1)}(x) \in \mathbb{F}_{729}[x]$
from~\eqref{eq:rf_polys} after $10^{6}$ transmissions by $\chi$ and let $\unif_{\F_{729}}$ be the probability mass
function of the uniform distribution among $\F_{729}$.
We obtained the \ac{KL} divergence values
\begin{itemize}
    \item $D_{KL}(\chi \,||\, \unif_{\F_{729}}) \approx 3.32 \cdot 10^{-4}$ bits for $\foldParVec = (3, 3)$ and $t = 2$,
    \item $D_{KL}(\chi \,||\, \unif_{\F_{729}}) \approx 2.30 \cdot 10^{-4}$ bits for $\foldParVec = (3, 2)$ and $t = 2$, and
    \item $D_{KL}(\chi \,||\, \unif_{\F_{729}}) \approx 3.42 \cdot 10^{-4}$ bits for $\foldParVec = (3, 2)$ and $t = 3$.
\end{itemize}
This shows that the measured distribution is in all cases remarkably close to the uniform distribution, which justifies
the assumption in~\autoref{thm:probabilisticUniqueDecoding}.
The results are illustrated in more detail in~\autoref{fig:distributions_and_divergence}, where the subfigures~(a)--(c)
show the probability mass functions $\chi$ of the coefficients that were observed within $10^{6}$ transmissions for
$\foldParVec = (3, 3)$ with error weight $t = 2$ and for $\foldParVec = (3, 2)$ with error weight $t = 2$ and $t = 3$, respectively.
The red line marks the (in fact discrete) probability mass function $\unif_{\F_{729}}$ of the uniform distribution for
reference.
Subfigure (d) shows the evolution of the \acl{KL} divergence $D_{KL}(\chi \,||\, \unif_{\F_{729}})$ over the
$10^{6}$ runs for all investigated scenarios.

\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{.48\textwidth}
        \centering
        \resizebox{\textwidth}{!}{%
\begin{tikzpicture}
	\begin{axis}[%
		scale=2.25,
		xlabel={field element (randomly indexed)},
		xmajorgrids,
		ymin=0.00055,
		ymax=0.0015,
		ylabel={observed probability},
		ymajorgrids,
		legend style={legend pos=south west,legend cell align=left,align=left,draw=white!15!black}
		]
		\addplot [style=distribution, only marks] table[row sep=crcr]{%
0 0.001369 \\
1 0.001364 \\
2 0.001361 \\
3 0.001389 \\
4 0.001397 \\
5 0.001367 \\
6 0.001359 \\
7 0.001370 \\
8 0.001405 \\
9 0.001375 \\
10 0.001381 \\
11 0.001362 \\
12 0.001362 \\
13 0.001406 \\
14 0.001376 \\
15 0.001380 \\
16 0.001378 \\
17 0.001393 \\
18 0.001371 \\
19 0.001378 \\
20 0.001339 \\
21 0.001373 \\
22 0.001376 \\
23 0.001376 \\
24 0.001373 \\
25 0.001387 \\
26 0.001351 \\
27 0.001387 \\
28 0.001379 \\
29 0.001365 \\
30 0.001375 \\
31 0.001364 \\
32 0.001380 \\
33 0.001367 \\
34 0.001394 \\
35 0.001349 \\
36 0.001381 \\
37 0.001385 \\
38 0.001355 \\
39 0.001384 \\
40 0.001367 \\
41 0.001391 \\
42 0.001382 \\
43 0.001341 \\
44 0.001373 \\
45 0.001385 \\
46 0.001404 \\
47 0.001391 \\
48 0.001375 \\
49 0.001357 \\
50 0.001375 \\
51 0.001361 \\
52 0.001363 \\
53 0.001368 \\
54 0.001387 \\
55 0.001386 \\
56 0.001356 \\
57 0.001368 \\
58 0.001381 \\
59 0.001357 \\
60 0.001389 \\
61 0.001357 \\
62 0.001363 \\
63 0.001392 \\
64 0.001383 \\
65 0.001383 \\
66 0.001373 \\
67 0.001383 \\
68 0.001381 \\
69 0.001404 \\
70 0.001358 \\
71 0.001346 \\
72 0.001372 \\
73 0.001385 \\
74 0.001355 \\
75 0.001368 \\
76 0.001343 \\
77 0.001359 \\
78 0.001371 \\
79 0.001375 \\
80 0.001382 \\
81 0.001366 \\
82 0.001376 \\
83 0.001367 \\
84 0.001378 \\
85 0.001377 \\
86 0.001374 \\
87 0.001368 \\
88 0.001403 \\
89 0.001368 \\
90 0.001358 \\
91 0.001377 \\
92 0.001347 \\
93 0.001376 \\
94 0.001346 \\
95 0.001364 \\
96 0.001383 \\
97 0.001375 \\
98 0.001373 \\
99 0.001380 \\
100 0.001413 \\
101 0.001370 \\
102 0.001386 \\
103 0.001347 \\
104 0.001401 \\
105 0.001386 \\
106 0.001349 \\
107 0.001347 \\
108 0.001382 \\
109 0.001373 \\
110 0.001384 \\
111 0.001376 \\
112 0.001386 \\
113 0.001376 \\
114 0.001355 \\
115 0.001383 \\
116 0.001361 \\
117 0.001372 \\
118 0.001347 \\
119 0.001388 \\
120 0.001393 \\
121 0.001356 \\
122 0.001363 \\
123 0.001383 \\
124 0.001375 \\
125 0.001373 \\
126 0.001383 \\
127 0.001388 \\
128 0.001361 \\
129 0.001348 \\
130 0.001379 \\
131 0.001365 \\
132 0.001376 \\
133 0.001361 \\
134 0.001373 \\
135 0.001385 \\
136 0.001368 \\
137 0.001348 \\
138 0.001363 \\
139 0.001358 \\
140 0.001373 \\
141 0.001388 \\
142 0.001358 \\
143 0.001373 \\
144 0.001360 \\
145 0.001387 \\
146 0.001395 \\
147 0.001381 \\
148 0.001388 \\
149 0.001355 \\
150 0.001368 \\
151 0.001367 \\
152 0.001391 \\
153 0.001367 \\
154 0.001361 \\
155 0.001395 \\
156 0.001352 \\
157 0.001368 \\
158 0.001363 \\
159 0.001371 \\
160 0.001354 \\
161 0.001363 \\
162 0.001378 \\
163 0.001359 \\
164 0.001369 \\
165 0.001385 \\
166 0.001415 \\
167 0.001373 \\
168 0.001401 \\
169 0.001388 \\
170 0.001378 \\
171 0.001366 \\
172 0.001397 \\
173 0.001373 \\
174 0.001383 \\
175 0.001394 \\
176 0.001370 \\
177 0.001369 \\
178 0.001392 \\
179 0.001355 \\
180 0.001385 \\
181 0.001368 \\
182 0.001375 \\
183 0.001365 \\
184 0.001361 \\
185 0.001351 \\
186 0.001360 \\
187 0.001380 \\
188 0.001385 \\
189 0.001403 \\
190 0.001357 \\
191 0.001354 \\
192 0.001392 \\
193 0.001353 \\
194 0.001367 \\
195 0.001381 \\
196 0.001366 \\
197 0.001377 \\
198 0.001371 \\
199 0.001371 \\
200 0.001382 \\
201 0.001392 \\
202 0.001376 \\
203 0.001363 \\
204 0.001389 \\
205 0.001363 \\
206 0.001362 \\
207 0.001343 \\
208 0.001393 \\
209 0.001349 \\
210 0.001381 \\
211 0.001385 \\
212 0.001389 \\
213 0.001379 \\
214 0.001356 \\
215 0.001376 \\
216 0.001385 \\
217 0.001363 \\
218 0.001376 \\
219 0.001384 \\
220 0.001367 \\
221 0.001360 \\
222 0.001361 \\
223 0.001350 \\
224 0.001376 \\
225 0.001360 \\
226 0.001392 \\
227 0.001380 \\
228 0.001349 \\
229 0.001390 \\
230 0.001391 \\
231 0.001399 \\
232 0.001380 \\
233 0.001373 \\
234 0.001382 \\
235 0.001350 \\
236 0.001376 \\
237 0.001366 \\
238 0.001392 \\
239 0.001372 \\
240 0.001380 \\
241 0.001371 \\
242 0.001361 \\
243 0.001344 \\
244 0.001314 \\
245 0.001383 \\
246 0.001374 \\
247 0.001378 \\
248 0.001370 \\
249 0.001400 \\
250 0.001356 \\
251 0.001394 \\
252 0.001379 \\
253 0.001370 \\
254 0.001384 \\
255 0.001381 \\
256 0.001369 \\
257 0.001382 \\
258 0.001382 \\
259 0.001334 \\
260 0.001368 \\
261 0.001379 \\
262 0.001368 \\
263 0.001390 \\
264 0.001391 \\
265 0.001362 \\
266 0.001396 \\
267 0.001369 \\
268 0.001356 \\
269 0.001421 \\
270 0.001373 \\
271 0.001380 \\
272 0.001386 \\
273 0.001370 \\
274 0.001372 \\
275 0.001379 \\
276 0.001349 \\
277 0.001366 \\
278 0.001369 \\
279 0.001369 \\
280 0.001368 \\
281 0.001360 \\
282 0.001349 \\
283 0.001371 \\
284 0.001355 \\
285 0.001394 \\
286 0.001399 \\
287 0.001393 \\
288 0.001358 \\
289 0.001369 \\
290 0.001382 \\
291 0.001360 \\
292 0.001362 \\
293 0.001364 \\
294 0.001371 \\
295 0.001349 \\
296 0.001365 \\
297 0.001386 \\
298 0.001378 \\
299 0.001377 \\
300 0.001390 \\
301 0.001363 \\
302 0.001384 \\
303 0.001382 \\
304 0.001353 \\
305 0.001367 \\
306 0.001357 \\
307 0.001353 \\
308 0.001384 \\
309 0.001349 \\
310 0.001363 \\
311 0.001354 \\
312 0.001354 \\
313 0.001397 \\
314 0.001338 \\
315 0.001400 \\
316 0.001368 \\
317 0.001385 \\
318 0.001399 \\
319 0.001365 \\
320 0.001392 \\
321 0.001386 \\
322 0.001380 \\
323 0.001363 \\
324 0.001378 \\
325 0.001382 \\
326 0.001354 \\
327 0.001393 \\
328 0.001391 \\
329 0.001368 \\
330 0.001361 \\
331 0.001399 \\
332 0.001387 \\
333 0.001364 \\
334 0.001369 \\
335 0.001346 \\
336 0.001345 \\
337 0.001368 \\
338 0.001370 \\
339 0.001392 \\
340 0.001377 \\
341 0.001349 \\
342 0.001381 \\
343 0.001368 \\
344 0.001359 \\
345 0.001377 \\
346 0.001355 \\
347 0.001382 \\
348 0.001372 \\
349 0.001370 \\
350 0.001347 \\
351 0.001360 \\
352 0.001350 \\
353 0.001378 \\
354 0.001387 \\
355 0.001350 \\
356 0.001374 \\
357 0.001350 \\
358 0.001392 \\
359 0.001360 \\
360 0.001380 \\
361 0.001402 \\
362 0.001392 \\
363 0.001351 \\
364 0.001384 \\
365 0.001395 \\
366 0.001367 \\
367 0.001378 \\
368 0.001369 \\
369 0.001373 \\
370 0.001386 \\
371 0.001370 \\
372 0.001367 \\
373 0.001387 \\
374 0.001330 \\
375 0.001367 \\
376 0.001385 \\
377 0.001351 \\
378 0.001386 \\
379 0.001375 \\
380 0.001369 \\
381 0.001381 \\
382 0.001389 \\
383 0.001361 \\
384 0.001383 \\
385 0.001380 \\
386 0.001372 \\
387 0.001365 \\
388 0.001374 \\
389 0.001383 \\
390 0.001359 \\
391 0.001354 \\
392 0.001402 \\
393 0.001408 \\
394 0.001375 \\
395 0.001369 \\
396 0.001372 \\
397 0.001385 \\
398 0.001352 \\
399 0.001356 \\
400 0.001408 \\
401 0.001399 \\
402 0.001363 \\
403 0.001384 \\
404 0.001351 \\
405 0.001391 \\
406 0.001373 \\
407 0.001388 \\
408 0.001354 \\
409 0.001373 \\
410 0.001388 \\
411 0.001343 \\
412 0.001365 \\
413 0.001397 \\
414 0.001370 \\
415 0.001371 \\
416 0.001394 \\
417 0.001394 \\
418 0.001382 \\
419 0.001405 \\
420 0.001368 \\
421 0.001369 \\
422 0.001376 \\
423 0.001334 \\
424 0.001370 \\
425 0.001370 \\
426 0.001380 \\
427 0.001395 \\
428 0.001399 \\
429 0.001391 \\
430 0.001369 \\
431 0.001386 \\
432 0.001373 \\
433 0.001336 \\
434 0.001381 \\
435 0.001378 \\
436 0.001358 \\
437 0.001377 \\
438 0.001390 \\
439 0.001398 \\
440 0.001396 \\
441 0.001365 \\
442 0.001381 \\
443 0.001387 \\
444 0.001372 \\
445 0.001404 \\
446 0.001365 \\
447 0.001352 \\
448 0.001397 \\
449 0.001370 \\
450 0.001387 \\
451 0.001350 \\
452 0.001383 \\
453 0.001371 \\
454 0.001364 \\
455 0.001396 \\
456 0.001371 \\
457 0.001347 \\
458 0.001385 \\
459 0.001377 \\
460 0.001312 \\
461 0.001345 \\
462 0.001362 \\
463 0.001371 \\
464 0.001375 \\
465 0.001363 \\
466 0.001394 \\
467 0.001373 \\
468 0.001370 \\
469 0.001379 \\
470 0.001340 \\
471 0.001381 \\
472 0.001392 \\
473 0.001367 \\
474 0.001371 \\
475 0.001361 \\
476 0.001375 \\
477 0.001363 \\
478 0.001399 \\
479 0.001389 \\
480 0.001353 \\
481 0.001363 \\
482 0.001383 \\
483 0.001388 \\
484 0.001364 \\
485 0.001372 \\
486 0.001342 \\
487 0.001351 \\
488 0.001373 \\
489 0.001371 \\
490 0.001353 \\
491 0.001387 \\
492 0.001393 \\
493 0.001362 \\
494 0.001351 \\
495 0.001387 \\
496 0.001377 \\
497 0.001365 \\
498 0.001367 \\
499 0.001411 \\
500 0.001371 \\
501 0.001372 \\
502 0.001376 \\
503 0.001347 \\
504 0.001391 \\
505 0.001346 \\
506 0.001384 \\
507 0.001359 \\
508 0.001381 \\
509 0.001361 \\
510 0.001386 \\
511 0.001354 \\
512 0.001358 \\
513 0.001368 \\
514 0.001342 \\
515 0.001385 \\
516 0.001377 \\
517 0.001395 \\
518 0.001370 \\
519 0.001382 \\
520 0.001363 \\
521 0.001376 \\
522 0.001358 \\
523 0.001360 \\
524 0.001397 \\
525 0.001369 \\
526 0.001384 \\
527 0.001371 \\
528 0.001368 \\
529 0.001383 \\
530 0.001360 \\
531 0.001362 \\
532 0.001391 \\
533 0.001350 \\
534 0.001365 \\
535 0.001352 \\
536 0.001384 \\
537 0.001381 \\
538 0.001389 \\
539 0.001391 \\
540 0.001391 \\
541 0.001377 \\
542 0.001389 \\
543 0.001372 \\
544 0.001361 \\
545 0.001375 \\
546 0.001393 \\
547 0.001391 \\
548 0.001342 \\
549 0.001371 \\
550 0.001367 \\
551 0.001348 \\
552 0.001362 \\
553 0.001366 \\
554 0.001385 \\
555 0.001368 \\
556 0.001396 \\
557 0.001387 \\
558 0.001382 \\
559 0.001344 \\
560 0.001358 \\
561 0.001363 \\
562 0.001372 \\
563 0.001384 \\
564 0.001380 \\
565 0.001398 \\
566 0.001365 \\
567 0.001356 \\
568 0.001380 \\
569 0.001357 \\
570 0.001360 \\
571 0.001348 \\
572 0.001375 \\
573 0.001364 \\
574 0.001367 \\
575 0.001370 \\
576 0.001366 \\
577 0.001379 \\
578 0.001349 \\
579 0.001376 \\
580 0.001401 \\
581 0.001344 \\
582 0.001366 \\
583 0.001349 \\
584 0.001390 \\
585 0.001412 \\
586 0.001358 \\
587 0.001380 \\
588 0.001351 \\
589 0.001400 \\
590 0.001362 \\
591 0.001395 \\
592 0.001391 \\
593 0.001360 \\
594 0.001384 \\
595 0.001374 \\
596 0.001384 \\
597 0.001379 \\
598 0.001388 \\
599 0.001389 \\
600 0.001356 \\
601 0.001372 \\
602 0.001371 \\
603 0.001364 \\
604 0.001347 \\
605 0.001383 \\
606 0.001381 \\
607 0.000612 \\
608 0.001375 \\
609 0.001376 \\
610 0.001346 \\
611 0.001372 \\
612 0.001356 \\
613 0.001358 \\
614 0.001395 \\
615 0.001343 \\
616 0.001394 \\
617 0.001360 \\
618 0.001410 \\
619 0.001384 \\
620 0.001374 \\
621 0.001370 \\
622 0.001391 \\
623 0.001365 \\
624 0.001354 \\
625 0.001373 \\
626 0.001356 \\
627 0.001386 \\
628 0.001380 \\
629 0.001384 \\
630 0.001371 \\
631 0.001368 \\
632 0.001344 \\
633 0.001359 \\
634 0.001376 \\
635 0.001391 \\
636 0.001365 \\
637 0.001352 \\
638 0.001391 \\
639 0.001377 \\
640 0.001373 \\
641 0.001372 \\
642 0.001379 \\
643 0.001371 \\
644 0.001364 \\
645 0.001351 \\
646 0.001367 \\
647 0.001368 \\
648 0.001337 \\
649 0.001372 \\
650 0.001385 \\
651 0.001364 \\
652 0.001352 \\
653 0.001390 \\
654 0.001385 \\
655 0.001377 \\
656 0.001373 \\
657 0.001375 \\
658 0.001381 \\
659 0.001353 \\
660 0.001381 \\
661 0.001399 \\
662 0.001350 \\
663 0.001379 \\
664 0.001396 \\
665 0.001356 \\
666 0.001363 \\
667 0.001367 \\
668 0.001393 \\
669 0.001391 \\
670 0.001390 \\
671 0.001365 \\
672 0.001336 \\
673 0.001355 \\
674 0.001361 \\
675 0.001399 \\
676 0.001366 \\
677 0.001345 \\
678 0.001381 \\
679 0.001396 \\
680 0.001350 \\
681 0.001358 \\
682 0.001393 \\
683 0.001370 \\
684 0.001378 \\
685 0.001375 \\
686 0.001385 \\
687 0.001359 \\
688 0.001381 \\
689 0.001382 \\
690 0.001364 \\
691 0.001373 \\
692 0.001372 \\
693 0.001407 \\
694 0.001352 \\
695 0.001371 \\
696 0.001334 \\
697 0.001367 \\
698 0.001384 \\
699 0.001399 \\
700 0.001371 \\
701 0.001386 \\
702 0.001359 \\
703 0.001379 \\
704 0.001363 \\
705 0.001384 \\
706 0.001369 \\
707 0.001385 \\
708 0.001373 \\
709 0.001369 \\
710 0.001400 \\
711 0.001367 \\
712 0.001366 \\
713 0.001377 \\
714 0.001368 \\
715 0.001365 \\
716 0.001379 \\
717 0.001390 \\
718 0.001375 \\
719 0.001358 \\
720 0.001349 \\
721 0.001373 \\
722 0.001379 \\
723 0.001387 \\
724 0.001333 \\
725 0.001389 \\
726 0.001372 \\
727 0.001373 \\
728 0.001365 \\
		};
		\addlegendentry{$\foldParVec = (3, 3)$, $t = 2$}
		\draw[help lines, color=red] (axis cs:-100,0.001372) -- (axis cs:828,0.001372);
	\end{axis}
\end{tikzpicture}
        }
        \caption{Probability mass function for the code with $\foldParVec = (3, 3)$ and $t = 2$.}
        \label{fig:distribution-1}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{.48\textwidth}
        \centering
        \resizebox{\textwidth}{!}{%
\begin{tikzpicture}
	\begin{axis}[%
		scale=2.25,
		xlabel={field element (randomly indexed)},
		xmajorgrids,
		ymin=0.00055,
		ymax=0.0015,
		ylabel={observed probability},
		ymajorgrids,
		legend style={legend pos=south west,legend cell align=left,align=left,draw=white!15!black}
		]
		\addplot [style=distribution, only marks] table[row sep=crcr]{%
0 0.001397 \\
1 0.001381 \\
2 0.001343 \\
3 0.001377 \\
4 0.001387 \\
5 0.001357 \\
6 0.001366 \\
7 0.001389 \\
8 0.001343 \\
9 0.001359 \\
10 0.001373 \\
11 0.001338 \\
12 0.001358 \\
13 0.001371 \\
14 0.001418 \\
15 0.001396 \\
16 0.001388 \\
17 0.001384 \\
18 0.001410 \\
19 0.001373 \\
20 0.001378 \\
21 0.001391 \\
22 0.001377 \\
23 0.001356 \\
24 0.001391 \\
25 0.001381 \\
26 0.001357 \\
27 0.001380 \\
28 0.001409 \\
29 0.001356 \\
30 0.001395 \\
31 0.001401 \\
32 0.001337 \\
33 0.001428 \\
34 0.001350 \\
35 0.001376 \\
36 0.001399 \\
37 0.001388 \\
38 0.001362 \\
39 0.001372 \\
40 0.001387 \\
41 0.001365 \\
42 0.001344 \\
43 0.001355 \\
44 0.001354 \\
45 0.001367 \\
46 0.001383 \\
47 0.001395 \\
48 0.001360 \\
49 0.001382 \\
50 0.001363 \\
51 0.001362 \\
52 0.001380 \\
53 0.001357 \\
54 0.001395 \\
55 0.001385 \\
56 0.001362 \\
57 0.001421 \\
58 0.001377 \\
59 0.001371 \\
60 0.001387 \\
61 0.001388 \\
62 0.001358 \\
63 0.001372 \\
64 0.001352 \\
65 0.001369 \\
66 0.001393 \\
67 0.001391 \\
68 0.001415 \\
69 0.001380 \\
70 0.001367 \\
71 0.001372 \\
72 0.001395 \\
73 0.001349 \\
74 0.001360 \\
75 0.001362 \\
76 0.001354 \\
77 0.001352 \\
78 0.001371 \\
79 0.001381 \\
80 0.001356 \\
81 0.001390 \\
82 0.001387 \\
83 0.001390 \\
84 0.001367 \\
85 0.001361 \\
86 0.001394 \\
87 0.001384 \\
88 0.001359 \\
89 0.001395 \\
90 0.001324 \\
91 0.001394 \\
92 0.001380 \\
93 0.001367 \\
94 0.001389 \\
95 0.001363 \\
96 0.001397 \\
97 0.001387 \\
98 0.001421 \\
99 0.001381 \\
100 0.001387 \\
101 0.001397 \\
102 0.001363 \\
103 0.001412 \\
104 0.001361 \\
105 0.001382 \\
106 0.001373 \\
107 0.001371 \\
108 0.001388 \\
109 0.001369 \\
110 0.001350 \\
111 0.001357 \\
112 0.001375 \\
113 0.001396 \\
114 0.001361 \\
115 0.001372 \\
116 0.001374 \\
117 0.001393 \\
118 0.001371 \\
119 0.001381 \\
120 0.001375 \\
121 0.001342 \\
122 0.001349 \\
123 0.001338 \\
124 0.001359 \\
125 0.001337 \\
126 0.001396 \\
127 0.001376 \\
128 0.001353 \\
129 0.001351 \\
130 0.001403 \\
131 0.001349 \\
132 0.001371 \\
133 0.001363 \\
134 0.001367 \\
135 0.001359 \\
136 0.001362 \\
137 0.001379 \\
138 0.001379 \\
139 0.001334 \\
140 0.001380 \\
141 0.001363 \\
142 0.001370 \\
143 0.001383 \\
144 0.001391 \\
145 0.001379 \\
146 0.001391 \\
147 0.001388 \\
148 0.001363 \\
149 0.001393 \\
150 0.001384 \\
151 0.001358 \\
152 0.001380 \\
153 0.001342 \\
154 0.001386 \\
155 0.001348 \\
156 0.001407 \\
157 0.001366 \\
158 0.001328 \\
159 0.001344 \\
160 0.001354 \\
161 0.001365 \\
162 0.001337 \\
163 0.001359 \\
164 0.001352 \\
165 0.001371 \\
166 0.001366 \\
167 0.001388 \\
168 0.001378 \\
169 0.001354 \\
170 0.001389 \\
171 0.001392 \\
172 0.001387 \\
173 0.001409 \\
174 0.001366 \\
175 0.001381 \\
176 0.001387 \\
177 0.001394 \\
178 0.001360 \\
179 0.001347 \\
180 0.001363 \\
181 0.001381 \\
182 0.001375 \\
183 0.001377 \\
184 0.001399 \\
185 0.001351 \\
186 0.001359 \\
187 0.001356 \\
188 0.001372 \\
189 0.001361 \\
190 0.001367 \\
191 0.001424 \\
192 0.001348 \\
193 0.001380 \\
194 0.001394 \\
195 0.001353 \\
196 0.001376 \\
197 0.001386 \\
198 0.001363 \\
199 0.001410 \\
200 0.001361 \\
201 0.001393 \\
202 0.001370 \\
203 0.001388 \\
204 0.001338 \\
205 0.001367 \\
206 0.001349 \\
207 0.001382 \\
208 0.001371 \\
209 0.001359 \\
210 0.001397 \\
211 0.001348 \\
212 0.001364 \\
213 0.001403 \\
214 0.001393 \\
215 0.001346 \\
216 0.001362 \\
217 0.001369 \\
218 0.001377 \\
219 0.001357 \\
220 0.001377 \\
221 0.001372 \\
222 0.001349 \\
223 0.001331 \\
224 0.001386 \\
225 0.001360 \\
226 0.001382 \\
227 0.001387 \\
228 0.001382 \\
229 0.001357 \\
230 0.001349 \\
231 0.001344 \\
232 0.001375 \\
233 0.001348 \\
234 0.001361 \\
235 0.001406 \\
236 0.001353 \\
237 0.001378 \\
238 0.001363 \\
239 0.001392 \\
240 0.001383 \\
241 0.001369 \\
242 0.001368 \\
243 0.001362 \\
244 0.001368 \\
245 0.001380 \\
246 0.001390 \\
247 0.001416 \\
248 0.001400 \\
249 0.001411 \\
250 0.001379 \\
251 0.001392 \\
252 0.001400 \\
253 0.001359 \\
254 0.001375 \\
255 0.001365 \\
256 0.001349 \\
257 0.001389 \\
258 0.001343 \\
259 0.001379 \\
260 0.000836 \\
261 0.001379 \\
262 0.001336 \\
263 0.001372 \\
264 0.001353 \\
265 0.001394 \\
266 0.001409 \\
267 0.001367 \\
268 0.001375 \\
269 0.001396 \\
270 0.001365 \\
271 0.001383 \\
272 0.001403 \\
273 0.001380 \\
274 0.001343 \\
275 0.001392 \\
276 0.001385 \\
277 0.001366 \\
278 0.001398 \\
279 0.001347 \\
280 0.001361 \\
281 0.001380 \\
282 0.001383 \\
283 0.001369 \\
284 0.001335 \\
285 0.001357 \\
286 0.001367 \\
287 0.001360 \\
288 0.001362 \\
289 0.001348 \\
290 0.001361 \\
291 0.001345 \\
292 0.001363 \\
293 0.001371 \\
294 0.001359 \\
295 0.001373 \\
296 0.001404 \\
297 0.001374 \\
298 0.001343 \\
299 0.001418 \\
300 0.001374 \\
301 0.001389 \\
302 0.001370 \\
303 0.001354 \\
304 0.001368 \\
305 0.001398 \\
306 0.001385 \\
307 0.001355 \\
308 0.001380 \\
309 0.001350 \\
310 0.001383 \\
311 0.001412 \\
312 0.001399 \\
313 0.001337 \\
314 0.001372 \\
315 0.001379 \\
316 0.001395 \\
317 0.001356 \\
318 0.001368 \\
319 0.001386 \\
320 0.001354 \\
321 0.001370 \\
322 0.001401 \\
323 0.001362 \\
324 0.001371 \\
325 0.001412 \\
326 0.001399 \\
327 0.001395 \\
328 0.001369 \\
329 0.001361 \\
330 0.001377 \\
331 0.001388 \\
332 0.001394 \\
333 0.001379 \\
334 0.001380 \\
335 0.001379 \\
336 0.001364 \\
337 0.001373 \\
338 0.001362 \\
339 0.001386 \\
340 0.001369 \\
341 0.001386 \\
342 0.001381 \\
343 0.001351 \\
344 0.001377 \\
345 0.001359 \\
346 0.001360 \\
347 0.001390 \\
348 0.001413 \\
349 0.001375 \\
350 0.001390 \\
351 0.001365 \\
352 0.001355 \\
353 0.001394 \\
354 0.001368 \\
355 0.001377 \\
356 0.001397 \\
357 0.001349 \\
358 0.001378 \\
359 0.001355 \\
360 0.001385 \\
361 0.001363 \\
362 0.001367 \\
363 0.001352 \\
364 0.001354 \\
365 0.001399 \\
366 0.001402 \\
367 0.001386 \\
368 0.001342 \\
369 0.001406 \\
370 0.001350 \\
371 0.001338 \\
372 0.001393 \\
373 0.001353 \\
374 0.001391 \\
375 0.001383 \\
376 0.001407 \\
377 0.001372 \\
378 0.001392 \\
379 0.001386 \\
380 0.001381 \\
381 0.001360 \\
382 0.001361 \\
383 0.001371 \\
384 0.001377 \\
385 0.001391 \\
386 0.001373 \\
387 0.001384 \\
388 0.001380 \\
389 0.001379 \\
390 0.001389 \\
391 0.001402 \\
392 0.001377 \\
393 0.001368 \\
394 0.001355 \\
395 0.001374 \\
396 0.001383 \\
397 0.001385 \\
398 0.001357 \\
399 0.001374 \\
400 0.001376 \\
401 0.001361 \\
402 0.001402 \\
403 0.001374 \\
404 0.001419 \\
405 0.001363 \\
406 0.001336 \\
407 0.001391 \\
408 0.001366 \\
409 0.001383 \\
410 0.001379 \\
411 0.001393 \\
412 0.001354 \\
413 0.001393 \\
414 0.001372 \\
415 0.001366 \\
416 0.001368 \\
417 0.001375 \\
418 0.001339 \\
419 0.001376 \\
420 0.001354 \\
421 0.001349 \\
422 0.001343 \\
423 0.001374 \\
424 0.001376 \\
425 0.001348 \\
426 0.001340 \\
427 0.001361 \\
428 0.001374 \\
429 0.001373 \\
430 0.001385 \\
431 0.001398 \\
432 0.001377 \\
433 0.001348 \\
434 0.001370 \\
435 0.001396 \\
436 0.001380 \\
437 0.001331 \\
438 0.001390 \\
439 0.001391 \\
440 0.001364 \\
441 0.001351 \\
442 0.001377 \\
443 0.001365 \\
444 0.001327 \\
445 0.001345 \\
446 0.001358 \\
447 0.001323 \\
448 0.001349 \\
449 0.001358 \\
450 0.001412 \\
451 0.001406 \\
452 0.001371 \\
453 0.001378 \\
454 0.001353 \\
455 0.001337 \\
456 0.001379 \\
457 0.001359 \\
458 0.001346 \\
459 0.001379 \\
460 0.001375 \\
461 0.001377 \\
462 0.001349 \\
463 0.001387 \\
464 0.001375 \\
465 0.001373 \\
466 0.001377 \\
467 0.001388 \\
468 0.001379 \\
469 0.001360 \\
470 0.001344 \\
471 0.001373 \\
472 0.001395 \\
473 0.001361 \\
474 0.001391 \\
475 0.001364 \\
476 0.001377 \\
477 0.001381 \\
478 0.001385 \\
479 0.001385 \\
480 0.001369 \\
481 0.001379 \\
482 0.001405 \\
483 0.001335 \\
484 0.001382 \\
485 0.001362 \\
486 0.001331 \\
487 0.001377 \\
488 0.001344 \\
489 0.001400 \\
490 0.001355 \\
491 0.001374 \\
492 0.001347 \\
493 0.001383 \\
494 0.001341 \\
495 0.001370 \\
496 0.001336 \\
497 0.001353 \\
498 0.001397 \\
499 0.001379 \\
500 0.001362 \\
501 0.001369 \\
502 0.001374 \\
503 0.001382 \\
504 0.001381 \\
505 0.001329 \\
506 0.001352 \\
507 0.001377 \\
508 0.001376 \\
509 0.001373 \\
510 0.001314 \\
511 0.001369 \\
512 0.001385 \\
513 0.001383 \\
514 0.001368 \\
515 0.001379 \\
516 0.001357 \\
517 0.001363 \\
518 0.001389 \\
519 0.001391 \\
520 0.001393 \\
521 0.001387 \\
522 0.001357 \\
523 0.001377 \\
524 0.001392 \\
525 0.001377 \\
526 0.001355 \\
527 0.001367 \\
528 0.001407 \\
529 0.001373 \\
530 0.001360 \\
531 0.001376 \\
532 0.001413 \\
533 0.001339 \\
534 0.001391 \\
535 0.001384 \\
536 0.001384 \\
537 0.001396 \\
538 0.001386 \\
539 0.001410 \\
540 0.001344 \\
541 0.001351 \\
542 0.001377 \\
543 0.001400 \\
544 0.001389 \\
545 0.001379 \\
546 0.001365 \\
547 0.001350 \\
548 0.001368 \\
549 0.001369 \\
550 0.001363 \\
551 0.001334 \\
552 0.001387 \\
553 0.001406 \\
554 0.001373 \\
555 0.001356 \\
556 0.001368 \\
557 0.001381 \\
558 0.001394 \\
559 0.001368 \\
560 0.001367 \\
561 0.001346 \\
562 0.001365 \\
563 0.001391 \\
564 0.001347 \\
565 0.001384 \\
566 0.001359 \\
567 0.001395 \\
568 0.001352 \\
569 0.001375 \\
570 0.001389 \\
571 0.001359 \\
572 0.001353 \\
573 0.001385 \\
574 0.001357 \\
575 0.001393 \\
576 0.001361 \\
577 0.001410 \\
578 0.001376 \\
579 0.001370 \\
580 0.001366 \\
581 0.001368 \\
582 0.001356 \\
583 0.001354 \\
584 0.001338 \\
585 0.001374 \\
586 0.001378 \\
587 0.001355 \\
588 0.001390 \\
589 0.001348 \\
590 0.001329 \\
591 0.001374 \\
592 0.001370 \\
593 0.001349 \\
594 0.001380 \\
595 0.001386 \\
596 0.001359 \\
597 0.001367 \\
598 0.001372 \\
599 0.001342 \\
600 0.001357 \\
601 0.001379 \\
602 0.001376 \\
603 0.001374 \\
604 0.001355 \\
605 0.001353 \\
606 0.001399 \\
607 0.001382 \\
608 0.001384 \\
609 0.001358 \\
610 0.001385 \\
611 0.001385 \\
612 0.001390 \\
613 0.001340 \\
614 0.001395 \\
615 0.001370 \\
616 0.001361 \\
617 0.001361 \\
618 0.001385 \\
619 0.001344 \\
620 0.001379 \\
621 0.001385 \\
622 0.001370 \\
623 0.001342 \\
624 0.001370 \\
625 0.001350 \\
626 0.001367 \\
627 0.001350 \\
628 0.001358 \\
629 0.001346 \\
630 0.001359 \\
631 0.001363 \\
632 0.001343 \\
633 0.001373 \\
634 0.001318 \\
635 0.001401 \\
636 0.001369 \\
637 0.001367 \\
638 0.001388 \\
639 0.001357 \\
640 0.001378 \\
641 0.001345 \\
642 0.001378 \\
643 0.001384 \\
644 0.001356 \\
645 0.001392 \\
646 0.001422 \\
647 0.001337 \\
648 0.001352 \\
649 0.001387 \\
650 0.001343 \\
651 0.001366 \\
652 0.001365 \\
653 0.001399 \\
654 0.001408 \\
655 0.001365 \\
656 0.001389 \\
657 0.001372 \\
658 0.001393 \\
659 0.001370 \\
660 0.001387 \\
661 0.001346 \\
662 0.001396 \\
663 0.001360 \\
664 0.001315 \\
665 0.001322 \\
666 0.001399 \\
667 0.001384 \\
668 0.001443 \\
669 0.001396 \\
670 0.001332 \\
671 0.001352 \\
672 0.001351 \\
673 0.001351 \\
674 0.001358 \\
675 0.001389 \\
676 0.001399 \\
677 0.001380 \\
678 0.001353 \\
679 0.001357 \\
680 0.001360 \\
681 0.001346 \\
682 0.001396 \\
683 0.001391 \\
684 0.001415 \\
685 0.001346 \\
686 0.001397 \\
687 0.001381 \\
688 0.001362 \\
689 0.001334 \\
690 0.001433 \\
691 0.001361 \\
692 0.001390 \\
693 0.001389 \\
694 0.001329 \\
695 0.001382 \\
696 0.001383 \\
697 0.001396 \\
698 0.001368 \\
699 0.001385 \\
700 0.001358 \\
701 0.001389 \\
702 0.001354 \\
703 0.001392 \\
704 0.001403 \\
705 0.001340 \\
706 0.001398 \\
707 0.001407 \\
708 0.001397 \\
709 0.001419 \\
710 0.001399 \\
711 0.001377 \\
712 0.001372 \\
713 0.001342 \\
714 0.001363 \\
715 0.001340 \\
716 0.001340 \\
717 0.001362 \\
718 0.001393 \\
719 0.001349 \\
720 0.001410 \\
721 0.001370 \\
722 0.001363 \\
723 0.001373 \\
724 0.001355 \\
725 0.001372 \\
726 0.001411 \\
727 0.001348 \\
728 0.001365 \\
		};
		\addlegendentry{$\foldParVec = (3, 2)$, $t = 2$}
		\draw[help lines, color=red] (axis cs:-100,0.001372) -- (axis cs:828,0.001372);
	\end{axis}
\end{tikzpicture}
        }
        \caption{Probability mass function for the code with $\foldParVec = (3, 2)$ and $t = 2$.}
        \label{fig:distribution-2}
    \end{subfigure}
    \\
    \vspace*{.3cm}
    \begin{subfigure}[t]{.48\textwidth}
        \centering
        \resizebox{\textwidth}{!}{%
\begin{tikzpicture}
	\begin{axis}[%
		scale=2.25,
		xlabel={field element (randomly indexed)},
		xmajorgrids,
		ymin=0.00055,
		ymax=0.0015,
		ylabel={observed probability},
		ymajorgrids,
		legend style={legend pos=south west,legend cell align=left,align=left,draw=white!15!black}
		]
		\addplot [style=distribution, only marks] table[row sep=crcr]{%
0 0.001369 \\
1 0.001372 \\
2 0.001356 \\
3 0.001367 \\
4 0.001379 \\
5 0.001390 \\
6 0.001363 \\
7 0.001373 \\
8 0.001371 \\
9 0.001365 \\
10 0.001338 \\
11 0.001382 \\
12 0.001361 \\
13 0.001384 \\
14 0.001353 \\
15 0.001399 \\
16 0.001379 \\
17 0.001366 \\
18 0.001356 \\
19 0.001399 \\
20 0.001410 \\
21 0.001369 \\
22 0.001362 \\
23 0.001377 \\
24 0.001382 \\
25 0.001323 \\
26 0.001392 \\
27 0.001383 \\
28 0.001365 \\
29 0.001400 \\
30 0.001351 \\
31 0.001380 \\
32 0.001372 \\
33 0.001384 \\
34 0.001375 \\
35 0.001387 \\
36 0.001395 \\
37 0.001363 \\
38 0.001344 \\
39 0.001364 \\
40 0.001396 \\
41 0.001324 \\
42 0.001376 \\
43 0.001377 \\
44 0.001373 \\
45 0.001378 \\
46 0.001354 \\
47 0.001375 \\
48 0.001376 \\
49 0.001346 \\
50 0.001343 \\
51 0.001378 \\
52 0.001369 \\
53 0.001383 \\
54 0.001420 \\
55 0.001401 \\
56 0.001364 \\
57 0.001377 \\
58 0.001393 \\
59 0.001377 \\
60 0.001417 \\
61 0.001362 \\
62 0.001387 \\
63 0.001373 \\
64 0.001362 \\
65 0.001379 \\
66 0.001365 \\
67 0.001369 \\
68 0.001386 \\
69 0.001373 \\
70 0.001352 \\
71 0.001359 \\
72 0.001374 \\
73 0.001383 \\
74 0.001390 \\
75 0.001348 \\
76 0.001360 \\
77 0.001360 \\
78 0.001373 \\
79 0.001355 \\
80 0.001376 \\
81 0.001370 \\
82 0.001392 \\
83 0.001375 \\
84 0.001359 \\
85 0.001398 \\
86 0.001344 \\
87 0.001357 \\
88 0.001353 \\
89 0.001362 \\
90 0.001377 \\
91 0.001350 \\
92 0.001358 \\
93 0.001359 \\
94 0.001363 \\
95 0.001393 \\
96 0.001404 \\
97 0.001338 \\
98 0.001372 \\
99 0.001422 \\
100 0.001356 \\
101 0.001415 \\
102 0.001354 \\
103 0.001389 \\
104 0.001362 \\
105 0.001352 \\
106 0.001424 \\
107 0.001356 \\
108 0.001383 \\
109 0.001371 \\
110 0.001385 \\
111 0.001361 \\
112 0.001373 \\
113 0.001382 \\
114 0.001369 \\
115 0.001390 \\
116 0.001338 \\
117 0.001373 \\
118 0.001374 \\
119 0.001380 \\
120 0.001397 \\
121 0.001335 \\
122 0.001396 \\
123 0.001366 \\
124 0.001363 \\
125 0.001381 \\
126 0.001392 \\
127 0.001381 \\
128 0.001368 \\
129 0.001368 \\
130 0.001362 \\
131 0.001346 \\
132 0.001356 \\
133 0.001372 \\
134 0.001411 \\
135 0.001389 \\
136 0.001370 \\
137 0.001353 \\
138 0.001362 \\
139 0.001398 \\
140 0.001369 \\
141 0.001357 \\
142 0.001362 \\
143 0.001384 \\
144 0.001386 \\
145 0.001343 \\
146 0.001334 \\
147 0.001354 \\
148 0.001351 \\
149 0.001386 \\
150 0.001381 \\
151 0.001385 \\
152 0.001368 \\
153 0.001358 \\
154 0.001396 \\
155 0.001413 \\
156 0.001380 \\
157 0.001356 \\
158 0.001369 \\
159 0.001392 \\
160 0.001372 \\
161 0.001416 \\
162 0.001373 \\
163 0.001359 \\
164 0.001332 \\
165 0.001377 \\
166 0.001368 \\
167 0.001405 \\
168 0.001395 \\
169 0.001362 \\
170 0.001368 \\
171 0.001380 \\
172 0.001349 \\
173 0.001380 \\
174 0.001322 \\
175 0.001368 \\
176 0.001394 \\
177 0.001351 \\
178 0.001411 \\
179 0.001399 \\
180 0.001383 \\
181 0.001410 \\
182 0.001365 \\
183 0.001360 \\
184 0.001386 \\
185 0.001341 \\
186 0.001393 \\
187 0.001373 \\
188 0.001370 \\
189 0.001385 \\
190 0.001390 \\
191 0.001386 \\
192 0.001393 \\
193 0.001385 \\
194 0.001353 \\
195 0.001388 \\
196 0.001328 \\
197 0.001380 \\
198 0.001380 \\
199 0.001342 \\
200 0.001336 \\
201 0.001355 \\
202 0.001353 \\
203 0.001382 \\
204 0.001383 \\
205 0.001345 \\
206 0.001359 \\
207 0.001389 \\
208 0.001370 \\
209 0.001361 \\
210 0.001406 \\
211 0.001352 \\
212 0.001343 \\
213 0.001368 \\
214 0.001371 \\
215 0.001365 \\
216 0.001362 \\
217 0.001413 \\
218 0.001382 \\
219 0.001408 \\
220 0.001356 \\
221 0.001367 \\
222 0.001365 \\
223 0.001382 \\
224 0.001365 \\
225 0.001377 \\
226 0.001373 \\
227 0.001374 \\
228 0.001390 \\
229 0.001384 \\
230 0.001371 \\
231 0.001358 \\
232 0.001380 \\
233 0.001368 \\
234 0.001376 \\
235 0.001332 \\
236 0.001369 \\
237 0.001363 \\
238 0.001374 \\
239 0.001373 \\
240 0.001378 \\
241 0.001361 \\
242 0.001394 \\
243 0.001372 \\
244 0.001366 \\
245 0.001408 \\
246 0.001319 \\
247 0.001385 \\
248 0.001357 \\
249 0.001386 \\
250 0.001364 \\
251 0.001368 \\
252 0.001353 \\
253 0.001368 \\
254 0.001363 \\
255 0.001388 \\
256 0.001363 \\
257 0.001375 \\
258 0.001400 \\
259 0.001364 \\
260 0.001360 \\
261 0.001369 \\
262 0.001379 \\
263 0.001362 \\
264 0.001358 \\
265 0.001358 \\
266 0.001377 \\
267 0.001371 \\
268 0.001348 \\
269 0.001394 \\
270 0.001380 \\
271 0.001361 \\
272 0.001372 \\
273 0.001382 \\
274 0.001368 \\
275 0.001373 \\
276 0.001375 \\
277 0.001375 \\
278 0.001379 \\
279 0.001358 \\
280 0.001365 \\
281 0.001382 \\
282 0.001415 \\
283 0.001390 \\
284 0.001379 \\
285 0.001358 \\
286 0.001380 \\
287 0.001406 \\
288 0.001336 \\
289 0.001393 \\
290 0.001363 \\
291 0.001368 \\
292 0.001389 \\
293 0.001364 \\
294 0.001358 \\
295 0.001359 \\
296 0.001348 \\
297 0.001376 \\
298 0.001377 \\
299 0.001366 \\
300 0.001375 \\
301 0.001333 \\
302 0.001393 \\
303 0.001370 \\
304 0.001362 \\
305 0.001371 \\
306 0.001367 \\
307 0.001365 \\
308 0.001351 \\
309 0.001379 \\
310 0.001391 \\
311 0.001374 \\
312 0.001385 \\
313 0.001371 \\
314 0.001354 \\
315 0.001391 \\
316 0.001399 \\
317 0.001359 \\
318 0.001382 \\
319 0.001339 \\
320 0.001412 \\
321 0.001382 \\
322 0.001350 \\
323 0.001343 \\
324 0.001391 \\
325 0.001386 \\
326 0.001354 \\
327 0.001385 \\
328 0.001364 \\
329 0.001350 \\
330 0.001345 \\
331 0.001381 \\
332 0.001378 \\
333 0.001410 \\
334 0.001359 \\
335 0.001383 \\
336 0.001364 \\
337 0.001401 \\
338 0.001373 \\
339 0.001397 \\
340 0.001361 \\
341 0.001348 \\
342 0.001365 \\
343 0.001353 \\
344 0.001400 \\
345 0.001367 \\
346 0.001380 \\
347 0.001354 \\
348 0.001380 \\
349 0.001380 \\
350 0.001369 \\
351 0.001375 \\
352 0.001398 \\
353 0.001347 \\
354 0.001339 \\
355 0.001369 \\
356 0.001358 \\
357 0.001381 \\
358 0.001389 \\
359 0.001368 \\
360 0.001393 \\
361 0.001372 \\
362 0.001366 \\
363 0.001387 \\
364 0.001383 \\
365 0.001405 \\
366 0.001378 \\
367 0.001375 \\
368 0.001391 \\
369 0.001382 \\
370 0.001378 \\
371 0.001383 \\
372 0.001350 \\
373 0.001392 \\
374 0.001365 \\
375 0.001354 \\
376 0.001363 \\
377 0.001344 \\
378 0.001397 \\
379 0.001365 \\
380 0.001377 \\
381 0.001362 \\
382 0.001371 \\
383 0.001370 \\
384 0.001404 \\
385 0.001370 \\
386 0.001396 \\
387 0.001374 \\
388 0.001392 \\
389 0.001382 \\
390 0.001383 \\
391 0.001365 \\
392 0.001395 \\
393 0.001372 \\
394 0.001371 \\
395 0.001358 \\
396 0.001375 \\
397 0.001375 \\
398 0.001394 \\
399 0.001388 \\
400 0.001388 \\
401 0.001377 \\
402 0.001388 \\
403 0.001377 \\
404 0.001353 \\
405 0.001324 \\
406 0.001382 \\
407 0.001334 \\
408 0.001380 \\
409 0.001370 \\
410 0.001340 \\
411 0.001359 \\
412 0.001376 \\
413 0.001351 \\
414 0.001352 \\
415 0.001358 \\
416 0.001348 \\
417 0.001362 \\
418 0.001320 \\
419 0.001401 \\
420 0.001363 \\
421 0.001409 \\
422 0.001365 \\
423 0.001336 \\
424 0.001376 \\
425 0.001354 \\
426 0.001384 \\
427 0.001369 \\
428 0.001358 \\
429 0.001360 \\
430 0.001400 \\
431 0.001376 \\
432 0.001368 \\
433 0.001366 \\
434 0.001372 \\
435 0.001387 \\
436 0.001373 \\
437 0.001398 \\
438 0.001386 \\
439 0.001363 \\
440 0.001392 \\
441 0.001381 \\
442 0.001392 \\
443 0.001359 \\
444 0.001378 \\
445 0.001372 \\
446 0.001371 \\
447 0.001332 \\
448 0.001351 \\
449 0.001382 \\
450 0.001367 \\
451 0.001364 \\
452 0.001410 \\
453 0.001340 \\
454 0.001382 \\
455 0.001371 \\
456 0.001387 \\
457 0.001366 \\
458 0.001371 \\
459 0.001350 \\
460 0.001368 \\
461 0.001371 \\
462 0.001349 \\
463 0.001368 \\
464 0.001331 \\
465 0.001370 \\
466 0.001379 \\
467 0.001394 \\
468 0.001364 \\
469 0.001341 \\
470 0.001361 \\
471 0.001384 \\
472 0.001372 \\
473 0.001396 \\
474 0.001342 \\
475 0.001412 \\
476 0.001356 \\
477 0.001387 \\
478 0.001346 \\
479 0.001389 \\
480 0.001353 \\
481 0.001380 \\
482 0.001346 \\
483 0.001376 \\
484 0.001366 \\
485 0.001378 \\
486 0.001377 \\
487 0.001345 \\
488 0.001379 \\
489 0.001378 \\
490 0.001362 \\
491 0.001348 \\
492 0.001360 \\
493 0.001352 \\
494 0.001368 \\
495 0.001376 \\
496 0.001379 \\
497 0.001346 \\
498 0.001395 \\
499 0.001362 \\
500 0.001376 \\
501 0.001394 \\
502 0.001360 \\
503 0.001400 \\
504 0.001378 \\
505 0.001384 \\
506 0.001358 \\
507 0.001380 \\
508 0.001375 \\
509 0.001352 \\
510 0.001377 \\
511 0.001353 \\
512 0.001416 \\
513 0.001347 \\
514 0.001395 \\
515 0.001410 \\
516 0.001406 \\
517 0.001386 \\
518 0.001353 \\
519 0.001358 \\
520 0.001340 \\
521 0.001378 \\
522 0.001384 \\
523 0.001401 \\
524 0.001371 \\
525 0.001402 \\
526 0.001364 \\
527 0.001409 \\
528 0.001351 \\
529 0.001381 \\
530 0.001386 \\
531 0.001368 \\
532 0.001386 \\
533 0.001393 \\
534 0.001373 \\
535 0.001359 \\
536 0.001368 \\
537 0.001345 \\
538 0.001359 \\
539 0.001344 \\
540 0.001380 \\
541 0.001371 \\
542 0.001384 \\
543 0.001345 \\
544 0.001353 \\
545 0.001387 \\
546 0.001384 \\
547 0.001380 \\
548 0.001375 \\
549 0.001378 \\
550 0.001377 \\
551 0.001366 \\
552 0.001368 \\
553 0.001389 \\
554 0.001358 \\
555 0.001395 \\
556 0.001362 \\
557 0.001360 \\
558 0.001352 \\
559 0.001388 \\
560 0.001405 \\
561 0.001372 \\
562 0.001376 \\
563 0.001386 \\
564 0.001357 \\
565 0.001397 \\
566 0.001388 \\
567 0.001378 \\
568 0.001351 \\
569 0.001375 \\
570 0.001381 \\
571 0.001391 \\
572 0.001391 \\
573 0.001379 \\
574 0.001365 \\
575 0.001349 \\
576 0.001400 \\
577 0.001357 \\
578 0.001382 \\
579 0.001364 \\
580 0.001368 \\
581 0.001416 \\
582 0.001385 \\
583 0.001376 \\
584 0.001363 \\
585 0.001373 \\
586 0.001361 \\
587 0.001402 \\
588 0.001394 \\
589 0.001378 \\
590 0.001378 \\
591 0.001392 \\
592 0.001367 \\
593 0.001383 \\
594 0.001373 \\
595 0.001382 \\
596 0.001386 \\
597 0.001382 \\
598 0.001395 \\
599 0.001406 \\
600 0.001348 \\
601 0.001373 \\
602 0.001370 \\
603 0.001360 \\
604 0.001386 \\
605 0.001336 \\
606 0.001367 \\
607 0.001374 \\
608 0.001393 \\
609 0.001403 \\
610 0.001414 \\
611 0.001375 \\
612 0.001347 \\
613 0.001373 \\
614 0.001377 \\
615 0.001386 \\
616 0.001368 \\
617 0.001385 \\
618 0.001364 \\
619 0.001355 \\
620 0.001366 \\
621 0.001386 \\
622 0.001374 \\
623 0.001376 \\
624 0.001389 \\
625 0.001387 \\
626 0.001366 \\
627 0.001391 \\
628 0.001374 \\
629 0.001375 \\
630 0.001350 \\
631 0.001367 \\
632 0.001391 \\
633 0.001383 \\
634 0.001384 \\
635 0.001359 \\
636 0.001357 \\
637 0.001362 \\
638 0.001387 \\
639 0.001362 \\
640 0.001374 \\
641 0.001367 \\
642 0.001371 \\
643 0.001376 \\
644 0.001400 \\
645 0.001376 \\
646 0.001378 \\
647 0.001392 \\
648 0.001370 \\
649 0.001357 \\
650 0.001362 \\
651 0.001380 \\
652 0.001386 \\
653 0.001364 \\
654 0.001399 \\
655 0.001380 \\
656 0.001373 \\
657 0.001378 \\
658 0.001391 \\
659 0.001359 \\
660 0.001377 \\
661 0.001363 \\
662 0.001376 \\
663 0.001385 \\
664 0.001390 \\
665 0.001383 \\
666 0.001390 \\
667 0.001381 \\
668 0.001362 \\
669 0.001373 \\
670 0.001388 \\
671 0.001359 \\
672 0.001361 \\
673 0.001371 \\
674 0.001390 \\
675 0.001366 \\
676 0.001370 \\
677 0.001346 \\
678 0.001395 \\
679 0.001375 \\
680 0.001374 \\
681 0.001357 \\
682 0.001382 \\
683 0.001359 \\
684 0.001390 \\
685 0.001358 \\
686 0.001381 \\
687 0.001340 \\
688 0.001358 \\
689 0.001389 \\
690 0.001378 \\
691 0.001363 \\
692 0.001384 \\
693 0.001375 \\
694 0.001386 \\
695 0.001364 \\
696 0.001347 \\
697 0.001363 \\
698 0.001391 \\
699 0.001388 \\
700 0.001374 \\
701 0.001371 \\
702 0.001391 \\
703 0.001337 \\
704 0.001334 \\
705 0.001389 \\
706 0.001374 \\
707 0.001379 \\
708 0.001383 \\
709 0.001346 \\
710 0.001351 \\
711 0.001366 \\
712 0.000625 \\
713 0.001370 \\
714 0.001367 \\
715 0.001362 \\
716 0.001388 \\
717 0.001361 \\
718 0.001376 \\
719 0.001379 \\
720 0.001374 \\
721 0.001351 \\
722 0.001357 \\
723 0.001423 \\
724 0.001371 \\
725 0.001391 \\
726 0.001385 \\
727 0.001390 \\
728 0.001356 \\
		};
		\addlegendentry{$\foldParVec = (3, 2)$, $t = 3$}
		\draw[help lines, color=red] (axis cs:-100,0.001372) -- (axis cs:828,0.001372);
	\end{axis}
\end{tikzpicture}
        }
        \caption{Probability mass function for the code with $\foldParVec = (3, 2)$ and $t = 3$.}
        \label{fig:distribution-3}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{.48\textwidth}
        \centering
        \resizebox{\textwidth}{!}{%
\begin{tikzpicture}
	\begin{loglogaxis}[%
		scale=2.25,
		xlabel={number of runs},
		xmajorgrids,
		ylabel={Kullback--Leibler divergence},
		ymajorgrids,
		legend style={legend pos = south west, legend cell align=left,align=left,draw=white!15!black}
		]
		\addplot [style=divergence_1]
		  table[row sep=crcr]{%
1 4.799914 \\
1001 0.074522 \\
2001 0.034024 \\
3001 0.023404 \\
4001 0.017673 \\
5001 0.014034 \\
6001 0.012015 \\
7001 0.010299 \\
8001 0.009150 \\
9001 0.008089 \\
10001 0.007295 \\
11001 0.006562 \\
12001 0.006083 \\
13001 0.005564 \\
14001 0.005262 \\
15001 0.004695 \\
16001 0.004439 \\
17001 0.004153 \\
18001 0.003949 \\
19001 0.003716 \\
20001 0.003608 \\
21001 0.003495 \\
22001 0.003321 \\
23001 0.003208 \\
24001 0.003034 \\
25001 0.002913 \\
26001 0.002789 \\
27001 0.002700 \\
28001 0.002592 \\
29001 0.002523 \\
30001 0.002460 \\
31001 0.002400 \\
32001 0.002380 \\
33001 0.002349 \\
34001 0.002295 \\
35001 0.002250 \\
36001 0.002175 \\
37001 0.002104 \\
38001 0.002057 \\
39001 0.001995 \\
40001 0.001967 \\
41001 0.001918 \\
42001 0.001869 \\
43001 0.001786 \\
44001 0.001764 \\
45001 0.001757 \\
46001 0.001719 \\
47001 0.001693 \\
48001 0.001674 \\
49001 0.001637 \\
50001 0.001620 \\
51001 0.001597 \\
52001 0.001553 \\
53001 0.001536 \\
54001 0.001516 \\
55001 0.001501 \\
56001 0.001488 \\
57001 0.001463 \\
58001 0.001442 \\
59001 0.001407 \\
60001 0.001407 \\
61001 0.001374 \\
62001 0.001355 \\
63001 0.001331 \\
64001 0.001314 \\
65001 0.001300 \\
66001 0.001297 \\
67001 0.001281 \\
68001 0.001278 \\
69001 0.001256 \\
70001 0.001241 \\
71001 0.001230 \\
72001 0.001204 \\
73001 0.001183 \\
74001 0.001165 \\
75001 0.001159 \\
76001 0.001149 \\
77001 0.001133 \\
78001 0.001115 \\
79001 0.001112 \\
80001 0.001092 \\
81001 0.001079 \\
82001 0.001081 \\
83001 0.001060 \\
84001 0.001044 \\
85001 0.001025 \\
86001 0.001016 \\
87001 0.001003 \\
88001 0.000995 \\
89001 0.000990 \\
90001 0.000982 \\
91001 0.000965 \\
92001 0.000954 \\
93001 0.000942 \\
94001 0.000935 \\
95001 0.000930 \\
96001 0.000910 \\
97001 0.000902 \\
98001 0.000900 \\
99001 0.000893 \\
100001 0.000878 \\
101001 0.000874 \\
102001 0.000867 \\
103001 0.000861 \\
104001 0.000861 \\
105001 0.000862 \\
106001 0.000855 \\
107001 0.000849 \\
108001 0.000846 \\
109001 0.000844 \\
110001 0.000840 \\
111001 0.000831 \\
112001 0.000828 \\
113001 0.000815 \\
114001 0.000821 \\
115001 0.000816 \\
116001 0.000817 \\
117001 0.000814 \\
118001 0.000806 \\
119001 0.000805 \\
120001 0.000800 \\
121001 0.000797 \\
122001 0.000794 \\
123001 0.000790 \\
124001 0.000784 \\
125001 0.000781 \\
126001 0.000784 \\
127001 0.000777 \\
128001 0.000776 \\
129001 0.000775 \\
130001 0.000778 \\
131001 0.000767 \\
132001 0.000761 \\
133001 0.000758 \\
134001 0.000747 \\
135001 0.000751 \\
136001 0.000753 \\
137001 0.000750 \\
138001 0.000742 \\
139001 0.000738 \\
140001 0.000730 \\
141001 0.000735 \\
142001 0.000733 \\
143001 0.000732 \\
144001 0.000728 \\
145001 0.000727 \\
146001 0.000727 \\
147001 0.000724 \\
148001 0.000719 \\
149001 0.000717 \\
150001 0.000718 \\
151001 0.000715 \\
152001 0.000715 \\
153001 0.000712 \\
154001 0.000711 \\
155001 0.000713 \\
156001 0.000709 \\
157001 0.000704 \\
158001 0.000705 \\
159001 0.000705 \\
160001 0.000696 \\
161001 0.000695 \\
162001 0.000693 \\
163001 0.000686 \\
164001 0.000679 \\
165001 0.000680 \\
166001 0.000674 \\
167001 0.000671 \\
168001 0.000666 \\
169001 0.000665 \\
170001 0.000659 \\
171001 0.000654 \\
172001 0.000656 \\
173001 0.000655 \\
174001 0.000655 \\
175001 0.000651 \\
176001 0.000647 \\
177001 0.000645 \\
178001 0.000646 \\
179001 0.000647 \\
180001 0.000645 \\
181001 0.000640 \\
182001 0.000638 \\
183001 0.000638 \\
184001 0.000638 \\
185001 0.000635 \\
186001 0.000631 \\
187001 0.000630 \\
188001 0.000629 \\
189001 0.000623 \\
190001 0.000623 \\
191001 0.000625 \\
192001 0.000623 \\
193001 0.000624 \\
194001 0.000623 \\
195001 0.000622 \\
196001 0.000625 \\
197001 0.000622 \\
198001 0.000622 \\
199001 0.000618 \\
200001 0.000616 \\
201001 0.000617 \\
202001 0.000615 \\
203001 0.000615 \\
204001 0.000613 \\
205001 0.000611 \\
206001 0.000608 \\
207001 0.000603 \\
208001 0.000602 \\
209001 0.000604 \\
210001 0.000602 \\
211001 0.000603 \\
212001 0.000604 \\
213001 0.000602 \\
214001 0.000601 \\
215001 0.000598 \\
216001 0.000597 \\
217001 0.000595 \\
218001 0.000592 \\
219001 0.000592 \\
220001 0.000590 \\
221001 0.000590 \\
222001 0.000588 \\
223001 0.000586 \\
224001 0.000586 \\
225001 0.000581 \\
226001 0.000577 \\
227001 0.000576 \\
228001 0.000570 \\
229001 0.000571 \\
230001 0.000568 \\
231001 0.000567 \\
232001 0.000566 \\
233001 0.000564 \\
234001 0.000563 \\
235001 0.000563 \\
236001 0.000561 \\
237001 0.000561 \\
238001 0.000556 \\
239001 0.000554 \\
240001 0.000551 \\
241001 0.000549 \\
242001 0.000552 \\
243001 0.000550 \\
244001 0.000549 \\
245001 0.000546 \\
246001 0.000544 \\
247001 0.000543 \\
248001 0.000541 \\
249001 0.000539 \\
250001 0.000538 \\
251001 0.000535 \\
252001 0.000531 \\
253001 0.000532 \\
254001 0.000531 \\
255001 0.000528 \\
256001 0.000528 \\
257001 0.000525 \\
258001 0.000523 \\
259001 0.000522 \\
260001 0.000525 \\
261001 0.000523 \\
262001 0.000521 \\
263001 0.000519 \\
264001 0.000520 \\
265001 0.000517 \\
266001 0.000517 \\
267001 0.000514 \\
268001 0.000514 \\
269001 0.000515 \\
270001 0.000514 \\
271001 0.000512 \\
272001 0.000512 \\
273001 0.000511 \\
274001 0.000511 \\
275001 0.000510 \\
276001 0.000510 \\
277001 0.000509 \\
278001 0.000509 \\
279001 0.000507 \\
280001 0.000506 \\
281001 0.000506 \\
282001 0.000505 \\
283001 0.000504 \\
284001 0.000502 \\
285001 0.000501 \\
286001 0.000498 \\
287001 0.000497 \\
288001 0.000497 \\
289001 0.000496 \\
290001 0.000495 \\
291001 0.000494 \\
292001 0.000493 \\
293001 0.000493 \\
294001 0.000493 \\
295001 0.000491 \\
296001 0.000493 \\
297001 0.000492 \\
298001 0.000491 \\
299001 0.000492 \\
300001 0.000492 \\
301001 0.000492 \\
302001 0.000491 \\
303001 0.000490 \\
304001 0.000491 \\
305001 0.000491 \\
306001 0.000490 \\
307001 0.000490 \\
308001 0.000490 \\
309001 0.000488 \\
310001 0.000487 \\
311001 0.000487 \\
312001 0.000486 \\
313001 0.000485 \\
314001 0.000485 \\
315001 0.000485 \\
316001 0.000482 \\
317001 0.000479 \\
318001 0.000477 \\
319001 0.000477 \\
320001 0.000476 \\
321001 0.000475 \\
322001 0.000474 \\
323001 0.000474 \\
324001 0.000474 \\
325001 0.000471 \\
326001 0.000469 \\
327001 0.000467 \\
328001 0.000467 \\
329001 0.000466 \\
330001 0.000466 \\
331001 0.000465 \\
332001 0.000466 \\
333001 0.000463 \\
334001 0.000464 \\
335001 0.000464 \\
336001 0.000465 \\
337001 0.000464 \\
338001 0.000465 \\
339001 0.000465 \\
340001 0.000463 \\
341001 0.000462 \\
342001 0.000461 \\
343001 0.000461 \\
344001 0.000463 \\
345001 0.000463 \\
346001 0.000462 \\
347001 0.000463 \\
348001 0.000463 \\
349001 0.000462 \\
350001 0.000460 \\
351001 0.000457 \\
352001 0.000454 \\
353001 0.000453 \\
354001 0.000452 \\
355001 0.000450 \\
356001 0.000449 \\
357001 0.000448 \\
358001 0.000446 \\
359001 0.000444 \\
360001 0.000443 \\
361001 0.000443 \\
362001 0.000442 \\
363001 0.000441 \\
364001 0.000437 \\
365001 0.000438 \\
366001 0.000439 \\
367001 0.000438 \\
368001 0.000437 \\
369001 0.000437 \\
370001 0.000437 \\
371001 0.000434 \\
372001 0.000433 \\
373001 0.000433 \\
374001 0.000432 \\
375001 0.000432 \\
376001 0.000432 \\
377001 0.000433 \\
378001 0.000431 \\
379001 0.000429 \\
380001 0.000428 \\
381001 0.000430 \\
382001 0.000430 \\
383001 0.000430 \\
384001 0.000430 \\
385001 0.000429 \\
386001 0.000430 \\
387001 0.000430 \\
388001 0.000430 \\
389001 0.000432 \\
390001 0.000432 \\
391001 0.000433 \\
392001 0.000432 \\
393001 0.000431 \\
394001 0.000431 \\
395001 0.000431 \\
396001 0.000431 \\
397001 0.000431 \\
398001 0.000429 \\
399001 0.000430 \\
400001 0.000430 \\
401001 0.000432 \\
402001 0.000430 \\
403001 0.000430 \\
404001 0.000428 \\
405001 0.000428 \\
406001 0.000427 \\
407001 0.000428 \\
408001 0.000426 \\
409001 0.000426 \\
410001 0.000426 \\
411001 0.000426 \\
412001 0.000424 \\
413001 0.000423 \\
414001 0.000424 \\
415001 0.000422 \\
416001 0.000422 \\
417001 0.000423 \\
418001 0.000424 \\
419001 0.000423 \\
420001 0.000421 \\
421001 0.000421 \\
422001 0.000421 \\
423001 0.000421 \\
424001 0.000420 \\
425001 0.000420 \\
426001 0.000419 \\
427001 0.000419 \\
428001 0.000419 \\
429001 0.000419 \\
430001 0.000418 \\
431001 0.000418 \\
432001 0.000418 \\
433001 0.000418 \\
434001 0.000417 \\
435001 0.000416 \\
436001 0.000415 \\
437001 0.000415 \\
438001 0.000415 \\
439001 0.000415 \\
440001 0.000414 \\
441001 0.000414 \\
442001 0.000413 \\
443001 0.000413 \\
444001 0.000412 \\
445001 0.000411 \\
446001 0.000411 \\
447001 0.000411 \\
448001 0.000410 \\
449001 0.000410 \\
450001 0.000408 \\
451001 0.000408 \\
452001 0.000409 \\
453001 0.000408 \\
454001 0.000408 \\
455001 0.000407 \\
456001 0.000406 \\
457001 0.000405 \\
458001 0.000404 \\
459001 0.000404 \\
460001 0.000401 \\
461001 0.000400 \\
462001 0.000399 \\
463001 0.000397 \\
464001 0.000396 \\
465001 0.000395 \\
466001 0.000395 \\
467001 0.000395 \\
468001 0.000394 \\
469001 0.000394 \\
470001 0.000394 \\
471001 0.000392 \\
472001 0.000393 \\
473001 0.000392 \\
474001 0.000392 \\
475001 0.000393 \\
476001 0.000393 \\
477001 0.000392 \\
478001 0.000392 \\
479001 0.000391 \\
480001 0.000391 \\
481001 0.000390 \\
482001 0.000389 \\
483001 0.000389 \\
484001 0.000389 \\
485001 0.000388 \\
486001 0.000386 \\
487001 0.000386 \\
488001 0.000386 \\
489001 0.000386 \\
490001 0.000387 \\
491001 0.000387 \\
492001 0.000387 \\
493001 0.000387 \\
494001 0.000387 \\
495001 0.000388 \\
496001 0.000387 \\
497001 0.000387 \\
498001 0.000387 \\
499001 0.000387 \\
500001 0.000387 \\
501001 0.000385 \\
502001 0.000384 \\
503001 0.000384 \\
504001 0.000382 \\
505001 0.000382 \\
506001 0.000380 \\
507001 0.000380 \\
508001 0.000379 \\
509001 0.000380 \\
510001 0.000380 \\
511001 0.000379 \\
512001 0.000378 \\
513001 0.000377 \\
514001 0.000378 \\
515001 0.000379 \\
516001 0.000378 \\
517001 0.000377 \\
518001 0.000378 \\
519001 0.000379 \\
520001 0.000379 \\
521001 0.000378 \\
522001 0.000378 \\
523001 0.000377 \\
524001 0.000377 \\
525001 0.000377 \\
526001 0.000376 \\
527001 0.000375 \\
528001 0.000376 \\
529001 0.000376 \\
530001 0.000375 \\
531001 0.000374 \\
532001 0.000374 \\
533001 0.000374 \\
534001 0.000374 \\
535001 0.000374 \\
536001 0.000373 \\
537001 0.000373 \\
538001 0.000372 \\
539001 0.000372 \\
540001 0.000372 \\
541001 0.000373 \\
542001 0.000374 \\
543001 0.000373 \\
544001 0.000373 \\
545001 0.000374 \\
546001 0.000374 \\
547001 0.000372 \\
548001 0.000371 \\
549001 0.000371 \\
550001 0.000372 \\
551001 0.000371 \\
552001 0.000371 \\
553001 0.000371 \\
554001 0.000371 \\
555001 0.000371 \\
556001 0.000370 \\
557001 0.000369 \\
558001 0.000368 \\
559001 0.000367 \\
560001 0.000368 \\
561001 0.000368 \\
562001 0.000368 \\
563001 0.000368 \\
564001 0.000368 \\
565001 0.000368 \\
566001 0.000368 \\
567001 0.000368 \\
568001 0.000369 \\
569001 0.000369 \\
570001 0.000368 \\
571001 0.000367 \\
572001 0.000367 \\
573001 0.000367 \\
574001 0.000367 \\
575001 0.000368 \\
576001 0.000367 \\
577001 0.000367 \\
578001 0.000368 \\
579001 0.000366 \\
580001 0.000366 \\
581001 0.000365 \\
582001 0.000365 \\
583001 0.000365 \\
584001 0.000364 \\
585001 0.000364 \\
586001 0.000364 \\
587001 0.000363 \\
588001 0.000363 \\
589001 0.000361 \\
590001 0.000361 \\
591001 0.000361 \\
592001 0.000361 \\
593001 0.000361 \\
594001 0.000360 \\
595001 0.000360 \\
596001 0.000359 \\
597001 0.000360 \\
598001 0.000360 \\
599001 0.000360 \\
600001 0.000360 \\
601001 0.000360 \\
602001 0.000360 \\
603001 0.000360 \\
604001 0.000360 \\
605001 0.000360 \\
606001 0.000360 \\
607001 0.000358 \\
608001 0.000359 \\
609001 0.000359 \\
610001 0.000358 \\
611001 0.000358 \\
612001 0.000358 \\
613001 0.000358 \\
614001 0.000358 \\
615001 0.000358 \\
616001 0.000359 \\
617001 0.000358 \\
618001 0.000358 \\
619001 0.000357 \\
620001 0.000357 \\
621001 0.000357 \\
622001 0.000357 \\
623001 0.000357 \\
624001 0.000356 \\
625001 0.000356 \\
626001 0.000355 \\
627001 0.000355 \\
628001 0.000355 \\
629001 0.000356 \\
630001 0.000355 \\
631001 0.000355 \\
632001 0.000355 \\
633001 0.000355 \\
634001 0.000354 \\
635001 0.000353 \\
636001 0.000353 \\
637001 0.000354 \\
638001 0.000354 \\
639001 0.000355 \\
640001 0.000354 \\
641001 0.000354 \\
642001 0.000354 \\
643001 0.000354 \\
644001 0.000354 \\
645001 0.000353 \\
646001 0.000353 \\
647001 0.000352 \\
648001 0.000352 \\
649001 0.000351 \\
650001 0.000351 \\
651001 0.000352 \\
652001 0.000352 \\
653001 0.000351 \\
654001 0.000351 \\
655001 0.000351 \\
656001 0.000351 \\
657001 0.000350 \\
658001 0.000350 \\
659001 0.000350 \\
660001 0.000349 \\
661001 0.000349 \\
662001 0.000348 \\
663001 0.000347 \\
664001 0.000346 \\
665001 0.000347 \\
666001 0.000347 \\
667001 0.000346 \\
668001 0.000346 \\
669001 0.000346 \\
670001 0.000346 \\
671001 0.000346 \\
672001 0.000346 \\
673001 0.000347 \\
674001 0.000346 \\
675001 0.000347 \\
676001 0.000347 \\
677001 0.000348 \\
678001 0.000348 \\
679001 0.000349 \\
680001 0.000347 \\
681001 0.000348 \\
682001 0.000349 \\
683001 0.000348 \\
684001 0.000348 \\
685001 0.000348 \\
686001 0.000348 \\
687001 0.000348 \\
688001 0.000349 \\
689001 0.000348 \\
690001 0.000348 \\
691001 0.000348 \\
692001 0.000348 \\
693001 0.000347 \\
694001 0.000347 \\
695001 0.000347 \\
696001 0.000346 \\
697001 0.000346 \\
698001 0.000347 \\
699001 0.000347 \\
700001 0.000347 \\
701001 0.000347 \\
702001 0.000347 \\
703001 0.000347 \\
704001 0.000346 \\
705001 0.000346 \\
706001 0.000346 \\
707001 0.000347 \\
708001 0.000347 \\
709001 0.000347 \\
710001 0.000346 \\
711001 0.000345 \\
712001 0.000346 \\
713001 0.000346 \\
714001 0.000346 \\
715001 0.000346 \\
716001 0.000345 \\
717001 0.000345 \\
718001 0.000345 \\
719001 0.000345 \\
720001 0.000344 \\
721001 0.000344 \\
722001 0.000343 \\
723001 0.000343 \\
724001 0.000343 \\
725001 0.000343 \\
726001 0.000342 \\
727001 0.000342 \\
728001 0.000342 \\
729001 0.000342 \\
730001 0.000342 \\
731001 0.000342 \\
732001 0.000342 \\
733001 0.000343 \\
734001 0.000342 \\
735001 0.000341 \\
736001 0.000341 \\
737001 0.000341 \\
738001 0.000341 \\
739001 0.000341 \\
740001 0.000341 \\
741001 0.000341 \\
742001 0.000342 \\
743001 0.000342 \\
744001 0.000341 \\
745001 0.000341 \\
746001 0.000341 \\
747001 0.000341 \\
748001 0.000342 \\
749001 0.000342 \\
750001 0.000342 \\
751001 0.000342 \\
752001 0.000342 \\
753001 0.000341 \\
754001 0.000341 \\
755001 0.000341 \\
756001 0.000340 \\
757001 0.000340 \\
758001 0.000339 \\
759001 0.000339 \\
760001 0.000339 \\
761001 0.000339 \\
762001 0.000339 \\
763001 0.000338 \\
764001 0.000339 \\
765001 0.000338 \\
766001 0.000338 \\
767001 0.000338 \\
768001 0.000338 \\
769001 0.000338 \\
770001 0.000339 \\
771001 0.000339 \\
772001 0.000339 \\
773001 0.000339 \\
774001 0.000340 \\
775001 0.000339 \\
776001 0.000339 \\
777001 0.000339 \\
778001 0.000338 \\
779001 0.000338 \\
780001 0.000338 \\
781001 0.000338 \\
782001 0.000337 \\
783001 0.000338 \\
784001 0.000338 \\
785001 0.000338 \\
786001 0.000338 \\
787001 0.000339 \\
788001 0.000339 \\
789001 0.000338 \\
790001 0.000339 \\
791001 0.000338 \\
792001 0.000338 \\
793001 0.000338 \\
794001 0.000339 \\
795001 0.000339 \\
796001 0.000339 \\
797001 0.000339 \\
798001 0.000339 \\
799001 0.000339 \\
800001 0.000339 \\
801001 0.000339 \\
802001 0.000339 \\
803001 0.000338 \\
804001 0.000338 \\
805001 0.000338 \\
806001 0.000339 \\
807001 0.000338 \\
808001 0.000339 \\
809001 0.000339 \\
810001 0.000340 \\
811001 0.000339 \\
812001 0.000339 \\
813001 0.000339 \\
814001 0.000339 \\
815001 0.000339 \\
816001 0.000339 \\
817001 0.000339 \\
818001 0.000339 \\
819001 0.000338 \\
820001 0.000338 \\
821001 0.000338 \\
822001 0.000338 \\
823001 0.000339 \\
824001 0.000338 \\
825001 0.000338 \\
826001 0.000337 \\
827001 0.000336 \\
828001 0.000336 \\
829001 0.000336 \\
830001 0.000336 \\
831001 0.000336 \\
832001 0.000336 \\
833001 0.000336 \\
834001 0.000337 \\
835001 0.000337 \\
836001 0.000336 \\
837001 0.000336 \\
838001 0.000337 \\
839001 0.000337 \\
840001 0.000336 \\
841001 0.000336 \\
842001 0.000336 \\
843001 0.000336 \\
844001 0.000336 \\
845001 0.000336 \\
846001 0.000336 \\
847001 0.000335 \\
848001 0.000335 \\
849001 0.000335 \\
850001 0.000335 \\
851001 0.000335 \\
852001 0.000335 \\
853001 0.000335 \\
854001 0.000336 \\
855001 0.000336 \\
856001 0.000336 \\
857001 0.000337 \\
858001 0.000337 \\
859001 0.000337 \\
860001 0.000337 \\
861001 0.000336 \\
862001 0.000337 \\
863001 0.000336 \\
864001 0.000337 \\
865001 0.000337 \\
866001 0.000337 \\
867001 0.000337 \\
868001 0.000337 \\
869001 0.000336 \\
870001 0.000336 \\
871001 0.000336 \\
872001 0.000337 \\
873001 0.000336 \\
874001 0.000336 \\
875001 0.000336 \\
876001 0.000336 \\
877001 0.000336 \\
878001 0.000336 \\
879001 0.000336 \\
880001 0.000336 \\
881001 0.000336 \\
882001 0.000337 \\
883001 0.000336 \\
884001 0.000336 \\
885001 0.000336 \\
886001 0.000336 \\
887001 0.000336 \\
888001 0.000336 \\
889001 0.000336 \\
890001 0.000336 \\
891001 0.000335 \\
892001 0.000335 \\
893001 0.000335 \\
894001 0.000335 \\
895001 0.000335 \\
896001 0.000335 \\
897001 0.000335 \\
898001 0.000335 \\
899001 0.000335 \\
900001 0.000335 \\
901001 0.000335 \\
902001 0.000335 \\
903001 0.000335 \\
904001 0.000335 \\
905001 0.000335 \\
906001 0.000335 \\
907001 0.000335 \\
908001 0.000335 \\
909001 0.000335 \\
910001 0.000335 \\
911001 0.000335 \\
912001 0.000335 \\
913001 0.000335 \\
914001 0.000335 \\
915001 0.000335 \\
916001 0.000335 \\
917001 0.000335 \\
918001 0.000334 \\
919001 0.000334 \\
920001 0.000334 \\
921001 0.000334 \\
922001 0.000334 \\
923001 0.000334 \\
924001 0.000333 \\
925001 0.000333 \\
926001 0.000332 \\
927001 0.000333 \\
928001 0.000332 \\
929001 0.000332 \\
930001 0.000333 \\
931001 0.000333 \\
932001 0.000333 \\
933001 0.000333 \\
934001 0.000333 \\
935001 0.000332 \\
936001 0.000332 \\
937001 0.000333 \\
938001 0.000333 \\
939001 0.000332 \\
940001 0.000332 \\
941001 0.000332 \\
942001 0.000333 \\
943001 0.000332 \\
944001 0.000332 \\
945001 0.000331 \\
946001 0.000331 \\
947001 0.000330 \\
948001 0.000330 \\
949001 0.000331 \\
950001 0.000331 \\
951001 0.000331 \\
952001 0.000331 \\
953001 0.000330 \\
954001 0.000330 \\
955001 0.000330 \\
956001 0.000330 \\
957001 0.000330 \\
958001 0.000330 \\
959001 0.000331 \\
960001 0.000331 \\
961001 0.000331 \\
962001 0.000331 \\
963001 0.000331 \\
964001 0.000331 \\
965001 0.000331 \\
966001 0.000331 \\
967001 0.000331 \\
968001 0.000332 \\
969001 0.000332 \\
970001 0.000332 \\
971001 0.000333 \\
972001 0.000333 \\
973001 0.000333 \\
974001 0.000332 \\
975001 0.000332 \\
976001 0.000332 \\
977001 0.000332 \\
978001 0.000332 \\
979001 0.000332 \\
980001 0.000332 \\
981001 0.000332 \\
982001 0.000332 \\
983001 0.000332 \\
984001 0.000332 \\
985001 0.000332 \\
986001 0.000332 \\
987001 0.000332 \\
988001 0.000332 \\
989001 0.000332 \\
990001 0.000332 \\
991001 0.000332 \\
992001 0.000332 \\
993001 0.000332 \\
994001 0.000332 \\
995001 0.000332 \\
996001 0.000332 \\
997001 0.000332 \\
998001 0.000332 \\
999001 0.000332 \\
		};
		\addlegendentry{$\foldParVec = (3, 3)$, $t = 2$}

		\addplot [style=divergence_2]
		  table[row sep=crcr]{%
1 5.205379 \\
1001 0.110777 \\
2001 0.054037 \\
3001 0.034845 \\
4001 0.025771 \\
5001 0.021689 \\
6001 0.018524 \\
7001 0.015748 \\
8001 0.013363 \\
9001 0.012235 \\
10001 0.010929 \\
11001 0.009823 \\
12001 0.008835 \\
13001 0.008280 \\
14001 0.007904 \\
15001 0.007261 \\
16001 0.006773 \\
17001 0.006582 \\
18001 0.006108 \\
19001 0.006014 \\
20001 0.005521 \\
21001 0.005316 \\
22001 0.005043 \\
23001 0.004971 \\
24001 0.004879 \\
25001 0.004696 \\
26001 0.004477 \\
27001 0.004375 \\
28001 0.004136 \\
29001 0.004008 \\
30001 0.003929 \\
31001 0.003806 \\
32001 0.003673 \\
33001 0.003502 \\
34001 0.003338 \\
35001 0.003266 \\
36001 0.003187 \\
37001 0.003111 \\
38001 0.003007 \\
39001 0.002953 \\
40001 0.002853 \\
41001 0.002800 \\
42001 0.002723 \\
43001 0.002655 \\
44001 0.002583 \\
45001 0.002543 \\
46001 0.002529 \\
47001 0.002464 \\
48001 0.002416 \\
49001 0.002383 \\
50001 0.002315 \\
51001 0.002256 \\
52001 0.002226 \\
53001 0.002169 \\
54001 0.002125 \\
55001 0.002104 \\
56001 0.002060 \\
57001 0.002035 \\
58001 0.002018 \\
59001 0.002005 \\
60001 0.001982 \\
61001 0.001964 \\
62001 0.001918 \\
63001 0.001887 \\
64001 0.001840 \\
65001 0.001810 \\
66001 0.001801 \\
67001 0.001760 \\
68001 0.001743 \\
69001 0.001694 \\
70001 0.001680 \\
71001 0.001677 \\
72001 0.001650 \\
73001 0.001617 \\
74001 0.001599 \\
75001 0.001584 \\
76001 0.001567 \\
77001 0.001546 \\
78001 0.001511 \\
79001 0.001488 \\
80001 0.001473 \\
81001 0.001474 \\
82001 0.001469 \\
83001 0.001451 \\
84001 0.001438 \\
85001 0.001428 \\
86001 0.001409 \\
87001 0.001396 \\
88001 0.001372 \\
89001 0.001363 \\
90001 0.001344 \\
91001 0.001326 \\
92001 0.001298 \\
93001 0.001285 \\
94001 0.001264 \\
95001 0.001247 \\
96001 0.001239 \\
97001 0.001225 \\
98001 0.001210 \\
99001 0.001203 \\
100001 0.001164 \\
101001 0.001145 \\
102001 0.001136 \\
103001 0.001137 \\
104001 0.001133 \\
105001 0.001118 \\
106001 0.001106 \\
107001 0.001089 \\
108001 0.001086 \\
109001 0.001070 \\
110001 0.001064 \\
111001 0.001050 \\
112001 0.001040 \\
113001 0.001030 \\
114001 0.001011 \\
115001 0.000998 \\
116001 0.000989 \\
117001 0.000991 \\
118001 0.000985 \\
119001 0.000978 \\
120001 0.000974 \\
121001 0.000970 \\
122001 0.000964 \\
123001 0.000961 \\
124001 0.000954 \\
125001 0.000949 \\
126001 0.000947 \\
127001 0.000932 \\
128001 0.000926 \\
129001 0.000915 \\
130001 0.000911 \\
131001 0.000907 \\
132001 0.000905 \\
133001 0.000901 \\
134001 0.000896 \\
135001 0.000883 \\
136001 0.000883 \\
137001 0.000867 \\
138001 0.000857 \\
139001 0.000852 \\
140001 0.000845 \\
141001 0.000842 \\
142001 0.000845 \\
143001 0.000839 \\
144001 0.000834 \\
145001 0.000833 \\
146001 0.000837 \\
147001 0.000834 \\
148001 0.000828 \\
149001 0.000819 \\
150001 0.000817 \\
151001 0.000808 \\
152001 0.000800 \\
153001 0.000801 \\
154001 0.000793 \\
155001 0.000781 \\
156001 0.000779 \\
157001 0.000770 \\
158001 0.000768 \\
159001 0.000766 \\
160001 0.000768 \\
161001 0.000772 \\
162001 0.000771 \\
163001 0.000778 \\
164001 0.000770 \\
165001 0.000767 \\
166001 0.000761 \\
167001 0.000755 \\
168001 0.000751 \\
169001 0.000750 \\
170001 0.000748 \\
171001 0.000743 \\
172001 0.000738 \\
173001 0.000736 \\
174001 0.000729 \\
175001 0.000730 \\
176001 0.000730 \\
177001 0.000728 \\
178001 0.000724 \\
179001 0.000716 \\
180001 0.000706 \\
181001 0.000701 \\
182001 0.000696 \\
183001 0.000692 \\
184001 0.000687 \\
185001 0.000688 \\
186001 0.000690 \\
187001 0.000683 \\
188001 0.000678 \\
189001 0.000675 \\
190001 0.000668 \\
191001 0.000667 \\
192001 0.000662 \\
193001 0.000662 \\
194001 0.000653 \\
195001 0.000656 \\
196001 0.000651 \\
197001 0.000647 \\
198001 0.000642 \\
199001 0.000638 \\
200001 0.000633 \\
201001 0.000630 \\
202001 0.000623 \\
203001 0.000618 \\
204001 0.000619 \\
205001 0.000615 \\
206001 0.000612 \\
207001 0.000609 \\
208001 0.000603 \\
209001 0.000599 \\
210001 0.000597 \\
211001 0.000597 \\
212001 0.000594 \\
213001 0.000593 \\
214001 0.000594 \\
215001 0.000597 \\
216001 0.000595 \\
217001 0.000595 \\
218001 0.000593 \\
219001 0.000588 \\
220001 0.000586 \\
221001 0.000586 \\
222001 0.000587 \\
223001 0.000585 \\
224001 0.000585 \\
225001 0.000586 \\
226001 0.000583 \\
227001 0.000583 \\
228001 0.000575 \\
229001 0.000572 \\
230001 0.000574 \\
231001 0.000570 \\
232001 0.000570 \\
233001 0.000571 \\
234001 0.000566 \\
235001 0.000567 \\
236001 0.000567 \\
237001 0.000565 \\
238001 0.000564 \\
239001 0.000561 \\
240001 0.000558 \\
241001 0.000559 \\
242001 0.000559 \\
243001 0.000559 \\
244001 0.000557 \\
245001 0.000556 \\
246001 0.000551 \\
247001 0.000550 \\
248001 0.000547 \\
249001 0.000544 \\
250001 0.000542 \\
251001 0.000541 \\
252001 0.000535 \\
253001 0.000536 \\
254001 0.000538 \\
255001 0.000537 \\
256001 0.000533 \\
257001 0.000530 \\
258001 0.000526 \\
259001 0.000525 \\
260001 0.000520 \\
261001 0.000522 \\
262001 0.000522 \\
263001 0.000521 \\
264001 0.000524 \\
265001 0.000523 \\
266001 0.000517 \\
267001 0.000513 \\
268001 0.000509 \\
269001 0.000510 \\
270001 0.000509 \\
271001 0.000506 \\
272001 0.000505 \\
273001 0.000500 \\
274001 0.000496 \\
275001 0.000492 \\
276001 0.000491 \\
277001 0.000493 \\
278001 0.000492 \\
279001 0.000492 \\
280001 0.000493 \\
281001 0.000493 \\
282001 0.000496 \\
283001 0.000497 \\
284001 0.000496 \\
285001 0.000496 \\
286001 0.000497 \\
287001 0.000496 \\
288001 0.000492 \\
289001 0.000490 \\
290001 0.000486 \\
291001 0.000483 \\
292001 0.000481 \\
293001 0.000479 \\
294001 0.000478 \\
295001 0.000476 \\
296001 0.000474 \\
297001 0.000474 \\
298001 0.000470 \\
299001 0.000468 \\
300001 0.000468 \\
301001 0.000467 \\
302001 0.000467 \\
303001 0.000469 \\
304001 0.000468 \\
305001 0.000469 \\
306001 0.000468 \\
307001 0.000467 \\
308001 0.000465 \\
309001 0.000465 \\
310001 0.000468 \\
311001 0.000467 \\
312001 0.000464 \\
313001 0.000461 \\
314001 0.000463 \\
315001 0.000461 \\
316001 0.000460 \\
317001 0.000459 \\
318001 0.000459 \\
319001 0.000457 \\
320001 0.000455 \\
321001 0.000452 \\
322001 0.000448 \\
323001 0.000446 \\
324001 0.000446 \\
325001 0.000444 \\
326001 0.000444 \\
327001 0.000442 \\
328001 0.000442 \\
329001 0.000444 \\
330001 0.000445 \\
331001 0.000443 \\
332001 0.000442 \\
333001 0.000442 \\
334001 0.000441 \\
335001 0.000439 \\
336001 0.000439 \\
337001 0.000436 \\
338001 0.000437 \\
339001 0.000435 \\
340001 0.000432 \\
341001 0.000432 \\
342001 0.000431 \\
343001 0.000431 \\
344001 0.000432 \\
345001 0.000430 \\
346001 0.000428 \\
347001 0.000426 \\
348001 0.000423 \\
349001 0.000421 \\
350001 0.000420 \\
351001 0.000420 \\
352001 0.000417 \\
353001 0.000413 \\
354001 0.000412 \\
355001 0.000412 \\
356001 0.000411 \\
357001 0.000410 \\
358001 0.000410 \\
359001 0.000410 \\
360001 0.000410 \\
361001 0.000409 \\
362001 0.000410 \\
363001 0.000409 \\
364001 0.000409 \\
365001 0.000407 \\
366001 0.000405 \\
367001 0.000402 \\
368001 0.000400 \\
369001 0.000402 \\
370001 0.000399 \\
371001 0.000398 \\
372001 0.000396 \\
373001 0.000396 \\
374001 0.000396 \\
375001 0.000394 \\
376001 0.000390 \\
377001 0.000389 \\
378001 0.000388 \\
379001 0.000389 \\
380001 0.000389 \\
381001 0.000390 \\
382001 0.000391 \\
383001 0.000388 \\
384001 0.000388 \\
385001 0.000389 \\
386001 0.000388 \\
387001 0.000387 \\
388001 0.000387 \\
389001 0.000387 \\
390001 0.000387 \\
391001 0.000387 \\
392001 0.000386 \\
393001 0.000386 \\
394001 0.000386 \\
395001 0.000384 \\
396001 0.000384 \\
397001 0.000384 \\
398001 0.000382 \\
399001 0.000382 \\
400001 0.000381 \\
401001 0.000379 \\
402001 0.000378 \\
403001 0.000379 \\
404001 0.000378 \\
405001 0.000377 \\
406001 0.000376 \\
407001 0.000375 \\
408001 0.000375 \\
409001 0.000373 \\
410001 0.000374 \\
411001 0.000373 \\
412001 0.000375 \\
413001 0.000374 \\
414001 0.000372 \\
415001 0.000372 \\
416001 0.000369 \\
417001 0.000369 \\
418001 0.000368 \\
419001 0.000368 \\
420001 0.000365 \\
421001 0.000365 \\
422001 0.000363 \\
423001 0.000362 \\
424001 0.000361 \\
425001 0.000360 \\
426001 0.000360 \\
427001 0.000361 \\
428001 0.000359 \\
429001 0.000360 \\
430001 0.000359 \\
431001 0.000358 \\
432001 0.000356 \\
433001 0.000356 \\
434001 0.000353 \\
435001 0.000353 \\
436001 0.000351 \\
437001 0.000349 \\
438001 0.000349 \\
439001 0.000350 \\
440001 0.000349 \\
441001 0.000348 \\
442001 0.000347 \\
443001 0.000346 \\
444001 0.000347 \\
445001 0.000347 \\
446001 0.000346 \\
447001 0.000347 \\
448001 0.000347 \\
449001 0.000346 \\
450001 0.000345 \\
451001 0.000344 \\
452001 0.000344 \\
453001 0.000344 \\
454001 0.000342 \\
455001 0.000341 \\
456001 0.000340 \\
457001 0.000341 \\
458001 0.000341 \\
459001 0.000339 \\
460001 0.000339 \\
461001 0.000338 \\
462001 0.000337 \\
463001 0.000336 \\
464001 0.000335 \\
465001 0.000335 \\
466001 0.000335 \\
467001 0.000333 \\
468001 0.000333 \\
469001 0.000332 \\
470001 0.000330 \\
471001 0.000329 \\
472001 0.000327 \\
473001 0.000328 \\
474001 0.000328 \\
475001 0.000327 \\
476001 0.000327 \\
477001 0.000326 \\
478001 0.000325 \\
479001 0.000325 \\
480001 0.000324 \\
481001 0.000323 \\
482001 0.000323 \\
483001 0.000323 \\
484001 0.000323 \\
485001 0.000322 \\
486001 0.000322 \\
487001 0.000322 \\
488001 0.000320 \\
489001 0.000320 \\
490001 0.000319 \\
491001 0.000318 \\
492001 0.000317 \\
493001 0.000315 \\
494001 0.000315 \\
495001 0.000315 \\
496001 0.000314 \\
497001 0.000315 \\
498001 0.000315 \\
499001 0.000314 \\
500001 0.000314 \\
501001 0.000313 \\
502001 0.000312 \\
503001 0.000312 \\
504001 0.000313 \\
505001 0.000313 \\
506001 0.000313 \\
507001 0.000311 \\
508001 0.000311 \\
509001 0.000310 \\
510001 0.000309 \\
511001 0.000309 \\
512001 0.000309 \\
513001 0.000308 \\
514001 0.000309 \\
515001 0.000310 \\
516001 0.000309 \\
517001 0.000308 \\
518001 0.000307 \\
519001 0.000305 \\
520001 0.000306 \\
521001 0.000306 \\
522001 0.000306 \\
523001 0.000307 \\
524001 0.000307 \\
525001 0.000307 \\
526001 0.000306 \\
527001 0.000307 \\
528001 0.000307 \\
529001 0.000309 \\
530001 0.000308 \\
531001 0.000308 \\
532001 0.000308 \\
533001 0.000309 \\
534001 0.000308 \\
535001 0.000307 \\
536001 0.000307 \\
537001 0.000306 \\
538001 0.000308 \\
539001 0.000307 \\
540001 0.000308 \\
541001 0.000308 \\
542001 0.000308 \\
543001 0.000307 \\
544001 0.000307 \\
545001 0.000308 \\
546001 0.000307 \\
547001 0.000308 \\
548001 0.000309 \\
549001 0.000310 \\
550001 0.000310 \\
551001 0.000310 \\
552001 0.000308 \\
553001 0.000309 \\
554001 0.000309 \\
555001 0.000310 \\
556001 0.000309 \\
557001 0.000309 \\
558001 0.000309 \\
559001 0.000308 \\
560001 0.000306 \\
561001 0.000305 \\
562001 0.000305 \\
563001 0.000306 \\
564001 0.000305 \\
565001 0.000305 \\
566001 0.000305 \\
567001 0.000305 \\
568001 0.000304 \\
569001 0.000303 \\
570001 0.000303 \\
571001 0.000303 \\
572001 0.000303 \\
573001 0.000303 \\
574001 0.000303 \\
575001 0.000303 \\
576001 0.000301 \\
577001 0.000301 \\
578001 0.000299 \\
579001 0.000300 \\
580001 0.000300 \\
581001 0.000301 \\
582001 0.000301 \\
583001 0.000300 \\
584001 0.000301 \\
585001 0.000301 \\
586001 0.000300 \\
587001 0.000300 \\
588001 0.000299 \\
589001 0.000301 \\
590001 0.000301 \\
591001 0.000300 \\
592001 0.000300 \\
593001 0.000302 \\
594001 0.000302 \\
595001 0.000303 \\
596001 0.000302 \\
597001 0.000300 \\
598001 0.000300 \\
599001 0.000300 \\
600001 0.000300 \\
601001 0.000300 \\
602001 0.000302 \\
603001 0.000302 \\
604001 0.000302 \\
605001 0.000304 \\
606001 0.000303 \\
607001 0.000302 \\
608001 0.000302 \\
609001 0.000301 \\
610001 0.000301 \\
611001 0.000300 \\
612001 0.000300 \\
613001 0.000300 \\
614001 0.000300 \\
615001 0.000299 \\
616001 0.000301 \\
617001 0.000299 \\
618001 0.000299 \\
619001 0.000299 \\
620001 0.000298 \\
621001 0.000297 \\
622001 0.000296 \\
623001 0.000294 \\
624001 0.000292 \\
625001 0.000292 \\
626001 0.000291 \\
627001 0.000292 \\
628001 0.000293 \\
629001 0.000292 \\
630001 0.000292 \\
631001 0.000292 \\
632001 0.000293 \\
633001 0.000293 \\
634001 0.000294 \\
635001 0.000293 \\
636001 0.000292 \\
637001 0.000291 \\
638001 0.000291 \\
639001 0.000291 \\
640001 0.000290 \\
641001 0.000289 \\
642001 0.000290 \\
643001 0.000290 \\
644001 0.000290 \\
645001 0.000290 \\
646001 0.000290 \\
647001 0.000291 \\
648001 0.000291 \\
649001 0.000291 \\
650001 0.000291 \\
651001 0.000291 \\
652001 0.000291 \\
653001 0.000292 \\
654001 0.000293 \\
655001 0.000293 \\
656001 0.000293 \\
657001 0.000294 \\
658001 0.000293 \\
659001 0.000293 \\
660001 0.000292 \\
661001 0.000292 \\
662001 0.000292 \\
663001 0.000290 \\
664001 0.000289 \\
665001 0.000290 \\
666001 0.000291 \\
667001 0.000291 \\
668001 0.000291 \\
669001 0.000291 \\
670001 0.000290 \\
671001 0.000290 \\
672001 0.000291 \\
673001 0.000290 \\
674001 0.000289 \\
675001 0.000288 \\
676001 0.000287 \\
677001 0.000287 \\
678001 0.000287 \\
679001 0.000287 \\
680001 0.000287 \\
681001 0.000286 \\
682001 0.000287 \\
683001 0.000286 \\
684001 0.000286 \\
685001 0.000284 \\
686001 0.000285 \\
687001 0.000286 \\
688001 0.000287 \\
689001 0.000288 \\
690001 0.000288 \\
691001 0.000287 \\
692001 0.000287 \\
693001 0.000286 \\
694001 0.000287 \\
695001 0.000286 \\
696001 0.000286 \\
697001 0.000285 \\
698001 0.000285 \\
699001 0.000285 \\
700001 0.000284 \\
701001 0.000285 \\
702001 0.000284 \\
703001 0.000285 \\
704001 0.000285 \\
705001 0.000285 \\
706001 0.000284 \\
707001 0.000284 \\
708001 0.000284 \\
709001 0.000284 \\
710001 0.000283 \\
711001 0.000284 \\
712001 0.000282 \\
713001 0.000281 \\
714001 0.000281 \\
715001 0.000281 \\
716001 0.000283 \\
717001 0.000282 \\
718001 0.000282 \\
719001 0.000282 \\
720001 0.000281 \\
721001 0.000280 \\
722001 0.000281 \\
723001 0.000280 \\
724001 0.000281 \\
725001 0.000280 \\
726001 0.000279 \\
727001 0.000278 \\
728001 0.000278 \\
729001 0.000278 \\
730001 0.000277 \\
731001 0.000277 \\
732001 0.000277 \\
733001 0.000277 \\
734001 0.000277 \\
735001 0.000277 \\
736001 0.000278 \\
737001 0.000277 \\
738001 0.000276 \\
739001 0.000276 \\
740001 0.000276 \\
741001 0.000277 \\
742001 0.000276 \\
743001 0.000277 \\
744001 0.000277 \\
745001 0.000276 \\
746001 0.000275 \\
747001 0.000274 \\
748001 0.000274 \\
749001 0.000274 \\
750001 0.000274 \\
751001 0.000274 \\
752001 0.000273 \\
753001 0.000272 \\
754001 0.000271 \\
755001 0.000271 \\
756001 0.000271 \\
757001 0.000271 \\
758001 0.000271 \\
759001 0.000270 \\
760001 0.000270 \\
761001 0.000270 \\
762001 0.000270 \\
763001 0.000269 \\
764001 0.000269 \\
765001 0.000269 \\
766001 0.000269 \\
767001 0.000270 \\
768001 0.000269 \\
769001 0.000269 \\
770001 0.000268 \\
771001 0.000267 \\
772001 0.000267 \\
773001 0.000267 \\
774001 0.000267 \\
775001 0.000266 \\
776001 0.000265 \\
777001 0.000264 \\
778001 0.000264 \\
779001 0.000264 \\
780001 0.000264 \\
781001 0.000263 \\
782001 0.000262 \\
783001 0.000262 \\
784001 0.000261 \\
785001 0.000261 \\
786001 0.000261 \\
787001 0.000260 \\
788001 0.000259 \\
789001 0.000258 \\
790001 0.000259 \\
791001 0.000260 \\
792001 0.000259 \\
793001 0.000259 \\
794001 0.000258 \\
795001 0.000258 \\
796001 0.000257 \\
797001 0.000257 \\
798001 0.000257 \\
799001 0.000256 \\
800001 0.000255 \\
801001 0.000255 \\
802001 0.000254 \\
803001 0.000254 \\
804001 0.000254 \\
805001 0.000254 \\
806001 0.000254 \\
807001 0.000254 \\
808001 0.000254 \\
809001 0.000254 \\
810001 0.000253 \\
811001 0.000253 \\
812001 0.000253 \\
813001 0.000252 \\
814001 0.000253 \\
815001 0.000253 \\
816001 0.000253 \\
817001 0.000253 \\
818001 0.000252 \\
819001 0.000252 \\
820001 0.000252 \\
821001 0.000251 \\
822001 0.000251 \\
823001 0.000251 \\
824001 0.000251 \\
825001 0.000251 \\
826001 0.000251 \\
827001 0.000251 \\
828001 0.000251 \\
829001 0.000250 \\
830001 0.000250 \\
831001 0.000250 \\
832001 0.000251 \\
833001 0.000251 \\
834001 0.000250 \\
835001 0.000250 \\
836001 0.000250 \\
837001 0.000251 \\
838001 0.000251 \\
839001 0.000251 \\
840001 0.000251 \\
841001 0.000252 \\
842001 0.000251 \\
843001 0.000251 \\
844001 0.000251 \\
845001 0.000251 \\
846001 0.000251 \\
847001 0.000251 \\
848001 0.000251 \\
849001 0.000250 \\
850001 0.000249 \\
851001 0.000249 \\
852001 0.000249 \\
853001 0.000250 \\
854001 0.000249 \\
855001 0.000250 \\
856001 0.000250 \\
857001 0.000250 \\
858001 0.000251 \\
859001 0.000250 \\
860001 0.000251 \\
861001 0.000251 \\
862001 0.000250 \\
863001 0.000250 \\
864001 0.000250 \\
865001 0.000250 \\
866001 0.000250 \\
867001 0.000250 \\
868001 0.000250 \\
869001 0.000249 \\
870001 0.000249 \\
871001 0.000249 \\
872001 0.000249 \\
873001 0.000249 \\
874001 0.000249 \\
875001 0.000249 \\
876001 0.000248 \\
877001 0.000248 \\
878001 0.000247 \\
879001 0.000247 \\
880001 0.000247 \\
881001 0.000247 \\
882001 0.000247 \\
883001 0.000247 \\
884001 0.000247 \\
885001 0.000246 \\
886001 0.000247 \\
887001 0.000246 \\
888001 0.000246 \\
889001 0.000245 \\
890001 0.000245 \\
891001 0.000244 \\
892001 0.000244 \\
893001 0.000244 \\
894001 0.000244 \\
895001 0.000244 \\
896001 0.000244 \\
897001 0.000243 \\
898001 0.000244 \\
899001 0.000243 \\
900001 0.000243 \\
901001 0.000243 \\
902001 0.000243 \\
903001 0.000242 \\
904001 0.000241 \\
905001 0.000241 \\
906001 0.000241 \\
907001 0.000241 \\
908001 0.000240 \\
909001 0.000241 \\
910001 0.000240 \\
911001 0.000240 \\
912001 0.000240 \\
913001 0.000240 \\
914001 0.000240 \\
915001 0.000241 \\
916001 0.000241 \\
917001 0.000241 \\
918001 0.000240 \\
919001 0.000241 \\
920001 0.000240 \\
921001 0.000240 \\
922001 0.000239 \\
923001 0.000239 \\
924001 0.000239 \\
925001 0.000239 \\
926001 0.000238 \\
927001 0.000239 \\
928001 0.000239 \\
929001 0.000239 \\
930001 0.000239 \\
931001 0.000238 \\
932001 0.000237 \\
933001 0.000237 \\
934001 0.000237 \\
935001 0.000237 \\
936001 0.000237 \\
937001 0.000237 \\
938001 0.000237 \\
939001 0.000237 \\
940001 0.000237 \\
941001 0.000238 \\
942001 0.000238 \\
943001 0.000237 \\
944001 0.000236 \\
945001 0.000237 \\
946001 0.000237 \\
947001 0.000236 \\
948001 0.000236 \\
949001 0.000236 \\
950001 0.000236 \\
951001 0.000235 \\
952001 0.000235 \\
953001 0.000235 \\
954001 0.000234 \\
955001 0.000234 \\
956001 0.000233 \\
957001 0.000233 \\
958001 0.000233 \\
959001 0.000233 \\
960001 0.000233 \\
961001 0.000233 \\
962001 0.000233 \\
963001 0.000233 \\
964001 0.000232 \\
965001 0.000232 \\
966001 0.000232 \\
967001 0.000233 \\
968001 0.000233 \\
969001 0.000233 \\
970001 0.000233 \\
971001 0.000232 \\
972001 0.000232 \\
973001 0.000231 \\
974001 0.000231 \\
975001 0.000231 \\
976001 0.000231 \\
977001 0.000231 \\
978001 0.000231 \\
979001 0.000231 \\
980001 0.000230 \\
981001 0.000230 \\
982001 0.000230 \\
983001 0.000230 \\
984001 0.000230 \\
985001 0.000230 \\
986001 0.000230 \\
987001 0.000230 \\
988001 0.000230 \\
989001 0.000231 \\
990001 0.000231 \\
991001 0.000230 \\
992001 0.000230 \\
993001 0.000230 \\
994001 0.000230 \\
995001 0.000230 \\
996001 0.000230 \\
997001 0.000230 \\
998001 0.000230 \\
999001 0.000230 \\
		};
		\addlegendentry{$\foldParVec = (3, 2)$, $t = 2$}

		\addplot [style=divergence_3]
		  table[row sep=crcr]{%
1 5.205379 \\
1001 0.082120 \\
2001 0.039466 \\
3001 0.028556 \\
4001 0.020635 \\
5001 0.016550 \\
6001 0.013347 \\
7001 0.011475 \\
8001 0.009797 \\
9001 0.008862 \\
10001 0.007855 \\
11001 0.007358 \\
12001 0.006916 \\
13001 0.006283 \\
14001 0.005959 \\
15001 0.005557 \\
16001 0.005132 \\
17001 0.004789 \\
18001 0.004523 \\
19001 0.004252 \\
20001 0.004098 \\
21001 0.003878 \\
22001 0.003635 \\
23001 0.003462 \\
24001 0.003371 \\
25001 0.003328 \\
26001 0.003163 \\
27001 0.003047 \\
28001 0.002948 \\
29001 0.002869 \\
30001 0.002818 \\
31001 0.002711 \\
32001 0.002702 \\
33001 0.002591 \\
34001 0.002490 \\
35001 0.002388 \\
36001 0.002339 \\
37001 0.002257 \\
38001 0.002201 \\
39001 0.002140 \\
40001 0.002119 \\
41001 0.002078 \\
42001 0.002021 \\
43001 0.001962 \\
44001 0.001909 \\
45001 0.001904 \\
46001 0.001907 \\
47001 0.001884 \\
48001 0.001880 \\
49001 0.001853 \\
50001 0.001817 \\
51001 0.001785 \\
52001 0.001784 \\
53001 0.001751 \\
54001 0.001734 \\
55001 0.001684 \\
56001 0.001682 \\
57001 0.001651 \\
58001 0.001627 \\
59001 0.001608 \\
60001 0.001588 \\
61001 0.001589 \\
62001 0.001568 \\
63001 0.001547 \\
64001 0.001540 \\
65001 0.001503 \\
66001 0.001496 \\
67001 0.001473 \\
68001 0.001469 \\
69001 0.001466 \\
70001 0.001451 \\
71001 0.001443 \\
72001 0.001438 \\
73001 0.001417 \\
74001 0.001418 \\
75001 0.001400 \\
76001 0.001389 \\
77001 0.001370 \\
78001 0.001350 \\
79001 0.001325 \\
80001 0.001317 \\
81001 0.001292 \\
82001 0.001261 \\
83001 0.001267 \\
84001 0.001250 \\
85001 0.001245 \\
86001 0.001252 \\
87001 0.001232 \\
88001 0.001220 \\
89001 0.001201 \\
90001 0.001189 \\
91001 0.001185 \\
92001 0.001178 \\
93001 0.001173 \\
94001 0.001161 \\
95001 0.001148 \\
96001 0.001135 \\
97001 0.001119 \\
98001 0.001119 \\
99001 0.001110 \\
100001 0.001108 \\
101001 0.001103 \\
102001 0.001099 \\
103001 0.001090 \\
104001 0.001082 \\
105001 0.001080 \\
106001 0.001068 \\
107001 0.001055 \\
108001 0.001049 \\
109001 0.001034 \\
110001 0.001029 \\
111001 0.001036 \\
112001 0.001027 \\
113001 0.001019 \\
114001 0.001011 \\
115001 0.001014 \\
116001 0.001009 \\
117001 0.001005 \\
118001 0.000997 \\
119001 0.000994 \\
120001 0.000987 \\
121001 0.000974 \\
122001 0.000965 \\
123001 0.000966 \\
124001 0.000962 \\
125001 0.000956 \\
126001 0.000955 \\
127001 0.000941 \\
128001 0.000933 \\
129001 0.000922 \\
130001 0.000923 \\
131001 0.000919 \\
132001 0.000914 \\
133001 0.000904 \\
134001 0.000893 \\
135001 0.000889 \\
136001 0.000891 \\
137001 0.000893 \\
138001 0.000886 \\
139001 0.000880 \\
140001 0.000873 \\
141001 0.000868 \\
142001 0.000862 \\
143001 0.000858 \\
144001 0.000856 \\
145001 0.000857 \\
146001 0.000858 \\
147001 0.000851 \\
148001 0.000844 \\
149001 0.000840 \\
150001 0.000836 \\
151001 0.000831 \\
152001 0.000824 \\
153001 0.000823 \\
154001 0.000814 \\
155001 0.000804 \\
156001 0.000795 \\
157001 0.000795 \\
158001 0.000789 \\
159001 0.000786 \\
160001 0.000785 \\
161001 0.000784 \\
162001 0.000775 \\
163001 0.000769 \\
164001 0.000764 \\
165001 0.000762 \\
166001 0.000761 \\
167001 0.000762 \\
168001 0.000760 \\
169001 0.000755 \\
170001 0.000749 \\
171001 0.000745 \\
172001 0.000745 \\
173001 0.000742 \\
174001 0.000738 \\
175001 0.000736 \\
176001 0.000733 \\
177001 0.000730 \\
178001 0.000726 \\
179001 0.000723 \\
180001 0.000728 \\
181001 0.000726 \\
182001 0.000722 \\
183001 0.000718 \\
184001 0.000715 \\
185001 0.000716 \\
186001 0.000710 \\
187001 0.000707 \\
188001 0.000703 \\
189001 0.000701 \\
190001 0.000696 \\
191001 0.000697 \\
192001 0.000695 \\
193001 0.000693 \\
194001 0.000694 \\
195001 0.000698 \\
196001 0.000698 \\
197001 0.000694 \\
198001 0.000695 \\
199001 0.000696 \\
200001 0.000695 \\
201001 0.000693 \\
202001 0.000689 \\
203001 0.000682 \\
204001 0.000682 \\
205001 0.000681 \\
206001 0.000677 \\
207001 0.000672 \\
208001 0.000666 \\
209001 0.000664 \\
210001 0.000664 \\
211001 0.000661 \\
212001 0.000657 \\
213001 0.000655 \\
214001 0.000650 \\
215001 0.000649 \\
216001 0.000647 \\
217001 0.000646 \\
218001 0.000638 \\
219001 0.000636 \\
220001 0.000631 \\
221001 0.000626 \\
222001 0.000620 \\
223001 0.000616 \\
224001 0.000612 \\
225001 0.000609 \\
226001 0.000605 \\
227001 0.000607 \\
228001 0.000605 \\
229001 0.000602 \\
230001 0.000599 \\
231001 0.000601 \\
232001 0.000601 \\
233001 0.000601 \\
234001 0.000599 \\
235001 0.000597 \\
236001 0.000598 \\
237001 0.000598 \\
238001 0.000598 \\
239001 0.000599 \\
240001 0.000596 \\
241001 0.000593 \\
242001 0.000594 \\
243001 0.000593 \\
244001 0.000592 \\
245001 0.000591 \\
246001 0.000589 \\
247001 0.000584 \\
248001 0.000582 \\
249001 0.000580 \\
250001 0.000581 \\
251001 0.000581 \\
252001 0.000579 \\
253001 0.000576 \\
254001 0.000573 \\
255001 0.000573 \\
256001 0.000568 \\
257001 0.000567 \\
258001 0.000565 \\
259001 0.000566 \\
260001 0.000568 \\
261001 0.000567 \\
262001 0.000568 \\
263001 0.000567 \\
264001 0.000567 \\
265001 0.000565 \\
266001 0.000563 \\
267001 0.000561 \\
268001 0.000561 \\
269001 0.000563 \\
270001 0.000564 \\
271001 0.000559 \\
272001 0.000558 \\
273001 0.000558 \\
274001 0.000559 \\
275001 0.000558 \\
276001 0.000556 \\
277001 0.000553 \\
278001 0.000553 \\
279001 0.000552 \\
280001 0.000552 \\
281001 0.000553 \\
282001 0.000552 \\
283001 0.000548 \\
284001 0.000547 \\
285001 0.000546 \\
286001 0.000544 \\
287001 0.000543 \\
288001 0.000542 \\
289001 0.000539 \\
290001 0.000538 \\
291001 0.000537 \\
292001 0.000536 \\
293001 0.000535 \\
294001 0.000532 \\
295001 0.000532 \\
296001 0.000532 \\
297001 0.000532 \\
298001 0.000531 \\
299001 0.000529 \\
300001 0.000528 \\
301001 0.000526 \\
302001 0.000524 \\
303001 0.000525 \\
304001 0.000523 \\
305001 0.000523 \\
306001 0.000523 \\
307001 0.000523 \\
308001 0.000525 \\
309001 0.000524 \\
310001 0.000522 \\
311001 0.000522 \\
312001 0.000519 \\
313001 0.000518 \\
314001 0.000516 \\
315001 0.000515 \\
316001 0.000516 \\
317001 0.000514 \\
318001 0.000515 \\
319001 0.000514 \\
320001 0.000516 \\
321001 0.000512 \\
322001 0.000511 \\
323001 0.000510 \\
324001 0.000508 \\
325001 0.000507 \\
326001 0.000506 \\
327001 0.000504 \\
328001 0.000504 \\
329001 0.000505 \\
330001 0.000505 \\
331001 0.000502 \\
332001 0.000502 \\
333001 0.000501 \\
334001 0.000501 \\
335001 0.000499 \\
336001 0.000500 \\
337001 0.000500 \\
338001 0.000500 \\
339001 0.000499 \\
340001 0.000501 \\
341001 0.000499 \\
342001 0.000498 \\
343001 0.000500 \\
344001 0.000500 \\
345001 0.000498 \\
346001 0.000499 \\
347001 0.000498 \\
348001 0.000497 \\
349001 0.000497 \\
350001 0.000497 \\
351001 0.000498 \\
352001 0.000496 \\
353001 0.000495 \\
354001 0.000494 \\
355001 0.000496 \\
356001 0.000495 \\
357001 0.000495 \\
358001 0.000495 \\
359001 0.000496 \\
360001 0.000496 \\
361001 0.000497 \\
362001 0.000494 \\
363001 0.000493 \\
364001 0.000490 \\
365001 0.000489 \\
366001 0.000489 \\
367001 0.000489 \\
368001 0.000487 \\
369001 0.000488 \\
370001 0.000485 \\
371001 0.000484 \\
372001 0.000483 \\
373001 0.000482 \\
374001 0.000480 \\
375001 0.000478 \\
376001 0.000475 \\
377001 0.000477 \\
378001 0.000475 \\
379001 0.000476 \\
380001 0.000475 \\
381001 0.000474 \\
382001 0.000473 \\
383001 0.000471 \\
384001 0.000470 \\
385001 0.000468 \\
386001 0.000468 \\
387001 0.000468 \\
388001 0.000468 \\
389001 0.000467 \\
390001 0.000467 \\
391001 0.000467 \\
392001 0.000465 \\
393001 0.000466 \\
394001 0.000465 \\
395001 0.000464 \\
396001 0.000462 \\
397001 0.000461 \\
398001 0.000461 \\
399001 0.000460 \\
400001 0.000462 \\
401001 0.000462 \\
402001 0.000461 \\
403001 0.000462 \\
404001 0.000461 \\
405001 0.000462 \\
406001 0.000461 \\
407001 0.000457 \\
408001 0.000459 \\
409001 0.000458 \\
410001 0.000458 \\
411001 0.000454 \\
412001 0.000453 \\
413001 0.000452 \\
414001 0.000450 \\
415001 0.000449 \\
416001 0.000449 \\
417001 0.000449 \\
418001 0.000449 \\
419001 0.000448 \\
420001 0.000446 \\
421001 0.000444 \\
422001 0.000444 \\
423001 0.000445 \\
424001 0.000445 \\
425001 0.000444 \\
426001 0.000443 \\
427001 0.000444 \\
428001 0.000443 \\
429001 0.000444 \\
430001 0.000442 \\
431001 0.000443 \\
432001 0.000441 \\
433001 0.000441 \\
434001 0.000440 \\
435001 0.000439 \\
436001 0.000437 \\
437001 0.000435 \\
438001 0.000433 \\
439001 0.000432 \\
440001 0.000431 \\
441001 0.000432 \\
442001 0.000430 \\
443001 0.000430 \\
444001 0.000430 \\
445001 0.000431 \\
446001 0.000431 \\
447001 0.000430 \\
448001 0.000428 \\
449001 0.000428 \\
450001 0.000429 \\
451001 0.000427 \\
452001 0.000425 \\
453001 0.000424 \\
454001 0.000423 \\
455001 0.000425 \\
456001 0.000424 \\
457001 0.000424 \\
458001 0.000423 \\
459001 0.000424 \\
460001 0.000422 \\
461001 0.000423 \\
462001 0.000423 \\
463001 0.000421 \\
464001 0.000421 \\
465001 0.000422 \\
466001 0.000422 \\
467001 0.000423 \\
468001 0.000422 \\
469001 0.000423 \\
470001 0.000424 \\
471001 0.000423 \\
472001 0.000424 \\
473001 0.000423 \\
474001 0.000421 \\
475001 0.000419 \\
476001 0.000419 \\
477001 0.000419 \\
478001 0.000420 \\
479001 0.000420 \\
480001 0.000419 \\
481001 0.000418 \\
482001 0.000419 \\
483001 0.000418 \\
484001 0.000418 \\
485001 0.000416 \\
486001 0.000416 \\
487001 0.000416 \\
488001 0.000417 \\
489001 0.000418 \\
490001 0.000419 \\
491001 0.000419 \\
492001 0.000417 \\
493001 0.000416 \\
494001 0.000417 \\
495001 0.000417 \\
496001 0.000418 \\
497001 0.000417 \\
498001 0.000416 \\
499001 0.000414 \\
500001 0.000412 \\
501001 0.000411 \\
502001 0.000409 \\
503001 0.000409 \\
504001 0.000410 \\
505001 0.000409 \\
506001 0.000410 \\
507001 0.000409 \\
508001 0.000409 \\
509001 0.000409 \\
510001 0.000409 \\
511001 0.000409 \\
512001 0.000410 \\
513001 0.000409 \\
514001 0.000408 \\
515001 0.000408 \\
516001 0.000408 \\
517001 0.000406 \\
518001 0.000406 \\
519001 0.000407 \\
520001 0.000405 \\
521001 0.000404 \\
522001 0.000404 \\
523001 0.000405 \\
524001 0.000405 \\
525001 0.000405 \\
526001 0.000405 \\
527001 0.000404 \\
528001 0.000404 \\
529001 0.000404 \\
530001 0.000403 \\
531001 0.000403 \\
532001 0.000403 \\
533001 0.000403 \\
534001 0.000401 \\
535001 0.000400 \\
536001 0.000398 \\
537001 0.000398 \\
538001 0.000397 \\
539001 0.000397 \\
540001 0.000397 \\
541001 0.000396 \\
542001 0.000395 \\
543001 0.000395 \\
544001 0.000395 \\
545001 0.000395 \\
546001 0.000394 \\
547001 0.000394 \\
548001 0.000393 \\
549001 0.000392 \\
550001 0.000391 \\
551001 0.000391 \\
552001 0.000391 \\
553001 0.000390 \\
554001 0.000390 \\
555001 0.000390 \\
556001 0.000389 \\
557001 0.000388 \\
558001 0.000387 \\
559001 0.000387 \\
560001 0.000387 \\
561001 0.000388 \\
562001 0.000388 \\
563001 0.000388 \\
564001 0.000388 \\
565001 0.000388 \\
566001 0.000388 \\
567001 0.000389 \\
568001 0.000389 \\
569001 0.000389 \\
570001 0.000390 \\
571001 0.000389 \\
572001 0.000389 \\
573001 0.000390 \\
574001 0.000390 \\
575001 0.000389 \\
576001 0.000389 \\
577001 0.000389 \\
578001 0.000389 \\
579001 0.000388 \\
580001 0.000389 \\
581001 0.000389 \\
582001 0.000389 \\
583001 0.000388 \\
584001 0.000388 \\
585001 0.000388 \\
586001 0.000387 \\
587001 0.000387 \\
588001 0.000387 \\
589001 0.000386 \\
590001 0.000385 \\
591001 0.000386 \\
592001 0.000386 \\
593001 0.000385 \\
594001 0.000384 \\
595001 0.000384 \\
596001 0.000384 \\
597001 0.000384 \\
598001 0.000384 \\
599001 0.000384 \\
600001 0.000384 \\
601001 0.000383 \\
602001 0.000384 \\
603001 0.000383 \\
604001 0.000383 \\
605001 0.000384 \\
606001 0.000383 \\
607001 0.000383 \\
608001 0.000383 \\
609001 0.000383 \\
610001 0.000383 \\
611001 0.000382 \\
612001 0.000383 \\
613001 0.000382 \\
614001 0.000381 \\
615001 0.000381 \\
616001 0.000382 \\
617001 0.000382 \\
618001 0.000381 \\
619001 0.000381 \\
620001 0.000381 \\
621001 0.000382 \\
622001 0.000382 \\
623001 0.000381 \\
624001 0.000380 \\
625001 0.000379 \\
626001 0.000379 \\
627001 0.000379 \\
628001 0.000379 \\
629001 0.000378 \\
630001 0.000378 \\
631001 0.000378 \\
632001 0.000378 \\
633001 0.000378 \\
634001 0.000378 \\
635001 0.000377 \\
636001 0.000377 \\
637001 0.000377 \\
638001 0.000376 \\
639001 0.000376 \\
640001 0.000375 \\
641001 0.000375 \\
642001 0.000375 \\
643001 0.000375 \\
644001 0.000375 \\
645001 0.000376 \\
646001 0.000376 \\
647001 0.000376 \\
648001 0.000375 \\
649001 0.000374 \\
650001 0.000374 \\
651001 0.000375 \\
652001 0.000375 \\
653001 0.000375 \\
654001 0.000375 \\
655001 0.000374 \\
656001 0.000374 \\
657001 0.000375 \\
658001 0.000374 \\
659001 0.000374 \\
660001 0.000373 \\
661001 0.000373 \\
662001 0.000373 \\
663001 0.000373 \\
664001 0.000373 \\
665001 0.000372 \\
666001 0.000372 \\
667001 0.000372 \\
668001 0.000372 \\
669001 0.000371 \\
670001 0.000371 \\
671001 0.000372 \\
672001 0.000372 \\
673001 0.000371 \\
674001 0.000371 \\
675001 0.000370 \\
676001 0.000370 \\
677001 0.000371 \\
678001 0.000371 \\
679001 0.000370 \\
680001 0.000371 \\
681001 0.000370 \\
682001 0.000371 \\
683001 0.000370 \\
684001 0.000370 \\
685001 0.000369 \\
686001 0.000369 \\
687001 0.000369 \\
688001 0.000369 \\
689001 0.000369 \\
690001 0.000369 \\
691001 0.000368 \\
692001 0.000369 \\
693001 0.000369 \\
694001 0.000370 \\
695001 0.000369 \\
696001 0.000368 \\
697001 0.000368 \\
698001 0.000368 \\
699001 0.000367 \\
700001 0.000368 \\
701001 0.000367 \\
702001 0.000367 \\
703001 0.000366 \\
704001 0.000367 \\
705001 0.000367 \\
706001 0.000367 \\
707001 0.000367 \\
708001 0.000367 \\
709001 0.000367 \\
710001 0.000367 \\
711001 0.000366 \\
712001 0.000366 \\
713001 0.000366 \\
714001 0.000366 \\
715001 0.000367 \\
716001 0.000368 \\
717001 0.000368 \\
718001 0.000369 \\
719001 0.000368 \\
720001 0.000368 \\
721001 0.000368 \\
722001 0.000368 \\
723001 0.000368 \\
724001 0.000367 \\
725001 0.000367 \\
726001 0.000367 \\
727001 0.000367 \\
728001 0.000367 \\
729001 0.000367 \\
730001 0.000367 \\
731001 0.000366 \\
732001 0.000366 \\
733001 0.000365 \\
734001 0.000365 \\
735001 0.000365 \\
736001 0.000365 \\
737001 0.000366 \\
738001 0.000366 \\
739001 0.000366 \\
740001 0.000367 \\
741001 0.000366 \\
742001 0.000366 \\
743001 0.000365 \\
744001 0.000366 \\
745001 0.000365 \\
746001 0.000365 \\
747001 0.000365 \\
748001 0.000365 \\
749001 0.000364 \\
750001 0.000363 \\
751001 0.000363 \\
752001 0.000362 \\
753001 0.000362 \\
754001 0.000361 \\
755001 0.000361 \\
756001 0.000361 \\
757001 0.000360 \\
758001 0.000360 \\
759001 0.000361 \\
760001 0.000359 \\
761001 0.000359 \\
762001 0.000360 \\
763001 0.000359 \\
764001 0.000359 \\
765001 0.000360 \\
766001 0.000360 \\
767001 0.000359 \\
768001 0.000359 \\
769001 0.000359 \\
770001 0.000359 \\
771001 0.000358 \\
772001 0.000358 \\
773001 0.000358 \\
774001 0.000358 \\
775001 0.000357 \\
776001 0.000358 \\
777001 0.000358 \\
778001 0.000357 \\
779001 0.000357 \\
780001 0.000355 \\
781001 0.000355 \\
782001 0.000355 \\
783001 0.000355 \\
784001 0.000355 \\
785001 0.000355 \\
786001 0.000355 \\
787001 0.000354 \\
788001 0.000354 \\
789001 0.000353 \\
790001 0.000354 \\
791001 0.000353 \\
792001 0.000353 \\
793001 0.000353 \\
794001 0.000352 \\
795001 0.000353 \\
796001 0.000352 \\
797001 0.000352 \\
798001 0.000351 \\
799001 0.000351 \\
800001 0.000350 \\
801001 0.000350 \\
802001 0.000350 \\
803001 0.000349 \\
804001 0.000349 \\
805001 0.000350 \\
806001 0.000350 \\
807001 0.000350 \\
808001 0.000350 \\
809001 0.000349 \\
810001 0.000349 \\
811001 0.000349 \\
812001 0.000349 \\
813001 0.000349 \\
814001 0.000349 \\
815001 0.000349 \\
816001 0.000349 \\
817001 0.000350 \\
818001 0.000349 \\
819001 0.000348 \\
820001 0.000348 \\
821001 0.000349 \\
822001 0.000348 \\
823001 0.000349 \\
824001 0.000349 \\
825001 0.000349 \\
826001 0.000349 \\
827001 0.000349 \\
828001 0.000349 \\
829001 0.000350 \\
830001 0.000349 \\
831001 0.000348 \\
832001 0.000349 \\
833001 0.000348 \\
834001 0.000348 \\
835001 0.000348 \\
836001 0.000348 \\
837001 0.000348 \\
838001 0.000348 \\
839001 0.000349 \\
840001 0.000348 \\
841001 0.000348 \\
842001 0.000348 \\
843001 0.000348 \\
844001 0.000348 \\
845001 0.000349 \\
846001 0.000349 \\
847001 0.000347 \\
848001 0.000347 \\
849001 0.000346 \\
850001 0.000346 \\
851001 0.000346 \\
852001 0.000346 \\
853001 0.000345 \\
854001 0.000345 \\
855001 0.000345 \\
856001 0.000345 \\
857001 0.000345 \\
858001 0.000344 \\
859001 0.000344 \\
860001 0.000344 \\
861001 0.000345 \\
862001 0.000344 \\
863001 0.000344 \\
864001 0.000344 \\
865001 0.000344 \\
866001 0.000344 \\
867001 0.000344 \\
868001 0.000344 \\
869001 0.000344 \\
870001 0.000344 \\
871001 0.000344 \\
872001 0.000343 \\
873001 0.000343 \\
874001 0.000343 \\
875001 0.000343 \\
876001 0.000343 \\
877001 0.000342 \\
878001 0.000342 \\
879001 0.000343 \\
880001 0.000343 \\
881001 0.000343 \\
882001 0.000343 \\
883001 0.000343 \\
884001 0.000343 \\
885001 0.000343 \\
886001 0.000344 \\
887001 0.000344 \\
888001 0.000344 \\
889001 0.000344 \\
890001 0.000344 \\
891001 0.000343 \\
892001 0.000344 \\
893001 0.000344 \\
894001 0.000344 \\
895001 0.000344 \\
896001 0.000344 \\
897001 0.000344 \\
898001 0.000343 \\
899001 0.000343 \\
900001 0.000344 \\
901001 0.000344 \\
902001 0.000344 \\
903001 0.000343 \\
904001 0.000343 \\
905001 0.000343 \\
906001 0.000343 \\
907001 0.000343 \\
908001 0.000342 \\
909001 0.000342 \\
910001 0.000342 \\
911001 0.000343 \\
912001 0.000342 \\
913001 0.000342 \\
914001 0.000342 \\
915001 0.000343 \\
916001 0.000342 \\
917001 0.000342 \\
918001 0.000343 \\
919001 0.000342 \\
920001 0.000343 \\
921001 0.000343 \\
922001 0.000343 \\
923001 0.000343 \\
924001 0.000342 \\
925001 0.000342 \\
926001 0.000342 \\
927001 0.000342 \\
928001 0.000342 \\
929001 0.000343 \\
930001 0.000343 \\
931001 0.000344 \\
932001 0.000344 \\
933001 0.000343 \\
934001 0.000343 \\
935001 0.000343 \\
936001 0.000343 \\
937001 0.000343 \\
938001 0.000343 \\
939001 0.000343 \\
940001 0.000343 \\
941001 0.000343 \\
942001 0.000343 \\
943001 0.000343 \\
944001 0.000344 \\
945001 0.000344 \\
946001 0.000344 \\
947001 0.000343 \\
948001 0.000343 \\
949001 0.000342 \\
950001 0.000342 \\
951001 0.000342 \\
952001 0.000342 \\
953001 0.000342 \\
954001 0.000343 \\
955001 0.000343 \\
956001 0.000343 \\
957001 0.000343 \\
958001 0.000343 \\
959001 0.000343 \\
960001 0.000343 \\
961001 0.000342 \\
962001 0.000342 \\
963001 0.000342 \\
964001 0.000342 \\
965001 0.000342 \\
966001 0.000342 \\
967001 0.000343 \\
968001 0.000342 \\
969001 0.000342 \\
970001 0.000342 \\
971001 0.000342 \\
972001 0.000343 \\
973001 0.000342 \\
974001 0.000341 \\
975001 0.000342 \\
976001 0.000342 \\
977001 0.000342 \\
978001 0.000343 \\
979001 0.000343 \\
980001 0.000343 \\
981001 0.000343 \\
982001 0.000343 \\
983001 0.000343 \\
984001 0.000343 \\
985001 0.000343 \\
986001 0.000343 \\
987001 0.000343 \\
988001 0.000344 \\
989001 0.000343 \\
990001 0.000343 \\
991001 0.000343 \\
992001 0.000343 \\
993001 0.000343 \\
994001 0.000343 \\
995001 0.000343 \\
996001 0.000343 \\
997001 0.000342 \\
998001 0.000342 \\
999001 0.000342 \\
		};
		\addlegendentry{$\foldParVec = (3, 2)$, $t = 3$}
	\end{loglogaxis}
\end{tikzpicture}
        }
        \caption{Divergence with respect to the uniform distribution in all scenarios.}
        \label{fig:divergence}
    \end{subfigure}
    \caption{Observed probability mass function of the coefficients of $B_0^{(1)}(x)$ after $10^{6}$ probabilistic
    unique decodings with $\intDim = 2$ and $\mu = 1$ for codes with $q = 3$, $m = 6$, $k = 2$, $\lenVec = (6, 6)$ and
    either $\foldParVec = (3, 3)$ and $t = 2$ or $\foldParVec = (3, 2)$ and $t \in \{2, 3\}$ and evolution of its
    divergence with respect to the uniform distribution.}
    \label{fig:distributions_and_divergence}
\end{figure}

\section{Implications for Folded Skew Reed--Solomon Codes} \label{sec:implications-fsrs}

Motivated by the relation between \ac{LRS} codes and \ac{SRS} codes from~\cite{martinez2018skew}, we now derive \ac{FSRS} codes for the skew metric from \ac{FLRS} codes.
The skew metric is related to skew evaluation codes and was introduced in~\cite{martinez2018skew}.
Decoding schemes for \ac{SRS} codes that allow for correcting errors of skew weight up to the unique-decoding radius $\lfloor\frac{n-k}{2}\rfloor$ were presented in~\cite{martinez2018skew,boucher2020algorithm,liu2015construction,bartz2020fast}.

In this section we consider decoding of \ac{FSRS} codes with respect to the \emph{(burst) skew metric}, which was introduced for \ac{ISRS} codes in~\cite{bartz2022fast}.
In the following, we restrict ourselves to evaluation codes constructed by $\SkewPolyringZeroDer$, i.e. to the zero-derivation case.


\subsection{Preliminaries on Remainder Evaluation} \label{subsec:preliminaries-on-remainder-evaluation}

Apart from the (generalized) operator evaluation (see~\autoref{sec:preliminaries}) there exists the so-called \emph{remainder evaluation} for skew polynomials, which can be seen as an analog of the classical polynomial evaluation via polynomial division.

For a skew polynomial $f\in\SkewPolyringZeroDer$ the remainder evaluation $\remev{f}{b}$ of $f$ at an element $b\in\Fqm$ is defined as the unique remainder of the right division of $f(x)$ by $(x-b)$ such that (see~\cite{lam1985general, lam1988vandermonde})
\begin{equation}\label{eq:remEval}
f(x)=g(x)(x-b)+\remev{f}{b} \quad \Longleftrightarrow\quad \remev{f}{b} = f(x) \modr (x-b).
\end{equation}
We denote the evaluation of $f$ at all entries of a vector $\vec{b} = (b_1, \dots, b_n)\in\Fqm^n$ by $\remev{f}{\vec{b}}=\left(\remev{f}{b_1},\remev{f}{b_2},\dots,\remev{f}{b_n}\right)$.

For any $a\in\Fqm$, $b\in\Fqm^*$ and $f\in\SkewPolyringZeroDer$ the generalized operator evaluation of $f$ at $b$ with respect to $a$ is related to the remainder evaluation by (see~\cite{martinez2018skew,leroy1995pseudolinear})
\begin{equation}\label{eq:rel_remev_opev}
    \remev{f}{\op{a}{b}b^{-1}}=\opev{f}{b}{a}b^{-1}.
\end{equation}

The following notions were introduced in~\cite{lam1985general,lam1988vandermonde,lam1988algebraic}, and we use the notation of~\cite{martinez2019reliable}.
Let $\set{A} \subseteq \SkewPolyringZeroDer$, $\Omega \subseteq \Fqm$, and $a \in \Fqm$.
The \emph{zero set} of $\set{A}$ is defined as
\begin{equation*}
  \set{Z}(\set{A}) := \left\{ \alpha \in \Fqm \, : \, \remev{f}{\alpha} = 0 \, \forall \, f \in \set{A} \right\}
\end{equation*}
and
\begin{equation*}
  I(\Omega) := \left\{ f \in \SkewPolyringZeroDer \, : \, \remev{f}{\alpha} = 0 \, \forall \, \alpha \in \Omega \right\}
\end{equation*}
denotes the \emph{associated ideal} of $\Omega$.
The \emph{P-closure} (or \emph{polynomial closure}) of $\Omega$ is defined by $\bar{\Omega} := \set{Z}(I(\Omega))$, and $\Omega$ is called \emph{P-closed} if $\bar{\Omega}=\Omega$.
Note that a P-closure is always P-closed.
All elements of $\Fqm \setminus \bar{\Omega}$ are said to be \emph{P-independent from $\Omega$}.
A set $\set{B} \subseteq \Fqm$ is said to be \emph{P-independent} if any $b \in \set{B}$ is P-independent from $\set{B} \setminus \{b\}$.
If $\set{B}$ is P-independent and $\Omega := \bar{\set{B}} \subseteq \Fqm$, we say that $\set{B}$ is a \emph{P-basis of $\Omega$}.

For any $\x = (x_1,\dots,x_n) \in \Fqm^n$ and any P-basis $\set{B}=\{b_1,b_2,\dots,b_n\}$, there is a unique skew polynomial $\IPrem{\set{B}, \x} \in \SkewPolyringZeroDer$ of degree less than $n$ such that
\begin{align*}
\remev{\IPrem{\set{B}, \x}}{b_j} = x_j \quad \forall \, j=1,\dots,n.
\end{align*}
We call this the \emph{remainder interpolation polynomial} of $\x$ on $\set{B}$.
The \emph{skew weight} of a vector $\vec{x}\in\Fqm^n$ with respect to a P-closed set $\Omega=\bar{\set{B}}$ with P-basis $\set{B}=\{b_1,b_2,\dots,b_n\}$\footnote{%
  Here and in the sequel, we slightly abuse notation and take this to mean $\set{B}$ is an ordered set and that the $b_i$ are distinct.%
} is defined as (see~\cite{boucher2020algorithm})
\begin{equation}\label{eq:def_skew_weight}
 \SkewWeight^\set{B}(\vec{x})\defeq\SkewWeight^\set{B}(\IPrem{\set{B}, \x})\defeq\deg\left(\lclm\left(x-\conj{b_i}{x_i}\right)_{\mystack{1\leq i\leq n}{x_i\neq0}}\right).
\end{equation}
The skew weight of a vector depends on $\Omega$ but is independent from the particular P-basis $\set{B}$ (see~\cite[Prop.~13]{martinez2018skew}) of $\Omega$.
In order to simplify the notation for the skew weights of vectors, we indicate the dependence on $\Omega$ by a particular P-basis for $\Omega$ and use the notation $\SkewWeight(\cdot)$ whenever $\set{B}$ is clear from the context.
Similar to the rank and the sum-rank weight we have that $\SkewWeight(\vec{x})\leq\HammingWeight(\vec{x})$ for all $\vec{x}\in\Fqm^n$ (see~\cite{martinez2018skew}).
The \emph{skew distance} between two vectors $\vec{x},\vec{y}\in\Fqm^n$ is defined as
\begin{equation*}
 \SkewDist(\vec{x},\vec{y})\defeq\SkewWeight(\vec{x}-\vec{y}).
\end{equation*}

\subsection{Skew Metric for Folded Matrices} \label{subsec:skew-metric-folded}

By fixing a basis of $\Fqmh$ over $\Fqm$ we can consider a matrix $\X\in\Fqm^{\foldPar\times N}$ as a vector $\vec{x}=(x_1,x_2,\dots,x_N)\in\Fqmh^N$.
Similarly, we consider a tuple $\X\in\Fqm^{\h \times \N}$ as a matrix in $\Fqm^{\foldPar \times N}$ whenever the folding parameter $\foldPar$ is the same for each block, i.e. if $\h=(\foldPar,\dots,\foldPar)$.
Similar as for \ac{ISRS} codes we define the skew weight of a matrix $\X\in\Fqm^{\foldPar\times N}$ (or a tuple $\X\in\Fqm^{\h \times \N}$) with respect to $\set{B}$ as the skew weight of the vector $\x=\extInv_{\vecgamma}(\X)\in\Fqmh^N$, i.e. as (see~\cite{bartz2022fast})
\begin{equation}\label{eq:def_skew_weight_mat}
  \SkewWeight^\set{B}(\mat{X})\defeq \SkewWeight^\set{B}(\extInv_{\vecgamma}(\mat{X})) = \deg\left(\lclm\left(x-\conj{b_i}{x_i}\right)_{\mystack{1\leq i\leq N}{x_i\neq0}}\right)
\end{equation}
where the polynomial
\begin{equation}
  \lclm\left(x-\conj{b_i}{x_i}\right)_{\mystack{1\leq i\leq N}{x_i\neq0}}
\end{equation}
is now from $\Fqmh[\aut;x]$ since we have that $x_i\in\Fqmh$ for all $i=1,\dots,N$.

\begin{lemma}\label{lem:alpha_power_remev}
  Define $\genNorm{i}{a} \defeq \prod_{k=0}^{i-1} \aut^{k}(a)$ for any $i \in \NN$ and $a \in \Fqm$, let $c \in \Fqm$ and consider a skew polynomial $f \in \SkewPolyringZeroDer$.
  Then for any $b \in \Fqm$ and $j \in \NN$ we have that
  \begin{equation*}
    \remev{f}{c^j b} = \remev{\tilde{f}}{b}
  \end{equation*}
  where $\tilde{f}=\sum_{i=0}^{\deg(f)} f_i \genNorm{i}{c^j} x^i$.
\end{lemma}

\begin{proof}
  By~\cite[Lemma~2.4]{lam1988vandermonde} we have that
  \begin{equation*}
    \remev{f}{c^j b}
    = \sum_{i=0}^{\deg(f)} f_i \genNorm{i}{c^j b}
    \overset{(*)}{=} \sum_{i=0}^{\deg(f)} f_i \genNorm{i}{c^j} \genNorm{i}{b}
    = \remev{\tilde{f}}{b}
  \end{equation*}
  where $\tilde{f}=\sum_{i=0}^{\deg(f)} f_i \genNorm{i}{c^j} x^i$ and $(*)$ follows since $f \in \SkewPolyringZeroDer$.
\end{proof}

The following result shows that each matrix can be represented as the remainder evaluation of a single skew polynomial over the large field $\Fqmh$ at evaluation points from the small field $\Fqm$.

\begin{lemma}\label{lem:folded_mat_to_interleaved_mat_fsrs}
 Let $\pe$ be a primitive element of $\Fqm$, define $\FSRSoffset \defeq \aut(\pe)/\pe$, let the folding parameter $\foldPar$ divide $\len \leq m$ and define $\lenFLRS \defeq\frac{\len}{\foldPar}$.
 Consider an evaluation parameter $a\in\Fqm^*$ and define the vector
 \begin{equation*}
    \b \defeq (\op{a}{1}/1, \op{a}{\pe^\foldPar}/\pe^\foldPar, \dots, \op{a}{\pe^{(\lenFLRS-1)\foldPar}}/\pe^{(\lenFLRS-1)\foldPar}) \in \Fqm^{\lenFLRS}.
 \end{equation*}
 Then any matrix $\X\in\Fqm^{\foldPar \times \lenFLRS}$ can be represented as
 \begin{equation*}
   \X =
   \begin{pmatrix}
    \remev{f}{\b}
    \\
    \remev{f}{\FSRSoffset\b}
    \\
    \vdots
    \\
    \remev{f}{\FSRSoffset^{\foldPar-1} \b}
   \end{pmatrix}
   =
   \begin{pmatrix}
    \remev{f^{(1)}}{\b}
    \\
    \remev{f^{(2)}}{\b}
    \\
    \vdots
    \\
    \remev{f^{(\foldPar)}}{\b}
   \end{pmatrix}
 \end{equation*}
 for some $f, f^{(1)}, \dots, f^{(\foldPar)} \in \SkewPolyringZeroDer_{<\len}$.
 Further, we have that
 \begin{equation*}
   \extInv_{\vecgamma}(\X) = \remev{F}{\b}
 \end{equation*}
 for some $F \in \Fqmh[x; \aut]_{<\len}$.
\end{lemma}

\begin{proof}
    Let $\x = \foldOpInv{\foldPar}(\X)$ be the vector obtained by unfolding $\X$ and define
    \begin{equation*}
        \widetilde{\b} \defeq \left(\op{a}{1}/1, \op{a}{\pe}/\pe, \dots, \op{a}{\pe^{(\lenFLRS-1)\foldPar}}/\pe^{(\lenFLRS-1)\foldPar}\right) \in \Fqm^{\lenFLRS \foldPar}.
    \end{equation*}
    Since $\pe$ is a primitive element of $\Fqm$ we have that the entries in $\widetilde{\b}$ are P-independent.
    Let $f \defeq \IPrem{\widetilde{\b}, \x} \in \SkewPolyringZeroDer_{< n}$ be the unique interpolation polynomial satisfying
    \begin{equation*}
     \remev{\IPrem{\widetilde{\b}, \x}}{\widetilde{b}_j} = x_j \quad \forall j=1,\dots, \foldPar \lenFLRS.
    \end{equation*}
    Due to the structure of the evaluation points in $\widetilde{\b}$ we can write $\X$ as
    \begin{equation*}
        \X
        = \foldOp{\foldPar}\left(\remev{f}{\widetilde{\b}}\right)
        =
        \begin{pmatrix}
        \remev{f}{\b}
        \\
        \remev{f}{\FSRSoffset\b}
        \\
        \vdots
        \\
        \remev{f}{\FSRSoffset^{\foldPar-1} \b}
       \end{pmatrix}
       \overset{(*)}{=}
       \begin{pmatrix}
        \remev{f^{(1)}}{\b}
        \\
        \remev{f^{(2)}}{\b}
        \\
        \vdots
        \\
        \remev{f^{(\foldPar)}}{\b}
       \end{pmatrix}
    \end{equation*}
    where $(*)$ follows by~\autoref{lem:alpha_power_remev}.
    By fixing a basis $\vecgamma$ of $\Fqmh$ over $\Fqm$ we can represent $\X$ over $\Fqmh$ as
    \begin{equation*}
        \extInv_{\vecgamma}(\X) = \remev{F}{\b}
    \end{equation*}
    where $F(x) = \sum_{i=0}^{n-1}F_i x^i$ with $F_i=\extInv_{\vecgamma}\left( (f_i^{(1)}, f_i^{(2)}, \dots, f_i^{(\foldPar)})^\top \right)$ for all $i = 1, \dots, n-1$.
\end{proof}

\autoref{thm:sum-rank_relation_skew_and_sum-rank_metric} shows that applying the elementwise $\Fqm$-linear transformation from~\cite[Thm.~3]{martinez2018skew} to \emph{unfolded} matrices yields an isometry between the skew metric and the sum-rank metric for matrices obtained from folded vectors.

\begin{theorem}\label{thm:sum-rank_relation_skew_and_sum-rank_metric}
 Let $\pe$ be a primitive element of $\Fqm$ and consider $\shots \in \NN^{\ast}$.
 Let $1\leq \lenShot{i} \leq m$ for all $i=1,\dots,\shots$ and let $\a=(a_1, \dots, a_\shots)\in\Fqm^\shots$ contain representatives from different conjugacy classes.
 Let the folding parameter $\foldPar$ divide $\lenShot{i}$ for all $i=1,\dots,\shots$, define the $\shots$-composition $\lenFLRSVec=(\lenFLRSshot{1}, \lenFLRSshot{2}, \dots, \lenFLRSshot{\shots})$ with $\lenFLRSshot{i}=\frac{\lenShot{i}}{\foldPar}$ for all $i=1,\dots,\shots$ and define $\h=(\foldPar, \dots, \foldPar)\in\ZZ_{\geq 0}^\shots$.
 Let $\diag(\vecbeta^{-1})$ denote the diagonal matrix of the vector
 \begin{equation}
    \vecbeta^{-1}\defeq\left(1,\pe^{-1}, \dots, (\pe^{n_1-1})^{-1} \mid \dots \mid 1, \pe^{-1}, \dots, (\pe^{n_\shots-1})^{-1}\right)
 \end{equation}
 and define the map
  \begin{align}
  \varphi_{\alpha} \, : \, \Fqm^{\foldPar \times \lenFLRS} &\to  \Fqm^{\foldPar \times \lenFLRS}, \label{eq:sum_rank_to_skew}\\
  (\shot{\X}{1} \mid \shot{\X}{2} \mid \dots \mid \shot{\X}{\ell}) &\mapsto
  \foldOp{\foldParVec}(\foldOpInv{\foldParVec}(\X) \cdot \diag(\vecbeta^{-1})). \notag
  \end{align}
  Then for any $\X \in \Fqm^{\foldPar \times \lenFLRS}$ we have that the mapping $\varphi_{\alpha}$ is an isometry between the skew metric and the sum-rank metric, i.e. we have that
  \begin{equation}
    \SkewWeight^\set{B}(\varphi_{\alpha}(\X)) = \SumRankWeight(\X)
  \end{equation}
  where $\set{B}=\{\op{a_i}{\pe^{j\foldPar}}/\pe^{j\foldPar}: j=0,\dots\lenShot{i}-1, i=1,\dots,\shots\}$.
\end{theorem}

\begin{proof}
  The vectors $\shot{\vecalpha}{i} \defeq (1, \pe^\foldPar, \dots, \pe^{(\lenFLRSshot{i}-1)\foldPar})$ contain $\Fq$-linearly independent elements from $\Fqm$ since $\pe$ is a primitive element of $\Fqm$ and $\lenShot{i}=\lenFLRSshot{i}\foldPar \leq m$ for all $i=1,\dots,\shots$.
  Thus, by~\cite[Thm.~4.5]{lam1988vandermonde} we have that the vectors
  \begin{equation*}
    \shot{\b}{i} = \left(\op{a_i}{1}, \op{a_i}{\pe^\foldPar}/\pe^\foldPar, \dots, \op{a_i}{\pe^{(\lenFLRSshot{i}-1)\foldPar}}/\pe^{(\lenFLRSshot{i}-1)\foldPar}\right)
  \end{equation*}
  contain P-independent elements for all $i=1, \dots, \shots$.
  Since $a_1, \dots, a_\shots$ are representatives of different conjugacy classes of $\Fqm$, we also have that the entries in $\b=(\shot{\b}{1} \mid \shot{\b}{2} \mid \dots \mid \shot{\b}{\shots})$ are P-independent which implies that $\set{B}$ is a P-independent set (cf.~\cite[Thm.~9]{martinez2019reliable} and~\cite{lam1985general, lam1988vandermonde}).

  By using the relation between the generalized operator evaluation and the remainder evaluation in~\eqref{eq:rel_remev_opev} and the result of~\autoref{lem:folded_mat_to_interleaved_mat_fsrs}, we can write the blocks of the transformed tuple
  \begin{equation*}
    \widetilde{\X} \defeq \varphi_{\pe}(\X)=\foldOp{\foldParVec}\left(\foldOpInv{\foldParVec}(\X)\cdot \diag(\vecbeta^{-1})\right)
  \end{equation*}
  in terms of the remainder evaluation as
  \begin{equation*}
    \shot{\widetilde{\X}}{i}
    \defeq
    \foldOp{\foldPar}\left(\foldOpInv{\foldPar}(\shot{\X}{i})\cdot \diag\left((\shot{\vecbeta}{i})^{-1}\right)\right)
    =
    \begin{pmatrix}
     \remev{f}{\shot{\b}{i}}
     \\
     \remev{f}{\FSRSoffset \shot{\b}{i}}
     \\
     \vdots
     \\
     \remev{f}{\FSRSoffset^{\foldPar - 1} \shot{\b}{i}}
    \end{pmatrix}
    =
    \begin{pmatrix}
     \remev{f^{(1)}}{\shot{\b}{i}}
     \\
     \remev{f^{(2)}}{\shot{\b}{i}}
     \\
     \vdots
     \\
     \remev{f^{(\foldPar)}}{\shot{\b}{i}}
    \end{pmatrix},
  \end{equation*}
  where $(\shot{\vecbeta}{i})^{-1} \defeq (1,\pe^{-1},\dots,(\pe^{\lenShot{i}-1})^{-1})$ for all $i=1,\dots,\shots$ such that $\vecbeta^{-1}=((\shot{\vecbeta}{1})^{-1} \mid \dots \mid (\shot{\vecbeta}{\shots})^{-1})$ and $f^{(j)}=\sum_{l=0}^{n-1} f_l \genNorm{a_i}{\FSRSoffset^j} x^l$.

  Hence we can write each transformed block $\shot{\widetilde{\X}}{i}$ over $\Fqmh$ as an evaluation of $F \in \Fqmh[x; \aut]_{<n}$ at the P-independent elements from $\Fqm$ in $\shot{\b}{i}$, i.e. we have
  \begin{equation*}
    \shot{\widetilde{\x}}{i} \defeq \extInv_{\vecgamma}(\shot{\widetilde{\X}}{i}) = \remev{F}{\shot{\b}{i}}
    \quad \forall i = 1, \dots, \shots.
  \end{equation*}

  Define the vectors $\widetilde{\x} \defeq (\shot{\widetilde{\x}}{1} \mid \shot{\widetilde{\x}}{2} \mid \dots \mid \shot{\widetilde{\x}}{\shots}) \in \Fqmh^\lenFLRS$ and $\x \defeq (\shot{\x}{1} \mid \shot{\x}{2} \mid \dots \mid \shot{\x}{\shots}) \in \Fqmh^\lenFLRS$.
  Then it follows from~\cite[Thm.~3]{martinez2018skew} that
  \begin{equation*}
   \SkewWeight^{\set{B}}(\widetilde{\x}) = \SumRankWeight(\x).
  \end{equation*}
\end{proof}

\autoref{ex:sum_rank_skew_map} illustrates the operator $\varphi_{\alpha}$.
\begin{example}\label{ex:sum_rank_skew_map}
  Consider a matrix $\X=(\shot{\X}{1} \mid\shot{\X}{2})\in\Fqm^{\foldPar \times \lenFLRS}$ where $\foldPar=3$ and $\lenFLRSVec=(2,3)$.
  Then the operator $\varphi_{\alpha}$ applied to $\X$ gives
  \begin{equation*}
    \varphi_{\alpha}(\X)=
    \left(
    \begin{array}{cc|ccc}
     \shot{x}{1}_{1,1}/1 & \shot{x}{1}_{1,2}/\pe^3 & \shot{x}{2}_{1,1}/1 & \shot{x}{2}_{1,2}/\pe^3 & \shot{x}{2}_{1,3}/\pe^6
     \\
     \shot{x}{1}_{2,1}/\pe & \shot{x}{1}_{2,2}/\pe^4 & \shot{x}{2}_{2,1}/\pe & \shot{x}{2}_{2,2}/\pe^4 & \shot{x}{2}_{2,3}/\pe^7
     \\
     \shot{x}{1}_{3,1}/\pe^2 & \shot{x}{1}_{3,2}/\pe^5 & \shot{x}{2}_{3,1}/\pe^2 & \shot{x}{2}_{3,2}/\pe^5 & \shot{x}{2}_{3,3}/\pe^8
    \end{array}
    \right).
  \end{equation*}
\end{example}

Skew Reed--Solomon codes were proposed by Boucher and Ulmer in~\cite{boucher2014linear} and further investigated in~\cite{liu2015construction, martinez2018skew}.

\begin{definition}[Skew Reed--Solomon Codes~\cite{boucher2014linear}]
    Let $\b=(b_1, b_2, \dots, b_n) \in \Fqm^n$ contain P-independent elements from $\Fqm$. Then a \emph{\acl{SRS} code} of length $n$ and dimension $k \leq n$ is defined as
    \begin{equation*}
      \skewRS{\b; n,k}=\{\remev{f}{\b} : f \in \SkewPolyringZeroDer_{<k}\}.
    \end{equation*}
\end{definition}

\begin{definition}[Folded Skew Reed--Solomon Codes]\label{def:folded_srs}
    Let $\pe$ be a primitive element of $\Fqm$ and define $\FSRSoffset \defeq \aut(\pe)/\pe$.
    Let $a_1,\dots,a_\shots$ be representatives of pairwise distinct nontrivial conjugacy classes of $\Fqm$.
    Define $\b=(\shot{\b}{1} \mid \shot{\b}{2} \mid \dots \mid \shot{\b}{\shots})$ with
    \begin{equation*}
        \shot{\b}{i} \defeq
        a_i \left(1, \FSRSoffset, \FSRSoffset^2, \dots, \FSRSoffset^{\lenShot{i}-1}\right)
        \in \Fqm^{\lenShot{i}}
        \quad \forall i = 1, \dots, \shots.
    \end{equation*}
    Choose a folding parameter $\foldPar \in \NN$ satisfying $\foldPar \mid \lenShot{i}$ for all $1 \leq i \leq \shots$ and $\lenFLRSshot{i} \defeq \frac{\lenShot{i}}{\foldPar} \leq \foldPar$ for all $1 \leq i \leq \shots$ and write
    $\N \defeq (\lenFLRSshot{1}, \dots, \lenFLRSshot{\shots})$.
    Then an \emph{$\foldPar$-folded \acl{SRS} code} of length $\lenFLRS \defeq \sum_{i=1}^{\shots} \lenFLRSshot{i}$ and dimension $k$ is defined as
    \begin{equation}
        \foldedSkewRS{\b, \foldPar; \lenFLRSVec, k}
        \defeq
        \left\{
        \foldOp{\foldPar}(\remev{f}{\b}) : f \in \SkewPolyringZeroDer_{<k} \right\}.
    \end{equation}
\end{definition}

\begin{remark}
  Equivalently, we can define \ac{FSRS} codes as
  \begin{equation}
        \foldedSkewRS{\b, \foldPar; \lenFLRSVec, k}
        \defeq
        \left\{
        \foldOp{\foldPar}(\c) : \c \in \skewRS{\b; n,k} \right\}
  \end{equation}
  where $\b$ is defined as in~\autoref{def:folded_srs}.
\end{remark}

Note that any codeword $\C \in \foldedSkewRS{\b, \foldPar; \lenFLRSVec, k} \subseteq
\Fqm^{\foldPar \times \lenFLRS}$ corresponding to a message polynomial $f \in \SkewPolyringZeroDer_{<k}$ has the form
\begin{equation*}
    \C = \left( \C^{(1)} \mid \dots \mid \C^{(\shots)} \right)
\end{equation*}
where
\begin{equation*}
    \C^{(i)} =
    \begin{pmatrix}
        \remev{f}{a_i} & \remev{f}{\FSRSoffset^\foldPar a_i} & \cdots
        & \remev{f}{\FSRSoffset^{\lenShot{i}-\foldPar} a_i}
        \\
        \remev{f}{\FSRSoffset a_i} & \remev{f}{\FSRSoffset^{\foldPar+1} a_i} & \cdots
        & \remev{f}{\FSRSoffset^{\lenShot{i}-\foldPar+1} a_i}
        \\
        \vdots & \vdots & \ddots & \vdots
        \\
        \remev{f}{\FSRSoffset^{\foldPar - 1} a_i} & \remev{f}{\FSRSoffset^{2\foldPar-1} a_i} & \cdots
        & \remev{f}{\FSRSoffset^{\lenShot{i}-1} a_i}
    \end{pmatrix}
    \in \Fqm^{\foldPar \times \lenFLRSshot{i}}
\end{equation*}
for all $i \in \{1, \ldots, \shots\}$.

\begin{proposition}[Relation between \ac{FLRS} and \ac{FSRS} Codes]\label{prop:rel_flrs_fsrs}
  Let $\foldedSkewRS{\b, \foldPar; \allowbreak \lenFLRSVec, k}$ be an \ac{FSRS} code whose parameters comply with~\autoref{def:folded_srs}.
  Then,
  \begin{equation*}
    \foldedSkewRS{\b, \foldPar; \lenFLRSVec, k}
    =
    \{\varphi_{\pe}(\C) : \C \in \foldedLinRS{\pe, \a, \foldParVec; \lenFLRSVec, k}\}
  \end{equation*}
  where the code $\foldedLinRS{\pe, \a, \foldParVec; \lenFLRSVec, k}$ with $\foldParVec = (\foldPar, \dots, \foldPar)$ is considered as subset of $\Fqm^{\foldPar \times \lenFLRS}$.
\end{proposition}

\begin{proof}
  The result follows directly by using the relation between the generalized operator evaluation and the remainder evaluation in~\eqref{eq:rel_remev_opev}.
\end{proof}

By using the isometry between the sum-rank metric and the skew metric from \autoref{thm:sum-rank_relation_skew_and_sum-rank_metric}, we obtain the following corollary from~\autoref{thm:minimum_distance_flrs}.

\begin{corollary}[Minimum Skew Distance]
  The minimum skew distance of an \ac{FSRS} code $\mycode{C} \defeq \foldedSkewRS{\b, \foldPar; \lenFLRSVec, k}$ of length $\lenFLRS=\sum_{i=1}^{\shots}\lenFLRSshot{i}$ as defined in~\autoref{def:folded_srs} is
  \begin{equation*}
    \SkewDist(\mycode{C}) = \lenFLRS - \left\lceil\frac{k}{\foldPar}\right\rceil + 1.
  \end{equation*}
\end{corollary}

\subsection{Interpolation-Based Decoding of Folded Skew Reed--Solomon Codes} \label{subsec:decoding-of-fsrs-codes}

We now consider interpolation-based decoding of \ac{FSRS} codes with respect to the skew metric.
As a channel model we consider the skew error channel with input and output alphabet $\Fqm^{\foldPar \times \lenFLRS}$, where the input $\C$ is related to the output $\R$ by
\begin{equation}\label{eq:skew_error_channel}
  \R = \C + \E
\end{equation}
and $\E$ with $\SkewWeight(\E)=t$ is chosen uniformly at random from all matrices from $\Fqm^{\foldPar \times \lenFLRS}$ with skew weight $t$.

Suppose we transmit a codeword $\C \in \foldedSkewRS{\b, \foldPar; \lenFLRSVec, k}$ over a skew error channel~\eqref{eq:skew_error_channel} and receive a matrix $\R=(\shot{\R}{1} \mid \shot{\R}{2} \mid \dots \mid \shot{\R}{\shots})$.
Let $\varphi^{-1}_{\alpha}$ denote the inverse map of $\varphi_{\alpha}$.
By using the isometry between the sum-rank metric and the relation between \ac{FLRS} codes and \ac{FSRS} codes, we can transform the received matrix $\R$ to
\begin{equation*}
  \widetilde{\R} \defeq \varphi^{-1}_{\alpha}(\R) = \varphi^{-1}_{\alpha}(\C) + \varphi^{-1}_{\alpha}(\E)
\end{equation*}
where $\varphi^{-1}_{\alpha}(\C)$ is in the corresponding \ac{FLRS} code $\foldedLinRS{\pe, \a, \foldParVec; \lenFLRSVec, k}$ (see \autoref{prop:rel_flrs_fsrs}) and $\varphi^{-1}_{\alpha}(\E)$ has sum-rank weight $t$ (see~\autoref{thm:sum-rank_relation_skew_and_sum-rank_metric}).
Hence, the decoding problem for \ac{FSRS} codes with respect to the skew metric is mapped to an equivalent decoding problem for \ac{FLRS} codes in the sum-rank metric.

Therefore, we can use the interpolation-based decoding schemes for \ac{FLRS} codes from~\autoref{sec:decoding} to decode \ac{FSRS} codes in the skew metric as follows:

\begin{enumerate}
  \item Compute $\widetilde{\R} \defeq \varphi^{-1}_{\alpha}(\R)$, which requires $\OCompl{n}$ operations in $\Fqm$.

  \item Apply a decoder for \ac{FLRS} codes in the sum-rank metric (e.g.~\autoref{alg:decoder}) to $\widetilde{\R}$.
\end{enumerate}

\section{Conclusion} \label{sec:conclusion}

\acresetall

We introduced the family of \ac{FLRS} codes whose members are \ac{MSRD} codes for appropriate parameter choices.
We further described an efficient decoding scheme to correct sum-rank errors in the context of list and probabilistic
unique decoding with quadratic complexity in the length of the unfolded code.
Up to our knowledge, this is the first explicit \ac{MSRD} code construction that allows different block sizes and has
an explicit efficient decoding algorithm.
We analyzed the decoder and gave upper bounds on both list size and failure probability.
Monte Carlo simulations verified that the observed failure probability is indeed below the derived bound and further
experiments show that the assumption under which the upper bound was derived is reasonable.
Since the proposed decoding scheme has a rate restriction, we investigated a Justesen-like improvement tailored to
high-rate \ac{FLRS} codes.

The focus of the second part of the paper was the skew metric for which we introduced \ac{FSRS} codes in the
zero-derivation setting.
Moreover, we explained how the decoding scheme for \ac{FLRS} codes in the sum-rank metric can be applied to the
presented skew-metric codes.

Goals for further research could be the extension of \ac{FSRS} codes to the nonzero-derivation case or to more general
parameters as e.g.\ code locators.
Moreover, it is tempting to study if there are other useful ways of folding codes in different metrics.

\vspace*{.5cm}
\noindent
\textbf{Acknowledgments.}
F. HÃ¶rmann and H. Bartz acknowledge the financial support by the Federal Ministry of Education and Research of
Germany in the programme of ``SouverÃ¤n. Digital. Vernetzt.'' Joint project 6G-RIC, project identification
number: 16KISK022.


\bibliographystyle{splncs04}
\bibliography{references}



\end{document}
