@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})


@inproceedings{NUWA,
  author    = {Chenfei Wu and
               Jian Liang and
               Lei Ji and
               Fan Yang and
               Yuejian Fang and
               Daxin Jiang and
               Nan Duan},
  title     = {N{\"{U}}WA: Visual Synthesis Pre-training for Neural visUal World
               creAtion},
  booktitle = {ECCV},
  year      = {2022},
}

@inproceedings{TATS,
  author    = {Songwei Ge and
               Thomas Hayes and
               Harry Yang and
               Xi Yin and
               Guan Pang and
               David Jacobs and
               Jia{-}Bin Huang and
               Devi Parikh},
  title     = {Long Video Generation with Time-Agnostic {VQGAN} and Time-Sensitive
               Transformer},
  booktitle = {ECCV},
  year      = {2022},
}

@article{videoGPT,
  title={Videogpt: Video generation using vq-vae and transformers},
  author={Yan, Wilson and Zhang, Yunzhi and Abbeel, Pieter and Srinivas, Aravind},
  journal={arXiv preprint arXiv:2104.10157},
  year={2021}
}

@inproceedings{VQGAN,
  author    = {Patrick Esser and
               Robin Rombach and
               Bj{\"{o}}rn Ommer},
  title     = {Taming Transformers for High-Resolution Image Synthesis},
  booktitle = {CVPR},
  year      = {2021},
}

@inproceedings{DALL-E,
  author    = {Aditya Ramesh and
               Mikhail Pavlov and
               Gabriel Goh and
               Scott Gray and
               Chelsea Voss and
               Alec Radford and
               Mark Chen and
               Ilya Sutskever},
  title     = {Zero-Shot Text-to-Image Generation},
  booktitle = {ICML},
  year      = {2021},
}

@inproceedings{MaskGIT,
  author    = {Huiwen Chang and
               Han Zhang and
               Lu Jiang and
               Ce Liu and
               William T. Freeman},
  title     = {MaskGIT: Masked Generative Image Transformer},
  booktitle = {CVPR},
  year      = {2022},
}

@inproceedings{MMVID,
  author    = {Ligong Han and
               Jian Ren and
               Hsin{-}Ying Lee and
               Francesco Barbieri and
               Kyle Olszewski and
               Shervin Minaee and
               Dimitris N. Metaxas and
               Sergey Tulyakov},
  title     = {Show Me What and Tell Me How: Video Synthesis via Multimodal Conditioning},
  booktitle = {CVPR},
  year      = {2022},
}

@article{CogView2,
  author    = {Ming Ding and
               Wendi Zheng and
               Wenyi Hong and
               Jie Tang},
  title     = {CogView2: Faster and Better Text-to-Image Generation via Hierarchical
               Transformers},
  journal   = {CoRR},
  volume    = {abs/2204.14217},
  year      = {2022},
}

@inproceedings{CogView,
  author    = {Ming Ding and
               Zhuoyi Yang and
               Wenyi Hong and
               Wendi Zheng and
               Chang Zhou and
               Da Yin and
               Junyang Lin and
               Xu Zou and
               Zhou Shao and
               Hongxia Yang and
               Jie Tang},
  title     = {CogView: Mastering Text-to-Image Generation via Transformers},
  booktitle = {NIPS},
  year      = {2021},
}

@article{VPVQVAE,
  author    = {Jacob Walker and
               Ali Razavi and
               A{\"{a}}ron van den Oord},
  title     = {Predicting Video with {VQVAE}},
  journal   = {CoRR},
  volume    = {abs/2103.01950},
  year      = {2021},
}

@inproceedings{VQVAE,
  author    = {A{\"{a}}ron van den Oord and
               Oriol Vinyals and
               Koray Kavukcuoglu},
  title     = {Neural Discrete Representation Learning},
  booktitle = NIPS,
  year      = {2017},
}

@inproceedings{BigBird,
  author    = {Manzil Zaheer and
               Guru Guruganesh and
               Kumar Avinava Dubey and
               Joshua Ainslie and
               Chris Alberti and
               Santiago Onta{\~{n}}{\'{o}}n and
               Philip Pham and
               Anirudh Ravula and
               Qifan Wang and
               Li Yang and
               Amr Ahmed},
  title     = {Big Bird: Transformers for Longer Sequences},
  booktitle = NIPS,
  year      = {2020},
}

@inproceedings{LVT,
  author    = {Ruslan Rakhimov and
               Denis Volkhonskiy and
               Alexey Artemov and
               Denis Zorin and
               Evgeny Burnaev},
  title     = {Latent Video Transformer},
  booktitle = {VISIGRAPP},
  year      = {2021},
}

@article{LongFormer,
  author    = {Iz Beltagy and
               Matthew E. Peters and
               Arman Cohan},
  title     = {Longformer: The Long-Document Transformer},
  journal   = {CoRR},
  volume    = {abs/2004.05150},
  year      = {2020},
}

@article{Ho2019,
  author    = {Jonathan Ho and
               Nal Kalchbrenner and
               Dirk Weissenborn and
               Tim Salimans},
  title     = {Axial Attention in Multidimensional Transformers},
  journal   = {CoRR},
  volume    = {abs/1912.12180},
  year      = {2019},
}

@article{MaskViT,
  author    = {Agrim Gupta and
               Stephen Tian and
               Yunzhi Zhang and
               Jiajun Wu and
               Roberto Mart{\'{\i}}n{-}Mart{\'{\i}}n and
               Li Fei{-}Fei},
  title     = {MaskViT: Masked Visual Pre-Training for Video Prediction},
  journal   = {CoRR},
  volume    = {abs/2206.11894},
  year      = {2022},
}

@article{CogVideo,
  author    = {Wenyi Hong and
               Ming Ding and
               Wendi Zheng and
               Xinghan Liu and
               Jie Tang},
  title     = {CogVideo: Large-scale Pretraining for Text-to-Video Generation via
               Transformers},
  journal   = {CoRR},
  volume    = {abs/2205.15868},
  year      = {2022},
}

@inproceedings{Perceiver,
  author    = {Andrew Jaegle and
               Felix Gimeno and
               Andy Brock and
               Oriol Vinyals and
               Andrew Zisserman and
               Jo{\~{a}}o Carreira},
  title     = {Perceiver: General Perception with Iterative Attention},
  booktitle = {ICML},
  year      = {2021},
}

@inproceedings{M6-UFC,
  author    = {Zhu Zhang and
               Jianxin Ma and
               Chang Zhou and
               Rui Men and
               Zhikang Li and
               Ming Ding and
               Jie Tang and
               Jingren Zhou and
               Hongxia Yang},
  title     = {{UFC-BERT:} Unifying Multi-Modal Controls for Conditional Image Synthesis},
  booktitle = NIPS,
  year      = {2021},
}

@article{UCF,
  author    = {Khurram Soomro and
               Amir Roshan Zamir and
               Mubarak Shah},
  title     = {{UCF101:} {A} Dataset of 101 Human Actions Classes From Videos in
               The Wild},
  journal   = {CoRR},
  volume    = {abs/1212.0402},
  year      = {2012},
}

@article{EfficientTransformers,
  author    = {Yi Tay and
               Mostafa Dehghani and
               Dara Bahri and
               Donald Metzler},
  title     = {Efficient Transformers: {A} Survey},
  journal   = {arXiv},
  year      = {2020},
}

@inproceedings{LUNA,
  author    = {Xuezhe Ma and
               Xiang Kong and
               Sinong Wang and
               Chunting Zhou and
               Jonathan May and
               Hao Ma and
               Luke Zettlemoyer},
  title     = {Luna: Linear Unified Nested Attention},
  booktitle = NIPS,
  year      = {2021},
}

@article{Linformer,
  author    = {Sinong Wang and
               Belinda Z. Li and
               Madian Khabsa and
               Han Fang and
               Hao Ma},
  title     = {Linformer: Self-Attention with Linear Complexity},
  journal   = {arXiv},
  year      = {2020},
}

@inproceedings{PerceiverIO,
  author    = {Andrew Jaegle and
               Sebastian Borgeaud and
               Jean{-}Baptiste Alayrac and
               Carl Doersch and
               Catalin Ionescu and
               David Ding and
               Skanda Koppula and
               Daniel Zoran and
               Andrew Brock and
               Evan Shelhamer and
               Olivier J. H{\'{e}}naff and
               Matthew M. Botvinick and
               Andrew Zisserman and
               Oriol Vinyals and
               Jo{\~{a}}o Carreira},
  title     = {Perceiver {IO:} {A} General Architecture for Structured Inputs {\&}
               Outputs},
  booktitle = ICLR,
  year      = {2022},
}

@inproceedings{SetTransformer,
  author    = {Juho Lee and
               Yoonho Lee and
               Jungtaek Kim and
               Adam R. Kosiorek and
               Seungjin Choi and
               Yee Whye Teh},
  editor    = {Kamalika Chaudhuri and
               Ruslan Salakhutdinov},
  title     = {Set Transformer: {A} Framework for Attention-based Permutation-Invariant Neural Networks},
  booktitle = {ICML},
  year      = {2019},
}

@inproceedings{SetVAE,
  author    = {Jinwoo Kim and
               Jaehoon Yoo and
               Juho Lee and
               Seunghoon Hong},
  title     = {SetVAE: Learning Hierarchical Composition for Generative Modeling of Set-Structured Data},
  booktitle = CVPR,
  year      = {2021},
}

@inproceedings{BERT,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  booktitle = {NAACL-HLT},
  year      = {2019},
}

@inproceedings{MAE,
  author    = {Kaiming He and
               Xinlei Chen and
               Saining Xie and
               Yanghao Li and
               Piotr Doll{\'{a}}r and
               Ross B. Girshick},
  title     = {Masked Autoencoders Are Scalable Vision Learners},
  booktitle = CVPR,
  year      = {2022},
}

@inproceedings{draft_and_revise,
  title={Draft-and-Revise: Effective Image Generation with Contextual RQ-Transformer},
  author={Lee, Doyup and Kim, Chiheon and Kim, Saehoon and Cho, Minsu and Han, Wook-Shin},
  booktitle=NIPS,
  year={2022}
}
@article{GAN,
  author    = {Ian J. Goodfellow and
               Jean Pouget{-}Abadie and
               Mehdi Mirza and
               Bing Xu and
               David Warde{-}Farley and
               Sherjil Ozair and
               Aaron C. Courville and
               Yoshua Bengio},
  title     = {Generative adversarial networks},
  journal   = {Commun. {ACM}},
  year      = {2020},
}

@article{DVDGAN,
  author    = {Aidan Clark and
               Jeff Donahue and
               Karen Simonyan},
  title     = {Efficient Video Generation on Complex Datasets},
  journal   = {CoRR},
  volume    = {abs/1907.06571},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.06571},
}

@inproceedings{TGAN,
  author    = {Masaki Saito and
               Eiichi Matsumoto and
               Shunta Saito},
  title     = {Temporal Generative Adversarial Nets with Singular Value Clipping},
  booktitle = ICCV,
  year      = {2017},
}

@article{TGANv2,
  author    = {Masaki Saito and
               Shunta Saito and
               Masanori Koyama and
               Sosuke Kobayashi},
  title     = {Train Sparsely, Generate Densely: Memory-Efficient Unsupervised Training
               of High-Resolution Temporal {GAN}},
  journal   = {Int. J. Comput. Vis.},
  year      = {2020},
}

@inproceedings{MoCoGAN,
  author    = {Sergey Tulyakov and
               Ming{-}Yu Liu and
               Xiaodong Yang and
               Jan Kautz},
  title     = {MoCoGAN: Decomposing Motion and Content for Video Generation},
  booktitle = CVPR,
  year      = {2018},
}

@inproceedings{MoCoGAN-HD,
  author    = {Yu Tian and
               Jian Ren and
               Menglei Chai and
               Kyle Olszewski and
               Xi Peng and
               Dimitris N. Metaxas and
               Sergey Tulyakov},
  title     = {A Good Image Generator Is What You Need for High-Resolution Video
               Synthesis},
  booktitle = ICLR,
  year      = {2021},
}

@article{LDVDGAN,
  author    = {Emmanuel Kahembwe and
               Subramanian Ramamoorthy},
  title     = {Lower dimensional kernels for video discriminators},
  journal   = {Neural Networks},
  year      = {2020},
}

@inproceedings{StyleGAN-V,
  author    = {Ivan Skorokhodov and
               Sergey Tulyakov and
               Mohamed Elhoseiny},
  title     = {StyleGAN-V: {A} Continuous Video Generator with the Price, Image Quality
               and Perks of StyleGAN2},
  booktitle = CVPR,
  year      = {2022},
}

@inproceedings{DIGAN,
  author    = {Sihyun Yu and
               Jihoon Tack and
               Sangwoo Mo and
               Hyunsu Kim and
               Junho Kim and
               Jung{-}Woo Ha and
               Jinwoo Shin},
  title     = {Generating Videos with Dynamics-aware Implicit Generative Adversarial
               Networks},
  booktitle = ICLR,
  year      = {2022},
}
@inproceedings{VPN,
  author    = {Nal Kalchbrenner and
               A{\"{a}}ron van den Oord and
               Karen Simonyan and
               Ivo Danihelka and
               Oriol Vinyals and
               Alex Graves and
               Koray Kavukcuoglu},
  title     = {Video Pixel Networks},
  booktitle = {ICML},
  year      = {2017},
}

@inproceedings{ARVideo,
  author    = {Dirk Weissenborn and
               Oscar T{\"{a}}ckstr{\"{o}}m and
               Jakob Uszkoreit},
  title     = {Scaling Autoregressive Video Models},
  booktitle = ICLR,
  year      = {2020},
}

@inproceedings{stl,
  author    = {Wei Xiong and
               Wenhan Luo and
               Lin Ma and
               Wei Liu and
               Jiebo Luo},
  title     = {Learning to Generate Time-Lapse Videos Using Multi-Stage Dynamic Generative
               Adversarial Networks},
  booktitle = CVPR,
  year      = {2018},
}

@inproceedings{taichi,
  author    = {Aliaksandr Siarohin and
               St{\'{e}}phane Lathuili{\`{e}}re and
               Sergey Tulyakov and
               Elisa Ricci and
               Nicu Sebe},
  title     = {First Order Motion Model for Image Animation},
  booktitle = NIPS,
  year      = {2019},
}

@article{FVD,
  author    = {Thomas Unterthiner and
               Sjoerd van Steenkiste and
               Karol Kurach and
               Rapha{\"{e}}l Marinier and
               Marcin Michalski and
               Sylvain Gelly},
  title     = {Towards Accurate Generative Models of Video: {A} New Metric {\&}
               Challenges},
  journal   = {CoRR},
  volume    = {abs/1812.01717},
  year      = {2018},
}
@article{kinetics,
  author    = {Will Kay and
               Jo{\~{a}}o Carreira and
               Karen Simonyan and
               Brian Zhang and
               Chloe Hillier and
               Sudheendra Vijayanarasimhan and
               Fabio Viola and
               Tim Green and
               Trevor Back and
               Paul Natsev and
               Mustafa Suleyman and
               Andrew Zisserman},
  title     = {The Kinetics Human Action Video Dataset},
  journal   = {CoRR},
  volume    = {abs/1705.06950},
  year      = {2017},
}

@inproceedings{IS,
  author    = {Tim Salimans and
               Ian J. Goodfellow and
               Wojciech Zaremba and
               Vicki Cheung and
               Alec Radford and
               Xi Chen},
  title     = {Improved Techniques for Training GANs},
  booktitle = NIPS,
  year      = {2016},
}

@inproceedings{c3d,
  author    = {Du Tran and
               Lubomir D. Bourdev and
               Rob Fergus and
               Lorenzo Torresani and
               Manohar Paluri},
  title     = {Learning Spatiotemporal Features with 3D Convolutional Networks},
  booktitle = ICCV,
  year      = {2015},
}

@inproceedings{CCVS,
  author    = {Guillaume Le Moing and
               Jean Ponce and
               Cordelia Schmid},
  title     = {{CCVS:} Context-aware Controllable Video Synthesis},
  booktitle = NIPS,
  year      = {2021},
}

@inproceedings{VGAN,
  author    = {Carl Vondrick and
               Hamed Pirsiavash and
               Antonio Torralba},
  title     = {Generating Videos with Scene Dynamics},
  booktitle = NIPS,
  year      = {2016},
}

@article{SAVP,
  author    = {Alex X. Lee and
               Richard Zhang and
               Frederik Ebert and
               Pieter Abbeel and
               Chelsea Finn and
               Sergey Levine},
  title     = {Stochastic Adversarial Video Prediction},
  journal   = {CoRR},
  volume    = {abs/1804.01523},
  year      = {2018},
}

@inproceedings{CWVAE,
  author    = {Vaibhav Saxena and
               Jimmy Ba and
               Danijar Hafner},
  title     = {Clockwork Variational Autoencoders},
  booktitle = NIPS,
  year      = {2021},
}

@inproceedings{SVG,
  author    = {Emily Denton and
               Rob Fergus},
  title     = {Stochastic Video Generation with a Learned Prior},
  booktitle = {ICML},
  year      = {2018},
}

@article{FitVid,
  author    = {Mohammad Babaeizadeh and
               Mohammad Taghi Saffar and
               Suraj Nair and
               Sergey Levine and
               Chelsea Finn and
               Dumitru Erhan},
  title     = {FitVid: Overfitting in Pixel-Level Video Prediction},
  journal   = {CoRR},
  volume    = {abs/2106.13195},
  year      = {2021},
}

@inproceedings{HVP,
  author    = {Wonkwang Lee and
               Whie Jung and
               Han Zhang and
               Ting Chen and
               Jing Yu Koh and
               Thomas E. Huang and
               Hyungsuk Yoon and
               Honglak Lee and
               Seunghoon Hong},
  title     = {Revisiting Hierarchical Approach for Persistent Long-Term Video Prediction},
  booktitle = ICLR,
  year      = {2021},
}

@inproceedings{SRVP,
  author    = {Jean{-}Yves Franceschi and
               Edouard Delasalles and
               Micka{\"{e}}l Chen and
               Sylvain Lamprier and
               Patrick Gallinari},
  title     = {Stochastic Latent Residual Video Prediction},
  booktitle = {ICML},
  year      = {2020},
}

@inproceedings{Villegas2017,
  author    = {Ruben Villegas and
               Jimei Yang and
               Yuliang Zou and
               Sungryull Sohn and
               Xunyu Lin and
               Honglak Lee},
  editor    = {Doina Precup and
               Yee Whye Teh},
  title     = {Learning to Generate Long-term Future via Hierarchical Prediction},
  booktitle = {ICML},
  year      = {2017},
}

@inproceedings{KimNCK19,
  author    = {Yunji Kim and
               Seonghyeon Nam and
               In Cho and
               Seon Joo Kim},
  title     = {Unsupervised Keypoint Learning for Guiding Class-Conditional Video Prediction},
  booktitle = NIPS,
  year      = {2019},
}

@inproceedings{LeeKCKR21,
  author    = {Sangmin Lee and
               Hak Gu Kim and
               Dae Hwi Choi and
               Hyung{-}Il Kim and
               Yong Man Ro},
  title     = {Video Prediction Recalling Long-Term Motion Context via Memory Alignment
               Learning},
  booktitle = CVPR,
  year      = {2021},
}

@article{Akan2022,
  author    = {Adil Kaan Akan and
               Sadra Safadoust and
               Erkut Erdem and
               Aykut Erdem and
               Fatma G{\"{u}}ney},
  title     = {Stochastic Video Prediction with Structure and Motion},
  journal   = {CoRR},
  volume    = {abs/2203.10528},
  year      = {2022},
}

@inproceedings{GHVAE,
  author    = {Bohan Wu and
               Suraj Nair and
               Roberto Mart{\'{\i}}n{-}Mart{\'{\i}}n and
               Li Fei{-}Fei and
               Chelsea Finn},
  title     = {Greedy Hierarchical Variational Autoencoders for Large-Scale Video
               Prediction},
  booktitle = CVPR,
  year      = {2021},
}

@inproceedings{ImprovedVRNN,
  author    = {Llu{\'{\i}}s Castrej{\'{o}}n and
               Nicolas Ballas and
               Aaron C. Courville},
  title     = {Improved Conditional VRNNs for Video Prediction},
  booktitle = ICCV,
  year      = {2019},
}

@inproceedings{LiangLDX17,
  author    = {Xiaodan Liang and
               Lisa Lee and
               Wei Dai and
               Eric P. Xing},
  title     = {Dual Motion {GAN} for Future-Flow Embedded Video Prediction},
  booktitle = ICCV,
  year      = {2017},
}

@inproceedings{AdamW,
  author    = {Ilya Loshchilov and
               Frank Hutter},
  title     = {Decoupled Weight Decay Regularization},
  booktitle = ICLR,
  year      = {2019},
}