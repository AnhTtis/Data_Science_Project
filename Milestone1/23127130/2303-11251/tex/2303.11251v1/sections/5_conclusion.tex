\cutparagraphup
\section{Conclusion}
% \cutparagraphup
We proposed a Memory-efficient Bidirectional Transformer (MeBT), a transformer-based generative model for moderately long-term video synthesis.
By formulating the video synthesis as an iterative mask prediction task and employing bidirectional transformers with efficient encoder-decoder architecture, we showed that we could push the transformers to leverage much longer videos in training while enjoying fast inference speed and robustness in error propagation.
Our experiments demonstrated that by training with longer videos, MeBT could learn long-term dependencies and generate coherent videos over longer time horizon.
