%%
%% This is file `sample-manuscript.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,manuscript')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-manuscript.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[manuscript]{acmart}
\settopmatter{printacmref=false}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2025}
\acmYear{2025}
\acmDOI{XXXXXXX.XXXXXXX}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}
\usepackage{multirow}
\usepackage{threeparttable}
\DeclareCaptionLabelFormat{appendixtable}{Appendix Table~#2}
\captionsetup[table]{labelformat=appendixtable, labelsep=period}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Label-Efficient Deep Learning in Medical Image Analysis: Challenges and Future Directions}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Cheng Jin}
\authornote{Both authors contributed equally to this research.}
\email{cheng.jin@connect.ust.hk}
\orcid{0000-0002-3522-3592}
\author{Zhengrui Guo}
\authornotemark[1]
\email{zguobc@connect.ust.hk}
\orcid{0009-0006-9920-0978}
\affiliation{%
  \institution{The Hong Kong University of Science and Technology}
  \country{Hong Kong SAR}
}

\author{Yi Lin}
\affiliation{
  \institution{Weill Cornell Medicine, New York, NY}
  \country{USA}
}
\orcid{0000-0002-7635-2518}
\email{yil4033@med.cornell.edu}

\author{Luyang Luo}
\affiliation{
  \institution{Harvard University, Cambridge, MA}
  \country{USA}
}
\orcid{0000-0002-7485-4151}
\email{luyang_luo@hms.harvard.edu}

\author{Hao Chen}
\authornote{Corresponding author.}
\affiliation{
 \institution{The Hong Kong University of Science and Technology}
 \country{Hong Kong SAR}
}
\orcid{0000-0002-8400-3780}
\email{jhc@cse.ust.hk}

\thanks{This work was supported by the National Natural Science Foundation of China (No. 62202403), Hong Kong Innovation and Technology Commission (Project No. MHP/002/22 and ITCPD/17-9), and Research Grants Council of the Hong Kong Special Administrative Region, China (Project No. R6003-22 and C4024-22GF).}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Jin et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
Deep learning has significantly advanced medical imaging analysis (MIA), achieving state-of-the-art performance across diverse clinical tasks. However, its success largely depends on large-scale, high-quality labeled datasets, which are costly and time-consuming to obtain due to the need for expert annotation. To mitigate this limitation, label-efficient deep learning methods have emerged to improve model performance under limited supervision by leveraging labeled, unlabeled, and weakly labeled data. In this survey, we systematically review over 350 peer-reviewed studies and present a comprehensive taxonomy of label-efficient learning methods in MIA. These methods are categorized into four labeling paradigms: \textit{no label}, \textit{insufficient label}, \textit{inexact label}, and \textit{label refinement}. For each category, we analyze representative techniques across imaging modalities and clinical applications, highlighting shared methodological principles and task-specific adaptations. We also examine the growing role of health foundation models (HFMs) in enabling label-efficient learning through large-scale pre-training and transfer learning, enhancing the use of limited annotations in downstream tasks. Finally, we identify current challenges and future directions to facilitate the translation of label-efficient learning from research promise to everyday clinical care.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10002944.10011122.10002945</concept_id>
       <concept_desc>General and reference~Surveys and overviews</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010147.10010257.10010258</concept_id>
       <concept_desc>Computing methodologies~Learning paradigms</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
   <concept>
       <concept_id>10010147.10010257.10010321</concept_id>
       <concept_desc>Computing methodologies~Machine learning algorithms</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
   <concept>
       <concept_id>10010147.10010178.10010224</concept_id>
       <concept_desc>Computing methodologies~Computer vision</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{General and reference~Surveys and overviews}
\ccsdesc[300]{Computing methodologies~Learning paradigms}
\ccsdesc[300]{Computing methodologies~Machine learning algorithms}
\ccsdesc[300]{Computing methodologies~Computer vision}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Medical Image Analysis, Label-Efficient Learning, Health Foundation Model.}

\received{7 March 2025}

%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
Deep learning (DL) has revolutionized medical image analysis (MIA), significantly improving the efficiency and accuracy of disease detection, diagnosis, and treatment \cite{de2018clinically, cao2023large, vorontsov2024foundation}. By providing a data-driven framework for interpreting large and diverse medical image datasets, DL models have achieved unprecedented performance.
% transition, importance
Despite these advancements, the success of DL models remains heavily dependent on large volumes of precisely annotated data, which are costly and time-consuming to obtain due to the need for expert input \cite{yu2021convolutional}. This growing demand for annotation contrasts sharply with the limited availability of medical experts \cite{rosenkrantz2016us, lu2020national}, creating a widening gap between the increasing volume of medical images and the capacity to label them. Reducing annotation costs, accelerating annotation workflows, and alleviating the burden on annotators have thus become critical challenges in DL-based MIA.

To address the annotation bottleneck in medical imaging, researchers have proposed a variety of learning paradigms, including self-supervised, semi-supervised, weakly supervised, and active learning. These approaches are designed to handle scenarios where annotations are missing, limited, imprecise, or require refinement. By leveraging different levels of supervision, ranging from pixel-level labels to weaker forms such as points, scribbles, bounding boxes, or even unlabeled data, they provide flexibility across diverse labeling conditions. The emergence of health foundation models (HFMs) has further strengthened these strategies by pretraining on large-scale medical datasets to extract generalizable features. These features can be effectively transferred to downstream tasks such as classification, segmentation, or detection, which improves performance and reduces the need for extensive labeled data during fine-tuning \cite{he2024foundation}. In this paper, we refer to the full spectrum of these methods, both traditional and HFM-based, as \textbf{label-efficient learning}.
As illustrated in Fig. \ref{fig_class}, label-efficient learning methods have rapidly expanded in recent years. High-level tasks such as classification, segmentation, and detection remain their primary focus, while applications to low-level tasks, including denoising, image registration, and super-resolution, are also gaining momentum. This growing versatility underscores the increasing impact of label-efficient learning across the MIA pipeline, supporting its broader integration into both research and clinical workflows.

\input{Figures/fig_pipeline.tex}

Several surveys have previously addressed label-efficient learning in MIA, each offering valuable insights yet exhibiting certain limitations. Cheplygina et al. \cite{cheplygina2019not} introduced the term ``not-so-supervised'' learning and categorized methods into supervised, semi-supervised, multi-instance, and transfer learning. However, their work focused on theoretical concepts and lacked practical relevance to clinical MIA applications. Budd et al. \cite{budd2021survey} emphasized human-in-the-loop strategies, while Wang et al. \cite{wang2024comprehensive} provided a more recent survey, but covered only a subset of label-efficient methods, limiting its scope. In contrast, our taxonomy is organized around specific annotation scenarios, offering a more intuitive and application-oriented framework. Furthermore, we analyze how HFMs are reshaping traditional paradigms within each scenario, highlighting open research questions that merit future exploration, as shown in Fig. \ref{fig_class}.

To provide a comprehensive overview of label-efficient learning in MIA, we review over 350 peer-reviewed studies and categorize them into four annotation scenarios: \textit{no label}, where data lacks annotations; \textit{insufficient label}, where labeled data is limited; \textit{inexact label}, where annotations are noisy or coarse; and \textit{label refinement}, where existing labels require improvement. To the best of our knowledge, this is the first extensive review to systematically cover all four scenarios. For each, we define the core challenges, provide essential background, and examine the role of HFMs in enhancing performance. Our analysis not only synthesizes recent progress but also identifies key limitations and outlines future research directions, offering a roadmap for advancing label-efficient learning in MIA. The remainder of this paper is organized as follows. Sections \ref{sec:ssl}--\ref{sec:al} introduce the four annotation scenarios: \textit{no label} in Section \ref{sec:ssl}, \textit{insufficient label} in Section \ref{sec:semi}, \textit{inexact label} in Section \ref{sec:weakly}, and \textit{label refinement} in Section \ref{sec:al}. Section \ref{sec:cnfd} discusses current challenges and explores potential solutions and research opportunities. Finally, we conclude this survey in Section \ref{sec:con}.
\input{Sections/sec_self_sup}
\input{Sections/sec_semi_sup}
\input{Sections/sec_weakly_sup}
\input{Sections/sec_act_learn}
\input{Sections/sec_challenge_n_dirs}
\section{Conclusion}\label{sec:con}
Label-efficient learning has emerged as a pivotal direction in medical image analysis, addressing not only the practical constraints of annotation scarcity but also prompting a re-examination of the fundamental relationship between data, supervision, and clinical value. In this survey, we have introduced a unified taxonomy that spans scenarios of no label, insufficient label, inexact label, and label refinement. This framework has clarified the methodological landscape and illuminated the distinct challenges and opportunities inherent to each paradigm. Through a critical analysis of state-of-the-art methodologies, we have highlighted both recent advances and the persistent barriers to clinical adoption. Our synthesis demonstrates that genuine progress in label efficiency requires not only algorithmic innovation but also coordinated advances in large-scale data curation, adaptive learning strategies, and standardized evaluation. As the field moves toward broader clinical integration, the challenges of generalization, interoperability, and meaningful assessment remain central. By clarifying these issues and outlining future directions, this survey aims to serve as both a reference and a foundation for the continued evolution of label-efficient learning in medical imaging.

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{reference}


%%
%% If your work has an appendix, this is the place to put it.
\appendix
\newpage
\noindent\Large{\textbf{Appendix}}
\section{Survey Scope}
\label{appendix1}
To ensure comprehensive coverage of relevant literature, we conducted a systematic search using Google Scholar for publications related to label-efficient medical imaging up to March 2025. Additionally, we queried the arXiv preprint server for manuscripts containing key terms pertinent to label-efficient learning in medical imaging. Major conference proceedings—including CVPR, ICCV, ECCV, NeurIPS, AAAI, and MICCAI—as well as leading journals such as Medical Image Analysis (MIA), IEEE Transactions on Medical Imaging (TMI), and Nature Biomedical Engineering, were thoroughly reviewed based on paper titles and abstracts. Furthermore, the reference lists of selected papers were examined to identify additional relevant works. In cases where similar work appeared in multiple venues, only the most impactful or comprehensive publication(s) were included in this survey.

\clearpage

\section{Surveyed Literature and Datasets}

\subsection{Surveyed Literature}
\input{Sections/Tables/tab_self_sup_v2.tex}
\input{Sections/Tables/tab_semi_sup_v2.tex}
\input{Sections/Tables/tab_multi_ins_v2.tex}
\input{Sections/Tables/tab_anno_effi_v2.tex}
\input{Sections/Tables/tab_al_v2.tex}

\clearpage

\subsection{Datasets}
\input{Sections/Appendix/dataset_1.tex}

\input{Sections/Appendix/dataset_2.tex}

\input{Sections/Appendix/dataset_3.tex}

\input{Sections/Appendix/dataset_4.tex}

\input{Sections/Appendix/dataset_5.tex}
\end{document}
\endinput
%%
%% End of file `sample-manuscript.tex'.
