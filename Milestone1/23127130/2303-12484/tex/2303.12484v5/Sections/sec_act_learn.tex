\section{Label Refinement} \label{sec:al}

The \textit{label refinement} scenario arises when existing annotations are limited or suboptimal, often due to annotation costs and expert scarcity in MIA. \textbf{Active learning (AL)} has emerged as a primary solution by prioritizing expert annotation on the most informative samples. Unlike prior paradigms that passively exploit available labels, AL actively involves human experts to iteratively improve data quality. Typically, AL starts with a model trained on a small, initially labeled dataset and, in each cycle, ranks the remaining unlabeled or weakly labeled samples by informativeness for expert review. The model is then retrained with the refined labels, and this process repeats until the desired performance or annotation budget is reached.

Informative sampling is central to AL for label refinement, as its effectiveness relies on selecting samples whose refined labels most benefit the model. Accordingly, AL methods are typically classified by their \textbf{informativeness evaluation} criteria, such as uncertainty- or representativeness-based, and \textbf{sampling strategies} for efficient querying. Appendix Table~\ref{tab:al} summarizes representative methods. The following subsections detail these criteria and strategies.

\input{Figures/fig_al_schematic}

\subsection{Informativeness Evaluation}

Informativeness evaluation is fundamental to active learning, guiding the selection of unlabeled samples that are most beneficial for model improvement. Existing methods primarily fall into two categories: uncertainty-based and representativeness-based strategies.

Uncertainty-based methods select samples where the model is least confident, employing measures such as entropy, margin, or Bayesian uncertainty~\cite{yang2017suggestive, chen2016dcan}. These techniques have evolved to incorporate feature-space similarity and loss prediction networks, especially in structured tasks like segmentation, where metrics such as the Dice coefficient are used to estimate sample informativeness~\cite{zhao2021dsal, wu2021covid}. Recent advances further enhance robustness by integrating gradient-based uncertainty and out-of-distribution detection~\cite{hu2023learning, schmidt2024focused}.

Representativeness-based approaches aim to ensure that selected samples capture the diversity of the data distribution. Clustering, curriculum learning, and latent space distance metrics have been widely adopted for this purpose~\cite{li2021pathal, guo2018curriculumnet}. In medical imaging, where class imbalance and label noise are common, mechanisms such as automatic exclusion of noisy samples and task-specific loss functions are often incorporated~\cite{huang2019o2u, liu2017stein}.

A growing body of work seeks to unify these perspectives through hybrid criteria that combine uncertainty, representativeness, and other informativeness signals~\cite{qu2023openal, mahapatra2024gandalf, li2023hal}. Such methods leverage, for example, Mahalanobis distance, graph-based propagation, or divergence-based measures to improve sample selection efficiency and model robustness ~\cite{tang2023pld, atzeni2022deep}. In summary, informativeness evaluation in AL has thus evolved from simple uncertainty heuristics to hybrid strategies that jointly consider uncertainty, representativeness, and deep feature representations, significantly improving annotation efficiency and model robustness.

\subsection{Sampling Strategy}
Once informativeness has been assessed, the next challenge lies in designing effective sampling strategies that maximize annotation efficiency, particularly when labeling resources are limited.

A straightforward approach is top-$k$ selection, where samples with the highest informativeness scores are prioritized. However, this can lead to redundancy, as similar samples may be repeatedly chosen~\cite{zhou2021active}. To overcome this, many later strategies integrate additional criteria such as diversity and representativeness into the selection process~\cite{ozdemir2021active, zhao2017infovae}. By jointly considering these factors, hybrid methods aim to ensure that selected samples are both informative and broadly representative of the underlying data distribution—a consideration especially important in domains characterized by data heterogeneity or class imbalance.

To further enhance the sampling process, some approaches incorporate data augmentation or generative models, increasing the diversity of candidate samples and reducing annotation redundancy~\cite{mahapatra2018efficient}. Optimization-based formulations have also been proposed, dynamically balancing uncertainty, consistency, and diversity during selection~\cite{li2023hal, qu2023openal}. Other strategies leverage feature-space metrics, clustering, or graph-based algorithms to maximize coverage and minimize overlap among selected samples~\cite{bai2023slpt, mahapatra2024gandalf, mahapatra2024alfredo}.

Overall, effective sampling strategies in active learning seek to maximize annotation value by balancing informativeness, diversity, and representativeness~\cite{schmidt2024focused, wang2024dual, tang2023pld}. These principles have been shown to improve label efficiency and model robustness, particularly in complex and data-rich applications.

\subsection{Discussion}
Active learning addresses label scarcity in medical imaging by iteratively selecting the most informative samples for expert annotation, a process shaped by the interplay between informativeness evaluation and sampling strategy. Early in the annotation process, model performance is largely determined by how well informativeness is quantified, with advanced criteria offering clear gains over naive uncertainty measures~\cite{wang2024comprehensive}. As the labeled set expands, redundancy emerges as the main bottleneck, making sophisticated sampling strategies increasingly important \cite{follmer2024active}.

The rise of HFMs, particularly multi-modal architectures such as MedSAM \cite{ma2024segment} is fundamentally reshaping AL by providing rich, transferable representations that enhance both informativeness evaluation and sampling efficiency~\cite{gupte2024revisiting}. HFMs enable dynamic adjustment of an image’s uncertainty profile through textual or visual prompts, allowing rare or long-tail cases to be surfaced that traditional approaches may overlook. However, confidence estimates from HFMs often require careful calibration, especially for atypical cases ~\cite{gupte2024revisiting}. Future frameworks should therefore jointly optimize prompt design and sample selection with careful calibration of model confidence, leveraging the capabilities of HFMs to achieve more efficient and clinically relevant annotation.

