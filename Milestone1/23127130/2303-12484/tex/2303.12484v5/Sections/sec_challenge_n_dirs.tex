\section{Challenges and Future Directions} \label{sec:cnfd}
\input{Figures/fig_future}
While the previous sections have reviewed various label-efficient learning paradigms designed for MIA, notable challenges still impede their translation from research to clinical practice. Addressing these barriers is vital for realizing the full potential of these methods in real-world healthcare settings. In the following, we summarize the main challenges and discuss promising future directions.

\subsection{Health Foundation Models}
The diversity and complexity of MIA tasks, coupled with persistent labeled data scarcity, have historically limited the scalability and clinical translation of label-efficient algorithms. Recent advances in HFMs have shifted this paradigm by introducing highly generalizable representations pretrained on heterogeneous medical image datasets~\cite{he2024foundation, chen2024towards, wu2024voco, xiang2025vision}. This extensive and diverse pretraining enables HFMs to capture rich, transferable visual features, thereby substantially reducing the volume of annotated data and expert time required for downstream applications. As a result, HFMs facilitate rapid adaptation to tasks such as classification, segmentation, detection, and report generation, often achieving strong performance with minimal supervision~\cite{ma2024segment, zhang2025multimodal}. Collectively, these developments position HFMs as a foundational technology in the field, delivering significant improvements in annotation efficiency, generalizability, and clinical applicability for label-efficient MIA. Despite these advances, however, the reliance of HFMs on downstream fine-tuning with task-specific labeled data remains a fundamental limitation, as truly label-efficient or label-free learning has yet to be fully realized. These technical limitations are further compounded by broader issues, such as the scalable and ethical curation of large-scale medical datasets, the mitigation of biases arising from data heterogeneity, and the integration of cross-modal and longitudinal data sources—such as genomics profile, electronic health records, and pathology whole-slide images. Furthermore, ensuring that HFMs are aligned with clinical safety standards and are sufficiently interpretable is essential for their reliable deployment in real-world healthcare settings. Addressing these challenges is critical for HFMs to progress from large-scale models to foundational infrastructure supporting the future of label-efficient MIA.

\subsection{Human-in-the-loop Interaction}

The introduction of HFMs pretrained on large-scale medical data has facilitated more efficient human-in-the-loop (HITL) collaboration in medical image analysis, particularly for reducing expert annotation costs. While AL focuses on selecting informative samples for annotation during training, HITL strategies such as interactive segmentation incorporate real-time expert feedback at inference. Beyond technical benefits, recent studies highlight that effective HITL in medical AI requires supporting meaningful human control and co-reasoning, integrating ethical and practical judgment from both clinicians and patients into the decision-making process \cite{salloch2024humans, marinov2024deep}. Meanwhile, in the broader machine learning community, there has been substantial progress in label-efficient HITL paradigms, including adaptive querying, scalable annotation platforms, and uncertainty-aware feedback mechanisms, with recent frameworks demonstrating that verification of auto-suggested labels can be 3–4 times faster than manual labeling and improve overall efficiency by 1.5–2 times \cite{beck2024beyond, feng2025duo}. However, these advances are still underexplored in MIA, where annotation costs, privacy, and workflow integration pose unique challenges. Bridging these advances, future research should focus on adapting state-of-the-art HITL strategies to the medical domain by leveraging foundation models for automated pre-annotation, developing intuitive and privacy-preserving expert collaboration interfaces, and embedding interactive feedback into clinical workflows \cite{huang2025pathologist}. Such efforts can further reduce annotation effort, enhance model robustness, and accelerate the safe and effective deployment of AI in clinical settings.

\subsection{Generative Data Augmentation}
With robust annotation pipelines established through human-in-the-loop interaction, the next step is to address the long-tail of medical imaging datasets by synthesizing rare or underrepresented cases. Synthetic data generated by advanced models has proven effective for enhancing diversity and improving performance in vision tasks \cite{goceri2023medical}. Although early GAN-based methods suffer from instability and limited diversity \cite{lin2022insmix}, current research increasingly adopts two main architectures that offer higher fidelity, broader mode coverage, and more stable optimization. Diffusion models \cite{ho2020denoising} have demonstrated clear benefits in label‑efficient multi‑organ CT segmentation \cite{wang2024textguideddiff}, weakly‑supervised medical image segmentation \cite{xu2023conditional} and brain MRI label rectification \cite{li2024diffrect}, where they deliver 2-5\% gains in Dice or accuracy under limited annotation budgets. Meanwhile, MaskGIT-style transformers enable rapid, class-conditioned synthesis and achieve strong results with far less labeled data \cite{liu2024maskgitmed}. Despite these advances, several key challenges remain. First, it is critical to devise principled strategies for balancing real and synthetic samples to prevent overfitting to model-generated artifacts. Second, scaling generative augmentation to high-resolution modalities such as WSI presents significant computational and architectural hurdles. Third, integrating expert-driven, text- or report-level conditioning remains an open problem for enabling controllable and clinically meaningful data synthesis. Addressing these challenges will be essential for establishing generative augmentation as a robust and foundational component of future label-efficient MIA pipelines.
%The expressive priors encoded by HFMs facilitate high-fidelity generative data augmentation. By leveraging pretrained decoders, these models can synthesize anatomically coherent and clinically plausible rare cases, thereby enhancing model robustness in the face of data imbalance and sparsity.

\subsection{Federated Label-efficient Learning} 

As the scale of medical imaging data continues to grow, privacy concerns and the need for cross-institutional collaboration rapidly emerge as critical bottlenecks. \textbf{Federated learning (FL)} provides an effective framework to address these challenges by enabling collaborative model training across institutions without sharing raw data, thereby safeguarding patient privacy. More importantly, FL facilitates label-efficient learning by allowing institutions to maximize the utility of their limited labeled data in a distributed setting \cite{rieke2020future}. This approach has yielded fruitful results in The field of MIA \cite{li2020multi,dayan2021federated,lu2022federated}. However, current FL algorithms are primarily trained in a supervised manner. When applying the FL to real-world scenarios in MIA, a crucial problem, namely, label deficiency, may appear in local health datasets. Labels may be missing to varying degrees between medical centers, or the granularity of the labels will vary. Therefore, designing label-efficient federated learning methods to address this significant problem is an important research direction. For example, incorporating informative sampling strategies from active learning \cite{chen2024think, wu2024feda3i} into FL frameworks shows great potential for improving label efficiency in this setting. Nonetheless, FL faces unique challenges such as communication delays and efficiency; while recent works explore communication-efficient strategies \cite{yan2025fedvck}, future research should investigate approaches such as adapters or low-rank updates, which can be communicated across institutions to jointly optimize both label efficiency and communication efficiency.

\subsection{Generalization Across Domains and Datasets}
While recent advances in label-efficient MIA have reduced annotation requirements, the central challenge remains ensuring robust and reliable clinical deployment across diverse environments. Even HFMs can suffer significant performance drops when deployed on previously unseen scanners, imaging protocols, or patient populations \cite{he2024foundation}. This vulnerability is largely due to hardware heterogeneity, acquisition variability, and demographic differences, which constrain the transferability of models trained on limited or homogeneous datasets \cite{yoon2024domain}. To address this, \textbf{domain generalization (DG)} must become a central design objective for future label-efficient MIA systems. Recent research focuses on systematically identifying and mitigating domain biases that persist after large-scale pre-training, with growing emphasis on adaptive model recalibration ~\cite{zu2024embedded, chen2024each, jiang2025generalizable}. These advances collectively aim to ensure that models retain reliability and generalizability under label efficiency, which is essential for clinically robust and globally deployable MIA solutions.

\subsection{Benchmark Establishment and Comparison}
As the preceding sections have systematically reviewed the main challenges and promising directions in label-efficient MIA, their practical value, however, remains difficult to assess due to the lack of standardized and rigorous evaluation. The current landscape is highly fragmented, with studies differing in tasks, target organs, annotation budgets, protocols, and data partitioning \cite{bassi2024touchstone}. Privacy constraints further restrict access to large and diverse datasets, limiting evaluation to single-center cohorts with non-standardized splits \cite{jin2024fairmedfm}.  As a result, published results seldom reveal which method achieves the best accuracy per annotation cost in realistic clinical scenarios. Overcoming these limitations requires a new benchmarking infrastructure with curated multi-task datasets, fixed label budgets, cost-aware metrics for annotation and computational efficiency, and standardized protocols for human-in-the-loop evaluation. Federated benchmarking, where the code runs securely within each institution, can enable privacy-preserving comparison among multiple centers. Continuous, blinded leaderboards are also crucial for reproducibility and bias detection. Establishing a unified, community-driven benchmarking framework with these features is essential for objective model comparison and for translating methodological advances into reliable, clinically deployable systems.


 
