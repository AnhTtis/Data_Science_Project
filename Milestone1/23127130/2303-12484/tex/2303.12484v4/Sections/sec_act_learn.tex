\section{Active Learning in MIA} \label{sec:al}
\begin{table*}[ht]
\centering
\caption{Overview of Active Learning-based Studies in Medical Image Analysis}

\resizebox{\textwidth}{.13\textwidth}{
\begin{threeparttable}
\begin{tabular}{@{}llllll@{}}
\toprule
 &Reference (Year) & Organ & Sampling Method & Dataset & Result \\ \midrule
\rule{0pt}{2ex} \multirow{1}{*}{\rotatebox{90}{Classification}}&  
%Gal \textit{et al.} 
\citet{gal2017deep} &  Skin  & BALD + KL-divergence  &  ISIC 2016 & 22\%  image input: AUC: 0.75\rule[-1.5ex]{0pt}{0pt}\\ 
\cline{2-6}
\rule{0pt}{2.5ex}& 
%Wu \textit{et al.} 
\citet{wu2021covid} &  Lung  & Loss Prediction Network  & CC-CCII Dataset & 42\% Chest X-Ray input: Acc: 86.6\%\rule[-1.5ex]{0pt}{0pt}\\ 
\cline{2-6}
\rule{0pt}{3ex}&
%Li \textit{et al.} 
\citet{li2021pathal}  &  Prostate  & CurriculumNet + O2U-Net  &  ISIC 2017; PANDA Dataset & 60\% input: QWK: 0.895\rule[-3.5ex]{0pt}{0pt}\\
\hline
\rule{0pt}{2.5ex} \multirow{8}{*}{\rotatebox{90}{Segmentation}}&
%Yang \textit{et al.} 
\citet{yang2017suggestive} & Gland; Lymph  & Cosine Similarity + Bootstrapping + FCN& GlaS 2015; Private Dataset: 80 US images & MICCAI 2015: 50\% input: F1: 0.921; Private Dataset: 50\% input: F1: 0.871\rule[-1.5ex]{0pt}{0pt}\\ 
\cline{2-6}
\rule{0pt}{2.5ex}&    
%Konyushkova \textit{et al.}
\citet{konyushkova2019geometry}& Brain (Striatum; Hippocampus)  &    Geometric Priors + Boosted Trees  &  BraTS 2012; EFPL EM Dataset & MRI Data: 60\% input: DSC$\approx$0.76;  EM Data: 40\% input: DSC$\approx$0.60 \rule[-1.5ex]{0pt}{0pt} \\
\cline{2-6}
\rule{0pt}{2.5ex} &    
%Nath \textit{et al.} 
\citet{nath2020diminishing} &  Brain  & Entropy + SVGD Optimization  &  MSD 2018 Dataset & 22.69\% Hippocampus MRI input: DSC: 0.7241 \rule[-1.5ex]{0pt}{0pt}\\
\cline{2-6}
\rule{0pt}{2.5ex}& 
%Ozdemir \textit{et al.} 
\citet{ozdemir2021active}  & Shoulder & BNN +  MMD Divergence & Private Dataset: 36 Volume of MRIs & 48\% MRI input: DSC$\approx$0.85 \rule[-2ex]{0pt}{0pt}\\
\cline{2-6}
\rule{0pt}{2.5ex}& 
%Zhao \textit{et al.} 
\citet{zhao2021dsal} &  Hand; Skin  & U-Net  & RSNA-Bone; ISIC 2017 & 9 AL Iteration: DSC: 0.834 \rule[-1.5ex]{0pt}{0pt}\\
\hline
\rule{0pt}{2.5ex} \multirow{5}{*}{\rotatebox{90}{Others}} & \multirow{2}{*}{\citet{mahapatra2018efficient}$_{\text{CS}}$} %Mahapatra \textit{et al.}
&  Chest  & Bayesian Neural Network + & JSRT Database;& Classification: 35\% input: AUC: 0.953;\\ 
& && cGAN Data Augmentation & ChestX-ray8 & Segmentation: 35\% input: DSC: 0.910\rule[-1.5ex]{0pt}{0pt}\\
\cline{2-6}
\rule{0pt}{2.5ex}& \multirow{2}{*}{
%Zhou \textit{et al.}
\citet{zhou2021active}$_{\text{CD}}$} & 
Colon & Traditional Data Augmentation& Private Dataset: 6 colonoscopy videos & Classification: 4\% input: AUC: 0.9204;\\
& &&Entropy + Diversity & 38 polyp videos + 121 CTPA datasets & Detection: 2.04\% input: AUC: 0.9615\rule[-1.5ex]{0pt}{0pt}\\
\bottomrule
\end{tabular}
\begin{tablenotes}    
        \footnotesize               
        \item[1] For the sake of brevity, we denote references that contain more than one task in the following abbreviations: \textbf{C}: Classification, \textbf{S}: Segmentation, \textbf{D}: Detection. 
      \end{tablenotes}
\end{threeparttable}
}
\label{tab:al}
\end{table*}
\subsection{Data Uncertainty-Based Methods}
Developed from the conventional entropy uncertainty metrics\footnote{To aid the understanding of these metrics, a detailed description of the prior knowledge is provided in Appendix A.2.}, 
%Konyushkova \textit{et al.} 
\citet{konyushkova2019geometry} defined geometric smoothness priors with boosted trees to classify the formed graph representation of electron microscopy images. Here, they flatten 3D images into supervoxels with the SLIC algorithm \citep{achanta2012slic} to conduct graph representations. 
%Yang \textit{et al.} 
\citet{yang2017suggestive} use cosine similarity and a bootstrapping technique to evaluate the uncertainty and representativeness of the output feature with a DCAN \citep{chen2016dcan}-like network.
%Zhou \textit{et al.} 
\citet{zhou2021active} propose the concept of ``active selection" policies, which is the highest confidence based on the entropy and diversity results from sampled data in the mean prediction results. 

Aside from leveraging conventional metrics, utilizing metrics from the deep learning model is another trend. Intuitively, 
%Wu \textit{et al.} 
\citet{wu2021covid} utilize network loss as well as the diversity condition as the uncertainty metric for sampling from a loss prediction network, and conduct the COVID-19 classification task from another classification network. 
%Nath \textit{et al.} 
\citet{nath2020diminishing} leverage marginal probabilities between the query images and the labeled ones, they build a mutual information metric as the diversity metric to serve as a regularizer. Moreover, they adopt Dice log-likelihood instead of its original entropy-based log-likelihood for Stein variational gradient descent optimizer \citep{liu2017stein} to solve the label imbalance problem. 
%Zhao \textit{et al.} 
\citet{zhao2021dsal} utilize Dice's coefficient of the predicted mask calculated between the middle layer and the final layer of the model as the uncertainty metric for the image segmentation task. They use their DS-UNet with a denseCRF \citep{krahenbuhl2011efficient} refiner to annotate low uncertainty samples and oracle annotators for the others. 
%Li \textit{et al.} 
\citet{li2021pathal} use k-means clustering and curriculum classification (CC) based on the CurriculumNet \citep{guo2018curriculumnet} for uncertainty and representativeness estimation. Furthermore, they consider the condition under which noisy medical labels are present and accomplish their automatic exclusion using O2U-Net \citep{huang2019o2u}.  
\subsection{Model Uncertainty-Based Methods}
Bayesian neural networks have attracted increasing attention for their ability to represent and propagate the probability of the DL model. 
%Gal \textit{et al.} 
\citet{gal2017deep} employ Bayesian CNNs for skin cancer classification with Bayesian active learning by disagreement (BALD) \citep{houlsby2011bayesian}.
%Ozdemir \textit{et al.} 
\citet{ozdemir2021active} form a Bayesian network and employ Monte Carlo dropout \citep{gal2016dropout} to obtain the variance information as the model uncertainty. They also construct a representativeness metric produced by infoVAE \citep{zhao2017infovae} for maximum likelihood sampling in the latent space. 
%Mahapatra \textit{et al.} 
\citet{mahapatra2018efficient} also uses a Bayesian neural network to sample the training data. Meanwhile, they use conditional GAN to generate realistic medical images for data augmentation.
\subsection{Discussion}
Whether from the data or from the model, uncertainty measurement is a critical task throughout the whole AL process. The current research directions regarding label-efficient AL methods in MIA focus primarily on the improvement of AL query strategies and the optimization of training methods. For the future, researchers could i) delve into hybrid AL query strategies together with diversity assessment, ii) concentrate on hybrid training schemes (\textit{i.e.}, combined Semi-SL, Self-SL schemes) to yield an intermediate feature representation to further guide the training process, iii) mitigate the degradation of annotation quality when encountering noisy labels.