\section{Few-Shot Learning in MIA} \label{sec:fsl}

\begin{table*}[ht]
\centering
\caption{Overview of Few-Shot Learning-based studies in Medical Image Analysis}
\resizebox{\textwidth}{.22\textwidth}{
\begin{threeparttable}
\begin{tabular}{@{}llllll@{}}
\toprule
&Reference (Year) & Organ & Prior Knowledge Source & Dataset & Result \\ \midrule
\multirow{12}{*}{\rotatebox{90}{Classification}}& 
%Medela \textit{et al.} 
\citet{medela2019few} & Colon; Breast; & Siamese Network & \citep{kather2016multi}; Private Dataset & 15-shot Balanced Acc$\approx$93\%\\
&& Lung &&\rule[-1ex]{0pt}{0pt}\\
\cline{2-6}
% \rule{0pt}{2.5ex}&Quellec \textit{et al.} \cite{quellec2020automatic}$_{2020}$  &  Retina   &   CNN + Probabilistic Model &  OPHDIAT Dataset \cite{decenciere2013teleophta}\rule[-1ex]{0pt}{0pt}\\
% \cline{2-6}
% \rule{0pt}{2.5ex}&Mahajan \textit{et al.} \cite{mahajan2020meta}$_{2020}$ & Skin & Reptile; Prototype Network & ISIC 2018, Derm7pt Dataset \cite{Kawahara2018-7pt}; \\
% &&&& SD-198 Dataset \cite{sun2016benchmark}\\
%\cline{2-6}
\rule{0pt}{2.5ex}&
%Chao \textit{et al.} 
\citet{chao2021generalizing} & Liver; Kidney & MAML & TGCA Dataset & 8-shot AUC: 0.6944\\
&& Colon; Breast && \rule[-1ex]{0pt}{0pt}\\
\cline{2-6}
\rule{0pt}{2.5ex}&
%Singh \textit{et al.} 
\citet{singh2021metamed} & Breast; Skin & Reptile & BreakHis dataset \citep{spanhol2015dataset}; ISIC 2018 & BreakHis (with CutMix): 10-shot Acc: 0.8612; \\
&&&&& ISIC 2018 (with MixUp): 10-shot Acc: 0.8425 \rule[-1ex]{0pt}{0pt}\\
\cline{2-6}
\rule{0pt}{2.5ex}&
%Deusche \textit{et al.} 
\citet{deuschel2021multi} & Colon & Prototype Network & Private Dataset: 356 Annotated WSIs & 20-shot (with data augmentation):\\
&&&&&  Acc: 0.489; F1 Score: 0.728\rule[-1ex]{0pt}{0pt}\\
\cline{2-6}
\rule{0pt}{2.5ex}&
%Tang \textit{et al.} 
\citet{tang2021recurrent} & Brain &  Prototype Network & ABD-110 Dataset \citep{tang2021spatial}; ABD-30 Dataset \citep{landman2015miccai} & ADB-110: One-shot Dice Score: 0.8191\\ %Segmentation
&&&& ABD-MR Dataset \citep{kavur2021chaos} & ABD-30 One-shot: Dice Score: 0.7248\\
&&&&& ABD-MR One-shot: Dice Score: 0.7926\rule[-1ex]{0pt}{0pt}\\
\hline
\multirow{15}{*}{\rotatebox{90}{Segmentation}} & 
%Cui \textit{et al.} 
\citet{cui2020unified}     &   Brain; Liver   &  Prototype Network  &  MRBrainS18;  & MRBrainS18: Three-shot Dice Score: 0.8198  \\ %Segmentation
&&&&BTCV Abdomen Dataset \citep{gibson2018multi} & BTCV: One-shot Dice Score: 0.6913 \rule[-1ex]{0pt}{0pt}\\
\cline{2-6}
\rule{0pt}{2.5ex}&
%Roy \textit{et al.} 
\citet{roy2020squeeze}& Liver; Spleen; & U-Net + & VISCERAL Dataset \citep{jimenez2016cloud}& One-shot: Dice Score: 0.485; ASD: 10.48\\
&& Kidney; Psoas & Channel Squeeze-and-Excitation Blocks & &\rule[-1ex]{0pt}{0pt}\\
\cline{2-6}
\rule{0pt}{2.5ex}&
%Khandelwal \textit{et al.} 
\citet{khandelwal2020domain}  & Spine; Vertebrae & Meta-Learning Domain Generalization & MICCAI 2014; xVertSeg Dataset \citep{korez2015framework}; & 5-shot Dice Score: 0.8052\\
&&&& Versatile Dataset \citep{sekuboyina2021verse} \rule[-1ex]{0pt}{0pt}\\
\cline{2-6}
\rule{0pt}{2.5ex}&
%Wang \textit{et al.} 
\citet{wang2021alternative}         &  Spleen; Kidney; Liver;   &  Siamese Network  & CANDI Dataset \citep{kennedy2012candishare}; Multi-organ Dataset & 4-shot: Dice Score: 0.890; Jaccard: 0.804\\ %Segmentation
&& Stomach; Pancreas; && \citep{gibson2018automatic, roth2015deeporgan, clark2013cancer,xu2016evaluation}\\
&&  Duodenum; Esophagus &&  \rule[-1ex]{0pt}{0pt}\\
\cline{2-6}
\rule{0pt}{2.5ex}&
%Yu \textit{et al.} 
\citet{yu2021location}$_{}$         &  Liver; Spleen;   &    Prototype Network  &  VISCERAL Dataset \citep{jimenez2016cloud}& One-Shot Dice Score: 0.703\\
&& Kidney; Psoas && \rule[-1ex]{0pt}{0pt}\\ %   Segmentation
\cline{2-6}
\rule{0pt}{2.5ex}&
%Guo \textit{et al.}
\citet{guo2021multi} & Heart & Multi-level Semantic Adaptation &  MICCAI 2018; Private Dataset: 3,000 & 5-shot: Dice Score: 0.9564; IoU: 0.9185\\
&&&& CT Images and 13,500 Echo Images  \rule[-1ex]{0pt}{0pt}\\
\hline
\multirow{-1}{*}{\rotatebox{90}{Others}}&\multirow{2}{*}{\citet{he2021few}$_{\text{R}}$}   & Heart; Vertebrae & Perception CNN &  MM-WHS 2017 \citep{zhuang2016multi};& 10-shot: Dice Score: 0.867; ASD: 0.41 \rule[-1ex]{0pt}{0pt}\\
&&&&LBPA40 Dataset \citep{gibson158whyntie}\\
% &&&& REFUGE Dataset \cite{orlando2020refuge}; RIM-One Dataset \cite{fumero2011rim}\\
% Lu \textit{et al.} \cite{lu2022transfer}   &  Segmentation  &  Brain   &   Transfer Learning &  HCP Dataset \cite{van2013wu}; Private Dataset    \\
% Mai \textit{et al.} \cite{mai2021few} & Classification & Retina & Transfer Learning & Cell Dataset \cite{kermany2018labeled}; BOE Dataset \cite{srinivasan2014fully}\\
% Paul \textit{et al.} \cite{paul2021discriminative}          &    Classification  &  Chest   &  Ensenble Learning &  NIH Dataset \cite{wang2017chestx}\\ 
\bottomrule
\end{tabular}
\begin{tablenotes}    
        \footnotesize               
        \item[1] For the sake of brevity, we denote references in Others class in the following abbreviations: \textbf{R}: Registration. 
      \end{tablenotes}
\end{threeparttable}
}
\end{table*}

\subsection{Metric-Based Methods}
Due to the high-dimensionality of input images, it is natural to design feature extractor specifically targets at the sparse data to obtain better embedding for the inputs.
\citet{roy2020squeeze} utilized their channel squeeze \& spatial excitation (sSE) Blocks \citep{roy2018concurrent} to import the feature extracted by U-Net-like architecture from the support set. In addition, they offer an effective technique for volumetric segmentation by optimally matching a small number of support volume slices with all query volume slices. Multi-scale information is another source for extracting feature for FSL. \citet{guo2021multi} proposed their multi-level semantic adaption (MSA) mechanism that can self-adaptively handle sequence-level, frame-level and pixel-level features, thus the MSA can process the hierarchical attention metric. Particularly, they utilize LSTMs to consider the temporal correlation among each frame of the sequence data. 

%denoted as a function $g: \mathbb{R}^{m} \rightarrow \mathbb{R}^{n}, m>n$. 
%Consequently, the idea behind metric-based FSL methods is to either learn the embedding function $g$ under the conventional distance function $d$ or to learn both the embedding function $g$ and the distance function $d$ parameterized by neural networks. 

%The key to designing a metric-based method is to distinguish the difference between the query sample and the support sample. 
Exploiting existing metric-learning architectures targeting general FSL tasks is another common approach in this subfield. %As Fig. \ref{fig_prototype} illustrates, 
prototype networks \citep{snell2017prototypical}  computes prototype representations for each base class by averaging the feature vectors. They then measure the distances between these prototype representations and each query image.
\citet{deuschel2021multi} broadened the prototypes into a latent space and designed a COREL loss to discriminate the prototypes and features. \citet{tang2021recurrent} utilized a recurrent mask fashion to progressively learn the correlations between mask and features, and incorporated PANet \citep{wang2019panet}, an extended version of the Prototype Networks for few-shot medical image segmentation. \citet{cui2020unified} discovers a multi-modal mixed prototype for each category and makes dense predictions based on cosine distances between the deep embeddings of the pixels and the category prototypes. %Their multi-modal representations make excellent use of inter-subject similarities and intra-class variances to prevent overfitting caused by very little data. In the segmentation experiments on brain MRI and abdominal CT datasets, the proposed framework outperforms standard 3D U-Net \cite{cciccek20163d} and classical registration-based ANTs \cite{avants2011reproducible} methods for few-shot segmentation. 
\citet{yu2021location} present a location-sensitive local prototype network that exploits spatial priors to perform few-shot medical image segmentation. The method reduces the challenging problem of segmenting the entire image into easily solvable sub-problems of segmenting particular regions using local grid information. %For organ segmentation studies on the VISCERAL CT image dataset, their method utilize 85 CT scans and outperforms the state-of-the-art techniques by a mean Dice coefficient of 10\%.  

%\input{Figures/fig_siamese}
Other than prototype networks, siamese networks \citep{koch2015siamese} 
%are illustrated in Fig. \ref{fig_siamese} 
are another type of prior feature extraction method for FSL. In this architecture, two identical subnetworks, that share the same architecture and weights. Each subnetwork takes one input from a pair and independently processes it. The outputs of the subnetworks are then combined, usually through a similarity metric, to determine the similarity or dissimilarity of the input pair. \citet{medela2019few} incorporates a siamese network with a pre-trained VGG16 \citep{simonyan2014very} backbone with triplet loss to classify tumor types. \citet{wang2021alternative} exploit anatomical similarities to actively learn dense correspondences between the support and query images. The core principles are inspired by the traditional practice of multi-atlas segmentation, in which registration, label propagation, and label fusion, are combined into a single framework in their work. %The provided two baselines, named Siamese-Baseline and the Individual Difference-Aware Baseline are targeted at different morphological structure, where the former is aimed for anatomically stable structures while the latter is for organs with huge morphological variances. %In conclusion, their study establishes a baseline for few-shot 3D medical picture segmentation and its performance are close to the supervised U-Net upper bounds.


\subsection{Meta-Based Methods}

% In the framework of meta-learning, the methods can be distinguished from the formulation of the meta-learner in two sub-categories: Metric-Based Strategies and Gradient-Based Strategies.

% \subsubsection{Gradient-Based Strategics}
%Meta-learning methods typically employ a meta-training approach, where they train a model on a sequence of few-shot tasks derived from the base classes during the training phase. The objective is to equip the pre-trained model with the capability to quickly adapt to entirely new tasks during the testing phase.
%Training on limited data from scratch using vanilla gradient backward propagation to optimize the model would lead an unsatisfactory result due to the limited generalization capability of the model. Aside from obtaining prior knowledge from the samples, targeting at optimization process is another thinking path to improve the performance. Gradient-Based Methods tend to develop the gradient descend approach in order to achieve better generalization performance. %It is worth to point out that the gradient-based strategics do not depend on the architecture of the neural network, as they are targeting at the update process and may apply to any framework.

Most of the advancements in meta-based algorithms are focused on gradient update policy. \citet{khandelwal2020domain} adapted meta-learning domain generalization (MLDG) \citep{li2018learning} method to minimize the loss on the meta-training domains. Based on the 3D-UNet architecture, their hand-crafted gradient update policy aims to integrate the knowledge from the meta-training phase into the meta-testing stage and is stated as: $\theta \longleftarrow \theta-\gamma \frac{\partial\left(F(\hat{S} ; \theta)+\beta G\left(\bar{S} ; \theta-\alpha \nabla_{\theta}\right)\right)}{\partial \theta}$, where $\hat{S}$ denotes the meta-training data, $\overline{S}$ denotes the meta-testing data, $F, G$ denote two losses from meta-training phase as well as meta-testing phase respectively, $\theta$ denotes the network parameters, and $\alpha, \beta, \gamma$ denote the learning rate-like hyper parameters. The modification brings accurate and generalized few-shot segmentation outcomes in three datasets by up to 10\% Dice score improvement compared to the human oracle. 

%\input{Figures/fig_maml}
\citet{chao2021generalizing} integrated the well-known model-agnostic meta-learning (MAML) \citep{finn2017model} into the classification task, which can fast adapt over insufficient samples. The framework iteratively samples a large number of meta-training tasks from the support set to obtain a strong enough generalization ability, so that when faced with a new task, it can be fitted quickly. %As Fig. \ref{fig_maml} denotes, 
The framework generally contains two loops: One is the outer loop that updates the parameters of the whole framework using the gradient information from the inner loop. In the inner loop, it samples the tasks from the support set, tests them in the query set, and updates the parameters individually. The parameter update policy is as: $\theta \leftarrow \theta-\eta \nabla_{\theta} \sum_{\mathcal{Z}_{i} \sim p(\mathcal{Z})}\left(\mathcal{L}_{\mathcal{Z}_{i}}\left(f_{\theta^{\prime}}\right)\right)$,
where $f$ denotes the ResNet18 \citep{he2016deep} backbone used in the work, $\mathcal{Z}_i$ denotes the sampled batch, $p(\mathcal{Z}_i)$ denotes the cancer type distribution of the sampled batch, $\theta^\prime$ denotes the parameters updated in the sample batch, $\mathcal{L}$ denotes the loss function, and $\eta$ denotes the hyper-parameter. The loop of sampling performs meta-learning using the cumulative test error of the backbone model and obtains the parameters as output. %They examine the performance by conducting a few-shot classification problem using a train set size of 8 slides and achieve a state-of-the-art performance.

\citet{singh2021metamed} integrated another popular method in meta-learning field, named Reptile \citep{nichol2018reptile}, which is a similar framework structure as the MAML. 
%\input{Figures/fig_reptile}
%As Fig. \ref{fig_reptile} denotes, 
The only difference is that it iterates several times in the inner loop and takes the final gradient message back to the outer loop. The parameter update rule goes in: $\theta \leftarrow \theta^{\prime} +\epsilon \frac{1}{m} \sum_{k=1}^{m}\left(f_{\theta_{k}}-f_{\theta^{\prime}}\right)$, 
where $\theta^{\prime}$ denotes the model parameters in the outer loop, $\theta_k$ denotes the parameters of the $k$-th sample in the inner sampling loop, $m$ denotes the number of sampled data, and $\epsilon$ denotes the hyper-parameter. The use of the Reptile algorithm reduces the computational cost due to the gradient calculations are fewer than the MAML method. To ensure the performance of the method, the authors combined random augmentation strategies to enhance the generalization capability of the model.

Moreover, methods mixing the above-mentioned types are rising recently, \citet{mahajan2020meta} separately take metric-learning and gradient-learning type methods for their MetaDermDiagnosis Network to solve the skin lesion classification problem. In addition, they implement Group Equivalent convolutions (G-convolutions) \citep{cohen2016group} to improve disease identification performance, as these images typically lack any prevailing global orientation/canonical structure, and G-convolutions make the network equivalent to discrete transformations.

\subsection{Discussions}
While FSL advancements centered around metric-based and meta-based methods and shown promising results. However,  metric-based models often struggle with highly heterogeneous medical datasets, while meta-based approaches can be computationally intensive and complex to implement \citep{song2023comprehensive}. As we look to the future, the integration of other learning schemes could address these shortcomings. This includes, but is not limited to semi-supervised learning \citep{mai2021few}, transfer learning \citep{lu2022transfer}, and ensemble learning \citep{paul2021discriminative}, to name a few \citep{he2021few}. Such a holistic approach promises the development of models that are not only more robust but also exhibit greater versatility.

%Attention Mechanism is favored since its lower parameter cost, parallel interference capability and better performance. Experiment on three datasets demonstrated that their method has outperformed the compared state-of-the-art methods as the Dice, IoU and HD scores are the best with the usage of as low as 0.6\% of the total dataset.

% Quellec \textit{et al.}  \cite{quellec2020automatic} designed a probabilistic model powered by PCA and t-SNE \cite{van2008visualizing} observation for determining classification probability. In detail, it is based on the discovery that CNNs often view images with comparable anomalies as similar, despite the fact that these CNNs were taught to identify unrelated circumstances. For experiments, it compared with other SOTA FSL learning methods and proved its performance superiority.

%Besides in search of mathematical expressions, 
%Besides segmentation tasks, \citet{he2021few} proposed a two-stage few-shot medical image registration network. Firstly, the inputs are encoded by the proposed perception and correspondence networks, and send to the second stage as past knowledge. In the second phase, their Reverse Teaching method for aligning labeled and unlabeled pictures provides adequate supervisory information to the structure and style knowledge for unlabeled images, hence generating more training data. 
%Compared to the state-of-the-art methods, they achieve 12.5\%, 6.3\%, and 1\% improvements on three datasets with less than 60 unregistered images in total, suggesting their method has great clinical application potential.

%Transfer learning has been another approach that going viral in FSL sphere. Mai \textit{et al.} \cite{mai2021few} formulate few-shot retinal diseases recognition problems as a Student-Teacher Transfer Learning task with a discriminative feature space and Knowledge Distillation (KD) from the auxiliary dataset. Lu \textit{et al.} \cite{lu2022transfer} proposed a Transfer Learning-based method for Few-Shot novel White Matter (WM) tract segmentation. It transfers the knowledge acquired for segmenting existing WM tracts to the segmentation of novel WM tracts via a fine-tuning technique, in which a CNN pretrained for segmenting existing WM tracts is fine-tuned without losing the information of the final task-specific layer, as conventional fine-tuning process would neglect it completely. Moreover, they derive a superior initialization for the final task-specific layer of the target model that segments fresh WM tracts from the weights of the pretrained task-specific layer. At last, they offer a data augmentation technique that generates synthetic annotated images with tract-aware image mixing. %Using the HCP dataset and a private dataset, they demonstrate their method on 22 novel WM tracts in total with significantly better performance than the baselines.

%Paul \textit{et al.} \cite{paul2021discriminative} takes the ensemble learning approach for FSL scenario. In the first stage, a CNN-based coarse-learner is used to learn the general properties of chest X-rays. In the second phase, they incorporate a self-designed, saliency-based discriminative autoencoder-based classifier to extract disease-specific salient characteristics from the coarse-learner output and classify based on them. Besides, part of the method is subjected to meta-training and meta-testing, in which they teach the coarse-learner during the meta-training phase. During the meta-testing phase, however, they exclusively train the saliency-based classifier. Experiments reveal a 19\% improvement in F1-score relative to the baseline in the diagnosis of chest X-rays.

%Lastly, Zhao \textit{et al.} \cite{zhao2019data} pushed FSL to an extreme condition, that is, one-shot learning. They proposed a learned data augmentation method to conduct a one-shot segmentation task, i.e., the training data only has one sample. This method has utilized U-Net-based models as general network architecture to learn spatial and appearance transform from the atlas (image with segmentation label) separately. For spatial alignment, they leverage the learning scheme of the VoxelMorph \cite{balakrishnan2019voxelmorph} model, which learns to generate a smooth displacement vector field that registers one image to another by concurrently optimizing their normalized cross-correlation loss and a smoothness term for the displacement field. For appearance alignment, they design a similarity loss with a smooth regularizer. Then synthesize the augmented training image and the corresponding segmentation maps. The experiments on eight public datasets show that their method has outperformed the state-of-the-art one-shot learning methods by increased Dice score.