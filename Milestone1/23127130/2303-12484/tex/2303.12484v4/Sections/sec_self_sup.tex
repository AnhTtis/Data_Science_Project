\section{Self-supervised Learning in MIA} \label{sec:ssl}
\input{Sections/Tables/tab_self_sup_v2.tex}

\subsection{Reconstruction-Based Methods}
\textbf{Reconstruction-based methods} in Self-SL focus on exploring the inherent structures of data without the help of human annotations. These methods are conducted on several tasks including super-resolution \citep{li2021single,zhao2020smore}, inpainting \citep{zhao2021anomaly}, colorization \citep{abbet2020divide}, and the emerging MIA-specific application, multi-modal reconstruction \citep{cao2020auto,hervella2018retinal}. 

A straightforward way to establish the reconstruction task is proposed by \citet{li2020sacnn}, who adopt an auto-encoder network to encode and reconstruct normal-dose computed tomography (CT) images for learning the latent features by minimizing the mean squared error (MSE) loss. After self-supervised pre-training, the encoder is utilized for feature extraction, and a supervised loss is computed with the encoded latent features. However, the self-supervised pre-training based on the minimization of reconstruction loss might neglect the basic structure of the input image and capture the color space distribution instead \citep{abbet2020divide}. More proxy tasks have been motivated to solve this challenge.

The super-resolution reconstruction task is to generate fine-grained and realistic high-resolution images by utilizing low-resolution input images. In this proxy task, the targeted model can learn the underlying semantic features and structures of data. %In , 
\citet{zhao2020smore} propose an anti-aliasing algorithm based on super-resolution reconstruction to reduce aliasing and restore the quality of magnetic resonance images (MRIs). While \citet{li2023generic} utilize the frequency information in fundus image as guidance to conduct image enhancement. 
In the meantime, super-resolution reconstruction is also an appropriate proxy task for gigapixel histopathology whole-slide images (WSIs) because low-resolution WSIs are rather easy to store and process. From this application, \citet{li2021single} conduct single image super-resolution for WSIs using GAN. 

The image colorization task is to predict the RGB version of the gray-scale images. During this process, the network is trained to capture the contour and shape of different tissues in the sample and fill them with respective colors \citep{abbet2020divide, fan2023cancerself, lin2023nuclei}. \citet{abbet2020divide} introduce the image colorization task into survival analysis of colorectal cancer. They train a convolutional auto-encoder to convert the original input image into a two-channel image, namely, hematoxylin and eosin. Then, MSE loss is applied to measure the difference between the original input image and its converted counterpart. Moreover, in the context of survival analysis,  \citet{fan2023cancerself} extend their methodology beyond image colorization to include a cross-channel pre-text task. This additional task challenges the model to restore the lightness channel in image patches, utilizing the information from their color channels.

The image inpainting task aims to predict and fill in missing parts based on the remaining regions of the input image. This proxy task allows the model to recognize the common features of identical objects, such as color and structure, and thus to predict the missing parts consistently with the rest of the image. \citet{zhao2021anomaly} propose a restoration module based on Self-SL to facilitate the anomaly detection of optical coherence tomography (OCT) and chest X-ray. It demonstrates that the restoration of missing regions facilitates the model's learning of the anatomic information.

In recent years, the multi-modal reconstruction task has emerged  \citep{cao2020auto,hervella2018retinal}. In this task, the model uses the aligned multi-modal images of a patient to reconstruct an image in one modality by taking another modality as the input. \citet{hervella2018retinal} propose this proxy task to enrich the model with joint representations of different modalities, arguing that each modality offers a complementary aspect of the object. Therefore, they take retinography and fluorescein angiography into consideration to facilitate retinal image understanding. Meanwhile,  \citet{cao2020auto} develop a self-supervised collaborative learning algorithm, aiming at learning modality-invariant features for medical image synthesis by generating the missing modality with auto-encoder and GAN.

\subsection{Context-Based Methods}
\textbf{Context-based methods} utilize the inherent context information of the input image. Recent years have witnessed attempts to design novel predictive tasks for specific MIA tasks by training the network for prediction of the output class or localization of objects with the original image as the supervision signal \citep{bai2019self,spitzer2018improving,srinidhi2022self}. \citet{bai2019self} propose a proxy task to predict the anatomical positions from cardiac chamber view planes by applying an encoder-decoder structure. This proxy task properly employs the chamber view plane information, which is available from cardiac MR scans easily. While \citet{zheng2023msvrl} aims to perform finer-grained representation and deal with different target scales by designing a multi-scale consistency objective to boost medical image segmentation. Further advancements in proxy tasks for 3D medical images are presented by \citet{he2023geometric}. They propose a novel paradigm, termed Geometric Visual Similarity Learning, which integrates a topological invariance prior into the assessment of inter-image similarity. This approach aims to ensure consistent representation of semantic regions.
In addition, \citet{srinidhi2022self} propose an MIA-specific proxy task, Resolution Sequence Prediction, which utilizes the multi-resolution information contained in the pyramid structure of WSIs. A neural network is employed to predict the order of multi-resolution image patches out of all possible sequences that can be generated from these patches. In this way, both contextual structure and local details can be captured by the network at lower and higher magnifications, respectively. 

Other efforts have been made to explore the spatial context structure of input data, such as the order of different patches constituting an image, or the relative position of several patches in the same image, which can provide useful semantic features for the network. \citet{chen2019self} focus on the proxy task, dubbed context restoration, of randomly switching the position of two patches in a given image iteratively and restoring the original image. During this process, semantic features can be learned in a straightforward way. Instead of concentrating on the inherent intensity distribution of an image, \citet{li2021rotation} aims to improve the performance of a network with rotation angle prediction as the proxy task. The input retinal images are first augmented, generating several views, then randomly rotated. %in angles \{0째, 90째, 180째, 270째\}
The model is encouraged to predict the rotation angle and cluster the representations with similar features. More advanced proxy tasks such as Jigsaw Puzzles \citep{freeman1964apictorial} and Rubik's Cube \citep{korf1985macro} are also attracting an increasing number of researchers. \citet{taleb2021multimodal} improve the Jigsaw Puzzle task with multi-modal data. Concretely, an input image is constituted of out-of-order patches of different modalities and the model is expected to restore the original image. Rubik's Cube is a task set for 3-dimensional data. \citet{zhuang2019selfsupervised} and \citet{tao2020revisiting} introduce Rubik's Cube into the MIA area, and significantly boost the performance of a deep learning model on 3D data. In this method, the 3D volume will first be cut into a grid of cubes and a random rotation operation will be conducted on these cubes. The aim of this proxy task is to recover the original volume. 

However, for histopathology images, common proxy tasks such as prediction of the rotation or relative position of objects may only provide minor improvements to the model in histopathology due to the lack of a sense of global orientation in WSIs \citep{graham2020dense,koohbanani2021self}. Therefore, \citet{koohbanani2021self} propose proxy tasks targeted at histopathology, namely, magnification prediction, solving magnification puzzle, and hematoxylin channel prediction. In this way, their model can significantly integrate and learn the contextual, multi-resolution, and semantic features inside the WSIs.

\subsection{Contrastive-Based Methods}
\textbf{Contrastive-based methods} are based on the idea that the learned representations of different views of the same image should be similar and those of different images should be clearly distinguishable. Intriguingly, the ideas behind several high-performance algorithms such as SimCLR \citep{chen2020simple} and BYOL \citep{grill2020bootstrap} have been incorporated into the MIA field \citep{azizi2021big,wang2021transpath}. Multi-Instance Contrastive Learning (MICLe), is proposed by  \citet{azizi2021big}, is a refinement and improvement of SimCLR. Instead of using one input to generate augmented views for contrastive learning, they propose to minimize the disagreement of several views from multiple input images of the same patient, creating of more positive pairs. Meanwhile, \citet{wang2021transpath} adopt the BYOL architecture to facilitate histopathology image classification. A contribution of their work was to collect the currently largest WSI dataset for Self-SL pre-training. It includes 2.7 million patches cropped from 32,529 WSIs covering over 25 anatomic sites and 32 classes of cancer subtypes. Similarly, \citet{ghesu2022self} develop a contrastive learning and online clustering algorithm based on over 100 million radiography, CT, MRI, and ultrasound images. By leveraging this large unlabeled dataset for pre-training, the performance and convergence rate of the proposed model show a significant improvement over the state-of-the-art. Another line of work that utilizes large-scale unsupervised dataset is \citep{nguyen2023lvm}, in which over 1.3 million multi-modal data from 55 publicly available datasets are integrated. In addition to considering different perspectives of the same input, \citet{jiang2023anatomical} introduce a contrastive objective for the learning of anatomically invariant features. This approach is designed to fully exploit the inherent similarities in anatomical structures across diverse medical imaging volumes.

Further studies take into account the global and local contrast for better representation learning. Their methods usually minimize the InfoNCE loss \citep{oord2018representation} to capture the global and local level information. In \citep{yan2022sam}, the authors implement the InfoNCE by encoding each pixel of the input image. Their goal is to generate embeddings that can precisely describe the anatomical location of that pixel. To achieve this, they develop a pixel-level contrastive learning framework to generate embeddings at both the global and local level. Further, \citet{liu2023hierarchical} propose a hierarchical contrastive learning objective to capture the unsupervised representation of intra-oral mesh scans from point-level, region-level, and cross-level.

\subsection{Hybrid Methods}
Studies have made efforts to combine some or all of the different types of Sefl-SL methods into a universal framework to learn latent representations from multiple perspectives, such as semantic features and structure information inside unlabeled data \citep{haghighi2020learning,tang2022self,yang2022cs,zhou2021preservational}. For instance, \citet{tang2022self} combine masked volume inpainting, contrastive coding, and image rotation tasks into a Swin Transformer encoder architecture for medical image segmentation.

\subsection{Discussion}
Self-SL methods aim to learn and obtain a model with prior knowledge by manipulating and exploiting unlabeled data. The key to the superior performance of Self-SL models is the design of proxy tasks. Numerous existing Self-SL methods directly adopt proxy tasks prevailing in natural image processing into the MIA field. However, the unique properties of medical images, such as CT, WSI, and MRI, should be exclusively considered and injected into the design process of proxy tasks. The medical field has witnessed pioneering research efforts, exemplified by \citet{zhang2023dive}, that aim to establish guidelines for the design of Self-SL proxy tasks.
Further, proxy task design based on the combination of different medical image modalities is a prospective research direction, during which the model can capture disentangled features of each modality, leading to a robust pre-trained network. For example, large vision-language pre-trained models \citep{park2023self,zhou2022generalized,zhou2023advancing} are emerging in chest X-ray and obtaining ever-increasing research interests.