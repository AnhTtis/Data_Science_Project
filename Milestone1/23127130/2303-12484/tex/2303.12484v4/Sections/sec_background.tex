\section{Background and Categorization}\label{sec:background}
In this section, we review the background of the learning schemes covering label-efficient learning. In addition, we present the categorization of each learning scheme in MIA.
\subsection{Semi-Supervised Learning}
\input{Figures/fig_semi_schematic.tex}
As illustrated in Fig. \ref{fig_semi_schematic}, \textbf{Semi-supervised learning (Semi-SL)} introduces an additional unlabeled dataset to help the model learn task-related invariant features and aim to achieve better performance than supervised learning. Concretely, one has a set of $L$ labeled data points $X_L = \{(x_i, y_i)\}_{i=1}^{L}$, in which $x_i$ represents the raw data sample from the given input space $\mathcal{X}$ and $y_i$ is the corresponding label. In the meantime, an unlabeled dataset $X_U = \{x_i\}_{i=L+1}^{L+U}$ with a much larger scale is involved, \textit{i.e.}, $U\gg L$. And $X=X_L \cup X_U$ denotes the entire dataset. During the training process, the optimization problem\footnote{Several assumptions and prior knowledge of Semi-SL can be referred to Appendix A.1.} that Semi-SL intends to solve is defined as:
\begin{equation}\label{eq:semi}
    \min_{\theta}\sum_{(x,y)\in X_{L}}\mathcal{L}_{s}(x, y, \theta)+\alpha \sum_{x \in X_U}\mathcal{L}_{u}(x,\theta)+\beta \sum_{x\in X}\mathcal{R}(x,\theta),
\end{equation}
where $\theta$ represents the model parameters, $\mathcal{L}_{s}$ is the supervised loss function, $\mathcal{L}_{u}$ represents the unsupervised loss function, and $\mathcal{R}$ is a regularization term. In addition, $\alpha, \beta \in \mathbb{R}^{+}$ control the trade-off between unsupervised loss $\mathcal{L}_u$ and regularization term $\mathcal{R}$.

Based on how the model incorporates and leverages unlabeled data, we will discuss the categories of Semi-SL methods and their applications in MIA starting from \textbf{proxy-labeling methods}, followed by \textbf{generative methods}, \textbf{consistency regularization methods}, and finally \textbf{hybrid methods}. Meanwhile, we present a brief summary of the representative publications in Tab. \ref{tab:semi}
% \footnote{The summary of all collected publications in Semi-SL and the rest of the learning schemes can be referred to in Appendix B.}. 
\subsection{Self-Supervised Learning}
\input{Figures/fig_self_schematic.tex}
\textbf{Self-supervised learning (Self-SL)} was proposed to extract and learn the underlying features of a large-scale unlabeled dataset without human annotation. Generally, Self-SL methods build proxy tasks for the model to learn the latent features and representations from a massive amount of unlabeled data, thus facilitating the performance on downstream tasks, as shown in Fig. \ref{fig_self_schematic}. Concretely, the training procedure of Self-SL can be divided into two stages: pre-training with proxy tasks and fine-tuning on different downstream tasks. During the pre-training phase, researchers design proxy tasks that satisfy the following two properties \citep{jing2020self}: (1) The label of the input data for the proxy task can be generated automatically by the data itself; (2) the neural network can learn related representations or features of the input data by solving the proxy task.

After the pre-training with proxy tasks, the learned representations will be utilized to solve the main task. The advantages of utilizing proxy tasks are two-fold: on the one hand, by defining particular tasks, the model can be targeted to learn features or representations of the specific studied data; on the other hand, by using a large amount of unlabeled data for pre-training, the model can significantly avoid overfitting during fine-tuning compared to supervised learning, especially for small datasets, in downstream training.

Based on the characteristics of the proxy tasks, we group the mainstream Self-SL methods in MIA into the following four general categories: \textbf{Reconstruction-Based Methods}, \textbf{Context-Based Methods}, \textbf{Contrastive-Based Methods}, and \textbf{Hybrid Methods} with a summary of the representative publications in Tab. \ref{tab:self}.


\subsection{Multi-instance Learning}
\input{Figures/fig_mil_schematic.tex}
% As illustrated in Fig. \ref{fig_mil_schematic}, the goal for \textbf{multi-instance learning (MIL)} is to detect and/or classify target patterns of weakly-labeled data. 
In \textbf{multi-instance learning (MIL)}, the concept of a \textit{bag} is introduced. A bag $X_i$ is composed of $k$ instances:
$X_i = \{x_{i,1}, x_{i,2},\cdots,x_{i,k_i}\}$, where $x_{i,j}$ denotes an instance in bag $X_i$,
and the training dataset $\mathcal{X}$ consists of $N$ bags: $\mathcal{X}=\{X_1,X_2,\cdots,X_N\}$. Next, suppose $Y_i \in \{1,0\}$ and $y_{i,j} \in \{1,0\}$ are the labels of bag $X_i$ and the instance $x_{i,j}$ inside it, respectively, in which $1$ denotes positive and $0$ denotes negative for the binary classification scenario. Two common assumptions can be made based on this basic definition of MIL:
\begin{itemize}
    \item If bag $X_i$ is positive, then there exists at least one positive instance $x_{i,m} \in X_i$ and $m\in \{1,2,\cdots,k_i\}$ is unknown. This assumption can be summarized as: if $Y_i=1$, then $\sum^{k_i}_{j=1}{y_{i,j}}\geq 1$.
    \item If bag $X_i$ is negative, then all the instances in $X_i$ are negative, namely, if $Y_i=0$, then $\sum^{k_i}_{j=1}{y_{i,j}}=0$.
\end{itemize}

Based on the assumptions, MIL methods can perform both bag-level and instance-level tasks (illustrated in Fig. \ref{fig_mil_schematic}), with the latter often used in weakly-supervised learning. Concretely, MIL algorithms leverage the instances to identify positive or negative bags, which contributes not only to the image-level diagnosis but also to precise abnormal region detection and localization. This great interpretability of the MIL algorithm fits well in MIA, as both the global structure and local details are crucial components for solving such problems.

In this survey, we categorize MIL methods that aim at detecting all the particular target patterns in the data, such as every patch with a special disease manifestation in a large histopathology image, as \textbf{local detection}; and methods that aim at simply detecting whether or not the particular target patterns exist in the given sample as \textbf{global detection}. Note that taxonomy is in line with the methodology of MIL, \textit{i.e.}, to classify bag-level label (global detection) or to classify instance-level label (local detection). Tab. \ref{tab:mil} presents an overview of the representative publications of each method.

\subsection{Active Learning}
\input{Figures/fig_al_schematic.tex}
\textbf{Active learning (AL)} is a relatively understudied area in the MIA field. It attempts to maintain the performance of a deep learning model while annotating the fewest data with the help of an oracle, which resonates with the philosophy of label-efficient learning, \textit{i.e.}, how to effectively use noisy, limited, and unannotated data throughout the deep learning process. More specifically, its goal is to select the most valuable samples and forward them to the oracle (\textit{e.g.}, human annotator) for labeling to improve the generalization capability of the model. In active learning (AL) practice, the measurement of annotation uncertainty using various strategies is often considered as the metric for sample value. Meanwhile, in order to preserve the network's generalization capability, different mechanisms have been developed to ensure that the sampled images are distributed diversely. % since the annotation uncertainty tends to occur in ambiguous boundaries and the region with partial volume effect\cite{karimi2023learning}, etc. 

As Fig. \ref{fig_al_schematic} illustrates, before the start of the data selection process, a deep learning model is initialized or pre-trained from a labeled dataset $X_L$ with its corresponding parameter $\theta$. After that, AL sampling algorithms construct an uncertainty metric $\mathcal{U}$ for each item of unlabeled dataset $X_U$. This metric determines whether an oracle is required for annotation, and we denote this newly annotated dataset as $X_{L^{\prime}}\subset X_U$. Then the network model will either use the combined labeled data $X_{\hat{L}}=X_{L}\cup X_{L^{\prime}}$ to train from scratch or only use them to fine-tune the model. Denoting the fully labeled version of $X_U$ as $X^L_U$, the goal of AL is to build a model $f(\theta\mid X_L^{*})$ with $|X_L^{*}|
\ll |X^L_U|$ to perform equivalently or better than $f(\theta\mid X_L)$. 

Based on how the uncertainty is obtained, we categorize AL methods into \textbf{data uncertainty-based methods} and \textbf{model uncertainty-based methods}. Data uncertainty-based methods attempt to get a sample with the greatest uncertainty from a batched dataset, while model uncertainty-based methods tend to sample the samples that cause the greatest uncertainty of the deep learning model's performance. A brief summary of surveyed AL papers is presented in Tab. \ref{tab:al}.%This, however, is likely to overlook the link between samples. 
%As a result, numerous sampling approaches have been proposed recently.  and  %For a review of general AL methods, please refer to \cite{ren2021survey}.

\subsection{Few-Shot Learning}
\input{Figures/fig_fsl_schematic}
Few-shot learning (FSL) is the problem of building a deep learning model to make predictions based on a limited number of samples. This limited sample size restricts the model's generalization ability in conventional learning schemes.  In FSL literature, the terms \textit{support set} $S$ and \textit{query set} $Q$ represent the training and testing sets, respectively. Each support set $S$ comprises $C$ distinct categories, each containing $K$ training samples, thus establishing a \textit{C-way K-shot} configuration.  In this section, we categorize FSL methods based on mainstream MIA literature into two categories: \textbf{metric-based methods}, \textbf{meta-based methods}\footnote{To aid the understanding of each subfield, a detailed description is provided in Appendix A.3.}. For a comprehensive review of general FSL methods, please refer to \citet{song2023comprehensive}.

\subsection{Annotation-Efficient Learning}
\input{Figures/fig_anno_effi}
% In practice, accurate and complete annotation is time-consuming and labor-intensive. 
% The main challenges~\cite{dudea2012ultrasonography} lie in
% 1) the annotation process requiring multiple annotators to work independently and the inevitable diagnostic inter-/intra-individual variability; 
% 2) the gold standard for diagnosis needing extra tests to acquire sufficient data; 
% and 3) incomplete or low-quality annotations significantly impacting the model's performance. 
% Other factors, such as domain-specific knowledge, patients' privacy, and large data volumes~\cite{lin2019automated}, may also affect the annotation process.
% Annotation-efficient learning is a technique that utilizes deep learning methods with partially labeled data for dense predictions to improve labeling efficiency.
% The intuitive approach to increase annotation efficiency is to provide markings other than fully dense annotations. 
% Fig.~\ref{fig_anno_effi} shows different forms of annotation, 
% and we will separately review the annotation-efficient learning methods regarding the ``not exact label'' from coarse-to-fine granularity, \textit{i.e.}, \textbf{Tag}, \textbf{Point}, \textbf{Scribble}, and \textbf{Box}. The overview of the representative publications of this category is presented in Tab. \ref{tab:anno}.
\textbf{Annotation-efficient learning} is a technique that utilizes deep learning methods with partially labeled data for dense predictions to improve labeling efficiency.
The intuitive approach to increase annotation efficiency is to provide markings other than fully dense annotations. 
While there may be overlapping techniques with the aforementioned categories, annotation-efficient learning methods specifically focus on leveraging the specific characteristics of the different forms of annotation to enhance the annotation efficiency and hence minimize the granularity difference between the annotation and the prediction.
Fig.~\ref{fig_anno_effi} shows different forms of annotation, and we will separately review the annotation-efficient learning methods that address the ``not exact label'' through a coarse-to-fine way. 
Specifically, we will discuss the techniques related to \textbf{Tag}, \textbf{Point}, \textbf{Scribble}, and \textbf{Box} annotations. 
Tab.~\ref{tab:anno} provides an overview of representative publications in this category.

