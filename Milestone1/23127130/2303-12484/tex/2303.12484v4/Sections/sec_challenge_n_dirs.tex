\section{Challenges and Future Directions} \label{sec:cnfd}
Our comprehensive discussion of label-efficient learning schemes in MIA raises several challenges that should be taken into account to improve the performance of the DL model. In this section, we describe the crucial challenges and shed light on potential future directions for solving these challenges.

\subsection{Omni-Supervised Learning} 
Although the methods we have presented have achieved promising performance, many of them are targeted at addressing \textit{ad hoc} label shortage problems, \textit{i.e.}, these methods do not utilize as much supervision as possible.
Served as a special regime of Semi-SL, \textbf{Omni-supervised learning} is a crucial trend for label-efficient learning in MIA for the simultaneous utilization of different forms of supervision. Studies \citep{chai2022orf,luo2021oxnet} have demonstrated the feasibility of omni-supervised learning under teacher-student \citep{tarvainen2017mean} and the dynamic label assignment \citep{chai2022orf} pipeline, respectively. In the teacher-student training approach, the model trained on fully annotated datasets serves as the teacher model, and features extracted from the weakly-/un-annotated datasets serve as guidance to refine the model. 
Through designated mechanisms, the student model utilizes the teacher model with the provided guidance to further improve performance.  Meanwhile, the dynamic label assignment approach forms the crafted metrics from different types of labels in the training process and dynamically gives the final predicted labels. 

During the process of omni-supervised learning, however, centralizing or releasing different supervision health data raises multiple ethical, legal, regulatory, and technological issues \citep{rieke2020future}. On the one hand, collecting and maintaining a high-quality medical dataset consumes a large amount of expense, time, and effort. 
On the other hand, the privacy of patients may be compromised during the centralization or release of health datasets, even with techniques such as anonymization and safe transfer. To address the privacy preservation problem during model development, researchers proposed \textbf{federated learning (FL)} to conduct training in a data-decentralized manner. 
This approach has yielded fruitful results in The field of MIA \citep{dayan2021federated,li2020multi,lu2022federated}. However, current FL algorithms are primarily trained in a supervised manner. When applying the FL to real-world scenarios in MIA, a crucial problem, namely, label deficiency, may appear in local health datasets.
Labels may be missing to varying degrees between medical centers, or the granularity of the labels will vary. A promising research direction is to design label-efficient federated learning methods to address this significant problem. For example, semi-supervised learning \citep{liu2021federated}, active learning, and self-supervised learning \citep{dong2021federated} are suitable to be incorporated into this setting.

\subsection{Human-in-the-loop Interaction}
The application of expert knowledge to refine the output of the model is often carried out in practice, and there have been various efforts to investigate this field, known as human-in-the-loop (HITL). The AL scheme can be considered a part of HITL as it involves the introduction of expert knowledge to refine data supervision. However, AL focuses on efficiently using limited labeled data to improve a model's performance, often involving human annotators. HITL, on the other hand, involves training models based on feedback or rewards provided by humans, often to shape the model's behavior or outputs in ways that align with human preferences or judgments. In HITL, expert knowledge is introduced as action supervision under the \textbf{reinforcement learning (RL)} schemes to improve the performance of the DL model \citep{liao2020iteratively, ma2020boundary}. Under the RL scheme, a set of “agents” is formulated to learn expert behaviors in an interactive environment via trial and error. In MIA tasks, RL methods mainly treat the interactive refinement process as the Markov decision process (MDP) and give the solution by the RL process. RL-based interventional model training brings the potential for dealing with rare cases in MIA, since the expert-provided interactions can refine the prediction result at the final stage to hinge samples that failed to process by the DL model.
In addition, recent developments in diverse learning methodologies, including but not limited to few-shot learning \citep{al2021ifss,feng2021interactive} and interpretability-guided learning \citep{mahapatra2021interpretability}, have contributed to improved efficacy of human-in-the-loop workflows, thereby reducing labor costs in MIA. This indicates a positive trend towards increased cost-effectiveness in this field.

\subsection{Generative Data Augmentation}
Data augmentation with synthesized images produced by generative-based methods is regarded as a way to unlock additional information from the dataset and leads the way in computation speed and quality of results in the scope of generative methods \citep{shorten2019survey}.
In the field of MIA, numerous studies \citep{lin2022insmix,wang2020semi} have investigated data augmentation with the original GAN \citep{goodfellow2014generative}  and its variations. 
 However, the unique adversarial training procedure of GANs may suffer from training instability \citep{gulrajani2017improved} and mode collapse \citep{lin2018pacgan}, yielding ``Copy GAN", which only generates a limited set of samples \citep{yang2019bi}.
Thus, synthesizing augmented data with high visual realism and diversity is the key challenge of GAN.
Meanwhile, the \textbf{probabilistic diffusion model} \citep{ho2020denoising}, has recently sparked much interest in MIA applications \citep{baranchuk2021labelefficient,kazerouni2022diffusion}. 
This model establishes a forward diffusion stage in which the input data is gradually disrupted by adding Gaussian noise over multiple stages and then learns to reverse the diffusion process to obtain the required noise-free data from noisy data samples. 
Despite their recognized computational overhead \citep{xiao2022tackling}, diffusion models are generally praised for their high mode coverage and sample quality, and various efforts have been made to ease the computational cost and further improve their generalization capability.

\subsection{Generalization Across Domains and Datasets}
From semi-supervised learning to annotation-efficient learning, we have introduced a considerable number of methods that address the problem of the low-quantity and/or -quality of labels. Nevertheless, recent results reveal that these novel methods may encounter significant performance degradation when shifting to different domains or datasets. The generalization problem in the MIA field arises due to multiple causes, such as variance among scanner manufacturers, scanning parameters, and subject cohorts. And various current deep learning algorithms cannot be robustly deployed in various real scenarios. To address this practical problem, the concept of \textbf{domain generalization} has been introduced, of which the key idea is to learn a trained model that encapsulates general knowledge so as to adapt to unseen domains and new datasets with little effort and cost. A plethora of methods have been developed to tackle the domain generalization problem \citep{zhou2022domain}, such as domain alignment \citep{li2018domain}, meta-learning \citep{li2019feature}, data augmentation \citep{qiao2020learning}, and so on. MIA has also seen some publications with respect to domain generalization \citep{che2023iqad,che2023dgdr,li2020domain,liu2021feddg}. Further, another challenge for generalization across domains and datasets is that the proposed methods may require numerous labeled multi-source data to extract domain-invariant features. For example, \citet{yuan2022label} have made a successful attempt to achieve model generalization in source domains with limited annotations by leveraging active learning and semi-supervised domain generalization, eliminating the dilemma between domain generalization and expensive annotations.

\subsection{Benchmark Establishment and Comparison}
Label-efficient learning in MIA spans multiple tasks, such as classification, segmentation, and detection, as well as multiple organs, such as the retina, lung, and kidney. Differences and variances in tasks and target organs lead to confounding experiment settings and unfair performance comparisons. Meanwhile, a lack of sufficient public health datasets also contributes to this dilemma. For example, many researchers can only conduct experiments to measure the performance of their proposed algorithms based on their own private datasets due to reasons such as privacy. Moreover, a number of medical image datasets does not contain standard train-test split and most of the algorithms evaluate the performance on different test-split data. In this regard, the results in different papers are not directly comparable, and they can only provide an overall indication about the performance of the models.
However, few publications have emerged \citep{gut2022benchmarking} to address the problem, especially for label-efficient learning. Thus, benchmarking remains a pressing problem for model evaluation. On the one hand, the public should urge for the availability of large datasets. On the other hand, a clearly defined set of benchmarking tasks and the corresponding evaluation procedures should be established. Further, specific experimental details should be stipulated to facilitate the comparability of different label-efficient learning algorithms.

\subsection{Foundation Models}
The inherent distinctions among MIA tasks, such as classification, segmentation and detection, coupled with label scarcity hinder the progress and applicability of label-efficient algorithms. Recent advancements in \textbf{foundation model} \citep{azad2023foundational, qiu2023large} have ushered in a new era in this domain, marking a significant turning point.
Foundation model undergoes training using extensive and heterogeneous datasets, often employing large-scale self-supervision techniques. It's important to understand that these models stand out due to their scale, versatility, and ability to perform multiple tasks in label-efficient learning compared to the conventional Self-SL models. 

Foundation models in medical imaging are typically developed either from scratch or through fine-tuning existing models. Training from scratch involves building models using massive, diverse medical datasets from the ground up, allowing for highly specialized adaptation to medical contexts \citep{chen2023general,ghesu2022self}. Alternatively, fine-tuning involves adjusting pretrained foundation models, often developed for general computer vision field, to suit specific MIA downstream tasks, leveraging their pretrained knowledge for improved efficiency and effectiveness in label-efficient learning \citep{mazurowski2023segment}. Recent developments in segmentation and detection tasks \citep{li2023llavamed, liu2023clip, wu2023self} showcase the remarkable adaptability of these models. Building upon the adaptability of foundation models in medical imaging, their application in label-efficient fine-tuning, zero-shot learning, and generalizability across modalities heralds new research directions in label-efficient MIA, with limited research efforts to date \citep{lu2023visual}. These research directions strive to address challenges such as improving diagnostic efficiency with limited labels, achieving accurate predictions in unfamiliar scenarios, and leveraging the capabilities of the foundation models across diverse data modalities.