\section{Semi-supervised Learning in MIA} \label{sec:semi}
\input{Sections/Tables/tab_semi_sup_v2.tex}

\subsection{Proxy-labeling Methods}
\textbf{Proxy-labeling methods} provide proxy labels for unlabeled data samples in $X_U$. They include those data samples with high confidence proxy labels in the training dataset, training in an iterative manner. Proxy-labeling methods can be mainly categorized into two sub-categories: \textit{Self-training methods} and \textit{multi-view learning methods}.

\subsubsection{Self-training Methods}
\textit{Self-training methods} aim to learn a prediction function $f_{\theta}$ with parameters $\theta$ by using a fraction of labeled data samples $x\in X_L$. After that, the trained prediction function $f_{\theta}$ is utilized to provide proxy labels of unlabeled data samples $x\in X_U$. Normally, a threshold $\tau$ is manually set and the sample-label pair $(x, \mathrm{argmax}{f_{\theta}(x)})$ will be added to the labeled dataset $X_L$ if the highest prediction probability in the output of $f_{\theta}$ outweighs $\tau$. The updated labeled dataset will be consequently used to train the prediction function $f_{\theta}$, and this process is conducted iteratively until $f_{\theta}$ cannot make predictions with enough confidence.

Entropy minimization \cite{grandvalet2004semi} is a method that regularizes the model based on the low-density assumption, encouraging the model to generate low-entropy prediction for the unlabeled data. \textbf{Pseudo-label} \cite{lee2013pseudo} is a simple yet effective self-training mechanism which inherits the concept of entropy minimization in the prediction space. The labeled samples are trained in a supervised way, and unlabeled data are assigned with the most confident predictions. In MIA, pseudo-label is employed as an auxiliary component to enhance model performance \cite{fan2020inf,zhang2022boostmis,chaitanya2023local}. %yao2022enhancing. 
In fact, proxy labels are normally noisy and may not reflect the ground truth. Therefore, various quality measurements such as uncertainty-aware confidence evaluation \cite{wang2021semiself}, conditional random field-based proxy label refinement \cite{bai2017semi}, and adversarial training-based method \cite{zhou2019collaborative} have been developed to ensure  that reliable supervision signals can be generated based on pseudo labels. Pseudo-label has also been used in MIA to refine a given annotation with the assistance of unlabeled data. Qu \textit{et al.} \cite{qu2020weakly} introduce pseudo-label into nuclei segmentation and design an iterative learning algorithm to refine the background of weakly labeled images where only nuclei are annotated, leaving large areas ignored. Similar ideas can also be seen in \cite{nie2018asdnet}. 


\subsubsection{Multi-view learning methods}
\textit{Multi-view learning methods} assume that each sample has two or multiple complementary views and features of the same sample extracted with different views are supposed to be consistent. Therefore, the key idea of multi-view learning methods is to train the model with multiple views of the sample or train multiple learners and minimize the disagreement between them, thus learning the underlying features of the data from multiple aspects. \textbf{Co-training} is a method that falls into this category. It assumes that data sample $x$ can be represented by two views, $\textbf{v}_1(x)$ and $\textbf{v}_{2}(x)$, and each of them are capable of solely training a good learner, respectively. Consequently, the two learners are set to make predictions of each view's unlabeled data, and iteratively choose the candidates with the highest confidence for the other model \cite{yang2021survey}. 
Another variation of multi-view learning methods is Tri-training \cite{zhou2005tri}, which is proposed to tackle the lack of multiple view data and mistaken labels of unlabeled data produced by self-training methods. Tri-training aims to learn three models from three different training sets obtained with bootstrap sampling. Recently a deep learning version of Tri-training, i.e. Tri-Net, has been proposed in \cite{dong2018tri}.

Co-training, or deep co-training, is dominant in multi-view learning in MIA, with a steady flow of publications\cite{zhao2019multi,zhou2019semi,xia2020uncertainty,wang2021selfco,fang2020dmnet,zeng2023pefat}. To conduct whole brain segmentation, Zhao \textit{et al.} \cite{zhao2019multi} implement co-training by obtaining different views of data with data augmentation. A similar idea can be seen for 3D medical image segmentation in \cite{xia2020uncertainty} and \cite{zhou2019semi}. These two works both utilize co-training by learning individual models from different views of 3D volumes such as the sagittal, coronal, and axial planes. Further works have been proposed to refine co-training. To produce reliable and confident predictions, Wang \textit{et al.} \cite{wang2021selfco} develop a self-paced learning strategy for co-training, forcing the network to start with the easier-to-segment regions and transition to the difficult areas gradually. 
% by introducing generalized Jensen Shannon Divergence into the model
Rather than discarding samples with low-quality pseudo-labels, Zeng \textit{et al.} \cite{zeng2023pefat} introduce a novel regularization approach, which focuses on extracting discriminative information from such samples by injecting adversarial noise at the feature level, thereby smoothing the decision boundary.
Meanwhile, to avoid the errors of different model components accumulating and causing deviation, Fang and Li \cite{fang2020dmnet} develop an end-to-end model called difference minimization network for medical image segmentation by conducting co-training with an encoder shared by two decoders.

\subsection{Generative Methods}
Generative Semi-SL assumes that the entire dataset $X$ %$X=\{X_L,X_U\}$ 
is generated from the same latent distribution. In this sense, the key point of generative methods is to learn and simulate the latent distribution with the help of unlabeled data. Then the model with a well learned latent distribution aims to improve performance by combining supervised information.

\textbf{Generative adversarial network (GAN)} is a widely used model leveraging both labeled and unlabeled data. The standard GAN is composed of a generator $\mathcal{G}$ and a discriminator $\mathcal{D}$, trying to satisfy the Nash equilibrium \cite{goodfellow2014generative}. Typically, a generator is trained aiming to generate plausible images and a discriminator is trained to distinguish the generated image and the real one.
The unlabeled data can be involved during the adversarial training process, in which the discriminator aims to distinguish the generated fake input and real unlabeled data. By solving the two-player minimax game, GAN can learn the underlying distribution with the help of unlabeled data. The MIA filed has seen publications with respect to generative Semi-SL methods based on GAN \cite{chaitanya2021semi,hou2022semi,zhou2019collaborative, madani2018semi,diaz2019retinal,kamran2021vtgan}. Chaitanya \textit{et al.} \cite{chaitanya2021semi} directly incorporate the unlabeled data during the adversarial training of GAN to train a better generator for boosting medical data augmentation, arguing that utilizing unlabeled samples allows more variations in shape and intensity so as to make the model robust and guide the optimization. A similar idea can be seen in Hou \textit{et al.} \cite{hou2022semi}. While Zhou \textit{et al.} \cite{zhou2019collaborative} develop a generator network to predict the pseudo lesion masks for unlabeled data and utilize the discriminator to facilitate the quality of generated lesion mask. Other researchers have designed quite a number of methods modifying the discriminator $\mathcal{D}$. Instead of only distinguishing real or fake images, Odena \textit{et al.} \cite{odena2016semi} seek to learn the category information by predicting $K$ classes and an additional real or fake class. In this way, the unlabeled data can contribute to the model during the classification of the $K+1$ categories. In the context of MIA, the architecture proposed in \cite{odena2016semi} has produced fruitful results in various fields, such as retinal image synthesis \cite{kamran2021vtgan, diaz2019retinal,xie2023fundus}, glaucoma assessment \cite{diaz2019retinal}, chest X-ray classification \cite{madani2018semi}, and so on \cite{hou2022semi}.

\textbf{Variational autoencoder (VAE)} is also useful and prospective in utilizing unlabeled data. It is an autoencoder rooted in Bayesian inference theory \cite{kingma2013auto}. A typical VAE encodes a data sample into a latent variable and decodes it into the reconstruction of input by maximizing the variational lower bound. Our review of related literature shows that VAEs in MIA scenarios are mostly utilized for learning the inherent feature similarity from a large unlabeled dataset, thus contributing to a well-constrained latent space which can consequently avoid the need of numerous labeled data for training \cite{sedai2017semi, wang2022rethinking}. Sedai \textit{et al.} \cite{sedai2017semi} propose a dual-VAE framework to conduct semi-supervised segmentation of the optic cup in retinal fundus images, in which one VAE learns the data distribution with unlabeled data and transfers the prior knowledge to the other VAE which conducts segmentation with the labeled data. Instead of using a mean vector and a variance vector for the latent representation, Wang \textit{et al.} \cite{wang2022rethinking} adapts the VAE architecture into 3D medical image segmentation by introducing a mean vector and a covariance matrix to involve the correlation of different slices of an input volume.


\subsection{Consistency Regularization Methods}
Based on the smoothness or manifold assumption, \textbf{Consistency regularization methods} follow the idea that the perturbation of data points does not change the prediction of the model. Meanwhile, this process does not require label information, which is proved an effective constraint for learning the unlabeled data.

$\boldsymbol{\Pi}$\textbf{-model} \cite{sajjadi2016regularization} is a simple yet effective implementation of the above idea. This method uses a shared encoder to obtain different views of the input sample %$x_i$ 
through augmentation and 
% proceed consequent feature extraction. Concretely, $\Pi$-model 
force the classifier to produce the same prediction for different augmentations of $x$. Meanwhile, label information is included in the training process to improve the performance of the classifier. By designing a $\Pi$-model-based semi-supervised algorithm, Li \textit{et al.} \cite{li2018semipi} set a new record for skin lesion segmentation with only 300 labeled images, surpassing the state-of-the-art which was fully-supervised and used a set of 2,000 labeled images. Similar idea can be seen in \cite{bortsova2019semi,meng2023dual}, where Bortsova \textit{et al.} \cite{bortsova2019semi} conduct semi-supervised chest X-ray segmentation by learning prediction consistency given a set of transformations, and Meng \textit{et al.} \cite{meng2023dual} utilize graph convolution networks to constrain the regional consistency and marginal consistency for Semi-SL optic disc and cup Segmentation.  \textbf{Temporal ensembling} \cite{laine2016temporal} was developed to improve the prediction stability of the $\Pi$-model by adding exponentially moving average module for updating prediction. And a number of researchers have implemented this module to address MIA-related problems \cite{cao2020uncertainty,gyawali2019semi,shi2020graph,luo2020deep}. To conduct accurate breast mass segmentation, Cao \textit{et al.} \cite{cao2020uncertainty} introduce uncertainty into the temporal ensembling model by using uncertainty maps as guidance for the neural network to ensure the reliability of generated predictions. Similarly, Luo \textit{et al.} \cite{luo2020deep} propose an uncertainty-aware temporal ensembling to learn from external partially labeled data for chest X-ray screening. Instead of directly feeding the augmented version of sample $x_i$ into neural networks, Gyawali \textit{et al.} \cite{gyawali2019semi} employ a VAE model to firstly extract the disentangled latent space and use it as stochastic embedding for the model input, leading to improved temporal ensembling in chest X-ray classification. During the training process of temporal ensembling, the activation of each training sample is only updated once in one epoch. By implementing exponentially moving average on model parameters rather than network activations, \textbf{Mean teacher} \cite{tarvainen2017mean} overcomes this disadvantage and has been applied in the MIA field as well \cite{li2020transformation,yu2019uncertainty,wang2020double,xu2023ambiguity,adiga2023anatomically}. \cite{li2020transformation} is a typical application of the mean teacher model in MIA, which utilizes this model to conduct transformation-consistent medical image segmentation. However, with no ground-truth given for unlabeled training data, the output of the teacher model can be inaccurate and noisy. Yu \textit{et al.} \cite{yu2019uncertainty} incorporate an uncertainty map with the mean teacher model to ensure the reliability of targets generated by the teacher. Similar idea can be found in \cite{adiga2023anatomically}. Wang \textit{et al.} \cite{wang2020double} further improve uncertainty-aware methods for segmentation of the left atrium and kidney by proposing a double-uncertainty-weighted method, which extends segmentation uncertainty to feature level uncertainty. While Xu \textit{et al.} \cite{xu2023ambiguity} put emphasis on boosting the performance of Mean teacher model via selecting productive unsupervised consistency targets. In their work, a simple-yet-effective ambiguity-consensus mean-teacher model is proposed to better exploit the complementary informative clues from unlabeled data. 

\subsection{Hybrid Methods}
A burgeoning Semi-SL research direction is to combine the aforementioned types of methods together and unify them into a holistic framework for better performance \cite{wang2021deephybrid, zhang2022boostmis, wang2020focalmix}. These are called hybrid methods in this survey. For example, Wang \textit{et al.} \cite{wang2021deephybrid} and Zhang \textit{et al.} \cite{zhang2022boostmis} combine consistency regularization with self-training to solve medical image classification problems. Besides, Mixup \cite{zhang2017mixup} has been utilized frequently as an effective data augmentation strategy in hybrid methods. In \cite{gyawali2020semi}, the authors implement Mixup on both input and latent space to create more sample-label pairs based on both labeled and unlabeled data to facilitate medical image classification. By leveraging Mixup and focal loss, Wang \textit{et al.} \cite{wang2020focalmix} improve MixMatch \cite{berthelot2019mixmatch}, which is a combination of consistency regularization and pseudo-labeling, in the filed of 3D medical image detection. By leveraging multiple Semi-SL methods, the model is able to learn the underlying invariant features and meanwhile empowered with a strong predictive capability.

\subsection{Discussion}
Various unlabeled data inclusion and regularization approach lead to numerous Semi-SL methods. Many research efforts are devoted to generating pseudo labels for unlabeled data to enrich the training dataset, during which the measurement of pseudo labels' quality and confidence plays an essential role. In addition, other researchers aim to leverage the unlabeled data to learn the distribution of real data such as generative methods or learn a model with robust prediction ability such as consistency regularization methods. Establishing a theoretical foundation for this process is also a critical area of study, albeit with limited research efforts to date, as highlighted in Miao \textit{et al.} \cite{miao2023caussl}. Further, an open problem for Semi-SL is how to ensure the model performs well when input unlabeled data are noisy, \textit{i.e.}, to learn task-specific and perturbation-invariant features. Besides, a burgeoning research direction is to combine various Semi-SL methods to maximize the exploitation and utilization of unlabeled data and boost MIA tasks.