\section{Conclusion and Future Work}
We present a framework for learning an auto-regressive motion planner (ARMP) to generate physically plausible motion plans for various tasks and environments. We describe how we construct a motion library using a trajectory optimization method. We then illustrate how the motion planner generates physically feasible trajectories via deep learning while following high-level commands using an autoregressive manner. Our evaluation results show that the proposed ARMP can produce a variety of physically feasible motions, including walking, turning, jumping, and stair climbing. Finally, we show that the learned motion planner can be used for complex indoor navigation tasks, such as navigating to goals on different floors or goals behind an obstacle that can not go around, which is not impossible for wheeled robots.

While our work shows promising results, it is still challenging to collect the required trajectories in the motion library due to the difficulty of tasks and the complexity of environments. For instance, it is not straightforward to solve a jumping motion using trajectory optimization, which makes us retarget the captured motion of a real dog. In another example, the environment can be too complex to consider all the possible scenarios, such as stepstones with various gaps or densely populated obstacles. We can approach these challenges by developing a better low-level trajectory optimization module or adaptively sampling the environments based on the learning progress.

If the motion library becomes larger and larger, our learning-based motion planner may not be possible to learn all the trajectories in the database. In this case, it may generate inaccurate trajectories with poor physics or diverged behaviors. One possible solution is to increase the size of the network or to introduce a new architecture that has better consideration of spatial and temporal relationships between frames. We will leave this to our future work.
