% Chapter 2

\chapter{Preliminaries} % Main chapter title

\label{Chapter2} % For referencing the chapter elsewhere, use \ref{Chapter2} 

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 

%---------------------------------------------------------------------------------------- 

In this Chapter we present notations for spaces with their properties and a general variational setting, recalling the Banach-Ne$\breve{c}$as-Babu$\breve{s}$ka Theorem and the Lax-Milgram Lemma.

All the normed spaces that we will consider in the thesis will be real vector spaces. Hence, we are not going to specify this, except for the cases where it is preferable to underline.

In the whole work, for a real value $T>0$, $(0,T)$ is a time interval. 

\section{Sobolev spaces in $(0,T)$}\label{sec sobolev}
In this section we recall some useful Sobolev spaces that we will consider from now on.

With the usual notations, for $p \in \mathbb{N}$, the Hilbert space $H^{p}(0,T)$ is the Sobolev space of (classes of) real-valued functions endowed with the inner product $\langle \cdot, \cdot \rangle_{H^p(0,T)}$ and the induced norm $||\cdot||_{H^p(0,T)}$, i.e.
\begin{gather*}
	H^p(0,T):=\{u \in L^2(0,T): \ \partial^m_t u \in L^2(0,T) \ \forall \ 0\leq m \leq p \},\\
	\langle u,v \rangle_{H^p(0,T)}:=\int_{0}^{T} u(t)v(t) \ dt + \sum_{m=1}^{p} \int_0^T \partial^m_t u(t)\partial^m_t v(t) \ dt, \quad u,v \in H^p(0,T).
\end{gather*}
Also, we will consider the seminorm
\begin{equation*}
	|u|_{H^p(0,T)}:=\sqrt{\int_0^T (\partial^p_t u(t))^2 \ dt}, \quad u \in H^p(0,T).
\end{equation*}

Since $H^1(0,T) \subset AC([0,T])$, the space of absolutely continuous functions, see (\cite{Brezis2011}), we can define the following subspaces of $H^1(0,T)$ 
\begin{gather*}
	H^1_{0,*}(0,T)=\{u \in H^1(0,T): \ u(0)=0\},\\
	H^1_{*,0}(0,T)=\{u \in H^1(0,T): \ u(T)=0\},
\end{gather*}
endowed with the Hilbertian norm
\begin{gather*}
	\|u\|_{H^1_{0,*}(0,T)}:=|u|_{H^1(0,T)}=\|\partial_t u\|_{L^2(0,T)},\\
	\|v\|_{H^1_{*,0}(0,T)}:=|v|_{H^1(0,T)}=\|\partial_t v\|_{L^2(0,T)},
\end{gather*}
for $u \in H^1_{0,*}(0,T)$ and for $v \in H^1_{*,0}(0,T)$.

Clearly, for $1 \leq p \leq q$, $H^q(0,T) \subset H^p(0,T)$ with a continuous embedding, thus we can also define the following spaces
\begin{gather*}
H^p_{0,*}(0,T)=\{u \in H^p(0,T): \ u(0)=0\},\\
H^p_{*,0}(0,T)=\{u \in H^p(0,T): \ u(T)=0\}.
\end{gather*}

Let $\delta \in \mathbb{R}$, with $\delta >T$. Recalling that the space $C^{\infty}_{c}(0,\delta)$ is dense in $H^1_0(0,\delta)$, the set
\begin{equation*}
	C^{\infty}_c(0,T]:=\{\phi_{|(0,T]}: \ \phi \in C^{\infty}_{c}(0,\delta)\}
\end{equation*}
is dense in $H^1_{0,*}(0,T)$. Let $\eta \in \mathbb{R}$, with $\eta<0$. Analogously,  the set 
\begin{equation*}
	C^{\infty}_c[0,T):=\{\phi_{|[0,T)}: \ \phi \in C^{\infty}_{c}(-\eta,T)\}
\end{equation*}
is dense in $H^1_{*,0}(0,T)$.


In $H^1_{0,*}(0,T)$ and $H^1_{*,0}(0,T)$ there hold inequalities of Poincaré type with sharp constants, see Lemma 3.4.5 of (\cite{Zank2020}), i.e., for all $u \in H^1_{0,*}(0,T)$ and $v \in H^1_{*,0}(0,T)$, there hold
\begin{equation}\label{Poinc}
	\|u\|_{L^2(0,T)} \leq \frac{2T}{\pi} \|\partial_{t}u\|_{L^2(0,T)} \quad \text{and} \quad \|v\|_{L^2(0,T)} \leq \frac{2T}{\pi} \|\partial_{t}v\|_{L^2(0,T)},
\end{equation}
and the constants in these inequalities are sharp. Thus, $\|\cdot\|_{H^1(0,T)}$ and \\ $|\cdot|_{H^1(0,T)}$ are equivalent Hilbertian norm in $H^1_{0,*}(0,T)$ and in $H^1_{*,0}(0,T)$.

\begin{oss}
	The estimates \eqref{Poinc} are more accurate (by a factor of about $0.1$) than those proposed in (\cite{Steinbach2019}). Therefore, the estimate proven by using \eqref{Poinc} are slightly different from those in (\cite{Steinbach2019}).  
\end{oss}


The dual spaces $[H^1_{0,*}(0,T)]'$ and $[H^1_{*,0}(0,T)]'$ are Hilbert spaces, and they can be characterised as completions of $L^2(0,T)$ with respect to their dual Hilbertian norm, see (\cite{wloka1987partial}).\\ \bigskip


\section{Spline spaces over a real  interval}\label{sec splines} 
In this Chapter we will give a brief overview of B-splines and of the most common spline spaces, all seen in the simple case of one-dimensional domains, which are the subjects of interest of Chapter \ref{ch 3}. Our main references are (\cite{de1978practical, schumaker2007spline, Hllig2013ApproximationAM}) and Chapter 1 of (\cite{chapter1}). Note that there is a lot of literature on splines, given to the fact that they have application in several branches of the sciences.

First of all, let us remark that splines, in one- or plus- dimensional cases, in the broad sense of the term, are functions consisting of pieces of smooth functions glued together in a certain smooth way. The most popular species is the one where the pieces
are algebraic polynomials and inter-smoothness is imposed by means of equality of derivatives up to a given order. This species is the one of interest for isogeometric analysis, and is therefore the one we will consider in this Chapter in the one-dimensional case.

\subsubsection{Univariate B-splines}
The concept of knot vector is essential to define univariate B-splines.
\begin{definizione}
	A knot vector (or knot sequence) $\Xi$ is a nondecreasing sequence of real numbers,
	\begin{equation*}
	\Xi := \{\xi_i\}_{i=1}^m=\{\xi_1\leq \ldots \leq \xi_m\}, \quad m \in \mathbb{N}_{>0}.
	\end{equation*} 
The elements $\xi_i$ are called knots and, if $\xi_1 \neq \xi_m$, the nondecreasing distinct knots are called break points.
\end{definizione}

Provided that $m \geq p+2$, we can define univariate B-splines of degree $p$ over the knot vector $\Xi$.

\begin{definizione}
	Suppose for a nonnegative integer $p$ and some integer $j$ that $\xi_j \leq \ldots \leq \xi_{j+p+1}$ are $p+2$ real numbers taken from a knot vector $\Xi$. The $j$-th B-spline of degree $p$ is defined recursively by
	\begin{equation}\label{cox de boor}
	b_{j,p,\Xi}(x):=\begin{cases} \frac{x-\xi_j}{\xi_{j+p}-\xi_j} b_{j,p-1,\Xi}(x)+\frac{\xi_{j+p+1}-x}{\xi_{j+p+1}-\xi_{j+1}}b_{j+1,p-1,\xi}(x) \quad x \in [\xi_j,\xi_{j+p+1})\\
	0 \quad \text{otherwise}
	\end{cases}
	\end{equation}
	starting with
	\begin{equation*}
	b_{i,0,\Xi}(x):=\begin{cases}
	1 \quad x \in [\xi_i,\xi_{i+1}),\\
	0 \quad \text{otherwise},
	\end{cases}
	\end{equation*}
	where we adopt the convention $0/0=0$.
\end{definizione}
Formula \eqref{cox de boor} is known as \textit{Cox-de Boor recursion formula}. \\ \bigskip 

Let us underline the following properties. For a proof and for more details on B-splines properties we refer to Chapter 1 of (\cite{chapter1})
\begin{itemize}
	\item For degree $0$ the B-spline $B_{i,0,\Xi}$ is simply the characteristic function of the half open interval  $[\xi_i;\xi_{i+1})$, if $\xi_{i} \neq \xi_{i+1}$.
	\item A B-spline is right-continuous.
	\item A B-spline is locally supported on the interval given by the extreme
	knots used in its definition, i.e., supp($b_{j,p,\Xi}$) $\subseteq [\xi_j,\xi_{j+p+1}]$ is a compact subinterval of $[\xi_j,\xi_{j+p+1}]$.
	\item A B-spline is nonnegative everywhere, and positive in the interior part of its
	support (if $\xi_{j+p+1} \neq \xi_j$), i.e.,
	\begin{gather*}
	b_{j,p,\Xi}(x) \geq 0 \quad \forall x \in \mathbb{R},\\
	b_{j,p,\Xi}(x) > 0 \quad \forall x \in (\xi_j,\xi_{j+p+1}).
	\end{gather*}
	\item A B-spline $b_{j,p,\Xi}$ has a piecewise polynomial structure of degree less then or equal to $p$ over the subintervals defined by the knots.
	\item We say that a knot has multiplicity $m$ if it occurs exactly $m$ times in the knot sequence. If $\xi$ is a knot of $b_{j,p,\Xi}$ of multiplicity $m \leq p+1$, then 
	\begin{equation*}
	b_{j,p,\Xi} \in C^{p-m}(\xi),
	\end{equation*}
	i.e., its derivatives of order $0,\ldots,p-m$ are continuous at $\xi$, and $C^{-1}(\xi)$ denotes discontinuity at $\xi$. In particular, the maximal regularity at knots is $C^{p-1}$.
\end{itemize}

\begin{figure}[h]	
	\centering
		\includegraphics[scale=0.65]{Figures/B-splines}
		\caption{Several examples of B-splines of degree $p = 1,2,3$ respectively. The knot positions are visualized by vertical dotted lines. The same knot vector is chosen for the different degrees, with only simple knots, i.e., with knots with multiplicity equal to 1.}
\end{figure}

\subsubsection{Spline spaces}

Let $n>p \geq 0$ be two integers and let 
\begin{equation}\label{knot vector basis}
\Xi := \{\xi_i\}_{i=1}^{n+p+1}=\{\xi_1\leq \ldots \leq \xi_{n+p+1}\},
\end{equation}
be a given knot vector. This knot sequence allows us to define a set of $n$ B-splines of degree $p$, i.e.,
\begin{equation*}
\{ b_{1,p,\Xi}, \ldots, b_{n,p,\Xi}\}.
\end{equation*}

We are now interested in considering a family of B-splines which is a basis of the space of piecewise polynomials of degree $p$ on the intervals defined by the break points of the knot vector $\Xi$. Since the B-splines we are going to consider are restricted to the interval $[\xi_{p+1},\xi_{n+1}]$, we define the B-splines to be left continuous at the right endpoint, in order to avoid an asymmetry. Namely, we require that its value at $\xi_{n+1}$ is obtained by taking limits from the left:
\begin{equation*}
b_{j,p,\Xi}(\xi_{n+1}):=\lim_{x \rightarrow \xi_{n+1}^{-}} b_{j,p,\Xi}(x), \quad j=1,\ldots,n.
\end{equation*}

\begin{definizione}
The knot vector \eqref{knot vector basis} is said to be open on an interval $[a,b]$ if it satisfies
\begin{equation*}
a=\xi_1=\ldots=\xi_{p+1} < \xi_{p+2} \leq \ldots \leq \xi_n < \xi_{n+1} = \ldots = \xi_{n+p+1}=b.
\end{equation*}
\end{definizione}
	From now on we will simply say \textit{open knot vector} without specifying the defining range $[a,b]$, except in cases where we are interested in underling the defining domain.
\begin{oss}
	The B-splines $\{ b_{1,p,\Xi}, \ldots, b_{n,p,\Xi}\}$ defined by an open knot vector $\Xi$ satisfy the following properties:
	\begin{itemize}
		\item \textbf{Partition of unity}: 
		\begin{equation*}
		\sum_{i=1}^n b_{i,p,\Xi}(x)=1, \quad \forall x \in [\xi_{p+1},\xi_{n+1}].
		\end{equation*}
		\item \textbf{Interpolation property}: $b_{1,p,\Xi}$ and $b_{n,p,\Xi}$ are interpolatory at $\xi_{p+1}$ and $\xi_{n+1}$ respectively, i.e.,
		\begin{gather*}
		b_{1,p,\Xi}(\xi_{p+1})=1,\\
		b_{n,p,\Xi}(\xi_{n+1})=1.
		\end{gather*} 
		\item \textbf{Linear independence}: they are linearly independent on $[\xi_{p+1},\xi_{n+1}]$.
	\end{itemize}		 
\end{oss}

\begin{figure}[h]	
	\centering
	\includegraphics[scale=0.65]{Figures/Open}
	\caption{The B-spline basis of degree $p = 3$ on an open knot sequence. The knot positions are visualized by vertical dotted lines. The interior knots are simple, i.e., their multiplicity is equal to 1.}
\end{figure}

Let $\Delta$ be a sequence of real numbers:
\begin{equation}\label{delta}
\Delta:=\{\eta_0 < \eta_1 < \ldots < \eta_{l+1}\}.
\end{equation}
Furthermore, let $\mathbf{r}:=(r_1,\ldots,r_l)$ be a vector of integers such that $-1 \leq r_i \leq p-1$ for $i = 1,\ldots,l$. The space $S_p^{\mathbf{r}}(\Delta)$ of piecewise
polynomials of degree p with smoothness $\mathbf{r}$ over the partition \eqref{delta} is defined by
\begin{equation}\label{pol tratti}
\begin{split}
S_p^{\mathbf{r}}(\Delta):= \{ s: [\eta_0, \eta_{l+1}] \rightarrow \mathbb{R} \ | \ s \in \mathbb{P}_p([\eta_i, \eta_{i+1})) \ i=0,\ldots,l-1&, \ \\s \in \mathbb{P}_p([\eta_l, \eta_{l+1}]), \ s \in C^{r_i}(\eta_i)  \ i =1,\ldots,l \}.
\end{split}
\end{equation}

\begin{theorem}[\cite{chapter1}]
	The piecewise polynomial space \eqref{pol tratti} is characterized in terms of B-splines by
	\begin{equation}\label{spline space}
	S_p^{\mathbf{r}}(\Delta)= \text{span}\{b_{i,p,\Xi}\}_{i=1}^n,
	\end{equation}
	where $\Xi:=\{\xi_1\leq \ldots \leq \xi_{n+p+1}\}$ is an open knot sequence with $n:=\text{dim}(S_p^{\mathbf{r}}(\Delta))$ such that 
	\begin{equation*}
	\xi_1=\ldots=\xi_{p+1}:=\eta_0, \quad \xi_{n+1}=\ldots=\xi_{n+p+1}:=\eta_{l+1},
	\end{equation*}
	and
	\begin{equation*}
	\xi_{p+2},\ldots,\xi_{n}:=\overset{p-r_1}{\overbrace{\eta_1,\ldots,\eta_1}}, \ldots, \overset{p-r_l}{\overbrace{\eta_l,\ldots,\eta_l}}.
	\end{equation*}
\end{theorem}

The space \eqref{spline space} is called \textit{spline space}. We will denote it by $S^p_\Xi([\xi_{p+1},\xi_{n+1}])$ in the case of $C^{p-1}$ global regularity, or with $S^p_h([\xi_{p+1},\xi_{n+1}])$, where $h$ is defined as $h:=\max{\{|\xi_{i+1}-\xi_i|\ : \ i=1,\ldots,n+p+1}\}$. Our choice will depend on which notation is most convenient for the case we consider.

\begin{definizione}
	The coefficients of the B-splines generating the spline space are called control points or degrees of freedom. The elements in \eqref{spline space} are also called B-spline curves.
\end{definizione}

Let us note that an affine transformation of a B-spline curve is obtained by applying the transformation to control points (\cite{isogeoCAD}). This is one of the many reasons why these curves are widely used in Computer-Aided Design (CAD).

\begin{oss}
In general, control points do not interpolate B-spline curves in knots. Instead, extremal control points interpolate B-spline curves at the extremal knots $\xi_{p+1}$ and $\xi_{n+1}$.
\end{oss}

\begin{oss}
	In this section on spline spaces we could have followed a more general treatment, instead of considering only open knot vectors. This was not of interest to us, since open knot vectors are the ones used in CAD and isogeometric analysis. See (\cite{chapter1}) if you are interested in a more general discussion.
\end{oss}


\section{Variational methods}

\subsection{Well-posedness of abstract problems}
In this Section we introduce an abstract variational problem and determine the conditions under which this problem is well-posed. The main references of this Section are Chapter 2 of (\cite{lect2}) and (\cite{saito2018notes}). 

Let $V$ and $W$ be two vector spaces endowed with norms $\|\cdot\|_V$ and $\|\cdot\|_W$. Let $a: W \times V \rightarrow \mathbb{R}$ be a given bounded bilinear form and let $\mathcal{F} \in V'$. Let us consider the following abstract variational problem
\begin{equation}\label{pbl var}
\begin{cases}
\text{Find} \ u \in W \ \text{such that}\\
a(u,v)=\langle \mathcal{F},v\rangle_{V', V} \quad \forall v \in V.
\end{cases}
\end{equation}
$W$ is called the \textit{solution space} and $V$ is called the \textit{test space}.

\begin{oss}
	A significant question is: what do we mean by \textbf{solution} of a partial differential equation (PDE)? One could ask for the PDE of order k to be solved pointwise by one (or more) functions of class $C^k$, or even by one (or more) of class $C^\infty$: in this case the solution(s) is (are) called classical or strong solution(s). However, in general, solutions to relevant problems are not so regular. Therefore, the concept of a weak solution is introduced for a given PDE and, if necessary, its regularity is studied. Typically, the variational formulation \eqref{pbl var} results from the weak formulation of PDEs. Consider, for example, the Poisson problem:
	\begin{equation*}
	\begin{cases}
	-\Delta u(x) = f(x) \quad x \in \Omega\\
	u(x) = 0 \quad x \in \partial{\Omega},
	\end{cases}
	\end{equation*}
	where $\Omega \subset \mathbb{R}^n$ is an open bounded Lipschitz domain. By integration by part, its weak formulation reads as follows
	\begin{equation}\label{poiss var}
	\begin{cases}
	\text{Find} \ u \in H^1_0(\Omega) \quad \text{such that}\\
	\langle \nabla u, \nabla v \rangle_{L^2(\Omega)} = \langle f, v \rangle_\Omega \quad \forall v \in H^1_0(\Omega),
	\end{cases}
	\end{equation}
	where $f \in H^{-1}(\Omega)$ is given. In particular, in \eqref{poiss var}, the bilinear form is defined as
	\begin{gather*}
	a: H^1_0(\Omega) \times H^1_0(\Omega) \longrightarrow \mathbb{R} \quad \text{s.t.}\\
	a(u,v)=\langle \nabla u, \nabla v \rangle_{L^2(\Omega)} \quad \forall (u,v) \in H^1_0(\Omega) \times H^1_0(\Omega).
	\end{gather*}
	
\end{oss}

\begin{definizione}[Hadamard]
	Problem \eqref{pbl var} is said to be well-posed if it
	admits one and only one solution and if the following a priori estimate holds:
	\begin{equation}\label{stab}
		\exists C>0: \ \forall \mathcal{F} \in V', \ \|u\|_{W} \leq C \|\mathcal{F}\|_{V'}.
	\end{equation}
\end{definizione}

\begin{oss}
	The notion of well-posedness of a problem captures many of the desirable characteristics for a solution of a PDE. In particular, condition \eqref{stab} is very important for problems arising from physical applications. Indeed, it is clearly preferable that the solution has a ``little'' change when the specific conditions of the problem have ``little'' changes.
\end{oss}
\begin{oss}
	A bounded, linear operator $\mathcal{A}: W \rightarrow V'$ is associated with the bounded bilinear form $a(\cdot,\cdot)$ by setting
	\begin{equation*}
		\langle \mathcal{A}u,v \rangle_{V', V}:=a(u,v), \quad u \in W, v \in V.
	\end{equation*}
	Therefore, problem \eqref{pbl var} amounts to seeking $u \in W$ such that $\mathcal{A}u=\mathcal{F}$ in $V'$.
	
	The two following statements are equivalent:
	\begin{itemize}
		\item The variational problem \eqref{pbl var} is well-posed.
		\item The bounded linear operator $\mathcal{A}: W \rightarrow V'$ associated with the continuous bilinear form $a(\cdot,\cdot)$ is an isomorphism.
	\end{itemize}

Also, every bounded, linear operator $\mathcal{A}: W \rightarrow V'$ defines a bounded bilinear form $a: W \times V \rightarrow \mathbb{R}$ by setting
\begin{equation*}
a(u,v):=\langle \mathcal{A}u,v \rangle_{V', V}, \quad u \in W, v \in V.
\end{equation*}
\end{oss}
\hspace{0.2cm} 
\\
\textbf{The Banach-Ne$\mathbf{\breve{c}}$as-Babu$\mathbf{\breve{s}}$ka Theorem}. This Theorem gives \textit{necessary and sufficient} conditions for the well-posedness of \eqref{pbl var}.
\begin{theorem}[Banach-Ne$\mathbf{\breve{c}}$as-Babu$\mathbf{\breve{s}}$ka, (\cite{saito2018notes})]\label{BNB}
	Let $(W,\|\cdot\|_W)$ be a real Banach space, let $(V,\|\cdot\|_V)$ be a real reflexive, Banach space. Then the following statements are equivalent:
	\begin{itemize}
		\item[1.] The variational problem \eqref{pbl var} is well-posed.
		\item[2.] For the bounded bilinear form $a: W \times V \rightarrow \mathbb{R}$ there hold:
		\begin{itemize}
			\item There exists a constant $\beta >0$ such that
			\begin{equation}\label{infsup}
			\inf_{u \in W} \sup_{v \in V} 
			\frac{a(u,v)}{\|u\|_W \|v\|_V} \geq \beta.
			\end{equation}
			\item For each $v \in V$,
			\begin{equation}\label{non null}
			(\forall u \in W, \ a(u,v)=0) \Longrightarrow (v=0)
			\end{equation}
		\end{itemize}
		\item[3.] There exist two constants $\beta, \gamma >0$ such that
		\begin{gather*}
			\inf_{u \in W} \sup_{v \in V} 
			\frac{a(u,v)}{\|u\|_W \|v\|_V} \geq \beta,\\
			\inf_{v \in V} \sup_{u \in W} 
			\frac{a(u,v)}{\|u\|_W \|v\|_V} \geq \gamma.
		\end{gather*}
	\end{itemize}
\end{theorem}

Condition \eqref{infsup} is usually called the \textit{inf-sup} condition or the \textit{Babu$\breve{s}$ka-Brezzi} condition.

\begin{oss}
	The following statements hold:
	\begin{itemize}
		\item Given $V$ and $W$ two real normed spaces, condition \eqref{infsup} is expressed equivalently as
		\begin{equation*}
			\exists \beta>0: \ \beta \|u\|_W \leq \sup_{v \in V} 
			\frac{a(u,v)}{\|v\|_V} \quad \forall u \in W.
		\end{equation*}
		\vspace{0.5cm} \\
		Under the assumptions of Theorem \ref{BNB}:
		\item The well-posedness of \eqref{pbl var} is satisfied with
		\begin{equation*}
			\|u\|_{W} \leq  \frac{1}{\beta} \|\mathcal{F}\|_{V'}.
		\end{equation*}
		In general, given $V$ and $W$ two normed spaces, if \eqref{pbl var} admits unique solution for every $\mathcal{F} \in V'$, then condition \eqref{stab} is equivalent to \eqref{infsup} with $\beta = \frac{1}{C}$.
		\item We can translate conditions \eqref{infsup}, \eqref{non null} into conditions for the linear operator $\mathcal{A}(\cdot)$, see (\cite{lect2}). \\ 
		\begin{gather*}
			\eqref{infsup} \Longleftrightarrow (\ker{(\mathcal{A})}=\{0\} \ \text{and} \ \text{Im}(\mathcal{A}) \ \text{is closed}) \Longleftrightarrow (\mathcal{A}^{*} \ \text{is surjective}),\\ 
			\eqref{non null} \Longleftrightarrow (\ker{(\mathcal{A}^*)}=\{0\}) \Longleftrightarrow (\mathcal{A}^* \ \text{is injective}),
		\end{gather*}
		where $\mathcal{A}^*$ is the adjoint operator of $\mathcal{A}$. \vspace{0.3cm} \\
		In general, given $X$ and $Y$ two real normed vector spaces and a linear operator $\mathcal{A}: X \rightarrow Y$, if $\mathcal{A}$ is invertible, then the adjoint operator of $\mathcal{A}$ is invertible and satisfies $(\mathcal{A}^*)^{-1}=(\mathcal{A}^{-1})^*$, see (\cite{adjoint}) for the case of Hilbert spaces (the generalisation of the results to the case of any normed space is straightforward). In particular, as a consequence of $(\mathcal{A}^*)^{-1}=(\mathcal{A}^{-1})^*$ and of the equality in norm between an operator and its adjoint, if $\mathcal{A}$ is isomorphism, then $\mathcal{A}^*$ is an isomorphism with the same continuity constants (also for the inverse maps). The BNB Theorem \ref{BNB} guarantees that, if $X=W$ is a real Banach space, and $Y=V'$, with $V$ that is a real reflexive Banach space, the reverse is also true, i.e., if $\mathcal{A}^*$ is an isomorphism, then $\mathcal{A}$ is an isomorphism.
		\item The well-posedness of the adjoint problem 
		\begin{equation*}
		\begin{cases}
		\text{Find} \ v \in V \ \text{such that}\\
		a(u,v)=\langle \mathcal{G},u\rangle_{W', W} \quad \forall u \in W,
		\end{cases}
		\end{equation*}
		where $\mathcal{G} \in W'$,
		is equivalent to $\mathcal{A}^*$ being an isomorphism.
	\end{itemize}
\end{oss}
\hspace{0.2cm} 
\\
\textbf{The Lax-Milgram Lemma}. Consider the case where the solution space and the test space are identical Hilbert spaces. Thus, the abstract variational problem has the following formulation:
\begin{equation}\label{pbl var lm}
\begin{cases}
\text{Find} \ u \in V \ \text{such that}\\
a(u,v)=\langle \mathcal{F},v\rangle_{V', V} \quad \forall v \in V
\end{cases}
\end{equation}
The Lax-Milgram Lemma gives \textit{sufficient} conditions under which problem \eqref{pbl var lm} is well-posed.
\begin{lemma}[Lax-Milgram]\label{lax-milgram}
	Let $V$ be a Hilbert space, let $a: V \times V \rightarrow \mathbb{R}$ be a bounded bilinear form. Assume that $a(\cdot,\cdot)$ is coercive, i.e, 
	\begin{equation}\label{coerc}
	\exists \alpha >0: \ \forall u \in V, \ a(u,u)\geq \alpha \|u\|_V^2.
	\end{equation}
	Let $\mathcal{F} \in V'$. Then problem \eqref{pbl var} is well-posed with the following a priori estimate
	\begin{equation*}
		\|u\|_V \leq \frac{1}{\alpha} \|\mathcal{F}\|_{V'}.
	\end{equation*}
\end{lemma}

The Lax-Milgram Lemma can be viewed as a Corollary of the Banach-Ne$\breve{c}$as-Babu$\breve{s}$ka Theorem, since the coercivity of $a(\cdot,\cdot)$ implies statement $2$ of Theorem \ref{BNB}.

\begin{lemma}\label{LM then BNB}
	The coercivity condition \eqref{coerc} implies conditions \eqref{infsup}, \eqref{non null} of the BNB Theorem. 
\end{lemma}
\begin{proof}
	Let $u \in V$. Condition \eqref{infsup} is immediately deduced from
	\begin{equation*}
		\alpha \|u\|_V \overset{\eqref{coerc}}\leq \frac{a(u,u)}{\|u\|_V} \leq \sup_{v \in V} \frac{a(u,v)}{\|v\|_V}.
	\end{equation*}
	Let now $v \in V$. As a consequence of coercivity there hold
	\begin{equation*}
		\sup_{u \in V} a(u,v) \geq a(v,v) \overset{\eqref{coerc}} \geq \alpha \|v\|_V^2.
	\end{equation*}
	Therefore, $\sup_{u \in V} a(u,v)=0$ implies $v=0$, i.e., \eqref{non null}.
\end{proof}

\begin{oss}
	The reversal of Lemma \ref{LM then BNB} is wrong, i.e., \eqref{coerc} is not equivalent to the well-posedness of \eqref{pbl var lm}. However, when the bilinear form $a(\cdot,\cdot)$ is symmetric and positive, coercivity is equivalent to well-posedness, see (\cite{lect2}).
\end{oss}

\subsection{Galerkin method}\label{galerkin method}
Let $W_h$ be a finite-dimensional subspace of $W$ and $V_h$ be a finite-dimensional subspace of $V$. The Galerkin method constructs an approximation of the solution $u$ of the abstract variational problem \eqref{pbl var} by solving the following problem
\begin{equation}\label{galerkin petrov}
\begin{cases}
\text{Find} \ u_h \in W_h \ \text{such that}\\
a(u_h,v_h)=\langle \mathcal{F}_{|V_h},v_h\rangle_{V_h', V_h} \quad \forall v_h \in V_h.
\end{cases}
\end{equation}
$W_h$ is called the \textit{solution space} or the \textit{trial space}, whereas $V_h$ is called the \textit{test space}. If the trial space and the test space are the same, the Galerkin method is the following problem:
\begin{equation}\label{galerkin bubnov}
\begin{cases}
\text{Find} \ u_h \in V_h \ \text{such that}\\
a(u_h,v_h)=\langle \mathcal{F}_{|V_h},v_h\rangle_{V_h', V_h} \quad \forall v_h \in V_h.
\end{cases}
\end{equation}
Typically, the former is called \textit{Galerkin-Petrov method}, whereas the latter is called \textit{Galerkin-Bubnov method}.

\begin{oss}
	We can also consider $W_h$ and $V_h$ as closed subspaces of $W$ and $V$ respectively, but, for the numerical approximation of $u$, we are interested in finite-dimensional subspaces of the trial and test spaces.
\end{oss}

We are interested in investigating the well-posedness of the approximate problems \eqref{galerkin petrov}, \eqref{galerkin bubnov}, in proving a stability condition, i.e., a uniform (w.r.t a numerical parameter $h$ indexing the discrete spaces) a priori estimate \eqref{stab} for the discrete problem, and convergence results (w.r.t $h$) of the discrete solution to the abstract one. Let us begin by considering the first and second questions. The following Proposition is straightforward.
\begin{prop}
	If the variational problem \eqref{pbl var lm} satisfies Lax-Milgram hypothesis, then the variational problem \eqref{galerkin bubnov} is well-posed. In particular, for all $\mathcal{F} \in V'$ the stability estimate $\|u_h\|_V \leq \frac{1}{\alpha} \|\mathcal{F}\|_{V'}$ holds.
\end{prop}
\begin{proof}
	We can apply Lax-Milgram Lemma \ref{lax-milgram} since the bilinear form $a(\cdot,\cdot)$ is coercive in $V_h$.
\end{proof}

In general, instead, there is no guarantee that conditions \eqref{infsup}, \eqref{non null} of the BNB Theorem are automatically transferred from the abstract problem to the approximate problem. Thanks to the BNB Theorem, the well-posedness of \eqref{galerkin petrov} is equivalent to the following discrete conditions:
\begin{itemize}
	\item There exists a constant $\beta_h >0$ such that
	\begin{equation}\label{infsup discreta}
	\inf_{u_h \in W_h} \sup_{v_h \in V_h} 
	\frac{a(u_h,v_h)}{\|u_h\|_{W_h} \|v_h\|_{V_h}} \geq \beta_h.
	\end{equation}
	\item For each $v_h \in V_h$,
	\begin{equation}\label{non null discreta}
	(\forall u_h \in W_h, \ a(u_h,v_h)=0) \Longrightarrow (v_h=0)
	\end{equation}
\end{itemize}
Condition \eqref{infsup discreta} is usually called \textit{discrete inf-sup} condition.
\begin{oss}
	In many cases, the subscript $h$ denotes the mesh-size of the discretization and, in general, we are interested in proving an a priori estimate \eqref{stab} for the discrete problem that is independent of $h$. Hence, the discrete inf-sup condition \eqref{infsup discreta} is not sufficient for the desired stability, if no information on the value of $\beta_h$ is available.
\end{oss}

\begin{oss}\label{remark discrete system}
	Evaluating the bilinear form $a(\cdot,\cdot)$ and the linear operator $\mathcal{F}(\cdot)$ on the basis functions of the spaces $W_h$ and $V_h$, we obtain a linear system that is equivalent to the general approximate problem \eqref{galerkin petrov}, see (\cite{lect2}). We use the notation $\mathbf{A}$ for the system matrix, which will be refer to as the \textit{stiffness matrix}. \\
	There hold the following statements.
	\begin{itemize}
		\item[1.] The well-posedness of the approximate problem is equivalent to non-singularity of  $\mathbf{A}$.
		\item[2.] If the abstract bilinear form $a(\cdot,\cdot)$ of problem \eqref{pbl var lm} is coercive, $\mathbf{A}$ is positive definite, i.e., defined $M:=\text{dim}(V_h)$, there holds 
		\begin{multline*}
		(\exists \alpha >0: \ \forall u \in V, \ a(u,u) \geq \alpha \|u\|_V^2) \Longrightarrow\\
		(\forall X \in \mathbb{R}^M, \ (\mathbf{A}X,X) \geq 0 \ \text{and} \ ((\mathbf{A}X,X)=0 \Longleftrightarrow X=0) ).
		\end{multline*}
		\item[3.] If $a(\cdot,\cdot)$ is symmetric, $\mathbf{A}$ is symmetric.
		\item[4.] Condition \eqref{infsup discreta} is equivalent to $\ker{(A)}=\{0\}$, i.e., to the injectivity of $\mathbf{A}$.
		\item[5.] Condition \eqref{non null discreta} is equivalent to rank$(\mathbf{A})=$dim$(V_h)$, i.e., to the surjectivity of $\mathbf{A}$.
		\item[6.] If dim$(V_h)=$ dim$(W_h)$, \eqref{infsup discreta} is equivalent to \eqref{non null discreta}.
	\end{itemize}
	For a proof we refer to (\cite{lect2}).
\end{oss}
\vspace{0.3cm} 
Let us now consider the convergence of the discrete solution to the abstract solution. In this connection, we recall some classic results.
\begin{lemma}[Galerkin orthogonality]
	Let $u$ be the solution of the general abstract problem \eqref{pbl var} and $u_h$ be the solution of the general approximate problem \eqref{galerkin petrov}, then there holds
	\begin{equation}\label{gal ort}
		a(u-u_h,v_h)=0 \quad \forall v_h \in V_h.
	\end{equation}
\end{lemma}
\begin{proof}
	This is immediate using the bilinearity of $a(\cdot,\cdot)$.
\end{proof}

\begin{lemma}[Céa]\label{céa}
	Let the hypothesis of Lax-Milgram Lemma \ref{lax-milgram} be satisfied. Assuming $u$ is the solution of \eqref{pbl var lm} and $u_h$ is the solution of \eqref{galerkin bubnov}, then the following estimate holds
	\begin{equation}\label{céa bound}
		\|u-u_h\|_V \leq \frac{C_a}{\alpha} \inf_{v_h \in V_h} \|u-v_h\|_V,
	\end{equation}
	where $C_a$ is the continuity constant of $a(\cdot,\cdot)$.
\end{lemma}
\begin{proof}
	Let $v_h \in V_h$. As a consequence of coercivity, bilinearity, continuity and Galerkin ortogonality there hold
	\begin{equation*}
		\begin{split}
			\alpha \|u-u_h\|^2 &\overset{\eqref{coerc}}\leq a(u-u_h,u-u_h) \\
			&=a(u-u_h,u-v_h+v_h-u_h)\\
			&=a(u-u_h,u-v_h)+a(u-u_h,v_h-u_h) \quad \text{(bilinearity of $a(\cdot,\cdot)$)}\\
			&\overset{\eqref{gal ort}}=a(u-u_h,u-v_h)\\
			&\leq C_a \|u-u_h\|_V\|u-v_h\| \quad \text{(continuity of $a(\cdot,\cdot)$)}.
		\end{split}
	\end{equation*}
\end{proof}

\begin{oss}
	Note that \eqref{céa bound} is a quasi-optimality estimate. Typically, a quasi-optimality bound is an important result, since, according to that, the error committed by the Galerkin method depends on two terms. The first one, which is $\frac{C_a}{\alpha}$ in this case, is a stability term: it is only related to the continuous problem. The second one, i.e., the best approximation error $\inf_{v_h \in V_{h}} \|u-v_h\|_V$, measures how well the discrete space is able to approximate the solution $u$. In particular, if $(V_h)_h$ are dense in $V$, i.e., if
	\begin{equation*}
	 \inf_{v_h \in V_{h}} \|u-v_h\|_V \underset{h \rightarrow 0}{\longrightarrow} 0 \quad \forall u \in V,
	\end{equation*}
	estimate \eqref{céa bound} tells us that we eventually reach convergence.
\end{oss}

In the Banach-Ne$\mathbf{\breve{c}}$as-Babu$\mathbf{\breve{s}}$ka setting, quasi-optimality estimates are also obtained.

Let us assume that the general abstract problem \eqref{pbl var} is well-posed. We denote by $C_a$ the continuity constant of the bilinear form $a(\cdot,\cdot)$. Let us suppose that the discrete problem \eqref{galerkin petrov} satisfies the two BNB conditions \eqref{infsup discreta}, \eqref{non null discreta}, and that the discrete inf-sup condition is independent of the index $h$ (this is the case of greatest interest), and we denote it by $\beta_{dis}$. The following result holds.

\begin{prop}\label{err BNB}
	Assuming $u$ is the solution of \eqref{pbl var lm} and $u_h$ is the solution of \eqref{galerkin petrov}, then the following quasi-optimality estimate holds
	\begin{equation*}
	\|u-u_h\|_W \leq \Bigg[1+\frac{C_a}{\beta_{dis}}\Bigg]\inf_{w_h \in W_h}\|u-w_h\|_W,
	\end{equation*}
	where $C_a$ is the continuity constant of $a(\cdot,\cdot)$ and $\beta_{dis}$ is the inf-sup uniform constant of the discrete problem \eqref{galerkin petrov}.
\end{prop}

\begin{proof}
	For any $w \in W$ we define $w_h:= G_h w \in W_h$ as the Galerkin projection satisfying 
	\begin{equation*}
	a(G_hw,v_h)=a(w, v_h) \quad \forall v_h \in V_h,
	\end{equation*}
	which is well defined thanks to the well-posedness of the discrete problem. Hence, by using the stability estimate \eqref{infsup discreta} with $\beta_{dis}$ and the continuity of $a(\cdot,\cdot)$ with $C_a$, there hold
	\begin{equation*}
	\begin{split}	
	\beta_{dis}\|G_hw\|_{W}  
	&\leq \sup_{0 \neq v_h \in V_h} \frac{a(G_hw, v_h)}{\|v_h\|_{V}} \quad \text{(discrete infsup)}\\
	&=\sup_{0 \neq v_h \in V_h} \frac{a(w, v_h)}{\|v_h\|_{V}}\\
	 &\leq  C_a\|w\|_{W} \quad \text{(boundness of $a(\cdot,\cdot)$)}.
	 \end{split}	
	\end{equation*}
	Since $u_h=G_h u$ and $w_h = G_h w_h$ for all $w_h \in W_h$, we conclude
	\begin{equation*}
	\begin{split}
	\|u-u_h\|_{W} &\leq \|u-w_h\|_{W}+\|G_h(w_h-u)\|_{W} \\
	& \leq \Bigg[ 1 + \frac{C_a}{\beta_{dis}} \Bigg] \|u-w_h\|_{W}.
	\end{split}
	\end{equation*}
\end{proof}

\section{Preliminaries on compact perturbations}\label{sec prel ode}
In this Section we recall the definitions of two important classes of bounded linear operators between Hilbert spaces, emphasizing the most important properties that will be useful in Chapter \ref{ch 3}. The main references of this Section are (\cite{sayas, Brezis2011, var_techniques, moiola}). 
\begin{definizione}[Compact operator]
	Let $H_1$ and $H_2$ be two Hilbert (or Banach) spaces. A bounded linear operator $K: H_1\rightarrow H_2$ is compact if the image of a bounded sequence admits a converging subsequence, i.e., the image of a bounded set in $H_1$ is pre-compact in $H_2$.
\end{definizione} 

\begin{definizione}[Fredholm operator]\label{fredh}
	Let $H_1$ and $H_2$ be two Hilbert spaces. A bounded linear operator $T: H_1\rightarrow H_2$ is a Fredholm operator of index 0 if it is the sum of an invertible one and a compact one.
\end{definizione} 
\begin{oss}
	Actually, definition \ref{fredh} is a possible characterization of Fredholm operators of index 0. E.g. (\cite{Brezis2011}) defines $T: H_1\rightarrow H_2$ (bounded linear operator between Hilbert spaces) as Fredholm operator of $Ind(T):=dim(KerT)-dim(ImT)^\perp$ if $dim(KerT), \ dim(ImT)^\perp < \infty$. For a proof of the equivalence with this classic definition we refer to (\cite{moiola}). 
\end{oss}
Henceforth, Fredholm operators of index 0 will be refer to as Fredholm operators.

An important result is the \textit{Fredholm alternative}, which, in its simplest form, reads as follows; see (\cite{Brezis2011}).
\begin{theorem}[Fredholm alternative]\label{fredh th}
	Let $T: H_1\rightarrow H_2$ be a Fredholm operator. Then $T$ is injective if and only if it is surjective. In this case its inverse is bounded.
\end{theorem}

\begin{oss}
	Note that the boundedness of the inverse of an invertible Fredholm operator is due to the ``bounded inverse Theorem''.
\end{oss}

\begin{oss}
	In a finite dimensional setting Fredholm operators are precisely those associated to square matrices. Indeed, an invertible linear operator between finite-dimensional spaces corresponds to an invertible square matrix, and all finite-range operators are compact, since all bounded sequences of $\mathbb{R}^n$ admits converging subsequences. Thus, Theorem \ref{fredh} is an extension of the finite-dimensional case.
\end{oss}
\hspace{0.2cm}
\\
\textbf{Abstract problem and Galerkin method}. Let $H$ be an Hilbert space and $\mathcal{F} \in H'$. Let now consider the following variational problem
\begin{equation}\label{compact var}
\begin{cases}
\text{Find} \ u \in H \quad \text{such that}\\
a(u,v):=b(u,v)+d(u,v)=\langle\mathcal{F},v \rangle_{H',H} \quad \forall v \in H,
\end{cases}
\end{equation}
where:
\begin{itemize}
	\item[1.] The bilinear form $b(\cdot,\cdot)$ is bounded and coercive.
	\item[2.] The bilinear form $d(\cdot,\cdot)$ defines a compact operator $\mathcal{D}: H \rightarrow H'$ by setting
	\begin{equation*}
	\langle \mathcal{D}u,v \rangle_{H',H}:=d(u,v), \quad u,v \in H.
	\end{equation*}
	\item[3.] The linear operator $\mathcal{A}:=\mathcal{B}+\mathcal{D}: H \rightarrow H'$ associated to the bilinear form $a(\cdot,\cdot)$ is injective, where
	\begin{equation*}
	\langle \mathcal{B}u,v \rangle_{H',H}:=b(u,v) \quad u,v \in H.
	\end{equation*}
\end{itemize}
Assumptions $1$ and $2$, and Lax-Milgram Lemma \ref{lax-milgram}, ensure that the operator $\mathcal{A}$ is Fredholm. As a consequence of assumption 3 and Theorem \ref{fredh}, problem \eqref{compact var} is well-posed.

Let now consider a family of finite-dimensional subspaces $V_h \subset H$ directed in a real non-negative parameter $h \rightarrow 0$ and let $\pi_h: H \rightarrow V_{h}$ be the orthogonal projection. Let us also assume that
\begin{equation}
\pi_h u \underset{h \rightarrow 0}{\longrightarrow} u, \quad \forall u \in H,
\end{equation}
i.e., $(V_{h})_h$ is a dense discrete family of subspaces in $H$.
As in Section \ref{galerkin method}, we refer to the following problem as the Galerkin approximation of \eqref{compact var}:
\begin{equation}\label{gal comp}
\begin{cases}
\text{Find} \ u_h \in V_{h} \quad \text{such that}\\
a(u_h,v_h)=\langle\mathcal{F}_{|V_h},v_h \rangle \quad \forall v_h \in V_{h}.
\end{cases}
\end{equation}
In our work the subscript $h$ corresponds to the sequence of mesh-sizes of our discretization. 

The results that we are going to recall establish the uniform (w.r.t. $h$) well posedness of problem \eqref{gal comp}, provided the mesh-size is \textit{small enough} (Proposition 8.8 of \cite{var_techniques}). Moreover, a quasi-optimality estimate will follow.

\begin{prop}\label{prop infsup comp}
	In the hypothesis (1)-(3) for the bilinear forms, there exist two constants $C,\overline{h}>0$ such that the following inf-sup estimate holds
	\begin{equation*}
	\beta \|u_h\|_{H} \leq  \sup_{0 \neq u_h \in V_{h}} \frac{b(u_h,v_h)+d(u_h,v_h)}{\|v_h\|_H} \quad \forall u_h \in V_{h}, \ \forall h \leq \overline{h}.
	\end{equation*}
\end{prop}

\begin{oss}
	The bound on the mesh-size and the inf-sup constant are not explicit because the proof of this result is made by contradiction.
\end{oss}

\begin{cor}\label{well-pos comp dis}
	Let the hypothesis of Proposition \ref{prop infsup comp} be satisfied. Let $h \leq \overline{h}$. Then problem \eqref{gal comp} is well-posed, with the following stability estimate
	\begin{equation*}
	\|u_h\|_H \leq \frac{1}{\beta} \|\mathcal{F}\|_{H'}, \quad \mathcal{F} \in H'.
	\end{equation*}
\end{cor}
Note that Corollary \ref{well-pos comp dis} is a consequence  of Remark \ref{remark discrete system} and of BNB Theorem \ref{BNB}.
\begin{cor}\label{céa comp}
	Under the hypothesis of Proposition \ref{prop infsup comp}, let $h \leq \overline{h}$.  Then a quasi-optimality estimate holds
	\begin{equation}\label{quas opt comp}
	\|u-u_h\|_H \leq \Bigg(1+\frac{\|\mathcal{B}+\mathcal{D}\|}{\beta} \Bigg) \inf_{v_h \in V_{h}} \|u-v_h\|_H,
	\end{equation}
	where $u,u_h$ are the solutions of \eqref{compact var},\eqref{gal comp} respectively and with $\|\cdot\|$ we denote the operator norm of linear bounded maps from $H$ to $H'$. 
\end{cor}

\begin{oss}
	Note that Corollary \ref{céa comp} is a consequence of Proposition \ref{err BNB} and tells that we eventually reach convergence for $h \rightarrow 0$, since the succession of discrete spaces is dense in $H$.
\end{oss}

\subsubsection{Galerkin method applied to G\aa rding-type problems}
In this Section we consider a special case of Fredholm operators. Roughly speaking, we consider Fredholm operators whose compact perturbation we can "quantify". For these operators it is possible to have stability and error estimates with explicit constants. The theory we are interested in is that of \textit{Galerkin method applied to G\aa rding-type problems}. Our main reference are (\cite{spence14, moiola}).

Let $H$ be a real Hilbert space, $V_h \subset H$ a finite-dimensional subspace, $a(\cdot,\cdot)$ and $\mathcal{F}(\cdot)$ a bounded bilinear form and a bounded linear operator on $H$, respectively. Let us now consider the following abstract variational problem 
\begin{equation}\label{var gard}
\begin{cases}
\text{Find} \ u \in H \ \text{such that}\\
a(u,v)=\langle \mathcal{F},v\rangle_{H', H} \quad \forall v \in H,
\end{cases}
\end{equation}
and its Galerkin discretization
\begin{equation}\label{gal gard}
\begin{cases}
\text{Find} \ u_h \in V_h \ \text{such that}\\
a(u_h,v_h)=\langle \mathcal{F}_{|V_h},v_h\rangle_{V_h', V_h} \quad \forall v_h \in V_h.
\end{cases}
\end{equation}


\begin{theorem}[Galerkin method with G\aa rding inequality]\label{theo gard}
	Let $H \subset V$ be real Hilbert spaces and the inclusion be compact. Let $a(\cdot,\cdot)$ be a bounded bilinear form on $H$ with respect to a continuity constant $C_a >0$:
	\begin{equation*}
	|a(v,w)|\leq C_a \|v\|_H \|w\|_H \quad \forall v,w \in H, 
	\end{equation*}
	that satisfies the G\aa rding inequality with respect to $\alpha, C_v >0$
	\begin{equation}\label{gard}
	a(v,v) \geq \alpha \|v\|_H^2-C_V \|v\|_V^2  \quad \forall v \in H.
	\end{equation}
	Assume that the only $u_0 \in H$ such that $a(u_0,v)=0$ for all $v \in H$ is $u_0=0$ (so that the variational problem \eqref{var gard} is well-posed for any right-hand side). Let $\mathcal{F}(\cdot)$ be a bounded linear operator on H and $u$ be the solution of the variational problem \eqref{var gard}.\\
	Given $g \in V$, let $z_g \in H$ be the solution of the adjoint problem
	\begin{equation}\label{adj}
	a(v,z_g)=(g,v)_V \quad \forall v \in H,
	\end{equation}
	where $(\cdot,\cdot)_V$ is the scalar product in $V$. Let $V_h \subset H$ be a finite-dimensional subspace of H and define
	\begin{equation}\label{eta gard}
	\eta(V_h):=\sup_{0 \neq g \in V} \inf_{v_h \in V_h} \frac{\|z_g-v_h\|_H}{\|g\|_V}.
	\end{equation}
	If $\eta(V_h)$ satisfies the threshold condition
	\begin{equation}\label{cond eta}
	\eta(V_h) \leq \frac{1}{C_a} \sqrt{\frac{\alpha}{2 C_V}},
	\end{equation}
	then the Galerkin method \eqref{gal gard} is well-posed with the following stability estimate
	\begin{equation*}
	\|u_h\|_H \leq C_{stab}\Bigg(1+\frac{2C_a}{\alpha}\Bigg)\|\mathcal{F}\|_{H'},
	\end{equation*}
	where $C_{stab}$ is the stability constant of the abstract problem \eqref{var gard}, and its solution $u_h$ satisfies the quasi-optimality bound
	\begin{equation*}
	\|u-u_h\|_H \leq \frac{2 C_a}{\alpha} \inf_{v_h \in V_h} \|u-v_h\|_H.
	\end{equation*}
\end{theorem}

\begin{oss}\label{oss gard}
	Note the following facts.
	\begin{itemize}
		\item [1.] The G\aa rding inequality \eqref{gard} and the compact inclusion $H \subset V$ imply that the \textit{solution-to-data} operator $\mathcal{A}: H \rightarrow H'$,$u \mapsto a(u,\cdot)$ is Fredholm (of index $0$). For a proof we refer to (\cite{spence14}). Therefore, the assumption
		\begin{center}
			``the only $u_0 \in H$ such that $a(u_0,v)=0$ for all $v \in H$ is $u_0=0$''
		\end{center}
		implies the well-posedness of the variational problem \eqref{var gard}, since the above assumption is equivalent to the injectivity of $\mathcal{A}$. In particular we can apply Theorem \ref{fredh th}.
		\item[2.] The well-posedness of the adjoint problem \eqref{adj} (w.r.t. the dual norm $\|g\|_{H'}$, and hence w.r.t. $\|g\|_V$) is a consequence of the well-posedness of the primal problem \eqref{var gard}. Indeed, if $\mathcal{A}:H \rightarrow H'$ is an isomorphism, its adjoint operator $\mathcal{A^*}:H \rightarrow H'$ is an isomorphism, with $(\mathcal{A}^*)^{-1}=(\mathcal{A}^{-1})^*$, see (\cite{adjoint}). Also, as a consequence of $(\mathcal{A}^*)^{-1}=(\mathcal{A}^{-1})^*$, there holds $\|(\mathcal{A}^*)^{-1}\|=\|\mathcal{A}^{-1}\|$. Hence, the stability constant of the adjoint problem (w.r.t. the dual norm $\|g\|_{H'}$) is equal to the stability constant of the primal problem.
		\item [3.] The parameter $\eta(V_h)$ precisely quantify how well $V_h$ approximates the solution of the adjoint problem, whose data $g$ is an element of the larger space $V$. Thus, roughly speaking, Theorem \ref{theo gard} states that if the discrete space is sufficiently fine, the Galerkin method applied to a G\aa rding-type (well-posed) problem is well-posed, stable and quasi-optimal.
	\end{itemize}
\end{oss}
