




\section{Hyper-parameters}
\subsection{ImageNet-1K image classification}
On ImageNet-1K \cite{imagenet_cvpr, imagenet_ijcv} classification benchmark, following ConvNeXt \cite{convnext} and ConvNeXt-A trained by timm \cite{rw2019timm}, we adopt the hyper-parameters shown in Table \ref{tab:hyperparameter} to train \modelname{} at the input resolution of $224^2$ and fine-tune it at $384^2$. Our code is implemented by PyTorch \cite{pytorch} based on timm library \cite{rw2019timm}.

\subsection{Semantic segmentation}
For ADE20K \cite{ade20k} semantic segmentation, we utilize ConvNeXt as the backbone with UpNet \cite{upernet} following the configs of Swin \cite{swin}, and FPN \cite{fpn} following the configs of PVT \cite{pvt} and PoolFormer \cite{metaformer}. The backbone is initialized by checkpoints pre-trained on ImageNet-1K at the resolution of $224^2$. The peak stochastic depth rates of the \modelname{} backbone are shown in Table \ref{tab:hyperparameter_ade}. Our implementation is based on PyTorch \cite{pytorch} and mmsegmentation library \cite{mmseg2020}.


\section{Qualitative results}
Grad-CAM \cite{gradcam} is employed to visualize the activation maps of different models trained on ImageNet-1K, including RSB-ResNet-50 \cite{resnet, resnetsb}, Swin-T \cite{swin}, ConvNeXt-T \cite{convnext} and our \modelname{}-T. The results are shown in Figure \ref{fig:grad_cam}. Compared with other models, \modelname{}-T locates key parts more accurately with smaller activation areas.

\begin{table}[h]
\setlength{\tabcolsep}{4pt}
\footnotesize
\centering
\input{tables/hyperparameters}
\caption{\textbf{Hyper-parameters of \modelname{} on ImageNet-1K image classification.}
\label{tab:hyperparameter}
}
\end{table}



\begin{table}[h]
\centering
\input{tables/hyperparameters_ade20k}
\caption{\textbf{Stochasic depth rate of \modelname{} backbone with UperNet and FPN for ADE20K semantic segmentation.}
\label{tab:hyperparameter_ade}
}
\end{table}







\begin{figure*}[h]
    \centering
    \begin{subfigure}[b]{0.19\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{figures/qualitative_results/n07873807/ILSVRC2012_val_00016614_224.JPEG}
        \includegraphics[width=1\textwidth]{figures/qualitative_results/n01530575/ILSVRC2012_val_00047878_224.JPEG}
        \includegraphics[width=1\textwidth]{figures/qualitative_results/n02123045/ILSVRC2012_val_00043014_224.JPEG}
        \includegraphics[width=1\textwidth]{figures/qualitative_results/n03495258/ILSVRC2012_val_00006832_224.JPEG}
    \end{subfigure}    
    \begin{subfigure}[b]{0.19\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{figures/qualitative_results/n07873807/ILSVRC2012_val_00016614_resnet.JPEG}
        \includegraphics[width=1\textwidth]{figures/qualitative_results/n01530575/ILSVRC2012_val_00047878_resnet.JPEG}
        \includegraphics[width=1\textwidth]{figures/qualitative_results/n02123045/ILSVRC2012_val_00043014_resnet.JPEG}
        \includegraphics[width=1\textwidth]{figures/qualitative_results/n03495258/ILSVRC2012_val_00006832_resnet.JPEG}
    \end{subfigure}  
    \begin{subfigure}[b]{0.19\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{figures/qualitative_results/n07873807/ILSVRC2012_val_00016614_swin.JPEG}
        \includegraphics[width=1\textwidth]{figures/qualitative_results/n01530575/ILSVRC2012_val_00047878_swin.JPEG}
        \includegraphics[width=1\textwidth]{figures/qualitative_results/n02123045/ILSVRC2012_val_00043014_swin.JPEG}
        \includegraphics[width=1\textwidth]{figures/qualitative_results/n03495258/ILSVRC2012_val_00006832_swin.JPEG}
    \end{subfigure}  
    \begin{subfigure}[b]{0.19\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{figures/qualitative_results/n07873807/ILSVRC2012_val_00016614_convnext.JPEG}
        \includegraphics[width=1\textwidth]{figures/qualitative_results/n01530575/ILSVRC2012_val_00047878_convnext.JPEG}
        \includegraphics[width=1\textwidth]{figures/qualitative_results/n02123045/ILSVRC2012_val_00043014_convnext.JPEG}
        \includegraphics[width=1\textwidth]{figures/qualitative_results/n03495258/ILSVRC2012_val_00006832_convnext.JPEG}
    \end{subfigure}  
    \begin{subfigure}[b]{0.19\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{figures/qualitative_results/n07873807/ILSVRC2012_val_00016614_inceptionnext.JPEG}
        \includegraphics[width=1\textwidth]{figures/qualitative_results/n01530575/ILSVRC2012_val_00047878_inceptionnext.JPEG}
        \includegraphics[width=1\textwidth]{figures/qualitative_results/n02123045/ILSVRC2012_val_00043014_inceptionnext.JPEG}
        \includegraphics[width=1\textwidth]{figures/qualitative_results/n03495258/ILSVRC2012_val_00006832_inceptionnext.JPEG}
    \end{subfigure}  
    \begin{center}
    	 ~~~~~~~Input\qquad \qquad \quad RSB-ResNet-50 \cite{resnet, resnetsb} \qquad  Swin-T \cite{deit} \qquad ~~~~ ConvNeXt-T \cite{convnext} \qquad ~~ \modelname{}-T
    \end{center}  
    \caption{
        \label{fig:grad_cam} Grad-CAM \cite{gradcam} activation maps of different models trained on ImageNet-1K. The visualized images are from the validation set of ImageNet-1K. 
    }
\end{figure*}

