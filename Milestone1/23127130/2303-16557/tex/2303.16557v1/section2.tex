\section{Method}\label{sec:method}

\begin{figure*}[t]
	\centering 
     \subfigure[\label{fig:overview} ]
    {\includegraphics[width=0.35\columnwidth]{./new_figures/new_figure_overview_fixed.pdf}\hspace{1.5mm}}
    \subfigure[\label{fig:dongbin_figure_5} ]
    {\includegraphics[width=0.24\columnwidth]{./new_figures/fig_tr_overview.pdf}}
    \subfigure[\label{fig:dongbin_figure_6} ]
    {\includegraphics[width=0.3\columnwidth]
    {./new_figures/MICCAI_new_figure9_last2.pdf}}
    \caption{(a) An overview of the Sauvegrain method with SAT. (b) Token replay prevents semantic representation from vanishing by adding the regional tokens $z_0$ to class tokens from $\tilde{z}_1$ to $\tilde{z}_L$. 
    (c) Block matrix $B$ is added on attention matrix $\tilde{A}$. Thus regional bias block $D_R$, where diagonal values are RAB of each region $r$, is added to the top-right side of the attention matrix $\tilde{A}$. 
    }
    \label{fig:dongbin_figure_temp}
\end{figure*}

\subsection{Preliminary}
\subsubsection{MV-MT Vision Transformer.}
Here we describe how we train the vanilla MV-MT ViT as its variant for ordinal classification.
We adopt a hybrid vision transformer where a patch-wise projection module is replaced by a CNN encoder with an average pooling $E: \mathcal{X} \rightarrow \mathbb{R}^d$ (e.g., ResNet~\cite{resnet})
Therefore, a RoI image $x \in \mathbb{R}^{H \times W \times C}$ is processed with the embedding network: $e_r^0 = E(x_r)$, where $r \in \{1,...,R\}$ indicates the landmark index and $R=5$.

Before feeding them to the ViT, learnable \verb|[CLS]| tokens $\tilde{z}_0 := \left[\tilde{e}_1^0, \dots, \tilde{e}_R^0\right]$ are prepended to the embedded sequence of regional tokens $z_0 := \left[e_1^0, \dots, e_R^0\right]$.
A sequence of tokens $\left[\tilde{z}_0, z_{0}\right] \in \mathbb{R}^{2R \times d}$ is then fed to the ViT with $L$ encoder layers $\{h_l\}_{l=1}^L$.
For obtaining $R$ RoI predictions, we use the final \verb|[CLS]| tokens $\tilde{z}_L$ to classify the maturity scores with each RoI-specific classifier which consists single dense layer.
The detailed comparison illustrations for architectures between SV-ST, MV-ST, and MV-MT are shown in the supplementary section.

\noindent \textbf{Ordinal Classification}. To estimate the bone age of an individual, where their classes have an ordered relation, our method handles the ordinal classification.
Therefore, we adopt the mean-variance loss~\cite{mvloss} as our loss function.
In our framework, which addresses multi-view and multi-task, each region $r$ is associated with different numbers of classes (scores) $K_r$.
The maturity score probability distribution $p_r$ of the region $r$ is calculated by forwarding an embedding vector $\tilde{e}_r^L$ introduced by the last $L$-th encoder layer into a classification head $F_r(\tilde{e}_r^L)$.
Consequently, we can get the probability value for $k$-th label of the region $r$ as $p_{r,k}$ ($k\in\{1,2,...,K_r\}$).
Given a predicted probability $p_{r,k}$ value over $K_r$ possible scores and $y_r$ its ground-truth label, the mean loss $\mathcal{L}_{\mu}(x)$ for an region image $x$ is defined as:
\begin{equation}
    \label{eq:mean}
    \mathcal{L}_{\mu}(x) = \frac{1}{R} \sum_{r=1}^{R}(\mu_r - y_r)^2 = \frac{1}{R}\sum_{r=1}^{R}(\sum_{k=1}^{K_r}k*p_{r,k}-y_r)^2.
\end{equation}
We utilize the mean squared error (MSE) loss for reducing the difference between predicted mean $\mu_r=\mathbb{E}_{\hat{y} \sim p_r}\left[\hat{y}\right]$ and the underlying ground-truth score $y_r$.
Similarly, the variance loss $\mathcal{L}_{\sigma^2}(x)$ for an region image $x$ is defined as:
\begin{equation}\label{eq:var}
    \mathcal{L}_{\sigma^2}(x) = \frac{1}{R}\sum_{r=1}^{R}\sum_{k=1}^{K_r}p_{r,k}*(k-\mu_r)^2.
\end{equation}
Thus, considering the dataset size of $N$, mean loss and variance loss is calculated as $\frac{1}{N}\sum_{i=1}^{N}\mathcal{L}_{\mu}(x_i)$ and $\frac{1}{N}\sum_{i=1}^{N}\mathcal{L}_{\sigma^2}(x_i)$ respectively.
Finally our model is optimized by following total loss:
\begin{equation}\label{eq:total}
    \mathcal{L}_{total}(x) = \mathcal{L}_{ce}(x) + \lambda_{\mu} \cdot \mathcal{L}_{\mu}(x) +\lambda_{\sigma^2} \cdot \mathcal{L}_{\sigma^2}(x),
\end{equation}
where $\mathcal{L}_{ce}$ is the cross-entropy loss, coefficient $\lambda_{\mu}$ and $\lambda_{\sigma^2}$ is a hyperparameter to adjust the weight of each loss function. In our work, we have found that $\lambda_{\mu}$ and $\lambda_{\sigma^2}$ works best at 0.2 and 0.05 respectively. 


\subsection{Analysis on Anisotropic Relations between Landmarks}
When training the vanilla ViT as described above, we have observed that the attention module emphasizes excessively on inter-RoI patches.
As shown in Fig. ~\ref{fig:relevance}, olecranon has gained most of the attention from inter RoIs.
Indeed, this result can be interpreted as natural behavior when assessing bone age, as an interpretation of bone age using olecranon alone is the simple yet effective method in clinical practice \cite{dimeglio2005accuracy}.
However, to obtain a better elaborate and accurate interpretation of bone age, scores from all RoIs based on their morphology is essential to be obtained in the Sauvegrain method ~\cite{dimeglio2005accuracy}.
Thus, true correlations between maturity scores are better to be more isotropic, i.e. discrepancies are allowed for inter-landmarks but predictions on a single landmark must be identical.
To resolve the disparity between ViT and expected behaviors, we propose two modifications: (1) \textit{token replay} method that repeatedly adds patch embeddings to intermediary features with corresponding tokens, and (2) RAB, which explicitly imposes regional bias on the attention map.

\begin{figure*}[h]
    \centering 
    \subfigure[\label{fig:relevance}]{\hspace{0mm}\includegraphics[width=0.54\columnwidth]{./new_figures/MICCAI_new_figure_attentionMap.pdf}\hspace{0mm}}
    \subfigure[\label{fig:learning_curve}]{\hspace{0mm}\includegraphics[width=0.44\columnwidth]{./new_figures/MICCAI_new_figure_learning_curve.pdf}\hspace{0mm}} 
    \caption{(a) Relevance maps \cite{transformer_interpretability} visualizing attention between [CLS] and regional token (Left: vanilla ViT, Right: SAT). 
    (b) Effect of token replay on optimization and generalization (Left: loss, Right: mean absolute error).
    }
\end{figure*}


\subsection{Self-accumulative Vision Transformer}
\smalltitle{Token Replay}
Regional predictions (classification heads) do not necessarily prioritize their corresponding regional tokens.
Since each class token in the last encoder layer that is used for computing the each maturity score utilizes the self-attention mechanism with multiple regional tokens and other class tokens, their own region-specific semantic information could be hindered and mixed with other tokens. Thus, they could not preserve their own region-specific information.
In contrast, we argue that intentionally considered isotropic behavior could be efficient to improve the classification performance.
Therefore \textit{token replay} is designed to preserve region-specific signals in predicting maturity scores by ``replaying'' input regional tokens $z_0 = \left[e_1, \dots, e_R\right]$ so that $z_0$ are added to \verb|[CLS]| tokens encoding as $\tilde{z}_l = h_l \left(\left[\tilde{z}_{l-1}, z_{l-1}\right]\right) + \left[z_0, 0\right]$ at each layer $l$.
Fig. \ref{fig:dongbin_figure_5} illustrates how token replay works in each encoder layer.

Take the final features $\tilde{z}_L + z_0$ (with a slight abuse of notation) as an example used by classifier heads to predict maturity stages.
Similar to how information propagation is improved through the use of residual connections in neural networks \cite{resnet,densenet}, classification heads are guaranteed to attribute weights to regional patches.
Fig. \ref{fig:learning_curve} illustrates how token replay improves optimization and generalization, confirming the need that each \verb|[CLS]| tokens should be accentuated by intra-regional signals.


\smalltitle{Regional Attention Bias (RAB)}
Attention modules are designed to underscore more relevant query-key token pairs.
Recall the expected behavior of the maturity score prediction model is to attribute intra-regional features.
Regional predictions in attention modules as-is are not incited to prioritize their corresponding regional tokens.
Consequently, the class-regional token attention relevance scores \cite{transformer_interpretability} are observed in left Fig. \ref{fig:relevance} to be highly anisotropic conflicting with their desired behavior.

To remedy this anisotropic behavior, as shown in Fig. \ref{fig:dongbin_figure_6}, we explicitly add a matrix $B$ to each attention $\tilde{A}$ where $\tilde{A} \in \mathbb{R}^{2R \times 2R}$ denote the pre-softmax attention at a fixed layer and $B$ is a $2 \times 2$ \textit{block matrix} with $0$s on all blocks other than the second block $D_R$.
Thus, the top-right side of the matrix $B$ has values of $D_R$ which denotes the $R$-dimensional diagonal matrix.
RAB $d_r$ in $D_R$ is computed by the following equation
\begin{equation}\label{eq:rab}
    d_r = \tanh{(b_r + 1)} * 0.5.
\end{equation}
Here $b_r$ denotes the learnable scalar for each region.
By amplifying both forward and back-propagation with RAB from the beginning, intra-regional attention is emphasized throughout training. Thus, the attention to intra-landmarks is increasingly emphasized with SAT as presented in Fig. \ref{fig:relevance}.


