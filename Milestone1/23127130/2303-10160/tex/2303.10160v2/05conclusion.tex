\vspace{-1em}
In this work, we have used visual information to aid ASR EC, a method that has not been previously explored. We conducted several experiments to show that visual information can help in ASR EC, which would otherwise be hard to correct for strong baseline models like transformers or even humans without the context. We have introduced simple methods like using captions as prompts, which do not need any modification to the original architecture of transformers, and it improves the WER by upto 1.2\% over the baseline methods. Although we focused on text and visual methods in this work, we believe that incorporating audio information could further enhance our results, which we aim to explore in the future.
%in the future.