% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}

% -- my imports and commends
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue}
}
\usepackage{xcolor} % blue color
\usepackage{booktabs} % table: rules
\usepackage{multirow}
\usepackage{siunitx} % +-
\usepackage{array} % table: wr column type
\usepackage[misc]{ifsym} % Letter
\newcommand{\importantfeature}[1]{{\color{purple}\textbf{#1}}}
% 00 

\renewcommand\UrlFont{\color{blue}\rmfamily} % template requirement

\begin{document}
%
\title{Hospital Length of Stay Prediction Based on Multi-modal Data towards Trustworthy Human-AI Collaboration in Radiomics}
%
\titlerunning{Trustworthy LoS Prediction Based on Multi-modal Data}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Hubert Baniecki\inst{1, 2}\orcidID{0000-0001-6661-5364} \and
Bartlomiej Sobieski\inst{2} \and\\
Przemysław Bombiński\inst{2, 3} \and
Patryk Szatkowski\inst{2, 3} \and\\
Przemysław Biecek\inst{1, 2}\orcidID{0000-0001-8423-1823}}
%
\authorrunning{H. Baniecki et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{MI2.AI, University of Warsaw, Warsaw, Poland\\
\email{h.baniecki@uw.edu.pl} \and
MI2.AI, Warsaw University of Technology, Warsaw, Poland\\
\email{przemyslaw.biecek@pw.edu.pl} \and
Medical University of Warsaw, Warsaw, Poland
}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
\emph{To what extent can the patient's length of stay in a hospital be predicted using only an X-ray image?} We answer this question by comparing the performance of machine learning survival models on a novel multi-modal dataset created from 1235 images with textual radiology reports annotated by humans. Although black-box models predict better on average than interpretable ones, like Cox proportional hazards, they are not inherently understandable. To overcome this trust issue, we introduce time-dependent model explanations into the human-AI decision making process. Explaining models built on both: human-annotated and algorithm-extracted radiomics features provides valuable insights for physicians working in a hospital. We believe the presented approach to be general and widely applicable to other time-to-event medical use cases. For reproducibility, we open-source code and the \textsc{tlos} dataset at \url{https://github.com/mi2datalab/xlungs-trustworthy-los-prediction}.

\keywords{
explainable AI \and
survival analysis \and 
healthcare \and 
radiology \and
interpretable machine learning
}
\end{abstract}
%
%
%

\section{Introduction}

Predicting patients' hospital length of stay (LoS) is a challenging task supporting the day-to-day decisions of medical doctors and nurses~\cite{huang2013length}. For example, accurate LoS prediction can increase hospital service efficiency, cutting costs and improving patient care. Historically, white-box statistical learning methods were used to estimate the anticipated LoS~\cite{chaou2017predicting}. These provide clear reasoning behind the prediction, which is especially important in medical applications requiring stakeholders to comprehend ``Why?''~\cite{rudin2019stop}. Nowadays, advancements in machine and deep learning for healthcare provide valuable improvements in the performance of predicting LoS~\cite{muhlestein2019predicting,wen2022time,zhang2020combining}. The natural drawback of using not inherently interpretable black-box models is their complex nature~\cite{biecek2021explanatory,rudin2019stop}. Indeed, a recent systematic review on the exact topic of hospital LoS prediction concludes with a concrete statement that there are no studies on the explainability of black-box models predicting LoS~\cite{stone2022systematic}, a matter of high importance for diverse stakeholders involved in this healthcare process. Therefore in this paper, we demonstrate the applicability of explainable machine learning methods~\cite{biecek2021explanatory,krzyzinski2023survshap} in the LoS prediction task as an enabler towards trustworthy human-AI collaboration.

\subsubsection{Contribution.} We summarize our contributions as follows.
In Section \ref{sec:model-benchmark}, we introduce a novel task of hospital LoS prediction based on multi-modal X-ray data and benchmark on it machine learning survival models. To achieve this, we create the \textsc{tlos} dataset by manually annotating 1235 X-ray textual radiology reports from one of the Polish hospitals resulting in 17 interpretable features. Moreover, we include the state-of-the-art radiomics features extracted from images and critically evaluate their predictive performance.
In Section \ref{sec:model-analysis}, we put recent advancements in time-dependent explainable machine learning to practice. In that, we explain the best-performing models to gain insights into the importance of features and their effects on LoS prediction. Analysing complementary explanations leads to an improved human understanding of AI, e.g. allows discovering bias in a model, increasing trust. We conclude with a discussion on the limitations of our study and potential future work in Section~\ref{sec:discussion}.

\subsubsection{Related work.} Applying AI through machine learning to predict hospital length of stay from data is broadly studied as it has a high potential to support decision making in healthcare~\cite{stone2022systematic}. In~\cite{huang2013length}, LoS is predicted based on information from clinical treatment processes, i.e. sequences of time-point hospital events. In~\cite{chaou2017predicting}, hospital events like the number of tests and time of arrival are aggregated to quantify their importance in patient discharge. We base our analysis on clinical features impacting physician understanding of the patient's severity instead. In~\cite{muhlestein2019predicting}, machine learning models predict LoS after brain surgery using clinical features in a single-value regression task. This results in simple feature importance and effects explanations without the valuable time dimension. In~\cite{zhang2020combining}, deep learning models classify the patient staying in a hospital for longer than 7 days based on multi-modal data combining unstructured notes and tabular features. In \cite{wen2022time}, various machine and deep learning survival models are benchmarked for predicting LoS of COVID-19 patients. Both studies focus on predictive performance without explaining the models. For a broader overview of works on LoS prediction, we refer the reader to \cite{stone2022systematic}.

Contrary to the above-mentioned studies, we specifically use raw X-ray images to analyze the predictive power of radiomics features  and explain the prediction in a time-dependent manner. To achieve it, we rely on \texttt{pyradiomics} -- the state-of-the-art radiomics feature extraction tool~\cite{van2017computational} and \texttt{survex} -- a toolbox for explaining machine learning survival models~\cite{spytek2022survex} implementing among others the SurvSHAP(t) explanation method~\cite{krzyzinski2023survshap}. Related to this are works introducing alternative explanation methods to interpret time-to-event models predicting patients' survival~\cite{rad2022extracting,wang2021counterfactual}. We explain survival models predicting LoS instead.


\begin{figure}[ht]
    \centering
    \includegraphics[width=0.97\textwidth]{figures/tlos.pdf}
    \caption{Human-AI collaboration in radiomics. 
    Shortly after the X-ray examination, a physician annotates the radiology report and AI extracts features from the image. Based on this data, a time-to-event model is used to predict the hospital length of stay.
    }
    \label{fig:tlos}
\end{figure}

% \clearpage
\section{Predicting hospital length of stay using X-ray images}\label{sec:model-benchmark}

We consider a setting where LoS is predicted using time-to-event survival models instead of single-value time estimation with regression models or time-span classification. Besides giving a more holistic prediction, survival analysis naturally allows for censored observations in data, e.g. a patient was discharged from one hospital and moved to another with further information missing (see Figure \ref{fig:tlos}). 

A unique multi-modal dataset used in this study is created based on image, text and tabular data of 1235 patients from one of the Polish hospitals. The \emph{target feature} is the time between the patient's radiological examination and hospital discharge (in days, $min=1$, $median=7$, $mean=13.73$, $max=330$). Due to the high skewness of the time distribution, we model the logarithm of time in practice. About 20\% of outcomes are right-censored, e.g. due to death. 

Each radiologic exam consists of an X-ray image with a written report stating observable features, e.g. pathological signs, lung lesions and pleural abnormalities, but also the occurrence of medical devices on the image, e.g. tubing and electrocardiographic leads. We manually annotate each report into 17 interpretable binary features informing whether the pathology occurs or is absent. Note that we sampled patients at random and capped their quantity after reaching the reasonable capacity of human annotators. Moreover, we automatically extract 76 numerical features from the image using the \texttt{pyradiomics} tool~\cite{van2017computational}. It computes various statistics based on an image and a lung segmentation mask. e.g. various aggregations of the gray-level co-occurrence matrix.\footnote{A detailed description of algorithm-extracted features from \texttt{pyradiomics} is available at \url{https://pyradiomics.readthedocs.io/en/v3.0.1/features.html}.} 
A pretrained CE-Net~\cite{gu2019net} model was used to obtain lung segmentation masks inputted to \texttt{pyradiomics}. We treat it as a reasonable baseline approach while acknowledging that segmentation errors will inevitably contribute to errors in algorithm-extracted features. 

The described procedure leads to obtaining four feature sets referred to as:
\begin{itemize}
    \item \emph{baseline} (number of features: $d=2$) -- includes the patient's age and sex,
    \item \emph{human-annotated} ($d=2+17$) -- includes \emph{baseline} and pathology occurrences,
    \item \emph{algorithm-extracted} ($d=2+76$) -- includes \emph{baseline} and image statistics, 
    \item \emph{all features} ($d=2+17+76$).
\end{itemize}
We use the dataset to answer the question of interest: \emph{To what extent can the patient's length of stay in a hospital be predicted using only an X-ray image?}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.96\textwidth]{figures/model_comparison.pdf}
    \caption{Benchmark of machine learning survival models predicting LoS using features from X-ray images. Based on 10 repeats of 10-fold cross-validation, the GBDT algorithm performs best on average (marked with $\hat{\mu}_{mean}$), i.e. achieves 0.668 C-index and 0.117 IBS. In contrast to Figure \ref{fig:blackbox_whitebox_comparison}, we omit reporting \emph{p} values for significant differences as there are too many.}
    \label{fig:model_comparison}
\end{figure}

\subsubsection{Models.}  We first use all features to compare various machine learning survival models in predicting LoS using X-ray images and then evaluate the impact of particular feature sets on the best models' predictive performance. 

We perform a comprehensive benchmark of relevant learning algorithms available in the \texttt{mlr3proba} toolbox~\cite{sonabend2021mlr3proba}: a decision tree (CTree), gradient boosting decision trees (GBDT), two implementations of random survival forest (Ranger \& RF-SRC), Cox proportional hazards (CoxPH), and two implementations of neural networks (DeepSurv \& DeepHit). We use 10 repeats of 10-fold cross-validation and assess the predictive performance of survival models with two measures: C-index where higher means better performance and the baseline value of a random model equals 0.5, and Integrated Brier Score (IBS) where lower is better and the baseline value of a random model equals 0.25. The evaluation protocol mimics a benchmark of survival prediction methods described in~\cite{herrman2021benchmark}.

Figure \ref{fig:model_comparison} presents the results where models are sorted by an average C-index. First, note that most DeepHit models did not converge and provide random predictions; thus, DeepHit is removed from the comparison. We observe that, on average, the best algorithm is a gradient boosting decision tree (0.668 C-index, 0.117 IBS) with a random survival forest in second. Interestingly, the interpretable and widely-used CoxPH model performs worse (0.645 C-index, 0.127 IBS). Overall, neural networks have a hard time learning meaningful models. 

Comparing the raw performance values with results from related work leads to the conclusion that \emph{predicting the patient's LoS from an X-ray image is indeed possible}, but challenging. Possible future improvements include improving data quality and tuning the hyperparameters of learning algorithms (see Section \ref{sec:discussion}).

\begin{figure}[t]
    \centering
    \includegraphics[width=0.96\textwidth]{figures/bb_performance.pdf}
    \includegraphics[width=0.96\textwidth]{figures/wb_performance.pdf}
    \caption{Benchmark of feature sets in predicting LoS using GBDT black-box and CoxPH white-box model. The \emph{p} values mark significant differences between the averages $\hat{\mu}_{mean}$.}
    \label{fig:blackbox_whitebox_comparison}
\end{figure}

\subsubsection{Feature performance.} We now tackle the performance-interpretability tradeoff in machine learning for medicine~\cite{rudin2019stop}. Based on the benchmark results reported in Figure~\ref{fig:model_comparison}, we choose the best black-box algorithm (GBDT) to compare with CoxPH -- the widely-adopted interpretable approach to time-to-event analysis. Note that one can consider the human-annotated features as interpretable and algorithm-extracted features as a black-box approach, i.e. training the CoxPH model on algorithm-extracted features is not necessarily a white-box model. We test the two algorithms on four feature sets using the same cross-validation scheme and performance measures as the previous benchmark. 

Figure \ref{fig:blackbox_whitebox_comparison} presents the results where feature sets are sorted by an average C-index. We observe that both algorithm-extracted and human-annotated features include valuable information for predicting LoS. The only significant difference (on average) between the two sets is for the CoxPH algorithm evaluated with IBS. For GBDT, using all features results in the best performance, while for CoxPH, increasing the number of features leads to the same or worse performance due to the curse of dimensionality. 

In summary, the best-performing interpretable algorithm is CoxPH trained on human-annotated features (0.642 C-index, 0.120 IBS), and the black-box approach is GBDT trained on all features (0.668 C-index, 0.117 IBS). 
The difference in C-index is significant (\emph{p} value $< 0.001$). 
Although this difference may be neglectable in reality, CoxPH is limited by the number of features, which now rapidly increases in medical applications, e.g. in radiology where tools for feature extractions become more prevalent \cite{chaou2017predicting}. Moreover, annotating images by humans is costly, and GBDT remains more efficient with algorithm-extracted features.

% \clearpage
\section{Explaining length of stay predictions to humans}\label{sec:model-analysis}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/experimental_local_explanations}
    %\vspace{0.5em}\\
    \includegraphics[width=\textwidth]{figures/experimental_global_explanations}
    \caption{Complementary time-dependent explanations of the GBDT model trained on age, sex, and human-annotated radiomics features. These are accompanied by exemplary X-ray images of (\textbf{top}) lung disease in an adult and (\textbf{bottom}) healthy children's lungs with medical devices. \textbf{Top left}: SurvSHAP(t) local explanation for a selected patient informing about the 6 most important features and their effect on the predicted length of stay at each day since X-ray examination. \textbf{Top right}: What-if analysis for the same patient and the selected ambiguous feature, informing about how the predicted length of stay would change upon the change in feature value. \textbf{Bottom left}: Feature importance global explanation based on aggregated SurvSHAP(t) values for a subset of patients informing about the 6 most important features overall. \textbf{Bottom right}: Partial dependence global explanation for the most important feature informing about its effect on the predicted length of stay on average.}
    \label{fig:blackbox_explanations}
\end{figure}

A classic approach to the explanatory analysis of time-to-event models involves analysing the significance of the CoxPH model's coefficients. For a broader context, we use all observations in data to fit CoxPH models to the four feature sets. Table~\ref{tab:coxph} reports features with significant coefficients, effectively serving as a list of features important to predicting LoS. The main limitation of this approach is explaining only a particular learning algorithm that performs worse in the predictive task, as in our case. 

Therefore, we propose to use model-agnostic explanations to interpret the predictions of any black-box survival model predicting LoS in general. We extend the explanatory model analysis framework \cite{biecek2021explanatory} to include the SurvSHAP(t) explanation \cite{krzyzinski2023survshap}, time-dependent What-if and Partial dependence plots, all implemented in \texttt{survex} \cite{spytek2022survex}. For a concrete example, we use all observations in data and fit a GBDT model to the human-annotated feature set.

Figure \ref{fig:blackbox_explanations} presents four complementary local and global explanations providing a multi-faceted understanding of the black-box model. It is accompanied by exemplary X-ray images of lung disease and healthy lungs with medical devices. We first interpret the particular prediction for a 78-year-old male patient with parenchymal opacification in the lungs and possibly also pleural effusion. SurvSHAP(t) attributes high importance to the occurrence of parenchymal opacification, but also the absence of medical devices on the chest X-ray. In fact, the latter decreases the predicted probability of longer LoS as X-rays with observable medical devices usually indicate a severe patient condition. This image feature is a potential bias in data that later propagates to a predictive model. Next, we perform a What-if analysis for the ambiguous pleural effusion feature to explain the uncertainty in LoS prediction conditioned on this feature. Over the 60 days since the X-ray examination, there is an increased probability of staying in a hospital by 0.125 when a pleural effusion occurred (for this patient).

The bottom of Figure \ref{fig:blackbox_explanations} presents global explanations of the model's behaviour: feature importance and effects, also referred to as Partial dependence. We obtain time-dependent feature importance by aggregating absolute SurvSHAP(t) values for a representative subset of patients. The visualization indicates that the model finds the occurrence of medical devices as a proxy for LoS, which may be correlated with the patient's condition. Other important radiomics features include pleural effusion, age, parenchymal opacification, cardiac silhouette enlargement and lung mass. For each of these pathologies, a Partial dependence plot explains its aggregated effect on the LoS prediction. Specifically, when medical devices occur on an image, there is an increased probability by 0.25 of staying in a hospital 20 days after the X-ray examination.

As illustrated here, incorporating time-dependent explanations of machine learning models predicting LoS into the existing decision support systems can provide useful information for physicians. We believe the presented approach to be general and widely applicable to other time-to-event medical use cases.

\begin{table}
    \centering
    \caption{Coefficients of only significant features (\emph{p} value $<0.05$) in the CoxPH models fitted to all observations and the four feature sets. For example, the CoxPH model fitted on age and sex of 1235 patients relies on age, not sex to make the prediction. A detailed description of algorithm-extracted features with their acronyms is available at \url{https://pyradiomics.readthedocs.io/en/v3.0.1/features.html}.} 
    \label{tab:coxph}
    \begin{tabular}{llwr{2cm}wr{1.5cm}}
      \toprule
    \textbf{Feature set} & \textbf{Feature name} & \textbf{Estimate} & \emph{p} \textbf{value} \\ 
      \midrule
    baseline ($d=2$) & Age & $0.007_{\pm 0.001}$ & 0.000 \\ 
      \midrule
    \multirow{6}{3cm}{baseline with human-annotated features ($d=2+17$)} 
        & Parenchymal opacification & $-0.194_{\pm 0.081}$ & 0.016 \\ 
      & Pleural effusion & $-0.334_{\pm 0.084}$ & 0.000 \\ 
      & Medical devices & $-0.628_{\pm 0.083}$ & 0.000 \\ 
      & Lung mass & $-0.311_{\pm 0.142}$ & 0.029 \\ 
      & Reticular pattern & $-0.397_{\pm 0.156}$ & 0.011 \\ 
      & Global atelectasis & $-0.430_{\pm 0.216}$ & 0.046 \\ 
        \midrule
     \multirow{12}{3cm}{baseline with algorithm-extracted features ($d=2+76$)} 
        & Shape--Maximum2DDiameterSlice & $-1.547_{\pm 0.512}$ & 0.003 \\ 
      & Firstorder--Entropy & $422.9_{\pm 161.1}$ & 0.009 \\ 
      & GLCM--ID & $-325.9_{\pm 140.0}$ & 0.020 \\ 
      & GLCM--IDN & $1000_{\pm 425.7}$ & 0.019 \\ 
      & GLCM--IMC1 & $296.4_{\pm 85.14}$ & 0.000 \\ 
      & GLCM--InverseVariance & $93.89_{\pm 43.39}$ & 0.030 \\ 
      & GLCM--JointEntropy & $-533.5_{\pm 177.5}$ & 0.003 \\ 
      & GLDM--DependenceEntropy & $156.7_{\pm 57.70}$ & 0.007 \\ 
      & GLDM--LGLE & $-120.9_{\pm 49.07}$ & 0.014 \\ 
      & GLRLM--GLNN & $-497.3_{\pm 207.2}$ & 0.016 \\ 
      & GLRLM--LRE & $6.213_{\pm 2.180}$ & 0.004 \\ 
      & GLSZM--SALGLE & $-694.2_{\pm 283.6}$ & 0.014 \\ 
    \midrule
      \multirow{20}{3cm}{all features ($d=2+17+76$)} 
        & Pleural effusion & $-0.385_{\pm 0.095}$ & 0.000 \\ 
      & Medical devices & $-0.389_{\pm 0.101}$ & 0.000 \\ 
      & Chest wall subcutaneous emphysema & $0.354_{\pm 0.180}$ & 0.049 \\ 
      \cmidrule[0.125pt]{2-4}
      & Shape--Maximum2DDiameterRow & $0.730_{\pm 0.313}$ & 0.020 \\ 
      & Shape--Maximum2DDiameterSlice & $-1.531_{\pm 0.536}$ & 0.004 \\ 
      & Firstorder--Entropy & $407.0_{\pm 165.3}$ & 0.014 \\ 
      & Firstorder--Range & $-4.361_{\pm 1.858}$ & 0.019 \\ 
      & GLCM--ID & $-358.4_{\pm 142.8}$ & 0.012 \\ 
      & GLCM--IDN & $926.6_{\pm 438.3}$ & 0.034 \\ 
      & GLCM--IMC1 & $274.2_{\pm 87.89}$ & 0.002 \\ 
      & GLCM--InverseVariance & $94.82_{\pm 44.86}$ & 0.035 \\ 
      & GLCM--JointEntropy & $-517.9_{\pm 182.2}$ & 0.004 \\ 
      & GLDM--DependenceEntropy & $185.9_{\pm 59.69}$ & 0.002 \\ 
      & GLDM--LGLE & $-136.8_{\pm 50.56}$ & 0.007 \\ 
      & GLRLM--GLNN & $-606.7_{\pm 211.5}$ & 0.004 \\ 
      & GLRLM--LRE & $6.261_{\pm 2.176}$ & 0.004 \\ 
      & GLSZM--SALGLE & $-581.1_{\pm 288.6}$ & 0.044 \\ 
      & NGTDM--Busyness & $1.252_{\pm 0.606}$ & 0.039 \\ 
      & NGTDM--Complexity & $1.406_{\pm 0.625}$ & 0.024 \\ 
       \bottomrule
    \end{tabular}
\end{table}

% \clearpage
\section{Discussion} \label{sec:discussion}

\subsubsection{Details of human annotation.} The original raw dataset includes X-ray images and textual radiology reports, which were manually annotated by two board-certified radiologists. First, we developed a project-specific ontology of chest pathologies that can be observed on X-ray images. It compiles information from the selected relevant radiology literature~\cite{hansell2008fleischner}, existing ontologies like RadLex~\cite{radlex}, and popular X-ray databases available online (CheXpert, MIMIC, VinBigData challenge). Second, we identified problems in our reports related to, e.g. ambiguous interpretations of phrases in the radiological reports, differences in the quality and length of descriptions prepared by different physicians and for different types of examinations (like follow-up or comparison to previous examinations). We fixed them by updating the ontology in accordance with the domain knowledge. As a result, a set of 35 classes was obtained. Finally, we chose the 17 most common features, i.e. with more than 3\% occurrence among patients, for further analysis in this study. Although we are yet unable to share X-ray images and textual reports due to privacy concerns, the preprocessed \textsc{tlos} dataset with further documentation and code to reproduce our results is available at \url{https://github.com/mi2datalab/xlungs-trustworthy-los-prediction}. We hope this resource can spark further research on trustworthy LoS prediction. 

\subsubsection{Limitations.} First, the segmentation model used to obtain masks for feature extraction propagates errors to LoS predictions, and it can be improved if the final goal of a study would be a definitive evaluation of those features. Tuning the hyperparameters of survival models is also an option. Moreover, physicians and other stakeholders interpreting predictions need to understand that the presented explanations are only an approximation of the black-box model~\cite{rudin2019stop}. One needs to be sure that stakeholders properly interpret these visualizations.

\subsubsection{Future work.} A natural future direction can be to improve the dataset and models for a more accurate LoS prediction. While this paper proposes explaining LoS predictions for knowledge discovery, e.g. importance of features, future work could address external evaluation of human-AI collaboration in a hospital. 


{\small 
\subsubsection{Acknowledgements.} This work was financially supported by the Polish National Center for Research and Development grant number INFOSTRATEG-I/0022/2021-00, and carried out with the support of the Laboratory of Bioinformatics and Computational Genomics and the High Performance Computing Center of the Faculty of Mathematics and Information Science, Warsaw University of Technology.
}


\bibliographystyle{splncs04}
\bibliography{cameraready}

\end{document}
