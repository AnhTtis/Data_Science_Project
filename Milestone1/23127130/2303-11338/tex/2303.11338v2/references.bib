@IEEEtranBSTCTL{IEEEexample:BSTcontrol,
  CTLuse_forced_etal       = "yes",
  CTLmax_names_forced_etal = "6",
  CTLnames_show_etal       = "1" 
}

@ARTICLE{wang2022generalizing,
  author={Wang, Jindong and Lan, Cuiling and Liu, Chang and Ouyang, Yidong and Qin, Tao and Lu, Wang and Chen, Yiqiang and Zeng, Wenjun and Yu, Philip},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  title={Generalizing to Unseen Domains: A Survey on Domain Generalization},
  year={2022},
  volume={},
  number={},
  pages={1-1},
  doi={10.1109/TKDE.2022.3178128}}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  month={May},
  year={2015},
  publisher={Nature Publishing Group},
  doi={10.1038/nature14539}
}

@ARTICLE{he2016deep,
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title={Deep Residual Learning for Image Recognition},
  year={2016},
  volume={},
  number={},
  pages={770-778},
  doi={10.1109/CVPR.2016.90}
}

@inproceedings{ballascinc2022,
  title={Listen to your heart: A self-supervised approach for detecting murmur in heart-beat sounds},
  author={Ballas, Aristotelis and Papapanagiotou, Vasileios and Delopoulos, Anastasios and Diou, Christos},
  booktitle={2022 Computing in Cardiology (CinC)},
  volume={49},
  year={2022},
  organization={IEEE},
  notes={In Press}
}

@article{mckinney_international_2020,
	title = {International evaluation of an {AI} system for breast cancer screening},
	volume = {577},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	doi = {10.1038/s41586-019-1799-6},
	language = {en},
	number = {7788},
	journal = {Nature},
	author = {McKinney, Scott Mayer and Sieniek, Marcin and Godbole, Varun and Godwin, Jonathan and Antropova, Natasha and Ashrafian, Hutan and Back, Trevor and Chesus, Mary and Corrado, Greg S. and Darzi, Ara and Etemadi, Mozziyar and Garcia-Vicente, Florencia and Gilbert, Fiona J. and Halling-Brown, Mark and Hassabis, Demis and Jansen, Sunny and Karthikesalingam, Alan and Kelly, Christopher J. and King, Dominic and Ledsam, Joseph R. and Melnick, David and Mostofi, Hormuz and Peng, Lily and Reicher, Joshua Jay and Romera-Paredes, Bernardino and Sidebottom, Richard and Suleyman, Mustafa and Tse, Daniel and Young, Kenneth C. and De Fauw, Jeffrey and Shetty, Shravya},
	month = jan,
	year = {2020},
	keywords = {Breast cancer, Preclinical research},
	pages = {89--94},
}

@article{krizhevsky2017imagenet,
  title={{ImageNet} classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Communications of the ACM},
  volume={60},
  number={6},
  pages={84--90},
  month={June},
  year={2017},
  publisher={AcM New York, NY, USA}
}

@article{vaswani2017attention,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 volume = {30},
 year = {2017}
}

@article{he2015delving,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1026--1034},
  year={2015},
  doi={10.1109/ICCV.2015.123}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  month={February},
  year={2015},
  publisher={Nature Publishing Group},
  doi={10.1038/nature14236}
}

@InProceedings{recht2019imagenet,
  title = 	 {Do {I}mage{N}et Classifiers Generalize to {I}mage{N}et?},
  author =       {Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {5389--5400},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {June},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/recht19a/recht19a.pdf},
}

@article{zhou2022domainold,
  title={Domain generalization: A survey},
  author={Zhou, Kaiyang and Liu, Ziwei and Qiao, Yu and Xiang, Tao and Loy, Chen Change},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2022},
  publisher={IEEE}
}

@ARTICLE{zhou2022domain,
  author={Zhou, Kaiyang and Liu, Ziwei and Qiao, Yu and Xiang, Tao and Loy, Chen Change},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title={Domain Generalization: A Survey},
  year={2022},
  volume={},
  number={},
  pages={1-20},
  doi={10.1109/TPAMI.2022.3195549}}

@article{blanchard2011generalizingold,
  title={Generalizing from several related classification tasks to a new unlabeled sample},
  author={Blanchard, Gilles and Lee, Gyemin and Scott, Clayton},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@inproceedings{blanchard2011generalizing,
 author = {Blanchard, Gilles and Lee, Gyemin and Scott, Clayton},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Shawe-Taylor and R. Zemel and P. Bartlett and F. Pereira and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Generalizing from Several Related Classification Tasks to a New Unlabeled Sample},
 volume = {24},
 year = {2011}
}

@article{alday_classification_2020,
	title = {Classification of 12-lead {ECGs}: the {PhysioNet}/{computing} in {cardiology} {challenge} 2020},
	volume = {41},
	doi = {10.1088/1361-6579/abc960},
	abstract = {Objective: Vast 12-lead ECGs repositories provide opportunities to develop new machine learning approaches for creating accurate and automatic diagnostic systems for cardiac abnormalities. However, most 12-lead ECG classification studies are trained, tested, or developed in single, small, or relatively homogeneous datasets. In addition, most algorithms focus on identifying small numbers of cardiac arrhythmias that do not represent the complexity and difficulty of ECG interpretation. This work addresses these issues by providing a standard, multi-institutional database and a novel scoring metric through a public competition: the PhysioNet/Computing in Cardiology Challenge 2020. Approach: A total of 66 361 12-lead ECG recordings were sourced from six hospital systems from four countries across three continents; 43 101 recordings were posted publicly with a focus on 27 diagnoses. For the first time in a public competition, we required teams to publish open-source code for both training and testing their algorithms, ensuring full scientific reproducibility. Main results: A total of 217 teams submitted 1395 algorithms during the Challenge, representing a diversity of approaches for identifying cardiac abnormalities from both academia and industry. As with previous Challenges, high-performing algorithms exhibited significant drops (10\%) in performance on the hidden test data. Significance: Data from diverse institutions allowed us to assess algorithmic generalizability. A novel evaluation metric considered different misclassification errors for different cardiac abnormalities, capturing the outcomes and risks of different diagnoses. Requiring both trained models and code for training models improved the generalizability of submissions, setting a new bar in reproducibility for public data science competitions.},
	number = {12},
	journal = {Physiological Measurement},
	author = {Alday, Erick A. Perez and Gu, Annie and Shah, Amit J. and Robichaux, Chad and Wong, An-Kwok Ian and Liu, Chengyu and Liu, Feifei and Rad, Ali Bahrami and Elola, Andoni and Seyedi, Salman and Li, Qiao and Sharma, Ashish and Clifford, Gari D. and Reyna, Matthew A.},
	month = dec,
	year = {2020},
	publisher = {Publisher: IOP Publishing},
	pages = {124003},
}

@INPROCEEDINGS{duan_differential_2013,
  author={Duan, Ruo-Nan and Zhu, Jia-Yi and Lu, Bao-Liang},
  booktitle={2013 6th International IEEE/EMBS Conference on Neural Engineering (NER)},
  title={Differential entropy feature for {EEG}-based emotion classification},
  year={2013},
  volume={},
  number={},
  pages={81-84},
  doi={10.1109/NER.2013.6695876}}

% SEED DATASET
@article{zheng_investigating_2015,
	title = {Investigating {Critical} {Frequency} {Bands} and {Channels} for {EEG}-based {Emotion} {Recognition} with {Deep} {Neural} {Networks}},
	volume = {7},
	doi = {10.1109/TAMD.2015.2431497},
	number = {3},
	journal = {IEEE Transactions on Autonomous Mental Development},
	author = {Zheng, Wei-Long and Lu, Bao-Liang},
	year = {2015},
	pages = {162--175},
}

% SEED-GER and SEED-FRA
@article{schaefer_assessing_2010,
  title = {Assessing the effectiveness of a large database of emotion-eliciting films: A new tool for emotion researchers},
  author = {Schaefer, Alexandre and Nils, Fr{\'e}d{\'e}ric and Sanchez, Xavier and Philippot, Pierre},
  journal = {Cognition and emotion},
  volume = {24},
  number = {7},
  pages = {1153--1172},
  year = {2010},
  publisher ={Taylor \& Francis}
}

@article{liu_identifying_2022,
	title = {Identifying similarities and differences in emotion recognition with {EEG} and eye movements among {Chinese}, {German}, and {French} {People}},
	volume = {19},
	number = {2},
	journal = {Journal of Neural Engineering},
	author = {Liu, Wei and Zheng, Wei-Long and Li, Ziyi and Wu, Si-Yuan and Gan, Lu and Lu, Bao-Liang},
	year = {2022},
	pages = {26--12},
}

@inproceedings{Li_2017_ICCV,
  title={Deeper, broader and artier domain generalization},
  author={Li, Da and Yang, Yongxin and Song, Yi-Zhe and Hospedales, Timothy M},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={5542--5550},
  year={2017}
}

@inproceedings{ballassetn2022,
  author={Ballas, Aristotelis and Diou, Christos},
  title = {Multi-Layer Representation Learning for Robust {OOD} Image Classification},
  year = {2022},
  isbn = {9781450395977},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3549737.3549780},
  booktitle = {Proceedings of the 12th Hellenic Conference on Artificial Intelligence},
  articleno = {39},
  numpages = {4},
  keywords = {deep learning, domain generalization, image classification, out of distribution},
  location = {Corfu, Greece},
  series = {SETN '22}
}

@INPROCEEDINGS {9898255,
author = {A. Ballas and C. Diou},
booktitle = {2022 IEEE Eighth International Conference on Big Data Computing Service and Applications (BigDataService)},
title = {A Domain Generalization Approach for Out-Of-Distribution 12-lead {ECG} Classification with Convolutional Neural Networks},
year = {2022},
volume = {},
issn = {},
pages = {9-13},
abstract = {Deep Learning systems have achieved great success in the past few years, even surpassing human intelligence in several cases. As of late, they have also established themselves in the biomedical and healthcare domains, where they have shown a lot of promise, but have not yet achieved widespread adoption. This is in part due to the fact that most methods fail to maintain their performance when they are called to make decisions on data that originate from a different distribution than the one they were trained on, namely Out-Of-Distribution (OOD) data. For example, in the case of biosignal classification, models often fail to generalize well on datasets from different hospitals, due to the distribution discrepancy amongst different sources of data. Our goal is to demonstrate the Domain Generalization problem present between distinct hospital databases and propose a method that classifies abnormalities on 12-lead Electrocardiograms (ECGs), by leveraging information extracted across the architecture of a Deep Neural Network, and capturing the underlying structure of the signal. To this end, we adopt a ResNet-18 as the backbone model and extract features from several intermediate convolutional layers of the network. To evaluate our method, we adopt publicly available ECG datasets from four sources and handle them as separate domains. To simulate the distributional shift present in real-world settings, we train our model on a subset of the domains and leave-out the remaining ones. We then evaluate our model both on the data present at training time (intra-distribution) and the held-out data (out-of-distribution), achieving promising results and surpassing the baseline of a vanilla Residual Network in most of the cases.},
keywords = {deep learning;training;hospitals;databases;biological system modeling;computational modeling;electrocardiography},
doi = {10.1109/BigDataService55688.2022.00009},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {aug}
}

@InProceedings{pmlr-v37-ganin15,
  title = 	 {Unsupervised Domain Adaptation by Backpropagation},
  author = 	 {Ganin, Yaroslav and Lempitsky, Victor},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {1180--1189},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
}

@inproceedings{misra2020self,
  title={Self-supervised learning of pretext-invariant representations},
  author={Misra, Ishan and Maaten, Laurens van der},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6707--6717},
  year={2020}
}

@article{WANG2021339,
title = {Inter-patient {ECG} arrhythmia heartbeat classification based on unsupervised domain adaptation},
journal = {Neurocomputing},
volume = {454},
pages = {339-349},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.04.104},
author = {Guijin Wang and Ming Chen and Zijian Ding and Jiawei Li and Huazhong Yang and Ping Zhang},
}


@ARTICLE{8337789,  
author={Lan, Zirui and Sourina, Olga and Wang, Lipo and Scherer, Reinhold and Müller-Putz, Gernot R.},  
journal={IEEE Transactions on Cognitive and Developmental Systems},   
title={Domain Adaptation Techniques for {EEG}-Based Emotion Recognition: A Comparative Study on Two Public Datasets},   
year={2019},  
volume={11},  
number={1}, 
pages={85-94},  
doi={10.1109/TCDS.2018.2826840}
}

@article{yan2017learning,
  title={Learning domain-invariant subspace using domain features and independence maximization},
  author={Yan, Ke and Kou, Lu and Zhang, David},
  journal={IEEE transactions on cybernetics},
  volume={48},
  number={1},
  pages={288--299},
  year={2017},
  publisher={IEEE}
}

@article{pan2010domain,
  title={Domain adaptation via transfer component analysis},
  author={Pan, Sinno Jialin and Tsang, Ivor W and Kwok, James T and Yang, Qiang},
  journal={IEEE transactions on neural networks},
  volume={22},
  number={2},
  pages={199--210},
  year={2010},
  publisher={IEEE}
}


@inproceedings{fernando2013unsupervised,
  title={Unsupervised visual domain adaptation using subspace alignment},
  author={Fernando, Basura and Habrard, Amaury and Sebban, Marc and Tuytelaars, Tinne},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2960--2967},
  year={2013}
}


@article{weimann2021transfer,
  title={Transfer learning for {ECG} classification},
  author={Weimann, Kuba and Conrad, Tim OF},
  journal={Scientific reports},
  volume={11},
  number={1},
  pages={1--12},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{MEHARI2022105114,
title = {Self-supervised representation learning from 12-lead {ECG} data},
journal = {Computers in Biology and Medicine},
volume = {141},
pages = {105114},
year = {2022},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2021.105114},
author = {Temesgen Mehari and Nils Strodthoff},
keywords = {Deep neural networks, Electrocardiography, Time series analysis, Unsupervised learning, Self-supervised learning},
}

@article{sarkar2020self,
  title={Self-supervised {ECG} representation learning for emotion recognition},
  author={Sarkar, Pritam and Etemad, Ali},
  journal={IEEE Transactions on Affective Computing},
  year={2020},
  publisher={IEEE}
}

@ARTICLE{9154600,
  author={Zhao, He and Zheng, Qingqing and Ma, Kai and Li, Huiqi and Zheng, Yefeng},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Deep Representation-Based Domain Adaptation for Nonstationary {EEG} Classification}, 
  year={2021},
  volume={32},
  number={2},
  pages={535-545},
  doi={10.1109/TNNLS.2020.3010780}
}

@INPROCEEDINGS{8918693,
  author={Banville, Hubert and Albuquerque, Isabela and Hyvärinen, Aapo and Moffat, Graeme and Engemann, Denis-Alexander and Gramfort, Alexandre},
  booktitle={2019 IEEE 29th International Workshop on Machine Learning for Signal Processing (MLSP)}, 
  title={Self-Supervised Representation Learning from Electroencephalography Signals}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/MLSP.2019.8918693}}


@article{banville2021uncovering,
  title={Uncovering the structure of clinical {EEG} signals with self-supervised learning},
  author={Banville, Hubert and Chehab, Omar and Hyv{\"a}rinen, Aapo and Engemann, Denis-Alexander and Gramfort, Alexandre},
  journal={Journal of Neural Engineering},
  volume={18},
  number={4},
  pages={046020},
  year={2021},
  publisher={IOP Publishing}
}

@INPROCEEDINGS{9385345,
  author={Gramfort, Alexandre and Banville, Hubert and Chehab, Omar and Hyvärinen, Aapo and Engemann, Denis},
  booktitle={2021 9th International Winter Conference on Brain-Computer Interface (BCI)}, 
  title={Learning with self-supervision on EEG data}, 
  year={2021},
  volume={},
  number={},
  pages={1-2},
  doi={10.1109/BCI51272.2021.9385345}
}

@INPROCEEDINGS{9391844,
  author={Sun, Jiayao and Xie, Jin and Zhou, Huihui},
  booktitle={2021 IEEE 3rd Global Conference on Life Sciences and Technologies (LifeTech)}, 
  title={{EEG} Classification with Transformer-Based Models}, 
  year={2021},
  volume={},
  number={},
  pages={92-93},
  doi={10.1109/LifeTech52111.2021.9391844}
}

@ARTICLE{9684393,
  author={Wang, Zhe and Wang, Yongxiong and Hu, Chuanfei and Yin, Zhong and Song, Yu},
  journal={IEEE Sensors Journal}, 
  title={Transformers for {EEG}-Based Emotion Recognition: A Hierarchical Spatial Information Learning Model}, 
  year={2022},
  volume={22},
  number={5},
  pages={4359-4368},
  doi={10.1109/JSEN.2022.3144317}
}

@ARTICLE{9298838,
  author={Dissanayake, Theekshana and Fernando, Tharindu and Denman, Simon and Ghaemmaghami, Houman and Sridharan, Sridha and Fookes, Clinton},
  journal={IEEE Transactions on Biomedical Engineering}, 
  title={Domain Generalization in Biosignal Classification}, 
  year={2021},
  volume={68},
  number={6},
  pages={1978-1989},
  doi={10.1109/TBME.2020.3045720}
}


@INPROCEEDINGS{9344210,
  author={Hasani, Hosein and Bitarafan, Adeleh and Baghshah, Mahdieh Soleymani},
  booktitle={2020 Computing in Cardiology}, 
  title={Classification of 12-lead {ECG} Signals With Adversarial Multi-Source Domain Generalization}, 
  year={2020},
  volume={},
  number={},
  pages={1-4},
  doi={10.22489/CinC.2020.445}
}


@article{ganin2016domain,
  title={Domain-adversarial training of neural networks},
  author={Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, Fran{\c{c}}ois and Marchand, Mario and Lempitsky, Victor},
  journal={The journal of machine learning research},
  volume={17},
  number={1},
  pages={2096--2030},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{ma2019reducing,
  title={Reducing the subject variability of {EEG} signals with adversarial domain generalization},
  author={Ma, Bo-Qun and Li, He and Zheng, Wei-Long and Lu, Bao-Liang},
  booktitle={International Conference on Neural Information Processing},
  pages={30--42},
  year={2019},
  organization={Springer}
}

@article{arjovsky_invariant_2020,
	title = {Invariant Risk Minimization},
	abstract = {We introduce Invariant Risk Minimization (IRM), a learning paradigm to estimate invariant correlations across multiple training distributions. To achieve this goal, IRM learns a data representation such that the optimal classifier, on top of that data representation, matches for all training distributions. Through theory and experiments, we show how the invariances learned by IRM relate to the causal structures governing the data and enable out-of-distribution generalization.},
	journal = {arXiv:1907.02893 [cs, stat]},
	author = {Arjovsky, Martin and Bottou, Léon and Gulrajani, Ishaan and Lopez-Paz, David},
	month = mar,
	year = {2020},
	note = {arXiv: 1907.02893},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	},
}


@InProceedings{Zhang_2021_CVPR,
    author    = {Zhang, Xingxuan and Cui, Peng and Xu, Renzhe and Zhou, Linjun and He, Yue and Shen, Zheyan},
    title     = {Deep Stable Learning for Out-of-Distribution Generalization},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2021}
}

@InProceedings{Carlucci_2019_CVPR,
author = {Carlucci, Fabio M. and D'Innocente, Antonio and Bucci, Silvia and Caputo, Barbara and Tommasi, Tatiana},
title = {Domain Generalization by Solving Jigsaw Puzzles},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
year = {2019}
}

@inproceedings{li2018learning,
  title={Learning to generalize: Meta-learning for domain generalization},
  author={Li, Da and Yang, Yongxin and Song, Yi-Zhe and Hospedales, Timothy M},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}


@InProceedings{pmlr-v70-finn17a,
  title = 	 {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},
  author =       {Chelsea Finn and Pieter Abbeel and Sergey Levine},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  year = 	 {2017},
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
  abstract = 	 {We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.}
}


@InProceedings{10.1007/978-3-030-58607-2_12,
author="Du, Yingjun
and Xu, Jun
and Xiong, Huan
and Qiu, Qiang
and Zhen, Xiantong
and Snoek, Cees G. M.
and Shao, Ling",
title="Learning to Learn with Variational Information Bottleneck for Domain Generalization",
booktitle="Computer Vision -- ECCV 2020",
year="2020",
publisher="Springer International Publishing",
address="Cham",
abstract="Domain generalization models learn to generalize to previously unseen domains, but suffer from prediction uncertainty and domain shift. In this paper, we address both problems. We introduce a probabilistic meta-learning model for domain generalization, in which classifier parameters shared across domains are modeled as distributions. This enables better handling of prediction uncertainty on unseen domains. To deal with domain shift, we learn domain-invariant representations by the proposed principle of meta variational information bottleneck, we call MetaVIB. MetaVIB is derived from novel variational bounds of mutual information, by leveraging the meta-learning setting of domain generalization. Through episodic training, MetaVIB learns to gradually narrow domain gaps to establish domain-invariant representations, while simultaneously maximizing prediction accuracy. We conduct experiments on three benchmarks for cross-domain visual recognition. Comprehensive ablation studies validate the benefits of MetaVIB for domain generalization. The comparison results demonstrate our method outperforms previous approaches consistently.",
isbn="978-3-030-58607-2"
}

@inproceedings{huangRSC2020,
  title={Self-Challenging Improves Cross-Domain Generalization},
  author={Zeyi Huang and Haohan Wang and Eric P. Xing and Dong Huang},
  booktitle={ECCV},
  year={2020}
}

@InProceedings{10.1007/978-3-030-58542-6_5,
author="Seo, Seonguk
and Suh, Yumin
and Kim, Dongwan
and Kim, Geeho
and Han, Jongwoo
and Han, Bohyung",
title="Learning to Optimize Domain Specific Normalization for Domain Generalization",
booktitle="Computer Vision -- ECCV 2020",
year="2020",
publisher="Springer International Publishing",
address="Cham",
abstract="We propose a simple but effective multi-source domain generalization technique based on deep neural networks by incorporating optimized normalization layers that are specific to individual domains. Our approach employs multiple normalization methods while learning separate affine parameters per domain. For each domain, the activations are normalized by a weighted average of multiple normalization statistics. The normalization statistics are kept track of separately for each normalization type if necessary. Specifically, we employ batch and instance normalizations in our implementation to identify the best combination of these two normalization methods in each domain. The optimized normalization layers are effective to enhance the generalizability of the learned model. We demonstrate the state-of-the-art accuracy of our algorithm in the standard domain generalization benchmarks, as well as viability to further tasks such as multi-source domain adaptation and domain generalization in the presence of label noise.",
isbn="978-3-030-58542-6"
}

@misc{venkatesh2020calibrate,
      title={Calibrate and Prune: Improving Reliability of Lottery Tickets Through Prediction Calibration}, 
      author={Bindya Venkatesh and Jayaraman J. Thiagarajan and Kowshik Thopalli and Prasanna Sattigeri},
      year={2020},
      eprint={2002.03875},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@inproceedings{li2018domain,
  title={Domain generalization with adversarial feature learning},
  author={Li, Haoliang and Pan, Sinno Jialin and Wang, Shiqi and Kot, Alex C},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5400--5409},
  year={2018}
}

@inproceedings{sun2016return,
  title={Return of frustratingly easy domain adaptation},
  author={Sun, Baochen and Feng, Jiashi and Saenko, Kate},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={30},
  number={1},
  year={2016}
}

@inproceedings{sun2016deep,
  title={Deep coral: Correlation alignment for deep domain adaptation},
  author={Sun, Baochen and Saenko, Kate},
  booktitle={European conference on computer vision},
  pages={443--450},
  year={2016},
  organization={Springer}
}


@incollection{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
}

@article{liu_open_2018,
	title = {An Open Access Database for Evaluating the Algorithms of Electrocardiogram Rhythm and Morphology Abnormality Detection},
	volume = {8},
	issn = {2156-7018},
	doi = {10.1166/jmihi.2018.2442},
	language = {en},
	number = {7},
	urldate = {2022-05-15},
	journal = {Journal of Medical Imaging and Health Informatics},
	author = {Liu, Feifei and Liu, Chengyu and Zhao, Lina and Zhang, Xiangyu and Wu, Xiaoling and Xu, Xiaoyan and Liu, Yulin and Ma, Caiyun and Wei, Shoushui and He, Zhiqiang and Li, Jianqing and Yin Kwee, Eddie Ng},
	month = sep,
	year = {2018},
	pages = {1368--1373},
}

@article{wagner_ptb-xl_2020,
	title = {{PTB}-{XL}, a large publicly available electrocardiography dataset},
	volume = {7},
	copyright = {2020 The Author(s)},
	issn = {2052-4463},
	doi = {10.1038/s41597-020-0495-6},
	abstract = {Electrocardiography (ECG) is a key non-invasive diagnostic tool for cardiovascular diseases which is increasingly supported by algorithms based on machine learning. Major obstacles for the development of automatic ECG interpretation algorithms are both the lack of public datasets and well-defined benchmarking procedures to allow comparison s of different algorithms. To address these issues, we put forward PTB-XL, the to-date largest freely accessible clinical 12-lead ECG-waveform dataset comprising 21837 records from 18885 patients of 10 seconds length. The ECG-waveform data was annotated by up to two cardiologists as a multi-label dataset, where diagnostic labels were further aggregated into super and subclasses. The dataset covers a broad range of diagnostic classes including, in particular, a large fraction of healthy records. The combination with additional metadata on demographics, additional diagnostic statements, diagnosis likelihoods, manually annotated signal properties as well as suggested folds for splitting training and test sets turns the dataset into a rich resource for the development and the evaluation of automatic ECG interpretation algorithms.},
	language = {en},
	number = {1},
	journal = {Scientific Data},
	author = {Wagner, Patrick and Strodthoff, Nils and Bousseljot, Ralf-Dieter and Kreiseler, Dieter and Lunze, Fatima I. and Samek, Wojciech and Schaeffter, Tobias},
	month = may,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Cardiovascular diseases, Data publication and archiving, Electrocardiography – EKG, Machine learning},
	pages = {154},
	file = {Full Text PDF:C\:\\Users\\telis\\Zotero\\storage\\L42W6AFU\\Wagner et al. - 2020 - PTB-XL, a large publicly available electrocardiogr.pdf:application/pdf;Snapshot:C\:\\Users\\telis\\Zotero\\storage\\795CMUG6\\s41597-020-0495-6.html:text/html},
}


@misc{tihonenko_st-petersburg_2007,
	title = {St.-{Petersburg} Institute of Cardiological Technics 12-lead Arrhythmia Database},
	abstract = {This database consists of 75 annotated recordings extracted from 32 Holter records. Each record is 30 minutes long and contains 12 standard leads, each sampled at 257 Hz, with gains varying from 250 to 1100 analog-to-digital converter units per millivolt. Gains for each record are specified in its .hea file. The reference annotation files contain over 175,000 beat annotations in all.},
	publisher = {physionet.org},
	author = {Tihonenko, Viktor and Khaustov, Alexander and Ivanov, Sergey and Rivin, Alexei},
	year = {2007},
	doi = {10.13026/C2V88N},
	note = {Type: dataset},
}

@INPROCEEDINGS{9344053,  
  author={Natarajan, Annamalai and Chang, Yale and Mariani, Sara and Rahman, Asif and Boverman, Gregory and Vij, Shruti and Rubin, Jonathan},
  booktitle={2020 Computing in Cardiology},   
  title={A Wide and Deep Transformer Neural Network for 12-Lead {ECG} Classification},   
  year={2020},  
  volume={},  
  number={},  
  pages={1-4},  
  doi={10.22489/CinC.2020.107}
}

@article{song2018eeg,
  title={{EEG} emotion recognition using dynamical graph convolutional neural networks},
  author={Song, Tengfei and Zheng, Wenming and Song, Peng and Cui, Zhen},
  journal={IEEE Transactions on Affective Computing},
  volume={11},
  number={3},
  pages={532--541},
  year={2018},
  publisher={IEEE}
}

@article{vapnik1991principles,
	title={Principles of risk minimization for learning theory},
	author={Vapnik, Vladimir},
	journal={Advances in neural information processing systems},
	volume={4},
	year={1991}
}


@InProceedings{gulrajani2021in,
	title={In Search of Lost Domain Generalization},
	author={Ishaan Gulrajani and David Lopez-Paz},
	booktitle={International Conference on Learning Representations},
	year={2021},
}

@inproceedings{hariharan_hypercolumns_2015,
	address = {Boston, MA, USA},
	title = {Hypercolumns for object segmentation and fine-grained localization},
	isbn = {978-1-4673-6964-0},
	doi = {10.1109/CVPR.2015.7298642},
	language = {en},
	urldate = {2022-05-17},
	booktitle = {2015 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Hariharan, Bharath and Arbelaez, Pablo and Girshick, Ross and Malik, Jitendra},
	month = jun,
	year = {2015},
	pages = {447--456},
}


@article{togacar_enhancing_2021,
	title = {Enhancing of dataset using {DeepDream}, fuzzy color image enhancement and hypercolumn techniques to detection of the {Alzheimer}'s disease stages by deep learning model},
	volume = {33},
	issn = {1433-3058},
	doi = {10.1007/s00521-021-05758-5},
	language = {en},
	number = {16},
	urldate = {2022-02-15},
	journal = {Neural Comput \& Applic},
	author = {Toğaçar, Mesut and Cömert, Zafer and Ergen, Burhan},
	month = aug,
	year = {2021},
	pages = {9877--9889},
}


@inproceedings{ronneberger_u-net_2015,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	isbn = {978-3-319-24574-4},
	language = {en},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} – {MICCAI} 2015},
	publisher = {Springer International Publishing},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	editor = {Navab, Nassir and Hornegger, Joachim and Wells, William M. and Frangi, Alejandro F.},
	year = {2015},
	keywords = {Convolutional Layer, Data Augmentation, Deep Network, Ground Truth Segmentation, Training Image},
	pages = {234--241},
}


@inproceedings{huang_densely_2017,
	address = {Honolulu, HI},
	title = {Densely {Connected} {Convolutional} {Networks}},
	isbn = {978-1-5386-0457-1},
	url = {https://ieeexplore.ieee.org/document/8099726/},
	doi = {10.1109/CVPR.2017.243},
	language = {en},
	urldate = {2023-01-31},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q.},
	month = jul,
	year = {2017},
	pages = {2261--2269},
}

@InProceedings{ballasdiouattention2023,
	author = {Ballas, Aristotelis and Diou, Christos},
	title = {CNNs with Multi-Level Attention for Domain Generalization},
	year = {2023},
	isbn = {9798400701788},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	doi = {10.1145/3591106.3592263},
	location = {Thessaloniki, Greece},
	series = {ICMR '23}
}


@article{maaten_visualizing_2008,
	title = {Visualizing {Data} using t-{SNE}},
	volume = {9},
	number = {86},
	journal = {Journal of Machine Learning Research},
	author = {Maaten, Laurens van der and Hinton, Geoffrey},
	year = {2008},
	pages = {2579--2605},
}

@inproceedings{nam2021reducing,
	title={Reducing domain gap by reducing style bias},
	author={Nam, Hyeonseob and Lee, HyunJae and Park, Jongchan and Yoon, Wonjun and Yoo, Donggeun},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={8690--8699},
	year={2021}
}