

\section{Evaluating passphrases}
\label{evalsec}

\noindent Our goal is to improve upon the passphrases generated by template-based diceware by resolving its shortcomings while still not losing out on the advantages it offers. In other words, we would like to generate passphrases that are easier to remember while still being hard to guess. In this section, we will evaluate the quality of passphrases generated by \system and compare it with passphrases used by users or generated using other methods---we will compare the following five sets of passphrases:

\textbf{\dice}. \dice was proposed earlier for generating passphrases by random selecting a sequence of words from a vocabulary~\cite{reinholddiceware}. We use a wordlist commonly used as vocabulary \dice~\cite{bonneau_2018}. These passphrases are in general much harder to guess (e.g., ``clay reactive smasher authentic chrome hamster'').

\textbf{\mmap}. An improved version of \dice, where passphrases are generated based on predefined syntactic templates for the English language. The templates are composed of various parts of speech like nouns, verbs, adjectives, etc., which will be replaced with suitable words from a vocabulary segregated in a similar way \cite{mmapCode}. The passphrases generated in such a way are relatively easier to remember (e.g., ``when does a bellboy spike an elect but not a sidebar'').  

\textbf{\markov}. We also use a bigram Markov model trained on the \wiki dataset as a baseline for comparison considering that \system is an enhanced version of the former. The process of passphrase generation is similar to \system. However, we don't impose any constraints on the intermediate steps and sample words weighted on their conditional bigram probability (e.g., ``leopold arranged for some users include the war'').

\textbf{\userpp}. We identified several user-created passphrases from prior password leaks ( in~\secref{sec:usegen}). These passphrases are user-created, close to natural text and therefore, should be very easy to remember (e.g., ``just another happy ending''). 

\textbf{\ours}. Finally, we consider the model we propose --- \system~ --- which also internally uses a bigram Markov model trained on the \wiki dataset, with several control parameters to ensure the generated passphrase has higher memorability while maintaining a high guessrank (e.g., ``edge bands influenced how far north south''). Later we detail training and passphrase-generation of \system (\secref{ssec:genmodel}~and~\ref{ssec:constraints}).

We add a few random samples of passphrases from each set in Appendix~\ref{sec:passsample}. We compare the memorability of these five sets of passphrases using CER and strength using guessrank.



  




\vspace{2mm}
\noindent \textbf{Test sample.} We generated one million passphrases from template-based diceware, and following the same distribution of lengths, we generated same number of passphrases from each of \dice, \markov and \system. We use these as test sample in our evaluations. For \userpp, owing to the limited size of the dataset, we used only 6,500 user passphrases as our test sample. %
Note that the length distribution of \userpp passphrases is different from others, as users often tend to utilize passphrases of smaller lengths. We did not use the length distribution of \userpp for the system generated samples for this reason---as that would bias the test samples from \dice, \markov and \system towards smaller length passphrases.  


\subsection{Strength of the passphrases}
\label{ssec:guesseval}

We measure the strength of a passphrase based on their guessrank %
using the \textit{min auto} approach discussed in~\secref{ssec:guessability_old}. \changed{Note that we considered an offline generalized untargeted adversary as mentioned in~\secref{ssec:secandthreat}}. To compute a min-auto rank of password we take the minimum guessrank according to a number of guessrank estimations. Prior work has shown such approach provides close approximation of
real-worlds. 

We considered seven guessing algorithms for the min-auto approach: 2-gram and 3-gram word-based Markov models and  4-gram, 5-gram, 6-gram character-based  Markov model~\cite{markovProb}, Wiki-5 bigram model, and template-based guessing algorithm. We explain  last two guessing models below. 

\textbf{Probabilistic \wiki bigram Markov.} For \markov and \ours, other than training on a huge corpus of generated passphrases, an attacker can also train it on the dataset using which the passphrases are generated, namely \wiki. As a bigram Markov model is used for the generation of the passphrases in these two systems, we also use a probabilistic bigram Markov guessing model trained on the \wiki dataset. The rest of the guessrank estimation is similar to the process described above.

\textbf{Template based estimation.} An attacker can use the fact that the passphrases generated by \mmap are finitely bounded by the templates that are being used. Thus, a guessrank for a passphrase generated by the algorithm can be guessed by trying out all the possible passphrases across all templates. To simulate this process, we first find the number of passphrases each template can produce. We then randomly choose templates one by one until the source template for that passphrase is chosen (we remember the source template so that we can estimate the guessrank, it is not available to the attacker) and count all the passphrases that the attacker would have enumerated by then, which will give us the guessrank for that passphrase. This guessing strategy is particularly effective against \mmap, and limits the largest guessrank a \mmap generated passphrase can achieve. 


Recall that according to the threat model described in \secref{ssec:secandthreat}, the attacker has access to a huge corpus of passphrases generated from the system whose passphrases are being cracked. Therefore, the attacker have $10^7$ system-generated passphrases from \{\dice, \markov, \ours, \mmap\}, on which the attacker can train his cracking algorithm. For \userpp passphrases, the attacker trains on a smaller set of 70 thousand passphrases. 

This trained model is then used to guess the passphrases of the corresponding test samples. Each passphrase has a probability of generation according to a model and using the method in \secref{ssec:guessability_old}, we can estimate the guessrank that is, the number of guesses the attacker will need to guess the passphrase correctly using that particular guessing model. A smoothing factor is used for any out of vocabulary (OOV) n-grams encountered. We took the minimum guessrank across all the models as the final output. 











\begin{figure}[t]
  \includegraphics[width=6.5cm]{figures/gr_new_cropped.pdf}

  \caption{Comparing the strength of different sets of passphrases by evaluating their guessrank. Here, a cumulative distribution frequency of log guessrank (base 10) is shown. We can see that diceware passphrases are the most secure, while the user ones being the most predictable.
  }
  \label{fig:gr-all}
\end{figure}

\textbf{Results.} We show the (estimated) guessranks of the passphrases in the test samples in ~\figref{fig:gr-all}. \dice passphrases are the most secure with 50\% of passphrases requiring at least $10^{40}$ guesses. On the other end of the spectrum, we have \userpp passphrases, with 50\% of passphrases guessed within $10^{14}$ guesses, which is not even as secure as some of the most secure passwords \cite{realWorldAccuracies}. The predictability of \userpp passphrases can be somewhat attributed to their smaller length, but since that is the inherent nature of these passphrases, we did not see fit to change it. In between \userpp and \dice, we have \ours, \markov and \mmap. The security of \markov and \ours are similar, with \ours having a slight advantage over \markov in the 20\% most predictable passphrases of each set.

The main aim of \ours is to resolve the shortcoming of \mmap. Comparing these two, we see that the only advantage the latter has over the former is that the guessrank of \mmap is slightly higher than \ours for passphrases below the 40$^{\text{th}}$ percentile. These are the passphrases of a length less than 8. As we move along the curve, we observe a huge difference in the number of guesses needed by \ours and \mmap for their most secure passphrases. Template-based diceware needs $10^{22}$ guesses for at least 20\% of the passphrases, whereas \ours significantly improves upon it and requires over $10^{30}$ guesses. %



However, we argue that memorability of passphrases is another important criterion that should be considered while picking a passphrase. We discuss the memorability of passphrases next.


\subsection{Memorability of passphrases}
\label{ssec:memeval}

\noindent Passphrases must be memorable while being difficult to guess to be usable in practice. In this section, we measure the memorability of the passphrases in the test samples based on the character error rate (CER) estimate we devised in ~\secref{ssec:memorability}. CER estimates the probability of making an error while typing from memory (and not the actual \#characters that one might get wrong). 


\begin{figure}[t]
  \includegraphics[width=6.5cm]{figures/cer_new_cropped.pdf}

  \caption{Distribution (CDF) of CER (Character Error Rate) for passphrases among the various samples. \dice passphrases have the highest CER, making it the least memorable and \userpp passphrases have the lowest CER which in turn means that they are easiest to remember.}
  \label{fig:cer-new}
\end{figure}


\paragraph{Results.}  The distribution of CER of the passphrases are shown in ~\figref{fig:cer-new}. As expected, \dice passphrases have a very high CER --- 50\% passphrases have CER of more than 17\% --- meaning that users are likely to make a mistake every 6 characters they type, which indicates a very low memorability. We hypothesize the lack of any syntactic structure is responsible for such high CER.  \userpp passphrases seem to perform the best, with 80\% of the passphrases with less than 5\% CER (a mistake every 20 characters). This is within expectations, given that users, in general, choose highly common phrases, quotes, and song or movie titles.


CER values of passphrases from \ours, \markov and \mmap are between \userpp and \dice. All the three CERs are almost similar (with \mmap having a slight advantage), with each of them having a 12.5\% CER for at least 50\% of the passphrases in their corresponding samples--- significantly better than \dice, although much worse than \userpp passphrases. 




\paragraph{Takeaway.} We measure the guessrank of the passphrases using the \textit{min auto} approach employing multiple models to estimate the guessrank close to what a practical adversary might achieve. The memorability of the passphrases is determined by a commonly accepted proxy, CER.

Although we would like to increase the guessrank (decrease the guessability) of passphrases while reducing the CER, they are inversely correlated (intuitively, more structure to passphrases leads to high predictability) and thus one cannot be lowered without increasing the other. We tried to find a sweet spot that allows us to increase as much guessing resistance as possible while keeping the CER values close to what user-chosen passphrases enjoy. 

The results show that \system mitigate  the limitations of \mmap discussed in \secref{ssec:langmodel} and is potentially much more effective to use in practice. Although \dice offers significantly high security, users will also find it hard to remember, owing to its high CER. On the other end of the spectrum, while \userpp passphrases are very easy to remember, they offer little to no security. Furthermore, given the parameterized generation process of \system, one can
configure it to a setting that meets their needs, giving room to significant personalization.




















  



