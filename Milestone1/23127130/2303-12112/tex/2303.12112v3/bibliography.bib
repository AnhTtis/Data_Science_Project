@string{cvpr     = {CVPR}}
@string{cvprw    = {CVPR Workshops}}
@string{nips     = {NeurIPS}}
@string{nipsw    = {NeurIPS Workshops}}
@string{iccv     = {ICCV}}
@string{iccvw    = {ICCV Workshops}}
@string{eccv     = {ECCV}}
@string{eccvw    = {ECCV Workshops}}
@string{iclr     = {ICLR}}
@string{iclrw    = {ICLR Workshops}}
@string{bmvc     = {BMVC}}
@string{civr     = {CIVR}}
@string{acmmm    = {ACM Multimedia}}
@string{icml     = {ICML}}
@string{ecml     = {ECML}}
@string{icip     = {ICIP}}
@string{icpr     = {ICPR}}
@string{icmr     = {ICMR}}
@string{aaai     = {AAAI}}
@string{wacv     = {WACV}}
@string{emnlp    = {EMNLP}}
@string{emnlpw   = {EMNLP Workshops}}
@string{ijcai    = {IJCAI}}
@string{tdv      = {3DV}}
@string{naacl    = {NAACL}}
@string{naaclw   = {NAACL Workshops}}
@string{icra     = {ICRA}}
@string{miccai   = {MICCAI}}
@string{acl      = {ACL}}
@string{aclw     = {ACL Workshops}}
@string{coling   = {COLING}}
@string{aistats  = {AISTATS}}
@string{icme     = {ICME}}
@string{aaaiw    = {AAAI Workshops}}
@string{parc      = {PARC}}
@string{accv      = {ACCV}}
@string{eacl     = {EACL}}
@string{cbmi     = {CBMI}}

@string{ieeetpami  = {IEEE Trans. PAMI}}
@string{ieeetip  = {IEEE Trans. Image Processing}}
@string{ieeetit    = {IEEE Trans. Inform. Theory}}
@string{ieeetcom   = {IEEE Trans. Communications}}
@string{ieeetro  = {IEEE Trans. Robot.}}
@string{jair     = {JAIR}}
@string{cviu     = {CVIU}}
@string{ijcv     = {IJCV}}
@string{tomm     = {ACM TOMM}}
@string{dicta    = {DICTA}}
@string{tacl     = {TACL}}
@string{tmm      = {IEEE Trans. Multimedia}}
@string{ieeetcsvt = {IEEE TCSVT}}

%----------------------------------[ 2023 ]----------------------------------
@inproceedings{zhu2023imagine,
  title={{ImaginE: An Imagination-Based Automatic Evaluation Metric for Natural Language Generation}},
  author={Zhu, Wanrong and Wang, Xin Eric and Yan, An and Eckstein, Miguel and Wang, William Yang},
  booktitle=eacl,
  year={2023}
}


%----------------------------------[ 2022 ]----------------------------------
@inproceedings{sarto2022retrieval,
  title={{Retrieval-Augmented Transformer for Image Captioning}},
  author={Sarto, Sara and Cornia, Marcella and Baraldi, Lorenzo and Cucchiara, Rita},
  booktitle=cbmi,
  year={2022}
}

@inproceedings{wang2022simvlm,
  title={{SimVLM: Simple Visual Language Model Pretraining with Weak Supervision}},
  author={Wang, Zirui and Yu, Jiahui and Yu, Adams Wei and Dai, Zihang and Tsvetkov, Yulia and Cao, Yuan},
  booktitle=iclr,
  year={2022}
}

@inproceedings{barraco2022camel,
  title={{CaMEL: Mean Teacher Learning for Image Captioning}},
  author={Barraco, Manuele and Stefanini, Matteo and Cornia, Marcella and Cascianelli, Silvia and Baraldi, Lorenzo and Cucchiara, Rita},
  booktitle=icpr,
  year={2022},
}

@inproceedings{barraco2022unreasonable,
  title={{The Unreasonable Effectiveness of CLIP Features for Image Captioning: An Experimental Analysi}},
  author={Barraco, Manuele and Cornia, Marcella and Cascianelli, Silvia and Baraldi, Lorenzo and Cucchiara, Rita},
  booktitle=cvprw,
  year={2022}
}

@inproceedings{materzynska2022disentangling,
  title={{Disentangling Visual and Written Concepts in CLIP}},
  author={Materzy{\'n}ska, Joanna and Torralba, Antonio and Bau, David},
  booktitle=cvpr,
  year={2022}
}

@inproceedings{khandelwal2022simple,
  title={{Simple but Effective: CLIP Embeddings for Embodied AI}},
  author={Khandelwal, Apoorv and Weihs, Luca and Mottaghi, Roozbeh and Kembhavi, Aniruddha},
  booktitle=cvpr,
  year={2022}
}

@inproceedings{kim2022mutual,
  title={{Mutual Information Divergence: A Unified Metric for Multimodal Generative Models}},
  author={Kim, Jin-Hwa and Kim, Yunji and Lee, Jiyoung and Yoo, Kang Min and Lee, Sang-Woo},
  booktitle=nips,
  year={2022}
}

@inproceedings{shi2022emscore,
  title={{EMScore: Evaluating Video Captioning via Coarse-Grained and Fine-Grained Embedding Matching}},
  author={Shi, Yaya and Yang, Xu and Xu, Haiyang and Yuan, Chunfeng and Li, Bing and Hu, Weiming and Zha, Zheng-Jun},
  booktitle=cvpr,
  year={2022}
}

@inproceedings{li2022blip,
  title={{BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation}},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle=icml,
  year={2022}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle=cvpr,
  year={2022}
}

@inproceedings{schuhmann2022laion,
  title={{LAION-5B: An open large-scale dataset for training next generation image-text models}},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and Schramowski, Patrick and Kundurthy, Srivatsa  and Crowson, Katherine and Schmidt, Ludwig and Kaczmarczyk, Robert and Jitsev, Jenia},
  booktitle=nips,
  year={2022}
}

@inproceedings{wortsman2022robust,
  title={Robust fine-tuning of zero-shot models},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Kim, Jong Wook and Li, Mike and Kornblith, Simon and Roelofs, Rebecca and Lopes, Raphael Gontijo and Hajishirzi, Hannaneh and Farhadi, Ali and Namkoong, Hongseok and Schmidt, Ludwig},
  booktitle=cvpr,
  year={2022}
}

@article{stefanini2022show,
  title={{From Show to Tell: A Survey on Deep Learning-based Image Captioning}},
  author={Stefanini, Matteo and Cornia, Marcella and Baraldi, Lorenzo and Cascianelli, Silvia and Fiameni, Giuseppe and Cucchiara, Rita},
  journal=ieeetpami,
  year={2022},
}

@article{cornia2022universal,
  title={{Universal Captioner: Inducing Content-Style Separation in Vision-and-Language Model Training}},
  author={Cornia, Marcella and Baraldi, Lorenzo and Fiameni, Giuseppe and Cucchiara, Rita},
  journal={arXiv preprint arXiv:2111.12727},
  year={2022}
}

@inproceedings{gafni2022make,
  title={{Make-A-Scene: Scene-Based Text-to-Image Generation with Human Priors}},
  author={Gafni, Oran and Polyak, Adam and Ashual, Oron and Sheynin, Shelly and Parikh, Devi and Taigman, Yaniv},
  booktitle=eccv,
  year={2022}
}

@article{ramesh2022hierarchical,
  title={{Hierarchical Text-Conditional Image Generation with CLIP Latents}},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}

@article{saharia2022photorealistic,
  title={{Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding}},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily and Ghasemipour, Seyed Kamyar Seyed and Ayan, Burcu Karagol and Mahdavi, S Sara and Lopes, Rapha Gontijo and Salimans, Tim and Ho, Jonathan and Fleet, David J and  Norouzi, Mohammad},
  journal={arXiv preprint arXiv:2205.11487},
  year={2022}
}


%----------------------------------[ 2021 ]----------------------------------

@article{nichol2021glide,
  title={{GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models}},
  author={Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
  journal={arXiv preprint arXiv:2112.10741},
  year={2021}
}

@inproceedings{hessel2021clipscore,
  title={{CLIPScore: A Reference-free Evaluation Metric for Image Captioning}},
  author={Hessel, Jack and Holtzman, Ari and Forbes, Maxwell and Bras, Ronan Le and Choi, Yejin},
  booktitle=emnlp,
  year={2021}
}

@inproceedings{radford2021learning,
  title={{Learning Transferable Visual Models From Natural Language Supervision}},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  booktitle=icml,
  year={2021}
}

@inproceedings{wang2021faier,
  title={{FAIEr: Fidelity and Adequacy Ensured Image Caption Evaluation}},
  author={Wang, Sijin and Yao, Ziwei and Wang, Ruiping and Wu, Zhongqin and Chen, Xilin},
  booktitle=cvpr,
  year={2021}
}

@inproceedings{unanue2021berttune,
  title={{BERTTune: Fine-Tuning Neural Machine Translation with BERTScore}},
  author={Unanue, Inigo Jauregi and Parnell, Jacob and Piccardi, Massimo},
  booktitle=acl,
  year={2021}
}

@inproceedings{lee2021umic,
  title={{UMIC: An Unreferenced Metric for Image Captioning via Contrastive Learning}},
  author={Lee, Hwanhee and Yoon, Seunghyun and Dernoncourt, Franck and Bui, Trung and Jung, Kyomin},
  booktitle=acl,
  year={2021}
}

@inproceedings{zhang2021vinvl,
  title={{VinVL: Revisiting visual representations in vision-language models}},
  author={Zhang, Pengchuan and Li, Xiujun and Hu, Xiaowei and Yang, Jianwei and Zhang, Lei and Wang, Lijuan and Choi, Yejin and Gao, Jianfeng},
  booktitle=cvpr,
  year={2021}
}

%----------------------------------[ 2020 ]----------------------------------

@inproceedings{zhang2019bertscore,
  title={{BERTScore: Evaluating Text Generation with BERT}},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  booktitle=iclr,
  year={2020}
}

@inproceedings{pan2020x,
  title={{X-Linear Attention Networks for Image Captioning}},
  author={Pan, Yingwei and Yao, Ting and Li, Yehao and Mei, Tao},
  booktitle=cvpr,
  year={2020}
}

@inproceedings{cornia2020meshed,
  title={{Meshed-Memory Transformer for Image Captioning}},
  author={Cornia, Marcella and Stefanini, Matteo and Baraldi, Lorenzo and Cucchiara, Rita},
  booktitle=cvpr,
  year={2020}
}

@inproceedings{yi2020improving,
  title={{Improving Image Captioning Evaluation by Considering Inter References Variance}},
  author={Yi, Yanzhi and Deng, Hangyu and Hu, Jinglu},
  booktitle=acl,
  year={2020}
}

@inproceedings{lee2020vilbertscore,
  title={{ViLBERTScore: Evaluating Image Caption Using Vision-and-Language BERT}},
  author={Lee, Hwanhee and Yoon, Seunghyun and Dernoncourt, Franck and Kim, Doo Soon and Bui, Trung and Jung, Kyomin},
  booktitle=emnlpw,
  year={2020}
}

@inproceedings{wang2020towards,
  title={{Towards unique and informative captioning of images}},
  author={Wang, Zeyu and Feng, Berthy and Narasimhan, Karthik and Russakovsky, Olga},
  booktitle=eccv,
  year={2020},
}

@article{wang2020diversity,
  title={{On Diversity in Image Captioning: Metrics and Methods}},
  author={Wang, Qingzhong and Wan, Jia and Chan, Antoni B},
  journal=ieeetpami,
  year={2020},
}

@inproceedings{cornia2020smart,
  title={{SMArT: Training Shallow Memory-aware Transformers for Robotic Explainability}},
  author={Cornia, Marcella and Baraldi, Lorenzo and Cucchiara, Rita},
  booktitle=icra,
  year={2020}
}


@inproceedings{dosovitskiy2020image,
  title={{An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  booktitle=iclr,
  year={2021}
}

@inproceedings{chen2020uniter,
  title={{UNITER: UNiversal Image-TExt Representation Learning}},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle=eccv,
  year={2020},
}


@inproceedings{li2020oscar,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
  booktitle=eccv,
  year={2020}
}

%----------------------------------[ 2019 ]----------------------------------

@inproceedings{jiang2019tiger,
  title={{TIGEr: Text-to-Image Grounding for Image Caption Evaluation}},
  author={Jiang, Ming and Huang, Qiuyuan and Zhang, Lei and Wang, Xin and Zhang, Pengchuan and Gan, Zhe and Diesner, Jana and Gao, Jianfeng},
  booktitle=emnlp,
  year={2019}
}

@inproceedings{huang2019attention,
  title={{Attention on Attention for Image Captioning}},
  author={Huang, Lun and Wang, Wenmin and Chen, Jie and Wei, Xiao-Yong},
  booktitle=iccv,
  year={2019}
}

@inproceedings{wang2019vatex,
  title={{VaTeX: A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research}},
  author={Wang, Xin and Wu, Jiawei and Chen, Junkun and Li, Lei and Wang, Yuan-Fang and Wang, William Yang},
  booktitle=iccv,
  year={2019}
}

@inproceedings{zhou2019grounded,
  title={Grounded video description},
  author={Zhou, Luowei and Kalantidis, Yannis and Chen, Xinlei and Corso, Jason J and Rohrbach, Marcus},
  booktitle=cvpr,
  year={2019}
}

@inproceedings{jiang2019reo,
  title={{REO-Relevance, Extraness, Omission: A Fine-grained Evaluation for Image Captioning}},
  author={Jiang, Ming and Hu, Junjie and Huang, Qiuyuan and Zhang, Lei and Diesner, Jana and Gao, Jianfeng},
  booktitle=emnlp,
  year={2019}
}

@inproceedings{wang2019describing,
  title={{Describing like humans: on diversity in image captioning}},
  author={Wang, Qingzhong and Chan, Antoni B},
  booktitle=cvpr,
  year={2019}
}

@inproceedings{cornia2019show,
  title={{Show, Control and Tell: A Framework for Generating Controllable and Grounded Captions}},
  author={Cornia, Marcella and Baraldi, Lorenzo and Cucchiara, Rita},
  booktitle=cvpr,
  year={2019}
}

@inproceedings{lu2019vilbert,
  title={{ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks}},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  booktitle=nips,
  year={2019}
}

@inproceedings{yang2019auto,
  title={{Auto-Encoding Scene Graphs for Image Captioning}},
  author={Yang, Xu and Tang, Kaihua and Zhang, Hanwang and Cai, Jianfei},
  booktitle=cvpr,
  year={2019}
}

@inproceedings{herdade2019image,
  title={Image captioning: Transforming objects into words},
  author={Herdade, Simao and Kappeler, Armin and Boakye, Kofi and Soares, Joao},
  booktitle=nips,
  year={2019}
}

@inproceedings{loshchilov2019decoupled,
  title={{Decoupled Weight Decay Regularization}},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle=iclr,
  year={2019}
}

%----------------------------------[ 2018 ]----------------------------------

@article{oord2018representation,
  title={{Representation Learning with Contrastive Predictive Coding}},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@inproceedings{devlin2018bert,
  title={{BERT: Pre-training of deep bidirectional transformers for language understanding}},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle=naacl,
  year={2018}
}

@inproceedings{yao2018exploring,
  title={Exploring visual relationship for image captioning},
  author={Yao, Ting and Pan, Yingwei and Li, Yehao and Mei, Tao},
  booktitle=eccv,
  year={2018}
}

@inproceedings{anderson2018bottom,
  title={{Bottom-up and top-down attention for image captioning and visual question answering}},
  author={Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
  booktitle=cvpr,
  year={2018}
}

@inproceedings{rohrbach2018object,
  title={{Object Hallucination in Image Captioning}},
  author={Rohrbach, Anna and Hendricks, Lisa Anne and Burns, Kaylee and Darrell, Trevor and Saenko, Kate},
  booktitle=emnlp,
  year={2018}
}

@inproceedings{cui2018learning,
  title={{Learning to Evaluate Image Captioning}},
  author={Cui, Yin and Yang, Guandao and Veit, Andreas and Huang, Xun and Belongie, Serge},
  booktitle=cvpr,
  year={2018}
}

@inproceedings{sharif2018nneval,
  title={{NNEval: Neural network based evaluation metric for image captioning}},
  author={Sharif, Naeha and White, Lyndon and Bennamoun, Mohammed and Shah, Syed Afaq Ali},
  booktitle=eccv,
  year={2018}
}

@inproceedings{van2018measuring,
  title={{Measuring the diversity of automatic image descriptions}},
  author={Van Miltenburg, Emiel and Elliott, Desmond and Vossen, Piek},
  booktitle=coling,
  year={2018}
}

@inproceedings{lee2018stacked,
  title={{Stacked Cross Attention for Image-Text Matching}},
  author={Lee, Kuang-Huei and Chen, Xi and Hua, Gang and Hu, Houdong and He, Xiaodong},
  booktitle=eccv,
  year={2018}
}


%----------------------------------[ others ]----------------------------------

@inproceedings{papineni2002bleu,
  title={{BLEU: a method for automatic evaluation of machine translation}},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle=acl,
  year={2002}
}

@inproceedings{banerjee2005meteor,
  title={{METEOR: An automatic metric for MT evaluation with improved correlation with human judgments}},
  author={Banerjee, Satanjeev and Lavie, Alon},
  booktitle=aclw,
  year={2005}
}

@inproceedings{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle=aclw,
  year={2004}
}

@inproceedings{vedantam2015cider,
  title={{CIDEr: Consensus-based Image Description Evaluation}},
  author={Vedantam, Ramakrishna and Lawrence Zitnick, C and Parikh, Devi},
  booktitle=cvpr,
  year={2015}
}

@inproceedings{spice2016,
  title     = {{SPICE: Semantic Propositional Image Caption Evaluation}},
  author={Anderson, Peter and Fernando, Basura and Johnson, Mark and Gould, Stephen},
  year      = {2016},
  booktitle = eccv
}

@article{hodosh2013framing,
  title={Framing image description as a ranking task: Data, models and evaluation metrics},
  author={Hodosh, Micah and Young, Peter and Hockenmaier, Julia},
  journal=jair,
  volume={47},
  pages={853--899},
  year={2013}
}


@article{aditya2015images,
  title={{From Images to Sentences through Scene Description Graphs using Commonsense Reasoning and Knowledge}},
  author={Aditya, Somak and Yang, Yezhou and Baral, Chitta and Fermuller, Cornelia and Aloimonos, Yiannis},
  journal={arXiv preprint arXiv:1511.03292},
  year={2015}
}

@inproceedings{lin2014microsoft,
Author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
Booktitle = eccv,
Title = {{Microsoft COCO: Common Objects in Context}},
Year = {2014}
}

@article{young2014image,
  title={{From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions}},
  author={Young, Peter and Lai, Alice and Hodosh, Micah and Hockenmaier, Julia},
  journal=tacl,
  year={2014},
}

@inproceedings{rashtchian2010collecting,
  title={{Collecting Image Annotations Using Amazonâ€™s Mechanical Turk}},
  author={Rashtchian, Cyrus and Young, Peter and Hodosh, Micah and Hockenmaier, Julia},
  booktitle=naaclw,
  year={2010}
}

@inproceedings{shekhar2017foil,
  title={{FOIL it! Find One mismatch between Image and Language caption}},
  author={Shekhar, Ravi and Pezzelle, Sandro and Klimovich, Yauhen and Herbelot, Aur{\'e}lie and Nabi, Moin and Sangineto, Enver and Bernardi, Raffaella},
  booktitle=acl,
  year={2017}
}

@inproceedings{kingma2015adam,
  title={{Adam: A Method for Stochastic Optimization}},
  author={Kingma, Diederik P and Ba, Jimmy},
  booktitle=iclr,
  year={2015}
}

@inproceedings{karpathy2015deep,
  title={Deep visual-semantic alignments for generating image descriptions},
  author={Karpathy, Andrej and Fei-Fei, Li},
  booktitle=cvpr,
  year={2015}
}

@inproceedings{shetty2017speaking,
  title={Speaking the same language: Matching machine to human captions by adversarial training},
  author={Shetty, Rakshith and Rohrbach, Marcus and Anne Hendricks, Lisa and Fritz, Mario and Schiele, Bernt},
  booktitle=iccv,
  year={2017}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle=cvpr,
  year={2016}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle=nips,
  year={2017},
}

@inproceedings{zitnick2013bringing,
  title={Bringing semantics into focus using visual abstraction},
  author={Zitnick, C Lawrence and Parikh, Devi},
  booktitle=cvpr,
  year={2013}
}

@inproceedings{xu2015show,
  title={Show, attend and tell: Neural image caption generation with visual attention},
  author={Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhutdinov, Ruslan and Zemel, Richard S and Bengio, Yoshua},
  booktitle=icml,
  year={2015},
}

@inproceedings{vinyals2015show,
  title={Show and tell: A neural image caption generator},
  author={Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
  booktitle=cvpr,
  year={2015}
}

@article{robertson2004understanding,
  title={{Understanding inverse document frequency: on theoretical arguments for IDF}},
  author={Robertson, Stephen},
  journal={Journal of Documentation},
  year={2004},
}

@inproceedings{yao2017boosting,
  title={Boosting image captioning with attributes},
  author={Yao, Ting and Pan, Yingwei and Li, Yehao and Qiu, Zhaofan and Mei, Tao},
  booktitle=iccv,
  year={2017}
}


