In this paper, we have proposed a positive-augmented contrastive learning approach for image and video captioning evaluation. Our proposal, PAC-S, is trained by considering cleaned data sources and leveraging synthetic images and captions as an additional source of supervision. Experimentally, we have demonstrated that PAC-S is superior to all previous metrics in terms of correlation with human judgment and sensitivity to hallucinated objects in both reference-free and reference-based settings.