\appendix

\section{Additional Experimental Results}
\tinytit{Correlation with MID score}
In addition to the experiments presented in the main paper, we conducted further comparisons with the MID metric~\cite{kim2022mutual}. Since it exploits CLIP-based features as CLIP-S~\cite{hessel2021clipscore} and our proposal, in Table~\ref{tab:mid} we compare the results of the original MID score with a re-implemented version that uses our embeddings in place of those of CLIP. In particular, we conduct this analysis on the Flickr8k-Expert, Flickr8k-CF, and FOIL datasets and show that using our embeddings can further improve the results of the MID score in the majority of the considered settings, thus further demonstrating the appropriateness of our positive-augmented contrastive learning approach.

\tit{Reference-based results using ViT-based backbones} As a complement to Table~\ref{tab:features}, in Table~\ref{tab:featuresViT} we report the referenced-based results using different cross-modal features. In particular, we experiment with different ViT-based backbones of CLIP~\cite{radford2021learning} and OpenCLIP~\cite{wortsman2022robust} models. From these results, we confirm the effectiveness of \ours also in the reference-based setting on both image and video captioning datasets. Both ViT-L/14 models outperform the others even in this case, still confirming that using more powerful features can lead to better results.

\begin{table}[b]
\centering
\footnotesize
% \begin{center}
% , when using the full \ours training set.
\setlength{\tabcolsep}{.25em}
\resizebox{\linewidth}{!}{
\begin{tabular}{lcc cc c cc c c c c}
\toprule
 & & & \multicolumn{2}{c}{\textbf{Flickr8k-Expert}} & & \multicolumn{2}{c}{\textbf{Flickr8k-CF}}  & & \textbf{Pascal-50S} & & \textbf{FOIL} \\
  \cmidrule{4-5} \cmidrule{7-8} \cmidrule{10-10} \cmidrule{12-12}
 & \textbf{Features} & & Kendall $\tau_b$ & Kendall $\tau_c$ & & Kendall $\tau_b$ & Kendall $\tau_c$ & & Accuracy & & Accuracy \\
\midrule
MID~\cite{kim2022mutual} & CLIP & & - & 54.9 & & \textbf{37.3} & - & & \textbf{85.2} & & 90.5 \\
\midrule
MID$^\dagger$ & CLIP & & 54.3 & 54.6 & & 36.5 & 18.7 & & 84.6 & & 93.2 \\
\rowcolor{LightCyan}
\textbf{MID$^\dagger$} & \textbf{Ours} & &  {\textbf{54.7}} & \textbf{55.1} & & 36.7 & \textbf{18.8} & & 85.0 & & \textbf{93.3} \\
\bottomrule
\end{tabular}
}
\caption{Performance of MID with CLIP and PAC ViT-B/32 features. The $\dagger$ marker indicates our re-implementation.}
\label{tab:mid}
\vspace{-.15cm}
\end{table}

\begin{figure}[b]
\centering
\setlength{\tabcolsep}{.1em}
\begin{tabular}{ccc}
\includegraphics[width=0.325\linewidth]{images/pac_scores_w=2.pdf} &
\includegraphics[width=0.325\linewidth]{images/pac_scores_w=2.5.pdf} &
\includegraphics[width=0.325\linewidth]{images/pac_scores_w=3.pdf}
\end{tabular}
\vspace{-.3cm}
\caption{Distribution of PAC scores using different $w$ (Eq.~\ref{eq:clip_score} of the main paper).}
\label{fig:graph}
\vspace{-.3cm}
\end{figure}

\tit{Analyzing ResNet-based backbones}
In Table~\ref{tab:featuresResnet}, we conduct the same analysis in both reference-free and reference-based settings but using visual features extracted from a ResNet backbone~\cite{he2016deep}. Specifically, we use the following CLIP-based models: ResNet-50, ResNet-101, and ResNet-50$\times$4, which employ an EfficientNet-style architecture scaling. For these experiments, we finetune the last attention pooling of the visual backbone and the final projection of the textual branch using the same settings described in the main paper. Also in this case, our metric achieves the best results in almost all datasets, with the only exception of VATEX-EVAL in which the EMScore obtains slightly better correlation scores. 

\begin{table*}[t]
\small
\centering
\setlength{\tabcolsep}{.35em}
\resizebox{\linewidth}{!}{
\begin{tabular}{clc cc c cc c cc c c c c c c}
\toprule
& & & \multicolumn{2}{c}{\textbf{Flickr8k-Expert}} & & \multicolumn{2}{c}{\textbf{Flickr8k-CF}} & & \multicolumn{2}{c}{\textbf{VATEX-EVAL}} & & \textbf{PASCAL-50S} & & \textbf{FOIL} & & \textbf{ActivityNet-FOIL} \\
\cmidrule{4-5} \cmidrule{7-8} \cmidrule{10-11} \cmidrule{13-13} \cmidrule{15-15} \cmidrule{17-17}
& & & Kendall $\tau_b$ & Kendall $\tau_c$  & & Kendall $\tau_b$ & Kendall $\tau_c$ & & Kendall $\tau_b$ & Spearman $\rho$ & & Accuracy & & Accuracy & & Accuracy \\
\midrule
& RefCLIP-S~\cite{hessel2021clipscore} & & 53.6 & 54.0 & & 36.7 & 19.0 & & - & - & & 84.0 & & 94.8 & & - \\
& EMScoreRef~\cite{shi2022emscore}  & & - & - & & - & - & & 37.1 & 47.5 & & - & & - & & 92.2 \\
\rowcolor{LightCyan}
\cellcolor[rgb]{1,1,1} & &  &  \textbf{56.0} &  \textbf{56.4} &  &  \textbf{37.5} &  \textbf{19.4} &  & \textbf{38.8} & \textbf{49.6} &  &  \textbf{84.8} &  &  \textbf{95.1} &  &  \textbf{92.6} \\
\rowcolor{LightCyan}
\cellcolor[rgb]{1,1,1} \multirow{-4}{*}{\textbf{CLIP ViT-B/16}} & \multirow{-2}{*}{\textbf{\oursref}} & & (\textcolor{blue}{+2.4}) & (\textcolor{blue}{+2.4}) & & (\textcolor{blue}{+0.8}) & (\textcolor{blue}{+0.4}) & & (\textcolor{blue}{+1.7}) & (\textcolor{blue}{+2.1}) & & (\textcolor{blue}{+0.8}) & & (\textcolor{blue}{+0.3}) & & (\textcolor{blue}{+0.4}) \\
\midrule
 & RefCLIP-S~\cite{hessel2021clipscore} & & 54.0 & 54.4 & & 36.5 & 18.9 & & - & - & & \textbf{85.0} & & 94.9 & & - \\
& EMScoreRef~\cite{shi2022emscore}  & & - & - & & - & - & & 37.0 & 47.4 & & - & & - & & 93.5 \\
\rowcolor{LightCyan}
\cellcolor[rgb]{1,1,1} & & &  \textbf{56.7} &  \textbf{57.1} &  &  \textbf{37.7} &  \textbf{19.5} &  &  \textbf{38.6} &  \textbf{49.3} &  &  \textbf{85.0} &  &  \textbf{95.3} &  &  \textbf{94.2} \\
\rowcolor{LightCyan}
\cellcolor[rgb]{1,1,1} \multirow{-4}{*}{\textbf{CLIP ViT-L/14}} & \multirow{-2}{*}{\textbf{\oursref}} & & (\textcolor{blue}{+2.7}) & (\textcolor{blue}{+2.7}) & & (\textcolor{blue}{+1.2}) & (\textcolor{blue}{+0.6}) & & (\textcolor{blue}{+1.6}) & (\textcolor{blue}{+1.9}) & & (+0.0) & & (\textcolor{blue}{+0.4}) & & (\textcolor{blue}{+0.7}) \\
\midrule
 & RefCLIP-S~\cite{hessel2021clipscore} & & 53.9 & 54.3 & & 36.8 & 19.0 & & - & - & & \textbf{84.7} & & \textbf{94.7} & & - \\
\textbf{OpenCLIP} & EMScoreRef~\cite{shi2022emscore} & & - & - & & - & - & & 38.4 & 49.1 & & - & & - & & 93.0 \\
\rowcolor{LightCyan}
\cellcolor[rgb]{1,1,1} \textbf{ViT-B/32} &  &  &  \textbf{54.8} &  \textbf{55.2} &  &  \textbf{37.4} &  \textbf{19.3} &  &   \textbf{38.8} &   \textbf{49.5} &  & 84.5 &  & 94.1 &  &  \textbf{93.6} \\
\rowcolor{LightCyan}
\cellcolor[rgb]{1,1,1} & \multirow{-2}{*}{\textbf{\oursref}} & & (\textcolor{blue}{+0.9}) & (\textcolor{blue}{+0.9}) & & (\textcolor{blue}{+0.6}) & (\textcolor{blue}{+0.3}) & & (\textcolor{blue}{+0.4}) & (\textcolor{blue}{+0.4}) & & (\textcolor{black}{-0.2}) & & (\textcolor{black}{-0.6}) & & (\textcolor{blue}{+0.6}) \\
\midrule
 & RefCLIP-S~\cite{hessel2021clipscore}  & & 55.7 & 55.8 & & 37.5 & 19.4 & & - & - & & \textbf{85.3} & & \textbf{95.9} & & - \\
\textbf{OpenCLIP} & EMScoreRef~\cite{shi2022emscore}  & & - & - & & - & - & & 39.4 & 50.3 & & - & & - & & 94.0 \\
\rowcolor{LightCyan}
\cellcolor[rgb]{1,1,1} \textbf{ViT-L/14}  &  &  &  \textbf{56.5} &  \textbf{56.9} &  &  \textbf{38.0} &  \textbf{19.7} &  &  \textbf{40.3} &  \textbf{51.4} &  &  84.9 &  &  95.8 &  &  \textbf{94.4} \\
\rowcolor{LightCyan}
\cellcolor[rgb]{1,1,1} & \multirow{-2}{*}{\textbf{\oursref}} & & (\textcolor{blue}{+0.8}) & (\textcolor{blue}{+1.1}) & & (\textcolor{blue}{+0.5}) & (\textcolor{blue}{+0.3}) & & (\textcolor{blue}{+0.9}) & (\textcolor{blue}{+1.1}) & & (-0.4) & & (\textcolor{black}{-0.1}) & & (\textcolor{blue}{+0.4}) \\
\bottomrule
\end{tabular}
}
\vspace{-.1cm}
\caption{Captioning evaluation results in a reference-based setting on both image and video captioning datasets using different cross-modal features.}
\label{tab:featuresViT}
\vspace{-.15cm}
\end{table*}

\begin{table*}[t]
\small
\centering
\setlength{\tabcolsep}{.35em}
\resizebox{\linewidth}{!}{
\begin{tabular}{clc cc c cc c cc c c c c c c}
\toprule
& & & \multicolumn{2}{c}{\textbf{Flickr8k-Expert}} & & \multicolumn{2}{c}{\textbf{Flickr8k-CF}} & & \multicolumn{2}{c}{\textbf{VATEX-EVAL}} & & \textbf{PASCAL-50S} & & \textbf{FOIL} & & \textbf{ActivityNet-FOIL} \\
\cmidrule{4-5} \cmidrule{7-8} \cmidrule{10-11} \cmidrule{13-13} \cmidrule{15-15} \cmidrule{17-17}
& & & Kendall $\tau_b$ & Kendall $\tau_c$  & & Kendall $\tau_b$ & Kendall $\tau_c$ & & Kendall $\tau_b$ & Spearman $\rho$ & & Accuracy & & Accuracy & & Accuracy \\
\midrule
 & CLIP-S~\cite{hessel2021clipscore} & & 51.0 & 51.4 & & 34.0 & 17.6 & & - & - & & 80.6 & & \textbf{87.9} & & - \\
& EMScore~\cite{shi2022emscore} & & - & - & & - & - & & \textbf{22.0} & \textbf{28.6} & & - & & - & & 87.0 \\
\rowcolor{LightCyan}
\cellcolor[rgb]{1,1,1} & & & \textbf{52.6} & \textbf{52.9} & &  \textbf{34.6} & \textbf{17.9} &  & 19.4 & 25.4 &  & \textbf{81.7} &  & 87.1 &  &  \textbf{87.7} \\
\rowcolor{LightCyan}
\cellcolor[rgb]{1,1,1} \multirow{-4}{*}{\textbf{CLIP RN50}} & \multirow{-2}{*}{\textbf{\ours}} & & (\textcolor{blue}{+1.6}) & (\textcolor{blue}{+1.5}) & & (\textcolor{blue}{+0.6}) & (\textcolor{blue}{+0.3}) & & (-2.6) & (-3.2) & & (\textcolor{blue}{+1.1}) & & (-0.8) & & (\textcolor{blue}{+0.7}) \\
\midrule & RefCLIP-S~\cite{hessel2021clipscore} & & 52.5 & 52.8 & & 35.9 & 18.5 & & - & - & & 83.4 & & \textbf{93.4} & & - \\
& EMScoreRef~\cite{shi2022emscore} & & - & - & & - & - & & \textbf{36.6 } & {\textbf{46.9}}  & & - & & - & & 91.8 \\
\rowcolor{LightCyan}
\cellcolor[rgb]{1,1,1} & & &  \textbf{54.1} & \textbf{54.5} &  & \textbf{36.4}  & {\textbf{18.8}}  &  &  36.4 &  46.7 &  & \textbf{83.8} &  & 93.1  &  &  {\textbf{92.7}} \\
\rowcolor{LightCyan}
\cellcolor[rgb]{1,1,1} \multirow{-4}{*}{\textbf{CLIP RN50}} & \multirow{-2}{*}{\textbf{\oursref }} & & (\textcolor{blue}{+1.6}) & (\textcolor{blue}{+1.7}) & & (\textcolor{blue}{+0.5}) & (\textcolor{blue}{+0.3}) & & (-0.2) & (-0.2) & & (\textcolor{blue}{+0.4}) & & (\textcolor{black}{-0.3}) & & (\textcolor{blue}{+0.9}) \\
\midrule
 & CLIP-S~\cite{hessel2021clipscore} & & 50.5 & 50.9 & & 33.5 & 17.3 & & - & - & & 80.5 & & \textbf{89.1} & & - \\
& EMScore~\cite{shi2022emscore} & & - & - & & - & - & & \textbf{21.6} & \textbf{28.2} & & - & & - & & \textbf{89.6} \\
\rowcolor{LightCyan}
\cellcolor[rgb]{1,1,1} & & & \textbf{53.4} &  \textbf{53.7} &  &  \textbf{34.4} &  \textbf{17.8} &  &  20.4 &  26.6 &  &  \textbf{81.8} &  &  89.0 &  &  88.9 \\
\rowcolor{LightCyan}
\cellcolor[rgb]{1,1,1} \multirow{-4}{*}{\textbf{CLIP RN101}} & \multirow{-2}{*}{\textbf{\ours}} & & (\textcolor{blue}{+2.9}) & (\textcolor{blue}{+2.8}) & & (\textcolor{blue}{+0.9}) & (\textcolor{blue}{+0.5}) & & (-1.2) & (-1.6) & & (\textcolor{blue}{+1.3}) & & (-0.1) & & (-0.7) \\
\midrule
& RefCLIP-S~\cite{hessel2021clipscore} & & 52.2 & 52.6 & & 35.6 & 18.4 & & - & - & & 83.3 & & 95.2 & & - \\
& EMScoreRef~\cite{shi2022emscore}& & - & - & & - & - & & 36.6 & 46.9  & & - & & - & & 91.7 \\
\rowcolor{LightCyan}
\cellcolor[rgb]{1,1,1} & & & {\textbf{55.5}}  &   {\textbf{55.9}}  &  &  {\textbf{36.6}}  &  {\textbf{ 18.9}} &  &  {\textbf{37.1}}  &  {\textbf{47.5}}  &  &  {\textbf{84.8}}  &  &  {\textbf{95.4}}  &  & {\textbf{92.1}}  \\
\rowcolor{LightCyan}
\cellcolor[rgb]{1,1,1} \multirow{-4}{*}{\textbf{CLIP RN101}} & \multirow{-2}{*}{\textbf{\oursref}} & & (\textcolor{blue}{+3.3}) & (\textcolor{blue}{+3.3}) & & (\textcolor{blue}{+1.0}) & (\textcolor{blue}{+0.5}) & & (\textcolor{blue}{+0.5}) & (\textcolor{blue}{+0.6}) & & (\textcolor{blue}{+1.5}) & & (\textcolor{blue}{+0.2}) & & (\textcolor{blue}{+0.4}) \\
\midrule
& CLIP-S~\cite{hessel2021clipscore} & & 50.7 & 51.0 & & 34.0 & 17.6 & & - & - & & 80.7 & & 89.5 & & - \\
& EMScore~\cite{shi2022emscore}& & - & - & & - & - & & \textbf{22.0} & \textbf{28.8}  & & - & & - & & \textbf{88.8} \\
\rowcolor{LightCyan}
\cellcolor[rgb]{1,1,1} & & & \textbf{53.9} &  \textbf{54.3} &  &  \textbf{35.9} &  \textbf{18.6} &  & 21.9 & 28.6 &  &  \textbf{82.5} &  &  \textbf{90.5} &  &  87.7 \\
\rowcolor{LightCyan}
\cellcolor[rgb]{1,1,1} \multirow{-4}{*}{\textbf{CLIP RN50$\times$4}} & \multirow{-2}{*}{\textbf{\ours}} & & (\textcolor{blue}{+3.2}) & (\textcolor{blue}{+3.3}) & & (\textcolor{blue}{+1.9}) & (\textcolor{blue}{+1.0}) & & (-0.1) & (-0.2) & & (\textcolor{blue}{+1.8}) & & (\textcolor{blue}{+1.0}) & & (-1.1) \\
\midrule
& RefCLIP-S~\cite{hessel2021clipscore} & & 52.3 & 52.7 & & 36.1 & 18.7 & & - & - & & 83.3 & & 95.3 & & - \\
& EMScoreRef~\cite{shi2022emscore} & & - & - & & - & - & & 36.7 & 45.0 & & - & & - & & 91.5 \\
\rowcolor{LightCyan}
\cellcolor[rgb]{1,1,1} & &  & {\textbf{56.2}}  &  {\textbf{56.6}} &  & {\textbf{37.3}}  & {\textbf{19.3}}  &  & {\textbf{37.4}}  & {\textbf{47.7}}  &  & {\textbf{84.8}}  &  &  {\textbf{95.8}}  &  &  \textbf{91.9} \\
\rowcolor{LightCyan}
\cellcolor[rgb]{1,1,1} \multirow{-4}{*}{\textbf{CLIP RN50$\times$4}} & \multirow{-2}{*}{\textbf{\oursref}} & & (\textcolor{blue}{+3.9}) & (\textcolor{blue}{3.9}) & & (\textcolor{blue}{+1.2}) & (\textcolor{blue}{+0.6}) & & (\textcolor{blue}{+0.7}) & (\textcolor{blue}{+2.7}) & & (\textcolor{blue}{+1.5}) & & (\textcolor{blue}{+0.5}) & & (\textcolor{blue}{+0.4}) \\
\midrule
\end{tabular}
}
\vspace{-.1cm}
\caption{Additional human correlation and accuracy scores on both image and video captioning datasets using different cross-modal ResNet-based backbones.}
\label{tab:featuresResnet}
\vspace{-.35cm}
\end{table*}

\tit{Choice of hyperparameters}
The scaling factor, denoted by $w$ in Eq.~\ref{tab:featuresViT}, is utilized to adjust the scale of the final metric to improve its numerical readability, without affecting the ranking of the results. CLIP-S also employs a comparable technique, where $w$ is assigned the value of 2.5.
To provide additional clarification, we present in Fig.~\ref{fig:graph} the impact of varying values of $w$. The raw PAC-S scores with $w=1$ lie between 0 and 0.5 on all datasets. Therefore, we decide to use a scaling factor $w$ equal to 2 which stretch the PAC-S scores between 0 and 1. 

\begin{figure*}[t]
\centering
\includegraphics[width=\linewidth]{images/generated.pdf}
\caption{Additional real and generated image-text samples used to augment the training set for positive-augmented contrastive learning.}
\label{fig:generated}
\vspace{-.15cm}
\end{figure*}

\begin{figure*}[t]
\centering
\includegraphics[width=\linewidth]{images/pascal.pdf}
\caption{Additional comparisons of existing metrics for captioning with respect to \ours on the Pascal-50S dataset. The candidate caption highlighted in green is the one preferred by humans.}
\label{fig:pascal}
\vspace{-.3cm}
\end{figure*}

\section{Generated Samples and Qualitatives}
Fig.~\ref{fig:generated} shows additional image-text generated examples used for the presented positive-augmented contrastive learning strategy. As it can be seen, both image and text generated samples are realistic and plausible and can be effectively used as an additional source of supervision.

We report in Fig.~\ref{fig:pascal} some additional qualitative comparisons between \ours and well-known metrics on the Pascal-50S dataset. These qualitative results show that in the majority of cases \ours is more aligned with the human judgments than other metrics. Finally, in Fig.~\ref{fig:foil} and~\ref{fig:flickr}, we report sample results comparing our metric with CLIP-S~\cite{hessel2021clipscore} on FOIL, Flickr8k-Expert, and Flickr8k-CF datasets. As it can be observed, \ours can correctly identify hallucinated objects and better correlates with human judgments, demonstrating its effectiveness compared to CLIP-S also from a qualitative point of view.


\begin{figure*}[t]
\centering
\includegraphics[width=\linewidth]{images/foil.pdf}
\caption{Sample images from the FOIL hallucination detection dataset and corresponding evaluation scores generated by our proposed metric in comparison with CLIP-S. Captions with hallucinated objects are highlighted in red.}
\label{fig:foil}
\end{figure*}

\begin{figure*}[t]
\centering
\includegraphics[width=\linewidth]{images/flickr.pdf}
\caption{Sample images from both Flickr8k-Expert and Flickr8k-CF datasets associated with the corresponding CLIP-S and \ours scores. The preferred caption accordingly to the human ratings is highlighted in green.}
\label{fig:flickr}
\end{figure*}
