\section{Introduction} \label{sec.intro}
We consider the problem of minimizing a function over a network. Each node of the network has a portion of the global objective function and the edges represent nodes that can communicate. Such problems arise in many application areas such as machine learning \cite{forero2010consensus,tsianos2012consensus}, sensor networks \cite{baingana2014proximal, predd2007distributed}, multi-agent coordination \cite{cao2012overview, zhou2011multirobot} and signal processing \cite{combettes2011proximal}. The goal is to collectively minimize a finite sum of functions where each component is only known to one of the $n$ nodes (or agents) of the network. This problem, known as a \emph{decentralized optimization} problem, can be represented as follows:
\begin{align}		\label{eq:prob}
	\min_{x\in \mathbb{R}^d}\quad f(x) = \frac{1}{n} \sum_{i=1}^n f_i(x),
\end{align}
where $f: \mathbb{R}^d \rightarrow \mathbb{R}$ is the global objective function, $f_i: \mathbb{R}^d \rightarrow \mathbb{R}$ for each $i\in \{1,2,...,n \}$ is the local objective function known only to agent $i$ and $x\in \mathbb{R}^d$ is the decision variable.

To decouple the computation across different agents (nodes), \eqref{eq:prob} is often reformulated as (see e.g., \cite{bertsekas2015parallel,nedic2009distributed})
\begin{equation}\label{eq:cons_prob}
\begin{aligned}	
	\min_{x_i \in \mathbb{R}^d}&\quad \frac{1}{n} \sum_{i=1}^n f_i(x_i)\\
	 \text{s.t.} &\quad  x_i = x_j, \quad \forall \,\, (i, j) \in \mathcal{E},
\end{aligned}
\end{equation}
where $x_i \in \mathbb{R}^d$ for each agent $i\in \{1,2,...,n \}$ is a local copy of the decision variable, and  $\mathcal{E}$ denotes the set of edges in the network. If the underlying network is connected, the \emph{consensus constraint} ensures that all local copies are equal, and, thus, problems \eqref{eq:prob} and \eqref{eq:cons_prob} are equivalent. For compactness, we express problem \eqref{eq:cons_prob} as
% \sg{where $x_i \in \mathbb{R}^d$ for each agent $i\in \{1,2,...,n \}$ is a local copy of the decision variable, and  $\mathcal{E}$ denotes the set of edges in the network. If the underlying network is connected, \eqref{eq:cons_prob} ensures that all local copies are equal, making \eqref{eq:cons_prob} and \eqref{eq:prob} equivalent problems. We express \eqref{eq:cons_prob} as}
% where $x_i \in \mathbb{R}^d$ for each agent $i\in \{1,2,...,n \}$ is a local copy of the decision variable, and  $\mathcal{E}$ denotes the set of edges in the network. The \emph{consensus constraint} imposed in problem \eqref{eq:cons_prob} enforces local copies of neighboring nodes to be equal. If the underlying network is connected, the constraint ensures that all local copies are equal, and, thus, problems \eqref{eq:prob} and \eqref{eq:cons_prob} are equivalent. We express problem \eqref{eq:cons_prob} as
\begin{equation}\label{eq:cons_prob1}
\begin{aligned}		
	\min_{x_i \in \mathbb{R}^d}&\quad \textbf{f} (\textbf{x}) = \frac{1}{n} \sum_{i=1}^n f_i(x_i)\\
	\text{s.t.} & \quad (\textbf{W}\otimes I_d)\textbf{x} = \textbf{x}, 
\end{aligned}
\end{equation}
where $\textbf{x} \in \mathbb{R}^{nd}$ is a concatenation of local copies $x_i$, $\textbf{W} \in \mathbb{R}^{n \times n}$ is a matrix that captures the connectivity of the underlying network, $I_d$ is the identity matrix of dimension $d$, and the operator $\otimes$ denotes the Kronecker product,  $\textbf{W}\otimes I_d \in \mathbb{R}^{nd \times nd}$. The matrix $\textbf{W}$, known as the \emph{mixing matrix}, is a symmetric, doubly-stochastic matrix with $w_{ii}>0$ and $w_{ij}>0$ ($i\neq j$) if and only if $(i, j) \in \mathcal{E}$ in the underlying network. This matrix ensures that $(\textbf{W}\otimes I_d) \textbf{x}=\textbf{x}$ if and only if $x_i=x_j \,\, \forall \,\, (i, j) \in \mathcal{E}$ in the connected network making \eqref{eq:cons_prob} and \eqref{eq:cons_prob1} equivalent problems.
% where $\textbf{x} \in \mathbb{R}^{nd}$ is a concatenation of local copies $x_i$, $\textbf{W} \in \mathbb{R}^{n \times n}$ is a matrix that captures information about the connectivity of the underlying network, $I_d$ is the identity matrix of dimension $d$, and the operator $\otimes$ denotes the Kronecker product i.e., $\textbf{W}\otimes I_d \in \mathbb{R}^{nd \times nd}$. The matrix $\textbf{W}$, known as the \emph{mixing matrix}, is a symmetric, doubly-stochastic matrix with $w_{ii}>0$ and $w_{ij}>0$ ($i\neq j$) if and only if $(i, j) \in \mathcal{E}$ in the underlying communication network. This matrix ensures that $(\textbf{W}\otimes I_d) \textbf{x}=\textbf{x}$ if and only if $x_i=x_j \,\, \forall \,\, (i, j) \in \mathcal{E}$ in the connected network making \eqref{eq:cons_prob} and \eqref{eq:cons_prob1} equivalent problems.


\asb{In this paper, we focus on gradient tracking algorithms (GTA).} \rb{Several methods have been developed within this framework that differ in the communication strategies used for sharing information across the network
%employ different communication strategies to share information across the network 
\cite{nedic2017achieving,shi2015extra,sun2022distributed,di2016next,xu2015augmented,nedic2017geometrically}.} 
\asb{We propose a generalized form of GTA that unifies the various communication strategies and allows for a direct theoretical and empirical  comparison. Specifically, we consider a general algorithmic framework whose iteration can be concisely expressed as
\begin{equation}\label{eq : general form}
\begin{aligned}
    \xmbf_{k+1} & = \Zmbf_1 \xmbf_k - \alpha \Zmbf_2 \ymbf_k \\ 
    \ymbf_{k+1} & = \Zmbf_3 \ymbf_k + \Zmbf_4 (\nabla \fmbf(\xmbf_{k+1}) - \nabla \fmbf(\xmbf_{k})), 
\end{aligned}
\end{equation}
where $\Wmbf_1$, $\Wmbf_2$, $\Wmbf_3$ and $\Wmbf_4$ are communication matrices}\rb{, symmetric doubly stochastic matrices that respect the connectivity of network}\asb{, and $\Zmbf_i = \Wmbf_i \otimes I_d, \,\, \forall \,\, i = \{1, 2, 3, 4\}$, $\alpha$ is the constant step size,
\begin{align*}
    \xmbf_k = 
    \begin{bmatrix}
        x_{1, k}\\
        x_{2, k}\\
        \vdots \\
        x_{n, k}
    \end{bmatrix} \in \mathbb{R}^{nd}\mbox{,} \quad
    \ymbf_k = 
    \begin{bmatrix}
        y_{1, k}\\
        y_{2, k}\\
        \vdots \\
        y_{n, k}
    \end{bmatrix} \in \mathbb{R}^{nd}
    \mbox{,} \quad
      \nabla \fmbf(\xmbf_k) = 
    \begin{bmatrix}
        \nabla f_1(x_{1, k})\\
        \nabla f_2(x_{2, k})\\
        \vdots \\
        \nabla f_n(x_{n, k})
    \end{bmatrix} \in \mathbb{R}^{nd},
\end{align*}
and $x_{i, k} \in \mathbb{R}^{d}$ and $y_{i, k} \in \mathbb{R}^{d}$ are local copies (for each agent $i$) of the decision and auxiliary variables, respectively, at iteration $k$. The auxiliary variable $y_{i,k}$ estimates the average gradient across the network. %At every iteration, each agent in the network communicates the vectors $x_{i, k}$ and $y_{i, k}$ with local neighbors, computes the gradient at $x_{i, k+1}$, and communicates the vector $\nabla f_i (x_{i, k+1}) - \nabla f_i (x_{i, k})$. 
This framework captures as special cases several of the most popular gradient tracking methods, e.g., DIGing~\cite{nedic2017achieving}, EXTRA~\cite{shi2015extra}, SONATA~\cite{sun2022distributed}, NEXT \cite{di2016next}, Aug-DGM~\cite{xu2015augmented} and ATC-DIgging~\cite{nedic2017geometrically}; (see Table~\ref{tab: Algorithm Def}).}   \asb{That being said, it allows for flexibility in the communication strategies, i.e., the choices of the matrices $\Wmbf_1$, $\Wmbf_2$, $\Wmbf_3$ and $\Wmbf_4$.

The iterate update form  \eqref{eq : general form} can be decomposed as: $(1)$ one \emph{computation step} of calculating the local gradient $\nabla \fmbf (\xmbf_{k+1})$, and $(2)$ one \emph{communication step} of sharing the vectors ${x}_{i, k}$ and ${y}_{i, k}$. In practice, the complexity of the two steps can vary significantly across applications. For example, XXX ADD EXAMPLES. The subject of developing algorithms (and convergence guarantees) that balance the costs received significant attention in recent years; see e.g.,~\cite{}. Developing algorithms (and convergence guarantees) that balance the costs received significant attention in recent years. In this paper, we follow the approach used in~\cite{berahas2018balancing,9479747,sayed2014diffusion,chen2012fast,berahas2019nested}. That is, we explicitly decompose the two steps, and so our algorithms are endowed with flexibility in terms of the number of communication and computation steps performed at each iteration. We show the benefits of using this flexibility theoretically and empirically.}

\newpage

% In this paper, we focus on gradient tracking algorithms. While classical first order methods converge to a neighbourhood of the solution \cite{nedic2009distributed, yuan2016convergence}, gradient tracking algorithms \cite{nedic2017achieving, nedic2017geometrically, xu2015augmented, di2016next} converge to the solution at a linear rate. They do so by maintaining an auxiliary variable $y_{i}$ at each agent $i$ in addition to the local decision variable $x_{i}$ for all $i \in \{1, 2, ..., n\}$. The auxiliary variable $y_i$ estimates the average gradient across the network. One of the first such algorithms, \emph{DIGing} \cite{nedic2017achieving}, employs the following iteration form,
% \begin{equation}\label{eq : DIGing iter}
% \begin{aligned}
%     \xmbf_{k+1} &= \Zmbf\xmbf_k - \alpha \ymbf_k   \\
%     \ymbf_{k+1} &= \Zmbf\ymbf_k + \nabla \fmbf (\xmbf_{k+1}) - \nabla \fmbf (\xmbf_k),  
% \end{aligned}
% \end{equation}
% where $\Zmbf = \Wmbf\otimes I_d \in \mathbb{R}^{nd \times nd}$, $\alpha$ is the constant step size, 
% \begin{align*}
%     \xmbf_k = 
%     \begin{bmatrix}
%         x_{1, k}\\
%         x_{2, k}\\
%         \vdots \\
%         x_{n, k}
%     \end{bmatrix} \in \mathbb{R}^{nd}\mbox{,} \quad
%     \ymbf_k = 
%     \begin{bmatrix}
%         y_{1, k}\\
%         y_{2, k}\\
%         \vdots \\
%         y_{n, k}
%     \end{bmatrix} \in \mathbb{R}^{nd}
%     \mbox{,} \quad
%       \nabla \fmbf(\xmbf_k) = 
%     \begin{bmatrix}
%         \nabla f_1(x_{1, k})\\
%         \nabla f_2(x_{2, k})\\
%         \vdots \\
%         \nabla f_n(x_{n, k})
%     \end{bmatrix} \in \mathbb{R}^{nd},
% \end{align*}
% and $x_{i, k} \in \mathbb{R}^{d}$ and $y_{i, k} \in \mathbb{R}^{d}$ are local copies (for each agent $i$) of the decision  and auxiliary variables at iteration $k$. We call the information shared by the gradient tracking algorithm across the network as it's communication strategy. \emph{DIGing} shares ${x}_{i, k}$ and ${y}_{i, k}$  which is a combine then adapt (CTA \cite{sayed2014diffusion}) communication strategy. Adapt then combine (ATC \cite{sayed2014diffusion}), combinations of ATC and CTA are other communication strategies present in literature. 
Employing a different communication strategy results in a different gradient tracking algorithm.  
This has allowed gradient tracking algorithms to be applied to a wide variety of complex decentralized settings like time varying networks \cite{nedic2017achieving}, uncoordinated stepsizes \cite{nedic2017geometrically, pu2020push, xu2015augmented}, directed networks \cite{nedic2017achieving, pu2020push}, non convex functions \cite{di2016next, sun2022distributed, sun2016distributed} and stochastic gradients \cite{pu2021distributed}. When applied to the same decentralized setting, different strategies exhibit different theoretical properties and impose different implementation constraints. Thus, one requires a way to compare communication strategies to choose one for their application. We propose a generalized form of gradient tracking algorithms to unify the various communication strategies and allow a theoretical comparison.
\sg{This has allowed gradient tracking algorithms to be applied to a wide variety of complex decentralized settings like time varying networks \cite{nedic2017achieving}, directed networks \cite{nedic2017achieving, pu2020push}, stochastic functions \cite{pu2021distributed} and many more. When applied to the same decentralized setting, different communication strategies exhibit different theoretical properties while imposing different implementation constraints. Thus, one requires a way to compare communication strategies to choose one for their application. We propose a generalized form of gradient tracking algorithms that unifies the various communication strategies and allows a theoretical comparison.}

% The iterate update form  \eqref{eq : DIGing iter} can be decomposed as: $(1)$ one \emph{computation step} of calculating the local gradient $\nabla \fmbf (\xmbf_{k+1})$, and $(2)$ one \emph{communication step} of sharing the vectors ${x}_{i, k}$ and ${y}_{i, k}$. In practice, the complexity of performing communication and computation steps is not the same and the balance differs across applications. In \cite{berahas2018balancing,9479747}, the authors argue that adapting algorithms to the decentralized application with respect to number of communication and computation steps performed each iteration can improve overall performance. We provide flexibility in terms of number of communication and computation steps performed each iteration in our generalized framework. We show benefits of using this flexibility theoretically and empirically on practical problems.

\subsection{Literature Review} \label{sec.lit}

The Decentralized Gradient Descent (DGD) method~\cite{nedic2009distributed} is considered the prototypical method for solving~\eqref{eq:prob}. The DGD method is a primal method that employs a CTA communication strategy. Under reasonable assumptions, with a constant step size, it converges to a neighbourhood of the solution \cite{yuan2016convergence}. Gradient tracking methods, e.g., EXTRA \cite{shi2015extra}, SONATA \cite{sun2022distributed}, NEXT \cite{di2016next}, DIGing \cite{nedic2017achieving}, Aug-DGM \cite{xu2015augmented}, have emerged as popular alternatives as they avoid the aforementioned shortcomings. Gradient tracking methods maintain, update and communicate an auxiliary variable that tracks the average gradient (additional cost to DGD-type method).  Usually applied to smooth convex functions over undirected networks, they are also applicable to various other settings like time varying networks \cite{nedic2017achieving}, uncoordinated stepsizes \cite{nedic2017geometrically, pu2020push, xu2015augmented}, directed networks \cite{nedic2017achieving, pu2020push}, non convex functions \cite{di2016next, sun2022distributed, sun2016distributed} and stochastic gradients \cite{pu2021distributed}. Our algorithmic framework generalizes and extends current gradient tracking methodologies, allowing for a unified analysis and direct comparison of popular approaches. In \cite{sundararajan2017robust} and \cite{zhang2019computational}, the authors presented a method to unify all CTA and ATC communication strategies in gradient tracking algorithms using semi-definite programming. Our framework is simpler and also able to encompass heterogeneous communication strategies where all information is not communicated among the same neighbors. 

Another class of methods that achieve linear convergence to the solution are primal dual methods based that work with the Lagrangian function \cite{arjevani2020ideal, jakovetic2014linear, ling2015dlm, shi2014linear, wei20131, mansoori2021flexpd, mancino2021decentralized}. These algorithms (explain what the key idea is in one sentence). Another approach to this problem is looking at the consensus constraint as a proximal operator. These algorithms aim to reduce communication load on distributed systems but are designed for networks where all pairs of nodes are connected. Algorithms such as Scaffnew \cite{mishchenko2022proxskip}, FedAvg \cite{li2019convergence}, Scaffold \cite{karimireddy2020scaffold}, Local-SGD \cite{gorbunov2021local}, FedLin \cite{mitra2021linear} achieve this by performing communications less often while continuously performing local updates.

% This paper is part of the growing literature in decentralized optimization. One of the first algorithms to solve problem \eqref{eq:cons_prob1} is Distributed Gradient Descent (DGD,  \cite{nedic2009distributed, yuan2016convergence}), a first order primal iterative method with a CTA communication structure. It has been shown to converge to a neighbourhood of the solution under a constant stepsize when the problem is smooth and convex. In \cite{berahas2018balancing} and \cite{9479747}, the authors introduced variants of DGD with an ATC communication strategy. These variants show convergence to the solution every iteration under a constant step size when communications are increased every iteration, not possible with DGD. Algorithms with similar neighbourhood convergence results can be found in \cite{mokhtari2016network, sayed2014diffusion}.

% Gradient tracking methods such as EXTRA \cite{shi2015extra}, SONATA \cite{sun2022distributed}, NEXT \cite{di2016next}, DIGing \cite{nedic2017achieving}, Aug-DGM \cite{xu2015augmented} also collectively referred to as push-pull algorithms \cite{pu2020push} are first order primal methods. They use an auxiliary variable to track the average gradient across the network. These algorithms achieve a linear rate of convergence to the solution with a constant stepsize. Usually applied to smooth convex functions over undirected networks, they are also applicable to various other settings like time varying networks \cite{nedic2017achieving}, uncoordinated stepsizes \cite{nedic2017geometrically, pu2020push, xu2015augmented}, directed networks \cite{nedic2017achieving, pu2020push}, non convex functions \cite{di2016next, sun2022distributed, sun2016distributed} and stochastic gradients \cite{pu2021distributed} and randomized communication \cite{pu2021distributed}. In this paper we unify and further generalise the communication strategies of gradient tracking algorithms present in literature while restricting ourselves to smooth convex functions over undirected graphs with deterministic gradients. We also introduce flexibility in terms of number of computation and communication steps in iterations in the general framework. In \cite{sundararajan2017robust} and \cite{zhang2019computational}, the authors presented a method to unify all CTA and ATC diffusion strategies in gradient tracking algorithms using semi-definite programming. Our framework is simpler and also able to encompass heterogeneous communication strategies where all information is not communicated among the same neighbors.

% Another class of methods that achieve linear convergence to the solution are primal dual methods based on the idea of lagrangian dualitly and alternating method of multipliers (ADMM) \cite{arjevani2020ideal, jakovetic2014linear, ling2015dlm, shi2014linear, wei20131}. Algorithms such as Flex-PD \cite{mansoori2021flexpd} and ADAPD \cite{mancino2021decentralized}  have built upon the idea of augmented lagrangian and decentralised ADMM to provide the flexibility in number of communication and computation steps. 

\sg{While Flex-PD works for smooth strongly convex functions, it does not provide the flexibility to manipulate both communications and computations at the same time while our framework does. Flex-PD shows an exponential decrease in stepsize requirement with increase in both communications and computation in an iteration. Our algorithm shows an improved stepsize and convergence rate with increase in communication. Our algorithm shows a polynomial decrease in the stepsize with increased computation. ADAPD is a framework for non convex problems. It shows improvement in performance with multiple communications. Multiple computations are performed within ADAPD in terms of solving a local problem to a certain accuracy. Our method allows to specify the exact number of computations being performed at each node. This allows greater control over the balance between computation and communication to the user based on the systems properties. ADAPD framework also does not empirically show any improvements in terms of iterations when multiple computations are performed while ours does.}

% Another approach to this problem is looking at the consensus constraint as a proximal operator. These algorithms aim to reduce communication load on distributed systems but are designed for fully connected networks where all pair of nodes are connected. Algorithms such as Scaffnew \cite{mishchenko2022proxskip}, FedAvg \cite{li2019convergence}, Scaffold \cite{karimireddy2020scaffold}, Local-SGD \cite{gorbunov2021local}, FedLin \cite{mitra2021linear} achieve this by performing communications less often while continuously performing local updates. The decision to whether or not communicate in an iteration is determined using either a deterministic or randomized sequence. The iterate update is usually accompanied by a correction term to correct for the bias from local updates. In this paper, we propose a deterministic method to introduce flexibility in number of communication and computation steps for any connectivity of the network.

\subsection{Contributions} \label{sec.contri}

We summarize our main contributions as follows:
\asb{
\begin{enumerate}
	\item We propose an algorithmic framework (\texttt{GTA}) that unifies communication strategies in gradient tracking algorithms. The framework recovers as special cases popular methods, i.e., ~\texttt{GTA-1} \cite[EXTRA]{shi2015extra}, \cite[DIGing]{nedic2017achieving}, \texttt{GTA-2} \cite[NEXT]{di2016next}, \cite[SONATA]{sun2022distributed} and \texttt{GTA-3} \cite[ATC-Digging]{nedic2017geometrically}, \cite[Aug-DGM]{xu2015augmented}; see Table~\ref{tab: Algorithm Def}.
	\item %We propose a gradient tracking algorithm (\texttt{GTA}) that provides flexibility in number of communication and computation steps performed in each iteration built over the generalisation framework. 
    We establish the conditions required on the communication strategy and the step size parameter to guarantee a global linear rate of convergence for \texttt{GTA} with multiple communication and single computation steps (\cref{th. general g=1 step cond}), and multiple communication and multiple computation steps (\cref{th. alpha bound g > 1}). We also compare the relative performance of the special case algorithms and show that the rate constant of \texttt{GTA-3} is better than \texttt{GTA-2} which is better than \texttt{GTA-1} (\cref{th.incr rates} and \cref{th.incr rates g > 1}), a comparison that has not been established in the literature.
    \item When a single computation step is performed in the \texttt{GTA} framework, we show that the rate constants improve with increasing communication steps and the extent of improvement depends on the communication strategy (Theorem~\ref{th. general g=1 rate bound}). As a consequence of this result, we could show that the improvements are much more profound in \texttt{GTA-3} compared to \texttt{GTA-2} and \texttt{GTA-1} (Corollary~\ref{col. g=1 rate bound}).
    \item We illustrate the empirical performance of the proposed \texttt{GTA} framework on quadratic problems and binary classification logistic regression problems. We show the effect of performing multiple communication and/or computation steps per iteration on the performance of the special case algorithms.
\end{enumerate}}
% \vrb{
% \begin{enumerate}
%     \item We propose a generalized gradient tracking algorithmic (GTA) framework that incorporates flexibility in the number of communication and computation steps performed at each iteration. This framework incorporates generic communication strategies that include popular gradient tracking algorithms as special cases, which are referred to as GTA-1 \cite{shi2015extra,nedic2017achieving}, GTA-2 \cite{sun2022distributed,di2016next,pu2020push} and GTA-3 \cite{xu2015augmented,nedic2017geometrically} in this paper (see Table~\ref{tab: Algorithm Def}). 
%     \item We establish conditions required on the communication strategies and the step size parameter to guarantee global linear rate of convergence of the GTA framework with multiple communication and single computation steps (see Theorem~\ref{th. general g=1 step cond}, and multiple communication and multiple computation steps (see Theorem~\ref{th. alpha bound g > 1}). We also establish relative performance of the special case algorithms and show that the rate constant of GTA-3 is better than GTA-2 which is better than GTA-1 (see Theorem~\ref{th.incr rates} and Theorem~\ref{th.incr rates g > 1}), a comparison not well established in the literature.
%     \item We show the effect of multiple communication steps on the convergence rate in the special case where single computation step is performed in the GTA framework. We show that the rate constants improve with increasing communication steps and the extent of improvement depends on the communication strategy (see Theorem~\ref{th. general g=1 rate bound}). As a consequence of this result, we could show that the improvements are much more profound in GTA-3 compared to GTA-2 and GTA-1 (see Corollary~\ref{col. g=1 rate bound}). 
    
%     \item We illustrate the empirical performance of the proposed GTA framework on quadratic and binary classification logistic regression problems where we show the improvement in performance of the special case algorithms with respect to multiple communication and computation steps. 
% \end{enumerate}}
% \sg{
% \begin{enumerate}
%     \item We propose a framework to unify communication strategies in  gradient tracking methods. We discuss popular gradient tracking methods as special cases referred to as \texttt{GTA-1} \cite{shi2015extra,nedic2017achieving}, \texttt{GTA-2} \cite{sun2022distributed,di2016next,pu2020push} and \texttt{GTA-3} \cite{xu2015augmented,nedic2017geometrically} in this paper (see Table~\ref{tab: Algorithm Def}).
%     \item We propose a gradient tracking algorithm (\texttt{GTA}) that provides flexibility in number of communication and computation steps performed in each iteration built over the generalisation framework. We establish conditions required on the communication strategy and the step size parameter to guarantee global linear rate of convergence of \texttt{GTA} with multiple communication and single computation steps (see \cref{th. general g=1 step cond}), and multiple communication and multiple computation steps (see \cref{th. alpha bound g > 1}). We also establish relative performance of the special case algorithms and show that the rate constant of \texttt{GTA-3} is better than \texttt{GTA-2} which is better than \texttt{GTA-1} (see \cref{th.incr rates} and \cref{th.incr rates g > 1}), a comparison not well established in the literature.
%     \item When a single computation step is performed in the \texttt{GTA} framework, we show that the rate constants improve with increasing communication steps and the extent of improvement depends on the communication strategy (see Theorem~\ref{th. general g=1 rate bound}). As a consequence of this result, we could show that the improvements are much more profound in \texttt{GTA-3} compared to \texttt{GTA-2} and \texttt{GTA-1} (see Corollary~\ref{col. g=1 rate bound}). 
%     \item We illustrate the empirical performance of the proposed \texttt{GTA} framework on quadratic functions and binary classification logistic regression problems. We show the improvement in performance of the special case algorithms with respect to multiple communication and computation steps. 
% \end{enumerate}
% }

\subsection{Notation} \label{sec.notation}
The average of all local vectors $s_i \in \mathbb{R}^d$ for $i \in \{1,2,\dots,n\}$ is denoted by $\bar{s} = \frac{1}{n} \sum_{i=1}^n s_i $ (component wise average across agents). Boldface lower case letters represent concatenated vectors across all agents, i.e., $\textbf{s} \in \mathbb{R}^{nd}$ is the concatenation of local vectors $s_i \in \mathbb{R}^d$ for $i \in \{1,2,\dots,n\}$, and the concatenation of vector $\bar{s}$ repeated $n$ times is denoted by $\bar{\textbf{s}} \in \mathbb{R}^{nd}$. The concatenated vector of local gradients is $\nabla \fmbf(\smbf) = 
\left[ \nabla f_1(s_{1})^T \,\, \nabla f_2(s_{2})^T \,\, \hdots \nabla f_n(s_{n})^T \right]^T \in \mathbb{R}^{nd}$. A $n$ dimensional vector of all ones is denoted by $1_n$ and an identity matrix of dimension $n$ is denoted by $I_n$. The spectral radius of square matrix $A \in \mathbb{R}^{n\times n}$ is $\rho(A)$. The three subscripts in $x_{i, k, j}$ and $y_{i, k, j}$ indicate the local copy of agent $i$ in  outer iteration $k$ and inner iteration $j$. The two subscripts in $\xmbf_{k, j}$ and $\ymbf_{k, j}$ indicate the concatenation of local copies of all agents in outer iteration $k$ and inner iteration $j$. 
%Absence of an inner iteration count implies it is 1. 
Inequalities among matrices are defined component wise, i.e. $A \geq B$ implies every element in matrix A is greater than or equal to it's corresponding element in matrix $B$. \rb{The Kronecker product of any two matrices A and B is represented using the operator $\otimes$ and denoted as $A \otimes B$.}

\subsection{Paper Organization} The paper is structured as follows. In \cref{sec.methods}, we describe our proposed framework to generalise gradient tracking methods and our algorithm that provides flexibility in number of communication and computation steps performed in each iteration. In \cref{sec.theory}, we provide theoretical convergence guarantees for the proposed algorithm. We first analyse the algorithm with only multiple communication steps being performed in each iteration in \cref{sec.mult comms} and extend the analysis to multiple communication and computation steps in \cref{sec.mult grads}. In \cref{sec.full graph res}, we analyse the algorithm under a fully connected network as it is a special case not covered by \cref{sec.mult comms} and \cref{sec.mult grads}. In \cref{sec.num_exp}, we illustrate the performance of the algorithm over  quadratic functions and binary logistic regression. Finally, we provide concluding remarks and future directions in \cref{sec.conc}.