\section{Final Remarks}\label{sec.conc}

In this paper, we have proposed a framework that unifies and generalizes communication strategies in gradient tracking methods with flexibility in the number of communication and computation steps performed at every iteration. We have established convergence guarantees for the proposed gradient tracking framework. Specifically, we have shown linear convergence for the general framework and the special cases of gradient tracking methods. Moreover, we have shown the positive influence of performing multiple communication steps at every iteration on the convergence rate and provide results that allow for the direct comparison of popular gradient tracking methods. Finally, our experiments on quadratic and logistic regression problems illustrate the effects of different communication strategies and the benefits of flexibility in terms of iterations and number of communication and computation steps. The advantages of the proposed framework can be further realized when the actual cost, i.e., a combination of the complexity of both communication and computation steps that is application specific, is considered. %This paper 
Finally, the algorithmic framework can be extended to other interesting settings such as nonconvex problems, stochastic local information, asynchronous updates, and higher-order approaches.

% Shagun version 1
% In this paper, we propose a framework to unify and generalise communication strategies in gradient tracking methods with flexibility in number of communication and computation steps performed each iteration. We establish theoretical results that enable one to compare among different communication strategies. We establish theoretical results showing increased rate of convergence with respect to iterations with increased communication steps per iteration. We show theoretical convergence for multiple computation steps per iteration. We illustrate the difference in communication strategies and the benefit of employing flexibility empirically using synthetic quadratic and logistic regression problems. The results show how the proposed flexibility can help reduce communication or computation load based on the systems requirements.

% We consider smooth strongly convex functions with deterministic gradients under a static undirected network in this work. Gradient tracking methods have been successfully used for various complex settings as discussed in \cref{sec.lit}. We wish to explore providing such flexibility for cases like stochastic gradients and non convex objectives. While we introduce heterogeneous communication strategies and provide convergence conditions, we do not provide any theoretical or empirical analysis towards the benefits or demerits of employing such a strategy. We also aim to explore methods for providing flexibility with other aspects of decentralized systems such as communication bandwidth, memory limitations and privacy.
