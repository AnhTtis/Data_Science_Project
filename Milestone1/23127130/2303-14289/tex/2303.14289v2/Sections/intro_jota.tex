
\section{Introduction} \label{sec.intro}

We consider the problem of minimizing a function over a network. In this setting, each node of the network has a portion of the global objective function and the edges represent neighbor nodes that can exchange information, i.e., communicate. The goal is to collectively minimize a finite sum of functions where each component is only known to one of the $n$ nodes (or agents) of the network. Such problems arise in many application areas such as machine learning \cite{forero2010consensus,tsianos2012consensus}, sensor networks \cite{baingana2014proximal, predd2007distributed}, multi-agent coordination \cite{cao2012overview, zhou2011multirobot} and signal processing \cite{combettes2011proximal}. The problem, known as a \emph{decentralized optimization} problem, can be represented as follows:
\begin{align}		\label{eq:prob}
	\min_{x\in \mathbb{R}^d}\quad f(x) = \frac{1}{n} \sum_{i=1}^n f_i(x),
\end{align}
where $f: \mathbb{R}^d \rightarrow \mathbb{R}$ is the global objective function, $f_i: \mathbb{R}^d \rightarrow \mathbb{R}$ for each $i\in \{1,2,...,n \}$ is the local objective function known only to node $i$ and $x\in \mathbb{R}^d$ is the decision variable.

To decouple the computation across different nodes, \eqref{eq:prob} is often reformulated as 
\begin{equation}\label{eq:cons_prob}
\begin{aligned}	
	\min_{x_i \in \mathbb{R}^d}&\quad \frac{1}{n} \sum_{i=1}^n f_i(x_i)\\
    \text{s.t.} &\quad  x_i = x_j, \quad \forall \,\, (i, j) \in \mathcal{E},
\end{aligned}
\end{equation}
where $x_i \in \mathbb{R}^d$ for each node $i\in \{1,2,...,n \}$ is a local copy of the decision variable, and  $\mathcal{E}$ denotes the set of edges of the network; see e.g., \cite{bertsekas2015parallel,nedic2009distributed}. If the underlying network is connected, the \emph{consensus} constraint ensures that all local copies are equal, and, thus, problems \eqref{eq:prob} and \eqref{eq:cons_prob} are equivalent. For compactness, we express problem \eqref{eq:cons_prob} as
\begin{equation}\label{eq:cons_prob1}
\begin{aligned}		
	\min_{x_i \in \mathbb{R}^d}&\quad \textbf{f} (\textbf{x}) = \frac{1}{n} \sum_{i=1}^n f_i(x_i)\\
	\text{s.t.} & \quad (\textbf{W}\otimes I_d)\textbf{x} = \textbf{x}, 
\end{aligned}
\end{equation}
where $\textbf{x} \in \mathbb{R}^{nd}$ is a concatenation of local copies $x_i$, $\textbf{W} \in \mathbb{R}^{n \times n}$ is a matrix that captures the connectivity of the underlying network, $I_d \in \mathbb{R}^{d \times d}$ is the identity matrix of dimension $d$, and the operator $\otimes$ denotes the Kronecker product,  $\textbf{W}\otimes I_d \in \mathbb{R}^{nd \times nd}$. The matrix $\textbf{W}$, known as the \emph{mixing} matrix, is a symmetric, doubly-stochastic matrix with $w_{ii}>0$ and $w_{ij}>0$ ($i\neq j$) if and only if $(i, j) \in \mathcal{E}$ in the underlying network. This matrix ensures that $(\textbf{W}\otimes I_d) \textbf{x}=\textbf{x}$ if and only if $x_i=x_j \,\, \forall \,\, (i, j) \in \mathcal{E}$ in the connected network, thus, % making 
\eqref{eq:cons_prob} and \eqref{eq:cons_prob1} are equivalent.% problems.

In this paper, we focus on gradient tracking methods. These first-order methods update and communicate the local decision variables, and also maintain, update and communicate an additional auxiliary variable that estimates (tracks) the gradient of the global objective function.
%\rb{These first-order methods update and communicate the local decision variables, and an additional auxiliary variable that estimates (tracks) the gradient of the global objective function.  }
%average gradient across all the nodes.} 
%These methods maintain an auxiliary variable ($y_i$) that estimates the average gradient across the network in addition to the decision variable ($x_i$) at each agent (node) $i$. 
We refer to the information shared by the methods as the communication strategy. When applied to the same decentralized setting, the theoretical convergence guarantees and practical implementations of gradient tracking methods with different communication strategies can vary significantly. %When applied to the same decentralized setting, the theoretical convergence guarantees and practical implementations of the methods vary with respect to the communication strategy. 
We propose an algorithmic framework that unifies communication strategies in gradient tracking methods and that allows for a direct theoretical and empirical comparison. The framework recovers popular gradient tracking methods as special cases.

The update form of gradient tracking methods can be generalized and decomposed as: $(1)$ one \emph{computation step} of calculating the local gradients, and $(2)$ one \emph{communication step} of sharing information based on the communication strategy. The %In practice, the 
complexity (cost) of these two steps can vary significantly across applications. For example, a large-scale machine learning problem solved on a cluster of computers with shared memory access has a higher cost of computation than communication \cite{tsianos2012consensus}. On the other hand, optimally allocating channels over a wireless sensor network requires economic usage of communications due to limited battery power \cite{magnusson2017bandwidth}.
The subject of developing algorithms (and convergence guarantees) that balance these costs has received significant attention in recent years; see e.g.,~\cite{chen2012fast,berahas2018balancing,9479747,berahas2019nested,sayed2014diffusion,zhang2018communication} and the references therein. In this paper, we follow the approach used in~\cite{berahas2018balancing} and 
explicitly decompose the two steps.
As a result, our algorithms are endowed with flexibility in terms of the number of communication and computation steps performed at each iteration. We show the benefits of this flexibility theoretically and empirically.

\subsection{Literature Review} \label{sec.lit}

Decentralized Gradient Descent (DGD) \cite{bertsekas2015parallel, nedic2009distributed}, a primal first-order method, is considered the prototypical method for solving~\eqref{eq:prob}. 
At each iteration nodes perform local computations and communicate local decision variable to neighbors. 
Gradient tracking methods, e.g., EXTRA \cite{shi2015extra}, SONATA \cite{sun2022distributed}, NEXT \cite{di2016next}, DIGing \cite{nedic2017achieving}, Aug-DGM \cite{xu2015augmented}, have emerged as popular alternatives due to their superior theoretical guarantees and empirical performance. 
They maintain, update and communicate an additional auxiliary variable that tracks the average gradient (additional communication cost compared to DGD). These methods are usually applied to smooth convex functions over undirected networks; however, they are also applicable to various other settings such as time varying networks \cite{nedic2017achieving}, uncoordinated step sizes \cite{nedic2017geometrically, xu2015augmented}, directed networks \cite{nedic2017achieving, pu2020push}, nonconvex functions \cite{di2016next, sun2022distributed}  
and stochastic gradients \cite{pu2021distributed}. Our algorithmic framework generalizes and extends current gradient tracking methodologies, allowing for a unified analysis and direct comparison of popular methods. Notably, our framework differs significantly from existing works that aim to unify gradient tracking methods. In \cite{sundararajan2017robust} and \cite{zhang2019computational}, semi-definite programming is used for this purpose. In \cite{alghunaim2020decentralized} and \cite{xu2021distributed}, the authors introduce unifying frameworks, similar to those proposed in this paper, for comparing different communication strategies. %have introduced unifying frameworks, much like ours, for comparing different communication strategies. 
However, our framework is simpler and allows for the exact specification of communication and computation steps at each iteration within the network. Furthermore, our proposed framework can accommodate a wider range of communication strategies than those discussed in \cite{sundararajan2017robust,zhang2019computational, alghunaim2020decentralized, xu2021distributed}. As a result of this increased algorithmic flexibility, our framework %This flexibility 
makes it possible to perform comprehensive comparisons among popular gradient tracking methods.

%\rb{Furthermore, our framework is significantly different from other existing frameworks that unify different communications strategies. } 
% In \cite{sundararajan2017robust,zhang2019computational}, semi-definite programming is used to unify communication strategies in gradient tracking methods. 
% \sg{In \cite{alghunaim2020decentralized} and \cite{xu2021distributed}, the authors also introduce unifying frameworks similar to ours to perform comparisons among communication strategies.
% \rb{However, o}ur framework is simpler, more intuitive in terms of exact specification of communication of quantities within the network and allows for more general communication strategies than those discussed in \cite{sundararajan2017robust,zhang2019computational, alghunaim2020decentralized, xu2021distributed}. \rb{Moreover, w}e also extend our framework to specify exact composition for communication and computation steps at each iteration and perform comparisons among gradient tracking methods with this flexibility.}


Another class of popular methods is  
primal-dual methods \cite{arjevani2020ideal, jakovetic2014linear, ling2015dlm, shi2014linear, wei20131, mansoori2021flexpd, mancino2021decentralized}. Of these methods, Flex-PD \cite{mansoori2021flexpd} and ADAPD \cite{mancino2021decentralized} allow for flexibility with respect to the number of communication and computation steps. That said, Flex-PD \cite{mansoori2021flexpd} does not show improved performance with the employment of the flexibility and ADAPD \cite{mancino2021decentralized} does not allow for a balance between communication and computation. In \cite{nguyen2022performance}, the authors propose LU-GT, an algorithm that has similarities to our framework in terms of executing multiple local computation steps within gradient tracking methods. Despite the common motivation and similarities, there are several distinct and notable differences. The LU-GT algorithm has two step size hyper-parameters, whereas our approach has only one. 
% Furthermore, our analysis results in less pessimistic step size conditions and more favorable convergence rates. 
Furthermore, our analysis results in less pessimistic step size conditions. 
It is worth noting that modifying LU-GT to align with our framework by setting the second step size to one is not possible due to the required conditions imposed in \cite{nguyen2022performance}. 
Moreover, our framework also provides a unifying foundation encompassing all popular gradient tracking methods. 
% Finally, our framework provides a unifying foundation encompassing all gradient tracking methods.

% \rb{In \cite{nguyen2022performance}, the authors introduced LU-GT, a method similar to ours in performing multiple local computation steps within gradient tracking methods. Although there are some similarities, our approach differs significantly. While LU-GT requires two hyper-parameter step sizes, our approach requires only one. Furthermore, our analysis results in more favorable convergence conditions on the stepsizes. We also note that modifying LU-GT to align with our framework by setting the second step size to one is not feasible due to their outlined convergence conditions. Additionally, our framework provides a unifying foundation encompassing all gradient tracking methods.} 
% \sg{In \cite{nguyen2022performance}, the authors present LU-GT, an algorithm that closely resembles our approach in terms of executing multiple local computation steps within gradient tracking methods. Despite a shared motivation, our work exhibits notable distinctions. In contrast to LU-GT, which necessitates two hyper-parameter step sizes, our algorithm relies on just one. Moreover, our analytical findings yield less pessimistic convergence conditions. It's worth noting that modifying LU-GT to align with our framework by setting the second step size to one is not feasible due to the convergence conditions outlined in their work. Additionally, our framework provides a unifying foundation encompassing all gradient tracking methods.}
Finally, algorithms that consider the consensus constraint as a proximal operator have been proposed. These algorithms aim to reduce communication load on distributed systems via a randomization scheme but are primarily designed for fully connected networks (all pairs of nodes are connected). 
Examples of such methods include, but are not limited to, Scaffnew \cite{mishchenko2022proxskip}, FedAvg \cite{li2019convergence}, Scaffold \cite{karimireddy2020scaffold}, Local-SGD \cite{gorbunov2021local} and FedLin \cite{mitra2021linear}.


\subsection{Contributions} \label{sec.contri}
We summarize our main contributions as follows:
\begin{enumerate}
	\item We propose a gradient tracking algorithmic framework (\texttt{GTA}) that unifies communication strategies in gradient tracking methods and provides flexibility in the number of communication and computation steps performed at each iteration. The framework recovers as special cases popular gradient tracking methods, i.e., ~\texttt{GTA-1} \cite{shi2015extra, nedic2017achieving}, \texttt{GTA-2} \cite{di2016next, sun2022distributed} and \texttt{GTA-3} \cite{nedic2017geometrically, xu2015augmented}; see \cref{tab: Algorithm Def}.
    \item We establish the conditions required, on the communication strategy and the step size parameter, that %to
    guarantee a global linear rate of convergence for \texttt{GTA} with multiple communication and multiple computation steps. 
    We also compare the relative performance of the special case gradient tracking algorithms, and illustrate the theoretical advantages of \texttt{GTA-3} over \texttt{GTA-2} (and \texttt{GTA-2} over \texttt{GTA-1}), a direct comparison not established in prior literature. 
    \item We show that the rate of convergence improves 
    with increasing the number of communication steps, and the extent of improvement depends on the communication strategy. 
    The improvements are much more profound in \texttt{GTA-3} as compared to \texttt{GTA-2} and \texttt{GTA-1}. 
    \item We illustrate the empirical performance of the proposed \texttt{GTA} framework on quadratic and binary classification logistic regression problems. We show the effect and benefits of %performing 
    multiple communication and/or computation steps per iteration on the performance of the %special case 
    algorithms.
\end{enumerate}

\subsection{Notation} \label{sec.notation}
Our proposed algorithmic framework is iterative and works with inner and outer loops. The variables $x_{i, k, j} \in \mathbb{R}^d$ and $y_{i, k, j} \in \mathbb{R}^d$ denote the local copies %copy 
of the decision variable and the auxiliary variable, respectively, of node $i$, in outer iteration $k$ and inner iteration $j$. The averages of all local decision variables and local auxiliary variables are denoted by $\bar{x}_{k, j} = \frac{1}{n} \sum_{i=1}^n x_{i, k, j}$ and $\bar{y}_{k, j} = \frac{1}{n} \sum_{i=1}^n y_{i, k, j}$, respectively. Boldface lowercase letters represent concatenated vectors of local copies
\begin{align*}
    \xmbf_{k, j} = 
    \begin{bmatrix}
        x_{1, k, j}\\
        x_{2, k, j}\\
        \vdots \\
        x_{n, k, j}
    \end{bmatrix} \in \mathbb{R}^{nd}\mbox{,} \quad
    \ymbf_{k, j} = 
    \begin{bmatrix}
        y_{1, k, j}\\
        y_{2, k, j}\\
        \vdots \\
        y_{n, k, j}
    \end{bmatrix} \in \mathbb{R}^{nd}
    \mbox{,} \quad
      \nabla \fmbf(\xmbf_{k, j}) = 
    \begin{bmatrix}
        \nabla f_1(x_{1, k, j})\\
        \nabla f_2(x_{2, k, j})\\
        \vdots \\
        \nabla f_n(x_{n, k, j})
    \end{bmatrix} \in \mathbb{R}^{nd}.%,
\end{align*}
The concatenated vector of the average of decision variables ($\Bar{x}_{k, j}$) and auxiliary variables ($\Bar{y}_{k, j}$) repeated $n$ times is denoted by $\xbb_{k, j}$ and $\ybb_{k, j}$, respectively. 
The $n$ dimensional vector of all ones is denoted by $1_n$ and the identity matrix of dimension $n$ is denoted by $I_n$. The spectral radius of square matrix $A$ is $\rho(A)$. Matrix inequalities are defined component wise. 
The Kronecker product of any two matrices $A \in \mathbb{R}^{n \times n}$ and $B \in \mathbb{R}^{d \times d}$ is represented using the operator $\otimes$ and denoted as $A \otimes B \in \mathbb{R}^{nd \times nd}$.

\subsection{Paper Organization} In \cref{sec.methods}, we describe our proposed gradient tracking algorithmic framework (\texttt{GTA}). In \cref{sec.theory}, we provide theoretical convergence guarantees for the proposed algorithmic framework for multiple communication steps and a single computation step at each iteration (\cref{sec.mult comms}) and multiple communication and computation steps at each iteration (\cref{sec.mult grads}). In \cref{sec.full graph res}, we consider the special case 
of fully connected networks. Numerical experiments on quadratic and binary classification logistic regression problems 
are presented in \cref{sec.num_exp}. Finally, we provide concluding remarks in \cref{sec.conc}.