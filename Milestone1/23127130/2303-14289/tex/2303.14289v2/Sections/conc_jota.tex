
\section{Final Remarks}\label{sec.conc}

In this paper, we have proposed a framework that unifies and generalizes communication strategies in gradient tracking methods with flexibility in the number of communication and computation steps performed at every iteration. We have established convergence guarantees for the proposed gradient tracking framework. Specifically, we have shown linear convergence for the general framework and the special cases of gradient tracking methods. Moreover, we have shown the positive influence of performing multiple communication steps at every iteration on the convergence rate and provide results that allow for the direct comparison of popular gradient tracking methods. Our experiments on quadratic and logistic regression problems illustrate the effects of different communication strategies and the benefits of the flexibility in terms of iterations and number of communication and computation steps. The advantages of the proposed framework can be further realized when the actual cost, i.e., a combination of the complexity of both communication and computation steps that is application specific, is considered. 
Finally, the algorithmic framework can be extended to other interesting settings such as nonconvex problems, stochastic local information, asynchronous updates, and higher-order approaches.