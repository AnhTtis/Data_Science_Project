@inproceedings{Liu2019,
   author = {Yang Liu and Mirella Lapata},
   journal = {arXiv preprint arXiv:1908.08345},
   note = {Problem: Bert in text summarization<br/><br/>Methods: <br/>1. insert [cls] to divide sentences<br/>2. odd and even segment embedding<br/>3. initialized position embedding, fine tunable<br/><br/>Extractive:<br/>[cls] embedding from BERTSUM<br/>then add transformer on cls embedding<br/>then binary classification <br/><br/>Abstractive: <br/>due to <b>mismatch</b> between enc&amp;decdifferent lr and warmups<br/>fine-tune enc on extractive then abs<br/>ENC: BERTSUM from Extractive<br/>DEC: 6-layered Transformer<br/><br/>Datasets:<br/>CNN/DailyMail<br/>NYT<br/>Xsum<br/><br/>Results: <br/>CNN-BERTSUMEXT(large) R1 43.85 R2 20.34 RL 39.90},
   title = {Text summarization with pretrained encoders},
   year = {2019},
}
@inproceedings{Liu2018,
   abstract = {We show that generating English Wikipedia articles can be approached as a multi-document summarization of source documents. We use extractive summarization to coarsely identify salient information and a neural abstractive model to generate the article. For the abstractive model, we introduce a decoder-only architecture that can scalably attend to very long sequences, much longer than typical encoder-decoder architectures used in sequence transduction. We show that this model can generate fluent, coherent multi-sentence paragraphs and even whole Wikipedia articles. When given reference documents, we show it can extract relevant factual information as reflected in perplexity, ROUGE scores and human evaluations.},
   author = {Peter J. Liu and Mohammad Saleh and Etienne Pot and Ben Goodrich and Ryan Sepassi and Łukasz Kaiser and Noam Shazeer},
   journal = {6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings},
   publisher = {International Conference on Learning Representations, ICLR},
   title = {Generating wikipedia by summarizing long sequences},
   year = {2018},
}
@article{Gehrmann2018,
   author = {Sebastian Gehrmann and Yuntian Deng and Alexander M Rush},
   journal = {arXiv preprint arXiv:1808.10792},
   title = {Bottom-up abstractive summarization},
   year = {2018},
}
@article{Liu2021,
   author = {Yixin Liu and Pengfei Liu},
   journal = {arXiv preprint arXiv:2106.01890},
   note = {method: <br/>generate candidate summaries<br/>assign similarity score r to candidates<br/>then use a sorted candidate sets to train h<br/><b>after training, func h can do pick best candidate, that's the meaning of constrast learning</b>},
   title = {SimCLS: A Simple Framework for Contrastive Learning of Abstractive Summarization},
   year = {2021},
}
@inproceedings{Yasunaga2019,
   author = {Michihiro Yasunaga and Jungo Kasai and Rui Zhang and Alexander R Fabbri and Irene Li and Dan Friedman and Dragomir R Radev},
   isbn = {2374-3468},
   issue = {01},
   journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
   note = {papers are all from acl anthology<br/><br/>Method:<br/>cited text spans: top2 tf-idf cosine similarity sentences in the RP for a given citation sentence},
   pages = {7386-7393},
   title = {Scisummnet: A large annotated corpus and content-impact models for scientific paper summarization with citation networks},
   volume = {33},
   year = {2019},
}
@article{Lo2019,
   author = {Kyle Lo and Lucy Lu Wang and Mark Neumann and Rodney Kinney and Dan S Weld},
   journal = {arXiv preprint arXiv:1911.02782},
   note = {papers are from Semantic Scholar, maybe overlap with pubmed},
   title = {S2ORC: The semantic scholar open research corpus},
   year = {2019},
}
@inproceedings{Chen2021,
   author = {Zhihong Chen and Yaling Shen and Yan Song and Xiang Wan},
   journal = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
   note = {thought: there must be a lot of factual erorrs in the generated report, maybe we can came up with someth to fix it.},
   pages = {5904-5914},
   title = {Cross-modal Memory Networks for Radiology Report Generation},
   year = {2021},
}
@article{West2019,
   author = {Peter West and Ari Holtzman and Jan Buys and Yejin Choi},
   journal = {arXiv preprint arXiv:1909.07405},
   note = {pretrain: use compressed sentence to predict next sentence, the core of it is the compressed one should discard most of irelevant info and retain useful info for the next goal},
   title = {Bottlesum: Unsupervised and self-supervised sentence summarization using the information bottleneck principle},
   year = {2019},
}
@inproceedings{Xu2020,
   abstract = {Recent neural network approaches to summarization are largely either selection-based extraction or generation-based abstraction. In this work, we present a neural model for single-document summarization based on joint extraction and syntactic compression. Our model chooses sentences from the document, identifies possible compressions based on constituency parses, and scores those compressions with a neural model to produce the final summary. For learning, we construct oracle extractive-compressive summaries, then learn both of our components jointly with this supervision. Experimental results on the CNN/Daily Mail and New York Times datasets show that our model achieves strong performance (comparable to state-of-the-art systems) as evaluated by ROUGE. Moreover, our approach outperforms an off-the-shelf compression module, and human and manual evaluation shows that our model's output generally remains grammatical.},
   author = {Jiacheng Xu and Greg Durrett},
   doi = {10.18653/v1/d19-1324},
   isbn = {9781950737901},
   journal = {EMNLP-IJCNLP 2019 - 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, Proceedings of the Conference},
   pages = {3292-3303},
   title = {Neural extractive text summarization with syntactic compression},
   year = {2020},
}
@inproceedings{Wang2019,
   author = {Wenbo Wang and Yang Gao and He-Yan Huang and Yuxiang Zhou},
   journal = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
   pages = {3076-3085},
   title = {Concept pointer network for abstractive summarization},
   year = {2019},
}
@article{Grenander2019,
   author = {Matt Grenander and Yue Dong and Jackie Chi Kit Cheung and Annie Louis},
   journal = {arXiv preprint arXiv:1909.04028},
   note = {auxiliary loss: make the sentence selection possibility distribution close to a rouge distribution.},
   title = {Countering the effects of lead bias in news summarization via multi-stage training and auxiliary losses},
   year = {2019},
}
@article{Sharma2019,
   author = {Eva Sharma and Luyang Huang and Zhe Hu and Lu Wang},
   journal = {arXiv preprint arXiv:1909.02059},
   note = {entity aware sentence selection},
   title = {An entity-driven framework for abstractive summarization},
   year = {2019},
}
@inproceedings{Xiao2019,
   abstract = {In this paper, we propose a novel neural single-document extractive summarization model for long documents, incorporating both the global context of the whole document and the local context within the current topic. We evaluate the model on two datasets of scientific papers, Pubmed and arXiv, where it outperforms previous work, both extractive and abstractive models, on ROUGE-1, ROUGE-2 and METEOR scores. We also show that, consistently with our goal, the benefits of our method become stronger as we apply it to longer documents. Rather surprisingly, an ablation study indicates that the benefits of our model seem to come exclusively from modeling the local context, even for the longest documents.},
   author = {Wen Xiao and Giuseppe Carenini},
   doi = {10.18653/v1/d19-1298},
   isbn = {9781950737901},
   journal = {EMNLP-IJCNLP 2019 - 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, Proceedings of the Conference},
   note = {global = document level representation<br/>local = section level, could be use},
   pages = {3011-3021},
   title = {Extractive summarization of long documents by combining global and local context},
   year = {2019},
}
@inproceedings{Cohan2015,
   abstract = {We propose a summarization approach for scientific articles which takes advantage of citation-context and the document discourse model. While citations have been previously used in generating scientific summaries, they lack the related context from the referenced article and therefore do not accurately reflect the article's content. Our method overcomes the problem of inconsistency between the citation summary and the article's content by providing context for each citation. We also leverage the inherent scientific article's discourse for producing better summaries. We show that our proposed method effectively improves over existing summarization approaches (greater than 30% improvement over the best performing baseline) in terms of ROUGE scores on TAC2014 scientific summarization dataset. While the dataset we use for evaluation is in the biomedical domain, most of our approaches are general and therefore adaptable to other domains.},
   author = {Annan Cohan and Nazli Goharian},
   doi = {10.18653/v1/d15-1045},
   isbn = {9781941643327},
   journal = {Conference Proceedings - EMNLP 2015: Conference on Empirical Methods in Natural Language Processing},
   note = {text span classfication: hypothesis, method, results, implication, disscusion, dataset-used},
   pages = {390-400},
   title = {Scientific article summarization using citation-context and article's discourse structure},
   year = {2015},
}
@inproceedings{Cohan2018,
   abstract = {Neural abstractive summarization models have led to promising results in summarizing relatively short documents. We propose the first model for abstractive summarization of single, longer-form documents (e.g., research papers). Our approach consists of a new hierarchical encoder that models the discourse structure of a document, and an attentive discourse-aware decoder to generate the summary. Empirical results on two large-scale datasets of scientific papers show that our model significantly outperforms state-of-the-art models.},
   author = {Arman Cohan and Franck Dernoncourt and Doo Soon Kim and Trung Bui and Seokhwan Kim and Walter Chang and Nazli Goharian},
   doi = {10.18653/v1/n18-2097},
   isbn = {9781948087292},
   journal = {NAACL HLT 2018 - 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference},
   pages = {615-621},
   title = {A discourse-aware attention model for abstractive summarization of long documents},
   volume = {2},
   year = {2018},
}
@article{Liu2019,
   author = {Yang Liu and Mirella Lapata},
   journal = {arXiv preprint arXiv:1905.13164},
   note = {method:<br/><br/>ranking paragraph: rouge-2 recall train regression<br/>global transformer encode<br/>decoder},
   title = {Hierarchical transformers for multi-document summarization},
   year = {2019},
} 
@inproceedings{Mao2020,
   author = {Yuning Mao and Liyuan Liu and Qi Zhu and Xiang Ren and Jiawei Han},
   journal = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
   note = {define support sentence for gold sum,<br/>then calculate the recall of sup sent in ext sum},
   pages = {4941-4957},
   title = {Facet-Aware Evaluation for Extractive Summarization},
   year = {2020},
}
@inproceedings{Ghalandari2020,
   author = {Demian Gholipour Ghalandari and Georgiana Ifrim},
   journal = {The 58th Annual Meeting of the Association for Computational Linguistics, Online, 6-8 July 2020},
   title = {Examining the State-of-the-Art in News Timeline Summarization},
   year = {2020},
}
@inproceedings{viswanathan-etal-2021-citationie,
   abstract = {Automatically extracting key information from scientific documents has the potential to help scientists work more efficiently and accelerate the pace of scientific progress. Prior work has considered extracting document-level entity clusters and relations end-to-end from raw scientific text, which can improve literature search and help identify methods and materials for a given problem. Despite the importance of this task, most existing works on scientific information extraction (SciIE) consider extraction solely based on the content of an individual paper, without considering the paper\{'\}s place in the broader literature. In contrast to prior work, we augment our text representations by leveraging a complementary source of document context: the citation graph of referential links between citing and cited papers. On a test set of English-language scientific documents, we show that simple ways of utilizing the structure and content of the citation graph can each lead to significant gains in different scientific information extraction tasks. When these tasks are combined, we observe a sizable improvement in end-to-end information extraction over the state-of-the-art, suggesting the potential for future work along this direction. We release software tools to facilitate citation-aware SciIE development.},
   author = {Vijay Viswanathan and Graham Neubig and Pengfei Liu},
   city = {Online},
   doi = {10.18653/v1/2021.acl-long.59},
   journal = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
   month = {8},
   pages = {719-731},
   publisher = {Association for Computational Linguistics},
   title = {CitationIE: Leveraging the Citation Graph for Scientific Information Extraction},
   url = {https://aclanthology.org/2021.acl-long.59},
   year = {2021},
}
@article{Yasunaga2017,
   author = {Michihiro Yasunaga and Rui Zhang and Kshitijh Meelu and Ayush Pareek and Krishnan Srinivasan and Dragomir Radev},
   journal = {arXiv preprint arXiv:1706.06681},
   note = {sentence embedding -&gt; gcn -&gt; salient sents},
   title = {Graph-based neural multi-document summarization},
   year = {2017},
}
@inproceedings{Mao2021DYLEDL,
   author = {Ziming Mao and Chen Henry Wu and Ansong Ni and Yusen Zhang and Rui Zhang and Tao Yu and Budhaditya Deb and Chenguang Zhu and Ahmed Hassan Awadallah and Dragomir Radev},
   note = {use three losses<br/>extractive: oracle loss<br/>generate loss: normal, but assign a weight for every hidden state<br/>conssitant loss: make the dynamic weight closs to the extractor distribution},
   title = {DYLE: Dynamic Latent Extraction for Abstractive Long-Input Summarization},
   year = {2021},
}
@inproceedings{Xu2020,
   author = {Jiacheng Xu and Zhe Gan and Yu Cheng and Jingjing Liu},
   journal = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
   note = {RST tree do devide doc to EDUs<br/>then use a graph conv (nodes: EDUs, edge: co-ref or RST discourse relation)},
   pages = {5021-5031},
   title = {Discourse-Aware Neural Extractive Text Summarization},
   year = {2020},
}
@article{Zhang2019,
   author = {Yuhao Zhang and Derek Merck and Emily Bao Tsai and Christopher D Manning and Curtis P Langlotz},
   journal = {arXiv preprint arXiv:1911.02541},
   note = {factual reward : parser input sentence, pick wanted variable to form a vector, then use RL to optimize it},
   title = {Optimizing the factual correctness of a summary: A study of summarizing radiology reports},
   year = {2019},
}
@article{Huang2020,
   author = {Luyang Huang and Lingfei Wu and Lu Wang},
   journal = {arXiv preprint arXiv:2005.01159},
   note = {use openIE to make a relation graph, then use relation graph embedding and roberta output},
   title = {Knowledge graph-augmented abstractive summarization with semantic-driven cloze reward},
   year = {2020},
}
@inproceedings{Ladhak2020,
   author = {Faisal Ladhak and Bryan Li and Yaser Al-Onaizan and Kathleen McKeown},
   journal = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
   pages = {5043-5054},
   title = {Exploring Content Selection in Summarization of Novel Chapters},
   year = {2020},
}
@article{Wang2019,
   author = {Kai Wang and Xiaojun Quan and Rui Wang},
   journal = {arXiv preprint arXiv:1906.05012},
   title = {BiSET: Bi-directional selective encoding with template for abstractive summarization},
   year = {2019},
}
@article{Matsumaru2020,
   author = {Kazuki Matsumaru and Sho Takase and Naoaki Okazaki},
   journal = {arXiv preprint arXiv:2005.00882},
   note = {train a text entail model, and train summarization model after deleting the non-entailment pairs in datasets},
   title = {Improving truthfulness of headline generation},
   year = {2020},
}
@article{Zhang2019,
   author = {Xingxing Zhang and Furu Wei and Ming Zhou},
   journal = {arXiv preprint arXiv:1905.06566},
   title = {HIBERT: Document level pre-training of hierarchical bidirectional transformers for document summarization},
   year = {2019},
}
@article{Wang2019,
   author = {Hong Wang and Xin Wang and Wenhan Xiong and Mo Yu and Xiaoxiao Guo and Shiyu Chang and William Yang Wang},
   journal = {arXiv preprint arXiv:1906.04466},
   title = {Self-supervised learning for contextualized extractive summarization},
   year = {2019},
}
@article{Li2020,
   author = {Wei Li and Xinyan Xiao and Jiachen Liu and Hua Wu and Haifeng Wang and Junping Du},
   journal = {arXiv preprint arXiv:2005.10043},
   note = {paragraph relation = tf idf},
   title = {Leveraging graph to improve abstractive multi-document summarization},
   year = {2020},
}
@article{Zhu2020,
   author = {Chenguang Zhu and William Hinthorn and Ruochen Xu and Qingkai Zeng and Michael Zeng and Xuedong Huang and Meng Jiang},
   journal = {arXiv preprint arXiv:2003.08612},
   note = {ie -&gt; kg -&gt; GAT -&gt; decoder},
   title = {Enhancing factual consistency of abstractive summarization},
   year = {2020},
}
@inproceedings{Zhong2020,
   author = {Ming Zhong and Pengfei Liu and Yiran Chen and Danqing Wang and Xipeng Qiu and Xuan-Jing Huang},
   journal = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
   pages = {6197-6208},
   title = {Extractive Summarization as Text Matching},
   year = {2020},
}
@article{Suhara2020,
   author = {Yoshihiko Suhara and Xiaolan Wang and Stefanos Angelidis and Wang-Chiew Tan},
   journal = {arXiv preprint arXiv:2005.01901},
   note = {opinion extraction -&gt; key event<br/>extract from multiple opinions then cluster key words<br/><br/>summarization:<br/>train a model reconstruct opinion from key event,<br/>used clustered keys to geenerate sum},
   title = {OpinionDigest: A simple framework for opinion summarization},
   year = {2020},
}
@inproceedings{athar-teufel-2012-context,
   author = {Awais Athar and Simone Teufel},
   city = {Montréal, Canada},
   journal = {Proceedings of the 2012 Conference of the North \{A\}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
   month = {6},
   pages = {597-601},
   publisher = {Association for Computational Linguistics},
   title = {Context-Enhanced Citation Sentiment Detection},
   url = {https://aclanthology.org/N12-1073},
   year = {2012},
}
@inproceedings{Jain2020,
   author = {Sarthak Jain and Madeleine van Zuylen and Hannaneh Hajishirzi and Iz Beltagy},
   journal = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
   pages = {7506-7516},
   title = {SciREX: A Challenge Dataset for Document-Level Information Extraction},
   year = {2020},
}
@inproceedings{cohan-etal-2019-structural,
   abstract = {Identifying the intent of a citation in scientific papers (e.g., background information, use of methods, comparing results) is critical for machine reading of individual publications and automated analysis of the scientific literature. We propose structural scaffolds, a multitask model to incorporate structural information of scientific papers into citations for effective classification of citation intents. Our model achieves a new state-of-the-art on an existing ACL anthology dataset (ACL-ARC) with a 13.3\{\%\} absolute increase in F1 score, without relying on external linguistic resources or hand-engineered features as done in existing methods. In addition, we introduce a new dataset of citation intents (SciCite) which is more than five times larger and covers multiple scientific domains compared with existing datasets. Our code and data are available at: https://github.com/allenai/scicite.},
   author = {Arman Cohan and Waleed Ammar and Madeleine van Zuylen and Field Cady},
   city = {Minneapolis, Minnesota},
   doi = {10.18653/v1/N19-1361},
   journal = {Proceedings of the 2019 Conference of the North \{A\}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
   month = {6},
   pages = {3586-3596},
   publisher = {Association for Computational Linguistics},
   title = {Structural Scaffolds for Citation Intent Classification in Scientific Publications},
   url = {https://aclanthology.org/N19-1361},
   year = {2019},
}
@article{Pradeep2020,
   author = {Ronak Pradeep and Xueguang Ma and Rodrigo Nogueira and Jimmy Lin},
   journal = {arXiv preprint arXiv:2010.11930},
   title = {Scientific Claim Verification with VERT5ERINI},
   year = {2020},
}
@inproceedings{Valenzuela2015,
   author = {Marco Valenzuela and Vu Ha and Oren Etzioni},
   journal = {Workshops at the twenty-ninth AAAI conference on artificial intelligence},
   note = {1. citation number<br/>2. discourse ( where the citation appear<br/>3. direct: in the references, indirect: in paper, citation sent<br/><br/>4. levels: <b>incidental</b>(related work), <b>incidental</b>(comparison), <b>important</b>(using), <b>important</b>(extending)},
   title = {Identifying meaningful citations},
   year = {2015},
}
@article{Cohan2019,
   author = {Arman Cohan and Iz Beltagy and Daniel King and Bhavana Dalvi and Daniel S Weld},
   journal = {arXiv preprint arXiv:1909.04054},
   title = {Pretrained language models for sequential sentence classification},
   year = {2019},
}
@article{Lauscher2021,
   author = {Anne Lauscher and Brandon Ko and Bailey Kuhl and Sophie Johnson and David Jurgens and Arman Cohan and Kyle Lo},
   journal = {arXiv preprint arXiv:2107.00414},
   title = {MultiCite: Modeling realistic citations requires moving beyond the single-sentence single-label setting},
   year = {2021},
}
@article{Ju2021,
   author = {Jiaxin Ju and Ming Liu and Huan Yee Koh and Yuan Jin and Lan Du and Shirui Pan},
   journal = {arXiv preprint arXiv:2110.01280},
   note = {2 views, pick topk, reordering},
   title = {Leveraging Information Bottleneck for Scientific Document Summarization},
   year = {2021},
}
@inproceedings{Hardy2018,
   author = {Hardy Hardy and Andreas Vlachos},
   journal = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
   pages = {768-773},
   title = {Guided Neural Language Generation for Abstractive Summarization using Abstract Meaning Representation},
   year = {2018},
}
@article{Liao2018,
   abstract = {Generating an abstract from a collection of documents is a desirable capability for many real-world applications. However, abstractive approaches to multi-document summarization have not been thoroughly investigated. This paper studies the feasibility of using Abstract Meaning Representation (AMR), a semantic representation of natural language grounded in linguistic theory, as a form of content representation. Our approach condenses source documents to a set of summary graphs following the AMR formalism. The summary graphs are then transformed to a set of summary sentences in a surface realization step. The framework is fully data-driven and flexible. Each component can be optimized independently using small-scale, in-domain training data. We perform experiments on benchmark summarization datasets and report promising results. We also describe opportunities and challenges for advancing this line of research.},
   author = {Kexin Liao and Logan Lebanoff and Fei Liu},
   journal = {Proceedings of the 27th International Conference on Computational Linguistics},
   pages = {1178-1190},
   title = {Abstract Meaning Representation for Multi-Document Summarization},
   url = {http://arxiv.org/abs/1806.05655},
   year = {2018},
}
@article{Dohare2017,
   abstract = {With an ever increasing size of text present on the Internet, automatic summary generation remains an important problem for natural language understanding. In this work we explore a novel full-fledged pipeline for text summarization with an intermediate step of Abstract Meaning Representation (AMR). The pipeline proposed by us first generates an AMR graph of an input story, through which it extracts a summary graph and finally, generate summary sentences from this summary graph. Our proposed method achieves state-of-the-art results compared to the other text summarization routines based on AMR. We also point out some significant problems in the existing evaluation methods, which make them unsuitable for evaluating summary quality.},
   author = {Shibhansh Dohare and Harish Karnick and Vivek Gupta},
   issn = {2331-8422},
   journal = {arXiv preprint arXiv:1706.01678},
   title = {Text Summarization using Abstract Meaning Representation},
   url = {http://arxiv.org/abs/1706.01678},
   year = {2017},
}
@inproceedings{Liu2015,
   abstract = {We present a novel abstractive summarization framework that draws on the recent development of a treebank for the Abstract Meaning Representation (AMR). In this framework, the source text is parsed to a set of AMR graphs, the graphs are transformed into a summary graph, and then text is generated from the summary graph. We focus on the graph-to-graph transformation that reduces the source semantic graph into a summary graph, making use of an existing AMR parser and assuming the eventual availability of an AMR-to-text generator. The framework is data-driven, trainable, and not specifically designed for a particular domain. Experiments on gold-standard AMR annotations and system parses show promising results. Code is available at: https://github.com/summarization.},
   author = {Fei Liu and Jeffrey Flanigan and Sam Thomson and Norman Sadeh and Noah A Smith},
   doi = {10.3115/v1/n15-1114},
   isbn = {9781941643495},
   journal = {NAACL HLT 2015 - 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference},
   pages = {1077-1086},
   title = {Toward abstractive summarization using semantic representations},
   year = {2015},
}
@inproceedings{Luu2021,
   author = {Kelvin Luu and Xinyi Wu and Rik Koncel-Kedziorski and Kyle Lo and Isabel Cachola and Noah A Smith},
   journal = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
   pages = {2130-2144},
   title = {Explaining Relationships Between Scientific Documents},
   year = {2021},
}
@inproceedings{peyrard-2019-simple,
   abstract = {Research on summarization has mainly been driven by empirical approaches, crafting systems to perform well on standard datasets with the notion of information Importance remaining latent. We argue that establishing theoretical models of Importance will advance our understanding of the task and help to further improve summarization systems. To this end, we propose simple but rigorous definitions of several concepts that were previously used only intuitively in summarization: Redundancy, Relevance, and Informativeness. Importance arises as a single quantity naturally unifying these concepts. Additionally, we provide intuitions to interpret the proposed quantities and experiments to demonstrate the potential of the framework to inform and guide subsequent works.},
   author = {Maxime Peyrard},
   city = {Florence, Italy},
   doi = {10.18653/v1/P19-1101},
   journal = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
   month = {7},
   note = {it didnt discuss how to model a semantic unit<br/>and neglect readableness<br/><br/>redundancy<br/>relevance<br/>informativeness<br/>Importance},
   pages = {1059-1073},
   publisher = {Association for Computational Linguistics},
   title = {A Simple Theoretical Model of Importance for Summarization},
   url = {https://aclanthology.org/P19-1101},
   year = {2019},
}
@inproceedings{lee-etal-2021-enhancing,
   abstract = {Text style transfer aims to alter the style (e.g., sentiment) of a sentence while preserving its content. A common approach is to map a given sentence to content representation that is free of style, and the content representation is fed to a decoder with a target style. Previous methods in filtering style completely remove tokens with style at the token level, which incurs the loss of content information. In this paper, we propose to enhance content preservation by implicitly removing the style information of each token with reverse attention, and thereby retain the content. Furthermore, we fuse content information when building the target style representation, making it dynamic with respect to the content. Our method creates not only style-independent content representation, but also content-dependent style representation in transferring style. Empirical results show that our method outperforms the state-of-the-art baselines by a large margin in terms of content preservation. In addition, it is also competitive in terms of style transfer accuracy and fluency.},
   author = {Dongkyu Lee and Zhiliang Tian and Lanqing Xue and Nevin L Zhang},
   city = {Online},
   doi = {10.18653/v1/2021.acl-long.8},
   journal = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
   month = {8},
   note = {pretrain a style classifier to tell pos or neg},
   pages = {93-102},
   publisher = {Association for Computational Linguistics},
   title = {Enhancing Content Preservation in Text Style Transfer Using Reverse Attention and Conditional Layer Normalization},
   url = {https://aclanthology.org/2021.acl-long.8},
   year = {2021},
}
@inproceedings{An2021,
   author = {Chenxin An and Ming Zhong and Yiran Chen and Danqing Wang and Xipeng Qiu and Xuanjing Huang},
   isbn = {2374-3468},
   issue = {14},
   journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
   pages = {12498-12506},
   title = {Enhancing scientific papers summarization with citation graph},
   volume = {35},
   year = {2021},
}
@article{Huang2020,
   author = {Ting-Hao'Kenneth' Huang and Chieh-Yang Huang and Chien-Kuang Cornelia Ding and Yen-Chia Hsu and C Lee Giles},
   journal = {arXiv preprint arXiv:2005.02367},
   note = {annotated abstract based on research aspect},
   title = {CODA-19: using a non-expert crowd to annotate research aspects on 10,000+ abstracts in the COVID-19 open research dataset},
   year = {2020},
}
@article{Meng2021,
   author = {Rui Meng and Khushboo Thaker and Lei Zhang and Yue Dong and Xingdi Yuan and Tong Wang and Daqing He},
   journal = {arXiv preprint arXiv:2106.00130},
   title = {Bringing Structure into Summaries: a Faceted Summarization Dataset for Long Scientific Documents},
   year = {2021},
}
@article{DeYoung2021,
   author = {Jay DeYoung and Iz Beltagy and Madeleine van Zuylen and Bailey Kuehl and Lucy Lu Wang},
   journal = {arXiv preprint arXiv:2104.06486},
   title = {MS2: Multi-Document Summarization of Medical Studies},
   year = {2021},
}
@inproceedings{Bevilacqua2021,
   author = {Michele Bevilacqua and Rexhina Blloshmi and Roberto Navigli},
   title = {One SPRING to rule them both: Symmetric AMR semantic parsing and generation without a complex pipeline},
   year = {2021},
}
@inproceedings{Manakul2021,
   author = {Potsawee Manakul and Mark Gales},
   journal = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
   pages = {6026-6041},
   title = {Long-span summarization via local attention and content selection},
   year = {2021},
}
@inproceedings{Pilault2020,
   author = {Jonathan Pilault and Raymond Li and Sandeep Subramanian and Christopher Pal},
   journal = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
   note = {extract sents<br/>using intro or extracted sents to generate sum throught a big PLM},
   pages = {9308-9319},
   title = {On extractive and abstractive neural document summarization with transformer language models},
   year = {2020},
}
@article{You2020,
   author = {Yuning You and Tianlong Chen and Yongduo Sui and Ting Chen and Zhangyang Wang and Yang Shen},
   journal = {Advances in Neural Information Processing Systems},
   pages = {5812-5823},
   title = {Graph contrastive learning with augmentations},
   volume = {33},
   year = {2020},
}
@inproceedings{Nan2021,
   abstract = {A commonly observed problem with the state-of-the art abstractive summarization models is that the generated summaries can be factually inconsistent with the input documents. The fact that automatic summarization may produce plausible-sounding yet inaccurate summaries is a major concern that limits its wide application. In this paper we present an approach to address factual consistency in summarization. We first propose an efficient automatic evaluation metric to measure factual consistency; next, we propose a novel learning algorithm that maximizes the proposed metric during model training. Through extensive experiments, we confirm that our method is effective in improving factual consistency and even overall quality of the summaries, as judged by both automatic metrics and human evaluation.},
   author = {Feng Nan and Cicero dos Santos and Henghui Zhu and Patrick Ng and Kathleen McKeown and Ramesh Nallapati and Dejiao Zhang and Zhiguo Wang and Andrew O Arnold and Bing Xiang},
   city = {Online},
   doi = {10.18653/v1/2021.acl-long.536},
   journal = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
   month = {8},
   note = {construct a question and answer pair sets from gold sum<br/>get the log likelihood of those pair of doc and sum = QUALS<br/>use QUALS points to do contrastive learning},
   pages = {6881-6894},
   publisher = {Association for Computational Linguistics},
   title = {Improving Factual Consistency of Abstractive Summarization via Question Answering},
   url = {https://aclanthology.org/2021.acl-long.536},
   year = {2021},
}
@inproceedings{Xu2021,
   author = {Yumo Xu and Mirella Lapata},
   journal = {ACL/IJCNLP},
   title = {Generating Query Focused Summaries from Query-Free Resources},
   year = {2021},
}
@inproceedings{Xu2020,
   author = {Yumo Xu and Mirella Lapata},
   journal = {Proceedings of the 2020 Conference on empirical methods in natural language processing (EMNLP)},
   note = {using qa datasets to train the sentence selector},
   pages = {3632-3645},
   title = {Coarse-to-fine query focused multi-document summarization},
   year = {2020},
}
@article{Cao2021,
   author = {Shuyang Cao and Lu Wang},
   journal = {ArXiv},
   note = {summary representation: average over all, entity tokens, last token<br/>positive: back translation<br/>negtive:  swapENT, maskEnt, MaskRel, RegenENt},
   title = {CLIFF: Contrastive Learning for Improving Faithfulness and Factuality in Abstractive Summarization},
   volume = {abs/2109.09209},
   year = {2021},
}
@inproceedings{Cao2018,
   author = {Ziqiang Cao and Furu Wei and Wenjie Li and Sujian Li},
   isbn = {2374-3468},
   issue = {1},
   journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
   title = {Faithful to the original: Fact aware neural abstractive summarization},
   volume = {32},
   year = {2018},
}
@inproceedings{Falke2019,
   author = {Tobias Falke and Leonardo F R Ribeiro and Prasetya Ajie Utama and Ido Dagan and Iryna Gurevych},
   journal = {ACL},
   title = {Ranking Generated Summaries by Correctness: An Interesting but Challenging Application for Natural Language Inference},
   year = {2019},
}
@article{Dou2020,
   author = {Zi-Yi Dou and Pengfei Liu and Hiroaki Hayashi and Zhengbao Jiang and Graham Neubig},
   journal = {arXiv preprint arXiv:2010.08014},
   title = {Gsum: A general framework for guided neural abstractive summarization},
   year = {2020},
}
@article{Narayan2021,
   author = {Shashi Narayan and Yao Zhao and Joshua Maynez and Gonçalo Simoes and Vitaly Nikolaev and Ryan McDonald},
   journal = {arXiv preprint arXiv:2104.07606},
   title = {Planning with Learned Entity Prompts for Abstractive Summarization},
   year = {2021},
}
@article{He2020,
   author = {Junxian He and Wojciech Kryściński and Bryan McCann and Nazneen Rajani and Caiming Xiong},
   journal = {arXiv preprint arXiv:2012.04281},
   note = {keyword extraction:<br/>    select sents based on ROUGE<br/>    longest sub seq<br/>    remove stop and duplicate words},
   title = {Ctrlsum: Towards generic controllable text summarization},
   year = {2020},
}
@article{Maynez2020,
   author = {Joshua Maynez and Shashi Narayan and Bernd Bohnet and Ryan T McDonald},
   journal = {ArXiv},
   title = {On Faithfulness and Factuality in Abstractive Summarization},
   volume = {abs/2005.00661},
   year = {2020},
}
@inproceedings{Scialom2021,
   author = {Thomas Scialom and Paul-Alexis Dray and Patrick Gallinari and Sylvain Lamprier and Benjamin Piwowarski and Jacopo Staiano and Alex Wang},
   title = {QuestEval: Summarization Asks for Fact-based Evaluation},
   year = {2021},
}
@article{Fabbri2021,
   author = {Alexander R Fabbri and Wojciech Kryściński and Bryan McCann and Caiming Xiong and Richard Socher and Dragomir Radev},
   journal = {Transactions of the Association for Computational Linguistics},
   pages = {391-409},
   publisher = {MIT Press},
   title = {Summeval: Re-evaluating summarization evaluation},
   volume = {9},
   year = {2021},
}
@article{Chen2018,
   author = {Yen-Chun Chen and Mohit Bansal},
   journal = {ArXiv},
   title = {Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting},
   volume = {abs/1805.11080},
   year = {2018},
}
@inproceedings{Hsu2018,
   author = {Wan Ting Hsu and Chieh-Kai Lin and Ming-Ying Lee and Kerui Min and Jing Tang and Min Sun},
   journal = {ACL},
   title = {A Unified Model for Extractive and Abstractive Summarization using Inconsistency Loss},
   year = {2018},
}
@article{Wang2020,
   author = {Danqing Wang and Pengfei Liu and Yining Zheng and Xipeng Qiu and Xuanjing Huang},
   journal = {arXiv preprint arXiv:2004.12393},
   note = {sentence node feature = CNN + LSTM<br/>edge between word and sent = TF-IDF<br/><br/>},
   title = {Heterogeneous graph neural networks for extractive document summarization},
   year = {2020},
}
@inproceedings{Hu2017,
   author = {Zhiting Hu and Zichao Yang and Xiaodan Liang and Ruslan Salakhutdinov and Eric P Xing},
   isbn = {2640-3498},
   journal = {International Conference on Machine Learning},
   pages = {1587-1596},
   publisher = {PMLR},
   title = {Toward controlled generation of text},
   year = {2017},
}
@article{He2020,
   author = {Junxian He and Xinyi Wang and Graham Neubig and Taylor Berg-Kirkpatrick},
   journal = {arXiv preprint arXiv:2002.03912},
   title = {A probabilistic formulation of unsupervised text style transfer},
   year = {2020},
}
@inproceedings{Fu2018,
   author = {Zhenxin Fu and Xiaoye Tan and Nanyun Peng and Dongyan Zhao and Rui Yan},
   isbn = {2374-3468},
   issue = {1},
   journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
   title = {Style transfer in text: Exploration and evaluation},
   volume = {32},
   year = {2018},
}
@inproceedings{Manakul2021,
   author = {Potsawee Manakul and Mark John Francis Gales},
   journal = {EMNLP},
   title = {Sparsity and Sentence Structure in Encoder-Decoder Attention of Summarization Systems},
   year = {2021},
}
@inproceedings{Chen2021,
   abstract = {With the continuous upgrading of the summarization systems driven by deep neural networks, researchers have higher requirements on the quality of the generated summaries, which should be not only fluent and informative but also factually correct. As a result, the field of factual evaluation has developed rapidly recently. Despite its initial progress in evaluating generated summaries, the meta-evaluation methodologies of factuality metrics are limited in their opacity, leading to the insufficient understanding of factuality metrics' relative advantages and their applicability. In this paper, we present an adversarial meta-evaluation methodology that allows us to (i) diagnose the fine-grained strengths and weaknesses of 6 existing top-performing metrics over 24 diagnostic test datasets, (ii) search for directions for further improvement by data augmentation. Our observations from this work motivate us to propose several calls for future research. We make all codes, diagnostic test datasets, trained factuality models available: https://github.com/zide05/AdvFact.},
   author = {Yiran Chen and Pengfei Liu and Xipeng Qiu},
   city = {Punta Cana, Dominican Republic},
   journal = {Findings of the Association for Computational Linguistics: EMNLP 2021},
   month = {11},
   pages = {2082-2095},
   publisher = {Association for Computational Linguistics},
   title = {Are Factuality Checkers Reliable? Adversarial Meta-evaluation of Factuality in Summarization},
   url = {https://aclanthology.org/2021.findings-emnlp.179},
   year = {2021},
}
@article{Zhou2019,
   abstract = {Fact verification (FV) is a challenging task which requires to retrieve relevant evidence from plain text and use the evidence to verify given claims. Many claims require to simultaneously integrate and reason over several pieces of evidence for verification. However, previous work employs simple models to extract information from evidence without letting evidence communicate with each other, e.g., merely concatenate the evidence for processing. Therefore, these methods are unable to grasp sufficient relational and logical information among the evidence. To alleviate this issue, we propose a graph-based evidence aggregating and reasoning (GEAR) framework which enables information to transfer on a fully-connected evidence graph and then utilizes different aggregators to collect multi-evidence information. We further employ BERT, an effective pre-trained language representation model, to improve the performance. Experimental results on a large-scale benchmark dataset FEVER have demonstrated that GEAR could leverage multi-evidence information for FV and thus achieves the promising result with a test FEVER score of 67.10%. Our code is available at https://github.com/thunlp/GEAR.},
   author = {Jie Zhou and Xu Han and Cheng Yang and Zhiyuan Liu and Lifeng Wang and Changcheng Li and Maosong Sun},
   month = {7},
   title = {GEAR: Graph-based Evidence Aggregating and Reasoning for Fact Verification},
   url = {http://arxiv.org/abs/1908.01843},
   year = {2019},
}
@article{Zhao2020,
   author = {Z Zhao and Shay B Cohen and Bonnie Lynn Webber},
   journal = {ArXiv},
   title = {Reducing Quantity Hallucinations in Abstractive Summarization},
   volume = {abs/2009.13312},
   year = {2020},
}
@inproceedings{Dong2020,
   author = {Yue Dong and Shuohang Wang and Zhe Gan and Yu Cheng and Jackie Chi Kit Cheung and Jingjing Liu},
   journal = {EMNLP},
   title = {Multi-Fact Correction in Abstractive Text Summarization},
   year = {2020},
}
@inproceedings{Zhou2021,
   author = {Chunting Zhou and Jiatao Gu and Mona T Diab and Paco Guzmán and Luke Zettlemoyer and Marjan Ghazvininejad},
   journal = {FINDINGS},
   title = {Detecting Hallucinated Content in Conditional Neural Sequence Generation},
   year = {2021},
}
@inproceedings{Desai2020,
   author = {Shrey Desai and Jiacheng Xu and Greg Durrett},
   journal = {EMNLP},
   title = {Compressive Summarization with Plausibility and Salience Modeling},
   year = {2020},
}
@inproceedings{Xu2020,
   author = {Jiacheng Xu and Shrey Desai and Greg Durrett},
   journal = {EMNLP},
   title = {Understanding Neural Abstractive Summarization Models via Uncertainty},
   year = {2020},
}
@article{Chen2021,
   author = {Sihao Chen and Fan Zhang and Kazoo Sone and Dan Roth},
   journal = {ArXiv},
   title = {Improving Faithfulness in Abstractive Summarization with Contrast Candidate Generation and Selection},
   volume = {abs/2104.09061},
   year = {2021},
}
@article{Durmus2020,
   author = {Esin Durmus and He He and Mona T Diab},
   journal = {ArXiv},
   title = {FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization},
   volume = {abs/2005.03754},
   year = {2020},
}
@article{Narayan2018,
   author = {Shashi Narayan and Shay B Cohen and Mirella Lapata},
   journal = {arXiv preprint arXiv:1808.08745},
   title = {Don't give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization},
   year = {2018},
}
@article{Hayashi2020,
   author = {Hiroaki Hayashi and Wojciech Kryscinski and Bryan McCann and Nazneen Rajani and Caiming Xiong},
   journal = {ArXiv},
   title = {What's New? Summarizing Contributions in Scientific Literature},
   volume = {abs/2011.03161},
   year = {2020},
}
@article{Qazvinian2008,
   author = {Vahed Qazvinian and Dragomir R Radev},
   journal = {arXiv preprint arXiv:0807.1560},
   title = {Scientific paper summarization using citation summary networks},
   year = {2008},
}
@article{Elkiss2008,
   author = {Aaron Elkiss and Siwei Shen and Anthony Fader and Güneş Erkan and David States and Dragomir Radev},
   issn = {1532-2882},
   issue = {1},
   journal = {Journal of the American Society for Information Science and Technology},
   pages = {51-62},
   publisher = {Wiley Online Library},
   title = {Blind men and elephants: What do citation summaries tell us about a research article?},
   volume = {59},
   year = {2008},
}
@article{Erkan2004,
   author = {Günes Erkan and Dragomir R Radev},
   issn = {1076-9757},
   journal = {Journal of artificial intelligence research},
   pages = {457-479},
   title = {Lexrank: Graph-based lexical centrality as salience in text summarization},
   volume = {22},
   year = {2004},
}
@inproceedings{Cao2017,
   author = {Ziqiang Cao and Wenjie Li and Sujian Li and Furu Wei},
   isbn = {2374-3468},
   issue = {1},
   journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
   title = {Improving multi-document summarization via text classification},
   volume = {31},
   year = {2017},
}
@inproceedings{Krishna2018,
   author = {Kundan Krishna and Balaji Vasan Srinivasan},
   journal = {NAACL},
   title = {Generating Topic-Oriented Summaries Using Neural Attention},
   year = {2018},
}
@inproceedings{Frermann2019,
   author = {Lea Frermann and A Klementiev},
   journal = {ACL},
   title = {Inducing Document Structure for Aspect-based Summarization},
   year = {2019},
}
@article{Cao2021,
   author = {Shuyang Cao and Lu Wang},
   journal = {arXiv preprint arXiv:2104.01724},
   title = {Inference Time Style Control for Summarization},
   year = {2021},
}
@article{Dong2020,
   author = {Yue Dong and Andrei Mircea and Jackie C K Cheung},
   journal = {arXiv preprint arXiv:2005.00513},
   title = {Discourse-Aware Unsupervised Summarization of Long Scientific Documents},
   year = {2020},
}
@article{Amplayo2021,
   author = {Reinald Kim Amplayo and Stefanos Angelidis and Mirella Lapata},
   journal = {arXiv preprint arXiv:2109.03171},
   title = {Aspect-controllable opinion summarization},
   year = {2021},
}
@article{Huebner2021,
   author = {Andras Huebner and Wei Ji and Xiang Xiao},
   journal = {arXiv preprint arXiv:2111.08210},
   title = {Meeting Summarization with Pre-training and Clustering Methods},
   year = {2021},
}
@inproceedings{Choi2019,
   abstract = {This paper describes our submission to the TL;DR challenge. Neural abstractive summarization models have been successful in generating fluent and consistent summaries with advancements like the copy (Pointer-generator) and coverage mechanisms. However, these models suffer from their extractive nature as they learn to copy words from the source text. In this paper, we propose a novel abstractive model based on Variational Autoencoder (VAE) to address this issue. We also propose a Unified Summarization Framework for the generation of summaries. Our model eliminates non-critical information at a sentence-level with an extractive summarization module and generates the summary word by word using an abstractive summarization module. To implement our framework, we combine submodules with state-of-the-art techniques including Pointer-Generator Network (PGN) and BERT while also using our new VAE-PGN abstractive model. We evaluate our model on the benchmark Reddit corpus as part of the TL;DR challenge and show that our model outperforms the baseline in ROUGE score while generating diverse summaries.},
   author = {Hyungtak Choi and Lohith Ravuru and Tomasz Dryjański and Sunghan Rye and Donghyun Lee and Hojung Lee and Inchul Hwang},
   city = {Tokyo, Japan},
   doi = {10.18653/v1/W19-8664},
   journal = {Proceedings of the 12th International Conference on Natural Language Generation},
   month = {10},
   pages = {510-515},
   publisher = {Association for Computational Linguistics},
   title = {VAE-PGN based Abstractive Model in Multi-stage Architecture for Text Summarization},
   url = {https://aclanthology.org/W19-8664},
   year = {2019},
}
@article{Dathathri2020,
   author = {Sumanth Dathathri and Andrea Madotto and Janice Lan and Jane Hung and Eric Frank and Piero Molino and Jason Yosinski and Rosanne Liu},
   journal = {ArXiv},
   title = {Plug and Play Language Models: A Simple Approach to Controlled Text Generation},
   volume = {abs/1912.02164},
   year = {2020},
}
@inproceedings{Li2018,
   author = {Juntao Li and Yan Song and Haisong Zhang and Dongmin Chen and Shuming Shi and Dongyan Zhao and Rui Yan},
   journal = {EMNLP},
   title = {Generating Classical Chinese Poems via Conditional Variational Autoencoder and Adversarial Training},
   year = {2018},
}
@article{Teufel2002,
   author = {Simone Teufel and Marc Moens},
   journal = {Computational Linguistics},
   pages = {409-445},
   title = {Summarizing Scientific Articles: Experiments with Relevance and Rhetorical Status},
   volume = {28},
   year = {2002},
}
@inproceedings{Angelidis2018,
   author = {Stefanos Angelidis and Mirella Lapata},
   journal = {EMNLP},
   title = {Summarizing Opinions: Aspect Extraction Meets Sentiment Prediction and They Are Both Weakly Supervised},
   year = {2018},
}
@article{Fang2021,
   author = {Le Fang and Tao Zeng and Chao-Chun Liu and Liefeng Bo and Wen Dong and Changyou Chen},
   journal = {ArXiv},
   title = {Transformer-based Conditional Variational Autoencoder for Controllable Story Generation},
   volume = {abs/2101.00828},
   year = {2021},
}
@inproceedings{Li2020,
   author = {Chunyuan Li and Xiang Gao and Yuan Li and Xiujun Li and Baolin Peng and Yizhe Zhang and Jianfeng Gao},
   journal = {EMNLP},
   title = {Optimus: Organizing Sentences via Pre-trained Modeling of a Latent Space},
   year = {2020},
}
@inproceedings{Fan2018,
   author = {Angela Fan and David Grangier and Michael Auli},
   journal = {NMT@ACL},
   title = {Controllable Abstractive Summarization},
   year = {2018},
}
@article{He2020,
   author = {Junxian He and Wojciech Kryscinski and Bryan McCann and Nazneen Rajani and Caiming Xiong},
   journal = {ArXiv},
   title = {CTRLsum: Towards Generic Controllable Text Summarization},
   volume = {abs/2012.04281},
   year = {2020},
}
@inproceedings{Stead2019,
   author = {Connor A Stead and Stephen Smith and Peter A Busch and Savanid Vatanasakdakul},
   journal = {ALTA},
   title = {Emerald 110k: A Multidisciplinary Dataset for Abstract Sentence Classification},
   year = {2019},
}
@inproceedings{Chen2020,
   abstract = {Text summarization is one of the most challenging and interesting problems in NLP. Although much attention has been paid to summarizing structured text like news reports or encyclopedia articles, summarizing conversations-an essential part of human-human/machine interaction where most important pieces of information are scattered across various utterances of different speakers-remains relatively under-investigated. This work proposes a multi-view sequence-to-sequence model by first extracting conversational structures of unstructured daily chats from different views to represent conversations and then utilizing a multi-view decoder to incorporate different views to generate dialogue summaries. Experiments on a large-scale dialogue summarization corpus demonstrated that our methods significantly outperformed previous state-of-the-art models via both automatic evaluations and human judgment. We also discussed specific challenges that current approaches faced with this task. We have publicly released our code at https://github.com/GT-SALT/Multi-View-Seq2Seq.},
   author = {Jiaao Chen and Diyi Yang},
   doi = {10.18653/v1/2020.emnlp-main.336},
   isbn = {9781952148606},
   journal = {EMNLP 2020 - 2020 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference},
   pages = {4106-4118},
   publisher = {Association for Computational Linguistics (ACL)},
   title = {Multi-view sequence-to-sequence models with conversational structure for abstractive dialogue summarization},
   year = {2020},
}
@inproceedings{Aralikatte2021,
   abstract = {Professional summaries are written with document-level information, such as the theme of the document, in mind. This is in contrast with most seq2seq decoders which simultaneously learn to focus on salient content, while deciding what to generate, at each decoding step. With the motivation to narrow this gap, we introduce Focus Attention Mechanism, a simple yet effective method to encourage decoders to proactively generate tokens that are similar or topical to the input document. Further, we propose a Focus Sampling method to enable generation of diverse summaries, an area currently understudied in summarization. When evaluated on the BBC extreme summarization task, two state-of-the-art models augmented with Focus Attention generate summaries that are closer to the target and more faithful to their input documents, outperforming their vanilla counterparts on ROUGE and multiple faithfulness measures. We also empirically demonstrate that Focus Sampling is more effective in generating diverse and faithful summaries than top-k or nucleus sampling-based decoding methods.},
   author = {Rahul Aralikatte and Shashi Narayan and Joshua Maynez and Sascha Rothe and Ryan McDonald},
   doi = {10.18653/v1/2021.acl-long.474},
   isbn = {9781954085527},
   journal = {ACL-IJCNLP 2021 - 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Proceedings of the Conference},
   pages = {6078-6095},
   publisher = {Association for Computational Linguistics (ACL)},
   title = {Focus attention: Promoting faithfulness and diversity in summarization},
   year = {2021},
}
@article{Lamers2021,
   author = {Wout S Lamers and Kevin Boyack and Vincent Larivière and Cassidy R Sugimoto and Nees Jan van Eck and Ludo Waltman and Dakota Murray},
   issn = {2050-084X},
   journal = {Elife},
   pages = {e72737},
   publisher = {eLife Sciences Publications Limited},
   title = {Meta-Research: Investigating disagreement in the scientific literature},
   volume = {10},
   year = {2021},
}
@inproceedings{Samanta2021,
   author = {Bidisha Samanta and Mohit Agrawal and Niloy Ganguly},
   journal = {ACL/IJCNLP},
   title = {A Hierarchical VAE for Calibrating Attributes while Generating Text using Normalizing Flow},
   year = {2021},
}
@inproceedings{Guu2020,
   abstract = {Language model pre-training has been shown to capture a surprising amount of world knowledge, crucial for NLP tasks such as question answering. However, this knowledge is stored implicitly in the parameters of a neural network, requiring everlarger networks to cover more facts. To capture knowledge in a more modular and interpretable way, we augment language model pretraining with a latent knowledge retriever, which allows the model to retrieve and attend over documents from a large corpus such as Wikipedia, used during pre-training, fine-tuning and inference. For the first time, we show how to pre-train such a knowledge retriever in an unsupervised manner, using masked language modeling as the learning signal and backpropagating through a retrieval step that considers millions of documents. We demonstrate the effectiveness of RetrievalAugmented Language Model pre-training (REALM) by fine-tuning on the challenging task of Open-domain Question Answering (Open-QA). We compare against state-of-the-art models for both explicit and implicit knowledge storage on three popular Open-QA benchmarks, and find that we outperform all previous methods by a significant margin (4-16% absolute accuracy), while also providing qualitative benefits such as interpretability and modularity.},
   author = {Kelvin Guu and Kenton Lee and Zora Tung and Panupong Pasupat and Ming Wei Chang},
   journal = {37th International Conference on Machine Learning, ICML 2020},
   title = {REALM: Retrieval-Augmented language model pre-training},
   volume = {PartF168147-6},
   year = {2020},
}
@inproceedings{Krishna2021,
   abstract = {The task of long-form question answering (LFQA) involves retrieving documents relevant to a given question and using them to generate a paragraph-length answer. While many models have recently been proposed for LFQA, we show in this paper that the task formulation raises fundamental challenges regarding evaluation and dataset creation that currently preclude meaningful modeling progress. To demonstrate these challenges, we first design a new system that relies on sparse attention and contrastive retriever learning to achieve state-of-the-art performance on the ELI5 LFQA dataset. While our system tops the public leaderboard, a detailed analysis reveals several troubling trends: (1) our system's generated answers are not actually grounded in the documents that it retrieves; (2) ELI5 contains significant train / validation overlap, as at least 81% of ELI5 validation questions occur in paraphrased form in the training set; (3) ROUGE-L is not an informative metric of generated answer quality and can be easily gamed; and (4) human evaluations used for other text generation tasks are unreliable for LFQA. We offer suggestions to mitigate each of these issues, which we hope will lead to more rigorous LFQA research and meaningful progress in the future.},
   author = {Kalpesh Krishna and Aurko Roy and Mohit Iyyer},
   doi = {10.18653/v1/2021.naacl-main.393},
   title = {Hurdles to Progress in Long-form Question Answering},
   year = {2021},
}
@inproceedings{Jia2019,
   abstract = {Most information extraction methods focus on binary relations expressed within single sentences. In high-value domains, however, n-ary relations are of great demand (e.g., drug-gene-mutation interactions in precision oncology). Such relations often involve entity mentions that are far apart in the document, yet existing work on cross-sentence relation extraction is generally confined to small text spans (e.g., three consecutive sentences), which severely limits recall. In this paper, we propose a novel multiscale neural architecture for document-level n-ary relation extraction. Our system combines representations learned over various text spans throughout the document and across the subrelation hierarchy. Widening the system's purview to the entire document maximizes potential recall. Moreover, by integrating weak signals across the document, multiscale modeling increases precision, even in the presence of noisy labels from distant supervision. Experiments on biomedical machine reading show that our approach substantially outperforms previous n-ary relation extraction methods.},
   author = {Robin Jia and Cliff Wong and Hoifung Poon},
   doi = {10.18653/v1/n19-1370},
   journal = {NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference},
   title = {Document-level N-ary relation extraction with multiscale representation learning},
   volume = {1},
   year = {2019},
}
@inproceedings{Li2020,
   abstract = {Event extraction, which aims to identify event triggers of pre-defined event types and their arguments of specific roles, is a challenging task in NLP. Most traditional approaches formulate this task as classification problems, with event types or argument roles taken as golden labels. Such approaches fail to model rich interactions among event types and arguments of different roles, and cannot generalize to new types or roles. This work proposes a new paradigm that formulates event extraction as multi-turn question answering. Our approach, MQAEE, casts the extraction task into a series of reading comprehension problems, by which it extracts triggers and arguments successively from a given sentence. A history answer embedding strategy is further adopted to model question answering history in the multi-turn process. By this new formulation, MQAEE makes full use of dependency among arguments and event types, and generalizes well to new types with new argument roles. Empirical results on ACE 2005 shows that MQAEE outperforms current state-of-the-art, pushing the final F1 of argument extraction to 53.4% (+2.0%). And it also has a good generalization ability, achieving competitive performance on 13 new event types even if trained only with a few samples of them.},
   author = {Fayuan Li and Weihua Peng and Yuguang Chen and Quan Wang and Lu Pan and Yajuan Lyu and Yong Zhu},
   doi = {10.18653/v1/2020.findings-emnlp.73},
   journal = {Findings of the Association for Computational Linguistics Findings of ACL: EMNLP 2020},
   title = {Event extraction as multi-turn question answering},
   year = {2020},
}
@inproceedings{Choi2017,
   abstract = {We present a framework for question answering that can efficiently scale to longer documents while maintaining or even improving performance of state-of-the-art models. While most successful approaches for reading comprehension rely on recurrent neural networks (RNNs), running them over long documents is prohibitively slow because it is difficult to parallelize over sequences. Inspired by how people first skim the document, identify relevant parts, and carefully read these parts to produce an answer, we combine a coarse, fast model for selecting relevant sentences and a more expensive RNN for producing the answer from those sentences. We treat sentence selection as a latent variable trained jointly from the answer only using reinforcement learning. Experiments demonstrate the state of the art performance on a challenging subset of the WIKIREADING dataset (Hewlett et al., 2016) and on a new dataset, while speeding up the model by 3.5x-6.7x.},
   author = {Eunsol Choi and Daniel Hewlett and Jakob Uszkoreit and Illia Polosukhin and Alexandre Lacoste and Jonathan Berant},
   doi = {10.18653/v1/P17-1020},
   journal = {ACL 2017 - 55th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)},
   title = {Coarse-to-fine question answering for long documents},
   volume = {1},
   year = {2017},
}
@inproceedings{Narayan2018,
   abstract = {Single document summarization is the task of producing a shorter version of a document while preserving its principal information content. In this paper we conceptualize extractive summarization as a sentence ranking task and propose a novel training algorithm which globally optimizes the ROUGE evaluation metric through a reinforcement learning objective. We use our algorithm to train a neural summarization model on the CNN and DailyMail datasets and demonstrate experimentally that it outperforms state-of-The-Art extractive and abstractive systems when evaluated automatically and by humans.},
   author = {Shashi Narayan and Shay B. Cohen and Mirella Lapata},
   doi = {10.18653/v1/n18-1158},
   journal = {NAACL HLT 2018 - 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference},
   title = {Ranking sentences for extractive summarization with reinforcement learning},
   volume = {1},
   year = {2018},
}
@inproceedings{Cao2020,
   abstract = {Neural abstractive summarization systems have achieved promising progress, thanks to the availability of large-scale datasets and models pre-trained with self-supervised methods. However, ensuring the factual consistency of the generated summaries for abstractive summarization systems is a challenge. We propose a post-editing corrector module to address this issue by identifying and correcting factual errors in generated summaries. The neural corrector model is pre-trained on artificial examples that are created by applying a series of heuristic transformations on reference summaries. These transformations are inspired by an error analysis of state-of-the-art summarization model outputs. Experimental results show that our model is able to correct factual errors in summaries generated by other neural summarization models and outperforms previous models on factual consistency evaluation on the CNN/DailyMail dataset. We also find that transferring from artificial error correction to downstream settings is still very challenging.},
   author = {Meng Cao and Yue Dong and Jiapeng Wu and Jackie Chi Kit Cheung},
   doi = {10.18653/v1/2020.emnlp-main.506},
   isbn = {9781952148606},
   journal = {EMNLP 2020 - 2020 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference},
   pages = {6251-6258},
   publisher = {Association for Computational Linguistics (ACL)},
   title = {Factual error correction for abstractive summarization models},
   year = {2020},
}
@inproceedings{Wojciech2020,
   abstract = {The most common metrics for assessing summarization algorithms do not account for whether summaries are factually consistent with source documents. We propose a weakly-supervised, model-based approach for verifying factual consistency and identifying conflicts between source documents and generated summaries. Training data is generated by applying a series of rule-based transformations to the sentences of source documents. The factual consistency model is then trained jointly for three tasks: 1) predict whether each summary sentence is factually consistent or not, 2) in either case, extract a span in the source document to support this consistency prediction, 3) for each summary sentence that is deemed inconsistent, extract the inconsistent span from it. Transferring this model to summaries generated by several neural models reveals that this highly scalable approach outperforms previous models, including those trained with strong supervision using datasets from related domains, such as natural language inference and fact checking. Additionally, human evaluation shows that the auxiliary span extraction tasks provide useful assistance in the process of verifying factual consistency. We also release a manually annotated dataset for factual consistency verification, code for training data generation, and trained model weights at https://github.com/salesforce/factCC.},
   author = {Wojciech Kryściński and Bryan McCann and Caiming Xiong and Richard Socher},
   doi = {10.18653/v1/2020.emnlp-main.750},
   isbn = {9781952148606},
   journal = {EMNLP 2020 - 2020 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference},
   pages = {9332-9346},
   publisher = {Association for Computational Linguistics (ACL)},
   title = {Evaluating the factual consistency of abstractive text summarization},
   year = {2020},
}
@inproceedings{,
   abstract = {Text summarization aims at compressing long documents into a shorter form that conveys the most important parts of the original document. Despite increased interest in the community and notable research effort, progress on benchmark datasets has stagnated. We critically evaluate key ingredients of the current research setup: datasets, evaluation metrics, and models, and highlight three primary shortcomings: 1) automatically collected datasets leave the task underconstrained and may contain noise detrimental to training and evaluation, 2) current evaluation protocol is weakly correlated with human judgment and does not account for important characteristics such as factual correctness, 3) models overfit to layout biases of current datasets and offer limited diversity in their outputs.},
   author = {Wojciech Kryściński and Nitish Shirish Keskar and Bryan McCann and Caiming Xiong and Richard Socher},
   doi = {10.18653/v1/d19-1051},
   isbn = {9781950737901},
   journal = {EMNLP-IJCNLP 2019 - 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, Proceedings of the Conference},
   pages = {540-551},
   publisher = {Association for Computational Linguistics},
   title = {Neural text summarization: A critical evaluation},
   year = {2020},
}
@inproceedings{Bhandari2020,
   abstract = {Automated evaluation metrics as a stand-in for manual evaluation are an essential part of the development of text-generation tasks such as text summarization. However, while the field has progressed, our standard metrics have not - for nearly 20 years ROUGE has been the standard evaluation in most summarization papers. In this paper, we make an attempt to re-evaluate the evaluation method for text summarization: assessing the reliability of automatic metrics using top-scoring system outputs, both abstractive and extractive, on recently popular datasets for both system-level and summary-level evaluation settings. We find that conclusions about evaluation metrics on older datasets do not necessarily hold on modern datasets and systems. We release a dataset of human judgments that are collected from 25 top-scoring neural summarization systems (14 abstractive and 11 extractive): https://github.com/neulab/REALSumm.},
   author = {Manik Bhandari and Pranav Gour and Atabak Ashfaq and Pengfei Liu and Graham Neubig},
   doi = {10.18653/v1/2020.emnlp-main.751},
   isbn = {9781952148606},
   journal = {EMNLP 2020 - 2020 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference},
   pages = {9347-9359},
   publisher = {Association for Computational Linguistics (ACL)},
   title = {Re-evaluating evaluation in text summarization},
   year = {2020},
}
@inproceedings{Gabriel2021,
   abstract = {While neural language models can generate text with remarkable fluency and coherence, controlling for factual correctness in generation remains an open research question. This major discrepancy between the surface-level fluency and the content-level correctness of neural generation has motivated a new line of research that seeks automatic metrics for evaluating the factuality of machine text. In this paper, we introduce GO FIGURE, a meta-evaluation framework for evaluating factuality evaluation metrics. We propose five necessary conditions to evaluate factuality metrics on diagnostic factuality data across three different summarization tasks. Our benchmark analysis on ten factuality metrics reveals that our metaevaluation framework provides a robust and efficient evaluation that is extensible to multiple types of factual consistency and standard generation metrics, including QA metrics. It also reveals that while QA metrics generally improve over standard metrics that measure factuality across domains, performance is highly dependent on the way in which questions are generated.},
   author = {Saadia Gabriel and Asli Celikyilmaz and Rahul Jha and Yejin Choi and Jianfeng Gao},
   doi = {10.18653/v1/2021.findings-acl.42},
   isbn = {9781954085541},
   journal = {Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
   pages = {478-487},
   publisher = {Association for Computational Linguistics (ACL)},
   title = {GO FIGURE: A Meta Evaluation of Factuality in Summarization},
   year = {2021},
}
@inproceedings{Xie2021,
   author = {Yuexiang Xie and Fei Sun and Yang Deng and Yaliang Li and Bolin Ding},
   journal = {EMNLP},
   title = {Factual Consistency Evaluation for Text Summarization via Counterfactual Estimation},
   year = {2021},
}
@inproceedings{Zeng2021,
   abstract = {Neural abstractive summarization systems have gained significant progress in recent years. However, abstractive summarization often produce inconsisitent statements or false facts. How to automatically generate highly abstract yet factually correct summaries? In this paper, we proposed an efficient weak-supervised adversarial data augmentation approach to form the factual consistency dataset. Based on the artificial dataset, we train an evaluation model that can not only make accurate and robust factual consistency discrimination but is also capable of making inter-pretable factual errors tracing by backpropa-gated gradient distribution on token embed-dings. Experiments and analysis conduct on public annotated summarization and factual consistency datasets demonstrate our approach effective and reasonable. Our codes can be found at https://github.com/ parZival27/GrAdualCC},
   author = {Zhiyuan Zeng and Jiaze Chen and Weiran Xu and Lei Li},
   doi = {10.18653/v1/2021.emnlp-main.337},
   title = {Gradient-Based Adversarial Factual Consistency Evaluation for Abstractive Summarization},
   year = {2021},
}
@inproceedings{Pagnoni2021,
   abstract = {Modern summarization models generate highly fluent but often factually unreliable outputs. This motivated a surge of metrics attempting to measure the factuality of automatically generated summaries. Due to the lack of common benchmarks, these metrics cannot be compared. Moreover, all these methods treat factuality as a binary concept and fail to provide deeper insights into the kinds of inconsistencies made by different systems. To address these limitations, we devise a typology of factual errors and use it to collect human annotations of generated summaries from state-of-the-art summarization systems for the CNN/DM and XSum datasets. Through these annotations, we identify the proportion of different categories of factual errors in various summarization models and benchmark factuality metrics, showing their correlation with human judgment as well as their specific strengths and weaknesses.},
   author = {Artidoro Pagnoni and Vidhisha Balachandran and Yulia Tsvetkov},
   doi = {10.18653/v1/2021.naacl-main.383},
   title = {Understanding Factuality in Abstractive Summarization with FRANK: A Benchmark for Factuality Metrics},
   year = {2021},
}
@inproceedings{Goyal2020,
   abstract = {Despite significant progress in text generation models, a serious limitation is their tendency to produce text that is factually inconsistent with information in the input. Recent work has studied whether textual entailment systems can be used to identify factual errors; however, these sentence-level entailment models are trained to solve a different problem than generation filtering and they do not localize which part of a generation is non-factual. In this paper, we propose a new formulation of entailment that decomposes it at the level of dependency arcs. Rather than focusing on aggregate decisions, we instead ask whether the semantic relationship manifested by individual dependency arcs in the generated output is supported by the input. Human judgments on this task are difficult to obtain; we therefore propose a method to automatically create data based on existing entailment or paraphrase corpora. Experiments show that our dependency arc entailment model trained on this data can identify factual inconsistencies in paraphrasing and summarization better than sentence-level methods or those based on question generation, while additionally localizing the erroneous parts of the generation.},
   author = {Tanya Goyal and Greg Durrett},
   doi = {10.18653/v1/2020.findings-emnlp.322},
   isbn = {9781952148903},
   journal = {Findings of the Association for Computational Linguistics Findings of ACL: EMNLP 2020},
   pages = {3592-3603},
   publisher = {Association for Computational Linguistics (ACL)},
   title = {Evaluating factuality in generation with dependency-level entailment},
   year = {2020},
}
@article{,
   author = {Maartje ter Hoeve and Julia Kiseleva and Maarten de Rijke},
   journal = {arXiv preprint arXiv:2012.07619},
   title = {What Makes a Good Summary? Investigating the Focus of Automatic Summarization in an Educational Context},
   year = {2020},
}
@article{Martinc2021,
   abstract = {<p>We present a set of novel neural supervised and unsupervised approaches for determining the readability of documents. In the unsupervised setting, we leverage neural language models, whereas in the supervised setting, three different neural classification architectures are tested. We show that the proposed neural unsupervised approach is robust, transferable across languages, and allows adaptation to a specific readability task and data set. By systematic comparison of several neural architectures on a number of benchmark and new labeled readability data sets in two languages, this study also offers a comprehensive analysis of different neural approaches to readability classification. We expose their strengths and weaknesses, compare their performance to current state-of-the-art classification approaches to readability, which in most cases still rely on extensive feature engineering, and propose possibilities for improvements.</p>},
   author = {Matej Martinc and Senja Pollak and Marko Robnik-Šikonja},
   doi = {10.1162/coli_a_00398},
   issn = {0891-2017},
   issue = {1},
   journal = {Computational Linguistics},
   month = {4},
   pages = {141-179},
   title = {Supervised and Unsupervised Neural Approaches to Text Readability},
   volume = {47},
   year = {2021},
}
@inproceedings{August2022,
   abstract = {Unfamiliar terminology and complex language can present barriers to understanding science. Natural language processing stands to help address these issues by automatically defining unfamiliar terms. We introduce a new task and dataset for defining scientific terms and controlling the complexity of generated definitions as a way of adapting to a specific reader's background knowledge. We test four definition generation methods for this new task, finding that a sequence-to-sequence approach is most successful. We then explore the version of the task in which definitions are generated at a target complexity level. We introduce a novel reranking approach and find in human evaluations that it offers superior fluency while also controlling complexity, compared to several controllable generation baselines.},
   author = {Tal August and Katharina Reinecke and Noah Smith},
   city = {Dublin, Ireland},
   journal = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
   month = {5},
   pages = {8298-8317},
   publisher = {Association for Computational Linguistics},
   title = {Generating Scientific Definitions with Controllable Complexity},
   url = {https://aclanthology.org/2022.acl-long.569},
   year = {2022},
}
@inproceedings{Ruan2022,
   author = {Qian Ruan and Malte Ostendorff and Georg Rehm},
   journal = {Findings of the Association for Computational Linguistics: ACL 2022},
   pages = {1292-1308},
   title = {HiStruct+: Improving Extractive Text Summarization with Hierarchical Structure Information},
   year = {2022},
}
@inproceedings{Yang2019,
   abstract = {The training objective of neural machine translation (NMT) is to minimize the loss between the words in the translated sentences and those in the references. In NMT, there is a natural correspondence between the source sentence and the target sentence. However, this relationship has only been represented using the entire neural network and the training objective is computed in word-level. In this paper, we propose a sentence-level agreement module to directly minimize the difference between the representation of source and target sentence. The proposed agreement module can be integrated into NMT as an additional training objective function and can also be used to enhance the representation of the source sentences. Empirical results on the NIST Chinese-to-English and WMT English-to-German tasks show the proposed agreement module can significantly improve the NMT performance.},
   author = {Mingming Yang and Rui Wang and Kehai Chen and Masao Utiyama and Eiichiro Sumita and Min Zhang and Tiejun Zhao},
   city = {Florence, Italy},
   doi = {10.18653/v1/P19-1296},
   journal = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
   month = {7},
   pages = {3076-3082},
   publisher = {Association for Computational Linguistics},
   title = {Sentence-Level Agreement for Neural Machine Translation},
   url = {https://aclanthology.org/P19-1296},
   year = {2019},
}
@inproceedings{,
   author = {Amjad Abu-Jbara and Dragomir Radev},
   journal = {Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies},
   pages = {500-509},
   title = {Coherent citation-based summarization of scientific papers},
   year = {2011},
}
@article{Hochreiter1997,
   author = {Sepp Hochreiter and Jürgen Schmidhuber},
   issue = {8},
   journal = {Neural computation},
   pages = {1735-1780},
   publisher = {MIT Press},
   title = {Long short-term memory},
   volume = {9},
   year = {1997},
}
@article{Chung2014,
   author = {Junyoung Chung and Caglar Gulcehre and KyungHyun Cho and Yoshua Bengio},
   journal = {arXiv preprint arXiv:1412.3555},
   title = {Empirical evaluation of gated recurrent neural networks on sequence modeling},
   year = {2014},
}
@article{Devlin2018,
   author = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
   journal = {arXiv preprint arXiv:1810.04805},
   title = {Bert: Pre-training of deep bidirectional transformers for language understanding},
   year = {2018},
}
@article{Lewis2019,
   author = {Mike Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and Abdelrahman Mohamed and Omer Levy and Ves Stoyanov and Luke Zettlemoyer},
   journal = {arXiv preprint arXiv:1910.13461},
   title = {Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension},
   year = {2019},
}
@inproceedings{Zhang2020,
   author = {Jingqing Zhang and Yao Zhao and Mohammad Saleh and Peter Liu},
   journal = {International Conference on Machine Learning},
   pages = {11328-11339},
   title = {Pegasus: Pre-training with extracted gap-sentences for abstractive summarization},
   year = {2020},
}
@article{Wang2020,
   author = {Lucy Lu Wang and Kyle Lo and Yoganand Chandrasekhar and Russell Reas and Jiangjiang Yang and Darrin Eide and Kathryn Funk and Rodney Kinney and Ziyang Liu and William Merrill and others},
   journal = {ArXiv},
   publisher = {ArXiv},
   title = {Cord-19: The covid-19 open research dataset},
   year = {2020},
}
@article{Gidiotis2020,
   author = {Alexios Gidiotis and Grigorios Tsoumakas},
   journal = {CoRR},
   title = {A Divide-and-Conquer Approach to the Summarization of Academic Articles},
   volume = {abs/2004.06190},
   url = {https://arxiv.org/abs/2004.06190},
   year = {2020},
}
@article{Rohde2021,
   author = {Tobias Rohde and Xiaoxia Wu and Yinhan Liu},
   journal = {CoRR},
   title = {Hierarchical Learning for Generation with Long Source Sequences},
   volume = {abs/2104.07545},
   url = {https://arxiv.org/abs/2104.07545},
   year = {2021},
}
@article{Guo2021,
   author = {Mandy Guo and Joshua Ainslie and David Uthus and Santiago Ontanon and Jianmo Ni and Yun-Hsuan Sung and Yinfei Yang},
   journal = {arXiv preprint arXiv:2112.07916},
   title = {Longt5: Efficient text-to-text transformer for long sequences},
   year = {2021},
}
@article{Beltagy2020,
   author = {Iz Beltagy and Matthew E Peters and Arman Cohan},
   journal = {arXiv preprint arXiv:2004.05150},
   title = {Longformer: The long-document transformer},
   year = {2020},
}
@inproceedings{Lin2004,
   author = {Chin-Yew Lin},
   journal = {Text summarization branches out},
   pages = {74-81},
   title = {Rouge: A package for automatic evaluation of summaries},
   year = {2004},
}
@inproceedings{Paice1980,
   author = {Chris D Paice},
   journal = {Proceedings of the 3rd annual ACM conference on Research and development in information retrieval},
   pages = {172-191},
   title = {The automatic generation of literature abstracts: an approach based on the identification of self-indicating phrases},
   year = {1980},
}
@article{See2017,
   author = {Abigail See and Peter J Liu and Christopher D Manning},
   journal = {arXiv preprint arXiv:1704.04368},
   title = {Get to the point: Summarization with pointer-generator networks},
   year = {2017},
}
@article{Xiao2020,
   author = {Wen Xiao and Giuseppe Carenini},
   journal = {arXiv preprint arXiv:2012.00052},
   title = {Systematically exploring redundancy reduction in summarizing long documents},
   year = {2020},
}
@article{Nallapati2016,
   author = {Ramesh Nallapati and Bowen Zhou and Caglar Gulcehre and Bing Xiang and others},
   journal = {arXiv preprint arXiv:1602.06023},
   title = {Abstractive text summarization using sequence-to-sequence rnns and beyond},
   year = {2016},
}
@article{Lu2020,
   author = {Yao Lu and Yue Dong and Laurent Charlin},
   journal = {arXiv preprint arXiv:2010.14235},
   title = {Multi-XScience: A large-scale dataset for extreme multi-document summarization of scientific articles},
   year = {2020},
}
@article{Cachola2020,
   author = {Isabel Cachola and Kyle Lo and Arman Cohan and Daniel S Weld},
   journal = {arXiv preprint arXiv:2004.15011},
   title = {TLDR: Extreme summarization of scientific documents},
   year = {2020},
}
@article{,
   author = {Richard Van Noorden},
   journal = {Nature news blog},
   title = {Global scientific output doubles every nine years},
   year = {2014},
}
@article{Chandrasekaran2019,
   author = {Muthu Kumar Chandrasekaran and Michihiro Yasunaga and Dragomir Radev and Dayne Freitag and Min-Yen Kan},
   journal = {arXiv preprint arXiv:1907.09854},
   title = {Overview and results: Cl-scisumm shared task 2019},
   year = {2019},
}
@inproceedings{Clark2019,
   abstract = {For evaluating machine-generated texts, automatic methods hold the promise of avoiding collection of human judgments, which can be expensive and time-consuming. The most common automatic metrics, like BLEU and ROUGE, depend on exact word matching, an inflexible approach for measuring semantic similarity. We introduce methods based on sentence mover's similarity; our automatic metrics evaluate text in a continuous space using word and sentence embeddings. We find that sentence-based metrics correlate with human judgments significantly better than ROUGE, both on machine-generated summaries (average length of 3.4 sentences) and human-authored essays (average length of 7.5). We also show that sentence mover's similarity can be used as a reward when learning a generation model via reinforcement learning; we present both automatic and human evaluations of summaries learned in this way, finding that our approach outperforms ROUGE.},
   author = {Elizabeth Clark and Asli Celikyilmaz and Noah A Smith},
   city = {Florence, Italy},
   doi = {10.18653/v1/P19-1264},
   journal = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
   month = {7},
   pages = {2748-2760},
   publisher = {Association for Computational Linguistics},
   title = {Sentence Mover's Similarity: Automatic Evaluation for Multi-Sentence Texts},
   url = {https://aclanthology.org/P19-1264},
   year = {2019},
}
@inproceedings{Gao2020,
   abstract = {We study unsupervised multi-document summarization evaluation metrics, which require neither human-written reference summaries nor human annotations (e.g. preferences, ratings, etc.). We propose SUPERT, which rates the quality of a summary by measuring its semantic similarity with a pseudo reference summary, i.e. selected salient sentences from the source documents, using contextualized embeddings and soft token alignment techniques. Compared to the state-of-the-art unsupervised evaluation metrics, SUPERT correlates better with human ratings by 18- 39%. Furthermore, we use SUPERT as rewards to guide a neural-based reinforcement learning summarizer, yielding favorable performance compared to the state-of-the-art unsupervised summarizers. All source code is available at https://github.com/yg211/acl20-ref-free-eval.},
   author = {Yang Gao and Wei Zhao and Steffen Eger},
   city = {Online},
   doi = {10.18653/v1/2020.acl-main.124},
   journal = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
   month = {7},
   pages = {1347-1354},
   publisher = {Association for Computational Linguistics},
   title = {SUPERT: Towards New Frontiers in Unsupervised Evaluation Metrics for Multi-Document Summarization},
   url = {https://aclanthology.org/2020.acl-main.124},
   year = {2020},
}
@inproceedings{Child2020,
   author = {Rewon Child},
   journal = {International Conference on Learning Representations},
   title = {Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images},
   year = {2020},
}
@article{Qin2022,
   author = {Lianhui Qin and Sean Welleck and Daniel Khashabi and Yejin Choi},
   journal = {arXiv preprint arXiv:2202.11705},
   title = {COLD decoding: Energy-based constrained text generation with langevin dynamics},
   year = {2022},
}
@inproceedings{Ahuja2022,
   abstract = {Generic summaries try to cover an entire document and query-based summaries try to answer document-specific questions. But real users' needs often fall in between these extremes and correspond to aspects, high-level topics discussed among similar types of documents. In this paper, we collect a dataset of realistic aspect-oriented summaries, AspectNews, which covers different subtopics about articles in news sub-domains. We annotate data across two domains of articles, earthquakes and fraud investigations, where each article is annotated with two distinct summaries focusing on different aspects for each domain. A system producing a single generic summary cannot concisely satisfy both aspects. Our focus in evaluation is how well existing techniques can generalize to these domains without seeing in-domain training data, so we turn to techniques to construct synthetic training data that have been used in query-focused summarization work. We compare several training schemes that differ in how strongly keywords are used and how oracle summaries are extracted. Our evaluation shows that our final approach yields (a) focused summaries, better than those from a generic summarization system or from keyword matching; (b) a system sensitive to the choice of keywords.},
   author = {Ojas Ahuja and Jiacheng Xu and Akshay Gupta and Kevin Horecka and Greg Durrett},
   city = {Dublin, Ireland},
   doi = {10.18653/v1/2022.acl-long.449},
   journal = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
   month = {5},
   pages = {6494-6506},
   publisher = {Association for Computational Linguistics},
   title = {ASPECTNEWS: Aspect-Oriented Summarization of News Documents},
   url = {https://aclanthology.org/2022.acl-long.449},
   year = {2022},
}
@article{Liang2022,
   author = {Yunlong Liang and Fandong Meng and Chulun Zhou and Jinan Xu and Yufeng Chen and Jinsong Su and Jie Zhou},
   journal = {arXiv preprint arXiv:2203.03820},
   title = {A variational hierarchical model for neural cross-lingual summarization},
   year = {2022},
}
@inproceedings{Katsimpras2022,
   author = {Georgios Katsimpras and Georgios Paliouras},
   journal = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
   pages = {1947-1957},
   title = {Predicting Intervention Approval in Clinical Trials through Multi-Document Summarization},
   year = {2022},
}
@inproceedings{Amplayo2021,
   author = {Reinald Kim Amplayo and Mirella Lapata},
   journal = {Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume},
   pages = {2662-2672},
   title = {Informative and Controllable Opinion Summarization},
   year = {2021},
}
@article{Jin2020,
   author = {Hanqi Jin and Tianming Wang and Xiaojun Wan},
   doi = {10.1609/aaai.v34i05.6312},
   issue = {05},
   journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
   month = {4},
   pages = {8026-8033},
   title = {SemSUM: Semantic Dependency Guided Neural Abstractive Summarization},
   volume = {34},
   url = {https://ojs.aaai.org/index.php/AAAI/article/view/6312},
   year = {2020},
}
@inproceedings{Li2018,
   abstract = {Neural network models, based on the attentional encoder-decoder model, have good capability in abstractive text summarization. However, these models are hard to be controlled in the process of generation, which leads to a lack of key information. We propose a guiding generation model that combines the extractive method and the abstractive method. Firstly, we obtain keywords from the text by a extractive model. Then, we introduce a Key Information Guide Network (KIGN), which encodes the keywords to the key information representation, to guide the process of generation. In addition, we use a prediction-guide mechanism, which can obtain the long-term value for future decoding, to further guide the summary generation. We evaluate our model on the CNN/Daily Mail dataset. The experimental results show that our model leads to significant improvements.},
   author = {Chenliang Li and Weiran Xu and Si Li and Sheng Gao},
   city = {New Orleans, Louisiana},
   doi = {10.18653/v1/N18-2009},
   journal = {Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)},
   month = {6},
   pages = {55-60},
   publisher = {Association for Computational Linguistics},
   title = {Guiding Generation for Abstractive Text Summarization Based on Key Information Guide Network},
   url = {https://aclanthology.org/N18-2009},
   year = {2018},
}
@inproceedings{Tang2019,
   abstract = {Text generation is among the most fundamental tasks in natural language processing. In this paper, we propose a text generation model that learns semantics and structural features simultaneously. This model captures structural features by a sequential variational autoencoder component and leverages a topic modeling component based on Gaussian distribution to enhance the recognition of text semantics. To make the reconstructed text more coherent to the topics, the model further adapts the encoder of the topic modeling component for a discriminator. The results of experiments over several datasets demonstrate that our model outperforms several states of the art models in terms of text perplexity and topic coherence. Moreover, the latent representations learned by our model is superior to others in a text classification task. Finally, given the input texts, our model can generate meaningful texts which hold similar structures but under different topics.},
   author = {Hongyin Tang and Miao Li and Beihong Jin},
   city = {Hong Kong, China},
   doi = {10.18653/v1/D19-1513},
   journal = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
   month = {11},
   pages = {5090-5099},
   publisher = {Association for Computational Linguistics},
   title = {A Topic Augmented Text Generation Model: Joint Learning of Semantics and Structural Features},
   url = {https://aclanthology.org/D19-1513},
   year = {2019},
}
@inproceedings{Yang2018,
   author = {Zichao Yang and Zhiting Hu and Chris Dyer and Eric P Xing and Taylor Berg-Kirkpatrick},
   editor = {S Bengio and H Wallach and H Larochelle and K Grauman and N Cesa-Bianchi and R Garnett},
   journal = {Advances in Neural Information Processing Systems},
   publisher = {Curran Associates, Inc.},
   title = {Unsupervised Text Style Transfer using Language Models as Discriminators},
   volume = {31},
   url = {https://proceedings.neurips.cc/paper/2018/file/398475c83b47075e8897a083e97eb9f0-Paper.pdf},
   year = {2018},
}
@inproceedings{Mei2008,
   author = {Qiaozhu Mei and ChengXiang Zhai},
   journal = {Proceedings of ACL-08: HLT},
   pages = {816-824},
   title = {Generating impact-based summaries for scientific literature},
   year = {2008},
}
@article{Bornmann2015,
   author = {Lutz Bornmann and Rüdiger Mutz},
   issue = {11},
   journal = {Journal of the Association for Information Science and Technology},
   pages = {2215-2222},
   publisher = {Wiley Online Library},
   title = {Growth rates of modern science: A bibliometric analysis based on the number of publications and cited references},
   volume = {66},
   year = {2015},
}
@article{Ware2015,
   author = {Mark Ware and Michael Mabe},
   title = {The STM report: An overview of scientific and scholarly journal publishing},
   year = {2015},
}
@report{Rumelhart1985,
   author = {David E Rumelhart and Geoffrey E Hinton and Ronald J Williams},
   institution = {California Univ San Diego La Jolla Inst for Cognitive Science},
   title = {Learning internal representations by error propagation},
   year = {1985},
}
@article{Vaswani2017,
   author = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N Gomez and Łukasz Kaiser and Illia Polosukhin},
   journal = {Advances in neural information processing systems},
   title = {Attention is all you need},
   volume = {30},
   year = {2017},
}
@article{Zaheer2020,
   author = {Manzil Zaheer and Guru Guruganesh and Kumar Avinava Dubey and Joshua Ainslie and Chris Alberti and Santiago Ontanon and Philip Pham and Anirudh Ravula and Qifan Wang and Li Yang and others},
   journal = {Advances in Neural Information Processing Systems},
   pages = {17283-17297},
   title = {Big bird: Transformers for longer sequences},
   volume = {33},
   year = {2020},
}
@inproceedings{Beltagy2019,
   abstract = {Obtaining large-scale annotated data for NLP tasks in the scientific domain is challenging and expensive. We release SciBERT, a pretrained language model based on BERT (Devlin et. al., 2018) to address the lack of high-quality, large-scale labeled scientific data. SciBERT leverages unsupervised pretraining on a large multi-domain corpus of scientific publications to improve performance on downstream scientific NLP tasks. We evaluate on a suite of tasks including sequence tagging, sentence classification and dependency parsing, with datasets from a variety of scientific domains. We demonstrate statistically significant improvements over BERT and achieve new state-of-the-art results on several of these tasks. The code and pretrained models are available at https://github.com/allenai/scibert/.},
   author = {Iz Beltagy and Kyle Lo and Arman Cohan},
   city = {Hong Kong, China},
   doi = {10.18653/v1/D19-1371},
   journal = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
   month = {11},
   pages = {3615-3620},
   publisher = {Association for Computational Linguistics},
   title = {SciBERT: A Pretrained Language Model for Scientific Text},
   url = {https://aclanthology.org/D19-1371},
   year = {2019},
}
@generic{Gu2020,
   author = {Yu Gu and Robert Tinn and Hao Cheng and Michael Lucas and Naoto Usuyama and Xiaodong Liu and Tristan Naumann and Jianfeng Gao and Hoifung Poon},
   title = {Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing},
   year = {2020},
}
@inproceedings{Guo2021,
   author = {Yue Guo and Wei Qiu and Yizhong Wang and Trevor Cohen},
   issue = {1},
   journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
   pages = {160-168},
   title = {Automated Lay Language Summarization of Biomedical Scientific Reviews},
   volume = {35},
   year = {2021},
}
@inproceedings{Devaraj2021,
   author = {Ashwin Devaraj and Byron C Wallace and Iain J Marshall and Junyi Jessy Li},
   journal = {Proceedings of the conference. Association for Computational Linguistics. North American Chapter. Meeting},
   pages = {4972},
   title = {Paragraph-level simplification of medical texts},
   volume = {2021},
   year = {2021},
}
@inproceedings{Wang2020,
   abstract = {Abstractive document summarization is a comprehensive task including document understanding and summary generation, in which area Transformer-based models have achieved the state-of-the-art performance. Compared with Transformers, topic models are better at learning explicit document semantics, and hence could be integrated into Transformers to further boost their performance. To this end, we rearrange and explore the semantics learned by a topic model, and then propose a topic assistant (TA) including three modules. TA is compatible with various Transformer-based models and user-friendly since i) TA is a plug-and-play model that does not break any structure of the original Transformer network, making users easily fine-tune Transformer+TA based on a well pre-trained model; ii) TA only introduces a small number of extra parameters. Experimental results on three datasets demonstrate that TA is able to improve the performance of several Transformer-based models.},
   author = {Zhengjue Wang and Zhibin Duan and Hao Zhang and Chaojie Wang and Long Tian and Bo Chen and Mingyuan Zhou},
   city = {Online},
   doi = {10.18653/v1/2020.emnlp-main.35},
   journal = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
   month = {11},
   pages = {485-497},
   publisher = {Association for Computational Linguistics},
   title = {Friendly Topic Assistant for Transformer Based Abstractive Summarization},
   url = {https://aclanthology.org/2020.emnlp-main.35},
   year = {2020},
}
@generic{Goyal2021,
   author = {Tanya Goyal and Nazneen Fatema Rajani and Wenhao Liu and Wojciech Kryściński},
   doi = {10.48550/ARXIV.2110.04400},
   keywords = {Computation and Language (cs.CL),FOS: Computer and information sciences},
   publisher = {arXiv},
   title = {HydraSum: Disentangling Stylistic Features in Text Summarization using Multi-Decoder Models},
   url = {https://arxiv.org/abs/2110.04400},
   year = {2021},
}
@inproceedings{Cao2022,
   abstract = {Document structure is critical for efficient information consumption. However, it is challenging to encode it efficiently into the modern Transformer architecture. In this work, we present HIBRIDS, which injects Hierarchical Biases foR Incorporating Document Structure into attention score calculation. We further present a new task, hierarchical question-summary generation, for summarizing salient content in the source document into a hierarchy of questions and summaries, where each follow-up question inquires about the content of its parent question-summary pair. We also annotate a new dataset with 6,153 question-summary hierarchies labeled on government reports. Experiment results show that our model produces better question-summary hierarchies than comparisons on both hierarchy quality and content coverage, a finding also echoed by human judges. Additionally, our model improves the generation of long-form summaries from long government reports and Wikipedia articles, as measured by ROUGE scores.},
   author = {Shuyang Cao and Lu Wang},
   city = {Dublin, Ireland},
   doi = {10.18653/v1/2022.acl-long.58},
   journal = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
   month = {5},
   pages = {786-807},
   publisher = {Association for Computational Linguistics},
   title = {HIBRIDS: Attention with Hierarchical Biases for Structure-aware Long Document Summarization},
   url = {https://aclanthology.org/2022.acl-long.58},
   year = {2022},
}
@inproceedings{Liu2021,
   author = {Shuaiqi Liu and Jiannong Cao and Ruosong Yang and Zhiyuan Wen},
   journal = {FINDINGS},
   title = {Highlight-Transformer: Leveraging Key Phrase Aware Attention to Improve Abstractive Multi-Document Summarization},
   year = {2021},
}
@inproceedings{Vu2022,
   abstract = {There has been growing interest in parameter-efficient methods to apply pre-trained language models to downstream tasks. Building on the Prompt Tuning approach of Lester et al. (2021), which learns task-specific soft prompts to condition a frozen pre-trained model to perform different tasks, we propose a novel prompt-based transfer learning approach called SPoT: Soft Prompt Transfer. SPoT first learns a prompt on one or more source tasks and then uses it to initialize the prompt for a target task. We show that SPoT significantly boosts the performance of Prompt Tuning across many tasks. More remarkably, across all model sizes, SPoT matches or outperforms standard Model Tuning (which fine-tunes all model parameters) on the SuperGLUE benchmark, while using up to 27,000 fewer task-specific parameters. To understand where SPoT is most effective, we conduct a large-scale study on task transferability with 26 NLP tasks in 160 combinations, and demonstrate that many tasks can benefit each other via prompt transfer. Finally, we propose an efficient retrieval approach that interprets task prompts as task embeddings to identify similar tasks and predict the most transferable source tasks for a novel target task.},
   author = {Tu Vu and Brian Lester and Noah Constant and Rami Al-Rfou' and Daniel Cer},
   city = {Dublin, Ireland},
   doi = {10.18653/v1/2022.acl-long.346},
   journal = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
   month = {5},
   pages = {5039-5059},
   publisher = {Association for Computational Linguistics},
   title = {SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer},
   url = {https://aclanthology.org/2022.acl-long.346},
   year = {2022},
}
@inproceedings{Cao2020,
   abstract = {The curse of knowledge can impede communication between experts and laymen. We propose a new task of expertise style transfer and contribute a manually annotated dataset with the goal of alleviating such cognitive biases. Solving this task not only simplifies the professional language, but also improves the accuracy and expertise level of laymen descriptions using simple words. This is a challenging task, unaddressed in previous work, as it requires the models to have expert intelligence in order to modify text with a deep understanding of domain knowledge and structures. We establish the benchmark performance of five state-of-the-art models for style transfer and text simplification. The results demonstrate a significant gap between machine and human performance. We also discuss the challenges of automatic evaluation, to provide insights into future research directions. The dataset is publicly available at https://srhthu.github.io/expertise-style-transfer/.},
   author = {Yixin Cao and Ruihao Shui and Liangming Pan and Min-Yen Kan and Zhiyuan Liu and Tat-Seng Chua},
   city = {Online},
   doi = {10.18653/v1/2020.acl-main.100},
   journal = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
   month = {7},
   pages = {1061-1071},
   publisher = {Association for Computational Linguistics},
   title = {Expertise Style Transfer: A New Task Towards Better Communication between Experts and Laymen},
   url = {https://aclanthology.org/2020.acl-main.100},
   year = {2020},
}
@inproceedings{August2020,
   abstract = {Communicating complex scientific ideas without misleading or overwhelming the public is challenging. While science communication guides exist, they rarely offer empirical evidence for how their strategies are used in practice. Writing strategies that can be automatically recognized could greatly support science communication efforts by enabling tools to detect and suggest strategies for writers. We compile a set of writing strategies drawn from a wide range of prescriptive sources and develop an annotation scheme allowing humans to recognize them. We collect a corpus of 128k science writing documents in English and annotate a subset of this corpus. We use the annotations to train transformer-based classifiers and measure the strategies' use in the larger corpus. We find that the use of strategies, such as storytelling and emphasizing the most important findings, varies significantly across publications with different reader audiences.},
   author = {Tal August and Lauren Kim and Katharina Reinecke and Noah A Smith},
   city = {Online},
   doi = {10.18653/v1/2020.emnlp-main.429},
   journal = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
   month = {11},
   pages = {5327-5344},
   publisher = {Association for Computational Linguistics},
   title = {Writing Strategies for Science Communication: Data and Computational Analysis},
   url = {https://aclanthology.org/2020.emnlp-main.429},
   year = {2020},
}
@inproceedings{August2022,
   abstract = {Unfamiliar terminology and complex language can present barriers to understanding science. Natural language processing stands to help address these issues by automatically defining unfamiliar terms. We introduce a new task and dataset for defining scientific terms and controlling the complexity of generated definitions as a way of adapting to a specific reader's background knowledge. We test four definition generation methods for this new task, finding that a sequence-to-sequence approach is most successful. We then explore the version of the task in which definitions are generated at a target complexity level. We introduce a novel reranking approach and find in human evaluations that it offers superior fluency while also controlling complexity, compared to several controllable generation baselines.},
   author = {Tal August and Katharina Reinecke and Noah A Smith},
   city = {Dublin, Ireland},
   doi = {10.18653/v1/2022.acl-long.569},
   journal = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
   month = {5},
   pages = {8298-8317},
   publisher = {Association for Computational Linguistics},
   title = {Generating Scientific Definitions with Controllable Complexity},
   url = {https://aclanthology.org/2022.acl-long.569},
   year = {2022},
}
@inproceedings{Soleimani2022,
   abstract = {We study the zero-shot setting for the aspect-based scientific document summarization task. Summarizing scientific documents with respect to an aspect can remarkably improve document assistance systems and readers experience. However, existing large-scale datasets contain a limited variety of aspects, causing summarization models to over-fit to a small set of aspects and a specific domain. We establish baseline results in zero-shot performance (over unseen aspects and the presence of domain shift), paraphrasing, leave-one-out, and limited supervised samples experimental setups. We propose a self-supervised pre-training approach to enhance the zero-shot performance. We leverage the PubMed structured abstracts to create a biomedical aspect-based summarization dataset. Experimental results on the PubMed and FacetSum aspect-based datasets show promising performance when the model is pre-trained using unlabelled in-domain data.},
   author = {Amir Soleimani and Vassilina Nikoulina and Benoit Favre and Salah Ait Mokhtar},
   city = {Dublin, Ireland},
   doi = {10.18653/v1/2022.bionlp-1.5},
   journal = {Proceedings of the 21st Workshop on Biomedical Language Processing},
   month = {5},
   pages = {49-62},
   publisher = {Association for Computational Linguistics},
   title = {Zero-Shot Aspect-Based Scientific Document Summarization using Self-Supervised Pre-training},
   url = {https://aclanthology.org/2022.bionlp-1.5},
   year = {2022},
}
@inproceedings{Huang2021,
   author = {Luyang Huang and Shuyang Cao and Nikolaus Nova Parulian and Heng Ji and Lu Wang},
   journal = {NAACL},
   title = {Efficient Attentions for Long Document Summarization},
   year = {2021},
}
@article{Chen2022,
   author = {Xiuying Chen and Hind Alamro and Li Mingzhe and Shen Gao and Rui Yan and Xin Gao and Xiangliang Zhang},
   journal = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
   title = {Target-aware Abstractive Related Work Generation with Contrastive Learning},
   year = {2022},
}
@inproceedings{You2021,
   abstract = {Neural sequence-to-sequence (Seq2Seq) models and BERT have achieved substantial improvements in abstractive document summarization (ADS) without and with pre-training, respectively. However, they sometimes repeatedly attend to unimportant source phrases while mistakenly ignore important ones. We present reconstruction mechanisms on two levels to alleviate this issue. The sequence-level reconstructor reconstructs the whole document from the hidden layer of the target summary, while the word embedding-level one rebuilds the average of word embeddings of the source at the target side to guarantee that as much critical information is included in the summary as possible. Based on the assumption that inverse document frequency (IDF) measures how important a word is, we further leverage the IDF weights in our embedding-level reconstructor. The proposed frameworks lead to promising improvements for ROUGE metrics and human rating on both the CNN/Daily Mail and Newsroom summarization datasets.},
   author = {Jingyi You and Chenlong Hu and Hidetaka Kamigaito and Hiroya Takamura and Manabu Okumura},
   city = {Held Online},
   journal = {Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)},
   month = {9},
   pages = {1586-1596},
   publisher = {INCOMA Ltd.},
   title = {Abstractive Document Summarization with Word Embedding Reconstruction},
   url = {https://aclanthology.org/2021.ranlp-1.178},
   year = {2021},
}
@inproceedings{Shaw2018,
   author = {Peter Shaw and Jakob Uszkoreit and Ashish Vaswani},
   journal = {Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)},
   pages = {464-468},
   title = {Self-Attention with Relative Position Representations},
   year = {2018},
}
@inproceedings{Otmakhova2022,
   abstract = {Although multi-document summarisation (MDS) of the biomedical literature is a highly valuable task that has recently attracted substantial interest, evaluation of the quality of biomedical summaries lacks consistency and transparency. In this paper, we examine the summaries generated by two current models in order to understand the deficiencies of existing evaluation approaches in the context of the challenges that arise in the MDS task. Based on this analysis, we propose a new approach to human evaluation and identify several challenges that must be overcome to develop effective biomedical MDS systems.},
   author = {Yulia Otmakhova and Karin Verspoor and Timothy Baldwin and Jey Han Lau},
   city = {Dublin, Ireland},
   doi = {10.18653/v1/2022.acl-long.350},
   journal = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
   month = {5},
   pages = {5098-5111},
   publisher = {Association for Computational Linguistics},
   title = {The patient is more dead than alive: exploring the current state of the multi-document summarisation of the biomedical literature},
   url = {https://aclanthology.org/2022.acl-long.350},
   year = {2022},
}
@article{Tiu2022,
   abstract = {In tasks involving the interpretation of medical images, suitably trained machine-learning models often exceed the performance of medical experts. Yet such a high-level of performance typically requires that the models be trained with relevant datasets that have been painstakingly annotated by experts. Here we show that a self-supervised model trained on chest X-ray images that lack explicit annotations performs pathology-classification tasks with accuracies comparable to those of radiologists. On an external validation dataset of chest X-rays, the self-supervised model outperformed a fully supervised model in the detection of three pathologies (out of eight), and the performance generalized to pathologies that were not explicitly annotated for model training, to multiple image-interpretation tasks and to datasets from multiple institutions.},
   author = {Ekin Tiu and Ellie Talius and Pujan Patel and Curtis P Langlotz and Andrew Y Ng and Pranav Rajpurkar},
   doi = {10.1038/s41551-022-00936-9},
   issn = {2157-846X},
   journal = {Nature Biomedical Engineering},
   title = {Expert-level detection of pathologies from unannotated chest X-ray images via self-supervised learning},
   url = {https://doi.org/10.1038/s41551-022-00936-9},
   year = {2022},
}
@article{Sankar2022,
   author = {Aiswarya Sankar and Ankit Chadha},
   journal = {arXiv preprint arXiv:2205.03978},
   title = {ACM–Attribute Conditioning for Abstractive Multi Document Summarization},
   year = {2022},
}
@article{Li2022,
   author = {Yudong Li and Yuqing Zhang and Zhe Zhao and Linlin Shen and Weijie Liu and Weiquan Mao and Hui Zhang},
   journal = {arXiv preprint arXiv:2209.05034},
   title = {CSL: A Large-scale Chinese Scientific Literature Dataset},
   year = {2022},
}
@inproceedings{Krasnashchok2018,
   abstract = {News related content has been extensively studied in both topic modeling research and named entity recognition. However, expressive power of named entities and their potential for improving the quality of discovered topics has not received much attention. In this paper we use named entities as domain-specific terms for news-centric content and present a new weighting model for Latent Dirichlet Allocation. Our experimental results indicate that involving more named entities in topic descriptors positively influences the overall quality of topics, improving their interpretability, specificity and diversity.},
   author = {Katsiaryna Krasnashchok and Salim Jouili},
   city = {Melbourne, Australia},
   doi = {10.18653/v1/P18-2040},
   journal = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
   month = {7},
   pages = {247-253},
   publisher = {Association for Computational Linguistics},
   title = {Improving Topic Quality by Promoting Named Entities in Topic Modeling},
   url = {https://aclanthology.org/P18-2040},
   year = {2018},
}
@inproceedings{Zhang2022,
   abstract = {Recent years have witnessed growing interests in incorporating external knowledge such as pre-trained word embeddings (PWEs) or pre-trained language models (PLMs) into neural topic modeling. However, we found that employing PWEs and PLMs for topic modeling only achieved limited performance improvements but with huge computational overhead. In this paper, we propose a novel strategy to incorporate external knowledge into neural topic modeling where the neural topic model is pre-trained on a large corpus and then fine-tuned on the target dataset. Experiments have been conducted on three datasets and results show that the proposed approach significantly outperforms both current state-of-the-art neural topic models and some topic modeling approaches enhanced with PWEs or PLMs. Moreover, further study shows that the proposed approach greatly reduces the need for the huge size of training data.},
   author = {Linhai Zhang and Xuemeng Hu and Boyu Wang and Deyu Zhou and Qian-Wen Zhang and Yunbo Cao},
   city = {Dublin, Ireland},
   doi = {10.18653/v1/2022.acl-long.413},
   journal = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
   month = {5},
   pages = {5980-5989},
   publisher = {Association for Computational Linguistics},
   title = {Pre-training and Fine-tuning Neural Topic Model: A Simple yet Effective Approach to Incorporating External Knowledge},
   url = {https://aclanthology.org/2022.acl-long.413},
   year = {2022},
}
@inproceedings{Wang2022,
   author = {Yifan Wang and Yiping Song and Shuai Li and Chaoran Cheng and Wei Ju and Ming Zhang and Sheng Wang},
   journal = {AAAI},
   title = {DisenCite: Graph-Based Disentangled Representation Learning for Context-Specific Citation Generation},
   year = {2022},
}
@generic{Luo2022,
   author = {Zheheng Luo and Qianqian Xie and Sophia Ananiadou},
   doi = {10.48550/ARXIV.2210.04705},
   keywords = {Computation and Language (cs.CL),FOS: Computer and information sciences},
   publisher = {arXiv},
   title = {Readability Controllable Biomedical Document Summarization},
   url = {https://arxiv.org/abs/2210.04705},
   year = {2022},
}
@article{Shah2021,
   author = {Darsh J Shah and Lili Yu and Tao Lei and Regina Barzilay},
   journal = {arXiv preprint arXiv:2104.03465},
   title = {Nutribullets hybrid: Multi-document health summarization},
   year = {2021},
}
@article{,
   abstract = {The number of scholarly documents available on the web is estimated using capture/recapture methods by studying the coverage of two major academic search engines: Google Scholar and Microsoft Academic Search. Our estimates show that at least 114 million English-language scholarly documents are accessible on the web, of which Google Scholar has nearly 100 million. Of these, we estimate that at least 27 million (24%) are freely available since they do not require a subscription or payment of any kind. In addition, at a finer scale, we also estimate the number of scholarly documents on the web for fifteen fields: Agricultural Science, Arts and Humanities, Biology, Chemistry, Computer Science, Economics and Business, Engineering, Environmental Sciences, Geosciences, Material Science, Mathematics, Medicine, Physics, Social Sciences, and Multidisciplinary, as defined by Microsoft Academic Search. In addition, we show that among these fields the percentage of documents defined as freely available varies significantly, i.e., from 12 to 50%.},
   author = {C Lee Khabsa Madian AND Giles},
   doi = {10.1371/journal.pone.0093949},
   issue = {5},
   journal = {PLOS ONE},
   month = {10},
   pages = {1-6},
   publisher = {Public Library of Science},
   title = {The Number of Scholarly Documents on the Public Web},
   volume = {9},
   url = {https://doi.org/10.1371/journal.pone.0093949},
   year = {2014},
}
@inproceedings{Elaraby2022,
   abstract = {A challenging task when generating summaries of legal documents is the ability to address their argumentative nature. We introduce a simple technique to capture the argumentative structure of legal documents by integrating argument role labeling into the summarization process. Experiments with pretrained language models show that our proposed approach improves performance over strong baselines.},
   author = {Mohamed Elaraby and Diane Litman},
   city = {Gyeongju, Republic of Korea},
   journal = {Proceedings of the 29th International Conference on Computational Linguistics},
   month = {10},
   pages = {6187-6194},
   publisher = {International Committee on Computational Linguistics},
   title = {ArgLegalSumm: Improving Abstractive Summarization of Legal Documents with Argument Mining},
   url = {https://aclanthology.org/2022.coling-1.540},
   year = {2022},
}
@generic{Huang2021,
   author = {Jie Huang and Hanyin Shao and Kevin Chen-Chuan Chang and Jinjun Xiong and Wen-mei Hwu},
   doi = {10.48550/ARXIV.2111.07267},
   keywords = {Artificial Intelligence (cs.AI),Computation and Language (cs.CL),FOS: Computer and information sciences},
   publisher = {arXiv},
   title = {Understanding Jargon: Combining Extraction and Generation for Definition Modeling},
   url = {https://arxiv.org/abs/2111.07267},
   year = {2021},
}
@generic{Huang2022,
   author = {Jie Huang and Hanyin Shao and Kevin Chen-Chuan Chang},
   doi = {10.48550/ARXIV.2205.12628},
   keywords = {Artificial Intelligence (cs.AI),Computation and Language (cs.CL),Cryptography and Security (cs.CR),FOS: Computer and information sciences},
   publisher = {arXiv},
   title = {Are Large Pre-Trained Language Models Leaking Your Personal Information?},
   url = {https://arxiv.org/abs/2205.12628},
   year = {2022},
}
@inproceedings{Ge2021,
   abstract = {In this paper, we focus on the problem of citing sentence generation, which entails generating a short text to capture the salient information in a cited paper and the connection between the citing and cited paper. We present BACO, a BAckground knowledge- and COntent-based framework for citing sentence generation, which considers two types of information: (1) background knowledge by leveraging structural information from a citation network; and (2) content, which represents in-depth information about what to cite and why to cite. First, a citation network is encoded to provide background knowledge. Second, we apply salience estimation to identify what to cite by estimating the importance of sentences in the cited paper. During the decoding stage, both types of information are combined to facilitate the text generation, and then we conduct a joint training for the generator and citation function classification to make the model aware of why to cite. Our experimental results show that our framework outperforms comparative baselines.},
   author = {Yubin Ge and Ly Dinh and Xiaofeng Liu and Jinsong Su and Ziyao Lu and Ante Wang and Jana Diesner},
   city = {Online},
   doi = {10.18653/v1/2021.acl-long.116},
   journal = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
   month = {8},
   pages = {1466-1478},
   publisher = {Association for Computational Linguistics},
   title = {BACO: A Background Knowledge- and Content-Based Framework for Citing Sentence Generation},
   url = {https://aclanthology.org/2021.acl-long.116},
   year = {2021},
}
@generic{Peng2022,
   author = {Xiangyu Peng and Chen Xing and Prafulla Kumar Choubey and Chien-Sheng Wu and Caiming Xiong},
   doi = {10.48550/ARXIV.2210.12587},
   keywords = {Computation and Language (cs.CL),FOS: Computer and information sciences},
   publisher = {arXiv},
   title = {Model ensemble instead of prompt fusion: a sample-specific knowledge transfer method for few-shot prompt tuning},
   url = {https://arxiv.org/abs/2210.12587},
   year = {2022},
}
@inproceedings{Moro2022,
   abstract = {Although current state-of-the-art Transformer-based solutions succeeded in a wide range for single-document NLP tasks, they still struggle to address multi-input tasks such as multi-document summarization. Many solutions truncate the inputs, thus ignoring potential summary-relevant contents, which is unacceptable in the medical domain where each information can be vital. Others leverage linear model approximations to apply multi-input concatenation, worsening the results because all information is considered, even if it is conflicting or noisy with respect to a shared background. Despite the importance and social impact of medicine, there are no ad-hoc solutions for multi-document summarization. For this reason, we propose a novel discriminative marginalized probabilistic method (DAMEN) trained to discriminate critical information from a cluster of topic-related medical documents and generate a multi-document summary via token probability marginalization. Results prove we outperform the previous state-of-the-art on a biomedical dataset for multi-document summarization of systematic literature reviews. Moreover, we perform extensive ablation studies to motivate the design choices and prove the importance of each module of our method.},
   author = {Gianluca Moro and Luca Ragazzi and Lorenzo Valgimigli and Davide Freddi},
   city = {Dublin, Ireland},
   doi = {10.18653/v1/2022.acl-long.15},
   journal = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
   month = {5},
   pages = {180-189},
   publisher = {Association for Computational Linguistics},
   title = {Discriminative Marginalized Probabilistic Neural Method for Multi-Document Summarization of Medical Literature},
   url = {https://aclanthology.org/2022.acl-long.15},
   year = {2022},
}
@inproceedings{Otmakhova2022,
   abstract = {Although multi-document summarisation (MDS) of the biomedical literature is a highly valuable task that has recently attracted substantial interest, evaluation of the quality of biomedical summaries lacks consistency and transparency. In this paper, we examine the summaries generated by two current models in order to understand the deficiencies of existing evaluation approaches in the context of the challenges that arise in the MDS task. Based on this analysis, we propose a new approach to human evaluation and identify several challenges that must be overcome to develop effective biomedical MDS systems.},
   author = {Yulia Otmakhova and Karin Verspoor and Timothy Baldwin and Jey Han Lau},
   city = {Dublin, Ireland},
   doi = {10.18653/v1/2022.acl-long.350},
   journal = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
   month = {5},
   pages = {5098-5111},
   publisher = {Association for Computational Linguistics},
   title = {The patient is more dead than alive: exploring the current state of the multi-document summarisation of the biomedical literature},
   url = {https://aclanthology.org/2022.acl-long.350},
   year = {2022},
}
@inproceedings{Miura2021,
   abstract = {Neural image-to-text radiology report generation systems offer the potential to improve radiology reporting by reducing the repetitive process of report drafting and identifying possible medical errors. However, existing report generation systems, despite achieving high performances on natural language generation metrics such as CIDEr or BLEU, still suffer from incomplete and inconsistent generations. Here we introduce two new simple rewards to encourage the generation of factually complete and consistent radiology reports: one that encourages the system to generate radiology domain entities consistent with the reference, and one that uses natural language inference to encourage these entities to be described in inferentially consistent ways. We combine these with the novel use of an existing semantic equivalence metric (BERTScore). We further propose a report generation system that optimizes these rewards via reinforcement learning. On two open radiology report datasets, our system substantially improved the F1 score of a clinical information extraction performance by +22.1 (Delta +63.9%). We further show via a human evaluation and a qualitative analysis that our system leads to generations that are more factually complete and consistent compared to the baselines.},
   author = {Yasuhide Miura and Yuhao Zhang and Emily Tsai and Curtis Langlotz and Dan Jurafsky},
   city = {Online},
   doi = {10.18653/v1/2021.naacl-main.416},
   journal = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
   month = {6},
   pages = {5288-5304},
   publisher = {Association for Computational Linguistics},
   title = {Improving Factual Completeness and Consistency of Image-to-Text Radiology Report Generation},
   url = {https://aclanthology.org/2021.naacl-main.416},
   year = {2021},
}
@article{Wang2022,
   author = {Zifeng Wang and Zhenbang Wu and Dinesh Agarwal and Jimeng Sun},
   journal = {arXiv preprint arXiv:2210.10163},
   title = {Medclip: Contrastive learning from unpaired medical images and text},
   year = {2022},
}
@article{Chen2022,
   author = {Xiuying Chen and Mingzhe Li and Shen Gao and Rui Yan and Xin Gao and Xiangliang Zhang},
   journal = {arXiv preprint arXiv:2212.04214},
   title = {Scientific Paper Extractive Summarization Enhanced by Citation Graphs},
   year = {2022},
}
@article{Ondov2022,
   author = {Brian Ondov and Kush Attal and Dina Demner-Fushman},
   issue = {11},
   journal = {Journal of the American Medical Informatics Association},
   pages = {1976-1988},
   publisher = {Oxford University Press},
   title = {A survey of automated methods for biomedical text simplification},
   volume = {29},
   year = {2022},
}
@article{,
   author = {Liam van der Poel and Ryan Cotterell and Clara Meister},
   journal = {arXiv preprint arXiv:2210.13210},
   title = {Mutual Information Alleviates Hallucinations in Abstractive Summarization},
   year = {2022},
}
@inproceedings{Li2016,
   author = {Jiwei Li and Michel Galley and Chris Brockett and Jianfeng Gao and William B Dolan},
   journal = {Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
   pages = {110-119},
   title = {A Diversity-Promoting Objective Function for Neural Conversation Models},
   year = {2016},
}
@article{Liu2022,
   author = {Yixin Liu and Ansong Ni and Linyong Nan and Budhaditya Deb and Chenguang Zhu and Ahmed H Awadallah and Dragomir Radev},
   journal = {arXiv preprint arXiv:2205.12476},
   title = {Leveraging Locality in Abstractive Text Summarization},
   year = {2022},
}
@inproceedings{Liang2022,
   abstract = {The goal of the cross-lingual summarization (CLS) is to convert a document in one language (e.g., English) to a summary in another one (e.g., Chinese). The CLS task is essentially the combination of machine translation (MT) and monolingual summarization (MS), and thus there exists the hierarchical relationship between MT&MS and CLS. Existing studies on CLS mainly focus on utilizing pipeline methods or jointly training an end-to-end model through an auxiliary MT or MS objective. However, it is very challenging for the model to directly conduct CLS as it requires both the abilities to translate and summarize. To address this issue, we propose a hierarchical model for the CLS task, based on the conditional variational auto-encoder. The hierarchical model contains two kinds of latent variables at the local and global levels, respectively. At the local level, there are two latent variables, one for translation and the other for summarization. As for the global level, there is another latent variable for cross-lingual summarization conditioned on the two local-level variables. Experiments on two language directions (English-Chinese) verify the effectiveness and superiority of the proposed approach. In addition, we show that our model is able to generate better cross-lingual summaries than comparison models in the few-shot setting.},
   author = {Yunlong Liang and Fandong Meng and Chulun Zhou and Jinan Xu and Yufeng Chen and Jinsong Su and Jie Zhou},
   city = {Dublin, Ireland},
   doi = {10.18653/v1/2022.acl-long.148},
   journal = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
   month = {5},
   pages = {2088-2099},
   publisher = {Association for Computational Linguistics},
   title = {A Variational Hierarchical Model for Neural Cross-Lingual Summarization},
   url = {https://aclanthology.org/2022.acl-long.148},
   year = {2022},
}
@inproceedings{Zhang2020,
   abstract = {Recent work pre-Training Transformers with self-supervised objectives on large text corpora has shown great success when fine-Tuned on downstream NLP tasks including text summarization. However, pre-Training objectives tailored for abstractive text summarization have not been explored. Furthermore there is a lack of systematic evaluation across diverse domains. In this work, we propose pre-Training large Transformer-based encoder-decoder models on massive text corpora with a new selfsupervised objective. In PEGASUS, important sentences are removed/masked from an input document and are generated together as one output sequence from the remaining sentences, similar to an extractive summary. We evaluated our best PEGASUS model on 12 downstream summarization tasks spanning news, science, stories, instructions, emails, patents, and legislative bills. Experiments demonstrate it achieves state-of-The-Art performance on all 12 downstream datasets measured by ROUGE scores. Our model also shows surprising performance on low-resource summarization, surpassing previous state-of-The-Art results on 6 datasets with only 1000 examples. Finally we validated our results using human evaluation and show that our model summaries achieve human performance on multiple datasets.},
   author = {Jingqing Zhang and Yao Zhao and Mohammad Saleh and Peter J. Liu},
   isbn = {9781713821120},
   journal = {37th International Conference on Machine Learning, ICML 2020},
   pages = {11265-11276},
   publisher = {International Machine Learning Society (IMLS)},
   title = {PEGASUS: Pre-Training with extracted gap-sentences for abstractive summarization},
   volume = {PartF168147-15},
   year = {2020},
}
@inproceedings{Li2021,
   abstract = {Fine-tuning is the de facto way of leveraging large pretrained language models for downstream tasks. However, fine-tuning modifies all the language model parameters and therefore necessitates storing a full copy for each task. In this paper, we propose prefix-tuning, a lightweight alternative to fine-tuning for natural language generation tasks, which keeps language model parameters frozen and instead optimizes a sequence of continuous task-specific vectors, which we call the prefix. Prefix-tuning draws inspiration from prompting for language models, allowing subsequent tokens to attend to this prefix as if it were “virtual tokens”. We apply prefix-tuning to GPT-2 for table-to-text generation and to BART for summarization. We show that by modifying only 0.1% of the parameters, prefix-tuning obtains comparable performance in the full data setting, outperforms fine-tuning in low-data settings, and extrapolates better to examples with topics that are unseen during training.},
   author = {Xiang Lisa Li and Percy Liang},
   doi = {10.18653/v1/2021.acl-long.353},
   isbn = {9781954085527},
   journal = {ACL-IJCNLP 2021 - 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Proceedings of the Conference},
   pages = {4582-4597},
   publisher = {Association for Computational Linguistics (ACL)},
   title = {Prefix-tuning: Optimizing continuous prompts for generation},
   year = {2021},
}
@inproceedings{Fabbri2020,
   abstract = {Automatic generation of summaries from multiple news articles is a valuable tool as the number of online publications grows rapidly. Single document summarization (SDS) systems have benefited from advances in neural encoder-decoder model thanks to the availability of large datasets. However, multi-document summarization (MDS) of news articles has been limited to datasets of a couple of hundred examples. In this paper, we introduce Multi-News, the first large-scale MDS news dataset. Additionally, we propose an end-to-end model which incorporates a traditional extractive summarization model with a standard SDS model and achieves competitive results on MDS datasets. We benchmark several methods on Multi-News and release our data and code in hope that this work will promote advances in summarization in the multi-document setting.},
   author = {Alexander R. Fabbri and Irene Li and Tianwei She and Suyi Li and Dragomir R. Radev},
   doi = {10.18653/v1/p19-1102},
   isbn = {9781950737482},
   journal = {ACL 2019 - 57th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference},
   pages = {1074-1084},
   publisher = {Association for Computational Linguistics (ACL)},
   title = {Multi-news: A large-scale multi-document summarization dataset and abstractive hierarchical model},
   year = {2020},
}
@inproceedings{Goodrich2019,
   abstract = {We propose a model-based metric to estimate the factual accuracy of generated text that is complementary to typical scoring schemes like ROUGE (Recall-Oriented Understudy for Gisting Evaluation) and BLEU (Bilingual Evaluation Understudy). We introduce and release a new large-scale dataset based on Wikipedia and Wikidata to train relation classifiers and end-to-end fact extraction models. The end-to-end models are shown to be able to extract complete sets of facts from datasets with full pages of text. We then analyse multiple models that estimate factual accuracy on a Wikipedia text summarization task, and show their efficacy compared to ROUGE and other model-free variants by conducting a human evaluation study.},
   author = {Ben Goodrich and Vinay Rao and Peter J. Liu and Mohammad Saleh},
   doi = {10.1145/3292500.3330955},
   isbn = {9781450362016},
   journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
   keywords = {Datasets,Deep learning,End-to-end,Fact extraction,Metric,Neural networks},
   month = {7},
   pages = {166-175},
   publisher = {Association for Computing Machinery},
   title = {Assessing the factual accuracy of generated text},
   year = {2019},
}
@inproceedings{Wu2021,
   abstract = {ive summarization for long-document or multi-document remains challenging for the Seq2Seq architecture, as Seq2Seq is not good at analyzing long-distance relations in text. In this paper, we present BASS, a novel framework for Boosting Abstractive Summarization based on a unified Semantic graph, which aggregates co-referent phrases distributing across a long range of context and conveys rich relations between phrases. Further, a graph-based encoder-decoder model is proposed to improve both the document representation and summary generation process by leveraging the graph structure. Specifically, several graph augmentation methods are designed to encode both the explicit and implicit relations in the text while the graph-propagation attention mechanism is developed in the decoder to select salient content into the summary. Empirical results show that the proposed architecture brings substantial improvements for both long-document and multi-document summarization tasks.},
   author = {Wenhao Wu and Wei Li and Xinyan Xiao and Jiachen Liu and Ziqiang Cao and Sujian Li and Hua Wu and Haifeng Wang},
   doi = {10.18653/v1/2021.acl-long.472},
   isbn = {9781954085527},
   journal = {ACL-IJCNLP 2021 - 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Proceedings of the Conference},
   pages = {6052-6067},
   publisher = {Association for Computational Linguistics (ACL)},
   title = {BASS: Boosting abstractive summarization with unified semantic graph},
   year = {2021},
}
@inproceedings{You2020,
   abstract = {Comprehensive document encoding and salient information selection are two major difficulties for generating summaries with adequate salient information. To tackle the above difficulties, we propose a Transformer-based encoder-decoder framework with two novel extensions for abstractive document summarization. Specifically, (1) to encode the documents comprehensively, we design a focus-attention mechanism and incorporate it into the encoder. This mechanism models a Gaussian focal bias on attention scores to enhance the perception of local context, which contributes to producing salient and informative summaries. (2) To distinguish salient information precisely, we design an independent saliency-selection network which manages the information flow from encoder to decoder. This network effectively reduces the influences of secondary information on the generated summaries. Experimental results on the popular CNN/Daily Mail benchmark demonstrate that our model outperforms other state-of-the-art baselines on the ROUGE metrics.},
   author = {Yongjian You and Weijia Jia and Tianyi Liu and Wenmian Yang},
   doi = {10.18653/v1/p19-1205},
   isbn = {9781950737482},
   journal = {ACL 2019 - 57th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference},
   pages = {2132-2141},
   publisher = {Association for Computational Linguistics (ACL)},
   title = {Improving abstractive document summarization with salient information modeling},
   year = {2020},
}
@inproceedings{Xiao2020,
   abstract = {Modeling content importance is an essential yet challenging task for summarization. Previous work is mostly based on statistical methods that estimate word-level salience, which does not consider semantics and larger context when quantifying importance. It is thus hard for these methods to generalize to semantic units of longer text spans. In this work, we apply information theory on top of pre-trained language models and define the concept of importance from the perspective of information amount. It considers both the semantics and context when evaluating the importance of each semantic unit. With the help of pre-trained language models, it can easily generalize to different kinds of semantic units (n-grams or sentences). Experiments on CNN/Daily Mail and New York Times datasets demonstrate that our method can better model the importance of content than prior work based on F1 and ROUGE scores.},
   author = {Liqiang Xiao and Lu Wang and Hao He and Yaohui Jin},
   doi = {10.18653/v1/2020.emnlp-main.293},
   isbn = {9781952148606},
   journal = {EMNLP 2020 - 2020 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference},
   pages = {3606-3611},
   publisher = {Association for Computational Linguistics (ACL)},
   title = {Modeling content importance for summarization with pre-trained language models},
   year = {2020},
}
@article{,
   abstract = {Clarity and accuracy of reporting are fundamental to the scientific process. Readability formulas can estimate how difficult a text is to read. Here, in a corpus consisting of 709,577 abstracts published between 1881 and 2015 from 123 scientific journals, we show that the readability of science is steadily decreasing. Our analyses show that this trend is indicative of a growing use of general scientific jargon. These results are concerning for scientists and for the wider public, as they impact both the reproducibility and accessibility of research findings.},
   author = {Pontus Plavén-Sigray and Granville James Matheson and Björn Christian Schiffler and William Hedley Thompson},
   doi = {10.7554/eLife.27725},
   editor = {Stuart King},
   issn = {2050-084X},
   journal = {eLife},
   keywords = {data analysis,jargon,metascience,readability,scientific communication},
   month = {9},
   pages = {e27725},
   publisher = {eLife Sciences Publications, Ltd},
   title = {Research: The readability of scientific texts is decreasing over time},
   volume = {6},
   url = {https://doi.org/10.7554/eLife.27725},
   year = {2017},
}
@article{Friedman2002,
   abstract = {Natural language processing (NLP) systems have been developed to provide access to the tremendous body of data and knowledge that is available in the biomedical domain in the form of natural language text. These NLP systems are valuable because they can encode and amass the information in the text so that it can be used by other automated processes to improve patient care and our understanding of disease processes and treatments. Zellig Harris proposed a theory of sublanguage that laid the foundation for natural language processing in specialized domains. He hypothesized that the informational content and structure form a specialized language that can be delineated in the form of a sublanguage grammar. The grammar can then be used by a language processor to capture and encode the salient information and relations in text. In this paper, we briefly summarize his language and sublanguage theories. In addition, we summarize our prior research, which is associated with the sublanguage grammars we developed for two different biomedical domains. These grammars illustrate how Harris’ theories provide a basis for the development of language processing systems in the biomedical domain. The two domains and their associated sublanguages discussed are: the clinical domain, where the text consists of patient reports, and the biomolecular domain, where the text consists of complete journal articles.},
   author = {Carol Friedman and Pauline Kra and Andrey Rzhetsky},
   doi = {https://doi.org/10.1016/S1532-0464(03)00012-1},
   issn = {1532-0464},
   issue = {4},
   journal = {Journal of Biomedical Informatics},
   note = {Sublanguage - Zellig Harris Memorial},
   pages = {222-235},
   title = {Two biomedical sublanguages: a description based on the theories of Zellig Harris},
   volume = {35},
   url = {https://www.sciencedirect.com/science/article/pii/S1532046403000121},
   year = {2002},
}
@inproceedings{Bishop2022,
   abstract = {Text summarization (TS) is an important NLP task. Pre-trained Language Models (PLMs) have been used to improve the performance of TS. However, PLMs are limited by their need of labelled training data and by their attention mechanism, which often makes them unsuitable for use on long documents. To this end, we propose a hybrid, unsupervised, abstractive-extractive approach, in which we walk through a document, generating salient textual fragments representing its key points. We then select the most important sentences of the document by choosing the most similar sentences to the generated texts, calculated using BERTScore. We evaluate the efficacy of generating and using salient textual fragments to guide extractive summarization on documents from the biomedical and general scientific domains. We compare the performance between long and short documents using different generative text models, which are finetuned to generate relevant queries or document titles. We show that our hybrid approach out-performs existing unsupervised methods, as well as state-of-the-art supervised methods, despite not needing a vast amount of labelled training data.},
   author = {Jennifer Bishop and Qianqian Xie and Sophia Ananiadou},
   city = {Dublin, Ireland},
   doi = {10.18653/v1/2022.bionlp-1.22},
   journal = {Proceedings of the 21st Workshop on Biomedical Language Processing},
   month = {5},
   pages = {220-240},
   publisher = {Association for Computational Linguistics},
   title = {GenCompareSum: a hybrid unsupervised summarization method using salience},
   url = {https://aclanthology.org/2022.bionlp-1.22},
   year = {2022},
}
@report{Kincaid1975,
   author = {J Peter Kincaid and Robert P Fishburne Jr and Richard L Rogers and Brad S Chissom},
   institution = {Naval Technical Training Command Millington TN Research Branch},
   title = {Derivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel},
   year = {1975},
}
@article{Coleman1975,
   author = {Meri Coleman and Ta Lin Liau},
   journal = {Journal of Applied Psychology},
   pages = {283-284},
   title = {A computer readability formula designed for machine scoring.},
   volume = {60},
   year = {1975},
}
@report{Senter1967,
   author = {R J Senter and Edgar A Smith},
   institution = {Cincinnati Univ OH},
   title = {Automated readability index},
   year = {1967},
}
@inproceedings{Shardlow2022,
   abstract = {Specialist high-quality information is typically first available in English, and it is written in a language that may be difficult to understand by most readers. While Machine Translation technologies contribute to mitigate the first issue, the translated content will most likely still contain complex language. In order to investigate and address both problems simultaneously, we introduce Simple TICO-19, a new language resource containing manual simplifications of the English and Spanish portions of the TICO-19 corpus for Machine Translation of COVID-19 literature. We provide an in-depth description of the annotation process, which entailed designing an annotation manual and employing four annotators (two native English speakers and two native Spanish speakers) who simplified over 6,000 sentences from the English and Spanish portions of the TICO-19 corpus. We report several statistics on the new dataset, focusing on analysing the improvements in readability from the original texts to their simplified versions. In addition, we propose baseline methodologies for automatically generating the simplifications, translations and joint translation and simplifications contained in our dataset.},
   author = {Matthew Shardlow and Fernando Alva-Manchego},
   city = {Marseille, France},
   journal = {Proceedings of the Thirteenth Language Resources and Evaluation Conference},
   month = {6},
   pages = {3093-3102},
   publisher = {European Language Resources Association},
   title = {Simple TICO-19: A Dataset for Joint Translation and Simplification of COVID-19 Texts},
   url = {https://aclanthology.org/2022.lrec-1.331},
   year = {2022},
}
@article{Goyal2022,
   author = {Tanya Goyal and Junyi Jessy Li and Greg Durrett},
   journal = {ArXiv},
   title = {News Summarization and Evaluation in the Era of GPT-3},
   volume = {abs/2209.12356},
   year = {2022},
}
@article{Laban2021,
   author = {Philippe Laban and Tobias Schnabel and Paul N Bennett and Marti A Hearst},
   journal = {Transactions of the Association for Computational Linguistics},
   pages = {163-177},
   title = {SummaC: Re-Visiting NLI-based Models for Inconsistency Detection in Summarization},
   volume = {10},
   year = {2021},
}
@article{Yu2022,
   author = {W Yu and Dan Iter and Shuohang Wang and Yichong Xu and Mingxuan Ju and Soumya Sanyal and Chenguang Zhu and Michael Zeng and Meng Jiang},
   journal = {ArXiv},
   title = {Generate rather than Retrieve: Large Language Models are Strong Context Generators},
   volume = {abs/2209.10063},
   year = {2022},
}
@article{Wei2022,
   author = {Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Ed Huai-hsin Chi and Quoc Le and Denny Zhou},
   journal = {ArXiv},
   title = {Chain of Thought Prompting Elicits Reasoning in Large Language Models},
   volume = {abs/2201.11903},
   year = {2022},
}
@article{Hoffmann2022,
   author = {Jordan Hoffmann and Sebastian Borgeaud and Arthur Mensch and Elena Buchatskaya and Trevor Cai and Eliza Rutherford and Diego de Las Casas and Lisa Anne Hendricks and Johannes Welbl and Aidan Clark and Tom Hennigan and Eric Noland and Katie Millican and George van den Driessche and Bogdan Damoc and Aurelia Guy and Simon Osindero and Karen Simonyan and Erich Elsen and Jack W Rae and Oriol Vinyals and L Sifre},
   journal = {ArXiv},
   title = {Training Compute-Optimal Large Language Models},
   volume = {abs/2203.15556},
   year = {2022},
}
@article{Chowdhery2022,
   author = {Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra et al},
   journal = {ArXiv},
   title = {PaLM: Scaling Language Modeling with Pathways},
   volume = {abs/2204.02311},
   year = {2022},
}
@article{Tam2022,
   author = {Derek Tam and Anisha Mascarenhas and Shiyue Zhang and Sarah Kwan and Mohit Bansal and Colin Raffel},
   journal = {ArXiv},
   title = {Evaluating the Factual Consistency of Large Language Models Through Summarization},
   volume = {abs/2211.08412},
   year = {2022},
}
@article{Kojima2022,
   author = {Takeshi Kojima and Shixiang Shane Gu and Machel Reid and Yutaka Matsuo and Yusuke Iwasawa},
   journal = {ArXiv},
   title = {Large Language Models are Zero-Shot Reasoners},
   volume = {abs/2205.11916},
   year = {2022},
}
@article{Kocmi2023,
   author = {Tom Kocmi and Christian Federmann},
   journal = {ArXiv},
   title = {Large Language Models Are State-of-the-Art Evaluators of Translation Quality},
   volume = {abs/2302.14520},
   year = {2023},
}
@article{Zhong2023,
   author = {Qihuang Zhong and Liang Ding and Juhua Liu and Bo Du and Dacheng Tao},
   journal = {ArXiv},
   title = {Can ChatGPT Understand Too? A Comparative Study on ChatGPT and Fine-tuned BERT},
   volume = {abs/2302.10198},
   year = {2023},
}
@article{Ouyang2022,
   author = {Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke E Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Francis Christiano and Jan Leike and Ryan J Lowe},
   journal = {ArXiv},
   title = {Training language models to follow instructions with human feedback},
   volume = {abs/2203.02155},
   year = {2022},
}
@article{Scao2022,
   author = {Teven Le Scao and Angela Fan and Christopher Akiki and Elizabeth-Jane Pavlick and Suzana Ili'c et al},
   journal = {ArXiv},
   title = {BLOOM: A 176B-Parameter Open-Access Multilingual Language Model},
   volume = {abs/2211.05100},
   year = {2022},
}
@article{Ouyang2022TrainingLM,
  title={Training language models to follow instructions with human feedback},
  author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke E. Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Francis Christiano and Jan Leike and Ryan J. Lowe},
  journal={ArXiv},
  year={2022},
  volume={abs/2203.02155}
}
@article{Zhang2022ExtractiveIN,
  title={Extractive is not Faithful: An Investigation of Broad Unfaithfulness Problems in Extractive Summarization},
  author={Shiyue Zhang and David Wan and Mohit Bansal},
  journal={ArXiv},
  year={2022},
  volume={abs/2209.03549}
}
@article{Kocmi2023LargeLM,
  title={Large Language Models Are State-of-the-Art Evaluators of Translation Quality},
  author={Tom Kocmi and Christian Federmann},
  journal={ArXiv},
  year={2023},
  volume={abs/2302.14520}
}
@article{Fu2023GPTScoreEA,
  title={GPTScore: Evaluate as You Desire},
  author={Jinlan Fu and See-Kiong Ng and Zhengbao Jiang and Pengfei Liu},
  journal={ArXiv},
  year={2023},
  volume={abs/2302.04166}
}

@inproceedings{huang-etal-2020-achieved,
    title = "What Have We Achieved on Text Summarization?",
    author = "Huang, Dandan  and
      Cui, Leyang  and
      Yang, Sen  and
      Bao, Guangsheng  and
      Wang, Kun  and
      Xie, Jun  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.33",
    doi = "10.18653/v1/2020.emnlp-main.33",
    pages = "446--469",
}
@inproceedings{laban-etal-2021-keep,
    title = "Keep It Simple: Unsupervised Simplification of Multi-Paragraph Text",
    author = "Laban, Philippe  and
      Schnabel, Tobias  and
      Bennett, Paul  and
      Hearst, Marti A.",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.498",
    doi = "10.18653/v1/2021.acl-long.498",
    pages = "6365--6378",
}

@inproceedings{williams-etal-2018-broad,
    title = "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
    author = "Williams, Adina  and
      Nangia, Nikita  and
      Bowman, Samuel",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1101",
    doi = "10.18653/v1/N18-1101",
    pages = "1112--1122",
}
@article{Liu2019RoBERTaAR,
  title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
  journal={ArXiv},
  year={2019},
  volume={abs/1907.11692}
}
@inproceedings{brodersen2010balanced,
  title={The balanced accuracy and its posterior distribution},
  author={Brodersen, Kay Henning and Ong, Cheng Soon and Stephan, Klaas Enno and Buhmann, Joachim M},
  booktitle={2010 20th international conference on pattern recognition},
  pages={3121--3124},
  year={2010},
  organization={IEEE}
}
@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}
@article{wang2023chatgpt,
  title={Is ChatGPT a Good NLG Evaluator? A Preliminary Study},
  author={Wang, Jiaan and Liang, Yunlong and Meng, Fandong and Shi, Haoxiang and Li, Zhixu and Xu, Jinan and Qu, Jianfeng and Zhou, Jie},
  journal={arXiv preprint arXiv:2303.04048},
  year={2023}
}
@inproceedings{zhang2020pegasus,
  title={Pegasus: Pre-training with extracted gap-sentences for abstractive summarization},
  author={Zhang, Jingqing and Zhao, Yao and Saleh, Mohammad and Liu, Peter},
  booktitle={International Conference on Machine Learning},
  pages={11328--11339},
  year={2020},
  organization={PMLR}
}
@article{yuan2021bartscore,
  title={Bartscore: Evaluating generated text as text generation},
  author={Yuan, Weizhe and Neubig, Graham and Liu, Pengfei},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={27263--27277},
  year={2021}
}
@inproceedings{zhangbertscore,
  title={BERTScore: Evaluating Text Generation with BERT},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  booktitle={International Conference on Learning Representations}
}
@article{laban2022summac,
  title={SummaC: Re-visiting NLI-based models for inconsistency detection in summarization},
  author={Laban, Philippe and Schnabel, Tobias and Bennett, Paul N and Hearst, Marti A},
  journal={Transactions of the Association for Computational Linguistics},
  volume={10},
  pages={163--177},
  year={2022},
  publisher={MIT Press}
}

@article{Wang2023IsCA,
  title={Is ChatGPT a Good NLG Evaluator? A Preliminary Study},
  author={Jiaan Wang and Yunlong Liang and Fandong Meng and Haoxiang Shi and Zhixu Li and Jinan Xu and Jianfeng Qu and Jie Zhou},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.04048}
}

@article{zar2005spearman,
  title={Spearman rank correlation},
  author={Zar, Jerrold H},
  journal={Encyclopedia of biostatistics},
  volume={7},
  year={2005},
  publisher={Wiley Online Library}
}
@article{mukaka2012guide,
  title={A guide to appropriate use of correlation coefficient in medical research},
  author={Mukaka, Mavuto M},
  journal={Malawi medical journal},
  volume={24},
  number={3},
  pages={69--71},
  year={2012}
}
@article{kendall1938new,
  title={A new measure of rank correlation},
  author={Kendall, Maurice G},
  journal={Biometrika},
  volume={30},
  number={1/2},
  pages={81--93},
  year={1938},
  publisher={JSTOR}
}
@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}
@inproceedings{goodrich2019assessing,
  title={Assessing the factual accuracy of generated text},
  author={Goodrich, Ben and Rao, Vinay and Liu, Peter J and Saleh, Mohammad},
  booktitle={Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={166--175},
  year={2019}
}
@article{huang2021factual,
  title={The factual inconsistency problem in abstractive text summarization: A survey},
  author={Huang, Yichong and Feng, Xiachong and Feng, Xiaocheng and Qin, Bing},
  journal={arXiv preprint arXiv:2104.14839},
  year={2021}
}
@article{qin2022t5score,
  title={T5Score: Discriminative Fine-tuning of Generative Evaluation Metrics},
  author={Qin, Yiwei and Yuan, Weizhe and Neubig, Graham and Liu, Pengfei},
  journal={arXiv preprint arXiv:2212.05726},
  year={2022}
}
@article{jiao2023chatgpt,
  title={Is ChatGPT a good translator? A preliminary study},
  author={Jiao, Wenxiang and Wang, Wenxuan and Huang, Jen-tse and Wang, Xing and Tu, Zhaopeng},
  journal={arXiv preprint arXiv:2301.08745},
  year={2023}
}
@article{qin2023chatgpt,
  title={Is chatgpt a general-purpose natural language processing task solver?},
  author={Qin, Chengwei and Zhang, Aston and Zhang, Zhuosheng and Chen, Jiaao and Yasunaga, Michihiro and Yang, Diyi},
  journal={arXiv preprint arXiv:2302.06476},
  year={2023}
}
@article{yang2023exploring,
  title={Exploring the limits of chatgpt for query or aspect-based text summarization},
  author={Yang, Xianjun and Li, Yan and Zhang, Xinlu and Chen, Haifeng and Cheng, Wei},
  journal={arXiv preprint arXiv:2302.08081},
  year={2023}
}
@article{wang2023cross,
  title={Cross-Lingual Summarization via ChatGPT},
  author={Wang, Jiaan and Liang, Yunlong and Meng, Fandong and Li, Zhixu and Qu, Jianfeng and Zhou, Jie},
  journal={arXiv preprint arXiv:2302.14229},
  year={2023}
}
@article{bang2023multitask,
  title={A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity},
  author={Bang, Yejin and Cahyawijaya, Samuel and Lee, Nayeon and Dai, Wenliang and Su, Dan and Wilie, Bryan and Lovenia, Holy and Ji, Ziwei and Yu, Tiezheng and Chung, Willy and others},
  journal={arXiv preprint arXiv:2302.04023},
  year={2023}
}