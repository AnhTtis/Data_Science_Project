{
    "arxiv_id": "2303.17192",
    "paper_title": "Sublinear Convergence Rates of Extragradient-Type Methods: A Survey on Classical and Recent Developments",
    "authors": [
        "Quoc Tran-Dinh"
    ],
    "submission_date": "2023-03-30",
    "revised_dates": [
        "2023-03-31"
    ],
    "latest_version": 1,
    "categories": [
        "math.OC",
        "stat.ML"
    ],
    "abstract": "The extragradient (EG), introduced by G. M. Korpelevich in 1976, is a well-known method to approximate solutions of saddle-point problems and their extensions such as variational inequalities and monotone inclusions. Over the years, numerous variants of EG have been proposed and studied in the literature. Recently, these methods have gained popularity due to new applications in machine learning and robust optimization. In this work, we survey the latest developments in the EG method and its variants for approximating solutions of nonlinear equations and inclusions, with a focus on the monotonicity and co-hypomonotonicity settings. We provide a unified convergence analysis for different classes of algorithms, with an emphasis on sublinear best-iterate and last-iterate convergence rates. We also discuss recent accelerated variants of EG based on both Halpern fixed-point iteration and Nesterov's accelerated techniques. Our approach uses simple arguments and basic mathematical tools to make the proofs as elementary as possible, while maintaining generality to cover a broad range of problems.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.17192v1"
    ],
    "publication_venue": "47 pages, a survey paper"
}