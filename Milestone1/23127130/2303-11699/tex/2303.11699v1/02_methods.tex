\subsection{Generating synthetic crystals} \label{sec:generate_crystals} 

    To generate synthetic crystals, we randomly place atoms on the Wyckoff
    positions of a given space group and
    then apply the respective symmetry operations. The algorithm is
    explained in the following (see also Figure~\ref{fig:generation_and_distributed}a for a flow diagram of the algorithm).
    We only explain the most important steps, details can be found in Section~S1 in the SI.

    \begin{enumerate}
        \itemsep0em
        \item Random selection of a space group. We follow the space group distribution of the ICSD to allow comparison with previous work (see Section~\ref{sec:online_learning}).
        \item Sample unique elements of the crystal and their number of repetitions in the asymmetric unit.
        \item Place atoms onto the Wyckoff positions and draw uniform coordinates for each.
        \item Draw lattice parameters from KDE based on the ICSD.
        \item Apply space group symmetry operations.
    \end{enumerate}

    Parts of this algorithm were inspired by the generation algorithm of the
    \emph{Python} library \emph{PyXtal}
    \supercite{fredericksPyXtalPythonLibrary2021}. 
    We only keep generated crystals for training if the
    conventional unit cell volume is below \SI{7000}{\angstrom\cubed} and if
    there are less than 100 atoms in the asymmetric unit. 
    We did not employ any form of
    distance checks on the coordinates, as we found this to have no meaningful
    impact on space group classification accuracy. We only prevented the
    algorithm from placing more than one atom on a Wyckoff position that does not
    have a degree of freedom. We also did not use partial occupancies. We chose
    this algorithm for its simplicity and its capability to reproduce many
    important characteristics of ICSD crystals adequately (see Section
    \ref{sec:synth_distribution}).

    For some space groups, there are not enough crystals in the ICSD to form a
    representative KDE for the volume or to calculate suitable occupation
    probabilities for individual Wyckoff positions. Therefore, we chose to only
    perform the classification on space groups with 50 or more crystals
    available in the statistics dataset we used to extract the probabilities
    (see Section~\ref{sec:dataset_split}), resulting in the exclusion of 85
    space groups.\footnote{Note that also a classifier trained directly on ICSD
    data of all space groups will not be able to properly identify these space
    groups containing very few samples.}

    \begin{figure}[!htb] 
    \centering
    \includegraphics{./figures/combined_generation_and_distributed_system.pdf}
    \caption{a) Flowchart of how the generation algorithm produces synthetic
    crystals. Atoms are independently placed on the Wyckoff positions and random
    coordinates are drawn. b) Overview of the distributed computing system
    implemented using the \emph{Python} library
    \emph{Ray}\supercite{moritzRayDistributedFramework2018a}. Two compute nodes
    (that generate and simulate diffractograms) are connected to the \emph{Ray}
    head node using a \emph{Ray queue} object.}
    \label{fig:generation_and_distributed}
    \end{figure}

    \subsection{Simulating diffractograms} \label{sec:simulation} 

    To simulate powder diffractograms based on the generated crystals, we used
    the implementation found in the \emph{Python} library \emph{Pymatgen}
    \supercite{ongPythonMaterialsGenomics2013}. We optimized the simulation code
    using the LLVM just-in-time compiler \emph{Numba}
    \supercite{lamNumbaLLVMbasedPython2015}. This increases the performance of
    the main loop over the reciprocal lattice vectors of the crystal
    significantly and makes the continuous simulation while training (discussed
    in the next section) possible.

    We used the wavelength \SI{1.5406}{\angstrom} (Cu K$_\alpha$ line) to
    simulate all diffractograms. The obtained peaks were further broadened with
    a Gaussian peak profile to form the full diffractogram. To obtain the peak
    widths, we used the Scherrer
    equation\supercite{gilmoreInternationalTablesCrystallography2019}

    \begin{equation}
        \beta=\frac{K \lambda}{L \cos \theta} \text{,} \label{eq:scherrer}
    \end{equation}

    where $ \beta $ is the line broadening at half maximum intensity (on the
    $2\theta$-scale), $K$ is a shape factor, $\lambda$ is the wavelength, and
    $L$ is the (average) thickness of crystallites. We drew crystallite sizes
    from the range $ \left[ 20, 100 \right] $ \si{\nano \metre} and used 
    $K=0.9$.

    Diffractograms were generated in the range $ 2 \theta \in \left[ 5, 90
    \right] \si{\degree} $ with step size \SI{0.01}{\degree}. After generating
    each diffractogram, it was rescaled to fit in the intensity range $ \left[
    0,1 \right]$.

    \subsection{Continuous generation of training data}\label{sec:online_learning} 
    
    Typically, machine learning models are trained with a fixed dataset predefined at the beginning of training. Sometimes, data augmentation
    is applied to further increase the effective size of this dataset. In
    contrast to that, we generated our dataset on-the-fly, parallel to model training. The
    main advantage of using this approach compared to a fixed-size dataset is
    the eliminated possibility to overfit to individual diffractograms since
    every diffractogram is only used once. Furthermore, not having to
    pre-simulate a dataset before training makes this approach more flexible
    when changing simulation parameters.

    We used a distributed architecture on multiple nodes using the \emph{Python}
    framework \emph{Ray} \supercite{moritzRayDistributedFramework2018a}. The
    configuration utilized throughout this study is visualized in Figure~\ref{fig:generation_and_distributed}b. Training took place on a \emph{Ray}
    head node with one or two\footnote{The ``parkCNN'' models used a single GPU, while
    the ResNet models were trained on two GPUs.} RTX 2080 Ti GPUs. Training on two
    GPUs was performed using the \emph{MirroredStrategy} of \emph{TensorFlow}
    \supercite{abadiTensorFlowLargeScaleMachine2015}. 28 out of the 32 cores of
    the head node were used for the generation of diffractograms. Next to the
    head node, we used two additional compute nodes with 128 cores each to
    generate diffractograms. Communication between the nodes took place using a
    \emph{Ray queue} object to access the simulated diffractograms. Depending on
    the model size and corresponding training speed, this setup allows
    full-speed training with up to millions of diffractograms per hour while efficiently using the GPUs for most of the models used in this
    study.\footnote{For the ``parkCNN'' models (see Section~\ref{sec:models_and_experiments}), training is very fast and the data
    generation becomes the bottleneck.}

    As already discussed, the distribution of space groups in the ICSD is highly
    imbalanced. If a similar performance for all space groups is desired, a
    uniform distribution of space groups in the training dataset is needed. This is
    trivially possible with our synthetic approach, in contrast to training directly on the ICSD, where weighting, over-, or undersampling methods are needed \supercite{sunClassificationImbalancedData2009}.
    To allow a direct and fair comparison between our approach and the original approach of training directly on ICSD entries, we still
    followed the same distribution of space groups of the ICSD in our synthetic
    training dataset. This eliminates the problem that the effective number of total
    space groups is smaller when training on a highly imbalanced dataset, making it
    easier to reach high accuracies. 

    \subsection{Dataset split} \label{sec:dataset_split} 
    
    The ICSD database contains many structures that are very similar with
    slightly different lattice parameters and coordinates. For example, there
    are 25 entries for \ce{NaCl} (October 2022). Furthermore,
    there are 3898 entries that have the same structure type as \ce{NaCl} and
    thus also similar powder diffractograms. If some of them appear in the
    training dataset and some in the test dataset, the classification will be
    simplified to recognizing the structure type or structure. In that case, the
    test set accuracy will not represent the true generalization performance of the neural
    network. To quantify the true generalization performance, we split the
    dataset in such a way that the same structure type appears either only in
    the training or in the test dataset. We used the structure type definitions
    provided by the ICSD. The obtained accuracy on the test dataset reflects the
    accuracy of our network when being used on a novel sample with a structure
    type not yet present in the ICSD database.

    We want to emphasize that the used split is very important for the task of
    space group classification and not a trivial choice. The ICSD contains many
    subtypes of structure types (for example, subtypes of perovskites), which we
    regarded as separate structure types in our split. Considering the subtypes
    as the same structure type may also be a viable option when performing the
    split. A combination of a split based on structure type and sum formula or
    similar approaches are also possible. However, we think that our choice of
    splitting the dataset is able to effectively measure the generalization
    performance while still being relatively simple.

    We divided the ICSD (database version 2021, June 15) in a 70:30 split. For
    our synthetic crystal approach, the 70\% part (called statistics or training
    dataset) was only used to create the KDEs and to calculate the Wyckoff
    occupation probabilities needed for the generation algorithm. Since we can
    judge the performance of the synthetic generation algorithm by comparing the
    training accuracy (on synthetic crystals) with the accuracy tested on
    diffractograms simulated directly from the statistics dataset, an additional
    validation dataset was not needed. For comparison with the original
    approach by
    \citeauthor{parkClassificationCrystalStructure2017}\supercite{parkClassificationCrystalStructure2017}
    of directly training on ICSD crystals, we simulated crystals directly from
    the statistics dataset and trained on them.

    Analogous to the synthetic generation, we only used crystals with a
    conventional unit cell volume below \SI{7000}{\angstrom\cubed} and with less
    than 100 atoms in the asymmetric unit for the statistics and test dataset.
    This covers $ \approx 94\% $ of the ICSD crystals.

    \subsection{Models and experiments} \label{sec:models_and_experiments}

    \subsubsection*{Models}
    We will briefly introduce the models we used for the classification
    of space groups. A more detailed description can be found in the SI
    Section~S2.

    As a baseline, we first used the CNN models introduced by
    \citeauthor{parkClassificationCrystalStructure2017}\supercite{parkClassificationCrystalStructure2017}.
    They used three models, one for the classification of crystal systems
    (``parkCNN small''), one for extinction groups (``parkCNN medium''), and one
    for space groups (``parkCNN big''). All models have three convolution layers
    with two hidden fully connected layers and one output layer. The
    three models differ in the number of neurons in the hidden fully connected
    layers, increasing the number of model parameters with the number of target
    labels. Here, we only used the models ``parkCNN medium'' and ``parkCNN big''
    and applied both to the classification of space groups. When using ICSD
    crystals to train the ``parkCNN'' models, dropout was used, while the
    training of the ``parkCNN'' models on synthetic crystals did not use
    dropout.

    Since the approach of using an infinite stream of generated training data
    eliminates the problem of overfitting, we further used deeper models with a
    higher number of model parameters. For this, we used the deep convolutional
    neural networks ResNet-10, ResNet-50, and ResNet-101, which were introduced
    by
    \citeauthor{heDeepResidualLearning2016}\supercite{heDeepResidualLearning2016}
    in 2015.

    We were not able to achieve good results when using the original ResNet
    architecture with batch normalization. The test accuracy calculated after
    each epoch was highly unstable and had high fluctuations, probably due to
    the moving averages of the batch normalization not converging properly. This
    is possibly caused by using an infinite stream of batches of
    diffractograms, instead of using a training dataset of fixed size. We fixed
    this problem by using group
    normalization\supercite{wuGroupNormalization2018} with 32 groups instead of
    batch normalization.

    \subsubsection*{Machine learning setup}

    To train all models, we used \emph{Keras} \supercite{francoisKeras} with
    \emph{TensorFlow} 2.3 \supercite{abadiTensorFlowLargeScaleMachine2015}.
    Optimization was performed using \emph{Adam}
    \supercite{kingmaAdamMethodStochastic2017} with $ \beta_1=0.9 $ and $
    \beta_2=0.999 $ (\emph{Keras} default parameters). We also tried to use stochastic gradient descent (SGD)
    with momentum and a stepwise learning rate scheduler, but this did not yield
    good results. Depending on the initial conditions, most of the training runs
    using SGD were either unstable or reached low accuracies. For all
    experiments, a cross-entropy loss was utilized.
    
    We used a batch size of $870$ for the ``parkCNN'' models and a batch size
    of $145$ for the three ResNet models. Furthermore, the ``parkCNN'' models
    were trained for $1000$ epochs with a learning rate of $0.001$, while the
    ResNet models were trained for $2000$ epochs with a learning rate of $0.0001$.
    The ResNet models used a step decay of the initial learning rate,
    halving the learning rate after every $500$ epochs.

    When training on diffractograms simulated from synthetic crystals, we used
    $150$ generated batches per epoch when a batch size of $870$ was used
    (``parkCNN medium'' and ``parkCNN big'') and $900$ batches per epoch when a
    batch size of $145$ was used (ResNet). This means that each epoch always
    contained $130\,500$ diffractograms\footnote{Note that the division into epochs
    for training using synthetic crystals is rather arbitrary since each epoch
    contains different diffractograms simulated from different crystals.
    However, the division makes it easy to calculate the performance on the test
    dataset after each epoch.}.

    For the experiments performed directly on diffractograms simulated from ICSD
    crystals, we used the statistics dataset directly to pre-generate the
    training dataset. We excluded the same 85 space groups that were not used by
    the synthetic training due to missing statistics. We used two different
    crystallite sizes for each crystal in the statistics dataset, yielding
    $148\,466 \cdot 2 = 296\,932 $ diffractograms in the training dataset.
    
    \subsubsection*{Experiments}

    We performed two sets of experiments to evaluate our synthetic crystal generation approach: Firstly, we trained and tested models on ICSD crystals only, and secondly, we trained on synthetic crystals and tested on ICSD crystals.

    In particular, we first 
    performed an experiment with the ``parkCNN medium'' model trained directly on the diffractograms
    simulated from the ICSD statistics dataset (similar to
    \citeauthor{parkClassificationCrystalStructure2017}
    \supercite{parkClassificationCrystalStructure2017}) with a
    fully random train-test split, instead of splitting by the structure type of
    the crystals. This experiment makes a comparison of the two different
    methods of train-test split possible.
    We then trained the ``parkCNN big'' model using the structure type-based split, again directly on ICSD diffractograms. 
    We further repeated the
    same experiment using the smaller model ``parkCNN medium'' to resolve
    potential overfitting to the ICSD diffractograms.

    For the experiments performed on our continuously generated
    dataset based on synthetic crystals, we used the structure type-
    based split. As discussed in Section~\ref{sec:dataset_split}, the training / 
    statistics dataset was only used to extract more general statistics, such as the 
    element distribution.
    First, we trained the ``parkCNN big'' model. For each
    batch, we generated $ 435 $ random crystals and simulated two diffractograms
    with different crystallite sizes for each of them. This resulted in the
    above-mentioned batch size of $ 870 $. 
    Since our synthetic crystal generation algorithm yields an infinite stream
    of unique diffractograms to train on, using much larger models than for the
    fixed ICSD dataset is possible without overfitting. We performed experiments
    for the ResNet-10, ResNet-50, and ResNet-101 models. Instead of generating
    two diffractograms with different uniformly sampled crystallite sizes for each generated crystal (as
    we did for the ``parkCNN big'' model), we now created only one diffractogram
    for each of the $ 145 $ crystals generated for one batch. This is due to 
    the slower training of the ResNet models, which means that reusing the same 
    diffractogram with different crystallite sizes is not necessary to generate
    training data fast enough.
    
    To obtain the
    highest-possible ICSD test accuracy, we further applied the square root
    function as a preprocessing step to the input diffractograms of the
    network when using the ResNet models. This was suggested by
    \citeauthor{zalogaCrystalSymmetryClassification2020}
    \supercite{zalogaCrystalSymmetryClassification2020} and in their case
    improved classification accuracy by approximately 2 percentage points. Some
    initial tests suggested that this approach also yields a higher accuracy for our
    case, so used this preprocessing step to train the ResNet
    models.

    While we focused mainly on the methodology of using synthetic crystals to extract structural information from powder diffractograms, we also show some initial steps toward applying our methods to experimental data. We used the publicly available RRUFF mineral database
    \supercite{lafuentePowerDatabasesRRUFF2015} which provides experimental measurements, including powder diffractograms. In order to imitate experimental diffractograms, we added Gaussian additive and multiplicative noise and a background function based on samples from a Gaussian process to our simulated diffractograms. Furthermore, we added
    a small amount of an impurity phase to each diffractogram. Details about the experimental data generation protocol can be found in the SI Section~S3. Using the ResNet-50 model, we performed two experiments for experimental data, one with the mentioned impurity phase, and one without.