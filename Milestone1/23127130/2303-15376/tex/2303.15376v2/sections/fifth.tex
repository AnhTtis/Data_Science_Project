\section{Methods for inference}
\label{Section5}

\subsection{Related work}
Many algorithms exist to estimate the causal graph $\mathcal{G}$ from observational data, each requiring different assumptions, guarantees, and outputs. See \cite{ZhangReview}, or Chapter~4 in \cite{Elements_of_Causal_Inference} for a review. In the following three paragraphs, we describe three main approaches in the recent literature. 

Identifiable model-based methods such as LiNGaM \citep{Lingam}, RESIT \citep{Peters2014}, PNL \citep{Zhang2010},  GHD DAG \citep{ParkGHD,ParkVariance}, HECI \citep{xu2022inferring} or LOCI \citep{immer2022identifiability}  exploit the fact that we can not fit a certain model in both causal directions. 
This is also the approach of this paper.
For practical evaluation, we need to measure how well the model fits the data. One possibility is to test the independence between the cause and the estimated noise. The second possibility is to use a maximum likelihood approach. In both cases, the choice of the model is very important. 
%. However, the choice of model is crucial and should be based on some knowledge about the dataset at hand (or possibly data-driven). Different applications require different models, and a discussion about the choice of the model is as important as in classical statistics. 

Score-based methods \citep{Greedy_search, Score-based_causal_learning} are very popular for distinguishing between the DAGs in the Markov equivalence class. Denote the space of DAGs on $d$ nodes by $DAG(d)$ and let $s: DAG(d)\to \mathbb{R}$ be a score function. Function $s$ assigns each DAG a score that evaluates the overall fit. The goal is then to find  $\min_{\mathcal{G}\in DAG(d)}s(\mathcal{G})$ which is typically an NP-hard problem \citep{NP-hard_score_based_causal_learning}.  However, under appropriately chosen $s$ and additional assumptions, algorithms with polynomial time complexity were proposed \citep{Bregmans_information}. Nevertheless, the choice of $s$ is crucial since the graph which minimizes $s(\mathcal{G})$ can differ from the true data-generating mechanism. 
 
Other methods based on algorithmic mutual information \citep{IGCI,Natasa_Tagasovska} or Information-Geometric approaches \citep{IGCI} are popular, especially in computer science. They are based on a different paradigm of independence (based on Kolmogorov complexity or independence between certain functions in a deterministic scenario).  Often, they are implemented only in the bivariate case. In the simulations in Section \ref{Section_simulations_Gaussian}, we compare our method with several previously mentioned methods. 

\subsection{Algorithm for CPCM using independence testing}
\label{Section_Algorithm}
Our CPCM methodology is based on choosing an appropriate model (in our case, reduced to a choice of $F_1, F_2$) and a measure of a model fit. In what follows, we measure the model fit by exploiting the principle of independence between the cause and the mechanism. First, we provide a more general framework for the model-based methodologies. 

\subsubsection{Invertible functional causal models}

We explain the algorithm in a more general framework. Algorithms such as RESIT \citep{Peters2014}, CAM \citep{BuhlmannCAM}, PNL \citep{Zhang2009}, LOCI \citep{immer2022identifiability} are special cases or only small modifications of this framework. 

Recall that the general SCM corresponds to $d$ equations $X_i = f_{i}(\textbf{X}_{pa_i}, \varepsilon_i)$, $i=1, \dots, d$, where $\varepsilon=(\varepsilon_1, \dots, \varepsilon_d)^\top$ are jointly independent noise variables. We define the \textbf{invertible functional causal model} \textbf{(IFCM)} as an acyclic SCM, such that there exist functions $f_1^{\leftarrow}, \dots, f_d^{\leftarrow}$ for which $\varepsilon_i  =  f_i^{\leftarrow}(\textbf{X}_{pa_i}, X_i)$, $i=1, \dots, d$.  IFCM is a very general model since it is strictly broader than all previously mentioned models (e.g., the post-nonlinear model where $X_i=f_i(\textbf{X}_{pa_i}, \varepsilon) = g_2\big(g_1(\textbf{X}_{pa_i}) + \varepsilon\big)$ satisfy $\varepsilon = g_2^{-1}(X_i)-g_1(\textbf{X}_{pa_i})$, for $g_2$ invertible). 

\subsubsection{Main steps of the algorithm}

We say that a causal graph is \textbf{plausible} under the causal model $\mathcal{M}$ if the joint distribution \textit{can} be generated under model $\mathcal{M}$ with such a graph. The algorithm in Table \ref{tableDefinitions} describes the main steps to test the plausibility. If one direction is plausible and the other is not, we consider the former as a final estimate. Problems arise if both directions have the same plausibility. If both directions are plausible, it suggests an unidentifiable setup (or we have insufficient data). If both directions are unplausible, it suggests that some assumptions are not fulfilled or that our estimate $\hat{f}^{\leftarrow}$ (resp $\hat{\theta}$) is not appropriate. 
% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table}[htbp]
\resizebox{\columnwidth}{!}{%
\begin{tabular}{|l|l|}
\hline
\multicolumn{1}{|c|}{\textbf{General IFCM}} &
  \multicolumn{1}{c|}{$\mathbf{CPCM(F_1, F_2)}$  } \\ \hline
Test for independence between $X_1, X_2$. &
  Test for independence between $X_1, X_2$. \\
If not rejected, return an empty graph. &
  If not rejected, return an empty graph. \\ \hline
In direction  $X_1\to X_2$: &
  In direction  $X_1\to X_2$: \\
\,\,\,\,\,\,\,\,\,\,1) Estimate function $\hat{f}^{\leftarrow}$ &
  \,\,\,\,\,\,\,\,\,\,1) Estimate $\hat{\theta}(X_1)$. \\
\,\,\,\,\,\,\,\,\,\,2) Compute $\hat{\varepsilon}_2 := \hat{f}^{\leftarrow}(X_1, X_2)$. &
  \,\,\,\,\,\,\,\,\,\,2) Use probability transform $\hat{\varepsilon}_2 := F_2\big(X_2; \hat{\theta}(X_1)\big)$ \\
\,\,\,\,\,\,\,\,\,\,3) Test an independence between $\hat{\varepsilon}_2$ and $X_1$. &
  \,\,\,\,\,\,\,\,\,\,3) Test an independence between $\hat{\varepsilon}_2$ and $X_1$. \\
 Direction $X_1\to X_2$ is \textit{plausible} if the test from step 3&
 Direction $X_1\to X_2$ is \textit{plausible}  if the test  from step 3\\
 is not rejected. &
 is not rejected. \\ \hline
Repeat for the other direction $X_2\to X_1$. &
  Repeat for the other direction $X_2\to X_1$ using $F_1$. \\ \hline
\end{tabular}%
}
\caption{Main steps of the algorithm for the estimation of the causal graph under IFCM and CPCM models in a bivariate case. }
\label{tableDefinitions}
\end{table}

Estimation of $\hat{f}^{\leftarrow}$ without additional assumptions is very difficult and has to be based on a more restricted model. Under CPCM, this reduces to an estimation of $\hat{\theta}(X_1)$ in the first step. This can be done using any machine learning algorithm, such as GAM, GAMLSS, random forest, or neural networks. For the third step (test of independence), we can use a Kernel-based HSIC test \citep{Kernel_based_tests} or a copula-based test \citep{copula_based_independence_test}. 

Generalizing this approach for the multivariate case with $d$ variables is straightforward. For each $\mathcal{G}\in DAG(d)$, we estimate  $\hat{\theta}_i(\textbf{X}_{pa_i(\mathcal{G})})$ for all $i = 1, \dots, d$ and compute the probability transform $\hat{\varepsilon}_i := F_i\big(X_i; \hat{\theta}_i(\textbf{X}_{pa_i(\mathcal{G})})\big)$. Then, we can test independence between  $\hat{\varepsilon}_1, \dots, \hat{\varepsilon}_d$ and say that $\mathcal{G}$ is plausible if this test is not rejected. However, in the multivariate case, several graphs can be plausible, which can be inconvenient in practice. The score-based algorithm can overcome this nuisance, as we shortly describe. 

\subsection{Score-based algorithm for CPCM }
\label{Section_score_based_algorithm}
The algorithm for CPCM using the independence testing presented in the previous subsection does not always provide an output. The possibility of rejecting the independence test in all directions can be considered a safety net, shielding us against unfulfilled assumptions or unidentifiable cases. Nevertheless, we may still want to obtain an estimation of the graph. 

Following the ideas from \citep{Score-based_causal_learning} and \citep{Peters2014}, we use the penalized independence score 
\begin{equation*}
\hat{\mathcal{G}} =  \min_{\mathcal{G}\in DAG(d)}s(\mathcal{G}) = \argmin_{\mathcal{G}\in DAG(d)}\rho (\hat{\varepsilon}_1, \dots, \hat{\varepsilon}_d) + \lambda (\text{Number of edges in }\mathcal{G}),
\end{equation*}
where $\rho$ represents some measure of independence, $\hat{\varepsilon}_1, \dots, \hat{\varepsilon}_d$ are noise estimations obtained by estimating $\hat{\theta}_i(\textbf{X}_{pa_i(\mathcal{G})})$ and putting $\hat{\varepsilon}_i := F_i\big(X_i; \hat{\theta}_i(\textbf{X}_{pa_i(\mathcal{G})})\big)$ such as in step 1 and step 2 in the algorithm in Section \ref{Section_Algorithm}. 

As for the choice of $\rho$, we use minus the logarithm of the p-value of the copula-based independence test \citep{copula_based_independence_test} and $\lambda = 2$. These choices seem to work well in practice, but we do not provide any theoretical justification of their optimality. In the bivariate case, we test the independence between $X_1, X_2$ and if rejected, we choose the graph with the lowest score $\rho (\hat{\varepsilon}_1, \hat{\varepsilon}_2)$. Doing so, we do not have to choose an appropriate $\lambda$.  

Another natural choice for the score function $s$ is based on log-likelihood  or AIC (or BIC) as in \cite{Score-based_causal_learning}. We do not comment on this further in this paper. 

The main disadvantage of the proposed method is that we have to go through all graphs $\mathcal{G}\in DAG(d)$, which is possible only for $d\lesssim 5$, since the number of DAGs grows superexponentially with dimension $d$ \citep{NP-hard_score_based_causal_learning}. Several modifications can be used in order to speed up the process. Greedy algorithms have been proposed \citep{Greedy_search, Bregmans_information}. This is beyond the scope of this paper. Our algorithm is relatively standard and is only a slight modification of classical algorithms. Hence, in Section \ref{simulations_section}, we provide only a short simulation study to highlight the results of Section 3. 


\subsection{Model choice, overfitting and problems in practice}
\label{Section5Model_choice}
The choice of the model (choice of $F$ or $F_1, F_2$ if we opt for our CPCM framework) is a crucial step in our approach. The choice of a model is a common problem in classical statistics; however, it is more subtle in causal discovery. 
Here, $F$ should be viewed as a metric for the "complexity" of SCM. We mention some of the problems that arise in practice. We also discuss them in detail in our application. 
\begin{itemize}
\item \textbf{Choosing $F$ with too many parameters ($q$ is large)}: Even if the theory suggests that it is not possible to fit a $CPCM(F)$ in both causal directions, this is only an asymptotic result no longer valid for a finite number of data. If we choose $F$ with many parameters to estimate, our data will be fitted perfectly, and we will not reject the wrong causal graph. However, by choosing an overly simple $F$, our assumptions do not have to be fulfilled, and we may reject the correct causal graph. 

\item \textbf{Several choices of $F$ and multiple testing}: The choice of $F$ should ideally be based on prior knowledge of the data-generating process. Looking at the marginal distributions of $X_1, X_2$ can be useful, although it is questionable how much marginal distributions can help choose an appropriate model for the conditional distribution.  Comparing many different $F$s can lead to multiple testing problems, and we should be careful with data-driven estimation of $F$, as the following lemma suggests:  \begin{lemma}\label{lemma_o_overparametrizacii}
Let $F_2$ be a distribution function with one parameter ($q_2=1$) belonging to the exponential family with the corresponding sufficient statistic $T_2$. 
Suppose that the joint distribution $F_{(X_1,X_2)}$ is generated according to model $CPCM(F_2)$ ( \ref{BCPCM}) with graph $X_1\to X_2$. 

Then, there exists $F_1$ such that the model $CPCM(F_1)$ ( \ref{BCPCM}) with graph $X_2\to X_1$ also generates  $F_{(X_1,X_2)}$. In other words, there exists $F_1$ such that the causal graph in $CPCM(F_1, F_2)$ is not identifiable from the joint distribution. 
\end{lemma}

The proof (provided in \hyperref[appendix]{Appendix} \ref{Proof of lemma_o_overparametrizacii}) is based on the specific choice of $F_{1}$, such that its sufficient statistic $T_1$ is equal to $\theta_2$ (where $\theta_2$ is the parameter from the original model $CPCM(F_{2})$).  Typically, such $F_{1}$ is "ugly" and would lead to a very non-standard distribution. Lemma \ref{lemma_o_overparametrizacii} indicates that a data-driven estimation of $F_{1}$ can be problematic.  

\item \textbf{Different complexity between models}: We recommend choosing the same $F$ in both directions (if reasonable), or at least trying to choose $F_{1}, F_{2}$ with the same number of parameters $q_1 = q_2$. If we choose, say, $F_{1}$ with one parameter and $F_{2}$ with five parameters ($q_1 = 1, q_2 = 5$), it will create a bias towards one direction because the model with more parameters will fit the data more easily. We refer to this as an "unfair game". 
\end{itemize}


In this paper, we opt for the following choices: we choose GAM \citep{Wood2} estimation of $\hat{\theta}(X_i)$. As for the independence test, we choose Hoeffding D-test \citep{Nonparametric_test_for_independence_review} in the bivariate case, copula-based independence test \citep{Kojadinovic2009} in the multivariate case with $n>1000$ and HSIC \citep{ZhangKernelTest} when $n\leq 1000$ (see a review of different tests and their comparisons \cite{copula_based_independence_test}). 













