%Rozmysli si F_i being CONDITIONAL distirubiton functions
%Zmaz vsetky bold math symboly

\section{Multivariate case}
\label{Section4}

Now, we move the theory to the case with more than two variables $d\geq 2$. We assume causal sufficiency (all relevant variables have been observed) and causal minimality. On the other hand, we do not assume faithfulness. 
It is straightforward to generalize the asymmetric $\M$-causal model to the multivariate case, where we assume that each variable $X_i$ arises under the $\mathcal{M}_i$ model. 

To be more rigorous, we define a multivariate CPCM, as a generalization of (\ref{asymetrical_F_one_F_two_model}). 

\begin{definition}\label{DefinitionCPCM}
Let $F_1, \dots, F_d$ be distribution functions with $q_1, \dots, q_d$ parameters respectively. 
We define an asymmetrical $\mathcal{M}_{F_1}, \dots, \mathcal{M}_{F_d}$-causal model ($CPCM(F_1, \dots, F_d)$ for short) as a collection of equations 
\begin{equation*}
S_j:  X_j = F^{-1}_{j}(\varepsilon_j; \theta_j\big(\textbf{X}_{pa_j})\big), j=1, \dots, d,
\end{equation*}
 and we assume that the corresponding causal graph is acyclic. $(\varepsilon_1, \dots, \varepsilon_d)^\top$ is a collection of jointly independent uniformly distributed random variables. $\theta_j: \mathbb{R}^{|pa_j|}\to \mathbb{R}^{q_j}$ are non-constant functions in any of their arguments and are continuous if $\textbf{X}_{pa_j}$ are continuous. 

If $F_j^{-1} = F^{-1}$  for some quantile function $F^{-1}$ and for all $j\not\in Source(\mathcal{G}_0)$, we call such a model the conditionally parametric causal model ($CPCM(F)$).
\end{definition}
Simply said, we assume that $X_j\mid \textbf{X}_{pa_j}$ is distributed according to the distribution $F_j$ with parameters $\theta_j(\textbf{X}_{pa_j})$. We assume all $F_j$ \textit{are known} besides the source variables. 


The question of the identifiability of $\mathcal{G}$ in the multivariate case is in order. Here, it is not satisfactory to consider the identifiability of each pair of $X_i\to X_j$ separately. Each pair $X_i, X_j$  needs to have an identifiable causal relation \textit{conditioned} on other variables $\textbf{X}_S$, as the following theorem suggests. 


 \begin{theorem}\label{thmMultivairateIdentifiability}
Let $F_{\textbf{X}}$ be generated by the $CPCM(F_1, \dots, F_d)$ with DAG $\mathcal{G}$ and with density $p_{\textbf{X}}$. Let for all $ i,j\in\mathcal{G}, i\in pa_j$ hold the following: $\forall S\subseteq V$ such that  $pa_j\setminus \{i\}\subseteq S \subseteq nd_j\setminus\{i,j\}$ there exist $\textbf{x}_{S}: p_{\textbf{X}_S}(\textbf{x}_S)>0$ satisfying: a bivariate model defined as $X=\tilde{\varepsilon}_X, Y = F^{-1}_j\big(\tilde{\varepsilon}_Y, \tilde{\theta}(X)\big)$ is identifiable (in the sense of Definition \ref{DEFidentifiability}), where  $F_{\tilde{\varepsilon}_X} = F_{X_i\mid \textbf{X}_{S} =\textbf{ x}_S}    $ and $\tilde{\theta}(x) = \theta_j(\textbf{x}_{pa_j\setminus\{i\}}, x)$, where $x\in supp(X)$.

Then,  $\mathcal{G}$ is identifiable from the joint distribution. 
 \end{theorem}
 The proof is provided in \hyperref[Proof of thmMultivairateIdentifiability]{Appendix} \ref{Proof of thmMultivairateIdentifiability}. It is an adaptation of \citep[Theorem 28]{Peters2014}. 
 An important special case arises when we assume (conditional) normality.

\begin{consequence}[Multivariate Gaussian case]\label{ExampleMultivariateGaussiancase}
Suppose that $\textbf{X}=(X_1, \dots, X_d)$ follow $CPCM(F)$ with a Gaussian distribution function $F$. This corresponds to $X_j\mid \textbf{X}_{pa_j}\sim N\big(\mu_j(\textbf{X}_{pa_j}), \sigma_j^2(\textbf{X}_{pa_j})\big)$ for all $j=1, \dots, d$ and for some functions $\mu_j, \sigma_j$. In other words, we assume that the data-generating process has a form 
$$
X_j = \mu_j(\textbf{X}_{pa_j}) + \sigma_j(\textbf{X}_{pa_j})\varepsilon_j, \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\, \varepsilon_j \text{  is Gaussian.}
$$
Potentially, source nodes can have arbitrary distributions. Combining Theorem~\ref{normalidentifiability} and Theorem~\ref{thmMultivairateIdentifiability}, the causal graph $\mathcal{G}$ is identifiable if the following holds: 
functions $\theta_j(\textbf{x}):=\big(\mu_j(\textbf{x}), \sigma_j(\textbf{x})\big)^\top, \textbf{x}\in\mathbb{R}^{|pa_j(\mathcal{G})|}$ , $j=1, \dots, d$, are two times differentiable and they are \textit{not} in the form (\ref{norm}) in any of their arguments. 
\end{consequence}


















