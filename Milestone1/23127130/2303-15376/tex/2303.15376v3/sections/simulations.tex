

\section{Simulations} \label{simulations_section}
The \texttt{R} code with the implementations of the algorithms presented in the previous section and the code for the simulations and the application can be found in the supplementary package or \url{https://github.com/jurobodik/Causal_CPCM.git}.

In this section, we illustrate our methodology under controlled conditions. We first consider the bivariate case in which $X_1$ causes $X_2$. We select different distribution functions $F$ in the CPCM model, different forms of $\theta$, and different distributions of $\varepsilon_1$. We recreate a few of the theoretical results presented in Section 2. 


\subsection{Pareto case following Example \ref{example_Pareto} and Consequence  \ref{paretoidentifiability} }

Consider the Pareto distribution function $F$; functions $p_{\varepsilon_1}(x),\theta(x)$ are defined similarly as in (\ref{eq50}). Specifically, we choose $p_{\varepsilon_1}(x)\propto \frac{1}{ [\log(x)+1] x^{2} }$ and $\theta(x) = x^\alpha log(x) +1$ for some hyper-parameter $\alpha\in\mathbb{R}$. This $\alpha$ represents the distortion from the unidentifiable case. If $\alpha = 0$, we are in the unidentifiable case described in Consequence \ref{paretoidentifiability}. If $\alpha> 0$, Consequence \ref{paretoidentifiability} suggests that we should be able to distinguish between the cause and the effect. If $\alpha<0$, then $\theta$ is almost constant (function $\frac{log(x)}{x^{-\alpha}}$ is close to zero function on $x\in [1, \infty)$) and $(X_1, X_2)$ are (close to) independent.

For the size of the dataset $n =300$ and  $\alpha \in \{  -2,   0,  2\}$, we simulate data as described above. Using our $CPCM(F)$ algorithm from Section \ref{Section_Algorithm}, we obtain an estimate of the causal graph.  After averaging results from 100 repetitions, we obtain the results described in Figure \ref{Pareto_simulations1}. The resulting numbers are as expected: if $\alpha = 0$, then both directions tend to be plausible. If $\alpha >0$, we tend to estimate the correct direction $X_1\to X_2$; if $\alpha<0$, then we tend to estimate an empty graph since $X_1, X_2$ are (close to) independent.  


\begin{figure}[ht]
\centering
\includegraphics[scale=0.5]{figures/1.pdf}
\caption{Simulations corresponding to the CPCM model with Pareto distribution function $F$. The results represent our estimations of the graph structure with the $CPCM(F)$ algorithm from Section \ref{Section_Algorithm}. The green line represents the case when both directions are plausible (we do not reject the independence test in both directions). The yellow line represents the case in which both directions are unplausible (we reject the independence test in both directions. This case did not occur). }
\label{Pareto_simulations1}
\end{figure}



\subsection{The Gaussian case and comparison with baseline methods}
\label{Section_simulations_Gaussian}
For simulated data, we use the benchmark dataset introduced in \cite{Natasa_Tagasovska}. The dataset consists of additive and location-scale Gaussian pairs of the form $X_2= \mu(X_1)+\sigma(X_1)\varepsilon_2$, where $\varepsilon_2\sim N(0, 1)$, $X_1\sim N(0, \sqrt{2})$. In one setup (LSg), we consider  $\mu$ and $ \sigma$  as nonlinear functions simulated using Gaussian processes with Gaussian kernel with bandwidth one \citep{Gaussian_processes}.  In the second setup (LSs), we consider $\mu$ and $ \sigma$ as sigmoids \citep{BuhlmannCAM}. Further, nonlinear additive noise models (ANM) are generated as LS with constant $\sigma(X_1)=\sigma \sim U(1/5, \sqrt{2/5})$ and nonlinear multiplicative noise models (MN) are generated as LS with fixed $\mu(X_1)=0$ (only with sigmoid functions for $\sigma$).  For each of the five cases (LSg, LSs, ANMg, ANMs, and MNs), we simulate 100 pairs with $n=1000$ datapoints.

We compare our method with LOCI \citep{immer2022identifiability}, HECI  \citep{xu2022inferring}, RESIT \citep{Peters2014},  bQCD \citep{Natasa_Tagasovska}, IGCI with Gaussian and uniform reference measures \citep{IGCI} and Slope \citep{Slope}. Details can be found in  Appendix \ref{Appendix_simulations}.  As in \cite{reviewANMMooij}, we use the accuracy for forced decisions as our evaluation metric. The results are presented in Table \ref{Table_Simulated_data_Gaussian}.  We conclude that our estimator performs well on all datasets, and provides comparable results with those using LOCI and IGCI (although utilizing the uniform reference measure would lead to much worse results for IGCI).

Note that in the ANM and MN cases, we non-parametrically estimate two parameters while only one is relevant. Therefore, it can happen that we ``overfit'' (see Section \ref{Section5Model_choice}), and both directions are not rejected. To improve our results, fixing either $\mu$ or $\sigma$ could be beneficial (although it may prove challenging to determine this conclusively in practical applications). 

\begin{table}[!ht]
    \centering
    \begin{tabular}{|l|l|l|l|l|l|}
    \hline
        \textbf{} & \textbf{ANMg} & \textbf{ANMs} & \textbf{MNs} & \textbf{LSg} & \textbf{LSs} \\ \hline
        \textbf{Our CPCM} & {100} & 97 & 95 & {99} & {98} \\ \hline
        \textbf{LOCI} & {100} & {100} & {99} & 91 & 85 \\ \hline
        \textbf{HECI} & {99} & 43 & 29 & 96 & 54 \\ \hline
        \textbf{RESIT} & {100} & {100} & 39 & 51 & 11 \\ \hline
        \textbf{bQCD} & {100} & 79 & {99} & {100} & 98 \\ \hline
        \textbf{IGCI (Gauss)} & {100} & {99} & {99} & 97 & {100} \\ \hline
        \textbf{IGCI (Unif)} & 31 & 35 & 12 & 36 & 28 \\ \hline
        \textbf{Slope} & 22 & 25 & 9 & 12 & 15 \\ \hline
    \end{tabular}
    \caption{Accuracy of different estimators on simulated Gaussian datasets. ANM represents additive models, MN represents multiplicative, and LS represents location-scale models. The difference between ANMg and ANMs (LSg, LSs) is how the functions $\mu$ and $\sigma$ are generated. Analogous results (without the first row) can also be found in \cite{Natasa_Tagasovska} and \cite{immer2022identifiability}, with several other estimators from the literature. }
    \label{Table_Simulated_data_Gaussian}
\end{table}



\subsection{Robustness against a misspecification of F}
%add alpha definiton
Consider $X_1\to X_2$, where $X_1\sim N(2,1)^+$, \footnote{$N(2,1)^+$ denotes the truncated Gaussian distribution on $\{x>0\}$. Therefore, $X_1>0$, with a mean of approximately $2.07$.} and let
\begin{equation}\label{eq9870p}
    X_2\mid X_1\sim Exp\big(\alpha(X_1)\big),
\end{equation}
where $\alpha$ is a non-negative function. In other words, we generate $X_2$ according to (\ref{BCPCM}), with $F$ being an exponential distribution function. Recall that the exponential distribution is a special case of Gamma distribution with a fixed shape parameter. 

The goal of this simulation is to ascertain how the choice of $F$ affects the resulting estimate of the causal graph. We consider five different choices for $F$: Gamma with fixed scale, Gamma (with two parameters as in Consequence \ref{consequenceprva}), Pareto, Gaussian with fixed variance, and Gaussian (with two parameters as in Example \ref{Gaussian case}). 


We generate $n=500$ variables, according to (\ref{eq9870p}), with different functions, $\alpha$. Then, we apply the CPCM algorithm with different choices of $F$. Table \ref{table_simulations_about_misspecified_F} presents the percentage of correctly estimated causal graphs (an average out of 100 repetitions). 
The results remain more or less good for $F$ that are ``similar'' to the exponential distribution, with respect to the density and support. However, if we select the Gaussian distribution (a uni-modal distribution with different support), our methodology often provides wrong estimates. 

\begin{table}[tbh]
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
  F       & $\alpha(x) = x$ & $\alpha(x) = x^2+1$  & $\alpha(x) = \frac{e^x}{2}$ & Random $\alpha$ \\ \hline
Gamma (fixed scale)   & $93$           & $95$                                & $97$                       & $92$      \\ \hline 
Gamma (two parameters)  & $82$           & $86$                               & $76$                       & $92$           \\ \hline
Pareto    & $99$           & $100$             & $99$                                   & $97$           \\ \hline
Gaussian (fixed variance) & $0$           & $0$                               & $0$                       & $9$           \\ \hline
Gaussian (two parameters) & $16$           & $25$                           & $33$                       & $41$           \\ \hline
\end{tabular}
\caption{Comparison of the accuracy of CPCM estimations for different choices of $F$. Random $\alpha$ represents a function generated using Gaussian processes, which is similar to Simulations \ref{Section_simulations_Gaussian}.}
\label{table_simulations_about_misspecified_F}
\end{table}











