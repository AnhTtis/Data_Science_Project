\section{Inference}
\label{Section5}

\subsection{ CPCM algorithm - bivariate case   }
\label{Section_Algorithm}

Our CPCM methodology is based on selecting an appropriate causal model (in our case, the choice of collection $\{F_1, \dots, F_k\}$) and a measure of a model fit. In the following subsections, we measure the model fit by exploiting the principle of independence between the cause and the mechanism. 


We say that a DAG $\mathcal{G}$ is \textbf{plausible} under $CPCM(F)$ model if the joint distribution \textit{can} be generated via $CPCM(F)$ model with graph $\mathcal{G}$. The Algorithm~\ref{Algorithm1} describes the main steps to test the plausibility and estimation of $\mathcal{G}$ in the bivariate case. 

\begin{algorithm}[]
  \SetAlgoLined
  \KwData{ Random sample $(x_{1,1}, x_{2,1})^\top, \dots, (x_{1,n}, x_{2,n})^\top$}
  \KwResult{Estimate $\hat{\mathcal{G}}$ and plausibility of graphs $X_1\to X_2$ and $X_2\to X_1$}
\textbf{Step 0) }Test independence between $X_1$ and $X_2$. 

\textbf{Step 1) } Determine plausibility of   $X_1\to X_2$ using the following: 

  
  \hspace{0.3cm}\textbf{1a)} Estimate $\theta(X_1)$ in $X_2 = F^{-1}(\varepsilon_2; \theta(X_1))$; compute $\hat{\varepsilon}_2 := F(X_2; \hat{\theta}(X_1))$.
  
  \hspace{0.3cm}\textbf{1b)} Test independence between $\hat{\varepsilon}_2$ and $X_1$. If the p-value is larger than $\alpha=0.05$, mark $X_1 \to X_2$ as \textit{plausible}.

  \textbf{Step 2:} Repeat Step 1 for $X_2 \to X_1$.

\textbf{Forced estimate}  (Choose the direction with the higher residual independence):  Return $X_1 \to X_2$ if $\text{p-value}(\hat{\varepsilon}_2, X_1) > \text{p-value}(\hat{\varepsilon}_1, X_2)$, else return $X_2 \to X_1$.

\textbf{Conservative Estimate:}  
\begin{itemize}
 \setlength{\itemsep}{0pt} % Reduce space between items
    \setlength{\parskip}{0pt} % Reduce space between paragraphs
    \item If Step 0 fails to reject independence, return $\hat{\mathcal{G}} = \emptyset$.
    \item If exactly one of the two graph directions is plausible, return it as $\hat{\mathcal{G}}$.
    \item If both directions are plausible, return \texttt{"Unidentifiable case"}.
    \item If neither is plausible, return \texttt{"Assumptions not fulfilled"}.
\end{itemize}

  \caption{CPCM(F)}
  \label{Algorithm1}
\end{algorithm}


An estimation of ${\theta}(X_1)$ in Step 1a) is discussed in detail in Appendix~\ref{Appendix_consistency}. It can be performed using any suitable machine learning method, such as GAM, GAMLSS, random forests, or neural networks \citep{GAM, GAMLSS}. For the independence test in Step 1b), one may use the HSIC test (kernel-based Hilbert–Schmidt independence criterion; \cite{Kernel_based_tests}) or a copula-based test \citep{copula_based_independence_test}.


The conservative estimate $\hat{\mathcal{G}}$ helps guard against unfulfilled assumptions or unidentifiable cases. If it returns ``Assumptions not fulfilled,'' it means that we were unable to fit the $CPCM(F)$ model in either direction, suggesting that the variables do not follow the $CPCM(F)$ model.  In this case, one should consider increasing the complexity (i.e., the number of parameters) of $F$. This is discussed further in Section~\ref{Section5Model_choice}. 

If it returns ``Unidentifiable case,'' this means that we were able to fit the $CPCM(F)$ model in both directions. This could indicate that the sample size is too small or that we are in an unfortunate unidentifiable case, such as the one described in Consequence~\ref{consequenceprva}.  In this case, one should consider decreasing the complexity (i.e., the number of parameters) of $F$.

While the warnings from the conservative estimate  $\hat{\mathcal{G}}$  are useful, we often require a single estimate of $\hat{\mathcal{G}}$  for comparison with other benchmark methods. 

\subsubsection{Extension to $CPCM(F_1, \dots, F_k)$}
The following adjustment to Step 1 in Algorithm~\ref{Algorithm1} can be applied to accommodate the \(CPCM(F_1, \dots, F_k)\) model, given a collection \(\{F_1, \dots, F_k\}\).


\begin{algorithm*}[H]
  \SetAlgoLined
$\boldsymbol{CPCM(F_1, \dots, F_k)}$

    \textbf{Step 1) } Determine plausibility of   $X_1\to X_2$ using the following: 

\textbf{$\,\,\,\,\,\,$Step 1a) } Estimate the set $S:=\{j\in \{1, \dots, k\}: supp(F_j) = supp(X_2)\}$. If empty, return ``STOP: Inappropriate choice of $F$''. 

\textbf{$\,\,\,\,\,\,$Step 1b) } For all  $j\in \hat{S}$,  estimate $\theta(X_1)$ in a model $X_2 = F_j\big(\varepsilon_2; \theta(X_1)\big)$,  and compute probability transform $\hat{\varepsilon}_2^j := F_j\big(X_2; \hat{\theta}(X_1)\big)$.  

\textbf{$\,\,\,\,\,\,$Step 1c)} Compute the p-value of an independence test between $\hat{\varepsilon}_2^j$ and $X_1$ for all $j\in\hat{S}$. Choose the largest p-value. Direction $X_1\to X_2$ is marked as \textit{plausible} if this p-value is larger than  $\alpha=0.05$. 

%  \caption{Modification of Step 1 in Algorithm~\ref{Algorithm1} accounting for $CPCM(F_1, \dots, F_k)$}
%  \label{Algorithm2}
\end{algorithm*}

By estimating the set $S$ in Step 1a), we can  preliminarily filter out the $F_j$ choices that are evidently unsuitable, such as fitting Gaussian model when the data are discrete. We can apply a simple heuristic under the assumption that \( \text{supp}(X_2) \) and \( \text{supp}(F_j) \) for all \( j \) are one of the following: 1) \(\mathbb{R}\) (Gaussian), 2) \(\mathbb{R}^+\) (Gamma), 3) \([0,1]\) (Beta), or 4) \(\mathbb{N}\)(Poisson). The heuristic is as follows: if the number of unique values in \( (x_{2,1}, \dots, x_{2,n}) \) is fewer than \( n/10 \) and the values lie in $\mathbb{N}$, we set \( \text{supp}(X_2) = \mathbb{N} \). Otherwise, if all values lie within \([0,1]\), we set \( \text{supp}(X_2) = [0,1] \). To distinguish between \(\mathbb{R}\) and \(\mathbb{R}^+\), we use the skewness of the distribution: if the skewness is close to 0, the distribution resembles a Gaussian distribution, so we set \( \text{supp}(X_2) = \mathbb{R} \). Otherwise, the distribution resembles a Gamma distribution, so we set \( \text{supp}(X_2) = \mathbb{R}^+ \).





\subsection{Multivariate case: $CPCM(F)$ as a score-based DAG optimization
\label{Section_score_based_algorithm}
}
The forced estimate of $\mathcal{G}$ in Algorithm~\ref{Algorithm1} can be seen as a score-based algorithm; defining the score of a graph as a p-value of the corresponding independence test, we simply compare the scores of graphs $X_1\to X_2$ and $X_2\to X_1$. In the following, we formalize this idea, leading to generalizing the CPCM inference to multivariate case. 

Following the ideas of \cite{Bregmans_information, Score-based_causal_learning, Peters2014}, we use the following penalized independence score: 
\begin{equation}\label{score_definition1}
\hat{\mathcal{G}} =  \argmin_{\mathcal{G}\in DAG(d)}s(\mathcal{G}) = \argmin_{\mathcal{G}\in DAG(d)}\rho (\hat{\varepsilon}_1, \dots, \hat{\varepsilon}_d) + \lambda (\text{Number of edges in }\mathcal{G}),
\end{equation}
where $\rho$ represents some measure of independence, $\lambda$ is a hyperparameter, $DAG(d)$ is the set of all DAGs over $V=\{1, \dots, d\}$ and $\hat{\varepsilon}_1, \dots, \hat{\varepsilon}_d$ are noise estimators obtained by estimating ${\theta}_i(\textbf{X}_{pa_i(\mathcal{G})})$ and putting $\hat{\varepsilon}_i := F\big(X_i; \hat{\theta}_i(\textbf{X}_{pa_i(\mathcal{G})})\big)$ analogously to Algorithm~\ref{Algorithm1}. 

With regard to choice of $\rho$, we use minus the logarithm of the p-value of the independence test \citep{copula_based_independence_test} and $\lambda = 2$. These choices appear to work well in practice, but we do not provide any theoretical justification of their optimality.

Analogously to the bivariate case, we can define that a DAG ${\mathcal{G}}$ is \textbf{plausible} if the p-value of the corresponding independence test between $(\hat{\varepsilon}_1, \dots, \hat{\varepsilon}_d)$ is larger than level $\alpha\in (0,1)$. If every ${\mathcal{G}}\in DAG(d)$ is not plausible, it suggests that the variables do not follow the $CPCM(F)$ model. In this case, one should consider increasing the complexity (i.e., the number of parameters) of $F$; this is discussed in more detail in Section~\ref{S1_or_S2}. On the contrary to the bivariate case, many DAGs can be plausible in an identifiable $CPCM(F)$ model. In particular, if a true causal graph $\mathcal{G}$ is plausible, than any $\tilde{\mathcal{G}}\supseteq \mathcal{G}$ should be plausible. 

 It is important to note that in a bivariate case, score based estimate \eqref{score_definition1} is equal to the forced output of Algorithm~\ref{Algorithm1}, given $\lambda = -\infty$.



\subsubsection{$CPCM(F_1,\dots, F_k)$ extension
}
Similarly to the extension of Algorithm~\ref{Algorithm1}, the following adjustment can be applied to accommodate the \(CPCM(F_1, \dots, F_k)\) model, given a collection \(\{F_1, \dots, F_k\}\):

\begin{equation}
\label{multi_extention}
s(\mathcal{G}) = \min_{j_1\in \hat{S}_1, \dots, j_d\in \hat{S}_d}\rho (\hat{\varepsilon}_1^{j_i}, \dots, \hat{\varepsilon}_d^{j_d}) + \lambda (\text{Number of edges in }\mathcal{G}),
\end{equation}
where $\hat{S}_i$ are estimates of $S_i:= \{ j\in\{1, \dots, k\}: supp(X_i) = supp(F_j) \}$, and $\hat{\varepsilon}_i^{j_i} := F_{j_i}\big(X_i; \hat{\theta}_i(\textbf{X}_{pa_i(\mathcal{G})})\big)$. If $supp(F_i) \neq supp(F_j)$ for all $i\neq j$, we end up with a single evaluation of the score function for each possible $\mathcal{G}$. 



\subsubsection{Consistency}

\cite{reviewANMMooij} demonstrates consistency of a causal discovery algorithm in ANMs.  We establish an analogous result for $CPCM(F_1, \dots, F_k)$.


\begin{proposition}
\label{consistency_proposition}
Let $(X_1, X_2)$ follow an identifiable  $CPCM(F_1, \dots, F_k)$ with DAG $\mathcal{G}$. Then, our score based algorithm presented in Section~\ref{Section_score_based_algorithm} is consistent, meaning that
$$\hat{\mathcal{G}} \overset{P}{\to}\mathcal{G}\,\,\,as\,\,n\to\infty,$$
given that we employ a ``suitable'' estimation procedure for the estimation $\hat{\varepsilon}_i$, we use HSIC score as our choice of $\rho$ and consistent estimators $\hat{S}_i$ (for definitions, proof and more details, see  Appendix~\ref{Appendix_consistency}). 
\end{proposition}

\subsubsection{Scalability and greedy algorithms for larger dimensions}
\label{section_scalability}
The main disadvantage of the proposed method is that we have to go through all graphs $\mathcal{G}\in DAG(d)$, which is possible only for very small $d$. However, even though graph learning is typically NP-hard \citep{NP-hard_score_based_causal_learning}, numerous algorithms have been proposed to speed up the process \citep{Bregmans_information, Greedy_search, Ramsey2016, Nandy2018, Silander2006}. 

For example, the \textbf{naive-edge-greedy} search algorithm \citep{Greedy_search} begins with an empty DAG and iteratively explores neighboring graphs by adding or removing a single edge. Each candidate DAG is evaluated using the CPCM score function \eqref{score_definition1}, and the graph with the lowest score is selected. If this best candidate improves upon the current graph, it replaces it and the process repeats. The algorithm terminates when no further improvements are possible.

Another example is \textbf{RESIT} (Regression with Subsequent Independence Test) algorithm, a polynomial-time procedure that first estimates a topological ordering and then prunes superfluous edges via independence tests \citep{Peters2014}.  This method can be naturally adapted for the CPCM framework (Algorithm~\ref{alg:resit} in Appendix~\ref{appendix_greedy_definitions}) and comes with theoretical guarantees for large-sample consistency (Lemma~\ref{thm:resit_consistency} in Appendix~\ref{appendix_greedy_definitions}). Despite its computational efficiency and theoretical backing, RESIT tends to perform poorly in high-dimensional settings. Errors made in the early stages of ordering propagate downstream, and false positives in Phase 2 lead to persistent spurious edges in the final output.

To combine the strengths of both approaches, we propose a hybrid \textbf{RESIT-greedy} algorithm that combines Phase 1 of RESIT with the edge-pruning strategy of the greedy search  (Algorithm~\ref{alg:resit_greedy} in Appendix~\ref{appendix_greedy_definitions}). In Phase 1, we estimate the topological ordering by iteratively removing the node with the weakest dependence between $\hat{\varepsilon}_i$ and the rest of the variables. The node exhibiting the weakest dependence is removed and appended to the estimated topological order. 
In Phase 2, rather than performing independence tests, we use a greedy edge removal procedure guided by the CPCM score: starting from the fully connected graph (consistent with the estimated ordering), we iteratively remove the edge whose removal yields the largest decrease in the CPCM score, until no further improvement is possible.


In Appendix~\ref{appendix_greedy_definitions}, we compare these algorithms in terms of accuracy and computational time. The results show that the exact method achieves the highest accuracy but is computationally feasible only for small graphs ($d \leq 4$). RESIT and naive-greedy methods are scalable but exhibit limited accuracy, particularly as the number of nodes increases. The RESIT-greedy algorithm strikes a balance: it consistently outperforms both RESIT and naive-greedy in terms of accuracy while maintaining reasonable computational efficiency for moderate dimensions ($d < 10$), making it a practical choice in such cases.

For much larger dimensions, a hybrid approach is recommended: using e.g. PC algorithm to estimate the skeleton and applying the CPCM algorithm only to smaller subgroups of unoriented edges. Similar strategy has been discussed, for example, in \citep{Goudet2017}, though a detailed exploration is beyond the scope of this paper.

\subsection{Choice of the collection $\{F_1, \dots, F_k\}$}
\label{Section5Model_choice}

\subsubsection{Why $\{F_1, \dots, F_k\}$ cannot be chosen in a data-driven way }

Selecting the collection \(\{F_1, \dots, F_k\}\) is a crucial step in our approach. Unfortunately, there is no principled, general data-driven way to select this collection without access to alternative data. As discussed in Section~\ref{motivation_section}, alternative methods such as ANM, QVF, bQCD, or IGCI all predefine the notion of a ``simple'' distribution. This predefinition is necessary; otherwise, Occam's razor loses its meaning. The following lemma formalizes this idea.  

\begin{lemma}\label{lemma_o_overparametrizacii}
Suppose that the joint distribution $F_{(X_1,X_2)}$ is generated according to the model $CPCM(F_2)$ with graph $X_1\to X_2$, where $F_2$ is a distribution function belonging to the exponential family. 

Then, there exists $F_1$ such that the model $CPCM(F_1)$ with graph $X_2\to X_1$ also generates $F_{(X_1,X_2)}$. In other words, there exists $F_1$ such that the causal graph in $CPCM(F_1, F_2)$ is not identifiable from the joint distribution. 
\end{lemma}

The proof (provided in \hyperref[Proof of lemma_o_overparametrizacii]{Appendix} \ref{Proof of lemma_o_overparametrizacii}) is based on the specific choice of $F_{1}$, such that its sufficient statistic is equal to the parameter $\theta_2$ from the original model $CPCM(F_{2})$. 

It is important to note that such an $F_1$ often results in a rather non-standard distribution. While the notion of a ``standard'' distribution is somewhat philosophical, some distributions are objectively considered standard due to physical motivations; for example, the Gaussian (by the central limit theorem) or the Poisson (which arises when counting independent events). This motivates the definition of a ``standard set of well-known distributions,'' which we discuss in Section~\ref{Section_practical_choices}.

\subsubsection{Unfair game issue}

Even if the theory suggests that it is not possible to fit a $CPCM(F_1, \dots, F_k)$ in both causal directions, this is only an asymptotic result and may not hold in practice with finite samples. Overparameterized models may overfit and capture spurious patterns, while underparameterized ones may violate key assumptions. To ensure a fair comparison, we recommend selecting all $F_i$ with the same number of parameters ($q_i = q_j$). For example, choosing $F_1$ with one parameter and $F_2$ with three ($q_1 = 1$, $q_2 = 3$) introduces bias, since the more flexible model is more likely to fit the data regardless of its correctness (unless we are in the asymptotic regime). We refer to this issue as an ``unfair game.'' 

\subsubsection{Practical choices of the set of ``standard well-known distributions''}
\label{Section_practical_choices}

We define nested sets of ``standard set of well-known distributions''; set $\mathscr{S}_1$  containing distributions with one parameter, and a more complex set $\mathscr{S}_2$ containing distributions with two parameters. We do this to avoid the  ``unfair game'' issue. Both sets should be rich enough to contain a wide range of distributions with different supports and characteristics, but should not contain many distributions with the same support in order to avoid unidentifiable setups. 

For practical purposes, we restrict our attention to distributions that are implemented in \texttt{mgcv} package in \texttt{family.mgcv} \citep{Wood}.  These include:
\begin{enumerate}
    \item $\mathscr{S}_1$ consists of  the following one parameter distributions: Gaussian with fixed variance, Poisson, Pareto and Exponential distribution. 
    \item  $\mathscr{S}_2$ consists of  the two parameter following distributions: Gaussian, Negative binomial, Generalized Pareto and Gamma distribution.
\end{enumerate}
These choices are tactically made such that every distribution in the family $\mathscr{S}_1$ is a special case of some distribution in $\mathscr{S}_2$; for example, the Poisson distribution arises as a special (limiting) case of the Negative Binomial distribution \citep[see][p. 96]{CasellaBerger2024}. 

We emphasize that many other choices are possible, and our collections are neither exhaustive nor immutable. They may be adapted for specific applications where alternative distributions could be regarded as “standard.” 
\subsubsection{$\mathscr{S}_1$ or $\mathscr{S}_2$? Sequential approach}
\label{S1_or_S2}
We propose a sequential approach for the selection between \(\mathscr{S}_1\) and \(\mathscr{S}_2\). We first choose the (least complex) set \(\mathscr{S}_1\); if this choice is ``not appropriate'', we then extend the set of distributions to \(\mathscr{S}_1\cup \mathscr{S}_2\). If $\mathscr{S}_1\cup \mathscr{S}_2$ is also ``not appropriate'', we may further extend the model class by introducing $\mathscr{S}_3$: the class of standard three-parameter distributions. This hierarchical selection process incrementally increases the complexity of the conditional distributions until at least one graph is plausible. 

We define that \(\mathscr{S}_1\) is ``not appropriate'' if there does not exist any \textit{plausible} graph $\mathcal{G} \in DAG(d)$ under $CPCM(\mathscr{S}_1)$. More formally, consider the following algorithm: 

\begin{algorithm*}[H]
  \SetAlgoLined
  \SetAlgoNoLine
  \renewcommand{\thealgocf}{}  % removes numbering
    \textbf{Exact version:} For each ${\mathcal{G}} \in \text{DAG}(d)$, infer whether it is plausible under $CPCM(\mathscr{S}_1)$ (as discussed in Section~\ref{Section_score_based_algorithm}). If no graph is plausible, return $\mathscr{S}_1 \cup \mathscr{S}_2$; otherwise, return $\mathscr{S}_1$.\\  
    
    \textbf{Fast version:} Estimate $\hat{\mathcal{G}}$ using the model $CPCM(\mathscr{S}_1)$ (using the score-based algorithm~\eqref{multi_extention}, for instance). If $\hat{\mathcal{G}}$ is not plausible under $CPCM(\mathscr{S}_1)$, return $\mathscr{S}_1\cup \mathscr{S}_2$; otherwise, return~$\mathscr{S}_1$.
  \caption*{Sequential approach for the choice between $\mathscr{S}_1$ and $\mathscr{S}_2$}
\end{algorithm*}
By sequentially expanding \(\mathscr{S}_1\) by \(\mathscr{S}_2\), and potentially by \(\mathscr{S}_3\), we ensure that the simplest adequate model is chosen while avoiding unnecessary complexity and unfair game issue. As an example when our data are continuous uni-modal with full support, consider that a Gaussian model with fixed variance is fitted in both directions $X\to Y$ and $Y\to X$. If both graphs are not \textit{plausible}, we expand the model to location-scale Gaussian model. Potentially, if both directions are again not plausible in this model, we add a shape parameter and consider Generalized Gaussian model \citep{Nadarajah01092005}.  

\begin{consequence}
\label{consequence_consistency}
Let $(X_1, X_2)$ follow an $CPCM(F)$ model with DAG $\mathcal{G}$, for some $F\in\mathscr{S}_1\cup \mathscr{S}_2$. Assume the conditions of Proposition~\ref{consistency_proposition} hold: namely, identifiability of $CPCM(\mathscr{S}_1 \cup \mathscr{S}_2)$, a ``suitable'' estimation procedure, and the use of the HSIC score. Then, our score-based algorithm, with the collection $\{F_1, \dots, F_k\}$ chosen via the Sequential approach (Exact or Fast version), is consistent:
$\hat{\mathcal{G}} \overset{P}{\to}\mathcal{G}$, as $n\to\infty$.
\end{consequence}

In practice, the exact version is feasible only for very small $d$. When employing a greedy or RESIT-greedy search algorithm, we naturally traverse multiple DAG candidates. For each such candidate, we may  assess plausibility, thereby integrating the sequential model expansion directly into the search. This creates a trade-off between the exact and fast versions: while it reduces the exhaustive search cost of the exact method, it still retains some of its thoroughness by evaluating plausibility along the search path. In Appendix~\ref{Simulations_seq_approach} we evaluate the empirical performance of the sequential approach on simulated data. 