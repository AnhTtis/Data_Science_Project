\renewcommand\thesection{B}
\section{Experiments details and additional plots}
\label{Appendix_simulations}

\input{sections/Appendix_2_greedy}


\subsection{Sequential approach vs oracle: empirical performance}
\label{Simulations_seq_approach}
We evaluate the empirical performance of the sequential approach for selecting the distribution family, comparing it to $CPCM(F)$ with access to the true (oracle) distribution $F$. The data is generated as follows:
$$
X_1 \sim \mathcal{N}(0,1), \quad X_2 = F^{-1}(\varepsilon, \theta(X)), \quad \varepsilon \indep X, \; \varepsilon \sim \mathcal{U}(0,1),
$$
where $F \in \mathscr{S}_s$ belongs to either the one-parameter family $\mathscr{S}_1$ or the two-parameter family~$\mathscr{S}_2$.

When $s = 1$, $F$ is, with equal probability ($1/4$), either a Gaussian distribution with fixed variance, a Poisson, Pareto, or Exponential distribution. The parameter is generated as a random function of $X$ via a randomly drawn polynomial. When $s = 2$, $F$ is, again with equal probability, a Gaussian, Negative Binomial, Generalized Pareto, or Gamma distribution, with both parameters generated as random functions of $X$ using random polynomials.

We estimate the graph $\mathcal{G} = {1 \to 2}$ using both $CPCM(\text{Seq.app})$ and $CPCM(F)$ with oracle knowledge of $F$, for various sample sizes $n$, repeating each experiment 100 times for both $s = 1$ and $s = 2$. Figure~\ref{Fig_seq} summarizes the results across sample sizes.

For $s = 1$, we observe that $CPCM(\text{Seq.app})$ typically performs equivalently to oracle $CPCM(F)$ for $n > 100$. For $s = 2$, the sequential approach tends to select the simpler class $\mathscr{S}_1$ instead of the true two-parameter family $\mathscr{S}_2$ at smaller sample sizes. Nevertheless, the performance gap between the sequential approach and the oracle method remains almost negligible.

These results indicate that the sequential approach is performing nearly as well as the oracle $CPCM(F)$, provided that $F \in \mathscr{S}_1 \cup \mathscr{S}_2$.

\begin{figure}[]
\centering
\includegraphics[scale=0.7]{figures/Sequ.appr.pdf}
\caption{Performance of the sequential approach. Left: percentage of simulations where $\hat{\mathcal{G}} = {1 \rightarrow 2}$. Right: percentage of simulations in which $CPCM(\text{Seq.app})$ and $CPCM(F)$ with oracle $F$ are equivalent. }
\label{Fig_seq}
\end{figure}








\subsection{Details about sections~\ref{Section_simulations_Pareto}, \ref{Section_simulations_Gaussian}, \ref{Section_simulations_multivariate} and \ref{Section7}}

\label{Appendix_Section_simulations_Pareto}
The additional plots corresponding to \textbf{Section~\ref{Section_simulations_Pareto}} are presented in Table~\ref{Pareto_simulations1} and Figures~\ref{Pareto_histograms} and Figure~\ref{sample_size_pareto}. Figure~\ref{Simulations2_plots} shows an example of datasets generated via different models from Section~\ref{Section_simulations_Gaussian}.

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[]
\centering
\renewcommand{\arraystretch}{1.15}
\begin{tabular}{l|
                S[table-format=3.0]
                S[table-format=3.0]
                S[table-format=3.0]
                S[table-format=3.0]
                S[table-format=3.0]}
\toprule
\textbf{$\gamma$} &
{$X_1 \to X_2$} &
{$X_2 \to X_1$} &
{\makecell{Empty\\graph}} &
{\makecell{Both directions\\appear plausible}} &
{\makecell{Neither direction\\appears plausible}} \\
\midrule
\rowcolor{RowAlt}
$-2$ & 0  & 0  & \bfseries 96 & 2  & 2  \\
$-1$ & 3  & 2  & 0  & \bfseries 95 & 0  \\
\rowcolor{RowAlt}
\,\,$0$  & 7  & 1  & 0  & \bfseries 92 & 0  \\
\,\,$1$  & 7  & 5  & 0  & \bfseries 86 & 2  \\
\rowcolor{RowAlt}
\,\,$2$  & \bfseries 93 & 0  & 0  & 14 & 3  \\
\bottomrule
\end{tabular}
\caption{Simulation results for the CPCM model using the Pareto distribution function \(F\). The table displays the percentage of cases for each type of graph structure estimated by Conservative Algorithm~\ref{Algorithm1} with the model specified in \eqref{fwesef}, across various values of the hyperparameter \(\gamma \in \mathbb{R}\). The columns indicate the frequency of each graph structure being estimated, with the highest frequency in each row highlighted in bold.}
\label{Pareto_simulations1}
\end{table}


\begin{figure}[]
\centering
\includegraphics[width = 0.8\textwidth]{figures/pareto_histogram.pdf}
\caption{(Simulations~\ref{Section_simulations_Pareto}). Distributions of the p-values from the independence test in Step 1b) of Algorithm~\ref{Algorithm1}, for model \eqref{fwesef} with \(\gamma = 0\) and \(\gamma = 2\).}
\label{Pareto_histograms}
\end{figure}


\begin{figure}[]
\centering
\includegraphics[scale=0.7]{figures/score_based_estimate.pdf}
\caption{(Simulations~\ref{Section_simulations_Pareto}). The plot displays the percentage of correctly estimated causal directions across a range of sample sizes \( n \), using model \eqref{fwesef} with hyperparameters \(\gamma = 1\) and \(\gamma = 2\). As \( n \) increases, the algorithm demonstrates near-perfect performance, affirming the theoretical consistency of the proposed method. }
\label{sample_size_pareto}
\end{figure}




The experiments from \textbf{Simulations~\ref{Section_simulations_Gaussian}} were inspired by \cite{Natasa_Tagasovska} and implementations of other baseline methods are also taken from \cite{Natasa_Tagasovska} and \cite{immer2022identifiability}. 

For LOCI, we use the default format with neural network estimations and subsequent independence testing (also denoted as $NN-LOCI_H$) \citep{immer2022identifiability}.
For IGCI, we use the original implementation from \cite{IGCI} with slope-based estimation with Gaussian and uniform reference measures. For RESIT, we use the implementation from \cite{Peters2014} with GP regression and the HSIC independence test with a threshold value of $0.05$. For the slope algorithm, we use the implementation of \cite{Slope}, with the local regression included in the fitting process. For comparisons with other methods such as PNL, GPI-MML, ANM, Sloppy, GR-AN, EMD, GRCI, see Section 3.2 in \cite{Natasa_Tagasovska} and Section 5 in \cite{immer2022identifiability}. 

In \textbf{Section~\ref{Section_simulations_multivariate}}, the other baseline methods are implemented using the \texttt{pcalg} package \citep{pcalg_package}, employing its default independence test \texttt{gaussCItest} for PC algorithm and GES with the Gaussian observational BIC score, using the default penalty. For ANM-RESIT, for fairness, we use the same choices as in our CPCM method (that is, GAM estimator and HSIC). 

Finally, regarding \textbf{Section~\ref{Section7}},  Table~\ref{tab:edge_share} shows the relative frequencies with which each edge was recovered across repeated subsamples of the motor insurance dataset.


\begin{figure}[]
\centering
\includegraphics[scale=0.4]{figures/sim6.2_sample.png}
\caption{Simulations~\ref{Section_simulations_Gaussian}. An example of datasets generated via different models. }
\label{Simulations2_plots}
\end{figure}



\begin{table}[ht]
\centering
\begin{minipage}{0.45\linewidth}
\centering
\begin{tabular}{lc}
\hline
Edge & Share (\%) \\
\hline
VehAge $\to$ ClaimNb     & 60 \\
Exposure $\to$ ClaimNb   & 48 \\
VehPower $\to$ ClaimNb   & 42 \\
VehPower $\to$ Exposure  & 44 \\
\hline
\end{tabular}
\end{minipage}\hfill
\begin{minipage}{0.45\linewidth}
\centering
\begin{tabular}{lc}
\hline
Edge & Share (\%) \\
\hline
VehAge $\to$ Exposure    & 36 \\
Exposure $\to$ VehAge    & 64 \\
VehPower $\to$ VehAge    & 54 \\
VehAge $\to$ VehPower    & 30 \\
\hline
\end{tabular}
\end{minipage}
\caption{Relative frequency (in \%) with which each directed edge was recovered by CPCM across 50 random subsamples of the French MTPL motor insurance dataset (shown only those with more than $25\%$ share).}
\label{tab:edge_share}
\end{table}









