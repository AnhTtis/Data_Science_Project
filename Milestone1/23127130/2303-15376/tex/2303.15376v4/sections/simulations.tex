
\section{Simulations} \label{simulations_section}
The \texttt{R} code for the presented algorithms, simulations, and application is available at \url{https://github.com/jurobodik/Causal_CPCM.git}.

In this section, we illustrate our methodology under controlled conditions, primarily focusing on the bivariate case. In Section~\ref{Section_simulations_Pareto}, we empirically validate Consequence~\ref{paretoidentifiability} and Proposition~\ref{consistency_proposition}, and show the distribution of the p-values (scores)  in Algorithm~\ref{Algorithm1} corresponding to the different causal graphs. In Section~\ref{Section_simulations_Gaussian}, we compare our methodology with state-of-the-art methods using benchmark datasets. In Section~\ref{Section_simulations_robustness}, we investigate the robustness of our approach against misspecifications of the choice of \(F\) (e.g., when the data are generated with \(F\) being an exponential distribution but we use Gaussian or Pareto \(F\)). In Section~\ref{Section7} we consider an application on real-world data. When conducting tests using Algorithm~\ref{Algorithm1}, we always apply a significance level of \(0.05\).

\subsection{Empirical validation of 
 Consequence  \ref{paretoidentifiability}, Proposition~\ref{consistency_proposition} and p-value distribution in Pareto model}
\label{Section_simulations_Pareto}


Consider the Pareto distribution function $F$, graph $X_1\to X_2$ and let  
\begin{equation}
    \label{fwesef}
     p_{X_1}(x) \propto \frac{1}{ [\log(x)+1] x^{2} },\,\,\,\,\,\,\,\,\,\,\,\,\,\, \theta(x) = x^\alpha\log(x)+1,\,\,\,\,\,\,\,\,\forall x\geq 1,
\end{equation}
where $\alpha\in\mathbb{R}$ is a hyper-parameter and let $X_2$ be generated such that $X_2\mid X_1\sim Pareto(\theta(x))$. 

Consequence \ref{paretoidentifiability} suggests that we should be able to distinguish between the cause and the effect if and only if $\alpha = 0$. Here, $\alpha$ represents the distortion from the unidentifiable case. If $\alpha$ is large, we should be able to identify the correct causal graph. However, for negative $\alpha<0$, then $\theta$ is almost constant (function $\frac{log(x)}{x^{-\alpha}}\approx 0$ on $x\in [1, \infty)$) and $(X_1, X_2)$ are (close to) independent.

For the size of the dataset $n =500$ and  $\alpha \in \{  -2,   1, 0, 1,  2\}$, we simulate data as described above. We apply Algorithm~\ref{Algorithm1} with Pareto distribution function $F$. Note that Algorithm~\ref{Algorithm1} has five possible outcomes: 1) $X_1\indep X_2$, 2) $X_1\to X_2$, 3) $X_2\to X_1$, 4) ``unidentifiable setup'' (both directions appear to be plausible) and 5) ``Assumptions not fulfilled'' (neither direction appears to be plausible). After averaging results from 100 repetitions, we obtain the results described in Table~\ref{Pareto_simulations1}. 

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\multicolumn{1}{|l|}{} &
  \multirow{2}{*}{ $X_1\to X_2$}&
  \multicolumn{1}{l|}{\multirow{2}{*}{$X_2\to X_1$}} &
  \multicolumn{1}{l|}{\multirow{2}{*}{Empty graph}} &
  \multicolumn{1}{l|}{Both directions} &
  \multicolumn{1}{l|}{Neither direction} \\
\multicolumn{1}{|l|}{} &
   &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{} &
  \multicolumn{1}{l|}{appear to be plausbile} &
  \multicolumn{1}{l|}{appears to be plausbile} \\ \hline
$\alpha = -2$& 1  & 1 & \textbf{91}& 6  & 1\\ \hline
$\alpha = -1$& 1  & 3 & 13& \textbf{83}& 0\\ \hline
$\alpha = 0$& 3  & 2 & 0  & \textbf{95}& 0 \\ \hline
$\alpha = 1$& 10 & 0 & 0  & \textbf{90}& 0 \\ \hline
$\alpha = 2$& \textbf{97}& 0 & 0  & 2  & 1\\ \hline
\end{tabular}%
}
\caption{Simulation results for the CPCM model using the Pareto distribution function \(F\). The table displays the percentage of cases for each type of graph structure estimated by Algorithm~\ref{Algorithm1} with the model specified in \eqref{fwesef}, across various values of the hyperparameter \(\alpha \in \mathbb{R}\). The columns indicate the frequency of each graph structure being estimated, with the highest frequency in each row highlighted in bold.}
\label{Pareto_simulations1}
\end{table}

The results align with the theory: if \(\alpha = 0\), we typically estimate both directions to be plausible. If \(\alpha > 0\), we tend to estimate the correct direction \( X_1 \to X_2 \); if \(\alpha < 0\), we tend to estimate an empty graph since \( X_1 \) and \( X_2 \) are (nearly) independent.

Additionally, Figure~\ref{Pareto_histograms} in Appendix~\ref{Appendix_simulations} shows the distributions of the p-values from the independence test in Step 1b) of Algorithm~\ref{Algorithm1}, using data simulated with \(\alpha = 0\) and \(\alpha = 2\). The distribution of the p-values appears roughly uniform on $(0,1)$ in the \(\alpha = 0\) case and in the correct direction \( X \to Y \), while the p-values in the direction \( Y \to X \) are typically close to $0$ in the identifiable setup  $\alpha=2$.

Finally, Figure~\ref{sample_size_pareto} located in Appendix~\ref{Appendix_simulations} shows an empirical validation of the consistency result from Proposition~\ref{consistency_proposition}. For a range of sample sizes \( n \), we generate the dataset using \(\alpha = 1\) and \(\alpha = 2\) as the hyperparameters, and we compute the percentage (out of 100 repetitions) of correctly estimated causal direction. The algorithm appears to achieve near-perfect performance for $n>500$. 


\subsection{The Gaussian case and comparison with baseline methods}
\label{Section_simulations_Gaussian}
We compare our method with LOCI \citep{immer2022identifiability}, HECI  \citep{xu2022inferring}, RESIT \citep{Peters2014},  bQCD \citep{Natasa_Tagasovska}, IGCI with Gaussian and uniform reference measures \citep{IGCI} and Slope \citep{Slope}. Details can be found in  Appendix \ref{Appendix_simulations}.  As in \cite{reviewANMMooij}, we use the accuracy for forced decisions as our evaluation metric. 


We consider seven benchmark datasets, described as follows. In each case, we generate $X_1 \sim N(0, \sqrt{2})$. The first five datasets are taken from \cite{Natasa_Tagasovska} and consist of additive and location-scale Gaussian pairs of the form $X_2 = \mu(X_1) + \sigma(X_1) \varepsilon_2$, where $\varepsilon_2 \sim N(0, 1)$.

\begin{enumerate}
    \item \textbf{LSg (Location-Scale Gaussian)}: Here, $\mu$ and $\sigma$ are nonlinear functions simulated using Gaussian processes with a Gaussian kernel with bandwidth one \citep{Gaussian_processes}.
    \item \textbf{LSs (Location-Scale Sigmoid)}: In this setup, $\mu$ and $\sigma$ are sigmoid functions \citep{BuhlmannCAM}.
    \item \textbf{ANMg (Additive Noise Model)}: Nonlinear additive noise models generated similarly to LSg, but with constant $\sigma(X_1) = \sigma \sim U(1/5, \sqrt{2/5})$.
    \item \textbf{ANMs (Additive Noise Model)}: Nonlinear additive noise models generated similarly to LSs, but with constant $\sigma(X_1) = \sigma \sim U(1/5, \sqrt{2/5})$.
    \item \textbf{MNs (Multiplicative Noise)}: Nonlinear multiplicative noise models generated similarly to LSs, but with $\mu(X_1) = 0$.
\end{enumerate}

In addition to the models from \cite{Natasa_Tagasovska}, we consider two more setups:

\begin{enumerate}
    \setcounter{enumi}{5}
    \item \textbf{POISg (Poisson Model)}: $X_2 \sim \text{Pois}(\lambda(X_1))$, where $\lambda$ is generated using Gaussian processes similar to $\sigma$ in LSg. Note that $X_2$ is discrete, creating error in some methods. 
    \item \textbf{PARg (Pareto Model)}: $X_2 \sim \text{Pareto}(\theta(X_1))$, where $\theta$ is generated using Gaussian processes similar to $\sigma$ in LSg.
\end{enumerate}

For each of the seven setups, we simulate 100 pairs with $n=1000$ data points each. One realisation of each model can be found in Figure \ref{Simulations2_plots} in  Appendix \ref{Appendix_simulations}. 

The results are presented in Table \ref{Table_Simulated_data_Gaussian}. We conclude that our estimator performs well across all datasets, effectively handling the mix of discrete and continuous variables. Under the Gaussian location-scale setups, it provides comparable results to LOCI and bQCD, which are specifically developed for such cases.





\begin{table}[!ht]
    \centering
    \begin{tabular}{|l|l|l|l|l|l|l|l|}
    \hline
        \textbf{} & \textbf{ANMg} & \textbf{ANMs} & \textbf{MNs} & \textbf{LSg} & \textbf{LSs}  & \textbf{POISg}&\textbf{PARg} \\ \hline
        \textbf{Our CPCM} & \textbf{100} & \textbf{97} & \textbf{95} & \textbf{99} & \textbf{98}  & \textbf{90} & \textbf{90} \\ \hline
        \textbf{LOCI} & \textbf{100} & \textbf{100} & \textbf{99} & \textbf{91} & \textbf{85}  & {79}& {0}\\ \hline
        \textbf{HECI} & \textbf{98}& \textbf{43} & \textbf{29} & \textbf{96} & \textbf{54}  & {-}& {100}\\ \hline
        \textbf{RESIT} & \textbf{100} & \textbf{100} & {39}& {51}& {11}& 0& {12}\\ \hline
        \textbf{bQCD} & \textbf{100} & \textbf{79} & \textbf{99} & \textbf{100} & \textbf{98}  & {97}& {34}\\ \hline
        \textbf{IGCI (Gauss)} & {100} & {99} & {99} & {97}& {100}& 0 & 0 \\ \hline
        \textbf{IGCI (Unif)} & 31 & 35 & 12 & 36 & 28  & 0 & 100 \\ \hline
        \textbf{Slope} & 22 & 25 & 9 & 12 & 15  & 0 & 100 \\ \hline
    \end{tabular}
    \caption{Accuracy of different estimators on simulated Gaussian datasets. Similar results (excluding the first row and the last two columns) can also be found in \cite{immer2022identifiability}. Bold entries indicate cases where we expect high accuracy because the data-generating mechanism aligns with the methodâ€™s modeling assumptions. }
    \label{Table_Simulated_data_Gaussian}
\end{table}


\subsection{Robustness against a misspecification of F}
\label{Section_simulations_robustness}
Consider $X_1\to X_2$, where $X_1\sim N(2,1)^+$, \footnote{$N(2,1)^+$ denotes the truncated Gaussian distribution on $\{x>0\}$. Therefore, $X_1>0$, with a mean of approximately $2.07$.} and let
\begin{equation}\label{eq9870p}
    X_2\mid X_1\sim Exp\big(\alpha(X_1)\big),
\end{equation}
where $\alpha$ is a non-negative function. In other words, we generate $X_2$ according to (\ref{BCPCM}), with $F$ being an exponential distribution function. Recall that the exponential distribution is a special case of Gamma distribution with a fixed shape parameter. 

The goal of this simulation is to ascertain how the choice of $F$ affects the resulting estimate of the causal graph. We consider five different choices for $F$: Gamma with fixed scale, Gamma (with two parameters as in Consequence \ref{consequenceprva}), Pareto, Gaussian with fixed variance, and Gaussian (with two parameters as in Example \ref{Gaussian case}). 


We generate $n=500$ data-points according to (\ref{eq9870p}). Then, we apply the score-based $CPCM(F)$ algorithm with different choices of $F$. Table \ref{table_simulations_about_misspecified_F} presents the percentage of correctly estimated causal graphs (an average out of 100 repetitions). 
The results remain relatively robust for distributions \( F \) that are ``similar'' to the exponential distribution in terms of density and support. However, when \( F=Gaussian\) (a unimodal distribution with different support), our methodology often yields inaccurate estimates. One might question why \( F = \text{Gamma} \), despite being the correctly specified conditional distribution, does not produce the best results. The reason is over-parameterization. With a sample size of only \( n = 500 \), the direction \( X_2 \to X_1 \) is often well-fitted with two parameters. Moreover, if we choose a distribution with three parameters, the accuracy would be close to $50\%$, akin to a coin toss. This demonstrates the importance of the number of parameters in the model.


\begin{table}[tbh]
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
  F       & $\alpha(x) = x$ & $\alpha(x) = x^2+1$  & $\alpha(x) = \frac{e^x}{2}$ & Random $\alpha$ \\ \hline
Gamma (fixed scale)   & $93$           & $95$                                & $97$                       & $92$      \\ \hline 
Gamma (two parameters)  & $82$           & $86$                               & $76$                       & $92$           \\ \hline
Pareto    & $99$           & $100$             & $99$                                   & $97$           \\ \hline
Gaussian (fixed variance) & $0$           & $0$                               & $0$                       & $9$           \\ \hline
Gaussian (two parameters) & $16$           & $25$                           & $33$                       & $41$           \\ \hline
\end{tabular}
\caption{Comparison of the accuracy of CPCM estimations for different choices of $F$. Random $\alpha$ represents a function generated using Gaussian processes, which is similar to Simulations \ref{Section_simulations_Gaussian}.}
\label{table_simulations_about_misspecified_F}
\end{table}







