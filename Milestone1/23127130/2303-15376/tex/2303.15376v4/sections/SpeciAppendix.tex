\section{Exponential family}
\label{appendix_exponential_family}

The exponential family is a set of probability distributions whose probability density function can be expressed in the following form:
\begin{equation}\label{Exponential family of distributions}
f(x;\theta) = h_1(x)h_2(\theta)\exp\big[\sum_{i=1}^q\theta_iT_i(x)\big],
\end{equation}
where $h_1, T_i$ are real functions and $h_2:\mathbb{R}^q\to\mathbb{R}^+$ is a vector-valued function. We call $T_i$ a \textit{sufficient} statistic, $h_1$ a base measure, and $h_2$ a normalizing (or partition) function.  

Often, form (\ref{Exponential family of distributions}) is called a canonical form and $$f(x;\theta) = h_1(x)h_2(\theta)\exp\big[\sum_{i=1}^qh_{3,i}(\theta)T_i(x)\big],$$ where  $h_{3,i}:\mathbb{R}^q\to\mathbb{R}, i=1, \dots, q$, is called its \textit{reparametrization} (natural parameters are a specific form of the reparametrization). We always work only with a canonical form (attention for Gaussian distribution, where the standard form is not in the canonical form). 

Numerous important distributions lie in the exponential family of distributions, such as Gaussian, Pareto (with fixed support), log-normal, Poisson, Binomial, Gamma, and Beta distributions, to name a few. 

It is important to note that functions in (\ref{Exponential family of distributions}) are \textit{not} uniquely defined. For example, $T_i$ is unique up to a linear transformation. 

The support of $f$ is fixed and does not depend on $\theta$. Potentially, $T_i$ and $h_1$ do not have to be defined outside of this support; however, we typically overlook this fact (or possibly define $h_1(x) = T_i(x) = 0$ for $x$ where these functions are not defined). We additionally assume that the support is nontrivial in the sense that it contains at least two distinct values.

Without loss of generality, we always assume that $q$ is minimal in the sense that we cannot write $f(x;\theta)$ using only $q-1$ parameters. Then, $T_1, \dots, T_q$ are linearly independent in the following sense: there exists $x_1, \dots, x_q\in supp(f)$, such that  matrix 
\begin{equation}\label{eq2431087}
\begin{pmatrix}
T_{1}(x_1) & \cdots & T_{{q}}(x_1) \\
\cdots & \cdots & \cdots \\
T_{1}(x_q) & \cdots & T_{{q}}(x_{q}) 
\end{pmatrix} 
\end{equation}
has full rank. Moreover, $T_1, \dots, T_q$ are affinly independent in the following sense: there exists $y_0, y_1, \dots, y_q\in supp(f)$, such that a matrix 
\begin{equation}\label{eq145151}
\begin{pmatrix}
T_{1}(y_1) - T_1(y_0) & \cdots & T_{{q}}(y_1) -T_q(y_0)\\
\cdots & \cdots & \cdots \\
T_{1}(y_q) -T_1(y_0) & \cdots & T_{{q}}(y_{q}) -T_q(y_0)
\end{pmatrix} 
\end{equation}
has full rank. In this paper (particularly in Lemma \ref{PomocnaLemma1}), we assume that  $T_1, \dots, T_q$ are affinly independent (i.e., satisfy (\ref{eq145151})). 

Since the notions of  linear and affine independence are nonstandard, consider the following example. Say  $T_1(x) = x, T_2(x) = x^2$ (sufficient statistics in Gaussian distribution). Then, matrices (\ref{eq2431087}) and (\ref{eq145151}) are
\begin{equation*}
M_1=\begin{pmatrix}
x_1 &  x_1^2\\
x_2  & x_{2}^2
\end{pmatrix} , \,\,\,\,
M_2=\begin{pmatrix}
y_1-y_0 &  y_1^2 -y_0^2\\
y_2 -y_0 &  y_2^2 -y_0^2
\end{pmatrix} ,
\end{equation*}
which are full ranked for a choice $(x_1, x_2) = (1,2)$ and $(y_0, y_1, y_2) = (0,1,2)$, for example. 




