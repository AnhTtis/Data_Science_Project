\section{Inference}
\label{Section5}

\subsection{Algorithm for CPCM using independence testing}
\label{Section_Algorithm}
Our CPCM methodology is based on selecting an appropriate causal model (in our case, the choice of collection $\{F_1, \dots, F_k\}$) and a measure of a model fit. In the following subsections, we measure the model fit by exploiting the principle of independence between the cause and the mechanism. 


A causal graph is said to be \textbf{plausible} under $CPCM(F)$ model if the joint distribution \textit{can} be generated via $CPCM(F)$ model with such a graph. The Algorithm~\ref{Algorithm1} describes the main steps to test the plausibility. 

\begin{algorithm}[H]
  \SetAlgoLined
  \KwData{ Random sample $(x_{1,1}, x_{2,1})^\top, \dots, (x_{1,n}, x_{2,n})^\top$}
  \KwResult{ Plausibility of a graphs $X_1\to X_2$, $X_2\to X_1$ and an estimate of $\mathcal{G}$}
\textbf{Step 0) }Test for independence between $X_1$ and $X_2$. If not rejected, return an empty graph.

\textbf{Step 1) } Determine plausibility of   $X_1\to X_2$ using the following: 


\textbf{$\,\,\,\,\,\,$Step 1a)} Estimate $\theta(X_1)$ in the model $X_2 = F\big(\varepsilon_2; \theta(X_1)\big)$ and compute probability transform $\hat{\varepsilon}_2 := F\big(X_1; \hat{\theta}(X_1)\big)$ 

\textbf{$\,\,\,\,\,\,$Step 1b)} Test an independence between $\hat{\varepsilon}_2$ and $X_1$ on level $\alpha$. Direction $X_1\to X_2$ is marked as \textit{plausible}  if the test is not rejected. 

\textbf{Step 2) }  Repeat for the other direction $X_2\to X_1$. 

\textbf{Estimate of $\mathcal{G}$: }  If one direction is plausible and the other is not, the former is the final estimate. If both directions are plausible, return ``insufficient data or unidentifiable setup''. If both directions are not plausible, return ``Assumptions not fulfilled''. 
  \caption{CPCM(F)}
  \label{Algorithm1}
\end{algorithm}

An estimation of $\hat{\theta}(X_1)$ in the Step 1a) can be done using any machine learning algorithm, such as GAM, GAMLSS, random forest, or neural networks \citep{GAM, GAMLSS}. For the independence test in in  Step 1b), we can use a HSIC test (kernel-based Hilbert-Schmidt independence test, \cite{Kernel_based_tests}) or a copula-based test \citep{copula_based_independence_test}. 

Generalizing Algorithm~\ref{Algorithm1} for $d$ variables is straightforward. For each $\mathcal{G}\in DAG(d)$, we estimate  $\hat{\theta}_i(\textbf{X}_{pa_i(\mathcal{G})})$ for all $i = 1, \dots, d$ and compute the probability transform $\hat{\varepsilon}_i:= F\big(X_i; \hat{\theta}_i(\textbf{X}_{pa_i(\mathcal{G})})\big)$. Then, we can test independence between  $\hat{\varepsilon}_1, \dots, \hat{\varepsilon}_d$ and conclude that $\mathcal{G}$ is plausible if this test is not rejected. However, even if the causal graph is identifiable, multiple graphs often remain plausible for finite sample sizes unless $n$ is very large. In Section~\ref{Section_score_based_algorithm}, we introduce the score-based algorithm, which selects the ``best'' causal graph even when many plausible graphs exist.

The following adjustment to Step 1 in Algorithm~\ref{Algorithm1} can be applied to accommodate the \(CPCM(F_1, \dots, F_k)\) model, given a collection \(\{F_1, \dots, F_k\}\).


\begin{algorithm*}[H]
  \SetAlgoLined
\textbf{Step 1) } Determine plausibility of   $X_1\to X_2$ using the following: 

\textbf{$\,\,\,\,\,\,$Step 1a) } Estimate the set $S:=\{j\in \{1, \dots, k\}: supp(F_j) = supp(X_2)\}$. If empty, return ``Inappropriate choice of $F$''. 

\textbf{$\,\,\,\,\,\,$Step 1b) } For all  $j\in \hat{S}$,  estimate $\theta(X_1)$ in a model $X_2 = F_j\big(\varepsilon_2; \theta(X_1)\big)$,  and compute probability transform $\hat{\varepsilon}_2^j := F_j\big(X_2; \hat{\theta}(X_1)\big)$.  

\textbf{$\,\,\,\,\,\,$Step 1c)} Test an independence between $\hat{\varepsilon}_2^j$ and $X_1$ for all $j\in\hat{S}$. Direction $X_1\to X_2$ is marked as \textit{plausible}  if this test is not rejected for at least one $j\in \hat{S}$. 

%  \caption{Modification of Step 1 in Algorithm~\ref{Algorithm1} accounting for $CPCM(F_1, \dots, F_k)$}
%  \label{Algorithm2}
\end{algorithm*}

By estimating the set $S$ in Step 1a), we can  preliminarily filter out the $F_j$ choices that are evidently unsuitable. We can apply a simple heuristic under the assumption that \( \text{supp}(X_2) \) and \( \text{supp}(F_j) \) for all \( j \) are one of the following: 1) \(\mathbb{R}\) (Gaussian), 2) \(\mathbb{R}^+\) (Gamma), 3) \([0,1]\) (Beta), or 4) \(\mathbb{N}\)(Poisson). The heuristic is as follows: if the number of unique values in \( (x_{2,1}, \dots, x_{2,n}) \) is fewer than \( n/10 \) and the values lie in $\mathbb{N}$, we set \( \text{supp}(X_2) = \mathbb{N} \). Otherwise, if all values lie within \([0,1]\), we set \( \text{supp}(X_2) = [0,1] \). To distinguish between \(\mathbb{R}\) and \(\mathbb{R}^+\), we use the skewness of the distribution: if the skewness is close to 0, the distribution resembles a Gaussian distribution, so we set \( \text{supp}(X_2) = \mathbb{R} \). Otherwise, the distribution resembles a Gamma distribution, so we set \( \text{supp}(X_2) = \mathbb{R}^+ \).











\subsection{Score-based algorithm for CPCM(F) }
\label{Section_score_based_algorithm}
Algorithm~\ref{Algorithm1} does not always provide an output. The possibility of rejecting the independence test in all directions can be considered a safety net, thereby shielding us against unfulfilled assumptions or unidentifiable cases. Nevertheless, we may still want to obtain an estimation of the graph. 

Following the ideas of \cite{Score-based_causal_learning} and \cite{Peters2014}, we use the following penalized independence score: 
\begin{equation*}
\hat{\mathcal{G}} =  \argmin_{\mathcal{G}\in DAG(d)}s(\mathcal{G}) = \argmin_{\mathcal{G}\in DAG(d)}\rho (\hat{\varepsilon}_1, \dots, \hat{\varepsilon}_d) + \lambda (\text{Number of edges in }\mathcal{G}),
\end{equation*}
where $\rho$ represents some measure of independence, and $\hat{\varepsilon}_1, \dots, \hat{\varepsilon}_d$ are noise estimations obtained by estimating $\hat{\theta}_i(\textbf{X}_{pa_i(\mathcal{G})})$ and putting $\hat{\varepsilon}_i := F\big(X_i; \hat{\theta}_i(\textbf{X}_{pa_i(\mathcal{G})})\big)$ such as in Algorithm~\ref{Algorithm1}. 

With regard to choice of $\rho$, we use minus the logarithm of the p-value of the copula-based independence test \citep{copula_based_independence_test} and $\lambda = 2$. These choices appear to work well in practice, but we do not provide any theoretical justification of their optimality.

The main disadvantage of the proposed method is that we have to go through all graphs $\mathcal{G}\in DAG(d)$, which is possible only for small $d$, since the number of DAGs grows superexponentially with dimension $d$ \citep{NP-hard_score_based_causal_learning}. Several modifications can be used in order to speed up the process. In this regard, greedy algorithms have been proposed \citep{Greedy_search, Bregmans_information}; however, this is beyond the scope of this paper. 

\subsubsection{$CPCM(F_1,\dots, F_k)$ extension and consistency
}
Similarly to the extension of Algorithm~\ref{Algorithm1}, the following adjustment can be applied to accommodate the \(CPCM(F_1, \dots, F_k)\) model, given a collection \(\{F_1, \dots, F_k\}\):

\begin{equation*}
s(\mathcal{G}) = \min_{j_1\in \hat{S}_1, \dots, j_d\in \hat{S}_d}\rho (\hat{\varepsilon}_1^{j_i}, \dots, \hat{\varepsilon}_d^{j_d}) + \lambda (\text{Number of edges in }\mathcal{G}),
\end{equation*}
where $\hat{S}_i$ are estimates of $S_i:= \{ j\in\{1, \dots, k\}: supp(X_i) = supp(F_j) \}$, and $\hat{\varepsilon}_i^{j_i} := F_{j_i}\big(X_i; \hat{\theta}_i(\textbf{X}_{pa_i(\mathcal{G})})\big)$. If $supp(F_i) \neq supp(F_j)$ for all $i\neq j$, we end up with a single evaluation of the score function for each possible $\mathcal{G}$. 

\cite{reviewANMMooij} demonstrates that if $(X_1, X_2)$ follows a bivariate additive noise model, the ANM algorithm consistently estimates the causal direction between $X_1$ and $X_2$. We establish an analogous result for $CPCM(F_1, \dots, F_k)$.


\begin{proposition}
\label{consistency_proposition}
Let $(X_1, X_2)$ follow an identifiable  $CPCM(F_1, \dots, F_k)$ with DAG $\mathcal{G}$. Then, our score based algorithm presented in Section~\ref{Section_score_based_algorithm} is consistent, meaning that
$$\hat{\mathcal{G}} \overset{P}{\to}\mathcal{G}\,\,\,as\,\,n\to\infty,$$
given that we employ a ``suitable'' estimation procedure for the estimation of $\hat{\varepsilon}_i$, we use HSIC score as our choice of $\rho$ and consistent estimators $\hat{S}_i$ (for proof, definitions and details, see  Appendix~\ref{Appendix_consistency}). 
\end{proposition}


\subsection{Choice of the collection $\{F_1, \dots, F_k\}$}
\label{Section5Model_choice}

Selecting  the collection $\{F_1, \dots, F_k\}$ is a crucial step in our approach. If this collection is large, we loose statistical power and increase the chance of having an unidentifiable model as the following lemma suggests. 


\begin{lemma}\label{lemma_o_overparametrizacii}
Suppose that the joint distribution $F_{(X_1,X_2)}$ is generated according to model $CPCM(F_2)$ with graph $X_1\to X_2$, where $F_2$ is a distribution function with one parameter ($q_2=1$) belonging to the exponential family with the corresponding sufficient statistic $T_2$. 

Then, there exists $F_1$ such that the model $CPCM(F_1)$  with graph $X_2\to X_1$ also generates  $F_{(X_1,X_2)}$. In other words, there exists $F_1$ such that the causal graph in $CPCM(F_1, F_2)$ is not identifiable from the joint distribution. 
\end{lemma}

The proof (provided in \hyperref[Proof of lemma_o_overparametrizacii]{Appendix} \ref{Proof of lemma_o_overparametrizacii}) is based on the specific choice of $F_{1}$, such that its sufficient statistic $T_1$ is equal to $\theta_2$ (where $\theta_2$ is the parameter from the original model $CPCM(F_{2})$). 

It is important to note that such $F_{1}$ would lead to a rather non-standard distribution. This leads us to define a ``standard set of well-known distributions''.   We discuss the practical choices for this set in Section~\ref{Section_practical_choices}. 

\subsubsection{Unfair game issue}

Even if the theory suggests that it is not possible to fit a $CPCM(F_1, \dots, F_k)$ in both causal directions, this is only an asymptotic result that is no longer valid for a finite number of data. If we select $F$ with numerous parameters to estimate, our data will be fitted perfectly and we will not reject the wrong causal graph. However, by selecting an overly simple $F$, our assumptions may not be fulfilled and we may end up rejecting the correct causal graph. We recommend choosing all $F_{i}$ with the same number of parameters $q_i = q_j$. If we select, say, $F_{1}$ with one parameter and $F_{2}$ with five parameters ($q_1 = 1, q_2 = 5$), it will create a bias because the model with more parameters will fit the data more easily. We refer to this as an ``unfair game.'' 

\subsubsection{Practical choices of the set of ``standard well-known distributions'' and the choices of tests used in our implementation }
\label{Section_practical_choices}

We define two sets of ``standard set of well-known distributions''; set $\mathscr{S}_1$  containing distributions with one parameter and set $\mathscr{S}_2$  with two parameters. This avoids the  ``unfair game'' issue discussed before. Both sets should be rich enough to contain a wide range of distributions with different supports and characteristics, but should not contain many distributions with the same support in order to avoid unidentifiable setups. In practice, we mostly restrict our attention to distributions that are implemented in \texttt{mgcv} package in \texttt{family.mgcv} \citep{Wood}.  


In our implementation, we used the following distributions: Gaussian with fixed variance, Gaussian, Gamma, Pareto, Poisson and Negative binomial distribution. Here, $\mathscr{S}_1$ consists of the distributions with one parameter and  $\mathscr{S}_2$ consists of the distributions with two parameters.  However, we should note that many more choices are appropriate and our collections are not exhaustive and may be improved for specific applications where potentially different distributions may be seen as ``standard''. 


The choice between $\mathscr{S}_1$ and $\mathscr{S}_2$ should be made based on the sample size. Choosing $\mathscr{S}_2$ in small sample sizes leads to not rejecting neither direction, while choosing $\mathscr{S}_1$ for large sample sizes can often results in rejecting both causal directions. 

In our implementation of Algorithm~\ref{Algorithm1}, we use GAM \citep{Wood2} estimation of $\hat{\theta}(X_i)$. With regard to the independence test, we use Hoeffding D-test \citep{Nonparametric_test_for_independence_review} in the bivariate case, copula-based independence test \citep{Kojadinovic2009} in the multivariate case with $n>1000$, and HSIC \citep{ZhangKernelTest} when $n\leq 1000$ (for a review of different tests and their comparisons, see \cite{copula_based_independence_test}). 



