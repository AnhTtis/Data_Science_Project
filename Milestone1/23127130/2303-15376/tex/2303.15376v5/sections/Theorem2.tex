

\begin{customthm}{\ref{thmAssymetricMultivariatesufficient}}
Let $(X_1, X_2)$ follow the $CPCM(F_1, \dots, F_k)$ model with graph $X_1\to X_2$, where $F_1, \dots, F_k$ belong to the exponential family of distributions with corresponding sufficient statistics  $T_m= (T_{m,1}, \dots, T_{m,q_m})^\top$, $m=1, \dots, k$.  Following Definition~\ref{CPCM(F1F2)}, let $\tilde{m}\in\{1, \dots, k\}$ be the index such that  $X_2 = F_\tilde{m}^{-1}\big(\varepsilon_2; \theta_2(X_1)\big)$. 

The causal graph is identifiable if for all $m\in \{1, \dots, k\}$, at least one of the following holds: 
\begin{itemize}
    \item $ supp(F_m) \neq supp(X_1)$. 
    \item The function \( \theta_2 \) is not a linear combination of the sufficient statistics \( T_{m,1}, \dots, T_{m,q_m} \), i.e., there do not exist coefficients \( a_{i,j}, b_i \in \mathbb{R} \) for \( i = 1, \dots, q_{\tilde{m}} \) and \( j = 1, \dots, q_m \) such that  
   \begin{equation}\tag{\ref{eq158}}
   \theta_{2,i}(x) = \sum_{j=1}^{q_m} a_{i,j} T_{m,j}(x) + b_i, \quad \forall x \in \operatorname{supp}(X_1), \quad \forall i \in \{1, \dots, q_{\tilde{m}}\}.
   \end{equation}  
    \item There do not exist constants \( c_1, \dots, c_{q_m} \in \mathbb{R} \) such that the density of \( X_1 \) satisfies  
   \begin{equation}\tag{\ref{eq007v2}}
   p_{X_1}(x) \propto \frac{h_{\tilde{m},1}(x)}{h_{m,2}[\theta_2(x)]} \exp\left(\sum_{i=1}^{q_m} c_i T_{m,i}(x) \right), \quad \forall x \in \operatorname{supp}(X_1),
   \end{equation}  where \( h_{\tilde{m},1} \) is a base measure associated with \( F_{\tilde{m}} \) and \( h_{m,2} \) is the normalizing function of \( F_m \), both defined in \hyperref[appendix_exponential_family]{Appendix} \ref{appendix_exponential_family}. 
\end{itemize}

Consequentially, the space of non-identifiable distributions is contained in a $\tilde{d}$-dimensional space, where 
\begin{equation}\tag{\ref{dimension_in_theorem2}}
    \tilde{d} = \sum_{m\in\{1, \dots, k\}:  supp(F_m) = supp(X_1)} (q_m+1)(q_{\tilde{m}}+1) -1 .  
\end{equation}
\end{customthm}



\begin{proof}
\label{Proof of thmAssymetricMultivariatesufficient}{}

If the $CPCM(F_1,\dots, F_k)$ is \textit{not} identifiable, then there exists $m\in\{1, \dots, k\}$ and functions $\theta_1$ and $\theta_2$, such that models 
\begin{equation}
    \label{eq425}
    X_1 = \varepsilon_1, X_2 = F_\tilde{m}^{-1}(\varepsilon_2, \theta_2(X_1))\text{, and } X_2 = \varepsilon_2, X_1 = F_m^{-1}(\varepsilon_1, \theta_1(X_2))
\end{equation}generate the same joint density function. For simplifying the notation, let $m=1$ and $\tilde{m}=2$. 

\textbf{1) }Trivially, $X_1$ can not be generated as $X_1 = F_1^{-1}(\varepsilon_1, \theta_1(X_2))$ if $supp(F_1) \neq supp(X_1)$. 

\textbf{2)} For a contradiction, we show that $\theta_2$ is a linear combination of $T_{1,1}, \dots, T_{1,q_m}$. Decompose the joint density as
\begin{equation}\label{eq59}
  p_{(X_1, X_2)}(x,y) = p_{X_1}(x)p_{X_2\mid {X_1}}(y\mid x) = p_{X_2}(y)p_{{X_1}\mid {X_2}}(x\mid y), \,\,\,\,\,\,\,\,x\in supp(X_1), y\in supp(X_2).
 \end{equation}
Since $F_1$ and $F_2$ lie in the exponential family of distributions, we use the notation from \hyperref[appendix_exponential_family]{Appendix} \ref{appendix_exponential_family} and rewrite it as
\begin{equation*}
    \begin{split}
  &     p_{{X_2}\mid {X_1}}(y\mid x) = h_{1,1}(y)h_{1,2}[\theta_2(x)]\exp[\sum_{i=1}^{q_2}\theta_{2,i}(x)T_{2,i}(y)],\\&
  p_{{X_1}\mid {X_2}}(x\mid y) = h_{2,1}(x)h_{2,2}[{\theta_1}(y)]\exp[\sum_{i=1}^{q_1}{\theta}_{1,i}(y)T_{1,i}(x)].  
    \end{split}
\end{equation*}
After a logarithmic transformation of both sides of (\ref{eq59}), we obtain 
\begin{equation}\label{eq254}
\begin{split}
\log[p_{(X_1,X_2)}(x,y)] &= \log[p_{X_1}(x)] +  \log[h_{1,1}(y)]+\log\{h_{1,2}[\theta_{2}(x)]\} + \sum_{i=1}^{q_2}\theta_{2,i}(x)T_{2,i}(y) \\&
= \log[p_{X_2}(y)] +  \log[h_{2,1}(x)]+\log\{h_{2,2}[\theta_{1}(y)]\} + \sum_{i=1}^{q_1}\theta_{1,i}(y)T_{1,i}(x).
\end{split}
\end{equation}
Define $f(x) = \log[p_{X_1}(x)] +\log\{h_{1,2}[\theta_{2}(x)]\} -\log[h_{2,1}(x)]$ and $g(y) =\log[h_{1,1}(y)] -  \log[p_{X_2}(y)] + \log\{h_{2,2}[\theta_{1}(y)]\}$. Then, equality (\ref{eq254}) reads as 
\begin{equation}\label{eq9876}
f(x) + g(y) = \sum_{i=1}^{q_1}\theta_{1,i}(y)T_{1,i}(x) - \sum_{i=1}^{q_2}T_{2,i}(y)\theta_{2,i}(x).
\end{equation}
Finally, we use Lemma \ref{PomocnaLemma1}. We know that functions $T_{2,i}$ are affinly independent in the sense presented in Lemma  \ref{PomocnaLemma1} (see (\ref{eq145151}) in \hyperref[appendix_exponential_family]{Appendix} \ref{appendix_exponential_family}). Therefore, Lemma \ref{PomocnaLemma1} gives us that $\theta_{2,i}, i=1, \dots, q_2$ are only a linear combination of $T_{1, j}, j=1, \dots, q_1$, which is what we wanted to show. 

\textbf{3)} For a contradiction, we show that $p_{X_1}$ must have a form \eqref{eq007v2}. Let us rewrite equation~\ref{eq9876} into 
\begin{equation}\label{eq9876543}
\begin{split}
    \log[p_{X_1}(x)]   =&-\log\{h_{1,2}[\theta_{2}(x)]\} +\log[h_{2,1}(x)]-g(y)\\&  +\sum_{i=1}^{q_1}\theta_{1,i}(y)T_{1,i}(x) - \sum_{i=1}^{q_2}T_{2,i}(y)\theta_{2,i}(x).
\end{split}
\end{equation}
Fix $y\in supp(F_2)$. Using the form of $\theta_{2,i}$ from the previous bullet-point, we can write 
\begin{equation*}
    \begin{split}
      &  \sum_{i=1}^{q_1}\theta_{1,i}(y)T_{1,i}(x) - \sum_{i=1}^{q_2}T_{2,i}(y)\theta_{2,i}(x) = \sum_{i=1}^{q_1}\theta_{1,i}(y)T_{1,i}(x) - \sum_{i=1}^{q_2}T_{2,i}(y)\bigg( \sum_{j=1}^{q_1}a_{i,j}T_{1,j}(x)+b_i \bigg) \\& = \sum_{i=1}^{q_1}c_iT_{1,i}(x)+d, 
    \end{split}
\end{equation*}
where $c_i = \theta_{1,i}(y) - \sum_{j=1}^{q_2}\sum_{k=1}^{q_1}T_{2,i}(y)a_{i,j}$ and $d =  \sum_{j=1}^{q_2}b_jT_{2,j}(y)$. Therefore, equation~\ref{eq9876543} can be written as 
\begin{equation*}
   \log[p_{X_1}(x)]   =-\log\{h_{1,2}[\theta_{2}(x)]\} +\log[h_{2,1}(x)]  +\sum_{i=1}^{q_1}c_iT_{1,i}(x) +(d-g(y)).
\end{equation*}
Applying exponential on both sides, we obtain (\ref{eq007v2}). 

\textbf{Part ''Consequentially'':} We have shown that if \eqref{eq425} holds, then \( \operatorname{supp}(F_m) = \operatorname{supp}(X_1) \), and the joint density \( p_{(X_1, X_2)} \) is uniquely determined by the coefficients \( a_{i,j}, b_i, c_j \in \mathbb{R} \), where \( i = 1, \dots, q_{\tilde{m}} \) and \( j = 1, \dots, q_m \).  

By counting the number of these coefficients, we find that there are \( (q_m+1)(q_{\tilde{m}}+1) -1 \) of them, with the  ''\( -1 \)'' term accounting for the normalization of the density function. Consequently, \eqref{dimension_in_theorem2} follows by summing over all \( m \in \{1, \dots, k\} \).  

\end{proof}

