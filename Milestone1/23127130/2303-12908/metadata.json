{
    "arxiv_id": "2303.12908",
    "paper_title": "Self-supervised Learning with Speech Modulation Dropout",
    "authors": [
        "Samik Sadhu",
        "Hynek Hermansky"
    ],
    "submission_date": "2023-03-22",
    "revised_dates": [
        "2023-03-24"
    ],
    "latest_version": 1,
    "categories": [
        "eess.AS",
        "cs.SD"
    ],
    "abstract": "We show that training a multi-headed self-attention-based deep network to predict deleted, information-dense 2-8 Hz speech modulations over a 1.5-second section of a speech utterance is an effective way to make machines learn to extract speech modulations using time-domain contextual information. Our work exhibits that, once trained on large volumes of unlabelled data, the outputs of the self-attention layers vary in time with a modulation peak at 4 Hz. These pre-trained layers can be used to initialize parts of an Automatic Speech Recognition system to reduce its reliance on labeled speech data greatly.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.12908v1"
    ],
    "publication_venue": null
}