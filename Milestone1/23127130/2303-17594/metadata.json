{
    "arxiv_id": "2303.17594",
    "paper_title": "MobileInst: Video Instance Segmentation on the Mobile",
    "authors": [
        "Renhong Zhang",
        "Tianheng Cheng",
        "Shusheng Yang",
        "Haoyi Jiang",
        "Shuai Zhang",
        "Jiancheng Lyu",
        "Xin Li",
        "Xiaowen Ying",
        "Dashan Gao",
        "Wenyu Liu",
        "Xinggang Wang"
    ],
    "submission_date": "2023-03-30",
    "revised_dates": [
        "2023-03-31"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "Although recent approaches aiming for video instance segmentation have achieved promising results, it is still difficult to employ those approaches for real-world applications on mobile devices, which mainly suffer from (1) heavy computation and memory cost and (2) complicated heuristics for tracking objects. To address those issues, we present MobileInst, a lightweight and mobile-friendly framework for video instance segmentation on mobile devices. Firstly, MobileInst adopts a mobile vision transformer to extract multi-level semantic features and presents an efficient query-based dual-transformer instance decoder for mask kernels and a semantic-enhanced mask decoder to generate instance segmentation per frame. Secondly, MobileInst exploits simple yet effective kernel reuse and kernel association to track objects for video instance segmentation. Further, we propose temporal query passing to enhance the tracking ability for kernels. We conduct experiments on COCO and YouTube-VIS datasets to demonstrate the superiority of MobileInst and evaluate the inference latency on a mobile CPU core of Qualcomm Snapdragon-778G, without other methods of acceleration. On the COCO dataset, MobileInst achieves 30.5 mask AP and 176 ms on the mobile CPU, which reduces the latency by 50% compared to the previous SOTA. For video instance segmentation, MobileInst achieves 35.0 AP on YouTube-VIS 2019 and 30.1 AP on YouTube-VIS 2021. Code will be available to facilitate real-world applications and future research.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.17594v1"
    ],
    "publication_venue": "Preprint. 12 pages, 7 figures"
}