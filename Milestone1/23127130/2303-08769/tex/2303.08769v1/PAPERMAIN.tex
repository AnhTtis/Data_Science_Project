\documentclass[journal,10pt]{IEEEtran} 
\IEEEoverridecommandlockouts
\usepackage{lipsum}
%\documentclass[journal,onecolumn]{IEEEtran} 
%\documentclass[sigconf]{acmart}
%\usepackage[sorting=none,style=numeric]{biblatex}
%\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

%-------------------------------- 0210
\usepackage[english]{babel}
\usepackage[square,numbers]{natbib}
\usepackage{longtable}
\usepackage{etoolbox}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{natbib}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\usepackage{multirow}
\usepackage{makecell}
\usepackage{amsmath}        % new
\usepackage{amssymb}        % new
\usepackage{amsthm}
\usepackage{tikz}
\usepackage{pdfpages}
\usepackage{comment}
%\usepackage{cite}
%\usepackage{caption}
%\usepackage{subcaption}
\usepackage{flushend}
\usepackage[linesnumbered,ruled]{algorithm2e}
\usepackage[justification=centering]{caption}
%\usepackage[backend=biber,style=ieee, maxnames=10]{biblatex}

%For Verbatim fonts and sizes
\usepackage{fancyvrb}
\usepackage{datetime}
\newdate{date}{25}{01}{2023}
\date{\displaydate{date}}
%\date{\monthyeardate}

\pagestyle{empty}
%\let\svmaketitle\maketitle
%\def\maketitle{\svmaketitle\thispagestyle{empty}}
%\markboth{Stanford CS372 Lecture Notes, 2020-22}%
%{Shell \MakeLowercase{\textit{et al.}}: Edward Y. Chang}


\newenvironment{noindlist}
 {\begin{list}{\labelitemi}{\leftmargin=0.3em \itemindent=0.6em}}
 {\end{list}}

 \newenvironment{noindenumerate}
  {\begin{list}{\arabic{enumi}.}
    {\usecounter{enumi}
     \setlength{\labelwidth}{0.6cm}
     \setlength{\leftmargin}{0.33cm}
     \setlength{\labelsep}{0.1cm}
     \setlength{\itemindent}{0cm}
     }
  }
  {\end{list}}

\begin{document}
%\pagenumbering{gobble} 

\title{Prompting Large Language Models \\ With the Socratic Method}

\begin{comment}
\author{
{\bf Edward Y. Chang,%~\IEEEmembership{Fellow,~IEEE}
} \\
Computer Science \\
Stanford University \\ 
echang@cs.stanford.edu \\
%\displaydate{date} \\
}
\end{comment}

\author{Edward Y. Chang \\ Computer Science, Stanford University \\ echang@cs.stanford.edu%
  \thanks{Accepted by the $13^{th}$ IEEE CCWC, 2/11/2023.}%
}

%\markboth{IEEE CWCC}{}
%\@anonymizetrue 
\maketitle
%\thispagestyle{empty}

%\IEEEoverridecommandlockouts
%\IEEEpubid{\makebox[\columnwidth]{979-8-3503-3286-5/23/\$31.00 \copyright 2023 IEEE \hfill} \hspace{\columnsep}\makebox[\columnwidth]{ }}


\begin{abstract}
This paper outlines a systematic approach to using the Socratic method in developing prompt templates that effectively interact with large language models, including GPT-3. We examine various methods and identify those that yield precise answers and justifications while simultaneously fostering creativity and imagination to enhance creative writing. Specifically, we discuss how techniques such as definition, elenchus, dialectic, maieutics, generalization, and counterfactual reasoning can be applied in engineering prompt templates, and provide practical examples that demonstrate their effectiveness in performing inductive, deductive, and abductive reasoning.
\end{abstract}

\begin{IEEEkeywords}
large language model, natural language processing, prompting, the Socratic method.
\end{IEEEkeywords}

\input{Introduction.tex}
\input{SocraticMethod.tex}
\input{PromptTemplates.tex}
\input{GenesisTable.tex}
\input{Conclusions.tex}
\input{AppendixA.tex}

\bibliographystyle{abbrvnat}
\bibliography{References}
\end{document}

