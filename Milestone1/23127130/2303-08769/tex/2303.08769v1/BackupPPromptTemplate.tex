\section{Prompt Template Engineering}
\label{sec:template}

Our examples with GPT-3, utilizing the ChatGPT user interface and its APIs, have revealed that utilizing the methods of definition, elenchus, dialectic, maieutics, counterfactual reasoning can effectively enhance the output's accuracy and conciseness through arguments and verification, as well as showcase guided generalization and creativity. The ongoing challenge is to generate prompt templates within an interactive setting, with each prompt being generated based on the context accumulated thus far, akin to the Socratic method of recollection.

Prompt template engineering refers to the process of designing and creating templates for providing input, or ``prompts,'' to a language model to guide its output generation. This section first discusses prompt template engineering methods for
the basic building blocks, and then integrates the the methods of definition, elenchus, maieutics, counterfactual reasoning to compose complex templates.

\subsection{Basic, One Shot Template}

Let us start with a simple one-shot template.
The work of \cite{SocraticModels-Google2022} uses a simple formulation function to generate prompt $x'$,
$x'$ = $f_{prompt}$($x$) given input $x$.

For the task of machine translation, the template may take a form “Translate from [Lan$_{from}$]: [X] to [Lan$_{to}$]: [Y],” where Lan$_{from}$ can be detected
by the prompt template or can rely on the LLM
to find out. Input $x$ consists of information to
fill slots [X] and [Lan$_{to}$].
For instance, if input $x$ is ``translate good morning to French,'' the template $x'$ is filled with the
information in $x$, and $x'$ = ``Translate from English: ``good morning'' to French: [Y].''  The empty slot [Y] is
for the LLM to return.  
Once the LLM has completed the translation task, it
replaces Y to be ``bonjour.'' In cases when LLM may return multiple responses
(e.g., when x is a word with multiple meanings without additional context), it also provides a score for each. The prompt template can decide to
output the response with the highest score, or to
send back to the LLM to produce a summarize.

There are three main design considerations when engineering a basic prompt. First, it is important to consider how to phrase the template so that it can handle different styles of user input for the same task. For example, a user may ask for a translation task to be performed by saying ``Translate x to French'' or ``What is the French translation of x?''. Second, as discussed in \cite{PromptSurvey2023}, it is important to take into account the patterns and capabilities of the partner language model (LLM) when designing the template, such as whether the LLM is left-to-right \cite{OpenAI-GPT3-2020} or masked \cite{Devlin2019BERTPO}. Third, certain tasks, such as language detection and summarization, can be performed by the template itself or by the LLM. The decision between these options should take into account factors such as cost, as using an LLM often incurs a fee, while developing a template as a client module can be done for free.

To address the first two technical challenges, one can first hand-engineer a few seed templates and then paraphrase them into an ensemble \cite{Haviv2021BERTeseLT}. We believe that the basic, one-shot formulation can always be replaced by an ensemble formulation \cite{Schick2020ExploitingCF,Peng2022ModelEI} and then learn the weights of its members for each query instance to produce the final output. Additionally, it is not necessary to conduct mining on LLMs to understand their capabilities, as an ensemble with various paraphrased prompts can find out what an LLM knows by examining which basic prompts have high weights. From those highly weighted prompts, we can infer the strengths of the LLM. 

%\noindent
%{\color{blue} Note} Experiment idea: evaluate LLMs using ensembles.

\subsection{Clarification with Method Definition}
\label{sec:template-definition}

There are computer algorithms that can already be used to recursively clarify a question, its definitions, and sub-terms' definitions. In fact, the natural language processing (NLP) community has developed a large 
number of useful methods and algorithms over the years \cite{NLP-Text-JM3}. 
One can use NLP techniques, such as dependency parsing and named-entity recognition (NER) \cite{NLPScratch2011}, to analyze the structure and meaning of a question and identify key terms and concepts. For example, 
NER can be used to extract entities in user input, such as names, locations, and organizations, and co-reference resolution can be used to understand the referred entity of a pronoun. 
Before submitting a template to an LLM, the application (e.g., a chatbot) 
that uses the template should check if all input slots are filled, 
and perform a sanity check. In the translation example, if the [Lan$_{to}$] was not provided or the specified language is not supported by the LLM, then the application should inquire the user for clarification.

Regarding mapping a natural language input to a prompt template, existing techniques of knowledge representation and reasoning can be very helpful. More specifically, ontology alignment and semantic parsing \cite{Campagna2020AFS,zhou-etal-2021-structure} can help map an NL input to a structured representation of knowledge and infer implicit concepts and relationships. These algorithms can be used to generate more precise and accurate prompts for LLMs, and to improve the effectiveness of the Socratic method in dialogue formulation \cite{DialoguewithAttention2023}. Some available tools include NLTK (Natural Language Toolkit) and spaCy for NLP\footnote{spaCy (https://spacy.io/)}, and TensorFlow for ML\footnote{TensorFlow (https://www.tensorflow.org/)}.

%\noindent
%{\color{blue} Note} Experiment idea: compare w/ and w/o.

\subsection{Verification with Method Elenchus}

The main purposes of conducting cross examination in a template are to validate the credibility of the information sources and to identify inconsistencies in the process. Cross examination is typically conducted through a multi-turn dialogue \cite{DialoguewithAttention2023}. In the context of template engineering, the goal is to formulate a productive dialogue that can be used to assess the reliability of an LLM's output.  

There are several methods that can be used to assess and strengthen the reliability of an LLM's output. 1) The first approach is to paraphrase a question in order to obtain different answers and identify inconsistencies, if they exist, in multiple answers. 2) The second method is to ask for further evidence, such as querying top-k sources of information and asking the LLM to rate the credibility of each source. This can be used to compute the reliability of the output. 3) Additionally, template engineering can be used to query an LLM for opposing views of its output, including sources and credibility, and then evaluate if a different perspective is strong.

The implementation of the first two methods for cross examination, paraphrasing a question and asking for further evidence, is readily covered by the techniques enumerated in Section~\ref{sec:template-definition}. To implement the third method of asking for different perspectives, a simple approach is to find the sentiment of the original question and then rewrite the question with an opposite sentiment. For example, if the original question is phrased in a positive tone, the prompt template can reformulate the question with a negative tone to elicit a contrasting viewpoint.
A more elaborate method is to identify the people and sources in the LLM-generated responses and then re-post the questions to those who have a reputation for having different views. For example, if the original answer came from a democratic right-leaning source, the prompt template may post the same question to a source of a republican-left persuasion, and vice versa. This approach allows for a more comprehensive examination of the topic by considering multiple perspectives.

The template to examine the semantic relation between two sentences $S_1$ and $S_2$ can be 
written as ``<$S_1$>, [R], [$S_2$],'' where R
is one of the three most important 
types of semantic relations: paraphrase, entailment, and contradiction \cite{PTRSUN2021}. Two sentences that have the same meaning are called paraphrases of each other. Two sentences that
have different meanings can be called 
disagreement or contradiction. The template 
can be trained to identify the degree
of agreement (or disagreement) between two
sentences.  


Table \ref{tab:Elenchus} shows two examples of this. In the first example (shown on the top portion of the table), the prompter asks GPT-3 to confirm if James Watson and Francis Crick are the only contributors to the discovery of the DNA double helix structure. GPT-3 replies by mentioning two other contributors. The second example in the table asks GPT-3 to provide not only the answer to a question but also its information sources and rate the credibility of each source according to the prompter's specification. Although the reliability of GPT-3's ratings remains to be validated, this rating mechanism can serve as an alert when some sources are found to be unreliable.


\begin{table}[htbp!]
\caption{Examples of Method Elenchus}
%\vspace{-.12in}
\label{tab:Elenchus}
%\resizebox{\textwidth}{!}
\begin{tikzpicture}
\begin{normalsize}
\node (table) [inner sep=0.1pt] {
\begin{tabular}{p{1.1cm}|p{6.4cm}}
\toprule
Role & Dialogue \\
\midrule
Prompt & {The discovery of the double helix structure of DNA was credited to James Watson and Francis Crick. However, are there opposing opinions to the list of contributors regarding this discovery?}\\

GPT3 & {There are some historical debates on the contributions of other scientists who also worked on the structure of DNA such as Maurice Wilkins and Rosalind Franklin.} \\ \\
\midrule 

Prompt & 
{What is the tallest building in the world.  Please provide three references and rate their credibility as high, medium, or low.} \\

GPT3 & {As of 2021, the tallest building in the world is the Burj Khalifa located in Dubai, United Arab Emirates. It stands at 828 meters (2,722 feet) tall.

References:
\begin{noindenumerate}
\item Credibility {\color{red}High}: "Burj Khalifa."... 
 this is the official website of the building, providing accurate information.
\item Credibility {\color{red}High}: "The Tallest Buildings in the World." Council on Tall Buildings and Urban Habitat... this is a well-respected organization in the field of tall building and urban habitat research.
\item Credibility {\color{red}Medium}: "The Tallest Buildings in the World." World Atlas..., 
this is a well-known website providing accurate information on different topics, but it's always good to cross-reference with other sources.
\end{noindenumerate}
}
%\bottomrule
\end{tabular}
};
\draw [rounded corners=.5em] (table.north west) rectangle (table.south east);
\end{normalsize}
\end{tikzpicture}
\end{table}


\subsection{Guided Generalization with Method Maieutics}

The example shown in Table~\ref{tab:Maieutics}, ``planting gourd yields cucumber,'' expects the GPT-3 to first learn to select the input objects are two produces, vegetables or fruit. The template is ``The farmer was so sad because he [verb] [X] but yields [Y], where price(X) >> price(Y).'' This first shot may not have strongly conveyed the condition: price(X) >> price(Y), but with a couple of training iterations, GPT-3 started to ``recognize'' the price constraint and could also provide justifications when arguing for the price of tea being much higher than the price of spinach (not presented in the table).
More interestingly, after GPT-3 gets the price right, it started suggesting food other than produce such as caviar, roe, lobster, and crab. While the price constraint was observed, the verb ``plant'' is incorrect. Here, we suggest making the hard-coded verb plant an output slot: ``The farmer was so sad because he [verb] [X] but yields [Y], where price(X) >> price(Y).''
Amazingly, GPT-3 is able to fill in with accurate verbs:
\begin{enumerate}
\item "Harvesting truffle yields mushroom."
\item "Fishing for caviar yields roe."
\item "Trapping lobster yields crab."
\end{enumerate}

The example shown in Table~\ref{tab:Maieutics}, ``planting gourd yields cucumber,'' demonstrates that GPT-3 is able to generate novel examples based on a template. When it suggests food items other than produce, it could be seen as an error as the boundary set by the verb ``plant'' is trespassed. However, this could also be seen as an innovative act by GPT-3, extending the constraint hinted by the verb. 
Impressively, the new examples still preserve the original intent of showing a producer's emotional distress.

How can this guided generalization be 
accurately and automatically
performed to edit a template?  
Socrates' method of generalization starts with specific instances and then draws general statements from them\footnote{The process of generalization in the Socratic method can be thought of as a form of induction, where specific examples are used to draw general conclusions. In the field of natural language processing and computational linguistics, there are a number of algorithms and techniques that have been proposed for identifying and extracting patterns from text data. These include methods for clustering, categorization, and classification of text data, as well as techniques for natural language understanding and information extraction. However, the specific algorithms and techniques used will depend on the specific task and application, and there is no one-size-fits-all procedure for generalization.}. The procedure for generalization involves identifying common patterns or themes in a set of examples, and then formulating a general rule that captures these patterns.
In the example presented in Table~\ref{tab:Maieutics},  we started with asking GPT-3 to meet the price(X) >> price(Y) constraint, with the condition that X and Y must both be produce grown in soil. However, upon analyzing GPT-3's outputs, we discovered that some instances of X and Y were not produce (e.g. lobster and caviar). This finding led to the realization that the hard-coded verb ``plant'' in the existing template was incorrect. To address this issue, generalization was applied by allowing the [verb] slot to be open, making the template statement more general. In this case, the mistakes made by GPT-3 served as valuable training data, allowing us to generalize the original template and make the expression more vivid and dynamic.


\subsection{Guided Imagination with Counterfactual}


Imagination and creating novel plots are crucial for writers, as it allows for ``creative freedom'' and ``artistic license.'' Creativity is the ability to think differently and approach problems with fresh and imaginative ideas.

However, an imagination without a clear subject matter, scope, or a story line can lead to a lack of productivity. To captivate the audience, a writer must consider human experiences and emotions as constraints. Therefore, ``creative freedom'' should not be viewed as total freedom, but rather as the ability to condition future narratives in the context and to create plots that turn and twist in unexpected ways.

The technique of counterfactual \cite{Pearl2009} can be useful in guiding imagination. It involves considering alternative scenarios and outcomes. This can lead to the exploration of different possibilities and the generation of new and unique plot ideas. For example, a writer may ask ``what if'' questions to change the narrative of events, such as ``what if the main character had not fallen in love?'' or ``what if an accident occurred on the way to a highly-anticipated date?'' By considering these counterfactuals, a writer and an LLM can create more engaging and interesting stories. One can ask an LLM to generate several scenarios and then select the most suitable one for the writer to continue writing.

As mentioned in Section~\ref{sec:cf}, we have experimented with using the counterfactual technique to
rewrite a chapter to connect the two greatest Chinese classical novels,
``Outlaws of the Marsh'' and ``Dream of the Red Chamber.'' We have
also asked GPT-3 to rewrite Genesis chapter 3 after verse six by prompting GPT-3
that: ``What if Adam and Eve refused the serpent to eat the fruit?''
The results were impressive, as GPT-3 was able to generate unique and interesting scenarios that deviated from the original story while still maintaining the core themes and concepts. 
This technique can be used in a wide range of writing and storytelling, 
from fiction to non-fiction, to generate new and compelling ideas. 

\subsection{Remarks on Evaluations}

Evaluating the strategies and methods presented in this section can be challenging as traditional methods such as using standard benchmarks may not be suitable for evaluating creative and imaginative output. Subjectivity can also play a role in the evaluation process. However, it is important to note that failure is a natural part of the writing process, as it often involves multiple revisions. In the specific case of our experiment in bridging two  classical novels, the process was a trial-and-error one with few successful ideas. However, there were two occasions where GPT-3 produced impressive results, which outweigh all the failures that occurred along the way for a writer.