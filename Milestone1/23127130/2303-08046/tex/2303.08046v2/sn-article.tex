\begin{filecontents}{sn-jnl.cls}
\NeedsTeXFormat{LaTeX2e}[1995/12/01]
\ProvidesClass{sn-jnl}
              [2019/11/18 v0.1: An authoring template for Springer Journal articles]

\newif\if@restonecol
\newif\if@titlepage   \@titlepagefalse
\newif\if@cropmarkson \@cropmarksonfalse
\newif\ifDoublecol    \Doublecolfalse%
\newif\ifpagebody\global\pagebodyfalse%
\newif\if@iicol\global\@iicolfalse%
\newif\if@bibcomment\global\@bibcommentfalse%
\newif\if@referee\global\@refereefalse%
\newif\if@vrulerlinenumberon\global\@vrulerlinenumberonfalse%
\newif\if@pdflatex\global\@pdflatexfalse%
\newif\if@remarkboxon\global\@remarkboxonfalse%

\newif\if@Spr@basic@refstyle\global\@Spr@basic@refstylefalse% 1.Basic Springer Nature Reference Style/Chemistry Reference Style -> sn-basic.bst
\newif\if@Mathphys@refstyle\global\@Mathphys@refstylefalse% 2.Math and Physical Sciences Reference Style -> sn-mathphys.bst
\newif\if@APS@refstyle\global\@APS@refstylefalse% 3.American Physical Society (APS) Reference Style -> sn-APS.bst
\newif\if@Vancouver@refstyle\global\@Vancouver@refstylefalse% 4.Vancouver Reference Style -> sn-vancouver.bst
\newif\if@APA@refstyle\global\@APA@refstylefalse% 5.APA-based Social Sciences/Psychology Reference Style -> sn-apacite.bst
\newif\if@Chicago@refstyle\global\@Chicago@refstylefalse% 6.Chicago-based Humanities Reference Style -> sn-chicago.bst
\newif\if@Standard@Nature@refstyle\global\@Standard@Nature@refstylefalse% 7.Standard Nature Research Style -> sn-nature.bst
\newif\if@Default@refstyle\global\@Default@refstylefalse% 8. default reference style - no bib/bst required

%% Template Options
\DeclareOption{a4paper}{\PassOptionsToPackage{a4}{crop}}
\DeclareOption{a3paper}{\PassOptionsToClass{a3paper}{article}\PassOptionsToPackage{a3}{crop}}
\DeclareOption{centre}{\PassOptionsToPackage{center}{crop}}
\DeclareOption{crop}{\PassOptionsToPackage{frame}{crop}\global\@cropmarksontrue}
\DeclareOption{nocrop}{\PassOptionsToPackage{off}{crop}\global\@cropmarksontrue}
\DeclareOption{info}{\PassOptionsToPackage{info}{crop}}
\DeclareOption{noinfo}{\PassOptionsToPackage{noinfo}{crop}}

%% Classfile Options
\DeclareOption{oneside}{\@twosidefalse \@mparswitchfalse}
\DeclareOption{twoside}{\@twosidetrue  \@mparswitchtrue}
\DeclareOption{draft}{\setlength\overfullrule{5pt}}
\DeclareOption{titlepage}{\@titlepagetrue}
\DeclareOption{notitlepage}{\@titlepagefalse}
\DeclareOption{onecolumn}{\@twocolumnfalse}
\DeclareOption{twocolumn}{\@twocolumntrue}
\DeclareOption{openbib}{\let\if@openbib\iftrue}
\DeclareOption{pagegrid}{\global\pagebodytrue}%
\DeclareOption{iicol}{\global\@iicoltrue}%
\DeclareOption{bibcomment}{\global\@bibcommenttrue}%
\DeclareOption{referee}{\global\@refereetrue}%
\DeclareOption{lineno}{\global\@vrulerlinenumberontrue}%
\DeclareOption{pdflatex}{\global\@pdflatextrue}%
\DeclareOption{remarkboxoff}{\global\@remarkboxonfalse}%

\DeclareOption{sn-basic}{\global\@Spr@basic@refstyletrue}%
\DeclareOption{sn-mathphys}{\global\@Mathphys@refstyletrue}%
\DeclareOption{sn-aps}{\global\@APS@refstyletrue}%
\DeclareOption{sn-vancouver}{\global\@Vancouver@refstyletrue}%
\DeclareOption{sn-apa}{\global\@APA@refstyletrue}%
\DeclareOption{sn-chicago}{\global\@Chicago@refstyletrue}%
\DeclareOption{sn-standardnature}{\global\@Standard@Nature@refstyletrue}%
\DeclareOption{default}{\global\@Default@refstyletrue}%

%%\ExecuteOptions{twosidecrop,crop,centre,info,croppage}
\ProcessOptions
\LoadClass[twoside,fleqn]{article}

\gdef\refereedefns{%
\if@referee%
\usepackage{setspace}%
\doublespacing%
\fi}%
\refereedefns%

%% General Packages Used
%
\AtBeginDocument{%
%%\newcommand*\ExtraParaSkip{12pt}%
\SetFootnoteHook{\hspace*{-8pt}}%
\DeclareNewFootnote{A}[gobble]%
\setlength{\skip\footinsA}{0pt}}%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fonts & Sizes %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%% Fonts Used
%%\RequirePackage[T1]{fontenc}%
%
\DeclareOldFontCommand{\rm}{\normalfont\rmfamily}{\mathrm}%
\DeclareOldFontCommand{\sf}{\normalfont\sffamily}{\mathsf}%
\DeclareOldFontCommand{\tt}{\normalfont\ttfamily}{\mathtt}%
\DeclareOldFontCommand{\bf}{\normalfont\bfseries}{\mathbf}%
\DeclareOldFontCommand{\it}{\normalfont\itshape}{\mathit}%
\DeclareOldFontCommand{\sl}{\normalfont\slshape}{\@nomath\sl}%
\DeclareOldFontCommand{\sc}{\normalfont\scshape}{\@nomath\sc}%
\DeclareRobustCommand*\cal{\@fontswitch\relax\mathcal}%
\DeclareRobustCommand*\mit{\@fontswitch\relax\mathnormal}%
%
\renewcommand\normalsize{%
   \@setfontsize\normalsize{10bp}{12bp}%
   \abovedisplayskip 12\p@ \@plus2\p@ \@minus1\p@
   \abovedisplayshortskip \z@ \@plus3\p@%
   \belowdisplayshortskip 3\p@ \@plus3\p@ \@minus3\p@%
   \belowdisplayskip \abovedisplayskip%
   \let\@listi\@listI}%
\normalsize%
%
\newcommand\medsize{%
   \@setfontsize\small\@xipt{13}%
   \abovedisplayskip 5\p@ \@plus3\p@ \@minus4\p@
   \abovedisplayshortskip \z@ \@plus2\p@
   \belowdisplayshortskip 3\p@ \@plus2\p@ \@minus2\p@
   \def\@listi{\leftmargin\leftmargini
               \topsep 4\p@ \@plus2\p@ \@minus2\p@
               \parsep 2\p@ \@plus\p@ \@minus\p@
               \itemsep \parsep}%
   \belowdisplayskip \abovedisplayskip}%
%
\renewcommand\small{%
   \@setfontsize\small\@ixpt{11}%
   \abovedisplayskip 5\p@ \@plus3\p@ \@minus4\p@
   \abovedisplayshortskip \z@ \@plus2\p@
   \belowdisplayshortskip 3\p@ \@plus2\p@ \@minus2\p@
   \def\@listi{\leftmargin\leftmargini
               \topsep 4\p@ \@plus2\p@ \@minus2\p@
               \parsep 2\p@ \@plus\p@ \@minus\p@
               \itemsep \parsep}%
   \belowdisplayskip \abovedisplayskip}%
%
\renewcommand\footnotesize{%
   \@setfontsize\footnotesize{7}{8}%
   \abovedisplayskip 5\p@ \@plus2\p@ \@minus4\p@
   \abovedisplayshortskip \z@ \@plus\p@
   \belowdisplayshortskip 3\p@ \@plus\p@ \@minus2\p@
   \def\@listi{\leftmargin\leftmargini
               \topsep 3\p@ \@plus\p@ \@minus\p@
               \parsep 2\p@ \@plus\p@ \@minus\p@
               \itemsep \parsep}%
   \belowdisplayskip \abovedisplayskip}
%
\renewcommand\scriptsize{\@setfontsize\scriptsize\@ixpt\@ixpt}%
\newcommand\scrisize{\@setfontsize\scrisize{9.3}{9}}%
\renewcommand\tiny{\@setfontsize\tiny\@vpt\@vipt}%
\renewcommand\large{\@setfontsize\large{12}{14}}%
\newcommand\larg{\@setfontsize\larg{11}{13}}%
\renewcommand\Large{\@setfontsize\Large{16}{18}}%
\renewcommand\LARGE{\@setfontsize\LARGE\@xviipt{22}}%
\renewcommand\huge{\@setfontsize\huge\@xxpt{25}}%
\renewcommand\Huge{\@setfontsize\Huge\@xxvpt{30}}%
%
\DeclareMathSizes{\@ixpt}{\@ixpt}{7}{5}%
\DeclareMathSizes{\@xpt}{\@xpt}{7}{5}%
\DeclareMathSizes{\@xipt}{\@xipt}{7}{5}%
%
\DeclareRobustCommand*\textsubscript[1]{%
  \@textsubscript{\selectfont#1}}%
%
\def\@textsubscript#1{%
  {\m@th\ensuremath{_{\mbox{\fontsize\sf@size\z@#1}}}}}%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%% Layout Settings %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%\RequirePackage{geometry}%
%
\newlength\columnhsize%
%
%% Regular Pages (for Opening page - redefined)
%
\if@iicol%
%
%% for double column used sn-medium design trim and page size %%
%
\setlength\paperwidth{193mm}%
\setlength\paperheight{260mm}%
%
\setlength\textwidth{160mm}%
\setlength\textheight{216mm}%
%
\setlength\headheight{12pt}%
\setlength\headsep{5.15mm}%
%
\setlength\columnsep{8mm}%
\setlength\columnhsize{76mm}%
%
\setlength\maxdepth{0pt}%
\setlength\footnotesep{7\p@}%
\setlength{\skip\footins}{18\p@ \@plus 6\p@ \@minus 3\p@}%
%
\RequirePackage[%
    reversemp,
    paperwidth=193mm,
    paperheight=260mm,
    top={19.29mm},
    headheight={12pt},
    headsep={5.15mm},
    text={160mm,216mm},
    marginparsep=5mm,
    marginparwidth=12mm,
    bindingoffset=6mm,
    footskip=10.13mm,twocolumn]{geometry}%
%
\renewcommand\footnoterule{%
  \kern3\p@%
  \hrule \@height.2mm \@width\columnwidth%
  \kern5.5\p@}%
%
\else%
%% For single column used smallcond design trim and page size %%
\RequirePackage[%
    reversemp,
    paperwidth=155mm,
    paperheight=235mm,
    top={19.5mm},
    headheight={5.5pt},
    headsep={5.6mm},
    text={119mm,194.25mm},
    marginparsep=5mm,
    marginparwidth=12mm,
    bindingoffset=6mm,
    footskip=10mm]{geometry}
%
    \setlength\maxdepth{0pt}%
    \setlength\columnsep{5mm}%
    \setlength{\marginparsep}{5mm}%
    \setlength{\marginparwidth}{12mm}%
    \setlength\footnotesep{5.75\p@}%
    \setlength{\skip\footins}{8\p@ \@plus 4\p@ \@minus 0\p@}%
%
\renewcommand\footnoterule{%
  \kern3\p@%
  \ifodd\c@page%
     \hrule \@height.2mm \@width\textwidth%
  \else%
     \hrule \@height.2mm \@width37mm
  \fi%
  \kern5.5\p@}%
%
\fi%
%
%
\setlength\parindent{1.5em}%
%
\def\StepUpCounter#1{\global\advance#1by 1\relax}%
\def\StepDownCounter#1{\global\advance#1by -1\relax}%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%% Standard LaTeX Packages %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\usepackage{graphicx}%
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{mathrsfs}%
\usepackage[figuresright]{rotating}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{program}%
\usepackage{listings}%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%% Pagination Settings %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Line spacing
\setlength\lineskip{1\p@}%
\setlength\normallineskip{1\p@}%
%%\renewcommand\baselinestretch{1.5}%
\parskip=0pt%
%
% Page break penalties
%
\@lowpenalty   51
\@medpenalty  151
\@highpenalty 301
%
% Disallow widows and orphans
%
\clubpenalty 10000
\widowpenalty 10000
%
% Disable page breaks before equations, allow pagebreaks after
% equations and discourage widow lines before equations.
%
\displaywidowpenalty 100
\predisplaypenalty   10000
\postdisplaypenalty  0
%
% Set these global demerits
%
\doublehyphendemerits 1000000   % corresponds to badness 800
\finalhyphendemerits  1000000  % corresponds to badness 1000
%
% Allow loose lines rather than overfull lines
%
\vbadness=9999
\tolerance=9999
%
% Allow breaking the page in the middle of a paragraph
%
\interlinepenalty 0
%
% Disallow breaking the page after a hyphenated line
\brokenpenalty 10000
%
% Hyphenation; don't split words into less than three characters
\lefthyphenmin=3
\righthyphenmin=3
%
% Float placement parameters
%
% The total number of floats that can be allowed on a page.
\setcounter{totalnumber}{3}
%
% The maximum number of floats at the top and bottom of a page.
\setcounter{topnumber}{5}
\setcounter{bottomnumber}{5}
%
% The maximum part of the top or bottom of a text page that can be
% occupied by floats. This is set so that at least four lines of text
% fit on the page.
\renewcommand\topfraction{.921}
\renewcommand\bottomfraction{.921}

% The minimum amount of a text page that must be occupied by text.
% This should accomodate four lines of text.
\renewcommand\textfraction{.13}

% The minimum amount of a float page that must be occupied by floats.
\renewcommand\floatpagefraction{.887}

% The same parameters repeated for double column output
\renewcommand\dbltopfraction{.88}
\renewcommand\dblfloatpagefraction{.88}

% Space between floats
\setlength\floatsep{18\p@ \@plus 4\p@ \@minus 2\p@}

% Space between floats and text
\setlength\textfloatsep{15\p@ \@plus 4\p@ \@minus 2\p@}

% Space above and below an inline figure
\setlength\intextsep   {18\p@ \@plus 4\p@ \@minus 2\p@}

% For double column floats
\setlength\dblfloatsep    {20\p@ \@plus 4\p@ \@minus 2\p@}
\setlength\dbltextfloatsep{15\p@ \@plus 4\p@ \@minus 2\p@}

\hyphenation{Figure Figures Table Tables Equation Equations Section Sections Appendix Theorem Lemma}


%
%%%%%%%%%%%%%%%%%%%%%%%%%%% Math Settings %%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%% For above/below spacing  
\def\eqnarray{%
   \stepcounter{equation}%
   \def\@currentlabel{\p@equation\theequation}%
   \global\@eqnswtrue
   \m@th
   \global\@eqcnt\z@
   \tabskip\@centering
   \let\\\@eqncr
   $$\everycr{}\halign to\displaywidth\bgroup
       \hskip\@centering$\displaystyle\tabskip\z@skip{##}$\@eqnsel
      &\global\@eqcnt\@ne\hskip \tw@\arraycolsep \hfil${##}$\hfil
      &\global\@eqcnt\tw@ \hskip \tw@\arraycolsep
         $\displaystyle{##}$\hfil\tabskip\@centering
      &\global\@eqcnt\thr@@ \hb@xt@\z@\bgroup\hss##\egroup
         \tabskip\z@skip
      \cr
}
\def\endeqnarray{%
      \@@eqncr
      \egroup
      \global\advance\c@equation\m@ne
   $$\@ignoretrue
}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%% Titles %%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\renewcommand\refname{References}%
\renewcommand\figurename{Fig.}% defined as per springer style 
\renewcommand\tablename{Table}%
\renewcommand\appendixname{Appendix}%
\renewcommand\abstractname{Abstract}%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%% Article Front Matter %%%%%%%%%%%%%%%%%%%%%%%%%%%
%

\def\raggedleft{\leftskip0pt plus 1fil\parfillskip=0pt\relax}%
\def\raggedright{\rightskip0pt plus 1fil\parfillskip=0pt\relax}%
\def\raggedcenter{\leftskip=0pt plus 0.5fil\rightskip=0pt plus 0.5fil%
\parfillskip=0pt\let\hb=\break}%
\def\titraggedcenter{\leftskip=12pt plus 0.5fil\rightskip=12pt plus 0.5fil%
\parfillskip=0pt\let\hb=\break}%
\def\absraggedcenter{\leftskip=24pt plus 0.5fil\rightskip=24pt plus 0.5fil%
\parfillskip=0pt\let\hb=\break}%

%
%%% Font Def
\def\Artcatfont{\reset@font\fontsize{8bp}{10bp}\selectfont}%
\def\Titlefont{\reset@font\fontsize{17bp}{22.5bp}\selectfont\titraggedcenter}%
\def\SubTitlefont{\reset@font\fontsize{14bp}{16.5bp}\selectfont\titraggedcenter}%
\def\Authorfont{\reset@font\fontsize{12bp}{14.5bp}\selectfont\boldmath\titraggedcenter}%
\def\addressfont{\reset@font\fontsize{11bp}{13.5bp}\selectfont\titraggedcenter}%
\def\abstractheadfont{\reset@font\fontsize{9bp}{11bp}\bfseries\selectfont\titraggedcenter}%
\def\abstractsubheadfont{\reset@font\fontsize{9bp}{11bp}\bfseries\selectfont}%
\def\abstractfont{\reset@font\fontsize{9bp}{11bp}\selectfont\leftskip=24pt\rightskip=24pt}%
\def\keywordfont{\reset@font\fontsize{8bp}{9.5bp}\selectfont\leftskip=24pt\rightskip=24pt plus0.5fill}%
\def\historyfont{\reset@font\fontsize{8bp}{9.5bp}\selectfont\leftskip=24pt\rightskip=24pt plus0.5fill}%

%% Article Type

\newbox\artcatbox%

\AtBeginDocument{\definecolor{artcatboxgray}{cmyk}{0.0,0.0,0.0,0.30}}%

\def\articletype#1{\if!#1!\else\setbox\artcatbox\hbox{\Artcatfont\hskip1mm#1\hskip1mm}\fi%
\gdef\ArtType{\fboxsep=0pt\colorbox{artcatboxgray}{\vbox to 4mm{\vfil%
              {\raggedright\box\artcatbox}\vfil}}}%
\gdef\@ArtType{#1}}%
%%\articletype{RESEARCH ARTICLE}%
\articletype{}%

%% Meta Info
\def\@jyear{{0000}}%
\def\jyear#1{\gdef\@jyear{#1}}%

%% Article Title

\renewcommand{\title}[2][]{%
\gdef\@checktitle{#1}\ifx\@checktitle\empty\gdef\@title{#2}%
\gdef\s@title{#2}\else\gdef\@title{#2}\gdef\s@title{#1}\fi%
\markboth{\textit{\s@title}}{\textit{\s@title}}}%

\def\subtitle#1{\gdef\@subtitle{#1}}\subtitle{}%

%% Cross Link for Author & Address
\def\jmkLabel#1{\@bsphack\protected@write\@auxout{}{\string\Newlabel{#1}{\@currentlabel}}\@esphack}%
\def\Newlabel#1#2{\expandafter\xdef\csname X@#1\endcsname{#2}}%
\def\jmkRef#1{\@ifundefined{X@#1}{0}{\csname X@#1\endcsname}}%

%% Article Author(s)
\let\sep\@empty%
\let\authorsep\@empty%
\newcount\aucount%
\newcount\corraucount%
\newcount\punctcount%
%
\def\artauthors{}%
\newif\if@auemail%
\newif\if@corauemail%
%
\def\au@and{\ifnum\punctcount=2\ and\else\unskip,\advance\punctcount by -1 \fi}%
%
\def\author{\advance\aucount by 1\@ifstar\@@corrauthor\@@author}%
%
\newcommand{\@@author}[2][]{\@corauemailfalse%
\g@addto@macro\artauthors{%
    \ifnum\aucount=1%
    \global\@auemailtrue%
    \else%
    \global\@auemailfalse%
    \fi%
    \Authorfont%
    \def\baselinestretch{1}%
    \authorsep{#2}\unskip\ifx#1\empty\else\textsuperscript{\smash{{%
      \@for\@@affmark:=#1\do{\edef\affnum{\@ifundefined{X@\@@affmark}{1}{\jmkRef{\@@affmark}}}%
     \unskip\sep\affnum\let\sep=,}}}}\fi%
    \def\authorsep{\au@and~}%%% 
    \global\let\sep\@empty\global\let\@corref\@empty%
}}%
%
\newcommand{\@@corrauthor}[2][]{\@corauemailtrue\advance\corraucount by 1%
\g@addto@macro\artauthors{%
    \global\@auemailtrue%
    \Authorfont%
    \def\baselinestretch{1}%
    \authorsep{#2}\unskip\ifx#1\empty\else\textsuperscript{\smash{{%
      \@for\@@affmark:=#1\do{\edef\affnum{\@ifundefined{X@\@@affmark}{1}{\jmkRef{\@@affmark}}}%
     \unskip\sep\affnum\let\sep=,}}}{*}\hskip-1pt}\fi\unskip%
    \def\authorsep{\au@and~}%%% 
    \global\let\sep\@empty\global\let\@corref\@empty%
}}%
%%
%% Miscellaneous macros %%
%%
\def\fnm#1{#1}%
\def\sur#1{#1}%
\def\spfx#1{#1}%
\def\pfx#1{#1}%
\def\sfx#1{#1}%
\def\tanm#1{#1}%
\def\dgr#1{#1}%
%
%% Author Email
%
\let\nomail\relax%
\def\corrauthemail{}%
\def\authemail{}%

\newcount\emailcnt%

\def\email#1{\global\advance\emailcnt by 1\relax%
\if@corauemail%
   \g@addto@macro\corrauthemail{%
   \setcounter{footnote}{0}%
   \textcolor{blue}{#1};\ %
   }%
\else%
   \g@addto@macro\authemail{%
   \setcounter{footnote}{0}%
   \textcolor{blue}{#1};\ %
   }%
\fi}

%% Corrseponding Address 
\def\@copycorthanks{}%
\def\auaddress{}%
\def\@auaddress{}%

\newcounter{affn}%
\newcount\addcount% To check the count of address

\renewcommand\theaffn{\arabic{affn}}%

\def\affil{\advance\addcount by 1\@ifstar\@@coraddress\@@address}%

\newcommand{\@@coraddress}[2][]{%\advance\addcount by 1
\g@addto@macro\auaddress{%
     \stepcounter{affn}%
     \xdef\@currentlabel{\theaffn}%
     \jmkLabel{\theaffn}%
     {\textsuperscript{#1*}#2.\par} }
}

%% Macros for present address

\newif\ifpresentaddress%

\def\@presentaddresstxt{}% 
\def\presentaddresstxt#1{\gdef\@presentaddresstxt{#1:}}\presentaddresstxt{Present Address}%
\newcommand{\presentaddress}[1]{\gdef\@presentaddresstext{\@presentaddresstxt\par#1}\global\presentaddresstrue}%

%% Macros for equally contributed

\newif\ifequalcont%

%\def\@equalconttxt{}% 
%\def\equalcontxt#1{\gdef\@equalconttxt{#1}}\equalcontxt{These authors contributed equally to this work.}%
%\newcommand{\equalcont}[1][\@equalconttxt]{\gdef\@equalconttext{#1}\g@addto@macro\artauthors{$^{\dagger}$}\global\equalconttrue}%

\def\@equalconttxt{}% 
\def\equalcontxt#1{\gdef\@equalconttxt{#1}}\equalcontxt{}%
\newcommand{\equalcont}[1]{\gdef\@equalconttext{#1}\g@addto@macro\artauthors{$^{\dagger}$}\global\equalconttrue}%

%% Author Address 

\newcommand{\@@address}[2][]{%%\advance\addcount by 1
\g@addto@macro\auaddress{%
     \stepcounter{affn}%
     \xdef\@currentlabel{\theaffn}%
     \jmkLabel{\theaffn}%
     {\textsuperscript{#1}#2.\par} }%\theaffn
}

%% Address tagging 
\newcommand{\orgdiv}[1]{#1}%
\newcommand{\orgname}[1]{#1}%
\newcommand{\orgaddress}[1]{#1}%
\newcommand{\street}[1]{#1}%
\newcommand{\postcode}[1]{#1}%
\newcommand{\city}[1]{#1}%
\newcommand{\state}[1]{#1}%
\newcommand{\country}[1]{#1}%

%% Article notes

\def\@artnote{}%
\def\artnote#1{\gdef\@artnote{#1}}%

%% Miscellaneous notes 

\def\@miscnote{}%
\def\miscnote#1{\gdef\@miscnote{\par\addvspace{3pt}#1}}%

%% Motto

\def\mottofont{\reset@font\fontfamily{\rmdefault}\fontsize{8.5bp}{10bp}\fontshape{it}\selectfont\raggedright}
%
\let\@motto\@empty
\def\mottoraggedright{\rightskip0mm\leftskip=42mm plus 1fil\parfillskip=0pt\relax}%
\newcommand{\motto}[2][]{\gdef\@headcheck{#1}\gdef\@motto{\@headcheck\ifx\@headcheck\@empty\vskip12pt\else\fi{\mottofont\mottoraggedright#2\par}}}

%% Article Abstract
\newcommand\abstracthead{\@startsection {section}{1}{\z@}{-22pt \@plus0ex \@minus0ex}{3pt}{\abstractheadfont}}
\newcommand\subabstracthead{\@startsection{subsection}{2}{\z@}{3pt \@plus0ex \@minus0ex}{-.5em}{\abstractsubheadfont}}

\def\@abstract{}%
\long\def\abstract#1 \par{\def\@abstract{%
\let\paragraph\subabstracthead%
\abstractfont%
\abstracthead*{\abstractname}%
#1\par}}%

\def\printabstract{\ifx\@abstract\empty\else\@abstract\fi\par}%

\def\printkeywords{\ifx\@keywords\empty\else\@keywords\fi\par}%

%
%% Keywords
\def\keywordname{Keywords}%
\def\keywords#1{\ifx#1\empty\else\def\@keywords{\par\addvspace{10pt}{\keywordfont{\bfseries\keywordname:} #1\par}}\fi}%
\def\@keywords{}%

%% PACs

\def\pacsbullet{\hbox{\hskip2.5pt,\hskip2.5pt}}%

\def\change@commas#1,#2{%
  \ifx#2\@empty%
    #1%
  \else%
    #1\nobreak\hbox{\pacsbullet}\allowbreak\expandafter\change@commas%
  \fi%
  #2}%

\newcommand\keywordhead[1]{\par\addvspace{10pt}%
{{\keywordfont\bfseries#1:\ }}}%

\newcommand{\pacs}[1]{\keywordhead{\pacsname}#1}%
%
\newcount\PacsCount%
\PacsCount=0%
%
\newcount\PacsTmpCnt%
\PacsTmpCnt=1%
%
\gdef\StorePacsText#1#2{%
\edef\GetRoman{\romannumeral#1}%
\expandafter\gdef\csname\GetRoman StorePacsTxt\endcsname{#2}%
}%
%
\let\oldpacs\pacs%
\renewcommand\pacs[2][PAC Codes]{\gdef\pacsname{{\bfseries#1}}\gdef\@pacs{\keywordfont\raggedright\oldpacs\change@commas#2,\@empty\par}
\StepUpCounter{\PacsCount}%
\StorePacsText{\the\PacsCount}{\gdef\pacsname{{\bfseries#1}}\keywordfont\raggedright\oldpacs\change@commas#2,\@empty}%
}%

\def\@pacs{}%

%% Glossary

\def\gloshead{Glossary}%

\newenvironment{glos}[1][\gloshead]{\begingroup\parindent=0pt%
\section*{#1}
\def\item[##1]{##1,\ }}{%
\endgroup}%
%

%% Article History

\def\received#1{\g@addto@macro\@history{{Received #1}}}%
\def\revised#1{\g@addto@macro\@history{{; revised #1}}}%
\def\accepted#1{\g@addto@macro\@history{{; accepted #1}}}%

%% Remark on Front page %%

\newdimen\FMremarkdim%

\newcommand{\FMremark}{\begingroup\parindent=0pt\parskip=0pt%
\if@referee\singlespacing\fi%
\fboxsep=6pt\fboxrule=0.5pt%
\FMremarkdim=\textwidth%%\paperwidth%
\advance\FMremarkdim-\fboxsep%
\advance\FMremarkdim-2\fboxrule%
\if@referee\vskip-21pt\fi%
%%\fbox{\vbox{\hsize=\FMremarkdim\small%
\unvbox\fmremarkbox
%%}}%
\endgroup}

\newbox\fmremarkbox%

\newenvironment{fmremark}{\begingroup\parindent=0pt%
\fboxsep=6pt\fboxrule=0.5pt%
\FMremarkdim=\textwidth%%\paperwidth%
\advance\FMremarkdim-\fboxsep%
\advance\FMremarkdim-2\fboxrule%
\global\setbox\fmremarkbox\vbox\bgroup\small%
}{\egroup\endgroup}

%% Article Header Definition
\renewcommand{\@maketitle}{\newpage\null%
    \if@remarkboxon\vbox to 0pt{\vspace*{-78pt}\hspace*{-18pt}\FMremark}\else\vskip21pt\fi%%\par%
    \hsize\textwidth\parindent0pt%%%\vskip7pt%
    %% Aritle Type
    {\hbox to \textwidth{{\Artcatfont\ArtType\hfill}\par}}
    %% Aritle Title
    \ifx\@title\empty\else%
        \removelastskip\vskip20pt\nointerlineskip%
        {\Titlefont\@title\par}
        %\addcontentsline{toc}{chapter}{\@title}% for bookmarks
    \fi%
    %% Aritle SubTitle
    \ifx\@subtitle\empty\else%
        \vskip9pt%
        {{\SubTitlefont\@subtitle\par}}
    \fi%
    %% Aritle Authors, Address and Correspondings
    \ifnum\aucount>0
        \global\punctcount\aucount%
        \vskip20pt%
        \artauthors\par%%     authors and emails
        {\vskip7pt\addressfont\auaddress\par%%      corresponding adress
	 \removelastskip\vskip24pt%
	\ifnum\emailcnt>0\relax%
           \ifx\corrauthemail\@empty\else{\ifnum\aucount>1*\fi}%
	   Corresponding author's E-mail: \corrauthemail\par\fi%
	   \ifx\authemail\@empty\else Contributing authors:\ \authemail\fi%
        \fi%
        \ifequalcont{\par$^{\dagger}$\@equalconttext\par}\fi%
	 \removelastskip\vskip24pt%
        \ifpresentaddress{\par\@presentaddresstext\par}\fi%
	}
     \fi%
     {\printabstract\par}%
     {\printkeywords\par}%
     \ifx\@pacs\empty\else%
       \loop\ifnum\PacsCount>0%
          \csname\romannumeral\PacsTmpCnt StorePacsTxt\endcsname\par%
          \StepDownCounter{\PacsCount}%
          \StepUpCounter{\PacsTmpCnt}%
       \repeat%
    \fi%
    %%{\printhistory\par}%
    %%{\ifx\@motto\empty\else\@motto\fi}%
    \removelastskip\vskip36pt\vskip0pt}%

%% Printing Article Header
\renewcommand\maketitle{\par
  \@afterindentfalse%
  \begingroup
    \gdef\UrlFont{\rmfamily}%
    \renewcommand\thefootnote{\@fnsymbol\c@footnote}%
    \def\@makefnmark{\rlap{\@textsuperscript{\normalfont\smash{\@thefnmark}}}}%
    \long\def\@makefntext##1{\parindent 1em\noindent\small\selectfont
            \hbox{\@textsuperscript{\normalfont\@thefnmark}}##1}%
    \thispagestyle{titlepage}%
    \if@twocolumn
      \ifnum \col@number=\@ne%
        \twocolumn[\@maketitle]%
      \else
        \twocolumn[\@maketitle]%
      \fi%
    \else%
      \newpage%
      \global\@topnum\z@% Prevents figures from going at top of page.
      \@maketitle%
    \fi%
    %%\thispagestyle{plain}%
  \endgroup%
  \ifx\@artnote\@empty\else\footnoteA{\@artnote}\fi%
  \ifx\@miscnote\@empty\else\footnoteA{\@miscnote\par}\fi%
  \setcounter{footnote}{0}%
  \global\let\thanks\relax%
  \global\let\artnote\relax%
  \global\let\maketitle\relax%
  \global\let\@maketitle\relax%
  \global\let\@thanks\@empty%
  \global\let\@author\@empty%
  \global\let\@date\@empty%
  \global\let\title\relax%
  \global\let\author\relax%
  \global\let\date\relax%
  \global\let\and\relax%
  \pagestyle{headings}%
  %%%print continuous abstract on next page
  \@afterheading%
  %%\vskip-18pt% this is included to avoid vertical space at the beginning of left column on article opening pages
}%

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Page Styles %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
\def\opheaderfont{\reset@font\fontsize{10bp}{0bp}\selectfont}%
\def\headerfont{\reset@font\fontsize{10bp}{0bp}\selectfont}%
\def\footerfont{\reset@font\fontsize{10bp}{0bp}\selectfont}%

%% Regular Page Style      
\def\ps@headings{%
    \def\@oddfoot{\hfill}%
    \let\@evenfoot\@oddfoot%
      %%\def\@evenhead{{\headerfont\thepage\qquad\rightmark\hfill\includegraphics{springer-nature-logo}}}%
      %%\def\@oddhead{{\headerfont\includegraphics{springer-nature-logo}\hfill\leftmark\qquad\thepage}}%
      %\def\@evenhead{%
      %\vbox to 0pt{\vspace*{-39pt}%
      %   \hbox to \hsize{\hfill Springer Nature 2021 \LaTeX\ template\hfill}}\par%%
      %\hspace*{-\textwidth}\hbox to \hsize{\headerfont\thepage\qquad\rightmark\hfill}}%
      %\def\@oddhead{%
      %\vbox to 0pt{\vspace*{-39pt}%
      %   \hbox to \hsize{\hfill Springer Nature 2021 \LaTeX\ template\hfill}}\par%%
      %\hspace*{-\textwidth}\hbox to \hsize{\headerfont\hfill\leftmark\qquad\thepage}}%
      %\let\@mkboth\markboth%
      }%

\newdimen\opshortpage%

\def\printcopyright#1{#1}%%

\gdef\@copyrighttext{}%
\gdef\@copyrightyear{\@jyear}%

\def\copytext#1#2{\gdef\@copyrightyear{#2}\def\@copyrighttext{\begin{minipage}[t]{\textwidth}\footerfont\textcopyright\ #1\ \@copyrightyear\end{minipage}}}

\copytext{Springer Science+Business Media B.V.}{\@jyear}%

\def\@opjournalheader{\leftmark\space\ {{(\@jyear),\ \textbf{\@jvol}:\@artid}} {\thepage{--}\pageref*{LastPage}}\\
{\@DOI}}%

%% Opening Page Style      
\def\ps@titlepage{%
     %%\def\@oddhead{\vbox{\vskip-36pt\hbox to \textwidth{\hfill\includegraphics{springer-nature-logo}\hspace*{-1pt}}}}%
     \let\@oddhead\@empty\let\@evenhead\@empty%
      %\def\@oddhead{%
      %\vbox to 0pt{\vspace*{-38pt}%
      %   \hbox to \hsize{\hfill \hfill}}}%%
     \let\@evenhead\@oddhead%
     \def\@oddfoot{\vbox to 18pt{\vfill\reset@font\rmfamily\hfil\thepage\hfil}}%%
     \def\@evenfoot{}}%

\def\ps@plain{\let\@mkboth\@gobbletwo%
\let\@oddhead\@empty\let\@evenhead\@empty%
\def\@oddfoot{\vbox to 18pt{\vfill\reset@font\rmfamily\hfil\thepage\hfil}}%
\let\@evenfoot\@oddfoot}%

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Sections %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%

\def\numbered{\setcounter{secnumdepth}{3}}%
\def\unnumbered{\setcounter{secnumdepth}{0}}%
\numbered%% default is numbered Sections

\renewcommand\thesection      {\@arabic\c@section}%
\renewcommand\thesubsection   {\thesection.\@arabic\c@subsection}%
\renewcommand\thesubsubsection{\thesubsection.\@arabic\c@subsubsection}%
\renewcommand\theparagraph    {\thesubsubsection.\@arabic\c@paragraph}%
\renewcommand\thesubparagraph {\theparagraph.\@arabic\c@subparagraph}%
%%
\def\@seccntformat#1{\csname the#1\endcsname\hskip.5em}%

\def\@sect#1#2#3#4#5#6[#7]#8{%
  \ifnum #2>\c@secnumdepth
    \let\@svsec\@empty
  \else
    \refstepcounter{#1}%
      \protected@edef\@svsec{\@seccntformat{#1}\relax}%
  \fi
  \@tempskipa #5\relax
  \ifdim \@tempskipa>\z@
    \begingroup
      #6{%
        \@hangfrom{\hskip #3\relax\@svsec}%
          \interlinepenalty \@M #8\@@par}%
    \endgroup
    \csname #1mark\endcsname{#7}%
    \addcontentsline{toc}{#1}{%
      \ifnum #2>\c@secnumdepth \else
        \protect\numberline{\csname the#1\endcsname}%
      \fi
      #7}%
  \else
    \def\@svsechd{%
      #6{\hskip #3\relax
      \@svsec #8.}%
      \csname #1mark\endcsname{#7}%
      \addcontentsline{toc}{#1}{%
        \ifnum #2>\c@secnumdepth \else
          \protect\numberline{\csname the#1\endcsname}%
        \fi
        #7}}%
  \fi
  \@xsect{#5}}
%
\def\sectionfont{\reset@font\fontfamily{\rmdefault}\fontsize{14bp}{16bp}\bfseries\selectfont\raggedright\boldmath}%
\def\subsectionfont{\reset@font\fontfamily{\rmdefault}\fontsize{12bp}{14bp}\bfseries\selectfont\raggedright\boldmath}%
\def\subsubsectionfont{\reset@font\fontsize{11bp}{13bp}\bfseries\selectfont\raggedright\boldmath}%
\def\paragraphfont{\reset@font\fontsize{10bp}{12bp}\bfseries\itshape\selectfont\raggedright}%
%
\def\subparagraphfont{\itshape}%
\def\bmheadfont{\reset@font\fontfamily{\rmdefault}\fontsize{10bp}{12bp}\bfseries\selectfont\raggedright\boldmath}%
%
\renewcommand\section{\@startsection{section}{1}{\z@}%
                                    {-12pt \@plus -4pt \@minus -2pt}%
                                    {9pt}%
                                    {\sectionfont}}
\renewcommand\subsection{\@startsection{subsection}{2}{\z@}%
                                       {-12pt \@plus -4pt \@minus -2pt}%
                                       {6pt}%
                                       {\subsectionfont}}
\renewcommand\subsubsection{\@startsection{subsubsection}{3}{\z@}%
                                          {-12pt \@plus -4pt \@minus -2pt}%
                                          {6pt}%
                                          {\subsubsectionfont}}
\renewcommand\paragraph{\@startsection{paragraph}{4}{\z@}%
                                      {-12pt \@plus -4pt \@minus-2pt}%
                                      {3pt}%
                                      {\paragraphfont}}
\renewcommand\subparagraph{\@startsection{subparagraph}{5}{\z@}%
                                         {6pt \@plus1ex \@minus.2ex}%
                                         {-1em}%
                                         {\subparagraphfont}}
\newcommand\bmhead{\@startsection{subparagraph}{5}{\z@}%
                                 {6pt \@plus1ex \@minus .2ex}%
                                 {-1em}%
                                 {\bmheadfont}}
%
\def\@startsection#1#2#3#4#5#6{%
  \if@noskipsec \leavevmode \fi
  \par
  \@tempskipa #4\relax
  \@afterindenttrue
  \ifdim \@tempskipa <\z@
    \@tempskipa -\@tempskipa \@afterindentfalse
  \fi
  \if@nobreak
    \everypar{}%
  \else
    \addpenalty\@secpenalty\addvspace\@tempskipa
  \fi
  \@ifstar
    {\@ssect{#3}{#4}{#5}{#6}}%
    {\@dblarg{\@sect{#1}{#2}{#3}{#4}{#5}{#6}}}}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Lists %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\newdimen\labelwidthi%
\newdimen\labelwidthii%
\newdimen\labelwidthiii%
\newdimen\labelwidthiv%

\def\normal@labelsep{0.5em}%
\labelsep\normal@labelsep%
\settowidth{\labelwidthi}{(iii)}%
\settowidth{\labelwidthii}{(d)}%
\settowidth{\labelwidthiii}{(iii)}%
\settowidth{\labelwidthiv}{(M)}%

\leftmargini\labelwidthi     \advance\leftmargini\labelsep
\leftmarginii\labelwidthii   \advance\leftmarginii\labelsep
\leftmarginiii\labelwidthiii \advance\leftmarginiii\labelsep
\leftmarginiv\labelwidthiv   \advance\leftmarginiv\labelsep

\def\setleftmargin#1#2{\settowidth{\@tempdima}{#2}\labelsep\normal@labelsep
  \csname labelwidth#1\endcsname\@tempdima
  \@tempdimb\@tempdima \advance\@tempdimb\labelsep
  \csname leftmargin#1\endcsname\@tempdimb}
\def\@listI{\leftmargin\leftmargini
  \labelwidth\labelwidthi \labelsep\normal@labelsep
  \topsep \z@ \partopsep\z@ \parsep\z@ \itemsep\z@
  \listparindent 1em}
\def\@listii{\leftmargin\leftmarginii
  \labelwidth\labelwidthii \labelsep\normal@labelsep
  \topsep\z@ \partopsep\z@ \parsep\z@ \itemsep\z@
  \listparindent 1em}
\def\@listiii{\leftmargin\leftmarginiii
  \labelwidth\labelwidthiii \labelsep\normal@labelsep
  \topsep\z@ \partopsep\z@ \parsep\z@ \itemsep\z@
  \listparindent 1em}
\def\@listiv{\leftmargin\leftmarginiv
  \labelwidth\labelwidthiv \labelsep\normal@labelsep
  \topsep\z@ \partopsep\z@ \parsep\z@ \itemsep\z@
  \listparindent 1em}
\let\@listi\@listI
\@listi
%
\setlength  \labelsep  {.5em}
\setlength  \labelwidth{\leftmargini}
\addtolength\labelwidth{-\labelsep}
\@beginparpenalty -\@lowpenalty
\@endparpenalty   -\@lowpenalty
\@itempenalty     -\@lowpenalty
\def\labelitemi{$\bullet$}          \def\labelitemii{$\cdot$}
\def\labelenumi{\theenumi.}         \def\theenumi{\arabic{enumi}}
\def\labelenumii{(\alph{enumii})}   \def\theenumii{\theenumi\alph{enumii}}
\def\labelenumiii{(\roman{enumiii})}\def\theenumiii{\theenumii.\roman{enumiii}}
\def\labelenumiv{(\Alph{enumiv})}   \def\theenumiv{\theenumiii.\Alph{enumiv}}

%
%%%%%%%%%%%%%%%%%%%%%%%%%%% Ordered & Unordered List  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\def\listfont{\normalsize}%
%
\def\enumargs{%
   \listfont%
   \leftmargini0pt%
   \leftmarginii0pt%
   \leftmarginiii0pt%
   \ifnum\@enumdepth=3\topsep0pt\else\ifnum\@enumdepth=2\topsep0pt\else\topsep 6pt\fi\fi%
   \partopsep     \z@%
   \itemsep       \z@%
   \parsep        \z@%
   \labelsep      0.5em%
   \rightmargin   \z@%
   \raggedright%   
   \listparindent \parindent%
   \itemindent    \z@}%

\def\enumerate{%
    \@ifnextchar[{\@numerate}{\@numerate[0.]}}

\def\@numerate[#1]{\par%
     \ifnum \@enumdepth >3 \@toodeep\else
     \advance\@enumdepth \@ne
     \edef\@enumctr{enum\romannumeral\the\@enumdepth}
     \list{\csname label\@enumctr\endcsname}{%
       \enumargs%
       \setlength{\leftmargin}{\csname leftmargin\romannumeral\the\@enumdepth\endcsname}
       \usecounter{\@enumctr}
       \settowidth\labelwidth{#1}
       \addtolength{\leftmargin}{\labelwidth}
       \addtolength{\leftmargin}{\labelsep}
       \def\makelabel##1{\hss\llap{##1}}}%
     \fi
   }
\let\endenumerate\endlist

%%Unnumbered list%%

\def\unenumargs{%
   \listfont%
   \leftmargini\parindent%
   \topsep6pt%
   \partopsep     \z@%
   \itemsep       \z@%
   \parsep        \z@%
   \labelsep      0\p@%
   \rightmargin   \z@%
   \raggedright%
   \listparindent \parindent%
   \itemindent    -12pt}%

\def\unenumerate{%
    \@ifnextchar[{\@unenumerate}{\@unenumerate[0.]}}

\def\@unenumerate[#1]{\par%
     \ifnum \@enumdepth >3 \@toodeep\else
     \advance\@enumdepth \@ne
     \edef\@enumctr{enum\romannumeral\the\@enumdepth}
     \list{}{%
       \unenumargs
       \setlength{\leftmargin}{\csname leftmargin\romannumeral\the\@enumdepth\endcsname}
       \usecounter{\@enumctr}
       \settowidth\labelwidth{#1}
       \addtolength{\leftmargin}{0pt}
       \addtolength{\leftmargin}{0pt}
       \def\makelabel##1{\hss\llap{##1}}}%
     \fi
   }

\let\endunenumerate\endlist%

%% bulleted list 

\def\itemargs{%
   \listfont%
   \leftmargini0pt%
   \leftmarginii0pt%
   \ifnum\@enumdepth=3\topsep0pt\else\ifnum\@enumdepth=2\topsep0pt\else\topsep 6pt\fi\fi%
   \partopsep     \z@%
   \itemsep       \z@%
   \parsep        \z@%
   \labelsep      0.5em%
   \rightmargin   \z@%
   \raggedright%
   \listparindent \z@%
   \itemindent    \z@}%

\renewcommand\labelitemi{\raise1pt\hbox{\textbullet}}%
\renewcommand\labelitemii{\textendash}%

\def\itemize{%
   \@ifnextchar[{\@itemize}{\@itemize[$\bullet$]}}

\def\@itemize[#1]{\par%
     \ifnum \@itemdepth >3 \@toodeep\else
     \advance\@itemdepth \@ne
     \edef\@itemctr{item\romannumeral\the\@itemdepth}
     \list{\csname label\@itemctr\endcsname}{%
       \itemargs
       \setlength{\leftmargin}{\csname leftmargin\romannumeral\the\@itemdepth\endcsname}
       \settowidth\labelwidth{#1}
       \addtolength{\leftmargin}{\labelwidth}
       \addtolength{\leftmargin}{\labelsep}
       \def\makelabel##1{\hss \llap{##1}}}%
     \fi
   }
\let\enditemize\endlist
%
\def\quote{\list{}{\itemindent\z@
   \leftmargin 1em \rightmargin \z@}%
\item[]}
\let\endquote\endlist
%
\def\descriptionlabel#1{\hspace\labelsep \itshape #1}
\def\description{\list{}{\labelwidth\z@
  \leftmargin \z@ \topsep6pt\itemindent \z@ %-\leftmargin
  \let\makelabel\descriptionlabel}}
\let\enddescription\endlist

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Float %%%%%%%%%%%%%%%%%%%%%%%%%%%%

\setlength\abovecaptionskip{2.25\p@}%
\setlength\belowcaptionskip{6\p@}%

\setlength\arraycolsep{2\p@}%
\setlength\tabcolsep{6\p@}%
\setlength\arrayrulewidth{.4\p@}%
\setlength\doublerulesep{2\p@}%
\setlength\tabbingsep{\labelsep}%

\def\fnum@figure{{\bfseries\figurename\space\thefigure}}%
\def\fnum@table{{\bfseries\tablename\space\thetable}}%

\def\FigName{figure}%

\long\def\@makecaption#1#2{%
    \ifx\FigName\@captype
      \vskip\abovecaptionskip
        \@figurecaption{#1}{#2}
    \else
        \@tablecaption{#1}{#2}
      \vskip\belowcaptionskip
    \fi%
}

%% Figure

\def\figurecaptionfont{\reset@font\fontfamily{\rmdefault}\fontsize{8}{9.5}\selectfont}%

\newdimen\figwidth%
\newdimen\figheight%
\newdimen\sidecapwidth
\newdimen\wrapcapline%
\newdimen\totalwrapline%
\newdimen\wraptotline%

%% Figures macro
\newbox\figurebox%
\newbox\wrapfigcapbox

\def\FIG#1#2{%
\setbox\figurebox\hbox{#1}%
%% Figure dimensions
\figwidth\wd\figurebox%
\figheight\ht\figurebox%
{\parbox{\hsize}{%
\centerline{\box\figurebox}%
%% Caption
#2}}}

%% Figures caption
\newbox\figcapbox
\newbox\capbox
\long\def\@figurecaption#1#2{{\figurecaptionfont{\bfseries#1}\hskip.7em#2\par}}%

\newenvironment{unnumfigure}{\begingroup\setlength{\topsep}{12pt}%
\begin{center}}{\end{center}\endgroup}

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\@ifpackageloaded{booktabs}{\cmidrulewidth=.15pt}{}%
%
\def\tablecaptionfont{\reset@font\fontsize{8bp}{9.5bp}\selectfont}%
\def\tablebodyfont{\reset@font\fontsize{8bp}{9.5bp}\selectfont}%
\def\tablecolheadfont{\reset@font\fontsize{8bp}{9.5bp}\selectfont\bfseries\boldmath}%
\def\tablefootnotefont{\reset@font\fontsize{8bp}{9.5bp}\selectfont}%

%% Table Macro

\newskip\headwidthskip%

\def\tabraggedcenter{\leftskip=0pt plus 0.5fil\rightskip=0pt plus 0.5fil\parfillskip=0pt}%

\newenvironment{@processtable}[4]{%
\setbox4=\hbox to \hsize{\hss%
\begin{minipage}[t]{#4}%
\tabraggedcenter%
\caption{#1}\par%
{\tablebodyfont\noindent\ignorespaces#2\par}\par\vglue6pt%
{\if!#3!\else{\tablefootnotefont#3}\fi}%
\end{minipage}%
\hss}%
\box4\par}%

\newcommand\TBL[3]{\begingroup%
%
\if!#1!\let\caption\relax\fi%
%
   \global\setbox\temptbox=\hbox{\bgroup{\tablebodyfont#2}\egroup}%
   \global\tempdime\wd\temptbox%
    \@processtable{#1}{\global\headwidthskip=\tempdime%
	 \vbox{#2}}{#3}{\tempdime}%
\endgroup}%

%% Table Caption
\newbox\tabcapbox%
\newbox\temptbox%
\newdimen\tempdime%
\newdimen\tabhtdime%

\long\def\@tablecaption#1#2{%
  \setbox\tabcapbox\vbox{\tablecaptionfont\raggedright%
  {\bfseries #1}{\hskip2mm}#2\vphantom{y}\par}%
  \box\tabcapbox%
}

%% Table Column Heads
\def\TCH#1{{\tablecolheadfont #1}}

%% Table Footnotes

\newenvironment{tablenotes}{\list{}{\setlength{\labelsep}{0pt}% 
\setlength{\labelwidth}{0pt}%
\setlength{\leftmargin}{0pt}%
\setlength{\rightmargin}{0pt}%
\setlength{\topsep}{-6pt}%
\setlength{\itemsep}{2pt}%
\setlength{\partopsep}{0pt}%
\setlength{\listparindent}{0em}%
\setlength{\parsep}{0pt}}%
\item\relax%
}{\endlist}%

\def\tnote#1{$^{#1}$}%%

%% Table Rules

\def\toprule{%\noalign{\vskip3pt}
\noalign{\ifnum0=`}\fi
  \hrule \@height 0\p@ \@width 0pt
  \hrule \@height 0.75\p@ % <- rule height
  \hrule \@height 5pt \@width 0pt
  \futurelet\@tempa\@xhline}
% Middle rule
\def\midrule{\noalign{\ifnum0=`}\fi%
  \hrule \@height 3pt \@width 0pt
  \hrule \@height .5pt % <- rule height
  \hrule \@height 5pt \@width 0pt
  \futurelet \@tempa\@xhline}
% Bottom rule
\def\botrule{\noalign{\ifnum0=`}\fi
  \hrule \@height 3pt \@width 0pt
  \hrule \@height 0.75\p@ % <- rule height
  \hrule \@height 3pt \@width 0pt
  \futurelet\@tempa\@xhline}
%
\def\@@@cmidrule[#1-#2]#3#4{\global\@cmidla#1\relax
    \global\advance\@cmidla\m@ne
    \ifnum\@cmidla>0\global\let\@gtempa\@cmidrulea\else
    \global\let\@gtempa\@cmidruleb\fi
    \global\@cmidlb#2\relax
    \global\advance\@cmidlb-\@cmidla
    \global\@thisrulewidth=#3
    \@setrulekerning{#4}
    \ifnum\@lastruleclass=\z@\vskip 3\p@\fi
    \ifnum0=`{\fi}\@gtempa
    \noalign{\ifnum0=`}\fi\futurenonspacelet\@tempa\@xcmidrule}
\def\@xcmidrule{%
   \ifx\@tempa\cmidrule
       \vskip-\@thisrulewidth
       \global\@lastruleclass=\@ne
   \else \ifx\@tempa\morecmidrules
       \vskip \cmidrulesep
       \global\@lastruleclass=\@ne\else
       \vskip 5\p@
       \global\@lastruleclass=\z@
   \fi\fi
   \ifnum0=`{\fi}}
\let\cline\cmidrule

\let\tableorg\table%
\let\endtableorg\endtable%

\renewenvironment{table}[1][]%
{\begin{tableorg}[#1]%
\tablebodyfont%
\renewcommand\footnotetext[2][]{{\removelastskip\vskip3pt%
\let\tablebodyfont\tablefootnotefont%
\hskip0pt\if!##1!\else{\smash{$^{##1}$}}\fi##2\par}}%
}{\end{tableorg}}

% \let\sidewaystableorg\sidewaystable%
% \let\endsidewaystableorg\endsidewaystable%
% 
% \newenvironment{sidewaystable}%
% {\begin{sidewaystableorg}%
% \tablebodyfont%
% \renewcommand\@makefntext[1]{{\vskip3pt%
% \let\tablebodyfont\tablefootnotefont%
% \hskip0pt{\smash{\@makefnmark}}##1\par}}%
% }{\end{sidewaystableorg}}

\def\sidewaystablefn{\renewcommand\footnotetext[2][]{{\removelastskip\vskip3pt%
\let\tablebodyfont\tablefootnotefont%
\hskip0pt\if!##1!\else{\smash{$^{##1}$}}\fi##2\par}}%
}%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%% Other Env. %%%%%%%%%%%%%%%%%%%%%%%%%
%

\def\quotefont{\reset@font\fontfamily{\rmdefault}\fontsize{9}{11}\selectfont}%

\renewenvironment{quote}
               {\list{}{\topsep=0pt\topsep6pt\leftmargin=1em\raggedright\quotefont}%
                \item\relax}
               {\endlist}
               
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%% Appendix %%%%%%%%%%%%%%%%%%%%%%%%%
%

\newif\ifbackmatter%
\newcommand{\backmatter}{\global\backmattertrue}%

\usepackage[title]{appendix}%

\@ifpackageloaded{appendix}{%
%
\renewenvironment{appendices}{%
  \@resets@pp
  \if@dotoc@pp
    \if@dopage@pp              % both page and toc
      \if@chapter@pp           % chapters
        \clear@ppage
      \fi
      \appendixpage
    \else                      % toc only
       \if@chapter@pp          % chapters
         \clear@ppage
       \fi
      \addappheadtotoc
    \fi
  \else
    \if@dopage@pp              % page only
      \appendixpage
    \fi
  \fi
  \if@chapter@pp
    \if@dotitletoc@pp \@redotocentry@pp{chapter} \fi
  \else
    \if@dotitletoc@pp \@redotocentry@pp{section} \fi
    \if@dohead@pp
      \def\sectionmark##1{%
        \if@twoside
          \markboth{\@formatsecmark@pp{##1}}{}
        \else
          \markright{\@formatsecmark@pp{##1}}{}
        \fi}
    \fi
    \if@dotitle@pp
      \def\sectionname{\appendixname}
      \def\@seccntformat##1{\@ifundefined{##1name}{}{\csname ##1name\endcsname\ }%
        \csname the##1\endcsname\quad}
    \fi
  \fi
}{%
  \@ppsaveapp\@pprestoresec}
%%
\AtBeginDocument{%
%
\let\oldappendices\appendices%
\let\oldendappendices\endappendices%
%%
\renewenvironment{appendices}{%
\setcounter{figure}{0}%
\setcounter{table}{0}%
\setcounter{equation}{0}%
%%
\begin{oldappendices}%
  \gdef\thefigure{\@Alph\c@section\arabic{figure}}%
  \gdef\thetable{\@Alph\c@section\arabic{table}}%
  \gdef\theequation{\@Alph\c@section\arabic{equation}}%
}{\end{oldappendices}}
}
%%
}{}            


%
%%%%%%%%%%%%%%%%%%%%%%%%%%% Article History  %%%%%%%%%%%%%%%%%%%%
%
\def\@history{}
\def\printhistory{{\par\addvspace{8pt}%
\historyfont\noindent%
\ifx\@history\empty\gdef\@history{Received xx xxx xxxx}\fi\@history\par}}%
%
%%%%%%%%%%%%%%%%%%%%%%% Footnotes %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
\renewcommand\@makefntext[1]{%
    \hskip8pt{\smash{\@makefnmark}}#1}
%
\RequirePackage[backref=page]{hyperref}%
%%\RequirePackage{hypcap}%
\gdef\breakurldefns{%
\if@pdflatex\else%
\RequirePackage[hyphenbreaks]{breakurl}%
\let\href\burlalt%
\fi}%
\breakurldefns%
%    \bgroup
%      \catcode`\&=12\relax
%      \hyper@normalise\burl@addtocharlistbefore{%}
%      \hyper@normalise\burl@addtocharlistafter{:/.?#&_,;!=+~}%% for extra breaks in url
%    \egroup
%    \burl@defifstructure
%
\hypersetup{%
        colorlinks,
        breaklinks=true,
        plainpages=false,%
        citecolor=blue,
        linkcolor=blue,
        urlcolor=blue,
        bookmarksopen=true,%
        bookmarksnumbered=false,%
        bookmarksdepth=5%
}
%
\AtBeginDocument{\renewcommand\UrlFont{\rmfamily}}%
%
\AtBeginDocument{%
\@ifpackageloaded{natbib}{%
  \renewcommand\bibsection{%
   \section*{\refname}%
  }%
}{}%
}%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\pagestyle{headings}%
\pagenumbering{arabic}%
\sloppy%
\frenchspacing%
\flushbottom%

%%% special parameters for TeX
\adjdemerits=100
\linepenalty=100
%
%%%%%%%%%%%%%%% Biography
%
\RequirePackage{wrapfig}%
%
%
%  \begin{wrapfigure}[12]{r}[34pt]{5cm} <figure> \end{wrapfigure}
%                     --  -  ----  ---
%  [number of narrow lines] {placement} [overhang] {width of figure}
\newcount\wraplines%
%%\wraplines=5%
%
\newbox\@authorfigbox%
\newskip\@authorfigboxdim%
%
\newskip\biofigadjskip%
\biofigadjskip=0pt%
%
\def\authbiotextfont{\reset@font\fontsize{8bp}{9.5bp}\selectfont}%
%
\newenvironment{biography}[2]{\par\addvspace{11.5pt plus3.375pt minus1.6875pt}%\lineno@off%
\def\author##1{{\bfseries##1}}%
\if!#1!\def\@authorfig{}\else\def\@authorfig{{#1}}\fi%
\setbox\@authorfigbox=\hbox{#1}%
\@authorfigboxdim=\wd\@authorfigbox%
\if@iicol\advance\@authorfigboxdim by -10pt\else\advance\@authorfigboxdim by -2pt\fi%
\wraplines=9\fboxrule=1pt\fboxsep=6pt%
\noindent{%
\ifx\@authorfig\@empty\else\unskip%
\begin{wrapfigure}[\wraplines]{l}[0pt]{\@authorfigboxdim}%{38.25mm}%
\vskip-19pt\addvspace{\biofigadjskip}%
\@authorfig%
\end{wrapfigure}%
\fi%
{\authbiotextfont#2\par}%
\par%
}}{\par\addvspace{10.5pt plus3.375pt minus1.6875pt}}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Theorem %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
\@ifpackageloaded{amsthm}{%
%
%\let\proof\relax%
%\let\endproof\relax%

\def\@begintheorem#1#2[#3]{%
  \deferred@thm@head{\the\thm@headfont \thm@indent
    \@ifempty{#1}{\let\thmname\@gobble}{\let\thmname\@iden}%
    \@ifempty{#2}{\let\thmnumber\@gobble}{\let\thmnumber\@iden}%
    \@ifempty{#3}{\let\thmnote\@gobble}{\let\thmnote\@iden}%
    \thm@swap\swappedhead\thmhead{#1}{#2}{#3}%
    \the\thm@headpunct
    \thmheadnl % possibly a newline.
    \hskip\thm@headsep
  }%
  \ignorespaces
}

\def\@endtheorem{\endtrivlist\@endpefalse}


\AtBeginDocument{%
%
\DeclareSymbolFont{AMSa}{U}{msa}{m}{n}%
\DeclareMathSymbol{\opensquare}{\mathord}{AMSa}{"03}%
\def\qedsymbol{\opensquare}%
%
\newenvironment{spiproof}[1][\proofname]{\par\removelastskip%\vspace*{2pt}%
  \pushQED{\qed}%
  \small\normalfont \topsep7.5\p@\@plus7.5\p@\relax%
  \trivlist%
  \item[\hskip\labelsep%
        \itshape%
    #1\@addpunct{}]\ignorespaces%
}{%
  \popQED\endtrivlist\@endpefalse%
}%
%
\let\proof\spiproof\let\endproof\endspiproof% 
%
}%
%
\def\thm@space@setup{%
\thm@preskip=12pt%
\thm@postskip=12pt}
%
%%%%%%%%%%%%%%%%%% StyleOne
%
\newtheoremstyle{thmstyleone}% Numbered
{18pt plus2pt minus1pt}% Space above
{18pt plus2pt minus1pt}% Space below
{\small\itshape}% Body font
{0pt}% Indent amount
{\small\bfseries}% Theorem head font
{}% Punctuation after theorem head
{.5em}% Space after theorem headi
{\thmname{#1}\thmnumber{\@ifnotempty{#1}{ }\@upn{#2}}%
  \thmnote{ {\the\thm@notefont(#3)}}}% Theorem head spec (can be left empty, meaning `normal')
%
\newtheoremstyle{thmstyletwo}% Numbered
{18pt plus2pt minus1pt}% Space above
{18pt plus2pt minus1pt}% Space below
{\small\normalfont}% Body font
{0pt}% Indent amount
{\small\itshape}% Theorem head font
{}% Punctuation after theorem head
{.5em}% Space after theorem headi
{\thmname{#1}\thmnumber{\@ifnotempty{#1}{ }{#2}}%
  \thmnote{ {\the\thm@notefont(#3)}}}% Theorem head spec (can be left empty, meaning `normal')
%
\newtheoremstyle{thmstylethree}% Definition
{18pt plus2pt minus1pt}% Space above
{18pt plus2pt minus1pt}% Space below
{\small\normalfont}% Body font
{0pt}% Indent amount
{\small\bfseries}% Theorem head font
{}% Punctuation after theorem head
{.5em}% Space after theorem headi
{\thmname{#1}\thmnumber{\@ifnotempty{#1}{ }\@upn{#2}}%
  \thmnote{ {\the\thm@notefont(#3)}}}% Theorem head spec (can be left empty, meaning `normal')
%
\newtheoremstyle{thmstylefour}% Proof
{18pt plus2pt minus1pt}% Space above
{18pt plus2pt minus1pt}% Space below
{\small\normalfont}% Body font
{0pt}% Indent amount
{\small\itshape}% Theorem head font
{}% Punctuation after theorem head
{.5em}% Space after theorem headi
{\global\proofthmtrue\thmname{#1} \thmnote{#3}}% Theorem head spec (can be left empty, meaning `normal')
%
}{}

%% Macros for bibliographystyles %%

% \def\bibcommenthead{\if@bibcomment\begingroup\parindent=0pt\parskip=0pt%
% \removelastskip\vskip13pt\nointerlineskip%
% 
% \vbox{\bibfont If you are submitting to one of the Nature Research journals, using the eJP 
%  submission system, please include the references within the manuscript file itself. You may 
%  do this by copying the reference list from your .bbl file, and pasting it into the bibliography
%  environment of the main manuscript .tex file.}\par%
% \removelastskip\nobreak\vskip13pt\nobreak%
% \endgroup\fi}%

\def\bibcommenthead{}%

\if@Spr@basic@refstyle%
  \usepackage[authoryear]{natbib}%
  \gdef\NumBib{NO}%
  \bibliographystyle{sn-basic}%
  \setlength{\bibsep}{1em}%
  \def\bibfont{\reset@font\fontfamily{\rmdefault}\normalsize\selectfont}%
\fi%
\if@Mathphys@refstyle%
  \usepackage[numbers,sort&compress]{natbib}%
  \gdef\NumBib{YES}%
  \bibliographystyle{sn-mathphys}%
  \setlength{\bibsep}{1em}%
  \def\bibfont{\reset@font\fontfamily{\rmdefault}\normalsize\selectfont}%
\fi%
\if@APS@refstyle%
  \usepackage[numbers,sort&compress]{natbib}%
  \gdef\NumBib{YES}%
  \bibliographystyle{sn-APS}%
  \setlength{\bibsep}{1em}%
  \def\bibfont{\reset@font\fontfamily{\rmdefault}\normalsize\selectfont}%
\fi%
\if@Vancouver@refstyle%
  \usepackage[numbers,sort&compress]{natbib}%
  \gdef\NumBib{YES}%
  \bibliographystyle{sn-vancouver}%
  \setlength{\bibsep}{1em}%
  \def\bibfont{\reset@font\fontfamily{\rmdefault}\normalsize\selectfont}%
\fi%
\if@APA@refstyle%
  \usepackage[natbibapa]{apacite}%
  \gdef\NumBib{NO}%
  \bibliographystyle{sn-apacite}%
  \def\refdoi#1{\urlstyle{rm}\url{#1}}%
  \renewcommand{\doiprefix}{}%
  \AtBeginDocument{%
    \renewcommand{\BPBI}{.}% Period between initials - command from apacite.sty
  }%
  \setlength{\bibsep}{1em}%
  \def\bibfont{\reset@font\fontfamily{\rmdefault}\normalsize\selectfont}%
\fi%
\if@Chicago@refstyle%
  \usepackage[authoryear]{natbib}%
  \gdef\NumBib{NO}%
  \bibliographystyle{sn-chicago}%
  \hypersetup{urlcolor=black,colorlinks=false,pdfborder={0 0 0}}\urlstyle{same}%
  \setlength{\bibsep}{1em}%
  \def\bibfont{\reset@font\fontfamily{\rmdefault}\normalsize\selectfont}%
\fi%
\if@Standard@Nature@refstyle%
  \usepackage[numbers,sort&compress]{natbib}%
  \gdef\NumBib{YES}%
  \bibliographystyle{sn-standardNature}%
  \setlength{\bibsep}{1em}%
  \def\bibfont{\reset@font\fontfamily{\rmdefault}\normalsize\selectfont}%
\fi%
\if@Default@refstyle%
  \usepackage[numbers,sort&compress]{natbib}%
  \gdef\NumBib{YES}%
  \setlength{\bibsep}{1em}%
  \def\bibfont{\reset@font\fontfamily{\rmdefault}\normalsize\selectfont}%
\fi%

\AtBeginDocument{\allowdisplaybreaks}%

\def\eqnheadfont{\reset@font\fontfamily{\rmdefault}\fontsize{16}{18}\bfseries\selectfont}%

\newcommand{\eqnhead}[1]{\begingroup%
\begin{center}
{\eqnheadfont #1}\par%
\end{center}
\removelastskip\vskip24pt%
\thispagestyle{titlepage}%%
%%\thispagestyle{empty}%
\endgroup}

%% Macros for border matrix %%

\newif\if@borderstar

\def\bordermatrix{\@ifnextchar*{%
\@borderstartrue\@bordermatrix@i}{\@borderstarfalse\@bordermatrix@i*}%
}
\def\@bordermatrix@i*{\@ifnextchar[{\@bordermatrix@ii}{\@bordermatrix@ii[()]}}
\def\@bordermatrix@ii[#1]#2{%
\begingroup
\m@th\@tempdima8.75\p@\setbox\z@\vbox{%
\def\cr{\crcr\noalign{\kern 2\p@\global\let\cr\endline }}%
\ialign {$##$\hfil\kern 2\p@\kern\@tempdima & \thinspace %
\hfil $##$\hfil && \quad\hfil $##$\hfil\crcr\omit\strut %
\hfil\crcr\noalign{\kern -\baselineskip}#2\crcr\omit %
\strut\cr}}%
\setbox\tw@\vbox{\unvcopy\z@\global\setbox\@ne\lastbox}%
\setbox\tw@\hbox{\unhbox\@ne\unskip\global\setbox\@ne\lastbox}%
\setbox\tw@\hbox{%
$\kern\wd\@ne\kern -\@tempdima\left\@firstoftwo#1%
\if@borderstar\kern2pt\else\kern -\wd\@ne\fi%
\global\setbox\@ne\vbox{\box\@ne\if@borderstar\else\kern 2\p@\fi}%
\vcenter{\if@borderstar\else\kern -\ht\@ne\fi%
\unvbox\z@\kern-\if@borderstar2\fi\baselineskip}%
\if@borderstar\kern-2\@tempdima\kern2\p@\else\,\fi\right\@secondoftwo#1 $%
}\null \;\vbox{\kern\ht\@ne\box\tw@}%
\endgroup
}

%% Macros for line numbers %%

\if@vrulerlinenumberon%
%
\usepackage{vruler}%
%
%%\setvruler[<SCALE>][<INITIAL_COUNT>][<STEP>][<DIGITS>][<MODE>][<ODD_HSHIFT]>][<EVEN_HSHIFT>][<VSHIFT>][<HEIGHT>]
\def\linenoon{%%\definecolor{blue}{gray}{0}% 
\def\tiny{\normalsize\color{black}}%
\setvruler[12bp][1][1][3][1][1.18\textwidth][26pt][-7pt][0.99\textheight]% for even pages: left side; for odd pages: right side;
%%\linkbluecolor
}%
\linenoon%
\def\lineno@off{\unsetvruler}%
\fi%

%% url macros %%

\endinput

\end{filecontents}

\begin{filecontents}{sn-standardnature.bst}
ENTRY
  { address
    archive
    author
    booktitle
    chapter
    edition
    editor
    eprint
    howpublished
    institution
    journal
    key
    keywords
    month
    note
    number
    organization
    pages
    publisher
    school
    series
    title
    type
    url
    doi
    volume
    year
    archivePrefix
    primaryClass
    eid
    adsurl
    adsnote
    version
  }
  {}
  { label }
INTEGERS { output.state before.all mid.sentence after.sentence after.block }
FUNCTION {init.state.consts}
{ #0 'before.all :=
  #1 'mid.sentence :=
  #2 'after.sentence :=
  #3 'after.block :=
}
STRINGS { s t}
FUNCTION {output.nonnull}
{ 's :=
  output.state mid.sentence =
    { ", " * write$ }
    { output.state after.block =
        { add.period$ write$
          newline$
          "\newblock " write$
        }
        { output.state before.all =
            'write$
            { add.period$ " " * write$ }
          if$
        }
      if$
      mid.sentence 'output.state :=
    }
  if$
  s
}

FUNCTION {output.in.nonnull}
{ 's :=
  output.state mid.sentence =
    { ", " * write$ }
    { output.state after.block =
        { add.period$ write$
          newline$
          "\newblock " write$
        }
        { output.state before.all =
            'write$
            { add.period$ " " * write$ }
          if$
        }
      if$
      mid.sentence 'output.state :=
    }
  if$
  s
}
FUNCTION {output}
{ duplicate$ empty$
    'pop$
    'output.nonnull
  if$
}
FUNCTION {output.check}
{ 't :=
  duplicate$ empty$
    { pop$ "empty " t * " in " * cite$ * warning$ }
    'output.nonnull
  if$
}

FUNCTION {in.output.check}
{ 't :=
  duplicate$ empty$
    { pop$ "empty " t * " in " * cite$ * warning$ }
    'output.in.nonnull
  if$
}
FUNCTION {fin.entry}
{ add.period$
  write$
  newline$
}

FUNCTION {new.block}
{ output.state before.all =
    'skip$
    { after.block 'output.state := }
  if$
}
FUNCTION {new.sentence}
{ output.state after.block =
    'skip$
    { output.state before.all =
        'skip$
        { after.sentence 'output.state := }
      if$
    }
  if$
}
FUNCTION {add.blank}
{  " " * before.all 'output.state :=
}

FUNCTION {date.block}
{
  new.block
}

FUNCTION {not}
{   { #0 }
    { #1 }
  if$
}
FUNCTION {and}
{   'skip$
    { pop$ #0 }
  if$
}
FUNCTION {or}
{   { pop$ #1 }
    'skip$
  if$
}
FUNCTION {new.block.checka}
{ empty$
    'skip$
    'new.block
  if$
}
FUNCTION {new.block.checkb}
{ empty$
  swap$ empty$
  and
    'skip$
    'new.block
  if$
}
FUNCTION {new.sentence.checka}
{ empty$
    'skip$
    'new.sentence
  if$
}
FUNCTION {new.sentence.checkb}
{ empty$
  swap$ empty$
  and
    'skip$
    'new.sentence
  if$
}
FUNCTION {field.or.null}
{ duplicate$ empty$
    { pop$ "" }
    'skip$
  if$
}
FUNCTION {emphasize}
{ duplicate$ empty$
    { pop$ "" }
    { "\emph{" swap$ * "}" * }
  if$
}
FUNCTION {bolden}
{ duplicate$ empty$
    { pop$ "" }
    { "\textbf{" swap$ * "}" * }
  if$
}
FUNCTION {tie.or.space.prefix}
{ duplicate$ text.length$ #3 <
    { "~" }
    { " " }
  if$
  swap$
}

FUNCTION {capitalize}
{ "u" change.case$ "t" change.case$ }

FUNCTION {space.word}
{ " " swap$ * " " * }
 % Here are the language-specific definitions for explicit words.
 % Each function has a name bbl.xxx where xxx is the English word.
 % The language selected here is ENGLISH
FUNCTION {bbl.and}
{ "and"}

FUNCTION {bbl.etal}
{ "et~al." }

FUNCTION {bbl.in.editors}
{ "eds " }

FUNCTION {bbl.editors}
{ "eds" }

FUNCTION {bbl.editor}
{ "ed." }

FUNCTION {bbl.edby}
{ "edited by" }

FUNCTION {bbl.edition}
{ "edn" }

FUNCTION {bbl.volume}
{ "Vol." }

FUNCTION {bbl.of}
{ "of" }

FUNCTION {bbl.number}
{ "no." }

FUNCTION {bbl.nr}
{ "no." }

FUNCTION {bbl.in}
{ "in" }

FUNCTION {bbl.pages}
{ "" }

FUNCTION {bbl.page}
{ "" }

FUNCTION {bbl.chapter}
{ "Ch." }

FUNCTION {bbl.techrep}
{ "Tech. Rep." }

FUNCTION {bbl.mthesis}
{ "Master's thesis" }

FUNCTION {bbl.phdthesis}
{ "Ph.D. thesis" }

MACRO {jan} {"Jan."}

MACRO {feb} {"Feb."}

MACRO {mar} {"Mar."}

MACRO {apr} {"Apr."}

MACRO {may} {"May"}

MACRO {jun} {"Jun."}

MACRO {jul} {"Jul."}

MACRO {aug} {"Aug."}

MACRO {sep} {"Sep."}

MACRO {oct} {"Oct."}

MACRO {nov} {"Nov."}

MACRO {dec} {"Dec."}

 %-------------------------------------------------------------------
 % Begin module:
 % \ProvidesFile{physjour.mbs}[2002/01/14 2.2 (PWD)]
MACRO {aa}{"Astron. \& Astrophys."}
MACRO {aasup}{"Astron. \& Astrophys. Suppl. Ser."}
MACRO {aj} {"Astron. J."}
MACRO {aph} {"Acta Phys."}
MACRO {advp} {"Adv. Phys."}
MACRO {ajp} {"Amer. J. Phys."}
MACRO {ajm} {"Amer. J. Math."}
MACRO {amsci} {"Amer. Sci."}
MACRO {anofd} {"Ann. Fluid Dyn."}
MACRO {am} {"Ann. Math."}
MACRO {ap} {"Ann. Phys. (NY)"}
MACRO {adp} {"Ann. Phys. (Leipzig)"}
MACRO {ao} {"Appl. Opt."}
MACRO {apl} {"Appl. Phys. Lett."}
MACRO {app} {"Astroparticle Phys."}
MACRO {apj} {"Astrophys. J."}
MACRO {apjsup} {"Astrophys. J. Suppl."}
MACRO {apss} {"Astrophys. Space Sci."}
MACRO {araa} {"Ann. Rev. Astron. Astrophys."}
MACRO {baas} {"Bull. Amer. Astron. Soc."}
MACRO {baps} {"Bull. Amer. Phys. Soc."}
MACRO {cmp} {"Comm. Math. Phys."}
MACRO {cpam} {"Commun. Pure Appl. Math."}
MACRO {cppcf} {"Comm. Plasma Phys. \& Controlled Fusion"}
MACRO {cpc} {"Comp. Phys. Comm."}
MACRO {cqg} {"Class. Quant. Grav."}
MACRO {cra} {"C. R. Acad. Sci. A"}
MACRO {fed} {"Fusion Eng. \& Design"}
MACRO {ft} {"Fusion Tech."}
MACRO {grg} {"Gen. Relativ. Gravit."}
MACRO {ieeens} {"IEEE Trans. Nucl. Sci."}
MACRO {ieeeps} {"IEEE Trans. Plasma Sci."}
MACRO {ijimw} {"Interntl. J. Infrared \& Millimeter Waves"}
MACRO {ip} {"Infrared Phys."}
MACRO {irp} {"Infrared Phys."}
MACRO {jap} {"J. Appl. Phys."}
MACRO {jasa} {"J. Acoust. Soc. America"}
MACRO {jcp} {"J. Comp. Phys."}
MACRO {jetp} {"Sov. Phys.--JETP"}
MACRO {jfe} {"J. Fusion Energy"}
MACRO {jfm} {"J. Fluid Mech."}
MACRO {jmp} {"J. Math. Phys."}
MACRO {jne} {"J. Nucl. Energy"}
MACRO {jnec} {"J. Nucl. Energy, C: Plasma Phys., Accelerators, Thermonucl. Res."}
MACRO {jnm} {"J. Nucl. Mat."}
MACRO {jpc} {"J. Phys. Chem."}
MACRO {jpp} {"J. Plasma Phys."}
MACRO {jpsj} {"J. Phys. Soc. Japan"}
MACRO {jsi} {"J. Sci. Instrum."}
MACRO {jvst} {"J. Vac. Sci. \& Tech."}
MACRO {nat} {"Nature"}
MACRO {nature} {"Nature"}
MACRO {nedf} {"Nucl. Eng. \& Design/Fusion"}
MACRO {nf} {"Nucl. Fusion"}
MACRO {nim} {"Nucl. Inst. \& Meth."}
MACRO {nimpr} {"Nucl. Inst. \& Meth. in Phys. Res."}
MACRO {np} {"Nucl. Phys."}
MACRO {npb} {"Nucl. Phys. B"}
MACRO {nt/f} {"Nucl. Tech./Fusion"}
MACRO {npbpc} {"Nucl. Phys. B (Proc. Suppl.)"}
MACRO {inc} {"Nuovo Cimento"}
MACRO {nc} {"Nuovo Cimento"}
MACRO {pf} {"Phys. Fluids"}
MACRO {pfa} {"Phys. Fluids A: Fluid Dyn."}
MACRO {pfb} {"Phys. Fluids B: Plasma Phys."}
MACRO {pl} {"Phys. Lett."}
MACRO {pla} {"Phys. Lett. A"}
MACRO {plb} {"Phys. Lett. B"}
MACRO {prep} {"Phys. Rep."}
MACRO {pnas} {"Proc. Nat. Acad. Sci. USA"}
MACRO {pp} {"Phys. Plasmas"}
MACRO {ppcf} {"Plasma Phys. \& Controlled Fusion"}
MACRO {phitrsl} {"Philos. Trans. Roy. Soc. London"}
MACRO {prl} {"Phys. Rev. Lett."}
MACRO {pr} {"Phys. Rev."}
MACRO {physrev} {"Phys. Rev."}
MACRO {pra} {"Phys. Rev. A"}
MACRO {prb} {"Phys. Rev. B"}
MACRO {prc} {"Phys. Rev. C"}
MACRO {prd} {"Phys. Rev. D"}
MACRO {pre} {"Phys. Rev. E"}
MACRO {ps} {"Phys. Scripta"}
MACRO {procrsl} {"Proc. Roy. Soc. London"}
MACRO {rmp} {"Rev. Mod. Phys."}
MACRO {rsi} {"Rev. Sci. Inst."}
MACRO {science} {"Science"}
MACRO {sciam} {"Sci. Am."}
MACRO {sam} {"Stud. Appl. Math."}
MACRO {sjpp} {"Sov. J. Plasma Phys."}
MACRO {spd} {"Sov. Phys.--Doklady"}
MACRO {sptp} {"Sov. Phys.--Tech. Phys."}
MACRO {spu} {"Sov. Phys.--Uspeki"}
MACRO {st} {"Sky and Telesc."}
 % End module: physjour.mbs
 %-------------------------------------------------------------------
 % Begin module:
 % \ProvidesFile{geojour.mbs}[2002/07/10 2.0h (PWD)]
MACRO {aisr} {"Adv. Space Res."}
MACRO {ag} {"Ann. Geophys."}
MACRO {anigeo} {"Ann. Geofis."}
MACRO {angl} {"Ann. Glaciol."}
MACRO {andmet} {"Ann. d. Meteor."}
MACRO {andgeo} {"Ann. d. Geophys."}
MACRO {andphy} {"Ann. Phys.-Paris"}
MACRO {afmgb} {"Arch. Meteor. Geophys. Bioklimatol."}
MACRO {atph} {"Atm\'osphera"}
MACRO {aao} {"Atmos. Ocean"}
MACRO {ass}{"Astrophys. Space Sci."}
MACRO {atenv} {"Atmos. Environ."}
MACRO {aujag} {"Aust. J. Agr. Res."}
MACRO {aumet} {"Aust. Meteorol. Mag."}
MACRO {blmet} {"Bound.-Lay. Meteorol."}
MACRO {bams} {"Bull. Amer. Meteorol. Soc."}
MACRO {cch} {"Clim. Change"}
MACRO {cdyn} {"Clim. Dynam."}
MACRO {cbul} {"Climatol. Bull."}
MACRO {cap} {"Contrib. Atmos. Phys."}
MACRO {dsr} {"Deep-Sea Res."}
MACRO {dhz} {"Dtsch. Hydrogr. Z."}
MACRO {dao} {"Dynam. Atmos. Oceans"}
MACRO {eco} {"Ecology"}
MACRO {empl}{"Earth, Moon and Planets"}
MACRO {envres} {"Environ. Res."}
MACRO {envst} {"Environ. Sci. Technol."}
MACRO {ecms} {"Estuarine Coastal Mar. Sci."}
MACRO {expa}{"Exper. Astron."}
MACRO {geoint} {"Geofis. Int."}
MACRO {geopub} {"Geofys. Publ."}
MACRO {geogeo} {"Geol. Geofiz."}
MACRO {gafd} {"Geophys. Astrophys. Fluid Dyn."}
MACRO {gfd} {"Geophys. Fluid Dyn."}
MACRO {geomag} {"Geophys. Mag."}
MACRO {georl} {"Geophys. Res. Lett."}
MACRO {grl} {"Geophys. Res. Lett."}
MACRO {ga} {"Geophysica"}
MACRO {gs} {"Geophysics"}
MACRO {ieeetap} {"IEEE Trans. Antenn. Propag."}
MACRO {ijawp} {"Int. J. Air Water Pollut."}
MACRO {ijc} {"Int. J. Climatol."}
MACRO {ijrs} {"Int. J. Remote Sens."}
MACRO {jam} {"J. Appl. Meteorol."}
MACRO {jaot} {"J. Atmos. Ocean. Technol."}
MACRO {jatp} {"J. Atmos. Terr. Phys."}
MACRO {jastp} {"J. Atmos. Solar-Terr. Phys."}
MACRO {jce} {"J. Climate"}
MACRO {jcam} {"J. Climate Appl. Meteor."}
MACRO {jcm} {"J. Climate Meteor."}
MACRO {jcy} {"J. Climatol."}
MACRO {jgr} {"J. Geophys. Res."}
MACRO {jga} {"J. Glaciol."}
MACRO {jh} {"J. Hydrol."}
MACRO {jmr} {"J. Mar. Res."}
MACRO {jmrj} {"J. Meteor. Res. Japan"}
MACRO {jm} {"J. Meteor."}
MACRO {jpo} {"J. Phys. Oceanogr."}
MACRO {jra} {"J. Rech. Atmos."}
MACRO {jaes} {"J. Aeronaut. Sci."}
MACRO {japca} {"J. Air Pollut. Control Assoc."}
MACRO {jas} {"J. Atmos. Sci."}
MACRO {jmts} {"J. Mar. Technol. Soc."}
MACRO {jmsj} {"J. Meteorol. Soc. Japan"}
MACRO {josj} {"J. Oceanogr. Soc. Japan"}
MACRO {jwm} {"J. Wea. Mod."}
MACRO {lao} {"Limnol. Oceanogr."}
MACRO {mwl} {"Mar. Wea. Log"}
MACRO {mau} {"Mausam"}
MACRO {meteor} {"``Meteor'' Forschungsergeb."}
MACRO {map} {"Meteorol. Atmos. Phys."}
MACRO {metmag} {"Meteor. Mag."}
MACRO {metmon} {"Meteor. Monogr."}
MACRO {metrun} {"Meteor. Rundsch."}
MACRO {metzeit} {"Meteor. Z."}
MACRO {metgid} {"Meteor. Gidrol."}
MACRO {mwr} {"Mon. Weather Rev."}
MACRO {nwd} {"Natl. Weather Dig."}
MACRO {nzjmfr} {"New Zeal. J. Mar. Freshwater Res."}
MACRO {npg} {"Nonlin. Proc. Geophys."}
MACRO {om} {"Oceanogr. Meteorol."}
MACRO {ocac} {"Oceanol. Acta"}
MACRO {oceanus} {"Oceanus"}
MACRO {paleoc} {"Paleoceanography"}
MACRO {pce} {"Phys. Chem. Earth"}
MACRO {pmg} {"Pap. Meteor. Geophys."}
MACRO {ppom} {"Pap. Phys. Oceanogr. Meteor."}
MACRO {physzeit} {"Phys. Z."}
MACRO {pps} {"Planet. Space Sci."}
MACRO {pss} {"Planet. Space Sci."}
MACRO {pag} {"Pure Appl. Geophys."}
MACRO {qjrms} {"Quart. J. Roy. Meteorol. Soc."}
MACRO {quatres} {"Quat. Res."}
MACRO {rsci} {"Radio Sci."}
MACRO {rse} {"Remote Sens. Environ."}
MACRO {rgeo} {"Rev. Geophys."}
MACRO {rgsp} {"Rev. Geophys. Space Phys."}
MACRO {rdgeo} {"Rev. Geofis."}
MACRO {revmeta} {"Rev. Meteorol."}
MACRO {sgp}{"Surveys in Geophys."}
MACRO {sp} {"Solar Phys."}
MACRO {ssr} {"Space Sci. Rev."}
MACRO {tellus} {"Tellus"}
MACRO {tac} {"Theor. Appl. Climatol."}
MACRO {tagu} {"Trans. Am. Geophys. Union (EOS)"}
MACRO {wrr} {"Water Resour. Res."}
MACRO {weather} {"Weather"}
MACRO {wafc} {"Weather Forecast."}
MACRO {ww} {"Weatherwise"}
MACRO {wmob} {"WMO Bull."}
MACRO {zeitmet} {"Z. Meteorol."}
 % End module: geojour.mbs
 %-------------------------------------------------------------------
 % Begin module:
 % \ProvidesFile{photjour.mbs}[1999/02/24 2.0b (PWD)]

MACRO {appopt} {"Appl. Opt."}
MACRO {bell} {"Bell Syst. Tech. J."}
MACRO {ell} {"Electron. Lett."}
MACRO {jasp} {"J. Appl. Spectr."}
MACRO {jqe} {"IEEE J. Quantum Electron."}
MACRO {jlwt} {"J. Lightwave Technol."}
MACRO {jmo} {"J. Mod. Opt."}
MACRO {josa} {"J. Opt. Soc. America"}
MACRO {josaa} {"J. Opt. Soc. Amer.~A"}
MACRO {josab} {"J. Opt. Soc. Amer.~B"}
MACRO {jdp} {"J. Phys. (Paris)"}
MACRO {oc} {"Opt. Commun."}
MACRO {ol} {"Opt. Lett."}
MACRO {phtl} {"IEEE Photon. Technol. Lett."}
MACRO {pspie} {"Proc. Soc. Photo-Opt. Instrum. Eng."}
MACRO {sse} {"Solid-State Electron."}
MACRO {sjot} {"Sov. J. Opt. Technol."}
MACRO {sjqe} {"Sov. J. Quantum Electron."}
MACRO {sleb} {"Sov. Phys.--Leb. Inst. Rep."}
MACRO {stph} {"Sov. Phys.--Techn. Phys."}
MACRO {stphl} {"Sov. Techn. Phys. Lett."}
MACRO {vr} {"Vision Res."}
MACRO {zph} {"Z. f. Physik"}
MACRO {zphb} {"Z. f. Physik~B"}
MACRO {zphd} {"Z. f. Physik~D"}

MACRO {CLEO} {"CLEO"}
MACRO {ASSL} {"Adv. Sol.-State Lasers"}
MACRO {OSA}  {"OSA"}
 % End module: photjour.mbs
%% Copyright 1994-2002 Patrick W Daly
MACRO {acmcs} {"ACM Comput. Surv."}

MACRO {acta} {"Acta Inf."}

MACRO {cacm} {"Commun. ACM"}

MACRO {ibmjrd} {"IBM J. Res. Dev."}

MACRO {ibmsj} {"IBM Syst.~J."}

MACRO {ieeese} {"IEEE Trans. Software Eng."}

MACRO {ieeetc} {"IEEE Trans. Comput."}

MACRO {ieeetcad}
 {"IEEE Trans. Comput. Aid. Des."}

MACRO {ipl} {"Inf. Process. Lett."}

MACRO {jacm} {"J.~ACM"}

MACRO {jcss} {"J.~Comput. Syst. Sci."}

MACRO {scp} {"Sci. Comput. Program."}

MACRO {sicomp} {"SIAM J. Comput."}

MACRO {tocs} {"ACM Trans. Comput. Syst."}

MACRO {tods} {"ACM Trans. Database Syst."}

MACRO {tog} {"ACM Trans. Graphic."}

MACRO {toms} {"ACM Trans. Math. Software"}

MACRO {toois} {"ACM Trans. Office Inf. Syst."}

MACRO {toplas} {"ACM Trans. Progr. Lang. Syst."}

MACRO {tcs} {"Theor. Comput. Sci."}

FUNCTION {bibinfo.check}
{ swap$
  duplicate$ missing$
    {
      pop$ pop$
      ""
    }
    { duplicate$ empty$
        {
          swap$ pop$
        }
        { swap$
          "\bibinfo{" swap$ * "}{" * swap$ * "}" *
        }
      if$
    }
  if$
}
FUNCTION {bibinfo.warn}
{ swap$
  duplicate$ missing$
    {
      swap$ "missing " swap$ * " in " * cite$ * warning$ pop$
      ""
    }
    { duplicate$ empty$
        {
          swap$ "empty " swap$ * " in " * cite$ * warning$
        }
        { swap$
          "\bibinfo{" swap$ * "}{" * swap$ * "}" *
        }
      if$
    }
  if$
}
FUNCTION {format.eprint}
{ eprint duplicate$ empty$
    'skip$
    { "\eprint"
      archive empty$
        'skip$
        { "[" * archive * "]" * }
      if$
      "{" * swap$ * "}" *
    }
  if$
}
FUNCTION {format.url}
{ url empty$
    { "" }
    { "\urlprefix\url{" url * "}" * }
  if$
}

FUNCTION {format.doi}
{ doi empty$
    { "" }
    { "\doi{" doi * "}" * }
  if$
}

STRINGS  { bibinfo}
INTEGERS { nameptr namesleft numnames }

FUNCTION {format.names}
{ 'bibinfo :=
  duplicate$ empty$ 'skip$ {
  's :=
  "" 't :=
  #1 'nameptr :=
  s num.names$ 'numnames :=
  numnames 'namesleft :=
    { namesleft #0 > }
    { s nameptr
      "{vv~}{ll}{, f.}{, jj}"
      format.name$
      bibinfo bibinfo.check
      't :=
      nameptr #1 >
        {
          nameptr #1
          #1 + =
          numnames #5
          > and
            { "others" 't :=
              #1 'namesleft := }
            'skip$
          if$
          namesleft #1 >
            { ", " * t * }
            {
              s nameptr "{ll}" format.name$ duplicate$ "others" =
                { 't := }
                { pop$ }
              if$
              t "others" =
                {
                  " " * bbl.etal emphasize *
                }
                {
                  "\&"
                  space.word * t *
                }
              if$
            }
          if$
        }
        't
      if$
      nameptr #1 + 'nameptr :=
      namesleft #1 - 'namesleft :=
    }
  while$
  } if$
}
FUNCTION {format.names.ed}
{
  format.names
}
FUNCTION {format.authors}
{ author "author" format.names
}
FUNCTION {get.bbl.editor}
{ editor num.names$ #1 > 'bbl.editors 'bbl.editor if$ }

FUNCTION {get.in.bbl.editor}
{  }

FUNCTION {format.editors}
{ editor "editor" format.names duplicate$ empty$ 'skip$
    {
      " " *
      get.bbl.editor
   "(" swap$ * ")" *
      *
    }
  if$
}

FUNCTION {format.in.editors}
{ "" editor "editor" format.names duplicate$ empty$ 'skip$
    {     swap$ "(eds" *
          " " * swap$ *
                swap$ " " * 
		swap$ * ")" * 
		}
  if$
}

FUNCTION {format.note}
{
 note empty$
    { "" }
    { note #1 #1 substring$
      duplicate$ "{" =
        'skip$
        { output.state mid.sentence =
          { "l" }
          { "u" }
        if$
        change.case$
        }
      if$
      note #2 global.max$ substring$ * "note" bibinfo.check
    }
  if$
}



FUNCTION {format.in.title}
{ title
  duplicate$ empty$ 'skip$
    { "t" change.case$ }
  if$
 " in \textit{" swap$ * "}" * "title" bibinfo.check
}

FUNCTION {format.title}
{ title
  duplicate$ empty$ 'skip$
    { "t" change.case$ }
  if$
  "title" bibinfo.check
}

FUNCTION {format.inpro.title}
{ title
  duplicate$ empty$ 'skip$
    { "t" change.case$ }
  if$
  "title" bibinfo.check
 emphasize}

FUNCTION {format.version}
{ version
  duplicate$ empty$ 'skip$
    { "t" change.case$ }
  if$
  "version" bibinfo.check
}

%FUNCTION {format.inpro.title}
%{ title
%  duplicate$ empty$ 'skip$
%    { "t" change.case$ }
%  if$
%  "title" bibinfo.check
% emphasize}

FUNCTION {output.bibitem}
{ newline$
  "\bibitem{" write$
  cite$ write$
  "}" write$
  newline$
  ""
  before.all 'output.state :=
}

FUNCTION {n.dashify}
{
  't :=
  ""
    { t empty$ not }
    { t #1 #1 substring$ "-" =
        { t #1 #2 substring$ "--" = not
            { "--" *
              t #2 global.max$ substring$ 't :=
            }
            {   { t #1 #1 substring$ "-" = }
                { "-" *
                  t #2 global.max$ substring$ 't :=
                }
              while$
            }
          if$
        }
        { t #1 #1 substring$ *
          t #2 global.max$ substring$ 't :=
        }
      if$
    }
  while$
}

FUNCTION {word.in}
{ bbl.in capitalize
  " " * }

FUNCTION {format.date}
{
  ""
  duplicate$ empty$
  year  "year"  bibinfo.check duplicate$ empty$
    { swap$ 'skip$
        { "there's a month but no year in " cite$ * warning$ }
      if$
      *
    }
    { swap$ 'skip$
        {
          swap$
          " " * swap$
        }
      if$
      *
    }
  if$
  duplicate$ empty$
    'skip$
    {
      before.all 'output.state :=
    " (" swap$ * ")" *
    }
  if$
}
FUNCTION {format.btitle}
{ title "title" bibinfo.check
  duplicate$ empty$ 'skip$
    {
      emphasize
    }
  if$
}
FUNCTION {either.or.check}
{ empty$
    'pop$
    { "can't use both " swap$ * " fields in " * cite$ * warning$ }
  if$
}
FUNCTION {format.bvolume}
{ volume empty$
    { "" }
    { bbl.volume volume tie.or.space.prefix
      "volume" bibinfo.check * *
      series "series" bibinfo.check
      duplicate$ empty$ 'pop$
        { swap$ bbl.of space.word * swap$
          emphasize * }
      if$
      "volume and number" number either.or.check
    }
  if$
}
FUNCTION {format.number.series}
{ volume empty$
    { number empty$
        { series field.or.null }
        { series empty$
            { number "number" bibinfo.check }
        { output.state mid.sentence =
            { bbl.number }
            { bbl.number capitalize }
          if$
          number tie.or.space.prefix "number" bibinfo.check * *
          bbl.in space.word *
          series "series" bibinfo.check *
        }
      if$
    }
      if$
    }
    { "" }
  if$
}

FUNCTION {format.edition}
{ edition duplicate$ empty$ 'skip$
    {
      output.state mid.sentence =
        { "l" }
        { "t" }
      if$ change.case$
      "edition" bibinfo.check
      " " * bbl.edition *
    }
  if$
}
INTEGERS { multiresult }
FUNCTION {multi.page.check}
{ 't :=
  #0 'multiresult :=
    { multiresult not
      t empty$ not
      and
    }
    { t #1 #1 substring$
      duplicate$ "-" =
      swap$ duplicate$ "," =
      swap$ "+" =
      or or
        { #1 'multiresult := }
        { t #2 global.max$ substring$ 't := }
      if$
    }
  while$
  multiresult
}
FUNCTION {format.pages}
{ pages duplicate$ empty$ 'skip$
    { duplicate$ multi.page.check
        {
          n.dashify
        }
        {
        }
      if$
      "pages" bibinfo.check
    }
  if$
}
FUNCTION {format.journal.pages}
{ pages duplicate$ empty$ 'pop$
    { swap$ duplicate$ empty$
        { pop$ pop$ format.pages }
        {
          ", " *
          swap$
          n.dashify
          "pages" bibinfo.check
          *
        }
      if$
    }
  if$
}
FUNCTION {format.number}
    {number empty$
        'skip$
        { "~(" number * ")" * * }
      if$
    }
FUNCTION {format.vol.num.pages}
{ volume field.or.null
  duplicate$ empty$ 'skip$
    {
      "volume" bibinfo.check
    }
  if$
  bolden
  format.number
  format.journal.pages
}

FUNCTION {format.chapter.pages}
{ chapter empty$
    'format.pages
    { type empty$
        { bbl.chapter }
        { type "l" change.case$
          "type" bibinfo.check
        }
      if$
      chapter tie.or.space.prefix
      "chapter" bibinfo.check
      * *
      pages empty$
        'skip$
        { ", " * format.pages * }
      if$
    }
  if$
}

FUNCTION {format.booktitle}
{
  booktitle "booktitle" bibinfo.check
  emphasize
}
FUNCTION {format.in.ed.booktitle}
{  duplicate$ empty$ 'skip$
    { 
editor "editor" format.names.ed duplicate$ empty$ 'pop$
        {  
format.booktitle swap$
"(" editor num.names$ #1 > 'bbl.in.editors 'bbl.editor if$  * swap$   ") " *
          * swap$
          * }
      if$ 
    }  
  if$
}
FUNCTION {empty.misc.check}
{ author empty$ title empty$ howpublished empty$
  month empty$ year empty$ note empty$
  and and and and and
    { "all relevant fields are empty in " cite$ * warning$ }
    'skip$
  if$
}
FUNCTION {format.thesis.type}
{ type duplicate$ empty$
    'pop$
    { swap$ pop$
      "t" change.case$ "type" bibinfo.check
    }
  if$
}
FUNCTION {format.tr.number}
{ number "number" bibinfo.check
  type duplicate$ empty$
    { pop$ bbl.techrep }
    'skip$
  if$
  "type" bibinfo.check
  swap$ duplicate$ empty$
    { pop$ "t" change.case$ }
    { tie.or.space.prefix * * }
  if$
}
FUNCTION {format.article.crossref}
{
  key duplicate$ empty$
    { pop$
      journal duplicate$ empty$
        { "need key or journal for " cite$ * " to crossref " * crossref * warning$ }
        { "journal" bibinfo.check emphasize word.in swap$ * }
      if$
    }
    { word.in swap$ * " " *}
  if$
  " \cite{" * crossref * "}" *
}
FUNCTION {format.crossref.editor}
{ editor #1 "{vv~}{ll}" format.name$
  "editor" bibinfo.check
  editor num.names$ duplicate$
  #2 >
    { pop$
      "editor" bibinfo.check
      " " * bbl.etal
      emphasize
      *
    }
    { #2 <
        'skip$
        { editor #2 "{ff }{vv }{ll}{ jj}" format.name$ "others" =
            {
              "editor" bibinfo.check
              " " * bbl.etal
              emphasize
              *
            }
            {
              " \& "
              * editor #2 "{vv~}{ll}" format.name$
              "editor" bibinfo.check
              *
            }
          if$
        }
      if$
    }
  if$
}
FUNCTION {format.book.crossref}
{ volume duplicate$ empty$
    { "empty volume in " cite$ * "'s crossref of " * crossref * warning$
      pop$ word.in
    }
    { bbl.volume
      capitalize
      swap$ tie.or.space.prefix "volume" bibinfo.check * * bbl.of space.word *
    }
  if$
  editor empty$
  editor field.or.null author field.or.null =
  or
    { key empty$
        { series empty$
            { "need editor, key, or series for " cite$ * " to crossref " *
              crossref * warning$
              "" *
            }
            { series emphasize * }
          if$
        }
        { key * }
      if$
    }
    { format.crossref.editor * }
  if$
  " \cite{" * crossref * "}" *
}
FUNCTION {format.incoll.inproc.crossref}
{
  editor empty$
  editor field.or.null author field.or.null =
  or
    { key empty$
        { format.booktitle duplicate$ empty$
            { "need editor, key, or booktitle for " cite$ * " to crossref " *
              crossref * warning$
            }
            { word.in swap$ * }
          if$
        }
        { word.in key * " " *}
      if$
    }
    { word.in format.crossref.editor * " " *}
  if$
  " \cite{" * crossref * "}" *
}
FUNCTION {format.org.or.pub}
{ 't :=
  ""
  year empty$
    { "empty year in " cite$ * warning$ }
    'skip$
  if$
  address empty$ t empty$ and
  year empty$ and
    'skip$
    {
      add.blank "(" *
      t empty$
        { address "address" bibinfo.check *
        }
        { t *
          address empty$
            'skip$
            { ", " * address "address" bibinfo.check * }
          if$
        }
      if$
      year empty$
        'skip$
        { t empty$ address empty$ and
            'skip$
            { ", " * }
          if$
          year "year" bibinfo.check
          *
        }
      if$
      ")" *
    }
  if$
}
FUNCTION {format.publisher.address}
{ publisher "publisher" bibinfo.warn format.org.or.pub
}

FUNCTION {format.organization.address}
{ organization "organization" bibinfo.check format.org.or.pub
}

FUNCTION {format.archive}
{
  archivePrefix empty$
      { "" }
      { archivePrefix ":" *}
  if$           
}

FUNCTION {format.primaryClass}
{
  primaryClass empty$
      { "" }
      { " {[" primaryClass * "]}" *}
  if$           
}

FUNCTION {format.soft.eprint}
{ eprint empty$
     { ""}
     { archive empty$
          {"{\href{https://arxiv.org/abs/" eprint * "}" *
             "{{" * format.archive * eprint * "}}}" *}
          {"{\href{https://arxiv.org/abs/" eprint * "}" *
             "{{" * format.archive * eprint * "}}}" *}
       if$
     }
     if$
     "eprint" bibinfo.check
}

FUNCTION {format.softmisc.archive}
{
  archivePrefix empty$
      { "" }
      { "" }
  if$           
}

FUNCTION {format.softmisc.eprint}
{ eprint empty$
     { ""}
     { archive empty$
          {"{\href{https://ascl.net/" format.softmisc.archive * eprint * "}" *
             "{{" * format.archive * eprint * "}}}" *}
          {"{\href{https://ascl.net/" format.softmisc.archive * eprint * "}" *
             "{{" * format.archive * eprint * "}}}" *}
       if$
     }
     if$
}

FUNCTION {article}
{ output.bibitem
  format.authors "author" output.check
  new.block
  format.title "title" output.check
  new.block
  crossref missing$
    {
      journal
      "journal" bibinfo.check
      emphasize
      "journal" output.check
      add.blank
      format.vol.num.pages output
      format.date "year" output.check
    }
    { format.article.crossref output.nonnull
      format.pages output
    }
  if$
  new.block
  format.url output
  new.block
  format.doi output
  format.note output
  %%format.eprint output
  format.soft.eprint output
  add.blank
  format.primaryClass output
  fin.entry
}
FUNCTION {book}
{ output.bibitem
  author empty$
    { format.editors "author and editor" output.check
      add.blank
    }
    { format.authors output.nonnull
      crossref missing$
        { "author and editor" editor either.or.check }
        'skip$
      if$
    }
  if$
  new.block
  format.btitle "title" output.check
      add.blank
	  format.edition output
  crossref missing$
    { format.bvolume output
      new.block
      format.number.series output
      new.sentence
      format.publisher.address output
    }
    {
      new.block
      format.book.crossref output.nonnull
      format.date "year" output.check
    }
  if$
  new.block
  format.url output
  new.block
  format.note output
  format.eprint output
  fin.entry
}
FUNCTION {booklet}
{ output.bibitem
  format.authors output
  new.block
  format.title "title" output.check
  new.block
  howpublished "howpublished" bibinfo.check output
  address "address" bibinfo.check output
  format.date output
  new.block
  format.url output
  new.block
  format.note output
  format.eprint output
  fin.entry
}

FUNCTION {inbook}
{ output.bibitem
  author empty$
    { format.editors "author and editor" output.check
    }
    { format.authors output.nonnull
      crossref missing$
        { "author and editor" editor either.or.check }
        'skip$
      if$
    }
  if$
  new.block
  format.btitle "title" output.check
  crossref missing$
    {
      format.bvolume output
      format.chapter.pages "chapter and pages" output.check
      new.block
      format.number.series output
      new.sentence
      format.publisher.address output
    }
    {
      format.chapter.pages "chapter and pages" output.check
      new.block
      format.book.crossref output.nonnull
      format.date "year" output.check
    }
  if$
  format.edition output
  new.block
  format.url output
  new.block
  format.note output
  format.eprint output
  fin.entry
}

FUNCTION {incollection}
{ output.bibitem
  format.authors "author" output.check
  new.block
  format.in.title "title" output.check
      add.blank
  format.edition output
%  new.block
  crossref missing$
    { format.in.ed.booktitle "booktitle" output.check
      format.bvolume output
      add.blank
      format.number.series output
      format.chapter.pages output
      new.sentence
      format.publisher.address output
    }
    { format.incoll.inproc.crossref output.nonnull
      format.chapter.pages output
    }
  if$
  new.block
  format.url output
  new.block
  format.note output
  format.eprint output
  fin.entry
}
FUNCTION {inproceedings}
{ output.bibitem
  format.authors "author" output.check
	  new.block
	  format.editors output
add.blank
  format.inpro.title "title" output.check
  new.block
  crossref missing$
    { format.in.ed.booktitle "booktitle" output.check
      format.bvolume output
      format.number.series output
      format.pages output
      new.sentence
      publisher empty$
        { format.organization.address output }
        { organization "organization" bibinfo.check output
          format.publisher.address output
        }
      if$
    }
    { format.incoll.inproc.crossref output.nonnull
      format.pages output
    }
  if$
  new.block
  format.url output
  new.block
  format.note output
  format.eprint output
  fin.entry
}
FUNCTION {conference} { inproceedings }
FUNCTION {manual}
{ output.bibitem
  author empty$
    { organization "organization" bibinfo.check
      duplicate$ empty$ 'pop$
        { output
          address "address" bibinfo.check output
        }
      if$
    }
    { format.authors output.nonnull }
  if$
  new.block
  format.btitle "title" output.check
  author empty$
    { organization empty$
        {
          address new.block.checka
          address "address" bibinfo.check output
        }
        'skip$
      if$
    }
    {
      organization address new.block.checkb
      organization "organization" bibinfo.check output
      address "address" bibinfo.check output
    }
  if$
  format.edition output
  format.date output
  new.block
  format.url output
  new.block
  format.note output
  format.eprint output
  fin.entry
}

FUNCTION {mastersthesis}
{ output.bibitem
  format.authors "author" output.check
  new.block
  format.btitle
  "title" output.check
  new.block
  bbl.mthesis format.thesis.type output.nonnull
  school "school" bibinfo.warn output
  address "address" bibinfo.check output
  format.date "year" output.check
  new.block
  format.url output
  new.block
  format.note output
  format.eprint output
  fin.entry
}

FUNCTION {misc}
{ output.bibitem
  format.authors output
  title howpublished new.block.checkb
  format.title output
  howpublished new.block.checka
  howpublished "howpublished" bibinfo.check output
  format.date output
  new.block
  format.url output
  new.block
  format.note output
  format.eprint output
  fin.entry
  empty.misc.check
}

FUNCTION {softmisc}
{ output.bibitem
  format.authors output
  title howpublished new.block.checkb
  format.title output
  format.version output
  howpublished new.block.checka
  howpublished "howpublished" bibinfo.check output
  format.date output
  new.block
  format.url output
  new.block
  format.note output
  %%format.eprint output
  format.softmisc.eprint output
  fin.entry
  empty.misc.check
}

FUNCTION {phdthesis}
{ output.bibitem
  format.authors "author" output.check
  new.block
  format.btitle
  "title" output.check
  new.block
  bbl.phdthesis format.thesis.type output.nonnull
  school "school" bibinfo.warn output
  address "address" bibinfo.check output
  format.date "year" output.check
  new.block
  format.url output
  new.block
  format.note output
  format.eprint output
  fin.entry
}

FUNCTION {proceedings}
{ output.bibitem
  editor empty$
    { organization "organization" bibinfo.check output
    }
    { format.editors output.nonnull }
  if$
  new.block
  format.btitle "title" output.check
  format.bvolume output
  format.number.series output
  editor empty$
    { publisher empty$
        'skip$
        {
          new.sentence
          format.publisher.address output
        }
      if$
    }
    { publisher empty$
        {
          new.sentence
          format.organization.address output }
        {
          new.sentence
          organization "organization" bibinfo.check output
          format.publisher.address output
        }
      if$
     }
  if$
  new.block
  format.url output
  new.block
  format.note output
  format.eprint output
  fin.entry
}

FUNCTION {techreport}
{ output.bibitem
  format.authors "author" output.check
  new.block
  format.title
  "title" output.check
  new.block
  format.tr.number output.nonnull
  institution "institution" bibinfo.warn output
  address "address" bibinfo.check output
  format.date "year" output.check
  new.block
  format.url output
  new.block
  format.note output
  format.eprint output
  fin.entry
}

FUNCTION {unpublished}
{ output.bibitem
  format.authors "author" output.check
  new.block
  format.title "title" output.check
  format.date output
  new.block
  format.url output
  new.block
  format.note "note" output.check
  format.eprint output
  fin.entry
}

FUNCTION {default.type} { misc }
READ
STRINGS { longest.label }
INTEGERS { number.label longest.label.width }
FUNCTION {initialize.longest.label}
{ "" 'longest.label :=
  #1 'number.label :=
  #0 'longest.label.width :=
}
FUNCTION {longest.label.pass}
{ number.label int.to.str$ 'label :=
  number.label #1 + 'number.label :=
  label width$ longest.label.width >
    { label 'longest.label :=
      label width$ 'longest.label.width :=
    }
    'skip$
  if$
}
EXECUTE {initialize.longest.label}
ITERATE {longest.label.pass}
FUNCTION {begin.bib}
{ preamble$ empty$
    'skip$
    { preamble$ write$ newline$ }
  if$
  "\begin{thebibliography}{"  longest.label  * "}" *
  write$ newline$
  "\expandafter\ifx\csname url\endcsname\relax"
  write$ newline$
  %%"  \def\url#1{\texttt{#1}}\fi"
  "  \def\url#1{\burl{#1}}\fi"
  write$ newline$
  "\expandafter\ifx\csname urlprefix\endcsname\relax\def\urlprefix{URL }\fi"
  write$ newline$
  "\providecommand{\bibinfo}[2]{#2}"
  write$ newline$
  "\providecommand{\eprint}[2][]{\url{#2}}"
  write$ newline$
  "\providecommand{\doi}[1]{\url{https://doi.org/#1}}"
  write$ newline$
  "\bibcommenthead" write$ newline$
}
EXECUTE {begin.bib}
EXECUTE {init.state.consts}
ITERATE {call.type$}
FUNCTION {end.bib}
{ newline$
  "\end{thebibliography}" write$ newline$
}
EXECUTE {end.bib}
%% End of customized bst file
%%
%% End of file `nature.bst'.
\end{filecontents}


\documentclass[sn-standardnature, colorlinks=true,linkcolor=blue, allcolors=blue, backref=page]{sn-jnl}



\usepackage{layouts}
\usepackage{graphicx} 
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{xr-hyper}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{caption}
% \usepackage{unicode-math}
\usepackage{cleveref}
\usepackage{siunitx}
\usepackage{lineno}
\usepackage{array}
\usepackage{placeins}
\usepackage{pdfpages}
%\usepackage[colorlinks=true,linkcolor=blue, allcolors=blue, backref=page]{hyperref}
%\usepackage[backref=page]{hyperref}
%\usepackage{stackengine}
%\usepackage[table]{xcolor}
%\usepackage{calrsfs}
\newcommand{\overbar}[1]{\mkern 1.5mu\overline{\mkern-1.5mu#1\mkern-1.5mu}\mkern 1.5mu}
\DeclareMathAlphabet{\pazocal}{OMS}{zplm}{m}{n}
\newcommand{\La}{\mathcal{L}}
\newcommand{\Lb}{\pazocal{L}}
\newcommand{\la}{\mathcal{l}}
\newcommand{\lb}{\pazocal{l}}
\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}

%\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

%\theoremstyle{remark}
%\newtheorem*{remark}{Remark}
\DeclareFontFamily{U}{mathx}{\hyphenchar\font45}
\DeclareFontShape{U}{mathx}{m}{n}{%
<-6> mathx5
<6-7> mathx6
<7-8> mathx7
<8-9> mathx8
<9-10> mathx9
<10-12> mathx10
<12-> mathx12
}{}

\DeclareSymbolFont{mathx}{U}{mathx}{m}{n}
\DeclareFontSubstitution{U}{mathx}{m}{n}

\DeclareMathSymbol{\bigovoid}{\mathop}{mathx}{"EC}

\newcommand{\BigO}{\mathop{\stackinset{c}{}{c}{}{ \scalebox{1.1}{$\bigovoid$}}{ \scalebox{1.15}{$\bigovoid$}}}}

\newcommand{\bigO}{\mathop{\stackinset{c}{-2pt}{c}{}{ \scalebox{0.8}{$\bigovoid$}}{\scalebox{0.85}{$\bigovoid$}}}}

\DeclareMathOperator{\Tr}{Tr}



\raggedbottom
%%\unnumbered% uncomment this for unnumbered level heads
\begin{document}
%\linenumbers

\title[IEA-GAN]{Ultra-High-Granularity Detector Simulation with Intra-Event Aware Generative Adversarial Network and Self-Supervised Relational Reasoning}


\author*[1]{\fnm{Baran} \sur{Hashemi}}\email{baran.hashemi@origins-cluster.de}

\author[1]{\fnm{Nikolai} \sur{Hartmann}}%\email{nikolai.hartmann@physik.uni-muenchen.de}

\author[2]{\fnm{Sahand} \sur{Sharifzadeh}}%\email{sharifzadeh@google.com}

\author[3,4]{\fnm{James} \sur{Kahn}}%\email{james.kahn@kit.edu}

\author[1]{\fnm{Thomas} \sur{Kuhr}}%\email{thomas.Kuhr@lmu.de}


\affil*[1]{\orgdiv{Faculty of Physics}, \orgname{Ludwig Maximilians University in Munich}, \country{Germany}}


\affil[2]{\orgdiv{Faculty of Computer Science}, \orgname{Ludwig Maximilians University of Munich}, \country{Germany}}

\affil[3]{\orgname{Helmholtz AI}, \country{Germany}}
\affil[4]{\orgdiv{Steinbuch Centre for Computing (SCC)}, \orgname{Karlsruhe Institute of Technology (KIT)}, \country{Germany}}


%%==================================%%
%% sample for unstructured abstract %%
%%==================================%%
\abstract{
Simulating high-resolution detector responses is a computationally intensive process that has long been challenging in Particle Physics. Despite the ability of generative models to streamline it, full ultra-high-granularity detector simulation still proves to be difficult as it contains correlated and fine-grained information.
To overcome these limitations, we propose Intra-Event Aware Generative Adversarial Network~(IEA-GAN). IEA-GAN presents a Relational Reasoning Module that approximates an event in detector simulation, generating contextualized high-resolution full detector responses with a proper relational inductive bias. IEA-GAN also introduces a Self-Supervised intra-event aware loss and Uniformity loss, significantly enhancing sample fidelity and diversity. We demonstrate IEA-GAN's application in generating sensor-dependent images for the ultra-high-granularity Pixel Vertex Detector~(PXD), with more than 7.5~M information channels at the Belle~II Experiment.
Applications of this work span from Foundation Models for high-granularity detector simulation, such as at the HL-LHC~(High Luminosity LHC), to simulation-based inference and fine-grained density estimation.
}

%To our knowledge, IEA-GAN is the first algorithm for faithful ultra-high-granularity detector simulation with event-based reasoning

\keywords{High-resolution and high-granularity detector simulation, Fine-grained conditional image generation, Relational Inductive Bias, GANs, Self-Supervised Learning with Knowledge Transfer}


\maketitle

\section{Introduction}
\label{sec:intro}

The Efficient and Fast Simulation~\cite{paganiniAcceleratingScienceGenerative2018,vallecorsaGenerativeModelsFast2018a,PhysRevD.97.014021,oliveiraControllingPhysicalAttributes2018a,erdmannGeneratingRefiningParticle2018,srebreGenerationBelleII2020a,hashemiPixelDetectorBackground2021a,buhmannGettingHighHigh2021} campaign in particle physics sparked the search for faster and more storage-efficient simulation methods of collider physics experiments.
Simulations play a vital role in various downstream tasks, including optimizing detector geometries, designing physics analyses, and searching for new phenomena beyond the Standard Model~(SM).
Efficient detector simulation has been revolutionized by the introduction of the Generative Adversarial Network~(GAN)~\cite{goodfellowGenerativeAdversarialNets2014a} for image data.

Deep Generative Models have been widely used in particle physics to achieve detector simulation for the LHC~\cite{PhysRevD.97.014021,vallecorsaGenerativeModelsFast2018a,oliveiraControllingPhysicalAttributes2018a,belaynehCalorimetryDeepLearning2020,khattakFastSimulationHigh2022a,buhmannGettingHighHigh2021,krauseCaloFlowCaloChallengeDataset2023,buhmannFastAccurateElectromagnetic2021,mikuniScorebasedGenerativeModels2022,krauseCaloFlowIIEven2023}, mainly targeting calorimeter simulation or collision event generation~\cite{hashemiLHCAnalysisspecificDatasets2019,disipioDijetGANGenerativeAdversarialNetwork2019,martinezParticleGenerativeAdversarial2020,alanaziSurveyMachineLearningBased2021a,butterHowGANLHC2019a,ottenEventGenerationStatistical2021a}.
Previous work on generating high spatial resolution detector responses includes the Prior-Embedding GAN~(PE-GAN) by Hashemi et al.~\cite{hashemiPixelDetectorBackground2021a}, which utilizes an end-to-end embedding of global prior information about the detector sensors, and the work by Srebre et al.~\cite{srebreGenerationBelleII2020a} in which a Wasserstein GAN~\cite{arjovskyWassersteinGenerativeAdversarial2017} with gradient penalty~\cite{gulrajaniImprovedTrainingWasserstein2017a} was used as a proof of concept to generate high-resolution images without conditioning. 
For mid-granularity calorimeter simulation, the recent approaches~\cite{buhmannGettingHighHigh2021,krauseCaloFlowCaloChallengeDataset2023}, experiment with several GAN-like and Flow-based~\cite{rezendeVariationalInferenceNormalizing2015} architectures with less than 30k simulated channels, and 3DGAN~\cite{khattakFastSimulationHigh2022a} for high granularity calorimeter simulation with only 65k pixel channels. 
Nonetheless, these studies barely scratch the surface of the profound challenges posed by future detector simulations. Take, for instance, the impending High Granularity Calorimeter~(HGCAL) - a component of the High Luminosity Large Hadron Collider~(HL-LHC)~\cite{aberleHighLuminosityLargeHadron2020} upgrade program at the Compact Muon Solenoid~(CMS) experiment~\cite{Phase2UpgradeCMS2017a}. With an estimated \num{6.5} million detector channels distributed across 50 layers, the HGCAL's complexity far surpasses the capacity of existing methods, pointing to the urgency of developing more advanced simulation approaches.

The task of learning to generate ultra-high-resolution detector responses has several challenges. First, in general, we are dealing with spatially asymmetric high-frequency hitmaps. With current state-of-the-art~(SOTA) GAN setups for high-resolution image generation candidates, when the discriminator becomes much stronger than the generator, the fake images are easily separated from real ones, thus reaching a point where gradients from the discriminator vanish. This happens more frequently with asymmetric high-resolution images due to the difficulty of generating imbalanced high-frequency details. On the other hand, a less powerful discriminator results in a mode collapse, where the generator greedily optimizes its loss function, producing only a few modes to deceive the discriminator.

Furthermore, the detector responses in an event, a single readout window after the collision of particles, share both statistical and semantic similarities~\cite{deselaersVisualSemanticSimilarity2011} with each other.
For example, the sparsity~(occupancy) of each image within a class, defined as the fraction of pixels with a non-zero value, shows statistical similarities between detector components~(see the Supplementary Figures in supplementary note).
Moreover, as the detector response images show extreme resemblance at the semantic and visual levels~\cite{deselaersVisualSemanticSimilarity2011}, they can be classified as fine-grained images.
When generating fine-grained images, the objective is to create visual objects from subordinate categories.
A similar scenario in computer vision is generating images of different dog breeds or car models.
The small inter-class and considerable intra-class variation inherent to fine-grained image analysis make it a challenging problem~\cite{weiFineGrainedImageAnalysis2022}.
The current state-of-the-art conditional GAN models focus on class and intra-class level image similarity, in which intra-image~\cite{zhangSelfAttentionGenerativeAdversarial2019c}, data-to-class~\cite{miyatoCGANsProjectionDiscriminator2018a}, and data-to-data~\cite{NEURIPS2020_f490c742} relations are considered.
However, in the case of detector simulation, classes become hierarchical and fine-grained, and the discrimination between generated classes that are semantically and visually similar becomes harder.
Therefore, the aforementioned models show extensive class confusion~\cite{kangRebootingACGANAuxiliary2021a,rangwaniClassBalancingGAN2021} at the inter-class level.
In addition, since the information in an event comes from a single readout window of the detector, the processes happening in this window affect all sensors simultaneously, leading to a correlation among them~(see~\cref{sec:results}).
In this paper, we demonstrate how this fine-grain intra-event correlation plays a pivotal role in the downstream Physics analysis.

To overcome all these challenges with ultra-high-resolution detector simulation,
we introduce the Intra-Event Aware GAN~(IEA-GAN), a novel deep generative model to generate sensor/layer-dependent detector response images with the highest fidelity while satisfying all relevant metrics. Since we are dealing with a fine-grained and contextualized~(by each event) set of images that share information. First, we introduce a Relational Reasoning Module~(RRM) for the discriminator and generator to capture inter-class relations.
Then, we propose a loss function for the generator to imitate the discriminator's knowledge of dyadic class-to-class correspondence~\cite{caoCouplingLearningComplex2015a}.
Finally, we introduce an auxiliary loss function for the discriminator to leverage its reasoning codomain by imposing an information uniformity condition~\cite{wangUnderstandingContrastiveRepresentation2020b} to alleviate the mode-collapse issue and increase the generalization of the model. IEA-GAN captures not only statistical-level and semantic-level information but also a correlation among samples in a fine-grained image generation task.

We demonstrate the IEA-GAN's application on the ultra-high dimensional data of the Pixel Vertex Detector~(PXD)~\cite{muellerAspectsPixelVertex2014a} at Belle~II~\cite{abeBelleIITechnical2010d} with more than 7.5M pixel channels- the highest spatial resolution detector simulation dataset ever analyzed with deep generative models.
Then, we investigate several evaluation metrics and show that in all of them, IEA-GAN is in much better agreement with the target distribution than other SOTA deep generative models for high-dimensional image generation. We also perform an ablation study and exploration of hyperparameters to provide insight into the model. 

It is crucial to highlight that our approach extends beyond the scope of the existing models in calorimeter simulations that try to capture layer-by-layer correlations~\cite{diefenbacherL2LFlowsGeneratingHighfidelity2023}. While these existing models do consider observables that depend on more than one layer simultaneously, they are restricted to simulating particle showers originating from a single particle source within a confined and localized area of the shower.
In contrast, our approach embraces the complexity of an entire event with multiple-particle origins, encompassing the full detector simulation. This perspective offers to capture correlations between detector sensors across various angles and layers. By doing so, it approximates the intricate and dynamic interplay of sensors throughout the entire detector, surpassing the limitations of simulations focused solely on localized particle showers.

%In the end, by applying IEA-GAN to the PXD at Belle~II, we are able not only to reduce the storage demand for pre-produced background data by a factor of \num{2} but also dramatically reduce the CPU time of online simulation in comparison to the old infeasible Geant4 approach as shown in~\Cref{tab:computational_perf}. As a result, It is now finally possible to employ the IEA-GAN as an online surrogate model for the ultra high-granularity PXD background simulation on the fly, a task that was unattainable before for such a high-resolution detector simulation. Thus, IEA-GAN stands as the first viable candidate capable of managing the ultra-high granularity of the forthcoming HL-LHC~\cite{aberleHighLuminosityLargeHadron2020} era.

In this paper, we study the most challenging detector simulation problem with the highest spatial resolution dataset coming from the Pixel Vertex Detector~(PXD)~\cite{muellerAspectsPixelVertex2014a}, shown in~\cref{fig:PXD_overview}, the innermost tracking sub-detector of Belle~II~\cite{abeBelleIITechnical2010d}.
The configuration of the PXD consists of \num{40} sensors within two detector layers, as shown in \cref{fig:PXD_overview}.
The inner layer has \num{16} sensors, and the outer layer comprises \num{24} sensors.
Thus, each event includes \num{40} grey-scale images, each with a resolution of $250\times 768$ pixels, resulting in more than 7.5 million pixel channels per event as shown in~\cref{fig:PXD_overview}. The recorded background signatures by PXD that comprise the majority of the PXD hits in each event come from various processes in the detector that do not originate from the physics processes of interest, called signal processes. These background processes can be categorized into beam-induced and luminosity-dependent processes. The beam-induced processes come from the synchrotron radiation and collisions of beam particles with residual gas in the beampipe, bending magnets, or particles within a bunch. In contrast, luminosity-dependent processes comprise electron-positron collisions leading to physics processes such as Bhabha scattering or two-photon processes.

The problem with such a high-resolution background overlay~\cite{kimSimulationLibraryBelle2017} is that many resources are required for their readout, storage, and distribution. For example, the size of the PXD background overlay data needed for the simulation of a single event is approximately $\SI{200}{\kilo\byte}$. This is roughly $2N$ times the size of the background overlay data per event with respect to all other detector components together~\cite{kuhrComputingBelleII2011a} where $N$ is the PXD background amplifier coefficient. 
Thus, an idea is to simulate them online. However, the on-the-fly simulation of background events is not feasible due to the considerable simulation time required by Geant4, which takes approximately 1500 seconds to simulate a single event.
As a result, while storing such a massive amount of data is very inefficient for high-resolution detectors, we propose to generate the background signatures with IEA-GAN on the fly as a surrogate model. 
%This way, it will not only free up a significant amount of storage space~(see~\Cref{tab:computational_perf} in~\cref{sec:ex_tables}) but also enable us to have the ability of online simulation as shown in~\cref{fig:evtgen}.

Here we show, by applying IEA-GAN, to the PXD at Belle~II, we are able not only to reduce the storage demand for pre-produced background data by a factor of \num{2}~(see~\cref{sec:discuss}) but also enable us to have the ability of online simulation as shown in~\cref{fig:PXD_overview} by dramatically reduce the CPU time of online simulation in comparison to the old infeasible Geant4 approach. 
As a result, It is now finally possible to employ the IEA-GAN as an online surrogate model for the ultra high-granularity PXD background simulation on the fly, a task that was unattainable before for such a high-resolution detector simulation. 
Thus, IEA-GAN stands as the viable candidate capable of managing the ultra-high granularity of the forthcoming HL-LHC~\cite{aberleHighLuminosityLargeHadron2020} era.


\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth, trim={2cm 8cm 2cm 8cm}, clip]{IEA_GAN_f1.pdf}
    \caption{
        \textbf{Pixel detector layout}~(taken from~\cite{belle2KEK}) The pixel detector~(PXD) is the inner-most sub-detector of the Belle~II experiment (\textbf{a}) and is configured in a two-layered overlapping sensor structure (\textbf{b}).
        PXD image examples~(\textbf{c}) for sensors \num{7} (top) and \num{25} (down).
        (\textbf{d}) The event generation pipeline with Geant4~\cite{agostinelliGeant4SimulationToolkit2003a}~(top) and using IEA-GAN~(bottom).
        Generating PXD data on the fly of analysis avoids the need to store them offline.
    }
    \label{fig:PXD_overview}
\end{figure}


%\begin{figure}
%    \centering
%    \begin{subfigure}[t]{0.6\textwidth}
%        \centering
%        \includegraphics[width=\textwidth]{plots/belleii_pxd.pdf}
%        \caption{}
%        \label{fig:pxd_location}
%    \end{subfigure}%
%    \hfill%
%    \begin{subfigure}[t]{0.3\textwidth}
%        \centering
%        \includegraphics[width=\textwidth]{plots/pxd_ladder}
%        \caption{}
%        \label{fig:pxd_layout}
%    \end{subfigure}
%    
%    \begin{subfigure}[t]{0.55\textwidth}
%        \centering
%        %\includegraphics[width=\textwidth]{plots/sen07.png}%
%        \includegraphics[width=\textwidth]{plots/sen07}
%        \vfill
%        \includegraphics[width=\textwidth]{plots/sen25}
%        \caption{}
%        \label{fig:pxd_sensor_examples}
%    \end{subfigure}%
%    \begin{subfigure}[t]{0.45\textwidth}
%        \centering
%        \includegraphics[width=0.9\textwidth]{plots/evtgen_geant4.pdf}
%        \vfill
%        \includegraphics[width=0.9\textwidth]{plots/evtgen_IEA-GAN.pdf}
%        \caption{}
%        \label{fig:evtgen}
%    \end{subfigure}%
%    \caption{
%        \textbf{Pixel detector layout} The pixel detector~(PXD) is the inner-most sub-detector of the Belle~II experiment (\textbf{a}) and is configured in a two-layered overlapping sensor structure (\textbf{b}).
%        PXD image examples~(\textbf{c}) for sensors \num{7} (top) and \num{25} (down).
%        (\textbf{d}) The event generation pipeline with Geant4~\cite{agostinelliGeant4SimulationToolkit2003a}~(top) and using IEA-GAN~(bottom).
%        Generating PXD data on the fly of analysis avoids the need to store them offline.
%    }
%    \label{fig:PXD_overview}
%\end{figure}


\section{Results}
\label{sec:results}
\subsection{IEA-GAN Architecture}
A Generative Adversarial Network~(GAN) is an unsupervised deep learning architecture that involves two networks, the Generator and the Discriminator, whose goal is to find a Nash equilibrium~\cite{nashNonCooperativeGames1951a} in a two-player min-max problem. IEA-GAN, as shown in~\cref{fig:IEAGAN_arch}, is a deep generative model based on a self-supervised relational grounding.

IEA-GAN's discriminator, $\mathrm{D}$, takes the set of detector response images $\textbf{x}_i \in \mathbf{R}^d$ coming from one event and embeds them as input nodes within a fully connected event graph in a self-supervised way. The Event graph is a weighted graph where the nodes are the embedded detector images in an event, and the edges are weighted by the degree of similarity between the detector images in each event~(see~\cref{sec:methods}).
IEA-GAN approximates the concept of an event~(the event graph) by contextual reasoning using the permutation equivariant Relational Reasoning Module~(RRM). RRM is a GAN-compatible, fully connected, multi-head Graph Transformer Network~\cite{battagliaRelationalInductiveBiases2018c,sharifzadehClassificationAttentionScene2021b,locatelloObjectCentricLearningSlot2020} that groups the image tokens in an event based on their contextual similarity. The contextual degree of similarity between samples in an event is learned by the attention mechanism in the RRM.
For multi-modal contrastive reasoning, the discriminator also takes the sensor embedding of the detector as class tokens~(see~\cref{sec:methods}). In the end, it compactifies both image and class modalities information by projecting the normalized graph onto a hypersphere as discussed in detail in~\cref{sec:methods}. 

To ensure that the Generator $G$ has a proper understanding of an event and captures the intra-event correlation, it first samples from a Normal distribution, $\mathcal{N}(0,1)$, at each event as random degrees of freedom~(Rdof), and decorates the sensor embeddings with this four-dimensional learnable Rdof~(see~\cref{sec:methods}). Then, for a self-supervised contextual embedding of each event, the RRM acts on top of this. Notably, Rdof differs from the original GAN~\cite{goodfellowGenerativeAdversarialNets2014a} Gaussian latent vectors. Rdof can be considered as an event-level learnable segment embedding~\cite{devlinBERTPretrainingDeep2019a} or perturbation~\cite{zhangWordEmbeddingPerturbation2018a} to the token embeddings, which can leverage the diversity of generated images. Combining these modules with the IEA Loss allows the Generator to gain insight and establish correlation among the samples in an event, thus improving its overall performance. 

Apart from the adversarial loss, IEA-GAN also benefits from a self-supervised and contrastive-based set of losses. The model understands the geometry of the detector through a proxy-based contrastive 2C loss~\cite{NEURIPS2020_f490c742} where the learnable proxies are the sensor embeddings over the hypersphere. Moreover, to improve the diversity and stability of the training, we introduce a Uniformity loss for the discriminator. The Uniformity loss can encourage the discriminator to give equal weight to all regions of the hypersphere~\cite{wangUnderstandingContrastiveRepresentation2020b} rather than just focusing on the areas where it can easily distinguish between real and fake data. Encouraging the discriminator to impose uniformity not only promotes more diverse and varied outputs but also mitigates issues such as mode collapse.

Another essential part of IEA-GAN is the IEA loss that addresses the class confusion~\cite{kangRebootingACGANAuxiliary2021a,rangwaniClassBalancingGAN2021} problem of the conditional generative models for fine-grained datasets. In the IEA-loss, the generator tries to imitate the discriminator's understanding of each event through a dyadic information transfer with a stop-gradient~(sg) for the discriminator. This can improve the ability of the generator to generate more fine-grained samples in the simulation process by being aware of the variability of conditions at each event.


%begin{figure}[!htp]
%   \centering
%   % \includegraphics[width=\textwidth,clip]{plots/IEAGAN.pdf}
%   \begin{subfigure}[t]{\textwidth}
%   \centering
%   \includegraphics[width=\textwidth]{plots/IEAGAN_main.pdf}
%   \caption{Rdof stands for Random degrees of freedom, which decorates the generator's sensor/layer embedding with an event-level learnable embedding responsible for the generator's intra-event correlation. The Relational Reasoning Modules~(RRM) in the generator and the discriminator do the intra-event reasoning by clustering class/image embeddings based on their contextual similarity, respectively.
%   The red lines correspond to the forward and backward passes of the generator. The black lines correspond to the forward and backward passes of the discriminator. The discriminator is trained with the Adversarial loss, see~\cref{eq:hinge_loss}, 2C loss, see~\cref{eq:2C_loss} and the Uniformity loss, see~\cref{eq:uniformity_loss}. On the other hand, the generator uses the Adversarial loss, 2C loss, and the IEA loss, see~\cref{eq:iea_loss}. Sg means stop-gradient for the discriminator from the IEA loss, a self-supervised dyadic-aware loss for the generator.}
%   \label{fig:IEA_GAN}
%   \end{subfigure}
%   \hfill%
%   \begin{subfigure}[t]{\textwidth}
%   \centering
%   \includegraphics[width=0.7\textwidth]{plots/RRM.pdf}
%   \caption{The Relational Reasoning Module~(RRM) for the generator~(left) and the discriminator~(right)that creates event graphs at each iteration. The attention mechanism inside the RRM. learns the contextual degree of similarity between samples in an event.}
%   \label{fig:RRM_components}
%   \end{subfigure}
%   \caption{IEA-GAN architecture~(\textbf{a}) and Relational Reasoning Module components~(\textbf{b}).}
%   \label{fig:IEAGAN_arch}
%end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth, trim={2cm 15cm 2cm 1cm}, clip]{IEA_GAN_f2.pdf}
    \caption{IEA-GAN architecture~(\textbf{a}) and Relational Reasoning Module components~(\textbf{b}), and the IEA Self-Supervised Loss~(\textbf{c}).
    \textbf{a} Rdof stands for Random degrees of freedom, which decorates the generator's sensor/layer embedding with an event-level learnable embedding responsible for the generator's intra-event correlation. The Relational Reasoning Modules~(RRM) in the generator and the discriminator do the intra-event reasoning by clustering class/image embeddings based on their contextual similarity, respectively. The red lines correspond to the forward and backward passes of the generator. The black lines correspond to the forward and backward passes of the discriminator. The discriminator is trained with the Adversarial loss, see~\cref{eq:hinge_loss}, 2C loss, see~\cref{eq:2C_loss} and the Uniformity loss, see~\cref{eq:uniformity_loss}. On the other hand, the generator uses the Adversarial loss, 2C loss, and the IEA loss, see~\cref{eq:iea_loss}, illustrated in~(c). Sg means stop-gradient for the discriminator from the IEA loss, a self-supervised dyadic-aware loss for the generator. \textbf{b} The Relational Reasoning Module~(RRM) for the generator~(left) and the discriminator~(right) create event graphs at each iteration. The attention mechanism inside the RRM learns the contextual degree of similarity between samples in an event. \textbf{c} The IEA-loss imposes a pair-wise fine-grained class-to-class imitation force for the generator. Sg indicates that gradients are stopped for the discriminator, and only the generator's gradients will be updated.}
    \label{fig:IEAGAN_arch}
\end{figure}

%\begin{figure}[!htp]
%    \centering
%    \begin{subfigure}[t]{\textwidth}
%        \centering
%        \includegraphics[width=\textwidth]{plots/IEAGAN_main.pdf}
%        \caption{}
%        \label{fig:IEA_GAN}
%    \end{subfigure}
%
%    \begin{subfigure}[t]{0.4\textwidth}
%        \includegraphics[width=\textwidth]{plots/RRM.pdf}
%        \caption{}
%        \label{fig:RRM_components}
%    \end{subfigure}
%    \hfil
%    \begin{subfigure}[t]{0.59\textwidth}
%        \includegraphics[width=\textwidth]{plots/IEAloss.pdf}
%        \caption{}
%        \label{fig:IEA_loss}
%    \end{subfigure}
%    
%    \caption{IEA-GAN architecture~(\textbf{a}) and Relational Reasoning Module components~(\textbf{b}), and the IEA Self-Supervised Loss~(\textbf{c}).
%    \textbf{a} Rdof stands for Random degrees of freedom, which decorates the generator's sensor/layer embedding with an event-level learnable embedding responsible for the generator's intra-event correlation. The Relational Reasoning Modules~(RRM) in the generator and the discriminator do the intra-event reasoning by clustering class/image embeddings based on their contextual similarity, respectively. The red lines correspond to the forward and backward passes of the generator. The black lines correspond to the forward and backward passes of the discriminator. The discriminator is trained with the Adversarial loss, see~\cref{eq:hinge_loss}, 2C loss, see~\cref{eq:2C_loss} and the Uniformity loss, see~\cref{eq:uniformity_loss}. On the other hand, the generator uses the Adversarial loss, 2C loss, and the IEA loss, see~\cref{eq:iea_loss}, illustrated in~(c). Sg means stop-gradient for the discriminator from the IEA loss, a self-supervised dyadic-aware loss for the generator. \textbf{b} The Relational Reasoning Module~(RRM) for the generator~(left) and the discriminator~(right) create event graphs at each iteration. The attention mechanism inside the RRM learns the contextual degree of similarity between samples in an event. \textbf{c} The IEA-loss imposes a pair-wise fine-grained class-to-class imitation force for the generator. Sg indicates that gradients are stopped for the discriminator, and only the generator's gradients will be updated.}
%    \label{fig:IEAGAN_arch}
%\end{figure}



\subsection{IEA-GAN Evaluation}
\label{sec:eval}
Our study showcases the performance of IEA-GAN in generating ultra-high-granularity detector responses, demonstrated through its successful application to the ultra-high dimensional data of the Pixel Vertex Detector~(PXD) at Belle~II, consisting of over 7.5 million pixel channels. Furthermore, our findings reveal that the Frchet inception distance~(FID)~\cite{heuselGANsTrainedTwo2017a} and Kernel Inception Distance~(KID)~\cite{binkowskiDemystifyingMMDGANs2021} metrics for detector simulation are a very versatile estimator in conjunction with the marginal distributions and is associated with the other image level metrics. 
We show that by using IEA-GAN, we are able to capture the underlying distributions so that we can generate and amplify detector response information with a very good agreement with the Geant4 distributions. We also find out that the SOTA models in high-resolution image generation, even with an in-depth hyperparameter tuning analysis, do not perform well in comparison.

For evaluation, we have two categories of metrics: image level and physics level. As we are interested in having the best pixel-level properties, diversity, and correlation of the generated images simultaneously while adhering to minimal generator complexity due to computational limitations, choosing the best iteration to compare results is challenging.
Hence, we choose models' weights with the best FID for all comparisons. To compute the FID and KID scores, based on the recent Clean-FID project~\cite{parmarAliasedResizingSurprising2022a}, we entirely fine-tuned the Inception-V3~\cite{szegedyRethinkingInceptionArchitecture2016a} model on the PXD images, as the PXD images are very different from the natural images used in their initial training. The downstream task for the fine-tuning was multi-class classification, involving 40 different sensors with which it acquired the ability to discriminate sensors. In other words, the classification task of the Inception-V3 involved identifying the specific sensor ID from a range of \num{1} to \num{40}.
This task required the model to identify the sensor to which each data sample belonged by discerning the data characteristics inherent to each sensor.
This process can be done for any other detector dataset. 
FID measures the similarity of the generated samples representations to those of samples from the real distribution. 
Given large sampling statistics, for each hidden activation of the Inception model, the FID evaluates the Frchet distance, also known as Wasserstein-2 distance, between the first two moments of the activation distributions. As demonstrated to be useful and practical in the natural image analysis domain, FID performs~\cite{xuEmpiricalStudyEvaluation2018} well in terms of discriminability, diversity, and robustness despite only modeling the first two moments of the distributions in the feature space.
The lower the FID score, the more similar the distributions of the real and generated samples are. 
Kernel Inception Distance~(KID) is another metric similar to FID, used for evaluating the quality of generative models. Unlike FID, KID uses a kernel two-sample test, which provides an unbiased estimate of the distance between distributions and is more robust to small sample sizes.


We compare IEA-GAN with three other models~(only for image-level metrics) and the reference, which is the Geant4-simulated~\cite{agostinelliGeant4SimulationToolkit2003a} dataset. 
The baselines are the SOTA in conditional image generation: BigGAN-deep~\cite{brockLargeScaleGAN2019a} and ContraGAN~\cite{NEURIPS2020_f490c742}.
We also compare IEA-GAN with the previous works on the PXD image generation task: PE-GAN~\cite{hashemiPixelDetectorBackground2021a} and WGAN-gp~\cite{srebreGenerationBelleII2020a}~(only for FID). 

\Cref{tab:fid} demonstrates that generated images by IEA-GAN have the lowest FID and KID score compared to the other models and outperform them by \num{42}\%. This indicates that our model is able to generate synthetic samples that are much closer to the target data than the samples generated by the other models. The low FID and KID values for the Test Data indicate that the model has achieved a full understanding of the full data. In~\cref{tab:fid_jitter} in supplementary note, we demonstrate the sensitivity and possible interoperability of FID to various types of image distortions directly linked to the underlying physics recorded by the corresponding sensor. We achieved this by introducing controlled changes or jitters to the images and tracking their impact on the FID score.

\begin{table}[ht]
\begin{minipage}{\textwidth}
    \begin{center}
    \caption{
    FID and KID comparison between models~(all models in the benchmark are highly tuned to the current problem and dataset), averaged across six random seeds~(retrained and averaged across six models trained with different random seeds).
    The lower the FID and KID, the better the image quality and diversity.}
    \label{tab:fid}
    \setlength{\tabcolsep}{2.5pt} % adjust this value to suit your needs, default is 6pt
    \begin{tabular}{@{}l|llllll@{}}
        \toprule
        & WGAN-gp & BigGAN-deep & ContraGAN & PE-GAN & IEA-GAN & Test Data \\ 
        \midrule
        \textbf{FID}  & $12.09$ & $4.40\pm 0.88$ & $3.14\pm 0.74$ & $2.61\pm 0.91$ & $\mathbf{1.50\pm 0.16}$ & $2.4 \times 10^{-5}$ \\
        \midrule
        $\textbf{KID}^{(\times 10^{-3})}$ & $9.6$ & $3.1\pm 0.1$ & $1.5\pm 0.2$& $2.1\pm 0.4$ & $\mathbf{1.0\pm 0.2}$ & $7.6 \times 10^{-1}$ \\
        \bottomrule
    \end{tabular}
    \end{center}
\end{minipage}
\end{table}

\begin{table}[htbp]
    \centering
    \caption{FID Score on PXD images after different jittering methods applied to them, providing interoperability to it's value.} % Unnumbered caption
    \label{tab:fid_jitter} % Label for referencing
    \begin{tabular}{@{}p{6cm}p{3cm}@{}} % p{} is used for paragraph column with text justification
        \toprule
        \textbf{Image Jitterings} & \textbf{FID} \\ [0.5ex] 
        \midrule
        None &  $2.4 \times 10^{-5}$\\
        Random Masking~(dead zones) &  14.58\\ 
        Random Noise &  87.23\\ 
        Random Rotation~(30 degrees) &  23.69\\
        Random Rotation~(10 degrees) &  2.81\\
        Random Translation~(0.1, 0.1) &  1.99\\
        Random Shear~(10, 10) &  23.53\\
        Random Zoom &  9.06\\
        High-Intensity Charge Smearing & 3.16\\
        Low-Intensity Charge Smearing & 47.24\\
        \bottomrule
    \end{tabular}
\end{table}



At the pixel level, there are the pixel intensity distribution, occupancy distribution, and mean occupancy.
The pixel intensity distribution defines the distribution of the energy of the background hits. 
The occupancy distribution and the pixel intensity distribution are evaluated over all sensors of a given number of events, while the mean occupancy corresponds to the mean value of sparsity across events for each sensor.
This pixel-level information is essential since upon physics analysis via the basf2 software~\cite{kuhrBelleIICore2018}, when one wants to use the images and overlay the extracted information on the signal hits, the sparsity of the image defines the volume of the background hits on each sensor.
The pixel intensity distribution, the occupancy distribution, as well as the mean occupancy per sensor are shown in \Cref{fig:occupancy-intensity}. The distributions for the IEA-GAN model show the closest agreement with the reference. 

The bimodal distribution of the occupancy comes from the geometry of the detector, as the sensors are not in a cylindrical shape like a calorimeter but in an annulus shape. This indicates how challenging generating this detector signature is concerning both its geometry and resolution. In order to capture the correct bi-modality of the occupancy distribution, the RRM and the Uniformity loss play an important role. By using the Uniformity loss in the discriminator, the generator is incentivized to produce samples that are not biased towards a particular mode or class, leading to a wider bimodal distribution of generated samples.

Moreover, by utilizing the RRM module that considers the inter-dependencies and correlations among the samples within an event, the IEA-GAN exhibits a superior consistency with high-energy hits, which enhances the diversity of generated samples in regions with lower occurrence rates.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth, trim={2cm 15cm 2cm 2cm}, clip]{IEA_GAN_f3.pdf}
    \caption{Pixel intensity distribution in linear~(top left) and logarithmic scale~(top right), the distribution of the occupancy~(bottom left) and the mean occupancy per sensor~(bottom right) for \num{10000} events.}
    \label{fig:occupancy-intensity}
\end{figure}


%\begin{figure}[ht]
%    \centering
%    \includegraphics[width=0.49\textwidth]{plots/pixel_intensity_lin_new.pdf}%
%    \includegraphics[width=0.49\textwidth]{plots/pixel_intensity_log_new.pdf}
%    \includegraphics[width=0.49\textwidth]{plots/occupancy_distribution_new.pdf}
%    \includegraphics[width=0.49\textwidth]{plots/mean_occupancy_new.pdf}
%    \caption{Pixel intensity distribution in linear~(top left) and logarithmic scale~(top right), the distribution of the occupancy~(bottom left) and the mean occupancy per sensor~(bottom right) for \num{10000} events.}
%    \label{fig:occupancy-intensity}
%\end{figure}

Along with all these image-level metrics, we also need an intra-event sensitive metric.
All the above metrics are equivariant under permutation between the samples among events. In other words, if we randomly shuffle the samples between events while fixing the sensor number, all the discussed metrics are unchanged. Hence, we need a metric that looks at the context of each event individually in its event space and goes beyond the sample space.
Ergo, we compute the Spearman's correlation between the occupancy of the sensors along the population of generated events,

\begin{equation}
\mathbf{r}_s = \mathrm{Corr_p}(\mathrm{R}(\biguplus_{i=1}^{M=40}(\|\mathbf{x}_i\|_0)),\mathrm{R}(\biguplus_{i=1}^{M=40}(\|\mathbf{x}_i\|_0))),
\label{eq:spearman_corr}
\end{equation}

where $\mathrm{R}(.)$ is the rank operator, a function that assigns a rank to each number in a list as in the definition of Spearman's correlation, and $\mathrm{Corr_p}(.)$ is the Pearson Correlation function. $\biguplus$ is the disjoint union operator that symbolizes the concatenation operation. The norm with subscript 0, denoted by $\|.\|_0$, is the L0 measure. It is a function that counts the number of non-zero elements in a vector. In this work, it is used to calculate the occupancy of the sensors, i.e., the number of non-zero elements in the sensor image $x_i$.
The coefficients by PE-GAN are random values in the range $[-0.2,0.2]$, whereas IEA-GAN images show a meaningful correlation among their generated images.
Even though the desired correlation is different from the reference, as shown in~\cref{fig:spearman_corr}, IEA-GAN understands a monotonically positive correlation for intra-layer sensors and a primarily negative correlation for inter-layer sensors. 

In order to demonstrate that the learned correlation is actually meaningful, 
we incorporate the Mantel test~\cite{mantelDetectionDiseaseClustering1967,sokalBiometry1995}, which is a significance test of the correlation between two distance/correlation matrices excluding the diagonal part.
The Mantel test works by comparing each pair of corresponding elements in the two matrices. The null hypothesis is that there's no relationship between the two sets of correlations, and the test statistic is a correlation coefficient.
The significance of the observed correlation is evaluated using permutation testing. This involves randomly rearranging the elements of one matrix many times, recalculating the test statistic each time, and then seeing how extreme the observed test statistic is relative to this null distribution of test statistics. If the observed test statistic is very extreme, then the p-value is less than \num{0.05}, and the null hypothesis is rejected.
For IEA-GAN, the Mantel test results show a veridical correlation of $18 \pm 2\%$ with empirical p-value $0.0013$. 
As the p-value is less than 0.05, we can reject the null hypothesis and observe that there is significant evidence for a correlation between the two sets of matrices.
This suggests that the sensor classes that are more correlated in the Geant4 samples tend to also be correlated in the generated ones by IEA-GAN.
Whereas for PE-GAN, the Mantel test results show a veridical correlation of $0.2\%$ with empirical p-value $0.96$ in support of the null hypothesis.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth, trim={2cm 22cm 2cm 2cm}, clip]{IEA_GAN_f4.pdf}
    \caption{Spearman's correlation between the occupancy of Geant4 sensor images~(left), and sensor images from IEA-GAN~(center), sensor images from PE-GAN~(right).}
    \label{fig:spearman_corr}
\end{figure}


%\begin{figure}[ht]
%    \centering
%    \includegraphics[width=\textwidth]{plots/corr_all}
%    \caption{Spearman's correlation between the occupancy of Geant4 sensor images~(left), and sensor images from IEA-GAN~(center), sensor images from PE-GAN~(right).}
%    \label{fig:spearman_corr}
%\end{figure}

%\subsubsection{Physics-Level Evaluation:}
While image level metrics indicate the low-level quality of simulations, we must also confirm that the resulting simulations are reasonable physics-wise when the entire detector is considered as a whole. For this, we do the tracking analysis to examine the Helix Parameter Resolutions~(HPR). The quality of the tracking and HPRs directly impacts the precision and accuracy of the measurements.

At the Belle~II experiment, after each collision event, tracks propagating in vacuum in a uniform magnetic eld move roughly along a helix path described by the ve helix parameters $\{d_0, z_0, \phi_0,\omega, \tan\lambda\}$ with respect to a pivot point~\cite{kouBelleIIPhysics2020a}.
The difference between the true and reconstructed helix parameters defines the resolution for the corresponding helix parameter.
The track parameter resolution is affected by the number of hits, the hit intensity, and the underlying intra-event correlation. Understanding how the background effects impact the HPR can give us crucial insights into the overall performance of the detector and the quality of the data it produces. 

In this study, we utilize the same event generation and track reconstruction~(employing the same set of signal events across all simulations to factor out signal fluctuations) for all simulations, ensuring that the signal hits across simulations are essentially identical.
Consequently, the true track information remains consistent. Then, the primary point of difference lies in the origin of the background. This distinct differentiation allows any disparities identified in the tracking parameter resolutions to be attributed largely to the different backgrounds and their generation origin, enabling a direct evaluation of the quality and performance of the IEA-GAN model in comparison to Geant4. 
It is essential to note that the core objective of this study is not to isolate or mitigate the effects of background noise but to simulate and measure its impact on track reconstruction efficiency accurately. The background affects the tracking to make it assign wrong hits. The background processes can create additional hits in the detector simulation that are not part of the actual particle trajectory. When these spurious hits are incorporated into the track reconstruction process, it leads to imperfect track parameter~(Helix parameters) resolution. 
Thus, the effectiveness of the surrogate model is evaluated based on how well it replicates the Geant4 simulated background effects. As a result, we aim to ensure that IEA-GAN can generate the PXD background that impacts the track reconstruction process like Geant4-simulated background processes would.

First, as a physics motivation, we highlight the impact of the intra-event correlation by shuffling Geant4 samples. In other words, we show that in a physics analysis, the intra-event sensor-by-sensor correlation influences the performance of the tracking parameters.
We examine the results by comparing the standard deviation of the Helix parameter resolutions and the 2-sample KolmogorovSmirnov test~(KS test)~\cite{massey1951kolmogorov} between the shuffled and unshuffled Geant4 PXD background. 
The standard deviation for each resolution, $\Delta \text{p}$, where $\text{p}$ is a Helix parameter, is computed as follows:

\begin{equation}
\sigma_\text{p} = \sqrt{\frac{\sum_{i=1}^{n} (\Delta \text{p}^i - \overbar{\Delta \text{p}})^2}{n}},
\label{eq:std}
\end{equation}

where $\sigma_p$ is the standard deviation for the Helix parameter p, $n$ is the number of the reconstructed tracks, and $\overbar{\Delta \text{p}}$ is the resolution mean. 
The Error~(margin of error) for the standard deviation~(using the confidence interval method)~\cite{devoreModernMathematicalStatistics2011,ramachandranMathematicalStatisticsApplications2020} is 

\begin{equation}
\text{Error} = \frac{\sqrt{\frac{n\sigma_\text{p}^2}{\chi^2_{1-\alpha/2, n}}} - \sqrt{\frac{n\sigma_\text{p}^2}{\chi^2_{\alpha/2, n}}}}{2}.
\label{eq:error}
\end{equation}

Where $\sigma_p$ is the standard deviation computed using~\cref{eq:std}, $n$ is the number of the reconstructed tracks, $\chi^2_{\alpha/2, n}$ and $\chi^2_{1-\alpha/2, n}$ are the critical values from the chi-square distribution for $n$ degrees of freedom, and $\alpha$ is the significance level for a $95\%$ confidence interval.
For \num{5000} events, the results for the high momentum tracks, with more than \SI{0.4}{\giga\electronvolt} show that there is strong evidence that losing the intra-event sensor-by-sensor correlation would impact the resolution and thus the precision of the $\mathbf{d}_0$, $\phi_0$ and $\omega$ Helix parameters. 
For the $\mathbf{z}_0$ and $\tan\lambda$ parameter, there is no significant difference in the standard deviation of the resolutions. However, the KS test for these parameters yields low p-values, indicating a high discrepancy between the shape of the two distributions.

In the context of each Helix parameter, for $\mathbf{d}_0$ impact parameter, the significant standard deviation in resolution shows that the loss of correlation directly impacts how well we can measure the particle's closest approach to the origin in the transverse plane. Losing sensor-by-sensor correlations that help to associate track hits correctly leads to a more spread out distribution of reconstructed values as shown in~\cref{fig:d0_dplot} and~\cref{tab:shuf_helix}. This could affect subsequent analyses, such as identifying primary and secondary vertices, especially in scenarios where particles have negligible deflection~(high momentum regime).

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth, trim={2cm 21cm 2cm 2cm}, clip]{IEA_GAN_f5.pdf}
     \caption{The pull plot for the resolution of $d_0$~(left) and $z_0$~(right) in the presence of correlated~(unshuffled) background and uncorrelated~(shuffled) background at high momentum regime. The pull, $\pi(\Delta(\text{p}))$ where p is a Helix parameter, is computed as $\pi(\Delta(\text{p})) = \frac{{\Delta{\text{p}}}^{\text{Shuff.}} -~{\Delta{\text{p}}}^{\text{Unshuff.}}}{\sqrt{\sigma_{{\Delta{\text{p}}}^{\text{Shuff.}}}^2 +~ \sigma_{{\Delta{\text{p}}}^{\text{Unshuff.}}}^2}}$.}
     \label{fig:d0_dplot}
\end{figure}

%\begin{figure}[ht]
% \centering
% \begin{subfigure}{0.49\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{IEA-GAN/plots/new_plots/shuff/pull_plot_d0.pdf} 
% \end{subfigure}
% \begin{subfigure}{0.49\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{IEA-GAN/plots/new_plots/shuff/pull_plot_z0.pdf}
% \end{subfigure}
% \label{fig:d0_dplot}
% \caption{The pull plot for the resolution of $d_0$~(left) and $z_0$~(right) in the presence of correlated~(unshuffled) background and uncorrelated~(shuffled) background at high momentum regime. The pull, $\pi(\Delta(\text{p}))$ where p is a Helix parameter, is computed as $\pi(\Delta(\text{p})) = \frac{{\Delta{\text{p}}}^{\text{Shuff.}} -~{\Delta{\text{p}}}^{\text{Unshuff.}}}{\sqrt{\sigma_{{\Delta{\text{p}}}^{\text{Shuff.}}}^2 +~ \sigma_{{\Delta{\text{p}}}^{\text{Unshuff.}}}^2}}$.}
%\end{figure}

For the $\phi_0$ parameter, the insignificant resolution standard deviation difference and KS test result suggest that the lack of layer correlation doesn't significantly impact the distribution and precision of measurements of the azimuthal for high momentum tracks.
The higher error in the standard deviation of $\Delta \mathbf{z}_0$ in the shuffled data suggests that the lack of correlation between detector layers introduces more uncertainty in determining the longitudinal interaction point. High momentum tracks are less likely to deviate significantly in the z-direction. Combined with the insignificant KS test result, this indicates a fundamental difference in how particle trajectories are reconstructed in the z-direction without layer correlation.
$\omega$ is a measure of the curvature of the particle's track and is inversely proportional to the particle's momentum. For high-momentum particles, we would expect the curvature to be smaller since higher-momentum particles travel more linearly.
The standard deviation for $\Delta\omega$ shows a slight discrepancy between the shuffled and unshuffled data, but the KS test doesn't show a significant difference. This indicates that while the overall distributions of the curvature resolution don't significantly differ, there's a minor difference in the precision with which the curvature is reconstructed, which could have implications for subsequent physics analyses that depend on accurate momentum information.
Despite the insignificant resolution difference, the significant KS test result for $\Delta \tan\lambda$ suggests differences in the inclination distributions of high momentum tracks between the shuffled and unshuffled data. This might indicate that the inclination of the track, which is also related to the momentum in the longitudinal direction, is affected by the loss of correlation between layers and sensors.

\begin{table}[ht]
\centering
\begin{tabular}{@{}lcc|cc@{}}
\toprule
Parameter & \multicolumn{2}{c}{Standard deviation $\pm$ error} & KS statistic & p-value \\ 
\cmidrule(lr){2-3}
          & Shuffled Geant4 & Unshuffled Geant4 \\
\midrule
$\Delta d_0$~[cm]        & $0.1343 \pm 0.0007$ & $0.0732 \pm 0.0004$ & $0.0067$ & $0.7655$ \\
$\Delta \phi_0$~[rad]       & $0.2158 \pm 0.0011$ & $0.1859 \pm 0.0009$ & $0.0066$ & $0.7899$ \\
$\Delta z_0$~[cm]        & $5.0076 \pm 0.0253$ & $4.9341 \pm 0.0249$ & $0.0152$ & $0.0211$ \\
$\Delta \omega~[\text{cm}^{-1}]$     & $0.0010 \pm 0.0001$ & $0.0008 \pm 0.0001$ & $0.0138$ & $0.0485$ \\
$\Delta \tan\lambda$ & $0.0388 \pm 0.0002$ & $0.0382 \pm 0.0002$ & $0.0167$ & $0.0086$ \\
\bottomrule
\end{tabular}
\caption{Standard deviation~(using~\cref{eq:std} and~\cref{eq:error}) and KS test results for the shuffled and unshuffled Geant4 data across the 5 Helix parameters.}
\label{tab:shuf_helix}
\end{table}

Now, we compare IEA-GAN with PE-GAN~(the second-best performing model on the overall image level metrics) for the resolutions of all five helix parameters as shown in~\cref{fig:helix_param_res} and~\cref{tab:model_compare} for \num{5000} events for high momentum tracks $(P_T>\SI{0.4}{\giga\electronvolt})$. In the low momentum region, the resolution performance of the models is on par. The tail behavior of $\Delta \phi$ comes from curling tracks where the direction of the tracks is swapped.
Our meticulous comparison revealed that the standard deviation of these parameters, produced by the IEA-GAN model, approximates the Geant4 reference more closely, outperforming the PE-GAN model in each instance. 
Moreover, the Kolmogorov-Smirnov test results further consolidated our findings, showing higher p-values for the IEA-GAN model, thus adhering more accurately to the Geant4 reference. 
Another interesting observation is that, in comparison with the shuffled Geant4, IEA-GAN shows a more significant KS test p-value for $\mathbf{z}_0$, $\omega$, and $\tan\lambda$ resolutions and a more precise $\mathbf{d}_0$ reconstruction. 
Looking at the precision of IEA-GAN's $\mathbf{d}_0$ and $\mathbf{z}_0$ reconstruction, one can also deduce that despite only capturing a weak correlation, the downstream physics analysis, track reconstruction, benefits from even the weak correlation captured by IEA-GAN.

%Over the low momentum region, $(P_T<0.4)$, even though no significant difference was observed with the Helix parameter resolution, we observed a slight discrepancy over the momentum versus number of PXD hits distribution, see \Cref{fig:pxdhits_pt}. The inability of PE-GAN to generate 5-PXD hit events despite having similar helix parameter resolution to Geant4 and IEA-GAN could be related to modeling the high-level interaction between particles and the detector geometry. The low-momentum regime, where these 5-hit events are observed, is a challenging scenario because particles with low momentum are more likely to scatter and undergo complex interactions within the detector.

%\begin{figure}[ht]
%    \centering
%    \includegraphics[width=\textwidth]{plots/pxdhits_comparison.pdf} 
%    \caption{Caption for the PDF figure}
%    \label{fig:pxdhits_pt}
%\end{figure}

As a result of the analysis, we observe a good agreement between the IEA-GAN and Geant4, both in the tail segments~(standard deviation) and precision of the resolutions where the most significant difference between Geant4 and no background is found. 
Hence, not only does IEA-GAN demonstrate a close image level agreement with Geant4, but it maintains a proper reconstructed physical behavior during track reconstruction as well.

\begin{table}[htb]
\centering
\begin{tabular}{@{}lcccccc@{}}
\toprule
Model & Parameter & \multicolumn{2}{c}{Standard deviation $\pm$ error} & KS statistic & p-value \\ 
\cmidrule(lr){3-4}
      &           & Model & Geant4 \\
\midrule
\multirow{5}{*}{PEGAN} & $\Delta d_0$~[cm]       & $0.1709 \pm 0.0009$ & $0.0732 \pm 0.0004$ & $0.0156$ & $0.0164$ \\
                           & $\Delta\phi_0$~[rad]     & $0.2207 \pm 0.0011$ & $0.1859 \pm 0.0009$ & $0.0120$ & $0.1193$ \\
                           & $\Delta z_0$~[cm]      & $6.9073 \pm 0.0349$ & $4.9341 \pm 0.0249$ & $0.0183$ & $0.0029$ \\
                           & $\Delta \omega~[\text{cm}^{-1}]$    & $0.0014 \pm 0.0001$ & $0.0008 \pm 0.0001$ & $0.0116$ & $0.1425$ \\
                           & $\Delta\tan\lambda$     & $0.0579 \pm 0.0003$ & $0.0382 \pm 0.0002$ & $0.0179$ & $0.0037$ \\
\midrule
\multirow{5}{*}{IEA-GAN}   & $\Delta d_0$~[cm]       & $0.0762 \pm 0.0004$ & $0.0732 \pm 0.0004$ & $0.0104$ & $0.2373$ \\
                           & $\Delta\phi_0$~[rad]     & $0.1905 \pm 0.0010$ & $0.1859 \pm 0.0009$ & $0.0109$ & $0.1939$ \\
                           & $\Delta z_0$~[cm]       & $5.1467 \pm 0.0261$ & $4.9341 \pm 0.0249$ & $0.0073$ & $0.6814$ \\
                           & $\Delta \omega~[\text{cm}^{-1}]$    & $0.0010 \pm 0.0001$ & $0.0008 \pm 0.0001$ & $0.0103$ & $0.2537$ \\
                           & $\Delta\tan\lambda$     & $0.0412 \pm 0.0002$ & $0.0382 \pm 0.0002$ & $0.0068$ & $0.7538$ \\
\bottomrule
\end{tabular}
\caption{Comparison of standard deviation and KS test results for the PE-GAN and IEA-GAN models with the Geant4 reference across 5 Helix parameters for high momentum tracks.}
\label{tab:model_compare}
\end{table}



%\begin{figure}[ht]
%\centering
%\begin{subfigure}{.5\textwidth}
%\centering
%\includegraphics[width=0.8\linewidth]{IEA-GAN/plots/new_phys_figs/iea/bplot_0.pdf}
%\includegraphics[width=0.8\linewidth]{IEA-GAN/plots/new_phys_figs/iea/bplot_1.pdf}
%\includegraphics[width=0.8\linewidth]{IEA-GAN/plots/new_phys_figs/iea/bplot_2.pdf}
%\includegraphics[width=0.8\linewidth]{IEA-GAN/plots/new_phys_figs/iea/bplot_3.pdf}
%\includegraphics[width=0.8\linewidth]{IEA-GAN/plots/new_phys_figs/iea/bplot_4.pdf}
%\end{subfigure}%
%\begin{subfigure}{.5\textwidth}
%\centering
%\includegraphics[width=0.8\linewidth]{IEA-GAN/plots/new_phys_figs/pegan/bplot_0.pdf}
%\includegraphics[width=0.8\linewidth]{IEA-GAN/plots/new_phys_figs/pegan/bplot_1.pdf}
%\includegraphics[width=0.8\linewidth]{IEA-GAN/plots/new_phys_figs/pegan/bplot_2.pdf}
%\includegraphics[width=0.8\linewidth]{IEA-GAN/plots/new_phys_figs/pegan/bplot_3.pdf}
%\includegraphics[width=0.8\linewidth]{IEA-GAN/plots/new_phys_figs/pegan/bplot_4.pdf}
%\end{subfigure}
%\caption{ The boxplot for comparing the Helix parameter resolutions for $d_0$~(row 1), $\phi_0$~(row 2), $z_0$~(row 3), $\omega_0$~(row 4), and $\tan \lambda$~(row 5).
%For each parameter, the left figure corresponds to the IEA-GAN simulated background, and the right figure corresponds to the PE-GAN simulated background. The $\pm 5$ standard deviations interval for the no-background case is shown in all 3 cases for reference as a red dashed line.
%}
%\label{fig:helix_param_res}
%\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth, trim={2.cm 2.5cm 2.cm 2.5cm}, clip]{IEA_GAN_f6.pdf}
    \caption{The pull plots for comparing the Helix parameter resolutions for $d_0$, $z_0$, $\phi_0$, $\omega$, and $\tan \lambda$. For each parameter, the left figure corresponds to the IEA-GAN simulated background and the right-side figure corresponds to the PE-GAN simulated background.}
    \label{fig:helix_param_res}
\end{figure}

%\begin{figure}[htb]
%\centering
%\begin{subfigure}{.48\textwidth}
%\centering
%\includegraphics[width=0.8\linewidth]{IEA-GAN/plots/new_plots/iea/pull_plot_d0.pdf}
%\includegraphics[width=0.8\linewidth]{IEA-GAN/plots/new_plots/iea/pull_plot_z0.pdf}
%\includegraphics[width=0.8\linewidth]{IEA-GAN/plots/new_plots/iea/pull_plot_phi0.pdf}
%\includegraphics[width=0.8\linewidth]{IEA-GAN/plots/new_plots/iea/pull_plot_omega.pdf}
%\includegraphics[width=0.8\linewidth]{IEA-GAN/plots/new_plots/iea/pull_plot_tlmd.pdf}
%\end{subfigure}%
%\begin{subfigure}{.48\textwidth}
%\centering
%\includegraphics[width=0.8\linewidth]{IEA-GAN/plots/new_plots/pegan/pull_plot_d0.pdf}
%\includegraphics[width=0.8\linewidth]{IEA-GAN/plots/new_plots/pegan/pull_plot_z0.pdf}
%\includegraphics[width=0.8\linewidth]{IEA-GAN/plots/new_plots/pegan/pull_plot_phi0.pdf}
%\includegraphics[width=0.8\linewidth]{IEA-GAN/plots/new_plots/pegan/pull_plot_omega.pdf}
%\includegraphics[width=0.8\linewidth]{IEA-GAN/plots/new_plots/pegan/pull_plot_tlmd.pdf}
%\end{subfigure}
%\caption{ The pull plots for comparing the Helix parameter resolutions for $d_0$, $z_0$, $\phi_0$, $\omega$, and $\tan \lambda$.
%For each parameter, the left figure corresponds to the IEA-GAN simulated background and the right-side figure corresponds to the PE-GAN simulated background.
%}
%\label{fig:helix_param_res}
%\end{figure}







%in two transverse momentum cuts, above \SI{0.2}{\giga\electronvolt} for high momentum background hits and below \SI{0.2}{\giga\electronvolt} for background hits with low momentum.
% As expected, the effect of the background is more visible over the tails of the resolution distribution.
% The other HPRs are shown in the appendix in \Cref{fig:hpr_phi0_omega_tlmd}.
% As a result, IEA-GAN generated PXD background shows a close resemblance to the Geant4 simulated background at the physics level as well.
%
%\begin{figure}[ht]
%\centering
%\includegraphics[width=0.33\textwidth]{plots/physics_figs/d0_plot.pdf}%
%\includegraphics[width=0.33\textwidth]{plots/physics_figs/z0_plot.pdf}%
%\includegraphics[width=0.33\textwidth]{plots/physics_figs/phi0_plot.pdf}
%\includegraphics[width=0.33\textwidth]{plots/physics_figs/omega_plot.pdf}%
%\includegraphics[width=0.33\textwidth]{plots/physics_figs/tlmd_plot.pdf}
%\caption{
%Helix parameter resolutions for $d_0$~(top left), $z_0$~(top middle), $\phi_0$~(top right), $\omega_0$~(bottom left), and $\tan \lambda$~(bottom right).
%Blue corresponds to the IEA-GAN simulated background, red to Geant4, and blue to resolution with no background overlay.
%}
%\label{fig:helix_param_res}
%\end{figure}
%
\FloatBarrier
\section{Discussion}
\label{sec:discuss}
In this work, we have proposed a series of robust methods for ultra-high-resolution, fine-grained, correlated detector response generation and conditional sampling tasks with our Intra-Event Aware GAN (IEA-GAN). 
IEA-GAN not only captures the dyadic class-to-class relations but also exhibits explainable intra-event correlations among the generated detector images while other models fail to capture any correlation. To achieve this, we present the Relational Reasoning Module~(RRM) and the IEA-loss, with the Uniformity loss used in Deep Metric Learning. 
The RRM introduced a self-supervised relational contextual embedding for the samples in an event, which is compatible with GAN training policies, a task that is very challenging. 
It dynamically clusters the images in a collider event based on their inherent correlation, culminating in approximating a collision event.
Our IEA-loss, a discriminator-supervised loss, helps the generator reach a consensus over the discriminator's dyadic relations between samples in each event.
Finally, we have demonstrated that the Uniformity loss plays a crucial role for the discriminator in maximizing the homogeneity of the information entropy over the embedding space, thus helping the model overcome mode-collapse and capture a better bi-modality of generated occupancy.

As a result, an improvement to all metrics compared to the previous SOTA occurs, achieving an FID score of $1.50$, an over $42\%$ improvement, and a KID score of $0.0010$, as presented in~\Cref{tab:fid}. Using IEA-GAN also comes with a storage release of more than $2$ orders of magnitude. 
Furthermore, due to the dramatic CPU speed-up of $\times \num{147}$ as shown in~\cref{tab:computational_perf}, It is now possible to employ the IEA-GAN as an online surrogate model for the ultra high-granularity PXD background simulation on the fly, a task that was unattainable before for such a high-resolution detector simulation. 
Consequently, IEA-GAN, as a surrogate model that can generate more than \num{7.5}M information channels, would be the applicable candidate that can handle the ultra-high granularity of the HL-LHC era.
Moreover, we have shown that the application of the FID and KID metrics for the detector simulation provides a powerful tool for evaluating the performance of deep generative models in detector simulation.
We have also illustrated the vital role that intra-event sensor-by-sensor correlation plays in downstream physics analysis. Consequently, we revealed that IEA-GAN, despite only capturing a weak correlation, surpasses PE-GAN and even outperforms the inter-event-shuffled~(uncorrelated) Geant4 in certain metrics.
We have also conducted an in-depth study into the optimal design and hyperparameters of the RRM, the IEA-loss, and the Uniformity loss.
It is important to note that many existing models in calorimeter simulations do consider observables that depend on more than one layer simultaneously. These models typically focus on the simulation of particle showers from a single particle origin and a small region with the shower, which indeed capture aspects of inter-layer correlation within the scope of a localized area. 
However, our approach extends this concept by considering the entire event with multiple-particle origins that embrace the entire PXD detector as a whole, where correlations between different directions and depths~(various angles and layers) become important within its readout window. 
Given the unique topology and geometry of PXD, this distinction is critical and allows for a more comprehensive full detector simulation, approximating the complex interplay within an event across the entire detector rather than just the localized particle shower. Furthermore, while previous studies may have implicitly accounted for layer-by-layer correlations within their framework, our study explicitly evaluates and compares these correlations and their influence on downstream physics analysis.

\begin{table}[ht]
\begin{minipage}{\textwidth}
    \centering
    \caption{
    Computational performance of IEA-GAN and PE-GAN generators on a
    single core of an Intel Xeon Silver~\num{4108}~\num{1.80}GHz~(CPU) and NVIDIA V100 with~\num{32} GB of memory~(GPU) compared to Geant4. For the generative models, the mean and standard deviation were obtained for sets of~\num{10000} events, meaning that the model generates these events one at a time, not in a batch of \num{10000}.
    The time for Geant4 refers to the theoretical time it would take to run the simulation of background processes on the fly, one event at a time. The storage consumption for Geant4 corresponds to storing~\num{10000} simulated events of \num{1} times the PXD background information, while for the surrogate models~(i.e., IEA-GAN and PE-GAN), the term storage specifically refers to the models' weights.}
    
    \label{tab:computational_perf}
    \begin{tabular}{lllll}  % added one more 'l' for the extra column
        \toprule
        Hardware & Simulator & time/event~[s] & Storage~[Mb] & Speed-up \\
        \midrule
        \multirow{3}{*}{CPU}  & Geant4 & $\approx 1500$ & $\approx 2000$ & $1$\\
                              & PE-GAN & $11.781\pm 0.357$ & $\approx 47$ & $\approx \times127$ \\
                              & IEA-GAN & $10.159\pm 0.208$ & $\approx 47$ & $\approx \times\textbf{147}$ \\
        \midrule
        \multirow{2}{*}{GPU}  & PE-GAN & $0.090\pm 0.010$ & $\approx 47$ & $\approx \times16667$ \\
                              & IEA-GAN & $0.070\pm 0.006$ & $\approx 47$ & $\approx \times21429$ \\
        \bottomrule
    \end{tabular}
\end{minipage}
\end{table}


The ability to capture the underlying correlation structure of the data in particle physics experiments where the physical interpretation of the results heavily relies on it is very important. The true correlation between the occupancy of the sensors is determined by the underlying physical processes within the simulation. Although the actual correlation differs from the one captured by IEA-GAN, the model is learning patterns related to detector geometry, grounded in how these correlations manifest in the context of the PXD detector's structure. 
In particular, the model picked up a distinct positive layer-wise correlation, particularly between sensors $0-15$ in the first layer and between sensors $16-39$ in the second layer. 
This distinct pattern reflects a layer-wise understanding of the Toroidal geometry of PXD, although it differs partially from the actual correlations seen in the Geant4 data. This suggests that the difference in occupancy between inner and outer layers could be a major feature learned by the model, which may impede the learning of more subtle correlations. Therefore, while the IEA-GAN can provide valuable insights into the correlations and patterns present in the data, it is important to interpret its results in conjunction with the domain knowledge. To alleviate the discrepancy, we expect that incorporating perturbations directly into the discriminator's RRM module would improve its contextual understanding and, thus, the intra-event correlation. For example, using random masking~\cite{liuRoBERTaRobustlyOptimized2019a} or inter-event permutation~\cite{yangXLNetGeneralizedAutoregressive2019} over the samples and asking the RRM module to predict the representation of the perturbed sample will improve the robustness of the model.

This work significantly impacts high-granularity fast and efficient detector response and collider event simulations. Since they require fine-grained intra-event-correlated data generation, we believe that the Intra-Event Aware GAN~(IEA-GAN) offers a robust controllable sampling for all particle physics experiments and simulations, such as detector simulation~\cite{khattakFastSimulationHigh2022a,haririGraphGenerativeModels2021a} and event generation~\cite{butterHowGANLHC2019a,verheyenEventGenerationDensity2022a,alanaziSurveyMachineLearningBased2021a,butterMachineLearningLHC2023} at both Belle~II~\cite{abeBelleIITechnical2010d} and LHC~\cite{evansLHCMachine2008b}.
In particular, the High-Luminosity Large Hadron Collider~(HL-LHC)~\cite{aberleHighLuminosityLargeHadron2020} is expected to surpass the LHC's design integrated luminosity by increasing it by a factor of 10.
For instance, the upcoming high-granularity Calorimeter~(HGCAL) with roughly \num{6.5}M channels, or the ITk 3D pixel detector at the HL-LHC~\cite{terzoNovel3DPixel2021} with around \num{1}M information channels, will massively increase the geometry and precision complexity, leading to a dramatic increase in the time and storage to simulate the detector~\cite{pedroCurrentFuturePerformance2019}
As a result, much more effective and efficient high-resolution detector simulations are required.
IEA-GAN is the potential candidate for simulating the corresponding full high-resolution and high-granular detector signatures with capability of generating more than 7.5M pixel channels. 
Nevertheless, while our approach offers a foundation for dealing with the complexities of any ultra-high granularity experiments, it is but a stepping stone. Our work aims to pave the way for such advancements, providing a preliminary framework capable of addressing the ultra-high granularity challenges.

Finally, IEA-GAN also has potential applications in protein design, which is a process that involves the generation of novel amino acid sequences to produce proteins with desired functions, such as enhanced stability and foldability, new binding specificity, or enzymatic activity~\cite{huangComingAgeNovo2016}. Proteins can be grouped into different categories based on the arrangement and connectivity of their secondary structure features, such as alpha helices and beta sheets. Our developed intra-event aware methods, where an event represents the higher category of features, can also be applied to fine-grained density estimation~\cite{liuDensityEstimationUsing2021} for generating new foldable protein~\cite{repeckaExpandingFunctionalProtein2021,NEURIPS2018_afa299a4,strokachDeepGenerativeModeling2022} structures where category-level reasoning is of paramount importance. 

\section{Methods}
\label{sec:methods}
%Belle~II~\cite{abe2010belle} is a B-factory experiment located at the intersection point of the SuperKEKB~\cite{ohnishiAcceleratorDesignSuperKEKB2013} accelerator in Tsukuba, Japan, designed for a peak luminosity of $\SI{6e35}{\per\centi\meter\squared\per\second}$. The accelerator collides electrons and positrons at a center-of-mass energy of $\SI{10.58}{GeV}$, corresponding to the $\Upsilon(4S)$ resonance state that decays almost exclusively to entangled pairs of either charged or neutral B mesons. Other processes include continuum events originating from quark pair production. The precise measurement of $CP$-violation and the search for rare decays of B mesons, charm hadrons, or tau-leptons as probes for new physics relies heavily on a large number of recorded events and precise reconstruction of decay vertices. To perform such measurements, Belle~II plans to collect a 50 times larger dataset than its predecessor, Belle. The desired increase in the collision rate of particles at the upgraded accelerator leads to more significant background rates for all sub-detectors. To profit from the much larger recorded dataset, the systematic uncertainties of simulated datasets must be well understood, for which sufficient amounts of simulated data are needed. This requires proper incorporation of beam background effects in the detector simulation.  Various background processes lead to signals in the detector that do not originate from the physics processes of interest, called signal processes. These background processes can be categorized into beam-induced and luminosity-dependent processes. The beam-induced processes originate from the synchrotron radiation and collisions of beam particles with residual gas in the beampipe, bending magnets, or particles within a bunch. In contrast, luminosity-dependent processes comprise electron-positron collisions leading to ``non-interesting'' physics processes such as Bhabha scattering or two-photon processes.  The background overlay is one way to include and simulate the aforementioned beam background effects. This method uses random trigger~\cite{iwasakiLevelTriggerSystem2010} events in actual data. Random trigger samples are actual data samples taken with a random trigger. Ergo, one decides randomly when to trigger and then records everything in the detector at that moment. 

%This works on the digit level and thus needs a detector-specic treatment of cases where background and signal contribute to the same channel.


\subsection{Theory of Generative Adversarial Networks}

GANs are generative models that try to learn to generate the input distribution as faithfully as possible.
For conditional GANs~\cite{mirzaConditionalGenerativeAdversarial2014a}, the goal is to generate features given a label. 
Two player-based GAN models introduce a zero-sum game between two Synthetic Intelligent Agents, a generator network $\mathrm{G}$, and a discriminator network $\mathrm{D}$. 

\begin{definition}[Vanilla GAN]
Given the generator $\mathrm{G}$, a function $\mathrm{G}:\mathbb{R}^d\rightarrow \mathbb{R}^n$, that maps a latent variable $\mathbf{z} \in \mathbb{R}^d$ sampled from a distribution to an n-dimensional observable, and the discriminator $\mathrm{D}$, a functional $\mathrm{D}:\mathbb{R}^n\rightarrow [0,1]$, that takes a generated image $\mathbf{x} \in \mathbb{R}^n$ and assigns a probability to it, they are the players of the following two-player minimax game with value function $\mathrm{V}(\mathrm{D}, \mathrm{G})$~\cite{goodfellowGenerativeAdversarialNets2014a},

\begin{equation}
\mathop{min}_{\mathrm{G}}\mathop{max}_{\mathrm{D}}~\mathrm{V}(\mathrm{D},\mathrm{G}) = \mathbb{E}_{\mathbf{\mathbf{x}}\sim \mathbb{R}^n}[\log \mathrm{D}(\mathbf{\mathbf{x}})]+\mathbb{E}_{\mathbf{z}\sim \mathbb{R}^d}[\log(1-\mathrm{D}(\mathrm{G}(\mathbf{z}))].
% \label{eq:GAN_minmax}
\end{equation}
\end{definition}

After introducing the vanilla GAN, a vast amount of research has been undertaken to improve its convergence and stability, as, in general, training GANs is a highly brittle task. It requires a significant amount of hyperparameter tuning for domain-specific tasks.
Many tricks, model add-ons, and structural changes have been introduced.
A recent and comprehensive study prompted a very powerful SOTA model, BigGAN-deep~\cite{brockLargeScaleGAN2019a}, which incorporates the hinge-loss variation of the adversarial loss~\cite{limGeometricGAN2017a},

\begin{align}
\Lb_\mathrm{D}^{\mathrm{hinge}} &= -\mathbb{E}_{\mathbf{x}\sim \mathbb{R}^n}[\min(0,-1+\mathrm{D}(\mathbf{x}))]-\mathbb{E}_{\mathbf{z}\sim \mathbb{R}^d}[\min(0, -1-\mathrm{D}(\mathrm{G}(\mathbf{z}))] ~, \\
\Lb_\mathrm{G}^{\mathrm{hinge}} &= -\mathbb{E}_{\mathbf{z}\sim \mathbb{R}^d}[\mathrm{D}(\mathrm{G}(\mathbf{z}))].
\label{eq:hinge_loss}
\end{align}

Furthermore, many schemes for capturing the class conditions have been proposed since conditional GANs over image labels have been introduced~\cite{mirzaConditionalGenerativeAdversarial2014a}.
The main idea is to minimize a specific metric between a class identification output of the discriminator and the actual labels after injecting an embedding of the conditional prior information into the generator.
For example, ACGAN~\cite{odenaConditionalImageSynthesis2017a} tries to capture data-to-class relations by introducing an auxiliary classifier.
The ProjGAN~\cite{miyatoCGANsProjectionDiscriminator2018a} also tries to capture these data-to-class relations by projecting the class embeddings onto the output of the discriminator via an inner product that contributes to the adversarial loss.
The recent ContraGAN~\cite{NEURIPS2020_f490c742} incorporated concepts from metric learning or self-supervised learning~(SSL) in order to seize data-to-data relations or intra-class relations by introducing the 2C~loss, derived from NT-Xent loss~\cite{chenSimpleFrameworkContrastive2020a}, and proxy-based SSL,

\begin{equation}
\resizebox{.9\hsize}{!}{$\ell_{\mathrm{2C}}(\mathbf{x}_i,\mathbf{y}_i) = -~\log(\frac{\exp{(\mathrm{S}_c(\mathbf{h}(\mathbf{x}_i)^{\top}\mathbf{e}(\mathbf{y}_i)))}+\sum^m_{k=1}\mathbf{1}_{k=i}.\exp{(\mathrm{S}_c(\mathbf{h}(\mathbf{x}_i)^{\top}\mathbf{h}(\mathbf{x}_k)))}}{\exp{(\mathrm{S}_c(\mathbf{h}(\mathbf{x}_i)^{\top}\mathbf{e}(\mathbf{y}_i)))}+\sum^m_{k=1}\mathbf{1}_{k\neq i}.\exp{(\mathrm{S}_c(\mathbf{h}(\mathbf{x}_i)^{\top}\mathbf{h}(\mathbf{x}_k)))}}).$}
\label{eq:2C_loss}
\end{equation}

Here, $\mathbf{x}_i \in \mathbf{x}$ are the images, $\mathbf{y}_i \in \mathbf{y}$ are the corresponding labels, $\mathrm{S}_c(.,.)$ is a similarity metric, $\mathbf{h}(.)$ is the output of the image embeddings, and $\mathbf{e}(.)$ is the output of the class embeddings.
Although ContraGAN benefits from this loss by capturing the intra-class characteristics among the images that belong to the same class, it is prone to class-confusion~\cite{kangRebootingACGANAuxiliary2021a,rangwaniClassBalancingGAN2021} as different classes could also show similarity among themselves since their vector representation in the embedding space might not be orthogonal to each other, which is precisely what we are dealing with in a fine-grained dataset.

\subsection{Relational Reasoning}

%\subsubsection*{Background}
Transformers~\cite{vaswaniAttentionAllYou2017b} are widely used in different contexts. However, their application in Generative Adversarial Networks is either over the image manifold to learn long-range interactions between pixels~\cite{zhangSelfAttentionGenerativeAdversarial2019c,hudsonGenerativeAdversarialTransformers2021a} or via pure Vision-Transformer based GANs~\cite{jiangTransGANTwoPure2021a} in which they utilize a fully Vision-Transformer~\cite{dosovitskiyImageWorth16x162021} based generator and discriminator.
Given the fact that training the Transformers is notoriously difficult~\cite{liuUnderstandingDifficultyTraining2020a} and task-agnostic when determining the best learning rate schedule, warm-up strategy, decay settings, and gradient clipping, fusing and adapting a Transformer encoder over a GAN learning regime is a highly non-trivial task.
In this paper, we successfully merge a Transformer-based module adapted to the GAN training schemes for the discriminator's image and the generator's class modalities without any of the aforementioned problems.


\begin{definition}[Attention]
Transformers utilize a self-attention mechanism, the data of $(\mathbf{K},\mathbf{Q},\mathbf{V},\mathrm{A})$. The vector spaces $\mathbf{K}\in \mathbb{R}^{N\times d_k}$, $\mathbf{Q}\in \mathbb{R}^{N\times d_k}$ and $\mathbf{V}\in \mathbb{R}^{N\times d_v}$ are the set of Keys, Queries, and Values.
The bilinear map $\mathrm{a}:\mathbf{K}\times \mathbf{Q}\rightarrow \mathbb{R}^{N\times N}$ is a similarity function between a key and a query. The attention, $\mathrm{A}$, is defined as
\begin{equation}
\mathrm{A}(\mathbf{K},\mathbf{Q},\mathbf{V}):= \mathrm{Softmax}(\mathrm{a}(\mathbf{K},\mathbf{Q}))\mathbf{V} ~,
% \label{eq:attention}
\end{equation}
where $d_k$ and $d_v$ are the dimensions of the corresponding vector spaces.
\end{definition}

The attention mapping used in the vanilla Transformer~\cite{vaswaniAttentionAllYou2017b} adopts the scaled dot-product as the bilinear map between keys and queries as
\begin{equation}
\mathrm{A}(\mathbf{K},\mathbf{Q},\mathbf{V}):= \mathrm{Softmax}(\frac{\mathbf{K}\mathbf{Q}^T}{\sqrt{d_k}}))\mathbf{V} ~.
\label{eq:attention_map}
\end{equation}

The normalization factor $\frac{1}{\sqrt{d_k}}$ mitigates vanishing gradients for large inputs.
Rather than simply computing the attention once, the multi-head mechanism runs through the scaled dot-product attention of linearly transformed versions of keys, queries, and values multiple times in parallel via learnable maps $\mathbf{W}_i^k$, $\mathbf{W}_i^q$ and $\mathbf{W}_i^v$.
The independent attention outputs over $h$ number of heads are then aggregated and projected back into the desired number of dimensions via $\mathbf{W}^p$, 

\begin{equation}
\mathrm{MultiHead}(\mathbf{K},\mathbf{Q},\mathbf{V}):= [\biguplus_{i=1}^h \mathbf{H}_i]\mathbf{W}^p ~,
\label{eq:attention_multi_head}
\end{equation}

where $\mathbf{H}_i$ is given by $ \mathrm{A}(\mathbf{K}\mathbf{W}_i^k,\mathbf{Q}\mathbf{W}_i^q,\mathbf{V}\mathbf{W}_i^v)$. When used for processing sequences of tokens, the Self-Attention mechanism allows the transformer to figure out how important all other tokens in the sequence are, with respect to the target token, and then use these weights to build features of each token.

%\subsubsection*{Event Approximation}
%\label{sub:event_approx}

\textbf{Event Approximation.} An event, a single readout window after the collision of particles, consisted of \num{40} of images, each of which a sensor hitmap~(image) of size $256\times768$. Thus, each event represents a round of detector signature collection. 
In order to approximate the concept of an event, at each iteration, IEA-GAN should take an event with \num{40} sensor images. Therefore, we are conditioning the model with the sensor type $[[1,40]]$, which can be thought of as a mixture of angle and radius conditioning. These conditions have to enter the model as learnable \emph{tokens} as they are not absolute and are context-based. It is impossible to pre-define meaningful sparse connections among the sample nodes in an event. For instance, the relation between images from different sensors can vary from event to event, albeit cumulatively, they follow a particular distribution. 
Ergo, the model has to learn any dynamical inherited conditions from the data in context~(through the Relational Reasoning Module).

To model the context-based similarity between the different detector sensors in each event rather than their absolute properties, we have to use a permutation-equivariant~\cite{guttenbergPermutationequivariantNeuralNetworks2016,ravanbakhshEquivarianceParameterSharing2017} relational block that can encode pairwise correspondence among elements in the input set.
For instance, Max-Pooling~(e.g.~DeepSets~\cite{zaheerDeepSets2017a}) and Self-Attention~\cite{vaswaniAttentionAllYou2017b} are the common permutation equivariant modules for set-based problems.
Performing attention on all token pairs in a set to identify which pairs are the most interesting enables Transformers like Bert~\cite{devlinBERTPretrainingDeep2019a} to learn a context-specific syntax as the different heads in the multi-head attention might be looking at different syntactic properties~\cite{clarkWhatDoesBERT2019a,yunAreTransformersUniversal2020a}.

Hence, we use a self-attention mechanism with weighted sum pooling as a form of information routing to process meaningful connections between elements in the input set and create an event graph. Each sample in an event is viewed as a node in a fully connected event graph, where the edges represent the learnable degree of similarity.
Samples in each event go into message propagation steps of our Relational Reasoning Module~(RRM), a GAN-compatible fully connected multi-head Graph Transformer Network~\cite{battagliaRelationalInductiveBiases2018c,sharifzadehClassificationAttentionScene2021b,locatelloObjectCentricLearningSlot2020}.

%\subsubsection*{Relational Reasoning Module}

\textbf{Relational Reasoning Module.} Specifically designed to be compatible with GAN training policies, the Relational Reasoning Module~(RRM) can capture contextualized embeddings and cluster the image or class tokens in an event based on their inherent similarity. 

Let $\mathbf{X}=\{\mathbf{x}_1,...,\mathbf{x}_m\}$ be the set of the sampled images in each event, where $\mathbf{x}_i \in \mathbb{R}^{d}$, and $\mathbf{y}=\{\mathbf{y}_1,...,\mathbf{y}_m\}$ be the set of labels, with $y_i \in [\![1,40]\!]$ for \num{40} detector~(PXD) sensors.
We also define two linear hypersphere projection diffeomorphisms, $\mathbf{h}_x:\mathbb{R}^k \rightarrow \mathbb{S}^n$ and $\mathbf{h}_y:\mathbb{Z} \rightarrow \mathbb{S}^n$, which map the image embedding manifold and the set of labels to a unit n-sphere, respectively.
The unit n-sphere is the set of points, $\mathbb{S}^n = \{s\in\mathbb{R}^{n+1}\mid \|s\|_2=1 \}$, that is always convex and connected.
The Relational Reasoning Module benefits from a variant of the Pre-Norm Transformer~\cite{vaswaniAttentionAllYou2017b} with a dot-product Multi-head Attention block such that,

\begin{align}
\mathbf{p}'^{(l)}_i &= \mathbf{p}^{(l)}_i +\sum_{k=1}^h\sum_{j=1}^{m} a_{ij}^{(l,k)}\mathbf{W}_{\mathrm{SN}}^{(l)}\mathbf{LN}(\mathbf{p}_j^{(l)}) ~, 
\label{eq:dis_1}
\\
\mathbf{p}^{(L)}_i &= \mathbf{h}_x^{\mathrm{LN}}\left(\mathbf{LN}(\mathbf{\bigcirc}_{l=0}^{L}(\mathbf{p}'^{(l)}_i + \mathcal{F}_{\mathrm{SN}}[\mathbf{LN}(\mathbf{p}'^{(l)}_i)]))\right) ~,
\label{eq:dis_2}
\end{align}
where $\mathbf{p}'^{(l)}_i\in \mathbb{R}^{k}$ is the embedding of each image via the discriminator for layer $l$ of the RRM.
$\mathbf{LN}$ is the Layer Norm function~\cite{baLayerNormalization2016a} and $h$ is the number of heads defined in \Cref{eq:attention_multi_head}.
$\mathcal{F}[~.~]$ is a two layer MLP functional defined as $\mathcal{F}_{\mathrm{SN}}[\mathbf{p}_i^{(l)}] = \textrm{ReLU}(\mathbf{p}_i^{(l)}\mathbf{W}_{\mathrm{SN}}^{(l,1)})\mathbf{W}_{\mathrm{SN}}^{(l,2)}$ with Spectral Normalization~\cite{miyatoSpectralNormalizationGenerative2018b}.
The logits $a_{ij}^{(l,k)}$ are the normalized Attention weights of the bilinear function that monitor the dyadic interaction between image embeddings in layer $l$ and head $k$ defined in \Cref{eq:attention_map}. $\mathbf{W}_{\mathrm{SN}}^{(l)}$ in~\Cref{eq:dis_1} is the learnable multi-head projector at layer $l$ defined in \Cref{eq:attention_multi_head} with Spectral Normalization.
The output of the composition of all layers via the composition of $L$ functionals, $\bigcirc_{l=0}^{L}\Phi^l:= \phi_{w_L}\circ ... \circ \phi_{w_0}[\mathbf{p}_i^{(l=0)}]\in \mathbb{R}^{m\times k}$, goes into a Layer Normalization layer where $\Phi^l = \mathbf{p}'^{(l)}_i + \mathcal{F}[\mathbf{LN}(\mathbf{p}'^{(l)}_i)]$.
$\mathbf{h}_x^{\mathrm{LN}}(~.~)$ in~\Cref{eq:dis_2} is the hypersphere compactification while the vectors are being standardized over the unit n-sphere $\mathbb{S}^n$ by a Layer Normalization.

For the discriminator, this module takes the set of image embeddings as input nodes within a fully connected event graph, applies a dot-product self-attention over them, and then updates each sample or node's embedding via the attentive message passing, as shown on the right of~\Cref{fig:IEAGAN_arch}.
In the end, it compactifies the information by projecting the normalized graph onto a hypersphere via an L2 normalization~\cite{wangNormFaceL2Hypersphere2017a}.
Embedding the samples in an event on the unit hypersphere provides several benefits.
In modern machine learning tasks such as face verification and face recognition~\cite{wangNormFaceL2Hypersphere2017a}, when dot products are omnipresent, fixed-norm vectors are known to increase training stability.
In our case, this avoids gradient explosion in the discriminator.
Furthermore, as $S^n$ is homeomorphic to the 1-point compactification of $\mathbb{R}^n$ when classes are densely grouped on the n-sphere as a compact convex manifold, they are linearly separable, which is not the case for the Euclidean space~\cite{gorbanStochasticSeparationTheorems2017a}. 

For the generator's RRM, we use a simpler version of the above dot-product Multi-head Attention block without the last hypersphere compactification due to the stability issues, as shown on the left of~\cref{fig:IEAGAN_arch}.
It finds a learnable contextual embedding for each event that will be fused to each class token via the feature mixing layer, which is a matrix factorization linear layer $\mathbf{W}_{\mathrm{SN}}(.)$. Formally, we have,

\begin{align}
\mathbf{q}^{(0)}_i &= \mathbf{W}_{\mathrm{SN}}(\mathbf{r}_i\uplus\mathbf{e}_i) ~,
\label{eq:feat_mix_1}
\\
\mathbf{q}'^{(l)}_i &= \mathbf{q}^{(l)}_i+\sum_{k=1}^M\sum_{j=1}^{m} a_{ij}^{(l,k)}\mathbf{W}^{(l)}\mathbf{LN}(\mathbf{q}_j^{(l)}) ~,
\label{eq:feat_mix_2}
\\
\mathbf{q}^{L}_i &=\mathbf{LN}\left(\mathbf{\bigcirc}_{l=0}^{L}( \mathbf{q}'^{(l)}_i + \mathcal{F}[\mathbf{LN}(\mathbf{q}'^{(l)}_i)])\right) ~,
\label{eq:feat_mix_3}
\end{align}

where $\mathbf{e}_i:\mathbb{Z} \rightarrow \mathbb{R}^t$ is the embedding of each class token via the embedding layer of the generator. The logits $a_{ij}^{(l,k)}$ are the normalized Attention weights of the bilinear function that monitor the dyadic interaction between classes in the event embeddings in layer $l$ and head $k$ defined in~\Cref{eq:attention_map}. $\mathbf{W}^{(l)}$ in~\Cref{eq:feat_mix_2} is the learnable multi-head projector at layer $l$ defined in \Cref{,eq:attention_multi_head}. The output of the composition of all layers via the composition of $L$ functionals, $\bigcirc_{l=0}^{L}\Phi^l:= \phi_{w_L}\circ ... \circ \phi_{w_0}[\mathbf{q}_i^{(l=0)}]\in \mathbb{R}^{m\times t}$, goes into a Layer Normalization layer where $\Phi^l = \mathbf{q}'^{(l)}_i + \mathcal{F}[\mathbf{LN}(\mathbf{q}'^{(l)}_i)]$ as shown in~\Cref{eq:feat_mix_3}.

One input to the generator is the embedded labels, which can be considered rigid token embeddings that will be learned as a global representation bias of each sensor. As sensor conditions change for each event as a set, having merely class embeddings, as used in conditional GANs~\cite{mirzaConditionalGenerativeAdversarial2014a}, is insufficient because the context-based information will not be learned.
Thus, the generator samples from a per-event shared distribution at each event as random degrees of freedom~(Rdof).
Rdofs are random samples from a shared Normal distribution for each class, $\mathbf{r}_i \sim \mathcal{N}(0,1)$, that introduces four-dimensional learnable degrees of freedom for the generator, see~\Cref{eq:feat_mix_1} 
This way, we ensure that the generator is aware of intra-event local changes, culminating in having an intra-event correlation among the generated images. Rdof can be interpreted as both perturbation~\cite{zhangWordEmbeddingPerturbation2018a} to the token embeddings and an event-level segment embedding~\cite{devlinBERTPretrainingDeep2019a}, which can enhance the diversity of the generated images.


\subsection{Intra-Event Aware Loss}
Motivated by Self-Supervised Learning~\cite{raniSelfsupervisedLearningSuccinct2023}, to transfer the intra-event contextualized knowledge of the discriminator to the generator in an explicit way, we introduce an Intra-Event Aware~(IEA) loss for the generator that captures class-to-class relations,

\begin{equation}
\ell_\mathrm{IEA}(\mathbf{x}_r,\mathbf{x}_f) = \sum_{i,j} D_\mathrm{KL} \left( \sigma \left( \mathbf{h}(\mathbf{x}^{(r)}_i)^{\top}\mathbf{h}(\mathbf{x}^{(r)}_j) \right) \Big\Vert \sigma \left(\mathbf{h}(\mathbf{x}^{(f)}_i)^{\top}\mathbf{h}(\mathbf{x}^{(f)}_j)\right)\right),
\label{eq:iea_loss}
\end{equation}

where $\mathbf{x}_r=\{\mathbf{x}^{(r)}_i\}_{i=1}^m$ is the set of real images, and $\mathbf{x}_f=\{\mathrm{G}(\mathbf{z}^i,\mathbf{y}^i,\mathbf{r}^i)=\mathbf{x}^{(f)}_i\}_{i=1}^m$ the set of generated images. The softmax function, $\sigma:\mathbb{R}^m\rightarrow [0,1]^m$, normalizes the dot-product self-attention between the image embeddings.
The map $\mathbf{h}:\mathbb{R}^k \rightarrow \mathbb{S}^n$ is the unit hypersphere projection of the discriminator.
Therefore, the dot product is equivalent to the cosine distance.
$D_{\mathrm{KL}}(.\vert \vert.)$ is the Kullback-Leibler~(KL) divergence~\cite{kullbackInformationSufficiency1951a} which takes two $m\times m$ matrices that have values in the closed unit interval (due to the softmax function).
Hence, having a KL divergence is natural here as we want to compare one probability density with another in an event.
We also tested other distance functions reported in the supplementary note.
By considering the linear interaction~\cite{caoCouplingLearningComplex2015a} between every sample in an event and assigning a weight to their similarity, the generator mimics the fine-grained class-to-class relations within each event and incorporates this information in its RRM module as shown in~\cref{fig:IEAGAN_arch}.

%\Hosein{put it to ablation}: One can interpret the KL divergence here as the additional bit cost associated with compressing data samples when the false distribution of the normalized self-attention logits of the discriminator's embedding of the generated images is used instead of the true distribution of the normalized self-attention logits of the discriminator's embedding of the real images.
%\begin{figure}[ht]
%     \centering
%     \includegraphics[width=\textwidth,clip]{plots/IEAloss.pdf}
%     \caption{IEA-loss imposes a pair-wise fine-grained class-to-class imitation force for the generator. Sg indicates that for the discriminator, gradients are stopped, and only the generator's gradients will be updated.}
%     \label{fig:IEA_loss}
% \end{figure}

Upon minimizing it for the generator~(having the stop-gradient for the discriminator), we are putting a discriminator-supervised penalizing system over the intra-event awareness of the generator by encouraging it to look for more detailed dyadic connections among the images and be sensitive to even slight differences.
Ultimately, we want to maximize the consensus of data points on two unit hyperspheres of real images and generated image embeddings. 

\subsection{Uniformity Loss}
\label{sec:uniformity}

The other crucial loss function comes from contrastive representation learning.
With the task of learning fine-grained class-to-class relations among the images, we also want to ensure the feature vectors have as much hyperspherical diversity as possible.
Thus, by imposing a uniformity condition over the feature vectors on the unit hypersphere, they preserve as much information as possible since the uniform distribution carries a high entropy.
This idea stems from the Thomson problem~\cite{thomsonXXIVStructureAtom1904a}, where a static equilibrium with minimal potential energy is sought to distribute N electrons on the unit sphere in the evenest manner.
To do that, we incorporate the uniformity metric~\cite{wangUnderstandingContrastiveRepresentation2020b}, which is based on a Gaussian potential kernel,

\begin{equation}
\Lb_{\mathrm{uniform}}(\mathbf{x};s) = \log \mathbb{E}_{\mathbf{x}_i,\mathbf{x}_j\sim p_{\mathrm{event}}} [\exp(s\|\mathbf{h}(\mathbf{x}_i)-\mathbf{h}(\mathbf{x}_j)\|_2^2)].
\label{eq:uniformity_loss}
\end{equation}

Upon minimizing this loss for the discriminator, it tries to maintain a uniform distance among the samples that are not well-clustered and thus not similar.
In other words, eventually, we want to reach a maximum geodesic separation incorporating the Riesz s-kernel~\cite{liuLearningMinimumHyperspherical2018} with $s=-2$ as a measure of geodesic similarity, to preserve maximal information over the Hypersphere.
Therefore, asymptotically it corresponds to the uniform distribution on the hypersphere~\cite{kuijlaarsAsymptoticsMinimalDiscrete1998b}.
This loss is beneficial for capturing the exact distribution of the mean occupancy distribution and balancing the inter-class pulling force of the Relational Reasoning module. As a result, not only does it help generate more diverse and varied outputs, but it also can prevent issues such as mode collapse or overfitting.

\subsection{Model Details and Hyperparameters}
\label{sec:dataset_and_model_details}
In this study, we utilized a dataset of \num{40000} Monte Carlo simulated events~\cite{kuhrComputingBelleII2011a}, of which \num{35000} were allocated for training, \num{5000} for model selection~(validation), and an independent set of \num{10000} events served as the test set for assessing the final model performance. It is noteworthy to acknowledge that this is a rather small dataset to train a deep generative model for $\mathcal{O}(10^7)$ data channels.
%, which signifies the power of IEA-GAN to be able to do so.
The data in each event consists of \num{40} grey-scale $256\times 768$ zero-padded images. They are zero-padded on both sides from their original size of $250 \times 768$ to be divisible by \num{16} for training purposes.

To capture the intra-event mutual information among the images using the RRM and approximate the concept of an event, the model samples~(and generates) an entire event at each iteration. This approach ensures that each event in our analysis comprises a correlated set of \num{40} unique images. All hyperparameters are chosen based on the model's stability and performance upon the validation set.
The learning rates for the Generator and Discriminator are $5\times10^{-5}$ with one sample per class sampler.
The Relational Reasoning Module of the Generator has two heads and one layer of non-spectrally normalized message propagation with an embedding dimension of 128 and ReLU non-linearity.
The input to the generator's RRM is embedded class tokens mixed with \num{4} random degrees of freedom by a spectrally normalized linear layer. 

For the Discriminator, the RRM has four heads with one layer of spectrally normalized message propagation with the embedding dimension \num{1024} as the hypersphere dimension and ReLU non-linearity.
All Generator and Discriminator modules use Orthogonal initialization~\cite{saxeExactSolutionsNonlinear2014a}.
For the IEA-loss in \Cref{eq:iea_loss}, the coefficient $\lambda_{\mathrm{IEA}} = 1.0$~(highlighted in Supplementary Algorithm 1 in supplementary note) gives the best result.
The most stable contribution of the Uniformity loss, defined in \Cref{eq:uniformity_loss}, is with $\lambda_{\mathrm{uniform}}=0.1$.
For the backbone of both the discriminator and the generator, we use BigGAN-deep~\cite{brockLargeScaleGAN2019a} with a non-local block at channel \num{32} for the discriminator only.
Since there is no meaningful way to define a minimal loss in GAN training, our stopping point is the divergence of the FID.

\section{Ablation Studies and Things We Tried But Did Not Work}
\label{sec:ablation_studies}

For the IEA-loss we tested several losses in order to achieve the best stability, shown in \Cref{fig:FID_IEAloss}.
Some of them have their own merits and downsides. We explored the Kullback-Leibler~(KL) divergence~\cite{kullbackInformationSufficiency1951a}, the L1 loss, the Huber loss~\cite{huberRobustEstimationLocation1964}, and the L2 loss. KL divergence was more stable in capturing differences between the real and fake self-similarities and more robust in outliers.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.6\textwidth,clip]{plots/fid_IEAloss.pdf}
    \caption{Comparison of the FID between different IEA-losses}
    \label{fig:FID_IEAloss}
\end{figure}

We probed a range of coefficients for the IEA-loss and the Uniformity loss.
For the KL divergence as the IEA-loss, we tried the values \{0.1, 1, 5, 10\} and selected $1$.
For the L1 loss, as well as the IEA-loss, the best $\lambda_{\mathrm{IEA}}$ value is $10$.
For the Uniformity loss, we probed the values \{0.01, 0.1, 0.5, 0.75, 1, 5, 10\} and selected $0.1$.
Moreover, IEA-GAN, without the IEA-loss and Uniformity loss, suffers from the lack of agreement maximization penalty for the generator and information maximization for the discriminator.
Our study shows that having either of these losses without the other causes training instability, divergence, and lower fidelity, as shown in \Cref{tab:fid_ablation_losses}.

\begin{table}[ht]
\begin{minipage}{\textwidth}
 \begin{center}
    \caption{FID comparison between IEA-GAN,  IEA-GAN with RRM only, IEA-GAN with Uniformity loss only, and IEA-GAN with both IEA-loss, averaged across six random seeds.}
    \label{tab:fid_ablation_losses}
    \begin{tabular}{@{}lllll@{}}
    \toprule
    & IEA-GAN & Only RRM & RRM with Uniformity & RRM with IEA-loss \\ 
    \midrule
    \textbf{FID}  & $\mathbf{1.50\pm 0.16}$ & $2.74\pm 0.62$& $2.29\pm 0.14$& $3.42\pm 0.52$ \\
    \bottomrule
    \end{tabular}
  \end{center}
\end{minipage}
\end{table}

For the hypersphere dimension, we probed the values \{512, 768, 1024, 2048\} and selected \num{1024}.
For dimensions smaller than \num{512}, the discriminator fails to converge.
We also changed the position of the hypersphere projection layer and put it before and after the Multi-head attention~\cite{vaswaniAttentionAllYou2017b}.
The best position for the hypersphere projection is after the Multi-head attention and two layers of MLP. 
Moreover, for the hypersphere projection, we also tried an inverse Stereographic Projection $h:\mathbb{R}^N \rightarrow \mathbb{S}^N/\{p\}$ with p as a north pole on the n-sphere~\cite{eybpooshApplyingInverseStereographic2022a} instead of L2 compactification.
This map is conformal; thus, it locally preserves angles between the data points.
The results were more stable, but the average FID was better with L2 compactification, as shown in \Cref{tab:fid_hyper_comparison}.

\begin{table}[ht]
\begin{minipage}{\textwidth}
  \begin{center}
     \caption{FID comparison between two different Hypersphere projections for IEA-GAN's discriminator, averaged across six random seeds.}
     \label{tab:fid_hyper_comparison}
    \begin{tabular}{@{}lll@{}}
    \toprule
    & L2 compactification & Inverse Stereographic projection \\ 
    \midrule
    \textbf{FID} & $\mathbf{1.50\pm 0.16}$ & $2.01\pm 0.07$ \\
    \bottomrule
    \end{tabular}
  \end{center}
\end{minipage}
\end{table}

Inside the RRM, we tried a GeLU~\cite{hendrycksGaussianErrorLinear2023} non-linearity instead of ReLU, and the result was in favor of the latter.
We also put the layer normalization before and after the Multi-head Attention.
The pre-norm version seems to be much more stable and adaptable to GAN~\cite{mirzaConditionalGenerativeAdversarial2014a} training intricacies.
Another observation related to RRM is the weight normalization of the linear layers.
We observed that for the discriminator, spectrally normalized MLPs show the best results.
For the Generator, applying Spectral Normalization~\cite{miyatoSpectralNormalizationGenerative2018b} to the linear layers destabilizes the training.
Our observation regarding the effect of RRM over the generator's label embedding shows that without it, the RRM in the discriminator also becomes unstable, and the training diverges very early.

For the random degrees of freedom~(Rdof), first, we utilized the random vectors that are fed to the generator and applied the RRM on top of it. However, the FID~\cite{heuselGANsTrainedTwo2017a} did not reach values below \num{20}, and there was no correlation. Hence, we introduced separate random sampling for event generation for which we probed dimensions \{2, 4, 8, 16, 32\}. \num{4} degrees of freedom was the most optimal choice. We observed that as the dimension of Rdof increases, the intra-event correlation fades away between the generated images. We also checked the Uniform distribution for event Rdof sampling, which did not lead to any stable result. 
Several ways to fuse the Rdof to the class embeddings were tested such as learnable neural network layer~(matrix factorization), concatenating, summing, and having an MLP with non-linear part, but eventually chose a learnable neural network layer~(matrix factorization) for the feature mixing layer.

We also looked at different combinations of learning rates for G and D.
Using the TTUR regime results in a severe mode collapse.
Thus, we used the same learning rates for both G and D.
We swept through $\{1\times10^{-5}, 2.5\times10^{-5}, 5\times10^{-5}, 7.5\times10^{-5}, 1\times10^{-4}\}$ and selected $5\times10^{-5}$. For the backbone model, the shallow version of BigGAN-deep~\cite{brockLargeScaleGAN2019a}, BigGAN~\cite{brockLargeScaleGAN2019a}, led to mode-collapse; therefore, we chose BigGAN-deep.


\section{Supplementary Figures and Supplementary Tables}
\label{sec:ex_tables}
The following~\cref{fig:PXD_num_hits} is referenced in the Introduction, and the Algorithm ~\cref{alg:iea} is highlighted in Methods section of the main manuscript.

%\setcounter{figure}{0}  % reset counter for figure
%\setcounter{table}{0}  % reset counter for table
%\renewcommand\thefigure{\thesection\arabic{figure}} % redefine 
%\renewcommand\thetable{\thesection\arabic{table}} % redefine 

\begin{figure}[ht]
     \centering
         \centering
         \includegraphics[width=0.85\textwidth]{plots/num_hits}
         \caption{
         The number of PXD hits per layer and sensor (ladder).
         Each sensor has different occupancies for sensors in the inner and outer layers.
         The global asymmetry between them stems from the $\phi$ dependency of PXD images.
         }
         \label{fig:PXD_num_hits}
\end{figure}

\begin{algorithm}[htb]
\caption{Intra-Event Aware GAN}
\label{alg:iea}
\begin{algorithmic}[1]
\Require{generator and discriminator parameters $\theta_G$, $\theta_D$, Intra-Event-aware coefcient $\lambda_{\mathrm{IEA}}$, Uniformity coefcient $\lambda_{\mathrm{uniform}}$ and hyperparameter $s$, Adam hyperparameters $\alpha$, $\beta_1$, $\beta_2$, event size $M$, number of discriminator iteration steps per generator iteration $N_D$}
\Statex
\For{number of training iterations}
    \For{$t=1,...,N_D$}
        \State sample $\{\mathbf{z}^{i}\}^M_{i=1}\sim \mathrm{p}(\mathbf{z})$, 
        \State $\{\mathbf{x}^{i},\mathbf{y}^i\}^M_{i=1}\sim \mathrm{p}_{\mathrm{event}}(\mathbf{x}, \mathbf{y})$, $\{\mathbf{r}^i\}^M_{i=1} \sim \mathrm{p}_{\mathrm{Rdof}}(\mathbf{z})$ \Comment{\scriptsize Event Sampling.}
        \For{$i=1,...,M$}
            \State $\ell_{\mathrm{D}_{\mathrm{hinge}}}^{(i)}\leftarrow \ell_{\mathrm{D}_{\mathrm{hinge}}}(\mathbf{x}^{(i)};\mathrm{G}(\mathbf{z}^{i}, \mathbf{y}^{i}, \mathbf{r}^i))$
        \EndFor
        \State $\Lb_{\mathrm{D}_{\mathrm{hinge}}}\leftarrow \frac{1}{M}\sum_{i=1}^M\ell_{\mathrm{D}_{\mathrm{hinge}}}^{(i)}$
        \State $\Lb_{\mathrm{uniform}}\leftarrow \Lb_{\mathrm{uniform}}(\mathbf{x};s)$
        \Comment{\scriptsize The Uniformity Loss.}
        \State $\Lb_{2C}^{\mathrm{real}}\leftarrow \frac{1}{M}\sum_{i=1}^M\ell_{2C}(\mathbf{x}^i,\mathbf{y}^i)$
        \State $\theta_D\leftarrow Adam(\Lb_{\mathrm{D}_{\mathrm{hinge}}}+\lambda_{2C}\Lb_{2C}^{\mathrm{real}}+\lambda_{\mathrm{uniform}} \Lb_{\mathrm{uniform}}, \alpha, \beta_1, \beta_2)$
    \EndFor
    \State sample $\{\mathbf{z}^{i}\}^M_{i=1}\sim \mathrm{p}(\mathbf{z})$, 
    \State sample $\{\mathbf{r}^i\}^M_{i=1} \sim \mathrm{p}_{\mathrm{Rdof}}(\mathbf{z})$ \Comment{\scriptsize Event Sampling.}
    \For{$i=1,...,M$}
        \State $\ell_{\mathrm{G}_{\mathrm{hinge}}}^{(i)}\leftarrow \ell_{G_{\mathrm{hinge}}}(\mathrm{G}(\mathbf{z}^{i}, \mathbf{y}^{i}, \mathbf{r}^{i}))$
    \EndFor
    \State $\Lb_{\mathrm{G}_{\mathrm{hinge}}}\leftarrow \frac{1}{M}\sum_{i=1}^M\ell_{\mathrm{G}_{\mathrm{hinge}}}^{(i)}$
    \State $\Lb_{\mathrm{IEA}}\leftarrow \frac{1}{M}\sum_{i=1}^M\ell_{\mathrm{IEA}}(\mathrm{G}(\mathbf{z}^i,\mathbf{y}^i, \mathbf{r}^i),\mathbf{x}^{i})$
    \Comment{\scriptsize The Intra-Event Aware Loss.}
    \State $\Lb_{2C}^{\mathrm{fake}}\leftarrow \frac{1}{M}\sum_{i=1}^M\ell_{2C}(\mathrm{G}(\mathbf{z}^i,\mathbf{y}^i,\mathbf{r}^i),\mathbf{y}^i)$
    \State $\theta_G\leftarrow \mathrm{Adam}(\Lb_{\mathrm{G}_{\mathrm{hinge}}}+\lambda_{2C}\Lb_{2C}^{\mathrm{fake}}+\lambda_{\mathrm{IEA}}\Lb_{\mathrm{IEA}},\alpha, \beta_1, \beta_2)$
\EndFor

\end{algorithmic}
\end{algorithm}


\backmatter

%\section*{Acknowledgments}
%This research was supported by the collaborative project IDT-UM~(Innovative Digitale Technologien zur Erforschung von Universum und Materie) and KISS consortium funded by the German Federal Ministry of Education and Research~(BMBF) and the Deutsche Forschungsgemeinschaft under Germany's Excellence Strategy  EXC 2094 ``ORIGINS''  390783311. James Kahn's work is supported by the Helmholtz Association Initiative and Networking Fund under the Helmholtz AI platform grant. BH and SS wish to express their gratitude to Volker Tresp for the valuable discussions that enriched this work. We also thank David Katheder for his assistance with preparing the GitHub repository. We thank our colleagues from the Ludwig Maximilian University in Munich and the Computational Center for Particle and Astrophysics~(C2PAP), who provided expertise and computation power that greatly assisted the research.

\FloatBarrier
\section*{Declarations}

\subsection*{Data availability}
The data used in this study is openly available at \href{Zenodo}{https://zenodo.org/record/8331919}~\cite{hashemiPixelVertexDetector2023}.

\subsection*{Code availability}
The code for this study is available at \href{Github}{https://github.com/Hosein47/IEA-GAN}~\cite{hashemiIEAGAN2024}.

%\begin{itemize}
%\item Funding
%\item Conflict of interest/Competing interests (check journal-specific guidelines for which heading to use)
%\item Ethics approval 
%\item Consent to participate
%\item Consent for publication
%\item Availability of data and materials
%\item Code availability 
%\item Authors' contributions
%\end{itemize}
\clearpage

%%===========================================================================================%%
%% If you are submitting to one of the Nature Portfolio journals, using the eJP submission   %%
%% system, please include the references within the manuscript file itself. You may do this  %%
%% by copying the reference list from your .bbl file, paste it into the main manuscript .tex %%
%% file, and delete the associated \verb+\bibliography+ commands.                            %%
%%===========================================================================================%%

%\bibliography{sn-bibliography}% common bib file
%\begin{thebibliography}{}

%\end{thebibliography}

%% if required, the content of .bbl file can be included here once bbl is generated
%%\input sn-article.bbl

%% Default %%
% \input sn-sample-bib.tex%
% \bibliographystyle{plain}
% \bibliography{sn-bibliography}% common bib file
% \bibliography{zot-bib}% common bib file
%% BioMed_Central_Bib_Style_v1.01

\begin{thebibliography}{150}
% BibTex style file: bmc-mathphys.bst (version 2.1), 2014-07-24
\ifx \bisbn   \undefined \def \bisbn  #1{ISBN #1}\fi
\ifx \binits  \undefined \def \binits#1{#1}\fi
\ifx \bauthor  \undefined \def \bauthor#1{#1}\fi
\ifx \batitle  \undefined \def \batitle#1{#1}\fi
\ifx \bjtitle  \undefined \def \bjtitle#1{#1}\fi
\ifx \bvolume  \undefined \def \bvolume#1{\textbf{#1}}\fi
\ifx \byear  \undefined \def \byear#1{#1}\fi
\ifx \bissue  \undefined \def \bissue#1{#1}\fi
\ifx \bfpage  \undefined \def \bfpage#1{#1}\fi
\ifx \blpage  \undefined \def \blpage #1{#1}\fi
\ifx \burl  \undefined \def \burl#1{\textsf{#1}}\fi
\ifx \doiurl  \undefined \def \doiurl#1{\url{https://doi.org/#1}}\fi
\ifx \betal  \undefined \def \betal{\textit{et al.}}\fi
\ifx \binstitute  \undefined \def \binstitute#1{#1}\fi
\ifx \binstitutionaled  \undefined \def \binstitutionaled#1{#1}\fi
\ifx \bctitle  \undefined \def \bctitle#1{#1}\fi
\ifx \beditor  \undefined \def \beditor#1{#1}\fi
\ifx \bpublisher  \undefined \def \bpublisher#1{#1}\fi
\ifx \bbtitle  \undefined \def \bbtitle#1{#1}\fi
\ifx \bedition  \undefined \def \bedition#1{#1}\fi
\ifx \bseriesno  \undefined \def \bseriesno#1{#1}\fi
\ifx \blocation  \undefined \def \blocation#1{#1}\fi
\ifx \bsertitle  \undefined \def \bsertitle#1{#1}\fi
\ifx \bsnm \undefined \def \bsnm#1{#1}\fi
\ifx \bsuffix \undefined \def \bsuffix#1{#1}\fi
\ifx \bparticle \undefined \def \bparticle#1{#1}\fi
\ifx \barticle \undefined \def \barticle#1{#1}\fi
\bibcommenthead
\ifx \bconfdate \undefined \def \bconfdate #1{#1}\fi
\ifx \botherref \undefined \def \botherref #1{#1}\fi
%\ifx \url \undefined \def \url#1{\textsf{#1}}\fi
\ifx \bchapter \undefined \def \bchapter#1{#1}\fi
\ifx \bbook \undefined \def \bbook#1{#1}\fi
\ifx \bcomment \undefined \def \bcomment#1{#1}\fi
\ifx \oauthor \undefined \def \oauthor#1{#1}\fi
\ifx \citeauthoryear \undefined \def \citeauthoryear#1{#1}\fi
\ifx \endbibitem  \undefined \def \endbibitem {}\fi
\ifx \bconflocation  \undefined \def \bconflocation#1{#1}\fi
\ifx \arxivurl  \undefined \def \arxivurl#1{\textsf{#1}}\fi
\csname PreBibitemsHook\endcsname

%%% 1
\bibitem{paganiniAcceleratingScienceGenerative2018}
\begin{barticle}
\bauthor{\bsnm{Paganini}, \binits{M.}},
\bauthor{\bsnm{{de Oliveira}}, \binits{L.}},
\bauthor{\bsnm{Nachman}, \binits{B.}}:
\batitle{Accelerating {{Science}} with {{Generative Adversarial Networks}}:
  {{An Application}} to {{3D Particle Showers}} in {{Multilayer
  Calorimeters}}}.
\bjtitle{Physical Review Letters}
\bvolume{120}(\bissue{4}),
\bfpage{042003}
(\byear{2018}).
\doiurl{10.1103/PhysRevLett.120.042003}
\end{barticle}
\endbibitem

%%% 2
\bibitem{vallecorsaGenerativeModelsFast2018a}
\begin{barticle}
\bauthor{\bsnm{Vallecorsa}, \binits{S.}}:
\batitle{Generative models for fast simulation}.
\bjtitle{Journal of Physics: Conference Series}
\bvolume{1085}(\bissue{2}),
\bfpage{022005}
(\byear{2018}).
\doiurl{10.1088/1742-6596/1085/2/022005}
\end{barticle}
\endbibitem

%%% 3
\bibitem{PhysRevD.97.014021}
\begin{barticle}
\bauthor{\bsnm{Paganini}, \binits{M.}},
\bauthor{\bsnm{{de Oliveira}}, \binits{L.}},
\bauthor{\bsnm{Nachman}, \binits{B.}}:
\batitle{{{CaloGAN}}: {{Simulating 3D}} high energy particle showers in
  multilayer electromagnetic calorimeters with generative adversarial
  networks}.
\bjtitle{Physical Review D: Particles and Fields}
\bvolume{97}(\bissue{1}),
\bfpage{014021}
(\byear{2018}).
\doiurl{10.1103/PhysRevD.97.014021}
\end{barticle}
\endbibitem

%%% 4
\bibitem{oliveiraControllingPhysicalAttributes2018a}
\begin{barticle}
\bauthor{\bparticle{de} \bsnm{Oliveira}, \binits{L.}},
\bauthor{\bsnm{Paganini}, \binits{M.}},
\bauthor{\bsnm{Nachman}, \binits{B.}}:
\batitle{Controlling {{Physical Attributes}} in {{GAN-Accelerated Simulation}}
  of {{Electromagnetic Calorimeters}}}.
\bjtitle{Journal of Physics: Conference Series}
\bvolume{1085}(\bissue{4}),
\bfpage{042017}
(\byear{2018}).
\doiurl{10.1088/1742-6596/1085/4/042017}
\end{barticle}
\endbibitem

%%% 5
\bibitem{erdmannGeneratingRefiningParticle2018}
\begin{barticle}
\bauthor{\bsnm{Erdmann}, \binits{M.}},
\bauthor{\bsnm{Geiger}, \binits{L.}},
\bauthor{\bsnm{Glombitza}, \binits{J.}},
\bauthor{\bsnm{Schmidt}, \binits{D.}}:
\batitle{Generating and {{Refining Particle Detector Simulations Using}} the
  {{Wasserstein Distance}} in {{Adversarial Networks}}}.
\bjtitle{Computing and Software for Big Science}
\bvolume{2}(\bissue{1}),
\bfpage{4}
(\byear{2018}).
\doiurl{10.1007/s41781-018-0008-x}
\end{barticle}
\endbibitem

%%% 6
\bibitem{srebreGenerationBelleII2020a}
\begin{barticle}
\bauthor{\bsnm{Srebre}, \binits{M.}},
\bauthor{\bsnm{Schmolz}, \binits{P.}},
\bauthor{\bsnm{Hashemi}, \binits{B.}},
\bauthor{\bsnm{Ritter}, \binits{M.}},
\bauthor{\bsnm{Kuhr}, \binits{T.}}:
\batitle{Generation of {{Belle II Pixel Detector Background Data}} with a
  {{GAN}}}.
\bjtitle{EPJ Web of Conferences}
\bvolume{245},
\bfpage{02010}
(\byear{2020}).
\doiurl{10.1051/epjconf/202024502010}
\end{barticle}
\endbibitem

%%% 7
\bibitem{hashemiPixelDetectorBackground2021a}
\begin{barticle}
\bauthor{\bsnm{Hashemi}, \binits{B.}},
\bauthor{\bsnm{Hartmann}, \binits{N.}},
\bauthor{\bsnm{Kuhr}, \binits{T.}},
\bauthor{\bsnm{Ritter}, \binits{M.}},
\bauthor{\bsnm{Srebre}, \binits{M.}}:
\batitle{Pixel {{Detector Background Generation}} using {{Generative
  Adversarial Networks}} at {{Belle II}}}.
\bjtitle{EPJ Web of Conferences}
\bvolume{251},
\bfpage{03031}
(\byear{2021}).
\doiurl{10.1051/epjconf/202125103031}
\end{barticle}
\endbibitem

%%% 8
\bibitem{buhmannGettingHighHigh2021}
\begin{barticle}
\bauthor{\bsnm{Buhmann}, \binits{E.}},
\bauthor{\bsnm{Diefenbacher}, \binits{S.}},
\bauthor{\bsnm{Eren}, \binits{E.}},
\bauthor{\bsnm{Gaede}, \binits{F.}},
\bauthor{\bsnm{Kasieczka}, \binits{G.}},
\bauthor{\bsnm{Korol}, \binits{A.}},
\bauthor{\bsnm{Kr{\"u}ger}, \binits{K.}}:
\batitle{Getting {{High}}: {{High Fidelity Simulation}} of {{High Granularity
  Calorimeters}} with {{High Speed}}}.
\bjtitle{Computing and Software for Big Science}
\bvolume{5}(\bissue{1}),
\bfpage{13}
(\byear{2021}).
\doiurl{10.1007/s41781-021-00056-0}
\end{barticle}
\endbibitem

%%% 9
\bibitem{goodfellowGenerativeAdversarialNets2014a}
\begin{bchapter}
\bauthor{\bsnm{Goodfellow}, \binits{I.}},
\bauthor{\bsnm{{Pouget-Abadie}}, \binits{J.}},
\bauthor{\bsnm{Mirza}, \binits{M.}},
\bauthor{\bsnm{Xu}, \binits{B.}},
\bauthor{\bsnm{{Warde-Farley}}, \binits{D.}},
\bauthor{\bsnm{Ozair}, \binits{S.}},
\bauthor{\bsnm{Courville}, \binits{A.}},
\bauthor{\bsnm{Bengio}, \binits{Y.}}:
\bctitle{Generative {{Adversarial Nets}}}.
In: \bbtitle{Advances in {{Neural Information Processing Systems}}},
vol. \bseriesno{27}.
\bpublisher{Curran Associates, Inc.},
\blocation{Virtual}
(\byear{2014}).
\burl{https://proceedings.neurips.cc/paper_files/paper/2014/hash/5ca3e9b122f61f8f06494c97b1afccf3-Abstract.html}
Accessed 2024-04-01
\end{bchapter}
\endbibitem

%%% 10
\bibitem{belaynehCalorimetryDeepLearning2020}
\begin{barticle}
\bauthor{\bsnm{Belayneh}, \binits{D.}},
\bauthor{\bsnm{Carminati}, \binits{F.}},
\bauthor{\bsnm{Farbin}, \binits{A.}},
\bauthor{\bsnm{Hooberman}, \binits{B.}},
\bauthor{\bsnm{Khattak}, \binits{G.}},
\bauthor{\bsnm{Liu}, \binits{M.}},
\bauthor{\bsnm{Liu}, \binits{J.}},
\bauthor{\bsnm{Olivito}, \binits{D.}},
\bauthor{\bsnm{Pacela}, \binits{V.B.}},
\bauthor{\bsnm{Pierini}, \binits{M.}},
\bauthor{\bsnm{Schwing}, \binits{A.}},
\bauthor{\bsnm{Spiropulu}, \binits{M.}},
\bauthor{\bsnm{Vallecorsa}, \binits{S.}},
\bauthor{\bsnm{Vlimant}, \binits{J.-R.}},
\bauthor{\bsnm{Wei}, \binits{W.}},
\bauthor{\bsnm{Zhang}, \binits{M.}}:
\batitle{Calorimetry with deep learning: Particle simulation and reconstruction
  for collider physics}.
\bjtitle{The European Physical Journal C}
\bvolume{80}(\bissue{7}),
\bfpage{688}
(\byear{2020}).
\doiurl{10.1140/epjc/s10052-020-8251-9}
\end{barticle}
\endbibitem

%%% 11
\bibitem{khattakFastSimulationHigh2022a}
\begin{barticle}
\bauthor{\bsnm{Khattak}, \binits{G.R.}},
\bauthor{\bsnm{Vallecorsa}, \binits{S.}},
\bauthor{\bsnm{Carminati}, \binits{F.}},
\bauthor{\bsnm{Khan}, \binits{G.M.}}:
\batitle{Fast simulation of a high granularity calorimeter by generative
  adversarial networks}.
\bjtitle{The European Physical Journal C}
\bvolume{82}(\bissue{4}),
\bfpage{386}
(\byear{2022}).
\doiurl{10.1140/epjc/s10052-022-10258-4}
\end{barticle}
\endbibitem

%%% 12
\bibitem{krauseCaloFlowCaloChallengeDataset2023}
\begin{botherref}
\oauthor{\bsnm{Krause}, \binits{C.}},
\oauthor{\bsnm{Pang}, \binits{I.}},
\oauthor{\bsnm{Shih}, \binits{D.}}:
{{CaloFlow}} for {{CaloChallenge Dataset}} 1.
arXiv.
Comment: 32 pages, 18 figures, v2: updated pion evaluation
(2023).
\doiurl{10.48550/arXiv.2210.14245}
\end{botherref}
\endbibitem

%%% 13
\bibitem{buhmannFastAccurateElectromagnetic2021}
\begin{barticle}
\bauthor{\bsnm{Buhmann}, \binits{E.}},
\bauthor{\bsnm{Diefenbacher}, \binits{S.}},
\bauthor{\bsnm{Eren}, \binits{E.}},
\bauthor{\bsnm{Gaede}, \binits{F.}},
\bauthor{\bsnm{Hundhausen}, \binits{D.}},
\bauthor{\bsnm{Kasieczka}, \binits{G.}},
\bauthor{\bsnm{Korcari}, \binits{W.}},
\bauthor{\bsnm{Korol}, \binits{A.}},
\bauthor{\bsnm{Kr{\"u}ger}, \binits{K.}},
\bauthor{\bsnm{McKeown}, \binits{P.}},
\bauthor{\bsnm{Rustige}, \binits{L.}}:
\batitle{Fast and {{Accurate Electromagnetic}} and {{Hadronic Showers}} from
  {{Generative Models}}}.
\bjtitle{EPJ Web of Conferences}
\bvolume{251},
\bfpage{03049}
(\byear{2021}).
\doiurl{10.1051/epjconf/202125103049}
\end{barticle}
\endbibitem

%%% 14
\bibitem{mikuniScorebasedGenerativeModels2022}
\begin{barticle}
\bauthor{\bsnm{Mikuni}, \binits{V.}},
\bauthor{\bsnm{Nachman}, \binits{B.}}:
\batitle{Score-based generative models for calorimeter shower simulation}.
\bjtitle{Physical Review D}
\bvolume{106}(\bissue{9}),
\bfpage{092009}
(\byear{2022}).
\doiurl{10.1103/PhysRevD.106.092009}
\end{barticle}
\endbibitem

%%% 15
\bibitem{krauseCaloFlowIIEven2023}
\begin{botherref}
\oauthor{\bsnm{Krause}, \binits{C.}},
\oauthor{\bsnm{Shih}, \binits{D.}}:
{{CaloFlow II}}: {{Even Faster}} and {{Still Accurate Generation}} of
  {{Calorimeter Showers}} with {{Normalizing Flows}}.
arXiv.
Comment: 24 pages, 15 figures, 4 tables; v2: matches accepted version
(2023).
\doiurl{10.48550/arXiv.2110.11377}
\end{botherref}
\endbibitem

%%% 16
\bibitem{hashemiLHCAnalysisspecificDatasets2019}
\begin{botherref}
\oauthor{\bsnm{Hashemi}, \binits{B.}},
\oauthor{\bsnm{Amin}, \binits{N.}},
\oauthor{\bsnm{Datta}, \binits{K.}},
\oauthor{\bsnm{Olivito}, \binits{D.}},
\oauthor{\bsnm{Pierini}, \binits{M.}}:
{{LHC}} Analysis-Specific Datasets with {{Generative Adversarial Networks}}.
arXiv.
Comment: 14 pages, 11 figures
(2019).
\doiurl{10.48550/arXiv.1901.05282}
\end{botherref}
\endbibitem

%%% 17
\bibitem{disipioDijetGANGenerativeAdversarialNetwork2019}
\begin{barticle}
\bauthor{\bsnm{Di~Sipio}, \binits{R.}},
\bauthor{\bsnm{Giannelli}, \binits{M.F.}},
\bauthor{\bsnm{Haghighat}, \binits{S.K.}},
\bauthor{\bsnm{Palazzo}, \binits{S.}}:
\batitle{{{DijetGAN}}: A {{Generative-Adversarial Network}} approach for the
  simulation of {{QCD}} dijet events at the {{LHC}}}.
\bjtitle{Journal of High Energy Physics}
\bvolume{2019}(\bissue{8}),
\bfpage{110}
(\byear{2019}).
\doiurl{10.1007/JHEP08(2019)110}
\end{barticle}
\endbibitem

%%% 18
\bibitem{martinezParticleGenerativeAdversarial2020}
\begin{barticle}
\bauthor{\bsnm{Mart{\'i}nez}, \binits{J.A.}},
\bauthor{\bsnm{Nguyen}, \binits{T.Q.}},
\bauthor{\bsnm{Pierini}, \binits{M.}},
\bauthor{\bsnm{Spiropulu}, \binits{M.}},
\bauthor{\bsnm{Vlimant}, \binits{J.-R.}}:
\batitle{Particle {{Generative Adversarial Networks}} for full-event simulation
  at the {{LHC}} and their application to pileup description}.
\bjtitle{Journal of Physics: Conference Series}
\bvolume{1525}(\bissue{1}),
\bfpage{012081}
(\byear{2020}).
\doiurl{10.1088/1742-6596/1525/1/012081}
\end{barticle}
\endbibitem

%%% 19
\bibitem{alanaziSurveyMachineLearningBased2021a}
\begin{bchapter}
\bauthor{\bsnm{Alanazi}, \binits{Y.}},
\bauthor{\bsnm{Sato}, \binits{N.}},
\bauthor{\bsnm{Ambrozewicz}, \binits{P.}},
\bauthor{\bsnm{{Hiller-Blin}}, \binits{A.}},
\bauthor{\bsnm{Melnitchouk}, \binits{W.}},
\bauthor{\bsnm{Battaglieri}, \binits{M.}},
\bauthor{\bsnm{Liu}, \binits{T.}},
\bauthor{\bsnm{Li}, \binits{Y.}}:
\bctitle{A {{Survey}} of {{Machine Learning-Based Physics Event Generation}}}.
In: \bbtitle{Twenty-{{Ninth International Joint Conference}} on {{Artificial
  Intelligence}}},
vol. \bseriesno{5},
pp. \bfpage{4286}--\blpage{4293}
(\byear{2021}).
\doiurl{10.24963/ijcai.2021/588}
\end{bchapter}
\endbibitem

%%% 20
\bibitem{butterHowGANLHC2019a}
\begin{barticle}
\bauthor{\bsnm{Butter}, \binits{A.}},
\bauthor{\bsnm{Plehn}, \binits{T.}},
\bauthor{\bsnm{Winterhalder}, \binits{R.}}:
\batitle{How to {{GAN LHC}} events}.
\bjtitle{SciPost Physics}
\bvolume{7}(\bissue{6}),
\bfpage{075}
(\byear{2019}).
\doiurl{10.21468/SciPostPhys.7.6.075}
\end{barticle}
\endbibitem

%%% 21
\bibitem{ottenEventGenerationStatistical2021a}
\begin{barticle}
\bauthor{\bsnm{Otten}, \binits{S.}},
\bauthor{\bsnm{Caron}, \binits{S.}},
\bauthor{\bsnm{{de Swart}}, \binits{W.}},
\bauthor{\bsnm{{van Beekveld}}, \binits{M.}},
\bauthor{\bsnm{Hendriks}, \binits{L.}},
\bauthor{\bsnm{{van Leeuwen}}, \binits{C.}},
\bauthor{\bsnm{Podareanu}, \binits{D.}},
\bauthor{\bsnm{{Ruiz de Austri}}, \binits{R.}},
\bauthor{\bsnm{Verheyen}, \binits{R.}}:
\batitle{Event generation and statistical sampling for physics with deep
  generative models and a density information buffer}.
\bjtitle{Nature Communications}
\bvolume{12}(\bissue{1}),
\bfpage{2985}
(\byear{2021}).
\doiurl{10.1038/s41467-021-22616-z}
\end{barticle}
\endbibitem

%%% 22
\bibitem{arjovskyWassersteinGenerativeAdversarial2017}
\begin{bchapter}
\bauthor{\bsnm{Arjovsky}, \binits{M.}},
\bauthor{\bsnm{Chintala}, \binits{S.}},
\bauthor{\bsnm{Bottou}, \binits{L.}}:
\bctitle{Wasserstein {{Generative Adversarial Networks}}}.
In: \bbtitle{Proceedings of the 34th {{International Conference}} on {{Machine
  Learning}}},
pp. \bfpage{214}--\blpage{223}.
\bpublisher{PMLR},
\blocation{Virtual}
(\byear{2017}).
\burl{https://proceedings.mlr.press/v70/arjovsky17a.html}
Accessed 2024-04-01
\end{bchapter}
\endbibitem

%%% 23
\bibitem{gulrajaniImprovedTrainingWasserstein2017a}
\begin{bchapter}
\bauthor{\bsnm{Gulrajani}, \binits{I.}},
\bauthor{\bsnm{Ahmed}, \binits{F.}},
\bauthor{\bsnm{Arjovsky}, \binits{M.}},
\bauthor{\bsnm{Dumoulin}, \binits{V.}},
\bauthor{\bsnm{Courville}, \binits{A.}}:
\bctitle{Improved training of wasserstein {{GANs}}}.
In: \bbtitle{Proceedings of the 31st {{International Conference}} on {{Neural
  Information Processing Systems}}}.
\bsertitle{{{NIPS}}'17},
pp. \bfpage{5769}--\blpage{5779}.
\bpublisher{Curran Associates Inc.},
\blocation{Red Hook, NY, USA}
(\byear{2017})
\end{bchapter}
\endbibitem

%%% 24
\bibitem{rezendeVariationalInferenceNormalizing2015}
\begin{bchapter}
\bauthor{\bsnm{Rezende}, \binits{D.}},
\bauthor{\bsnm{Mohamed}, \binits{S.}}:
\bctitle{Variational {{Inference}} with {{Normalizing Flows}}}.
In: \bbtitle{Proceedings of the 32nd {{International Conference}} on {{Machine
  Learning}}},
pp. \bfpage{1530}--\blpage{1538}.
\bpublisher{PMLR},
\blocation{Virtual}
(\byear{2015}).
\burl{https://proceedings.mlr.press/v37/rezende15.html}
Accessed 2024-04-01
\end{bchapter}
\endbibitem

%%% 25
\bibitem{aberleHighLuminosityLargeHadron2020}
\begin{botherref}
\oauthor{\bsnm{Aberle}, \binits{O.}},
\oauthor{\bsnm{B{\'e}jar~Alonso}, \binits{I.}},
\oauthor{\bsnm{Br{\"u}ning}, \binits{O.}},
\oauthor{\bsnm{Fessia}, \binits{P.}},
\oauthor{\bsnm{Rossi}, \binits{L.}},
\oauthor{\bsnm{Tavian}, \binits{L.}},
\oauthor{\bsnm{Zerlauth}, \binits{M.}},
\oauthor{\bsnm{Adorisio}, \binits{C.}},
\oauthor{\bsnm{Adraktas}, \binits{A.}},
\oauthor{\bsnm{Ady}, \binits{M.}},
\oauthor{\bsnm{Albertone}, \binits{J.}},
\oauthor{\bsnm{Alberty}, \binits{L.}},
\oauthor{\bsnm{Alcaide~Leon}, \binits{M.}},
\oauthor{\bsnm{Alekou}, \binits{A.}},
\oauthor{\bsnm{Alesini}, \binits{D.}},
\oauthor{\bsnm{Ferreira}, \binits{B.A.}},
\oauthor{\bsnm{Lopez}, \binits{P.A.}},
\oauthor{\bsnm{Ambrosio}, \binits{G.}},
\oauthor{\bsnm{Andreu~Munoz}, \binits{P.}},
\oauthor{\bsnm{Anerella}, \binits{M.}},
\oauthor{\bsnm{{Angal-Kalinin}}, \binits{D.}},
\oauthor{\bsnm{Antoniou}, \binits{F.}},
\oauthor{\bsnm{Apollinari}, \binits{G.}},
\oauthor{\bsnm{Apollonio}, \binits{A.}},
\oauthor{\bsnm{Appleby}, \binits{R.}},
\oauthor{\bsnm{Arduini}, \binits{G.}},
\oauthor{\bsnm{Alonso}, \binits{B.A.}},
\oauthor{\bsnm{Artoos}, \binits{K.}},
\oauthor{\bsnm{Atieh}, \binits{S.}},
\oauthor{\bsnm{Auchmann}, \binits{B.}},
\oauthor{\bsnm{Badin}, \binits{V.}},
\oauthor{\bsnm{Baer}, \binits{T.}},
\oauthor{\bsnm{Baffari}, \binits{D.}},
\oauthor{\bsnm{Baglin}, \binits{V.}},
\oauthor{\bsnm{Bajko}, \binits{M.}},
\oauthor{\bsnm{Ball}, \binits{A.}},
\oauthor{\bsnm{Ballarino}, \binits{A.}},
\oauthor{\bsnm{Bally}, \binits{S.}},
\oauthor{\bsnm{Bampton}, \binits{T.}},
\oauthor{\bsnm{Banfi}, \binits{D.}},
\oauthor{\bsnm{Barlow}, \binits{R.}},
\oauthor{\bsnm{Barnes}, \binits{M.}},
\oauthor{\bsnm{Barranco}, \binits{J.}},
\oauthor{\bsnm{Barthelemy}, \binits{L.}},
\oauthor{\bsnm{Bartmann}, \binits{W.}},
\oauthor{\bsnm{Bartosik}, \binits{H.}},
\oauthor{\bsnm{Barzi}, \binits{E.}},
\oauthor{\bsnm{Battistin}, \binits{M.}},
\oauthor{\bsnm{Baudrenghien}, \binits{P.}},
\oauthor{\bsnm{Alonso}, \binits{I.B.}},
\oauthor{\bsnm{Belomestnykh}, \binits{S.}},
\oauthor{\bsnm{Benoit}, \binits{A.}},
\oauthor{\bsnm{{Ben-Zvi}}, \binits{I.}},
\oauthor{\bsnm{Bertarelli}, \binits{A.}},
\oauthor{\bsnm{Bertolasi}, \binits{S.}},
\oauthor{\bsnm{Bertone}, \binits{C.}},
\oauthor{\bsnm{Bertran}, \binits{B.}},
\oauthor{\bsnm{Bestmann}, \binits{P.}},
\oauthor{\bsnm{Biancacci}, \binits{N.}},
\oauthor{\bsnm{Bignami}, \binits{A.}},
\oauthor{\bsnm{Bliss}, \binits{N.}},
\oauthor{\bsnm{Boccard}, \binits{C.}},
\oauthor{\bsnm{Body}, \binits{Y.}},
\oauthor{\bsnm{Borburgh}, \binits{J.}},
\oauthor{\bsnm{Bordini}, \binits{B.}},
\oauthor{\bsnm{Borralho}, \binits{F.}},
\oauthor{\bsnm{Bossert}, \binits{R.}},
\oauthor{\bsnm{Bottura}, \binits{L.}},
\oauthor{\bsnm{Boucherie}, \binits{A.}},
\oauthor{\bsnm{Bozzi}, \binits{R.}},
\oauthor{\bsnm{Bracco}, \binits{C.}},
\oauthor{\bsnm{Bravin}, \binits{E.}},
\oauthor{\bsnm{Bregliozzi}, \binits{G.}},
\oauthor{\bsnm{Brett}, \binits{D.}},
\oauthor{\bsnm{Broche}, \binits{A.}},
\oauthor{\bsnm{Brodzinski}, \binits{K.}},
\oauthor{\bsnm{Broggi}, \binits{F.}},
\oauthor{\bsnm{Bruce}, \binits{R.}},
\oauthor{\bsnm{Brugger}, \binits{M.}},
\oauthor{\bsnm{Br{\"u}ning}, \binits{O.}},
\oauthor{\bsnm{Buffat}, \binits{X.}},
\oauthor{\bsnm{Burkhardt}, \binits{H.}},
\oauthor{\bsnm{Burnet}, \binits{J.}},
\oauthor{\bsnm{Burov}, \binits{A.}},
\oauthor{\bsnm{Burt}, \binits{G.}},
\oauthor{\bsnm{Cabezas}, \binits{R.}},
\oauthor{\bsnm{Cai}, \binits{Y.}},
\oauthor{\bsnm{Calaga}, \binits{R.}},
\oauthor{\bsnm{Calatroni}, \binits{S.}},
\oauthor{\bsnm{Capatina}, \binits{O.}},
\oauthor{\bsnm{Capelli}, \binits{T.}},
\oauthor{\bsnm{Cardon}, \binits{P.}},
\oauthor{\bsnm{Carlier}, \binits{E.}},
\oauthor{\bsnm{Carra}, \binits{F.}},
\oauthor{\bsnm{Carvalho}, \binits{A.}},
\oauthor{\bsnm{Carver}, \binits{L.R.}},
\oauthor{\bsnm{Caspers}, \binits{F.}},
\oauthor{\bsnm{Cattenoz}, \binits{G.}},
\oauthor{\bsnm{Cerutti}, \binits{F.}},
\oauthor{\bsnm{Chanc{\'e}}, \binits{A.}},
\oauthor{\bsnm{Rodrigues}, \binits{M.C.}},
\oauthor{\bsnm{Chemli}, \binits{S.}},
\oauthor{\bsnm{Cheng}, \binits{D.}},
\oauthor{\bsnm{Chiggiato}, \binits{P.}},
\oauthor{\bsnm{Chlachidze}, \binits{G.}},
\oauthor{\bsnm{Claudet}, \binits{S.}},
\oauthor{\bsnm{Coello De~Portugal}, \binits{{\relax JM}.}},
\oauthor{\bsnm{Collazos}, \binits{C.}},
\oauthor{\bsnm{Corso}, \binits{J.}},
\oauthor{\bsnm{Costa~Machado}, \binits{S.}},
\oauthor{\bsnm{Costa~Pinto}, \binits{P.}},
\oauthor{\bsnm{Coulinge}, \binits{E.}},
\oauthor{\bsnm{Crouch}, \binits{M.}},
\oauthor{\bsnm{Cruikshank}, \binits{P.}},
\oauthor{\bsnm{Cruz~Alaniz}, \binits{E.}},
\oauthor{\bsnm{Czech}, \binits{M.}},
\oauthor{\bsnm{{Dahlerup-Petersen}}, \binits{K.}},
\oauthor{\bsnm{Dalena}, \binits{B.}},
\oauthor{\bsnm{Daniluk}, \binits{G.}},
\oauthor{\bsnm{Danzeca}, \binits{S.}},
\oauthor{\bsnm{Day}, \binits{H.}},
\oauthor{\bsnm{De~Carvalho~Saraiva}, \binits{J.}},
\oauthor{\bsnm{De~Luca}, \binits{D.}},
\oauthor{\bsnm{De~Maria}, \binits{R.}},
\oauthor{\bsnm{De~Rijk}, \binits{G.}},
\oauthor{\bsnm{De~Silva}, \binits{S.}},
\oauthor{\bsnm{Dehning}, \binits{B.}},
\oauthor{\bsnm{Delayen}, \binits{J.}},
\oauthor{\bsnm{Deliege}, \binits{Q.}},
\oauthor{\bsnm{Delille}, \binits{B.}},
\oauthor{\bsnm{Delsaux}, \binits{F.}},
\oauthor{\bsnm{Denz}, \binits{R.}},
\oauthor{\bsnm{Devred}, \binits{A.}},
\oauthor{\bsnm{Dexter}, \binits{A.}},
\oauthor{\bsnm{Di~Girolamo}, \binits{B.}},
\oauthor{\bsnm{Dietderich}, \binits{D.}},
\oauthor{\bsnm{Dilly}, \binits{J.W.}},
\oauthor{\bsnm{Doherty}, \binits{A.}},
\oauthor{\bsnm{Dos~Santos}, \binits{N.}},
\oauthor{\bsnm{Drago}, \binits{A.}},
\oauthor{\bsnm{{D.Drskovic}}},
\oauthor{\bsnm{Ramos}, \binits{D.D.}},
\oauthor{\bsnm{Ducimeti{\`e}re}, \binits{L.}},
\oauthor{\bsnm{Efthymiopoulos}, \binits{I.}},
\oauthor{\bsnm{Einsweiler}, \binits{K.}},
\oauthor{\bsnm{Esposito}, \binits{L.}},
\oauthor{\bsnm{Esteban~Muller}, \binits{J.}},
\oauthor{\bsnm{Evrard}, \binits{S.}},
\oauthor{\bsnm{Fabbricatore}, \binits{P.}},
\oauthor{\bsnm{Farinon}, \binits{S.}},
\oauthor{\bsnm{Fartoukh}, \binits{S.}},
\oauthor{\bsnm{{Faus-Golfe}}, \binits{A.}},
\oauthor{\bsnm{Favre}, \binits{G.}},
\oauthor{\bsnm{Felice}, \binits{H.}},
\oauthor{\bsnm{Feral}, \binits{B.}},
\oauthor{\bsnm{Ferlin}, \binits{G.}},
\oauthor{\bsnm{Ferracin}, \binits{P.}},
\oauthor{\bsnm{Ferrari}, \binits{A.}},
\oauthor{\bsnm{Ferreira}, \binits{L.}},
\oauthor{\bsnm{Fessia}, \binits{P.}},
\oauthor{\bsnm{Ficcadenti}, \binits{L.}},
\oauthor{\bsnm{Fiotakis}, \binits{S.}},
\oauthor{\bsnm{Fiscarelli}, \binits{L.}},
\oauthor{\bsnm{Fitterer}, \binits{M.}},
\oauthor{\bsnm{Fleiter}, \binits{J.}},
\oauthor{\bsnm{Foffano}, \binits{G.}},
\oauthor{\bsnm{Fol}, \binits{E.}},
\oauthor{\bsnm{Folch}, \binits{R.}},
\oauthor{\bsnm{Foraz}, \binits{K.}},
\oauthor{\bsnm{Foussat}, \binits{A.}},
\oauthor{\bsnm{Frankl}, \binits{M.}},
\oauthor{\bsnm{Frasciello}, \binits{O.}},
\oauthor{\bsnm{Fraser}, \binits{M.}},
\oauthor{\bsnm{Menendez}, \binits{P.F.}},
\oauthor{\bsnm{Fuchs}, \binits{J.-F.}},
\oauthor{\bsnm{Furuseth}, \binits{S.}},
\oauthor{\bsnm{Gaddi}, \binits{A.}},
\oauthor{\bsnm{Gallilee}, \binits{M.}},
\oauthor{\bsnm{Gallo}, \binits{A.}},
\oauthor{\bsnm{Alia}, \binits{R.G.}},
\oauthor{\bsnm{Gavela}, \binits{H.G.}},
\oauthor{\bsnm{Matos}, \binits{J.G.}},
\oauthor{\bsnm{Garcia~Morales}, \binits{H.}},
\oauthor{\bsnm{Valdivieso}, \binits{A.G.-T.}},
\oauthor{\bsnm{Garino}, \binits{C.}},
\oauthor{\bsnm{Garion}, \binits{C.}},
\oauthor{\bsnm{Gascon}, \binits{J.}},
\oauthor{\bsnm{Gasnier}, \binits{{\relax Ch}.}},
\oauthor{\bsnm{Gentini}, \binits{L.}},
\oauthor{\bsnm{Gentsos}, \binits{C.}},
\oauthor{\bsnm{Ghosh}, \binits{A.}},
\oauthor{\bsnm{Giacomel}, \binits{L.}},
\oauthor{\bsnm{Hernandez}, \binits{K.G.}},
\oauthor{\bsnm{Gibson}, \binits{S.}},
\oauthor{\bsnm{Ginburg}, \binits{C.}},
\oauthor{\bsnm{Giordano}, \binits{F.}},
\oauthor{\bsnm{Giovannozzi}, \binits{M.}},
\oauthor{\bsnm{Goddard}, \binits{B.}},
\oauthor{\bsnm{Gomes}, \binits{P.}},
\oauthor{\bsnm{Gonzalez De La Aleja~Cabana}, \binits{M.}},
\oauthor{\bsnm{Goudket}, \binits{P.}},
\oauthor{\bsnm{Gousiou}, \binits{E.}},
\oauthor{\bsnm{Gradassi}, \binits{P.}},
\oauthor{\bsnm{Costa}, \binits{A.G.}},
\oauthor{\bsnm{{Grand-Cl{\'e}ment}}, \binits{L.}},
\oauthor{\bsnm{Grillot}, \binits{S.}},
\oauthor{\bsnm{Guillaume}, \binits{{\relax JC}.}},
\oauthor{\bsnm{Guinchard}, \binits{M.}},
\oauthor{\bsnm{Hagen}, \binits{P.}},
\oauthor{\bsnm{Hakulinen}, \binits{T.}},
\oauthor{\bsnm{Hall}, \binits{B.}},
\oauthor{\bsnm{Hansen}, \binits{J.}},
\oauthor{\bsnm{Heredia~Garcia}, \binits{N.}},
\oauthor{\bsnm{Herr}, \binits{W.}},
\oauthor{\bsnm{Herty}, \binits{A.}},
\oauthor{\bsnm{Hill}, \binits{C.}},
\oauthor{\bsnm{Hofer}, \binits{M.}},
\oauthor{\bsnm{H{\"o}fle}, \binits{W.}},
\oauthor{\bsnm{Holzer}, \binits{B.}},
\oauthor{\bsnm{Hopkins}, \binits{S.}},
\oauthor{\bsnm{Hrivnak}, \binits{J.}},
\oauthor{\bsnm{Iadarola}, \binits{G.}},
\oauthor{\bsnm{Infantino}, \binits{A.}},
\oauthor{\bsnm{Bermudez}, \binits{S.I.}},
\oauthor{\bsnm{Jakobsen}, \binits{S.}},
\oauthor{\bsnm{Jebramcik}, \binits{M.A.}},
\oauthor{\bsnm{Jenninger}, \binits{B.}},
\oauthor{\bsnm{Jensen}, \binits{E.}},
\oauthor{\bsnm{Jones}, \binits{M.}},
\oauthor{\bsnm{Jones}, \binits{R.}},
\oauthor{\bsnm{Jones}, \binits{T.}},
\oauthor{\bsnm{Jowett}, \binits{J.}},
\oauthor{\bsnm{Juchno}, \binits{M.}},
\oauthor{\bsnm{Julie}, \binits{C.}},
\oauthor{\bsnm{Junginger}, \binits{T.}},
\oauthor{\bsnm{Kain}, \binits{V.}},
\oauthor{\bsnm{Kaltchev}, \binits{D.}},
\oauthor{\bsnm{Karastathis}, \binits{N.}},
\oauthor{\bsnm{Kardasopoulos}, \binits{P.}},
\oauthor{\bsnm{Karppinen}, \binits{M.}},
\oauthor{\bsnm{Keintzel}, \binits{J.}},
\oauthor{\bsnm{Kersevan}, \binits{R.}},
\oauthor{\bsnm{Killing}, \binits{F.}},
\oauthor{\bsnm{Kirby}, \binits{G.}},
\oauthor{\bsnm{Korostelev}, \binits{M.}},
\oauthor{\bsnm{Kos}, \binits{N.}},
\oauthor{\bsnm{Kostoglou}, \binits{S.}},
\oauthor{\bsnm{Kozsar}, \binits{I.}},
\oauthor{\bsnm{Krasnov}, \binits{A.}},
\oauthor{\bsnm{Krave}, \binits{S.}},
\oauthor{\bsnm{Krzempek}, \binits{L.}},
\oauthor{\bsnm{Kuder}, \binits{N.}},
\oauthor{\bsnm{Kurtulus}, \binits{A.}},
\oauthor{\bsnm{{Kwee-Hinzmann}}, \binits{R.}},
\oauthor{\bsnm{Lackner}, \binits{F.}},
\oauthor{\bsnm{Lamont}, \binits{M.}},
\oauthor{\bsnm{Lamure}, \binits{A.L.}},
\oauthor{\bsnm{{m}}, \binits{L.L.}},
\oauthor{\bsnm{Lazzaroni}, \binits{M.}},
\oauthor{\bsnm{Le~Garrec}, \binits{M.}},
\oauthor{\bsnm{Lechner}, \binits{A.}},
\oauthor{\bsnm{Lefevre}, \binits{T.}},
\oauthor{\bsnm{Leuxe}, \binits{R.}},
\oauthor{\bsnm{Li}, \binits{K.}},
\oauthor{\bsnm{Li}, \binits{Z.}},
\oauthor{\bsnm{Lindner}, \binits{R.}},
\oauthor{\bsnm{Lindstrom}, \binits{B.}},
\oauthor{\bsnm{Lingwood}, \binits{C.}},
\oauthor{\bsnm{L{\"o}ffler}, \binits{C.}},
\oauthor{\bsnm{Lopez}, \binits{C.}},
\oauthor{\bsnm{{Lopez-Hernandez}}, \binits{{\relax LA}.}},
\oauthor{\bsnm{Losito}, \binits{R.}},
\oauthor{\bsnm{Maciariello}, \binits{F.}},
\oauthor{\bsnm{Macintosh}, \binits{P.}},
\oauthor{\bsnm{Maclean}, \binits{E.H.}},
\oauthor{\bsnm{Macpherson}, \binits{A.}},
\oauthor{\bsnm{Maesen}, \binits{P.}},
\oauthor{\bsnm{Magnier}, \binits{C.}},
\oauthor{\bsnm{Durand}, \binits{H.M.}},
\oauthor{\bsnm{Malina}, \binits{L.}},
\oauthor{\bsnm{Manfredi}, \binits{M.}},
\oauthor{\bsnm{Marcellini}, \binits{F.}},
\oauthor{\bsnm{Marchevsky}, \binits{M.}},
\oauthor{\bsnm{Maridor}, \binits{S.}},
\oauthor{\bsnm{Marinaro}, \binits{G.}},
\oauthor{\bsnm{Marinov}, \binits{K.}},
\oauthor{\bsnm{Markiewicz}, \binits{T.}},
\oauthor{\bsnm{Marsili}, \binits{A.}},
\oauthor{\bsnm{Martinez~Urioz}, \binits{P.}},
\oauthor{\bsnm{Martino}, \binits{M.}},
\oauthor{\bsnm{Masi}, \binits{A.}},
\oauthor{\bsnm{Mastoridis}, \binits{T.}},
\oauthor{\bsnm{Mattelaer}, \binits{P.}},
\oauthor{\bsnm{May}, \binits{A.}},
\oauthor{\bsnm{Mazet}, \binits{J.}},
\oauthor{\bsnm{Mcilwraith}, \binits{S.}},
\oauthor{\bsnm{McIntosh}, \binits{E.}},
\oauthor{\bsnm{Medina~Medrano}, \binits{L.}},
\oauthor{\bsnm{Mejica~Rodriguez}, \binits{A.}},
\oauthor{\bsnm{Mendes}, \binits{M.}},
\oauthor{\bsnm{Menendez}, \binits{P.}},
\oauthor{\bsnm{Mensi}, \binits{M.}},
\oauthor{\bsnm{Mereghetti}, \binits{A.}},
\oauthor{\bsnm{Mergelkuhl}, \binits{D.}},
\oauthor{\bsnm{Mertens}, \binits{T.}},
\oauthor{\bsnm{Mether}, \binits{L.}},
\oauthor{\bsnm{M{\'e}tral}, \binits{E.}},
\oauthor{\bsnm{Migliorati}, \binits{M.}},
\oauthor{\bsnm{Milanese}, \binits{A.}},
\oauthor{\bsnm{Minginette}, \binits{P.}},
\oauthor{\bsnm{Missiaen}, \binits{D.}},
\oauthor{\bsnm{Mitsuhashi}, \binits{T.}},
\oauthor{\bsnm{Modena}, \binits{M.}},
\oauthor{\bsnm{Mokhov}, \binits{N.}},
\oauthor{\bsnm{Molson}, \binits{J.}},
\oauthor{\bsnm{Monneret}, \binits{E.}},
\oauthor{\bsnm{Montesinos}, \binits{E.}},
\oauthor{\bsnm{{Moron-Ballester}}, \binits{R.}},
\oauthor{\bsnm{Morrone}, \binits{M.}},
\oauthor{\bsnm{Mostacci}, \binits{A.}},
\oauthor{\bsnm{Mounet}, \binits{N.}},
\oauthor{\bsnm{Moyret}, \binits{P.}},
\oauthor{\bsnm{Muffat}, \binits{P.}},
\oauthor{\bsnm{Muratori}, \binits{B.}},
\oauthor{\bsnm{Muttoni}, \binits{Y.}},
\oauthor{\bsnm{Nakamoto}, \binits{T.}},
\oauthor{\bsnm{{Navarro-Tapia}}, \binits{M.}},
\oauthor{\bsnm{Neupert}, \binits{H.}},
\oauthor{\bsnm{Nevay}, \binits{L.}},
\oauthor{\bsnm{Nicol}, \binits{T.}},
\oauthor{\bsnm{Nilsson}, \binits{E.}},
\oauthor{\bsnm{Ninin}, \binits{P.}},
\oauthor{\bsnm{Nobrega}, \binits{A.}},
\oauthor{\bsnm{Noels}, \binits{C.}},
\oauthor{\bsnm{Nolan}, \binits{E.}},
\oauthor{\bsnm{Nosochkov}, \binits{Y.}},
\oauthor{\bsnm{Nuiry}, \binits{{\relax FX}.}},
\oauthor{\bsnm{Oberli}, \binits{L.}},
\oauthor{\bsnm{Ogitsu}, \binits{T.}},
\oauthor{\bsnm{Ohmi}, \binits{K.}},
\oauthor{\bsnm{R}, \binits{O.}},
\oauthor{\bsnm{Oliveira}, \binits{J.}},
\oauthor{\bsnm{Orlandi}, \binits{{\relax Ph}.}},
\oauthor{\bsnm{Ortega}, \binits{P.}},
\oauthor{\bsnm{Osborne}, \binits{J.}},
\oauthor{\bsnm{Otto}, \binits{T.}},
\oauthor{\bsnm{Palumbo}, \binits{L.}},
\oauthor{\bsnm{Papadopoulou}, \binits{S.}},
\oauthor{\bsnm{Papaphilippou}, \binits{Y.}},
\oauthor{\bsnm{Paraschou}, \binits{K.}},
\oauthor{\bsnm{Parente}, \binits{C.}},
\oauthor{\bsnm{Paret}, \binits{S.}},
\oauthor{\bsnm{Park}, \binits{H.}},
\oauthor{\bsnm{Parma}, \binits{V.}},
\oauthor{\bsnm{Pasquino}, \binits{{\relax Ch}.}},
\oauthor{\bsnm{Patapenka}, \binits{A.}},
\oauthor{\bsnm{Patnaik}, \binits{L.}},
\oauthor{\bsnm{Pattalwar}, \binits{S.}},
\oauthor{\bsnm{Payet}, \binits{J.}},
\oauthor{\bsnm{Pechaud}, \binits{G.}},
\oauthor{\bsnm{Pellegrini}, \binits{D.}},
\oauthor{\bsnm{Pepinster}, \binits{P.}},
\oauthor{\bsnm{Perez}, \binits{J.}},
\oauthor{\bsnm{Espinos}, \binits{J.P.}},
\oauthor{\bsnm{Marcone}, \binits{A.P.}},
\oauthor{\bsnm{Perin}, \binits{A.}},
\oauthor{\bsnm{Perini}, \binits{P.}},
\oauthor{\bsnm{Persson}, \binits{T.H.B.}},
\oauthor{\bsnm{Peterson}, \binits{T.}},
\oauthor{\bsnm{Pieloni}, \binits{T.}},
\oauthor{\bsnm{Pigny}, \binits{G.}},
\oauthor{\bsnm{{Pinheiro de Sousa}}, \binits{J.P.}},
\oauthor{\bsnm{Pirotte}, \binits{O.}},
\oauthor{\bsnm{Plassard}, \binits{F.}},
\oauthor{\bsnm{Pojer}, \binits{M.}},
\oauthor{\bsnm{Pontercorvo}, \binits{L.}},
\oauthor{\bsnm{Poyet}, \binits{A.}},
\oauthor{\bsnm{Prelipcean}, \binits{D.}},
\oauthor{\bsnm{Prin}, \binits{H.}},
\oauthor{\bsnm{Principe}, \binits{R.}},
\oauthor{\bsnm{Pugnat}, \binits{T.}},
\oauthor{\bsnm{Qiang}, \binits{J.}},
\oauthor{\bsnm{Quaranta}, \binits{E.}},
\oauthor{\bsnm{Rafique}, \binits{H.}},
\oauthor{\bsnm{Rakhno}, \binits{I.}},
\oauthor{\bsnm{Duarte}, \binits{D.R.}},
\oauthor{\bsnm{Ratti}, \binits{A.}},
\oauthor{\bsnm{Ravaioli}, \binits{E.}},
\oauthor{\bsnm{Raymond}, \binits{M.}},
\oauthor{\bsnm{Redaelli}, \binits{S.}},
\oauthor{\bsnm{Renaglia}, \binits{T.}},
\oauthor{\bsnm{Ricci}, \binits{D.}},
\oauthor{\bsnm{Riddone}, \binits{G.}},
\oauthor{\bsnm{Rifflet}, \binits{J.}},
\oauthor{\bsnm{Rigutto}, \binits{E.}},
\oauthor{\bsnm{Rijoff}, \binits{T.}},
\oauthor{\bsnm{Rinaldesi}, \binits{R.}},
\oauthor{\bsnm{Riu~Martinez}, \binits{O.}},
\oauthor{\bsnm{Rivkin}, \binits{L.}},
\oauthor{\bsnm{Rodriguez~Mateos}, \binits{F.}},
\oauthor{\bsnm{Roesler}, \binits{S.}},
\oauthor{\bsnm{Romera~Ramirez}, \binits{I.}},
\oauthor{\bsnm{Rossi}, \binits{A.}},
\oauthor{\bsnm{Rossi}, \binits{L.}},
\oauthor{\bsnm{Rude}, \binits{V.}},
\oauthor{\bsnm{Rumolo}, \binits{G.}},
\oauthor{\bsnm{Rutkovksi}, \binits{J.}},
\oauthor{\bsnm{Sabate~Gilarte}, \binits{M.}},
\oauthor{\bsnm{Sabbi}, \binits{G.}},
\oauthor{\bsnm{Sahner}, \binits{T.}},
\oauthor{\bsnm{Salemme}, \binits{R.}},
\oauthor{\bsnm{Salvant}, \binits{B.}},
\oauthor{\bsnm{Galan}, \binits{F.S.}},
\oauthor{\bsnm{Santamaria~Garcia}, \binits{A.}},
\oauthor{\bsnm{Santillana}, \binits{I.}},
\oauthor{\bsnm{Santini}, \binits{C.}},
\oauthor{\bsnm{Santos}, \binits{O.}},
\oauthor{\bsnm{Diaz}, \binits{P.S.}},
\oauthor{\bsnm{Sasaki}, \binits{K.}},
\oauthor{\bsnm{Savary}, \binits{F.}},
\oauthor{\bsnm{Sbrizzi}, \binits{A.}},
\oauthor{\bsnm{Schaumann}, \binits{M.}},
\oauthor{\bsnm{Scheuerlein}, \binits{C.}},
\oauthor{\bsnm{Schmalzle}, \binits{J.}},
\oauthor{\bsnm{Schmickler}, \binits{H.}},
\oauthor{\bsnm{Schmidt}, \binits{R.}},
\oauthor{\bsnm{Schoerling}, \binits{D.}},
\oauthor{\bsnm{Segreti}, \binits{M.}},
\oauthor{\bsnm{Serluca}, \binits{M.}},
\oauthor{\bsnm{Serrano}, \binits{J.}},
\oauthor{\bsnm{Sestak}, \binits{J.}},
\oauthor{\bsnm{Shaposhnikova}, \binits{E.}},
\oauthor{\bsnm{Shatilov}, \binits{D.}},
\oauthor{\bsnm{Siemko}, \binits{A.}},
\oauthor{\bsnm{Sisti}, \binits{M.}},
\oauthor{\bsnm{Sitko}, \binits{M.}},
\oauthor{\bsnm{Skarita}, \binits{J.}},
\oauthor{\bsnm{Skordis}, \binits{E.}},
\oauthor{\bsnm{Skoufaris}, \binits{K.}},
\oauthor{\bsnm{Skripka}, \binits{G.}},
\oauthor{\bsnm{Smekens}, \binits{D.}},
\oauthor{\bsnm{Sobiech}, \binits{Z.}},
\oauthor{\bsnm{Sosin}, \binits{M.}},
\oauthor{\bsnm{Sorbio}, \binits{M.}},
\oauthor{\bsnm{Soubelet}, \binits{F.}},
\oauthor{\bsnm{Spataro}, \binits{B.}},
\oauthor{\bsnm{Spiezia}, \binits{G.}},
\oauthor{\bsnm{Stancari}, \binits{G.}},
\oauthor{\bsnm{Staterao}, \binits{M.}},
\oauthor{\bsnm{Steckert}, \binits{J.}},
\oauthor{\bsnm{Steele}, \binits{G.}},
\oauthor{\bsnm{Sterbini}, \binits{G.}},
\oauthor{\bsnm{Struik}, \binits{M.}},
\oauthor{\bsnm{Sugano}, \binits{M.}},
\oauthor{\bsnm{Szeberenyi}, \binits{A.}},
\oauthor{\bsnm{Taborelli}, \binits{M.}},
\oauthor{\bsnm{Tambasco}, \binits{C.}},
\oauthor{\bsnm{Rego}, \binits{R.T.}},
\oauthor{\bsnm{Tavian}, \binits{L.}},
\oauthor{\bsnm{Teissandier}, \binits{B.}},
\oauthor{\bsnm{Templeton}, \binits{N.}},
\oauthor{\bsnm{Therasse}, \binits{M.}},
\oauthor{\bsnm{Thiesen}, \binits{H.}},
\oauthor{\bsnm{Thomas}, \binits{E.}},
\oauthor{\bsnm{Toader}, \binits{A.}},
\oauthor{\bsnm{Todesco}, \binits{E.}},
\oauthor{\bsnm{Tom{\'a}s}, \binits{R.}},
\oauthor{\bsnm{Toral}, \binits{F.}},
\oauthor{\bsnm{{Torres-Sanchez}}, \binits{R.}},
\oauthor{\bsnm{Trad}, \binits{G.}},
\oauthor{\bsnm{Triantafyllou}, \binits{N.}},
\oauthor{\bsnm{Tropin}, \binits{I.}},
\oauthor{\bsnm{Tsinganis}, \binits{A.}},
\oauthor{\bsnm{Tuckamantel}, \binits{J.}},
\oauthor{\bsnm{Uythoven}, \binits{J.}},
\oauthor{\bsnm{Valishev}, \binits{A.}},
\oauthor{\bsnm{Van Der~Veken}, \binits{F.}},
\oauthor{\bsnm{Van~Weelderen}, \binits{R.}},
\oauthor{\bsnm{Vande~Craen}, \binits{A.}},
\oauthor{\bsnm{Vazquez De~Prada}, \binits{B.}},
\oauthor{\bsnm{Velotti}, \binits{F.}},
\oauthor{\bsnm{Verdu~Andres}, \binits{S.}},
\oauthor{\bsnm{Verweij}, \binits{A.}},
\oauthor{\bsnm{Shetty}, \binits{N.V.}},
\oauthor{\bsnm{Vlachoudis}, \binits{V.}},
\oauthor{\bsnm{Volpini}, \binits{G.}},
\oauthor{\bsnm{Wagner}, \binits{U.}},
\oauthor{\bsnm{Wanderer}, \binits{P.}},
\oauthor{\bsnm{Wang}, \binits{M.}},
\oauthor{\bsnm{Wang}, \binits{X.}},
\oauthor{\bsnm{Wanzenberg}, \binits{R.}},
\oauthor{\bsnm{Wegscheider}, \binits{A.}},
\oauthor{\bsnm{Weisz}, \binits{S.}},
\oauthor{\bsnm{Welsch}, \binits{C.}},
\oauthor{\bsnm{Wendt}, \binits{M.}},
\oauthor{\bsnm{Wenninger}, \binits{J.}},
\oauthor{\bsnm{Weterings}, \binits{W.}},
\oauthor{\bsnm{White}, \binits{S.}},
\oauthor{\bsnm{Widuch}, \binits{K.}},
\oauthor{\bsnm{Will}, \binits{A.}},
\oauthor{\bsnm{Willering}, \binits{G.}},
\oauthor{\bsnm{Wollmann}, \binits{D.}},
\oauthor{\bsnm{Wolski}, \binits{A.}},
\oauthor{\bsnm{Wozniak}, \binits{J.}},
\oauthor{\bsnm{Wu}, \binits{Q.}},
\oauthor{\bsnm{Xiao}, \binits{B.}},
\oauthor{\bsnm{Xiao}, \binits{L.}},
\oauthor{\bsnm{Xu}, \binits{Q.}},
\oauthor{\bsnm{Yakovlev}, \binits{Y.}},
\oauthor{\bsnm{Yammine}, \binits{S.}},
\oauthor{\bsnm{Yang}, \binits{Y.}},
\oauthor{\bsnm{Yu}, \binits{M.}},
\oauthor{\bsnm{Zacharov}, \binits{I.}},
\oauthor{\bsnm{Zagorodnova}, \binits{O.}},
\oauthor{\bsnm{Zannini}, \binits{C.}},
\oauthor{\bsnm{Zanoni}, \binits{C.}},
\oauthor{\bsnm{Zerlauth}, \binits{M.}},
\oauthor{\bsnm{Zimmermann}, \binits{F.}},
\oauthor{\bsnm{Zlobin}, \binits{A.}},
\oauthor{\bsnm{Zobov}, \binits{M.}},
\oauthor{\bsnm{Zurbano~Fernandez}, \binits{I.}}:
High-{{Luminosity Large Hadron Collider}} ({{HL-LHC}}): {{Technical}} design
  report.
Technical report,
CERN,
Geneva
(2020).
\doiurl{10.23731/CYRM-2020-0010}
\end{botherref}
\endbibitem

%%% 26
\bibitem{Phase2UpgradeCMS2017a}
\begin{botherref}
The {{Phase-2 Upgrade}} of the {{CMS Endcap Calorimeter}}.
CERN,
Geneva
(2017).
\doiurl{10.17181/CERN.IV8M.1JY2}
\end{botherref}
\endbibitem

%%% 27
\bibitem{deselaersVisualSemanticSimilarity2011}
\begin{bchapter}
\bauthor{\bsnm{Deselaers}, \binits{T.}},
\bauthor{\bsnm{Ferrari}, \binits{V.}}:
\bctitle{Visual and semantic similarity in {{ImageNet}}}.
In: \bbtitle{{{CVPR}} 2011},
pp. \bfpage{1777}--\blpage{1784}
(\byear{2011}).
\doiurl{10.1109/CVPR.2011.5995474}
\end{bchapter}
\endbibitem

%%% 28
\bibitem{weiFineGrainedImageAnalysis2022}
\begin{barticle}
\bauthor{\bsnm{Wei}, \binits{X.-S.}},
\bauthor{\bsnm{Song}, \binits{Y.-Z.}},
\bauthor{\bsnm{Aodha}, \binits{O.M.}},
\bauthor{\bsnm{Wu}, \binits{J.}},
\bauthor{\bsnm{Peng}, \binits{Y.}},
\bauthor{\bsnm{Tang}, \binits{J.}},
\bauthor{\bsnm{Yang}, \binits{J.}},
\bauthor{\bsnm{Belongie}, \binits{S.}}:
\batitle{Fine-{{Grained Image Analysis With Deep Learning}}: {{A Survey}}}.
\bjtitle{IEEE Transactions on Pattern Analysis and Machine Intelligence}
\bvolume{44}(\bissue{12}),
\bfpage{8927}--\blpage{8948}
(\byear{2022}).
\doiurl{10.1109/TPAMI.2021.3126648}
\end{barticle}
\endbibitem

%%% 29
\bibitem{zhangSelfAttentionGenerativeAdversarial2019c}
\begin{bchapter}
\bauthor{\bsnm{Zhang}, \binits{H.}},
\bauthor{\bsnm{Goodfellow}, \binits{I.}},
\bauthor{\bsnm{Metaxas}, \binits{D.}},
\bauthor{\bsnm{Odena}, \binits{A.}}:
\bctitle{Self-{{Attention Generative Adversarial Networks}}}.
In: \bbtitle{Proceedings of the 36th {{International Conference}} on {{Machine
  Learning}}},
pp. \bfpage{7354}--\blpage{7363}.
\bpublisher{PMLR},
\blocation{Virtual}
(\byear{2019}).
\burl{https://proceedings.mlr.press/v97/zhang19d.html}
Accessed 2024-04-01
\end{bchapter}
\endbibitem

%%% 30
\bibitem{miyatoCGANsProjectionDiscriminator2018a}
\begin{botherref}
\oauthor{\bsnm{Miyato}, \binits{T.}},
\oauthor{\bsnm{Koyama}, \binits{M.}}:
{{cGANs}} with {{Projection Discriminator}}.
arXiv.
Comment: Published as a conference paper at ICLR 2018
(2018).
\doiurl{10.48550/arXiv.1802.05637}
\end{botherref}
\endbibitem

%%% 31
\bibitem{NEURIPS2020_f490c742}
\begin{bchapter}
\bauthor{\bsnm{Kang}, \binits{M.}},
\bauthor{\bsnm{Park}, \binits{J.}}:
\bctitle{{{ContraGAN}}: {{Contrastive}} learning for conditional image
  generation}.
In: \beditor{\bsnm{Larochelle}, \binits{H.}},
\beditor{\bsnm{Ranzato}, \binits{M.}},
\beditor{\bsnm{Hadsell}, \binits{R.}},
\beditor{\bsnm{Balcan}, \binits{M.F.}},
\beditor{\bsnm{Lin}, \binits{H.}} (eds.)
\bbtitle{Advances in Neural Information Processing Systems},
vol. \bseriesno{33},
pp. \bfpage{21357}--\blpage{21369}.
\bpublisher{Curran Associates, Inc.},
\blocation{Virtual}
(\byear{2020}).
\burl{https://proceedings.neurips.cc/paper_files/paper/2020/file/f490c742cd8318b8ee6dca10af2a163f-Paper.pdf}
\end{bchapter}
\endbibitem

%%% 32
\bibitem{kangRebootingACGANAuxiliary2021a}
\begin{bchapter}
\bauthor{\bsnm{Kang}, \binits{M.}},
\bauthor{\bsnm{Shim}, \binits{W.}},
\bauthor{\bsnm{Cho}, \binits{M.}},
\bauthor{\bsnm{Park}, \binits{J.}}:
\bctitle{Rebooting {{ACGAN}}: {{Auxiliary Classifier GANs}} with {{Stable
  Training}}}.
In: \bbtitle{Advances in {{Neural Information Processing Systems}}},
vol. \bseriesno{34},
pp. \bfpage{23505}--\blpage{23518}.
\bpublisher{Curran Associates, Inc.},
\blocation{Virtual}
(\byear{2021}).
\burl{https://proceedings.neurips.cc/paper_files/paper/2021/hash/c5ab6cebaca97f7171139e4d414ff5a6-Abstract.html}
Accessed 2024-04-01
\end{bchapter}
\endbibitem

%%% 33
\bibitem{rangwaniClassBalancingGAN2021}
\begin{bchapter}
\bauthor{\bsnm{Rangwani}, \binits{H.}},
\bauthor{\bsnm{Mopuri}, \binits{K.R.}},
\bauthor{\bsnm{Babu}, \binits{R.V.}}:
\bctitle{Class balancing {{GAN}} with a classifier in the loop}.
In: \bbtitle{Proceedings of the {{Thirty-Seventh Conference}} on
  {{Uncertainty}} in {{Artificial Intelligence}}},
pp. \bfpage{1618}--\blpage{1627}.
\bpublisher{PMLR},
\blocation{Virtual}
(\byear{2021}).
\burl{https://proceedings.mlr.press/v161/rangwani21a.html}
Accessed 2024-04-01
\end{bchapter}
\endbibitem

%%% 34
\bibitem{caoCouplingLearningComplex2015a}
\begin{barticle}
\bauthor{\bsnm{Cao}, \binits{L.}}:
\batitle{Coupling learning of complex interactions}.
\bjtitle{Information Processing \& Management}
\bvolume{51}(\bissue{2}),
\bfpage{167}--\blpage{186}
(\byear{2015}).
\doiurl{10.1016/j.ipm.2014.08.007}
\end{barticle}
\endbibitem

%%% 35
\bibitem{wangUnderstandingContrastiveRepresentation2020b}
\begin{bchapter}
\bauthor{\bsnm{Wang}, \binits{T.}},
\bauthor{\bsnm{Isola}, \binits{P.}}:
\bctitle{Understanding {{Contrastive Representation Learning}} through
  {{Alignment}} and {{Uniformity}} on the {{Hypersphere}}}.
In: \bbtitle{Proceedings of the 37th {{International Conference}} on {{Machine
  Learning}}},
pp. \bfpage{9929}--\blpage{9939}.
\bpublisher{PMLR},
\blocation{Virtual}
(\byear{2020}).
\burl{https://proceedings.mlr.press/v119/wang20k.html}
Accessed 2024-04-01
\end{bchapter}
\endbibitem

%%% 36
\bibitem{muellerAspectsPixelVertex2014a}
\begin{barticle}
\bauthor{\bsnm{Mueller}, \binits{F.}}:
\batitle{Some aspects of the {{Pixel Vertex Detector}} ({{PXD}}) at {{Belle
  II}}}.
\bjtitle{Journal of Instrumentation}
\bvolume{9}(\bissue{10}),
\bfpage{10007}
(\byear{2014}).
\doiurl{10.1088/1748-0221/9/10/C10007}
\end{barticle}
\endbibitem

%%% 37
\bibitem{abeBelleIITechnical2010d}
\begin{botherref}
\oauthor{\bsnm{Abe}, \binits{T.}},
\oauthor{\bsnm{Adachi}, \binits{I.}},
\oauthor{\bsnm{Adamczyk}, \binits{K.}},
\oauthor{\bsnm{Ahn}, \binits{S.}},
\oauthor{\bsnm{Aihara}, \binits{H.}},
\oauthor{\bsnm{Akai}, \binits{K.}},
\oauthor{\bsnm{Aloi}, \binits{M.}},
\oauthor{\bsnm{Andricek}, \binits{L.}},
\oauthor{\bsnm{Aoki}, \binits{K.}},
\oauthor{\bsnm{Arai}, \binits{Y.}},
\oauthor{\bsnm{Arefiev}, \binits{A.}},
\oauthor{\bsnm{Arinstein}, \binits{K.}},
\oauthor{\bsnm{Arita}, \binits{Y.}},
\oauthor{\bsnm{Asner}, \binits{D.M.}},
\oauthor{\bsnm{Aulchenko}, \binits{V.}},
\oauthor{\bsnm{Aushev}, \binits{T.}},
\oauthor{\bsnm{Aziz}, \binits{T.}},
\oauthor{\bsnm{Bakich}, \binits{A.M.}},
\oauthor{\bsnm{Balagura}, \binits{V.}},
\oauthor{\bsnm{Ban}, \binits{Y.}},
\oauthor{\bsnm{Barberio}, \binits{E.}},
\oauthor{\bsnm{Barvich}, \binits{T.}},
\oauthor{\bsnm{Belous}, \binits{K.}},
\oauthor{\bsnm{Bergauer}, \binits{T.}},
\oauthor{\bsnm{Bhardwaj}, \binits{V.}},
\oauthor{\bsnm{Bhuyan}, \binits{B.}},
\oauthor{\bsnm{Blyth}, \binits{S.}},
\oauthor{\bsnm{Bondar}, \binits{A.}},
\oauthor{\bsnm{Bonvicini}, \binits{G.}},
\oauthor{\bsnm{Bozek}, \binits{A.}},
\oauthor{\bsnm{Bracko}, \binits{M.}},
\oauthor{\bsnm{Brodzicka}, \binits{J.}},
\oauthor{\bsnm{Brovchenko}, \binits{O.}},
\oauthor{\bsnm{Browder}, \binits{T.E.}},
\oauthor{\bsnm{Cao}, \binits{G.}},
\oauthor{\bsnm{Chang}, \binits{M.-C.}},
\oauthor{\bsnm{Chang}, \binits{P.}},
\oauthor{\bsnm{Chao}, \binits{Y.}},
\oauthor{\bsnm{Chekelian}, \binits{V.}},
\oauthor{\bsnm{Chen}, \binits{A.}},
\oauthor{\bsnm{Chen}, \binits{K.-F.}},
\oauthor{\bsnm{Chen}, \binits{P.}},
\oauthor{\bsnm{Cheon}, \binits{B.G.}},
\oauthor{\bsnm{Chiang}, \binits{C.-C.}},
\oauthor{\bsnm{Chistov}, \binits{R.}},
\oauthor{\bsnm{Cho}, \binits{K.}},
\oauthor{\bsnm{Choi}, \binits{S.-K.}},
\oauthor{\bsnm{Chung}, \binits{K.}},
\oauthor{\bsnm{Comerma}, \binits{A.}},
\oauthor{\bsnm{Cooney}, \binits{M.}},
\oauthor{\bsnm{Cowley}, \binits{D.E.}},
\oauthor{\bsnm{Critchlow}, \binits{T.}},
\oauthor{\bsnm{Dalseno}, \binits{J.}},
\oauthor{\bsnm{Danilov}, \binits{M.}},
\oauthor{\bsnm{Dieguez}, \binits{A.}},
\oauthor{\bsnm{Dierlamm}, \binits{A.}},
\oauthor{\bsnm{Dillon}, \binits{M.}},
\oauthor{\bsnm{Dingfelder}, \binits{J.}},
\oauthor{\bsnm{Dolenec}, \binits{R.}},
\oauthor{\bsnm{Dolezal}, \binits{Z.}},
\oauthor{\bsnm{Drasal}, \binits{Z.}},
\oauthor{\bsnm{Drutskoy}, \binits{A.}},
\oauthor{\bsnm{Dungel}, \binits{W.}},
\oauthor{\bsnm{Dutta}, \binits{D.}},
\oauthor{\bsnm{Eidelman}, \binits{S.}},
\oauthor{\bsnm{Enomoto}, \binits{A.}},
\oauthor{\bsnm{Epifanov}, \binits{D.}},
\oauthor{\bsnm{Esen}, \binits{S.}},
\oauthor{\bsnm{Fast}, \binits{J.E.}},
\oauthor{\bsnm{Feindt}, \binits{M.}},
\oauthor{\bsnm{Garcia}, \binits{M.F.}},
\oauthor{\bsnm{Fifield}, \binits{T.}},
\oauthor{\bsnm{Fischer}, \binits{P.}},
\oauthor{\bsnm{Flanagan}, \binits{J.}},
\oauthor{\bsnm{Fourletov}, \binits{S.}},
\oauthor{\bsnm{Fourletova}, \binits{J.}},
\oauthor{\bsnm{Freixas}, \binits{L.}},
\oauthor{\bsnm{Frey}, \binits{A.}},
\oauthor{\bsnm{Friedl}, \binits{M.}},
\oauthor{\bsnm{Fruehwirth}, \binits{R.}},
\oauthor{\bsnm{Fujii}, \binits{H.}},
\oauthor{\bsnm{Fujikawa}, \binits{M.}},
\oauthor{\bsnm{Fukuma}, \binits{Y.}},
\oauthor{\bsnm{Funakoshi}, \binits{Y.}},
\oauthor{\bsnm{Furukawa}, \binits{K.}},
\oauthor{\bsnm{Fuster}, \binits{J.}},
\oauthor{\bsnm{Gabyshev}, \binits{N.}},
\oauthor{\bsnm{Cueto}, \binits{A.G.d.V.}},
\oauthor{\bsnm{Garmash}, \binits{A.}},
\oauthor{\bsnm{Garrido}, \binits{L.}},
\oauthor{\bsnm{Geisler}, \binits{C.}},
\oauthor{\bsnm{Gfall}, \binits{I.}},
\oauthor{\bsnm{Goh}, \binits{Y.M.}},
\oauthor{\bsnm{Golob}, \binits{B.}},
\oauthor{\bsnm{Gorton}, \binits{I.}},
\oauthor{\bsnm{Grzymkowski}, \binits{R.}},
\oauthor{\bsnm{Guo}, \binits{H.}},
\oauthor{\bsnm{Ha}, \binits{H.}},
\oauthor{\bsnm{Haba}, \binits{J.}},
\oauthor{\bsnm{Hara}, \binits{K.}},
\oauthor{\bsnm{Hara}, \binits{T.}},
\oauthor{\bsnm{Haruyama}, \binits{T.}},
\oauthor{\bsnm{Hayasaka}, \binits{K.}},
\oauthor{\bsnm{Hayashi}, \binits{K.}},
\oauthor{\bsnm{Hayashii}, \binits{H.}},
\oauthor{\bsnm{Heck}, \binits{M.}},
\oauthor{\bsnm{Heindl}, \binits{S.}},
\oauthor{\bsnm{Heller}, \binits{C.}},
\oauthor{\bsnm{Hemperek}, \binits{T.}},
\oauthor{\bsnm{Higuchi}, \binits{T.}},
\oauthor{\bsnm{Horii}, \binits{Y.}},
\oauthor{\bsnm{Hou}, \binits{W.-S.}},
\oauthor{\bsnm{Hsiung}, \binits{Y.B.}},
\oauthor{\bsnm{Huang}, \binits{C.-H.}},
\oauthor{\bsnm{Hwang}, \binits{S.}},
\oauthor{\bsnm{Hyun}, \binits{H.J.}},
\oauthor{\bsnm{Igarashi}, \binits{Y.}},
\oauthor{\bsnm{Iglesias}, \binits{C.}},
\oauthor{\bsnm{Iida}, \binits{Y.}},
\oauthor{\bsnm{Iijima}, \binits{T.}},
\oauthor{\bsnm{Imamura}, \binits{M.}},
\oauthor{\bsnm{Inami}, \binits{K.}},
\oauthor{\bsnm{Irmler}, \binits{C.}},
\oauthor{\bsnm{Ishizuka}, \binits{M.}},
\oauthor{\bsnm{Itagaki}, \binits{K.}},
\oauthor{\bsnm{Itoh}, \binits{R.}},
\oauthor{\bsnm{Iwabuchi}, \binits{M.}},
\oauthor{\bsnm{Iwai}, \binits{G.}},
\oauthor{\bsnm{Iwai}, \binits{M.}},
\oauthor{\bsnm{Iwasaki}, \binits{M.}},
\oauthor{\bsnm{Iwasaki}, \binits{M.}},
\oauthor{\bsnm{Iwasaki}, \binits{Y.}},
\oauthor{\bsnm{Iwashita}, \binits{T.}},
\oauthor{\bsnm{Iwata}, \binits{S.}},
\oauthor{\bsnm{Jang}, \binits{H.}},
\oauthor{\bsnm{Ji}, \binits{X.}},
\oauthor{\bsnm{Jinno}, \binits{T.}},
\oauthor{\bsnm{Jones}, \binits{M.}},
\oauthor{\bsnm{Julius}, \binits{T.}},
\oauthor{\bsnm{Kageyama}, \binits{T.}},
\oauthor{\bsnm{Kah}, \binits{D.H.}},
\oauthor{\bsnm{Kakuno}, \binits{H.}},
\oauthor{\bsnm{Kamitani}, \binits{T.}},
\oauthor{\bsnm{Kanazawa}, \binits{K.}},
\oauthor{\bsnm{Kapusta}, \binits{P.}},
\oauthor{\bsnm{Kataoka}, \binits{S.U.}},
\oauthor{\bsnm{Katayama}, \binits{N.}},
\oauthor{\bsnm{Kawai}, \binits{M.}},
\oauthor{\bsnm{Kawai}, \binits{Y.}},
\oauthor{\bsnm{Kawasaki}, \binits{T.}},
\oauthor{\bsnm{Kennedy}, \binits{J.}},
\oauthor{\bsnm{Kichimi}, \binits{H.}},
\oauthor{\bsnm{Kikuchi}, \binits{M.}},
\oauthor{\bsnm{Kiesling}, \binits{C.}},
\oauthor{\bsnm{Kim}, \binits{B.K.}},
\oauthor{\bsnm{Kim}, \binits{G.N.}},
\oauthor{\bsnm{Kim}, \binits{H.J.}},
\oauthor{\bsnm{Kim}, \binits{H.O.}},
\oauthor{\bsnm{Kim}, \binits{J.-B.}},
\oauthor{\bsnm{Kim}, \binits{J.H.}},
\oauthor{\bsnm{Kim}, \binits{M.J.}},
\oauthor{\bsnm{Kim}, \binits{S.K.}},
\oauthor{\bsnm{Kim}, \binits{K.T.}},
\oauthor{\bsnm{Kim}, \binits{T.Y.}},
\oauthor{\bsnm{Kinoshita}, \binits{K.}},
\oauthor{\bsnm{Kishi}, \binits{K.}},
\oauthor{\bsnm{Kisielewski}, \binits{B.}},
\oauthor{\bsnm{{van Dam}}, \binits{K.K.}},
\oauthor{\bsnm{Knopf}, \binits{J.}},
\oauthor{\bsnm{Ko}, \binits{B.R.}},
\oauthor{\bsnm{Koch}, \binits{M.}},
\oauthor{\bsnm{Kodys}, \binits{P.}},
\oauthor{\bsnm{Koffmane}, \binits{C.}},
\oauthor{\bsnm{Koga}, \binits{Y.}},
\oauthor{\bsnm{Kohriki}, \binits{T.}},
\oauthor{\bsnm{Koike}, \binits{S.}},
\oauthor{\bsnm{Koiso}, \binits{H.}},
\oauthor{\bsnm{Kondo}, \binits{Y.}},
\oauthor{\bsnm{Korpar}, \binits{S.}},
\oauthor{\bsnm{Kouzes}, \binits{R.T.}},
\oauthor{\bsnm{Kreidl}, \binits{C.}},
\oauthor{\bsnm{Kreps}, \binits{M.}},
\oauthor{\bsnm{Krizan}, \binits{P.}},
\oauthor{\bsnm{Krokovny}, \binits{P.}},
\oauthor{\bsnm{Krueger}, \binits{H.}},
\oauthor{\bsnm{Kruth}, \binits{A.}},
\oauthor{\bsnm{Kuhn}, \binits{W.}},
\oauthor{\bsnm{Kuhr}, \binits{T.}},
\oauthor{\bsnm{Kumar}, \binits{R.}},
\oauthor{\bsnm{Kumita}, \binits{T.}},
\oauthor{\bsnm{Kupper}, \binits{S.}},
\oauthor{\bsnm{Kuzmin}, \binits{A.}},
\oauthor{\bsnm{Kvasnicka}, \binits{P.}},
\oauthor{\bsnm{Kwon}, \binits{Y.-J.}},
\oauthor{\bsnm{Lacasta}, \binits{C.}},
\oauthor{\bsnm{Lange}, \binits{J.S.}},
\oauthor{\bsnm{Lee}, \binits{I.-S.}},
\oauthor{\bsnm{Lee}, \binits{M.J.}},
\oauthor{\bsnm{Lee}, \binits{M.W.}},
\oauthor{\bsnm{Lee}, \binits{S.-H.}},
\oauthor{\bsnm{Lemarenko}, \binits{M.}},
\oauthor{\bsnm{Li}, \binits{J.}},
\oauthor{\bsnm{Li}, \binits{W.D.}},
\oauthor{\bsnm{Li}, \binits{Y.}},
\oauthor{\bsnm{Libby}, \binits{J.}},
\oauthor{\bsnm{Limosani}, \binits{A.}},
\oauthor{\bsnm{Liu}, \binits{C.}},
\oauthor{\bsnm{Liu}, \binits{H.}},
\oauthor{\bsnm{Liu}, \binits{Y.}},
\oauthor{\bsnm{Liu}, \binits{Z.}},
\oauthor{\bsnm{Liventsev}, \binits{D.}},
\oauthor{\bsnm{Virto}, \binits{A.L.}},
\oauthor{\bsnm{Makida}, \binits{Y.}},
\oauthor{\bsnm{Mao}, \binits{Z.P.}},
\oauthor{\bsnm{Marinas}, \binits{C.}},
\oauthor{\bsnm{Masuzawa}, \binits{M.}},
\oauthor{\bsnm{Matvienko}, \binits{D.}},
\oauthor{\bsnm{Mitaroff}, \binits{W.}},
\oauthor{\bsnm{Miyabayashi}, \binits{K.}},
\oauthor{\bsnm{Miyata}, \binits{H.}},
\oauthor{\bsnm{Miyazaki}, \binits{Y.}},
\oauthor{\bsnm{Miyoshi}, \binits{T.}},
\oauthor{\bsnm{Mizuk}, \binits{R.}},
\oauthor{\bsnm{Mohanty}, \binits{G.B.}},
\oauthor{\bsnm{Mohapatra}, \binits{D.}},
\oauthor{\bsnm{Moll}, \binits{A.}},
\oauthor{\bsnm{Mori}, \binits{T.}},
\oauthor{\bsnm{Morita}, \binits{A.}},
\oauthor{\bsnm{Morita}, \binits{Y.}},
\oauthor{\bsnm{Moser}, \binits{H.-G.}},
\oauthor{\bsnm{Martin}, \binits{D.M.}},
\oauthor{\bsnm{Mueller}, \binits{T.}},
\oauthor{\bsnm{Muenchow}, \binits{D.}},
\oauthor{\bsnm{Murakami}, \binits{J.}},
\oauthor{\bsnm{Myung}, \binits{S.S.}},
\oauthor{\bsnm{Nagamine}, \binits{T.}},
\oauthor{\bsnm{Nakamura}, \binits{I.}},
\oauthor{\bsnm{Nakamura}, \binits{T.T.}},
\oauthor{\bsnm{Nakano}, \binits{E.}},
\oauthor{\bsnm{Nakano}, \binits{H.}},
\oauthor{\bsnm{Nakao}, \binits{M.}},
\oauthor{\bsnm{Nakazawa}, \binits{H.}},
\oauthor{\bsnm{Nam}, \binits{S.-H.}},
\oauthor{\bsnm{Natkaniec}, \binits{Z.}},
\oauthor{\bsnm{Nedelkovska}, \binits{E.}},
\oauthor{\bsnm{Negishi}, \binits{K.}},
\oauthor{\bsnm{Neubauer}, \binits{S.}},
\oauthor{\bsnm{Ng}, \binits{C.}},
\oauthor{\bsnm{Ninkovic}, \binits{J.}},
\oauthor{\bsnm{Nishida}, \binits{S.}},
\oauthor{\bsnm{Nishimura}, \binits{K.}},
\oauthor{\bsnm{Novikov}, \binits{E.}},
\oauthor{\bsnm{Nozaki}, \binits{T.}},
\oauthor{\bsnm{Ogawa}, \binits{S.}},
\oauthor{\bsnm{Ohmi}, \binits{K.}},
\oauthor{\bsnm{Ohnishi}, \binits{Y.}},
\oauthor{\bsnm{Ohshima}, \binits{T.}},
\oauthor{\bsnm{Ohuchi}, \binits{N.}},
\oauthor{\bsnm{Oide}, \binits{K.}},
\oauthor{\bsnm{Olsen}, \binits{S.L.}},
\oauthor{\bsnm{Ono}, \binits{M.}},
\oauthor{\bsnm{Ono}, \binits{Y.}},
\oauthor{\bsnm{Onuki}, \binits{Y.}},
\oauthor{\bsnm{Ostrowicz}, \binits{W.}},
\oauthor{\bsnm{Ozaki}, \binits{H.}},
\oauthor{\bsnm{Pakhlov}, \binits{P.}},
\oauthor{\bsnm{Pakhlova}, \binits{G.}},
\oauthor{\bsnm{Palka}, \binits{H.}},
\oauthor{\bsnm{Park}, \binits{H.}},
\oauthor{\bsnm{Park}, \binits{H.K.}},
\oauthor{\bsnm{Peak}, \binits{L.S.}},
\oauthor{\bsnm{Peng}, \binits{T.}},
\oauthor{\bsnm{Peric}, \binits{I.}},
\oauthor{\bsnm{Pernicka}, \binits{M.}},
\oauthor{\bsnm{Pestotnik}, \binits{R.}},
\oauthor{\bsnm{Petric}, \binits{M.}},
\oauthor{\bsnm{Piilonen}, \binits{L.E.}},
\oauthor{\bsnm{Poluektov}, \binits{A.}},
\oauthor{\bsnm{Prim}, \binits{M.}},
\oauthor{\bsnm{Prothmann}, \binits{K.}},
\oauthor{\bsnm{Regimbal}, \binits{K.}},
\oauthor{\bsnm{Reisert}, \binits{B.}},
\oauthor{\bsnm{Richter}, \binits{R.H.}},
\oauthor{\bsnm{{Riera-Babures}}, \binits{J.}},
\oauthor{\bsnm{Ritter}, \binits{A.}},
\oauthor{\bsnm{Ritter}, \binits{A.}},
\oauthor{\bsnm{Ritter}, \binits{M.}},
\oauthor{\bsnm{Roehrken}, \binits{M.}},
\oauthor{\bsnm{Rorie}, \binits{J.}},
\oauthor{\bsnm{Rosen}, \binits{M.}},
\oauthor{\bsnm{Rozanska}, \binits{M.}},
\oauthor{\bsnm{Ruckman}, \binits{L.}},
\oauthor{\bsnm{Rummel}, \binits{S.}},
\oauthor{\bsnm{Rusinov}, \binits{V.}},
\oauthor{\bsnm{Russell}, \binits{R.M.}},
\oauthor{\bsnm{Ryu}, \binits{S.}},
\oauthor{\bsnm{Sahoo}, \binits{H.}},
\oauthor{\bsnm{Sakai}, \binits{K.}},
\oauthor{\bsnm{Sakai}, \binits{Y.}},
\oauthor{\bsnm{Santelj}, \binits{L.}},
\oauthor{\bsnm{Sasaki}, \binits{T.}},
\oauthor{\bsnm{Sato}, \binits{N.}},
\oauthor{\bsnm{Sato}, \binits{Y.}},
\oauthor{\bsnm{Scheirich}, \binits{J.}},
\oauthor{\bsnm{Schieck}, \binits{J.}},
\oauthor{\bsnm{Schwanda}, \binits{C.}},
\oauthor{\bsnm{Schwartz}, \binits{A.J.}},
\oauthor{\bsnm{Schwenker}, \binits{B.}},
\oauthor{\bsnm{Seljak}, \binits{A.}},
\oauthor{\bsnm{Senyo}, \binits{K.}},
\oauthor{\bsnm{Seon}, \binits{O.-S.}},
\oauthor{\bsnm{Sevior}, \binits{M.E.}},
\oauthor{\bsnm{Shapkin}, \binits{M.}},
\oauthor{\bsnm{Shebalin}, \binits{V.}},
\oauthor{\bsnm{Shen}, \binits{C.P.}},
\oauthor{\bsnm{Shibuya}, \binits{H.}},
\oauthor{\bsnm{Shiizuka}, \binits{S.}},
\oauthor{\bsnm{Shiu}, \binits{J.-G.}},
\oauthor{\bsnm{Shwartz}, \binits{B.}},
\oauthor{\bsnm{Simon}, \binits{F.}},
\oauthor{\bsnm{Simonis}, \binits{H.J.}},
\oauthor{\bsnm{Singh}, \binits{J.B.}},
\oauthor{\bsnm{Sinha}, \binits{R.}},
\oauthor{\bsnm{Sitarz}, \binits{M.}},
\oauthor{\bsnm{Smerkol}, \binits{P.}},
\oauthor{\bsnm{Sokolov}, \binits{A.}},
\oauthor{\bsnm{Solovieva}, \binits{E.}},
\oauthor{\bsnm{Stanic}, \binits{S.}},
\oauthor{\bsnm{Staric}, \binits{M.}},
\oauthor{\bsnm{Stypula}, \binits{J.}},
\oauthor{\bsnm{Suetsugu}, \binits{Y.}},
\oauthor{\bsnm{Sugihara}, \binits{S.}},
\oauthor{\bsnm{Sugimura}, \binits{T.}},
\oauthor{\bsnm{Sumisawa}, \binits{K.}},
\oauthor{\bsnm{Sumiyoshi}, \binits{T.}},
\oauthor{\bsnm{Suzuki}, \binits{K.}},
\oauthor{\bsnm{Suzuki}, \binits{S.Y.}},
\oauthor{\bsnm{Takagaki}, \binits{H.}},
\oauthor{\bsnm{Takasaki}, \binits{F.}},
\oauthor{\bsnm{Takeichi}, \binits{H.}},
\oauthor{\bsnm{Takubo}, \binits{Y.}},
\oauthor{\bsnm{Tanaka}, \binits{M.}},
\oauthor{\bsnm{Tanaka}, \binits{S.}},
\oauthor{\bsnm{Taniguchi}, \binits{N.}},
\oauthor{\bsnm{Tarkovsky}, \binits{E.}},
\oauthor{\bsnm{Tatishvili}, \binits{G.}},
\oauthor{\bsnm{Tawada}, \binits{M.}},
\oauthor{\bsnm{Taylor}, \binits{G.N.}},
\oauthor{\bsnm{Teramoto}, \binits{Y.}},
\oauthor{\bsnm{Tikhomirov}, \binits{I.}},
\oauthor{\bsnm{Trabelsi}, \binits{K.}},
\oauthor{\bsnm{Tsuboyama}, \binits{T.}},
\oauthor{\bsnm{Tsunada}, \binits{K.}},
\oauthor{\bsnm{Tu}, \binits{Y.-C.}},
\oauthor{\bsnm{Uchida}, \binits{T.}},
\oauthor{\bsnm{Uehara}, \binits{S.}},
\oauthor{\bsnm{Ueno}, \binits{K.}},
\oauthor{\bsnm{Uglov}, \binits{T.}},
\oauthor{\bsnm{Unno}, \binits{Y.}},
\oauthor{\bsnm{Uno}, \binits{S.}},
\oauthor{\bsnm{Urquijo}, \binits{P.}},
\oauthor{\bsnm{Ushiroda}, \binits{Y.}},
\oauthor{\bsnm{Usov}, \binits{Y.}},
\oauthor{\bsnm{Vahsen}, \binits{S.}},
\oauthor{\bsnm{Valentan}, \binits{M.}},
\oauthor{\bsnm{Vanhoefer}, \binits{P.}},
\oauthor{\bsnm{Varner}, \binits{G.}},
\oauthor{\bsnm{Varvell}, \binits{K.E.}},
\oauthor{\bsnm{Vazquez}, \binits{P.}},
\oauthor{\bsnm{Vila}, \binits{I.}},
\oauthor{\bsnm{Vilella}, \binits{E.}},
\oauthor{\bsnm{Vinokurova}, \binits{A.}},
\oauthor{\bsnm{Visniakov}, \binits{J.}},
\oauthor{\bsnm{Vos}, \binits{M.}},
\oauthor{\bsnm{Wang}, \binits{C.H.}},
\oauthor{\bsnm{Wang}, \binits{J.}},
\oauthor{\bsnm{Wang}, \binits{M.-Z.}},
\oauthor{\bsnm{Wang}, \binits{P.}},
\oauthor{\bsnm{Wassatch}, \binits{A.}},
\oauthor{\bsnm{Watanabe}, \binits{M.}},
\oauthor{\bsnm{Watase}, \binits{Y.}},
\oauthor{\bsnm{Weiler}, \binits{T.}},
\oauthor{\bsnm{Wermes}, \binits{N.}},
\oauthor{\bsnm{Wescott}, \binits{R.E.}},
\oauthor{\bsnm{White}, \binits{E.}},
\oauthor{\bsnm{Wicht}, \binits{J.}},
\oauthor{\bsnm{Widhalm}, \binits{L.}},
\oauthor{\bsnm{Williams}, \binits{K.M.}},
\oauthor{\bsnm{Won}, \binits{E.}},
\oauthor{\bsnm{Xu}, \binits{H.}},
\oauthor{\bsnm{Yabsley}, \binits{B.D.}},
\oauthor{\bsnm{Yamamoto}, \binits{H.}},
\oauthor{\bsnm{Yamaoka}, \binits{H.}},
\oauthor{\bsnm{Yamaoka}, \binits{Y.}},
\oauthor{\bsnm{Yamauchi}, \binits{M.}},
\oauthor{\bsnm{Yin}, \binits{Y.}},
\oauthor{\bsnm{Yoon}, \binits{H.}},
\oauthor{\bsnm{Yu}, \binits{J.}},
\oauthor{\bsnm{Yuan}, \binits{C.Z.}},
\oauthor{\bsnm{Yusa}, \binits{Y.}},
\oauthor{\bsnm{Zander}, \binits{D.}},
\oauthor{\bsnm{Zdybal}, \binits{M.}},
\oauthor{\bsnm{Zhang}, \binits{Z.P.}},
\oauthor{\bsnm{Zhao}, \binits{J.}},
\oauthor{\bsnm{Zhao}, \binits{L.}},
\oauthor{\bsnm{Zhao}, \binits{Z.}},
\oauthor{\bsnm{Zhilich}, \binits{V.}},
\oauthor{\bsnm{Zhou}, \binits{P.}},
\oauthor{\bsnm{Zhulanov}, \binits{V.}},
\oauthor{\bsnm{Zivko}, \binits{T.}},
\oauthor{\bsnm{Zupanc}, \binits{A.}},
\oauthor{\bsnm{Zyukova}, \binits{O.}}:
Belle {{II Technical Design Report}}.
arXiv.
Comment: Edited by: Z. Dole{\textbackslash}v\{z\}al and S. Uno
(2010).
\doiurl{10.48550/arXiv.1011.0352}
\end{botherref}
\endbibitem

%%% 38
\bibitem{diefenbacherL2LFlowsGeneratingHighfidelity2023}
\begin{barticle}
\bauthor{\bsnm{Diefenbacher}, \binits{S.}},
\bauthor{\bsnm{Eren}, \binits{E.}},
\bauthor{\bsnm{Gaede}, \binits{F.}},
\bauthor{\bsnm{Kasieczka}, \binits{G.}},
\bauthor{\bsnm{Krause}, \binits{C.}},
\bauthor{\bsnm{Shekhzadeh}, \binits{I.}},
\bauthor{\bsnm{Shih}, \binits{D.}}:
\batitle{{{L2LFlows}}: Generating high-fidelity {{3D}} calorimeter images}.
\bjtitle{Journal of Instrumentation}
\bvolume{18}(\bissue{10}),
\bfpage{10017}
(\byear{2023}).
\doiurl{10.1088/1748-0221/18/10/P10017}
\end{barticle}
\endbibitem

%%% 39
\bibitem{kimSimulationLibraryBelle2017}
\begin{barticle}
\bauthor{\bsnm{Kim}, \binits{D.Y.}},
\bauthor{\bsnm{Ritter}, \binits{M.}},
\bauthor{\bsnm{Bilka}, \binits{T.}},
\bauthor{\bsnm{Bobrov}, \binits{A.}},
\bauthor{\bsnm{Casarosa}, \binits{G.}},
\bauthor{\bsnm{Chilikin}, \binits{K.}},
\bauthor{\bsnm{Ferber}, \binits{T.}},
\bauthor{\bsnm{Godang}, \binits{R.}},
\bauthor{\bsnm{Jaegle}, \binits{I.}},
\bauthor{\bsnm{Kandra}, \binits{J.}},
\bauthor{\bsnm{Kodys}, \binits{P.}},
\bauthor{\bsnm{Kuhr}, \binits{T.}},
\bauthor{\bsnm{Kvasnicka}, \binits{P.}},
\bauthor{\bsnm{Nakayama}, \binits{H.}},
\bauthor{\bsnm{Piilonen}, \binits{L.}},
\bauthor{\bsnm{Pulvermacher}, \binits{C.}},
\bauthor{\bsnm{Santelj}, \binits{L.}},
\bauthor{\bsnm{Schwenker}, \binits{B.}},
\bauthor{\bsnm{Sibidanov}, \binits{A.}},
\bauthor{\bsnm{Soloviev}, \binits{Y.}},
\bauthor{\bsnm{Stari{\v c}}, \binits{M.}},
\bauthor{\bsnm{Uglov}, \binits{T.}}:
\batitle{The simulation library of the {{Belle II}} software system}.
\bjtitle{Journal of Physics: Conference Series}
\bvolume{898}(\bissue{4}),
\bfpage{042043}
(\byear{2017}).
\doiurl{10.1088/1742-6596/898/4/042043}
\end{barticle}
\endbibitem

%%% 40
\bibitem{kuhrComputingBelleII2011a}
\begin{barticle}
\bauthor{\bsnm{Kuhr}, \binits{T.}}:
\batitle{Computing at {{Belle II}}}.
\bjtitle{Journal of Physics: Conference Series}
\bvolume{331}(\bissue{7}),
\bfpage{072021}
(\byear{2011}).
\doiurl{10.1088/1742-6596/331/7/072021}
\end{barticle}
\endbibitem

\bibitem{belle2KEK}
\begin{botherref}
\oauthor{\bsnm{Belle II / KEK}}:
\texttt{https://www.belle2.org/archives/} with the copyright: (C) Belle II / KEK.
(\byear{2024}).
\end{botherref}
\endbibitem


%%% 41
\bibitem{agostinelliGeant4SimulationToolkit2003a}
\begin{barticle}
\bauthor{\bsnm{Agostinelli}, \binits{S.}},
\bauthor{\bsnm{Allison}, \binits{J.}},
\bauthor{\bsnm{Amako}, \binits{K.}},
\bauthor{\bsnm{Apostolakis}, \binits{J.}},
\bauthor{\bsnm{Araujo}, \binits{H.}},
\bauthor{\bsnm{Arce}, \binits{P.}},
\bauthor{\bsnm{Asai}, \binits{M.}},
\bauthor{\bsnm{Axen}, \binits{D.}},
\bauthor{\bsnm{Banerjee}, \binits{S.}},
\bauthor{\bsnm{Barrand}, \binits{G.}},
\bauthor{\bsnm{Behner}, \binits{F.}},
\bauthor{\bsnm{Bellagamba}, \binits{L.}},
\bauthor{\bsnm{Boudreau}, \binits{J.}},
\bauthor{\bsnm{Broglia}, \binits{L.}},
\bauthor{\bsnm{Brunengo}, \binits{A.}},
\bauthor{\bsnm{Burkhardt}, \binits{H.}},
\bauthor{\bsnm{Chauvie}, \binits{S.}},
\bauthor{\bsnm{Chuma}, \binits{J.}},
\bauthor{\bsnm{Chytracek}, \binits{R.}},
\bauthor{\bsnm{Cooperman}, \binits{G.}},
\bauthor{\bsnm{Cosmo}, \binits{G.}},
\bauthor{\bsnm{Degtyarenko}, \binits{P.}},
\bauthor{\bsnm{Dell'Acqua}, \binits{A.}},
\bauthor{\bsnm{Depaola}, \binits{G.}},
\bauthor{\bsnm{Dietrich}, \binits{D.}},
\bauthor{\bsnm{Enami}, \binits{R.}},
\bauthor{\bsnm{Feliciello}, \binits{A.}},
\bauthor{\bsnm{Ferguson}, \binits{C.}},
\bauthor{\bsnm{Fesefeldt}, \binits{H.}},
\bauthor{\bsnm{Folger}, \binits{G.}},
\bauthor{\bsnm{Foppiano}, \binits{F.}},
\bauthor{\bsnm{Forti}, \binits{A.}},
\bauthor{\bsnm{Garelli}, \binits{S.}},
\bauthor{\bsnm{Giani}, \binits{S.}},
\bauthor{\bsnm{Giannitrapani}, \binits{R.}},
\bauthor{\bsnm{Gibin}, \binits{D.}},
\bauthor{\bsnm{G{\'o}mez~Cadenas}, \binits{J.J.}},
\bauthor{\bsnm{Gonz{\'a}lez}, \binits{I.}},
\bauthor{\bsnm{Gracia~Abril}, \binits{G.}},
\bauthor{\bsnm{Greeniaus}, \binits{G.}},
\bauthor{\bsnm{Greiner}, \binits{W.}},
\bauthor{\bsnm{Grichine}, \binits{V.}},
\bauthor{\bsnm{Grossheim}, \binits{A.}},
\bauthor{\bsnm{Guatelli}, \binits{S.}},
\bauthor{\bsnm{Gumplinger}, \binits{P.}},
\bauthor{\bsnm{Hamatsu}, \binits{R.}},
\bauthor{\bsnm{Hashimoto}, \binits{K.}},
\bauthor{\bsnm{Hasui}, \binits{H.}},
\bauthor{\bsnm{Heikkinen}, \binits{A.}},
\bauthor{\bsnm{Howard}, \binits{A.}},
\bauthor{\bsnm{Ivanchenko}, \binits{V.}},
\bauthor{\bsnm{Johnson}, \binits{A.}},
\bauthor{\bsnm{Jones}, \binits{F.W.}},
\bauthor{\bsnm{Kallenbach}, \binits{J.}},
\bauthor{\bsnm{Kanaya}, \binits{N.}},
\bauthor{\bsnm{Kawabata}, \binits{M.}},
\bauthor{\bsnm{Kawabata}, \binits{Y.}},
\bauthor{\bsnm{Kawaguti}, \binits{M.}},
\bauthor{\bsnm{Kelner}, \binits{S.}},
\bauthor{\bsnm{Kent}, \binits{P.}},
\bauthor{\bsnm{Kimura}, \binits{A.}},
\bauthor{\bsnm{Kodama}, \binits{T.}},
\bauthor{\bsnm{Kokoulin}, \binits{R.}},
\bauthor{\bsnm{Kossov}, \binits{M.}},
\bauthor{\bsnm{Kurashige}, \binits{H.}},
\bauthor{\bsnm{Lamanna}, \binits{E.}},
\bauthor{\bsnm{Lamp{\'e}n}, \binits{T.}},
\bauthor{\bsnm{Lara}, \binits{V.}},
\bauthor{\bsnm{Lefebure}, \binits{V.}},
\bauthor{\bsnm{Lei}, \binits{F.}},
\bauthor{\bsnm{Liendl}, \binits{M.}},
\bauthor{\bsnm{Lockman}, \binits{W.}},
\bauthor{\bsnm{Longo}, \binits{F.}},
\bauthor{\bsnm{Magni}, \binits{S.}},
\bauthor{\bsnm{Maire}, \binits{M.}},
\bauthor{\bsnm{Medernach}, \binits{E.}},
\bauthor{\bsnm{Minamimoto}, \binits{K.}},
\bauthor{\bsnm{{Mora de Freitas}}, \binits{P.}},
\bauthor{\bsnm{Morita}, \binits{Y.}},
\bauthor{\bsnm{Murakami}, \binits{K.}},
\bauthor{\bsnm{Nagamatu}, \binits{M.}},
\bauthor{\bsnm{Nartallo}, \binits{R.}},
\bauthor{\bsnm{Nieminen}, \binits{P.}},
\bauthor{\bsnm{Nishimura}, \binits{T.}},
\bauthor{\bsnm{Ohtsubo}, \binits{K.}},
\bauthor{\bsnm{Okamura}, \binits{M.}},
\bauthor{\bsnm{O'Neale}, \binits{S.}},
\bauthor{\bsnm{Oohata}, \binits{Y.}},
\bauthor{\bsnm{Paech}, \binits{K.}},
\bauthor{\bsnm{Perl}, \binits{J.}},
\bauthor{\bsnm{Pfeiffer}, \binits{A.}},
\bauthor{\bsnm{Pia}, \binits{M.G.}},
\bauthor{\bsnm{Ranjard}, \binits{F.}},
\bauthor{\bsnm{Rybin}, \binits{A.}},
\bauthor{\bsnm{Sadilov}, \binits{S.}},
\bauthor{\bsnm{Di~Salvo}, \binits{E.}},
\bauthor{\bsnm{Santin}, \binits{G.}},
\bauthor{\bsnm{Sasaki}, \binits{T.}},
\bauthor{\bsnm{Savvas}, \binits{N.}},
\bauthor{\bsnm{Sawada}, \binits{Y.}},
\bauthor{\bsnm{Scherer}, \binits{S.}},
\bauthor{\bsnm{Sei}, \binits{S.}},
\bauthor{\bsnm{Sirotenko}, \binits{V.}},
\bauthor{\bsnm{Smith}, \binits{D.}},
\bauthor{\bsnm{Starkov}, \binits{N.}},
\bauthor{\bsnm{Stoecker}, \binits{H.}},
\bauthor{\bsnm{Sulkimo}, \binits{J.}},
\bauthor{\bsnm{Takahata}, \binits{M.}},
\bauthor{\bsnm{Tanaka}, \binits{S.}},
\bauthor{\bsnm{Tcherniaev}, \binits{E.}},
\bauthor{\bsnm{Safai~Tehrani}, \binits{E.}},
\bauthor{\bsnm{Tropeano}, \binits{M.}},
\bauthor{\bsnm{Truscott}, \binits{P.}},
\bauthor{\bsnm{Uno}, \binits{H.}},
\bauthor{\bsnm{Urban}, \binits{L.}},
\bauthor{\bsnm{Urban}, \binits{P.}},
\bauthor{\bsnm{Verderi}, \binits{M.}},
\bauthor{\bsnm{Walkden}, \binits{A.}},
\bauthor{\bsnm{Wander}, \binits{W.}},
\bauthor{\bsnm{Weber}, \binits{H.}},
\bauthor{\bsnm{Wellisch}, \binits{J.P.}},
\bauthor{\bsnm{Wenaus}, \binits{T.}},
\bauthor{\bsnm{Williams}, \binits{D.C.}},
\bauthor{\bsnm{Wright}, \binits{D.}},
\bauthor{\bsnm{Yamada}, \binits{T.}},
\bauthor{\bsnm{Yoshida}, \binits{H.}},
\bauthor{\bsnm{Zschiesche}, \binits{D.}}:
\batitle{Geant4---a simulation toolkit}.
\bjtitle{Nuclear Instruments and Methods in Physics Research Section A:
  Accelerators, Spectrometers, Detectors and Associated Equipment}
\bvolume{506}(\bissue{3}),
\bfpage{250}--\blpage{303}
(\byear{2003}).
\doiurl{10.1016/S0168-9002(03)01368-8}
\end{barticle}
\endbibitem

%%% 42
\bibitem{nashNonCooperativeGames1951a}
\begin{barticle}
\bauthor{\bsnm{Nash}, \binits{J.}}:
\batitle{Non-{{Cooperative Games}}}.
\bjtitle{Annals of Mathematics}
\bvolume{54}(\bissue{2}),
\bfpage{286}--\blpage{295}
(\byear{1951})
{\href{https://arxiv.org/abs/1969529}{{1969529}}}.
\doiurl{10.2307/1969529}
\end{barticle}
\endbibitem

%%% 43
\bibitem{battagliaRelationalInductiveBiases2018c}
\begin{botherref}
\oauthor{\bsnm{Battaglia}, \binits{P.W.}},
\oauthor{\bsnm{Hamrick}, \binits{J.B.}},
\oauthor{\bsnm{Bapst}, \binits{V.}},
\oauthor{\bsnm{{Sanchez-Gonzalez}}, \binits{A.}},
\oauthor{\bsnm{Zambaldi}, \binits{V.}},
\oauthor{\bsnm{Malinowski}, \binits{M.}},
\oauthor{\bsnm{Tacchetti}, \binits{A.}},
\oauthor{\bsnm{Raposo}, \binits{D.}},
\oauthor{\bsnm{Santoro}, \binits{A.}},
\oauthor{\bsnm{Faulkner}, \binits{R.}},
\oauthor{\bsnm{Gulcehre}, \binits{C.}},
\oauthor{\bsnm{Song}, \binits{F.}},
\oauthor{\bsnm{Ballard}, \binits{A.}},
\oauthor{\bsnm{Gilmer}, \binits{J.}},
\oauthor{\bsnm{Dahl}, \binits{G.}},
\oauthor{\bsnm{Vaswani}, \binits{A.}},
\oauthor{\bsnm{Allen}, \binits{K.}},
\oauthor{\bsnm{Nash}, \binits{C.}},
\oauthor{\bsnm{Langston}, \binits{V.}},
\oauthor{\bsnm{Dyer}, \binits{C.}},
\oauthor{\bsnm{Heess}, \binits{N.}},
\oauthor{\bsnm{Wierstra}, \binits{D.}},
\oauthor{\bsnm{Kohli}, \binits{P.}},
\oauthor{\bsnm{Botvinick}, \binits{M.}},
\oauthor{\bsnm{Vinyals}, \binits{O.}},
\oauthor{\bsnm{Li}, \binits{Y.}},
\oauthor{\bsnm{Pascanu}, \binits{R.}}:
Relational Inductive Biases, Deep Learning, and Graph Networks.
arXiv
(2018).
\doiurl{10.48550/arXiv.1806.01261}
\end{botherref}
\endbibitem

%%% 44
\bibitem{sharifzadehClassificationAttentionScene2021b}
\begin{barticle}
\bauthor{\bsnm{Sharifzadeh}, \binits{S.}},
\bauthor{\bsnm{Baharlou}, \binits{S.M.}},
\bauthor{\bsnm{Tresp}, \binits{V.}}:
\batitle{Classification by {{Attention}}: {{Scene Graph Classification}} with
  {{Prior Knowledge}}}.
\bjtitle{Proceedings of the AAAI Conference on Artificial Intelligence}
\bvolume{35}(\bissue{6}),
\bfpage{5025}--\blpage{5033}
(\byear{2021}).
\doiurl{10.1609/aaai.v35i6.16636}
\end{barticle}
\endbibitem

%%% 45
\bibitem{locatelloObjectCentricLearningSlot2020}
\begin{bchapter}
\bauthor{\bsnm{Locatello}, \binits{F.}},
\bauthor{\bsnm{Weissenborn}, \binits{D.}},
\bauthor{\bsnm{Unterthiner}, \binits{T.}},
\bauthor{\bsnm{Mahendran}, \binits{A.}},
\bauthor{\bsnm{Heigold}, \binits{G.}},
\bauthor{\bsnm{Uszkoreit}, \binits{J.}},
\bauthor{\bsnm{Dosovitskiy}, \binits{A.}},
\bauthor{\bsnm{Kipf}, \binits{T.}}:
\bctitle{Object-{{Centric Learning}} with {{Slot Attention}}}.
In: \bbtitle{Advances in {{Neural Information Processing Systems}}},
vol. \bseriesno{33},
pp. \bfpage{11525}--\blpage{11538}.
\bpublisher{Curran Associates, Inc.},
\blocation{Virtual}
(\byear{2020}).
\burl{https://proceedings.neurips.cc/paper/2020/hash/8511df98c02ab60aea1b2356c013bc0f-Abstract.html}
Accessed 2024-04-01
\end{bchapter}
\endbibitem

%%% 46
\bibitem{devlinBERTPretrainingDeep2019a}
\begin{bchapter}
\bauthor{\bsnm{Devlin}, \binits{J.}},
\bauthor{\bsnm{Chang}, \binits{M.-W.}},
\bauthor{\bsnm{Lee}, \binits{K.}},
\bauthor{\bsnm{Toutanova}, \binits{K.}}:
\bctitle{{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for
  {{Language Understanding}}}.
In: \beditor{\bsnm{Burstein}, \binits{J.}},
\beditor{\bsnm{Doran}, \binits{C.}},
\beditor{\bsnm{Solorio}, \binits{T.}} (eds.)
\bbtitle{Proceedings of the 2019 {{Conference}} of the {{North American
  Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human
  Language Technologies}}, {{Volume}} 1 ({{Long}} and {{Short Papers}})},
pp. \bfpage{4171}--\blpage{4186}.
\bpublisher{Association for Computational Linguistics},
\blocation{Minneapolis, Minnesota}
(\byear{2019}).
\doiurl{10.18653/v1/N19-1423}
\end{bchapter}
\endbibitem

%%% 47
\bibitem{zhangWordEmbeddingPerturbation2018a}
\begin{botherref}
\oauthor{\bsnm{Zhang}, \binits{D.}},
\oauthor{\bsnm{Yang}, \binits{Z.}}:
Word {{Embedding Perturbation}} for {{Sentence Classification}}.
arXiv
(2018).
\doiurl{10.48550/arXiv.1804.08166}
\end{botherref}
\endbibitem

%%% 48
\bibitem{heuselGANsTrainedTwo2017a}
\begin{bchapter}
\bauthor{\bsnm{Heusel}, \binits{M.}},
\bauthor{\bsnm{Ramsauer}, \binits{H.}},
\bauthor{\bsnm{Unterthiner}, \binits{T.}},
\bauthor{\bsnm{Nessler}, \binits{B.}},
\bauthor{\bsnm{Hochreiter}, \binits{S.}}:
\bctitle{{{GANs}} trained by a two time-scale update rule converge to a local
  nash equilibrium}.
In: \bbtitle{Proceedings of the 31st {{International Conference}} on {{Neural
  Information Processing Systems}}}.
\bsertitle{{{NIPS}}'17},
pp. \bfpage{6629}--\blpage{6640}.
\bpublisher{Curran Associates Inc.},
\blocation{Red Hook, NY, USA}
(\byear{2017})
\end{bchapter}
\endbibitem

%%% 49
\bibitem{binkowskiDemystifyingMMDGANs2021}
\begin{botherref}
\oauthor{\bsnm{Bi{\'n}kowski}, \binits{M.}},
\oauthor{\bsnm{Sutherland}, \binits{D.J.}},
\oauthor{\bsnm{Arbel}, \binits{M.}},
\oauthor{\bsnm{Gretton}, \binits{A.}}:
Demystifying {{MMD GANs}}.
arXiv.
Comment: Published at ICLR 2018: https://openreview.net/forum?id=r1lUOzWCW
(2021).
\doiurl{10.48550/arXiv.1801.01401}
\end{botherref}
\endbibitem

%%% 50
\bibitem{parmarAliasedResizingSurprising2022a}
\begin{bchapter}
\bauthor{\bsnm{Parmar}, \binits{G.}},
\bauthor{\bsnm{Zhang}, \binits{R.}},
\bauthor{\bsnm{Zhu}, \binits{J.-Y.}}:
\bctitle{On {{Aliased Resizing}} and {{Surprising Subtleties}} in {{GAN
  Evaluation}}}.
In: \bbtitle{2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and
  {{Pattern Recognition}} ({{CVPR}})},
pp. \bfpage{11400}--\blpage{11410}.
\bpublisher{IEEE Computer Society},
\blocation{Virtual}
(\byear{2022}).
\doiurl{10.1109/CVPR52688.2022.01112}
\end{bchapter}
\endbibitem

%%% 51
\bibitem{szegedyRethinkingInceptionArchitecture2016a}
\begin{bchapter}
\bauthor{\bsnm{Szegedy}, \binits{C.}},
\bauthor{\bsnm{Vanhoucke}, \binits{V.}},
\bauthor{\bsnm{Ioffe}, \binits{S.}},
\bauthor{\bsnm{Shlens}, \binits{J.}},
\bauthor{\bsnm{Wojna}, \binits{Z.}}:
\bctitle{Rethinking the {{Inception Architecture}} for {{Computer Vision}}}.
In: \bbtitle{2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern
  Recognition}} ({{CVPR}})},
pp. \bfpage{2818}--\blpage{2826}
(\byear{2016}).
\doiurl{10.1109/CVPR.2016.308}
\end{bchapter}
\endbibitem

%%% 52
\bibitem{xuEmpiricalStudyEvaluation2018}
\begin{botherref}
\oauthor{\bsnm{Xu}, \binits{Q.}},
\oauthor{\bsnm{Huang}, \binits{G.}},
\oauthor{\bsnm{Yuan}, \binits{Y.}},
\oauthor{\bsnm{Guo}, \binits{C.}},
\oauthor{\bsnm{Sun}, \binits{Y.}},
\oauthor{\bsnm{Wu}, \binits{F.}},
\oauthor{\bsnm{Weinberger}, \binits{K.}}:
An Empirical Study on Evaluation Metrics of Generative Adversarial Networks.
arXiv.
Comment: arXiv admin note: text overlap with arXiv:1802.03446 by other authors
(2018).
\doiurl{10.48550/arXiv.1806.07755}
\end{botherref}
\endbibitem

%%% 53
\bibitem{brockLargeScaleGAN2019a}
\begin{botherref}
\oauthor{\bsnm{Brock}, \binits{A.}},
\oauthor{\bsnm{Donahue}, \binits{J.}},
\oauthor{\bsnm{Simonyan}, \binits{K.}}:
Large {{Scale GAN Training}} for {{High Fidelity Natural Image Synthesis}}.
arXiv
(2019).
\doiurl{10.48550/arXiv.1809.11096}
\end{botherref}
\endbibitem

%%% 54
\bibitem{kuhrBelleIICore2018}
\begin{barticle}
\bauthor{\bsnm{Kuhr}, \binits{T.}},
\bauthor{\bsnm{Pulvermacher}, \binits{C.}},
\bauthor{\bsnm{Ritter}, \binits{M.}},
\bauthor{\bsnm{Hauth}, \binits{T.}},
\bauthor{\bsnm{Braun}, \binits{N.}}:
\batitle{The {{Belle II Core Software}}}.
\bjtitle{Computing and Software for Big Science}
\bvolume{3}(\bissue{1}),
\bfpage{1}
(\byear{2018}).
\doiurl{10.1007/s41781-018-0017-9}
\end{barticle}
\endbibitem

%%% 55
\bibitem{mantelDetectionDiseaseClustering1967}
\begin{barticle}
\bauthor{\bsnm{Mantel}, \binits{N.}}:
\batitle{The detection of disease clustering and a generalized regression
  approach}.
\bjtitle{Cancer Research}
\bvolume{27}(\bissue{2}),
\bfpage{209}--\blpage{220}
(\byear{1967})
\end{barticle}
\endbibitem

%%% 56
\bibitem{sokalBiometry1995}
\begin{bbook}
\bauthor{\bsnm{Sokal}, \binits{R.R.}},
\bauthor{\bsnm{Rohlf}, \binits{F.J.}}:
\bbtitle{Biometry}.
\bpublisher{W. H. Freeman}, \bisbn{978-0-7167-2411-7}
(\byear{1995})
\end{bbook}
\endbibitem

%%% 57
\bibitem{kouBelleIIPhysics2020a}
\begin{barticle}
\bauthor{\bsnm{Kou}, \binits{E.}},
\bauthor{\bsnm{Urquijo}, \binits{P.}},
\bauthor{\bsnm{Altmannshofer}, \binits{W.}},
\bauthor{\bsnm{Beaujean}, \binits{F.}},
\bauthor{\bsnm{Bell}, \binits{G.}},
\bauthor{\bsnm{Beneke}, \binits{M.}},
\bauthor{\bsnm{Bigi}, \binits{I.I.}},
\bauthor{\bsnm{Bishara}, \binits{F.}},
\bauthor{\bsnm{Blanke}, \binits{M.}},
\bauthor{\bsnm{Bobeth}, \binits{C.}},
\bauthor{\bsnm{Bona}, \binits{M.}},
\bauthor{\bsnm{Brambilla}, \binits{N.}},
\bauthor{\bsnm{Braun}, \binits{V.M.}},
\bauthor{\bsnm{Brod}, \binits{J.}},
\bauthor{\bsnm{Buras}, \binits{A.J.}},
\bauthor{\bsnm{Cheng}, \binits{H.Y.}},
\bauthor{\bsnm{Chiang}, \binits{C.W.}},
\bauthor{\bsnm{Ciuchini}, \binits{M.}},
\bauthor{\bsnm{Colangelo}, \binits{G.}},
\bauthor{\bsnm{Crivellin}, \binits{A.}},
\bauthor{\bsnm{Czyz}, \binits{H.}},
\bauthor{\bsnm{Datta}, \binits{A.}},
\bauthor{\bsnm{De~Fazio}, \binits{F.}},
\bauthor{\bsnm{Deppisch}, \binits{T.}},
\bauthor{\bsnm{Dolan}, \binits{M.J.}},
\bauthor{\bsnm{Evans}, \binits{J.}},
\bauthor{\bsnm{Fajfer}, \binits{S.}},
\bauthor{\bsnm{Feldmann}, \binits{T.}},
\bauthor{\bsnm{Godfrey}, \binits{S.}},
\bauthor{\bsnm{Gronau}, \binits{M.}},
\bauthor{\bsnm{Grossman}, \binits{Y.}},
\bauthor{\bsnm{Guo}, \binits{F.K.}},
\bauthor{\bsnm{Haisch}, \binits{U.}},
\bauthor{\bsnm{Hanhart}, \binits{C.}},
\bauthor{\bsnm{Hashimoto}, \binits{S.}},
\bauthor{\bsnm{Hirose}, \binits{S.}},
\bauthor{\bsnm{Hisano}, \binits{J.}},
\bauthor{\bsnm{Hofer}, \binits{L.}},
\bauthor{\bsnm{Hoferichter}, \binits{M.}},
\bauthor{\bsnm{Hou}, \binits{W.S.}},
\bauthor{\bsnm{Huber}, \binits{T.}},
\bauthor{\bsnm{Hurth}, \binits{T.}},
\bauthor{\bsnm{Jaeger}, \binits{S.}},
\bauthor{\bsnm{Jahn}, \binits{S.}},
\bauthor{\bsnm{Jamin}, \binits{M.}},
\bauthor{\bsnm{Jones}, \binits{J.}},
\bauthor{\bsnm{Jung}, \binits{M.}},
\bauthor{\bsnm{Kagan}, \binits{A.L.}},
\bauthor{\bsnm{Kahlhoefer}, \binits{F.}},
\bauthor{\bsnm{Kamenik}, \binits{J.F.}},
\bauthor{\bsnm{Kaneko}, \binits{T.}},
\bauthor{\bsnm{Kiyo}, \binits{Y.}},
\bauthor{\bsnm{Kokulu}, \binits{A.}},
\bauthor{\bsnm{Kosnik}, \binits{N.}},
\bauthor{\bsnm{Kronfeld}, \binits{A.S.}},
\bauthor{\bsnm{Ligeti}, \binits{Z.}},
\bauthor{\bsnm{Logan}, \binits{H.}},
\bauthor{\bsnm{Lu}, \binits{C.D.}},
\bauthor{\bsnm{Lubicz}, \binits{V.}},
\bauthor{\bsnm{Mahmoudi}, \binits{F.}},
\bauthor{\bsnm{Maltman}, \binits{K.}},
\bauthor{\bsnm{Mishima}, \binits{S.}},
\bauthor{\bsnm{Misiak}, \binits{M.}},
\bauthor{\bsnm{Moats}, \binits{K.}},
\bauthor{\bsnm{Moussallam}, \binits{B.}},
\bauthor{\bsnm{Nefediev}, \binits{A.}},
\bauthor{\bsnm{Nierste}, \binits{U.}},
\bauthor{\bsnm{Nomura}, \binits{D.}},
\bauthor{\bsnm{Offen}, \binits{N.}},
\bauthor{\bsnm{Olsen}, \binits{S.L.}},
\bauthor{\bsnm{Passemar}, \binits{E.}},
\bauthor{\bsnm{Paul}, \binits{A.}},
\bauthor{\bsnm{Paz}, \binits{G.}},
\bauthor{\bsnm{Petrov}, \binits{A.A.}},
\bauthor{\bsnm{Pich}, \binits{A.}},
\bauthor{\bsnm{Polosa}, \binits{A.D.}},
\bauthor{\bsnm{Pradler}, \binits{J.}},
\bauthor{\bsnm{Prelovsek}, \binits{S.}},
\bauthor{\bsnm{Procura}, \binits{M.}},
\bauthor{\bsnm{Ricciardi}, \binits{G.}},
\bauthor{\bsnm{Robinson}, \binits{D.J.}},
\bauthor{\bsnm{Roig}, \binits{P.}},
\bauthor{\bsnm{Rosiek}, \binits{J.}},
\bauthor{\bsnm{Schacht}, \binits{S.}},
\bauthor{\bsnm{{Schmidt-Hoberg}}, \binits{K.}},
\bauthor{\bsnm{Schwichtenberg}, \binits{J.}},
\bauthor{\bsnm{Sharpe}, \binits{S.R.}},
\bauthor{\bsnm{Shigemitsu}, \binits{J.}},
\bauthor{\bsnm{Shih}, \binits{D.}},
\bauthor{\bsnm{Shimizu}, \binits{N.}},
\bauthor{\bsnm{Shimizu}, \binits{Y.}},
\bauthor{\bsnm{Silvestrini}, \binits{L.}},
\bauthor{\bsnm{Simula}, \binits{S.}},
\bauthor{\bsnm{Smith}, \binits{C.}},
\bauthor{\bsnm{Stoffer}, \binits{P.}},
\bauthor{\bsnm{Straub}, \binits{D.}},
\bauthor{\bsnm{Tackmann}, \binits{F.J.}},
\bauthor{\bsnm{Tanaka}, \binits{M.}},
\bauthor{\bsnm{Tayduganov}, \binits{A.}},
\bauthor{\bsnm{{Tetlalmatzi-Xolocotzi}}, \binits{G.}},
\bauthor{\bsnm{Teubner}, \binits{T.}},
\bauthor{\bsnm{Vairo}, \binits{A.}},
\bauthor{\bsnm{{van Dyk}}, \binits{D.}},
\bauthor{\bsnm{Virto}, \binits{J.}},
\bauthor{\bsnm{Was}, \binits{Z.}},
\bauthor{\bsnm{Watanabe}, \binits{R.}},
\bauthor{\bsnm{Watson}, \binits{I.}},
\bauthor{\bsnm{Westhoff}, \binits{S.}},
\bauthor{\bsnm{Zupan}, \binits{J.}},
\bauthor{\bsnm{Zwicky}, \binits{R.}},
\bauthor{\bsnm{Abudin{\'e}n}, \binits{F.}},
\bauthor{\bsnm{Adachi}, \binits{I.}},
\bauthor{\bsnm{Adamczyk}, \binits{K.}},
\bauthor{\bsnm{Ahlburg}, \binits{P.}},
\bauthor{\bsnm{Aihara}, \binits{H.}},
\bauthor{\bsnm{Aloisio}, \binits{A.}},
\bauthor{\bsnm{Andricek}, \binits{L.}},
\bauthor{\bsnm{Anh~Ky}, \binits{N.}},
\bauthor{\bsnm{Arndt}, \binits{M.}},
\bauthor{\bsnm{Asner}, \binits{D.M.}},
\bauthor{\bsnm{Atmacan}, \binits{H.}},
\bauthor{\bsnm{Aushev}, \binits{T.}},
\bauthor{\bsnm{Aushev}, \binits{V.}},
\bauthor{\bsnm{Ayad}, \binits{R.}},
\bauthor{\bsnm{Aziz}, \binits{T.}},
\bauthor{\bsnm{Baehr}, \binits{S.}},
\bauthor{\bsnm{Bahinipati}, \binits{S.}},
\bauthor{\bsnm{Bambade}, \binits{P.}},
\bauthor{\bsnm{Ban}, \binits{Y.}},
\bauthor{\bsnm{Barrett}, \binits{M.}},
\bauthor{\bsnm{Baudot}, \binits{J.}},
\bauthor{\bsnm{Behera}, \binits{P.}},
\bauthor{\bsnm{Belous}, \binits{K.}},
\bauthor{\bsnm{Bender}, \binits{M.}},
\bauthor{\bsnm{Bennett}, \binits{J.}},
\bauthor{\bsnm{Berger}, \binits{M.}},
\bauthor{\bsnm{Bernieri}, \binits{E.}},
\bauthor{\bsnm{Bernlochner}, \binits{F.U.}},
\bauthor{\bsnm{Bessner}, \binits{M.}},
\bauthor{\bsnm{Besson}, \binits{D.}},
\bauthor{\bsnm{Bettarini}, \binits{S.}},
\bauthor{\bsnm{Bhardwaj}, \binits{V.}},
\bauthor{\bsnm{Bhuyan}, \binits{B.}},
\bauthor{\bsnm{Bilka}, \binits{T.}},
\bauthor{\bsnm{Bilmis}, \binits{S.}},
\bauthor{\bsnm{Bilokin}, \binits{S.}},
\bauthor{\bsnm{Bonvicini}, \binits{G.}},
\bauthor{\bsnm{Bozek}, \binits{A.}},
\bauthor{\bsnm{Bra{\v c}ko}, \binits{M.}},
\bauthor{\bsnm{Branchini}, \binits{P.}},
\bauthor{\bsnm{Braun}, \binits{N.}},
\bauthor{\bsnm{Briere}, \binits{R.A.}},
\bauthor{\bsnm{Browder}, \binits{T.E.}},
\bauthor{\bsnm{Burmistrov}, \binits{L.}},
\bauthor{\bsnm{Bussino}, \binits{S.}},
\bauthor{\bsnm{Cao}, \binits{L.}},
\bauthor{\bsnm{Caria}, \binits{G.}},
\bauthor{\bsnm{Casarosa}, \binits{G.}},
\bauthor{\bsnm{Cecchi}, \binits{C.}},
\bauthor{\bsnm{{\v C}ervenkov}, \binits{D.}},
\bauthor{\bsnm{Chang}, \binits{M.-C.}},
\bauthor{\bsnm{Chang}, \binits{P.}},
\bauthor{\bsnm{Cheaib}, \binits{R.}},
\bauthor{\bsnm{Chekelian}, \binits{V.}},
\bauthor{\bsnm{Chen}, \binits{Y.}},
\bauthor{\bsnm{Cheon}, \binits{B.G.}},
\bauthor{\bsnm{Chilikin}, \binits{K.}},
\bauthor{\bsnm{Cho}, \binits{K.}},
\bauthor{\bsnm{Choi}, \binits{J.}},
\bauthor{\bsnm{Choi}, \binits{S.-K.}},
\bauthor{\bsnm{Choudhury}, \binits{S.}},
\bauthor{\bsnm{Cinabro}, \binits{D.}},
\bauthor{\bsnm{Cremaldi}, \binits{L.M.}},
\bauthor{\bsnm{Cuesta}, \binits{D.}},
\bauthor{\bsnm{Cunliffe}, \binits{S.}},
\bauthor{\bsnm{Dash}, \binits{N.}},
\bauthor{\bsnm{{de la Cruz Burelo}}, \binits{E.}},
\bauthor{\bsnm{{de Lucia}}, \binits{E.}},
\bauthor{\bsnm{De~Nardo}, \binits{G.}},
\bauthor{\bsnm{De~Nuccio}, \binits{M.}},
\bauthor{\bsnm{De~Pietro}, \binits{G.}},
\bauthor{\bsnm{De~Yta~Hernandez}, \binits{A.}},
\bauthor{\bsnm{Deschamps}, \binits{B.}},
\bauthor{\bsnm{Destefanis}, \binits{M.}},
\bauthor{\bsnm{Dey}, \binits{S.}},
\bauthor{\bsnm{Di~Capua}, \binits{F.}},
\bauthor{\bsnm{Di~Carlo}, \binits{S.}},
\bauthor{\bsnm{Dingfelder}, \binits{J.}},
\bauthor{\bsnm{Dole{\v z}al}, \binits{Z.}},
\bauthor{\bsnm{Dom{\'i}nguez~Jim{\'e}nez}, \binits{I.}},
\bauthor{\bsnm{Dong}, \binits{T.V.}},
\bauthor{\bsnm{Dossett}, \binits{D.}},
\bauthor{\bsnm{Duell}, \binits{S.}},
\bauthor{\bsnm{Eidelman}, \binits{S.}},
\bauthor{\bsnm{Epifanov}, \binits{D.}},
\bauthor{\bsnm{Fast}, \binits{J.E.}},
\bauthor{\bsnm{Ferber}, \binits{T.}},
\bauthor{\bsnm{Fiore}, \binits{S.}},
\bauthor{\bsnm{Fodor}, \binits{A.}},
\bauthor{\bsnm{Forti}, \binits{F.}},
\bauthor{\bsnm{Frey}, \binits{A.}},
\bauthor{\bsnm{Frost}, \binits{O.}},
\bauthor{\bsnm{Fulsom}, \binits{B.G.}},
\bauthor{\bsnm{Gabriel}, \binits{M.}},
\bauthor{\bsnm{Gabyshev}, \binits{N.}},
\bauthor{\bsnm{Ganiev}, \binits{E.}},
\bauthor{\bsnm{Gao}, \binits{X.}},
\bauthor{\bsnm{Gao}, \binits{B.}},
\bauthor{\bsnm{Garg}, \binits{R.}},
\bauthor{\bsnm{Garmash}, \binits{A.}},
\bauthor{\bsnm{Gaur}, \binits{V.}},
\bauthor{\bsnm{Gaz}, \binits{A.}},
\bauthor{\bsnm{Ge{\ss}ler}, \binits{T.}},
\bauthor{\bsnm{Gebauer}, \binits{U.}},
\bauthor{\bsnm{Gelb}, \binits{M.}},
\bauthor{\bsnm{Gellrich}, \binits{A.}},
\bauthor{\bsnm{Getzkow}, \binits{D.}},
\bauthor{\bsnm{Giordano}, \binits{R.}},
\bauthor{\bsnm{Giri}, \binits{A.}},
\bauthor{\bsnm{Glazov}, \binits{A.}},
\bauthor{\bsnm{Gobbo}, \binits{B.}},
\bauthor{\bsnm{Godang}, \binits{R.}},
\bauthor{\bsnm{Gogota}, \binits{O.}},
\bauthor{\bsnm{Goldenzweig}, \binits{P.}},
\bauthor{\bsnm{Golob}, \binits{B.}},
\bauthor{\bsnm{Gradl}, \binits{W.}},
\bauthor{\bsnm{Graziani}, \binits{E.}},
\bauthor{\bsnm{Greco}, \binits{M.}},
\bauthor{\bsnm{Greenwald}, \binits{D.}},
\bauthor{\bsnm{Gribanov}, \binits{S.}},
\bauthor{\bsnm{Guan}, \binits{Y.}},
\bauthor{\bsnm{Guido}, \binits{E.}},
\bauthor{\bsnm{Guo}, \binits{A.}},
\bauthor{\bsnm{Halder}, \binits{S.}},
\bauthor{\bsnm{Hara}, \binits{K.}},
\bauthor{\bsnm{Hartbrich}, \binits{O.}},
\bauthor{\bsnm{Hauth}, \binits{T.}},
\bauthor{\bsnm{Hayasaka}, \binits{K.}},
\bauthor{\bsnm{Hayashii}, \binits{H.}},
\bauthor{\bsnm{Hearty}, \binits{C.}},
\bauthor{\bsnm{Heredia De La~Cruz}, \binits{I.}},
\bauthor{\bsnm{Hernandez~Villanueva}, \binits{M.}},
\bauthor{\bsnm{Hershenhorn}, \binits{A.}},
\bauthor{\bsnm{Higuchi}, \binits{T.}},
\bauthor{\bsnm{Hoek}, \binits{M.}},
\bauthor{\bsnm{Hollitt}, \binits{S.}},
\bauthor{\bsnm{Hong~Van}, \binits{N.T.}},
\bauthor{\bsnm{Hsu}, \binits{C.-L.}},
\bauthor{\bsnm{Hu}, \binits{Y.}},
\bauthor{\bsnm{Huang}, \binits{K.}},
\bauthor{\bsnm{Iijima}, \binits{T.}},
\bauthor{\bsnm{Inami}, \binits{K.}},
\bauthor{\bsnm{Inguglia}, \binits{G.}},
\bauthor{\bsnm{Ishikawa}, \binits{A.}},
\bauthor{\bsnm{Itoh}, \binits{R.}},
\bauthor{\bsnm{Iwasaki}, \binits{Y.}},
\bauthor{\bsnm{Iwasaki}, \binits{M.}},
\bauthor{\bsnm{Jackson}, \binits{P.}},
\bauthor{\bsnm{Jacobs}, \binits{W.W.}},
\bauthor{\bsnm{Jaegle}, \binits{I.}},
\bauthor{\bsnm{Jeon}, \binits{H.B.}},
\bauthor{\bsnm{Ji}, \binits{X.}},
\bauthor{\bsnm{Jia}, \binits{S.}},
\bauthor{\bsnm{Jin}, \binits{Y.}},
\bauthor{\bsnm{Joo}, \binits{C.}},
\bauthor{\bsnm{K{\"u}nzel}, \binits{M.}},
\bauthor{\bsnm{Kadenko}, \binits{I.}},
\bauthor{\bsnm{Kahn}, \binits{J.}},
\bauthor{\bsnm{Kakuno}, \binits{H.}},
\bauthor{\bsnm{Kaliyar}, \binits{A.B.}},
\bauthor{\bsnm{Kandra}, \binits{J.}},
\bauthor{\bsnm{Kang}, \binits{K.H.}},
\bauthor{\bsnm{Kato}, \binits{Y.}},
\bauthor{\bsnm{Kawasaki}, \binits{T.}},
\bauthor{\bsnm{Ketter}, \binits{C.}},
\bauthor{\bsnm{Khasmidatul}, \binits{M.}},
\bauthor{\bsnm{Kichimi}, \binits{H.}},
\bauthor{\bsnm{Kim}, \binits{J.B.}},
\bauthor{\bsnm{Kim}, \binits{K.T.}},
\bauthor{\bsnm{Kim}, \binits{H.J.}},
\bauthor{\bsnm{Kim}, \binits{D.Y.}},
\bauthor{\bsnm{Kim}, \binits{K.}},
\bauthor{\bsnm{Kim}, \binits{Y.}},
\bauthor{\bsnm{Kimmel}, \binits{T.D.}},
\bauthor{\bsnm{Kindo}, \binits{H.}},
\bauthor{\bsnm{Kinoshita}, \binits{K.}},
\bauthor{\bsnm{Konno}, \binits{T.}},
\bauthor{\bsnm{Korobov}, \binits{A.}},
\bauthor{\bsnm{Korpar}, \binits{S.}},
\bauthor{\bsnm{Kotchetkov}, \binits{D.}},
\bauthor{\bsnm{Kowalewski}, \binits{R.}},
\bauthor{\bsnm{Kri{\v z}an}, \binits{P.}},
\bauthor{\bsnm{Kroeger}, \binits{R.}},
\bauthor{\bsnm{Krohn}, \binits{J.-F.}},
\bauthor{\bsnm{Krokovny}, \binits{P.}},
\bauthor{\bsnm{Kuehn}, \binits{W.}},
\bauthor{\bsnm{Kuhr}, \binits{T.}},
\bauthor{\bsnm{Kulasiri}, \binits{R.}},
\bauthor{\bsnm{Kumar}, \binits{M.}},
\bauthor{\bsnm{Kumar}, \binits{R.}},
\bauthor{\bsnm{Kumita}, \binits{T.}},
\bauthor{\bsnm{Kuzmin}, \binits{A.}},
\bauthor{\bsnm{Kwon}, \binits{Y.-J.}},
\bauthor{\bsnm{Lacaprara}, \binits{S.}},
\bauthor{\bsnm{Lai}, \binits{Y.-T.}},
\bauthor{\bsnm{Lalwani}, \binits{K.}},
\bauthor{\bsnm{Lange}, \binits{J.S.}},
\bauthor{\bsnm{Lee}, \binits{S.C.}},
\bauthor{\bsnm{Lee}, \binits{J.Y.}},
\bauthor{\bsnm{Leitl}, \binits{P.}},
\bauthor{\bsnm{Levit}, \binits{D.}},
\bauthor{\bsnm{Levonian}, \binits{S.}},
\bauthor{\bsnm{Li}, \binits{S.}},
\bauthor{\bsnm{Li}, \binits{L.K.}},
\bauthor{\bsnm{Li}, \binits{Y.}},
\bauthor{\bsnm{Li}, \binits{Y.B.}},
\bauthor{\bsnm{Li}, \binits{Q.}},
\bauthor{\bsnm{Li~Gioi}, \binits{L.}},
\bauthor{\bsnm{Libby}, \binits{J.}},
\bauthor{\bsnm{Liptak}, \binits{Z.}},
\bauthor{\bsnm{Liventsev}, \binits{D.}},
\bauthor{\bsnm{Longo}, \binits{S.}},
\bauthor{\bsnm{Loos}, \binits{A.}},
\bauthor{\bsnm{Lopez~Castro}, \binits{G.}},
\bauthor{\bsnm{Lubej}, \binits{M.}},
\bauthor{\bsnm{Lueck}, \binits{T.}},
\bauthor{\bsnm{Luetticke}, \binits{F.}},
\bauthor{\bsnm{Luo}, \binits{T.}},
\bauthor{\bsnm{M{\"u}ller}, \binits{F.}},
\bauthor{\bsnm{M{\"u}ller}, \binits{T.}},
\bauthor{\bsnm{MacQueen}, \binits{C.}},
\bauthor{\bsnm{Maeda}, \binits{Y.}},
\bauthor{\bsnm{Maggiora}, \binits{M.}},
\bauthor{\bsnm{Maity}, \binits{S.}},
\bauthor{\bsnm{Manoni}, \binits{E.}},
\bauthor{\bsnm{Marcello}, \binits{S.}},
\bauthor{\bsnm{Marinas}, \binits{C.}},
\bauthor{\bsnm{Martinez~Hernandez}, \binits{M.}},
\bauthor{\bsnm{Martini}, \binits{A.}},
\bauthor{\bsnm{Matvienko}, \binits{D.}},
\bauthor{\bsnm{McKenna}, \binits{J.A.}},
\bauthor{\bsnm{Meier}, \binits{F.}},
\bauthor{\bsnm{Merola}, \binits{M.}},
\bauthor{\bsnm{Metzner}, \binits{F.}},
\bauthor{\bsnm{Miller}, \binits{C.}},
\bauthor{\bsnm{Miyabayashi}, \binits{K.}},
\bauthor{\bsnm{Miyake}, \binits{H.}},
\bauthor{\bsnm{Miyata}, \binits{H.}},
\bauthor{\bsnm{Mizuk}, \binits{R.}},
\bauthor{\bsnm{Mohanty}, \binits{G.B.}},
\bauthor{\bsnm{Moon}, \binits{H.K.}},
\bauthor{\bsnm{Moon}, \binits{T.}},
\bauthor{\bsnm{Morda}, \binits{A.}},
\bauthor{\bsnm{Morii}, \binits{T.}},
\bauthor{\bsnm{Mrvar}, \binits{M.}},
\bauthor{\bsnm{Muroyama}, \binits{G.}},
\bauthor{\bsnm{Mussa}, \binits{R.}},
\bauthor{\bsnm{Nakamura}, \binits{I.}},
\bauthor{\bsnm{Nakano}, \binits{T.}},
\bauthor{\bsnm{Nakao}, \binits{M.}},
\bauthor{\bsnm{Nakayama}, \binits{H.}},
\bauthor{\bsnm{Nakazawa}, \binits{H.}},
\bauthor{\bsnm{Nanut}, \binits{T.}},
\bauthor{\bsnm{Naruki}, \binits{M.}},
\bauthor{\bsnm{Nath}, \binits{K.J.}},
\bauthor{\bsnm{Nayak}, \binits{M.}},
\bauthor{\bsnm{Nellikunnummel}, \binits{N.}},
\bauthor{\bsnm{Neverov}, \binits{D.}},
\bauthor{\bsnm{Niebuhr}, \binits{C.}},
\bauthor{\bsnm{Ninkovic}, \binits{J.}},
\bauthor{\bsnm{Nishida}, \binits{S.}},
\bauthor{\bsnm{Nishimura}, \binits{K.}},
\bauthor{\bsnm{Nouxman}, \binits{M.}},
\bauthor{\bsnm{Nowak}, \binits{G.}},
\bauthor{\bsnm{Ogawa}, \binits{K.}},
\bauthor{\bsnm{Onishchuk}, \binits{Y.}},
\bauthor{\bsnm{Ono}, \binits{H.}},
\bauthor{\bsnm{Onuki}, \binits{Y.}},
\bauthor{\bsnm{Pakhlov}, \binits{P.}},
\bauthor{\bsnm{Pakhlova}, \binits{G.}},
\bauthor{\bsnm{Pal}, \binits{B.}},
\bauthor{\bsnm{Paoloni}, \binits{E.}},
\bauthor{\bsnm{Park}, \binits{H.}},
\bauthor{\bsnm{Park}, \binits{C.-S.}},
\bauthor{\bsnm{Paschen}, \binits{B.}},
\bauthor{\bsnm{Passeri}, \binits{A.}},
\bauthor{\bsnm{Paul}, \binits{S.}},
\bauthor{\bsnm{Pedlar}, \binits{T.K.}},
\bauthor{\bsnm{Perell{\'o}}, \binits{M.}},
\bauthor{\bsnm{Peruzzi}, \binits{I.M.}},
\bauthor{\bsnm{Pestotnik}, \binits{R.}},
\bauthor{\bsnm{Piilonen}, \binits{L.E.}},
\bauthor{\bsnm{Podesta~Lerma}, \binits{L.}},
\bauthor{\bsnm{Popov}, \binits{V.}},
\bauthor{\bsnm{Prasanth}, \binits{K.}},
\bauthor{\bsnm{Prencipe}, \binits{E.}},
\bauthor{\bsnm{Prim}, \binits{M.}},
\bauthor{\bsnm{Purohit}, \binits{M.V.}},
\bauthor{\bsnm{Rabusov}, \binits{A.}},
\bauthor{\bsnm{Rasheed}, \binits{R.}},
\bauthor{\bsnm{Reiter}, \binits{S.}},
\bauthor{\bsnm{Remnev}, \binits{M.}},
\bauthor{\bsnm{Resmi}, \binits{P.K.}},
\bauthor{\bsnm{{Ripp-Baudot}}, \binits{I.}},
\bauthor{\bsnm{Ritter}, \binits{M.}},
\bauthor{\bsnm{Ritzert}, \binits{M.}},
\bauthor{\bsnm{Rizzo}, \binits{G.}},
\bauthor{\bsnm{Rizzuto}, \binits{L.}},
\bauthor{\bsnm{Robertson}, \binits{S.H.}},
\bauthor{\bsnm{Rodriguez~Perez}, \binits{D.}},
\bauthor{\bsnm{Roney}, \binits{J.M.}},
\bauthor{\bsnm{Rosenfeld}, \binits{C.}},
\bauthor{\bsnm{Rostomyan}, \binits{A.}},
\bauthor{\bsnm{Rout}, \binits{N.}},
\bauthor{\bsnm{Rummel}, \binits{S.}},
\bauthor{\bsnm{Russo}, \binits{G.}},
\bauthor{\bsnm{Sahoo}, \binits{D.}},
\bauthor{\bsnm{Sakai}, \binits{Y.}},
\bauthor{\bsnm{Salehi}, \binits{M.}},
\bauthor{\bsnm{Sanders}, \binits{D.A.}},
\bauthor{\bsnm{Sandilya}, \binits{S.}},
\bauthor{\bsnm{Sangal}, \binits{A.}},
\bauthor{\bsnm{Santelj}, \binits{L.}},
\bauthor{\bsnm{Sasaki}, \binits{J.}},
\bauthor{\bsnm{Sato}, \binits{Y.}},
\bauthor{\bsnm{Savinov}, \binits{V.}},
\bauthor{\bsnm{Scavino}, \binits{B.}},
\bauthor{\bsnm{Schram}, \binits{M.}},
\bauthor{\bsnm{Schreeck}, \binits{H.}},
\bauthor{\bsnm{Schueler}, \binits{J.}},
\bauthor{\bsnm{Schwanda}, \binits{C.}},
\bauthor{\bsnm{Schwartz}, \binits{A.J.}},
\bauthor{\bsnm{Seddon}, \binits{R.M.}},
\bauthor{\bsnm{Seino}, \binits{Y.}},
\bauthor{\bsnm{Senyo}, \binits{K.}},
\bauthor{\bsnm{Seon}, \binits{O.}},
\bauthor{\bsnm{Seong}, \binits{I.S.}},
\bauthor{\bsnm{Sevior}, \binits{M.E.}},
\bauthor{\bsnm{Sfienti}, \binits{C.}},
\bauthor{\bsnm{Shapkin}, \binits{M.}},
\bauthor{\bsnm{Shen}, \binits{C.P.}},
\bauthor{\bsnm{Shimomura}, \binits{M.}},
\bauthor{\bsnm{Shiu}, \binits{J.-G.}},
\bauthor{\bsnm{Shwartz}, \binits{B.}},
\bauthor{\bsnm{Sibidanov}, \binits{A.}},
\bauthor{\bsnm{Simon}, \binits{F.}},
\bauthor{\bsnm{Singh}, \binits{J.B.}},
\bauthor{\bsnm{Sinha}, \binits{R.}},
\bauthor{\bsnm{Skambraks}, \binits{S.}},
\bauthor{\bsnm{Smith}, \binits{K.}},
\bauthor{\bsnm{Sobie}, \binits{R.J.}},
\bauthor{\bsnm{Soffer}, \binits{A.}},
\bauthor{\bsnm{Sokolov}, \binits{A.}},
\bauthor{\bsnm{Solovieva}, \binits{E.}},
\bauthor{\bsnm{Spruck}, \binits{B.}},
\bauthor{\bsnm{Stani{\v c}}, \binits{S.}},
\bauthor{\bsnm{Stari{\v c}}, \binits{M.}},
\bauthor{\bsnm{Starinsky}, \binits{N.}},
\bauthor{\bsnm{Stolzenberg}, \binits{U.}},
\bauthor{\bsnm{Stottler}, \binits{Z.}},
\bauthor{\bsnm{Stroili}, \binits{R.}},
\bauthor{\bsnm{Strube}, \binits{J.F.}},
\bauthor{\bsnm{Stypula}, \binits{J.}},
\bauthor{\bsnm{Sumihama}, \binits{M.}},
\bauthor{\bsnm{Sumisawa}, \binits{K.}},
\bauthor{\bsnm{Sumiyoshi}, \binits{T.}},
\bauthor{\bsnm{Summers}, \binits{D.}},
\bauthor{\bsnm{Sutcliffe}, \binits{W.}},
\bauthor{\bsnm{Suzuki}, \binits{S.Y.}},
\bauthor{\bsnm{Tabata}, \binits{M.}},
\bauthor{\bsnm{Takahashi}, \binits{M.}},
\bauthor{\bsnm{Takizawa}, \binits{M.}},
\bauthor{\bsnm{Tamponi}, \binits{U.}},
\bauthor{\bsnm{Tan}, \binits{J.}},
\bauthor{\bsnm{Tanaka}, \binits{S.}},
\bauthor{\bsnm{Tanida}, \binits{K.}},
\bauthor{\bsnm{Taniguchi}, \binits{N.}},
\bauthor{\bsnm{Tao}, \binits{Y.}},
\bauthor{\bsnm{Taras}, \binits{P.}},
\bauthor{\bsnm{Tejeda~Munoz}, \binits{G.}},
\bauthor{\bsnm{Tenchini}, \binits{F.}},
\bauthor{\bsnm{Tippawan}, \binits{U.}},
\bauthor{\bsnm{Torassa}, \binits{E.}},
\bauthor{\bsnm{Trabelsi}, \binits{K.}},
\bauthor{\bsnm{Tsuboyama}, \binits{T.}},
\bauthor{\bsnm{Uchida}, \binits{M.}},
\bauthor{\bsnm{Uehara}, \binits{S.}},
\bauthor{\bsnm{Uglov}, \binits{T.}},
\bauthor{\bsnm{Unno}, \binits{Y.}},
\bauthor{\bsnm{Uno}, \binits{S.}},
\bauthor{\bsnm{Ushiroda}, \binits{Y.}},
\bauthor{\bsnm{Usov}, \binits{Y.}},
\bauthor{\bsnm{Vahsen}, \binits{S.E.}},
\bauthor{\bsnm{{van Tonder}}, \binits{R.}},
\bauthor{\bsnm{Varner}, \binits{G.}},
\bauthor{\bsnm{Varvell}, \binits{K.E.}},
\bauthor{\bsnm{Vinokurova}, \binits{A.}},
\bauthor{\bsnm{Vitale}, \binits{L.}},
\bauthor{\bsnm{Vos}, \binits{M.}},
\bauthor{\bsnm{Vossen}, \binits{A.}},
\bauthor{\bsnm{Waheed}, \binits{E.}},
\bauthor{\bsnm{Wakeling}, \binits{H.}},
\bauthor{\bsnm{Wan}, \binits{K.}},
\bauthor{\bsnm{Wang}, \binits{M.-Z.}},
\bauthor{\bsnm{Wang}, \binits{X.L.}},
\bauthor{\bsnm{Wang}, \binits{B.}},
\bauthor{\bsnm{Warburton}, \binits{A.}},
\bauthor{\bsnm{Webb}, \binits{J.}},
\bauthor{\bsnm{Wehle}, \binits{S.}},
\bauthor{\bsnm{Wessel}, \binits{C.}},
\bauthor{\bsnm{Wiechczynski}, \binits{J.}},
\bauthor{\bsnm{Wieduwilt}, \binits{P.}},
\bauthor{\bsnm{Won}, \binits{E.}},
\bauthor{\bsnm{Xu}, \binits{Q.}},
\bauthor{\bsnm{Xu}, \binits{X.}},
\bauthor{\bsnm{Yabsley}, \binits{B.D.}},
\bauthor{\bsnm{Yamada}, \binits{S.}},
\bauthor{\bsnm{Yamamoto}, \binits{H.}},
\bauthor{\bsnm{Yan}, \binits{W.}},
\bauthor{\bsnm{Yan}, \binits{W.}},
\bauthor{\bsnm{Yang}, \binits{S.B.}},
\bauthor{\bsnm{Ye}, \binits{H.}},
\bauthor{\bsnm{Yeo}, \binits{I.}},
\bauthor{\bsnm{Yin}, \binits{J.H.}},
\bauthor{\bsnm{Yonenaga}, \binits{M.}},
\bauthor{\bsnm{Yoshinobu}, \binits{T.}},
\bauthor{\bsnm{Yuan}, \binits{W.}},
\bauthor{\bsnm{Yuan}, \binits{C.Z.}},
\bauthor{\bsnm{Yusa}, \binits{Y.}},
\bauthor{\bsnm{Zakharov}, \binits{S.}},
\bauthor{\bsnm{Zani}, \binits{L.}},
\bauthor{\bsnm{Zeyrek}, \binits{M.}},
\bauthor{\bsnm{Zhang}, \binits{J.}},
\bauthor{\bsnm{Zhang}, \binits{Y.}},
\bauthor{\bsnm{Zhang}, \binits{Y.}},
\bauthor{\bsnm{Zhou}, \binits{X.}},
\bauthor{\bsnm{Zhukova}, \binits{V.}},
\bauthor{\bsnm{Zhulanov}, \binits{V.}},
\bauthor{\bsnm{Zupanc}, \binits{A.}}:
\batitle{The {{Belle II Physics Book}}}.
\bjtitle{Progress of Theoretical and Experimental Physics}
\bvolume{2020}(\bissue{2}),
\bfpage{029201}
(\byear{2020}).
\doiurl{10.1093/ptep/ptaa008}
\end{barticle}
\endbibitem

%%% 58
\bibitem{massey1951kolmogorov}
\begin{barticle}
\bauthor{\bsnm{Massey~Jr}, \binits{F.J.}}:
\batitle{The {{Kolmogorov-Smirnov}} test for goodness of fit}.
\bjtitle{Journal of the American statistical Association}
\bvolume{46}(\bissue{253}),
\bfpage{68}--\blpage{78}
(\byear{1951})
\end{barticle}
\endbibitem

%%% 59
\bibitem{devoreModernMathematicalStatistics2011}
\begin{bbook}
\bauthor{\bsnm{Devore}, \binits{J.L.}},
\bauthor{\bsnm{Berk}, \binits{K.N.}}:
\bbtitle{Modern {{Mathematical Statistics}} with {{Applications}}}.
\bpublisher{Springer}, \bisbn{978-1-4614-0390-6}
(\byear{2011})
\end{bbook}
\endbibitem

%%% 60
\bibitem{ramachandranMathematicalStatisticsApplications2020}
\begin{bbook}
\bauthor{\bsnm{Ramachandran}, \binits{K.M.}},
\bauthor{\bsnm{Tsokos}, \binits{C.P.}}:
\bbtitle{Mathematical {{Statistics}} with {{Applications}} in {{R}}}.
\bpublisher{Academic Press}, \bisbn{978-0-12-817816-4}
(\byear{2020})
\end{bbook}
\endbibitem

%%% 61
\bibitem{liuRoBERTaRobustlyOptimized2019a}
\begin{botherref}
\oauthor{\bsnm{Liu}, \binits{Y.}},
\oauthor{\bsnm{Ott}, \binits{M.}},
\oauthor{\bsnm{Goyal}, \binits{N.}},
\oauthor{\bsnm{Du}, \binits{J.}},
\oauthor{\bsnm{Joshi}, \binits{M.}},
\oauthor{\bsnm{Chen}, \binits{D.}},
\oauthor{\bsnm{Levy}, \binits{O.}},
\oauthor{\bsnm{Lewis}, \binits{M.}},
\oauthor{\bsnm{Zettlemoyer}, \binits{L.}},
\oauthor{\bsnm{Stoyanov}, \binits{V.}}:
{{RoBERTa}}: {{A Robustly Optimized BERT Pretraining Approach}}.
arXiv
(2019).
\doiurl{10.48550/arXiv.1907.11692}
\end{botherref}
\endbibitem

%%% 62
\bibitem{yangXLNetGeneralizedAutoregressive2019}
\begin{bchapter}
\bauthor{\bsnm{Yang}, \binits{Z.}},
\bauthor{\bsnm{Dai}, \binits{Z.}},
\bauthor{\bsnm{Yang}, \binits{Y.}},
\bauthor{\bsnm{Carbonell}, \binits{J.}},
\bauthor{\bsnm{Salakhutdinov}, \binits{R.}},
\bauthor{\bsnm{Le}, \binits{Q.V.}}:
\bctitle{{{XLNet}}: Generalized autoregressive pretraining for language
  understanding}.
In: \bbtitle{Proceedings of the 33rd {{International Conference}} on {{Neural
  Information Processing Systems}}},
pp. \bfpage{5753}--\blpage{5763}.
\bpublisher{Curran Associates Inc.},
\blocation{Red Hook, NY, USA}
(\byear{2019})
\end{bchapter}
\endbibitem

%%% 63
\bibitem{haririGraphGenerativeModels2021a}
\begin{botherref}
\oauthor{\bsnm{Hariri}, \binits{A.}},
\oauthor{\bsnm{Dyachkova}, \binits{D.}},
\oauthor{\bsnm{Gleyzer}, \binits{S.}}:
Graph {{Generative Models}} for {{Fast Detector Simulations}} in {{High Energy
  Physics}}.
arXiv.
Comment: Edited references and corrected typos
(2021).
\doiurl{10.48550/arXiv.2104.01725}
\end{botherref}
\endbibitem

%%% 64
\bibitem{verheyenEventGenerationDensity2022a}
\begin{barticle}
\bauthor{\bsnm{Verheyen}, \binits{R.}}:
\batitle{Event {{Generation}} and {{Density Estimation}} with {{Surjective
  Normalizing Flows}}}.
\bjtitle{SciPost Physics}
\bvolume{13}(\bissue{3}),
\bfpage{047}
(\byear{2022}).
\doiurl{10.21468/SciPostPhys.13.3.047}
\end{barticle}
\endbibitem

%%% 65
\bibitem{butterMachineLearningLHC2023}
\begin{barticle}
\bauthor{\bsnm{Butter}, \binits{A.}},
\bauthor{\bsnm{Plehn}, \binits{T.}},
\bauthor{\bsnm{Schumann}, \binits{S.}},
\bauthor{\bsnm{Badger}, \binits{S.}},
\bauthor{\bsnm{Caron}, \binits{S.}},
\bauthor{\bsnm{Cranmer}, \binits{K.}},
\bauthor{\bsnm{Di~Bello}, \binits{F.A.}},
\bauthor{\bsnm{Dreyer}, \binits{E.}},
\bauthor{\bsnm{Forte}, \binits{S.}},
\bauthor{\bsnm{Ganguly}, \binits{S.}},
\bauthor{\bsnm{Gon{\c c}alves}, \binits{D.}},
\bauthor{\bsnm{Gross}, \binits{E.}},
\bauthor{\bsnm{Heimel}, \binits{T.}},
\bauthor{\bsnm{Heinrich}, \binits{G.}},
\bauthor{\bsnm{Heinrich}, \binits{L.}},
\bauthor{\bsnm{Held}, \binits{A.}},
\bauthor{\bsnm{H{\"o}che}, \binits{S.}},
\bauthor{\bsnm{Howard}, \binits{J.N.}},
\bauthor{\bsnm{Ilten}, \binits{P.}},
\bauthor{\bsnm{Isaacson}, \binits{J.}},
\bauthor{\bsnm{Jan{\ss}en}, \binits{T.}},
\bauthor{\bsnm{Jones}, \binits{S.}},
\bauthor{\bsnm{Kado}, \binits{M.}},
\bauthor{\bsnm{Kagan}, \binits{M.}},
\bauthor{\bsnm{Kasieczka}, \binits{G.}},
\bauthor{\bsnm{Kling}, \binits{F.}},
\bauthor{\bsnm{Kraml}, \binits{S.}},
\bauthor{\bsnm{Krause}, \binits{C.}},
\bauthor{\bsnm{Krauss}, \binits{F.}},
\bauthor{\bsnm{Kr{\"o}ninger}, \binits{K.}},
\bauthor{\bsnm{Barman}, \binits{R.K.}},
\bauthor{\bsnm{Luchmann}, \binits{M.}},
\bauthor{\bsnm{Magerya}, \binits{V.}},
\bauthor{\bsnm{Ma{\^i}tre}, \binits{D.}},
\bauthor{\bsnm{Malaescu}, \binits{B.}},
\bauthor{\bsnm{Maltoni}, \binits{F.}},
\bauthor{\bsnm{Martini}, \binits{T.}},
\bauthor{\bsnm{Mattelaer}, \binits{O.}},
\bauthor{\bsnm{Nachman}, \binits{B.}},
\bauthor{\bsnm{Pitz}, \binits{S.}},
\bauthor{\bsnm{Rojo}, \binits{J.}},
\bauthor{\bsnm{Schwartz}, \binits{M.}},
\bauthor{\bsnm{Shih}, \binits{D.}},
\bauthor{\bsnm{Siegert}, \binits{F.}},
\bauthor{\bsnm{Stegeman}, \binits{R.}},
\bauthor{\bsnm{Stienen}, \binits{B.}},
\bauthor{\bsnm{Thaler}, \binits{J.}},
\bauthor{\bsnm{Verheyen}, \binits{R.}},
\bauthor{\bsnm{Whiteson}, \binits{D.}},
\bauthor{\bsnm{Winterhalder}, \binits{R.}},
\bauthor{\bsnm{Zupan}, \binits{J.}}:
\batitle{Machine learning and {{LHC}} event generation}.
\bjtitle{SciPost Physics}
\bvolume{14}(\bissue{4}),
\bfpage{079}
(\byear{2023}).
\doiurl{10.21468/SciPostPhys.14.4.079}
\end{barticle}
\endbibitem

%%% 66
\bibitem{evansLHCMachine2008b}
\begin{barticle}
\bauthor{\bsnm{Evans}, \binits{L.}},
\bauthor{\bsnm{Bryant}, \binits{P.}}:
\batitle{{{LHC Machine}}}.
\bjtitle{Journal of Instrumentation}
\bvolume{3}(\bissue{08}),
\bfpage{08001}
(\byear{2008}).
\doiurl{10.1088/1748-0221/3/08/S08001}
\end{barticle}
\endbibitem

%%% 67
\bibitem{terzoNovel3DPixel2021}
\begin{botherref}
\oauthor{\bsnm{Terzo}, \binits{S.}},
\oauthor{\bsnm{Boscardin}, \binits{M.}},
\oauthor{\bsnm{Carlotto}, \binits{J.}},
\oauthor{\bsnm{Dalla~Betta}, \binits{G.-F.}},
\oauthor{\bsnm{Darbo}, \binits{G.}},
\oauthor{\bsnm{Dorholt}, \binits{O.}},
\oauthor{\bsnm{Ficorella}, \binits{F.}},
\oauthor{\bsnm{Gariano}, \binits{G.}},
\oauthor{\bsnm{Gemme}, \binits{C.}},
\oauthor{\bsnm{Giannini}, \binits{G.}},
\oauthor{\bsnm{Grinstein}, \binits{S.}},
\oauthor{\bsnm{Heggelund}, \binits{A.}},
\oauthor{\bsnm{Huiberts}, \binits{S.}},
\oauthor{\bsnm{Kok}, \binits{A.}},
\oauthor{\bsnm{Koybasi}, \binits{O.}},
\oauthor{\bsnm{Lapertosa}, \binits{A.}},
\oauthor{\bsnm{Lauritzen}, \binits{M.E.}},
\oauthor{\bsnm{Manna}, \binits{M.}},
\oauthor{\bsnm{Mendicino}, \binits{R.}},
\oauthor{\bsnm{Oide}, \binits{H.}},
\oauthor{\bsnm{Pellegrini}, \binits{G.}},
\oauthor{\bsnm{Povoli}, \binits{M.}},
\oauthor{\bsnm{Quirion}, \binits{D.}},
\oauthor{\bsnm{Rohne}, \binits{O.M.}},
\oauthor{\bsnm{Ronchin}, \binits{S.}},
\oauthor{\bsnm{Sandaker}, \binits{H.}},
\oauthor{\bsnm{Abdulla~Samy}, \binits{M.A.}},
\oauthor{\bsnm{Stugu}, \binits{B.}},
\oauthor{\bsnm{Vannoli}, \binits{L.}}:
Novel {{3D Pixel Sensors}} for the {{Upgrade}} of the {{ATLAS Inner Tracker}}.
Frontiers in Physics
\textbf{9}
(2021).
\doiurl{10.3389/fphy.2021.624668}
\end{botherref}
\endbibitem

%%% 68
\bibitem{pedroCurrentFuturePerformance2019}
\begin{barticle}
\bauthor{\bsnm{Pedro}, \binits{K.}}:
\batitle{Current and {{Future Performance}} of the {{CMS Simulation}}}.
\bjtitle{EPJ Web of Conferences}
\bvolume{214},
\bfpage{02036}
(\byear{2019}).
\doiurl{10.1051/epjconf/201921402036}
\end{barticle}
\endbibitem

%%% 69
\bibitem{huangComingAgeNovo2016}
\begin{barticle}
\bauthor{\bsnm{Huang}, \binits{P.-S.}},
\bauthor{\bsnm{Boyken}, \binits{S.E.}},
\bauthor{\bsnm{Baker}, \binits{D.}}:
\batitle{The coming of age of de novo protein design}.
\bjtitle{Nature}
\bvolume{537}(\bissue{7620}),
\bfpage{320}--\blpage{327}
(\byear{2016}).
\doiurl{10.1038/nature19946}
\end{barticle}
\endbibitem

%%% 70
\bibitem{liuDensityEstimationUsing2021}
\begin{barticle}
\bauthor{\bsnm{Liu}, \binits{Q.}},
\bauthor{\bsnm{Xu}, \binits{J.}},
\bauthor{\bsnm{Jiang}, \binits{R.}},
\bauthor{\bsnm{Wong}, \binits{W.H.}}:
\batitle{Density estimation using deep generative neural networks}.
\bjtitle{Proceedings of the National Academy of Sciences of the United States
  of America}
\bvolume{118}(\bissue{15}),
\bfpage{2101344118}
(\byear{2021}).
\doiurl{10.1073/pnas.2101344118}
\end{barticle}
\endbibitem

%%% 71
\bibitem{repeckaExpandingFunctionalProtein2021}
\begin{barticle}
\bauthor{\bsnm{Repecka}, \binits{D.}},
\bauthor{\bsnm{Jauniskis}, \binits{V.}},
\bauthor{\bsnm{Karpus}, \binits{L.}},
\bauthor{\bsnm{Rembeza}, \binits{E.}},
\bauthor{\bsnm{Rokaitis}, \binits{I.}},
\bauthor{\bsnm{Zrimec}, \binits{J.}},
\bauthor{\bsnm{Poviloniene}, \binits{S.}},
\bauthor{\bsnm{Laurynenas}, \binits{A.}},
\bauthor{\bsnm{Viknander}, \binits{S.}},
\bauthor{\bsnm{Abuajwa}, \binits{W.}},
\bauthor{\bsnm{Savolainen}, \binits{O.}},
\bauthor{\bsnm{Meskys}, \binits{R.}},
\bauthor{\bsnm{Engqvist}, \binits{M.K.M.}},
\bauthor{\bsnm{Zelezniak}, \binits{A.}}:
\batitle{Expanding functional protein sequence spaces using generative
  adversarial networks}.
\bjtitle{Nature Machine Intelligence}
\bvolume{3}(\bissue{4}),
\bfpage{324}--\blpage{333}
(\byear{2021}).
\doiurl{10.1038/s42256-021-00310-5}
\end{barticle}
\endbibitem

%%% 72
\bibitem{NEURIPS2018_afa299a4}
\begin{bchapter}
\bauthor{\bsnm{Anand}, \binits{N.}},
\bauthor{\bsnm{Huang}, \binits{P.}}:
\bctitle{Generative modeling for protein structures}.
In: \beditor{\bsnm{Bengio}, \binits{S.}},
\beditor{\bsnm{Wallach}, \binits{H.}},
\beditor{\bsnm{Larochelle}, \binits{H.}},
\beditor{\bsnm{Grauman}, \binits{K.}},
\beditor{\bsnm{{Cesa-Bianchi}}, \binits{N.}},
\beditor{\bsnm{Garnett}, \binits{R.}} (eds.)
\bbtitle{Advances in Neural Information Processing Systems},
vol. \bseriesno{31}.
\bpublisher{Curran Associates, Inc.},
\blocation{Virtual}
(\byear{2018}).
\burl{https://proceedings.neurips.cc/paper_files/paper/2018/file/afa299a4d1d8c52e75dd8a24c3ce534f-Paper.pdf}
\end{bchapter}
\endbibitem

%%% 73
\bibitem{strokachDeepGenerativeModeling2022}
\begin{barticle}
\bauthor{\bsnm{Strokach}, \binits{A.}},
\bauthor{\bsnm{Kim}, \binits{P.M.}}:
\batitle{Deep generative modeling for protein design}.
\bjtitle{Current Opinion in Structural Biology}
\bvolume{72},
\bfpage{226}--\blpage{236}
(\byear{2022}).
\doiurl{10.1016/j.sbi.2021.11.008}
\end{barticle}
\endbibitem

%%% 74
\bibitem{mirzaConditionalGenerativeAdversarial2014a}
\begin{botherref}
\oauthor{\bsnm{Mirza}, \binits{M.}},
\oauthor{\bsnm{Osindero}, \binits{S.}}:
Conditional {{Generative Adversarial Nets}}.
arXiv
(2014).
\doiurl{10.48550/arXiv.1411.1784}
\end{botherref}
\endbibitem

%%% 75
\bibitem{limGeometricGAN2017a}
\begin{botherref}
\oauthor{\bsnm{Lim}, \binits{J.H.}},
\oauthor{\bsnm{Ye}, \binits{J.C.}}:
Geometric {{GAN}}.
arXiv
(2017).
\doiurl{10.48550/arXiv.1705.02894}
\end{botherref}
\endbibitem

%%% 76
\bibitem{odenaConditionalImageSynthesis2017a}
\begin{bchapter}
\bauthor{\bsnm{Odena}, \binits{A.}},
\bauthor{\bsnm{Olah}, \binits{C.}},
\bauthor{\bsnm{Shlens}, \binits{J.}}:
\bctitle{Conditional {{Image Synthesis}} with {{Auxiliary Classifier GANs}}}.
In: \bbtitle{Proceedings of the 34th {{International Conference}} on {{Machine
  Learning}}},
pp. \bfpage{2642}--\blpage{2651}.
\bpublisher{PMLR},
\blocation{Virtual}
(\byear{2017}).
\burl{https://proceedings.mlr.press/v70/odena17a.html}
Accessed 2024-04-01
\end{bchapter}
\endbibitem

%%% 77
\bibitem{chenSimpleFrameworkContrastive2020a}
\begin{bchapter}
\bauthor{\bsnm{Chen}, \binits{T.}},
\bauthor{\bsnm{Kornblith}, \binits{S.}},
\bauthor{\bsnm{Norouzi}, \binits{M.}},
\bauthor{\bsnm{Hinton}, \binits{G.}}:
\bctitle{A simple framework for contrastive learning of visual
  representations}.
In: \bbtitle{Proceedings of the 37th {{International Conference}} on {{Machine
  Learning}}}.
\bsertitle{{{ICML}}'20},
vol. \bseriesno{119},
pp. \bfpage{1597}--\blpage{1607}.
\bpublisher{JMLR.org},
\blocation{Virtual}
(\byear{2020})
\end{bchapter}
\endbibitem

%%% 78
\bibitem{vaswaniAttentionAllYou2017b}
\begin{bchapter}
\bauthor{\bsnm{Vaswani}, \binits{A.}},
\bauthor{\bsnm{Shazeer}, \binits{N.}},
\bauthor{\bsnm{Parmar}, \binits{N.}},
\bauthor{\bsnm{Uszkoreit}, \binits{J.}},
\bauthor{\bsnm{Jones}, \binits{L.}},
\bauthor{\bsnm{Gomez}, \binits{A.N.}},
\bauthor{\bsnm{Kaiser}, \binits{{\L}.}},
\bauthor{\bsnm{Polosukhin}, \binits{I.}}:
\bctitle{Attention is all you need}.
In: \bbtitle{Proceedings of the 31st {{International Conference}} on {{Neural
  Information Processing Systems}}}.
\bsertitle{{{NIPS}}'17},
pp. \bfpage{6000}--\blpage{6010}.
\bpublisher{Curran Associates Inc.},
\blocation{Red Hook, NY, USA}
(\byear{2017})
\end{bchapter}
\endbibitem

%%% 79
\bibitem{hudsonGenerativeAdversarialTransformers2021a}
\begin{bchapter}
\bauthor{\bsnm{Hudson}, \binits{D.A.}},
\bauthor{\bsnm{Zitnick}, \binits{L.}}:
\bctitle{Generative {{Adversarial Transformers}}}.
In: \bbtitle{Proceedings of the 38th {{International Conference}} on {{Machine
  Learning}}},
pp. \bfpage{4487}--\blpage{4499}.
\bpublisher{PMLR},
\blocation{Virtual}
(\byear{2021}).
\burl{https://proceedings.mlr.press/v139/hudson21a.html}
Accessed 2024-04-01
\end{bchapter}
\endbibitem

%%% 80
\bibitem{jiangTransGANTwoPure2021a}
\begin{bchapter}
\bauthor{\bsnm{Jiang}, \binits{Y.}},
\bauthor{\bsnm{Chang}, \binits{S.}},
\bauthor{\bsnm{Wang}, \binits{Z.}}:
\bctitle{{{TransGAN}}: {{Two Pure Transformers Can Make One Strong GAN}}, and
  {{That Can Scale Up}}}.
In: \bbtitle{Advances in {{Neural Information Processing Systems}}},
vol. \bseriesno{34},
pp. \bfpage{14745}--\blpage{14758}.
\bpublisher{Curran Associates, Inc.},
\blocation{Virtual}
(\byear{2021}).
\burl{https://proceedings.neurips.cc/paper_files/paper/2021/hash/7c220a2091c26a7f5e9f1cfb099511e3-Abstract.html}
Accessed 2024-04-01
\end{bchapter}
\endbibitem

%%% 81
\bibitem{dosovitskiyImageWorth16x162021}
\begin{botherref}
\oauthor{\bsnm{Dosovitskiy}, \binits{A.}},
\oauthor{\bsnm{Beyer}, \binits{L.}},
\oauthor{\bsnm{Kolesnikov}, \binits{A.}},
\oauthor{\bsnm{Weissenborn}, \binits{D.}},
\oauthor{\bsnm{Zhai}, \binits{X.}},
\oauthor{\bsnm{Unterthiner}, \binits{T.}},
\oauthor{\bsnm{Dehghani}, \binits{M.}},
\oauthor{\bsnm{Minderer}, \binits{M.}},
\oauthor{\bsnm{Heigold}, \binits{G.}},
\oauthor{\bsnm{Gelly}, \binits{S.}},
\oauthor{\bsnm{Uszkoreit}, \binits{J.}},
\oauthor{\bsnm{Houlsby}, \binits{N.}}:
An {{Image}} Is {{Worth}} 16x16 {{Words}}: {{Transformers}} for {{Image
  Recognition}} at {{Scale}}.
arXiv.
Comment: Fine-tuning code and pre-trained models are available at
  https://github.com/google-research/vision\_transformer. ICLR camera-ready
  version with 2 small modifications: 1) Added a discussion of CLS vs GAP
  classifier in the appendix, 2) Fixed an error in exaFLOPs computation in
  Figure 5 and Table 6 (relative performance of models is basically not
  affected)
(2021).
\doiurl{10.48550/arXiv.2010.11929}
\end{botherref}
\endbibitem

%%% 82
\bibitem{liuUnderstandingDifficultyTraining2020a}
\begin{bchapter}
\bauthor{\bsnm{Liu}, \binits{L.}},
\bauthor{\bsnm{Liu}, \binits{X.}},
\bauthor{\bsnm{Gao}, \binits{J.}},
\bauthor{\bsnm{Chen}, \binits{W.}},
\bauthor{\bsnm{Han}, \binits{J.}}:
\bctitle{Understanding the {{Difficulty}} of {{Training Transformers}}}.
In: \beditor{\bsnm{Webber}, \binits{B.}},
\beditor{\bsnm{Cohn}, \binits{T.}},
\beditor{\bsnm{He}, \binits{Y.}},
\beditor{\bsnm{Liu}, \binits{Y.}} (eds.)
\bbtitle{Proceedings of the 2020 {{Conference}} on {{Empirical Methods}} in
  {{Natural Language Processing}} ({{EMNLP}})},
pp. \bfpage{5747}--\blpage{5763}.
\bpublisher{Association for Computational Linguistics},
\blocation{Online}
(\byear{2020}).
\doiurl{10.18653/v1/2020.emnlp-main.463}
\end{bchapter}
\endbibitem

%%% 83
\bibitem{guttenbergPermutationequivariantNeuralNetworks2016}
\begin{botherref}
\oauthor{\bsnm{Guttenberg}, \binits{N.}},
\oauthor{\bsnm{Virgo}, \binits{N.}},
\oauthor{\bsnm{Witkowski}, \binits{O.}},
\oauthor{\bsnm{Aoki}, \binits{H.}},
\oauthor{\bsnm{Kanai}, \binits{R.}}:
Permutation-Equivariant Neural Networks Applied to Dynamics Prediction.
arXiv.
Comment: 7 pages, 4 figures
(2016).
\doiurl{10.48550/arXiv.1612.04530}
\end{botherref}
\endbibitem

%%% 84
\bibitem{ravanbakhshEquivarianceParameterSharing2017}
\begin{bchapter}
\bauthor{\bsnm{Ravanbakhsh}, \binits{S.}},
\bauthor{\bsnm{Schneider}, \binits{J.}},
\bauthor{\bsnm{P{\'o}czos}, \binits{B.}}:
\bctitle{Equivariance {{Through Parameter-Sharing}}}.
In: \bbtitle{Proceedings of the 34th {{International Conference}} on {{Machine
  Learning}}},
pp. \bfpage{2892}--\blpage{2901}.
\bpublisher{PMLR},
\blocation{Virtual}
(\byear{2017}).
\burl{https://proceedings.mlr.press/v70/ravanbakhsh17a.html}
Accessed 2024-04-01
\end{bchapter}
\endbibitem

%%% 85
\bibitem{zaheerDeepSets2017a}
\begin{bchapter}
\bauthor{\bsnm{Zaheer}, \binits{M.}},
\bauthor{\bsnm{Kottur}, \binits{S.}},
\bauthor{\bsnm{Ravanbhakhsh}, \binits{S.}},
\bauthor{\bsnm{P{\'o}czos}, \binits{B.}},
\bauthor{\bsnm{Salakhutdinov}, \binits{R.}},
\bauthor{\bsnm{Smola}, \binits{A.J.}}:
\bctitle{Deep {{Sets}}}.
In: \bbtitle{Proceedings of the 31st {{International Conference}} on {{Neural
  Information Processing Systems}}}.
\bsertitle{{{NIPS}}'17},
pp. \bfpage{3394}--\blpage{3404}.
\bpublisher{Curran Associates Inc.},
\blocation{Red Hook, NY, USA}
(\byear{2017})
\end{bchapter}
\endbibitem

%%% 86
\bibitem{clarkWhatDoesBERT2019a}
\begin{bchapter}
\bauthor{\bsnm{Clark}, \binits{K.}},
\bauthor{\bsnm{Khandelwal}, \binits{U.}},
\bauthor{\bsnm{Levy}, \binits{O.}},
\bauthor{\bsnm{Manning}, \binits{C.D.}}:
\bctitle{What {{Does BERT Look}} at? {{An Analysis}} of {{BERT}}'s
  {{Attention}}}.
In: \beditor{\bsnm{Linzen}, \binits{T.}},
\beditor{\bsnm{Chrupa{\l}a}, \binits{G.}},
\beditor{\bsnm{Belinkov}, \binits{Y.}},
\beditor{\bsnm{Hupkes}, \binits{D.}} (eds.)
\bbtitle{Proceedings of the 2019 {{ACL Workshop BlackboxNLP}}: {{Analyzing}}
  and {{Interpreting Neural Networks}} for {{NLP}}},
pp. \bfpage{276}--\blpage{286}.
\bpublisher{Association for Computational Linguistics},
\blocation{Florence, Italy}
(\byear{2019}).
\doiurl{10.18653/v1/W19-4828}
\end{bchapter}
\endbibitem

%%% 87
\bibitem{yunAreTransformersUniversal2020a}
\begin{botherref}
\oauthor{\bsnm{Yun}, \binits{C.}},
\oauthor{\bsnm{Bhojanapalli}, \binits{S.}},
\oauthor{\bsnm{Rawat}, \binits{A.S.}},
\oauthor{\bsnm{Reddi}, \binits{S.J.}},
\oauthor{\bsnm{Kumar}, \binits{S.}}:
Are {{Transformers}} Universal Approximators of Sequence-to-Sequence Functions?
arXiv.
Comment: 23 pages, ICLR 2020 camera-ready version
(2020).
\doiurl{10.48550/arXiv.1912.10077}
\end{botherref}
\endbibitem

%%% 88
\bibitem{baLayerNormalization2016a}
\begin{botherref}
\oauthor{\bsnm{Ba}, \binits{J.L.}},
\oauthor{\bsnm{Kiros}, \binits{J.R.}},
\oauthor{\bsnm{Hinton}, \binits{G.E.}}:
Layer {{Normalization}}.
arXiv
(2016).
\doiurl{10.48550/arXiv.1607.06450}
\end{botherref}
\endbibitem

%%% 89
\bibitem{miyatoSpectralNormalizationGenerative2018b}
\begin{botherref}
\oauthor{\bsnm{Miyato}, \binits{T.}},
\oauthor{\bsnm{Kataoka}, \binits{T.}},
\oauthor{\bsnm{Koyama}, \binits{M.}},
\oauthor{\bsnm{Yoshida}, \binits{Y.}}:
Spectral {{Normalization}} for {{Generative Adversarial Networks}}.
arXiv.
Comment: Published as a conference paper at ICLR 2018
(2018).
\doiurl{10.48550/arXiv.1802.05957}
\end{botherref}
\endbibitem

%%% 90
\bibitem{wangNormFaceL2Hypersphere2017a}
\begin{bchapter}
\bauthor{\bsnm{Wang}, \binits{F.}},
\bauthor{\bsnm{Xiang}, \binits{X.}},
\bauthor{\bsnm{Cheng}, \binits{J.}},
\bauthor{\bsnm{Yuille}, \binits{A.L.}}:
\bctitle{{{NormFace}}: {{L2 Hypersphere Embedding}} for {{Face Verification}}}.
In: \bbtitle{Proceedings of the 25th {{ACM}} International Conference on
  {{Multimedia}}}.
\bsertitle{{{MM}} '17},
pp. \bfpage{1041}--\blpage{1049}.
\bpublisher{Association for Computing Machinery},
\blocation{New York, NY, USA}
(\byear{2017}).
\doiurl{10.1145/3123266.3123359}
\end{bchapter}
\endbibitem

%%% 91
\bibitem{gorbanStochasticSeparationTheorems2017a}
\begin{barticle}
\bauthor{\bsnm{Gorban}, \binits{A.N.}},
\bauthor{\bsnm{Tyukin}, \binits{I.Y.}}:
\batitle{Stochastic separation theorems}.
\bjtitle{Neural Networks}
\bvolume{94},
\bfpage{255}--\blpage{259}
(\byear{2017}).
\doiurl{10.1016/j.neunet.2017.07.014}
\end{barticle}
\endbibitem

%%% 92
\bibitem{raniSelfsupervisedLearningSuccinct2023}
\begin{barticle}
\bauthor{\bsnm{Rani}, \binits{V.}},
\bauthor{\bsnm{Nabi}, \binits{S.T.}},
\bauthor{\bsnm{Kumar}, \binits{M.}},
\bauthor{\bsnm{Mittal}, \binits{A.}},
\bauthor{\bsnm{Kumar}, \binits{K.}}:
\batitle{Self-supervised {{Learning}}: {{A Succinct Review}}}.
\bjtitle{Archives of Computational Methods in Engineering}
\bvolume{30}(\bissue{4}),
\bfpage{2761}--\blpage{2775}
(\byear{2023}).
\doiurl{10.1007/s11831-023-09884-2}
\end{barticle}
\endbibitem

%%% 93
\bibitem{kullbackInformationSufficiency1951a}
\begin{barticle}
\bauthor{\bsnm{Kullback}, \binits{S.}},
\bauthor{\bsnm{Leibler}, \binits{R.A.}}:
\batitle{On {{Information}} and {{Sufficiency}}}.
\bjtitle{The Annals of Mathematical Statistics}
\bvolume{22}(\bissue{1}),
\bfpage{79}--\blpage{86}
(\byear{1951}).
\doiurl{10.1214/aoms/1177729694}
\end{barticle}
\endbibitem

%%% 94
\bibitem{thomsonXXIVStructureAtom1904a}
\begin{barticle}
\bauthor{\bsnm{Thomson}, \binits{J.J.}}:
\batitle{{{XXIV}}. {{On}} the structure of the atom: An investigation of the
  stability and periods of oscillation of a number of corpuscles arranged at
  equal intervals around the circumference of a circle; with application of the
  results to the theory of atomic structure}.
\bjtitle{The London, Edinburgh, and Dublin Philosophical Magazine and Journal
  of Science}
\bvolume{7}(\bissue{39}),
\bfpage{237}--\blpage{265}
(\byear{1904}).
\doiurl{10.1080/14786440409463107}
\end{barticle}
\endbibitem

%%% 95
\bibitem{liuLearningMinimumHyperspherical2018}
\begin{bchapter}
\bauthor{\bsnm{Liu}, \binits{W.}},
\bauthor{\bsnm{Lin}, \binits{R.}},
\bauthor{\bsnm{Liu}, \binits{Z.}},
\bauthor{\bsnm{Liu}, \binits{L.}},
\bauthor{\bsnm{Yu}, \binits{Z.}},
\bauthor{\bsnm{Dai}, \binits{B.}},
\bauthor{\bsnm{Song}, \binits{L.}}:
\bctitle{Learning towards minimum hyperspherical energy}.
In: \bbtitle{Proceedings of the 32nd {{International Conference}} on {{Neural
  Information Processing Systems}}}.
\bsertitle{{{NIPS}}'18},
pp. \bfpage{6225}--\blpage{6236}.
\bpublisher{Curran Associates Inc.},
\blocation{Red Hook, NY, USA}
(\byear{2018})
\end{bchapter}
\endbibitem

%%% 96
\bibitem{kuijlaarsAsymptoticsMinimalDiscrete1998b}
\begin{barticle}
\bauthor{\bsnm{Kuijlaars}, \binits{A.}},
\bauthor{\bsnm{Saff}, \binits{E.}}:
\batitle{Asymptotics for minimal discrete energy on the sphere}.
\bjtitle{Transactions of the American Mathematical Society}
\bvolume{350}(\bissue{2}),
\bfpage{523}--\blpage{538}
(\byear{1998}).
\doiurl{10.1090/S0002-9947-98-02119-9}
\end{barticle}
\endbibitem

%%% 97
\bibitem{saxeExactSolutionsNonlinear2014a}
\begin{botherref}
\oauthor{\bsnm{Saxe}, \binits{A.M.}},
\oauthor{\bsnm{McClelland}, \binits{J.L.}},
\oauthor{\bsnm{Ganguli}, \binits{S.}}:
Exact Solutions to the Nonlinear Dynamics of Learning in Deep Linear Neural
  Networks.
arXiv.
Comment: Submission to ICLR2014. Revised based on reviewer feedback
(2014).
\doiurl{10.48550/arXiv.1312.6120}
\end{botherref}
\endbibitem

%%% 98
\bibitem{huberRobustEstimationLocation1964}
\begin{barticle}
\bauthor{\bsnm{Huber}, \binits{P.J.}}:
\batitle{Robust {{Estimation}} of a {{Location Parameter}}}.
\bjtitle{The Annals of Mathematical Statistics}
\bvolume{35}(\bissue{1}),
\bfpage{73}--\blpage{101}
(\byear{1964}).
\doiurl{10.1214/aoms/1177703732}
\end{barticle}
\endbibitem

\bibitem{eybpooshApplyingInverseStereographic2022a}
\begin{barticle}
\bauthor{\bsnm{Eybpoosh}, \binits{K.}},
\bauthor{\bsnm{Rezghi}, \binits{M.}},
\bauthor{\bsnm{Heydari}, \binits{A.}}:
\batitle{Applying inverse stereographic projection to manifold learning and
  clustering}.
\bjtitle{Applied Intelligence}
\bvolume{52}(\bissue{4}),
\bfpage{4443}--\blpage{4457}
(\byear{2022}).
\doiurl{10.1007/s10489-021-02513-0}
\end{barticle}
\endbibitem

%%% 102
\bibitem{hendrycksGaussianErrorLinear2023}
\begin{botherref}
\oauthor{\bsnm{Hendrycks}, \binits{D.}},
\oauthor{\bsnm{Gimpel}, \binits{K.}}:
Gaussian {{Error Linear Units}} ({{GELUs}}).
arXiv.
Comment: Trimmed version of 2016 draft
(2023).
\doiurl{10.48550/arXiv.1606.08415}
\end{botherref}
\endbibitem

%%% 99
\bibitem{hashemiPixelVertexDetector2023}
\begin{botherref}
\oauthor{\bsnm{Hashemi}, \binits{B.}}:
Ultra-High Granularity Pixel Vertex Detector (PXD) Signature Images.
In: \textit{Machine Learning and the Physical Sciences, NeurIPS 2022)},
Zenodo,
Version v1.
\doiurl{10.5281/zenodo.8331919}
(2023)
\end{botherref}
\endbibitem

%%% 100
\bibitem{hashemiIEAGAN2024}
\begin{botherref}
\oauthor{\bsnm{Hashemi}, \binits{B.}}:
Hosein47/IEA-GAN: IEA-GAN v1.
In: \textit{Nature Communications},
Zenodo.
\doiurl{10.5281/zenodo.11070305}
(2024)
\end{botherref}
\endbibitem



\end{thebibliography}

\section*{Acknowledgments}
This research was supported by the collaborative project IDT-UM~(Innovative Digitale Technologien zur Erforschung von Universum und Materie) and KISS consortium funded by the German Federal Ministry of Education and Research~(BMBF) and the Deutsche Forschungsgemeinschaft under Germany's Excellence Strategy  EXC 2094 ORIGINS  390783311. James Kahn's work is supported by the Helmholtz Association Initiative and Networking Fund under the Helmholtz AI platform grant. BH and SS wish to express their gratitude to Volker Tresp for the valuable discussions that enriched this work. 
We also thank David Katheder for his assistance with preparing the GitHub repository. We thank our colleagues from the Ludwig Maximilian University in Munich and the Computational Center for Particle and Astrophysics~(C2PAP), who provided expertise and computation power that greatly assisted the research.

\section*{Author Contributions}
B.H. designed and implemented the main idea of the research, conducted all the experimental runs, performed the downstream physics analysis, and wrote the manuscript. 
N.H., S.S., and T.K. contributed to maturing the research idea at various stages.
N.H. contributed to several parts of the code, plots, data analysis pipeline, and validation of the results.
T.K. guided the physics analysis and validation of the results.
J.K. guided and conducted the development of the manuscript and plots at all stages. All authors have reviewed and commented on the manuscript.

\section*{Competing interests}
The authors declare no competing interests.
\end{document}
