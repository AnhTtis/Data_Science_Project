% autosam.tex
% Annotated sample file for the preparation of LaTeX files
% for the final versions of papers submitted to or accepted for 
% publication in AUTOMATICA.

% See also the Information for Authors.

% Make sure that the zip file that you send contains all the 
% files, including the files for the figures and the bib file.

% Output produced with the elsart style file does not imitate the
% AUTOMATICA style. The style file is generic for all Elsevier
% journals and the output is laid out for easy copy editing. The
% final document is produced from the source file in the
% AUTOMATICA style at Elsevier.

% You may use the style file autart.cls to obtain a two-column 
% document (see below) that more or less imitates the printed 
% Automatica style. This may helpful to improve the formatting 
% of the equations, tables and figures, and also serves to check 
% whether the paper satisfies the length requirements.

% Please note: Authors must not create their own macros.

% For further information regarding the preparation of LaTeX files 
% for Elsevier, please refer to the "Full Instructions to Authors" 
% from Elsevier's anonymous ftp server on ftp.elsevier.nl in the
% directory pub/styles, or from the internet (CTAN sites) on
% ftp.shsu.edu, ftp.dante.de and ftp.tex.ac.uk in the directory
% tex-archive/macros/latex/contrib/supported/elsevier.


%\documentclass{elsart}               % The use of LaTeX2e is preferred.

\documentclass[twocolumn]{autart}    % Enable this line and disable the 
                                     % preceding line to obtain a two-column 
                                     % document whose style resembles the
                                     % printed Automatica style.

\usepackage{enumitem}
\def\rddots#1{\cdot^{\cdot^{\cdot^{#1}}}}
\usepackage{graphicx}          % Include this line if your 
                               % document contains figures,
%\usepackage[dvips]{epsfig}    % or this line, depending on which
                               % you prefer.
\usepackage{amsmath,amssymb,amsfonts} 
\theoremstyle{plain}
\newtheorem{theorem}{thm}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assume}[theorem]{Assumption}
\newtheorem{remark}[theorem]{Remark}
\usepackage{xcolor}
\usepackage{hyperref}

\begin{document}

\begin{frontmatter}
%\runtitle{Insert a suggested running title}  % Running title for regular 
                                              % papers but only if the title  
                                              % is over 5 words. Running title 
                                              % is not shown in output.

\title{Randomized Matrix Weighted Consensus\thanksref{footnoteinfo}} % Title, preferably not more 
                                                % than 10 words.

\thanks[footnoteinfo]{This paper was not presented at any IFAC 
meeting. Corresponding author: M.~H.~Trinh.}

\author[Viettel,HUST]{Nhat-Minh Le-Phan}\ead{minh.lpn221013m@sis.hust.edu.vn},    % Add the 
\author[HUST]{Minh Hoang Trinh}\ead{minh.trinhhoang@hust.edu.vn}, 
\author[HUST]{Phuoc Doan Nguyen}\ead{phuoc.nguyendoan@hust.edu.vn}  % (ead) as shown
            % e-mail address 

\address[Viettel]{Navigation, Guidance and Control
Technologies Center, Viettel Aerospace Institute, Hanoi, Vietnam}  % Please supply                                              
\address[HUST]{Department of Automation Engineering, School of Electrical and Electronic Engineering, Hanoi, Vietnam}             % full addresses
%\address[Baiae]{The White House, Baiae}        % here.

          
\begin{keyword}                           % Five to ten keywords,  
Matrix-weighted consensus; 	multi-agent systems; gossip; randomized algorithms.               % chosen from the IFAC 
\end{keyword}                             % keyword list or with the 
                                          % help of the Automatica 
                                          % keyword wizard


\begin{abstract}                          % Abstract of not more than 200 words.
In this paper, a randomized gossip-type matrix-weighted consensus algorithm is proposed for both leaderless and leader-follower topologies. Under some mild assumptions, the proposed pairwise asynchronous update algorithm achieves a consensus in expectation. Moreover, the probability distribution, the weighting matrices, and the updating step size jointly determine the upper bound of the $\epsilon$-convergence time of the algorithm. The theoretical result is verified by several simulation examples.
\end{abstract}

\end{frontmatter}

\section{Introduction}
\label{sec:intro}
In recent years, cooperative control of multi-agent systems has been widely studied, in which consensus algorithms are essential for various applications \cite{Olfati2007consensuspieee} such that formation control, network localization, distributed estimation, synchronization, and social networks, \ldots 

In a networked system, the dynamics of each agent in the system are often described by a vector of more than one state variable, and there may exist cross-layer couplings between these variables of the agents. The authors in \cite{THM2018} proposed a matrix-weighted consensus algorithm, in which each pair-wise interaction between neighboring agents is associated with a symmetric nonnegative matrix weight. The matrix-weighted consensus, thus, is a generalization of the scalar-weighted consensus algorithm. Corresponding to a matrix-weighted consensus system, one may define a matrix-weighted graph and a matrix-weighted Laplacian. It has been shown that algebraic graph properties of the matrix-weighted Laplacian determine the consensus and clustering behaviors of the whole system \cite{Barooah2006graph,Kwon2020matrix,Pan2020controllability,Nguyen2022MCA}. Several applications of the matrix-weighted consensus algorithm can be found in the literature. For example, the authors in \cite{Ahn2020opinion,Ye2020Aut} propose multi-dimensional opinion dynamics, where the interactions and inter-logical dependencies between several considered topics are captured by matrix weights, respectively. In bearing-based formation control and network localization \cite{Zhao2015MSC,zhao2016aut}, the interactions between neighboring agents are modeled by an orthogonal projection matrix obtained from the directional (or bearing) vector between neighboring agents. Also, the author in \cite{Tuna2016aut} considers the synchronization of multi-dimensional mechanical and electrical systems where the subsystems interact via positive semidefinite matrix weights. 

%The authors in \cite{Kwon2020matrix} exploited the detailed interlayer graph to find several graphical conditions for reaching a consensus and clustering. Controllability and observability of matrix-weighted consensus were studied in \cite{Pan2020controllability}. 
%The authors in \cite{Foight2020performance} propose a simple method to synthesize matrix-weighted networks based on $\mathcal{H}_2$ norm of the system. Ye el. al. proposed two multi-dimensional opinion dynamic models where the cognitive process is captured by a homogeneous logic matrix \cite{Ye2020Aut}. 
% Another multi-dimensional consensus model using matrix weights was proposed in \cite{Ahn2020opinion}, where the strength of interactions has been captured with state-dependent matrix weights. In formation control and network localization, the rigidity of a framework can be determined from the bearing Laplacian, of which each block is an orthogonal projection matrix. The kernel of the bearing Laplacian always has an extra eigenvector corresponding to the scaling motion of the framework \cite{zhao2016aut}. 
%Matrix-weighted consensus with switching network topologies, with acyclic directed topology, second-order agent dynamics, and with discrete-time updates was also studied, see for examples  \cite{Pan2021consensus,Miao2021second,quoc2021}. %\textcolor{red}{:Not yet completed.}

It is noteworthy that most existing works on matrix-weighted consensus assumed that the agents update their states synchronously or following a deterministic update sequence. Continuous-time matrix-weighted consensus with switching graph topologies was studied in \cite{Pan2021consensus}. Discrete-time matrix-weighted consensus with fixed or switching topologies was studied in \cite{quoc2021}. Matrix-weighted consensus with hybrid continuous-discrete time updates was examined in \cite{Miao2022consensus}.

% \textcolor{blue}{I would suggest using the terminology ``randomized'' rather than ``stochastic'' since all cited related works are using this term. Please take a look at the wikipedia and consult Prof. Phuoc for his input on the use of these terms.\\
% \url{https://en.wikipedia.org/wiki/Randomized_algorithm} \\
% \url{https://en.wikipedia.org/wiki/Stochastic_control}
% } \textcolor{red}{After reading two definitions in the above links, I think your suggestion is reasonable. }

%\textcolor{red}
{The randomized consensus algorithms, which refer to a family of consensus algorithms in which the edges between agents are randomly selected according to some stochastic model for every discrete instant, have received a lot of attention in the literature \cite{FB-LNS}. These algorithms, with their immense simplicity and reliability, have been successfully implemented for many applications in the next generation of networks, such as social networks, sensor networks, and peer-to-peer networks,... The randomized gossip algorithm, which is proposed in \cite{boyd2006}, was a significant step toward solving the average consensus problem in a randomized manner. Many approaches have been proposed based on \cite{boyd2006} to enhance its convergence speed as well as robustness, see for example, \cite{5625615,TIT2010,1238221} on geographic gossip; \cite{HE20118718,7887729,LABAHN1994235} on periodic gossiping; \cite{7581065,4787122} on broadcast gossip; \cite{8946047} on reduce the probability of selecting duplicate nodes ... However, these studies only cover the situation when the connecting weights between agents are scalar, i.e., they do not have the ability to deal with the coupling mechanism when each agent has more than one state variable.}

%Differently from existing works in the literature, we consider a matrix-weighted consensus network where each update in the network involves at most two agents and follows a stochastic process. 
The main contribution of this paper is that it generalizes the scalar gossip algorithm proposed in \cite{boyd2006}. To the best of our knowledge, this is the first article regarding randomized and asynchronous update approaches for matrix-weighted multi-agent systems. Compared to the existing works on randomized consensus, this paper takes into consideration the coupling effect between agents' channels, which is useful for a variety of applications, including formation control and network localization. Additionally, to guarantee the consensus, \cite{boyd2006,5340530} require constraints regarding the first two moments of the updating matrix; these constraints are difficult to comprehend \cite{FRASCA20132496}. The consensus sufficient conditions in this research, which are based on the connectivity of the underlying graph, are more intuitive and simple to test.


\section{Preliminaries and problem formulation}
\label{sec:prel}
\subsection{Matrix-weighted graph}
A matrix-weighted graph is denoted by $ \mathcal{G}=(V,E,A)$, where, $V=\left\{ 1,2,...,n\right\}$ is the vertex set (agents), $E\subseteq V\times V$ is the edge set, and 
$A=\{ \mathbf{A}_{ij} \in \mathbb{R}^{d \times d}|~(i,j) \in E\}$ denotes the set of matrix weights. $d \geq 1$ is the dimension of each agent's state vector. When $d = 1$, $\mathcal{G}$ reduces to a scalar graph. The interactions between any two agents in $\mathcal{G}$ are captured by the corresponding matrix weights: if $i$ and $j$ are connected, there is a symmetric positive definite/positive semi-definite matrix weight $\mathbf{A}_{ij}=\mathbf{A}_{ij}^\top\geq 0$; and if $i$ and $j$ are disconnected, then  $\mathbf{A}_{ij} = \mathbf{0}_{d\times d}$. 

First, we define $\mathbf{D}_{i}= \sum_{j \in V} \mathbf{A}_{ij}$ as the matrix-degree of vertex $i$, and $\mathbf{D} = \text{blkdiag}(\mathbf{D}_{1}, \ldots,\mathbf{D}_{n})$ the \emph{degree matrix} of $\mathcal{G}$. The \emph{matrix-weighted Laplacian} is then defined as $\mathbf{L} = \mathbf{D} - \mathbf{A} \in \mathbb{R}^{nd \times nd}$. We also provided a number of new definitions that will be used throughout this study. Defining $\mathbf{M}_{ij}=\frac{1}{n}(\mathbf{A}_{ij} {\rm P}_{ij}+\mathbf{A}_{ji} {\rm 
 P}_{ji})$ as the \emph{expected weight} between $i$ and $j$, and $\mathbf{A}^{\text{M}}=[\mathbf{M}_{ij}]$ as the \emph{expected adjacency matrix} of $\mathcal{G}$. It is obvious that $\mathbf{M}_{ij}=\mathbf{M}_{ji}=\mathbf{M}_{ij}^{\top} \geq 0$. We call an edge $(i,j)$ positive definite (resp., positive semi-definite) if the related expected weight $\mathbf{M}_{ij}$ is positive definite (resp., positive semi-definite). The \emph{expected degree matrix} is defined as $\mathbf{D}^{\text{M}}= \text{blkdiag}(\mathbf{D}^{\text{M}}_{1},\ldots,\mathbf{D}^{\text{M}}_{n})$, whereas $\mathbf{D}^{\text{M}}_{i}= \sum_{j \in V}\mathbf{M}_{ij}$. Then, $\mathbf{L}^{\text{M}} = \mathbf{D}^{\text{M}}-\mathbf{A}^{\text{M}} \in \mathbb{R}^{nd \times nd}$ is the \emph{expected Laplacian matrix} of $\mathcal{G}$. An \emph{expected path} is a sequence of vertices in $\mathcal{G}$ denoted by $\mathcal{P}=i_1,i_2,...,i_l$ such that $\mathbf{M}_{i_{k}i_{k+1}} \geq 0, k=1,...,l-1$. 
%Note that an expected path is undirected. 
An \emph{expected tree} is a graph (with at least one vertex) where every pair of agents is connected by exactly one expected path.

\begin{definition}
\emph{(Expected positive path)} An expected positive path in $\mathcal{G}$ is an expected path $\mathcal{P}=i_1,i_2,...,i_l$ such that $\mathbf{M}_{i_{k}i_{k+1}} > 0,~k=1,...,l-1$. 
\end{definition}

\begin{definition}
\emph{(Expected positive tree)} An expected positive tree in $\mathcal{G}$ is an expected tree $\mathcal{T}$ such that for all $i,j \in \mathcal{T}$, there exists exactly an expected positive path in $\mathcal{T}$ connecting i and j.
\end{definition}
\begin{definition}
\emph{(Expected positive spanning tree)} An expected positive spanning tree $\mathcal{T}$ in $\mathcal{G}$ is an expected positive tree containing all vertices in V.
\end{definition}
\begin{lemma}\label{nullspace}
\emph{\cite{THM2018}}
The expected Laplacian matrix $\mathbf{L}^{\rm M}$ is symmetric and positive semi-definite, and its null space is given as:
  ${\rm null}(\mathbf{L}^{\rm M}) = {\rm span}\{ {\rm range}(\mathbf{1}_n \otimes \mathbf{I}_d), \{ \mathbf{v}=[v_1^\top,\dots, v_n^\top]^\top \in \mathbb{R}^{nd}|~(v_j-v_j)\in {\rm null}(\mathbf{M}_{ij}), \forall (i,j) \in E \} \}$.
\end{lemma}
\subsection{Randomized distributed protocol}
In this section, we describe the basic protocol that will be used for the rest of this article, which can be found in \cite{ishii2010}. Consider the multiagent system from the previous section. The random manner is specified by the random process $\gamma(k)\in V$ where $k\in \mathbb{Z}_{+}$ is called time slot. At time slot $k$, $\gamma(k) = i$ indicates that agent $i$ wakes up, then it will choose another neighbor $j$ with a probability $P_{ij}$ to communicate, and both agents update their state values. $\gamma(k)$ is assumed to be i.i.d., and its probability distribution is given by
\begin{equation}\label{manner}
{\rm P}(\gamma(k)=i)=\frac{1}{n}, \forall k\in \mathbb{Z}_{+}.
\end{equation}
This means the distribution of agents choosing to wake up at any time slot is uniform. This protocol can be implemented distributively by giving each agent an independent clock that ``ticks'' (wakes the agent up) at the times of an identical stochastic process. For example, \cite{boyd2006} sets a clock that
``ticks'' are distributed as a rate 1 Poisson process for each agent. In this paper, we do not restrict to any particular stochastic process for the purpose of simplicity. Because time slots are the only instances when the value of each agent changes \cite{boyd2006}, we will utilize them as a new time axis in all of our results. The matrix-weighted consensus laws for both leaderless and leader-following topologies based on the discussed protocol will be introduced in the next section.
\begin{lemma}
\emph{(Markov inequality)} If a random variable X can only take non-negative values, then \cite{prob}:
   $${\rm P}(X>a) \leq \frac{{{\rm E}}[X]}{a}, \ \  \forall a >0,$$
where ${\rm E}[X]$ is the expectation of X.
\end{lemma}
\section{Randomized matrix weighted consensus with Leaderless topology}
\label{sec:leaderless}
In this section, we propose the randomized matrix weighted consensus law with leaderless topology as follows:
Consider a system consisting of $n$ agents whose interconnections between agents are $\mathbf{A}_{ij}\in\mathbb{R}^{d\times d}$. Each agent $i\in V$ stores its own local vector $\overline{x}_i \in \mathbb{R}^d$. When an agent $i$ wakes up at the $k^{\text{th}}$ time slot, it will contact a neighbor $j$ with a probability ${\rm P}_{ij}$ and both agents will update their current state vector as:
\begin{equation}\label{algorithm1}
    \begin{aligned}
    \overline{x}_i(k+1)&=\overline{x}_i(k)-\alpha_i \mathbf{A}_{ij}\big(\overline{x}_i(k)-\overline{x}_j(k)\big)\\
    \overline{x}_j(k+1)&=\overline{x}_j(k)-\alpha_j \mathbf{A}_{ij}\big(\overline{x}_j(k)-\overline{x}_i(k)\big)\\
    \end{aligned}
\end{equation}
where $\alpha_i > 0$ is updating step size of agent $i$, and will be designed later.
\begin{assume}\label{pii}
When an agent wakes up, it has to find another agent to exchange information, that is, $P_{ii}=~ 0$ for all $i\in V$.
\end{assume}
Denote $\overline{\mathbf{x}}(k) = \text{vec}(\overline{\mathbf{x}}_i(k))$, (\ref{algorithm1}) can be rewritten as follow:
\begin{equation}\label{algorithm11}
    \overline{\mathbf{x}}(k+1)=W_{ij}\overline{\mathbf{x}}(k),
\end{equation}
where $W_{ij}$ is a block matrix: 
\begin{equation}\label{algorithm12}
W_{ij}=\begin{bmatrix}
    &\mathbf{I}_d        &\cdots     &\mathbf{O}_d             &\cdots    &\mathbf{O}_d &\cdots &\mathbf{O}_d \\
    &\vdots     &\ddots     &\vdots          &\ddots    &\vdots &\ddots &\vdots \\
    &\mathbf{O}_d        &\cdots  &\mathbf{I}_d-\alpha_i \mathbf{A}_{ij} &\cdots    &\alpha_i \mathbf{A}_{ij} &\cdots &\mathbf{O}_d  \\
    &\vdots     &\ddots     &\vdots          &\ddots    &\vdots &\ddots &\vdots \\
    &\mathbf{O}_d        &\cdots  &\alpha_j \mathbf{A}_{ij} &\cdots    &\mathbf{I}_d-\alpha_j\mathbf{A}_{ij} &\cdots &\mathbf{O}_d  \\
    &\vdots     &\ddots     &\vdots          &\ddots    &\vdots &\ddots &\vdots \\
    &\mathbf{O}_d        &\cdots     &\mathbf{O}_d             &\cdots    &\mathbf{O}_d &\cdots &\mathbf{I}_d
\end{bmatrix}
\end{equation}
in which $\mathbf{I}_d$ denotes the $d\times d$ identity matrix, $\mathbf{O}_d$ denotes the $d\times d$ zero matrix, $\mathbf{I}_d-\alpha_i \mathbf{A}_{ij}$ is the block entry of matrix $W_{ij}$ in the $({i(d-1)+1:id})^{\text{th}}$ rows
and $({i(d-1)+1:id})^{\text{th}}$ columns. Block $\mathbf{I}_d-\alpha_j \mathbf{A}_{ij}$ is in the $({j(d-1)+1:jd})^{\text{th}}$ rows
and $({j(d-1)+1:jd})^{\text{th}}$ columns of $W_{ij}$. Due to the symmetry of $\mathbf{A}_{ij}$, $W_{ij}$ is also symmetric.

At a random $k^{\text{th}}$ time slot, we can write:
\begin{equation}\label{algorithm13}
\overline{\mathbf{x}}(k+1)=W(k)\overline{\mathbf{x}}(k),
\end{equation}
where the random variable $W(k)$ is drawn i.i.d from some distribution on the set of possible values $W_{ij}$ \cite{boyd2006}. Note that the probability that $W(k)$ takes a specific value $W_{ij}$ is $\frac{1}{n}{\rm P}_{ij}$ (the probability that agent $i$ will wake up at $k^{\text{th}}$ time slot is $\frac{1}{n}$, and the probability that $j$ will be chosen by $i$ is ${\rm P}_{ij}$). The expectation of $W(k)$ is thus obtained as
\begin{equation}
    \begin{aligned}
        \overline{W}={\rm E}[W]=\sum_{i \in V}\sum_{j \in V} \frac{1}{n}{\rm P}_{ij} W_{ij}.
    \end{aligned}
\end{equation}
The block entries of $\overline{W}$ are determined as follow:
\begin{itemize}
    \item If $i=j$, then:
    \begin{align*}
        \overline{W}&(i,i)=\bigg(1-\frac{1}{n}\sum_{j\in V}({\rm P}_{ij}+{\rm P}_{ji})\bigg)\mathbf{I}_d \nonumber\\
        &+\frac{1}{n}\sum_{j \in V}\big({\rm P}_{ij}(\mathbf{I}_d-\alpha_i \mathbf{A}_{ij})+{\rm P}_{ji}(\mathbf{I}_d-\alpha_i \mathbf{A}_{ji})\big) \nonumber\\
        &\qquad= \mathbf{I}_d - \alpha_i\frac{1}{n}\sum_{j \in V}({\rm P}_{ij} \mathbf{A}_{ij}+{\rm P}_{ji} \mathbf{A}_{ji}) \nonumber\\
        &\qquad= \mathbf{I}_d-\alpha_i\sum_{j \in V}\mathbf{M}_{ij}.
    \end{align*}
    \item If $i \neq j$:
\begin{align*}
\overline{W}(i,j)&=\frac{\alpha_i}{n} %\sum_{j \in V}
({\rm P}_{ij} \mathbf{A}_{ij} + {\rm P}_{ji} \mathbf{A}_{ji}) =\alpha_i 
\mathbf{M}_{ij}.
\end{align*}
\end{itemize}
As a result, \eqref{algorithm13} can be rewritten as:
\begin{equation}\label{wbar}
\overline{W}=\mathbf{I}_{dn} - \mathbf{G}(\mathbf{D}^{\text{M}}-\mathbf{A}^\text{M}),
\end{equation}
where $\mathbf{G}=\text{blkdiag}\left\{\alpha_i\mathbf{I}_d\right\}_{i=1}^n$.
\subsection{Convergence in expectation}
The solution of (\ref{algorithm13}) can be easily obtained as:
\begin{equation}\label{sol}
\overline{\mathbf{x}}(k+1) = \underbrace{W(k)W(k-1)\dots W(0)}_{:=\phi(k)} \overline{\mathbf{x}}(0).
\end{equation}
In order to prove the convergence in expectation, we consider the mean of $\phi(k)$
\begin{equation}\label{mean}
    \begin{aligned}
        {\rm E}[\phi(k)]&={\rm E}[W(k)W(k-1)\dots W(0)] \\
        &={\rm E}[W(k)]{\rm E}[W(k-1)]\dots{\rm E}[W(0)]\\
        &=\overline{W}^{k+1}=\big(\mathbf{I}_{dn}-\mathbf{G}(\mathbf{D}^\text{M}-\mathbf{A}^\text{M})\big)^{k+1}.
    \end{aligned}
\end{equation}
Thus, to investigate the convergence of $\overline{\mathbf{x}}(k)$, the spectral properties of $\overline{W}$ should be analyzed. Similar to \cite{quoc2021}, the following lemma is obtained
\begin{lemma}\label{stepsize}
Select the step sizes such that $\alpha_i < \frac{1}{\lVert \mathbf{D}^{{\rm M}}_{i} \rVert}$, the matrix $\overline{W}= \mathbf{I}_{dn}-\mathbf{G}(\mathbf{D}^{\rm M}-\mathbf{A}^{\rm M})$ satisfies the following properties:
\begin{itemize}
    \item All eigenvalues of $\overline{W}$ lie in the range $(-1,1]$ and the spectral radius is $\rho(\overline{W})=1$ with the corresponding eigenvectors that are $\mathbf{\textit{v}}\in {\rm null}(\mathbf{L}^{\rm M})$.
    \item The unity eigenvalue 1 of $\overline{W}$ is semi-simple, and $\overline{W}^{\infty}:=\lim_{k\to \infty} \overline{W}^{k}$ exists and is finite. 
\end{itemize}
\end{lemma}
Regarding the existence of $\overline{W}^{\infty}$, we have \cite{quoc2021}:
\begin{equation}
    \begin{aligned}
        \overline{W}^{\infty}&=(\mathbf{V}\mathbf{J}\mathbf{V}^{-1})^{\infty}=\mathbf{VJ^{\infty}V^{-1}}\\
        &=\mathbf{V}\text{blkdiag}(1,\dots,1,\mathbf{J}_{l_2}^{\infty},\dots,\mathbf{J}_{l_p}^{\infty})\mathbf{V}^{-1}\\
        &=\mathbf{V}\text{blkdiag}(1,\dots,1,0,\dots,0)\mathbf{V}^{-1}\\
        &=\sum_{i=1}^{l_1}v_i u_i^{\top},
    \end{aligned}
\end{equation}
where $\mathbf{V}=[v_1,\dots,v_{dn}]$ and $\mathbf{V}^{-1}=[u_1,\dots,u_{dn}]^{\top}$ contain the left and right eigenvectors of $\overline{W}$, respectively. The eigenvectors corresponding to unity eigenvalues appear earlier. The Jordan form 
$\mathbf{J}=\text{blkdiag}(1,\dots,1,\mathbf{J}_{l_2},\dots,\mathbf{J}_{l_p}) \in \mathbb{R}^{dn\times dn}$ contains Jordan blocks $\mathbf{J}_{l_i},i=2,\ldots,p,$ corresponding to the eigenvalues $\lambda_i$ with magnitudes strictly smaller than 1.
\begin{thm}\label{conthm}
Select the step sizes to satisfy Lemma~\ref{stepsize}. With an arbitrary initial state vector $\mathbf{\overline{x}}(0)$, the solution $\mathbf{\overline{x}}(k)$ of \eqref{sol} converges in the expectation to $\mathbf{\overline{x}}^{*}=\mathbf{1}_n\otimes \big([\mathbf{\textit{u}}_1, \mathbf{\textit{u}}_2,\dots,\mathbf{\textit{u}}_d]^\top \mathbf{x}(0) \big)$, if and only if {\rm null}$(\mathbf{L}^{\rm M})=${\rm range}$(\mathbf{1}_n \otimes \mathbf{I}_d)$.
\end{thm}
\begin{remark} \cite{THM2018} The existence of an expected positive spanning tree in $ \mathcal{G}$ is a sufficient condition for ${\rm null}(\mathbf{L}^{\rm M})={\rm range}(\mathbf{1}_n\otimes \mathbf{I}_d)$.
 \end{remark}
 \subsection{Randomized matrix weighted average consensus}
 When all agents choose the same updating step size $\alpha$, the matrix $\overline{W}$ becomes symmetric, and $\mathbf{V}^{\top}=\mathbf{V}^{-1}$. The following theorem yields
 \begin{thm}\label{avconthm}
Suppose that all agents use the same step size $\alpha < \frac{1}{\max_{i\in V}\lVert \mathbf{D}^{\rm M}_{i} \rVert}$. With an arbitrary initial state vector $\mathbf{\overline{x}}(0)$, the solution $\mathbf{\overline{x}}(k)$ of (\ref{sol}) converges in expectation to the average vector $\mathbf{\overline{x}}^{*}= \mathbf{1}_n \otimes \hat{\mathbf{x}}$, where $\hat{\mathbf{x}}=\frac{1}{n}\big(\mathbf{1}_n^\top\otimes \mathbf{I}_d\big)\mathbf{\overline{x}}(0)$, if and only if {\rm null}$(\mathbf{L}^{\rm M})={\rm range}(\mathbf{1}_n\otimes \mathbf{I}_d)$.
\end{thm}
Although we have shown that, with graph $\mathcal{G}$ satisfying a mild assumption and the step size is  small enough, it is guaranteed that the agents reach the average consensus in expectation. However, we have not yet mentioned the convergence rate of these agents. The following section  will describe a method to quantify the average convergence rate of agents. It will be shown that the convergence rate of the agents is closely related to the second-largest amplitude eigenvalue of the matrix ${\rm E}[W(k)^\top W(k)]$. Inspired by \cite{boyd2006}, we first introduce our quantity of interest
\begin{definition}
 \emph{($\epsilon$-consensus time)} For any $0<\epsilon<1$, the $\epsilon$-consensus time is defined as:
\begin{equation}
\begin{aligned}
    T(\epsilon)=\underset{\overline{\mathbf{x}}(0)}{\sup}\inf \bigg( k:{\rm P}\bigg(\frac{\lVert \mathbf{\overline{x}}(k)-\mathbf{1}_n\otimes \hat{\mathbf{\overline{x}}} \rVert}{\lVert \mathbf{\overline{x}}(0)-\mathbf{1}_n\otimes \hat{\mathbf{\overline{x}}} \rVert} \geq \epsilon\bigg)\leq \epsilon\bigg)
\end{aligned}
\end{equation}
\end{definition}
Intuitively, $T({\epsilon})$ represents the number of clock ticks needed for the trajectory $\mathbf{\overline{x}}$ to reach the consensus value with a high probability. It is worth noting that $\epsilon$ measures both accuracy and success probability and is often set to $\frac{1}{n}$ \cite{TIT2010}. In this paper, we provide the upper bound formula for the proposed average consensus algorithm. Firstly, the convergence of the second moment should be proved.
\subsubsection{Convergence of the second moment}
Define the error vector $\mathbf{\overline{y}}(k)=\mathbf{\overline{x}}(k)-\mathbf{1}_n\otimes \hat{\mathbf{\overline{x}}}$, we have
\begin{equation}\label{y}
\begin{aligned}
    \mathbf{\overline{y}}(k+1)&= \mathbf{\overline{x}}(k+1)-\mathbf{1}_n\otimes \hat{\mathbf{\overline{x}}}\\
%    &=W(k)\mathbf{\overline{x}}(k)-\mathbf{1}_n\otimes \mathbf{I}_d\hat{\mathbf{\overline{x}}}\\
%    &=W(k)\mathbf{\overline{x}}(k)-(\mathbf{1}_n\otimes \mathbf{I}_d)\hat{\mathbf{\overline{x}}}\\    
    &=W(k)\mathbf{\overline{x}}(k)-W(k)(\mathbf{1}_n\otimes \mathbf{I}_d)\hat{\mathbf{\overline{x}}}\\  
%    &=W(k)\big(\mathbf{\overline{x}}(k)-(\mathbf{1}_n\otimes \mathbf{I}_d)\hat{\mathbf{\overline{x}}}\big)\\
%    &=W(k)\big(\mathbf{\overline{x}}(k)-\mathbf{1}_n\otimes \hat{\mathbf{\overline{x}}}\big)\\  
    &=W(k)\mathbf{\overline{y}}(k)
\end{aligned}
\end{equation}
Thus, $\mathbf{\overline{y}}(k)$ has the same linear system as $\mathbf{\overline{x}}(k)$. From \eqref{y}, we have the following equation \cite{boyd2006}
\begin{equation}\label{minh}
    \begin{aligned}
        {\rm E}[\mathbf{\overline{y}}(k+1)^{\top}\mathbf{\overline{y}}(k+1)|\mathbf{\overline{y}}(k)]
        = \mathbf{\overline{y}}(k)^{\top}{\rm E}[W(k)^{\top}W(k)]\mathbf{\overline{y}}(k)
    \end{aligned}
\end{equation}
Similar to $W(k)$, we can consider $W(k)^\top W(k)$ as a random variable which is drawn i.i.d from some distribution on the set of possible values $W_{ij}^\top W_{ij}$. Some properties of ${\rm E}[W(k)^\top W(k)]$ are provided by the following lemmas.
 \begin{lemma}\label{stepsizeav}
Let the step size for each agent satisfy $\alpha < \underset{i,j}{\min}(\frac{1}{\max\lVert \mathbf{D}^{\rm M}_{i} \rVert},\frac{1}{\max\lVert \mathbf{A}_{ij} \rVert})$, the following statements hold
\begin{enumerate}[label=(\roman*)]
    \item The set of all real symmetric matrices with eigenvalues in $[0,1]$ is convex. Every possible matrix $W_{ij}^\top W_{ij}$ is in this set.
    \item ${\rm E}[W(k)^\top W(k)]$ has a unity spectral radius, and its unity eigenvalues are semi-simple.
    \item $\mathbf{1}_n \otimes\mathbf{I}_d$ are 
only $d$ orthogonal right eigenvectors corresponding to the unity eigenvalue $\lambda=1$ of ${\rm E}[W(k)^\top W(k)]$ if and only if {\rm null}$(\mathbf{L}^{\rm M})= {\rm range}(\mathbf{1}_n\otimes \mathbf{I}_d)$.
\end{enumerate}
    
\textit{Proof:} See Appendix A.
\end{lemma}
Under the assumption null$(\mathbf{L}^{\text{M}})=\text{range}(\mathbf{1}_n\otimes \mathbf{I}_d)$ on our hand, $[v_1,\dots,v_d] =\mathbf{1}_n \otimes\mathbf{I}_d$ are 
only $d$ orthogonal right eigenvectors corresponding to the unity eigenvalue $\lambda=1$ of ${\rm E}[W(k)^\top W(k)]$. By reason of $\mathbf{\overline{y}}(k)\perp \text{span}\big( v_1,\dots,v_d \big)$, the Rayleigh-Ritz theorem \cite{matrix} states that
%\begin{equation}
\begin{align} \label{raritz}
\mathbf{\overline{y}}(k)^\top &{\rm E}[W(k)^\top W(k)] \mathbf{\overline{y}}(k) \nonumber\\
      &\leq \lambda_{d+1}({\rm E}[W(k)^\top W(k)]) \mathbf{\overline{y}}(k)^\top \mathbf{\overline{y}}(k)
\end{align}
%\end{equation}
where $\lambda_{d+1}<1$ is the second largest eigenvalue of ${\rm E}[W(k)^\top W(k)]$. After iterating (\ref{minh}) and (\ref{raritz}), we get:
\begin{equation}\label{raritz2}
    \begin{aligned}
      {\rm E}[\mathbf{\overline{y}}(k)^\top \mathbf{\overline{y}}(k)] \leq \lambda_{d+1}^{k}({\rm E}[W(k)^\top W(k)]) \mathbf{\overline{y}}(0)^\top \mathbf{\overline{y}}(0)
    \end{aligned}
\end{equation}
which also implies the convergence of the second moment of the proposed algorithm. 

When the matrix weight $\mathbf{A}_{ij}$ is nonsymmetric in general, necessary and sufficient conditions can be obtained by applying the results proposed in \cite{boyd2006,1272421}, which are as follow
\begin{lemma}\label{iff}
 {The first and second moment of the solution of (\ref{algorithm11}) will converge in probability if and only if there exists a common stepsize $\alpha$ such that.
\begin{enumerate}[label=(\roman*)]
    \item $\rho\big(\overline{W}-\frac{(\mathbf{1}_n\mathbf{1}_n^\top)\otimes\mathbf{I}_d}{n}\big)<1$
    \item $\rho\big({\rm E}[W(k)\otimes W(k)]-\frac{(\mathbf{1}_{n^2}\mathbf{1}_{n^2}^\top)\otimes\mathbf{I}_{d^2}}{n^2}\big)<1$
\end{enumerate}
}
\end{lemma}
{In Lemma \ref{iff}, the first constraint makes all agents reach the average consensus, whereas the second guarantees the convergence of the second moment. However, despite having explicit criteria for the convergence of the second moment, it is clearly seen that these requirements are not intuitive and quite hard to assess. Moreover, the symmetry of $\mathbf{A}_{ij}$ allows us to find interesting results of $\epsilon$-consensus time, which will be provided later.}
\subsubsection{Upper bound of the $\epsilon$-consensus time}
\begin{thm}\label{upperbound1}
    Select a common step size for every agent such that $\alpha < \underset{i,j}{\min}(\frac{1}{\max\| \mathbf{D}^{\rm M}_{i} \|},\frac{1}{\max \| \mathbf{A}_{ij} \|})$. With an arbitrary initial state vector $\mathbf{\overline{x}}(0)$, the solution $\mathbf{\overline{x}}(k)$ of \eqref{sol} converges in the expectation to the average vector $\mathbf{\overline{x}}^{*}=\big(\frac{1}{n} \mathbf{1}_n\mathbf{1}_n^\top \otimes \mathbf{I}_d \big)\mathbf{\overline{x}}(0)$ if and only if ${\rm null}(\mathbf{L}^{\rm M})={\rm range}(\mathbf{1}_n\otimes \mathbf{I}_d)$. Furthermore, the $\epsilon$-consensus time is upper bounded by a function of the second largest eigenvalue of ${\rm E}[W(k)^\top W(k)])$.
\end{thm}
Proof: Using Markov's inequality, we have:
\begin{align}
        {\rm P}\bigg(\frac{\lVert \mathbf{\overline{x}}(k)-\mathbf{1}_n\otimes \hat{\mathbf{\overline{x}}} \rVert}{\lVert \mathbf{\overline{x}}(0)-\mathbf{1}_n\otimes \hat{\mathbf{\overline{x}}} \rVert} & \geq \epsilon \bigg) 
        ={\rm P}\bigg(\frac{\mathbf{\overline{y}}(k)^\top \mathbf{\overline{y}}(k)}{\mathbf{\overline{y}}(0)^\top \mathbf{\overline{y}}(0)}\geq \epsilon^2\bigg) \nonumber\\
        &\leq\frac{\epsilon^{-2}{\rm E}[\mathbf{\overline{y}}(k)^\top \mathbf{\overline{y}}(k)]}{\mathbf{\overline{y}}(0)^\top \mathbf{\overline{y}}(0)} \nonumber\\
        &\leq \epsilon^{-2} \lambda_{d+1}^k \big( {\rm E}[\mathbf{\overline{W}}(k)^\top \mathbf{\overline{W}}(k)] \big).
\end{align}

As a result, for $k \geq K(\epsilon)=\frac{3{\log}(\epsilon^{-1})}{{\log}\lambda_{d+1}^{-1} \big( {\rm E}[\mathbf{\overline{W}}(k)^\top \mathbf{\overline{W}}(k)] \big)}$, there holds
$$\rm{P}\bigg(\frac{\lVert \mathbf{\overline{x}}(k)-\mathbf{1}_n\otimes \hat{\mathbf{\overline{x}}} \rVert}{\lVert \mathbf{\overline{x}}(0)-\mathbf{1}_n\otimes \hat{\mathbf{\overline{x}}} \rVert} \geq \epsilon \bigg) \leq \epsilon.$$ 
This implies $K(\epsilon)$ is the upper bound of the $\epsilon$-consensus time. 

\section{Randomized matrix weighted consensus with leader-following topology}
\label{sec:leader-follower}
Consider the previous graph $\mathcal{G}$, and then add a node $i=0$ to represent the leader. This leader node has a state vector $\mathbf{\overline{x}}_0$. A set of directed edges $E_0$ from vertex $0$ to some vertices $i \in V$, and a corresponding set of matrix-weights $\mathcal{A}_0=\left\{\mathbf{A}_{i0} = \mathbf{A}_{i0}^\top \geq 0, \forall i\in V\right\}$. $\mathbf{A}_{i0}=0$ represents the situation in which agent $i$ has no connection to the leader. The leader-following system is said to achieve a consensus if, for any initial state $\mathbf{\overline{x}}_i(0)\in\mathbb{R}^d, i\in V$, there holds $\lim_{t\rightarrow\infty} \mathbf{\overline{x}}_i(t)\rightarrow \mathbf{\overline{x}}_0$. In \cite{LFT17}, the authors proposed a continuous deterministic algorithm where the consensus phenomena are completely proven. In this paper, we first propose a discrete-time version of \cite{LFT17}, and then the randomized one will be presented.
\subsection{Discrete time matrix-weighted consensus with Leader-Following topology}
Our deterministic consensus algorithm for the Leader-Following topology is as follows: in particular, each agent $i \in V$ updates its value to $\mathbf{\overline{x}}_0(k+1)$ via
\begin{equation}\label{algorithm2}
    \begin{aligned}
    \overline{x}_0(k+1)&=\overline{x}_0(k)\\
    \overline{x}_i(k+1)&=\overline{x}_i(k)+ \theta\alpha \sum_{j\in \mathcal{N}_i} \mathbf{A}_{ij}\big(\overline{x}_j(k)-\overline{x}_i(k)\big)\\
    &\qquad\quad + (1-\theta)\alpha  \mathbf{A}_{i0}\big(\overline{x}_0 - \overline{x}_i(k)\big),\\
    \end{aligned}
\end{equation}
where $0<\theta<1$ and the step sizes $\alpha > 0$ will be designed later. To ensure the system reaches a consensus, we state the following assumptions:
\begin{assume}\label{Ai0}
    $\sum_{i \in V} \mathbf{A}_{i0} >0$.
\end{assume}
\begin{assume}\label{nullL}
    {\rm null}$(\mathbf{L}) = {\rm range}(\mathbf{1}_n \otimes \mathbf{I}_d)$.
\end{assume}
Under these assumptions, we have the following theorem.
\begin{thm}\label{ddmwc}
    Select $\alpha<\min(\frac{1}{\max_i\lVert \mathbf{D}_{i} \rVert}, \frac{2}{ \max_i(\lambda(\mathbf{A}_{i0}))})$, for any initial condition $\mathbf{\overline{x}}(0)$, the system \eqref{algorithm2} achieves leader-follower consensus at geometric rate.
\end{thm}
Proof: See Appendix \ref{append:B}.
% Place acknowledgments
\subsection{Randomized matrix-weighted consensus with Leader-Following topology}
The randomized version of  matrix-weighted consensus with Leader-Following topology is thus described as follow: Each agent $i\in V$ stores its own local vector $\overline{x}_i \in \mathbb{R}^d$. When an agent $i$ wakes up at the $k^{\text{th}}$ time slot, it will contact a neighbor $j$ with a probability ${\rm P}_{ij}$ and both agents will update their current state vector as
\begin{equation}\label{algorithm3}
    \begin{aligned}
    \overline{x}_i(k+1)&=\overline{x}_i(k)+ \theta\alpha \mathbf{A}_{ij} \big(\overline{x}_j(k)-\overline{x}_i(k)\big)\\
    &\qquad + (1-\theta)\alpha \mathbf{A}_{i0} \big(\overline{x}_0-\overline{x}_i(k)\big)\\
    \overline{x}_j(k+1)&=\overline{x}_j(k)+ \theta\alpha \mathbf{A}_{ij}\big(\overline{x}_i(k)-\overline{x}_j(k)\big)\\
    &\qquad + (1-\theta)\alpha \mathbf{A}_{j0}\big(\overline{x}_0 - \overline{x}_j(k)\big)\\
    \end{aligned}
\end{equation}
where $0<\theta<1$, $\alpha > 0$ are step sizes.
\begin{definition}
\emph{(Expected leader-follower weight)} An expected leader-follower weight of agent $i\in V$ is define as:
$$\mathbf{M}_{i0}=\frac{1}{n} \sum_j({\rm P}_{ij}+{\rm P}_{ji}) \mathbf{A}_{i0}.$$
\end{definition}
The following assumptions are adopted
\begin{assume}\label{Mi0}
    $\sum_{i \in V} \mathbf{M}_{i0} >0$
\end{assume}
\begin{assume}\label{Lm}
   {\rm null}$(\mathbf{L}^{\rm M})={\rm range}(\mathbf{1}_n\otimes \mathbf{I}_d)$.
\end{assume}
Denote the error vector $\mathbf{\overline{y}}_i(k)=\mathbf{\overline{x}}_i(k)-\mathbf{\overline{x}}_0$ and $\mathbf{\overline{y}}(k)=\text{vec}(\overline{y}_i(k))$. With a probability $\frac{1}{n}{\rm P}_{ij}$, we have
\begin{equation}\label{algorithm31}
    \begin{aligned}
        \overline{\mathbf{y}}(k+1)=W_{ij}\overline{\mathbf{y}}(k),
    \end{aligned}
\end{equation}
where $W_{ij}$ can be expressed as \eqref{algorithm22}. 
\begin{figure*}
    \centering
\begin{equation}\label{algorithm22}
    \begin{aligned}
        W_{ij}= \mathbf{I}_{dn}-\alpha\theta
        \begin{bmatrix}
         &\mathbf{O}_d        &\cdots     &\mathbf{O}_d             &\cdots    &\mathbf{O}_d &\cdots &\mathbf{O}_d \\
        &\vdots     &\ddots     &\vdots          &\ddots    &\vdots &\ddots &\vdots \\
         &\mathbf{O}_d        &\cdots  &\mathbf{A}_{ij} &\cdots    &-\mathbf{A}_{ij} &\cdots &\mathbf{O}_d  \\
        &\vdots     &\ddots     &\vdots          &\ddots    &\vdots &\ddots &\vdots \\
        &\mathbf{O}_d        &\cdots  &- \mathbf{A}_{ij} &\cdots    & \mathbf{A}_{ij} &\cdots &\mathbf{O}_d  \\
        &\vdots     &\ddots     &\vdots          &\ddots    &\vdots &\ddots &\vdots \\
        &\mathbf{O}_d        &\cdots     &\mathbf{O}_d             &\cdots    &\mathbf{O}_d &\cdots &\mathbf{O}_d   \\
        \end{bmatrix}
 -\alpha(1-\theta)
    \begin{bmatrix}
         &\mathbf{O}_d        &\cdots     &\mathbf{O}_d             &\cdots    &\mathbf{O}_d &\cdots &\mathbf{O}_d \\
        &\vdots     &\ddots     &\vdots          &\ddots    &\vdots &\ddots &\vdots \\
         &\mathbf{O}_d        &\cdots  & \mathbf{A}_{i0} &\cdots    &\mathbf{O}_d &\cdots &\mathbf{O}_d  \\
        &\vdots     &\ddots     &\vdots          &\ddots    &\vdots &\ddots &\vdots \\
        &\mathbf{O}_d        &\cdots  &\mathbf{O}_d &\cdots    & \mathbf{A}_{j0} &\cdots &\mathbf{O}_d  \\
        &\vdots     &\ddots     &\vdots          &\ddots    &\vdots &\ddots &\vdots \\
        &\mathbf{O}_d        &\cdots     &\mathbf{O}_d             &\cdots    &\mathbf{O}_d &\cdots &\mathbf{O}_d,
    \end{bmatrix}.
    \end{aligned}
\end{equation}
%\caption{Caption}
%\label{fig:my_label}
\end{figure*}

To analyze the dynamic of expectation, we consider $\overline{W}~={\rm E}[W(k)]=\frac{1}{n}\sum_{i,j} {\rm P}_{ij} W_{ij}$:
\begin{align} \label{23}
    \overline{W} &= \mathbf{I}_{dn}- \theta \alpha (\mathbf{D}^{\text{M}}-\mathbf{A}^{\text{M}})-(1-\theta)\alpha \text{blkdiag}(\mathbf{M}_{i0}) \nonumber\\
    &=\mathbf{I}_{dn}- \alpha \big(\theta  \mathbf{L}^{{\text{M}}}+(1-\theta) \text{blkdiag}(\mathbf{M}_{i0})\big)
\end{align}
with the Assumptions \ref{Mi0} and \ref{Lm}, the following theorem yields
\begin{thm}\label{sdmwc}
 Select $\alpha<\min(\frac{1}{ \underset{i}{\max}\lVert{\mathbf{D}^{\rm M}_{i}\rVert}},\frac{2}{ \underset{i}{\max}(\lambda(\mathbf{M}_{i0}))})$, for any initial condition $\mathbf{\overline{x}}(0)$, system \eqref{algorithm3} exponentially achieves a leader-follower consensus in expectation. 
\end{thm}
 Proof: The proof of this theorem is similar to the Appendix B.% \textcolor{red}{(exercise for readers)}.

 To check the convergence of the second moment and then determine the convergence rate, we again study the spectral properties of ${\rm E}[W(k)^\top W(k)]$.

 \begin{thm}\label{2mmlf}
 Select $\alpha<\min(\frac{1}{ \underset{i}{\max}\lVert(\mathbf{D}^{\rm M}_{i}) \rVert},\frac{2}{ \underset{i}{\max}(\lambda(\mathbf{M}_{i0}))})$, for any initial condition $\mathbf{\overline{x}}(0)$, the spectral radius of ${\rm E}[W(k)^\top W(k)]$ is strictly less than 1, implying that the proposed algorithm's second moment has converged.
\end{thm}
Proof: See Appendix \ref{append:C}.

The following result follows from Theorem \ref{2mmlf}:
\begin{align*} \label{largesteig}
\mathbf{\overline{y}}(k)^\top &{\rm E}[W(k)^\top W(k)] \mathbf{\overline{y}}(k) \nonumber\\
      &\leq \lambda_{\max}({\rm E}[W(k)^\top W(k)]) \mathbf{\overline{y}}(k)^\top \mathbf{\overline{y}}(k)\\
      &\leq \lambda^k_{\max}({\rm E}[W(k)^\top W(k)]) \mathbf{\overline{y}}(0)^\top \mathbf{\overline{y}}(0),
\end{align*}
%\end{equation}
where $\lambda_{max}<1$ is the maximum eigenvalue of ${\rm E}[W(k)^\top W(k)]$.
\subsubsection{Upper bound of the $\epsilon$-consensus time: Leader-following topology}
\begin{thm}\label{upperbound2}
    Select a common step size for every agent to satisfy Theorem \ref{2mmlf}. With an arbitrary initial  state vector $\mathbf{\overline{x}}(0)$, the solution $\mathbf{\overline{x}}(k)$ of (\ref{algorithm3}) converges in the expectation to the leader's state vector. Furthermore, the $\epsilon$-consensus time is upper bounded by a function of the spectral radius of ${\rm E}[W(k)^\top W(k)])$.
\end{thm}
Proof: Using Markov's inequality, we have
\begin{align*}
        {\rm P}\bigg( &\frac{\lVert \mathbf{\overline{x}}(k)-\mathbf{1}_n\otimes \mathbf{\overline{x}}_0 \rVert}{\lVert \mathbf{\overline{x}}(0)-\mathbf{1}_n\otimes \mathbf{\overline{x}}_0 \rVert}  \geq \epsilon \bigg) 
        ={\rm P}\bigg(\frac{\mathbf{\overline{y}}(k)^\top \mathbf{\overline{y}}(k)}{\mathbf{\overline{y}}(0)^\top \mathbf{\overline{y}}(0)}\geq \epsilon^2\bigg) \nonumber\\
        &\leq\frac{\epsilon^{-2}{\rm E}[\mathbf{\overline{y}}(k)^\top \mathbf{\overline{y}}(k)]}{\mathbf{\overline{y}}(0)^\top \mathbf{\overline{y}}(0)} \leq \epsilon^{-2} \lambda_{\max}^k \big( {\rm E}[\mathbf{\overline{W}}(k)^\top \mathbf{\overline{W}}(k)] \big).
\end{align*}
As a result, for $k \geq K(\epsilon)=\frac{3{\log}(\epsilon^{-1})}{{\log}\lambda_{max}^{-1} \big( {\rm E}[\mathbf{\overline{W}}(k)^\top \mathbf{\overline{W}}(k)] \big)}$, there holds
$$\rm{P}\bigg(\frac{\lVert \mathbf{\overline{x}}(k)-\mathbf{1}_n\otimes \mathbf{\overline{x}}_0 \rVert}{\lVert \mathbf{\overline{x}}(0)-\mathbf{1}_n\otimes \mathbf{\overline{x}}_0 \rVert} \geq \epsilon \bigg) \leq \epsilon.$$ 
Thus $K(\epsilon)$ is the upper bound of the $\epsilon$-consensus time. 
\section{Numerical examples}
\subsection{Randomized matrix weighted consensus  with Leaderless topology}
Consider a system of four agents whose state vectors are defined in $\mathbb{R}^3$. The matrix-weights of the system are given as:
{\small
\begin{align*}
\mathbf{A}_{12}&= 
\begin{bmatrix}
1 &0 &0\\
0 &\frac{1}{2} &\frac{1}{5}\\
0 &\frac{1}{2} &1
\end{bmatrix},
\mathbf{A}_{21}= 
\begin{bmatrix}
4 &2 &0\\
2 &\frac{1}{2} &0\\
0 &0 &0
\end{bmatrix}, 
\mathbf{A}_{13}= 
\begin{bmatrix}
5 &\frac{1}{3} &0\\
\frac{1}{3} &\frac{1}{2} &0\\
0 &0 &0
\end{bmatrix},\\
\mathbf{A}_{31}&= 
\begin{bmatrix}
5 &\frac{1}{3} &0\\
\frac{1}{3} &\frac{1}{2} &0\\
0 &0 &1
\end{bmatrix},
\mathbf{A}_{23} = 
\begin{bmatrix}
1 &\frac{1}{2} &0\\
\frac{1}{2} &1 &0\\
0 &0 &\frac{1}{3}
\end{bmatrix},
\mathbf{A}_{32}= 
\begin{bmatrix}
1 &\frac{1}{2} &0\\
\frac{1}{2} &\frac{1}{2} &0\\
0 &0 &\frac{1}{3}
\end{bmatrix},\\
\mathbf{A}_{34} &= 
\begin{bmatrix}
2 &0 &\frac{1}{2}\\
0 &2 &0\\
\frac{1}{2} &0 &1
\end{bmatrix},
\mathbf{A}_{43}= 
\begin{bmatrix}
3 &0 &0\\
0 &1 &1\\
0 &1 &1
\end{bmatrix}.
\end{align*}
}
and zero matrices otherwise. The transition matrix $\pi = [{\rm P}_{ij}]$ is designed as follow
{\small
\begin{equation*}
\pi =  
\begin{bmatrix}
0 &\frac{1}{2} &\frac{1}{2} &0\\
\frac{1}{3} &0 &\frac{2}{3} &0\\
\frac{1}{2} &\frac{1}{4} &0 &\frac{1}{4}\\
0 &0 &1 &0
\end{bmatrix}.
\end{equation*}}
The initial vectors of the agents are given as $\overline{x}_1(0)=[1,-2,3]^\top, \overline{x}_2(0)=[0,6,3]^\top,\overline{x}_3(0)=[-1,10,1]^\top,\overline{x}_1(0)=[0,2,5]^\top$. The average state vector is thus $\hat{\overline{x}}=[0,4,3]^\top$. To meet Theorem \ref{upperbound1}, the agents' common step size is set at $\alpha=0.02$. As shown in Fig.~\ref{leaderless}, four agents achieve a consensus. Their convergence value is $[0.0,3.9,3.0]^\top$, whose error to the ideal average is fairly small.
\begin{figure}
\begin{center}
\includegraphics[height=6cm]{gossip_leaderless}    % The printed column  
\caption{Randomized matrix weighted consensus of four agents with
Leaderless topology}  % width is 8.4 cm.
\label{leaderless}                                 % Size the figures 
\end{center}                                 % accordingly.
\end{figure}
\subsection{Randomized matrix weighted consensus  with Leader-Following topology}
We added a leader node $\overline{x}_0=[-1,3,1]^\top$ to the previous system. The leader-follower matrix-weights are given as {\small $ \mathbf{A}_{10}=
\begin{bmatrix}
1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 0
\end{bmatrix},
\mathbf{A}_{20}=
\begin{bmatrix}
0 & 0 & 0\\
0 & 0 & 0\\
0 & 0 & 5
\end{bmatrix}
$} 
and zero matrices, otherwise. The common step size is set at $\alpha = 0.1, \theta=0.5$. The simulation result is depicted in Fig.~\ref{leader}. All agents asymptotically reach a consensus at $[-1.0,3.0,1.0]^\top$, which is as expected.
\begin{figure}
\begin{center}
\includegraphics[height=6cm]{gossip_leader}    % The printed column  
\caption{Randomized matrix weighted consensus of four agents with
Leader-Following topology}  % width is 8.4 cm.
\label{leader}                                 % Size the figures 
\end{center}                                 % accordingly.
\end{figure}
\section{Conclusion}
In this paper, two randomized matrix-weighted consensus algorithms for both leaderless and leader-following topologies have been developed. We started with the general protocol, in which agents update their vector state in a randomized asynchronous manner. It was shown that, under some mild assumptions and by choosing a small enough updating step size, the agents could reach consensus in expectations. Furthermore, the upper bound of the convergence rate could be predetermined given the knowledge of each agent's probability distribution. Finally, numerical examples verified the theoretical result. One of our future research directions is to apply optimization techniques to find the optimal probability distribution for each agent, which will improve the consensus speed of the system.
\begin{ack} 
  % here.
\end{ack}

\bibliographystyle{plain}        % Include this if you use bibtex 
\bibliography{autosam}           % and a bib file to produce the 
                                 % bibliography (preferred). The
                                 % correct style is generated by
                                 % Elsevier at the time of printing.

%\begin{thebibliography}{99}     % Otherwise use the  
                                 % thebibliography environment.
                                 % Insert the full references here.
                                 % See a recent issue of Automatica 
                                 % for the style.
%  \bibitem[Heritage, 1992]{Heritage:92}
%     (1992) {\it The American Heritage. 
%     Dictionary of the American Language.}
%     Houghton Mifflin Company.
%  \bibitem[Able, 1956]{Abl:56}
%     B.~C.~Able (1956). Nucleic acid content of macroscope. 
%     {\it Nature 2}, 7--9. 
%  \bibitem[Able {\em et al.}, 1954]{AbTaRu:54}   
%     B.~C. Able, R.~A. Tagg, and M.~Rush (1954).
%     Enzyme-catalyzed cellular transanimations.
%     In A.~F.~Round, editor, 
%     {\it Advances in Enzymology Vol. 2} (125--247). 
%     New York, Academic Press.
%  \bibitem[R.~Keohane, 1958]{Keo:58}
%     R.~Keohane (1958).
%     {\it Power and Interdependence: 
%     World Politics in Transition.}
%     Boston, Little, Brown \& Co.
%  \bibitem[Powers, 1985]{Pow:85}
%     T.~Powers (1985).
%     Is there a way out?
%     {\it Harpers, June 1985}, 35--47.

%\end{thebibliography}

\appendix
\section{Proof of Lemma \ref{stepsizeav}}    % Each appendix must have a short title.
\label{append:A}
$\bullet$ \emph{The set of all real symmetric matrices with eigenvalues in $[0,1]$ is convex. Every possible matrix $W_{ij}^\top W_{ij}$ is in this set.}

The first part of this statement is a consequence of the following lemma \cite{matrix2}: \emph{A, B are nÃ—n Hermitian matrices. If the eigenvalues of A and B are all in an interval I, then the eigenvalues of any convex combination of A and B are also in I.} 

Rearrange the rows and columns of $W_{ij}$ we get
\begin{equation}
W_{ij}=\begin{bmatrix}

        &\mathbf{I}_d-\alpha_i \mathbf{A}_{ij} &\alpha_i \mathbf{A}_{ij} &\cdots &\mathbf{O}_d  \\
        &\alpha_j \mathbf{A}_{ij} &\mathbf{I}_d-\alpha_j\mathbf{A}_{ij} &\cdots &\mathbf{O}_d  \\
       &\vdots          &\vdots    &\ddots  &\vdots \\
        &\mathbf{O}_d   &\mathbf{O}_d    &\cdots &\mathbf{I}_d  \\
\end{bmatrix}
\end{equation}
Thus, the union of the unity eigenvalues (which correspond to the identity matrices $\mathbf{I}_d$) and the eigenvalues of matrix $w=
\begin{bmatrix}
    &\mathbf{I}_d-\alpha_i \mathbf{A}_{ij} &\alpha_i \mathbf{A}_{ij}\\
    &\alpha_j \mathbf{A}_{ij} &\mathbf{I}_d-\alpha_j\mathbf{A}_{ij} \\
\end{bmatrix}
$ yields the eigenvalues of $W_{ij}$. By choosing $\alpha<\frac{1}{\max\lVert \mathbf{A}_{ij} \rVert}$, we can easily obtain $-1<\lambda(w)\leq 1$ (see Lemma \ref{stepsize}). $W_{ij}$'s eigenvalues then satisfy $\lambda(W_{ij}) \in (-1,1]$. Hence, $\lambda(W_{ij}^{\top}W_{ij})=\lambda(W_{ij}^2)=\lambda(W_{ij})^2 ~\in [0,1]$.

$\bullet$ \emph{${\rm E}[W(k)^\top W(k)]$ has a unity spectral radius, and its unity eigenvalues are semi-simple.}

We take into account ${\rm E}[W(k)^{\top}W(k)]$  as a convex combination of all possible $W_{ij}^2$. As a result, using the first statement of Lemma \ref{stepsizeav}, ${\rm E}[W(k)^\top W(k)]$ has a unity spectral radius. Due to the symmetry of ${\rm E}[W(k)^{\top}W(k)]$,
its unity eigenvalues are semi-simple.

$\bullet$ \emph{$\mathbf{1}_n \otimes\mathbf{I}_d$ are 
only $d$ orthogonal right eigenvectors corresponding to the unity eigenvalues $\lambda=1$ of ${\rm E}[W(k)^\top W(k)]$ if and only if null$(\mathbf{L}^{\rm M})=\text{range}(\mathbf{1}_n\otimes \mathbf{I}_d)$}.

Using (\ref{algorithm12}), we can easily get the following:
\begin{equation}
W_{ij}^{\top}W_{ij}=\begin{bmatrix}
    &\mathbf{I}_d        &\cdots     &\mathbf{O}_d             &\cdots    &\mathbf{O}_d &\cdots &\mathbf{O}_d \\
    &\vdots     &\ddots     &\vdots          &\ddots    &\vdots &\ddots &\vdots \\
    &\mathbf{O}_d        &\cdots  &\mathbf{I}_d-\mathbf{\hat{A}}_{ij} &\cdots    &\mathbf{\hat{A}}_{ij} &\cdots &\mathbf{O}_d  \\
    &\vdots     &\ddots     &\vdots          &\ddots    &\vdots &\ddots &\vdots \\
    &\mathbf{O}_d        &\cdots  &\mathbf{\hat{A}}_{ij} &\cdots    &\mathbf{I}_d-\mathbf{\hat{A}}_{ij} &\cdots &\mathbf{O}_d  \\
    &\vdots     &\ddots     &\vdots          &\ddots    &\vdots &\ddots &\vdots \\
    &\mathbf{O}_d        &\cdots     &\mathbf{O}_d             &\cdots    &\mathbf{O}_d &\cdots &\mathbf{I}_d 
\end{bmatrix},
\end{equation}
where $\mathbf{\hat{A}}_{ij}=2\alpha \mathbf{A}_{ij}(\mathbf{I}_d-\alpha \mathbf{A}_{ij})$. Denote $\mathbf{\hat{M}}_{ij}= \frac{1}{n}(\mathbf{\hat{A}}_{ij} {\rm P}_{ij}+\mathbf{\hat{A}}_{ji} {\rm P}_{ji})$. By choosing $0<\alpha<\frac{1}{\max\lVert \mathbf{A}_{ij} \rVert}$, $\mathbf{\hat{A}}_{ij}$ is positive definite (resp., positive semi-definite) if and only if $\mathbf{A}_{ij}$ is positive definite (resp., positive semi-definite). The same kind of relationship also holds for $\mathbf{\hat{M}}_{ij}$ and $\mathbf{M}_{ij}$. Moreover, it is simply provable that $\text{null}(\mathbf{\hat{A}}_{ij})=\text{null}(\mathbf{A}_{ij})$ and thus $\text{null}(\mathbf{\hat{M}}_{ij})=\text{null}(\mathbf{M}_{ij})$. We now rewrite ${\rm E}[W(k)^\top W(k)]$ as 
$${\rm E}[W(k)^\top W(k)]=\mathbf{I}_{dn} - (\mathbf{\hat{D}}^{\text{M}}-\mathbf{\hat{A}}^\text{M})=\mathbf{I}_{dn} - \mathbf{\hat{L}}^\text{M},$$
in which $\mathbf{\hat{D}}^{\text{M}}= \text{blkdiag}(\mathbf{\hat{D}}^{\text{M}}_{1},\ldots,\mathbf{\hat{D}}^{\text{M}}_{n})$, whereas $\mathbf{\hat{D}}^{\text{M}}_{i}= \sum_{j \in V}\mathbf{\hat{M}}_{ij}$ and $\mathbf{\hat{A}}^\text{M}=[\mathbf{\hat{M}}_{ij}]$. It is clear that the eigenvectors corresponding to the unity eigenvalue of ${\rm E}[W(k)^\top W(k)]$ is the null space of $\mathbf{\hat{L}}^\text{M}$. Similar to Lemma \ref{nullspace}, the following holds:
  $\text{null}(\mathbf{\hat{L}}^{\text{M}}) =  \text{span}\{ \text{range}(\mathbf{1}_n \otimes \mathbf{I}_d),  \{ \mathbf{v}=[v_1^\top,\dots, v_n^\top]^\top \in \mathbb{R}^{nd}|~(v_j-v_j)\in \text{null}(\mathbf{\hat{M}}_{ij})=\text{null}(\mathbf{M}_{ij}), \forall (i,j) \in V \} \}$. Therefore, $\text{null}(\mathbf{\hat{L}}^{\text{M}})=\text{range}(\mathbf{1}_n\otimes \mathbf{I}_d)$ if and only if $\text{null}(\mathbf{L}^{\text{M}})=\text{range}(\mathbf{1}_n\otimes \mathbf{I}_d)$.

\section{Proof of Theorem \ref{ddmwc}}         % Sections and subsections are supported  
\label{append:B}
Denote the error vector $\overline{y}_i(k)=\overline{x}_i(k)-\overline{x}_0$. System (\ref{algorithm2}) can be rewritten as
\begin{equation}\label{B1}
    \begin{aligned}
    \overline{y}_i(k+1)&=\overline{y}_i(k)- \theta\alpha\sum_{j\in \mathcal{N}_i} \mathbf{A}_{ij}\big(\overline{y}_i(k)-\overline{y}_j(k)\big)\\
    &\quad- (1-\theta)\alpha \mathbf{A}_{i0} \overline{y}_i(k)\\
    \end{aligned}
\end{equation}
For the whole system, (\ref{B1}) becomes
\begin{align} \label{B2}
    \mathbf{\overline{y}}(k+1)&=\big(\mathbf{I}_{dn}-\theta\alpha \mathbf{L}-(1-\theta)\alpha \text{blkdiag}({\mathbf{A}_{i0}})\big)\mathbf{\overline{y}}(k) \nonumber\\
    &=(\mathbf{I}_{dn}-\mathbf{N})\mathbf{\overline{y}}(k) =\mathbf{H}\mathbf{\overline{y}}(k),
\end{align}
where $\mathbf{\overline{y}}(k)=\text{vec}(\overline{y}_i(k))$.  

Choosing the updating step sizes $\alpha$ satisfy Theorem \ref{ddmwc}, we will have $\lambda(\alpha\mathbf{L})$, $\lambda(\alpha\text{blkdiag}({\mathbf{A}_{i0}})) \in [0,2) $ and thus the convex combination of these two matrices $\mathbf{N}$ satisfy $0\leq\lambda(\mathbf{N})<2$ and $-1<\lambda(\mathbf{H})\leq1$.
With the assumptions (\ref{Ai0}) and (\ref{nullL}), $\mathbf{N}$ is positive definite (the complete proof can be found in \cite{LFT17}) and then $\lambda(\mathbf{H})<1$. As a result, it yields $-1<\lambda(\mathbf{H})<1$. 
The matrix $\mathbf{H}$ is thus stable, and $\mathbf{\overline{y}}(k)\rightarrow 0$ as $k \rightarrow \infty$. Furthermore, it is well known from linear control theory that the converge rate of $\mathbf{\overline{y}}(k)$ will depend on the largest-in-magnitude eigenvalue of $\mathbf{H}$.

\section{Proof of Theorem \ref{2mmlf}}   
\label{append:C}
Choosing the updating step sizes $\alpha$ satisfy Theorem \ref{sdmwc}, it is easily obtained that each possible $W_{ij}$ has eigenvalues satisfy $-1<\lambda(W_{ij})\leq 1$ and thus $0\leq\lambda(W_{ij}^\top W_{ij})\leq 1$. Denote $\left\{v_{ij}\right\}$ as the eigenspace of $W_{ij}$ corresponding to the eigenvalue $\lambda=1$. Clearly, $\left\{v_{ij}\right\}$ is also the eigenspace corresponding to the unity eigenvalue of $W_{ij}^\top W_{ij}$. We now treat the expectation ${\rm E}[W_{ij}]$ (resp., ${\rm E}[W_{ij}^\top W_{ij}]$)  as a convex combination of all possible $W_{ij}$ (resp., $W_{ij}^\top W_{ij}$) where ${\rm P}_{ij}\neq 0$. Because $W_{ij}$ is symmetric (and thus $W_{ij}^\top W_{ij}$), ${\rm E}[W_{ij}]$ cannot have a unity eigenvalue unless there exists a common eigenvector between every eigenspace $\left\{v_{ij}\right\}$. From Theorem \ref{ddmwc}, we already have $-1<\lambda({\rm E}[W_{ij}])<1$, which implies $\underset{{\rm P}_{ij}\neq 0}{\bigcap}\left\{v_{ij}\right\}=\varnothing$. Thus, it is obvious that $0\leq \lambda({\rm E}[W_{ij}^\top W_{ij}])<1$. This completes the proof of Theorem \ref{2mmlf}.
\end{document}