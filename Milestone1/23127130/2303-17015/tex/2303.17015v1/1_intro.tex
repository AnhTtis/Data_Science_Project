\section{Introduction}
\label{sec:intro}

Recent years have seen profound development in implicit neural field models, demonstrating powerful representations, particularly 3D shape geometry~\cite{park2019deepsdf, chabra2020deepls}, neural radiance fields (NeRF)~\cite{mildenhall2021nerf}, and complex signals with higher-order derivative constraints~\cite{sitzmann2020implicit}. Typically, an implicit neural field\footnote{Implicit neural fields are also referred to as coordinate fields or coordinate-based networks. We use these terms interchangeably.}
maps an input coordinate location in $n$-dimensional space to the target signal domain. For example,
an implicit surface representation
\begin{equation*}
    \{\mathbf{x}\in \mathbb{R}^n | f(\mathbf{x},\theta) = 0\},
\end{equation*}
where $f:\mathbb{R}^n\rightarrow\mathbb{R}$ is typically characterized by a multilayer perceptron (MLP).
Notably, such neural fields efficiently represent sparse high-dimensional data in a relatively low-dimensional MLP weight space.
This continuous mapping enables sampling at arbitrary-resolution for surface representations, eliminating explicit resolution constraints inherent to classical point, mesh, or voxel representations.
One can then easily reconstruct the mesh underlying this compact representation through methods such as Marching Cubes~\cite{lorensen1987marching}.
It has enabled faithful 3D reconstruction where an MLP is optimized to fit a set of point observations~\cite{park2019deepsdf}, as well as preliminary results in higher-dimensional 4D reconstruction and tracking~\cite{li20214dcomplete}.

\begin{figure}[hbtp]
    \centering
    \includegraphics[width=\linewidth]{images/3d_gen.png}
    (a) Generated 3D shapes.
    
    \includegraphics[width=\linewidth]{images/4d_gen.png}

    (b) Generated 4D animation sequence.
    
    \caption{\OURS is a dimension-agnostic generative model. The same approach can be trained on data of various dimensionalities to synthesize high-fidelity examples. For instance, 
   (a) 3D shapes, and (b) 4D animation sequences (3D and time).}
    \label{fig:multi_planes}
\end{figure}

The aforementioned implicit neural field representation also poses a new opportunity for generative modeling -
that is, rather than model the raw 3D or 4D surface information, we aim to directly model the space of optimized neural field MLPs without relying on any ties to alternative explicit representations (e.g., points, meshes, and voxels) or approximation to latent manifolds (which typically require a pair of  encoder and decoder networks pretrained on large-scale datasets).
In particular, we observe that optimized neural field MLPs typically maintain an extremely compact representation of a high-dimensional 3D or 4D surface.

We thus propose \OURS{}, a new paradigm for generative modeling of neural fields. 
\OURS{} leverages diffusion modeling directly on the weight space of optimized neural fields, enabling generative modeling of high-dimensional data characterized by neural fields.
Our \OURS{} approach is dimension-agnostic, and we apply the same method towards both unconditional 3D and 4D (3D and time) surface generation to demonstrate the power of directly generating neural fields as MLP weights.

Specifically, to model neural fields characterizing $n$-dimensional surface data, we consider a set of MLPs that have been optimized to represent individual instances from a dataset.
We then employ a transformer-based network to model the diffusion process directly on the optimized MLP weights.
This enables generative modeling on a low-dimensional space, and we demonstrate its high-fidelity and diverse generative modeling capabilities, achieving state-of-the-art 3D and 4D surface synthesis.

\medskip
Our contributions can be summarized as follows:
\begin{itemize}
    \vspace{-0.15cm}
    \item We present the first approach to model the space of neural field MLP weights by diffusion modeling, enabling a new paradigm for high-dimensional generative modeling.
    \vspace{-0.15cm}
    \item Our MLP optimization of surface occupancy provides a low-dimensional weight space for  effective unconditional diffusion modeling with a transformer-based architecture for both 3D and 4D surfaces at high fidelity. 
\end{itemize}


\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{images/overview_last.pdf}
    \caption{
    Overview of \OURS{}.
    We first fit a set of neural field MLPs to a dataset of 3D or 4D shapes in an overfitting process, producing high-fidelity shape representations that support arbitrary resolutions (left).
    To support the following diffusion process on the MLP weights, we use an arbitrary optimized MLP to initialize the rest of the MLP optimization.
    We then use a transformer-based architecture to model a diffusion process directly on these optimized MLP weights, predicting the denoised MLP weights and biases as flattened vectors (middle).
    This enables synthesis of new neural field representations as their MLP weights, from which meshes can be extracted through Marching Cubes.
    Our approach is agnostic to the resolution of the dataset instances, and we demonstrate effective 3D and 4D shape modeling.
    }
    \label{fig:overview}
\end{figure*}