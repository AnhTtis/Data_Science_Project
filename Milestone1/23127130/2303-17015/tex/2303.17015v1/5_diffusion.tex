\section{MLP Weight-Space Diffusion}
\label{sec:diffusion}

We then model the weight space of our optimized MLPs through a diffusion process.
We consider each set of optimized MLP weights and biases $\{\theta_i\}$ as a flattened 1D vector.
We use a transformer architecture $\mathcal{T}$, following \cite{peebles2022learning}, for our denoising network. 
As transformers have been shown to elegantly handle long vectors in the language domain, we find it to be a suitable choice for modeling the MLP weight space.
$\mathcal{T}$ predicts the denoised MLP weights directly, rather than the noise.
% 
Our $h$-dimensional vectors $\{\theta_i\}$ of MLP weights and biases are input to $\mathcal{T}$.
Each $\theta_i$ is divided into 8 tokens by MLP layers, to be encoded by $\mathcal{T}$.

Modeling the MLP weights as a 1D vector for diffusion enables a general formulation for modeling neural fields, as the MLP weights are agnostic to varying-dimensional data.
This makes \OURS{} flexible to a variety of neural field representations; in particular, we observe the neural field ability to compactly represent high-dimensional shape data and demonstrate  generative modeling of MLPs representing 3D and 4D shapes, respectively.

During diffusion modeling, we apply standard gaussian noise $t$ times to each vector $\theta$. 
The noisy vector, along with the sinusoidal embedding of $t$, are then input to a linear projection. The projections are then summed up with a learnable positional encoding vector.
Then, the transformer outputs denoised tokens that we pass through a final output projection to produce the predicted denoised MLP weights $w^*$.
We train with a Mean Squared Error (MSE) loss between the denoised weights $\theta^*$ and the input weights $\theta$.

We illustrate the denoising process for MLPs representing 3D shapes in Figure~\ref{fig:denoising_vis}. 
Noisy MLPs correspond to invalid shapes, which are denoised to MLPs that represent valid 3D surfaces. We employ Denoising Diffusion Implicit Models (DDIM) \cite{song2020denoising} to sample new MLPs from the diffusion process.


\begin{figure*}[hbtp]
    \includegraphics[width=\linewidth]{images/denoising.pdf}
    \caption{
    Denoising MLP parameters at various time steps, visualized with their corresponding shapes, from random noise (left) to fully denoised (right). The image shows the gradual change from 0 denoising steps, which are generated from random MLP weights, up to 500 steps corresponding to fully-denoised shape. More specifically, we leverage the DDIM \cite{song2020denoising} sampling strategy. Interestingly, noisy MLP weights do not necessarily correspond to a valid 3D shape; however, the iterative application of the denoising operator eventually converges to a quality output shape.  
    }
    \label{fig:denoising_vis}
\end{figure*}

\paragraph{Implementation Details}
Our 3-layer 128-dim MLPs  contain $\approx 36$k parameters, which are flattened and tokenized for diffusion.
We use an  AdamW~\cite{loshchilov2017decoupled} optimizer with batch size $32$ and initial   learning rate of $2e^{-4}$, which is reduced by $20$\% every $200$ epochs.
We train for $\approx 4000$ epochs until convergence, which takes $\approx 4$ days on a single A6000 GPU.