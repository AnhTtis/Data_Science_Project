{
    "arxiv_id": "2303.10694",
    "paper_title": "Improving Uncertainty Quantification of Deep Classifiers via Neighborhood Conformal Prediction: Novel Algorithm and Theoretical Analysis",
    "authors": [
        "Subhankar Ghosh",
        "Taha Belkhouja",
        "Yan Yan",
        "Janardhan Rao Doppa"
    ],
    "submission_date": "2023-03-19",
    "revised_dates": [
        "2023-03-21"
    ],
    "latest_version": 1,
    "categories": [
        "cs.LG",
        "stat.ML"
    ],
    "abstract": "Safe deployment of deep neural networks in high-stake real-world applications requires theoretically sound uncertainty quantification. Conformal prediction (CP) is a principled framework for uncertainty quantification of deep models in the form of prediction set for classification tasks with a user-specified coverage (i.e., true class label is contained with high probability). This paper proposes a novel algorithm referred to as Neighborhood Conformal Prediction (NCP) to improve the efficiency of uncertainty quantification from CP for deep classifiers (i.e., reduce prediction set size). The key idea behind NCP is to use the learned representation of the neural network to identify k nearest-neighbors calibration examples for a given testing input and assign them importance weights proportional to their distance to create adaptive prediction sets. We theoretically show that if the learned data representation of the neural network satisfies some mild conditions, NCP will produce smaller prediction sets than traditional CP algorithms. Our comprehensive experiments on CIFAR-10, CIFAR-100, and ImageNet datasets using diverse deep neural networks strongly demonstrate that NCP leads to significant reduction in prediction set size over prior CP methods.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.10694v1"
    ],
    "publication_venue": "To appear in the Proceedings of the AAAI Conference on Artificial Intelligence, 2023"
}