{
    "arxiv_id": "2303.14933",
    "paper_title": "MD-VQA: Multi-Dimensional Quality Assessment for UGC Live Videos",
    "authors": [
        "Zicheng Zhang",
        "Wei Wu",
        "Wei Sun",
        "Dangyang Tu",
        "Wei Lu",
        "Xiongkuo Min",
        "Ying Chen",
        "Guangtao Zhai"
    ],
    "submission_date": "2023-03-27",
    "revised_dates": [
        "2023-03-28"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "User-generated content (UGC) live videos are often bothered by various distortions during capture procedures and thus exhibit diverse visual qualities. Such source videos are further compressed and transcoded by media server providers before being distributed to end-users. Because of the flourishing of UGC live videos, effective video quality assessment (VQA) tools are needed to monitor and perceptually optimize live streaming videos in the distributing process. In this paper, we address \\textbf{UGC Live VQA} problems by constructing a first-of-a-kind subjective UGC Live VQA database and developing an effective evaluation tool. Concretely, 418 source UGC videos are collected in real live streaming scenarios and 3,762 compressed ones at different bit rates are generated for the subsequent subjective VQA experiments. Based on the built database, we develop a \\underline{M}ulti-\\underline{D}imensional \\underline{VQA} (\\textbf{MD-VQA}) evaluator to measure the visual quality of UGC live videos from semantic, distortion, and motion aspects respectively. Extensive experimental results show that MD-VQA achieves state-of-the-art performance on both our UGC Live VQA database and existing compressed UGC VQA databases.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.14933v1"
    ],
    "publication_venue": "Accepted to CVPR2023"
}