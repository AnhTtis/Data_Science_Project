{
    "arxiv_id": "2303.17505",
    "paper_title": "Unsupervised Anomaly Detection with Local-Sensitive VQVAE and Global-Sensitive Transformers",
    "authors": [
        "Mingqing Wang",
        "Jiawei Li",
        "Zhenyang Li",
        "Chengxiao Luo",
        "Bin Chen",
        "Shu-Tao Xia",
        "Zhi Wang"
    ],
    "submission_date": "2023-03-29",
    "revised_dates": [
        "2023-03-31"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "Unsupervised anomaly detection (UAD) has been widely implemented in industrial and medical applications, which reduces the cost of manual annotation and improves efficiency in disease diagnosis. Recently, deep auto-encoder with its variants has demonstrated its advantages in many UAD scenarios. Training on the normal data, these models are expected to locate anomalies by producing higher reconstruction error for the abnormal areas than the normal ones. However, this assumption does not always hold because of the uncontrollable generalization capability. To solve this problem, we present LSGS, a method that builds on Vector Quantised-Variational Autoencoder (VQVAE) with a novel aggregated codebook and transformers with global attention. In this work, the VQVAE focus on feature extraction and reconstruction of images, and the transformers fit the manifold and locate anomalies in the latent space. Then, leveraging the generated encoding sequences that conform to a normal distribution, we can reconstruct a more accurate image for locating the anomalies. Experiments on various datasets demonstrate the effectiveness of the proposed method.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.17505v1"
    ],
    "publication_venue": "4 pages, 3 figures, 4 tables"
}