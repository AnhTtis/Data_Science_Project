@InProceedings{C2,
  author = 	 "Jones, C.D. and Smith, A.B. and Roberts, E.F.",
  title =        "Article Title",
  booktitle =        "Proceedings Title",
  organization = "IEEE",
  year = 	 "2003",
  volume = 	 "II",
  pages = 	 "803-806"
}


@incollection{Bengio+chapter2007,
	title        = {Scaling Learning Algorithms Towards {AI}},
	author       = {Bengio, Yoshua and LeCun, Yann},
	year         = 2007,
	booktitle    = {Large Scale Kernel Machines},
	publisher    = {MIT Press}
}
@article{Hinton06,
	title        = {A Fast Learning Algorithm for Deep Belief Nets},
	author       = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
	year         = 2006,
	journal      = {Neural Computation},
	volume       = 18,
	pages        = {1527--1554}
}
@book{goodfellow2016deep,
	title        = {Deep learning},
	author       = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
	year         = 2016,
	publisher    = {MIT Press},
	volume       = 1
}
@inproceedings{dosovitskiy2020image,
	title        = {An image is worth 16x16 words: Transformers for image recognition at scale},
	author       = {Dosovitskiy, Alexey and others},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2010.11929},
	booktitle    = {ICLR}
}
@article{krizhevsky2012imagenet,
	title        = {Imagenet classification with deep convolutional neural networks},
	author       = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	year         = 2012,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 25,
	pages        = {1097--1105}
}
@inproceedings{carreira2017quo,
	title        = {Quo vadis, action recognition? a new model and the kinetics dataset},
	author       = {Carreira, Joao and Zisserman, Andrew},
	year         = 2017,
	booktitle    = {proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {6299--6308}
}
@inproceedings{feichtenhofer2020x3d,
	title        = {X3d: Expanding architectures for efficient video recognition},
	author       = {Feichtenhofer, Christoph},
	year         = 2020,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {203--213}
}
@inproceedings{feichtenhofer2019slowfast,
	title        = {Slowfast networks for video recognition},
	author       = {Feichtenhofer, Christoph and Fan, Haoqi and Malik, Jitendra and He, Kaiming},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages        = {6202--6211}
}
@inproceedings{carion2020end,
	title        = {End-to-end object detection with transformers},
	author       = {Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
	year         = 2020,
	booktitle    = {European Conference on Computer Vision},
	pages        = {213--229},
	organization = {Springer}
}
@article{simonyan2014very,
	title        = {Very deep convolutional networks for large-scale image recognition},
	author       = {Simonyan, Karen and Zisserman, Andrew},
	year         = 2014,
	journal      = {arXiv preprint arXiv:1409.1556}
}
@inproceedings{szegedy2015going,
	title        = {Going deeper with convolutions},
	author       = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	year         = 2015,
	booktitle    = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages        = {1--9}
}
@inproceedings{bertasius2021space,
	title        = {Is space-time attention all you need for video understanding?},
	author       = {Bertasius, Gedas and Wang, Heng and Torresani, Lorenzo},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2102.05095},
	booktitle    = {Proceedings of the International Conference on Machine Learning},
	volume       = 2,
	pages        = 4
}
@inproceedings{arnab2021vivit,
	title        = {Vivit: A video vision transformer},
	author       = {Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lu{\v{c}}i{\'c}, Mario and Schmid, Cordelia},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2103.15691},
	booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages        = {6836--6846}
}
@inproceedings{fan2021multiscale,
	title        = {Multiscale vision transformers},
	author       = {Fan, Haoqi and others},
	year         = 2021,
	booktitle    = {Proc. ICCV}
}
@article{akbari2021vatt,
	title        = {Vatt: Transformers for multimodal self-supervised learning from raw video, audio and text},
	author       = {Akbari, Hassan and Yuan, Liangzhe and Qian, Rui and Chuang, Wei-Hong and Chang, Shih-Fu and Cui, Yin and Gong, Boqing},
	year         = 2021,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 34,
	pages        = {24206--24221}
}
@article{christoph2016spatiotemporal,
	title        = {Spatiotemporal residual networks for video action recognition},
	author       = {Christoph, R and Pinz, Feichtenhofer Axel},
	year         = 2016,
	journal      = {Advances in Neural Information Processing Systems},
	pages        = {3468--3476}
}
@inproceedings{xie2018rethinking,
	title        = {Rethinking spatiotemporal feature learning: Speed-accuracy trade-offs in video classification},
	author       = {Xie, Saining and Sun, Chen and Huang, Jonathan and Tu, Zhuowen and Murphy, Kevin},
	year         = 2018,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)},
	pages        = {305--321}
}
@article{touvron2021going,
	title        = {Going deeper with image transformers},
	author       = {Touvron, Hugo and Cord, Matthieu and Sablayrolles, Alexandre and Synnaeve, Gabriel and J{\'e}gou, Herv{\'e}},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2103.17239}
}
@article{touvron2020deit,
	title        = {Training data-efficient image transformers & distillation through attention},
	author       = {Hugo Touvron and Matthieu Cord and Matthijs Douze and Francisco Massa and Alexandre Sablayrolles and Herv\'e J\'egou},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2012.12877}
}
@inproceedings{zheng2020rethinking,
	title        = {Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers},
	author       = {Zheng, Sixiao and Lu, Jiachen and Zhao, Hengshuang and Zhu, Xiatian and Luo, Zekun and Wang, Yabiao and Fu, Yanwei and Feng, Jianfeng and Xiang, Tao and Torr, Philip HS and others},
	year         = 2021,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}
}
@article{zhao2020point,
	title        = {Point transformer},
	author       = {Zhao, Hengshuang and Jiang, Li and Jia, Jiaya and Torr, Philip and Koltun, Vladlen},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2012.09164}
}
@inproceedings{kitaev2020reformer,
	title        = {Reformer: The efficient transformer},
	author       = {Kitaev, Nikita and Kaiser, {\L}ukasz and Levskaya, Anselm},
	year         = 2020,
	booktitle    = {International Conference on Learning Representations}
}
@article{kay2017kinetics,
	title        = {The kinetics human action video dataset},
	author       = {Kay, Will and others},
	year         = 2017,
	journal      = {arXiv preprint arXiv:1705.06950}
}
@article{soomro2012ucf101,
	title        = {UCF101: A dataset of 101 human actions classes from videos in the wild},
	author       = {Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
	year         = 2012,
	journal      = {arXiv preprint arXiv:1212.0402}
}
@inproceedings{kuehne2011hmdb,
	title        = {HMDB: a large video database for human motion recognition},
	author       = {Kuehne, Hildegard and Jhuang, Hueihan and Garrote, Est{\'\i}baliz and Poggio, Tomaso and Serre, Thomas},
	year         = 2011,
	booktitle    = {International Conference on Computer Vision},
	pages        = {2556--2563},
	organization = {IEEE}
}
@inproceedings{wang2020video,
	title        = {Video modeling with correlation networks},
	author       = {Wang, Heng and Tran, Du and Torresani, Lorenzo and Feiszli, Matt},
	year         = 2020,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {352--361}
}
@inproceedings{tran2019video,
	title        = {Video classification with channel-separated convolutional networks},
	author       = {Tran, Du and Wang, Heng and Torresani, Lorenzo and Feiszli, Matt},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages        = {5552--5561}
}
@inproceedings{qiu2019learning,
	title        = {Learning spatio-temporal representation with local and global diffusion},
	author       = {Qiu, Zhaofan and Yao, Ting and Ngo, Chong-Wah and Tian, Xinmei and Mei, Tao},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {12056--12065}
}
@inproceedings{wang2013action,
	title        = {Action recognition with improved trajectories},
	author       = {Wang, Heng and Schmid, Cordelia},
	year         = 2013,
	booktitle    = {Proceedings of the IEEE International Conference on Computer Vision},
	pages        = {3551--3558}
}
@inproceedings{simonyan2014two,
	title        = {Two-stream convolutional networks for action recognition in videos},
	author       = {Simonyan, Karen and Zisserman, Andrew},
	year         = 2014,
	journal      = {arXiv preprint arXiv:1406.2199},
	booktitle    = {Proceedings of the 27th International Conference on Neural Information Processing Systems-Volume 1},
	pages        = {568--576}
}
@inproceedings{wang2016temporal,
	title        = {Temporal segment networks: Towards good practices for deep action recognition},
	author       = {Wang, Limin and Xiong, Yuanjun and Wang, Zhe and Qiao, Yu and Lin, Dahua and Tang, Xiaoou and Van Gool, Luc},
	year         = 2016,
	booktitle    = {European Conference on Computer Vision},
	pages        = {20--36},
	organization = {Springer}
}
@inproceedings{hara2018can,
	title        = {Can spatiotemporal 3d cnns retrace the history of 2d cnns and imagenet?},
	author       = {Hara, Kensho and Kataoka, Hirokatsu and Satoh, Yutaka},
	year         = 2018,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {6546--6555}
}
@inproceedings{tran2018closer,
	title        = {A closer look at spatiotemporal convolutions for action recognition},
	author       = {Tran, Du and Wang, Heng and Torresani, Lorenzo and Ray, Jamie and LeCun, Yann and Paluri, Manohar},
	year         = 2018,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {6450--6459}
}
@inproceedings{fan2019more,
	title        = {More is less: Learning efficient video representations by big-little network and depthwise temporal aggregation},
	author       = {Fan, Quanfu and Chen, Chun-Fu and Kuehne, Hilde and Pistoia, Marco and Cox, David},
	year         = 2019,
	booktitle    = {Advances in Neural Information Processing Systems}
}
@inproceedings{jiang2019stm,
	title        = {Stm: Spatiotemporal and motion encoding for action recognition},
	author       = {Jiang, Boyuan and Wang, MengMeng and Gan, Weihao and Wu, Wei and Yan, Junjie},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages        = {2000--2009}
}
@inproceedings{li2020tea,
	title        = {Tea: Temporal excitation and aggregation for action recognition},
	author       = {Li, Yan and Ji, Bin and Shi, Xintian and Zhang, Jianguo and Kang, Bin and Wang, Limin},
	year         = 2020,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {909--918}
}
@inproceedings{lin2019tsm,
	title        = {Tsm: Temporal shift module for efficient video understanding},
	author       = {Lin, Ji and Gan, Chuang and Han, Song},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages        = {7083--7093}
}
@inproceedings{wang2018non,
	title        = {Non-local neural networks},
	author       = {Wang, Xiaolong and Girshick, Ross and Gupta, Abhinav and He, Kaiming},
	year         = 2018,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {7794--7803}
}
@inproceedings{deng2009imagenet,
	title        = {Imagenet: A large-scale hierarchical image database},
	author       = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
	year         = 2009,
	booktitle    = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {248--255},
	organization = {Ieee}
}
@inproceedings{yeung2016end,
	title        = {End-to-end learning of action detection from frame glimpses in videos},
	author       = {Yeung, Serena and Russakovsky, Olga and Mori, Greg and Fei-Fei, Li},
	year         = 2016,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {2678--2687}
}
@inproceedings{kristan2019seventh,
	title        = {The seventh visual object tracking vot2019 challenge results},
	author       = {Kristan, Matej and Matas, Jiri and Leonardis, Ales and Felsberg, Michael and Pflugfelder, Roman and Kamarainen, Joni-Kristian and Cehovin Zajc, Luka and Drbohlav, Ondrej and Lukezic, Alan and Berg, Amanda and others},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops},
	pages        = {0--0}
}
@inproceedings{ke2019time,
	title        = {Time-conditioned action anticipation in one shot},
	author       = {Ke, Qiuhong and Fritz, Mario and Schiele, Bernt},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {9925--9934}
}
@inproceedings{liu2016spatio,
	title        = {Spatio-temporal lstm with trust gates for 3d human action recognition},
	author       = {Liu, Jun and Shahroudy, Amir and Xu, Dong and Wang, Gang},
	year         = 2016,
	booktitle    = {European Conference on Computer Vision},
	pages        = {816--833},
	organization = {Springer}
}
@inproceedings{liu2017global,
	title        = {Global context-aware attention lstm networks for 3d action recognition},
	author       = {Liu, Jun and Wang, Gang and Hu, Ping and Duan, Ling-Yu and Kot, Alex C},
	year         = 2017,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {1647--1656}
}
@inproceedings{qiu2017learning,
	title        = {Learning spatio-temporal representation with pseudo-3d residual networks},
	author       = {Qiu, Zhaofan and Yao, Ting and Mei, Tao},
	year         = 2017,
	booktitle    = {proceedings of the IEEE International Conference on Computer Vision},
	pages        = {5533--5541}
}
@inproceedings{tran2015learning,
	title        = {Learning spatiotemporal features with 3d convolutional networks},
	author       = {Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
	year         = 2015,
	booktitle    = {Proceedings of the IEEE International Conference on Computer Vision},
	pages        = {4489--4497}
}
@inproceedings{vaswani2017attention,
	title        = {Attention is All you Need},
	author       = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
	year         = 2017,
	booktitle    = {Advances in Neural Information Processing Systems},
	volume       = 30,
	pages        = {5998--6008}
}
@inproceedings{devlin2019bert,
	title        = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	author       = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
	pages        = {4171--4186}
}
@article{touvron2020training,
	title        = {Training data-efficient image transformers \& distillation through attention},
	author       = {Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2012.12877}
}
@inproceedings{ramachandran2019stand,
	title        = {Stand-alone self-attention in vision models},
	author       = {Ramachandran, Prajit and Parmar, Niki and Vaswani, Ashish and Bello, Irwan and Levskaya, Anselm and Shlens, Jonathon},
	year         = 2019,
	booktitle    = {Advances in Neural Information Processing Systems}
}
@inproceedings{parmar2018image,
	title        = {Image transformer},
	author       = {Parmar, Niki and Vaswani, Ashish and Uszkoreit, Jakob and Kaiser, Lukasz and Shazeer, Noam and Ku, Alexander and Tran, Dustin},
	year         = 2018,
	booktitle    = {International Conference on Machine Learning},
	pages        = {4055--4064},
	organization = {PMLR}
}
@article{chu2021we,
	title        = {Do We Really Need Explicit Position Encodings for Vision Transformers?},
	author       = {Chu, Xiangxiang and Zhang, Bo and Tian, Zhi and Wei, Xiaolin and Xia, Huaxia},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2102.10882}
}
@article{wu2021cvt,
	title        = {Cvt: Introducing convolutions to vision transformers},
	author       = {Wu, Haiping and Xiao, Bin and Codella, Noel and Liu, Mengchen and Dai, Xiyang and Yuan, Lu and Zhang, Lei},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2103.15808}
}
@inproceedings{wang2021pyramid,
	title        = {Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
	author       = {Wang, Wenhai and others},
	year         = 2021,
	booktitle      = {Prof. ICCV}
}
@inproceedings{andoni2015practical,
	title        = {Practical and optimal LSH for angular distance},
	author       = {Andoni, Alexandr and Indyk, Piotr and Laarhoven, TMM and Razenshteyn, Ilya and Schmidt, Ludwig},
	year         = 2015,
	booktitle    = {Advances in Neural Information Processing Systems (NIPS 2015)},
	pages        = {1225--1233},
	organization = {Curran Associates}
}
@inproceedings{wang2020attentionnas,
	title        = {Attentionnas: Spatiotemporal attention cell search for video classification},
	author       = {Wang, Xiaofang and Xiong, Xuehan and Neumann, Maxim and Piergiovanni, AJ and Ryoo, Michael S and Angelova, Anelia and Kitani, Kris M and Hua, Wei},
	year         = 2020,
	booktitle    = {European Conference on Computer Vision},
	pages        = {449--465},
	organization = {Springer}
}
@article{carreira2018short,
	title        = {A short note about kinetics-600},
	author       = {Carreira, Joao and Noland, Eric and Banki-Horvath, Andras and Hillier, Chloe and Zisserman, Andrew},
	year         = 2018,
	journal      = {arXiv preprint arXiv:1808.01340}
}
@article{lecun1998gradient,
	title        = {Gradient-based learning applied to document recognition},
	author       = {LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
	year         = 1998,
	journal      = {Proceedings of the IEEE},
	publisher    = {Ieee},
	volume       = 86,
	number       = 11,
	pages        = {2278--2324}
}
@inproceedings{vedaldi2010vlfeat,
	title        = {VLFeat: An open and portable library of computer vision algorithms},
	author       = {Vedaldi, Andrea and Fulkerson, Brian},
	year         = 2010,
	booktitle    = {Proceedings of the 18th ACM International Conference on Multimedia},
	pages        = {1469--1472}
}
@inproceedings{goyal2017something,
	title        = {The" something something" video database for learning and evaluating visual common sense},
	author       = {Goyal, Raghav and Ebrahimi Kahou, Samira and Michalski, Vincent and Materzynska, Joanna and Westphal, Susanne and Kim, Heuna and Haenel, Valentin and Fruend, Ingo and Yianilos, Peter and Mueller-Freitag, Moritz and others},
	year         = 2017,
	booktitle    = {Proceedings of the IEEE International Conference on Computer Vision},
	pages        = {5842--5850}
}
@article{ridnik2021imagenet,
	title        = {ImageNet-21K Pretraining for the Masses},
	author       = {Ridnik, Tal and Ben-Baruch, Emanuel and Noy, Asaf and Zelnik-Manor, Lihi},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2104.10972}
}
@article{hendrycks2016gaussian,
	title        = {Gaussian error linear units (gelus)},
	author       = {Hendrycks, Dan and Gimpel, Kevin},
	year         = 2016,
	journal      = {arXiv preprint arXiv:1606.08415}
}
@article{monfort2019moments,
	title        = {Moments in time dataset: one million videos for event understanding},
	author       = {Monfort, Mathew and Andonian, Alex and Zhou, Bolei and Ramakrishnan, Kandan and Bargal, Sarah Adel and Yan, Tom and Brown, Lisa and Fan, Quanfu and Gutfreund, Dan and Vondrick, Carl and others},
	year         = 2019,
	journal      = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	publisher    = {IEEE},
	volume       = 42,
	number       = 2,
	pages        = {502--508}
}
@inproceedings{muller2019does,
	title        = {When does label smoothing help?},
	author       = {M{\"u}ller, Rafael and Kornblith, Simon and Hinton, Geoffrey},
	year         = 2019,
	booktitle    = {Advances in Neural Information Processing Systems}
}

@inproceedings{abnar2020quantifying,
	title        = {Quantifying Attention Flow in Transformers},
	author       = {Abnar, Samira and Zuidema, Willem},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2005.00928},
	booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
	pages        = {4190--4197}
}
@inproceedings{li2018resound,
	title        = {Resound: Towards action recognition without representation bias},
	author       = {Li, Yingwei and Li, Yi and Vasconcelos, Nuno},
	year         = 2018,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)},
	pages        = {513--528}
}
@inproceedings{zhu2016co,
	title        = {Co-occurrence feature learning for skeleton based action recognition using regularized deep LSTM networks},
	author       = {Zhu, Wentao and Lan, Cuiling and Xing, Junliang and Zeng, Wenjun and Li, Yanghao and Shen, Li and Xie, Xiaohui},
	year         = 2016,
	booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 30
}

@inproceedings{huang2020cycle,
	title        = {Cycle-Consistent Adversarial Autoencoders for Unsupervised Text Style Transfer},
	author       = {Huang, Yufang and Zhu, Wentao and Xiong, Deyi and Zhang, Yiye and Hu, Changjian and Xu, Feiyu},
	year         = 2020,
	booktitle    = {Proceedings of the 28th International Conference on Computational Linguistics},
	pages        = {2213--2223}
}
@inproceedings{li2021improved,
	title        = {Improved multiscale vision transformers for classification and detection},
	author       = {Li, Yanghao and others},
	year         = 2022,
	booktitle    = {Proc. CVPR}
}
@inproceedings{gong2021ast,
	title        = {{AST: Audio spectrogram transformer}},
	author       = {Gong, Yuan and Chung, Yu-An and Glass, James},
	year         = 2021,
	booktitle    = {Proc. Interspeech}
}
@inproceedings{liu2021video,
	title        = {Video swin transformer},
	author       = {Liu, Ze and Ning, Jia and Cao, Yue and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Hu, Han},
	year         = 2022,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {3202--3211}
}
@inproceedings{zha2021shifted,
	title        = {Shifted chunk transformer for spatio-temporal representational learning},
	author       = {Zha, Xuefan and Zhu, Wentao and Xun, Lv and Yang, Sen and Liu, Ji},
	year         = 2021,
	booktitle    = {Advances in Neural Information Processing Systems},
	volume       = 34
}
@inproceedings{li2022uniformer,
	title        = {Uniformer: Unified Transformer for Efficient Spatiotemporal Representation Learning},
	author       = {Li, Kunchang and Wang, Yali and Gao, Peng and Song, Guanglu and Liu, Yu and Li, Hongsheng and Qiao, Yu},
	year         = 2022,
	booktitle    = {International Conference on Learning Representations}
}
@inproceedings{yan2022multiview,
	title        = {Multiview Transformers for Video Recognition},
	author       = {Yan, Shen and Xiong, Xuehan and Arnab, Anurag and Lu, Zhichao and Zhang, Mi and Sun, Chen and Schmid, Cordelia},
	year         = 2022,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@inproceedings{nagrani2021attention,
	title        = {Attention bottlenecks for multimodal fusion},
	author       = {Nagrani, Arsha and others},
	year         = 2021,
	booktitle      = {NeurIPS},
	volume       = 34
}
@inproceedings{radford2021learning,
	title        = {Learning transferable visual models from natural language supervision},
	author       = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
	year         = 2021,
	booktitle    = {International Conference on Machine Learning},
	pages        = {8748--8763},
	organization = {PMLR}
}
@article{li2021align,
	title        = {Align before fuse: Vision and language representation learning with momentum distillation},
	author       = {Li, Junnan and Selvaraju, Ramprasaath and Gotmare, Akhilesh and Joty, Shafiq and Xiong, Caiming and Hoi, Steven Chu Hong},
	year         = 2021,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 34
}
@article{hendricks2021decoupling,
	title        = {Decoupling the role of data, attention, and losses in multimodal transformers},
	author       = {Hendricks, Lisa Anne and Mellor, John and Schneider, Rosalia and Alayrac, Jean-Baptiste and Nematzadeh, Aida},
	year         = 2021,
	journal      = {Transactions of the Association for Computational Linguistics},
	publisher    = {MIT Press},
	volume       = 9,
	pages        = {570--585}
}
@article{savitzky1964smoothing,
	title        = {Smoothing and differentiation of data by simplified least squares procedures.},
	author       = {Savitzky, Abraham and Golay, Marcel JE},
	year         = 1964,
	journal      = {Analytical chemistry},
	publisher    = {ACS Publications},
	volume       = 36,
	number       = 8,
	pages        = {1627--1639}
}
@inproceedings{zeiler2010deconvolutional,
	title        = {Deconvolutional networks},
	author       = {Zeiler, Matthew D and Krishnan, Dilip and Taylor, Graham W and Fergus, Rob},
	year         = 2010,
	booktitle    = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	pages        = {2528--2535},
	organization = {IEEE}
}
@inproceedings{loshchilov2018decoupled,
	title        = {Decoupled Weight Decay Regularization},
	author       = {Loshchilov, Ilya and Hutter, Frank},
	year         = 2018,
	booktitle    = {ICLR}
}
@inproceedings{gemmeke2017audio,
	title        = {Audio set: An ontology and human-labeled dataset for audio events},
	author       = {Gemmeke, Jort F and others},
	year         = 2017,
	booktitle    = {ICASSP},
	organization = {IEEE}
}
@inproceedings{zellers2022merlot,
	title        = {Merlot reserve: Neural script knowledge through vision and language and sound},
	author       = {Zellers, Rowan and Lu, Jiasen and Lu, Ximing and Yu, Youngjae and Zhao, Yanpeng and Salehi, Mohammadreza and Kusupati, Aditya and Hessel, Jack and Farhadi, Ali and Choi, Yejin},
	year         = 2022,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {16375--16387}
}
@inproceedings{liang2021dualformer,
	title        = {DualFormer: Local-Global Stratified Transformer for Efficient Video Recognition},
	author       = {Liang, Yuxuan and Zhou, Pan and Zimmermann, Roger and Yan, Shuicheng},
	year         = 2022,
	booktitle    = {European Conference on Computer Vision}
}
@article{Damen2021RESCALING,
	title        = {{Rescaling Egocentric Vision: Collection, Pipeline and Challenges for EPIC-KITCHENS-100}},
	author       = {Damen, Dima and others},
	year         = 2021,
	journal      = {IJCV},
	url          = {https://doi.org/10.1007/s11263-021-01531-2}
}
@inproceedings{Damen2018EPICKITCHENS,
	title        = {{Scaling Egocentric Vision: The EPIC-KITCHENS Dataset}},
	author       = {Damen, Dima and others},
	year         = 2018,
	booktitle    = {ECCV}
}
@article{Damen2021PAMI,
	title        = {{The EPIC-KITCHENS Dataset: Collection, Challenges and Baselines}},
	author       = {Damen, Dima and others},
	year         = 2021,
	journal      = {IEEE TPAMI},
	doi          = {10.1109/TPAMI.2020.2991965}
}
@inproceedings{arandjelovic2017look,
	title        = {Look, listen and learn},
	author       = {Arandjelovic, Relja and Zisserman, Andrew},
	year         = 2017,
	booktitle    = {Proc. ICCV},
	pages        = {609--617}
}
@inproceedings{chen2020vggsound,
	title        = {{VGGSound: A large-scale audio-visual dataset}},
	author       = {Chen, Honglie and others},
	year         = 2020,
	booktitle    = {ICASSP},
	pages        = {721--725},
	organization = {IEEE}
}
@article{xiao2020audiovisual,
	title        = {Audiovisual slowfast networks for video recognition},
	author       = {Xiao, Fanyi and others},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2001.08740}
}
@inproceedings{kazakos2021slow,
	title        = {Slow-fast auditory streams for audio recognition},
	author       = {Kazakos, Evangelos and others},
	year         = 2021,
	booktitle    = {ICASSP},
	pages        = {855--859},
	organization = {IEEE}
}
@inproceedings{zhou2018temporal,
	title        = {Temporal relational reasoning in videos},
	author       = {Zhou, Bolei and Andonian, Alex and Oliva, Aude and Torralba, Antonio},
	year         = 2018,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)},
	pages        = {803--818}
}
@inproceedings{kazakos2019epic,
	title        = {Epic-fusion: Audio-visual temporal binding for egocentric action recognition},
	author       = {Kazakos, Evangelos and others},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages        = {5492--5501}
}
@inproceedings{selvaraju2017grad,
	title        = {Grad-cam: Visual explanations from deep networks via gradient-based localization},
	author       = {Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
	year         = 2017,
	booktitle    = {Proceedings of the IEEE International Conference on Computer Vision},
	pages        = {618--626}
}
@inproceedings{hershey2017cnn,
	title        = {CNN architectures for large-scale audio classification},
	author       = {Hershey, Shawn and others},
	year         = 2017,
	booktitle    = {ICASSP}
}
@article{ba2016layer,
	title        = {Layer normalization},
	author       = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
	year         = 2016,
	journal      = {arXiv preprint arXiv:1607.06450}
}
@inproceedings{Kazakos2021SlowFastAuditory,
	title        = {Slow-Fast Auditory Streams For Audio Recognition},
	author       = {Kazakos, Evangelos and Nagrani, Arsha and Zisserman, Andrew and Damen, Dima},
	year         = 2021,
	booktitle    = {IEEE international conference on acoustics, speech and signal processing (ICASSP)}
}
@inproceedings{de1994learning,
	title        = {Learning classification with unlabeled data},
	author       = {de Sa, Virginia R},
	year         = 1994,
	booktitle    = {Advances in neural information processing systems}
}
@inproceedings{korbar2018cooperative,
	title        = {Cooperative learning of audio and video models from self-supervised synchronization},
	author       = {Korbar, Bruno and Tran, Du and Torresani, Lorenzo},
	year         = 2018,
	booktitle    = {Advances in Neural Information Processing Systems}
}
@article{mcgurk1976hearing,
	title        = {Hearing lips and seeing voices},
	author       = {McGurk, Harry and MacDonald, John},
	year         = 1976,
	journal      = {Nature}
}
@inproceedings{xianCVPR17,
	title        = {Zero-Shot Learning - The Good, the Bad and the Ugly},
	author       = {Yongqin Xian and Bernt Schiele and Zeynep Akata},
	year         = 2017,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
% ==== Multi-modal transformers
@inproceedings{lin2020audiovisual,
	title        = {Audiovisual Transformer with Instance Attention for Audio-Visual Event Localization},
	author       = {Lin, Yan-Bo and Wang, Yu-Chiang Frank},
	year         = 2020,
	booktitle    = {Proceedings of the Asian Conference on Computer Vision}
}
@inproceedings{boes2019audiovisual,
	title        = {Audiovisual transformer architectures for large-scale classification and synchronization of weakly labeled audio events},
	author       = {Boes, Wim and Van hamme, Hugo},
	year         = 2019,
	booktitle    = {Proceedings of the ACM International Conference on Multimedia}
}
@article{bain2021frozen,
	title        = {Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval},
	author       = {Bain, Max and Nagrani, Arsha and Varol, G{\"u}l and Zisserman, Andrew},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2104.00650}
}
@article{wang2021t2vlad,
	title        = {T2vlad: global-local sequence alignment for text-video retrieval},
	author       = {Wang, Xiaohan and Zhu, Linchao and Yang, Yi},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2104.10054}
}
@article{liu2021hit,
	title        = {HiT: Hierarchical Transformer with Momentum Contrast for Video-Text Retrieval},
	author       = {Liu, Song and Fan, Haoqi and Qian, Shengsheng and Chen, Yiru and Ding, Wenkui and Wang, Zhongyuan},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2103.15049}
}
@article{tan2019lxmert,
	title        = {Lxmert: Learning cross-modality encoder representations from transformers},
	author       = {Tan, Hao and Bansal, Mohit},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1908.07490}
}
@article{su2019vl,
	title        = {Vl-bert: Pre-training of generic visual-linguistic representations},
	author       = {Su, Weijie and Zhu, Xizhou and Cao, Yue and Li, Bin and Lu, Lewei and Wei, Furu and Dai, Jifeng},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1908.08530}
}
@article{li2019visualbert,
	title        = {Visualbert: A simple and performant baseline for vision and language},
	author       = {Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1908.03557}
}
@inproceedings{li2020unicoder,
	title        = {Unicoder-vl: A universal encoder for vision and language by cross-modal pre-training},
	author       = {Li, Gen and Duan, Nan and Fang, Yuejian and Gong, Ming and Jiang, Daxin},
	year         = 2020,
	booktitle    = aaai
}
@article{lu2019vilbert,
	title        = {Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
	author       = {Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1908.02265}
}
@inproceedings{sun2019videobert,
	title        = {Videobert: A joint model for video and language representation learning},
	author       = {Sun, Chen and Myers, Austin and Vondrick, Carl and Murphy, Kevin and Schmid, Cordelia},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE International Conference on Computer Vision}
}
@article{sun2019learning,
	title        = {Learning video representations using contrastive bidirectional transformer},
	author       = {Sun, Chen and Baradel, Fabien and Murphy, Kevin and Schmid, Cordelia},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1906.05743}
}
@inproceedings{gabeur2020multi,
	title        = {Multi-modal transformer for video retrieval},
	author       = {Gabeur, Valentin and Sun, Chen and Alahari, Karteek and Schmid, Cordelia},
	year         = 2020,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)}
}
@article{iashin2020better,
	title        = {A better use of audio-visual cues: Dense video captioning with bi-modal transformer},
	author       = {Iashin, Vladimir and Rahtu, Esa},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2005.08271}
}
%  ===
@inproceedings{zhou2019vision,
	title        = {Vision-infused deep audio inpainting},
	author       = {Zhou, Hang and Liu, Ziwei and Xu, Xudong and Luo, Ping and Wang, Xiaogang},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE International Conference on Computer Vision}
}
@inproceedings{goldstein2018guitar,
	title        = {Guitar Music Transcription from Silent Video.},
	author       = {Goldstein, Shir and Moses, Yael},
	year         = 2018,
	booktitle    = {Proceedings of the IEEE International Conference on Computer Vision}
}
@inproceedings{koepke2020sight,
	title        = {Sight to sound: An end-to-end approach for visual piano transcription},
	author       = {Koepke, A Sophia and Wiles, Olivia and Moses, Yael and Zisserman, Andrew},
	year         = 2020,
	booktitle    = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}
}
@article{su2020multi,
	title        = {Multi-Instrumentalist Net: Unsupervised Generation of Music from Body Movements},
	author       = {Su, Kun and Liu, Xiulong and Shlizerman, Eli},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2012.03478}
}
@inproceedings{gan2020foley,
	title        = {Foley music: Learning to generate music from videos},
	author       = {Gan, Chuang and Huang, Deng and Chen, Peihao and Tenenbaum, Joshua B and Torralba, Antonio},
	year         = 2020,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)}
}

@inproceedings{narasimhan2021strumming,
  title={Strumming to the beat: Audio-conditioned contrastive video textures},
  author={Narasimhan, Medhini and Ginosar, Shiry and Owens, Andrew and Efros, Alexei A and Darrell, Trevor},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={3761--3770},
  year={2022}
}

@inproceedings{afouras2021selfsupervised,
	title        = {Self-supervised object detection from audio-visual correspondence},
	author       = {Afouras, Triantafyllos and Asano, Yuki M and Fagan, Francois and Vedaldi, Andrea and Metze, Florian},
	year         = 2020,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)}
}
@inproceedings{Afouras20b,
	title        = {Self-Supervised Learning of Audio-Visual Objects from Video},
	author       = {Triantafyllos Afouras and Andrew Owens and Joon~Son Chung and Andrew Zisserman},
	year         = 2020,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)}
}
@inproceedings{chen2021distilling,
	title        = {Distilling Audio-Visual Knowledge by Compositional Contrastive Learning},
	author       = {Chen, Yanbei and Xian, Yongqin and Koepke, A. Sophia and Shan, Ying and Akata, Zeynep},
	year         = 2021,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@article{kong2020panns,
	title        = {{PANNS: Large-scale pretrained audio neural networks for audio pattern recognition}},
	author       = {Kong, Qiuqiang and others},
	year         = 2020,
	journal      = {IEEE/ACM TASLP}
}
@article{chen2021and,
	title        = {Where and When: Space-Time Attention for Audio-Visual Explanations},
	author       = {Chen, Yanbei and Hummel, Thomas and Koepke, A. Sophia and Akata, Zeynep},
	year         = 2021,
	journal      = {arXiv e-prints}
}
@inproceedings{chen2021localizing,
	title        = {Localizing Visual Sounds the Hard Way},
	author       = {Chen, Honglie and Xie, Weidi and Afouras, Triantafyllos and Nagrani, Arsha and Vedaldi, Andrea and Zisserman, Andrew},
	year         = 2021,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@inproceedings{caba2015activitynet,
	title        = {ActivityNet: A Large-Scale Video Benchmark for Human Activity Understanding},
	author       = {Fabian Caba Heilbron, Victor Escorcia, Bernard Ghanem and Juan Carlos Niebles},
	year         = 2015,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {961--970}
}
@inproceedings{wu2017unified,
	title        = {A unified view of multi-label performance measures},
	author       = {Wu, Xi-Zhu and Zhou, Zhi-Hua},
	year         = 2017,
	booktitle    = icml
}
@inproceedings{parekh2018weakly,
	title        = {Weakly supervised representation learning for unsynchronized audio-visual events},
	author       = {Parekh, Sanjeel and Essid, Slim and Ozerov, Alexey and Duong, Ngoc QK and P{\'e}rez, Patrick and Richard, Ga{\"e}l},
	year         = 2018,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops}
}
@inproceedings{santoro2017simple,
	title        = {A simple neural network module for relational reasoning},
	author       = {Santoro, Adam and Raposo, David and Barrett, David G and Malinowski, Mateusz and Pascanu, Razvan and Battaglia, Peter and Lillicrap, Timothy},
	year         = 2017,
	booktitle    = nips
}
@inproceedings{perez2018film,
	title        = {Film: Visual reasoning with a general conditioning layer},
	author       = {Perez, Ethan and Strub, Florian and De Vries, Harm and Dumoulin, Vincent and Courville, Aaron},
	year         = 2018,
	booktitle    = aaai
}
@inproceedings{fayek2020large,
	title        = {Large Scale Audiovisual Learning of Sounds with Weakly Labeled Data},
	author       = {Fayek, Haytham M and Kumar, Anurag},
	year         = 2020,
	booktitle    = ijcai
}
@inproceedings{owens2016ambient,
	title        = {Ambient sound provides supervision for visual learning},
	author       = {Owens, Andrew and Wu, Jiajun and McDermott, Josh H and Freeman, William T and Torralba, Antonio},
	year         = 2016,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)}
}
@inproceedings{owens2018audio,
	title        = {Audio-visual scene analysis with self-supervised multisensory features},
	author       = {Owens, Andrew and Efros, Alexei A},
	year         = 2018,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)}
}
@article{owens2018learning,
	title        = {Learning sight from sound: Ambient sound provides supervision for visual learning},
	author       = {Owens, Andrew and Wu, Jiajun and McDermott, Josh H and Freeman, William T and Torralba, Antonio},
	year         = 2018,
	journal      = {International Journal of Computer Vision}
}

@inproceedings{morgado2020audio,
  title={Audio-visual instance discrimination with cross-modal agreement},
  author={Morgado, Pedro and Vasconcelos, Nuno and Misra, Ishan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12475--12486},
  year={2021}
}

@inproceedings{alwassel2019self,
	title        = {Self-supervised learning by cross-modal audio-video clustering},
	author       = {Alwassel, Humam and Mahajan, Dhruv and Torresani, Lorenzo and Ghanem, Bernard and Tran, Du},
	year         = 2020,
	booktitle    = {Advances in Neural Information Processing Systems}
}
@inproceedings{patrick2020multi,
	title        = {Multi-modal self-supervision from generalized data transformations},
	author       = {Patrick, Mandela and Asano, Yuki M and Fong, Ruth and Henriques, Jo{\~a}o F and Zweig, Geoffrey and Vedaldi, Andrea},
	year         = 2020,
	booktitle    = {Advances in Neural Information Processing Systems}
}
@article{rouditchenko2020avlnet,
	title        = {AVLnet: Learning Audio-Visual Language Representations from Instructional Videos},
	author       = {Rouditchenko, Andrew and Boggust, Angie and Harwath, David and Joshi, Dhiraj and Thomas, Samuel and Audhkhasi, Kartik and Feris, Rogerio and Kingsbury, Brian and Picheny, Michael and Torralba, Antonio and others},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2006.09199}
}
@inproceedings{asano2020labelling,
	title        = {Labelling unlabelled videos from scratch with multi-modal self-supervision},
	author       = {Yuki M. Asano and Mandela Patrick and Christian Rupprecht and Andrea Vedaldi},
	year         = 2020,
	booktitle    = {Advances in Neural Information Processing Systems}
}
%
@inproceedings{wang2020mead,
	title        = {Mead: A large-scale audio-visual dataset for emotional talking-face generation},
	author       = {Wang, Kaisiyuan and Wu, Qianyi and Song, Linsen and Yang, Zhuoqian and Wu, Wayne and Qian, Chen and He, Ran and Qiao, Yu and Loy, Chen Change},
	year         = 2020,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)}
}
@inproceedings{gao20192,
	title        = {2.5 d visual sound},
	author       = {Gao, Ruohan and Grauman, Kristen},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@inproceedings{gao2019co,
	title        = {Co-separating sounds of visual objects},
	author       = {Gao, Ruohan and Grauman, Kristen},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE International Conference on Computer Vision}
}
@inproceedings{zhao2019sound,
	title        = {The sound of motions},
	author       = {Zhao, Hang and Gan, Chuang and Ma, Wei-Chiu and Torralba, Antonio},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE International Conference on Computer Vision}
}
@inproceedings{afouras2020self,
	title        = {Self-supervised learning of audio-visual objects from video},
	author       = {Afouras, Triantafyllos and Owens, Andrew and Chung, Joon Son and Zisserman, Andrew},
	year         = 2020,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)}
}
@inproceedings{gan2019self,
	title        = {Self-supervised moving vehicle tracking with stereo sound},
	author       = {Gan, Chuang and Zhao, Hang and Chen, Peihao and Cox, David and Torralba, Antonio},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE International Conference on Computer Vision}
}
@inproceedings{tian2018audio,
	title        = {Audio-visual event localization in unconstrained videos},
	author       = {Tian, Yapeng and Shi, Jing and Li, Bochen and Duan, Zhiyao and Xu, Chenliang},
	year         = 2018,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)}
}
@inproceedings{arandjelovic2018objects,
	title        = {Objects that sound},
	author       = {Arandjelovic, Relja and Zisserman, Andrew},
	year         = 2018,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)}
}
@inproceedings{zhao2018sound,
	title        = {The sound of pixels},
	author       = {Zhao, Hang and Gan, Chuang and Rouditchenko, Andrew and Vondrick, Carl and McDermott, Josh and Torralba, Antonio},
	year         = 2018,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)}
}
@article{afouras2018deep,
	title        = {Deep audio-visual speech recognition},
	author       = {Afouras, Triantafyllos and Chung, Joon Son and Senior, Andrew and Vinyals, Oriol and Zisserman, Andrew},
	year         = 2018,
	journal      = {IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)}
}
%
@article{noroozi2017audio,
	title        = {Audio-visual emotion recognition in video clips},
	author       = {Noroozi, Fatemeh and Marjanovic, Marina and Njegus, Angelina and Escalera, Sergio and Anbarjafari, Gholamreza},
	year         = 2017,
	journal      = {IEEE Transactions on Affective Computing}
}
@inproceedings{kodirov2017semantic,
	title        = {Semantic autoencoder for zero-shot learning},
	author       = {Kodirov, Elyor and Xiang, Tao and Gong, Shaogang},
	year         = 2017,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@inproceedings{romera2015embarrassingly,
	title        = {An embarrassingly simple approach to zero-shot learning},
	author       = {Romera-Paredes, Bernardino and Torr, Philip},
	year         = 2015,
	booktitle    = icml
}
@inproceedings{xu2020attribute,
	title        = {Attribute prototype network for zero-shot learning},
	author       = {Xu, Wenjia and Xian, Yongqin and Wang, Jiuniu and Schiele, Bernt and Akata, Zeynep},
	year         = 2020,
	booktitle    = {Advances in neural information processing systems}
}
@inproceedings{zhu2018fine,
	title        = {Fine-grained video categorization with redundancy reduction attention},
	author       = {Zhu, Chen and Tan, Xiao and Zhou, Feng and Liu, Xiao and Yue, Kaiyu and Ding, Errui and Ma, Yi},
	year         = 2018,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)}
}
@inproceedings{mikolov2013efficient,
	title        = {Efficient estimation of word representations in vector space},
	author       = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	year         = 2013,
	journal      = {arXiv preprint arXiv:1301.3781},
	booktitle    = {International Conference on Learning Representations}
}
@inproceedings{huang2017densely,
	title        = {Densely connected convolutional networks},
	author       = {Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q.},
	year         = 2017,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@techreport{WahCUB_200_2011,
	title        = {{The Caltech-UCSD Birds-200-2011 Dataset}},
	author       = {Wah, C. and Branson, S. and Welinder, P. and Perona, P. and Belongie, S.},
	year         = 2011,
	institution  = {California Institute of Technology}
}
@inproceedings{he2016deep,
	title        = {Deep residual learning for image recognition},
	author       = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	year         = 2016,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {770--778}
}
@inproceedings{zagoruyko2016wide,
	title        = {Wide residual networks},
	author       = {Zagoruyko, Sergey and Komodakis, Nikos},
	year         = 2016,
	booktitle    = {Proceedings of the British Machine Vision Conference}
}
@article{xian2018zero,
	title        = {Zero-shot learninga comprehensive evaluation of the good, the bad and the ugly},
	author       = {Xian, Yongqin and Lampert, Christoph H and Schiele, Bernt and Akata, Zeynep},
	year         = 2018,
	journal      = {IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)}
}
@inproceedings{narayan2020latent,
	title        = {Latent embedding feedback and discriminative features for zero-shot classification},
	author       = {Narayan, Sanath and Gupta, Akshita and Khan, Fahad Shahbaz and Snoek, Cees GM and Shao, Ling},
	year         = 2020,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)}
}
@inproceedings{zhu2019learning,
	title        = {Learning feature-to-feature translator by alternating back-propagation for generative zero-shot learning},
	author       = {Zhu, Yizhe and Xie, Jianwen and Liu, Bingchen and Elgammal, Ahmed},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE International Conference on Computer Vision}
}
@inproceedings{akata2015evaluation,
	title        = {Evaluation of output embeddings for fine-grained image classification},
	author       = {Akata, Zeynep and Reed, Scott and Walter, Daniel and Lee, Honglak and Schiele, Bernt},
	year         = 2015,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@article{akata2015label,
	title        = {Label-embedding for image classification},
	author       = {Akata, Zeynep and Perronnin, Florent and Harchaoui, Zaid and Schmid, Cordelia},
	year         = 2015,
	journal      = {IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)}
}
@inproceedings{parida2020coordinated,
	title        = {Coordinated joint multimodal embeddings for generalized audio-visual zero-shot classification and retrieval of videos},
	author       = {Parida, Kranti and Matiyali, Neeraj and Guha, Tanaya and Sharma, Gaurav},
	year         = 2020,
	booktitle    = {IEEE Winter Conference on Applications of Computer Vision (WACV)}
}
@inproceedings{dutta2019semantically,
	title        = {Semantically tied paired cycle consistency for zero-shot sketch-based image retrieval},
	author       = {Dutta, Anjan and Akata, Zeynep},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@article{chaudhuri2020crossatnet,
	title        = {CrossATNet-a novel cross-attention based framework for sketch-based image retrieval},
	author       = {Chaudhuri, Ushasi and Banerjee, Biplab and Bhattacharya, Avik and Datcu, Mihai},
	year         = 2020,
	journal      = {Image and Vision Computing}
}
@inproceedings{xian2019f,
	title        = {f-vaegan-d2: A feature generating framework for any-shot learning},
	author       = {Xian, Yongqin and Sharma, Saurabh and Schiele, Bernt and Akata, Zeynep},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@inproceedings{chao2016empirical,
	title        = {An empirical study and analysis of generalized zero-shot learning for object recognition in the wild},
	author       = {Chao, Wei-Lun and Changpinyo, Soravit and Gong, Boqing and Sha, Fei},
	year         = 2016,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)}
}
@inproceedings{xiao2010sun,
	title        = {Sun database: Large-scale scene recognition from abbey to zoo},
	author       = {Xiao, Jianxiong and Hays, James and Ehinger, Krista A and Oliva, Aude and Torralba, Antonio},
	year         = 2010,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@inproceedings{brattoli2020rethinking,
	title        = {Rethinking zero-shot video classification: End-to-end training for realistic applications},
	author       = {Brattoli, Biagio and Tighe, Joseph and Zhdanov, Fedor and Perona, Pietro and Chalupka, Krzysztof},
	year         = 2020,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {4613--4623}
}
@inproceedings{bishay2019tarn,
	title        = {Tarn: Temporal attentive relation network for few-shot and zero-shot action recognition},
	author       = {Bishay, Mina and Zoumpourlis, Georgios and Patras, Ioannis},
	year         = 2019,
	booktitle    = {Proceedings of the British Machine Vision Conference}
}
@article{hahn2019action2vec,
	title        = {Action2vec: A crossmodal embedding approach to action learning},
	author       = {Hahn, Meera and Silva, Andrew and Rehg, James M},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1901.00484}
}
@inproceedings{dey2019doodle,
	title        = {Doodle to search: Practical zero-shot sketch-based image retrieval},
	author       = {Dey, Sounak and Riba, Pau and Dutta, Anjan and Llados, Josep and Song, Yi-Zhe},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@inproceedings{xie2019attentive,
	title        = {Attentive region embedding network for zero-shot learning},
	author       = {Xie, Guo-Sen and Liu, Li and Jin, Xiaobo and Zhu, Fan and Zhang, Zheng and Qin, Jie and Yao, Yazhou and Shao, Ling},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@inproceedings{pennington2014glove,
	title        = {GloVe: Global Vectors for Word Representation},
	author       = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
	year         = 2014,
	booktitle    = emnlp
}
@inproceedings{liu2019attribute,
	title        = {Attribute attention for semantic disambiguation in zero-shot learning},
	author       = {Liu, Yang and Guo, Jishun and Cai, Deng and He, Xiaofei},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@inproceedings{morgado2017semantically,
	title        = {Semantically consistent regularization for zero-shot recognition},
	author       = {Morgado, Pedro and Vasconcelos, Nuno},
	year         = 2017,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}

@article{abu2016youtube,
	title        = {Youtube-8m: A large-scale video classification benchmark},
	author       = {Abu-El-Haija, Sami and Kothari, Nisarg and Lee, Joonseok and Natsev, Paul and Toderici, George and Varadarajan, Balakrishnan and Vijayanarasimhan, Sudheendra},
	year         = 2016,
	journal      = {arXiv preprint arXiv:1609.08675}
}
@misc{license,
	title        = {Xeno-canto Creative Commons Licenses},
	note         = {[Online; accessed 23-Sept-2021]},
	howpublished = {\url{https://www.xeno-canto.org/about/terms}}
}
@inproceedings{xian2018feature,
	title        = {Feature generating networks for zero-shot learning},
	author       = {Xian, Yongqin and Lorenz, Tobias and Schiele, Bernt and Akata, Zeynep},
	year         = 2018,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {5542--5551}
}
@inproceedings{frome2013devise,
	title        = {Devise: A deep visual-semantic embedding model},
	author       = {Frome, Andrea and Corrado, Greg and Shlens, Jonathon and Bengio, Samy and Dean, Jeffrey and Ranzato, MarcAurelio and Mikolov, Tomas},
	year         = 2013,
	booktitle    = {Advances in neural information processing systems}
}
@inproceedings{farhadi2009describing,
	title        = {Describing objects by their attributes},
	author       = {Farhadi, Ali and Endres, Ian and Hoiem, Derek and Forsyth, David},
	year         = 2009,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@inproceedings{zhu2018generative,
	title        = {A generative adversarial approach for zero-shot learning from noisy texts},
	author       = {Zhu, Yizhe and Elhoseiny, Mohamed and Liu, Bingchen and Peng, Xi and Elgammal, Ahmed},
	year         = 2018,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@inproceedings{verma2018generalized,
	title        = {Generalized zero-shot learning via synthesized examples},
	author       = {Verma, Vinay Kumar and Arora, Gundeep and Mishra, Ashish and Rai, Piyush},
	year         = 2018,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@inproceedings{schonfeld2019generalized,
	title        = {Generalized zero-and few-shot learning via aligned variational autoencoders},
	author       = {Schonfeld, Edgar and Ebrahimi, Sayna and Sinha, Samarth and Darrell, Trevor and Akata, Zeynep},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@inproceedings{xu2016multi,
	title        = {Multi-task zero-shot action recognition with prioritised data augmentation},
	author       = {Xu, Xun and Hospedales, Timothy M and Gong, Shaogang},
	year         = 2016,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)},
	pages        = {343--359},
	organization = {Springer}
}
@article{wang2017zero,
	title        = {Zero-shot visual recognition via bidirectional latent embedding},
	author       = {Wang, Qian and Chen, Ke},
	year         = 2017,
	journal      = {International Journal of Computer Vision},
	publisher    = {Springer},
	volume       = 124,
	number       = 3,
	pages        = {356--383}
}
@inproceedings{roitberg2018towards,
	title        = {Towards a fair evaluation of zero-shot action recognition using external data},
	author       = {Roitberg, Alina and Martinez, Manuel and Haurilet, Monica and Stiefelhagen, Rainer},
	year         = 2018,
	booktitle    = {Proceedings of the European Conference on Computer Vision Workshop},
	pages        = {0--0}
}
@inproceedings{zhu2018towards,
	title        = {Towards universal representation for unseen action recognition},
	author       = {Zhu, Yi and Long, Yang and Guan, Yu and Newsam, Shawn and Shao, Ling},
	year         = 2018,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@inproceedings{devlin2018bert,
	title        = {Bert: Pre-training of deep bidirectional transformers for language understanding},
	author       = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1810.04805},
	booktitle    = {NAACL}
}
@inproceedings{choi2019zero,
	title        = {Zero-shot learning for audio-based music classification and tagging},
	author       = {Choi, Jeong and Lee, Jongpil and Park, Jiyoung and Nam, Juhan},
	year         = 2019,
	booktitle    = {ISMIR}
}
@inproceedings{usunier2009ranking,
	title        = {Ranking with ordered weighted pairwise classification},
	author       = {Usunier, Nicolas and Buffoni, David and Gallinari, Patrick},
	year         = 2009,
	booktitle    = icml
}
@inproceedings{nair2010rectified,
	title        = {Rectified linear units improve restricted boltzmann machines},
	author       = {Nair, Vinod and Hinton, Geoffrey E},
	year         = 2010,
	booktitle    = icml
}
@inproceedings{ioffe2015batch,
	title        = {Batch normalization: Accelerating deep network training by reducing internal covariate shift},
	author       = {Ioffe, Sergey and Szegedy, Christian},
	year         = 2015,
	booktitle    = icml
}
@article{JMLR:v15:srivastava14a,
	title        = {Dropout: a simple way to prevent neural networks from overfitting},
	author       = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	year         = 2014,
	journal      = {JMLR}
}
@article{gowda2021new,
	title        = {A New Split for Evaluating True Zero-Shot Action Recognition},
	author       = {Gowda, Shreyank N and Sevilla-Lara, Laura and Kim, Kiyoon and Keller, Frank and Rohrbach, Marcus},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2107.13029}
}
@inproceedings{kumar2018knowledge,
	title        = {Knowledge transfer from weakly labeled audio using convolutional neural network for sound events and scenes},
	author       = {Kumar, Anurag and Khadkevich, Maksim and F{\"u}gen, Christian},
	year         = 2018,
	booktitle    = {IEEE international conference on acoustics, speech and signal processing (ICASSP)}
}
@inproceedings{xuan2020cross,
	title        = {Cross-modal attention network for temporal inconsistent audio-visual event localization},
	author       = {Xuan, Hanyu and Zhang, Zhenyu and Chen, Shuo and Yang, Jian and Yan, Yan},
	year         = 2020,
	booktitle    = aaai
}
@inproceedings{min2020domain,
	title        = {Domain-aware visual bias eliminating for generalized zero-shot learning},
	author       = {Min, Shaobo and Yao, Hantao and Xie, Hongtao and Wang, Chaoqun and Zha, Zheng-Jun and Zhang, Yongdong},
	year         = 2020,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@article{wah2011caltech,
	title        = {The caltech-ucsd birds-200-2011 dataset},
	author       = {Wah, Catherine and Branson, Steve and Welinder, Peter and Perona, Pietro and Belongie, Serge},
	year         = 2011,
	publisher    = {California Institute of Technology}
}
@inproceedings{nagrani2020disentangled,
	title        = {Disentangled speech embeddings using cross-modal self-supervision},
	author       = {Nagrani, Arsha and Chung, Joon Son and Albanie, Samuel and Zisserman, Andrew},
	year         = 2020,
	booktitle    = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}
}
@inproceedings{xu2022vgse,
	title        = {VGSE: Visually-Grounded Semantic Embeddings for Zero-Shot Learning},
	author       = {Xu, Wenjia and Xian, Yongqin and Wang, Jiuniu and Schiele, Bernt and Akata, Zeynep},
	year         = 2022,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@inproceedings{momeni2020seeing,
	title        = {Seeing wake words: Audio-visual keyword spotting},
	author       = {Momeni, Liliane and Afouras, Triantafyllos and Stafylakis, Themos and Albanie, Samuel and Zisserman, Andrew},
	year         = 2020,
	booktitle    = {Proceedings of the British Machine Vision Conference}
}
@inproceedings{Prajwal2021,
	title        = {Visual Keyword Spotting with Attention},
	author       = {Prajwal, KR and Momeni, Liliane  and Afouras, Triantafyllos and Zisserman, Andrew},
	year         = 2021,
	booktitle    = {Proceedings of the British Machine Vision Conference}
}
@inproceedings{su2021does,
	title        = {How Does it Sound?},
	author       = {Su, Kun and Liu, Xiulong and Shlizerman, Eli},
	year         = 2021,
	booktitle    = {Advances in neural information processing systems}
}
@inproceedings{qian2020multiple,
	title        = {Multiple sound sources localization from coarse to fine},
	author       = {Qian, Rui and Hu, Di and Dinkel, Heinrich and Wu, Mengyue and Xu, Ning and Lin, Weiyao},
	year         = 2020,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)}
}
@inproceedings{xu2020cross,
	title        = {Cross-modal relation-aware networks for audio-visual event localization},
	author       = {Xu, Haoming and Zeng, Runhao and Wu, Qingyao and Tan, Mingkui and Gan, Chuang},
	year         = 2020,
	booktitle    = {Proceedings of the ACM International Conference on Multimedia}
}
@inproceedings{tzinis2020into,
	title        = {Into the wild with audioscope: Unsupervised audio-visual separation of on-screen sounds},
	author       = {Tzinis, Efthymios and Wisdom, Scott and Jansen, Aren and Hershey, Shawn and Remez, Tal and Ellis, Daniel PW and Hershey, John R},
	year         = 2021,
	booktitle    = {International Conference on Learning Representations}
}
@inproceedings{zhu2022v,
	title        = {V-slowfast network for efficient visual sound separation},
	author       = {Zhu, Lingyu and Rahtu, Esa},
	year         = 2022,
	booktitle    = {IEEE Winter Conference on Applications of Computer Vision (WACV)}
}
@inproceedings{chen2021audio,
	title        = {Audio-Visual Synchronisation in the wild},
	author       = {Chen, Honglie and Xie, Weidi and Afouras, Triantafyllos and Nagrani, Arsha and Vedaldi, Andrea and Zisserman, Andrew},
	year         = 2021,
	booktitle    = {Proceedings of the British Machine Vision Conference}
}
@inproceedings{chung2016out,
	title        = {Out of time: automated lip sync in the wild},
	author       = {Chung, Joon Son and Zisserman, Andrew},
	year         = 2016,
	booktitle    = {Proceedings of the Asian Conference on Computer Vision}
}
@inproceedings{ebeneze2021detection,
	title        = {Detection of audio-video synchronization errors via event detection},
	author       = {Ebeneze, Joshua P and Wu, Yongjun and Wei, Hai and Sethuraman, Sriram and Liu, Zongyi},
	year         = 2021,
	booktitle    = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}
}
@inproceedings{khosravan2019attention,
	title        = {On Attention Modules for Audio-Visual Synchronization.},
	author       = {Khosravan, Naji and Ardeshir, Shervin and Puri, Rohit},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshop}
}
@inproceedings{cheng2020look,
	title        = {Look, listen, and attend: Co-attention network for self-supervised audio-visual representation learning},
	author       = {Cheng, Ying and Wang, Ruize and Pan, Zhihao and Feng, Rui and Zhang, Yuejie},
	year         = 2020,
	booktitle    = {Proceedings of the ACM International Conference on Multimedia}
}
@inproceedings{brown2021face,
	title        = {Face, body, voice: Video person-clustering with multiple modalities},
	author       = {Brown, Andrew and Kalogeiton, Vicky and Zisserman, Andrew},
	year         = 2021,
	booktitle    = {Proceedings of the IEEE International Conference on Computer Vision}
}
@inproceedings{park2018multimodal,
	title        = {Multimodal explanations: Justifying decisions and pointing to the evidence},
	author       = {Park, Dong Huk and Hendricks, Lisa Anne and Akata, Zeynep and Rohrbach, Anna and Schiele, Bernt and Darrell, Trevor and Rohrbach, Marcus},
	year         = 2018,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@inproceedings{zellers2019recognition,
	title        = {From recognition to cognition: Visual commonsense reasoning},
	author       = {Zellers, Rowan and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@inproceedings{xu2020explainable,
	title        = {Explainable object-induced action decision for autonomous vehicles},
	author       = {Xu, Yiran and Yang, Xiaoyin and Gong, Lihang and Lin, Hsuan-Chu and Wu, Tz-Ying and Li, Yunsheng and Vasconcelos, Nuno},
	year         = 2020,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@inproceedings{kim2018textual,
	title        = {Textual explanations for self-driving vehicles},
	author       = {Kim, Jinkyu and Rohrbach, Anna and Darrell, Trevor and Canny, John and Akata, Zeynep},
	year         = 2018,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)}
}
%% language and other cues (bounding boxes)
% bounding boxes
% \cite{kanehira2019multimodal}
% \cite{hendricks2016generating,hendricks2018grounding}
@inproceedings{kanehira2019multimodal,
	title        = {Multimodal explanations by predicting counterfactuality in videos},
	author       = {Kanehira, Atsushi and Takemoto, Kentaro and Inayoshi, Sho and Harada, Tatsuya},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@inproceedings{hendricks2018grounding,
	title        = {Grounding visual explanations},
	author       = {Hendricks, Lisa Anne and Hu, Ronghang and Darrell, Trevor and Akata, Zeynep},
	year         = 2018,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)}
}
@inproceedings{hendricks2016generating,
	title        = {Generating visual explanations},
	author       = {Hendricks, Lisa Anne and Akata, Zeynep and Rohrbach, Marcus and Donahue, Jeff and Schiele, Bernt and Darrell, Trevor},
	year         = 2016,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)}
}
@inproceedings{tian2020unified,
	title        = {Unified multisensory perception: weakly-supervised audio-visual video parsing},
	author       = {Tian, Yapeng and Li, Dingzeyu and Xu, Chenliang},
	year         = 2020,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)}
}
@article{mesaros2016metrics,
	title        = {Metrics for polyphonic sound event detection},
	author       = {Mesaros, Annamaria and Heittola, Toni and Virtanen, Tuomas},
	year         = 2016,
	journal      = {Applied Sciences}
}
@inproceedings{karpathy2014sports,
	title        = {Large-Scale Video Classification with Convolutional Neural Networks},
	author       = {Karpathy, Andrej and Toderici, George and Shetty, Sanketh and Leung, Thomas and Sukthankar, Rahul and Fei-Fei, Li},
	year         = 2014,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@inproceedings{kingma2014adam,
	title        = {Adam: A method for stochastic optimization},
	author       = {Kingma, Diederik P and Ba, Jimmy},
	year         = 2015,
	booktitle    = {CoRR}
}
@article{ernst2004merging,
	title        = {Merging the senses into a robust percept},
	author       = {Ernst, Marc O and B{\"u}lthoff, Heinrich H},
	year         = 2004,
	journal      = {Trends in cognitive sciences}
}
% missing modalities
@article{miech2018learning,
	title        = {Learning a text-video embedding from incomplete and heterogeneous data},
	author       = {Miech, Antoine and Laptev, Ivan and Sivic, Josef},
	year         = 2018,
	journal      = {arXiv preprint arXiv:1804.02516}
}
@article{lee2020parameter,
	title        = {Parameter Efficient Multimodal Transformers for Video Representation Learning},
	author       = {Lee, Sangho and Yu, Youngjae and Kim, Gunhee and Breuel, Thomas and Kautz, Jan and Song, Yale},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2012.04124}
}
@inproceedings{tran2017missing,
	title        = {Missing modalities imputation via cascaded residual autoencoder},
	author       = {Tran, Luan and Liu, Xiaoming and Zhou, Jiayu and Jin, Rong},
	year         = 2017,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@inproceedings{mazumder2021avgzslnet,
	title        = {Avgzslnet: Audio-visual generalized zero-shot learning by reconstructing label features from multi-modal embeddings},
	author       = {Mazumder, Pratik and Singh, Pravendra and Parida, Kranti Kumar and Namboodiri, Vinay P},
	year         = 2021,
	booktitle    = {IEEE Winter Conference on Applications of Computer Vision (WACV)}
}
@inproceedings{xie2021zero,
	title        = {Zero-Shot Audio Classification with Factored Linear and Nonlinear Acoustic-Semantic Projections},
	author       = {Xie, Huang and R{\"a}s{\"a}nen, Okko and Virtanen, Tuomas},
	year         = 2021,
	booktitle    = {IEEE international conference on acoustics, speech and signal processing (ICASSP)}
}
@article{xie2021zeroieee,
	title        = {Zero-Shot Audio Classification via Semantic Embeddings},
	author       = {Xie, Huang and Virtanen, Tuomas},
	year         = 2021,
	journal      = {IEEE/ACM Transactions on Audio, Speech, and Language Processing}
}
@article{du2019techniques,
	title        = {Techniques for interpretable machine learning},
	author       = {Du, Mengnan and Liu, Ninghao and Hu, Xia},
	year         = 2019,
	journal      = {Communications of the ACM}
}
@inproceedings{zeiler2014visualizing,
	title        = {Visualizing and understanding convolutional networks},
	author       = {Zeiler, Matthew D and Fergus, Rob},
	year         = 2014,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)}
}
@inproceedings{mahendran2015understanding,
	title        = {Understanding deep image representations by inverting them},
	author       = {Mahendran, Aravindh and Vedaldi, Andrea},
	year         = 2015,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@article{simonyan2013deep,
	title        = {Deep inside convolutional networks: Visualising image classification models and saliency maps},
	author       = {Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
	year         = 2013,
	journal      = {arXiv preprint arXiv:1312.6034}
}
% \cite{zhou2016learning,fukui2019attention,liznerski2020explainable}
% CAM
@inproceedings{zhou2016learning,
	title        = {Learning deep features for discriminative localization},
	author       = {Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
	year         = 2016,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
% ABN
@inproceedings{fukui2019attention,
	title        = {Attention branch network: Learning of attention mechanism for visual explanation},
	author       = {Fukui, Hiroshi and Hirakawa, Tsubasa and Yamashita, Takayoshi and Fujiyoshi, Hironobu},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@inproceedings{wang2019sharpen,
	title        = {Sharpen focus: Learning with attention separability and consistency},
	author       = {Wang, Lezi and Wu, Ziyan and Karanam, Srikrishna and Peng, Kuan-Chuan and Singh, Rajat Vikram and Liu, Bo and Metaxas, Dimitris N},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE International Conference on Computer Vision}
}
@article{zhang2018top,
	title        = {Top-down neural attention by excitation backprop},
	author       = {Zhang, Jianming and Bargal, Sarah Adel and Lin, Zhe and Brandt, Jonathan and Shen, Xiaohui and Sclaroff, Stan},
	year         = 2018,
	journal      = {International Journal of Computer Vision}
}
% one-class
@inproceedings{liznerski2020explainable,
	title        = {Explainable deep one-class classification},
	author       = {Liznerski, Philipp and Ruff, Lukas and Vandermeulen, Robert A and Franks, Billy Joe and Kloft, Marius and M{\"u}ller, Klaus-Robert},
	year         = 2021,
	booktitle    = {International Conference on Learning Representations}
}
% one-class
@inproceedings{liu2020towards,
	title        = {Towards visually explaining variational autoencoders},
	author       = {Liu, Wenqian and Li, Runze and Zheng, Meng and Karanam, Srikrishna and Wu, Ziyan and Bhanu, Bir and Radke, Richard J and Camps, Octavia},
	year         = 2020,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@article{hsieh2020evaluations,
	title        = {Evaluations and Methods for Explanation through Robustness Analysis},
	author       = {Hsieh, Cheng-Yu and Yeh, Chih-Kuan and Liu, Xuanqing and Ravikumar, Pradeep and Kim, Seungyeon and Kumar, Sanjiv and Hsieh, Cho-Jui},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2006.00442}
}
@inproceedings{chattopadhay2018grad,
	title        = {Grad-cam++: Generalized gradient-based visual explanations for deep convolutional networks},
	author       = {Chattopadhay, Aditya and Sarkar, Anirban and Howlader, Prantik and Balasubramanian, Vineeth N},
	year         = 2018,
	booktitle    = {IEEE Winter Conference on Applications of Computer Vision (WACV)}
}
@article{smilkov2017smoothgrad,
	title        = {Smoothgrad: removing noise by adding noise},
	author       = {Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Vi{\'e}gas, Fernanda and Wattenberg, Martin},
	year         = 2017,
	journal      = {arXiv preprint arXiv:1706.03825}
}
% Integrated Gradients
@inproceedings{sundararajan2017axiomatic,
	title        = {Axiomatic attribution for deep networks},
	author       = {Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
	year         = 2017,
	booktitle    = icml
}
@inproceedings{mmv,
	title        = {Self-supervised multimodal versatile networks},
	author       = {Alayrac, Jean-Baptiste and Recasens, Adri{\`a} and Schneider, Rosalia and Arandjelovi{\'c}, Relja and Ramapuram, Jason and De Fauw, Jeffrey and Smaira, Lucas and Dieleman, Sander and Zisserman, Andrew},
	year         = 2020,
	booktitle    = {Advances in neural information processing systems}
}
@article{recasens2021broaden,
	title        = {Broaden Your Views for Self-Supervised Video Learning},
	author       = {Recasens, Adri{\`a} and Luc, Pauline and Alayrac, Jean-Baptiste and Wang, Luyu and Strub, Florian and Tallec, Corentin and Malinowski, Mateusz and Patraucean, Viorica and Altch{\'e}, Florent and Valko, Michal and others},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2103.16559}
}
@inproceedings{kerrigan2021reformulating,
	title        = {Reformulating zero-shot action recognition for multi-label actions},
	author       = {Kerrigan, Alec and Duarte, Kevin and Rawat, Yogesh and Shah, Mubarak},
	year         = 2021,
	booktitle      = {Advances in Neural Information Processing Systems},
	volume       = 34,
	pages        = {25566--25577}
}
@inproceedings{gowda2021claster,
	title        = {CLASTER: Clustering with Reinforcement Learning for Zero-Shot Action Recognition},
	author       = {Gowda, Shreyank N and Sevilla-Lara, Laura and Keller, Frank and Rohrbach, Marcus},
	year         = 2022,
	booktitle      = {Proceedings of the European Conference on Computer Vision}
}
@inproceedings{kodirov2015unsupervised,
	title        = {Unsupervised domain adaptation for zero-shot learning},
	author       = {Kodirov, Elyor and Xiang, Tao and Fu, Zhenyong and Gong, Shaogang},
	year         = 2015,
	booktitle    = {Proceedings of the IEEE international conference on computer vision},
	pages        = {2452--2460}
}
@inproceedings{DenseposeEvo20,
	title        = {Transferring Dense Pose to Proximal Animal Classes},
	author       = {Artsiom Sanakoyeu and Vasil Khalidov and Maureen S. McCarthy and Andrea Vedaldi and Natalia Neverova},
	year         = 2020,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}
}
@article{roitberg2018informed,
	title        = {Informed democracy: voting-based novelty detection for action recognition},
	author       = {Roitberg, Alina and Al-Halah, Ziad and Stiefelhagen, Rainer},
	year         = 2018,
	journal      = {arXiv preprint arXiv:1810.12819}
}
@inproceedings{qin2017zero,
	title        = {Zero-shot action recognition with error-correcting output codes},
	author       = {Qin, Jie and Liu, Li and Shao, Ling and Shen, Fumin and Ni, Bingbing and Chen, Jiaxin and Wang, Yunhong},
	year         = 2017,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {2833--2842}
}
@article{zhang2018visual,
	title        = {Visual data synthesis via GAN for zero-shot video classification},
	author       = {Zhang, Chenrui and Peng, Yuxin},
	year         = 2018,
	journal      = {arXiv preprint arXiv:1804.10073}
}
@article{chuang2015aaai,
	title        = {Exploring semantic inter-class relationships (sir) for zero-shot action recognition},
	author       = {Gan, Chuang and Lin, Ming and Yang, Y. and Zhuang, Y. and Hauptmann, Alexander},
	year         = 2015,
	month        = {01},
	journal      = {Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence},
	pages        = {3769--3775}
}
@article{action2vec,
	title        = {Action2Vec: A Crossmodal Embedding Approach to Action Learning},
	author       = {Hahn, Meera and Silva, Andrew and Rehg, James M},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1901.00484}
}
@article{tarn,
	title        = {TARN: Temporal Attentive Relation Network for Few-Shot and Zero-Shot Action Recognition},
	author       = {Bishay, Mina and Zoumpourlis, Georgios and Patras, Ioannis},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1907.09021}
}
@inproceedings{uar,
	title        = {Towards universal representation for unseen action recognition},
	author       = {Zhu, Yi and Long, Yang and Guan, Yu and Newsam, Shawn and Shao, Ling},
	year         = 2018,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {9436--9445}
}
@inproceedings{zhang2018cross,
	title        = {Cross-Modal and Hierarchical Modeling of Video and Text},
	author       = {Zhang, Bowen and Hu, Hexiang and Sha, Fei},
	year         = 2018,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)},
	pages        = {374--390}
}
@article{piergiovanni2018learning,
	title        = {Learning Shared Multimodal Embeddings with Unpaired Data.},
	author       = {Piergiovanni, AJ and Ryoo, Michael S},
	year         = 2018,
	journal      = {CoRR}
}
@article{chuang2016ijcv,
	title        = {Recognizing an Action Using Its Name: A Knowledge-Based Approach},
	author       = {Gan, Chuang and Yang, Yi and Zhu, Linchao and Zhao, Deli and Zhuang, Yueting},
	year         = 2016,
	month        = {03},
	journal      = {International Journal of Computer Vision},
	volume       = 120,
	pages        = {},
	doi          = {10.1007/s11263-016-0893-6}
}
@inproceedings{chuang2016,
	title        = {Learning attributes equals multi-source domain generalization},
	author       = {Gan, Chuang and Yang, Tianbao and Gong, Boqing},
	year         = 2016,
	booktitle    = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages        = {87--97}
}
@inproceedings{chuang2016aaai,
	title        = {Concepts not alone: Exploring pairwise relationships for zero-shot video activity recognition},
	author       = {Gan, Chuang and Lin, Ming and Yang, Yi and De Melo, Gerard and Hauptmann, Alexander G},
	year         = 2016,
	booktitle    = {Thirtieth AAAI Conference on Artificial Intelligence}
}
@inproceedings{larochelle2008zero,
	title        = {Zero-data learning of new tasks.},
	author       = {Larochelle, Hugo and Erhan, Dumitru and Bengio, Yoshua},
	year         = 2008,
	booktitle    = {The AAAI Conference on Artificial Intelligence},
	volume       = 1,
	number       = 2,
	pages        = 3
}
@inproceedings{palatucci2009zero,
	title        = {Zero-shot learning with semantic output codes},
	author       = {Palatucci, Mark and Pomerleau, Dean and Hinton, Geoffrey E and Mitchell, Tom M},
	year         = 2009,
	booktitle    = {Advances in neural information processing systems},
	pages        = {1410--1418}
}
######################################################
@inproceedings{wang2017alternative,
	title        = {Alternative semantic representations for zero-shot human action recognition},
	author       = {Wang, Qian and Chen, Ke},
	year         = 2017,
	booktitle    = {Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
	pages        = {87--102},
	organization = {Springer}
}
@inproceedings{alexiou2016exploring,
	title        = {Exploring synonyms as context in zero-shot action recognition},
	author       = {Alexiou, Ioannis and Xiang, Tao and Gong, Shaogang},
	year         = 2016,
	booktitle    = {2016 IEEE International Conference on Image Processing (ICIP)},
	pages        = {4190--4194},
	organization = {IEEE}
}
@inproceedings{xu2015semantic,
	title        = {Semantic embedding space for zero-shot action recognition},
	author       = {Xu, Xun and Hospedales, Timothy and Gong, Shaogang},
	year         = 2015,
	booktitle    = {2015 IEEE International Conference on Image Processing (ICIP)},
	pages        = {63--67},
	organization = {IEEE}
}
@inproceedings{mishra2018generative,
	title        = {A generative approach to zero-shot and few-shot action recognition},
	author       = {Mishra, Ashish and Verma, Vinay Kumar and Reddy, M Shiva Krishna and Arulkumar, S and Rai, Piyush and Mittal, Anurag},
	year         = 2018,
	booktitle    = {2018 IEEE Winter Conference on Applications of Computer Vision (WACV)},
	pages        = {372--380},
	organization = {IEEE}
}
@article{xu2017transductive,
	title        = {Transductive zero-shot action recognition by word-vector embedding},
	author       = {Xu, Xun and Hospedales, Timothy and Gong, Shaogang},
	year         = 2017,
	journal      = {International Journal of Computer Vision},
	publisher    = {Springer},
	volume       = 123,
	number       = 3,
	pages        = {309--333}
}
################### Video Action Reco #################################
@inproceedings{feichtenhofer2017spatiotemporal,
	title        = {Spatiotemporal multiplier networks for video action recognition},
	author       = {Feichtenhofer, Christoph and Pinz, Axel and Wildes, Richard P},
	year         = 2017,
	booktitle    = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages        = {4768--4777}
}
@inproceedings{feichtenhofer2016convolutional,
	title        = {Convolutional two-stream network fusion for video action recognition},
	author       = {Feichtenhofer, Christoph and Pinz, Axel and Zisserman, Andrew},
	year         = 2016,
	booktitle    = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages        = {1933--1941}
}
@inproceedings{wang2017spatiotemporal,
	title        = {Spatiotemporal pyramid network for video action recognition},
	author       = {Wang, Yunbo and Long, Mingsheng and Wang, Jianmin and Yu, Philip S},
	year         = 2017,
	booktitle    = {Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
	pages        = {1529--1538}
}
@inproceedings{fernando2015modeling,
	title        = {Modeling video evolution for action recognition},
	author       = {Fernando, Basura and Gavves, Efstratios and Oramas, Jose M and Ghodrati, Amir and Tuytelaars, Tinne},
	year         = 2015,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {5378--5387}
}
@inproceedings{gan2016concepts,
	title        = {Concepts not alone: Exploring pairwise relationships for zero-shot video activity recognition},
	author       = {Gan, Chuang and Lin, Ming and Yang, Yi and De Melo, Gerard and Hauptmann, Alexander G},
	year         = 2016,
	booktitle    = {Thirtieth AAAI Conference on Artificial Intelligence}
}
@inproceedings{gan2015exploring,
	title        = {Exploring semantic inter-class relationships (sir) for zero-shot action recognition},
	author       = {Gan, Chuang and Lin, Ming and Yang, Yi and Zhuang, Yueting and Hauptmann, Alexander G},
	year         = 2015,
	booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 29
}
% 	number       = 1
@inproceedings{gan2016learning,
	title        = {Learning attributes equals multi-source domain generalization},
	author       = {Gan, Chuang and Yang, Tianbao and Gong, Boqing},
	year         = 2016,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {87--97}
}
@inproceedings{zhang2021vidtr,
	title        = {Vidtr: Video transformer without convolutions},
	author       = {Zhang, Yanyi and Li, Xinyu and Liu, Chunhui and Shuai, Bing and Zhu, Yi and Brattoli, Biagio and Chen, Hao and Marsic, Ivan and Tighe, Joseph},
	year         = 2021,
	booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages        = {13577--13587}
}
@article{idrees2017thumos,
	title        = {The THUMOS challenge on action recognition for videos in the wild},
	author       = {Idrees, Haroon and Zamir, Amir R and Jiang, Yu-Gang and Gorban, Alex and Laptev, Ivan and Sukthankar, Rahul and Shah, Mubarak},
	year         = 2017,
	journal      = {Computer Vision and Image Understanding},
	publisher    = {Elsevier},
	volume       = 155,
	pages        = {1--23}
}
@inproceedings{ghosh2021learning,
	title        = {Learning Graphs for Knowledge Transfer with Limited Labels},
	author       = {Ghosh, Pallabi and Saini, Nirat and Davis, Larry S and Shrivastava, Abhinav},
	year         = 2021,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {11151--11161}
}
@article{smaira2020short,
	title        = {A short note on the kinetics-700-2020 human action dataset},
	author       = {Smaira, Lucas and Carreira, Jo{\~a}o and Noland, Eric and Clancy, Ellen and Wu, Amy and Zisserman, Andrew},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2010.10864}
}
@inproceedings{tang2012learning,
	title        = {Learning latent temporal structure for complex event detection},
	author       = {Tang, Kevin and Fei-Fei, Li and Koller, Daphne},
	year         = 2012,
	booktitle    = {2012 IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {1250--1257},
	organization = {IEEE}
}
@inproceedings{chen2019drop,
	title        = {Drop an octave: Reducing spatial redundancy in convolutional neural networks with octave convolution},
	author       = {Chen, Yunpeng and Fan, Haoqi and Xu, Bing and Yan, Zhicheng and Kalantidis, Yannis and Rohrbach, Marcus and Yan, Shuicheng and Feng, Jiashi},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages        = {3435--3444}
}
@inproceedings{pgj2017unsup,
	title        = {{Unsupervised Learning of Sentence Embeddings using Compositional n-Gram Features}},
	author       = {Pagliardini, Matteo and Gupta, Prakhar and Jaggi, Martin},
	year         = 2018,
	booktitle    = {NAACL 2018 - Conference of the North American Chapter of the Association for Computational Linguistics}
}
@inproceedings{mandal2019out,
	title        = {Out-of-distribution detection for generalized zero-shot action recognition},
	author       = {Mandal, Devraj and Narayan, Sanath and Dwivedi, Sai Kumar and Gupta, Vikram and Ahmed, Shuaib and Khan, Fahad Shahbaz and Shao, Ling},
	year         = 2019,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {9985--9993}
}
@inproceedings{chen2021elaborative,
	title        = {Elaborative Rehearsal for Zero-shot Action Recognition},
	author       = {Chen, Shizhe and Huang, Dong},
	year         = 2021,
	booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages        = {13638--13647}
}
@inproceedings{huynh2020fine,
	title        = {Fine-grained generalized zero-shot learning via dense attribute-based attention},
	author       = {Huynh, Dat and Elhamifar, Ehsan},
	year         = 2020,
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {4483--4493}
}


@inproceedings{yang2022vision,
  title={Vision-Language Pre-Training with Triple Contrastive Learning},
  author={Yang, Jinyu and Duan, Jiali and Tran, Son and Xu, Yi and Chanda, Sampath and Chen, Liqun and Zeng, Belinda and Chilimbi, Trishul and Huang, Junzhou},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15671--15680},
  year={2022}
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@article{khosla2020supervised,
  title={Supervised contrastive learning},
  author={Khosla, Prannay and Teterwak, Piotr and Wang, Chen and Sarna, Aaron and Tian, Yonglong and Isola, Phillip and Maschinot, Aaron and Liu, Ce and Krishnan, Dilip},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={18661--18673},
  year={2020}
}

@article{van2008visualizing,
  title={Visualizing data using t-SNE.},
  author={Van der Maaten, Laurens and Hinton, Geoffrey},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={11},
  year={2008}
}


@inproceedings{wu2022memvit,
  title={Memvit: Memory-augmented multiscale vision transformer for efficient long-term video recognition},
  author={Wu, Chao-Yuan and Li, Yanghao and Mangalam, Karttikeya and Fan, Haoqi and Xiong, Bo and Malik, Jitendra and Feichtenhofer, Christoph},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13587--13597},
  year={2022}
}

@inproceedings{kondratyuk2021movinets,
  title={Movinets: Mobile video networks for efficient video recognition},
  author={Kondratyuk, Dan and Yuan, Liangzhe and Li, Yandong and Zhang, Li and Tan, Mingxing and Brown, Matthew and Gong, Boqing},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16020--16030},
  year={2021}
}

@article{patrick2021keeping,
  title={Keeping your eye on the ball: Trajectory attention in video transformers},
  author={Patrick, Mandela and Campbell, Dylan and Asano, Yuki and Misra, Ishan and Metze, Florian and Feichtenhofer, Christoph and Vedaldi, Andrea and Henriques, Jo{\~a}o F},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={12493--12506},
  year={2021}
}


@article{gong2021psla,
  title={{PSLA: Improving audio tagging with pretraining, sampling, labeling, and aggregation}},
  author={Gong, Yuan and Chung, Yu-An and Glass, James},
  journal={IEEE/ACM TASLP},
  volume={29},
  pages={3292--3306},
  year={2021},
  publisher={IEEE}
}

@inproceedings{eyben2013recent,
  title={Recent developments in opensmile, the munich open-source multimedia feature extractor},
  author={Eyben, Florian and Weninger, Felix and Gross, Florian and Schuller, Bj{\"o}rn},
  booktitle={ACM MM},
  year={2013}
}

@inproceedings{schuller2013interspeech,
  title={{The INTERSPEECH 2013 computational paralinguistics challenge: Social signals, conflict, emotion, autism}},
  author={Schuller, Bj{\"o}rn and others},
  booktitle={Proc. Interspeech},
  year={2013}
}

@inproceedings{jaitly2011learning,
  title={Learning a better representation of speech soundwaves using restricted boltzmann machines},
  author={Jaitly, Navdeep and Hinton, Geoffrey},
  booktitle={ICASSP},
  pages={5884--5887},
  year={2011},
  organization={IEEE}
}

@inproceedings{dieleman2014end,
  title={End-to-end learning for music audio},
  author={Dieleman, Sander and Schrauwen, Benjamin},
  booktitle={ICASSP},
  year={2014},
  organization={IEEE}
}

@inproceedings{trigeorgis2016adieu,
  title={Adieu features? end-to-end speech emotion recognition using a deep convolutional recurrent network},
  author={Trigeorgis, George and others},
  booktitle={ICASSP},
  pages={5200--5204},
  year={2016},
  organization={IEEE}
}

@inproceedings{gong2022ssast,
  title={{SSAST: Self-supervised audio spectrogram transformer}},
  author={Gong, Yuan and others},
  booktitle={Proc. AAAI},
  year={2022}
}

@article{gong2022cmkd,
  title={{CMKD: CNN/Transformer-Based Cross-Model Knowledge Distillation for Audio Classification}},
  author={Gong, Yuan and others},
  journal={arXiv preprint arXiv:2203.06760},
  year={2022}
}

@article{woodard1992modeling,
  title={Modeling and classification of natural sounds by product code hidden markov models},
  author={Woodard, Jeffrey P},
  journal={IEEE Transactions on signal processing},
  year={1992},
  publisher={IEEE}
}

@article{lecun1995convolutional,
  title={Convolutional networks for images, speech, and time series},
  author={LeCun, Yann and Bengio, Yoshua and others},
  journal={The handbook of brain theory and neural networks},
  volume={3361},
  number={10},
  pages={1995},
  year={1995},
  publisher={Cambridge, MA USA}
}

@article{li2018attention,
  title={An Attention Pooling Based Representation Learning Method for Speech Emotion Recognition},
  author={Li, Pengcheng and others},
  journal={Proc. Interspeech},
  year={2018}
}

@inproceedings{dieleman2013multiscale,
  title={Multiscale approaches to music audio feature learning},
  author={Dieleman, Sander and Schrauwen, Benjamin},
  booktitle={ISMIR},
  year={2013}
}

@inproceedings{snyder2018x,
  title={X-vectors: Robust dnn embeddings for speaker recognition},
  author={Snyder, David and others},
  booktitle={ICASSP},
  year={2018},
  organization={IEEE}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and others},
  booktitle={Proc. ICCV},
  year={2021}
}

@article{kong2020sound,
  title={Sound event detection of weakly labelled data with CNN-transformer and automatic threshold optimization},
  author={Kong, Qiuqiang and others},
  journal={IEEE/ACM TASLP},
  volume={28},
  pages={2450--2460},
  year={2020},
  publisher={IEEE}
}

@inproceedings{chen2022hts,
  title={{HTS-AT: A hierarchical token-semantic audio transformer for sound classification and detection}},
  author={Chen, Ke and others},
  booktitle={ICASSP},
  year={2022},
  organization={IEEE}
}

@article{mcinnes2018umap,
  title={{UMAP: Uniform Manifold Approximation and Projection}},
  author={McInnes, Leland and others},
  year={2018}
}

@inproceedings{wang2019comparison,
  title={A comparison of five multiple instance learning pooling functions for sound event detection with weak labeling},
  author={Wang, Yun and Li, Juncheng and Metze, Florian},
  booktitle={ICASSP},
  year={2019},
  organization={IEEE}
}

@inproceedings{loshchilov2016sgdr,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle={ICLR},
  year={2017}
}

@article{rousseeuw1987silhouettes,
  title={Silhouettes: a graphical aid to the interpretation and validation of cluster analysis},
  author={Rousseeuw, Peter J},
  year={1987},
  publisher={Elsevier}
}

@article{hubert1985comparing,
  title={Comparing partitions},
  author={Hubert, Lawrence and Arabie, Phipps},
  journal={Journal of classification},
  volume={2},
  number={1},
  pages={193--218},
  year={1985},
  publisher={Springer}
}

@inproceedings{rosenberg2007v,
  title={V-measure: A conditional entropy-based external cluster evaluation measure},
  author={Rosenberg, Andrew and Hirschberg, Julia},
  booktitle={Proc. EMNLP-CoNLL},
  pages={410--420},
  year={2007}
}

@inproceedings{lin2022eclipse,
  title={ECLIPSE: Efficient Long-range Video Retrieval using Sight and Sound},
  author={Lin, Yan-Bo and others},
  booktitle={Proc. ECCV},
  year={2022}
}

@inproceedings{dai2020funnel,
  title={Funnel-transformer: Filtering out sequential redundancy for efficient language processing},
  author={Dai, Zihang and others},
  booktitle={Proc. NeurIPS},
  year={2020}
}

@inproceedings{zhu2021speechnas,
  title={SpeechNAS: Towards better trade-off between latency and accuracy for large-scale speaker verification},
  author={Zhu, Wentao and others},
  booktitle={ASRU},
  pages={1102--1109},
  year={2021},
  organization={IEEE}
}

@article{zhumultiscale,
  title={Multiscale Multimodal Transformer for Multimodal Action Recognition},
  author={Zhu, Wentao and others}
}

@article{zhuavt,
  title={AVT: Audio-Video Transformer for Multimodal Action Recognition},
  author={Zhu, Wentao and others}
}
