%% bare_adv.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% See: 
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the advanced use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE Computer
%% Society journal paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall the IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. The IEEE's font choices and paper sizes can   ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/


% IEEEtran V1.7 and later provides for these CLASSINPUT macros to allow the
% user to reprogram some IEEEtran.cls defaults if needed. These settings
% override the internal defaults of IEEEtran.cls regardless of which class
% options are used. Do not use these unless you have good reason to do so as
% they can result in nonIEEE compliant documents. User beware. ;)
%
%\newcommand{\CLASSINPUTbaselinestretch}{1.0} % baselinestretch
%\newcommand{\CLASSINPUTinnersidemargin}{1in} % inner side margin
%\newcommand{\CLASSINPUToutersidemargin}{1in} % outer side margin
%\newcommand{\CLASSINPUTtoptextmargin}{1in}   % top text margin
%\newcommand{\CLASSINPUTbottomtextmargin}{1in}% bottom text margin

\documentclass[10pt,journal,compsoc]{IEEEtran} 


% *** CITATION PACKAGES ***
\ifCLASSOPTIONcompsoc
  % The IEEE Computer Society needs nocompress option
  % requires cite.sty v4.0 or later (November 2003)
  % \usepackage[nocompress]{cite}
  \usepackage[nocompress]{cite}
\else
  % normal IEEE
  \usepackage{cite}
\fi


% *** GRAPHICS RELATED PACKAGES ***
\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
  \graphicspath{{./figures/at.vti/}{./figures/miranda/}{./figures/noisyTerrain/}{./figures/viscous/}{./figures/wallmodes/}}
  \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  \usepackage[dvips]{graphicx}
  \graphicspath{{./figures/at.vti/}{./figures/miranda/}{./figures/noisyTerrain/}{./figures/viscous/}{./figures/wallmodes/}}
  \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\fi

% *** MATH PACKAGES ***
\usepackage{amsmath}

% *** ALIGNMENT PACKAGES ***
\usepackage{array}

% *** SUBFIGURE PACKAGES ***
\ifCLASSOPTIONcompsoc
  \usepackage[caption=false,font=footnotesize,labelfont=sf,textfont=sf]{subfig}
\else
  \usepackage[caption=false,font=footnotesize]{subfig}
\fi
\renewcommand\citepunct{, }

% *** FONTS PACKAGES ***
\usepackage{inconsolata}

% *** TABLE PACKAGES ***
\usepackage{multicol}
\usepackage{multirow}
\usepackage[table,dvipsnames]{xcolor}
\usepackage{colortbl}

\definecolor{mygray2}{gray}{0.8}
\definecolor{mygray1}{gray}{0.9}
\definecolor{mygray3}{gray}{0.98}

\newenvironment{tttabular}[1]%
{\ttfamily \begin{tabular}{#1}}%
{\end{tabular}}

% *** FLOAT PACKAGES ***
\usepackage{stfloats}
\usepackage{wrapfig}
\fnbelowfloat

% *** PDF, URL AND HYPERLINK PACKAGES ***
\usepackage{url} 

% *** TIKZ SETTINGS ***
%\usepackage{tikz}
\usepackage{circuitikz}
\usetikzlibrary{er,positioning,arrows,arrows.meta,patterns,calc,shapes}
\usepackage{ifthen}
\input{tikz/tikzUtils.tex}

% *** MATH NOTATIONS ***
\usepackage{amsfonts}
\usepackage{amssymb}

%\usepackage{comment}

% *** HYPERREF SETTINGS ***
\newcommand\MYhyperrefoptions{bookmarks=true,bookmarksnumbered=true,
pdfpagemode={UseOutlines},plainpages=false,pdfpagelabels=true,
colorlinks=true,linkcolor={black},citecolor={black},urlcolor={black},
pdftitle={Parallel Computation of Piecewise Linear Morse-Smale Segmentations},
pdfsubject={Algorithm/Technique},
pdfauthor={Robin G. C. Maack},
pdfkeywords={Morse-Smale Complex, Watershed transformation, Segmentation, Topology, Visualization}}

\ifCLASSINFOpdf
  \usepackage[\MYhyperrefoptions,pdftex]{hyperref}
\else
  \usepackage[\MYhyperrefoptions,breaklinks=true,dvips]{hyperref}
  \usepackage{breakurl}
\fi

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

%Comments
%\usepackage[markup=nocolor]{changes}

\renewcommand{\figureautorefname}{Fig.}
\renewcommand{\sectionautorefname}{Sec.}

\usepackage{enumitem}

\begin{document}

\title{Parallel Computation of\\Piecewise Linear Morse-Smale Segmentations}

\author{
    Robin G. C. Maack,
    Jonas Lukasczyk, %~\IEEEmembership{Member,~IEEE,}
    Julien Tierny, %~\IEEEmembership{Member,~IEEE,}
    Hans Hagen, %~\IEEEmembership{Member,~IEEE,}
    Ross Maciejewski, %~\IEEEmembership{Member,~IEEE,}
    and
    Christoph Garth %,~\IEEEmembership{Member,~IEEE}
    \IEEEcompsocitemizethanks{
    \IEEEcompsocthanksitem R. G. C. Maack, J. Lukasczyk, H. Hagen, and C. Garth\\are with RPTU Kaiserslautern-Landau.\protect\\
    E-mails: \{maack, lukasczyk, hagen, garth\}@rptu.de
    \IEEEcompsocthanksitem J. Tierny is with the CNRS and Sorbonne Universit\'{e}.\protect\\
    Email: julien.tierny@sorbonne-universite.fr
    \IEEEcompsocthanksitem R. Maciejewski is with Arizona State University.\protect\\
    Email: rmacieje@asu.edu}
    %\thanks{Manuscript received XXX, 2022; revised August XX, 2022.}
}

% The paper headers
\ifCLASSOPTIONpeerreview
  \markboth{IEEE Transactions on Visualization and Computer Graphics,~Vol.~X, No.~X, Month~202X}%
  {Parallel Computation of Piecewise Linear Morse-Smale Segmentations}
\else 
  \markboth{IEEE Transactions on Visualization and Computer Graphics,~Vol.~X, No.~X, Month~202X}%
  {Maack \MakeLowercase{\textit{et al.}}: Parallel Computation of Piecewise Linear Morse-Smale Segmentations}
\fi

\IEEEtitleabstractindextext{%
\begin{abstract}
This paper presents a well-scaling parallel algorithm for the computation of Morse-Smale (MS) segmentations, including the region separators and region boundaries. The segmentation of the domain into ascending and descending manifolds, solely defined on the vertices, improves the computational time using path compression and fully segments the border region. Region boundaries and region separators are generated using a multi-label marching tetrahedra algorithm. This enables a fast and simple solution to find optimal parameter settings in preliminary exploration steps by generating an MS complex preview. It also poses a rapid option to generate a fast visual representation of the region geometries for immediate utilization. Two experiments demonstrate the performance of our approach with speedups of over an order of magnitude in comparison to two publicly available implementations. The example section shows the similarity to the MS complex, the useability of the approach, and the benefits of this method with respect to the presented datasets. We provide our implementation with the paper.
\end{abstract}

\begin{IEEEkeywords}
Topology, Visualization, Segmentation, Morse-Smale Complex, Watershed transformation.
\end{IEEEkeywords}}

\IEEEoverridecommandlockouts
\IEEEpubid{\makebox[\columnwidth]{978-1-5386-5541-2/18/\$31.00~\copyright2018 IEEE \hfill} \hspace{\columnsep}\makebox[\columnwidth]{ }}

\maketitle

\IEEEpubidadjcol

\ifCLASSOPTIONcompsoc
\IEEEraisesectionheading{\section{Introduction}\label{sec:introduction}}
\else
\section{Introduction}
\label{sec:introduction}
\fi

\definecolor{darkgreen}{rgb}{0.0, 0.5, 0.0}
\newcommand{\jonas}[1]{{\color{red}[#1]}}
\newcommand{\julien}[1]{{\color{blue}#1}}
\newcommand{\ross}[1]{{\color{orange}#1}}
\newcommand{\robin}[1]{{\color{darkgreen}#1}}

\renewcommand{\subsectionautorefname}{Section}
\renewcommand{\subsubsectionautorefname}{Section}

\IEEEPARstart{T}{opological Data Analysis}~(TDA) provides a family of effective feature characterizations, including the well-studied Morse-Smale~(MS) complex. 
The MS complex is a central tool in TDA for feature-driven data analysis and visualization, as it segments the domain of a scalar field into regions with equivalent gradient flow behavior (see \autoref{fig:wallmodes} and \autoref{sec:Preliminaries}).
This rather abstract feature characterization based on gradient flow has been applied successfully in several domains, including
chemistry~\cite{olejniczak2020topological,bhatia2018topoms},
material science~\cite{venkat2021towards,homberg2014definition}, 
physics~\cite{laney2006understanding,gyulassy2015interstitial},
and
cosmology~\cite{sousbie2011persistent}.
% Due to its ability to simplify and analyze datasets in a robust manner many applications already utilize its algorithms.

\begin{figure}
    \centering
    \include{tikz/sepMode}
    \vspace*{-3em}
    \caption{A $4\times4$ example triangulation showing the input field (a) and available segmentations and region-separating geometries (b-e). Each color represents the influence area of a specific extremum (the areas of minima 0 and 1 are shown in red and yellow, while the area of maxima 14 and 15 are shown in blue and green). The descending segmentation (b) represents the influence area of maxima and the ascending segmentation (c) the ones of all minima. In the case of Morse-Smale segmentations (d-e) the nodes show the influence of minima-maxima combinations, leading to nodes being colored by the minima color at the bottom and the maximum color at the top. Subfigures (b) and (d) show region separators (thin black lines), while (c) and (e) show region boundaries (thick black lines).
    \label{fig:wallmodes}
    }
\end{figure}

However, due to the high computational complexity of MS complex generation, it often becomes a time-consuming bottleneck. Especially in the case of interactive analysis and visualization, users expect to quickly retrieve a visual output, where long wait times can interrupt their workflow.
% As datasets also grow in size, so does the need to process them with high parallel efficiency. 
Furthermore, many applications do not require the computation of the full MS complex, but only two of its central features:
1)~the MS segmentation of the domain that assigns extrema to each vertex by following the gradient along the steepest descend and ascend;
and
2)~the interfaces between different regions in the segmentation.  

In this paper we describe a scalable implementation of these two tasks with high parallel efficiency, further referred to as the piecewise linear Morse-Smale segmentation~(PLMSS) algorithm~(\autoref{sec:Methods}).
As the name suggests, the input of PLMSS is a scalar field defined on the vertices of a piecewise linear domain, i.e., a simplicial complex.
PLMSS utilizes path compression to derive the MS segmentation of the domain and a multi-label marching tetrahedra procedure to derive the interfaces between different regions of the MS segmentation.
We chose these two underlying algorithms since they are known to be embarrassingly parallelizable, and therefore expected to scale well.
In \autoref{sec:Results} we demonstrate the benefit of using PLMSS for effective data analysis and visualization on four datasets.

We compare PLMSS against the corresponding subprocedures of two state-of-the-art Morse-Smale complex software libraries, i.e., the implementations available in the Topology ToolKit~(TTK)~\cite{ttk19} and MSCEER~\cite{msceer}.
Specifically, we performed two strong scaling studies~(\autoref{sec:performance}) that show that MSCEER outperforms TTK, but PLMSS is still up to an order of magnitude faster than MSCEER, while also providing superior parallel efficiency.
% As the MS segmentations computed by PLMSS, TTK, and MSCEER are identical, both TTK and MSCEER would also benefit from utilizing path compression.
However, the qualitative and quantitative comparison between the region separators computed by PLMSS and their counterpart of MS complex 2-cells is more challenging.
Although they both separate regions with different gradient flow behavior, they are defined and computed differently~(\autoref{sec:Preliminaries}).
Yet, for many applications---including the scenarios presented in \autoref{sec:Results}---the computation of region separators is sufficient without the need for expensive discrete gradient field and dual mesh computations.\vspace*{0.4em}

\noindent In short, the contributions of our work are:
\begin{itemize}[itemindent=0em]
    \item A scalable algorithm with high parallel efficiency for the computation of piecewise linear Morse-Smale segmentations~(PLMSS);
    \item A detailed performance benchmark that compares PLMSS with the corresponding subprocedures of two state-of-the-art Morse-Smale complex software libraries (TTK and MSCEER); and
    \item The integration of PLMSS in TTK to facilitate future benchmarks and reproducibility.
\end{itemize}

% It exclusively extracts the region of influence of either minima~(ascending), maxima~(descending), or minima-maxima pairs~(Morse-Smale).
% The segmentation of the domain into ascending and descending manifolds, solely defined on the vertices, is computed using path compression.
% This speeds up the process considerably and only needs vertex neighbor relations as cached information, strongly reducing the memory footprint compared to the MS complex of TTK~\cite{ttk17}.
% Next, we compute geometry that separates individual regions of the segmentation by utilizing a multi-label marching tetrahedra algorithm.

% In use cases where additional information is required that can only be provided by the full Morse-Smale complex---such as saddle-saddle separatrices---our approach can still be employed for initial parameter tuning which involves multiple recalculations of the MS segmentation before calculating the full complex.

%, yielding a much shorter waiting time in between parameter sets.
% As the resulting representation is still very close to the original MS complex, it can be used as a rapid option to generate a visual representation of the region surfaces for immediate utilization.
% If needed, the MS complex can be executed as the last step to fully enable all its features.
% Still, in many situations the computation of the Piecewise Linear MS Segmentation (PLMSS) is already sufficient, yielding much simpler region-separating geometries compared to the MS complex as saddle-saddles separatrices, i.e. separators of the MS complex which do not separate extremum regions, are skipped by design. For ease of use, either the region separators, separating all regions from each other, or region boundaries, surrounding each region with a surface, can be created. 

% To validate the performance of our implementation, we conducted two strong scaling studies. First, a Rayleigh-Taylor instability dataset at a resolution of $512^3$ is used to show the performance regarding larger datasets with a lot of region-separating geometry. \autoref{fig:teaser} is a $128 \times 128 \times 1024$ cutout of the whole dataset to compare the visual result of both the MS complex and the PLMSS. Second, a CT scan of a foot at a resolution of ~($256^3$) is used to represent datasets with less region-separating geometry and smaller data size. The analysis results can be found in \autoref{sec:performance}.

% The task of this work was to create a well-scaling parameterless segmentation algorithm that mimics the dataset subdivision formed by the MS complex, also extracting region-separating geometries that emulate MS complex 2-cells. Therefore, we contribute an implementation that fulfills this goal by utilizing path compression and marching tetrahedra for our implementation. The results show that those methods are a great choice for this task, delivering great segmentation results, also achieving very similar region-separating geometries. Two strong-scaling studies indicate the outstanding parallel efficiency of our implementation, reaching a speedup of over an order of magnitude for one and 5-7 times speedup for another dataset.

% \subsection{Contributions}
% PLMSS is a scalable  

% In this paper we set out to provide a scalable algorithm with high parallel efficiency for computing Morse-Smale segmentations and geometry that separates these segments.
% To this end, we utilize path compression to compute ascending, descending, and Morse-Smale segmentations, and utilize a multi-label marching tetrahedra algorithm to generate region separators.

% By comparing PLMSS against two state-of-the-art solutions~(TTK~\cite{ttk19} and MSCEER~\cite{msceer}), we demonstrate that our implementation outperforms these solutions in regard to parallel efficiency and scalability since path compression and a multi-label marching tetrahedra algorithm




% Morse-Smale segmentations that separate the domain into regions with uniform gradient flow behavior.
% Specifically, we set out to 
% To this end, we developed an implementation called \textit{Piecewise Linear Morse-Smale Segmentation}~(PLMSS) that utilizes 



% In this paper we contribute:
% \begin{enumerate}
%     \item A parallel algorithm to retrieve descending, ascending and Morse-Smale segmentations.
%     \item A parallel approach to efficiently create basin separating surfaces.
%     \item A performance analysis between two publicly available approaches.
%     %\item A strong performance increase in segmentation tasks.
%     %\item A memory-efficient approach with little cached information necessary.
% \end{enumerate}

\section{Related Work}
\label{sec:RelatedWork}
The MS complex subdivides a given scalar field into regions of uniform gradient flow behavior, segmenting the domain such that each point in the same MS manifold will flow towards the same critical point pair considering forward and backward integration. Two approaches to computing the MS complex arose from Morse theory~\cite{milnor2016morse}, where either a discrete gradient vector field is defined on the whole domain~\cite{forman1998morse}, or piecewise linear Morse theory is used to define a segmentation~\cite{banchoff1967critical, banchoff1970critical}. For an in-depth comparison of both approaches, we refer to Lewiner's work~\cite{lewiner2013critical}.

Algorithms based on piecewise linear Morse theory are divided into boundary-based and region-growing algorithms. Boundary-based algorithms trace lines of steepest descent/ascent seeded at the saddles, such that every vertex on a line of steepest ascent/descent belongs to the same region. Region-growing algorithms grow sets of top-level cells, e.g. cubes or tetrahedra in 3D, located at the minima and maxima of a scalar function, iteratively enlarging regions. One representative of boundary-based algorithms is Edelsbrunner et al.~\cite{edelsbrunner2001hierarchical} that first introduced the MS complex for piecewise linear 2-manifolds, recording paths of steepest ascent and descent. They also introduced the notion of the quasi MS complex that was extended to 3-manifolds~\cite{edelsbrunner2003morse} and later improved in geometric accuracy by Bremer et al.~\cite{bremer2004topological}. Concerning region-growing algorithms, Danovaro et al.~\cite{danovaro2003topological} started growing regions by using triangles incident on maxima at vertices, adding edge incident triangles iteratively. They extended this approach by appending additional seeding points at initialization, while also enabling to process higher-dimensional scalar fields~\cite{danovaro2003morphology}. Gyulassy et al.~\cite{gyulassy2007efficient} implemented a region-growing algorithm that labels the vertices to extract 3-, 2-, and 1-cells, also extendable from 3D to higher dimensional scalar fields.

Discrete Morse theory was developed by Forman~\cite{forman2002user}, applying Morse theory to any type of simplicial cell complex. Many algorithms build upon the discrete gradient vector field to effectively compute the MS complex~\cite{gunther2012efficient, robins2011theory, king2005generating}. To efficiently compute the MS complex for large datasets, several parallel and distributed memory implementations were introduced. Gyulassy et al.~\cite{gyulassy2008practical} first proposed splitting a dataset into subsets called parcels, extracting the MS complex from each parcel to later merge them in a cancellation-based step. This allowed for the computation of datasets that do not fit into memory and gave rise to distributed memory approaches~\cite{gyulassy2012parallel, peterka2011scalable}. Further parallel optimizations were achieved by merging gradient paths, enabling the computation of the gradient assignment and extrema traversals on the GPU~\cite{shivashankar2012parallel, shivashankar2012parallel3D}. Subhash et al.~\cite{subhash2020gpu} then accomplished computing all steps of the MS complex computation on the GPU. Even though some algorithms improved the steepest descent line tracing~\cite{bremer2004topological, gyulassy2007efficient} by allowing the traversal to use edges and triangles, still all presented algorithms often produce incorrect connectivity and inaccurate geometry due to the refinement of the underlying discrete domain~\cite{heine2016survey}. Here, Gyulassy et al.~\cite{gyulassy2012computing} implemented a probabilistic algorithm to extract the correct geometry and connectivity. Morse-Smale complexes were already used in many applications such as material science~\cite{gyulassy2007topologically}, chemistry~\cite{gunther2014characterizing}, and medicine~\cite{gyulassy2014conforming}, allowing for fast and consistent analysis of the data. Cancellation-based simplification~\cite{lukasczyk2020localized, fellegara2014efficient, weinkauf2010topology} is often used in applications, where pairs of critical points are removed to simplify the MS complex and eliminate noise in the dataset. It counteracts over-segmentation of the domain and enables the extraction of persistent features.

The Watershed transform, originally defined by Beucher and Lantu\'{e}joul~\cite{beucher1979use}, is another approach to Morse theory, segmenting the domain, usually gray-scale images, into catchment basins that represent the zone of influence of minima and watershed lines, separating catchment basins from each other. Beucher~\cite{beucher1982watersheds} described catchment basins as areas where each drop of water ends up at the same minimum when flowing down the surface. In contrast to Morse theory, minima don't have to be distinct but can rather consist of multiple vertices of the same function value. Those definitions were further improved to be rigorous~\cite{meyer1993integrals, najman1993definition} and extended to the discrete case~\cite{meyer1994topographic, vincent1991watersheds}. De Floriani~\cite{de2015morse} distinguishes three types of watershed algorithms that are either based on topographic distance, simulated immersion, or rainfalling simulation. Algorithms based on topographic distance compute shortest paths to find corresponding catchment basins~\cite{meyer1990morphological, meyer1994topographic}. Gabrielyan et al.~\cite{gabrielyan2022parallel} and Yeghiazaryan and Voiculescu~\cite{yeghiazaryan2018path} provide GPU implementations using an approach similar to path compression, speeding up the shortest path computation. Simulated immersion approaches seed catchment basins at minima, extending them by processing vertices in increasing function value order\cite{vincent1991watersheds, soille2004morphological}. Rainfalling simulation algorithms use an inverted logic, finding and labeling minima first, then decreasing in function value for each vertex by steepest descent until a labeled vertex is found~\cite{mangan1999partitioning, stoev2000extracting}.

Marching tetrahedra~\cite{marchingTetrahedra} is an algorithm to extract boundary surfaces from a tetrahedralization separating differently labeled vertices from each other. It is a generalization of the marching cubes algorithm~\cite{marchingCubes,marchingCubesAmbiguity} that initially allowed the creation of iso-surfaces at a selected isovalue by subdividing voxels such that areas with values above and below the isovalue were separated. Yet, in contrast to the original marching cubes algorithm, it allows multiple labels to be present at each tetrahedron and always extracts a distinct triangulation at each tetrahedron, eliminating ambiguous cases. The effect of various simplicial subdivisions on the quality of the resulting surfaces has been studied by Carr et al.\cite{carr2006artifacts}. Also, various applications use this approach for its simplicity and performance~\cite{chouchaneVersatile2019, MULLER2014205,weinstein2000,zhang2006integrating}.

\section{Preliminaries}
\label{sec:Preliminaries}
\input{notations}

This section describes the formal setting of our work. It contains definitions adapted from the Topology ToolKit (TTK)~\cite{ttk17, ttk19}. We refer the reader to textbooks~\cite{edelsbrunner09, zomorodianBook} for comprehensive introductions to computational topology.

\subsection{Input Data}
The input is a piecewise linear (PL) scalar field $f :
\domain
\rightarrow \mathbb{R}$ defined on a $d$-dimensional simplicial
complex, with $d \leqslant 3$ in our applications.
The \emph{star} $\Star(\simplex)$ of a simplex $\simplex$ is the set of
simplices of $\domain$ which contain $\sigma$ as a face. The \emph{link}
$\Link(\simplex)$ is the set of faces of the simplices of $\Star(\simplex)$
which do not intersect $\simplex$.
The input field $f$ is  provided on the vertices of $\domain$
and interpolated on the simplices of higher dimensions. $f$ is assumed to
be injective, which is achieved in practice by substituting the $f$ value
of a vertex by its position in the non-ambiguous, global vertex order
(by increasing $f$ values).

\subsection{Critical Points}
The sub-level set
$\sublevelset{f}(w)$
of an isovalue $w \in \mathbb{R}$ is
defined as $\sublevelset{f}(w) = \{p \in \mathcal{M} ~|~ f(p) < w\}$. 
As $w$ continuously increases, the topology of $\sublevelset{f}(w)$ changes at
specific vertices of $\domain$, called the \emph{critical points} of $f$.
Let $\Link^-(v)$ be the \emph{lower link} of the vertex $v$:
$\Link^-(v) = \{\simplex \in \Link(v) ~|~ \forall u \in
\simplex : f(u) < f(v)\}$.
The \emph{upper link} of $v$ is defined symmetrically:
$\Link^+(v) = \{\simplex \in \Link(v) ~|~ \forall u \in
\simplex : f(u) > f(v)\}$.
A vertex $v$ is \emph{regular} if and only if both $\Link^-(v)$ and
$\Link^+(v)$ are simply connected. Otherwise, $v$ is a \emph{critical vertex} of
$f$~\cite{banchoff1970critical}.
A critical vertex $v$ can be classified by its \emph{index} $\Index(v)$, which
is
$0$ for minima, $1$ for $1$-saddles, $(d-1)$ for $(d-1)$-saddles and $d$
for maxima. Vertices for which the number of connected components of
$\Link^-(v)$ or $\Link^+(v)$ are greater than $2$ are called \emph{degenerate
saddles}.

\subsection{Integral Lines}
\label{sec_integralLines}
\emph{Integral lines} are piecewise linear curves on 
$\domain$ which
locally describe the gradient of $f$.
They can be used
to capture and visualize
adjacency relations between critical points.
Given a vertex $v$, its \emph{forward} integral line, noted
$\forwardIntegralLine(v)$, is a path along the edges of $\domain$, initiated in
$v$, such that each edge of $\forwardIntegralLine(v)$ connects a vertex $v'$ to
its highest neighbor $v''$. Then forward integrals are guaranteed to terminate
in local maxima of $f$.
A \emph{backward} integral line, noted
$\backwardIntegralLine(v)$, is defined symmetrically (i.e. integrating
downwards towards minima).

Moreover, we define a \emph{forward extremal integral line} as a forward integral line started at a connected component of upper link $\Link^+(s)$ of a saddle $s$. Backward extremal integral lines are defined symmetrically. 
We say that a saddle $s$ is a \emph{forward separating saddle} if there exist at least two forward extremal integral lines starting at $s$ which terminate in distinct local maxima. Backward-separating saddles are defined symmetrically.
In practice, extremal integral lines help capture adjacency relations between critical points.

\subsection{Morse-Smale Segmentation}
\label{sec_segmentation}
In this section, we formalize the notion of Morse-Smale segmentation computed by our approach.

For a given vertex $v$, let $m$ and $M$ be its \emph{integration extremities}: $m$ is the local minimum reached by the backward integral line started in $v$, while $M$ is the local maximum reached by the forward integral line started in $v$. We now introduce an equivalence relation $v_1 \sim v_2$ 
between two vertices $v_1$ and $v_2$, which holds if their integration extremities are identical. The \emph{Morse-Smale (MS) segmentation} is then a decomposition of the set of vertices of $\domain$ into maximal subsets $\domain_i$, called \emph{MS regions}, such that for all pairs of vertices $(v_1, v_2) \in \domain_i$, we have $v_1 \sim v_2$.

Let $\tau$ be a $d'$-simplex of $\domain$ (with $0 \leq d' < d$), which only contains vertices belonging to a single MS region $\domain_i$. If the link $\Link(\tau)$
%(i.e. the faces of the co-faces of $\tau$ which do not intersect to $\tau$) 
includes vertices which do \emph{not} belong to $\domain_i$, we say that $\tau$ is a boundary simplex for $\domain_i$. Then the \emph{region boundary} of $\domain_i$ is the simplicial complex formed by the union of all the boundary simplices of $\domain_i$ (and their faces). Each \emph{region boundary} separates $\domain_i$ from the remaining dataset. The \emph{region separators} separate all regions $\domain_i \in \domain$ from each other. To create them, every $d$-simplex of $\domain$ that contains vertices belonging to at least two distinct MS regions spawns $(d-1)$-simplices inside its convex hull, as depicted in \autoref{fig:TriangleCases} and \autoref{fig:tetrahedraTriangulation}.

\subsection{Discrete Morse Theory}
We now conclude this section of preliminaries with notions (adapted from~\cite{guillou_tech22}) of discrete Morse theory~\cite{forman1998morse}, or DMT for short, as it has become a central component in modern implementations of the notion of Morse-Smale complex.
We discuss the key differences between the Morse-Smale complex and the structures extracted by our approach (formalized in Secs. \ref{sec_integralLines} and \ref{sec_segmentation}).

A \emph{discrete vector} is a pair formed by a simplex $\simplex_i \in
\domain$ (of dimension $i$) and one of its co-facets $\simplex_{i+1}$ (i.e. one
of its co-faces of dimension $i+1$), noted $\{\simplex_i < \simplex_{i+1}\}$.
$\simplex_{i+1}$ is usually referred to as the \emph{head} of the vector, while
$\simplex_{i}$ is its \emph{tail}. Examples of discrete vectors include a pair
between a vertex and one of its incident edges or a pair between an edge and a
triangle containing it. A \emph{discrete vector field} on $\domain$ is then
defined as a collection $\discreteVectorField$ of pairs $\{\simplex_i <
\simplex_{i+1}\}$, such that each simplex of $\domain$ is involved in at most
one pair. A simplex $\simplex_i$ which is involved in no discrete vector
$\discreteVectorField$ is called a \emph{critical simplex}.

A \emph{v-path} is a sequence of discrete vectors
$\big\{\{\simplex^0_i < \simplex^0_{i+1}\}, \dots,
\{\simplex^k_i <
\simplex^k_{i+1}\}\big\}$, such that \emph{(i)} $\sigma^j_i \neq
\sigma^{j+1}_i$ (i.e. the tails of two consecutive vectors are distinct) and
\emph{(ii)} $\sigma^{j+1}_i < \sigma^{j}_{i+1}$ (i.e. the tail of a vector in
the sequence is a face of the head of the previous vector), for any $0 < j <
k$.
A \emph{v-path} can be interpreted as the discrete analog to the notion of PL integral line introduced in \autoref{sec_integralLines}.
We say that a v-path \emph{terminates} at a critical simplex $\simplex_i$ if $\simplex_i$ is a face of the head of its last vector $\{\simplex^k_i < \simplex^k_{i+1}\}$. Symmetrically, we say that a v-path \emph{starts} at a critical simplex $\simplex_{i+1}$ if $\simplex_{i+1}$ is a co-facet of the tail of its first vector $\{\simplex^0_i < \simplex^0_{i+1}\}$. Then, the collection of all the v-paths terminating in a given critical simplex $\simplex_i$ is called the \emph{discrete stable set} of $\simplex_i$ and is noted $\domain(\simplex_i)$. Symmetrically, the collection of all the v-path starting at a given critical simplex $\simplex_i$ is called the \emph{discrete unstable set} of $\simplex_i$ and is noted $\domain'(\simplex_i)$.

A \emph{discrete gradient field} is then a discrete vector field such that
all its possible \emph{v-paths} are loop-free. Several algorithms have been
proposed to compute such a discrete gradient field from an
input PL scalar field (see~\cite{robins2011theory} for instance).
The \emph{discrete Morse complex} is then defined as the complex formed by the discrete unstable sets of all the critical simplices. It is a cell complex made of $d'$-dimensional cells (with $d' \in \{0, 1, \dots, d\}$), such that each $d'$-dimensional cell is the discrete unstable set of a critical $d'$-simplex.
The \emph{opposite discrete Morse complex} is defined symmetrically, i.e. it is the cell complex formed by the discrete stable sets of all the critical simplices.
Finally, the \emph{discrete Morse-Smale complex} is defined as the complex formed by the intersections of the cells of the  {discrete Morse complex} and the {opposite discrete Morse complex}. 

Several conceptual differences exist between the Morse-Smale complex and the Morse-Smale (MS) segmentations considered in our work. First, as their name suggests, MS segmentations only provide vertex-based decompositions of the input domain,  not a cell complex that exhaustively and precisely captures all possible adjacency relations between integral lines (formally v-paths). Thus, MS segmentations target a subset of the applications enabled by the Morse-Smale complex (specifically, involving data segmentation). While the separatrices of the MS regions (\autoref{sec_segmentation}) resemble the $2$-dimensional cells of the Morse-Smale complex, they only correspond to the unstable sets of \emph{separating} saddles (\autoref{sec_integralLines}), which constitutes a subset of all the saddles (i.e. saddles where isosurfaces change their genus are not considered). 
% Similarly, the extremal integral lines extracted with our approach correspond to a subset of the $1$-dimensional cells of the Morse-Smale complex (specifically involving separating saddles).
Finally, note that in DMT, local maxima (critical $d$-simplices) cannot strictly occur on the boundary of $\domain$, which only includes $d'$-simplices (with $d' < d$). 
%This nuance has an important implication in practice, as discrete Morse-Smale complexes will tend to fail at capturing features involving maxima located on the boundary of the domain.

\section{Method}
\label{sec:Methods}
In this section, the algorithms for the computation of the PLMSS are described in detail. First, necessary preprocessing steps and data structures are presented. Then the ascending and descending segmentation of the domain is described, followed by the computation of the MS segmentation. 

\subsection{Preprocessing}
\label{sec:preprocessing}

To prevent ambiguity during the computation of integral paths, we apply a variant of \emph{Simulation of Simplicity}~\cite{edelsbrunner1990simulation} on the input scalar field $f$.
We first sort all vertices of the domain according to their scalar value, where we resolve ties based on the indices of the compared vertices.
Then, we derive the so-called order field $\bar f$ that records for each vertex its index in this sorted array.
Note, that each critical point of $f$ is also a critical point of $\bar f$, but $\bar f$ might exhibit additional critical points that result from the disambiguation.
These spurious critical points, however, can be removed via topological simplification, which we apply in order to remove non-persistent critical points from the scalar field.
For a detailed discussion on topological simplification and its implementation in TTK, we refer the reader to the work of Lukasczyk et al.~\cite{lukasczyk2020localized}.

The advantage of processing an order field over the original input scalar field is that $\bar f$ is injective, i.e., every vertex has a distinct largest and smallest neighbor in the order field.
It is only possible that a vertex has no neighbor with a larger or smaller order value, in which case the vertex is a maximum or minimum, respectively. Hence, there is always a distinct direction of steepest ascent and descent, which is essential for the computation of the ascending and descending manifolds, described next.

\subsection{Segmentation and Extrema Retrieval}
\label{sec:segmentation}

The segmentation of the domain is a two-step process. In the first step, the ascending and descending segmentations are created; representing areas of influence of minima and maxima, respectively. These segmentations are intersected to create the MS segmentation, representing the areas of influence of minimum-maximum pairs.

\subsubsection{Ascending and Descending Segmentation}
\label{sec:method_segmentation}

MS segmentations subdivide a domain into areas of similar flow behavior, meaning that forward and backward integration for any vertex in the same region leads to the same extremum pair. This means that each MS subset of the domain corresponds to all steepest descent/ascent paths that terminate in the same pair of extrema. To achieve this, first, every vertex has to be assigned to its minimum and maximum. Therefore, the ascending ($asc$) and descending ($dsc$) segmentations of the domain are computed. As the process is the same for both directions, without loss of generality, it will be described for the descending segmentation.

Maximum assignment for each vertex can be achieved by iteratively finding the largest neighbor's largest neighbor. As this process is lengthy, taking many steps to converge to the maximum, path compression~\cite{seidel2005top} is used to double the step size in each iteration. \autoref{fig:segmentation_explenaitation} gives an example path compression run using 7 ordered vertices.

The segmentation computation starts by assigning each vertex $v$ to its largest neighbor in the triangulation according to the order field function value $dsc(v) = argmax_{x \in N(v)} \bar{f}(x)$, allowing for a fast lookup later in the process. $N(v)$ is the set of all vertices that are connected to $v$ via an edge in the triangulation.

At the same time, maxima can be extracted by recording cases where no larger neighbor is found. For further processing, each vertex that is not a maximum is written to a list of vertices $L_0$ that did not find their maximum yet.

In the second step, the maximum for each vertex in $L_0$ is found using path compression. Here, the value of each vertex gets assigned to the largest neighbor's largest neighbor $dsc(v) = dsc(dsc(v))$. This allows doubling the step size towards the maximum in each iteration. If the corresponding maximum is not found $dsc(v) \neq dsc(dsc(v))$, the vertex did not converge to its maximum and is written to a second list $L_1$. After fully iterating over $L_0$, the process starts again using $L_1$, i.e. $L_0 = L_1$. If $L_1 = \emptyset$ after iterating over $L_0$ the maximum $dsc(v)$ is found for every vertex $v$. 

In parallel environments, each vertex can be evaluated independently with little communication in between iterations, as both steps iterate over a set of vertices. Here, the first step of finding the largest neighbor is equally distributed such that every thread executes the same amount of vertices. Still, every thread $t$ keeps a local list of active vertices, i.e. $L_{0t}, L_{1t}$, executing the following iterations independently for each thread. It is also possible to compute the ascending and descending segmentations simultaneously, further improving performance. To do this, both the largest and smallest neighbors are found at the same time in the first step, and a vertex is added to $L_1$ if it did not converge in both directions in the second step.

\begin{figure}[!htb]
    \centering
    \include{tikz/pathCompression}
    \caption{Path compression example showing vertices as circles and current vertex assignment as arrows.
    The number attached to a vertex is the order field function value, and the outer ring shows if a vertex converged (red).
    The gradient step assigns the largest neighbor to each vertex and each following Iteration sets the neighbor's neighbor for active vertices.
    Please note that the order in which every iteration is executed matters. In this example, it starts with the smallest active vertex and continues in an increasing fashion. If iteration 1 would start with the largest vertex in decreasing order the assignment would already terminate after the first iteration. \label{fig:segmentation_explenaitation}}
\end{figure}

\subsubsection{Morse-Smale Segmentation}
The ascending and descending segmentation obtained by the algorithm above can be combined into an MS segmentation. As the descending segmentation assigns a maximum to each vertex and the ascending segmentation assigns a minimum to each vertex, vertices with the same minimum and maximum are assigned to the same MS id. Therefore, the extremum pair combination is written to each vertex as a tuple, allowing access to the involved extrema. This process is trivial to parallelize, as each thread can independently write the MS ids for its vertices.

\subsection{Multi-Label Marching Triangles/Tetrahedra}
\label{sec:marchingtet}
To visually divide MS regions from each other, region-separating geometries can be created between the regions. As the triangulation consists of triangles in the 2D case and tetrahedra in the 3D case, both cases have to be treated in slightly different ways. In 2D, region-separating geometry is created using edges that split triangles with multiple labels, whereas in 3D, triangles are utilized to separate the vertices of multi-label tetrahedra. Like marching tetrahedra~\cite{doi1991efficient}, each tetrahedron or triangle is evaluated independently, considering the labels at its vertices for generating the bisecting geometry.

\subsubsection{Triangles}
\label{sec:MarchingTriangles}
In the 2D case, a triangle can either have 1, 2, or 3 unique labels at its vertices. In the case of 1 label, no edges have to be generated as the vertices belong to the same region. When 2 different labels are present, one vertex $a$ has a different label than the other two vertices $b,c$. Here, as shown in \autoref{fig:TriangleCases}, the centers of the edges connecting $a$ to $b$ and $a$ to $c$ are used as the endpoints for the edge that splits the labels. In the case of 3 unique labels, an edge is created from the triangle center to all three of its edges.

\begin{figure}[!hb]
\centering
\include{tikz/triangleCaseDescision}
\caption{Decision tree for the triangle binary code creation. Each rhombus represents a decision, each node shows the resulting code with the bit representation in bold and integer representation in brackets.\label{fig:TriangleDescisionTree}}
\end{figure}

Computationally, this is achieved using a lookup table that describes every possible configuration in a triangle. Therefore, a 3-bit binary code with values in the range of $\{0, .., 6\}$ is created to describe the current triangle configuration, utilizing the labels at the three vertices $a, b, c$ of the considered triangle, converted to a dense local representation such that $a = 0, b \in \{0, 1\}, c \in \{0, 1, 2\}$. The label $a$ is always considered to be $0$, $b$ can either be $0$ or $1$ depending on the equality to label $a$, and $c$ can either be $0$, $1$, or $2$ depending on the equality to labels $a$ and $b$. Therefore, $b \in \{0,1\}$ determines the left bit and $c \in \{0,1,2\}$ determines the last two bits. \autoref{fig:TriangleDescisionTree} provides the decision tree. It should be noted that some binary codes cannot appear, as $c = 1$ can only be the case if $b = 1$. Also, codes like $011(3)$ are not possible in general, as there is no label $3$.

Each of the five valid binary codes corresponds to a triangle configuration, as shown in \autoref{fig:TriangleCases}. This allows retrieving the triangle edges that need to be connected. The whole procedure is well-scaling as it is executed per triangle.

\begin{figure}[!htb]
\centering
\include{tikz/triCaseNew}
\caption{All five valid cases for splitting a triangle. The label at the vertices of the triangles is drawn by color (red = $0$, blue = $1$, green = $2$), showing binary code and integer representation at the bottom, and the resulting separating edge(s) in the middle. White circles mark the points of intersection on the edges of the triangle. \label{fig:TriangleCases}}
\end{figure}

\subsubsection{Tetrahedra}
In 3D, the domain is subdivided into tetrahedra. Therefore, up to 4 unique labels $a, b, c, d$ can be present at the vertices of a tetrahedron. Similar to the triangle case, a 5-bit binary code is created and translated into a tetrahedron configuration. This configuration is used to create a consistent triangulation that separates unique labels from each other.

The binary code for tetrahedra is created by an extended logic. $a$ is considered to be 0 again, $b \in \{0,1\}$ determines the left bit, $c \in \{0,1,2\}$ determines the next 2 bits and $d \in \{0,1,2,3\}$ determines the last two bits. If the label of a vertex with lower index matches, its label is used as the resulting label, otherwise the index of the own vertex is used. All valid configurations are provided in \autoref{tab:TetBinaryCode}. Some binary codes are invalid, as some labels might not exist and can not be assigned to a vertex of a higher index. E.g. $00010(2)$ is not possible as $d$ would have label $2$, but $c$ has label $0$, making label $2$ non-existent in this configuration.

\begin{table}[!htb]
    \caption{All valid binary codes, the codes converted to an integer, the number of unique labels of the tetrahedron, and the value of each label. \label{tab:TetBinaryCode}}
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
        Binary code  & Case & \#Labels & $a$ & $b$ & $c$ & $d$ \\
        \hline
        00000 & 0  & 1 & 0 & 0 & 0 & 0 \\
        00011 & 3  & 2 & 0 & 0 & 0 & 3 \\
        01000 & 8  & 2 & 0 & 0 & 2 & 0 \\
        01010 & 10 & 2 & 0 & 0 & 2 & 2 \\
        01011 & 11 & 3 & 0 & 0 & 2 & 3 \\
        10000 & 16 & 2 & 0 & 1 & 0 & 0 \\
        10001 & 17 & 2 & 0 & 1 & 0 & 1 \\
        10011 & 19 & 3 & 0 & 1 & 0 & 3 \\
        10100 & 20 & 2 & 0 & 1 & 1 & 0 \\
        10101 & 21 & 2 & 0 & 1 & 1 & 1 \\
        10111 & 23 & 3 & 0 & 1 & 1 & 3 \\
        11000 & 24 & 3 & 0 & 1 & 2 & 0 \\
        11001 & 25 & 3 & 0 & 1 & 2 & 1 \\
        11010 & 26 & 3 & 0 & 1 & 2 & 2 \\
        11011 & 27 & 4 & 0 & 1 & 2 & 3 \\
        \hline
    \end{tabular}
\end{table}

After the binary code is determined, a lookup table is used to retrieve the resulting separating triangles utilizing the edge, triangle, and tetrahedra centers to be connected. This allows for a fast triangulation of the tetrahedra, as the resulting triangle vertices are directly retrieved. \autoref{fig:tetrahedraTriangulation} shows the resulting triangulation for all cases ignoring permutations and rotations. The triangulation across tetrahedra is always consistent, as the triangle labels of the tetrahedron mimic the 2D case, i.e. triangles are either split by connecting their edge centers to their triangle center, or two triangle edges are connected. Therefore, the triangle connecting two incident tetrahedra is always split in the same way and the resulting triangulation separates labels from each other without any holes in the geometry.

\begin{figure}[!htb]
    \centering
    \include{tikz/tetCaseNew}
    \caption{Triangulation for tetrahedra with more than 1 unique label ignoring permutations and rotations. The case number below the tetrahedra refers to \autoref{tab:TetBinaryCode}. \label{fig:tetrahedraTriangulation}}
\end{figure}

\subsubsection{Triangulation Options}
As the information requested slightly varies from user to user, two region-separating geometries are available. The user can utilize any segmentation (ascending, descending, and Morse-Smale) together with either region boundaries or region separators. \autoref{fig:wallmodes} showcases a closeup view of the segmentations (b-e), where (b) and (d) show region separators, and (c) and (e) show region boundaries.

\noindent\textbf{Segmentation Selection:}
For some applications, a certain segmentation will be of great interest. Here, either the MS, ascending, or descending segmentation can be chosen to deliver the labels for the marching tetrahedra algorithm.  Instead of using the MS segmentation, it is also possible to show the union of the ascending and descending segmentation, producing intersecting geometry at the meeting points of both region-separating geometries.

\noindent\textbf{Region Separating Geometries:}
Both the region separators and the region boundaries have slightly different use cases and allow to map different information to its geometry. The region separators divide all regions, or areas of influence of minima-maxima pairs, from each other by building geometry between them. Therefore, information about the minima and maxima involved in each separating triangle can be displayed to the user. Each subset of the surface that separates the same two regions can be extracted here. Still, some overhead is involved in computing the region separators, as many triangles have to be used to separate the regions from each other, depicted in \autoref{fig:tetrahedraTriangulation}.

Region boundaries allow extracting the hull of regions or areas of influence of minima-maxima pairs. They use all tetrahedra with 3 vertices of the same label. Those 3 vertices form a triangle in the input simplicial complex that can be directly used as a separating geometry. This option will result in faster computation times and allows the extraction of geometry for each region.

% The separate basins mode allows direct extraction of an outer basin surface. This way each label can get its own wall that separates it from the rest of the dataset, enabling easy thresholding for specific labels. It has two options called "fast" and "fine", allowing to get either a simple surface with little geometry involved or a detailed version with many triangles to draw. They can be combined with the ascending, descending, or MS segmentation. 

% The "fast" mode only uses tetrahedra with exactly three vertices of the same label. Any triangle created by such three vertices is directly extracted and attached to the label of these three vertices. This method creates a gap of the size of a tetrahedron between basin surfaces but poses a very fast option to get first results. Its speed makes it a good choice to test various settings before generating more detailed geometry. A drawback of this method is that very fine structures, like a 1 vertex wide tunnel of one label, would not generate any geometry as there are no tetrahedra with 3 vertices of this same label.

% The "fine" option on the other hand is a detailed representation of the basin surfaces that can be created on demand. Generally, it calculates a normal multi-label marching tetrahedra triangulation, duplicating all triangles and moving them slightly towards their assigned vertices by linearly interpolating vertex positions. This closes the above-mentioned gaps and creates a fine-grained triangulation at the cost of memory overhead and higher computation times. Figure~\ref{fig:wallmode_fine} provides an example of the triangulation process where 2 tetrahedron vertices each have the same label. Note that this process is executed for every case shown in \autoref{fig:tetrahedraTriangulation}.

% \subsection{Saddle-Extrema Connections}
% To visually connect extrema and saddles in 3D, integral lines can be created showing the path of steepest ascent or descent from each saddle to their reachable extrema. In 2D, these lines are created by the Marching triangles algorithm provided in \autoref{sec:MarchingTriangles}.

% An extremum is considered reachable by a saddle if an integral line starting at a neighbor vertex of a saddle can reach the extrema by steepest ascent or descent. As this step requires the position of all saddles and extrema, either the saddles have to be provided as an input, or they have to be computed beforehand. 

% Please note that we do not aim at producing the exhaustive list of saddle-extremum connections, i.e. including connections that partially overlap with other connections, but rather a fast, global visual representation of the geometry of the union of these connections.

% In a first step, the neighbors of every saddle are checked for their region id of the provided segmentation. For every region id saddle pair, the neighbor vertex with the steepest decrease(1-saddles) or increase(2-saddles) from its saddle is written to list $L$, containing the saddle, neighbor, and direction of integration. For every entry of $L$, an integral line is created, starting at the saddle towards its chosen neighbor. Now the largest/smallest neighbor in order field function value is found and added to the integral line. This process is continued until an extremum is found.

% As this process would require finding the largest or smallest neighbor at a given vertex, the process is accelerated by using previously computed information. In the first step of the segmentation in \autoref{sec:segmentation}, for the ascending and descending segmentation, every largest or smallest neighbor of each vertex is found. The resulting field can be copied to directly look up the largest/smallest neighbor of every vertex. A benefit of the two-step process, finding the saddle neighbor combinations and shooting the integral lines, is the ability to parallelize this process per saddle neighbor pair. So each integral line is computed by a single thread without interfering with other threads.

\section{Results}
\label{sec:Results}
In this section, three example datasets and their region-separating geometry outputs for both algorithms are provided. The Noisy Terrain dataset in \autoref{sec:noisy_terrain} is used to highlight differences between both algorithms in the 2D case. \autoref{sec:at_dataset} shows that both algorithms produce a very similar output when no saddle-saddle 2-cells are present. The last two datasets indicate that the MS complex is providing more geometry than necessary to effectively extract useful information in many cases, while the PLMSS can extract the areas of influence without additional preprocessing. 

% Here, \autoref{sec:viscous_fingering} is a showcase for small datasets, whereas \autoref{sec:rayleigh-taylor} provides a large dataset.

\subsection{Noisy Terrain}
\label{sec:noisy_terrain}
\begin{figure}[!hbt]
\centering
    \subfloat[PLMSS]{\label{fig:noisymss}\includegraphics[width=0.45\linewidth]{figures/noisyTerrain/noisyTerrainMSS3.png}}
    \hfil
    \subfloat[MS complex]{\label{fig:noisymsc}\includegraphics[width=0.45\linewidth]{figures/noisyTerrain/noisyTerrainMSC3.png}}
    \hfil
    \subfloat[Region separators]{\label{fig:noisymssmsc}\includegraphics[width=0.80\linewidth]{figures/noisyTerrain/noisy_mss_vs_msc.png}}
\caption{Noisy Terrain dataset~\cite{ttkData} showing the PLMSS and MS complex next to each other. Both show critical points (blue = Minima, white = Saddles, red = Maxima), separating geometries in white, and the surface colored by MS complex ids. The border region of the MS complex is not fully segmented 
as a vanilla implementation of the expansion-based discrete gradient computation algorithm \cite{robins2011theory} may miss maxima on the boundary,
%as discrete Morse theory prevents the detection of maxima on the boundary (TTK uses the expansion-based discrete gradient computation algorithm \cite{robins2011theory}),
whereas the boundary of the PLMSS is fully segmented. (c) visually compares the region-separating geometry of the PLMSS (blue) and the MS complex (red). The MS complex produces geometries with a characteristic step-function shape (red), whereas the PLMSS produces separating geometries with a linear-slope shape (blue).
\label{fig:noisyTerrain}}
\end{figure}

The Noisy Terrain dataset is a triangulated surface with elevation scalars attached, chosen as an illustrative example. It has a 300x300 resolution and can be found in the TTK data repository~\cite{ttkData}. Generally, the dataset consists of hills and valleys on a regular grid, where the hills are getting smaller the closer they are to the border. Additionally, noise was added to the terrain to showcase topological simplification.

\autoref{fig:noisyTerrain} compares the PLMSS with the MS complex, using the same color coding for critical points, separating geometries, and segmentation in both versions. Slight differences can be detected regarding the separating geometries, where the MS complex separating geometries are defined on the dual graph and are connecting triangle centers in the 2D case. Concerning the PLMSS, triangles are split according to the labels at the triangle vertices. Another difference can be spotted at the borders of the MS complex, where great sections of the border are not labeled, as a vanilla implementation of the expansion-based discrete gradient computation algorithm of Robins et al.~\cite{robins2011theory} (implemented in TTK) may miss PL maxima on the domain boundary (local post-processing of the discrete gradient would be required to enforce the detection of discrete maxima 
in the star of boundary PL maxima).
%on the boundary).
%as discrete Morse theory prevents the detection of maxima along the domain boundary (TTK now uses the expansion-based discrete gradient computation algorithm of Robins et al. \cite{robins2011theory} by default). 
As the PLMSS assigns a maximum-minimum pair to each vertex, every vertex is properly labeled without skipping the boundary region.

\subsection{AT Molecule}
\label{sec:at_dataset}

\begin{figure}[!htb]
\centering
    \subfloat[PLMSS]{\label{fig:at_mss}\includegraphics[width=0.95\linewidth, angle=90]{figures/at.vti/at_RT_MSS2.png}}
    \subfloat[MS complex]{\label{fig:at_MS complex}\includegraphics[width=0.95\linewidth, angle=90]{figures/at.vti/at_RT_MSC2.png}} 
\caption{Comparison between the region separators computed by PLMSS~(a), and the MS complex 2-cells computed by TTK~(b) using the AT dataset.
The resulting surfaces are colored by the segmentation type, i.e., red for the descending and blue for the ascending segmentation.
%%% NOTES-julien:
%%% I would remove this sentence. Only the ascending cells are computed on the dual (the descending ones 
%%% are computed on the primal). Indeed, that justifies a bit the geometry difference. However, I do not 
%%% believe this is the main reason: the cells of the MS-complex are restricted to simplices of the input
%%% (i.e. the surfaces are constrained to the triangles of the input). Then, by construction, there is a 
%%% difference just from there.
% Note, region separators are computed by PLMSS on the original domain, while 2-cells of the MS complex are % computed on a dual mesh.
% Thus, by construction, the resulting geometries of both approaches can not be identical.
To ease visual comparison, both surfaces were smoothed 20 times using TTK's geometry smoother.
%%% NOTES-julien
%%% I have removed this sentence because this is not correct. The original "at" dataset (i.e. with maxima
%%% at atoms and minima on the boundary) does include many saddle-saddle separatrices (actually, several 
%%% saddle-saddle connectors per carbon cycle).
% The "at" dataset does not exhibit saddle-saddle separatrices, thus for every 2-cell of the MS complex % exists a corresponding region separator computed by PLMSS.
% As shown, b
Both surfaces are almost visually identical.
% , while PLMSS did not require the computation of a discrete gradient field.
%%% NOTES-julien
%%% I removed this part of the sentence because the dual is not explicitly computed. The geometry of the 
%%% cells is obtained on-the-fly by putting a vertex at the barycenter of each traversed tet, adding an
%%% edge for adjacent traversed tets and adding a polygon when ever an edge-loop is created.
%%% So I would say the only overhead is really the computation of the barycenters of these simplices 
%%% (as far as I remember, these are not pre-computed during discrete gradient computation). I don't 
%%% believe this is significant.
% , nor the memory-intensive definition of a dual mesh.
% TODO Julien: please check caption
}
% , while PLMSS has the advantage that the separators were computed on the original domain .
\label{fig:at_vti}
\end{figure}

The AT dataset from the TTK Tutorial Data~\cite{ttkTutorialData} shows the simulation of the electron density of a molecule restricted to a plane but embedded in 3D space. This example, provided in \autoref{fig:at_vti}, shows that the PLMSS and MS complex extract the same underlying geometry at heart if no saddle-saddle 2-cells are present in the dataset. To allow an easier comparison of the separating geometries, all geometries were colored by the underlying segmentation (ascending in red and descending in blue) and smoothed. Most of the separating geometry coincides with at most 1 tetrahedron space in between both representations. The largest difference can be seen in the two narrow red geometries on the middle right of the images, as their distance is smaller when using the PLMSS. The difference between both representations themselves is a result of the dual graph definition of MS complex, compared to the per-vertex definition of the PLMSS.



\subsection{Viscous Fingering}
\label{sec:viscous_fingering}

\begin{figure}[tb]
\centering
    \subfloat[PLMSS]{\label{fig:viscous_mss}\includegraphics[width=0.5\linewidth]{figures/viscous/viscFingersMSS3.png}}
    \hfill
    \subfloat[MS complex]{\label{fig:viscous_msc_post}\includegraphics[width=0.5\linewidth]{figures/viscous/viscFingersMSC3.png}}
 \caption{Comparison of the PLMSS region boundaries and the MS complex using the Viscous Fingering dataset~\cite{ttkData} simplified with an absolute persistence threshold of $0.1$. Both images show the boundary interface of viscous fingers as contours of the salt concentration density scalar field, colored by the density from yellow (high concentration) to purple (low concentration). (a) shows that the PLMSS region boundaries can extract the region-separating geometries that separate single viscous fingers effectively without cluttering the visualization. (b) provides the original MS complex, where more geometry is extracted due to the saddle-saddle 2-cells, cluttering the image. Those saddle-saddle walls would have to be removed by additional postprocessing.\label{fig:viscous_dataset}}
\end{figure}

The Viscous Fingering dataset~\cite{ttkData} represents the result of finite pointset method simulations that simulate the mixing of salt solutions inside water. Regions of high salt concentration form structures called viscous fingers. The analysis of such structures usually involves Reeb graphs or iso-surfaces to identify single fingers in the dataset~\cite{lukasczyk2017viscous}. The MS complex suffers from additional saddle-saddle 2-cells in such scenarios that stem from discrete Morse theory, complicating effective analysis. 
Filtering these saddle-saddle 2-cells out of the set of 2-cells is usually expensive as further post-processing is required to identify and simplify the saddles responsible for such 2-cells. 
The PLMSS, on the other hand, segments the data into regions of influence of maxima-minima pairs, providing a region for each partial viscous finger. The granularity of these separating geometries can be controlled by topological simplification, allowing users to achieve the desired level of detail of the segmentation.

\autoref{fig:viscous_dataset} shows the Viscous Fingering dataset from the TTK data repository~\cite{ttkData} with an applied persistence threshold of 0.1. The colored isosurfaces provide the finger surfaces that correspond to regions of high salt concentration. To allow a deeper look into the dataset, it was clipped in the middle after all geometries were created. Figure~\ref{fig:viscous_dataset}a shows that the PLMSS effectively separates fingers from each other, providing the area of influence of the maxima and hence, for the viscous fingers. The region separators are used to extract the area of influence of single fingers to analyze the area they are growing into with increasing salt concentration. \autoref{fig:viscous_dataset}b provides the MS complex. As for additional saddle-saddle 2-cells, the image is less clear and more cluttered, which can be problematic with noisy or large datasets. Those saddle-saddle walls would have to be removed by additional postprocessing.

\subsection{Rayleigh-Taylor instability (Miranda)}
\label{sec:rayleigh-taylor}

\begin{figure*}[!bth]
  \centering
%   \includegraphics[trim=360 300 640 800, clip, width=.43\linewidth]{teaser-msspl.jpg}
%   \hspace{5mm}
%   \includegraphics[trim=360 300 640 800, clip, width=.43\linewidth]{teaser-msc.jpg}
  \includegraphics[width=.95\linewidth]{figures/teaser-both-horiz.jpg}
      \caption{Illustration showing the results of the piecewise linear Morse-Smale segmentation (PLMSS) ~(top) and the Morse-Smale (MS) complex (bottom) utilizing a Rayleigh-Taylor instability simulation~\cite{miranda} dataset.  The image shows extrema as large orange spheres, additionally providing saddles as green small spheres in the MS complex, as saddle-saddle separatrices are the actual reason for the cluttered MS complex visualization. Even though filtering out saddle-saddle separatrices is possible, the computational overhead will favor the PLMSS in situations where saddle-saddle separatrices hide important features. 
      %Additionally, the MS complex does not detect maxima at the boundary of the domain, as they are generally unnoticed by discrete Morse theory. As opposed to the MS complex, the PLMSS includes the aforementioned boundary maxima.
      \label{fig:teaser}}
      %The Rayleigh-Taylor instability originates from an uneven heating process of the fusion capsule containing the hydrogen isotopes.
\end{figure*}

A concept of controlled fusion using hydrogen isotopes in a laser-lighted fuel capsule lead to the discovery of Rayleigh-Taylor instability\cite{miranda} at the boundary of the capsule. The simulation models the heating process of two hydrogen isotopes for fusion burn. The energy from the laser is non-uniformly distributed and causes small perturbations that quickly grow. One time step of a simulation is analyzed using the MS complex of TTK and the PLMSS.

To filter noise from the data, an absolute persistence threshold of $0.1$ was applied by utilizing localized topological simplification~\cite{lukasczyk2020localized}. By solely extracting the border surfaces of the area of influence created by maximum-minimum pairs, the PLMSS removes clutter from the separating geometries of the MS complex due to the missing saddle-saddle 2-cells. 

\autoref{fig:teaser} compares the visual results of the PLMSS with the MS complex, using one timestep of a Rayleigh-Taylor instability simulation. Here, the PLMSS manages to extract the area of influence of minima and maxima in the dataset. The region-separating geometry is very structured and the boundary between regions of interest can be identified. In contrast, the MS complex introduces a lot of noise due to the remaining saddle-saddle 2-cells that clutter the resulting image. Additionally, the maxima on the boundary are missing, 
as a vanilla implementation of the expansion-based discrete gradient computation algorithm of Robins et al.~\cite{robins2011theory} (implemented in TTK) may miss PL maxima on the domain boundary.

%as they are not allowed by discrete Morse theory.

\section{Performance}
\label{sec:performance}

\begin{table*}[th]
    \centering
    \caption{Raw timing data of the MSCEER, TTK, and PLMSS algorithms in seconds. For each timing, the test was executed 10 times, removing the best and worst time regarding the time listed in the last row, and averaging the remaining runs. It should be noted that the top-level cell count is 6 times higher with TTK and PLMSS than with MSCEER. Similarly, the total number of cells in the input simplicial complex are differing by a factor of roughly 3.24 (Miranda MSCEER: 1,070,599,167 / TTK, PLMSS: 3,473,956,851) (Foot MSCEER: 133,432,831 / TTK, PLMSS: 432,287,731).}
    \begin{tttabular}{llrrrrrrrrrrrr}
&  & \multicolumn{6}{c}{Miranda $512^3$} & \multicolumn{6}{c}{Foot $256^3$} \\
Task & \multicolumn{1}{|c}{Algo.} & \multicolumn{1}{|r}{1T} & 2T & 4T & 8T & 16T & 24T & \multicolumn{1}{|r}{1T} & 2T & 4T & 8T & 16T & 24T \\ \hline \hline
% \multirow{3}{*}{Remove} & \multicolumn{1}{|r}{{\cellcolor{mygray1}{MSCEER}}} & \multicolumn{1}{|r}{{\cellcolor{mygray1}{ - }}}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}&\multicolumn{1}{|r}{{\cellcolor{mygray1}{ - }}}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}\\
% & \multicolumn{1}{|r}{{\cellcolor{mygray2}{TTK}}} & \multicolumn{1}{|r}{ {\cellcolor{mygray2}{2417.15}}} & {\cellcolor{mygray2}{1311.68}} & {\cellcolor{mygray2}{753.39}} & {\cellcolor{mygray2}{476.70}} & {\cellcolor{mygray2}{334.50}} & {\cellcolor{mygray2}{288.09}} & \multicolumn{1}{|r}{{\cellcolor{mygray2}{309.08}}} & {\cellcolor{mygray2}{172.78}} & {\cellcolor{mygray2}{103.68}} & {\cellcolor{mygray2}{67.02}} & {\cellcolor{mygray2}{48.38}} & {\cellcolor{mygray2}{43.12}}\\
% & \multicolumn{1}{|r}{{\cellcolor{mygray3}{PLMSS}}} & \multicolumn{1}{|r}{ {\cellcolor{mygray3}{87.93}}} & {\cellcolor{mygray3}{46.54}} & {\cellcolor{mygray3}{25.09}} & {\cellcolor{mygray3}{13.87}} & {\cellcolor{mygray3}{7.85}} & {\cellcolor{mygray3}{6.02}} & \multicolumn{1}{|r}{{\cellcolor{mygray3}{9.83}}} & {\cellcolor{mygray3}{5.09}} & {\cellcolor{mygray3}{2.71}} & {\cellcolor{mygray3}{1.53}} & {\cellcolor{mygray3}{0.98}} & {\cellcolor{mygray3}{0.79}}\\ \hline 
\multirow{3}{*}{DGF} & \multicolumn{1}{|r}{{\cellcolor{mygray2}{TTK}}} & \multicolumn{1}{|r}{ {\cellcolor{mygray2}{1,326.76}}} & {\cellcolor{mygray2}{685.52}} & {\cellcolor{mygray2}{365.00}} & {\cellcolor{mygray2}{200.15}} & {\cellcolor{mygray2}{112.10}} & {\cellcolor{mygray2}{84.55}} & \multicolumn{1}{|r}{{\cellcolor{mygray2}{152.65}}} & {\cellcolor{mygray2}{78.00}} & {\cellcolor{mygray2}{42.45}} & {\cellcolor{mygray2}{23.32}} & {\cellcolor{mygray2}{13.32}} & {\cellcolor{mygray2}{10.08}}\\
& \multicolumn{1}{|r}{{\cellcolor{mygray1}{MSCEER}}} & \multicolumn{1}{|r}{ {\cellcolor{mygray1}{116.51}}} & {\cellcolor{mygray1}{67.33}} & {\cellcolor{mygray1}{34.43}} & {\cellcolor{mygray1}{20.25}} & {\cellcolor{mygray1}{15.11}} & {\cellcolor{mygray1}{12.80}} & \multicolumn{1}{|r}{{\cellcolor{mygray1}{20.54}}} & {\cellcolor{mygray1}{12.25}} & {\cellcolor{mygray1}{7.78}} & {\cellcolor{mygray1}{5.67}} & {\cellcolor{mygray1}{4.94}} & {\cellcolor{mygray1}{4.86}}\\
& \multicolumn{1}{|r}{{\cellcolor{mygray3}{PLMSS}}} & \multicolumn{1}{|r}{{\cellcolor{mygray3}{ - }}}&{\cellcolor{mygray3}{ - }}&{\cellcolor{mygray3}{ - }}&{\cellcolor{mygray3}{ - }}&{\cellcolor{mygray3}{ - }}&{\cellcolor{mygray3}{ - }}&\multicolumn{1}{|r}{{\cellcolor{mygray3}{ - }}}&{\cellcolor{mygray3}{ - }}&{\cellcolor{mygray3}{ - }}&{\cellcolor{mygray3}{ - }}&{\cellcolor{mygray3}{ - }}&{\cellcolor{mygray3}{ - }}\\ \hline 
\multirow{3}{*}{Asc/Desc} & \multicolumn{1}{|r}{{\cellcolor{mygray2}{TTK}}} & \multicolumn{1}{|r}{ {\cellcolor{mygray2}{442.15}}} & {\cellcolor{mygray2}{269.68}} & {\cellcolor{mygray2}{197.04}} & {\cellcolor{mygray2}{167.68}} & {\cellcolor{mygray2}{158.19}} & {\cellcolor{mygray2}{152.42}} & \multicolumn{1}{|r}{{\cellcolor{mygray2}{35.12}}} & {\cellcolor{mygray2}{28.23}} & {\cellcolor{mygray2}{24.54}} & {\cellcolor{mygray2}{22.92}} & {\cellcolor{mygray2}{22.38}} & {\cellcolor{mygray2}{22.63}}\\
& \multicolumn{1}{|r}{{\cellcolor{mygray1}{MSCEER}}} & \multicolumn{1}{|r}{ {\cellcolor{mygray1}{167.60}}} & {\cellcolor{mygray1}{99.48}} & {\cellcolor{mygray1}{53.12}} & {\cellcolor{mygray1}{28.71}} & {\cellcolor{mygray1}{15.89}} & {\cellcolor{mygray1}{11.63}} & \multicolumn{1}{|r}{{\cellcolor{mygray1}{34.77}}} & {\cellcolor{mygray1}{24.07}} & {\cellcolor{mygray1}{21.35}} & {\cellcolor{mygray1}{19.88}} & {\cellcolor{mygray1}{18.97}} & {\cellcolor{mygray1}{19.25}}\\
& \multicolumn{1}{|r}{{\cellcolor{mygray3}{PLMSS}}} & \multicolumn{1}{|r}{ {\cellcolor{mygray3}{39.61}}} & {\cellcolor{mygray3}{20.08}} & {\cellcolor{mygray3}{10.64}} & {\cellcolor{mygray3}{5.73}} & {\cellcolor{mygray3}{3.07}} & {\cellcolor{mygray3}{2.31}} & \multicolumn{1}{|r}{{\cellcolor{mygray3}{4.40}}} & {\cellcolor{mygray3}{2.23}} & {\cellcolor{mygray3}{1.16}} & {\cellcolor{mygray3}{0.68}} & {\cellcolor{mygray3}{0.43}} & {\cellcolor{mygray3}{0.36}}\\ \hline
\multirow{3}{*}{MS} & \multicolumn{1}{|r}{{\cellcolor{mygray2}{TTK}}} & \multicolumn{1}{|r}{ {\cellcolor{mygray2}{4.78}}} & {\cellcolor{mygray2}{2.44}} & {\cellcolor{mygray2}{1.40}} & {\cellcolor{mygray2}{1.02}} & {\cellcolor{mygray2}{0.73}} & {\cellcolor{mygray2}{0.66}} & \multicolumn{1}{|r}{{\cellcolor{mygray2}{0.46}}} & {\cellcolor{mygray2}{0.23}} & {\cellcolor{mygray2}{0.18}} & {\cellcolor{mygray2}{0.16}} & {\cellcolor{mygray2}{0.11}} & {\cellcolor{mygray2}{0.10}}\\
& \multicolumn{1}{|r}{{\cellcolor{mygray1}{MSCEER}}} & \multicolumn{1}{|r}{{\cellcolor{mygray1}{ - }}}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}&\multicolumn{1}{|r}{{\cellcolor{mygray1}{ - }}}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}\\
& \multicolumn{1}{|r}{{\cellcolor{mygray3}{PLMSS}}} & \multicolumn{1}{|r}{ {\cellcolor{mygray3}{0.32}}} & {\cellcolor{mygray3}{0.16}} & {\cellcolor{mygray3}{0.09}} & {\cellcolor{mygray3}{0.05}} & {\cellcolor{mygray3}{0.03}} & {\cellcolor{mygray3}{0.02}} & \multicolumn{1}{|r}{{\cellcolor{mygray3}{0.04}}} & {\cellcolor{mygray3}{0.02}} & {\cellcolor{mygray3}{0.01}} & {\cellcolor{mygray3}{0.01}} & {\cellcolor{mygray3}{0.00}} & {\cellcolor{mygray3}{0.00}}\\ \hline
\multirow{3}{*}{Index} & \multicolumn{1}{|r}{{\cellcolor{mygray2}{TTK}}} & \multicolumn{1}{|r}{ {\cellcolor{mygray2}{152.24}} }& {\cellcolor{mygray2}{90.30}} & {\cellcolor{mygray2}{46.73}} & {\cellcolor{mygray2}{24.59}} & {\cellcolor{mygray2}{12.80}} & {\cellcolor{mygray2}{9.43}} & \multicolumn{1}{|r}{{\cellcolor{mygray2}{26.73}}} & {\cellcolor{mygray2}{16.49}} & {\cellcolor{mygray2}{8.83}} & {\cellcolor{mygray2}{4.58}} & {\cellcolor{mygray2}{2.56}} & {\cellcolor{mygray2}{2.07}}\\
& \multicolumn{1}{|r}{{\cellcolor{mygray1}{{\cellcolor{mygray1}{MSCEER}}}}} & \multicolumn{1}{|r}{{\cellcolor{mygray1}{117.00}}} & {\cellcolor{mygray1}{58.92}} & {\cellcolor{mygray1}{30.87}} & {\cellcolor{mygray1}{16.20}} & {\cellcolor{mygray1}{8.68}} & {\cellcolor{mygray1}{6.24}} & \multicolumn{1}{|r}{{\cellcolor{mygray1}{15.70}}} & {\cellcolor{mygray1}{8.37}} & {\cellcolor{mygray1}{4.90}} & {\cellcolor{mygray1}{3.00}} & {\cellcolor{mygray1}{2.07}} & {\cellcolor{mygray1}{1.77}}\\
& \multicolumn{1}{|r}{{\cellcolor{mygray3}{PLMSS}}} & \multicolumn{1}{|r}{ {\cellcolor{mygray3}{39.00}}} & {\cellcolor{mygray3}{19.62}} & {\cellcolor{mygray3}{10.24}} & {\cellcolor{mygray3}{5.28}} & {\cellcolor{mygray3}{2.72}} & {\cellcolor{mygray3}{1.89}} & \multicolumn{1}{|r}{{\cellcolor{mygray3}{4.81}}} & {\cellcolor{mygray3}{2.42}} & {\cellcolor{mygray3}{1.27}} & {\cellcolor{mygray3}{0.67}} & {\cellcolor{mygray3}{0.41}} & {\cellcolor{mygray3}{0.29}}\\ \hline
\multirow{3}{*}{Geometry} & \multicolumn{1}{|r}{{\cellcolor{mygray2}{TTK}}} & \multicolumn{1}{|r}{ {\cellcolor{mygray2}{491.21}}} & {\cellcolor{mygray2}{263.75}} & {\cellcolor{mygray2}{143.22}} & {\cellcolor{mygray2}{83.25}} & {\cellcolor{mygray2}{50.67}} & {\cellcolor{mygray2}{41.04}} & \multicolumn{1}{|r}{{\cellcolor{mygray2}{94.11}}} & {\cellcolor{mygray2}{49.84}} & {\cellcolor{mygray2}{27.69}} & {\cellcolor{mygray2}{16.05}} & {\cellcolor{mygray2}{10.02}} & {\cellcolor{mygray2}{8.25}}\\
& \multicolumn{1}{|r}{{\cellcolor{mygray1}{MSCEER}}} & \multicolumn{1}{|r}{{\cellcolor{mygray1}{ - }}}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}&\multicolumn{1}{|r}{{\cellcolor{mygray1}{ - }}}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}&{\cellcolor{mygray1}{ - }}& {\cellcolor{mygray1}{ - }}\\
& \multicolumn{1}{|r}{{\cellcolor{mygray3}{PLMSS}}} & \multicolumn{1}{|r}{ {\cellcolor{mygray3}{8.99}}} & {\cellcolor{mygray3}{6.68}} & {\cellcolor{mygray3}{4.12}} & {\cellcolor{mygray3}{2.81}} & {\cellcolor{mygray3}{2.03}} & {\cellcolor{mygray3}{1.79}} & \multicolumn{1}{|r}{{\cellcolor{mygray3}{0.59}}} & {\cellcolor{mygray3}{0.42}} & {\cellcolor{mygray3}{0.27}} & {\cellcolor{mygray3}{0.18}} & {\cellcolor{mygray3}{0.13}} & {\cellcolor{mygray3}{0.14}}\\ \hline  \hline
DGF + & \multicolumn{1}{|r}{{\cellcolor{mygray2}{TTK}}} & \multicolumn{1}{|r}{ {\cellcolor{mygray2}{1,921.16}}} & {\cellcolor{mygray2}{1,045.49}} & {\cellcolor{mygray2}{608.77}} & {\cellcolor{mygray2}{392.42}} & {\cellcolor{mygray2}{283.09}} & {\cellcolor{mygray2}{\textbf{246.39}}} & \multicolumn{1}{|r}{{\cellcolor{mygray2}{214.50}}} & {\cellcolor{mygray2}{122.71}} & {\cellcolor{mygray2}{75.82}} & {\cellcolor{mygray2}{50.81}} & {\cellcolor{mygray2}{38.26}} & {\cellcolor{mygray2}{\textbf{34.78}}}\\
Index + & \multicolumn{1}{|r}{{\cellcolor{mygray1}{MSCEER}}} & \multicolumn{1}{|r}{ {\cellcolor{mygray1}{401.12}}} & {\cellcolor{mygray1}{225.73}} & {\cellcolor{mygray1}{118.43}} & {\cellcolor{mygray1}{65.16}} & {\cellcolor{mygray1}{39.68}} & {\cellcolor{mygray1}{\textbf{30.67}}} & \multicolumn{1}{|r}{{\cellcolor{mygray1}{71.02}}} & {\cellcolor{mygray1}{44.70}} & {\cellcolor{mygray1}{34.03}} & {\cellcolor{mygray1}{28.56}} & {\cellcolor{mygray1}{25.98}} & {\cellcolor{mygray1}{\textbf{25.87}}}\\
Asc/Des & \multicolumn{1}{|r}{{\cellcolor{mygray3}{PLMSS}}} & \multicolumn{1}{|r}{ {\cellcolor{mygray3}{78.61}}} & {\cellcolor{mygray3}{39.70}} & {\cellcolor{mygray3}{20.89}} & {\cellcolor{mygray3}{11.01}} & {\cellcolor{mygray3}{5.79}} & {\cellcolor{mygray3}{\textbf{4.20}}} & \multicolumn{1}{|r}{{\cellcolor{mygray3}{9.21}}} & {\cellcolor{mygray3}{4.65}} & {\cellcolor{mygray3}{2.43}} & {\cellcolor{mygray3}{1.35}} & {\cellcolor{mygray3}{0.84}} & {\cellcolor{mygray3}{\textbf{0.65}}}\\ \hline
    \end{tttabular} \hfill%
    \label{tab:strong_scaling}
\end{table*}

\begin{figure*}[!htb]
\includegraphics[width=0.95\textwidth]{figures/performance/mir-speedup.pdf}
\caption{Rayleigh-Taylor instability dataset~\cite{miranda} performance of all three algorithms at a resolution of  $512^3$. The left graph shows the runtime sum of the DGF, ascending and descending segmentation, and indexing as a log-log plot regarding the number of cores used for the experiment. In the middle, the speedup factor, i.e. the runtime of 1 thread divided by the runtime of $x$ threads, is also shown as a log-log plot regarding core counts. On the right, the parallel efficiency, i.e. the speedup factor divided by the number of cores, is represented in a semi-log plot.\label{fig:miranda_performance}}
\end{figure*}

\begin{figure*}[!htb]
\includegraphics[width=0.95\textwidth]{figures/performance/foot-speedup.pdf}
\caption{Foot dataset~\cite{ttkData} performance of all three algorithms at a resolution of  $256^3$. The left graph shows the runtime sum of the DGF, ascending and descending segmentation, and indexing as a log-log plot regarding the number of cores used for the experiment. In the middle, the speedup factor, i.e. the runtime of 1 thread divided by the runtime of $x$ threads, is also shown as a log-log plot of core counts. On the right, the parallel efficiency, i.e. the speedup factor divided by the number of cores, is represented in a semi-log plot.\label{fig:foot_performance}}
\end{figure*}

In this section, the computational performance of our implementation is analyzed and compared to the MS complex implementation of TTK\cite{ttk17} and MSCEER\cite{msceer}. As hinted by the authors of MSCEER, we use the ``steepest\_lstar'' and ``extractms'' packages, as they supply the fastest implementation without accurate geometry. Both strong scaling studies show that the PLMSS is scaling well with core count due to the mentioned improvements. We utilize the Rayleigh-Taylor instability (Miranda) dataset~\cite{miranda} at a resolution of $512^3$ and the Foot dataset~\cite{ttkData} at a resolution of $256^3$ for the computation speed comparisons of all three algorithms.

\subsection{Algorithmic improvements}
In general, three main aspects of the PLMSS result in a strongly reduced computation time as compared to the MS complex. First, the segmentation of the domain is improved by path compression, which is much faster than computing a discrete gradient field. Second, the multi-label marching tetrahedra algorithm supports computing the separating geometries in a well-scaling way. Third,  splitting the marching tetrahedra algorithms into indexing and geometry creation steps allows the allocation of the resources needed in the geometry creation step without additional computations.  

\subsubsection{Segmentation}
The segmentation of the domain into the ascending and descending manifold and the intersection of both manifolds, called MS manifold, are computed differently for the MS complex and the PLMSS. Both MS complex implementations require a discrete gradient field to be computed first, then following the v-paths along the gradient field to assign labels to each vertex. However, the PLMSS segmentation utilizes path compression to assign each vertex to its designated minimum or maximum, without the need for any additional structure other than the order field.

For path compression to work, all neighbors of each vertex must be visited once to get the largest and smallest neighbor of that vertex. With this information, the maximum can be found iteratively by assigning its largest neighbor's largest neighbor to the vertex. This process is executed in multiple iterations, where each iteration finds the designated maximum of a vertex or a vertex closer to the designated maximum. Here, each time the step length is doubled, yielding extremum assignment in $log(s)$ steps for each vertex, where $s$ is the number of vertices on the integral line of the vertex to the extremum. Also, the iterations get smaller every time, as more and more vertices are assigned to their extremum.

\autoref{tab:strong_scaling} shows the timings of those steps in the first three rows, where "DGF" refers to the discrete gradient field computation, "Asc/Desc" refers to the ascending and descending segmentation, and "MS" refers to the MS segmentation. Please note that the MSCEER algorithm does not compute an MS segmentation in the provided implementation.

Even in a single-threaded environment, the performance gains of retrieving the ascending and descending segmentations already show strong improvements in the computation time of the PLMSS compared to the MS complex implementations. For the Miranda dataset, PLMSS only needs a total of 39.61s for the computation of the ascending and descending segmentation. Comparing this to the MS complex implementations (MSCEER: 284.11s / TTK: 1768.91s) leaves us at a speedup of 7x and 44x respectively.

\subsubsection{Multi-Label Marching Tetrahedra}
After segmenting the domain into various regions, region-separating geometries can be created that help to visualize the segmentation effectively. Again, the PLMSS and the MS complex implementations differ in the realization of this step. Regarding the MS complex implementations, paths between critical point pairs have to be traced on the DGF, whereas the PLMSS uses a marching tetrahedra algorithm.

Marching tetrahedra algorithms scale very well as they are executed per vertex. In our implementation, the binary code, as described in \autoref{sec:marchingtet}, and the number of triangles created per thread are computed in a preliminary step. This allows the allocation of the exact amount of memory needed for the triangles. In a follow-up step, this enables direct writing of triangles to memory.

\autoref{tab:strong_scaling} shows the timings of those steps in the 4th and 5th row, where "Index" refers to the computation of simplex indices that will spawn triangles, and "Geometry" represents writing the triangles to memory. Please note that the MSCEER algorithm does not compute the geometry itself in the provided implementation, but only gathers the indices of relevant simplices.

A comparison of the single thread timings with the Miranda dataset shows that the indexing is almost four times faster compared to TTK and three times faster than MSCEER. These speedups come from the excessive use of lookup tables and a per tetrahedra execution that does not require any tracing of paths. With the additional memory counting in the indexing step and the lower number of triangles created, the geometry-creating part strongly improved regarding computation times.

\subsection{TTK vs. MSCEER}
Both MS complex solutions are slightly different in the specifics of their implementation. First of all, TTK uses a simplicial complex that uses tetrahedra and triangles as top-level simplices, whereas MSCEER uses cubes and squares. This already leads to roughly $324\%$ more total cells and six times more top-level cells in the case of the TTK-based implementation, such as the MS complex or PLMSS. This will have an effect on the runtime of the algorithms, as well as the resolution of the extracted region-separating geometries. Still, this is only a limitation of the current TTK version and might change in the future to trade accuracy for runtime efficiency.

Another issue, when comparing both algorithms with each other, is the output generated by each implementation. The version provided by Gyulassy et al.\cite{msceer} only provides an ascending and descending segmentation of the domain and the indices of top-level cells that would spawn region-separating geometries. The MS complex representation and the surface geometries would be created by a different software at runtime that was not supplied with the library.

\subsection{Strong Scaling Setup}
Both strong scaling studies were carried out on a dual Intel XEON SP 6126 node with 24 CPU cores and 384GB of RAM. For each algorithm, various timings were created, starting with the computation of the discrete gradient field, ascending and descending segmentation, MS segmentation, indexing of tetrahedra or cubes that generate region-separating geometries, and writing the region-separating geometries to memory. The results for both studies are shown in \autoref{tab:strong_scaling}, where the last row shows the total time to get an ascending and descending segmentation and mark all top-level cells that generate region-separating geometries. To mimic the layout of the 2-cells of the MS complex, the region separators of the PLMSS were computed for those results.

For each combination of the dataset, the number of threads, and the algorithm, the experiment was executed $10$ times. From these 10 runs, the best and the worst ones, regarding total computation time, were discarded. The remaining 8 runs were averaged to achieve more stable results.

\subsection{Strong Scaling: Rayleigh-Taylor Instability}
Utilizing the Rayleigh-Taylor instability dataset~\cite{miranda}, a strong scaling analysis was carried out for a $512^3$ subset of the data, simplified with a persistence threshold of $0.1$. Computation times, speedup factor (i.e. the time a single thread takes divided by the time the current number of threads take), and parallel efficiency (i.e. speedup factor divided by the number of threads) are plotted against the number of cores, shown in \autoref{fig:miranda_performance}.

The total execution time in the last row of \autoref{tab:strong_scaling} shows that the PLMSS is more than an order of magnitude faster than TTK and 5 to 7 times faster than MSCEER. As the PLMSS still has to be executed on roughly three times the cells, this is still an improvement of an order of magnitude regarding the time per cell. The speedup factor and parallel efficiency also show a clear trend that PLMSS is scaling very well with more cores. In this regard, MSCEER beats TTK in terms of scalability but clearly performs worse against PLMSS. The speedup factor graph also hints that more cores would be beneficial in future experiments as PLMSS still scales well at 24 cores. Due to insufficient computational resources, we were unable to offer a larger strong scaling analysis.

\subsection{Strong Scaling: CT Scan of a Human Foot}
The foot dataset~\cite{ttkData} was chosen to represent smaller data sizes with a resolution of $256^3$, simplified with a persistence threshold of $110$. It consists of a CT scan of the tip of a foot, where the threshold of 110 was chosen to represent each bone with its own region.

Regarding the total execution time at $24$ Threads in \autoref{tab:strong_scaling}, a speedup of over 50x and almost 40x (TTK and MSCEER) can be achieved using PLMSS. The resulting graphs in \autoref{fig:foot_performance} also show clear improvements regarding parallel efficiency, as PLMSS ($0,59$) still achieves good results that hint towards using even more cores, where TTK ($0,26$) and MSCEER ($0,11$) are already in a range where more cores do not strongly improve runtime performance and communication overhead takes over.

\subsection{Discussion}
For both datasets, the PLMSS showed good improvements over the MSCEER and TTK implementation, yielding a great parallel efficiency. Especially, for the foot dataset, great runtime performance improvements of roughly 40x were achieved. Even with the 5-7x runtime improvement regarding the Rayleigh-Taylor instability dataset, 6x more top-level cells had to be traversed compared to MSCEER.

\section{Limitations}
\label{sec:Limitations}
Our entire approach aims at efficiently computing ascending and descending segmentations of the input scalar field.
Its output is not a complete Morse-Smale complex.
First, it does not capture saddle-saddle connectors, which may be useful in certain applications.
Second, it does not output an explicit CW complex modeling the Morse-Smale complex (i.e. where vertices encode critical points, 1-dimensional cells encode separatrices, 2-dimensional cells encode separating geometries, and 3-dimensional cells encode regions with identical integration extremities), only the domain segmentation is provided. 
This can be detrimental in applications involving post-processing of the Morse-Smale complex, such as regular remeshing~\cite{DongBGPH06} or hierarchical simplification~\cite{GyulassyNPBH06}.
For these applications, a standard algorithm based on discrete Morse theory (such as the one available in TTK~\cite{ttk17} or MSCEER~\cite{msceer}) should be preferred.

\section{Conclusion and Future Work}
\label{sec:Conclusion}
The presented algorithm describes a well-scaling approach to computing MS segmentations, allowing for speedups of more than an order of magnitude compared to two MS complex implementations. Utilizing path compression to create the segmentations allows us to quickly extract the labels for the multi-label marching tetrahedra algorithm that powers the generation of region-separating geometries. The algorithm is not only faster but also has a lower memory footprint, as no discrete gradient vector field and little preprocessing of the triangulation is needed. Only a scalar field saving the 5-bit index representation for each vertex has to be created. The utilization of only top-level cells and vertices  simplifies triangulation generation. Additionally, maxima at the border of the MS complex are not allowed by DMT design, often leading to missing border regions in each segmentation. This issue is fixed by segmenting the whole domain, also retrieving all border maxima in the process. Regarding the generated separating geometries, several use cases have been presented that show the applicability of our approach where the MS complex failed to deliver without expensive post-processing using saddle-saddle 2-cell cancellation. Simply speaking, our algorithm allows us to extract areas of influence of minima, maxima, and minima-maxima pairs by separating their boundaries with two available separating geometries that can be triggered by three segmentation options. Still, this does not invalidate the Morse-Smale complex as we only compute a segmentation and not the complex itself. Features like the saddle-saddle connectors are not computed. Therefore, we conclude that the PLMSS is a versatile tool to generate MS segmentations in a well-scaling parallel way, allowing users to explore their data much faster, while still being able to fall back to the MS complex on demand. 

For future work, we are planning to improve the PLMSS in various ways. The load on each of the threads can be imbalanced when a particular thread receives a lot of triangles to generate. Here, a workload balance system could be introduced. To scale to even larger datasets, an MPI implementation will be provided to enable distributed memory execution. The knowledge gained from creating the segmentations will be implemented into the TTK MS complex implementation to improve its performance and useability. As shown in \autoref{sec:performance}, a thorough comparison between MS complex implementations is out of the scope of this paper. Comparing all publicly available implementations and characterizing them in terms of input simplicial complex, handling of functions that are not Morse, available simplification models (pre- vs. post-simplification), output options, and memory footprint would be beneficial. Additionally, a version of the PLMSS using voxels as top-level cells in 3D could potentially speed up the computation considerably and would downsize the memory footprint even more. Also, the effect of path compression might be applicable to the computation of the MS complex, so additional research in integrating it might be of interest to achieve better runtime efficiency of MS complex implementations.

% use section* for acknowledgment
\ifCLASSOPTIONcompsoc
  %The Computer Society usually uses the plural form
  \section*{Acknowledgments}
    This research was funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)  252408385  IRTG 2057.
    This work is also partially supported by the European Commission grant ERC-2019-COG \emph{``TORI''} (ref. 863464, \url{https://erc-tori.github.io/}).
\else
  %regular IEEE prefers the singular form
  \section*{Acknowledgment}
    This research was funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)  252408385  IRTG 2057.
    This work is also partially supported by the European Commission grant ERC-2019-COG \emph{``TORI''} (ref. 863464, \url{https://erc-tori.github.io/}).
\fi

% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

\bibliographystyle{IEEEtran}
\bibliography{paper}

% biography section
% 
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{biographies/robin_maack.png}}]{Robin G. C. Maack}
received the Master's degree in computer science in October 2020 from the University of Kaiserslautern. He started as a student assistant in January 2017 and now further develops his projects as a PhD student. His research interests include topological data analysis, medical image analysis and visualization, biochemical visualization, and uncertainty visualization.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{biographies/jonas.jpeg}}]{Jonas Lukasczyk}
received his Ph.D. degree from the Visual Information Analysis Group, Technische Universitat Kaiserslautern, Germany, where he also studied applied computer science and mathematics. His recent work focuses on topology-based characterization of features and their evolution in large-scale simulations. 
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{biographies/tierny.jpeg}}]{Julien Tierny}
received the PhD degree in computer science from the University of Lille, in
2008. He is currently a CNRS senior scientist, affiliated with
Sorbonne University. Prior to his
CNRS tenure, he held a Fulbright fellowship (U.S.
Department of State) and was a postdoctoral
researcher at the Scientific Computing and Imaging Institute at the University of Utah. His research expertise lies in topological
methods for data analysis and visualization. He is the founder and lead
developer of the Topology ToolKit (TTK), an open source library for topological data analysis.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{biographies/hans_new.jpg}}]{Hans Hagen}
is a computer science professor at University
of Kaiserslautern and an adjunct professor at University of California,
Davis. He received a Bachelors degree in computer science, a Master
degree in mathematics from the University of Freiburg and a PhD in
mathematics (geometry) from the University of Dortmund. His main
research interests are scientific visualization and geometric modeling.
He is a member of the IEEE Visualization Academy of Science, and
he got the IEEE Visualization Career Award, the ACM Solid Modeling
Pioneer Award and the John Gregory Memorial Award among others.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{biographies/ross.jpg}}]{Ross Maciejewski}
is a professor with the School of Computing and Augmented Intelligence at Arizona State University and director of the Center for Accelerating Operational Efficiciency - a Department of Homeland Security Center of Excellence. His primary research interests include the areas of geographical visualization and visual analytics.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{biographies/garth_new.jpg}}]{Christoph Garth}
received the PhD degree in
computer science from Technische Universitt
(TU) Kaiserslautern in 2007. After four years as
a postdoctoral researcher with the University of
California, Davis, he rejoined TU Kaiserslautern
where he is currently a full professor of computer
science. His research interests include largescale data analysis and visualization, in situ visualization, topology-based methods in visualization, and interdisciplinary applications of visualization.
\end{IEEEbiography}

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}



% that's all folks
\end{document}


