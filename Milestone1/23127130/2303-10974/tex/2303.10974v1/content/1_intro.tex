\section{Introduction}

Adversarial perturbations are carefully crafted modifications of the input that are imperceptible for humans but force a machine learning model to perform poorly.
Initially discovered in the domain of computer vision~\cite{DBLP:journals/corr/SzegedyZSBEGF13,DBLP:journals/corr/GoodfellowSS14}, where imperceptibility is attained by restricting the norm of additive perturbation, they were later extended to the natural language processing (NLP).
Since the nature of language is discrete, the imperceptibility in NLP is attained either on the character-level~\cite{DBLP:conf/coling/EbrahimiLD18,DBLP:conf/acl/EbrahimiRLD18}, where only few characters in a word are subject to change, or on the word-level~\cite{DBLP:conf/conll/BlohmJSYV18,DBLP:conf/aaai/ChengYCZH20}, where the words are allowed to be replaced only by the semantically similar words (e.g., by synonyms). 

However, machine translation (MT) systems are known to be vulnerable to adversarial examples with relaxed imperceptibility~\cite{chen2022should}.
More than that, apart from sensitivity to imperceptible adversarial examples, MT may both produce meaningful translations for nonsensical gibberish input queries and refuse to translate seemingly benign input phrases.
This unpredictable behavior may not only interfere with understanding a new language but also may lead to serious problems (e.g., several years ago Facebookâ€™s MT system mistranslated an Arabic phrase meaning ``good morning'' as ``attack them'' which led to a wrongful arrest~\cite{berger2017israel,ebrahimi2018adversarial}). Hence, understanding the unpredictable behavior of these systems is an essential step for improving the robustness of machine translation and, as a result, for preventing such incidents. 

In this work, we investigate the stability and behavior of MT systems for inputs with low likelihood.
We consider three major well-known online translators DeepL
%\footnote{
%    \url{https://www.DeepL.com/translator}.
%},
Google,
%\footnote{
%    \url{https://translate.google.com}.
%}
and Yandex,
%\footnote{
%\url{https://translate.yandex.ru}.
%},
and set the task of automatically finding an input in Russian representing an arbitrary set of letters of a given length (not a word), which, however, leads to a meaningful translation into English (a word or set of words).
We formulate it as a problem of maximizing the difference between the perplexity~\cite{sadrizadeh2023transfool} of the translation and the source text, and we apply GPT-2~\cite{radford2019language} to define the perplexity of the input and output sequences.
For a search of the best combination of input symbols we use the new global optimization method PROTES\footnote{
    We use the code from \url{https://github.com/anabatsh/PROTES}.
}~\cite{batsheva2023protes}, which is based on the low-rank tensor train (TT) decomposition~\cite{oseledets2011tensor} and can efficiently perform gradient-free multivariate discrete optimization.
For all three considered MT systems, we obtained a set of seven-letter inputs in Russian that are not words, which, however, lead to a translation representing a word or set of words in English.
Hereafter, for the sake of brevity, we will refer to such inputs as \emph{hallucinogens}.

What is an intriguing, both manual and automatic combinations of the obtained hallucinogens, as it turned out, allows getting a variety of valid English phrases.
Moreover, some of these phrases turn out to be examples of adversarial attacks (detected so far only for the DeepL translator).
When trying to translate them back into Russian, the translator produces significantly incorrect results (garbage word combinations or even a blank translation string).

To summarize, our main contributions are the following:
\begin{itemize}
    \item
        We develop a new black-box optimization method for the automatic generation of low-likelihood input sequences (``hallucinogens'')  with high translation likelihood for MT systems based on the perplexity estimation of the input and output sequences. %and the PROTES optimization method in the TT-format.
    \item
        We demonstrate that it is possible to use this approach for black-box adversarial attacks on MT systems since the corresponding translation results for a set (phrase) of hallucinogens often correspond to the ``instability points'' of the system and lead to invalid backward translation.
    \item
        We apply the proposed approach for major online translators DeepL, Google, and Yandex, find an extensive set of hallucinogens and their combinations for all three translators, and demonstrate the possibility of an adversarial attack on the DeepL system\footnote{
            The program code and all results with the supporting screenshots are available in our public repository 
            % TODO for final version:
            \url{https://github.com/AndreiChertkov/TranFighterPro}.
        }.
\end{itemize}