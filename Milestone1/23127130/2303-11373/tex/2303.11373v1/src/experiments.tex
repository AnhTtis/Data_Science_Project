\section{Experiments} \label{sec:experiments}
We have proposed~\methodname as a solution to the object rearrangement problem that addresses two challenges:~\methodname addresses the correspondence problem by learning a factorized object-centric world model with dSLATE and it addresses the combinatorial problem by abstracting entity representations into a queryable state transition graph.
Now we test~\methodname's efficacy in solving both problems.

The key question is whether~\methodname is better than state-of-the-art offline RL algorithms in generalizing over combinatorially-structured task spaces from perceptual input.
As stated in \S\ref{sec:problem}, the crucial test for answering this question is to evaluate all methods on solving new rearrangement problems with a disjoint set of object configurations from those encountered during training.
The most straightforward way to find a disjoint subset of the combinatorial space is to evaluate with a novel number of objects.
We compare~\methodname to several offline RL baselines and ablations on two rearrangement environments and find a significant gap in performance between our method and the next best method.

\input{src/figs/experiment_tasks}

\textbf{Environments.}
In \emph{block-rearrange} (Fig.~\ref{fig:environments}a), all objects are the same size, shape, and orientation.
$\mathcal{S}$ covers 16 locations in a grid. 
$\mathcal{Z}$ is the continuous space of red-green-blue values from $0$ to $1$.
\emph{robogym-rearrange} (Fig.~\ref{fig:environments}b) is adapted from the~\citet{robogym2020} rearrange environment and removes the assumptions from \emph{block-rearrange} that all objects have the same size, shape, and orientation.
The objects are uniformly sampled from a set of 94 meshes consisting of the YCB object set \citep{calli2015ycb} and a set of basic geometric shapes, with colors sampled from a set of 13.
Although locations are not pre-defined in \emph{robogym-rearrange} as in \emph{block-rearrange}, in practice there is a limit to the number of ways to arrange objects on the table to still be visible to the camera, which makes the bisimulation still a reasonable assumption here.
For \emph{block-rearrange} we use the SA attention mask $\alpha$ as the state $s$, and for \emph{robogym-rearrange} we use the action-dependent part of the SA slot $\bm{\lambda}^s$ as the state $s$.
Further environment details are in Appdx.~\ref{appdx:environment_details}.

\textbf{Experimental setup.}
We evaluate two settings: \emph{complete} and \emph{partial}.
In the \emph{complete} setting, the goal image shows all objects in new locations.
The \emph{partial} setting is underspecified: only a subset of objects have associated goal constraints (Fig.~\ref{fig:environments}b).
In \emph{block-rearrange}, all constraints are unsatisfied in the start state.
In \emph{robogym-rearrange}, four constraints are unsatisfied in the start state.
Our metric is the \emph{fractional success rate}, the average change in the number of satisfied constraints divided by the number of initially unsatisfied constraints.

The experiences buffer consists of 5000 trajectories showing 4 objects.
We evaluate on 4-7 objects for 100 episodes across 10 seeds.
Even if we assume full access to the underlying state space, the task spaces are enormous: with $|S|$ object locations and $k$ objects, the number of possible trajectories over object configurations of $t$ timesteps is ${|S| \choose k} \times (k \times (|S| - k))^t$, which amounts to searching over more than $10^{16}$ possible trajectories % 4.506193851207048 Ã— 10^16
for the complete specification setting of \emph{block-rearrange} with $k=7$ objects (see Appdx.~\ref{appdx:combinatorial_space} for derivation).
Our setting of assuming access to only pixels makes the problem even harder.

\textbf{Baselines.}
The claim of this paper are that, for object rearrangement, (1) object-centric methods fare better than monolithically-structured offline RL methods (2) non-parametric graph search fares better than parametric planning for object rearrangement and (3) a factorized graph search over state transitions of individual entities fares better than a non-factorized graph search over state transitions over entire entity-sets.
To test (1), we compare with state-of-the-art pixel-based behavior cloning (BC) and implicit Q-learning (IQL) implementations based off of~\cite{jaxrl}.
To test (2), we compare against a version of object-centric model predictive control (MPC)~\citep{veerapaneni2020entity} that uses the cross entropy method over dSLATE rollouts.
To test (3), we compare against an ablation (abbrv. NF, for ``non-factorized'') that constructs a graph with state transitions of entity-sets than of individual states.
Our last baseline just takes random actions (Rand).
Baseline implementation details are in Appdx.~\ref{sec:baseline_implementation_details}.

\subsection{Results}
Figure~\ref{tab:quantiative_results} shows that~\methodname performs significantly better than all baselines (about a 5-10x improvement), thereby refuting the alternatives to our claims in our experimental context.
Most of the baselines perform no better or only slightly better than random.
We observe that it is indeed difficult to perform shooting-based planning with an entity-centric world model trained to predict a single step forward~\citep{janner2019trust}: the MPC baseline performs poorly because its rollouts are poor, and it is significantly more computationally expensive to run (11 hours instead of 20 minutes).
We also observe that the NF ablation performs poorly, showing the importance of factorizing the non-parametric graph search.
Additional results are in Appdx.~\ref{appdx:additional_results}, with limitations in Appdx.~\ref{appdx:limitations}

\begin{table}[!htb]
    \centering
    \small
    \caption{
    This table compares~\methodname with various baselines in the complete and partial evaluation settings of \emph{block-rearrange} and \emph{robogym-rearrange}.
    The methods were trained on 4 objects and evaluated on generalizing to 4, 5, 6, and 7 objects.
    We report the fractional success rate, with a standard error computed over 10 seeds.
    }
    \label{tab:quantiative_results}
    \begin{subtable}{.48\linewidth}
    \raggedleft
      \vspace{-5pt}
      \caption{
      \label{tab:block_rearrange_combinatorial_generalization}
      \emph{block-rearrange}, complete specification.}
      \vspace{-5pt}
        \resizebox{\textwidth}{!}{\begin{tabular}{ c c c c c } 
 Method & 4 & 5 & 6 & 7 \\
 \toprule
 \textbf{\methodname (ours)} & \textbf{0.94} \tiny{$\pm$ 0.01} & \textbf{0.93} \tiny{$\pm$ 0.00} & \textbf{0.93} \tiny{$\pm$ 0.00} & \textbf{0.89} \tiny{$\pm$ 0.00} \\
 Rand  & 0.06 \tiny{$\pm$ 0.02} & 0.07 \tiny{$\pm$ 0.03} & 0.07 \tiny{$\pm$ 0.03} & 0.08 \tiny{$\pm$ 0.03} \\
 MPC  & 0.16 \tiny{$\pm$ 0.06} & 0.12 \tiny{$\pm$ 0.04} & 0.11 \tiny{$\pm$ 0.04} & 0.10 \tiny{$\pm$ 0.03} \\
 NF  & 0.07 \tiny{$\pm$ 0.03} & 0.06 \tiny{$\pm$ 0.02} & 0.07 \tiny{$\pm$ 0.02} & 0.08 \tiny{$\pm$ 0.03} \\
 IQL   & 0.07 \tiny{$\pm$ 0.01}  &  0.03 \tiny{$\pm$ 0.00}  &  0.02 \tiny{$\pm$ 0.00}  &  0.02 \tiny{$\pm$ 0.00} \\ 
 BC  &  0.03 \tiny{$\pm$ 0.00}  &  0.02 \tiny{$\pm$ 0.00}  &  0.01 \tiny{$\pm$ 0.00}  &  0.01 \tiny{$\pm$ 0.00}  \\ 
\end{tabular}}
    \end{subtable}
    \quad
    \begin{subtable}{.48\linewidth}
      \raggedright
        \small
      \vspace{-5pt}
        \caption{\label{tab:block_stacking_combinatorial_generalization} \emph{block-rearrange}, complete specification.}
        \vspace{-5pt}
        \resizebox{\textwidth}{!}{\begin{tabular}{ c c c c c } 
 Method  & 4 & 5 & 6 & 7 \\
 \toprule
\textbf{\methodname (ours)} & \textbf{0.89} \tiny{$\pm$ 0.01} & \textbf{0.86} \tiny{$\pm$ 0.01} & \textbf{0.78} \tiny{$\pm$ 0.01} & \textbf{0.70} \tiny{$\pm$ 0.01} \\ 
Rand & 0.06 \tiny{$\pm$ 0.02} & 0.08 \tiny{$\pm$ 0.03} & 0.08 \tiny{$\pm$ 0.03} & 0.08 \tiny{$\pm$ 0.03} \\
MPC & 0.13 \tiny{$\pm$ 0.05} & 0.11 \tiny{$\pm$ 0.04} & 0.10 \tiny{$\pm$ 0.04} & 0.08 \tiny{$\pm$ 0.03} \\
NF & 0.06 \tiny{$\pm$ 0.03} & 0.07 \tiny{$\pm$ 0.03} & 0.08 \tiny{$\pm$ 0.03} & 0.07 \tiny{$\pm$ 0.03} \\
IQL & 0.01 \tiny{$\pm$ 0.01} & 0.07 \tiny{$\pm$ 0.01} & 0.05 \tiny{$\pm$ 0.01} & 0.05 \tiny{$\pm$ 0.00} \\ 
BC & 0.05 \tiny{$\pm$ 0.01} & 0.04 \tiny{$\pm$ 0.00} & 0.03 \tiny{$\pm$ 0.00} & 0.03 \tiny{$\pm$ 0.00} \\ 
\end{tabular}}
    \end{subtable}
\begin{subtable}{.48\linewidth}
    \raggedleft
     \vspace{5pt}
      \caption{\label{tab:robogym_rearrange_combinatorial_generalization}\emph{robogym-rearrange}, complete specification.}
      \vspace{-5pt}
        \resizebox{\textwidth}{!}{\begin{tabular}{ c c c c c } 
 Method  & 4 & 5 & 6 & 7 \\
 \toprule
 \textbf{\methodname (ours)} & \textbf{0.64} \tiny{$\pm$ 0.01} & \textbf{0.47} \tiny{$\pm$ 0.01} & \textbf{0.49} \tiny{$\pm$ 0.01} & \textbf{0.41} \tiny{$\pm$ 0.01} \\ 
 Rand  & 0.01 \tiny{$\pm$ 0.00} & 0.01 \tiny{$\pm$ 0.00} & 0.00 \tiny{$\pm$ 0.00} & 0.00 \tiny{$\pm$ 0.00} \\ 
 MPC  & 0.00 \tiny{$\pm$ 0.00} & 0.00 \tiny{$\pm$ 0.00} & 0.00 \tiny{$\pm$ 0.00} & 0.00 \tiny{$\pm$ 0.00} \\
 NF  & 0.01 \tiny{$\pm$ 0.00} & 0.01 \tiny{$\pm$ 0.00} & 0.00 \tiny{$\pm$ 0.00} & 0.00 \tiny{$\pm$ 0.00} \\ 
 IQL  & 0.00 \tiny{$\pm$ 0.00} & 0.00 \tiny{$\pm$ 0.00} & 0.00 \tiny{$\pm$ 0.00} & 0.00 \tiny{$\pm$ 0.00} \\ 
 BC & 0.00 \tiny{$\pm$ 0.00} & 0.00 \tiny{$\pm$ 0.00} & 0.00 \tiny{$\pm$ 0.00} & 0.00 \tiny{$\pm$ 0.00} \\ 
\end{tabular}}
    \end{subtable}
    \quad
    \begin{subtable}{.48\linewidth}
      \raggedright
        \small
     \vspace{5pt}
        \caption{\label{tab:block_stacking_combinatorial_generalization_partial} \emph{robogym-rearrange}, partial specification.}
        \vspace{-5pt}
        \resizebox{\textwidth}{!}{\begin{tabular}{ c c c c c } 
 Method  & 4 & 5 & 6 & 7 \\
 \toprule
\textbf{\methodname (ours)} & \textbf{0.47} \tiny{$\pm$ 0.01} & \textbf{0.33} \tiny{$\pm$ 0.01} & \textbf{0.27} \tiny{$\pm$ 0.01} & \textbf{0.22} \tiny{$\pm$ 0.01} \\ 
Rand & 0.005 \tiny{$\pm$ 0.001} & 0.001 \tiny{$\pm$ 0.00} & 0.002 \tiny{$\pm$ 0.001} & 0.001 \tiny{$\pm$ 0.00} \\ 
 MPC & 0.00 \tiny{$\pm$ 0.00} & 0.001 \tiny{$\pm $ 0.001} & 0.00 \tiny{$\pm$ 0.00} & 0.00 \tiny{$\pm$ 0.00} \\
 NF & 0.005 \tiny{$\pm$ 0.001} & 0.001 \tiny{$\pm$ 0.00} & 0.002 \tiny{$\pm$ 0.001} & 0.001 \tiny{$\pm$ 0.00} \\ 
 IQL & 0.00 \tiny{$\pm$ 0.00} & 0.00 \tiny{$\pm$ 0.00} & 0.00 \tiny{$\pm$ 0.00} & 0.00 \tiny{$\pm$ 0.00} \\ 
 BC & 0.00 \tiny{$\pm$ 0.00} & 0.00 \tiny{$\pm$ 0.00} & 0.00 \tiny{$\pm$ 0.00} & 0.00 \tiny{$\pm$ 0.00} \\ 
\end{tabular}}
    \end{subtable} 
    \vspace{-10pt}
\end{table}

\input{src/figs/robogym_tsne}

\subsection{Analysis}
Having quantitatively shown the relative strength of~\methodname in combinatorial generalization from pixels, we now examine how our key design choices of (1) factorizing entity representations into action-invariant and action-dependent features and (2) querying a state transition graph constructed from action-dependent features contribute to~\methodname's behavior and performance.
Is copying the entity type during latent prediction as dSLATE does sufficient for disentangling the location and appearance of objects into the state and type respectively?
Does dSLATE learn to sparsely modify only the entity that corresponds to the moved object in the sensorimotor transition, such that the nodes of the state transition graph meaningfully can be reused across entities?
These are nontrivial capabilities because~\methodname is self-supervised on only the experience buffer.

Fig.~\ref{fig:planning_and_control}b, which visualizes the \texttt{align}, \texttt{select-constraint}, and \texttt{bind} functions of~\methodname on \emph{robogym-rearrange}, suggests that, at least for the simplified setting we consider, the answer to both questions is yes.
\methodname has learned to represent different objects in different slots and construct a graph whose nodes capture location information.
Fig.~\ref{fig:robogym_tsne} shows a t-SNE~\citep{van2008visualizing} plot that clusters entities inferred from the \emph{robogym} environment.
Because we have not provided supervision on what states should represent, we observe there are multiple cluster indices that map onto similar groups of points.
This reveals that multiple different regions of $\mathcal{S}$ appear to be modeling similar states.
We also tried merging redundant clusters, but found that this did not improve quantitative performance.
