\begin{figure}
    \centering
    \vspace{-20pt}
    \includegraphics[width=\textwidth]{figs/model_large.pdf}
    \caption{\small{\textbf{Modeling}.
    \methodname constructs a two-level abstraction hierarchy to model transitions in the experience buffer.
    (a) \textbf{Level 1:}~\methodname learns to infer a set of entities from sensorimotor transitions with pick-and-move actions, in which one entity is moved per transition.
    We enforce that the type $z$ (shown with solid colors) of an entity remains unchanged between time-steps.
    The GPT dynamics model learns to sparsely predict the states $s$ (shown with textures) of the entities at the next time-step.
    \emph{This addresses the correspondence problem by forcing the network to use predict and reconstruct observations through the entity bottleneck.}
    (b) \textbf{Level 2:}~\methodname abstracts transitions over entity-sets into transitions over states of individual entities, constructing a graph where states are nodes and transitions between them are edges.
    This is done by clustering entity transitions that share similar initial states and final states.
    \emph{This addresses the combinatorial problem by making it possible for state transitions to reused for different entity types and with different context entities.
    }
    }}
    \label{fig:model}
    \vspace{-10pt}
\end{figure}