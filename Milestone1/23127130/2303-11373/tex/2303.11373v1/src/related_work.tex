\section{Related Work}
The problem of discovering re-composable representations is generally motivated by combinatorial task spaces.
The traditional approach to enforcing this compositional inductive bias is to compactly represent the task space with MDPs that human-defined abstractions of entities, such as factored MDPs~\citep{Boutilier_exploiting,Boutilier_factored,guestrin2003factored}, relational MDPs~\citep{wang2008relational,guestrin2003generalizing,gardiol_envelope-based_2003}, and object-oriented MDPs~\citep{Diuk_object,AbelHBBOMT15}.
Approaches building off of such symbolic abstractions~\citep{chang2016compositional,battaglia2018relational,zadaianchuk2022self,bapst2019structured,zhang2018composable} do not address the problem of how such entity abstractions arise from raw data.
Our work is one of the first to learn compact representations of combinatorial task spaces directly from raw sensorimotor data.

Recent object-centric methods~\citep{greff2017neural,van2018relational,greff2019multi,greff2020binding,locatello2020object,kipf2021conditional,zoran2021parts,singh2021illiterate} do learn entity representations, as well as their transformations~\citep{alias2021neural,goyal2020object}, from sensorimotor data, but only do so for modeling images and video, rather than for taking actions.
Instead, we study \emph{how well entity-representations can reused for solving tasks}.
\citet{kulkarni2019unsupervised} considers how object representations improve exploration, but we consider the offline setting which requires zero-shot generalization.
\citet{veerapaneni2020entity} also considers control tasks, but their shooting-based planning method suffers from compounding errors as other learned single-step models do~\citep{janner2019trust}, while our hierarchical non-parametric approach enables us to plan for longer horizons.

Non-parametric approaches have recently become popular for long horizon planning~\citep{yang2020plan2vec,zhang2018composable,lippi2020latent,emmons2020sparse,zhang2021worldmodel}, but the drawback of these approaches is they represent the entire scenes monolithically, which causes a blowup of nodes in combinatorial task spaces, making it infeasible for these methods to be applied in rearrangement tasks that require generalizing to novel object configurations with different numbers of objects.
Similar to our work, \citet{huang2019neural} also tackles rearrangement problems by searching over a constructed latent task graph, but they require a demonstration during deployment time, whereas~\methodname does not because it reuses context-agnostic state transitions that were constructed during training.
\cite{zhang2021worldmodel} conducts non-parametric planning directly on abstract subgoals rather than object-centric states --- while similar, the downside of using subgoals rather than abstract states is that those subgoals are not used to represent equivalent states and therefore cannot generalize to new states at test time. Our method, NCS, captures both reachability between known states and new, unseen states that can be mapped to the same abstract state.