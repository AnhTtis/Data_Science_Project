\section{Goal-Conditioned Reinforcement Learning with Entities} \label{sec:problem}
This section introduces a set of modifications to the standard goal-conditioned partially observed Markov decision process (POMDP) problem formulation that explicitly expose the combinatorial structure of object rearrangement tasks of the following kind: ``Sequentially move a subset (or all) of the objects depicted in the current observation $o_1$ to satisfy the constraints depicted in the goal image $o_g$.''
We assume an offline RL setting, where the agent is trained on a buffer of transitions $\{(o_1, a_1, ... a_{T-1}, o_T)\}_{n=1}^N$ and evaluated on tasks specified as $(o_1, o_g)$.

The standard POMDP problem formulation assumes an observation space $\mathcal{O}$, action space $\mathcal{A}$, latent space $\mathcal{H}$, goal space $\mathcal{G}$, observation function  $E: \mathcal{H} \rightarrow \mathcal{O}$, transition function $P: \mathcal{H} \times \mathcal{A} \rightarrow \mathcal{H}$, and reward function  $R: \mathcal{H} \times \mathcal{G} \rightarrow \mathbb{R}$.
Monolithically modeling the latent space this way does not expose commonalities among different scenes, such as scenes that contain objects in the same location or scenes with multiple instances of the same type of object.
This prevents us from designing control algorithms that exploit these commonalities to collapse the combinatorial task space.

\input{src/figs/problem}
To overcome this issue, we introduce structural assumptions of independence, symmetry, and factorization to the standard formulation. 
The \emph{independence} assumption encodes the intuitive property that objects can be acted upon without affecting other objects.
This is implemented by decomposing the latent space into independent subspaces as $\mathcal{H} = \mathcal{H}^1 \times ... \times \mathcal{H}^K$, one for each independent degree of freedom (e.g. object) in the scene.
The \emph{symmetry} assumption encodes the property that the the same physical laws apply to all objects.
This is implemented by constraining the observation, transition, and reward functions to be shared across all subspaces, thereby treating $\mathcal{H}^1 = ... = \mathcal{H}^K$.
We define an \textbf{entity}\footnote{We use ``object'' to refer to an independent degree of freedom in the environment, and ``entity'' to refer to the agent's representation of the object.} $h \in \mathcal{H}^k$ as a member of such a subspace, and an \textbf{entity-set} as the set of entities $\mathbf{h} = (h^1, ..., h^K)$ that explain an observation, similar to~\citet{Diuk_object,weld_solving_nodate}.
Lastly, the \emph{factorization} assumption encodes that each subspace can be decomposed as $\mathcal{H}^k = \mathcal{Z} \times \mathcal{S}$, where $z \in \mathcal{Z}$ represents an entity's action-invariant features like appearance, and $s \in \mathcal{S}$ represents its action-dependent features like location.
We call $z$ the \textbf{type} and $s$ the \textbf{state}.

Introducing these assumptions solves the problem of modeling the commonalities among different scenes stated above.
It allows us to describe scenes that contain objects in the same location by assigning entities in different scenes to share the same state $s$.
It allows us to describe a scene with multiple instances of the same type of object by assigning multiple entities in the scene to share the same type $z$.
This formulation also makes it natural to express goals as a set of constraints $\mathbf{h}_g = (h^1_g, ..., h^k_g)$. 
To solve a task is to take actions that transform the subset of entities in the initial observation $o_1$ whose types are given by $\mathbf{z}_g$ to new states specified by $\mathbf{s}_g$.

Exposing this structure in our problem formulation gives us a language for designing methods that represent entities in an independent, symmetric, and factorized way and that use these three properties to collapse the combinatorial task space.
These methods need to solve two problems: the \textbf{correspondence problem} of learning to represent entities in this way and the \textbf{combinatorial problem} of using these properties to make planning tractable.
The correspondence problem is hard because it assumes no human supervision of what the entities are.
It also goes beyond problems solved by existing object-centric methods for images and videos
because it involves action: it requires representing entities such that there is a correspondence between how the agent models how its actions affect entities and how its actions actually affect objects in the environment.
The combinatorial problem goes beyond problems solved by methods for solving 
object-oriented MDPs,
relational MDPs,
and factorized MDPs
because it requires the agent to recognize whether and how previously observed state transitions can be used for new problems, using learned, rather than human-defined, entity representations.
The natural evaluation criterion for both problems is to test to what extent an agent can zero-shot-generalize to solve rearrangement tasks involving new sets of object configurations that aree disjoint from the configurations observed in training, assuming that the training configurations have collectively covered $\mathcal{Z}$ and $\mathcal{S}$.
Our experiments in \S\ref{sec:experiments} test exactly this. 

\paragraph{Simplifying assumptions}
To focus on the combinatorial nature of rearrangement, we are not interested in low-level manipulation, so we represent each action as $(w, \Delta w)$, where $w$ are  Cartesian coordinates $w = (x, y, z)$.
We assume actions sparsely affect one entity at a time and how an action affects an object's state does not depend on its identity.
We are not interested in handling occlusion, so we assume that objects are constrained to the $xy$ plane or $xz$ plane and are directly visible to the camera.
Following prior work~\citep{hansen2022bisimulation,castro2009equivalence}, we make a \emph{bisimulation} assumption that the state space can be partitioned into a finite set of equivalence classes, and that there is one action primitive that transitions between each pair of equivalence classes.
Lastly, we assume objects can be moved independently.
Preliminary experiments suggest that~\methodname can be augmented to support tasks like block-stacking that involve dependencies among objects, but how to handle these dependencies would warrant a standalone treatment in future work.