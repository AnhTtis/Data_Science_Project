% We join a line of benchmarks that introduce a test set without predefined train splits \citep{thrush2022winoground,rudinger2018gender,emelin-sennrich-2021-wino}, \citep{Bitton2022WinoGAViLGA}. 
We train a supervised model for figurative classification of idioms. We add a binary classifier on top of pre-trained embeddings to classify whether a given image is figurative. We use CLIP (VIT-B/32) model, concatenating the textual idiom embedding to the visual image embedding, followed by a classifier that produces a matching score. A  score above $0.5$ is labeled ‘‘Figurative’’. We use the Adam optimizer \citep{Kingma2014} with a learning rate of $0.001$, batch size of $12$, and train for $7$ epochs. We run the fine-tuned model on the multimodal figurative language detection (\S\ref{sec:understanding_task}) task using the model's matching score. We train the binary classifier on $4790$ images, making sure the training data does not contain any of the images or idioms that appear in the task. We repeat five experiments with different random seeds for each task and take the mean score and std. 

%Unlike understanding idioms, that requires language and cultural knowledge, metaphors and similes require abstraction and mapping between domains \citep{mitchell2021abstraction}. %It should be able to solve unseen cases without extensive training . Given these distinct requirements,
%Thus, supervised experiments on metaphors and similes are outside the scope of this paper, and we leave it to future work.

%We believe that in order to understand metaphors and similes, a machine must be able to abstract and map between domains. It should be able to solve unseen cases without extensive training \citep{mitchell2021abstraction}. Contrary to metaphors and similes, understanding idioms requires language and cultural knowledge that can be learned through extensive training. 