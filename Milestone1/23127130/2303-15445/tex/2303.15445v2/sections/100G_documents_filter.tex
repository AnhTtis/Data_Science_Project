In an effort to minimize the number of images dominated by text, we filtered out images containing more than a few words, which accounted for $15\%$ of the total. Despite this, certain images like documents, books, and contracts managed to bypass our OCR-based filters, representing $2\%$ of the total images. To address this issue, we developed a filter using the ViLT model \citep{kim2021vilt}. This filter calculates an image's matching score with the prompts "a document", "a page of a book", or "a contract" and removes it if the total score surpasses a set "document" threshold. To find this threshold, we conducted a grid search on $20$ sampled images at each point in the distribution of $-30,-25,-20,-15,-10,-5,0,5,10,15,20,25\\,30$ categorizing each as a "document" or "non-document". The $(20, 15)$ range showed the best results, so we conducted a more dense grid search within this range and found the best threshold to be $18.77$ with a TPR of $100\%$ and an FPR of $1\%$.