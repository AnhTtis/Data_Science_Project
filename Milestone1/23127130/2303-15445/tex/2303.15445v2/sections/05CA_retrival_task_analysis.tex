Zero-shot results are presented in Table \ref{tab:ranking-task}. We evaluate all figurative phrases that have both Figurative and Partial Literal images.
\input{tables/ranking_task_results.tex}
Models' scores on the preference task are low (<$61\%$). We expect models with proper figurative preference to achieve better results. Models' success in the Figurative+Literal category can be attributed to the literal connections of the Figurative+Literal images.

The supervised model achieved a score of $68\pm3.8$ in the Figurative category, almost double the zero-shot score of CLIP-ViT-B/32 ($36$). Additionally, the score in the Figurative+Literal category was improved by $10\pm2.25$ points. These results align well with the observation that the multimodal figurative language detection task supervised model, which was trained using the same method on a different training set, also showed substantially moderate literal preference. Table~\ref{tab:preference_task_supervision} shows the fine-tuned model results. 
\input{tables/preference_task_supervision.tex}
