We evaluate humans and state-of-the-art image recognition models ability to understand figurative language (Section \ref{sec:understanding_task}). We show that IRFL tasks are easy for humans (97\% accuracy) and challenging for models (<27\%). Additionally, we provide a detailed analysis per figure of speech, experiments with idioms and their definitions as input, and with different candidate types. We find that models fail the IRFL task due to their preference for partially literal images over figurative images and introduce a preference task to tackle this problem (Section \ref{sec:ranking Task Analysis}). In addition, we examine the ability of generative models such as Dall-E and Stable Diffusion to generate figurative images for idioms (Section \ref{sec:genearive_models_analysis}). We find that they are unable to generate figurative images given idiomatic phrases. Given the definitions of an idiom, generative models can generate figurative images.

%\yonatan{missing more experiments (What we've discussed from the ``Why is Winoground hard paper'') - Iterate each one of the chapters we discussed and see if you can repeat the experiments in this study}\ron{we can do it only with metaphors and similes, it will not work with idioms. I am in favor on adding it to the next version}