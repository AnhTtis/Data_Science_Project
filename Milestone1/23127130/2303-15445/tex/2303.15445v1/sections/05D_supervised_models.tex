We join a line of benchmarks that introduce a test set without predefined train splits \cite{thrush2022winoground,rudinger2018gender,emelin-sennrich-2021-wino}, \cite{Bitton2022WinoGAViLGA}. We believe that in order to understand metaphors and similes, a machine must be able to abstract and map between domains. It should be able to solve unseen cases without extensive training \cite{mitchell2021abstraction}. Contrary to metaphors and similes, understanding idioms requires language and cultural knowledge that can be learned through extensive training. We train a supervised model for figurative classification of idioms. We add a binary classifier on top of the pre-trained embeddings to classify whether a given image is figurative or not. We use CLIP (VIT-B/32) model, concatenate the textual idiom embedding to the visual image embedding, followed by a classifier that produces a matching score, where a matching score above 0.5 is labeled ‘Figurative’. We use the Adam optimizer \cite{Kingma2014} with a learning rate of 0.001, batch size of 12, and train for 7 epochs. We run the fine-tuned model on the understanding and preference task using the model's matching score. We train the binary classifier on 4790 images for the understanding task and 3802 images for the preference task\footnote{Training data does not contain any of the images or idioms that appear in the task.}. We repeat five experiments with different random seeds for each task and take the mean score along with the standard deviation. 
