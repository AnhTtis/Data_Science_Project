\section{Introduction}
The objective of semantic segmentation is to predict a label for every single pixel of an input image \cite{long2015fully}.
%
Conditioning on each pixel's observation, existing segmentation methods
\cite{chen2017rethinking,zheng2021rethinking,xie2021segformer, cheng2021per} naturally adopt the {\em discriminative learning} paradigm, along with dedicated efforts on integrating task prior knowledge (\eg{}, spatial correlation)
\cite{zheng2021rethinking,cheng2021per, ji2021fsnet,wanseaformer}.
%
For example, existing methods
\cite{chen2017rethinking,zheng2021rethinking,xie2021segformer} typically use a linear projection to optimize the log-likelihood classification for each pixel.
Despite the claim of subverting per-pixel classification, the bipartite matching-based semantic segmentation~\cite{cheng2021per,cheng2022masked} still 
cannot avoid the per-pixel max log-likelihood.

\input{figures/intro}
In this paper, we introduce a new approach, {\bf\em Generative Semantic Segmentation} (GSS), that formulates semantic segmentation as {\em an image-conditioned mask generation problem}.
%
This conceptually differs from the conventional formulation of discriminative per-pixel classification learning, based on the log-likelihood of a conditional probability
(\ie\ the classification probability of image pixels).
%
%
Taking the manner of image generation instead~\cite{kingma2013auto, van2017neural}, 
we generate the {\em whole} segmentation masks
with {\em an auxiliary latent variable distribution} introduced.
%
This formulation is not only simple and more task-agnostic,
but also facilitates the exploitation of off-the-shelf big generative models 
(\eg\ DALL$\cdot$E~\cite{ramesh2021zero} trained by 3 billion iterations on a 300 million open-image dataset, far beyond both the data scale and training cost of semantic segmentation).

However, achieving segmentation segmentation in a generic generation framework (\eg{} the Transformer architecture \cite{esser2021taming}) is non-trivial due to drastically different data format.
To address this obstacle, 
we propose a notion of \texttt{maskige} that expresses 
the segmentation mask in the RGB image form.
%
This enables the use of a pretrained latent posterior distribution (\eg\ VQVAE~\cite{van2017neural}) of existing generative models.
%
Our model takes a two-stage optimization: 
{\bf(i)} Learning the posterior distribution of the latent variables conditioned on the semantic segmentation masks so that the latent variables can simulate the target segmentation masks;
To achieve this, we introduce an fixed pre-trained VQVAE from~\cite{ramesh2021zero} and a couple of lightweight transformation modules, which can be trained with minimal cost, or they can be manually set up without requiring any additional training. 
In either case, the process is efficient and does not add significant overhead to the overall optimization.
{\bf(ii)} Minimizing the distance between the posterior distribution and the prior distribution of the latent variables given input training images and their masks, enabling to condition the generation of semantic masks on the input images.
%
This can be realized by a generic encoder-decoder style architecture (\eg\ a Transformer).

We summarize the {\em contributions} as follows. 
\textbf{(i)} We propose a {\bf\em Generative Semantic Segmentation} approach that reformulates semantic segmentation as an image-conditioned mask generation problem.
%
This represents a {\em conceptual shift} from conventional discriminative learning based paradigm.
%
\textbf{(ii)}
We realize a \model{} model in an established conditional image generation framework,
with minimal need for task-specific architecture and loss function modifications 
while fully leveraging the knowledge of off-the-shelf generative models.
\textbf{(iii)}
Extensive experiments on several semantic segmentation benchmarks
show that our \model{} is competitive with prior art models in the standard setting, whilst achieving a new state of the art 
in the more challenging and practical cross-domain setting (\eg\ MSeg \cite{lambert2020mseg}).