\begin{table}[tb]
\tablestyle{1.8pt}{1.1}
\renewcommand\tabcolsep{7.1pt}
\renewcommand\arraystretch{1.2}
\begin{tabular}{x{44}x{14}x{44}x{30}|c}
\hline

\hline

\hline

\hline
Method & Pretrain & Backbone & Iteration&mIoU \\
\shline
\multicolumn{4}{l}{\emph{- Discriminative modeling:}} \\
\shline
\multicolumn{1}{l}{FCN~\cite{long2015fully}} & 1K & ResNet-101 & {80k} &{77.02}\\ 
\multicolumn{1}{l}{PSPNet~\cite{zhao2017pyramid}} & 1K& ResNet-101 &{80k}  & {79.77}\\
\multicolumn{1}{l}{DeepLab-v3+~\cite{chen2018encoder}}& 1K & ResNet-101 &{80k} & {80.65}\\

\multicolumn{1}{l}{NonLocal~\cite{wang2018nonlocal}} & 1K& ResNet-101 &{80k} & {79.40}\\
\multicolumn{1}{l}{CCNet~\cite{huang2019ccnet}}& 1K & ResNet-101 &{80k} &{79.45} \\
% \multicolumn{1}{l}{GCNet~\cite{cao2019gcnet}} & 1K& ResNet-101 &{80k} & {} \\
\multicolumn{1}{l}{Maskformer~\cite{cheng2021per}} & 1K& ResNet-101 & {90k} & {78.50} \\ % resnet-101 miou 78.5, resnet-101-c miou 79.70
\multicolumn{1}{l}{Mask2former~\cite{cheng2022masked}} & 1K& ResNet-101 & {90k} & {80.10} \\ 
\multicolumn{1}{l}{SETR~\cite{zheng2021rethinking}} & 22K& ViT-Large & {80k} & {78.10} \\
\multicolumn{1}{l}{UperNet~\cite{xiao2018unified}}& 22K & Swin-Large & {80k}  & {82.89}\\ % 81.0
\multicolumn{1}{l}{Maskformer~\cite{cheng2021per}}& 22K & Swin-Large & {90k}  & {78.50}\\
\multicolumn{1}{l}{Mask2former~\cite{cheng2022masked}}& 22K & Swin-Large & {90k}  & \textbf{83.30}\\
\multicolumn{1}{l}{SegFormer~\cite{xie2021segformer}} & 1K& MiT-B5 & {160k} & {82.25} \\
\shline
\multicolumn{3}{l}{\emph{- Generative modeling:}} \\
\shline
\multicolumn{1}{l}{UViM$^\dag$~\cite{kolesnikov2022uvim}}& 22K & Swin-Large & 160k &70.77 \\
\rowcolor[gray]{.9}
\multicolumn{1}{l}{\model-\gssb{}~(Ours)} & 1K & ResNet-101 & 80k & {77.76} \\
\rowcolor[gray]{.9}
\multicolumn{1}{l}{\model-\gssc{}-W~(Ours)}& 1K & ResNet-101 & 80k & {78.46} \\
\rowcolor[gray]{.9}
\multicolumn{1}{l}{\model-\gssb{}~(Ours)} & 22K& Swin-Large & 80k & {78.90} \\
\rowcolor[gray]{.9}
\multicolumn{1}{l}{\model-\gssc{}-W~(Ours)}& 22K & Swin-Large & 80k & \textbf{80.05}\\

\hline

\hline

\hline

\hline
\end{tabular}
\vspace{-0.5em}
\caption{\textbf{Performance comparison on the Cityscapes {\tt val} split:} UViM$^\dag$~\cite{kolesnikov2022uvim} is reproduced by us on PyTorch. ``1K" means pretrained on ImageNet 1K~\cite{deng2009imagenet} while ``22K" means pretrained on ImageNet 22K~\cite{deng2009imagenet}.}
\label{tab:cityscapes_val}
\vspace{-0.5em}
\end{table}