



\documentclass[10pt,twocolumn,letterpaper]{article}



\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{stfloats}
\usepackage{cite}
\usepackage{color}
\usepackage{times}
\usepackage{overpic}
\usepackage{bm}
\usepackage{tabu}
\usepackage{bbding}
\usepackage{multicol}

\usepackage{diagbox}
\usepackage{multirow}
\usepackage{scalerel,stackengine}
\usepackage[table ]{xcolor}
\usepackage[accsupp]{axessibility}
\newcommand{\PAR}[1]{\vskip3pt \noindent {{\bf #1~}}}
\newcommand{\TITLE}{SLOPER4D}
\newcommand{\framevideo}{300k~}
\newcommand{\framelidar}{100k~}
\newcommand{\framemocap}{500k~}
\newcommand{\numberscene}{10~}
\newcommand{\numberseq}{15~}
\newcommand{\numberperson}{12~}










\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}

\def\cvprPaperID{5047} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2023}


\begin{document}

\title{SLOPER4D: A Scene-Aware Dataset for Global 4D Human Pose Estimation in Urban Environments

}

\author{Yudi~Dai\textsuperscript{1}
\and Yitai~Lin\textsuperscript{1}
\and Xiping~Lin\textsuperscript{1}
\and Chenglu~Wen\textsuperscript{1}\thanks{Corresponding author.}
\and Lan~Xu\textsuperscript{2}
\and Hongwei~Yi\textsuperscript{3} 
\and Siqi~Shen\textsuperscript{1} 
\and Yuexin~Ma\textsuperscript{2}
\and Cheng~Wang\textsuperscript{1}
\and $^{1}$Xiamen University, China 
\hspace{20mm}$^{2}$ShanghaiTech University, China
\and
$^{3}$Max Planck Institute for Intelligent Systems, Germany
} 
















\makeatletter
\let\@oldmaketitle\@maketitle% Store \@maketitle
\renewcommand{\@maketitle}{
   \@oldmaketitle% Update \@maketitle to insert...
	\begin{center}
      \vspace{-6mm}
      \includegraphics[width=0.96\linewidth]{figures/teaser.pdf}
	\end{center}
   \vspace{-2mm}

  \refstepcounter{figure}\normalfont Figure~\thefigure. 
  Using the head-mounted LiDAR and camera to scan the IMUs wearer, we construct \TITLE, a large scene-aware dataset for global 4D human pose estimation in urban environments, including LiDAR point clouds, the RGB videos with 2D/3D annotations, accurate global human pose annotations, and the reconstructed scene.
  \label{fig:teaser}
  \newline
  }

\makeatother

\maketitle

\begin{abstract}













   We present SLOPER4D, a novel scene-aware dataset collected in large urban environments to facilitate the research of global human pose estimation (GHPE) with human-scene interaction in the wild. Employing a head-mounted device integrated with a LiDAR and camera, we record 12 human subjects' activities over 10 diverse urban scenes from an egocentric view. Frame-wise annotations for 2D key points, 3D pose parameters, and global translations are provided, together with reconstructed scene point clouds. To obtain accurate 3D ground truth in such large dynamic scenes, we propose a joint optimization method to fit local SMPL meshes to the scene and fine-tune the camera calibration during dynamic motions frame by frame, resulting in plausible and scene-natural 3D human poses. Eventually, SLOPER4D consists of 15 sequences of human motions, each of which has a trajectory length of more than 200 meters (up to 1,300 meters) and covers an area of more than 2,000 $m^2$ (up to 13,000 $m^2$), including more than 100K LiDAR frames, 300k video frames, and 500K IMU-based motion frames. With SLOPER4D, we provide a detailed and thorough analysis of two critical tasks, including camera-based 3D HPE and LiDAR-based 3D HPE in urban environments, and benchmark a new task, GHPE. The in-depth analysis demonstrates SLOPER4D poses significant challenges to existing methods and produces great research opportunities. The dataset and code are released at \url{http://www.lidarhumanmotion.net/sloper4d/}.
\end{abstract}

\vspace{-2ex}

\section{Introduction}
\label{sec:intro}
\input{sections/introduction.tex}

\section{Related Work}
\label{sec:Related work}
\input{sections/relatedwork.tex}

\section{\TITLE~Dataset}
\label{sec:dataset_constructing}
\input{sections/dataset_constructing.tex}

\input{sections/dataset.tex}


\section{Experiments}
\label{sec:experiments}
\input{sections/experiments.tex}

\input{sections/dataset_valid.tex}


\section{Discussions}
\label{sec:discussion}
\input{sections/conclutions}

{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}


\end{document}