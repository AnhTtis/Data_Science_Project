To obtain precise and scene-plausible human motion $M$ in the world coordinate system, we use scene geometry \bm{${S}$} with several physic-based terms to perform joint optimizations to find the optimal motion $M^*$ that minimize $\mathcal{L}$. 
In a k-frame segment, the optimization is written as:
\vspace{-1mm}
\begin{equation}
	\begin{split}   
    & M^*_{1:k} = 
    \arg \min _{M_{1:k}}\mathcal{L} (M_{1:k}, \bm{S}),\\
    & \mathcal{L}_{} = 
        {\mathcal{L}}_{smt} + 
        \lambda_{sc}\mathcal{L}_{sc} + 
        {\lambda_{pri}\mathcal{L}}_{pri}+
        {\lambda_{m2p}\mathcal{L}}_{m2p}, \\
    & \mathcal{L}_{smt} = 
        \lambda_{trans} \mathcal{L}_{trans} + 
        \lambda_{orit} \mathcal{L}_{orit} + 
        \lambda_{jts} \mathcal{L}_{jts},
    \end{split}
\end{equation}

\noindent where $\mathcal{L}_{smt}$ is a smoothness term, which consists of a translation loss $\mathcal{L}_{trans}$, an orientation loss $\mathcal{L}_{orit}$, and a joints loss $\mathcal{L}_{jts}$.
$\mathcal{L}_{sc}$ is a scene-aware-contact term,
$\mathcal{L}_{pri}$ is a pose prior term, 
and $\mathcal{L}_{m2p}$ is a mesh-to-points term. 
The $\lambda_{sc}$, $\lambda_{pri}$, $\lambda_{trans}$, $\lambda_{orit}$, $\lambda_{jts}$, and $\lambda_{m2p}$ are loss terms' coefficients. $\mathcal{L}$ is minimized with a gradient descent algorithm.

\PAR{Smoothness term.} The objective of this term is to minimize the acceleration of the pelvis joint, the accelerations of the other 23 pelvis-relative joints, which is denoted as $J_{1:k} = \{\jmath_{1},\ldots, \jmath_{k}\} \in \mathbb{R}^{69 \times k}$, and the angular velocity of all joints to smooth human movements. 

\PAR{Scene-aware contact term.} we compare the movement of every foot vertices in IMU motions ${M}_k^I$ and label the foot as stable if its velocity is less than 0.1 $m/s^2$. Finally, the Chamfer Distance (CD) between this foot and its closest surface is expressed as the scene contact loss $\mathcal{L}_{sc}$.

\PAR{Pose prior term.} The poses estimated by IMUs are roughly accurate but will likely cause some misalignments to the end of the body limb due to the accumulating error.
Hence, $\mathcal{L}_{prior}$ is used to constrain the $\Theta$ close to the initial value at the beginning of the optimization. 

\PAR{Mesh-to-points term.}
The point cloud $p^L$ from the moving LiDAR provides strong prior depth information. However, though the SMPL mesh is watertight and complete, the human points are sparse and partial, which makes the registration methods such as ICP, not ideal as expected.
To address this issue, we propose a viewpoint-based mesh-to-point loss function $\mathcal{L}_{m2p}$. First, we remove the hidden SMPL mesh faces from the LiDAR's viewpoint. Then we sample points, denoted as $P'\,\!_{1:k} = \{p'\,\!_{1},\ldots, p'\,\!_{k}\}$, from the remaining faces by LiDAR resolution. The loss is defined as the Chamfer Distance from $P'\,\!_{1:k}$ to $P_{1:k}$. 

All loss terms functions are detailed as follows:

\vspace{-4mm}
\begin{equation}
	\begin{split} 
        & \mathcal{L}_{trans} = 
        \frac{1}{k-2}\sum_{i=1}^{k-2}\|t_{i+2} - 2t_{i+1} + t_{i}\|_2^2,\\ 
        & \mathcal{L}_{jts} = 
        \frac{1}{k-2} \sum_{i=1}^{k-2}\|{\jmath}_{i+2} - 2{\jmath}_{i+1} + {\jmath}_{i}\|_2^2,\\ 
        & \mathcal{L}_{\text {orit}} = 
        \frac{1}{k-1}\sum_{i=1}^{k-1} 
        \|r_{i+1} - r_{i}\|_{2}^2, \\
        & \mathcal{L}_{\text {pri}} = 
        \frac{1}{k}\sum_{i=1}^{k} 
        \|\theta_{i} - R^{WI}\theta_{i}^{I}\|_{2}^2, \\
        & \mathcal{L}_{m2p} = 
        \frac{1}{k}\sum_{j=1}^{k} 
        (\frac{1}{|p'\,\!_{i}|}\sum_{\hat{p'\,\!}\in p'\,\!_{i}}\min_{\hat{p} \in p_{i}}\|\hat{p} - \hat{p'\,\!}\|_{2}^{2}).
    \end{split}
    \vspace{-4mm}
\end{equation}

\PAR{Camera extrinsic optimization.}
We aim to optimize extrinsic parameters $K_{ex}$ for every frame by minimizing the $\mathcal{L}_{cam}$, which comprises of the keypoints loss $\mathcal{L}_{kpt}$ and the bounding box loss $\mathcal{L}_{box}$. 
The $\mathcal{L}_{kpt}$ measures the mean square error (MSE) between the 2D human keypoints $kpt^{2d}$ in the image and the 3D human keypoints $kpt^{3d}$ of the optimized SMPL model projected to the image with $K_{ex}$; 
the $\mathcal{L}_{box}$ computes the Intersection over Union(IoU) loss between the 2D human bounding box $box^{2d}$ in the image and the 3D human bounding box $box^{3d}$ projected to the image with $K_{ex}$. 

\vspace{-4mm}
\begin{equation}
	\begin{split}   
    K_{ex}^* = &
    \arg \min _{K_{ex} \in SE(3)} \mathcal{L}_{cam}(K_{ex}), \\
    \mathcal{L}_{cam} = &
    \lambda_{kpt} \mathcal{L}_{kpt}(kpt^{3d}, kpt^{2d}, K_{ex}) + \\
    & \lambda_{box} \mathcal{L}_{box}(box^{3d}, box^{2d}, K_{ex}), \\
    \end{split}
    \vspace{-2mm}
\end{equation}
\noindent where $\lambda_{kpt}$ and $\lambda_{box}$ are constant coefficients. 
