\section{Conclusion}
\label{sec:conclusion}
We have implemented, PFSL, by incorporating transfer learning with lightweight personalization and work fairness while ensuring privacy for both input data and labels. Our extensive empirical studies have demonstrated that it is computationally efficient for thin clients and outperforms FL-TL and current 2-stage SL variants in accuracy and fairness metrics. We have shown the advantages of personalization for split learning for clients with non-i.i.d. data distributions. Our fair work balance constraint doesn't add any additional burden on clients with the larger quantum of data while achieving performance gains. Our work suggests several interesting directions for future study including proving PFSL's convergence and privacy guarantees theoretically, studying its performance under adversarial attacks, hardware implementation and further optimization of resource consumption overheads.