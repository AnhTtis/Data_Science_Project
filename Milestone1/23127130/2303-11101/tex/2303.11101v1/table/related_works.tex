\begin{table*}[!t]
    \small
    \centering
    \addtolength{\tabcolsep}{-0.7pt}
    \resizebox{1.0\textwidth}{!}{
    \begin{tabular}{l|l|c|c|c|c|l}
        \toprule
         &  & Train & Train & & & \\
         \multirow{-2}{*}{Task [ref.]} & \multirow{-2}{*}{Problem Setting} & \!\!\!(Labeled)\!\!\! & \!\!\!(Unlabeled)\!\!\! & \multirow{-2}{*}{Test} & \multirow{-2}{*}{\!\!\!\!\!\!\!\!\!\!\!\!Definition of \texttt{OS}\,/\,\texttt{CS} \hfill} & \multirow{-2}{*}{Main Goal}  \\
         \midrule \midrule
         \thead[l]{Novel Class Discovery\\\cite{hsu2017learning, han2020automatically, zhong2021openmix}} & \thead[l]{test data consist of\\only novel classes} & \thead{seen} & - & \thead{novel} & - & \thead[l]{cluster novel classes\\in test dataset} \\
         \hline
         \thead[l]{Open-Set Recognition\\\cite{scheirer2012toward, bendale2016towards, chen2021adversarial, vaze2021open}} & \thead[l]{test set contains seen\\and novel classes} & \thead{seen} & - & \thead{\!seen\,+\!\\novel} & \thead[l]{[\texttt{OS}] test dataset containing\\seen and novel classes} & \thead[l]{reject instances from\\novel classes at test time} \\
         \hline
         \thead[l]{Webly Sup.\\\cite{chen2015webly, li2020mopro, sun2021webly}} & \thead[l]{train data contains web-\\crawled noisy samples} & \thead{partially\\noisy} & - & \thead{seen} & \thead[l]{[\texttt{OS}] web-crawled train dataset\\containing noisy samples} & \thead[l]{robustly train instances\\with corrupted labels} \\
         \hline
         \thead[l]{Open-Set Semi-Sup. \\\cite{saito2021openmatch, oliver2018realistic, chen2020semi, killamsetty2021retrieve, su2021realistic}} & \thead[l]{unlabeled train data\\contain novel classes} & \thead{seen} & \thead{seen\,+\\novel} & \thead{seen} & \thead[l]{[\texttt{OS}] training dataset contain-\\ing seen and novel classes} & \thead[l]{train a robust model while\\regularizing novel classes} \\
         \hline
         \thead[l]{Open-World Semi-Sup. \\\cite{cao2021open, boult2019learning, bendale2015towards}} & \thead[l]{train and test data\\contain novel classes} & \thead{seen} & \thead{seen\,+\\novel} & \thead{\!seen\,+\!\\novel} & \thead[l]{[\texttt{OS}] dataset containing\\seen and novel classes}& \thead[l]{discover novel classes and\\assign samples at test time} \\
         \hline
         \thead[l]{Open-Set Annotation\\\cite{ning2022active}} & \thead[l]{unlabeled data pool\\contains novel classes} & \thead{seen} & \thead{seen*\,+\\novel*} & \thead{seen} & \thead[l]{[\texttt{OS}] unlabeled data pool\\with seen and novel classes} & \thead[l]{aim to query seen classes\\from unlabeled data pool} \\
         \hline
         \thead[l]{Coreset Selection\\in AL\cite{coreset, wei2015submodularity}} & \thead[l]{query instances to be\\annotated 
         } & \thead{seen} & \thead{seen*} & \thead{seen} & \thead[l]{[\texttt{CS}] the most representative\\subset of unlabeled set} & \thead[l]{find a small subset\\competitive to whole dataset} \\
         \hline
         \thead[l]{Coreset Selection\\in CL\cite{aljundi2019gradient, yoon2021online, tiwari2022gcr}} & \thead[l]{continuously learn\\a sequence of tasks} & \thead{\!\!partially\!\!\\novel} & - & \thead{seen} & \thead[l]{[\texttt{CS}] the most representative\\instances at each task} & \thead[l]{promote task adaptation with\\less catastrophic forgetting} \\
         \hline
         \thead[l]{Hard Negative Mining\\in Self-Sup.\cite{robinson2020contrastive, wang2021understanding}} & \thead[l]{assume that hard\\negatives are helpful} & - & \thead{target} & \thead{target} & \thead[l]{[\texttt{CS}] the hardest contrastive\\pair instances for SSL} & \thead[l]{improve SSL performance \\using core-negative instances} \\
         \hline
         \thead[l]{\bf Open-Set Self-Sup.\\\bf [ours]} & \thead[l]{utilize open-set in \\pretraining, which may\!\\have irrelevant data} & - & \thead{target\,+\\\!irrelevant\!} & \thead{target} & \thead[l]{[\texttt{OS}] large-scale unlabeled set\\ \!\,[\texttt{CS}] subset of \texttt{OS} sharing the\\same semantics with target set} & \thead[l]{improve SSL performance\\on fine-grained datset via\\coreset sampling method} \\
        \bottomrule
        \end{tabular}}
    \caption{Comparisons of the OpenSSL problem with relevant literature. We focus on the problem setting and the definition of open-set\,(\texttt{OS}) or coreset\,(\texttt{CS}) in each field. AL and CL refer to active learning and continual learning, respectively, and * indicates the instances in the unlabeled data pool that are supposed to be annotated after the active selection.}
    \label{tab:related_works}
\end{table*}
