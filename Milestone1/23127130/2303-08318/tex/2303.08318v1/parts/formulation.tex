\section{Problem Formulation}
We formulate micro-video tagging as a link prediction problem on a video-tag network $\boldsymbol{G}(\mathcal{V}, \mathcal{E})$. $\mathcal{V}$ is the node set composed of videos and tags, and $\mathcal{E}$ is the edge set. Note that video tagging with graphical data can also be formulated as a knowledge graph embedding problem \cite{jin_transfusion_2021}. However, such formulation only supports transductive learning, and is unable to handle new videos. 

For each node $u\in\mathcal{V}$, we denote its initial representation as $\mathbf{h}^0(u)\in\mathbb{R}^d$, where $d$ is the size of hidden dimension. For tag node, $\mathbf{h}^0$ comes from the sum of word embedding and learnable embedding. For video node, $\mathbf{h}^0$ comes from aggregated frame embedding. Given $\mathbf{h}^0$ and $\boldsymbol{G}$, our RADAR model, a $L$-layer heterogeneous GNN, can derive a better node representation $\mathbf{h}^L\in\mathbb{R}^d$:
\begin{equation} \label{eq:RADAR_formulation}
    \mathbf{h}^L = \textmd{RADAR} \left( \mathbf{h}^0, \boldsymbol{G} \right).
\end{equation}
Based on this representation, we predict the confidence score $\hat{y}(v,t)\in\mathbb{R}$ that micro-video $v\in\mathcal{V}_{\textmd{video}}$ has tag $t\in\mathcal{V}_{\textmd{tag}}$:
\begin{equation}
    \hat{y}(v,t) = \textmd{Sigmoid} \left( \mathbf{h}^L(v) \cdot \left [ \mathbf{h}^L(t) \right ]^T  \right).
\end{equation}

% For each tag node, $\mathbf{h}^0$ comes from its word embedding $\mathbf{w}\in\mathbb{R}^{M\times d_w}$:
% \begin{equation}    
%     \mathbf{h}^0 = \textmd{Tag-Linear} \left( \textmd{MeanPool} \left( \mathbf{w} \right) + id \right),
% \end{equation}
% where $M$ is the length of the tag, $d_w$ is the size of word embedding, and $id$ is the learn-able tag embedding. For each video node, $\mathbf{h}^0$ comes from the frame embedding $\mathbf{f}\in\mathbb{R}^{F\times d_f}$:
% \begin{equation}    
%     \mathbf{h}^0 = \textmd{Video-Linear} \left( \textmd{MeanPool} \left( \mathbf{f} \right) \right),
% \end{equation}
% where $F$ is the number of sampled frames, $d_f$ is the size of frame embedding.
