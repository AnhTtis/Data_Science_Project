\section{Introduction}
%
The last decade has evidenced the prosperity of micro-videos in User-Generated Content (UGC) platforms. 
To strengthen the applications like searching and recommendation \cite{wei2019neural, wei2020graph, sun2022response}, tags are widely-used to summarize micro-videos.
Considering the fact that users may not add sufficient tags when uploading micro-videos, tagging has hence become an expensive routine for operation teams on UGC platforms. 
According to the statistics over 600 million videos collected from Kuaishou platform, around 85.7\% of them have no tags at all. 
In order to generate tags with minimal human efforts, automatic micro-video tagging has drawn considerable attention from industrial and academic communities. 
Most existing methods formulate video tagging as a multi-label classification problem. 
Basic methods leverage information from video content and descriptions for tagging \cite{nextvlad, wu_tencent_mmads_1st_2021}. 
Sophisticated methods leverage extra information, such as tag graph \cite{ml_gcn, cma, li_mall_2022, jin_transfusion_2021}, query log \cite{taggnn}, user behavior \cite{jit2r}, and user profile \cite{wei_personalized_2019, li_long-tail_2019} to assist tagging. 

\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/task_example.pdf}
    \vspace{-1em}
    \caption{
    Example of social influence and tag relation. Social influence: user A is a follower of B, and imitates user B to create a video with similar tags (illustrated in \textit{italics}).}
    \vspace{-2em}
    \label{fig:task_example}
\end{figure}

However, users’ social influence and tag relation are rarely discussed, which could have played a pivotal role. 
%%
%On one hand, users’ social influence is crucial since user may imitate their influential social network neighbors to create similar micro-videos. 
%This phenomenon mainly results from a prominent characteristic in UGC platforms that users are not only content creators but also consumers. 
On one hand, users’ social influence is crucial since user may imitate their social network neighbors to create similar micro-videos, especially on UGC platforms because users are not only content creators but also consumers. 
%
%That is, users' creation is partially affected by what they have watched.
% Taking \autoref{fig:task_example} as an example, user B produces a micro-video about a new kind of ``grass cake'', 
Taking \autoref{fig:task_example} as an example, user B produces a micro-video about a ``grass cake'', 
and then the follower, user A, imitates this video to produce a similar one with almost the same set of tags. 
% Considering that similar videos generally have similar tags, such imitation phenomenon in the social network, namely \textbf{Behavior Spread} \cite{centola2010spread}, can enhance tagging performance if correctly modeled.
% %%
Such imitation phenomenon in the social network, namely \textbf{Behavior Spread} \cite{centola2010spread}, can enhance tagging performance if correctly modeled.
%%
% On the other hand, tag relation is reflected by a \textbf{tag ontology}. Tag ontology is often represented as a Directed Acyclic Graph (DAG) composed of tags with \textit{is\_subtopic\_of} relations. 
On the other hand, tag relation is reflected by a \textbf{tag ontology},
which is often represented as a Directed Acyclic Graph (DAG) composed of tags with \textit{is\_subtopic\_of} relations. 
Tag ontology facilitates tagging by providing external knowledge from three aspects: (i) tag dependencies \cite{cma, kssnet}, (ii) top-down knowledge transfer \cite{li_long-tail_2019}, and (iii) buttom-up semantics abstraction \cite{nie_large-scale_2020}.

To incorporate users’ social influence and tag relations, we build a heterogeneous user-video-tag network.
%, considering that user follow relations and tag ontology are both graphical structures. 
% The user-user, tag-tag, video-tag relations of the network come from user follow, tag ontology, video-tag annotations, respectively. Thereafter, we turn to a heterogeneous graph neural network to derive a better video and tag representation. 
This heterogeneous graph neural network is then used to derive a better video and tag representation.
Consequently, we are able to measure the video-tag similarly to get tagging results.
%
%
%Straightforward though the above approach is, we face challenges in the following aspects: 
There are still challenges for the above approach:
\textbf{C1: Behavior Spread modeling}. 
% Behavior Spread has not been incorporated into video tagging before. 
% We need to propose an effective model to filter irrelevant information, since not all micro-videos are created through imitation.
We need to propose an effective model to filter irrelevant information for Behavior Spread modeling, since not all micro-videos are created through imitation.
%
\textbf{C2: Visual-linguistic knowledge aggregation}. 
There are two sources of knowledge for learning a tag representation: visual knowledge from videos and linguistic knowledge from relevant tags in the tag ontology. 
%Both knowledge can be divided into source-unique (exists in one source), and source-common knowledge (exists in both sources). 
Existing aggregation methods \cite{kssnet, cma} that apply direct aggregation approaches like vector concatenation or attention mechanism are sub-optimal due to the ignorance of the redundancy in common knowledge. 
Concretely, concatenation duplicates the common knowledge, and attention mechanism tends to over concern the unique knowledge \cite{lu_aan_ref_ReID_2020, li_aan_ref_CTR_2020, verma_deepcu_2019}. 
%%
\textbf{C3: Tag ontology construction}. 
Most of the methods \cite{kssnet, li_long-tail_2019} acquire the desired tag ontology from existing open knowledge bases. However, because video content in UGC platforms changes very fast, open knowledge bases can cover only a portion of tags. Other methods \cite{ml_gcn, fang_folksonomy-based_2016} attempt to build the tag ontology from tag statistics. These methods are rule-based and thus lack accuracy.

% Taking \autoref{fig:task_example} as am example, there are common information about tag "cake" in both modalities, because visually its a kind of "food", and "food" is a parent tag as well. There are unique information. Visual information tells us the shape and texture while linguistic information indicates its scenario.

%In this work, we are dedicated to solving the above three challenges. 
% We first cast the task of micro-video tagging as a link prediction problem in a simplified video-tag network. Its video-video relations are inherited from follow relations of their creators. 
To solve \textbf{C3}, we construct a tag ontology using semi-supervised classification based upon hand-crafted features. 
%
% After ontology construction, we need to derive a better representation of each micro-video and tag node for tagging. 
% To achieve this, we design an adve\textbf{R}sarial aggregated g\textbf{A}te\textbf{D} gr\textbf{A}ph t\textbf{R}ansformer network (\textbf{RADAR}) to propagate information over the entire graph. 
%
After that, we design an adve\textbf{R}sarial aggregated g\textbf{A}te\textbf{D} gr\textbf{A}ph t\textbf{R}ansformer network (\textbf{RADAR}) to propagate information over the entire graph 
for a better representation of each micro-video and tag node.
RADAR is a heterogeneous Graph Neural Network (GNN) composed of a Gated Graph Transformer (GGT) and an Adversarial Aggregation Network (AAN). 
GGT aims to tackle \textbf{C1} by aggregating information from neighbors, and filtering irrelevant information. 
To cope with \textbf{C2}, AAN is applied to aggregate visual and linguistic knowledge by removing the redundant information while keeping the complementary. 
Finally, we compute the semantic similarity between a given micro-video and all candidate tags as our predictions.
To justify our model, we conduct extensive experiments over large-scale real-world datasets. The experimental results demonstrate the effectiveness of GGT and ANN, and our methods are consistently superior to several start-of-the-art baselines.

In summary, the contributions of this work are threefold:
%\vspace{-0.5em}
\begin{itemize}
    \item We construct a dataset of 450,000 micro-videos with their creators' social network in a UGC platform, and our experiments show that social network can benefit video tagging. To the best of our knowledge, this is the first work on modeling users' social influence towards micro-video tagging.
    \item We propose a semi-supervised manner to build a tag ontology, outperforming existing methods with little human effort.
    \item We design RADAR, a heterogeneous GNN composed of GGT and AAN to jointly model users’ social influence and tag relation in an end-to-end manner. RADAR outperforms cutting-edge methods with a clear margin in real-world datasets. Our code is available\footnote{\url{https://github.com/SCZwangxiao/RADAR-MM2022.git}}.
    % \item To the best of our knowledge, this is the first work on modeling users' social influence towards micro-video tagging. We construct a dataset of 450,000 videos. Inspired by Behavior Spread phenomenon, our method incorporates follow relations into a video-tag network to model the influence of social network neighbors.
    % \item We construct a tag ontology via a semi-supervised manner. Our construction approach outperforms the existing rule-based method by 2.69\%, and the constructed ontology covers 96.67\% of tags.
    % \item We design RADAR, a heterogeneous GNN composed of GGT and AAN to jointly model users’ social influence and tag relation. Thereinto, GGT and AAN solve Behavior Spread modeling and visual-linguistic knowledge aggregation challenges, respectively. RADAR outperforms cutting-edge methods with a clear margin in real-world datasets. Our code is available.\footnote{\url{https://github.com/mm1465/MM2022_sub1465}}
\end{itemize}