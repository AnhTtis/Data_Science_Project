@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{yang2022vision,
  title={Vision-Language Pre-Training with Triple Contrastive Learning},
  author={Yang, Jinyu and Duan, Jiali and Tran, Son and Xu, Yi and Chanda, Sampath and Chen, Liqun and Zeng, Belinda and Chilimbi, Trishul and Huang, Junzhou},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  year={2022}
}

@inproceedings{ALBEF,
      title={Align before Fuse: Vision and Language Representation Learning with Momentum Distillation}, 
      author={Junnan Li and Ramprasaath R. Selvaraju and Akhilesh Deepak Gotmare and Shafiq Joty and Caiming Xiong and Steven Hoi},
      year={2021},
      booktitle={NeurIPS},
}

@inproceedings{singh2022flava,
  author = {
    Amanpreet Singh and
    Ronghang Hu and
    Vedanuj Goswami and
    Guillaume Couairon and
    Wojciech Galuba and
    Marcus Rohrbach and
    Douwe Kiela
  },
  title = {
    {FLAVA:} {A} Foundational Language And 
    Vision Alignment Model
  },
  booktitle={CVPR},
  year={2022}
}
@article{yuan2021florence,
  title={Florence: A new foundation model for computer vision},
  author={Yuan, Lu and Chen, Dongdong and Chen, Yi-Ling and Codella, Noel and Dai, Xiyang and Gao, Jianfeng and Hu, Houdong and Huang, Xuedong and Li, Boxin and Li, Chunyuan and others},
  journal={arXiv preprint arXiv:2111.11432},
  year={2021}
}
@article{yu2022coca,
  title={Coca: Contrastive captioners are image-text foundation models},
  author={Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  journal={arXiv preprint arXiv:2205.01917},
  year={2022}
}
@inproceedings{soho,
  title={Seeing out of the box: End-to-end pre-training for vision-language representation learning},
  author={Huang, Zhicheng and Zeng, Zhaoyang and Huang, Yupan and Liu, Bei and Fu, Dongmei and Fu, Jianlong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12976--12985},
  year={2021}
}
@article{liu2021cross,
  title={Cross-modal discrete representation learning},
  author={Liu, Alexander H and Jin, SouYoung and Lai, Cheng-I Jeff and Rouditchenko, Andrew and Oliva, Aude and Glass, James},
  journal={arXiv preprint arXiv:2106.05438},
  year={2021}
}
@article{li2022unimo,
  title={UNIMO-2: End-to-End Unified Vision-Language Grounded Learning},
  author={Li, Wei and Gao, Can and Niu, Guocheng and Xiao, Xinyan and Liu, Hao and Liu, Jiachen and Wu, Hua and Wang, Haifeng},
  journal={arXiv preprint arXiv:2203.09067},
  year={2022}
}

@inproceedings{uniter,
  title={Uniter: Universal image-text representation learning},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle={European conference on computer vision},
  pages={104--120},
  year={2020},
  organization={Springer}
}


@inproceedings{oscar,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
  booktitle={European Conference on Computer Vision},
  pages={121--137},
  year={2020},
  organization={Springer}
}

@inproceedings{clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}


@inproceedings{align,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International Conference on Machine Learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}

@article{filip,
  title={Filip: Fine-grained interactive language-image pre-training},
  author={Yao, Lewei and Huang, Runhui and Hou, Lu and Lu, Guansong and Niu, Minzhe and Xu, Hang and Liang, Xiaodan and Li, Zhenguo and Jiang, Xin and Xu, Chunjing},
  journal={arXiv preprint arXiv:2111.07783},
  year={2021}
}


@article{declip,
  title={Supervision exists everywhere: A data efficient contrastive language-image pre-training paradigm},
  author={Li, Yangguang and Liang, Feng and Zhao, Lichen and Cui, Yufeng and Ouyang, Wanli and Shao, Jing and Yu, Fengwei and Yan, Junjie},
  journal={arXiv preprint arXiv:2110.05208},
  year={2021}
}

@article{bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{gpt,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}

@article{crossdiscrete,
  title={Cross-modal discrete representation learning},
  author={Liu, Alexander H and Jin, SouYoung and Lai, Cheng-I Jeff and Rouditchenko, Andrew and Oliva, Aude and Glass, James},
  journal={arXiv preprint arXiv:2106.05438},
  year={2021}
}

@article{vqvae,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


@article{wang2022cross,
  title={Cross-modal image--text search via Efficient Discrete Class Alignment Hashing},
  author={Wang, Song and Zhao, Huan and Wang, Yunbo and Huang, Jing and Li, Keqin},
  journal={Information Processing \& Management},
  volume={59},
  number={3},
  pages={102886},
  year={2022},
  publisher={Elsevier}
}


@article{mm_dict_cls,
  title={Multimodal task-driven dictionary learning for image classification},
  author={Bahrampour, Soheil and Nasrabadi, Nasser M and Ray, Asok and Jenkins, William Kenneth},
  journal={IEEE transactions on Image Processing},
  volume={25},
  number={1},
  pages={24--38},
  year={2015},
  publisher={IEEE}
}

@article{mm_dict_conv,
  title={Multi-Modal Convolutional Dictionary Learning},
  author={Gao, Fangyuan and Deng, Xin and Xu, Mai and Xu, Jingyi and Dragotti, Pier Luigi},
  journal={IEEE Transactions on Image Processing},
  volume={31},
  pages={1325--1339},
  year={2022},
  publisher={IEEE}
}

@article{conv_dict,
  title={Convolutional dictionary learning: A comparative review and new algorithms},
  author={Garcia-Cardona, Cristina and Wohlberg, Brendt},
  journal={IEEE Transactions on Computational Imaging},
  volume={4},
  number={3},
  pages={366--381},
  year={2018},
  publisher={IEEE}
}


@inproceedings{cookie,
  title={Cookie: Contrastive cross-modal knowledge sharing pre-training for vision-language representation},
  author={Wen, Keyu and Xia, Jin and Huang, Yuanyuan and Li, Linyang and Xu, Jiayan and Shao, Jie},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2208--2217},
  year={2021}
}


@inproceedings{cots,
  title={COTS: Collaborative Two-Stream Vision-Language Pre-Training Model for Cross-Modal Retrieval},
  author={Lu, Haoyu and Fei, Nanyi and Huo, Yuqi and Gao, Yizhao and Lu, Zhiwu and Wen, Ji-Rong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15692--15701},
  year={2022}
}


@article{declip_benchmark,
  title={Democratizing Contrastive Language-Image Pre-training: A CLIP Benchmark of Data, Model, and Supervision},
  author={Cui, Yufeng and Zhao, Lichen and Liang, Feng and Li, Yangguang and Shao, Jing},
  journal={arXiv preprint arXiv:2203.05796},
  year={2022}
}

@inproceedings{cc12m,
  title={Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts},
  author={Changpinyo, Soravit and Sharma, Piyush and Ding, Nan and Soricut, Radu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3558--3568},
  year={2021}
}



@inproceedings{cc3m,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={2556--2565},
  year={2018}
}


@inproceedings{mscoco,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European conference on computer vision},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@article{cosinedecay,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1608.03983},
  year={2016}
}


@inproceedings{sparsemax,
  title={From softmax to sparsemax: A sparse model of attention and multi-label classification},
  author={Martins, Andre and Astudillo, Ramon},
  booktitle={International conference on machine learning},
  pages={1614--1623},
  year={2016},
  organization={PMLR}
}
@article{peng2022beit2,
  title={BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers},
  author={Peng, Zhiliang and Dong, Li and Bao, Hangbo and Ye, Qixiang and Wei, Furu},
  journal={arXiv preprint arXiv:2208.06366},
  year={2022}
}
@article{wang2022beit3,
  title={Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks},
  author={Wang, Wenhui and Bao, Hangbo and Dong, Li and Bjorck, Johan and Peng, Zhiliang and Liu, Qiang and Aggarwal, Kriti and Mohammed, Owais Khan and Singhal, Saksham and Som, Subhojit and others},
  journal={arXiv preprint arXiv:2208.10442},
  year={2022}
}

@inproceedings{learning_concepts,
  title={Learning semantic concepts and order for image and sentence matching},
  author={Huang, Yan and Wu, Qi and Song, Chunfeng and Wang, Liang},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6163--6171},
  year={2018}
}

@inproceedings{msclip,
  title={Learning Visual Representation from Modality-Shared Contrastive Language-Image Pre-training},
  author={You, Haoxuan and Zhou, Luowei and Xiao, Bin and Codella, Noel and Cheng, Yu and Xu, Ruochen and Chang, Shih-Fu and Yuan, Lu},
  booktitle={European Conference on Computer Vision},
  pages={69--87},
  year={2022},
  organization={Springer}
}

@article{snil_ve,
  title={Visual entailment: A novel task for fine-grained image understanding},
  author={Xie, Ning and Lai, Farley and Doran, Derek and Kadav, Asim},
  journal={arXiv preprint arXiv:1901.06706},
  year={2019}
}

@inproceedings{vqa,
  title={Vqa: Visual question answering},
  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2425--2433},
  year={2015}
}

@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}


@inproceedings{swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10012--10022},
  year={2021}
}


@article{image_infinity,
  title={What Is Considered Complete for Visual Recognition?},
  author={Xie, Lingxi and Zhang, Xiaopeng and Wei, Longhui and Chang, Jianlong and Tian, Qi},
  journal={arXiv preprint arXiv:2105.13978},
  year={2021}
}

@inproceedings{Gra_unif,
  title={Learning Granularity-Unified Representations for Text-to-Image Person Re-identification},
  author={Shao, Zhiyin and Zhang, Xinyu and Fang, Meng and Lin, Zhifeng and Wang, Jian and Ding, Changxing},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={5566--5574},
  year={2022}
}

@article{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  journal={arXiv preprint arXiv:2201.12086},
  year={2022}
}

@inproceedings{
    vit,
    title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
    author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
    booktitle={International Conference on Learning Representations},
    year={2021},
    url={https://openreview.net/forum?id=YicbFdNTTy}
}

@inproceedings{
    loshchilov2018decoupled,
    title={Decoupled Weight Decay Regularization},
    author={Ilya Loshchilov and Frank Hutter},
    booktitle={International Conference on Learning Representations},
    year={2019},
    url={https://openreview.net/forum?id=Bkg6RiCqY7},
}


@article{f30k,
  title={From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions},
  author={Young, Peter and Lai, Alice and Hodosh, Micah and Hockenmaier, Julia},
  journal={Transactions of the Association for Computational Linguistics},
  volume={2},
  pages={67--78},
  year={2014},
  publisher={MIT Press}
}


@article{slip,
  title={Slip: Self-supervision meets language-image pre-training},
  author={Mu, Norman and Kirillov, Alexander and Wagner, David and Xie, Saining},
  journal={arXiv preprint arXiv:2112.12750},
  year={2021}
}

@inproceedings{tcl,
  title={Vision-Language Pre-Training with Triple Contrastive Learning},
  author={Yang, Jinyu and Duan, Jiali and Tran, Son and Xu, Yi and Chanda, Sampath and Chen, Liqun and Zeng, Belinda and Chilimbi, Trishul and Huang, Junzhou},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15671--15680},
  year={2022}
}


@article{cifar10,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada}
}


@inproceedings{sun397,
  title={Sun database: Large-scale scene recognition from abbey to zoo},
  author={Xiao, Jianxiong and Hays, James and Ehinger, Krista A and Oliva, Aude and Torralba, Antonio},
  booktitle={2010 IEEE computer society conference on computer vision and pattern recognition},
  pages={3485--3492},
  year={2010},
  organization={IEEE}
}

@inproceedings{cars,
  title={3d object representations for fine-grained categorization},
  author={Krause, Jonathan and Stark, Michael and Deng, Jia and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE international conference on computer vision workshops},
  pages={554--561},
  year={2013}
}

@article{aircraft,
  title={Fine-grained visual classification of aircraft},
  author={Maji, Subhransu and Rahtu, Esa and Kannala, Juho and Blaschko, Matthew and Vedaldi, Andrea},
  journal={arXiv preprint arXiv:1306.5151},
  year={2013}
}

@inproceedings{dtd,
  title={Describing textures in the wild},
  author={Cimpoi, Mircea and Maji, Subhransu and Kokkinos, Iasonas and Mohamed, Sammy and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3606--3613},
  year={2014}
}

@inproceedings{caltech,
  title={Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories},
  author={Fei-Fei, Li and Fergus, Rob and Perona, Pietro},
  booktitle={2004 conference on computer vision and pattern recognition workshop},
  pages={178--178},
  year={2004},
  organization={IEEE}
}

@inproceedings{flower,
  title={Automated flower classification over a large number of classes},
  author={Nilsback, Maria-Elena and Zisserman, Andrew},
  booktitle={2008 Sixth Indian Conference on Computer Vision, Graphics \& Image Processing},
  pages={722--729},
  year={2008},
  organization={IEEE}
}

@inproceedings{food101,
  title={Food-101--mining discriminative components with random forests},
  author={Bossard, Lukas and Guillaumin, Matthieu and Gool, Luc Van},
  booktitle={European conference on computer vision},
  pages={446--461},
  year={2014},
  organization={Springer}
}

@inproceedings{imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}


@inproceedings{meter,
  title={An empirical study of training end-to-end vision-and-language transformers},
  author={Dou, Zi-Yi and Xu, Yichong and Gan, Zhe and Wang, Jianfeng and Wang, Shuohang and Wang, Lijuan and Zhu, Chenguang and Zhang, Pengchuan and Yuan, Lu and Peng, Nanyun and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18166--18176},
  year={2022}
}


@inproceedings{pets,
  title={Cats and dogs},
  author={Parkhi, Omkar M and Vedaldi, Andrea and Zisserman, Andrew and Jawahar, CV},
  booktitle={2012 IEEE conference on computer vision and pattern recognition},
  pages={3498--3505},
  year={2012},
  organization={IEEE}
}

@inproceedings{
    geng2023hiclip,
    title={Hi{CLIP}: Contrastive Language-Image Pretraining with Hierarchy-aware Attention},
    author={Shijie Geng and Jianbo Yuan and Yu Tian and Yuxiao Chen and Yongfeng Zhang},
    booktitle={The Eleventh International Conference on Learning Representations },
    year={2023}
}

@inproceedings{chen2023more,
  title={More than just attention: Improving cross-modal attentions with contrastive constraints for image-text matching},
  author={Chen, Yuxiao and Yuan, Jianbo and Zhao, Long and Chen, Tianlang and Luo, Rui and Davis, Larry and Metaxas, Dimitris N},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={4432--4440},
  year={2023}
}

@inproceedings{zhang2022learning,
  title={Learning 3D Representations from 2D Pre-trained Models via Image-to-Point Masked Autoencoders},
  author={Zhang, Renrui and Wang, Liuhui and Qiao, Yu and Gao, Peng and Li, Hongsheng},
booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2023}
}


@inproceedings{zhang2023prompt,
  title={Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong Few-shot Learners},
  author={Zhang, Renrui and Hu, Xiangfei and Li, Bohao and Huang, Siyuan and Deng, Hanqiu and Li, Hongsheng and Qiao, Yu and Gao, Peng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2023}
}

@inproceedings{zhang2023parameter,
  title={Parameter is Not All You Need: Starting from Non-Parametric Networks for 3D Point Cloud Analysis},
  author={Zhang, Renrui and Wang, Liuhui and Wang, Yali and Gao, Peng and Li, Hongsheng and Shi, Jianbo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2023}
}

@article{zhang2022sine,
  title={SINE: SINgle Image Editing with Text-to-Image Diffusion Models},
  author={Zhang, Zhixing and Han, Ligong and Ghosh, Arnab and Metaxas, Dimitris and Ren, Jian},
  journal={arXiv preprint arXiv:2212.04489},
  year={2022}
}

@inproceedings{lin2022frozen,
  title={Frozen clip models are efficient video learners},
  author={Lin, Ziyi and Geng, Shijie and Zhang, Renrui and Gao, Peng and de Melo, Gerard and Wang, Xiaogang and Dai, Jifeng and Qiao, Yu and Li, Hongsheng},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXV},
  pages={388--404},
  year={2022},
  organization={Springer}
}

@article{gao2021clip,
  title={Clip-adapter: Better vision-language models with feature adapters},
  author={Gao, Peng and Geng, Shijie and Zhang, Renrui and Ma, Teli and Fang, Rongyao and Zhang, Yongfeng and Li, Hongsheng and Qiao, Yu},
  journal={arXiv preprint arXiv:2110.04544},
  year={2021}
}

@inproceedings{chen2018you,
  title={You Type a Few Words and We Do the Rest: Image Recommendation for Social Multimedia Posts},
  author={Chen, Tianlang and Chen, Yuxiao and Guo, Han and Luo, Jiebo},
  booktitle={2018 IEEE International Conference on Big Data (Big Data)},
  pages={2124--2133},
  year={2018},
  organization={IEEE}
}

@article{amir2021deep,
  title={Deep vit features as dense visual descriptors},
  author={Amir, Shir and Gandelsman, Yossi and Bagon, Shai and Dekel, Tali},
  journal={arXiv preprint arXiv:2112.05814},
  volume={2},
  number={3},
  pages={4},
  year={2021}
}