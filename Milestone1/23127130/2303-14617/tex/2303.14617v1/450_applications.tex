\section{Applications}
\label{sec:apps}

In addition to graph database use cases, the framework of complex query answering is applied in a variety of graph-conditioned machine learning tasks.
For example, SE-KGE~\citep{se_kge} applies GQE to answer geospatial queries conditioned on numerical $\{x,y\}$ coordinates. 
The coordinates encoder fuses numerical representations with entity embeddings such that the prediction task is still entity ranking.

In case-based reasoning, CBR-SUBG~\citep{cbr_subg2022} is a method for question answering over KGs based on subgraph extraction and encoding. 
As a byproduct, CBR-SUBG is capable of answering conjunctive queries with projections and intersections.
However, due to a non-standard evaluation protocol and custom synthetic dataset, its performance cannot be directly compared to \clqa models. 
Similarly, \citet{wang2023unifying} merge a Query2Box-like model with a pre-trained language model to improve question answering performance.
LEGO~\citep{lego} also applies \clqa models for KG question answering. The idea is to simultaneously parse a natural language question as a query step and execute the step in the latent space with \clqa models.

LogiRec~\citep{wu2022highorder} frames product recommendation as a complex logical query such that source products are root nodes, combinations of multiple products form intersections, and non-similar products to be filtered out form negations. 
LogiRec employs BetaE as a query engine.
Similarly, \cite{syed2022context} design an explainable recommender system based on Query2Box. 
Given a logical query, they first use Query2Box to generate a set of candidates and rerank them using neural collaborate filtering \citep{he2017neural}.  
