\section{Preliminaries}\label{sec:prelim}

Here, we discuss the foundational terms and preliminaries often seen in the database and graph learning literature 
%
before introducing neural graph databases. This includes definitions of different types of graphs, graph queries and their mapping to structured languages like SPARQL, formalizing approximate graph query answering, logical operators, and fuzzy logic. The full hierarchy of definitions is presented in \autoref{fig:def_hierarchy}.

\subsection{Types of Graphs}  

\begin{figure}[!ht]
	\centering
	\includegraphics[width=\linewidth]{figs/nqe_modality.pdf}
	\caption{An example of KG modalities. Triple-only graphs have directed binary edges between nodes. Hyper-relational graphs allow key-value relation-entity attributes over edges. Hypergraphs consist of hyperedges composed of multiple nodes.
 }
	\label{fig:modality}
\end{figure}


Here we introduce different types of graphs relevant for this research area. 
These serve as the core data structure of various query reasoning works and also our neural graph storage module (\Secref{sec:storage}). Our definitions are adaptations from those in \cite[ch. 2]{hogan2021knowledge}. 

We begin by defining a set with all elements used in our graph
\begin{definition}[\con]
$\con$ is an infinite set of constants.\footnote{
In case the constants do not include representations for the real numbers, this set would be countably infinite.
}
\end{definition}

\begin{definition}[(Standard / Triple based) Knowledge Graph]
\label{def:kg}
We define a knowledge graph (KG) $\gG=(\gE, \gR, \gS)$, where $\gE \subset \con$ represents a set of nodes (entities), $\gR \subset \con$ is a set of relations (edge types), and $\gS \subset (\gE \times \gR \times \gE)$ is a set of edges (triples)~\footnote{There might be an overlap between $\gE$ and $\gR$, i.e., some constants might be used as an edge and as a node.}.
Each edge $s\in\gS$ on a KG $\gG$ denotes a statement (or fact) $(e_s, r, e_o)$ in a triple format or $r(e_s,e_o)$ as a formula in first-order logic (FOL) form, where $e_s, e_o \in \gE$ denote the subject and object entities, and $r\in\gR$ denotes the relationship between the subject and the object.
Often, the graph is restricted such that the set of nodes and edges must be finite, we will make this assumption unless indicated otherwise.
\end{definition}
For example, one statement on the KG in \autoref{fig:clqa_1}\encirclered{b} is \texttt{(Hinton, university, UofT)} or \texttt{university(Hinton, UofT)}. Note all relations are binary on KGs, \ie, each relation involves exactly two entities. 
This is also the choice made for the resource description framework (RDF)~\citep{brickley2014rdf} that defines a triple as a basic representation of a fact, yet RDF allows a broader definition of triples, where the object can be literals including numbers and timestamps (detailed in the following paragraphs).



Hyper-relational KGs generalize triple KGs by allowing edges to have relation-entity qualifiers. We define them as follows:
\begin{definition}[Hyper-relational Knowledge Graph - derived from \cite{starqe}]
With $\gE$ and $\gR$ defined as in \autoref{def:kg}, let $\fQ = 2^{(\gR \times \gE)}$, we define a hyper-relational knowledge graph $\gG=(\gE,\gR,\gS)$. In this case, the edge set $\gS \subset (\gE \times \gR \times \gE \times \fQ)$ consists of qualified statements, where each statement $s=(e_s, r, e_o, qp)$ includes $qp$ that represent contextual information for the main relation $r$.
This set $qp = \{q_1, \ldots\} = \{(qr_1, qe_1), (qr_2, qe_2) \ldots\} \subset \mathcal{R} \times \mathcal{E}$ is the set of \emph{qualifier pairs}, where $\{qr_1, qr_2, \ldots\} $ are the \emph{qualifier relations} and $\{qe_1, qe_2, \ldots\} $ the \emph{qualifier entities}.
\label{def:hyper_relational_kg}
\end{definition}
We note that if $\gE$ and $\gR$ are finite sets, then also $\fQ$ is finite and, there are only a finite number of ($r, qp$) combinations possible.
As a consequence, we find that with these conditions, and by defining a canonical ordering over $\fQ$, we can represent the hyper-relational graph using first order logic by coining a new predicate $r_{qp}$ for each combination.
The statement from the definition can then be written as $r_{qp}(e_s,e_o)$.


For example, one statement on a hyper-relational KG in (\autoref{fig:modality}) is \texttt{(Hinton, education, Cambridge, \{(degree, Bachelor)\})}. The qualifier pair \texttt{\{(degree, Bachelor)\}} provides additional context to the main triple and helps to distinguish it from other \texttt{education} facts. 
If the conditions mentioned above are met, we can write this statement as $\mathtt{education_{\{(degree:Bachelor)\}}(Hinton, Cambridge)}$. 

Hyper-relational KGs can capture a more diverse set of facts by using the additional qualifiers for facts on the graph.
This concept is closely connected to the RDF-star (previously known as RDF*) format introduced in \citet{hartig2022rdfstar}, as an extension of RDF. 
RDF-star explicitly separates metadata (context) from data (statements).
RDF-star supports a superset of hyper-relational graphs; it extends the values allowed in the object and qualifier value position to include literals, which we will discuss below. 

\begin{definition}[Hypergraph Knowledge Graph]
With $\gE$ and $\gR$ defined as in \autoref{def:kg}, a hypergraph KG is a graph $\gG=(\gE, \gR, \gS)$ where statements $\gS \subset (\gR \times 2^\gE )$ are hyperedges.
Such a hyperedge $s = (r, e) = (r, \{e_1, \dots, e_k\})$ has one relation type $r$ and links the $k$ entities together, where the order of these entities is not significant. $k$, the size of $e$ is called the \emph{arity} of the hyperedge.
\label{def:hypergraph_kg}
\end{definition}

An example hyperedge in \autoref{fig:modality} is $(\texttt{education\_degree}, \{\texttt{Hinton}, \texttt{Cambridge}, \texttt{Bachelor}\})$. 
This is a 3-ary statement (being comprised of three entities).
In contrast to hyper-relational KGs, hyperedges consist of only one relation type and cannot naturally incorporate more fine-grained relational compositions. 
Instead, the type of the hyperedge is rather a merged set of statement relations and every composition leads to a new relation type on hypergraph KGs. It is thus not as compositional as the hyper-relational KG. 
That is, when describing, for instance, a \texttt{major} relation of the \texttt{education(Hinton, Cambridge)} fact, a hyper-relational KG can simply use it as a qualifier and retain both relations whereas a hypergraph model has to come up with a new hyperedge type \texttt{education\_major}. 
With a growing number of relations, such a strategy of creating new hyperedge relation types might lead to a combinatorial explosion. 
However, the hypergraph model is more suitable for representing relationships of varying arity, with equal contributions of all entities such as \texttt{partnership(companyA, companyB, companyC)}.


Each of the graph types introduced above can be extended to also support literals.
This happens by allowing nodes or qualifier values to contain a literal value. 
Some graphs, like property graphs allow nodes to contain attributes, but this is equivalent with creating extra nodes with these attribute values and adding relations to those.
In theory, also the edge type could be a literal, but we exclude these from this work. 
\begin{definition}[KG with Literals]
With $\gE$ and $\gR$ as for one of the graph types above, a corresponding KG with literals $\gG_{\gL}=(\gE, \gR, \gS_{\gL}, \gL)$ has an additional set of literals $\gL \subset \con$ representing numerical, categorical, textual, images, sound waves, or other continuous values ($\gL$ is disjoint from $\gE$ and $\gR$). 
If we extend standard KGs to RDF graphs, literals can only be used in the objects position, that is $\gS_{\gL} \subset (\gE \times \gR \times (\gE \cup \gL))$. 
In RDF-star graphs, literals can be objects or qualifier values, that is, $\fQ = 2^{(\gR \times (\gE \cup \gL))}$ and $\gS_{\gL} \subset (\gE \times \gR \times (\gE \cup \gL) \times \fQ)$.\footnote{
Both RDF and RDF-star also allow blank nodes used to indicate entities without a specified identity in the subject and object position
\cite{brickley2014rdf}
.
Besides, they also have support for named graphs (and in some cases for quadruples). 
We do not support these explicitly in our formalism, but all of these can be modeled using hyper-relational graphs.
}
For both of these, we could also define graph types with literals in other positions of the triples, as necessary, or introduce more complex substructures in the elements of the triple (see e.g.,~\cite{cochez2012semantic}).
In hypergraph KGs, literals can be introduced in the elements of a hyperedge, $\gS_{\gL} \subset (\gR \times 2^{\gE \cup \gL} )$
\label{def:kg_literals}
\end{definition}
If the set of possible statements of the KG with literals has the same finiteness properties as the one without literals, then the properties regarding expressing it using first order logic do not change.

An example triple with a literal object (\autoref{fig:reasoning_domain}) is \texttt{(Cambridge, established, 1209)}. 
Literals contain numerical, categorical, discrete timestamps, or text data that cannot be easily discretized in an exhaustive set of possible values, like entities.
Similarly to the Web Ontology Language (OWL,~\cite{motik2009owl}) that distinguishes \emph{object properties} that connect two entities from \emph{datatype properties} that connect an entity and a literal, it is common to use the term \emph{relation} for an edge between two entities, and \emph{attribute} for an edge between an entity and a literal.
For example, in \texttt{education(Hinton, Cambridge)}, \texttt{education} is a relation, whereas \texttt{established(Cambridge, 1209)} is an attribute.


The knowledge graph definitions above are not exhaustive. 
It is possible to create graphs with other properties.
Examples include graphs with undirected edges, without edge labels, with time characteristics, with probabilistic or fuzzy relations, etc.
Besides, it is also possible to have graphs or edges with combined characteristics. 
One could, for instance, define a hyperedge with qualifying information. 
Because of this plethora of options, we decided to limit ourselves to the limited set of options above.
In the next section we introduce how to query these graphs. 

\subsection{Basic Graph Query Answering}
We base our definition of basic graph queries on the one from \cite[section 2.2.1 basic graph patterns]{hogan2021knowledge}, but adapt it to our graph formalization.



 \begin{wrapfigure}[14]{R}{0.50\textwidth}
      \begin{adjustbox}{width=0.50\textwidth}
          \input{tikz/defs_hierarchy}     
      \end{adjustbox}
\definecolor{row1_color}{HTML}{fff2cc}
\definecolor{row2_color}{HTML}{d9ead3}
\definecolor{row3_color}{HTML}{fce5cd}
\definecolor{row3b_color}{HTML}{f9cb9c}
\definecolor{row3_split_color}{HTML}{e69138}
\definecolor{row4_color}{HTML}{c9daf8}  
\vspace{-\baselineskip}
%\captionsetup{font=footnotesize}
     \caption{
A hierarchy of definitions from \colorbox{row1_color}{Graph Query} to \colorbox{row2_color}{Graph Query Answering}, a more general
     \colorbox{row3b_color}{Approximate Graph Query Answering}
     leading to \colorbox{row4_color}{Neural Graph Database, \ngdb}. }
     \label{fig:def_hierarchy}
 \end{wrapfigure}


\begin{definition}[Term and Var]
Given a knowledge graph $\gG=(\gE, \gR, \gS)$ (or equivalent $\gG=(\gE, \gR, \gS, \gL)$), 
we define the set of variables $\variable  = \{v_1, v_2, \dots \}$ which take values from $\con$, but is strictly disjoint from it.
We call the union of the variables and the constants the terms: $\term = \con \cup \variable$
\end{definition}

With these concepts in place a Basic Graph Query is defined as follows:

\begin{definition}[Basic Graph Query]
\label{def:basic_graph_query}
A basic graph query is a 4-tuple $\gQ=(\gE', \gR', \gS', \overline{\gS'})$
 (equivalently a 5-tuple $\gQ=(\gE', \gR', \gS', \overline{\gS'}, \gL')$, with literals), 
with $\gE' \subset \term$ a set of node terms, $\gR' \subset \term$ a set of relation terms, and $\gS', \overline{\gS'} \subset \gE' \times \gR' \times \gE'$, two sets of edges (or equivalent to how graph edges are defined with literals).
The query looks like two (small) graphs; one formed by the edges in $\gS'$, and another by the edges in $\overline{\gS'}$.
The former set includes edges that must be matched in the graph to obtain answers to the query, while the latter contains edges that \textbf{must not} be matched (\ie, atomic negation). 
\end{definition}

With $\variable_Q = \gE' \cap \variable$ (all variables in the query), the answer to the query is defined as follows. 

\begin{definition}[Basic Graph Query Answering]
\label{def:basic_graph_query_answering}
Given a knowledge graph $\gG$ and a query $\gQ$ as defined above, an answer to the query is any mapping 
$\mu : \variable_Q \to \con$ 
such that replacing each variable $v_i$ in the edges in $\gS'$ with $\mu(v_i)$ results in an edge in $\gS$, \emph{and} replacing each variable $v_j$ in the edges in $\overline{\gS'}$ with $\mu(v_j)$ results in an edge that is \textbf{not} in $\gS$.
The set of all answers to the query is the set of all such mappings. 
\end{definition}

For triple-based KGs, each edge $(a, R, b)$ of the edge set $\gS$ (respectively $\gS'$) can be seen as relation projections $R(a,b)$ (resp. $\neg R(a,b)$), \ie, binary functions. Now, because the conjunction (\ie, all) of these relation projections (resp. the negation) have to be true, we also call these \emph{conjunctive} queries with atomic negation~(\CQn). 
The SPARQL query language defines basic graph patterns (BGPs). 
These closely resemble our basic graph query for RDF graphs, but with $\overline{\gS'} = \emptyset$, \ie, they do not support atomic negation but only conjunctive queries (\CQ).
We could analogously create {\CQ} and {\CQn} classes for the other KG types. 

In \autoref{fig:clqa_1}\encirclered{c} we provide an example of a Basic Graph Query expressed in the 
%
form of a SPARQL query.
This corresponds to our formalism: 
\begin{align*}
\gQ=(&\{\texttt{TuringAward}, \textit{?person}, \texttt{DeepLearning}, \textit{?uni}\}, \tag{\texttt{\# Node Terms } $\gE'$}  \\
&\{\textit{win}, \textit{field}, \textit{university}\}, \tag{\texttt{\# Relation Terms } $\gR'$} \\
&\{(\texttt{TuringAward},\textit{win}, \textit{?person}), (\texttt{DeepLearning}, \textit{field}, \textit{?person}), (\textit{?person},\textit{university}, \textit{?uni})\}, \tag{$\gS'$}\\
&\emptyset \tag{$\overline{\gS'}$})
\end{align*}
A possible answer to this query is the following partial mapping:
$
\mu_1 =\{(\textit{?person}, \texttt{Hinton}), (\textit{?uni}, \texttt{UofT})\}
$
This is also the only answer, so the set of all answers is $\{\mu_1\}$

If we want to exclude people who have worked together with \texttt{Welling}, then we modify the query as follows:
\begin{align*}
	\gQ=(&\{\texttt{TuringAward}, \textit{?person}, \texttt{DeepLearning}, \textit{?uni}\},\\
	&\{\textit{win}, \textit{field}, \textit{university}\}, \\
	&\{(\texttt{TuringAward},\textit{win}, \textit{?person}), (\texttt{DeepLearning}, \textit{field}, \textit{?person}), (\textit{?person},\textit{university}, \textit{?uni})\},\\
	&\pmb{\{(\textit{?person}, \textit{collab}, \texttt{Welling})\}})
\end{align*}
Note the key difference here is that we add \{(\textit{?person}, \textit{collab}, \texttt{Welling})\} to $\overline{\gS'}$. The answer set to this query is empty.


\subsection{Basic Approximate Graph Query Answering}


Until now, we have assumed that our KG is complete, \ie, it is possible to exactly answer the queries.
However, we are interested in the setting where we do not have the complete graph.
The situation can be described as follows:
Given a knowledge graph $\gG$ (subset of a complete, but not observable graph $\hat{\gG}$) and a basic graph query $\gQ$.
Basic Approximate Graph Query Answering is the task of answering $\gQ$, without having access to $\hat{\gG}$.
Depending on the setting, an approach to this could have access to $\gG$, or to a set of example (query, answer) pairs, which can be used to produce the answers (see also \autoref{sec:graph_training}).
In the example from \autoref{fig:clqa_1}, we also have several edges drawn with dashes. These are edges which are true, but only there in the non-observable part of the graph $\hat{\gG}$.

The goal is to find the answer set as if $\hat{\gG}$ was known.
In this case, the complete answer set becomes
$
\{
\mu_1, 
\{(\textit{?person}, \texttt{Bengio}), (\textit{?uni}, \texttt{UdeM})\}, 
\{(\textit{?person}, \texttt{LeCun}), (\textit{?uni}, \texttt{NYU})\} 
\}
$, which includes the answer $\mu_1$ of the non-approximate version. 

The query which includes the negation would have the following answers if our graph was complete:
$
\{
\{(\textit{?person}, \texttt{Bengio}), (\textit{?uni}, \texttt{UdeM})\}, 
\{(\textit{?person}, \texttt{LeCun}), (\textit{?uni}, \texttt{NYU})\} 
\}
$, which does not include $\mu_1$.

Approximate Query Answering Systems provide a score $\in \scoredomain$ for \emph{every possible} mapping\footnote{	
This score can indicate the rank of the mapping, a likelihood or a truth value, or be a binary indicating value.
}.
Hence, the answer provided by these systems is a function from mappings (\ie, a $\mu$) to their corresponding score in \scoredomain.

\begin{definition}[Basic Approximate Graph Query Answering]
\label{def:basic_approx_gqa}
Given a knowledge graph $\gG$ (subgraph of a complete, but not observable knowledge graph $\hat{\gG}$), a basic graph query $\gQ$, and the scoring domain \scoredomain,
a \emph{basic approximate graph query answer} to the query $\gQ$ is a function $f$ which maps every possible  mapping ($\mu : \variable_Q \to \con$) to \scoredomain.
\end{definition}

\begin{wraptable}[10]{R}{5cm}
    \vspace{-\baselineskip}
	\centering
    %\scriptsize
	\caption{Ordered scored mappings for %Basic Approximate Graph Query Answering on 
    the example query.
    The two wrong mappings are in red.}
	\label{tab:basic_approx_gqa_example}
	\begin{tabular}{ll|l}
		\toprule
		?person  & ?uni & score \\
		\midrule
		Hinton & UofT & 40 \\
		Bengio & UdeM & 35 \\
		{\color{red}Welling} & {\color{red} UofT} & 34 \\
		{\color{red} UdeM} & {\color{red} Hinton} & 33  \\
		LeCun & NYU & 32 \\
		\dots & \dots & \dots \\
		\bottomrule
	\end{tabular}
\end{wraptable}

The objective is to make it such that the correct answers according to the graph $\hat{\gG}$ get a better score (are ranked higher, have a higher probability, have a higher truth value) than those which are not correct answers. 
However, it is not guaranteed that answers which are in the observable graph $\gG$ will get a high score. 


For our example, a possible mapping is visualized in \autoref{tab:basic_approx_gqa_example}. 
Each row in the table corresponds to one mapping $\mu$. 
Ideally, all correct mappings should be ranked on top, and all others below.
However, in this example we see several correct answers ranked high, but also two which are wrong.


\subsection{Graph Query Answering}

In the previous sections, we introduced the basic graph query and how it can be answered either exactly, or in an approximate graph querying setting.
However, there is variation in what types of queries methods can answer; some only support a subset  of our basic graph queries, while others support more complicated queries. 
In this section we will again focus on \emph{exact (non-approximate) query answering} and look at some possible restrictions and then at extensions. We will also highlight links to FOL fragments.


\begin{definition}[Graph Query Answering]
\label{def:graph_query_answering}
Given a knowledge graph $\gG$, a query formalism, and a graph query $\gQ$ according to that formalism. 
An answer to the query 	is any mapping $\mu: \variable_Q \to \con$ 
such that the requirements of the query formalism are met.
The set of all answers is the set of all such mappings. 	
\end{definition}
%
For our basic graph queries introduced in \autoref{def:basic_graph_query}, the query formalism sets requirements as to what edges must and must not exist in the graph (\autoref{def:basic_graph_query_answering}).
In that context we already mentioned conjunctive queries, which exist either with (\CQn) or without (\CQ) negation.
If the conditions for writing our graphs using first order logic (FOL) hold, we can equivalently write our basic graph queries in first order logic. Each variable in the query becomes existentially quantified, and the formula becomes a conjunction of 
\begin{inparaenum}[1)]
	\item the terms formed from the triples in $S'$, and
	\item the negation of the terms formed from the triples in $\overline{S'}$%
\end{inparaenum}.
If there are variables on the edges of the query graph, then we can rewrite the second order formula in first order logic, by interpreting them as a disjunction over all possible predicates from the finite number of options.
Our example query from above becomes the following FOL sentence.
\begin{multline*}
	q = \exists \textit{?person}, \textit{?uni} :  \textit{win}(\texttt{TuringAward}, \textit{?person}) \wedge \textit{field}(\texttt{DeepLearning}, \textit{?person}) \wedge \textit{university}(\textit{?person},\textit{?uni})
\end{multline*}
The answer to the query is the variable assignment function. For several of the more restrictive fragments, it is useful to formulate the queries using this FOL syntax.

\begin{figure}[t]
	\centering
	\includegraphics[width=0.7\linewidth]{figs/query_pattern_venn.pdf}
	\caption{A space of query patterns and their relative expressiveness. 
		Multi-hop reasoning systems tackle the simplest \emph{Path} queries. Existing complex query answering systems support \emph{Tree} queries whereas \emph{DAG} and \emph{Cyclic} queries remain unanswerable by current neural models.}
	\label{fig:query_patterns}
\end{figure}

\paragraph{Restrictions}

\label{sec:multihop_vs_complex}
The first restriction one can introduce are \textbf{multi-hop queries}, known in the NLP and KG literature for a long time~\citep{guu-2015-traversing, das-2017-chains, Asai2020Learning} mostly in the context of question answering.
Formally, multi-hop queries (or \emph{path} queries) are \CQ\ which form a chain, where the tail of one projection is a head of the following projection, \ie,

\begin{equation*}
	q_{\text{path}} = V_k, \exists V_1, \dots, V_{k-1}: r_1(v, V_1) \wedge r_2(V_1, V_2) \wedge \dots \wedge r_k(V_{k-1}, V_k)
\end{equation*}

where $v \in \gE$, $\forall i \in [1, k]: r_i \in \gR, V_i \in \variable$ and all $V_i$ are existentially quantified variables.
In other words, path queries do not contain branch intersections and can be solved iteratively by fetching the neighbors of the nodes.
One could also define multi-hop queries which allow negation.


Other ways of restricting \CQ\ and on \CQn, resulting in more expressive queries than the multi-hop ones exist.
One can define families of logical queries shaped as a \emph{Tree}, a \emph{DAG}, and allowing \emph{cyclic} parts.
% 
Illustrated in \autoref{fig:query_patterns}, path (multi-hop) queries form the least expressive set of logical queries. 
Tree queries add more reasoning branches connected by intersection operators, DAG queries drop the query tree requirement and allow queries to be directed acyclic graphs, and, finally, cyclic queries further drop the acyclic requirement.
Note that these queries do not allow variables in the predicate position. 
Besides, all entities (in this context referred to as anchors) must occur before all variables in the topological ordering.

We elaborate more on these query types in \autoref{sec:query_pat} and note that the majority of surveyed neural \clqa methods in \autoref{sec:learning} are still limited to Tree-like queries, falling behind the expressiveness of many graph database query languages. 
Bridging this gap is an important avenue for future work.



\paragraph{Extensions}

\begin{figure}
	\centering
	\includegraphics[width=0.7\textwidth]{figs/fol_vs_sparql_venn_v5.pdf}
	%
	\caption{Current query answering models cover Existential Positive First Order (EPFO) and Existential First Order (EFO) logic fragments (marked in a red rectangle). EPFO and EFO are equivalent to unions of conjunctions (UCQ), and those with atomic negation (\UCQn), respectively. These, in turn, are a subset of first order logic (FOL). FOL queries, in turn, are only a subset of queries answerable by graph database languages. For example regular path queries cannot be expressed in FOL. Languages like SPARQL, SPARQL*, or Cypher, encompass all the query types and more.}
	\label{fig:fol_sparql_venn}
\end{figure}




The first extension we introduce is the \textbf{union}.

\begin{definition}[Union of Sets of Mappings]
	\label{def:union}
Given two sets of mappings (like $\mu$ from \autoref{def:basic_graph_query_answering}), we can create a new set of mappings by taking their union.
This union operator is commutative and associative, we can hence also talk about the union of three or more mappings. 
It is permissible that the domains of the mappings in the input sets are not the same.
\end{definition}
We can define a new type of query by applying the union operation on the outcomes of two or more underlying queries.
If these underlying queries are basic graph queries, we will call this new type of queries \textbf{Unions of Conjunctive Queries with negation (\UCQn)} and if the basic queries did not include negation, as \textbf{Union of Conjunctive Queries (\UCQ)}.
These classes are also familiar from FOL, and indeed correspond to a disjunction of conjunctions. 

As an example, the following query is in \UCQn\xspace because it is a disjunction of conjunctive terms which consist of atoms $a_i$ that are relation projections or their negations:
\begin{equation*}
	q = v_?.\exists v_1, \dots, v_n : \Big(\underbrace{r_1(c, v_1)}_{a_1} \wedge \underbrace{r_2(v_1, v_2)}_{a_2}\Big) \vee \Big(\underbrace{\lnot r_3(v_2, v_3)}_{a_3}\Big) \vee \dots \vee \underbrace{r_k(v_n, v_?)}_{a_m} 
\end{equation*}

Moreover, there are FOL fragments that are equivalent to these fragments.
Specifically, all queries in \textbf{EPFO}, which are Existential Positive First Order sentences, have an equivalent query in \UCQ, and all queries in \textbf{EFO}, Existential First Order sentences, have an equivalent query in \UCQn.
The reason is that EPFO and EFO sentences can be written in the Disjunctive Normal Form (DNF) as a union of conjunctive terms. 

Some query languages, like SPARQL, allow an optional part to a query. In our formalism, we can define the \textbf{optional} part using the union operator.
%
Assuming there are $n$ optional parts in the query, create $2^n$ different queries, in which other combinations of optional parts are removed.
The answer to the query is then the union of the answers to all those queries.
If the query language already allowed unions, then optionals do not make it more expressive.

Beyond these extensions, one could extend further to \textbf{all queries one could express with FOL}, which requires either universal quantification, or negation of conjunctions. These are, however, still not all possible graph queries.
An example of interesting queries, which are not in FOL, are \textbf{conjunctive regular path queries}.
These are akin to the path queries we discussed above, but without a specified length.

\begin{definition}[Regular Path Query]
	\label{def:regular_path_query}
A regular path query is a 3-tuple $(s, R, t)$, where $s \in \term$ the starting term of the path,  $R \in \term$ the relation term of the path, and $t\in \term$ the ending term of the path.
The query represents a path starting in $s$, traversing an arbitrary number of edges of type $R$  ending in $t$.
\end{definition}

Because this kind of query is a conjunction of an arbitrary length, it cannot be represented in FOL.
If one wants to express paths with a fixed length, this would be a multi-hop path like the one described above.
If one wants to express a maximum length, then this could be done using a union of all allowed lengths.
For the two latter cases, the query can still be expressed in $EPFO$.

\begin{definition}[Regular Path Query Answering]
	\label{def:regular_path_query_answering}
Given a knowledge graph $\gG$ and a regular path query $\gQ=(s, R, t)$.  
An answer to the query is any mapping $\mu : \variable_Q \to \con$ , such that if we replace all variables $v$ in $\gQ$ with $\mu(v)$, obtaining $(\hat{s}, \hat{R}, \hat{t})$, there exists a path in the graph that starts at node $\hat{s}$, then traverses one or more edges of type $\hat{R}$, and ends in $\hat{t}$.
The set of all answers to the query is the set of all such mappings.
\end{definition}

There exist several variations on regular path queries and they can also be combined with the above query types to form new ones.
%
In \autoref{fig:fol_sparql_venn} we illustrate how the fragments relate to other query classes.
Most methods fall strictly within the EFO fragment, \ie, they only support a subset with restrictions as we discussed above.
We will discuss further limitations of these methods in \autoref{sec:queries}. 

Two final aspects we want to highlight here are \emph{projections} and \emph{joins}.

\begin{definition}[Projection of a Query Answer]
	\label{def:projection}
	Given a query answer $\mu$, and a set of variables $\gV \in \variable$.
	The projection of the query answer on the variables $\gV$ is
	$\{  (var, val | (var, val) \in \mu, var \in \gV  \}$.
\end{definition}
In other words, it is the answer but restricted to a specific set of variables. 
The query forms introduced above can all be augmented with a projection to only obtain values for specific variables. %, by projecting all answers in their answer sets.
This corresponds to the \texttt{SELECT ?var} clause in SPARQL. Alternatively, it is possible to project all variables in $\gV$ which is equivalent to the \texttt{SELECT *} clause.
A query without any projected variable is a Boolean subgraph matching problem equivalent to the \texttt{ASK} query in SPARQL.

A join is used to combine the results of two separate queries into one.
Specifically,

\begin{definition}[Join of Query Answers]
Given two query answers $\mu_A$ and $\mu_B$, and $\variable_A$, and $\variable_B$ the variables occurring in $\mu_A$ and $\mu_B$, respectively.
The join of these two answers only exists in case they have the same value for all variables they have in common, \ie, $\forall var \in \variable_A \cap \variable_B: \mu_A(var) = \mu_b(var) $.
In that case, $\join(\mu_A, \mu_B) = \mu_A \cup \mu_B$. 
\end{definition}

Given two sets of answers, their join is defined as follows.
\begin{definition}[Join of Query Answer Sets]
	\label{def:join}
Given two sets of query answers A and B, the join of these two is a new set 
$\join(A, B) = \{ \join(a,b) | a \in A, b \in B, \text{and} \: \join(a,b) \: \text{exists} \}$.
\end{definition}
This operation enables us to combine multiple underlying queries, potentially of multiple types into a single one.
For example, given the set of answers from our example basic graph query above:
	\[
	A=\{
	\{(\textit{?person}, \texttt{Hinton}), (\textit{?uni}, \texttt{UofT})\}, 
	\{(\textit{?person}, \texttt{Bengio}), (\textit{?uni}, \texttt{UdeM})\}, 
	\{(\textit{?person}, \texttt{LeCun}), (\textit{?uni}, \texttt{NYU})\} 
	\}
	\]
	and another set of answers 
	\[
	B=\{
	\{(\textit{?person}, \texttt{Hinton}), (\textit{?born}, \texttt{1947})\}, 
	\{(\textit{?person}, \texttt{Bengio}), (\textit{?born}, \texttt{1964})\}, 
	\{(\textit{?person}, \texttt{Welling}), (\textit{?born}, \texttt{1968})\} 
	\}
	\]
	The join of these becomes:
	\[
	\join(A, B) = \{
	\{(\textit{?person}, \texttt{Hinton}), (\textit{?uni}, \texttt{UofT}), (\textit{?born}, \texttt{1947})\}, 
	\{(\textit{?person}, \texttt{Bengio}), (\textit{?uni}, \texttt{UdeM}), (\textit{?born}, \texttt{1964})\}
	\}
	\]


We will discuss joins further in \autoref{sec:query_ops}, where we will use these basic building blocks to define a broader set of query operators, aiming to cover all operations that exist in SPARQL. 
This includes 
%conjunction ($\wedge$), disjunction ($\vee$), negation ($\neg$), 
Kleene plus/star (+/*) for building property paths, FILTER, OPTIONAL, and different aggregation functions. 


\subsection{Approximate Graph Query Answering}




Now that we have defined what Basic Approximate Graph Query Answering is, we can define what we mean by the more general Approximate Graph Query Answering.
The definition of Approximate Graph Query Answering is the same as the basic case, but rather than only providing answers to basic queries, it is about answering a broader set of query types.
%
\begin{definition}[Approximate Graph Query Answering]\label{def:approx_gqa}
Given a knowledge graph $\gG$, subgraph of a complete, but not observable knowledge graph $\hat{\gG}$, a query formalism, \textbf{any} graph query $\gQ$ according to that formalism, and the scoring domain \scoredomain.

An approximate graph query answer to the query $\gQ$ is a function $f$ which maps every possible mapping ($\mu : \variable_Q \to \con$) to \scoredomain.
\end{definition}
Note there that the variables are not always mapped to nodes which occur in the graph.
It is well possible that the query contains an aggregation function which results in a literal value.


%\todo[inline]{check the following paragraph}
In the literature, we can find the concepts of \emph{easy} and \emph{hard} answers. This refers to whether the answers can be found by only having access to $\gG$ or not.

\begin{definition}[Easy and Hard answers]\label{def:easy_hard_ans}
    Given a knowledge graph $\gG$, subgraph of a larger unobservable graph $\hat{\gG}$, and a query $\gQ$.
    Easy and hard answers are defined in terms of exact query answering (\autoref{def:graph_query_answering}).
    The set of \textbf{easy} answers is the intersection of the answers obtained from $\gG$, and those from $\hat{\gG}$.
    The set of \textbf{hard} answers is the set difference between the answers from $\hat{\gG}$ and those from $\gG$.
\end{definition}

Note the asymmetry in the definitions.
Easy answers are those that can be found in both $\gG$ and $\hat{\gG}$.
Hard answers are those that can be found only in $\hat{\gG}$ but not in $\gG$.
For Basic Graph Queries (\autoref{def:basic_graph_query}), all easy answers can also be found from $\hat{\gG}$.
However, for some more complex query types (\eg, these which allow negation) there could also be answers which  in $\gG$ which are not in $\hat{G}$.
We call these answers \textbf{false positives} in the context of answering over $\hat{\gG}$.



\subsection{Triangular Norms and Conorms}
\label{sec:tnorms}

Answering logical queries implies execution of logical operators. 
Approximate query answering, in turn, implies continuous vector inputs and output truth values that are not necessarily binary.
Besides, the methods often require that the logical operators are smooth and differentiable.
Triangular norms (T-norms) and triangular conorms (T-conorms) define functions that generalize logical conjunction and disjunction, respectively, to the continuous space of truth values and implement fuzzy logical operations.

T-norm defines a continuous function $\top: [0,1]\times [0,1] \to [0,1]$ with the following properties $\top(x,y)=\top(y,x)$ (commutativity), $\top(x, \top(y,z))=\top(\top(x,y),z)$ (associativity), and $y\leq z \to \top(x,y)\leq \top(x,z)$ (monotonicity). Also, we have 1 to be the identity element for $\top$, \ie, $\top(x,1)=1$. The goal of t-norms is to generalize logical conjunction with a continuous function. T-conorm can be seen as a duality of a t-norm that similarly defines a function $\bot$ with the same domain and range $\bot: [0,1]\times [0,1]\to [0,1]$. T-conorms use the continuous function $\bot$ to generalize disjunction to fuzzy logic. The function $\bot$ satisfies the same commutativity, associativity, and monotonicity properties as $\top$ with the only difference being 0 is the identity element, \ie, $\bot(x,0)=x$.

There exist many triangular norms, conorms, and  fuzzy negations~\citep{tnorm,vankrieken_fuzzy} that stem from the corresponding logical formalisms, \eg, 
%
(1) \emph{G\"odel logic} defines t-norm: $\top_{\text{min}}(x,y)=\text{min}(x,y)$, t-conorm: $\bot_\text{max}(x,y)=\max(x, y)$; (2) \emph{Product logic} with t-norm: $\top_\text{prod}(x,y)=x\cdot y$, t-conorm: $\bot_\text{prod}(x,y)=x+y-x\cdot y$; (3) in the \emph{\L{}ukasiewicz logic} t-norm: $\top_{\text{\L{}uk}}(x, y)= \max(x+y-1, 0)$, t-conorm: $\bot_{\text{\L{}uk}}(x,y)=\min(x+y, 1)$. 
Using fuzzy negation $N(x)= 1-x$, it is easy to verify that 
%$\bot(x,y)=N(\top(N(x), \top(N(y)))$
$\bot(x,y)=N(\top(N(x), N(y)))$
(De Morgan's laws) naturally obtaining a pair of $(\top, \bot)$. 

\subsection{Graph Representation Learning}
\label{sec:grl} 

Graph Representation Learning (GRL) is a subfield of machine learning aiming at learning low-dimensional vector representations of graphs or their elements such as single nodes~\citep{hamilton2020graph}.
For example, $\Em{h}_v \in \RR^d$ denotes a $d$-dimensional vector associated with a node $v$. 
Conceptually, we want nodes that share certain structural and semantic features in the graph to have similar vector representations (where similarity is often measured by a distance function or its modifications).

\paragraph{Shallow Embeddings}
The first GRL approaches focused on learning shallow node embeddings, that is, learning a unique vector per node directly used in the optimization task. 
For homogeneous (single-relation) graphs, DeepWalk~\citep{deepwalk} and node2vec~\citep{node2vec} trained node embeddings on the task of predicting walks in the graph whereas in multi-relational graphs TransE~\citep{transe} trained node and edge type embeddings in the autoencoder fashion by reconstructing the adjacency matrix.

\paragraph{Graph Neural Networks}
%

The idea of \emph{graph neural networks} (GNNs)~\citep{scarselli2008graph} implies learning an additional neural network encoder with shared parameters on top of given (or learnable) node features by performing neighborhood aggregation. 
This framework can be generalized to \emph{message passing}~\citep{Gilmer2017} where at each layer $t$ a node $v$ receives messages from its neighbors (possibly adding edge and graph features), aggregates the messages in the permutation-invariant way, and updates the representation:

\begin{align*}
    \Em{h}_v^{(t)} = \textsc{Update}\Big(\Em{h}_v^{(t-1)}, \textsc{Aggregate}_{u \in \gN(v)}\big( \textsc{Message}(\Em{h}_v^{(t-1)}, \Em{h}_u^{(t-1)}, \Em{e}_{uv})) \big)  \Big)
\end{align*}

Here, $\Em{h}_u$ is a feature of the neighboring node $u$, $\Em{e}_{uv}$ is the edge feature, \textsc{Message} function builds a message from node $u$ to node $v$ and can be parameterized with a neural network. 
As the set of neighbors $\gN(v)$ is unordered, \textsc{Aggregate} is often a permutation-invariant function like \emph{sum} or \emph{mean}. 
The \textsc{Update} function takes the previous node state and aggregated messages of the neighbors to produce the final state of the node $v$ at layer $t$ and can be parameterized with a neural network as well.

Classical GNN architectures like GCN~\citep{Kipf2017}, GAT~\citep{Velickovic2018}, and GIN~\citep{Xu2019} were designed to work with homogeneous, single-relation graphs. Later, several works have developed GNN architectures that work on heterogeneous graphs with multiple relations~\citep{rgcn,compgcn,zhu2021neural}.
GNNs and message passing paved the way for \emph{Geometric Deep Learning}~\citep{bronstein2021geometric} that leverages symmetries and invariances in the input data as inductive bias for building deep learning models. 

