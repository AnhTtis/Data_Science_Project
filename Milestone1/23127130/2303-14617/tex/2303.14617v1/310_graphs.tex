\clearpage
\begin{figure}[!ht]
    \centering
    \begin{adjustbox}{height=0.9\textheight}
      \input{tikz/taxonomy}
    \end{adjustbox}
    \caption{The Neural Query Engine Taxonomy consists of three main branches -- Graphs, Modeling, and Queries. We describe each branch in more detail including prominent examples in the relevant sections.}
    \label{fig:taxonomy}
\end{figure}

\section{Graphs}
\label{sec:graphs}

The \emph{Graphs} category covers the underlying graph structure ($\gG$ in Definition~\ref{def:basic_approx_gqa}) against which complex queries are sent and the answers are produced. 
Understanding the graph, its contents and modeling paradigms is crucial for designing query answering models. 
To this end, we propose to analyze the underlying graph from three aspects: \emph{Modality}, \emph{Reasoning Domain}, and \emph{Background Semantics}.

\subsection{Modality}
\label{sec:modality}



We highlight four modalities common for KGs and graph databases: standard \textbf{triple-based KGs} adhering to the RDF data model, \textbf{hyper-relational KGs} following the RDF-star or Labeled Property Graph (LPG) formats, and \textbf{hypergraph KGs} (we elaborate on choosing an appropriate modeling paradigm in \autoref{sec:storage}).
The difference among the three modalities is illustrated in \autoref{fig:modality}.
Additionally, we outline \textbf{multi-modal KGs} that contain not just a graph of nodes and edges, but also text, images, audio, video, and other data formats linked to the underlying graph explicitly or implicitly.


We categorize the literature along the Modality aspect in \autoref{tab:modality}.
To date, most query answering approaches operate solely on \textbf{triple-based} graphs.
Among approaches supporting \textbf{hyper-relational} graphs, we are only aware of StarQE~\citep{starqe} that incorporates entity-relation \emph{qualifiers} over labeled edges and its extension NQE~\citep{nqe}. 
We posit that the hyper-relational model might serve as a theoretical foundation of temporal query answering approaches since temporal attributes are in fact continuous key-value edge attributes.
To date, we are not aware of complex query answering models supporting \textbf{hypergraphs} or \textbf{multi-modal} graphs. 
We foresee them as possible area of future research in the area. 



\input{tables/tab_modality}

\subsection{Reasoning Domain}
\label{sec:domain}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=\linewidth]{figs/nqe_reasoning_domain.pdf}
	\caption{Reasoning Domains. The \emph{Discrete} domain only allows entities and relations as constants, variables, and answers. The \emph{Discrete + Time} domain extends the space to discrete timestamps and time-specific operators. The \emph{Discrete + Continuous} domain allows continuous inputs (literals) and outputs.}
	\label{fig:reasoning_domain}
\end{figure}

Following Definition~\ref{def:basic_graph_query_answering}, a query $\gQ$ includes constants $\con$, variables $\variable$, and returns \emph{answers} as mappings $\mu: \variable_Q \rightarrow \con$.
By \emph{Reasoning Domain} we understand a space of possible constants, variables, and answers, that is, what query answering models can reason about.
We highlight three common domains (\emph{Discrete}, \emph{Discrete + Time}, \emph{Discrete + Continuous}), illustrate them in \autoref{fig:reasoning_domain}, and categorize existing works in \autoref{tab:reasoning_domain}. 
Each subsequent domain is a superset of the previous domains, \eg, \emph{Discrete + Continuous} includes the capabilities of \emph{Discrete} and \emph{Discrete + Time} and expands the space to continuous inputs and outputs.

In the \emph{Discrete} domain, constants, variables, and answers can be entities $\gE$ and (or) relation types $\gR$ of the KG, $\con \subseteq \gE \cup \gR$, $\variable \subseteq \gE \cup \gR$, $\mu \subseteq \gE \cup \gR$.
%$A_{\gG}(\gQ) \subseteq \gE \cup \gR$. 
That is, input queries may only contain entities (or relations) and their answers are only entities (or relations). 
For example, a query $?x: \mathtt{education}(\mathtt{Hinton}, x)$ in \autoref{fig:reasoning_domain} can only return two entities $\mathtt{\{Edinburgh, Cambridge\}}$ as answers.
Conceptually, the framework allows relation types $r \in \gR$ to be variables as well describing, for example, a SPARQL graph pattern \texttt{\{Hinton ?r Cambridge\}} -- or $?r: r(\mathtt{Hinton}, \mathtt{Cambridge})$ in the functional form -- that returns all relation types between two nodes \texttt{Hinton} and \texttt{Cambridge}.
However, to the best of our knowledge, the majority of existing query answering literature and datasets limit the space of constants, variables, and answers to entities-only, $\con \subseteq \gE$, $\variable \subseteq \gE$, $\mu \subseteq \gE$ and all relation types are given in advance (we discuss queries structure in more detail in \autoref{sec:queries}).
To date, most of the literature in the field 
belongs to the \emph{Discrete} reasoning domain (\autoref{tab:reasoning_domain}).

Some nodes and edges might have \emph{timestamps} from a set of discrete timestamps $t \in \mathcal{TS}$ indicating a validity period of a certain statement. 
In a more general case, certain subgraphs might be timestamped. 
We define the \emph{Discrete + Time} domain when queries include temporal data. 
In this domain, the set of constants is extended with timestamps $\con \subseteq \gE \cup \gR \cup \mathcal{TS}$ and relation projections might be instantiated with a certain timestamp $R_t(a,b)$.
For instance (\autoref{fig:reasoning_domain}), given a timestamped graph and a query $?x: \mathtt{education}_{\mathtt{year}==1973}(\mathtt{Hinton}, x)$, the answer set includes only \texttt{Edinburgh} as the timestamp $1973$ falls into the validity period of only one edge.

It is possible to extend the domain of variables and query answers with timestamps as well, $\variable, \mu \subseteq \gE \cup \gR \cup \mathcal{TS}$, such that queries might employ timestamps as intermediate existentially quantified variables and possible answers can be entities or timestamps.
%
This approach is followed by the Temporal Feature-Logic Embedding Framework (TFLEX) by \citet{lin2022tflex} that defines additional operators \textbf{before}, \textbf{after}, \textbf{between} over edges with discrete timestamps. 

Finally, the most expressive domain is \emph{Discrete + Continuous} that enables reasoning over continuous inputs (such as numbers, texts, continuous timestamps) often available as node and edge attributes or \emph{literals}. 
%
Formally, for numerical data, the space of constants, variables, and answers is extended with real numbers $\RR$, \ie, $\con, \variable, \mu \subseteq \gE \cup \gR \cup \mathcal{TS} \cup \RR$.
An example query in \autoref{fig:reasoning_domain} $?x: \mathtt{education}(\mathtt{Hinton}, x) \land x.\mathtt{students} < 30000$ includes a conjunctive term $x.\mathtt{students} < 30000$ that requires numerical reasoning over the \texttt{students} attribute of a variable $x$ to produce the answer  \texttt{Cambridge}. 
In a similar fashion, extending the answer set to continuous outputs can be framed as a regression task.
To date, we are not aware of any complex query answering approaches capable of working in the continuous domain. %
Still, the ability to reason over continuous data is crucial for query answering given that most real-world KGs heavily rely on literals.


\input{tables/tab_reasoning_domain}

\subsection{Background Semantics}
\label{sec:bg_sem}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=\linewidth]{figs/nqe_bg_semantics.pdf}
	\caption{Background Semantics. \emph{Facts-only} are graphs that only have assertions (\abox) and have no higher-level schema. \emph{Class Hierarchy} introduces node types (classes) and hierarchical relationships between classes. Finally, \emph{Complex Axioms} add even more complex logical rules (\tbox) governed by certain OWL profiles, \eg, \emph{A professor is someone who has one or more students and works at university.}}
	\label{fig:bg_sem}
\end{figure}

Relational databases often contain a \emph{schema}, that is, a specification of how tables and columns are organized that gives a high-level overview of the database content.
In graphs databases, schemas exist as well and might describe, for instance, node types are common in the Labeled Property Graph (LPG) paradigm. 
RDF graphs, however, might provide an additional layer of logical consistence by employing standards based on \emph{Description Logics}~\citep{baader2003description}. 
As incorporating schema is crucial for designing effective query answering ML models, we introduce the \emph{Background Semantics} (\autoref{fig:bg_sem}) as the notion of additional schema information available on top of plain facts (statements).

\paragraph{Facts-only.} In the simplest case, there is no background schema such that a KG consists of statements (facts) only, that is, a KG follows Definition~\ref{def:kg}, $\gG = (\gE, \gR, \gS)$. 
In terms of description logics, a graph only has \emph{assertions} (\abox). 
Queries, depending on the Reasoning Domain (\autoref{sec:domain}), involve only entities, relations, and literals.
The original GQE~\citep{gqe} focused on facts-only graphs and the majority of subsequent query answering approaches (\autoref{tab:bg_semantics}) operate exclusively on schema-less KGs.

\paragraph{Class Hierarchy.} 
Classes of entities, or node types, are a natural addition to a facts-only graph as a basic schema. 
Extending Definition~\ref{def:kg} with a set of types $\gT$, a graph $\gG$ is defined as $\gG = (\gE, \gR, \gS, \gT)$. 
Each entity $e$ might have one or more associated classes $\textit{type}(e) = \{ t_1, \dots, t_k \} | t \in \gT$.
Both LPG and RDF graphs support classes albeit in RDF it is possible to specify hierarchical relationships between classes using RDF Schema (RDFS)~\citep{brickley2014rdf}\footnote{RDFS has more expressive means (\eg, a hierarchy of relations)  but we leave them to \emph{Complex Axioms}}.
Formally, types become explicit nodes in a graph, and statements $\gS$ can now have types as subjects or objects, $\gS \subset ((\gE \cup \gT) \times \gR \times (\gE \cup \gT))$, or other statement elements in graphs of other modalities.
Practically, edges involving types might be present physically in a KG or be considered as an additional supervised input to a particular model.

To date, we are aware of three query answering approaches (\autoref{tab:bg_semantics}) that incorporate entity types.
Contextual Graph Attention (\textsc{CGA}, \citet{cga}) only uses types for entity embedding initialization and requires each entity to have only one type. 
The queries are not conditioned by entity types and the answer set still includes entities only. 
That is, query constants, variables, and the answer set follow  $\con \subseteq \gE, \variable \subseteq \gE, \mu \subseteq \gE$. 

In Type-Aware Message Passing (\textsc{Temp}, \citet{temp2022}), type embeddings are used to enrich entity and relation representations that are later sent to a downstream query answering model. 
Each node might have several types. 
In the inductive scenario (we elaborate on inference scenarios in \autoref{sec:trans_ind}) with unseen nodes at inference time, type and relation embeddings are learned \emph{invariants} that transfer across training and inference entities.
Query-wise, constants, variables, and the answer set are still limited to entities only.

The \tbox\xspace and \abox\xspace Neural Reasoner (\textsc{TAR}, \citet{abin_abductive2022}) incorporates types and their hierarchy to improve predictions over entities as well as introduces a task of predicting types of answer entities, that is, $\mu \subseteq (\gE \cup \gT)$. 
Constants and variables are still entity-only such that using types as query variables is not allowed.
The class hierarchy in \textsc{TAR} is used in three auxiliary losses besides the original entity prediction, that is, \emph{concept retrieval} -- prediction of the answer set of types, \emph{subsumption} -- predicting which type is a subclass of another type, and \emph{instantiation} -- predicting a type for each entity.

A natural next step for the \emph{Class Hierarchy} family of approaches is to incorporate types in queries in the form of constants and variables, $\con \subseteq (\gE \cup \gT), \variable \subseteq (\gE \cup \gT)$.


\paragraph{Complex Axioms.}
Finally, a schema might contain not just a class hierarchy but a set of more complex axioms involving, for example, a hierarchy of relations, qualified restrictions on relations, or composite classes. 
Such a complex schema can now be treated as an \emph{ontology} $\gO$ that extends the definition of the graph $\gG = (\gE, \gR, \gS, \gO)$.
In \autoref{fig:bg_sem}, the axiom $\texttt{Professor} \sqsubseteq \: \geq1 \: \textit{hasStudent} \sqcap \forall\textit{works}.\texttt{University}$ describes that \emph{A professor is someone who has one or more students and works at university.}
In terms of description logics, a graph has an additional \emph{terminology} component (\tbox). 
The expressiveness of \tbox\xspace directly affects the complexity of symbolic reasoning engines up to exponential (\textsc{ExpTime}) for most expressive fragments.
To alleviate this issue, ontology languages (like Web Ontology Language, OWL) specify less expressive but computationally feasible \emph{profiles}, e.g., OWL 2 introduces three profiles \emph{OWL EL}, \emph{OWL QL}, \emph{OWL RL}~\citep{motik2009owl}. \emph{OWL-QL}, in turn, is loosely connected to the $\textit{DL-Lite}_{\gR}$ ontology language~\citep{artale2009dl}.

In graph representation learning, incorporating complex ontological axioms is non-trivial even for simple link prediction models~\citep{zhang2022_logic_emb_survey}.
In the query answering literature, the only attempt to include complex axioms is taken by \citet{q2b_onto}. 
In Q2B Onto (O2B), an extension of Query2Box (Q2B, \cite{q2b}), the set of considered complex axioms belongs to the $\textit{DL-Lite}_{\gR}$ fragment and supports the hierarchy of classes (\emph{subclasses}), the hierarchy of relations (\emph{subproperties}), as well as \emph{range} and \emph{domain} of relations.
The model architecture is not directly conditioned on the axioms and remains the original Query2Box. 
Instead, the axioms affect the graph structure, query sampling, and an auxiliary loss, that is, \emph{query rewriting} mechanisms are used to materialize more answers to original queries as if executed against the complete graph (\emph{deductive closure}) akin to data augmentation.
During optimization, an auxiliary regularization loss aims at including a specialized query box %
$q$ into the  more general version of this query $q'$.

Still, even the expensive procedure of incorporating complex axioms in query sampling in O2B benefits mostly the \emph{deductive} capabilities of query answering, that is, inferring answers that are already implied by the graph $\gG$ and ontology $\gO$, and does not improve the \emph{generalization} capabilities when missing edges cannot be inferred by ontological axioms. 
We elaborate on \emph{deductive}, \emph{generalization}, and other setups in \autoref{sec:datasets}. 

Another avenue for future work is a better understanding of theoretical expressiveness of Graph Neural Network (GNN) encoders when applied to multi-relational KGs. 
Initial works on non-relational graphs~\citep{Barcelo2020logic} map the expressiveness to the $\text{FOC}_2$ subset of FOL with two variables and counting quantifiers, and to $\text{FOC}_B$~\citep{luo2022on} for hypergraphs of maximum arity $B$. 
In relational graphs, \citet{rwl} quantified the expressiveness of relational GNNs in terms of the \emph{relational Weisfeiler-Leman} (RWL) test proving that RWL is more expressive than classical WL test~\citep{wl1968} and that common relational GNN architectures like R-GCN~\citep{rgcn} and CompGCN~\citep{compgcn} are bounded by 1-RWL.
Using RWL, \citet{huang2023theory} derive that the family of GNNs conditioned on the query node, such as Neural Bellman-Ford Networks~\citep{zhu2021neural}, are bounded by the asymmetric local 2-RWL and expressive as $\text{rGFO}^3_{\text{cnt}}$, restricted guarded first-order logic fragment with three variables and counting.
Concurrently, \citet{gao2023double} study KGs as double permutation equivariant structures (to permuting nodes and edge types) and map their expressiveness to universally quantified entity-relation (UQER) Horn clauses.
However, it is still an open question if GNNs can capture OWL-like axioms and leverage them as an inductive bias in complex query answering.

\input{tables/tab_bg_semantics}

