\documentclass[twocolumn]{autart}
\let\theoremstyle\relax% Enable this line and disable the 
                                     % preceding line to obtain a two-column 
                                     % document whose style resembles the
                                     % printed Automatica style.

\usepackage{graphicx,comment}          % Include this line if your 
                               % document contains figures,
%\usepackage[dvips]{epsfig}    % or this line, depending on which
                               % you prefer.
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
%\usepackage[sorting=none]{biblatex} %Imports biblatex package
\usepackage{amsfonts}
% \usepackage[capitalize,noabbrev]{cleveref}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage[numbers]{natbib}
\usepackage{algpseudocode}
\usepackage{mathtools}
\usepackage{xcolor}
\usepackage{enumitem}

\usepackage[dvipsnames]{xcolor}
\usepackage{tikz}
\usetikzlibrary{3d,calc}
\usepackage{geometry,graphicx}
\usepackage{pgfplots}
\usepackage{bm}
\usepgfplotslibrary{fillbetween}
\usetikzlibrary{arrows.meta,hobby,tikzmark}

\newcommand{\tr}{^\intercal}
\newcommand{\norm}[1]{\left\| #1 \right\|}

\newcommand{\ani}[1]{{\color{red} Anil: #1}}

\newcommand{\diagentry}[1]{\mathmakebox[1.8em]{#1}}
\newcommand{\xddots}{%
  \raise 4pt \hbox {.}
  \mkern 6mu
  \raise 1pt \hbox {.}
  \mkern 6mu
  \raise -2pt \hbox {.}
}

\newcommand{\rvline}{\hspace*{-\arraycolsep}\vline\hspace*{-\arraycolsep}}

\DeclarePairedDelimiterX{\Set}[2]\{\}{%
  \, #1 \;\delimsize\vert\; #2 \,
}

\newtheorem{Theorem}{Theorem}
\newtheorem{Assumption}{Assumption}
\newtheorem{Definition}{Definition}
\newtheorem{Proposition}{Proposition}
\newtheorem{Lemma}{Lemma}
\newtheorem{Remark}{Remark}
\allowdisplaybreaks
\begin{document}

\begin{frontmatter}
%\runtitle{Insert a suggested running title}  % Running title for regular 
                                              % papers but only if the title  
                                              % is over 5 words. Running title 
                                              % is not shown in output.

\title{One perturbation is sufficient: A closed loop approach to robust MPC design \thanksref{footnoteinfo}} 

% One perturbation is sufficient: A closed loop approach to recursive feasibility in robust MPC 
% One perturbation is sufficient: recursive feasibility of MPC using receding horizon invariance  

\thanks[footnoteinfo]{This work was supported by the Swiss National Science Foundation under Grant 200021\_178890 and NCCR Automation Grant 180545.}

% \author[Paestum]{Marcus Tullius Cicero}\ead{cicero@senate.ir},    % Add the 
% \author[Rome]{Julius Caesar}\ead{julius@caesar.ir},               % e-mail address 
% \author[Baiae]{Publius Maro Vergilius}\ead{vergilius@culture.ir}  % (ead) as shown

% \address[Paestum]{Buckingham Palace, Paestum}  % Please supply                                              
% \address[Rome]{Senate House, Rome}             % full addresses
% \address[Baiae]{The White House, Baiae}        % here.
\author[First]{Anilkumar Parsi}\ead{aparsi@control.ee.ethz.ch},
\author[First]{Marcell Bartos} \ead{mbartos@student.ethz.ch},
\author[First]{Amber Srivastava}\ead{asrivastava@control.ee.ethz.ch},
\author[Second]{Sebastien Gros}\ead{sebastien.gros@ntnu.no},
\author[First]{Roy S. Smith}\ead{rsmith@control.ee.ethz.ch}

\address[First]{Automatic Control Laboratory, ETH Zurich, Switzerland}   
\address[Second]{Department of Engineering Cybernetics, Norwegian University of Science and Technology (NTNU) Trondheim, Norway}          
\begin{keyword}                           
	Model predictive and optimization-based control; Robust controller synthesis;  Linear multivariable systems ; 	Constrained control;  	 	Robustness analysis
\end{keyword}                            

\begin{abstract}                          % Abstract of not more than 200 words.
A novel perspective on the design of robust model predictive control (MPC) methods is presented, 
whereby closed loop constraint satisfaction is ensured using recursive feasibility of the MPC optimization. 
Necessary and sufficient conditions are derived for recursive feasibility, based on the effects of perturbations occurring at {\em one} time step. Using these conditions and Farkas' lemma, sufficient conditions suitable for design are formulated. The proposed method is called a closed loop design, as only the existence of feasible inputs at the next time step is enforced by design. 
%The proposed method is called a closed loop design, because executable control policies are not explicitly computed in the offline phase, but their existence is enforced by design.
%because only existence of feasible inputs is enforced in the offline design phase, but the inputs are not explicitly computed.
This is in contrast to most existing formulations, which compute control policies that are feasible along the prediction horizon, even under the worst-case realizations of all perturbations in the horizon.
%which consider the worst-case open loop realizations of all perturbations in the prediction horizon of MPC
The proposed method has an online computational complexity similar to nominal MPC methods while preserving guarantees of constraint satisfaction, recursive feasibility and stability. Numerical simulations demonstrate the efficacy of our proposed approach.


% A novel perspective on the design and analysis of Model Predictive Control (MPC) methods is presented, whereby closed loop constraint satisfaction is ensured using recursive feasibility of the MPC optimization. Necessary and sufficient conditions are derived for recursive feasibility based only on the effects of the perturbations occurring at {\em one} time step. This contrasts with most existing methods that consider the worst-case open loop realizations of {\em all} the perturbations in the prediction horizon to derive the above conditions. Thus, resulting into lesser conservatism in our proposed approach. Further, using the above conditions and Farkas' lemma, sufficient conditions suitable for design are formulated. The existence of feasible inputs is enforced in the offline design phase, however, the actual inputs are computed online via a closed loop design strategy. The proposed method has an online computational complexity similar to nominal MPC methods while preserving guarantees of constraint satisfaction, recursive feasibility and stability. The simulations demonstrate the efficacy of our proposed approach.
\end{abstract}

\end{frontmatter}

\section{Introduction}
Sequential decisions are ubiquitous in engineering design problems. Applications such as smart buildings, robotics and power electronics \cite{roijers2013survey} involve making sequential decisions, where the underlying models are often characterized as discrete-time controlled dynamical systems. In such a description of the dynamics, the system transitions from one state to another based on a control policy, incurring a pre-defined cost. The objective is to design a control policy that minimizes the cumulative cost incurred over large time horizons, subject to suitable constraints on the state and control input. 
Prior literature provides extensive frameworks to address these problems, such as dynamic programming, optimal control \cite{liberzon2011calculus}, Markov decision processes \cite{bertsekas1996neuro}, and model predictive control \cite{borelli2017model}; and the choice of the framework is governed by the application at hand as well as the individual capabilities of the framework. 

Amidst the existing frameworks, model predictive control (MPC) is a powerful control design technique that can efficiently handle (deterministic and probabilistic) constraints on the system states and control inputs, while also guaranteeing the stability of the system \cite{borelli2017model}. In particular, MPC poses the control design as an optimization problem, where it optimizes a suitable objective function subject to the constraints resulting from the system's dynamics, and admissible system states and control inputs. The optimization problem is solved at each time step to compute an open loop input sequence over a finite number of time steps (called the prediction horizon), of which only the first input is applied in closed loop. A popular approach in practice is to use an approximate linear model of the system, as it results in convex optimization problems suitable for real-time implementation \cite{darby2012mpc}. Such an approximation can be compensated for, by introducing structured uncertainty into the model. % Additionally, such a description of the dynamics allows one to consider unaccounted external disturbances and the inherent uncertainty in system identification methods \cite{Ljung1999}.

%the dynamical evolution of the system. Most often, the latter dynamical evolutions are governed by an inexact (data-driven) linear model of the system obtained using techniques in system identification [XX], where the inexactness arises from the uncertainty of the estimated model, or unaccounted external disturbances. 
%For instance, in the case of linear systems with an additive disturbance on the state dynamics, a popular approach is to determine a sequence of control laws that drive the system to a terminal set, where this terminal set is designed to be invariant under a linear feedback and lies in the permitted state and control input space.

Robust MPC algorithms explicitly consider the effects of uncertainties in the controller design \cite{kouvaritakis2015model} so that closed-loop stability and constraint satisfaction can be guaranteed. In addition to these properties, an important consideration for MPC is that the optimization problem remains feasible in closed loop operation, which is known as recursive feasibility \cite{kerrigan2001robust_PHD,lofberg2012oops}. The design of robust MPC thus has three desired properties: (i) constraint satisfaction, (ii) recursive feasibility, and (iii) closed loop stability. The main concern of this paper is (i) and (ii), and to highlight that the design for (ii) already implies (i). %The property (iii) is also guaranteed by our work, and can be achieved using standard robust MPC arguments \cite{kouvaritakis2015model}.

The design for (i) and (ii) is coupled in most existing MPC works and follows an open loop approach. The design involves two steps. First, constraint satisfaction is explicitly enforced on the open loop trajectories computed by the MPC optimizer, considering the worst-case perturbations along the prediction horizon of MPC. Second, the state of the system at the end of the prediction horizon is driven into a precomputed terminal set, which is robustly invariant under a known terminal controller. This ensures that the open loop control policy computed by the MPC controller is always feasible and does not violate any constraints for an infinite time. Thus, recursive feasibility and closed loop constraint satisfaction are also satisfied.

Although such an approach works, it results in a large degree of conservatism. This is because, MPC either has to recursively outer-approximate the reachable sets under worst-case perturbations (as in tube MPC methods \cite{langsonRobust,parsi2022scalable}), or use scenario trees which grow exponentially along the horizon \cite{maiworm2015scenario}. Thus, with an increase in the prediction horizon, the number of perturbations increase, along with the computational complexity of MPC. %Thus, in these approaches, recursive feasibility is achieved at the cost of initial feasibility. 

It must be noted that recursive feasibility is a one-step property. That is, it guarantees that under the receding horizon policy, the MPC optimization is feasible at the next time step if it is feasible at the current one. In contrast, constraint satisfaction is an infinite-step property. It guarantees that the system's constraints are never violated in closed loop operation. 

% Because MPC uses an approximate model over multiple time steps in its prediction horizon, ensuring constraint satisfaction involves considering the effect of uncertainty over all these time steps. Over the past two decades, two distinct strategies have evolved in this aspect. The first, is multi-scenario MPC, where a scenario tree is to account for model uncertainty, but its complexity grows exponentially with the prediction horizon \cite{lucia2013multi,maiworm2015scenario}. In the second strategy known as tube MPC, the set of reachable states is outer approximated using a convex set (called the state tube), and the state tube is constrained to lie inside the system constraints \cite{fleming2014robust,parsi2022computationally}. This approach tends to be conservative, as a recursive outer approximation of the reachable states is required, which results in conservatism and higher computational demand compared to nominal MPC methods.

% The design for recursive feasibility uses the concept of invariance \cite{blanchini2008set}. The state of the system at the end of the prediction horizon is driven into a precomputed robust invariant set of the system. This guarantees a feasible solution to the MPC optimization at the next time step, thereby ensuring recursive feasibility. In this way, existing methods use different MPC components to ensure constraint satisfaction and recursive feasibility. 

This work was motivated by the insight that for a well-formulated MPC problem, recursive feasibility implies constraint satisfaction. That is, if an MPC problem remains feasible in closed loop, then the system's constraints are also satisfied. Although this is plainly obvious to see, it is not exploited in the controller design in most existing methods. On the bright side, if constraint satisfaction is guaranteed using recursive feasibility, the large conservatism and computational demands of robust MPC methods can be eliminated.
 %Moreover, recursive feasibility depends on the perturbations occurring at only one time step.%, whereas that for constraint satisfaction considers uncertainties from multiple time-steps. 

Although this insight does not appear formally in existing literature, a few early robust MPC methods have implicitly used it \cite{kerrigan2001Robust,kerrigan2001robust_PHD,chisci99Robustifying}. 
All these methods study the recursive feasibility of the MPC optimization, and do not explicitly prove constraint satisfaction. The method in \cite{chisci99Robustifying} proposes a way to robustify nominal MPC controllers, if a robust control invariant set is known apriori. This has been extended to systems with multiplicative uncertainty in \cite[~Chapter 6.5]{kerrigan2001robust_PHD}. However, robust control invariant sets are in general very difficult to compute \cite{rakovic2007optimized,rungger2017}. Whereas \cite{kerrigan2001Robust} studies the problem of ensuring recursive feasibility using set-invariance, it only provides tools for analysis of a given robust MPC algorithm. The recent work \cite{abdelsalam2021synthesis}   extends the ideas from \cite{kerrigan2001Robust} for systems with multiplicative uncertainties, but also provides conditions suitable for analysis, not design.

In contrast to these early methods, most methods proposed thereafter explicitly design for constraint satisfaction \cite{langsonRobust,fleming2014robust,parsi2022scalable}. This includes the methods proposed by the authors of \cite{chisci99Robustifying} and \cite{kerrigan2001Robust}, such as \cite{chisci2001systems} and \cite{goulart2006optimization} respectively. The reason for choosing such open loop approaches is due to the lack of efficient closed loop design strategies to ensure recursive feasibility, as proposed in this work.

%Related works in literature are \cite{kerrigan2001Robust,kerrigan2001robust_PHD,chisci99Robustifying,abdelsalam2021synthesis}. Whereas \cite{kerrigan2001Robust} studies the problem of ensuring recursive feasibility using set-invariance, it only provides tools for analysis of a given robust MPC algorithm. The methods in \cite{chisci99Robustifying} and  assume knowledge of robust control invariant sets, which are very difficult to compute  \cite{rakovic2007optimized,rungger2017}. The recent work \cite{abdelsalam2021synthesis}   extends the ideas from \cite{kerrigan2001Robust} for systems with multiplicative uncertainties, but also provides conditions suitable for analysis, not design. 

% Although all these existing works implicitly use the property that recursive feasibility implies constraint satisfaction, there is no formal presentation of this property to the best of our knowledge. Moreover, most robust MPC methods thereafter explicitly design for constraint satisfaction and recursive feasibility, including 

% To the best of authors' knowledge, early robust MPC works such as  \cite{chisci99Robustifying} and \cite{kerrigan2001Robust} use the property that recursively feasibility implies constraint satisfaction, and thus only design for recursive feasibility. However, most methods thereafter explicitly design for constraint satisfaction, which involves the conservative open loop strategy of considering multiple perturbations over the prediction horizon \cite{langsonRobust,fleming2014robust,lucia2013multi}. This includes later methods proposed by the authors of \cite{kerrigan2001Robust} and \cite{chisci99Robustifying}, such as \cite{goulart2006optimization} and \cite{chisci2001systems}. The reason for choosing such open loop approaches is due to the lack of efficient closed loop design strategies to ensure recursive feasibility, as proposed in this work.

To perform the control design based on recursive feasibility, a tool known as constraint tightening is employed in this work. In constraint tightening methods, the system's constraints along the prediction horizon are tightened to account for model uncertainty, such that if a nominal trajectory satisfies the modified constraints, the closed loop trajectories remain feasible under perturbations \cite{chisci2001systems,mayne2005robust,parsi2022computationally}. 
%When the uncertainty is described by additive disturbances, the state tube can be explicitly computed and optimized offline, as done in \cite{parsi2022computationally,sieber2022system}. However, for models with more complex uncertainty description, such as linear fractional perturbations, tubes computed offline would result in large conservatism. In such cases, most methods compute the state tubes online \cite{langsonRobust,parsi2022scalable}. 

In this work, a constraint tightening technique is developed for systems whose dynamics can be described by a nominal linear model combined with %time varying model uncertainty and exogenous disturbances. The model uncertainty is described using 
a linear fractional perturbation structure \cite{cockburn1997linear}. The proposed algorithm has two phases: offline and online. In the offline phase, a single non-convex optimization is solved to compute the constraint tightenings. In the online phase, a convex quadratic program is solved at each time step. The method guarantees recursive feasibility and constraint satisfaction. Numerical examples demonstrate that the proposed method results in an order of magnitude reduction in online computation time and improved performance compared to state-of-the-art methods. 

Our work has three novel contributions. First, we formally present the conditions under which recursive feasibility of MPC optimization implies closed loop constraint satisfaction. Second, a necessary and sufficient condition for recursive feasibility is presented. Third, a sufficient condition for recursive feasibility is derived using a closed loop feedback approach. That is, feedback is employed to only prove the \emph{existence} of control inputs which can be computed in closed loop by the MPC optimizer.

\subsection{Notation}
The sets of real numbers is denoted by $ \mathbb{R} $ and the sequence of integers from $ n_1 $ to $ n_2 $  by $ \mathbb{N}_{n_1}^{n_2} $. 
%For a vector $ b $, $ b^{\intercal} $ represents its transpose, and $ [b]_i $ refers to its $ i ^{th}$ element. 
For a vector $ b $ and a matrix $ A $,  $\norm{b}_2$ represents the $2-$norm. The $ i ^{th}$ row of a matrix $ A $ is denoted by $ [A]_{i} $. The notation $ a_{l|k} $ denotes the value of $ a $ at time step $ k+l $ computed at the time step $ k $. The identity matrix of size $n\times n$ is denoted by $I_n$.  A block of zeros of size $n\times m$ inside a larger matrix will be denoted by $0_{n,m}$ when the size cannot be inferred from the other blocks, and $0$ otherwise. The Kronecker product of two matrices $A$ and $B$ is denoted by $A \otimes B$. 
A continuous function $ \alpha: \mathbb{R}_{\ge 0} \rightarrow \mathbb{R}_{\ge 0}  $ is a $ \mathcal{K} $ function if $ \alpha(0) = 0 $, $ \alpha(s) >0 $ for all $ s>0 $ and it is strictly increasing. A continuous function $ \beta:\mathbb{R}_{\ge 0} \times \mathbb{N}_{0}^{\infty} \rightarrow \mathbb{R}_{\ge 0} $ is a $ \mathcal{K} \mathcal{L} $ function if $ \beta(s,t) $ is a $ \mathcal{K}$ function in $ s $ for every $ t\ge 0 $, it is strictly decreasing in $ t $ for every $ s>0 $ and $ \beta(s,t) \rightarrow 0$ when $ t \rightarrow \infty $.


\section{Problem setup}

% Describe model structure
We consider uncertain linear, time-invariant systems of the form:
\begin{subequations}\label{eq:Dynamics}
\begin{align}
    x_{k+1} &= A x_{k} + B u_{k} + B_p p_k + B_w w_k, \label{eq:Dynamics1}\\
    q_k &= D_x x_k + D_u u_k + D_w w_k, \label{eq:Dynamics2}\\ 
    p_k &= \Delta_k q_k,\label{eq:Dynamics3} 
\end{align}
\end{subequations}
where $x_k \in \mathbb{R}^{n_x} $ represents the state of the system, $u_k \in \mathbb{R}^{n_u} $ represents the control input and $w_k \in \mathbb{R}^{n_w}$ represents an exogenous disturbance acting on the system's state. In addition, the uncertainty in the model is captured using a linear fractional transformation (LFT) \cite{cockburn1997linear}, described by $p_k, q_k \in \mathbb{R}^{n_p}$ and the matrix $\Delta_k \in \mathbb{R}^{n_p \times n_p}$. The vectors $ p_k, q_k $ and the matrix $\Delta_k$ cannot be measured, but $\Delta_k$ is known to lie inside the set
\begin{align}\label{eq:DeltaBound}
    \mathcal{P}:= \text{co}\{ \Delta^1, \Delta^2,\ldots ,\Delta^{n_{\Delta}} \},
\end{align}
for all $ k $, where $n_{\Delta}$ represents the number of vertices defining the convex hull $\mathcal{P}$. 

The exogenous disturbance $w_k$ lies within the set
\begin{align}\label{eq:wBound}
    \mathcal{W}:= \{ w |  H_w w \le h_w \},
\end{align}
where $ H_w \in \mathbb{R}^{n_{H_w}\times n_w}, h_w \in \mathbb{R}^{n_{H_w}}$, and the origin is an interior point of $\mathcal{W}$. 

Moreover, the states and inputs of the system must always lie in a compact polytopic set containing the origin, defined as
\begin{align}\label{eq:Constraints}
    \mathcal{C}:= \{(x,u) | F x + G u \le b \} ,
\end{align}
where $F\in\mathbb{R}^{n_c\times n_x}, G\in\mathbb{R}^{n_c\times n_u}, b\in\mathbb{R}^{n_c}$. The control task is subject to a stage cost, i.e., given that the system is at a state $\hat{x}_0$ at the timestep $ k=0 $, control inputs $ \{u_k\}_{k=0}^{\infty}$ must be computed such that the the following nominal cost is minimized
\begin{align}\label{eq:CostDefn}
 \sum_{k=0}^{\infty} l(\tilde{x}_k, \tilde{u}_k)
\end{align}
where  $l(\cdot,\cdot)$ represents the stage cost function. Additionally $\tilde{x}_k$ and $\tilde{u}_k$ represent disturbance-free realizations of the state and input under \eqref{eq:Dynamics}, that is, states and inputs when $\{w_i\}_{i=0}^{\infty}=0$. However, minimization of \eqref{eq:CostDefn} is intractable, as it requires optimization over infinite number of variables and constraints.
%However, the cost in \eqref{eq:CostDefn} cannot be optimized over, since the true state trajectory $ \{x_k\}_{k=0}^{\infty} $ depends on the realizations of the model uncertainty and disturbances to be observed in the future. Moreover, using the infinite horizon state and input trajectories in the optimization problem results in an infinite number of decision variables.

In light of these difficulties, model predictive control (MPC) is used to find suboptimal input sequences \cite{borelli2017model}. In this approach, a receding horizon strategy is used  where the control inputs over the next $ N $  timesteps (called the prediction horizon) are optimized while also ensuring that the state after $ N $ timesteps reaches a terminal set $ \mathcal{X}_N:= \{x\: | \:Yx\le z\} $ which contains the origin. 

Thus, an optimization problem of the following form is solved at each time step $k$ using the available state measurement $ x_k $
\begin{subequations}\label{eq:OnlOptProb}
    \begin{align}
        \min_{\hat{\mathbf{u}}_k,\hat{\mathbf{x}}_k}  \quad  l_N(\hat{x}_{N|k}) + \textstyle\sum_{i=0}^{N-1} &l(\hat{x}_{i|k}, \hat{u}_{i|k}) \label{eq:OnlOptProb1} \\
		\text{s.t.} \quad A\hat{x}_{i|k} + B\hat{u}_{i|k} &= \hat{x}_{i|k+1}, \quad \hat{x}_{k,0}=x_k, \label{eq:OnlOptProb2}\\
            F\hat{x}_{i|k} + G\hat{u}_{i|k}  &\le b - t_i,  \quad i\in \mathbb{N}_{0}^{N-1}, \label{eq:OnlOptProb3} \\
            Y\hat{x}_{N|k} &\le z - t_N, \label{eq:OnlOptProb4}
    \end{align}
\end{subequations}
where $\hat{\mathbf{u}}_k{:=} [\hat{u}_{0|k}\tr,\ldots,\hat{u}_{N-1|k}\tr]\tr $ and $  \hat{\mathbf{x}}_k {:=} [\hat{x}_{0|k}\tr,\ldots,\hat{x}_{N|k}\tr]\tr$. 
In \eqref{eq:OnlOptProb2}, only the nominal dynamics are used to predict the system trajectories. The terms $\{t_i\}_{i=0}^{N-1}$ represent tightenings imposed on the constraints along the prediction horizon to account for the perturbations $\Delta_k$ and $w_k$. In addition \eqref{eq:OnlOptProb4} is a terminal constraint imposed on the last state in the prediction horizon, and $l_N(\cdot) $ represents a terminal cost function.
%Note that this is in contrast to tube MPC methods \cite{kouvaritakis2015model} and multi-scenario MPC methods \cite{lucia2013multi}, where the evolution of the state trajectories within the MPC prediction horizon is explicitly accounted for by the optimization variables.  

Let the optimal solution to \eqref{eq:OnlOptProb} be defined by the superscript $( ^*)$ on the optimization variables. The MPC control law is then defined as $\pi(x_k) =\hat{u}_{0|k}^*$. That is, only the first control input from $\hat{\mathbf{u}}_k^*$ is applied to the system, and another optimization problem is solved at the following time step. 

%\ani{- Add remark that Section.. will present the case when only disturbances are present.}

\section{Constraint satisfaction using recursive feasibility}\label{Sec:RCS_RF}
Two main properties that are desired to be satisfied by robust MPC controllers are (i)  constraint satisfaction and (ii) recursive feasibility. Most existing  robust MPC methods are designed by explicitly accounting for both (i) and (ii), for example \cite{chisci2001systems,parsi2022scalable}. In this work, a novel design strategy is proposed such that satisfying (ii) implicitly ensures that (i) is satisfied. 

For this purpose, the notion of recursive feasibility is formally presented. The optimization \eqref{eq:OnlOptProb} is said to be recursively feasible if the following assumption is satisfied. 
\vspace{2pt}
%\begin{Assumption}\label{Ass:RecFeas}
%    Let the optimization problem \eqref{eq:OnlOptProb} be feasible at time $k\ge 0$. Under the dynamics \eqref{eq:Dynamics} and the MPC control law $u_k = \pi(x_k)$, problem \eqref{eq:OnlOptProb} is guaranteed to be feasible at time $k+1$.
%\end{Assumption}
\begin{Assumption}[Recursive feasibility] \label{Ass:RecFeas}
%Consider the control policy $u_k = \pi(x_k)$ generated by MPC \eqref{eq:OnlOptProb}. 
For any state $x_k$ such that \eqref{eq:OnlOptProb} is feasible at time $k\ge 0$, under the dynamics \eqref{eq:Dynamics} and the MPC control law $u_k = \pi(x_k)$, MPC \eqref{eq:OnlOptProb} is also feasible at time $k+1$ for any $w_k \in \mathcal{W}$ and $\Delta_k \in \mathcal{P}$.
\end{Assumption}

Note that the control law $\pi(x_k) = \hat{u}_{0|k}^*$ uses only the first input from the optimal solution to \eqref{eq:OnlOptProb}, and the optimal solution cannot be easily expressed as an explicit function of $x_k$. Thus, Assumption \ref{Ass:RecFeas} is difficult to verify, or use as a design criterion. In the light of these difficulties, it is useful to consider a simpler assumption, pertaining to constraints \eqref{eq:OnlOptProb2}-\eqref{eq:OnlOptProb4} only, which will ensure that Assumption \ref{Ass:RecFeas} is satisfied. To that end, let $\mathcal{U}(x_k)$ be the set of input sequences such that \eqref{eq:OnlOptProb2}-\eqref{eq:OnlOptProb4} are satisfied for a given state $x_k$. Additionally, define $\mathcal{U}_0(x_k)$  as the set of feasible inputs at the first predicted time step, that is,  %the set of inputs such that there is an input sequence starting satisfying the MPC constraints \eqref{eq:OnlOptProb2}-\eqref{eq:OnlOptProb4} for a given state $x$.
\begin{align}\label{eq: U_0}
\mathcal{U}_0(x_k) := \left\{u_{0|k}\: \:|\:\:  \exists \{u_{l|k}\}_{l=0}^{N-1} \in \mathcal U(x_k) \right\}.
\end{align}
We then consider the following assumption.
\vspace{2pt}
\begin{Assumption}[Strong recursive feasibility] \label{Ass:RecFeas2} 
%Let problem \eqref{eq:OnlOptProb} be feasible at time $k\ge 0$. Then, problem \eqref{eq:OnlOptProb} is guaranteed to be feasible at time $k+1$ under the dynamics \eqref{eq:Dynamics} and 
For any state $x_k$ such that \eqref{eq:OnlOptProb} is feasible at time $k\ge 0$, under the dynamics \eqref{eq:Dynamics} and any control input $u_k \in \mathcal{U}_0(x_k)$, the optimization \eqref{eq:OnlOptProb} is also feasible at time $k+1$ for any  $w_k \in \mathcal{W}$ and $\Delta_k \in \mathcal{P}$.
%$u_k = \hat{\pi}(x_k)$ such that $\hat{\pi}(x_k)\in \hat{\Pi}(x_k)$ for all feasible $x_k$.
\end{Assumption}

Assumption \ref{Ass:RecFeas2} is a stronger than Assumption \ref{Ass:RecFeas}, and has been referred to in literature as \emph{strong recursive feasibility} (SRF) \cite[Definition 2.2]{lofberg2012oops}, or \emph{robust strong feasibility} \cite[Definition 12]{kerrigan2001Robust}. Note that SRF is a sufficient condition for recursive feasibility.
%, as any optimization \eqref{eq:OnlOptProb} satisfying \ref{Ass:RecFeas2} also satisfies \ref{Ass:RecFeas}. 
Thus, it can be used to design recursively feasible optimization problems, as the optimal solution to \eqref{eq:OnlOptProb} need not be explicitly formulated. 
%systems satisfying Definition \ref{Def:RecFeas2} allow feasibility to be retained in closed loop even when problem \eqref{eq:OnlOptProb} may not be solved to optimality. 
Although using SRF for design could lead to conservatism, it must be noted that  most existing robust MPC methods satisfy SRF \cite{mayne2005robust,langsonRobust,parsi2022scalable}. 

%In most existing robust MPC methods, (i) is achieved by explicitly by accounting for the effect of perturbations and disturbances on the state and input trajectories, and suitably designing feedback controllers so that no constraint violations occur within the prediction horizon. ...

%In this work, we use the following property which then enables the closed loop approach to recursive feasibility and constraint satisfaction.

In this paper, we will rely on the fact that, under very mild conditions, recursive feasibility implies closed-loop constraint satisfaction. That is, if the control policy generated by the MPC scheme satisfies Assumption \ref{Ass:RecFeas}, then the conditions under which constraints \eqref{eq:Constraints} are always satisfied by the closed-loop trajectories are trivial. Moreover, it can be seen that Assumption \ref{Ass:RecFeas2} depends only on the perturbations $\Delta_k$ and $w_k$ acting at a single time step. Thus, recursive feasibility and thereby constraint satisfaction can be ensured by analysing the effects of perturbations at a single time step, instead of computing their effects over the entire prediction horizon as performed in existing methods \cite{kouvaritakis2015model}. 
%ensure constraint satisfaction by imposing conditions on the MPC scheme \eqref{eq:OnlOptProb} that are very ``local" in time -- in the sense of Assumption \ref{Ass:RecFeas} demanding conditions over a single time-step -- rather than conditions that must hold over the infinite closed-loop trajectories. 
Let us formalise these statements using the following theorem.
\vspace{2pt}
\begin{Theorem}\label{Th:RF_RCS}
    Let Assumption \ref{Ass:RecFeas} be satisfied. Let $t_0 \ge 0$ and \eqref{eq:OnlOptProb} be feasible at time $k=0$. Then, the closed loop trajectories resulting from the dynamics \eqref{eq:Dynamics} and MPC control policy $\pi(x)$ never violate the constraints \eqref{eq:Constraints}.  
\end{Theorem}
\begin{proof}
Because the optimization \eqref{eq:OnlOptProb} is feasible at time step $k=0$ and $t_0 \ge 0$, there exists $\hat{u}_{0,0}$ such that 
\begin{align}
    F x_0 + G \hat{u}_{0,0} \le b - t_0\le b.
\end{align}
Therefore, \eqref{eq:Constraints} is satisfied at time $k=0$. Moreover, because Assumption \ref{Ass:RecFeas} is satisfied, optimization \eqref{eq:OnlOptProb} always remains feasible under the MPC control law $\pi(x)$. Therefore,  \eqref{eq:Constraints} is satisfied for all $k\ge 0$.
\end{proof}

It can be useful to stress here that Theorem \ref{Th:RF_RCS} -- beyond Assumption \ref{Ass:RecFeas} -- requires only that MPC \eqref{eq:OnlOptProb} is initially feasible, and that the initial constraint \eqref{eq:OnlOptProb3} is ``properly" tightened, i.e. that $t_0\geq 0$. The latter requirement is arguably trivial.

\begin{Remark}
Note that Theorem \ref{Th:RF_RCS} relies only on the feasibility of the solutions to MPC \eqref{eq:OnlOptProb} and not on their optimality. As a consequence, a straightforward corollary is that Theorem \ref{Th:RF_RCS} also holds under Assumption \ref{Ass:RecFeas2}. Hence, recursive feasibility of \eqref{eq:OnlOptProb} will guarantee constraint satisfaction under any control input $u_k \in \hat{\Pi}(x_k)$. That is, even if problem \eqref{eq:OnlOptProb} cannot be solved to optimality, constraint satisfaction can be guaranteed using recursive feasibility.
\end{Remark}

Most robust MPC methods explicitly build outer bounds on worst-case trajectories of the system to ensure constraint satisfaction \cite{kouvaritakis2015model}, which can be interpreted as an open loop approach to robust MPC design. This is because the trajectories predicted by MPC in open loop are designed to lie inside the system constraints under worst-case perturbations along the prediction horizon. Theorem \ref{Th:RF_RCS} enables a design which circumvents this construction altogether, and can be seen as a closed loop approach. In the following sections, the different components, i.e. $Y, z, \{t_i\}_{i=0}^{N}$,  of \eqref{eq:OnlOptProb} will be designed such that Assumption \ref{Ass:RecFeas2} is satisfied. 

The objective is formulate the design of these components as an optimization problem that needs to be solved only once, offline. This offline optimization will be formally presented in  Section \ref{Sec:AlgProp}.

\section{Necessary and sufficient conditions for SRF}
In order to utilize Theorem \ref{Th:RF_RCS} for design, recursive feasibility of \eqref{eq:OnlOptProb} needs to be guaranteed. In this section, necessary and sufficient conditions for SRF of \eqref{eq:OnlOptProb} are derived. The constraints \eqref{eq:OnlOptProb2}-\eqref{eq:OnlOptProb4} can be compactly written as 
\begin{align}\label{eq:FeasCond_k}
    \mathbf{H}_{xu}\mathbf{S} \mathbf{s}_k \le \mathbf{b}-\mathbf{t},
\end{align}
where
\begin{subequations}\label{eq:Notation1}
\begin{align}
&\mathbf{s_k} = \Big[x_k\tr~~\hat{\mathbf{u}}_{k}\tr\Big]\tr, ~\mathbf{H}_{xu}= 
\begin{bmatrix}
    I_N \otimes F & 0 & I_N \otimes G\\
    0 & Y & 0 
\end{bmatrix},\\
&\mathbf{S} =\left[ \begin{array}{c|cccc} 
    I & 0 & ... & ... & 0 \\ A & B & 0 & ... & 0  \\ \vdots & \vdots & \ddots & \ddots & \vdots \\ A^{N-1} & A^{N-2}B & ... & B & 0 \\ A^N & A^{N-1} B &...& AB &  B \\ 0 & \multicolumn{4}{c}{I_{Nn_u}} 
    \end{array}    \right]
    = \left[ \begin{array}{c|c} 
        \mathbf{S}_x &  \mathbf{S}_u 
    \end{array}    \right]\\
&\mathbf{b} = \Big[\textbf{1}_N\tr\otimes b\tr~~z\tr\Big]\tr, ~\text{and }\mathbf{t} = [t_o~~t_1~~\hdots~~t_N]\tr.
\end{align}
\end{subequations}
One can readily observe that the vector $\mathbf{s}_k$ collects the initial state $x_k$ and input trajectory $\hat{\mathbf{u}}_k$. The matrix $\mathbf{S}$ maps the initial state $x_k$ and input trajectory $\hat{\mathbf{u}}_k$ (i.e., $\mathbf{s_k}$) to the predicted state-input trajectories; more precisely, $\mathbf{Ss}_k = [\hat{\mathbf{x}}_k\tr~~\hat{\mathbf{u}}_k\tr]\tr$. The matrix $\mathbf{H}_{xu}$ maps this predicted state-input trajectories to the left-hand side of constraints \eqref{eq:OnlOptProb3}-\eqref{eq:OnlOptProb4}. Vectors $\mathbf{b}$ and $\mathbf{t}$ collect the right-hand side of constraints \eqref{eq:OnlOptProb3}-\eqref{eq:OnlOptProb4}. Let $\mathbb{P}_0$ denote the set of all feasible $\mathbf{s}_k$'s, that is,
\begin{align} \label{eq:Poytope_P0}
    \mathbb{P}_0 &:= \Set{\mathbf{s}_k}{ \mathbf{H}_{xu}\mathbf{S} \mathbf{s}_k \le \mathbf{b}-\mathbf{t}}. 
\end{align}
In other words, $\mathbb{P}_0$ contains all possible initial states $x_k$ and input trajectories $\hat{\mathbf{u}}_k$ such that \eqref{eq:FeasCond_k} holds. Observe that SRF is satisfied if, for every $\mathbf{s}_k=[x_k\tr~\hat{u}_{0|k}\tr~\hdots~\hat{u}_{N-1|k}\tr]\tr\in\mathbb{P}_0$, all possible realizations of $x_{k+1}$, under the dynamics (\ref{eq:Dynamics}) and the control input $\hat{u}_{0|k}$, admit a feasible solution to \eqref{eq:OnlOptProb}. In other words, for all the above realizations of $x_{k+1}$ there exists a $\mathbf{s}_{k+1}=[x_{k+1}\tr~\hat{\mathbf{u}}_{k+1}\tr]\tr$ such that
\begin{align}\label{eq:FeasCond_k+1}
    \mathbf{H}_{xu}\mathbf{S} \mathbf{s}_{k+1} \le \mathbf{b}-\mathbf{t}. 
\end{align}
Note that the constraint (\ref{eq:FeasCond_k+1}) can alternatively be expressed in terms of $\mathbf{s}_{k}$, $w_k$, and the transition matrices in (\ref{eq:Dynamics}) by re-writing the state-input trajectories $\mathbf{Ss}_{k+1}$ as
\begin{align}\label{eq:s_k+1}
    \mathbf{S} \mathbf{s}_{k+1} = \mathbf{C}^{\Delta_k}_{\mathbf{s}}\mathbf{s}_k + \mathbf{C}_\mathbf{w}^{\Delta_k}w_k + \mathbf{S}_u \hat{\mathbf{u}}_{k+1},
\end{align}
\begin{comment}
\begin{subequations}\label{eq:s_k+1}
\begin{align}
    \mathbf{S} \mathbf{s}_{k+1} &=   \mathbf{S}_x x_{k+1} +  \mathbf{S}_u \hat{\mathbf{u}}_{k+1}, \label{eq:s_k+1_1}\\
    &=  \mathbf{S}_x (A x_k + B u_k)  + 
   \mathbf{S}_x\big( B_w w_k +B_p \Delta_k (D_x x_k \nonumber\\ 
   &\quad + D_u u_k + D_w w_k)\big)+\mathbf{S}_u \hat{\mathbf{u}}_{k+1} \label{eq:s_k+1_2}\\
       & =(\mathbf{L} {+} \mathbf{S}_x B_p \Delta_k  D_{xu}  ) \mathbf{s}_k \nonumber\\ 
     &\quad + \mathbf{S}_x (B_w {+} B_p \Delta_k D_w )w_k +  \mathbf{S}_u \hat{\mathbf{u}}_{k+1} \\
     &=\mathbf{C_ss}_k + \mathbf{C_w}w_k + \mathbf{S}_u \hat{\mathbf{u}}_{k+1},
\end{align}
\end{subequations}
\end{comment}
where
\begin{subequations}
\begin{align}
&\mathbf{C}^{\Delta_k}_{\mathbf{s}} = \mathbf{L} + \mathbf{S}_x B_p \Delta_k  D_{xu},\mathbf{C}_{\mathbf{w}}^{\Delta_k} = \mathbf{S}_x (B_w  + B_p \Delta_k D_w),\nonumber\\
&\mathbf{L} = \begin{bmatrix} 
    A & B & 0   \\ A^2 & AB & 0 \\ \vdots & \vdots & \vdots \\ A^{N+1} & A^N B & 0 \\  \multicolumn{3}{c}{0_{Nn_u,n_x+Nn_u}} 
    \end{bmatrix},\text{ and }
    D_{xu} = \begin{bmatrix} D_x\\
    D_u
    \\
    0_{n_p,(N-1)n_u}
    \end{bmatrix}.\nonumber
\end{align}
\end{subequations}
Please see Appendix \ref{app: AppendixA} for details on the algebraic manipulations in (\ref{eq:s_k+1}). Note that the superscript in $\mathbf{C}^{\Delta_k}_{\mathbf{s}}$ and $\mathbf{C}^{\Delta_k}_{\mathbf{w}}$ indicates their explicit dependence on the perturbation $\Delta_k\in\mathcal{P}$. Further, it can be readily checked that the matrix {\color{red}$\mathbf{C}_{\mathbf{s}}^{\Delta_k}$ maps $\mathbf{s_k}$ into the predicted trajectory at time $k+1$, and the matrix $\mathbf{C}_{\mathbf{w}}^{\Delta_k}$ provides the gain from disturbance $w_k$ at time $k$ to the predicted state-input trajectories at time $k+1$}. 
\begin{comment}
The constraint (\ref{eq:FeasCond_k+1}) can now be re-written, using the above notations, as
\begin{align}\label{eq:FeasCond_k+1_ver2}
\mathbf{H}_{xu}  \left(\mathbf{C}_{\mathbf{s}}^{\Delta_k} \mathbf{s}_k + \mathbf{C}_{\mathbf{w}}^{\Delta_k} w_k + \mathbf{S_u}\hat{\mathbf{u}}_{k+1} \right)  \leq \mathbf{b}-\mathbf{t}. &
\end{align}
\end{comment}
The following theorem presents necessary and sufficient conditions, motivated from \eqref{eq:FeasCond_k+1} and \eqref{eq:s_k+1}, and the vertices $\Delta^j$ that define $\mathcal{P}$, that are required for the SRF to hold true.
\begin{Theorem}\label{Thm:NecSuff}
    Let $\mathbb{P}_1$ be a polytope defined as
    \begin{equation}\label{eq:Poytope_P1}
    \mathbb{P}_1 = \Set*{\begin{bmatrix}
        \mathbf{s}_k \\ w_k
    \end{bmatrix} \: \: }{\: \:\begin{bmatrix}
        \mathbf{H}_{xu}\mathbf{S} & 0 \\
        0 & H_w
    \end{bmatrix}
    \begin{bmatrix}
        \mathbf{s}_k \\ w_k
    \end{bmatrix} \leq
    \begin{bmatrix}
        \mathbf{b}-\mathbf{t} \\ h_w
    \end{bmatrix} }.
\end{equation}
Then, SRF is satisfied if, and only if, $\forall$   $\begin{bmatrix}
        \mathbf{s}_k \tr & w_k\tr
    \end{bmatrix}\tr \in \mathbb{P}_1$ and $ \forall j\in \mathbb{N}_{1}^{n_\Delta}$, there exist $ \hat{\mathbf{u}}_{k+1}^j $ such that 
\begin{align}\label{eq:NecSuff}
     \mathbf{H}_{xu}  \left(\mathbf{C}^{\Delta^j}_{\mathbf{s}} \mathbf{s}_k + \mathbf{C}^{\Delta^j}_{\mathbf{w}} w_k + \mathbf{S_u}\hat{\mathbf{u}}_{k+1}^j \right)  \leq \mathbf{b}-\mathbf{t}, &
\end{align}
where $\mathbf{C}^{\Delta^j}_{\mathbf{s}} = \mathbf{L} + \mathbf{S}_x B_p \Delta^j  D_{xu}$,   $\mathbf{C}^{\Delta^j}_{\mathbf{w}} = \mathbf{S}_x (B_w  + B_p \Delta^j D_w)$, and $\Delta^j$ denote the vertices of $\mathcal{P}$.
\end{Theorem}
\begin{proof}
\textit{Sufficiency:}\\
Let $\hat{\mathbf{u}}_{k+1}^j$ be the input trajectory such that \eqref{eq:NecSuff} is satisfied for each $j \in \mathbb{N}_{1}^{n_\Delta}$ and  $\Big[\mathbf{s}_k \tr ~ w_k\tr\Big] \tr \in \mathbb{P}_1$. 
Let the true perturbation $\Delta_k$ and an input trajectory $\hat{\mathbf{u}}_{k+1}$ be given as 
\begin{align}\label{eq:Delta_k}
    \Delta_k = \sum_{j=1}^{n_\Delta} \mu_j \Delta^j,\quad \hat{\mathbf{u}}_{k+1} =  \sum_{j=1}^{n_\Delta} \tau_j \hat{\mathbf{u}}_{k+1}^j,
\end{align}
where $ \sum_{j=1}^{n_\Delta} \mu_j = 1$, $\mu_j \ge 0$, and $\tau_j\in\mathbb{R}$. Note that a representation of $\Delta_k$ as in \eqref{eq:Delta_k} is possible as it lies inside the convex hull $\mathcal{P}$ defined in \eqref{eq:DeltaBound}. Upon substituting (\ref{eq:Delta_k}) in \eqref{eq:s_k+1}, it readily follows that,
\begin{align}
\mathbf{S} \mathbf{s}_{k+1} = \sum_{j=1}^{n_\Delta}\mu_j \left(\mathbf{C}^{\Delta^j}_{\mathbf{s}} \mathbf{s}_k + \mathbf{C}^{\Delta^j}_{\mathbf{w}} w_k + \mathbf{S_u}\hat{\mathbf{u}}_{k+1}^j  \right), 
\end{align}
\begin{comment}
\begin{subequations}\label{eq:Suff_NecSuff}
\begin{align}
    &\mathbf{S} \mathbf{s}_{k+1}  \nonumber \\
    &=(\mathbf{L} {+} \mathbf{S}_x B_p \Delta_k  D_{xu}  ) \mathbf{s}_k  {+}  
     \mathbf{S}_u \hat{\mathbf{u}}_{k{+}1} {+} \mathbf{S}_x (B_w {+} B_p \Delta_k D_w )w_k \\
     &= (\mathbf{L} {+} \mathbf{S}_x B_p \sum_{j=1}^{n_\Delta} \mu_j \Delta^j  D_{xu}  ) \mathbf{s}_k  {+}  \nonumber
     \mathbf{S}_u \sum_{j=1}^{n_\Delta}\mu_j  \hat{\mathbf{u}}_{k{+}1}^j {+} \\
     & \qquad \qquad \mathbf{S}_x (B_w {+} B_p \sum_{j=1}^{n_\Delta} \mu_j \Delta^j D_w )w_k \\
     &= \sum_{j=1}^{n_\Delta}\mu_j \big( (\mathbf{L} {+} \mathbf{S}_x B_p  \Delta^j  D_{xu}  ) \mathbf{s}_k  {+}   \mathbf{S}_u \hat{\mathbf{u}}_{k{+}1}^j {+}  \nonumber \\
     & \qquad \qquad \mathbf{S}_x (B_w {+} B_p \Delta^j D_w )w_k \big)\\
     &= \sum_{j=1}^{n_\Delta}\mu_j \left(\mathbf{C}^j_{\mathbf{s}} \mathbf{s}_k + \mathbf{S_u}\hat{\mathbf{u}}_{k+1}^j  + \mathbf{C}^j_{\mathbf{w}} w_k \right),
\end{align}
\end{subequations}
\end{comment}
and we obtain that
\begin{align}
   \mathbf{H}_{xu}\mathbf{S} \mathbf{s}_{k+1} &= \mathbf{H}_{xu} \sum_{j=1}^{n_\Delta}\mu_j \left(\mathbf{C}^j_{\mathbf{s}} \mathbf{s}_k +  \mathbf{C}^j_{\mathbf{w}} w_k + \mathbf{S_u}\hat{\mathbf{u}}_{k+1}^j\right)\nonumber\\
    & = \sum_{j=1}^{n_\Delta}\mu_j \mathbf{H}_{xu}  \left(\mathbf{C}^j_{\mathbf{s}} \mathbf{s}_k + \mathbf{S_u}\hat{\mathbf{u}}_{k+1}^j  + \mathbf{C}^j_{\mathbf{w}} w_k \right)\nonumber\\
    &\le \sum_{j=1}^{n_\Delta}\mu_j (\mathbf{b}-\mathbf{t})  = \mathbf{b}-\mathbf{t},\nonumber
\end{align}
where the inequality in the last step is obtained because \eqref{eq:NecSuff} is satisfied by the input sequences $\hat{\mathbf{u}}_{k+1}^j$.
Thus, \eqref{eq:FeasCond_k+1} admits a feasible solution and SRF holds true. 
\\
\textit{Necessity: }\\
Let the online optimization problem \eqref{eq:OnlOptProb} be recursively feasible. That is, let \eqref{eq:FeasCond_k+1} admit a feasible solution whenever \eqref{eq:FeasCond_k} admits one, for all realizations of $\Delta_k\in \mathcal{P}$ and $w_k \in \mathcal{W}$. 

Then, consider that for each $j \in \mathbb{N}_{1}^{n_\Delta}$, $\hat{\mathbf{u}}_{k+1}^j$ represents the feasible input sequences for \eqref{eq:FeasCond_k+1} when the perturbation $\Delta_k$ takes the value $\Delta^j$, and for $\mathbf{s}_k$ satisfying \eqref{eq:FeasCond_k} and $w_k \in \mathcal{W}$ . Then, using \eqref{eq:s_k+1}, \eqref{eq:FeasCond_k+1} can be written as
\begin{align}
\begin{split}
    \mathbf{H}_{xu}  (\mathbf{L} {+} \mathbf{S}_x B_p \Delta^j  D_{xu}  ) \mathbf{s}_k  +\mathbf{S}_u \hat{\mathbf{u}}_{k{+}1}^j + \quad & \nonumber \\
      \mathbf{S}_x (B_w {+} B_p \Delta^j D_w )w_k &\le \mathbf{b}-\mathbf{t} \\
     \implies \mathbf{H}_{xu}  \left(\mathbf{C}^{\Delta^j}_{\mathbf{s}} \mathbf{s}_k + \mathbf{C}^{\Delta^j}_{\mathbf{w}} w_k + \mathbf{S_u}\hat{\mathbf{u}}_{k+1}^j \right) &\le \mathbf{b}-\mathbf{t},
\end{split}
\end{align}
proving that \eqref{eq:NecSuff} is satisfied for all $j\in\mathbb{N}_{1}^{n_\Delta}$, and for $s_k$ satisfying \eqref{eq:FeasCond_k} and $w_k \in \mathcal{W}$, or compactly,
$ \forall \begin{bmatrix}
        \mathbf{s}_k \tr & w_k\tr
    \end{bmatrix}\tr \in \mathbb{P}_1$. 
\end{proof}
\vspace{0.1cm}
\begin{Remark}
    Theorem \ref{Thm:NecSuff} explicitly captures the conditions under which SRF holds. Whereas Theorem \ref{Thm:NecSuff} 
 formulates it as an existence of input sequences, the criteria can be written as set inclusions using ideas from set-invariance \cite{blanchini2008set,kerrigan2001Robust}. The early work \cite{kerrigan2001Robust} presents necessary and sufficient conditions to achieve SRF for generic nonlinear systems with disturbances. However, the resulting conditions could only be used as tests for SRF, but not as design methods, even for LTI systems with additive disturbances. Recently, these tests were extended to the multiplicative uncertainty case in  \cite{abdelsalam2021synthesis}, where polytope projections were used to certify SRF. However, this method also requires that the MPC parameters are known apriori, and has a much higher computational complexity compared to \cite{kerrigan2001Robust} due to the projection operation.
 %The work in \cite{kerrigan2001Robust} formulates necessary and sufficient conditions for SRF using Minkowski sums, applied to piecewise affine systems with additive disturbances. This has been extended for systems with multiplicative uncertainty in \cite{abdelsalam2021synthesis}, where polytope projections are used to certify SRF. However, this strategy is not suitable for design, as projection of polytopes is computationally demanding, and cannot be performed unless the polytope is known apriori.
\end{Remark}

\section{Sufficient condition using feedback}\label{Sec:SuffCond_Feedback}
Although Theorem \ref{Thm:NecSuff} provides necessary and sufficient conditions for the characterization of SRF, \eqref{eq:NecSuff} is difficult to directly use in the design of \eqref{eq:OnlOptProb}. This is because in \eqref{eq:NecSuff}, one must guarantee the existence of $\hat{\mathbf{u}}_{k+1}^j$ to prove recursive feasibility, which is difficult to formulate into design critera on the MPC components. In this section, this difficulty is alleviated by parameterizing the control inputs using feedback gains.

%In this section, a sufficient condition is derived for the satisfaction of Assumption \ref{Ass:RecFeas2} by parameterizing the control inputs using a combination of state and disturbance feedback gains. The derived sufficient conditions are then used to formulate the offline optimization problem to design MPC components. 
Theorem \ref{Thm:NecSuff} allows one to design independent input sequences $\hat{\mathbf{u}}_{k+1}^j $  for each $j\in \mathbb{N}_{1}^{n_\Delta}$. This is in contrast to most existing open loop design strategies, where a single feedback law is designed to compensate for all perturbations \cite{smith2004robust,parsi2022scalable}.  Exploiting the fact that independent input sequences are sufficient to ensure SRF,  for each $j\in \mathbb{N}_{1}^{n_\Delta}$, the input sequences $\hat{\mathbf{u}}_{k+1}^j $ is parameterized as
\begin{align}\label{eq:InputParameterization}
    \hat{u}_{i|k+1}^j &= \hat{u}_{i+1|k}^j + M_i^j B_w w_k + K^j_{i} y_k, \: \forall i \in \mathbb{N}_{0}^{N-2}, \nonumber\\
    \hat{u}_{N-1|k+1}^j &= K^j \hat{x}_{N|k} + M_{N{-}1}^j B_w w_k  + K^j_{N{-}1} y_k, 
\end{align}
where $y_k = \begin{bmatrix}
x_k\tr & u_k\tr \end{bmatrix}\tr$, and for $j\in \mathbb{N}_{1}^{n_\Delta}$ and $i \in \mathbb{N}_{0}^{N-
1}$  $K^j$ represents a terminal state feedback gain, $M_i^j$ represents a disturbance feedback gain and $K_{i,\Delta}^j$ represents feedback on the perturbation due to $\Delta_k$ . The use of disturbance feedback gains is common in robust MPC \cite{goulart2006optimization}. Moreover, each $K_{i,\Delta}^j$ compensates for the effect of $\Delta^j$ on the nominal trajectory. The product with $y_k$ is used for feedback as the perturbation from $\Delta^j$  on the nominal trajectories also appears as a product with $y_k$ (see \eqref{eq:s_k+1_2}).

% An advantage of choosing the input parameterization according to \eqref{eq:InputParameterization} is that independent feedback gains can be computed to account for each $j\in \mathbb{N}_{1}^{n_\Delta}$. This is in contrast to existing design methods, where a single feedback gain is used to compensate for all perturbations \cite{parsi2022scalable}. This can additionally reduce the conservatism of existing methods.

% \begin{Remark}
% It must be highlighted that the proposed algorithm does not use the input parameterization \eqref{eq:InputParameterization} in closed loop operation. 
% Moreover, only the knowledge of states and inputs is assumed in this work, which means that the true values of $w_k$ and $\Delta_k$ cannot be explicitly computed, and \eqref{eq:InputParameterization} cannot be applied. The parameterization \eqref{eq:InputParameterization} will only be used to show the existence of inputs satisfying \eqref{eq:NecSuff}, thereby proving that a non-empty feasible region exists for the MPC optimization problem. 
% %The MPC optimization \eqref{eq:OnlOptProb} will be recursively solved in closed loop and the control inputs will be applied as $u_k = \pi(x_k)$. 
% \end{Remark}

Condition \eqref{eq:NecSuff} can now be rewritten as the existence of suitable feedback gains which can be solved for offline. Towards this end, we begin by defining a set $\mathbb{P}_2^j$ for each $j\in\mathbb{N}_{1}^{n_{\Delta}}$ that consists of all the $\mathbf{s}_k=[x_k\tr~\hat{u}_{0|k}\tr~\hdots~\hat{u}_{N-1|k}\tr]\tr$, and the disturbances $w_k\in\mathcal{W}$ such that the resulting state $x_{k+1}$, under the dynamics (\ref{eq:Dynamics}) and fixed perturbation $\Delta_k = \Delta^j$, and the parameterized input trajectory $\hat{\mathbf{u}}_{k+1}$ in (\ref{eq:InputParameterization}) satisfy the constraints \eqref{eq:OnlOptProb3}-\eqref{eq:OnlOptProb4} at the $k+1$-th time step. In other words, for the above state and input trajectories at time step $k+1$, $\mathbf{s}_{k+1}=[x_{k+1}\tr~\hat{\mathbf{u}}_{k+1}\tr]\tr$ satisfies (\ref{eq:FeasCond_k+1}).
Consider the polytopes
\begin{align}
    \mathbb{P}_2^j &:= \Set*{\begin{bmatrix}
        \mathbf{s}_k \\ w_k
        %%
    \end{bmatrix} }{\mathbf{H}_{xu}\begin{bmatrix}
        \mathbf{C}_K^j &   \mathbf{C}_M^j
    \end{bmatrix}
    \begin{bmatrix}
        \mathbf{s}_k \\ w_k
    \end{bmatrix} \leq \mathbf{b}-\mathbf{t}  }, \label{eq:Poytope_P2j} 
\end{align}
for each $j\in \mathbb{N}_{1}^{n_\Delta}$, where 
\begin{subequations}
\begin{align}
&\mathbf{C}_K^j = \mathbf{L}_K^j + \mathbf{S}_x B_p \Delta^j  D_{xu} \nonumber\\
 &\quad\qquad +\mathbf{S}_u \mathbf{K}^j_{\Delta} \Big[
    I_{n_x+n_u} ~~0_{n_x+n_u, n_u(N-1)} \Big], \\
&\mathbf{L}_K^j = \begin{bmatrix}
A & B & 0  & ... & 0 \\ A^2 & AB & B & ... & 0 \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ A^N & A^{N-1} B & A^{N-2} B &... &  B \\ A_K^j A^N & A_K^j A^{N-1} B & A_K^j A^{N-2} B &... &  A_K^j B \\ 
0 & 0 & \multicolumn{3}{c}{I_{(N-1)n_u}}  \\
K^j A^N & K^j A^{N-1} B & K^j A^{N-2} B &... &  K^j B
\end{bmatrix} \\
&A_K^j= A + B K^j, \mathbf{K}^j_{\Delta} = \begin{bmatrix}  {K^j_{0,\Delta}}\tr \hdots & {K^j_{N-1,\Delta}}\tr   \end{bmatrix} \tr,\\
%%
&\mathbf{C}_M^j = \mathbf{S}_x (B_w  + B_p \Delta^j D_w)+ \mathbf{S}_u\mathbf{M}^jB_w,\\
&\mathbf{M}^j = \Big[{M_0^j}\tr ~ {M_1^j}\tr ~ \hdots~ {M_{N{-}1}^j}\tr \Big]\tr.
\end{align}
\end{subequations}

Here, the matrix $\mathbf{L}_K^j$ maps a pair of initial state and the nominal input trajectory (that is, $\mathbf{s}_k$) into the corresponding nominal predicted state and input trajectory ($[\hat{\mathbf{x}}_{k+1}\tr~~\hat{\mathbf{u}}_{k+1}\tr]\tr]$) at the next time step under the controller parameterization \eqref{eq:InputParameterization}. Matrix $\mathbf{C}_K^j$  maps  $\mathbf{s}_k$ into a perturbed state-input trajectory ( $[\mathbf{x}_{k+1}\tr~~\hat{\mathbf{u}}_{k+1}\tr]\tr$) at the next time step, when the perturbation  $\Delta_k= \Delta^j$  and the input is parameterized as \eqref{eq:InputParameterization}. Similarly, $\mathbf{C}_M^j$ maps the effects of a disturbance $w_k$ on the state-input trajectory at the next time step.

Polytopes $\mathbb{P}_0,\mathbb{P}_1$ and $\mathbb{P}_2^j$ can be interpreted in the following manner. Polytope $\mathbb{P}_0$ in (\ref{eq:Poytope_P0}) is the set of feasible initial states and input trajectories defined by the MPC optimization \eqref{eq:OnlOptProb}, and $\mathbb{P}_1$ in (\ref{eq:Poytope_P1}) is the union of $\mathbb{P}_0$ with the set of possible disturbances \eqref{eq:wBound}. For each $j$,  $\mathbb{P}_2^j$ is the set of initial states, input trajectories and disturbances acting at time step $k$ such that, if $\Delta_{k} = \Delta^j$, $\mathbf{s}_{k+1}$ lies inside $\mathbb{P}_0$. That is, $\mathbb{P}_2^j$ is the pre-image of $\mathbb{P}_0$ under the dynamics \eqref{eq:Dynamics} with $\Delta_{k} = \Delta^j$ and $u_k$ as in \eqref{eq:InputParameterization}. The following theorem then defines polytopic set inclusions which guarantee SRF.

\begin{Theorem}\label{Thm:SuffCond}
    Consider the polytopes $\{\mathbb{P}_2^j\}_{j=1}^{n_{\Delta}}$  proposed in \eqref{eq:Poytope_P2j}.
    Then, Assumption \ref{Ass:RecFeas2} is satisfied if there exist feedback gains $K$, $\{ \{M_i^j\}_{j=i}^{n_{\Delta}} \}_{i=0}^{N-1}$ and $\{ \{ K_{i,\Delta}^j\}_{j=i}^{n_{\Delta}}\}_{i=0}^{N-1} $  such that
\begin{align}\label{eq:SuffCond}
     \mathbb{P}_1 \subseteq \mathbb{P}_2^j, \quad \forall j \in \mathbb{N}_1^{n_{\Delta}}.
\end{align}
\end{Theorem}
\begin{proof}
In order for Assumption \ref{Ass:RecFeas2} to be satisfied, \eqref{eq:FeasCond_k+1} must be feasible for every $\mathbf{s}_k$ satisfying \eqref{eq:FeasCond_k}, $w_k\in \mathcal{W}$ and $\Delta_k \in \mathcal{P}$. 

Let $\Delta_k $ be defined as in \eqref{eq:Delta_k} and a candidate control input sequence be defined as $\hat{\mathbf{u}}_{k+1} =  \sum_{j=1}^{n_\Delta} \tau_j \hat{\mathbf{u}}_{k+1}^j$, where $\tau_j\in\mathbb{R}$ and  $\hat{\mathbf{u}}_{k+1}^j$ are parameterized according to \eqref{eq:InputParameterization}. 
Substituting this candidate sequence in \eqref{eq:s_k+1} and using \eqref{eq:InputParameterization} we obtain that
\begin{align}\label{eq:SuffCondPf1}
\mathbf{S} \mathbf{s}_{k+1} = \sum_{j=1}^{n_\Delta} \tau_j \bigg(\mathbf{C}_K^j s_k + \mathbf{C}_M^j w_k  \bigg).
\end{align}
Please see Appendix \ref{app: AppendixB} for algebraic details. Further, using \eqref{eq:SuffCondPf1}, it can be seen that
\begin{subequations}\label{eq:SuffCondPf2}
\begin{align}
   & H_{xu} \mathbf{S} \mathbf{s}_{k+1} = H_{xu}  \sum_{j=1}^{n_\Delta} \tau_j \bigg(\mathbf{C}_K^j s_k + \mathbf{C}_M^j w_k  \bigg) \label{eq:SuffCondPf2_1}\\
   &=    \sum_{j=1}^{n_\Delta} \tau_j H_{xu} \big( \mathbf{C}_K^j s_k + \mathbf{C}_M^j w_k  \big) \label{eq:SuffCondPf2_2}\\
   &\le  \sum_{j=1}^{n_\Delta} \tau_j (\mathbf{b}-\mathbf{t}) \le \mathbf{b}-\mathbf{t}, \label{eq:SuffCondPf2_3}
\end{align}
\end{subequations}
where \eqref{eq:SuffCondPf2_3} is obtained because any $\begin{bmatrix}
        \mathbf{s}_k \tr & w_k\tr
    \end{bmatrix}\tr $ inside $ \mathbb{P}_1$ also lies inside $\mathbb{P}_2^j$ from \eqref{eq:SuffCond}. 
Therefore, \eqref{eq:FeasCond_k+1} is satisfied for all feasible realizations of $s_k$, $\Delta_k$ and $w_k$ under the proposed feedback if \eqref{eq:SuffCond} holds, and Assumption \ref{Ass:RecFeas2} is satisfied.
\begin{comment}
\begin{subequations}\label{eq:SuffCondPf1}
\begin{align}
    &\mathbf{S} \mathbf{s}_{k+1} = (\mathbf{L} {+} \mathbf{S}_x B_p \sum_{j=1}^{n_\Delta} \tau_j \Delta^j  D_{xu}  ) \mathbf{s}_k  \nonumber \\
     & {+} \mathbf{S}_x (B_w {+} B_p \sum_{j=1}^{n_\Delta} \tau_j\Delta^j D_w )w_k  +\mathbf{S}_u  \sum_{j=1}^{n_\Delta} \tau_j \hat{\mathbf{u}}_{k+1}^j \label{eq:SuffCondPf1_1}\\
     &= \sum_{j=1}^{n_\Delta} \tau_j \bigg( \bigg( \mathbf{L}_K^j + \mathbf{S}_x B_p \Delta^j  D_{xu}  \nonumber\\ 
     &\quad + \mathbf{S}_u \mathbf{K}^j_{\Delta} \begin{bmatrix}
        I_{n_x+n_u}  & 0_{n_x+n_u, n_u(N-1)}
    \end{bmatrix}\bigg) \mathbf{s}_k, \nonumber \\     
    & \quad + \textbf{S}_x \big( B_w + B_p\Delta^jD_w \big) w_k + \mathbf{S}_u\mathbf{M}^j B_w w_k
        \bigg) \label{eq:SuffCondPf1_2}\\
        & = \sum_{j=1}^{n_\Delta} \tau_j \bigg(\mathbf{C}_K^j s_k + \mathbf{C}_M^j w_k  \bigg) . \label{eq:SuffCondPf1_3}
\end{align}
\end{subequations}
In \eqref{eq:SuffCondPf1}, \eqref{eq:SuffCondPf1_2} is obtained by plugging in the control law \eqref{eq:InputParameterization} in \eqref{eq:SuffCondPf1_1} and using the definition of $\mathbf{L}_K^j$. Using \eqref{eq:SuffCondPf1}, it can be seen that
\begin{subequations}\label{eq:SuffCondPf2}
\begin{align}
   & H_{xu} \mathbf{S} \mathbf{s}_{k+1} = H_{xu}  \sum_{j=1}^{n_\Delta} \tau_j \bigg(\mathbf{C}_K^j s_k + \mathbf{C}_M^j w_k  \bigg) \label{eq:SuffCondPf2_1}\\
   &=    \sum_{j=1}^{n_\Delta} \tau_j H_{xu} \big( \mathbf{C}_K^j s_k + \mathbf{C}_M^j w_k  \big) \label{eq:SuffCondPf2_2}\\
   &\le  \sum_{j=1}^{n_\Delta} \tau_j (\mathbf{b}-\mathbf{t}) \le \mathbf{b}-\mathbf{t}, \label{eq:SuffCondPf2_3}
\end{align}
\end{subequations}
where \eqref{eq:SuffCondPf2_3} is obtained because any $\begin{bmatrix}
        \mathbf{s}_k \tr & w_k\tr
    \end{bmatrix}\tr $ inside $ \mathbb{P}_1$ also lies inside $\mathbb{P}_2^j$ from \eqref{eq:SuffCond}. 
Therefore, \eqref{eq:FeasCond_k+1} is satisfied for all feasible realizations of $s_k$, $\Delta_k$ and $w_k$ under the proposed feedback if \eqref{eq:SuffCond} holds, and Assumption \ref{Ass:RecFeas2} is satisfied.
\end{comment}
\end{proof}
\vspace{-0.5cm}

Note that \eqref{eq:NecSuff} depends on the state of the system $x_k$, \eqref{eq:SuffCond} does not. This implies that the condition \eqref{eq:SuffCond} can be used to compute the MPC components offline. The following result based on Farkas' Lemma will be used to reformulate \eqref{eq:SuffCond}.
\vspace{0.3cm}
\begin{Lemma}\cite[Lemma~5.6]{kouvaritakis2015model}\label{Lem:Farkas}
    Let $\mathbb{X}_i = \Set{x}{H_i x \le h_i}$ for $i=1,2$ be two polytopes. Then, $\mathbb{X}_1 \subseteq \mathbb{X}_2 $ is satisfied if, and only if, there exists a matrix $\Lambda$ such that
    \begin{align}\label{eq:Farkas}
       \Lambda \ge 0, \quad \Lambda H_1 = H_2, \quad \Lambda h_1 \le h_2.
    \end{align}
\end{Lemma}
\vspace{-0.5cm}
Note that the first inequality in \eqref{eq:Farkas} is element-wise.
\vspace{0.3cm}
\begin{Proposition}\label{Prop:LambdaRefo}
The set inlcusions \eqref{eq:SuffCond} are satisfied if, and only if, there exist matrices $\{ \Lambda^j\}_{j=1}^{n_{\Delta}}$ such that 
    \begin{subequations}\label{eq:LambdaRefo}
    \begin{align}
        \Lambda^j \ge 0, \\
        \Lambda^j \begin{bmatrix}
        \mathbf{H}_{xu}\mathbf{S} & 0 \\
        0 & H_w
    \end{bmatrix} &= \mathbf{H}_{xu}\begin{bmatrix}
        \mathbf{C}_K^j &   \mathbf{C}_M^j
    \end{bmatrix}, \\
    \Lambda^j \begin{bmatrix}
        \mathbf{b}-\mathbf{t} \\ h_w
    \end{bmatrix} &\le \mathbf{b}-\mathbf{t}, \quad \forall j \in \mathbb{N}_{1}^{n_{\Delta}}.
    \end{align}
    \end{subequations}
\end{Proposition}
\begin{proof}
    The proof follows from a direct application of Lemma \ref{Lem:Farkas} to each set inclusion in \eqref{eq:SuffCond}.
\end{proof}

Conditions \eqref{eq:LambdaRefo} will be directly used in the following section to build an algorithm for the design of recursively feasible robust MPC schemes.

\section{Algorithm and properties}\label{Sec:AlgProp}
Building upon the results obtained in the previous sections, a robust MPC algorithm is presented in this section. %The algorithm has two phases, offline and online. The algorithm will be presented first, and then the closed loop properties will be discussed.

\subsection{Terminal components}
It can already be seen that Theorem \ref{Th:RF_RCS} imposes the constraint $t_0\geq 0$. Additionally, Proposition \ref{Prop:LambdaRefo} explicitly formulates constraints under which the MPC problem satisfies SRF. The MPC components in \eqref{eq:OnlOptProb} which are to be computed are  $Y, z, \mathbf{t}$, and the terminal cost $l_N(\cdot)$. The design for SRF does not depend on the choice of the cost function, and hence, $l_N(\cdot)$ will be defined later. 

Ideally, all the components $Y, z, \mathbf{t}$ would be set as decision variables in the offline design problem. However, this would result in large number of bilinear constraints in \eqref{eq:LambdaRefo}, as  $Y$ is a component of $\mathbf{H}_{xu}$ defined in \eqref{eq:Notation1}. 

%Whereas the terms $F$, $G$ and $b$ can be chosen from \eqref{eq:Constraints},  
%However, we need design criteria to choose the terminal set $\mathcal{X}_N$. 
%Ideally, all these components can all be set as variables in the offline optimization problem. Such a choice results in large number of decision variables. 

Thus, in this work, a popular strategy from literature is used to choose $Y$ and $z$ apriori \cite{kouvaritakis2015model,kolmanovsky1998theory}. Specifically, they are chosen to be of the structure of maximal robust positively invariant sets under a terminal feedback law $K_Y$, given as
\begin{align}\label{eq:TermSetPara}
    Y := \begin{bmatrix}
        F+G K_Y \\
        (F+G K_Y) (A+B K_Y)\\
        \vdots
        \\ 
        (F+G K_Y) (A+B K_Y)^{k'}
    \end{bmatrix}, z:=\begin{bmatrix}
        b \\
        b \\
        \vdots \\
        b
    \end{bmatrix}
\end{align}
where $K_Y$ is a feedback chosen such that $A+BK_Y$ is Schur stable, and $k'$ is a positive scalar chosen by the designer depending on the desired flexibility. Under the parameterization \eqref{eq:TermSetPara}, only the tightenings $\mathbf{t}$ are variables in the offline optimization problem, and allow the optimizer to shape the terminal set. 


\subsection{Offline optimization for constraint tightening}
Given an uncertain model \eqref{eq:Dynamics}-\eqref{eq:wBound} and constraint set \eqref{eq:Constraints}, the terminal set is computed as in \eqref{eq:TermSetPara}, and the following optimization problem is solved to compute the tightenings $\mathbf{t}$. 
\begin{align}\label{eq:OfflineOpt_gen}
\begin{split}
    \min_{\substack{\mathbf{t},  K,\\
   \{ \Lambda^j,  \mathbf{M}^j,    \mathbf{K}^j_{\Delta} \}_{j=1}^{n_{\Delta}} }} &l_t(\mathbf{t})\\
    \text{s.t.} \qquad \eqref{eq:LambdaRefo}, \quad &t_0 \ge 0, \quad f_t(\mathbf{t}) \le 0.
\end{split}
\end{align}
In  \eqref{eq:OfflineOpt_gen}, $l_t(\cdot)$ represents an objective function, and $f_t(\cdot)$ represents additional constraints which can be imposed on the tightenings based on the desired goal of the control application. Moreover, the constraint $t_0 \ge 0$ needs to be explicitly enforced, so that recursive feasibility of \eqref{eq:OnlOptProb} results in robust constraint satisfaction, as shown in Theorem \ref{Th:RF_RCS}. 
Note that the guarantees derived in Theorem \ref{Thm:SuffCond} and Proposition \ref{Prop:LambdaRefo} are independent of $l_t(\cdot)$ and $f_t(\cdot)$, as long as \eqref{eq:LambdaRefo} are satisfied.

Here, we describe one possible strategy of choosing $l_t(\cdot)$ and $f_t(\cdot)$, where the design objective is to maximize the region of attraction (ROA) of the closed loop system. The ROA is defined by the feasible region of the MPC optimization \eqref{eq:OnlOptProb}, and thus is a convex polytope. Because the volume of a generic polytope is difficult to compute  even when the hyperplanes are known apriori \cite{lawrence1991polytope}, maximizing ROA is a difficult task. Under the chosen parameterization \eqref{eq:OnlOptProb}, minimization of $\norm{\mathbf{t}}_2$ can be used as an approximation for maximizing ROA as proposed in \cite{parsi2022computationally}. 

However, solely approximating ROA maximization with minimization of $\norm{\mathbf{t}}_2$ can sometimes lead to poor results. In this work, the approximation is improved by additionally maximizing the size of an $l_1$-norm ball that can fit inside the feasible region of the state space. Consider the vertices of the unit-$l_1$-norm ball in $\mathbb{R}^{n_x}$, represented by $\{x^i\}_{i=1}^{2n_x}$, which lie on the positive and negative directions of the principal axes of the state space. For each vertex, define the corresponding MPC optimization variable $\mathbf{s}^i_{\alpha}$ as
\begin{equation}
    \mathbf{s}^{i}_{\alpha} = \begin{bmatrix}
        \alpha {x^i} \\ \mathbf{u}^i
    \end{bmatrix}, \quad \forall i \in \mathbb{N}_{1}^{2n_x}
\end{equation}
where $\alpha$ is a positive scalar defining the size of the $l_1$-norm ball, and $\mathbf{u}^i$ represents a feasible input sequence for the $i^{\text{th}}$ vertex. Then, the offline optimization problem can be written as
\begin{subequations}\label{eq:OfflineOpt}
\begin{align}
    \min_{\substack{\mathbf{t},  K, \alpha, \{\mathbf{u}^{i}\}_{i=1}^{2n_x}, \\
   \{ \Lambda^j,  \mathbf{M}^j,    \mathbf{K}^j_{\Delta} \}_{j=1}^{n_{\Delta}} }} &\norm{\mathbf{t}}_2 - \mu \alpha \label{eq:OfflineOpt1}\\
    \text{s.t.} \qquad &     \Lambda^j \ge 0, \quad \alpha > 0, \quad t_0 > 0, \label{eq:OfflineOpt2}\\
        \Lambda^j \begin{bmatrix}
        \mathbf{H}_{xu}\mathbf{S} & 0 \\
        0 & H_w
    \end{bmatrix} &= \mathbf{H}_{xu}\begin{bmatrix}
        \mathbf{C}_K^j &   \mathbf{C}_M^j
    \end{bmatrix}, \label{eq:OfflineOpt3}\\
    \Lambda^j \begin{bmatrix}
        \mathbf{b}-\mathbf{t} \\ h_w
    \end{bmatrix} &\le \mathbf{b}-\mathbf{t}, \quad \forall j \in \mathbb{N}_{1}^{n_{\Delta}}, \label{eq:OfflineOpt4}\\
    \mathbf{H}_{xu} \mathbf{S} \mathbf{s}^{i}_{\alpha} &\le \mathbf{b-t}, \quad \forall i \in \mathbb{N}_{1}^{2n_x}, \label{eq:OfflineOpt5}
\end{align}
\end{subequations}
where  $\mu$ is a positive weighting factor between minimizing $\norm{\mathbf{t}}$ and maximizing $\alpha$.
Additionally, \eqref{eq:OfflineOpt5} represent the feasibility constraints for each vertex of the $l_1$-norm ball. 


%This is an approximation of the ideal objective, which would be the maximization of the feasible region of the online MPC optimization \eqref{eq:OnlOptProb}, also called as the region of attraction (ROA). Such an approximation is required, because estimating the ROA is a difficult task for high-dimensional polytopes. A similar approximation is also used in \cite{parsi2022computationally} to simplify the ROA maximization problem. 

The optimization problem \eqref{eq:OfflineOpt} is non-convex, due to the presence of bilinear constraints \eqref{eq:OfflineOpt4}.  Although this increases the complexity of design,  problem \eqref{eq:OfflineOpt} needs to be solved only once, in the offline phase. Moreover, given a good initial guess of the tightenings $\mathbf{t}$, feasible solutions to all the other optimization variables can be computed by solving a convex optimization problem (by fixing $\mathbf{t}$ in \eqref{eq:OfflineOpt}). This provides a simple way to initialize non-convex optimization algorithms to solve \eqref{eq:OfflineOpt}. 
    
\begin{Remark}[Initial guess]\label{Rem:InGuess}
It can be difficult to compute a feasible initial guesses for the tightenings  $\mathbf{t}$ in \eqref{eq:OfflineOpt}, as the tightenings are problem dependent. In practice, one strategy which produced good results was to use an existing constraint tightening technique, such as \cite{chisci2001systems} or \cite{parsi2022computationally} to guess $\mathbf{t}$. Note that these techniques were designed for systems affected by additive disturbances alone, and may not always result in feasible initial guesses for $\mathbf{t}$. 
\end{Remark}

\subsection{Cost functions and online optimization}
Whereas the constraints in \eqref{eq:OnlOptProb} enable constraint satisfaction and recursive feasibility, the cost function must be chosen to guarantee closed loop stability. The goal of this work is to highlight former part of the design of robust MPC schemes, that is, the design of constraints. The proposed theory can be used in conjunction with any stage cost $l(\cdot)$ and terminal cost $l_N(\cdot)$ functions. A tracking cost formulation is presented here to improve clarity for the reader.  %Moreover, given the guarantees of robust constraint satisfaction and recursive feasibility, the following notion of stability is always satisfied for any choice of the cost function.

Consider the stage cost defined as
\begin{equation}
    l(x,u) = x\tr Q_x x + u\tr Q_u u,
\end{equation}
where the matrices $Q_x, Q_u$ are positive definite. Then, a terminal cost of the form $l_N(x) = x\tr Q_N x$ can be defined using a positive definite matrix $Q_N$ which can be computed as the solution to the discrete-time algebraic Riccati equation under the state feedback defined by $K_Y$. Thus, the online optimization is 
\begin{subequations}\label{eq:OnlOptProb_reg}
    \begin{align}
        \min_{\hat{\mathbf{x}}_k,\hat{\mathbf{u}}_k}  \quad  \hat{x}_{N|k}\tr Q_N \hat{x}_{N|k} + &\textstyle\sum_{i=0}^{N-1}  \hat{x}_{i|k}\tr Q_x \hat{x}_{i|k} +  \hat{u}_{i|k}\tr Q_u \hat{u}_{i|k} \label{eq:OnlOptProb_reg1} \\
		\text{s.t.} \quad A\hat{x}_{i|k} + B\hat{u}_{i|k} &= \hat{x}_{i|k+1}, \quad \hat{x}_{k,0}=x_k, \label{eq:OnlOptProb_reg2}\\
            F\hat{x}_{i|k} + G\hat{u}_{i|k}  &\le b - t_i,  \quad i\in \mathbb{N}_{0}^{N-1}, \label{eq:OnlOptProb_reg3} \\
            Y\hat{x}_{N|k} &\le z - t_N. \label{eq:OnlOptProb_reg4}
    \end{align}
\end{subequations}

The computational complexity of \eqref{eq:OnlOptProb_reg} is the same as that of a nominal MPC problem. This enables a large computational advantage compared to existing robust MPC methods, such as tube MPC \cite{parsi2022scalable,langsonRobust}. 

\subsection{Robust MPC algorithm}
Using the offline \eqref{eq:OfflineOpt} and online \eqref{eq:OnlOptProb_reg} optimization problems, a robust MPC algorithm is formally described in Algorithm \ref{Alg:RMPC}. The properties of the proposed algorithm will now be discussed. For this purpose, the notion of regional input to state practical stability (ISpS) is first defined.

\begin{algorithm}[t]
\caption{Closed loop design for robust MPC}\label{Alg:RMPC}
\begin{algorithmic}[1]
\Statex \textbf{Offline:} 
\State Choose $K_Y$ and compute terminal components \eqref{eq:TermSetPara}
\State Choose $\mu$ 
\State Solve  \eqref{eq:OfflineOpt} to compute $\mathbf{t}$
%\State Set $\mathbf{t}=\boldsymbol{\tau^*}$
%\Statex 
\setcounter{ALG@line}{0}
\Statex \textbf{Online:} At each time-step $k\ge0$:
\State Obtain the measurement $x_k$
\State Solve \eqref{eq:OnlOptProb_reg}
\State Apply $\pi(x_k)=\hat{u}^*_{k,0}$ 
\end{algorithmic}
\end{algorithm}

\begin{Definition}[Regional ISpS in $\mathbb{X}$ \cite{raimondo2009min}]
    Given a system whose dynamics can be described by  \eqref{eq:Dynamics}-\eqref{eq:wBound}, and a compact set
$\mathbb{X}\subseteq \mathbb{R}^{n_x}$ including the origin as an interior point, the system is said to be ISpS (input-to-state practically stable) in $\mathbb{X}$ with
respect to $w_k$ if $\mathbb{X}$ is a robust positively invariant set and if there exist a $\mathcal{KL}$ function $\beta(\cdot, \cdot)$, a $\mathcal{K}$ function $\lambda(\cdot)$ and a
constant $c \ge 0 $ such that, for all $x_0 \in \mathbb{X}$ and $k \ge 0$
\begin{equation}\label{eq:ISpS}
    \norm{x_k} \le \beta(\norm{x_0},k) + \lambda(\norm{\mathbf{w}}) + c,
\end{equation}
where $\mathbf{w} = \{w_0, w_1, \ldots, w_{k-1} \}$.
\end{Definition}
Regional ISpS is typically used to analyze systems defined by robust MPC controllers with a worst-case cost function \cite{limon2009input}. This is a weaker notion of stability compared to asymptotic stability and input-to-state (ISS) stability, but requires no further design conditions or assumptions on the system. A stronger notions of stability, such as ISS, would require further design assumptions, and will be the subject of future research.

\begin{Proposition}\label{Prop:Props}
    Let the offline optimization problem \eqref{eq:OfflineOpt} be feasible, and the online optimization \eqref{eq:OnlOptProb_reg} have a feasible solution at time $k=0$. Moreover, let $\mathbb{P}_{0,x}$ be the projection of $\mathbb{P}_0$ on the first $n_x$ elements of $\mathbf{s}_k$. Then, the closed loop formed by a system with dynamics \eqref{eq:Dynamics}-\eqref{eq:wBound} and the robust MPC controller in Algorithm \ref{Alg:RMPC} satisfies the following properties
    \begin{enumerate}[label=(\alph*)]
        \item The online optimization \eqref{eq:OnlOptProb} remains feasible for all $k > 0$. \label{Thm:Props1}
        \item The constraints \eqref{eq:Constraints} are satisfied for all $k > 0$.\label{Thm:Props2}
        \item The closed loop system is regionally ISpS in $\mathbb{P}_{0,x}$ with respect to $w_k$.\label{Thm:Props3}
    \end{enumerate}    
\end{Proposition}
\begin{proof}
    Property \ref{Thm:Props1} is satisfied as a consequence of Proposition \ref{Prop:LambdaRefo}. Because the offline optimization problem is feasible, Assumption \ref{Ass:RecFeas2} is satisfied. Therefore, the online optimization \eqref{eq:OnlOptProb_reg} is recursively feasible. 

    Moreover, \ref{Thm:Props2} follows from Theorem \ref{Th:RF_RCS}. This is because the offline optimization \eqref{eq:OfflineOpt} explicitly enforces $t_0 \ge 0$, and Assumption \ref{Ass:RecFeas2} implies that Assumption \ref{Ass:RecFeas} is satisfied. 

    Finally, the proof of \ref{Thm:Props3} can be seen as follows. For any state $x\in \mathbb{P}_{0,x}$, under the robust MPC controller, it is guaranteed that the state at the next time step is also inside $\mathbb{P}_{0,x}$. This is because the optimization \eqref{eq:OnlOptProb_reg} is recursively feasible by design. Therefore, the set $\mathbb{P}_{0,x}$ is a robust positively invariant set of the closed loop system. Then, the constant $c$ in \eqref{eq:ISpS} can be chosen as $c = \max_{x\in \mathbb{P}_{0,x}} \norm{x}$, so that \eqref{eq:ISpS} always holds.
\end{proof}

\subsection{Discussion}
The central idea of this work is that recursive feasibility implies constraint satisfaction, as shown in Theorem \ref{Th:RF_RCS}. However, barring a few results in early MPC literature \cite{chisci2001systems,kerrigan2001Robust}, this idea has not been fully utilized. Hence, some discussion is warranted on interesting research directions.

\subsubsection{Beyond constraint tightening}
Theorem \ref{Th:RF_RCS} does not restrict the robust MPC optimization to be of the structure \eqref{eq:OnlOptProb_reg}, which is a characteristic of constraint tightening techniques. The theorem is also valid for any MPC optimization of the form
\begin{subequations}\label{eq:OnlOptProb_flex}
    \begin{align}
        \min_{\hat{\mathbf{x}}_k,\hat{\mathbf{u}}_k}  \quad  \hat{x}_{N|k}\tr &Q_N \hat{x}_{N|k} + \textstyle\sum_{i=0}^{N-1}  \hat{x}_{i|k}\tr Q_x \hat{x}_{i|k} +  \hat{u}_{i|k}\tr Q_u \hat{u}_{i|k} \label{eq:OnlOptProb_flex1} \\
		\text{s.t.} \quad &\hat{x}_{k,0}=x_k,\\
            A&\hat{x}_{i|k} + B\hat{u}_{i|k} = \hat{x}_{i|k+1}, \:  \forall i\in \mathbb{N}_{0}^{N-1},\label{eq:OnlOptProb_flex2}\\
             % &\qquad \qquad \nonumber\\
            &F\hat{x}_{0|k} + G\hat{u}_{0|k}  \le b,   \label{eq:OnlOptProb_flex3} \\
            &\Phi_x \hat{x}_{0|k} + \Phi_u \hat{\mathbf{u}}_k \le \phi, \label{eq:OnlOptProb_flex4}
    \end{align}
\end{subequations}
where $\Phi_x,\Phi_u$ and $\phi$ can be chosen by the designer. In \eqref{eq:OnlOptProb_flex}, the system's constraints \eqref{eq:Constraints} are only imposed on the first state and input in the prediction horizon in \eqref{eq:OnlOptProb_flex3}, which can be seen as selecting $t_0 = 0$ in \eqref{eq:OnlOptProb}. Using a similar approach as in Theorem \ref{Thm:SuffCond} and Proposition \ref{Prop:LambdaRefo}, sufficient conditions can also be derived for SRF of \eqref{eq:OnlOptProb_flex}. However, in practice, solving the resulting non-convex optimization problem is harder, due to the higher number of bilinearities. 

\subsubsection{Robust control invariance}
A key concept which is known in control literature is that of robust control invariance (RCI) \cite{blanchini2008set,kerrigan2001robust_PHD}. As opposed to  robust invariance (RI), which considers invariance of autonomous systems subject to uncertainty, RCI considers systems where an input can be designed. For this reason, computation of RCI sets is challenging \cite{rakovic2007optimized,rungger2017}.  

RCI provides an alternative interpretation of Theorem \ref{Thm:NecSuff}. A necessary and sufficient condition for strong recursive feasibility of MPC is that the feasible region is RCI. Because generic RCI sets are difficult to compute, the proposed method uses parameterized feedback laws to formulate the problem as computation of the resulting RI sets. Note that all RI sets are also RCI sets, and are easier to compute in practice. One possible research direction is to improve the proposed method of computing RCI sets using existing ones from literature.

\section{Illustrative example}
In this section, the proposed algorithm will be used to generate controllers for a mass-spring-damper system, where two masses which are connected to each other by a spring and a damper whose spring constant and damping coefficient are uncertain.  
%In this section, the proposed algorithm will be used to generate controllers for two different systems, and the resulting performance is studied in simulation. The first system is a mass-spring-damper whose spring stiffness and damping coefficient are uncertain, as considered in \cite{parsi2022scalable}. The second system is a chemical reactor affected by persistent disturbances, as presented in \cite{alvarado2022tractable}. The code to simulate both these examples is available in an online repository \ani{\cite{Parsi}}.
% \subsection{Mass-spring-damper example}\label{Sec:MSD}
%The first example is of system with two masses which are connected to each other by a spring and a damper. 
The example has been adapted from \cite{parsi2022scalable}, where similar systems with increasing number of masses are considered, and a tube MPC strategy was used to design the controller. The system dynamics can be represented in discrete time by 
\begin{align}\label{eq:MSD_Dyn}
\begin{split}
A &= \left[ \arraycolsep=4pt \begin{array}{cccc}
1 & T_s & 0  & 0 \\
{-}\frac{k_{12}T_s}{m_1} & {-}\frac{c_{12}T_s}{m_1}{+}1 & \frac{k_{12}T_s}{m_1} & \frac{c_{12}T_s}{m_1} \\ 
0 & 0 & 1  & T_s\\
\frac{k_{12}T_s}{m_2} & \frac{c_{12}T_s}{m_2} & {-}\frac{k_{12}T_s}{m_2} & -\frac{c_{12}T_s}{m_2} {+} 1 \\
\end{array}\right], \\
%
B_p &{=} \left[ \begin{array}{cccc}
0 & 0   \\
\frac{k_{u}T_s}{m_1} & \frac{c_u T_s}{m_1}  \\
0 & 0 \\
{-}\frac{k_{u}T_s}{m_2} & {-}\frac{c_{u}T_s}{m_2}  \\
\end{array} \right] , 
B {=} 
\begin{bmatrix}
0 & 0  \\
\frac{T_s}{m_1} & 0  \\
0 & 0  \\
0 & \frac{T_s}{m_2} 
\end{bmatrix}, 
B_w {=} w_b B, \\
D_q &= 
\begin{bmatrix}
{-}1 & 0 \\
0 & {-}1  \\
\end{bmatrix}, \quad D_u = 0, \quad D_w = 0,
\end{split}
\end{align}
where $m_1 = m_2 =0.2\mathrm{kg}$ is the mass, $k_{12} = 0.5 \mathrm{Nm^{-1}}$ and $c_{12} = 0.5 \mathrm{Nsm^{-1}}$ are the nominal spring constant and damping coefficient. The terms $k_u = 0.04 k_{12}$ and $c_u = 0.02 c_{12}$  model the uncertainty in the spring and damping coefficients respectively. In addition, $T_s = 0.1\mathrm{s}$ represents the sampling time used for discretization, and $w_b=0.2$ represents the bound on a disturbance acting on the velocity states. The states of the system is a stacked vector of the  position and velocity of each mass, and the input is a vector of forces acting on each mass.  The magnitudes of the states and inputs are bounded by 2. 

Two controllers are designed for the system. The first uses Algorithm \ref{Alg:RMPC}, and is referred to as CLR, for closed loop robust MPC. The second uses the method proposed in \cite{parsi2022scalable}, where an ellipsoidal tube is constructed at each time step by the controller to bound the states and inputs in the prediction horizon. This method will be referred to as ET, for ellipsoidal tube MPC. Both the controllers use $N=8$ time steps. The terminal components of CLR are computed using $K_Y$ as the LQR gain, and $k' = 3$. 

The initial state of the system is chosen to be $x_0 = [1.9,0.5,-1.7,1.7]\tr$. The disturbance affecting the system is the same for both the controllers, and is sampled from a uniform distribution in $\mathcal{W}$. The simulations were performed for 50 realizations of the spring constants, damping coefficients and disturbance sequences chosen using a uniform distribution within the specified bounds. 

The closed loop trajectories of the system are shown in Figure \ref{fig:traj_msd}, where the largest and smallest values of state and input variables at each time step are plotted as a function of time. It can be seen that both the controllers successfully regulate the state to the origin without constraint violations. However, the ET controller is aggressive at the start of the simulation, because $[x]_1$ is too close to the constraint, and the mass has a positive velocity. Moreover, the ET controller recursively outer-approximates the effect of worst-case perturbations on state trajectories over the prediction horizon, resulting in the aggressive behavior. The average closed loop cost achieved by CLR is 83.1 and that for ET is 94.4.   

It was observed that CLR requires higher offline computation times compared to ET, but results in a much lower online computation time. This is because the ET algorithm solves semi definite programs offline and online, whereas CLR  solves a non-convex optimization offline and a quadratic program online. All the optimization problems were solved  on a laptop with Intel i7-8550U processor, and setup using YALMIP \cite{Lofberg2004}. The convex optimization problems were solved using Gurobi \cite{gurobi} and MOSEK \cite{mosek}, and the non-convex optimization using IPOPT \cite{wachter2006implementation}. The offline computation time for the CLR controller is  $ 180.8 \mathrm{s}$, whereas that for ET is $ 0.06 \mathrm{s}$.  The average online computation time for CLR is $ 2.2 \mathrm{ms}$, whereas that for ET is $ 53.9 \mathrm{ms}$. 

\begin{figure}[t]
	\centering
	\includegraphics{traj_msd.eps}
	\caption{ Upper and lower bounds on the closed loop trajectories with CLR and ET MPC algorithms over 25 random realizations of disturbances and true system parameters.} 
	\label{fig:traj_msd}
\end{figure}

% \subsection{Chemical reactor example}\label{Sec:ChemReac}
% In this example, a double reactor and separator system is considered. This example has been studied in \cite{alvarado2022tractable}, where a robust MPC controller was designed using constraint tightening. In this work, the proposed method will be compared to that proposed in \cite{alvarado2022tractable}, and the latter will be referred to as AT (for Alvarado's tightening). 

% The description of the nonlinear dynamics for this system is given in \cite[~Section 5.1]{krupa2021implementation}, and the application of the proposed method to this system is explained in \cite{bartos2023}. Two first order reactions of the following form take place in the system
% \begin{equation*}
%     \mathcal{R} \rightarrow \mathcal{S}, \quad \quad \mathcal{S} \rightarrow \mathcal{T},
% \end{equation*}
% where $\mathcal{R}, \mathcal{S}$  and $ \mathcal{T}$ represent the reactants. The plant consists two reactors and a separator connected in series. The state of the system is given by
% \begin{equation*}
% \setcounter{MaxMatrixCols}{20}
%     x = \begin{bmatrix}
%         h_1 & c_{\mathcal{S}1} & c_{\mathcal{R}1} & T_1 &
%         h_2 & c_{\mathcal{S}2} & c_{\mathcal{R}2} & T_2 &
%         h_3 & c_{\mathcal{S}3}  & c_{\mathcal{R}3} & T_3 
%     \end{bmatrix}\tr,
% \end{equation*}
% where the subscripts $1,2$ refer to the two reactors and $3$ to the separator. Moreover for $i\in \mathbb{N}_1^{3}$, $h_i$ represents the height of the liquid in container $i$, $c_{Xi}$  represents the concentration of reactant $X$ in container $i$ and $T_i$ represents the temperature of the liquid in container $i$. The control input is 
% \begin{equation*}
%     u = \begin{bmatrix}
%         \mathcal{Q}_1 & \mathcal{Q}_2 &\mathcal{Q}_3 & \mathcal{F}_1 & \mathcal{F}_2 & \mathcal{F}_r
%     \end{bmatrix}\tr ,
% \end{equation*}
% where $\mathcal{Q}_i$ represents the heat transferred/removed from the container $i$, $F_1, F_2$ represent external feed rates into the containers 1 and 2, and $F_r$ represents the feed rate from container 3 into container 1. The dynamics are linearized as proposed in \cite{alvarado2022tractable}. In addition, bounded additive disturbances are assumed to be acting on the three height states and the three temperatures. The bounds on the disturbances on heights are $\pm 0.01 \mathrm{m}$ and that for the temperatures are $\pm 1 \mathrm{K}$. All the states and inputs are constrained by individual upper and lower bounds, as specified in \cite[Table 5.1]{krupa2021implementation}. 

% The proposed CLR controller was designed with fixed value of $\mu=0.2 $ in \eqref{eq:OfflineOpt}. In addition the gain $K_Y$ was chosen as the optimal LQR feedback gain. The design of AT uses hyperparameters, whose values were chosen as $\rho = 0.2, \mu = 0.2 $ and $\lambda = 0.6$, after reasonable amount of tuning to achieve a large ROA. Both the controllers were designed for three different values of prediction horizon, specifically, $N = 2,3, 5$. Due to the large state dimension, the offline optimization of CLR required large computation times, which were $759, 2483$ and $ 10036 $ seconds for $N = 2,3$ and $ 5$ respectively. Note that, the terminal set parameterization was slightly modified, in that only active constraints in the MRPI set were selected from \eqref{eq:TermSetPara}, so that the computation time can be reduced. 

% The ROA achieved by each controller is estimated by gridding the state space, as the volume of the feasible region of \eqref{eq:OnlOptProb} is difficult to compute. The ROA is estimated by only gridding the heights in each container with \ani{50} points along each dimension and setting all the other states are set to be at \ani{the origin}. The ROA achieved by CLR and AT are compared in Figure \ref{Fig:ROA_plant}. It can be seen that the CLR method doubles the ROA achieved by AT for all the scenarios. 
 
\section{Conclusions}
A novel design approach was presented for robust MPC, using the property that recursive feasibility can imply constraint satisfaction in closed loop. Recursive feasibility is a one-step property, meaning that it depends on perturbations occurring at \emph{one} time step. Moreover, recursive feasibility only requires the existence of a feasible input sequence at the subsequent time step, as the MPC optimizer can compute the input sequence in closed loop. Exploiting these ideas, it was shown that recursive feasibility can be imposed as a constraint in the robust MPC design. Such a design reduces the conservatism of most existing MPC methods, which ensure constraint satisfaction by computing feasible open-loop trajectories under multiple perturbations and disturbances occurring along the prediction horizon.

As a part of our ongoing research, we extend the proposed fundamental idea to different control synthesis frameworks. For instance, System Level Synthesis [XX] framework 

\appendix
\section*{Appendix}
\section{Algebraic simplification of $\mathbf{Ss}_k$ in (\ref{eq:s_k+1})}\label{app: AppendixA}
\begin{subequations}
\begin{align}
    \mathbf{S} \mathbf{s}_{k+1} &=   \mathbf{S}_x x_{k+1} +  \mathbf{S}_u \hat{\mathbf{u}}_{k+1}, \label{eq:s_k+1_1}\\
    &=  \mathbf{S}_x (A x_k + B u_k)  + 
   \mathbf{S}_x\big( B_w w_k +B_p \Delta_k (D_x x_k \nonumber\\ 
   &\quad + D_u u_k + D_w w_k)\big)+\mathbf{S}_u \hat{\mathbf{u}}_{k+1} \label{eq:s_k+1_2}\\
       & =(\mathbf{L} {+} \mathbf{S}_x B_p \Delta_k  D_{xu}  ) \mathbf{s}_k \nonumber\\ 
     &\quad + \mathbf{S}_x (B_w {+} B_p \Delta_k D_w )w_k +  \mathbf{S}_u \hat{\mathbf{u}}_{k+1} \\
     &=\mathbf{C_ss}_k + \mathbf{C_w}w_k + \mathbf{S}_u \hat{\mathbf{u}}_{k+1},
\end{align}
\end{subequations}
\section{Algebraic simplification of $\mathbf{Ss}_k$ in (\ref{eq:SuffCondPf1})}\label{app: AppendixB}
\begin{subequations}\label{eq:SuffCondPf11}
\begin{align}
    &\mathbf{S} \mathbf{s}_{k+1} = (\mathbf{L} {+} \mathbf{S}_x B_p \sum_{j=1}^{n_\Delta} \tau_j \Delta^j  D_{xu}  ) \mathbf{s}_k  \nonumber \\
     & {+} \mathbf{S}_x (B_w {+} B_p \sum_{j=1}^{n_\Delta} \tau_j\Delta^j D_w )w_k  +\mathbf{S}_u  \sum_{j=1}^{n_\Delta} \tau_j \hat{\mathbf{u}}_{k+1}^j \label{eq:SuffCondPf1_1}\\
     &= \sum_{j=1}^{n_\Delta} \tau_j \bigg( \bigg( \mathbf{L}_K^j + \mathbf{S}_x B_p \Delta^j  D_{xu}  \nonumber\\ 
     &\quad + \mathbf{S}_u \mathbf{K}^j_{\Delta} \begin{bmatrix}
        I_{n_x+n_u}  & 0_{n_x+n_u, n_u(N-1)}
    \end{bmatrix}\bigg) \mathbf{s}_k, \nonumber \\     
    & \quad + \textbf{S}_x \big( B_w + B_p\Delta^jD_w \big) w_k + \mathbf{S}_u\mathbf{M}^j B_w w_k
        \bigg) \label{eq:SuffCondPf1_2}\\
        & = \sum_{j=1}^{n_\Delta} \tau_j \bigg(\mathbf{C}_K^j s_k + \mathbf{C}_M^j w_k  \bigg) . \label{eq:SuffCondPf1_3}
\end{align}
\end{subequations}
In \eqref{eq:SuffCondPf11}, \eqref{eq:SuffCondPf1_2} is obtained by plugging in the control law \eqref{eq:InputParameterization} in \eqref{eq:SuffCondPf1_1} and using the definition of $\mathbf{L}_K^j$.
\bibliographystyle{plain}        %Include this if you use bibtex 
%\bibliographystyle{unsrtnat}
\bibliography{autosam}           % and a bib file to produce the 
                                 % bibliography (preferred). The
                                 % correct style is generated by
                                 % Elsevier at the time of printing.

\appendix

\end{document}