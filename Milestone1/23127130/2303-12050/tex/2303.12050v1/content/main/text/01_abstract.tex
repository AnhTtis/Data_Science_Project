%%%%%%%%% ABSTRACT



\begin{abstract}

% Version 1:
% Modern depth sensors such as LiDAR operate by sweeping laser-beams across the scene, resulting in a point cloud with notable 1D curve-like structures. However, most existing point cloud backbones  discard the rich, 1D traversal patterns and rely mainly on Euclidean operations.
% In this work, we present a novel point cloud processing scheme and backbone, \textbf{CurveCloudNet}, that exploits the curve-like structure of modern depth sensors. Concretely, %instead of treating each point independently, 
% we parameterize the point cloud as a collection of polylines and thus establish a local surface-level ordering on the points. 
% We then devise curve-specific operations to process the ``curve clouds:'' (1) a \textit{symmetrical 1D convolution}, 2) a \textit{ball grouping} operation for merging points along curves, and (3) an efficient \textit{1D furthest-point-sampling} algorithm on curves. \textbf{CurveCloudNet} combines these curve operations with existing point-based operations, resulting in an efficient, scalable, and expressive backbone that uses little GPU memory. We evaluate \textbf{CurveCloudNet} on the ShapeNet, Kortx, Audi Driving, and nuScenes datasets, showcasing state-of-the-art segmentation and classification performance across {\em both} object-level and large outdoor scene datasets, the first reported 3D point backbones to do so. 

% Version 2:
% In this work we introduce a new point cloud processing scheme and backbone, called CurveCloudNet, which takes advantage of the curve-like structure inherent in modern depth sensors such as LiDAR. While traditional point cloud backbones discard the rich, 1D laser-traversal patterns and rely on Euclidean operations, CurveCloudNet parameterizes the point cloud as a collection of polylines. This parameterization establishes a local surface-level ordering on the points. Our method applies curve-specific operations to process the ``curve clouds," including symmetrical 1D convolution, ball grouping for merging points along curves, and an efficient 1D furthest-point-sampling algorithm on curves. Combining these curve operations with existing point-based operations results in an efficient, scalable, and expressive backbone that uses little GPU memory. We evaluate CurveCloudNet on several datasets, including ShapeNet, Kortx, Audi Driving, and nuScenes, and report state-of-the-art segmentation and classification performance across \textbf{both} object-level and large outdoor scene datasets, making CurveCloudNet the first 3D point backbone to achieve such results.
% \vspace{-1em}

% Version 3
Modern depth sensors such as LiDAR operate by sweeping laser-beams across the scene, resulting in a point cloud with notable 1D curve-like structures. In this work, we introduce a new point cloud processing scheme and backbone, called CurveCloudNet, which takes advantage of the curve-like structure inherent to these sensors. While existing backbones discard the rich 1D traversal patterns and rely on Euclidean operations, CurveCloudNet parameterizes the point cloud as a collection of polylines (dubbed a ``curve cloud‚Äù), establishing a local surface-aware ordering on the points. Our method applies curve-specific operations to process the curve cloud, including a symmetric 1D convolution, a ball grouping for merging points along curves, and an efficient 1D farthest point sampling algorithm on curves. By combining these curve operations with existing point-based operations, CurveCloudNet is an efficient, scalable, and accurate backbone with low GPU memory requirements. 
% CurveCloudNet achieves state-of-the-art segmentation performance on the ShapeNet, Kortx, Audi Autonomous Driving, and nuScenes datsets, which include both individual objects and large outdoor scenes captured with various sensor scanning patterns. These evaluations demonstrate that \arch scales to large scenes better than existing point-based backbones while improving object-level semantic segmentation compared to sparse-voxel backbones.
Evaluations on the ShapeNet, Kortx, Audi Driving, and nuScenes datasets demonstrate that \arch outperforms both point-based and sparse-voxel backbones in various segmentation settings, notably scaling better to large scenes than point-based alternatives while exhibiting better single object performance than sparse-voxel alternatives.

% Evaluations on ShapeNet, Kortx, Audi Driving, and nuScenes demonstrate that \arch outperforms point-based methods on both individual objects and large-scale scenes, outperforms sparse-voxel backbones on individual objects, and closes the gap between point-based and sparse-voxel backbones on large-scale scenes while requiring significantly less GPU memory.

% CurveCloudNet is evaluated on several datasets that include both individual objects and large
% outdoor scenes captured with various sensor scanning patterns. These evaluations demonstrate that our model can
% outperform point-based and sparse-voxel backbones at both
% object and scene level, achieving state-of-the-art performance on segmentation tasks.
\vspace{-1em}
\end{abstract}


% ================= OLD VERSIONS======================
% ====================================================
% We then adapt three standard point cloud operations for the resulting ``curves": (1) a \textit{symmetrical 1D convolution} that operates along curves, (2) a \textit{ball grouping} similar to PointNet++ \cite{Qi2017NIPS} that groups points along curves, and (3) an efficient \textit{1D furthest-point-sampling} algorithm on curves. \textbf{CurveCloudNet} combines these curve operations with point-based operations, resulting in an efficient, scalable, and expressive backbone that uses little GPU memory. We evaluate \textbf{CurveCloudNet} on the ShapeNet, Kortx, Audi Driving, and nuScenes datasets, showcasing state-of-the-art segmentation and classification performance across both object-level and outdoor datasets with various sensor configurations.

% , including ShapeNet, Kortx, Audi Driving, and nuScenes datsets. and we consistently achieve state-of-the-art segmentation and classification performance across datasets.

% We present a new point cloud processing backbone, dubbed CurveCloudNet, that exploits the curve-like structure of point cloud outputs of modern 3D sensors, e.g., LiDAR. CurveCloudNet represents the lasers' sweeping trajectories as 1D polyline curves and aims to process the ``curve clouds'' for perception tasks, leveraging the geodesic proximity of the curve points. We adapt three standard point cloud operations to work on  

% Many high-fidelity and long-range 3D scanners, such as LiDAR, sweep laser beams across surfaces to obtain 3D measurements. 
%
% Due to the lasers' traversals, the resulting point cloud contains a rich 1D sampling structure, akin to curves.
%; in fact, the point cloud is comparable to an unordered set of 1D curves. 
%
% Despite this, most state-of-the-art point cloud backbones ignore this 1D pattern, overlooking benefits resulting from structuring the 3D point cloud in a manner consistent with its 1D capture. % overlooking intrinsic structure and geometry improvements in  inefficiency and accuracy captured 1D geometric information such as surface connectivity, boundaries, curvatures, and tangents. 
%
% However, Euclidean operations discard additional geometric information resulting from the scanning pattern, such as intrinsic surface connectivity along a curve and surface boundary information at curve endpoints, and (2) euclidean point operations do not efficiently scale to large scenes.
%
% In this work, we explicitly interpret the lasers' sampling trajectories as 1D polyline ``curves".
%
% We propose a new point cloud backbone, \textbf{CurveCloudNet}, that makes use of highly efficient sampling, grouping, and convolution operations along curves.
%
% By reasoning along curves, CurveCloudNet is a scalable backbone that can better leverage the aforementioned 1D geometric information.
% 
% Then, we propose a novel 3D point cloud backbone, \textbf{CurveCloudNet}, that makes use of curve and point operations.
%
% CurveCloudNet leverages additional curve information and structure to significantly improve accuracy and generalizability.
%
% CurveCloudNet achieves state-of-the-art performance on object-level part segmentation from real world scans.
%
% Furthermore, CurveCloudNet greatly outperforms previous point cloud backbones on LiDAR segmentation, bridging the gap between point-cloud and sparse-voxel methods on large LiDAR scenes.
%
% Finally, CurveCloudNet is more flexible than previous backbones: it is the only backbone to consistently achieve SOTA accuracy and efficiency across different point cloud sizes (\ie from object level to large-scale scenes) as well as different laser scanning patterns.
%
% On real-world object part segmentation, CurveCloudNet improves accuracy over previous methods while maintaining low latency and GPU memory usage. 
%
% On scene-level LiDAR segmentation, CurveCloudNet significantly outperforms previous point-based methods, lowers the GPU memory footprint compared to sparse-voxel methods, and generalizes across domains better than all methods.




% \begin{abstract}
%     Applying deep learning methods to point cloud data is an exceptionally well studied problem.
%     %
%     Still, state-of-the-art backbones are usually developed for and evaluated on data that is dense, uniformly sampled on the object surface, and unoccluded.
%     %
%     % Counter to this practice, point cloud backbones are known to exhibit unpredictable and adverse behavior in less idyllic scenarios.  
%     Counter to this practice, many real-world laser scanners, such as LiDAR, acquire 3D measurements along a piece-wise 1D manifold. That is, points are sampled densely in the direction of the laser's motion and no points sampled in the orthogonal direction.
%     %
%     In this work, we aim to better understand the 1D ``curve" sampling pattern that arises from these scanners. 
%     %
%     % Specifically, laser scanners acquire 3D measurements along a piece-wise 1D manifold: points are sampled densely in one direction and are not sampled in the orthogonal plane.
%     %
%     First, we provide an analysis of how existing backbones accommodate a variety different curve sampling patterns on the ShapeNet Part Segmentation Benchmark.
%     %
%     Then, we propose a set of ``curve-aware" modules that improve existing models' performance by operating on polylines extracted from the 1D pattern.
%     %
%     Finally, we integrate our curve-aware modules into LiDAR backbones and show network improvements on the popular SemanticKitti Benchmark and the Audi Autonomous Driving Dataset.
%     % 
%     We consider this work a first step towards treating scanning patterns as sets of 1D submanifolds embedded in $\mathbb{R}^3$.

% \end{abstract}