
\section{Introduction}
\label{sec:intro}
% \input{content/main/figures/teaser}
\input{content/main/tables/summary-results.tex}


Over the past decade, the computer vision community has proposed many backbones for processing 3D point clouds for fundamental tasks such as semantic segmentation \cite{Qi2017CVPR, Qi2017NIPS, Wang2019SIGGRAPHb, Thomas2019ICCV, Hu2020CVPR}
and object detection \cite{Wu2022GeosciRemoteSens, Wang2021NeurIPS, Wu2022ARXIV, Wu2022CVPR, Yang2022ECCV}.
%
Existing 3D backbones can be generally characterized as point-based or discretization-based.
%
Backbones that directly operate on 3D points \cite{Qi2017NIPS, Su2018CVPR, Hua2018CVPR, Wang2018CVPRb, Xu2018ECCV, Esteves2018ECCV,
Wu2019CVPR, Thomas2019ICCV} typically exchange and aggregate point features in Euclidean space, and have shown success for individual objects or relatively small indoor scenes. These methods, however, do not scale well to large scenes (\eg in outdoor settings) due to inefficiencies in processing large unstructured point sets.
%
On the other hand, popular discretization approaches such as sparse voxel methods \cite{Wu2018ICRA, Su2018CVPR, Graham2018CVPR, Choy2019CVPR,
Liu2019NeurIPS, Zhou2020ARXIV, Hu2020CVPR, Zhang2022ARXIV} rely on efficient sparse data structures that scale better to large scenes. However, for small or irregularly-distributed point sets, they often incur discretization errors. %, especially when the scene is not axis-aligned structure.

% While for the past decade this trend was fine, 
In recent years, this trade off between point and voxel backbones has been less explored due to the distinct environments in most 3D applications - autonomous vehicles do not leave roads, manufacturing robots do not leave warehouses, and quality-assurance systems do not look beyond a tabletop. However, as the community moves to dynamic and unregulated settings such as open-world robotics (\eg embodied agents), it is essential to have architectures that consistently perform well in diverse settings.

To this end, we present a novel point cloud processing scheme that achieves both performance and flexibility across diverse 3D environments. We achieve this by tailoring 
%
%Our key idea is to tailor 
our approach to the popular family of laser-scanning 3D sensors (such as LiDARs), which gather 3D measurements by sweeping laser-beams across the scene.
%
While previous works ignore the innate curve-like structures of the scanner outputs, we parameterize the point cloud as a collection of polylines, which we refer to as a ``curve cloud”. Our formulation establishes a local structure on the points, allowing for efficient and cache-local communication between points along a curve. This enables scaling to large scenes without incurring discretization errors and/or computational overhead. Furthermore, we hypothesize that the local curve ordering injects a lightweight and flexible surface-aware prior into the network (see \cref{subsec:why-curves}).

% To this end, we present a novel point cloud processing scheme that achieves both performance and flexibility across many 3D environments captured with a laser-scanning 3D sensor (such as LiDAR).
% Laser scanning 3D sensors operate by sweeping laser-beams across the scene. As the laser traverses object surfaces, it returns dense measurements along the scanning direction, resulting in a 3D point cloud with explicit curve-like structures (see \cref{fig:overview}).
% While previous works ignore the innate curve-like structures of the scanner outputs and treat points independently, we parameterize the point cloud as a collection of polylines, which we refer to as a ``curve cloud”. Our formulation establishes a local structure on the points, allowing for efficient and cache-local communication between points along a curve. This enables scaling to large scenes without incurring discretization errors and/or computational overhead. Furthermore, we hypothesize that the local curve ordering injects a lightweight and flexible surface-aware prior into the network (see \cref{subsec:why-curves}).

We propose a new backbone, \arch, that applies 1D operations along curves and combines curve operations with state-of-the-art point-based operations \cite{Qian2022PointNeXtRP, Ma2022ICLR, Wang2019SIGGRAPHb, Qi2017NIPS}. \arch uses curve operations at higher resolutions when there is clearer curve structure and uses point operations at downsampled resolutions. 
Put together, \arch is an efficient, scalable, and accurate backbone that can outperform segmentation and classification pipelines in a variety of settings (see \cref{tab:summary-results-and-datasets}a).

% : this includes indoor, outdoor, object-centric, scene-centric, sparsely scanned, and densely scanned scenes, where each setting exhibits unique laser scanner patterns (see \todo{Supp. tab 3} for example scanning patterns).

% achieves the best of both points and voxels. uses little GPU memory (see \cref{fig:teaser}). and combines 1D curve reasoning with established point-based operations to achieve the best of both points and voxels. That is, curve reasoning makes CurveCloudNet efficient, scalable, and accurate, and
% Our proposed \arch combines 1D curve reasoning with established point-based operations to achieve the best of both points and voxels. That is, curve reasoning makes our backbone scalable, accurate, and efficient for both objects and large-scale scenes and across many scanning patterns.

%
% \todo{is this next sentence too negative?}
% Intuitively, \arch echos a story of strategic specialization - by leveraging the intrinsic curve structure of laser-scanned data, we can improve perception for this common medium. 


% The essence of 1D curve reasoning is a novel adaptation of three standard point cloud operations for 1D curve structures: (1) a \textit{symmetrical 1D convolution} that operates along curves, (2) a \textit{ball grouping} similar to PointNet++ \cite{Qi2017NIPS} that groups points along curves, and (3) an efficient \textit{1D farthest-point-sampling} algorithm on curves.
% Carefully integrated together with state-of-the-art point-based operations \cite{Qian2022PointNeXtRP, Ma2022ICLR, Wang2019SIGGRAPHb, Qi2017NIPS}, CurveCloudNet is a versatile, efficient, and high-performing backbone that uses little GPU memory (see \cref{fig:teaser}).

We evaluate CurveCloudNet on a variety of object-level and outdoor scene-level datasets that exhibit distinct 3D size, structure, and unique laser scanning patterns (see \cref{tab:summary-results-and-datasets}b and \cref{fig:teaser}): this includes indoor, outdoor, object-centric, scene-centric, sparsely scanned, and densely scanned scenes. We evaluate \arch on the object part segmentation task using the ShapeNet \cite{Chang2015ARXIV, Yi2016ToG} dataset along with a new real-world object-level dataset captured with the \kortx scanning system \cite{summer-robotics}. For the outdoor semantic segmentation task, we use the nuScenes~\cite{Caesar2020CVPR}, Audi Autonomous Driving (A2D2)~\cite{Geyer2020ARXIV}, and Semantic Kitti ~\cite{behley2019iccv, Geiger2012CVPR} datasets.
%The A2D2 dataset offers a unique sensor configuration resulting in a grid-like scanning pattern, which is distinct from previous LiDAR datasets \cite{Geiger2012CVPR, Caesar2020CVPR, Chang2019CVPR, Sun2020CVPR}.
Supplementary experiments on object classification demonstrate flexibility to other perception tasks. Our evaluations demonstrate that using curve structures leads to improved or competitive performance on \textit{all} experiments, with the best performance on average (see \cref{tab:summary-results-and-datasets}a).
%We believe our diverse set of evaluations is more indicative of the unpredictable 3D environments faced in open-world robotics.
% As 3D applications such as open-world robotics become more dynamic and diverse, we beleive it is important to have 3D architectures exhibit flexibility and great ``on-average" performance across various environments.
% To the best of our knowledge, our work is the first to experimentally showcase accurate and efficient predictions on \emph{both} object-level and outdoor datasets. 


% contributions
In summary, we make the following \textbf{contributions}: 
\textbf{(1)} we propose operating on laser-scanned point cloud data using a \emph{curve cloud} representation, \textbf{(2)} we design efficient operations that run on polyline curves, \textbf{(3)} we design a novel backbone, CurveCloudNet, that strategically combines both curve and point operations, and \textbf{(4)} we show accurate and efficient segmentation results on real-world data captured for both objects and large-scale scenes in multiple environments and with various scanning patterns.
