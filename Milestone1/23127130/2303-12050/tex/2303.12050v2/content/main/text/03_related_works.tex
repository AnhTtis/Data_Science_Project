\section{Related Work}

Existing point cloud methods can be roughly characterized as
point-based and discretization-based approaches. As our work addresses trade-offs between them, we discuss related works from each category.

\paragraph{Point-Based Networks}
%Prior work has extensively studied backbones that map a 3D point cloud to a high-dimensional feature space used for downstream applications, such as 3D reconstruction, shape classification, part segmentation, semantic segmentation, and more \cite{Fan2017CVPR, Qi2017CVPR,Qi2017NIPS, Wang2019SIGGRAPHb, Thomas2019ICCV}. 
%
% PointNet \cite{Qi2017CVPR} was a seminal work that combined a series of MLPs with a max pooling layer to learn point-wise features. 
One popular approach to point-based reasoning is to aggregate local neighborhood information in a hierarchical manner and at multiple geometric scales \cite{Ma2022ICLR, Qi2017NIPS, Li2018CVPR, Zhao2021ICCV,Qian2022PointNeXtRP, Hu2020CVPR, Zhang2022CVPR, Yang20203DSSDP3, Qi2017CVPR}. Recently, Ma \etal \cite{Ma2022ICLR} introduced a modern MLP-based architecture along these lines, while Quian \etal \cite{Qian2022PointNeXtRP} modernized the seminal PointNet++ \cite{Qi2017NIPS} -- both showed compelling results on object-level and indoor scenes.
% 
Nevertheless, most hierarchical and MLP point networks are inefficient in large-scale settings, and although several backbones \cite{Hu2020CVPR,Zhang2022CVPR,Yang20203DSSDP3} have addressed this, they trade off scalability with task-specific frameworks or lower accuracy. 
In contrast, CurveCloudNet scales to large scenes by using the explicit curve structure of laser scanners.

Another line of research makes use of point convolutions for learning per-point local features. Point convolutions are usually defined using \textit{kernels} \cite{Su2018CVPR, Hua2018CVPR, Wang2018CVPRb, Xu2018ECCV, Esteves2018ECCV,
Wu2019CVPR, Mao2019ICCV, Lei2019CVPR, Komarichev2019CVPR, Lan2019CVPR, Thomas2019ICCV, Wiersma2022SIGGRAPH} or \textit{graphs} \cite{Te2018SIGGRAPH, Liu2019ICCVb, Chen2020CVPRa, Eliasof2020NeurIPS}. Kernels have been defined using a family of polynomial
functions~\cite{Xu2018ECCV}, using MLPs~\cite{Wang2018CVPRb,
Liu2019CVPR}, or directly using local 3D point coordinates \cite{Atzmon2018SIGGRAPH, Thomas2019ICCV, Wu2019CVPR, Xu2021CVPR,
Boulch2020ACCV}. In contrast, graph methods usually construct a K-Nearest-Neighbors graph in Euclidean space \cite{Shen2018CVPR, Verma2018CVPR} or feature space \cite{Wang2019SIGGRAPHb}, and apply graph-convolutions on the resulting edges and vertices.
% More sophisticated models such as Spherical CNN~\cite{Esteves2018ECCV} addressed 3D rotation equivariance by implementing convolutions in the spherical harmonic domain.
% InterpConv~\cite{Mao2019ICCV} utilized the point coordinates to interpolates
% point features to the neighboring kernel weights and
% DeltaConv~\cite{Wiersma2022SIGGRAPH} proposed to construct anisotropic convolutions by learning combinations of differential operators.
More recently, CurveNet~\cite{Xiang2021ICCV} applied guided random walks on uniformly-sampled input point clouds to construct graph neighborhoods that go beyond K-Nearest-Neighbors and that exhibit 1D ``curve" structure; then, CurveNet pooled features over the traversed curves. Aside from defining ``curves", CurveNet and CurveCloudNet have little in common: CurveNet's guided random walks are not related to physical laser traversals and do not scale to large scenes. In contrast, \arch efficiently recovers explicit curves from a scannerâ€™s physical laser traversals, and then applies a variety of operations, \eg, subsampling, aggregation, and convolution, along each curve.
%More related to our work is CurveNet~\cite{Xiang2021ICCV}, which proposed to perform random walks on point clouds and aggregate features along these ``curves" to capture local geometric details. In constrast, our work defines efficient point cloud operations for existing 1D curve structures.

% An alternative line of research proposed to construct a graph from the input point cloud and apply \emph{graph-based convolutions} \cite{Te2018SIGGRAPH, Liu2019ICCVb, Chen2020CVPRa, Eliasof2020NeurIPS} to capture local geometric structure. 

% For example,
% \cite{Shen2018CVPR} introduced a graph-based network that replaced
% convolutions with correlations computed between points and their $k$-nearest neighbors. Similarly, \cite{Verma2018CVPR,
% Wang2019SIGGRAPHb} proposed to construct a local neighborhood graph and apply convolutional operations on the edges connecting neighboring pairs of points.

% DiffGCN~\cite{Eliasof2020NeurIPS} performed message passing based on approximate surface gradients and an approximate Laplacian matrix, whereas \cite{Wang2018ECCVc} investigated using local spectral graph convolution.
Many works \cite{Xie2018CVPR, Liu2019AAI, Yang2019CVPR, Zhang2019CVPR, Hehe2021CVPR, Zhao2021ICCV, Ishan2021ICCV, wu2022pointtransformerv2} have shown success with \emph{attention-based aggregation} using
transformer architectures with self-attention \cite{Vaswani2017NIPS}. However, we found CurveCloudNet's reasoning over local 1D ``curve" neighborhoods to be sufficiently expressive without attention.


\paragraph{Discretization-Based Networks}
Although point-based backbones can successfully process individual objects or
small indoor scenes, they struggle to scale to large point clouds due to inefficiency in processing large unstructured point sets. To address this,
several works \cite{Su2018CVPR, Graham2018CVPR, Choy2019CVPR,
Liu2019NeurIPS, Zhang2020CVPR, Zhou2020ARXIV, Zhang2022ARXIV, Yan2018Sensors, Lang2018CVPR, Liu2021TPAMI, Xu2021ICCV, Hou2022CVPR} proposed to convert a point cloud into a 3D
voxel grid and use this volumetric representation. Early works converted a point cloud into a dense voxel grid and applied dense 3D convolutions \cite{Maturana2015IROS, Qi2016VolumetricAMCVPR}, however the cubic size of the dense grid proved to be computationally prohibitive. 
% PVCNN~\cite{Liu2019NeurIPS}
% was a seminal work in combining point operations with low-resolution dense voxel convolutions to efficiently
% process smaller-scale point clouds.
%
% sparse voxel architectures
To scale to large scenes, several works \cite{Choy2019CVPR, Lang2018CVPR, Zhou2020ARXIV, Liu2021TPAMI, Xu2021ICCV, Cheng2021AF2S3NetAF, Xu2021RPVNetAD, Yan2020SparseSS, Hou2022CVPR, Yan20222DPASS2P} employed the sparse-voxel data structure from \cite{Graham2018CVPR}. 
MinkowskiNet~\cite{Choy2019CVPR} was a seminal work in showing that sparse voxel convolutions can be highly efficient and expressive. 
%sparse voxel convolutions to the time domain, showing efficient and accurate reasoning on 4D scenes. 
PVNAS~\cite{Liu2021TPAMI} incorporated a network architecture search, demonstrating the importance of the architecture channels, network depth, kernel sizes, and training schedule. More recent works have supplemented sparse-voxel backbones with attention operations \cite{Cheng2021AF2S3NetAF}, range-view and point information \cite{Xu2021RPVNetAD}, image information \cite{Yan20222DPASS2P}, and knowledge distillation \cite{Hou2022CVPR}. 
% PVT~\cite{Zhang2022ARXIV} introduced a sparse attention module to efficiently process per-voxel local features using a transformer encoder~\cite{Vaswani2017NIPS}.

% different descritization
Other methods seek a better discretization of point clouds captured with \lidar scans. For example, PolarNet~\cite{Zhang2020CVPR}
proposed to partition input points using grid cells defined in a polar
coordinate system, while Cylinder3D~\cite{Zhou2020ARXIV} employed a cylindrical
partitioning scheme based on a cylindrical coordinate system. Sphereformer \cite{lai2023spherical} combined polar grid cells with modern attention operations. In an alternative line of research, many methods \cite{Kong2023Preprint, Gu2022MaskRangeAM, Cheng2022CenetTC, Ando2023RangeViTTV, Zhao2021FIDNetLP, Xu2020ECCV, Wu2018ICRA, Wu2019CVPR}
employ spherical or bird's-eye view projections to represent point clouds as images that are passed to a 2D convolutional or transformer network. 

Unlike discretization methods, \arch directly operates on points and curves, scaling to larger scenes without discretizing. Additionally, our curve operations are applied locally and do not assume global patterns such as polar, cylindrical, or planar structure. 
% individual objects, where the point clouds do not necessarily follow
% cylindrical patterns (see \cref{fig:teaser}).

% Unlike these works, our model directly operates on points and curves, and hence does not
% rely on either 2D or 3D convolutions. Notably, although our model only processes 3D points,
% we showcase that it can be efficiently employed on larger point clouds.
