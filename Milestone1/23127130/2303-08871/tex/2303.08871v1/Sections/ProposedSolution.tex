We propose two solutions. First, we integrate federated learning (FL) to a wireless drone swarm network and propose an ML model and data set for enhancing the B.A.T.M.A.N. routing protocol. Next, we demonstrate an FL simulation environment built on the EMANE emulation environment, which will be integrated with the proposed ML model in future work to investigate a larger UAV network, and to introduce movement among the UAVs, since this will be a feature compensated for by the ML model. 

\subsection{Machine Learning Model \& Dataset}\label{sec:MLBat}
We consider a supervised learning approach for this work. The objective of supervised learning is to learn a mapping, or function approximation, $\hat{\mathbb{F}}(\mathbf{x},\mathbf{y})$, between a set of samples, $x_{i} \in X$, and their labels, $y_{i} \in Y$, where $X$ and $Y$ are the sample space and label space, respectively. Ideally, $\hat{\mathbb{F}}(x,y)$ takes a set of new samples, $\mathbf{x^{*}}$ and produces the correct label, $\mathbf{y^{*}}$. The quality of the mapping is determined by the loss function, $L(y^{*}_{i}, \hat{y}_{i})$, where $y^{*}_{i}$ is the true label of the new sample, and $\hat{y}_{i}$ is the output of $\hat{\mathbb{F}}({x^{*}_{i}}, \cdot)$ \cite{b18}. An accurate function approximation is quantified by a low loss value. 
 
Since the B.A.T.M.A.N. routing protocol does not maintain a history of route conditions (\textit{i.e.} link cost, throughput), we need to modify the B.A.T.M.A.N. algorithm to include a memory element. The model should learn a history of the prior link costs for each route, and the route the node selected. These requirements make the long short-term memory (LSTM) model, a type of recurrent neural network (RNN) that is designed to learn long-term dependencies in sequential data, appropriate for this task \cite{b14}.

The input to the LSTM model is a two dimensional array of the history of the link cost at each neighboring route from $D_{B}$, (see Fig.~\ref{fig:SysMod}). However, this approach can be extended to $n$ dimensions for $n$ many neighbors in a more complex network. The corresponding labels are a history of the selected route for transmission.  Instead of feeding the entire history of the network to the model, we implement a windowing technique. For example, if the window size is set to 4, then four prior time steps are fed into the model for training. We can treat this as a classification problem and use the binary cross entropy loss function since we are training the LSTM to select which of the two routes from $D_{B}$ to transmit across. 

\subsection{Federated Learning Approach}
Traditional machine learning approaches are centralized, meaning a model is trained on a central dataset that is collected and stored in a central location. However, this approach assumes all devices on the network have the same computational capabilities and network resources, which is often not the case for UAV networks \cite{b2}. As a result, a FL-based distributed ML technique is employed in this research where training of a global model is performed on data distributed across many UAVs in various locations. For generality, we assume there are $J$ UAVs in the network. Each UAV for $j \in J$ observes a unique dataset $\mathbf{x_{j}} = \{x_{j1}, x_{j2}, \ldots, x_{jN}\}$. Since we use a supervised learning approach, we assume a single input sample, $X_{jn}$ corresponds to a single output $y_{jn} \in \{y_{j1}, y_{j2}, \ldots, y_{jN}\}$. The sets $\mathbf{x}_{j}$ and $\mathbf{y}_{j}$ are used to train the local ML model at each UAV. Let $\mathbf{w}_{j} \in \mathbf{w}$ denote the corresponding model parameters at the $j^{th}$ UAV. Then, the FL objective function can be employed, which is defined as~\cite{b19}:

\begin{equation}\label{eq:FLObj}
\argmin_{\mathbf{w} \in \mathbb{R}^{d}} F(\mathbf{w}) = \frac{1}{N} \sum_{j}^{J}\sum_{n=1}^{N_{j}}f(\mathbf{w}_{j}, x_{jn}, y_{jn}). 
\end{equation}

We solve (\ref{eq:FLObj}) via the following steps: First, all UAVs are initialized with random parameters. Each UAV trains on its respective training sets, $x_{jn}$ and $y_{jn}$. After one epoch of training, the FL parameters at the $j^{th}$ UAV are sent to a central server. Once all parameters are received, the central server aggregates the parameters according to the following expression:

\begin{equation}\label{eq:fedAvg}
w_{global} = \frac{1}{J}\sum_{j=1}^{J} \mathbf{w_{j}}
\end{equation}

The global parameters, $w_{global}$, are sent back to the UAVs, and the training process repeats for $K$ epochs, or until $F(\mathbf{w})$ has converged to the optimal parameters, $w^{*}$. Fig.~\ref{fig:FLEMANE} summarizes this approach. 

\subsection{Federated Learning in EMANE}\label{sec:FLinEMANE}
This works also aims to build an FL emulation environment, with the future goal of integrating the emulator with the proposed ML model to test the feasibility of the proposed solution. A system diagram of the emulator is shown in Fig.~\ref{fig:FLEMANE}. At the core of the emulator is EMANE, which allows for the creation of Network Emulation Modules (NEMs) to model different radio interface types. In turn, these can be incorporated into a real-time emulation running in a distributed environment and allow the direct integration of standard software, such as PyTorch, for handling ML tasks. 

For the results in this work, we construct a simulator with three NEMs, similar to the model setup in Fig.~\ref{fig:SysMod}. One NEM is designated as the central server. The remaining NEMs carry out the FL task. However, this could be generalized to $M$ nodes, see Fig.~\ref{fig:FLEMANE}. 

\begin{figure}[!t]
    \centering
    \includegraphics[width = \linewidth]{Images/FL_in_EMANE.png}
    \caption{Federated Learning Setup in EMANE}
    \label{fig:FLEMANE}
\end{figure}