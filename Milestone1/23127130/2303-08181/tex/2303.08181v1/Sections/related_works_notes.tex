DO NOT INCLUDE JUST FOR OUR OWN REFERNCE ON DOCUMENTS

\begin{itemize}
     \item application GP to robotics \cite{Deisenroth_GP_robotics}
    \item \textbf{Residual Learning}
    \item Online GP-MPC Learning limited to last 30 points \cite{hewing2019cautious}
    \item Data Driven MPC Scaramuzza GP on MPC \cite{Guillem_datadriveMPC}
    \item GPMPC Uncertainty Propogation \cite{Gang2016GPMPC}
        \item STate Space GP online learning with a car in simulation though \cite{park2020gaussian}
    \cite{WangonlineGP2018} Online learning GP barrier function
    \cite{hewing2019cautious}
    \item \textbf{Alternative GP}
    
    \item Fast GP matrix calculations \cite{Sivaram_fastGP_calc}
    \item Fast Big data GP basically inducing points in parallel \cite{DAS201812}
    \item state space GP\cite{solin2016stochastic}
    \item Extension to State SPace GP  \cite{sarkka2013spatiotemporal}
    \item GP logarithmic time Do the State Space GP regression in parallel  \cite{corenflos2022temporal}
    \item Inducing Points using a subset of the dataset \cite{joaquin_unifiyng_view}
    

    
\end{itemize}




\begin{equation}
    \begin{aligned}
              Q(t)&=  a_n \frac{\partial^n f(t)}{\partial t^n}+\cdots+a_1 \frac{\partial f(t)}{\partial t}+a_0 f(t) \\
\frac{\partial \mathbf{f}(\mathbf{x}) }{\partial \mathbf{x}} &=\mathbf{A} \mathbf{f}(\mathbf{x})+\mathbf{L} Q(\mathbf{x}),\\
\mathbf{y} &=\mathbf{H} \mathbf{f}\left( x_{k}\right)+\varepsilon_{k},\\
\mathbf{f}(\mathbf{x})&=\begin{bmatrix}
f(\mathbf{x}_{\ast}) & \frac{\partial  f(\mathbf{x}_{\ast})}{\partial \mathbf{x}} & \cdots &  \frac{\partial ^m f(\mathbf{x}_{\ast})}{\partial  \mathbf{x}^m}
\end{bmatrix}^\top.
\end{aligned}
\label{eq_SSGP_model}
\end{equation}


In order to solve for an appropriate matrix values for $\mathbf{A}$, $\mathbf{H}$, and $\mathbf{L}$, we construct a relationship through the Fourier transform, $\mathcal{F}$ to the original kernel function and spectral power density. Using eq.~(\ref{eqn:bochner}), we are able to solve for a spectral density of our kernel function. Before, we would like to remind the reader on three key properties of fourier transforms and spectral density


where  that corresponds to the square of the absolute value of the Fourier transform of the process. This value is tunable by the user depending on their confidence. Using the following properties, we are able to convert our spectral density solved from Bochner's theorem into a differential equation. For the following equation let $\mathbf{S}(\omega)$ be the spectral density function of a Fourier transform $\mathbf{s}(i\omega)$. It is important to understand that spectral power density is not the same as the frequency function, but it is the difference between the absolute value of a complex number and a complex number. Also let $\mathcal{F}^{-1}$ be the inverse Fourier transform. We can not directly construct the differential equation from a spectral density. The inverse Fourier transform of an actual frequency domain is what creates the differential equation


