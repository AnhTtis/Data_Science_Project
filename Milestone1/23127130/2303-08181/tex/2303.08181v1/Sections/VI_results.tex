\section{Results}
We design our evaluation procedure to address the following questions. 
(i) What is the computational speed gain from converting to state space versus a traditional matrix inversion eq.~(\ref{eq_GP_prediction})? 
(ii) Can the SSGP perform robust inference to the real-world data comparable to the baseline matrix inversion implementation of eq.~(\ref{eq_GP_prediction})? 
(iii) Can extending the input space to multiple inputs greatly improve the inference?
We perform several experiments to address these questions. First, we compare our computational time for solving a full dataset between our implementation and a traditional method. Next, we compared the inference RMSE and fitting of our SSGP approach with a traditional inference approach of matrix inversion for both SISO and MISO. 
For our baseline implementation of eq.~(\ref{eq_GP_prediction}) we leverage GPytorch (GPT), \cite{gardner2018gpytorch} a library that performs robust and efficient matrix operations and optimizations by integrating with Pytorch's ecosystem. 
This allows GPT to perform both efficient optimization of hyperparameters for the objective eq.~(\ref{eq_log_marg_likelihood}) and inference with eq.~(\ref{eq_GP_prediction}) . We evaluated our approach on a real-world dataset of quadrotor dynamics and flight, \cite{Ale_PiTCN}. This dataset contains real-world unfiltered data resulting in much noisier signals and stressing our models' ability to perform inference. We chose three different flight trajectories: Circle (training), Parabola (validation), and Lemniscate (validation).
To validate inference time, we tested our implementation on a 11th Gen Intel i7 for both  SSGP and GPT in Table~\ref{tab:inference_time} with pure CPU computation. The results were repeated with a Xavier NX achieving similar timing trends. This table records the average amount of time taken to complete one inferences given a dataset of size $n$. Our time comparison consists of the following kernels: RBF, Matern, and periodic given different approximation orders, RBF $m=6$, Matern $m=3$, and periodic $m=18$ and compared with both GPT in a SISO format and a MISO ($5$ independent inputs). Our model for SISO or $m\leq10$ can perform inference much faster than a comparable baseline implementation, especially for datasets $>1000$. However, the SSGP formulation slows down in the MISO formulation. This is because computationally MISO for the SSGP of order $m=6$ and $5$ inputs is equivalent to a $m=30$ approximation. This gives even slower computations than the GPT version until  $2500+$ points are used. 
\begin{table}[t]
    \centering
    \caption{\label{tab:laptop_evaluation}}
    \vspace{-0.75em}
    \caption*{\scshape Predictive Performance RMSE [$\SI{}{\meter\per\second\squared}$]}
    \vspace{-0.3em}
    \begin{tabular}{r r r r r}
        \toprule\toprule
        \multirow{2}{*}{Trajectory} &
        \multicolumn{2}{c}{SISO} &
        \multicolumn{2}{c}{MISO} \\   
        \cmidrule(lr){2-3}\cmidrule(lr){4-5}
        & \multicolumn{1}{c}{SSGP} & \multicolumn{1}{c}{GPT} & \multicolumn{1}{c}{SSGP} &  \multicolumn{1}{c}{GPT}  \\
        \midrule
        Circle (training) & $0.0938$ & $0.0755$& $0.0852$&  $\mathbf{0.0666}$\\
        Transposed Parabola (val) & $0.1330$& $0.1164$ &$\mathbf{0.0889}$  &$0.1516$\\
        Extended Lemniscate (val) & $0.6079$& $0.4561$& $\mathbf{0.3176}$ & $0.4698$\\
        \bottomrule\bottomrule
    \end{tabular}
    \label{tab:rmse_performances}
\vspace{-20pt}
\end{table}
Our inference task on the dataset is to model the residual accelerations defined in Section \ref{sec:quad_dynamics} with body velocity as the input to prediction acceleration error for SISO, and body velocity and motor speeds for MISO.
For our RMSE evaluation in Fig.~(\ref{fig:pred_performance}), we focused on estimating the drag term on the y-axis, $f_{{GP}_y}$, choosing the RBF Kernel with an approximation order $m=6$.  The residual inference performance of SSGP is compared to the same kernel implemented in GPT using the same hyperparameters. As observed, our SSGP method despite performing similarly to GPT on the training set better generalizes on the testing dataset with lower RMSEs across all test sets (see Table \ref{tab:rmse_performances}), and can perform faster inference. We believe the greater generalizability of our system depends on the prior induced by the SSGP structure where inference is achieved through observing the data trend rather than a correlation on the dataset like in GPT. Furthermore scaling our inputs to include the motor rates allows the MISO SSGP to better capture high-frequency features than a SISO system.
Similar results are obtained for the other drag components $f_{{GP}_x}$, $f_{{GP}_z}$.


