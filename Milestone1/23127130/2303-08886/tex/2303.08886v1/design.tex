
\textbf{Design Principle.} Our {\em blind hash} scheme was initially inspired by  algorithm-based fault tolerance (ABFT) techniques~\cite{hari2021making-checksum, ABFT-1984-checksum, ding2011matrix-2011-checksum, checksum-2017} that utilize checksums to detect computational errors due to faults in systems. The checksum provides redundant mathematical relationship of data that is preserved in the output, such that computational error becomes detectable through verifying the relationship in the output. However, while effective in detecting faults, ABFT techniques have a fundamental flaw if used for detecting errors due to attacks in untrusted environments: attackers can bypass the detection by manipulating both data and the checksum, leveraging the knowledge of the computation process. Even though the checksum is encrypted by FHE, it is mathematically related to data in ways known or guessable by the attacker, creating a security gap between fault detection and attack detection. Our {\em blind hash} bridges the gap and improves upon ABFT by following the main principle of {\em concealing the checksum computing process} from the untrusted environments: {\em blind hash} incorporates an extra layer of security by adding a blind hash function into the checksum computation process. The blind hash function is only visible to the data owners and generated checksum is encrypted by FHE, making it secure and tamper-resistant. {\em Blind hash} not only detects faults, as in ABFT, but also detects attacks. 

\textbf{Workflow.} Our development of {\em blind hash} will take the following steps: (i) blind hash calculation. Given data $x$ and predefined hash vector $h^x$, the data owner calculates the blind hash checksum values by $hash(x, h^x)=h^xx$, attaches it to the original data as $x'$, and encrypts $x'$ using FHE to generate $[x']$, here $[x']$ represents ciphertext of plaintext $x'$.   (ii) data sharing. The data owner shares encrypted $[x']$ with the service provider. (iii) private computation for result and proof. The service provider performs arithmetic function $[f([x'])]$ on encrypted data $[x']$ directly, where $f()$ function can be any arithmetic function, including convolution, matrix operation, etc, and it usually depends on parameters $w$, e.g., convolution filter, machine learning weights.  

(iv) client's integrity checking. The client decrypts $[f([x'])]$, i.e., ($[f([hash(x, h^x)])]$ and $[f([x])]$), and verifies the integrity and correctness by checking the results and proof $f([hash(x, h^x)])$ and $hash(h^x, f([x]))$.

\textbf{Function Privacy.} The function $[f([x'], w)]$ can be directly performed in many applications~\cite{Occlumency:TEE-deep-learning,VISE-TEE-FHE} where the variable $w$ is public to both the client and the server. However, for applications where the weight $w$ is kept confidential by the client, the client can compute the blind hash on $w$ and encrypt it in the same manner as the input $x$. The encrypted $w'$ can be shared with the server, allowing the server to perform multiplication with the encrypted $x'$.  On the other hand, if $w$ is private to the server, the server would perform the computations with the encrypted $x'$ and $w'$, and then add noise to the intermediate results $[f([x'], w)]$ through the noise flooding technique~\cite{FHE-Gentry2009} to enhance the privacy of the function.

\begin{figure}[tbp]
\centerline{
  \hspace{0.3cm}
\includegraphics[width=0.45\textwidth]{figures/checksum.pdf}}
\caption{Illustrating vFHE with blind hash, which enables the verification of Fully Homomorphic Encryption (FHE) against both malicious tampering and computational errors. }
\label{fig:illustration}
\end{figure}

\textbf{Blind Hash Illustration.}
We illustrate the process of a blind hash by utilizing matrix multiplication, as depicted in Figure~\ref{fig:illustration}. Assume the data owner has matrix $A$ with a size of $m\times n$ and requests matrix multiplication service of $C=A \times B$  from the server, and $B$ has a length of $n\times k$. %In this example, the variable $B$ is not encrypted. However, its encrypted scenario can also be accommodated by adhering to the privacy protection steps outlined previously.  
Directly encrypting $A$ as $[A]$ using FHE and allowing the server to calculate the matrix multiplication of $[A]$ and $B$ may pose integrity risks for two reasons. Firstly, the server can manipulate the outcome $C$ into $C'$, or even fabricate a result without actually performing the computation. Secondly, the FHE computations executed by the server are susceptible to errors, including excessive FHE noise and hardware malfunctions. While ABFT~\cite{hari2021making-checksum, ABFT-1984-checksum, ding2011matrix-2011-checksum, checksum-2017} effectively detects errors, it falls short in detecting attacks in untrusted environments. {\em Blind hash} not only detects faults, as in ABFT but also detects attacks since it incorporates an extra layer of security by adding a blind hash function into the checksum computation process. 

Our blind hash method ensures Fully Homomorphic Encryption (FHE) integrity by following these steps: The client creates a hash encoding vector $h^A$ with dimensions $1\times m$, where $m$ represents the number of rows in data $A$, and each element is randomly chosen from the plaintext space. The client then multiplies $h^A$ by $A$ to produce the hashed value $hash(A, h^A)$, as depicted in Figure~\ref{fig:illustration}(a). The client encrypts the pair $(^A_{hash(A, h^A)})$ into ciphertext $[A]$ using FHE and shares this with the server. This FHE encryption guarantees that the hashed checksum value $hash(A, h^A)$ remains hidden.

The server carries out FHE matrix multiplication between $[A]$ and $B$, resulting in the encrypted outcome and proof, denoted as $([^C_{C^A}])$, where $[C]$ is the result and $C^A$ is the computational proof, as demonstrated in Figure~\ref{fig:illustration}(b).

Upon receiving the encrypted outcome and proof, the client decrypts them into plaintexts $C$ and $C^A$. The client then multiplies $C$ by the blind hash vector $h^A$ to compute $hash(C, h^A)$. The integrity of the computation is confirmed by comparing $hash(C, h^A)$ with $C^A$. If they match, the computation is deemed valid. Otherwise, an integrity issue exists. This procedure is illustrated in Figure~\ref{fig:illustration}(c).

\section{Scheme Analysis}
\textbf{Security Analysis}. If the hash vector $h^A$ is exposed to other parties, such as the server, the checksum will no longer be considered {\em blind}, and its integrity can be compromised. For instance, the server could add $h^AM$ to both $C$ and $h^AC$ simultaneously, where $M$ shares the same size as $C$. This type of manipulation would go undetected by the client. In our blind hash, however, $h^A$ is kept hidden from the server as $h^AA$ is encrypted using FHE, and the encrypted $[h^AA]$ is transmitted to the server. Without knowledge of $h^A$, it becomes difficult for the server to attack the checksum verification. 

\textbf{Ensuring Security}.
One might contend that the blind hash method is not secure if the data matrix is invertible, allowing an attacker to extract the value of $h^A$ by calculating the matrix inverse $A^{-1}$ and applying $h^AAA^{-1}$ to obtain $h^A$. We propose two solutions to address this concern. First, since only a square matrix is invertible, we alter matrix $A$ to be non-square. For example, the client can configure the FHE scheme such that the number of slots exceeds the data size of $A$. Second, the client can introduce errors into the blind hash, which serves to impede the extraction of $A$'s inverse.

In the first approach, the blind hash functions effectively when the matrix is non-square. If the matrix is square, one can either partition it into two non-square matrices or introduce padding to transform it into a non-square matrix.
%If the number of slots is more significant than the number of data, there is a padding process during encryption. FHE scheme will pad many new numbers to fill all of the slots that transform the dimension of the matrix. A data matrix that was previously invertible in the plaintext space would become non-invertible in the ciphertext space. To compute the inverse matrix, an attacker must first decrypt the ciphertext data, which is impossible since the decryption process requires the secret key.
In the second approach, we introduce a blind hash with the error shown in Figure~\ref{fig:extended} based on the original blind hash. 
Given a matrix $A$, the data owner calculates the blind hash $hash(A, h^A, r^A)$ by $h^AA+r^A$ where $r^A$ is the \textit{error}, i.e., a random secret vector as the Figure~\ref{fig:extended}(a) shows.  

Subsequently, the data owner appends the $hash(A, h^A, r^A)$ to matrix $A$ and encrypts them together. The same procedure can be applied to matrix $B$, as illustrated in Figure~\ref{fig:extended}(b). The FHE computation step in this case is identical to that of the blind hash. During verification, the data owner must execute two steps. First, the data owner computes the $hash(C, h^A)$, resulting in $h^AC$. Second, the data owner subtracts $hash(C, h^A)$ from $C^A$ and modulo the error $r^A$, and verifies if the outcome equals 0, as shown in Figure~\ref{fig:extended}(c).

%Then the client can verify the integrity by subtracting $e^TAB$ and doing a modulus operation with secret vector $r^T$, as shown in figure \ref{fig:extended} (b). The secret vector $r^T$ prevents the attacker from extracting the hash key $e^T$ even though they have the invertible matrix $A^{-1}$. 

\begin{figure}[tbp]
\centerline{
  \hspace{0.3cm}
\includegraphics[width=0.5\textwidth]{figures/checksum-error.pdf}}
\caption{Blind Hash with Error enhances the security of Blind Hash}
\label{fig:extended}
\end{figure}


\begin{figure*}[t]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/results_crop.pdf}
    \caption{vFHE runtime overhead.}
    \label{fig:results}
\end{figure*}


\textbf{Overhead Analysis.} We demonstrate that our implementation of a {\em blind hash} results in minimal increases in various areas, including plaintext expansion, server-side computational overhead, ciphertext expansion, and client computation. (i) Plaintext expansion.  When applied to a matrix with dimensions of $m\times n$, the resulting {\em blind hash} will have dimensions of $1\times n$. The plaintext expansion rate of the {\em blind hash} can be calculated as $\frac{1}{m}$, indicating a relatively small increase in the size of the original matrix. (ii) FHE computation. The implementation of a blind hash does not require any modifications to the server. A {\em blind hash} has a minimal impact on computational resources, particularly in the case of large matrix multiplications. The computational complexity of multiplying two matrices, $A$ and $B$, with dimensions of $m\times n$ and $n\times k$ respectively, is expressed as $\mathcal{O}(mnk)$. A {\em blind hash} increases the computational number from $mnk$ to $(m+1)nk$, yet the overall computational complexity remains unchanged at $\mathcal{O}(mnk)$. This demonstrates that the FHE computation overhead of a {\em blind hash} is negligible for sufficiently-sized matrices. (iii) Ciphertext expansion. The ciphertext expansion rate, which determines the communicational overhead between the client and the server, is equal to or less than $1+\frac{1}{m}$ due to the ability to pack multiple values into a single ciphertext. 
(iv) Client computation. The client's computational overhead is comprised of two components: the generation of the hash vector and checksum vector, and the verification of the proof. The generation of the hash vector can be performed in advance, while the generation of the checksum vector involves a vector-matrix multiplication with a computational complexity of $\mathcal{O}(mn)$, where the vector and matrix have dimensions of $1\times m$ and $m\times n$, respectively. The overhead ratio of this process to the original computation is $\mathcal{O}({\frac{1}{k}})=\frac{\mathcal{O}(mn)}{\mathcal{O}(mnk)}$. The verification process of the proof involves a vector-matrix multiplication with a computational complexity of $\mathcal{O}(mk)$, i.e., $\frac{1}{n}$ of matrix multiplication, and a comparison of two vectors with dimensions of $1\times k$, which has a complexity of $\mathcal{O}(k)$, i.e., $\frac{1}{mn}$ of matrix multiplication. We propose the use of power-of-2 hash values and inexpensive shift operations to reduce the costly $\mathcal{O}(mn)$ multiplication with inexpensive shift operations, leading to a significant decrease in the client's computational overhead. As convolution operations in deep neural networks can be represented mathematically as matrix multiplications~\cite{checksum-2017}, we only analyze the complexity of representative matrix multiplications.  

