In this section, we briefly describe FHE and the current state of the art to guarantee integrity in FHE.
\subsection{Fully Homomorphic Encryption}
An encryption scheme transforms plaintext (unencrypted data) into ciphertext (encrypted data) using an encryption algorithm to make the ciphertext unintelligible to unauthorized parties. Encryption schemes are used to protect the confidentiality and privacy of data, as well as to ensure the integrity and authenticity of data. FHE stands for Fully Homomorphic Encryption. This type of encryption scheme allows computations to be performed on ciphertexts without first decrypting them. In other words, it enables the computation of functions directly on encrypted data.

Currently, various Fully HE (FHE) schemes such as BGV~\cite{brakerski2014leveled} and BFV~\cite{halevi2019BFVimproved}, as well as CKKS~\cite{fhe-ckks}, are based on ring-based learning with errors and operate on different polynomials in a ring-based structure. Since FHE operations are approximately 10,000 times slower than non-FHE operations~\cite{CryptoNets:ICML2016}, a significant portion of FHE and FHE-based privacy-preserving machine learning research~\cite{CryptoNets:ICML2016, lou2019she,lou2020safenet,Brutzkus:ICML19, GAZELLE:USENIX18, Pratyush:USENIX2020} has focused on improving the efficiency of FHE through innovative schemes and hardware acceleration, such as incorporating GPU support for FHE~\cite{fhe-gpu} and utilizing techniques like ciphertext batching~\cite{GAZELLE:USENIX18, Pratyush:USENIX2020} which significantly reduce latency and improve the throughput of privacy-preserving computation.


% \subsection{Requirement of FHE Integrity}
% \subsubsection{Universality}

% Universality is the capability to support different FHE scheme. 

% \subsubsection{Scalability}

% Scalability is a crucial factor for Fully Homomorphic Encryption (FHE) because FHE schemes are computationally intensive, and the size of the encrypted data grows as more computations are performed. Thus, as the number of computations and the size of the encrypted data increase, the computational complexity of the FHE scheme increases exponentially, making it impractical to use for large-scale applications.

% Scalability is essential for FHE because it enables the efficient handling of large amounts of data and computations, which is necessary for real-world applications. If an FHE scheme cannot scale well, it may not be practical to use it for large-scale data processing tasks, such as those in finance, healthcare, and e-commerce.

% Moreover, scalability is closely related to efficiency in FHE. The efficiency of an FHE scheme is determined by how quickly it can perform operations on encrypted data, and how much computational power it requires. A scalable FHE scheme can maintain its efficiency even as the size of the data and the number of computations increase, making it a more practical and useful tool for real-world applications.

% In summary, scalability is crucial for FHE because it enables efficient handling of large amounts of data and computations, maintains the efficiency of the FHE scheme, and makes it a practical and useful tool for real-world applications.

% \subsubsection{Security}
% MAC-then-encrypt is generally not considered a secure approach when used with Fully Homomorphic Encryption (FHE). This is because MAC-then-encrypt can be vulnerable to certain types of attacks, such as chosen-ciphertext attacks (CCA).

% In a CCA attack, an attacker can modify the encrypted message and observe the corresponding decrypted message, which can then be used to gain information about the secret key used for encryption. Since FHE schemes are typically used for applications where the encrypted data is sent over an insecure channel, such as the internet, they are vulnerable to these attacks.

% \subsubsection{Overhead}
% Zero-Knowledge Succinct Non-Interactive Argument of Knowledge (zk-SNARK) protocols are known to have a high overhead in terms of computation and memory requirements. This is because zk-SNARKs require several rounds of computation and communication between the prover and verifier, which can be computationally expensive.

% Specifically, zk-SNARKs require the prover to perform a series of complex computations to generate proof, which is then verified by the verifier. The computations in generating the proof can be computationally intensive, requiring significant processing power and memory.

% \subsubsection{Veriffiable Model}

% FHE computation often assumes that the server is trustworthy to perform the predefined function f (x) and the underlying hardware is fully reliable. This assumption carries great risks. Clients should be cautious when relying on computations performed by a third-party cloud for several reasons. First, the server may not be dependable; bit error rates in production servers were higher than previously thought [71]. Second, the cloud may be vulnerable to malware that can tamper the results with malicious intent. For example, a compromised cloud may consistently misclassify certain digits in a recognition task or grant unauthorized access to certain users in a face recognition system. Finally, the cloud may be financially incentivized to cut corners and use less accurate but cheaper models.

% \subsubsection{ML support}
% Without an approximate number support, building secure ML based on FHE would limit the datatype to integer only. This would give several disadvantages.
% Limited precision: Integer arithmetic is inherently limited in precision, which can result in reduced accuracy in the DNN. This is particularly true for very deep networks or networks with many parameters.
% Limited range: Integer arithmetic is also limited in range, which can be problematic if the inputs or weights of the DNN exceed the range of the integer datatype.
% Limited hardware support: Some hardware, such as GPUs, may not be optimized for integer arithmetic, resulting in slower computation times.
% \subsubsection{No Hardware}





\subsection{Comparison with Related Works}

In table \ref{tab:features}, we compare our blind hash method with the related works.  Research on computational integrity primarily focuses on two approaches: cryptographic integrity checking protocols~\cite{bhadauria2020ligero++, bunz2018bulletproofs, gennaro2010non,goldwasser2015delegating, parno2016pinocchio, weng2021wolverine, brakerski2011fully, bois2021flexible, fiore2014efficiently, fiore2020boosting, ganesh2021rinocchio}, e.g., MAC, MAC', ZKP, and ZKP'; and utilizing trusted execution environments (TEE) hardware~\cite{natarajan2021chex, wang2019toward, coppolino2020vise,sabt2015trusted}. 

Several studies have presented MAC-based approaches in scholarly literature~\cite{brakerski2011fully, bois2021flexible, fiore2014efficiently, fiore2020boosting, ganesh2021rinocchio}. A notable example of a MAC~\cite{MAC-CCS2014} focuses on verifying ciphertext computations by specifically examining quadratic functions within a particular variant of the BV scheme~\cite{brakerski2011fully}. However, these methods are not universally applicable to all FHE schemes and have limitations in scalability, efficiency and functionality~\cite{chatel2022verifiable}.
In comparison, the MAC' method~\cite{chatel2022verifiable} improves efficiency and universality by implementing alternative encoding methods. Nonetheless, the applicability of this method to all FHE schemes universally remains uncertain, in contrast to our vFHE approach, which does not necessitate alterations to encoding techniques. Additionally, the overhead associated with this method is no less than twice that of the original computation.

Modulus residue approaches \cite{Awadallah2021}  \cite{cryptoeprint:2023/231} are derivations of the MAC scheme. They offer lower overhead by creating an unencrypted verification encoding with reduced data size. The efficiency of these residue methods, which feature unencrypted verification and an unprotected verification function, is achieved at the expense of compromised security. Common FHE schemes, such as BFV, BGV, and CKKS, enable FHE computation with plaintext. A malicious actor could manipulate the data and bypass the verification by simply altering both the data and the checksum through arithmetic plaintext operations on encrypted data. In comparison, our blind hash scheme maintains security while minimizing overhead. Although these residue methods are well-suited for safeguarding integrity against faulty hardware, they are not as effective against sophisticated adversaries. Despite their significantly lower overhead relative to MAC schemes, their limited scalability arises from the linear increase in verification size as the message size grows.



The ZKP method \cite{ganesh2021rinocchio} has been explored for maintaining computational integrity; however, employing a Zero-Knowledge Proof technique for universal FHE verification without optimization specific to a particular FHE scheme results in considerable overhead. This overhead intensifies in proportion to the size of the data. In contrast, ZKP' \cite{viand2023verifiable}, optimized for a distinct FHE scheme, might not attain full universality.

The hardware-based strategy, which executes complete or partial FHE operations within a Trusted Execution Environment (TEE) \cite{natarajan2021chex, viand2023verifiable}, exhibits universality; however, it imposes considerable performance overheads. The reported overheads range from $3-30\times$ \cite{natarajan2021chex, wang2019toward, coppolino2020vise, chatel2022verifiable}, highlighting the significant performance implications of this approach. This is due to one key limitation: TEEs were designed for non-FHE computation. Hence their designs mismatch with what FHE needs. %This calls for a {\em clean-slate redesign} of TEEs for supporting FHE computation to reduce the performance overheads.
