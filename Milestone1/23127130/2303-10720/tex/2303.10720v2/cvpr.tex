% CVPR 2023 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
% \usepackage[review]{cvpr}      % To produce the REVIEW version
\usepackage{cvpr}              % To produce the CAMERA-READY version
% \usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{algorithm2e}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{multicol}
\usepackage[dvipsnames]{xcolor}
\RestyleAlgo{ruled}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).

\definecolor{kevincolor}{RGB}{147,112,219}

\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}
\newcommand{\zk}[1]{{\color{blue}{(\textbf{ZK: }#1)}}}
\newcommand{\kevin}[1]{{\color{kevincolor}{(\textbf{Kevin: }#1)}}}
\newcommand{\xdai}[1]{{\color{brown}{(\textbf{XD: }#1)}}}
\newcommand{\zechengh}[1]{{\color{cyan}{(\textbf{ZH: }#1)}}}
\newcommand{\js}[1]{{\color{orange}{(\textbf{JS: }#1)}}}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{assumption}{Assumption}
\newtheorem{definition}{Definition}
% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{4761} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2023}


\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Trainable Projected Gradient Method for Robust Fine-tuning}

% \author{Junjiao Tian$^1$\\
% {\tt\small jtian73@gatech.edu}
% \and
% Xiaoliang Dai$^2$\\
% {\tt\small xiaoliangdai@fb.com}
% \and
% Chih-Yao Ma$^2$\\
% {\tt\small cyma@fb.com}
% \and
% Zecheng He$^2$\\
% {\tt\small zechengh@fb.com}
% \and
% Yen-Cheng Liu$^1$\\
% {\tt\small ycliu@gatech.edu}
% \and 
% Zsolt Kira$^1$\\
% {\tt\small zk15@gatech.edu}\\
% }\\

\author{
\textbf{Junjiao Tian\thanks{Work partially done during internship at Meta.}\,\,\textsuperscript{1}
\quad Xiaoliang Dai\textsuperscript{2}
\quad Chih-Yao Ma\textsuperscript{2}} \\ 
\textbf{Zecheng He\textsuperscript{2}
\quad Yen-Cheng Liu\textsuperscript{1}
\quad Zsolt Kira\textsuperscript{1}} \\
\\
\textsuperscript{1}Georgia Institute of Technology
\quad \textsuperscript{2}Meta}

\maketitle

%%%%%%%%% ABSTRACT
\begin{abstract}

\looseness=-1  
Recent studies on transfer learning have shown that selectively fine-tuning a subset of layers or customizing different learning rates for each layer can greatly improve robustness to out-of-distribution (OOD) data and retain generalization capability in the pre-trained models. However, most of these methods employ manually crafted heuristics or expensive hyper-parameter searches, which prevent them from scaling up to large datasets and neural networks. To solve this problem, we propose Trainable Projected Gradient Method (TPGM) to automatically learn the constraint imposed for each layer for a fine-grained fine-tuning regularization. This is motivated by formulating fine-tuning as a bi-level constrained optimization problem. Specifically, TPGM maintains a set of projection radii, i.e., distance constraints between the fine-tuned model and the pre-trained model, for each layer, and enforces them through weight projections. To learn the constraints, we propose a bi-level optimization to automatically learn the best set of projection radii in an end-to-end manner. {\color{black}Theoretically, we show that the bi-level optimization formulation could explain the regularization capability of TPGM.} Empirically, with little hyper-parameter search cost, TPGM outperforms existing fine-tuning methods in OOD performance while matching the best in-distribution (ID) performance. For example, when fine-tuned on DomainNet-Real and ImageNet, compared to vanilla fine-tuning, TPGM shows $22\%$ and $10\%$ relative OOD improvement respectively on their sketch counterparts.  Code is available at \url{https://github.com/PotatoTian/TPGM}.
\end{abstract}

%%%%%%%%% BODY TEXT
\input{introdcution}
\input{related_works}
\input{method}
\input{theory}
\input{experiments}
\input{conclusion}

\paragraph{Acknowledgements.} This work was partially supported by Meta, ONR grant N00014-18-1-2829, and GTRI.

%%%%%%%%% REFERENCES

{\small
\bibliographystyle{ieee_fullname}
\bibliography{cvpr}
}

\clearpage
\input{appendix}
\end{document}
