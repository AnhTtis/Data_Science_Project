In our main experiments, we subsampled the original and GAN-inverted images to match the number of training images for the classifiers for comparison with different synthetic average datasets.
For completeness, here we include the ``best-case scenario'' classification performance results for these baselines by using the full training dataset in APTOS. 
\input{Author Guidelines for ECCV Submission/Tables/table7}
The results are shown in Supplementary Table~\ref{table:fairness}.
We obtained a Cohen's $\kappa$ of 0.914 and 0.857 for Original and GAN-Inverted, respectively, without subsampling, compared to 0.888 and 0.828 with subsampling with $k=5$ (i.e., a 20\% sampling rate), respectively.
These results suggest that, while subsampling does reduce the performance, the impact is relatively small and that $k$-SALSA performance is still competitive with the best-case scenario, especially when used with our data augmentation strategy described in the previous section.
