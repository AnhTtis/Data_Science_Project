Retinal imaging is a fast, non-invasive, and cost-effective platform to study a range of systemic diseases, e.g. cardiovascular and neurological disorders~\cite{Wagner20}. Recent advances in machine learning (ML) are accelerating this transformation, equipping researchers with tools to recognize clinically relevant biomarkers across diverse imaging modalities, such as fundus imaging and optical coherence tomography (OCT). Studies have demonstrated the effectiveness of deep learning models in predicting clinical traits such as cardiovascular risk factors as well as other health-related information such as age, sex, and smoking status~\cite{Korot21,Poplin18,Wisely22}.

However, privacy concerns prevent the sharing of retinal images, presenting a hurdle for ML in ophthalmology~\cite{EyeNet21,Tom20}. 
Despite not being legally recognized as a biometric identifier in certain cases (e.g. HIPAA~\cite{Hipaa02}), retinal images are widely regarded as sensitive because they include individual-specific patterns like blood vessel structure~\cite{Marino06}.
Reflecting these concerns,
medical institutions have begun to refrain from using retinal images in grand rounds, lectures, and publications, leading to difficulties in research and education. We aim to tackle these challenges by transforming retinal images to protect privacy while preserving clinical utility.

To this end, a seminal work by Newton et al.~\cite{Newton05} on face de-identification introduced a class of techniques known as the ``$k$-Same’’ algorithms, wherein mutually disjoint clusters of $k$ images in the dataset are individually replaced with a single representative synthetic image that summarizes the visual characteristics of the images in each cluster. This naturally leads to a synthetic dataset satisfying the classical privacy notion of $k$-anonymity~\cite{Sweeney02}, which requires that each data instance in the released dataset cannot be distinguished among at least $k$ underlying individuals. $k$-anonymity has been widely considered in the medical literature as a meaningful privacy notion and has been used as a core principle in real-world systems and polices~\cite{Garfinkel15,Gkoulalas14,Jakob20}. Furthermore, recent successes of generative adversarial networks (GANs)~\cite{Goodfellow16,Gui21} in synthesizing realistic images in diverse domains suggest a promising approach for generating high-quality representatives of individual clusters by taking an average of images in the latent embedding space of a GAN, also known as the $k$-Same-Net algorithm~\cite{Meden18}. 

Despite the promise of these approaches, several key challenges remain in applying these methods to retinal images. First, while several works have explored the use of GANs to generate synthetic retinal images~\cite{Burlina22,Burlina19,Chen21,Coyner20,Niu19}, none to our knowledge have addressed the problem of effectively summarizing these images in the latent space, making the feasibility of this approach for retinal images an unknown. Next, the difficulty of capturing fine-grain visual patterns of retinal images (e.g. hemorrhages or lipid deposits) poses an additional challenge in preserving the clinical utility of these images. Finally, because $k$-anonymity does not directly imply privacy (individual images could potentially be inferred from the average), a direct evaluation of privacy offered by $k$-anonymity in the context of retinal images is needed before these tools may be used in practice~\cite{paul2021defending}. 

To address these challenges, we developed $k$-SALSA, an end-to-end
pipeline for synthesizing a $k$-anonymous dataset given a private dataset of retinal images.
We modernize the approach of $k$-Same-Net to use state-of-the-art techniques for training and inverting GANs.
This allows us to map the source images to an embedding space, ``average'' them, and generate a representative synthetic image.
We improve upon the existing methodology of taking the Euclidean average of embedding vectors by introducing a new technique called \emph{local style alignment}, which aims to maximize the retention of local texture information from the source images. This ensures that the output keeps clinically relevant features.

We evaluate our pipeline on two benchmark datasets (APTOS and EyePACS) and demonstrate the enhanced visual fidelity of the synthetic images generated by our approach with respect to the Fr\'{e}chet inception distance~\cite{Heusel17}, a standard quality metric for synthetic images.
We also show that the synthetic dataset generated by our approach enables accurate training of downstream classifiers for predicting varying degrees of diabetic retinopathy.

Lastly, we evaluate the privacy of our approach with respect to membership inference attacks (MIA), where an adversary tries to predict whether a given retinal image was part of the cluster represented by a specific synthetic image.
Our results show that synthetic images generated by $k$-SALSA provide strong mitigation of MIA, while prior $k$-Same approaches using pixel-wise or eigenvector-based averaging fail to do so, despite the fact that all of these approaches ostensibly satisfy $k$-anonymity.

\textbf{Summary of our contributions.} 
(1) We demonstrate the feasibility of GAN-based $k$-anonymization of retinal images. (2) We present a modernized $k$-Same algorithm using state-of-the-art GAN techniques, which are crucial for practical performance. (3) We introduce a novel technique---local style alignment---for generating a synthetic average with enhanced fidelity and downstream utility. (4) We perform comprehensive experiments on two datasets, evaluating the fidelity, utility, and privacy of our method compared to existing techniques.