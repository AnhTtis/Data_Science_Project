% updated April 2002 by Antje Endemann
% Based on CVPR 07 and LNCS, with modifications by DAF, AZ and elle, 2008 and AA, 2010, and CC, 2011; TT, 2014; AAS, 2016; AAS, 2020; TH, 2022

\documentclass[runningheads]{llncs}
\usepackage{graphicx}
% DO NOT USE \usepackage{times}, it will be removed by typesetters
%\usepackage{times}

\usepackage{tikz}
\usepackage{comment}
\usepackage{amsmath,amssymb} % define this before the line numbering.
\usepackage{color}
\usepackage{xcolor}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{tabularx, booktabs, makecell, caption}
\usepackage{multirow}
\usepackage{adjustbox}
\usepackage{threeparttable}
\usepackage{graphicx}
% \usepackage{orcidlink}
% \usepackage{siunitx}
% \usepackage{multicol}
% The "axessiblity" package can be found at: https://ctan.org/pkg/axessibility?lang=en
\usepackage[accsupp]{axessibility}  % Improves PDF readability for those with disabilities.
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
}

\makeatletter
\renewcommand*{\@fnsymbol}[1]{\ensuremath{\ifcase#1\or *\or \dagger\or \ddagger\or
   \mathsection\or \mathparagraph\or \|\or **\or \dagger\dagger
   \or \ddagger\ddagger \else\@ctrerr\fi}}
\makeatother

\begin{document}
\pagestyle{headings}
\mainmatter
\def\ECCVSubNumber{6974}  % Insert your submission number here

\title{$k$-SALSA: $k$-anonymous synthetic averaging of retinal images via local style alignment} % Replace with your title

% INITIAL SUBMISSION 
%\begin{comment}
% \titlerunning{ECCV-22 submission ID \ECCVSubNumber} 
% \authorrunning{ECCV-22 submission ID \ECCVSubNumber} 
% \author{Anonymous ECCV submission}
% \institute{Paper ID \ECCVSubNumber}
%\end{comment}
%******************

% CAMERA READY SUBMISSION
% \begin{comment}
\titlerunning{Synthetic Averaging of Retinal Images via Local Style Alignment}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
% \author{Minkyu Jeon\inst{1,2}\orcidlink{0000-0003-0572-6065} \and
% Hyeonjin Park\inst{5,}\thanks{This work was performed while the author was at Korea University}\and
% Hyunwoo J. Kim\inst{2,}$^\dagger$\orcidlink{0000-0002-2181-9264} \and
% Michael Morley\inst{3,4,}$^\dagger$\orcidlink{0000-0001-6373-7008} \and
% Hyunghoon Cho\inst{1,}\thanks{Corresponding authors}\orcidlink{0000-0002-2713-0150}}
\author{Minkyu Jeon\inst{1,2} \and
Hyeonjin Park\inst{5,}\thanks{This work was performed while the author was at Korea University}\and
Hyunwoo J. Kim\inst{2,}$^\dagger$ \and
Michael Morley\inst{3,4,}$^\dagger$ \and
Hyunghoon Cho\inst{1,}\thanks{Corresponding authors}}

%
\authorrunning{M. Jeon et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Broad Institute of MIT and Harvard, Cambridge, MA, USA\\ 
\email{\{mjeon, hhcho\}@broadinstitute.org} \and
Korea University, Seoul, Republic of Korea\\
\email{hyunwoojkim@korea.ac.kr} \and
Harvard Medical School, Boston, MA, USA \\ \and
Ophthalmic Consultants of Boston, Boston, MA, USA \\
\email{mgmorley@eyeboston.com}\and
NAVER CLOVA, Seoul, Republic of Korea \\ \email{hyeonjin.park.ml@navercorp.com}}
% \end{comment}
%******************
\newcommand{\minkyu}{\textcolor[rgb]{1,0,1}}
\newcommand{\correct}{\textcolor[rgb]{0,0,1}}
\maketitle
\begin{abstract}
\input{0_abstract}
\end{abstract}
\section{Introduction}
\label{sec:introduction}
\input{1_introduction}

\section{Related Work}
\input{2_relatedwork}

\section{Method}
\input{3_method}

\section{Experiments}
\input{4_experiments}

\section{Discussion and Conclusions}
\input{5_conclusion}\\

\noindent\textbf{Acknowledgements.} \input{Acknowledgement}

% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
\bibliographystyle{splncs04}
% \bibliography{egbib.bbl}
\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }
\providecommand{\doi}[1]{https://doi.org/#1}

\bibitem{Abramian19}
Abramian, D., Eklund, A.: Refacing: Reconstructing anonymized facial features
  using {GANS}. In: 2019 IEEE 16th International Symposium on Biomedical
  Imaging (ISBI 2019) (2019)

\bibitem{Alaluf21}
Alaluf, Y., Patashnik, O., Cohen-Or, D.: Restyle: A residual-based stylegan
  encoder via iterative refinement. In: Proceedings of the IEEE/CVF
  International Conference on Computer Vision (2021)

\bibitem{Bischoff07}
Bischoff-Grethe, A., Ozyurt, I.B., Busa, E., Quinn, B.T., Fennema-Notestine,
  C., Clark, C.P., Morris, S., Bondi, M.W., Jernigan, T.L., Dale, A.M., et~al.:
  A technique for the deidentification of structural brain mr images. Human
  brain mapping  (2007)

\bibitem{Burlina22}
Burlina, P., Paul, W., Liu, T.Y.A., Bressler, N.M.: {Detecting Anomalies in
  Retinal Diseases Using Generative, Discriminative, and Self-supervised Deep
  Learning}. JAMA Ophthalmology  (2022)

\bibitem{Burlina19}
Burlina, P.M., Joshi, N., Pacheco, K.D., Liu, T.Y.A., Bressler, N.M.:
  {Assessment of Deep Generative Models for High-Resolution Synthetic Retinal
  Image Generation of Age-Related Macular Degeneration}. JAMA Ophthalmology
  (2019)

\bibitem{Chen21}
Chen, Y., Long, J., Guo, J.: Rf-gans: A method to synthesize retinal fundus
  images based on generative adversarial network. Computational intelligence
  and neuroscience  (2021)

\bibitem{Coyner20}
Coyner, A.S., Chen, J., Campbell, J.P., Ostmo, S., Singh, P., Kalpathy-Cramer,
  J., Chiang, M.F.: {Diagnosability of Synthetic Retinal Fundus Images for Plus
  Disease Detection in Retinopathy of Prematurity.} AMIA Symposium  (2020)

\bibitem{Dwork14}
Dwork, C., Roth, A., et~al.: The algorithmic foundations of differential
  privacy. Found. Trends Theor. Comput. Sci.  (2014)

\bibitem{Fei09}
Fei-Fei, L., Deng, J., Li, K.: Imagenet: Constructing a large-scale image
  database. Journal of vision  (2009)

\bibitem{Garfinkel15}
Garfinkel, S., et~al.: De-identification of Personal Information:. US
  Department of Commerce, National Institute of Standards and Technology (2015)

\bibitem{Gatys16}
Gatys, L.A., Ecker, A.S., Bethge, M.: Image style transfer using convolutional
  neural networks. In: Proceedings of the IEEE conference on computer vision
  and pattern recognition (2016)

\bibitem{Gkoulalas14}
Gkoulalas-Divanis, A., Loukides, G., Sun, J.: Publishing data from electronic
  health records while preserving privacy: A survey of algorithms. Journal of
  biomedical informatics  (2014)

\bibitem{Goodfellow16}
Goodfellow, I.: Nips 2016 tutorial: Generative adversarial networks. arXiv
  preprint arXiv:1701.00160  (2016)

\bibitem{Der21}
der Goten, V., Alexander, L., Hepp, T., Akata, Z., Smith, K.: Conditional
  de-identification of 3d magnetic resonance images. arXiv preprint
  arXiv:2110.09927  (2021)

\bibitem{Gui21}
Gui, J., Sun, Z., Wen, Y., Tao, D., Ye, J.: A review on generative adversarial
  networks: Algorithms, theory, and applications. IEEE Transactions on
  Knowledge and Data Engineering  (2021)

\bibitem{He20}
He, K., Fan, H., Wu, Y., Xie, S., Girshick, R.: Momentum contrast for
  unsupervised visual representation learning. In: Proceedings of the IEEE/CVF
  conference on computer vision and pattern recognition (2020)

\bibitem{He16}
He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image
  recognition. In: Proceedings of the IEEE conference on computer vision and
  pattern recognition (2016)

\bibitem{he2016deep}
He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image
  recognition. In: Proceedings of the IEEE conference on computer vision and
  pattern recognition (2016)

\bibitem{Heusel17}
Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., Hochreiter, S.: Gans
  trained by a two time-scale update rule converge to a local nash equilibrium.
  Advances in neural information processing systems  (2017)

\bibitem{Jakob20}
Jakob, C.E., Kohlmayer, F., Meurers, T., Vehreschild, J.J., Prasser, F.: Design
  and evaluation of a data anonymization pipeline to promote open science on
  covid-19. Scientific data  (2020)

\bibitem{Jeong21}
Jeong, Y., Choi, J., Kim, S., Ro, Y., Oh, T.H., Kim, D., Ha, H., Yoon, S.:
  Ficgan: Facial identity controllable gan for de-identification. arXiv
  preprint arXiv:2110.00740  (2021)

\bibitem{Jourabloo15}
Jourabloo, A., Yin, X., Liu, X.: Attribute preserved face de-identification.
  In: 2015 International conference on biometrics (ICB) (2015)

\bibitem{Karras20b}
Karras, T., Aittala, M., Hellsten, J., Laine, S., Lehtinen, J., Aila, T.:
  Training generative adversarial networks with limited data. Advances in
  Neural Information Processing Systems  (2020)

\bibitem{Karras2020ada}
Karras, T., Aittala, M., Hellsten, J., Laine, S., Lehtinen, J., Aila, T.:
  Training generative adversarial networks with limited data. In: Proc. NeurIPS
  (2020)

\bibitem{Karras19}
Karras, T., Laine, S., Aila, T.: A style-based generator architecture for
  generative adversarial networks. In: Proceedings of the IEEE/CVF conference
  on computer vision and pattern recognition (2019)

\bibitem{Karras20a}
Karras, T., Laine, S., Aittala, M., Hellsten, J., Lehtinen, J., Aila, T.:
  Analyzing and improving the image quality of stylegan. In: Proceedings of the
  IEEE/CVF conference on computer vision and pattern recognition (2020)

\bibitem{Kifer14}
Kifer, D., Machanavajjhala, A.: Pufferfish: A framework for mathematical
  privacy definitions. ACM Transactions on Database Systems (TODS)  (2014)

\bibitem{kingma2014adam}
Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. arXiv
  preprint arXiv:1412.6980  (2014)

\bibitem{Korot21}
Korot, E., Pontikos, N., Liu, X., Wagner, S.K., Faes, L., Huemer, J., Balaskas,
  K., Denniston, A.K., Khawaja, A., Keane, P.A.: Predicting sex from retinal
  fundus photographs using automated deep learning. Scientific reports  (2021)

\bibitem{Long21}
Long, Y., Wang, B., Yang, Z., Kailkhura, B., Zhang, A., Gunter, C., Li, B.:
  G-pate: Scalable differentially private data generator via private
  aggregation of teacher discriminators. Advances in Neural Information
  Processing Systems  (2021)

\bibitem{long2021gpate}
Long, Y., Wang, B., Yang, Z., Kailkhura, B., Zhang, A., Gunter, C.A., Li, B.:
  G-pate: Scalable differentially private data generator via private
  aggregation of teacher discriminators. NeurIPS 2021  (2021)

\bibitem{Loshchilov16}
Loshchilov, I., Hutter, F.: Sgdr: Stochastic gradient descent with warm
  restarts. arXiv preprint arXiv:1608.03983  (2016)

\bibitem{Marino06}
Mari{\~n}o, C., Penedo, M.G., Penas, M., Carreira, M.J., Gonzalez, F.: Personal
  authentication using digital retinal images. Pattern Analysis and
  Applications  (2006)

\bibitem{Maximov20}
Maximov, M., Elezi, I., Leal-Taix{\'e}, L.: Ciagan: Conditional identity
  anonymization generative adversarial networks. In: Proceedings of the
  IEEE/CVF Conference on Computer Vision and Pattern Recognition (2020)

\bibitem{Meden18}
Meden, B., Emer{\v{s}}i{\v{c}}, {\v{Z}}., {\v{S}}truc, V., Peer, P.:
  k-same-net: k-anonymity with generative deep neural networks for face
  deidentification. Entropy  (2018)

\bibitem{Milchenko13}
Milchenko, M., Marcus, D.: Obscuring surface anatomy in volumetric imaging
  data. Neuroinformatics  (2013)

\bibitem{Mohamed07}
Mohamed, Q., Gillies, M.C., Wong, T.Y.: Management of diabetic retinopathy: a
  systematic review. Jama  (2007)

\bibitem{Nesterov03}
Nesterov, Y.: Introductory lectures on convex optimization: A basic course.
  Springer Science \& Business Media (2003)

\bibitem{Newton05}
Newton, E.M., Sweeney, L., Malin, B.: Preserving privacy by de-identifying face
  images. IEEE transactions on Knowledge and Data Engineering  (2005)

\bibitem{Niu19}
Niu, Y., Gu, L., Lu, F., Lv, F., Wang, Z., Sato, I., Zhang, Z., Xiao, Y., Dai,
  X., Cheng, T.: Pathological evidence exploration in deep retinal image
  diagnosis. In: Proceedings of the AAAI conference on artificial intelligence
  (2019)

\bibitem{paul2021defending}
Paul, W., Cao, Y., Zhang, M., Burlina, P.: Defending medical image diagnostics
  against privacy attacks using generative methods. arXiv preprint
  arXiv:2103.03078  (2021)

\bibitem{Poplin18}
Poplin, R., Varadarajan, A.V., Blumer, K., Liu, Y., McConnell, M.V., Corrado,
  G.S., Peng, L., Webster, D.R.: Prediction of cardiovascular risk factors from
  retinal fundus photographs via deep learning. Nature Biomedical Engineering
  (2018)

\bibitem{radford2015unsupervised}
Radford, A., Metz, L., Chintala, S.: Unsupervised representation learning with
  deep convolutional generative adversarial networks. arXiv preprint
  arXiv:1511.06434  (2015)

\bibitem{Ravindra21}
Ravindra, V., Grama, A.: De-anonymization attacks on neuroimaging datasets. In:
  Proceedings of the 2021 International Conference on Management of Data (2021)

\bibitem{Ribaric15}
Ribaric, S., Pavesic, N.: An overview of face de-identification in still images
  and videos. In: 2015 11th IEEE International Conference and Workshops on
  Automatic Face and Gesture Recognition (FG) (2015)

\bibitem{richardson2021encoding}
Richardson, E., Alaluf, Y., Patashnik, O., Nitzan, Y., Azar, Y., Shapiro, S.,
  Cohen-Or, D.: Encoding in style: a stylegan encoder for image-to-image
  translation. In: IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR) (June 2021)

\bibitem{Schimke11}
Schimke, N., Kuehler, M., Hale, J.: Preserving privacy in structural
  neuroimages. In: IFIP annual conference on data and applications security and
  privacy (2011)

\bibitem{Simonyan15}
Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale
  image recognition. In: International Conference on Learning Representations
  (2015)

\bibitem{Sweeney02}
Sweeney, L.: k-anonymity: A model for protecting privacy. International Journal
  of Uncertainty, Fuzziness and Knowledge-Based Systems  (2002)

\bibitem{Szegedy16}
Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z.: Rethinking the
  inception architecture for computer vision. In: Proceedings of the IEEE
  conference on computer vision and pattern recognition (2016)

\bibitem{EyeNet21}
Taylor, R.: {AI and the Retina: Finding Patterns of Systemic Disease}. EyeNet
  Magazine  (2021)

\bibitem{Tom20}
Tom, E., Keane, P.A., Blazes, M., Pasquale, L.R., Chiang, M.F., Lee, A.Y., Lee,
  C.S., Force, A.A.I.T.: Protecting data privacy in the age of ai-enabled
  ophthalmology. Translational Vision Science \& Technology  (2020)

\bibitem{Hipaa02}
{U.S. Dept. of Health and Human Services}: {Standards for privacy of
  individually identifiable health information, Final Rule}. Federal Registrar
  (2002)

\bibitem{Wagner20}
Wagner, S.K., Fu, D.J., Faes, L., Liu, X., Huemer, J., Khalid, H., Ferraz, D.,
  Korot, E., Kelly, C., Balaskas, K., et~al.: Insights into systemic disease
  through retinal imaging-based oculomics. Translational vision science \&
  technology  (2020)

\bibitem{Wang21}
Wang, X., Zhang, R., Shen, C., Kong, T., Li, L.: Dense contrastive learning for
  self-supervised visual pre-training. In: Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition (2021)

\bibitem{wang2004image}
Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P.: Image quality
  assessment: from error visibility to structural similarity. IEEE transactions
  on image processing  (2004)

\bibitem{Wisely22}
Wisely, C.E., Wang, D., Henao, R., Grewal, D.S., Thompson, A.C., Robbins, C.B.,
  Yoon, S.P., Soundararajan, S., Polascik, B.W., Burke, J.R., et~al.:
  Convolutional neural network to identify symptomatic alzheimerâ€™s disease
  using multimodal retinal imaging. British Journal of Ophthalmology  (2022)

\bibitem{Wu19}
Wu, Y., Yang, F., Xu, Y., Ling, H.: Privacy-protective-gan for privacy
  preserving face de-identification. Journal of Computer Science and Technology
   (2019)

\bibitem{Xia21}
Xia, W., Zhang, Y., Yang, Y., Xue, J.H., Zhou, B., Yang, M.H.: Gan inversion: A
  survey. arXiv preprint arXiv:2101.05278  (2021)

\bibitem{Xu19}
Xu, C., Ren, J., Zhang, D., Zhang, Y., Qin, Z., Ren, K.: Ganobfuscator:
  Mitigating information leakage under gan via differential privacy. IEEE
  Transactions on Information Forensics and Security  (2019)

\bibitem{Yu19}
Yu, Z., Xiang, Q., Meng, J., Kou, C., Ren, Q., Lu, Y.: Retinal image synthesis
  from multiple-landmarks input with generative adversarial networks.
  Biomedical engineering online  (2019)

\bibitem{Zhou20}
Zhou, Y., Wang, B., He, X., Cui, S., Shao, L.: Dr-gan: Conditional generative
  adversarial network for fine-grained lesion synthesis on diabetic retinopathy
  images. IEEE Journal of Biomedical and Health Informatics  (2020)

\end{thebibliography}

\setcounter{section}{0}
\renewcommand\thesection{\Alph{section}}

\input{Author Guidelines for ECCV Submission/Appendix/0_implementation_detail.tex}

\section{Choice of similarity metric for local style alignment}
\input{Author Guidelines for ECCV Submission/Appendix/1_ablation}

\section{Addressing the reduced size of synthetic dataset}
\input{Author Guidelines for ECCV Submission/Appendix/7_addressing_reduced_size}

\section{Additional comparisons with Original/gan-inverted}
\input{Author Guidelines for ECCV Submission/Appendix/6_fairness_of_comparison}

\section{Performance dependence on the cluster size $k$}
\input{Author Guidelines for ECCV Submission/Appendix/5_performance_dependence_on_k}

\section{Challenges of differentially private GANs}
\input{Author Guidelines for ECCV Submission/Appendix/3_dp_gan}

\section{Choice of visual fidelity metric}
\input{Author Guidelines for ECCV Submission/Appendix/4_other_quality_metrics}

\section{Additional examples of synthetic averages}
\input{Author Guidelines for ECCV Submission/Appendix/2_additional_results}

\end{document}