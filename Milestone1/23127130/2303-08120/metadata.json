{
    "arxiv_id": "2303.08120",
    "paper_title": "Blind Video Deflickering by Neural Filtering with a Flawed Atlas",
    "authors": [
        "Chenyang Lei",
        "Xuanchi Ren",
        "Zhaoxiang Zhang",
        "Qifeng Chen"
    ],
    "submission_date": "2023-03-14",
    "revised_dates": [
        "2023-03-15"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "Many videos contain flickering artifacts. Common causes of flicker include video processing algorithms, video generation algorithms, and capturing videos under specific situations. Prior work usually requires specific guidance such as the flickering frequency, manual annotations, or extra consistent videos to remove the flicker. In this work, we propose a general flicker removal framework that only receives a single flickering video as input without additional guidance. Since it is blind to a specific flickering type or guidance, we name this \"blind deflickering.\" The core of our approach is utilizing the neural atlas in cooperation with a neural filtering strategy. The neural atlas is a unified representation for all frames in a video that provides temporal consistency guidance but is flawed in many cases. To this end, a neural network is trained to mimic a filter to learn the consistent features (e.g., color, brightness) and avoid introducing the artifacts in the atlas. To validate our method, we construct a dataset that contains diverse real-world flickering videos. Extensive experiments show that our method achieves satisfying deflickering performance and even outperforms baselines that use extra guidance on a public benchmark.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.08120v1"
    ],
    "publication_venue": "To appear in CVPR2023. Code: github.com/ChenyangLEI/All-In-One-Deflicker Website: chenyanglei.github.io/deflicker"
}