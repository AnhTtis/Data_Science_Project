
\input{Paper/Figures/Dual_camera}

\section{ExLPose Dataset} \label{sec:dataset}
We propose the first \emph{Extremely Low-light} image dataset for human Pose estimation, coined ExLPose.
The ExLPose dataset provides pairs of low-light and well-lit images that are real and aligned, as well as their ground-truth human pose labels.
We believe that the accurate pose labels and well-lit counterparts for extremely low-light images will open a new and promising research direction towards human pose estimation in low-light conditions.

Since it is practically impossible to simultaneously capture paired low-light and well-lit images using common cameras, we construct a dual-camera system~\cite{Jiang_2019_ICCV, rim_2022_ECCV}
dedicated to the purpose.
Our camera system is depicted in \Fig{system}. 
It consists of two camera modules with a beam splitter that distributes light from a lens equally to the two camera modules. 
One of the modules captures well-lit images, and the other captures low-light images through a 1\% neutral density (ND) filter that optically reduces the amount of light by 100 times.
The two camera modules simultaneously capture a pair of low-light and well-lit images of the same scene with a synchronized shutter. 
As done in~\cite{jsrim-ECCV2020}, the images are geometrically aligned using a reference image pair captured in a static scene. Details of the geometric alignment are given in Sec.~\ref{appendix:geometric_alignment} of the supplement.


\input{Paper/Figures/ExLPose_pair}
\input{Paper/Tables/ExLPose_statistics}
\input{Paper/Figures/ExLPose_examples}

We collected images of various indoor and daytime outdoor scenes in the sRGB format. 
To cover low-light scenes of diverse brightness levels, we collected low-light images with various exposure times.
Specifically, for each scene, we first manually found a proper exposure time and a gain value to capture a well-lit image without losing much information in the highlights or in the shadows, and also without motion blur.
Then, we sequentially captured low-light images reducing the exposure time by 1, 2, 4, 8, and 12 times with the same gain value as shown at the bottom of \Fig{pair}.
At the same time, for the well-lit images, we also changed the exposure time in the same manner to synchronize the exposure time for each frame, but inverse-proportionally increased the gain value to maintain the same brightness level as presented at the top of \Fig{pair}. 
For the indoor scenes, we reduced the exposure time by 1, 2, 3, 4, and 6 times.
Note that low-light and well-lit images of a pair are captured with the same exposure time.

Finally, we collected 2,556 pairs of low-light and well-lit images of 251 scenes; 2,065 pairs of 201 scenes are used for training, and the remaining 491 pairs of 50 scenes are kept for testing.
We manually annotated a bounding box and 14 body joints for each person using well-lit images following the CrowdPose dataset~\cite{Li_2019_CVPR}, and collected annotations for 14,215 human instances. 
The annotations are used as the ground-truth labels for both low-light and well-lit images as the images are spatially aligned.

While the dedicated camera system allows capturing real low-light images paired with well-lit images, it may introduce two limitations regarding the generalization ability of the pose estimation method.
First, the dataset does not cover diverse cameras as the system is designed with specific camera modules.
Second, low-light images captured with an ND filter may have different characteristics than low-light images captured at night.
Thus, for the evaluation of the generalization ability, we also propose another dataset, named ExLPose-OCN, that provides extremely low-light images captured by Other Cameras at Night.
Specifically, the ExLPose-OCN dataset provides images captured using a DSLR camera (A7M3) and a compact camera (RICHO3) and manually annotated ground-truth labels, but no well-lit images. The images are in JPEG format. For each camera, 180 images are provided.
\Tbl{dataset_statistics} summarizes statistics of the ExLPose and ExLPose-OCN datasets, and \Fig{overview_dataset} and \Fig{overview_dataset_oc} show example images of the two datasets.
