%-------------------------------------------------------------------------
\section{Related Work}
\label{sec:related_work}

\noindent \textbf{Human NeRF.}
NeRF~\cite{nerf,advancesinnerf} has inspired research in 3D human reconstruction. Human NeRF can synthesize high-fidelity novel views or poses of 3D humans, given multi-view or monocular human videos. Neural Body~\cite{peng2021neural} applies sparse convolutions to model the radiance volume, while others model human NeRF in the canonical space~\cite{chen2021animatable, animatablenerf, xu2021h, noguchi2021neural, weng2022humannerf, su2021nerf, jiang2022selfrecon, jiang2022neuman, wang2022arah} using SMPL LBS weights or optimizing LBS weights with appearance.
While these methods achieve impressive results, they often require time-consuming optimization and dense observations. To address this, there has been a growing interest in generalizable human NeRF~\cite{kwon2021neural, gao2022mps, choi2022mononhr, zhao2021humannerf, huang2022elicit}. These methods require fewer observations and only one forward pass.
This work also aims to develop generalizable human NeRF and tackle a more challenging scenario, recovering animatable human NeRF from a single image.

\noindent \textbf{Monocular Human Reconstruction.}
Statistical 3D human models~\cite{SMPL:2015, smplx, joo2018total, romero2022embodied, xu2020ghum} have enabled the reconstruction of 3D humans from monocular observations. Using these models, researchers have estimated coarse human shapes and poses~\cite{kanazawa2018end, kocabas2020vibe, kocabas2021pare, kolotouros2019learning}. To model the complex shape of clothed humans, mesh deformation is estimated~\cite{alldieck2018detailed, alldieck2018video, alldieck2019tex2shape, pons2017clothcap, zhu2019detailed}. Implicit representations, such as SDF, have been used to improve geometry quality~\cite{saito2019pifu, saito2020pifuhd, he2020geo, li2020robust, dong2022pina, li2020monocular, bozic2021neural, yang2021s3}. To take advantage of both explicit and implicit representations, researchers have explored combining these representations~\cite{bhatnagar2020combining, bhatnagar2020loopreg, huang2020arch, he2021arch++, zheng2021pamir, xiu2022icon, xiu2022econ, alldieck2022photorealistic, corona2022structured} for better generalizability and reconstruction quality. In comparison, with the advantages of NeRF, we do not need 3D ground truth for training. Moreover, we reconstruct humans in the canonical space, which can be easily driven with novel poses.

\noindent \textbf{Generalizable NeRF.}
NeRF requires dense calibrated views~\cite{nerf, muller2022instant}, but recent advances have led to the development of generalizable NeRF that can work with very few or even single views. Cross-scene multi-view aggregators~\cite{wang2021ibrnet, chen2021mvsnerf, liu2022neuray, wang2022generalizable} can synthesize novel views by learning to aggregate sparse views. Other works~\cite{gao2020portrait,lin2022vision,sitzmann2019scene,mi2022im2nerf,guo2022fast,sajjadi2022scene,cao2022fwd} encode observations to latent space and decode to NeRF.
Our work focuses on generalizable Human NeRF that encodes single human images into the canonical 3D space.