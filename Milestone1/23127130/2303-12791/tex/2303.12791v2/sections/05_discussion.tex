\section{Discussion and Conclusion}
To conclude, we propose \textbf{\nickname{}}, the first generalizable human NeRF model that recovers animatable 3D humans from single human image inputs.
To render high-fidelity 3D humans, \nickname{} proposes to learn both global and local details from the bank of 3D-aware hierarchical features comprising global features, point-level features, and pixel-aligned features. 
By using a feature fusion transformer, \nickname{} successfully enhances the information from the 2D observation and complements the information missing from the input image. 
On four large-scale human datasets, \nickname{} achieves state-of-the-art performance and renders high-fidelity images in both novel views and poses.

\vspace{1.75mm}
\noindent \textbf{Limitations:}
1) There still exists visible artifacts in target renderings when some body parts are occluded in the observation space. 
A better feature presentation like occlusion-aware features may be explored to solve this issue. 
2) How to complement the information missing from single image input remains a challenging problem.
\nickname{} starts from the reconstruction view and can only render deterministic results when predicting novel views.
One potential direction is to investigate the use of conditional generative models to diversely generate higher quality novel views.

\vspace{1.75mm}
\noindent \textbf{Potential Negative Societal Impacts:} 
\nickname{} can be misused to create fake images or videos of real humans and cause negative social impacts.

\section{Acknowledgment}
This study is supported by the Ministry of Education, Singapore, under its MOE AcRF Tier 2 (MOE-T2EP20221-0012), NTU NAP, and under the RIE2020 Industry Alignment Fund â€“ Industry Collaboration Projects (IAF-ICP) Funding Initiative, as well as cash and in-kind contribution from the industry partner(s).
