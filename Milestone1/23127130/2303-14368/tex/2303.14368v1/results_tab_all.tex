\begin{table*}[t]
\begin{center}
\begin{tabular}{ |c|c|c|c|c|c| } 
\hline
{Dataset} & {Views} & {Method} & {LPIPS} $\times 10^3$ $\downarrow$ & {PSNR} $\uparrow$ & {SSIM} $\uparrow$\\ 
\hline
\rowcolor{gray!25}
\cellcolor{white} \multirow{6}{8em}{PeopleSnapshot \cite{alldieck2018video}} &  & HumanNeRF \cite{Weng2022HumanNeRFFR} & 39.27 & 27.65 & 0.8816 \\ 
% \cline{3-6}
\hhline{~~|*4{-}|}
\rowcolor{gray!25}
\cellcolor{white} & \multirow{-2}{5em}{Sparse$^\ddagger$} & Ours & \textbf{37.11} & \textbf{28.09} & \textbf{0.9003} \\ 
\cline{2-6}
 & \multirow{3}{5em}{Full} & Neural Body \cite{Peng2021NeuralBI} & 57.67$^*$ & 24.62 & 0.8490 \\ 
\cline{3-6}
% & & H-NeRF \cite{Xu2021HNeRFNR} & 57.31$^*$ & {26.33} & {0.8680} \\ 
% \cline{3-6}
& & HumanNeRF \cite{Weng2022HumanNeRFFR} & 36.79 & 28.05 & 0.8984 \\ 
\cline{3-6}
& & Ours & \textbf{35.63} & \textbf{28.77} & \textbf{0.9043} \\
%-------------------------------------------------------------
\hline
\hline
\rowcolor{gray!25}
\cellcolor{white} \multirow{6}{8em}{ZJU-MoCap \cite{Peng2021NeuralBI, fang2021mirrored}} &  & HumanNeRF \cite{Weng2022HumanNeRFFR} & 36.02 & 29.82 & 0.9597 \\ 
% \cline{3-6}
\arrayrulecolor{gray!25}
\hhline{~|*1{-}|}
\arrayrulecolor{black}
\hhline{~~|*4{-}|}
\rowcolor{gray!25}
\cellcolor{white} & \multirow{-2}{5em}{Sparse$^\ddagger$} & Ours & \textbf{31.68} & \textbf{30.18} & \textbf{0.9685} \\ 
\cline{2-6}
 & \multirow{3}{5em}{Full} & Neural Body \cite{Peng2021NeuralBI} & 52.28 & 29.07 & 0.9615 \\ 
\cline{3-6}
% & & H-NeRF \cite{Xu2021HNeRFNR} & - & - & - \\ 
\cline{3-6}
& & HumanNeRF \cite{Weng2022HumanNeRFFR} & 31.72 & 30.24 & 0.9679 \\ 
\cline{3-6}
& & Ours & \textbf{29.01} & \textbf{31.73} & \textbf{0.9765} \\

\hline
\hline
%-------------------------------------------------------------
\rowcolor{gray!25}
\cellcolor{white} &  & Neural Body \cite{Peng2021NeuralBI} & 48.62 & 25.07 & 0.9131 \\ 
\cline{3-6}
\rowcolor{gray!25}
% \cellcolor{white} & & H-NeRF \cite{Xu2021HNeRFNR} & - & - & - \\ 
% \cline{3-6}
\hhline{~~|*4{-}|}
\rowcolor{gray!25}
\cellcolor{white} & & HumanNeRF \cite{Weng2022HumanNeRFFR} & 39.71 & 26.12 & 0.9366 \\ 
% \cline{3-6}
\hhline{~~|*4{-}|}
\rowcolor{gray!25}
\cellcolor{white} \multirow{-4}{8em}{SCF Dataset$^\dag$} & \multirow{-3}{5em}{\cellcolor{gray!25} Sparse$^\ddagger$} & Ours & \textbf{34.26} & \textbf{29.55} & \textbf{0.9627} \\
\hline
\end{tabular}

\end{center}
  \caption{Comparison of performance across benchmark datasets. $*$ refers to adjusted LPIPS from the values reported in~\cite{Xu2021HNeRFNR} to fit the same scale as our experiments. $\dag$ refers to the Self-Captured Fashion (SCF) dataset. $\ddagger$ indicates the model trained with sparse ($\sim 40$) views.}
  \label{tab:all_datasets}
\end{table*}