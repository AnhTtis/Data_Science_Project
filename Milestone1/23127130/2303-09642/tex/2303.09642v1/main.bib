@article{sud,
  title={SUD: Supervision by denoising for medical image segmentation},
  author={Young, Sean I and Dalca, Adrian V and Ferrante, Enzo and Golland, Polina and Fischl, Bruce and Iglesias, Juan Eugenio},
  journal={arXiv preprint arXiv:2202.02952},
  year={2022}
}

@article{ulyanov2016instance,
  title={Instance normalization: The missing ingredient for fast stylization},
  author={Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
  journal={arXiv preprint arXiv:1607.08022},
  year={2016}
}

@article{ding2020image,
  title={Image quality assessment: Unifying structure and texture similarity},
  author={Ding, Keyan and Ma, Kede and Wang, Shiqi and Simoncelli, Eero P},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={44},
  number={5},
  pages={2567--2581},
  year={2020},
  publisher={IEEE}
}

@inproceedings{wang2003multiscale,
  title={Multiscale structural similarity for image quality assessment},
  author={Wang, Zhou and Simoncelli, Eero P and Bovik, Alan C},
  booktitle={The Thrity-Seventh Asilomar Conference on Signals, Systems \& Computers, 2003},
  volume={2},
  pages={1398--1402},
  year={2003},
  organization={Ieee}
}

@article{zhao2016loss,
  title={Loss functions for image restoration with neural networks},
  author={Zhao, Hang and Gallo, Orazio and Frosio, Iuri and Kautz, Jan},
  journal={IEEE Transactions on computational imaging},
  volume={3},
  number={1},
  pages={47--57},
  year={2016},
  publisher={IEEE}
}

@inproceedings{isola2017image,
  title={Image-to-image translation with conditional adversarial networks},
  author={Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1125--1134},
  year={2017}
}

@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  pages={448--456},
  year={2015},
  organization={pmlr}
}

@inproceedings{wu2018group,
  title={Group normalization},
  author={Wu, Yuxin and He, Kaiming},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018}
}

@article{elfwing2018sigmoid,
  title={Sigmoid-weighted linear units for neural network function approximation in reinforcement learning},
  author={Elfwing, Stefan and Uchibe, Eiji and Doya, Kenji},
  journal={Neural Networks},
  volume={107},
  pages={3--11},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{drozdzal2016importance,
  title={The importance of skip connections in biomedical image segmentation},
  author={Drozdzal, Michal and Vorontsov, Eugene and Chartrand, Gabriel and Kadoury, Samuel and Pal, Chris},
  booktitle={International Workshop on Deep Learning in Medical Image Analysis, International Workshop on Large-Scale Annotation of Biomedical Data and Expert Label Synthesis},
  pages={179--187},
  year={2016},
  organization={Springer}
}

@article{metzler2016denoising,
  title={From denoising to compressed sensing},
  author={Metzler, Christopher A and Maleki, Arian and Baraniuk, Richard G},
  journal={IEEE Transactions on Information Theory},
  volume={62},
  number={9},
  pages={5117--5144},
  year={2016},
  publisher={IEEE}
}

@article{zhang2017beyond,
  title={Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising},
  author={Zhang, Kai and Zuo, Wangmeng and Chen, Yunjin and Meng, Deyu and Zhang, Lei},
  journal={IEEE transactions on image processing},
  volume={26},
  number={7},
  pages={3142--3155},
  year={2017},
  publisher={IEEE}
}

@article{dabov2007image,
  title={Image denoising by sparse 3-D transform-domain collaborative filtering},
  author={Dabov, Kostadin and Foi, Alessandro and Katkovnik, Vladimir and Egiazarian, Karen},
  journal={IEEE Transactions on image processing},
  volume={16},
  number={8},
  pages={2080--2095},
  year={2007},
  publisher={IEEE}
}

@article{kadkhodaie2021stochastic,
  title={Stochastic solutions for linear inverse problems using the prior implicit in a denoiser},
  author={Kadkhodaie, Zahra and Simoncelli, Eero},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={13242--13254},
  year={2021}
}

@inproceedings{egiazarian2007compressed,
  title={Compressed sensing image reconstruction via recursive spatially adaptive filtering},
  author={Egiazarian, Karen and Foi, Alessandro and Katkovnik, Vladimir},
  booktitle={2007 IEEE International Conference on Image Processing},
  volume={1},
  pages={I--549},
  year={2007},
  organization={IEEE}
}

@inproceedings{venkatakrishnan2013plug,
  title={Plug-and-play priors for model based reconstruction},
  author={Venkatakrishnan, Singanallur V and Bouman, Charles A and Wohlberg, Brendt},
  booktitle={2013 IEEE Global Conference on Signal and Information Processing},
  pages={945--948},
  year={2013},
  organization={IEEE}
}

@article{elad2023image,
  title={Image Denoising: The Deep Learning Revolution and Beyond--A Survey Paper--},
  author={Elad, Michael and Kawar, Bahjat and Vaksman, Gregory},
  journal={arXiv preprint arXiv:2301.03362},
  year={2023}
}

@inproceedings{blau2018perception,
  title={The perception-distortion tradeoff},
  author={Blau, Yochai and Michaeli, Tomer},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6228--6237},
  year={2018}
}

@inproceedings{wakin2005high,
  title={High-resolution navigation on non-differentiable image manifolds},
  author={Wakin, Michael B and Donoho, David L and Choi, Hyeokho and Baraniuk, Richard G},
  booktitle={Proceedings.(ICASSP'05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005.},
  volume={5},
  pages={v--1073},
  year={2005},
  organization={IEEE}
}

@inproceedings{chung2023diffusion,
title={Diffusion Posterior Sampling for General Noisy Inverse Problems},
author={Hyungjin Chung and Jeongsol Kim and Michael Thompson Mccann and Marc Louis Klasky and Jong Chul Ye},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=OnD9zGAGT0k}
}


@article{red,
  title={The little engine that could: Regularization by denoising (RED)},
  author={Romano, Yaniv and Elad, Michael and Milanfar, Peyman},
  journal={SIAM Journal on Imaging Sciences},
  volume={10},
  number={4},
  pages={1804--1844},
  year={2017},
  publisher={SIAM}
}


@article{tweedie,
author = {Efron, Bradley},
year = {2011},
month = {12},
pages = {1602-1614},
title = {Tweedie’s Formula and Selection Bias},
volume = {106},
journal = {Journal of the American Statistical Association},
doi = {10.1198/jasa.2011.tm11181}
}

@article{red_clarifications,
  title={Regularization by denoising: Clarifications and new interpretations},
  author={Reehorst, Edward T and Schniter, Philip},
  journal={IEEE transactions on computational imaging},
  volume={5},
  number={1},
  pages={52--67},
  year={2018},
  publisher={IEEE}
}


@inproceedings{cnn_dehaze,
  title={Single image dehazing via multi-scale convolutional neural networks},
  author={Ren, Wenqi and Liu, Si and Zhang, Hua and Pan, Jinshan and Cao, Xiaochun and Yang, Ming-Hsuan},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part II 14},
  pages={154--169},
  year={2016},
  organization={Springer}
}


@article{dehazenet,
author = {Cai, Bolun and Xu, Xiangmin and Jia, Kui and Qing, Chunmei and Tao, Dacheng},
title = {DehazeNet: An End-to-End System for Single Image Haze Removal},
year = {2016},
issue_date = {November 2016},
publisher = {IEEE Press},
volume = {25},
number = {11},
issn = {1057-7149},
url = {https://doi.org/10.1109/TIP.2016.2598681},
doi = {10.1109/TIP.2016.2598681},
abstract = {Single image haze removal is a challenging ill-posed problem. Existing methods use various constraints/priors to get plausible dehazing solutions. The key to achieve haze removal is to estimate a medium transmission map for an input hazy image. In this paper, we propose a trainable end-to-end system called DehazeNet, for medium transmission estimation. DehazeNet takes a hazy image as input, and outputs its medium transmission map that is subsequently used to recover a haze-free image via atmospheric scattering model. DehazeNet adopts convolutional neural network-based deep architecture, whose layers are specially designed to embody the established assumptions/priors in image dehazing. Specifically, the layers of Maxout units are used for feature extraction, which can generate almost all haze-relevant features. We also propose a novel nonlinear activation function in DehazeNet, called bilateral rectified linear unit, which is able to improve the quality of recovered haze-free image. We establish connections between the components of the proposed DehazeNet and those used in existing methods. Experiments on benchmark images show that DehazeNet achieves superior performance over existing methods, yet keeps efficient and easy to use.},
journal = {Trans. Img. Proc.},
month = {nov},
pages = {5187–5198},
numpages = {12}
}


@inproceedings{CelebAMask-HQ,
  title = {MaskGAN: Towards Diverse and Interactive Facial Image Manipulation},
  author = {Lee, Cheng-Han and Liu, Ziwei and Wu, Lingyun and Luo, Ping},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2020}
}

@inproceedings{vision_bad_weather,
  title={Vision in bad weather},
  author={Nayar, Shree K and Narasimhan, Srinivasa G},
  booktitle={Proceedings of the seventh IEEE international conference on computer vision},
  volume={2},
  pages={820--827},
  year={1999},
  organization={IEEE}
}


@article{nayar,
  title={Vision and the Atmosphere},
  author={Srinivasa G. Narasimhan and Shree K. Nayar},
  journal={International Journal of Computer Vision},
  year={2002},
  volume={48},
  pages={233-254}
}

@INPROCEEDINGS{cyclegan_ssl,
  author={Xu, Zhenghua and Qi, Chang and Xu, Guizhi},
  booktitle={2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Semi-Supervised Attention-Guided CycleGAN for Data Augmentation on Medical Images}, 
  year={2019},
  volume={},
  number={},
  pages={563-568},
  doi={10.1109/BIBM47256.2019.8982932}
}

@article{ssl_survey,
  title={A survey on deep semi-supervised learning},
  author={Yang, Xiangli and Song, Zixing and King, Irwin and Xu, Zenglin},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2022},
  publisher={IEEE}
}


@article{ddpm,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}


@article{pseudolabel,
author = {Lee, Dong-Hyun},
year = {2013},
month = {07},
pages = {},
title = {Pseudo-Label : The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Networks},
journal = {ICML 2013 Workshop : Challenges in Representation Learning (WREPL)}
}

@inproceedings{CycleGAN2017,
  title={Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks},
  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
  booktitle={Computer Vision (ICCV), 2017 IEEE International Conference on},
  year={2017}
}



@inproceedings{relu,
author = {Nair, Vinod and Hinton, Geoffrey E.},
title = {Rectified Linear Units Improve Restricted Boltzmann Machines},
year = {2010},
isbn = {9781605589077},
publisher = {Omnipress},
address = {Madison, WI, USA},
abstract = {Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an infinite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these "Stepped Sigmoid Units" are unchanged. They can be approximated efficiently by noisy, rectified linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset. Unlike binary units, rectified linear units preserve information about relative intensities as information travels through multiple layers of feature detectors.},
booktitle = {Proceedings of the 27th International Conference on International Conference on Machine Learning},
pages = {807–814},
numpages = {8},
location = {Haifa, Israel},
series = {ICML'10}
}

@InProceedings{unet,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}



@misc{diffusion,
  doi = {10.48550/ARXIV.1503.03585},
  url = {https://arxiv.org/abs/1503.03585},
  author = {Sohl-Dickstein, Jascha and Weiss, Eric A. and Maheswaranathan, Niru and Ganguli, Surya},
  keywords = {Machine Learning (cs.LG), Disordered Systems and Neural Networks (cond-mat.dis-nn), Neurons and Cognition (q-bio.NC), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Physical sciences, FOS: Physical sciences, FOS: Biological sciences, FOS: Biological sciences},
  title = {Deep Unsupervised Learning using Nonequilibrium Thermodynamics},
  publisher = {arXiv},
  year = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@article{temporal_ensembling,
  title={Temporal ensembling for semi-supervised learning},
  author={Laine, Samuli and Aila, Timo},
  journal={arXiv preprint arXiv:1610.02242},
  year={2016}
}




@inproceedings{mean_teacher,
author = {Tarvainen, Antti and Valpola, Harri},
title = {Mean Teachers Are Better Role Models: Weight-Averaged Consistency Targets Improve Semi-Supervised Deep Learning Results},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The recently proposed Temporal Ensembling has achieved state-of-the-art results in several semi-supervised learning benchmarks. It maintains an exponential moving average of label predictions on each training example, and penalizes predictions that are inconsistent with this target. However, because the targets change only once per epoch, Temporal Ensembling becomes unwieldy when learning large datasets. To overcome this problem, we propose Mean Teacher, a method that averages model weights instead of label predictions. As an additional benefit, Mean Teacher improves test accuracy and enables training with fewer labels than Temporal Ensembling. Without changing the network architecture, Mean Teacher achieves an error rate of 4.35% on SVHN with 250 labels, outperforming Temporal Ensembling trained with 1000 labels. We also show that a good network architecture is crucial to performance. Combining Mean Teacher and Residual Networks, we improve the state of the art on CIFAR-10 with 4000 labels from 10.55% to 6.28%, and on ImageNet 2012 with 10% of the labels from 35.24% to 9.11%.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {1195–1204},
numpages = {10},
location = {Long Beach, California, USA},
series = {NIPS'17}
}

@inproceedings{I-HAZE_2018,
author = {Codruta O. Ancuti and Cosmin Ancuti and Radu Timofte and Christophe De Vleeschouwer},
title = {I-HAZE: a dehazing benchmark with real hazy and haze-free indoor images},
booktitle =  {arXiv:1804.05091v1},
year = {2018}
}

@INPROCEEDINGS{AMT,
  author={Sorokin, Alexander and Forsyth, David},
  booktitle={2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops}, 
  title={Utility data annotation with Amazon Mechanical Turk}, 
  year={2008},
  volume={},
  number={},
  pages={1-8},
  doi={10.1109/CVPRW.2008.4562953}
}


@INPROCEEDINGS{dcp,
  author={Kaiming He and Jian Sun and Xiaoou Tang},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Single image haze removal using dark channel prior}, 
  year={2009},
  volume={},
  number={},
  pages={1956-1963},
  doi={10.1109/CVPR.2009.5206515}
}

@INPROCEEDINGS {cycledehaze,
author = {D. Engin and A. Genc and H. Ekenel},
booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
title = {Cycle-Dehaze: Enhanced CycleGAN for Single Image Dehazing},
year = {2018},
volume = {},
issn = {},
pages = {938-9388},
abstract = {In this paper, we present an end-to-end network, called Cycle-Dehaze, for single image dehazing problem, which does not require pairs of hazy and corresponding ground truth images for training. That is, we train the network by feeding clean and hazy images in an unpaired manner. Moreover, the proposed approach does not rely on estimation of the atmospheric scattering model parameters. Our method enhances CycleGAN formulation by combining cycle-consistency and perceptual losses in order to improve the quality of textural information recovery and generate visually better haze-free images. Typically, deep learning models for dehazing take low resolution images as input and produce low resolution outputs. However, in the NTIRE 2018 challenge on single image dehazing, high resolution images were provided. Therefore, we apply bicubic downscaling. After obtaining low-resolution outputs from the network, we utilize the Laplacian pyramid to upscale the output images to the original resolution. We conduct experiments on NYU-Depth, I-HAZE, and O-HAZE datasets. Extensive experiments demonstrate that the proposed approach improves CycleGAN method both quantitatively and qualitatively.},
keywords = {atmospheric modeling;scattering;laplace equations;image color analysis;generators;image resolution;meteorology},
doi = {10.1109/CVPRW.2018.00127},
url = {https://doi.ieeecomputersociety.org/10.1109/CVPRW.2018.00127},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jun}
}


@article{ongie2020deep,
  title={Deep learning techniques for inverse problems in imaging},
  author={Ongie, Gregory and Jalal, Ajil and Metzler, Christopher A and Baraniuk, Richard G and Dimakis, Alexandros G and Willett, Rebecca},
  journal={IEEE Journal on Selected Areas in Information Theory},
  volume={1},
  number={1},
  pages={39--56},
  year={2020},
  publisher={IEEE}
}

@inproceedings{Silberman:ECCV12,
  author    = {Nathan Silberman, Derek Hoiem, Pushmeet Kohli and Rob Fergus},
  title     = {Indoor Segmentation and Support Inference from RGBD Images},
  booktitle = {ECCV},
  year      = {2012}
}

@inproceedings{REVIDE,
    author    = {Zhang, Xinyi and Dong, Hang and Pan, Jinshan and Zhu, Chao and Tai, Ying and Wang, Chengjie and Li, Jilin and Huang, Feiyue and Wang, Fei},
    title     = {Learning To Restore Hazy Video: A New Real-World Dataset and a New Method},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {9239-9248}
}

@INPROCEEDINGS {lpips,
author = {R. Zhang and P. Isola and A. A. Efros and E. Shechtman and O. Wang},
booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
title = {The Unreasonable Effectiveness of Deep Features as a Perceptual Metric},
year = {2018},
volume = {},
issn = {},
pages = {586-595},
abstract = {While it is nearly effortless for humans to quickly assess the perceptual similarity between two images, the underlying processes are thought to be quite complex. Despite this, the most widely used perceptual metrics today, such as PSNR and SSIM, are simple, shallow functions, and fail to account for many nuances of human perception. Recently, the deep learning community has found that features of the VGG network trained on ImageNet classification has been remarkably useful as a training loss for image synthesis. But how perceptual are these so-called &quot;perceptual losses&quot;? What elements are critical for their success? To answer these questions, we introduce a new dataset of human perceptual similarity judgments. We systematically evaluate deep features across different architectures and tasks and compare them with classic metrics. We find that deep features outperform all previous metrics by large margins on our dataset. More surprisingly, this result is not restricted to ImageNet-trained VGG features, but holds across different deep architectures and levels of supervision (supervised, self-supervised, or even unsupervised). Our results suggest that perceptual similarity is an emergent property shared across deep visual representations.},
keywords = {distortion;task analysis;measurement;visualization;training;network architecture;computer architecture},
doi = {10.1109/CVPR.2018.00068},
url = {https://doi.ieeecomputersociety.org/10.1109/CVPR.2018.00068},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jun}
}

@article{lsun,
  title={Lsun: Construction of a large-scale image dataset using deep learning with humans in the loop},
  author={Yu, Fisher and Seff, Ari and Zhang, Yinda and Song, Shuran and Funkhouser, Thomas and Xiao, Jianxiong},
  journal={arXiv preprint arXiv:1506.03365},
  year={2015}
}


@inproceedings{O-HAZE_2018,
author = { Codruta O. Ancuti and Cosmin Ancuti and Radu Timofte and Christophe De Vleeschouwer},
title = {O-HAZE: a dehazing benchmark with real hazy and haze-free outdoor images},
booktitle =  {IEEE Conference on Computer Vision and Pattern Recognition, NTIRE Workshop },
series = {NTIRE CVPR'18},
year = {2018},
location = {Salt Lake City, Utah, USA},
}

@misc{ntire2020,
  doi = {10.48550/ARXIV.2005.03457},
  url = {https://arxiv.org/abs/2005.03457},
  author = {Ancuti, Codruta O. and Ancuti, Cosmin and Vasluianu, Florin-Alexandru and Timofte, Radu and Liu, Jing and Wu, Haiyan and Xie, Yuan and Qu, Yanyun and Ma, Lizhuang and Huang, Ziling and Deng, Qili and Chao, Ju-Chin and Yang, Tsung-Shan and Chen, Peng-Wen and Hsu, Po-Min and Liao, Tzu-Yi and Sun, Chung-En and Wu, Pei-Yuan and Do, Jeonghyeok and Park, Jongmin and Kim, Munchurl and Metwaly, Kareem and Li, Xuelu and Guo, Tiantong and Monga, Vishal and Yu, Mingzhao and Cherukuri, Venkateswararao and Chuang, Shiue-Yuan and Lin, Tsung-Nan and Lee, David and Chang, Jerome and Wang, Zhan-Han and Chang, Yu-Bang and Lin, Chang-Hong and Dong, Yu and Zhou, Hongyu and Kong, Xiangzhen and Das, Sourya Dipta and Dutta, Saikat and Zhao, Xuan and Ouyang, Bing and Estrada, Dennis and Wang, Meiqi and Su, Tianqi and Chen, Siyi and Sun, Bangyong and de Dravo, Vincent Whannou and Yu, Zhe and Narang, Pratik and Mehra, Aryan and Raghunath, Navaneeth and Mandal, Murari},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {NTIRE 2020 Challenge on NonHomogeneous Dehazing},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@INPROCEEDINGS{ntire2021,
  author={Ancuti, Codruta O. and Ancuti, Cosmin and Vasluianu, Florin-Alexandru and Timofte, Radu and Fu, Minghan and Liu, Huan and Yu, Yankun and Chen, Jun and Wang, Keyan and Chang, Jerome and Wang, Xiyao and Liu, Jing and Xu, Yi and Zhang, Xinjian and Zhao, Minyi and Zhou, Shuigeng and Chen, Tianyi and Fu, Jiahui and Jiang, Wentao and Gao, Chen and Liu, Si and Wang, Yudong and Guo, Jichang and Li, Chongyi and Yan, Qixin and Zheng, Sida and Zamir, Syed Waqas and Arora, Aditya and Dudhane, Akshay and Khan, Salman and Hayat, Munawar and Khan, Fahad Shahbaz and Shao, Ling and Zhang, Haichuan and Guo, Tiantong and Monga, Vishal and Yang, Wenjin and Lin, Jin and Luo, Xiaotong and Huang, Guowen and Chen, Shuxin and Qu, Yanyun and Xu, Kele and Yang, Lehan and Sun, Pengliang and Niu, Xuetong and Zheng, Junjun and Ruan, Xiaotong and Wang, Yunfeng and Yang, Jiang and Luo, Zhipeng and Wang, Sai and Xu, Zhenyu and Cao, Xiaochun and Luo, Jun and Zheng, Zhuoran and Ren, Wenqi and Wang, Tao and Chen, Yiqun and Leng, Cong and Li, Chenghua and Cheng, Jian and Sung, Chang-Sung and Chen, Jun-Cheng and Jo, Eunsung and Sim, Jae-Young and M M, Geethu and K A, Akhil and K G, Sreeni and R S, Jeena and Zacharias, Joseph and Manu, Chippy M and Huang, Zexi and Zhang, Baofeng and Zhang, Yiwen and Li, Jindong and Chen, Mianjie and Xiao, Quan and Su, Qingchao and Han, Lihua and Huang, Yanting and Prajapati, Kalpesh and Chudasama, Vishal and Patel, Heena and Sarvaiya, Anjali and Upla, Kishor and Raja, Kiran and Ramachandra, Raghavendra and Busch, Christoph and Jing, Hongyuan and Huang, Zilong and Fu, Yiran and Wu, Haoqiang and Zha, Quanxing and Zhu, Zhiwei and Lv, Hejun},
  booktitle={2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={NTIRE 2021 NonHomogeneous Dehazing Challenge Report}, 
  year={2021},
  volume={},
  number={},
  pages={627-646},
  doi={10.1109/CVPRW53098.2021.00074}
}