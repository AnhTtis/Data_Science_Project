

\section{The Dirac-Frenkel-MacLachlan principle}
\label{sect: DFMP}

In this section we consider the Schr√∂dinger equation \eqref{eqn: cNLS with psi}.
As it has been explained before, the equation consists in two parts: the linear part \eqref{eqn: cNLS with psi -- linear part}, and the nonlinear part \eqref{eqn: cNLS with psi -- nonlinear part}.
Section \ref{sect: The Harmonic Oscillator} was dedicated to solving the Harmonic oscillator, namely the linear part.
We are interested now in solving the nonlinear part, and as it is usually done for numerical simulations, we will use a splitting method.
This will allow us to solve \eqref{eqn: cNLS with psi} by solving separately \eqref{eqn: cNLS with psi -- linear part} and \eqref{eqn: cNLS with psi -- nonlinear part}, one after the other. 
By doing so, a splitting error is made, which depends on the timestep \( \Delta t \), and the order of the error depends on the specific splitting method.
It is also possible to apply high-order splitting methods.


\vspace{1em}


We focus on approximating numerically the solution to \eqref{eqn: cNLS with psi -- nonlinear part}:
\begin{equation*}
    i \partial_{t} \psi = \psi |\psi|^2
.\end{equation*}
%
We are free to use any method we want, but one has to keep in mind that Algorithm \ref{algo: HO -- exact solve} solves \eqref{eqn: cNLS with psi -- linear part} exactly when \( \psi \) is expressed under the form \eqref{eqn: generic discretization of psi -- ansatz}, i.e. as a sum of bubbles. Therefore we would like the approximate solution to \eqref{eqn: cNLS with psi -- nonlinear part} to keep this particular form. This naturally calls for the use of the Dirac-Frenkel-MacLachlan principle (abbreviated DFMP). For more details, see \cite[Sect.~3]{lasserComputingQuantumDynamics2020}. 
Let \( \mathcal{M} \) be a manifold of complex-valued Gaussian functions:
\begin{equation}
    \label{eqn: manifold for the dirac-frenkel-maclachlan principle}
    \mathcal{M} := \left\{
        u \in \mathbb{L}^2( \mathbb{R}^d ) 
        \left| \begin{aligned}
            u(x) = \sum_{j=1}^N \frac{A_j}{L_j} e^{i\gamma_j + i\beta_j \cdot (x - X_j) - \frac{2+iB_j}{4L_j^2} \left| x - X_j \right|^2} &,\\
            A_j, B_j, \gamma_j \in \mathbb{R},\, L_j \in \mathbb{R}_+^*, \, X_j, \beta_j \in \mathbb{R}^d &
        \end{aligned} \right.
    \right\}
.\end{equation}
%
We look for a function \( u \in \mathcal{M} \) that solves \eqref{eqn: cNLS with psi -- nonlinear part} on \( \mathcal{M} \). More precisely, \( u \) is defined such that its time derivative lies in the tangent space of \( \mathcal{M} \) at \( u \), \( \mathcal{T}_{u(t)} \mathcal{M} \), and such that the residual of equation \eqref{eqn: cNLS with psi -- nonlinear part} is orthogonal to the tangent space. That is, 
\begin{equation}
    \label{eqn: definition of u(t) in DFMP}
    \begin{aligned}
        &\partial_{t} u(t) \in \mathcal{T}_{u(t)} \mathcal{M}, \quad \text{ such that } \\
        &\qquad \langle f, i \partial_{t} u(t) - u(t) |u(t)|^2 \rangle = 0, \, \forall f \in \mathcal{T}_{u(t)} \mathcal{M}.
    \end{aligned}
\end{equation}

\begin{remark}
    The definition of \( \partial_{t} u(t) \) via \eqref{eqn: definition of u(t) in DFMP}, initially proposed by Dirac and Frenkel \cite{diracNoteExchangePhenomena1930,frenkelWaveMechanicsAdvanced1934}, has been later criticized by MacLachlan \cite{mclachlanVariationalSolutionTimedependent1964}. 
    He proposed an alternative approach, which would consist in minimizing the quantity
    \begin{equation*}
        \left|\left| i \partial_{t} u(t) - |u(t)|^2 u(t) \right|\right|^2
    .\end{equation*}
    %
    However, the two formulations are equivalent if the tangent space \( \mathcal{T}_{u(t)} \mathcal{M} \) is \( \mathbb{C} \)-linear \cite{broeckhoveEquivalenceTimedependentVariational1988}. 
    This is the case here because multiplying by the complex unit \( i \) simply amounts to \( \gamma_j \mapsto \gamma_j + \frac{\pi}{2}  \). 
    Therefore, the approaches by Dirac-Frenkel and MacLachlan are equivalent.
\end{remark}
%
\bigskip

Let \( B_{u(t)} \) be a basis of \( \mathcal{T}_{u(t)} \mathcal{M} \), then \eqref{eqn: definition of u(t) in DFMP} is equivalent to
\begin{equation}
    \label{eqn: definition of u(t) in DFMP -- with general basis of Tu M}
    \begin{aligned}
        &\partial_{t} u(t) \in \mathcal{T}_{u(t)} \mathcal{M}, \quad \text{ such that } \\
        &\qquad \langle f, i \partial_{t} u(t) \rangle = \langle f, u(t) |u(t)|^2 \rangle, \, \forall f \in B_{u(t)}.
    \end{aligned}
\end{equation}
%
A family (which may happen to be linearly dependent) spanning the tangent space \( \mathcal{T}_{u(t)} \mathcal{M} \) is given by 
\begin{equation}
    \label{eqn: base of Tu M in DFMP}
    \begin{aligned}
        B_{u(t)} 
        &= \left\{ e^{i\Gamma_j(y_j) - \frac{| y |^2}{2}},
                    (y_j)_1 e^{i\Gamma_j(y_j) - \frac{| y_j |^2}{2}},
                    \dots,
                    (y_j)_d e^{i\Gamma_j(y_j) - \frac{| y_j |^2}{2}},
                    |y_j|^2 e^{i\Gamma_j(y_j) - \frac{| y_j |^2}{2}}
            : j=1, \dots, N   \right\}, \\
        &=: \left\{ b_{j,1}, b_{j, 2}, \dots, b_{j, d+1}, b_{j,d+2} : j=1, \dots, N \right\},
    \end{aligned}
\end{equation}
%
where we defined
\begin{equation*}
    \Gamma_j(y_j) := \gamma_j + L_j \beta_j \cdot y_j - \frac{B_j}{4} |y_j|^2
.\end{equation*}
%


Thus, \eqref{eqn: definition of u(t) in DFMP -- with general basis of Tu M} is equivalent to 
\begin{equation}
    \label{eqn: definition of u(t) in DFMP -- with particular basis of Tu M}
    \langle i \partial_{t} u(t), b_{j, l} \rangle = \langle u |u|^2, b_{j, l}  \rangle
    , \quad j = 1, \dots, N,\quad l=1, \dots, d+2
.\end{equation}
%

The next step consists in expressing \eqref{eqn: definition of u(t) in DFMP -- with particular basis of Tu M} as a linear system involving the parameters of the bubbles and their time derivative. We then solve the linear system, which yields ODEs on the parameters that we can integrate numerically.
The main advantage of this approach is that it guarantees to keep the approximate solution of \eqref{eqn: cNLS with psi -- nonlinear part} as a sum of \( N \) bubbles.


In order to obtain the linear system, we first have to get the expression of \( i\partial_{t} u(t) \)  when \( v(y) = e^{-\frac{|y|^2}{2}} \): by summing \eqref{eqn: i dt uj} over \( j=1,\dots, N \), one has
\begin{equation}
    \label{eqn: i dt u}
    \begin{aligned}
        i \partial_{t} u
        = \sum_{j=1}^N \frac{u_j}{L_j^2} 
                &\left\{ |y_j|^2 \left( i \frac{(L_j)_s}{L_j} - \frac{B_j (L_j)_s}{2L_j} + \frac{(B_j)_s}{4} \right) \right. \\
                &\quad+ y_j \cdot \left( -L_j(\beta_j)_s + i\frac{(X_j)_s}{L_j} - \frac{B_j}{2L_j} (X_j)_s  \right) \\
                &\quad\left. + i\frac{(A_j)_s}{A_j} - i\frac{(L_j)_s}{L_j} + \beta \cdot (X_j)_s - (\gamma_j)_s \right\}.
    \end{aligned}
\end{equation}
%
More concisely, we have
\begin{equation}
    \label{eqn: i dt u -- with basis elements}
    \begin{aligned}
        i \partial_{t} u
        &= \sum_{j=1}^N \frac{A_j}{L_j^3} e^{i\Gamma_j -\frac{| y_j |^2}{2}}
            \left\{ |y_j|^2 \left( E_j^{(5)} + i E_j^{(6)}  \right) \right. \\
            &\hspace{6em}+ y_j \cdot \left( E_j^{(3)(1, \dots, d)} + iE_j^{(4)(1, \dots, d)}   \right) \\
            &\hspace{6em}\left. + \left( E_j^{(1)} + iE_j^{(2)} \right) \right\} \\
        &= \sum_{j=1}^N \frac{A_j}{L_j^3} 
            \left\{ b_{j, 1} \left( E_j^{(1)} + iE_j^{(2)} \right) + b_{j, 2} \left( E_j^{(3)(1)} + iE_j^{(4)(1)} \right) \right.\\
            &\hspace{6em}\ \, \cdots  + b_{j, d+1} \left( E_j^{(3)(d)} + iE_j^{(4)(d)} \right) + \left. b_{j, d+2} \left( E_j^{(5)} + i E_j^{(6)}  \right) \right\},
    \end{aligned}
\end{equation}
%
where
\begin{equation}
    \label{eqn: DFMP -- definition of the Ej}
    \begin{alignedat}{3}
        &E_j^{(1)} := \beta_j \cdot (X_j)_s - (\gamma_j)_s,        &\qquad& E_j^{(2)} := \frac{(A_j)_s}{A_j} - \frac{(L_j)_s}{L_j}, \\
        &E_j^{(3)(l)} := -L_j((\beta_j)_l)_s - \frac{B_j}{2L_j} ((X_j)_l)_s, &\qquad& E_j^{(4)(l)} := \frac{((X_j)_l)_s}{L_j}, \qquad l = 1, \dots, d, \\
        &E_j^{(5)} := \frac{(B_j)_s}{4} - \frac{B_j (L_j)_s}{2L_j}, &\qquad& E_j^{(6)} := \frac{(L_j)_s}{L_j},
    \end{alignedat}
\end{equation}
%
and where \( E_j^{(k)(1, \dots, d)} \) denotes the vector \( (E_j^{(k)(1)}, \dots,  E_j^{(k)(d)}) \). We recall the subscript \( {}_s \) denotes the derivative with respect to time \( s \).

According to \eqref{eqn: definition of u(t) in DFMP -- with particular basis of Tu M}, we then want to project \( i \partial_{t} u(t) \) against every element of \( B_{u(t)} \). We obtain the following linear system:
\begin{equation}
    \label{eqn: linear system for DFMP}
    \mathbf{A} \mathbf{E} = S
,\end{equation}
%
where
\begin{equation*}
    \mathbf{A} :=
    \begin{pmatrix}
        \langle b_{1, 1}, b_{1, 1} \rangle & \langle b_{1, 2}, b_{1, 1} \rangle & \dots & \langle b_{N, d+1}, b_{1, 1} \rangle & \langle b_{N, d+2}, b_{1, 1} \rangle \\
        \vdots                             &                                    &       &                                      & \vdots\\
        \langle b_{1, 1}, b_{N, d+2} \rangle & \langle b_{1, 2}, b_{N, d+2} \rangle & \dots & \langle b_{N, d+1}, b_{N, d+2} \rangle & \langle b_{N, d+2}, b_{N, d+2} \rangle \\
    \end{pmatrix} \in \mathbb{C}^{(d+2)N, (d+2)N}
,\end{equation*}
%
\begin{equation*}
    \mathbf{E} := \begin{pmatrix}
        \frac{A_1}{L_1^3} \left( E_1^{(1)} + i E_1^{(2)} \right)\\
        \frac{A_1}{L_1^3} \left( E_1^{(3)(1)} + i E_1^{(4)(1)} \right)\\
        \vdots \\
        \frac{A_1}{L_1^3} \left( E_1^{(3)(d)} + i E_1^{(4)(d)} \right)\\
        \frac{A_1}{L_1^3} \left( E_1^{(5)} + i E_1^{(6)} \right)\\
        \vdots \\
        \frac{A_j}{L_j^3} \left( E_j^{(1)} + i E_j^{(2)} \right)\\
        \frac{A_j}{L_j^3} \left( E_j^{(3)(1)} + i E_j^{(4)(1)} \right)\\
        \vdots \\
        \frac{A_j}{L_j^3} \left( E_j^{(3)(d)} + i E_j^{(4)(d)} \right)\\
        \frac{A_j}{L_j^3} \left( E_j^{(5)} + i E_j^{(6)} \right)\\
        \vdots \\
        \frac{A_N}{L_N^3} \left( E_N^{(1)} + i E_N^{(2)} \right)\\
        \frac{A_N}{L_N^3} \left( E_N^{(3)(1)} + i E_N^{(4)(1)} \right)\\
        \vdots \\
        \frac{A_N}{L_N^3} \left( E_N^{(3)(d)} + i E_N^{(4)(d)} \right)\\
        \frac{A_N}{L_N^3} \left( E_N^{(5)} + i E_N^{(6)} \right)
    \end{pmatrix} \in \mathbb{R}^{(d+2)N},
\end{equation*}
%
and 
\begin{equation*}
    \mathbf{S} := \begin{pmatrix}
        \langle u|u|^2, b_{1, 1} \rangle \\
        \vdots \\
        \langle u|u|^2, b_{N, d+2} \rangle \\
    \end{pmatrix} \in \mathbb{C}^{(d+2)N}
.\end{equation*}
%


The matrix \( \mathbf{A} \) is the Gram matrix of the family \( B_{u(t)} \), which obviously depends on time. In order to solve the linear system \eqref{eqn: linear system for DFMP} we shall use the Moore-Penrose pseudo-inverse which always exists, and which corresponds to the Least Squares solution if the matrix \( \mathbf{A}^* \mathbf{A} \) is invertible. The matrix \( \mathbf{A} \) is invertible if and only if \( B_{u(t)} \) is a linearly independent family of \( \mathbb{L}^2( \mathbb{R}^d ) \).
We can already notice that if two bubbles have the same parameters then the family will be linearly dependent: this is why the Moore-Penrose pseudo-inverse is used instead of \( \mathbf{A}^{-1} \), which is not always well-defined.


Once the linear system \eqref{eqn: linear system for DFMP} is solved, we obtain \( \mathbf{E} \), from which we can update the modulation parameters. 
In order to solve numerically the linear system, we shall rewrite it under a more convenient form. Let \( \mathbf{A}_\Re := \Re (\mathbf{A}) \), \( \mathbf{A}_\Im := \Im (\mathbf{A}) \), \( \mathbf{E}_\Re := \Re (\mathbf{E}) \), \( \mathbf{E}_\Im := \Im (\mathbf{E}) \), \( \mathbf{S}_\Re := \Re (\mathbf{S}) \), and \( \mathbf{S}_\Im := \Im (\mathbf{S}) \). Then, \eqref{eqn: linear system for DFMP} writes:
\begin{align}
    \mathbf{A} \mathbf{E} = \mathbf{S} 
    &\iff (\mathbf{A}_\Re + i \mathbf{A}_\Im)(\mathbf{E}_\Re + i \mathbf{E}_\Im) = \mathbf{S}_\Re + i \mathbf{S}_\Im \nonumber \\
    &\iff \left\{ \begin{aligned}
        \mathbf{A}_\Re \mathbf{E}_\Re - \mathbf{A}_\Im \mathbf{E}_\Im &= \mathbf{S}_\Re \\
        \mathbf{A}_\Im \mathbf{E}_\Re + \mathbf{A}_\Re \mathbf{E}_\Im &= \mathbf{S}_\Im
    \end{aligned} \right. \nonumber\\
    &\iff \begin{pmatrix}
        \mathbf{A}_\Re & - \mathbf{A}_\Im \\ 
        \mathbf{A}_\Im & \mathbf{A}_\Re
    \end{pmatrix}
    \begin{pmatrix}
        \mathbf{E}_\Re \\
        \mathbf{E}_\Im
    \end{pmatrix}
    = \begin{pmatrix}
        \mathbf{S}_\Re \\
        \mathbf{S}_\Im
    \end{pmatrix}
    \label{eqn: linear system for DFMP - real matrices}
.\end{align}
%
It is more convenient to solve \eqref{eqn: linear system for DFMP - real matrices} than \eqref{eqn: linear system for DFMP}, because we only have to deal with real matrices and vectors.

\begin{remark}
    We first tried to solve \eqref{eqn: linear system for DFMP} using the Moore-Penrose pseudo-inverse, however it yielded incomprehensible results. After some investigation, we found out that the issue seems to be the complex numbers involved, and that they do not mix well with the pseudo-inverse. The linear system \eqref{eqn: linear system for DFMP - real matrices} yields much better results.
\end{remark}

Once \eqref{eqn: linear system for DFMP - real matrices} is solved, we have to update the bubbles parameters according to \eqref{eqn: DFMP -- definition of the Ej}. The parameters of the bubbles labelled \( j \) can be updated with \( (\mathbf{E}_\Re)_k \) and \( (\mathbf{E}_\Im)_k \) for \( k = (d+2)(j-1)+1, \dots, (d+2)j \). For the sake of clarity, let 
\( \mathbf{F} := \begin{pmatrix}
    \mathbf{E}_\Re \\
    \mathbf{E}_\Im
\end{pmatrix} \).
Then 
\begin{align*}
    \frac{A_j}{L_j^3} \begin{pmatrix}
        E_j^{(1)} \\ 
        E_j^{(3)(1)} \\
        \vdots \\
        E_j^{(3)(d)} \\
        E_j^{(5)} \\
        E_j^{(2)} \\
        E_j^{(4)(1)} \\
        \vdots \\
        E_j^{(4)(d)} \\
        E_j^{(6)}
    \end{pmatrix}
    =& \begin{pmatrix}
        (\mathbf{E}_\Re)_{(d+2)(j-1)+1} \\
        (\mathbf{E}_\Re)_{(d+2)(j-1)+2} \\
        \vdots \\
        (\mathbf{E}_\Re)_{(d+2)(j-1)+d+1} \\
        (\mathbf{E}_\Re)_{(d+2)(j-1)+d+2} \\
        (\mathbf{E}_\Im)_{(d+2)(j-1)+1} \\
        (\mathbf{E}_\Im)_{(d+2)(j-1)+2} \\
        \vdots \\
        (\mathbf{E}_\Im)_{(d+2)(j-1)+d+1} \\
        (\mathbf{E}_\Im)_{(d+2)(j-1)+d+2}
    \end{pmatrix} 
    = \begin{pmatrix}
        \mathbf{F}_{(d+2)(j-1)+1} \\
        \mathbf{F}_{(d+2)(j-1)+2} \\
        \vdots\\
        \mathbf{F}_{(d+2)(j-1)+d+1} \\
        \mathbf{F}_{(d+2)(j-1)+d+2} \\
        \mathbf{F}_{(d+2)N + (d+2)(j-1)+1} \\
        \mathbf{F}_{(d+2)N + (d+2)(j-1)+2} \\
        \vdots \\
        \mathbf{F}_{(d+2)N + (d+2)(j-1)+d+1} \\
        \mathbf{F}_{(d+2)N + (d+2)(j-1)+d+2}
    \end{pmatrix}
    =: \begin{pmatrix}
        F_j^{(1)} \\
        F_j^{(3)(1)} \\
        \vdots\\
        F_j^{(3)(d)} \\
        F_j^{(5)} \\
        F_j^{(2)} \\
        F_j^{(4)(1)} \\
        \vdots\\
        F_j^{(4)(d)} \\
        F_j^{(6)}
    \end{pmatrix} \\
    %
    \iff &\begin{pmatrix}
        \beta_j\cdot (X_j)_s - (\gamma_j)_s \\
        -L_j (\beta_j)_s - \frac{B_j}{2L_j} (X_j)_s \\
        \frac{(B_j)_s}{4} - \frac{B_j (L_j)_s}{2L_j} \\
        \frac{(A_j)_s}{A_j} - \frac{(L_j)_s}{L_j} \\
        \frac{(X_j)_s}{L_j} \\
        \frac{(L_j)_s}{L_j}
    \end{pmatrix}
    = \frac{L_j^3}{A_j}
    \Re \begin{pmatrix}
        F_j^{(1)} \\
        F_j^{(3)(1, \dots, d)} \\
        F_j^{(5)} \\
        F_j^{(2)} \\
        F_j^{(4)(1, \dots, d)} \\
        F_j^{(6)}
    \end{pmatrix} 
.\end{align*}
%

Hence
\begin{equation*}
    \left\{\begin{aligned}
        &\beta_j\cdot (X_j)_s - (\gamma_j)_s = F_j^{(1)}, \\
        &-L_j (\beta_j)_s - \frac{B_j}{2L_j} (X_j)_s = F_j^{(3)(1, \dots, d)}, \\
        &\frac{(B_j)_s}{4} - \frac{B_j (L_j)_s}{2L_j} = F_j^{(5)}, \\
        &\frac{(A_j)_s}{A_j} - \frac{(L_j)_s}{L_j} = F_j^{(2)}, \\
        &\frac{(X_j)_s}{L_j} = F_j^{(4)(1, \dots, d)}, \\
        &\frac{(L_j)_s}{L_j} = F_j^{(6)},
    \end{aligned} \right.
    \iff
    \left\{ \begin{aligned}
        (A_j)_s &= A_j \left( F_j^{(2)} + F_j^{(6)} \right), \\
        (L_j)_s &= L_j F_j^{(6)}, \\
        (B_j)_s &= 4F_j^{(5)} + 2 B_j F_j^{(6)}, \\
        (X_j)_s &= L_j F_j^{(4)(1, \dots, d)}, \\
        (\beta_j)_s &= - \frac{1}{L_j} F_j^{(3)(1, \dots, d)} - \frac{B_j}{2L_j} F_j^{(4)(1, \dots, d)}, \\
        (\gamma_j)_s &= L_j \beta_j \cdot F_j^{(4)(1, \dots, d)} - F_j^{(1)},
    \end{aligned} \right.
\end{equation*}
%
and with respect to time \( t \),
\begin{equation}
    \label{eqn: DFMP -- update of parameters with interactions -- wrt time t}
    \left\{ \begin{aligned}
        (A_j)_s &= \frac{A_j}{L_j^2}  \left( F_j^{(2)} + F_j^{(6)} \right), \\
        (L_j)_s &= \frac{1}{L_j}  F_j^{(6)}, \\
        (B_j)_s &= \frac{4}{L_j^2} F_j^{(5)} + \frac{2}{L_j^2}  B_j F_j^{(6)}, \\
        (X_j)_s &= \frac{1}{L_j}  F_j^{(4)(1, \dots, d)}, \\
        (\beta_j)_s &= - \frac{1}{L_j^3} F_j^{(3)(1, \dots, d)} - \frac{B_j}{2L_j^3} F_j^{(4)(1, \dots, d)}, \\
        (\gamma_j)_s &= \frac{1}{L_j}  \beta_j \cdot F_j^{(4)(1, \dots, d)} - \frac{1}{L_j^2}  F_j^{(1)},
    \end{aligned} \right.
\end{equation}
%






\subsection{Computing coefficients of the linear system \eqref{eqn: linear system for DFMP}}


In order to be able to compute \( \mathbf{A} \) and \( \mathbf{S} \), we give the exact expression of the inner products involved. For \( j, l = 1, \dots, N \), let 
\begin{equation}
    \left |  \begin{aligned}
        z &:= \frac{2+iB_l}{4L_l^2} + \frac{2-iB_j}{4L_j^2}, \\
        a &:= \frac{X_l}{L_l^2} + \frac{X_j}{L_j^2}, \\
        \xi &:= \frac{B_j}{2L_j^2} X_j + \beta_j - \frac{B_l}{2L_l^2} X_l - \beta_l, \\
        C &= \exp\left\{i(\gamma_l - \gamma_j) - \frac{2+iB_l}{4L_l^2}  | X_l | ^2 - \frac{2-iB_j}{4L_j^2}  | X_j | ^2 - i\beta_l \cdot X_l + i\beta_j \cdot X_j \right\}.
    \end{aligned}
    \right.
\end{equation}
%
Those quantities obviously depend on the indices \( j \) and \( l \), but for clarity we do not write explicitly these dependences since they are pretty clear. Then, for \( n, m = 1, \dots, d \),
\begin{align*}
    \langle b_{l, 1}, b_{j, 1} \rangle &= C \widehat{f}(\xi) \\
    %
    \langle b_{l, n+1}, b_{j, 1} \rangle &= \frac{C}{L_l} \left( \widehat{x f}_n - (X_l)_n \widehat{f} \right)(\xi) \\
    %
    \langle b_{l, d+2}, b_{j, 1} \rangle 
    &= \frac{C}{L_l^2} \left( \widehat{ | x | ^2 f} - 2X_l \cdot \widehat{x f} +  | X_l | ^2 \widehat{f} \right)(\xi) \\
    %
    \langle b_{l, n+1}, b_{j, m+1} \rangle
    &= \frac{C}{L_j L_l} \left[ \widehat{x_n x_m f} - (X_l)_n \widehat{x_m f} - (X_j)_m \widehat{x_n f} + (X_l)_n (X_j)_m \widehat{f} \right](\xi) \\
    %
    \langle b_{l, d+2}, b_{j, m+1} \rangle &=
    \frac{C}{L_l^2 L_j} \left[ \widehat{x_m | x | ^2 f} - 2X_l \cdot \widehat{x_m x f} + | X_l | ^2 \widehat{x_m f} \right.\\
    &\hspace{1cm} \left. - (X_j)_m \widehat{ | x | ^2 f} + 2(X_j)_m X_l \cdot \widehat{x f} - | X_l | ^2 (X_j)_m \widehat{f} \right](\xi) \\
    %
    \langle b_{l, d+2}, b_{j, d+2} \rangle  &= \frac{C}{L_l^2 L_j^2} \left[ \widehat{ | x | ^4 f} - 2X_l \cdot \widehat{ | x | ^2 x f} +  | X_l | ^2 \widehat{ | x | ^2 f} - 2X_j \cdot \widehat{x | x | ^2 f} \right. \\
    &\hspace{2cm}  + 4\sum_{n, m=1}^d (X_l)_n (X_j)_m \widehat{x_n x_m f} - 2 | X_l | ^2 X_j \cdot \widehat{x f} \\
    &\hspace{2cm} \left. + \widehat{ | x | ^2 f}  | X_j | ^2 - 2 | X_j | ^2 X_l \cdot \widehat{x f} +  | X_l | ^2  | X_j | ^2 \widehat{f} \right](\xi)
\end{align*}
%
Moreover, we recall that \( \mathbf{A} \) is hermitian, so the above relations allow us to obtain all

We now compute the components of the vector \( S \). For \( j, k, l, m=1, \dots, N \), let
\begin{equation}
    \left| 
        \begin{aligned}
            C_\Im &:= \exp\left\{ i\left( \gamma_k + \gamma_l - \gamma_m - \gamma_j \right) \right\} \\
            &\hspace{1em} \times \exp\left\{ i\left(\beta_j \cdot X_j + \beta_m \cdot X_m - \beta_l\cdot X_l - \beta_k \cdot X_k \right) \right\} \\
            &\hspace{1em} \times \exp\left\{- i\left( \frac{B_k}{4L_k^2} |X_k|^2 + \frac{B_l}{4L_l^2} |X_l|^2 - \frac{B_m}{4L_m^2} |X_m|^2 - \frac{B_j}{4L_j^2} |X_j|^2  \right) \right\}, \\
            C_\Re &:= \exp\left\{-\frac{1}{2} \left( \frac{|X_k|^2}{L_k^2} + \frac{|X_l|^2}{L_l^2} + \frac{|X_m|^2}{L_m^2} + \frac{|X_j|^2}{L_j^2} \right) \right\}, \\
            C &:= \frac{A_k A_l A_m}{L_k L_l L_m} C_\Im C_\Re, \\
            \xi &:= -\left[ \beta_k + \beta_l - \beta_m - \beta_j + \frac{B_k}{2L_k^2} X_k + \frac{B_l}{2L_l^2} X_l - \frac{B_m}{2L_m^2} X_m - \frac{B_j}{2L_j^2} X_j \right], \\
            z &:= \frac{1}{2} \left( \frac{1}{L_k^2} + \frac{1}{L_l^2} + \frac{1}{L_m^2} + \frac{1}{L_j^2} \right) + i \left( \frac{B_k}{4L_k^2} + \frac{B_l}{4L_l^2} - \frac{B_m}{4L_m^2} - \frac{B_j}{4L_j^2} \right), \\
            a &:= \frac{1}{L_k^2} X_k + \frac{1}{L_l^2} X_l + \frac{1}{L_m^2} X_m + \frac{1}{L_j^2} X_j.
        \end{aligned}
    \right.
\end{equation}
%
Those quantities obviously depend on the indices \( j, k, l \) and \( m \), but for clarity we do not write explicitly these dependences since they are pretty clear. Then, for \( 1 \leq r \leq d \),
\begin{align*}
    \langle u|u|^2, b_{j, 1} \rangle &= \sum_{k,l,m} C \widehat{f}(\xi) \\
    \langle u|u|^2, b_{j, r+1} \rangle &= \sum_{k,l,n} \frac{C}{L_j} \left( \widehat{x_r f} - (X_j)_r \widehat{f} \right) \\
    \langle u|u|^2, b_{j, d+2} \rangle &= \sum_{k,l,m} \frac{C}{L_j^2} \left( \widehat{|x|^2 f} - 2X_j \cdot \widehat{xf} + |X_j|^2 \widehat{f} \right).
\end{align*}
%
We refer to Appendix \ref{appendix: populating the linear system for DFMP} for more details. Moreover, Appendix \ref{appendix: fourier transforms of gaussians} contains Table \ref{table: useful Fourier transforms} which gives the useful Fourier transforms. 




\begin{remark}[Computational complexity]
    In \eqref{eqn: generic discretization of psi -- expression for uj -  vj gaussian} we chose \( v_j(s_j, y_j) = e^{-\frac{1}{2} | y_j |^2} \).
    This choice was made so that the inner products involved in the application of the DFMP are computable exactly.
    Therefore we do not rely on numerical integration to compute the coefficients of the linear system \eqref{eqn: linear system for DFMP}. 
    In particular, this shows that the computational effort required to obtain the linear system is \( \mathcal{O}(N^4d + N^2(d+2)^2)\).
    To obtain the total complexity, we have to add the cost of computing the pseudo-inverse of the hermitian matrix \( \mathbf{A} \in \mathbb{C}^{(d+2)N, (d+2)N} \), which is \( O((d+2)^3 N^3)\).
    This yields the overall computational complexity: \( \mathcal{O}(N^4d + d^3 N^3)\).
\end{remark}




We obtain Algorithm \ref{algo: DFMP -- solve approximately cNLS} which can be used to obtain an approximate solution to \eqref{eqn: cNLS with psi} as a sum of bubbles, using the Strang splitting between the linear and nonlinear parts, and using an arbitrary explicit time-integrator for the nonlinear part.

\begin{algorithm}
    \caption{Approximating a solution to \eqref{eqn: cNLS with psi} as a sum of bubbles.}
    \label{algo: DFMP -- solve approximately cNLS}
    \begin{algorithmic}
        \For{ Each timestep of size \( dt \) } 
            \For{ \( j = 1, \dots, N \) }
            \Comment{\(j\) denotes a bubble's index.}
                \State Use Algorithm \ref{algo: HO -- exact solve} to update the bubbles over a timestep of size \( dt/2 \).
                \For{each stage of a time-integrator}
                    \State Compute the coefficients of the linear system \eqref{eqn: linear system for DFMP}.
                    \State Solve the linear system \eqref{eqn: linear system for DFMP} to obtain \( \mathbf{E} \).
                    \State Use \eqref{eqn: DFMP -- update of parameters with interactions -- wrt time t} to update the parameters over a timestep whose length depends on the stage of the time-integrator.
                \EndFor
                \State Use Algorithm \ref{algo: HO -- exact solve} to update the bubbles over a timestep of size \( dt/2 \).
            \EndFor
        \EndFor
    \end{algorithmic}
\end{algorithm}


\begin{remark}
    The error term for Algorithm \ref{algo: DFMP -- solve approximately cNLS} is of order 2 since we are using a Strang splitting. We emphasize however that the \( \mathbb{L}^2 \) norm may be better preserved: indeed, algorithm \ref{algo: DFMP -- solve approximately cNLS} is a composition of two sub-algorithms. The first one is Algorithm \ref{algo: HO -- exact solve} and preserves exactly the \( \mathbb{L}^2 \) norm, and the second sub-algorithm preserves the \( \mathbb{L}^2 \) norm up to the time-discretization error (for the conservation of \( \mathbb{L}^2 \) norm by DFMP, see Section \ref{sect: Hamiltonian and norm conservation for the interactions}). In our numerical examples we will use the 4-th order Runge-Kutta method, hence the \( \mathbb{L}^2 \) norm will be globally preserved up to some error term of order \( \Delta t^4 \).
\end{remark}



\subsection{Hamiltonian and norm conservation for the interactions}
\label{sect: Hamiltonian and norm conservation for the interactions}

When solving \eqref{eqn: cNLS with psi -- nonlinear part} via the DFMP, i.e. when solving the linear system \eqref{eqn: linear system for DFMP}, a Hamiltonian is conserved. 
\begin{lemma}
    Let \( u(t) \) be the approximation to \eqref{eqn: cNLS with psi -- nonlinear part} obtained by applying the Dirac-Frenkel-MacLachlan principle, and define
    \begin{equation*}
        H_{\textnormal{interactions}}(t) := \frac{1}{4} \langle u(t), u(t)| u(t)|^2 \rangle = \frac{1}{4} \langle u(t)^2, u(t)^2 \rangle
    .\end{equation*}
    %
    Then \( H_{\textnormal{interactions}} \) is conserved, i.e.
    \begin{equation*}
        \frac{\textnormal{d}}{\textnormal{d}t} H_{\textnormal{interactions}}(t) = 0
    ,\end{equation*}
    %
    and the \( \mathbb{L}^2 \) norm of \( u \) is also conserved.
\end{lemma}


\begin{proof}
    We have
    \begin{equation*}
        H_{\textnormal{interactions}}(t) := \frac{1}{4} \langle u(t), u(t)| u(t)|^2 \rangle = \frac{1}{4}  \langle u(t)^2, u(t)^2 \rangle
    ,\end{equation*}
    %
    by using the Hermitian property of the inner product \( \langle \cdot, \cdot \rangle \). Then,
    \begin{align*}
        \frac{\textnormal{d}}{\textnormal{d}t} H_{\textnormal{interactions}}(t)
        &= \frac{1}{4} \frac{\textnormal{d}}{\textnormal{d}t} \langle u(t)^2, u(t)^2 \rangle \\
        &= \frac{1}{4} \left\langle 2u(t) \partial_{t} u(t) , u(t)^2 \right\rangle + \frac{1}{4}  \left\langle u(t)^2, 2u(t) \partial_{t} u(t) \right\rangle \\
        &= \Re \left\langle u(t) \partial_{t} u(t) , u(t)^2 \right\rangle \\
        &= \Re \left\langle \partial_{t} u(t) , u(t) |u(t)|^2 \right\rangle.
    \end{align*}
    %
    By definition of \( \partial_{t} u(t) \), we have \( \partial_{t} u(t) \in \mathcal{T}_{u(t)} \mathcal{M} \), hence we can take \( f = \partial_{t} u(t) \) in \eqref{eqn: definition of u(t) in DFMP}. We obtain the following equality:
    \begin{equation*}
        \langle \partial_{t} u(t), u(t) |u(t)|^2 \rangle = \langle \partial_{t} u(t), i \partial_{t} u(t) \rangle = -i \| \partial_{t} u(t) \|^2
    .\end{equation*}
    %
    Therefore,
    \begin{equation*}
        \frac{\textnormal{d}}{\textnormal{d}t} H_{\textnormal{interactions}}(t) = \Re \left( -i \| \partial_{t} u(t) \|^2 \right) = 0
    .\end{equation*}
    %

    Using similar ideas, we can easily show the conservation of the \( \mathbb{L}^2 \) norm: we obviously have \( u(t) \in \mathcal{T}_{u(t)} \mathcal{M} \), hence
    \begin{align*}
        \frac{\textd}{\textd t} \|u(t)\|^2 
        &= 2\Re\langle u(t), \partial_{t} u(t) \rangle = 2 \Re \langle u(t), -i u(t)|u(t)|^2 \rangle \\
        &= 2 \Re \left( i \langle |u(t)|^2, |u(t)|^2 \rangle\right) = 0
    \end{align*}
    %
\end{proof}





\subsection{Recovering the Harmonic Oscillator equations}

Suppose the family \( B_{u(t)} \subset \mathbb{L}^2( \mathbb{R}^d ) \) defined by \eqref{eqn: base of Tu M in DFMP} is linearly independent, and consider the equation \eqref{eqn: cNLS with psi -- linear part}.
By summing equation \eqref{eqn: HO -- idt u - Hu -- with v} over \( j=1, \dots, N \) with \( v_j(s_j,y_j) = e^{-\frac{|y_j|^2}{2}} \), and letting this sum be equal to zero, we obtain an equation of the form
\begin{equation}
    \label{eqn: recovering the HO eqns -- write HO with generic coefficients in basis B}
    \sum_{j=1}^N \left( c_{j, 1} b_{j, 1} + c_{j, 2} b_{j, 2} + \dots + c_{j, d+1} b_{j, d+1} + c_{j, d+2} b_{j, d+2} \right) = 0
.\end{equation}
%
Thanks to the assumption that \( B_{u(t)} \) is a linearly independent family, we know that we must have 
\begin{equation}
    \label{eqn: recovering HO equations from DFMP -- all coeffs equal to zero}
    c_{k, 1} = c_{k, 2} = \dots = c_{k, d+1} = c_{k, d+2} = 0,\qquad k=1,\dots, (d+2)N    
.\end{equation}
%
This yields exactly the system of equations \eqref{eqn: modulation ODEs -- linear part wrt time s - with v}, with the \( \gamma \) equation replaced by \eqref{eqn: HO -- ODE on gamma}.
In other words, the DFMP approach gives the same equations as those given in Section \ref{sect: HO -- ODEs on the modulation parameters with particular vj} when \( B_{u(t)} \) is a linearly independent family. However, our approach as described in Section \ref{sect: HO -- ODEs on the modulation parameters with particular vj} allows to solve them exactly and not only numerically with some numerical time-integrator.

Finally, if the family \( B_{u(t)} \) is linearly dependent, then we cannot write equation \eqref{eqn: recovering HO equations from DFMP -- all coeffs equal to zero} anymore, hence the DFMP approach fails. Our approach avoids this issue by naturally imposing conditions \eqref{eqn: recovering HO equations from DFMP -- all coeffs equal to zero} in all cases.
