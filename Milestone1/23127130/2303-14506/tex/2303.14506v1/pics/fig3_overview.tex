

\begin{figure*}[t]
    \begin{center}
        \subfigure[Cooperation of multiple LUTs with complementary, hierarchical, and channel indexing.]{
        \includegraphics[width=0.9\textwidth]{figures/MuLUT_Framework.pdf}}

        \subfigure[Different types of the MuLUT Block in a MuLUTNet.]{
        \includegraphics[width=0.9\textwidth]{figures/MuLUTBlock.pdf}}
    \end{center}
    \caption{Overview of MuLUT. (a) With complementary, hierarchical, and channel indexing, LUTs can be constructed in a general and flexible way like neural networks. These LUTs are learned with a MuLUTNet, which is composed of multiple MuLUT blocks in a shared structure. After training, the inputs and outputs of each MuLUT block are cached into a LUT, while the computation graph is retained. (b) We design different types of MuLUT blocks to construct the learnable MuLUTNet. The convolution layer is denoted in the format of $\mathtt{kernel\_width} \times \mathtt{kernel\_height}(\mathtt{input\_channel} \rightarrow \mathtt{output\_channel})$. The connecting lines denotes the dense connection \cite{DBLP:conf/cvpr/HuangLMW17}.}
    \label{fig:overview}
\end{figure*}
