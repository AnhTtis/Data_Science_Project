\section{Cooperation of Multiple Look-Up Tables}

% \mathchardef\mhyphen="2D % Define a "math hyphen"
% \newcommand\luts{\mathop{LUT\mhyphen S}}
% \newcommand\lutd{\mathop{LUT\mhyphen D}}
% \newcommand\luty{\mathop{LUT\mhyphen Y}}
% \newcommand\lutone{\mathop{LUT\mhyphen X1}}
% \newcommand\luttwo{\mathop{LUT\mhyphen X2}}

\mathchardef\mhyphen="2D % Define a "math hyphen"
\newcommand\luts{\mathop{LUT_S}}
\newcommand\lutd{\mathop{LUT_D}}
\newcommand\luty{\mathop{LUT_Y}}
% \newcommand\lutx{\mathop{LUT_*}}
\newcommand\lutx{\mathop{LUT}} % no underscriptor

\newcommand\lutone{\mathop{LUT^{(1)}}}
\newcommand\luttwo{\mathop{LUT^{(2)}}}
\newcommand\lutN{\mathop{LUT^{(N)}}}
\newcommand\lutM{\mathop{LUT^{(M)}}}

% This observation implies that the main obstacle of inferior performance is the limitation of RF, which plays a critical role in the image super-resolution \cite{DBLP:conf/cvpr/GuD21}. 

% increasing the number of trainable parameters of the SR network (SR-LUT-Deep) or involving elaborated designs (SR-LUT-IMDN) make little help.

% \caption{Overview of MuLUT. Compared with a single LUT, MuLUT is able to greatly increase the RF size (\emph{e.g.}, from $3\times3$ to $9\times9$). The MuLUT blocks are trained end-to-end and then cached to multiple LUTs. At inference time, these parallel and cascaded LUTs are retrieved with complementary indexing and hierarchical indexing in exactly the same order as the MuLUT blocks.} 

%  with restricted input and output spatial dimensions
% As shown in Fig.~\ref{fig:overview}, the MuLUT network with 3 parallel blocks and 2 cascaded stages increases the RF size from $3 \times 3$ to $9 \times 9$ (9 times larger), while the total size of these LUTs is less than 4 times a single LUT. In contrast, the full size of a 25D LUT with an equivalent $9 \times 9$ RF size is $(2^8)^{25-4}=2^{168}$ times a 4D LUT. 

\subsection{Overview}

% From the above observation, we propose to increase the indexing capacity by cooperating multiple LUTs, thus addressing the limitation of the RF size.  To obtain multiple LUTs, we train a MuLUT network, composed of multiple elementary MuLUT blocks

Inspired by the construction of a common DNN, we treat a single LUT as an elementary component and construct multiple LUTs in the spatial, depth, and channel dimensions. Specifically, as illustrated in Fig.~\ref{fig:overview}(a), we propose three fundamental ways, \emph{i.e.}, complementary indexing, hierarchical indexing, and channel indexing, to generalize a single LUT to MuLUT, whose RF can be effectively enlarged by constructing multiple elementary components as a neural network. For clarity, we term the elementary component as a ``MuLUT Block'' and the resulting network as a ``MuLUTNet''. As shown in Fig.~\ref{fig:overview}(b), we design different types of MuLUT blocks, including two spatial-wise types and one channel-wise type. By parallelizing and cascading these MuLUT blocks, the RF of the MuLUTNet increases, while the total size of the cached LUTs grows linearly instead of exponentially. In this way, MuLUT equips with a much larger indexing capacity without introducing the enormous cost of storage and computation.

% The MuLUTNet is trained in an end-to-end manner, and the caced LUTs then share exactly the same structure as the original neural network and can be retrieved through complementary indexing, hierarchical indexing, and channel indexing. In these principled ways, we construct multiple LUTs in the spatial, depth, and channel dimensions and empower it to cache more complicated neural networks, while taking advantage of both elaborate designs of deep neural networks and the high efficiency of LUT retrieval. 

In the following sections, we will detail the proposed indexing techniques to enable the cooperation of multiple LUTs, as well as a LUT-aware finetuning strategy.

% Taking the configuration illustrated in Fig.~\ref{fig:overview} as an intuitive example
% powerful representation brought by the depth of neural networks

\subsection{Constructing LUTs Spatially}

\input{pics/fig5_gmblock.tex}

% \begin{equation}
%     \mathbf{V} = (\luts[I_{0}][I_{1}][I_{3}][I_{4}] + \lutd[I_{0}][I_{2}][I_{6}][I_{8}] + \luty[(I_{0}][I_{4}][I_{5}][I_{7}]) / 3,
% \end{equation}
% \emph{i.e.}, $\luts$, $\lutd$, and $\luty$,
% Different from the parallel filters in neural networks, \emph{e.g.} InceptionNet \cite{}, w
% Different from the variants of SR-LUT, 

\input{pics/fig6_hindex.tex}
The first cooperation in MuLUT is parallelizing LUTs with complementary indexing. For image restoration tasks, the surrounding pixels provide critical information to restore the high-frequency details, making it essential to cover as many as input pixels for restoration models. Thus, we construct multiple LUTs with different indexing patterns in parallel, which are carefully designed to complement each other. For 4D LUTs, besides the standard indexing pattern introduced in SR-LUT (named MuLUT-S here), we devise more novel indexing patterns (MuLUT-D, MuLUT-Y, MuLUT-E, MuLUT-H, and MuLUT-O), as shown in Fig.~\ref{fig:comp_index}. These patterns cover complementary pixels, for example, the indexing pixels of MuLUT-S, MuLUT-D, and MuLUT-Y are $(I_{0}, I_{1}, I_{3}, I_{4})$, $(I_{0}, I_{2}, I_{6}, I_{8})$, and $(I_{0}, I_{4}, I_{5}, I_{7})$, respectively. Our design covers the whole $5 \times 5$ area with these three types of MuLUT blocks working together. Even more pixels can be covered by further involving MuLUT-E, MuLUT-H, and MuLUT-O blocks. Correspondingly, the MuLUTNet is designed to be with multiple branches, where the parallel MuLUT blocks with complementary pixels are jointly trained. The cached LUTs are then retrieved in parallel, after which their predictions are averaged. Generally, for anchor $I_0$, the corresponding output values $V$ are obtained by
\begin{equation}
    V = \frac{\sum^{N}_{1}{\lutx[I_*]}}{N},
\end{equation}
where $N$ denotes the number of parallelized LUTs, and $LUT[\cdot]$ denotes the lookup and interpolation process in LUT retrieval, as illustrated in step 3 of Fig.~\ref{fig:srlut_recap}. 

In practice, the MuLUT-S, MuLUT-D, and MuLUT-E blocks can be implemented with standard convolutions, where the MuLUT-D block equips with an entry convolution layer with a dilation size of 2 and the MuLUT-E block with 3. But the MuLUT-Y, MuLUT-H, and MuLUT-O blocks cannot be readily implemented with standard convolutions. Thus, we propose a general implementation to support arbitrary indexing patterns, as illustrated in Fig.~\ref{fig:gmblock}. Precisely, we first unfold the input image by extracting patches with a sliding window. Then, we sample the pixels according to the specified coordinates and reshape these pixels into $1 \times 4$ vectors, which are fed into a standard convolution with a $1 \times 4$ kernel. Thus, as illustrated in Fig.~\ref{fig:overview}(b), our generalized MuLUT block supports arbitrary indexing patterns of a 4D LUT. This implementation is shared between training the generalized MuLUT block and retrieving the cached LUT. With this formulation, one can devise more spatial patterns effortlessly. In summary, with complementary indexing of parallel LUTs, more surrounding pixels are involved to better capture the local structures, which helps to restore the corresponding high-frequency details.


\subsection{Cascading LUTs in Depth}
% \begin{equation}
%     \mathbf{V} = \luttwo[\lutone[I_*]][\lutone[I_*]][\lutone[I_*]][\lutone[I_*]].
% \end{equation}

The second cooperation in MuLUT is cascading LUTs with hierarchical indexing. As illustrated in Fig.~\ref{fig:hierarch_index}~(left), with cascaded LUTs, we conduct the lookup process in a hierarchical manner. The values ($I^{(2)}_*$) in the previous LUT serve as the indexes of the following LUT. This hierarchical indexing process can be formulated as
\begin{equation}
    V = \lutM[\cdot\cdot\cdot\luttwo[\lutone[I_*]]],
\end{equation}
where $M$ denotes the number of cascaded LUTs. From the perspective of the RF, this process is similar to cascading multiple network layers in a DNN. As shown in Fig.~\ref{fig:hierarch_index} (right), cascading two stages of MuLUT blocks enlarges the RF size from $3 \times 3$ to $5 \times 5$. However, the indexes for image data are sampled and stored in the \emph{int8} data type due to LUT size constraint, while training neural networks requires gradients in the \emph{float} data type. Thus, we design a LUT re-indexing mechanism to integrate the behavior of hierarchical indexing in the learning process of the MuLUTNet. Specifically, as shown in Fig.~\ref{fig:hierarch_index}~(right), the prediction values of the previous MuLUT block are quantized to integers in the forward pass while their gradients are retained as floating-point values in the backward pass. This way, the cascaded LUTs can reproduce the performance of the cascaded MuLUT blocks. In practice, as shown in Fig.~\ref{fig:overview}(b), we adopt the dense connections \cite{DBLP:conf/cvpr/HuangLMW17} between hidden layers in the MuLUT blocks to help the convergence of the MuLUTNet with multiple cascaded stages.


% \setcounter{figure}{7}    
\input{pics/fig8_dm.tex}

% \setcounter{figure}{6}    
\input{pics/fig7_mulut_sr.tex}

% \setcounter{figure}{8}    

\subsection{Channel Interaction between LUTs}

The third cooperation in MuLUT is channel indexing. In SR-LUT, the three channels of color images are processed independently, lacking the ability to model cross-color correlations. On the other hand, in the image processing pipeline \cite{DBLP:journals/tip/MukherjeeM08,DBLP:journals/tog/MantiukDK08,DBLP:journals/pami/KimLLSLB12} and image enhancement methods \cite{DBLP:journals/pami/ZengCLCZ22,DBLP:conf/iccv/Wang0PMWSY21}, LUT is adopted to serve as a mapping operator to perform color manipulation. Here, as illustrated in Fig.~\ref{fig:overview}(a), we propose channel indexing, where channel-wise LUTs are integrated with spatial-wise LUTs to allow color channel interaction. The channel-wise LUT is learned with a channel-wise MuLUT block, as shown in Fig.~\ref{fig:overview}(b). Different from spatial-wise LUTs, channel-wise LUTs index pixels across different color channels or timestamps. A $K$ dimensional channel-wise LUT can be converted from a channel-wise MuLUT block with an entry layer of $1 \times 1$ convolution with $K$ input channels. For color image processing, we set $K$ to 3. By inserting channel-wise LUTs between spatial-wise LUTs, we empower multiple LUTs to be constructed like pseudo-3D networks \cite{DBLP:conf/iccv/QiuYM17}.



\subsection{The LUT-aware Finetuning Strategy}
Finally, we propose a finetuning strategy to improve the conversion from the learned neural network to LUTs. In SR-LUT \cite{DBLP:conf/cvpr/JoK21}, due to the constraint of storage, the indexes of a LUT are uniformly sampled to reduce the LUT size, and the nonsampled indexes are approximated with nearest neighbors. Also, an interpolation process is performed to compute final predictions from weighted LUT values during LUT retrieval. The information loss caused by nearest neighbor approximation and interpolation leads to a performance gap between the learned network and the cached LUT (see Table~\ref{tab:ft_abl}). Thus, we propose a LUT-aware finetuning strategy to address this issue. Specifically, we treat the values stored inside LUTs as trainable parameters and finetune them in a similar process to LUT re-indexing, where their forward values are quantized, and their gradients are retained as floating-point in the backward pass. After finetuning, the values inside LUTs are adapted to the sampling and interpolation process. This strategy is universal and serves as a practical improvement to bridge the performance gap between the learned network and the cached LUT for both SR-LUT and MuLUT.



\section{Applications in Image Restoration}

Following the design principles of DNN, MuLUT enables flexible and on-demand construction of multiple LUTs. In the following, we introduce different configurations of MuLUT to be applied in different image restoration tasks. The configurations are also detailed in Table~\ref{tab:config}.

% \subsection{}

% Taking the configuration illustrated in Fig.~\ref{fig:overview} as an intuitive example
% As shown in Fig.~\ref{fig:overview}, the MuLUT network with 3 parallel blocks and 2 cascaded stages increases the RF size from $3 \times 3$ to $9 \times 9$ (9 times larger), while the total size of these LUTs is less than 4 times a single LUT. In contrast, the full size of a 25D LUT with an equivalent $9 \times 9$ RF size is $(2^8)^{25-4}=2^{168}$ times a 4D LUT. 



\subsection{Super-Resolution} 

We apply MuLUT to the task of single-image super-resolution to show its advantage in enlarging RF size. Taking the configuration illustrated in Fig.~\ref{fig:mulut_sr} as an intuitive example, we construct a MuLUTNet with 2 cascaded stages, where each stage contains 3 parallel blocks with indexing patterns of ``S'', ``D'', and ``Y'', denoted as MuLUT-SDY-X2. In the second stage, we add the $\mathtt{pixelshuffle}$ operation \cite{DBLP:conf/cvpr/ShiCHTABRW16} to the output layers of MuLUT blocks to enlarge the spatial resolution, \emph{i.e.}, each record of the second stage LUT will contain 4 values for $2 \times$ super-resolution. As shown in Fig.~\ref{fig:mulut_sr}, for an anchor pixel $(x,y)$, it is replaced by 4 pixels in the HR image. MuLUT enlarges the RF from $3 \times 3$ to $9 \times 9$ (9 times larger), while the total size of these LUTs is less than 4 times a single 4D LUT (See Table~\ref{tab:runtime_sr}). In contrast, according to Eq.~\ref{eq:lut_size}, the full size of a 25D LUT with an equivalent $9 \times 9$ RF size is $(2^8)^{25-4}=2^{168}$ times a 4D LUT.

% As shown in Fig.~\ref{fig:mulut_sr}, 
% MuLUT enables the flexible design of the processing pipeline for different vision tasks. Here, we take demosaicing Bayer-patterned images as an example. 
%  Following previous work \cite{DBLP:conf/cvpr/JoK21}, we process three color channels independently for the super-resolution task.


\input{tables/config_table.tex}
\input{tables/energy_table.tex}


\input{tables/comp_table.tex}

\input{pics/fig9_sr_tradeoff.tex}

\subsection{Demosaicing} 

We further show the generalization ability of MuLUT on the task of demosaicing Bayer-patterned images. Image demosaicing can be viewed as a super-resolution problem with a particular color pattern. However, there are grave obstacles to adopting SR-LUT for this task. Two single-LUT baseline solutions are shown in Fig.~\ref{fig:dm}(a) and Fig.~\ref{fig:dm}(b), respectively. In Baseline-A, pixels in a $2 \times 2$ Bayer pattern block are treated as four independent channels, which are processed separately, and then the two green channels are averaged. However, this solution suffers from a subpixel shift of center points due to the misalignment between the HR pixels and the Bayer-patterned sampled ones. In Baseline-B, at a stride of $2$, the $2 \times 2 \times 1$ Bayer-patterned blocks are upsampled into $2 \times 2 \times 3$ colored patches directly. But the limited RF of a single LUT fails to capture the inter-block correlation. In contrast, MuLUT is easy to be adapted to the characteristics of Bayer-patterned images. As shown in Fig.~\ref{fig:dm}(c), MuLUT resembles three color channels like Baseline-B in the first stage, and then integrates the surrounding pixels with three indexing patterns in the second stage. Finally, a channel-wise MuLUT block is cascaded to apply tone mapping between color channels. We denote this configuration of MuLUT as MuLUT-SDY-X2-C, where ``-C'' denotes MuLUT with channel indexing. This multi-stage and multi-branch structure, enabled by the cooperation of multiple LUTs, addresses the above obstacles of adapting LUT to the task of image demosaicing, showing the versatility of MuLUT.



\subsection{Denoising and Deblocking}

%     \end{figure*}
For grayscale image denoising, the pipeline of MuLUT is similar to super-resolution. The difference is that the $\mathtt{pixelshuffle}$ operations in all MuLUT blocks are removed, since there is no need to change the resolution of the input image. This pipeline can be adapted to other grayscale image processing tasks, \emph{e.g.}, grayscale image deblocking, where the spatial resolution is not changed after processing. We apply a configuration of MuLUT with two cascaded stages, where each stage contains all proposed indexing patterns (``S'', ``D'', ``Y'', ``E'', ``H'', and ``O''). We denote this configuration as MuLUT-SDYEHO-X2.

% For grayscale image deblocking, we keep the pipeline as grayscale image denoising.

For color image denoising, we adopt a pipeline like the one illustrated in Fig.~\ref{fig:overview}(a), where a channel-wise MuLUT block is inserted between cascaded stages. The three color channels are processed with different spatial-wise LUTs and then concatenated together. After processed across channels with channel-wise LUTs, the image can be further processed by another group of spatial-wise LUTs. Finally, the restored image is obtained by concatenating three color channels again. This pipeline can be adapted to other color image processing tasks as well as video processing tasks. Following the configuration used in grayscale image denoising, we denote the configuration of MuLUT for color image denoising as MuLUT-SDYEHO-X2-C.
