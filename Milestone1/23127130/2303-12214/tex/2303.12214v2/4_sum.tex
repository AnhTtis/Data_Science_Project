\section{Conclusion}
In this work, we introduced a new framework, Prompt-MIL, which combines the use of Multiple Instance Learning (MIL) with prompts to improve the performance of WSI classification.  Prompt-MIL adopts a prompt tuning mechanism rather than a conventional full fine-tuning of the entire feature representation. In such a scheme, only a small fraction of parameters calibrates the pretrained representations to encode task-specific information, so the entire training can be performed in an end-to-end manner. 
We applied our proposed method to three publicly available datasets.
Extensive experiments demonstrated the superiority of Prompt-MIL over the conventional MIL as well as the conventional fully fine-tuning methods.
Moreover, by fine-tuning much fewer parameters compared to fully fine-tuning, our method is GPU memory efficient and fast.
Our proposed approach also showed promising potentials in transferring foundation models. 
We will further explore the task-specific features that are captured by our prompt toward explainability of these models.