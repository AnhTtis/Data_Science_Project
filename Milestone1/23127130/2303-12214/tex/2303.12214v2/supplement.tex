% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{url}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{makecell}

\usepackage{times}
\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{booktabs}
\usepackage{tablefootnote}
\usepackage{color}

\newcommand{\hl}[1]{\textcolor{red}{{[PP: #1]}}}
\newcommand{\hll}[1]{\textcolor{green}{{[LZ: #1]}}}
\newcommand{\myparagraph}[1]{\smallskip\noindent\textbf{#1}}
\newcommand\myeq{\mathrel{\overset{\makebox[0pt]{\mbox{\normalfont\tiny\sffamily def}}}{=}}}

\usepackage{flafter}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}
\begin{document}
%
\title{Supplementary Material of \\ Prompt-MIL: Boosting Multi-Instance Learning Schemes via Task-specific Prompt Tuning}


\titlerunning{}

\author{}
\authorrunning{}
\institute{}
\maketitle              % typeset the header of the

\begin{table}[h]
\caption{Comparison of accuracy and AUROC between the conventional MIL model and fine-tuning the last Transfromer encoder ($L_{12}$ in ViT-T), using various MIL schemes. ``Num. of Parameters'' represents the number of optimized parameters.}
\label{table:sup:mil}
\begin{center}
\setlength{\tabcolsep}{0.9mm}{

\begin{tabular}{c | l | c c c c |c}
\toprule
\multicolumn{1}{c|}{MIL scheme} 
&\multicolumn{1}{c|}{Method} 
        & \multicolumn{2}{c}{TCGA-CRC}
            & \multicolumn{2}{c}{BRIGHT}
    & \multicolumn{1}{|c}{Num. of}
\\
% \midrule
&\multicolumn{1}{c|}{} 
        & \multicolumn{1}{c}{Accuracy} & \multicolumn{1}{c}{AUROC}
            & \multicolumn{1}{c}{Accuracy} & \multicolumn{1}{c}{AUROC}
    & \multicolumn{1}{|c}{Parameters} 
\\
\midrule
&Conventional MIL 
        & $73.02$         & $69.24$
            & $62.08$         & $80.96$
    & 64k
\\
DSMIL~\cite{li2021dual_dsmil} & Fine-tuning $L_{12}$
        & 69.81  & 70.72
            & 61.25 & 80.10
    & 509k
\\ 
&Prompt-MIL (ours) 
        & $\bm{75.47}$  & $\bm{75.45}$ 
            & $\bm{64.58}$  & $\bm{81.31}$ 
            
    & 64k+192
\\
\midrule
&Conventional MIL 
        & $74.10$         & $68.56$
            & $61.25$         & $\bm{80.35}$
    & 25k
\\
ABMIL~\cite{ilse2018attention_abmil} & Fine-tuning $L_{12}$
        & 70.37  &  $\bm{70.78}$
            & $\bm{62.50}$ & 78.92
    & 470k
\\ 
&Prompt-MIL (ours) 
        & $\bm{75.87}$  & $\bm{70.10}$ 
            & $\bm{62.50}$  & $79.30$ 
            
    & 25k+192
\\
\midrule
&Conventional MIL 
        & $75.87$         & $77.50$
            & $62.08$         & $82.97$
    & 59k
\\
CLAM~\cite{lu2021data_clam} &Fine-tuning $L_{12}$
        &  74.07 & $71.40$ 
            & 63.33  & 81.32
    & 504k
\\ 
&Prompt-MIL (ours) 
        & $\bm{76.19}$  & $\bm{80.84}$ 
            & $\bm{64.17}$  & $\bm{84.31}$ 
            
    & 59k+192
\\
% \midrule
% &Conventional MIL 
%         & $76.38$         & $77.67$
%             & $60.00$         & $79.54$
%     & 
% \\
% TransMIL~\cite{shao2021transmil} &Full fine-tuning 
%         &  & 
%             &  & 
%     & 
% \\ 
% &Prompt-MIL (ours) 
%         & $\bm{*}$  & $\bm{*}$ 
%             & $\bm{*}$  & $\bm{*}$ 
            
%     & 
% \\
\bottomrule
\end{tabular}
}
\end{center}
\end{table}

\begin{table}[hb]
\caption{Comparison of accuracy and AUROC on TCGA-BRCA and BRIGHT between the baseline ViT-small model and the same model fine-tuned by our Prompt-MIL. The baseline ViT-small model is a pathological foundation model, which was pretrained using DINO and the entire TCGA dataset~\cite{chen2022scaling_hipt}. It is a different model from the one in the main paper.}
\label{table:result:universal_models}
\begin{center}
\setlength{\tabcolsep}{1.6mm}{
\begin{tabular}{l c c  c c }
\toprule
\multicolumn{1}{c}{Dataset} 
    & \multicolumn{2}{c}{TCGA-BRCA} 
        % & \multicolumn{2}{c}{TCGA-CRC} 
            & \multicolumn{2}{c}{BRIGHT} \\
% \midrule
\multicolumn{1}{c}{Metric} 
& \multicolumn{1}{c}{Accuracy} & \multicolumn{1}{c}{AUROC} 
% & \multicolumn{1}{c}{Accuracy} & \multicolumn{1}{c}{AUROC} 
& \multicolumn{1}{c}{Accuracy} & \multicolumn{1}{c}{AUROC}  \\
\midrule
ViT-small in ~\cite{chen2022scaling_hipt}
    & $88.49$          & $90.69$  
        % & $ $          & $ $       
            & $56.25$  & $73.69$ \\
ViT-small w/ Prompt-MIL
    & $\bm{92.00} $ & $\bm{95.65}$
        % & $\bm{} $ & $\bm{}$
            & $\bm{60.00}$  & $\bm{75.79}$ \\
\bottomrule
\end{tabular}
}
\end{center}
\end{table}

\begin{figure}[t]
\begin{center}
%\fbox{\rule{0pt}{2in} \rule{.9\linewidth}{0pt}}
\includegraphics[width=\linewidth]{imgs/vis.png}
\end{center}
   \caption{(a) The attention visualization of the classifier $G(\cdot)$. Compared to that in the conventional MIL, the attention map of our Prompt-MIL focused more on the tumor regions which are critical for the cancer classification task. (b) The attention visualization of the last multi-head self-attention layer in the feature model $F(\cdot)$. The prompt token guided the attention to cover more on the tumor regions.}
\label{fig:vis}
\end{figure}
% The attention values were re-scaled for better visualization.

% \begin{figure}[h]
% \begin{center}
% %\fbox{\rule{0pt}{2in} \rule{.9\linewidth}{0pt}}
% \includegraphics[width=0.5
% \linewidth]{imgs/vis_patch.png}
% \end{center}
%    \caption{(a)Attention visualization of the last multi-head self-attention in the feature model $F(\cdot)$. The prompt token guided attention scattered more on task-specific regions.}
% \label{fig:vis}
% \end{figure}

% \clearpage
\vspace{0.8\baselineskip}
\bibliographystyle{splncs04}
\bibliography{supplement.bib}
\end{document}
