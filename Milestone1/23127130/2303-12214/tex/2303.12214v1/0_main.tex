% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
\usepackage{color}
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\usepackage{times}
\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{booktabs}
\usepackage{tablefootnote}
\usepackage{color}


\newcommand{\ceil}[1]{\lceil {#1} \rceil}
\usepackage{tikz}
\usepackage{pifont}
            
\newcommand{\KM}[1]{{\color{red} \textbf{KM}: #1}}
\newcommand{\JZ}[1]{{\color{blue} \textbf{JZ}: #1}}
% \newcommand{\JZ}[1]{#1}
\newcommand{\PP}[1]{{\color{cyan} \textbf{PP}: #1}}
\newcommand{\MV}[1]{{\color{magenta} \textbf{MV}: #1}}

\newcommand{\resultsection}[1]{\noindent\textbf{{#1}}}
% \newcommand{\resultsection}[1]{\paragraphdata{#1}}
\newcommand{\datasection}[1]{\textbf{#1}}
% \newcommand{\datasection}[1]{\paragraphdata{#1}}

\newcommand{\vspaceadj}{\vspace{0.8\baselineskip}}

%
\begin{document}
%
\title{Prompt-MIL: Boosting Multi-Instance Learning Schemes via Task-specific Prompt Tuning}
% Prompt-MIL: Boosting Multi-Instance Learning Schemes for Whole Slide Image Classification
%
\titlerunning{Prompt-MIL: Boosting MIL Schemes via Prompt Tuning}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Jingwei Zhang\inst{1} \and
Saarthak Kapse\inst{1} \and Ke Ma \inst{2} \and Prateek Prasanna\inst{1} \and
Joel Saltz\inst{1} \and Maria Vakalopoulou\inst{3} 
\and Dimitris Samaras\inst{1}}
%
\authorrunning{F. Author et al.}
% % First names are abbreviated in the running head.
% % If there are more than two authors, 'et al.' is used.
% %
\institute{
    Stony Brook University, USA \and Snap Inc., USA
        \and
        CentraleSup√©lec, University of Paris-Saclay, France\\
    \email{\email{\{jingwezhang, kemma, samaras\}@cs.stonybrook.edu}} \\
    \email{\{saarthak.kapse, prateek.prasanna\}@stonybrook.edu} \\
    \email{Joel.Saltz@stonybrookmedicine.edu   maria.vakalopoulou@centralesupelec.fr}
}

% \author{Anonymous}
% \authorrunning{Anonymous et al.}
% \institute{Anonymous Organization\\
% { \email{**@******.***} } }

%%%% llncs was modified by adding paragraphdata

%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
Whole slide image (WSI) classification is a critical task in computational pathology, requiring the processing of gigapixel-sized images, which is challenging for current deep-learning methods. 
Current state of the art methods are based on multi-instance learning schemes (MIL), which usually rely on pretrained features to represent the instances. 
Due to the lack of task-specific annotated data, these features are either obtained from well-established backbones on natural images, or, more recently from self-supervised models pretrained on histopathology. 
However, both approaches yield task-agnostic features, resulting in performance loss compared to the appropriate task-related supervision, if available.
In this paper, we show that when task-specific annotations are limited, we can inject such supervision into downstream task training, to reduce the gap between fully task-tuned and task agnostic features. 
We propose Prompt-MIL, an MIL framework that integrates prompts into WSI classification. 
Prompt-MIL adopts a prompt tuning mechanism, where only a small fraction of parameters calibrates the pretrained features to encode task-specific information, rather than the conventional full fine-tuning approaches.
Extensive experiments on three WSI datasets, TCGA-BRCA, TCGA-CRC, and BRIGHT, demonstrate the superiority of Prompt-MIL over conventional MIL methods, achieving a relative improvement of 1.49\%-4.03\% in accuracy and 0.25\%-8.97\% in AUROC while using fewer than 0.3\% additional parameters. 
Compared to conventional full fine-tuning approaches, we fine-tune less than 1.3\% of the parameters, yet achieve a relative improvement of 1.29\%-13.61\% in accuracy and 3.22\%-27.18\% in AUROC and reduce GPU memory consumption by 38\%-45\% while training 21\%-27\% faster.


\keywords{Whole slide image classification  \and Multiple instance
learning \and Prompt tuning.}
\end{abstract}
%
%
%

\input{1_intro}
\input{2_method}
\input{3_exp}
\input{4_sum}

% \subsubsection{Acknowledgements} Please place your acknowledgments at
% the end of the paper, preceded by an unnumbered run-in heading (i.e.
% 3rd-level heading).


%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
\bibliographystyle{splncs04}
\bibliography{bibliography}
%
\end{document}
