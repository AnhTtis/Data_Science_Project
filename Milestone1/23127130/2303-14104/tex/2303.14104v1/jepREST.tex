% !TeX spellcheck = pt_PT 
% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage[portuguese]{babel}
\usepackage{listings}
\lstset{
  basicstyle=\footnotesize\ttfamily,
}
\usepackage{fancyvrb}
\fvset{%
fontsize=\small,
numbers=left
}

% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}
%Removes page number
\pagenumbering{gobble}
%Removes page header
\pagestyle{plain}

\title{JepREST: Teste Funcional de Aplicações REST Distribuídas}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Sara Simões, Ana Ribeiro, Carla Ferreira e Nuno Preguiça}
\authorrunning{S. Simões, A. Ribeiro, C. Ferreira, N. Preguiça}
\institute{Faculdade de Ciências e Tecnologia da Universidade Nova de Lisboa}
%\and
%\email{sp.simoes@campus.fct.unl.pt}
%\and
%\email{acm.ribeiro@campus.fct.unl.pt}
%\and
%\email{carla.ferreira@fct.unl.pt}
%\and
%\email{nuno.preguica@fct.unl.pt}

\maketitle  
% typeset the header of the contribution
%
%\vspace{-0.4cm}
\begin{abstract}
As aplicações móveis e Web são frequentemente suportadas
por serviços aplicacionais com interface REST, 
implementados usando um conjunto de componentes 
distribuídos que interagem entre si. 
Esta aproximação permite que os serviços apresentem 
elevada disponibilidade e desempenho, a um custo inferior 
ao de um sistema monolítico. 
Porém, a existência de múltiplos componentes torna o 
processo de desenvolvimento destes sistemas mais complexo 
e por isso, suscetível à existência de erros.
Neste trabalho apresentamos o JepREST, um sistema
que permite automatizar a utilização das bibliotecas
Jepsen para testar a correção de aplicações distribuídas
que fornecem uma interface REST. 
A partir de uma especificação da interface do 
serviço, o JepREST gera e executa um conjunto de 
testes com múltiplos clientes a efetuarem operações 
concorrentemente, verificando posteriormente se o 
comportamento do sistema é linearizável. 
A avaliação preliminar efetuada mostra que o
JepREST permite simplificar o teste de aplicações REST. 
%\vspace{-0.3cm}
%\keywords{
%    Sistemas Distribuídos
%    \and
%    Correção
%    \and
%    Jepsen
%    \and
%    Aplicações REST
%    \and
%    Verificação
%}
\end{abstract}
%\vspace{-1cm}
\section{Introdução}
%Com o aumento da utilização de APIs que contêm um estilo arquitetural REST, tornou-se importante para os \textit{developers} e programadores realizares testes nestas APIs. 
%O teste a uma aplicação REST é um processo que se concentra em determinar se a API foi desenvolvida de forma a cumprir os termos previstos de funcionalidade, desempenho, confiabilidade e segurança. 
%(INTRODUCAO) - explicar q se tem de testar pq sao mais usadas, o q e q e pq e importante
%\vspace{-0.3cm}
%Introdução é sempre Contexto, Motivação, Contribuições

As aplicações móveis e Web são frequentemente implementadas utilizando 
serviços aplicacionais de suporte que executam a lógica da aplicação e mantêm o seu estado, 
fornecendo uma interface REST usadas pelos clientes para executar operações na aplicação.
Em aplicações não triviais, estes serviços 
aplicacionais 
são sistemas distribuídos complexos,
compostos por vários componentes, incluindo serviço de \textit{cache} aplicacionais (e.g., Memcached, Redis),
serviços de disseminação de eventos (e.g. Kafka), bases de dados e serviços de armazenamento 
de dados replicados.

A complexidade destes sistemas advém do objetivo de permitir um elevado desempenho, disponibilidade e
tolerância a falhas. Em consequência, estes sistemas tornam-se também difíceis de desenhar e programar,
sendo suscetíveis à ocorrência de erros. 
Assim, a validação e teste de sistemas aplicacionais é
um problema importante e o teste de aplicações distribuídas complexas tem atraído a atenção 
da comunidade de investigação e da indústria~\cite{netflix,jepsenElleGitHub,Alvaro17Abstracting}. 

Existem várias ferramentas para testar serviços REST~\cite{load_testing_tools}, em particular ferramentas que permitem executar testes de carga, avaliando o desempenho dos serviços REST. 
Algumas destas ferramentas (e.g. Artillery~\cite{artillery-docs}) permitem efetuar testes funcionais, nos quais se verifica se os serviços se comportam de acordo com o esperado. 
No entanto, o suporte para efetuar testes funcionais é limitado e complexo. Primeiro, deve ser o utilizador da ferramenta a especificar o resultado esperado da execução de uma operação. Se é possível fazê-lo em testes simples, torna-se  difícil ou mesmo impossível fazê-lo em testes aleatórios e que envolvam a execução concorrente de operações. 
Segundo, estas ferramentas não têm mecanismos para perturbar a execução dos componentes do serviço, testando o comportamento do sistema em situações em que ocorram falhas. 
Assim, tem sido realçada a necessidade de criar aplicações que simplifiquem a criação de testes de aplicações distribuídas~\cite{Alvaro17Abstracting}.

Este artigo apresenta o JepREST, um sistema para simplificar 
o teste de aplicações distribuídas com interfaces REST, cujo objetivo é analisar a correção de uma aplicação REST quando a mesma é submetida a um conjunto de testes funcionais, onde existem múltiplos clientes a executarem pedidos concorrentes, podendo ocorrer falhas nos vários componentes da aplicação em estudo.

O JepREST é constituído por quatro componentes.
O primeiro componente gera, a partir da especificação do serviço REST, 
o código para invocar operações no serviço REST. 
O segundo componente gera o código para a execução de cargas
de trabalhos definidas pelo programador, incluindo o código para a criação de novos objetos na aplicação. 
O terceiro componente executa os testes, controlando a execução da 
aplicação REST e dos clientes de teste do serviço. 
O último componente verifica se a execução corresponde a um comportamento
correto da aplicação REST, definido como uma execução que seja linearizável~\cite{linearizability}, i.e., verifica-se que, se todas operações que foram efetuadas com sucesso durante a execução ocorreram atomicamente, segundo a ordem de tempo real, e.g. se uma operação A for concluída antes do início de uma operação B, então a execução de A deve sempre preceder à execução de B, ou seja, a execução de B deve sempre observar os efeitos da execução de A.
O JepREST pode ser visto como um sistema que permite simplificar a utilização do Jepsen\cite{jepsenwebsite}, uma biblioteca construída para analisar a correção de sistemas distribuídos, no teste de aplicações REST. 
No desenho do JepREST foi necessário endereçar múltiplos desafios, incluindo 
como construir automaticamente o código necessário para a execução dos testes a partir da especificação da interface REST, incluindo a criação de novos objetos e como definir o modelo necessário à verificação da correção da execução.

O JepREST está ainda em desenvolvimento, com a versão atual suportando apenas o teste de aplicações a correrem num único servidor onde as operações seguem a semântica \textit{standard} do REST. As experiências preliminares 
efetuadas permitiram verificar que o sistema consegue detetar um 
conjunto alargado de violações da correção. 

O resto do artigo,
a secção~\ref{related_work} discute o trabalho relacionado;
a secção~\ref{background} introduz as bibliotecas usadas pelo JepREST;
a secção~\ref{system} descreve o sistema;
a secção~\ref{eval} apresenta os testes efetuados e a 
secção~\ref{conclusion} conclui o artigo.

\section{Trabalho Relacionado}\label{related_work}

A verificação da correção de um sistema distribuído é um processo complexo, devido a vários fatores, entre os quais
o funcionamento descentralizado do sistema, com os componentes a executarem ações independentes, 
a concorrência das ações executadas em diferentes componentes e em cada componente e as falhas parciais que podem 
ocorrer nas comunicações e nos próprios componentes. 
Nos testes de \textit{software} é possível decompor a verificação num conjunto de etapas~\cite{nidhra2012black}. 
Os testes unitários pretendem verificar a correção de cada componente isoladamente.
Os testes de integração pretendem verificar a correção da integração de múltiplos componentes distribuídos, podendo-se 
considerar componentes a executar na mesma máquina física ou em diferentes máquinas.
Os testes funcionais pretendem verificar que o sistema como um todo funciona de forma correta, i.e., de acordo com a especificação. 

Para que os testes funcionais dum sistema distribuído sejam significativos é necessário considerar vários fatores.
Por um lado, simular cargas de trabalho que correspondam às utilizações esperadas e a casos limites
de utilização do sistema. Por outro lado, é necessário considerar o modelo de falhas definido para o sistema,
i.e., quais as falhas que o sistema deve conseguir tolerar, simulando-as de forma a verificar que o sistema 
consegue efetivamente tolerar estas falhas.  

Múltiplos trabalhos abordam a problemática da introdução de falhas em sistemas distribuídos, incluindo a injeção de falhas nos componentes~\cite{faultsee,Natella16Assessing,Madeira00Emulation} e nas 
comunicações~\cite{nftape}. Estes trabalhos são complementares ao nosso e poderiam ser utilizados para simular falhas durante a execução dos testes.

Existem igualmente vários sistemas para a execução de testes de carga~\cite{jiang2008automatic}, que permitem avaliar 
propriedades não funcionais, como latência, desempenho e escalabilidade de aplicações distribuídas. 

\textbf{Testes de APIs REST}
Existem múltiplas ferramentas e bibliotecas que podem ser usadas para testar serviços com APIs REST.
O cURL~\cite{curl} fornece uma biblioteca que permite efetuar chamadas que sejam feitas sobre HTTP e pode ser utilizado na construção de aplicações de teste. Aplicações como o Postman~\cite{postman} e o SoapUI~\cite{soapui} 
permitem criar \textit{scripts} para testar APIs REST, definindo a sequência de operações que devem ser invocadas, assim como o resultado esperado. No entanto, nenhuma destas ferramentas permite efetuar pedidos concorrentes. 

O Dredd~\cite{dredd} permite gerar testes a partir de uma descrição da API, no formato \textit{API Blueprint} ou \textit{Swagger},
simplificando o processo de teste. No entanto, a análise dos resultados limita-se a confirmar se os mesmos estão de acordo com o formato esperado, não lidando com possíveis pedidos concorrentes nem verificando a correção do conteúdo da resposta.

O ReqBin~\cite{reqbin} é uma ferramenta \textit{online} que permite testar serviços REST e suporta a execução de pedidos concorrentes a partir de múltiplas localizações geográficas. Contudo, não suporta a análise da \mbox{correção dos resultados obtidos.} 

Existem várias ferramentas que permitem efetuar testes de carga a serviços REST~\cite{JMeter,Locust,Taurus,artillery-docs}.
Nestas aplicações os programadores especificam os testes a efetuar, indicando a sequência de operações que devem ser executadas e
a frequência relativa de cada sequência. As ferramentas executam os testes, simulando múltiplos clientes concorrentes que
executam as várias operações definidas. Em geral, os programadores podem definir qual o resultado esperado depois duma invocação, 
mas esta funcionalidade é difícil de utilizar numa situação em que o resultado dependa de operações executadas anteriormente
e que possa ser influenciado por eventuais operações concorrentes.
%poderia fazer a diferença com cada ferramenta - se tiver espaço, mas o principal é isto a verificação e a introdução de falhas
O nosso trabalho difere destas ferramentas em vários pontos, em particular no suporte à verificação da correção dos 
resultados, o qual é feito usando a biblioteca Knossos~\cite{jepsenKnossosGitHub} e na possibilidade de introduzir vários tipos de falhas nos vários componentes da aplicação.

Outros trabalhos abordaram a verificação da correção de serviços Web existentes~\cite{Freitas16Characterizing} e de bases 
de dados~\cite{cobra}. Ao contrário destes, o nosso trabalho foca-se no teste de sistemas distribuídos genéricos que apresentam interfaces REST.

\section{Contexto}\label{background}

Nesta secção apresenta-se o contexto em que o trabalho foi realizado, incluindo as bibliotecas usadas na construção do JepREST.

%\begin{table}[t]
 %   \centering
  %  \renewcommand{\arraystretch}{1.2}
   % \begin{tabular}{l|l}
%Anotação     & Descrição                     \\\hline
%\texttt{@Operation}             &  Descreve uma operação ou um método HTTP com um \textit{path} específico\\
%\texttt{@Parameter}             &  Representa um parâmetro único numa operação\\
%\texttt{@RequestBody}            &   Representa o corpo do pedido numa operação\\
%\texttt{@ApiResponse}            &  Representa uma resposta numa operação\\
%\texttt{@Tag}            &  Representa as \textit{tags} de uma operação ou de uma definição do OpenAPI\\
%\texttt{@Link}            &  Representa um possível link de uma resposta\\ 
%\texttt{@Schema}            &  Permite definir os dados de \textit{input} e \textit{output} \\ 
%\texttt{@Content}            &  Fornece um esquema e exemplos para um tipo de dados específico\\ 
%\end{tabular}
%\caption{Exemplos de algumas anotações oferecidas pelo OpenAPI}
%\label{tab:tabelaOpenAPI}
%\vspace{-0.4cm}
%\end{table}


\noindent 
\textbf{Especificação OpenAPI}
(OAS)~\cite{openAPI} define uma forma de especificar um serviço web RESTful de forma independente da linguagem utilizada para desenvolver o serviço.
Esta especificação permite, usando um conjunto de anotações,
indicar quais as operações do serviço, quais os parâmetros e resultados destas operações, incluindo o esquema dos objetos manipulados e ligações entre atributos de diferentes objetos, entre outras informações.

Existem ferramentas que permitem transformar uma especificação OpenAPI em especificações utilizadas em diferentes linguagens, como o JAX-RS usado em Java, e vice-versa, simplificando a geração da especificação OpenAPI a partir de uma implementação existente.

\noindent 
\textbf{PETIT}
O PETIT~\cite{tese} é uma ferramenta de teste de microserviços, que utiliza uma especificação OpenAPI estendida com a possibilidade de definir invariantes sobre os dados e pré e pós-condições
para a execução das operações, usando lógica de primeira ordem. 
Para além de realizar pedidos à API dos serviços e avaliar os resultados obtidos, o PETIT permite gerar dados relevantes para os testes, de acordo com os esquemas definidos no documento da especificação.

\noindent 
\textbf{Jepsen}
\label{related_work:jepsen}
%
O Jepsen \cite{jepsenwebsite} é uma biblioteca em clojure utilizada na criação de programas para testar a correção de sistemas distribuídos, 
em particular de bases de dados.
%
O teste de uma base de dados distribuída usando o Jepsen é feito em ambiente Docker, com o programa de teste a executar num \textit{container} e a base de dados a executar em múltiplos outros \textit{containers}.

O programa de teste executa diversos clientes da base de dados concorrentemente, os quais executam a sequência de 
operações indicadas pelo \textit{thread} que coordena os testes. Durante o teste, podem ser injetadas no sistema um conjunto de 
falhas, sendo que o conjunto de operações e o conjunto de falhas são ambos definidos pelo programador.

Durante a execução de um teste é armazenada a história~\cite{consistency} da execução, que inclui as operações executadas e o resultado obtido. O Jepsen fornece duas ferramentas, o Knossos e o Elle~\cite{jepsenElleGitHub}, para verificar a correção da execução.
%Penso que o Knossos e o Elle estão weirds - penso que aqui é que devo adicionar o que é que o Knossos faz em mais detalhe para saber o que raio é que o JepRest considera um comportamento correto ou um comportamento incorreto
O Knossos verifica se uma história é linearizável com base num modelo do sistema, que inclui a definição do 
comportamento das operações e do estado do sistema. Enquanto o Knossos analisa as operações de forma individual, 
o Elle permite estender a validação da correção da história à execução de transações compostas por múltiplas operações.

\textbf{Faker} 
O Faker~\cite{faker} é uma biblioteca que permite gerar dados realistas, que podem ser utilizados no processo de teste, em grande escala, de aplicações com interfaces REST. 
A vantagem da utilização desta biblioteca é a sua capacidade de gerar dados relevantes, ou seja, dados semelhantes aos dados que seriam submetidos por utilizadores reais. Por exemplo, caso a aplicação necessite de um valor que seja um nome de um utilizador, a biblioteca Faker vai gerar um nome real, i.e., um nome possível para um utilizador real.


%Nesta secção apresenta-se informação de contexto do trabalho realizado, incluindo as bibliotecas usadas na construção do sistema JepREST.
%\subsection{Especificação OpenAPI}
%%não deveria falar das anotações ??????????
%A especificação OpenAPI (OAS)~\cite{openAPI}
%%, anteriormente designada especificação Swagger, 
%foi criada com o objetivo de definir uma interface padrão, independente da linguagem, para descrever os serviços web RESTful. Desta forma, é possível descobrir e perceber as capacidades de um serviço sem que seja necessário ter acesso ao seu código fonte e à sua documentação. Se a especificação estiver definida corretamente é possível um utilizador entender e interagir com o serviço remotamente, sem conhecimento detalhado sobre a lógica de implementação.
%
%Um documento OpenAPI é um objeto JSON que define e descreve uma API, que pode ser representado no formato YAML ou JSON. O documento OpenAPI de uma API REST pode ser automaticamente gerado recorrendo à utilização da \textit{feature} openapi-3.0, que oferece suporte à especificação OpenAPI. Para isso, devem ser especificadas as anotações do OpenAPI no código da API REST. De seguida, a documentação da API REST gerada pode ser visualizada num \textit{browser} que utiliza uma interface simples que é fácil de aprender e utilizar~\cite{openAPI-annotations}.
%
%A tabela~\ref{tab:ann_openAPI} apresenta uma descrição sobre a representação de algumas das anotações que são utilizadas para gerar a documentação OpenAPI.
%
%\begin{table}
%    \centering
%    \renewcommand{\arraystretch}{1.2}
%    \begin{tabular}{l|l}
%Anotação     & Descrição                     \\\hline
%\texttt{@Operation}             &  Descreve uma operação ou um método HTTP com um \textit{path} específico\\
%\texttt{@Parameter}             &  Representa um parâmetro único numa operação\\
%\texttt{@RequestBody}            &   Representa o corpo do pedido numa operação\\
%\texttt{@ApiResponse}            &  Representa uma resposta numa operação\\
%\texttt{@Tag}            &  Representa as \textit{tags} de uma operação ou de uma definição do OpenAPI\\
%\texttt{@Link}            &  Representa um possível link de uma resposta\\ 
%\texttt{@Schema}            &  Permite definir os dados de \textit{input} e \textit{output} \\ 
%\texttt{@Content}            &  Fornece um esquema e exemplos para um tipo de dados específico\\ 
%\end{tabular}
%\label{tab:ann_openAPI}
%\caption{Exemplos de algumas anotações oferecidas pelo OpenAPI}
%\end{table}
%
%
%\subsection{PETIT}
%
%\par O PETIT~\cite{tese} é uma ferramenta de teste de microserviços, independente do código, que necessita de receber um documento com a especificação OpenAPI, escrita em JSON, devidamente anotado com a linguagem de especificação baseada em lógica de primeira ordem. Estas anotações  permitem definir invariantes de dados, pré e pós-condicões escritas com base em operações puras do mesmo API. 
%
%Para além de realizar pedidos à API e avaliar os resultados obtidos, PETIT também é capaz de gerar os dados relevantes, de acordo com os esquemas definidos no documento da especificação, que são utilizados para realizar os testes e avaliar se a implementação da API ou de uma operação específica está, de facto, de acordo com a sua especificação.
%
%\subsection{Jepsen}
%\label{related_work:jepsen}
%
%O Jepsen \cite{jepsenwebsite} é uma ferramenta utilizada para testar a correção de sistema distribuídos. Para isso, são submetidos ao sistema um conjunto de testes, assim como introduzidas algumas falhas com o intuito de verificar se existem execuções onde as propriedades prometidas pelo sistema são violadas.
%
%O processo de teste realizado pelo Jepsen a uma base de dados distribuída é feito em ambiente Docker, onde é construído um \textit{cluster} com seis \textit{containers}, por omissão, onde um deles é considerado o nó de controlo e os outros cinco são os nós da base de dados. Assim que um teste for iniciado, o nó de controlo vai criar um grupo de \textit{worker threads} para aceder aos nós da base de dados simultaneamente através do protocolo SSH, onde cada \textit{worker thread} contém um cliente. De seguida, o gerador vai informar o cliente sobre o conjunto de operações que deve submeter ao sistema para serem executadas, enquanto o \textit{nemesis} transmite ao cliente o conjunto de falhas que devem ser injetadas no sistema~\cite{nebula_jepsen}. O conjunto de operações e o conjunto de falhas são ambos definidos pelo programador.
%
%Durante a execução de um teste é armazenada numa história~\cite{consistency} toda a informação relativamente às operações que foram submetidas ao sistema, assim como o comportamento do mesmo ao executá-las. A história é analisada após a execução do conjunto de operações que foi definido, de forma a verificar se a mesma representa uma execução correta do sistema. Para a análise a uma história, o Jepsen recorre à utilização de um dos \textit{checkers} implementados, o Knossos ou o Elle.
%
%O Knossos \cite{jepsenKnossosGitHub} é o \textit{checker} principal utilizado pelo Jepsen cujo objetivo é determinar se uma dada história é ou não linearizável relativamente ao modelo definido, que descreve o comportamento correto do sistema na presença de uma operação específica. Uma história é considerada linearizável~\cite{linearizability} se todas as suas operações foram efetuadas atomicamente, segundo a ordem de tempo real. Por exemplo, se uma operação A for concluída antes do início de uma operação B, então a execução de A deve sempre preceder à execução de B, ou seja, a execução de B deve sempre observar os efeitos da execução A.
%
%O \textit{checker} Elle~\cite{kingsbury2020elle} tem como objetivo detetar problemas de consistência em transações. De modo a atingir este objetivo, este \textit{checker} vai procurar sequências de eventos impossíveis de ocorrer nessa ordem e utiliza esta inferência para provar que a história destes eventos é inconsistente~\cite{jepsenElleGitHub}. Para a elaboração desta prova, Elle recorre à construção de um grafo de dependências entre as diferentes transações. De forma a detetar quais as dependências entre as diferentes transações, as histórias geradas têm de satisfazer as propriedades de \textit{traceability} e de \textit{recoverability}. Isto é, em cada leitura é retornada a história que contém todos os valores escritos até ao momento e em cada escrita faz-se o mapeamento único entre os valores escritos e as transações que os escreveram, o que apenas é possível porque considera-se que cada valor escrito é único.
%
%Devido à sua capacidade de 
%%abordagem onde são detetados ciclos, 
%detetar ciclos, Elle tem algumas vantagens relativamente ao \textit{checker} principal do Jepsen. Nomeadamente, o Elle produz explicações claras sobre os resultados encontrados, contrariamente ao Knossos onde é apenas indicado se existe ou não uma história serial válida. Adicionalmente, o Knossos não é capaz de analisar histórias onde o número de operações seja superior a algumas centenas, enquanto que o Elle permite o processo de análise a histórias com centenas de milhares de operações \cite{jepsenElleGitHub}. Isto acontece porque o tempo de execução do Knossos diverge exponencialmente com o número de transações, enquanto que o Elle é efetivamente constante.
%
%\subsection{Faker} 
%
%O Faker~\cite{faker} é uma biblioteca responsável por gerar dados, que podem ser utilizados no processo de teste, em grande escala, de aplicações com interface REST. 
%
%A grande vantagem da utilização desta biblioteca é que a mesma tem a capacidade de gerar dados relevantes, ou seja, dados semelhantes aos dados que seriam submetidos por utilizadores reais. Por exemplo, caso a aplicação necessite de um valor que seja um nome de um utilizador, a biblioteca Faker vai gerar um nome real, isto é, um nome possível para um utilizador real.


%\vspace{-0.5cm}
\section{JepREST}
\label{system}
%\vspace{-0.2cm}

O JepREST é um sistema desenvolvido para verificar a 
correção de aplicações com interfaces REST, após a submissão de um teste funcional.
Para isso, o sistema JepREST recorre à utilização 
da biblioteca Jepsen, apresentada
na secção~\ref{related_work:jepsen}, para gerar e submeter um 
conjunto de testes funcionais com múltiplos clientes a efetuarem 
operações concorrentes à aplicação REST em análise. 
De seguida, o JepREST analisa as respostas
que foram geradas pela aplicação, de forma a verificar 
se as mesmas correspondem a um comportamento correto.

O teste de aplicações utilizando o JepREST consiste na seguinte sequência de passos, demonstrados na figura~\ref{fig:API}:

\begin{enumerate}[nosep]
    \item Definição da API da aplicação em estudo, assim
     como, da semântica associada às operações. A partir da API é gerado o código necessário à invocação dos métodos do serviço, incluindo a criação de novos objetos. 
    \item Definição do conjunto de testes a serem executados
     pela sistema de teste.
     O JepRest gera código para executar as cargas de trabalho definidas num \textit{script} YAML.
    \item Execução das cargas de trabalho, utilizando o código gerado anteriormente, recorrendo às bibliotecas do Jepsen para controlar a execução dos testes e obter o \textit{log} da execução.
    \item Análise dos resultados obtidos, verificando se a execução corresponde a um comportamento correto, definido como uma execução que seja linearizável segundo o modelo da API definido.
\end{enumerate}

\begin{figure}[t]
  \centering
  \includegraphics[height=3cm]{images/Arquitetura_JepREST.png}
\vspace{-0.4cm}
  \caption{Passos do teste de aplicações usando o JepREST.}
  \label{fig:API}
\vspace{-0.4cm}
\end{figure}

De seguida detalha-se cada um dos passos da solução.
%\vspace{-0.4cm}
\subsection{Definição da API da aplicação}
\label{jeprest:api}
%\vspace{-0.2cm}

Como o JepREST vai necessitar de utilizar os métodos e as estruturas oferecidas pelo Jepsen, que estão desenvolvidas em clojure, foi necessário criar um gerador de código para processar a especificação da aplicação e gerar métodos em clojure que vão ser executados pelo Jepsen para fazer as chamadas necessárias à aplicação REST em estudo. A especificação do serviço REST deve ser fornecida pelo programador em código Java, com anotações do OpenAPI e do JAX-RS.

%Para usar o JepREST, o programador deve especificar o serviço REST definido usando a especificação OpenAPI.
%Por simplicidade de implementação, esta especificação é transformada numa especificação JAX-RS estendida (com as anotações OpenAPI não disponíveis em JAX-RS.
%, que é posteriormente processada pelo JepREST para gerar código clojure que usa a biblioteca Jepsen para fazer as chamadas ao serviço. 
A biblioteca Jepsen oferece clientes que efetuam operações de leitura e de escrita simples, contudo não contém
nenhum cliente que permita submeter operações REST. Por isso, foi necessário criar um novo cliente Jepsen e definir para cada tipo de operação REST o comportamento do cliente para o pedido ser executado. 
Para cada operação definida na API, define-se o comportamento da mesma através de um método clojure gerado que é executado por um cliente quando for submetido um pedido da operação correspondente. Para a geração destes métodos, assume-se que a aplicação em estudo adota a semântica REST \textit{standard}, em que: o POST consiste na criação de novos recursos; o GET consiste na leitura de um ou vários recursos; o PUT consiste em atualizar um recurso específico; o PATCH consiste em atualizar parcialmente um recurso já existente e, por fim, o DELETE consiste na remoção de um recurso específico.


\subsection{Definição do conjunto de testes}

Para determinar a correção de uma aplicação REST é necessário analisar
as respostas do sistema quando é executado um conjunto de testes significativo.
Existem dois desafios neste processo. Primeiro, garantir que as operações 
são invocadas com parâmetros relevantes. Segundo, definir cargas de trabalho
que sejam apropriadas para o sistema.
    
Relativamente ao primeiro desafio, se fosse definido um conjunto de operações onde apenas são emitidas operações GET, PUT, PATCH ou DELETE de recursos
que nunca foram criados, os resultados gerados pela aplicação 
não serão muito informativos sobre a implementação da 
aplicação em estudo.
Para lidar com este problema, o código gerado mantém informação nos clientes de quais os objetos criados nos servidores e utiliza a anotação @Link do OpenAPI para estabelecer ligações entre diferentes objetos. Estas anotações definem dependências entre as diferentes operações, e.g. se uma operação A apresenta uma anotação @Link para um operação B, como no exemplo da figura~\ref{fig:POST_Link} considera-se que a operação B é dependente da operação A, uma vez que a mesma para ser efetuada com sucesso necessita de receber como parâmetro a informação da operação~A.

\begin{figure}[t]
  \centering
  \begin{lstlisting}[language= Java, frame=single, basicstyle=\scriptsize]
@POST
@Operation(operationId = "createStudent", responses = {
    @ApiResponse(links = {@Link(name = "GetStudentByID", 
    operationId = "getStudent", 
    parameters = {@LinkParameter(name = "studentId", 
                   expression = "$response.body#/id")})})})
Response createStudent(Student student);
  \end{lstlisting}
\vspace{-0.4cm}
  \caption{Exemplo de uma anotação @Link criada.}
  \label{fig:POST_Link}
  \vspace{-0.4cm}
\end{figure}

Após o processamento das anotações JAX-RS de cada operação da especificação para gerar os métodos clojure que descrevem o comportamento de um cliente quando se deseja que essa operação seja submetida à aplicação, o gerador de código vai analisar e processar todas as anotações @Link existentes na especificação da aplicação, para detetar todas as dependências entre as operações e armazenar em listas toda a informação de uma operação específica que possa ser utilizada como \textit{input} noutras operações da aplicação.
De seguida, o gerador de código é responsável por gerar os métodos clojure que vão definir as invocações que serão feitas à aplicação REST. Para isso, o gerador vai utilizar as listas que criou para selecionar os valores dos \textit{inputs} das operações que são dependentes de outras, e.g. parâmetros.
%De seguida, o gerador vai definir todas as operações que podem ser chamadas submetidas à aplicação, onde se utilizará as listas para selecionar os valores dos parâmetros
%As listas serão usadas pelo gerador de operações para selecionar os \textit{inputs}, e.g. parâmetros das
%operações de leitura e modificação de objetos já existentes. 
% De seguida, o gerador irá procurar por todas as operações 
%que são dependentes de outras operações. 
%Quando estas forem detetadas é gerado código em 
%clojure onde será definido o \textit{input} destas operações
%quando as mesmas forem submetidas à aplicação. 
%O \textit{input} de uma operação dependente irá sempre 
%pertencer ao conjunto de dados que já foram
%retornados pelas operações da qual a operação é dependente.
%No exemplo dado, sempre que a operação getStudent for submetida, 
%é escolhido como parâmetro, de forma \textit{random}, um dos 
%identificadores existentes na lista de identificadores de 
%estudantes que foram retornados pela operação createStudent.
%FALTA ADICIONAR: caso o conjunto de dados estiver vazio sao enviados dados dummy - random

Um segundo aspeto relativo a definir invocações com parâmetro relevantes prende-se com a geração de novos objetos - e.g. a informação dum estudante. 
Para endereçar este desafio, o JepREST recorre às bibliotecas Faker e PETIT, para a geração automática dos dados. O programador deve definir na especificação da API como os diferentes dados devem ser gerados, recorrendo ao uso de diferentes tipos de anotações, a figura~\ref{fig:Dados_Annot} é um exemplo de como os dados podem ser especificados. 
Caso exista a anotação especial @Values, o gerador de código define que esse dado vai ser gerado pela ferramenta Faker, onde será evocado o método descrito na anotação. Caso sejam utilizadas anotações @Min, @Max, @Size ou @Pattern sem a anotação @Values, o gerador de código, por sua vez, define que esse dado será gerado pela ferramenta PETIT, onde os valores das anotações serão enviados como parâmetros dos métodos do PETIT que vão ser chamados. 

Desta forma, irá se utilizar sempre que possível a ferramenta Faker, uma vez que a mesma gera dados realistas, que poderiam ser fornecidos durante a utilização da aplicação por um utilizador real.


%O programador, na especificação da API deve definir como os dados devem ser gerados.
%Se existir uma anotação @Values, então é gerado código clojure
%que irá chamar o método da ferramenta Faker que está definido 
%como valor na anotação @Values. Caso contrário, será sempre 
%gerado código clojure que irá chamar os métodos da 
%ferramenta PETIT para gerar os dados desejados.

\begin{figure}[t]
  \centering
  \begin{lstlisting}[language=Java, frame=single, basicstyle=\scriptsize]
    @Values("faker.name/first-name") @Pattern(regexp = "[A-Z][a-z]+")
    private String firstName;
    @Min(0) @Max(100)
    private int age;
    @Pattern(regexp = "[A-Z][a-z]+") @Size(min = 20, max = 500)
    private String description; 
  \end{lstlisting}
 \vspace{-0.4cm}
 \caption{Exemplo de anotações que representam as propriedades dos dados.}
  \label{fig:Dados_Annot}
   \vspace{-0.4cm}
\end{figure}
 
%Na figura \ref{fig:Dados_Annot} estão representados alguns 
%exemplos das anotações utilizadas para representar as 
%propriedades dos dados que se pretende gerar. 
%Quando o gerador de código processar as anotações do
%exemplo apresentado, para o firstName vai ser chamado, em código 
%clojure, o método faker.name/first-name da ferramenta 
%Faker. Para o parâmetro age vai ser chamado o método
%PrimitiveTypes/generateInRange da ferramenta PETIT, onde
%a informação das anotações @Min e @Max será enviada como 
%parâmetros. Por fim, para gerar um valor para o parâmetro 
%description, o gerador de código irá definir que deverá 
%ser chamado o método PrimitiveTypes/generateFromRegex da 
%ferramenta PETIT, onde a informação das anotações @Pattern 
%e @Size será enviada como argumento.
O segundo desafio prende-se com a definição das cargas de trabalho 
a serem submetidas à aplicação durante o processo de teste.
No JepREST, as cargas de trabalho são definidas num \textit{script} YAML inspirado na ferramenta Artillery\footnote{É de realçar que ao contrário
dum \textit{script} de testes Artillery, que especifica os detalhes da invocação das operações REST (incluindo entre outros o método HTTP, os parâmetros e a sua codificação), o \textit{script} usado pelo JepREST
apenas indica o nome das operações.},
especificando diferentes cenários de teste, compostos por sequências de operações, definidas na \textit{tag flow}, (definidas usando o nome do método clojure gerado no passo anterior) a serem executadas concorrentemente por vários clientes, onde cada cenário terá um dado peso. Os pesos são relevantes para determinar qual o cenário que deve ser executado um maior número de vezes, e.g. se num ficheiro YAML existir o cenário 1 com peso 90 e o cenário 2 com peso 10, a sequência de operações definida no primeiro cenário executará 9 vezes mais frequentemente que a sequência de operações definidas no segundo cenário. 

%\begin{figure}[t]
  %%\centering
  %\begin{lstlisting}[frame=single,basicstyle=\scriptsize]
  %  scenarios:
  %    weight: 90
  %    flow:
  %      - createStudentData
  %      - getStudentData
  %    weight: 10
  %    flow:
  %      - createSubjectData
  %      - getAllSubjectsData  
  %\end{lstlisting}
%\vspace{-0.4cm}
 % \caption{Exemplo de um ficheiro yaml utilizado pelo Artillery}
  %\label{fig:Artillery}
%\end{figure}

%A figura \ref{fig:Artillery} é um exemplo de um ficheiro YAML 
%com diferentes cenários com pesos diferentes. 

%O ficheiro YAML (não apresentado na figura) permite também definir o número 
%SSSde clientes concorrentes usados nos testes e a duração da experiência.

%No final de todas as operações de um cenário serem
%executadas pela aplicação, será gerado um novo número aleatório
%para determinar qual o próximo cenário a ser submetido à
%aplicação. Isto é feito durante o tempo de execução do teste, que
%atualmente está definido para durar cerca de 30 segundos.
%\vspace{-0.6cm}
\subsection{Execução dos testes}
%\vspace{-0.2cm}

Antes do JepREST submeter um teste à aplicação em estudo, o programador é responsável por definir a localização dos \textit{containers} onde os servidores REST existentes estão a correr, i.e. endereço IP e a porta, para que os clientes possam saber aonde é que podem submeter os seus pedidos.

Assume-se que sempre que um teste é executado, a aplicação é inicializada, o JepREST não suporta a verificação de aplicações já em funcionamento, onde já foram efetuados pedidos REST. Portanto, antes da execução de um teste o serviço é inicializado e lançado em ambiente Docker - a aplicação que se está a testar está a correr em um ou mais \textit{containers Docker}. O JepREST permite verificar a correção tanto se estes \textit{containers} estiverem a correr localmente ou remotamente, apenas é necessário informar a localização dos mesmos.
Quando o JepREST executa um teste, o mesmo é responsável por gerar e enviar ao Jepsen a sequência de operações que foi definida. De seguida, o \textit{container} de controlo do Jepsen vai criar vários clientes e informá-los sobre as operações que os mesmos devem submeter à aplicação, assim como toda a informação necessária dos pedidos, inclusive a localização do \textit{container}, onde o servidor a qual se pretende fazer o pedido está a correr.
%O JepREST executa um teste, submetendo as operações à aplicação com o auxílio da biblioteca Jepsen. 
%Assim, o JepREST começa por lançar o sistema que se está a testar, recorrendo ao Docker - a aplicação 
%que se está a testar deve correr em um ou mais \textit{containers Docker}.
%Antes deste passo, o programador é responsável por definir a localização dos servidores existentes, i.e, o seu endereço IP e porta, para que os clientes possam submeter os seus pedidos. 

Algumas funcionalidades ainda em implementação neste componente do sistema incluem a definição do conjunto de 
falhas a simular e o suporte de múltiplos e distintos serviços REST para a mesma aplicação. 

%\vspace
%???
\subsection{Validação dos resultados}
%\vspace{-0.2cm}

Após a conclusão de um teste, o JepREST vai analisar as suas respostas para 
verificar se as mesmas correspondem a um funcionamento correto. 
A informação da história da execução é armazenada num ficheiro 
automaticamente gerado pelo Jepsen, durante a execução das 
várias operações.

O JepREST analisa a história de operações efetuadas recorrendo
ao \textit{checker} Knossos, oferecido pelo Jepsen. 
Este \textit{checker} é responsável por verificar se a 
história de operações é linearizável segundo o modelo que representa
o estado e como o mesmo deve ser modificado na presença de operações.

Para usar o Knossos, o JepREST define e implementa o modelo
do estado da aplicação, onde é expressa a forma como o mesmo é alterado na presença de uma operação REST específica.

A implementação do modelo foi dividida em duas fases, a primeira onde foi escolhido um tipo de dados para representar o estado da aplicação REST em estudo, e a segunda onde se determina qual deve ser a mudança do estado da aplicação após a execução de uma operação REST específica.
Na primeira fase, definiu-se que o estado de uma aplicação REST iria ser representado através de um mapa, onde as chaves são o nome dos recursos e os valores são outros mapas em que as chaves são os identificadores dos recursos que já foram criados e os valores são os objetos \textit{json} que representam os recursos existentes. 

Na segunda fase é definido o novo estado da aplicação, em resultado da aplicação das várias operações REST definidas.
Por exemplo, um POST devolve um erro caso o identificador do objeto já exista e caso não exista atualiza o estado da aplicação com
o objeto recebido. As restantes operações são definidas de forma semelhante, considerando as situações de erro e as atualizações 
correspondentes.
%As operações t após a execução com sucesso de um tipo de operação REST:
%%aqui, explicar melhor como o estado é alterado na presença de uma operação REST específica
%\begin{itemize}[nosep]
%  \item Se for efetuada uma operação POST com sucesso, verifica-se se já existe o identificador do objeto criado pelo POST. Em caso positivo, é detetado e devolvido um erro de inconsistência no modelo, visto que não podem existir dois objetos do mesmo recurso com o mesmo identificador. Caso contrário define-se o novo estado como sendo o mapa do estado anterior juntamente com o novo objeto que foi criado pela operação POST.
%  \item No caso de ser efetuada uma operação GET com sucesso e a mesma tiver como um \textit{input} um identificador de um objeto de um recurso específico, considera-se que a operação deve retornar o objeto com o identificador dado. A operação GET está implementada corretamente se existir um recurso com o identificador dado e se o recurso retornado pela operação for igual ao objeto que está presente no mapa do estado da aplicação, com o mesmo identificador. Se isto acontecer, o estado da aplicação mantêm-se, caso contrário é retornado um erro de inconsistência.
%  
%  Caso seja efetuada com sucesso uma operação GET que não recebe \textit{input} assume-se que a operação deve devolver todos os objetos criados de um recurso específico. Se esta operação não devolver todos os elementos do recurso específico que estão presentes no mapa do estado da aplicação, é retornado um erro de inconsistência do modelo. Caso contrário, define-se que o estado da aplicação mantém-se.
%  \item Se for efetuada uma operação PUT ou PATCH com sucesso, verifica-se se existe um recurso com o identificador dado. Em caso negativo, é retornado um erro de inconsistência, caso contrário o novo estado da aplicação é igual ao estado anterior cujo objeto com o identificador dado está atualizado com a informação recebida no \textit{input} da operação efetuada.
%  \item Se for efetuada uma operação DELETE com sucesso e não existir nenhum objeto com o identificador recebido, é retornado um erro de inc  onsistência do modelo. Caso contrário, define-se que o novo estado da aplicação é igual ao estado anterior sem o objeto que foi removido pela operação DELETE.
%\end{itemize}
%
%%acho que tenho a parte do modelo e da mudanca do estado de forma esquisita
%\vspace{-0.7cm}
%\begin{figure}[htbp]
%  \centering
%  \begin{lstlisting}[frame=single]
%{:model {:allJsons
%    {:students
%     {"96B812BC48C46700F1A73BF8D84B0AACAB72E0C5"
%       {:id "96B812BC48C46700F1A73BF8D84B0AACAB72E0C5",
%        :firstName "Micaela",:lastName "Kerluke",
%        :email "ladarius@altenwerth.com",
%        :age 21, :phone "(737)672-3957 x2328"},
%       "FF309F016A144666CCA3B8E687AEC9996EE4C169"
%       {:id "FF309F016A144666CCA3B8E687AEC9996EE4C169",
%        :firstName "Aleen",:lastName "Lynch",
%        :email "kristofer.nienow@shea.ca",
%        :age 95, :phone "459.404.7572 x0841"}},
%      :subjects
%      {"52123A208FB1B7D293A156FC2AEE59716FFAA970"
%       {:id "52123A208FB1B7D293A156FC2AEE59716FFAA970",
%        :name "Didkz", :professorName "Ms. Kyle Bahringer",
%        :semester 1, :year 4, :capacity 95}}}}
%  \end{lstlisting}
%  \caption{Modelo de uma Aplicação REST após a execução de um conjunto de operações}
%  \label{fig:Modelo_AppREST}
%\end{figure}
%\vspace{-1cm}


%\section{Desenho da Solução}
%\label{system}
%O JepREST é um sistema desenvolvido para verificar a 
%correção de aplicações que contenham um estilo 
%arquitetural REST.
%Para isso, o sistema JepREST recorrere à utilização 
%das bibliotecas oferecidas pela ferramenta Jepsen, detalhada
%na secção \ref{related_work:jepsen}, para gerar e submeter um 
%conjunto de testes com múltiplos clientes a efetuarem 
%operações concorremente à aplicação REST em análise. 
%Seguidamente, o JepREST analisa todas as respostas
%que foram geradas pela aplicação, de forma a verificar 
%se as mesmas correspondem a um comportamento correto.
%
%A implementação do JepREST foi dividida em vários passos
%complementares, que foram endereçados individualmente.
%Os passos da solução desenvolvida são os seguintes:
%
%\begin{enumerate}[nosep]
%    \item Definição da API da aplicação em estudo, assim
%     como, a semântica associada.
%    \item Definição do conjunto de testes a serem executados
%     pela aplicação.
%    \item Definição de um método responsável por submeter o 
%    conjunto de testes à aplicação.
%    \item Definição de um método que analise os resultados
%     gerados pela aplicação e determine se os mesmos 
%     correspondem ou não a um comportamento correto.
%\end{enumerate}
%
%A arquitetura do JepREST é demonstrada na figura \ref{fig:API}. 
%
%\begin{figure}[htbp]
%  \centering
%  \includegraphics[height=3cm]{images/Arquitetura_JepREST.png}
%  \caption{Arquitetura do JepREST}
%  \label{fig:API}
%\end{figure}
%
%De seguida será feita uma descrição detalhada sobre como 
%cada passo da solução foi endereçado.
%
%\subsection{Passos da Solução}
%\paragraph{\textbf{Definição da API da aplicação em estudo, assim como, a semântica associada}}
%
%O sistema JepREST para realizar o processo de teste a uma aplicação com interface REST necessita de receber um documento com a descrição da API, escrito em Java. Para especificar as operações REST oferecidas, recorreu-se à utilização de anotações JAX-RS e OpenAPI.
%Este documento, atualmente, é uma interface Java que extende todas as interfaces da aplicação REST.
%
%De seguida, o JepREST utiliza um gerador de código, escrito em Java, que é responsável por processar o documento com a especificação da API, nomeadamente as anotações de cada operação, e gerar o código clojure que será executado pelos métodos oferecidos pelas bibliotecas do Jepsen:
%
%\begin{itemize}[nosep]
%    \item Como o Jepsen não contém nenhum cliente que possa submeter operações REST, é necessário criar um novo cliente Jepsen e definir o tipo de operações REST que o mesmo pode submeter e qual deve ser o comportamento de cada uma. Portanto, para cada operação definida na API é gerado um método clojure que indique o comportamento da operação quando a mesma é invocada.
%    
%    De forma, a atingir este objetivo, é necessário definir a semântica que se vai utilizar para representar as diferentes operações REST: POST, GET, PUT, PATCH e DELETE. Estas operações têm uma semântica bem definida no modelo arquitetural REST, embora muitas aplicações implementem diferentes funcionalidades. Por isso, o JepREST, atualmente, considera apenas a semântica base destas operações, onde um:
%
%\begin{itemize}[nosep]
%    \item POST consiste na criação de novos recursos.
%    \item GET consiste na leitura de um ou vários recursos.
%    \item PUT consiste em atualizar um recurso específico.
%    \item PATCH consiste em atualizar parcialmente um recurso já existente.
%    \item DELETE consiste na remoção de um recurso específico.
%    
%\end{itemize}
%    \item De forma, ao sistema JepREST conhecer as diferentes operações oferecidas pela API em estudo, o gerador de código vai também gerar um método para cada operação que vai pode ser chamado pelo cliente Jepsen para invocar essa operação.
%\end{itemize}
%
%\paragraph{\textbf{Definição do conjunto de testes a serem executados
%pela aplicação}}
%
%Como já foi referido, o JepREST para determinar a propriedade
%correção de uma aplicação REST necessita de analisar as 
%respostas desta quando a mesma é submetida a um conjunto 
%de testes.
%    
%Para cada teste pretende-se definir um conjunto de operações
%relevantes, isto é, que permita obter nova informação sobre 
%o funcionamento e implementação da aplicação em estudo. Por
%exemplo, se for definido um conjunto de operações onde apenas
%são emitidas operações de GET, PUT, PATCH ou DELETE de recursos
%que nunca foram criados, os resultados gerados pela aplicação 
%não serão muito informativos sobre a implementação da 
%aplicação em estudo.
%Portanto, de forma a minimizar a existência de conjuntos de
%operações pouco informativas e irrelevantes, recorreu-se à 
%utilização de anotações @Link, oferecidos pelo OpenAPI,
%na especificação da API da aplicação.
%
%A figura \ref{fig:POST_Link} é um exemplo de uma anotação @Link
%criada, onde o identificador retornado pela operação createStudent que 
%faz um POST de um estudante, pode ser utilizado como parâmetro na 
%operação getStudent que realiza um GET de um estudante com 
%identificador dado. Por este motivo, considera-se que existe uma 
%dependência entre estas duas operações, onde a operação getStudent
%depende da execução da operação createStudent. Por outras palavras,
%sempre que existe uma anotação @Link de uma operação A para uma operação B
%classifica-se a operação B como sendo dependente da operação A.
%
%\begin{figure}[htbp]
%  \centering
%  \begin{lstlisting}[language= Java, frame=single]
%@POST
%@Operation(operationId = "createStudent", responses = {
%    @ApiResponse(links = {@Link(
%          name = "GetStudentByID", operationId = "getStudent", 
%          parameters = { @LinkParameter(
%                name = "studentId", 
%                expression = "$response.body#/id")})})})
%  Response createStudent(Student student);
%  \end{lstlisting}
%  \caption{Exemplo de uma anotação @Link criada}
%  \label{fig:POST_Link}
%\end{figure}
%
%
%O gerador de código é responsável por analisar e processar
%toda a informação contida nas anotações @Link definidas na
%especificação da API da aplicação, de forma
%a detetar as dependências existentes entre as diferentes
%operações.
%
%De forma a atingir este objetivo, o gerador de código procura
%operações que contenham as anotações @Link e de seguida
%gera código em clojure que irá armazenar numa lista todos
%os dados retornados que podem ser utilizados como \textit{input}
%em operações diferentes.
%No exemplo apresentado vai ser gerada uma lista em clojure
%que irá armazenar todos os identificadores dos estudantes que 
%foram criados e retornados pela operação createStudent.
%De seguida, o gerador irá procurar por todas as operações 
%que são dependentes de outras operações. 
%Quando estas forem detetadas é gerado código em 
%clojure onde será definido o \textit{input} destas operações
%quando as mesmas forem submetidas à aplicação. 
%O \textit{input} de uma operação dependente irá sempre 
%pertencer ao conjunto de dados que já foram
%retornados pelas operações da qual a operação é dependente.
%No exemplo dado, sempre que a operação getStudent for submetida, 
%é escolhido como parâmetro, de forma \textit{random}, um dos 
%identificadores existentes na lista de identificadores de 
%estudantes que foram retornados pela operação createStudent.
%%FALTA ADICIONAR: caso o conjunto de dados estiver vazio sao enviados dados dummy - random
%
%Após o processamento de anotações @Link, foi implementado no
%JepREST um método que integrasse a utilização da ferramenta
%Faker juntamente com a ferramenta PETIT, 
%para a geração automática dos dados necessários para 
%a execução das operações definidas na especificação
%da API da aplicação.
%Este método recorre ao gerador de código para processar 
%as propriedades dos dados que estão expressas em anotações. 
%Se existir uma anotação @Values, então é gerado código clojure
%que irá chamar o método da ferramenta Faker que está definido 
%como valor na anotação @Values. Caso contrário, será sempre 
%gerado código clojure que irá chamar os métodos da 
%ferramenta PETIT para gerar os dados desejados.
%
%\begin{figure}[htbp]
%  \centering
%  \begin{lstlisting}[language=Java, frame=single]
%    @Values("faker.name/first-name")
%    @Pattern(regexp = "[A-Z][a-z]+")
%    private String firstName;
%
%    @Min(0)
%    @Max(100)
%    private int age;
%
%    @Pattern(regexp = "[A-Z][a-z]+")
%    @Size(min = 20, max = 500)
%    private String description; 
%
%  \end{lstlisting}
%  \caption{Exemplo de anotações que representam as propriedades dos dados}
%  \label{fig:Dados_Annot}
%\end{figure}
% 
%Na figura \ref{fig:Dados_Annot} estão representados alguns 
%exemplos das anotações utilizadas para representar as 
%propriedades dos dados que se pretende gerar. 
%Quando o gerador de código processar as anotações do
%exemplo apresentado, para o firstName vai ser chamado, em código 
%clojure, o método faker.name/first-name da ferramenta 
%Faker. Para o parâmetro age vai ser chamado o método
%PrimitiveTypes/generateInRange da ferramenta PETIT, onde
%a informação das anotações @Min e @Max será enviada como 
%parâmetros. Por fim, para gerar um valor para o parâmetro 
%description, o gerador de código irá definir que deverá 
%ser chamado o método PrimitiveTypes/generateFromRegex da 
%ferramenta PETIT, onde a informação das anotações @Pattern 
%e @Size será enviada como argumento.
%
%Para concluir este passo, falta definir o conjunto de operações
%a serem submetidas à aplicação durante o processo de teste. Para
%isso, recorreu-se ao uso do Artillery para definir diferentes 
%cenários de teste com diferentes pesos. As operações especificadas
%nos diferentes cenários do yaml são representadas pelos
%nomes dos métodos em clojure que submetem as operações definidas
%à aplicação REST.
%
%\begin{figure}[htbp]
%  \centering
%  \begin{lstlisting}[frame=single]
%    scenarios:
%    - name: 'Create Student'
%      weight: 90
%      flow:
%        - createStudentData
%        - getStudentData
%    - name: 'Create Subject'
%      weight: 10
%      flow:
%        - createSubjectData
%        - getAllSubjectsData  
%
%  \end{lstlisting}
%  \caption{Exemplo de um ficheiro yaml utilizado pelo Artillery}
%  \label{fig:Artillery}
%\end{figure}
%
%A figura \ref{fig:Artillery} é um exemplo de um ficheiro yaml 
%criado com diferentes cenários com pesos diferentes. 
%Este ficheiro vai ser lido pelo clojure,
%onde vai ser gerado um número \textit{random} entre 1 e 
%o (número total de pesos + 1) para determinar qual o cenário de testes
%a executar, num dado instante.
%No exemplo dado, se o número \textit{random} não for superior a 
%90 o cenário "Create Student" é escolhido e as operações 
%definidas no \textit{flow} vão ser submetidas à aplicação concorrentemente
%. Caso contrário, será escolhido o cenário "Create
%Subject", onde o conjunto de operações definidas neste cenário 
%também serão emitidas concorrentemente.
%
%No final de todas as operações de um cenário serem
%executadas pela aplicação, será gerado um novo número aleatório
%para determinar qual o próximo cenário a ser submetido à
%aplicação. Isto é feito durante o tempo de execução do teste, que
%atualmente está definido para durar cerca de 30 segundos.
%
%\paragraph{\textbf{Definição de um método responsável por submeter o
%conjunto de testes à aplicação}}
%
%Atualmente, o JepREST suporta apenas ter um único servidor REST a executar operações. Por isso, após o conjunto de operações de um teste ser definido, o sistema desenvolvido é responsável por submetê-las à aplicação. Para isto, o JepREST recorre ao auxílio das bibliotecas da ferramenta Jepsen, 
%onde o conjunto de operações é enviado ao gerador do Jepsen que é responsável por informar os vários clientes sobre as operações que os mesmos devem submeter à aplicação.
%
%De forma a isto ser possível, foi necessário, primeiro colocar o único servidor REST em ambiente Docker na mesma rede dos clientes Jepsen. De seguida, estabeleceu-se a conexão entre os vários clientes e o servidor. Para isso, foi necessário informá-los sobre a localização do servidor, ou seja, fornecer o endereço IP e a porta do mesmo.
%
%\paragraph{\textbf{Definição de um método que analise os resultados
%gerados pela aplicação e determine se os mesmos correspondem
%ou não a um comportamento correto}}
%%reler
%No final da aplicação executar todas as operações que lhe foram
%submetidas, o JepREST vai analisar as suas respostas para 
%verificar se as mesmas correspondem a um funcionamento correto. 
%Esta informação é armazenada numa história que é um ficheiro 
%automaticamente gerado pelo Jepsen, durante a execução das 
%várias operações.
%
%O JepREST para analisar a história de operações efetuadas recorre
%à utilização do \textit{checker} Knossos, oferecido pelo Jepsen. 
%Este \textit{checker} é responsável por verificar se a 
%história de operações é linearizável segundo o modelo que representa
%o estado e como o mesmo deve ser modificado na presença de operações.
%
%De forma, a ser possível utilizar o Knossos, foi implementado
%no sistema JepREST o modelo que representa o estado da aplicação 
%e como o mesmo deve ser alterado na presença de uma operação REST
%específica.
%
%A implementação do modelo foi dividida em duas fase, a primeira onde foi escolhido um tipo de dados para representar o estado da aplicação REST em estudo, e a segunda onde se determina qual deve ser a mudança do estado da aplicação após a execução de uma operação REST específica.
%%aqui explicar melhor como o mesmo é representado
%Na primeira fase, definiu-se que o estado de uma aplicação REST iria ser representado através de um mapa, onde as chaves são o nome dos recursos e os valores são outros mapas em que as chaves são os identificadores dos recursos que já foram criados e os valores são os objetos \textit{json} que representam os recursos existentes. A figura~\ref{fig:Modelo_AppREST} é um exemplo do estado da aplicação num dado instante durante a execução de um teste.
%
%Na segunda fase é definido um método que determina o novo estado da aplicação após a execução com sucesso de um tipo de operação REST:
%%aqui, explicar melhor como o estado é alterado na presença de uma operação REST específica
%\begin{itemize}[nosep]
%  \item Se for efetuada uma operação POST com sucesso, verifica-se se já existe o identificador do objeto criado pelo POST. Em caso positivo, é detetado e devolvido um erro de inconsistência no modelo, visto que não podem existir dois objetos do mesmo recurso com o mesmo identificador. Caso contrário define-se o novo estado como sendo o mapa do estado anterior juntamente com o novo objeto que foi criado pela operação POST.
%  \item No caso de ser efetuada uma operação GET com sucesso e a mesma tiver como um \textit{input} um identificador de um objeto de um recurso específico, considera-se que a operação deve retornar o objeto com o identificador dado. A operação GET está implementada corretamente se existir um recurso com o identificador dado e se o recurso retornado pela operação for igual ao objeto que está presente no mapa do estado da aplicação, com o mesmo identificador. Se isto acontecer, o estado da aplicação mantêm-se, caso contrário é retornado um erro de inconsistência.
%  
%  Caso seja efetuada com sucesso uma operação GET que não recebe \textit{input} assume-se que a operação deve devolver todos os objetos criados de um recurso específico. Se esta operação não devolver todos os elementos do recurso específico que estão presentes no mapa do estado da aplicação, é retornado um erro de inconsistência do modelo. Caso contrário, define-se que o estado da aplicação mantém-se.
%  \item Se for efetuada uma operação PUT ou PATCH com sucesso, verifica-se se existe um recurso com o identificador dado. Em caso negativo, é retornado um erro de inconsistência, caso contrário o novo estado da aplicação é igual ao estado anterior cujo objeto com o identificador dado está atualizado com a informação recebida no \textit{input} da operação efetuada.
%  \item Se for efetuada uma operação DELETE com sucesso e não existir nenhum objeto com o identificador recebido, é retornado um erro de inconsistência do modelo. Caso contrário, define-se que o novo estado da aplicação é igual ao estado anterior sem o objeto que foi removido pela operação DELETE.
%\end{itemize}
%
%%acho que tenho a parte do modelo e da mudanca do estado de forma esquisita
%
%\begin{figure}[htbp]
%  \centering
%  \begin{lstlisting}[frame=single]
%{:model {:allJsons
%     {:students
%      {"96B812BC48C46700F1A73BF8D84B0AACAB72E0C5"
%       {:id "96B812BC48C46700F1A73BF8D84B0AACAB72E0C5",
%       :firstName "Micaela", :lastName "Kerluke",
%       :email "ladarius@altenwerth.com",:age 21,
%       :phone "(737)672-3957 x2328"},
%       "FF309F016A144666CCA3B8E687AEC9996EE4C169"
%      {:id "FF309F016A144666CCA3B8E687AEC9996EE4C169", 
%       :firstName "Aleen",:lastName "Lynch", 
%       :email "kristofer.nienow@shea.ca",:age 95,
%       :phone "459.404.7572 x0841"}},
%       :subjects
%      {"52123A208FB1B7D293A156FC2AEE59716FFAA970"
%       {:id "52123A208FB1B7D293A156FC2AEE59716FFAA970",
%        :name "Didkz",:professorName "Ms. Kyle Bahringer",
%        :semester 1,:year 4,:capacity 95}}}}
%  \end{lstlisting}
%  \caption{Modelo de uma Aplicação REST após a execução de um conjunto de operações}
%  \label{fig:Modelo_AppREST}
%\end{figure}

%\vspace{-0.5cm}
\section{Experiências}
\label{eval}
%\vspace{-0.3cm}

A figura~\ref{fig:Actions_JepREST} mostra os passos que um utilizador tem de seguir para utilizar a ferramenta JepREST para testar uma aplicação com interface REST. O maior esforço de um programador que pretende utilizar o JepREST é ter de escrever a especificação da API em estudo, indicar a localização do servidor REST, providenciar o ficheiro .war da API e indicar a sua localização no Dockerfile da API. Os restantes passos são praticamente automáticos onde apenas é necessário executar comandos no terminal ou mesmo executar código, como por exemplo, correr o código do gerador ou o código Clojure para submeter testes à aplicação.
% -- esta na parte de execução de testes - Atualmente, o JepREST assume que a aplicação em estudo é sempre inicializada antes da execução de um teste, ou seja, um teste é sempre submetido a uma aplicação REST vazia. 


\begin{figure}[t]
  \centering
  \includegraphics[height=3cm]{images/Passos_JepREST.png}
\vspace{-0.4cm}
  \caption{Ações de um utilizador para executar o JepREST.}
  \label{fig:Actions_JepREST}
  \vspace{-0.3cm}
\end{figure}

Para verificar se o sistema JepREST avalia corretamente as execuções de aplicações REST quando são emitidos pedidos concorrentes, foi desenvolvida uma aplicação, escrita em Java, onde é utilizada uma base de dados H2 \textit{embedded} e foi criado apenas um recurso e 6 \textit{endpoints} diferentes: criar um estudante (POST), devolver um estudante com o dado identificador (GET), devolver todos os estudantes (GET), modificar um estudante com o identificador dado (PUT), modificar parcialmente um estudante com o identificador dado (PATCH) e remover um estudante com o identificador dado (DELETE). Ao implementar cada um destes \textit{endpoints} optou-se por não utilizar transações sempre que fosse necessário fazer modificações à base de dados. Tomou-se esta decisão uma vez que existirão problemas de consistência num ambiente de concorrência e pretende-se confirmar que o JepREST consegue detetar estes problemas nas várias execuções da API, onde são emitidos os vários tipos de pedidos REST.

Após a implementação da API, a escrita da sua especificação e a geração do código clojure, escreveu-se o teste a correr no ficheiro YAML, onde se definiu um cenário para ser executado várias vezes a cada 1 milissegundo, durante 30 segundos, demonstrado na figura~\ref{fig:cenario}. Este cenário contêm uma sequência de operações que vão ser submetidas à aplicação por vários clientes, de forma concorrente, mesmo se ocorrerem falhas a meio da sequência, as operações continuam a ser emitidas pelos vários clientes do JepREST.

\begin{figure}[t]
  \centering
  \begin{lstlisting}[frame=single, basicstyle=\scriptsize]
scenarios:
    weight: 100
    flow:
      - createStudentData
      - updateStudentData
      - getAllStudentsData
      - getStudentData
      - deleteStudentData
  \end{lstlisting}
\vspace{-0.4cm}
  \caption{Cenário executado pelo sistema JepREST.}
  \label{fig:cenario}
\end{figure}

O JepREST submeteu este teste, várias vezes à aplicação criada, e detetou diferentes problemas de consistência em quase todas as execuções.
De seguida, são apresentados os resultados das várias execuções do teste definido, com uma breve descrição sobre os problemas de consistência que foram detetados.


%algo não está claro - o que é um erro
\noindent \textbf{Experiência 1.}
A figura \ref{fig:error_get1} demonstra parte de um \textit{log} gerado pelo JepREST após a execução do teste definido, onde são retratadas as sequências de operações que foram submetidas assim como as respostas da aplicação após a execução das mesmas. Uma linha do \textit{log} tem a seguinte informação, respetivamente da esquerda para a direita: um \textit{timestamp} que representa o instante que a operação foi invocada/executada, o identificador do cliente Jepsen responsável por submeter/receber a operação, uma indicação sobre se a operação é uma invocação (invoke) ou uma resposta (ok/fail), o tipo de operação REST (post/put/get/patch/delete) e, por fim, informação extra sobre a operação, como o \textit{input} e o \textit{output}.

\begin{figure}[t]
  \centering
  \begin{lstlisting}[numbers = left, frame=single,basicstyle=\scriptsize]
11:59:59 :4 :invoke, :put, {:firstName "Brycen", :lastName "Cummerata",
            :email "adam@prince.com", :age 129, :phone "119-364-8408"},
            :path "498C98D9E8CB"
11:59:59 :0 :invoke, :get
11:59:59 :2 :invoke, :get, :path "498C98D9E8CB"
11:59:59 :3 :invoke, :delete, :path "498C98D9E8CB"
11:59:59 :4 :ok, :put, :output {:id "498C98D9E8CB", 
            :firstName "Brycen",:lastName "Cummerata", 
            :email "adam@prince.com", :age 129, :phone "119-364-8408"}
11:59:59 :3 :ok, :delete, :output "498C98D9E8CB"
11:59:59 :0 :fail, :get
11:59:59 :2 :ok, :get, :path "498C98D9E8CB", :output {:id "498C98D9E8CB", 
            :firstName "Brycen",:lastName "Cummerata", 
            :email "adam@prince.com", :age 129, :phone "119-364-8408"}
  \end{lstlisting}
\vspace{-0.4cm}
  \caption{Parte de um \textit{log} gerado pelo JepRest durante uma execução do teste definido.}
  \label{fig:error_get1}
  \vspace{-0.4cm}
\end{figure}

Este \textit{log} retrata nas linhas 1, 4, 5 e 6, a submissão de quatro operações REST distintas à aplicação, de forma concorrente e ao observar as respostas da aplicação, destes pedidos, verifica-se que na linha 10 a operação DELETE é efetuada com sucesso, ou seja, o estudante com o identificador ``498C98D9E8CB'' é removido, contudo, na linha 12, a aplicação responde que a operação GET é efetuada com sucesso e o estudante com o identificador ``498C98D9E8CB'' é recebido. Isto acontece, porque o estudante com identificador dado é removido depois de ser verificado se o mesmo existe pela operação GET. Contudo, como a operação DELETE foi efetuada com sucesso (linha 10) antes da operação GET (linha 12), o JepREST reporta um erro de consistência, afirmando que a operação GET não pode ter sido efetuada com sucesso, visto que o identificador do estudante dado já foi removido.

\noindent \textbf{Experiência 2.}
Esta experiência retrata outra execução do mesmo teste à aplicação REST implementada, onde são obtidos resultados diferentes da primeira experiência. Parte do \textit{log} gerado pelo JepRest está apresentado na figura~\ref{fig:error_get2}, e este apresenta a mesma informação que o \textit{log} da experiência anterior.  

\begin{figure}[t]
  \centering
      \begin{lstlisting}[numbers = left, frame=single,basicstyle=\scriptsize]
12:30:17 :2 :invoke, :put, {:firstName "Sasha", :lastName "Hyatt", 
         :email "claudine.prosacco@hotmail.com", :age 93, 
         :phone "(165)479-5262 x15024"}, :path "71D1083D76BD"
12:30:17 :3 :invoke, :get
12:30:17 :1 :invoke, :get, :path "71D1083D76BD"
12:30:17 :0 :invoke, :delete, :path "71D1083D76BD"
12:30:17 :1 :ok, :get, :path "71D1083D76BD", :output {:id "71D1083D76BD",
         :firstName "Grayce", :lastName "Brekke",
         :email "marques.rodriguez@yahoo.com", :age 40, 
         :phone "1-162-508-6862 x13530"}
12:30:17 :3 :ok, :get, :output ({:id "71D1083D76BD", 
         :firstName "Grayce", :lastName "Brekke", 
         :email "marques.rodriguez@yahoo.com", :age 40, 
         :phone "1-162-508-6862 x13530"})
12:30:17 :0 :ok, :delete, :output "71D1083D76BD"
12:30:17 :2 :ok, :put, :path "71D1083D76BD", :output nil
  \end{lstlisting}
\vspace{-0.4cm}
  \caption{Parte de um \textit{log} gerado pelo JepRest durante uma execução do teste definido.}
  \label{fig:error_get2}
\vspace{-0.4cm}
\end{figure}
Tal como no \textit{log} da Experiência 1, pode-se observar nas linhas 1, 4, 5 e 6 vários pedidos concorrentes de diferentes clientes à aplicação REST. Nesta experiência, o JepREST deteta um erro de consistência na linha 16, uma vez que é observado que a operação responsável por atualizar o estudante com o identificador "71D1083D76BD" é efetuada com sucesso, contudo a operação responsável por remover o estudante com este identificador foi efetuada com sucesso momentos antes, na linha 15. O sistema criado, JepREST, deteta esta inconsistência e reporta-a informando que o resultado da operação PUT está incorreto (linha~15), visto que o identificador do estudante que pretende atualizar já foi removido pela operação DELETE (linha 16).

%\vspace{-0.5cm}
\section{Conclusões e Trabalho Futuro}
%\vspace{-0.4cm}
\label{conclusion}

%A minha conclusão do resultado dos testes
O sistema JepREST permite simplificar o teste de aplicações distribuídas com interfaces REST, assim como, a verificação da sua correção.
A versão atual do sistema inclui todos os componentes necessários ao teste de aplicações que adotam o modelo REST \textit{standard}.
As experiências realizadas mostram que o JepREST permite detetar problemas de correção das aplicações que apenas surgem 
devido à concorrência entre múltiplos clientes. 

%
%
%Através das experiências feitas, concluímos que o JepRest ao executar um teste várias vezes consegue detetar diferentes problemas na implementação da aplicação REST em estudo. Nos exemplos das experiências feitas, demonstrados na secção \ref{eval}, na primeira execução do teste -- Experiência 1 --  foi detetado um erro de implementação na operação GET onde é retornado o estudante com o identificador dado, e na segunda execução do mesmo teste -- Experiência 2 -- foi detetado outro problema, mas desta vez foi na implementação da operação PUT, onde é feita a atualização do estudante com o identificador dado. 
%\vspace{-0.3cm}
%\paragraph{\textbf{Trabalho Futuro}}

O sistema JepREST encontra-se ainda em desenvolvimento, em particular as seguintes funcionalidades.
Primeiro, o suporte à execução das aplicações está a ser estendido para suportar a injeção de falhas durante a execução.
As falhas a introduzir serão especificadas pelos programadores num ficheiro de \textit{script}.
Segundo, pretende-se suportar operações que implementam diferentes semânticas, incluindo a possibilidade de definir transações.
Para tal, será necessário usar o Elle~\cite{jepsenElleGitHub} para verificar a correção do aplicação.


%A implementação do sistema JepRest pode ser melhorada, de forma a cobrir uma área maior de erros que possam existir em APIs REST. Idealmente, o JepRest realizaria o processo de teste a vários servidores REST onde também seriam injetadas algumas falhas de forma ao JepRest poder avaliar o comportamento do sistema em condições extremas. Para além disto, poderia-se extender o JepRest de forma a suportar a verificação em operações mais complexas e, por sua vez, com semânticas diferentes. Outra melhoria que poderia também ser implementada, seria utilizar um método mais eficiente para verificar a correção de uma aplicação. Por exemplo, em vez de utilizar o \textit{checker} Knossos que tem uma complexidade exponencial, poderia-se utilizar o \textit{checker} Elle, também do Jepsen, que tem uma complexidade praticamente constante. 
%Por fim, também se poderia melhorar o JepRest de forma a torná-lo mais \textit{black-box}, ou seja, poderia-se processar uma especificação da API REST mais independente do código, como por exemplo, uma especificação do OpenAPI.


% the environments 'definition', 'lemma', 'proposition', 'corollary',
% 'remark', and 'example' are defined in the LLNCS documentclass as well.
%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%\bibliographystyle{splncs04}
%\bibliography{bibliography}
%\end{document}
%\vspace{-0.45cm}
%\newpage
{\footnotesize
\vspace{-0.2cm}
\paragraph*{Agradecimentos:}
Agradecemos a Kyle Kingsbury pelos comentários ao sistema JepREST.
Este trabalho foi parcialmente financiado pelos projectos 
UIDB/04516/2020, %LISBOA-01-0145-FEDER-032662/
PTDC/CCI-INF/32662/2017 e PTDC/CCI-INF/32081/2017 da FCT/MCTES.
}
%\vspace{-0.3cm}
\begin{thebibliography}{10}
%\providecommand{\url}[1]{\texttt{#1}}
%\providecommand{\urlprefix}{URL }
%\providecommand{\doi}[1]{https://doi.org/#1}
%\vspace{-0.4cm}
\bibitem{load_testing_tools}
{15 Top Load Testing Tools for 2021 (Open Source Guide)}.
  \url{https://testguild.com/load-testing-tools}, accessed in July 2021

\bibitem{Locust}
{An open source load testing tool.} \url{https://locust.io/}, accessed in July
  2021

\bibitem{JMeter}
{Apache JMeter}. \url{https://jmeter.apache.org/}, accessed in July 2021

\bibitem{artillery-docs}
{Artillery?} \url{https://artillery.io/}, accessed in July 2021

\bibitem{Taurus}
{Codename Taurus}. \url{https://gettaurus.org/}, accessed in July 2021

\bibitem{consistency}
{Consistency Models}. \url{https://jepsen.io/consistency}, accessed in February
  2021

\bibitem{faker}
{Faker’s documentation!} \url{https://faker.readthedocs.io/}, accessed in
  July 2021

\bibitem{jepsenwebsite}
{Jepsen}. \url{https://jepsen.io/}, accessed in June 2021

\bibitem{jepsenKnossosGitHub}
{Knossos}. \url{https://github.com/jepsen-io/knossos}, accessed in June 2021

\bibitem{openAPI}
{OpenAPI Specification}. \url{https://swagger.io/specification/}, accessed in
  July 2021

\bibitem{curl}
{cURL}. \url{https://curl.se/} (1998), accessed in June 2021

\bibitem{soapui}
{SoapUI}. \url{https://www.soapui.org/} (2006), accessed in June 2021

\bibitem{reqbin}
ReqBin: Online rest \& soap api testing tool (2018), accessed in June 2021

\bibitem{dredd}
Dredd. \url{https://dredd.org/en/latest/index.html} (2020), accessed in June
  2021

\bibitem{postman}
Postman. \url{https://learning.getpostman.com/} (2020), accessed in June 2021

\bibitem{Alvaro17Abstracting}
Alvaro, P., Tymon, S.: Abstracting the geniuses away from failure testing:
  Ordinary users need tools that automate the selection of custom-tailored
  faults to inject. Queue  \textbf{15}(5),  29–53 (Oct 2017).

\bibitem{Freitas16Characterizing}
Freitas, F., Leitao, J., Pregui\c{c}a, N., Rodrigues, R.: Characterizing the
  consistency of online services (practical experience report). In DSN 2016.
   pp. 638--645 (2016).
  
\bibitem{linearizability}
Herlihy, M.P., Wing, J.M.: Linearizability: A correctness condition for
  concurrent objects. ACM Trans. Program. Lang. Syst.  \textbf{12}(3),
  463–492 (Jul 1990). %\doi{10.1145/78969.78972}.

\bibitem{jiang2008automatic}
Jiang, Z.M., Hassan, A.E., Hamann, G., Flora, P.: Automatic identification of
  load testing problems. In: ICSME 2008. pp. 307--316. IEEE (Sep 2008)

\bibitem{jepsenElleGitHub}
Kingsbury, K., Alvaro, P.: Elle: Inferring isolation anomalies from
  experimental observations. Proc. VLDB Endow.  \textbf{14}(3),  268–280 (Nov
  2020)

\bibitem{Madeira00Emulation}
Madeira, H., Costa, D., Vieira, M.: On the emulation of software faults by
  software fault injection. In DSN 2000.
  p. 417–426. (Jun 2000)

\bibitem{faultsee}
Matos, M., Pardal, M., Amaral, M.A.P., Mercier, H.: Faultsee: Reproducible
  fault injection in distributed systems. In EDCC 2020 (Sep 2020)

\bibitem{Natella16Assessing}
Natella, R., Cotroneo, D., Madeira, H.S.: Assessing dependability with software
  fault injection: A survey. ACM Comput. Surv.  \textbf{48}(3) (Feb 2016).

\bibitem{nidhra2012black}
Nidhra, S., Dondeti, J.: Black box and white box testing techniques - a
  literature review. International Journal of Embedded Systems and Applications
  \textbf{2}(2),  29--50.% (2012)

\bibitem{tese}
Ribeiro, A.: {Invariant-Driven Automated Testing}. Master's thesis, 
Universidade Nova de Lisboa, Lisboa (2021)

\bibitem{nftape}
Stott, D., Floering, B., Burke, D., Kalbarczpk, Z., Iyer, R.: {NFTAPE}: a
  framework for assessing dependability in distributed systems with lightweight
  fault injectors. In IPDS 2000. pp. 91--100 (Mar 2000).

\bibitem{cobra}
Tan, C., Zhao, C., Mu, S., Walfish, M.: Cobra: Making transactional key-value
  stores verifiably serializable. In: OSDI 2020. pp. 63--80. (Nov 2020).

\bibitem{netflix}
Tseitlin, A.: The antifragile organization. Commun. ACM  \textbf{56}(8),
  40–44 (Aug 2013). %\doi{10.1145/2492007.2492022},

\end{thebibliography}

\end{document}
