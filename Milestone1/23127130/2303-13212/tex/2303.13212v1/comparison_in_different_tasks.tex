\begin{table}[t]
\centering
\setlength{\tabcolsep}{4pt}
\begin{tabular}{lccc}
\toprule
\textbf{Task} & \textbf{Cls} & \textbf{Det} & \textbf{Seg} \\
\textbf{Metric} & \textbf{Top-1 Acc} & \textbf{BBox mAP} & \textbf{mIoU} \\
\midrule
\textbf{\gc{Student}} & \gc{69.9} & \gc{36.5} & \gc{69.9} \\
\textbf{\gc{Teacher}} & \gc{73.6} & \gc{41.0} & \gc{75.9} \\
\midrule
\textbf{Identity} & 70.3 (+0.4) & 38.8 (+2.3) & 46.2 (-23.7) \\
\textbf{Linear} & 71.0 (+1.1) & 39.3 (+2.8) & 71.4 (+1.5) \\
\textbf{Task-Specific$^{*}$} & 70.9 (+1.0) & 39.3 (+2.8) & 72.4 (+2.5) \\
\textbf{MLP(ours)} & 71.5 (+1.6) & 39.5 (+3.0) & 73.5 (+3.6) \\
\bottomrule
\multicolumn{4}{l}{$^{*}$ We use TaT~\cite{lin2022tat} in Cls and Seg, FGD~\cite{yang2022fgd} in Det}\\
\end{tabular}
\vspace{-2mm}
\caption{
% Comparison of various transformation methods in knowledge distillation across different computer vision tasks, including classification(Cls), Segmentation(Seg) and Detection(Det). 
Comparison of various transformation methods in knowledge distillation for classification(Cls), Segmentation(Seg) and Detection(Det) tasks. 
%The "Direct" approach directly mimics features using the l2-distance metric, the "Linear" approach employs a linear conv1x1 transformation,
%while the "Task-Specific" method utilizes established techniques specifically designed for each task. % such as TaT-Cls~\cite{lin2022tat} for classification, FGD~\cite{yang2022fgd} for object detection, and TaT-Seg~\cite{lin2022tat} for semantic segmentation.
% Further details can be found in the Appendix.
% The results demonstrate that with equal channel numbers, channel-wise transformation can still improves performance, and direct feature mimicking may reduce performance in some cases
Teacher and student feature maps have the same number of channels. 
Distillation with the help of the transformation module can improve student performance compared to direct mimics. 
}
\vspace{-2mm}
\label{table:DifferentTasks}
\end{table}