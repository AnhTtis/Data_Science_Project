\begin{figure*}
    \centering
    \includegraphics[width = \textwidth]{channel_analysis.pdf}
    \caption{
    An example to illustrate that the MLP module serves as a semantic ``translator''. Left: We adopt a similar way with \cite{yang2022fgd} to calculate the channel-wise attention map, observe the value distribution on different channels, and find that though the student model after distillation shows different distribution to the teacher model, it becomes similar to the channel attention map after the MLP module. Right: Activation patterns of the teacher feature, distilled student feature, and feature after MLP module.
    }
    % \vspace{-2mm}
    \label{fig:visual_activation}
\end{figure*}