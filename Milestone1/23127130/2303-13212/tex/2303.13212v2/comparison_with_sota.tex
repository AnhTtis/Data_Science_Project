\begin{table}[t]
\centering
% \small
\setlength{\tabcolsep}{5pt}
\begin{tabular}{ccccccc}
\toprule
& & Cls & Det & Ins Seg & Seg & \#Hyper \\
\midrule
KR\cite{reviewkd} & & \bf{+2.5} & - & - & - & 2\\
FGD\cite{yang2022fgd} & & - & +3.1 & +2.4 & - & 5 \\
CWD\cite{shu2021cwd} & & - & - & - & +3.2 & 2\\
MGD\cite{yang2022mgd} & & +2.4 & +3.3 & +2.7 & +3.3 & 2\\ \midrule
\textbf{Ours} & & +2.4 & \bf{+3.5} & \bf{+2.8} & \bf{+4.0} & \bf{1}\\
\bottomrule
\end{tabular}
\caption{
% A comparison of our method with other state-of-the-art methods on various computer vision tasks, including image classification, object detection, instance segmentation, and semantic segmentation. The number of hyperparameters is shown in the column "\#Hyper". The metrics reported are the average improvement in Top-1 accuracy (Cls), BBox mAP (Det), Mask AP (Instance Seg), and mIoU (Seg). Our method achieves state-of-the-art results while being simple and efficient, requiring fewer hyperparameters.
Comparisons of the state-of-the-art methods on image classification (Cls), object detection (Det), instance segmentation (Ins Seg), and semantic segmentation (Seg). The metrics reported are Top-1 accuracy, BBox mAP, Mask AP, and mIoU, improvement relative to students, respectively. Hyper denotes hyperparameters. 
Our method achieves state-of-the-art results with only 1 hyperparameter.
% Our method achieves state-of-the-art results while being simple and efficient, requiring fewer hyperparameters.
}
\label{table:Comparewithsota}
\vspace{-2mm}
\end{table}