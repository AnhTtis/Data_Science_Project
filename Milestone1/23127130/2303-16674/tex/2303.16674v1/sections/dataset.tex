\section{Datasets}
\label{sec:dataset}

We experiment on two datasets: CUB-200-2011 \cite{cub-200-201} and TMC-2007-500 \cite{tmc}, to explore multi-class and multi-label classification respectively. Both provide discrete attributes that are translated to propositional atoms and taken as input for our neural DNF-based models.

\subsection{CUB Dataset}

CUB-200-2011 \cite{cub-200-201} is a real-world multi-class bird classification dataset with crowd-worker-annotated bird attributes as concepts. A sample such as in Figure~\ref{fig:cub-dataset-demo} contains an image, a set of 312 attribute annotations and a class label out of 200 possible classes. To focus on scalable and interpretable rule learning form propositions, we leave the end-to-end learning from images as future work.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figure/CB-CUB_Sample_Demo.pdf}
    \caption{A sample from the CUB-200-2011 dataset before any data pre-processing. We ignore the image and the input to our neural DNF-based models would only be the attributes.}
    \label{fig:cub-dataset-demo}
\end{figure}

The attribute annotation has two components. The `present' label represents whether the sample has that attribute, where 0 means attribute not present and 1 means attribute present. The other one is the certainty label which indicates the degree of confidence of the `present' label being true. The certainty goes from 1 to 4 where 1 is not visible, 2 is guessing, 3 is probably and 4 is definitely. These attribute annotations are not consistent throughout the dataset. To de-noise it, we follow the same pre-processing procedure used in the Concept Bottleneck Models paper \cite{cbm}: compute the median of an attribute's presence label in a class, and keep it if this attribute is consistently present in at least $N$ classes, where $N$ is a hyperparameter. With different values of $N$, the data pre-processing procedure results in different numbers of attributes remaining. This procedure removes the certainty labels and unifies the attribute encoding for different samples in the same class. We provide a pseudo-code for the pre-processing procedure and further discussion in Appendix~\ref{app:data-pre-processing-cub}.

Table~\ref{tab:cub-different-dataset} provides the statistics of the CUB dataset (before and after pre-processing) and the pre-processed subsets we experiment on. These data subsets are created for the purpose of scalability check, and are generated by taking samples of the first $k$ classes (class 1 to $k$) in the original dataset, e.g. class 1 to 3 for CUB-3 subset. We apply the data pre-processing procedure with different values $N$ due to the different numbers of classes in the subsets. All our multi-class classification experiments use pre-processed CUB datasets/subsets, and, for simplicity, from now on we do not explicitly mention `after pre-processing' for each CUB dataset/subset.

\begin{table}[h]
\begin{minipage}[b]{.5\linewidth}
\tiny
\begin{tabular}{c|ccc}
Dataset/Subset                      & No. samples & No. classes & No. attributes \\ \hline
Original CUB-200-2011                  & 11788             & 200               & 312                  \\
CUB-3    & 178               & 3                 & 34                   \\
CUB-10   & 543               & 10                & 41                   \\ 
CUB-15   & 837               & 15                & 40                   \\ 
CUB-20   & 1115              & 20                & 48                   \\ 
CUB-25   & 1402              & 25                & 50                   \\ 
CUB-50   & 2889              & 50                & 61                   \\ 
CUB-100  & 5864              & 100               & 82                   \\
CUB-200  & 11788             & 200               & 112                  \\
\end{tabular}
\subcaption{Statistics of different CUB datasets/subsets.}
\label{tab:cub-different-dataset}
\end{minipage}%
\begin{minipage}[b]{.5\linewidth}
\tiny
\begin{tabular}{c|ccc}
Dataset/Subset           & No. samples    & No. labels & No. attributes \\ \hline
Original TMC2007-500     & 28596          & 22             & 500\\
TMC-3  & 16947           & 3              & 59                 \\
TMC-5  & 18565           & 5              & 60                 \\
TMC-10 & 21454           & 10             & 34                 \\
TMC-15 & 24318           & 15             & 80                 \\
TMC-22 & 28538           & 22             & 103                \\
\end{tabular}
\subcaption{Statistics of different TMC datasets/subsets.}
\label{tab:tmc-different-datasets}
\end{minipage}
\caption{Data statistics for CUB and TMC dataset/subsets. Except for `Original CUB-200-2011' and `Original TMC2007-500', all the other datasets/subsets are pre-processed. The number of samples is the sum of samples from all train, validation and test sets. We use the suffix `-k' after the dataset name to represent the number of classes/labels used in the datasets/subsets.}
\end{table}

\subsection{TMC2007-500}

TMC2007-500 \cite{tmc} is a texted-based multi-label classification dataset based on space shuttle reports, and the goal is to identify different types of anomalies from the text. The dataset provides 500 discrete attributes along with 22 labels, while the reports and actual anomalies are not revealed due to their sensitivity. A sample from the dataset is shown in Figure~\ref{fig:tmc-sample}. The attributes themselves are words, making the input similar to an NLP bag-of-words encoding where each bit of the encoding represents if a word appears in the report. For this reason, we apply data pre-processing (detailed in Appendix~\ref{app:data-pre-processing-tmc}) to filter out attributes with low mutual information (MI) with respect to the output label combinations (not on individual labels). Only attributes with MI values greater or equal to a threshold $t$ are kept.

Similar to the CUB dataset, we create subsets and apply the pre-processing on each subset. Table \ref{tab:tmc-different-datasets} shows the statistics of the datasets/subsets after pre-processing. We apply different MI thresholds during pre-processing on different subsets, resulting in different numbers of attributes used in each subset.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\linewidth]{figure/TMC_Sample.pdf}
    \caption{A sample from the TMC2007-500 dataset before any data pre-processing. The dataset does not explicitly give the names of the anomalies for each label.}
    \label{fig:tmc-sample}
\end{figure}
