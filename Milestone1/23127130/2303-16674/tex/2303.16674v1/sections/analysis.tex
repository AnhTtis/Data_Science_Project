\section{Analysis} \label{chap:analysis}

We analyse our neural DNF-based models further in the three areas of \textit{classification performance}, \textit{interpretability}, and \textit{scalability} to compare against the baselines of MLPs, decision trees and FastLAS \cite{fastlas}.

\textbf{Classification performance}\ \ \ \ Our neural DNF-based models learns as well as their MLP counterparts when general patterns exist in the dataset\footnote{To further support this statement, we also construct synthetic datasets for both multi-class and multi-label classification tasks. The data points are generated based on a set of rules such that the data points follow general patterns/show regularities. We train neural DNF-based models on them, and in both scenarios, our models learn almost perfectly, and we can extract symbolic rules. See more details in Appendix~\ref{app:synthetic}}. In CUB experiments, our neural DNF-EO model always achieves test accuracy of 1 as the MLP (Table~\ref{tab:cub-acc-comp}), but also gives test Jaccard index score of 1 and provides mutual exclusion which an MLP trained with cross-entropy cannot provide. Although the TMC experiments show a difference in performance, we speculate that the dataset lacks general patterns/regularities as discussed in Chapter~\ref{sec:tmc-experiments-baseline-comparison}, and the loss plot (Figure~\ref{fig:tmc-dnf-loss}) suggests that the logically constrained bias in our vanilla neural DNF model increases the difficulty of training. In regards to decision trees, our models have a different learning mechanism, and TMC dataset/subsets do not fully reflect the end-to-end learning capability of our models: the data instances in the dataset/subsets cannot be easily encoded in features with low dimensionality, making it hard for our models (and also MLPs) to generalise without overfitting, while decision trees without a depth limit overfit. But when data points in the dataset/subset follow some general patterns, such as the CUB dataset/subsets, our models perform equally well as decision trees (Table~\ref{tab:cub-acc-comp}).

\textbf{Interpretability}\ \ \ \ The logically constrained bias in the semi-symbolic layers makes it possible to extract symbolic rules from our models through post-training processes, contrasting to the lack of interpretability in MLPs. However, as shown in the CUB experiments (Table~\ref{tab:dnf-eo-cub}), our current process does not always result in a successful rule extraction for multi-class classification. The thresholding process is the current bottleneck of the pipeline, as it cannot maintain mutual exclusivity across a large number of classes. Our rules are also not guaranteed to be in the most compact form compared to FastLAS (Figure~\ref{fig:cub-rules-comp}). FastLAS with a scoring function on body length will guarantee the most compact hypothesis, while we do not have a strong signal for the neural DNF-based models to learn the most compact rules, which may further restrict gradient-based learning. Although we do include an L1 regulariser during training and prune the model at post-training processes, it does not necessarily reject hypotheses with longer rules. On the other hand, decision trees show less compactness than rules extracted from our neural DNF-based models, and also are prone to overfitting. 

\textbf{Scalability}\ \ \ \ Our neural DNF-based models scale better than FastLAS. The conjunctive and disjunctive layers of the neural DNF-based model create a hypothesis space that allows rules with any combination of body atoms, and through gradient descent, the model moves towards an approximated hypothesis. FastLAS first needs to compute a hypothesis sub-space that guarantees to contain the optimal solution and may run out of memory during this computation process, which is what happens in the CUB-200 experiment and all TMC experiments. Comparing our model to MLP and decision tree, all three are trainable under the same setting regardless of the input/output size. However, training the neural DNF-based model is more difficult than an MLP (Figure~\ref{fig:tmc-dnf-loss}), and the thresholding process in the post-training pipeline does not yield perfect rules from the trained model anymore after 20 classes (Table~\ref{tab:dnf-eo-cub}).

To summarise, (i) our neural DNF-based model performs as well as an MLP and a decision tree when general patterns exist in the dataset; (ii) it has better interpretability than an MLP by providing ASP rules, and the rules are in average more compact than a decision tree's decision paths; (iii) it also scales better than FastLAS when the hypothesis search space is large.
