\section{Conclusion and Future Work}

Building upon pix2rule \cite{pix2rule}, we propose a novel neural DNF-EO model to support learning and symbolic rule extraction in real-world multi-class classification, while using the vanilla neural DNF model similar to pix2rule's neural DNF module for multi-label classification tasks. Our evaluations show that when the data have underlying general patterns, our neural DNF-based models learn as well as the MLPs while also providing symbolic rules after post-training processes. Our neural DNF-EO model also provides mutual exclusivity, which MLPs with cross-entropy loss cannot provide. Our models also scale better than FastLAS \cite{fastlas} over large hypothesis search space and can be trained with large numbers of inputs/outputs. Compared to decision trees, our models learn more compact rules and provide end-to-end training capability with other differentiable models.

In future work, we aim towards end-to-end neuro-symbolic rule learning with our neural DNF-based models from unstructured input, such as the task of learning from images in the CUB dataset \cite{cub-200-201}. By connecting our model to other neural networks, the full architecture will first translate low-level signals to high-level representation and then learn symbolic rules. Apart from this, the neuro DNF-EO model's perfect Jaccard index score in the multi-class CUB-20 experiment (48 attributes and 20 classes) gives a promising direction of taking the model into reinforcement learning environments for interpretable policy learning. Many reinforcement environments, such as maze navigation and driving simulation \textit{highway-env} \cite{highway-env}, provide a small number of action choices and the agents can only pick exactly one action at a time. The neural DNF-EO model's symbolic enforcement of mutual exclusivity and its interpretability would make it more favoured than vanilla deep learning approaches. In another direction, taking our neural DNF-based models back to ILP benchmarks would give a better picture of our models' learning capability compared to other classical ILP and differentiable ILP approaches. 

\clearpage