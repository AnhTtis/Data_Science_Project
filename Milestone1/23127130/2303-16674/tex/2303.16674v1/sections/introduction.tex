\section{Introduction}

The recent success of deep learning has started to bring transformative impacts in different sectors of our society. However, they are not interpretable and cannot be used to solve real-world problems that require safe and sound reasoning. There has been an increasing interest in neuro-symbolic approaches that combine symbolic reasoning with neural networks \cite{nsai-3-wave}. Some of these approaches have proposed differentiable models that support inductive learning of symbolic rules~\cite{pix2rule, delta-ilp, lri, lnn-ilp, hri, nlm, dnl-ilp, dlm}. Similarly to pure logic-based learning (e.g. Inductive Logic Programming (ILP) \cite{ilp}), these differentiable ILP methods aim to learn interpretable rules from positive and negative examples, but they do so using pure statistical mechanisms. Most approaches have been shown to perform well over classical ILP benchmark tasks where data are symbolic~\cite{delta-ilp, lri, hri, nlm, dnl-ilp, dlm}, whereas a few have been applied to unstructured data for learning rules capable of solving classification tasks~\cite{pix2rule}. Many of the proposed differentiable ILP approaches rely on human-engineered rule templates to restrict their search space~\cite{delta-ilp, lri, lnn-ilp, hri}, and these templates are often limited in their expressivity since they allow predominantly Datalog chain rules. Approaches that do not require rule templates either lose interpretability~\cite{nlm}, or resort to additional tricks, e.g., to treat negation in a specific way~\cite{dlm}. On the other hand, \textit{pix2rule} \cite{pix2rule} presents a neural model capable of learning \textit{interpretable} rules from unstructured data in an end-to-end fashion \textit{without} the use of template rules. The model uses a \emph{Disjunctive Normal Form (DNF)} module that has two feed-forward layers and enables learning over a large search space of interdependent rules with negation. Although shown to be effective in solving binary classification tasks, it has only been empirically evaluated over synthetic data.

In this paper, we build upon pix2rule's neural DNF module to support rule learning in \textit{real-world multi-class} and \textit{multi-label} classification tasks. We investigate the learning capability of the \emph{vanilla neural DNF model} similar to the neural DNF module in pix2rule on real-world multi-label classification tasks. We also propose a novel model called \emph{neural DNF-EO (Exactly-One)} for multi-class classification to address its requirement of mutual exclusivity, i.e. having exactly one class to be true at a time. In a symbolic learner, logical constraints enforce mutual exclusion, but a vanilla MLP is not able to strictly enforce it with a cross-entropy loss. Our neural DNF-EO model is trained with a cross-entropy loss but enforces mutual exclusion, realising the symbolic constraint in a differentiable fashion. We evaluate our models over two real-world datasets, the multi-class dataset CUB-200-2011 \cite{cub-200-201} and its subsets, and the multi-label dataset TMC2007-500 \cite{tmc} and its subsets. We focus on exploring (i) the classification performance and scalability of our models over an increasing number of discrete attributes, and (ii) the interpretability of the learned rules versus other pure symbolic and statistical methods such as decision trees. Our experimental results show that our neural DNF-based models perform as well as pure neural networks, whilst providing symbolic rules through post-training processes. They scale better than a state-of-the-art pure symbolic rule learner FastLAS \cite{fastlas} over large search spaces. Our models successfully solve all tasks while FastLAS fails to learn in multi-class classification tasks with 200 classes and in all multi-label settings. Compared to other differentiable ILP methods (e.g.,\cite{delta-ilp, nlm, dlm}), our neural DNF-based models do not require human-engineered rule templates, provide interpretability by enabling extraction of symbolic rules after training, and handle logical negation without special treatment.
