%\paragraph{KG Relation Patterns}
%An overriding goal in KG embedding methods has been to learn KG representation while capturing distinct latent logical/relation patterns (symmetry/anti-symmetry, composition, and inversion). A plethora of approaches has been presented to generate representations of KGs \citep{TransE, DistMult, ComplEx, RotatE, TransH}. Except for RotatE, which can capture all of them in complex space, most of them can explicitly or implicitly model one or more of the aforementioned patterns. However, all of these KG embedding methods only focus on the link prediction task or single-hop queries but are limited in answering multi-hop and first-order logical queries.
%\paragraph{Complex query answering}
%Here we review the query answering methods as follows.
To answer more complex queries, a number of path-based \citep{deeppath,lin-etal-2018-multi}, neural \citep{GQE,Query2box,BiQE}, and neural-symbolic \citep{CQD,GNNQE} methods have been developed. Among these methods, geometric and probabilistic query embedding approaches \citep{GQE,Query2box,ConE,BetaE} provide a way to tractably handle first-order logic operators in queries and equip excellent computing efficiency. This is done by representing entity sets as geometric objects or probability distributions, such as boxes \citep{Query2box}, cones \citep{ConE}, or Beta distribution \citep{BetaE}, and performing neural logical operations directly on them. In this way, the expensive search for intermediate variables in multi-hop queries is avoided. %The Graph Query Embedding (GQEs) \citep{GQE} was first proposed to answer only conjunctive queries via modeling the query as single vector $\bf{q}$ through geometric translational operators. However, representing a query as a single vector limits the model's expressiveness in modeling multiple entities. Query2Box \citep{Query2box} remedies this flaw by modeling entities as points within boxes. This allows Q2B to predict the intersection of entity sets as the intersection of boxes in vector space. 
%ConE \citep{ConE} is proposed as the first geometry-based query embedding method that can handle complete FOL queries via embedding the set of entities (query embedding) as cones in Euclidean space.% 
All of the above query embedding methods commonly apply multi-layer perceptron networks for selecting answer entities of atomic queries by relation and performing logical operations. Thus, their ability to capture relation patterns in KGs remains unclear. Our proposed method RoConE fills in this gap and combines the benefits of both worlds (KG embedding and complex query answering) together.
