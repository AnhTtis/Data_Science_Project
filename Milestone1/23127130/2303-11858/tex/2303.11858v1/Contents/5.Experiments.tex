\begin{table}
\centering
\resizebox{\hsize}{!}{
\begin{tabular}{lllllllllll}
\hline
 \textbf{Dataset} & \textbf{Model} & \textbf{1p} & \textbf{2p} & \textbf{3p} & \textbf{2i} & \textbf{3i} & \textbf{pi} & \textbf{ip} & \textbf{2u} & \textbf{up}\\
\hline
 & GQE & 35.2 & 7.4	& 5.5 & 23.6 & 35.7 & 16.7 & 10.9 & 8.4 & 5.8\\
 & Query2Box & 41.3 & 9.9 & 7.2 & 31.1 & 45.4 & 21.9 & 13.3 & 11.9 & 8.1\\
FB15k-237 & BetaE & 39.0 & \underline{10.9} & \underline{10.0} & 28.8 & 42.5 & 22.4 & 12.6 & 12.4 & \underline{9.7}\\
 & ConE & 41.8 & \textbf{12.8} & \textbf{11} & \underline{32.6} & 47.3 & \textbf{25.5} & 14.0 & \textbf{14.5} & \textbf{10.8}\\
 & RoConE & \textbf{42.2} & 10.5 & 7.5 & \textbf{33.5} & \textbf{48.1} & \underline{23.5} & \textbf{14.5} & \underline{12.8} & 8.9\\
\hline
 & GQE & 33.1 & 12.1 & 9.9 & 27.3 & 35.1 & 18.5 & 14.5 & 8.5 & 9.0\\
 & Query2Box & 42.7 & 14.5 & 11.7 & 34.7 & 45.8 & 23.2 & 17.4 & 12.0 & 10.7\\
NELL995 & BetaE & 53.0 & 13.0 & 11.4 & 37.6 & 47.5 & 24.1 & 14.3 & 12.2 & 8.5\\
 & ConE & \underline{53.1} & \underline{16.1} & \underline{13.9} & \underline{40.0} & \underline{50.8} & \textbf{26.3} & \underline{17.5} & \underline{15.3} & \underline{11.3}\\
 & RoConE & \textbf{54.5} & \textbf{17.7} & \textbf{14.4} & \textbf{41.9} & \textbf{53.0} & \underline{26.1} & \textbf{20.7} & \textbf{16.5} & \textbf{12.8}\\
\hline
\end{tabular}
}
\caption{
MRR results (\%) of RoConE, BETAE, Q2B, and GQE on answering EPFOL ($\exists, \land, \lor$) queries. The best statistic is highlighted in bold, while the second best is highlighted in underline.
}
\label{EPFOL}
\end{table}

\paragraph{Experiment setup}
We evaluate RoConE on two benchmark datasets NELL995 \citep{NELL995} and FB15k-237 \citep{FB15k-237}. RoConE is compared with various state-of-the-art query embedding models. Mean reciprocal rank (MRR) is used as the metric. More experimental details are in Appendix \ref{Experiment}. 

\paragraph{Main results}
Table \ref{EPFOL} summarizes the performance of all methods on answering various query types without negation. 
% compared with baselines that can only model EPFOL (Existential Positive First-Order Logical) with conjunction and disjunction without negation. 
RoConE outperforms baseline methods on the majority of query types while achieving competitive results on the others. We also observed that RoConE shows better performances on NELL-995 than those on FB15k-237. We conjecture that this is due to the discrepancy in the distribution of relation patterns between these two datasets.
% It demonstrates that RoConE outperforms the state-of-the-art query embedding models on both datasets across the majority of EPFOL query types. It is noticed that RoConE shows better performances on reasoning multi-hop queries from NELL995 than those from FB15k-237. We suspect this is due to the discrepancy in the distribution of relation patterns between these two datasets.
As Table \ref{Negation results} shows, RoConE does not bring many improvements for answering query types involving negation. There are two folds of possible reasons that might lead to this result. Firstly, the traditional modeling of negation as complements may be problematic, which can be reflected in the poor performance of all existing QE models. This largely brings too much uncertainty into the query embedding and leads to severe bias in prediction. Secondly, the influence of relation patterns on negation queries is limited when we model negation as complements. % On the other hand, the learning of relation patterns does not bring improvements to the queries with negation. There are two folds of possible reasons that might lead to this result. Firstly, the traditional modeling of negation as complements may be problematic, at least, this largely brings too much uncertainty into the query embedding, which leads to severe bias in prediction. Secondly, the influence of relation patterns on negation queries is limited when we model negation as complements. 

\begin{table}[ht]
\centering
\resizebox{\hsize}{!}{
\begin{tabular}{lllllll}
\hline
 \textbf{Dataset} & \textbf{Model} & \textbf{2in} & \textbf{3in} & \textbf{inp} & \textbf{pin} & \textbf{pni}\\
\hline
 \multirow{3}{5em}{FB15k-237} & BetaE & 5.1 & 7.9 & 7.4 & 3.6 & 3.4\\
 & ConE & \textbf{5.4} & \textbf{8.6} & \textbf{7.8} & \textbf{4.0} & \textbf{3.6}\\
 & RoConE & 4.1 & 7.9 & 6.9 & 3.1 & 2.8\\
\hline
\multirow{3}{4em}{NELL995} & BetaE & 5.1 & 7.8 & 10 & 3.1 & 3.5\\
 & ConE & \textbf{5.7} & \textbf{8.1} & \textbf{10.8} & \textbf{3.5} & \textbf{3.9}\\
 & RoConE & 5.2 & 7.7 & 9.4 & 3.2 & 3.7\\
\hline
\end{tabular}
}
\caption{
MRR results (\%) of RoConE, BETAE, and ConE on answering queries with negation ($\neg$).
}
\label{Negation results}
\end{table}

\paragraph{Ablation study}
To investigate the influence of relation patterns on the query answering model, we designed an ablation study for RoConE on NELL995. The results are reported in Table \ref{ablation study}. RoConE (Base) denotes the neural baseline model without the relational rotating projection module. RoConE (S.E) and RoConE (Trunc) correspond to two variants of RoConE with different rotation strategies. More details are elaborated in Appendix \ref{Variants of RoConE}. The overperformance of RoConE and RoConE (truncation) reconfirms the efficiency of relation patterns in logical query reasoning tasks.

\begin{table}[ht]
\centering
\resizebox{\hsize}{!}{
\begin{tabular}{llllllllll}
\hline
 \textbf{Model} & \textbf{1p} & \textbf{2p} & \textbf{3p} & \textbf{2i} & \textbf{3i} & \textbf{pi} & \textbf{ip} & \textbf{2u} & \textbf{up}\\
\hline
RoConE (Base) & 53.1 & 16.1 & 13.9 & 40 & 50.8 & 26.3 & 17.5 & 15.3 & 11.3\\
RoConE (S.E.) & 51.3 & 16.6 & 13.8 & 38.4 & 48.4 & 18.9 & 19.5 & 14.7 & 12.1\\
RoConE (Trunc) & 53.7 & \textbf{17.8} & 14.2 & \textbf{41.9} & \textbf{53.0} & \textbf{27.5} & 20.4 & \textbf{16.6} & 12.7 \\
RoConE & \textbf{54.5} & 17.7 & \textbf{14.4} & \textbf{41.9} & \textbf{53.0} & 26.1 & \textbf{20.7} & 16.5 & \textbf{12.8}\\
\hline
\end{tabular}
}
\caption{
Ablation study of RoConE on NELL995
}
\label{ablation study}
\end{table}


