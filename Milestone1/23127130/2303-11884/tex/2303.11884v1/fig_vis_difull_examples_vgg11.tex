\begin{figure}[H]
    \centering
    \includegraphics[width=0.55\linewidth]{figures/vis_imagenet_aggatt_examples_vgg19_Disconnected_input.png}
    \caption{\textbf{Examples from each \aggatt bin for each method at the input layer on \difull using VGG19.} From each bin, the image and its attribution at the median position are shown.}
    \label{fig:vis:examples:difull:vgg11:input}
\end{figure}
At the final layer (\cref{fig:vis:examples:difull:vgg11:final}), the backpropagation-based methods and \layercam still show perfect localization, for the same reason as discussed above. Attributions from \grad and \gb show similar artifacts as seen with \gridpg (\cref{sec:qual:gridpg}), but are localized to the top-left cell. The activation-based methods apart from \layercam concentrate their attributions at the top-left and bottom-right grid cells, particularly in the early bins. This is because both these cells contain images from the same class, and the weighing of activation maps by these methods using a scalar value causes both to be attributed, even though only the instance at the top-left influences the classification. Further, \occ and \rise show similar results as at the input layer. The attributions of \occ are noticeably lower in resolution, since the relative size of the occlusion kernel as compared to the activation map is much larger at the final layer.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.55\linewidth]{figures/vis_imagenet_aggatt_examples_vgg19_Disconnected_final.png}
    \caption{\textbf{Examples from each \aggatt bin for each method at the final layer on \difull using VGG19.} From each bin, the image and its attribution at the median position are shown.}
    \label{fig:vis:examples:difull:vgg11:final}
\end{figure}