\begin{figure}[H]
    \centering
    \includegraphics[width=0.55\linewidth]{figures/vis_imagenet_aggatt_examples_vgg19_PointingGame_input.png}
    \caption{\textbf{Examples from each \aggatt bin for each method at the input layer on \gridpg using VGG19.} From each bin, the image and its attribution at the median position are shown.}
    \label{fig:vis:examples:gridpg:vgg11:input}
\end{figure}
At the final layer (\cref{fig:vis:examples:gridpg:vgg11:final}), attributions from \grad \cite{simonyan2013deep} and \gb \cite{springenberg2014striving} are very noisy and only slightly concentrate at the top-left cell. The checkerboard-like pattern is a consequence of the max pooling operation after the final layer, which allocates all the gradient only to the maximum activation. Gradients from each position of the sliding classification kernel then get averaged to form the attributions. The localization of \intgrad \cite{sundararajan2017axiomatic}, \ixg, \gradcam \cite{selvaraju2017grad}, and \occ \cite{zeiler2013visualizing} improve considerably as compared to the input layer, which agrees with the quantitative results, and shows that diverse methods can show similar performance when compared fairly. The performance of the other activation-based methods and \rise \cite{petsiuk2018rise} improves to some extent, but is still poorly localized for around the half the dataset.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.55\linewidth]{figures/vis_imagenet_aggatt_examples_vgg19_PointingGame_final.png}
    \caption{\textbf{Examples from each \aggatt bin for each method at the final layer on \gridpg using VGG19.} From each bin, the image and its attribution at the median position are shown.}
    \label{fig:vis:examples:gridpg:vgg11:final}
\end{figure}