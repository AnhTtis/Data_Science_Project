\section{Implications}
In this section, we highlight the implications for different stakeholders in AI systems.

\mypar{Implications to AI Practitioners}
Practitioners should be aware of the differences between \greenai{} and \redai{} and the energy-efficient practices that we have laid bare in this study. As such, when developing and tuning new deep learning models, developers should look beyond the realm of baseline optimisation strategies and opt for more advanced techniques such as Bayesian optimisation. Another valid approach is to outsource this part of the training pipeline and implement existing solutions such as the population-based training algorithm from Ray Tune\footnote{\href{https://docs.ray.io/en/latest/tune/tutorials/tune-advanced-tutorial.html}{https://docs.ray.io/en/latest/tune/tutorials/tune-advanced-tutorial.html}}.  

\mypar{Implications to Software Engineers} Software engineers are already incorporating transdisciplinary AI teams to enable the productionisation of AI models. We argue that the role of software engineers is quintessential to enable energy-aware AI pipelines. One cannot ask regular AI practitioners to engineer the collection of energy-efficiency metrics -- it is important that software engineers have the right knowledge and experience to help include energy as an important factor when developing AI pipelines.

\mypar{Implications to AI tool developers}
Our results show that AI frameworks have to provide green alternatives. For example, there are not many options when selecting hyperparameter strategies. Moreover, there is no information about the energy efficiency of these alternatives. Hence, our results call for more energy-efficient options and better documentation with sustainability tips, in line with previous findings in \greenai{}~\cite{Georgiou2022May}.

\mypar{Implications to Researchers}
In the past four years, several works have emerged that call for a research agenda that considers energy efficiency in AI~\cite{bender2021dangers,strubell2019energy,schwartz2020green}. Past these positional papers, the number of hands-on studies is still very limited. Researchers should answer the call by building on our results w.r.t. hyperparameter tuning and efficient network architectures, or explore new areas of energy-efficient practices. 

\mypar{Implications to Tech Organisations}
Large corporations are the biggest consumers in the field of AI. In this study, we have shown that the energy consumption of a deep learning model rises at a much faster pace than the performance. Tech organisations should make an effort to measure and report their energy consumption as a metric of equal importance to accuracy. This will change how we evaluate state-of-the-art deep learning models and encourage the development of \greenai{}.