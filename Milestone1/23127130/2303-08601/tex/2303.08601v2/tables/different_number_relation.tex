



% % Table generated by Excel2LaTeX from sheet 'Sheet1'
% \begin{table}[htbp]
%   \centering
%   \small
%   \caption{Split the test dataset of \camera and test the models on different data. N refers to the number of relation in a sentence. R-Pre, R-Rec, R-$F1$ refers to Relation-Pre, Relation-Rec, Relation-F1, respectively.}
%     \begin{tabular}{r|l|ccccc}
%   \toprule
   
%     \multicolumn{1}{l|}{N} & \multicolumn{1}{l|}{model} & \makebox[0.005\textwidth][c]{R-Pre} & \makebox[0.005\textwidth][c]{R-Rec} & \makebox[0.005\textwidth][c]{R-$F1$} \\
%     \midrule
%     \multicolumn{1}{l|}{single} & CRF   & 0.1648  & 0.2376  & 0.1946    \\
%           & BERT  & 0.2362  & 0.3536  & 0.2832   \\
%           & BERT+CRF & 0.2290  & 0.3923  & 0.2892   \\
%           & GPT2 & 0.3021  & 0.3204  & 0.3110   \\
%           & \modelname & \textbf{0.3586}  & \textbf{0.3923}  & \textbf{0.3747 }   \\
%     \midrule
%     \multicolumn{1}{l|}{double } & CRF   & 0.1193  & 0.1275  & 0.1232   \\
%           & BERT  & 0.3478  & \textbf{0.3137}  & \textbf{0.3299 }  \\
%           & BERT+CRF & 0.1985  & 0.2549  & 0.2232   \\
%           & GPT2 & \textbf{0.4091}  & 0.2872  & 0.3375    \\
%           & \modelname & 0.3944  & 0.2745  & 0.3237    \\
%     \midrule
%     \multicolumn{1}{l|}{multiple } & CRF   & 0.1515  & 0.2336  & 0.1838  \\
%           & BERT  & 0.3409  & 0.5607  & 0.4240   \\
%           & BERT+CRF & 0.4277  & \textbf{0.6916}  & \textbf{0.5286 }  \\
%           & GPT2  & 0.5116  & 0.2157  & 0.3034    \\
%           & \modelname & \textbf{0.5472}  & 0.2710  & 0.3625    \\
%     \bottomrule
%     \end{tabular}%
%   \label{tab:different_number}%
% \end{table}%


% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table}
  \centering
  \small
  \caption{Precision, recall and $F1$ on \camera, by number of comparative relations $N$ in each sentence.}
%  \caption{Split the test dataset of \camera and test the models on different data. N refers to the number of relation in a sentence. R-Pre, R-Rec, R-$F1$ refers to Relation-Pre, Relation-Rec, Relation-F1, respectively. GPT-2 refers GPT-2 model training without prompt words.}
    \begin{tabular}{c|l|ccc}
   \toprule
   
    $N$ & Model &  Precision & Recall & $F1$ \\
    \midrule
     $1$ & CRF   & 0.165  & 0.238  & 0.195  \\
          & BERT  & 0.236  & 0.354  & 0.283  \\
          & BERT-CRF & 0.229  & 0.392  & 0.289  \\
          & GPT-2 & 0.322  & 0.320  & 0.321 \\
          & \modelname& \textbf{0.386} & \textbf{0.392} & \textbf{0.389}\\
      \midrule
    $2$ & CRF  & 0.119  & 	0.138 	& 0.128  \\
          & BERT  & 0.348  & \textbf{0.340} & \textbf{0.344} \\
          & BERT-CRF & 0.198  & 0.277  & 0.231  \\
          & GPT-2 & \textbf{0.422} & 0.287  & 0.342  \\
          & \modelname  & 0.388  & 0.277  & 0.323 \\
    \midrule
    $>2$ & CRF   & 0.152  &	0.245  &	0.187  \\
          & BERT  & 0.341  & 0.588  & 0.432  \\
          & BERT-CRF & 0.428  & \textbf{0.725} & \textbf{0.538} \\
          & GPT-2 & 0.537  & 0.216  & 0.308 \\
          & \modelname & \textbf{0.600} & 0.265  & 0.367   \\
    \bottomrule
    \end{tabular}%
  \label{tab:different_number}%
\end{table}%

