Biomedical entity linking (EL) aims to identify entity mentions from biomedical free texts and link them to the pre-defined knowledge base (KB, e.g. UMLS~\cite{bodenreider2004unified}), which is an essential step for various tasks in biomedical language understanding including relation extraction~\cite{li2016biocreative,lin2020high,hiai2021relation,yu2022bios} and question answering~\cite{qareview}.

\begin{figure}
    \centering
    \small
     \includegraphics[width=0.48\textwidth]{task_overview.PNG}
    \caption{Visual illustration of partial KB inference scenario. Partial KB inference from training KB MeSH (left) to a partial KB MEDIC (right). \textit{Methylprednisolone} is not extracted since it is not in MEDIC.}
    \label{fig:task_overview}
    \vspace{-1em}
\end{figure}

EL naturally contains two subtasks: named entity recognition (NER) and named entity disambiguation (NED).
NER is designed for mention detection, while NED aims to find the best match entities from KB.
One direct way for EL is executing NER and NED sequentially~\cite{liu2020self,zhang2021knowledge,yuan2022coder}.
Neural NER and NED models are usually trained by corpora labeled with a KB.
However, potential users of biomedical EL, including doctors, patients, and developers of knowledge graphs (KGs) may only be interested in entities inside a subset of KB such as SNOMED-CT \cite{donnelly2006snomed}, one semantic type of entities in UMLS, or KB customized by medical institutions.
Besides, doctors from different medical institutions have different terminology sets. 
Some hospitals are using ICD-10, while some hospitals are still using ICD-9 and even custom terminology set.
Patients are only interested in specific diseases, symptoms, and drugs.
As for developers of KGs, they may need to build a KG for special diseases like diabetes \cite{chang2021diakg} and COVID-19 \cite{reese2021kg}, or particular relation types like drug-drug interaction \cite{lin2020kgnn}. 
All scenarios above need to infer EL using a partial KB.
Off-the-shelf models trained on a comprehensive KB will extract mentions linked to entities outside the users' KB.
% The training KB and the in
% Leveraging the pre-train then fine-tune paradigm in recent natural language processing frontiers, many studies achieve extraordinary performances on biomedical entity linking~\cite{yuan2022coder,,zhang2021knowledge}. 
% These methods take advantages of large scale pretrained language models and are trained on comprehensive huge knowledge base, such as Unified Medical Language System (UMLS) and Wikipedia.
% However, as the number of biomedical concepts is enormous and the concepts cover different fields of knowledge related to bio-medicine, the potential users of biomedical EL systems usually only concern entities in a subset of comprehensive KBs, such as entities in a semantic type of Chemicals or Diseases, SNOMED~\cite{donnelly2006snomed} (A considerably smaller KB comparing with UMLS), or other customized subsets of concepts that related to specific medical scenarios.
% Although a straightforward solution is r
Although retraining models based on users' KBs can obtain satisfactory performances, it is not feasible under most scenarios because users can have significantly different KBs and may have difficulties with computational resources in finetuning large-scale models.
Therefore, we propose a scenario focusing on inference on the partial KB.
We name this scenario \textbf{partial knowledge base inference}: Train an EL model with one KB and infer on partial of this KB without further training.
\Cref{fig:task_overview} provides a case of this scenario.
This scenario is widely faced in the medical industry but remains understudied.

%Training separated models for each subset is a straightforward way to solve this problem, but it is computationally and practically infeasible.
%A more realistic scenario is that the biomedical entity linking models are trained on annotations from a cover-all KB (e.g., UMLS) while evaluated on possible entities corresponding to a sub-KB (e.g., SNOMED CT). We name the scenario as \textbf{partial knowledge base inference}.
%Therefore, good transferability from large training KBs to small evaluation KBs is required for a biomedical linking system, while recent evaluation procedures overlook such scenario.

%Previous research made many efforts to increase the generalization of deep learning methods, as the models may over-fit the biases induced by the pattern of training samples.
%During partial KB inference, the distribution of the target mentions and concepts may alter and we investigate the performance of current  methods facing the scenario. 


This work reviews and evaluates current state-of-the-art EL methods under the partial KB inference scenario.
To be specific, we evaluate three paradigms:
(1) \textit{NER-NED} \cite{yuan-etal-2021-improving,coder},
(2) \textit{NED-NER} \cite{zhang2022entqa},
(3) \textit{simultaneous generation} \cite{genre}.
The first two paradigms are pipeline methods, whose difference is the order of NER and NED.
The last paradigm is an end-to-end method that generates mention and corresponding concepts by language models.
We construct partial KB inference datasets based on two widely used biomedical EL datasets: BC5CDR \cite{li2016biocreative} and MedMentions \cite{medmentions}.
Our experimental findings reveal the different implicit mechanisms and performance bottlenecks within each paradigm which shows partial KB inference is challenging.

We also propose two redemption methods based on our findings, \textbf{post-pruning} and \textbf{thresholding}, to help models improve partial KB inference performance effortlessly.
Post-pruning infers with a large KB and removes entities in the large KB but not in partial KB.
Post-pruning is effective but memory-unfriendly for storing embeddings of entities in the large KB.
Thresholding removes entities with scores below a threshold.
These two redemption methods are all designed to reduce the impact of NIL entities and boost EL performances.
To our best knowledge, this is the first work that researches partial KB inference in biomedical EL.
Our main contributions are the following:

\begin{itemize}[leftmargin=1em]
    \setlength\itemsep{0em}
    \item We extensively investigate partial KB inference in biomedical EL. We give a detailed definition, evaluation procedures, and open-source curated datasets.
    
    \item Experiment results show that the NED-NER paradigm behaves more robust towards partial KB inference, while the other paradigms suffer from sharp degradation caused by NIL.
    
    \item We propose two redemption techniques to address the NIL issue with little computational overhead for better partial KB inference.
    
\end{itemize}