
In this section, we present the main results of partial KB inference (\Cref{sec:main-result})
Then, we provided two redemption methods for enhancing model performance in partial KB inference (\Cref{sec:post-processing}).
In the end, we discuss the factors related to difficulties hindering partial KB inference performance (\Cref{sec:analysis}).

\begin{table*}[t]
\small 
\centering
\setlength{\tabcolsep}{1.5mm}{
\begin{tabular}{p{2mm}ll|ccc|ccc|ccc}
\toprule
& \multicolumn{2}{c}{Target KB.}& \multicolumn{3}{c}{EntQA} & \multicolumn{3}{c}{GENRE}& \multicolumn{3}{c}{KeBioLM+CODER} \\
&Train KB & Eval KB &Precision & Recall & F1&Precision & Recall & F1&Precision & Recall & F1 \\ 
 \hline
\cellcolor{blue!10}&UMLS &UMLS  & 82.72 &51.81&63.72&64.27&66.17&65.21&69.08&71.88&70.45\\
\cellcolor{blue!10}&&\SNOMEDint  & 82.09 & 51.83 & 63.54 & 45.78&65.74&53.97&43.22&74.04&54.58\\
\cellcolor{blue!10}&&\SNOMEDext  & 80.57 &53.82 &64.53 & 30.34 & 60.13 & 40.33 & 26.94 & 71.32 & 39.11 \\
\cellcolor{blue!10}&&\TAint  & 82.43&52.66&64.27&22.34&64.10&33.13&14.85&76.36&24.86\\
\cellcolor{blue!10}&&\TAext  & 82.08&51.83&63.54& 53.44 & 64.86 & 58.60 & 55.26 & 72.07 & 62.56 \\
\cellcolor{blue!10}&&\TBint  & 78.92& 56.54 &65.88&11.37&53.31&18.75&7.76&67.68&13.93\\
\cellcolor{blue!10}\multirow{-7}{*}{\rotatebox[origin=c]{90}{\textit{Medmentions}}}&&\TBext  &82.91 &50.53&62.78& 59.90 & 66.30 & 62.94 & 62.35 & 73.65 & 67.53 \\
\hline
\multicolumn{3}{c}{Avg. Drop}\vline & 1.22 & -1.06 & -0.37 & 27.08 & 3.76 & 20.59 & 34.02 & -0.64 & 26.68 \\
\hline 
\cellcolor{blue!10}&MeSH&MeSH & 94.67 &82.56 &88.20 &87.59&84.86&86.20&86.47&91.05&88.70 \\
\cellcolor{blue!10}&&\MEDICint  & 92.31 &84.04 &87.99 & 37.85&81.84&51.76 &36.46&86.46&51.29\\
\cellcolor{blue!10}\multirow{-3}{*}{\rotatebox[origin=c]{90}{\textit{BC5.}}}&&\MEDICext & 96.37 & 82.93 & 89.14 & 49.07 & 85.38 & 62.32 & 50.13 & 94.99 & 65.63 \\
\hline
\multicolumn{3}{c}{Avg. Drop}\vline & 0.33 & -0.93 & -0.37 & 44.13 & 1.25 & 29.16 & 43.18 & 0.33 & 30.24 \\
\bottomrule
\end{tabular}}
\caption{Results for mention detection in partial KB inference.  Table arrangements are the same as \Cref{tab:main_end-to-end_result}.
% The first section shows results on MedMentions
% with UMLS as training KB. The last section shows results on BC5CDR with MeSH as training KB. The average drop in table is the average among
% metric drops between full evaluation (first row in each section) and subset evaluation (other rows in each section).
}
\label{tab:mention_detect}
\small 
\vspace{-1em}
\end{table*}

\begin{table}[t]
\small 
\centering
%\resizebox{0.48\textwidth}{!}{
\setlength{\tabcolsep}{0.5mm}{
\begin{tabular}{p{2mm}ll|cccc}
\toprule
&\multicolumn{2}{c}{Target KB.}& \multicolumn{2}{c}{EntQA} & \multicolumn{1}{c}{GENRE}& \multicolumn{1}{c}{Ke.+CO.} \\
&Train KB & Eval KB & R@100 & Acc. & Acc. & Acc. \\ 
 \hline
\cellcolor{blue!10}&UMLS &UMLS  & 57.26 & 75.38 &66.03&48.61\\
\cellcolor{blue!10}&&\SNOMEDint  & 65.86&74.81&75.14&65.22\\
\cellcolor{blue!10}&&\SNOMEDext  & 61.72& 68.67 &65.33 & 52.64\\
\cellcolor{blue!10}&&\TAint  & 75.10&65.34&77.26&65.86\\
\cellcolor{blue!10}&&\TAext  &58.54 & 66.89 &65.44 &47.99 \\
\cellcolor{blue!10}&&\TBint  & 74.28&57.92&67.63&61.34\\
\cellcolor{blue!10}\multirow{-7}{*}{\rotatebox[origin=c]{90}{\textit{MedMentions}}}&&\TBext  &58.76 & 68.52 &67.53 &51.24 \\
\hline
\multicolumn{3}{c}{Avg. Drop} & -8.45 & 8.35 & -3.69 & -8.77 \\
\hline 
\cellcolor{blue!10}&MeSH&MeSH & 80.34 & 92.72 & 80.97& 83.51 \\
\cellcolor{blue!10}&&\MEDICint  & 88.72 & 90.95 & 83.30 & 80.20\\
\cellcolor{blue!10}\multirow{-3}{*}{\rotatebox[origin=c]{90}{\textit{BC5.}}}&&\MEDICext  & 77.73 & 93.23 &76.52  &84.92 \\
\hline
\multicolumn{3}{c}{Avg. Drop} & -2.89 & 0.63 & 1.06 & 0.95\\
\bottomrule
\end{tabular}
}
%}
\caption{Results for NED in partial KB inference. The disambiguation accuracies (Acc.) are calculated with respect to correctly detected mentions. For EntQA, we additionally add recall at the top 100 (R@100) to show its first-stage concept retrieval performance.}
\label{tab:main_dismbi}
\small 
\vspace{-1em}
\end{table}

\begin{table*}[h]
\small 
\centering
\setlength{\tabcolsep}{1.2mm}{
\begin{tabular}{p{2mm}l|cccc|ccccc}
\toprule
% &  & \multicolumn{6}{c}{BC5CDR on MeSH} \\
&& \multicolumn{4}{c}{\MEDICint}\vline & \multicolumn{4}{c}{\MEDICext} \\
&& EL-P/R&EL-F1&NER-F1&NED-Acc& EL-P/R&EL-F1&NER-F1&NED-Acc \\
\hline
\cellcolor{blue!10}& In-KB Train &81.27/71.34&\textbf{75.98}& \textbf{88.16} & \textbf{92.14 }&86.87/69.30& \textbf{77.10}& \textbf{90.08} & \textbf{94.44}\\
\cellcolor{blue!10}& Partial KB Inference &81.92/70.45& \underline{75.75} &\underline{87.99} & \underline{90.95} &87.10/66.92 & \underline{75.69}&\underline{89.14}& \underline{93.23}\\
% \cellcolor{blue!10}& \ \ +w/ Thresholding &60.83/69.44& 64.85 & 83.28 & 80.14 & 79.64/66.55&72.51& 88.22 & 79.63 \\
\cellcolor{blue!10}\multirow{-3}{*}{\rotatebox[origin=c]{90}{EntQA}}& \ \ w/ Post-pruning&62.97/64.99&63.96 &84.10 &80.76 & 80.02/63.11&70.57& 86.42 & 77.84\\
\hline
\cellcolor{blue!10}& In-KB Train &65.65/68.38& \underline{66.99} &\underline{78.56}& {85.26}&69.96/62.02& \underline{65.75}&\underline{85.52}&76.89 \\
\cellcolor{blue!10}& Partial KB Inference &31.53/68.19&43.12 &51.76&83.30& 37.55/65.33&47.69 &62.32 & 76.52 \\
\cellcolor{blue!10}& \ \ w/ Thresholding & 76.32/59.25&66.71&72.43 &\textbf{92.11} &69.05/56.99& 62.45 &74.86& \textbf{83.41} \\
\cellcolor{blue!10}\multirow{-4}{*}{\rotatebox[origin=c]{90}{GENRE}}& \ \ w/ Post-pruning & 69.31/68.59&\textbf{68.95} &\textbf{79.92}&\underline{86.27}&69.46/66.29& \textbf{67.83}&\textbf{86.47}&\underline{78.45}  \\
\hline
\cellcolor{blue!10}& In-KB Train  &63.98/68.47& 66.15 &\textbf{82.94} &80.48&77.52/80.65& \underline{79.05}&\textbf{92.82}&85.18 \\
\cellcolor{blue!10}& Partial KB Inference &29.24/68.38 &40.96 &51.29&80.20& 42.57/80.67&55.73 &65.63 & 84.92\\
\cellcolor{blue!10}& \ \ w/ Thresholding &79.20/65.08& \textbf{71.45}&78.46& \textbf{91.07}&86.32/77.04& \textbf{81.41} &83.35&\textbf{97.68} \\
\cellcolor{blue!10}\multirow{-4}{*}{\rotatebox[origin=c]{90}{Ke.+CO.}}& \ \ w/ Post-pruning&69.03/65.27& \underline{67.10} &\underline{78.48}&\underline{85.49}&69.17/80.67& 74.48&\underline{87.27}&\underline{85.34} \\
\bottomrule
\end{tabular}
}
\caption{Results of partial KB inference, In-KB training and two redemption methods for three investigated models. The results are evaluated on partial KB \MEDICint and \MEDICext in BC5CDR.
% Results among four partial knowledge base inference methods in end-to-end F1 scores, which are direct training on target KBs, using Off-the-shelf models trained on comprehensive KB and doing online pruning in inference, and two post-processing techniques: thresholding and post pruning. 
The best performance for a model in each dataset is identified with \textbf{bold} and the second is \underline{underlined}.
}
\label{tab:main_transfer_enhance}
\small 
\vspace{-1em}
\end{table*}

\subsection{Main Results}\label{sec:main-result}

% We demonstrate the result of three end-to-end entity linking models in zero-shot partial KB transfer on eight target KB settings as main results.
% First, we report end-to-end entity linking to show the overall performance shifting between large KB and subset KBs in various scales.
% Then, we show model performance in two main stages of end-to-end entity linking, mention detection and entity disambiguation, respectively, to discuss deep reasons behind performance drop in subset KB transfer.

% Our main results include model performance in entity linking and differential analyses of two subtasks.

\paragraph{EL}
\Cref{tab:main_end-to-end_result} shows entity linking results on different partial KB settings.
First of all, we witness a significant and consistent performance drop in precision among all methods on MedMentions.
EntQA has the least precision drop (5.36\%) while GENRE and KEBioLM+CODER have a more obvious decrease, which is 16.68\% and 14.35\%, respectively. 
On the opposite, recalls in partial KBs remained the same even slightly increased.
KeBioLM+CODER shows the largest average recall increase (6.71\%), followed by EntQA (2.13\%), while the average recall of GENRE remains the same (only drops 0.11\%). 
Due to the stability in precision, the average change of F1 by EntQA even slightly increases (-0.7\%). 
However, the average F1 of GENRE and KeBioLM+CODER drops significantly on partial KBs, which are 12.04\% and 9.96\%.
The same pattern appears in BC5CDR.
EntQA shows extraordinary robustness in direct partial KB inference in contrast to the degradation of GENRE and KeBioLM. 
For individual partial KBs, a consistent pattern of precision and F1 drop is observed in GENRE and KeBioLM+CODER and EntQA is more robust compared to others. 
The F1 degradation led to by precision decrease reflects that the models detect redundant mentions that are out of the partial KBs.
% We witness a consistent precision drop on both subset KB and its complement in GENRE and KeBioLM+CODER on all transfer experiments.
% The same phenomenon also happens in most experiments with EntQA except SNOMED subset and MEDIC complement subset, on which precision remains the same or slightly increase.
% This further analysis shows conclusions in the former paragraph are consistent among subset KBs and their complements. The drop of precision and F1 are still common trends after eliminating the potential effect of subset sampling.


\paragraph{NER}
\Cref{tab:mention_detect} shows the results for mention detection.
When inference on partial KBs, both GENRE and KeBioLM+CODER show drastically F1 score decrease on mention detection.
On MedMentions, average drops are 20.59\% and 26.68\% respectively for GENRE and KeBioLM+CODER.
On BC5CDR, the average drops are 29.16\% and 30.24\%.
The large fluctuation mainly comes from the sharp decreases of mention detection precision which are 27.08\%/34.02\% on MedMentions, and 44.13\%/43.18\% for GENRE and KEBIOLM+CODER respectively.
By comparison, the recall barely changes on partial KB inference. 
On the contrary, the fluctuations for EntQA are marginal, and across metrics and datasets, the largest drop is only 3.80\% for precision. 
EntQA shows rather robust performance on mention detection.
The trend is consistent across different subset KBs. 
Generally, GENRE and KeBioLM+CODER are sensitive to the changes to partial KBs.
These models detect mentions in $\mathcal{E}_1-\mathcal{E}_2$ during inference.
Therefore, these two frameworks present large precision degradation while recall barely fluctuates. 
EntQA detects mentions relying on retrieved concepts from the first phase.
It learns to restrict mentions according to concepts so it behaves robustly in partial KB inference. 
The results indicate a main defect for NER-NED and simultaneous generative paradigms is that the reliance between concepts and mentions is not well modeled, hence having poor NER performance in partial KB inference. 


\paragraph{NED}
\Cref{tab:main_dismbi} shows the performance on the NED for correctly detected mentions.
Disambiguation accuracy shows little fluctuation for all methods while slightly increases on MedMentions. 
For example, the accuracy of KeBioLM+CODER increases from 48.61\% to 65.86\% when KB transfers from UMLS to T038 semantic type.
These results reveal that models learn the mapping between related mentions and concepts and are not biased by the out-of-KB annotations. 
The shrunk concept space of partial KBs makes the disambiguation task easier and leads to performance improvement.

\paragraph{Conclusion} We can conclude that
(1) NER-NED and Generative frameworks are not robust to direct partial KB inference, while the performance of NED-NER framework is more stable;
(2) degradation of entity linking performance is mainly a result of drastically degenerated mention detection performance on partial KBs and entity disambiguation abilities are stable; 
(3) EntQA potentially handled NILs via filtering out irrelevant entities before NER, while other methods suffer from low precision due to mislinking NILs to existing entities.
%(3) we can conjecture the superior robustness of EntQA is due to the explicitly modelled reliance between concepts and mentions.




\subsection{Simple Redemptions}
\label{sec:post-processing}

In former subsections, we identify performance drops in partial KB inference mainly due to precision drops in the mention detection.
We introduce two simple-yet-effective methods to redeem the performance drops for partial KB inference: \textbf{Post-pruning} and \textbf{Thresholding}, which are shown in \Cref{fig:method_overview} and an example is provided in \Cref{app:example}.
Two methods are motivated by removing NIL mentions for improving mention detection performances.

\paragraph{Post-Pruning} asks the model to infer using  $\mathcal{E}_1$ and remove mention-entity pairs  out of the partial KBs $\mathcal{E}_1 - \mathcal{E}_2$. \textbf{This redemption method is naive but needs to know $\mathcal{E}_1$.}
% , which should lead to the performance close to full evaluation. 
% The idea is based on the finding that models achieve similar or worse F1 scores compared to full evaluation. 

\paragraph{Thresholding} uses $\mathcal{E}_2$ for inference. After obtaining mention-entity pairs, it will search a fixed threshold $\theta$ on the development set to maximize F1 and remove results with scores under the threshold.
% Specifically, scores are the conditional probabilities of mention spans by the reader in EntQA, the log-likelihoods for the mention span and concept name in GENRE, and cosine similarities between mention and concepts in KeBioLM+CODER. 
\textbf{This method is not aware of $\mathcal{E}_1$.}

Specifically, for KeBioLM+CODER, we set a threshold on the cosine similarities of detected mentions and their most similar concepts:
\begin{equation*}
    {\rm score}=\max_{e\in\mathcal{E}_2}\cos(h_m, h_e),
\end{equation*}
where $m$ represents the mention extracted by NER and $h$ represents embeddings.

For EntQA, we obtain $K$ entities from the retriever and we compute the score for $k^{th}$ entity with starting and ending index $s,t$:
% we set a threshold on the reranked span probabilities provided by the reader:
% The reranked span probabilities are multiplications between reranking scores of Top-K entity candidates and its span prediction scores provided by the EntQA reader.
\begin{equation*}
    {\rm score}=P_{re}(e_k|e_{1:K})P_{st}(s|e_k,\boldsymbol{s})P_{ed}(t|e_k,\boldsymbol{s})
\end{equation*}
where $P_{re}$ computes the probability of $e_k$ among all entities and $P_{st}$ and $P_{ed}$ computes probabilities of $s$ and $t$ are the starting and ending of $e_k$.
The original implementation of EntQA integrated thresholding during inference, so the partial KB inference is equivalent to inference with thresholding.

For GENRE, we use the log-likelihoods for the generated mention span and concepts names in the output sequences $\boldsymbol{s}_m^e = \{M^B,x_i,\ldots x_j,M^E,E^B,e,E^E\}$ as scores: 
% Let recap the token sequence of the generated mention span and concepts names is formulated as:
% \begin{align*}
%      \boldsymbol{s}_m^e = \{M^B,x_i,\ldots x_j,M^E,E^B,e,E^E\},
% \end{align*}
% then the log-likelihood is calculated as: 
% \begin{align*}
%     {\rm score}=&\frac{1}{|\boldsymbol{s}_m^e|}\{\sum_{k=i}^j \log(P_{\text{ar}}(x_k)) + \sum_{k=1}^{n_e} \log(P_{\text{ar}}(t_k)) \\ 
%     &+\log(P_{\text{ar}}(M^B)) + \log(P_{\text{ar}}(M^E)) \\
%     &+ \log(P_{\text{ar}}(E^B)) + \log(P_{\text{ar}}(E^E))\},
% \end{align*}
\begin{equation*}
    {\rm score}=\frac{1}{|\boldsymbol{s}_m^e|}\sum_{x\in \boldsymbol{s}_m^e}\log(P_{\text{ar}}(x))
\end{equation*}
where $P_{\text{ar}}$ represents the token's probability auto-regressively conditioned on its preceding tokens.

% These two redemption methods are all inspired 

We compare two methods with direct partial KB inference.
We also include a setting where models are trained on the partial KB $\mathcal{E}_2$ for comparison.
% In this setting, the annotation label distributions between training and inference are consistent.
We dub this `in-domain' setting as \textbf{In-KB train}.

\begin{figure*}[ht]
    \centering
    \resizebox{0.9\textwidth}{!}{
    \includegraphics{f1drop.PNG}
    }
    \caption{The x-axis is the proportion of mention-concept annotations corresponding to the partial KBs in training data. The six points in each line represent different partial KBs in MedMentions. }
    \label{fig:f1drop}
    \vspace{-1em}
\end{figure*}

\paragraph{Redemptions Performances} \Cref{tab:main_transfer_enhance} shows results of partial KB inference on \MEDICint and \MEDICext on BC5CDR. 
We also identify the same pattern in other subset KBs (\Cref{app:redeem_result}).
% Different settings lead to different performances for three paradigms.
Paradigms behave differently under these settings.

For KeBioLM+CODER, the best improvements are brought by thresholding.
Mention-concept pairs with low similarities can be categorized into concepts within $\mathcal{E}_1-\mathcal{E}_2$ or incorrect mention spans.
These two kinds of pairs are removed by thresholding which results of the improvement of NER and NED.
% the concept similarities are well learned and presented by cosine similarity.
Post-pruning also brings improvement of NED by removing concepts within $\mathcal{E}_1-\mathcal{E}_2$, but it cannot deal with incorrect mention spans.
% In-KB training only influences the NER stage of KeBioLM+CODER
% and has similar results to In-KB training.
% This reflects although post-pruning compensates linking precision, the further improvements are bottle-necked by the large search space of the training KB as shown by NED-accuracy.

For EntQA, direct partial KB transfer achieves similar results to In-KB training.
The great performance of direct partial KB transfer is due to the integration of the thresholding mechanism.
% Post-pruning brings degradation in terms of F1  
% For EntQA, In-KB training achieves similar results to direct partial KB transfer, since EntQA is robust towards partial KB transfer.
% % While two redemption methods bring degradation in terms of F1 and the decrease is more significant on \MEDICint which dropped approximately 10\%.
% However, two redemption methods bring degradation in entity linking.
% Thresholding xxxxx
% Post-pruning xxxxx
% The precision of entity linking drops the most which indicates (1) through thresholding, EntQA makes unsure predictions with low probability scores; (2) through post-pruning, concepts out of partial KBs confuse the model to make wrong predictions. 

For GENRE, the best performance is achieved uniformly by post-pruning. 
Post-pruning removes concepts within $\mathcal{E}_1-\mathcal{E}_2$ to boost performance.
Thresholding also has significant improvement and performs better than In-KB training.
% This may due to the log-likelihood cannot accurately scoring the mention-entity validity, thresholding leads to improved performance over partial KB inference while it is surpassed by In-KB training.
The reason thresholding performs worse than post-pruning may be the log-likelihood is not a direct estimate of mention-entity pair validity.

Another observation is two redemption methods can outperform direct In-KB training, which suggests additional supervision from KB $\mathcal{E}_1-\mathcal{E}_2$ can benefit partial KB inference on $\mathcal{E}_2$.
%This is a surprising result and we conjecture that annotations out of partial KBs may carry information that are beneficial for learning In-KB information.
%How to better transfer knowledge from outside KBs is a significant direction of future research for improved biomedical entity linking performance.

\subsection{Discussion}
\label{sec:analysis}

%The performances of partial KB inference are diverse across different partial KBs.
In this section, we provide a further investigation into what causes performance variance across different partial KBs.
In training data, annotations associated with different partial KBs may take different proportions of total annotations.
Models may over-fit the frequency of mention annotations existing in training samples. 
We visualize F1 performance drop of entity linking and mention detection against the proportion of partial KB annotations in training data. 
As shown in \Cref{fig:f1drop}(a)(b), the performance drop is negatively correlated with the annotation proportions for GENRE and KeBioLM+CODER.
The relation is more prominent for mention detection.  
For EntQA, performances barely change in terms of entity linking and mention detection due to its robustness. 
This negative correlation suggests mention detection of GENRE and KeBioLM+CODER over-fit annotation frequency.
EntQA detects mentions according to retrieved concepts.
This explicit modeling makes it more robust since it handles out-of-KB mentions by filtering out irrelevant concepts in the retrieving stage.

For NED as shown in \Cref{fig:f1drop}(c), there exists no obvious trend between accuracy drops and annotation proportions.
For GENRE and KeBioLM+CODER, the disambiguation performances are improved when inference on partial KBs.
Improvements are also observed for EntQA on concept retrieval R@100. 
Concept spaces are shrunk for partial KBs and therefore the disambiguation problem becomes easier to approach. 
Contrarily, the disambiguation accuracy of EntQA drops, which is probably because of the distribution shift of retrieved concepts between training and inference
which serve as inputs for the reader. The distribution shifts in a way that for the same number of top retrieved concepts many concepts with lower ranks may be unseen for the reader in partial KB inference.
This illustrates EntQA is still influenced by partial KB inference although it is robust for detecting mentions.




\begin{comment}
\begin{table*}[t]
\small 
\centering
\begin{tabular}{c|cccccccccccc}
% \hline 
& \multicolumn{3}{c}{EntQA} & \multicolumn{3}{c}{GENRE}& \multicolumn{3}{c}{KeBioLM+CODER} \\
 \hline
 &Precision & Recall & F1&Precision & Recall & F1&Precision & Recall & F1 \\ 
 Vanilla &41.52&31.56&35.86 & 17.26&49.53&25.60 & 9.78&50.28&16.37  \\
 /w In D. Train & 54.63&27.52&36.60 & 44.58&42.86&43.70 & 46.13&47.31&46.71\\
 /w Threshold & 15.43&24.01&18.53 & 30.76&42.10&35.54 & 56.04&45.08&49.97\\
 /w Post-process & 23.87&27.92&25.74 & 51.19&49.43&50.29 & 47.75&39.69&43.35\\
% \hline
\end{tabular}
\caption{Detailed analysis on Thresholding and Post-processing on T038.}
\label{tab:main_domain_gen}
\small 
\end{table*}
\end{comment}