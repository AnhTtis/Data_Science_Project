\subsection{Overview of Proposed Framework}
\label{sec:overview}

The goal of data-centric approaches is to augment training datasets by generating useful labeled data examples. Under that, the goal of our data-centric transfer (\method) framework is to \textit{transfer} the knowledge from unlabeled data into the data augmentation.
Specifically, for each graph-label pair $(G^{[k]} \in \mathcal{G}^{[k]} $, $y^{[k]} \in \mathcal{Y}^{[k]})$ in the task $k$,
the framework is expected to output a new example $G^{\prime[k]}$ with the label $y^{\prime[k]}$ such that (1) $y^{\prime[k]} = y^{[k]}$ and (2) $G^{\prime[k]}$ and $G^{[k]}$ are from the same graph space $\mathcal{G}^{[k]}$. However, if the graph structures of $G^{\prime[k]}$ and $G^{[k]}$ were too similar, the augmentation would duplicate the original data examples, become useless, and even cause over-fitting. So, the optimal graph data augmentation should \textit{enrich the training data with good diversity as well as preserve the labels of the original graphs}.
To achieve this, \method utilizes a diffusion probabilistic model to first \textit{learn the data distribution from unlabeled graphs} (Section~\ref{sec:learning}). Then \method adapts the reverse process in the diffusion model to \textit{generate task-specific labeled graphs for data augmentation} (Section~\ref{sec:generating}).
Thus, the augmented graphs will be derived from the distribution of a huge collection of unlabeled data for \textit{diversity}. To \textit{preserve the labels}, \method controls the reverse process with two {task-related optimization objectives} to transfer \textit{minimal sufficient knowledge} from the unlabeled data. The first objective minimizes an upper bound of mutual information between the augmented and the original graphs in the graph space. The second objective maximizes the probability of the predicted label of augmented graphs being the same as the label of original graphs.
The first is for minimal knowledge transfer, and the second is for sufficient knowledge transfer.
\method integrates the two objectives into the reverse process of the diffusion model to guide the generation of new labeled graphs.
\method iteratively trains the graph property predictor (used in the second objective) and creates the augmented training data. To simplify notations, we remove the task superscript $[k]$ in the following sections.

\def\I{{\mathcal{I}}}
\def\P{{\mathcal{P}}}
\begin{figure*}[t]
    \centering
    \begin{minipage}[c]{0.63\textwidth}
    \includegraphics[width=\textwidth]{figures/implementation_v3.pdf}
    \end{minipage}\hfill
    \begin{minipage}[c]{0.36\textwidth}
    \caption{Diffusion model in DCT: It performs task-specific data augmentation using objectives $\I_1$ and $\I_2$ in the reverse process. The model was trained on unlabeled graphs to learn the general data distribution. Then it generates $(G^\prime,y^\prime=y)$ based on $(G,y)$ in the reverse process. It perturbs $G$ with $D$ steps and optimizes $G^\prime$ to be minimally similar to $G$ (Objective $\I_1$) and sufficiently preserve the label of $G$ (Objective $\I_2$).
    } \label{fig:implementation}
  \end{minipage}
\end{figure*}
\begin{figure*}[t]
    \centering
    \includegraphics[width=0.99\linewidth]{figures/compare_real_gen_runs.pdf}
    \caption{
    Relative improvement (increased AUC or reduced MAE) from three data-centric methods (over ten runs), compared to the basic GIN: Blue is for self-training with selected real unlabeled graphs. Green is for self-training with graphs directly generated by a standard diffusion model. Red is for \method that generates task-specific labeled graphs. The first two often make little or negative impact. Our \method has consistent and significant improvement shown as the percentages in \textcolor[rgb]{0.83137255, 0.22745098, 0.22745098}{red}.
    }
    \label{fig:compare gnn runs}
\end{figure*}
\subsection{Learning Data Distribution from Unlabeled Graphs}
\label{sec:learning}

The diffusion process for graphs in~\cref{fig:implementation} applies to both graph structure and node features. The diffusion model slowly corrupts unlabeled graphs to a standard normal distribution with noise. For graph generation, the model samples noise from the normal distribution and learns a score function to reverse the perturbed noise. Given an unlabeled graph $G$, we use continuous time $t \in [0,T]$ to index multiple diffusion steps $\{G^{(t)}\}_{t=1}^T$ on the graph, such that $G^{(0)}$ follows the original data distribution and $G^{(T)}$ follows a prior distribution like the normal distribution. The forward diffusion is a stochastic differential equation (SDE) from the graph to the noise:
\begin{equation}\label{eq:forward graph SDE}
\mathrm{d} G^{(t)}=\mathbf{f} \left(G^{(t)}, t \right) \mathrm{d} t+g(t)~\mathrm{d} \mathbf{w},
\end{equation}
where $\mathbf{w}$ is the standard Wiener process, $\mathbf{f}(\cdot, t): \mathcal{G} \rightarrow \mathcal{G}$ is the drift coefficient and $g(t): \mathbb{R} \rightarrow \mathbb{R}$ is the diffusion coefficient. $\mathbf{f}(G^{(t)}, t)$ and $g(t)$ relate to the amount of noise added to the graph at each infinitesimal step $t$. The reverse-time SDE uses gradient fields or scores of the perturbed graphs $\nabla_{G^{(t)}} \log p_t(G^{(t)})$ for denoising and graph generation from $T$ to $0$~\citep{song2020score}:
\begin{equation}\label{eq:reverse graph SDE}
\mathrm{d} G^{(t)} =\left[\mathbf{f}(G^{(t)}, t)-g(t)^2 \nabla_{G^{(t)}} \log p_t(G^{(t)})\right] \mathrm{d} t+g(t) \mathrm{d} \overline{\mathbf{w}},
\end{equation}
where $p_t(G^{(t)})$ is the marginal distribution at time $t$ in forward diffusion. $\overline{\mathbf{w}}$ is a reverse time standard Wiener process. $\mathrm{d} t$ here is an infinitesimal negative time step. The score $\nabla_{G^{(t)}} \log p_t(G^{(t)})$ is unknown in practice and it is approximated by the score function $\mathbf{s}(G^{(t)}, t)$ with score matching techniques~\citep{song2020score}. On graphs, \citet{jo2022score} used two GNNs to develop the score function $\mathbf{s}(G^{(t)}, t)$ to de-noise both node features and graph structures and details are in~\cref{add:method:tech}.

\subsection{Generating Task-specific Labeled Graphs}
\label{sec:generating}

\vspace{-0.05in}
\textit{Self-training} approaches would propose to either (1) select unlabeled graphs by a graph property predictor or (2) generate graphs directly from the standard diffusion model, and then use the predictor to assign them labels so that the training data could be enriched.
However, we have observed that neither of them can guarantee positive impact on the prediction performance. In fact, as shown in~\cref{fig:compare gnn runs}, they make very little or even negative impact.
That is because \textit{the selected or directly-generated graphs are too different from the labeled graph space of the target tasks}. Task details of ten datasets are in~\cref{sec: add exp setups}.

Given a labeled graph ($G,y$) from the original dataset of a specific task, the new labeled graph $(G^\prime,y^\prime)$ is expected to provide \textit{useful knowledge to augment} the training set. We name it \emph{the augmented graph} throughout this section. The augmented graph is desired to have the following two properties, as in~\cref{sec:overview}: \textbf{Task relatedness}: As an effective training data point, $G^\prime \in \mathcal{G}$ and $y^\prime \in \mathcal{Y}$ are from the graph/label spaces of the specific task where $(G,y)$ come from and thus transfer sufficient task knowledge into the training set; \textbf{Diversity}: If $G^\prime$ was too similar to $G$, the new data point would cause severe over-fitting on the property prediction model. The augmentation aims to learn from unlabeled graph to create diverse data points, which should contain minimal task knowledge about $G$.

The selected unlabeled graphs used in \textit{self-training} have little task relatedness because the unlabeled data distribution might be too far from the one of the specific task. Existing graph \textit{data augmentation} methods could not create diverse graph examples because they manipulated labeled graphs and did not learn from the unlabeled graphs. Our novel data-centric approach \method works towards both desired properties by transferring \textit{minimally sufficient knowledge} from the unlabeled graphs: \textbf{Sufficiency} is achieved by maximizing the possibility for label preservation (i.e., $y^\prime = y$). It ensures that the knowledge from unlabeled graphs is task-related;
\textbf{Minimality} refers to the minimization of graph similarity between $G^\prime$ and $G$ to ensure that the augmentation introduces diversity. Both optimizations can be formulated using mutual information $\I(\cdot \ ; \cdot)$ to generate task-specific labeled data $(G^\prime,y^\prime)$:
\begin{definition}[Sufficiency for Data Augmentation]
    The augmented graph $G^\prime$ sufficiently preserves the label of the original graph $G$ if and only if $\I(G^\prime;y) = \I(G;y) $.
\end{definition}

\begin{definition}[Minimal Sufficiency for Data Augmentation]
    The Sufficiency is minimal for data augmentation if and only if $\I(G^\prime; G) \leq \I(\bar{G}; G)$, $\forall \bar{G}$ represents any augmented graph that sufficiently preserves the original graph's label.
\end{definition}

Self-supervised tasks applied a similar philosophy in pre-training~\citep{soatto2014visual}, however, they did not use labeled data from any specific tasks. So the optimizations were unable to extract useful knowledge and transfer it to the downstream~\citep{tian2020makes}. In our \method that performs task-specific data augmentation, the augmented graphs can be optimized toward the objectives using any labeled graph $G$ and its label $y$:
\begin{equation}\label{eq:fine-tune objective}
    \min_{\I_1}\max_{\I_2} \ \ \mathbb{E}_{G} \left[ 
    \I_1\left(G^\prime; G \right) + \I_2\left(G^\prime; y\right) 
    \right].
\end{equation}
For the first objective, we use the leave-one-out variant of {InfoNCE}~\citep{poole2019variational,oord2018representation} as the upper bound estimation. For the $i$-th labeled graph $(G_i,y_i)$,
\begin{equation}\label{eq:upper bound infonce}
    \I_1 \leq \I_\text{bound} (G_i^\prime; G_i) = 
    \log \frac{p(G_i^\prime |G_i)}{\sum_{j=1,j \neq i}^{M} p(G_i^\prime | G_j)} ,
\end{equation}
where
$G_i^\prime$ is the augmented graph.
When $G_i^\prime$ is optimized, $G_i$ makes a positive pair; $\{G_j\}$ ($j\neq i$) are $M-1$ negative samples of labels that do not equal $y_i$. ($M$ is a hyperparameter.)
We use cosine similarity and a softmax function to calculate $p(G_i^\prime|G_j)=\frac{\exp({\operatorname{sim}(G_i^\prime, G_j) })}{\sum_{j=1}^M \exp({\operatorname{sim}(G_i^\prime, G_j) }) }$.  
In practice, we extract statistical features of graphs to calculate their similarity. Details are in \cref{add:sec:raw feature}.

For the second objective, we denote the predicted label of the augmented graph $G^\prime$ by $f_\theta(G^\prime)$.
% to measure $\I_2(G^\prime; y)$.
We maximize the log likelihood $\operatorname{log} p \left(y | f_\theta(G^\prime) \right)$ to maximize $\I_2(G^\prime; y)$.
Specifically, after the predictor $f_\theta$ is trained for several epochs on the labeled data, we freeze its parameters and use it to optimize the augmented graphs so they are task-related:
\begin{equation}\label{eq:fine-tune loss}
    \mathcal{L} (G^\prime) = 
    \I_\text{bound}\left(G^\prime; G \right) 
    - \operatorname{log} p \left(y | f_\theta(G^\prime) \right).
\end{equation}

\paragraph{Framework details:} As shown in~\cref{fig:implementation}, after the diffusion model learns the data distribution from unlabeled graphs, given a labeled graph $G$ from a specific task, \method perturbs it for $D$ ($D \ll T$) steps. The perturbed noisy graph, denoted by $\Tilde{G}^{(D)}$, stays inside the task-specific graph and label space, rather than the noise distribution (at step $T$). To reverse the noise in it and generate a task-specific augmented example $G^\prime$, \method integrates the loss function in~\cref{eq:fine-tune loss} into the score function $\mathbf{s}(\cdot, t)$ for minimal sufficient knowledge transfer:
\begin{align}\label{eq:finetune guided reverse SDE}
    \mathrm{d} \Tilde{G}^{(t)} = \left[\mathbf{f}(\Tilde{G}^{(t)}, t) - g(t)^2 \left(\mathbf{s}(\Tilde{G}^{(t)}, t) - \alpha \nabla_{\Tilde{G}^{(t)}} \mathcal{L}(\Tilde{G}^{(t)}) \right) \right] \mathrm{d}t
    +g(t) \mathrm{d} \overline{\mathbf{w}},
\end{align}
where $\alpha$ is a scalar for score alignment between $\mathbf{s}$ and $\nabla\mathcal{L}$ to avoid the dominance of any of them: $\alpha = \frac{\| \mathbf{s}(\Tilde{G}^{(t)}, t) \|_2}
    { \| \nabla_{\Tilde{G}^{(t)}} \mathcal{L}(\Tilde{G}^{(t)}) \|_2 }.$
Because $\Tilde{G}^{(t)}$ is an intermediate state in the reverse process, the noise in it may fail the optimizations. So, we design a new sampling method named \textit{double-loop sampling} for accurate loss calculation. 
It has an inner-loop sampling using \cref{eq:reverse graph SDE} to sample $\hat{G}_{(t)}$, as the denoised version of $\Tilde{G}^{(t)}$ at the reverse time $t$. Then $\nabla_{\hat{G}} \mathcal{L}( \hat{G}_{(t)} )$ is calculated as an alternative for $ \nabla_{\Tilde{G}^{(t)}} \mathcal{L}(\Tilde{G}^{ (t)})$.
Finally, an outer-loop sampling takes one step to guide denoising using~\cref{eq:finetune guided reverse SDE}.

DCT iteratively creates the augmented graphs $(G^\prime,y^\prime)$, updates the training dataset $\{(G_i, y_i)\}$, and trains the graph property predictor $f_\theta$. In each iteration, for task $k$, $n \ll N^{[k]}$ labeled graphs of the lowest property prediction loss are selected to create the augmented graphs.The predictor is better fitted to these graphs for more accurate sufficiency estimation of the augmentation. 
