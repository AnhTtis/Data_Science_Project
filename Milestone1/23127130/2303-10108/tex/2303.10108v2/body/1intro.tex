Graph data such as molecules and polymers are found to have attractive properties in drug and material discovery~\citep{bohm2004scaffold,huang2021therapeutics}, but annotating them requires specialized knowledge, as well as lengthy and costly experiments in wet labs~\citep{cormack2004molecularly}. So, it is important for graph property predictors to learn \textit{useful knowledge} from unlabeled graphs.

Self-supervised learning~\citep{hu2019strategies,rong2020self,you2021graph,kim2022graph} utilizes unlabeled graphs to learn through \textit{predictive tasks} or \textit{contrastive tasks} to represent and transfer the knowledge as \textit{model parameters}. Despite the empirical success in language and vision~\citep{brown2020language,he2022masked}, their performance on graph data applications remains unsatisfactory because of the significant gap between the graph self-supervised task and the graph label prediction task. Models trained on node attribute prediction~\citep{hu2019strategies} as a simple \textit{predictive} self-supervised task extract too limited knowledge from the graph structure, which has been observed after too fast convergence~\citep{sun2022does}.
More complex tasks like graph context prediction~\citep{hu2019strategies,zhang2021motif} may transfer knowledge that conflicts with downstream tasks. Aromatic rings, for instance, are a prevalent structure in molecules~\citep{maziarka2020mol} and are considered valuable in context prediction tasks~\citep{zhang2021motif}. However, graph properties such as oxygen permeability can be more related to non-aromatic rings in some cases~\citep{liu2022graph}, which is overlooked if not using tailored predictive tasks specifically for downstream tasks. As predictive tasks strive for universality, the transferred knowledge may force models to focus more on aromatic rings, leading to poor prediction.

On the other line, \textit{contrastive} tasks~\citep{you2021graph,kim2022graph} aim to learn the similarity between original and perturbed graphs. However, the learned similarity can hardly generalize across tasks~\citep{kim2022graph}. First, perturbations without domain knowledge, \eg bioisosteres, do not preserve broad biological properties~\citep{sun2021mocl}. Second, it is difficult, if not impossible, to find universal perturbations that generalize to diverse property prediction tasks. For example, bioisosteric (subgraph) replacements produce similar biological properties for molecules. And they may reduce toxicity~\citep{brown2014bioisosteres}. So, contrastive tasks with bioisosteric replacement enforce the similarity between toxic and non-toxic molecules. However, models pre-trained on such contrastive tasks hurt the performance on downstream tasks, \eg toxicity prediction.

Our \textit{data-centric} idea avoids the use of self-supervised tasks that are not appropriate. We use a diffusion probabilistic model (known as \textit{diffusion model}) to capture the data distribution of \textit{unlabeled graphs}, leveraging its capability of distribution coverage, stationarity, and scalability~\citep{dhariwal2021diffusion}. At the stage of performing a particular property prediction task, the reverse process, guided by novel task-related optimization objectives, generates new task-specific labeled examples. Minimal sufficient knowledge from the unlabeled data is transferred into these examples, instead of uninterpretable model parameters, and then to enhance the training of prediction models.

\begin{figure}[t]
\captionsetup[subfigure]%
 {labelformat=empty,justification=RaggedRight}
    \begin{subfigure}{0.5\textwidth}
        \begin{minipage}{0.5\linewidth}
        \includegraphics[width=\textwidth]{figures/intro_data_centric_existing.pdf}
        \end{minipage}\hfill
        \begin{minipage}{0.5\linewidth}
        \caption{\textbf{Existing approach}: Knowledge from self-supervised tasks could not be aligned or even conflict with what predictions need. Parameter initialization could \textit{hardly interpret} how unlabeled graphs were or would be able to improve the models, leading to high prediction errors.}
        \label{fig:intro_existing}
    \end{minipage}
    \end{subfigure}%
\hfill % maximize space between the subfigures
    \begin{subfigure}{0.49\textwidth}
    \begin{minipage}{0.5\linewidth}
    \includegraphics[width=\textwidth]{figures/intro_data_centric_proposed.pdf}
    \end{minipage}\hfill
    \begin{minipage}{0.5\linewidth}
    \caption{\textbf{Data-centric approach}: Target knowledge in labeled graphs guides the denoising process in diffusion model to generate new labeled examples close to the target graph space instead of the unlabeled graph space. The augmented knowledge for the prediction model is \textit{visible} as graphs.}
    \label{fig:intro_proposed}
    \end{minipage}
\end{subfigure}
\caption{Comparing the diagrams of the existing approach and the proposed approach to learning from unlabeled graphs for a variety of graph property prediction tasks.}
\label{fig:intro}
\end{figure}

To implement our idea, we propose a \textit{Data-Centric Transfer} framework (\method) based on a diffusion model for graph data, as shown in~\cref{fig:intro_proposed}.
It aims to transfer minimal sufficient knowledge from unlabeled graphs to property predictors by data augmentation.
The diffusion model gradually adds Gaussian noise to a graph from which a score function (\ie the gradient of the log probability density) is then learned to estimate the noise step by step to reverse the process. \method trains the diffusion model on the unlabeled graphs to get ready to augment any labeled dataset.
Given a labeled graph from a particular task (\ie type of property), the diffusion model adds noise to perturb it by a few steps and then generates a new graph through the score function.
The new graph could be close to the distribution of the unlabeled graphs for diversity, however, it would lose the relatedness to the target task. So, we add two task-related objectives into the score function to guide the reverse process. When a predictor model $f$ has been trained on the task, given an original labeled graph $G$, the first objective is to optimize the new graph $G^\prime$ to \emph{sufficiently} preserve the label of $G$ with $f$. The second objective is to optimize $G^\prime$ to be very different from (\ie \textit{minimally} similar to) $G$. These two objectives ensure that $G^\prime$ carries minimal sufficient knowledge from the unlabeled graphs to be an augmentation of $G$.
\method iteratively generates new examples to augment the labeled dataset and progressively trains the prediction model with it.

We test \method on \textit{fifteen} graph property prediction datasets from three fields: chemistry (molecules), material science (polymers), and biology (protein-protein interaction graphs). \method achieves the best performance over all these tasks.
We find that the state-of-the-art self-supervised methods often struggle to transfer knowledge to regression tasks, etc. \method reduces the mean absolute error relatively by 13.4\% and 10.2\% compared to the best baseline on the molecule and polymer graph regression tasks, respectively.
