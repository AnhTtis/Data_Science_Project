\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2023


% ready for submission
\usepackage{neurips_2023}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2023}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2023}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2023}

% require
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors


\RequirePackage{fancyhdr}
\RequirePackage{algorithm}
\RequirePackage{algorithmic}
\RequirePackage{eso-pic} % used by \AddToShipoutPicture
\RequirePackage{forloop}
% Recommended, but optional, packages for figures and better typesetting:
\usepackage{natbib}
\setcitestyle{aysep{}} %Citation-related commands
\usepackage{graphicx}% \usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
% \usepackage[capitalize,noabbrev]{cleveref}
\usepackage{cleveref}
\crefname{equation}{Eq.}{Eqs.}
\crefname{table}{Table}{Tables}
\crefname{figure}{Figure}{Figures}
\crefname{section}{Section}{Sections}
\crefname{algorithm}{Algorithm}{Algorithms}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% my imports
\usepackage{xcolor,colortbl}
\usepackage{adjustbox}
\usepackage{url}
\usepackage{multirow,multicol,xspace}
% \usepackage{amsthm,amsmath,amssymb}
\usepackage{float}
\usepackage{graphics}
\usepackage{paralist}
\usepackage{wrapfig}
\usepackage[normalem]{ulem}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
% my imports: figure draw
\usepackage{pgfplots}
\pgfplotsset{width=8cm,compat=1.17} % <----
% check mark
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
% 
\usepackage{subcaption,ragged2e}
\usepackage{caption}

\newcommand*{\scale}[2][4]{\scalebox{#1}{$#2$}}
\newcommand{\opfunc}[1]{\textsc{#1}}


\title{Rebuttal}
% \author{}

\begin{document}
% \maketitle
\section{Summary}

Dear AC and reviewers,

We appreciate all the valuable feedback from four different aspects: novelty, literature review, method detail, and experiment. Here we present all the concerns raised by each reviewer and outline how we have addressed these concerns.

\#\# Reviewer 6AKL

1. Method detail: We explained the training details of the diffusion model.

2. Experiment: We provided a detailed explanation of the dataset used in our experiments. We also analyzed the impact of the perturbation scale on model performance. 

\#\# Reviewer T9FT

1. Novelty: We have highlighted a major novelty: knowledge transfer from unlabeled graphs by data augmentation. This sets our work apart from the two referenced papers as mentioned by the reviewers, which focused on different tasks - one on node-level tasks and the other on active learning.

2. Literature review: We showed that we have covered two referenced papers as mentioned by the reviewers. We also showed that the literature review on baselines is broad and sufficient.

2. Experiment: We have addressed concerns about the performance and introduced experiments comparing a new baseline, demonstrating that our baseline method selection and comparison do not lead to cherry-picking presentation.

\#\# Reviewer trSH

1. Literature review: We discussed more work related to pseudo-labeling.

2. Method detail: We explained the details of using diffusion for graph generation tasks. We also clarified the definition of $\bar{G}$.

3. Experiments: We explained that the augmented examples can introduce noise as the top-$n$ hyper-parameter increases, potentially causing a performance drop in Figure 4.

\#\# Reviewer 3gzg

1. Literature review: We discussed more work related to the diffusion model. We also discussed how the proposed framework can adapt to various diffusion models.

2. Method detail: We explained how to generate desirable graphs in downstream tasks and how to use them with the downstream predictor model.

3. Experiment: We presented more evidence to support our claim on the visible knowledge transfer.

---

We are encouraged by successfully addressing the concerns raised by Reviewer 6AKL and T9FT through discussions. We sincerely apologize if we missed any important concerns that the reviewers believe were not adequately summarized or addressed. We respectfully request the opportunity to further address these concerns during the remaining discussion period. Your feedback is highly valued.

% \section{Review 2 T9FT}

% (1)

% We value your feedback and are pleased to have addressed your questions 1 and 3 regarding the novelty and performance of our method.

% We respectfully disagree with your comment: "The apparent lack of specific SOTA methods in this comparative experiment" and your previous comment in the second question: "The paper appears to have an insufficiency in its literature review" We believe that these assertions may overlook several important facts covered in our paper. 

% You referenced three papers [3, 4, 5] as evidence: GROVER [4] was presented at NeurIPS 2020, MGSSL [3] at NeurIPS 2021, and GraphLoG [5] at ICML 2021. \textbf{We would like to emphasize once again that we have already included the comparison with MGSSL [3] and GraphLoG [5] in Table 1.} As previously mentioned, we initially considered MGSSL [3] rather than GROVER [4] because both GROVER [4] and MGSSL [3] utilized graph structures (motifs) for self-supervised tasks, and MGSSL [3] demonstrated better performance over GROVER [4] in fair and direct comparisons. We chose the \textbf{better one} from MGSSL [3] and GROVER [4] to allocate space for other valuable studies within the main text. Therefore, the assertion: "cherry-picking of the compared methods" is unjust. Here, we provide empirical validation through additional experiments. The table below displays the performance of the pre-trained GROVER [4] base model, fine-tuned on classification tasks (OGBG-BBBP and OGBG-BACE) and regression tasks (OGBG-FreeSolv and OGBG-ESOL) over three runs. We follow the default settings in the official implementation.

% \begin{table}[h]
% \begin{tabular}{|l|l|l|l|l|}
% \hline
%                              & BBBP      & BACE      & FreeSolv     & ESOL         \\ \hline
% GIN                          & 67.5(2.7) & 77.5(2.8) & 1.639(0.146) & 0.766(0.016) \\ \hline
% GROVER                       & 63.3(0.1) & 78.4(3.1) & 2.539(0.523) & 1.263(0.125) \\ \hline
% Best graph self-supervised   & 69.9(0.5) & 81.3(2.4) & 1.952(0.088) & 0.935(0.018) \\ \hline
% Best graph semi-supervised   & 66.7(1.9) & 78.4(3.0) & 1.547(0.082) & 0.724(0.082) \\ \hline
% Best graph data augmentation & 70.2(1.0) & 82.4(2.4) & 1.565(0.098) & 0.755(0.039) \\ \hline
% Ours                         & 70.8(0.5) & 85.6(0.6) & 1.339(0.075) & 0.717(0.020) \\ \hline
% \end{tabular}
% \end{table}

% % |                              | BBBP      | BACE      | FreeSolv     | ESOL         |
% % |------------------------------|-----------|-----------|--------------|--------------|
% % | GIN                          | 67.5(2.7) | 77.5(2.8) | 1.639(0.146) | 0.766(0.016) |
% % | GROVER                       | 63.3(0.1) | 78.4(3.1) | 2.539(0.523) | 1.263(0.125) |
% % | Best graph self-supervised   | 69.9(0.5) | 81.3(2.4) | 1.952(0.088) | 0.935(0.018) |
% % | Best graph semi-supervised   | 66.7(1.9) | 78.4(3.0) | 1.547(0.082) | 0.724(0.082) |
% % | Best graph data augmentation | 70.2(1.0) | 82.4(2.4) | 1.565(0.098) | 0.755(0.039) |
% % | Ours                         | 70.8(0.5) | 85.6(0.6) | 1.339(0.075) | 0.717(0.020) |

% Results support our point that: the omitted method \textbf{does not} lead to cherry-picking of the compared methods. Our results also show that semi-supervised learning and graph data augmentation methods are competitive and sometimes even outperform the state-of-the-art self-supervised learning approaches. We have discussed the potential reasons for the limitations of self-supervised learning in molecular property prediction tasks in our motivation (lines 20-42) and presented experiment analysis in lines 256-267. Our results align closely with recent observations [13].

% Besides, the assertion that "The comparison to SOTA methods is missing" is potentially misleading. \textbf{We selected 15 baselines from graph self-supervised learning, graph semi-supervised learning, and graph data augmentation methods} to comprehensively cover a wide range of representative and state-of-the-art approaches. Our baselines include pioneering methods like those (Hu et al., 2019 and Velickovic et al., 2019) as mentioned by you, as well as the state-of-the-art methods in 2022 such as D-SLA [10], G-Mixup [11], and GREA [12]. We believe that our comparison with recent and broader approaches would reflect the advancements and trends in the field of molecular property prediction.



% Ref. 

% [10] Graph self-supervised learning with accurate discrepancy learning. NeurIPS 2022.

% [11] G-Mixup: Graph Data Augmentation for Graph Classification. ICML 2022.

% [12] Graph Rationalization with Environment-based Augmentations. KDD 2022.

% [13] Does gnn pretraining help molecular representation? NeurIPS 2022.

% (2)

% Thank you for your interesting questions. As visualized in Figure 6, the diffusion model can generate desirable molecules with the guidance of downstream predictor and targets. We believe it would be a promising direction to use our framework for the generation of novel molecules.



% 1. We select the state-of-the-art baselines broadly from three different categories (self-supervised learning, semi-supervised learning, and graph data augmentation) of methods and widely from 2019 to 2023. Specifically 

% two of them have already been included in our paper.



% \section{Review 1 6AKL}

% Thank you for providing feedback on our model details. Below, we offer detailed responses to each of your points.

% \subsection{To question 1 and 2 about the training of the diffusion model and dataset}

% We train one diffusion model for 14 molecule and polymer tasks on the unlabeled QM9 datasets. 

% We consider another task on protein-protein interaction (PPI) graphs. These graphs have proteins as nodes and protein-protein relations as edges, whereas molecular graphs have atoms as nodes and bonds as edges. It is not reasonable to transfer the knowledge about molecular graph structure to protein-protein interaction structure. Therefore, another diffusion model is trained on unlabeled PPI graphs for the downstream PPI tasks. 

% More details could be found in the baselines and implementation paragraph (lines 240-252). 

% \subsection{To question 3 about the training of the downstream prediction model}

% We adopt an iterative approach to train the downstream prediction model and create augmented graphs. As a result, the prediction model is trained on both the original labeled graphs and the newly generated labeled graphs from the second iteration onwards. The GIN model serves as the backbone, and we also report its performance in Table 1 as it is trained solely on the original labeled graphs. 

% \subsection{To question 4 about the perturbation}

% Thank you for your insightful questions. We use the hyper-parameter, the perturbation step $D$, to represent the scale of perturbation applied to the augmented graphs. To analyze the sensitivity of this hyper-parameter, we conducted experiments with $D$ ranging from 1 to 10, as illustrated in the top figure of Figure 4. We observed that DCT remains robust across a broad range of $D$ values, and we recommend setting $D$ to 5 as a default value. Further details on this analysis can be found in Section 5.3, specifically in lines 300 to 301 of the paper.

% \section{Review 2 T9FT}

% We sincerely value your feedback. We respectfully and firmly defend the originality, the literature review, and a fair evaluation of the performance of our model. We will begin by offering a concise overview of our rebuttal, followed by a comprehensive point-by-point elaboration.

% \subsection{Summary}
% (\underline{The first six references strictly adhere to the order used by the reviewer}.)

% 1. Originality: Our novelties and motivations: transfer learning by data augmentation are essentially different from the reference [1,2]. Another clear difference is that we focused on graph property prediction with automatic knowledge transfer from unlabeled graphs, while [1] focused on node classification and [2] focused on active learning.

% 2. Literature review: \textbf{We have already compared} both methods (MGSSL) from the reference [3] and (GraphLoG) from the reference [5] in our reported results and particularly \textbf{reviewed} the disadvantages of MGSSL [3]. The reference [4] is found not as good as the MGSSL [3] in the study of the reference [3].

% 3. Model performance: To ensure unbiased conclusions, we need (and have conducted) a fair evaluation, which should exclude complex training techniques like domain knowledge fingerprints and hybrid models. These techniques are broadly used in the ogbg-HIV leaderboard. 

% We give a detailed response to support our summary as follows.

% \subsection{To question 1 about originality}:

% We emphasize one of our major novelties and motivations: transfer learning by data augmentation is essentially different from the reference [1,2]. 

% 1.1. In our work, we primarily emphasize graph-level knowledge transfer, whereas [1] concentrates more on node-level tasks where the local graph structure holds greater importance. As indicated in the reported performance from [1] on the graph-level task ogbg-hiv, which stands at 76.18, it appears to be lower than our GIN implementation which achieves 77.4. These results potentially highlight the distinctions between node-level and graph-level approaches. For example, in this work, we find that local structures like aromatic rings could be misleading (see Lines 28-33 in our paper). Therefore, the gap between unlabeled distribution and task label distribution for graph data objectives is more important to address in our task.

% 1.2. The work [2] focused on another interesting topic: active learning for molecular property prediction. Active learning needs an oracle such as chemists, while we focus on automatically discovering useful knowledge from massive unlabeled graphs and transferring them to downstream tasks.

% In summary, the work [1,2] is interesting. We use generative modeling techniques in common, but it is crucial and undeniable to emphasize that our main focus lies in different areas, as described earlier. We will add extended discussions for potential connections and applications about node-level tasks and active learning. However, as demonstrated above, our originality clearly distinguishes it from [1,2].
% .

% \subsection{To question 2 about lack of literature review and evaluation}

% We would like to politely clarify that \textbf{we have already compared} both methods (MGSSL) [3] and (GraphLoG) [5] and particularly \textbf{reviewed} the disadvantages of MGSSL [3]. You can find our discussion on MGSSL [3] in lines 27-33 and a comparison with [3] and [5] in Table 1 (the 6th and 7th lines in the self-supervised section). The work [4] was proposed in 2020 and has been beaten by MGSSL, which was proposed in 2021. We would like to prefer more advanced techniques for comparison to leave more page space to comprehensively study the effectiveness of the proposed framework. However, we remain open to expanding our discussion for the reference [4], if it holds the potential to yield a broader impact on our research.

% \subsection{To question 3 about OGBG leaderboard}

% It is worth noting that the top-performing approaches on the ogbg-hiv leaderboard are the result of combining various training tricks and incorporating domain knowledge. Here are a few examples: (1) Fingerprint. It consists of domain knowledge rule extraction with expertise knowledge; (2) Advanced graph neural network (GNN) structures; (3) Hybrid models from different machine learning models and GNN models. Most of the existing graph pre-training models [5,7,9] do not include these tricks. We want to evaluate the model in line with these pre-training baselines. Besides, developing our method following the simplest setting helps avoid drawing spurious conclusions attributed to more complex models. In a fair evaluation, our method demonstrates notable improvements compared to 15 state-of-the-art baselines from self-supervised learning, semi-supervised learning, and graph data augmentation. Specifically, we achieve a reduction of 13.4\% in mean absolute error for the molecule graph regression task and 10.2\% for the polymer graph regression task.

% \subsection{To question 3 about the reported performance in [3,4,5]}

% We want to emphasize that direct comparisons between the reported numbers in our paper and those in papers [3,4,5] are not fair. The reason for the difference in reported numbers is due to different data splitting and underlying prediction models used in the evaluation process. While we generally follow the scaffold splitting method, the results may differ with different random seeds [7,8]. Additionally, in the work [4], three random-seeded scaffold splittings were used with the graph transformer as the backbone. These differences make direct comparisons with reported numbers in different papers impossible. In our paper, we ensure a unified and fair evaluation setting by implementing all baselines following [8].


% \subsection{Ref.} 

% [1] Liu, Songtao, et al. "Local augmentation for graph neural networks." International Conference on Machine Learning. PMLR, 2022.

% [2] Zhou, Kuangqi, et al. "Jointly Modelling Uncertainty and Diversity for Active Molecular Property Prediction." Learning on Graphs Conference. PMLR, 2022.

% [3] Zhang, Zaixi, et al. "Motif-based graph self-supervised learning for molecular property prediction." Advances in Neural Information Processing Systems 34 (2021): 15870-15882.

% [4] Rong, Yu, et al. "Self-supervised graph transformer on large-scale molecular data." Advances in Neural Information Processing Systems 33 (2020): 12559-12571.

% [5] Xu, Minghao, et al. "Self-supervised graph-level representation learning with local and global structure." International Conference on Machine Learning. PMLR, 2021.

% [6] https://ogb.stanford.edu/docs/leader\_graphprop/\#ogbg-molhiv 

% [7] Weihua, Wu et al. Strategies for pre-training graph neural networks.  International Conference on Learning Representations 2020.

% [8] Weihua Wu et al. Open graph benchmark: Datasets for machine learning on graphs. Advances in neural information processing systems. 2020.

% [9] Kim, D., Baek, J., \& Hwang, S. J. Graph self-supervised learning with accurate discrepancy learning. Advances in Neural Information Processing Systems. 2022.


% \section{Reviewer 3 trSH}

% \subsection{To weakness 1 and question 2 about the diffusion model on graphs}
% % (weak 1 and question 2).

% Thanks for your comments.

% We follow [1,2] to define graph diffusion models. [2] unified score-based generative models and denoising diffusion probabilistic models, using stochastic differential equations (SDE) in continuous state spaces. [1] extended [2] to graphs. Besides [2], there are many recent work that has verified the effectiveness of the diffusion models on graphs [3,4,5]. We also want to point out that, differing from the existing work [1,3,4,5], which mainly focused on advancing the generative performance of the diffusion model, we propose to leverage the diffusion model for predictive tasks via data augmentation and knowledge transfer. Here, we present a more careful review to discuss recent advances for diffusion models on graphs.

% On how to apply the diffusion model to graph structure and node features, we mainly follow the idea from [1,2] as follows:

% Given a graph data point $G \in \mathcal{G}$ in the graph space with the adjacency matrix $\mathbf{A} \in \mathbb{R}^{N \times N}$ and the node feature matrix $\mathbf{X} \in \mathbb{R}^{N\times F}$, where $N$ is the number of nodes and $F$ is the dimension of node features, [1] extended the above SDE to the graph data $G \in \mathbb{R}^{N\times N} \times \mathbb{R}^{N\times F} $ as:
% $$
% d\mathbf{G}^{(t)}=\mathbf{f}(G^{(t)},t)dt + g(t)d\mathbf{w}.
% $$
% We have presented it in our Eq. (3). Starting with $\mathbf{x}^{(T)}\sim p_T$ and reversing the diffusion process, we sample $x^{(0)} \sim p_0$. The reverse of the diffusion process is another diffusion process, as described in [2]:
% $$
% d \mathbf{x}^{(t)}= [\mathbf{f}(\mathbf{x}^{(t)},t)-g(t)^2 \nabla_{\mathbf{x}^{(t)}} \log p_t (\mathbf{x}^{(t)}) ]d {t} + g(t)d\mathbf{\bar{w}},
% $$
% where $d {t}$ is an infinitesimal negative timestep flowing backward from $T$ to $0$ and $\mathbf{\bar{w}}$ is a standard Wiener process. $\log p_t (\mathbf{x}^{(t)})$ denotes the log likelihood of the marginal distribution of $\mathbf{x}^{(t)}$ at the timestep $t$. $\log p_t (\mathbf{x}^{(t)}) $ is often referred to as the score in the diffusion model. 
% [1] extended the reverse diffusion process to the graph data and proposed a new graph diffusion process that models the joint distribution of the nodes and edges:
% $$
% d G^{(t)}= [\mathbf{f}(G^{(t)},t)-g(t)^2 \nabla_{{G}^{(t)}} \log p_t ({G}^{(t)}) ]d{t} + g(t)d\mathbf{\bar{w}}.
% $$
% Our Eq.(4) follows this equation. Here the diffusion model uses neural networks to learn and estimate the score in the reverse process. On graph data, to avoid the estimation of the high-dimensional score $\nabla_{G^{(t)}} \log p_t ({G}^{(t)}) \in \mathbb{R}^{N \times N} \times \mathbb{R} ^ {N \times F} $, [1] assumed that the transition distribution $p_{0t} (G^{(t)} | G^{(0)}) $ from the time $0$ to the time $t$ in the forward process could be:
% $$
% p_{0t} (G^{(t)} | G^{(0)}) =  p_{0t} (\mathbf{X}^{(t)} | \mathbf{X}^{(0)})  p_{0t} (\mathbf{A}^{(t)} | \mathbf{A}^{(0)}).
% $$

% In this way,  [1] separated the estimation of $d \mathbf{G^{(t)}} $ in the reverse process into two parts: node feature estimation $d \mathbf{X^{(t)}} $ and edges feature (i.e., adjacency matrix) estimation $d \mathbf{A^{(t)}}$:
% $$
% d \mathbf{X^{(t)}}= [\mathbf{f}_1(\mathbf{X}^{(t)},t)-g_1(t)^2 \nabla_\mathbf{X^{(t)}} \log p_t (\mathbf{X}^{(t)},\mathbf{A}^{(t)}) ]d{t} + g_1(t)d\mathbf{\bar{w}_1}
% $$
% $$
% d \mathbf{A^{(t)}}= [\mathbf{f}_2(\mathbf{A}^{(t)},t)-g_2(t)^2 \nabla_\mathbf{X^{(t)}} \log p_t (\mathbf{X}^{(t)},\mathbf{A}^{(t)}) ] d{t} + g_2(t)d\mathbf{\bar{w}_2}. 
% $$
% Here $\mathbf{f}_1$ and $\mathbf{f}_2$ are linear drift coefficients satisfying $\mathbf{f} (G, t) = (\mathbf{f}_1(\mathbf{X}, t), \mathbf{f}_2(\mathbf{A}, t))$. $g_1$ and $g_2$ denote scalar diffusion coefficients. $\mathbf{\bar{w}_1}$ and $\mathbf{\bar{w}_2}$ denote the reverse-time standard Wiener processes. To estimate $\nabla_\mathbf{X^{(t)} } \log p_t (\mathbf{X}^{(t)},\mathbf{A}^{(t)})$ and $\nabla_\mathbf{A^{(t)}} \log p_t (\mathbf{X}^{(t)},\mathbf{A}^{(t)})$, [1] used two separate graph neural networks trained with score matching methods [2].

% Following [1], we perform functions on graphs, such as $\mathbf{f}(\cdot,t)$, separately on the node feature variable $\mathbf{X}$ and adjacency matrix variable $\mathbf{A}$. The marginal distribution of the graph probability $p_t(G^{(t)})$ at time step $t$ is also defined from two aspects: the node feature $\mathbf{X}$ and the adjacency matrix $\mathbf{A}$. The ground-truth gradient for the probability or $\log p_t(G^{(t)})$ is estimated by two graph neural networks: one estimates $\nabla_{\mathbf{X}^{(t)}} \log p_t (\mathbf{X}^{(t)}, \mathbf{A}^{(t)})$ for node features, and the other estimates $\nabla_{\mathbf{A}^{(t)}} \log p_t (\mathbf{X}^{(t)}, \mathbf{A}^{(t)})$ for adjacency matrices. These neural networks are trained by score matching methods [2]. We kindly note that certain descriptions are available in our paper, particularly in Section 4.2. Unfortunately, due to the page limit, many details were moved to the appendix such as the B.3 section. For more details, including equations, instantiations, and algorithms, we kindly direct reviewers to the appendix. Additionally, we will add more details to the main text.

% \subsection{To weakness 2 about the literature review on pseudo-labeling}

% Thanks for your suggestion. Pseudo-labeling is a common technique for semi-supervised learning [6,7] to address the small data problem. It first trains a model that iteratively assigns pseudo-labels to the set of unlabeled training examples. The pseudo-labeled examples are then used to enrich the labeled training set. And the model continues training with the updated training set. Many studies have explored improving uncertainty estimation [8,9,10] to help the model filter out noise and keep reliable pseudo-labels. Recently, pseudo-labels have been applied in imbalanced learning [11] and representation learning [12]. Pseudo-label methods are restricted to confidently predictable labels and may ignore the huge number of other unlabeled data.

% \subsection{To question 1 about performance drop in Figure 4 when increasing top-$n$}

% The performance drop from increasing augmented graphs per iteration could have multiple reasons. A key factor is the noisy graphs introduced with a high hyper-parameter $n$ in Figure 4 (e.g., > 30\%). We use an iterative process for training and augmented graph creation, expecting mutual enhancement (confirmed in Figure 5). As the downstream prediction model isn't perfect during augmented graph creation, we select only top-$n$ lowest property prediction loss to prevent noisy graph generation. When the top-$n$ is very high, like larger than 30\%, the noisy graphs would cause the performance drop as shown in Figure 4. We have discussed this phenomenon in lines 301-304 and lines 224-227.

% Regarding the concern of overfitting, we have briefly talked about it in lines 178-183. We discussed the balance between task-relatedness and diversity in generating augmented graphs. Limited diversity can lead to overfitting, thus we employ minimality (definition 4.2) to enhance augmented graph diversity.

% \subsection{To question 3 about the explanation of Definition 4.2}

% Thank you for your comments. Here we provide more details.$\forall \bar{G}$ represents any augmented graph that sufficiently preserves the original graph's label (as defined in Definition 4.1). We will add these details to clarify this definition in the paper.

% \subsection{ref}

% [1] Jo, J., Lee, S., \& Hwang, S. J. Score-based generative modeling of graphs via the system of stochastic differential equations. ICML 2022.

% [2] Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., \& Poole, B. Score-based generative modeling through stochastic differential equations. ICLR, 2021.

% [3] Kong, L., Cui, J., Sun, H., Zhuang, Y., Prakash, B. A., \& Zhang, C. Autoregressive Diffusion Model for Graph Generation. ICML 2023.

% [4] Chen, X., He, J., Han, X., \& Liu, L. P.  Efficient and Degree-Guided Graph Generation via Discrete Diffusion Modeling. 2023 ICML.

% [5] Vignac, C., Krawczuk, I., Siraudin, A., Wang, B., Cevher, V., \& Frossard, P. Digress: Discrete denoising diffusion for graph generation. ICLR 2023.

% [6] Iscen, A., Tolias, G., Avrithis, Y., \& Chum, O. Label propagation for deep semi-supervised learning. CVPR 2019.

% [7] Lee, D. H. Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks. In Workshop on challenges in representation learning, ICML 2013.

% [8] Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model uncertainty in deep learning. ICML 2016.

% [9] Natasa Tagasovska and David Lopez-Paz. Single-model uncertainties for deep learning. NeurIPS 2019.

% [10] Alexander Amini, Wilko Schwarting, Ava Soleimany, and Daniela Rus. Deep evidential regression. NeurIPS 2020.

% [11] Wei, C., Sohn, K., Mellina, C., Yuille, A., \& Yang, F. Crest: A class-rebalancing self-training framework for imbalanced semi-supervised learning. CVPR 2021.

% [12] Ghiasi, G., Zoph, B., Cubuk, E. D., Le, Q. V., \& Lin, T. Y. Multi-task self-training for learning general representations. CVPR 2021.


% \section{Reviewer 4 3gzg}

% \subsection{To weakness 1 about the literature review on graph diffusion model}

% Thanks for your comments. Here are discussions on recent advances for diffusion models on graphs.

% Recent works have improved the generative modeling of diffusion models on graphs [1,2,3,4,5]. EDP-GNN [1] employed score matching for permutation-invariant graph data distribution. GDSS [2] extended continuous-time framework [6] to model node-edge joint distribution. DiGress [3] used the transition matrix to preserve the discrete natures of the graph structure. GraphARM [4] introduced a node-absorbing autoregressive diffusion process. EDGE [5] focused on efficiently generating larger graphs. Instead of improving the generation capacity of the diffusion model, our model builds on [2,6] for predictive tasks, i.e., graph classification and graph regression. Our focus is on improving the transfer of knowledge from unlabeled graphs to various downstream tasks with the diffusion model.

% We will add the above discussion to the main text.

% \subsection{To weakness 2 about lines 318-319}

% Thank you for your valuable suggestions. To validate our hypothesis regarding the transfer of chemical rules from unlabeled graphs to downstream tasks, we gathered 1,000 task-specific graphs generated in the intermediate steps. We then assessed the chemical validity of these graphs on two classification tasks (ogbg-BACE and ogbg-BBBP) and two regression tasks (ogbg-FreeSolv and O$_2$Perm). The outcomes of these evaluations are summarized in the table below.

% \begin{table}[h]
% \begin{tabular}{lllll}
%          & BACE    & BBBP    & FreeSolv & O$_2$Perm \\
% Validity (\%) & 0.928   & 0.879   & 0.974    & 0.621  \\
% % Same/valid tot     & 214/928 & 569/879 & 474/974  & 38/621
% \end{tabular}
% \end{table}

% % |              |  BACE   | BBBP    | FreeSolv | O$_2$Perm |
% % |--------------|---------|---------|----------|--------|
% % | Validity (\%) | 0.928   | 0.879   | 0.974    | 0.621  |

% First, we observe that the validity is close to 0.9\% in most cases, validating our claim. Furthermore, transferring knowledge from pre-trained molecular data to target molecules has relatively high chemical validity. However, the validity drops to 62\% when transferring knowledge from pre-trained molecular data to target polymer data. This finding indicates that the transferability of chemical rules becomes more challenging when the distribution gap between pre-training data and downstream task data is larger. We will incorporate these findings into the main text accordingly.


% \subsection{To question 1 about lines 46-48}

% Thanks for your suggestions. We described our high-level ideas in lines 43--49. Technical details about the implementation of our idea could be found in lines 50--65 and all of Section 4. Specifically for your question for lines 46--48, we break the question into two parts: (1) how to generate graphs to close the gap between the unlabeled graphs and a specific task (2) how to use the generated task-specific graphs. A brief discussion on (1) could be found in lines 56--64 and details could be found in Section 4.3 (Lines 169--211). A brief discussion on (2) could be found in lines 64--65 and details could be found in Section 4.3 (Lines 212--226)

% Here we summarize the important points. For (1), we use two task-related losses to guide the generation of the diffusion model. So, the generated graphs are task-specific. For (2), we use an iterative process to alternatively generate task-specific graph data and train the downstream prediction model. The model is first trained on all the downstream labeled data and then the partially trained model is used to guide the generation of task-specific generated graphs. Then we start a new iteration and repeat training the model.

% \subsection{To question 2 about lines 60-61}

% Thanks for your question, as stated in lines 64--65:

% ```
% DCT iteratively generates new examples to augment the labeled dataset and
% 65 progressively trains the prediction model with it.
% ```

% We will iteratively update the downstream prediction model ($f$). We hypothesize that model training and task-specific data generation mutually enhance each other. This assumption is common in self-training [7,8,9,10]. We also empirically validated this assumption in Figure 5. Details are in lines 305-311.

% \subsection{To question 3 about the use of other diffusion models}

% We adopt the general framework [2,6] for continuous-time diffusion modeling via stochastic differential equations (SDE). Practical implementation requires discretizing SDE in both the diffusion and reverse process, yielding various model instances like SMLD [11] and DDPM [12]. Our adaptable framework could accommodate these Diffusion models and their extensions with minimal adjustments. We note that the framework [2,6] uses Gaussian noise for data perturbation and noise estimation in reverse processes, while DiGress [3] employs discrete noise, predicting clean graphs from perturbed ones. Corresponding code adjustments are needed for different noise types and model outputs.



% % Can other graph diffusion model methods be applied to the graph property prediction task with trivial adaptation? If not, why?




% ------

% Reference:

% [1] Niu, C., Song, Y., Song, J., Zhao, S., Grover, A., and Ermon,
% S. Permutation invariant graph generation via score-based
% generative modeling. AISTATS, 2020.

% [2] Jo, J., Lee, S., \& Hwang, S. J. Score-based generative modeling of graphs via the system of stochastic differential equations. ICML 2022.

% [3] Vignac, C., Krawczuk, I., Siraudin, A., Wang, B., Cevher, V., \& Frossard, P. Digress: Discrete denoising diffusion for graph generation. ICLR 2023.

% [4] Kong, L., Cui, J., Sun, H., Zhuang, Y., Prakash, B. A., \& Zhang, C. Autoregressive Diffusion Model for Graph Generation. ICML 2023.

% [5] Chen, X., He, J., Han, X., \& Liu, L. P.  Efficient and Degree-Guided Graph Generation via Discrete Diffusion Modeling. 2023 ICML.

% [6] Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., \& Poole, B. Score-based generative modeling through stochastic differential equations. ICLR, 2021.

% [7] Iscen, A., Tolias, G., Avrithis, Y., \& Chum, O. Label propagation for deep semi-supervised learning. CVPR 2019.

% [8] Lee, D. H. Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks. In Workshop on challenges in representation learning, ICML 2013.

% [9] Wei, C., Sohn, K., Mellina, C., Yuille, A., \& Yang, F. Crest: A class-rebalancing self-training framework for imbalanced semi-supervised learning. CVPR 2021.

% [10] Ghiasi, G., Zoph, B., Cubuk, E. D., Le, Q. V., \& Lin, T. Y. Multi-task self-training for learning general representations. CVPR 2021.

% [11] Song Y, Ermon S. Generative modeling by estimating gradients of the data distribution. NeurIPS 2019.

% [12] Ho, J., Jain, A., \& Abbeel, P.  Denoising diffusion probabilistic models. NeurIPS 2020.


% % 2. Visibility transfer.
% % Statistics on the validity of augmented graphs. (Some new coding work)

% % 3. Details on training framework

% % 3.1 Please describe how to use these generated task-specific labeled examples to bridge the gap between the final prediction and the generated graph.

% % ? Explain how to use augmented graphs for the training of final prediction model.

% % 3.2 How predictor trained, explain the mutual enhancement between augmentation and predictor training.

% % 4. Other diffusion model.

% % could be adapted to the proposed model. Many variants of SDE.



\end{document}

