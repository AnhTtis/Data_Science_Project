\def\I{{\mathcal{I}}}
\def\P{{\mathcal{P}}}
% \begin{figure*}[htp!]
%     \begin{minipage}[c]{0.67\textwidth}
%     \includegraphics[width=\textwidth]{figures/implementation_v3.pdf}
%     \end{minipage}\hfill
%     \begin{minipage}[c]{0.3\textwidth}
%     \caption{
%     The diffusion model in DCT: It performs task-specific data augmentation on graph data using two task-related optimization objectives $\I_1$ and $\I_2$ in the reverse process. The model was trained on unlabeled graphs to learn the general data distribution. Then it generates $(G^\prime,y^\prime=y)$ based on $(G,y)$ in the reverse process. It perturbs $G$ with $D$ steps and optimizes $G^\prime$ to be minimally similar to $G$ (Objective $\I_1$) and sufficiently preserve the label of $G$ (Objective $\I_2$).
%     } \label{fig:implementation}
%   \end{minipage}
% \end{figure*}
\begin{figure*}[ht]
\centering
\includegraphics[width=0.85\textwidth]{figures/implementation_v3.pdf}
\caption{
The diffusion model in DCT: It performs task-specific data augmentation on graph data using two task-related optimization objectives $\I_1$ and $\I_2$ in the reverse process. The model was trained on unlabeled graphs to learn the general data distribution. Then it generates $(G^\prime,y^\prime=y)$ based on $(G,y)$ in the reverse process. It perturbs $G$ with $D$ steps and optimizes $G^\prime$ to be minimally similar to $G$ (Objective $\I_1$) and sufficiently preserve the label of $G$ (Objective $\I_2$).
} \label{fig:implementation}
\end{figure*}

\begin{figure*}[ht]
    \centering
    % \vspace{-0.1in}
    \includegraphics[width=0.99\linewidth]{figures/compare_real_gen_runs.pdf}
    % \vspace{-0.1in}
    \caption{
    Relative improvement (increased AUC or reduced MSE) from three data-centric methods (over ten runs), compared to the basic GIN: Blue is for self-training with selected real unlabeled graphs. Green is for self-training with graphs directly generated by a standard diffusion model. Red is for \method that uses our proposed task-specific data augmentation method.
    The first two often make little or negative impact. Our \method has consistent and significant improvement shown as the percentages in \textcolor[rgb]{0.83137255, 0.22745098, 0.22745098}{red}.
    }
    \label{fig:compare gnn runs}
    % \vspace{-0.15in}
\end{figure*}

% \vspace{0.04in}
\subsection{Overview of Proposed Framework}
\label{sec:overview}

The goal of data-centric approaches is to augment training datasets by generating useful labeled data examples. Under that, the goal of our data-centric transfer (\method) framework is to \textit{transfer} the knowledge from unlabeled data into the data augmentation.
Specifically, for each graph-label pair $(G^{[k]} \in \mathcal{G}^{[k]} $, $y^{[k]} \in \mathcal{Y}^{[k]})$ in the task $k$,
the framework is expected to output a new example $G^{\prime[k]}$ with the label $y^{\prime[k]}$ such that (1) $y^{\prime[k]} = y^{[k]}$ and (2) $G^{\prime[k]}$ and $G^{[k]}$ are from the same graph space $\mathcal{G}^{[k]}$. However, if the graph structures of $G^{\prime[k]}$ and $G^{[k]}$ were too similar, the augmentation would duplicate the original data examples, become useless, and even cause over-fitting. So, the optimal graph data augmentation should \textit{enrich the training data with good diversity as well as preserve the labels of the original graphs}.
To achieve this, \method utilizes a diffusion probabilistic model to first \textit{learn the data distribution from unlabeled graphs} (Section~\ref{sec:learning}). Then \method adapts the reverse process in the diffusion model to \textit{generate task-specific labeled graphs for data augmentation} (Section~\ref{sec:generating}).
Thus, the augmented graphs will be derived from the distribution of a huge collection of unlabeled data for \textit{diversity}. To \textit{preserve the labels}, \method controls the reverse process with two {task-related optimization objectives} to transfer \textit{minimal sufficient knowledge} from the unlabeled data. The first objective minimizes an upper bound of mutual information between the augmented and the original graphs in the graph space. The second objective maximizes the probability of the predicted label of augmented graphs being the same as the label of original graphs.
The first is for minimal knowledge transfer, and the second is for sufficient knowledge transfer.
\method integrates the two objectives into the reverse process of the diffusion model to guide the generation of new labeled graphs.
\method iteratively trains the graph property predictor (used in the second objective) and creates the augmented training data.

To simplify notations, we remove the task superscript $[k]$ in the following sections.

\subsection{Learning Data Distribution from Unlabeled Graphs}
\label{sec:learning}

As shown in~\cref{fig:implementation}, the diffusion model corrupts unlabeled graphs to a standard normal distribution by slowly perturbing the data with noise. For graph generation, the model samples noise from the normal distribution and learns a score function to reverse the perturbed noise.
Given an unlabeled graph $G$, we use continuous time $t \in [0,T]$ to index multiple diffusion steps $\{G^{(t)}\}_{t=1}^T$ on the graph, such that $G^{(0)}$ follows the original data distribution and $G^{(T)}$ follows a prior distribution like the normal distribution. The forward diffusion is a stochastic differential equation (SDE) from the graph to the noise:
\begin{equation}\label{eq:forward graph SDE}
\mathrm{d} G^{(t)}=\mathbf{f} \left(G^{(t)}, t \right) \mathrm{d} t+g(t)~\mathrm{d} \mathbf{w},
\end{equation}
where $\mathbf{w}$ is the standard Wiener process (Brownian motion), $\mathbf{f}(\cdot, t): \mathcal{G} \rightarrow \mathcal{G}$ is the drift coefficient and $g(t): \mathbb{R} \rightarrow \mathbb{R}$ is the diffusion coefficient. $\mathbf{f}(G^{(t)}, t)$ and $g(t)$ relate to the amount of noise added to the graph at each infinitesimal step $t$. The reverse-time SDE uses gradient fields or scores of the perturbed graphs $\nabla_{G^{(t)}} \log p_t(G^{(t)})$ for denoising and graph generation from $T$ to $0$~\citep{song2020score}:
\begin{equation}\label{eq:reverse graph SDE}
\mathrm{d} G^{(t)} =\left[\mathbf{f}(G^{(t)}, t)-g(t)^2 \nabla_{G^{(t)}} \log p_t(G^{(t)})\right] \mathrm{d} t+g(t) \mathrm{d} \overline{\mathbf{w}},
\end{equation}
where $p_t(G^{(t)})$ is the marginal distribution at time $t$ in forward diffusion. $\overline{\mathbf{w}}$ is a reverse time standard Wiener process. $\mathrm{d} t$ here is an infinitesimal negative time step. The score $\nabla_{G^{(t)}} \log p_t(G^{(t)})$ is unknown in practice and it is approximated by the score function $\mathbf{s}(G^{(t)}, t)$ with score matching techniques~\citep{song2020score}. On graphs, \citet{jo2022score} used two GNNs to develop the score function $\mathbf{s}(G^{(t)}, t)$ to de-noise both node features and graph structures.

% \citet{jo2022score} used two GNNs as the score function $\mathbf{s}(G^{(t)}, t)$ to approximate the unknown score $\nabla_{G^{(t)}} \log p_t(G^{(t)})$ from both node and edge aspects. Each GNN is trained to capture the dependencies of nodes and edges at each time step. Usually, $G^{(t)}$ is calculated from $G^{(0)}$ in one step to train the score function $\mathbf{s}(G^{(t)}, t)$ with score matching~\citep{song2020score}.


 % Once the score function has been trained on unlabeled graphs, the diffusion model samples from a standard normal prior and use the reverse process in~\cref{eq:reverse graph SDE} to generate graphs. The generated graphs have the same data distribution as real unlabeled graphs. The generated graphs have the same distribution as real unlabeled graphs, When used, for example in self-training, they should have similar effects on the prediction model.

\subsection{Generating Task-specific Labeled Graphs}
\label{sec:generating}

\vspace{-0.05in}
\textit{Self-training} approaches would propose to either (1) select unlabeled graphs by a graph property predictor or (2) generate graphs directly from the standard diffusion model, and then use the predictor to assign them labels so that the training data could be enriched.
However, we have observed that neither of them can guarantee positive impact on the prediction performance. In fact, as shown in~\cref{fig:compare gnn runs}, they make very little or even negative impact.
That is because \textit{the selected or directly-generated graphs are too different from the labeled graph space of the target tasks}. Task details of ten datasets are in~\cref{sec: add exp setups}.

% As the unlabeled graphs are not task-specific, the real and generated unlabeled graphs would negatively affect the prediction performance as they are different from the labeled graphs in both graph and label spaces. To justify our assumptions, we set-up an experiment to use the self-training on both real and generated unlabeled graphs~\citep{ramakrishnan2014quantum}. Results on the test set of ten datasets are in~\cref{fig:compare gnn runs}. Task details are in~\cref{sec: add exp setups}.

% Although the self-training model using the generated unlabeled graphs has a similar performance with the self-training model using the real unlabeled graphs, both self-training models are negatively impacted by the unlabeled graphs on the task of \bbbp, \toxcast, \clintox, \melting, \glass, and \oxygen.  The potential risks of directly using unlabeled graphs emphasize the importance of generating task-specific data to close the gap between unlabeled and labeled graphs in the graph and label spaces.

% We find that real and generated unlabeled graphs impact the prediction performance in a similar way, \ie they both have positive impacts on three tasks (\hiv, \bace, and \sider) and negative impacts on six tasks (\bbbp, \toxcast, \clintox, \melting, \glass, and \oxygen). 
% The prediction model cannot distinguish between unlabeled graphs generated or those from the real dataset. It justifies that the diffusion model in the \method successfully models the data distribution of unlabeled graphs. However, most negative impacts indicate potential risks of directly using unlabeled graphs or the diffusion model.

% To close the gap, we (1) adapt the diffusion model to take the labeled graphs as inputs and (2) optimize the augmented examples to transfer task-related knowledge.

% Once the score function has been trained on unlabeled graphs, the generated examples from the diffusion model and the real unlabeled graphs should follow the same data distribution and have similar impacts on the prediction model. To justify its rationale, we set up self-training experiments to use real and generated unlabeled graphs on seven molecule classification~\citep{hu2020open} and three polymer regression~\citep{liu2022graph} tasks. The real unlabeled molecules are from QM9~\citep{ramakrishnan2014quantum}. The diffusion model~\citep{jo2022score} is trained on QM9 to provide the same number of generated examples. 

% Results on the test sets are in~\cref{fig:compare real gen five runs}. We find that real and generated unlabeled graphs impact the prediction performance in a similar way, \ie they both have positive impacts on three tasks (hiv, bace, and sider) and negative impacts on six tasks (bbbp, clintox, toxcast, oxygen, melting, and glass). The prediction model cannot distinguish between unlabeled graphs generated or those from the real dataset. It justifies that the diffusion model in the \method successfully models the data distribution of unlabeled graphs. However, most negative impacts indicate potential risks of directly using unlabeled graphs or the diffusion model.

% \cref{fig:compare real gen five runs} shows that unlabeled graphs could negatively affect the prediction performance as they are different from the labeled graphs in both graph and label spaces. 

Given a labeled graph ($G,y$) from the original dataset of a specific task, the new labeled graph $(G^\prime,y^\prime)$ is expected to provide \textit{useful knowledge to augment} the training set. We name it \emph{the augmented graph} throughout this section. The augmented graph is desired to have the following two properties, as discussed in~\cref{sec:overview}:
\begin{compactitem}
\item Task relatedness: As an effective training data point, $G^\prime \in \mathcal{G}$ and $y^\prime \in \mathcal{Y}$ are from the graph/label spaces of the specific task where $(G,y)$ come from and thus transfer sufficient task knowledge into the training set.
\item Diversity: If $G^\prime$ was too similar to $G$, the new data point would cause severe over-fitting on the property prediction model. The augmentation aims to learn from unlabeled graph to create diverse data points, which should contain minimal task knowledge about $G$.
\end{compactitem}

The selected unlabeled graphs used in \textit{self-training} could have little task relatedness, because the unlabeled data distribution might be too far from the one of the specific task. On the other hand, existing graph \textit{data augmentation} methods could not create diverse graph examples because they manipulated labeled graphs and did not learn from the unlabeled graphs. Our novel data-centric approach \method works towards both desired properties by transferring \textit{minimally sufficient knowledge} from the unlabeled graphs:
\begin{compactitem}
\item \textit{Sufficiency} is achieved by maximizing the possibility for label preservation (i.e., $y^\prime = y$). It ensures that the knowledge from unlabeled graphs is task-related.
\item \textit{Minimality} refers to the minimization of graph similarity between $G^\prime$ and $G$ to ensure that the augmentation introduces diversity.
\end{compactitem}

% Given any labeled graph in a specific task ($G,y$), the augmented graph $(G^\prime,y^\prime)$ is created from the space of $G$ and is desired to satisfy two properties, as given in~\cref{sec:overview}:
% \begin{compactitem}
% \item Label-Preservation: $y^\prime=y$ indicates that the augmented graph is still in the label space of the task.
% \item Diversity: $G^\prime$ should be less similar to $G$ though they are in the same graph space.
% \end{compactitem}
% Self-training, to some extent, could be thought of as the data augmentation that creates input-irrelevant examples to enrich the dataset. It shows that although unlabeled data is a good source to increase the diversity of the augmented data, redundant noise would also be introduced from a totally different unlabeled data distribution. 

% \method works toward two desired properties to transfer minimally sufficient knowledge from unlabeled graphs. The sufficiency is achieved by the maximization of the possibility for label preservation. It ensures that the knowledge from unlabeled graphs is task-related. Meanwhile, \method minimizes graph similarity between $G^\prime$ and $G$ to ensure the unlabeled knowledge introduces diversity. Formally, the minimal sufficient knowledge transfer by data augmentation could be formulated using mutual information $\I(\cdot \ ; \cdot)$:

In the context of data augmentation, both optimizations can be formulated using mutual information $\I(\cdot \ ; \cdot)$:
\begin{definition}[Sufficiency for Data Augmentation]
    The augmented graph $G^\prime$ sufficiently preserves the label of the original graph $G$ if and only if $\I(G^\prime;y) = \I(G;y) $.
\end{definition}

\begin{definition}[Minimal Sufficiency for Data Augmentation]
    The Sufficiency is minimal for data augmentation if and only if $\I(G^\prime; G) \leq \I(\bar{G}; G)$, $\forall \bar{G}$ is sufficient.
\end{definition}
% In other words, the minimal sufficient data augmentation encourages the transfer of task-related knowledge. It avoids redundant knowledge from the unlabeled graphs to the graph space of the labeled graph $G$. 

Self-supervised tasks applied a similar philosophy in pre-training~\citep{soatto2014visual}, however, they did not use labeled data from any specific tasks. So the optimizations were unable to extract useful knowledge and transfer it to the downstream~\citep{tian2020makes}.
% Without knowing the specific downstream task, the optimal is hard to achieve~\citep{tian2020makes}.
In our \method that performs task-specific data augmentation, the augmented graphs can be optimized toward the objectives using any labeled graph $G$ and its label $y$:
\begin{equation}\label{eq:fine-tune objective}
    \min_{\I_1}\max_{\I_2} \ \ \mathbb{E}_{G} \left[ 
    \I_1\left(G^\prime; G \right) + \I_2\left(G^\prime; y\right) 
    \right].
\end{equation}
% Essentially, \method introduces additional knowledge to minimize the mutual information between the augmented graph with the original one to a ``bottleneck'' that maximally supports the label prediction~\citep{tishby2000information}.
For the first objective, we use the leave-one-out variant of {InfoNCE}~\citep{poole2019variational,oord2018representation} as the upper bound estimation. For the $i$-th labeled graph $(G_i,y_i)$,
\begin{equation}\label{eq:upper bound infonce}
    \I_1 \leq \I_\text{bound} (G_i^\prime; G_i) = 
    \log \frac{p(G_i^\prime |G_i)}{\sum_{j=1,j \neq i}^{M} p(G_i^\prime | G_j)} ,
\end{equation}
where
$G_i^\prime$ is the augmented graph.
When $G_i^\prime$ is optimized, $G_i$ makes a positive pair; $\{G_j\}$ ($j\neq i$) are $M-1$ negative samples of labels that do not equal $y_i$. ($M$ is a hyperparameter.)
% $G_i$ is the positive (augmentation input) graph of $G_i^\prime$ and $G_j$ ($j\neq i$) indicates $M-1$ negative samples with different labels.
We use cosine similarity and a softmax function to calculate $p(G_i^\prime|G_j)=\frac{\exp({\operatorname{sim}(G_i^\prime, G_j) })}{\sum_{j=1}^M \exp({\operatorname{sim}(G_i^\prime, G_j) }) }$.  
In practice, we extract statistical features of graphs to calculate their similarity. Details are in \cref{add:sec:raw feature}.

For the second objective, we denote the predicted label of the augmented graph $G^\prime$ by $f_\theta(G^\prime)$.
% to measure $\I_2(G^\prime; y)$.
We maximize the log likelihood $\operatorname{log} p \left(y | f_\theta(G^\prime) \right)$ to maximize $\I_2(G^\prime; y)$.
Specifically, after the predictor $f_\theta$ is trained for several epochs on the labeled data, we freeze its parameters and use it to optimize the augmented graphs so they are task-related:
\begin{equation}\label{eq:fine-tune loss}
% \begin{split}
    \mathcal{L} (G^\prime) = 
    \I_\text{bound}\left(G^\prime; G \right) 
    - \operatorname{log} p \left(y | f_\theta(G^\prime) \right).
% \end{split}
\end{equation}
% $ \nabla_{G^{(t)}} \mathcal{L}_\textbf{aug}(G^{(t)})$ with the norm of $\mathbf{s}(G^{(t)}, t)$ 

% \textit{Task Guided Diffusion-based Augmentation}
% With the diffusion model, we optimize the augmented graphs by compositing the score $\mathbf{s}(\cdot, t)$ with~\cref{eq:fine-tune loss}. Therefore, we extend the~\cref{eq:reverse graph SDE} to be task guided:
% Graph generation in the diffusion model corrupts all graphs to the same noise distribution.
% the diversity of the augmented graph $G^\prime$ is achieved by guiding the denoising of $\Tilde{G}^{(D)}$ with the score function of~\cref{eq:reverse graph SDE} on unlabeled data in $D$ steps.

% With diversity from unlabeled graphs, \method So, we propose two optimization objectives for data augmentation with the minimal sufficient principle~\citep{tian2020makes, soatto2014visual}.
% and extends the~\cref{eq:reverse graph SDE} to be:

% \method begins within the task-specific graph space using labeled graphs as input.
\vspace{-0.2in}
\paragraph{Framework details:} After the diffusion model learns the data distribution from unlabeled graphs, given a labeled graph $G$ from a specific task, \method perturbs it for $D$ ($D \ll T$) steps. The perturbed noisy graph, denoted by $\Tilde{G}^{(D)}$, stays inside the task-specific graph and label space, rather than the noise distribution (at step $T$).
% Suppose the perturbed graph is $\Tilde{G}^{(D)}$,
To reverse the noise in it and generate a task-specific augmented example $G^\prime$, \method integrates the loss function in~\cref{eq:fine-tune loss} into the score function $\mathbf{s}(\cdot, t)$ for minimal sufficient knowledge transfer:
% \begin{equation}
\begin{align}\label{eq:finetune guided reverse SDE}
    % & \mathrm{d} \Tilde{G}^{(t)} = g(t) \mathrm{d} \overline{\mathbf{w}} +
    \mathrm{d} \Tilde{G}^{(t)} = \left[\mathbf{f}(\Tilde{G}^{(t)}, t) - g(t)^2 \left(\mathbf{s}(\Tilde{G}^{(t)}, t) - \alpha \nabla_{\Tilde{G}^{(t)}} \mathcal{L}(\Tilde{G}^{(t)}) \right) \right] \mathrm{d}t
    +g(t) \mathrm{d} \overline{\mathbf{w}},
\end{align}
% \end{equation}
where $\alpha$ is a scalar for score alignment between $\mathbf{s}$ and $\nabla\mathcal{L}$ to avoid the dominance of any of them:
% The norms of the two guidance terms in the equation are usually different. It causes the total guidance to be dominated by one of them. So, we align the norm of them using $\alpha$:
\begin{equation}\label{eq:coefficient for score alignment}
    \alpha = \frac{\| \mathbf{s}(\Tilde{G}^{(t)}, t) \|_2}
    { \| \nabla_{\Tilde{G}^{(t)}} \mathcal{L}(\Tilde{G}^{(t)}) \|_2 }.
\end{equation}
% Besides, the task-related objectives in \cref{eq:fine-tune loss} are proposed for graphs without noise. 
Because $\Tilde{G}^{(t)}$ is an intermediate state in the reverse process, the noise in it may fail the optimizations. So, we design a new sampling method named \textit{double-loop sampling} for accurate loss calculation. 
It has an inner-loop sampling using \cref{eq:reverse graph SDE} to sample $\hat{G}_{(t)}$, as the denoised version of $\Tilde{G}^{(t)}$ at the reverse time $t$. Then $\nabla_{\hat{G}} \mathcal{L}( \hat{G}_{(t)} )$ is calculated as an alternative for $ \nabla_{\Tilde{G}^{(t)}} \mathcal{L}(\Tilde{G}^{ (t)})$.
Finally, an outer-loop sampling takes one step to guide denoising using~\cref{eq:finetune guided reverse SDE}.

As shown in~\cref{fig:implementation}, DCT iteratively creates the augmented graphs $(G^\prime,y^\prime)$, updates the training dataset $\{(G_i, y_i)\}$, and trains the graph property predictor $f_\theta$. In each iteration, for task $k$,
% Each iteration for data augmentation, the graph property predictor selects
$n \ll N^{[k]}$ labeled graphs of the lowest property prediction loss are selected to create the augmented graphs.
% will be easiest predicted training graphs that have the lowest loss. Because
The predictor is better fitted to these graphs for more accurate sufficiency estimation of the augmentation. 

% Given the graph $G$ and the label $y$, we assume the augmented graph is $G^\prime$ and the mutual information between two variables is $\I(\cdot \ ; \cdot)$. The minimal and sufficient knowledge transfer from unlabeled data to specific tasks is achieved by producing minimal and sufficient augmentation. 
% \begin{definition}[Sufficiency for Data Augmentation]
%     An augmentation that produces $G^\prime$ is sufficient in preserving label if and only if $\I(G^\prime;y) = \I(G;y) $.
% \end{definition}

% \begin{definition}[Minimal Sufficient Data Augmentation]
%     The sufficient augmentation is minimal if and only if $\I(G^\prime; G) \leq \I(\bar{G}; G)$, $\forall \bar{G}$ is sufficient.
% \end{definition}

% In other words, the minimal sufficient augmentation encourages the transfer of relevant knowledge of the label $y$ and avoids redundant knowledge from the unlabeled graphs to the graph space of the labeled graph $G$. 

% to guide the reverse process for augmentation, 
% which is broadly verified in representation learning~\citep{tian2020makes, soatto2014visual}.

% The reverse-time SDE in~\cref{eq:reverse graph SDE} inputs noise and outputs graphs that follow the distribution of the unlabeled graphs. To adapt the reverse process for data augmentation, the \method inputs a labeled graph, perturb it with little noise, and outputs a new graph, instead of the original one. Specifically, given a graph-label pair $(G,y)$ from a specific task, we use a hyper-parameter $D \in [1, T]$ ($D \ll T$) to control the perturbation steps for the input graph $G$. So, the perturbed graph is $\Tilde{G}^{(D)}$. Without additional guidance for optimization, we could directly apply~\cref{eq:reverse graph SDE} to get the augmented example $G^\prime$ and may assume that the label of $G^\prime$ is $y$ with proper $D$.

% In the following subsections, we propose task-specific graph data augmentation and task-related optimization objectives in the \method to generate task-specific augmented graphs. An overview of them is in~\cref{fig:implementation}.

% To address the above issues data augmentation aims to create new graphs that share the same graph space. The unlabeled graphs are leveraged 

% \subsubsection{Task-specific Graph Data Augmentation}

% So, we propose a variant of the reverse process for augmentation purposes on graphs.

% \subsubsection{Task-related Optimization Objectives}

% To increase the diversity of augmented graphs, the \method learns the data distribution of unlabeled graphs with the diffusion model.
% So, it is the same as unconditional generative training. With the diffusion model, the denoising score function~\citep{jo2022score} is trained.
% can understand concepts such as the construction of molecules according to chemical rules

% Using the diffusion model for task-specific graph data augmentation with two ask-related optimization objectives. Given any labeled graph $G$ from a specific task as the input, we perturb the graph with $D$ steps and use task-related objectives $\I_1$ and $\I_2$ to optimize (guide the generation of) the augmented graph $G^\prime$ to be minimally similar to the input $G$ and sufficiently preserve the label of $G$.
% \begin{figure*}[htp!]
%     \centering
%     \includegraphics[width=0.75\linewidth]{figures/implementation.pdf}
%     \vspace{-0.2in}
%     \caption{\protect Diffusion model for generation (the above) and augmentation (the bottom).}
%     \label{fig:implementation}
%     \vspace{-0.2in}
% \end{figure*}

% We consider the problem of effectively utilizing knowledge from a large number of unlabeled graphs to improve the model prediction on downstream tasks that have a limited number of labeled examples. We introduce a data-centric framework to solve the problem without manually designing self-supervised tasks. To simplify notations, we remove the task superscript $[k]$ in the following sections.

% We hypothesize that the data augmentation and the task prediction in the \method mutually enhance each other when we end-to-end train the predictor and augment labeled data. Therefore, the \method iteratively trains the graph predictor and create augmented graphs. In each iteration, the \method first selects the Top-$n$ easiest predicted examples that the predictor has the lowest losses. Then, the \method creates new graphs for the selected examples. The training data is updated with augmented graphs and the prediction model continues training. 

% The task-related objectives optimize $G^\prime$ to be minimally similar to $G$ and sufficiently preserve the label of $G$ with the help of the task predictor. In this way, the training data is enriched with label-preserved and diverse augmented graphs. To integrate the task-related objectives with the score function, we propose the score alignment technique to align the norm of gradients from the task-related objectives and the score from the score function. We also propose double-loop sampling to avoid the noise in the reverse process of creating augmented examples. 

% We hypothesize that the data augmentation and the task prediction in the \method mutually enhance each other when we end-to-end train the predictor and augment labeled data. Therefore, the \method iteratively trains the graph predictor and create augmented graphs. In each iteration, the \method first selects the Top-$n$ easiest predicted examples that the predictor has the lowest losses. Then, the \method creates new graphs for the selected examples. The training data is updated with augmented graphs and the prediction model continues training. 

% We repeat the above steps until the convergence of $f_\theta(\cdot)$.

% To increase the diversity of the augmented examples, the \method utilizes the diffusion model on unlabeled graphs. z
% However, existing augmentation approaches~\citep{rong2019dropedge,han2022g} create new graph examples by either manual rules or learning methods on labeled data. The lack of leveraging a large number of unlabeled graphs results in a constraint on the diversity of augmented graphs, which would cause the over-fitting of a graph predictor.
% In this work, we achieve $\T_\phi(\cdot)$ using a diffusion-based graph generator because it is effective and efficient in modeling data distribution~\citep{dhariwal2021diffusion,song2020denoising} and fits the permutation-invariant nature of graphs~\citep{jo2022score}.

% \paragraph{Data-Centric Knowledge Transfer with Diffusion Model}

% The \method framework transfers knowledge from unlabeled graphs by data augmentation with the diffusion model. The augmentation function is initialized using unlabeled graphs and adapted in downstream tasks to optimize the augmented graphs. In this work, we achieve $\T_\phi(\cdot)$ using a diffusion-based graph generator and train the denoising score function in the diffusion model using unlabeled graphs to help model the data distribution of unlabeled graphs. In downstream tasks, we propose the \textit{diffusion-based augmentation} to augment new graph examples in a perturbing-denoising manner. The denoising process in a specific task is guided by the \textit{minimal sufficient principle for data augmentation}, using the graphs, labels, and the prediction model, as well as the score function. To integrate the guidance in the task with that of the score function trained on unlabeled graphs, we propose the \textit{score alignment} technique to align the norm of two guidance and the \textit{double-loop sampling} to avoid noise in the optimization of augmented examples. By training $f_\theta(\cdot)$ on the augmented graphs, knowledge from unlabeled graphs is transferred to the prediction model.

% \paragraph{Mutual Enhancement Framework}
% We hypothesize that $f_\theta(\cdot)$ and $\T_\phi(\cdot)$ mutually enhance each other when we end-to-end train the downstream prediction model and augment graphs. So, we augment graphs and train the prediction model in an iteration manner. Before augmentation, we select Top-$n$ examples that $f_\theta(\cdot)$ has the best predictions (lowest losses). Then we use $\T_\phi(\cdot)$ to augment new graphs guided by the novel objective. The training data is updated with new examples and the prediction model continues training with the updated data. We repeat the above steps until the convergence of $f_\theta(\cdot)$.

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.98\linewidth]{figures/compare_real_gen_runs.pdf}
%     \vspace{-0.1in}
%     \caption{Improvement percentage (AUC or MAE) using self-training with realistic or generated unlabeled graphs. Results from ten independent runs. Task details are in \cref{sec: add exp setups}.}
%     \label{fig:compare real gen five runs}
%     \vspace{-0.2in}
% \end{figure}

% After finishing the outer-loop sampling, we get $n$ new examples and update the training data. Then, we continue the training of $f_\theta (\cdot)$ until its convergence.
% the mutual information between the augmented graph $G^\prime$ and the label of the input graph $y$ could be estimated more accurate. A

% In existing works, the universality of data augmentation is either manually designed~\citep{rong2019dropedge, hu2019strategies} or learned from labeled data~\citep{liu2022graph,kong2022robust}. \tz{what is ``universality of data augmentation''? Also, seems only graph data augmentation works are cited here, you should either (1) cite broader or (2) change the narrative} However, the former is often argued cannot preserve the label of augmentation input~\citep{balestriero2022effects} and the latter learns to augment and predict at the same time, heavily relying on the labeled examples. In other words, the augmented examples from the learned $\T_\phi(\cdot)$ may bring limited extra knowledge and also suffer from the limitations of the labeled data such as the data insufficiency~\citep{balestriero2022effects,liu2022graph}

% $\T^{[k]}_\phi (\cdot)$ could be manually designed or learned from the task. Although the latter may preserve the label of the input graph, the augmented knowledge is limited by the small number of examples in the task and may cause over-fitting.
% [LESS MOTIVATION. M]

% The goal of the $\mathbf{s}(G^{(t)}, t)$ is to estimate the data distribution of unlabeled data.
% Training details of $\mathbf{s}(G, t)$ are in previous works~\citep{jo2022score,song2020score} and in our Appendix. 
% and it will not be tuned in downstream tasks. 

% We implement the diffusion model to initialize the augmentation function in our idea because it is effective, efficient, and stable in modeling data distribution~\citep{dhariwal2021diffusion,song2020denoising}. Also, it is shown that the diffusion model could achieve state-of-the-art and fits
% the permutation-invariant nature of graphs~\citep{jo2022score}.

% In reverse-time SDE, it needs to take a few thousand steps to sample good quality data from noises~\citep{song2020score,jo2022score}. Although recent works have reduced the sampling steps to a few hundred for images~\citep{song2020denoising}, the acceleration methods are still unclear for graphs. 

% We findx that real and generated unlabeled graphs impact the model performance in a similar way, \ie they are relatively positive to three tasks (hiv, bace, and sider) and negative to six tasks (bbbp, clintox, toxcast, oxygen, melting, and glass). 

% In other words, when we replace the realistic unlabeled data with generated unlabeled data and keep other settings the same, the prediction model should not be aware of the changes and performs similarly on the test data before and after replacement. 

% reveals that the \textit{negative transfer}~\citep{hu2019strategies,sun2019infograph} is popular when we transfer knowledge from unlabeled graphs to structurally different graphs, particularly when there is a clear gap between unlabeled and labeled data, \eg transferring knowledge from molecules to polymers. 

% Although the minimum sufficient principle is broadly verified in representation learning~\citep{tian2020makes, soatto2014visual}, it is less studied to guide augmentation. 

% In our augmentation, the graph $G$ carries the knowledge we want to preserve in the downstream task and the parameters $\theta$ carries the knowledge we want to transfer. To discover them in a unified way, we propose the \textit{minimum sufficient} principle for augmentation fine-tuning.

% We note that the original \textsc{InfoNCE} is a lower bound estimation of the mutual information $\I$. By leaving  $p(\T_\phi(G) | G)$ out of the denominator, the used variant $\I_\textbf{NCE}$ could be the upper bound ofeg the $\I$~\citep{poole2019variational}.

% optimize $\phi$ in the augmentation augmentation. Overall, the fine-tuning loss $\mathcal{L}_\textbf{aug}$ is:

% like the relationship between unlabeled data and prediction model in self-training~\citep{mclachlan1975iterative}

% Then we fine-tune $\T_\phi(\cdot)$ using these graphs with~\cref{eq:fine-tune loss} and augment for them after fine-tuning. 
% The training data is updated with new examples and the prediction model continues training with the updated data. We repeat the above steps until the convergence of $f_\theta(\cdot)$.

% To overcome the limitation of insufficient labels, self-supervised learning~\citep{hu2019strategies,oord2018representation} pre-train $f_\theta(\cdot)$ on unlabeled graphs. However, recent studies~\citep{trivedianalyzing,sun2022does} and our experiments (\cref{fig:compare real gen five runs} and \cref{tab:result of molecules}) show that it remains challenging to design appropriate self-supervised tasks on graphs for the transfer of scientific knowledge.

% Their empirical success relies on the robust and transferable model parameters learned from pre-training.

% Different from self-supervised learning, which heavily relies on hand-crafted tasks, our \method learns to transfer knowledge during fine-tuning for transferable data augmentation. During fine-tuning, task labels are available and we learn to generate new graphs that combine both advantages of labels and knowledge from unlabeled data. We first initialize $\T_\phi(\cdot)$ with a diffusion-based implementation~\citep{jo2022score} on unlabeled data. It learns the data distribution of unlabeled graphs to ``store'' knowledge from unlabeled data as much as possible. Then, we follow the minimal sufficient principle to fine-tune $\T_\phi(\cdot)$. By training $f_\theta(\cdot)$ on the augmented graphs from fine-tuned $\T_\phi(\cdot)$, the transferred knowledge to the $f_\theta(\cdot)$ is controlled by information bottleneck~\citep{tishby2000information}. 

% To measure whether the augmentation could preserve labels, we use the prediction model $f_\theta(\cdot)$ and select some examples that are easy to predict. Generally, $\T_\phi(\cdot)$ and $f_\theta(\cdot)$ are jointly learned in downstream tasks like self-training: the prediction model is initially trained on a few epochs to suggest easy-to-learn examples, the augmentation function is fine-tuned and used to augment these examples, and then the prediction model continues training.

% To overcome the limitation of insufficient labels, previous works~\citep{hu2019strategies,you2021graph} pre-trained $f_\theta(\cdot)$ with unlabeled graphs to get a latent space used for many downstream tasks~\citep{hu2019strategies, oord2018representation}. 
% This idea inspires us to propose the pre-training and fine-tuning strategy for augmentation learning. Specifically, we use a single pre-training step to initialize $\T_\phi(\cdot)$ and then fine-tune the augmentation function for different downstream tasks. The universality of the latent space in $f_\theta(\cdot)$ requires a careful design of the pre-training strategy and objective~\citep{hu2019strategies,you2021graph}. Different from it, the keypoint of the universality in $\T_\phi(\cdot)$ is fine-tuning.
% \tz{it seems to me that if this whole subsection is talking about general data augmentation}

% \subsection{Implementation with Diffusion-based Graph Generative Models}

% Rather than first fine-tuning the huge pre-trained parameters in $\mathbf{s}(G^{(t)}, t)$, and then sampling using them, we use the score alignment and double-loop sampling to fine-tune the generative model. At the same time, the desirable augmented graphs will be sampled with fine-tune guidance.

% $G^{(t)}_\text{clean}$
