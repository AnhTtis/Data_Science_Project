\section{Discussion and Limitations}

Although we can ablate concepts efficiently for a wide range of object instances, styles, and memorized images, our method is still limited in several ways. First, while our method overwrites a target concept, this does not guarantee that the target concept cannot be generated through a different, distant text prompt. We show an example in \reffig{limitation} (a), where after ablating {\menlo Van Gogh}, the model can still generate {\menlo starry night painting}. However, upon discovery, one can resolve this by explicitly ablating the target concept {\menlo starry night painting}. Secondly, when ablating a target concept, we still sometimes observe slight degradation in its surrounding concepts, as shown in \reffig{limitation} (c). 

\nupur{Our method does not prevent a downstream user with full access to model weights from re-introducing the ablated concept~\cite{ruiz2022dreambooth,kumari2022multi,gal2022image}. Even without access to the model weights, one may be able to iteratively optimize for a text prompt with a particular target concept. Though that may be much more difficult than optimizing the model weights, our work does not guarantee that this is impossible.}

Nevertheless, we believe every creator should have an ``opt-out'' capability. We take a small step towards this goal, creating a computational tool to remove copyrighted images and artworks from large-scale image generative models.
