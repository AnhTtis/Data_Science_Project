

\section{Experiments}\lblsec{expr}
In this section, we show the results of our method on ablating various instances, styles, and memorized images. All our experiments are based on the Stable Diffusion model~\cite{stablediffusionlink}. Please refer to the \refapp{implementation_details} for more training details. 




\subsection{Evaluation metrics and baselines}



\myparagraph{Baseline.}
We compare our method with a loss maximization baseline inspired by Tanno~\etal~\cite{tanno2022repairing}:
\begin{equation}
\begin{gathered}
    \arg \textnormal{min}_{\hat{\Phi}} \max(1- \mathcal{L}(\x^*,\c^*), 0) + \lambda||\hat{\Phi} - \Phi||_2 
\end{gathered}
\label{eqn:baseline_tanno}
\end{equation}
where $\x^*$ is the set of generated images with condition $\c^*$ and $\mathcal{L}$ is the diffusion training loss as defined in \refeq{loss_diffusion}. We compare our method with this baseline on ablating instances. 










\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/spell_mistake.pdf}
    \vspace{-18pt}
    \caption{\textbf{Robustness of the $\methodmodel$ variant to spelling mistakes in the text prompt.} Fine-tuning only the embedding makes it less robust to slight spelling mistakes. This makes it easy to circumvent the method and still be able to generate the target concept. Whereas fine-tuning cross-attention parameters is robust to those.}
    \label{fig:results_spell_mistake}
    \vspace{-10pt}
\end{figure}



\myparagraph{Evaluation metrics.} We use \emph{CLIP Score} and \emph{CLIP accuracy}~\cite{hessel2021clipscore} to evaluate whether the model can ablate the target concept. CLIP Score measures the similarity of the generated image with the target concept text, e.g., {\menlo Grumpy Cat} in CLIP feature space. Similarly, CLIP accuracy measures the accuracy of ablated vs. \anchor concept binary classification task for each generated image using cosine distance in CLIP feature space. For both metrics, lower values indicate more successful ablation. We further evaluate the performance on small spelling mistakes in the ablated text prompts. We also use the same metrics to evaluate the model on related \emph{surrounding concepts} (e.g., similar cat breeds for {\menlo Grumpy Cat}), which should be preserved. Similar to before, CLIP accuracy is measured between the surrounding concept and \anchor concept, and the higher, the better. Similarly, CLIP Score measures the similarity of the generated image with the surrounding concept text, and the higher, the better.



Furthermore, to test whether the fine-tuned model can retain existing concepts, we calculate \emph{KID}~\cite{binkowski2018demystifying} between the set of generated images from fine-tuned model and the pretrained model. Higher KID is better for the target concept, while lower KID is better for \anchor and surrounding concepts. We generate $200$ images each for ablated, \anchor, and surrounding concepts using $10$ prompts and $50$ steps of the DDPM sampler. The prompts are generated through ChatGPT for object instances and manually created for styles by captioning real images corresponding to each style. 

To measure the effectiveness of our method in ablating memorized images, following previous works~\cite{pizzi2022self,carlini2023extracting}, we use SSCD~\cite{pizzi2022self} model to measure the percentage of generated images having similarity with the memorized image greater than a threshold.



\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/loss_maximize_sample.pdf}
    \vspace{-18pt}
    \caption{\textbf{Qualitative comparison between baseline and ours.} Model fine-tuned by our method generates images that are relatively more similar to the ones generated by the pretrained model on the {\menlo BB8} instance, which should be preserved while ablating {\menlo R2D2}. Cross-Attention parameters are fine-tuned in both methods. }
    \label{fig:loss_maximize_sample}
    \vspace{-15pt}
\end{figure}




\begin{figure*}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/style_ablation.pdf}
    \vspace{-12pt}
    \caption{\textbf{Ablating styles with the $\methodmodel$ variant.} The ablated model generates similar content as the pretrained model but without the unique style. More samples for target and surrounding concepts are shown in the Appendix \reffig{vangogh_allimages}-\ref{fig:salvador_allimages}.
    }
    \label{fig:results_style}
    \vspace{-5pt}
\end{figure*}


\begin{figure*}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/memorization.pdf}
    \vspace{-18pt}
    \caption{\textbf{ Ablating memorized images with the $\methodmodel$ variant.} Text-to-image diffusion models often learn to generate exact or near-exact copies of real images. We fine-tune the model to map the generated image distribution for the given text prompt to images generated with its variations. This results in the fine-tuned model generating different variations instead of copying the real image. We show more samples in the Appendix \reffig{mem_orleans}-\ref{fig:mem_ann}.}
    \label{fig:results_memorize}
    \vspace{-15pt}
\end{figure*}



\subsection{Comparisons and main results}\lblsec{main_results}

\myparagraph{Instances.}
We show results on four concepts and replace them with \anchor concepts, namely, (1) Grumpy Cat $\rightarrow$ Cat, (2) Snoopy $\rightarrow$ Dog, (3) Nemo $\rightarrow$ Fish, and (4) R2D2 $\rightarrow$ Robot. \reffig{mse_kldiv_compare} compares our two proposed methods and the loss maximization baseline with \textit{Cross-Attention} fine-tuning. As the baseline method maximizes the norm between ground truth and predicted noise, it gradually generates noisy images when trained longer. This also leads to worse performance on surrounding concepts than our method, as shown by the quantitative metrics in \reffig{mse_kldiv_compare}. Qualitative samples on the target concept  {\menlo R2D2} and its surrounding concept {\menlo BB8} are also shown in \reffig{loss_maximize_sample}. Between our two methods, the $\methodmodel$ variant, i.e., minimizing the difference in prediction with the pretrained model's \anchor concept, leads to faster convergence and is better or on par with the $\methoddata$ variant. The qualitative comparison in \reffig{results_instance} also shows that, specifically on the {\menlo Nemo} instance. Thus, we use $\methodmodel$ variant for all later experiments. In \reffig{kldiv_compare}, we show the performance comparison when fine-tuning different subsets of the model weights. 

As shown in \reffig{results_instance}, %
the fine-tuned model successfully maps the target concept to the \anchor concept. Fine-tuning only the text embedding performs similarly or better than  fine-tuning cross-attention layers. However, it is less robust to small spelling errors that still generate the same instance in the pretrained model as shown in \reffig{kldiv_compare} (third column) and \reffig{results_spell_mistake}. We show more results of ablated target concept and its surrounding concepts in \refapp{samples}, \reffig{grumpy_allimages}-\ref{fig:snoopy_allimages}. %



\myparagraph{Style.}
For ablating styles, we consider four artists: (1) Van Gogh, (2) Salvador Dali, (3) Claude Monet, and (4) Greg Rutkowski, with the \anchor concept as generic painting styles. Figures \ref{fig:kldiv_compare} and \ref{fig:results_style} show our method's quantitative and qualitative performance when different subsets of parameters are fine-tuned. We successfully ablate specific styles while minimally affecting related surrounding styles.





\myparagraph{Memorized images.} We select eight image memorization examples from the recent works~\cite{somepalli2022diffusion,carlini2023extracting}, four of which are shown in \reffig{results_memorize}. %
It also shows the sample generations before and after fine-tuning. The fine-tuned model generates various outputs given the same text prompt instead of the memorized sample. Among different parameter settings, we find finetuning \textit{Full Weights} gives the best results. We show the percentage of samples with $\geq 0.5$ similarity with the memorized image in \reftbl{mem_percentage}. We show more sample generations and the initial set of anchor prompts for each case in \refapp{samples} and \ref{sec:implementation_details}. 


\begin{table}[!t]
\centering
\setlength{\tabcolsep}{5pt}
\resizebox{\linewidth}{!}{
\begin{tabular}{p{6cm} c  c}
\toprule
\shortstack[c]{\textbf{Target Prompt} } 
& \shortstack[c]{\textbf{Pretrained Model } }
& \shortstack[c]{\textbf{Ours} (\textit{Full Weights}) }\\
\midrule
 New Orleans House Galaxy Case & $65.5\%$ & $0.0\%$ \\
Portrait of Tiger in black and white by Lukas Holas & $50.0\%$ &  $0.0\%$ \\
VAN GOGH CAFE TERASSE copy.jpg & $56.5\%$ &  $1.5\%$ \\
Captain Marvel Exclusive Ccxp Poster Released Online By Marvel &  $95.0\%$ &  $0.5\%$ \\
Sony Boss Confirms Bloodborne Expansion is Coming & $83.5\%$  & $0.5\%$ \\
Ann Graham Lotz & $26.5\%$  & $0.0\%$ \\
$<i>$The Long Dark$</i>$ Gets First Trailer, Steam Early Access & $100.0\%$  & $0.0\%$ \\
A painting with letter M written on it Canvas Wall Art Print & $4.0\%$  & $0.0\%$ \\
\textbf{Total} & $60.1\%$ & $0.3\%$\\
\bottomrule
\vspace{-10pt}
\end{tabular}
}
\vspace{-12pt}
\caption{\textbf{Samples with $\geq 0.5$ similarity with memorized image.} We show here the percentage of $200$ samples generated using target prompt with $\geq 0.5$ similarity with the memorized image. }

\label{tbl:mem_percentage}
\vspace{-6pt}
\end{table}




\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/allinonemodel.pdf}
    \vspace{-20pt}
    \caption{{\textbf{Ablating multiple instances (left) and style (right).} \textit{Top:} quantitative results show the drop in the CLIP Accuracy of the target concept, which has been ablated, whereas the accuracy for surrounding concepts remains the same. \textit{Bottom:} one sample image corresponding to each ablated target concept. 
    }}
    \lblfig{allinonemodel}
    \vspace{-7pt}
\end{figure}

\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/category_samples.pdf}
    \vspace{-20pt}
    \caption{{\textbf{The choice of \anchor concepts.} Our method is robust to the choice of \anchor concepts. With both {\menlo British shorthair cat} and {\menlo Felidae} as \anchor concepts, our method can ablate the target {\menlo Grumpy Cat} concept.
    }}
    \lblfig{category_samples}
    \vspace{-20pt}
\end{figure}





 








\subsection{Additional Analysis}
\lblsec{other_experiments}

\vspace{-6pt}
\myparagraph{Single model with multiple concepts ablated.}
Our method can also remove multiple concepts from the model by training on the union of datasets for longer training steps. We show the results of one model with all instances and one model with all styles ablated in \reffig{allinonemodel}. We use the model-based variant of our method and cross-attention fine-tuning. More samples are shown in Appendix, \reffig{allinonemodel_instance_sample} and \ref{fig:allinonemodel_style_sample}. The drop in accuracy for the ablated concepts is similar to \reffig{results_instance} while maintaining the accuracy on surrounding concepts. 

\myparagraph{The role of \anchor category.}
In all the above experiments, we assume an \anchor category $\c^*$ is given to overwrite the target concept. Here, we investigate the role of choosing different \anchor categories for ablating {\menlo Grumpy Cat} and show results with the \anchor concept as {\menlo British Shorthair Cat} and {\menlo Felidae} in \reffig{category_samples}. Both \anchor concepts work well. 


\myparagraph{Reverse KL divergence.} \nupur{In our $\methodmodel$ concept ablation, we optimize the KL divergence between the anchor concept and target concept distribution. Here, we compare it with optimizing the approximation to reverse KL divergence, i.e., $\mathbb{E}_{\epsilon,\x^*,\c^*, \c, t } [w_t||\hat{\Phi} (\x_t^*, \c, t).\text{sg()} - \hat{\Phi} (\x_t^*, \c^*, t) ||]$. Thus the expectation of loss is over target concept images. \reffig{gentarget} shows the quantitative comparison on ablating instances and style concepts. As we can see, it performs marginally better on ablating style concepts but worse on instances. In \reffig{gentarget_sample}, we show sample generations for the case where it outperforms the forward KL divergence based objective qualitatively on ablating {\menlo Van Gogh}.
}


\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/reverse_kl.pdf}
    \vspace{-20pt}
    \caption{{\textbf{Reverse KL divergence objective.} \nupur{We show the results of optimizing the loss over target concept images for ablating instances (top) and style (bottom). Compared to using anchor concept images, this performs slightly worse on instances with lower CLIP Score on surrounding concepts while having similar or higher CLIP Score on the target concept. It performs marginally better on ablating styles.}
    }}
    \lblfig{gentarget}
    \vspace{-10pt}
\end{figure}

\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/gentarget_sample.pdf}
    \vspace{-22pt}
    \caption{{ \textbf{Qualitative samples with reverse KL divergence objective.} \nupur{It performs better on certain styles and can successfully ablate famous paintings as well which is not achievable with forward KL divergence based objective and requires additional steps as shown in \reffig{limitation}.}
    } 
    }
    \lblfig{gentarget_sample}
    \vspace{-20pt}
\end{figure}







\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/limitation.pdf}
    \vspace{-25pt}
    \caption{{ \textbf{Limitations.} \textit{Top:} (a) our method fails to remove certain paintings generated with the painting's titles. %
    (b) We can further ablate these concepts. \textit{Bottom:} \nupur{Though our method is better than baseline in preserving surrounding concepts as shown in \reffig{loss_maximize_sample}, the generated samples still sometimes show degradation for surrounding concepts, e.g., {\menlo Monet} (c) when ablating {\menlo Van Gogh} as compared to the pretrained model (d). }
    } 
    }
    \lblfig{limitation}
    \vspace{-15pt}
\end{figure}
























