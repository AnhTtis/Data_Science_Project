\renewcommand{\thefootnote}{\arabic{footnote}}

\clearpage
\noindent{\Large\bf Appendix}
\vspace{5pt}


\myparagraph{Overview.} 
In \refsec{loss_objective}, we show a detailed derivation of the $\methodmodel$ concept ablation algorithm. In \refsec{application}, we present \emph{compositional} concept ablation, where we ablate the composition of two concepts while retaining individual concepts. We then show more analysis on varying other parameters in our method in \refsec{analysis_supp}. Finally, we include more samples for all our models in \refsec{samples} and discuss implementation details in \refsec{implementation_details}. All experiments are with $\methodmodel$ variant of our method with cross-attention fine-tuning unless mentioned otherwise.





\section{Model-based concept ablation objective}\lblsec{loss_objective}
We show here that minimizing the KL divergence objective between the joint distribution of noisy latent variables conditioned on anchor and target concept, i.e., \refeq{loss} in the main paper, can be reduced to the $\ell_2$ difference between the predicted noise vectors. 

\vspace{-10pt}
\begin{equation}
    \begin{aligned}
      & \mathcal{D_{KL}}(p_{\Phi}(\x_{(0 ...T)}|\c) || p_{\hat{\Phi}}(\x_{(0 ...T)} | \c^*)) \\ 
      & =   \mathbb{E}_{p_{\Phi}(\x_0 ... \x_T)}\log \frac{ \prod_{t=1}^{T}p_{\Phi}(\x_{t-1}|\x_t,\c)p_{\Phi}(\x_T) }{\prod_{t=1}^{T}p_{\hat{\Phi}}(\x_{t-1}|\x_t,\c^*)p_{\hat{\Phi}}(\x_T)} \\
      &  = \sum_{\hat{t}=1}^T  \mathbb{E}_{p_{\Phi}(\x_0 ... \x_T)}\log \frac{ p_{\Phi}(\x_{\hat{t}-1}|\x_{\hat{t}},\c) }{p_{\hat{\Phi}}(\x_{\hat{t}-1}|\x_{\hat{t}},\c^*)}
\end{aligned}
\end{equation}

We expand the term corresponding to a particular time step $\hat{t}$, i.e.,
\begin{equation*}
    \begin{aligned}
    & \mathbb{E}_{p_{\Phi}(\x_0 ... \x_T)}\log \frac{ p_{\Phi}(\x_{\hat{t}-1}|\x_{\hat{t}},\c) }{p_{\hat{\Phi}}(\x_{\hat{t}-1}|\x_{\hat{t}},\c^*)}\\
    & = \mathop{\int}_{\x_{(0 ...T)}}\hspace{-0.2cm}\prod_{t=1}^{T}p_{\Phi}(\x_{t-1}|\x_t,\c)p(\x_T) \log \frac{ p_{\Phi}(\x_{\hat{t}-1}|\x_{\hat{t}},\c)}{p_{\hat{\Phi}}(\x_{\hat{t}-1}|\x_{\hat{t}},\c^*)} d\x_{(0...T)} \\
    & = \mathop{\int}_{\x_{(\hat{t} ...T)}} p_{\Phi}(\x_{(\hat{t} ...T)}|\c) \Biggr [ \mathop{\int}_{\x_{(0 ... {\hat{t}-1}})} \prod_{t=1}^{\hat{t}}p_{\Phi}(\x_{t-1}|\x_t,\c) \\
    & \hspace{2.5cm}\log \frac{ p_{\Phi}(\x_{\hat{t}-1}|\x_{\hat{t}},\c)}{p_{\hat{\Phi}}(\x_{\hat{t}-1}|\x_{\hat{t}},\c^*)} d\x_{(\hat{t}-1...0)} \Biggl ] d\x_{(\hat{t}...T)}\\
     & = \mathop{\int}_{\x_{\hat{t}}}p_{\Phi}(\x_{\hat{t}}|\c) 
     \Biggr [ \mathop{\int}_{\x_{(0 ... {\hat{t}-1}})} (\prod_{t=1}^{\hat{t}-1}p_{\Phi}(\x_{t-1}|\x_t,\c) )p_{\Phi}(\x_{\hat{t}-1}|\x_{\hat{t}}, \c )  \\ 
     & \hspace{3cm} \log \frac{ p_{\Phi}(\x_{\hat{t}-1}|\x_{\hat{t}},\c)}{p_{\hat{\Phi}}(\x_{\hat{t}-1}|\x_{\hat{t}},\c^*)} d\x_{(\hat{t}-1...0)} \Biggl ] d\x_{\hat{t}} 
\end{aligned}
\end{equation*}
\begin{equation*}
    \begin{aligned}
    & = \mathop{\int}_{\x_{\hat{t}}}p_{\Phi}(\x_{\hat{t}}|\c) 
     \Biggr [ \mathop{\int}_{\x_{\hat{t}-1}} p_{\Phi}(\x_{\hat{t}-1}|\x_{\hat{t}}, \c )   
     \log \frac{ p_{\Phi}(\x_{\hat{t}-1}|\x_{\hat{t}},\c)}{p_{\hat{\Phi}}(\x_{\hat{t}-1}|\x_{\hat{t}},\c^*)} \\
     & \hspace{1.5cm} \Big [ \mathop{\int}_{\x_{(0 ... {\hat{t}-2}})}\prod_{t=1}^{\hat{t}-1}p_{\Phi}(\x_{t-1}|\x_t,\c) d\x_{(\hat{t}-2...0)}  \Big ] d\x_{\hat{t}-1} \Biggl ] d\x_{\hat{t}} 
\end{aligned}
\end{equation*}
The integral over $d\x_{(\hat{t}-2...0)}$ will be $1$ since it is an integration of the probability distribution over the range it is defined. Thus the previous term can be re-written as,
\begin{equation*}
\begin{aligned}
     & \mathop{\mathbb{E}}_{\x_{\hat{t}} \sim p_{\Phi}(\x_{\hat{t}}|\c) } 
     \Biggr [ \mathop{\int}_{\x_{\hat{t}-1}} p_{\Phi}(\x_{\hat{t}-1}|\x_{\hat{t}}, \c )   
     \log \frac{ p_{\Phi}(\x_{\hat{t}-1}|\x_{\hat{t}},\c)}{p_{\hat{\Phi}}(\x_{\hat{t}-1}|\x_{\hat{t}},\c^*)} d\x_{\hat{t}-1}\Biggl ]  \\
    & = \mathop{\mathbb{E}}_{\x_{\hat{t}} \sim p_{\Phi}(\x_{\hat{t}}|\c) } 
     \Biggr [ \mathcal{D_{KL}}( p_{\Phi}(\x_{\hat{t}-1}|\x_{\hat{t}}, \c )   
     || p_{\hat{\Phi}}(\x_{\hat{t}-1}|\x_{\hat{t}},\c^*) )\Biggl ]  \\
     & = \mathop{\mathbb{E}}_{\x_{\hat{t}} \sim p_{\Phi}(\x_{\hat{t}}|\c) } 
     \Big [ \eta (\Phi(\x_{\hat{t}}, \c, t) - \hat{\Phi}(\x_{\hat{t}}, \c^*, t))^2 \Big ]  \\
    \end{aligned}
\end{equation*}

In the case of the diffusion model, each conditional distribution, $p_{\Phi}(\x_{\hat{t}-1}|\x_{\hat{t}},\c)$ and $p_{\hat{\Phi}}(\x_{\hat{t}-1}|\x_{\hat{t}},\c^*)$, is a normal distribution with fixed variance and mean as a linear combination of $\x_t$ and the predicted noise. Above we use this fact and that KL divergence between two normal distributions simplifies to the squared difference between the mean. We ignore the variance terms in the KL divergence as it is not learned. 





\begin{figure*}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/compose_removal.pdf}
    \vspace{-15pt}
    \caption{{ \textbf{Ablating composition of concepts.} Our method can remove the composition of ``kids with guns'' while preserving individual category kids and guns. 
    } 
    }
    \lblfig{compose_removal}
    \vspace{-15pt}
\end{figure*}

\section{Compositional Concept Ablation}\lblsec{application}
In this section, we show that our method can be used to ablate the composition of two concepts while still preserving the meaning of each concept. For example, we show results with ablating {\menlo kids with guns}. The training dataset $(\x, \c, \c^*)$ now consists of images generated using prompts with {\menlo kids}, i.e., anchor concept prompts and target concept prompt of {\menlo kids with guns}. In this case, we add a standard diffusion regularization loss on images corresponding to {\menlo kids} and {\menlo guns} individually. 

\myparagraph{Results.} \reffig{compose_removal} shows sample generations for both ours and pretrained model given the prompts for target concept and anchor concepts. As we can see, our method successfully ablated the {\menlo kids with guns} concept and only generates {\menlo kid} images given that prompt. For the anchor concept, {\menlo gun} and {\menlo kids}, sample images are similar to the one generated by the pretrained model. The CLIP Score between generated images from the fine-tuned model with {\menlo kids with guns} prompts and CLIP text feature {\menlo kids} is $0.62$ which is similar to the baseline score of $0.63$. For {\menlo guns}, it is $0.52$, which is significantly lower than the baseline model's score of $0.60$. Thus the {\menlo kids with guns} target concept has been successfully ablated in the fine-tuned model. 














\section{Additional analysis}\lblsec{analysis_supp}








\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/numimages.pdf}
    \vspace{-20pt}
    \caption{{\textbf{Number of training images.} We analyze the effect of varying numbers of training images when ablating {\menlo Grumpy cat}. As we can see, training with $200$ images results in a similar performance on target concept by convergence (100 training steps) but is marginally worse on surrounding concepts. 
    }}
    \lblfig{num_images}
\end{figure}






\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/realtarget_sample.pdf}
    \vspace{-18pt}
    \caption{{ \textbf{Qualitative samples on using real target concept images in training.} Our method can successfully ablate target concepts when given target concept images and their corresponding captions. But this requires manually labeling the images with correct prompts to get $\c^*$ and modifying it to get the corresponding anchor prompt $\c$. Thus, we do not use this as our standard setup. 
    } 
    }
    \lblfig{realtarget}
    \vspace{-7pt}
\end{figure}






\myparagraph{Number of training images.} In all the experiments, we typically generate $1000$ images as the training data. \reffig{num_images} shows the comparison of training with $200$ and $1000$ images. We observe that training on just $200$ images performs only slightly worse on surrounding concepts. 


\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/unique_prompt.pdf}
    \vspace{-20pt}
    \caption{{\textbf{Number of unique prompts.} We compare using only $50$ and $10$ prompts for generating the $1000$ training images with our standard setting of $200$ prompts on ablating {\menlo Grumpy Cat}. Using fewer prompts leads to slower convergence. 
    }}
    \lblfig{unique_quant}
    \vspace{-10pt}
\end{figure}

\myparagraph{Number of unique prompts} 
Here, we analyze the effect of the number of unique prompts used in training. We vary the number of prompts to $10$ and $50$ and generate $1000$ training images using the prompts. We show its results on ablating {\menlo Grumpy Cat} in \reffig{unique_quant}. As we can see, convergence is faster when using more variations in the prompts. 


\myparagraph{Real target concept images with reverse KL divergence.}
To reiterate, our $\methodmodel$ variant loss is $\mathbb{E}_{\epsilon,\x,\c^*, \c, t } [w_t||\hat{\Phi} (\x_t, \c, t).\text{sg()} - \hat{\Phi} (\x_t, \c^*, t) ||]$, where $\x$ is an image corresponding to the anchor concept prompt $\c$ (e.g. {\menlo photo of a cat} when $\c^*$ is {\menlo photo of a grumpy cat}). Thus the training objective minimizes the difference in prediction between anchor prompts, and target prompts over all possible noisy anchor concept images. \nupur{We discussed in \refsec{other_experiments} our approximation to reverse KL divergence objective, which optimizes the loss over target concept images, i.e., $\mathbb{E}_{\epsilon,\x^*,\c^*, \c, t } [w_t||\hat{\Phi} (\x_t^*, \c, t).\text{sg()} - \hat{\Phi} (\x_t^*, \c^*, t) ||]$.}
In the experiment, target concept images $\x^*$ are generated by the pretrained model. But it is also possible to use real target concept images with the above objective. We perform this experiment for ablating {\menlo Van Gogh} and {\menlo Grumpy Cat} using ten real images of each target concept and show its results in \reffig{realtarget}. It leads to slower convergence as in the case of {\menlo Grumpy Cat} but otherwise performs similarly. 


\myparagraph{Comparison between the training objectives when fine-tuning different parameter subset}
In the main paper, we compared our concept ablation methods with the baseline method of maximizing the loss when fine-tuning \textit{Cross-Attention} parameters~\cite{kumari2022multi}. Here, we show the comparison when fine-tuning the \textit{Embedding}~\cite{gal2022image} and \textit{Full Weights}~\cite{ruiz2022dreambooth} of the U-Net diffusion model. \reffig{dreambooth_loss_objective} and \ref{fig:embedding_loss_objective} shows the results. As we can see, in both these cases as well, our $\methodmodel$ variant performs better or on par with other methods. 

\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/dreambooth_loss_objective.pdf}
    \vspace{-20pt}
    \caption{{\textbf{Comparison of different loss objective when fine-tuning \textit{Full Weights}.} The $\methodmodel$ variant performs better than the baseline and $\methoddata$ variant in this case as well, with faster convergence and maintaining the average CLIP Score and CLIP Accuracy on surrounding concepts.  
    }}
    \lblfig{dreambooth_loss_objective}
    \vspace{-10pt}
\end{figure}

\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/embedding_loss_objective.pdf}
    \vspace{-20pt}
    \caption{{\textbf{Comparison of different loss objectives when fine-tuning \textit{Embedding}.} In this case both $\methodmodel$ and $\methoddata$ variant peform similarly and better than the baseline. But as discussed in the main paper, fine-tuning embedding is not robust to small spelling mistakes and thus can still be used to generate the target concept.  
    }}
    \lblfig{embedding_loss_objective}
    \vspace{-15pt}
\end{figure}


\section{More qualitative samples}\lblsec{samples}
We show more qualitative samples of ablating memorized images, styles, and instances and their surrounding concepts. \reffig{mem_orleans}-\ref{fig:mem_vangogh} shows the samples generated by the pretrained model and fine-tuned models with memorized image ablated. We can see that compared to the pretrained model, our models generate significantly varying images given the target prompt. \reffig{allinonemodel_instance_sample} and \ref{fig:allinonemodel_style_sample} show the results of ablating multiple styles and instances, respectively. In \reffig{vangogh_allimages}-\ref{fig:salvador_allimages}, we show a qualitative comparison of style ablated models with the pretrained model on the target concept and surrounding concept images. Finally, \reffig{grumpy_allimages}-\ref{fig:snoopy_allimages} shows the qualitative comparison of instance ablated models with the pretrained model on the target concept and surrounding concept images. 



\section{Implementation details}\lblsec{implementation_details}
We describe additional details for our method, baselines, and evaluation setup. Our code is built on top of Custom Diffusion repo~\footnote{https://github.com/adobe-research/custom-diffusion}. 

\myparagraph{Cross-Attention.} We train with a batch size of $8$ and learning rate $2\times 10^{-6}$ (scaled by the batch size). All qualitative samples are shown with $100$ training steps for our $\methodmodel$ variant, $200$ steps for the $\methoddata$ variant, and $50$ steps for the loss maximation baseline. 


\myparagraph{Embedding.} We train with a batch size of $8$ and learning rate $1\times 10^{-5}$ (scaled by the batch size). All qualitative samples are shown with $200$ training steps. 

\myparagraph{Full-weights.}
When fine-tuning all weights of the U-Net, training is done on batch-size $4$ instead of $8$ (because of increased memory requirement) with a learning rate of $5\times 10^{-7}$ (without any scaling with the batch size). All qualitative samples are shown with $200$ training steps for ablating style and instance concepts. In the case of ablating memorized images, we used $1\times 10^{-6}$ learning rate and $800$ training steps except for {\menlo Anne Graham Lotz} case for which we used the above default values. 

\myparagraph{Other details.} We add regularization loss on the anchor concept data, as explained in Section 3.2 in the main paper, with $\lambda=1$ in the case of ablating {\menlo Grumpy Cat} and memorized images. To obtain training images, we sample using the DDPM sampler with $200$ steps. When training the loss maximization baseline, the regularization on weights is added with a factor of $10$ (Eq.~\ref{eqn:baseline_tanno}, main paper). Similar to Custom-Diffusion~\cite{kumari2022multi}, our implementation detaches the first token of the text transformer output before input to the U-Net. We also use image augmentation similar to Custom-Diffusion~\cite{kumari2022multi} when ablating object instances. For different parameter subset fine-tuning, we select the learning rate which works the best. In the case of the $\methoddata$ variant of our method, we also tried increasing the learning rate for faster convergence, but it led to sub-optimal results with artifacts in generated images. All our experiments are done on 2 A6000 GPUs with 3 minutes per $100$ training step. For the CLIP Score metric, the standard error is less than $5 \times 10^{-3}$ in all cases. 

\myparagraph{Training and test set prompts.}
We used chatGPT to create training and test prompts for all object instances. The instruction to chatGPT~\cite{chatgpt} was: {\menlo provide 210 captions for images containing <anchor-concept>. The caption should also contain the word ``<anchor-concept>''.} Out of this first 200 captions were used to generate training images, and the remaining ten were used for evaluation purposes. Regarding style concepts, as mentioned in the main paper, we used clip-retrieval to collect $210$ captions. Out of this, $200$ prompts are used for training and $10$ for evaluating the anchor concept {\menlo painting}. For target and surrounding style concepts, we used image captioning (along with manual supervision) on real images corresponding to each style to create ten prompts for each style concept. All evaluation prompts are provided in \reftbl{prompts_style_eval} and \ref{tbl:prompts_instance_eval}. We also show the surrounding concept for each target concept in \reftbl{surrounding_concept}. For calculating CLIP Score and Accuracy metric when ablating style concepts, we use the text prompt as: {\menlo <target-concept> style}. 

For the eight memorization use cases, we again used chatGPT to create variations of the target concept prompt $\c$ using the instruction: {\menlo provide five captions for an image depicting <image description>}. For memorization, we observe that paraphrased text prompts also generate the memorized images with high probability. Therefore, we keep generating variations of the target concept prompt until we have five suggested prompts that generate copied images with less than $30\%$ probability. We manually inspect the suggested paraphrases to ensure they are coherent with the image. We show the paraphrases used for each case in \reftbl{prompts_mem}. 







\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/allinonemodel_instance_sample.pdf}
    \vspace{-10pt}
    \caption{{ \textbf{Ablating multiple instances} 
    } Our method can be used to ablate multiple concepts. Here, we show the sample generations from a single model from which all four instances (top row) have been ablated. The bottom row shows sample images for surrounding concepts.
    }
    \lblfig{allinonemodel_instance_sample}
    \vspace{-10pt}
\end{figure*}

\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/allinonemodel_style_sample.pdf}
    \vspace{-10pt}
    \caption{{ \textbf{Ablating multiple styles.} We show a qualitative comparison between the pretrained model and fine-tuned model with all four ablated styles (top row) and their surrounding concepts (bottom row). The fine-tuned model successfully ablated multiple target concepts while generating images similar to the ones generated by the pretrained model on other surrounding style concepts.  
    }}
    \lblfig{allinonemodel_style_sample}
    \vspace{-15pt}
\end{figure*}

\begin{figure*}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/memorization_orleans.pdf}
    \includegraphics[width=\linewidth]{figures/memorization_tigers.pdf}
    \vspace{-15pt}
    \caption{{ \textbf{Comparison on ablating memorized images.} \textit{Top:} {\menlo New Orleans House Galaxy Case.} \textit{Bottom:} {\menlo Portrait of Tiger in black and white by Lukas Holas.}
    } 
    }
    \lblfig{mem_orleans}
    \vspace{-10pt}
\end{figure*}


\begin{figure*}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/memorization_captain.pdf}
    \includegraphics[width=\linewidth]{figures/memorization_bloodborne.pdf}
    \vspace{-15pt}
    \caption{{ \textbf{Comparison on ablating memorized images.} \textit{Top:} {\menlo Captain Marvel Exclusive Ccxp Poster Released Online By Marvel.} \textit{Bottom:} {\menlo Sony Boss Confirms Bloodborne Expansion is Coming.}
    } 
    }
    \lblfig{mem_bloodborne}
\end{figure*}

\begin{figure*}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/memorization_vangoghcafe.pdf}
    \includegraphics[width=\linewidth]{figures/memorization_anne.pdf}
    \vspace{-15pt}
   \caption{{ \textbf{Comparison on ablating memorized images.} \textit{Top:} {\menlo VAN GOGH CAFE TERASSE copy.} \textit{Bottom:} {\menlo Ann Graham Lotz.}
    } 
    }
    \lblfig{mem_vangogh}
\end{figure*}

\begin{figure*}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/memorization_longdark.pdf}
    \includegraphics[width=\linewidth]{figures/memorization_letterm.pdf}
    \vspace{-15pt}
   \caption{{ \textbf{Comparison on ablating memorized images.} \textit{Top:} {\menlo $<i>$The Long Dark$</i>$ Gets First Trailer, Steam Early Access.} \textit{Bottom:} {\menlo A painting with letter M written on it Canvas Wall Art Print.}
    } 
    }
    \lblfig{mem_ann}
\end{figure*}


\section{Societal Impacts}\lblsec{society}
We present a fast and efficient method for ablating concepts from large-scale pretrained text-to-image diffusion models. Ablating concepts enables the removal of styles learned by the model without the artist's approval or removing personal and copyrighted images. Though this has many benefits, it can also be used adversely by removing desired concepts or changing the behavior of the model from expected, e.g., ablating {\menlo Grumpy Cat} concept and generating {\menlo Garfield} instead.  

\section{Change log}
\myparagraph{v1:} Original draft.

\myparagraph{v2:} Updated \reffig{method} and fixed a minor bug in the CLIP Score and Accuracy metric calculation. 

\begin{figure*}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/vangogh_allimages.pdf}
    \vspace{-10pt}
    \caption{{ \textbf{Target concept, surrounding concept, and anchor concept images when ablating Van Gogh style.} \textit{Top row}: sample comparison on the Van Gogh style generated images. \textit{Other rows:} surrounding and anchor concept images which should be similar to the ones generated by the pretrained model. Please zoom in for a more detailed comparison. Each sample shows the generated image and two small crops from the image.
    } 
    }
    \lblfig{vangogh_allimages}
    \vspace{-15pt}
\end{figure*}



\begin{figure*}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/monet_allimages.pdf}
    \vspace{-10pt}
    \caption{{ \textbf{Target concept, surrounding concept, and anchor concept images when ablating Monet style.} \textit{Top row}: sample comparison on the Monet style generated images. \textit{Other rows:} surrounding and anchor concept images which should be similar to the ones generated by the pretrained model. Please zoom in for a more detailed comparison. Each sample shows the generated image and two small crops from the image.
    } 
    }
    \lblfig{monet_allimages}
    \vspace{-15pt}
\end{figure*}


\begin{figure*}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/greg_allimages.pdf}
    \vspace{-10pt}
    \caption{{ \textbf{Target concept, surrounding concept, and anchor concept images when ablating Greg Rutkowski style.} \textit{Top row}: sample comparison on the Greg Rutkowski style generated images. \textit{Other rows:} surrounding and anchor concept images which should be similar to the ones generated by the pretrained model. Please zoom in for a more detailed comparison. Each sample shows the generated image and two small crops from the image.
    } 
    }
    \lblfig{greg_allimages}
    \vspace{-15pt}
\end{figure*}


\begin{figure*}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/salvador_allimages.pdf}
    \vspace{-10pt}
    \caption{{ \textbf{Target concept, surrounding concept, and anchor concept images when ablating Salvador Dali style.} \textit{Top row}: sample comparison on the Salvador Dali style generated images. \textit{Other rows:} surrounding and anchor concept images which should be similar to the ones generated by the pretrained model. Please zoom in for a more detailed comparison. Each sample shows the generated image and two small crops from the image.
    } 
    }
    \lblfig{salvador_allimages}
    \vspace{-15pt}
\end{figure*}


\begin{figure*}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/grumpy_allimages.pdf}
    \vspace{-10pt}
    \caption{{ \textbf{Target concept, surrounding concept, and anchor concept images when ablating {\menlo Grumpy Cat}.} \textit{Top row}: sample comparison on the {\menlo Grumpy Cat} generated images. \textit{Other rows:} surrounding and anchor concept images which should be similar to the ones generated by the pretrained model. Please zoom in for a more detailed comparison.
    } 
    }
    \lblfig{grumpy_allimages}
    \vspace{-15pt}
\end{figure*}


\begin{figure*}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/r2d2_allimages.pdf}
    \vspace{-10pt}
    \caption{{ \textbf{Target concept, surrounding concept, and anchor concept images when ablating R2D2.} \textit{Top row}: sample comparison on the R2D2 generated images. \textit{Other rows:} surrounding and anchor concept images which should be similar to the ones generated by the pretrained model. Please zoom in for a more detailed comparison.
    } 
    }
    \lblfig{r2d2_allimages}
    \vspace{-15pt}
\end{figure*}



\begin{figure*}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/nemo_allimages.pdf}
    \vspace{-10pt}
    \caption{{ \textbf{Target concept, surrounding concept, and anchor concept images when ablating Nemo.} \textit{Top row}: sample comparison on the Nemo generated images. \textit{Other rows:} surrounding and anchor concept images which should be similar to the ones generated by the pretrained model. Please zoom in for a more detailed comparison.
    } 
    }
    \lblfig{nemo_allimages}
    \vspace{-15pt}
\end{figure*}



\begin{figure*}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/snoopy_allimages.pdf}
    \vspace{-10pt}
    \caption{{ \textbf{Target concept, surrounding concept, and anchor concept images when ablating Snoopy.} \textit{Top row}: sample comparison on the Snoopy generated images. \textit{Other rows:} surrounding and anchor concept images which should be similar to the ones generated by the pretrained model. Please zoom in for a more detailed comparison.
    } 
    }
    \lblfig{snoopy_allimages}
    \vspace{-15pt}
\end{figure*}
\begin{table}[!t]
\centering
\setlength{\tabcolsep}{5pt}
\resizebox{\linewidth}{!}{
\begin{tabular}{l p{10cm}}
\toprule
\shortstack[c]{\textbf{Target Concept} } 
& \shortstack[c]{\textbf{Evaluation Prompt} } \\
\midrule
 \multirow{10}{*}{\shortstack[c]{Van Gogh }} &  Painting of olive trees in the style of Van Gogh \\
 & Painting of a tree in the style of Van Gogh\\
 & The starry night painting in the style of Van Gogh\\
 & Painting of women working in the garden, in the style of Van Gogh\\
 & A painting of a wheat field by Van Gogh\\
 & Painting of trees in bloom in the style of Van Gogh\\
 & Van Gogh style painting of a tree\\
 & Painting of a wheat field in the style of Van Gogh\\
 & Van Gogh style painting of a field with mountains in the background\\
 & Painting of an olive tree in the style of Van Gogh \\
\midrule
\multirow{10}{*}{\shortstack[c]{Monet }} &  Rocks in the ocean, in the style of Monet \\
 & A painting of a city in the style of Monet  \\
 & A painting of a river in the style of Monet \\
 &Monet style painting of a person on a cliff \\
 & A painting of a town, in the style of Monet \\
 & A painting of a sunset, in the style of Monet \\
 & A painting of mountains, in the style of Monet \\
 &Monet style painting of flowers in a field \\
 & A painting of a landscape in the style of Monet \\
 &Two trees in a field, painting in the style of Monet \\
\midrule
\multirow{10}{*}{\shortstack[c]{Greg Rutkowski }} &  A man riding a horse, dragon breathing fire, Greg Rutkowski  \\
& A dragon attacking a knight in the style of Greg Rutkowski  \\
& A demonic creature in the wood, painting by Greg Rutkowski  \\
& A man in a forbidden city, Greg Rutkowski  \\
& Painting of a group of people on a dock by Greg Rutkowski  \\
& A king standing, with people around in a hall, Greg Rutkowski  \\
&Two magical characters in space, painting by Greg Rutkowski  \\
& A man with a fire in his hands in the style of Greg Rutkowski  \\
& Painting of a woman sitting on a couch by Greg Rutkowski  \\
& A painting of a boat on the water in the style of Greg Rutkowski  \\
\midrule
\multirow{10}{*}{\shortstack[c]{Salvador Dali }} & The persistence of memory painting in the style of Salvador Dali \\
& The elephant painting in the style of Salvador Dali \\
& Soft construction with boiled beans painting in the style of Salvador Dali \\
& Galatea of the spheres painting in the style of Salvador Dali \\
& The temptation of St. Anthony painting in the style of Salvador Dali\\
& Swans reflecting elephants painting in the style of Salvador Dali \\
& Enigma of desire painting in the style of Salvador Dali \\
& Slave market with the disappearing bust of voltaire painting of Salvador Dali \\
& The meditative rose painting in the style of Salvador Dali \\
& Melting watch painting in the style of Salvador Dali \\
\midrule
\multirow{10}{*}{\shortstack[c]{Jeremy Mann }} & In the style of Jeremy Mann, a view of a city skyline at sunset, with a warm glow spreading across the sky and the buildings below \\
& In the style of Jeremy Mann, an urban scene of a group of people gathered on a street corner, captured in a moment of quiet reflection \\
& In the style of Jeremy Mann, a surreal composition of floating objects,  with a dreamlike quality to the light and color \\
& In the style of Jeremy Mann, a view of a city street at night, with the glow of streetlights and neon signs casting colorful reflections on the wet pavement\\
& In the style of Jeremy Mann, a moody, atmospheric scene of a dark alleyway, with a hint of warm light glowing in the distance \\
& In the style of Jeremy Mann, an urban scene of a group of people walking through a park captured in a moment of movement and energy \\
& In the style of Jeremy Mann, a landscape of a forest, with dappled sunlight filtering through the leaves and a sense of stillness and peace \\
& In the style of Jeremy Mann, a surreal composition of architectural details and organic forms, with a sense of tension and unease in the composition\\
&In the style of Jeremy Mann, an abstract composition of geometric shapes and intricate patterns, with a vibrant use of color and light\\
& In the style of Jeremy Mann, a moody, atmospheric scene of a dark alleyway, with a hint of warm light glowing in the distance \\
\midrule
\multirow{10}{*}{\shortstack[c]{Painting }} & Figure with a still-life in Oils - How to Paint Wooden Textures in Oil Painting \\
 &Glazing Technique Demo \\
 &paint background model train - Recherche Google \\
 &Miniature Artist Studio in half scale. \\
 &Portrait Of Eva Gonzales 1870 Poster \\
 &Doing Sidewalk Chalk Art Stock Footage \\
 &Female artist paints picture artwork in art studio. Female artist paints a picture oil painting artwork drawing on canvas easel in art studio. Student girl stock video\\
 &Little Artist. by KissSatsuki \\
 &Colorful Mess Painting - stock footage \\
 & The painter's monkey  \\
\bottomrule
\vspace{-10pt}
\end{tabular}
}
\vspace{-8pt}
\caption{\textbf{Prompts used for evaluating ablation of style concept.} We list here all the $10$ prompts that were used to generate the images during evaluation.}

\label{tbl:prompts_style_eval}
\vspace{-6pt}
\end{table}



\begin{table}[!t]
\centering
\setlength{\tabcolsep}{5pt}
\resizebox{\linewidth}{!}{
\begin{tabular}{l p{10cm}}
\toprule
\shortstack[c]{\textbf{Target Concept} } 
& \shortstack[c]{\textbf{Evaluation Prompt} } \\
\midrule
 \multirow{10}{*}{\shortstack[c]{Grumpy cat}} &  What a cute Grumpy cat \\
 & My Grumpy cat is so cute \\
 & I can't believe how cute my Grumpy cat is \\
 & Look at that Grumpy cat \\
 & That Grumpy cat is so cute \\
 & I want a Grumpy cat \\
 & I wish I had a Grumpy cat \\
 & I'm getting a Grumpy cat \\
 & A Grumpy cat laying in the sun \\
 & A Grumpy cat perched atop a bookshelf \\
\midrule
\multirow{10}{*}{\shortstack[c]{R2D2 }} & The future is now with this amazing home automation R2D2 \\
 &This helpful R2D2 will make your life easier \\
 &The possibilities are endless with this versatile R2D2 \\
 &This R2D2 is sure to revolutionize the way we live \\
 &I love spending time with my R2D2 friends \\
 &All hail our new R2D2 overlords \\
 &I'm not afraid of robots \\
 &I would be lost without my R2D2 \\
 &This R2D2 is my everything \\
 &I'll never be alone with my R2D2 by my side \\
\midrule
\multirow{10}{*}{\shortstack[c]{Nemo}} & A Nemo leaping out of the water \\
 &A Nemo swimming downstream \\
 &A Nemo flapping its fins \\
 &A Nemo in a fishbowl \\
 &Isn't this Nemo I caught beautiful \\
 &I can't believe I caught a Nemo this big \\
 &A big Nemo in an aquarium \\
 &I'm a little Nemo, swimming in the sea \\
 &A school of Nemo \\
 &A baby Nemo  \\
\midrule
\multirow{10}{*}{\shortstack[c]{Snoopy}} & A devoted Snoopy accompanying its owner on a road trip \\
 &A peaceful Snoopy watching the birds outside the window \\
 &A confident Snoopy standing tall and proud after a successful training session \\
 &A determined Snoopy focused on catching a frisbee mid-air \\
 &A patient Snoopy waiting for its owner to come out of the grocery store \\
 &A grateful Snoopy giving its owner a grateful look after being given a treat \\
 &A loyal Snoopy following its owner to the ends of the earth \\
 &A playful Snoopy splashing around in a puddle \\
 &A happy Snoopy jumping for joy after seeing its owner return home \\
 &A sweet Snoopy enjoying a game of hide-and-seek \\
\bottomrule
\vspace{-10pt}
\end{tabular}
}
\vspace{-8pt}
\caption{\textbf{Prompts used for evaluating ablation of instances.} We list here all the $10$ prompts that were used to generate the images during evaluation. For generating images with surrounding or anchor concepts, e.g. {\menlo British shorthair cat}, we replace the target concept {\menlo Grumpy Cat} in the sentence with that. }

\label{tbl:prompts_instance_eval}
\vspace{-6pt}
\end{table}




\begin{table}[!t]
\centering
\setlength{\tabcolsep}{5pt}
\resizebox{\linewidth}{!}{
\begin{tabular}{l l}
\toprule
\shortstack[c]{\textbf{Target Concept} } 
& \shortstack[c]{\textbf{Surrounding Concept} } \\
\midrule
 \multirow{1}{*}{\shortstack[c]{Grumpy Cat}} & British Shorthair cat, Himalayan cat, Scottish Fold cat, Persian cat \\
\multirow{1}{*}{\shortstack[c]{R2D2 }} & BB8, C-3PO, Wall-E, Baymax \\
\multirow{1}{*}{\shortstack[c]{Nemo}} & Clown fish, Gobies, Damsel fish, Angel fish \\
\multirow{1}{*}{\shortstack[c]{Snoopy}} &  Beagles, Basset Hound, Harrier Dog, English Foxhound \\
\midrule
\multirow{1}{*}{\shortstack[c]{Van Gogh}} & Monet, Greg Rutkowski, Slavador Dali, Jeremy Mann \\
\multirow{1}{*}{\shortstack[c]{Monet }} & Van Gogh, Greg Rutkowski, Slavador Dali, Jeremy Mann\\
\multirow{1}{*}{\shortstack[c]{Greg Rutkowski}} & Monet, Van Gogh, Slavador Dali, Jeremy Mann \\
\multirow{1}{*}{\shortstack[c]{Slavador Dali}} & Monet, Greg Rutkowski, Van Gogh, Jeremy Mann\\
\bottomrule
\vspace{-10pt}
\end{tabular}
}
\vspace{-8pt}
\caption{\textbf{Surrounding concepts for each target concept.} We list here the surrounding concepts we used for each target concept. In the case of style concept, we used other remaining style concepts and included one more style {\menlo Jeremy Mann}. In the case of instance concepts, we used chatGPT to list the most similar instances to the target concept and selected the best four that can be generated by the pretrained Stable Diffusion model.  }

\label{tbl:surrounding_concept}
\vspace{-6pt}
\end{table}




\begin{table*}[!t]
\centering
\setlength{\tabcolsep}{5pt}
\resizebox{\linewidth}{!}{
\begin{tabular}{p{4cm} p{20cm}}
\toprule
\textbf{Target prompt}  
& \textbf{Anchor Prompts}  \\
\midrule
 \multirow{5}{4cm}{Anne Graham Lotz} &  An image depicting Anne Graham Lotz. \\
 & Picture of Anne Graham Lotz.\\
 & Anne Graham Lotz's photo.\\
 & Portrait of Anne Graham Lotz.\\
 & Photograph featuring Anne Graham Lotz.\\
\midrule
\multirow{5}{4cm}{Sony Boss Confirms Bloodborne Expansion is Coming} & Bloodborne. ``Hunter in the Forbidden Woods'': A lone hunter, clad in worn leather armor and wielding a serrated saw cleaver, navigates through a dense forest filled with twisted trees and roving beasts. The air is thick with the scent of decay, and eerie whispers can be heard in the distance. \\
 &Bloodborne. ``Nightmare of Mensis'': Standing atop a massive stone balcony, a hunter looks out over a sprawling cityscape shrouded in darkness. Strange structures and twisted spires rise up from the mist, and the moon hangs low in the sky. In the distance, a massive spider-like creature can be seen crawling along the skyline.\\
 &Bloodborne. ``Cathedral Ward'': The grand entrance to a towering cathedral looms before a lone hunter, its ornate facade and intricate stonework casting long shadows in the moonlight. Gargoyles perch atop the steeples, and flickering candles can be seen through the stained glass windows.\\
 &Bloodborne. ``Beastly Pursuit'': A hunter sprints down a narrow alleyway, pursued by a hulking beast with razor-sharp claws and glowing yellow eyes. Crates and barrels are knocked aside in the frantic chase, and the hunter's only hope is to outrun the ferocious creature.\\
 &Bloodborne. ``A Meeting with the Doll'': In a dimly-lit workshop, a hunter stands before a life-sized doll with porcelain skin and flowing hair. Its eyes stare blankly ahead, but there is a palpable sense of otherworldly energy emanating from it. The hunter can almost sense the presence of a greater power guiding them forward on their quest. \\
\midrule
\multirow{5}{4cm}{$<i>$The Long Dark$<i>$ Gets First Trailer, Steam Early Access} & The video game called ``The Long Dark'' has released its initial  preview video and is now available for early access on the Steam platform. \\
 &Debut trailer and Steam Early Access now available for ``The Long Dark'' video game. \\
 &First glimpse of ``The Long Dark'' game in new trailer and early access release on Steam. \\
 &``The Long Dark'' game trailer and early access now on Steam. \\
 &Early access for ``The Long Dark'' now on Steam, accompanied by debut trailer.  \\
\midrule
\multirow{5}{4cm}{Portrait of Tiger in black and white by Lukas Holas}& Majestic and powerful: a black and white portrait of a tiger in its natural habitat.\\
 &The fierce gaze of a predator: Lukas Holas captures the intense beauty of a tiger in black and white.\\
 &Intricate patterns and piercing eyes: a stunning black and white portrait of a wild tiger in monochrome.\\
 &Lukas Holas' photography transports us to the heart of the jungle with this captivating black and white tiger portrait.\\
 &A glimpse into the wild: Lukas Holas' striking black and white photograph showcases the raw beauty of a tiger. \\
 \midrule
\multirow{5}{4cm}{A painting with letter M written on it Canvas Wall Art Print} & A Canvas Wall Art Print with the letter M painted on it.\\
 &An image of a painting featuring the letter M on Canvas Wall Art Print.\\
 &A work of art on a canvas print with the letter M inscribed on it.\\
 &An artwork consisting of the letter M painted on a canvas wall print.\\
 &A Canvas Wall Art Print displaying a painting that includes the letter M. \\
 \midrule
\multirow{5}{4cm}{Captain Marvel Exclusive Ccxp Poster Released Online By Marvel} & She's here to save the day! Captain Marvel to the rescue! \\
 &Earth's mightiest hero has arrived - Captain Marvel in action! \\
 &Unleashing her cosmic powers - Captain Marvel takes on any challenge! \\
 &Fighting for justice and protecting the universe - Captain Marvel is unstoppable! \\
 &With her fierce determination and superhuman strength, Captain Marvel is a force to be reckoned with! \\
 \midrule
\multirow{5}{4cm}{New Orleans House Galaxy Case} & Make a statement with your phone case - this Orleans House Samsung Galaxy cover is sure to turn heads.\\
 &If you're looking for a way to make your Samsung Galaxy phone stand out from the crowd, this Orleans House cover is the perfect solution. Featuring a unique and eye-catching design, this cover is sure to turn heads and make your device the envy of everyone around you.\\
 &Show off your love for architecture and technology with this Samsung Galaxy phone cover featuring Orleans house.\\
 &Make your Samsung Galaxy phone stand out from the crowd with this unique Orleans house phone cover.\\
 &Keep your phone safe and secure with a touch of elegance with this Samsung Galaxy phone cover featuring Orleans house. \\
  \midrule
\multirow{5}{4cm}{VAN GOGH CAFE TERASSE copy.jpg} & A glimpse into Van Gogh's world of vibrant cafes and bustling streets.\\
 &The allure of Parisian cafe culture captured on canvas by Van Gogh.\\
 &Step into the world of art and history with this stunning portrayal of a cafe by Van Gogh.\\
 &Van Gogh's signature brushstrokes bring this cafe to life with movement and energy.\\
 &Experience the warmth and charm of a Parisian cafe through Van Gogh's eyes. \\
\bottomrule
\vspace{-10pt}
\end{tabular}
}
\vspace{-8pt}
\caption{\textbf{Anchor prompts when ablating memorized images.} We list here the captions used as anchor prompts corresponding to the target prompts which leads to the generation of memorized images.  }

\label{tbl:prompts_mem}
\vspace{-6pt}
\end{table*}




