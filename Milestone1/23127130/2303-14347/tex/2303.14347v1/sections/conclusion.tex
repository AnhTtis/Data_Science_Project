\section{Conclusion}
We developed a novel learning, vision-based framework for autonomous vineyard navigation that lift the requirement of costly human annotation. A training dataset with annotation was automatically generated by a single-time autonomous field acquisition using a RGB-D camera and a RTK GPS. The generated training dataset was used to train a custom network for path detection for row tracking. The same model was also used to perform row switching, allowing the robot to traverse through the field of multiple rows autonomously. The experimental results demonstrated 1) the automatic annotation significantly reduced the cost and lowered the barriers of using learning-based model for navigtaion path detection and 2) the trained network and developed framework achieved satisfactory accuracy, robustness, and generalizability for autonomous navigation even in totally unseen vineyards.

In future studies, we will focus on 1) improving the stability of the row switching module, espcially under challenging cases and 2) adding the centerline tracking feature to the navigation framework for collecting uniform data for plant phenotyping and vineyard management purposes. We will also conduct additional field tests in different cropping systems (e.g., row crops) to explore the full potential of the developed framework.