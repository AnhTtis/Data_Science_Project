\section{Medical Temporal Constraints (MTCs)}

Modeling MTCs in DUGs is challenging for the following reasons. MTCs vary in terms of temporal precision; some MTCs are definitive, while some are imprecise. Many MTCs constrain a single activity, the medication intake activity (e.g., taking a medication at \textit{n} hour intervals). However, MTCs can also form dependencies between multiple activities (e.g., taking a medication \textit{m} hours before eating). Based on our review of DUGs from heterogeneous sources \cite{preum2018corpus, Medscape, openFDA, mtsamples}, we formulate the following novel taxonomy of MTCs.

\subsection{Taxonomy of MTCs}
MTCs can be either definitive or imprecise. Definitive MTCs can be further categorized into three classes: dependency, frequency, and interval. Imprecise MTCs can  be categorized into four classes: dependency, time dependency, consistency, and time-of-day.

\begin{enumerate}

\item Definitive dependency constraints capture temporal dependencies between taking medication and other regular activities. For example, from the DUG for the drug Protonix: "If you are taking the granules, take your dose \textbf{30 minutes before a meal}." 

\item Frequency constraints capture the temporal constraints regarding the suggested frequency of a medication administration, i.e., how many times a medication should be taken in a specific interval. For example, from the DUG for the drug Wellbutrin: "Take this medication by mouth, with or without food, usually \textbf{three times daily}."

\item Interval constraints capture the temporal constraints regarding the suggested interval between consecutive medication administrations. For example, again from the DUG for the drug Wellbutrin: "It is important to take your doses at least \textbf{6 hours apart} or as directed by your doctor to decrease your risk of having a seizure."

\item Imprecise dependency constraints capture inexact temporal dependencies between taking medication and other regular activities. For example, from the DUG for the drug Singulair: "Do not \textbf{take a dose before exercise} if you are already taking this medication daily for asthma or allergies. Doing so may increase the risk of side effects."

\item Time dependency constraints capture inexact temporal dependencies between taking medication and a specific time of day. For example, from the DUG for the medication Prednisone: "If you are prescribed only one dose per day, take it in the morning \textbf{before 9 AM}."

\item Consistency constraints capture the requirement to take a medication consistently at a given time interval. For example, from the DUG for the medication Zocor: "Remember to take it at the \textbf{same time each day}."

\item Time-of-day constraints capture the requirement to take a medication at a certain time of a day. Take, for example, the DUG for the medication Prednisone: "If you are prescribed only one dose per day, take it \textbf{in the morning}."

\end{enumerate}

A DUG may contain multiple MTCs for a single medication. For instance, consider the following statement from the DUG of the drug Starlix: "Take this medication by mouth \textbf{1-30 minutes before each main meal}, usually \textbf{3 times daily}, or as directed by your doctor." Here the text has both a definitive dependency constraint (MTC type 1) and a frequency constraint (MTC type 2).

\subsection{A Context-free Grammar for Modeling MTCs}
A formal grammar is "context-free" if its production rules can be applied regardless of the context of a nonterminal. The taxonomy of the MTCs mentioned above motivates us to develop a context-free grammar (CFG) to model these definitive and imprecise MTCs. A CFG is a suitable solution to model these dependencies and constraints as the production rule can be applied to any relevant dataset regardless of the context of the nonterminal, i.e., different types of MTCs. Our novel grammar developed and integrated in this work contains the following set of terminals. 

\begin{itemize}
    \item natural number, $n$: 1 $\mid$ 2 $\mid$ 3...
    \item activity, $act$: sleeping $\mid$ eating $\mid$ taking medication $\mid$ ...
    \item prepositions of temporal dependency, $dp$: before $\mid$ after 
    \item prepositions of interval dependency, $ip$: within $\mid$ for $\mid$ apart    
    \item prepositions of occurrence, $p$: at $\mid$ in
    \item unit of time slots, $u$: hour $\mid$ minute $\mid$ day $\mid$ week
    \item time stamp, $t$: the same time $\mid$ 9 am $\mid$ 10.30 pm $\mid$ ...
    \item time of the day, $d$: morning $\mid$ evening $\mid$ noon
\end{itemize}

Using these terminals, the MTCs can be expressed using the following nonterminals.

\begin{enumerate}
\item Definitive dependency constraint: $V_1$: $n$.$u$.$dp$.$act$ (e.g., 30 minutes before eating)
\item Frequency constraint:  $V_2$: $n$ times in a $u$ (e.g., three times a day)
\item Interval constraint: $V_3$: $n$.$u$.$ip$ (e.g., 6 hours apart)
\item Imprecise dependency constraint: $V_4$: $dp$.$act$ (e.g., before meal)
\item Imprecise time dependency constraint: $V_5$: $dp$.$t$ (e.g., before 9 AM)
\item Consistency constraint: $V_6$: $p$.$t$ each $u$ (e.g., at the same time each day or at 9 am each day)
\item Time-of-day constraint: $V_7$: $p$.$d$ (e.g., in morning)
\end{enumerate}

The proposed CFG can also be used to model compound MTCs. For instance, taking a medication 2 hours before meal ($V_1$), 3 times a day ($V_2$), and 4 hours apart ($V_3$) can be expressed as: $V_i$: $V_1$.$V_2$.$V_3$. This grammar can also be extended to model negated MTCs. For instance, "do not take this medication before exercise" can be modeled as, $\lnot$ $V_4$, where $V_4$: $dp$.$act$. 

%\section{Solution: MTC Extraction}

\subsection{The MTC Extraction Task}
\label{sec:extraction_task}
%\textcolor{blue}{Capitalize drug names?}
We define the task of \textbf{MTC extraction} as an information extraction \textbf{text-to-structure task}, in which a DUG is taken as input and a list of MTCs conforming to the proposed CFG is given as output. We choose to model MTCs using a CFG because it blends readability and parsability. Consider this statement from the DUG for the drug Pantoprazole, which is used to treat stomach ulcers: "If you are also taking Sucralfate, take Pantoprazole at least 30 minutes before Sucralfate." The MTC contained in this statement is a definitive dependency constraint (MTC type 1), which under the CFG is labeled "30 minute before taking Sucralfate." This label is easy to understand while also conforming to the proposed CFG, i.e. $n=$ 30 $u=$ minute $dp=$ before $act=$ taking Sucralfate. Because it conforms to the CFG, the label enables potential downstream systems to model the semantics of the MTC. 

MTCs contained in free-format DUGs may not always conform to the CFG exactly. Consider the statements "take this medication at least 1 hour before any meals" and "be sure to wait at least 1 hour after taking this medication before eating." Both statements contain the definitive dependency constraint "1 hour before eating" (MTC type 1) however neither statement directly conforms to the CFG. This highlights that the task of extracting and normalizing MTCs from these materials cannot be accomplished by grammar-based decoding alone. Hence, we examine other methods for extracting MTCs. % \textcolor{blue}{Refer to the table that has examples of these 3 types of prompts}

\subsection{In-Context Learning for MTC Extraction}
Guided by recent breakthroughs in clinical information extraction using LLMs \cite{agrawal2022large, dunn2022structured, torii2023task}, we explore the use of ICL to benchmark the MTC extraction task. ICL is a recently-introduced paradigm in few-shot sequence-to-sequence text modeling in which an LLM is asked to perform a task after being given a prompt and several examples \cite{agrawal2022large}. We choose to use GPT-3 \cite{brown2020language} in our MTC extraction experiments because it has been shown to be effective in extracting both structured scientific information \cite{dunn2022structured} and medication information, such as dosage and frequency \cite{agrawal2022large}, using ICL strategies. Additionally, the number of DUGs across our three datasets is relatively small ($<1000$). Lehman et al. show that for size-constrained datasets, ICL with GPT-3 outperforms task-specific models on a variety of clinical tasks \cite{lehman2023we}. We design two prompts for extracting MTCs from free-format textual DUG data using ICL, and a third model which utilizes customized/specialized prompts for each MTC type.

\textbf{Simple prompt:} We design a simple prompt for extracting all listed MTCs to serve as an ICL baseline. This is referred to as the \textit{simple} prompt.
    
\textbf{Guided prompt:} The second is a much longer prompt, featuring elements of the labeling guide given to human annotators for annotating the FDA dataset. This prompt includes the rules of the CFG, including lists of both the terminals and the nonterminals. It also includes a list of potential activities. This is referred to as the \textit{guided} prompt.

\textbf{Specialized prompt:} We develop prompts for extracting each of the MTC types separately. Each of the prompts contains a basic description of the MTC, as well as a heuristic for formatting the MTC correctly. This approach is referred to as the \textit{specialized} model.

% \begin{itemize}
%     \item We design a simple prompt for extracting all listed MTCs to serve as an ICL baseline. This is referred to as the \textit{simple} model.
%     \item The second is a much longer prompt, featuring elements of the labeling guide given to human annotators for annotating the FDA dataset. This prompt includes the rules of the CFG, including lists of both the terminals and the nonterminals. It also includes a list of potential activities. This is referred to as the \textit{guided} model.
%     \item We develop prompts for extracting each of the MTC types separately. Each of the prompts contains a basic description of the MTC, as well as a heuristic for formatting the MTC correctly. This approach is referred to as the \textit{specialized} model.
% \end{itemize}

% FIGURE
\begin{figure}[htbp]
\centerline{\includegraphics[width=\columnwidth]{../figures/system_chart.png}}
\caption{Overview of the In-Context Learning Text-to-Structure System}
\label{fig:system_chart}
\end{figure}

%\textcolor{blue}{( randomly-selected? if not should describe the strategy) }
In addition to each prompt, 20 DUGs are strategically selected from the datasets and passed as few-shot examples, as in \cite{agrawal2022large}. Specifically, these 20 DUGs are selected from all three datasets such that we have a representative sample distribution for each MTC type, i.e., including simple and difficult normalization examples, empty and non-empty examples, and examples of single and multiple extracted MTCs. The same 20 examples are used when testing ICL for MTC extraction across all datasets. These examples are removed from the datasets when testing to ensure no data leakage occurs. LLM output is passed through a simple post-processing module which attempts to align the outputs with the CFG. An overview of the ICL system is shown in Fig. \ref{fig:system_chart}.% The \textit{simple} and \textit{guided} prompts, along with an example prompt from the \textit{specialized} model, are given in Table \ref{tab:icl_prompts}. 

%\subfile{../tables/icl_prompts}

%\textcolor{blue}{missing information: prompting? details?}