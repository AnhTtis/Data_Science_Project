\section{Background}\label{sec:3}
In this section, we briefly describe the MPEPC navigation~\cite{park_mpepc} algorithm. We also give an overview of prior work on smooth control law~\cite{park_smoothlaw}. 
%and MPEPC-based Navigation~\cite{park_mpepc}.
%able~\ref{tab:notation} summarizes the commonly used notations in this paper.

\subsection{Assumptions}

We consider a differential-drive robot navigating complex environments with static and dynamic obstacles. The static environment information is available as an occupancy map, and we assume the current position and velocity data can be estimated for dynamic obstacles (like pedestrians). In addition, we use a constant velocity model to estimate the future positions of dynamic obstacles over the planning horizon.  Our approach can be used for simulated environments as well as real-world datasets captured using visual sensors.

\begin{table}[]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        $p_c$ & Collision Probability \\
        \hline
        $p_s$ & Survivability\\
        \hline
        $v_i$ & Velocity at time step $i$\\
        \hline
        $v_{max}$ & Max. velocity\\
        \hline
        $d_o$ & Distance to closest obstacle\\
        \hline
        $d_g$ & Distance to goal \\
        \hline
        $h$ & Time step \\
        \hline
        $TTC$ & Time to collision \\
        \hline
        $TTG$ & Time to goal\\
        \hline
        $T$ & Target goal \\
        \hline
        $r$ & Robot's distance from T\\
        \hline
        $los$ & Line of sight from robot to T\\
        \hline
        $\theta$ & Orientation of T relative to $los$\\
        \hline
        $\delta$ & Orientation of robots pose with $los$\\
        \hline
        $z*$ & Trajectory parameter $(r,\theta,\delta,v_{max})$\\
        \hline
        $N$ & Terminal timestep\\
        \hline
        $\omega$ & Angular velocity\\
        \hline
    \end{tabular}
    \caption{Symbols and Notation}
    \label{tab:notation}
\end{table}

\subsection{Smooth Control Law}\label{sec:smoothlaw}

Park and Kuipers~\cite{park_smoothlaw} define an ego-centric coordinate system relating the robot's current pose with its target goal pose $T$. Consider a goal configuration $T$ at a distance $r$ away from the robot, let $\theta$ represent the orientation of $T$ relative to the line of sight from the robot to the target, and let $\delta$ define the orientation of the robot's current configuration with the line of sight. The triplet $(r, \theta, \delta)$ defines an ego-centric coordinate system describing the robot's current pose with its target goal pose.

Further, the authors define a non-linear pose-following control law that globally drives a robot towards $T$. Here, $k_1$ and $k_2$ define gain parameters. 
$$
\omega = -\frac{v}{r} [ k_2 (\delta - arctan(-k_1\theta) + (1 + \frac{k_1}{1 + (k_1\theta)^2})\sin \delta]
$$
$$
\omega = \mathbf{\kappa} v
$$
The above control law defines the shape of the trajectory with the target $T$ acting as an attractor; the maximum velocity $v_{max}$ defines strength of the attraction.

The ego-centric frame $(r, \theta, \delta)$ and $v_{max}$ define a parameterized trajectory space. The 4-dimension vector, represented by $z* = (r, \theta, \delta, v_{max})$ completely defines the trajectory of the robot to target $T$. The trajectory space is smooth and realizable by construction. Thus, given a trajectory parameter $z*$, we can completely define the trajectory converging to the target.

\subsection{Robot Navigation using MPEPC}\label{ref:cost_mpepc}

Park et al.~\cite{park_mpepc} frames the safe navigation as an optimization problem, selecting a suitable trajectory parameter $z*$, which generates the desired trajectory. 
Let 
$$
q_{z*} : [0,T]\rightarrow C 
$$
denote the trajectory parameterized by $z*$ within a finite horizon $T$.  

The planner optimizes to select a suitable trajectory parameter $z*$ which minimizes the expected trajectory cost.
\begin{multline}\label{eqn:orig_cost}
    J(q_{z*}) = \sum^N  p_{s_i} * J_{progress_i} + J_{action_i} \\+ (1-p_{s_i})* J_{collision_i}
\end{multline}
The term $J_{progress}$ captures the progress the robot makes towards the goal, $J_{action}$ captures the cost of applying large action, and $J_{collision}$ captures the cost of collision. The progress and collision terms are weighed by survivability ($p_s$), which is a measure of the probability that the trajectory remains collision-free. $N$ is the planning horizon.
 
The authors define survivability based on the notion of collision probability into the cost function. From~\cite{park_thesis}, the probability of collision for a robot over a short time segment is defined by the bell-shaped function:

\begin{equation}\label{eqn:pci}
p_{c_i} = \exp(-d_o^2/ \sigma^2)
\end{equation}

The probability of survivability is defined using the $p_c$ as
\begin{equation}\label{eqn:psi}
    p_{s_i} = \Pi_1^i (1 - p_{c_k}).
\end{equation}
{\color{black}{
This formulation is used in a navigation framework~\cite{park_thesis}. The framework guarantees probabilistic safety rather than trying to provide absolute collision avoidance, which is very hard to guarantee in cluttered, dynamic environments. %Particularly the algorithm avoids robots motion when the robot is already in a collision state and continually tries to minimize the potential cost of collision due to robot motion.
}}