\section{Limitations and Future Work} \label{sec:discussions}

Our method produces highly photorealistic renderings with novel viewpoints and expressions. However, it suffers from a number of limitations. First, we noticed that it can generate artifacts in motions undergoing strong disocclusions (uncovering occlusions). For instance, in the case of the tongue, artifacts could occur around the mouth boundaries as the tongue starts to come out (see Fig.~\ref{fig:tonguelimiation}, Frame 1, blue region). The rendering quality, however, stabilizes with good quality as soon as the tongue becomes fully visible (see Fig.~\ref{fig:tonguelimiation}, Frame 2). Future work could address this limitation e.g. by including occlusion-aware priors.
%
Second, our solution is currently person-specific. Future work could examine building a model that generalizes to unseen identities. For this, our dataset of 16 identities is a good starting point, though it might require more identities. Here, we could also investigate refining the model using in-the-wild data.
%
Third, while we have shown real-time renderings at a resolution of $480\times270$, future avenues could enable real-time rendering at higher resolutions e.g. FHD synthesis. Here, we could investigate for instance super-resolution techniques, akin to~\cite{chan2022_efficient-geom-aware,Xiang22GRAM-HD}. 
%
Finally, we have shown results driven by monocular RGB videos so far. Theoretically, our image encoder could be replaced with other pre-trained encoders of different input modalities, such as audio signals. This would increase the spectrum of applications of our work.
