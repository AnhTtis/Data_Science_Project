


 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }


 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } 

 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } 
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } 
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } 
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } 
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } 
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }


 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})
@String(SIGGRAPH = {{SIGGRAPH}})
@String(CGF  = {Comput. Graph. Forum})

@String(CVFIEEE = {Computer Vision Foundation / {IEEE} Computer Society})
@String(CORR = {CoRR})
@String(ARXIV = {arXiv})
@String(IEEE = {{IEEE}})
@String(LNCS = {Lecture Notes in Computer Science})
@String(IEEEA = {{IEEE} Access})
@String(IEEECS = {{IEEE} Computer Society})
@String(ACM = {{ACM}})


@article{tewari2022_advances-neural-render,
    author    = {Ayush Tewari and Justus Thies and Ben Mildenhall and Pratul P. Srinivasan and
                 Edgar Tretschk and Yifan Wang and Christoph Lassner and Vincent Sitzmann and
                 Ricardo Martin{-}Brualla and Stephen Lombardi and Tomas Simon and
                 Christian Theobalt and Matthias Nie{\ss}ner and Jonathan T. Barron and
                 Gordon Wetzstein and Michael Zollh{\"{o}}fer and Vladislav Golyanik},
    title     = {Advances in Neural Rendering},
    journal   = CGF,
    volume    = {41},
    number    = {2},
    pages     = {703--735},
    year      = {2022}
}

@article{tewari2020_sota-neural-render,
    author    = {Ayush Tewari and Ohad Fried and Justus Thies and Vincent Sitzmann and 
                 Stephen Lombardi and Kalyan Sunkavalli and Ricardo Martin{-}Brualla and 
                 Tomas Simon and Jason M. Saragih and Matthias Nie{\ss}ner and 
                 Rohit Pandey and Sean Ryan Fanello and Gordon Wetzstein and 
                 Jun{-}Yan Zhu and Christian Theobalt and Maneesh Agrawala and 
                 Eli Shechtman and Dan B. Goldman and Michael Zollh{\"{o}}fer},
    title     = {State of the Art on Neural Rendering},
    journal   = CGF,
    volume    = {39},
    number    = {2},
    pages     = {701--727},
    year      = {2020}
}

@article{egger2020_3dmfm,
    author    = {Bernhard Egger and William A. P. Smith and Ayush Tewari and 
                 Stefanie Wuhrer and Michael Zollh{\"{o}}fer and Thabo Beeler and 
                 Florian Bernard and Timo Bolkart and Adam Kortylewski and 
                 Sami Romdhani and Christian Theobalt and Volker Blanz and Thomas Vetter},
    title     = {3D Morphable Face Models - Past, Present, and Future},
    journal   = TOG,
    volume    = {39},
    number    = {5},
    pages     = {157:1--157:38},
    year      = {2020}
}

@article{zollhofer18_sota-mon-3d,
  author    = {Michael Zollh{\"{o}}fer and
               Justus Thies and
               Pablo Garrido and
               Derek Bradley and
               Thabo Beeler and
               Patrick P{\'{e}}rez and
               Marc Stamminger and
               Matthias Nie{\ss}ner and
               Christian Theobalt},
  title     = {State of the Art on Monocular 3D Face Reconstruction, Tracking, and
               Applications},
  journal   = CGF,
  volume    = {37},
  number    = {2},
  pages     = {523--550},
  year      = {2018},
}

@article{kim2018_dvp,
    author    = {Hyeongwoo Kim and Pablo Garrido and Ayush Tewari and Weipeng Xu and
                 Justus Thies and Matthias Nie{\ss}ner and Patrick P{\'{e}}rez and
                 Christian Richardt and Michael Zollh{\"{o}}fer and Christian Theobalt},
    title     = {Deep video portraits},
    journal   = TOG,
    volume    = {37},
    number    = {4},
    pages     = {163},
    year      = {2018}
}


@article{thies2019_dnr,
  author    = {Justus Thies and
               Michael Zollh{\"{o}}fer and
               Matthias Nie{\ss}ner},
  title     = {Deferred neural rendering: image synthesis using neural textures},
  journal   = TOG,
  volume    = {38},
  number    = {4},
  pages     = {66:1--66:12},
  year      = {2019},
}

@article{tewari2020_pie,
  author    = {Ayush Tewari and Mohamed Elgharib and Mallikarjun B. R. and Florian Bernard and
               Hans{-}Peter Seidel and Patrick P{\'{e}}rez and Michael Zollh{\"{o}}fer and
               Christian Theobalt},
  title     = {{PIE:} portrait image embedding for semantic control},
  journal   = TOG,
  volume    = {39},
  number    = {6},
  pages     = {223:1--223:14},
  year      = {2020}
}

@article{chandran2021_rendering-style,
  author    = {Prashanth Chandran and Sebastian Winberg and Gaspard Zoss and
               J{\'{e}}r{\'{e}}my Riviere and Markus H. Gross and Paulo F. U. Gotardo and
               Derek Bradley},
  title     = {Rendering with style: combining traditional and neural approaches
               for high-quality face rendering},
  journal   = TOG,
  volume    = {40},
  number    = {6},
  pages     = {223:1--223:14},
  year      = {2021}
}

@inproceedings{wang2021_one-shot,
    author    = {Ting{-}Chun Wang and Arun Mallya and Ming{-}Yu Liu},
    title     = {One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing},
    booktitle = CVPR,
    pages     = {10039--10049},
    publisher = CVFIEEE,
    year      = {2021}
}

@inproceedings{meshry2021_learned-spatial,
    author    = {Moustafa Meshry and Saksham Suri and Larry S. Davis and Abhinav Shrivastava},
    title     = {Learned Spatial Representations for Few-shot Talking-Head Synthesis},
    booktitle = ICCV,
    pages     = {13809--13818},
    publisher = IEEE,
    year      = {2021}
}

@article{ichim2015_dynamic_3davatar,
  author    = {Alexandru Eugen Ichim and
               Sofien Bouaziz and
               Mark Pauly},
  title     = {Dynamic 3D avatar creation from hand-held video input},
  journal   = TOG,
  volume    = {34},
  number    = {4},
  pages     = {45:1--45:14},
  year      = {2015},
}

@article{cao2016_realtime,
  author    = {Chen Cao and
               Hongzhi Wu and
               Yanlin Weng and
               Tianjia Shao and
               Kun Zhou},
  title     = {Real-time facial animation with image-based dynamic avatars},
  journal   = TOG,
  volume    = {35},
  number    = {4},
  pages     = {126:1--126:12},
  year      = {2016},
}
@inproceedings{tewari2018_self-supervised,
    author    = {Ayush Tewari and Michael Zollh{\"{o}}fer and Pablo Garrido and
                 Florian Bernard and Hyeongwoo Kim and Patrick P{\'{e}}rez and
                 Christian Theobalt},
    title     = {Self-Supervised Multi-Level Face Model Learning for Monocular Reconstruction
                 at Over 250 Hz},
    booktitle = CVPR,
    pages     = {2549--2559},
    publisher = CVFIEEE,
    year      = {2018}
}

@article{yamaguchi2018_high-fidelity,
    author    = {Shugo Yamaguchi and Shunsuke Saito and Koki Nagano and Yajie Zhao and
                 Weikai Chen and Kyle Olszewski and Shigeo Morishima and Hao Li},
    title     = {High-fidelity facial reflectance and geometry inference from an unconstrained
                 image},
    journal   = TOG,
    volume    = {37},
    number    = {4},
    pages     = {162},
    year      = {2018}
}

@article{nagano2018_pagan,
    author    = {Koki Nagano and Jaewoo Seo and Jun Xing and Lingyu Wei and
                 Zimo Li and Shunsuke Saito and Aviral Agarwal and Jens Fursund and
                 Hao Li},
    title     = {paGAN: real-time avatars using dynamic textures},
    journal   = TOG,
    volume    = {37},
    number    = {6},
    pages     = {258},
    year      = {2018}
}

@inproceedings{thies2016face,
  author = {Thies, J. and Zollh{\"o}fer, M. and Stamminger, M. and Theobalt, C. and Nie{\ss}ner, M.},
  title = {Face2Face: Real-time Face Capture and Reenactment of RGB Videos},
  booktitle = {Proc. Computer Vision and Pattern Recognition (CVPR), IEEE},
  year = {2016}
}

@article{thies2019_face2face,
  author    = {Justus Thies and
               Michael Zollh{\"{o}}fer and
               Marc Stamminger and
               Christian Theobalt and
               Matthias Nie{\ss}ner},
  title     = {Face2Face: real-time face capture and reenactment of {RGB} videos},
  journal   = CACM,
  volume    = {62},
  number    = {1},
  pages     = {96--104},
  year      = {2019},
}


@inproceedings{tran2019_towards,
    author    = {Luan Tran and Feng Liu and Xiaoming Liu},
    title     = {Towards High-Fidelity Nonlinear 3D Face Morphable Model},
    booktitle = CVPR,
    pages     = {1126--1135},
    publisher = CVFIEEE,
    year      = {2019}
}

@article{shamai2019_synthesizing-facial,
    author = {Shamai, Gil and Slossberg, Ron and Kimmel, Ron},
    title = {Synthesizing Facial Photometries and Corresponding Geometries Using
             Generative Adversarial Networks},
    year = {2019},
    volume = {15},
    number = {3s},
    journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
}

@inproceedings{grecer2019_ganfit,
    author    = {Baris Gecer and Stylianos Ploumpis and Irene Kotsia and Stefanos Zafeiriou},
    title     = {{GANFIT:} Generative Adversarial Network Fitting for High Fidelity
                 3D Face Reconstruction},
    booktitle = CVPR,
    pages     = {1155--1164},
    publisher = CVFIEEE,
    year      = {2019},
}

@inproceedings{lin2020_towards-hf,
    author    = {Jiangke Lin and Yi Yuan and Tianjia Shao and Kun Zhou},
    title     = {Towards High-Fidelity 3D Face Reconstruction From In-the-Wild Images
                 Using Graph Convolutional Networks},
    booktitle = CVPR,
    pages     = {5890--5899},
    publisher = CVFIEEE,
    year      = {2020}
}

@article{lattas2022_avatarme++,
  author    = {Alexandros Lattas and
               Stylianos Moschoglou and
               Stylianos Ploumpis and
               Baris Gecer and
               Abhijeet Ghosh and
               Stefanos Zafeiriou},
  title     = {AvatarMe\({}^{\mbox{++}}\): Facial Shape and {BRDF} Inference With
               Photorealistic Rendering-Aware GANs},
  journal   = PAMI,
  volume    = {44},
  number    = {12},
  pages     = {9269--9284},
  year      = {2022},
}

@article{ren2022_facial-geom,
    author    = {Xingyu Ren and Alexandros Lattas and Baris Gecer and Jiankang Deng and
                 Chao Ma and  Xiaokang Yang and Stefanos Zafeiriou},
    title     = {Facial Geometric Detail Recovery via Implicit Representation},
    journal   = CORR,
    volume    = {abs/2203.09692},
    year      = {2022},
    eprinttype = ARXIV
}

@article{cao2014_facewarehouse,
  author    = {Chen Cao and
               Yanlin Weng and
               Shun Zhou and
               Yiying Tong and
               Kun Zhou},
  title     = {FaceWarehouse: {A} 3D Facial Expression Database for Visual Computing},
  journal   = TVCG,
  volume    = {20},
  number    = {3},
  pages     = {413--425},
  year      = {2014},
}

@article{li2017_flame, 
  author    = {Tianye Li and
               Timo Bolkart and
               Michael J. Black and
               Hao Li and
               Javier Romero},
  title     = {Learning a model of facial shape and expression from 4D scans},
  journal   = TOG,
  volume    = {36},
  number    = {6},
  pages     = {194:1--194:17},
  year      = {2017},
}

@inproceedings{gerig2018_morphable_models,
  author    = {Thomas Gerig and
               Andreas Morel{-}Forster and
               Clemens Blumer and
               Bernhard Egger and
               Marcel L{\"{u}}thi and
               Sandro Sch{\"{o}}nborn and
               Thomas Vetter},
  title     = {Morphable Face Models - An Open Framework},
  booktitle = {Conference on Automatic Face {\&} Gesture Recognition},
  pages     = {75--82},
  publisher = IEEECS,
  year      = {2018},
}

@article{feng2021_deca,
  author    = {Yao Feng and Haiwen Feng and Michael J. Black and Timo Bolkart},
  title     = {Learning an animatable detailed 3D face model from in-the-wild images},
  journal   = TOG,
  volume    = {40},
  number    = {4},
  pages     = {88:1--88:13},
  year      = {2021}
}

@inproceedings{mallikarjun2021_learning-complete,
  author    = {Mallikarjun B.R. and
               Ayush Tewari and
               Hans{-}Peter Seidel and
               Mohamed Elgharib and
               Christian Theobalt},
  title     = {Learning Complete 3D Morphable Face Models From Images and Videos},
  booktitle = CVPR,
  pages     = {3361--3371},
  publisher = CVFIEEE,
  year      = {2021},
}

@article{mueller2022_instant-ngp,
  author    = {Thomas M{\"{u}}ller and
               Alex Evans and
               Christoph Schied and
               Alexander Keller},
  title     = {Instant neural graphics primitives with a multiresolution hash encoding},
  journal   = TOG,
  volume    = {41},
  number    = {4},
  pages     = {102:1--102:15},
  year      = {2022},
}

@inproceedings{fridovich2022_plenoxels,
  author    = {Sara Fridovich{-}Keil and
               Alex Yu and
               Matthew Tancik and
               Qinhong Chen and
               Benjamin Recht and
               Angjoo Kanazawa},
  title     = {Plenoxels: Radiance Fields without Neural Networks},
  booktitle = CVPR,
  pages     = {5491--5500},
  publisher = IEEE,
  year      = {2022},
}

@article{mildenhall2022_nerf,
    author    = {Ben Mildenhall and Pratul P. Srinivasan and Matthew Tancik and
                 Jonathan T. Barron and Ravi Ramamoorthi and Ren Ng},
    title     = {NeRF: representing scenes as neural radiance fields for view synthesis},
    journal   = CACM,
    volume    = {65},
    number    = {1},
    pages     = {99--106},
    year      = {2022}
}
@inproceedings{park2019_deepsdf,
  author    = {Jeong Joon Park and
               Peter Florence and
               Julian Straub and
               Richard A. Newcombe and
               Steven Lovegrove},
  title     = {DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation},
  booktitle = CVPR,
  pages     = {165--174},
  publisher = CVFIEEE,
  year      = {2019},
}

@inproceedings{takikawa2021_nglod,
  author    = {Towaki Takikawa and
               Joey Litalien and
               Kangxue Yin and
               Karsten Kreis and
               Charles T. Loop and
               Derek Nowrouzezahrai and
               Alec Jacobson and
               Morgan McGuire and
               Sanja Fidler},
  title     = {Neural Geometric Level of Detail: Real-Time Rendering With Implicit
               3D Shapes},
  booktitle = CVPR,
  pages     = {11358--11367},
  publisher = CVFIEEE,
  year      = {2021},
}
@inproceedings{yu2021_plenoctrees,
  author    = {Alex Yu and
               Ruilong Li and
               Matthew Tancik and
               Hao Li and
               Ren Ng and
               Angjoo Kanazawa},
  title     = {PlenOctrees for Real-time Rendering of Neural Radiance Fields},
  booktitle = ICCV,
  pages     = {5732--5741},
  publisher = IEEE,
  year      = {2021},
}

@inproceedings{chan2022_efficient,
  author    = {Eric R. Chan and
               Connor Z. Lin and
               Matthew A. Chan and
               Koki Nagano and
               Boxiao Pan and
               Shalini De Mello and
               Orazio Gallo and
               Leonidas J. Guibas and
               Jonathan Tremblay and
               Sameh Khamis and
               Tero Karras and
               Gordon Wetzstein},
  title     = {Efficient Geometry-aware 3D Generative Adversarial Networks},
  booktitle = CVPR,
  pages     = {16102--16112},
  publisher = IEEE,
  year      = {2022},
}

@inproceedings{chan2021_pigan,
  author    = {Eric R. Chan and Marco Monteiro and Petr Kellnhofer and
               Jiajun Wu and Gordon Wetzstein},
  title     = {Pi-GAN: Periodic Implicit Generative Adversarial Networks for 3D-Aware
               Image Synthesis},
  booktitle = CVPR,
  pages     = {5799--5809},
  publisher = CVFIEEE,
  year      = {2021}
}

@inproceedings{deng2022_gram,
  author    = {Yu Deng and
               Jiaolong Yang and
               Jianfeng Xiang and
               Xin Tong},
  title     = {{GRAM:} Generative Radiance Manifolds for 3D-Aware Image Generation},
  booktitle = CVPR,
  pages     = {10663--10673},
  publisher = IEEE,
  year      = {2022},
}

@inproceedings{park2021_nerfies,
  author    = {Keunhong Park and Utkarsh Sinha and Jonathan T. Barron and Sofien Bouaziz and
               Dan B. Goldman and Steven M. Seitz and Ricardo Martin{-}Brualla},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  booktitle = ICCV,
  pages     = {5845--5854},
  publisher = IEEE,
  year      = {2021}
}

@article{park2021_hypernerf,
    author    = {Keunhong Park and Utkarsh Sinha and Peter Hedman and Jonathan T. Barron and
                 Sofien Bouaziz and Dan B. Goldman and Ricardo Martin{-}Brualla and
                 Steven M. Seitz},
  title     = {HyperNeRF: a higher-dimensional representation for topologically varying
               neural radiance fields},
  journal   = TOG,
  volume    = {40},
  number    = {6},
  pages     = {238:1--238:12},
  year      = {2021}
}

@inproceedings{gu2022_stylenerf,
    author    = {Jiatao Gu and Lingjie Liu and Peng Wang and Christian Theobalt},
    title     = {StyleNeRF: {A} Style-based 3D Aware Generator for High-resolution
                 Image Synthesis},
    booktitle = ICLR,
    publisher = {OpenReview.net},
    year      = {2022}
}

@inproceedings{or-el2022_stylesdf,
    author    = {Roy Or{-}El and Xuan Luo and Mengyi Shan and Eli Shechtman and
                 Jeong Joon Park and Ira Kemelmacher{-}Shlizerman},
    title     = {StyleSDF: High-Resolution 3D-Consistent Image and Geometry Generation},
    booktitle = CVPR,
    pages     = {13493--13503},
    publisher = IEEE,
    year      = {2022}
}

@inproceedings{ramon2021_h3dnet,
    author    = {Eduard Ramon and Gil Triginer and Janna Escur and Albert Pumarola and
                 Jaime Garcia Giraldez and Xavier Gir{\'{o}}{-}i{-}Nieto and Francesc Moreno{-}Noguer},
    title     = {H3D-Net: Few-Shot High-Fidelity 3D Head Reconstruction},
    booktitle = ICCV,
    pages     = {5600--5609},
    publisher = IEEE,
    year      = {2021}
}

@inproceedings{chan2022_efficient-geom-aware,
    author    = {Eric R. Chan and Connor Z. Lin and Matthew A. Chan and Koki Nagano and
                 Boxiao Pan and Shalini De Mello and Orazio Gallo and Leonidas J. Guibas and
                 Jonathan Tremblay and Sameh Khamis and Tero Karras and Gordon Wetzstein},
  title     = {Efficient Geometry-aware 3D Generative Adversarial Networks},
  booktitle = CVPR,
  pages     = {16102--16112},
  publisher = IEEE,
  year      = {2022}
}

@inproceedings{li2022_neural-3d-video,
    author    = {Tianye Li and Mira Slavcheva and Michael Zollh{\"{o}}fer and
                 Simon Green and Christoph Lassner and Changil Kim and Tanner Schmidt and
                 Steven Lovegrove and Michael Goesele and Richard A. Newcombe and
                 Zhaoyang Lv},
    title     = {Neural 3D Video Synthesis from Multi-view Video},
    booktitle = CVPR,
    pages     = {5511--5521},
    publisher = IEEE,
    year      = {2022}
}

@inproceedings{li2021_neural-scene,
  author    = {Zhengqi Li and
               Simon Niklaus and
               Noah Snavely and
               Oliver Wang},
  title     = {Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic
               Scenes},
  booktitle = CVPR,
  pages     = {6498--6508},
  publisher = CVFIEEE,
  year      = {2021},
}

@inproceedings{liu2020_nsvf,
  author    = {Lingjie Liu and
               Jiatao Gu and
               Kyaw Zaw Lin and
               Tat{-}Seng Chua and
               Christian Theobalt},
  title     = {Neural Sparse Voxel Fields},
  booktitle = NIPS,
  year      = {2020},
}

@article{sun2022_controllable,
  author    = {Keqiang Sun and Shangzhe Wu and Zhaoyang Huang and Ning Zhang and
               Quan Wang and Hongsheng Li},
  title     = {Controllable 3D Face Synthesis with Conditional Generative Occupancy
               Fields},
  journal   = CORR,
  volume    = {abs/2206.08361},
  year      = {2022},
  eprinttype = ARXIV
}

@inproceedings{hong2021_headnerf,
  author    = {Yang Hong and
               Bo Peng and
               Haiyao Xiao and
               Ligang Liu and
               Juyong Zhang},
  title     = {HeadNeRF: {A} Realtime NeRF-based Parametric Head Model},
  booktitle = CVPR,
  pages     = {20342--20352},
  publisher = IEEE,
  year      = {2022},
}

@inproceedings{athar2022rignerf,
  author    = {ShahRukh Athar and
               Zexiang Xu and
               Kalyan Sunkavalli and
               Eli Shechtman and
               Zhixin Shu},
  title     = {RigNeRF: Fully Controllable Neural 3D Portraits},
  booktitle = CVPR,
  pages     = {20332--20341},
  publisher = IEEE,
  year      = {2022},
}

@InProceedings{gafni2021_dynamic-nerf,
 author    = {Gafni, Guy and Thies, Justus and Zollh{\"o}fer, Michael and Nie{\ss}ner, Matthias},
 title     = {Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction},
 booktitle = CVPR,
 pages     = {8649-8658},
 publisher = IEEE,
 year      = {2021}
}

@inproceedings{zheng2022imavatar,
  author    = {Yufeng Zheng and
               Victoria Fern{\'{a}}ndez Abrevaya and
               Marcel C. B{\"{u}}hler and
               Xu Chen and
               Michael J. Black and
               Otmar Hilliges},
  title     = {I {M} Avatar: Implicit Morphable Head Avatars from Videos},
  booktitle = CVPR,
  pages     = {13535--13545},
  publisher = IEEE,
  year      = {2022},
}

@inproceedings{grassal2022_neural-head,
  author    = {Philip{-}William Grassal and
               Malte Prinzler and
               Titus Leistner and
               Carsten Rother and
               Matthias Nie{\ss}ner and
               Justus Thies},
  title     = {Neural Head Avatars from Monocular {RGB} Videos},
  booktitle = CVPR,
  pages     = {18632--18643},
  publisher = IEEE,
  year      = {2022},
}


@article{gao2022_nerfblendshape,
  author    = {Xuan Gao and
               Chenglai Zhong and
               Jun Xiang and
               Yang Hong and
               Yudong Guo and
               Juyong Zhang},
  title     = {Reconstructing Personalized Semantic Facial NeRF Models from Monocular
               Video},
  journal   = TOG,
  volume    = {41},
  number    = {6},
  pages     = {200:1--200:12},
  year      = {2022},
}


@article{cao2022_authentic,
  author    = {Chen Cao and Tomas Simon and Jin Kyu Kim and Gabe Schwartz and Michael Zollh{\"{o}}fer and
               Shunsuke Saito and Stephen Lombardi and Shih{-}En Wei and Danielle Belko and
               Shoou{-}I Yu and Yaser Sheikh and Jason M. Saragih},
  title     = {Authentic volumetric avatars from a phone scan},
  journal   = TOG,
  volume    = {41},
  number    = {4},
  pages     = {163:1--163:19},
  year      = {2022}
}

@inproceedings{wang2022_morf,
  author    = {Daoye Wang and
               Prashanth Chandran and
               Gaspard Zoss and
               Derek Bradley and
               Paulo F. U. Gotardo},
  title     = {MoRF: Morphable Radiance Fields for Multiview Neural Head Modeling},
  booktitle = SIGGRAPH,
  pages     = {55:1--55:9},
  publisher = ACM,
  year      = {2022},
}

@inproceedings{ma2021_pixel-codec,
    author    = {Shugao Ma and Tomas Simon and Jason M. Saragih and Dawei Wang and
                 Yuecheng Li and Fernando De la Torre and Yaser Sheikh},
    title     = {Pixel Codec Avatars},
    booktitle = CVPR,
    pages     = {64--73},
    publisher = CVFIEEE,
    year      = {2021}
}
@article{lombardi2018_deep-appear,
    author    = {Stephen Lombardi and Jason M. Saragih and Tomas Simon and Yaser Sheikh},
    title     = {Deep appearance models for face rendering},
    journal   = TOG,
    volume    = {37},
    number    = {4},
    pages     = {68},
    year      = {2018}
}

@article{lombardi21_mvp,
  author    = {Stephen Lombardi and
               Tomas Simon and
               Gabriel Schwartz and
               Michael Zollh{\"{o}}fer and
               Yaser Sheikh and
               Jason M. Saragih},
  title     = {Mixture of volumetric primitives for efficient neural rendering},
  journal   = TOG,
  volume    = {40},
  number    = {4},
  pages     = {59:1--59:13},
  year      = {2021},
}

@article{lombardi2019_neural-volumes,
 author = {Lombardi, Stephen and Simon, Tomas and Saragih, Jason and Schwartz, Gabriel and Lehrmann, Andreas and Sheikh, Yaser},
 title = {Neural Volumes: Learning Dynamic Renderable Volumes from Images},
 journal = TOG,
 volume = {38},
 number = {4},
 year = {2019},
 pages = {65:1--65:14},
 publisher = {ACM},
}

@inproceedings{mihajlovic22_keypointnerf,
  author    = {Marko Mihajlovic and
               Aayush Bansal and
               Michael Zollh{\"{o}}fer and
               Siyu Tang and
               Shunsuke Saito},
  title     = {KeypointNeRF: Generalizing Image-Based Volumetric Avatars Using Relative
               Spatial Encoding of Keypoints},
  booktitle = ECCV,
  series    = LNCS,
  volume    = {13675},
  pages     = {179--197},
  publisher = {Springer},
  year      = {2022},
}

@inproceedings{raj21_pixel-aligned,
  author    = {Amit Raj and
               Michael Zollh{\"{o}}fer and
               Tomas Simon and
               Jason M. Saragih and
               Shunsuke Saito and
               James Hays and
               Stephen Lombardi},
  title     = {Pixel-Aligned Volumetric Avatars},
  booktitle = CVPR,
  pages     = {11733--11742},
  publisher = CVFIEEE,
  year      = {2021},
}

@inproceedings{wang2021_learning-crf,
  author    = {Ziyan Wang and
               Timur M. Bagautdinov and
               Stephen Lombardi and
               Tomas Simon and
               Jason M. Saragih and
               Jessica K. Hodgins and
               Michael Zollh{\"{o}}fer},
  title     = {Learning Compositional Radiance Fields of Dynamic Human Heads},
  booktitle = CVPR,
  pages     = {5704--5713},
  publisher = CVFIEEE,
  year      = {2021},
}

@inproceedings{li2022_tava,
  author    = {Ruilong Li and
               Julian Tanke and
               Minh Vo and
               Michael Zollh{\"{o}}fer and
               J{\"{u}}rgen Gall and
               Angjoo Kanazawa and
               Christoph Lassner},
  title     = {{TAVA:} Template-free Animatable Volumetric Actors},
  booktitle = ECCV,
  series    = LNCS,
  volume    = {13692},
  pages     = {419--436},
  publisher = {Springer},
  year      = {2022},
}

@inproceedings{teed2021_raft,
  author    = {Zachary Teed and Jia Deng},
  editor    = {Zhi{-}Hua Zhou},
  title     = {{RAFT:} Recurrent All-Pairs Field Transforms for Optical Flow (Extended
               Abstract)},
  booktitle = IJCAI,
  pages     = {4839--4843},
  publisher = {ijcai.org},
  year      = {2021},
}

@inproceedings{lin2021_back_mattv2,
  author    = {Shanchuan Lin and Andrey Ryabtsev and Soumyadip Sengupta and
               Brian L. Curless and Steven M. Seitz and Ira Kemelmacher{-}Shlizerman},
  title     = {Real-Time High-Resolution Background Matting},
  booktitle = CVPR,
  pages     = {8762--8771},
  publisher = CVFIEEE,
  year      = {2021},
}

@misc{metashape,
 author = {Metashape},
 year   = {2020},
 title  = {Agisoft Metashape (Version 1.8.4) (Software)},
 note   = {Retrieved from: \url{https://www.agisoft.com/downloads/installer/}}
}

@article{wang2004_image-quality,
    author    = {Zhou Wang and Alan C. Bovik and Hamid R. Sheikh and Eero P. Simoncelli},
    title     = {Image quality assessment: from error visibility to structural similarity},
    journal   = {{IEEE} Trans. Image Process.},
    volume    = {13},
    number    = {4},
    pages     = {600--612},
    year      = {2004}
}

@inproceedings{zhang2018_unreasonable-effectiveness,
    author    = {Richard Zhang and Phillip Isola and Alexei A. Efros and
                 Eli Shechtman and Oliver Wang},
    title     = {The Unreasonable Effectiveness of Deep Features as a Perceptual Metric},
    booktitle = CVPR,
    pages     = {586--595},
    publisher = CVFIEEE,
    year      = {2018}
}


@article{zhang2022_flnerf,
  author    = {Hao Zhang and
               Tianyuan Dai and
               Yu{-}Wing Tai and
               Chi{-}Keung Tang},
  title     = {FLNeRF: 3D Facial Landmarks Estimation in Neural Radiance Fields},
  journal   = CORR,
  volume    = {abs/2211.11202},
  year      = {2022},
  eprinttype = ARXIV,
}

@article{bai2022_high-fidelity,
  author    = {Yunpeng Bai and
               Yanbo Fan and
               Xuan Wang and
               Yong Zhang and
               Jingxiang Sun and
               Chun Yuan and
               Ying Shan},
  title     = {High-fidelity Facial Avatar Reconstruction from Monocular Video with
               Generative Priors},
  journal   = CORR,
  volume    = {abs/2211.15064},
  year      = {2022},
  eprinttype = ARXIV,
}

@article{abdal2023_3davatargan,
  author    = {Rameen Abdal and
               Hsin{-}Ying Lee and
               Peihao Zhu and
               Menglei Chai and
               Aliaksandr Siarohin and
               Peter Wonka and
               Sergey Tulyakov},
  title     = {3DAvatarGAN: Bridging Domains for Personalized Editable Avatars},
  journal   = CORR,
  volume    = {abs/2301.02700},
  year      = {2023},
  eprinttype = ARXIV,
}

@misc{tang2022_torch-ngp,
    Author = {Jiaxiang Tang},
    Year = {2022},
    Note = {https://github.com/ashawkey/torch-ngp},
    Title = {Torch-ngp: a PyTorch implementation of instant-ngp}
}

@article{wang2022-neus2,
  author    = {Yiming Wang and
               Qin Han and
               Marc Habermann and
               Kostas Daniilidis and
               Christian Theobalt and
               Lingjie Liu},
  title     = {NeuS2: Fast Learning of Neural Implicit Surfaces for Multi-view Reconstruction},
  journal   = CORR,
  volume    = {abs/2212.05231},
  year      = {2022},
  eprinttype = ARXIV,
}

@article{Beeler11,
author = {Beeler, Thabo and Hahn, Fabian and Bradley, Derek and Bickel, Bernd and Beardsley, Paul and Gotsman, Craig and Sumner, Robert W. and Gross, Markus},
title = {High-Quality Passive Facial Performance Capture Using Anchor Frames},
year = {2011},
issue_date = {July 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/2010324.1964970},
doi = {10.1145/2010324.1964970},
abstract = {We present a new technique for passive and markerless facial performance capture based on anchor frames. Our method starts with high resolution per-frame geometry acquisition using state-of-the-art stereo reconstruction, and proceeds to establish a single triangle mesh that is propagated through the entire performance. Leveraging the fact that facial performances often contain repetitive subsequences, we identify anchor frames as those which contain similar facial expressions to a manually chosen reference expression. Anchor frames are automatically computed over one or even multiple performances. We introduce a robust image-space tracking method that computes pixel matches directly from the reference frame to all anchor frames, and thereby to the remaining frames in the sequence via sequential matching. This allows us to propagate one reconstructed frame to an entire sequence in parallel, in contrast to previous sequential methods. Our anchored reconstruction approach also limits tracker drift and robustly handles occlusions and motion blur. The parallel tracking and mesh propagation offer low computation times. Our technique will even automatically match anchor frames across different sequences captured on different occasions, propagating a single mesh to all performances.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {75},
numpages = {10},
keywords = {motion capture, facial performance capture, space-time geometry reconstruction}
}

@article{kasten2021layered,
  title={Layered neural atlases for consistent video editing},
  author={Kasten, Yoni and Ofri, Dolev and Wang, Oliver and Dekel, Tali},
  journal={ACM Transactions on Graphics (TOG)},
  volume={40},
  number={6},
  pages={1--12},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@InProceedings{Parkhi15,
  author       = "Omkar M. Parkhi and Andrea Vedaldi and Andrew Zisserman",
  title        = "Deep Face Recognition",
  booktitle    = "British Machine Vision Conference",
  year         = "2015",
}


@misc{Xiang22GRAM-HD,
  doi = {10.48550/ARXIV.2206.07255},
  url = {https://arxiv.org/abs/2206.07255},
  author = {Xiang, Jianfeng and Yang, Jiaolong and Deng, Yu and Tong, Xin},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {GRAM-HD: 3D-Consistent Image Generation at High Resolution with Generative Radiance Manifolds},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
