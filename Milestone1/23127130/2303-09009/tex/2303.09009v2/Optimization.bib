%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Long Chen at 2024-11-30 15:18:21 -0800 


%% Saved with string encoding Unicode (UTF-8) 



@article{young1954iterative,
	author = {Young, David},
	date-added = {2024-02-16 13:44:42 -0800},
	date-modified = {2024-02-16 13:44:42 -0800},
	journal = {Transactions of the American Mathematical Society},
	number = {1},
	pages = {92--111},
	title = {Iterative methods for solving partial difference equations of elliptic type},
	volume = {76},
	year = {1954}}

@article{AdlerEmersonMacLachlanManteuffel2016,
	abstract = {This paper compares the performance of penalty and Lagrange multiplier approaches for the necessary unit-length constraint in the computation of liquid crystal equilibrium configurations. Building on previous work in [SIAM J. Sci. Comput., 37 (2015), pp. S157--S176; SIAM J. Numer. Anal., 53 (2015), pp. 2226--2254], the penalty method is derived and well-posedness of the linearizations within the nonlinear iteration is discussed. In addition, the paper considers the effects of tailored trust-region methods in the context of finite-element discretizations and nested iteration for both formulations. Such methods are aimed at increasing the efficiency and robustness of each algorithm's nonlinear iterations. Three representative elastic equilibrium problems are considered to examine each method's performance. The first two configurations have analytical expressions for their exact solutions and, therefore, convergence to the true solution is considered. The third problem considers complicated boundary conditions, relevant in ongoing research, simulating surface nano-patterning. Finally, a novel multigrid scheme is introduced and tested for electrically and flexoelectrically coupled models to establish scalability for highly complicated applications. The Lagrange multiplier method is found to outperform the penalty method in a number of measures, the developed trust regions are shown to improve robustness, and nested iteration proves highly effective at reducing computational costs.},
	annotation = {00014},
	author = {Adler, J. and Emerson, D. and MacLachlan, S. and Manteuffel, T.},
	doi = {10.1137/141001846},
	file = {/Users/longchen1/Zotero/storage/62AVHHX4/Adler et al. - 2016 - Constrained Optimization for Liquid Crystal Equili.pdf;/Users/longchen1/Zotero/storage/5UEKSV2N/141001846.html},
	issn = {1064-8275},
	journal = {SIAM Journal on Scientific Computing},
	month = jan,
	number = {1},
	pages = {B50-B76},
	title = {Constrained {{Optimization}} for {{Liquid Crystal Equilibria}}},
	volume = {38},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.1137/141001846}}

@article{AlvarezAttouchBolteRedont2002,
	annotation = {00100},
	author = {Alvarez, F and Attouch, H and Bolte, J and Redont, P},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/ODE/Alvarez et al. - 2002 - A second-order gradient-like dissipative dynamical.pdf},
	journal = {J. Math. Pures Appl.},
	langid = {english},
	pages = {33},
	title = {A Second-Order Gradient-like Dissipative Dynamical System with {{Hessian-driven}} Damping. {{Application}} to Optimization and Mechanics},
	year = {2002}}

@article{anStochasticModifiedEquations2020,
	abstract = {We propose a stochastic modified equations (SME) for modeling the asynchronous stochastic gradient descent (ASGD) algorithms. The resulting SME of Langevin type extracts more information about the ASGD dynamics and elucidates the relationship between different types of stochastic gradient algorithms. We show the convergence of ASGD to the SME in the continuous time limit, as well as the SME's precise prediction to the trajectories of ASGD with various forcing terms. As an application of the SME, we propose an optimal mini-batching strategy for ASGD via solving the optimal control problem of the associated SME.},
	annotation = {ZSCC: 0000009},
	archiveprefix = {arXiv},
	author = {An, Jing and Lu, Jianfeng and Ying, Lexing},
	doi = {10.1093/imaiai/iaz030},
	eprint = {1805.08244},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/An et al. - 2020 - Stochastic modified equations for the asynchronous.pdf},
	issn = {2049-8764, 2049-8772},
	journal = {Information and Inference: A Journal of the IMA},
	keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
	langid = {english},
	month = dec,
	number = {4},
	pages = {851--873},
	title = {Stochastic Modified Equations for the Asynchronous Stochastic Gradient Descent},
	volume = {9},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1093/imaiai/iaz030}}

@article{ApidopoulosAujolDossal,
	annotation = {00007},
	author = {Apidopoulos, Vassilis and Aujol, Jean-Fran{\c c}ois and Dossal, Charles},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/Research/ode2opt/references/Apidopoulos et al. - The Differential Inclusion Modeling FISTA Algorith.pdf},
	langid = {english},
	pages = {21},
	title = {The {{Differential Inclusion Modeling FISTA Algorithm}} and {{Optimality}} of {{Convergence Rate}} in the {{Case}} b}}

@article{AttouchChbaniFadiliRiahi2019,
	abstract = {In a Hilbert space setting, for convex optimization, we analyze the convergence rate of a class of first-order algorithms involving inertial features. They can be interpreted as discrete time versions of inertial dynamics involving both viscous and Hessian-driven dampings. The geometrical damping driven by the Hessian intervenes in the dynamics in the form r2f (x(t))x\textperiodcentered{} (t). By treating this term as the time derivative of rf (x(t)), this gives, in discretized form, first-order algorithms in time and space. In addition to the convergence properties attached to Nesterov-type accelerated gradient methods, the algorithms thus obtained are new and show a rapid convergence towards zero of the gradients. On the basis of a regularization technique using the Moreau envelope, we extend these methods to non-smooth convex functions with extended real values. The introduction of time scale factors makes it possible to further accelerate these algorithms. We also report numerical results on structured problems to support our theoretical findings.},
	annotation = {00000},
	author = {Attouch, Hedy and Chbani, Zaki and Fadili, Jalal and Riahi, Hassan},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/Attouch/Attouch et al. - 2019 - First-order optimization algorithms via inertial s.pdf;/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/ODE/Attouch et al. - FIRST-ORDER OPTIMIZATION ALGORITHMS VIA INERTIAL S.pdf},
	ids = {AttouchChbaniFadiliRiahi2019a},
	journal = {ArXiv},
	keywords = {37N40; 46N10; 49M30; 65B99; 65K05; 65K10; 90B50; 90C25,Mathematics - Optimization and Control},
	langid = {english},
	pages = {29},
	title = {First-{{Order Optimization Algorithms Via Inertial Systems With Hessian Driven Damping}}},
	year = {2019}}

@article{AttouchChbaniRiahi2017,
	abstract = {In a Hilbert space setting \$\textbackslash mathcal H\$, given \$\textbackslash Phi: \textbackslash mathcal H \textbackslash to \textbackslash mathbb R\$ a convex continuously differentiable function, and \$\textbackslash alpha\$ a positive parameter, we consider the inertial system with Asymptotic Vanishing Damping \textbackslash begin\{equation*\} \textbackslash mbox\{(AVD)\}\_\{\textbackslash alpha\} \textbackslash quad \textbackslash quad \textbackslash ddot\{x\}(t) + \textbackslash frac\{\textbackslash alpha\}\{t\} \textbackslash dot\{x\}(t) + \textbackslash nabla \textbackslash Phi (x(t)) =0. \textbackslash end\{equation*\} Depending on the value of \$ \textbackslash alpha \$ with respect to 3, we give a complete picture of the convergence properties as \$t \textbackslash to + \textbackslash infty\$ of the trajectories generated by \$\textbackslash mbox\{(AVD)\}\_\{\textbackslash alpha\}\$, as well as iterations of the corresponding algorithms. Our main result concerns the subcritical case \$\textbackslash alpha \textbackslash leq 3\$, where we show that \$\textbackslash Phi (x(t))-\textbackslash min \textbackslash Phi = \textbackslash mathcal O (t\^\{-\textbackslash frac\{2\}\{3\}\textbackslash alpha\})\$. Then we examine the convergence of trajectories to optimal solutions. As a new result, in the one-dimensional framework, for the critical value \$\textbackslash alpha = 3 \$, we prove the convergence of the trajectories without any restrictive hypothesis on the convex function \$\textbackslash Phi \$. In the second part of this paper, we study the convergence properties of the associated forward-backward inertial algorithms. They aim to solve structured convex minimization problems of the form \$\textbackslash min \textbackslash left\textbackslash lbrace \textbackslash Theta:= \textbackslash Phi + \textbackslash Psi \textbackslash right\textbackslash rbrace\$, with \$\textbackslash Phi\$ smooth and \$\textbackslash Psi\$ nonsmooth. The continuous dynamics serves as a guideline for this study. We obtain a similar rate of convergence for the sequence of iterates \$(x\_k)\$: for \$\textbackslash alpha \textbackslash leq 3\$ we have \$\textbackslash Theta (x\_k)-\textbackslash min \textbackslash Theta = \textbackslash mathcal O (k\^\{-p\})\$ for all \$p {$<\backslash$}frac\{2\textbackslash alpha\}\{3\}\$ , and for \$\textbackslash alpha {$>$} 3\$ \textbackslash{} \$\textbackslash Theta (x\_k)-\textbackslash min \textbackslash Theta = o (k\^\{-2\})\$ . We conclude this study by showing that the results are robust with respect to external perturbations.},
	annotation = {00000},
	archiveprefix = {arXiv},
	author = {Attouch, Hedy and Chbani, Zaki and Riahi, Hassan},
	eprint = {1706.05671},
	eprinttype = {arxiv},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/Acceleration/Attouch et al. - 2017 - Rate of convergence of the Nesterov accelerated gr.pdf},
	journal = {arXiv:1706.05671 [math]},
	keywords = {49M37; 65K05; 90C25,Mathematics - Optimization and Control},
	langid = {english},
	month = jun,
	primaryclass = {math},
	title = {Rate of Convergence of the {{Nesterov}} Accelerated Gradient Method in the Subcritical Case \$\textbackslash alpha \textbackslash leq 3\$},
	year = {2017}}

@article{AttouchChbaniRiahi2019,
	abstract = {In a Hilbert setting, we consider a class of inertial proximal algorithms for nonsmooth convex optimization, with fast convergence properties. They can be obtained by time discretization of inertial gradient dynamics which have been rescaled in time. We will rely specifically on the recent developement linking Nesterov's accelerated method with vanishing damping inertial dynamics. Doing so, we somehow improve and obtain a dynamical interpretation of the seminal papers of Gu\textasciidieresis ler on the convergence rate of the proximal methods for convex optimization.},
	annotation = {00002},
	author = {Attouch, Hedy and Chbani, Zaki and Riahi, Hassan},
	doi = {10.1137/18M1230207},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/Acceleration/Attouch et al. - 2019 - Fast Proximal Methods via Time Scaling of Damped I.pdf},
	issn = {1052-6234, 1095-7189},
	journal = {SIAM Journal on Optimization},
	langid = {english},
	month = jan,
	number = {3},
	pages = {2227--2256},
	title = {Fast {{Proximal Methods}} via {{Time Scaling}} of {{Damped Inertial Dynamics}}},
	volume = {29},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1137/18M1230207}}

@article{AttouchGoudouRedont2000,
	abstract = {Let H be a real Hilbert space and {$\Phi$} : H \textrightarrow{} R a continuously differentiable function, whose gradient is Lipschitz continuous on bounded sets. We study the nonlinear dissipative dynamical system: x\textasciidieresis (t) + {$\lambda$}x\textperiodcentered{} (t) + {$\nabla\Phi$}(x(t)) = 0, {$\lambda$} {$>$} 0, plus Cauchy data, mainly in view of the unconstrained minimization of the function {$\Phi$}. New results concerning the convergence of a solution to a critical point are given in various situations, including when {$\Phi$} is convex (possibly with multiple minima) or is a Morse function (the critical point being then generically a local minimum); a counterexample shows that, without peculiar assumptions, a trajectory may not converge. By following the trajectories, we obtain a method for exploring local minima of {$\Phi$}. A singular perturbation analysis links our results with those concerning gradient systems.},
	annotation = {00178},
	author = {Attouch, H. and Goudou, X. and Redont, P.},
	doi = {10.1142/S0219199700000025},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/Acceleration/Attouch et al. - 2000 - THE HEAVY BALL WITH FRICTION METHOD, I. THE CONTIN.pdf},
	issn = {0219-1997, 1793-6683},
	journal = {Communications in Contemporary Mathematics},
	langid = {english},
	month = feb,
	number = {01},
	pages = {1--34},
	shorttitle = {{{THE HEAVY BALL WITH FRICTION METHOD}}, {{I}}. {{THE CONTINUOUS DYNAMICAL SYSTEM}}},
	title = {The {{Heavy Ball With Friction Method}}, {{I}}. {{The Continuous Dynamical System}}: {{Global Exploration Of The Local Minima Of A Real-Valued Function By Asymptotic Analysis Of A Dissipative Dynamical System}}},
	volume = {02},
	year = {2000},
	bdsk-url-1 = {https://doi.org/10.1142/S0219199700000025}}

@article{AttouchMaingeRedont2012,
	abstract = {We consider the second-order differential system with Hessian-driven damping u\textasciidieresis{} + {$\alpha$}u\textperiodcentered{} + {$\beta$} {$\nabla$}2{$\Phi$}(u)u\textperiodcentered{} + {$\nabla\Phi$}(u) + {$\nabla\Psi$}(u) = 0, where H is a real Hilbert space, {$\Phi$},{$\Psi$} : H \textrightarrow{} R are scalar potentials, and {$\alpha$},{$\beta$} are positive parameters. An interesting property of this system is that, after introduction of an auxiliary variable y , it can be equivalently written as a firstorder system involving only the time derivatives u\textperiodcentered{} , y\textperiodcentered{} and the gradient operators {$\nabla\Phi$} , {$\nabla\Psi$} . This allows to extend our analysis to the case of a convex lower semicontinuous function {$\Phi$} : H \textrightarrow{} R {$\cup$} \{+{$\infty\rbrace$} , and so to introduce constraints in our model. When {$\Phi$} = {$\delta$}K is the indicator function of a closed convex set K {$\subseteq$} H , the subdifferential operator {$\partial$} {$\Phi$} takes account of the contact forces, while {$\nabla\Psi$} takes account of the driving forces. In this setting, by playing with the geometrical damping parameter {$\beta$} , we can describe nonelastic shock laws with restitution coefficient. Taking advantage of the infinite dimensional framework, we introduce a nonlinear hyperbolic PDE describing a damped oscillating system with obstacle. The first-order system is dissipative; each trajectory weakly converges to a minimizer of {$\Phi$} + {$\Psi$} , provided that {$\Phi$} and {$\Phi$} + {$\Psi$} are convex functions. Exponential stabilization is obtained under strong convexity assumptions.\vphantom\}},
	annotation = {00018},
	author = {Attouch, Hedy and Maing{\'e}, Paul-Emile and Redont, Patrick},
	doi = {10.7153/dea-04-04},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/Attouch/Attouch et al. - 2012 - A second-order differential system with Hessian-dr.pdf},
	issn = {1847-120X},
	journal = {Differential Equations \& Applications},
	langid = {english},
	number = {1},
	pages = {27--65},
	title = {A Second-Order Differential System with {{Hessian-driven}} Damping; {{Application}} to Non-Elastic Shock Laws},
	volume = {4},
	year = {2012},
	bdsk-url-1 = {https://doi.org/10.7153/dea-04-04}}

@article{BabanezhadLaradjiShafaeiSchmidt,
	abstract = {We consider the stochastic optimization of finite sums over a Riemannian manifold where the functions are smooth and convex. We present MASAGA, an extension of the stochastic average gradient variant SAGA on Riemannian manifolds. SAGA is a variance-reduction technique that typically outperforms methods that rely on expensive full-gradient calculations, such as the stochastic variance-reduced gradient method. We show that MASAGA achieves a linear convergence rate with uniform sampling, and we further show that MASAGA achieves a faster convergence rate with non-uniform sampling. Our experiments show that MASAGA is faster than the recent Riemannian stochastic gradient descent algorithm for the classic problem of finding the leading eigenvector corresponding to the maximum eigenvalue.},
	author = {Babanezhad, Reza and Laradji, Issam H and Shafaei, Alireza and Schmidt, Mark},
	file = {/Users/longchen1/Zotero/storage/NU7IGLL6/Babanezhad et al. - MASAGA A Linearly-Convergent Stochastic First-Ord.pdf},
	langid = {english},
	pages = {16},
	title = {{{MASAGA}}: {{A Linearly-Convergent Stochastic First-Order Method}} for {{Optimization}} on {{Manifolds}}}}

@article{BadithelaSeiler,
	abstract = {In this paper, we analyze the convergence rate of the Heavy-ball algorithm applied to optimize a class of continuously differentiable functions. The analysis is performed with the Heavy-ball tuned to achieve the best convergence rate on the sub-class of quadratic functions. We review recent work to characterize convergence rate upper bounds for optimization algorithms using integral quadratic constraints (IQC). This yields a linear matrix inequality (LMI) condition which is typically solved numerically to obtain convergence rate bounds. We construct an analytical solution for this LMI condition using a specific ``weighted off-by-one'' IQC. We also construct a specific objective function such that the Heavy-ball algorithm enters a limit cycle. These results demonstrate that IQC condition is tight for the analysis of the tuned Heavy-ball, i.e. it yields the exact condition ratio that separates global convergence from non-global convergence for the algorithm.},
	annotation = {00000},
	author = {Badithela, Apurva and Seiler, Peter},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/Acceleration/Badithela and Seiler - Analysis of the Heavy-ball Algorithm using Integra.pdf},
	langid = {english},
	pages = {5},
	title = {Analysis of the {{Heavy-ball Algorithm}} Using {{Integral Quadratic Constraints}}}}

@article{BartaChillFasangova2012,
	abstract = {We explain and prove the statement from the title. This allows us to formulate a new type of gradient inequality and to obtain a new stabilization result for gradient-like ordinary differential equations.},
	annotation = {00028},
	author = {B{\'a}rta, Tom{\'a}{\v s} and Chill, Ralph and Fa{\v s}angov{\'a}, Eva},
	doi = {10.1007/s00605-011-0322-4},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/ODE/B{\'a}rta et al. - 2012 - Every ordinary differential equation with a strict.pdf},
	issn = {0026-9255, 1436-5081},
	journal = {Monatshefte f\"ur Mathematik},
	langid = {english},
	month = apr,
	number = {1},
	pages = {57--72},
	title = {Every Ordinary Differential Equation with a Strict {{Lyapunov}} Function Is a Gradient System},
	volume = {166},
	year = {2012},
	bdsk-url-1 = {https://doi.org/10.1007/s00605-011-0322-4}}

@article{BeckTetruashvili2013,
	abstract = {In this paper we study smooth convex programming problems where the decision variables vector is split into several blocks of variables. We analyze the block coordinate gradient projection method in which each iteration consists of performing a gradient projection step with respect to a certain block taken in a cyclic order. Global sublinear rate of convergence of this method is established and it is shown that it can be accelerated when the problem is unconstrained. In the unconstrained setting we also prove a sublinear rate of convergence result for the so-called alternating minimization method when the number of blocks is two. When the objective function is also assumed to be strongly convex, linear rate of convergence is established.},
	author = {Beck, Amir and Tetruashvili, Luba},
	doi = {10.1137/120887679},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/BlockCoordinateDescent/Beck and Tetruashvili - 2013 - On the Convergence of Block Coordinate Descent Typ.pdf},
	issn = {1052-6234, 1095-7189},
	journal = {SIAM Journal on Optimization},
	langid = {english},
	month = jan,
	number = {4},
	pages = {2037--2060},
	title = {On the {{Convergence}} of {{Block Coordinate Descent Type Methods}}},
	volume = {23},
	year = {2013},
	bdsk-url-1 = {https://doi.org/10.1137/120887679}}

@article{BetancourtJordanWilson2018,
	abstract = {Accelerated gradient methods have had significant impact in machine learning\textemdash in particular the theoretical side of machine learning\textemdash due to their ability to achieve oracle lower bounds. But their heuristic construction has hindered their full integration into the practical machine-learning algorithmic toolbox, and has limited their scope. In this paper we build on recent work which casts acceleration as a phenomenon best explained in continuous time, and we augment that picture by providing a systematic methodology for converting continuous-time dynamics into discrete-time algorithms while retaining oracle rates. Our framework is based on ideas from Hamiltonian dynamical systems and symplectic integration. These ideas have had major impact in many areas in applied mathematics, but have not yet been seen to have a relationship with optimization.},
	annotation = {00030},
	archiveprefix = {arXiv},
	author = {Betancourt, Michael and Jordan, Michael I. and Wilson, Ashia C.},
	eprint = {1802.03653},
	eprinttype = {arxiv},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/ODE/Betancourt et al. - 2018 - On Symplectic Optimization.pdf},
	journal = {arXiv:1802.03653 [stat]},
	keywords = {Statistics - Computation},
	langid = {english},
	month = feb,
	primaryclass = {stat},
	title = {On {{Symplectic Optimization}}},
	year = {2018}}

@article{bhandariAcceleratedRandomizedCoordinate2018,
	abstract = {We propose accelerated randomized coordinate descent algorithms for stochastic optimization and online learning. Our algorithms have significantly less per-iteration complexity than the known accelerated gradient algorithms. The proposed algorithms for online learning have better regret performance than the known randomized online coordinate descent algorithms. Furthermore, the proposed algorithms for stochastic optimization exhibit as good convergence rates as the best known randomized coordinate descent algorithms. We also show simulation results to demonstrate performance of the proposed algorithms.},
	archiveprefix = {arXiv},
	author = {Bhandari, Akshita and Singh, Chandramani},
	eprint = {1806.01600},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Bhandari and Singh - 2018 - Accelerated Randomized Coordinate Descent Algorith.pdf},
	journal = {arXiv:1806.01600 [cs, stat]},
	keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
	langid = {english},
	month = jul,
	primaryclass = {cs, stat},
	title = {Accelerated {{Randomized Coordinate Descent Algorithms}} for {{Stochastic Optimization}} and {{Online Learning}}},
	year = {2018}}

@article{bitterlichProximalAlternatingMinimization2019,
	abstract = {The Alternating Minimization Algorithm has been proposed by Paul Tseng to solve convex programming problems with two-block separable linear constraints and objectives, whereby (at least) one of the components of the latter is assumed to be strongly convex. The fact that one of the subproblems to be solved within the iteration process of this method does not usually correspond to the calculation of a proximal operator through a closed formula affects the implementability of the algorithm. In this paper, we allow in each block of the objective a further smooth convex function and propose a proximal version of the algorithm, which is achieved by equipping the algorithm with proximal terms induced by variable metrics. For suitable choices of the latter, the solving of the two subproblems in the iterative scheme can be reduced to the computation of proximal operators. We investigate the convergence of the proposed algorithm in a real Hilbert space setting and illustrate its numerical performances on two applications in image processing and machine learning.},
	annotation = {ZSCC: 0000006},
	author = {Bitterlich, Sandy and Bo{\c t}, Radu Ioan and Csetnek, Ern{\"o} Robert and Wanka, Gert},
	doi = {10.1007/s10957-018-01454-y},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/ADMM/Bitterlich et al. - 2019 - The Proximal Alternating Minimization Algorithm fo.pdf},
	issn = {0022-3239, 1573-2878},
	journal = {Journal of Optimization Theory and Applications},
	langid = {english},
	month = jul,
	number = {1},
	pages = {110--132},
	title = {The {{Proximal Alternating Minimization Algorithm}} for {{Two-Block Separable Convex Optimization Problems}} with {{Linear Constraints}}},
	volume = {182},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1007/s10957-018-01454-y}}

@article{BollapragadaScieurdAspremont2018,
	abstract = {We describe a convergence acceleration scheme for multistep optimization algorithms. The extrapolated solution is written as a nonlinear average of the iterates produced by the original optimization algorithm. Our scheme does not need the underlying fixed-point operator to be symmetric, hence handles e.g. algorithms with momentum terms such as Nesterov's accelerated method, or primal-dual methods. The weights are computed via a simple linear system and we analyze performance in both online and offline modes. We use Crouzeix's conjecture to show that acceleration performance is controlled by the solution of a Chebyshev problem on the numerical range of a non-symmetric operator modelling the behavior of iterates near the optimum. Numerical experiments are detailed on image processing problems, logistic regression and neural network training for CIFAR10 and ImageNet.},
	annotation = {00000},
	archiveprefix = {arXiv},
	author = {Bollapragada, Raghu and Scieur, Damien and {d'Aspremont}, Alexandre},
	eprint = {1810.04539},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Zotero/storage/PALEFWLD/Bollapragada et al. - 2018 - Nonlinear Acceleration of Momentum and Primal-Dual.pdf;/Users/longchen1/Zotero/storage/5AEMM2XG/1810.html},
	journal = {arXiv:1810.04539 [math]},
	keywords = {Mathematics - Optimization and Control},
	month = oct,
	primaryclass = {math},
	title = {Nonlinear {{Acceleration}} of {{Momentum}} and {{Primal-Dual Algorithms}}},
	year = {2018}}

@article{borgensRegularizedJacobitypeADMMmethods2019,
	abstract = {We consider a regularized version of a Jacobi-type alternating direction method of multipliers (ADMM) for the solution of a class of separable convex optimization problems in a Hilbert space. The analysis shows that this method is equivalent to the standard proximal-point method applied in a Hilbert space with a transformed scalar product. The method therefore inherits the known convergence results from the proximal-point method and allows suitable modifications to get a strongly convergent variant. Some additional properties are also shown by exploiting the particular structure of the ADMM-type solution method. Applications and numerical results are provided to the sparse optimization problem in finite dimensions and to the domain decomposition method in a Hilbert space setting.},
	author = {B{\"o}rgens, Eike and Kanzow, Christian},
	doi = {10.1007/s10589-019-00087-9},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/ADMM/B{\"o}rgens and Kanzow - 2019 - Regularized Jacobi-type ADMM-methods for a class o.pdf},
	issn = {0926-6003, 1573-2894},
	journal = {Computational Optimization and Applications},
	langid = {english},
	month = jul,
	number = {3},
	pages = {755--790},
	title = {Regularized {{Jacobi-type ADMM-methods}} for a Class of Separable Convex Optimization Problems in {{Hilbert}} Spaces},
	volume = {73},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1007/s10589-019-00087-9}}

@article{BotCsetnek2017,
	abstract = {We investigate the asymptotic convergence of the trajectories generated by the second-order dynamical system x\textasciidieresis (t) + {$\gamma$} x\textperiodcentered (t) + {$\nabla\varphi$}(x(t)) + {$\beta$}(t){$\nabla\psi$}(x(t)) = 0, where {$\varphi$}, {$\psi$} : H \textrightarrow{} R are the convex and smooth functions defined on a real Hilbert space H, {$\gamma$} {$>$} 0 and {$\beta$} is a function of time which controls the penalty term. We show weak convergence of the trajectories to a minimizer of the function {$\varphi$} over the (nonempty) set of minima of {$\psi$} as well as convergence for the objective function values along the trajectories, provided a condition expressed via the Fenchel conjugate of {$\psi$} is fulfilled. When the function {$\varphi$} is assumed to be strongly convex, we can even show strong convergence of the trajectories. The results can be seen as the second-order counterparts of the ones given by Attouch and Czarnecki (Journal of Differential Equations 248(6), 1315\textendash 1344, 2010) for first-order dynamical systems associated to the constrained variational inequalities. At the same time we give a positive answer to an open problem posed by Attouch and Czarnecki in a recent preprint.},
	annotation = {00010},
	author = {Bo{\c t}, Radu Ioan and Csetnek, Ern{\"o} Robert},
	doi = {10.1080/00036811.2016.1157589},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/ODE/Bo{\c t} and Csetnek - 2017 - Second-order dynamical systems associated to varia.pdf},
	issn = {0003-6811, 1563-504X},
	journal = {Applicable Analysis},
	langid = {english},
	month = apr,
	number = {5},
	pages = {799--809},
	title = {Second-Order Dynamical Systems Associated to Variational Inequalities},
	volume = {96},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1080/00036811.2016.1157589}}

@incollection{botevVarianceReduction2017,
	abstract = {Increased computer speed and memory have encouraged simulation analysts to develop ever more realistic stochastic models. Despite these advancements in computing hardware, the most significant gains in the speed of stochastic simulation are still the result of methodological advances and clever algorithmic design. In this article, we survey a few of the most important methods for variance reduction and speedup that will benefit any simulation, no matter what the capabilities of the computing hardware are.},
	address = {{Chichester, UK}},
	annotation = {ZSCC: NoCitationData[s0]},
	author = {Botev, Zdravko and Ridder, Ad},
	booktitle = {Wiley {{StatsRef}}: {{Statistics Reference Online}}},
	doi = {10.1002/9781118445112.stat07975},
	editor = {Balakrishnan, N. and Colton, Theodore and Everitt, Brian and Piegorsch, Walter and Ruggeri, Fabrizio and Teugels, Jozef L.},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Botev and Ridder - 2017 - Variance Reduction.pdf},
	isbn = {978-1-118-44511-2},
	langid = {english},
	month = nov,
	pages = {1--6},
	publisher = {{John Wiley \& Sons, Ltd}},
	title = {Variance {{Reduction}}},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1002/9781118445112.stat07975}}

@inproceedings{Bottou2010,
	abstract = {During the last decade, the data sizes have grown faster than the speed of processors. In this context, the capabilities of statistical machine learning methods is limited by the computing time rather than the sample size. A more precise analysis uncovers qualitatively different tradeoffs for the case of small-scale and large-scale learning problems. The large-scale case involves the computational complexity of the underlying optimization algorithm in non-trivial ways. Unlikely optimization algorithms such as stochastic gradient descent show amazing performance for large-scale problems. In particular, second order stochastic gradient and averaged stochastic gradient are asymptotically efficient after a single pass on the training set.},
	annotation = {02915},
	author = {Bottou, Leon},
	booktitle = {Proceedings of {{COMPSTAT}}},
	file = {/Users/longchen1/Zotero/storage/4GSQPZC9/Bottou - Large-Scale Machine Learning with Stochastic Gradi.pdf},
	langid = {english},
	pages = {177--186},
	title = {Large-{{Scale Machine Learning}} with {{Stochastic Gradient Descent}}},
	year = {2010}}

@article{BottouCurtisNocedal2018,
	abstract = {This paper provides a review and commentary on the past, present, and future of numerical optimization algorithms in the context of machine learning applications. Through case studies on text classification and the training of deep neural networks, we discuss how optimization problems arise in machine learning and what makes them challenging. A major theme of our study is that large-scale machine learning represents a distinctive setting in which the stochastic gradient (SG) method has traditionally played a central role while conventional gradient-based nonlinear optimization techniques typically falter. Based on this viewpoint, we present a comprehensive theory of a straightforward, yet versatile SG algorithm, discuss its practical behavior, and highlight opportunities for designing algorithms with improved performance. This leads to a discussion about the next generation of optimization methods for large-scale machine learning, including an investigation of two main streams of research on techniques that diminish noise in the stochastic directions and methods that make use of second-order derivative approximations.},
	annotation = {00442},
	author = {Bottou, L{\'e}on and Curtis, Frank E. and Nocedal, Jorge},
	doi = {10.1137/16M1080173},
	file = {/Users/longchen1/Zotero/storage/TAZX9EKI/Bottou et al. - 2018 - Optimization Methods for Large-Scale Machine Learn.pdf},
	issn = {0036-1445, 1095-7200},
	journal = {SIAM Review},
	langid = {english},
	month = jan,
	number = {2},
	pages = {223--311},
	title = {Optimization {{Methods}} for {{Large-Scale Machine Learning}}},
	volume = {60},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1137/16M1080173}}

@article{Bubeck,
	abstract = {This monograph presents the main mathematical ideas in convex optimization. Starting from the fundamental theory of black-box optimization, the material progresses towards recent advances in structural optimization and stochastic optimization. Our presentation of black-box optimization, strongly influenced by the seminal book of Nesterov, includes the analysis of the Ellipsoid Method, as well as (accelerated) gradient descent schemes. We also pay special attention to non-Euclidean settings (relevant algorithms include Frank-Wolfe, Mirror Descent, and Dual Averaging) and discuss their relevance in machine learning. We provide a gentle introduction to structural optimization with FISTA (to optimize a sum of a smooth and a simple non-smooth term), SaddlePoint Mirror Prox (Nemirovski's alternative to Nesterov's smoothing), and a concise description of Interior Point Methods. In stochastic optimization we discuss Stochastic Gradient Descent, mini-batches, Random Coordinate Descent, and sublinear algorithms. We also briefly touch upon convex relaxation of combinatorial problems and the use of randomness to round solutions, as well as random walks based methods.},
	annotation = {00080},
	author = {Bubeck, Sebastien},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/Bubeck - Theory of Convex Optimization for Machine Learning.pdf},
	langid = {english},
	pages = {110},
	title = {Theory of {{Convex Optimization}} for {{Machine Learning}}}}

@article{ByrdSchnabelShultz1987,
	abstract = {We present a trust region-based method for the general nonlinearly equality constrained optimization problem. The method works by iteratively minimizing a quadratic model of the Lagrangian subject to a possibly relaxed linearization of the problem constraints and a trust region constraint. The model minimization may be done approximately with a dogleg-type approach. We show that this method is globally convergent even if singular or indefinite Hessian approximations are made. A second order correction step that brings the iterates closer to the feasible set is described. If sufficiently precise Hessian information is used, this correction step allows us to prove that the method is also locally quadratically convergent, and that the limit satisfies the second order necessary conditions for constrained optimization. An example is given to show that, without this correction, a situation similar to the Maratos effect may occur where the iteration is unable to move away from a saddle point.},
	annotation = {00375},
	author = {Byrd, R. and Schnabel, R. and Shultz, G.},
	doi = {10.1137/0724076},
	file = {/Users/longchen1/Zotero/storage/NV3KZSRU/Byrd et al. - 1987 - A Trust Region Algorithm for Nonlinearly Constrain.pdf;/Users/longchen1/Zotero/storage/3QAN8EF8/0724076.html},
	issn = {0036-1429},
	journal = {SIAM Journal on Numerical Analysis},
	month = oct,
	number = {5},
	pages = {1152--1170},
	title = {A {{Trust Region Algorithm}} for {{Nonlinearly Constrained Optimization}}},
	volume = {24},
	year = {1987},
	bdsk-url-1 = {https://doi.org/10.1137/0724076}}

@article{cevherConvexOptimizationBig2014,
	abstract = {This article reviews recent advances in convex optimization algorithms for Big Data, which aim to reduce the computational, storage, and communications bottlenecks. We provide an overview of this emerging field, describe contemporary approximation techniques like first-order methods and randomization for scalability, and survey the important role of parallel and distributed computation. The new Big Data algorithms are based on surprisingly simple principles and attain staggering accelerations even on classical problems.},
	annotation = {ZSCC: 0000290},
	archiveprefix = {arXiv},
	author = {Cevher, Volkan and Becker, Stephen and Schmidt, Mark},
	doi = {10.1109/MSP.2014.2329397},
	eprint = {1411.0972},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Cevher et al. - 2014 - Convex Optimization for Big Data.pdf},
	issn = {1053-5888},
	journal = {IEEE Signal Processing Magazine},
	keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
	langid = {english},
	month = sep,
	number = {5},
	pages = {32--43},
	title = {Convex {{Optimization}} for {{Big Data}}},
	volume = {31},
	year = {2014},
	bdsk-url-1 = {https://doi.org/10.1109/MSP.2014.2329397}}

@article{chenConvergenceRateIts,
	annotation = {ZSCC: NoCitationData[s0]},
	author = {Chen, Bingchuan and Chai, Xiaolong and Bian, Rui and Li, Hengguang},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Chen et al. - Convergence Rate and Its Complexity.pdf},
	langid = {english},
	pages = {21},
	title = {Convergence {{Rate}} and {{Its Complexity}}}}

@article{chenDirectExtensionADMM2016,
	annotation = {ZSCC: 0000573},
	author = {Chen, Caihua and He, Bingsheng and Ye, Yinyu and Yuan, Xiaoming},
	doi = {10.1007/s10107-014-0826-5},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/ADMM/Chen2016_Article_TheDirectExtensionOfADMMForMul.pdf},
	issn = {0025-5610, 1436-4646},
	journal = {Mathematical Programming},
	langid = {english},
	month = jan,
	number = {1-2},
	pages = {57--79},
	title = {The Direct Extension of {{ADMM}} for Multi-Block Convex Minimization Problems Is Not Necessarily Convergent},
	volume = {155},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.1007/s10107-014-0826-5}}

@article{ChenYang2018,
	abstract = {In this paper, we propose a new SVRG-style acceleated stochastic algorithm for solving a family of non-convex optimization problems whose objective consists of a sum of \$n\$ smooth functions and a non-smooth convex function. Our major goal is to improve the convergence of SVRG-style stochastic algorithms to stationary points under a setting with a large condition number \$c\$ - the ratio between the smoothness constant and the negative curvature constant. The proposed algorithm achieves the best known gradient complexity when \$c\textbackslash geq \textbackslash Omega(n)\$, which was achieved previously by a SAGA-style accelerated stochastic algorithm. Compared with the SAGA-style accelerated stochastic algorithm, the proposed algorithm is more practical due to its low memory cost that is inherited from previous SVRG-style algorithms. Compared with previous studies on SVRG-style stochastic algorithms, our theory provides much stronger results in terms of (i) reduced gradient complexity under a large condition number; and (ii) that the convergence is proved for a sampled stagewise averaged solution that is selected from all stagewise averaged solutions with increasing sampling probabilities instead of for a uniformly sampled solutions across all iterations.},
	archiveprefix = {arXiv},
	author = {Chen, Zaiyi and Yang, Tianbao},
	eprint = {1809.06754},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Zotero/storage/QKVX5VCC/Chen and Yang - 2018 - A Variance Reduction Method for Non-Convex Optimiz.pdf;/Users/longchen1/Zotero/storage/WQFS6UMR/1809.html},
	journal = {arXiv:1809.06754 [math]},
	keywords = {Mathematics - Optimization and Control},
	month = sep,
	primaryclass = {math},
	title = {A {{Variance Reduction Method}} for {{Non-Convex Optimization}} with {{Improved Convergence}} under {{Large Condition Number}}},
	year = {2018}}

@book{ConnGouldToint2000,
	annotation = {02561},
	author = {Conn, Andrew R and Gould, Nicholas IM and Toint, Ph L},
	publisher = {{Siam}},
	title = {Trust Region Methods},
	volume = {1},
	year = {2000}}

@article{CyrusHuVanScoyLessard2017,
	abstract = {This work proposes an accelerated first-order algorithm we call the Robust Momentum Method for optimizing smooth strongly convex functions. The algorithm has a single scalar parameter that can be tuned to trade off robustness to gradient noise versus worst-case convergence rate. At one extreme, the algorithm is faster than Nesterov's Fast Gradient Method by a constant factor but more fragile to noise. At the other extreme, the algorithm reduces to the Gradient Method and is very robust to noise. The algorithm design technique is inspired by methods from classical control theory and the resulting algorithm has a simple analytical form. Algorithm performance is verified on a series of numerical simulations in both noise-free and relative gradient noise cases.},
	annotation = {00000},
	archiveprefix = {arXiv},
	author = {Cyrus, Saman and Hu, Bin and Van Scoy, Bryan and Lessard, Laurent},
	eprint = {1710.04753},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/ControlTheory/Cyrus et al. - 2017 - A Robust Accelerated Optimization Algorithm for St.pdf},
	journal = {arXiv:1710.04753 [cs, math]},
	keywords = {Electrical Engineering and Systems Science - Systems and Control,Mathematics - Optimization and Control},
	langid = {english},
	month = oct,
	primaryclass = {cs, math},
	title = {A {{Robust Accelerated Optimization Algorithm}} for {{Strongly Convex Functions}}},
	year = {2017}}

@article{Davidon.W1991,
	author = {Davidon, William C and Metric, Variable and For, Method},
	doi = {10.1137/0801001},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/Davidon, Metric, For/SIAM Journal on Optimization/Davidon, Metric, For - 1991 - Variable Metric Method for Minimization.pdf},
	journal = {SIAM Journal on Optimization},
	keywords = {49d37,65k05,65k10,90c30,a belated preface for,ams,anl 5990,computers,enrico fermi and nicholas,metropolis used one,mos,of,of the first digital,optimiza,optimization,primary,quasi-newton,secondary,subject classifications,the los alamos maniac,to determine which values,variable metric algorithms},
	number = {1},
	pages = {1--17},
	publisher = {{SIAM}},
	title = {Variable {{Metric Method}} for {{Minimization}}},
	volume = {1},
	year = {1991},
	bdsk-url-1 = {https://doi.org/10.1137/0801001}}

@article{davisLowProbabilityHigh,
	abstract = {Standard results in stochastic convex optimization bound the number of samples that an algorithm needs to generate a point with small function value in expectation. More nuanced high probability guarantees are rare, and typically either rely on ``light-tail'' noise assumptions or exhibit worse sample complexity. In this work, we show that a wide class of stochastic optimization algorithms for strongly convex problems can be augmented with high confidence bounds at an overhead cost that is only logarithmic in the confidence level and polylogarithmic in the condition number. The procedure we propose, called proxBoost, is elementary and builds on two well-known ingredients: robust distance estimation and the proximal point method. We discuss consequences for both streaming (online) algorithms and offline algorithms based on empirical risk minimization.},
	annotation = {ZSCC: 0000004},
	author = {Davis, Damek and Drusvyatskiy, Dmitriy and Xiao, Lin and Zhang, Junyu},
	file = {/Users/longchen1/Dropbox/Math/Research/Lyapunov_Framework/references/Davis et al. - From Low Probability to High Confidence in Stochast.pdf},
	langid = {english},
	pages = {38},
	title = {From {{Low Probability}} to {{High Confidence}} in {{Stochastic Convex Optimization}}}}

@article{defazioSAGAFastIncremental2014,
	abstract = {In this work we introduce a new optimisation method called SAGA in the spirit of SAG, SDCA, MISO and SVRG, a set of recently proposed incremental gradient algorithms with fast linear convergence rates. SAGA improves on the theory behind SAG and SVRG, with better theoretical convergence rates, and has support for composite objectives where a proximal operator is used on the regulariser. Unlike SDCA, SAGA supports non-strongly convex problems directly, and is adaptive to any inherent strong convexity of the problem. We give experimental results showing the effectiveness of our method.},
	archiveprefix = {arXiv},
	author = {Defazio, Aaron and Bach, Francis and {Lacoste-Julien}, Simon},
	eprint = {1407.0202},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Defazio et al. - 2014 - SAGA A Fast Incremental Gradient Method With Supp.pdf},
	journal = {arXiv:1407.0202 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
	langid = {english},
	month = dec,
	primaryclass = {cs, math, stat},
	shorttitle = {{{SAGA}}},
	title = {{{SAGA}}: {{A Fast Incremental Gradient Method With Support}} for {{Non-Strongly Convex Composite Objectives}}},
	year = {2014}}

@article{Dennis.J;More.J1977,
	abstract = {This paper is an attempt to motivate and justify quasi-Newton methods as useful modifications of Newton's method for general and gradient nonlinear systems of equations. References are given to ample numerical justification; here we give an overview of many of the important theoretical results and each is accompanied by sufficient discussion to make the results and hence the methods plausible.},
	author = {Dennis J. E., Jr. and More, Jorge J},
	issn = {0036-1445},
	journal = {SIAM Rev.},
	month = jan,
	number = {1},
	pages = {46--89},
	publisher = {{Society for Industrial and Applied Mathematics}},
	title = {Quasi-{{Newton Methods}}, {{Motivation}} and {{Theory}}},
	volume = {19},
	year = {1977}}

@article{DennisEl-AlemMaciel1997,
	abstract = {This work presents a global convergence theory for a broad class of trust-region algorithms for the smooth nonlinear programming problem with equality constraints. The main result generalizes Powell's 1975 result for unconstrained trust-region algorithms.The trial step is characterized by very mild conditions on its normal and tangential components. The normal component need not be computed accurately. The theory requires a quasi-normal component to satisfy a fraction of Cauchy decrease condition on the quadratic model of the linearized constraints. The tangential component then must satisfy a fraction of Cauchy decrease condition on a quadratic model of the Lagrangian function in the translated tangent space of the constraints determined by the quasi-normal component. Estimates of the Lagrange multipliers and the Hessians are assumed only to be bounded.The other main characteristic of this class of algorithms is that the step is evaluated by using the augmented Lagrangian as a merit function with the penalty parameter updated using the El-Alem scheme. The properties of the step and the way that the penalty parameter is chosen are sufficient to establish global convergence.As an example, an algorithm is presented that can be viewed as a generalization of the Steihaug--Toint dogleg algorithm for the unconstrained case. It is based on a quadratic programming algorithm that uses a step in a quasi-normal direction to the tangent space of the constraints and then takes feasible conjugate reduced-gradient steps to solve the reduced quadratic program. This algorithm should cope quite well with large problems for which effective preconditioners are known.},
	annotation = {00165},
	author = {Dennis, J. and {El-Alem}, M. and Maciel, M.},
	doi = {10.1137/S1052623492238881},
	file = {/Users/longchen1/Zotero/storage/GJNL6B57/Dennis et al. - 1997 - A Global Convergence Theory for General Trust-Regi.pdf;/Users/longchen1/Zotero/storage/KD2IITNP/S1052623492238881.html},
	issn = {1052-6234},
	journal = {SIAM Journal on Optimization},
	month = feb,
	number = {1},
	pages = {177--207},
	title = {A {{Global Convergence Theory}} for {{General Trust-Region-Based Algorithms}} for {{Equality Constrained Optimization}}},
	volume = {7},
	year = {1997},
	bdsk-url-1 = {https://doi.org/10.1137/S1052623492238881}}

@article{DennisVicente1997,
	abstract = {In a recent paper, Dennis, El-Alem, and Maciel proved global convergence to a stationary point for a general trust-region-based algorithm for equality-constrained optimization. This general algorithm is based on appropriate choices of trust-region subproblems and seems particularly suitable for large problems.This paper shows global convergence to a point satisfying the second-order necessary optimality conditions for the same general trust-region-based algorithm. The results given here can be seen as a generalization of the convergence results for trust-regions methods for unconstrained optimization obtained by Mor\'e and Sorensen. The behavior of the trust radius and the local rate of convergence are analyzed. Some interesting facts concerning the trust-region subproblem for the linearized constraints, the quasi-normal component of the step, and the hard case are presented.It is shown how these results can be applied to a class of discretized optimal control problems.},
	annotation = {00069},
	author = {Dennis, J. and Vicente, L.},
	doi = {10.1137/S1052623494276026},
	file = {/Users/longchen1/Zotero/storage/SL3SRYWU/Dennis and Vicente - 1997 - On the Convergence Theory of Trust-Region-Based Al.pdf;/Users/longchen1/Zotero/storage/66BVSQN7/S1052623494276026.html},
	issn = {1052-6234},
	journal = {SIAM Journal on Optimization},
	month = nov,
	number = {4},
	pages = {927--950},
	title = {On the {{Convergence Theory}} of {{Trust-Region-Based Algorithms}} for {{Equality-Constrained Optimization}}},
	volume = {7},
	year = {1997},
	bdsk-url-1 = {https://doi.org/10.1137/S1052623494276026}}

@article{devolderExactnessInexactnessStochasticity,
	annotation = {ZSCC: 0000077},
	author = {Devolder, Olivier},
	file = {/Volumes/LongBackupDrive/Backup/Dropbox/Math/LectureNotes/Optimization/references/SGD/Devolder - Exactness, Inexactness and Stochasticity in First-.pdf},
	langid = {english},
	pages = {320},
	title = {Exactness, {{Inexactness}} and {{Stochasticity}} in {{First-Order Methods}} for {{Large-Scale Convex Optimization}}}}

@article{DiakonikolasJordan2019,
	abstract = {We take a Hamiltonian-based perspective to generalize Nesterov's accelerated gradient descent and Polyak's heavy ball method to a broad class of momentum methods in the setting of (possibly) constrained minimization in Banach spaces. Our perspective leads to a generic and unifying non-asymptotic analysis of convergence of these methods in both the function value (in the setting of convex optimization) and in the norm of the gradient (in the setting of unconstrained, possibly nonconvex, optimization). The convergence analysis is intuitive and based on the conserved quantities of the time-dependent Hamiltonian that we introduce and that produces generalized momentum methods as its equations of motion.},
	annotation = {00000},
	archiveprefix = {arXiv},
	author = {Diakonikolas, Jelena and Jordan, Michael I.},
	eprint = {1906.00436},
	eprinttype = {arxiv},
	file = {/Volumes/GoogleDrive/My Drive/biblib/Papers/biblib/topics/Acceleration/Diakonikolas and Jordan - 2019 - Generalized Momentum-Based Methods A Hamiltonian .pdf},
	journal = {arXiv:1906.00436 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
	langid = {english},
	month = jun,
	primaryclass = {cs, math, stat},
	shorttitle = {Generalized {{Momentum-Based Methods}}},
	title = {Generalized {{Momentum-Based Methods}}: {{A Hamiltonian Perspective}}},
	year = {2019}}

@article{DoikovRichtarik2018,
	abstract = {We study the problem of minimizing the sum of three convex functions\textemdash a differentiable, twicedifferentiable and a non-smooth term\textemdash in a high dimensional setting. To this effect we propose and analyze a randomized block cubic Newton (RBCN) method, which in each iteration builds a model of the objective function formed as the sum of the natural models of its three components: a linear model with a quadratic regularizer for the differentiable term, a quadratic model with a cubic regularizer for the twice differentiable term, and perfect (proximal) model for the nonsmooth term. Our method in each iteration minimizes the model over a random subset of blocks of the search variable. RBCN is the first algorithm with these properties, generalizing several existing methods, matching the best known bound{$\surd$}s in all special cases. We establish O(1/ ), O(1/ ) and O(log(1/ )) rates under different assumptions on the component functions. Lastly, we show numerically that our method outperforms the state of the art on a variety of machine learning problems, including cubically regularized leastsquares, logistic regression with constraints, and Poisson regression.},
	annotation = {00015},
	archiveprefix = {arXiv},
	author = {Doikov, Nikita and Richt{\'a}rik, Peter},
	eprint = {1802.04084},
	eprinttype = {arxiv},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/CRNewton/Doikov and Richt{\'a}rik - 2018 - Randomized Block Cubic Newton Method.pdf},
	journal = {arXiv:1802.04084 [math]},
	keywords = {Mathematics - Optimization and Control},
	langid = {english},
	month = aug,
	primaryclass = {math},
	title = {Randomized {{Block Cubic Newton Method}}},
	year = {2018}}

@article{dragomirFastStochasticBregman2021,
	abstract = {We study the problem of minimizing a relatively-smooth convex function using stochastic Bregman gradient methods. We first prove the convergence of Bregman Stochastic Gradient Descent (BSGD) to a region that depends on the noise (magnitude of the gradients) at the optimum. In particular, BSGD with a constant step-size converges to the exact minimizer when this noise is zero (interpolation setting, in which the data is fit perfectly). Otherwise, when the objective has a finite sum structure, we show that variance reduction can be used to counter the effect of noise. In particular, fast convergence to the exact minimizer can be obtained under additional regularity assumptions on the Bregman reference function. We illustrate the effectiveness of our approach on two key applications of relative smoothness: tomographic reconstruction with Poisson noise and statistical preconditioning for distributed optimization.},
	annotation = {ZSCC: 0000000},
	archiveprefix = {arXiv},
	author = {Dragomir, Radu-Alexandru and Even, Mathieu and Hendrikx, Hadrien},
	eprint = {2104.09813},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Dragomir et al. - 2021 - Fast Stochastic Bregman Gradient Methods Sharp An.pdf},
	journal = {arXiv:2104.09813 [math]},
	keywords = {Mathematics - Optimization and Control},
	langid = {english},
	month = apr,
	primaryclass = {math},
	shorttitle = {Fast {{Stochastic Bregman Gradient Methods}}},
	title = {Fast {{Stochastic Bregman Gradient Methods}}: {{Sharp Analysis}} and {{Variance Reduction}}},
	year = {2021}}

@article{DriggsLiangSchonlieb2019,
	abstract = {We present a general analysis of variance reduced stochastic gradient methods with bias for minimising convex, strongly convex, and non-convex composite objectives. The key to our analysis is a new connection between bias and variance in stochastic gradient estimators, suggesting a new form of bias-variance tradeoff in stochastic optimisation. This connection allows us to provide simple convergence proofs for biased algorithms, extend proximal support to biased algorithms for the first time in the convex setting, and show that biased gradient estimators often offer theoretical advantages over unbiased estimators. We propose two algorithms, B-SAGA and B-SVRG, that incorporate bias into the SAGA and SVRG gradient estimators and analyse them using our framework. Our analysis shows that the bias in the B-SAGA and B-SVRG gradient estimators decreases their meansquared errors and improves their performance in certain settings.},
	annotation = {00000},
	archiveprefix = {arXiv},
	author = {Driggs, Derek and Liang, Jingwei and Sch{\"o}nlieb, Carola-Bibiane},
	eprint = {1906.01133},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Driggs et al. - 2019 - On the Bias-Variance Tradeoff in Stochastic Gradie.pdf},
	journal = {arXiv:1906.01133 [math]},
	keywords = {90C25; 90C26,Mathematics - Optimization and Control},
	langid = {english},
	month = jun,
	primaryclass = {math},
	title = {On the {{Bias-Variance Tradeoff}} in {{Stochastic Gradient Methods}}},
	year = {2019}}

@article{DroriTeboulle2014,
	abstract = {We introduce a novel approach for analyzing the worst-case performance of first-order black-box optimization methods. We focus on smooth unconstrained convex minimization over the Euclidean space. Our approach relies on the observation that by definition, the worst-case behavior of a black-box optimization method is by itself an optimization problem, which we call the performance estimation problem (PEP). We formulate and analyze the PEP for two classes of first-order algorithms. We first apply this approach on the classical gradient method and derive a new and tight analytical bound on its performance. We then consider a broader class of first-order black-box methods, which among others, include the so-called heavy-ball method and the fast gradient schemes. We show that for this broader class, it is possible to derive new bounds on the performance of these methods by solving an adequately relaxed convex semidefinite PEP. Finally, we show an efficient procedure for finding optimal step sizes which results in a first-order black-box method that achieves best worst-case performance.},
	annotation = {00085},
	author = {Drori, Yoel and Teboulle, Marc},
	doi = {10.1007/s10107-013-0653-0},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/Drori and Teboulle - 2014 - Performance of first-order methods for smooth conv.pdf},
	issn = {0025-5610, 1436-4646},
	journal = {Mathematical Programming},
	langid = {english},
	month = jun,
	number = {1-2},
	pages = {451--482},
	shorttitle = {Performance of First-Order Methods for Smooth Convex Minimization},
	title = {Performance of First-Order Methods for Smooth Convex Minimization: A Novel Approach},
	volume = {145},
	year = {2014},
	bdsk-url-1 = {https://doi.org/10.1007/s10107-013-0653-0}}

@article{ehrhardtGeometricIntegrationApproach,
	archiveprefix = {arXiv},
	author = {Ehrhardt, Matthias J and Riis, Erlend S and Ringholm, Torbj{\o}rn},
	eprint = {1805.06444v1},
	eprinttype = {arxiv},
	file = {/Volumes/GoogleDrive/My Drive/biblib/Papers/Ehrhardt, Riis, Ringholm/Unknown/Ehrhardt, Riis, Ringholm - Unknown - A geometric integration approach to smooth optimisation Foundations of the discrete gradient method.pdf},
	keywords = {-b,49m37,49q15,65k05,65k10,90c15,90c26,90c30,acknowledge support from,all authors acknowledge support,ams subject classifications,and c,discrete gradient method,e,from chips,geometric integration,grant,horizon 2020 rise project,j,m,nonconvex optimisation,s,smooth optimisation,stochastic optimisation},
	title = {A Geometric Integration Approach to Smooth Optimisation: {{Foundations}} of the Discrete Gradient Method}}

@article{FercoqQu2019,
	abstract = {Abstract             By analyzing accelerated proximal gradient methods under a local quadratic growth condition, we show that restarting these algorithms at any frequency gives a globally linearly convergent algorithm. This result was previously known only for long enough frequencies. Then as the rate of convergence depends on the match between the frequency and the quadratic error bound, we design a scheme to automatically adapt the frequency of restart from the observed decrease of the norm of the gradient mapping. Our algorithm has a better theoretical bound than previously proposed methods for the adaptation to the quadratic error bound of the objective. We illustrate the efficiency of the algorithm on Lasso, regularized logistic regression and total variation denoising problems.},
	annotation = {00026},
	author = {Fercoq, Olivier and Qu, Zheng},
	doi = {10.1093/imanum/drz007},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/Acceleration/Fercoq and Qu - 2019 - Adaptive restart of accelerated gradient methods u.pdf},
	issn = {0272-4979, 1464-3642},
	journal = {IMA Journal of Numerical Analysis},
	langid = {english},
	month = oct,
	number = {4},
	pages = {2069--2095},
	title = {Adaptive Restart of Accelerated Gradient Methods under Local Quadratic Growth Condition},
	volume = {39},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1093/imanum/drz007}}

@article{Frikha2016,
	abstract = {This paper studies multi-level stochastic approximation algorithms. Our aim is to extend the scope of the multilevel Monte Carlo method recently introduced by Giles (Giles 2008) to the framework of stochastic optimization by means of stochastic approximation algorithm. We first introduce and study a two-level method, also referred as statistical Romberg stochastic approximation algorithm. Then, its extension to multi-level is proposed. We prove a central limit theorem for both methods and describe the possible optimal choices of step size sequence. Numerical results confirm the theoretical analysis and show a significant reduction in the initial computational cost.},
	author = {Frikha, Noufel},
	doi = {10.1214/15-AAP1109},
	file = {/Users/longchen1/Zotero/storage/W843X7LJ/Frikha - 2016 - Multi-level stochastic approximation algorithms.pdf},
	journal = {The Annals of Applied Probability : an official journal of the institute of mathematical statistics},
	keywords = {Euler scheme,Multi-level Monte Carlo methods,stochastic approximation},
	number = {2},
	pages = {933--985},
	title = {Multi-Level Stochastic Approximation Algorithms},
	volume = {26},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.1214/15-AAP1109}}

@article{GelmanMandel1990,
	abstract = {This paper is concerned with multilevel iterative methods which combine a descent scheme with a hierarchy of auxiliary problems in lower dimensional subspaces. The construction of auxiliary problems as well as applications to elasto-plastic model and linear programming are described. The auxiliary problem for the dual of a perturbed linear program is interpreted as a dual of perturbed aggregated linear program. Coercivity of the objective function over the feasible set is sufficient for the boundedness of the iterates. Equivalents of this condition are presented in special cases.},
	annotation = {00055},
	author = {Gelman, E. and Mandel, J.},
	doi = {10.1007/BF01582249},
	file = {/Users/longchen1/Zotero/storage/CDAZUNN3/Gelman and Mandel - 1990 - On multilevel iterative methods for optimization p.pdf},
	issn = {1436-4646},
	journal = {Mathematical Programming},
	keywords = {aggregation,Coercivity,linear programming,multigrid methods,quadratic programming,relaxation},
	langid = {english},
	month = mar,
	number = {1},
	pages = {1--17},
	title = {On Multilevel Iterative Methods for Optimization Problems},
	volume = {48},
	year = {1990},
	bdsk-url-1 = {https://doi.org/10.1007/BF01582249}}

@inproceedings{GhadimiFeyzmahdavianJohansson2015,
	abstract = {This paper establishes global convergence and provides global bounds of the rate of convergence for the Heavy-ball method for convex optimization. When the objective function has Lipschitz-continuous gradient, we show that the Cesa\textasciiacute ro average of the iterates converges to the optimum at a rate of O(1/k) where k is the number of iterations. When the objective function is also strongly convex, we prove that the Heavy-ball iterates converge linearly to the unique optimum. Numerical examples validate our theoretical findings.},
	address = {{Linz, Austria}},
	annotation = {00051},
	author = {Ghadimi, Euhanna and Feyzmahdavian, Hamid Reza and Johansson, Mikael},
	booktitle = {2015 {{European Control Conference}} ({{ECC}})},
	doi = {10.1109/ECC.2015.7330562},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/Acceleration/Ghadimi et al. - 2015 - Global convergence of the Heavy-ball method for co.pdf},
	isbn = {978-3-9524269-3-7},
	langid = {english},
	month = jul,
	pages = {310--315},
	publisher = {{IEEE}},
	title = {Global Convergence of the {{Heavy-ball}} Method for Convex Optimization},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1109/ECC.2015.7330562}}

@article{Gill.P;Murray.W;Saunders.M2005,
	abstract = {Sequential quadratic programming (SQP) methods have proved highly effective for solving constrained optimization problems with smooth nonlinear functions in the objective and constraints. Here we consider problems with general inequality constraints (linear and nonlinear). We assume that first derivatives are available and that the constraint gradients are sparse. Second derivatives are assumed to be unavailable or too expensive to calculate. We discuss an SQP algorithm that uses a smooth augmented Lagrangian merit function and makes explicit provision for infeasibility in the original problem and the QP subproblems. The Hessian of the Lagrangian is approximated using a limited-memory quasi-Newton method. SNOPT is a particular implementation that uses a reduced-Hessian semidefinite QP solver (SQOPT) for the QP subproblems. It is designed for problems with many thousands of constraints and variables but is best suited for problems with a moderate number of degrees of freedom (say, up to 2000). Numerical results are given for most of the CUTEr and COPS test collections (about 1020 examples of all sizes up to 40000 constraints and variables, and up to 20000 degrees of freedom).},
	author = {Gill, Philip E and Murray, Walter and Saunders, Michael A},
	file = {/Volumes/GoogleDrive/My Drive/biblib/Papers/Gill, Murray, Saunders/SIAM Rev/Gill, Murray, Saunders - 2005 - SNOPT An SQP Algorithm for Large-Scale Constrained Optimization.pdf;/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/Gill, Murray, Saunders/SIAM Rev/Gill, Murray, Saunders - 2005 - SNOPT An SQP Algorithm for Large-Scale Constrained Optimization.pdf},
	journal = {SIAM Rev.},
	number = {1},
	pages = {99--131},
	title = {\{\{\}\vphantom\}{{SNOPT}}\{\}\vphantom\{\}: {{An SQP Algorithm}} for {{Large-Scale Constrained Optimization}}},
	volume = {47},
	year = {2005}}

@incollection{GillMurraySaundersWright1989,
	annotation = {00079},
	author = {Gill, Philip E. and Murray, Walter and Saunders, Michael A. and Wright, Margaret H.},
	booktitle = {Handbooks in {{Operations Research}} and {{Management Science}}},
	doi = {10.1016/S0927-0507(89)01004-2},
	file = {/Users/longchen1/Zotero/storage/W82A6KPV/Gill et al. - 1989 - Chapter III Constrained nonlinear programming.pdf},
	isbn = {978-0-444-87284-5},
	langid = {english},
	pages = {171--210},
	publisher = {{Elsevier}},
	title = {Chapter {{III Constrained}} Nonlinear Programming},
	volume = {1},
	year = {1989},
	bdsk-url-1 = {https://doi.org/10.1016/S0927-0507(89)01004-2}}

@article{Goodman1985,
	abstract = {We derive a quadratically convergent algorithm for minimizing a nonlinear function subject to nonlinear equality constraints. We show, following Kaufman [4], how to compute efficiently the derivative of a basis of the subspace tangent to the feasible surface. The derivation minimizes the use of Lagrange multipliers, producing multiplier estimates as a by-product of other calculations. An extension of Kantorovich's theorem shows that the algorithm maintains quadratic convergence even if the basis of the tangent space changes abruptly from iteration to iteration. The algorithm and its quadratic convergence are known but the drivation is new, simple, and suggests several new modifications of the algorithm.},
	annotation = {00061},
	author = {Goodman, Jonathan},
	doi = {10.1007/BF01582243},
	file = {/Users/longchen1/Zotero/storage/VXDDKD6N/Goodman - 1985 - Newton's method for constrained optimization.pdf},
	issn = {1436-4646},
	journal = {Mathematical Programming},
	keywords = {Constrained Optimization,Newton's Method,Quadratic Convergence},
	langid = {english},
	month = nov,
	number = {2},
	pages = {162--171},
	title = {Newton's Method for Constrained Optimization},
	volume = {33},
	year = {1985},
	bdsk-url-1 = {https://doi.org/10.1007/BF01582243}}

@article{GoudouMunier2009,
	abstract = {We consider the gradient system x\textperiodcentered (t) + {$\nabla\Phi$}(x(t)) = 0 and the so-called heavy ball with friction dynamical system x\textasciidieresis (t) + {$\lambda$}x\textperiodcentered (t) + {$\nabla\Phi$}(x(t)) = 0, as well as an implicit discrete (proximal) version of it, and study the asymptotic behavior of their solutions in the case of a smooth and quasiconvex objective function {$\Phi$}. Minimization properties of trajectories are obtained under various additional assumptions. We finally show a minimizing property of the heavy ball method which is not shared by the gradient method: the genericity of the convergence of each trajectory, at least when {$\Phi$} is a Morse function, towards local minimum of {$\Phi$}.},
	annotation = {00029},
	author = {Goudou, X. and Munier, J.},
	doi = {10.1007/s10107-007-0109-5},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/Acceleration/Goudou and Munier - 2009 - The gradient and heavy ball with friction dynamica.pdf},
	issn = {0025-5610, 1436-4646},
	journal = {Mathematical Programming},
	langid = {english},
	month = jan,
	number = {1-2},
	pages = {173--191},
	shorttitle = {The Gradient and Heavy Ball with Friction Dynamical Systems},
	title = {The Gradient and Heavy Ball with Friction Dynamical Systems: The Quasiconvex Case},
	volume = {116},
	year = {2009},
	bdsk-url-1 = {https://doi.org/10.1007/s10107-007-0109-5}}

@article{gowerSketchProjectRandomized2016a,
	abstract = {Probabilistic ideas and tools have recently begun to permeate into several fields where they had traditionally not played a major role, including fields such as numerical linear algebra and optimization. One of the key ways in which these ideas influence these fields is via the development and analysis of randomized algorithms for solving standard and new problems of these fields. Such methods are typically easier to analyze, and often lead to faster and/or more scalable and versatile methods in practice.},
	annotation = {ZSCC: 0000008},
	archiveprefix = {arXiv},
	author = {Gower, Robert M.},
	eprint = {1612.06013},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Gower - 2016 - Sketch and Project Randomized Iterative Methods f.pdf},
	journal = {arXiv:1612.06013 [math]},
	keywords = {15A06; 15B52; 65F10; 68W20; 65N75; 65Y20; 68Q25; 68W40; 90C20,G.1.3,Mathematics - Numerical Analysis},
	langid = {english},
	month = dec,
	primaryclass = {math},
	shorttitle = {Sketch and {{Project}}},
	title = {Sketch and {{Project}}: {{Randomized Iterative Methods}} for {{Linear Systems}} and {{Inverting Matrices}}},
	year = {2016}}

@article{GrattonSartenaerToint2008,
	abstract = {A class of trust-region methods is presented for solving unconstrained nonlinear and possibly nonconvex discretized optimization problems, like those arising in systems governed by partial differential equations. The algorithms in this class make use of the discretization level as a means of speeding up the computation of the step. This use is recursive, leading to true multilevel/multiscale optimization methods reminiscent of multigrid methods in linear algebra and the solution of partial differential equations. A simple algorithm of the class is then described and its numerical performance is shown to be numerically promising. This observation then motivates a proof of global convergence to first-order stationary points on the fine grid that is valid for all algorithms in the class.},
	annotation = {00161},
	author = {Gratton, Serge and Sartenaer, Annick and Toint, Philippe L.},
	doi = {10.1137/050623012},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/TrustRegion/Gratton et al. - 2008 - Recursive Trust-Region Methods for Multiscale Nonl.pdf},
	issn = {1052-6234, 1095-7189},
	journal = {SIAM Journal on Optimization},
	langid = {english},
	month = jan,
	number = {1},
	pages = {414--444},
	title = {Recursive {{Trust-Region Methods}} for {{Multiscale Nonlinear Optimization}}},
	volume = {19},
	year = {2008},
	bdsk-url-1 = {https://doi.org/10.1137/050623012}}

@inproceedings{GurbuzbalabanOzdaglarParriloVanli2017,
	annotation = {00004},
	author = {Gurbuzbalaban, Mert and Ozdaglar, Asuman and Parrilo, Pablo A and Vanli, Nuri},
	booktitle = {Advances in {{Neural Information Processing Systems}}},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/BlockCoordinateDescent/G{\"u}rb{\"u}zbalaban et al. - When Cyclic Coordinate Descent Outperforms Randomi.pdf},
	pages = {6999--7007},
	title = {When Cyclic Coordinate Descent Outperforms Randomized Coordinate Descent},
	year = {2017}}

@article{gutmanPerturbedFenchelDuality2021,
	abstract = {We provide a unified framework for analyzing the convergence of Bregman proximal first-order algorithms for convex minimization. Our framework hinges on properties of the convex conjugate and gives novel proofs of the convergence rates of the Bregman proximal subgradient, Bregman proximal gradient, and a new accelerated Bregman proximal gradient algorithm under fairly general and mild assumptions. Our accelerated Bregman proximal gradient algorithm attains the best-known accelerated rate of convergence when suitable relative smoothness and triangle scaling assumptions hold. However, the algorithm requires no prior knowledge of any related smoothness or triangle scaling constants.},
	annotation = {ZSCC: NoCitationData[s0]},
	archiveprefix = {arXiv},
	author = {Gutman, David H. and Pe{\~n}a, Javier F.},
	eprint = {1812.10198},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/Bregman/Gutman and Pe{\~n}a - 2021 - Perturbed Fenchel duality and first-order methods.pdf},
	journal = {arXiv:1812.10198 [math]},
	keywords = {Mathematics - Optimization and Control},
	langid = {english},
	month = dec,
	primaryclass = {math},
	title = {Perturbed {{Fenchel}} Duality and First-Order Methods},
	year = {2021}}

@article{hamedaniIterationComplexityRandomized2018,
	abstract = {In this paper we propose a class of randomized primal-dual methods to contend with large-scale saddle point problems defined by a convex-concave function L(x, y) m i=1fi(xi) + {$\Phi$}(x, y) - h(y).},
	archiveprefix = {arXiv},
	author = {Hamedani, E. Yazdandoost and Jalilzadeh, A. and Aybat, N. S. and Shanbhag, U. V.},
	eprint = {1806.04118},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Hamedani et al. - 2018 - Iteration Complexity of Randomized Primal-Dual Met.pdf},
	journal = {arXiv:1806.04118 [math]},
	keywords = {Mathematics - Optimization and Control},
	langid = {english},
	month = jul,
	primaryclass = {math},
	title = {Iteration {{Complexity}} of {{Randomized Primal-Dual Methods}} for {{Convex-Concave Saddle Point Problems}}},
	year = {2018}}

@article{hanSurveyRecentDevelopments2022,
	abstract = {Recently, alternating direction method of multipliers (ADMM) attracts much attentions from various fields and there are many variant versions tailored for different models. Moreover, its theoretical studies such as rate of convergence and extensions to nonconvex problems also achieve much progress. In this paper, we give a survey on some recent developments of ADMM and its variants.},
	annotation = {ZSCC: 0000000},
	author = {Han, De-Ren},
	doi = {10.1007/s40305-021-00368-3},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/ADMM/Han - 2022 - A Survey on Some Recent Developments of Alternatin.pdf},
	issn = {2194-668X, 2194-6698},
	journal = {Journal of the Operations Research Society of China},
	langid = {english},
	month = jan,
	title = {A {{Survey}} on {{Some Recent Developments}} of {{Alternating Direction Method}} of {{Multipliers}}},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1007/s40305-021-00368-3}}

@article{HanzelyDoikovRichtarikNesterov,
	annotation = {00003},
	author = {Hanzely, Filip and Doikov, Nikita and Richt{\'a}rik, Peter and Nesterov, Yurii},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/CRNewton/Hanzely et al. - Stochastic Subspace Cubic Newton Method.pdf},
	langid = {english},
	pages = {12},
	title = {Stochastic {{Subspace Cubic Newton Method}}}}

@article{HanzelyDoikovRichtarikNesterov2020,
	abstract = {In this paper, we propose a new randomized second-order optimization algorithm---Stochastic Subspace Cubic Newton (SSCN)---for minimizing a high dimensional convex function \$f\$. Our method can be seen both as a \{\textbackslash em stochastic\} extension of the cubically-regularized Newton method of Nesterov and Polyak (2006), and a \{\textbackslash em second-order\} enhancement of stochastic subspace descent of Kozak et al. (2019). We prove that as we vary the minibatch size, the global convergence rate of SSCN interpolates between the rate of stochastic coordinate descent (CD) and the rate of cubic regularized Newton, thus giving new insights into the connection between first and second-order methods. Remarkably, the local convergence rate of SSCN matches the rate of stochastic subspace descent applied to the problem of minimizing the quadratic function \$\textbackslash frac12 (x-x\^*)\^\textbackslash top \textbackslash nabla\^2f(x\^*)(x-x\^*)\$, where \$x\^*\$ is the minimizer of \$f\$, and hence depends on the properties of \$f\$ at the optimum only. Our numerical experiments show that SSCN outperforms non-accelerated first-order CD algorithms while being competitive to their accelerated variants.},
	annotation = {00003},
	archiveprefix = {arXiv},
	author = {Hanzely, Filip and Doikov, Nikita and Richt{\'a}rik, Peter and Nesterov, Yurii},
	eprint = {2002.09526},
	eprinttype = {arxiv},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/CRNewton/Hanzely et al. - 2020 - Stochastic Subspace Cubic Newton Method.pdf},
	journal = {arXiv:2002.09526 [cs, math]},
	keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control},
	langid = {english},
	month = feb,
	primaryclass = {cs, math},
	title = {Stochastic {{Subspace Cubic Newton Method}}},
	year = {2020}}

@article{hateleyFastMethodsComputing2014,
	annotation = {00010},
	author = {Hateley, James C. and Wei, Huayi and Chen, Long},
	doi = {10.1007/s10915-014-9894-1},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/Hateley, Wei, Chen/Journal of Scientific Computing/Hateley, Wei, Chen - 2014 - Fast Methods for Computing Centroidal Voronoi Tessellations.pdf},
	issn = {0885-7474},
	journal = {Journal of Scientific Computing},
	keywords = {centroidal voronoi tessellation,lloyd,mathematics subject classification,numerical optimization,quasi-newton methods,s method},
	month = aug,
	title = {Fast {{Methods}} for {{Computing Centroidal Voronoi Tessellations}}},
	volume = {DOI 10.100},
	year = {2014},
	bdsk-url-1 = {https://doi.org/10.1007/s10915-014-9894-1}}

@article{heBalancedAugmentedLagrangian2021,
	abstract = {We consider the convex minimization model with both linear equality and inequality constraints, and reshape the classic augmented Lagrangian method (ALM) by balancing its subproblems. As a result, one of its subproblems decouples the objective function and the coefficient matrix without any extra condition, and the other subproblem becomes a positive definite system of linear equations or a positive definite linear complementary problem. The balanced ALM advances the classic ALM by enlarging its applicable range, balancing its subproblems, and improving its implementation. We also extend our discussion to two-block and multiple-block separable convex programming models, and accordingly design various splitting versions of the balanced ALM for these separable models. Convergence analysis for the balanced ALM and its splitting versions is conducted in the context of variational inequalities through the lens of the classic proximal point algorithm.},
	annotation = {ZSCC: 0000003},
	archiveprefix = {arXiv},
	author = {He, Bingsheng and Yuan, Xiaoming},
	eprint = {2108.08554},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/ALM/He and Yuan - 2021 - Balanced Augmented Lagrangian Method for Convex Pr.pdf},
	journal = {arXiv:2108.08554 [math]},
	keywords = {Mathematics - Optimization and Control},
	langid = {english},
	month = aug,
	primaryclass = {math},
	title = {Balanced {{Augmented Lagrangian Method}} for {{Convex Programming}}},
	year = {2021}}

@article{hennigQuasiNewtonMethodsNew,
	abstract = {Four decades after their invention, quasi-Newton methods are still state of the art in unconstrained numerical optimization. Although not usually interpreted thus, these are learning algorithms that fit a local quadratic approximation to the objective function. We show that many, including the most popular, quasi-Newton methods can be interpreted as approximations of Bayesian linear regression under varying prior assumptions. This new notion elucidates some shortcomings of classical algorithms, and lights the way to a novel nonparametric quasi-Newton method, which is able to make more efficient use of available information at computational cost similar to its predecessors.},
	annotation = {ZSCC: 0000108},
	author = {Hennig, Philipp and Kiefel, Martin},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/QuasiNewton/Hennig and Kiefel - Quasi-Newton Methods A New Direction.pdf},
	langid = {english},
	pages = {23},
	title = {Quasi-{{Newton Methods}}: {{A New Direction}}}}

@inproceedings{HenriquesEhrhardtAlbanieVedaldi2019,
	abstract = {We propose a fast second-order method that can be used as a drop-in replacement for current deep learning solvers. Compared to stochastic gradient descent (SGD), it only requires two additional forward-mode automatic differentiation operations per iteration, which has a computational cost comparable to two standard forward passes and is easy to implement. Our method addresses long-standing issues with current second-order solvers, which invert an approximate Hessian matrix every iteration exactly or by conjugategradient methods, procedures that are much slower than a SGD step. Instead, we propose to keep a single estimate of the gradient projected by the inverse Hessian matrix, and update it once per iteration with just two passes over the network. This estimate has the same size and is similar to the momentum variable that is commonly used in SGD. No estimate of the Hessian is maintained. We first validate our method, called CURVEBALL, on small problems with known solutions (noisy Rosenbrock function and degenerate 2-layer linear networks), where current deep learning solvers struggle. We then train several large models on CIFAR and ImageNet, including ResNet and VGG-f networks, where we demonstrate faster convergence with no hyperparameter tuning. We also show our optimiser's generality by testing on a large set of randomly-generated architectures.},
	address = {{Seoul, Korea (South)}},
	annotation = {00003},
	author = {Henriques, Joao and Ehrhardt, Sebastien and Albanie, Samuel and Vedaldi, Andrea},
	booktitle = {2019 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})},
	doi = {10.1109/ICCV.2019.00486},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/CRNewton/Henriques et al. - 2019 - Small Steps and Giant Leaps Minimal Newton Solver.pdf},
	isbn = {978-1-72814-803-8},
	langid = {english},
	month = oct,
	pages = {4762--4771},
	publisher = {{IEEE}},
	shorttitle = {Small {{Steps}} and {{Giant Leaps}}},
	title = {Small {{Steps}} and {{Giant Leaps}}: {{Minimal Newton Solvers}} for {{Deep Learning}}},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1109/ICCV.2019.00486}}

@article{HintermullerItoKunisch2003,
	author = {Hintermuller, M. and Ito, K. and Kunisch, K.},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/Hintermuller, Ito, Kunisch/SIAM J. Optim/Hintermuller, Ito, Kunisch - 2003 - The primal-dual active set strategy as a semismooth newton method.pdf},
	journal = {SIAM J. Optim.},
	keywords = {1,65j99,65k10,90c33,ams subject classifications,by linearly constrained quadratic,complementarity problems,function spaces,introduction,pii,s1052623401383558,semismooth newton method,this paper is motivated},
	number = {3},
	pages = {865--888},
	title = {The Primal-Dual Active Set Strategy as a Semismooth Newton Method},
	volume = {13},
	year = {2003}}

@article{hofmannVarianceReducedStochastic,
	abstract = {Stochastic Gradient Descent (SGD) is a workhorse in machine learning, yet its slow convergence can be a computational bottleneck. Variance reduction techniques such as SAG, SVRG and SAGA have been proposed to overcome this weakness, achieving linear convergence. However, these methods are either based on computations of full gradients at pivot points, or on keeping per data point corrections in memory. Therefore speed-ups relative to SGD may need a minimal number of epochs in order to materialize. This paper investigates algorithms that can exploit neighborhood structure in the training data to share and re-use information about past stochastic gradients across data points, which offers advantages in the transient optimization phase. As a side-product we provide a unified convergence analysis for a family of variance reduction algorithms, which we call memorization algorithms. We provide experimental results supporting our theory.},
	annotation = {ZSCC: 0000098},
	author = {Hofmann, Thomas and {Lacoste-Julien}, Simon and Lucchi, Aurelien and McWilliams, Brian},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Hofmann et al. - Variance Reduced Stochastic Gradient Descent with .pdf},
	langid = {english},
	pages = {9},
	title = {Variance {{Reduced Stochastic Gradient Descent}} with {{Neighbors}}}}

@article{Holst.M2001,
	abstract = {Adaptive multilevel finite element methods are developed and analyzed for certain elliptic systems arising in geometric analysis and general relativity. This class of nonlinear elliptic systems of tensor equations on manifolds is first reviewed, and then adaptive multilevel fi- nite element methods for approximating solutions to this class of problems are considered in some detail. Two a posteriori error indicators are derived, based on local residuals and on global linearized adjoint or dual problems. The design of Manifold Code (MC) is then dis- cussed; MC is an adaptive multilevel finite element software package for 2- and 3-manifolds developed over several years at Caltech and UC San Diego. It employs a posteriori error estimation, adaptive simplex subdivision, unstructured algebraic multilevel methods, global inexact Newton methods, and numerical continuation methods for the numerical solution of nonlinear covariant elliptic systems on 2- and 3-manifolds. Some of the more interesting fea- tures of MC are described in detail, including some new ideas for topology and geometry representation in simplex meshes, and an unusual partition of unity-based method for exploit- ing parallel computers. A short example is then given which involves the Hamiltonian and momentum constraints in the Einstein equations, a representative nonlinear 4-component co- variant elliptic system on a Riemannian 3-manifold which arises in general relativity. A num- ber of operator properties and solvability results recently established in [55] are first summa- rized, making possible two quasi-optimal a priori error estimates for Galerkin approximations which are then derived. These two results complete the theoretical framework for effective use of adaptive multilevel finite element methods. A sample calculation using the MC soft- ware is then presented; more detailed examples using MC for this application may be found in [26].},
	author = {Holst, Michael},
	journal = {Advances in Computational Mathematics},
	pages = {139--191},
	title = {Adaptive Numerical Treatment of Elliptic Systems on Manifolds},
	volume = {15},
	year = {2001}}

@inproceedings{hsiehDualCoordinateDescent2008,
	abstract = {In many applications, data appear with a huge number of instances as well as features. Linear Support Vector Machines (SVM) is one of the most popular tools to deal with such large-scale sparse data. This paper presents a novel dual coordinate descent method for linear SVM with L1- and L2loss functions. The proposed method is simple and reaches an -accurate solution in O(log(1/ )) iterations. Experiments indicate that our method is much faster than state of the art solvers such as Pegasos, TRON, SVMperf , and a recent primal coordinate descent implementation.},
	address = {{Helsinki, Finland}},
	annotation = {ZSCC: 0001031},
	author = {Hsieh, Cho-Jui and Chang, Kai-Wei and Lin, Chih-Jen and Keerthi, S. Sathiya and Sundararajan, S.},
	booktitle = {Proceedings of the 25th International Conference on {{Machine}} Learning - {{ICML}} '08},
	doi = {10.1145/1390156.1390208},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Hsieh et al. - 2008 - A dual coordinate descent method for large-scale l.pdf},
	isbn = {978-1-60558-205-4},
	langid = {english},
	pages = {408--415},
	publisher = {{ACM Press}},
	title = {A Dual Coordinate Descent Method for Large-Scale Linear {{SVM}}},
	year = {2008},
	bdsk-url-1 = {https://doi.org/10.1145/1390156.1390208}}

@article{Hua,
	annotation = {00000},
	author = {Hu, Xiaozhe},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/Hu - Math 150 Numerical Optimization Large-Scale Opt.pdf},
	langid = {english},
	pages = {98},
	title = {Math 150: {{Numerical Optimization}} {{Large-Scale Optimization}}}}

@article{huDissipativityTheoryNesterov,
	abstract = {In this paper, we adapt the control theoretic concept of dissipativity theory to provide a natural understanding of Nesterov's accelerated method. Our theory ties rigorous convergence rate analysis to the physically intuitive notion of energy dissipation. Moreover, dissipativity allows one to efficiently construct Lyapunov functions (either numerically or analytically) by solving a small semidefinite program. Using novel supply rate functions, we show how to recover known rate bounds for Nesterov's method and we generalize the approach to certify both linear and sublinear rates in a variety of settings. Finally, we link the continuous-time version of dissipativity to recent works on algorithm analysis that use discretizations of ordinary differential equations.},
	annotation = {00040},
	author = {Hu, Bin and Lessard, Laurent},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/ControlTheory/Hu and Lessard - Dissipativity Theory for Nesterov's Accelerated Me.pdf},
	langid = {english},
	pages = {9},
	title = {Dissipativity {{Theory}} for {{Nesterov}}'s {{Accelerated Method}}}}

@article{HuSeilerRantzer,
	abstract = {We develop a simple routine unifying the analysis of several important recently-developed stochastic optimization methods including SAGA, Finito, and stochastic dual coordinate ascent (SDCA). First, we show an intrinsic connection between stochastic optimization methods and dynamic jump systems, and propose a general jump system model for stochastic optimization methods. Our proposed model recovers SAGA, SDCA, Finito, and SAG as special cases. Then we combine jump system theory with several simple quadratic inequalities to derive sufficient conditions for convergence rate certifications of the proposed jump system model under various assumptions (with or without individual convexity, etc). The derived conditions are linear matrix inequalities (LMIs) whose size roughly scale with the size of the training set. We make use of the symmetry in the stochastic optimization methods and reduce these LMIs to some equivalent small LMIs whose sizes are at most 3 \texttimes{} 3. We solve these small LMIs to provide analytical proofs of new convergence rates for SAGA, Finito and SDCA (with or without individual convexity). We also explain why our proposed LMI fails in analyzing SAG. We reveal a key difference between SAG and other methods, and briefly discuss how to extend our LMI analysis for SAG. An advantage of our approach is that the proposed analysis can be automated for a large class of stochastic methods under various assumptions (with or without individual convexity, etc).},
	annotation = {00010},
	author = {Hu, Bin and Seiler, Peter and Rantzer, Anders},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/ControlTheory/Hu et al. - A Unified Analysis of Stochastic Optimization Metho.pdf},
	langid = {english},
	pages = {33},
	title = {A {{Unified Analysis}} of {{Stochastic Optimization Methods Using Jump System Theory}} and {{Quadratic Constraints}}}}

@article{HuSyed2019,
	abstract = {In this paper, we provide a unified analysis of temporal difference learning algorithms with linear function approximators by exploiting their connections to Markov jump linear systems (MJLS). We tailor the MJLS theory developed in the control community to characterize the exact behaviors of the first and second order moments of a large family of temporal difference learning algorithms. For both the IID and Markov noise cases, we show that the evolution of some augmented versions of the mean and covariance matrix of TD learning exactly follows the trajectory of a deterministic linear time-invariant (LTI) dynamical system. Applying the well-known LTI system theory, we obtain closed-form expressions for the mean and covariance matrix of TD learning at any time step. We provide a tight matrix spectral radius condition to guarantee the convergence of the covariance matrix of TD learning, and perform a perturbation analysis to characterize the dependence of the TD behaviors on learning rate. For the IID case, we provide an exact formula characterizing how the mean and covariance matrix of TD learning converge to the steady state values at a linear rate. For the Markov case, we use our formulas to explain how the behaviors of TD learning algorithms are affected by learning rate and various properties of the underlying Markov chain.},
	annotation = {00000},
	archiveprefix = {arXiv},
	author = {Hu, Bin and Syed, Usman Ahmed},
	eprint = {1906.06781},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/ControlTheory/Hu and Syed - 2019 - Characterizing the Exact Behaviors of Temporal Dif.pdf},
	journal = {arXiv:1906.06781 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
	langid = {english},
	month = jun,
	primaryclass = {cs, math, stat},
	title = {Characterizing the {{Exact Behaviors}} of {{Temporal Difference Learning Algorithms Using Markov Jump Linear System Theory}}},
	year = {2019}}

@article{HuWrightLessard2018,
	abstract = {Techniques for reducing the variance of gradient estimates used in stochastic programming algorithms for convex finite-sum problems have received a great deal of attention in recent years. By leveraging dissipativity theory from control, we provide a new perspective on two important variance-reduction algorithms: SVRG and its direct accelerated variant Katyusha. Our perspective provides a physically intuitive understanding of the behavior of SVRG-like methods via a principle of energy conservation. The tools discussed here allow us to automate the convergence analysis of SVRG-like methods by capturing their essential properties in small semidefinite programs amenable to standard analysis and computational techniques. Our approach recovers existing convergence results for SVRG and Katyusha and generalizes the theory to alternative parameter choices. We also discuss how our approach complements the linear coupling technique. Our combination of perspectives leads to a better understanding of accelerated variance-reduced stochastic methods for finite-sum problems.},
	annotation = {00010},
	archiveprefix = {arXiv},
	author = {Hu, Bin and Wright, Stephen and Lessard, Laurent},
	eprint = {1806.03677},
	eprinttype = {arxiv},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/SGD/Hu et al. - 2018 - Dissipativity Theory for Accelerating Stochastic V.pdf},
	journal = {arXiv:1806.03677 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
	langid = {english},
	month = jun,
	primaryclass = {cs, math, stat},
	shorttitle = {Dissipativity {{Theory}} for {{Accelerating Stochastic Variance Reduction}}},
	title = {Dissipativity {{Theory}} for {{Accelerating Stochastic Variance Reduction}}: {{A Unified Analysis}} of {{SVRG}} and {{Katyusha Using Semidefinite Programs}}},
	year = {2018}}

@article{jacobsSolvingLargescaleOptimization2018,
	author = {Jacobs, Matt and Li, Wuchen and Eger, Flavien L and Osher, Stanley},
	file = {/Volumes/GoogleDrive/My Drive/biblib/Papers/Jacobs et al/Unknown/Jacobs et al. - 2018 - Solving large-scale optimization problems with a convergence rate independent of grid size .pdf},
	keywords = {1,49m29,65k10,algorithm,ams subject classifications,earth mover,go09,grid size independence,has been an explosion,in recent years there,introduction,of interest,optimal transport,primal-dual,s distance,total variation denoising},
	pages = {1--25},
	title = {Solving Large-Scale Optimization Problems with a Convergence Rate Independent of Grid Size {${_\ast}$}},
	year = {2018}}

@article{JohnsonZhang2013,
	author = {Johnson, Rie and Zhang, Tong},
	file = {/Volumes/GoogleDrive/My Drive/biblib/Papers/Johnson, Zhang/Advances in neural information processing systems/Johnson, Zhang - 2013 - Accelerating Stochastic Gradient Descent using Predictive Variance Reduction.pdf},
	journal = {Advances in neural information processing systems},
	pages = {315--323},
	title = {Accelerating {{Stochastic Gradient Descent}} Using {{Predictive Variance Reduction}}},
	year = {2013}}

@article{JohnstoneMoulin,
	abstract = {In this paper, we conduct a novel Lyapunov analysis of the Fast Iterative Soft Thresholding Algorithm (FISTA) and derive a local linear convergence rate for the special case of sparse optimization. The Lyapunov analysis allows us to determine conditions on the parameters which are sufficient for the weak convergence of the iterates to a minimizer in a real Hilbert space (strong convergence in Rn). Our results apply to a modified version of the sequence of momentum parameters proposed by Beck and Teboulle [1], for which convergence of the iterates is unknown. The Lyapunov analysis also allows us to prove local linear convergence of FISTA for sparse ( 1-regularized) optimization problems. We generalize the analysis by Hale et al. [2] for the Iterative Soft Thresholding Algorithm (ISTA) to FISTA by computing analogous bounds on the number of iterations until convergence to the optimal manifold and determining the local linear convergence rate. Our results show that the classical [1] and recent [3] choices for the momentum parameter are not the best for sparse optimization in terms of the local convergence rate.},
	annotation = {00010},
	author = {Johnstone, Patrick R and Moulin, Pierre},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/Research/ode2opt/references/Johnstone and Moulin - A LYAPUNOV ANALYSIS OF FISTA WITH LOCAL LINEAR CON.pdf},
	langid = {english},
	pages = {19},
	title = {A {{Lyapunov Analysis}} of {{FISTA}} with {{Local Linear Convergence}} for {{Sparse Optimization}}}}

@article{Jones,
	annotation = {00000},
	author = {Jones, Corinne},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/CRNewton/Jones - Implementing the cubic and adaptive cubic regulari.pdf},
	langid = {english},
	pages = {9},
	title = {Implementing the Cubic and Adaptive Cubic Regularization Algorithms}}

@inproceedings{Jordan2019,
	abstract = {Our topic is the relationship between dynamical systems and optimization. This is a venerable, vast area in mathematics, counting among its many historical threads the study of gradient flow and the variational perspective on mechanics. We aim to build some new connections in this general area, studying aspects of gradient-based optimization from a continuous-time, variational point of view. We go beyond classical gradient flow to focus on second-order dynamics, aiming to show the relevance of such dynamics to optimization algorithms that not only converge, but converge quickly.},
	address = {{Rio de Janeiro, Brazil}},
	annotation = {00002},
	author = {Jordan, Michael I.},
	booktitle = {Proceedings of the {{International Congress}} of {{Mathematicians}} ({{ICM}} 2018)},
	doi = {10.1142/9789813272880_0022},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/ODE/Jordan - 2019 - DYNAMICAL, SYMPLECTIC AND STOCHASTIC PERSPECTIVES .pdf},
	isbn = {978-981-327-287-3 978-981-327-288-0},
	langid = {english},
	month = may,
	pages = {523--549},
	publisher = {{WORLD SCIENTIFIC}},
	title = {Dynamical, {{Symplectic}} and {{Stochastic Perspectives}} on {{Gradient-Based Optimization}}},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1142/9789813272880_0022}}

@article{Karatson.J;Farago.I2004,
	author = {Kar{\'a}tson, J and Farag{\'o}, I},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/An, Anos, Atson/Unknown/An, Anos, Atson - 2003 - Variable preconditioning via quasi-Newton methods for nonlinear problems in Hilbert space.pdf},
	ids = {An2003},
	issn = {0036-1429},
	journal = {SIAM journal on numerical analysis},
	keywords = {10,1137,35j65,65j15,ams subject classifications,doi,iterative methods in hilbert,nonlinear elliptic problems,quasi-newton methods,s0036142901384277,space,variable preconditioning},
	pages = {1242--1262},
	publisher = {{JSTOR}},
	title = {Variable Preconditioning via Quasi-{{Newton}} Methods for Nonlinear Problems in {{Hilbert}} Space},
	year = {2004}}

@article{Kasai,
	annotation = {00002},
	author = {Kasai, Hiroyuki},
	file = {/Users/longchen1/Zotero/storage/IHNVK7KQ/Kasai - SGDLibrary A MATLAB library for stochastic optimi.pdf},
	langid = {english},
	pages = {5},
	title = {{{SGDLibrary}}: {{A MATLAB}} Library for Stochastic Optimization Algorithms}}

@article{Keyes2006,
	abstract = {Computational scientists are grappling with increasingly complex, multi-rate applications that couple such physical phenomena as fluid dynamics, electromagnetics, radiation transport, chemical and nuclear reactions, and wave and material propagation in inhomogeneous media. Parallel computers with large storage capacities are paving the way for high-resolution simulations of coupled problems; however, hardware improvements alone will not prove enough to enable simulations based on brute-force algorithmic approaches. To accurately capture nonlinear couplings between dynamically relevant phenomena, often while stepping over rapid adjustments to quasi-equilibria, simulation scientists are increasingly turning to implicit formulations that require a discrete nonlinear system to be solved for each time step or steady state solution. Recent advances in iterative methods have made fully implicit formulations a viable option for solution of these large-scale problems. In this paper, we overview one of the most effective iterative methods, Newton-Krylov, for nonlinear systems and point to software packages with its implementation. We illustrate the method with an example from magnetically confined plasma fusion and briefly survey other areas in which implicit methods have bestowed important advantages, such as allowing high-order temporal integration and providing a pathway to sensitivity analyses and optimization. Lastly, we overview algorithm extensions under development motivated by current SciDAC applications.},
	author = {Keyes, David E and Reynolds, Daniel R and Woodward, Carol S},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/Keyes, Reynolds, Woodward/J. Phys. Conf. Ser/Keyes, Reynolds, Woodward - 2006 - Implicit solvers for large-scale nonlinear problems.pdf},
	issn = {1742-6588},
	journal = {J. Phys. Conf. Ser.},
	pages = {433--442},
	title = {Implicit Solvers for Large-Scale Nonlinear Problems},
	volume = {46},
	year = {2006}}

@article{KimFessler2018,
	abstract = {This paper provides a new way of developing the fast iterative shrinkage/thresholding algorithm (FISTA) [A. Beck and M. Teboulle, SIAM J. Imaging Sci., 2 (2009), pp. 183\textendash 202] that is widely used for minimizing composite convex functions with a nonsmooth term such as the 1 regularizer. In particular, this paper shows that FISTA corresponds to an optimized approach to accelerating the proximal gradient method with respect to a worst-case bound of the cost function. This paper then proposes a new algorithm that is derived by instead optimizing the step coefficients of the proximal gradient method with respect to a worst-case bound of the composite gradient mapping. The proof is based on the worst-case analysis called the performance estimation problem in [Y. Drori and M. Teboulle, Math. Program., 145 (2014), pp. 451\textendash 482].},
	annotation = {00007},
	author = {Kim, Donghwan and Fessler, Jeffrey A.},
	doi = {10.1137/16M108940X},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/Research/ode2opt/references/Kim and Fessler - 2018 - Another Look at the Fast Iterative ShrinkageThres.pdf},
	issn = {1052-6234, 1095-7189},
	journal = {SIAM Journal on Optimization},
	langid = {english},
	month = jan,
	number = {1},
	pages = {223--250},
	title = {Another {{Look}} at the {{Fast Iterative Shrinkage}}/{{Thresholding Algorithm}} ({{FISTA}})},
	volume = {28},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1137/16M108940X}}

@article{KohlerLucchi,
	abstract = {We consider the minimization of non-convex functions that typically arise in machine learning. Specifically, we focus our attention on a variant of trust region methods known as cubic regularization. This approach is particularly attractive because it escapes strict saddle points and it provides stronger convergence guarantees than first- and second-order as well as classical trust region methods. However, it suffers from a high computational complexity that makes it impractical for large-scale learning. Here, we propose a novel method that uses sub-sampling to lower this computational cost. By the use of concentration inequalities we provide a sampling scheme that gives sufficiently accurate gradient and Hessian approximations to retain the strong global and local convergence guarantees of cubically regularized methods. To the best of our knowledge this is the first work that gives global convergence guarantees for a sub-sampled variant of cubic regularization on non-convex functions. Furthermore, we provide experimental results supporting our theory.},
	annotation = {00079},
	author = {Kohler, Jonas Moritz and Lucchi, Aurelien},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/CRNewton/Kohler and Lucchi - Sub-sampled Cubic Regularization for Non-convex Op.pdf},
	journal = {convex Optimization},
	langid = {english},
	pages = {10},
	title = {Sub-Sampled {{Cubic Regularization}} for {{Non-convex Optimization}}}}

@article{Kone2017,
	archiveprefix = {arXiv},
	author = {Kone, Jakub},
	eprint = {1707.01155v1},
	eprinttype = {arxiv},
	file = {/Volumes/GoogleDrive/My Drive/biblib/Papers/Kone/Unknown/Kone - 2017 - Stochastic, Distributed and Federated Optimization for Machine Learning.pdf},
	title = {Stochastic, {{Distributed}} and {{Federated Optimization}} for {{Machine Learning}}},
	year = {2017}}

@article{KonecnyLiuRichtarikTakac2016,
	author = {Kone{\v c}n{\'y}, Jakub and Liu, Jie and Richt{\'a}rik, Peter and Tak{\'a}{\v c}, Martin},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Mini-batch semi-stochastic gradient descent in the proximal setting-2016-Konecny\;Liu\;Richtarik\;Takac.pdf},
	number = {2},
	pages = {242--255},
	title = {Mini-{{Batch Semi-Stochastic Gradient Descent}} in the {{Proximal Setting}}},
	volume = {10},
	year = {2016}}

@article{konecnySemiStochasticGradientDescent2017,
	abstract = {In this paper we study the problem of minimizing the average of a large number (n) of smooth convex loss functions. We propose a new method, S2GD (Semi-Stochastic Gradient Descent), which runs for one or several epochs in each of which a single full gradient and a random number of stochastic gradients is computed, following a geometric law. The total work needed for the method to output an {$\epsilon$}-accurate solution in expectation, measured in the number of passes over data, or equivalently, in units equivalent to the computation of a single gradient of the loss, is O(({$\kappa$}/n) log(1/{$\epsilon$})), where {$\kappa$} is the condition number. This is achieved by running the method for O(log(1/{$\epsilon$})) epochs, with a single gradient evaluation and O({$\kappa$}) stochastic gradient evaluations in each. The SVRG method of Johnson and Zhang [3] arises as a special case. If our method is limited to a single epoch only, it needs to evaluate at most O(({$\kappa$}/{$\epsilon$}) log(1/{$\epsilon$})) stochastic gradients. In contrast, SVRG requires O({$\kappa$}/{$\epsilon$}2) stochastic gradients. To illustrate our theoretical results, S2GD only needs the workload equivalent to about 2.1 full gradient evaluations to find an 10-6-accurate solution for a problem with n = 109 and {$\kappa$} = 103.},
	annotation = {ZSCC: 0000062},
	author = {Kone{\v c}n{\'y}, Jakub and Richt{\'a}rik, Peter},
	doi = {10.3389/fams.2017.00009},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Kone{\v c}n{\'y} and Richt{\'a}rik - 2017 - Semi-Stochastic Gradient Descent Methods.pdf},
	issn = {2297-4687},
	journal = {Frontiers in Applied Mathematics and Statistics},
	langid = {english},
	month = may,
	pages = {9},
	title = {Semi-{{Stochastic Gradient Descent Methods}}},
	volume = {3},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.3389/fams.2017.00009}}

@article{konecnyStochasticDistributedFederated2017,
	abstract = {We study optimization algorithms for the finite sum problems frequently arising in machine learning applications. First, we propose novel variants of stochastic gradient descent with a variance reduction property that enables linear convergence for strongly convex objectives. Second, we study distributed setting, in which the data describing the optimization problem does not fit into a single computing node. In this case, traditional methods are inefficient, as the communication costs inherent in distributed optimization become the bottleneck. We propose a communication-efficient framework which iteratively forms local subproblems that can be solved with arbitrary local optimization algorithms. Finally, we introduce the concept of Federated Optimization/Learning, where we try to solve the machine learning problems without having data stored in any centralized manner. The main motivation comes from industry when handling user-generated data. The current prevalent practice is that companies collect vast amounts of user data and store them in datacenters. An alternative we propose is not to collect the data in first place, and instead occasionally use the computational power of users' devices to solve the very same optimization problems, while alleviating privacy concerns at the same time. In such setting, minimization of communication rounds is the primary goal, and we demonstrate that solving the optimization problems in such circumstances is conceptually tractable.},
	annotation = {ZSCC: 0000030},
	archiveprefix = {arXiv},
	author = {Kone{\v c}n{\'y}, Jakub},
	eprint = {1707.01155},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Kone{\v c}n{\'y} - 2017 - Stochastic, Distributed and Federated Optimization.pdf},
	journal = {arXiv:1707.01155 [cs]},
	keywords = {Computer Science - Machine Learning},
	langid = {english},
	month = jul,
	primaryclass = {cs},
	title = {Stochastic, {{Distributed}} and {{Federated Optimization}} for {{Machine Learning}}},
	year = {2017}}

@article{KricheneBayenBartlett2015,
	abstract = {We study accelerated mirror descent dynamics in continuous and discrete time. Combining the original continuous-time motivation of mirror descent with a recent ODE interpretation of Nesterov's accelerated method, we propose a family of continuous-time descent dynamics for convex functions with Lipschitz gradients, such that the solution trajectories converge to the optimum at a O(1/t2) rate. We then show that a large family of first-order accelerated methods can be obtained as a discretization of the ODE, and these methods converge at a O(1/k2) rate. This connection between accelerated mirror descent and the ODE provides an intuitive approach to the design and analysis of accelerated first-order algorithms.},
	annotation = {00080},
	author = {Krichene, Walid and Bayen, Alexandre M and Bartlett, Peter L},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/ODE/Krichene et al. - Accelerated Mirror Descent in Continuous and Discr.pdf},
	journal = {Advances in Neural Information Processing Systems},
	langid = {english},
	pages = {2845--2853},
	title = {Accelerated {{Mirror Descent}} in {{Continuous}} and {{Discrete Time}}},
	year = {2015}}

@article{lacoste-julienGlobalLinearConvergence,
	archiveprefix = {arXiv},
	author = {{Lacoste-julien}, Simon and Jaggi, Martin},
	eprint = {1511.05932v1},
	eprinttype = {arxiv},
	file = {/Volumes/GoogleDrive/My Drive/biblib/Papers/Lacoste-julien, Jaggi/Unknown/Lacoste-julien, Jaggi - Unknown - On the Global Linear Convergence of Frank-Wolfe Optimization Variants.pdf},
	pages = {1--26},
	title = {On the {{Global Linear Convergence}} of {{Frank-Wolfe Optimization Variants}}}}

@article{laleeImplementationAlgorithmLargeScale1998,
	abstract = {This paper describes a software implementation of Byrd and Omojokun's trust region algorithm for solving nonlinear equality constrained optimization problems. The code is designed for the efficient solution of large problems and provides the user with a variety of linear algebra techniques for solving the subproblems occurring in the algorithm. Second derivative information can be used, but when it is not available, limited memory quasi-Newton approximations are made. The performance of the code is studied using a set of difficult test problems from the CUTE collection.},
	annotation = {00127},
	author = {Lalee, M. and Nocedal, J. and Plantenga, T.},
	doi = {10.1137/S1052623493262993},
	file = {/Users/longchen1/Zotero/storage/6Q5MU6N3/Lalee et al. - 1998 - On the Implementation of an Algorithm for Large-Sc.pdf;/Users/longchen1/Zotero/storage/5ZDM9QSP/S1052623493262993.html},
	issn = {1052-6234},
	journal = {SIAM Journal on Optimization},
	month = aug,
	number = {3},
	pages = {682--706},
	title = {On the {{Implementation}} of an {{Algorithm}} for {{Large-Scale Equality Constrained Optimization}}},
	volume = {8},
	year = {1998},
	bdsk-url-1 = {https://doi.org/10.1137/S1052623493262993}}

@article{laudeBregmanProximalMappings2020,
	abstract = {We systematically study the local single-valuedness of the Bregman proximal mapping and local smoothness of the Bregman\textendash Moreau envelope under relative prox-regularity, an extension of prox-regularity for nonconvex functions which has been originally introduced by Poliquin and Rockafellar. Although, we focus on the left Bregman proximal mapping, a translation result yields analogue (and partially sharp) results for the right Bregman proximal mapping. The class of relatively prox-regular functions significantly extends the recently considered class of relatively hypoconvex functions. In particular, relative prox-regularity allows for functions with possibly nonconvex domain. Moreover, as a main source of examples, in analogy to the classical setting, we introduce relatively amenable functions by invoking the recently proposed notion of smooth adaptability or relative smoothness. Exemplarily we apply our theory to interpret joint alternating Bregman minimization with proximal regularization, locally, as a Bregman proximal gradient algorithm.},
	annotation = {ZSCC: 0000009},
	archiveprefix = {arXiv},
	author = {Laude, Emanuel and Ochs, Peter and Cremers, Daniel},
	eprint = {1907.04306},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/Bregman/Laude et al. - 2020 - Bregman Proximal Mappings and Bregman-Moreau Envel.pdf},
	journal = {arXiv:1907.04306 [math]},
	keywords = {Mathematics - Optimization and Control},
	langid = {english},
	month = jan,
	primaryclass = {math},
	title = {Bregman {{Proximal Mappings}} and {{Bregman-Moreau Envelopes}} under {{Relative Prox-Regularity}}},
	year = {2020}}

@article{LeeWright2016,
	abstract = {Variants of the coordinate descent approach for minimizing a nonlinear function are distinguished in part by the order in which coordinates are considered for relaxation. Three common orderings are cyclic (CCD), in which we cycle through the components of \$x\$ in order; randomized (RCD), in which the component to update is selected randomly and independently at each iteration; and random-permutations cyclic (RPCD), which differs from CCD only in that a random permutation is applied to the variables at the start of each cycle. Known convergence guarantees are weaker for CCD and RPCD than for RCD, though in most practical cases, computational performance is similar among all these variants. There is a certain type of quadratic function for which CCD is significantly slower than for RCD; a recent paper by \textbackslash cite\{SunY16a\} has explored the poor behavior of CCD on functions of this type. The RPCD approach performs well on these functions, even better than RCD in a certain regime. This paper explains the good behavior of RPCD with a tight analysis.},
	annotation = {00009},
	archiveprefix = {arXiv},
	author = {Lee, Ching-Pei and Wright, Stephen J.},
	eprint = {1607.08320},
	eprinttype = {arxiv},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/BlockCoordinateDescent/Lee and Wright - 2016 - Random Permutations Fix a Worst Case for Cyclic Co.pdf},
	journal = {arXiv:1607.08320 [math]},
	keywords = {65F10; 90C25; 68W20,Mathematics - Optimization and Control},
	langid = {english},
	month = jul,
	primaryclass = {math},
	title = {Random {{Permutations Fix}} a {{Worst Case}} for {{Cyclic Coordinate Descent}}},
	year = {2016}}

@article{lessardAnalysisDesignOptimization2016,
	abstract = {This paper develops a new framework to analyze and design iterative optimization algorithms built on the notion of integral quadratic constraints (IQCs) from robust control theory. IQCs provide sufficient conditions for the stability of complicated interconnected systems, and these conditions can be checked by semidefinite programming. We discuss how to adapt IQC theory to study optimization algorithms, proving new inequalities about convex functions and providing a version of IQC theory adapted for use by optimization researchers. Using these inequalities, we derive numerical upper bounds on convergence rates for the Gradient method, the Heavy-ball method, Nesterov's accelerated method, and related variants by solving small, simple semidefinite programming problems. We also briefly show how these techniques can be used to search for optimization algorithms with desired performance characteristics, establishing a new methodology for algorithm design.},
	annotation = {00210},
	author = {Lessard, Laurent and Recht, Benjamin and Packard, Andrew},
	doi = {10.1137/15M1009597},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/ControlTheory/Lessard et al. - 2016 - Analysis and Design of Optimization Algorithms via.pdf},
	issn = {1052-6234, 1095-7189},
	journal = {SIAM Journal on Optimization},
	langid = {english},
	month = jan,
	number = {1},
	pages = {57--95},
	title = {Analysis and {{Design}} of {{Optimization Algorithms}} via {{Integral Quadratic Constraints}}},
	volume = {26},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.1137/15M1009597}}

@article{LeyfferMahajan,
	abstract = {We survey the foundations of nonlinearly constrained optimization methods, emphasizing general methods and highlighting their key components, namely, the local model and global convergence mechanism. We then categorize current software packages for solving constrained nonlinear optimization problems. The packages include interior-point methods, sequential linear/quadratic programming methods, and augmented Lagrangian methods. For every package we highlight the main methodological components and provide a brief summary of interfaces and availability. We also comment on termination conditions of nonlinear solvers and provide a list of online optimization tools.},
	annotation = {00034},
	author = {Leyffer, Sven and Mahajan, Ashutosh},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/Leyffer and Mahajan - Nonlinear Constrained Optimization Methods and So.pdf},
	langid = {english},
	pages = {34},
	title = {Nonlinear {{Constrained Optimization}}: {{Methods}} and {{Software}}}}

@article{liANALYSISINEXACTUZAWA2010,
	abstract = {Inexact Uzawa algorithms for solving nonlinear saddle-point problems are proposed. A simple sufficient condition for the convergence of the inexact Uzawa algorithms is obtained. Numerical experiments show that the inexact Uzawa algorithms are convergent.},
	annotation = {ZSCC: 0000002},
	author = {Li, Jian-Lei and Huang, Ting-Zhu and Li, Liang},
	doi = {10.1017/S1446181110000829},
	file = {/Users/longchen1/Dropbox/Math/Research/NonlinearSaddle/reference/Li et al. - 2010 - ANALYSIS OF THE INEXACT UZAWA ALGORITHMS FOR NONLI.pdf},
	issn = {1446-1811, 1446-8735},
	journal = {The ANZIAM Journal},
	langid = {english},
	month = jan,
	number = {3},
	pages = {369--382},
	title = {{{ANALYSIS OF THE INEXACT UZAWA ALGORITHMS FOR NONLINEAR SADDLE-POINT PROBLEMS}}},
	volume = {51},
	year = {2010},
	bdsk-url-1 = {https://doi.org/10.1017/S1446181110000829}}

@article{liaoHessianEigenspectraMore,
	abstract = {Given an optimization problem, the Hessian matrix and its eigenspectrum can be used in many ways, ranging from designing more efficient second-order algorithms to performing model analysis and regression diagnostics. When nonlinear models and non-convex problems are considered, strong simplifying assumptions are often made to make Hessian spectral analysis more tractable. This leads to the question of how relevant the conclusions of such analyses are for more realistic nonlinear models. In this paper, we exploit deterministic equivalent techniques from random matrix theory to make a precise characterization of the Hessian eigenspectra for a broad family of nonlinear models, including models that generalize the classical generalized linear models, without relying on strong simplifying assumptions used previously. We show that, depending on the data properties, the nonlinear response model, and the loss function, the Hessian can have qualitatively different spectral behaviors: of bounded or unbounded support, with single- or multi-bulk, and with isolated eigenvalues on the left- or right-hand side of the bulk. By focusing on such a simple but nontrivial nonlinear model, our analysis takes a step forward to unveil the theoretical origin of many visually striking features observed in more complex machine learning models.},
	annotation = {ZSCC: 0000000},
	author = {Liao, Zhenyu and Mahoney, Michael W},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/StochasticHessian/Liao and Mahoney - Hessian Eigenspectra of More Realistic Nonlinear M.pdf},
	langid = {english},
	pages = {30},
	title = {Hessian {{Eigenspectra}} of {{More Realistic Nonlinear Models}}}}

@article{linCatalystAccelerationFirstorder,
	abstract = {We introduce a generic scheme for accelerating gradient-based optimization methods in the sense of Nesterov. The approach, called Catalyst, builds upon the inexact accelerated proximal point algorithm for minimizing a convex objective function, and consists of approximately solving a sequence of well-chosen auxiliary problems, leading to faster convergence. One of the keys to achieve acceleration in theory and in practice is to solve these sub-problems with appropriate accuracy by using the right stopping criterion and the right warm-start strategy. We give practical guidelines to use Catalyst and present a comprehensive analysis of its global complexity. We show that Catalyst applies to a large class of algorithms, including gradient descent, block coordinate descent, incremental algorithms such as SAG, SAGA, SDCA, SVRG, MISO/Finito, and their proximal variants. For all of these methods, we establish faster rates using the Catalyst acceleration, for strongly convex and non-strongly convex objectives. We conclude with extensive experiments showing that acceleration is useful in practice, especially for ill-conditioned problems.},
	annotation = {ZSCC: 0000078},
	author = {Lin, Hongzhou and Mairal, Julien and Harchaoui, Zaid},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Lin et al. - Catalyst Acceleration for First-order Convex Optim.pdf},
	langid = {english},
	pages = {54},
	title = {Catalyst {{Acceleration}} for {{First-order Convex Optimization}}: From {{Theory}} to {{Practice}}}}

@article{linImprovedSampleComplexity2020,
	abstract = {We propose an accelerated stochastic compositional variance reduced gradient method for optimizing the sum of a composition function and a convex nonsmooth function. We provide an incremental first-order oracle (IFO) complexity analysis for the proposed algorithm and show that it is provably faster than all the existing methods. Indeed, we show that our method achieves an asymptotic IFO complexity of O (m + n) log (1/{$\epsilon$}) + 1/{$\epsilon$}3 where m and n are the number of inner/outer component functions, improving the best-known results of O m + n + (m + n)2/3/{$\epsilon$}2 and achieving for the best known linear run time for convex composition problem. Experiment results on sparse meanvariance optimization with 21 real-world financial datasets confirm that our method outperforms other competing methods.},
	annotation = {ZSCC: 0000001},
	archiveprefix = {arXiv},
	author = {Lin, Tianyi and Fan, Chenyou and Wang, Mengdi and Jordan, Michael I.},
	eprint = {1806.00458},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Lin et al. - 2020 - Improved Sample Complexity for Stochastic Composit.pdf},
	journal = {arXiv:1806.00458 [cs, math]},
	keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control},
	langid = {english},
	month = aug,
	primaryclass = {cs, math},
	title = {Improved {{Sample Complexity}} for {{Stochastic Compositional Variance Reduced Gradient}}},
	year = {2020}}

@article{LiSunToh2017,
	abstract = {We develop a fast and robust algorithm for solving large-scale convex composite optimization models with an emphasis on the 1-regularized least squares regression (lasso) problems. Despite the fact that there exist a large number of solvers in the literature for the lasso problems, we found that no solver can efficiently handle difficult large-scale regression problems with real data. By leveraging on available error bound results to realize the asymptotic superlinear convergence property of the augmented Lagrangian algorithm, and by exploiting the second order sparsity of the problem through the semismooth Newton method, we are able to propose an algorithm, called Ssnal, to efficiently solve the aforementioned difficult problems. Under very mild conditions, which hold automatically for lasso problems, both the primal and the dual iteration sequences generated by Ssnal possess a fast linear convergence rate, which can even be superlinear asymptotically. Numerical comparisons between our approach and a number of state-of-the-art solvers, on real data sets, are presented to demonstrate the high efficiency and robustness of our proposed algorithm in solving difficult large-scale lasso problems.},
	annotation = {00041},
	archiveprefix = {arXiv},
	author = {Li, Xudong and Sun, Defeng and Toh, Kim-Chuan},
	eprint = {1607.05428},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Zotero/storage/UYV2AHED/Li et al. - 2017 - A highly efficient semismooth Newton augmented Lag.pdf},
	journal = {arXiv:1607.05428 [math]},
	keywords = {65F10; 90C06; 90C25; 90C31,Mathematics - Optimization and Control},
	langid = {english},
	month = may,
	primaryclass = {math},
	title = {A Highly Efficient Semismooth {{Newton}} Augmented {{Lagrangian}} Method for Solving {{Lasso}} Problems},
	year = {2017}}

@article{LiTai,
	abstract = {We develop the method of stochastic modified equations (SME), in which stochastic gradient algorithms are approximated in the weak sense by continuous-time stochastic differential equations. We exploit the continuous formulation together with optimal control theory to derive novel adaptive hyper-parameter adjustment policies. Our algorithms have competitive performance with the added benefit of being robust to varying models and datasets. This provides a general methodology for the analysis and design of stochastic gradient algorithms.},
	annotation = {00089},
	author = {Li, Qianxiao and Tai, Cheng},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/SGD/Li and Tai - Stochastic Modified Equations and Adaptive Stocha.pdf},
	langid = {english},
	pages = {10},
	title = {Stochastic {{Modified Equations}} and {{Adaptive Stochastic Gradient Algorithms}}}}

@article{LiTaiE,
	abstract = {We develop the mathematical foundations of the stochastic modified equations (SME) framework for analyzing the dynamics of stochastic gradient algorithms, where the latter is approximated by a class of stochastic differential equations with small noise parameters. We prove that this approximation can be understood mathematically as an weak approximation, which leads to a number of precise and useful results on the approximations of stochastic gradient descent (SGD), momentum SGD and stochastic Nesterov's accelerated gradient method in the general setting of stochastic objectives. We also demonstrate through explicit calculations that this continuous-time approach can uncover important analytical insights into the stochastic gradient algorithms under consideration that may not be easy to obtain in a purely discrete-time setting.},
	annotation = {00017},
	author = {Li, Qianxiao and Tai, Cheng and E, Weinan},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/SGD/Li and Tai - Stochastic Modified Equations and Dynamics of Stoch.pdf},
	langid = {english},
	pages = {47},
	title = {Stochastic {{Modified Equations}} and {{Dynamics}} of {{Stochastic Gradient Algorithms I}}: {{Mathematical Foundations}}}}

@inproceedings{LiuShangJiao2019,
	abstract = {Recently, research on variance reduced incremental gradient descent methods (e.g., SAGA) has made exciting progress (e.g., linear convergence for strongly convex (SC) problems). However, existing accelerated methods (e.g., point-SAGA) suffer from drawbacks such as inflexibility. In this paper, we design a novel and simple momentum to accelerate the classical SAGA algorithm, and propose a direct accelerated incremental gradient descent algorithm. In particular, our theoretical result shows that our algorithm attains a best-known oracle complexity for SC minimization problems and an improved convergence rate for the case of n {$\geq$} L/\textmu. We also give experimental results justifying our theoretical results and showing the effectiveness of our algorithm.},
	address = {{Macao, China}},
	annotation = {00000},
	author = {Liu, Yuanyuan and Shang, Fanhua and Jiao, Licheng},
	booktitle = {Proceedings of the {{Twenty-Eighth International Joint Conference}} on {{Artificial Intelligence}}},
	doi = {10.24963/ijcai.2019/422},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/Acceleration/Liu et al. - 2019 - Accelerated Incremental Gradient Descent using Mom.pdf},
	isbn = {978-0-9992411-4-1},
	langid = {english},
	month = aug,
	pages = {3045--3051},
	publisher = {{International Joint Conferences on Artificial Intelligence Organization}},
	title = {Accelerated {{Incremental Gradient Descent}} Using {{Momentum Acceleration}} with {{Scaling Factor}}},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.24963/ijcai.2019/422}}

@article{LiuWright2015,
	abstract = {We describe an asynchronous parallel stochastic proximal coordinate descent algorithm for minimizing a composite objective function, which consists of a smooth convex function added to a separable convex function. In contrast to previous analyses, our model of asynchronous computation accounts for the fact that components of the unknown vector may be written by some cores simultaneously with being read by others. Despite the complications arising from this possibility, the method achieves a linear convergence rate on functions that satisfy an optimal strong convexity property and a sublinear rate (1/k) on general convex functions. Near-linear speedup on a multicore system can be expected if the number of processors is O(n1/4). We describe results from implementation on 10 cores of a multicore processor.},
	annotation = {00158},
	author = {Liu, Ji and Wright, Stephen J.},
	doi = {10.1137/140961134},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/BlockCoordinateDescent/Liu and Wright - 2015 - Asynchronous Stochastic Coordinate Descent Parall.pdf},
	issn = {1052-6234, 1095-7189},
	journal = {SIAM Journal on Optimization},
	langid = {english},
	month = jan,
	number = {1},
	pages = {351--376},
	shorttitle = {Asynchronous {{Stochastic Coordinate Descent}}},
	title = {Asynchronous {{Stochastic Coordinate Descent}}: {{Parallelism}} and {{Convergence Properties}}},
	volume = {25},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1137/140961134}}

@article{LiZhaoAroraLiuEtAl2017,
	annotation = {00001},
	author = {Li, Xingguo and Zhao, Tuo and Arora, Raman and Liu, Han and Hong, Mingyi},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/BlockCoordinateDescent/Li and Zhao - On Faster Convergence of Cyclic Block Coordinate D.pdf},
	journal = {The Journal of Machine Learning Research},
	number = {1},
	pages = {6741--6764},
	publisher = {JMLR. org},
	title = {On Faster Convergence of Cyclic Block Coordinate Descent-Type Methods for Strongly Convex Minimization},
	volume = {18},
	year = {2017}}

@article{locatelloRevisitingFirstOrderConvex,
	archiveprefix = {arXiv},
	author = {Locatello, Francesco and Raj, Anant and Karimireddy, Sai Praneeth and Gunnar, R and Sch, Bernhard and Stich, Sebastian U and Jaggi, Martin},
	eprint = {1803.09539v2},
	eprinttype = {arxiv},
	file = {/Volumes/GoogleDrive/My Drive/biblib/Papers/Locatello et al/Unknown/Locatello et al. - Unknown - Revisiting First-Order Convex Optimization Over Linear Spaces.pdf},
	pages = {1--24},
	title = {Revisiting {{First-Order Convex Optimization Over Linear Spaces}}}}

@article{Lu2015,
	abstract = {In this paper we consider the composite self-concordant (CSC) minimization problem, which minimizes the sum of a self-concordant function f and a (possibly nonsmooth) proper closed convex function g. The CSC minimization is the cornerstone of the path-following interior point methods for solving a broad class of convex optimization problems. It has also found numerous applications in machine learning. The proximal damped Newton (PDN) methods have been well studied in the literature for solving this problem that enjoy a nice iteration complexity. Given that at each iteration these methods typically require evaluating or accessing the Hessian of f and also need to solve a proximal Newton subproblem, the cost per iteration can be prohibitively high when applied to large-scale problems. Inspired by the recent success of block coordinate descent methods, we propose a randomized block proximal damped Newton (RBPDN) method for solving the CSC minimization. Compared to the PDN methods, the computational cost per iteration of RBPDN is usually significantly lower. The computational experiment on a class of regularized logistic regression problems demonstrate that RBPDN is indeed promising in solving large-scale CSC minimization problems. The convergence of RBPDN is also analyzed in the paper. In particular, we show that RBPDN is globally convergent when g is Lipschitz continuous. It is also shown that RBPDN enjoys a local linear convergence. Moreover, we establish a global linear rate of convergence for a class of g including the case where g is smooth (but not necessarily self-concordant) and {$\nabla$}g is Lipschitz continuous in a certain level set of f + g. As a consequence, we obtain a global linear rate of convergence for the classical damped Newton methods [Y. Nesterov, Introductory Lectures on Convex Optimization: A Basic Course, Kluwer, Boston, 2004; Y. Zhang and L. Xiao, preprint, arXiv:1501.00263, 2015] and the PDN [Q. Tran-Dinh, A. Kyrillidis, and V. Cevher, J. Mach. Learn. Res., 16 (2015), pp. 371\textendash 416] for such g, which was previously unknown in the literature. Moreover, this result can be used to sharpen the existing iteration complexity of these methods.},
	annotation = {00000},
	archiveprefix = {arXiv},
	author = {Lu, Zhaosong},
	eprint = {1501.00263},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Zotero/storage/F4TFJT9L/Lu - 2015 - Randomized Block Proximal Damped Newton Method For.pdf},
	journal = {arXiv:1501.00263 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
	langid = {english},
	month = jan,
	primaryclass = {cs, math, stat},
	title = {Randomized {{Block Proximal Damped Newton Method For Composite Self-Concordant Minimization}}},
	year = {2015}}

@article{luoDifferentialEquationSolvers2021a,
	abstract = {Convergence analyses of accelerated first-order methods for convex optimization problems are presented from the point of view of ordinary differential equation solvers. A new dynamical system, called Nesterov accelerated gradient flow, has been derived from the connection between acceleration mechanism and A-stability of ODE solvers, and the exponential decay of a tailored Lyapunov function along with the solution trajectory is proved. Numerical discretizations are then considered and convergence analyses are established via a unified discrete Lyapunov function. The proposed differential equation solver approach can not only cover existing accelerated methods, such as FISTA, Gu\textasciidieresis ler's new proximal algorithm and Nesterov's accelerated gradient method, but also produce new algorithms for solving composite convex optimization that possess accelerated convergence rates.},
	annotation = {ZSCC: 0000008},
	author = {Luo, Hao and Chen, Long},
	date-modified = {2024-02-19 21:34:29 -0800},
	file = {/Users/longchen1/Dropbox/Math/biblib/topics/ChenLong/Luo and Chen - 2021 - From differential equation solvers to accelerated .pdf},
	issn = {0025-5610, 1436-4646},
	journal = {Mathematical Programming},
	langid = {english},
	month = oct,
	pages = {735--781},
	title = {From Differential Equation Solvers to Accelerated First-Order Methods for Convex Optimization},
	volume = {195},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1007/s10107-021-01713-3}}

@article{LuoTseng1992,
	abstract = {The coordinate descent method enjoys a long history in convex differentiable minimization. Surprisingly, very little is known about the convergence of the iterates generated by this method. Convergence typically requires restrictive assumptions such as that the cost function has bounded level sets and is in some sense strictly convex. In a recent work, Luo and Tseng showed that the iterates are convergent for the symmetric monotone linear complementarity problem, for which the cost function is convex quadratic, but not necessarily strictly convex, and does not necessarily have bounded level sets. In this paper, we extend these results to problems for which the cost function is the composition of an affine mapping with a strictly convex function which is twice differentiable in its effective domain. In addition, we show that the convergence is at least linear. As a consequence of this result, we obtain, for the first time, that the dual iterates generated by a number of existing methods for matrix balancing and entropy optimization are linearly convergent.},
	annotation = {00441},
	author = {Luo, Z. Q. and Tseng, P.},
	doi = {10.1007/BF00939948},
	file = {/Users/longchen1/Zotero/storage/ZPAREWU9/Luo and Tseng - 1992 - On the convergence of the coordinate descent metho.pdf},
	issn = {0022-3239, 1573-2878},
	journal = {Journal of Optimization Theory and Applications},
	langid = {english},
	month = jan,
	number = {1},
	pages = {7--35},
	title = {On the Convergence of the Coordinate Descent Method for Convex Differentiable Minimization},
	volume = {72},
	year = {1992},
	bdsk-url-1 = {https://doi.org/10.1007/BF00939948}}

@article{LuoTseng1993,
	abstract = {We survey and extend a general approach to analyzing the convergence and the rate of convergenceof feasibledescentmethods that does not require any nondegeneracy assumption on the problem. This approach is based on a certain error bound for estimatingthe distance to the solution set and is applicableto a broad class of methods.},
	annotation = {00268},
	author = {Luo, Zhi-Quan and Tseng, Paul},
	doi = {10.1007/BF02096261},
	file = {/Users/longchen1/Zotero/storage/VX9WR4ZA/Luo and Tseng - 1993 - Error bounds and convergence analysis of feasible .pdf},
	issn = {0254-5330, 1572-9338},
	journal = {Annals of Operations Research},
	langid = {english},
	month = mar,
	number = {1},
	pages = {157--178},
	shorttitle = {Error Bounds and Convergence Analysis of Feasible Descent Methods},
	title = {Error Bounds and Convergence Analysis of Feasible Descent Methods: A General Approach},
	volume = {46--47},
	year = {1993},
	bdsk-url-1 = {https://doi.org/10.1007/BF02096261}}

@article{LuXiao2015,
	abstract = {In this paper we analyze the randomized block-coordinate descent (RBCD) methods proposed in Nesterov (SIAM J Optim 22(2):341\textendash 362, 2012), Richt\'arik and Tak\'ac\textasciicaron{} (Math Program 144(1\textendash 2):1\textendash 38, 2014) for minimizing the sum of a smooth convex function and a block-separable convex function, and derive improved bounds on their convergence rates. In particular, we extend Nesterov's technique developed in Nesterov (SIAM J Optim 22(2):341\textendash 362, 2012) for analyzing the RBCD method for minimizing a smooth convex function over a block-separable closed convex set to the aforementioned more general problem and obtain a sharper expected-value type of convergence rate than the one implied in Richt\'arik and Tak\'ac\textasciicaron{} (Math Program 144 (1\textendash 2):1\textendash 38, 2014). As a result, we also obtain a better high-probability type of iteration complexity. In addition, for unconstrained smooth convex minimization, we develop a new technique called randomized estimate sequence to analyze the accelerated RBCD method proposed by Nesterov (SIAM J Optim 22(2):341\textendash 362, 2012) and establish a sharper expected-value type of convergence rate than the one given in Nesterov (SIAM J Optim 22(2):341\textendash 362, 2012).},
	annotation = {00147},
	author = {Lu, Zhaosong and Xiao, Lin},
	doi = {10.1007/s10107-014-0800-2},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/BlockCoordinateDescent/Lu and Xiao - 2015 - On the complexity analysis of randomized block-coo.pdf},
	issn = {0025-5610, 1436-4646},
	journal = {Mathematical Programming},
	langid = {english},
	month = aug,
	number = {1-2},
	pages = {615--642},
	title = {On the Complexity Analysis of Randomized Block-Coordinate Descent Methods},
	volume = {152},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1007/s10107-014-0800-2}}

@article{mahoneyOvercomingInversionBias,
	annotation = {ZSCC: NoCitationData[s0]},
	author = {Mahoney, Michael W},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/StochasticHessian/Mahoney - Overcoming Inversion Bias in Distributed Newton's .pdf},
	langid = {english},
	pages = {26},
	title = {Overcoming {{Inversion Bias}} in {{Distributed Newton}}'s {{Method}}}}

@article{MaingeMoudafi2008,
	abstract = {We present iterative methods for finding the critical points and/or the minima of extended real valued functions of the form {$\varphi$} = {$\psi$}+g-h, where {$\psi$} is a differentiable function and g and h are convex, proper, and lower semicontinuous. The underlying idea relies upon the discretization of a first order dissipative dynamical system which allows us to preserve the local feature and to obtain some convergence results. The main theorems not only recover known convergence results in this field but also provide a theoretical basis for the development of new iterative methods.},
	annotation = {00032},
	author = {Maing{\'e}, Paul-Emile and Moudafi, Abdellatif},
	doi = {10.1137/060655183},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/ODE/Maing{\'e} and Moudafi - 2008 - Convergence of New Inertial Proximal Methods for D.pdf},
	issn = {1052-6234, 1095-7189},
	journal = {SIAM Journal on Optimization},
	langid = {english},
	month = jan,
	number = {1},
	pages = {397--413},
	title = {Convergence of {{New Inertial Proximal Methods}} for {{DC Programming}}},
	volume = {19},
	year = {2008},
	bdsk-url-1 = {https://doi.org/10.1137/060655183}}

@article{mandtStochasticGradientDescent,
	abstract = {Stochastic Gradient Descent with a constant learning rate (constant SGD) simulates a Markov chain with a stationary distribution. With this perspective, we derive several new results. (1) We show that constant SGD can be used as an approximate Bayesian posterior inference algorithm. Specifically, we show how to adjust the tuning parameters of constant SGD to best match the stationary distribution to a posterior, minimizing the Kullback-Leibler divergence between these two distributions. (2) We demonstrate that constant SGD gives rise to a new variational EM algorithm that optimizes hyperparameters in complex probabilistic models. (3) We also show how to tune SGD with momentum for approximate sampling. (4) We analyze stochastic-gradient MCMC algorithms. For Stochastic-Gradient Langevin Dynamics and Stochastic-Gradient Fisher Scoring, we quantify the approximation errors due to finite learning rates. Finally (5), we use the stochastic process perspective to give a short proof of why Polyak averaging is optimal. Based on this idea, we propose a scalable approximate MCMC algorithm, the Averaged Stochastic Gradient Sampler.},
	annotation = {ZSCC: 0000324},
	author = {Mandt, Stephan and Hoffman, Matthew D},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Mandt and Hoffman - Stochastic Gradient Descent as Approximate Bayesia.pdf},
	langid = {english},
	pages = {35},
	title = {Stochastic {{Gradient Descent}} as {{Approximate Bayesian Inference}}}}

@article{McLachlanQuispelRobidoux1999,
	annotation = {00000},
	author = {McLachlan, Robert I. and Quispel, G. R. W. and Robidoux, Nicolas},
	doi = {10.1098/rsta.1999.0363},
	editor = {Budd, C.J. and Iserles, A.},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/ODE/McLachlan et al. - 1999 - Geometric integration using discrete gradients.pdf},
	issn = {1364-503X, 1471-2962},
	journal = {Philosophical Transactions of the Royal Society of London. Series A: Mathematical, Physical and Engineering Sciences},
	langid = {english},
	month = apr,
	number = {1754},
	pages = {1021--1045},
	title = {Geometric Integration Using Discrete Gradients},
	volume = {357},
	year = {1999},
	bdsk-url-1 = {https://doi.org/10.1098/rsta.1999.0363}}

@article{milzarekSemismoothNewtonMethod2014,
	abstract = {Due to their property of enhancing the sparsity of solutions, l1-regularized optimization problems have developed into a highly dynamic research area with a wide range of applications. We present a class of methods for l1-regularized optimization problems that are based on a combination of semismooth Newton steps, a filter globalization, and shrinkage/thresholding steps. A multidimensional filter framework is used to control the acceptance and to evaluate the quality of the semismooth Newton steps. If the current Newton iterate is rejected a shrinkage/thresholdingbased step with quasi-Armijo stepsize rule is used instead. Global convergence and transition to local q-superlinear convergence for both convex and nonconvex objective functions are established. We present numerical results and comparisons with several state-of-the-art methods that show the efficiency and competitiveness of the proposed method.},
	annotation = {00042},
	author = {Milzarek, Andre and Ulbrich, Michael},
	doi = {10.1137/120892167},
	file = {/Users/longchen1/Zotero/storage/MIKR4TJV/Milzarek and Ulbrich - 2014 - A Semismooth Newton Method with Multidimensional F.pdf},
	issn = {1052-6234, 1095-7189},
	journal = {SIAM Journal on Optimization},
	langid = {english},
	month = jan,
	number = {1},
	pages = {298--333},
	title = {A {{Semismooth Newton Method}} with {{Multidimensional Filter Globalization}} for \$l\_1\$-{{Optimization}}},
	volume = {24},
	year = {2014},
	bdsk-url-1 = {https://doi.org/10.1137/120892167}}

@article{muehlebachOptimizationMomentumDynamical,
	abstract = {We analyze the convergence rate of various momentum-based optimization algorithms from a dynamical systems point of view. Our analysis exploits fundamental topological properties, such as the continuous dependence of iterates on their initial conditions, to provide a simple characterization of convergence rates. In many cases, closed-form expressions are obtained that relate algorithm parameters to the convergence rate. The analysis encompasses discrete time and continuous time, as well as time-invariant and time-variant formulations, and is not limited to a convex or Euclidean setting. In addition, the article rigorously establishes why symplectic discretization schemes are important for momentum-based optimization algorithms, and provides a characterization of algorithms that exhibit accelerated convergence.},
	annotation = {ZSCC: 0000007},
	author = {Muehlebach, Michael and Jordan, Michael I},
	file = {/Users/longchen1/Dropbox/Math/Research/Lyapunov_Framework/references/Muehlebach and Jordan - Optimization with Momentum Dynamical, Control-The.pdf},
	journal = {Journal of Machine Learning Research},
	langid = {english},
	pages = {50},
	title = {Optimization with {{Momentum}}: {{Dynamical}}, {{Control-Theoretic}}, and {{Symplectic Perspectives}}}}

@article{Nash2014,
	annotation = {00010},
	author = {Nash, Stephen G.},
	doi = {10.1080/10556788.2012.759571},
	file = {/Users/longchen1/Zotero/storage/QCISFV7S/Nash - 2014 - Properties of a class of multilevel optimization a.pdf;/Users/longchen1/Zotero/storage/SQEFSE7D/Nash - 2014 - Properties of a class of multilevel optimization a.pdf},
	issn = {1055-6788, 1029-4937},
	journal = {Optimization Methods and Software},
	langid = {english},
	month = jan,
	number = {1},
	pages = {137--159},
	title = {Properties of a Class of Multilevel Optimization Algorithms for Equality-Constrained Problems},
	volume = {29},
	year = {2014},
	bdsk-url-1 = {https://doi.org/10.1080/10556788.2012.759571}}

@article{NecoaraNesterovGlineur2018,
	abstract = {The standard assumption for proving linear convergence of first order methods for smooth convex optimization is the strong convexity of the objective function, an assumption which does not hold for many practical applications. In this paper, we derive linear convergence rates of several first order methods for solving smooth non-strongly convex constrained optimization problems, i.e. involving an objective function with a Lipschitz continuous gradient that satisfies some relaxed strong convexity condition. In particular, in the case of smooth constrained convex optimization, we provide several relaxations of the strong convexity conditions and prove that they are sufficient for getting linear convergence for several first order methods such as projected gradient, fast gradient and feasible descent methods. We also provide examples of functional classes that satisfy our proposed relaxations of strong convexity conditions. Finally, we show that the proposed relaxed strong convexity conditions cover important applications ranging from solving linear systems, Linear Programming, and dual formulations of linearly constrained convex problems.},
	annotation = {00072},
	author = {Necoara, I. and Nesterov, Yu. and Glineur, F.},
	doi = {10.1007/s10107-018-1232-1},
	file = {/Users/longchen1/Zotero/storage/5LP2K26W/Necoara et al. - 2018 - Linear convergence of first order methods for non-.pdf},
	issn = {0025-5610, 1436-4646},
	journal = {Mathematical Programming},
	langid = {english},
	month = jan,
	title = {Linear Convergence of First Order Methods for Non-Strongly Convex Optimization},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1007/s10107-018-1232-1}}

@article{needellStochasticGradientDescent2015,
	archiveprefix = {arXiv},
	author = {Needell, Deanna and Srebro, Nathan and Ward, Rachel},
	eprint = {1310.5715v5},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Needell et al. - 2016 - Stochastic gradient descent, weighted sampling, an.pdf;/Volumes/GoogleDrive/My Drive/biblib/Papers/Needell, Srebro, Ward/Unknown/Needell, Srebro, Ward - 2015 - Stochastic gradient descent, weighted sampling, and the randomized kaczmarz algorithm.pdf},
	ids = {needellStochasticGradientDescent2016},
	keywords = {distribution reweighting,importance sampling,kaczmarz method,stochastic gradient},
	pages = {1--23},
	title = {Stochastic Gradient Descent, Weighted Sampling, and the Randomized Kaczmarz Algorithm},
	year = {2015}}

@book{NemirovskyYudin1983,
	annotation = {00000},
	author = {Nemirovsky, Arkadii Semenovich and Yudin, David Borisovich},
	publisher = {{New York: John Wiley.}},
	title = {Problem Complexity and Method Efficiency in Optimization},
	year = {1983}}

@article{Nesterov2009,
	abstract = {In this paper we present a new approach for constructing subgradient schemes for different types of nonsmooth problems with convex structure. Our methods are primal-dual since they are always able to generate a feasible approximation to the optimum of an appropriately formulated dual problem. Besides other advantages, this useful feature provides the methods with a reliable stopping criterion. The proposed schemes differ from the classical approaches (divergent series methods, mirror descent methods) by presence of two control sequences. The first sequence is responsible for aggregating the support functions in the dual space, and the second one establishes a dynamically updated scale between the primal and dual spaces. This additional flexibility allows to guarantee a boundedness of the sequence of primal test points even in the case of unbounded feasible set (however, we always assume the uniform boundedness of subgradients). We present the variants of subgradient schemes for nonsmooth convex minimization, minimax problems, saddle point problems, variational inequalities, and stochastic optimization. In all situations our methods are proved to be optimal from the view point of worst-case black-box lower complexity bounds.},
	annotation = {00619},
	author = {Nesterov, Yurii},
	doi = {10.1007/s10107-007-0149-x},
	file = {/Users/longchen1/Zotero/storage/W338TNZL/Nesterov - 2009 - Primal-dual subgradient methods for convex problem.pdf},
	issn = {0025-5610, 1436-4646},
	journal = {Mathematical Programming},
	langid = {english},
	month = aug,
	number = {1},
	pages = {221--259},
	title = {Primal-Dual Subgradient Methods for Convex Problems},
	volume = {120},
	year = {2009},
	bdsk-url-1 = {https://doi.org/10.1007/s10107-007-0149-x}}

@article{Nesterov2012,
	abstract = {In this paper we propose new methods for solving huge-scale optimization problems. For problems of this size, even the simplest full-dimensional vector operations are very expensive. Hence, we propose to apply an optimization technique based on random partial update of decision variables. For these methods, we prove the global estimates for the rate of convergence. Surprisingly, for certain classes of objective functions, our results are better than the standard worst-case bounds for deterministic algorithms. We present constrained and unconstrained versions of the method and its accelerated variant. Our numerical test confirms a high efficiency of this technique on problems of very big size.},
	annotation = {00797},
	author = {Nesterov, Yu.},
	doi = {10.1137/100802001},
	file = {/Users/longchen1/Zotero/storage/WAYPBNTE/Nesterov - 2012 - Efficiency of Coordinate Descent Methods on Huge-S.pdf},
	issn = {1052-6234, 1095-7189},
	journal = {SIAM Journal on Optimization},
	langid = {english},
	month = jan,
	number = {2},
	pages = {341--362},
	title = {Efficiency of {{Coordinate Descent Methods}} on {{Huge-Scale Optimization Problems}}},
	volume = {22},
	year = {2012},
	bdsk-url-1 = {https://doi.org/10.1137/100802001}}

@article{NesterovPolyak2006,
	abstract = {In this paper, we provide theoretical analysis for a cubic regularization of Newton method as applied to unconstrained minimization problem. For this scheme, we prove general local convergence results. However, the main contribution of the paper is related to global worst-case complexity bounds for different problem classes including some nonconvex cases. It is shown that the search direction can be computed by standard linear algebra technique.},
	annotation = {00634},
	author = {Nesterov, Yurii and Polyak, B.T.},
	doi = {10.1007/s10107-006-0706-8},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/CRNewton/Nesterov and Polyak - 2006 - Cubic regularization of Newton method and its glob.pdf},
	issn = {0025-5610, 1436-4646},
	journal = {Mathematical Programming},
	langid = {english},
	month = aug,
	number = {1},
	pages = {177--205},
	title = {Cubic Regularization of {{Newton}} Method and Its Global Performance},
	volume = {108},
	year = {2006},
	bdsk-url-1 = {https://doi.org/10.1007/s10107-006-0706-8}}

@article{nesterovQuasimonotoneSubgradientMethods2015,
	abstract = {In this paper, we develop new subgradient methods for solving nonsmooth convex optimization problems. These methods guarantee the best possible rate of convergence for the whole sequence of test points. Our methods are applicable as efficient real-time stabilization tools for potential systems with infinite horizon. Preliminary numerical experiments confirm a high efficiency of the new schemes.},
	annotation = {00020},
	author = {Nesterov, Yu. and Shikhman, V.},
	doi = {10.1007/s10957-014-0677-5},
	file = {/Users/longchen1/Zotero/storage/PI3ABGG4/Nesterov and Shikhman - 2015 - Quasi-monotone Subgradient Methods for Nonsmooth C.pdf},
	issn = {0022-3239, 1573-2878},
	journal = {Journal of Optimization Theory and Applications},
	langid = {english},
	month = jun,
	number = {3},
	pages = {917--940},
	title = {Quasi-Monotone {{Subgradient Methods}} for {{Nonsmooth Convex Minimization}}},
	volume = {165},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1007/s10957-014-0677-5}}

@article{NesterovStich2017,
	abstract = {In this paper we prove a new complexity bound for a variant of the accelerated coordinate descent method [Yu. Nesterov, SIAM J. Optim., 22 (2012), pp. 341\textendash 362]. We show that this method often outperforms the standard fast gradient methods (FGM [Yu. Nesterov, Dokl. Akad. Nauk SSSR, 269 (1983), pp. 542\textendash 547; Math. Program. (A), 103 (2005), pp. 127\textendash 152]) on optimization problems with dense data. In many important situations, the computational expenses of oracle and method itself at each iteration of our scheme are perfectly balanced (both depend linearly on dimensions of the problem). As application examples, we consider unconstrained convex quadratic minimization and the problems arising in the smoothing technique [Nesterov, Math. Program. (A), 103 (2005), pp. 127\textendash 152]. On some special problem instances, the provable acceleration factor with respect to FGM can reach the square root of the number of variables. Our theoretical conclusions are confirmed by numerical experiments.},
	annotation = {00028},
	author = {Nesterov, Yurii and Stich, Sebastian U.},
	doi = {10.1137/16M1060182},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/BlockCoordinateDescent/Nesterov and Stich - 2017 - Efficiency of the Accelerated Coordinate Descent M.pdf},
	issn = {1052-6234, 1095-7189},
	journal = {SIAM Journal on Optimization},
	langid = {english},
	month = jan,
	number = {1},
	pages = {110--123},
	title = {Efficiency of the {{Accelerated Coordinate Descent Method}} on {{Structured Optimization Problems}}},
	volume = {27},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1137/16M1060182}}

@article{NguyenNguyenRichtarikScheinbergEtAl2018,
	abstract = {The classical convergence analysis of SGD is carried out under the assumption that the norm of the stochastic gradient is uniformly bounded. While this might hold for some loss functions, it is violated for cases where the objective function is strongly convex. In Bottou et al. (2016), a new analysis of convergence of SGD is performed under the assumption that stochastic gradients are bounded with respect to the true gradient norm. We show that for stochastic problems arising in machine learning such bound always holds; and we also propose an alternative convergence analysis of SGD with diminishing learning rate regime, which results in more relaxed conditions than those in Bottou et al. (2016). We then move on the asynchronous parallel setting, and prove convergence of Hogwild! algorithm in the same regime in the case of diminished learning rate. It is well-known that SGD converges if a sequence of learning rates \$\textbackslash\{\textbackslash eta\_t\textbackslash\}\$ satisfies \$\textbackslash sum\_\{t=0\}\^\textbackslash infty \textbackslash eta\_t \textbackslash rightarrow \textbackslash infty\$ and \$\textbackslash sum\_\{t=0\}\^\textbackslash infty \textbackslash eta\^2\_t {$<$} \textbackslash infty\$. We show the convergence of SGD for strongly convex objective function without using bounded gradient assumption when \$\textbackslash\{\textbackslash eta\_t\textbackslash\}\$ is a diminishing sequence and \$\textbackslash sum\_\{t=0\}\^\textbackslash infty \textbackslash eta\_t \textbackslash rightarrow \textbackslash infty\$. In other words, we extend the current state-of-the-art class of learning rates satisfying the convergence of SGD.},
	annotation = {00000},
	archiveprefix = {arXiv},
	author = {Nguyen, Lam M. and Nguyen, Phuong Ha and Richt{\'a}rik, Peter and Scheinberg, Katya and Tak{\'a}{\v c}, Martin and {van Dijk}, Marten},
	eprint = {1811.12403},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Zotero/storage/KAYJ46LE/Nguyen et al. - 2018 - New Convergence Aspects of Stochastic Gradient Alg.pdf;/Users/longchen1/Zotero/storage/BBWV7MSC/1811.html},
	journal = {arXiv:1811.12403 [cs, math]},
	keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control},
	month = nov,
	primaryclass = {cs, math},
	title = {New {{Convergence Aspects}} of {{Stochastic Gradient Algorithms}}},
	year = {2018}}

@article{nguyenSARAHNovelMethod2017,
	abstract = {In this paper, we propose a StochAstic Recursive grAdient algoritHm (SARAH), as well as its practical variant SARAH+, as a novel approach to the finite-sum minimization problems. Different from the vanilla SGD and other modern stochastic methods such as SVRG, S2GD, SAG and SAGA, SARAH admits a simple recursive framework for updating stochastic gradient estimates; when comparing to SAG/SAGA, SARAH does not require a storage of past gradients. The linear convergence rate of SARAH is proven under strong convexity assumption. We also prove a linear convergence rate (in the strongly convex case) for an inner loop of SARAH, the property that SVRG does not possess. Numerical experiments demonstrate the efficiency of our algorithm.},
	annotation = {ZSCC: 0000270},
	archiveprefix = {arXiv},
	author = {Nguyen, Lam M. and Liu, Jie and Scheinberg, Katya and Tak{\'a}{\v c}, Martin},
	eprint = {1703.00102},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Nguyen et al. - 2017 - SARAH A Novel Method for Machine Learning Problem.pdf},
	journal = {arXiv:1703.00102 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
	langid = {english},
	month = jun,
	primaryclass = {cs, math, stat},
	shorttitle = {{{SARAH}}},
	title = {{{SARAH}}: {{A Novel Method}} for {{Machine Learning Problems Using Stochastic Recursive Gradient}}},
	year = {2017}}

@article{niederlanderSecondOrderDynamicsHessianDriven2021,
	abstract = {In a real Hilbert space setting, we investigate the asymptotic properties of the solutions of a second-order differential system in view of linearly constrained convex minimization. The inertial dynamics are governed by a Hessian-driven damping term associated with the convex function to be minimized and potential effects induced by the linear constraints. We provide conditions on both the damping and the potential for which the solutions converge towards some feasible point of the convex minimization problem; this convergence is towards some minimizer provided that the solutions' initial data is specifically preselected. In addition, we present asymptotic estimates on the convergence rate of the solutions depending on the interaction between damping and potential effects. Our analysis is mainly based on energy-like arguments that capture the dissipative nature of the inertial dynamics by means of a Bregman distance. We complement our study with the fact that the second-order dynamics admit a first-order representation in terms of the Arrow--Hurwicz differential system. Numerical experiments further illustrate our theoretical findings.},
	annotation = {ZSCC: 0000000},
	author = {Niederl{\"a}nder, Simon K.},
	doi = {10.1137/20M1323679},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/ODE/Niederl{\"a}nder - 2021 - Second-Order Dynamics with Hessian-Driven Damping .pdf},
	issn = {0363-0129, 1095-7138},
	journal = {SIAM Journal on Control and Optimization},
	langid = {english},
	month = jan,
	number = {5},
	pages = {3708--3736},
	title = {Second-{{Order Dynamics}} with {{Hessian-Driven Damping}} for {{Linearly Constrained Convex Minimization}}},
	volume = {59},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1137/20M1323679}}

@article{nouiehedConvergenceSecondOrderStationarity2018,
	abstract = {We consider the problem of finding an approximate second-order stationary point of a constrained non-convex optimization problem. We first show that, unlike the unconstrained scenario, the vanilla projected gradient descent algorithm may converge to a strict saddle point even when there is only a single linear constraint. We then provide a hardness result by showing that checking ( g, H )-second order stationarity is NP-hard even in the presence of linear constraints. Despite our hardness result, we identify instances of the problem for which checking second order stationarity can be done efficiently. For such instances, we propose a dynamic second order Frank\textendash Wolfe algorithm which converges to ( g, H )-second order stationary points in O(max\{ g-2, -H3\}) iterations. The proposed algorithm can be used in general constrained non-convex optimization as long as the constrained quadratic subproblem can be solved efficiently.},
	annotation = {00000},
	archiveprefix = {arXiv},
	author = {Nouiehed, Maher and Lee, Jason D. and Razaviyayn, Meisam},
	eprint = {1810.02024},
	eprinttype = {arxiv},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/biblib/Zotero/Nouiehed et al. - 2018 - Convergence to Second-Order Stationarity for Const.pdf},
	journal = {arXiv:1810.02024 [math]},
	keywords = {Mathematics - Optimization and Control},
	langid = {english},
	month = oct,
	primaryclass = {math},
	title = {Convergence to {{Second-Order Stationarity}} for {{Constrained Non-Convex Optimization}}},
	year = {2018}}

@article{NutiniLaradjiSchmidt,
	abstract = {Block coordinate descent (BCD) methods are widely-used for large-scale numerical optimization because of their cheap iteration costs, low memory requirements, amenability to parallelization, and ability to exploit problem structure. Three main algorithmic choices influence the performance of BCD methods: the block partitioning strategy, the block selection rule, and the block update rule. In this paper we explore all three of these building blocks and propose variations for each that can lead to significantly faster BCD methods. We (i) propose new greedy block-selection strategies that guarantee more progress per iteration than the Gauss-Southwell rule; (ii) explore practical issues like how to implement the new rules when using ``variable'' blocks; (iii) explore the use of message-passing to compute matrix or Newton updates efficiently on huge blocks for problems with a sparse dependency between variables; and (iv) consider optimal active manifold identification, which leads to bounds on the ``active-set complexity'' of BCD methods and leads to superlinear convergence for certain problems with sparse solutions (and in some cases finite termination at an optimal solution). We support all of our findings with numerical results for the classic machine learning problems of least squares, logistic regression, multi-class logistic regression, label propagation, and L1-regularization.},
	annotation = {00003},
	author = {Nutini, Julie and Laradji, Issam and Schmidt, Mark},
	file = {/Users/longchen1/Zotero/storage/RYGCH2YN/Nutini et al. - Let's Make Block Coordinate Descent Go Fast Faste.pdf},
	langid = {english},
	pages = {50},
	title = {Let's {{Make Block Coordinate Descent Go Fast}}: {{Faster Greedy Rules}}, {{Message-Passing}}, {{Active-Set Complexity}}, and {{Superlinear Convergence}}}}

@article{ODonoghueCandes2015,
	abstract = {In this paper we introduce a simple heuristic adaptive restart technique that can dramatically improve the convergence rate of accelerated gradient schemes. The analysis of the technique relies on the observation that these schemes exhibit two modes of behavior depending on how much momentum is applied at each iteration. In what we refer to as the `high momentum' regime the iterates generated by an accelerated gradient scheme exhibit a periodic behavior, where the period is proportional to the square root of the local condition number of the objective function. Separately, it is known that the optimal restart interval is proportional to this same quantity. This suggests a restart technique whereby we reset the momentum whenever we observe periodic behavior. We provide a heuristic analysis that suggests that in many cases adaptively restarting allows us to recover the optimal rate of convergence with no prior knowledge of function parameters.},
	annotation = {00330},
	author = {O'Donoghue, Brendan and Cand{\`e}s, Emmanuel},
	doi = {10.1007/s10208-013-9150-3},
	file = {/Users/longchen1/Zotero/storage/A7SB44E7/O'Donoghue and Cand{\`e}s - 2015 - Adaptive Restart for Accelerated Gradient Schemes.pdf},
	issn = {1615-3383},
	journal = {Foundations of Computational Mathematics},
	keywords = {80M50,90C06,90C25,Accelerated gradient schemes,Convex optimization,First order methods},
	langid = {english},
	month = jun,
	number = {3},
	pages = {715--732},
	title = {Adaptive {{Restart}} for {{Accelerated Gradient Schemes}}},
	volume = {15},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1007/s10208-013-9150-3}}

@article{OgaltsovTyurin2020,
	abstract = {A fast adaptive heuristic stochastic gradient descent method is proposed. It is shown that this algorithm has a higher convergence rate in practical problems than currently popular optimization methods. Furthermore, a justification of this method is given, and difficulties that prevent obtaining optimal estimates for the proposed algorithm are described.},
	annotation = {00000},
	author = {Ogal'tsov, A. V. and Tyurin, A. I.},
	doi = {10.1134/S0965542520070088},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/SGD/Ogal'tsov and Tyurin - 2020 - A Heuristic Adaptive Fast Gradient Method in Stoch.pdf},
	issn = {0965-5425, 1555-6662},
	journal = {Computational Mathematics and Mathematical Physics},
	langid = {english},
	month = jul,
	number = {7},
	pages = {1108--1115},
	title = {A {{Heuristic Adaptive Fast Gradient Method}} in {{Stochastic Optimization Problems}}},
	volume = {60},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1134/S0965542520070088}}

@article{Ohmer2008,
	author = {Ohmer, Klaus B},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/Ohmer/Unknown/Ohmer - 2008 - ON FINITE ELEMENT METHODS FOR FULLY NONLINEAR.pdf},
	keywords = {c 1 finite elements,conforming,convergence,discrete newton,fully,locally quadratic convergence,method,nonconforming finite element method,nonlinear elliptic differential equations,not in divergence form,order 2,quasi-linear elliptic equations,r n,regularity for finite element,solutions,stability,variational crimes},
	number = {3},
	pages = {1212--1249},
	title = {{{ON FINITE ELEMENT METHODS FOR FULLY NONLINEAR}}},
	volume = {46},
	year = {2008}}

@article{oliveiraSumsRandomHermitian2010,
	abstract = {We give a new, elementary proof of a key inequality used by Rudelson in the derivation of his well-known bound for random sums of rank-one operators. Our approach is based on Ahlswede and Winter's technique for proving operator Chernoff bounds. We also prove a concentration inequality for sums of random matrices of rank one with explicit constants.},
	annotation = {ZSCC: 0000119},
	author = {Oliveira, Roberto},
	doi = {10.1214/ECP.v15-1544},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Oliveira - 2010 - Sums of random Hermitian matrices and an inequalit.pdf},
	issn = {1083-589X},
	journal = {Electronic Communications in Probability},
	langid = {english},
	month = jan,
	number = {none},
	title = {Sums of Random {{Hermitian}} Matrices and an Inequality by {{Rudelson}}},
	volume = {15},
	year = {2010},
	bdsk-url-1 = {https://doi.org/10.1214/ECP.v15-1544}}

@article{painskyBregmanDivergenceBounds2020,
	abstract = {A loss function measures the discrepancy between the true values and their estimated fits, for a given instance of data. In classification problems, a loss function is said to be proper if a minimizer of the expected loss is the true underlying probability. We show that for binary classification, the divergence associated with smooth, proper, and convex loss functions is upper bounded by the Kullback-Leibler (KL) divergence, to within a normalization constant. This implies that by minimizing the logarithmic loss associated with the KL divergence, we minimize an upper bound to any choice of loss from this set. As such the logarithmic loss is universal in the sense of providing performance guarantees with respect to a broad class of accuracy measures. Importantly, this notion of universality is not problem-specific, enabling its use in diverse applications, including predictive modeling, data clustering and sample complexity analysis. Generalizations to arbitary finite alphabets are also developed. The derived inequalities extend several well-known f -divergence results.},
	annotation = {ZSCC: NoCitationData[s0]},
	archiveprefix = {arXiv},
	author = {Painsky, Amichai and Wornell, Gregory W.},
	eprint = {1810.07014},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/Bregman/Painsky and Wornell - 2020 - Bregman Divergence Bounds and Universality Propert.pdf},
	journal = {arXiv:1810.07014 [cs, math]},
	keywords = {Computer Science - Information Theory},
	langid = {english},
	month = jan,
	primaryclass = {cs, math},
	title = {Bregman {{Divergence Bounds}} and {{Universality Properties}} of the {{Logarithmic Loss}}},
	year = {2020}}

@article{Parpas2017,
	abstract = {Composite optimization models consist of the minimization of the sum of a smooth (not necessarily convex) function and a nonsmooth convex function. Such models arise in many applications where, in addition to the composite nature of the objective function, a hierarchy of models is readily available. It is common to take advantage of this hierarchy of models by first solving a low fidelity model and then using the solution as a starting point to a high fidelity model. We adopt an optimization point of view and show how to take advantage of the availability of a hierarchy of models in a consistent manner. We do not use the low fidelity model just for the computation of promising starting points but also for the computation of search directions. We establish the convergence and convergence rate of the proposed algorithm. Our numerical experiments on large scale image restoration problems and the transition path problem suggest that, for certain classes of problems, the proposed algorithm is significantly faster than the state of the art.},
	annotation = {00001},
	author = {Parpas, Panos},
	doi = {10.1137/16M1082299},
	file = {/Users/longchen1/Zotero/storage/LZEWK7QL/Parpas - 2017 - A Multilevel Proximal Gradient Algorithm for a Cla.pdf},
	issn = {1064-8275, 1095-7197},
	journal = {SIAM Journal on Scientific Computing},
	langid = {english},
	month = jan,
	number = {5},
	pages = {S681-S701},
	title = {A {{Multilevel Proximal Gradient Algorithm}} for a {{Class}} of {{Composite Optimization Problems}}},
	volume = {39},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1137/16M1082299}}

@article{pedregosaProximalSplittingMeets2019,
	abstract = {Despite the rise to fame of incremental variance-reduced methods in recent years, their use in nonsmooth optimization is still limited to few simple cases. This is due to the fact that existing methods require to evaluate the proximity operator for the nonsmooth terms, which can be a costly operation for complex penalties. In this work we introduce two variance-reduced incremental methods based on SAGA and SVRG that can efficiently take into account complex penalties which can be expressed as a sum of proximal terms. This includes penalties such as total variation, group lasso with overlap and trend filtering, to name a few. Furthermore, we also develop sparse variants of the proposed algorithms which can take advantage of sparsity in the input data. Like other incremental methods, it only requires to evaluate the gradient of a single sample per iteration, and so is ideally suited for large scale applications. We provide a convergence rate analysis for the proposed methods and show that they converge with a fixed step-size, achieving in some cases the same asymptotic rate as their full gradient variants. Empirical benchmarks on 3 different datasets illustrate the practical advantages of the proposed methods.},
	annotation = {ZSCC: 0000004},
	archiveprefix = {arXiv},
	author = {Pedregosa, Fabian and Fatras, Kilian and Casotto, Mattia},
	eprint = {1806.07294},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Pedregosa et al. - 2019 - Proximal Splitting Meets Variance Reduction.pdf},
	journal = {arXiv:1806.07294 [math]},
	keywords = {65K10,Mathematics - Optimization and Control},
	langid = {english},
	month = jan,
	primaryclass = {math},
	title = {Proximal {{Splitting Meets Variance Reduction}}},
	year = {2019}}

@book{platenNumericalSolutionStochastic2010,
	address = {{Berlin, Heidelberg}},
	annotation = {ZSCC: 0000405},
	author = {Platen, Eckhard and {Bruti-Liberati}, Nicola},
	doi = {10.1007/978-3-642-13694-8},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Platen and Bruti-Liberati - 2010 - Numerical Solution of Stochastic Differential Equa.pdf},
	isbn = {978-3-642-12057-2 978-3-642-13694-8},
	langid = {english},
	publisher = {{Springer Berlin Heidelberg}},
	series = {Stochastic {{Modelling}} and {{Applied Probability}}},
	title = {Numerical {{Solution}} of {{Stochastic Differential Equations}} with {{Jumps}} in {{Finance}}},
	volume = {64},
	year = {2010},
	bdsk-url-1 = {https://doi.org/10.1007/978-3-642-13694-8}}

@article{polyakLyapunovFunctionsOptimization2017,
	annotation = {ZSCC: NoCitationData[s0]},
	author = {Polyak, Boris and Shcherbakov, Pavel},
	doi = {10.1016/j.ifacol.2017.08.1513},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/Lyapunov/Polyak and Shcherbakov - 2017 - Lyapunov Functions An Optimization Theory Perspec.pdf},
	issn = {24058963},
	journal = {IFAC-PapersOnLine},
	langid = {english},
	month = jul,
	number = {1},
	pages = {7456--7461},
	shorttitle = {Lyapunov {{Functions}}},
	title = {Lyapunov {{Functions}}: {{An Optimization Theory Perspective}} * *{{This}} Work Was Supported by the {{Russian Scientific Foundation}}, Project No. 16-11-10015},
	volume = {50},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1016/j.ifacol.2017.08.1513}}

@article{PowellYuan1990,
	abstract = {A trust region algorithm for equality constrained optimization is proposed that employs a differentiable exact penalty function. Under certain conditions global convergence and local superlinear convergence results are proved.},
	annotation = {00328},
	author = {Powell, M. J. D. and Yuan, Y.},
	doi = {10.1007/BF01588787},
	file = {/Users/longchen1/Zotero/storage/UDZYSQ5G/Powell and Yuan - 1990 - A trust region algorithm for equality constrained .pdf},
	issn = {1436-4646},
	journal = {Mathematical Programming},
	keywords = {Equality constrained optimization,exact penalty functions,nonlinear programming,superlinear convergence,trust regions},
	langid = {english},
	month = nov,
	number = {1},
	pages = {189--211},
	title = {A Trust Region Algorithm for Equality Constrained Optimization},
	volume = {49},
	year = {1990},
	bdsk-url-1 = {https://doi.org/10.1007/BF01588787}}

@article{rafatiQuasiNewtonOptimizationMethods2019,
	abstract = {Deep learning algorithms often require solving a highly non-linear and nonconvex unconstrained optimization problem. Methods for solving optimization problems in large-scale machine learning, such as deep learning and deep reinforcement learning (RL), are generally restricted to the class of first-order algorithms, like stochastic gradient descent (SGD). While SGD iterates are inexpensive to compute, they have slow theoretical convergence rates. Furthermore, they require exhaustive trial-and-error to fine-tune many learning parameters. Using second-order curvature information to find search directions can help with more robust convergence for non-convex optimization problems. However, computing Hessian matrices for large-scale problems is not computationally practical. Alternatively, quasi-Newton methods construct an approximate of the Hessian matrix to build a quadratic model of the objective function. Quasi-Newton methods, like SGD, require only first-order gradient information, but they can result in superlinear convergence, which makes them attractive alternatives to SGD. The limited-memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) approach is one of the most popular quasi-Newton methods that construct positive definite Hessian approximations. In this chapter, we propose efficient optimization methods based on L-BFGS quasi-Newton methods using line search and trust-region strategies. Our methods bridge the disparity between first- and second-order methods by using gradient information to calculate low-rank updates to Hessian approximations. We provide formal convergence analysis of these methods as well as empirical results on deep learning applications, such as image classification tasks and deep reinforcement learning on a set of ATARI 2600 video games. Our results show a robust convergence with preferred generalization characteristics as well as fast training time.},
	annotation = {ZSCC: NoCitationData[s0]},
	archiveprefix = {arXiv},
	author = {Rafati, Jacob and Marcia, Roummel F.},
	eprint = {1909.01994},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/QuasiNewton/Rafati and Marcia - 2019 - Quasi-Newton Optimization Methods For Deep Learnin.pdf},
	journal = {arXiv:1909.01994 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
	langid = {english},
	month = sep,
	primaryclass = {cs, math, stat},
	title = {Quasi-{{Newton Optimization Methods For Deep Learning Applications}}},
	year = {2019}}

@article{reddiStochasticFrankWolfeMethods2016,
	archiveprefix = {arXiv},
	author = {Reddi, Sashank J and Smola, Alex},
	eprint = {1607.08254v2},
	eprinttype = {arxiv},
	file = {/Volumes/GoogleDrive/My Drive/biblib/Papers/Reddi, Smola/Unknown/Reddi, Smola - 2016 - Stochastic Frank-Wolfe Methods for Nonconvex Optimization arXiv 1607 . 08254v2 math . OC 29 Jul 2016.pdf},
	pages = {1--17},
	title = {Stochastic {{Frank-Wolfe Methods}} for {{Nonconvex Optimization arXiv}} : 1607 . 08254v2 [ Math . {{OC}} ] 29 {{Jul}} 2016},
	year = {2016}}

@article{reddiStochasticFrankWolfeMethods2016a,
	abstract = {We study Frank-Wolfe methods for nonconvex stochastic and finite-sum optimization problems. Frank-Wolfe methods (in the convex case) have gained tremendous recent interest in machine learning and optimization communities due to their projection-free property and their ability to exploit structured constraints. However, our understanding of these algorithms in the nonconvex setting is fairly limited. In this paper, we propose nonconvex stochastic Frank-Wolfe methods and analyze their convergence properties. For objective functions that decompose into a finitesum, we leverage ideas from variance reduction techniques for convex optimization to obtain new variance reduced nonconvex Frank-Wolfe methods that have provably faster convergence than the classical Frank-Wolfe method. Finally, we show that the faster convergence rates of our variance reduced methods also translate into improved convergence rates for the stochastic setting.},
	annotation = {ZSCC: 0000094},
	archiveprefix = {arXiv},
	author = {Reddi, Sashank J. and Sra, Suvrit and Poczos, Barnabas and Smola, Alex},
	eprint = {1607.08254},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Reddi et al. - 2016 - Stochastic Frank-Wolfe Methods for Nonconvex Optim.pdf},
	journal = {arXiv:1607.08254 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
	langid = {english},
	month = jul,
	primaryclass = {cs, math, stat},
	title = {Stochastic {{Frank-Wolfe Methods}} for {{Nonconvex Optimization}}},
	year = {2016}}

@article{RichtTak2017,
	archiveprefix = {arXiv},
	author = {Richt, Peter and Tak, Martin},
	eprint = {1706.01108v2},
	eprinttype = {arxiv},
	file = {/Volumes/GoogleDrive/My Drive/biblib/Papers/Richt, Tak/Unknown/Richt, Tak - 2017 - Stochastic Reformulations of Linear Systems Algorithms and Convergence Theory .pdf},
	title = {Stochastic {{Reformulations}} of {{Linear Systems}} : {{Algorithms}} and {{Convergence Theory}} {${_\ast}$}},
	year = {2017}}

@article{RouxSchmidtBach,
	author = {Roux, Nicolas Le and Schmidt, Mark and Bach, Francis},
	file = {/Volumes/GoogleDrive/My Drive/biblib/Papers/Roux, Schmidt, Bach/Unknown/Roux, Schmidt, Bach - Unknown - A Stochastic Gradient Method with an Exponential Convergence Rate for Finite Training Sets.pdf},
	number = {3},
	pages = {1--9},
	title = {A {{Stochastic Gradient Method}} with an {{Exponential Convergence Rate}} for {{Finite Training Sets}}}}

@article{RouxSchmidtBacha,
	author = {Roux, Nicolas Le and Schmidt, Mark and Bach, Francis},
	file = {/Volumes/GoogleDrive/My Drive/biblib/Papers/Roux, Schmidt, Bach/Unknown/Roux, Schmidt, Bach - Unknown - A Stochastic Gradient Method with an Exponential Convergence Rate for Finite Training Sets Context.pdf},
	title = {A {{Stochastic Gradient Method}} with an {{Exponential Convergence Rate}} for {{Finite Training Sets Context}} : {{Machine Learning}} for `` {{Big Data}} ''}}

@article{SchmidtLeBach2017,
	author = {Schmidt, Mark and Le, Nicolas and Bach, Francis},
	doi = {10.1007/s10107-016-1030-6},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Minimizing finite sums with the stochastic average gradient-2017-Schmidt\;Le Roux\;Bach.pdf},
	pages = {83--112},
	title = {Minimizing Finite Sums with the Stochastic Average Gradient},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1007/s10107-016-1030-6}}

@article{schmidtNonUniformStochasticAverage,
	abstract = {We apply stochastic average gradient (SAG) algorithms for training conditional random fields (CRFs). We describe a practical implementation that uses structure in the CRF gradient to reduce the memory requirement of this linearly-convergent stochastic gradient method, propose a non-uniform sampling scheme that substantially improves practical performance, and analyze the rate of convergence of the SAGA variant under nonuniform sampling. Our experimental results reveal that our method significantly outperforms existing methods in terms of the training objective, and performs as well or better than optimally-tuned stochastic gradient methods in terms of test error.},
	annotation = {ZSCC: 0000000},
	author = {Schmidt, Mark and Babanezhad, Reza and Ahemd, Mohamed Osama and Defazio, Aaron and Clifton, Ann and Sarkar, Anoop},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Schmidt et al. - Non-Uniform Stochastic Average Gradient Method for.pdf},
	langid = {english},
	pages = {10},
	title = {Non-{{Uniform Stochastic Average Gradient Method}} for {{Training Conditional Random Fields}}}}

@article{shalev-shwartzStochasticDualCoordinate,
	abstract = {Stochastic Gradient Descent (SGD) has become popular for solving large scale supervised machine learning optimization problems such as SVM, due to their strong theoretical guarantees. While the closely related Dual Coordinate Ascent (DCA) method has been implemented in various software packages, it has so far lacked good convergence analysis. This paper presents a new analysis of Stochastic Dual Coordinate Ascent (SDCA) showing that this class of methods enjoy strong theoretical guarantees that are comparable or better than SGD. This analysis justifies the effectiveness of SDCA for practical applications.},
	annotation = {ZSCC: 0000989},
	author = {{Shalev-Shwartz}, Shai and Zhang, Tong},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Shalev-Shwartz and Zhang - Stochastic Dual Coordinate Ascent Methods for Regu.pdf},
	langid = {english},
	pages = {33},
	title = {Stochastic {{Dual Coordinate Ascent Methods}} for {{Regularized Loss Minimization}}}}

@article{Sharma2018,
	abstract = {Stochastic Gradient Descent (SGD) Algorithm, despite its simplicity, is considered an effective and default standard optimization algorithm for machine learning classification models such as neural networks and logistic regression. However, SGD's gradient descent is biased towards the random selection of a data instance. In this paper, it has been termed as data inconsistency. The proposed variation of SGD, Guided Stochastic Gradient Descent (GSGD) Algorithm, tries to overcome this inconsistency in a given dataset through greedy selection of consistent data instances for gradient descent. The empirical test results show the efficacy of the method. Moreover, GSGD has also been incorporated and tested with other popular variations of SGD, such as Adam, Adagrad and Momentum. The guided search with GSGD achieves better convergence and classification accuracy in a limited time budget than its original counterpart of canonical and other variation of SGD. Additionally, it maintains the same efficiency when experimented on medical benchmark datasets with logistic regression for classification.},
	annotation = {00000},
	author = {Sharma, Anuraganand},
	doi = {10.1016/j.asoc.2018.09.038},
	file = {/Users/longchen1/Zotero/storage/FMXEFK68/Sharma - 2018 - Guided Stochastic Gradient Descent Algorithm for i.pdf;/Users/longchen1/Zotero/storage/LX3TSHY8/S156849461830557X.html},
	issn = {1568-4946},
	journal = {Applied Soft Computing},
	keywords = {Classification,Greedy selection,Guided Stochastic Gradient Descent Algorithm,Logistic regression,Machine learning,Neural networks,Stochastic Gradient Descent Algorithm},
	month = oct,
	title = {Guided {{Stochastic Gradient Descent Algorithm}} for Inconsistent Datasets},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1016/j.asoc.2018.09.038}}

@article{ShiDuJordanSu2018,
	abstract = {Gradient-based optimization algorithms can be studied from the perspective of limiting ordinary differential equations (ODEs). Motivated by the fact that existing ODEs do not distinguish between two fundamentally different algorithms\textemdash Nesterov's accelerated gradient method for strongly convex functions (NAG-SC) and Polyak's heavy-ball method\textemdash we study an alternative limiting process that yields high-resolution ODEs. We show that these ODEs permit a general Lyapunov function framework for the analysis of convergence in both continuous and discrete time. We also show that these ODEs are more accurate surrogates for the underlying algorithms; in particular, they not only distinguish between NAG-SC and Polyak's heavy-ball method, but they allow the identification of a term that we refer to as ``gradient correction'' that is present in NAG-SC but not in the heavy-ball method and is responsible for the qualitative difference in convergence of the two methods. We also use the high-resolution ODE framework to study Nesterov's accelerated gradient method for (non-strongly) convex functions, uncovering a hitherto unknown result\textemdash that NAG-C minimizes the squared gradient norm at an inverse cubic rate. Finally, by modifying the high-resolution ODE of NAG-C, we obtain a family of new optimization methods that are shown to maintain the accelerated convergence rates of NAG-C for smooth convex functions.},
	annotation = {00014},
	archiveprefix = {arXiv},
	author = {Shi, Bin and Du, Simon S. and Jordan, Michael I. and Su, Weijie J.},
	eprint = {1810.08907},
	eprinttype = {arxiv},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/Acceleration/Shi et al. - 2018 - Understanding the Acceleration Phenomenon via High.pdf},
	journal = {arXiv:1810.08907 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning,Mathematics - Classical Analysis and ODEs,Mathematics - Numerical Analysis,Mathematics - Optimization and Control,Statistics - Machine Learning},
	langid = {english},
	month = oct,
	primaryclass = {cs, math, stat},
	title = {Understanding the {{Acceleration Phenomenon}} via {{High-Resolution Differential Equations}}},
	year = {2018}}

@article{songInexactUzawaAlgorithmic2019,
	abstract = {We consider a class of nonlinear saddle point problems with various applications in PDEs and optimal control problems and propose an algorithmic framework based on some inexact Uzawa methods in the literature. Under mild conditions, the convergence of this algorithmic framework is uniformly proved and the linear convergence rate is estimated. We take an elliptic optimal control problem with control constraints as an example to illustrate how to choose application-tailored preconditioners to generate specific and efficient algorithms by the algorithmic framework. The resulting algorithm does not need to solve any optimization subproblems or systems of linear equations in its iteration; each of its iterations only requires the projection onto a simple admissible set, four algebraic multigrid V-cycles, and a few matrix-vector multiplications. Its numerical efficiency is then demonstrated by some preliminary numerical results.},
	annotation = {ZSCC: 0000001},
	author = {Song, Yongcun and Yuan, Xiaoming and Yue, Hangrui},
	doi = {10.1137/19M1245736},
	file = {/Users/longchen1/Dropbox/Math/Research/NonlinearSaddle/reference/Song et al. - 2019 - An Inexact Uzawa Algorithmic Framework for Nonline.pdf},
	issn = {0036-1429, 1095-7170},
	journal = {SIAM Journal on Numerical Analysis},
	langid = {english},
	month = jan,
	number = {6},
	pages = {2656--2684},
	title = {An {{Inexact Uzawa Algorithmic Framework}} for {{Nonlinear Saddle Point Problems}} with {{Applications}} to {{Elliptic Optimal Control Problem}}},
	volume = {57},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1137/19M1245736}}

@article{sprungUpperLowerBounds2019,
	annotation = {ZSCC: 0000011},
	author = {Sprung, Benjamin},
	doi = {10.1186/s13660-018-1953-y},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/Bregman/Sprung - 2019 - Upper and lower bounds for the Bregman divergence.pdf},
	issn = {1029-242X},
	journal = {Journal of Inequalities and Applications},
	langid = {english},
	month = dec,
	number = {1},
	pages = {4},
	title = {Upper and Lower Bounds for the {{Bregman}} Divergence},
	volume = {2019},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1186/s13660-018-1953-y}}

@article{suDifferentialEquationModeling,
	abstract = {We derive a second-order ordinary differential equation (ODE) which is the limit of Nesterov's accelerated gradient method. This ODE exhibits approximate equivalence to Nesterov's scheme and thus can serve as a tool for analysis. We show that the continuous time ODE allows for a better understanding of Nesterov's scheme. As a byproduct, we obtain a family of schemes with similar convergence rates. The ODE interpretation also suggests restarting Nesterov's scheme leading to an algorithm, which can be rigorously proven to converge at a linear rate whenever the objective is strongly convex.},
	annotation = {ZSCC: NoCitationData[s0]},
	author = {Su, Weijie and Boyd, Stephen and Candes, Emmanuel J},
	file = {/Users/longchen1/Dropbox/Math/Research/Lyapunov_Framework/references/Su et al. - A Differential Equation for Modeling Nesterov's Acc.pdf},
	langid = {english},
	pages = {43},
	title = {A {{Differential Equation}} for {{Modeling Nesterov}}'s {{Accelerated Gradient Method}}: {{Theory}} and {{Insights}}}}

@article{sunConvergent3BlockSemiProximal2015,
	abstract = {In this paper, we consider conic programming problems whose constraints consist of linear equalities, linear inequalities, a nonpolyhedral cone, and a polyhedral cone. A convenient way for solving this class of problems is to apply the directly extended alternating direction method of multipliers (ADMM) to its dual problem, which has been observed to perform well in numerical computations but may diverge in theory. Ideally, one should find a convergent variant which is at least as efficient as the directly extended ADMM in practice. We achieve this goal by designing a convergent semiproximal ADMM (called sPADMM3c for convenience) for convex programming problems having three separable blocks in the objective function with the third part being linear. At each iteration, the proposed sPADMM3c takes one special block coordinate descent (BCD) cycle with the order 1 \textrightarrow{} 3 \textrightarrow{} 2 \textrightarrow{} 3, instead of the usual 1 \textrightarrow{} 2 \textrightarrow{} 3 Gauss\textendash Seidel BCD cycle used in the nonconvergent directly extended 3-block ADMM, for updating the variable blocks. Our numerical experiments demonstrate that the convergent method is at least 20\% faster than the directly extended ADMM with unit step-length for the vast majority of about 550 large-scale doubly nonnegative semidefinite programming problems with linear equality and/or inequality constraints. This confirms that at least for conic convex programming, one can design a convergent and efficient ADMM with a special BCD cycle of updating the variable blocks.},
	annotation = {ZSCC: 0000130},
	author = {Sun, Defeng and Toh, Kim-Chuan and Yang, Liuqin},
	doi = {10.1137/140964357},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/ADMM/Sun et al. - 2015 - A Convergent 3-Block SemiProximal Alternating Dire.pdf},
	issn = {1052-6234, 1095-7189},
	journal = {SIAM Journal on Optimization},
	langid = {english},
	month = jan,
	number = {2},
	pages = {882--915},
	title = {A {{Convergent}} 3-{{Block SemiProximal Alternating Direction Method}} of {{Multipliers}} for {{Conic Programming}} with 4-{{Type Constraints}}},
	volume = {25},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1137/140964357}}

@article{SunYe2016,
	abstract = {This paper concerns the worst-case complexity of Gauss-Seidel method for solving a positive semidefinite linear system; or equivalently, that of cyclic coordinate descent (C-CD) for minimizing a convex quadratic function. The known provable complexity of C-CD can be O(n) times slower than gradient descent (GD) and O(n2) times slower than randomized coordinate descent (R-CD). However, these gaps seem rather puzzling since so far they have not been observed in practice; in fact, C-CD usually converges much faster than GD and sometimes comparable to R-CD. Thus some researchers believe the gaps are due to the weakness of the proof, but not that of the C-CD algorithm itself.},
	annotation = {00014},
	archiveprefix = {arXiv},
	author = {Sun, Ruoyu and Ye, Yinyu},
	eprint = {1604.07130},
	eprinttype = {arxiv},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/BlockCoordinateDescent/Sun and Ye - 2016 - Worst-case Complexity of Cyclic Coordinate Descent.pdf},
	journal = {arXiv:1604.07130 [cs, math]},
	keywords = {Computer Science - Computational Complexity,Mathematics - Numerical Analysis,Mathematics - Optimization and Control},
	langid = {english},
	month = apr,
	primaryclass = {cs, math},
	shorttitle = {Worst-Case {{Complexity}} of {{Cyclic Coordinate Descent}}},
	title = {Worst-Case {{Complexity}} of {{Cyclic Coordinate Descent}}: \${{O}}(N\^2)\$ {{Gap}} with {{Randomized Version}}},
	year = {2016}}

@article{SunYuan2001,
	abstract = {Trust-region methods are powerful optimization methods. The conic model method is a new type of method with more information available at each iteration than standard quadratic-based methods. Can we combine their advantages to form a more powerful method for constrained optimization? In this paper we give a positive answer and present a conic trust-region algorithm for non-linearly constrained optimization problems. The trust-region subproblem of our method is to minimize a conic function subject to the linearized constraints and the trust region bound. The use of conic functions allows the model to interpolate function values and gradient values of the Lagrange function at both the current point and previous iterate point. Since conic functions are the extension of quadratic functions, they approximate general nonlinear functions better than quadratic functions. At the same time, the new algorithm possesses robust global properties. In this paper we establish the global convergence of the new algorithm under standard conditions.},
	annotation = {00033},
	author = {Sun, Wenyu and Yuan, Ya-xiang},
	doi = {10.1023/A:1012955122229},
	file = {/Users/longchen1/Zotero/storage/F3ECG3SW/Sun and Yuan - 2001 - A Conic Trust-Region Method for Nonlinearly Constr.pdf},
	issn = {1572-9338},
	journal = {Annals of Operations Research},
	keywords = {conic model,constrained optimization,nonlinear programming,trust-region method},
	langid = {english},
	month = mar,
	number = {1},
	pages = {175--191},
	title = {A {{Conic Trust-Region Method}} for {{Nonlinearly Constrained Optimization}}},
	volume = {103},
	year = {2001},
	bdsk-url-1 = {https://doi.org/10.1023/A:1012955122229}}

@article{SutskeverMartensDahlHinton,
	abstract = {Deep and recurrent neural networks (DNNs and RNNs respectively) are powerful models that were considered to be almost impossible to train using stochastic gradient descent with momentum. In this paper, we show that when stochastic gradient descent with momentum uses a well-designed random initialization and a particular type of slowly increasing schedule for the momentum parameter, it can train both DNNs and RNNs (on datasets with long-term dependencies) to levels of performance that were previously achievable only with Hessian-Free optimization. We find that both the initialization and the momentum are crucial since poorly initialized networks cannot be trained with momentum and well-initialized networks perform markedly worse when the momentum is absent or poorly tuned.},
	annotation = {01418},
	author = {Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
	file = {/Users/longchen1/Zotero/storage/G88WNYYK/Sutskever et al. - On the importance of initialization and momentum i.pdf},
	langid = {english},
	pages = {14},
	title = {On the Importance of Initialization and Momentum in Deep Learning}}

@article{TaoBoleyZhang2016,
	abstract = {We use a model LASSO problem to analyze the convergence behavior of the ISTA and FISTA iterations, showing that both iterations satisfy local linear convergence rate bound when close enough to the solution. Using the observation that FISTA is an accelerated ISTA process, and a spectral analysis of the associated matrix operators, we show that FISTA's convergence rate can slow down as it proceeds, eventually becoming slower than ISTA. This observation leads to a proposed heuristic algorithm to take an ISTA step if it shows more progress compared to FISTA, as measured by the decrease in the objective function. We illustrate the results with some synthetic numerical examples.},
	annotation = {00035},
	author = {Tao, Shaozhe and Boley, Daniel and Zhang, Shuzhong},
	doi = {10.1137/151004549},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/Research/ode2opt/references/Tao et al. - 2016 - Local Linear Convergence of ISTA and FISTA on the .pdf},
	issn = {1052-6234, 1095-7189},
	journal = {SIAM Journal on Optimization},
	langid = {english},
	month = jan,
	number = {1},
	pages = {313--336},
	title = {Local {{Linear Convergence}} of {{ISTA}} and {{FISTA}} on the {{LASSO Problem}}},
	volume = {26},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.1137/151004549}}

@article{TaoPanWuTao2018,
	abstract = {Many well-known first-order gradient methods have been extended to cope with large-scale composite problems, which often arise as a regularized empirical risk minimization in machine learning. However, their optimal convergence is attained only in terms of the weighted average of past iterative solutions. How to make the individual convergence of stochastic gradient descent (SGD) optimal, especially for strongly convex problems has now become a challenging problem in the machine learning community. On the other hand, Nesterov's recent weighted averaging strategy succeeds in achieving the optimal individual convergence of dual averaging (DA) but it fails in the basic mirror descent (MD). In this paper, a new primal averaging (PA) gradient operation step is presented, in which the gradient evaluation is imposed on the weighted average of all past iterative solutions. We prove that simply modifying the gradient operation step in MD by PA strategy suffices to recover the optimal individual rate for general convex problems. Along this line, the optimal individual rate of convergence for strongly convex problems can also be achieved by imposing the strong convexity on the gradient operation step. Furthermore, we extend PA-MD to solve regularized nonsmooth learning problems in the stochastic setting, which reveals that PA strategy is a simple yet effective extra step toward the optimal individual convergence of SGD. Several real experiments on sparse learning and SVM problems verify the correctness of our theoretical analysis.},
	annotation = {00000},
	author = {Tao, Wei and Pan, Zhisong and Wu, Gaowei and Tao, Qing},
	doi = {10.1109/TCYB.2018.2874332},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/Tao et al. - 2018 - Primal Averaging A New Gradient Evaluation Step t.pdf},
	issn = {2168-2267, 2168-2275},
	journal = {IEEE Transactions on Cybernetics},
	langid = {english},
	pages = {1--11},
	shorttitle = {Primal {{Averaging}}},
	title = {Primal {{Averaging}}: {{A New Gradient Evaluation Step}} to {{Attain}} the {{Optimal Individual Convergence}}},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1109/TCYB.2018.2874332}}

@article{tibshiraniDykstraAlgorithmADMM,
	abstract = {We study connections between Dykstra's algorithm for projecting onto an intersection of convex sets, the augmented Lagrangian method of multipliers or ADMM, and block coordinate descent. We prove that coordinate descent for a regularized regression problem, in which the penalty is a separable sum of support functions, is exactly equivalent to Dykstra's algorithm applied to the dual problem. ADMM on the dual problem is also seen to be equivalent, in the special case of two sets, with one being a linear subspace. These connections, aside from being interesting in their own right, suggest new ways of analyzing and extending coordinate descent. For example, from existing convergence theory on Dykstra's algorithm over polyhedra, we discern that coordinate descent for the lasso problem converges at an (asymptotically) linear rate. We also develop two parallel versions of coordinate descent, based on the Dykstra and ADMM connections.},
	author = {Tibshirani, Ryan J},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/ADMM/Tibshirani - Dykstra's Algorithm, ADMM, and Coordinate Descent.pdf},
	langid = {english},
	pages = {12},
	title = {Dykstra's {{Algorithm}}, {{ADMM}}, and {{Coordinate Descent}}: {{Connections}}, {{Insights}}, and {{Extensions}}}}

@article{tibshiraniRegressionShrinkageSelection1996,
	abstract = {We propose a new method for estimation in linear models. The 'lasso' minim residual sum of squares subject to the sum of the absolute value of the coefficients than a constant. Because of the nature of this constraint it tends to produce coefficients that are exactly 0 and hence gives interpretable models. Our simulatio suggest that the lasso enjoys some of the favourable properties of both subset sele ridge regression. It produces interpretable models like subset selection and exh stability of ridge regression. There is also an interesting relationship with recent adaptive function estimation by Donoho and Johnstone. The lasso idea is quite ge can be applied in a variety of statistical models: extensions to generalized regressio and tree-based models are briefly described.},
	annotation = {31022},
	author = {Tibshirani, Robert},
	doi = {10.1111/j.2517-6161.1996.tb02080.x},
	file = {/Users/longchen1/Zotero/storage/G4S6XXKQ/Tibshirani - 1996 - Regression Shrinkage and Selection Via the Lasso.pdf},
	issn = {00359246},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	langid = {english},
	month = jan,
	number = {1},
	pages = {267--288},
	title = {Regression {{Shrinkage}} and {{Selection Via}} the {{Lasso}}},
	volume = {58},
	year = {1996},
	bdsk-url-1 = {https://doi.org/10.1111/j.2517-6161.1996.tb02080.x}}

@article{tibshiraniRegressionShrinkageSelection2011,
	abstract = {In the paper I give a brief review of the basic idea and some history and then discuss some developments since the original paper on regression shrinkage and selection via the lasso.},
	annotation = {01168},
	author = {Tibshirani, Robert},
	doi = {10.1111/j.1467-9868.2011.00771.x},
	file = {/Users/longchen1/Zotero/storage/TSLGXTAE/Tibshirani - 2011 - Regression shrinkage and selection via the lasso .pdf},
	issn = {13697412},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	langid = {english},
	month = jun,
	number = {3},
	pages = {273--282},
	shorttitle = {Regression Shrinkage and Selection via the Lasso},
	title = {Regression Shrinkage and Selection via the Lasso: A Retrospective: {{Regression Shrinkage}} and {{Selection}} via the {{Lasso}}},
	volume = {73},
	year = {2011},
	bdsk-url-1 = {https://doi.org/10.1111/j.1467-9868.2011.00771.x}}

@article{tranUNIQUESOLUTIONSCONVEX,
	annotation = {ZSCC: 0000000},
	author = {Tran, Thi Tu Trinh},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/LASSO/Tran - UNIQUE SOLUTIONS TO CONVEX 1-OPTIMIZATION PROBLEMS.pdf},
	langid = {english},
	pages = {116},
	title = {{{UNIQUE SOLUTIONS TO CONVEX}} 1-{{OPTIMIZATION PROBLEMS VIA SECOND-ORDER ANALYSIS}}}}

@article{TreisterTurek2014,
	abstract = {The sparse inverse covariance estimation problem arises in many statistical applications in machine learning and signal processing. In this problem, the inverse of a covariance matrix of a multivariate normal distribution is estimated, assuming that it is sparse. An 1 regularized log-determinant optimization problem is typically solved to approximate such matrices. Because of memory limitations, most existing algorithms are unable to handle large scale instances of this problem. In this paper we present a new block-coordinate descent approach for solving the problem for large-scale data sets. Our method treats the sought matrix block-by-block using quadratic approximations, and we show that this approach has advantages over existing methods in several aspects. Numerical experiments on both synthetic and real gene expression data demonstrate that our approach outperforms the existing state of the art methods, especially for large-scale problems.},
	annotation = {00028},
	author = {Treister, Eran and Turek, Javier S},
	file = {/Users/longchen1/Zotero/storage/QLA6PRKS/Treister and Turek - A Block-Coordinate Descent Approach for Large-scal.pdf},
	journal = {NIPS},
	langid = {english},
	pages = {27},
	title = {A {{Block-Coordinate Descent Approach}} for {{Large-scale Sparse Inverse Covariance Estimation}}},
	year = {2014}}

@book{TsitsiklisBertsekas1989,
	annotation = {07101},
	author = {Tsitsiklis, J.N. and Bertsekas, D.P.},
	langid = {english},
	publisher = {{Prentice- Hall, Inc}},
	title = {Parallel and {{Distributed Computation}}: {{Numerical Methods}}},
	year = {1989}}

@article{UlbrichUlbrich2003,
	abstract = {. We propose and analyze a class of penalty-function-free nonmonotone trust-region methods for nonlinear equality constrained optimization problems. The algorithmic framework yields global convergence without using a merit function and allows nonmonotonicity independently for both, the constraint violation and the value of the Lagrangian function. Similar to the Byrd\textendash Omojokun class of algorithms, each step is composed of a quasi-normal and a tangential step. Both steps are required to satisfy a decrease condition for their respective trust-region subproblems. The proposed mechanism for accepting steps combines nonmonotone decrease conditions on the constraint violation and/or the Lagrangian function, which leads to a flexibility and acceptance behavior comparable to filter-based methods. We establish the global convergence of the method. Furthermore, transition to quadratic local convergence is proved. Numerical tests are presented that confirm the robustness and efficiency of the approach.},
	annotation = {00110},
	author = {Ulbrich, M. and Ulbrich, S.},
	doi = {10.1007/s10107-002-0343-9},
	file = {/Users/longchen1/Zotero/storage/MVGB9TXX/Ulbrich and Ulbrich - 2003 - Non-monotone trust region methods for nonlinear eq.pdf},
	issn = {1436-4646},
	journal = {Mathematical Programming},
	keywords = {Constrain Optimization Problem,Global Convergence,Lagrangian Function,Penalty Function,Trust Region},
	langid = {english},
	month = jan,
	number = {1},
	pages = {103--135},
	title = {Non-Monotone Trust Region Methods for Nonlinear Equality Constrained Optimization without a Penalty Function},
	volume = {95},
	year = {2003},
	bdsk-url-1 = {https://doi.org/10.1007/s10107-002-0343-9}}

@article{VanScoyFreemanLynch2018,
	abstract = {We design and analyze a novel gradient-based algorithm for unconstrained convex optimization. When the objective function is m-strongly convex and its gradient is L-Lipschitz continuous, the iterates and function values converge linearly to the optimum at rates {$\rho$} and {$\rho$}2, respectively, where {$\rho$} = 1 - m/L. These are the fastest known guaranteed linear convergence rates for globally convergent first-order methods, and for high desired accuracies the corresponding iteration complexity is within a factor of two of the theoretical lower bound. We use a simple graphical design procedure based on integral quadratic constraints to derive closed-form expressions for the algorithm parameters. The new algorithm, which we call the triple momentum method, can be seen as an extension of methods such as gradient descent, Nesterov's accelerated gradient descent, and the heavy-ball method.},
	annotation = {00017},
	author = {Van Scoy, Bryan and Freeman, Randy A. and Lynch, Kevin M.},
	doi = {10.1109/LCSYS.2017.2722406},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/Acceleration/Van Scoy et al. - 2018 - The Fastest Known Globally Convergent First-Order .pdf},
	issn = {2475-1456},
	journal = {IEEE Control Systems Letters},
	langid = {english},
	month = jan,
	number = {1},
	pages = {49--54},
	title = {The {{Fastest Known Globally Convergent First-Order Method}} for {{Minimizing Strongly Convex Functions}}},
	volume = {2},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1109/LCSYS.2017.2722406}}

@article{Wangb,
	abstract = {This paper presents a unified gradient flow approach to nonlinear constrained optimization problems. This method is based on a continuous gradient flow reformulation of constrained optimization problems and on a two level time discretization of the gradient flow equation with a splitting parameter \texttheta{} . The convergence of the scheme is analyzed and it is shown that the scheme becomes first order when \texttheta{} {$\in$} [0, 1] and second order when \texttheta{} = 1 and the time discretization step length is sufficiently large. Numerical experiments for continuous, discrete and mixed discrete optimization problems were performed, and the numerical results show that the approach is effective for solving these problems.},
	annotation = {00021},
	author = {Wang, S},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/ODE/Wang - A Unified Gradient Flow Approach to Constrained No.pdf},
	langid = {english},
	pages = {18},
	title = {A {{Unified Gradient Flow Approach}} to {{Constrained Nonlinear Optimization Problems}}}}

@article{WangZhouLiangLan2019,
	abstract = {The inexact cubic-regularized Newton's method (CR) proposed by Cartis, Gould and Toint achieves the same convergence rate as exact CR proposed by Nesterov and Polyak, but the inexact condition is not implementable due to its dependence on a future variable. This note establishes the same convergence rate under a similar but implementable inexact condition, which depends on only current variables. Our proof bounds the function-value decrease over total iterations rather than each iteration in the previous studies.},
	annotation = {00000},
	author = {Wang, Zhe and Zhou, Yi and Liang, Yingbin and Lan, Guanghui},
	doi = {10.1016/j.orl.2019.01.009},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/CRNewton/Wang et al. - 2019 - A note on inexact gradient and Hessian conditions .pdf},
	issn = {01676377},
	journal = {Operations Research Letters},
	langid = {english},
	month = mar,
	number = {2},
	pages = {146--149},
	title = {A Note on Inexact Gradient and {{Hessian}} Conditions for Cubic Regularized {{Newton}}'s Method},
	volume = {47},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1016/j.orl.2019.01.009}}

@article{wrightCoordinateDescentAlgorithms2015,
	abstract = {Coordinate descent algorithms solve optimization problems by successively performing approximate minimization along coordinate directions or coordinate hyperplanes. They have been used in applications for many years, and their popularity continues to grow because of their usefulness in data analysis, machine learning, and other areas of current interest. This paper describes the fundamentals of the coordinate descent approach, together with variants and extensions and their convergence properties, mostly with reference to convex objectives. We pay particular attention to a certain problem structure that arises frequently in machine learning applications, showing that efficient implementations of accelerated coordinate descent algorithms are possible for problems of this type. We also present some parallel variants and discuss their convergence properties under several models of parallel execution.},
	annotation = {00352},
	author = {Wright, Stephen J.},
	doi = {10.1007/s10107-015-0892-3},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/BlockCoordinateDescent/Wright - 2015 - Coordinate descent algorithms.pdf},
	issn = {0025-5610, 1436-4646},
	journal = {Mathematical Programming},
	langid = {english},
	month = jun,
	number = {1},
	pages = {3--34},
	title = {Coordinate Descent Algorithms},
	volume = {151},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1007/s10107-015-0892-3}}

@article{xiaoProximalStochasticGradient2014,
	abstract = {We consider the problem of minimizing the sum of two convex functions: one is the average of a large number of smooth component functions, and the other is a general convex function that admits a simple proximal mapping. We assume the whole objective function is strongly convex. Such problems often arise in machine learning, known as regularized empirical risk minimization. We propose and analyze a new proximal stochastic gradient method, which uses a multistage scheme to progressively reduce the variance of the stochastic gradient. While each iteration of this algorithm has similar cost as the classical stochastic gradient method (or incremental gradient method), we show that the expected objective value converges to the optimum at a geometric rate. The overall complexity of this method is much lower than both the proximal full gradient method and the standard proximal stochastic gradient method.},
	annotation = {ZSCC: 0000650},
	author = {Xiao, Lin and Zhang, Tong},
	doi = {10.1137/140961791},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Xiao and Zhang - 2014 - A Proximal Stochastic Gradient Method with Progres.pdf},
	issn = {1052-6234, 1095-7189},
	journal = {SIAM Journal on Optimization},
	langid = {english},
	month = jan,
	number = {4},
	pages = {2057--2075},
	title = {A {{Proximal Stochastic Gradient Method}} with {{Progressive Variance Reduction}}},
	volume = {24},
	year = {2014},
	bdsk-url-1 = {https://doi.org/10.1137/140961791}}

@article{xuSecondOrderOptimizationNonConvex2018,
	abstract = {While first-order optimization methods such as stochastic gradient descent (SGD) are popular in machine learning (ML), they come with well-known deficiencies, including relatively-slow convergence, sensitivity to the settings of hyper-parameters such as learning rate, stagnation at high training errors, and difficulty in escaping flat regions and saddle points. These issues are particularly acute in highly non-convex settings such as those arising in neural networks. Motivated by this, there has been recent interest in second-order methods that aim to alleviate these shortcomings by capturing curvature information. In this paper, we report detailed empirical evaluations of a class of Newton-type methods, namely sub-sampled variants of trust region (TR) and adaptive regularization with cubics (ARC) algorithms, for non-convex ML problems. In doing so, we demonstrate that these methods not only can be computationally competitive with hand-tuned SGD with momentum, obtaining comparable or better generalization performance, but also they are highly robust to hyper-parameter settings. Further, in contrast to SGD with momentum, we show that the manner in which these Newton-type methods employ curvature information allows them to seamlessly escape flat regions and saddle points.},
	annotation = {ZSCC: NoCitationData[s0]},
	archiveprefix = {arXiv},
	author = {Xu, Peng and {Roosta-Khorasani}, Farbod and Mahoney, Michael W.},
	eprint = {1708.07827},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/SGD/Xu et al. - 2018 - Second-Order Optimization for Non-Convex Machine L.pdf},
	journal = {arXiv:1708.07827 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning,Mathematics - Numerical Analysis,Mathematics - Optimization and Control,Statistics - Machine Learning},
	langid = {english},
	month = feb,
	primaryclass = {cs, math, stat},
	shorttitle = {Second-{{Order Optimization}} for {{Non-Convex Machine Learning}}},
	title = {Second-{{Order Optimization}} for {{Non-Convex Machine Learning}}: {{An Empirical Study}}},
	year = {2018}}

@article{XuYin2017,
	annotation = {00088},
	author = {Xu, Yangyang and Yin, Wotao},
	doi = {10.1007/s10915-017-0376-0},
	file = {/Users/longchen1/Zotero/storage/FDYUXQB5/Xu and Yin - 2017 - A Globally Convergent Algorithm for Nonconvex Opti.pdf},
	issn = {0885-7474, 1573-7691},
	journal = {Journal of Scientific Computing},
	langid = {english},
	month = aug,
	number = {2},
	pages = {700--734},
	title = {A {{Globally Convergent Algorithm}} for {{Nonconvex Optimization Based}} on {{Block Coordinate Update}}},
	volume = {72},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1007/s10915-017-0376-0}}

@article{yeApproximateNewtonMethods,
	abstract = {Many machine learning models involve solving optimization problems. Thus, it is important to address a large-scale optimization problem in big data applications. Recently, subsampled Newton methods have emerged to attract much attention due to their efficiency at each iteration, rectified a weakness in the ordinary Newton method of suffering a high cost in each iteration while commanding a high convergence rate. Other efficient stochastic second order methods have been also proposed. However, the convergence properties of these methods are still not well understood. There are also several important gaps between the current convergence theory and the empirical performance in real applications. In this paper, we aim to fill these gaps. We propose a unifying framework to analyze both local and global convergence properties of second order methods. Accordingly, we present our theoretical results which match the empirical performance in real applications well.},
	annotation = {ZSCC: 0000017},
	author = {Ye, Haishan and Luo, Luo and Zhang, Zhihua},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/QuasiNewton/Ye et al. - Approximate Newton Methods.pdf},
	langid = {english},
	pages = {41},
	title = {Approximate {{Newton Methods}}}}

@article{yinConstructionPathwayMap2020,
	annotation = {00004},
	author = {Yin, Jianyuan and Wang, Yiwei and Chen, Jeff Z. Y. and Zhang, Pingwen and Zhang, Lei},
	doi = {10.1103/PhysRevLett.124.090601},
	file = {/Users/longchen1/Zotero/storage/3GQIGJBV/Yin et al. - 2020 - Construction of a Pathway Map on a Complicated Ene.pdf;/Users/longchen1/Zotero/storage/KM4I3W4X/Yin et al. - 2020 - Construction of a Pathway Map on a Complicated Ene.pdf},
	ids = {YinWangChenZhangEtAl2020a},
	issn = {0031-9007, 1079-7114},
	journal = {Physical Review Letters},
	langid = {english},
	month = mar,
	number = {9},
	pages = {090601},
	title = {Construction of a {{Pathway Map}} on a {{Complicated Energy Landscape}}},
	volume = {124},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1103/PhysRevLett.124.090601}}

@article{YinZhangZhang2019,
	abstract = {We present a high-index optimization-based shrinking dimer (HiOSD) method to compute index-k saddle points as a generalization of the optimization-based shrinking dimer method for index-1 saddle points [L. Zhang, Q. Du, and Z. Zheng, SIAM J. Sci. Comput., 38 (2016), pp. A528\textendash A544]. We first formulate a minimax problem for an index-k saddle point that is a local maximum on a k-dimensional manifold and a local minimum on its orthogonal complement. The k-dimensional maximal subspace is spanned by the k eigenvectors corresponding to the smallest k eigenvalues of the Hessian, which can be constructed by the simultaneous Rayleigh-quotient minimization technique or the locally optimal block preconditioned conjugate gradient method. Under the minimax framework, we implement the Barzilai\textendash Borwein gradient method to speed up the convergence. We demonstrate the efficiency of the HiOSD method for computing high-index saddle points by applying finite-dimensional examples and semilinear elliptic problems.},
	annotation = {00005},
	author = {Yin, Jianyuan and Zhang, Lei and Zhang, Pingwen},
	doi = {10.1137/19M1253356},
	file = {/Users/longchen1/Zotero/storage/IUM5RVEY/Yin et al. - 2019 - High-Index Optimization-Based Shrinking Dimer Meth.pdf},
	issn = {1064-8275, 1095-7197},
	journal = {SIAM Journal on Scientific Computing},
	langid = {english},
	month = jan,
	number = {6},
	pages = {A3576-A3595},
	title = {High-{{Index Optimization-Based Shrinking Dimer Method}} for {{Finding High-Index Saddle Points}}},
	volume = {41},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1137/19M1253356}}

@article{Yuan2011,
	author = {Yuan, Ya-Xiang},
	doi = {10.3934/naco.2011.1.15},
	file = {/Users/longchen1/Dropbox/Math/biblib/biblib/Zotero/Yuan/Numerical Algebra, Control and Optimization/Yuan - 2011 - Recent advances in numerical methods for nonlinear equations and nonlinear least squares.pdf;/Volumes/GoogleDrive/My Drive/biblib/Papers/Yuan/Numerical Algebra, Control and Optimization/Yuan - 2011 - Recent advances in numerical methods for nonlinear equations and nonlinear least squares.pdf;/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/biblib/biblib/Zotero/Yuan/Numerical Algebra, Control and Optimization/Yuan - 2011 - Recent advances in numerical methods for nonlinear equations and nonlinear least squares.pdf},
	issn = {2155-3289},
	journal = {Numerical Algebra, Control and Optimization},
	keywords = {and phrases,levenberg-marquardt,local error bound conditions,nonlinear equations,nonlinear least squares,quasi-newton,subspace,trust region,variable projection},
	month = feb,
	number = {1},
	pages = {15--34},
	title = {Recent Advances in Numerical Methods for Nonlinear Equations and Nonlinear Least Squares},
	volume = {1},
	year = {2011},
	bdsk-url-1 = {https://doi.org/10.3934/naco.2011.1.15}}

@article{Yuan2015,
	abstract = {Trust region methods are a class of numerical methods for optimization. Unlike line search type methods where a line search is carried out in each iteration, trust region methods compute a trial step by solving a trust region subproblem where a model function is minimized within a trust region. Due to the trust region constraint, nonconvex models can be used in trust region subproblems, and trust region algorithms can be applied to nonconvex and ill-conditioned problems. Normally it is easier to establish the global convergence of a trust region algorithm than that of its line search counterpart. In the paper, we review recent results on trust region methods for unconstrained optimization, constrained optimization, nonlinear equations and nonlinear least squares, nonsmooth optimization and optimization without derivatives. Results on trust region subproblems and regularization methods are also discussed.},
	annotation = {00076},
	author = {Yuan, Ya-xiang},
	doi = {10.1007/s10107-015-0893-2},
	file = {/Users/longchen1/Zotero/storage/BAFUIVQ2/Yuan - 2015 - Recent advances in trust region algorithms.pdf},
	issn = {1436-4646},
	journal = {Mathematical Programming},
	keywords = {65K05,90C30,Complexity,Convergence,Nonlinear optimization,Subproblem,Trust region algorithms},
	langid = {english},
	month = jun,
	number = {1},
	pages = {249--281},
	title = {Recent Advances in Trust Region Algorithms},
	volume = {151},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1007/s10107-015-0893-2}}

@article{YueZhouMan-ChoSo2019,
	abstract = {In this paper we consider the cubic regularization (CR) method for minimizing a twice continuously differentiable function. While the CR method is widely recognized as a globally convergent variant of Newton's method with superior iteration complexity, existing results on its local quadratic convergence require a stringent non-degeneracy condition. We prove that under a local error bound (EB) condition, which is much weaker a requirement than the existing non-degeneracy condition, the sequence of iterates generated by the CR method converges at least Q-quadratically to a second-order critical point. This indicates that adding a cubic regularization not only equips Newton's method with remarkable global convergence properties but also enables it to converge quadratically even in the presence of degenerate solutions. As a byproduct, we show that without assuming convexity, the proposed EB condition is equivalent to a quadratic growth condition, which could be of independent interest. To demonstrate the usefulness and relevance of our convergence analysis, we focus on two concrete nonconvex optimization problems that arise in phase retrieval and low-rank matrix recovery, respectively, and prove that with overwhelming probability, the sequence of iterates generated by the CR method for solving these two problems converges at least Q-quadratically to a global minimizer. We also present numerical results of the CR method when applied to solve these two problems to support and complement our theoretical development.},
	annotation = {00008},
	author = {Yue, Man-Chung and Zhou, Zirui and {Man-Cho So}, Anthony},
	doi = {10.1137/18M1167498},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/CRNewton/Yue et al. - 2019 - On the Quadratic Convergence of the Cubic Regulari.pdf},
	issn = {1052-6234, 1095-7189},
	journal = {SIAM Journal on Optimization},
	langid = {english},
	month = jan,
	number = {1},
	pages = {904--932},
	title = {On the {{Quadratic Convergence}} of the {{Cubic Regularization Method}} under a {{Local Error Bound Condition}}},
	volume = {29},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1137/18M1167498}}

@article{zhangExtendedProximalADMM2021,
	abstract = {We propose a new proximal alternating direction method of multipliers (ADMM) for solving a class of three-block nonconvex optimization problems with linear constraints. The proposed method updates the third primal variable twice per iteration and introduces semidefinite proximal terms to the subproblems with the first two blocks. The method can be regarded as an extension of the method proposed in Sun et al. (2015) which is specialized to the convex case with the third block of the objective function being quadratic. Based on the powerful Kurdyka\textendash\L ojasiewicz property, we prove that each bounded sequence generated by the proposed method converges to a critical point of the considered problem. Some numerical results are reported to indicate the effectiveness and superiority of the proposed method.},
	annotation = {ZSCC: 0000000},
	author = {Zhang, Chun and Song, Yongzhong and Cai, Xingju and Han, Deren},
	doi = {10.1016/j.cam.2021.113681},
	file = {/Users/longchen1/Dropbox/Math/LectureNotes/Optimization/references/ADMM/Zhang et al. - 2021 - An extended proximal ADMM algorithm for three-bloc.pdf},
	issn = {03770427},
	journal = {Journal of Computational and Applied Mathematics},
	langid = {english},
	month = dec,
	pages = {113681},
	title = {An Extended Proximal {{ADMM}} Algorithm for Three-Block Nonconvex Optimization Problems},
	volume = {398},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1016/j.cam.2021.113681}}

@article{ZhangSraJadbabaie2019,
	abstract = {We study gradient-based optimization methods obtained by direct Runge-Kutta discretization of the ordinary differential equation (ODE) describing the movement of a heavy-ball under constant friction coefficient. When the function is high order smooth and strongly convex, we show that directly simulating the ODE with known numerical integrators achieve acceleration in a nontrivial neighborhood of the optimal solution. In particular, the neighborhood can grow larger as the condition number of the function increases. Furthermore, our results also hold for nonconvex but quasi-strongly convex objectives. We provide numerical experiments that verify the theoretical rates predicted by our results.},
	annotation = {00000},
	archiveprefix = {arXiv},
	author = {Zhang, Jingzhao and Sra, Suvrit and Jadbabaie, Ali},
	eprint = {1905.12436},
	eprinttype = {arxiv},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/Research/ode2opt/references/Zhang et al. - 2019 - Acceleration in First Order Quasi-strongly Convex .pdf},
	journal = {arXiv:1905.12436 [math]},
	keywords = {Mathematics - Optimization and Control},
	langid = {english},
	month = may,
	primaryclass = {math},
	title = {Acceleration in {{First Order Quasi-strongly Convex Optimization}} by {{ODE Discretization}}},
	year = {2019}}

@article{ZhangTajbakhsh2020,
	abstract = {We propose a stochastic variance-reduced cubic regularized Newton algorithm for the finite-sum problem over Riemannian manifolds. The proposed algorithm requires full gradient and Hessian updates at the beginning of each epoch while it performs stochastic variance-reduced updates in the iterations within each epoch. The iteration complexity of the algorithm to attain an ( , {$\delta$})-second order stationary point is shown to be O(max\{ -3/2, {$\delta-$}3\}). Furthermore, the paper proposes a computationally more appealing version of the algorithm which only requires inexact solution of the cubic regularized Newton subproblem with the same rate of convergence. Numerical results verify our theoretical findings. Furthermore, the performance of the proposed method is compared with other second-order optimization algorithms for Riemannian manifolds.},
	annotation = {00000},
	archiveprefix = {arXiv},
	author = {Zhang, Dewei and Tajbakhsh, Sam Davanloo},
	eprint = {2010.03785},
	eprinttype = {arxiv},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/CRNewton/Zhang and Tajbakhsh - 2020 - Riemannian Stochastic Variance-Reduced Cubic Regul.pdf},
	journal = {arXiv:2010.03785 [math]},
	keywords = {Mathematics - Optimization and Control},
	langid = {english},
	month = oct,
	primaryclass = {math},
	title = {Riemannian {{Stochastic Variance-Reduced Cubic Regularized Newton Method}}},
	year = {2020}}

@article{ZhangXiaoZhang2018,
	abstract = {The cubic regularized Newton method of Nesterov and Polyak has become increasingly popular for non-convex optimization because of its capability of finding an approximate local solution with second-order guarantee. Several recent works extended this method to the setting of minimizing the average of N smooth functions by replacing the exact gradients and Hessians with subsampled approximations. It has been shown that the total Hessian sample complexity can be reduced to be sublinear in N per iteration by leveraging stochastic variance reduction techniques. We present an adaptive variance reduction scheme for subsampled Newton method with cubic regularization, and show that the expected Hessian sample complexity is O(N + N\^\{2/3\}\textbackslash epsilon\^\{-3/2\}) for finding an (\textbackslash epsilon,\textbackslash epsilon\^\{1/2\})-approximate local solution (in terms of first and second-order guarantees respectively). Moreover, we show that the same Hessian sample complexity retains with fixed sample sizes if exact gradients are used. The techniques of our analysis are different from previous works in that we do not rely on high probability bounds based on matrix concentration inequalities. Instead, we derive and utilize bounds on the 3rd and 4th order moments of the average of random matrices, which are of independent interest on their own.},
	annotation = {00000},
	archiveprefix = {arXiv},
	author = {Zhang, Junyu and Xiao, Lin and Zhang, Shuzhong},
	eprint = {1811.11637},
	eprinttype = {arxiv},
	file = {/Users/longchen1/Zotero/storage/L8BVF7TA/Zhang et al. - 2018 - Adaptive Stochastic Variance Reduction for Subsamp.pdf;/Users/longchen1/Zotero/storage/AYBGKXL5/1811.html},
	journal = {arXiv:1811.11637 [math]},
	keywords = {Mathematics - Optimization and Control},
	month = nov,
	primaryclass = {math},
	title = {Adaptive {{Stochastic Variance Reduction}} for {{Subsampled Newton Method}} with {{Cubic Regularization}}},
	year = {2018}}

@article{ZhaoZhang2014,
	archiveprefix = {arXiv},
	author = {Zhao, Peilin and Zhang, Tong},
	eprint = {1405.3080v1},
	eprinttype = {arxiv},
	file = {/Volumes/GoogleDrive/My Drive/biblib/Papers/Zhao, Zhang/arXiv preprint/Zhao, Zhang - 2014 - Accelerating Minibatch Stochastic Gradient Descent using Stratified Sampling.pdf},
	journal = {arXiv preprint},
	pages = {1--13},
	title = {Accelerating {{Minibatch Stochastic Gradient Descent}} Using {{Stratified Sampling}}},
	year = {2014}}

@article{ZhouWangLiang,
	abstract = {Cubic-regularized Newton's method (CR) is a popular algorithm that guarantees to produce a second-order stationary solution for solving nonconvex optimization problems. However, existing understandings of the convergence rate of CR are conditioned on special types of geometrical properties of the objective function. In this paper, we explore the asymptotic convergence rate of CR by exploiting the ubiquitous Kurdyka-\L ojasiewicz (K\L ) property of nonconvex objective functions. In specific, we characterize the asymptotic convergence rate of various types of optimality measures for CR including function value gap, variable distance gap, gradient norm and least eigenvalue of the Hessian matrix. Our results fully characterize the diverse convergence behaviors of these optimality measures in the full parameter regime of the K\L{} property. Moreover, we show that the obtained asymptotic convergence rates of CR are order-wise faster than those of first-order gradient descent algorithms under the K\L{} property.},
	annotation = {00000},
	author = {Zhou, Yi and Wang, Zhe and Liang, Yingbin},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/CRNewton/Zhou et al. - Convergence of Cubic Regularization for Nonconvex .pdf},
	langid = {english},
	pages = {10},
	title = {Convergence of {{Cubic Regularization}} for {{Nonconvex Optimization}} under {{K\L{} Property}}}}

@article{ZhouXuGu,
	annotation = {00006},
	author = {Zhou, Dongruo and Xu, Pan and Gu, Quanquan},
	file = {/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/LectureNotes/Optimization/references/CRNewton/Zhou et al. - Stochastic Variance-Reduced Cubic Regularization M.pdf},
	langid = {english},
	pages = {47},
	title = {Stochastic {{Variance-Reduced Cubic Regularization Methods}}}}

@mastersthesis{mccreesh_accelerated_2019,
	address = {Kingston, Ontario, Canada},
	author = {McCreesh, Michael Patrick Durrell},
	school = {Queen's University},
	title = {Accelerated {Convergence} of {Saddle}-{Point} {Dynamics}},
	year = {2019}}

@book{varga_matrix_2000,
	address = {Berlin},
	author = {Varga, Richard S.},
	edition = {2nd rev. and expanded ed},
	number = {27},
	publisher = {Springer Verlag},
	series = {Springer series in computational mathematics},
	title = {Matrix {Iterative} {Analysis}},
	year = {2000}}

@article{silvester2000determinants,
	author = {Silvester, John R},
	journal = {The Mathematical Gazette},
	number = {501},
	pages = {460--467},
	publisher = {Cambridge University Press},
	title = {Determinants of block matrices},
	volume = {84},
	year = {2000}}

@article{jiang2007algorithm,
	author = {Jiang, Erxiong},
	journal = {Frontiers of Mathematics in China},
	number = {2},
	pages = {227},
	publisher = {Springer Nature BV},
	title = {Algorithm for solving shifted skew-symmetric linear system},
	volume = {2},
	year = {2007}}

@article{chen2023transformed,
	author = {Chen, Long and Wei, Jingrong},
	journal = {Journal of Numerical Mathematics},
	publisher = {De Gruyter},
	title = {Transformed primal-dual methods for nonlinear saddle point systems},
	year = {2023}}

@article{chen1993convergence,
	author = {Chen, Gong and Teboulle, Marc},
	journal = {SIAM Journal on Optimization},
	number = {3},
	pages = {538--543},
	publisher = {SIAM},
	title = {Convergence analysis of a proximal-like minimization algorithm using {Bregman} functions},
	volume = {3},
	year = {1993}}

@book{Khalil:1173048,
	address = {Upper Saddle River, NJ},
	author = {Khalil, Hassan K},
	publisher = {Prentice-Hall},
	title = {{Nonlinear systems; 3rd ed.}},
	year = {2002}}

@book{Haddad2008,
	abstract = { Nonlinear Dynamical Systems and Control presents and develops an extensive treatment of stability analysis and control design of nonlinear dynamical systems, with an emphasis on Lyapunov-based methods. Dynamical system theory lies at the heart of mathematical sciences and engineering. The application of dynamical systems has crossed interdisciplinary boundaries from chemistry to biochemistry to chemical kinetics, from medicine to biology to population genetics, from economics to sociology to psychology, and from physics to mechanics to engineering. The increasingly complex nature of engineering systems requiring feedback control to obtain a desired system behavior also gives rise to dynamical systems.  Wassim Haddad and VijaySekhar Chellaboina provide an exhaustive treatment of nonlinear systems theory and control using the highest standards of exposition and rigor. This graduate-level textbook goes well beyond standard treatments by developing Lyapunov stability theory, partial stability, boundedness, input-to-state stability, input-output stability, finite-time stability, semistability, stability of sets and periodic orbits, and stability theorems via vector Lyapunov functions. A complete and thorough treatment of dissipativity theory, absolute stability theory, stability of feedback systems, optimal control, disturbance rejection control, and robust control for nonlinear dynamical systems is also given. This book is an indispensable resource for applied mathematicians, dynamical systems theorists, control theorists, and engineers.},
	author = {Wassim M. Haddad and VijaySekhar Chellaboina},
	date-modified = {2024-02-19 21:19:13 -0800},
	isbn = {9780691133294},
	publisher = {Princeton University Press},
	title = {Nonlinear Dynamical Systems and Control: A {Lyapunov}-Based Approach},
	urldate = {2022-06-24},
	year = {2008},
	bdsk-url-1 = {http://www.jstor.org/stable/j.ctvcm4hws}}

@article{chen2021unified,
	author = {Chen, Long and Luo, Hao},
	journal = {arXiv preprint arXiv:2108.00132},
	title = {A Unified Convergence Analysis of First Order Convex Optimization Methods via Strong {Lyapunov} Functions},
	year = {2021}}

@article{zhang2022lower,
	author = {Zhang, Junyu and Hong, Mingyi and Zhang, Shuzhong},
	journal = {Mathematical Programming},
	number = {1},
	pages = {901--935},
	publisher = {Springer},
	title = {On lower iteration complexity bounds for the convex concave saddle point problems},
	volume = {194},
	year = {2022}}

@article{qu2018exponential,
	author = {Qu, Guannan and Li, Na},
	journal = {IEEE Control Systems Letters},
	number = {1},
	pages = {43--48},
	publisher = {IEEE},
	title = {On the exponential stability of primal-dual gradient dynamics},
	volume = {3},
	year = {2018}}

@article{browder1967construction,
	author = {Browder, Felix E and Petryshyn, Wolodymyr V},
	journal = {Journal of Mathematical Analysis and Applications},
	number = {2},
	pages = {197--228},
	publisher = {Academic Press},
	title = {Construction of fixed points of nonlinear mappings in {Hilbert} space},
	volume = {20},
	year = {1967}}

@article{zhu1996co,
	author = {Zhu, Dao Li and Marcotte, Patrice},
	journal = {SIAM Journal on Optimization},
	number = {3},
	pages = {714--726},
	publisher = {SIAM},
	title = {Co-coercivity and its role in the convergence of iterative schemes for solving variational inequalities},
	volume = {6},
	year = {1996}}

@article{liu1998regularization,
	author = {Liu, Fengshan and Nashed, M Zuhair},
	journal = {Set-Valued Analysis},
	number = {4},
	pages = {313--344},
	publisher = {Springer},
	title = {Regularization of nonlinear ill-posed variational inequalities and convergence rates},
	volume = {6},
	year = {1998}}

@article{rockafellar1976monotone,
	author = {Rockafellar, R Tyrrell},
	journal = {SIAM journal on control and optimization},
	number = {5},
	pages = {877--898},
	publisher = {SIAM},
	title = {Monotone operators and the proximal point algorithm},
	volume = {14},
	year = {1976}}

@article{nesterov1988approach,
	author = {Nesterov, Yurii},
	journal = {Ekonomika i Mateaticheskie Metody},
	number = {3},
	pages = {509--517},
	title = {On an approach to the construction of optimal methods of minimization of smooth convex functions},
	volume = {24},
	year = {1988}}

@article{guler1992new,
	author = {G{\"u}ler, Osman},
	journal = {SIAM Journal on Optimization},
	number = {4},
	pages = {649--664},
	publisher = {SIAM},
	title = {New proximal point algorithms for convex minimization},
	volume = {2},
	year = {1992}}

@article{beck2009fast,
	author = {Beck, Amir and Teboulle, Marc},
	journal = {SIAM journal on imaging sciences},
	number = {1},
	pages = {183--202},
	publisher = {SIAM},
	title = {A fast iterative shrinkage-thresholding algorithm for linear inverse problems},
	volume = {2},
	year = {2009}}

@article{Benzi.M;Golub.G;Liesen.J2005,
	author = {Benzi, Michele and Golub, Gene H. and Liesen, J{\"o}rg},
	doi = {10.1017/S0962492904000212},
	file = {/Volumes/GoogleDrive/My Drive/biblib/Papers/Benzi, Golub, Liesen/Acta Numer/Benzi, Golub, Liesen - 2005 - Numerical solution of saddle point problems.pdf;/Volumes/GoogleDrive/My Drive/biblib/Papers/Benzi, Golub, Liesen/Acta Numer/Benzi, Golub, Liesen - 2005 - Numerical solution of saddle point problems.pdf;/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/Benzi, Golub, Liesen/Acta Numer/Benzi, Golub, Liesen - 2005 - Numerical solution of saddle point problems.pdf;/Volumes/LongBackupDrive/GoogleDrive/biblib/Papers/Benzi, Golub, Liesen/Acta Numer/Benzi, Golub, Liesen - 2005 - Numerical solution of saddle point problems.pdf},
	issn = {0962-4929},
	journal = {Acta Numer.},
	keywords = {},
	month = may,
	pages = {1--137},
	title = {Numerical Solution of Saddle Point Problems},
	volume = {14},
	year = {2005},
	bdsk-url-1 = {https://doi.org/10.1017/S0962492904000212}}

@article{kim2021accelerated,
	author = {Kim, Donghwan},
	journal = {Mathematical Programming},
	number = {1},
	pages = {57--87},
	publisher = {Springer},
	title = {Accelerated proximal point method for maximally monotone operators},
	volume = {190},
	year = {2021}}

@article{chambolle2011first,
	author = {Chambolle, Antonin and Pock, Thomas},
	journal = {Journal of mathematical imaging and vision},
	number = {1},
	pages = {120--145},
	publisher = {Springer},
	title = {A first-order primal-dual algorithm for convex problems with applications to imaging},
	volume = {40},
	year = {2011}}

@article{chambolle2016ergodic,
	author = {Chambolle, Antonin and Pock, Thomas},
	journal = {Mathematical Programming},
	number = {1},
	pages = {253--287},
	publisher = {Springer},
	title = {On the ergodic convergence rates of a first-order primal--dual algorithm},
	volume = {159},
	year = {2016}}

@article{he2012convergence,
	author = {He, Bingsheng and Yuan, Xiaoming},
	journal = {SIAM Journal on Imaging Sciences},
	number = {1},
	pages = {119--149},
	publisher = {SIAM},
	title = {Convergence analysis of primal-dual algorithms for a saddle-point problem: from contraction perspective},
	volume = {5},
	year = {2012}}

@article{hestenes1969multiplier,
	author = {Hestenes, Magnus R},
	journal = {Journal of optimization theory and applications},
	number = {5},
	pages = {303--320},
	publisher = {Springer},
	title = {Multiplier and gradient methods},
	volume = {4},
	year = {1969}}

@article{zhu2008efficient,
	author = {Zhu, Mingqiang and Chan, Tony},
	journal = {Ucla Cam Report},
	pages = {8--34},
	title = {An efficient primal-dual hybrid gradient algorithm for total variation image restoration},
	volume = {34},
	year = {2008}}

@article{powell1969method,
	author = {Powell, Michael JD},
	journal = {Optimization},
	pages = {283--298},
	publisher = {Academic Press},
	title = {A method for nonlinear constraints in minimization problems},
	year = {1969}}

@article{kovalev2022first,
	author = {Kovalev, Dmitry and Gasnikov, Alexander},
	journal = {arXiv preprint arXiv:2205.05653},
	title = {The First Optimal Algorithm for Smooth and Strongly-Convex-Strongly-Concave Minimax Optimization},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEG5SZWZlcmVuY2VzL1RoZSBGaXJzdCBPcHRpbWFsIEFsZ29yaXRobSBmb3IgU21vb3RoIGFuZCBTdHJvbmdseS1Db252ZXgtU3Ryb25nbHktQ29uY2F2ZSBNaW5pbWF4IE9wdGltaXphdGlvLnBkZk8RBbBib29rsAUAAAAABBAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgBAAABQAAAAEBAABVc2VycwAAAAkAAAABAQAAbG9uZ2NoZW4xAAAABwAAAAEBAABMaWJyYXJ5AAwAAAABAQAAQ2xvdWRTdG9yYWdlBwAAAAEBAABEcm9wYm94AAQAAAABAQAATWF0aAgAAAABAQAAUmVzZWFyY2gMAAAAAQEAAE5vbnN5bW1ldHJpYwoAAAABAQAAUmVmZXJlbmNlcwAAYwAAAAEBAABUaGUgRmlyc3QgT3B0aW1hbCBBbGdvcml0aG0gZm9yIFNtb290aCBhbmQgU3Ryb25nbHktQ29udmV4LVN0cm9uZ2x5LUNvbmNhdmUgTWluaW1heCBPcHRpbWl6YXRpby5wZGYAKAAAAAEGAAAEAAAAFAAAACgAAAA4AAAATAAAAFwAAABoAAAAeAAAAIwAAACgAAAACAAAAAQDAACeWAAAAAAAAAgAAAAEAwAAh5oDAAAAAAAIAAAABAMAAI6aAwAAAAAACAAAAAQDAAAygaYOAAAAAAgAAAAEAwAAXZcEAAAAAAAIAAAABAMAAL2lBAAAAAAACAAAAAQDAABv4wUAAAAAAAgAAAAEAwAAL0dgEwAAAAAIAAAABAMAAKBIYBMAAAAACAAAAAQDAADzJq0VAAAAACgAAAABBgAAPAEAAEwBAABcAQAAbAEAAHwBAACMAQAAnAEAAKwBAAC8AQAAzAEAAAgAAAAABAAAQcXHUvNlaXYYAAAAAQIAAAEAAAAAAAAADwAAAAAAAAAAAAAAAAAAAAgAAAAEAwAACAAAAAAAAAAEAAAAAwMAAPUBAAAIAAAAAQkAAGZpbGU6Ly8vDAAAAAEBAABNYWNpbnRvc2ggSEQIAAAABAMAAAAAhxE5AAAACAAAAAAEAABBxi/IBoAAACQAAAABAQAANDNDNUQ0RkUtREYxNS00QjRGLThGRkYtRkZCOUY2MkIxRTUxGAAAAAECAACBAAAAAQAAAO8TAAABAAAAAAAAAAAAAAABAAAAAQEAAC8AAAAAAAAAAQUAABoAAAABAQAATlNVUkxEb2N1bWVudElkZW50aWZpZXJLZXkAAAQAAAADAwAAdvAGAGkBAAABAgAAMjE2MDg1YmM2NWFkMDc4NDgxZmRjNzBjYzFmZmM1ZGI0ZjYxYjBjNzk5ZTFmZGM4ZTU3MTVmNTQxZGZjMjk2ZDswMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDswMDAwMDAwMDAwMDAwMDIwO2NvbS5hcHBsZS5hcHAtc2FuZGJveC5yZWFkLXdyaXRlOzAxOzAxMDAwMDEyOzAwMDAwMDAwMTVhZDI2ZjM7NTY7L3VzZXJzL2xvbmdjaGVuMS9saWJyYXJ5L2Nsb3Vkc3RvcmFnZS9kcm9wYm94L21hdGgvcmVzZWFyY2gvbm9uc3ltbWV0cmljL3JlZmVyZW5jZXMvdGhlIGZpcnN0IG9wdGltYWwgYWxnb3JpdGhtIGZvciBzbW9vdGggYW5kIHN0cm9uZ2x5LWNvbnZleC1zdHJvbmdseS1jb25jYXZlIG1pbmltYXggb3B0aW1pemF0aW8ucGRmAAAAANgAAAD+////AQAAAAAAAAARAAAABBAAAAwBAAAAAAAABRAAANwBAAAAAAAAEBAAABwCAAAAAAAAQBAAAAwCAAAAAAAAAiAAAOgCAAAAAAAABSAAAFgCAAAAAAAAECAAAGgCAAAAAAAAESAAAJwCAAAAAAAAEiAAAHwCAAAAAAAAEyAAAIwCAAAAAAAAICAAAMgCAAAAAAAAMCAAAPQCAAAAAAAAAcAAADwCAAAAAAAAEcAAABQAAAAAAAAAEsAAAEwCAAAAAAAAgPAAACwDAAAAAAAA/AIAgCADAAAAAAAAAAgADQAaACMAlAAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAZI}}

@article{kovalev2021accelerated,
	author = {Kovalev, Dmitry and Gasnikov, Alexander and Richt{\'a}rik, Peter},
	date-modified = {2024-02-19 21:24:48 -0800},
	journal = {arXiv:2112.15199},
	title = {Accelerated primal-dual gradient method for smooth and convex-concave saddle-point problems with bilinear coupling},
	year = {2021},
	bdsk-file-1 = {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}}

@article{gabay1976dual,
	author = {Gabay, Daniel and Mercier, Bertrand},
	journal = {Computers \& mathematics with applications},
	number = {1},
	pages = {17--40},
	publisher = {Elsevier},
	title = {A dual algorithm for the solution of nonlinear variational problems via finite element approximation},
	volume = {2},
	year = {1976}}

@article{glowinski1975approximation,
	author = {Glowinski, Roland and Marroco, Americo},
	journal = {Revue fran{\c{c}}aise d'automatique, informatique, recherche op{\'e}rationnelle. Analyse num{\'e}rique},
	number = {R2},
	pages = {41--76},
	publisher = {EDP Sciences},
	title = {Sur l'approximation, par {\'e}l{\'e}ments finis d'ordre un, et la r{\'e}solution, par p{\'e}nalisation-dualit{\'e} d'une classe de probl{\`e}mes de {Dirichlet} non lin{\'e}aires},
	volume = {9},
	year = {1975}}

@article{polyak1964some,
	author = {Polyak, Boris T},
	journal = {Ussr computational mathematics and mathematical physics},
	number = {5},
	pages = {1--17},
	publisher = {Elsevier},
	title = {Some methods of speeding up the convergence of iteration methods},
	volume = {4},
	year = {1964}}

@inproceedings{nesterov1983method,
	author = {Nesterov, Yurii Evgen'evich},
	booktitle = {Doklady Akademii Nauk},
	number = {3},
	organization = {Russian Academy of Sciences},
	pages = {543--547},
	title = {A method of solving a convex programming problem with convergence rate ${O}\bigl(\frac{1}{k^2} \bigr)$},
	volume = {269},
	year = {1983}}

@article{saad1986gmres,
	author = {Saad, Youcef and Schultz, Martin H},
	journal = {SIAM Journal on scientific and statistical computing},
	number = {3},
	pages = {856--869},
	publisher = {SIAM},
	title = {{GMRES}: A generalized minimal residual algorithm for solving nonsymmetric linear systems},
	volume = {7},
	year = {1986}}

@article{bai2003hermitian,
	author = {Bai, Zhong-Zhi and Golub, Gene H and Ng, Michael K},
	journal = {SIAM Journal on Matrix Analysis and Applications},
	number = {3},
	pages = {603--626},
	publisher = {SIAM},
	title = {Hermitian and {skew-Hermitian} splitting methods for {non-Hermitian} positive definite linear systems},
	volume = {24},
	year = {2003}}

@article{benzi2004preconditioner,
	author = {Benzi, Michele and Golub, Gene H},
	journal = {SIAM Journal on Matrix Analysis and Applications},
	number = {1},
	pages = {20--41},
	publisher = {SIAM},
	title = {A preconditioner for generalized saddle point problems},
	volume = {26},
	year = {2004}}

@book{idema2007minimal,
	author = {Idema, Reijer and Vuik, Cornelis},
	publisher = {Delft University of Technology},
	title = {A minimal residual method for shifted skew-symmetric systems},
	year = {2007}}

@article{hadjidimos2000successive,
	author = {Hadjidimos, A},
	journal = {Journal of Computational and Applied Mathematics},
	number = {1-2},
	pages = {177--199},
	publisher = {Elsevier},
	title = {Successive overrelaxation {(SOR)} and related methods},
	volume = {123},
	year = {2000}}

@article{bai2007successive,
	author = {Bai, Zhong-Zhi and Golub, Gene H and Ng, Michael K},
	journal = {Numerical Linear Algebra with Applications},
	number = {4},
	pages = {319--335},
	publisher = {Wiley Online Library},
	title = {On successive-overrelaxation acceleration of the {Hermitian} and {skew-Hermitian} splitting iterations},
	volume = {14},
	year = {2007}}

@article{bai2005generalized,
	author = {Bai, Zhong-Zhi and Parlett, Beresford N and Wang, Zeng-Qi},
	journal = {Numerische Mathematik},
	number = {1},
	pages = {1--38},
	publisher = {Springer},
	title = {On generalized successive overrelaxation methods for augmented linear systems},
	volume = {102},
	year = {2005}}

@article{bai2008inexact,
	author = {Bai, Zhong-Zhi and Golub, Gene H and Ng, Michael K},
	journal = {Linear Algebra and Its Applications},
	number = {2-3},
	pages = {413--440},
	publisher = {Elsevier},
	title = {On inexact {Hermitian} and skew-{Hermitian} splitting methods for non-{Hermitian} positive definite linear systems},
	volume = {428},
	year = {2008}}

@article{bai2007accelerated,
	author = {Bai, Zhong-Zhi and Golub, Gene H},
	journal = {IMA Journal of Numerical Analysis},
	number = {1},
	pages = {1--23},
	publisher = {Oxford University Press},
	title = {Accelerated {Hermitian} and skew-{Hermitian} splitting iteration methods for saddle-point problems},
	volume = {27},
	year = {2007}}

@inproceedings{thekumparampil2022lifted,
	author = {Thekumparampil, Kiran K and He, Niao and Oh, Sewoong},
	booktitle = {International Conference on Artificial Intelligence and Statistics},
	organization = {PMLR},
	pages = {4281--4308},
	title = {Lifted primal-dual method for bilinearly coupled smooth minimax optimization},
	year = {2022}}

@article{babuvska1973finite,
	author = {Babu{\v{s}}ka, Ivo},
	journal = {Numerische Mathematik},
	number = {3},
	pages = {179--192},
	publisher = {Springer},
	title = {The finite element method with {Lagrangian} multipliers},
	volume = {20},
	year = {1973}}

@article{Brezzi1974,
	author = {Brezzi, F.},
	journal = {ESAIM: Mathematical Modelling and Numerical Analysis - Mod{\'e}lisation Math{\'e}matique et Analyse Num{\'e}rique},
	language = {eng},
	number = {R2},
	pages = {129-151},
	publisher = {Dunod},
	title = {On the existence, uniqueness and approximation of saddle-point problems arising from {Lagrangian} multipliers},
	url = {http://eudml.org/doc/193255},
	volume = {8},
	year = {1974},
	bdsk-url-1 = {http://eudml.org/doc/193255}}

@book{nesterov2003introductory,
	author = {Nesterov, Yurii},
	publisher = {Springer Science \& Business Media},
	title = {Introductory lectures on convex optimization: {A} basic course},
	volume = {87},
	year = {2003}}

@inproceedings{salim2022optimal,
	author = {Salim, Adil and Condat, Laurent and Kovalev, Dmitry and Richt{\'a}rik, Peter},
	booktitle = {International Conference on Artificial Intelligence and Statistics},
	organization = {PMLR},
	pages = {4482--4498},
	title = {An optimal algorithm for strongly convex minimization under affine constraints},
	year = {2022}}

@article{xie2021dippa,
	author = {Xie, Guangzeng and Han, Yuze and Zhang, Zhihua},
	journal = {arXiv preprint arXiv:2103.08270},
	title = {Dippa: An improved method for bilinear saddle point problems},
	year = {2021}}

@article{attouch2019convergence,
	author = {Attouch, Hedy and Peypouquet, Juan},
	journal = {Mathematical Programming},
	number = {1},
	pages = {391--432},
	publisher = {Springer},
	title = {Convergence of inertial dynamics and proximal algorithms governed by maximally monotone operators},
	volume = {174},
	year = {2019}}

@article{hadjidimos1978accelerated,
	author = {Hadjidimos, Apostolos},
	journal = {Mathematics of Computation},
	number = {141},
	pages = {149--157},
	title = {Accelerated overrelaxation method},
	volume = {32},
	year = {1978}}

@article{vu2022asymptotic,
	author = {Vu, Trung and Raich, Raviv},
	journal = {IEEE Transactions on Signal Processing},
	pages = {4061--4076},
	publisher = {IEEE},
	title = {On asymptotic linear convergence of projected gradient descent for constrained least squares},
	volume = {70},
	year = {2022}}

@article{luo2021accelerated,
	author = {Luo, Hao},
	journal = {arXiv preprint arXiv:2109.12604},
	title = {Accelerated primal-dual methods for linearly constrained convex optimization problems},
	year = {2021}}

@article{kovalev2022accelerated,
	author = {Kovalev, Dmitry and Gasnikov, Alexander and Richt{\'a}rik, Peter},
	journal = {Advances in Neural Information Processing Systems},
	pages = {21725--21737},
	title = {Accelerated primal-dual gradient method for smooth and convex-concave saddle-point problems with bilinear coupling},
	volume = {35},
	year = {2022}}

@inproceedings{jin2022sharper,
	author = {Jin, Yujia and Sidford, Aaron and Tian, Kevin},
	booktitle = {Conference on Learning Theory},
	organization = {PMLR},
	pages = {4362--4415},
	title = {Sharper rates for separable minimax and finite sum optimization via primal-dual extragradient methods},
	year = {2022}}

@book{sutton2018reinforcement,
	author = {Sutton, Richard S and Barto, Andrew G},
	publisher = {MIT press},
	title = {Reinforcement learning: An introduction},
	year = {2018}}

@inproceedings{du2017stochastic,
	author = {Du, Simon S and Chen, Jianshu and Li, Lihong and Xiao, Lin and Zhou, Dengyong},
	booktitle = {International Conference on Machine Learning},
	organization = {PMLR},
	pages = {1049--1058},
	title = {Stochastic variance reduction methods for policy evaluation},
	year = {2017}}

@book{johnson2012numerical,
	author = {Johnson, Claes},
	publisher = {Courier Corporation},
	title = {Numerical solution of partial differential equations by the finite element method},
	year = {2012}}

@article{hemmingsson1996analysis,
	author = {Hemmingsson, Lina and Otto, Kurt},
	journal = {SIAM Journal on Scientific Computing},
	number = {1},
	pages = {47--64},
	publisher = {SIAM},
	title = {Analysis of semi-Toeplitz preconditioners for first-order PDEs},
	volume = {17},
	year = {1996}}

@article{bai2005block,
	author = {Bai, Zhong-Zhi and Golub, Gene H and Lu, Lin-Zhang and Yin, Jun-Feng},
	journal = {SIAM Journal on Scientific Computing},
	number = {3},
	pages = {844--863},
	publisher = {SIAM},
	title = {Block triangular and skew-Hermitian splitting methods for positive-definite linear systems},
	volume = {26},
	year = {2005}}

@article{van1992bi,
	author = {Van der Vorst, Henk A},
	journal = {SIAM Journal on scientific and Statistical Computing},
	number = {2},
	pages = {631--644},
	publisher = {SIAM},
	title = {Bi-CGSTAB: A fast and smoothly converging variant of Bi-CG for the solution of nonsymmetric linear systems},
	volume = {13},
	year = {1992}}

@inproceedings{wang2017exploiting,
	author = {Wang, Jialei and Xiao, Lin},
	booktitle = {International Conference on Machine Learning},
	organization = {PMLR},
	pages = {3694--3702},
	title = {Exploiting strong convexity from data with primal-dual first-order algorithms},
	year = {2017}}

@article{xiao2019dscovr,
	author = {Xiao, Lin and Yu, Adams Wei and Lin, Qihang and Chen, Weizhu},
	journal = {The Journal of Machine Learning Research},
	number = {1},
	pages = {1634--1691},
	publisher = {JMLR. org},
	title = {Dscovr: Randomized primal-dual block coordinate algorithms for asynchronous distributed optimization},
	volume = {20},
	year = {2019}}

@inproceedings{lei2017doubly,
	author = {Lei, Qi and Yen, Ian En-Hsu and Wu, Chao-yuan and Dhillon, Inderjit S and Ravikumar, Pradeep},
	booktitle = {International Conference on Machine Learning},
	organization = {PMLR},
	pages = {2034--2042},
	title = {Doubly greedy primal-dual coordinate descent for sparse empirical risk minimization},
	year = {2017}}

@article{mokhtari2020convergence,
	author = {Mokhtari, Aryan and Ozdaglar, Asuman E and Pattathil, Sarath},
	journal = {SIAM Journal on Optimization},
	number = {4},
	pages = {3230--3251},
	publisher = {SIAM},
	title = {Convergence rate of ${O}(1/k)$ for optimistic gradient and extragradient methods in smooth convex-concave saddle point problems},
	volume = {30},
	year = {2020}}

@article{li2023nesterov,
	author = {Li, Chris Junchi and Yuan, Angela and Gidel, Gauthier and Gu, Quanquan and Jordan, Michael},
	title = {Nesterov Meets Optimism: Rate-Optimal Separable Minimax Optimization},
	year = {2023}}

@techreport{el2017general,
	author = {El Halabi, Marwa and Hsieh, Ya-Ping and Vu, Bang and Nguyen, Quang and Cevher, Volkan},
	date-modified = {2024-02-19 21:32:17 -0800},
	title = {General proximal gradient method: A case for {non-Euclidean} norms},
	year = {2017}}

@article{hou2013linear,
	author = {Hou, Ke and Zhou, Zirui and So, Anthony Man-Cho and Luo, Zhi-Quan},
	journal = {Advances in Neural Information Processing Systems},
	title = {On the linear convergence of the proximal gradient method for trace norm regularization},
	volume = {26},
	year = {2013}}

@article{zosso2017efficient,
	author = {Zosso, Dominique and Osting, Braxton and Xia, Mandy and Osher, Stanley J},
	journal = {Journal of Scientific Computing},
	pages = {416--437},
	publisher = {Springer},
	title = {An efficient primal-dual method for the obstacle problem},
	volume = {73},
	year = {2017}}

@article{chen2008ifem,
	author = {Chen, Long},
	journal = {Preprint, University of Maryland},
	title = {iFEM: an innovative finite element methods package in MATLAB},
	year = {2008}}

@article{chen2024transformed,
	author = {Chen, Long and Guo, Ruchi and Wei, Jingrong},
	journal = {arXiv preprint arXiv:2312.12355},
	title = {Transformed Primal-Dual Methods with Variable-Preconditioners},
	year = {2023}}

@article{qi1993nonsmooth,
	author = {Qi, Liqun and Sun, Jie},
	journal = {Mathematical programming},
	number = {1-3},
	pages = {353--367},
	publisher = {Springer},
	title = {A nonsmooth version of {Newton}'s method},
	volume = {58},
	year = {1993}}

@article{li2018highly,
	author = {Li, Xudong and Sun, Defeng and Toh, Kim-Chuan},
	journal = {SIAM Journal on Optimization},
	number = {1},
	pages = {433--458},
	publisher = {SIAM},
	title = {A highly efficient semismooth {Newton} augmented {Lagrangian} method for solving {Lasso} problems},
	volume = {28},
	year = {2018}}

@article{jacobs2019solving,
	author = {Jacobs, Matt and L{\'e}ger, Flavien and Li, Wuchen and Osher, Stanley},
	journal = {SIAM Journal on Numerical Analysis},
	number = {3},
	pages = {1100--1123},
	publisher = {SIAM},
	title = {Solving large-scale optimization problems with a convergence rate independent of grid size},
	volume = {57},
	year = {2019}}

@article{chen2023accelerated,
	author = {Chen, Long and Wei, Jingrong},
	journal = {arXiv preprint arXiv:2303.09009},
	title = {Accelerated gradient and skew-symmetric splitting methods for a class of monotone operator equations},
	year = {2023}}

@article{rockafellar1976augmented,
	author = {Rockafellar, R Tyrrell},
	journal = {Mathematics of operations research},
	number = {2},
	pages = {97--116},
	publisher = {INFORMS},
	title = {Augmented {Lagrangians} and applications of the proximal point algorithm in convex programming},
	volume = {1},
	year = {1976}}

@article{goldstein1964convex,
	author = {Goldstein, Alan A},
	title = {Convex programming in Hilbert space},
	year = {1964}}

@article{polyak1966constrained,
	author = {Polyak, Boris T and LEVITIN, ES},
	journal = {USSR Compu-tational Mathematics and Mathematical Physics6},
	pages = {1--50},
	title = {Constrained minimization methods},
	volume = {5},
	year = {1966}}

@article{calamai1987projected,
	author = {Calamai, Paul H and Mor{\'e}, Jorge J},
	journal = {Mathematical programming},
	number = {1},
	pages = {93--116},
	publisher = {Springer},
	title = {Projected gradient methods for linearly constrained problems},
	volume = {39},
	year = {1987}}

@article{bertsekas1976penalty,
	author = {Bertsekas, Dimitri P},
	journal = {SIAM Journal on Control and Optimization},
	number = {2},
	pages = {216--235},
	publisher = {SIAM},
	title = {On penalty and multiplier methods for constrained minimization},
	volume = {14},
	year = {1976}}

@article{cherukuri2017saddle,
	author = {Cherukuri, Ashish and Gharesifard, Bahman and Cortes, Jorge},
	journal = {SIAM Journal on Control and Optimization},
	number = {1},
	pages = {486--511},
	publisher = {SIAM},
	title = {Saddle-point dynamics: conditions for asymptotic stability of saddle points},
	volume = {55},
	year = {2017}}

@book{arrow1958studies,
	address = {Stanford, CA},
	author = {Arrow, Kenneth Joseph and Hurwicz, Leonid and Uzawa, Hirofumi},
	publisher = {Stanford University Press},
	title = {Studies in linear and non-linear programming},
	year = {1958}}

@article{cherukuri2017role,
	author = {Cherukuri, Ashish and Mallada, Enrique and Low, Steven and Cort{\'e}s, Jorge},
	journal = {IEEE Transactions on Automatic Control},
	number = {8},
	pages = {2449--2464},
	publisher = {IEEE},
	title = {The role of convexity in saddle-point dynamics: Lyapunov function and robustness},
	volume = {63},
	year = {2017}}

@inproceedings{ding2019global,
	author = {Ding, Dongsheng and Jovanovi{\'c}, Mihailo R},
	booktitle = {2019 American Control Conference (ACC)},
	organization = {IEEE},
	pages = {3414--3419},
	title = {Global exponential stability of primal-dual gradient flow dynamics based on the proximal augmented Lagrangian},
	year = {2019}}

@inproceedings{du2019linear,
	author = {Du, Simon S and Hu, Wei},
	booktitle = {The 22nd International Conference on Artificial Intelligence and Statistics},
	organization = {PMLR},
	pages = {196--205},
	title = {Linear convergence of the primal-dual gradient method for convex-concave saddle point problems without strong convexity},
	year = {2019}}

@article{glad1979multiplier,
	author = {Glad, Torkel and Polak, Elijah},
	journal = {Mathematical Programming},
	number = {1},
	pages = {140--155},
	publisher = {Springer},
	title = {A multiplier method with automatic limitation of penalty growth},
	volume = {17},
	year = {1979}}

@article{di1989exact,
	author = {Di Pillo, Gianni and Grippo, Luigi},
	journal = {SIAM Journal on control and optimization},
	number = {6},
	pages = {1333--1360},
	publisher = {SIAM},
	title = {Exact penalty functions in constrained optimization},
	volume = {27},
	year = {1989}}

@article{lucidi1992new,
	author = {Lucidi, Stefano},
	journal = {SIAM Journal on optimization},
	number = {4},
	pages = {558--574},
	publisher = {SIAM},
	title = {New results on a continuously differentiable exact penalty function},
	volume = {2},
	year = {1992}}

@article{srivastava2020nesterov,
	author = {Srivastava, Priyank and Cort{\'e}s, Jorge},
	journal = {IEEE Control Systems Letters},
	number = {2},
	pages = {415--420},
	publisher = {IEEE},
	title = {Nesterov acceleration for equality-constrained convex optimization via continuously differentiable penalty functions},
	volume = {5},
	year = {2020}}

@article{devolder2014first,
	author = {Devolder, Olivier and Glineur, Fran{\c{c}}ois and Nesterov, Yurii},
	journal = {Mathematical Programming},
	pages = {37--75},
	publisher = {Springer},
	title = {First-order methods of smooth convex optimization with inexact oracle},
	volume = {146},
	year = {2014}}

@article{patrascu2018convergence,
	author = {Patrascu, Andrei and Necoara, Ion},
	journal = {IEEE Transactions on Automatic Control},
	number = {10},
	pages = {3317--3329},
	publisher = {IEEE},
	title = {On the convergence of inexact projection primal first-order methods for convex minimization},
	volume = {63},
	year = {2018}}

@article{zhu2023optimal,
	author = {Zhu, Zhenyuan and Chen, Fan and Zhang, Junyu and Wen, Zaiwen},
	journal = {arXiv preprint arXiv:2308.06470},
	title = {On the Optimal Lower and Upper Complexity Bounds for a Class of Composite Optimization Problems},
	year = {2023}}

@article{chen2017solving,
	author = {Chen, Puyin and Huang, Jianguo and Sheng, Huashan},
	journal = {Journal of Computational and Applied Mathematics},
	pages = {100--114},
	publisher = {Elsevier},
	title = {Solving steady incompressible Navier--Stokes equations by the Arrow--Hurwicz method},
	volume = {311},
	year = {2017}}

@article{chen1998global,
	author = {Chen, Xiaojun},
	journal = {SIAM journal on numerical analysis},
	number = {3},
	pages = {1130--1148},
	publisher = {SIAM},
	title = {Global and superlinear convergence of inexact Uzawa methods for saddle point problems with nondifferentiable mappings},
	volume = {35},
	year = {1998}}

@article{chen1998preconditioned,
	author = {Chen, Xiaojun},
	journal = {Journal of computational and applied mathematics},
	number = {2},
	pages = {207--224},
	publisher = {Elsevier},
	title = {On preconditioned Uzawa methods and SOR methods for saddle-point problems},
	volume = {100},
	year = {1998}}

@article{hu2006nonlinear,
	author = {Hu, Qiya and Zou, Jun},
	journal = {SIAM Journal on Optimization},
	number = {3},
	pages = {798--825},
	publisher = {SIAM},
	title = {Nonlinear inexact Uzawa algorithms for linear and nonlinear saddle-point problems},
	volume = {16},
	year = {2006}}

@article{bramble1997analysis,
	author = {Bramble, James H and Pasciak, Joseph E and Vassilev, Apostol T},
	journal = {SIAM Journal on Numerical Analysis},
	number = {3},
	pages = {1072--1092},
	publisher = {SIAM},
	title = {Analysis of the inexact Uzawa algorithm for saddle point problems},
	volume = {34},
	year = {1997}}

@article{krichene2015accelerated,
	author = {Krichene, Walid and Bayen, Alexandre and Bartlett, Peter L},
	journal = {Advances in neural information processing systems},
	title = {Accelerated mirror descent in continuous and discrete time},
	volume = {28},
	year = {2015}}

@article{beck2003mirror,
	author = {Beck, Amir and Teboulle, Marc},
	journal = {Operations Research Letters},
	number = {3},
	pages = {167--175},
	publisher = {Elsevier},
	title = {Mirror descent and nonlinear projected subgradient methods for convex optimization},
	volume = {31},
	year = {2003}}

@article{kose1956solutions,
	author = {Kose, T},
	journal = {Econometrica, Journal of the Econometric Society},
	pages = {59--70},
	publisher = {JSTOR},
	title = {Solutions of saddle value problems by differential equations},
	year = {1956}}

@article{metelev2024decentralized,
	author = {Metelev, Dmitry and Rogozin, Alexander and Gasnikov, Alexander and Kovalev, Dmitry},
	journal = {Computational Management Science},
	number = {1},
	pages = {5},
	publisher = {Springer},
	title = {Decentralized saddle-point problems with different constants of strong convexity and strong concavity},
	volume = {21},
	year = {2024}}

@article{taylor2023optimal,
	author = {Taylor, Adrien and Drori, Yoel},
	journal = {Mathematical Programming},
	number = {1},
	pages = {557--594},
	publisher = {Springer},
	title = {An optimal gradient method for smooth strongly convex minimization},
	volume = {199},
	year = {2023}}

@book{nesterov2013introductory,
	author = {Nesterov, Yurii},
	publisher = {Springer Science \& Business Media},
	title = {Introductory lectures on convex optimization: A basic course},
	volume = {87},
	year = {2013}}

@article{wei2024accelerated,
	author = {Wei, Jingrong and Chen, Long},
	journal = {arXiv preprint arXiv:2406.09772},
	title = {Accelerated Over-Relaxation Heavy-Ball Methods with Provable Acceleration and Global Convergence},
	year = {2024}}
