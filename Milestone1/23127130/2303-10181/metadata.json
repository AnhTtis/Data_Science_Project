{
    "arxiv_id": "2303.10181",
    "paper_title": "Operating critical machine learning models in resource constrained regimes",
    "authors": [
        "Raghavendra Selvan",
        "Julian Sch√∂n",
        "Erik B Dam"
    ],
    "submission_date": "2023-03-17",
    "revised_dates": [
        "2023-03-21"
    ],
    "latest_version": 1,
    "categories": [
        "cs.LG",
        "cs.AI"
    ],
    "abstract": "The accelerated development of machine learning methods, primarily deep learning, are causal to the recent breakthroughs in medical image analysis and computer aided intervention. The resource consumption of deep learning models in terms of amount of training data, compute and energy costs are known to be massive. These large resource costs can be barriers in deploying these models in clinics, globally. To address this, there are cogent efforts within the machine learning community to introduce notions of resource efficiency. For instance, using quantisation to alleviate memory consumption. While most of these methods are shown to reduce the resource utilisation, they could come at a cost in performance. In this work, we probe into the trade-off between resource consumption and performance, specifically, when dealing with models that are used in critical settings such as in clinics.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.10181v1"
    ],
    "publication_venue": "Source code available at https://github.com/raghavian/redl"
}