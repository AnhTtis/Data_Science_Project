\input{img/prototype_img}

\section{Design Considerations and Prototype}
\label{sec:prototype}

The question which motivates our research is how to design \simNonHumRobots{} so humans will trust them. The answer to this question is relatively straightforward with respect to the cognitive dimension – the robot should look reliable and should not make errors. However, this question is much more interesting with respect to the affective dimension of trust, which arguably is even more important because affective trust increases the willingness to cooperate and forgive errors. Research on trust in humans suggests that the ability to synchronize with the human partner may be an important factor in perceiving the robot as trustworthy.

Based on the above motivation and a review of related work, in this paper, we explore synchronization as a means of establishing trust between humans and \simNonHumRobots{}. While the literature highlights various types of body movements and body signals that could be used to establish such synchronization, in our work, we explore synchronization with upper body movements as an example. This way, we wanted to avoid complex movements on the participant's side, such as gesticulating or nodding. We wanted to obtain the simplest possible patterns leading to synchronization at the level of whole-body movement. For this, we designed a prototype that can mimic the participant’s upper body movements by bending the prototype's upper part. Besides synchronized movements, it can also generate random or simple movement patterns. In the following section, we present the design goals and the implementation of the prototype.

\subsection{Design Considerations}

To exclude possible confounding factors, we opted for an abstract form. That is, the participant would not associate it with anything known. In particular, we wanted to avoid anthropomorphizing the form of the robot. We also tried to prevent associations with all animate forms, which could be associated with expectations of preserving the prototype or carrying specific attitudes or emotions. We also avoided association with known machines, particularly with all kinds of robots, including industrial robots. For this reason, we chose to construct a 3-tendon single-segment continuum robot \cite{Robinson1999ContinuumR} that has no rigid joints associated with a stereotypical robot. Additionally, in the participant’s instructions, we used the word installation instead of a machine or robot to direct associations toward an abstract art object rather than a practical device.

%Thanks to the creation of our own research tool, we also had the opportunity to integrate a coin acceptor with the machine (see fig. \ref{fig:insync:prototype}D). Through this, the trust-game phase of the experiment could be presented as a continuation of the interaction with the machine.

%\input{img/prototype_math_picture}

\subsection{The prototype}
\label{sec:prototype:construction}
%Based on many years of experience in creating installations in the field of art and science popularization, as well as integrating the perspectives of an artist, designer, psychologist and computer scientist, we have conducted several experiments with various materials and types of actuators. Ultimately, we developed two prototypes and selected one after initial testing to carry out the research described here.

We chose a simple form, a flexible vertical element with a length of 1 meter, placed on a 90 cm height stand. The movement is obtained by bending the flexible element into an arc with a variable radius and direction of deflection. In pilot studies, we noticed that this form of object and this type of movement made study participants tend to imitate the prototype's movement by flexing the upper body and flexing the spine. With increasing intensity of body movement, participants started to move their hips and shoulders. 

We prepared a GitHub repository\footnote{GitHub repository: https://github.com/wbartkowski/In-Sync-Robot-Prototype} containing the prototype's technical documentation, mechanical parts, 3D models for printing, electronic schematics, software source code, and a complete list of required components from external vendors. We hope it helps the HCI community, e.g., replicate the experiment or build the robot for other purposes. 

%\subsection{Construction of single-segment continuum robot}

\subsubsection{Construction, mechanics, materials, actuation, and safety}

We opted to use a cable/tendon actuation, the most common method of driving continuum robots. As depicted in fig. \ref{fig:insync:prototype:model}, our cable-driven continuum robot has multiple spacer structures connected in series by a backbone located at the center axis. The three cables are spaced 120 degrees around the center backbone. Cables pass through a series of spacer structures that keep the cables in the correct position relative to the backbone. The end of the cables is fixed to the end structure on the top and to the actuators on the other end. As actuators pull the cable, the cable length inside the structure of the continuum robot is decreased, thus forcing the robot's structure to bend toward the side of the pulled cable. Through the coordinated displacement of each driving cable, the continuum robot can bend toward any specified direction \(\theta\) with a defined bending angle \(\phi\). As actuators    , we used two-phase stepper motors 17HS4401 controlled by TRINAMIC's TMC2209, an ultra-silent motor driver. Using this setup, we managed to achieve a smooth and noiseless movement, thus eliminating additional factors that may affect the perception of the study participant.

For safety reasons, we have limited the bending angle to 20 degrees to prevent the robot's tip from hitting the participant if they got too close. Because some delay is needed in mimicry, we also have limited acceleration to \(62.8\frac{cm}{s^2}\) and a maximum speed of cable pulling to \(25.12\frac{cm}{s}\).

We built two iterations of the prototype based on different materials. The first prototype uses a backbone made of a densely wound spring steel spring with a diameter of 12mm. Pilot studies indicated that participants perceived this as heavy and dangerous. Additionally, some participants were concerned about being accidentally hit by the robot. A sense of insecurity or an unfriendly appearance eliminated the possibility of establishing trust. Therefore, in the second iteration, we used a 3mm diameter fiberglass backbone also used to construct kites. The participants perceived this structure as light, airy, and non-threatening.

%\todo{DONE! some more implementaiton details here. We used an arduino/esp32/... these motors, implemented this in c, ... even though design committee, this is still a computer science driven conference, they like things like that.}

Other crucial parts of the prototype's structure were designed in CAD software Fusion 360, and 3D printed using PET-G filament, having excellent mechanical properties.

\subsubsection{Electronic, connectivity, and software}

We use Espressif Systems ESP32 chip with Xtensa® 32-bit LX6 microprocessors to compute the robot movement formula and control the actuator drivers. We chose ESP32 because it supports the ESP-NOW protocol developed by Espressif, which enables multiple devices to communicate with one another using ESP32’s Wi-Fi hardware without needing a Wi-Fi router, reducing the complexity of the hardware setup. Moreover, ESP-NOW is connectionless with no handshake required (as required for, e.g., Bluetooth pairing), so this solution was very convenient for our research setting, where three devices (robot prototype, orientation sensor device, and data recorder) have to communicate constantly with low latency and the possibility of instant reconnection in case of accidental power loss and during research hardware setup. 
 
Additionally, in the prototype, we use a separate microcontroller based on ATmega328P to control experiment conditions and coin acceptor. ATmega328P is communicating with ESP32 over the USART interface.  

Software for the prototype and other devices is written in C language and developed using Visual Studio Code environment with PlatformIO extension for easy management of different electronics development platforms.

\input{img/prototype_schematic_math}

\subsection{Movement Tracking and Mapping to Movements of the Prototype}

\subsubsection{Custom-built orientation sensor}

We tracked the participants' upper body movements using a custom-built orientation sensor device based on the Bosch BNO055 9-DOF IMU sensor with integrated sensor data fusion algorithms and calibration algorithms. We used the ESP-NOW protocol for wireless communication with the prototype based on the ESP32 chip (see the previous section). We integrated into the device a lithium-ion battery with a charger. Using a fusion algorithm, we extracted the orientation data, such as a pitch, roll, and heading, from the sensor. We transformed the orientation data through the formula (see fig.~\ref{fig:insync:prototype:math}) into the bending as described in the next subsection, \ref{sec:mapping}, where the heading corresponds to \(\theta\), and pitch and roll are used to compute \(\phi\). 

\subsubsection{Movement mapping}
\label{sec:mapping}

The orientation of the sensor placed on the participant's back is transformed into the orientation of the reference system at the tip of the prototype backbone (see fig. \ref{fig:teaser}) by bending the backbone caused by stretching the cables running along the inextensible backbone (see fig. \ref{fig:insync:prototype:model}). The degree of stretching of the cables \(l_1, l_2, l_3\) is calculated according to the formula~\cite{nazari2019forward} derived from the bending parameters of the curve defined by the bend direction angle \(\theta\) and bend angle \(\phi\) (see fig. \ref{fig:insync:prototype:mathsche}). 
