\section{Evaluation 2: Establishing Trust}
\label{sec:eval2}

Building on the results of the first evaluation, we conducted a second evaluation to investigate the influence of motion synchronization on users' trust formation towards embodied AI representations. More specifically, we investigated the following research questions:

\begin{description}
	\item[RQ1] TODO
	\item[RQ2] TODO
\end{description}

We obtained an ethics approval from our institution before the experiment, which had no objections. In the following section, we report on the methodology and results of the evaluation.

\subsection{Methodology}

To answer the research questions, we conducted a controlled experiment in which participants interacted with an embodied AI system. 

\subsubsection{Design and Task}
\label{sec:methodology:design}

We explained to the participants that we are working on a novel system for human-machine interaction and gave them the task to freely explore the system. To do this, participants were allowed to move around the room at will for 5 minutes.  Then, we gave the participants their fee of about \trustGameMoney{} (in local currency) and asked them to play a version of the trust game with the prototype. Participants could deposit any portion of the amount they were given (between 0 and \trustGameMoney{}) into the system. We informed the participants that the system would be credited with the tripled amount of their deposit and subsequently, at will, would pay a share (between 0 and 15 of this sum back.

Following the results of our exploratory evaluation, we expected that the type of movement performed by the device during the interaction would affect the participants' sense of trust in interacting with the AI system. Therefore, we varied the \factorMove{} as an independent variable with four levels, namely

\begin{description}
	\item[synchronized] as a device with movements synchronized to the participants movements. Based on the results of the explorative study, we chose x,y,z as synchronization parameters.\todo{details on synchronization parameters}
	\item[simple] as a simple and recognizable movement where the displacement rotates slowly around the center.
	\item[random] as a device with random movements. We chose the parameters of the random motion in a way that the amplitude and frequency of the motions were comparable to the motions emitted by the device in synchronization mode.
	\item[human] as a repetition of the movements of another individual, which are, therefore, not random, since they reflect the movements of a real person, but have no connection to the movements of the respective participant.
\end{description}

We varied the independent variable in a between-subjects design by assigning each participant to one of the four conditions. For each condition, we meassured the following dependent variables:

\begin{description}
	\item[\dvMoney{}] Similar to previous work in assessing trust in machines\todo{list 3-4 RW}, we used the amount of money staked in the trust game as a measure of the trust participants placed in the system.
	\item[\dvSTS{}] To further gain insight into the trust relationship between the machine and the participant, we employed the widely used \ac{STS} as proposed by \citet{Jian2000}. The \ac{STS} consists of twelve 7-point Likert items assessing different aspects of the trust placed in the system.
%	\item[\dvMovement{}] In addition to the measures quantifying trust, we recorded the participant's spatial movement and orientation during the exploration phase. We did this to uncover correlations between the user's movements - and the system's movements stimulated by them - and the trust placed in the system.
\end{description}


%we need a task that

%- stimulates movement
%- has the AI as a potential helpful item
%- 


%- trust game? Has no movement. 
%- we need something that has a collaborative aspect (AI as partner)

%DV:
%- System Trust Scale Jian et al.
%- 

\subsubsection{Study Setup and Apparatus}

- tracking

- adjustments to the prototype as presented earlier

- room size, position of the device

\subsubsection{Procedure}

After welcoming the participants, we introduced them to the topic of the experiment and asked
them to fill a consent form together with a demographic questionnaire. After that, we informed them that they were about to interact with a novel prototype of an AI-powered human-computer interaction device, which would react to their movements. We gave participants the task of interacting with and learning about this novel device. We told them that we would ask them questions about the device after a 5-minute exploration phase. We did not give the participants any further instructions about their actions and let them freely explore the device and its function in their chosen way. We further instructed the participants that we would measure their physiological body signals such as galvanic skin response and pulse during the exploration and informed them that we would need to attach a recording device to their body for this purpose. In fact, we attached the tracking unit as described in the previous section to the participants' backs to record their position and orientation in space.

After this introductory phase, we led participants to the room with the prototype and left to observe the experiment from an adjacent room through a camera view. After participants had 5 minutes to explore the device and its responses, the investigator returned to the room and asked the participant to leave the room together. After that, we asked the participants to complete the \ac{STS} and asked them for qualitative feedback in a semi-structured interview to assess their understanding of the functionality of the device and their feelings towards it.

Subsequently, we continued with the second phase of the experiment. We handed out the compensation in xy\todo{number of coins} coins to the participants and informed them that they had the chance to increase their compensation by playing a game with the device. We explained the rules of the trust game to the participants and told them that their participation was voluntary. We led the participants back to the room with the device and left them there alone with the device. Participants had as much time as they wanted to decide how much of their compensation they wanted to wager.\todo{how do participants enter the amount?} Following this, the machine paid back 1.5 times the participant's stake (with a random variance of 10\%). Thus, all participants who wagered their money had a positive winning experience. Finally, we brought the participants back out of the room and asked them to fill out the \ac{STS} again. In addition, we asked them again for qualitative feedback in a semi-structured interview regarding how their trust in the system had changed.

\subsubsection{Hygiene Measures}

All participants and the investigator were vaccinated against COVID-19 and tested negative using an antigen test on the same day. We made sure that only the investigator and the participant were present in the room. Both, the investigator and the participants, wore medical face masks throughout the experiment. Between participants, we disinfected the experimental setup and all surfaces touched and ventilated the room for 30 minutes. 

\subsubsection{Analysis}

We analyzed the recorded data using 1-way ANOVAs to unveil significant main effects. We employed Shapiro-Wilk’s test and Bartlett's test to check the data for violations of the assumptions of normality and homogeneity of variances, respectively. If one of the assumptions was violated, we performed a non-parametric analysis as described below. When the ANOVA indicated significant results, we used pairwise t-tests with Bonferroni correction for post-hoc analysis. For the non-parametric analysis of the Likert items, we used the Kruskal–Wallis 1-way analysis of variance with Dunn's tests for multiple comparisons for post-hoc comparisons. We further report the partial eta-squared \petasquared{} as an estimate of the effect size, classified using Cohen's suggestions as small ($>.0099$), medium ($>.0588$), or large ($>.1379$)~\cite{Cohen1988}.

\subsubsection{Participants}

We recruited a total of 51 participants (29 identified as female, 22 as male) from our university's mailing list. The participants were aged between 19 and 51 ($\mu = 23.5$, $\sigma = 5.4$). We divided the participants to the three experimental conditions in such a way that they were roughly equally distributed with respect to age and gender, resulting in 17 participants per condition. The participants received around \trustGameMoney{} in the local currency as compensation, which they could use in the trust game as part of the study.

\subsection{Results}

\input{img/results_sts_money.tex}

In the following section, we report the results of the controlled experiment as described above.

\subsubsection{System Trust Scale}

We evaluated the participant's trust in the system using the \ac{STS} questionnaire. \todo{description of how we came up with the one mean value.}. 

We found trust ratings on the \ac{STS} ranging from \val{3.59}{.74} (\factorMoveLvlRandom{}) over \val{3.90}{.91} (\factorMoveLvlNone{}) to \val{4.62}{.80} (\factorMoveLvlSynchronized{}), see fig. \ref{fig:insync:results:sts}. A Kruskal-Wallis test indicated a significant (\kruskalwallis{2}{11.18}{<.01}) influence of the \ivMovement{} on the perceived trust of the participants with a \efETAsquared{0.19} effect size. Dunn's post-hoc test corrected for multiple comparisons using the Bonferroni method confirmed significantly higher trust ratings for \factorMoveLvlSynchronized{} compared to both, \factorMoveLvlNone{} (\ztest{-2.48}{<.05}) and \factorMoveLvlRandom{} (\ztest{-3.18}{<.01}). We could not find any significant differences beteen \factorMoveLvlNone{} and \factorMoveLvlRandom{} (\ztest{.71}{>.05}). 

\input{img/likerttable.tex}

To gain further insights into the participants' attitudes towards the \factorMove{} of the system, we analyzed the individual subscales of the \ac{STS}. For six subscales, a Kruskal-Wallis test indicated significant differences (see table \ref{tab:insync:results:sts}). Post-hoc tests confirmed significant differences between the \factorMoveLvlSynchronized{} and \factorMoveLvlRandom{} conditions for five questions. Additionally, we found significant differences between \factorMoveLvlSynchronized{} and \factorMoveLvlNone{} for two questions. We could not find significant differences between \factorMoveLvlNone{} and \factorMoveLvlRandom{} for any question. Table \ref{tab:insync:results:sts} lists the test result for the individual questions. Further, figure \ref{fig:insync:results:likert} provides a breakdown of the internal distribution of the measured variables for all questions with significant differences.

\input{img/likert.tex}

\subsubsection{The Trust Game}

As an additional measurement for the participants' trust towards the machine, we adapted a method of the trust game as described in section \ref{sec:methodology:design}. We found the highest number of inserted coins for the \factorMoveLvlSynchronized{} condition (\val{2.82}{1.67}), followed by \factorMoveLvlRandom{} (\val{2.47}{1.66}) and \factorMoveLvlNone{} (\val{2.41}{1.33}), see fig. \ref{fig:insync:results:money}. As Shapiro-Wilk's test indicated a violation of the assumption of normality of the residuals that could not be resolved by transforming the data on the log scale, we continued with a non-parametric analysis. However, a subsequent Kruskal-Wallis test did not reveal a significant (\kruskalwallis{2}{0.85}{>.05}) influence of the \factorMove{} of the system on the number of coins inserted.


\subsubsection{Qualitative Results}
 