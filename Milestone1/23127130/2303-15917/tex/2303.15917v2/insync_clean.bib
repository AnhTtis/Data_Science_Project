@inproceedings{Aaltonen2017,
  title = {Hello {{Pepper}}, {{May I Tickle You}}? {{Children}}'s and {{Adults}}' {{Responses}} to an {{Entertainment Robot}} at a {{Shopping Mall}}},
  shorttitle = {Hello {{Pepper}}, {{May I Tickle You}}?},
  booktitle = {Proceedings of the {{Companion}} of the 2017 {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  author = {Aaltonen, Iina and Arvola, Anne and Heikkil{\"a}, P{\"a}ivi and Lammi, Hanna},
  year = {2017},
  month = mar,
  series = {{{HRI}} '17},
  pages = {53--54},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3029798.3038362},
  abstract = {We took a social robot Pepper to a shopping mall for one day to see what kind of initial responses it draws from people. We observed that the robot was quickly surrounded by children when there were others-especially adults-interacting with it. The children seemed to especially enjoy the activity-related applications, such as tickling the robot or giving a high-five. Adults were interested in hearing about useful applications and tended to talk to the robot as if it were any machine capable of speech recognition. These observations will help to design more interactive and entertaining applications for shopping mall robots.},
  isbn = {978-1-4503-4885-0},
  keywords = {adults,children,entertainment,human-robot interaction,observations,pepper,shopping mall,social robot},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Aaltonen et al_2017_Hello Pepper, May I Tickle You2.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\UXDNTJVK\\Aaltonen et al. - 2017 - Hello Pepper, May I Tickle You Children's and Adu.pdf}
}

@article{ALARCON2023103858,
  title = {Differential Biases in Human-Human versus Human-Robot Interactions},
  author = {Alarcon, Gene M. and Capiola, August and Hamdan, Izz Aldin and Lee, Michael A. and Jessup, Sarah A.},
  year = {2023},
  month = jan,
  journal = {Applied Ergonomics},
  volume = {106},
  pages = {103858},
  issn = {0003-6870},
  doi = {10.1016/j.apergo.2022.103858},
  abstract = {The research on human-robot interactions indicates possible differences toward robot trust that do not exist in human-human interactions. Research on these differences has traditionally focused on performance degradations. The current study sought to explore differences in human-robot and human-human trust interactions with performance, consideration, and morality trustworthiness manipulations, which are based on ability/performance, benevolence/purpose, and integrity/process manipulations, respectively, from previous research. We used a mixed factorial hierarchical linear model design to explore the effects of trustworthiness manipulations on trustworthiness perceptions, trust intentions, and trust behaviors in a trust game. We found partner (human versus robot) differences across all three trustworthiness perceptions, indicating biases towards robots may be more expansive than previously thought. Additionally, there were marginal effects of partner differences on trust intentions. Interestingly, there were no differences between partners on trust behaviors. Results indicate human biases toward robots may be more complex than considered in the literature.},
  langid = {english},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Alarcon et al_2023_Differential biases in human-human versus human-robot interactions.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\MQU66VRC\\S0003687022001818.html}
}

@inproceedings{avdicMachineBodyLanguage2021,
  title = {Machine {{Body Language}}: {{Expressing}} a {{Smart Speaker}}'s {{Activity}} with {{Intelligible Physical Motion}}},
  booktitle = {Designing {{Interactive Systems Conference}} 2021},
  author = {Avdic, Mirzel and Marquardt, Nicolai and Rogers, Yvonne and Vermeulen, Jo},
  year = {2021},
  month = jun,
  pages = {1403--1418},
  publisher = {{ACM}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3461778.3462031},
  abstract = {Findings: 6 Themes 1 | Mirroring, mimicking motions Dynamic Smart Speaker with Expressive Physical Motion User study Study participant Wizard-of-Oz lab study: 12 participants interacted with QUBI in 4 scripted scenarios + Questionnaire/interview Examples of expressive physical motion Nodding Wiggling Pointing QUBI 2 | Body language with voice 3 | Anthropomorphism 4 | Audio trumps motion 5 | Reaffirmations 6 | Emotional reactions Study environment QUBI, Wizard-of-Oz controlled 12 participants in total for study Interpretation of motion Figure 1: Visual abstract summarizing research of QUBI-a smart speaker design with multiple degrees of freedom for expressive physical motion, and key findings of our user study about people's interaction with QUBI. ABSTRACT People's physical movement and body language implicitly convey what they think and feel, are doing or are about to do. In contrast, current smart speakers miss out on this richness of body language, primarily relying on voice commands only. We present QUBI, a dynamic smart speaker that leverages expressive physical motion-stretching, nodding, turning, shrugging, wiggling, pointing and leaning forwards/backwards-to convey cues about its underlying behaviour and activities. We conducted a qualitative Wizard of Oz lab study, in which 12 participants interacted with QUBI in four scripted scenarios. From our study, we distilled six themes: (1) mirroring and mimicking motions; (2) body language to supplement voice instructions; (3) anthropomorphism and personality; (4) audio can trump motion; (5) reaffirming uncertain interpretations to support mutual understanding; and (6) emotional reactions to QUBI's behaviour. From this, we discuss design implications for future smart speakers. CCS CONCEPTS \textbullet{} Human-centered computing \textrightarrow{} Empirical studies in HCI; Natural language interfaces.},
  isbn = {978-1-4503-8476-6},
  keywords = {Breakdowns,Intelligent Personal Assistants,Intelligibility,Smart Speakers,Voice User Interfaces},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Avdic et al_2021_Machine Body Language.pdf}
}

@article{bailenson2008detecting,
  title = {Detecting Digital Chameleons},
  author = {Bailenson, Jeremy N and Yee, Nick and Patel, Kayur and Beall, Andrew C},
  year = {2008},
  journal = {Computers in Human Behavior},
  volume = {24},
  number = {1},
  pages = {66--87},
  publisher = {{Elsevier}},
  doi = {10.1016/j.chb.2007.01.015}
}

@article{bainbridgeBenefitsInteractionsPhysically2011,
  title = {The Benefits of Interactions with Physically Present Robots over Video-Displayed Agents},
  author = {Bainbridge, Wilma A. and Hart, Justin W. and Kim, Elizabeth S. and Scassellati, Brian},
  year = {2011},
  journal = {International Journal of Social Robotics},
  volume = {3},
  number = {1},
  pages = {41--52},
  publisher = {{Kluwer Academic Publishers}},
  issn = {18754805},
  doi = {10.1007/S12369-010-0082-7},
  abstract = {This paper explores how a robot's physical presence affects human judgments of the robot as a social partner. For this experiment, participants collaborated on simple book-moving tasks with a humanoid robot that was either physically present or displayed via a live video feed. Multiple tasks individually examined the following aspects of social interaction: greetings, cooperation, trust, and personal space. Participants readily greeted and cooperated with the robot whether present physically or in live video display. However, participants were more likely both to fulfill an unusual request and to afford greater personal space to the robot when it was physically present, than when it was shown on live video. The same was true when the live video displayed robot's gestures were augmented with disambiguating 3-D information. Questionnaire data support these behavioral findings and also show that participants had an overall more positive interaction with the physically present robot. \textcopyright{} Springer Science \& Business Media BV 2010.},
  keywords = {Cooperation,Human-robot interaction,Personal space,Presence,Trust},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Bainbridge et al_2011_The benefits of interactions with physically present robots over.pdf}
}

@article{baker2018toward,
  title = {Toward an {{Understanding}} of {{Trust Repair}} in {{Human-Robot Interaction}}: {{Current Research}} and {{Future Directions}}},
  shorttitle = {Toward an {{Understanding}} of {{Trust Repair}} in {{Human-Robot Interaction}}},
  author = {Baker, Anthony L. and Phillips, Elizabeth K. and Ullman, Daniel and Keebler, Joseph R.},
  year = {2018},
  month = nov,
  journal = {ACM Transactions on Interactive Intelligent Systems},
  volume = {8},
  number = {4},
  pages = {30:1--30:30},
  issn = {2160-6455},
  doi = {10.1145/3181671},
  abstract = {Gone are the days of robots solely operating in isolation, without direct interaction with people. Rather, robots are increasingly being deployed in environments and roles that require complex social interaction with humans. The implementation of human-robot teams continues to increase as technology develops in tandem with the state of human-robot interaction (HRI) research. Trust, a major component of human interaction, is an important facet of HRI. However, the ideas of trust repair and trust violations are understudied in the HRI literature. Trust repair is the activity of rebuilding trust after one party breaks the trust of another. These trust breaks are referred to as trust violations. Just as with humans, trust violations with robots are inevitable; as a result, a clear understanding of the process of HRI trust repair must be developed in order to ensure that a human-robot team can continue to perform well after a trust violation. Previous research on human-automation trust and human-human trust can serve as starting places for exploring trust repair in HRI. Although existing models of human-automation and human-human trust are helpful, they do not account for some of the complexities of building and maintaining trust in unique relationships between humans and robots. The purpose of this article is to provide a foundation for exploring human-robot trust repair by drawing upon prior work in the human-robot, human-automation, and human-human trust literature, concluding with recommendations for advancing this body of work.},
  keywords = {automation,Human-robot interaction,human-robot trust,trust,trust repair},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Baker et al_2018_Toward an Understanding of Trust Repair in Human-Robot Interaction.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\FCJI2MW6\\Baker et al. - 2018 - Toward an Understanding of Trust Repair in Human-R.pdf}
}

@incollection{baron1994local,
  title = {Local and Global Dynamics of Social Relations.},
  booktitle = {Dynamical Systems in Social Psychology.},
  author = {Baron, Reuben M. and Amazeen, Polemnia G. and Beek, Peter J.},
  year = {1994},
  pages = {111--138},
  publisher = {{Academic Press}},
  address = {{San Diego,  CA,  US}},
  abstract = {develop the theme of local and global dynamics in a social context / begin by reviewing basic concepts and simple coupling phenomena / address more complex dyadic and group-type problems in social coordination (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  isbn = {0-12-709990-5 (Hardcover)},
  keywords = {*Couples,*Social Interaction,*Systems Theory,⛔ No DOI found,Group Dynamics}
}

@article{BERG1995122,
  title = {Trust, Reciprocity, and Social History},
  author = {Berg, Joyce and Dickhaut, John and McCabe, Kevin},
  year = {1995},
  journal = {Games and Economic Behavior},
  volume = {10},
  number = {1},
  pages = {122--142},
  issn = {0899-8256},
  doi = {10.1006/game.1995.1027},
  abstract = {We designed an experiment to study trust and reciprocity in an investment setting. This design controls for alternative explanations of behavior including repeat game reputation effects, contractual precommitments, and punishment threats. Observed decisions suggest that reciprocity exists as a basic element of human behavior and that this is accounted for in the trust extended to an anonymous counterpart. A second treatment, social history, identifies conditions which strengthen the relationship between trust and reciprocity.},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Berg et al_1995_Trust, Reciprocity, and Social History.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\X93Y25L7\\S0899825685710275.html}
}

@incollection{bernieri1991interpersonal,
  title = {Interpersonal Coordination: {{Behavior}} Matching and Interactional Synchrony.},
  booktitle = {Fundamentals of Nonverbal Behavior.},
  author = {Bernieri, Frank J. and Rosenthal, Robert},
  year = {1991},
  series = {Studies in Emotion \& Social Interaction.},
  pages = {401--432},
  publisher = {{Cambridge University Press}},
  address = {{New York,  NY,  US}},
  abstract = {review the work on interpersonal coordination and explore its possible function and importance in social interaction / describe four conceptualizations of the phenomenon that emphasize slightly different aspects of interpersonal coordination  the variety of approaches to understanding interpersonal coordination has led to the development of a number of different measurement techniques / discuss these methodologies used to study interpersonal coordination and some of the results found with them  a new method of synchrony measurement based on synchrony ratings will be presented along with some initial findings / discuss briefly the practical implications that behavioral coordination may have for our social and professional encounters (PsycInfo Database Record (c) 2023 APA, all rights reserved)},
  isbn = {0-521-36388-8 (Hardcover); 0-521-36700-X (Paperback)},
  keywords = {*Interpersonal Compatibility,*Measurement,⛔ No DOI found,Synchrony}
}

@inproceedings{bos2002effects,
  title = {Effects of Four Computer-Mediated Communications Channels on Trust Development},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Bos, Nathan and Olson, Judy and Gergle, Darren and Olson, Gary and Wright, Zach},
  year = {2002},
  month = apr,
  series = {{{CHI}} '02},
  pages = {135--140},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/503376.503401},
  abstract = {When virtual teams need to establish trust at a distance, it is advantageous for them to use rich media to communicate. We studied the emergence of trust in a social dilemma game in four different communication situations: face-to-face, video, audio, and text chat. All three of the richer conditions were significant improvements over text chat. Video and audio conferencing groups were nearly as good as face-to-face, but both did show some evidence of what we term delayed trust (slower progress toward full cooperation) and fragile trust (vulnerability to opportunistic behavior)},
  isbn = {978-1-58113-453-7},
  keywords = {communication,media,social dilemmas,trust},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Bos et al_2002_Effects of four computer-mediated communications channels on trust development.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\QZ2T6ZV7\\Bos et al. - 2002 - Effects of four computer-mediated communications c.pdf}
}

@inproceedings{brave1998tangible,
  title = {Tangible Interfaces for Remote Collaboration and Communication},
  booktitle = {Proceedings of the 1998 {{ACM}} Conference on {{Computer}} Supported Cooperative Work},
  author = {Brave, Scott and Ishii, Hiroshi and Dahley, Andrew},
  year = {1998},
  month = nov,
  series = {{{CSCW}} '98},
  pages = {169--178},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/289444.289491},
  isbn = {978-1-58113-009-6},
  keywords = {force-feedback,haptic interfaces,physical presence,tangble interfaces,telemanipulation},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Brave et al_1998_Tangible interfaces for remote collaboration and communication.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\549835D2\\Brave et al. - 1998 - Tangible interfaces for remote collaboration and c.pdf}
}

@article{Brown2015,
  title = {Employee Trust and Workplace Performance},
  author = {Brown, Sarah and Gray, Daniel and McHardy, Jolian and Taylor, Karl},
  year = {2015},
  month = aug,
  journal = {Journal of Economic Behavior \& Organization},
  volume = {116},
  pages = {361--378},
  issn = {0167-2681},
  doi = {10.1016/j.jebo.2015.05.001},
  abstract = {We explore the relationship between employee trust of managers and workplace performance. We present a theoretical framework which serves to establish a link between employee trust and firm performance as well as to identify possible mechanisms through which the relationship may operate. We then analyse matched workplace and employee data in order to ascertain whether the average level of employee trust within the workplace influences workplace performance. We exploit the 2004 and 2011 Workplace Employment Relations Surveys (WERS) to analyse the role of average employee trust in influencing workplace performance in both pre- and post-recessionary periods. Our empirical findings support a positive relationship between three measures of workplace performance (financial performance, labour productivity and product or service quality) and average employee trust at both points in time. Moreover, this relationship holds when we jointly model average employee trust and firm performance in an instrumental variable framework in order to take into account the potential endogeneity of employee trust. We then exploit employee level data from the WERS to ascertain how individual level trust of the employee (rather than the average within the workplace) is influenced by measures taken by employers to deal with the recent recession. Our findings suggest that restricting paid overtime and access to training potentially erode employee trust. In addition, we find that job or work reorganisation experienced at either the employee or organisation level is associated with lower employee trust.},
  langid = {english},
  keywords = {Employee trust,Financial performance,Labour productivity,Product quality},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Brown et al_2015_Employee trust and workplace performance2.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\Q85MRA4F\\Brown et al. - 2015 - Employee trust and workplace performance.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\AITGRUM5\\S0167268115001365.html}
}

@incollection{bryson2010robots,
  title = {Robots Should Be Slaves},
  booktitle = {Close {{Engagements}} with {{Artificial Companions}}},
  author = {Bryson, Joanna J. and Wilks, Yorick},
  year = {2010},
  month = mar,
  series = {Natural {{Language Processing}}},
  pages = {63--74},
  publisher = {{John Benjamins Publishing Company}},
  address = {{Amsterdam, Noord-holland, 1033, Netherlands}},
  doi = {10.1075/nlp.8.11bry},
  abstract = {Robots should not be described as persons, nor given legal nor moral responsibility for their actions. Robots are fully owned by us. We determine their goals and behavior, either directly or indirectly through specifying their intelligence or how their intelligence is acquired. In humanising them, we not only further dehumanise real people, but also encourage poor human decision making in the allocation of resources and responsibility. This is true at both the individual and the institutional level. This chapter describes both causes and consequences of these errors, including consequences already present in society. I make specific proposals for best incorporating robots into our society. The potential of robotics should be understood as the potential to extend our own abilities and to address our own goals.},
  isbn = {978-90-272-8840-0 978-90-272-4994-4},
  langid = {english},
  file = {C\:\\Users\\ra46sin\\Zotero\\storage\\GS34IBG7\\nlp.8.html}
}

@inproceedings{calvo2020effects,
  title = {The {{Effects}} of {{Robot}}'s {{Facial Expressions}} on {{Children}}'s {{First Impressions}} of {{Trustworthiness}}},
  booktitle = {2020 29th {{IEEE International Conference}} on {{Robot}} and {{Human Interactive Communication}} ({{RO-MAN}})},
  author = {{Calvo-Barajas}, Natalia and Perugia, Giulia and Castellano, Ginevra},
  year = {2020},
  month = aug,
  pages = {165--171},
  publisher = {{IEEE Comput. Soc}},
  address = {{New York City, United States}},
  issn = {1944-9437},
  doi = {10.1109/RO-MAN47096.2020.9223456},
  abstract = {Facial expressions of emotions influence the perception of robots in first encounters. People can judge trustworthiness, likability, and aggressiveness in a few milliseconds by simply observing other individuals' faces. While first impressions have been extensively studied in adult-robot interaction, they have been addressed in child-robot interaction only rarely. This knowledge is crucial, as the first impression children build of robots might influence their willingness to interact with them over extended periods of time, for example in applications where robots play the role of companions or tutors. The present study focuses on investigating the effects of facial expressions of emotions on children's perceptions of trust towards robots during first encounters. We constructed a set of facial expressions of happiness and anger varying in terms of intensity. We implemented these facial expressions onto a Furhat robot that was either male-like or female-like. 129 children were exposed to the robot's expressions for a few seconds. We asked them to evaluate the robot in terms of trustworthiness, likability, and competence and investigated how emotion type, emotion intensity, and gender-likeness affected the perception of the robot. Results showed that a few seconds are enough for children to make a trait inference based on the robot's emotion. We observed that emotion type, emotion intensity, and gender-likeness did not directly affect trust, but the perception of likability and competence of the robot served as facilitator to judge trustworthiness.},
  keywords = {Conferences,Faces,Robots},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Calvo-Barajas et al_2020_The Effects of Robot’s Facial Expressions on Children’s First Impressions of.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\FK7EX9V7\\9223456.html}
}

@article{chartrand1999chameleon,
  title = {The Chameleon Effect: {{The}} Perception\textendash Behavior Link and Social Interaction},
  shorttitle = {The Chameleon Effect},
  author = {Chartrand, Tanya L. and Bargh, John A.},
  year = {1999},
  journal = {Journal of Personality and Social Psychology},
  volume = {76},
  pages = {893--910},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1315},
  doi = {10.1037/0022-3514.76.6.893},
  abstract = {The chameleon effect refers to nonconscious mimicry of the postures, mannerisms, facial expressions, and other behaviors of one's interaction partners, such that one's behavior passively and unintentionally changes to match that of others in one's current social environment. The authors suggest that the mechanism involved is the perception\textendash behavior link, the recently documented finding (e.g., J. A. Bargh, M. Chen, \& L Burrows, 1996) that the mere perception of another's behavior automatically increases the likelihood of engaging in that behavior oneself. Experiment 1 showed that the motor behavior of participants unintentionally matched that of strangers with whom they worked on a task. Experiment 2 had confederates mimic the posture and movements of participants and showed that mimicry facilitates the smoothness of interactions and increases liking between interaction partners. Experiment 3 showed that dispositionally empathic individuals exhibit the chameleon effect to a greater extent than do other people. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Imitation (Learning),Social Behavior,Social Interaction,Social Perception},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Chartrand_Bargh_1999_The chameleon effect.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\CGPLJBKE\\doiLanding.html}
}

@incollection{chartrand2009human,
  title = {Human {{Mimicry}}},
  booktitle = {Advances in {{Experimental Social Psychology}}},
  author = {Chartrand, Tanya L. and {van Baaren}, Rick},
  year = {2009},
  month = jan,
  volume = {41},
  pages = {219--274},
  publisher = {{Academic Press}},
  address = {{Cambridge, Massachusetts, United States}},
  doi = {10.1016/S0065-2601(08)00405-X},
  abstract = {Human mimicry is ubiquitous, and often occurs without the awareness of the person mimicking or the person being mimicked. First, we briefly describe some of the major types of nonconscious mimicry\textemdash verbal, facial, emotional, and behavioral\textemdash and review the evidence for their automaticity. Next, we argue for the broad impact of mimicry and summarize the literature documenting its influence on the mimicry dyad and beyond. This review highlights the moderators of mimicry as well, including the social, motivational, and emotional conditions that foster or inhibit automatic mimicry. We interpret these findings in light of current theories of mimicry. First, we evaluate the evidence for and against mimicry as a communication tool. Second, we review neuropsychological research that sheds light on the question of how we mimic. What is the cognitive architecture that enables us to do what we perceive others do? We discuss a proposed system, the perception-behavior link, and the neurological evidence (i.e., the mirror system) supporting it. We will then review the debate on whether mimicry is innate and inevitable. We propose that the architecture enabling mimicry is innate, but that the behavioral mimicry response may actually be (partly) a product of learning or associations. Finally, we speculate on what the behavioral data on mimicry may imply for the evolution of mimicry.},
  langid = {english},
  file = {C\:\\Users\\ra46sin\\Zotero\\storage\\MHCYULAN\\S006526010800405X.html}
}

@article{Cheng2022,
  title = {Integration of Social Status and Trust through Interpersonal Brain Synchronization},
  author = {Cheng, Xiaojun and Zhu, Yujiao and Hu, Yinying and Zhou, Xiaolin and Pan, Yafeng and Hu, Yi},
  year = {2022},
  month = feb,
  journal = {NeuroImage},
  volume = {246},
  pages = {118777},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2021.118777},
  abstract = {Trust can be a dynamic social process, during which the social identity of the interacting agents (e.g., an investor and a trustee) can bias trust outcomes. Here, we investigated how social status modulates trust and the neural mechanisms underlying this process. An investor and a trustee performed a 10-round repeated trust game while their brain activity was being simultaneously recorded using functional near-infrared spectroscopy. The social status (either high or low) of both investors and trustees was manipulated via a math competition task. The behavioral results showed that in the initial round, individuals invested more in low-status partners. However, the investment ratio increased faster as the number of rounds increased during trust interaction when individuals were paired with a high-status partner. This increasing trend was particularly prominent in the low (investor)-high (trustee) status group. Moreover, the low-high group showed increased investor-trustee brain synchronization in the right temporoparietal junction as the number of rounds increased, while brain activation in the right dorsolateral prefrontal cortex of the investor decreased as the number of rounds increased. Both interpersonal brain synchronization and brain activation predicted investment performance at the early stage; furthermore, two-brain data provided earlier predictions than did single-brain data. These effects were detectable in the investment phase in the low-high group only; no comparable effects were observed in the repayment phase or other groups. Overall, this study demonstrated a multi-brain mechanism for the integration of social status and trust.},
  langid = {english},
  keywords = {fNIRS,Hyperscanning,Interpersonal brain synchronization,Social status,Trust},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Cheng et al_2022_Integration of social status and trust through interpersonal brain2.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\SIKEGTR3\\S1053811921010491.html}
}

@article{chetty2021trust,
  title = {The {{Trust Game Does Not}} ({{Only}}) {{Measure Trust}}: {{The Risk-Trust Confound Revisited}}},
  shorttitle = {The {{Trust Game Does Not}} ({{Only}}) {{Measure Trust}}},
  author = {Chetty, Rinelle and Hofmeyr, Andre and Kincaid, Harold and Monroe, Brian},
  year = {2021},
  month = feb,
  journal = {Journal of Behavioral and Experimental Economics},
  volume = {90},
  pages = {101520},
  issn = {2214-8043},
  doi = {10.1016/j.socec.2020.101520},
  abstract = {The trust game has become the behavioral measure of choice in social science investigations of trust. This measure is often used uncritically to compare levels of trust across people and cultures even though those levels may be affected by people's attitudes to risk. We evaluate an incentive-compatible experiment designed to investigate the potential for a risk-trust confound using a sample of 202 students at the University of Cape Town in 2016. We depart from the earlier risk-trust literature by using a risk preference task that incorporates a wide range of prizes and probabilities. This allows us to investigate whether earlier ambiguous results concerning risk-trust interactions simply reflect weak measurement instruments, and facilitates the estimation of structural econometric risk preference models. We find that amounts sent in the trust game are indeed associated with attitudes to risk, that the magnitude of this relationship is economically significant, and that it is robust across statistical models. In addition, we find that most previous studies of the risk-trust confound use preference elicitation mechanisms that are underpowered for identifying risk-trust relationships. Our results caution against the widespread use of the trust game to measure and compare levels of trust without careful adjustments for risk attitudes.},
  langid = {english},
  keywords = {Risk Aversion,Risk-Trust Confound,Trust Game},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Chetty et al_2021_The Trust Game Does Not (Only) Measure Trust.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\LUE379UY\\S2214804319302290.html}
}

@inproceedings{choWillDeletingHistory2020,
  title = {Will {{Deleting History Make Alexa More Trustworthy}}?},
  booktitle = {Proceedings of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Cho, Eugene and Sundar, S. Shyam and Abdullah, Saeed and Motalebi, Nasim},
  year = {2020},
  month = apr,
  pages = {1--13},
  publisher = {{ACM}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3313831.3376551},
  abstract = {"Always-on" smart speakers have raised privacy and security concerns, to address which vendors have introduced customizable privacy settings. But, does the act of customizing one's privacy preferences have any effects on user experience and trust? To address this question, we developed an app for Amazon Alexa and conducted a user study (N = 90). Our data show that the affordance to customize privacy settings enhances trust and usability for regular users, while it has adverse effects on power users. In addition, only enabling privacy-setting customization without allowing content customization negatively affects trust among users with higher privacy concerns. When they can customize both content and privacy settings, user trust is highest. That is, while privacy customization may cause reactance among power users, allowing privacy-concerned individuals to simultaneously customize content can help to alleviate the resultant negative effect on trust. These findings have implications for designing more privacy-sensitive and trustworthy smart speakers.},
  isbn = {978-1-4503-6708-0},
  keywords = {Author Keywords Customization,power usage,privacy concern,security,security; smart speaker(s),smart speaker(s),voice assistant(s) CSS Concepts},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Cho et al_2020_Will Deleting History Make Alexa More Trustworthy.pdf}
}

@article{christoforakos2021can,
  title = {Can Robots Earn Our Trust the Same Way Humans Do? {{A}} Systematic Exploration of Competence, Warmth, and Anthropomorphism as Determinants of Trust Development in {{HRI}}},
  author = {Christoforakos, Lara and Gallucci, Alessio and {Surmava-Gro{\ss}e}, Tinatini and Ullrich, Daniel and Diefenbach, Sarah},
  year = {2021},
  journal = {Frontiers in Robotics and AI},
  volume = {8},
  issn = {2296-9144},
  doi = {10.3389/frobt.2021.640444},
  abstract = {Robots increasingly act as our social counterparts in domains such as healthcare and retail. For these human-robot interactions (HRI) to be effective, a question arises on whether we trust robots the same way we trust humans. We investigated whether the determinants competence and warmth, known to influence interpersonal trust development, influence trust development in HRI, and what role anthropomorphism plays in this interrelation. In two online studies with 2 \texttimes{} 2 between-subjects design, we investigated the role of robot competence (Study 1) and robot warmth (Study 2) in trust development in HRI. Each study explored the role of robot anthropomorphism in the respective interrelation. Videos showing an HRI were used for manipulations of robot competence (through varying gameplay competence) and robot anthropomorphism (through verbal and non-verbal design cues and the robot's presentation within the study introduction) in Study 1 (n = 155) as well as robot warmth (through varying compatibility of intentions with the human player) and robot anthropomorphism (same as Study 1) in Study 2 (n = 157). Results show a positive effect of robot competence (Study 1) and robot warmth (Study 2) on trust development in robots regarding anticipated trust and attributed trustworthiness. Subjective perceptions of competence (Study 1) and warmth (Study 2) mediated the interrelations in question. Considering applied manipulations, robot anthropomorphism neither moderated interrelations of robot competence and trust (Study 1) nor robot warmth and trust (Study 2). Considering subjective perceptions, perceived anthropomorphism moderated the effect of perceived competence (Study 1) and perceived warmth (Study 2) on trust on an attributional level. Overall results support the importance of robot competence and warmth for trust development in HRI and imply transferability regarding determinants of trust development in interpersonal interaction to HRI. Results indicate a possible role of perceived anthropomorphism in these interrelations and support a combined consideration of these variables in future studies. Insights deepen the understanding of key variables and their interaction in trust dynamics in HRI and suggest possibly relevant design factors to enable appropriate trust levels and a resulting desirable HRI. Methodological and conceptual limitations underline benefits of a rather robot-specific approach for future research.}
}

@book{Cohen1988,
  title = {Statistical {{Power Analysis}} for the {{Behavioral Sciences}}},
  author = {Cohen, Jacob},
  year = {1988},
  month = jul,
  edition = {Second},
  publisher = {{Routledge}},
  address = {{New York}},
  doi = {10.4324/9780203771587},
  abstract = {Statistical Power Analysis is a nontechnical guide to power analysis in research planning that provides users of applied statistics with the tools they need for more effective analysis. The Second Edition includes:  * a chapter covering power analysis in set correlation and multivariate methods; * a chapter considering effect size, psychometric reliability, and the efficacy of "qualifying" dependent variables and; * expanded power and sample size tables for multiple regression/correlation.},
  isbn = {978-0-203-77158-7}
}

@inproceedings{correia2016just,
  title = {Just Follow the Suit! {{Trust}} in Human-Robot Interactions during Card Game Playing},
  booktitle = {2016 25th {{IEEE International Symposium}} on {{Robot}} and {{Human Interactive Communication}} ({{RO-MAN}})},
  author = {Correia, Filipa and {Alves-Oliveira}, Patr{\'i}cia and Maia, Nuno and Ribeiro, Tiago and Petisca, Sofia and Melo, Francisco S. and Paiva, Ana},
  year = {2016},
  month = aug,
  pages = {507--512},
  publisher = {{IEEE Comput. Soc}},
  address = {{New York,  NY,  US}},
  issn = {1944-9437},
  doi = {10.1109/ROMAN.2016.7745165},
  abstract = {Robots are currently being developed to enter our lives and interact with us in different tasks. For humans to be able to have a positive experience of interaction with such robots, they need to trust them to some degree. In this paper, we present the development and evaluation of a social robot that was created to play a card game with humans, playing the role of a partner and opponent. This type of activity is especially important, since our target group is elderly people - a population that often suffers from social isolation. Moreover, the card game scenario can lead to the development of interesting trust dynamics during the interaction, in which the human that partners with the robot needs to trust it in order to succeed and win the game. The design of the robot's behavior and game dynamics was inspired in previous user-centered design studies in which elderly people played the same game. Our evaluation results show that the levels of trust differ according to the previous knowledge that players have of their partners. Thus, humans seem to significantly increase their trust level towards a robot they already know, whilst maintaining the same level of trust in a human that they also previously knew. Henceforth, this paper shows that trust is a multifaceted construct that develops differently for humans and robots.},
  keywords = {Artificial intelligence,Games,Human-robot interaction,Robots,Senior citizens,Statistics},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Correia et al_2016_Just follow the suit.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\UG56P6VZ\\Correia et al. - 2016 - Just follow the suit! Trust in human-robot interac.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\7MQBR9ZC\\7745165.html}
}

@article{CoxGeorge2018,
  title = {I, {{Sex Robot}}: The Health Implications of the Sex Robot Industry},
  shorttitle = {I, {{Sex Robot}}},
  author = {{Cox-George}, Chantal and Bewley, Susan},
  year = {2018},
  month = jul,
  journal = {BMJ Sexual \& Reproductive Health},
  volume = {44},
  number = {3},
  pages = {161--164},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {2515-1991, 2515-2009},
  doi = {10.1136/bmjsrh-2017-200012},
  abstract = {The sex technology industry is already estimated to be worth US\$30~billion.1~While sex toys are well-established, sex robots ('sexbots'), anthropomorphic devices created for sexual gratification, are no longer science fiction. Four companies sell adult sexbots priced between US\$5000 and US\$15\,000. They must be distinguished from 'paedobots' \textendash{} childlike robotic models at present only produced by one company.2 The market appears to be men, and so far only `female' adult sexbots have been created, although one company reports aiming to sell `male' devices later in 2018.3 Sex robots are realistic mannequins with variable ages, appearances and textures, and customisable oral, vaginal and anal openings. The medical profession needs to be prepared for inevitable questions about the impact of sex robots on health. Apart from free-market profits, the majority of arguments in their favour use `harm limitation' somewhat defensively to convince others that this is one way to protect the vulnerable. Opponents reject the hypothesis that they reduce sexual crimes, and instead raise concerns about the potential for harm by further promoting the pervasive idea that living women too are sex objects that should be constantly available - `misogynistic objectification' - and intensifying existing physical and sexual violence against women and children. What characterises all discussions of this issue is the paucity of an evidence base. This might falsely reassure clinicians not to concern themselves with changing their current clinical practice. However, an absence of evidence does not excuse the medical profession from discussing and debating the issues, as there will inevitably be consequences for physical, mental and social well-being. We aim to provide a succinct summary of the arguments for and against the sex robot industry and to assess the potential health implications that may affect both patients and clinicians. To find information about the health consequences of \ldots},
  chapter = {Editorial},
  copyright = {\textcopyright{} Article author(s) (or their employer(s) unless otherwise stated in the text of the article) 2018. All rights reserved. No commercial use is permitted unless otherwise expressly granted.},
  langid = {english},
  pmid = {30012720},
  keywords = {child sex abuse,ethics,sex robot,sexual health},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Cox-George_Bewley_2018_I, Sex Robot3.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\2ZIV28F7\\Cox-George and Bewley - 2018 - I, Sex Robot the health implications of the sex r.pdf}
}

@inproceedings{crick2006synchronization,
  title = {Synchronization in {{Social Tasks}}: {{Robotic Drumming}}},
  shorttitle = {Synchronization in {{Social Tasks}}},
  booktitle = {{{ROMAN}} 2006 - {{The}} 15th {{IEEE International Symposium}} on {{Robot}} and {{Human Interactive Communication}}},
  author = {Crick, Christopher and Munz, Matthew and Scassellati, Brian},
  year = {2006},
  month = sep,
  pages = {97--102},
  publisher = {{IEEE Comput. Soc}},
  address = {{New York,  NY,  US}},
  issn = {1944-9437},
  doi = {10.1109/ROMAN.2006.314401},
  abstract = {Music performance is an important, well-structured setting for evaluating a robot's ability to detect, understand and respond appropriately to complex human activity. Social tasks such as cooperative performance require participants to detect, interpret and attune to the actions of their partners quickly and accurately. The synthesis of multiple sensory perceptions may be a fruitful approach to this problem. In order to evaluate this approach, we programmed a humanoid robot, Nico, to play a drum in concert with human drummers and at the direction of a human conductor. Our results show that sensory integration can enable precise synchronization in social tasks even when perceptual data is imperfect, misleading and subject to extensive processing delay. By integrating several streams of information - visual, auditory, and proprioceptive - Nico can attune to a tempo that is set by a human conductor, in concert with human performers. Nico continuously evaluates its perceptions of its own actions and those of the humans around it, dealing with unforeseen changes in tempo and affect in real time},
  keywords = {Cognition,Cognitive robotics,Conductors,Delay,Force control,Human robot interaction,Humanoid robots,Oscillators,Robot kinematics,Robot sensing systems},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Crick et al_2006_Synchronization in Social Tasks.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\YPDAZDSN\\4107792.html}
}

@inproceedings{daudi2016effects,
  title = {Effects of {{Decision Synchronization}} on {{Trust}} in {{Collaborative Networks}}},
  booktitle = {Collaboration in a {{Hyperconnected World}}},
  author = {Daudi, Morice and Hauge, Jannicke Baalsrud and Thoben, Klaus-Dieter},
  editor = {Afsarmanesh, Hamideh and {Camarinha-Matos}, Luis M. and Lucas Soares, Ant{\'o}nio},
  year = {2016},
  series = {{{IFIP Advances}} in {{Information}} and {{Communication Technology}}},
  pages = {215--227},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-45390-3_19},
  abstract = {In collaborative networks, individual and organizational entities encounter many disagreements over many decisions rights. These disagreements procreate conflicting preferences, which in turn, affect trustworthy amongst partners. To that end, it becomes necessary that partners assume a degree of fairness on decision rights by calibrating positions which they initially consider a final. This calibration involves synchronizing partners' conflicting preferences to a compromise. The objective of this paper, therefore, is to analyze and evaluate the effect of both, compromised and uncompromised preferences on trust. To achieve this, a corresponding behavioral trust model is proposed and evaluated empirically using a logistics collaboration scenario. This evaluation applies a multi-agent systems simulation method. The simulation involves 360 observations with three preferences set as predictor variables. Results show that irrespective of a degree to which conflicting preferences are synchronized, a magnitude of the generated effect on trust, depends as well on other factors like transport cost and extent to which vehicles are loaded. Additionally, if other factors are kept constant, compromised preferences affects trust more positively than uncompromised ones.},
  isbn = {978-3-319-45390-3},
  langid = {english},
  keywords = {Collaborative networks,Conflicting preferences,Decision synchronization,Logistics collaboration,Trust},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Daudi et al_2016_Effects of Decision Synchronization on Trust in Collaborative Networks.pdf}
}

@article{de2021defining,
  title = {On Defining ``{{Reliance}}'' and ``{{Trust}}'': {{Purposes}}, Conditions of Adequacy, and New Definitions},
  author = {{de Fine Licht}, Karl and Br{\"u}lde, Bengt},
  year = {2021},
  journal = {Philosophia},
  volume = {49},
  number = {5},
  pages = {1981--2001},
  publisher = {{Springer}},
  doi = {10.1007/s11406-021-00339-1}
}

@article{deVisser2017,
  title = {A Little Anthropomorphism Goes a Long Way: {{Effects}} of Oxytocin on Trust, Compliance, and Team Performance with Automated Agents},
  author = {De Visser, Ewart J and Monfort, Samuel S and Goodyear, Kimberly and Lu, Li and O'Hara, Martin and Lee, Mary R and Parasuraman, Raja and Krueger, Frank},
  year = {2017},
  journal = {Human factors},
  volume = {59},
  number = {1},
  pages = {116--133},
  publisher = {{Sage Publications Sage CA: Los Angeles, CA}},
  doi = {10.1177/0018720816687205}
}

@incollection{dijksterhuis2005we,
  title = {Why We Are Social Animals},
  booktitle = {Perspectives on Imitation: {{From}} Neuroscience to Social Science - Volume 2: {{Imitation}}, Human Development, and Culture},
  author = {Dijksterhuis, Ap and Hurley, Susan and Chater, Nick},
  year = {2005},
  month = feb,
  series = {{{CogNet}}},
  volume = {2},
  eprint = {https://direct.mit.edu/book/chapter-pdf/173158/9780262275958\textbackslash\_caj.pdf},
  publisher = {{The MIT Press}},
  doi = {10.7551/mitpress/5331.003.0012},
  isbn = {978-0-262-27595-8}
}

@article{Ding2013,
  title = {The Influence of Trust on Consumer Behavior: {{An}} Application to Recurring Food Risks in {{Canada}}},
  author = {Ding, Yulian and Veeman, Michele M. and Adamowicz, Wiktor L.},
  year = {2013},
  month = aug,
  journal = {Journal of Economic Behavior and Organization},
  volume = {92},
  pages = {214--223},
  publisher = {{Elsevier BV}},
  doi = {10.1016/j.jebo.2013.06.009},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Ding et al_2013_The influence of trust on consumer behavior.pdf}
}

@article{doi:10.1080/21515581.2012.708496,
  title = {A Social Interactions Perspective on Trust and Its Determinants},
  author = {{Thomas B. Singh}},
  year = {2012},
  journal = {Journal of Trust Research},
  volume = {2},
  number = {2},
  eprint = {https://doi.org/10.1080/21515581.2012.708496},
  pages = {107--135},
  publisher = {{Routledge}},
  doi = {10.1080/21515581.2012.708496},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Thomas B. Singh_2012_A social interactions perspective on trust and its determinants.pdf}
}

@article{dybowski2022interpersonal,
  title = {Interpersonal {{Synchronization Protects Against}} the {{Antisocial Outcomes}} of {{Frustration}}},
  author = {Dybowski, Karol and Raczka, Barbara and Postarnak, Svetlana and Castro, S{\~a}o Lu{\'i}s and Silva, Susana},
  year = {2022},
  month = jan,
  journal = {Psychological Reports},
  publisher = {{SAGE Publications Inc}},
  issn = {0033-2941},
  doi = {10.1177/00332941211054771},
  abstract = {Prosociality improves with interpersonal synchronization?the temporal coordination of movement across individuals. We tested whether the benefits of interpersonal synchronization extend to temporary circumstances of induced frustration, where negative changes in prosociality are expected as a result. Participants performed two joint tasks?synchronization versus non-synchronization. Each task was performed twice, with high versus low induced frustration. After each joint task, prosociality was measured both with explicit tests, in which participants were aware of the test goal, and implicit ones, where they were less aware. Frustration levels per task were also reported. Results showed that increase in frustration led to decrease in implicit prosociality after the non-synchronization task, but not after synchronization, suggesting that interpersonal synchronization attenuates the antisocial outcomes of frustration. In addition, our study highlights the advantages of implicit measures of prosociality, among which the test we created (Interpersonal Trust Test) may stand as a useful resource in future experimental research.},
  langid = {english},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Dybowski et al_2022_Interpersonal Synchronization Protects Against the Antisocial Outcomes of.pdf}
}

@article{foehrAlexaCanTrust2020,
  title = {Alexa, {{Can I Trust You}}? {{Exploring Consumer Paths}} to {{Trust}} in {{Smart Voice-Interaction Technologies}}},
  author = {Foehr, Jonas and Germelmann, Claas Christian},
  year = {2020},
  month = feb,
  journal = {https://doi.org/10.1086/707731},
  volume = {5},
  number = {2},
  pages = {181--205},
  publisher = {{The University of Chicago PressChicago, IL}},
  issn = {23781823},
  doi = {10.1086/707731},
  abstract = {AbstractTrust is considered a prerequisite for consumer interaction with smart voice-interaction technologies such as smart speakers, although how exactly this develops remains unclear. Adopting th...}
}

@article{fusaroli2014dialog,
  title = {Dialog as Interpersonal Synergy},
  author = {Fusaroli, Riccardo and {R{\k{a}}czaszek-Leonardi}, Joanna and Tyl{\'e}n, Kristian},
  year = {2014},
  journal = {New Ideas in Psychology},
  volume = {32},
  pages = {147--157},
  publisher = {{Elsevier}},
  doi = {10.1016/j.newideapsych.2013.03.005}
}

@article{girouard-hallamChildrenTrustLearning2022,
  title = {Children's Trust in and Learning from Voice Assistants.},
  author = {{Girouard-Hallam}, Lauren N. and Danovitch, Judith H.},
  year = {2022},
  month = apr,
  journal = {Developmental Psychology},
  volume = {58},
  number = {4},
  pages = {646--661},
  publisher = {{American Psychological Association (APA)}},
  issn = {0012-1649},
  doi = {10.1037/DEV0001318},
  abstract = {As children increasingly interact with digital voice assistants, it is important to know whether they treat these devices as reliable information sources. Two studies investigated children's trust in and recall of statements made by a novel voice assistant and a human informant. In Study 1, children ages 4-5 (Mage = 5.05; 20 boys, 20 girls) and 7-8 (Mage = 7.98; 18 boys, 22 girls) from predominately White, upper middle-class families heard each informant respond to questions from multiple categories. With increasing age, children showed greater trust in the voice assistant for factual information and greater trust in the human for personal information about the experimenter identified as her friend. Endorsement of each informant's statements also predicted later recall. In Study 2, children ages 4-5 (Mage = 5.00; 20 boys, 20 girls) and 7-8 (Mage = 8.03; 19 boys, 21 girls) from predominately White, upper middle-class families chose whether to seek out information from a voice assistant or human informant. With increasing age, children showed an increasing preference to seek factual information from the voice assistant and an increasing preference to seek personal information from the human. Additionally, children's preferences were not related to attributions of epistemic capacities to each informant nor the presence of a voice assistant in children's homes. These results suggest that children's trust in voice assistants varies with age and depends on the type of information involved. (PsycInfo Database Record (c) 2022 APA, all rights reserved).},
  pmid = {35343713}
}

@inproceedings{gompei2018factors,
  title = {Factors and {{Development}} of {{Cognitive}} and {{Affective Trust}} on {{Social Robots}}},
  booktitle = {Social {{Robotics}}},
  author = {Gompei, Takayuki and Umemuro, Hiroyuki},
  editor = {Ge, Shuzhi Sam and Cabibihan, John-John and Salichs, Miguel A. and Broadbent, Elizabeth and He, Hongsheng and Wagner, Alan R. and {Castro-Gonz{\'a}lez}, {\'A}lvaro},
  year = {2018},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {45--54},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-05204-1_5},
  abstract = {The purpose of this study is to investigate the factors that contribute to cognitive and affective trust of social robots. Also investigated were the changes within two different types of trust over time and variables that influence trust. Elements of trust extracted from literature were used to evaluate people's trust of social robot in an experiment. As a result of a factor analysis, ten factors that construct trust were extracted. These factors were further analyzed in relations with both cognitive and affective trust. Factors such as Security, Teammate, and Performance were found to relate with cognitive trust, while factors such as Teammate, Performance, Autonomy, and Friendliness appeared to relate with affective trust. Furthermore, changes in cognitive and affective trust over the time phases of the interaction were investigated. Affective trust appeared to develop in the earlier phase, while cognitive trust appeared to develop over the whole period of the interaction. Conversation topics had influence on affective trust, while robot's mistakes had influence on the cognitive trust. On the other hand, prior experiences with social robots did now show any significant relations with neither cognitive nor affective trust. Finally, Familiarity attitude appeared to relate with both cognitive and affective trust, while other sub-dimensions of robot attitudes such as Interest, Negative attitude, and Utility appeared to relate with affective trust.},
  isbn = {978-3-030-05204-1},
  langid = {english},
  keywords = {Affective trust,Attitude,Cognitive trust,Conversation},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Gompei_Umemuro_2018_Factors and Development of Cognitive and Affective Trust on Social Robots.pdf}
}

@inproceedings{guptaMeasuringHumanTrust2020,
  title = {Measuring {{Human Trust}} in a {{Virtual Assistant}} Using {{Physiological Sensing}} in {{Virtual Reality}}},
  author = {Gupta, Kunal and Hajika, Ryo and Pai, Yun Suen and Duenser, Andreas and Lochner, Martin and Billinghurst, Mark},
  year = {2020},
  month = jun,
  pages = {756--765},
  publisher = {{Institute of Electrical and Electronics Engineers (IEEE)}},
  doi = {10.1109/vr46266.2020.00099},
  abstract = {With the advancement of Artificial Intelligence technology to make smart devices, understanding how humans develop trust in virtual agents is emerging as a critical research field. Through our research, we report on a novel methodology to investigate user's trust in auditory assistance in a Virtual Reality (VR) based search task, under both high and low cognitive load and under varying levels of agent accuracy. We collected physiological sensor data such as electroencephalography (EEG), galvanic skin response (GSR), and heart-rate variability (HRV), subjective data through questionnaire such as System Trust Scale (STS), Subjective Mental Effort Questionnaire (SMEQ) and NASA-TLX. We also collected a behavioral measure of trust (congruency of users' head motion in response to valid/ invalid verbal advice from the agent). Our results indicate that our custom VR environment enables researchers to measure and understand human trust in virtual agents using the matrices, and both cognitive load and agent accuracy play an important role in trust formation. We discuss the implications of the research and directions for future work.},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Gupta et al_2020_Measuring Human Trust in a Virtual Assistant using Physiological Sensing in.pdf}
}

@article{haleTestingRelationshipMimicry2016,
  title = {Testing the Relationship between Mimicry, Trust and Rapport in Virtual Reality Conversations},
  author = {Hale, Joanna and Hamilton, Antonia F. De C.},
  year = {2016},
  month = dec,
  journal = {Scientific Reports},
  volume = {6},
  number = {1},
  pages = {35295},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/srep35295},
  abstract = {People mimic each other's actions and postures during everyday interactions. It is widely believed this mimicry acts as a social glue, leading to increased rapport. We present two studies using virtual reality to rigorously test this hypothesis. In Study 1, 50 participants interacted with two avatars who either mimicked their head and torso movements at a 1 or 3 second time delay or did not mimic, and rated feelings of rapport and trust toward the avatars. Rapport was higher towards mimicking avatars, with no effect of timing. In Study 2, we aimed to replicate this effect in a pre-registered design and test whether it is modulated by cultural ingroup-outgroup boundaries. Forty participants from European or East Asian backgrounds interacted with four avatars, two of European appearance and two of East Asian appearance. Two avatars mimicked while the other two did not. We found no effects of mimicry on rapport or trust ratings or implicit trust behaviour in a novel maze task, and no effects of group status or interactions. These null results were calculated in line with our pre-registration. We conclude that being mimicked does not always increase rapport or trust, and make suggestions for future directions.},
  pmid = {27739460},
  keywords = {Human behaviour,Social behaviour},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Hale_Hamilton_2016_Testing the relationship between mimicry, trust and rapport in virtual reality.pdf}
}

@article{Hancock2011,
  title = {A Meta-Analysis of Factors Affecting Trust in Human-Robot Interaction},
  author = {Hancock, Peter A. and Billings, Deborah R. and Schaefer, Kristin E. and Chen, Jessie Y.C. and De Visser, Ewart J. and Parasuraman, Raja},
  year = {2011},
  month = oct,
  journal = {Human Factors},
  volume = {53},
  number = {5},
  pages = {517--527},
  publisher = {{SAGE PublicationsSage CA: Los Angeles, CA}},
  issn = {00187208},
  doi = {10.1177/0018720811417254},
  abstract = {Objective: We evaluate and quantify the effects of human, robot, and environmental factors on perceived trust in human-robot interaction (HRI).Background: To date, reviews of trust in HRI have been qualitative or descriptive. Our quantitative review provides a fundamental empirical foundation to advance both theory and practice.Method: Meta-analytic methods were applied to the available literature on trust and HRI. A total of 29 empirical studies were collected, of which 10 met the selection criteria for correlational analysis and 11 for experimental analysis. These studies provided 69 correlational and 47 experimental effect sizes.Results: The overall correlational effect size for trust was r- = +0.26, with an experimental effect size of d- = +0.71. The effects of human, robot, and environmental characteristics were examined with an especial evaluation of the robot dimensions of performance and attribute-based factors. The robot performance and attributes were the largest contributors to the development of trust in HRI. Environmental factors played only a moderate role.Conclusion: Factors related to the robot itself, specifically, its performance, had the greatest current association with trust, and environmental factors were moderately associated. There was little evidence for effects of human-related factors.Application: The findings provide quantitative estimates of human, robot, and environmental factors influencing HRI trust. Specifically, the current summary provides effect size estimates that are useful in establishing design and training guidelines with reference to robot-related factors of HRI trust. Furthermore, results indicate that improper trust calibration may be mitigated by the manipulation of robot design. However, many future research needs are identified. \textcopyright{} 2011, Human Factors and Ergonomics Society.},
  pmid = {22046724},
  keywords = {human-robot team,robotics,trust,trust development},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Hancock et al_2011_A meta-analysis of factors affecting trust in human-robot interaction.pdf}
}

@article{hancock2021evolving,
  title = {Evolving Trust in Robots: Specification through Sequential and Comparative Meta-Analyses},
  author = {Hancock, Peter A and Kessler, Theresa T and Kaplan, Alexandra D and Brill, John C and Szalma, James L},
  year = {2021},
  journal = {Human factors},
  volume = {63},
  number = {7},
  pages = {1196--1229},
  publisher = {{Sage Publications Sage CA: Los Angeles, CA}},
  doi = {10.1177/0018720820922080}
}

@inproceedings{hashimoto2009effects,
  title = {Effects of Emotional Synchronization in Human-Robot {{KANSEI}} Communications},
  booktitle = {{{RO-MAN}} 2009 - {{The}} 18th {{IEEE International Symposium}} on {{Robot}} and {{Human Interactive Communication}}},
  author = {Hashimoto, Minoru and Yamano, Misaki and Usui, Tatsuya},
  year = {2009},
  month = sep,
  pages = {52--57},
  publisher = {{IEEE Comput. Soc}},
  address = {{Toyama, Japan}},
  issn = {1944-9437},
  doi = {10.1109/ROMAN.2009.5326232},
  abstract = {Human-robot communication is an important subject for housekeeping, elderly care and entertainment robots. To make a natural communication entrainment between human and robot, emotion plays a vital role. From this view point we have developed a KANSEI communication system based on emotional synchronization. The robotic emotion was entrained to human emotion by using a vector field of dynamics, and then the robot made a facial expression to express the robot emotion. In this paper we investigate the effect of the emotional synchronization in human-robot KANSEI communications. We conducted experiments to evaluate the effects of the proposed system based on emotional synchronization. In the experiments of human-robot interaction using the emotional synchronization, we found that human feeling became comfortable when the robot made the synchronized facial expression to human emotion. Then it was confirmed that emotional synchronization in human-robot interaction could be effective to keep a comfortable state.},
  keywords = {Aging,Artificial intelligence,Atmosphere,Displays,Hospitals,Human robot interaction,Intelligent robots,Robot sensing systems,Senior citizens,Symbiosis},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Hashimoto et al_2009_Effects of emotional synchronization in human-robot KANSEI communications.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\H3W6VKAV\\5326232.html}
}

@inproceedings{hasnain2013intuitive,
  title = {Intuitive Human Robot Interaction Based on Unintentional Synchrony: {{A}} Psycho-Experimental Study},
  booktitle = {2013 {{IEEE}} Third Joint International Conference on Development and Learning and Epigenetic Robotics ({{ICDL}})},
  author = {Hasnain, Syed Khursheed and Mostafaoui, Ghiles and Salesse, Robin and Marin, Ludovic and Gaussier, Philippe},
  year = {2013},
  pages = {1--7},
  doi = {10.1109/DevLrn.2013.6652569},
  organization = {{IEEE}}
}

@incollection{hida1980brownian,
  title = {Brownian {{Motion}}},
  booktitle = {Brownian {{Motion}}},
  author = {Hida, T.},
  editor = {Hida, T.},
  year = {1980},
  series = {Applications of {{Mathematics}}},
  pages = {44--113},
  publisher = {{Springer US}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4612-6030-1_2},
  abstract = {We begin this chapter with the definition of Brownian motion and a proof that its distribution is supported by the space of continuous functions (\textsection 2.1), and then go on to deal with important aspects of Brownian motion such as its sample path (\textsection 2.2) and Markov properties (\textsection 2.4). It is through these discussions that we can appreciate the place of Brownian motion within the class of all stochastic processes and, in particular, Gaussian processes. Two methods of constructing Brownian motion will be presented (\textsection 2.3), each of which is significant in its own right, and which also exhibits the ideas underlying constructions relevant to later chapters. Markov properties will only be touched upon briefly (\textsection\textsection 2.4\textendash 2.6), but, hopefully, enough to enable a close connection with analysis to be seen.},
  isbn = {978-1-4612-6030-1},
  langid = {english},
  keywords = {Borel Subset,Brownian Motion,Markov Process,Markov Property,Sample Path}
}

@article{hoffman2011interactive,
  title = {Interactive Improvisation with a Robotic Marimba Player},
  author = {Hoffman, Guy and Weinberg, Gil},
  year = {2011},
  journal = {Autonomous Robots},
  volume = {31},
  number = {2},
  pages = {133--153},
  publisher = {{Springer}},
  doi = {10.1007/s10514-011-9237-0}
}

@article{hofree2014bridging,
  title = {Bridging the Mechanical and the Human Mind: Spontaneous Mimicry of a Physically Present Android},
  author = {Hofree, Galit and Ruvolo, Paul and Bartlett, Marian Stewart and Winkielman, Piotr},
  year = {2014},
  journal = {PloS one},
  volume = {9},
  number = {7},
  pages = {e99934},
  publisher = {{Public Library of Science San Francisco, USA}},
  doi = {10.1371/journal.pone.0099934}
}

@article{hove2009s,
  title = {It's All in the Timing: {{Interpersonal}} Synchrony Increases Affiliation},
  author = {Hove, Michael J and Risen, Jane L},
  year = {2009},
  journal = {Social cognition},
  volume = {27},
  number = {6},
  pages = {949--960},
  publisher = {{Guilford}},
  doi = {10.1521/soco.2009.27.6.949}
}

@article{Jian2000,
  title = {Foundations for an {{Empirically Determined Scale}} of {{Trust}} in {{Automated Systems}}},
  author = {Jian, Jiun-Yin and Bisantz, Ann M. and Drury, Colin G.},
  year = {2000},
  month = mar,
  journal = {International Journal of Cognitive Ergonomics},
  volume = {4},
  number = {1},
  pages = {53--71},
  publisher = {{Lawrence Erlbaum Associates, Inc.}},
  issn = {1088-6362},
  doi = {10.1207/S15327566IJCE0401_04},
  abstract = {One component in the successful use of automated systems is the extent to which people trust the automation to perform effectively. In order to understand the relationship between trust in computer...}
}

@article{kirkpatrick201710,
  title = {Trust and {{Human}}\textendash{{Robot Interactions}}},
  author = {Kirkpatrick, Jesse and Hahn, Erin N. and Haufler, Amy J.},
  year = {2017},
  month = oct,
  journal = {Robot ethics 2.0: from autonomous cars to artificial intelligence},
  volume = {1},
  pages = {91},
  publisher = {{Oxford University Press}},
  doi = {10.1093/oso/9780190652951.003.0010},
  abstract = {The concept of trust can take various forms, from interpersonal trust to institutional trust to trust in oneself or one's government. As robotic technologies approach autonomy, and in increasing cases achieve it, scholars have turned their attention to the relationship between trust and human\textendash robot interactions. This chapter explores that relationship using a multidisciplinary approach that includes philosophy, law, and neuroscience. The first section explicates the concept of human\textendash robot interaction. The second articulates a normative account of interpersonal trust in service of the third section's exploration of whether human\textendash robot interactions could approach or achieve interpersonal trust. In answering this question in the affirmative, the fourth section flags some of the potential deleterious consequences of facilitating interpersonal trust in human\textendash robot interactions. The fifth concludes with a call for future scholarship to address the philosophical, empirical, legal, and policy issues related to trust in human\textendash robot interactions.}
}

@article{kohEffectsSpecializationComputers2010,
  title = {Effects of Specialization in Computers, Web Sites, and Web Agents on e-Commerce Trust},
  author = {Koh, Yoon Jeon and Sundar, S. Shyam},
  year = {2010},
  month = dec,
  journal = {International Journal of Human-Computer Studies},
  volume = {68},
  number = {12},
  pages = {899--912},
  publisher = {{Academic Press}},
  issn = {1071-5819},
  doi = {10.1016/J.IJHCS.2010.08.002},
  abstract = {Suppose you went shopping online for wines and visited several sites, each recommending particular reds and whites. Which kind of site are you likely to trust morecostco.com or wine.com? The specialization implied by the latter suggests more expertise in the domain of wines. Does it mean that you are more likely to purchase wines recommended by sites such as wine.com and vintagecellars.com.au than those recommended by generalist sites such as costco.com and samsclub.com? Our study attempts to answer this question by experimentally investigating how specialization in media technology (specifically, web agent, web site, and computer) influences individuals' perception and attitudes towards sources in online communication, particularly consumer trust and purchase behaviors in e-commerce. All subjects (N=124) went to a specially constructed online site with a virtual shopping cart for a wine-purchasing task, as part of a 2 (specialist vs. generalist web agent)\texttimes 2 (specialist vs. generalist web site)\texttimes 2 (specialist computer vs. generalist computer) between-subjects experiment. Results indicate significant main effects and interactions of the agent, site, and computer specialization on trust and purchase decision time. Theoretical and practical implications are discussed. \textcopyright{} 2010 Elsevier Ltd. All rights reserved.},
  keywords = {Category-based perception,Domain expertise,Generalist technologies,Media equation,Source layers in HCI,Specialization,Web agent,Web site},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Koh_Sundar_2010_Effects of specialization in computers, web sites, and web agents on e-commerce.pdf}
}

@article{kohn2021measurement,
  title = {Measurement of {{Trust}} in {{Automation}}: {{A Narrative Review}} and {{Reference Guide}}},
  shorttitle = {Measurement of {{Trust}} in {{Automation}}},
  author = {Kohn, Spencer C. and {de Visser}, Ewart J. and Wiese, Eva and Lee, Yi-Ching and Shaw, Tyler H.},
  year = {2021},
  journal = {Frontiers in Psychology},
  volume = {12},
  pages = {604977},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2021.604977},
  abstract = {With the rise of automated and autonomous agents, research examining Trust in Automation (TiA) has attracted considerable attention over the last few decades. Trust is a rich and complex construct which has sparked a multitude of measures and approaches to study and understand it. This comprehensive narrative review addresses known methods that have been used to capture TiA. We examined measurements deployed in existing empirical works, categorized those measures into self-report, behavioral, and physiological indices, and examined them within the context of an existing model of trust. The resulting work provides a reference guide for researchers, providing a list of available TiA measurement methods along with the model-derived constructs that they capture including judgments of trustworthiness, trust attitudes, and trusting behaviors. The article concludes with recommendations on how to improve the current state of TiA measurement.},
  langid = {english},
  pmcid = {PMC8562383},
  pmid = {34737716},
  keywords = {automation,autonomous,behavioral,measurement,measures,physiological,self-report,trust},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Kohn et al_2021_Measurement of Trust in Automation2.pdf}
}

@article{Kok2020,
  title = {Trust in {{Robots}}: {{Challenges}} and {{Opportunities}}},
  author = {Kok, Bing Cai and Soh, Harold},
  year = {2020},
  month = dec,
  journal = {Current Robotics Reports},
  volume = {1},
  number = {4},
  pages = {297--309},
  publisher = {{Springer}},
  issn = {2662-4087},
  doi = {10.1007/s43154-020-00029-y},
  abstract = {To assess the state-of-the-art in research on trust in robots and to examine if recent methodological advances can aid in the development of trustworthy robots. While traditional work in trustworthy robotics has focused on studying the antecedents and consequences of trust in robots, recent work has gravitated towards the development of strategies for robots to actively gain, calibrate, and maintain the human user's trust. Among these works, there is emphasis on endowing robotic agents with reasoning capabilities (e.g., via probabilistic modeling). The state-of-the-art in trust research provides roboticists with a large trove of tools to develop trustworthy robots. However, challenges remain when it comes to trust in real-world human-robot interaction (HRI) settings: there exist outstanding issues in trust measurement, guarantees on robot behavior (e.g., with respect to user privacy), and handling rich multidimensional data. We examine how recent advances in psychometrics, trustworthy systems, robot-ethics, and deep learning can provide resolution to each of these issues. In conclusion, we are of the opinion that these methodological advances could pave the way for the creation of truly autonomous, trustworthy social robots.},
  isbn = {4315402000029},
  keywords = {Computer Appl. in Social and Behavioral Sciences,Control,Mechatronics,Occupational Medicine/Industrial Medicine,Robotics,Robotics and Automation,Surgical Orthopedics},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Kok_Soh_2020_Trust in Robots.pdf}
}

@article{kose2009effects,
  title = {Effects of Embodiment and Gestures on Social Interaction in Drumming Games with a Humanoid Robot},
  author = {{Kose-Bagci}, Hatice and Ferrari, Ester and Dautenhahn, Kerstin and Syrdal, Dag Sverre and Nehaniv, Chrystopher L},
  year = {2009},
  journal = {Advanced Robotics},
  volume = {23},
  number = {14},
  pages = {1951--1996},
  publisher = {{Taylor \& Francis}},
  doi = {10.1163/016918609X12518783330360}
}

@article{laird1974self,
  title = {Self-Attribution of Emotion: The Effects of Expressive Behavior on the Quality of Emotional Experience.},
  author = {Laird, James D},
  year = {1974},
  journal = {Journal of personality and social psychology},
  volume = {29},
  number = {4},
  pages = {475},
  publisher = {{American Psychological Association}},
  doi = {10.1037/h0036125}
}

@article{lakin2003using,
  title = {Using Nonconscious Behavioral Mimicry to Create Affiliation and Rapport},
  author = {Lakin, Jessica L and Chartrand, Tanya L},
  year = {2003},
  journal = {Psychological science},
  volume = {14},
  number = {4},
  pages = {334--339},
  publisher = {{SAGE Publications Sage CA: Los Angeles, CA}},
  doi = {10.1111/1467-9280.14481}
}

@article{Langer2019,
  title = {Trust in Socially Assistive Robots: {{Considerations}} for Use in Rehabilitation},
  author = {Langer, Allison and {Feingold-Polak}, R. and Mueller, Oliver and Kellmeyer, Philipp and {Levy-Tzedek}, Shelly},
  year = {2019},
  month = sep,
  journal = {Neuroscience \textbackslash\& Biobehavioral Reviews},
  volume = {104},
  pages = {231--239},
  publisher = {{Pergamon}},
  issn = {0149-7634},
  doi = {10.1016/J.NEUBIOREV.2019.07.014},
  abstract = {Incorporation of social robots into rehabilitation calls for understanding what factors affect user motivation and success of the interaction. Trust between the user and the robot has been identified as important in human-robot interaction and in human-human interactions in therapy. Trust has been studied in the context of automation technology, (e.g., autonomous cars), but not in the context of social robots for rehabilitation. In this narrative review, we address the unique patient-clinician-robot triad, and argue that this context calls for specific design features in order to foster trust with the users. We review pertinent methods for measuring trust, and studies demonstrating that culture, prior experience and propensity-to-trust affect to what extent users trust robots. We suggest design guidelines for fostering trust and methods for measuring trust in human-robot interactions in rehabilitation. We stress the need to create measures of trust that are accessible to people who suffer from speech or cognitive impairments. This review is pertinent to researchers, roboticists, and clinicians interested in designing and using social robots for rehabilitation.},
  pmid = {31348963},
  keywords = {HRI,Rehabilitation,Social robots,Trust},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Langer et al_2019_Trust in socially assistive robots.pdf}
}

@article{launay2013synchronization,
  title = {Synchronization Can Influence Trust Following Virtual Interaction.},
  author = {Launay, Jacques and Dean, Roger T and Bailes, Freya},
  year = {2013},
  journal = {Experimental psychology},
  volume = {60},
  number = {1},
  pages = {53},
  publisher = {{Hogrefe Publishing}},
  doi = {10.1027/1618-3169/a000173}
}

@article{Lestienne2001,
  title = {Spike Timing, Synchronization and Information Processing on the Sensory Side of the Central Nervous System},
  author = {Lestienne, R{\'e}my},
  year = {2001},
  month = dec,
  journal = {Progress in Neurobiology},
  volume = {65},
  number = {6},
  pages = {545--591},
  publisher = {{Elsevier BV}},
  doi = {10.1016/s0301-0082(01)00019-3},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Lestienne_2001_Spike timing, synchronization and information processing on the sensory side of.pdf}
}

@inproceedings{liaoHowShouldAI2021,
  title = {How {{Should AI Systems Talk}} to {{Users}} When {{Collecting}} Their {{Personal Information}}? {{Effects}} of {{Role Framing}} and {{Self-Referencing}} on {{Human-AI Interaction}}},
  booktitle = {Proceedings of the 2021 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Liao, Mengqi and Sundar, S. Shyam},
  year = {2021},
  month = may,
  pages = {1--14},
  publisher = {{ACM}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3411764.3445415},
  abstract = {AI systems collect our personal information in order to provide personalized services, raising privacy concerns and making users leery. As a result, systems have begun emphasizing overt over covert collection of information by directly asking users. This poses an important question for ethical interaction design, which is dedicated to improving user experience while promoting informed decision-making: Should the interface tout the benefts of information disclosure and frame itself as a help-provider? Or, should it appear as a help-seeker? We decided to fnd out by creating a mockup of a news recommendation system called Mindz and conducting an online user study (N=293) with the following four variations: AI system as help seeker vs. help provider vs. both vs. neither. Data showed that even though all participants received the same recommendations, power users tended to trust a help-seeking Mindz more whereas non-power users favored one that is both help-seeker and help-provider.},
  isbn = {978-1-4503-8096-6},
  keywords = {Human-ai interaction,Power usage,Social cues,Social presence of ai},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Liao_Sundar_2021_How Should AI Systems Talk to Users when Collecting their Personal Information.pdf}
}

@article{Malhotra2011,
  title = {Trust and Collaboration in the Aftermath of Conflict: {{The}} Effects of Contract Structure},
  author = {Malhotra, Deepak and Lumineau, Fabrice},
  year = {2011},
  month = oct,
  journal = {Academy of Management Journal},
  volume = {54},
  number = {5},
  pages = {981--998},
  publisher = {{Academy of Management}},
  doi = {10.5465/amj.2009.0683},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Malhotra_Lumineau_2011_Trust and collaboration in the aftermath of conflict.pdf}
}

@incollection{malle2021multidimensional,
  title = {A Multidimensional Conception and Measure of Human-Robot Trust},
  booktitle = {Trust in Human-Robot Interaction},
  author = {Malle, Bertram F and Ullman, Daniel},
  year = {2021},
  pages = {3--25},
  publisher = {{Elsevier}}
}

@article{marsh2009social,
  title = {Social Connection through Joint Action and Interpersonal Coordination},
  author = {Marsh, Kerry L and Richardson, Michael J and Schmidt, Richard C},
  year = {2009},
  journal = {Topics in Cognitive Science},
  volume = {1},
  number = {2},
  pages = {320--339},
  publisher = {{Wiley Online Library}},
  doi = {10.1111/j.1756-8765.2009.01022.x}
}

@article{miles2009rhythm,
  title = {The Rhythm of Rapport: {{Interpersonal}} Synchrony and Social Perception},
  author = {Miles, Lynden K and Nind, Louise K and Macrae, C Neil},
  year = {2009},
  journal = {Journal of experimental social psychology},
  volume = {45},
  number = {3},
  pages = {585--589},
  publisher = {{Elsevier}},
  doi = {10.1016/j.jesp.2009.02.002}
}

@article{mortl2014rhythm,
  title = {Rhythm Patterns Interaction-Synchronization Behavior for Human-Robot Joint Action},
  author = {M{\"o}rtl, Alexander and Lorenz, Tamara and Hirche, Sandra},
  year = {2014},
  journal = {PloS one},
  volume = {9},
  number = {4},
  pages = {e95195},
  publisher = {{Public Library of Science San Francisco, USA}},
  doi = {10.1371/journal.pone.0095195}
}

@inproceedings{mota2016playing,
  title = {Playing the `Trust Game' with Robots: {{Social}} Strategies and Experiences},
  shorttitle = {Playing the `Trust Game' with Robots},
  booktitle = {2016 25th {{IEEE International Symposium}} on {{Robot}} and {{Human Interactive Communication}} ({{RO-MAN}})},
  author = {Mota, Roberta C. Ramos and Rea, Daniel J. and Le Tran, Anna and Young, James E. and Sharlin, Ehud and Sousa, Mario C.},
  year = {2016},
  month = aug,
  pages = {519--524},
  publisher = {{IEEE Comput. Soc}},
  address = {{Columbia University, NY, USA}},
  issn = {1944-9437},
  doi = {10.1109/ROMAN.2016.7745167},
  abstract = {We present the results of a pilot study that investigates if and how people judge the trustworthiness of a robot during social Human-Robot Interaction (sHRI). Current research in sHRI has observed that people tend to interact with robots socially. However, results from neuroscience suggests people use different cognitive mechanisms interacting with robots than they do with humans, leading to a debate about whether people truly perceive robots as social entities. Our paper focuses on one aspect of this debate, by examining trustworthiness between people and robots using behavioral economics' `Trust Game' scenario. Our pilot study replicates a trust game scenario, where a person invests money with a robot trustee in hopes they will receive a larger sum (trusting the robot to give more back), then gets a chance to invest once more. Our qualitative analysis of investing behavior and interviews with participants suggests that people may follow a human-robot (h-r) trust model that is quite similar to the human-human trust model. Our results also suggest a possible resolution to the sHRI and Neuroscience debate: people try to interact socially with robots, but due to lack of common social cues, they draw from social experience, or create new experiences by actively exploring the robot behavior.},
  keywords = {Computers,Context,Economics,Games,Investment,Neuroscience,Robots},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Mota et al_2016_Playing the ‘trust game’ with robots.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\XE3QJ6KI\\7745167.html}
}

@article{naneva2020systematic,
  title = {A {{Systematic Review}} of {{Attitudes}}, {{Anxiety}}, {{Acceptance}}, and {{Trust Towards Social Robots}}},
  author = {Naneva, Stanislava and Sarda Gou, Marina and Webb, Thomas L. and Prescott, Tony J.},
  year = {2020},
  month = dec,
  journal = {International Journal of Social Robotics},
  volume = {12},
  number = {6},
  pages = {1179--1201},
  issn = {1875-4805},
  doi = {10.1007/s12369-020-00659-4},
  abstract = {As social robots become more common, there is a need to understand how people perceive and interact with such technology. This systematic review seeks to estimate people's attitudes toward, trust in, anxiety associated with, and acceptance of social robots; as well as factors that are associated with these beliefs. Ninety-seven studies were identified with a combined sample of over 13,000 participants and a standardized score was computed for each in order to represent the valence (positive, negative, or neutral) and magnitude (on a scale from 1 to -\,1) of people's beliefs about robots. Potential moderating factors such as the robots' domain of application and design, the type of exposure to the robot, and the characteristics of potential users were also investigated. The findings suggest that people generally have positive attitudes towards social robots and are willing to interact with them. This finding may challenge some of the existing doubt surrounding the adoption of robotics in social domains of application but more research is needed to fully understand the factors that influence attitudes.},
  langid = {english},
  keywords = {Attitudes toward technology,Human–robot interaction,Social robots,Systematic review},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Naneva et al_2020_A Systematic Review of Attitudes, Anxiety, Acceptance, and Trust Towards Social2.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\ZZG29I6Q\\Naneva et al. - 2020 - A Systematic Review of Attitudes, Anxiety, Accepta.pdf}
}

@misc{nazari2019forward,
  title = {Forward and {{Inverse Kinematics}} of a {{Single Section Inextensible Continuum Arm}}},
  author = {Nazari, Ali A. and Castro, Diego and Godage, Isuru S.},
  year = {2019},
  month = jul,
  number = {arXiv:1907.06518},
  eprint = {1907.06518},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1907.06518},
  abstract = {Continuum arms, such as trunk and tentacle robots, lie between the two extremities of rigid and soft robots and promise to capture the best of both worlds in terms of manipulability, dexterity, and compliance. This paper proposes a new kinematic model for a novel constant-length continuum robot that incorporates both soft and rigid elements. In contrast to traditional pneumatically actuated, variable-length continuum arms, the proposed design utilizes a hyper-redundant rigid chain to provide extra structural strength. The proposed model introduces a reduced-order mapping to account for mechanical constraints arising from the rigid-linked chain to derive a closed-form curve parametric model. The model is numerically evaluated and the results show that the derived model is reliable.},
  archiveprefix = {arXiv},
  keywords = {⛔ No DOI found,Computer Science - Robotics},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Nazari et al_2019_Forward and Inverse Kinematics of a Single Section Inextensible Continuum Arm.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\GGPEGDWZ\\1907.html}
}

@incollection{newtson1994perception,
  title = {The Perception and Coupling of Behavior Waves},
  booktitle = {Dynamical Systems in Social Psychology.},
  author = {Newtson, Darren},
  year = {1994},
  pages = {139--167},
  publisher = {{Academic Press}},
  address = {{San Diego,  CA,  US}},
  abstract = {behavior is a wave [measuring ongoing behavior, perception of behavior waves, spectral analysis of ongoing behavior] / the nature of behavior waves [the concept of information flow, the coupling of behavior waves] (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  isbn = {0-12-709990-5 (Hardcover)},
  keywords = {*Behavioral Assessment,*Social Behavior,*Systems Theory,⛔ No DOI found,Social Perception}
}

@incollection{nowak1998computational,
  title = {Computational Social Psychology: {{A}} Neural Network Approach to Interpersonal Dynamics},
  shorttitle = {Computational Social Psychology},
  booktitle = {Computer Modeling of Social Processes},
  author = {Nowak, Andrzej and Vallacher, Robin R. and Burnstein, Eugene},
  year = {1998},
  pages = {97--125},
  publisher = {{Sage Publications Ltd}},
  address = {{Thousand Oaks, CA}},
  abstract = {The analogy between mind and society has a long history in psychology. Well before there was an established science of either cognition or social psychology, many scholars argued that social groups and societies had a "collective mind" that functioned in much the same way that individual minds did. Other perspectives on interpersonal process have suggested a more explicit analogy between mind and society. The model of transactive memory is based on the idea that social groups are directly analogous to individual minds with respect to the distribution and storage of information and memories. In much the same way that an individual develops a differentiated cognitive structure to accommodate diverse information, a social group is said to develop a role structure in which various individuals assume responsibility for remembering different categories of knowledge. Cognitive psychology has taken a related tack in developing the analogy between mind and society.  The aim of this chapter is to go beyond the analogy between mind and society to show that the real parallelism exists between brain and society. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  isbn = {978-0-7619-5423-1 978-0-7619-5424-8},
  keywords = {Group Dynamics,Neural Networks,Society},
  file = {C\:\\Users\\ra46sin\\Zotero\\storage\\443NIB5Y\\1998-06862-005.html}
}

@article{nowak2000modeling,
  title = {Modeling the Temporal Coordination of Behavior and Internal States},
  author = {Nowak, Andrzej and Vallacher, Robin R and Borkowski, Wojciech and others},
  year = {2000},
  journal = {Advances in Complex Systems},
  volume = {3},
  number = {1-4},
  pages = {67--86},
  doi = {10.1142/S0219525900000066}
}

@article{nowak2007dynamical,
  title = {Dynamical {{Social Psychology}}: {{Complexity}} and {{Coherence}} in {{Human Experience}}: {{Complexity}} and {{Coherence}} in {{Human Experience}}},
  author = {Wiese, Susan L. and Vallacher, Robin R. and Strawinska, Urszula},
  year = {2010},
  month = nov,
  journal = {Social and Personality Psychology Compass},
  volume = {4},
  number = {11},
  pages = {1018--1030},
  issn = {17519004},
  doi = {10.1111/j.1751-9004.2010.00319.x}
}

@article{Nowak2017,
  title = {Functional Synchronization: {{The}} Emergence of Coordinated Activity in Human Systems},
  author = {Nowak, Andrzej and Vallacher, Robin R. and Zochowski, Michal and Rychwalska, Agnieszka},
  year = {2017},
  month = jun,
  journal = {Frontiers in Psychology},
  volume = {8},
  number = {JUN},
  pages = {945},
  publisher = {{Frontiers Media S.A.}},
  issn = {16641078},
  doi = {10.3389/FPSYG.2017.00945},
  abstract = {The topical landscape of psychology is highly compartmentalized, with distinct phenomena explained and investigated with recourse to theories and methods that have little in common. Our aim in this article is to identify a basic set of principles that underlie otherwise diverse aspects of human experience at all levels of psychological reality, from neural processes to group dynamics. The core idea is that neural, behavioral, mental, and social structures emerge through the synchronization of lower-level elements (e.g., neurons, muscle movements, thoughts and feelings, individuals) into a functional unit-a coherent structure that functions to accomplish tasks. The coherence provided by the formation of functional units may be transient, persisting only as long as necessary to perform the task at hand. This creates the potential for the repeated assembly and disassembly of functional units in accordance with changing task demands. This perspective is rooted in principles of complexity science and non-linear dynamical systems and is supported by recent discoveries in neuroscience and recent models in cognitive and social psychology. We offer guidelines for investigating the emergence of functional units in different domains, thereby honoring the topical differentiation of psychology while providing an integrative foundation for the field.},
  keywords = {Brain,Function,Mind,Self-organization,Social systems,Synchronization},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Nowak et al_2017_Functional synchronization.pdf}
}

@book{Nowak2020,
  title = {In Sync: {{The}} Emergence of Function in Minds, Groups and Societies},
  author = {Nowak, Andrzej K and Vallacher, Robin R and Praszkier, Ryszard and Rychwalska, Agnieszka and Zochowski, Michal},
  year = {2020},
  series = {Understanding {{Complex Systems}}},
  publisher = {{Springer Cham}},
  address = {{Switzerland}},
  isbn = {978-3-030-38987-1}
}

@article{nowakSynchronizationGroupsSocieties2020,
  title = {Synchronization in {{Groups}} and {{Societies}}},
  author = {Nowak, Andrzej K. and Vallacher, Robin R. and Praszkier, Ryszard and Rychwalska, Agnieszka and Zochowski, Michal},
  year = {2020},
  journal = {Understanding Complex Systems},
  pages = {113--136},
  publisher = {{Springer}},
  issn = {18600840},
  doi = {10.1007/978-3-030-38987-1_6},
  abstract = {Humans are a social species and spent most of their time interacting with many people and forming relationships with a significantly smaller subset of these people. While the previous chapter focused on dyadic interactions and the formation of dyadic relationships, it is clearly the case that much of social life takes place in the context of more than two people\textemdash sometimes in the context of dozens, hundreds, or even thousands of people.},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Nowak et al_2020_Synchronization in Groups and Societies.pdf}
}

@article{oksanen2020trust,
  title = {Trust toward Robots and Artificial Intelligence: {{An}} Experimental Approach to Human\textendash Technology Interactions Online},
  author = {Oksanen, Atte and Savela, Nina and Latikka, Rita and Koivula, Aki},
  year = {2020},
  journal = {Frontiers in Psychology},
  volume = {11},
  pages = {568256},
  publisher = {{Frontiers Media SA}},
  doi = {10.3389/fpsyg.2020.568256}
}

@article{Olaronke2017,
  title = {State {{Of The Art}}: {{A Study}} of {{Human-Robot Interaction}} in {{Healthcare}}},
  author = {Olaronke, Iroju and Oluwaseun, Ojerinde and Rhoda, Ikono},
  year = {2017},
  journal = {Information Engineering and Electronic Business},
  volume = {3},
  pages = {43--55},
  publisher = {{International Journal of Information Engineering and Electronic Business}},
  doi = {10.5815/ijieeb.2017.03.06},
  abstract = {In general, the applications of robots have shifted rapidly from industrial uses to social uses. This provides robots with the ability to naturally interact with human beings and socially fit into the human environment. The deployment of social robots in the healthcare system is becoming extensive as a result of the shortage of healthcare professionals, rising costs of healthcare and the exponential growth in the number of vulnerable populations such as the sick, the aged and children with developmental disabilities. Consequently, social robots are used in healthcare for providing health education and entertainment for patients in the hospital and for providing aids for the sick and aged. They are also used for dispensing drugs and providing rehabilitation as well as emotional and aging care. Hence, social robots improve the efficiency and quality of healthcare services. The interaction between social robots and human beings is known as human-robot interaction. Human-robot interaction in healthcare is faced with numerous challenges such as the fear of displacement of caregivers by robots, safety, usefulness, acceptability as well as appropriateness. These challenges ultimately lead to a low rate of acceptance of the robotic technology. Consequently, this paper extensively appraises human-robot interaction in healthcare, their applications and challenges. Design, ethical and usability issues such as privacy, trust, safety, users' attitude, culture, robot morphology as well as emotions and deception arising from the interaction between humans and robots in healthcare are also reviewed in this paper.},
  keywords = {Artificial Intelligence,Healthcare,Human,Robots,Robots Interaction,Social Robots},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Olaronke et al_2017_State Of The Art.pdf}
}

@inproceedings{Pasquali2021,
  title = {Magic {{iCub}}: {{A Humanoid Robot Autonomously Catching}} Your {{Lies}} in a {{Card Game}}},
  shorttitle = {Magic {{iCub}}},
  booktitle = {Proceedings of the 2021 {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  author = {Pasquali, Dario and {Gonzalez-Billandon}, Jonas and Rea, Francesco and Sandini, Giulio and Sciutti, Alessandra},
  year = {2021},
  month = mar,
  series = {{{HRI}} '21},
  pages = {293--302},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3434073.3444682},
  abstract = {Games are often used to foster human partners' engagement and natural behavior, even when they are played with or against robots. Therefore, beyond their entertainment value, games represent ideal interaction paradigms where to investigate natural human-robot interaction and to foster robots' diffusion in the society. However, most of the state-of-the-art games involving robots, are driven with a Wizard of Oz approach. To address this limitation, we present an end-to-end (E2E) architecture to enable the iCub robotic platform to autonomously lead an entertaining magic card trick with human partners. We demonstrate that with this architecture a robot is capable of autonomously directing the game from beginning to end. In particular, the robot could detect in real-time when the players lied in the description of one card in their hands (the secret card). In a validation experiment the robot achieved an accuracy of 88.2\% (against a chance level of 16.6\%) in detecting the secret card while the social interaction naturally unfolded. The results demonstrate the feasibility of our approach and its effectiveness in entertaining the players and maintaining their engagement. Additionally, we provide evidence on the possibility to detect important measures of the human partner`s inner state such as cognitive load related to lie creation with pupillometry in a short and ecological game-like interaction with a robot.},
  isbn = {978-1-4503-8289-2},
  keywords = {cognitive load,entertainment,human-robot interaction,magic,pupillometry},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Pasquali et al_2021_Magic iCub2.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\YPDIRBVM\\Pasquali et al. - 2021 - Magic iCub A Humanoid Robot Autonomously Catching.pdf}
}

@book{pikovsky2001synchronization,
  title = {Synchronization: {{A}} Universal Concept},
  author = {Pikovsky, Arkady and Rosenblum, Michael and Kurths, J{\"u}rgen},
  year = {2001},
  series = {Cambridge Nonlinear Science Series},
  volume = {2},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge, England}},
  keywords = {⛔ No DOI found}
}

@article{pitardiAlexaSheNot2021,
  title = {Alexa, She's Not Human But\ldots{} {{Unveiling}} the Drivers of Consumers' Trust in Voice-Based Artificial Intelligence},
  author = {Pitardi, Valentina and Marriott, Hannah R.},
  year = {2021},
  month = apr,
  journal = {Psychology \& Marketing},
  volume = {38},
  number = {4},
  pages = {626--642},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {1520-6793},
  doi = {10.1002/MAR.21457},
  abstract = {With the development of deep connections between humans and Artificial Intelligence voice-based assistants (VAs), human and machine relationships have transformed. For relationships to work it is essential for trust to be established. Although the capabilities of VAs offer retailers and consumers enhanced opportunities, building trust with machines is inherently challenging. In this paper, we propose integrating Human\textendash Computer Interaction Theories and Para-Social Relationship Theory to develop insight into how trust and attitudes toward VAs are established. By adopting a mixed-method approach, first, we quantitatively examine the proposed model using Covariance-Based Structural Equation Modeling on 466 respondents; based on the findings of this study, a second qualitative study is employed to reveal four main themes. Findings show that while functional elements drive users' attitude toward using VAs, the social attributes, being social presence and social cognition, are the unique antecedents for developing trust. Additionally, the research illustrates a peculiar dynamic between privacy and trust and it shows how users distinguish two different sources of trustworthiness in their interactions with VAs, identifying the brand producers as the data collector. Taken together, these results reinforce the idea that individuals interact with VAs treating them as social entities and employing human social rules, thus supporting the adoption of a para-social perspective.},
  keywords = {artificial intelligence,privacy,technology adoption,trust,voice assistants},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Pitardi_Marriott_2021_Alexa, she's not human but… Unveiling the drivers of consumers' trust in.pdf}
}

@article{plaks2022identifying,
  title = {Identifying Psychological Features of Robots That Encourage and Discourage Trust},
  author = {Plaks, Jason E and Rodriguez, Laura Bustos and Ayad, Reem},
  year = {2022},
  journal = {Computers in Human Behavior},
  volume = {134},
  pages = {107301},
  publisher = {{Elsevier}},
  doi = {10.1016/j.chb.2022.107301}
}

@incollection{pytlikzillig2016consensus,
  title = {Consensus on {{Conceptualizations}} and {{Definitions}} of {{Trust}}: {{Are We There Yet}}?},
  shorttitle = {Consensus on {{Conceptualizations}} and {{Definitions}} of {{Trust}}},
  booktitle = {Interdisciplinary {{Perspectives}} on {{Trust}}: {{Towards Theoretical}} and {{Methodological Integration}}},
  author = {PytlikZillig, Lisa M. and Kimbrough, Christopher D.},
  editor = {Shockley, Ellie and Neal, Tess M.S. and PytlikZillig, Lisa M. and Bornstein, Brian H.},
  year = {2016},
  pages = {17--47},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-22261-5_2},
  abstract = {This chapter presents a ``review of reviews'' of issues surrounding the conceptualization and definition of trust and identifies a number of common essences of trust conceptualizations, as well as common disagreements about the definitional boundaries of trust. Common essences of trust include that trust involves a trustor (subject) and trustee (object) that are somehow interdependent; involves a situation containing risks for the trustor (which also implies the trustor has goals); is experienced by the trustor as voluntary (implying autonomy, agency, and intrinsic motivation); and includes (or excludes) different types, forms, or sources of trust concepts, some of which may form the bases of others and many of which involve or relate to positive evaluations or expectations. Meanwhile, researchers continue to disagree on numerous considerations, including the types of relationships that must be in place for psychological or behavioral states to be truly considered trust; whether and the extent to which all trust conceptualizations necessitate risk, conscious consideration of risk, volition, and/or active choice by the trustor and trustee; the separability of risk and trust; the psychological versus behavioral nature of trust; the cognitive versus affective nature of trust; and the requirements for trust to stem from some bases but not others. In considering the reasons for such agreements and disagreements, we conclude that the varied interests of different researchers might be furthered by greater future attention to refining a set of definitions for trusting and trust-relevant constructs that are part of ``trust-as-process.''},
  isbn = {978-3-319-22261-5},
  langid = {english},
  keywords = {Affective nature of trust,Agency,Behavioral trust,Cognitive nature of trust,Conceptualization of trust,Context(s),Cooperation,Definition(s),Dispositional trust,Generalized trust,Interdependence,Intrinsic motivation,Risk,Trust-as-attitude,Trust-as-choice,Trust-as-process,Trustor goals,Trustworthiness,Volition,Vulnerability}
}

@article{ravreby2022liking,
  title = {Liking as a Balance between Synchronization, Complexity and Novelty},
  author = {Ravreby, Inbal and Shilat, Yoel and Yeshurun, Yaara},
  year = {2022},
  journal = {Scientific Reports},
  volume = {12},
  number = {1},
  pages = {1--12},
  publisher = {{Nature Publishing Group}},
  doi = {10.1038/s41598-022-06610-z}
}

@article{Richardson2016,
  title = {Sex {{Robot Matters}}: {{Slavery}}, the {{Prostituted}}, and the {{Rights}} of {{Machines}}},
  author = {Richardson, Kathleen},
  year = {2016},
  month = jun,
  journal = {IEEE Technology and Society Magazine},
  volume = {35},
  number = {2},
  pages = {46--53},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {0278-0097},
  doi = {10.1109/MTS.2016.2554421},
  abstract = {Slavery is the coercive and controlled use of another human. Contrary to the belief that the practice ended in the 1800s, slavery still persists today. There are many different terms used to describe slavery including, debt bondage (a person's pledge of labor for a debt or obligation), sale and exploitation of children, and human trafficking (forced labor or commercial sexual exploitation). Sexual exploitation is the most commonly identified form of human trafficking (79\%) followed by forced labor (18\%) [52]. To be held in slavery is to be held in miserable conditions and have a form of power over you that denies you a life of freedom. For most people in Europe and North America slavery is not a visible problem, and one could think slavery is somehow less important, and less violent today than in the past. This is not the case. The United Nations estimates that almost 21 million people are currently victims of slaver y [25]. A staggering \$150billion in profits is generated from forced labor and 168 million girls and boys are in child labor [25]. Central to our understanding of slavery and its related forms is that a person is recast, often without bodily integrity, as property that can be bought, sold, and accessed by others with more power, status, and money.},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Richardson_2016_Sex Robot Matters.pdf}
}

@article{riegelsberger2003researcher,
  title = {The Researcher's Dilemma: Evaluating Trust in Computer-Mediated Communication},
  author = {Riegelsberger, Jens and Sasse, M Angela and McCarthy, John D},
  year = {2003},
  journal = {International Journal of Human-Computer Studies},
  volume = {58},
  number = {6},
  pages = {759--781},
  publisher = {{Elsevier}},
  doi = {10.1016/S1071-5819(03)00042-9}
}

@article{rinott2022designing,
  title = {Designing for Interpersonal Motor Synchronization},
  author = {Rinott, Michal and Tractinsky, Noam},
  year = {2022},
  journal = {Human\textendash Computer Interaction},
  volume = {37},
  number = {1},
  pages = {69--116},
  publisher = {{Taylor \& Francis}},
  doi = {10.1080/07370024.2021.1912608}
}

@article{Robinson1999ContinuumR,
  title = {Continuum Robots - a State of the Art},
  author = {Robinson, Graham and Davies, J. Bruce C.},
  year = {1999},
  journal = {Proceedings 1999 IEEE International Conference on Robotics and Automation (Cat. No.99CH36288C)},
  volume = {4},
  pages = {2849-2854 vol.4},
  doi = {10.1109/ROBOT.1999.774029}
}

@article{Rosenblum1998,
  title = {Synchronization in Noisy Systems and Cardiorespiratory Interaction},
  author = {Rosenblum, M.G. and Kurths, J. and Pikovsky, A. and Schafer, C. and Tass, P. and Abel, H.-H.},
  year = {1998},
  journal = {IEEE Engineering in Medicine and Biology Magazine},
  volume = {17},
  number = {6},
  pages = {46--53},
  publisher = {{Institute of Electrical and Electronics Engineers (IEEE)}},
  doi = {10.1109/51.731320},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Rosenblum et al_1998_Synchronization in noisy systems and cardiorespiratory interaction.pdf}
}

@article{Rosenthal1981,
  title = {From Trust on Intimacy: {{A}} New Inventory for Examining Eriksons Stages of Psychosocial Development},
  author = {Rosenthal, Doreen A. and Gurney, Ross M. and Moore, Susan M.},
  year = {1981},
  month = dec,
  journal = {Journal of Youth and Adolescence},
  volume = {10},
  number = {6},
  pages = {525--537},
  publisher = {{Springer Science and Business Media LLC}},
  doi = {10.1007/bf02087944},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Rosenthal et al_1981_From trust on intimacy.pdf}
}

@article{safety8030048,
  title = {Assessing {{System-Wide Safety Readiness}} for {{Successful Human}}\textendash{{Robot Collaboration Adoption}}},
  author = {Berx, Nicole and Adriaensen, Arie and Decr{\'e}, Wilm and Pintelon, Liliane},
  year = {2022},
  month = sep,
  journal = {Safety},
  volume = {8},
  number = {3},
  pages = {48},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2313-576X},
  doi = {10.3390/safety8030048},
  abstract = {Despite their undisputed potential, the uptake of collaborative robots remains below expectations. Collaborative robots (cobots) are used differently from conventional industrial robots. The current safety focus of collaborative workspaces is predominantly on the technological design; additional factors also need to be considered to cope with the emerging risks associated with complex systems. Cobot technologies are characterized by an inherent tradeoff between safety and efficiency. They introduce new, emergent risks to organizations and can create psychosocial impacts on workers. This leads to a confusing body of information and an apparent contradiction about cobot safety. Combined with a lack of safety knowledge, this impedes the introduction of cobots. A multi-step methodology was used, including a literature review and conceptual modeling. This article argues for the need for a system-wide safety awareness readiness assessment in the consideration phase of cobot implementation to alleviate the knowledge deficit and confusion. This work will benefit both researchers and practitioners. In addition, it defends the appropriateness of a maturity grid model for a readiness assessment tool. The building blocks for an easy-to-use and practically applicable tool are proposed, as well as an agenda for the next steps.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {adoption,collaborative robots,maturity models,safety risk readiness,socio-technical},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Berx et al_2022_Assessing System-Wide Safety Readiness for Successful Human–Robot Collaboration.pdf}
}

@inproceedings{Salem2015,
  title = {Towards {{Safe}} and {{Trustworthy Social Robots}}: {{Ethical Challenges}} and {{Practical Issues}}},
  shorttitle = {Towards {{Safe}} and {{Trustworthy Social Robots}}},
  booktitle = {Social {{Robotics}}},
  author = {Salem, Maha and Lakatos, Gabriella and Amirabdollahian, Farshid and Dautenhahn, Kerstin},
  editor = {Tapus, Adriana and Andr{\'e}, Elisabeth and Martin, Jean-Claude and Ferland, Fran{\c c}ois and Ammi, Mehdi},
  year = {2015},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {584--593},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-25554-5_58},
  abstract = {As robots are increasingly developed to assist humans socially with everyday tasks in home and healthcare settings, questions regarding the robot's safety and trustworthiness need to be addressed. The present work investigates the practical and ethical challenges in designing and evaluating social robots that aim to be perceived as safe and can win their human users' trust. With particular focus on collaborative scenarios in which humans are required to accept information provided by the robot and follow its suggestions, trust plays a crucial role and is strongly linked to persuasiveness. Accordingly, human-robot trust can directly affect people's willingness to cooperate with the robot, while under- or overreliance may have severe or even dangerous consequences. Problematically, investigating trust and human perceptions of safety in HRI experiments proves challenging in light of numerous ethical concerns and risks, which this paper aims to highlight and discuss based on experiences from HRI practice.},
  isbn = {978-3-319-25554-5},
  langid = {english},
  keywords = {Roboethics,Safety and trust in HRI,Socially assistive robots},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Salem et al_2015_Towards Safe and Trustworthy Social Robots.pdf}
}

@inproceedings{salem2015would,
  title = {Would {{You Trust}} a ({{Faulty}}) {{Robot}}? {{Effects}} of {{Error}}, {{Task Type}} and {{Personality}} on {{Human-Robot Cooperation}} and {{Trust}}},
  shorttitle = {Would {{You Trust}} a ({{Faulty}}) {{Robot}}?},
  booktitle = {Proceedings of the {{Tenth Annual ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  author = {Salem, Maha and Lakatos, Gabriella and Amirabdollahian, Farshid and Dautenhahn, Kerstin},
  year = {2015},
  month = mar,
  series = {{{HRI}} '15},
  pages = {141--148},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2696454.2696497},
  abstract = {How do mistakes made by a robot affect its trustworthiness and acceptance in human-robot collaboration? We investigate how the perception of erroneous robot behavior may influence human interaction choices and the willingness to cooperate with the robot by following a number of its unusual requests. For this purpose, we conducted an experiment in which participants interacted with a home companion robot in one of two experimental conditions: (1) the correct mode or (2) the faulty mode. Our findings reveal that, while significantly affecting subjective perceptions of the robot and assessments of its reliability and trustworthiness, the robot's performance does not seem to substantially influence participants' decisions to (not) comply with its requests. However, our results further suggest that the nature of the task requested by the robot, e.g. whether its effects are revocable as opposed to irrevocable, has a significant impact on participants' willingness to follow its instructions.},
  isbn = {978-1-4503-2883-8},
  keywords = {cooperation,social human-robot interaction,trust},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Salem et al_2015_Would You Trust a (Faulty) Robot2.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\57WETJZD\\Salem et al. - 2015 - Would You Trust a (Faulty) Robot Effects of Error.pdf}
}

@article{sanders2017trust,
  title = {Trust and {{Prior Experience}} in {{Human-Robot Interaction}}},
  author = {Sanders, Tracy L. and MacArthur, Keith and Volante, William and Hancock, Gabriella and MacGillivray, Thomas and Shugars, William and Hancock, P. A.},
  year = {2017},
  month = sep,
  journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
  volume = {61},
  number = {1},
  pages = {1809--1813},
  publisher = {{SAGE Publications Inc}},
  issn = {2169-5067},
  doi = {10.1177/1541931213601934},
  abstract = {This experiment explored the influence of users? experience (prior interaction) with robots on their attitudes and trust toward robotic agents. Specifically, we hypothesized that prior experience would lead to 1) higher trust scores after viewing a robot complete a task, 2) smaller differences in trust scores when comparing a human and a robot completing the same task, and 3) more positive general attitudes towards robots. These hypotheses were supported although not all results achieved significant levels of differentiation. These findings confirm that prior experience plays an important role in both user trust and general attitude in human-robot interactions.},
  langid = {english},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Sanders et al_2017_Trust and Prior Experience in Human-Robot Interaction3.pdf}
}

@inproceedings{savery2019establishing,
  title = {Establishing {{Human-Robot Trust}} through {{Music-Driven Robotic Emotion Prosody}} and {{Gesture}}},
  booktitle = {2019 28th {{IEEE International Conference}} on {{Robot}} and {{Human Interactive Communication}} ({{RO-MAN}})},
  author = {Savery, Richard and Rose, Ryan and Weinberg, Gil},
  year = {2019},
  month = oct,
  pages = {1--7},
  publisher = {{IEEE Comput. Soc}},
  address = {{New Delhi, India}},
  issn = {1944-9437},
  doi = {10.1109/RO-MAN46459.2019.8956386},
  abstract = {As human-robot collaboration opportunities continue to expand, trust becomes ever more important for full engagement and utilization of robots. Affective trust, built on emotional relationship and interpersonal bonds is particularly critical as it is more resilient to mistakes and increases the willingness to collaborate. In this paper we present a novel model built on music-driven emotional prosody and gestures that encourages the perception of a robotic identity, designed to avoid uncanny valley. Symbolic musical phrases were generated and tagged with emotional information by human musicians. These phrases controlled a synthesis engine playing back pre-rendered audio samples generated through interpolation of phonemes and electronic instruments. Gestures were also driven by the symbolic phrases, encoding the emotion from the musical phrase to low degree-of-freedom movements. Through a user study we showed that our system was able to accurately portray a range of emotions to the user. We also showed with a significant result that our non-linguistic audio generation achieved an 8\% higher mean of average trust than using a state-of-the-art text-to-speech system.},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Savery et al_2019_Establishing Human-Robot Trust through Music-Driven Robotic Emotion Prosody and.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\P4BSRZ47\\8956386.html}
}

@incollection{schmidt2008dynamics,
  title = {Dynamics of Interpersonal Coordination},
  booktitle = {Coordination: {{Neural}}, Behavioral and Social Dynamics},
  author = {Schmidt, Richard C. and Richardson, Michael J.},
  editor = {Fuchs, Armin and Jirsa, Viktor K.},
  year = {2008},
  pages = {281--308},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-540-74479-5_14},
  abstract = {Everyday human actions often occur in a social context. Past psychological research has found that the motor behavior of socially situated individuals tends to be coordinated. Our research performed over the last 20 years has sought to understand how the mutuality, accommodation, and synchrony found in everyday interactional coordination can be understood using a dynamical theory of behavioral order, namely coordination dynamics. Using laboratory interpersonal tasks, we have demonstrated that when two people are asked to rhythmically coordinate their limbs they show behavioral phenomena identical to those found in bimanual interlimb coordination, which has been mathematically modeled as a dynamical process. Research has demonstrated that these same dynamical organizing principles can coordinate the rhythmic movements of two people unintentionally and that the weaker, intermittent coordination that ensues is affected by both perceptual (e.g., attentional focus and information pickup activity of the visual system) and dynamical constraints (e.g., intrapersonal rhythmic synergies and period basin of entrainment). Other research has investigated how traditional social and personality properties of a dyad (rapport, social competence) relate to dynamical properties of a dyad's coordinated movements and how the stability of coordinated movements mirrors the stability of mental connectedness experienced in social interactions.},
  isbn = {978-3-540-74479-5}
}

@inproceedings{scissors2008linguistic,
  title = {Linguistic Mimicry and Trust in Text-Based {{CMC}}},
  booktitle = {Proceedings of the 2008 {{ACM}} Conference on {{Computer}} Supported Cooperative Work},
  author = {Scissors, Lauren E. and Gill, Alastair J. and Gergle, Darren},
  year = {2008},
  month = nov,
  series = {{{CSCW}} '08},
  pages = {277--280},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1460563.1460608},
  abstract = {This study examines the relationship between linguistic mimicry and trust establishment in a text-chat environment. Twenty-six participant pairs engaged in a social dilemma investment game and chatted via Instant Messenger (IM) after every five rounds of investment. Results revealed that, within chat sessions, lexical mimicry (repetition of words or word phrases by both partners) was significantly higher for high-trusting pairs than for low-trusting pairs, but that lexical mimicry across chat sessions was significantly higher for low-trusting pairs than for high-trusting pairs. Theoretical and applied implications are discussed.},
  isbn = {978-1-60558-007-4},
  keywords = {instant messaging (im),lexical mimicry,rapport,social dilemma,trust,trusting language},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Scissors et al_2008_Linguistic mimicry and trust in text-based CMC.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\AILAVLFT\\Scissors et al. - 2008 - Linguistic mimicry and trust in text-based CMC.pdf}
}

@incollection{Semin2008,
  title = {Grounding {{Social Cognition}}: {{Synchronization}}, {{Coordination}}, and {{Co-Regulation}}},
  shorttitle = {Grounding {{Social Cognition}}},
  booktitle = {Embodied {{Grounding}}: {{Social}}, {{Cognitive}}, {{Affective}}, and {{Neuroscientific Approaches}}},
  author = {Semin, G{\"u}n R. and Cacioppo, John T.},
  editor = {Smith, Eliot R. and Semin, G{\"u}n R.},
  year = {2008},
  pages = {119--147},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/CBO9780511805837.006},
  abstract = {The tabula of human nature was never rasa.W. D. HamiltonINTRODUCTIONUnderstanding the social in social cognition has presented a number of challenges that have been with us from the very beginnings of ``modern'' psychology (cf. Semin, 1986). The first challenge is to come to terms with what the ``social'' means. As Gallese noted recently: ``The hard problem in `social cognition' is to understand how the epistemic gulf separating single individuals can be overcome'' (Gallese, 2006, p. 16). The foundations of V\"olkerpsychologie in the 1850s (Lazarus, 1861; Lazarus \&amp; Steinhal, 1860; Wedewer, 1860; Waitz, 1859) constituted an attempt to overcome the then prevailing individual-centered psychology in German psychology by introducing a social level of analysis. The emerging modern social psychology in the early 20th century grappled with this problem, fluctuating between notions of ``group mind'' and ``instinct,'' with Durkheim, LeBon, Ross, Tarde, and Wundt arguing in different voices for collective representations, group mind, collective mind, collective consciousness, or V\"olkerpsychologie. Of these various influences, the prevailing view that emerged was driven by Allport's vision of a social psychology that was individual-centered and regarded as a subdiscipline of psychology (Allport, 1924; cf. Post, 1980; Graumann, 1984, inter alia). This has very much remained the dominant view of mainstream social cognition and is underlined with reference to the biological finitude of the individual.},
  isbn = {978-0-521-88019-0},
  file = {C\:\\Users\\ra46sin\\Zotero\\storage\\5YTEJ8MU\\2D0F5C291E88EA57B12C6618A7FB164F.html}
}

@article{seymourExploringInteractionsTrust2021,
  title = {Exploring {{Interactions Between Trust}}, {{Anthropomorphism}}, and {{Relationship Development}} in {{Voice Assistants}}},
  author = {Seymour, William and Van Kleek, Max},
  year = {2021},
  month = oct,
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {5},
  number = {CSCW2},
  eprint = {2108.01923},
  eprinttype = {arxiv},
  issn = {25730142},
  doi = {10.1145/3479515},
  abstract = {Modern conversational agents such as Alexa and Google Assistant represent significant progress in speech recognition, natural language processing, and speech synthesis. But as these agents have gro...},
  archiveprefix = {arXiv},
  keywords = {anthropomorphism,relationship development,trust,voice assistants},
  annotation = {ACM 		PUB27 		New York, NY, USA}
}

@article{shen2015can,
  title = {Can Real-Time, Adaptive Human\textendash Robot Motor Coordination Improve Humans' Overall Perception of a Robot?},
  author = {Shen, Qiming and Dautenhahn, Kerstin and Saunders, Joe and Kose, Hatice},
  year = {2015},
  journal = {IEEE Transactions on Autonomous Mental Development},
  volume = {7},
  number = {1},
  pages = {52--64},
  publisher = {{IEEE}},
  doi = {10.1109/TAMD.2015.2398451}
}

@article{shneiderman2020bridging,
  title = {Bridging the Gap between Ethics and Practice: Guidelines for Reliable, Safe, and Trustworthy Human-Centered {{AI}} Systems},
  author = {Shneiderman, Ben},
  year = {2020},
  journal = {ACM Transactions on Interactive Intelligent Systems (TiiS)},
  volume = {10},
  number = {4},
  pages = {1--31},
  publisher = {{ACM New York, NY, USA}},
  doi = {10.1145/3419764}
}

@inproceedings{slovak2011exploring,
  title = {Exploring Trust in Group-to-Group Video-Conferencing},
  booktitle = {{{CHI}} '11 {{Extended Abstracts}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Slov{\'a}k, Petr and Nov{\'a}k, Peter and Troubil, Pavel and Holub, Petr and Hofer, Erik C.},
  year = {2011},
  month = may,
  series = {{{CHI EA}} '11},
  pages = {1459--1464},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1979742.1979791},
  abstract = {Previous work has shown that supporting trust via computer-mediated communication can be a challenge, especially among strangers. In this paper, we report on an experiment comparing two group-to-group video-conferencing environments and face-to-face communication in their ability to support trust and mutual cooperation in a social dilemma task. There are pronounced differences in participant behaviour between the two video-conferencing designs, indicating higher mutual trust in one of the video-conferencing conditions. The decisive factor seems to be a discrepancy in the type of group identity that develops during the game. Moreover, our results suggest that a combination of personal displays and a unique video-stream of each participant present in the better video-conferencing condition contributed to this result.},
  isbn = {978-1-4503-0268-5},
  keywords = {group identity,group-to-group videoconferencing,video conferencing},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Slovák et al_2011_Exploring trust in group-to-group video-conferencing.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\GWJST9XH\\Slovák et al. - 2011 - Exploring trust in group-to-group video-conferenci.pdf}
}

@inproceedings{slovak2014exploring,
  title = {Exploring Skin Conductance Synchronisation in Everyday Interactions},
  booktitle = {Proceedings of the 8th {{Nordic Conference}} on {{Human-Computer Interaction}}: {{Fun}}, {{Fast}}, {{Foundational}}},
  author = {Slov{\'a}k, Petr and Tennent, Paul and Reeves, Stuart and Fitzpatrick, Geraldine},
  year = {2014},
  month = oct,
  series = {{{NordiCHI}} '14},
  pages = {511--520},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2639189.2639206},
  abstract = {Detecting interpersonal and emotional aspects of behaviour is a growing area of research within HCI. However, this work primarily processes data from individuals, rather than drawing on the dynamics of an interaction between people. Literature in social psychology and neuroscience suggests that the synchronisation of peoples' biosignals, in particular skin conductance (EDA), can be indicative of complex interpersonal aspects such as empathy. This paper reports on an exploratory, mixed methods study to test the potential of EDA synchronisation to indicate qualities of interpersonal interaction in real-world relationships and contexts. We show that EDA synchrony can be indicate meaningful social aspects in everyday settings, linking it to the mutual emotional engagement of those interacting. This connects to earlier work on empathy in psychotherapy, and suggests new interpretations of EDA sychronisation in other social contexts. We then outline how these findings open opportunities for novel HCI and ubicomp applications, supporting training of social skills such as empathy for doctors, and more generally to explore shared experiences such as multiplayer games.},
  isbn = {978-1-4503-2542-4},
  keywords = {biosensors,empathy,GSR,mixed methods,physiological synchrony,skin conductance},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Slovák et al_2014_Exploring skin conductance synchronisation in everyday interactions.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\UHGTLICM\\Slovák et al. - 2014 - Exploring skin conductance synchronisation in ever.pdf}
}

@article{stel2010mimicry,
  title = {Mimicry in Social Interaction: {{Benefits}} for Mimickers, Mimickees, and Their Interaction},
  author = {Stel, Mari{\"e}lle and Vonk, Roos},
  year = {2010},
  journal = {British journal of psychology},
  volume = {101},
  number = {2},
  pages = {311--323},
  publisher = {{Wiley Online Library}},
  doi = {10.1348/000712609X465424}
}

@article{strack1988inhibiting,
  title = {Inhibiting and Facilitating Conditions of the Human Smile: A Nonobtrusive Test of the Facial Feedback Hypothesis.},
  author = {Strack, Fritz and Martin, Leonard L and Stepper, Sabine},
  year = {1988},
  journal = {Journal of personality and social psychology},
  volume = {54},
  number = {5},
  pages = {768},
  publisher = {{American Psychological Association}},
  doi = {10.1037/0022-3514.54.5.768}
}

@article{Su2019,
  title = {Of {{Dolls}} and {{Men}}: {{Anticipating Sexual Intimacy}} with {{Robots}}},
  author = {Su, Norman Makoto and Lazar, Amanda and Bardzell, Jeffrey and Bardzell, Shaowen},
  year = {2019},
  month = jun,
  journal = {ACM Transactions on Computer-Human Interaction},
  volume = {26},
  number = {3},
  pages = {1--35},
  publisher = {{Association for Computing Machinery}},
  issn = {1073-0516},
  doi = {10.1145/3301422},
  abstract = {{$<$}p{$>$}Sex and intimate technologies are important in people's everyday lives. A class of technologies that is becoming increasingly more prominent in discussions of the future are sex robots. In this article, we present a qualitative analysis of posts from a forum where people describe their interactions with sex dolls and their motivations for using them through text and photographs. Forum users use dolls as a content authoring interface, imbue them with agency, and construct meaningful sexual relationships with them. Implications for the design of future robots and autonomous agents in humans' everyday lives are discussed. We highlight that sex dolls are used for more than just sex; they provide fertile ground for embodied fictions and care of the self. Future, customizable technologies for sexual intimacy and wellness should account for this use.{$<$}/p{$>$}},
  keywords = {Care,Embodiment,Intimacy,Online forums,Robots,Sexuality,Wellness}
}

@inproceedings{Troiano2020,
  title = {"{{And This}}, {{Kids}}, {{Is How I Met Your Mother}}": {{Consumerist}}, {{Mundane}}, and {{Uncanny Futures}} with {{Sex Robots}}},
  shorttitle = {"{{And This}}, {{Kids}}, {{Is How I Met Your Mother}}"},
  booktitle = {Proceedings of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Troiano, Giovanni Maria and Wood, Matthew and Harteveld, Casper},
  year = {2020},
  month = apr,
  series = {{{CHI}} '20},
  pages = {1--17},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3313831.3376598},
  abstract = {Sex Robots are no longer science fiction and may soon be-come widespread. While much discussion has developed in academia on their moral and social impact, sex robots have yet to be examined from a critical design perspective and are under-explored in HCI. We use the Story Completion Method(SCM) to explore commonplace assumptions around futures with sex robots and discuss those from a critical design perspective. Thirty five participants completed a story stem of a human encountering a sex robot or vice-versa. Through thematic analysis, we show narratives of consumerist relation-ships between humans and sex robots, stories that describe sex robots as highly-efficient sex workers that (out)perform humans in routinal sex activities, and narratives that explore sex robots as empathetic and sentient beings. Our participant-created stories both reinforce and challenge established norms of sex robots and raise questions that concern responsible design and ethics in HCI. Finally, we show opportunities and limitations of using multiple-perspective story stems in SCM},
  isbn = {978-1-4503-6708-0},
  keywords = {ethics,human-robot interaction,research fiction,sex robots,sexual HCI,speculative design,story completion method},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Troiano et al_2020_And This, Kids, Is How I Met Your Mother.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\2XJPJUHS\\Troiano et al. - 2020 - And This, Kids, Is How I Met Your Mother Consum.pdf}
}

@article{Tuisku2019,
  title = {``{{Robots}} Do Not Replace a Nurse with a Beating Heart'': {{The}} Publicity around a Robotic Innovation in Elderly Care},
  author = {Tuisku, Outi and Pekkarinen, Satu and Hennala, Lea and Melkas, Helin{\"a}},
  year = {2019},
  month = jan,
  journal = {Information Technology and People},
  volume = {32},
  number = {1},
  pages = {47--67},
  publisher = {{Emerald Group Holdings Ltd.}},
  issn = {09593845},
  doi = {10.1108/ITP-06-2018-0277},
  abstract = {Purpose: The purpose of this paper is to investigate the publicity around the implementation of the Zora robot in elderly-care services in Lahti, Finland. The aim is to discover opinions concerning the use of robots in elderly care as well as the arguments and justifications behind those opinions. Zora is a humanoid robot intended to promote mobility and rehabilitation. The Lahti pilot was the first Zora pilot in Finland in public elderly-care services. It received much publicity, both regionally and nationally. Design/methodology/approach: This study is based on an empirical case study on the implementation of the Zora robot in elderly-care services. The data consist of interviews with personnel who operated Zora and comments from the general public about the ``Zora'' robot. Two data sources were used: 107 comments were collected from online and print media, and the personnel (n=39) who worked with Zora were interviewed. The data were analysed by means of interpretative content analysis. Findings: The results show that public opinion is mainly negative, but that the commentators apparently have little information about the robot and its tasks. The personnel had more positive views; they saw it as a recreational tool, not as a replacement for their own roles. Originality/value: There is clearly a need for more information, for a better informed discussion on how robots can be used in elderly care and how to involve the general public in this discussion in a constructive way.},
  keywords = {End users,Human–computer interaction (HCI),Innovation,IT innovation},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Tuisku et al_2019_“Robots do not replace a nurse with a beating heart”.pdf}
}

@article{vallacher2005dynamics,
  title = {Dynamics of Social Coordination: {{The}} Synchronization of Internal States in Close Relationships},
  author = {Vallacher, Robin R and Nowak, Andrzej and Zochowski, Michal},
  year = {2005},
  journal = {Interaction Studies},
  volume = {6},
  number = {1},
  pages = {35--52},
  publisher = {{John Benjamins}},
  doi = {10.1075/is.6.1.04val}
}

@inproceedings{weinberg2009leader,
  title = {A Leader-Follower Turn-Taking Model Incorporating Beat Detection in Musical Human-Robot Interaction},
  booktitle = {Proceedings of the 4th {{ACM}}/{{IEEE}} International Conference on {{Human}} Robot Interaction},
  author = {Weinberg, Gil and Blosser, Brian},
  year = {2009},
  month = mar,
  series = {{{HRI}} '09},
  pages = {227--228},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1514095.1514149},
  abstract = {This paper describes the implementation of a leader-follower model in a musical HRI based on beat detection analysis and a novel turn taking scheme. The project enables Haile, a robotic percussionist, to fluidly interact with humans in the context of an improvisatory jam session. The long-term goal of this work is to facilitate dynamic interactions between humans and machines that will lead to novel and inspiring musical outcomes.},
  isbn = {978-1-60558-404-1},
  keywords = {beat-detection,human-robot interaction,leader-follower paradigm,machine listening,robotic musicianship},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Weinberg_Blosser_2009_A leader-follower turn-taking model incorporating beat detection in musical.pdf;C\:\\Users\\ra46sin\\Zotero\\storage\\P7TKHS3B\\Weinberg and Blosser - 2009 - A leader-follower turn-taking model incorporating .pdf}
}

@article{Welge2016,
  title = {Better than Human: {{About}} the Psychological Superpowers of Robots},
  author = {Welge, Julika and Hassenzahl, Marc},
  year = {2016},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume = {9979 LNAI},
  pages = {993--1002},
  publisher = {{Springer Verlag}},
  issn = {16113349},
  doi = {10.1007/978-3-319-47437-3_97},
  abstract = {Social interaction is crucial for psychological wellbeing. However, for the elderly, desiring to live independently in their homes for as long as possible, getting the emotional care needed can become challenging. robots as social companions may help. To design companions, we argue to focus on the hybrid nature of robots in between being a ``thing'' and a ``human'' thus utilizing the unique ``capabilities'' of a robot. We discuss six psychological superpowers of robots rooted in their ``thingness'' rather than ``humanness.'' robots are void of competitiveness, have endless patience, can be unconditionally subordinated, have the ability to contain themselves, do not take things personally and can assume responsibility. These qualities all relate to everyday companionship, but may be difficult to actually realize for fellow humans. By exploiting these superpowers, robot companions can become meaningful \textendash{} not as a substitute for other humans, but as a novel, complementary form of social interaction.},
  isbn = {9783319474366},
  keywords = {Assistance systems,Eldercare,Emotion,Experience design,Human-robot-Interaction,Smart home,Social interaction,Social robot},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Welge_Hassenzahl_2016_Better than human.pdf}
}

@article{wienrichTrustworthinessVoiceAssistants2021,
  title = {The {{Trustworthiness}} of {{Voice Assistants}} in the {{Context}} of {{Healthcare Investigating}} the {{Effect}} of {{Perceived Expertise}} on the {{Trustworthiness}} of {{Voice Assistants}}, {{Providers}}, {{Data Receivers}}, and {{Automatic Speech Recognition}}},
  author = {Wienrich, Carolin and Reitelbach, Clemens and Carolus, Astrid},
  year = {2021},
  month = jun,
  journal = {Frontiers in Computer Science},
  volume = {3},
  pages = {53},
  publisher = {{Frontiers Media S.A.}},
  issn = {26249898},
  doi = {10.3389/FCOMP.2021.685250},
  abstract = {As an emerging market for voice assistants (VA), the healthcare sector imposes increasing requirements on the users' trust in the technological system. To encourage patients to reveal sensitive data requires patients to trust in the technological counterpart. In an experimental laboratory study, participants were presented a VA, which was introduced as either a ``specialist'' or a ``generalist'' tool for sexual health. In both conditions, the VA asked the exact same health-related questions. Afterwards, participants assessed the trustworthiness of the tool and further source layers (provider, platform provider, automatic speech recognition in general, data receiver) and reported individual characteristics (disposition to trust and disclose sexual information). Results revealed that perceiving the VA as a specialist resulted in higher trustworthiness of the VA and of the provider, the platform provider and automatic speech recognition in general. Furthermore, the provider's trustworthiness affected the perceived trustworthiness of the VA. Presenting both a theoretical line of reasoning and empirical data, the study points out the importance of the users' perspective on the assistant. In sum, this paper argues for further analyses of trustworthiness in voice-based systems and its effects on the usage behavior as well as the impact on responsible design of future technology.},
  keywords = {anamnesis tool,expertise framing (Min5-Max 8),trust,trustworthiness,voice assistant},
  file = {C\:\\Users\\ra46sin\\OneDrive\\Uni\\paper\\zotero\\Wienrich et al_2021_The Trustworthiness of Voice Assistants in the Context of Healthcare.pdf}
}

@article{yun2012interpersonal,
  title = {Interpersonal Body and Neural Synchronization as a Marker of Implicit Social Interaction},
  author = {Yun, Kyongsik and Watanabe, Katsumi and Shimojo, Shinsuke},
  year = {2012},
  journal = {Scientific reports},
  volume = {2},
  number = {1},
  pages = {1--8},
  publisher = {{Nature Publishing Group}},
  doi = {10.1038/srep00959}
}

@article{zorner2021immersive,
  title = {An Immersive Investment Game to Study Human-Robot Trust},
  author = {Z{\"o}rner, Sebastian and Arts, Emy and Vasiljevic, Brenda and Srivastava, Ankit and Schmalzl, Florian and Mir, Glareh and Bhatia, Kavish and Strahl, Erik and Peters, Annika and Alpay, Tayfun and others},
  year = {2021},
  journal = {Frontiers in Robotics and AI},
  volume = {8},
  pages = {644529},
  publisher = {{Frontiers Media SA}},
  doi = {10.3389/frobt.2021.644529}
}
