{
    "arxiv_id": "2303.12307",
    "paper_title": "Predicting and Enhancing the Fairness of DNNs with the Curvature of Perceptual Manifolds",
    "authors": [
        "Yanbiao Ma",
        "Licheng Jiao",
        "Fang Liu",
        "Maoji Wen",
        "Lingling Li",
        "Wenping Ma",
        "Shuyuan Yang",
        "Xu Liu",
        "Puhua Chen"
    ],
    "submission_date": "2023-03-22",
    "revised_dates": [
        "2024-05-27"
    ],
    "latest_version": 6,
    "categories": [
        "cs.CV",
        "cs.AI"
    ],
    "abstract": "To address the challenges of long-tailed classification, researchers have proposed several approaches to reduce model bias, most of which assume that classes with few samples are weak classes. However, recent studies have shown that tail classes are not always hard to learn, and model bias has been observed on sample-balanced datasets, suggesting the existence of other factors that affect model bias. In this work, we first establish a geometric perspective for analyzing model fairness and then systematically propose a series of geometric measurements for perceptual manifolds in deep neural networks. Subsequently, we comprehensively explore the effect of the geometric characteristics of perceptual manifolds on classification difficulty and how learning shapes the geometric characteristics of perceptual manifolds. An unanticipated finding is that the correlation between the class accuracy and the separation degree of perceptual manifolds gradually decreases during training, while the negative correlation with the curvature gradually increases, implying that curvature imbalance leads to model bias.Building upon these observations, we propose curvature regularization to facilitate the model to learn curvature-balanced and flatter perceptual manifolds. Evaluations on multiple long-tailed and non-long-tailed datasets show the excellent performance and exciting generality of our approach, especially in achieving significant performance improvements based on current state-of-the-art techniques. Our work opens up a geometric analysis perspective on model bias and reminds researchers to pay attention to model bias on non-long-tailed and even sample-balanced datasets.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.12307v1",
        "http://arxiv.org/pdf/2303.12307v2",
        "http://arxiv.org/pdf/2303.12307v3",
        "http://arxiv.org/pdf/2303.12307v4",
        "http://arxiv.org/pdf/2303.12307v5",
        "http://arxiv.org/pdf/2303.12307v6"
    ],
    "publication_venue": "17pages, Accepted by CVPR 2023, Submitted to TPAMI"
}