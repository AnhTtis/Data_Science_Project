{
  "2102-05406": {
    "title": "Non-stationary Reinforcement Learning without Prior Knowledge: An Optimal Black-box Approach",
    "authors": [
      "Chen-Yu Wei",
      "Haipeng Luo"
    ],
    "submission_date": "2021-02-10",
    "revised_dates": [],
    "arxiv_id": "2102.05406",
    "venue": "Annual Conference Computational Learning Theory",
    "year": 2021
  },
  "2010-04244": {
    "title": "Nonstationary Reinforcement Learning with Linear Function Approximation",
    "authors": [
      "Huozhi Zhou",
      "Jinglin Chen",
      "L. Varshney",
      "A. Jagmohan"
    ],
    "submission_date": "2020-10-08",
    "revised_dates": [],
    "arxiv_id": "2010.04244",
    "venue": "Trans. Mach. Learn. Res.",
    "year": 2020
  },
  "2007-05078": {
    "title": "A Kernel-Based Approach to Non-Stationary Reinforcement Learning in Metric Spaces",
    "authors": [
      "O. D. Domingues",
      "Pierre M'enard",
      "Matteo Pirotta",
      "E. Kaufmann",
      "Michal Valko"
    ],
    "submission_date": "2020-07-09",
    "revised_dates": [],
    "arxiv_id": "2007.05078",
    "venue": "International Conference on Artificial Intelligence and Statistics",
    "year": 2020
  },
  "2007-00148": {
    "title": "Dynamic Regret of Policy Optimization in Non-stationary Environments",
    "authors": [
      "Yingjie Fei",
      "Zhuoran Yang",
      "Zhaoran Wang",
      "Qiaomin Xie"
    ],
    "submission_date": "2020-06-30",
    "revised_dates": [],
    "arxiv_id": "2007.00148",
    "venue": "Neural Information Processing Systems",
    "year": 2020
  },
  "2006-14389": {
    "title": "Reinforcement Learning for Non-Stationary Markov Decision Processes: The Blessing of (More) Optimism",
    "authors": [
      "Wang Chi Cheung",
      "D. Simchi-Levi",
      "Ruihao Zhu"
    ],
    "submission_date": "2020-06-24",
    "revised_dates": [],
    "arxiv_id": "2006.14389",
    "venue": "International Conference on Machine Learning",
    "year": 2020
  },
  "2004-09656": {
    "title": "Tightening Exploration in Upper Confidence Reinforcement Learning",
    "authors": [
      "Hippolyte Bourel",
      "Odalric-Ambrym Maillard",
      "M. S. Talebi"
    ],
    "submission_date": "2020-04-20",
    "revised_dates": [],
    "arxiv_id": "2004.09656",
    "venue": "International Conference on Machine Learning",
    "year": 2020
  },
  "1905-05857": {
    "title": "Variational Regret Bounds for Reinforcement Learning",
    "authors": [
      "Pratik Gajane",
      "R. Ortner",
      "P. Auer"
    ],
    "submission_date": "2019-05-14",
    "revised_dates": [],
    "arxiv_id": "1905.05857",
    "venue": "Conference on Uncertainty in Artificial Intelligence",
    "year": 2019
  },
  "1811-09549": {
    "title": "Idiosyncrasies and challenges of data driven learning in electronic trading",
    "authors": [
      "Vangelis Bacoyannis",
      "Vacslav Glukhov",
      "Tom Jin",
      "Jonathan Kochems",
      "Doo Re Song"
    ],
    "submission_date": "2018-11-23",
    "revised_dates": [],
    "arxiv_id": "1811.09549",
    "year": 2018
  },
  "1805-10066": {
    "title": "A Sliding-Window Algorithm for Markov Decision Processes with Arbitrarily Changing Rewards and Transitions",
    "authors": [
      "Pratik Gajane",
      "R. Ortner",
      "P. Auer"
    ],
    "submission_date": "2018-05-25",
    "revised_dates": [],
    "arxiv_id": "1805.10066",
    "venue": "arXiv.org",
    "year": 2018
  },
  "1306-0940": {
    "title": "(More) Efficient Reinforcement Learning via Posterior Sampling",
    "authors": [
      "Ian Osband",
      "Daniel Russo",
      "Benjamin Van Roy"
    ],
    "submission_date": "2013-06-04",
    "revised_dates": [],
    "arxiv_id": "1306.0940",
    "venue": "Neural Information Processing Systems",
    "year": 2013
  }
}