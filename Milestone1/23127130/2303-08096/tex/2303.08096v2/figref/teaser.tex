\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{fig/teaser.pdf}
   \caption{\methodname infers a neural radiance field from an object-centered dataset.
   A dataset-specific encoder maps each image to a predicted pose $R_i$. Given an equivalence relation in camera space, we render rays from all the poses in the equivalence class $[R_i]$. The modulo loss only penalizes the smallest L2 distance from the ground truth color. At evaluation time, the neural field can be used to generate novel views.
   }
   \label{fig:teaser}
\vspace{-3mm}
\end{figure}