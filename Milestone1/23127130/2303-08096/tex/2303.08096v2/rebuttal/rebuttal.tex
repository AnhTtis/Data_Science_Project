\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv_rebuttal}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[font=footnotesize,labelfont=bf]{caption}
\usepackage{etoolbox}
\patchcmd{\thebibliography}{\section*{\refname}}{}{}{}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\input{preamble}
\input{definitions}
\newcommand{\RI}{{\bf \color{red}R1}}
\newcommand{\RII}{{\bf \color{green}R2}}
\newcommand{\RIII}{{\bf \color{blue}R3}}
\makeatletter
\renewcommand{\thefigure}{R\@arabic\c@figure}
\makeatother

\DeclareMathSymbol{\shortminus}{\mathbin}{AMSa}{"39}

%%%%%%%%% PAPER ID
\def\iccvPaperID{1256} 
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}
\begin{document}

%%%%%%%%% TITLE
\title{MELON: NeRF with Unposed Images Using Equivalence Class Estimation}
\maketitle
\thispagestyle{empty}

%%%%%%%%% BODY TEXT
% We appreciate the reviewers giving positive comments about the quality of the results and the usefulness of the theoretical tools introduced in the paper.
We thank the reviewers for their insightful feedback. We are glad reviewers feel positive about many aspects of our paper: ``the modulo-loss [being] a convincing contribution that is well explained'' (\RIII), ``the notion of self-similarity map [being] insightful'' (\RII), ``experimental results clearly show[ing] that in the synthetic setting MELON outperforms GNeRF'' (\RII) and ``the paper compar[ing] itself to other works in a real world setting'' (\RI) where ``MELON achieves superior quality over the competitors'' (\RII).

\vspace{2mm}
\textbf{(\RI,\RII,\RIII) Restriction to \sothree}
In many real-world scenarios, such as 3D face or object capture, cameras observe the scene from a nearly fixed distance. MELON successfully operates in these and many other scenarios. A general purpose solution operating in the unconstrained settings of SE(3) is an interesting avenue for future research.

We would like to emphasize that, in practice, all competing methods make similar assumptions or are restricted in other ways. For example, they either require a manual and time-consuming initialization of the camera poses \cite{lin2021barf, boss2022samurai}, which is often infeasible, or a very large number of images \cite{meng2021gnerf}, which are often not available. The closest method to ours, GNeRF, samples camera positions on the surface of a sphere and ``look-at'' points within 0.1\% of the origin, relative to camera distance. VMRF~\cite{zhang2022vmrf} showed GNeRF quickly degrades if the assumed prior deviates too much from the actual pose distribution, making competitive adversarial approaches practically limited to the same scenarios as MELON.

MELON is the only method capable of reconstructing challenging synthetic scenes like ``ship'', ``materials'' and ``ficus'' (Tab 1, Fig 4). Unlike GNeRF, MELON is robust to high levels of noise and works with fewer images.


% In real-world scenarios like avatar or 3D object capture, cameras face the scene from a nearly fixed distance, making the rendered images essentially sensitive to the \sothree-component of the extrinsic camera parameters. The simplifying object-centric assumption therefore preserves the most challenging aspect of the pose inference problem in these scenarios. In radiography and microscopy, where rendered images are independent of the camera-to-object distance (orthographic projections), the 3D reconstruction problem from centered images is even identical to the one addressed in the paper.

% All competing techniques that reconstruct a neural field from unposed images operate in this object-centric setup, but require either a manual and time-consuming initialization of the camera poses \cite{wang2021nerf, lin2021barf, boss2022samurai} or a large number of images \cite{meng2021gnerf}, which are not always available. Some methods can learn small translations, but all methods remain biased by the object-centric prior. GNeRF, for example, samples camera positions on the surface of a sphere and ``lookat'' points within 0.1\% of the camera-to-object distance. VMRF~\cite{zhang2022vmrf} showed GNeRF quickly degrades if the images deviate too much from this object-centric prior. Noticeably, MELON is the only method capable of reconstructing challenging synthetic scenes like ``ship'', ``materials'' and  ``ficus'' (Table 1, Fig 4). Unlike GNeRF, MELON is robust to high levels of noise and works with fewer images.
%Importantly, MELON does not make any assumption regarding the symmetries of the unknown object, but rather leverages the quasi-symmetries of real-world objects.

% MELON solves the problem of unposed inverse neural rendering on \sothree with state-of-the-art accuracy and can therefore be seen as a necessary stepping stone to solving this problem on \sethree. Unlike structure from-motion-methods, which estimate the poses, we propose a method that directly reconstructs a neural radiance field from unposed images. As the reviewers pointed out, the object-centric assumption is strong and limits the deployment of the method to real scenarios. However, the only existing methods for training a NeRF from unposed RGB cameras, without any pre-training step, either require a coarse initialization of the poses (NeRF$\shortminus\shortminus$, BARF, GARF, SAMURAI…) or are limited in resolution and require a large number of images (GNeRF, VMRF). Adversarial approaches like GNeRF assume the dataset to be roughly centered and we show that these methods are outperformed by MELON. On challenging synthetic datasets like ship, materials and ficus, MELON is the only method capable of reconstructing the scene if the user does not provide any initial pose (Table1, Fig 4). Importantly, MELON does not make any assumption regarding the symmetries of the unknown object, but rather leverages the quasi-symmetries of real-world objects.

\vspace{1mm}
\textbf{(\RII) Fair Comparison to GNeRF}
Our comparison to GNeRF on the NeRF-Synthetic scenes is fair because GNeRF uses a known object-to-camera distance and no in-plane translation on this dataset.

\vspace{1mm}
\textbf{(\RII) Title} If requested, we can change the title to "MELON: NeRF with Unposed Images Using Equivalence Class Estimation \emph{in \sothree}" to avoid any misunderstanding of our problem domain.

\vspace{1mm}
\textbf{(\RI,\RIII) Mathematical Heaviness}
We will move the equations that are not directly used in the method to the supplement (Eq. 11 and 16). We propose to add Fig.~\ref{fig:region-of-attraction} to clarify the notion of region of attraction.

\vspace{1mm}
\textbf{(\RII) Regions of Attraction on \sothree}
Although we are able to give a formal definition to the regions of attraction for 3D rendering, it is not possible to show them in 2D, hence the simplifications made in Fig.3. In order to offer a deeper understanding of the regions of attraction, we will add Fig.~\ref{fig:region-of-attraction}.

\vspace{1mm}
\textbf{(\RII) Informal Phrases}
We will remove uses of the phrase “more/less non-convex” and will replace them with a reference to the fractional covering of the regions of attraction ($\mathcal{D}(f^*)$ and $\mathcal{D}_\mathcal{R}(f^*)$) when relevant.

\vspace{1mm}
\textbf{(\RII) COLMAP Error}
The high mean angular error of COLMAP on the Lego dataset is due to large errors on few images. The distribution of angular errors (Fig.~\ref{fig:histo-colmap-errors}) shows a large discrepancy between the median and the mean. We report the mean angular error for all methods as this is common practice in the field. For all experiments, we report the best numbers of COLMAP obtained after a hyperparameter search, as reported in Supp. B1.

\vspace{1mm}
\textbf{(\RIII) Comparison to NeRF}
``NeRF'' in Table 1 uses ground truth poses and is therefore not a fair comparison to MELON and GNeRF, and thus not bolded. We will make this clearer in the caption.

\textbf{(\RI) DeepVoxels} Thank you spotting the misleading reference to 63. We will clarify that DeepVoxels came before NeRF.

\begin{figure}[!h]
  \centering
  \includegraphics[width=0.6\linewidth]{fig/histo_colmap_errors.pdf}
   \caption{
   Histogram of angular errors obtained with COLMAP on the Lego dataset. 100 images rendered at $128\times128$.
   }
   \label{fig:histo-colmap-errors}
\end{figure}
\vspace{-4mm}

\vspace{-1mm}
\begin{figure}[!h]
  \centering
  \includegraphics[width=\linewidth]{fig/region_of_attraction_lego_so3_flat.pdf}
   \caption{
   Self-similarity map and region of attraction on the Lego scene for all azimuths and elevations, fixed in-plane roll and a fixed reference $z^*$.
   The self-similarity map shows the photometric distance to the reference image with respect to the rendering pose $z\in\Omega$. The region of attraction (green) is the set of poses that can be linked to $z^*$ with a continuous decreasing path in the latent space $\Omega$. The region of attraction covers all the quotient set $\Omega/\mathcal{R}$ when $\mathcal{R}=\mathcal{R}_2$.
   Images rendered at $64\times 64$.
   }
   \label{fig:region-of-attraction}
\end{figure}
\vspace{-4mm}

\renewcommand{\thepage}{}
{\footnotesize
\bibliographystyle{ieeetr}
\bibliography{rebuttalbib}
}

\end{document}


% We do not intend MELON to be a pose estimation technique competitive with SfM in all respects, but a step towards eliminating SfM pre-processing \mm{in} NeRF techniques \mm{by} \emph{jointly estimating} pose \emph{and} neural field without pre-training.

% \vspace{1mm}
% \textbf{(\RII) Limitations of GNeRF} GNeRF is a strongly \sothree-biased technique with minimal ability to learn deviations from the object-centric case. During the generative phase, camera locations are sampled on the surface of a sphere and the ``lookat'' points are either fixed to the origin or sampled within 0.1\% of the camera-to-object distance.
% VMRF showed GNeRF quickly degrades if the dataset is not consistent with this object-centric prior.

% We additionally illustrate examples where SfM fails, including low view numbers, and very high noise scenarios.
% We thank \RII~for their suggestion to compare with \emph{Bundler} and will do so in our camera ready version.

% Only in the third phase of training is the parameter space fully relaxed to allow translations. This only succeeds because of the pose estimates obtained in their first stages, which \emph{required} restriction to the known \sothree manifold.

% In order to make the comparison between MELON and GNeRF fair, we give the ground truth in-plane translations and camera-to-object distances to GNeRF. We will clearly indicate it in the text.

% We will make a clear separation between (A) the toy problem, (B) the mathematical definitions (C) the practical method that is implemented.

% \mm{We will clarify our presentation by removing equations not directly used in the method (Eq. 11 and 16), and clearly separate our explanation of the technique from its motivation.}
% We propose to add Fig.~\ref{fig:region-of-attraction} to clarify the notion of region of attraction.



