%% ============================= SMART PEN and AR ========================================

%% editing trajectories - pointing to add waypoitns, waypoints can be selected and moved, B-spline fitting of waypoints, geometric features can be defined by characteristic points.
@INPROCEEDINGS{Zaeh2007Interactive, 
author={M. F. {Zaeh} and W. {Vogl}}, 
booktitle={2006 IEEE/ACM International Symposium on Mixed and Augmented Reality}, 
title={Interactive laser-projection for programming industrial robots}, 
year={2006}, 
volume={}, 
number={}, 
pages={125-128}, 
keywords={augmented reality;data visualisation;industrial robots;robot programming;user interfaces;interactive laser-projection;industrial robot programming;augmented reality;interactive visualization;tool trajectory;target coordinate;virtual information;motion path;AR-based user interface;Robot programming;Service robots;Robot kinematics;Displays;Robotics and automation;Optical mixing;Data visualization;Augmented reality;Trajectory;User interfaces}, 
doi={10.1109/ISMAR.2006.297803}, 
ISSN={}, 
month={Oct},}

%%%% Projector + pen
@inproceedings{gaschler2014intuitive,
  title={Intuitive robot tasks with augmented reality and virtual obstacles},
  author={Gaschler, Andre and Springer, Maximilian and Rickert, Markus and Knoll, Alois},
  booktitle={Robotics and Automation (ICRA), 2014 IEEE International Conference on},
  pages={6026--6031},
  year={2014},
  organization={IEEE}}
  
@INPROCEEDINGS{notheis2012ar-based, 
author={S. {Notheis} and W. {August} and B. {Hein} and H. {Woern}}, 
booktitle={ROBOTIK 2012; 7th German Conference on Robotics}, 
title={AR-based Approach for Evaluation of new Model-based Control Algorithms}, 
year={2012}, 
volume={}, 
number={}, 
pages={1-5}, 
keywords={Mathematical model;Service robots;Load modeling;Cameras;Robot vision systems;Robot kinematics}, 
doi={}, 
ISSN={}, 
month={May},}

%% projector and input device, editing trajectories, interacting with menus, digitising object surfaces - making 3d models, additional video see through to visualise virtual model of robot kinematics and check colisions 
@INPROCEEDINGS{Reinhart2007projection-based, 
author={G. {Reinhart} and W. {Vogl} and I. {Kresse}}, 
booktitle={2007 IEEE Symposium on Virtual Environments, Human-Computer Interfaces and Measurement Systems}, 
title={A Projection-based User Interface for Industrial Robots}, 
year={2007}, 
volume={}, 
number={}, 
pages={67-71}, 
keywords={industrial robots;interactive video;optical tracking;user interfaces;industrial robot teaching;projection-based user interface;spatial user interface system;handheld stylus;active optical tracking system;laser projector;video beamer;free editing;drag-and-drop;3D spatial trajectory;workpiece surface;virtual menu;interactive collision geometry modeling;User interfaces;Service robots;Calibration;Probes;Educational robots;Education;Laser modes;Solid modeling;Geometry;Shape;Augmented Reality;Spatial User Interfaces;Human-Robot-Interaction}, 
doi={10.1109/VECIMS.2007.4373930}, 
ISSN={1944-9410}, 
month={June},}

%%% projector + tracked input device for robot welding
@article{REINHART2008programing,
title = "A programming system for robot-based remote-laser-welding with conventional optics",
journal = "CIRP Annals",
volume = "57",
number = "1",
pages = "37 - 40",
year = "2008",
issn = "0007-8506",
doi = "https://doi.org/10.1016/j.cirp.2008.03.120",
url = "http://www.sciencedirect.com/science/article/pii/S0007850608000917",
author = "G. Reinhart and U. Munzert and W. Vogl",
keywords = "Robot, Programming, Remote-laser-welding"
}

%%%% static + end-effector mounted projector, mostly to show robot paths, some discussion of tracked  input device 
@inproceedings{Leutert2013,
 author = {Leutert, Florian and Herrmann, Christian and Schilling, Klaus},
 title = {A Spatial Augmented Reality System for Intuitive Display of Robotic Data},
 booktitle = {Proceedings of the 8th ACM/IEEE International Conference on Human-robot Interaction},
 series = {HRI '13},
 year = {2013},
 isbn = {978-1-4673-3055-8},
 location = {Tokyo, Japan},
 pages = {179--180},
 numpages = {2},
 url = {http://dl.acm.org/citation.cfm?id=2447556.2447626},
 acmid = {2447626},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
 keywords = {augmented reality, human-robot-interaction, manipulators, robotic interfaces},
} 


%% ============================ WORK of IPR ================================================

%% Dennis milling
@INPROCEEDINGS{hartmann2019machining,
  author={D. {Hartmann} and M. {Mende} and D. {Štogl} and B. {Hein} and T. {Kröger}},
  booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Robot-Based Machining of Unmodeled Objects via Feature Detection in Dense Point Clouds}, 
  year={2019},
  volume={},
  number={},
  pages={7777-7783},
  doi={10.1109/IROS40897.2019.8968060}}
  
%% Björn input
@INPROCEEDINGS{hein2009intuitive,
  author={B. {Hein} and H. {Wörn}},
  booktitle={2009 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={Intuitive and model-based on-line programming of industrial robots: New input devices}, 
  year={2009},
  volume={},
  number={},
  pages={3064-3069},
  doi={10.1109/IROS.2009.5354824}}



%% ============================ MY Work ====================================================

%% Mapping and octomapping
@INPROCEEDINGS{puljiz2020hololens,
  author={D. {Puljiz} and F. {Krebs} and F. {B{\"o}sing} and B. {Hein}},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={What the HoloLens Maps Is Your Workspace: Fast Mapping and Set-up of Robot Cells via Head Mounted Displays and Augmented Reality}, 
  year={2020},
  volume={},
  number={},}


%% =========================== Other AR ====================================================

@INPROCEEDINGS{Quintero2018ARProg, 
author={C. P. Quintero and S. Li and M. K. Pan and W. P. Chan and H. F. Machiel Van der Loos and E. Croft}, 
booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
title={Robot Programming Through Augmented Trajectories in Augmented Reality}, 
year={2018}, 
volume={}, 
number={}, 
pages={1838-1844}, 
keywords={Task analysis;Trajectory;Service robots;Visualization;End effectors}, 
doi={10.1109/IROS.2018.8593700}, 
ISSN={2153-0866}, 
month={Oct},}

%% ============================= Misc ===========================================

@article{schraft2006need,
  title={The need for an intuitive teaching method for small and medium enterprises},
  author={Schraft, Rolf Dieter and Meyer, Christian},
  journal={VDI BERICHTE},
  volume={1956},
  pages={95},
  year={2006},
  publisher={VDI; 1999}
}


@ARTICLE{Alexa2003MLS, 
author={M. {Alexa} and J. {Behr} and D. {Cohen-Or} and S. {Fleishman} and D. {Levin} and C. T. {Silva}}, 
journal={IEEE Transactions on Visualization and Computer Graphics}, 
title={Computing and rendering point set surfaces}, 
year={2003}, 
volume={9}, 
number={1}, 
pages={3-15}, 
keywords={rendering (computer graphics);image reconstruction;rendering;moving least squares;point sample rendering;3D acquisition;point sets;smooth manifold surface;computer graphics;representation;differential geometry;Least squares approximation;Multilevel systems;Strontium;Shape;Geometry;Approximation error;Displays;Rendering (computer graphics);Sampling methods;Error correction}, 
doi={10.1109/TVCG.2003.1175093}, 
ISSN={2160-9306}, 
month={Jan},}




%%%%%%%%%%% ALEX THESIS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{Ribo2001StateOT,
  title={State of the Art Report on Optical Tracking},
  author={Miguel Ribo},
  year={2001}
}

@mastersthesis{TUW-210294,
    author = {Mehling, Michael},
    title = {Implementation of a Low Cost Marker Based Infrared Light Optical Tracking System},
    school = {Institute for Software Technology {\&} Interactive Systems},
    year = {2006},
    
}

@inproceedings{Schwald2005ATA,
  title={A Tracking Algorithm for Rigid Point-Based Marker Models},
  author={B. Schwald},
  year={2005}
}

@article{article,
author = {Horn, Berthold and Hilden, Hugh and Negahdaripour, Shahriar},
year = {1988},
month = {07},
pages = {1127-1135},
title = {Closed-Form Solution of Absolute Orientation using Orthonormal Matrices},
volume = {5},
journal = {Journal of the Optical Society of America A},
doi = {10.1364/JOSAA.5.001127}
}

@inproceedings{Horn1986ClosedformSO,
  title={Closed-form solution of absolute orientation using uni t quaternions},
  author={B. Horn},
  year={1986}
}

@ARTICLE{4767965,
  author={K. S. {Arun} and T. S. {Huang} and S. D. {Blostein}},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Least-Squares Fitting of Two 3-D Point Sets}, 
  year={1987},
  volume={PAMI-9},
  number={5},
  pages={698-700}
 }
 
 @article{Umeyama1991LeastSquaresEO,
  title={Least-Squares Estimation of Transformation Parameters Between Two Point Patterns},
  author={S. Umeyama},
  journal={IEEE Trans. Pattern Anal. Mach. Intell.},
  year={1991},
  volume={13},
  pages={376-380}
}

@article{c0ae9ca782784f238570e1fc0c232744,
title = "A procedure for determining rigid body transformation parameters",
abstract = "For many biomechanical applications it is necessary to determine the parameters which describe the transformation of a rigid body from one reference frame to another. These parameters are a scaling factor, an attitude matrix, and a translation vector. The paper presents a new procedure for the determination of these parameters incorporating the work of Arun et al. [IEEE Trans. Pattern Anal. Machine Intell, 9, 698-700 (1987)] but expanding their analysis to allow for the determination of a scale factor, the scalar weighting of the least-squares problem, and the problem of obtaining the incorrect determinant when determining the attitude matrix. The procedure, which requires the coordinates of three or more noncollinear points, is based around the singular value decomposition, and provides a least-squares estimate of the rigid body transformation parameters. Examples are presented of the use of this procedure for determining the attitude of a rigid body, and for osteometric scaling. When used for osteometric scaling mirror transformations are possible, therefore a right-hand specimen can be scaled to the left-hand side of another specimen.",
author = "Challis, {John H.}",
year = "1995",
month = jun,
doi = "10.1016/0021-9290(94)00116-L",
language = "English (US)",
volume = "28",
pages = "733--737",
journal = "Journal of Biomechanics",
issn = "0021-9290",
publisher = "Elsevier Limited",
number = "6",
}

@ARTICLE{291441,
  author={K. {Kanatani}},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Analysis of 3-D rotation fitting}, 
  year={1994},
  volume={16},
  number={5},
  pages={543-549}
 }
 
 
@article{doi:10.1162/pres.1997.6.4.355,
author = {Azuma, Ronald T.},
title = {A Survey of Augmented Reality},
journal = {Presence: Teleoperators and Virtual Environments},
volume = {6},
number = {4},
pages = {355-385},
year = {1997},
doi = {10.1162/pres.1997.6.4.355},

URL = { 
        https://doi.org/10.1162/pres.1997.6.4.355
    
},
eprint = { 
        https://doi.org/10.1162/pres.1997.6.4.355
    
}
,
    abstract = { This paper surveys the field of augmented reality (AR), in which 3D virtual objects are integrated into a 3D real environment in real time. It describes the medical, manufacturing, visualization, path planning, entertainment, and military applications that have been explored. This paper describes the characteristics of augmented reality systems, including a detailed discussion of the tradeoffs between optical and video blending approaches. Registration and sensing errors are two of the biggest problems in building effective augmented reality systems, so this paper summarizes current efforts to overcome these problems. Future directions and areas requiring further research are discussed. This survey provides a starting point for anyone interested in researching or using augmented reality. }
}

@article{Carmigniani2010AugmentedRT,
  title={Augmented reality technologies, systems and applications},
  author={Julie Carmigniani and B. Furht and M. Anisetti and P. Ceravolo and E. Damiani and Misa Ivkovic},
  journal={Multimedia Tools and Applications},
  year={2010},
  volume={51},
  pages={341-377}
}

@article{azumaRecentAdvances,
author = {Azuma, Ronald and Baillot, Yohan and Behringer, Reinhold and Feiner, Steven and Julier, Simon and Macintyre, Blair},
year = {2001},
month = {12},
pages = {34 - 47},
title = {Recent advances in augmented reality. IEEE Comput Graphics Appl},
volume = {21},
journal = {Computer Graphics and Applications, IEEE},
doi = {10.1109/38.963459}
}
@article{Shrestha_Accommodation-Free,
author = {Shrestha, Pawan and Pryn, Matt and Jia, Jia and Chen, Jhen-Si and Fructuoso, Hector and Boev, Atanas and Zhang, Qing and Chu, Daping},
year = {2019},
month = {08},
pages = {1-9},
title = {Accommodation-Free Head Mounted Display with Comfortable 3D Perception and an Enlarged Eye-box},
volume = {2019},
journal = {Research},
doi = {10.34133/2019/9273723}
}

@INPROCEEDINGS{6907747,  author={A. {Gaschler} and M. {Springer} and M. {Rickert} and A. {Knoll}},  booktitle={2014 IEEE International Conference on Robotics and Automation (ICRA)},   title={Intuitive robot tasks with augmented reality and virtual obstacles},   year={2014},  volume={},  number={},  pages={6026-6031},}

@inproceedings{inproceedings,
author = {Hanses, Magnus and Behrens, Roland and Elkmann, Norbert},
year = {2016},
month = {09},
pages = {},
title = {Hand-guiding robots along predefined geometric paths under hard joint constraints},
doi = {10.1109/ETFA.2016.7733600}
}

@inproceedings{Real-time-hand-guiding,
author = {Moe, Signe and Schjølberg, Ingrid},
year = {2013},
month = {08},
pages = {644-649},
title = {Real-time hand guiding of industrial manipulator in 5 DOF using Microsoft Kinect and accelerometer},
journal = {Proceedings - IEEE International Workshop on Robot and Human Interactive Communication},
doi = {10.1109/ROMAN.2013.6628421}
}

@article{Human-direct-teaching-of-industrial,
author = {Kushida, Daisuke and Nakamura, Masatoshi and Goto, Satoru and Kyura, Nobuhiro},
year = {2001},
month = {03},
pages = {26-32},
title = {Human direct teaching of industrial articulated robot arms based on force-free control},
volume = {5},
journal = {Artificial Life and Robotics},
doi = {10.1007/BF02481317}
}

@article{a-survey-of-robot-programming,
author = {Biggs, Geoffrey and Macdonald, Bruce},
year = {2004},
month = {01},
pages = {},
title = {A Survey of Robot Programming Systems}
}

@INPROCEEDINGS{5756855,  author={Z. {Pan} and J. {Polden} and N. {Larkin} and S. V. {Duin} and J. {Norrish}},  booktitle={ISR 2010 (41st International Symposium on Robotics) and ROBOTIK 2010 (6th German Conference on Robotics)},   title={Recent Progress on Programming Methods for Industrial Robots},   year={2010},  volume={},  number={},  pages={1-8},}

@INPROCEEDINGS{924423,  author={S. {Rusinkiewicz} and M. {Levoy}},  booktitle={Proceedings Third International Conference on 3-D Digital Imaging and Modeling},   title={Efficient variants of the ICP algorithm},   year={2001},  volume={},  number={},  pages={145-152},}

@inproceedings{shoemake1985animating,
  title={Animating rotation with quaternion curves},
  author={Shoemake, Ken},
  booktitle={Proceedings of the 12th annual conference on Computer graphics and interactive techniques},
  pages={245--254},
  year={1985}
}

@misc{bworld,
  author = {Microsoft},
  title = {{HoloLensForCv}},
  howpublished = "\url{https://github.com/microsoft/HoloLensForCV}",
  year = {2017}, 
  note = "[Online; accessed 24-September-2020]"
}

@inproceedings{rospaper,
author = {Quigley, Morgan and Conley, Ken and Gerkey, Brian and Faust, Josh and Foote, Tully and Leibs, Jeremy and Wheeler, Rob and Ng, Andrew},
year = {2009},
month = {01},
pages = {},
title = {ROS: an open-source Robot Operating System},
volume = {3},
journal = {ICRA Workshop on Open Source Software}
}

https://github.com/MicrosoftDocs/mixed-reality/blob/5b32451f0fff3dc20048db49277752643118b347/mixed-reality-docs/locatable-camera.md

@misc{locatableCamera,
  author = {Microsoft},
  title = {{Locatable Camera}},
  howpublished = "\url{https://github.com/MicrosoftDocs/mixed-reality/blob/5b32451f0fff3dc20048db49277752643118b347/mixed-reality-docs/locatable-camera.md}",
  year = {2019}, 
  note = "[Online; accessed 24-September-2020]"
}

@misc{eigenlib,
  title = {{Eigen Library}},
  howpublished = "\url{https://gitlab.com/libeigen/eigen}",
  note = "[Online; accessed 24-September-2020]"
}

@misc{redsvd,
  title = {{RedSVD}},
  howpublished = "\url{https://code.google.com/archive/p/redsvd/}",
  note = "[Online; accessed 24-September-2020]"
}

@misc{rosbridge,
  title = {{ rosbridge suite}},
  howpublished = "\url{http://wiki.ros.org/rosbridge_suite}",
  note = "[Online; accessed 24-September-2020]"
}

@thesis{katharina2018,
    author = {Riesterer, Katharina},
    title = {{Towards automatic high-precision referencing between a robot and an augmented reality device}},
    year = {2018},
    type = {Bachelor's Thesis}
}

@INPROCEEDINGS{8917159,  author={T. {Kirks} and J. {Jost} and T. {Uhlott} and J. {Püth} and M. {Jakobs}},  booktitle={2019 IEEE Intelligent Transportation Systems Conference (ITSC)},   title={Evaluation of the Application of Smart Glasses for Decentralized Control Systems in Logistics},   year={2019},  volume={},  number={},  pages={4470-4476},  doi={10.1109/ITSC.2019.8917159}}


@InProceedings{francois2011handprecision,
author="B{\'e}rard, Fran{\c{c}}ois
and Wang, Guangyu
and Cooperstock, Jeremy R.",
editor="Campos, Pedro
and Graham, Nicholas
and Jorge, Joaquim
and Nunes, Nuno
and Palanque, Philippe
and Winckler, Marco",
title="On the Limits of the Human Motor Control Precision: The Search for a Device's Human Resolution",
booktitle="Human-Computer Interaction -- INTERACT 2011",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="107--122",
abstract="Input devices are often evaluated in terms of their throughput, as measured by Fitts' Law, and by their resolution. However, little effort has been made to understand the limit of resolution that is controllable or ``usable'' by the human using the device. What is the point of a 5000 dpi computer mouse if the human motor control system is far from being able to achieve this level of precision? This paper introduces the concept of a Device's Human Resolution (DHR): the smallest target size that users can acquire with an ordinary amount of effort using one particular device. We report on our attempt to find the DHR through a target acquisition experiment involving very small target sizes. Three devices were tested: a gaming mouse (5700 dpi), a PHANTOM (450 dpi), and a free-space device (85 dpi). The results indicate a decrease in target acquisition performance that is not predicted by Fitts' Law when target sizes become smaller than certain levels. In addition, the experiment shows that the actual achievable resolution varies greatly depending on the input device used, hence the need to include the ``device'' in the definition of DHR.",
isbn="978-3-642-23771-3"
}
