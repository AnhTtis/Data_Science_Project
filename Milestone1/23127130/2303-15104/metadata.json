{
    "arxiv_id": "2303.15104",
    "paper_title": "Generalizable Local Feature Pre-training for Deformable Shape Analysis",
    "authors": [
        "Souhaib Attaiki",
        "Lei Li",
        "Maks Ovsjanikov"
    ],
    "submission_date": "2023-03-27",
    "revised_dates": [
        "2023-03-28"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "Transfer learning is fundamental for addressing problems in settings with little training data. While several transfer learning approaches have been proposed in 3D, unfortunately, these solutions typically operate on an entire 3D object or even scene-level and thus, as we show, fail to generalize to new classes, such as deformable organic shapes. In addition, there is currently a lack of understanding of what makes pre-trained features transferable across significantly different 3D shape categories. In this paper, we make a step toward addressing these challenges. First, we analyze the link between feature locality and transferability in tasks involving deformable 3D objects, while also comparing different backbones and losses for local feature pre-training. We observe that with proper training, learned features can be useful in such tasks, but, crucially, only with an appropriate choice of the receptive field size. We then propose a differentiable method for optimizing the receptive field within 3D transfer learning. Jointly, this leads to the first learnable features that can successfully generalize to unseen classes of 3D shapes such as humans and animals. Our extensive experiments show that this approach leads to state-of-the-art results on several downstream tasks such as segmentation, shape correspondence, and classification. Our code is available at \\url{https://github.com/pvnieo/vader}.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.15104v1"
    ],
    "publication_venue": "16 pages, 14 figures, 7 tables, to be published in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
}