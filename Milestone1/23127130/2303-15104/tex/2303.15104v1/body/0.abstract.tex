%V1
\begin{abstract}
Transfer learning is fundamental for addressing problems in settings with little training data. While several transfer learning approaches have been proposed in 3D, unfortunately, these solutions typically operate on an entire 3D object or even scene-level and thus, as we show, fail to generalize to new classes, such as deformable organic shapes. In addition, there is currently a lack of understanding of what makes pre-trained features transferable across significantly different 3D shape categories. In this paper, we make a step toward addressing these challenges. First, we analyze the link between feature locality and transferability in tasks involving deformable 3D objects, while also comparing different backbones and losses for local feature pre-training. We observe that with proper training, learned features \emph{can be} useful in such tasks, but, crucially, only with an appropriate choice of the receptive field size. We then propose a differentiable method for optimizing the receptive field within 3D transfer learning. Jointly, this leads to the first learnable features that can successfully generalize to unseen classes of 3D shapes such as humans and animals. Our extensive experiments show that this approach leads to state-of-the-art results on several downstream tasks such as segmentation, shape correspondence, and classification. Our code is available at  \url{https://github.com/pvnieo/vader}.
\end{abstract}	
	
% V0
%\begin{abstract}
%	Transfer learning is a fundamental tool that allows to the application of learning-based solutions in settings with relatively little training data. While some works have considered transfer learning for \emph{rigid} 3D geometry, little work has been done in developing general-purpose solutions capable of handling \emph{non-rigid} organic shapes. In this paper, we make the first step in this direction. Our key insight is that while \emph{global} shape or scene-level features do not generalize well to deformable shape tasks, it is possible to pre-train informative and robust \emph{local} feature extractors that are applicable to a wide range of non-rigid shape categories. Interestingly, we show that pre-training local features on a rich dataset of rigid real-world scenes leads to powerful features that generalize to completely unseen classes of 3D shapes such as humans and animals. Through extensive experiments, we show that our local feature pre-training achieves state-of-the-art results on several non-rigid tasks such as segmentation, shape correspondence, and classification. \rev{To revise}
%\end{abstract}
