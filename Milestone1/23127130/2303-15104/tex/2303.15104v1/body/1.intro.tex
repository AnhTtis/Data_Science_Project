\section{Introduction}
\label{sec:intro}

Extracting informative representations from 3D geometry is a central task in Computer Vision, Computer Graphics, and related fields. Classical approaches have relied on hand-crafted features derived from basic geometric principles \cite{johnson1999using,belongie2000shape,pottmann2009integral,sun2009concise,aubry2011wave}.
More recently, the focus has shifted towards data-driven approaches that learn features directly from 3D data  \cite{guo2020deep,cao2020comprehensive,bronstein2017geometric} in a task-specific manner.

In addition to methods that learn features from scratch for each application, several recent works have also advocated for general-purpose \textit{representation learning} on geometric data \cite{xie2020pointcontrast,hou2020exploring,wang2021unsupervised}. Inspired by the success of transfer learning in other domains \cite{zhuang2020comprehensive}, these methods aim to learn informative representations of 3D data, which can then be exploited in data-limited downstream tasks. 

\input{body/figure_teaser}

Despite this progress, state-of-the-art architectures in \emph{deformable shape analysis} still either rely on classical hand-crafted features as input signals to their learning pipelines \cite{monti2017geometric,poulenard2018multi,litany2017deep,sharp2020diffusionnet}, or are trained \textit{from scratch} for each task \cite{groueix20183d,donati2020deep,li2020shape}, thus requiring significant amounts of labeled data. Unfortunately, as we demonstrate in our work, existing 3D representation learning approaches fail to provide a useful signal in tasks that involve highly deformable shapes, such as  shape correspondence or segmentation.

This result is perhaps expected since existing approaches have primarily focused on transfer learning across man-made 3D objects or scenes \cite{xiao2022unsupervised}, and are typically restricted to settings with significant domain overlap between training and test data. Furthermore, there is currently a lack of understanding of what makes pre-trained features transferable, especially across significantly different shape classes.

 %Thus, there is lack of \textit{general-purpose pre-trainable} feature extractors that would enable transfer learning and task-specific fine-tuning in deformable shape analysis.
% Unfortunately, both the lack of a canonical representation for 3D shapes and the scarcity of labeled data have so far prevented 

%This is in sharp contrast to modern image-based approaches that rely on strong generic feature extractors, trained, e.g., for image classification tasks \cite{simonyan2014very,he2016deep} or via contrastive learning \cite{he2020momentum}. The existence of such powerful pre-trained networks has enabled a myriad of applications, because (1) they provide robust and informative summary of image content, going well-beyond previous hand-crafted features, and (2) they allow transfer learning across diverse datasets. 

\input{body/figure_pipeline}


In this work, we aim to investigate the transferability of geometric features to develop representation learning approaches that are useful in downstream deformable shape analysis tasks, such as non-rigid shape matching and semantic segmentation (see \cref{fig:teaser}). Taking inspiration from recent studies that emphasize the importance of low and mid-level features in enabling 2D transfer learning \cite{matsoukas2022makes,zhao2021what}, we explore the impact of feature locality on downstream task accuracy across significantly different 3D shape categories. Our study shows that, with a carefully chosen architecture, successful general-purpose representation learning for deformable 3D shape analysis is possible. We also find that the receptive field (or local support) size plays a crucial role in the transferability of features and needs to be adapted between training and test data. To address this, we propose a receptive field optimization strategy, which, combined with a specific pre-training approach, leads to state-of-the-art results on a wide range of downstream tasks. An overview of our proposed method can be found in \cref{fig:pipeline}.


% In this work, we delve into the question of transferability of geometric features with the goal of developing representation learning approaches useful in downstream deformable shape analysis tasks, such as non-rigid shape matching, see \cref{fig:teaser}. Taking inspiration from recent studies that highlight the utility of low and mid-level features in enabling 2D transfer learning \cite{matsoukas2022makes,zhao2021what}, we investigate the impact of \emph{feature locality} on downstream task accuracy across significantly different 3D shape categories. As a result of this study, we find that with a carefully-chosen architecture, successful general-purpose representation learning is possible for deformable 3D shape analysis. At the same time, we observe the crucial importance of the receptive field size that needs to be adapted between training and test data. We thus propose \textit{a receptive field optimization} strategy, which, jointly with a specific pre-training strategy leads to state-of-the-art results on a wide range of downstream tasks, see \cref{fig:pipeline} for an overview of our proposed method.

%However, deformable shape analysis often deals with highly diverse but relatively small datasets of 3D shapes, such as scans of RNA molecules \cite{poulenard2019effective} or humans in motion \cite{Anguelov2005}, among many others (\cref{fig:teaser}).
%Although the prior feature pre-training approaches, like PointContrast \cite{xie2020pointcontrast}, demonstrate noticeable improvement to 3D scene analysis tasks, we find that they fail to generalize well to downstream highly-deformable shape tasks.




To summarize, our main contributions are as follows:
\begin{enumerate}[topsep=3pt,partopsep=3pt,itemsep=3pt,parsep=0pt]
    \item We investigate the link between the locality of geometric (3D) features and their transferability in challenging deformable shape tasks.
    \item We build upon the investigation and propose a novel method for optimizing the receptive field size of local features in the context of transfer learning in 3D tasks. We demonstrate that this optimization brings significant improvement and allows pre-trainable features to generalize well to unseen data in downstream tasks.
    \item We show that pre-training local features with an unsupervised cycle consistency loss outperforms the standard contrastive PointInfoNCE loss.
    \item Based on all of these insights, we propose a new local feature pre-training mechanism and show its utility in a wide range of tasks involving deformable objects, going beyond man-made objects or scenes considered in previous 3D transfer learning approaches.
\end{enumerate}
