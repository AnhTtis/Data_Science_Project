\section{Motivation}
\label{sec:motivation}

Our main objective is to build a general-purpose feature extractor that can be applied to highly deformable shape analysis tasks, such as matching human shapes or segmentation of molecular surfaces, among others.
We first examine existing designs of geometric feature pre-training and perform a pilot study to understand their generalization power in such  tasks.
Our key insight is that the \textit{locality} of geometric features plays a crucial role in their transferability across different categories, which has so far been overlooked in prior works. To this end, we first perform an in-depth analysis of feature locality versus transferability in a representative deformable shape matching task. 

\mypara{Revisiting PointContrast.}
PointContrast \cite{xie2020pointcontrast} is a recent feature pre-training framework, in which a geometric feature extractor is pre-trained by a pretext task involving correspondences on 3D scenes \cite{dai2017scannet} related by rigid motion.
Specifically, PointContrast uses a fully-convolutional sparse U-Net \cite{choy2019fully} to output a feature vector for every point in the input.
During pre-training, given two scene fragments, a contrastive PointInfoNCE loss is used to minimize the feature distance for corresponding points and maximize it for non-corresponding ones:
\begin{equation}
    \label{eq:NCELoss}
    \mathcal{L}_{\text{nce}} = - \sum_{(i,j) \in \Omega} \log \dfrac{\exp(\mathbf{f}_i \cdot \mathbf{f}_j / \tau)}{\sum_{(\cdot, k) \in \Omega} \exp(\mathbf{f}_i \cdot \mathbf{f}_k / \tau)},
\end{equation}
where $\Omega$ is the set of corresponding point pairs in the overlap region, $\mathbf{f}_{\square}$ denotes the learned point-wise feature vector, and $\tau$ is a temperature hyper-parameter.

\mypara{Pilot study on deformable shapes.}
We study the link between the locality of geometric features and their transferability through the lens of a downstream deformable shape matching task \cite{roufosse2019unsupervised,halimi2019unsupervised,eisenberger2020deep,donati2020deep,sharma2020weakly}.
Specifically, we leverage a widely-used human shape dataset, FAUST-Remeshed (FR) \cite{Ren2019,Bogo2014}, consisting of 100 humans in diverse poses.
Given a pair of 3D shapes as input, we first use pre-trained feature extractors to compute a feature vector for every point in the input.
We then find correspondences via nearest neighbor search between the extracted features and apply a lightweight refinement with ZoomOut \cite{Melzi_2019}, a common practice in prior works.
We use the standard mean geodesic error \cite{Kim2011} as the evaluation metric.
Note that there is no fine-tuning of network weights, and thus this study provides a good indication of how informative and transferable the pre-trained features are in downstream applications.

\input{body/figure_locality_vs_transferability}

\mypara{Feature locality vs. transferability.}
We evaluated the features produced by PointContrast in this context and obtained a matching error of \textbf{28.7}, compared to \textbf{6.1} achieved by a recent axiomatic method \cite{ren2018continuous}.  
%We first test PointContrast features on FR and obtain a matching error of \textbf{28.7} \maks{add some number for reference? compared e.g., to 2.7 reported in X (citation). or maybe compared to 30 obtained simply via random matching. we can't just use a number without any comparison.}, which shows their lack of utility for deformable shapes.
%
We attribute this limited utility of PointContrast features for deformable shapes to the global structure of its network, which employs a fully-convolutional U-Net design. Furthermore, this network is trained on entire 3D scenes with a global receptive field, making it significantly less likely to generalize to unseen shape categories.

To address this issue, we propose to limit the receptive field size and pre-train feature extractors \textit{that take as input only a local patch centered at each point}, and output a feature vector for the center point (\cref{fig:pipeline}). Intuitively, the space of local patches is significantly smaller than the space of shapes, thus potentially enabling generalization across different shape categories \cite{surfacerec07,patchnet2020,chabra2020,ao2021spinnet,pcpnet2018,fujiwara2011locally}.

To evaluate this general approach, we select three different architectures for pre-training a local feature extractor:
a) SparseConv \cite{choy20194dminkski,xie2020pointcontrast}, a sparse tensor-based network, which also constitutes the backbone of PointContrast;
b) PCPNet \cite{pcpnet2018,qi2017pointnet}, a PointNet-based architecture; 
and c) 3D CNN \cite{gojcic2019perfect,li2021updesc}, operating on voxel grids.
%We pre-train these feature extractors with the PointInfoNCE loss on 3D scene data \cite{zeng20173dmatch} in a similar manner as PointContrast.
%For completeness, we also include SHOT \cite{tombari2010unique}, a hand-crafted feature on 3D shapes.
We then pre-train these local feature extractors for \textit{the rigid alignment task} on 3D man-made scenes \cite{zeng20173dmatch}, following a similar strategy as in PointContrast. We follow the standard design choices and optimal pre-training patch size as used in the existing literature. Please see the exact architectures and pre-training details in the supplementary.

Given these pre-trained local feature extractors, a natural question would be how to adapt the receptive field (patch) size between pre-training and downstream 3D data, which may consist of significantly different shape classes, to make the local feature extractors generalize well. For this, we test a wide range of receptive field sizes (as ratios of the pre-training one) and plot their corresponding matching performance on FR in \cref{fig:locality_vs_transferability}.

When comparing PointContrast and Local SparseConv in \cref{fig:locality_vs_transferability}, we observe that making the network \textit{local} and operating on patches significantly improves feature transferability, especially for some specific receptive field size in this downstream task. Moreover, we observe that Local 3D CNN has the best generalization performance on FR, compared to Local SparseConv and Local PCPNet.

Most importantly, this pilot study highlights the importance of feature locality and the crucial role that the optimal receptive field size plays in the downstream task for successful transfer learning.
In practice, performing an exhaustive search of receptive field sizes is typically infeasible. To address this issue, we propose a differentiable approach to feature locality optimization for downstream 3D geometric data (\cref{subsec:local_feature_transfer}). 
