\vspace{0.16cm}
\section{Introduction}
\subsection{Motivation}
Human error has been proven to be one of the main causes of accidents in public driving with a share of over $\unit[90]{\%}$. The remaining $\unit[10]{\%}$ of the crashes happen because of technical vehicle failure or bad weather conditions. According to the World Health Organization (WHO)~\cite{who2004}, drivers encounter particularly difficult situations due to:
\begin{itemize} %enumerate
 \item Inexperience, recklessnes and fatigue which leads to violating the recommended speed or having inappropriate distances to the roadside and other cars.
 \item A limited field of view (sometimes caused by environmental objects, i.e., trees or buildings) which results in failing to see the point of interest. The reaction time for suddenly appearing obstacles can thus be critical. 
 \item Incapability to estimate the behavior of other participants. The deviation of the real situation and resulting ego action may generate unavoidable collisions.
\end{itemize}

During recent years, Advanced Driver Assistance Systems (ADAS) were developed to take over certain tasks in the control of the car. In total, about $\unit[33]{\%}$ of the occuring crashes represent single-vehicle events, $\unit[27]{\%}$ often correspond to longitudinal following or lane changes and $\unit[40]{\%}$ occur in intersection areas~\cite{nhtsa2008}.  
ADAS can already succesfully tackle the first and second category events with e.g. anti-lock braking systems, electronic stability control, adaptive cruise control and lane keeping assistance. However for general intersections, solutions are limited and no holistic ADAS is comercially available yet. Often, collision mitigation systems~\cite{bengler2014} simply execute an emergency braking shortly before an obstacle is crossing. More proactive ADAS are needed to prepare the driver in advance for different hazards arising from urban traffic.  

For this purpose, we present the so-called Risk Navigation System (RNS). RNS is based on a local dynamic map that serves as a central hub for road data and sensor measurements. We reduce the complexity of intersection scenarios by extracting relevant possible paths within a virtual horizon, regulatory objects (e.g. stop line, crosswalk and traffic light) as well as vehicle interaction zones (like junction areas and point of closest encounters with other cars). 
Consequently, Time-To-X indicators are employed to detect critical future situations and to recommend a safe behavior. 

If the user does not behave in a risk-appropriate way, RNS displays warnings that convey both the positional and temporal information related to the encountered risks. In real-time recordings combining GNSS\footnote{Accepted term for Global Navigation Satellite System (GPS, Galileo, GLONASS, etc.).} and lidar, we show that RNS is effective in analyzing and visualizing collision, curve and regulatory risk. Awareness and prediction abilities of the driver are improved. In Figure \ref{fig:blockdiagram}, the pipeline of the realized system is given. In this paper, our focus with RNS lies on the boxes indicated in blue.

\begin{figure}
  \centering
  \resizebox{\linewidth}{!}{
  \import{img/}{rns_block_diagram.pdf_tex}}
  \caption{Concept of the Risk Navigation System (RNS), designed for driver support at general intersections.}%Note: The pre-processing is not handled in this paper.}
  %schlange weg und namen direkt unter bloecken
  \vspace*{-0.15cm}
  \label{fig:blockdiagram} %Non-dashed lines are inputs or outputs and the dashed lines embody queries on the map. 
\end{figure} 

The remainder of the paper is structured as follows. First, related scientific work for risk warning is summarized with section \ref{sec:rel}. Afterwards, we explain our methods in detail in sections \ref{sec:riskextr} and \ref{sec:visrisk}. Central addressed topics are the storage, filtering and visualization of risk information using the local dynamic map. With section \ref{sec:fite}, the application of RNS and qualitative outputs are shown. Finally, we give a conclusion and outlook for future work in section \ref{sec:outl}.

\subsection{Related Work}
\label{sec:rel}
Communication of risks is a complex task. Traffic situations have high uncertainty and variability of how they might develop. 
On the one hand, a proper Human-Machine Interface (HMI) is required to provide sufficient context information around the ego vehicle (e.g. risk source or collision severity). On the other hand, driving risks lie in the range of seconds and need to be understood in a fast way. The HMI should be clear, intuitive and easily interpretable~\cite{eppler2008}. 
According to \cite{knoll2007}, the underlying three steps for associated warning systems consist of a) retrieval of risk indicators from sensors and maps, b) comparison of actual versus planned behavior and c) on demand application of HMI modalities in visual, audio or tactile form. 

Traffic risk extraction is commonly achieved with the help of outside sensors (camera, lidar and radar). Exemplarily, the authors of~\cite{messelodi2008} identify construction signs and vehicles in a front-mounted camera. For headway control or crash warning, \cite{gat2005} compute thereof distance and Time-To-Collision (TTC). Fusing camera with radar allows the reduction of noise in the object velocity estimation. 
Both approaches act in a relative coordinate system, while all inputs are received on-the-fly. 
In contrast, ego sensors (e.g. a GNSS plus intertial measurement unit) can be aligned in a global reference frame for leveraging map data. A real-time setup is shown in~\cite{nexyad2019}. Their HMI displays pop-up symbols from tagged speed limits or occluded crosswalks. Similarly, \cite{pu2015} employ road-level but calculate the curvature of the street for saving up fuel via an engine management. 
%\footnote{Generally accepted abbreviation for Global Navigation System Satellite and Inertial Measurement Unit.}

The RNS as proposed in this work relies on a relational local dynamic map that concurrently combines GNSS with lidar sensors. Effective retrieval of relevant risk sources from paths, traffic signs or vehicles is ensured with a graph instead of table database. For more literature about local dynamic maps, risk estimation or motion planning, please refer to \cite{ldm2017}, \cite{puphal2019} and \cite{puphal2018}. 

While most ADAS apply various visual monitors, audible and tactile actuators are still a topic of research. In \cite{alves2008}, a head-up display is enhanced by sound to shorten the response time of drivers. On top of that, \cite{dettmann2016} investigate light strips for spatially distant information and alarms for immanent critical entities. Concerning navigation devices, tactile impulses on a car seat~\cite{chang2011} can be applied in turning maneuvers, or mobile belts~\cite{krueger2018} vibrate according to the relative position of obstacles. In the process, the priority of elements is assigned by varying the press intensity. 

By comparison, visual modality supports animation elements and color coding for conveying urgency. Nevertheless, in handovers between machine and human, situation understanding is crucial and visual context is necessary. This is based on the circumstance that humans mainly rely on visual perception during driving~\cite{plavsic2009}. As a reference, typical HMI transitions in a single-risk scenario last on average 2 to 8 seconds~\cite{walch2015}. 

Symbolic displays in the cockpit (warning with text or icons) have been thoroughly investigated in user studies, e.g. compare~\cite{plavsic2009}. It turned out that workload and effort may increase with a 3D cluster opposed to 2D traffic environment. Bird's-eye views are additionally rated as rather clear and comfortable than first person views.
In order to provide a $\unit[360]{^{\circ}}$ analysis, \cite{winner2016} lately introduced safety rings which bend to indicate positions of dangerous vehicles.  
Analogically, lateral lane change plus longitudinal speed recommendation can be conveyed by visual HMIs \cite{habenicht2011}. Lastly, the field of augmented reality is gaining more and more attention. In order to intuitively display vehicle distance and velocity, \cite{roessing2013} artificially blur the motion and create depth on high-quality videos. Further tests were done in \cite{narzt2004} where colored lanes are embedded into images, e.g. right turns as green, left turns as red and straight crossing as yellow. 

For our RNS, we choose to employ multiple visual elements of charts, pop-up symbols and animations inside a 2D birds-eye-view from the ego surrounding. The simulator naturally supports 3D views in other perspectives as well. In summary, RNS navigates the user along a route to an urban goal safely across intersections by issuing predictive informations, recommendations as well as warnings. 


