{
    "arxiv_id": "2303.15068",
    "paper_title": "DQSOps: Data Quality Scoring Operations Framework for Data-Driven Applications",
    "authors": [
        "Firas Bayram",
        "Bestoun S. Ahmed",
        "Erik Hallin",
        "Anton Engman"
    ],
    "submission_date": "2023-03-27",
    "revised_dates": [
        "2023-03-28"
    ],
    "latest_version": 1,
    "categories": [
        "cs.DB",
        "cs.SE"
    ],
    "abstract": "Data quality assessment has become a prominent component in the successful execution of complex data-driven artificial intelligence (AI) software systems. In practice, real-world applications generate huge volumes of data at speeds. These data streams require analysis and preprocessing before being permanently stored or used in a learning task. Therefore, significant attention has been paid to the systematic management and construction of high-quality datasets. Nevertheless, managing voluminous and high-velocity data streams is usually performed manually (i.e. offline), making it an impractical strategy in production environments. To address this challenge, DataOps has emerged to achieve life-cycle automation of data processes using DevOps principles. However, determining the data quality based on a fitness scale constitutes a complex task within the framework of DataOps. This paper presents a novel Data Quality Scoring Operations (DQSOps) framework that yields a quality score for production data in DataOps workflows. The framework incorporates two scoring approaches, an ML prediction-based approach that predicts the data quality score and a standard-based approach that periodically produces the ground-truth scores based on assessing several data quality dimensions. We deploy the DQSOps framework in a real-world industrial use case. The results show that DQSOps achieves significant computational speedup rates compared to the conventional approach of data quality scoring while maintaining high prediction performance.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.15068v1"
    ],
    "publication_venue": "10 Pages The International Conference on Evaluation and Assessment in Software Engineering (EASE) conference"
}