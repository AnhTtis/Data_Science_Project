{
    "arxiv_id": "2303.14197",
    "paper_title": "Optimal Smoothing Distribution Exploration for Backdoor Neutralization in Deep Learning-based Traffic Systems",
    "authors": [
        "Yue Wang",
        "Wending Li",
        "Michail Maniatakos",
        "Saif Eddin Jabari"
    ],
    "submission_date": "2023-03-24",
    "revised_dates": [
        "2023-03-28"
    ],
    "latest_version": 1,
    "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
    ],
    "abstract": "Deep Reinforcement Learning (DRL) enhances the efficiency of Autonomous Vehicles (AV), but also makes them susceptible to backdoor attacks that can result in traffic congestion or collisions. Backdoor functionality is typically incorporated by contaminating training datasets with covert malicious data to maintain high precision on genuine inputs while inducing the desired (malicious) outputs for specific inputs chosen by adversaries. Current defenses against backdoors mainly focus on image classification using image-based features, which cannot be readily transferred to the regression task of DRL-based AV controllers since the inputs are continuous sensor data, i.e., the combinations of velocity and distance of AV and its surrounding vehicles. Our proposed method adds well-designed noise to the input to neutralize backdoors. The approach involves learning an optimal smoothing (noise) distribution to preserve the normal functionality of genuine inputs while neutralizing backdoors. By doing so, the resulting model is expected to be more resilient against backdoor attacks while maintaining high accuracy on genuine inputs. The effectiveness of the proposed method is verified on a simulated traffic system based on a microscopic traffic simulator, where experimental results showcase that the smoothed traffic controller can neutralize all trigger samples and maintain the performance of relieving traffic congestion",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.14197v1"
    ],
    "publication_venue": null
}