\section{Introduction}
% importance of deep learning in traffic control

The emergence of autonomous vehicles (AVs) has the potential to revolutionize transportation systems by increasing mobility and safety. The development of AVs can help solve long-standing transportation challenges, including traffic congestion \cite{DBLP:journals/corr/SternCMBBCHHPWP17,vahidi2018energy}. To approximate the highly non-linear nature of driving, Deep Neural Networks (DNNs) have been widely adopted in AVs. However, recent research has shown that DNNs are vulnerable to backdoor attacks \cite{DBLP:journals/access/GuLDG19,DBLP:conf/iclr/NguyenT21,DBLP:conf/uss/BagdasaryanS21}, where an adversary can manipulate the DNN to embed backdoor functionalities that can cause misclassifications for specific adversary-chosen inputs. The backdoor functionality is usually implanted by poisoning training datasets with malicious inputs having stealthy trigger patterns and incorrect target labels. Recent work demonstrated that DRL-based traffic controllers of AVs are also susceptible to stealthy backdoor attacks \cite{DBLP:journals/tifs/WangSLMJ21}, where an adversary could misclassify controller outputs of a backdoored AV by adding malicious triggers based on traffic physics with the sensor inputs. They proposed two types of attacks: (1) congestion attack - causing traffic congestion, and (2) insurance attack - causing the AV to crash into the vehicle in front. Therefore, it is important to develop robust defenses against backdoor attacks to ensure the safety and reliability of AVs.

%deep learning method is vulnerable
%With the help of deep learning methods, traffic control approaches can generate to more sophisticated traffic scenarios. 
The current defense methods \cite{DBLP:conf/ccs/LiuLTMAZ19,DBLP:conf/sp/WangYSLVZZ19,DBLP:journals/dt/SarkarAM20,DBLP:conf/sp/ChouTP20}  against backdoors in DNNs concentrate primarily on image classification tasks and can be divided into to categories. Techniques pertaining to one category (such as Neural Cleanse \cite{DBLP:conf/sp/WangYSLVZZ19}, Sentinet \cite{DBLP:conf/sp/ChouTP20} and ABS \cite{DBLP:conf/ccs/LiuLTMAZ19}) defense against backdoors by detecting specific trigger patterns that significantly impact the model classification performance. However, they might be breakable when facing advanced attacks \cite{wong2018provable,raghunathan2018certified}), and they cannot be transferred to DRL-based AV controllers  (as these controllers use continuous sensor data as inputs and the output are continuous values instead of class labels). Alternatively, randomized smoothing (RS) \cite{cohen2019certified} constructs a smoothed model via adding noise to the inputs and outputting the expected perturbed inputs. This increases the robustness of the model with potentially embedded backdoors. RS does not depend on a specific form of triggers and is effective whenever the triggers satisfy some general conditions. However, it impacts the accuracy of the model, and it is still limited to classification problems rather than regression problems.

Defense methods against backdoor attacks in sensor-based traffic control systems, which use streaming sensor data such as velocities and positions as input for the model, have not yet been fully explored. Therefore, we propose an approach that draws inspiration from randomized smoothing (RS) to learn an optimal smoothing (noise) distribution that balances model accuracy and robustness. Specifically, we learn an unnormalized density function of noise parameters that connects the noise to a well-defined metric that reveals the performance of the smoothed model. We can subsequently generate the desired noise by sampling from this density function. By doing so, we can maintain the model functionality while rendering any backdoor present in the model ineffective.
 The contributions of this work are: 
\begin{enumerate}
    \item We systematically explore the optimal smoothing (noise) distribution for regression tasks of DRL-based AV controllers based on sensor-values;
    \item We learn an unnormalized density function and propose a sampling strategy to generate desired noise, where we ensure that the optimal (noise) sample with maximum probability can be generated;
    \item  Experimental evaluation on AV controllers targeted for injecting backdoors demonstrates that the proposed method outperforms existing state-of-the-art defense methods.
\end{enumerate}
%The proposed model extends our previous work \cite{wang2020stop} in that we utilize reinforcement learning to develop the trigger sample as opposed to utilizing empirical distributions over the parameters of the traffic system.

%The difference between the adversarial distributions and the genuine distribution is evaluated using the Jensen-Shannon (JS)-divergence, which is an effective method of measuring the similarity between two probability distributions. We test our controller attacks using a general purpose simulator using our stealthy triggers and our experiments on two different traffic scenarios to verify that our attacks can cause safety-critical problems, like AVs crashing into leading vehicles from behind.  The focus of this work is on stealthy attacks of a new kind with the ultimate aim of facilitating research into defenses against such attacks.  We leave the latter to future research.% We hope our study will draw more attention to the threats from deep learning architectures in traffic control systems and encourage more work on their defense.

The rest of this paper is organized as follows: Section \ref{pre} presents the basic notions of backdoor attacks on AV controllers and randomized smoothing. 
In Section \ref{explore_noise}, we provide details of our methodology for learning the optimal smoothing (noise) distributions for backdoor neutralization. 
In Section \ref{s:Experimental}, we provide experiments and conclude the paper in %describe the insurance attacks and we discuss possible defenses in Section \ref{s:defense}. Finally, we conclude this work in 
Section \ref{s:conclusion}.

