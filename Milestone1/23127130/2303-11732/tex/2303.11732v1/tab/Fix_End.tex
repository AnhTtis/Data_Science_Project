\begin{table}[t]
\footnotesize
\setlength\tabcolsep{3.5pt}
\centering
\begin{tabular}{c|c|cc|c|c}
\toprule 
\multirow{2}{*}{Training} & \multirow{2}{*}{Modality} &\multicolumn{2}{c|}{mAP@IoU} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}AVG\\ (0.3-0.7)\end{tabular}} & \multirow{2}{*}{ACC} \\ \cline{3-4}
 & & 0.3 & 0.7 &  &  \\ \midrule
\multirow{1}{*}{Freeze} & \multirow{2}{*}{RGB+Flow} & 56.3 & 17.3 & 39.2 & 87.6 \\ 
\multirow{1}{*}{End-to-End} & & 41.7 & 12.8 & 29.3 & 71.3 \\ 
\bottomrule
\end{tabular}
\caption{\textbf{Optimization modes.} Comparing to freezing all encoders, end-to-end fine-tuning the entire model brings numerous parameters that tend to specialize on the base categories, thereby damaging the model generalization.}
\vspace{-0.1cm}
\label{tab:fixend}
\end{table}

