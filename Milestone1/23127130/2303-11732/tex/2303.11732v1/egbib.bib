@string{ACL = "Association for Computational Linguistics"}
@string{IJCV = "International Journal of Computer Vision"}
@string{ICIP = "IEEE International Conference on Image Processing"}
@string{NIPS = "Advances in Neural Information Processing Systems"}
@string{BMVC = "Proceedings of the British Machine Vision Conference"}
@string{ECCV = "Proceedings of the European Conference on Computer Vision"}
@string{ICCV = "Proceedings of the International Conference on Computer Vision"}
@string{PAMI = "IEEE Transactions on Pattern Analysis and Machine Intelligence"}
@string{TMM = "IEEE Transactions on Multimedia"}
@string{ICML = "Proceedings of the International Conference on Machine Learning"}
@string{ICLR = "Proceedings of the International Conference on Learning Representations"}
@string{IJCAI = "Proceedings of the International Joint Conference on Artificial Intelligence"}
@string{CVPR = "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition"}
@string{EMNLP = "Proceedings of the Conference on Empirical Methods in Natural Language Processinng"}
@string{AAAI = "Proceedings of the AAAI Conference on Artificial Intelligence"}
@string{ACMMM = "Proceedings of ACM International Conference on Multimedia"}
@string{TIP = "IEEE Transactions on Image Processing"}




@InProceedings{Shin20, 
  title={{AutoPrompt}: Eliciting Knowledge from Language Models with Automatically Generated Prompts},
  author={Taylor Shin and Yasaman Razeghi and Robert L. Logan IV and Eric Wallace and Sameer Singh},
  booktitle = emnlp,
  year = {2020}
}

@InProceedings{Timo21,
  title={Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference},
  author={Timo Schick and Hinrich Sch√ºtze},
  booktitle={In Proceedings of the 16th Conference of the European Chapter of the Association for Computer Linguistics},
  year={2021}
}

@Article{Jiang20,
  title = {How Can We Know What Language Models Know?},
  author = {Zhengbao Jiang and Frank F. Xu and  Jun Araki and Graham Neubig},
  journal = {Transactions of the Association for Computational Linguistics},
  pages={423--438},
  year = {2020},
}

@InProceedings{Gao21,
  title={Making Pre-trained Language Models Better Few-shot Learners},
  author={Tianyu Gao and Adam Fisch and Danqi Chen},
  booktitle=acl,
  year={2021}
}

@inproceedings{Lei21,
  title={Less is More: ClipBERT for Video-and-Language Learning via Sparse Sampling},
  author={Lei, Jie and Li, Linjie and Zhou, Luowei and Gan, Zhe and Berg, Tamara L. and Bansal, Mohit and Liu, Jingjing},
  booktitle=cvpr,
  pages={7331--7341},
  year={2021}
}

@inproceedings{anne2017localizing,
  title={Localizing moments in video with natural language},
  author={Anne Hendricks, Lisa and Wang, Oliver and Shechtman, Eli and Sivic, Josef and Darrell, Trevor and Russell, Bryan},
  booktitle=iccv,
  pages={5803--5812},
  year={2017}
}

@InProceedings{Miech20,
  title={End-to-End Learning of Visual Representations from Uncurated Instructional Videos},
  author={Antoine Miech and Jean-Baptiste Alayrac and Lucas Smaira and Ivan Laptev and Josef Sivic and Andrew Zisserman},
  booktitle=cvpr,
  pages={9879--9889},
  year={2020}
}

@InProceedings{Weston11,
  title={{WSABIE}: Scaling Up to Large Vocabulary Image Annotation},
  author={Jason Weston and Samy Bengio and Nicolas Usunier},
  booktitle=ijcai,
  year={2011},
}

@InProceedings{Frome13,
  title={DeViSE: A Deep Visual-Semantic Embedding Model},
  author={Frome, Andrea and Corrado, Greg S and Shlens, Jon and Bengio, Samy and Dean, Jeff and Ranzato, Marc Aurelio and Mikolov, Tomas},
  booktitle=nips,   
  year={2013}
}

@InProceedings{Mori99,
  title={Image-to-word transformation based on dividing and vector quantizing images with words},
  author={Mori, Yasuhide and Takahashi, Hironobu and Oka, Ryuichi},
  booktitle={First International Workshop on Multimedia Intelligent Storage and Retrieval Management (ACM Multimedia Conference)},
  pages={1--9},
  year={1999},
}

@article{ju2020point,
  title={Point-level temporal action localization: Bridging fully-supervised proposals to weakly-supervised losses},
  author={Ju, Chen and Zhao, Peisen and Zhang, Ya and Wang, Yanfeng and Tian, Qi},
  journal={arXiv preprint arXiv:2012.08236},
  year={2020}
}

@article{ju2023constraint,
  title={Constraint and Union for Partially-Supervised Temporal Sentence Grounding},
  author={Ju, Chen and Wang, Haicheng and Liu, Jinxiang and Ma, Chaofan and Zhao, Peisen and Zhang, Ya and Chang, Jianlong and Tian, Qi},
  journal={arXiv preprint arXiv:2302.09850},
  year={2023}
}

@article{ma2023diffusionseg,
  title={DiffusionSeg: Adapting Diffusion Towards Unsupervised Object Discovery},
  author={Ma, Chaofan and Yang, Yuhuan and Ju, Chen and Zhang, Fei and Liu, Jinxiang and Wang, Yu and Zhang, Ya and Wang, Yanfeng},
  journal={arXiv preprint arXiv:2303.09813},
  year={2023}
}

@article{ju2022distilling,
  title={Distilling Vision-Language Pre-training to Collaborate with Weakly-Supervised Temporal Action Localization},
  author={Ju, Chen and Zheng, Kunhao and Liu, Jinxiang and Zhao, Peisen and Zhang, Ya and Chang, Jianlong and Wang, Yanfeng and Tian, Qi},
  journal={arXiv preprint arXiv:2212.09335},
  year={2022}
}

@article{luo2022clip4clip,
  title={CLIP4Clip: An empirical study of CLIP for end to end video clip retrieval and captioning},
  author={Luo, Huaishao and Ji, Lei and Zhong, Ming and Chen, Yang and Lei, Wen and Duan, Nan and Li, Tianrui},
  journal={Neurocomputing},
  pages={293--304},
  year={2022},
  publisher={Elsevier}
}

@InProceedings{Brown20,
  title = {Language Models are Few-Shot Learners},
  author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and  Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  booktitle = NIPS,
  pages={1877--1901},
  year = {2020}
}

@inproceedings{yao2021filip,
  title={FILIP: Fine-grained Interactive Language-Image Pre-Training},
  author={Yao, Lewei and Huang, Runhui and Hou, Lu and Lu, Guansong and Niu, Minzhe and Xu, Hang and Liang, Xiaodan and Li, Zhenguo and Jiang, Xin and Xu, Chunjing},
  booktitle=ICLR,
  year={2022}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{zheng2020distance,
  title={Distance-IoU loss: Faster and better learning for bounding box regression},
  author={Zheng, Zhaohui and Wang, Ping and Liu, Wei and Li, Jinze and Ye, Rongguang and Ren, Dongwei},
  booktitle=AAAI,
  pages={12993--13000},
  year={2020}
}

@inproceedings{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  booktitle=NIPS,
  pages={1877--1901},
  year={2020}
}

@inproceedings{wang2020k,
  title={K-adapter: Infusing knowledge into pre-trained models with adapters},
  author={Wang, Ruize and Tang, Duyu and Duan, Nan and Wei, Zhongyu and Huang, Xuanjing and Cao, Guihong and Jiang, Daxin and Zhou, Ming and others},
  booktitle=EMNLP,
  year={2020}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle=ICML,
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}

@InProceedings{Lester21,
  author={Brian Lester and Rami Al-Rfou and Noah Constant},
  title={The Power of Scale for Parameter-Efficient Prompt Tuning},
  booktitle=EMNLP,
  year={2021}
}

@inproceedings{li21-prefixtuning,
  title={Prefix-Tuning: Optimizing Continuous Prompts for Generation}, author={Xiang Lisa Li and Percy Liang},
  booktitle=ACL,
  year={2021}
}


@inproceedings{zhang2022opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  booktitle=EMNLP,
  year={2022}
}

@inproceedings{Jia21,
  author = {Chao Jia and Yinfei Yang and Ye Xia and Yi-Ting Chen and Zarana Parekh and Hieu Pham and Quoc V. Le and Yunhsuan Sung and Zhen Li and Tom Duerig},
  title = {Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision},
  booktitle=ICML,
  pages={4904--4916},
  year = {2021}
}

@inproceedings{gao2017tall,
  title={Tall: Temporal activity localization via language query},
  author={Gao, Jiyang and Sun, Chen and Yang, Zhenheng and Nevatia, Ram},
  booktitle={ICCV},
  pages={5267--5275},
  year={2017}
}

@inproceedings{yao2016highlight,
  title={Highlight detection with pairwise deep ranking for first-person video summarization},
  author={Yao, Ting and Mei, Tao and Rui, Yong},
  booktitle={CVPR},
  pages={982--990},
  year={2016}
}

@inproceedings{shu2015joint,
  title={Joint inference of groups, events and human roles in aerial videos},
  author={Shu, Tianmin and Xie, Dan and Rothrock, Brandon and Todorovic, Sinisa and Chun Zhu, Song},
  booktitle={CVPR},
  pages={4576--4584},
  year={2015}
}

@inproceedings{yang2021uncertainty,
  title={Uncertainty guided collaborative training for weakly supervised temporal action detection},
  author={Yang, Wenfei and Zhang, Tianzhu and Yu, Xiaoyuan and Qi, Tian and Zhang, Yongdong and Wu, Feng},
  booktitle=CVPR,
  pages={53--63},
  year={2021}
}

@inproceedings{zhai2020two,
  title={Two-Stream Consensus Network for Weakly-Supervised Temporal Action Localization},
  author={Zhai, Yuanhao and Wang, Le and Tang, Wei and Zhang, Qilin and Yuan, Junsong and Hua, Gang},
  booktitle=ECCV,
  pages={37--54},
  year={2020}
}

@inproceedings{luo2020weakly,
  title={Weakly-Supervised Action Localization with Expectation-Maximization Multi-Instance Learning},
  author={Luo, Zhekun and Guillory, Devin and Shi, Baifeng and Ke, Wei and Wan, Fang and Darrell, Trevor and Xu, Huijuan},
  booktitle=ECCV,
  pages={729--745},
  year={2020}
}

@inproceedings{zhang2019adversarial,
  title={Adversarial Seeded Sequence Growing for Weakly-Supervised Temporal Action Localization},
  author={Zhang, Chengwei and Xu, Yunlu and Cheng, Zhanzhan and Niu, Yi and Pu, Shiliang and Wu, Fei and Zou, Futai},
  booktitle=ACMMM,
  pages={738--746},
  year={2019}
}

@inproceedings{he2022asm,
  title={ASM-Loc: Action-aware Segment Modeling for Weakly-Supervised Temporal Action Localization},
  author={He, Bo and Yang, Xitong and Kang, Le and Cheng, Zhiyu and Zhou, Xin and Shrivastava, Abhinav},
  booktitle=CVPR,
  pages={13925--13935},
  year={2022}
}

@inproceedings{huang2021foreground,
  title={Foreground-Action Consistency Network for Weakly Supervised Temporal Action Localization},
  author={Huang, Linjiang and Wang, Liang and Li, Hongsheng},
  booktitle=ICCV,
  pages={8002--8011},
  year={2021}
}

@inproceedings{liu2019weakly,
  title={Weakly Supervised Temporal Action Localization Through Contrast Based Evaluation Networks},
  author={Liu, Ziyi and Wang, Le and Zhang, Qilin and Gao, Zhanning and Niu, Zhenxing and Zheng, Nanning and Hua, Gang},
  booktitle=ICCV,
  pages={3899--3908},
  year={2019}
}

@inproceedings{shou2018autoloc,
  title={Autoloc: Weakly-supervised temporal action localization in untrimmed videos},
  author={Shou, Zheng and Gao, Hang and Zhang, Lei and Miyazawa, Kazuyuki and Chang, Shih-Fu},
  booktitle=ECCV,
  pages={154--171},
  year={2018}
}

@inproceedings{lee2021weakly,
  title={Weakly-supervised temporal action localization by uncertainty modeling},
  author={Lee, Pilhyeon and Wang, Jinglu and Lu, Yan and Byun, Hyeran},
  booktitle=AAAI,
  pages={1854--1862},
  year={2021}
}

@inproceedings{shi2020weakly,
  title={Weakly-Supervised Action Localization by Generative Attention Modeling},
  author={Shi, Baifeng and Dai, Qi and Mu, Yadong and Wang, Jingdong},
  booktitle=CVPR,
  pages={1009--1019},
  year={2020}
}

@inproceedings{gao2022fine,
  title={Fine-grained Temporal Contrastive Learning for Weakly-supervised Temporal Action Localization},
  author={Gao, Junyu and Chen, Mengyuan and Xu, Changsheng},
  booktitle=CVPR,
  pages={19999--20009},
  year={2022}
}

@inproceedings{lee2019background,
  title={Background Suppression Network for Weakly-supervised Temporal Action Localization},
  author={Lee, Pilhyeon and Uh, Youngjung and Byun, Hyeran},
  booktitle=AAAI,
  pages={11320--11327},
  year={2020}
}

@inproceedings{nguyen2019weakly,
  title={Weakly-supervised Action Localization with Background Modeling},
  author={Nguyen, Phuc Xuan and Ramanan, Deva and Fowlkes, Charless C},
  booktitle=ICCV,
  pages={5502--5511},
  year={2019}
}

@inproceedings{narayan2021d2,
  title={D2-Net: Weakly-supervised action localization via discriminative embeddings and denoised activations},
  author={Narayan, Sanath and Cholakkal, Hisham and Hayat, Munawar and Khan, Fahad Shahbaz and Yang, Ming-Hsuan and Shao, Ling},
  booktitle=ICCV,
  pages={13608--13617},
  year={2021}
}

@inproceedings{luo2021action,
  title={Action unit memory network for weakly supervised temporal action localization},
  author={Luo, Wang and Zhang, Tianzhu and Yang, Wenfei and Liu, Jingen and Mei, Tao and Wu, Feng and Zhang, Yongdong},
  booktitle=CVPR,
   pages={9969--9979},
  year={2021}
}

@inproceedings{min2020adversarial,
  title={Adversarial Background-Aware Loss for Weakly-supervised Temporal Activity Localization},
  author={Min, Kyle and Corso, Jason J},
  booktitle=ECCV,
  pages={283--299},
  year={2020}
}

@inproceedings{liu2019completeness,
  title={Completeness Modeling and Context Separation for Weakly Supervised Temporal Action Localization},
  author={Liu, Daochang and Jiang, Tingting and Wang, Yizhou},
  booktitle=CVPR,
  pages={1298--1307},
  year={2019}
}

@inproceedings{wang2017untrimmednets,
  title={Untrimmednets for weakly supervised action recognition and detection},
  author={Wang, Limin and Xiong, Yuanjun and Lin, Dahua and Van Gool, Luc},
  booktitle=CVPR,
  pages={4325--4334},
  year={2017}
}

@inproceedings{paul2018w,
  title={W-talc: Weakly-supervised temporal activity localization and classification},
  author={Paul, Sujoy and Roy, Sourya and Roy-Chowdhury, AmitK},
  booktitle=ECCV,
  pages={563--579},
  year={2018}
}

@inproceedings{nguyen2018weakly,
  title={Weakly supervised action localization by sparse temporal pooling network},
  author={Nguyen, Phuc and Liu, Ting and Prasad, Gautam and Han, Bohyung},
  booktitle=CVPR,
  pages={6752--6761},
  year={2018}
}

@inproceedings{lin2019fast,
  title={Fast Learning of Temporal Action Proposal via Dense Boundary Generator},
  author={Lin, Chuming and Li, Jian and Wang, Yabiao and Tai, Ying and Luo, Donghao and Cui, Zhipeng and Wang, Chengjie and Li, Jilin and Huang, Feiyue and Ji, Rongrong},
  booktitle=AAAI,
  pages={11499--11506},
  year={2020}
}

@inproceedings{lin2019bmn,
  title={BMN: Boundary-Matching Network for Temporal Action Proposal Generation},
  author={Lin, Tianwei and Liu, Xiao and Li, Xin and Ding, Errui and Wen, Shilei},
  booktitle=ICCV,
  pages={3889--3898},
  year={2019}
}

@inproceedings{wang2022rcl,
  title={RCL: Recurrent Continuous Localization for Temporal Action Detection},
  author={Wang, Qiang and Zhang, Yanhao and Zheng, Yun and Pan, Pan},
  booktitle=CVPR,
  pages={13566--13575},
  year={2022}
}

@inproceedings{xu2017r,
  title={R-c3d: Region convolutional 3d network for temporal activity detection},
  author={Xu, Huijuan and Das, Abir and Saenko, Kate},
  booktitle=ICCV,
  pages={5783--5792},
  year={2017}
}

@inproceedings{xu2020g,
  title={G-tad: Sub-graph localization for temporal action detection},
  author={Xu, Mengmeng and Zhao, Chen and Rojas, David S and Thabet, Ali and Ghanem, Bernard},
  booktitle=CVPR,
  pages={10156--10165},
  year={2020}
}

@inproceedings{tan2021relaxed,
  title={Relaxed transformer decoders for direct action proposal generation},
  author={Tan, Jing and Tang, Jiaqi and Wang, Limin and Wu, Gangshan},
  booktitle=ICCV,
  pages={13526--13535},
  year={2021}
}

@inproceedings{zhu2021enriching,
  title={Enriching Local and Global Contexts for Temporal Action Localization},
  author={Zhu, Zixin and Tang, Wei and Wang, Le and Zheng, Nanning and Hua, Gang},
  booktitle=ICCV,
  pages={13516--13525},
  year={2021}
}

@inproceedings{shou2016temporal,
  title={Temporal action localization in untrimmed videos via multi-stage cnns},
  author={Shou, Zheng and Wang, Dongang and Chang, Shih-Fu},
  booktitle=CVPR,
  pages={1049--1058},
  year={2016}
}

@inproceedings{gao2017turn,
  title={Turn tap: Temporal unit regression network for temporal action proposals},
  author={Gao, Jiyang and Yang, Zhenheng and Chen, Kan and Sun, Chen and Nevatia, Ram},
  booktitle=ICCV,
  pages={3628--3636},
  year={2017}
}

@inproceedings{chao2018rethinking,
  title={Rethinking the faster r-cnn architecture for temporal action localization},
  author={Chao, Yu-Wei and Vijayanarasimhan, Sudheendra and Seybold, Bryan and Ross, David A and Deng, Jia and Sukthankar, Rahul},
  booktitle=CVPR,
  pages={1130--1139},
  year={2018}
}

@inproceedings{lin2017single,
  title={Single shot temporal action detection},
  author={Lin, Tianwei and Zhao, Xu and Shou, Zheng},
  booktitle=ACMMM,
  pages={988--996},
  year={2017}
}

@inproceedings{bai2020boundary,
  title={Boundary content graph neural network for temporal action proposal generation},
  author={Bai, Yueran and Wang, Yingying and Tong, Yunhai and Yang, Yang and Liu, Qiyue and Liu, Junhui},
  booktitle=ECCV,
  pages={121--137},
  year={2020}
}




@inproceedings{zhao2017temporal,
  title={Temporal action detection with structured segment networks},
  author={Zhao, Yue and Xiong, Yuanjun and Wang, Limin and Wu, Zhirong and Tang, Xiaoou and Lin, Dahua},
  booktitle=ICCV,
  pages={2914--2923},
  year={2017}
}

@inproceedings{lin2018bsn,
  title={Bsn: Boundary sensitive network for temporal action proposal generation},
  author={Lin, Tianwei and Zhao, Xu and Su, Haisheng and Wang, Chongjing and Yang, Ming},
  booktitle=ECCV,
  pages={3--19},
  year={2018}
}

@inproceedings{zeng2019graph,
  title={Graph convolutional networks for temporal action localization},
  author={Zeng, Runhao and Huang, Wenbing and Tan, Mingkui and Rong, Yu and Zhao, Peilin and Huang, Junzhou and Gan, Chuang},
  booktitle=ICCV,
  pages={7094--7103},
  year={2019}
}

@inproceedings{zeng2021graph,
  title={Graph Convolutional Module for Temporal Action Localization in Videos},
  author={Zeng, Runhao and Huang, Wenbing and Tan, Mingkui and Rong, Yu and Zhao, Peilin and Huang, Junzhou and Gan, Chuang},
  booktitle=TPAMI,
  pages={6209--6223},
  year={2021}
}

@inproceedings{qing2021temporal,
  title={Temporal context aggregation network for temporal action proposal refinement},
  author={Qing, Zhiwu and Su, Haisheng and Gan, Weihao and Wang, Dongliang and Wu, Wei and Wang, Xiang and Qiao, Yu and Yan, Junjie and Gao, Changxin and Sang, Nong},
  booktitle=ICCV,
  pages={485--494},
  year={2021}
}

@inproceedings{lin2021learning,
  title={Learning Salient Boundary Feature for Anchor-free Temporal Action Localization},
  author={Lin, Chuming and Xu, Chengming and Luo, Donghao and Wang, Yabiao and Tai, Ying and Wang, Chengjie and Li, Jilin and Huang, Feiyue and Fu, Yanwei},
  booktitle=CVPR,
  pages={3320--3329},
  year={2021}
}

@inproceedings{shou2017cdc,
  title={Cdc: Convolutional-de-convolutional networks for precise temporal action localization in untrimmed videos},
  author={Shou, Zheng and Chan, Jonathan and Zareian, Alireza and Miyazawa, Kazuyuki and Chang, Shih-Fu},
  booktitle=CVPR,
  pages={5734--5743},
  year={2017}
}

@InProceedings{Lin18,
  author={Tianwei Lin and Xu Zhao and Haisheng Su and Chongjing Wang and Ming Yang},
  title={{BSN}: Boundary Sensitive Network for Temporal Action Proposal Generation},
  booktitle=ECCV,
  pages={3--19},
  year={2018},
}

@inproceedings{ju2021divide,
  title={Divide and conquer for single-frame temporal action localization},
  author={Ju, Chen and Zhao, Peisen and Chen, Siheng and Zhang, Ya and Wang, Yanfeng and Tian, Qi},
  booktitle=ICCV,
  pages={13455--13464},
  year={2021}
}

@inproceedings{ma2020sf,
  title={Sf-net: Single-frame supervision for temporal action localization},
  author={Ma, Fan and Zhu, Linchao and Yang, Yi and Zha, Shengxin and Kundu, Gourab and Feiszli, Matt and Shou, Zheng},
  booktitle=ECCV,
  pages={420--437},
  year={2020},
  organization={Springer}
}

@inproceedings{lee2021learning,
  title={Learning action completeness from points for weakly-supervised temporal action localization},
  author={Lee, Pilhyeon and Byun, Hyeran},
  booktitle=ICCV,
  pages={13648--13657},
  year={2021}
}

@article{yang2021background,
  title={Background-click supervision for temporal action localization},
  author={Yang, Le and Han, Junwei and Zhao, Tao and Lin, Tianwei and Zhang, Dingwen and Chen, Jianxin},
  journal=PAMI,
  year={2021},
  pages={9814--9829},
  publisher={IEEE}
}

@inproceedings{zhao2020bottom,
  title={Bottom-up temporal action localization with mutual regularization},
  author={Zhao, Peisen and Xie, Lingxi and Ju, Chen and Zhang, Ya and Wang, Yanfeng and Tian, Qi},
  booktitle=ECCV,
  pages={539--555},
  year={2020},
  organization={Springer}
}

@inproceedings{ju2022prompting,
  title={Prompting Visual-Language Models for Efficient Video Understanding},
  author={Chen Ju and Tengda Han and Kunhao Zheng and Ya Zhang and Weidi Xie},
  booktitle=ECCV,
  pages={105--124},
  year={2022},
  organization={Springer}
}

@article{ju2021adaptive,
  title={Adaptive mutual supervision for weakly-supervised temporal action localization},
  author={Ju, Chen and Zhao, Peisen and Chen, Siheng and Zhang, Ya and Zhang, Xiaoyun and Tian, Qi},
  journal=TMM,
  year={2022},
  publisher={IEEE}
}

@inproceedings{liu2022exploiting,
  title={Exploiting Transformation Invariance and Equivariance for Self-supervised Sound Localisation},
  author={Liu, Jinxiang and Ju, Chen and Xie, Weidi and Zhang, Ya},
  booktitle=ACMMM,
  pages={3742--3753},
  year={2022}
}

@article{zhang2022ow,
  title={OW-TAL: Learning Unknown Human Activities for Open-World Temporal Action Localization},
  author={Zhang, Yaru and Zhang, Xiao-Yu and Shi, Haichao},
  journal={Pattern Recognition},
  pages={109027},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{narayan20193c,
  title={3c-net: Category count and center loss for weakly-supervised action localization},
  author={Narayan, Sanath and Cholakkal, Hisham and Khan, Fahad Shahbaz and Shao, Ling},
  booktitle=ICCV,
  pages={8679--8687},
  year={2019}
}

@inproceedings{xu2019segregated,
  title={Segregated temporal assembly recurrent networks for weakly supervised multiple action detection},
  author={Xu, Yunlu and Zhang, Chengwei and Cheng, Zhanzhan and Xie, Jianwen and Niu, Yi and Pu, Shiliang and Wu, Fei},
  booktitle=AAAI,
  pages={9070--9078},
  year={2019}
}

@inproceedings{bao2022opental,
  title={OpenTAL: Towards Open Set Temporal Action Localization},
  author={Bao, Wentao and Yu, Qi and Kong, Yu},
  booktitle=CVPR,
  pages={2979--2989},
  year={2022}
}

@inproceedings{nag2022zero,
  title={Zero-shot temporal action detection via vision-language prompting},
  author={Nag, Sauradip and Zhu, Xiatian and Song, Yi-Zhe and Xiang, Tao},
  booktitle=ECCV,
  year={2022},
  pages={681--697},
  organization={Springer}
}

@InProceedings{Radford21,
	author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
	title={Learning Transferable Visual Models From Natural Language Supervision},
	booktitle=ICML,
	pages={8748--8763},
	year={2021},
}

@article{yang2020revisiting,
  title={Revisiting anchor mechanisms for temporal action localization},
  author={Yang, Le and Peng, Houwen and Zhang, Dingwen and Fu, Jianlong and Han, Junwei},
  journal=TIP,
  pages={8535--8548},
  year={2020},
  publisher={IEEE}
}

@inproceedings{zhao2019hacs,
  title={Hacs: Human action clips and segments dataset for recognition and temporal localization},
  author={Zhao, Hang and Torralba, Antonio and Torresani, Lorenzo and Yan, Zhicheng},
  booktitle=ICCV,
  pages={8668--8678},
  year={2019}
}

@inproceedings{dai2022ms,
  title={MS-TCT: Multi-Scale Temporal ConvTransformer for Action Detection},
  author={Dai, Rui and Das, Srijan and Kahatapitiya, Kumara and Ryoo, Michael S and Bremond, Francois},
  booktitle=CVPR,
  pages={20041--20051},
  year={2022}
}

@InProceedings{Chao18,
  author={Yu-Wei Chao and Sudheendra Vijayanarasimhan and Bryan Seybold and David A. Ross and Jia Deng and Rahul Sukthankar},
  title={Rethinking the Faster R-CNN Architecture for Temporal Action Localisation},
  booktitle=CVPR,  
  pages={1130--1139},
  year={2018},
}

@inproceedings{zhang2022actionformer,
  title={Actionformer: Localizing moments of actions with transformers},
  author={Zhang, Chenlin and Wu, Jianxin and Li, Yin},
  booktitle=ECCV,
  pages={492--510},
  year={2022},
  organization={Springer}
}

@inproceedings{zhou2022conditional,
  title={Conditional prompt learning for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  booktitle=CVPR,
  pages={16816--16825},
  year={2022}
}

@electronic{jiang2014thumos,
  title={THUMOS challenge: Action recognition with a large number of classes},
  author={Jiang, Yu-Gang and Liu, Jingen and Zamir, A Roshan and Toderici, George and Laptev, Ivan and Shah, Mubarak and Sukthankar, Rahul},
  url={{http://crcv.ucf.edu/THUMOS14/}}
}

@inproceedings{caba2015activitynet,
  title={Activitynet: A large-scale video benchmark for human activity understanding},
  author={Caba Heilbron, Fabian and Escorcia, Victor and Ghanem, Bernard and Carlos Niebles, Juan},
  booktitle=CVPR,
  pages={961--970},
  year={2015}
}

@inproceedings{carreira2017quo,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle=CVPR,
  pages={6299--6308},
  year={2017}
}

@incollection{wedel2009improved,
  title={An improved algorithm for tv-l 1 optical flow},
  author={Wedel, Andreas and Pock, Thomas and Zach, Christopher and Bischof, Horst and Cremers, Daniel},
  booktitle={Statistical and geometrical approaches to visual motion analysis},
  year={2009},
  pages={23--45},
  publisher={Springer}
}

@inproceedings{gao2018ctap,
  title={Ctap: Complementary temporal action proposal generation},
  author={Gao, Jiyang and Chen, Kan and Nevatia, Ram},
  booktitle=ECCV,
  pages={68--83},
  year={2018}
}

@inproceedings{liu2019multi,
  title={Multi-granularity generator for temporal action proposal},
  author={Liu, Yuan and Ma, Lin and Zhang, Yifeng and Liu, Wei and Chang, Shih-Fu},
  booktitle=CVPR,
  pages={3604--3613},
  year={2019}
}

@inproceedings{zhou2019learn,
  title={Learning to Prompt for Vision-Language Models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  booktitle=IJCV,
  pages={2337--2348},
  year={2019}
}

@inproceedings{zhou2022con,
  title={Conditional Prompt Learning for Vision-Language Models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  booktitle=CVPR,
  pages={16816--16825},
  year={2022}
}

@inproceedings{du2022learning,
  title={Learning to prompt for open-vocabulary object detection with vision-language model},
  author={Du, Yu and Wei, Fangyun and Zhang, Zihe and Shi, Miaojing and Gao, Yue and Li, Guoqi},
  booktitle=CVPR,
  pages={14084--14093},
  year={2022}
}

@inproceedings{gu2021open,
  title={Open-vocabulary object detection via vision and language knowledge distillation},
  author={Gu, Xiuye and Lin, Tsung-Yi and Kuo, Weicheng and Cui, Yin},
  booktitle=ICLR,
  year={2021}
}

@inproceedings{li2022language,
  title={Language-driven semantic segmentation},
  author={Li, Boyi and Weinberger, Kilian Q and Belongie, Serge and Koltun, Vladlen and Ranftl, Ren{\'e}},
  booktitle=ICLR,
  year={2022}
}

@article{mokady2021clipcap,
  title={Clipcap: Clip prefix for image captioning},
  author={Mokady, Ron and Hertz, Amir and Bermano, Amit H},
  journal={arXiv preprint arXiv:2111.09734},
  year={2021}
}

@inproceedings{shen2021much,
  title={How much can clip benefit vision-and-language tasks?},
  author={Shen, Sheng and Li, Liunian Harold and Tan, Hao and Bansal, Mohit and Rohrbach, Anna and Chang, Kai-Wei and Yao, Zhewei and Keutzer, Kurt},
  booktitle=ICLR,
  year={2021}
}

@inproceedings{lu2022prompt,
  title={Prompt distribution learning},
  author={Lu, Yuning and Liu, Jianzhuang and Zhang, Yonggang and Liu, Yajing and Tian, Xinmei},
  booktitle=CVPR,
  pages={5206--5215},
  year={2022}
}

@article{zhu2022prompt,
  title={Prompt-aligned gradient for prompt tuning},
  author={Zhu, Beier and Niu, Yulei and Han, Yucheng and Wu, Yue and Zhang, Hanwang},
  journal={arXiv preprint arXiv:2205.14865},
  year={2022}
}

@inproceedings{jia2022visual,
  title={Visual prompt tuning},
  author={Jia, Menglin and Tang, Luming and Chen, Bor-Chun and Cardie, Claire and Belongie, Serge and Hariharan, Bharath and Lim, Ser-Nam},
  booktitle=ECCV,
  pages={709--727},
  year={2022}
}

@article{huang2022vop,
  title={VoP: Text-Video Co-operative Prompt Tuning for Cross-Modal Retrieval},
  author={Huang, Siteng and Gong, Biao and Pan, Yulin and Jiang, Jianwen and Lv, Yiliang and Li, Yuyuan and Wang, Donglin},
  journal={arXiv preprint arXiv:2211.12764},
  year={2022}
}

@inproceedings{ni2022expanding,
  title={Expanding language-image pretrained models for general video recognition},
  author={Ni, Bolin and Peng, Houwen and Chen, Minghao and Zhang, Songyang and Meng, Gaofeng and Fu, Jianlong and Xiang, Shiming and Ling, Haibin},
  booktitle=ECCV,
  pages={1--18},
  year={2022}
}

@article{zhao2021soda,
  title={SODA: Weakly supervised temporal action localization based on astute background response and self-distillation learning},
  author={Zhao, Tao and Han, Junwei and Yang, Le and Wang, Binglu and Zhang, Dingwen},
  journal=IJCV,
  volume={129},
  number={8},
  pages={2474--2498},
  year={2021},
  publisher={Springer}
}

@article{vo2023aoe,
  title={Aoe-net: Entities interactions modeling with adaptive attention mechanism for temporal action proposals generation},
  author={Vo, Khoa and Truong, Sang and Yamazaki, Kashu and Raj, Bhiksha and Tran, Minh-Triet and Le, Ngan},
  journal=IJCV,
  volume={131},
  number={1},
  pages={302--323},
  year={2023},
  publisher={Springer}
}

@article{mettes2019pointly,
  title={Pointly-supervised action localization},
  author={Mettes, Pascal and Snoek, Cees GM},
  journal=IJCV,
  volume={127},
  pages={263--281},
  year={2019},
  publisher={Springer}
}

@article{ma2022weakly,
  title={Weakly Supervised Moment Localization with Decoupled Consistent Concept Prediction},
  author={Ma, Fan and Zhu, Linchao and Yang, Yi},
  journal=IJCV,
  volume={130},
  number={5},
  pages={1244--1258},
  year={2022},
  publisher={Springer}
}

@article{yudistira2022weakly,
  title={Weakly-Supervised Action Localization, and Action Recognition Using Global--Local Attention of 3D CNN},
  author={Yudistira, Novanto and Kavitha, Muthu Subash and Kurita, Takio},
  journal=IJCV,
  volume={130},
  number={10},
  pages={2349--2363},
  year={2022},
  publisher={Springer}
}

@article{ke2010volumetric,
  title={Volumetric features for video event detection},
  author={Ke, Yan and Sukthankar, Rahul and Hebert, Martial},
  journal=IJCV,
  volume={88},
  pages={339--362},
  year={2010},
  publisher={Springer}
}

@article{xu2021videoclip,
  title={Videoclip: Contrastive pre-training for zero-shot video-text understanding},
  author={Xu, Hu and Ghosh, Gargi and Huang, Po-Yao and Okhonko, Dmytro and Aghajanyan, Armen and Metze, Florian and Zettlemoyer, Luke and Feichtenhofer, Christoph},
  journal={arXiv preprint arXiv:2109.14084},
  year={2021}
}

@article{yuan2021florence,
  title={Florence: A new foundation model for computer vision},
  author={Yuan, Lu and Chen, Dongdong and Chen, Yi-Ling and Codella, Noel and Dai, Xiyang and Gao, Jianfeng and Hu, Houdong and Huang, Xuedong and Li, Boxin and Li, Chunyuan and others},
  journal={arXiv preprint arXiv:2111.11432},
  year={2021}
}

@inproceedings{li2021prefix,
  title={Prefix-tuning: Optimizing continuous prompts for generation},
  author={Li, Xiang Lisa and Liang, Percy},
  booktitle=acl,
  year={2021}
}

@inproceedings{zhai2022lit,
  title={Lit: Zero-shot transfer with locked-image text tuning},
  author={Zhai, Xiaohua and Wang, Xiao and Mustafa, Basil and Steiner, Andreas and Keysers, Daniel and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle=CVPR,
  pages={18123--18133},
  year={2022}
}

@article{zhu2016learning,
  title={Learning from multiple sources for video summarisation},
  author={Zhu, Xiatian and Loy, Chen Change and Gong, Shaogang},
  journal=IJCV,
  volume={117},
  pages={247--268},
  year={2016},
  publisher={Springer}
}

@article{yang2022learning,
  title={Learning to Collocate Visual-Linguistic Neural Modules for Image Captioning},
  author={Yang, Xu and Zhang, Hanwang and Gao, Chongyang and Cai, Jianfei},
  journal=IJCV,
  pages={1--19},
  year={2022},
  publisher={Springer}
}


