



\section{Model-based Optimization Algorithms for RIS-aided Wireless Networks}
\label{sec-model}

This section introduces model-based algorithms and applications for optimizing RIS-aided wireless networks, including AO, MM, SCA, BCD, SDR, SOCP, FP, and BnB. In addition, we summarize the features, advantages, drawbacks, difficulties, and applications of these techniques.   

\subsection{Alternating Optimization} 



AO has been widely applied for RIS-related control and optimizations. The main reason is the high complexity of joint optimization problems that include multiple control variables such as BS beamforming matrix and RIS phase shifts. Fig. \ref{fig-AO} shows the AO approach to decouple the RIS passive beamforming with BS active beamforming, and the circles in the figures indicate objective functions with the same value. $x^{l}_{1}$ is first optimized from $x^{l}_{1}$ to $x^{l+1}_{1}$ and holding $x^{l}_{2}$ unchanged, where $l$ indicates the iteration numbers. Then $x^{l}_{2}$ is optimized to $x^{l+1}_{2}$ alternatively. AO can significantly reduce the computational complexity by optimizing $x^{l}$ to $x^{l+1}$ in an iterative manner, since sub-problems with fewer control variables are easier to solve than original problemsx. 

For an optimization problem with $I$ control variables $\Vec{x} = (x_1,x_2,...,x_i,...,x_I) $ and  $x_i \in X_{i}$, to minimize objective function $f(\Vec{x})$, AO method is described by
 \begin{equation} \label{eq-ao}
    \resizebox{0.8\hsize}{!}{$ x^{l}_i \leftarrow \argmin\limits_{x_{i} \in X_i} f(\underbrace{x^{l}_1,x^{l}_2,...,x^{l}_{i-1}}_{\textbf{done}}\underbrace{,x_{i},}_{\textbf{current}}\underbrace{x^{l-1}_{i+1},...,x^{l-1}_{I}}_{\textbf{todo}})$},    
\end{equation}
where $x^{l}_i$ is optimized while holding all the other control variables $(x^{l}_1,x^{l}_2,...,x^{l}_{i-1},x^{l-1}_{i+1},...,x^{l-1}_{I})$ constant. Then, equation (\ref{eq-ao}) is repeated by $i=i+1$ until meeting the stop criteria.  
In equation (\ref{eq-ao}), AO simplifies joint optimization problems by optimizing single control variables alternatively while holding other variables unchanged\cite{jcbe}. Each iteration is time-efficient by optimizing one individual variable, which is easily implemented. In addition, it does not require step size parameter tuning and extra storage vectors. However, AO may slow down in the near optimum, and single-variable monotonically decreasing in each iteration can not guarantee the global minimum.

The RIS is often combined with other techniques for joint optimization, such as joint active and passive beamforming, RIS-related resource allocation, RIS-NOMA, and RIS-MEC, leading to coupled control variables and large solution spaces.    
AO is particularly useful in solving such joint optimization problems. For example, 
the RIS-MEC system can be decoupled into RIS phase-shift control sub-problem and task offloading sub-problem, and these two sub-problems will be iteratively optimized to reduce the overall complexity. Joint active and passive beamforming is another example that has been widely investigated, which applies AO to generate BS active beamforming and RIS passive beamforming sub-problems\cite{qingqing,qingqing2,qingqing3}. 

\begin{figure}[!t]
\centering
\includegraphics[width=0.9\linewidth]{Image/fig-AO.jpg}
\caption{The alternating optimization procedure for joint active and passive beamforming.}
\label{fig-AO}
\setlength{\abovecaptionskip}{-2pt} 
\vspace{-10pt}
\end{figure}

\subsection{Block Coordinate Descent}  
Coordinate descent is a very useful method to solve large-scale optimization problems, and BCD is considered a generalized version to improve computation efficiency.
Compared with AO method, each block in the BCD algorithm may include several control variables, enabling dynamic block generation, selection and updating. Therefore, BCD method is more suitable than AO for optimizing a large number of control variables simultaneously, which has been widely applied to RIS-related optimization problems. 

BCD method sequentially minimizes the objective function $F(\Vec{x})$ in each block $x_{i}$ while the other blocks are held fixed. Specifically, it minimizes $ x^{l}_{i} \leftarrow \argmin\limits_{x_i \in \mathscr{X_{i}}} (f(x_{i})+f_{i}(x_i))$ while holding other blocks $x_{1},x_{2},...,x_{i-1},x_{i+1},...x_{I}$ fixed. However, it is worth noting that each block consists of multiple control variables, and the block selection and updating method will affect the BCD performance. An ideal block selection method is expected to maximize the improvement by choosing the blocks that decrease $F(\Vec{x})$ by the largest amount\cite{Julie}. On the other hand, there are many alternatives for the block updating method such as block proximal updating
     \begin{equation} \label{eq-bcd2}
        x^{l}_{i} \leftarrow \argmin\limits_{x_i \in \mathscr{X_{i}}} (f(x_{i})+f_{i}(x_i)+\frac{L_{i}^{l-1}}{2}\|x_{i}-x^{l-1}_{i}\|^2),
    \end{equation}
where $L_{i}^{l-1}>0$. Equation (\ref{eq-bcd2}) is more stable than conventional BCD by including $\frac{L_{i}^{l-1}}{2}\|x_{i}-x^{l-1}_{i}\|^2$\. 
The BCD algorithm is easily deployed with low memory requirements and iteration costs, allowing parallel or distributed implementations. But the block selection may affect the algorithm performance, and block updating is difficult in some cases. 

Similar to AO, BCD is considered as an iteration-based scheme to reduce problem-solving complexity. BCD has been applied to sum-rate maximization \cite{cunhua,jiey,huayan}, user fairness maximization \cite{gang,xianghao2}, and power minimization \cite{zhiyang}. 
As an example, a two-block BCD is used to maximize the sum-rate in \cite{huayan}, in which the first block is for BS active beamforming and the second is for RIS passive beamforming, then these blocks are iteratively optimized. 






\subsection{Majorization-Minimization Method} 

MM is an iterative optimization method that has been applied for RIS control and optimizations. Consider an optimization problem with $\min\limits_{x}  f(x) $ and $x \in \mathscr{X}$, and $f(x)$ is a continuous objective function and $\mathscr{X}$ is a convex closed set. In RIS-related control problems, the $f(x)$ is usually complicated to solve directly due to fractional and logarithmic terms.
As shown in Fig. \ref{fig-mm}, the main idea of the MM algorithm is to construct a surrogate function $g(x)$ that can locally approximate the objective function $f(x)$, e.g., power minimization or sum-rate maximization. $g(x)$ is considered an upper bound of $f(x)$, which is easier to be optimized. Therefore, optimizing $g(x)$ can either improve the objective function value or leave it unchanged with $g(x) \geq f(x)$\cite{ying}.   

Constructing a surrogate function $g(x)$ is the first step of applying the MM algorithm, since $g(x)$ will be optimized directly instead of the original objective $f(x)$. The $g(x)$ construction rules include:\\
    A1): $g(x^{l-1}|x^{l-1})=f(x)$; \quad A2): $g(x|x^{l-1}) \geq f(x)$;\\
    A3): $ g'(x|x^{l-1};d)|_{x=x^{l-1}}=f'(x^{l-1};d)|_{x=x^{l-1}}$;\\
    A4): $g(x|x^{l-1})$ is continuous in $x$ and $x^{l-1}$, \\
where $x^{l-1}$ is the produced point at iteration $l-1$, $g(x|x^{l-1})$ is an approximation function of $f(x)$ at the iteration $l$, $d$ indicates the distance from a point $x$ to a set $\mathscr{X}$ and $d=\inf\limits_{x'\in \mathscr{X}}||(x-x')||$. $f'(x;d)$ is the directional derivative of $f(x)$ in direction $d$.
Assumptions (A1) and (A2) indicate that $g(x|x^{l-1})$ is a tight upper bound of the original objective $f(x)$. It guarantees that optimizing $g(x|x^{l-1})$ can meanwhile find an improved objective value for $f(x)$. 
Note that surrogate function may be defined in various ways, e.g. Jensen's inequality, Convexity inequality, Cauchy–Schwarz inequality.     
Then, the surrogate function $g(x|x^{l-1})$ is iteratively minimized and updated by
$ x^{l} \leftarrow \argmin\limits_{x \in \mathscr{X}} g(x|x^{l-1})$ until convergence. 

MM applies surrogate functions to avoid the complexity of optimizing the objective function directly, transforming non-differentiable problems into smooth optimizations. However, it requires that the surrogate function $g(x)$ must be a global upper bound for $f(x)$, which is very demanding in some cases. As an estimation-based method, MM is considered a low-complexity solution for many RIS-related optimizations, including sum-rate maximization\cite{cunhua}, fairness maximization\cite{menghua,guiz}, secure transmission\cite{xianghao2,huiming2} and so on. For example, in \cite{cunhua}, the RIS phase-shift optimization problem is first converted into a non-convex quadratically constrained quadratic program (QCQP) problem\footnote{A QCQP problem example is given by equation (\ref{eq-qcqp}) in Section \ref{section_sdr}, which is frequently formulated in wireless networks.}, then the MM method is applied to obtain local optimal solutions.  

\begin{figure}[!t]
\centering
\setlength{\abovecaptionskip}{-2pt} 
\includegraphics[width=0.95\linewidth]{Image/fig-MM.jpg}
\caption{MM method for RIS-related optimizations.}
\label{fig-mm}
\vspace{-10pt}
\end{figure}


\subsection{Successive Convex Approximation} 

\begin{figure}[!t]
\centering
\setlength{\abovecaptionskip}{-2pt} 
\includegraphics[width=1.02\linewidth]{Image/fig-SCA.jpg}
\caption{ Using SCA algorithm for RIS-related optimization.}
\label{fig-SCA}
\vspace{-10pt}
\end{figure}

Similar to the MM algorithm, SCA applies a surrogate function $g(x)$ to approximate the original objective function $f(x)$, which is shown in Fig. \ref{fig-SCA}. However, the $g(x)$ in the SCA algorithm does not have to be a tight upper bound for $f(x)$, reducing the complexity of the surrogate function design \cite{palomar}. Therefore, SCA is more flexible and easier to be implemented for RIS-related optimization problems.

The SCA method first constructs a surrogate function $g(x)$, and the assumptions are similar to the MM algorithm:  \\ 
A1): $g(x|x^{l-1})$ is continuous in $\mathscr{X}$;\\
A2): $g(x^{l-1}|x^{l-1})=f(x)$;\\
A3): $g(x)$ is differentiable with $\nabla_{x} g(x|x^{l-1})|_{x=x^{l-1}}=\nabla_{x} f(x)|_{x=x^{l-1}}$. \\
SCA relaxes the upper bound condition for the surrogate function, but $g(x|x^{l-1})$ must be strongly convex in $\mathscr{X}$.
Then, solving the constructed surrogate problem 
$\mathbf{\hat{x}}(x^{l}) \leftarrow \argmin\limits_{x \in \mathscr{X}} g(x|x^{l-1})$,
and smoothing the next point by 
\begin{equation}
    x^{l}=x^{l-1}+\beta^{l-1}(\mathbf{\hat{x}}(x^{l})-x^{l-1}),
\end{equation} 
where $\beta^{l-1}$ is the step size for value updating.
Finally,  $g(x)$ construction and solving are repeated until meeting the convergence criteria.   

The surrogate function $g(x)$ does not have to be a tight upper bound for $f(x)$. Therefore, the step size in each iteration requires dedicated designs to guarantee an accurate approximation. The factor $\beta^{l-1}$ is used to control the $x^{l}$ updating step size. Meanwhile, the MM algorithm updates the whole control variable $x$ at each iteration, but SCA can be naturally implemented in a distributed manner when the constraints are separable. 

Compared with MM, SCA is more frequently applied in RIS-related optimizations due to the relaxed upper bound, e.g., sum-rate maximization in \cite{ming,yuanbin,xidong} and power minimization in \cite{huimei,jianyue}. For instance, the non-convex BS transmit power constraint in \cite{huimei} is replaced by a first order Taylor approximation to apply SCA algorithm, and then the obtained BS beamforming vector and RIS phase shifts are alternatively optimized for transmit power minimization.




\subsection{Semidefinite Relaxation}  
\label{section_sdr}

Many RIS-related signal processing problems can be described by QCQP formulations, and SDR is an efficient solution to solve QCQP problems\cite{shuzhong}. The QCQP problem is defined by
\begin{equation}\label{eq-qcqp}
\begin{aligned}
\min\limits_{x\in \mathscr{X}}  \qquad & x^{T}C x  \\
 \text{s.t.}  \qquad & x^{T}D_{i} x \geq b_{i}, i=1,2,3,,,n,  
\end{aligned}
\end{equation} 
where the "$\geq$" in the constraint can also be replaced by "$\leq$". Note that $x^{T}C x$ produces an $1\times 1$ matrix, and therefore $x^{T}Cx=Cx^{T}x=Tr(Cx^{T}x)$. Similarly, $x^{T}D_{i}x=D_{i}x^{T}x=Tr(D_{i}x^{T}x)$ is achieved. By introducing $X=xx^T$, then  
\begin{equation}\label{eq-qcqp2}
\begin{aligned}
\min\limits_{x\in \mathscr{X}}  \qquad & Tr(CX)  \\
 \text{s.t.}  \qquad & Tr(DX_{i}) \geq b_{i}, i=1,2,3,,,I,  \\
 \qquad & X\succeq 0,     \\
  \qquad & rank(X)=1,   
\end{aligned}
\end{equation}
where $X\succeq 0$ indicates that $X$ is positive semidefinite with $X=xx^T$. Then, the non-convex constraint $rank(X)=1$ is relaxed and achieve 
\begin{equation}\label{eq-qcqp3}
\begin{aligned}
\min\limits_{x\in \mathscr{X}}  \qquad & Tr(CX)    \\
 \text{s.t.}  \qquad & Tr(DX_{i}) \geq b_{i}, i=1,2,3,,,I,   \\
 \qquad & X\succeq 0.  
\end{aligned}
\end{equation}

Equation (\ref{eq-qcqp3}) is a SDR of (\ref{eq-qcqp2}), which can be efficiently solved by semidefinite programming (SDP)\cite{zhiquan}. However, the following issue is how to transform a global optimal solution $\hat{X}$ in equation (\ref{eq-qcqp3}) into a feasible solution $\hat{x}$ in equation (\ref{eq-qcqp}). An ideal solution is that $\hat{X}$ is of rank-one, and $\hat{x}$ is easily obtained by solving $\hat{X}=\hat{x}\hat{x}^T$. Otherwise, if $rank(\hat{x})>1$, rank-one approximation may be used to obtain a suboptimal solution $\widetilde{x}$ for the problem (\ref{eq-qcqp}). 

In addition, there are multiple methods to find a feasible $\widetilde{x}$ from $\hat{X}$, leading to various solution qualities. For instance, Mu \textit{et al.} proposed a penalty-based method to relax the rank-one constraint, finding a sub-optimal solution by introducing penalties if $rank(\hat{x})>1$ \cite{mu2021simultaneously}. SDR has been very generally applied to RIS-related optimization problems, since the $rank(x)=1$ is frequently formulated for phase control. Specifically, the RIS phase shift constraint $|\theta_n|=1$ is non-convex, and then $|\theta_n|=1$ is transformed and relaxed as equation (\ref{eq-qcqp2}) to (\ref{eq-qcqp3}), which can be efficiently solved by standard optimization tools. SDR has been used for sum-rate maximization \cite{boya, peilan, ni2021resource}, power minimization \cite{guizhou2,huimei,guiz3,jianyue}, fairness maximization \cite{gang,hailiang,zaid,menghua}, and secure transmission \cite{zheng,wei,xianghao,biqian,zijie}. 



\subsection{Second-order Cone Programming}  
SOCP is another method that is used to efficiently solve optimization problems in wireless networks, especially for QCQP and fractional problems. It enables affine combinations of variables to be constrained inside a second-order cone
\begin{equation}\label{eq-scop}
\begin{aligned}
\min\limits_{x\in \mathscr{X}}  \qquad & C^{T} x   \\
 \text{s.t.}  \qquad & ||A_{i}x+b_{i}||\leq c_{i}^{T}x+d_{i}, i=1,2,3,,,I, 
\end{aligned}
\end{equation} 
where $A \in \mathbb{R}^{n_i\times n}$, $b_i \in \mathbb{R}^{n_i}$, $c_i \in \mathbb{R}^n$, and $d_i \in \mathbb{R}$. The $x$ in equation (\ref{eq-scop}) may be RIS phase shifts, BS beamforming vectors, and so on, which depends on specific application scenarios. Consider the inverse image of the unit second-order cone with an affine mapping
\begin{equation} \label{eq-scop3}
 ||A_{i}x+b_{i}||\leq c_{i}^{T}x+d_{i} \leftrightarrow 
 \left[ \begin{array}{c}  
    A_{i} \\  
    c_{i}^{T} \\ 
  \end{array} \right] x +  
\left[ \begin{array}{c}  
    b_{i} \\  
    d_{i} \\ 
  \end{array}
\right] \in \mathscr{C}_{n_i+1}.       
\end{equation}
Therefore, SOCP is a convex optimization problem with a convex objective function and convex constraints. Equations (\ref{eq-scop3}) indicate the core properties of SOCP problems, and hence many problems are converted into SOCPs and solved efficiently\cite{miguso}. 

For instance, sum and fractional problems are frequently defined in RIS-related problems to maximize the sum-rate or total throughput regarding the SINR
\begin{equation}\label{eq-scop7}
\begin{aligned}
\min\limits_{x\in \mathscr{X}}  \qquad & \sum_{i=1}^{I}\frac{||C_{i}^T+D_{i}||^2}{A_{i}^Tx+B_{i}}  \\
 \text{s.t.}  \qquad & A_{i}^Tx+B_{i} \geq 0, i=1,2,3,,,I, 
\end{aligned}
\end{equation} 
which is converted into a SOCP by
\begin{equation}\label{eq-scop8}
\begin{aligned}
\min\limits_{x\in \mathscr{X}}  \qquad & \sum_{i=1}^{I}t_{i} \\
 \text{s.t.}  \qquad & (C_{i}^T+D_{i})^T(C_{i}^T+D_{i}) \leq t_{i}(A_{i}^Tx+B_{i}),    \\
  \qquad & A_{i}^Tx+B_{i} > 0, i=1,2,3,,,I.  
\end{aligned}
\end{equation} 

SOCP can be efficiently solved by the interior point method. Meanwhile, SOCP is less general than SDP since equation (\ref{eq-scop}) may be transformed into an SDP problem. However, the complexity of solving SOCP is $O(n^2\sum_{i}{n_i})$, while the complexity for SDP is $O(n^2\sum_{i}{n_i}^2)$\cite{nest}. Such complexity difference is crucial for large-dimension problems. 

Finally, to apply SOCP for RIS-aided optimizations, the first step is to utilize AO or BCD scheme to decouple the control variables into multiple sub-problems, e.g., BS precoding matrix and RIS passive beamforming\cite{guiz,yiqing,menghua}, coordinated transmit beamforming and RIS passive beamforming\cite{hailiang}. For example, the max-min data rate problem in \cite{menghua} is decoupled into SOCP-based BS beamforming and SDR-based RIS phase-shift control, and the data rate maximization problem in \cite{jiey} is converted into a SOCP-based BS active beamforming and SDR-based RIS passive beamforming.         



\subsection{Fractional Programming} 
FP refers to optimization problems involving ratios or fractional terms.
FP is particularly useful for wireless network optimizations due to the fractional terms in communication systems, especially for SINR and energy efficiency\cite{zappone}. 

Consider a single-ratio FP problem to maximize the SINR of single UE by $\max\limits_{x\in \mathscr{X}} {f(x)}/{g(x)}$, where $f(x)$ is the signal strength and $g(x)$ is the interference and noise. There are many classic methods to solve FP problems, such as Charnes-Cooper transform and Dinkelbach’s transform\cite{Dinke}. Dinkelbach’s method reformulates the problem into $\max\limits_{x\in \mathscr{X},y\in \mathbb{R}}  f(x)-yg(x)$, where $y$ is the auxiliary variable that is updated iteratively $y^{(l+1)}={f(x)^l}/{g(x)^l}$, 
and $l$ is the iteration number. Then, alternatively updating $y$ and $x$ will lead to a converged solution with non-decreasing $y^l$. However, instead of the single-ratio problem, sum-ratio FP problems are more frequently involved in wireless networks, i.e., maximizing sum-rate or total channel capacity as 
$\max\limits_{x\in \mathscr{X}}  \ \sum_{i=1}^{I} f_{i}(x)/g_{i}(x) $.

However, classic methods can not be directly generalized to sum-ratio cases, since maximizing single ratios cannot guarantee the convergence and maximization for sum-ratio cases. An equivalent transform proposed by \cite{shenk} is 
\begin{equation}\label{eq-fp5}
\max\limits_{x\in \mathscr{X},y\in \mathbb{R}}  \quad 2yf(x)^{0.5}-y^{2}g(x),  
\end{equation} 
which can be readily converted into sum-ratio problems.
In addition, equation (\ref{eq-fp5}) is further generalized to sum-ratio problems as
\begin{equation}\label{eq-fp7}
\max\limits_{x\in \mathscr{X},y\in \mathbb{R}}  \quad \sum_{i=1}^{I}F_{i}(2y_{i}C_{i}(x)^{0.5}-y_{i}^{2}D_{i}(x)),  
\end{equation}
where $F_{i}$ is a non-decreasing function. Equation (\ref{eq-fp7}) is particularly useful given the frequently used term $\sum log(1+SINR)$ in wireless communications. 

Moreover, RIS-related max-min fairness problems are formulated as
$\max\limits_{x\in \mathscr{X}}  \  \min\limits_{1\leq i \leq I} \ {f_{i}(x)}/{g_{i}(x)}$, 
which is reformulated by
\begin{equation}\label{eq-fp9}
\begin{aligned}
\max\limits_{x\in \mathscr{X}, y,z\in \mathbb{R}}  &  \quad z \\
 \text{s.t.}  \quad & 2y_{i}f_{i}(x)^{0.5}-y_{i}^{2}g_{i}(x) \geq z; i=1,2,3,,,I.
\end{aligned}
\end{equation}

FP method significantly reduces the optimization complexity by decoupling the fractional terms. Therefore, it has been widely used in wireless network optimizations, including power control, beamforming, energy efficiency and so on. 
FP method can significantly lower the problem-solving complexity by eliminating fractional items. This transformation is very useful for RIS-related optimization problems, especially considering that RIS phase shifts will affect the received signal strength and interference simultaneously.
For instance, FP is applied to maximize the sum-rate of RIS-aided wireless networks in \cite{huayan,shuaiqi}. In particular, consider $f(x)$ is the received signal strength with RIS phase shifts and $g(x)$ represents interference and noise, then FP can decouple $f(x)$ and $g(x)$ in the SINR terms as indicated by equation (\ref{eq-fp7}).




\begin{figure}[!t]
\centering
\setlength{\abovecaptionskip}{-3pt} 
\includegraphics[width=0.8\linewidth]{Image/fig-bb.jpg}
\caption{Using BnB for RIS control with discrete phase shifts.}
\label{fig-bb}
\vspace{-15pt}
\end{figure}








\begin{table*}[!t]
\caption{Summary of model-based optimization algorithms for RIS-aided wireless networks }
\centering
\setstretch{1.05}
\small
\resizebox{1\textwidth}{!}{%
\begin{tabular}{|m{1cm}<{\centering}|m{3.7cm}<{\centering}|m{3.6cm}<{\centering}|m{3cm}<{\centering}|m{3cm}<{\centering}|m{4.6cm}<{\centering}|}
\hline 
Methods &  Main features   &     Advantage    &  Drawbacks    &  Difficulties   &  Application \qquad \qquad \qquad scenarios  \\
\hline
AO & Decoupling the joint optimization into multiple sub-problems, and alternatively optimizing each sub-problem.   &  The problem-solving complexity is greatly reduced. Each sub-problem may be easier to solve.  & Iterative optimization may lead to sub-optimal results; the convergence must be proved. &  The complexity is high when each sub-problem is still complicated.  & AO is the most widely applied optimization scheme for RIS-related optimization; it applies other algorithms to solve the sub-problems\cite{chongwen}.  \\
\hline
BCD &  The control variables are divided into multiple blocks. Minimizing one block in each iteration and keeping other blocks fixed.  & Cheap iteration costs; low memory requirements; potential for parallel implementation   &   Block selection may affect the BCD performance, and block updating is difficult in some cases.  &  Block selection and updating methods are complicated.  & BCD is deployed as an alternative optimization scheme to reduce joint optimization complexity, e.g., sum-rate maximization \cite{cunhua,jiey,huayan}, power minimization \cite{zhiyang}, user fairness \cite{gang,xianghao2}     \\
\hline
MM & Iteratively constructing and optimizing an upper bound surrogate function that can locally approximate objective functions. &  Avoiding the complexity of optimizing non-convex objective functions directly.  &  The surrogate function must be a strict tight upper bound for objective functions, which is hard to achieve in practice.   &  The surrogate function must follow the shape of objective functions and meanwhile be easy to optimize.  &  A low-complexity solution for many RIS-aided optimizations, i.e., sum-rate maximization\cite{cunhua}, fairness maximization\cite{menghua,guiz}, secure transmission\cite{xianghao2,huiming2}.    \\
\hline
SCA & Constructing and optimizing surrogate functions iteratively to estimate the objective function.  & Low computational complexity; the tight upper bound is not required for the surrogate function; naturally implemented in a distributed manner.  &  The step size selection is critical for an accurate approximation.  &  Surrogate function and step size selection.  &  SCA is more frequently used in RIS-related optimizations than MM, e.g., sum-rate maximization\cite{ming,yuanbin,xidong}, power minimization\cite{huimei,jianyue}.     \\
\hline
SDR & SDR is used to solve QCQP problems by relaxing the rank constraint. Then the reformulated problem is efficiently solved by SDP. & Given the objective problem, SDR is easily implemented without extra parameters or settings. & Approximation is required if the relaxed solution is not rank one.  &  The reformulated problem is complicated if the achieved solution is not rank one. & SDR is particularly useful in RIS-related optimization problems, since the $rank(x)=1$ is frequently formulated for phase control \cite{boya} \cite{peilan,qingqing,guizhou2}.         \\
\hline
SOCP & SOCP utilizes the property of the second-order cone, and many problems are reformulated into SOCP, which is much easier to be solved.  & SOCP can be efficiently solved by many existing algorithms. It has a lower complexity $O(n^2\sum_{i}{n_i})$ than SDR.  &  Problem reformulation into SOCP is complicated.  &  The main difficulty lies in how to reformulate the original problem into SOCP.  & SOCP has been used for power minimization \cite{yiqing} and user fairness \cite{guiz,hailiang,menghua}.     \\
\hline
FP & FP refers to optimization problems that involve fractional terms, which is very useful for wireless communications considering the form of SINR and energy efficiency.  & FP is easily implemented without extra parameters or problem formulation requirements.  &  The reformulated problems generally require iterative optimization to approximate the solution of original FP problems.   & Compared with single-ratio problems, wireless communications are more related to sum-ratio problems, which are more complicated to solve.   & FP is widely applied in RIS-aided wireless network optimizations due to the form of SINR and energy efficiency \cite{huayan,jianyue,chongwen,linsong}.     \\
\hline
BnB & BnB is mainly designed for combinational optimization problems. It applies a tree to enumerate all possible subsets and sub-problems.  &  Lower complexity compared with direct optimizations. The solution quality is controlled by deploying customized search, branching, and pruning rules.  &  The algorithm is slow when constantly searching or branching in the worst case.   &  The algorithm performance relies on the searching and pruning method, which is hard to select in some cases.  &  BnB is mainly applied for discrete and combinational optimization problems, i.e., RIS on/off and discrete phase shift\cite{shiqi,qingqing2,boya}.      \\
\hline
\end{tabular}}
\label{tab-comparison}
\vspace{-13pt}
\end{table*}



\subsection{Branch-and-Bound } 

BnB is a classic scheme for combinatorial and discrete optimization problems\cite{clau}. To minimize $f(x)$ with $x\in \mathscr{X}$, BnB applies a tree scheme to enumerate all possible subsets $X_{i} \subseteq \mathscr{X}$, and each subset $X_{i}$ indicates a sub-problem $f_{i}(x)$. Solving sub-problems $f_{i}(x)$ will generate and prune branches based on the estimated lower and upper bounds.  

BnB algorithm consists of three basic operations: branching, bounding, and pruning.
Consider a non-linear integer programming problem, and BnB scheme is summarized as Fig. \ref{fig-bb}. It produces a series of sub-problems $f_{i}(x)$ that are equivalent to the original $f(x)$, which is much more efficient than brute-force enumeration.         
BnB algorithm provides an alternative solution for challenging problems that cannot be solved directly. An important advantage is that the quality of the solution is controlled by customized searching, branching, and pruning rules. On the other hand, it can be slow if constantly searching and branching, learning to exponential worst-case performance. 

BnB is mainly applied for RIS control with discrete phase shift, including sum-rate maximization \cite{boya}, power minimization \cite{qingqing2}, and max-min SINR \cite{shiqi}. The main reason is that the problem formulations are usually MINLP problems, which are NP-hard and intractable. As shown in Fig. \ref{fig-bb}, the MINLP is converted into an 0-1 integer linear programming using the special ordered set of type 1 (SOS1) transformation \cite{qingqing2} and reformulation-linearization \cite{shiqi}. 



\subsection{Analyses and Discussion}

Table \ref{tab-comparison} summarizes model-based algorithms for RIS-aided wireless networks, including main features, advantages, disadvantages, difficulties, and application scenarios. 

Firstly, considering the high complexity of RIS-related optimization, AO is regarded as the primary scheme to decouple the joint optimization problem into several sub-problems. Then, each sub-problem is alternatively solved by using different algorithms, e.g., SCA, SDR, and BnB. BCD algorithm applies the same alternative optimization scheme, but one block may include multiple variables, which is more efficient for problems with a large number of control variables. 

MM and SCA are two estimation-based algorithms that avoid the complexity of direct optimizations. Compared with MM, SCA relaxes the upper bound requirement for surrogate functions, but the step size selection may affect the solution quality. MM and SCA are usually considered low-complexity solutions for RIS-aided wireless network optimizations. 

SDR and FP are usually combined with other techniques for optimizations. SDR is mainly used to relax the RIS phases constraint, while FP can decouple the numerator and denominator for SINR and energy efficiency. These two techniques reformulate the original problems into low-complexity or even convex forms, then other techniques can be applied. SOCP takes advantage of the property of the second-order cone, which is efficiently solved by many existing methods. But the main difficulty is how to transform the problem with logarithm and fractional terms into a second-order cone. BnB is mainly designed for combinational and discrete optimization problems, e.g., RIS control with discrete phase shifts and elements on/off.

Finally, it is worth noting that these algorithms are not independent, and multiple algorithms are usually combined for transformation and optimizations. The main objective of Table \ref{tab-comparison} is to analyze the feasibility of these problems for various RIS-related optimizations, and the most efficient solution for specific scenarios requires case-by-case analyses. 

