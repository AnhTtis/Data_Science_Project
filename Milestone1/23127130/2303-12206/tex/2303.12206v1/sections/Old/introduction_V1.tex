%!TEX root=../Draft1.tex

%\textbf{P1: Proliferation of technological services aimed at improving behavioral health}\\
For most health conditions, long-term outcomes are determined not only by clinical interventions but also by individual habits and behaviors (CITE). 
A range of behavioral health interventions---often delivered through digital platforms---have been introduced to improve outcomes for various health conditions, usually by affecting users' habits through motivation, education, nudging, or boosting (CITE ruggeri).
%Some behavioral health platforms aim to support clinical interventions (e.g., medication adherence, CITE), while others focus on more general wellbeing (e.g., dieting, meditation, sedentary habits, CITE).

%Some behaviors that contribute to health outcomes are strongly linked with clinical interventions (e.g., medication adherence), while others focus on more general wellbeing (e.g., dieting, meditation, sedentary habits). With the enhanced emphasis on non-clinical determinants of outcomes in the healthcare and health policy community, the supply of digital (usually mobile phone-based) applications to support behavioral health has increased, with recent estimates indicating that over 200 thousand applications are available to smartphone owners \citep{carlo2019numbers}, usually aimed at affecting behavior through motivation, education, nudging, or boosting (CITE ruggeri).

%\textbf{P2: Personalization of those services; how and when to reach out.}\\
While digital behavioral health platforms differ in the targeted behavior change or underlying clinical condition, they share the fundamental operational challenge of personalizing and targeting costly interventions. Most of them rely on a suite of interventions, from automated ones (e.g., reminders and push notifications) to manual ones (e.g., phone calls or messages from agents). Delivering both types of interventions is costly, from the platform's perspective---manual interventions are operationally costly since they require human resources and automated interventions can result in notification fatigue among users (even if delivering them is operationally cheap). As a result, behavioral health platforms face a need to optimize the timing and content of outreach to each patient, in order to ensure the right patient receives the right intervention at the right time. 

%For maximal impact, the timing and targeting of both automated and manual interventions must be optimized. Even if automated interventions are cheap to deploy, the timing of deployment is important to induce the desired behavioral response and avoid notification fatigue. Manual outreach is usually more resource intensive which constrains the level of feasible outreach. 

%\textbf{P3: The general setting prior to personalization analysis}\\
Most digital behavioral health platforms are initially launched with heuristic rules of thumb guiding the timing of outreach to each user.
During such pilot implementation, the platform then conducts regular data collection from users, aimed at identifying whether they are in a state of compliance with a desired behavior (e.g., medication adherence, exercise routine, correct diet) or not. Such data is usually used to establish an overall average effectiveness of the suite of interventions. Subsequently, the behavioral data collected during a pilot implementation---even if generated using a sub-optimal initial outreach heuristic---opens the door for data-driven optimization for the development of improved outreach policies. 
In this paper, we address exactly that question: how can observational data---describing a heuristic baseline policy for intervention as well as patient responses---be leveraged to develop improved targeting of interventions? 

Reinforcement Learning (RL) represents one natural approach to optimizing interventions. A salient feature of RL algorithms is their {\em model free} nature and the limited assumptions required for user behavior. While this is indeed beneficial, typical RL algorithms also engender certain traits that render them problematic in healthcare settings. First, policy makers or platform operators are naturally risk averse and as such must worry about the risk that a reinforcement learning algorithm materially deteriorates performance over the short run, even if it `eventually' learns an optimal policy. Second, online experimentation is often not desired or feasible. From a statistical perspective, the sample complexity of learning optimal policies can be large in settings where user behavior is inherently high dimensional. In addition, the ability to `experiment' or `explore', which is essential to such learning, is limited in healthcare settings. This latter limitation arises for multiple reasons including limited time horizons, limited data availability, as well as ethical considerations.

In this paper, we seek to leverage the promise of reinforcement learning for the task of intervention optimization while attempting to mitigate the aforementioned challenges.
To this end, we partner with a behavioral health startup, \textit{Keheala}, that promotes medication adherence for patients who have been prescribed TB treatment and fits the above description. 
First, their digital platform comprises a suite of automatic or on-demand interventions (reminder notifications and access to general TB information) as well as manual interventions (support sponors, employed by Keheala, will also make phone calls to patients to support treatment adherence). A unique featuer of the service is that it requires patients to self-verify daily treatment adherence using the digital platform. 
Second, the effectiveness of the service has been established through an RCT (for more details on the trial and data, see \S XX), in which the outreach policy was a one-size-fits-all heuristic by which support sponsors should call patients who had not verified treatment adherence for two consecutive days. 
Third, following the initial implementation, in the RCT, their current challenge is to use the data collected using the outreach heuristic to develop a more targeted and personalized outreach policy for the future scale-up of the system to a larger population. 
%The challenge facing Keheala is therefore a special case of the question stated above: can the data from the randomized controlled trial---in which support sponsors reach out to patients after two consecutive days of non-verification---inform an optimized policy for allocating the expensive and limited resource of support sponsor outreach?

%\textbf{P5: Description of our work. First theory, then practice.}\\
We make theoretical and practical progress towards answering this question. From a theoretical perspective, we first formulate a simple Markov Decision Process (MDP) model of patient behavior. This general model captures the salient features of many behavioral health situations, namely that patients alternate between being in a desired state (e.g., adhering to medication, following dieting guidelines, or exercising) and relapsing to an undesired state in which they are not following the recommended behavior. A behavioral health intervention can enhance patients' motivation for shifting from the undesired state to the desired one. In accordance with the general setting, described above, we observe the state of each patient over time and allow transition rates between states and intervention effects to be patient specific. 
Using this model, we first define two benchmark policies: $\BASE$ denotes the null-policy of never reaching out to patients while $\OPT$ refers to an optimal policy that maximizes the number of days patients spend in the desired state. We then introduce a \textit{Decomposed Policy Iteration}... V function and Q function [fill in].
This approach can be thought of as a one-step policy iteration, a main differentiator from standard policy iteration is that it decomposes to the patient level and thus removes the dependence on the exponentially sized action space. 
We prove that, relative to $\BASE$, the $\DPI$ policy achives at least half of the improvement attainable by the theoreatical upper bound of $\OPT$, in terms of days spent in the desired state. This is a significantly stronger performance guarantee than the standard 2-approximation result (see discussion in \S XX) since it refers to the marginal impact over and above the base policy $\BASE$ of doing nothing, even in settings (such as ours) where patients may stay in the desired state for many periods in the absence of any intervention.

From a more practical perspective, we move beyond the stylized MDP model of patient behavior and develop a modified version of the $\DPI$ policy which relaxes three key assumptions needed for the theroetical performance guarantee which might be violated in practice. 
First, the patient-level transition rates of the MDP will not generally be known in practice and are difficult to estimate. 
Second, patient behavior might not be static in practice, as many external factors affect behavior over time. For those two reasons, we extend the state space of each patient by incorporating  observable features that are predictive of adherence, to dynamically estimate the inputs of our policy directly from data in a model-free way. 
Finally, while our theoretical performance guarantee assumes a one-step policy iteration over the $\BASE$ policy of doing nothing to arrive at our $\DPI$ policy, the field data we have access to is for the existing one-size-fits-all heuristic employed in the original RCT. As a result, we perform the one-step iteration over and above that heuristic, to arrive at an improved practical policy. 

To evaluate the performance of this practical policy, we develop and validate a simulation model for patient behavior, based on the data collected in the RCT. We then conduct counterfactual simulations comparing various policies and demonstrate that our approach results in ...[fill in].

%\textbf{P6: Broader contributions to academic literature and managerial knowledge}\\
Our work contributes to both the academic literature on personalized behavioral health as well as the practical design of digital platforms aiming to support behavior change to improve health outcomes. From an academic perspective, multiple approaches have been suggested for similar problems (for a detailed literature review, see \S \ref{s.litreview}). One approach is to apply bandit algorithms, which aim to maximize short-term patient engagement but fail to incorporate the long-term impact of outreach. Another approach is to posit a simple Markov-Decision-Process (similar to our initial model, presented in \S \ref{s.model}) and try to learn its transition rate, but such approaches are susceptible to modeling error and non-stationarity. A third approach is to apply standard RL methods (e.g., Q learning). Such algorithms are not only hard to implement in a field setting but also suffer from the problem's sample complexity, requiring a long exploration period for each patient, which is not only undesirable in a sensitie healthcare setting but also not guaranteed to result in a good policy within the time horizon of a single patient's treatment regimen. In contrast, our approach uses existing data in a model free way to develop a policy with performance guarantees that can be learned through a one-step on-policy iteration and applied to a new cohort of patients without exploration. 
From a practical standpoint, we demonstrate the effectiveness of our approach using a validated simulation model based on real date. The approach is general and easily implementable by any organization wishing to improve long-term engagement with their digital services, as long as it has access to an initial dataset (e.g., from a pilot implementation).








