
This work tackles an important problem of personalizing and optimizing costly interventions in the context of digital systems for behavioral health.  
We develop an approach, $\DPI$, that learns an intervention policy from an existing dataset collected from a pilot study.
 $\DPI$ is model-free, which avoids the need to specify a model of patient behaviors.
Unlike many reinforcement learning methods which often rely on a long horizon to achieve good performance, $\DPI$ leverages offline data to immediately provide an effective policy.
We provide a theoretical guarantee on a special case of the model that is a stylized representation of the practical setting of interest, and it exhibits strong empirical performance on a validated simulation model of a real-world behavioral health setting.



\subsection{Managerial Implications}
\added{The operational settings that could benefit most from our work are those resembling our motivating example of \textit{Keheala}. In other words, consider an organization that has designed a protocol for a new behavioral program, by which some subjects are eligible for a costly intervention. A pilot implementation of this program reveals severe resource limitations such that it is infeasible to provide the intervention to all eligible subjects. During this pilot, the organization provides the intervention in an ad hoc manner (among eligible subjects) and collects data on engagement and outcomes. Our analysis reveals that as long as the ad hoc provision of the intervention during the pilot phase is practically random (e.g., if the intervention is delivered based on a call list that is alphabetical), $\DPI$ can be used to improve performance in subsequent deployment or scale-up, through additional targeting within the set of eligible subjects. Furthermore, our theoretical and numerical analysis consistently demonstrate that the value of $\DPI$ increases as the available resources become more limited, which is important since (as we discuss in \cref{s.intro}) algorithms that rely on online experimentation can be inefficient or even counterproductive in such settings. 

The above description clearly does not apply to all behavioral health settings, but we believe it is relevant for many new initiatives that are being designed, piloted, and scaled-up. In particular, we believe $\DPI$ can be valuable for interventions that aim to serve disadvantaged groups or regions since those inherently face more stringent resource limitations.}

\subsection{Limitations and Future Directions}
Lastly, we discuss limitations of the current work that serve as valuable future directions.
One gap between our model and the practical application of Keheala is that the ultimate objective of Keheala is to improve eventual health outcomes (i.e., cure patients of TB).
There are two major hurdles that need to be addressed in order to fully align with this goal, within the existing infrastructure of Keheala (of using daily adherence information).
The first obstacle is the lack of a mapping between treatment adherence patterns to health outcomes.
It has been shown that higher verification rates are associated with better outcomes \citep{Boutilier22Improving}
but it would be valuable to identify more specific and causal relationships (e.g., is it more important for a patient to adhere to their treatment in the earlier phase of their treatment regime compared to later?).
Addressing this issue is very specific to TB but would be tremendously valuable not only for optimizing a platform like Keheala, but also for the broader medical research on TB.
Second, a problem less specific to TB, is to design policies that can optimize for reward functions which are not necessarily additive for each time step (e.g., maximize the number of patients whose overall verification percentage is over 70\%).

Next, there are other interesting extensions to the model and the algorithm that one can consider.
With respect to performance guarantees on the stylized model in \cref{s.theory}, it would be valuable to analyze how the guarantee is impacted by various modeling extensions such as generalizing the MDP (e.g., more states, having interventions impact all states) or extending the class of baseline policies. 
From an algorithmic standpoint, valuable extensions include incorporating online samples, and incorporating other practical considerations such as fairness in how the interventions are distributed across patients. \added{Finally, even if the time horizon for TB treatment is determined by the drug regimen length, one can imaging other behavioral health situations in which the time horizon used to calculate the intervention value for each subject is endogenous to their prior behavior, such that increased engagement results in reduced likelihood of leaving the service.}



