
\subsection{Proof of \cref{prop:dpi_can_be_worse}} \label{s.proof_dpi_worse}
We describe an instance where $\pi_0$ is an optimal policy, but $\DPI(\pi_0)$ is a suboptimal policy.
Consider the following instance of the two-state MDP model from \cref{ss.2statemodel}.
There are $N=3$ patients, where the first two patients have parameters $p_i = 0, \tau_i = 0.01, g_i = 0$ for $i=1, 2$, and the third patient has parameters $p_3 = 0, \tau_3 = 0.01, g_3 = 0.1$.
When patients 1 or 2 goes to state 1, they stay there indefinitely, while patient 3 does not (since $g_3 > 0$). 
Since all other parameters are the same, the value of an intervention is strictly higher for patient 1 and 2, versus patient 3.

Suppose all patients start at state 0, and there are $T=5$ time steps.
Let $\pi_0$ be a policy that assigns at most one intervention per time step defined using the following rules:
\begin{itemize}
  \item If both patients 1 and 2 are in state 0, assign it to one of them uniformly at random.
  \item Otherwise, if either patient 1 or 2 is in state 0, assign them an intervention.
  \item If neither patient 1 or 2 are in state 0, then assign an intervention to patient 3.
\end{itemize}
Notice that $\pi_0$ is the optimal policy.
However, $\DPI(\pi_0)$ ends up being a suboptimal policy.
At time $t=3$, the intervention value for patient 3 is $z_{33}^{\pi_0}(0)=0.029$, whereas the intervention value for patient 1 and patient 2 is $z_{13}^{\pi_0}(0)=z_{23}^{\pi_0}(0)=0.010$.
Therefore, at time $t=3$, the intervention value for patient 3 is higher than that of patient 1 or 2, and hence $\DPI(\pi_0)$ will (suboptimally) prioritize patient 3 at time 3.

The reason for this behavior is that under $\pi_0$, the only time that patient 3 receives an intervention at time 3 is in the unlikely event where both patient 1 and 2 are in state 1 at time 3.
When this event occurs, since patients 1 and 2 stay in state 1 indefinitely, patient 3 is also guaranteed to receive an intervention at time $t=4$ (if they did not switch to state 1 by then).
Then, the $q$-value for patient 3 at time 3, $q^{\pi_0}_{33}(s=0, a=1)$, 
incorporates the fact that they will \textit{also receive an intervention at time 4}.
Therefore, the intervention value, $z_{33}^{\pi_0}(0)$ effectively represents the increase in reward when patient 3 is given interventions at both time 3 and 4, and hence is higher than the intervention value for patient 1 and 2.
This behavior stems from the fact that $q^{\pi_0}_{33}(s=0, a=1)$ does not contain information regarding the fact that under $\pi_0$, patient 3 only receives an intervention under a very specific \textit{system} state. 


\added{
\subsection{Proof of \cref{thm:improvement_random}} \label{s.proof_improvement_random}
Let $\pi_0 = \RAND(\gamma)$ and let $\pi_1 = \DPI(\RAND(\gamma))$.
For any system policy $\pi$, let $V_t^{\pi}$ and $Q_t^{\pi}$ denote the system value function and the system Q-function respectively for the system MDP under policy $\pi$:
\begin{align*} 
V_{t}^\pi(\tilde{\bS}) &= \bE_{\pi}\left[\sum_{t'=t}^T \sumN R(S_{it'}^\pi, S_{i,t'+1}^\pi, A_{it'}^\pi) \;\bigg|\; \bS_t^\pi = \tilde{\bS} \right], \\
Q_{t}^\pi(\tilde{\bS}, \tilde{\bA}) &= \bE_{\pi}\left[\sum_{t'=t}^T \sumN R(S_{it'}^\pi, S_{i,t'+1}^\pi, A_{it'}^\pi) \;\bigg|\;  \bS_t^\pi = \tilde{\bS},  \bA_t^\pi = \tilde{\bA} \right].
\end{align*}
With this notation, we have that $\RAND(\gamma) = V_1^{\pi_0}(\bS_1)$ and $\DPI(\RAND(\gamma)) = V_1^{\pi_1}(\bS_1)$, where $\bS_1$ is the initial state that specified by the instance.
Our goal is to show $V_1^{\pi_1}(\bS_1) \geq V_1^{\pi_0}(\bS_1)$.

Note that under the policy $\pi_0 = \RAND(\gamma)$, the actions $A_{it}$ are independently chosen for each patient $i$. 
Therefore, the system value function and the Q-functions can be decomposed as:
\begin{align*} 
V_{t}^{\pi_0}(\tilde{\bS}) = \sum_{i=1}^N \big(\gamma q_{it}^{\pi_0}(\tilde{S}_{i}, 1) + (1-\gamma) q_{it}^{\pi_0}(\tilde{S}_{i}, 0) \big), \quad
Q_{t}^{\pi_0}(\tilde{\bS}, \tilde{\bA}) = \sum_{i=1}^N q_{it}^{\pi_0}(\tilde{S}_{i}, \tilde{A}_{i}).
\end{align*}
For a system state $\bS$, let $\bA_t^{\pi_1}(\bS) \in \{0, 1\}^N$ be the action that $\pi_1$ chooses at state $\bS$ at time $t$.
We claim that under any state, it is better to take the action from $\pi_1$ and then continue with $\pi_0$ henceforth, compared to just following $\pi_0$.
\begin{claim} \label{claim:improvement}
For any state $\tilde{\bS}$ and any $t$, $Q_{t}^{\pi_0}(\tilde{\bS}, \bA_t^{\pi_1}(\tilde{\bS}) ) \geq V_{t}^{\pi_0}(\tilde{\bS})$.
\end{claim}

\begin{myproof}[Proof of \cref{claim:improvement}]
Recall that $z^{\pi_0}_{it}(s) = q_{it}^{\pi_0}(s, 1) - q_{it}^{\pi_0}(s, 0)$.
Then, we can write the value function $V_{t}^{\pi_0}(\tilde{\bS})$ as
\begin{align*}
V_{t}^{\pi_0}(\tilde{\bS}) &= \sum_{i=1}^N q_{it}^{\pi_0}(\tilde{S}_{i}, 0) + \gamma \sum_{i=1}^N  z^{\pi_0}_{it}(\tilde{S}_i).
\end{align*}
Similarly, we can write $Q_{t}^{\pi_0}(\tilde{\bS}, \bA_t^{\pi_1}(\tilde{\bS}))$ as
\begin{align*}
Q_{t}^{\pi_0}(\tilde{\bS}, \bA_t^{\pi_1}(\tilde{\bS})) &= \sum_{i=1}^N q_{it}^{\pi_0}(\tilde{S}_{i}, 0) + \sum_{i: \bA_t^{\pi_1}(\tilde{\bS})_i =1}  z^{\pi_0}_{it}(\tilde{S}_i).
\end{align*}
Note that by definition of $\pi_1$, $\bA_t^{\pi_1}(\tilde{\bS})_i =1$ for patients $i$ with the $B$ highest values of $z^{\pi_0}_{it}(\tilde{S}_i)$.
Since $B \geq \gamma N$, we have that $\sum_{i: \bA_t^{\pi_1}(\tilde{\bS})_i =1}  z^{\pi_0}_{it}(\tilde{S}_i) \geq \gamma \sum_{i=1}^N  z^{\pi_0}_{it}(\tilde{S}_i)$.
Therefore, $Q_{t}^{\pi_0}(\tilde{\bS}, \bA_t^{\pi_1}(\tilde{\bS})) \geq V_{t}^{\pi_0}(\tilde{\bS})$.
\end{myproof}

We leverage the claim to show that $V_1^{\pi_0}(\bS) \leq V_1^{\pi_1}(\bS)$ for any $\bS$, which finishes the proof.
\begin{align*}
V_1^{\pi_0}(\bS) 
&\leq Q_{1}^{\pi_0}(\bS, \bA^{\pi_1}(\bS)) \\
&=\bE_{\bS' \sim P(\bS, \cdot, \pi_1)}\left[ \sum_{i=1}^N R_i(S_{i}, S'_{i}, \bA_1^{\pi_1}(\bS)_i) +  V_{2}^{\pi_0}(\bS') \right] \\
&\leq \bE_{\bS' \sim P(\bS, \cdot, \pi_1)}\left[ \sum_{i=1}^N R_i(S_{i}, S'_{i}, \bA_1^{\pi_1}(\bS)_i) +  Q_{2}^{\pi_0}(\bS', \bA^{\pi_1}(\bS')) \right] \\
&= \bE_{\bS' \sim P(\bS, \cdot, \pi_1), \bS'' \sim P(\bS', \cdot, \pi_1)}\left[ \sum_{i=1}^N R_i(S_{i}, S'_{i}, \bA_1^{\pi_1}(\bS)_i) +  \sum_{i=1}^N R_i(S'_{i}, S''_{i}, \bA_2^{\pi_1}(\bS')_i) +  V_{3}^{\pi_0}(\bS'') \right] \\
&\leq \ldots \\
&\leq \bE_{\bS' \sim P(\bS, \cdot, \pi_1), \bS'' \sim P(\bS', \cdot, \pi_1), \dots}\left[ \sum_{i=1}^N R_i(S_{i}, S'_{i}, \bA_1^{\pi_1}(\bS)_i) +  \sum_{i=1}^N R_i(S'_{i}, S''_{i}, \bA_2^{\pi_1}(\bS')_i) +  \dots \right] \\
&= V^{\pi_1}_1(\bS).
\end{align*}
}
