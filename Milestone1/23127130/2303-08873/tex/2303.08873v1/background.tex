\section{Background}
\label{sec:background}

\begin{table}[!ht]
    \caption{The Apollo API}
    \centering
    \input{tables/apollo_api}
    \label{tab:apollo_api}
\end{table}

\textbf{Existing OpenMP adaptation}
In brief, OpenMP 5.0~\cite{openmp5.0} introduced variant directives, such as \code{metadirective} and \code{declare variant}, to support performance portability by adapting OpenMP pragmas and user code at compile time. 
The OpenMP context, which consists of traits from active OpenMP constructs, devices, implementations or user-defined conditions, can be used to specify adaptation by matching those traits to specified properties to select applicable variants for compilation and execution.
OpenMP 5.0 supported only matching compile-time conditions on traits, OpenMP 5.1~\cite{openmp5.1} extended that to include runtime user-defined conditions. 

\begin{listing}[!t]
\centering
\input{figures/vecAdd_existing_openmp}
\caption{Vector addition using existing OpenMP adaptation.}
\label{fig:example_existing_openmp}
\end{listing}

Of particular interest in this work is the OpenMP metadirective since we enhance its functionality through our adaptive OpenMP extensions.
In more details, the OpenMP metadirective supports selecting different \emph{directive variants} depending on conditions over OpenMP context traits. 
It accepts \code{when} clauses that specify the condition through a \emph{context selector specification} and the directive variant that applies when that condition evaluates as true.

As an example, Listing~\ref{fig:example_existing_openmp} shows a code excerpt using a metadirective to select CPU or GPU execution of a code region implementing a simple vector addition dependent on the vector size.
The metadirective in lines~\ref{ex1:begin}--\ref{ex1:end} specifies different directive variants depending on the vector size \code{N}: when \code{N} is less than the fixed threshold of 1024 elements, the kernel executes on the CPU as a worksharing loop, otherwise it executes on the GPU with an offloading directive.
Compilation of the metadirective generates code for both directive variants and the one actually executing at runtime will be conditional to the value of \code{N}.

Although this existing formulation of adaptation in OpenMP provides useful functionality, it does not address the challenge of dynamically determining what is the appropriate condition, such as the specific threshold on vector size of the example, for the adaptation of a specified code region.
Determining that manually is time consuming and error prone. 
The developer must explore the configuration space, including hardware architecture configurations and possible inputs, collect profiling data, and integrate those findings to some kind of model that will at runtime optimize variant selection.
Our OpenMP extensions address those shortcomings by automating code variant generation, data collection and model building, requiring only from the user to provide a set of input features and possible variants.

\textbf{Prior proposed OpenMP adaptation extensions.}
Previous work~\cite{LiaoExtending2021} attempts to enable adaptation exclusively for the metadirective in OpenMP.
It proposes a \code{declare adaptation} directive bound to a subsequent metadirective and requires the user to provide a set of features to define a machine learning model for selecting one of the metadirective's variants.
However, binding adaptation exclusively to metadirectives limits its applicability only to adaptation possibilities expressed through metadirective variants.
Furthermore, it introduces forward and backward dependencies when the adaptation model of a \code{metadirective} affects other code regions outside the bound metadirective, limiting possible adaptation.

In our approach, we design a new adaptation directive that is self-contained, proposing a producer-consumer pattern for adaptation.
Our new adaptation directive produces an adaptation model, given a set of features and a set of variants, disassociated from an explicit metadirective, supporting both multiple OpenMP metadirectives and other code regions as consumers of the model output.
This design enables much greater flexibility by avoiding the expressivity limitations of previous work and the proneness to hard-to-resolve dependencies.
Notably, use-cases, presented later, that require coordinated adaptation of multiple code regions are infeasible or impractical in previous work.

\textbf{Apollo Tuning API and Runtime.}
Apollo~\cite{beckingsale2017apollo,wood2021artemis} is a state-of-the-art, machine-learning based, tuning library that
enables users to instrument code for defining tunable regions, specifying input features for the region and an abstract set of variants -- called \emph{policies} in Apollo terminology -- to express possible tuning choices.
Apollo comes with a runtime library to implements its API, internally collecting profiling data and supporting training of different machine-learning models using those data. 
Table~\ref{tab:apollo_api} briefly describes the API calls and their functionality, while
Listing~\ref{fig:example_apollo} uses Apollo for adaptation, selecting the execution device on the vector addition kernel without a fixed threshold.

\begin{listing}[!t]
\input{figures/vecAdd_apollo}
\caption{Vector addition adaptation using Apollo}
\label{fig:example_apollo}
\vspace{-0.5em}
\end{listing}

In this formulation, the user creates the region once (lines~\ref{ex2:create:begin}--\ref{ex2:create:end}) using vector size as the feature, enumerating CPU or GPU execution as the possible policies, and requesting training a DecisionTree model using RoundRobin exploration of policies for collecting training data.
Specifically, the Apollo runtime cycles the possible policy variants for exploration and trains a decision tree model once at least 10 unique profiling data points are collected -- uniqueness is defined as collecting profiling data of different features and variants.
Calls to the Apollo API in lines~\ref{ex2:apollo:begin}--\ref{ex2:apollo:end}, begin the region execution in Apollo, and query the runtime to obtain the execution policy.
Lines~\ref{ex2:cond:begin}--\ref{ex2:cond:end} implement CPU or GPU execution, conditional on the execution policy choice.
Lastly, line~\ref{ex2:region:end} indicates the end of region execution in Apollo.

Profiling data collected by Apollo measure elapsed execution time between pairs of begin/end calls, stored in a persistent database of per region records.
Apollo, either at runtime or post-execution, finds the fastest execution policies per feature values from those records to train machine learning models for predicting the optimal policy choice, given a region and a set of possibly unseen features.

Apollo provides useful infrastructure for adaptation through its API, however it is completely agnostic of OpenMP.
Extending an OpenMP program for adaptation through Apollo will require non-trivial effort for instrumenting different parts of the code and customizing the implementation.
Compared to directly using the Apollo API, our adaptive OpenMP programming model enhances programmability by
abstracting instrumentation, necessarily explicit in Apollo, and by leveraging the compiler to generate different code variants when composed with the OpenMP \code{metadirective}.
Nevertheless, in our Clang/LLVM implementation of OpenMP adaptation we target the Apollo runtime library API in code generation to leverage its infrastructure, noting that it is possible to port our adaptive OpenMP to other runtime implementations that conform to the proposed semantics.

