\section{Limitations and Challenges}

In this section we discuss two of the main challenges of adaptive execution.

\subsection{Selecting features}
The proposed approach provides an easy-to-use programming model for developers to adapt their application execution and select optimal variants that the application's minimize execution. 
The approach requires the developer to identify a set of \emph{feature} variables that strongly correlate with the execution time of the adaptive region. 
In this work, we investigate \emph{feature} variables dependent on the application's input that control the computation complexity of a region, such as the number of parallel iterations to perform. 
We show empirically in our evaluation that this selection of \emph{feature} variables suffices for beneficial adaptation as a guideline.
Nevertheless, the benefit and accuracy of adaptation resides on domain-specific knowledge of the developer to select useful features in our adaptive approach.
However, there are algorithms for which it is hard or impractical to identify \emph{feature} variables that strongly correlate with the execution time of a code region. 
For example, the number of iterations required for the Conjugate Gradient (CG) algorithm to converge strongly depends on the condition number of the linear system being solved. 
In practice, a faithful estimate of the condition number may be not be easily attainable during an application execution and precluding it as a feature degrades possible adaptation.
Nonetheless, \emph{feature} values such as the dimensions of the underlying linear system or perhaps a rough estimate of the condition number, can still provide practical information for adaptation to enable higher performance.

\subsection{Profiling data collection for model training}
Our approach requires collecting a minimum number of profiling data points to train an adaptation model. 
Depending on the use-case, this data collection phase may require multiple application runs.
To effectively train an adaptation model, the user should identify representative inputs of the typical use cases of the application and its performance to collect useful data, similar to profiling-guided optimization techniques. 
Using the selection of execution device (CPU or GPU) as an example for \emph{AMGMk}, shown in Figure~\ref{fig:cpu_gpu_results}, the adaptive model will require profiling data from both small and larger input dimensions to train an effective model that generalizes to unknown inputs.
There are two options to tackle this challenge.
Either the user performs on purpose a set of training runs using representative inputs to cover the domain, which requires some manual effort and time spent for the training runs.
Or, the user completely delegates data collection to adaptive execution by specifying a possibly large minimum number of training data to be collected, which assumes running the application in a production setting will capture the desired adaptation effects with acceptable overhead of exploration on the possible, specified variants.
We favor the latter case, which requires minimal user intervention, and believe Bayesian optimization approaches to explore the variant space will be promising to reduce exploration overhead while providing effective adaptation for high performance.
