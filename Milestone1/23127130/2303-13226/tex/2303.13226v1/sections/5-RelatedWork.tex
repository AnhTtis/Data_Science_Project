%% 首先FTL中的地址映射研究工作，归纳总结三种并说明在此基础上都是基于局部性进行优化改进；
%% 分析局部性的研究对于随机负载下的读没有作用，必然引起二次读降低性能，而随机读又是闪存固态盘中非常重要的一类访问负载；
%% 说明Learned Index的研究进展，包括其在LSM树等存储领域的应用，突出其效应，从而引出是否可以用在闪存的FTL中，也就是本文的工作，是第一个尝试这么做的。我们受到的启发是Learned Index可以有效，希望能带动更多的人来做这个方向和尝试

\section{Related Work}
\label{related}

\vspace{-5pt}

\subsection{Mapping Schemes in FTL Design}\vspace{-5pt}

Existing address mapping schemes in flash-based SSDs can be classified into three categories: (1) page-level mapping, (2) block-level mapping, and (3) hybrid mapping. A survey paper~\cite{FTLSurvey} provides a broad overview of some typical address translation technologies for flash memories~\cite{gupta2009dftl,qin2011two,jiang2011s,wang2012zftl}. Among them, page-level mapping shows the best performance due to fine-grained mapping, but it requires a large mapping table~\cite{zhou2015efficient,chen2019hcftl,zhou2018correlation,mativenga2019rftl,ni2017hash,han2019wal,chen2019beyond,GFTL}. The existing mapping schemes share a common design principle: exploiting the workload locality to selectively cache a small part of mapping entries in DRAM while storing the whole mapping table on flash. As a result, they work well under workloads with strong access locality. However, if the working set is too large or accesses are random, the cache hit ratio will be very low and the performance will degrade significantly due to frequent swapping operations and double reads~\cite{zhou2015efficient}.


%Existing address mapping schemes in flash-based SSDs can be classified into three categories: (1) page-level mapping, (2) block-level mapping, and (3) hybrid mapping. 

%Among all mapping granularities, page-level mapping shows the best performance due to fine-grained mapping, but it requires a large mapping table. Some demand-based page-level FTL schemes were proposed to speed up the address translation with a limited size of DRAM~\cite{gupta2009dftl,qin2011two,thontirawong2014scftl,jiang2011s,zhou2015efficient,chen2019hcftl,wang2012zftl,zhou2018correlation,mativenga2019rftl,GFTL,zhang2019reinforcement,ni2017hash,chen2019beyond}. DFTL~\cite{gupta2009dftl}, the first demand-based page-level FTL, shows a great improvement over hybrid FTL designs. Its subsequent variants, such as TPFTL and HCFTL~\cite{chen2019hcftl}, focus on the optimization of cache replacement and management to further improve the hit ratio of mapping cache and the performance of flash-based SSDs. 

Recent studies also utilize machine learning (ML) techniques to improve the performance of flash-based SSDs~\cite{yang2019reducing,akgun2021machine,kang2017reinforcement,zhang2019reinforcement,LearnedSSD}. For example, Q-FTL~\cite{zhang2019reinforcement} uses a reinforcement learning-driven cache replacement algorithm to adapt and respond to ever-changing I/O streams, but only for specific workloads, i.e., remote sensing datasets. LearnedSSD~\cite{LearnedSSD} accelerates the development of new SSD devices by automating the hardware parameter configurations by utilizing both supervised and unsupervised ML techniques. Yang et al.~\cite{yang2019reducing} reduced GC overhead in SSD by introducing ML techniques to predict the future temperature of data. However, none of them have considered ML-based methods on the address mapping optimizations within flash-based SSDs.


\subsection{Learned Index}
% \vspace{-3pt}

Learned index builds an explicit model of the underlying data to provide effective indexing. It was first introduced in~\cite{kraska2018case} and many learned indexes have been proposed based on the idea, such as PGM index~\cite{ferragina2020pgm}, FITing tree~\cite{FITing}, ALEX~\cite{ALEX}, Flood~\cite{Flood}, Tsunami~\cite{Tsunami}, and FINEdex~\cite{li2021finedex}. They all investigate how to support update capability, provide better worst-case guarantees, and/or efficient index construction for different workloads.

Recently, BOURBON~\cite{Bourbon} shows how to integrate learned index structure for an LSM-based KV store. BOURBON employs greedy piecewise linear regression to learn key distributions and applies a cost-benefit strategy to decide when learning will be worthwhile, thus enabling fast lookup with minimal computation. APEX~\cite{APEX} is a PM-optimized learned index based on ALEX~\cite{ALEX}. APEX retains the benefits of learned indexes while guaranteeing crash consistency on PM and supporting instant recovery and scalable concurrency. Abu-Libdeh et al.~\cite{BigTable} demonstrate how a learned index can be integrated into a distributed and disk-based database system, Google’s Bigtable. Their results also validate that integrating the learned index can significantly improve the end-to-end read latency and throughput for Bigtable.

Inspired by these advancements in the learned index techniques, LearnedFTL is the first study on leveraging the learned index to improve the page-level FTL designs of flash-based SSDs to accelerate the address translation for workloads with random accesses. Different from the aforementioned learned index techniques, LearedFTL exploits the GC characteristics of flash devices to relocate physical flash pages and a virtual PPN representation to satisfy the training requirements of the learned index. Moreover, it eliminates the error interval associated with the traditional learned index with the bitmap prediction filter to reduce read amplification in flash storage.
