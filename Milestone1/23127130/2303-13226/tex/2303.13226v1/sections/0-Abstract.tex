\begin{abstract}
%With the emergence of 3D NAND and NVMe techniques, the capacity and performance of flash-based SSDs have increased significantly. Accordingly, the mapping table size for those using page-level FTL (Flash Translation Layer) cannot be practically deployed in SSDs since it consumes a prohibitively large memory. Moreover, storing the mapping table in SSDs causes the double-read problem of constantly accessing the flash for the address translation, which directly degrades the random-read performance of SSDs. Existing solutions are mostly locality-based FTL designs which become ineffective and useless under random accesses. 

%We present LearnedFTL, the first study on applying the learned index technique to the on-demand page-level FTL designs to improve random reads in flash-based SSDs by minimizing address translation-induced double reads. LearnedFTL exploits the page relocation characteristics of garbage collection and builds learned models to efficiently translate LPAs to their PPAs. As a result, LearnedFTL significantly reduces the double-read accesses and accelerates the translation speed. The trace-driven experiments on a FEMU-based prototype show that LearnedFTLâ€™s 99th percentile tail latency is on average 6.4$\times$ lower than that of the state-of-the-art TPFTL scheme and performs at a level very close to the ideal FTL in both average latency and tail latency under heavy loads. Moreover, LearnedFTL also provides much better performance under other benchmark evaluations. 
We present LearnedFTL, which applies learned indexes to on-demand page-level flash translation layer (FTL) designs to improve the random read performance of flash-based solid-state drives (SSDs). The first of its kind, it minimizes the number of double reads induced by address translation in random read accesses. To apply the learned indexes to address translation, LearnedFTL proposes dynamic piece-wise regression to efficiently build learned indexes. LearnedFTL also exploits the unique feature of page relocation in SSD internal garbage collection (GC), and embeds the learned index training in GC, which can minimize additional delay on normal read and write operations. Additionally, LearnedFTL employs a bitmap prediction filter to guarantee the accuracy of learned indexes' predictions. With these designs, LearnedFTL considerably speeds up address translation while reducing the number of flash read accesses caused by the demand-based page-level FTL. Our benchmark-driven experiments on a FEMU-based prototype show that LearnedFTL reduces the 99th percentile tail latency by 4.8$\times$, on average, compared to the state-of-the-art TPFTL scheme. 
%It also performs at a level very close to the ideal FTL in terms of both average and tail latencies under heavy loads.% Moreover, LearnedFTL provides higher performance than both DFTL and TPFTL in real-world applications.  
\end{abstract}
