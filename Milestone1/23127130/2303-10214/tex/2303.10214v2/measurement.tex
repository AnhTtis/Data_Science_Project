
\section{Measurement}
\label{sec:measure}
In our work, we commit to solving the two problems discussed in sub-section~\ref{subsec:prob}, through refined behavior indicators and solid measurement results. We discover characteristics of accounts' behavior patterns and uncover hidden correlations between and show how different they are between bot accounts and genuine users. All measurement results support a proper architecture of \BotShape in Section~\ref{sec:design}, including feature extraction and prediction model.



We split measurement work into two parts: (i) The first part shows how to construct calibrated indicators without a \emph{life-cycle} inconsistency problem. Then we analyze how the calibrated indicators change over time on a real-world data set. Furthermore, we also compare the fluctuating pattern between bot accounts and genuine users. (ii) The second part digs into tweet count analysis from a time series perspective. We observe the busy and idle time in the one-day and one-week range. Then we observe the clusters of behavioral time series to verify the assumption that bots have more synchronized behaviors than genuine users because of the centralized control of the dark industry.


\subsection{Account Life-cycle and Cleaning Inactive ones}
% how to calibrate
\subsubsection{\textbf{Account life-cycle and event logs}} Each social network account has its life-cycle, starting from the registration time to the current system time. One account did many actions in its life-cycle, e.g., following, liking, posting,  restored as \textbf{event logs} by the system. Behavioral logs accumulate day-by-day as time goes on; as a result, indicators like the count of tweets increase and change. Registration time-stamp is a vital starting point to calibrate event logs. We construct a new metric $Indicator_{dur}$  using $dur$ as a variable that refers to the duration from the registration to the current date-time. For fairness, we only compare indicators among accounts with the same parameter $dur$.


With complete tweeting records, we could calculate multiple behavior indicators with different $dur$ parameters at various positions in one account's life-cycle. For a better observation, we select multiple $dur$ variables with the same time interval. The definition of $dur$ in the measurement is the count of days from the registration to the analysis date-time. For example, if one account registered on May 1, 2014, and the virtual analysis happened on May 3, 2014, the $dur$ equals two days. 


\subsubsection{\textbf{Inactive accounts}} We calculate $Indicator_{dur}$ for each account after removing the inactive ones. We define \textbf{active account} as one having at least one tweet in the first month (30 days) after registering. Inactive accounts, most are audiences, present less behavior. They occupy a large proportion of the data set. We remove them to focus on informative and active behavior data rather than letting inactive accounts average and weaken important distribution regularity. For a fair comparison, we remove \textbf{inactive accounts} from the bot accounts and normal users simultaneously.

\begin{figure}[h]
\centering
\begin{tabular}{c}
\includegraphics[width=3.3in]{figs/month_tweets_active.pdf}
\vspace{-3pt}\\
\mbox{\small (a) Monthly count of tweets}
\vspace{3pt}\\
\includegraphics[width=3.3in]{figs/month_tweets_active_accum.pdf}
\vspace{-3pt}\\
\mbox{\small (b) Monthly accumulated count of tweets}
\end{tabular}
\caption{Boxplots of tweeting counts: bot  accounts vs normal users}
\label{fig:monthly_tweets}
\end{figure}


\begin{figure}[h]
\centering
\begin{tabular}{c}
\includegraphics[width=3.3in]{figs/week_tweets_active.pdf}
\vspace{-3pt}\\
\mbox{\small (a) Weekly count of tweets}
\vspace{3pt}\\
% 3.3
\includegraphics[width=3.3in]{figs/week_tweets_active_accum.pdf}
\vspace{-3pt}\\
\mbox{\small (b) Weekly accumulated count of tweets}
\end{tabular}
\caption{Boxplots of tweeting counts: social bots vs normal users}
\label{fig:weekly_tweets}
\end{figure}


\begin{figure*}[h]
\centering
\begin{minipage}[h]{0.45\textwidth}
\centering
\includegraphics[width=3.0in]{figs/normal_ts_cluster.pdf}
\caption{Clusters of monthly behavioral sequence for normal users}
\end{minipage}
\hspace{0.5in}
\begin{minipage}[h]{0.45\textwidth}
\centering
\includegraphics[width=3.0in]{figs/bot_ts_cluster.pdf}
\caption{Clusters of monthly behavioral sequence for social bots}
\end{minipage}
\label{fig:tweet_ts_cluster}
\end{figure*}


\subsection{Observe Behavioral Indicators Distribution in the Life-cycles of Accounts}

\subsubsection{\textbf{Behavioral statistic in a time-window}} 
The data set \Cresci has complete tweeting records with time stamps, contexts,  identifiers of accounts, and registering time stamps. Therefore, we set the analyzed indicator as the tweets count for each account in this section. We consider measuring tweeting behavior enough because the account independently controls tweeting behavior having no relationship with other accounts, unlike the count of followers and friends affected by other accounts. Therefore, it is the most direct and meaningful attribute to show accounts' behavior and capture attack traces.


To observe how one behavioral indicator fluctuates, we select various window sizes to calculate it. We first select one month as the time interval, meaning $dur$ equals 30, 60, 120, ... 360 (days). We also select one day as the time interval for a more fine-grain analysis, where $dur$ equals 1, 2, 3, ... 30 (days). $Indicator_{dur}$ equals the tweets count from the registration date to the $dur$ day.
We analyze how an indicator time series(called $Seq_{bhv}$) fluctuates across 12 months and 30 days. For a specific $dur$, we use box-plot \cite{potter2006methods} to present the distributions of $ indicator_{dur}$ consisting of all accounts. In the box-plot figure, each box shows the minimum value, first quartile, average, third quartile, and maximum value, which could clearly show the range and critical statistics of a bunch of data points.

\subsubsection{\textbf{A long-term observation}}

Figure~\ref{fig:monthly_tweets} shows the box-plot of monthly $Indicator_{dur}$. The upper left figure uses the data of normal users, and the upper right figure plots the data of social bot accounts. When comparing the two figures, we conclude that normal users are continually active, but bot accounts cooperate tacitly to reduce and even stop posting tweets after the sixth month. The following two figures are the accumulated tweet count from the registration to the corresponding month. The box plots of normal users show steady growth, but plots of bot accounts show a sudden termination starting in the fifth month.



All the results reflect each role of accounts. Most regular users have one account for one platform and persistently use it. In an online social occasion, changing into a new account tends to mean losing followers and friends, so regular users nearly do not change accounts. However, along with doing more and more spam, bot accounts will get more easily caught by the platform's risk control systems. What follows is that the cost of escaping detection and unlocking account improve quickly. As a result, the controller chooses to give up old bot accounts and register product new bot accounts for new spam purposes in the future.


\subsubsection{\textbf{The period at newly-registration}}
The monthly $dur$ interval is a bit coarse, in which account behavior patterns in newly-registered periods would hide. Therefore, we construct daily $dur$ indicators to watch the situation in the first month after registration. Figure~\ref{fig:weekly_tweets} is the box plot of tweeting count distribution at week-grain for three months (21 weeks). The two upper figures are the weekly count of tweets, and the two below are the accumulated count. The differences between bots and normal users are similar to monthly time granularity.

The normal users' tweeting box plot shows a burst of tweets in the first week, which means normal users often post more tweets at registration. However, bot accounts unexpectedly stay freezing (no tweeting behavior) until the third week after registration. Now look at the accumulation box plot: normal users show an apparent steady increase in tweet counts, but bot accounts have an unusual stopping of tweeting from the eighth week to the thirteenth week. In addition, the tweeting count of one normal user is larger than bot accounts on average.


\subsection{Mine Effective Patterns from Behavioral Sequences}

\subsubsection{\textbf{Busy and idle in a time-series seasonality}}
\label{subsec:busy_idle}


\begin{figure}[htbp]
\centering
\begin{tabular}{c}
\includegraphics[width=3.3in]{figs/tweet_hour.pdf}
\vspace{-3pt}\\
\mbox{\small (a) Percentages of tweets and tweeting users per hour}
\vspace{3pt}\\
\includegraphics[width=3.3in]{figs/tweet_day.pdf}
\vspace{-3pt}\\
\mbox{\small (b) Percentages of tweets and tweeting users per day of week}
\end{tabular}
\caption{Decomposed seasonality from behavioral sequences of tweeting}
\label{fig:tweet_ts_count}
\end{figure}

Due to the regularity of using habits, user behavior statistics in social network platforms are often time series with seasonality. Also, the busy and idle time distribution are related to usage habits. For example, people sleep at night and then perform an idle period. We analyze the tweeting behavior time series properties based on a seasonal method. We group tweets into multiple parts according to time attributes, such as the hour of the day (from 0 am to 11 pm) and the day of the week (from Monday to Sunday).

Figure~\ref{fig:tweet_ts_count} shows the results. We use the proportions of the counts occupying the total amount rather than the actual tweeting counts. The peak and low of normal users and bots are different. Normal users peak at 5 am and low around 11 am. Bot accounts peak at 5 pm and low at 6 am. 

What is more different is that the trends of the two groups are nearly opposite, from 0 am to 9 am, which means normal users are active, but bots are inactive. The day-of-week distribution reflects a similar problem. We observe the conflict between peak and low and different local trends. Tweeting user count distributions in 24 hours and seven days are uniform and similar, whether normal users or bot accounts. It means the active proportions of accounts in the two groups are similar in each time unit.


\subsubsection{\textbf{Patterns of time series}} 
The wave's shape is critical for classifying and clustering time series. Several algorithms could extract shaping features, such as 
Dynamic Time Warping (DTW) \cite{berndt1994using}, Shapelets \cite{ye2009time} and deep learning method. \cite{bao2017deep}. We choose the DTW algorithm to cluster monthly tweeting count time series because it is highly efficient to discover similar time series patterns among multiple time series. We use tslearn \cite{tslearn} k-means and dynamic time warping library for computing. It uses DTW as core features in k-means algorithms and can group a large amount of 
time series into clusters quickly and precisely. 

For fairness, we randomly sample 200 tweeting behavior time series from the normal user and bot account groups, respectively. Figure~\ref{fig:tweet_ts_cluster} shows the result. It is obvious that the time series of bots are highly similar, reflected in that in each cluster, shapes of curves are similar, and overall outlines (think black lines in each cluster) of 5 clusters are similar. The clustering results of normal users are the opposite, with a phenomenon where in each cluster, curves are mussy, having no similarity without a clear overall outline. Also, there is nearly no similarity or correlation among the 6 clusters. We can conclude that bot accounts' behavior correlates and acts concurrently due to centralized control. Regular accounts, controlled by natural persons,  perform vastly different behavior patterns due to various usage habits.

All the indicators shown in measurement results could be transformed into account features for machine learning models to do classification. Also, the variances of those features between a bot and normal users could improve the separability of the two data points groups, making prediction more accurate. 

