@String{ac={Acta Cryst.}}
@String{acr={Acc. Chem. Res.}}
@String{ajp={Am. J. Phys.}} 
@String{acp={Adv. Chem. Phys.}}
@String{acie={Angew. Chem. Int. Ed.}}
@String{arpc={Annu. Rev. Phys. Chem.}}
@String{bc={Biochem.}}
@String{bioinformatics={BIOINFORMATICS}}
@String{bcc={Bioconjugate Chem.}}
@String{bj={Biophys. J.}}
@String{bj={Biophys. J.}}
@String{bunsen={Bunsen-Magazin}}
@String{CHIMIA={CHIMIA}}
@STRING{cmame={Computer Methods in Applied Mechanics and Engineering}}
@String{cancer={Cancer Res.}}
@String{chemrev={Chem. Rev.}}
@String{cell={Cell}}
@String{cm={Chem. Mater.}}
@String{cms={Comp. Mat. Sci.}} 
@String{cp={Chem. Phys.}}
@String{chemrev={Chem. Rev.}}
@String{chemphyschem={ChemPhysChem}}
@String{cbdd={Chemical Biology \& Drug Design}}
@String{cc={Chem. Commun.}}
@String{cpl={Chem. Phys. Lett.}}
@String{chpl={Chin. Phys. Lett.}}
@String{chempc={ChemPhysChem.}} 
@String{cmls={Cell. Mol. Life Sci.}}
@String{cpr={Comput. Phys. Reports}}
@String{cpc={Comput. Phys. Comm.}}
@String{cr={Chem. Rev.}}
@String{csr={Chem. Soc. Rev.}}
@String{europl={Europhys. Lett.}}
@String{hca={Helvetica Chimica Acta}}
@String{ijqc={Int. J. Quantum Chem.}}
@String{iecr={Ind. Eng. Chem. Res.}} 
@String{jacs={J. Am. Chem. Soc.}}
@String{jbs={J. Biomol. Screen.}}
@String{jcamd={J. Comput. Aided Mol. Des.}}
@String{jcics={J. Chem. Inf. Comp. Sci.}}
@String{jcim={J. Chem. Inf. Model.}}
@String{jcp={J. Chem. Phys.}}
@String{jmats={J. Mater Soc.}}
@String{jmb={J. Mol. Biol.}}
@String{jmlr={J. Machine Learning Res.}}
@String{jms={J. Mol. Struc.}}
@String{jpbamp={J. Phys. B: Atom. Molec. Phys.}}
@String{jpc={J. Phys. Chem.}}
@String{jpca={J. Phys. Chem. A}}
@String{jpcb={J. Phys. Chem. B}}
@String{jpcc={J. Phys. Chem. C}}
@String{jpcl={J. Phys. Chem. Lett.}}
@String{jpcm={J. Phys.: Condens. Matter}}
@String{jpcssp={J. Phys. C: Solid State Phys.}}
@String{jpb={J. Phys. B}}
@String{jpoc={J. Phys. Org. Chem.}}
@String{jcc={J. Comp. Chem.}}
@String{jmc={J. Medic. Chem.}}
@String{jmgm={J. Mol. Graph. Model.}}
@String{jmm={J. Mol. Modeling}}
@String{jctc={J. Chem. Theory Comput.}}
@string(JChemPhys="J.{} Chem.{} Phys.{}")
@string(JPhysChemA="J.{} Phys.{} Chem.~A{}")
@String{ltp={Low Temp. Phys.}}
@String{mc={Mol. Cell}}
@String{mi={Mol. Inf.}}
@String{mms={Multiscale Mod. Sim.}}
@String{mplb={Mod. Phys. Lett. B}}
@String{mp={Mol. Phys.}}
@String{mrsb={MRS Bulletin}}
@String{msmse={Modelling Simul. Mater. Sci. Eng.}}
@String{nature={Nature}}
@String{naturecomm={Nat. Comm.}}
@String{naturereviews={Nature Reviews}}
@String{naturechemistry={Nature Chemistry}}
@String{naturematerials={Nature Materials}}
@String{nc={Neural Comp.}}
@String{njc={New J. Chem.}}
@String{nmtma={Numer. Math. Theor. Meth. Appl.}}
@String{nsb={Nat. Struct. Biol.}}
@String{obc={Org. Biomol. Chem.}}
@String{ol={Organic Letters}}
@String{pra={Phys. Rev. A}}
@String{prb={Phys. Rev. B}}
@String{pre={Phys. Rev. E}}
@String{prresearch={Phys. Rev. Research}}
@String{proteins={Proteins}}
@String{pcps={Proc. Camb. Phil. Soc.}}
@String{pccp={Phys. Chem. Chem. Phys.}}
@String{pnas={Proc. Natl. Acad. Sci. USA}}
@String{prl={Phys. Rev. Lett.}}
@String{prx={Phys. Rev. X.}}
@String{prsla={Proc. R. Soc. Lond. A}}
@String{pr={Phys. Rev.}}
@String{pssb={Phys. Stat. Sol. B}}
@String{prot={Proteins}}
@String{qsar={Quant. Struct. Act. Rel.}}
@string{rmg={Rev. Mineral. Geochem.}}
@String{rmp={Rev. Mod. Phys.}}
@String{scientificdata={Scientific Data}}
@String{ss={Surf. Sci.}}
@String{ssc={Solid State Comm.}}
@String{ssi={Solid State Ionics}}
@String{ssp={Solid State Physics}}
@String{science={Science}}
@String{scienceadvance={Sci. Adv.}}
@String{technometrics={Technometrics}}
@String{tca={Theor. Chim. Acta}}
@String{tcc={Top. Curr. Chem.}}
@String{tfs={Trans. Faraday Soc.}}
@String{thl={Tetrahedron Lett.}}
@String{theochem={J. Mol. Struct. (THEOCHEM)}}
@String{zpa={Z. Phys. A.}}
@String{zp={Z. Phys.}}
@String{zfp={Z. f. Phys.}}
@string(JChemInfModel="J. Chem. Inf. Model.")
@string(JChemInformComputSci="J. Chem. Inform. Comput. Sci.")
@article{ceriotti2021editorial,
  title ={Introduction: Machine Learning at the Atomic Scale},
  author={Ceriotti, Michele and Clementi, Cecilia and Anatole von Lilienfeld, O},
  year={2021},
  pages = {9719},
  volume = 121,
  journal= cr,
  publisher={ACS Publications}
}
@article{ceriotti_clementi_anatole_jcp2021,
author = {Ceriotti,Michele  and Clementi,Cecilia  and Anatole von Lilienfeld,O. },
title = {Machine learning meets chemical physics},
journal = {The Journal of Chemical Physics},
volume = {154},
number = {16},
pages = {160401},
year = {2021},
doi = {10.1063/5.0051418},

URL = { 
        https://doi.org/10.1063/5.0051418
    
},
eprint = { 
        https://doi.org/10.1063/5.0051418
    
}

}
@Article{ANI-1,
author ="Smith, J. S. and Isayev, O. and Roitberg, A. E.",
title  ="ANI-1: an extensible neural network potential with DFT accuracy at force field computational cost",
journal  ="Chem. Sci.",
year  ="2017",
volume  ="8",
issue  ="4",
pages  ="3192-3203",
publisher  ="The Royal Society of Chemistry",
doi  ="10.1039/C6SC05720A",
url  ="http://dx.doi.org/10.1039/C6SC05720A",
abstract  ="Deep learning is revolutionizing many areas of science and technology{,} especially image{,} text{,} and speech recognition. In this paper{,} we demonstrate how a deep neural network (NN) trained on quantum mechanical (QM) DFT calculations can learn an accurate and transferable potential for organic molecules. We introduce ANAKIN-ME (Accurate NeurAl networK engINe for Molecular Energies) or ANI for short. ANI is a new method designed with the intent of developing transferable neural network potentials that utilize a highly-modified version of the Behler and Parrinello symmetry functions to build single-atom atomic environment vectors (AEV) as a molecular representation. AEVs provide the ability to train neural networks to data that spans both configurational and conformational space{,} a feat not previously accomplished on this scale. We utilized ANI to build a potential called ANI-1{,} which was trained on a subset of the GDB databases with up to 8 heavy atoms in order to predict total energies for organic molecules containing four atom types: H{,} C{,} N{,} and O. To obtain an accelerated but physically relevant sampling of molecular potential surfaces{,} we also proposed a Normal Mode Sampling (NMS) method for generating molecular conformations. Through a series of case studies{,} we show that ANI-1 is chemically accurate compared to reference DFT calculations on much larger molecular systems (up to 54 atoms) than those included in the training data set."}

@article{QMLessayAnatole,
  title={Quantum Machine Learning in Chemical Compound Space},
  author={von Lilienfeld, O. Anatole}, 
  journal={Angewandte Chemie International Edition},
  pages = {4164},
  volume = 57,
  note = {http://dx.doi.org/10.1002/anie.201709686},
  year={2018},
  publisher={Wiley Online Library}}


@article{ML4Graeme2012,
 author =     {Z. D. Pozun and K. Hansen and D. Sheppard and  M. Rupp and K-R. M\"uller and G. Henkelman},
 title =     {Optimizing transition states via kernel-based machine learning}, 
 journal =    jcp,
 year =     2012,
 volume =     136,
 pages =    {174101-174109},
}   
@article{ML4Kieron2012,
 author =     {J. C. Snyder and M. Rupp and K. Hansen and K-R. M\"uller and K. Burke},
 title =     {Finding Density Functionals with Machine Learning},
 journal =    prl, 
 pages = 253002,
 volume = 108,
 year =     2012,
} 


@article{local_kernels_ceriotti,
author ="De, Sandip and Bartók, Albert P. and Csányi, Gábor and Ceriotti, Michele",
title  ="Comparing molecules and solids across structural and alchemical space",
journal  ="Phys. Chem. Chem. Phys.",
year  ="2016",
volume  ="18",
issue  ="20",
pages  ="13754-13769",
publisher  ="The Royal Society of Chemistry",
doi  ="10.1039/C6CP00415F",
url  ="http://dx.doi.org/10.1039/C6CP00415F",
abstract  ="Evaluating the (dis)similarity of crystalline{,} disordered and molecular compounds is a critical step in the development of algorithms to navigate automatically the configuration space of complex materials. For instance{,} a structural similarity metric is crucial for classifying structures{,} searching chemical space for better compounds and materials{,} and driving the next generation of machine-learning techniques for predicting the stability and properties of molecules and materials. In the last few years several strategies have been designed to compare atomic coordination environments. In particular{,} the smooth overlap of atomic positions (SOAPs) has emerged as an elegant framework to obtain translation{,} rotation and permutation-invariant descriptors of groups of atoms{,} underlying the development of various classes of machine-learned inter-atomic potentials. Here we discuss how one can combine such local descriptors using a regularized entropy match (REMatch) approach to describe the similarity of both whole molecular and bulk periodic structures{,} introducing powerful metrics that enable the navigation of alchemical and structural complexities within a unified framework. Furthermore{,} using this kernel and a ridge regression method we can predict atomization energies for a database of small organic molecules with a mean absolute error below 1 kcal mol−1{,} reaching an important milestone in the application of machine-learning techniques for the evaluation of molecular properties."}

 @article{lennard-jones2, 
    title={On the determination of molecular fields.-i. from the variation of the viscosity of a gas with temperature}, url={https://royalsocietypublishing.org/doi/10.1098/rspa.1924.0081}, 
    journal={Proceedings of the Royal Society of London. Series A}, 
    author={Jones, J. E.}, 
    year={1924}, 
    month={Oct}} 
 
@article{morse,
  title = {Diatomic Molecules According to the Wave Mechanics. II. Vibrational Levels},
  author = {Morse, Philip M.},
  journal = {Phys. Rev.},
  volume = {34},
  issue = {1},
  pages = {57--64},
  numpages = {0},
  year = {1929},
  month = {Jul},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRev.34.57},
  url = {https://link.aps.org/doi/10.1103/PhysRev.34.57}
}

@article{NN_Tucker2006,
 author = {S. Manzhos and T. {Carrington, Jr.}}, 
 title = {A random-sampling high dimensional model representation neural network for building potential energy surfaces},
 journal = jcp,
 year = 2006,
 volume = {125},
 pages = {084109-084123},
}
@article{Rabitz1996,
   author = "Ho, Tak‐San and Rabitz, Herschel",
   title = "A general method for constructing multidimensional molecular potential energy surfaces from ab initio calculations",
   journal = jcp,
   year = "1996",
  volume = "104",
   number = "7", 
   pages = "2584-2597",
   url = "http://scitation.aip.org/content/aip/journal/jcp/104/7/10.1063/1.470984",
   doi = "http://dx.doi.org/10.1063/1.470984"
} 

@article{Ramakrishnan_vonLilienfeld_2015, title={Many Molecular Properties from One Kernel in Chemical Space}, volume={69}, url={https://www.chimia.ch/chimia/article/view/2015_182}, DOI={10.2533/chimia.2015.182}, abstractNote={ We introduce property-independent kernels for machine learning models of arbitrarily many molecular properties. The kernels encode molecular structures for training sets of varying size, as well as similarity measures sufficiently diffuse in chemical space to sample over all training molecules. When provided with the corresponding molecular reference properties, they enable the instantaneous generation of machine learning models which can be systematically improved through the addition of more data. This idea is exemplified for single kernel based modeling of internal energy, enthalpy, free energy, heat capacity, polarizability, electronic spread, zero-point vibrational energy, energies of frontier orbitals, HOMO-LUMO gap, and the highest fundamental vibrational wavenumber. Models of these properties are trained and tested using 112,000 organic molecules of similar size. The resulting models are discussed as well as the kernels’ use for generating and using other property models. }, number={4}, journal={CHIMIA}, author={Ramakrishnan, Raghunathan and von Lilienfeld, O. Anatole}, year={2015}, month={Apr.}, pages={182} 
}

@article{felix_google,
author = {Faber, Felix A. and Hutchison, Luke and Huang, Bing and Gilmer, Justin and Schoenholz, Samuel S. and Dahl, George E. and Vinyals, Oriol and Kearnes, Steven and Riley, Patrick F. and von Lilienfeld, O. Anatole},
title = {Prediction Errors of Molecular Machine Learning Models Lower than Hybrid DFT Error},
journal = {Journal of Chemical Theory and Computation},
volume = {13},
number = {11},
pages = {5255-5264},
year = {2017},
doi = {10.1021/acs.jctc.7b00577},
    note ={PMID: 28926232},

URL = { 
        https://doi.org/10.1021/acs.jctc.7b00577
    
},
eprint = { 
        https://doi.org/10.1021/acs.jctc.7b00577
    
}

}

@article{GAP,
  title = {Gaussian Approximation Potentials: The Accuracy of Quantum Mechanics, without the Electrons},
  author = {Bart\'ok, Albert P. and Payne, Mike C. and Kondor, Risi and Cs\'anyi, G\'abor},
  journal = {Phys. Rev. Lett.},
  volume = {104},
  issue = {13},
  pages = {136403},
  numpages = {4},
  year = {2010},
  month = {Apr},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.104.136403},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.104.136403}
}

@article{Behler-Parrinello_NN,
  title = {Generalized Neural-Network Representation of High-Dimensional Potential-Energy Surfaces},
  author = {Behler, J\"org and Parrinello, Michele},
  journal = {Phys. Rev. Lett.},
  volume = {98},
  issue = {14},
  pages = {146401},
  numpages = {4},
  year = {2007},
  month = {Apr},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.98.146401},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.98.146401}
}


@article{PES_NN,
author = {Handley, Chris M. and Popelier, Paul L. A.},
title = {Potential Energy Surfaces Fitted by Artificial Neural Networks},
journal = {The Journal of Physical Chemistry A},
volume = {114},
number = {10},
pages = {3371-3383},
year = {2010},
doi = {10.1021/jp9105585},
    note ={PMID: 20131763},

URL = { 
        https://doi.org/10.1021/jp9105585
    
},
eprint = { 
        https://doi.org/10.1021/jp9105585
    
}

}

@article{bypassing_KS,
author={Brockherde, F and Vogt, L and Li, L and Tuckerman, M.E. and Burke, K and Müller, Klaus-Robert},
title={ Bypassing the Kohn-Sham equations with machine learning.},
journal={ Nature Communications},
volume={8},
pages={872},
year={2017}, doi={https://doi.org/10.1038/s41467-017-00839-3}}

@article{desc_role_Scheffler,
  title = {Big Data of Materials Science: Critical Role of the Descriptor},
  author = {Ghiringhelli, Luca M. and Vybiral, Jan and Levchenko, Sergey V. and Draxl, Claudia and Scheffler, Matthias},
  journal = {Phys. Rev. Lett.},
  volume = {114},
  issue = {10},
  pages = {105503},
  numpages = {5},
  year = {2015},
  month = {Mar},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.114.105503},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.114.105503}
}


@article{communication_bing,
author = {Huang,Bing  and von Lilienfeld,O. Anatole },
title = {Communication: Understanding molecular representations in machine learning: The role of uniqueness and target similarity},
journal = {The Journal of Chemical Physics},
volume = {145},
number = {16},
pages = {161102},
year = {2016},
doi = {10.1063/1.4964627},

URL = { 
        https://doi.org/10.1063/1.4964627
    
},
eprint = { 
        https://doi.org/10.1063/1.4964627
    
}

}

@article{FourierDesc.,
author = {von Lilienfeld, O. Anatole and Ramakrishnan, Raghunathan and Rupp, Matthias and Knoll, Aaron},
title = {Fourier series of atomic radial distribution functions: A molecular fingerprint for machine learning models of quantum chemical properties},
journal = {International Journal of Quantum Chemistry},
volume = {115},
number = {16},
pages = {1084-1093},
keywords = {machine learning, representation, descriptor, quantum chemistry, molecules},
doi = {https://doi.org/10.1002/qua.24912},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/qua.24912},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/qua.24912},
abstract = {We introduce a fingerprint representation of molecules based on a Fourier series of atomic radial distribution functions. This fingerprint is unique (except for chirality), continuous, and differentiable with respect to atomic coordinates and nuclear charges. It is invariant with respect to translation, rotation, and nuclear permutation, and requires no preconceived knowledge about chemical bonding, topology, or electronic orbitals. As such, it meets many important criteria for a good molecular representation, suggesting its usefulness for machine learning models of molecular properties trained across chemical compound space. To assess the performance of this new descriptor, we have trained machine learning models of molecular enthalpies of atomization for training sets with up to 10 k organic molecules, drawn at random from a published set of 134 k organic molecules with an average atomization enthalpy of over 1770 kcal/mol. We validate the descriptor on all remaining molecules of the 134 k set. For a training set of 10 k molecules, the fingerprint descriptor achieves a mean absolute error of 8.0 kcal/mol. This is slightly worse than the performance attained using the Coulomb matrix, another popular alternative, reaching 6.2 kcal/mol for the same training and test sets. © 2015 Wiley Periodicals, Inc.},
year = {2015}
}


@article{const_size,
author = {Collins,Christopher R.  and Gordon,Geoffrey J.  and von Lilienfeld,O. Anatole  and Yaron,David J. },
title = {Constant size descriptors for accurate machine learning models of molecular properties},
journal = {The Journal of Chemical Physics},
volume = {148},
number = {24},
pages = {241718},
year = {2018},
doi = {10.1063/1.5020441},

URL = { 
        https://doi.org/10.1063/1.5020441
    
},
eprint = { 
        https://doi.org/10.1063/1.5020441
    
}

}


@article{bob,
author = {Hansen, Katja and Biegler, Franziska and Ramakrishnan, Raghunathan and Pronobis, Wiktor and von Lilienfeld, O. Anatole and Müller, Klaus-Robert and Tkatchenko, Alexandre},
title = {Machine Learning Predictions of Molecular Properties: Accurate Many-Body Potentials and Nonlocality in Chemical Space},
journal = {The Journal of Physical Chemistry Letters},
volume = {6},
number = {12},
pages = {2326-2331},
year = {2015},
doi = {10.1021/acs.jpclett.5b00831},
    note ={PMID: 26113956},

URL = { 
        https://doi.org/10.1021/acs.jpclett.5b00831
    
},
eprint = { 
        https://doi.org/10.1021/acs.jpclett.5b00831
    
}

}


@article{soap,
  title = {On representing chemical environments},
  author = {Bart\'ok, Albert P. and Kondor, Risi and Cs\'anyi, G\'abor},
  journal = {Phys. Rev. B},
  volume = {87},
  issue = {18},
  pages = {184115},
  numpages = {16},
  year = {2013},
  month = {May},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevB.87.184115},
  url = {https://link.aps.org/doi/10.1103/PhysRevB.87.184115}
}

@article{axilrod_teller,
author = {Axilrod,B. M.  and Teller,E. },
title = {Interaction of the van der Waals Type Between Three Atoms},
journal = {The Journal of Chemical Physics},
volume = {11},
number = {6},
pages = {299-300},
year = {1943},
doi = {10.1063/1.1723844},

URL = { 
        https://doi.org/10.1063/1.1723844
    
},
eprint = { 
        https://doi.org/10.1063/1.1723844
    
}

}

@article{acsf,
author = {Behler,Jörg },
title = {Atom-centered symmetry functions for constructing high-dimensional neural network potentials},
journal = {The Journal of Chemical Physics},
volume = {134},
number = {7},
pages = {074106},
year = {2011},
doi = {10.1063/1.3553717},

URL = { 
        https://doi.org/10.1063/1.3553717
    
},
eprint = { 
        https://doi.org/10.1063/1.3553717
    
}

}

@article{fchl19,
author = {Christensen,Anders S.  and Bratholm,Lars A.  and Faber,Felix A.  and Anatole von Lilienfeld,O. },
title = {FCHL revisited: Faster and more accurate quantum machine learning},
journal = {The Journal of Chemical Physics},
volume = {152},
number = {4},
pages = {044107},
year = {2020},
doi = {10.1063/1.5126701},

URL = { 
        https://doi.org/10.1063/1.5126701
    
},
eprint = { 
        https://doi.org/10.1063/1.5126701
    
}

}

@misc{amons_slatm,
  doi = {10.48550/ARXIV.1707.04146},
  
  url = {https://arxiv.org/abs/1707.04146},
  
  author = {Huang, Bing and von Lilienfeld, O. Anatole},
  
  keywords = {Chemical Physics (physics.chem-ph), FOS: Physical sciences, FOS: Physical sciences},
  
  title = {Quantum machine learning using atom-in-molecule-based fragments selected on-the-fly},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{PI_townsend,
author={Townsend, Jacob
and Micucci, Cassie Putman
and Hymel, John H.
and Maroulas, Vasileios
and Vogiatzis, Konstantinos D.},
title={Representation of molecular structures with persistent homology for machine learning applications in chemistry},
journal={Nature Communications},
year={2020},
month={Jun},
day={26},
volume={11},
number={1},
pages={3230},
abstract={Machine learning and high-throughput computational screening have been valuable tools in accelerated first-principles screening for the discovery of the next generation of functionalized molecules and materials. The application of machine learning for chemical applications requires the conversion of molecular structures to a machine-readable format known as a molecular representation. The choice of such representations impacts the performance and outcomes of chemical machine learning methods. Herein, we present a new concise molecular representation derived from persistent homology, an applied branch of mathematics. We have demonstrated its applicability in a high-throughput computational screening of a large molecular database (GDB-9) with more than 133,000 organic molecules. Our target is to identify novel molecules that selectively interact with CO2. The methodology and performance of the novel molecular fingerprinting method is presented and the new chemically-driven persistence image representation is used to screen the GDB-9 database to suggest molecules and/or functional groups with enhanced properties.},
issn={2041-1723},
doi={10.1038/s41467-020-17035-5},
url={https://doi.org/10.1038/s41467-020-17035-5}
}

@article{energy_functionals,
  title = {Connections between the energy functional and interaction potentials for materials simulations},
  author = {Taylor, Christopher D.},
  journal = {Phys. Rev. B},
  volume = {80},
  issue = {2},
  pages = {024104},
  numpages = {10},
  year = {2009},
  month = {Jul},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevB.80.024104},
  url = {https://link.aps.org/doi/10.1103/PhysRevB.80.024104}
}

@article{qm9,
  title={Quantum chemistry structures and properties of 134 kilo molecules},
  author={Ramakrishnan, Raghunathan and Dral, Pavlo O and Rupp, Matthias and von Lilienfeld, O Anatole},
  journal={Scientific Data},
  volume={1},
  year={2014},
  publisher={Nature Publishing Group}
}

@book{Vapnik1998,
  added-at = {2009-11-30T17:48:31.000+0100},
  author = {Vapnik, Vladimir N.},
  biburl = {https://www.bibsonomy.org/bibtex/21a5aaa75fa8be088b01a7381d2f661be/fluctuator},
  interhash = {f211eacca8f6ce50e9c31c6bcc482809},
  intrahash = {1a5aaa75fa8be088b01a7381d2f661be},
  keywords = {imported},
  owner = {CHAENIG},
  publisher = {Wiley-Interscience},
  timestamp = {2009-11-30T17:48:32.000+0100},
  title = {Statistical Learning Theory},
  year = 1998
}

@book{Deisenroth2020,
  added-at = {2019-10-12T23:39:32.000+0200},
  author = {Deisenroth, Marc Peter and Faisal, A. Aldo and Ong, Cheng Soon},
  biburl = {https://www.bibsonomy.org/bibtex/271e556439bb49b11e015aa4c0d9cb785/lopusz_kdd},
  description = {Mathematics for Machine Learning: Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong: 9781108455145: Amazon.com: Books},
  interhash = {876f4a593e888f3257674a89d7456f25},
  intrahash = {71e556439bb49b11e015aa4c0d9cb785},
  keywords = {general_machine_learning},
  publisher = {Cambridge University Press},
  timestamp = {2019-10-12T23:43:51.000+0200},
  title = {Mathematics for Machine Learning},
  year = 2020
}


@article{OM,
author = {Zhu,Li  and Amsler,Maximilian  and Fuhrer,Tobias  and Schaefer,Bastian  and Faraji,Somayeh  and Rostami,Samare  and Ghasemi,S. Alireza  and Sadeghi,Ali  and Grauzinyte,Migle  and Wolverton,Chris  and Goedecker,Stefan },
title = {A fingerprint based metric for measuring similarities of crystalline structures},
journal = {The Journal of Chemical Physics},
volume = {144},
number = {3},
pages = {034203},
year = {2016},
doi = {10.1063/1.4940026},

URL = { 
        https://doi.org/10.1063/1.4940026
    
},
eprint = { 
        https://doi.org/10.1063/1.4940026
    
}

}


@misc{qmlcode2017,
  title={QML: A Python Toolkit for Quantum Machine Learning, https://github.com/qmlcode/qml},
  author = {A. S. Christensen, F. A. Faber and B. Huang, L. A. Bratholm, A. Tkatchenko, K.-R. M\"uller and O. A. von Lilienfeld},
  doi = {10.5281/zenodo.817332},
  url  ={http://www.qmlcode.org},
  year = {2017},
}

@misc{qml,
  author       = {Christensen, A. S.  and Bratholm, L. A. and Faber, F. A. and Huang, B. and Tkatchenko, A. and M\"uller, K. R. and von Lilienfeld, O. A.},
  title        = {QML: A Python Toolkit for Quantum Machine Learning},
  year         = {2017},
  url          = {https://github.com/qmlcode/qml},
  doi          = {10.5281/zenodo.817332}
}

@article{dscribe,
  author = {Himanen, Lauri and J{\"a}ger, Marc O.~J. and Morooka, Eiaki V. and Federici Canova, Filippo and Ranawat, Yashasvi S. and Gao, David Z. and Rinke, Patrick and Foster, Adam S.},
  title = {{DScribe: Library of descriptors for machine learning in materials science}},
  journal = {Computer Physics Communications},
  volume = {247},
  pages = {106949},
  year = {2020},
  doi = {10.1016/j.cpc.2019.106949},
  url = {https://doi.org/10.1016/j.cpc.2019.106949},
  issn = {0010-4655}
}
@book{anatolebook,
  author = {Kristof T. Schütt and Stefan Chmiela and O. Anatole von Lilienfeld and Alexandre Tkatchenko and Koji Tsuda and Klaus-Robert Müller},
  publisher = {Springer},
  title = {Machine Learning Meets Quantum Physics},
  year = {2020}
}

@book{gpr_rasmussen,
  added-at = {2020-07-17T00:00:00.000+0200},
  author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
  biburl = {https://www.bibsonomy.org/bibtex/2670a576a21065048f7ddede17e09b6b4/dblp},
  ee = {https://www.worldcat.org/oclc/61285753},
  interhash = {72c030472023000e0bdeeb06081c3764},
  intrahash = {670a576a21065048f7ddede17e09b6b4},
  isbn = {026218253X},
  keywords = {dblp},
  pages = {I-XVIII, 1-248},
  publisher = {MIT Press},
  series = {Adaptive computation and machine learning},
  timestamp = {2020-07-24T00:45:17.000+0200},
  title = {Gaussian processes for machine learning.},
  year = 2006
}

@article{stillinger-weber,
  title = {Computer simulation of local order in condensed phases of silicon},
  author = {Stillinger, Frank H. and Weber, Thomas A.},
  journal = {Phys. Rev. B},
  volume = {31},
  issue = {8},
  pages = {5262--5271},
  numpages = {0},
  year = {1985},
  month = {Apr},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevB.31.5262},
  url = {https://link.aps.org/doi/10.1103/PhysRevB.31.5262}
}
@inproceedings{numba,
author = {Lam, Siu Kwan and Pitrou, Antoine and Seibert, Stanley},
title = {Numba: A LLVM-Based Python JIT Compiler},
year = {2015},
isbn = {9781450340052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2833157.2833162},
doi = {10.1145/2833157.2833162},
abstract = {Dynamic, interpreted languages, like Python, are attractive for domain-experts and scientists experimenting with new ideas. However, the performance of the interpreter is often a barrier when scaling to larger data sets. This paper presents a just-in-time compiler for Python that focuses in scientific and array-oriented computing. Starting with the simple syntax of Python, Numba compiles a subset of the language into efficient machine code that is comparable in performance to a traditional compiled language. In addition, we share our experience in building a JIT compiler using LLVM[1].},
booktitle = {Proceedings of the Second Workshop on the LLVM Compiler Infrastructure in HPC},
articleno = {7},
numpages = {6},
keywords = {LLVM, Python, compiler},
location = {Austin, Texas},
series = {LLVM '15}
}
@book{amari2000methods,
  title={Methods of information geometry},
  author={Amari, Shun-ichi and Nagaoka, Hiroshi},
  volume={191},
  year={2000},
  publisher={American Mathematical Soc.}
}
@article{fml,
author = {Weinreich,Jan  and Browning,Nicholas J.  and von Lilienfeld,O. Anatole },
title = {Machine learning of free energies in chemical compound space using ensemble representations: Reaching experimental uncertainty for solvation},
journal = {The Journal of Chemical Physics},
volume = {154},
number = {13},
pages = {134113},
year = {2021},
doi = {10.1063/5.0041548},
URL = {https://doi.org/10.1063/5.0041548},
eprint = {https://doi.org/10.1063/5.0041548}
}

@article{schnet,
  doi = {10.1021/acs.jctc.8b00908},
  url = {https://doi.org/10.1021/acs.jctc.8b00908},
  year = {2018},
  month = nov,
  publisher = {American Chemical Society ({ACS})},
  volume = {15},
  number = {1},
  pages = {448--455},
  author = {K. T. Sch\"{u}tt and P. Kessel and M. Gastegger and K. A. Nicoli and A. Tkatchenko and K.-R. M\"{u}ller},
  title = {{SchNetPack}: A Deep Learning Toolbox For Atomistic Systems},
  journal = {Journal of Chemical Theory and Computation}
}

@inproceedings{schnetpack,
 author = {Sch\"{u}tt, Kristof and Kindermans, Pieter-Jan and Sauceda Felix, Huziel Enoc and Chmiela, Stefan and Tkatchenko, Alexandre and M\"{u}ller, Klaus-Robert},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {SchNet: A continuous-filter convolutional neural network for modeling quantum interactions},
 url = {https://proceedings.neurips.cc/paper/2017/file/303ed4c69846ab36c2904d3ba8573050-Paper.pdf},
 volume = {30},
 year = {2017}
}

@article{ lyp,
  title = {Development of the Colle-Salvetti correlation-energy formula into a functional of the electron density},
  author = {Lee, Chengteh and Yang, Weitao and Parr, Robert G.},
  journal = {Phys. Rev. B},
  volume = {37},
  issue = {2},
  pages = {785--789},
  numpages = {0},
  year = {1988},
  month = {Jan},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevB.37.785},
  url = {https://link.aps.org/doi/10.1103/PhysRevB.37.785}
}

@article{631g2dfp,
author = {Petersson,G. A.  and Bennett,Andrew  and Tensfeldt,Thomas G.  and Al‐Laham,Mohammad A.  and Shirley,William A.  and Mantzaris,John },
title = {A complete basis set model chemistry. I. The total energies of closed‐shell atoms and hydrides of the first‐row elements},
journal = {The Journal of Chemical Physics},
volume = {89},
number = {4},
pages = {2193-2218},
year = {1988},
doi = {10.1063/1.455064},

URL = { 
        https://doi.org/10.1063/1.455064
    
},
eprint = { 
        https://doi.org/10.1063/1.455064
    
}

}
@article{b3,
author = {Becke,Axel D. },
title = {Density‐functional thermochemistry. III. The role of exact exchange},
journal = {The Journal of Chemical Physics},
volume = {98},
number = {7},
pages = {5648-5652},
year = {1993},
doi = {10.1063/1.464913},

URL = { 
        https://doi.org/10.1063/1.464913
    
},
eprint = { 
        https://doi.org/10.1063/1.464913
    
}

}
}
@article{wacsf,
author = {Gastegger,M.  and Schwiedrzik,L.  and Bittermann,M.  and Berzsenyi,F.  and Marquetand,P. },
title = {wACSF—Weighted atom-centered symmetry functions as descriptors in machine learning potentials},
journal = {The Journal of Chemical Physics},
volume = {148},
number = {24},
pages = {241709},
year = {2018},
doi = {10.1063/1.5019667},

URL = { 
        https://doi.org/10.1063/1.5019667
    
},
eprint = { 
        https://doi.org/10.1063/1.5019667
    
}

}
@article{kresse2020,
author = {Jinnouchi,Ryosuke  and Karsai,Ferenc  and Verdi,Carla  and Asahi,Ryoji  and Kresse,Georg },
title = {Descriptors representing two- and three-body atomic distributions and their effects on the accuracy of machine-learned inter-atomic potentials},
journal = {The Journal of Chemical Physics},
volume = {152},
number = {23},
pages = {234102},
year = {2020},
doi = {10.1063/5.0009491},

URL = { 
        https://doi.org/10.1063/5.0009491
    
},
eprint = { 
        https://doi.org/10.1063/5.0009491
    
}

}
@article{atz2022delta,
  title={$\Delta$-Quantum machine-learning for medicinal chemistry},
  author={Atz, Kenneth and Isert, Clemens and B{\"o}cker, Markus NA and Jim{\'e}nez-Luna, Jos{\'e} and Schneider, Gisbert},
  journal={Physical Chemistry Chemical Physics},
  volume={24},
  number={18},
  pages={10775--10783},
  year={2022},
  publisher={Royal Society of Chemistry}
}
@article{browning2022gpu,
  title={GPU-accelerated approximate kernel method for quantum machine learning},
  author={Browning, Nicholas J and Faber, Felix A and Anatole von Lilienfeld, O},
  journal={The Journal of Chemical Physics},
  volume={157},
  number={21},
  pages={214801},
  year={2022},
  publisher={AIP Publishing LLC}
}
@misc{sml_dom,
  doi = {10.48550/ARXIV.2205.05633},
  
  url = {https://arxiv.org/abs/2205.05633},
  
  author = {Lemm, Dominik and von Rudorff, Guido Falk and von Lilienfeld, O. Anatole},
  
  keywords = {Chemical Physics (physics.chem-ph), FOS: Physical sciences, FOS: Physical sciences},
  
  title = {Improved decision making with similarity based machine learning},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}
@article{pip,
author = { Bastiaan J.   Braams  and  Joel M.   Bowman },
title = {Permutationally invariant potential energy surfaces in high dimensionality},
journal = {International Reviews in Physical Chemistry},
volume = {28},
number = {4},
pages = {577-606},
year  = {2009},
publisher = {Taylor & Francis},
doi = {10.1080/01442350903234923},

URL = { 
    
        https://doi.org/10.1080/01442350903234923
    
    

},
eprint = { 
    
        https://doi.org/10.1080/01442350903234923
    
    

}

}
@article{op_response_anders,
author = {Christensen,Anders S.  and Faber,Felix A.  and von Lilienfeld,O. Anatole },
title = {Operators in quantum machine learning: Response properties in chemical space},
journal = {The Journal of Chemical Physics},
volume = {150},
number = {6},
pages = {064105},
year = {2019},
doi = {10.1063/1.5053562},

URL = { 
        https://doi.org/10.1063/1.5053562
    
},
eprint = { 
        https://doi.org/10.1063/1.5053562
    
}

}

@inproceedings{vapnik1994learningcurves,
  title={Learning curves: Asymptotic values and rate of convergence},
  author={Cortes, Corinna and Jackel, Lawrence D and Solla, Sara A and Vapnik, Vladimir and Denker, John S},
  booktitle={Advances in Neural Information Processing Systems},
  pages={327--334},
  year={1994}
} 
@article{StatError_Muller1996,
    author     = {K. R. {M\"uller} and M. Finke and N. Murata and K. Schulten and S. Amari},
    title       = {A numerical study on learning curves in stochastic multilayer feedforward networks},
    journal     = nc,
    volume      = 8,
    pages       = 1085,
    year        = 1996
}


@article{Elpasolite_2016,
  title = {Machine Learning Energies of 2 Million Elpasolite $({ABC}_{2}{D}_{6})$ Crystals},
  author = {Faber, Felix A. and Lindmaa, Alexander and von Lilienfeld, O. Anatole and Armiento, Rickard},
  journal = {Phys. Rev. Lett.},
  volume = {117},
  issue = {13},
  pages = {135502},
  numpages = {6},
  year = {2016},
  month = {Sep},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.117.135502},
  url = {http://doi.org/10.1103/PhysRevLett.117.135502}
}

@Article{PI,
author={Townsend, Jacob
and Micucci, Cassie Putman
and Hymel, John H.
and Maroulas, Vasileios
and Vogiatzis, Konstantinos D.},
title={Representation of molecular structures with persistent homology for machine learning applications in chemistry},
journal={Nature Communications},
year={2020},
month={Jun},
day={26},
volume={11},
number={1},
pages={3230},
abstract={Machine learning and high-throughput computational screening have been valuable tools in accelerated first-principles screening for the discovery of the next generation of functionalized molecules and materials. The application of machine learning for chemical applications requires the conversion of molecular structures to a machine-readable format known as a molecular representation. The choice of such representations impacts the performance and outcomes of chemical machine learning methods. Herein, we present a new concise molecular representation derived from persistent homology, an applied branch of mathematics. We have demonstrated its applicability in a high-throughput computational screening of a large molecular database (GDB-9) with more than 133,000 organic molecules. Our target is to identify novel molecules that selectively interact with CO2. The methodology and performance of the novel molecular fingerprinting method is presented and the new chemically-driven persistence image representation is used to screen the GDB-9 database to suggest molecules and/or functional groups with enhanced properties.},
issn={2041-1723},
doi={10.1038/s41467-020-17035-5},
url={https://doi.org/10.1038/s41467-020-17035-5}
}

@article{qmmlpack,
  doi = {10.1002/qua.24954},
  url = {https://doi.org/10.1002/qua.24954},
  year = {2015},
  month = jul,
  publisher = {Wiley},
  volume = {115},
  number = {16},
  pages = {1058--1073},
  author = {Matthias Rupp},
  title = {Machine learning for quantum mechanics in a nutshell},
  journal = {International Journal of Quantum Chemistry}
}

@article{mbsf,
  doi = {10.1039/c7sc04934j},
  url = {https://doi.org/10.1039/c7sc04934j},
  year = {2018},
  publisher = {Royal Society of Chemistry ({RSC})},
  volume = {9},
  number = {8},
  pages = {2261--2269},
  author = {Kun Yao and John E. Herr and David~W. Toth and Ryker Mckintyre and John Parkhill},
  title = {The {TensorMol}-0.1 model chemistry: a neural network augmented with long-range physics},
  journal = {Chemical Science}
}
@Article{def2,
author ="Weigend, Florian and Ahlrichs, Reinhart",
title  ="Balanced basis sets of split valence{,} triple zeta valence and quadruple zeta valence quality for H to Rn: Design and assessment of accuracy",
journal  ="Phys. Chem. Chem. Phys.",
year  ="2005",
volume  ="7",
issue  ="18",
pages  ="3297-3305",
publisher  ="The Royal Society of Chemistry",
doi  ="10.1039/B508541A",
url  ="http://dx.doi.org/10.1039/B508541A",
abstract  ="Gaussian basis sets of quadruple zeta valence quality for Rb–Rn are presented{,} as well as bases of split valence and triple zeta valence quality for H–Rn. The latter were obtained by (partly) modifying bases developed previously. A large set of more than 300 molecules representing (nearly) all elements—except lanthanides—in their common oxidation states was used to assess the quality of the bases all across the periodic table. Quantities investigated were atomization energies{,} dipole moments and structure parameters for Hartree–Fock{,} density functional theory and correlated methods{,} for which we had chosen Møller–Plesset perturbation theory as an example. Finally recommendations are given which type of basis set is used best for a certain level of theory and a desired quality of results."}
@Article{wb97xd,
author ="Chai, Jeng-Da and Head-Gordon, Martin",
title  ="Long-range corrected hybrid density functionals with damped atom–atom dispersion corrections",
journal  ="Phys. Chem. Chem. Phys.",
year  ="2008",
volume  ="10",
issue  ="44",
pages  ="6615-6620",
publisher  ="The Royal Society of Chemistry",
doi  ="10.1039/B810189B",
url  ="http://dx.doi.org/10.1039/B810189B",
abstract  ="We report re-optimization of a recently proposed long-range corrected (LC) hybrid density functional [J.-D. Chai and M. Head-Gordon{,} J. Chem. Phys.{,} 2008{,} 128{,} 084106] to include empirical atom–atom dispersion corrections. The resulting functional{,} ωB97X-D yields satisfactory accuracy for thermochemistry{,} kinetics{,} and non-covalent interactions. Tests show that for non-covalent systems{,} ωB97X-D shows slight improvement over other empirical dispersion-corrected density functionals{,} while for covalent systems and kinetics it performs noticeably better. Relative to our previous functionals{,} such as ωB97X{,} the new functional is significantly superior for non-bonded interactions{,} and very similar in performance for bonded interactions."}
@Article{gfn2xtb,
author={Bannwarth, Christoph
and Ehlert, Sebastian
and Grimme, Stefan},
title={GFN2-xTB---An Accurate and Broadly Parametrized Self-Consistent Tight-Binding Quantum Chemical Method with Multipole Electrostatics and Density-Dependent Dispersion Contributions},
journal={Journal of Chemical Theory and Computation},
year={2019},
month={Mar},
day={12},
publisher={American Chemical Society},
volume={15},
number={3},
pages={1652-1671},
issn={1549-9618},
doi={10.1021/acs.jctc.8b01176},
url={https://doi.org/10.1021/acs.jctc.8b01176}
}
@Article{QMugs,
author={Isert, Clemens
and Atz, Kenneth
and Jim{\'e}nez-Luna, Jos{\'e}
and Schneider, Gisbert},
title={QMugs, quantum mechanical properties of drug-like molecules},
journal={Scientific Data},
year={2022},
month={Jun},
day={07},
volume={9},
number={1},
pages={273},
abstract={Machine learning approaches in drug discovery, as well as in other areas of the chemical sciences, benefit from curated datasets of physical molecular properties. However, there currently is a lack of data collections featuring large bioactive molecules alongside first-principle quantum chemical information. The open-access QMugs (Quantum-Mechanical Properties of Drug-like Molecules) dataset fills this void. The QMugs collection comprises quantum mechanical properties of more than 665 k biologically and pharmacologically relevant molecules extracted from the ChEMBL database, totaling {\textasciitilde}2{\thinspace}M conformers. QMugs contains optimized molecular geometries and thermodynamic data obtained via the semi-empirical method GFN2-xTB. Atomic and molecular properties are provided on both the GFN2-xTB and on the density-functional levels of theory (DFT, $\omega$B97X-D/def2-SVP). QMugs features molecules of significantly larger size than previously-reported collections and comprises their respective quantum mechanical wave functions, including DFT density and orbital matrices. This dataset is intended to facilitate the development of models that learn from molecular data on different levels of theory while also providing insight into the corresponding relationships between molecular structure and biological activity.},
issn={2052-4463},
doi={10.1038/s41597-022-01390-7},
url={https://doi.org/10.1038/s41597-022-01390-7}
}


@article{fchl18,
author = {Faber,Felix A.  and Christensen,Anders S.  and Huang,Bing  and von Lilienfeld,O. Anatole },
title = {Alchemical and structural distribution based representation for universal quantum machine learning},
journal = {The Journal of Chemical Physics},
volume = {148},
number = {24},
pages = {241717},
year = {2018},
doi = {10.1063/1.5020710},

URL = { 
        https://doi.org/10.1063/1.5020710
    
},
eprint = { 
        https://doi.org/10.1063/1.5020710
    
}

}
@article{parzen_density,
author = {Emanuel Parzen},
title = {{On Estimation of a Probability Density Function and Mode}},
volume = {33},
journal = {The Annals of Mathematical Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {1065 -- 1076},
year = {1962},
doi = {10.1214/aoms/1177704472},
URL = {https://doi.org/10.1214/aoms/1177704472}
}
@article{incompleteness_ceriotti,
  title = {Incompleteness of Atomic Structure Representations},
  author = {Pozdnyakov, Sergey N. and Willatt, Michael J. and Bart\'ok, Albert P. and Ortner, Christoph and Cs\'anyi, G\'abor and Ceriotti, Michele},
  journal = {Phys. Rev. Lett.},
  volume = {125},
  issue = {16},
  pages = {166001},
  numpages = {6},
  year = {2020},
  month = {Oct},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.125.166001},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.125.166001}
}

@article{mbtr,
	doi = {10.1088/2632-2153/aca005},
  
	url = {https://doi.org/10.1088%2F2632-2153%2Faca005},
  
	year = 2022,
	month = {nov},
  
	publisher = {{IOP} Publishing},
  
	volume = {3},
  
	number = {4},
  
	pages = {045017},
  
	author = {Haoyan Huo and Matthias Rupp},
  
	title = {Unified representation of molecules and crystals for machine learning},
  
	journal = {Machine Learning: Science and Technology}
}}

@article{ace,
  title = {Atomic cluster expansion for accurate and transferable interatomic potentials},
  author = {Drautz, Ralf},
  journal = {Phys. Rev. B},
  volume = {99},
  issue = {1},
  pages = {014104},
  numpages = {15},
  year = {2019},
  month = {Jan},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevB.99.014104},
  url = {https://link.aps.org/doi/10.1103/PhysRevB.99.014104}
}


@article{physics-inspired-reps-ceriotti,
author = {Musil, Felix and Grisafi, Andrea and Bartók, Albert P. and Ortner, Christoph and Csányi, Gábor and Ceriotti, Michele},
title = {Physics-Inspired Structural Representations for Molecules and Materials},
journal = {Chemical Reviews},
volume = {121},
number = {16},
pages = {9759-9815},
year = {2021},
doi = {10.1021/acs.chemrev.1c00021},
    note ={PMID: 34310133},

URL = { 
        https://doi.org/10.1021/acs.chemrev.1c00021
    
},
eprint = { 
        https://doi.org/10.1021/acs.chemrev.1c00021
    
}

}

@article{CM,
  title = {Fast and Accurate Modeling of Molecular Atomization Energies with Machine Learning},
  author = {Rupp, Matthias and Tkatchenko, Alexandre and M\"uller, Klaus-Robert and von Lilienfeld, O. Anatole},
  journal = {Phys. Rev. Lett.},
  volume = {108},
  issue = {5},
  pages = {058301},
  numpages = {5},
  year = {2012},
  month = {Jan},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.108.058301},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.108.058301}
}


@article{qm7,
  title = {Fast and Accurate Modeling of Molecular Atomization Energies with Machine Learning},
  author = {Rupp, Matthias and Tkatchenko, Alexandre and M\"uller, Klaus-Robert and von Lilienfeld, O. Anatole},
  journal = {Phys. Rev. Lett.},
  volume = {108},
  issue = {5},
  pages = {058301},
  numpages = {5},
  year = {2012},
  month = {Jan},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.108.058301},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.108.058301}
}
@article{orca5,
author = {Neese, Frank},
title = {Software update: The ORCA program system—Version 5.0},
journal = {WIREs Computational Molecular Science},
volume = {12},
number = {5},
pages = {e1606},
keywords = {density functional theory, electron correlation, QM/MM, quantum chemistry, theoretical spectroscopy},
doi = {https://doi.org/10.1002/wcms.1606},
url = {https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/wcms.1606},
eprint = {https://wires.onlinelibrary.wiley.com/doi/pdf/10.1002/wcms.1606},
abstract = {Abstract Version 5.0 of the ORCA quantum chemistry program suite was released in July 2021. ORCA 5.0 represents a major improvement over all previous versions of ORCA and features (1) highly improved performance, (2) increased numerical robustness, (3) a host of new functionality, and (4) greatly improved user friendliness. The article describes the most salient features of the program. This article is categorized under: Electronic Structure Theory > Ab Initio Electronic Structure Methods Data Science > Computer Algorithms and Programming Software > Quantum Chemistry},
year = {2022}
}

@article{ase,
doi = {10.1088/1361-648X/aa680e},
url = {https://dx.doi.org/10.1088/1361-648X/aa680e},
year = {2017},
month = {jun},
publisher = {IOP Publishing},
volume = {29},
number = {27},
pages = {273002},
author = {Ask Hjorth Larsen and Jens Jørgen Mortensen and Jakob Blomqvist and Ivano E Castelli and Rune Christensen and Marcin Dułak and Jesper Friis and Michael N Groves and Bjørk Hammer and Cory Hargus and Eric D Hermes and Paul C Jennings and Peter Bjerre Jensen and James Kermode and John R Kitchin and Esben Leonhard Kolsbjerg and Joseph Kubal and Kristen Kaasbjerg and Steen Lysgaard and Jón Bergmann Maronsson and Tristan Maxson and Thomas Olsen and Lars Pastewka and Andrew Peterson and Carsten Rostgaard and Jakob Schiøtz and Ole Schütt and Mikkel Strange and Kristian S Thygesen and Tejs Vegge and Lasse Vilhelmsen and Michael Walter and Zhenhua Zeng and Karsten W Jacobsen},
title = {The atomic simulation environment—a Python library for working with atoms},
journal = {Journal of Physics: Condensed Matter},
abstract = {The atomic simulation environment (ASE) is a software package written in the Python programming language with the aim of setting up, steering, and analyzing atomistic simulations. In ASE, tasks are fully scripted in Python. The powerful syntax of Python combined with the NumPy array library make it possible to perform very complex simulation tasks. For example, a sequence of calculations may be performed with the use of a simple ‘for-loop’ construction. Calculations of energy, forces, stresses and other quantities are performed through interfaces to many external electronic structure codes or force fields using a uniform interface. On top of this calculator interface, ASE provides modules for performing many standard simulation tasks such as structure optimization, molecular dynamics, handling of constraints and performing nudged elastic band calculations.}
}
@article{ci-neb,
author = {Henkelman,Graeme  and Uberuaga,Blas P.  and Jónsson,Hannes },
title = {A climbing image nudged elastic band method for finding saddle points and minimum energy paths},
journal = {The Journal of Chemical Physics},
volume = {113},
number = {22},
pages = {9901-9904},
year = {2000},
doi = {10.1063/1.1329672},

URL = { 
        https://doi.org/10.1063/1.1329672
    
},
eprint = { 
        https://doi.org/10.1063/1.1329672
    
}
}

@article{970m_qm7b,
  author  = {L. C. Blum and J.-L. Reymond},
  title   = {970 Million Druglike Small Molecules for Virtual Screening in the Chemical Universe Database {GDB-13}},
  journal = "J. Am. Chem. Soc.",
  volume  = 131,
  pages   = 8732,
  year    = 2009
}

@article{qm7b,
  author={Gr{\'e}goire Montavon and Matthias Rupp and Vivekanand Gobre and Alvaro Vazquez-Mayagoitia and Katja Hansen and Alexandre
Tkatchenko and Klaus-Robert M{\"u}ller and O Anatole von Lilienfeld},
  title={Machine learning of molecular electronic properties in chemical compound space},
  journal={New Journal of Physics},
  volume={15},
  number={9},
  pages={095003},
  url={http://stacks.iop.org/1367-2630/15/i=9/a=095003},
  year={2013},
  abstract={The combination of modern scientific computing with electronic structure theory can lead to an unprecedented amount of data amenable to intelligent data analysis for the identification of meaningful, novel and predictive structureâ€“property relationships. Such relationships enable high-throughput screening for relevant properties in an exponentially growing pool of virtual compounds that are synthetically accessible. Here, we present a machine learning model, trained on a database of ab initio calculation results for thousands of organic molecules, that simultaneously predicts multiple electronic ground- and excited-state properties. The properties include atomization energy, polarizability, frontier orbital eigenvalues, ionization potential, electron affinity and excitation energies. The machine learning model is based on a deep multi-task artificial neural network, exploiting the underlying correlations between various molecular properties. The input is identical to ab initio methods, i.e.Â nuclear charges and Cartesian coordinates of all atoms. For small organic molecules, the accuracy of such a â€˜quantum machineâ€™ is similar, and sometimes superior, to modern quantum-chemical methodsâ€”at negligible computational cost.}
}


}
@article{wasserstein,
doi = {10.1088/2632-2153/aba048},
url = {https://dx.doi.org/10.1088/2632-2153/aba048},
year = {2020},
month = {aug},
publisher = {IOP Publishing},
volume = {1},
number = {3},
pages = {03LT01},
author = {Onur Çaylak and O. Anatole von Lilienfeld and Björn Baumeier},
title = {Wasserstein metric for improved quantum machine learning with adjacency matrix representations},
journal = {Machine Learning: Science and Technology},
abstract = {We study the Wasserstein metric to measure distances between molecules represented by the atom index dependent adjacency ‘Coulomb’ matrix, used in kernel ridge regression based supervised learning. Resulting machine learning models of quantum properties, a.k.a. quantum machine learning models exhibit improved training efficiency and result in smoother predictions of energies related to molecular distortions. We first illustrate smoothness for the continuous extraction of an atom from some organic molecule. Learning curves, quantifying the decay of the atomization energy’s prediction error as a function of training set size, have been obtained for tens of thousands of organic molecules drawn from the QM9 data set. In comparison to conventionally used metrics (L 1 and L 2 norm), our numerical results indicate systematic improvement in terms of learning curve off-set for random as well as sorted (by norms of row) atom indexing in Coulomb matrices. Our findings suggest that this metric corresponds to a favorable similarity measure which introduces index-invariance in any kernel based model relying on adjacency matrix representations.}
}
@article{metric_learning,
doi = {10.1088/2632-2153/ac8e4f},
url = {https://dx.doi.org/10.1088/2632-2153/ac8e4f},
year = {2022},
month = {sep},
publisher = {IOP Publishing},
volume = {3},
number = {3},
pages = {035015},
author = {Raimon Fabregat and Puck van Gerwen and Matthieu Haeberle and Friedrich Eisenbrand and Clémence Corminboeuf},
title = {Metric learning for kernel ridge regression: assessment of molecular similarity},
journal = {Machine Learning: Science and Technology},
abstract = {Supervised and unsupervised kernel-based algorithms widely used in the physical sciences depend upon the notion of similarity. Their reliance on pre-defined distance metrics—e.g. the Euclidean or Manhattan distance—are problematic especially when used in combination with high-dimensional feature vectors for which the similarity measure does not well-reflect the differences in the target property. Metric learning is an elegant approach to surmount this shortcoming and find a property-informed transformation of the feature space. We propose a new algorithm for metric learning specifically adapted for kernel ridge regression (KRR): metric learning for kernel ridge regression (MLKRR). It is based on the Metric Learning for Kernel Regression framework using the Nadaraya-Watson estimator, which we show to be inferior to the KRR estimator for typical physics-based machine learning tasks. The MLKRR algorithm allows for superior predictive performance on the benchmark regression task of atomisation energies of QM9 molecules, as well as generating more meaningful low-dimensional projections of the modified feature space.}
}

@Article{numpy,
 title         = {Array programming with {NumPy}},
 author        = {Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J.
                 van der Walt and Ralf Gommers and Pauli Virtanen and David
                 Cournapeau and Eric Wieser and Julian Taylor and Sebastian
                 Berg and Nathaniel J. Smith and Robert Kern and Matti Picus
                 and Stephan Hoyer and Marten H. van Kerkwijk and Matthew
                 Brett and Allan Haldane and Jaime Fern{\'{a}}ndez del
                 R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre
                 G{\'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and
                 Warren Weckesser and Hameer Abbasi and Christoph Gohlke and
                 Travis E. Oliphant},
 year          = {2020},
 month         = sep,
 journal       = {Nature},
 volume        = {585},
 number        = {7825},
 pages         = {357--362},
 doi           = {10.1038/s41586-020-2649-2},
 publisher     = {Springer Science and Business Media {LLC}},
 url           = {https://doi.org/10.1038/s41586-020-2649-2}
}
@Article{reps_review_rupp,
author={Langer, Marcel F.
and Goe{\ss}mann, Alex
and Rupp, Matthias},
title={Representations of molecules and materials for interpolation of quantum-mechanical simulations via machine learning},
journal={npj Computational Materials},
year={2022},
month={Mar},
day={16},
volume={8},
number={1},
pages={41},
abstract={Computational study of molecules and materials from first principles is a cornerstone of physics, chemistry, and materials science, but limited by the cost of accurate and precise simulations. In settings involving many simulations, machine learning can reduce these costs, often by orders of magnitude, by interpolating between reference simulations. This requires representations that describe any molecule or material and support interpolation. We comprehensively review and discuss current representations and relations between them. For selected state-of-the-art representations, we compare energy predictions for organic molecules, binary alloys, and Al--Ga--In sesquioxides in numerical experiments controlled for data distribution, regression method, and hyper-parameter optimization.},
issn={2057-3960},
doi={10.1038/s41524-022-00721-x},
url={https://doi.org/10.1038/s41524-022-00721-x}
}


@article{gaussian_moments,
author = {Zaverkin, V. and Kästner, J.},
title = {Gaussian Moments as Physically Inspired Molecular Descriptors for Accurate and Scalable Machine Learning Potentials},
journal = {Journal of Chemical Theory and Computation},
volume = {16},
number = {8},
pages = {5410-5421},
year = {2020},
doi = {10.1021/acs.jctc.0c00347},
    note ={PMID: 32672968},

URL = { 
        https://doi.org/10.1021/acs.jctc.0c00347
    
},
eprint = { 
        https://doi.org/10.1021/acs.jctc.0c00347
    
}

}

@article{nice,
author = {Nigam,Jigyasa  and Pozdnyakov,Sergey  and Ceriotti,Michele },
title = {Recursive evaluation and iterative contraction of N-body equivariant features},
journal = {The Journal of Chemical Physics},
volume = {153},
number = {12},
pages = {121101},
year = {2020},
doi = {10.1063/5.0021116},

URL = { 
        https://doi.org/10.1063/5.0021116
    
},
eprint = { 
        https://doi.org/10.1063/5.0021116
    
}

}
@article{mtp,
author = {Shapeev, Alexander V.},
title = {Moment Tensor Potentials: A Class of Systematically Improvable Interatomic Potentials},
journal = {Multiscale Modeling \& Simulation},
volume = {14},
number = {3},
pages = {1153-1173},
year = {2016},
doi = {10.1137/15M1054183},

URL = { 
    
        https://doi.org/10.1137/15M1054183
    
    

},
eprint = { 
    
        https://doi.org/10.1137/15M1054183
    
    

}
,
    abstract = { Density functional theory offers a very accurate way of computing materials properties from first principles. However, it is too expensive for modeling large-scale molecular systems whose properties are, in contrast, computed using interatomic potentials. The present paper considers, from a mathematical point of view, the problem of constructing interatomic potentials that approximate a given quantum-mechanical interaction model. In particular, a new class of systematically improvable potentials is proposed, analyzed, and tested on an existing quantum-mechanical database. }
}
@article{wst,
  author    = {Matthew J. Hirn and
               Nicolas Poilvert and
               St{\'{e}}phane Mallat},
  title     = {Quantum Energy Regression using Scattering Transforms},
  journal   = {CoRR},
  volume    = {abs/1502.02077},
  year      = {2015},
  url       = {http://arxiv.org/abs/1502.02077},
  eprinttype = {arXiv},
  eprint    = {1502.02077},
  timestamp = {Wed, 02 Jan 2019 13:45:54 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/HirnPM15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@software{scikit-optimize,
  author       = {Head, Tim and
                  Kumar, Manoj and
                  Nahrstaedt, Holger and
                  Louppe, Gilles and
                  Shcherbatyi, Iaroslav},
  title        = {scikit-optimize/scikit-optimize},
  month        = oct,
  year         = 2021,
  publisher    = {Zenodo},
  version      = {v0.9.0},
  doi          = {10.5281/zenodo.5565057},
  url          = {https://doi.org/10.5281/zenodo.5565057}
}
@article{lbfgs,
  doi = {10.1007/bf01589116},
  url = {https://doi.org/10.1007/bf01589116},
  year = {1989},
  month = aug,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {45},
  number = {1-3},
  pages = {503--528},
  author = {Dong C. Liu and Jorge Nocedal},
  title = {On the limited memory {BFGS} method for large scale optimization},
  journal = {Mathematical Programming}
}

@article{PhysRevB.100.024112,
  title = {Optimizing many-body atomic descriptors for enhanced computational performance of machine learning based interatomic potentials},
  author = {Caro, Miguel A.},
  journal = {Phys. Rev. B},
  volume = {100},
  issue = {2},
  pages = {024112},
  numpages = {11},
  year = {2019},
  month = {Jul},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevB.100.024112},
  url = {https://link.aps.org/doi/10.1103/PhysRevB.100.024112}
}
@Article{ceriotti_electrostatics,
author ="Grisafi, Andrea and Nigam, Jigyasa and Ceriotti, Michele",
title  ="Multi-scale approach for the prediction of atomic scale properties",
journal  ="Chem. Sci.",
year  ="2021",
volume  ="12",
issue  ="6",
pages  ="2078-2090",
publisher  ="The Royal Society of Chemistry",
doi  ="10.1039/D0SC04934D",
url  ="http://dx.doi.org/10.1039/D0SC04934D",
abstract  ="Electronic nearsightedness is one of the fundamental principles that governs the behavior of condensed matter and supports its description in terms of local entities such as chemical bonds. Locality also underlies the tremendous success of machine-learning schemes that predict quantum mechanical observables – such as the cohesive energy{,} the electron density{,} or a variety of response properties – as a sum of atom-centred contributions{,} based on a short-range representation of atomic environments. One of the main shortcomings of these approaches is their inability to capture physical effects ranging from electrostatic interactions to quantum delocalization{,} which have a long-range nature. Here we show how to build a multi-scale scheme that combines in the same framework local and non-local information{,} overcoming such limitations. We show that the simplest version of such features can be put in formal correspondence with a multipole expansion of permanent electrostatics. The data-driven nature of the model construction{,} however{,} makes this simple form suitable to tackle also different types of delocalized and collective effects. We present several examples that range from molecular physics to surface science and biophysics{,} demonstrating the ability of this multi-scale approach to model interactions driven by electrostatics{,} polarization and dispersion{,} as well as the cooperative behavior of dielectric response functions."}
@Article{behler_electrostatics,
author={Ko, Tsz Wai
and Finkler, Jonas A.
and Goedecker, Stefan
and Behler, J{\"o}rg},
title={A fourth-generation high-dimensional neural network potential with accurate electrostatics including non-local charge transfer},
journal={Nature Communications},
year={2021},
month={Jan},
day={15},
volume={12},
number={1},
pages={398},
abstract={Machine learning potentials have become an important tool for atomistic simulations in many fields, from chemistry via molecular biology to materials science. Most of the established methods, however, rely on local properties and are thus unable to take global changes in the electronic structure into account, which result from long-range charge transfer or different charge states. In this work we overcome this limitation by introducing a fourth-generation high-dimensional neural network potential that combines a charge equilibration scheme employing environment-dependent atomic electronegativities with accurate atomic energies. The method, which is able to correctly describe global charge distributions in arbitrary systems, yields much improved energies and substantially extends the applicability of modern machine learning potentials. This is demonstrated for a series of systems representing typical scenarios in chemistry and materials science that are incorrectly described by current methods, while the fourth-generation neural network potential is in excellent agreement with electronic structure calculations.},
issn={2041-1723},
doi={10.1038/s41467-020-20427-2},
url={https://doi.org/10.1038/s41467-020-20427-2}
}

