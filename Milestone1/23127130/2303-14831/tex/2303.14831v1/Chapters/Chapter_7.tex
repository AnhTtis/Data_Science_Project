\chapter{Verdict} % Main chapter title

\label{Chapter7} % For referencing the chapter elsewhere, use \ref{Chapter1} 

In this chapter we sum up our primary conclusions in relation to our initial goals.

Additionally, we list some of the limitations encountered as well as questions that require further research to answer.

\section{Summary}

Radiosity has long proven itself an ideal solution for real-time global illumination in static scenes. Unfortunately, drawn-out periods of pre-computation can hinder productivity in designing 3D environments with realistic lighting.

Attempts to speed up this process have been centered around either

\begin{itemize}
\item the general reduction of computational complexity, as is done in instant radiosity, or
\item the exploitation of its parallelizable nature.
\end{itemize}

Both of these techniques manifest themselves in \textit{progressive refinement} radiosity, where patches are organized in quad-trees and updated simultaneously. 
Yet, few instances of this algorithm are implemented for GPU execution, and those that are typically rely on a z-buffered hemicube approximation for visibility, which comes at a significant expense whilst providing less realistic results.

Nvidia's Turing GPUs come equipped with dedicated raytracing hardware intended to speed up real-time raytracing. In chapter \ref{Chapter2} we demonstrated how raytracing and radiosity both share the same underlying principles by deriving each method from the rendering equation, implying that the performance gains enabled by RTX ought not only to speed up raytracing, but also radiosity.

In chapter \ref{Chapter6} we successfully demonstrated that this idea is both viable and competitive. Through our implementation we put a significant number of different methods and configurations to the test as well as examining additional extensions that serve as performance enhancements.

\section{Limitations}

In our evaluation we described the limitations encountered concerning visibility caching and voxel-raymarching in particular. 

Since these do not present an obstacle to the core idea of leveraging RTX for progressive refinement radiosity, holistically, the concept appears viable.

\newpage

Below we list our encountered limitations that are specific to our implementation of RTRad:

\begin{itemize}
\item Unless lightmap resolutions are sufficiently low or directional sampling is used, the performance remains marginally outside the domain of real-time.

\item Directional samples either require large light-sources or a vast amount of rays to produce serviceable results.

\item Our implementation of adaptive subdivision is subject to significant speed constraints because all pixels need to be tested for their alpha value. This problem may be ameliorated by creating an entirely separate texture consisting only of the pixels with an alpha value larger than zero.

\item Our implementation only uses a single UV channel both for color textures and lightmaps. This approach is unsuitable for a PBR material system, but is easily expandable by including an additional channel.

\item All light-sources must be reflected as a patch in the texturegroup. Point-lights or directional lights, as they are traditionally used in the phong illumination model, do not work.
\end{itemize}

\section{Conclusions}

Our analysis in chapter \ref{Chapter6} comes with several implications. In regards to our initial goals, we arrived at the following overarching conclusions:

\medskip
\textbf{Conclusion 1:} \textit{On the GPU, simpler radiosity variants perform better.}

Performance-wise, our findings were generally more favourable to simpler techniques over adaptive subdivision.
In our assessment, Monte-Carlo undersampling using the recommended settings listed in section \ref{Undersampling_Analysis} generally provides the best balance between speed, visual fidelity and reliability. For very large lightmaps and well-lit scenes, directional sampling is fastest.

Visibility-caching and voxel-raymarching are generally discouraged, but can be advantageous in specific use-cases.

We expect that a potential hybrid solution utilizing a conjoined set of patches sampled directionally and based on a quad-tree to provide ideal results.

\medskip
\textbf{Conclusion 2:} \textit{RTX can significantly improve GPU radiosity performance.}

As a whole, we were successful in demonstrating that RTX has the capability to speed up the offline lightmap generation process and, as more applications begin to move their heavy workloads onto the GPU, we expect radiosity to follow suit.

According to the \textit{Steam Hardware Survey} of July 2022, approximately 30\% of gaming-oriented PCs are equipped with a Turing graphics card \cite{SteamHardwareSurvey}. If this number continues to grow, we anticipate engines utilizing GPU lightmapping (such as Unity, Blender or Unreal) to begin leveraging this power.

\medskip
\textbf{Conclusion 3:} \textit{RTX can quickly compute vast amounts of accurate visibility data for arbitrary point-pairs.}

Extensively, RTX appears to be a great potential asset to \textit{any} application that requires large sets of highly accurate visibility data. This precedent is not strictly tied to just the domains of graphics or lighting, but may be expanded to computer vision, physics simulations and photogrammetry.

\section{Future Work}

RTX may prove useful for a variety of purposes depending on how widespread its adoption becomes. Our demonstration of its viability in lightmap generation opens up several new paths that would benefit from further research:

\begin{itemize}
\item We believe that the directional sampling approach in particular, which this thesis only touched on superficially, is the way forward for progressive radiosity on a very large scale. The potential that a hybrid approach may provide requires further examination. We expect that introducing multiple-importance sampling by prioritizing light-sources in combination with a number of directional samples for indirect light to function as a reasonable foundation for this approach.
\item The utilization of \textit{proxy geometry} has proved itself useful in computing global illumination with RTX \cite{ProxyGeometry}. It thus stands to reason that radiosity's performance may benefit from this as well.
\item Whilst our implementation performs all calculations on the GPU, hybrid methods that combine both GPU and CPU have demonstrated potential in the past \cite{ComplexGPURadiosity}. This opens the door to expanding a batch-wise view-factors computation on the GPU with RTX, whilst the CPU performs the steps related to light-transfer.
\item Elias' radiosity implementation \cite{HugoElias_Radiosity} utilizes a static texture that is multiplied with the samples of a hemicube. The brightness of this texture is proportional to the cosine of the angle between the surface normal, and the direction of the light which saves a significant amount of work on view factor calculation. Using a directional sampling approach with a hemicube and storing this value in the ray payload may prove to be faster and more flexible.
\item Diffuse indirect light scatters uniformly and usually does not require the same resolution as direct light. A common practice in applications handling global illumination is to isolate direct and indirect light by computing them separately \cite{gpu_gems_2005}. Using a model like Phong to compute direct light may allow a far lower lightmap resolution to be generated in RTRad to exclusively include the diffuse indirect component, enabling significantly shorter pass-times.
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[scale=1.15]{Figures/Gallery.png}
\decoRule
\caption[]{RTRad-generated lightmaps rendered in real-time using Unity's built-in rendering pipeline with specular reflection probes and some rudimentary post-processing effects.} 
\label{Gallery}
\end{figure}