\section{Introduction}
In recent years, the development of deep learning has led to increased interest in using 2D X-ray images for 3D reconstruction in radiation imaging. Various studies, including\cite{x_to_3d}\cite{x2ct_gan}\cite{x2_teeth}\cite{knee_3d}\cite{3d_leg}\cite{oral_3d}, have employed end-to-end deep learning models to translate one or more X-ray images of the imaging target into 3D space. This technology can potentially reduce the amount of absorbed radiation during examinations, and offer an alternative imaging solution for children and elderly individuals. However, the effectiveness of such generative models heavily depends on the diversity and scale of the paired training data, where the diversity and scale of the training dataset could increase the uncertainty during inference. In the case of single-image reconstruction, the model also relies on prior knowledge of the target shape or pixel-wise annotations to reconstruct an accurate shape of the 3D object. These conditions significantly limit the widespread adoption of such learning-based tomography in clinical applications.


Compared to learning-based methods that rely on vast amounts of data, recent advances in the field of neural radiance field (NeRF) \cite{nerf}\cite{nerf++} have shown promising results in 3D object reconstruction from a single image in medical imaging. A NeRF model uses a deep neural network to approximate a field function that maps 3D positions into voxel values, and is optimized using paired poses and view images from a camera to reconstruct the 3D object. In medical imaging, the imaging equipment can provide the position of a detector and its captured image, such as an X-ray source and a digital film, making it possible to reconstruct the target 3D object without requiring additional patient data.


Several recent works demonstrate the versatility of neural radiance field (NeRF) in medical imaging applications. For instance, \cite{naf} utilizes a neural network to predict attenuation coefficients for Cone Beam Computed Tomography (CBCT) reconstruction. Similarly, \cite{mednerf} develops a model that disentangles the shape and depth of surface and internal anatomical structures to create a continuous representation of CT scans from a single X-ray image. In another study, \cite{nerf_ultrasound} applies the NeRF algorithm in 3D ultrasound reconstruction to evaluate spinal curvature measurements. Lastly, \cite{nerf_surgery} presents a framework for stereo 3D reconstruction of deformable tissues from a single viewpoint in robotic surgery.


\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{figs/Nexf-PX-imaging.png}
    \caption{In CBCT, the X-ray camera rotates around a fixed center for $360^{\circ}$ and sends cone-shaped rays to the receiver. In PX, the X-ray camera and receiver rotates around different centers during imaging for $180^{\circ}$ to fit the curve of mandible and maxilla.
    }
    \label{fig:imaging}
\end{figure}

However, the existing studies have yet to investigate the application of NeRF in panoramic imaging (PX). PX has become a popular imaging technique in dental healthcare in recent decades due to its fast speed, high accuracy, and low radiation. Similar to (CBCT), which is widely used in orthodontics, the PX imaging process involves the X-ray source and sensors moving simultaneously during scanning. However, unlike CBCT, PX uses focal plane tomography to generate a projection image of the target area. The X-ray source and a moving film rotate horizontally to match the focal curve with the patient's mandible and maxilla shape, as illustrated in Figure~\ref{fig:imaging}. However, the limited projection information in the z dimension presents challenges for 3D reconstruction from panoramic imaging. To address this issue, we propose a framework called Oral-NeXF, based on neural field methods, for 3D oral reconstruction from panoramic imaging. We summarize our key contributions as follows:

\begin{itemize}
    \item In contrast to previous approaches for 3D oral reconstruction, such as Oral-3D\cite{oral_3d} and X2Teeth\cite{x2_teeth}, which rely on paired data to learn an inverse projection function and prior knowledge or voxel-wise annotations to restore the curved mandible shape, Oral-NeXF does not require any paired data or individual prior knowledge.
    \item To overcome the limited projection information in the z dimension in PX imaging, we introduce a multi-head neural field function that predicts a beam of voxel intensities at a single time given the 2D coordinate.
    \item With the feature of multi-head prediction, we introduce a dynamic sampling strategy when generating point samples from radiation rays. This could encourage the model to learn a smooth intensity distribution in the 3D space.
\end{itemize}

% https://iits.dentistry.utoronto.ca/node/765.html
%https://henryscheinequipmentcatalog.com/content-library/panoramic-radiography/
%https://en.wikipedia.org/wiki/Cone_beam_computed_tomography#Bone_density_and_the_Hounsfield_scale