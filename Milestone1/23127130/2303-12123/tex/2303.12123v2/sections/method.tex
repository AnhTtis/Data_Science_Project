\section{Methodologies}

\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{figs/Nexf-overview.png}
    \caption{This image provides an overview of our model, i.e., Oral-3Dv2. Starting with radiation rays, we use a dynamic sampler to acquire sample points on each ray at random sampling rates. Then, we employ our proposed multi-head neural X-ray field (NeXF) with a positional encoder to predict densities in the 3D space. The NeXF outputs a bunch of HU values from a single 2D coordinate. Next, we generate a projection image adapting to the dynamic resolution during sampling. Finally, we calculate the MSE loss between the projection slice and the ground-truth image to update parameters of our implicit representation model.
    }
    \label{fig:model}
\end{figure*}

\subsection{Problem Definition}
Given a pair of projection image $I$ and the trajectory of the rotation center $O$ during the PX imaging, the object is to find an implicit 3D representation $V: \mathbf{p} \rightarrow h$ that maps 3D coordinates $\mathbf{p}$ into HU values $h$ and minimizes the mean square error against the projection image given the imaging function $F(\cdot)$. The problem can be defined as:
\begin{equation}
\label{eq:opt_overall}
    \mathop{\arg\min}\limits_{V(\cdot)} ||F(V, O) - I||_2.
\end{equation}
With the sampled rotation center point at $O_i$ and the corresponding projection image $I_i$, the reconstruction problem in Eq (\ref{eq:opt_overall}) could be solved by optimizing the below objective function:
\begin{equation}
\label{eq:opt_detail}
    L_{obj}=\sum_{i=1}^{N} ||f(V(\mathbf{p_1}), V(\mathbf{p_2}), \cdots, V(\mathbf{p_m})) - I_i||_2,
\end{equation}
where $\mathbf{p_1}, \cdots, \mathbf{p_m}$ are the coordinates of points sampled along the radiation ray sent from the X-ray tube, and $f$ is the projection function that maps multiple voxel values into a single one. To distinguish with existing NeRF-like models $V_{NeRF}$, we refer to our implicit representation model as $V_{NeXF}$ (short for neural X-ray field) to represent the field function in X-ray imaging.

\subsection{Overview}
We show an overview of our proposed model in Fig.~\ref{fig:model}, where paired rays and rendering results are taken as input to train the implicit representation model $V_{NeXF}$. Given the direction and origin of the projection ray inferred from the moving trajectory $T(O)$ of the X-ray tube, we first generate points along the radiation ray at a random sampling rate. The sampled coordinates are then taken as the input of a positional encoding module, followed by our proposed NeXF model, to generate the projection results. The model is updated according to Eq. \ref{eq:opt_detail} until converge. Although our framework looks similar to NeRF-like models, we have three major differences due to the feature of PX imaging, where the radiation rays are almost parallel to the axial plane. First, our NeXF has a multi-head structure, whose input is a 2D coordinate and output is a bunch of voxel values in the same axial location. Second, we use a dynamic sampling strategy instead of a pair of coarse and fine networks to improve the reconstruction quality. Third, our model is view-independent as it is unreasonable for various density values for the same voxel in radiology.

\subsection{Dynamic Sampling}
NeRF-based models generally utilize a pair of coarse and fine networks to determine the sampling rate along the rays due to multiple free spaces and occluded regions in their 3D objects viewed from the outside. However, this is not applicable to radiology as the aim of imaging is to observe the inside structure of the object. Therefore, points along the radiation rays should be evenly sampled to evenly indicate the density variance in 3D space. To accommodate this, we propose a dynamic sampling strategy that acquires points from radiation rays in a random resolution to improve spatial smoothness without introducing additional new networks. As shown in Fig. \ref{fig:model}, radiation rays sent from different directions (represented by the red, blue, and purple arrows) acquire different numbers of sampling points when generating projection images. We show that the variance in sampling rate during projection in training could significantly improve the reconstruction quality in the ablation experiments.


\subsection{Positional Encoding}
Positional encoding has been widely used in implicit 3D representation models due to the tendency of learning low-frequency details as revealed in recent research like \cite{positional_bias1, positional_bias2}. To solve this spectral bias problem, frequency encoding is introduced in \cite{nerf, freq_encoding1} to encourage the model to exploit high-dimension spatial information during reconstruction. We follow the same way as in \cite{attention} that utilizes multi-resolution sequence to encode the coordinate value $p$ from $\mathbf{p}$ into $L$ levels of embedding as: 

\begin{equation}
\begin{aligned}
{Enc}(p)= & (\sin \left(2^0 p\right), \sin \left(2^1 p\right), \cdots, \sin \left(2^{L-1} p\right. \\
& \left.\cos \left(2^0 p\right), \cos \left(2^1 p\right), \cdots, \cos \left(2^{L-1} p\right)\right)
\end{aligned}
\end{equation}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.4\textwidth]{figs/Nexf-PX-Imaging-sagittal.png}
    \caption{We show the imaging process of PX in sagittal view in this picture. Unlike cameras, the X-ray tube used in radiology has a fixed trajectory and direction when moving, thus leading to limited variance in direction of radiation rays.
    }
    \label{fig:px_sagittal}
\end{figure}

\subsection{Multi-head Neural X-ray Field}
Different from NeRF-based models, where the camera has more freedom in position and angle, the X-ray tube in radiological scans generally moves in a fixed trajectory, leading to a limited direction and origin of radiation rays during the imaging. For example, as shown in the sagittal view of PX imaging in Fig. \ref{fig:px_sagittal}, radiation rays that pass through the oral cavity are approximately parallel to the axial plane. Taking advantage of this feature, we propose a different radiance field model that predicts a bunch of voxel values in the 3D space from a 2D coordinate. Given that the 3D object in radiology should be view-independent, our implicit representation model $V_{NeXF}$ can be defined as:
\begin{equation}
    V_{NeXF}: (x, y) \rightarrow (v_{x, y, 1}, v_{x, y, 2}, \cdots, v_{x, y, z_n}),
\end{equation}
in comparison to $V_{NeRF}$ defined as:
\begin{equation}
    V_{NeRF}: (x, y, z, \theta, \phi) \rightarrow v_{x, y, z}.
\end{equation}
We compare the difference between $V_{NeXF}$ and $V_{NeRF}$ in Fig. \ref{fig:multihed}. $V_{NeXF}$ uses a multi-head architecture that takes in a 2D coordinate as input and outputs $z_n$ number of voxel values, where $z_n$ is the same as the resolution of reconstruction object in $z$ axis. In contrast, $V_{NeRF}$ only predicts a single value per 5D coordinate. Therefore, $V_{NeXF}$ can reduce the computational complexity from $\mathcal{O}(N^3)$ to $\mathcal{O}(N^2)$ compared with $V_{NeRF}$ during the reconstruction of $N \times N \times N$ object.


\begin{figure}[t]
    \centering
    \includegraphics[width=0.45\textwidth]{figs/Nexf-multihead.png}
    \caption{We show the comparison of implicit representation model between NeXF and NeRF models in this picture. The NeRF-like models have a single-head structure that outputs the specific voxel value of the given input. However, in NeXF the model only takes in a 2D coordinate by predicts a bunch of voxel values with its multi-head architecture. This architecture could best fit the imaging process of PX and significantly decrease the computation complexity during both training and inference.
    }
    \label{fig:multihed}
\end{figure}


\begin{figure*}[t]
    \centering
    \includegraphics[width=0.9\textwidth]{figs/Nexf-PX-comapre.png}
    \caption{Comparison of different rendering methods in PX imaging. We can see that with soft rendering the generated PX image has a closer contrast with the real PX image (obtained from Internet). The real PX image looks more clear due to the high resolution of the PX machine.
    }
    \label{fig:px_compare}
\end{figure*}

\begin{table*}[ht]
    \centering
    \caption{Evaluation of 3D oral reconstruction by PSNR, SSIM(\%), and Dice.}
    \label{tab:compare}
    \begin{tabular}{p{6.0cm}<{\centering}p{2.0cm}<{\centering}p{2.0cm}<{\centering}p{2.0cm}<{\centering}p{2.0cm}<{\centering}}
    \hline
    Method&PSNR&Dice&SSIM&Overall\cr
    \hline
    NAF \cite{naf}&18.35$\pm$0.86&57.20$\pm$3.94&60.69$\pm$2.69&65.93\cr
    GAN \cite{gan}&16.71$\pm$0.89&75.10$\pm$1.46&63.96$\pm$7.03&76.93\cr
    ResEncoder \cite{x_to_3d}&18.26$\pm$0.50&72.67$\pm$1.56&62.52$\pm$5.56&75.49\cr
    Oral-3D \cite{oral_3d}&18.59$\pm$0.70&76.88$\pm$1.26&65.94$\pm$4.24&78.60\cr
    \textbf{Ours}&\textbf{20.34}$\pm$0.62&75.34$\pm$3.95&\textbf{81.06}$\pm$1.61&\textbf{86.04}\cr
    \hline
    \end{tabular}
\end{table*}

\subsection{Adaptive Projection}
Following Beer-Lambert absorption-only model \cite{beerlaw}, the fraction $\alpha$ of radiation arriving at the film after traveling volumes with spatially-varying density $\mu(t)$ along a ray parameterized with variable t within $[t_n, t_f]$ could be expressed as:
\begin{equation}
\label{eq:beer_law}
\alpha = \exp \int_{t_n}^{t_f}\mu(t)dt,
\end{equation}
where $\mu(t)$ is the attenuation coefficient and could be converted into a HU value by:
\begin{equation}
H(\mu)=1000 \times \frac{\mu-\mu_{\mathrm{water}}}{\mu_{\mathrm{water}}-\mu_{\mathrm{air}}},
\end{equation}
where $\mu_{\mathrm{water}}$ and $\mathrm{water}$ are constant values and $\mu$ is the accumulated attenuation coefficient along the ray path. By sampling along the radiation ray, Eq. (\ref{eq:beer_law}) can be converted into:
\begin{equation}
\label{eq:beer_law_discrete}
\alpha = \exp(\sum_{i}^{\lfloor t_f-t_n \rfloor}\mu_{i}).
\end{equation}
Therefore, the projection function $f(\cdot)$ in Eq. (\ref{eq:opt_detail}) can be adaptively expressed with our proposed implicit representation model $V$ and the dynamic sampling rate $N_s$ as:
\begin{equation}
\label{eq:render_function}
\begin{aligned}
f(\cdot) &= H(\frac{\sum_{i}^{\lfloor N_s(t_f-t_n) \rfloor}\mu_{i}}{N_s}) \\
&= H(\frac{\sum_{i}^{\lfloor N_s(t_f-t_n) \rfloor} H^{-1}(V(\mathbf{p_i})}{N_s})),
\end{aligned}
\end{equation}
where ${p_i}$ is the $i$-th sample point within $[t_n, t_f]$.

% \subsection{Dynamic Sampling and Adaptive Rendering}
% To obtain a smooth intensity distribution in 3D space, we propose to use a dynamic sampling strategy to acquire points from the radiation ray. Given a projection ray from training data, we acquire points with a random sampling rate $N_s$. For example, the dynamic sampler utilizes different sample rates to get sample points from the red, blue, and purple radiation rays, as shown in the output of the multi-head predictor in Fig.~\ref{fig:model}. Accordingly, the rendering function in (\ref{eq:render_continous}) could be expressed in a discrete form as:
% \begin{equation}
% \label{eq:render_discrete}
%     I_r(\mathbf{d})=S\cdot(\log\sum_i^{\left\lfloor N_s\left(t_f-t_n\right)\right\rfloor} e^{\frac{V\left(t_n+\frac{1}{N_s} \cdot i\right)-C}{S}}-\log{N_s}).
% \end{equation}


% \subsection{Soft Rendering}
% In this paper, we use CBCT data to simulate the PX imaging and obtain the ground truth of 3D oral structure. However, Hounsfield Units (HU) is unreliable in CBCT scans due to variations in grayscale values for different areas in the scan. This can occur even when these areas have the same density, but different relative positions within the scanned organ \cite{cbct_no_hu_1}\cite{cbct_no_hu_2}. To obtain the PX image with a close distribution with real PX images, we choose to use a different rendering method following the work in \cite{PX_generation}. Therefore, the projection value of a radiation ray that originates from the position $\textbf{o}$ with direction $\textbf{d}$ between $t_n$ and $t_f$ can be expressed as:
% \begin{equation}
% \label{eq:render_continous}
%     I_r(\mathbf{o})=S \cdot \log \int_{t_n}^{t_f} e^{\frac{v(\mathbf{o}+t\cdot\mathbf{d})-C}{S}}dt
% \end{equation},
% where $v()$ denotes the voxel intensity value in 3D space, S and C are the scaling and bias factors. The selection value for C and S depend on the CBCT data used for simulation. A comparison of the proposed and conventional projection methods can be seen in Fig.~\ref{fig:px_compare}.




% Second, Hounsfield Units (HU) is unreliable in CBCT scans due to variations in grayscale values for different areas in the scan. This can occur even when these areas have the same density, but different relative positions within the scanned organ \cite{cbct_no_hu_1}\cite{cbct_no_hu_2}. As a result, one can not simply estimate the X-ray projection by applying the Beerâ€“Lambert law. A comparison of CBCT and PX imaging in different views is shown in Fig. \ref{fig:imaging}. These characteristics have brought great challenges in exploring 3D Oral structure from PX images by NeRF-like models.
% In the absence of accurate HU that could reflect the attenuation rate in physical world, we choose to propose a different model that learns a neural X-ray field (NeXF) for 3D oral reconstruction by PX images. The NeXF model would 