\begin{table*}[hbt!]
    \centering
     \caption{Comparison of PX and CBCT in dental imaging}
\begin{tabular}{p{1.5cm}<{\centering}p{1.5cm}<{\centering}p{2.6cm}<{\centering}p{5cm}<{\centering}p{5.0cm}<{\centering}}
    \hline
    Method&Image&Rotation&Tomography Theory&Dental Applications\cr
    \hline
    CBCT&3D&Fixed center&Computed axial tomography&Orthodontics, tumor surgery \cr
    PX&2D&Moving center&Focal plane tomography&Tooth pulling/planting\cr
    \hline
    \end{tabular}
    \label{tab:ct_and_px}
\end{table*}

\section{Background and Related Works}

\subsection{Radiology in dental imaging}
There are mainly two radiological imaging methods in dental health, i.e., CBCT and PX. CBCT generates a 3D image of the oral cavity with rich spatial information of teeth, thus widely used in orthodontics and tumor surgery. As a comparison, PX is a faster and lightweight method used in the examination before pulling or planting teeth, where a 2D panoramic picture is taken of all the teeth along the mandibular curve. We show illustrations of these two imaging methods viewed in the axial plane in Fig.~ \ref{fig:imaging} and comparisons in Table \ref{tab:ct_and_px}. In CBCT, as shown in the left image, the X-ray tube and the film moves around a fixed center for $360^\circ$. The 3D image is then reconstructed from sinogram signals in 2D space \cite{ct_theory}, which is feasible as each point is projected from different directions during the imaging. In PX, the X-ray tube and the film move around a moving center from one side to the other. The trajectory, also named the focal plane, generally fits the curved shape of the mandible, leading to different projection levels for tissues at various locations. For example, as shown in the right picture, the red point at $O_1$ located on the moving trajectory is projected twice while the green point at $Q_1$ off the moving trajectory is projected only once when the X-ray tube and the film move from A to B. Therefore, the image shows stronger signals for tissues at $O_1$ than $Q_1$, thus generating a clear picture of objects around the focal plane. Like CBCT, points around the focal plane also receive multiple projections in PX but are not used to recover any 3D information during imaging. This feature is taken advantage of our proposed model for 3D oral reconstruction.

\subsection{Implicit representation in 3D reconstruction}
Implicit representation has been demonstrated to be a promising method in the task of 3D reconstruction since the work of neural radiance field (NeRF) \cite{nerf}, where the researchers use the deep neural network to map 5D coordinates of spatial location and viewing direction into the density and emitted radiance of a voxel. During the inference, the model could generate images from any position by rendering along the rays sent from the observation point. Based on this framework, D-NeRF \cite{dnerf} takes time as additional input to the system for the reconstruction of dynamic scenes. Nerfies \cite{nerfies} use an additional continuous volumetric deformation field to generate deformable photo-like scenes. Although our method also utilizes implicit 3D representation, there are still big differences due to the characteristic of the imaging process in radiology: 1) The movement of an X-ray tube has less degree of freedom (DoF) than a camera, thus leading to limited projection rays in both directions and origins. 2) The predicted density distribution represents the values of HU instead of the differential probability. 3) The reconstruction object should be view-independent.

\subsection{Cross-dimension translation in radiology}
Cross-dimension translation in radiology images between 2D and 3D by deep neural networks starts from the work of \cite{x_to_3d}, where the authors use an encoding-decoding network to learn a back projection function that maps a 2D projection image into 3D density volumes for the skull of mammals. Following this work, \cite{x2ct_gan, knee_3d} improve the reconstruction quality for the abdomen and knees by utilizing bi-planar X-ray images and adversarial networks. In dental healthcare, Oral-3D \cite{oral_3d} first uses a single panoramic X-ray image to reconstruct the 3D oral structure. X2Teeth \cite{x2_teeth} trains three networks to reconstruct and segment the teeth in 3D space with annotated X-ray images. Our model can be seen as an extension of these works that focus on the same problem but with a different technical solution: 1) In contrast to learning explicitly by auto encoding or adversarial learning, our method learns the representation of the 3D object in an implicit way. 2) Our model relies no more on paired 2D and 3D images or individual prior knowledge to restore the mandibular curve.

