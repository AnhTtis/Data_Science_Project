{
    "arxiv_id": "2303.10100",
    "paper_title": "Unified Mask Embedding and Correspondence Learning for Self-Supervised Video Segmentation",
    "authors": [
        "Liulei Li",
        "Wenguan Wang",
        "Tianfei Zhou",
        "Jianwu Li",
        "Yi Yang"
    ],
    "submission_date": "2023-03-17",
    "revised_dates": [
        "2023-03-20"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "The objective of this paper is self-supervised learning of video object segmentation. We develop a unified framework which simultaneously models cross-frame dense correspondence for locally discriminative feature learning and embeds object-level context for target-mask decoding. As a result, it is able to directly learn to perform mask-guided sequential segmentation from unlabeled videos, in contrast to previous efforts usually relying on an oblique solution - cheaply \"copying\" labels according to pixel-wise correlations. Concretely, our algorithm alternates between i) clustering video pixels for creating pseudo segmentation labels ex nihilo; and ii) utilizing the pseudo labels to learn mask encoding and decoding for VOS. Unsupervised correspondence learning is further incorporated into this self-taught, mask embedding scheme, so as to ensure the generic nature of the learnt representation and avoid cluster degeneracy. Our algorithm sets state-of-the-arts on two standard benchmarks (i.e., DAVIS17 and YouTube-VOS), narrowing the gap between self- and fully-supervised VOS, in terms of both performance and network architecture design.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.10100v1"
    ],
    "publication_venue": "CVPR 2023. code: https://github.com/0liliulei/Mask-VOS"
}