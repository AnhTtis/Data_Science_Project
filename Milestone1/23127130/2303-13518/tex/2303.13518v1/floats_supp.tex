\newcommand{\tabArhParams}{
\def\y{\checkmark}
\def\n{~}
\begin{table*}[t]
\centering
\begin{tabular}{ccccrr} \toprule
&&&& \multicolumn{2}{c}{Batch size} \\
\cmidrule{5-6}
Backbone & Self-training & Init lr & Device & \LVISminusrare & CC12M \\
\midrule
NFNet-F0 & \n & $3 \times 10^{-4}$ & 16 TPUv3 chips & 128 & / \\
NFNet-F0 & \y & $3 \times 10^{-4}$ & 16 TPUv3 chips & 128 & 1024 \\
NFNet-F6 & \n & $1 \times 10^{-4}$ & 16 TPUv3 chips & 64 & / \\
NFNet-F6 & \y & $1 \times 10^{-4}$ & 32 TPUv4 chips & 32 & 256 \\
\bottomrule
\end{tabular}
\caption{{\bf Architecture-specific optimization parameters.}
}
\label{tab:archparams}
\end{table*}
}


\newcommand{\tabLvisAll}{
\begin{table*}[t]
\definecolor{cheat}{HTML}{999999}
\centering
\begin{tabular}{ccccccc} \toprule
& & & \multicolumn{2}{c}{LVIS} & \multicolumn{2}{c}{Transfer} \\
\cmidrule(l){4-5} \cmidrule(l){6-7}
Method & Train dataset & Backbone & \APall & \APrare & COCO & O365 \\
\midrule
\tworec & LVIS & NFNet-F0 & \textcolor{cheat}{\meanstd{34.4}{0.11}} & \textcolor{cheat}{\meanstd{23.7}{1.41}} & \meanstd{40.8}{0.11} & \meanstd{14.7}{0.07} \\
\tworec & \LVISminusrare & NFNet-F0 & \meanstd{33.8}{0.15} & \meanstd{20.9}{0.34} & \meanstd{40.6}{0.14} & \meanstd{14.6}{0.04} \\
\threerec & \LVISminusrare & NFNet-F0 & \meanstd{35.7}{0.20} & \meanstd{25.6}{1.12} & \meanstd{41.5}{0.16} & \meanstd{16.4}{0.15} \\
\tworec & LVIS & NFNet-F6 & \textcolor{cheat}{\meanstd{45.1}{0.18}} & \textcolor{cheat}{\meanstd{37.0}{0.97}} & \meanstd{46.5}{0.04} & \meanstd{20.8}{0.05} \\
\tworec & \LVISminusrare & NNetF-F6 & \meanstd{43.5}{0.12} & \meanstd{27.6}{0.80} & \meanstd{46.5}{0.26} & \meanstd{20.3}{0.05} \\
\threerec & \LVISminusrare & NFNet-F6 & \meanstd{44.6}{0.31} & \meanstd{30.1}{1.83} & \best{\meanstd{46.9}{0.05}} & \best{\meanstd{22.8}{0.14}} \\
\bottomrule
\end{tabular}
\caption{{\bf Training on all of LVIS vs self-training.}
Training \emph{\tworec} on full LVIS predictably performs better on LVIS than when
training on \LVISminusrare (\ie LVIS without annotations for rare classes).
However, it loses to the self-trained detector (\emph{\threerec}) when transferring to COCO and Objects365.
}
\label{tab:lvisall}
\end{table*}
}

%
%
%
%


\newcommand{\figOrig}{
\begin{figure*}[t]
\definecolor{arrow}{HTML}{6aa84f}
\definecolor{gate}{HTML}{ff9900}
%
\definecolor{back}{HTML}{cfe2f3}
\includegraphics[width=\linewidth]{figures/arch_orig.pdf}
\caption{{\bf Standard single-stage detector architecture.}
\textcolor{CornflowerBlue}{Light blue} and \textcolor{Apricot}{light yellow} parallelograms
represent the backbone and FPN feature maps, respectively;
circles with â†‘2 are non-trainable up--sampling,
squares are trainable modules (\eg convolutions),
convolution blocks show the kernel size
and potential striding (`s2': stride 2).
The alignment preserving architecture is shown in \isArXiv{Figure~\ref{fig:gating}.}{Figure 3 of the main paper.}
}
\label{fig:orig}
\end{figure*}
}


\newcommand{\zs}[1]{\textcolor{RedOrange}{#1}}
\newcommand{\ms}[1]{\textcolor{Gray}{#1}}

\newcommand{\figQualThreeVsTwo}{
\begin{figure*}[t]
\def\imW{0.495\linewidth}
\centering%
\begin{tabular}{c@{~~}c}
\includegraphics[width=\imW]{figures/qual/f6_2/P1040771.jpeg}
&
\includegraphics[width=\imW]{figures/qual/f6_3/P1040771.jpeg}
\\
\includegraphics[width=\imW]{figures/qual/f6_2/Parisian_gargoyle_Unsplash.jpg}
&
\includegraphics[width=\imW]{figures/qual/f6_3/Parisian_gargoyle_Unsplash.jpg}
\\
\includegraphics[width=\imW]{figures/qual/f6_2/1280px-Macaroons_at_Smiths.jpg}
&
\includegraphics[width=\imW]{figures/qual/f6_3/1280px-Macaroons_at_Smiths.jpg}
\\
(a) \tworec & (b) \threerec
\end{tabular}
\caption{{\bf \emph{\tworec} vs \emph{\threerec} (NFNet-F6).}
Detections with a score larger than 0.3 are shown.
The queries for the three examples are:
(top) \zs{Eiffel tower}, \zs{French flag}, \zs{cannon}, \ms{poster};
(middle) \zs{Eiffel tower}, \zs{gargoyle};
(bottom) \ms{cake}, \zs{macaron}.
No human-annotated boxes were seen during training for
\zs{all queries} apart from \ms{poster} and \ms{cake}.
\emph{\tworec} has zero-shot detection capability,
but \emph{\threerec} generally outperforms it.
}
\label{fig:qual:threevstwo}
\end{figure*}
}


\newcommand{\figQualThreeParis}{
\begin{figure*}[t]
\def\imHu{4.7cm}
\def\imHd{4.79cm}
\includegraphics[height=\imHu]{figures/qual/f6_3/1280px-Wolves_chasing_a_wapiti,_Yellowstone_River_2.jpg}
\includegraphics[height=\imHu]{figures/qual/f6_3/Jumping_over_the_moon.jpg}
\includegraphics[height=\imHu]{figures/qual/f6_3/1280px-Round_hay_bales_and_a_hot_air_balloon_somewhere_in_Luxembourg} \\
\includegraphics[height=\imHd]{figures/qual/f6_3/1280px-Men_Ice_hockey.jpg}
\includegraphics[height=\imHd]{figures/qual/f6_3/Venezia-gondola_on_canal_grande.jpeg}
\includegraphics[height=\imHd]{figures/qual/f6_3/1280px-POOL_HALL_-_NARA_-_543975.jpg}
\caption{{\bf \emph{\threerec} (NFNet-F6) zero-shot detection examples.}
Detections with a score larger than 0.3 are shown.
The queries for the six examples are:
(top-left) \zs{wolf}, \zs{wapiti}, \ms{duck};
(top-middle) \zs{rocket}, \zs{moon};
(top-right) \zs{hot-air balloon}, \zs{haystack};
(bottom-left) \ms{helmet}, \zs{puck}, \zs{hockey stick};
(bottom-middle) \zs{gondola}, \ms{pole};
(bottom-right) \zs{pool table}, \ms{ball}, \ms{deer}, \ms{wallclock}.
Networks were trained with human-annotated boxes for
\ms{duck}, \ms{helmet}, \ms{pole}, \ms{ball}, \ms{deer} and \ms{wallclock},
while no human-annotated boxes were seen during training for
\zs{wolf}, \zs{wapiti}, \zs{rocket}, \zs{moon}, \zs{hot-air balloon}, \zs{haystack}, \zs{puck}, \zs{hockey stick},
\zs{gondola}, and \zs{pool table}.
Note that \ms{dog} (a frequent training category) rightfully has a
lower confidence than \zs{wolf} for the top-left image.
}
\label{fig:qual:threeparis}
\end{figure*}
}


\newcommand{\figQualLvis}{
\begin{figure*}[t]
\vspace{-0.5cm}
\centering
\includegraphics[width=0.95\linewidth]{figures/qual/lvis_6rows}
\caption{{\bf Random sample: LVIS validation set (\emph{\threerec}, NFNet-F6).}
Up to 20 detections with a score larger than 0.5 are shown.
Best viewed digitally.
}
\label{fig:qual:lvis}
\end{figure*}
}


\newcommand{\figQualCoco}{
\begin{figure*}[t]
\vspace{-0.5cm}
\centering
\includegraphics[width=0.95\linewidth]{figures/qual/coco_6rows}
\caption{{\bf Random sample: COCO validation set (\emph{\threerec}, NFNet-F6).}
The detector is trained on \LVISminusrare and transferred
to COCO without any additional training.
Up to 20 detections with a score larger than 0.5 are shown.
Best viewed digitally.
}
\label{fig:qual:coco}
\end{figure*}
}


\newcommand{\figQualObj}{
\begin{figure*}[t]
\vspace{-0.5cm}
\centering
\includegraphics[width=0.95\linewidth]{figures/qual/objects365v1_6rows}
\caption{{\bf Random sample: Objects365-v1 validation set (\emph{\threerec}, NFNet-F6).}
The detector is trained on \LVISminusrare and transferred
to Objects365 without any additional training.
Up to 20 detections with a score larger than 0.5 are shown.
Best viewed digitally.
}
\label{fig:qual:o365}
\end{figure*}
}
