
\begin{figure*}[htb]
  \centering
  \includegraphics[width=0.99\textwidth]{bars.pdf}
  \caption{Results of ~\framework{} with different encoding tree heights.}
  \label{fig:K-bar}
  \Description{Results with different encoding tree heights.}
\end{figure*}



\section{Results and Analysis}\label{sec:evalu}
In this section, we demonstrate the efficacy of \ \framework{} on semi-supervised node classification (\S ~\ref{sec:exp:overall}, followed by micro-benchmarks that investigate the detailed effect of the submodules on the overall performance and validate the robustness of ~\framework{} when tackling random perturbations (\S ~\ref{sec:exp:micro}). For better interpretation, we visualize the change of structural entropy and graph topology (\S ~\ref{sec:exp:int}).


\subsection{Node Classification}
\label{sec:exp:overall}



\subsubsection{Comparison with baselines}
We compare the node classification performance of ~\framework~ with ten baseline methods on nine benchmark datasets.
Table ~\ref{tab:performance comparison} shows the average accuracy and the standard deviation. 
Note that the results of H$_2$GCN (except PT and TW) and Geom-GCN are from the reported value in original papers ( - for not reported), while the rest are obtained based on the execution of the source code provided by their authors under our experimental settings. Our observations are three-fold: 
% \textbf{(1)} While all GNN methods can achieve satisfactory results on citation networks, graph structural learning frameworks perform significantly better than conventional GNN methods on WebKB, Wiki, and actor co-occurrence networks due to the high heterophily of these networks.
% The reason for this phenomenon is these conventional GNN models agggregate to much classification-irrelevant information from disassortative neighborhoods. 
% In contrast, graph structural learning can optimize the neighborhood topology to achieve better results.

% \textbf{(1)} While all GNN methods can achieve satisfactory results on citation networks, the specialized graph learning frameworks perform significantly better on WebKB, Wiki and actor co-occurence networks due to the heterophily challenge. 


\noindent \textbf{(1)} \framework~ achieves optimal results on 5 datasets, runner-up results on 8 datasets, and advanced results on all datasets. The accuracy can be improved up to 3.41\% on Pubmed, 3.00\% on Cora, and 2.92\% on Citeseer compared to the baselines. This indicates that our design can effectively capture the inherent and deep structure of the graph and hence the classification improvement. 


\noindent \textbf{(2)} \framework~ shows significant improvement on the datasets with heteropily graphs, e.g., up to 37.97\% and 27.13\% improvement against Wisconsin and Texas datasets, respectively. This demonstrates the importance of the graph structure enhancement that can contribute to a more informative and robust node representation.


\noindent \textbf{(3)} While all GNN methods can achieve satisfactory results on citation networks, the graph learning/high-order neighborhood awareness frameworks substantially outperform others on the WebKB datasets and the actor co-occurrence networks, which is highly disassortative. This is because these methods optimize local neighborhoods for better information aggregation. Our method is one of the top performers among them due to the explicit exploitation of the global structure information in the graph hierarchical semantics.




\subsubsection{Comparison base on different backbones}
Table~\ref{tab:backbone comparison} shows the mean classification accuracy of ~\framework{} with different backbone encoders.
Observably, ~\framework{} upon GCN and GAT overwhelmingly outperforms its backbone model, with an accuracy improvement of up to 31.04\% and 27.48\%, respectively. 
This indicates the iterative mechanism in the ~\framework{} pipeline can alternately optimize the node representation and graph structure.
We also notice that despite the lower improvement, ~\framework{} variants based on GraphSAGE and APPNP perform relatively better compared to those on GCN and GAT.
This is most likely due to the backbone model itself being more adapted to handle disassortative settings on graphs.
% We also notice that ~\framework~ based on GraphSAGE has the lowest improvement. This is most likely due to the weak adaptability of the backbone model itself to disassortative settings.

\begin{table}[t]
    \renewcommand{\arraystretch}{1.05}
    \setlength{\abovecaptionskip}{0.15cm}
    \setlength{\belowcaptionskip}{-0.25cm}
    \caption{Classification accuracy(\%) of ~\framework{} and corresponding backbones. Wisc. is short for Wisconsin.}%mean relative 
    \label{tab:backbone comparison}
    \centering
    % \scalebox{0.9}{
    % \setlength{\tabcolsep}{1mm}{
        \begin{tabular}{l|ccccc}
        \hline
        Method & Actor & TW & Texas & Wisc. & Improvement\\
        \hline
        \framework$_{GCN}$   & 35.03 & 66.88 & 75.68 & 79.61 & $\uparrow$ 5.20$\sim$31.04\\
        % Chebnet         &
        % \framework(Chebnet)
        % \midrule
        % SGC             &
        % \framework(SGC)
        % \framework
        % (SAGE)            & 36.34 & 66.92 & \textbf{81.62} & \textbf{86.27} & $\uparrow$ 0.25$\sim$3.79\\
          \framework$_{SAGE}$& 36.20 & 66.92 & \textbf{82.49} & \textbf{86.27} & $\uparrow$ 0.25$\sim$6.79\\
        \framework$_{GAT}$   & 32.46  & 63.57 & 74.59 & 78.82 & $\uparrow$ 4.69$\sim$27.48\\
        % \framework(APPNP) & \textbf{36.62} & 71.45 & 81.28 & 83.14 & 13.34\%\\
        \framework$_{APPNP}$ & \textbf{36.34} & \textbf{66.99} & 81.28 & 83.14 & $\uparrow$ 2.01$\sim$12.16\\
        \hline
        \end{tabular}
    % }
    % }
\end{table}


\begin{table}[t]
    % \renewcommand{\arraystretch}{0.75}
    \setlength{\abovecaptionskip}{0.15cm}
    \setlength{\belowcaptionskip}{-0.25cm}
    \caption{The $k$ selection for each iteration in structural optimization. Bolds represent the $k$ selection when the accuracy reaches maximum.}\label{tab:k-NN comparison}
    \centering
    % \scalebox{0.9}{
    \setlength{\tabcolsep}{2mm}{
        \begin{tabular}{l|ccccccccc}
        \hline
        Iteration & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9\\
        \hline
        {Cora}   & 22 & \bf{22} & 19 & 22 & 21 & 22 & 20 & 21 & 20\\
        {Actor}  & 23   & 15 & 15 & 15 & 14 & 15 & 14 & \bf{14} & 15\\
        {TW} & 50 & 16 & 16 & \bf{17} & 15 & 17 & 27 & 16 & 16 \\
        {Wisconsin} & 21 & 16 & \bf{11} & 16 & 14 & 13 & 16 & 13 & 11 \\
        {Texas}  & 21 & 13 & 13 & \bf{13} & 13 & 10 & 14 & 10 & 14 \\
        \hline
        \end{tabular}
    }
\end{table}

\subsection{Micro-benchmarking}
\label{sec:exp:micro}

\subsubsection{Effectiveness of~$k$-selector}
This subsection evaluate how the one-dimensional structural entropy guides the $k$-selector in \S ~\ref{step1}.
Table ~\ref{tab:k-NN comparison} showcases the selected parameter $k$ in each iteration with \framework$_{GCN}$. 
Noticeably, as the iterative optimization proceeds, the optimal parameter $k$ converges to a certain range, indicating the gradual stabilization of the graph structure and node representation. The disparity of parameter $k$ among different datasets also demonstrates the necessity of customizing $k$ in different cases rather than using $k$ as a static hyperparameter.




\subsubsection{Impact of the encoding tree's height $K$}
We evaluate all four variants of ~\framework~ on the website network datasets, and the encoding tree height $K$ involved in \S ~\ref{step2} varies from 2 to 4.
As shown in Fig. ~\ref{fig:K-bar}, there is a huge variation in the optimal tree heights among different datasets. For example, in the variants based on GAT, GCN, and APPNP, the best results can be targeted at $K=3$ in Texas and at $K=4$ in Cornell and Wisconsin. By contrast, in ~\framework$_{SAGE}$,  $K=2$ can enable the best accuracy of 86.27\%. This weak correlation between the best $K$ and the model performance is worth investigating further, which will be left as future work. 


\begin{figure}[tb]
  \centering
  \includegraphics[width=0.48\textwidth]{ptb_exp.pdf}
  \caption{Robustness of ~\framework~ against random noises.}
  \label{fig:pertubation}
  \Description{Results of perturbation experiment.}
\end{figure}


\begin{figure*}[tb]
  \centering
  \includegraphics[width=0.99\textwidth]{sedecrease.pdf}
  \caption{The normalized structural entropy changes during the training of ~\framework$_{GAT}$ with 2-dimensional structural entropy on (a) Texas, (b) Cornell, and (c) Wisconsin. The structure is iterated every 200 epochs. By comparison, (d) shows the entropy changes on Wisconsin without the graph reconstruction strategy.}
  \label{fig:sedecrease}
  \Description{Visualization of structural entropy and acc. variation.}
\end{figure*}


\begin{figure}[tb]
  \centering
  \includegraphics[width=0.49\textwidth]{topovisual.pdf}
  \caption {The visualized evolution of the graph structure on Cora (a,b,c) and Citeseer (d,e,f). The corresponding Structural Entropy (SE) is also shown.}
  \label{fig:topovisual}  
  \Description{Visualization of topology evolution.}
\end{figure}



\subsubsection{Sensitivity to perturbations}
We introduce random edge noises into Cora and Citeseer, with perturbation rates of 0.2, 0.4, 0.6, 0.8, and 1. As shown in Fig.~\ref{fig:pertubation}(a), ~\framework{} outperforms baselines in both GCN and GAT cases under most noise settings. For instance, ~\framework$_{GCN}$ achieves up to 8.09\% improvement against the native GCN when the perturbation rate is 0.8; by contrast, improvements by GCN-Jaccard and GCN-DropEdge are merely 6.99\% and 5.77\%, respectively. A similar phenomenon is observed for most cases in the Citeseer dataset (Fig.~\ref{fig:pertubation}(b)), despite an exception when compared against GCN-Jaccard. Nevertheless, our approach is still competitive and even better than GCN-Jaccard at a high perturbation rate. 

\subsection{Interpretation of Structure Evolution}
\label{sec:exp:int}



\subsubsection{Structural entropy variations analysis}
We evaluate how the structural entropy changes during the training of ~\framework$_{GAT}$ with 2-dimensional structural entropy on WebKB datasets. For comparison, we visualize the entropy changes on Wisconsin without the structure learning. In the experiment setting, both the graph structure and the encoding tree are updated once at each iteration (i.e., 200 GNN epochs), and within one iteration, the structural entropy is only affected by edge weights determined by the similarity matrix. For comparison, we normalize the structural entropy by $ \textstyle{\frac{H^{\mathcal{T}}(G)}{H^1(G)}}$.

As shown in Fig.~\ref{fig:sedecrease}(a)-(c), as the accuracy goes up, the normalized structural entropy constantly decreases during the iterative graph reconstruction, reaching the minimums of 0.7408 in Texas, 0.7245 in Cornell, and 0.7344 in Wisconsin. This means the increasing determinism of the overall graph structure and the reduced amount of information required to determine a vertex. 
Interestingly, if our graph reconstruction mechanism is disabled (as shown in Fig.~\ref{fig:sedecrease}(d)), the normalized structural entropy keeps rising from 0.7878, compared with Fig.~\ref{fig:sedecrease}(c). Accordingly, the final accuracy will even converge to 55.34\%, a much lower level. 

Such a comparison also provides a feasible explanation for the rising trend of the normalized structural entropy within every single iteration. 
This stems from the smoothing effect during the GNN training. 
As the node representation tends to be homogenized, the graph structure will be gradually smoothed, leading to a decrease in the one-dimensional structural entropy thus the normalized structural entropy increases.
% We speculate that the continuous rise in structural entropy may be a feasible explanation for the over-smoothing of graph neural networks, which requires further study.
% In summary, this experiment well explains the robustness of our framework.


\subsubsection{Visualization}
Fig.~\ref{fig:topovisual} visualizes the topology of the original Cora and Citeseer graph and of the 2nd and 5th iterations.
The vertex color indicates the class it belongs to, and the layout denotes connecting relations. Edges are hidden for clarity. As the iteration continues, much clearer clustering manifests -- few outliers and more concentrated clusters.  
Vertices with the same label are more tightly connected due to the iterative graph reconstruction scheme. This improvement hugely facilitates the interpretability of the GSL and the node representation models. 
