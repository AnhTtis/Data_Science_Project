
\section{Negative Weight Elimination in Vector Boson plus Jets Production at NLO}
\label{sec:analyses}

We are now in a position to apply cell resampling to large
high-multiplicity event samples. We consider the production of a
vector boson in association with jets at NLO, using
\textsc{ROOT}~\cite{Brun:1997pa} \texttt{ntuple}~\cite{Bern:2013zja,Anger:2017nkq}
event files generated with \textsc{BlackHat}~\cite{Berger:2008sj} and
\textsc{Sherpa} 2.1~\cite{Gleisberg:2008ta}. Jets are defined
according to the anti-$k_t$ algorithm~\cite{Cacciari:2008gp} with $R =
0.4$ and a minimum transverse momentum of $25\,$GeV. More details on
the event generation are given in~\cite{Bern:2013gka,Anger:2017nkq}. The various
samples with their most salient properties are listed in
table~\ref{tab:samples}.

\begin{table}[htb]
  \centering
  \begin{tabular}{llll}
    \toprule
    Sample & Process & Centre-of-mass energy & \# events \\
    \midrule
    \texttt{Z1} & $pp \to (Z \to e^+e^-) + \text{jet}$ & 13\,TeV & $8.21\times 10^8$\\
    \texttt{Z2} & $pp \to (Z \to e^+e^-) + 2\text{ jets}$ & 13\,TeV & $5.30\times 10^8$\\
    \texttt{Z3} & $pp \to (Z \to e^+e^-) + 3\text{ jets}$ & 13\,TeV & $1.65\times 10^9$\\
    \texttt{W5} & $pp \to (W^- \to e^- \nu_e) + 5\text{ jets}$ & 7\,TeV & $1.17 \times 10^9$\\
    \bottomrule
  \end{tabular}
  \caption{NLO event samples used for cell resampling.}
  \label{tab:samples}
\end{table}

We apply cell resampling to each of the samples, defining
infrared-safe physics objects according to the above jet
definition. We use the distance function defined in
\cite{Andersen:2020sjs}, which follows from
equations~\eqref{eq:d_event}, \eqref{eq:d_set}, and the momentum
distance
\begin{equation}
  \label{eq:p_dist}
  d(p, q) = \sqrt{\lvert\vec{p} - \vec{q}\,\rvert^2 + \tau^2 (p_\perp - q_\perp)^2}.
\end{equation}
Here, we set $\tau = 0$ and limit the maximum cell radius to 10\,GeV
for samples \texttt{Z1}, \texttt{Z2}, and \texttt{W5}, and to 2\,GeV
for sample \texttt{Z3}. To examine the impact of these choices for the
maximum radius we additionally compare to a resampling run with a
maximum cell size of 100\,GeV for sample \texttt{W5}.

For better parallelisation and general performance we
pre-partition each input sample into several regions according to one
of the upper levels of a vantage-point tree, as explained in
section~\ref{sec:nearest-neighbour_search}. Here, we use the seventh
level, corresponding to 128 regions.

To interpret our results we use standard
\textsc{Rivet}~\cite{Bierlich:2019rhm} analyses. We verify that the
event count and total cross section of each sample is preserved using
the \texttt{MC\_XS} analysis. Furthermore, we employ this analysis to
assess the degree to which negative weights are eliminated. For the
sample \texttt{W5} we additionally use the \texttt{MC\_WINC} and
\texttt{MC\_WJETS} analysis, and their counterparts \texttt{MC\_ZINC}
and \texttt{MC\_ZJETS} for the remaining samples involving a Z
boson. We investigate the impact of additional cuts applied after cell
resampling using the ATLAS analysis
\texttt{ATLAS\_2017\_I1514251}~\cite{ATLAS:2017sag} for inclusive Z
boson production.

\subsection{Comparison of Predictions}
\label{sec:comp_pred}

We first assert that predictions remain equivalent by comparing a
number of distributions before and after cell
resampling. Figure~\ref{fig:comp_W5} shows a variety of distributions
for sample \texttt{W5}. In figure~\ref{fig:comp_Z1_to_Z3} we show selected
distributions for the \texttt{Z1}, \texttt{Z2}, and \texttt{Z3}
samples. In all cases, we find that the differences between original
and resampled predictions are comparable to or even smaller than the
statistical bin-to-bin fluctuations in the original. A more indirect
way to estimate the bias introduced by cell resampling is to consider
the characteristic cell radii and the spread of measured observables
within the cells. This is discussed in appendix \ref{sec:cell_sizes}.

\begin{figure}[htb]
  \centering
  \includegraphics[width=0.45\linewidth]{W5/MC_WINC_W_pT}
  \includegraphics[width=0.45\linewidth]{W5/MC_WJETS_jet_pT_4}
  \includegraphics[width=0.45\linewidth]{W5/MC_WINC_W_y}
  \includegraphics[width=0.45\linewidth]{W5/MC_WJETS_jet_y_4}
  \includegraphics[width=0.45\linewidth]{W5/MC_WINC_W_phi}
  \includegraphics[width=0.45\linewidth]{W5/MC_WJETS_W_jet1_dR}
  \caption{%
    Comparison of distributions before and after cell resampling for
    sample \texttt{W5} in table~\ref{tab:samples}. The blue lines indicate
    cell resampling with a maximum cell radius of 10\,GeV, the green lines
    result from a radius limit of 100\,GeV. Distributions are normalised
    according to the total cross section for sample \texttt{W5}.
  }
  \label{fig:comp_W5}
\end{figure}

\begin{figure}[htb]
  \centering
  \begin{subfigure}{0.45\linewidth}
    \label{fig:Z1_pt}
      \includegraphics[width=\linewidth]{Z1/ATLAS_2017_I1514251_d13-x01-y01}
      \caption{$p_\perp$ of hardest jet in sample \texttt{Z1}}
    \end{subfigure}
\begin{subfigure}{0.45\linewidth}
    \label{fig:Z2_pt}
    \includegraphics[width=\linewidth]{Z2/ATLAS_2017_I1514251_d16-x01-y01}
  \caption{$p_\perp$ of hardest jet in sample \texttt{Z2}}
\end{subfigure}
\begin{subfigure}{0.45\linewidth}
      \label{fig:Z3_pt}
  \includegraphics[width=\linewidth]{Z3/ATLAS_2017_I1514251_d19-x01-y01}
  \caption{$p_\perp$ of hardest jet in sample \texttt{Z3}}
\end{subfigure}
\begin{subfigure}{0.45\linewidth}
      \label{fig:Z1_y}
  \includegraphics[width=\linewidth]{Z1/ATLAS_2017_I1514251_d25-x01-y01}
  \caption{Rapidity of hardest jet in sample \texttt{Z1}}
\end{subfigure}
\begin{subfigure}{0.45\linewidth}
      \label{fig:Zn_y}
  \includegraphics[width=\linewidth]{ZJETS_jety}
  \caption{Rapidity of $n$th jet in sample \texttt{Z}$n$}
\end{subfigure}
\caption{%
  Comparison of distributions before and after cell resampling for
  samples \texttt{Z1}, \texttt{Z2}, and \texttt{Z3} in table~\ref{tab:samples}.
  Subfigures (a) to (d) show jet transverse momentum and rapidity
  distributions taken from the \texttt{ATLAS\_2017\_I1514251} Rivet
  analysis. Subfigure (e) is a jet rapidity distribution taken from
  \texttt{MC\_ZJETS}.
  }
  \label{fig:comp_Z1_to_Z3}
\end{figure}

\subsection{Improvement in Sample Quality}
\label{sec:weight_elim}

In order to assess the improvement achieved through cell resampling,
we first consider the reduction in the negative weight
contribution. To this end, we determine how much larger the original
and the resampled event samples have to be to reach the same
statistical power as an event sample without negative weights. In
other words, we compute $N(r_-)$ as defined in
equation~\eqref{eq:N_r_-}, where the fractional negative-weight
contribution $r_- = \sigma_-/(\sigma_+ + \sigma_-)$ is obtained from
the contribution $\sigma_+$ of positive-weight events to the total
cross section $\sigma$ and the absolute value of the negative-weight
cross section contribution $\sigma_- = \sigma_+ - \sigma$.

As demonstrated in figure~\ref{fig:Neff}, cell resampling leads to a
drastic improvement by roughly two to three orders of
magnitude. Increasing the maximum cell radius leads to an even
stronger reduction, at the cost of increased computing time and
potentially larger systematic errors introduced by the procedure. To
assess the impact of pre-partioning the event samples, we
alternatively resample \texttt{Z1} without prior partitioning. This
leads to a slight reduction of $N(r_-)/N(0)$ from 18.4 with
pre-partitioning to 17.1 without pre-partitioning.
% see branch `no_parallel` for numbers

\begin{figure}[htb]
  \centering
  \includegraphics[width=\linewidth]{Neff}
  \caption{%
    Required number of events relative to an ideal event sample without
    negative weights before and after resampling. Event samples are
    labeled as listed in table~\ref{tab:samples}.
  }
  \label{fig:Neff}
\end{figure}

Cell resampling not only reduces the amount of negative weights, but
as a by-product also results in a narrower weight distribution,
enhancing the unweighting efficiency. Indeed, after standard
unweighting we retain only 320 out of the $8.21\times 10^8$ events in
the \texttt{Z1} sample. If we apply resampling beforehand, unweighting
yields 11574 events. The resulting unweighted sample is not only
larger, but also contains a lower fraction of negative-weight
events. We show the gain in statistical power by selecting a subset of
320 randomly chosen events and compare to the unweighted sample based
on the original events. Selected distributions are shown in figure~\ref{fig:unweight}.

\begin{figure}[htb]
  \centering
      \includegraphics[width=0.45\linewidth]{Z1/unweighted/MC_ZINC_Z_pT}
      \includegraphics[width=0.45\linewidth]{Z1/unweighted/MC_ZINC_Z_y}
      \includegraphics[width=0.45\linewidth]{Z1/unweighted/ATLAS_2017_I1514251_d13-x01-y01}
      \includegraphics[width=0.45\linewidth]{Z1/unweighted/ATLAS_2017_I1514251_d25-x01-y01}
      \caption{%
        Comparison between unweighted samples before and after
        cell resampling. Lines labeled ``original'' show the reference
        prediction from the original weighted event sample \texttt{Z1}. After
        standard unweighting, the lines with the label ``unweighted'' are
        obtained. Applying cell resampling followed by standard
        unweighting to the sample \texttt{Z1} yields a sample
        represented by the ``resampled + unweighted'' lines. Out of
        this sample, we randomly select a subset matching the size of the
        original ``unweighted'' sample. This leads to the ``resampled +
        unweighted (small sample)'' lines.  Data points are taken
        from~\cite{ATLAS:2017sag}.
      }
  \label{fig:unweight}
\end{figure}

\subsection{Runtime Requirements}
\label{sec:timings}

Cell resampling with the improvements presented in
section~\ref{sec:improvements} and a maximum cell size of 10\,GeV
typically takes a few hours of wall-clock time for samples with about
a billion events. As an example, let us consider the resampling for
the \texttt{W5} sample listed in table~\ref{tab:samples}. The combined
size of the original compressed event files is approximately
150\,GB. The resampling program requires about 450\,GB of memory and
the total runtime is about 9 hours on a machine with 24 Intel Xeon
E5-2643 processors. The memory usage could of course be reduced
significantly at the cost of computing time by not keeping all events
in memory, but we have not explored this option in our current
implementation. Reading in the events and converting them to a
space-efficient internal format that only retains the information
needed for resampling takes about 2 hours. This is followed by
approximately 30 minutes spent for the pre-partitioning of the event
sample and less than 3 hours for resampling itself, including the
construction of the search trees,
cf. section~\ref{sec:nearest-neighbour_search}. Since the event
information in the internal format is incomplete, we finally read in
the original events again and write them to disk after updating their
weights. This final step takes roughly 4 hours. While input and output
do not benefit from parallelisation, the pre-partitioning and the
resampling are performed in parallel and the total CPU time spent is
55 hours.

One important optimisation discussed in
section~\ref{sec:nearest-neighbour_search} is trimming the
nearest-neighbour search according to the maximum cell radius. In
fact, when increasing the allowed radius from 10\,GeV to 100\,GeV the
wall clock time needed for resampling rises to several weeks, with a correponding
increase in total CPU time. Extrapolating from smaller
sample sizes, the expected total required CPU time without any of the
new optimisations would be of the order of 1600 years for the much
simpler process of W boson production with two jets considered
in~\cite{Andersen:2021mvw}.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
