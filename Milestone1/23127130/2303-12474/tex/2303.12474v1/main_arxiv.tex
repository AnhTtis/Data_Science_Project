%%
%% This is file `sample-authordraft.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `authordraft')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-authordraft.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass command.
% DEFAULT \documentclass[sigconf,authordraft]{acmart} 
\documentclass[sigconf]{acmart} 
% authordraft / acmart -> anonymous for double-blind / clear

%% NOTE that a single column version may required for 
%% submission and peer review. This can be done by changing
%% the \doucmentclass[...]{acmart} in this template to 
%% \documentclass[manuscript,screen]{acmart}
%% 
%% To ensure 100% compatibility, please check the white list of
%% approved LaTeX packages to be used with the Master Article Template at
%% https://www.acm.org/publications/taps/whitelist-of-latex-packages 
%% before creating your document. The white list page provides 
%% information on how to submit additional LaTeX packages for 
%% review and adoption.
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.


%\setcopyright{acmlicensed}\acmConference[WWW '23 Companion]{Companion Proceedings of the ACM Web Conference 2023}{April 30-May 4, 2023}{Austin, TX, USA}
%\copyrightyear{2023}
%\acmYear{2023}
%\acmDOI{10.1145/3543873.3587638}

%% These commands are for a PROCEEDINGS abstract or paper.
%\acmConference[Submission to CySoc 2023]{}{April 30 -- May 04, 2023}{Austin, Texas, US}
%
%  Uncomment \acmBooktitle if th title of the proceedings is different
%  from ``Proceedings of ...''!
%
%\acmBooktitle{Companion Proceedings of the ACM Web Conference 2023 (WWW '23 Companion), April 30-May 4, 2023, Austin, TX, USA}
%\acmPrice{15.00}
%\acmISBN{978-1-4503-9419-2/23/04}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%


%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\usepackage{verbatim}
\usepackage[normalem]{ulem}


%\usepackage[colorinlistoftodos]{todonotes}


\definecolor{amethyst}{rgb}{0.6, 0.4, 0.8}

% decomment to EXTENDED VERSION (and decomment also in text) commentatao per togliere \newcommand per The ACM Publishing System (TAPS)
%\newcommand\fab[1]{{\color{teal}#1}}
%\newcommand\mari[1]{{\color{red}#1}}
%\newcommand{\newhref}[2]{\href{#1}{\color{blue}\underline{#2}}}%
%\newcommand{\cutforworkshop}[1]{}

% comment to submit
%\newcommand\man[1]{{\color{amethyst}#1}}
%\newcommand{\hlworkshop}[1]{\hl{#1}}
%\newcommand{\todoworkshop}[1]{\hl{#1}}
%\newcommand{\adjustfiltering}[1]{\textcolor{red}{#1}}

%comment for internal 
%\newcommand\man[1]{#1}
%\newcommand{\hlworkshop}[1]{#1}
%\newcommand{\todoworkshop}[1]{#1}
%\newcommand{\adjustfiltering}[1]{#1}


\usepackage{soul}

%\href{https://pypi.org/project/NEMtropy/}{\color{blue}{\underline{Pypi}}}
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
% \title{Swing and Safe states: Comparing online disinformation flows during the 2020 US elections}
% \title{Imbalance in online disinformation exposure\\ for swing and safe states in the 2020 US elections}
%\title{Swinging here and there: Imbalance of online disinformation\\ in safe and battleground states}
% \title{The swing state of the Union:\\how the disinformation on Twitter\\mirrors the US presidential election system}
\title{Swinging in the States:\\Does disinformation on Twitter mirror\\ the US presidential election system?}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.

\author{Manuel Pratelli}
\email{manuel.pratelli@imtlucca.it}
\orcid{0000-0002-9978-791X}
\affiliation{%
  \institution{IMT Scuola Alti Studi Lucca}
  \streetaddress{Piazza San Francesco 19}
  \city{Lucca}
  \country{Italy}
  \postcode{55100}
}
\affiliation{%
  \institution{Istituto di Informatica e Telematica CNR}
  \streetaddress{via G. Moruzzi 1}
  \city{Pisa}
  \country{Italy}
  \postcode{56124}
}

\author{Marinella Petrocchi}
\email{marinella.petrocchi@iit.cnr.it}
\orcid{0000-0003-0591-877X}
\affiliation{%
  \institution{Istituto di Informatica e Telematica CNR}
  \streetaddress{via G. Moruzzi 1}
  \city{Pisa}
  \country{Italy}
  \postcode{56124}
}
\affiliation{%
  \institution{IMT Scuola Alti Studi Lucca}
  \streetaddress{Piazza San Francesco 19}
  \city{Lucca}
  \country{Italy}
  \postcode{55100}
}

\author{Fabio Saracco}
\email{fabio.saracco@cref.it}
\orcid{0000-0003-0812-5927}
\affiliation{%
  \institution{`Enrico Fermi' Research Center}
  \streetaddress{via Panisperna 89A}
  \city{Rome}
  \country{Italy}
  \postcode{00184}
}
\affiliation{%
  \institution{IMT Scuola Alti Studi Lucca}
  \streetaddress{Piazza San Francesco 19}
  \city{Lucca}
  \country{Italy}
  \postcode{55100}
}


\author{Rocco De Nicola}
\email{rocco.denicola@imtlucca.it}
\orcid{0000-0003-4691-7570}
\affiliation{%
  \institution{IMT Scuola Alti Studi Lucca}
  \streetaddress{Piazza San Francesco 19}
  \city{Lucca}
  \country{Italy}
  \postcode{55100}
}


%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
%\renewcommand{\shortauthors}{Pratelli, M., et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  For more than a decade scholars have been investigating the disinformation flow on social media contextually to societal events, like, e.g., elections.
  In this paper, we analyze the Twitter traffic related to the US 2020 pre-election  debate and ask whether it mirrors the electoral system.
  The U.S. electoral system provides that, regardless of the actual vote gap, the premier candidate who received more votes in one state `takes' that state. Criticisms of this system have pointed out that election campaigns can be more intense in particular key states to achieve victory, so-called {\it swing states}.
  Our intuition is that election debate may cause more traffic on Twitter-and probably be more plagued by misinformation-when associated with swing states. The results mostly confirm the intuition. 
  %commentato per la versione workshop
  %\cutforworkshop{First, two main communities emerge, one displaying a purely Republican affiliation, the other one including accounts with mixed political orientation. Second, the vast majority of the disinformation flow is concentrated in the first community} 
About 88\% of the entire traffic can be associated with swing states, and links to non-trustworthy news are shared  far more in swing-related traffic than the same type of news in safe-related traffic.
%   but no clear majority of disinformation flow is detected in traffic associated with swing rather than safe states.
  Considering traffic origin instead, non-trustworthy tweets generated by automated accounts, so-called social bots, are mostly associated with swing states. Our work sheds light on the role an electoral system plays in the evolution of online debates, with, in the spotlight, disinformation and social bots.
%   To the best of our knowledge, this is the first work investigating the presence of disinformation flows relative to aspects intrinsic to an electoral system\man{, specifically concerning the US 2020 pre-election debate}. %Despite some limitations, we believe the results obtained are encouraging and we make publicly available to the scientific community the dataset used in this study to foster further research.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003033.10003083.10003094</concept_id>
       <concept_desc>Networks~Network dynamics</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010147.10010178</concept_id>
       <concept_desc>Computing methodologies~Artificial intelligence</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010405.10010455</concept_id>
       <concept_desc>Applied computing~Law, social and behavioral sciences</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10003120</concept_id>
       <concept_desc>Human-centered computing</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Networks~Network dynamics}
\ccsdesc[500]{Computing methodologies~Artificial intelligence}
\ccsdesc[500]{Applied computing~Law, social and behavioral sciences}
\ccsdesc[500]{Human-centered computing}



%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{social network analysis, disinformation flow, social bots, maximum-entropy null-models, 
US presidential elections, Twitter}



%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}

In human society, disinformation and propaganda have a history as long as mankind. Such phenomena  manifest themselves most bitterly in times of crisis, such as wars and natural disasters\footnote{The long history of disinformation during war. Online: \url{https://www.washingtonpost.com/outlook/2022/04/28/long-history-misinformation-during-war/}. All urls have been accessed on October 13, 2022.}.
%
Consider, for example, the Battle of Actium in 31 B.C., one of the most momentous naval battles in history, which saw Marc Antony succumb and paved the way for Octavian to become the first emperor of the Roman empire, under the name Caesar Augustus. 
`Propaganda did not decide the war, but it allowed each side to rally its troops'~\cite{Strauss22war}. 

% Indeed, the road to war was beaten on one side by Octavian, who accused Antony's lover Egyptian Queen Cleopatra of being a witch and manipulating her man against Rome. On the other hand, Antony was appealing to the Roman senate by boasting of Octavian's plebeian origins vs. his pure descent from Caesar. 

But while deception for societal strategies 
% as a military, political, economic, and social strategy 
has always existed, the advent of the internet and social media has made the spread of false and biased news faster (we would say almost instantaneous), widespread, and `able to reach specific segments of the population'~\cite{Bradshaw2018junk}.  
In addition, the continuous bombardment of information from every medium to which we are subjected makes it extremely difficult to learn essential and correct information about an issue; so much so that the World Health Organization created a new term, {\it infodemic}, portmanteau  of the words {\it information} and {\it epidemic}, to define the information confusion to which we are exposed daily~\cite{cinelli2020info}. 



% Scholars have been examining the online spread of fake news for years, and the focus since 2016 has been on the political debate, particularly election events such as general elections. 

Many scholars have focused on the 2016 U.S. presidential election, wondering how much digital disinformation influenced Trump's victory, but not finding a definitive answer. The study in~\cite{Georgacopoulos2020how} reports how, in the 3 months leading up to the election, fake news supporting Trump was shared on Facebook almost 4 times as many as the 8 million fake news supporting Clinton. Collecting more than 170 million tweets exchanged on Twitter in the 5 months prior to the same election, Bovet and Makse showed that the vast majority of news from trustworthy sources came from journalistic sources with verified Twitter accounts, while conspiracy theories, fake news and extremely biased news were mostly posted through unofficial Twitter clients, by unknown users, who then disappeared from Twitter, or automated accounts, {\it also known as} social bots~\cite{Bovet2019influence}. 
Shao et al., in~\cite{shao2018anatomy}, have highlighted the role of Twitter bots too, showing how bots were primarily responsible for the early spread of disinformation, interacting with influential accounts through mentions and replies. 

% Letteratura ha esaminato in dettaglio il dibattito online nei giorni e mesi precedenti alle elezioni di Trump nel 2016, 

% their importance and influence in the age of social media is still not clear. Indeed, massive digital misinformation has been designated as a major technological and geopolitical risk by the 2013 report of the World Economic Forum3. 

% Political misinformation has the potential to change election outcomes.

% “Falsehood flies, and truth comes limping after it, so that when men come to be undeceived, it is too late; the jest is over, and the tale hath had its effect.” -Jonathan Swift, “The Art of Political Lying”

% The potential impact of fake news on President Trump’s victory in 2016 is among the most contested controversies of his presidency. Although the State Department has found proof of Russian election interference, whether or not that translated into a win for Donald Trump is still widely argued against and doubted

% https://faculty.lsu.edu/fakenews/elections/sixteen.php

% concentrated on Facebook and lead to the following facts:
% Of the known fake news stories that appeared in the three months before the election, those favoring Trump were shared a total of 30 million times on Facebook, while those favoring Clinton were shared 8 million times.
% Just over half of average American adults who recall seeing fake news say they believed the stories
% People are much more likely to believe stories that favor their preferred candidate, especially if they are ideologically segregated within social media networks

% Bovet and Makse hanno analizzato [], mentre l'articolo by Shao et al. 
%  automated accounts, in the spread of misinformation12,23,24,25. In particular, Shao et al. found that, during the 2016 US presidential election on Twitter, bots were responsible for the early promotion of misinformation, that they targeted influential users through replies and mentions26 and that the sharing of fact-checking articles nearly disappears in the core of the network, while social bots proliferate13. 

Bots' evolutionary ability, namely the tendency they have acquired over the years to evade detection techniques,  is well known~\cite{Ferrara2016rise,Cresci2017paradigm}. The study in~\cite{luceri2019evolution}, for example, showed that, in the transition between the 2016 presidential elections to the 2018 midterms, the bots involved in the online political debate have evolved to the point where they are much more easily mistaken for humans.
Analyses have also been done on the manipulation of online narratives about the 2020 U.S. elections. Ferrara et al., in~\cite{Ferrara2020characterizing}, found how a relatively small number of automated accounts managed to create traffic spikes on the election debate comparable to human users, the latter counting for several orders of magnitude greater. 

Our work focuses precisely on the online Twitter debate in the week before November 4, 2020 and, like other studies, examines the disinformation flow and infiltration of bots into the debate. Unlike other work, however, ours points the binoculars at two specific aspects of the U.S. presidential elections, namely the {\it winner take all} system and the existence of {\it swing and safe states}. In fact, the recent literature, in comparing differences and similarities in the online political debates among different countries, highlights how the different election systems induce different structural properties of online social networks~\cite{Bright2018,Urman2020,VanVliet2021,Praet2021}. 
%At the best of our knowledge, our contribution is the first one that investigate how the spreading of disinformation reflects the election system.}
%%%%



%\cite{Luceri19red}


%%%%%

%The term `swing' refers to those states in which, even because of the presence of last-minute vote swings, one cannot be sure of a landslide victory for Republicans or Democrats. 
The term `swing' refers to those states in which one cannot be sure of a landslide victory for Republicans or Democrats since there is not a neat historical orientation of the electorate.
%In contrast to swing, a state is called `safe' where traditionally it is always the same party that wins, be it the Democratic or Republican candidate. 
In contrast to swing, a state is called `safe' if its citizens, in recent history, have always elected representatives from the same political party.
In all U.S. states, excluding Maine and Nebraska, the voting methodology is known by the name 
`winner-take-all'. Each state has a  number of presidential electors (dependent, among other things, on the number of residents in the state). 
After a popular election has been held, 
% (every first Tuesday following the first Monday in November of the election year), 
each state converts the popular votes of its citizens into its presidential electors. The `winner-take-all' system implies that whatever the number of votes for the Republican candidate and the Democratic candidate, whoever has the greater number earns the presidential electors of that state.

One of the main criticisms of this system is that it may lead  presidential candidates to focus their campaigns on a few swing states, since they are key states to achieve victory~\cite{Edwards2011why}. In fact, some battleground states have traditionally been the subject of more intense electoral campaigns, let the reader think, e.g., to Florida,  
%and Ohio, 
traditionally a swing state and with a  large population,  thus allocating many presidential electors (29). 
%the former and 18 the latter). 

% CHANGE:
% Opponents of this system argue that it can give rise to differences in the outcome between the popular vote and the Electoral College vote 
% % (such as the aforementioned case in the 2016 election) 
% and that it convinces presidential candidates to focus their campaigns on a few `swing states' (i.e., key states to achieve victory). [9][10][11][12][13]. Traditionally, some battleground states have been the subject of more intense electoral campaigns, think for example of the cases of Florida and Ohio, swing states with large populations and thus allocating many large electorates (29 the former and 18 the latter).

Translating that critique to the Twittersphere, in this paper we ask and answer the following question: is it possible that, in the run-up to the 2020 U.S. presidential election, the Twitter traffic related to the election debate reflects the election system, and, in particular, the division in swing and safe states?

%Is it possible that, in the run-up to the 2020 U.S. presidential election, there were substantial differences in the Twitter traffic related to the election debate in swing states to safe states? 

%Talking about substantial differences,
We refer specifically to disinformation flows:
\begin{itemize}
\item  Is the flow of tweets containing links to dubious or non-trustworthy news  different if it involves swing states or safe states? 
\item Does the presence of automated accounts in the pre-election online political debate differ, considering the traffic talking about swing and safe states?
\end{itemize}

% As we anticipated, much work in the literature focuses on the properties of social debate regarding prominent events such as political elections, particularly regarding the presence of misinformation and automated accounts. The present work differs from the existing because 1) to the best of our knowledge, it examines the flow of disinformation, including from automated accounts, focusing on safe and swing states; 2) [...]




% (EN) These 3 Common Arguments For Preserving the Electoral College Are All Wrong, su Time. URL consultato il 18 dicembre 2019.

%  The Case Against the Electoral College | Harvard Political Review, su harvardpolitics.com. URL consultato il 18 dicembre 2019.


% (Def. from Wikipedia) Swing and Safe states: In American politics, the term swing state (or battleground state) refers to any state that could reasonably be won by either the Democratic or Republican presidential candidate by a swing in votes. These states are usually targeted by both major-party campaigns, especially in competitive elections.[1] Meanwhile, the states that regularly lean to a single party are known as safe states, as it is generally assumed that one candidate has a base of support from which they can draw a sufficient share of the electorate without significant investment or effort by their campaign.

% Intuition: “candidates often campaign only in competitive states”
% Due to the winner-take-all method most states use to determine their presidential electors, candidates often campaign only in competitive states, which is why a select group of states frequently receives a majority of the advertisements and candidate visits. The battlegrounds may change in certain election cycles and may be reflected in overall polling, demographics, and the ideological appeal of the nominees.

%[..]

% Our aim is to check if a significant flow of misinformation take place during the time window (of one week) immediately before the 2020 u.s. election day. 

% The insights of our work are suggested by~\citep{howard2018social}, which showed in 2016 US election the possibility to finding a concentration of polarising content in swing states.\\ 
%\adjustfiltering{To conduct our analysis, we collected Twitter data based on keywords, one of which was always the name of a U.S. state (swing or safe). From the collected data, we extracted \cutforworkshop{(i) the main communities and their political orientation,} (i) the reputability level of the publishers whose news bounced in the tweets in our dataset and (ii) the boticity level of users. }
To conduct our analysis, we collected Twitter data based on keywords, one of which was always the name of a U.S. state (swing or safe). After filtering out useless data from the entire dataset, we extracted (i) the reputability level of the publishers whose news bounced in the tweets and (ii) the boticity level of the users.


% il modello elimina il rumore, ovvero un'informazione non significativa: scartiamo sia i retwittatori seriali, ovvero gli accounts che retwittano qualsiasi cosa, sia i retweets dovuti alla grande popolarita' degli autori del messaggio. 

% Prima di tutto, ci concentriamo  sulla rete dei retweet e sugli utenti Twitter verificati (ovvero quegli accounts la cui proprieta' e' verificata dalla piattaforma stessa). Su Twitter, gli utenti verificati sono generalmente uno stimolo per accendere il dibattito~\cit{}. La nostra processazione parte dall'intuizione che se due utenti verificati mostrano la stessa opinione a proposito di un tema, sono retwittati dagli stessi utenti standard. 




% In particolare, guidati dall'intuizione iniziale, considereremo i dati delle discussioni presenti su Twitter raccolte a partire dal nome di otto stati (quattro swing e quattro safe). 
% To perform a finer-grained characterization of the Twitter traffic we consider the following features: (i) the political orientation of the main emergent communities, (ii) the boticity level of users (i.e., using the external Botometer tool), (iii) the reliability of the online source that publish the disseminated news (i.e, using NewsGuard evaluation), (iv) the state name (using a keyword-based identification) to associate a tweet to a swing or safe state.

% \mari{NO, lo rimetto io com'era...cosi' e' troppppo dettagliato}

\subsection{Contributions} Our main contributions are:
\begin{itemize}
    \item We provide a fine-grained characterization of the Twitter traffic about the 2020 U.S. presidential elections, in the week leading up to election day, adopting a multidisciplinary approach including complex network analysis, 
    %(i.e., entropy-based null-model), 
    artificial intelligence, 
    %(i.e., Botometer tool) 
    and human-based annotation.
    %(i.e., NewsGuard's expert annotations).
    \item To the best of our knowledge, this is the first paper that addresses the problem of understanding whether, in the Twittersphere, the U.S. 2020 pre-election debate was polarized more in tweets about  swing states rather than safe states.%, by spreading more disinformation content associated to the former than to the latter. 
    \item There is evidence of an alignment between the real electoral mechanism -which often favors more intense campaigning in certain locations- and the online electoral debate. 
    \item 2020 election-related traffic focuses, for the vast majority, on tweets about swing states; swing state-related debate sees a higher concentration of links to non-trustworthy news sites. 
    % \man{Furthermore, considering only the traffic generated by classified users,} 
   The majority of disinformation content associated with swing states 
    %\cutforworkshop{and (ii) Republican supporters}
is posted and retweeted by automated accounts. 
\end{itemize}

% \subsection{RQs}

% Considering discussion inside the main emergent (politically oriented discursive) communities and related to swing/
% safe states:

% \begin{itemize}
%     \item [RQ1] Nelle discussioni si formano delle community associabili a correnti politiche ben definite?
%     \item [RQ2] Are there significant differences in terms of misinformation? Polarization?
%     \item [RQ3] Are there significant differences in terms of bot presence?
%     \item [RQ4] Are there correlations between the presence of bots and the spread of low credibility contents supporting misinformation? Polarization?
% \end{itemize}

\subsection{Main Results:} 
\begin{itemize}
    
    %\cutforworkshop{ \item Two main user communities emerge from the data:a homogeneous one (hereafter {\sc Rep}), consisting of Republican supporters, and a mixed one, with journalists and both Republican and Democratic supporters (hereafter {\sc Rep-Dem-Journ}).}
    % \item Dai dati sono emerse \textbf{due principali community} di utenti: una costituita principalmente da sostenitori repubblicani (di qui in avanti chiamata "rep") l'altra di sostenitori misti repubblicani, democratici e giornalisti ("rep\_dem\_journ");(vedi caratterizzazione community in Tab \ref{tab:community_characterization})
    %\cutforworkshop{ \item More than 90\% of links to news from non-trustworthy publishers are concentrated in the {\sc Rep} community. Each such link on average is shared 57 times, a much larger number than the average number of shares in the community {\sc Rep-Dem-Journ} (i.e. 7).}
   
    % \item Nella community dei "repubblicani" si concentra la maggior parte - 91\% - dei link poco affidabili (N) (vedi Figure\ref{fig:url_reliability_distrubution}); ogni link N viene ricondiviso in media 57 volte, numero molto maggiore della media condivisione nella community "rep\_dem\_journ" (vedi Fig \ref{fig:sharing_by_reliability});
    
   
    \item Tweets associated with swing states account for about 88\% of the whole traffic.  % commentato If we consider the population of the swing states in the dataset, the percentage is 66\%. 
    
    % \item The percentage of links to non-trustworthy news sites is higher in tweets associated to swing states - $\sim$23.5\% - than in those associated to safe states - $\sim$18\%. \mari{However, the gap is not such that a claim can be made about a net majority of disinformation flow  in traffic associated with swing rather than safe states.}
    % \item The percentage of trustworthy links  is higher in tweets about safe states - $\sim$51\% ($\sim$30\% in tweets about swings).
    
    \item Tweets associated to safe states have a higher concentration of URLs pointing to news with trustworthy publishers. Tweets associated to swing states  have a higher concentration of URLs pointing to news with no trustworthy publishers.% in all communities.
    
    %\cutforworkshop{ \item The percentage of tweets with URLs pointing to news with no trustworthy publishers is always higher for swing states in all communities.}%than for safe states (both over the whole dataset, {\sc Rep} and {\sc Rep-Dem-Journ}).}
 
    
    % \item mari: IO QUESTO NON LO METTEREI TRA I risultati principali: Le distribuzioni dei bot score associate alle due principali community sono significamente diverse ergo nelle due community intervengono nelle discussioni account sostanzialmente differenti  "in termini di bot score" (Fig \ref{fig:traffic_bot_score_distribution} e Tab \ref{tab:statistical_tests}), 
    
    % \item \textbf{ $[$ NOTA se consideriamo SOLO il traffico generato da account classificati come bot or not $]$ } Nella community dei "repubblicani" (i) i bot risultano piu attivi rispetto agli human (generano il 68\% del traffico) e sono responsabili del 73.84\% del traffico low-reputable, (ii) i flussi low-reputable generati da bot si concentrano maggiormente su discussioni associate a swing states (36.28\% swing vs. 32.57\% safe)... anche se il numero di tweets associati a safe states risulta molto minore.  
    
    %\item $[$RIVEDERE$]$ Si osservano bot score medi solitamente maggiori per gli utenti che condividono link N rispetto a quelli che condividono link T. Questa differenza appare più marcata dall'osservazione degli swing e safe states.
    %\item $[$RIVEDERE$]$ Nella community dei "repubblicani" si osserva una media di condivisione di link N piu alta per tweets associati a swing states. Questa tendenza si osserva nella community "rep" ma non in quella mista "rep\_dem\_journ" (risultati da consulidare).
    
    %\item \man{Considering only the traffic generated by the classified user that publish in "Both " the main communities,} accounts classified as bots are responsible for 64\% of the traffic and tweet and/or retweet about 73\% of the traffic with links to non-reputable news. \man{Focusing on the {\sc Rep} community, bots produce 71.93\% of traffic (35.95\% of this are un-reputable links). In other words, in {\sc Rep}, bots produce 73.84\% of low-reputable traffic; and 69\% of T traffic.}
    
    % \item \man{Considering only the traffic generated by the classified user in {\sc Rep} community, bots are responsable for 73.84\% of low-reputable traffic; and 69\% of T traffic.}
    
    %\item Accounts classified as bots in {\sc Rep} are responsible for $\sim$ 74\% of non-trustworthy traffic.
    
    
    % \item In {\sc Rep}, bot accounts i) generate much more traffic than genuine accounts (68 vs. 32\%) and are responsible for tweeting and retweeting nearly 75\% of posts with links to non-reputable news. 

    % \item \man{Considering only the traffic generated by the classified user that publish in the {\sc Rep} community,} non-reputable tweets generated by bot accounts are associated more with swing states than safe states (~36\% swing {\it vs} ~32\% safe). \man{In the same direction for discussions associated with safe states, a higher concentration of reputable links (T) is observed.}
    
    \item Of the total number of tweets associated with swing states and containing  no trustworthy URLs, 74\% of these are posted or retweeted by accounts classified as bots.
    %Accounts classified as bots in {\sc Rep} generate non-trustworthy tweets that are associated more with swing states than safe states ($\sim$74\% swing {\it vs} $\sim$68\% safe). 
    

\end{itemize}

\subsection{Originality}
 This work is not the first nor will it be the last to deal with the impact that real events have on virtual events, and vice versa. An in-depth study concerning disinformation flows on social networks in relation to major political events will be presented later in this article. Noteworthy is the work by Howard et al. in~\cite{howard2018social}, which examines tweets from authors who left some evidence of their physical location in the period leading up to the 2016 U.S. presidential election. The result of the analysis shows a high concentration of polarized news in swing states with many presidential electors. 
%\adjustfiltering{Aside from the different years (2016 {\it vs 2020}), the substantial difference of our study from~\cite{howard2018social} is the filtering procedure we implement on our dataset, an entropy-based null model for bipartite networks known as the Bipartite Configuration Model BiCM~\cite{Cimini2018a}. Focusing on the network of retweets, we first focus on verified Twitter users. Our processing starts from the intuition that if two verified users show the same opinion about a topic, they are retweeted by the same `standard' users. However, the interaction between verified and unverified users might not always be significant, either because the retweeter is retweeting everything or because the retweeted is a popular character. By applying BiCM, we make sure to focus on accounts whose number of common retweeters is statistically significant, i.e., it cannot be explained by the degree sequence of the nodes.}
Aside from the different years (2016 {it vs 2020}), the substantial difference of our study compared to~\cite{howard2018social} is the filtering procedure we apply on our dataset, which employs statistical methods for the analysis of complex networks (suited for the study of social networks interactions) (see Section \ref{sec:rw} and \ref{sssec:DisCo} for further details).  
%an entropy-based null model for bipartite networks known as the Bipartite Configuration Model BiCM~\cite{Cimini2018a}.


Using this filtering procedure allows us to bring out political discussions from the data so that we can discard all the rest.
The main idea lies in labeling `standard' users starting from labels assigned to groups of `similar' verified accounts i.e., accounts whose owners are certified by the platform itself. One group of `similar' verified users may be affiliated with a political orientation or not (this check is done manually for each group of verified). So in principle, we will discard (as noise) tweets posted by all `standard' users not affiliated with any political group of verified users. Instead, we will focus our analysis only on tweets posted by `standard' and verified users affiliated with political groups. The importance of focusing on political communities comes from the fact that we are analyzing who is  tweeting about swing and safe states, and what they are tweeting about, but we want to make sure that users are interested in the political narrative, and not, say, in sporting events. The complete filtering procedure will be explained in Section \ref{sssec:DisCo}.
%Our processing starts from the intuition that if two verified users show the same opinion about a topic, they are retweeted by the same `standard' users. However, the interaction between verified and unverified users might not always be significant, either because the retweeter is retweeting everything or because the retweeted is a popular character. By applying BiCM, we make sure to focus on accounts whose number of common retweeters is statistically significant, i.e., it cannot be explained by the degree sequence of the nodes.




\section{Related Work}
\label{sec:rw}

% TODO (studi di nostro interesse, accennare brevemente dove si colloca il nostro lavoro)

\paragraph{Disinformation flows in online political debates} 
In the introduction, we highlighted analyses on detecting online disinformation flows in the periods leading up to  the 2016 and 2020 U.S. presidential elections~\cite{Georgacopoulos2020how,Bovet2019influence, shao2018anatomy,Ferrara2020characterizing}.
%
% of some analyses conducted on the 2016 and 2020 U.S. presidential elections: specifically, how disinformation flows were detected on social media in the periods leading up to the events and that such flows, in many cases, were introduced and sustained by social bots~\cite{Georgacopoulos2020how,Bovet2019influence, shao2018anatomy,Ferrara2020characterizing}. 
%
Regarding the 2016 elections, the work in~\cite{budak2019happened} stands out from others in analyzing the disinformation flow around candidate Clinton (many works are focused on candidate Trump instead) and highlights how the prevalence of fake news on Twitter increased as the election approached and that the content of such news targeted Hillary Clinton contextually to periods when her online popularity was increasing. 
% One paper that touches on the period in between the two events is by 
Luceri et al., in~\cite{Luceri19red}, focus on the 2018 U.S.  midterms and examine the behavior of social bots on Twitter in the period leading up to the event. Social bots are categorized according to their political leanings: conservative bots tend to converse primarily with their human counterparts, while liberal bots are more `democratic', addressing a broader audience. 


% \man{The work~\cite{howard2018social} focuses on the 2016 US election and gives a first intuition about the possibility of finding, in swing states, higher levels of misinformation. This study, however, unlike ours, does not obtain the uses' political orientation from social media interactions and does not consider the presence of social bots.}

Online disinformation does not only touch presidential elections, and it does not only touch the United States. Pierri et al., in~\cite{pierri2020investigating}, analyze the online debate on Twitter in the five months leading up to the 2019 European Parliament elections.  In particular, the work looked at well-known Italian disinformation outlets, responsible for the majority of the disinformation circulating on Twitter, with an audience strongly and explicitly related to the Italian far-right political environment.
% Disinformation, mostly concerning controversial topics such as immigration and nationalism, was found to be confined to a limited community, strongly and explicitly related to the Italian far-right political environment.

The work in~\cite{caldarelli2020role}, although not focused on an election event, examines the debate on immigration in Italy, and brings out online communities with specific political identities, reflecting the composition of the Italian parliament at the time of data collection. The work discovers
% analyzes the presence of automated accounts and finds that not only are the vast majority of bots concentrated in the community affiliated with conservative parties, but more importantly, 
%there are 
teams of bots following the most influential accounts in the conservative community and amplifying their messages via retweeting. 

 Despite being a mostly scientific subject, the COVID-19 discussion shows a clear division in what results to be different political groups: Caldarelli et al., in~\cite{Caldarelli2021}, consider the Twitter debate around COVID during the months of the Italian lockdown (March-April 2020) and analyze the news linked in tweets: the vast majority of news from notoriously biased publishers is retweeted online by communities akin to center-right and right-wing political groups. 
%  The network structure of  seems to enhance the phenomenon of infodemic 
 Recent work by Mattei et al.~\cite{mattei2022bowtie} reveals that the retweet networks -where users interact about politics and society- show statistically significant bow-tie structures~\cite{broder2000graph}. When the network is affected by disinformation, the flux to the OUT sector, i.e. the most crowded one in the bow-tie decomposition,  is particularly consistent and display a high frequency of non reputable pieces of news.
 
 
 
%  The recent work by Mattei et al.~\cite{mattei2022bowtie} analyzes 8 thematic Twitter datasets, some in which political issues are discussed (such as, for example, the Dutch elections in 2021) and others in which non-political topics are debated (such as, for example, the 2020 European soccer championships). The work highlights how the retweet network of the political-themed datasets has a bow-tie~\cite{broder2000graph} structure, in which the vast majority of accounts form a so called Weakly Connected Component consisting of a group that produces content (IN group), a group that retweets that content and created new one (SCC group), and a group exposed to posts coming out of SCC (OUT group). Analyzing SCC-produced content, a high concentration of posts of questionable quality was revealed, and, consequently, a high exposure of the OUT groups to an infodemic phenomenon~\cite{cinelli2020info}\footnote{`An infodemic is too much information including false or misleading information in digital and physical environments during a disease outbreak. It causes confusion and risk-taking behaviours that can harm health' Online: \url{https://www.who.int/health-topics/infodemic#tab=tab_1}}.
 
 % Work prior to ours~\cite{howard2018social} deals with the analysis of polarised content on Twitter in the 2016 U.S. pre-election period. The work is based on tweets from accounts that left some evidence of their physical location in their profile. The result of the survey shows a high concentration of polarised news in swing states with many presidential electors. We can consider this work a valued predecessor to ours, which, however, unlike~\cite{howard2018social}, derives discursive communities directly from data and also considers the role of social bots.


 As introduced at the beginning of the article, Howard et al, in \cite{howard2018social} focused on analyzing tweets about swing and safe states posted during  the 2016 U.S. pre-election period. Results show a high concentration of polarized news in swing states with many presidential electors. This work represents a valuable predecessor to our current one. However, we would like to point out that the election we focus on is different, that our work also focuses on social bots, and that, most importantly, we filter out noise from the complete dataset by applying a procedure based on complex network analysis.% \cite{Sindermann2020susceptibility} This review discusses recent findings on susceptibility to falling for fake news in political contexts. In relation to political attitudes and analytical thinking, we find that individuals tend to overrate the accuracy of true and fake political news that are consistent with their own political attitudes. This tendency, however, does not seem to be explained by motivated reasoning. This is supported by findings showing that analytical thinking and deliberation are negatively related to susceptibility to falling for fake news, regardless of whether they are consistent or inconsistent with one’s political attitudes.
\paragraph{Social Bots} 
Research in social bot detection   has been going on for about 12 years. The first work appeared around 2010~\cite{YardiRSB10,mustarafi10}. In the first years of bots hunting ($\sim$2010-2014), researchers mainly focused on supervised machine learning and on the analysis of the single account: `classifiers were separately applied to each account of the group', to which they assigned a bot or not label~\cite{cresci2020decade}.   
Approximately from 2014 to 2019, instead, a number of research teams, independently,
%started to formalize
proposed new approaches
for detecting coordinated behavior
%that characterizes 
of automated malicious accounts, see, e.g.,~\cite{IntSys2015, yu2015}. Thus, researchers no longer took the individual account and classified it as bot or not. Instead, they considered a group of accounts, and their common characteristics, like  anomalies in synchronicity and normality~\cite{Giatsoglou2015,jiang2016}, detection of loosely synchronized actions~\cite{Cao:2014}, or distance between distributions of reputation scores~\cite{viswanath2015}. %those that may show that they have been programmed for the same purpose (and therefore, for example, they behave online in the same way).

We have seen a convergence of the two techniques (i.e., finding a general-purpose bot detection {\it vs} developing specialized ones for the characteristics of certain bots) in the last 3/4 years. 
A recent work that classifies the single accounts is 
 in~\cite{DBLP:conf/cikm/Sayyadiharikandeh20},  where specialized supervised models are built for various classes of bots. The models are aggregated into an ensemble and their outputs are combined through a voting scheme. 
Yang et al. ~\cite{DBLP:conf/aaai/YangVHM20} handle the full stream of public tweets on Twitter in real time. Key recipe of the analysis is to use account features that have a very low cost in terms of the data needed to compute them. In particular, the authors use features related only to the account profile. The same category of features has been recently tested in~\cite{DENICOLA2021102685} to spot a different kind of bots.

Recent literature has also seen proposals based on coordination as a team.
%}
% The methods described so far are based on traditional classifiers that assess the individual account and possibly tag it as bot. 
% The alternative to `classical' features for bot detection has been studied for a few years now, and is based on features of groups of accounts, rather than of individuals.
% There is thus a strand of research that uses specific techniques targeted to recognising teams of bots. 
% For the sake of completeness, we just mention some of them. 
Hui et al.~\cite{DBLP:conf/icwsm/HuiYTM20} leverage hashtags, links,  phrases, and trending media to let coordinated campaigns emerge from the crowd.
%  Other techniques are based, for example, on anomalies in synchronicity and normality~\cite{Giatsoglou2015,jiang2016}, detection of loosely synchronized actions~\cite{Cao:2014}, distance between distributions of reputation scores~\cite{viswanath2015},  
 Other techniques are based, for example, on similarity between sequences of actions~\cite{cresci2018social}, and interactions between accounts~\cite{sharma2020identifying}. 

%{\bf mari: cita qualcosa di quanto commentato sotto:}
%     []Thai Le, Long Tran-Thanh, Dongwon Lee:
% Socialbots on Fire: Modeling Adversarial Behaviors of Socialbots via Multi-Agent Hierarchical Reinforcement Learning. 545-554]

% [Ziyi Zhang, Shuofei Zhu, Jaron Mink, Aiping Xiong, Linhai Song, Gang Wang:
% Beyond Bot Detection: Combating Fraudulent Online Survey Takers. 699-709
% ]

% []Hassan Iqbal, Usman Mahmood Khan, Hassan Ali Khan, Muhammad Shahzad:
% Left or Right: A Peek into the Political Biases in Email Spam Filtering Algorithms During US Election 2020. 2491-2500]

% Weizhi Xu, Junfei Wu, Qiang Liu, Shu Wu, Liang Wang:
% Evidence-aware Fake News Detection with Graph Neural Networks. 2501-2510


% Orestis Papakyriakopoulos, Ellen Goodmann:
% The Impact of Twitter Labels on Misinformation Spread and User Engagement: Lessons from Trump's Election Tweets

% Vibhor Agarwal, Sagar Joglekar, Anthony P. Young, Nishanth Sastry:
% GraphNLI: A Graph-based Natural Language Inference Model for Polarity Prediction in Online Debates. 2729-2737

% Xinyi Zhou, Kai Shu, Vir V. Phoha, Huan Liu, Reza Zafarani:
% "This is Fake! Shared it by Mistake": Assessing the Intent of Fake News Spreaders. 3685-3694

The main purpose of this paper is not to define a new technique for bot detection, nor is it to detect a particular type of social bot. Therefore, to classify accounts as bots or not, we prefer to adopt Botometer, one of the most well-known tools in the literature for bot unveiling. 
Botometer~\cite{Varol2017,FerraraArming2019} 
%(in its earliest version known as `BotOrNot', publicly available as web interface and API since May, 2014) 
is based on a supervised machine learning approach employing Random Forest classifiers~\cite{Breiman2001}. Here, we will rely on Botometer v4, the new version of the bot detector, which has been recently shown to perform well for
detecting both single-acting bots and coordinated campaigns~\cite{DBLP:conf/cikm/Sayyadiharikandeh20}. 

\paragraph{Statistical methods for the analysis of online social networks}
The recent literature regarding online social networks has progressively implemented more techniques based on network science, with the aim of distinguishing  non-trivial signals of social interactions from random noise. In particular, the implementation of entropy-based null-models (see the review by Cimini et al~\cite{Cimini2018a}) has opened up a variety of applications, providing a general and unbiased benchmark for the analysis of complex networks.
%More in details, such methods were implemented for the identification of discursive communities on Twitter, i.e. groups of accounts based on their retweeting activities~\cite{Becatti2019d,caldarelli2020role, Radicioni2021a, Radicioni2021b,mattei2022bowtie}, for the detection of non-trivial fluxes of disinformation on Twitter ~\cite{Caldarelli2021,DeClerck2022a,DeClerck2022b}, for highlighting coordinated behaviours among Twitter automated accounts~\cite{caldarelli2020role, Bruno2022}, for the identification of different information diets on Facebook~\cite{Guarino2021} or for the detection of the effective subjects of debate~\cite{Radicioni2021a, Radicioni2021b,mattei2022bowtie}. 
The main idea is to create a maximally random benchmark (i.e., maximising the Shannon entropy associated with the system under analysis) that preserves some (topological) property of the original system. In this sense, with the aim of detecting non-trivial behaviours, maximum-entropy null-models represent a tool that, at the same time, is general and tailored on the observed network. 

% \subsection{Entropy-based null-models for complex network analysis}
% Here, we provide the sketch of the definition of the entropy-based null-models and  their implementation for detecting discursive communities on the retweet network. For more details on the entropy-based techniques for complex networks, we forward the interested reader to the review in~\cite{Cimini2018a} and to the references therein.

%\subsubsection*{Entropy-based null-models}
Here, we provide the sketch of the definition of the entropy-based null models for complex network analysis and all references for further information.
%the main flows of traffic i.e., those produced by the main communities of users on the retweet network. 

%\textbf{utenti verificati/non verificati che interagiscono tra loro in modo non bnale (l'interazione non banale porta alla clusterizzazione)}

%For more details on the entropy-based techniques for complex networks, we forward the interested reader to the review in~\cite{Cimini2018a} and to the references therein.


The aim of the entropy-based null-models is to define a benchmark for the analysis of a real network $G^*$ that 
is maximally random, but for a set of topological constraints $\vec{C}$ observed on $G^*$.
Thus, we define an \emph{ensemble} of graphs $\mathcal{G}$, i.e., the set of all possible graph configurations, from the empty graph to the fully connected one, all having the same number of nodes as in the real network. Then, we can assign a probability to every representative of the ensemble by maximising the relative Shannon entropy, i.e.,
\begin{equation*}
    S=-\sum_{G\in\mathcal{G}}P(G)\ln P(G),
\end{equation*}
under the constraint that the average over the ensemble of the vector $\vec{C}$ is exactly the value observed in the real network $G^*$, i.e., $\langle \vec{C}\rangle_\mathcal{G}=\vec{C}(G^*)$.
The result of this procedure returns in an Exponential Random Graph, i.e. $P(G)\sim e^{-\vec{C}(G)\cdot\vec{\theta}}$, where $\vec{\theta}$ are the Lagrangian multipliers associated to the constrained maximisation~\cite{Jaynes1957,park2004statistical}. The maximisation of the likelihood, i.e., the probability of observing the real system, is then implemented to find the numerical values of $\vec{\theta}$~\cite{Garlaschelli2008,Squartini2011a}.

Recently, a fast and efficient Python module able to solve many of the entropy-based null-models present in the literature was released and is available at \href{https://pypi.org/project/NEMtropy/}{\color{blue}\underline{Pypi}}.  %\newhref{https://pypi.org/project/NEMtropy/}{Pypi}~\cite{Vallarano2021}.

The importance of using a properly defined unbiased benchmark for the analysis of the spread of online disinformation was stressed in a recent work by De Clerck et al.~\cite{DeClerck2022b}: the authors  show how different entropy-based null-models can highlight different features of the various disinformation campaigns. In this paper, we will consider the entropy-based null-model known as Bipartite Configuration Model
(BiCM~\cite{Cimini2018a,Saracco2015}) as a benchmark to maintain only verified Twitter accounts that have statistically significant interactions with unverified ones.
%,  thus focusing on the actual information exchanged in the network and getting rid of random noise. 
In Section~\ref{sssec:DisCo} we describe the use of this model as a component of our filtering procedure.
%In , we describe the procedure how such model to our purposes: filter noise messages to the complete dataset.
%one of their application to maintain in our dataset only verified users who have non-trivial interactions with unverified users.
 
% \hlworkshop{As further elaborated below, by adopting BiCM as a benchmark, it is possible to  select, from our dataset,} only those accounts that have statistically significant interactions, thus focusing on the actual information exchanged in the network and getting rid of random noise. 



%More in details, in Ref.~\cite{caldarelli2020role} the null-models were used in order to highlight the non-random flux of content in the retweet network: it was therefore possible to spot the coordinated activity of a group of automated accounts (a \emph{bot squad})  significantly enhancing the visibility of many accounts, testifying the presence of a general strategy in the usage of automated accounts. Instead, in Ref.~\cite{Caldarelli2021}, the entropy-based filter was implemented in order to measure the effective impact of pieces of news originated from known purveyors of non-reputable information. In the Italian debate during the first wave of the COVID-19 pandemic, the right-wing users (as detected using the method of Ref.~\cite{Becatti2019d}) were shown to be the most active and crowded community: since the impact of disinformation, i.e. the percentage of messages containing URLs pointing to non-reputable websites, in this community was more than \textcolor{red}{XX} times the one of the other communities, the final effect was a particular exposure to false information. Finally, the network structure of the discursive communities seems to enhance the phenomenon of  infodemic mentioned above~\cite{mattei2022bowtie}: using entropy-based methods it was shown that, in the retweet network, discursive communities show statistically significant bow-tie structures~\cite{broder2000graph}. In the case of discursive communities affected by disinformation, then, the flux to the OUT sector, i.e. the most crowded one in the bow-tie decomposition of discursive communities, from the Strongly Connected Component, is particularly consistent and display a high frequency of non reputable pieces of news.}


    
%     \paragraph{Altro}
% \begin{itemize}
%     %\item tema election: bovet\&Makse (2016 us election), ...
%     \item swing\&safe $+$ disinformazione mai trattati insieme?
%     \item analisi disinformazione : EPJ nostro (covid, questo lavoro in in pi\`u ha dataset diverso e approccio fine-grained), discoursive community e bot ( bot squad ( -> discoursive comm. inclini disinformazione), ...)
%     \item concetto che comm di dx sono più inclini a diffondere disinfo:  noi, pacheco, \@Mari altri?
% \end{itemize}








% Botometer v3 imposes additional rate limits, while the current version v4
% % ~\footnote{We did not use v4 in the experiments of this manuscript, because it was released at the time the analyses were conducted.},
% provides 
%  both a free version and a premium version\footnote{\url{https://cnets.indiana.edu/blog/2020/09/01/botometer-v4/}}.  The premium version (50 dollars/month) allows a rate limit of 17,280 requests per day (each request processes 1 user only).  
% %  so this allows to check more than 1,700,000 users per day). 
% In addition, v4 premium offers the lite version BotometerLite, which does not interface with Twitter, but simply takes the tweet, retrieves the author, and does the necessary follow-up analysis.

% In this study we use Botometer Lite v.4 (Yang, et al., 2020), which [...]. In our analysis, we will use a conservative approach to classify bots as accounts that sit at the top end of the bot score distribution, rather than carrying out a binary classification of accounts into bots and humans. This addresses the problem of determining the nature of borderline cases for which detection can be inaccurate, and conversely allows to focus on accounts that exhibit clear bot traits.

\section{Results}

\subsection{Dataset}\label{sec:Dataset}
%The dataset can be downloaded at \url{https://doi.org/10.7910/DVN/ANBPTC}, hosted at \url{https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/CUWN54}.


Using the Streaming Twitter API, we collected around 5.3M tweets in the week immediately preceding the elections (27 October-3 November 2020). To guide the data collection, we chose keywords 
%(see Appendix, Table~\ref{tab:keywords})
combining the name of four swing and four safe states (see Table~\ref{tab:dataset_by_states}) with the candidates (i.e., Trump and Biden).

\begin{table}[ht!]
\caption{Keywords which drove the data collection phase  
\label{tab:keywords}}

\begin{tabular}{l}
Keywords\\
\hline
\hline
arizona biden\\
arizona trump\\
florida biden\\
florida trump\\
michigan biden\\
michigan trump\\
pennsylvania biden\\
pennsylvania trump\\
new jersey biden\\
new jersey trump\\
indiana biden\\
indiana trump\\
washington biden\\
washington trump\\
louisiana biden\\
louisiana trump\\
\hline
\end{tabular}
\end{table}

%\mari{The choice of the eight states was made taking into account polls and opinions of pundits and experts in the field in the months before the 2020 election\footnote{\url{https://www.maynoothuniversity.ie/research/spotlight-research/10-swing-states-will-decide-us-presidential-election}}. As for the states that were declared safe by these studies, we considered two traditionally associated with Democrats (Washington and New Jersey) and two with Republicans (Indiana and Louisiana). For the states that those polls gave as swing, we considered as a selective factor the number of inhabitants}. 


States have been chosen based on measures and indications provided in reports by experienced political analysts in the months leading up to the 2020 elections\footnote{\url{https://www.cookpolitical.com/sites/default/files/2020-03/EC\%20030920.4.pdf}}. We opted for a balanced list of states, i.e., four safe and four swing states.
As safe states, we selected two pairs, balanced in terms of political orientation and presidential electors. From the solid Democrats, we took Washington and New Jersey and from the solid Republicans, Indiana and Louisiana. This results in 26 electoral votes for the democratic candidate and 19 votes for the republican one. For the selection of swing states, we took the three most important states from the point of view of presidential electors: Florida (29 votes), Pennsylvania (20 votes) and Michigan (16 votes); we further added Arizona (11 votes) because it aroused particular interest in the election debates\footnote{\url{https://fivethirtyeight.com/features/how-arizona-became-a-swing-state/}}$^,$\footnote{\url{https://www.washingtonpost.com/politics/2022/09/16/senate-control-midterm-elections-2022/}}.


%The complete list of pairs of keywords sought for data collection is in the Appendix,  Table~\ref{tab:keywords}. 

The data were further processed in order to (i)
%\cutforworkshop{extract the discursive communities that naturally emerge from the discussions,}
maintain only accounts that, in the retweet network, have successfully passed the filtering procedure (filtering out useless data from the entire set)
,  (ii) enable link domain classification through NewsGuard, and (iii)  find a mapping between each tweet and the kind of state (i.e., swing or safe). % and (iv)  filter out useless data from the entire set.  

As anticipated, the dataset filtering procedure is described in Section~\ref{sssec:DisCo}. From here on, we shall call the `validated dataset' the product of the filtering procedure (to distinguish it from the initial dataset).
%The results are in Section~\ref{sec:politicalcomm}. 
For both the verified and unverified accounts that pass the filtering procedure, we also collect the bot scores via BotometerLite.

To enable the classification of URLs, we rely on NewsGuard\footnote{\url{https://www.newsguardtech.com/}}, which provides a set of \{\emph{domain\_name}, \emph{tag}\} pairs (tags are in Table~\ref{table:domains-tags}). It is therefore necessary to translate all the short-form URLs contained in the text of the tweets, so that we can have the domain names in clear. 
We clarify that a domain, for us, corresponds to the so-called `second-level domain' name\footnote{\url{https://en.wikipedia.org/wiki/Domain_name}}, i.e., the name directly to the left of .com, .net, and any other top-level domains. For instance,  \url{nytimes.com} and \url{latimes.com} are considered as domains in the present manuscript.
    
We employ a keyword-based approach to find the association between each tweet and the state type (i.e., swing or safe). In practice, from the text of each tweet -or retweet-, we first check for the presence of at least one state name among the chosen ones (Arizona, Florida, etc.) and then we discard all the tweets in which more than one state appear. Each tweet in the resulting dataset, thus, contains only one state name, which can be either  swing or safe. In addition, we consider English tweets only. The resulting dataset consists of $\sim$3.3M tweets and $\sim$398k URLs (see Table~\ref{tab:dataset_by_states}).


\begin{table}
\caption{Twitter's statistics by state. The asterisk `$\ast$' indicates swing states.}
\begin{tabular}{lcc}
\toprule
State &  No. Tweets &  No. URL \\
\midrule


Arizona$\ast$ &      224046 &    34637 \\
Florida$\ast$  &      744006 &    85373 \\
Michigan$\ast$ &      734600 &    87529 \\
Pennsylvania$\ast$ &     1209083 &   145067 \\


New Jersey &       38007 &     8114 \\
Indiana &       17185 &      988 \\
Washington &      342104 &    36254 \\
Louisiana &        6886 &      633 \\
\bottomrule
Total & 3315917 & 398595 \\
\bottomrule
\end{tabular}
\label{tab:dataset_by_states}
\end{table}

%sezione portata qua da Appendice
\subsection{Bipartite Configuration Model, Validated Projection and Community Detection}\label{sssec:DisCo}

%We apply the BiCM validation procedure~\cite{Cimini2018a,Saracco2015} to verified Twitter users. 

Here, we describe how we filter accounts in our dataset using the validation procedure known in the literature as Bipartite Configuration Model BiCM~\cite{Cimini2018a,Saracco2015}.
As anticipated, our aim is to bring out political communities, leveraging the knowledge of the  political affiliation of verified users.

The first observation is that most of the online debate is led by verified users, i.e., accounts whose owners are certified by the platform itself~\cite{Becatti2019d,Caldarelli2021,caldarelli2020role}. It is possible, therefore, to leverage this information to obtain proper communities of `similar' verified users: the intuition is that verified users with similar opinions in an online debate should have the same audience of `standard' users. 

Therefore we represent the retweet interactions between verified and unverified users as a bipartite network, i.e., networks in which nodes are divided in two sets, $\top$ and $\bot$ -called \emph{layers}- and connections are allowed only between layers; verified and unverified users are then represented by the two layers.

% As anticipated, the conceptual procedure of the entropy-based null-models can be applied for the practical detection of communities of users interacting among themselves via retweets, or \emph{discursive communities}~\cite{Becatti2019d,caldarelli2020role,Radicioni2021a}. \textbf{In particular we can leaverage on the concept of 'similarity' between verified users to extract community (that can be characterized from verified) that can be used to label others connected unverified users (la cui natura o similarita con altri utenti sarebbe sconosciuta). The basic idea is then to focus our analysis on the traffic flows produced by the main user communities \todo{spiegare communities basate su similarita'} participating in the discussion. Here, we describe our procedure for extracting these message flows.

% \man{The first observation is that most of the online debate is led by verified users,  i.e., accounts whose owners are certified by the platform itself. It is possible, therefore, to leverage this information to obtain proper discursive communities~\cite{Becatti2019d}: the intuition is that verified users with similar opinions in an online debate should have the same audience of `standard' users. Therefore we represent the retweet interactions between verified and unverified users as a bipartite network, i.e., networks in which nodes are divided in two sets, $\top$ and $\bot$ -called \emph{layers}- and connections are allowed only between layers; verified and unverified users are then represented by the two layers.}

We then project the bipartite network on the layer of verified users. Nevertheless, the projection only does not tell us so much: In fact, the common retweeters of two verified users could be many due to popularity of the latter or because the retweeters are retweeting many verified users.  We, therefore, need a benchmark that is maximally random and able to discount the effect of these two ingredients, which, in terms of the bipartite network defined above, are translated into the degree sequence of both layers. The entropy-based null-model for bipartite network discounting the information of the degree sequence is known as \emph{Bipartite Configuration Model} (BiCM,~\cite{Saracco2015}).

Using the BiCM as a benchmark, it is possible to validate the projection of the bipartite network on one of its layers: the co-occurrences observed in the real system are compared with the related BiCM distributions and, if they are statistically significant, they are validated~\cite{Saracco2017}. Therefore, the result of the validation procedure is a monopartite undirected unweighted network of verified users, in which two nodes are connected if the number of common retweeters is statistically significant, i.e., {\it it cannot be explained simply by the bipartite degree sequence.}

We subsequently run the Louvain community detection algorithm~\cite{Blondel2008} on the validated network of verified to obtain the main communities. Each of these communities was manually labeled based on the characteristics of the  verified users inside.

%We subsequently run the Louvain community detection algorithm~\cite{Blondel2008} on the validated network of verified users to obtain the main communities. 
%\hlworkshop{Of all the communities of verified accounts that emerge, two have strictly political connotations, one Republican, the other Democratic.} 
%\hl{Two main tipology of communities emerge from the analysis. The biggest one is mostly composed by Republican supporters. The second most populated community is a mixed one, including Republicans, Democrats and some journals and journalists with various political orientations}.

%We subsequently run the Louvain community detection algorithm~\cite{Blondel2008} on the validated network: the so-obtained labels are then propagated on the retweet network using the Raghavanan et al. algorithm~\cite{Raghavan2007b}, in order to provide all users a discursive community label. Several works, like~\cite{Becatti2019d,caldarelli2020role,Radicioni2021a,DeClerck2022a,DeClerck2022b} show that the procedure above is particularly effective in capturing the structure of Twitter online debate.

Then, to include also unverified users, the so-obtained labels are propagated on the retweet network using the Raghavanan et al. algorithm~\cite{Raghavan2007b}, in order to provide all users a %discursive 
community label. Several works, like~\cite{Becatti2019d,caldarelli2020role,Radicioni2021a,DeClerck2022a,DeClerck2022b} show that the procedure above is particularly effective in capturing the structure of Twitter online debate.

After the label propagation, the biggest community is mostly composed by Republican supporters. The second most populated community is a mixed one, including Republicans, Democrats and some journals and journalists with various political orientations. 

Figure~\ref{fig:retweet_network} shows the retweet network in terms of these two main communities. 

 % \hlworkshop{As a corollary result, which however goes beyond the scope of this paper, we can leverage the presence of verified accounts to analyse the nature of the diverse communities. Two main tipology of communities emerge from the analysis. The biggest one is mostly composed by Republican supporters. The second most populated community is a mixed one, including Republicans, Democrats and some journals and journalists with various political orientations}. Figure~\ref{fig:retweet_network} shows the validated retweet network in terms of these two main communities. 


% To characterize the community structure of the giant component, we manually analysed \emph{a posteriori} the various communities, leveraging the presence of verified accounts, as described in Section~\ref{sssec:DisCo}. The most crowded community of the giant component is mostly composed by Republican supporters and it includes $2.7\times10^{5}$ users; in the following, this community  is going to be called {\sc Rep}. The second most populated community ($\sim2.1\times10^{5}$ accounts) is a mixed one, including Republicans, Democrats and some journals and journalists with various political orientations and, therefore, it will be called {\sc Rep-Dem-Journ}.


%\subsection{RQ1 (presence of political community)}
% \subsection{Detection of political discursive communities}
% \label{sec:politicalcomm}



% \begin{table*}[ht!]
% \caption{Characteristics of the main discursive communities. 2 main communities emerge, {\sc Rep} and {\sc Rep-Dem-Journ}. With {\sc Others} we characterize all the accounts that do not belong to the giant component: their contribution is going to be disregarded in the following, since they do not contribute  to the entire debate.\label{tab:community_characterization}}
% \begin{tabular}{lccccccc}
% \toprule
%           Community &  No. Users &  No. Tweets &  Tweets Safe &  Tweets Swing &  No. URL &  Left &  Right \\
% \midrule
% {\sc Rep} &     269019 &     2083158 &           12.35 &            87.65 &   241488 &     0.59 &     \textbf{49.74} \\
% {\sc Rep-Dem-Journ} &     213679 &      919949 &           10.39 &            89.61 &    92412 &    \textbf{16.18} &      1.86 \\

% {\sc Journ-1} &        197 &        1174 &            4.86 &            95.14 &      485 &     3.30 &      0.82 \\
% {\sc Journ-2} &         53 &         404 &           10.64 &            89.36 &       74 &    22.97 &      2.70 \\
% {\sc Others} &     218880 &      311232 &           16.44 &            83.56 &    64136 &     6.62 &     14.60 \\
% \bottomrule
% Dataset &     701828 &     3315917 &           12.19 &            87.81 &   398595 &     5.18 &     32.92 \\
% \bottomrule
% \end{tabular}
% \end{table*}

% We ran the procedure described in Section~\ref{sssec:DisCo} to detect discursive communities, i.e., groups of Twitter accounts retweeting among themselves; the results are summarised in Table~\ref{tab:community_characterization}. 

% The giant component of the retweet network includes more than $4.8\times10^{5}$, while nearly $2.2\times10^{5}$ users belong to smaller clusters: the latter are not going to be analysed in the following since they are not relevant for the entire debate. To characterize the community structure of the giant component, we manually analysed \emph{a posteriori} the various communities, leveraging the presence of verified accounts, as described in Section~\ref{sssec:DisCo}. The most crowded community of the giant component is mostly composed by Republican supporters and it includes $2.7\times10^{5}$ users; in the following, this community  is going to be called {\sc Rep}. The second most populated community ($\sim2.1\times10^{5}$ accounts) is a mixed one, including Republicans, Democrats and some journals and journalists with various political orientations and, therefore, it will be called {\sc Rep-Dem-Journ}. Accounts in {\sc Rep} and {\sc Rep-Dem-Journ} communities are responsible of more than 90\% of the tweets of our dataset (Figure~\ref{fig:retweet_network} shows the resulting retweet network). Other communities are present in the giant component, but, since their dimension is practically negligible with respect to the ones just described, they are not going to be considered in the following.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{IMG/retweet_network.png}
  \caption{Retweet Network after label propagation (547k nodes, 1.8M edges). The two main communities that emerge are the red one, characterised by Republican supporters and the blue one, a mix between Republicans, Democrats, and journalists of various affiliations.
  %{\sc Rep} (red) and {\sc Rep-Dem-Journ} (blue). 
  \label{fig:retweet_network}}
  \Description{}
\end{figure}

% Beyond our manual annotation, the orientation of the news domains appearing in the tweets shared by the various communities confirm our finding. The columns Left and Right in Table~\ref{tab:community_characterization} indicate the percentage of sources identified by NewsGuard as, respectively, left-wing and right-wing oriented. In {\sc Rep}, nearly 50\% of the URLs shared come from right-oriented sources. Due to the mixed composition of the {\sc Rep-Dem-Journ} community, the frequency of left-oriented sources is much lower (nearly 16.2\%).





%sezione commentata per la versione da workshop
% \subsection{Reputation of news domains in communities }
% \label{sec:reputationComm}
% As seen in Section~\ref{sec:politicalcomm}, 
% two main discursive communities emerge from the online debate, i.e., {\sc Rep} and {\sc Rep-Dem-Journ}. To understand whether there are differences within these two communities in terms of number and distribution of links to non-trustworthy news sites, we classify the news publishers inheriting NewsGuard tags for those sites (reported in the Appendix, see Table~\ref{table:domains-tags}).

% The {\sc Rep-Dem-Journ} community is, in terms of traffic, less numerous than {\sc Rep} (less than half a traffic in terms of tweets and much less than half in terms of URLs, see Table~\ref{tab:community_characterization}).







% Figure~\ref{fig:url_reliability_distribution}  shows that, with respect to the whole dataset, the 93.9\% of non-trustworthy links (N) is shared within the two main political communities. In particular, about 91\% of the total is shared within the {\sc Rep} community. Furthermore, the news sources tagged as N by NewsGuard are mostly right-oriented (i.e., Slightly Left $2$, Far Left $6$, Slightly Right $4831$, Far Right $76161$). 
% Regarding the trustworthy links (T), the 79\% is shared within the two main political communities. In particular, 38\% of the total trustworthy links (T) is shared in the {\sc Rep} community, but the majority, 41\%, is in the {\sc Rep-Dem-Journ} community. The news sources tagged as T by NewsGuard are mostly left-oriented (i.e., Far Right $44$, Slightly Right	$1388$, Far Left $5545$, Slightly Left $7799$).  

% \begin{figure}[h]
% \centering
% \includegraphics[width=\linewidth]{IMG/sharing_by_reliability.png}
% \caption{Distribution of the number of link sharing in {\sc Rep} (left) and {\sc Rep-Dem-Journ} (right) for "T", "N" and all Tags (see Table\ref{table:domains-tags}). Values are normalized applying a log function. The green triangle is the mean; the red line is the median; outliers are not reported.\label{fig:sharing_by_reliability}}
% \end{figure}

% Figure~\ref{fig:sharing_by_reliability} reports the virality of the links, that is, how often the links in our dataset were shared. 
% We can see that,  in {\sc Rep}. links of types N are shared many more times than other types of links. Specifically, in {\sc Rep}, a N link is shared, on average, 57 times, while in {\sc Rep-Dem-Journ} 7 times.

\subsection{Reputation of news domains}
All the domains in our validated Twitter dataset have been tagged according to their degree of credibility and transparency,  as indicated by the browser extension and mobile app NewsGuard.
%
% Born from the joint effort of journalists and software developers,  NewsGuard evaluates news sites according to  criteria concerning credibility and transparency. 
For evaluating the credibility level, the Newsguard metrics consider, e.g., whether the news source regularly publishes false news, does not distinguish between facts and opinions, does not correct a wrongly reported news. For transparency, instead, the toolkit takes into account, e.g., whether owners, founders or authors of the news source are publicly known, and whether advertisements are easily recognizable\footnote{Details on the procedure for the  evaluation  are available at: \url{https://www.newsguardtech.com/ratings/rating-process-criteria/}.}

\begin{table}[ht!]
\caption{Tags for domain reputation labeling. Tags are inherited from NewsGuard, the UNC tag indicates that NewsGuard has not yet tagged that domain. %(UNC = Unclassified)  
\label{table:domains-tags}}
\centering
\begin{tabular}{c|l}
label & \text{description}\\
\hline
\hline
T & Trustworthy news domain\\
%$\sim\text{R}$ & Quasi Reputable news source\\
N & Non-trustworthy news domain\\
P & Platform (e.g., reddit.com, twitter.com)\\
S & Satire\\
UNC & unclassified\\
\hline
\end{tabular}

\smallskip

\end{table}

Table~\ref{table:domains-tags} shows the tags associated to the domains provided by NewsGuard. We are interested in quantifying reputation of news domains publishing during the period of interest. 
Thus, we do not consider those sources corresponding to platforms (tag P). Also, we will not consider satiric news (tag S). 
% \fasa{; nevertheless, the information regarding their frequency are available for the interested readers in the Supplementary Material.} 
Tags T and N in Table~\ref{table:domains-tags} are used only for news sites, be them newspapers, magazines, TV or radio social channels, and they stand for Trustworthy and Non-trustworthy, respectively. 


% Here, we report a series of analyses related to the domains that mostly appear in the tweets of the validated network of verified users. 
\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{IMG/URL_reliability_distribution_ds_validated.png}
  \caption{Classification of links: trustworthy news publisher (T); non-trustworthy news publisher (N); not a news site, e.g. platforms as amazon.com (P); link corresponding to a domain not covered by NewsGuard (UNC).\label{fig:url_reliability_distribution}}
\end{figure}

%\sout{We clarify that a domain, for us, corresponds to the so-called `second-level domain' name\footnote{\url{https://en.wikipedia.org/wiki/Domain_name}}, i.e., the name directly to the left of .com, .net, and any other top-level domains. For instance,  \url{nytimes.com} and \url{latimes.com} are considered as domains in the present manuscript.}

%Figure~\ref{fig:url_reliability_distribution} \hl{shows the distribution of URLs found in tweets in the complete and validated dataset regarding the tags that NewsGuard assigned to the related domains. A link is labeled UNC if the corresponding domain was not analyzed by NewsGuard, at least at the time of the data collection. T represent a trustworthy news publisher, N a non-trustworthy news publisher, and P is a link whose domain is not a news publisher.} \man{}

Figure~\ref{fig:url_reliability_distribution} shows the distribution of URLs found in tweets in the complete and validated dataset regarding the tags that NewsGuard assigned to the related domains. We can observe that the validation procedure discards $\sim17\%$ of the tweets from the complete dataset, which translates into approximately 64k tweets. Hence, most links are disseminated within the political communities that emerge from data.
%A link is labeled UNC if the corresponding domain was not analyzed by NewsGuard, at least at the time of the data collection. T represent a trustworthy news publisher, N a non-trustworthy news publisher, and P is a link whose domain is not a news publisher.} \man{}

\subsection{Bot detection}
\label{sec:botdetection}
The accounts in our dataset were examined with the bot detector Botometer~\cite{Varol2017,FerraraArming2019,DBLP:conf/cikm/Sayyadiharikandeh20}. The tool is based on a supervised machine learning approach employing Random Forest classifiers~\cite{Breiman2001}. 

In particular, we adopted Botomoter v4 premium in the lite version BotometerLite\footnote{\url{https://cnets.indiana.edu/blog/2020/09/01/botometer-v4/}},  which does not interface with Twitter, but simply takes the tweet, retrieves the author, and does the necessary follow-up analysis. This light version only needs the information in the user profile to perform bot detection and hence can also process historical data published by accounts that are no longer active. Each request to BotometerLite can process a maximum of 100 users, with the limit of 200 requests per day, leading to a maximum of 20k account checks per day.
%(50 dollars/month)
% allows a rate limit of 17,280 requests per day (each request processes 1 user only).  
%  so this allows to check more than 1,700,000 users per day). 
% In addition, v4 premium offers the lite version BotometerLite, which does not interface with Twitter, but simply takes the tweet, retrieves the author, and does the necessary follow-up analysis. 


%
% Given a Twitter account, Botometer extracts, via the Twitter API, over 1,000 features about the account, 
%  including measures of sentiment, time of day, tweets content and Twitter network. 
The immediate output of Botometer is the bot score $S$ ranging over \{0, \ldots 1\}, which however does not represent the probability that the considered account is a bot. The value has to be compared with other scores within a group of accounts, to come up with a plausible ranking. 



%In the main text,  we consider the distribution of bot scores on the main discursive communities emerged from data. 

\subsection{Reputation of news domains in tweets associated to swing and safe states}
\label{sec:reputationState}




\begin{table}[]
%commentate caption per versione da workshop
%\caption{Statistics regarding number of accounts, tweets, and type of URLs, \sout{per community and} per state type in \sc{Validated dataset}. 
\caption{Statistics regarding number of accounts, tweets, and type of URLs per state type in \sc{Validated dataset}.
\label{tab:misinformation_in_swing_and_safe}}
\begin{tabular}{lccccc}
\toprule
States &  No. Users &  No. Tweets &  No. URL &  T &  N \\%&  UNC \\
\midrule
%commentate la riga sotto per versione da workshop
%\multicolumn{6}{l}{\sc{Validated dataset}} \\

Swing &     636125 &     \textbf{2911735} &   352606 & \textbf{29.84} & \textbf{23.47} \\ %&   39.76 \\
Safe &     214329 &      \textbf{404182} &    45989 & \textbf{50.87} & \textbf{18.33} \\ %&   28.37 \\

%commentate le righe sotto per versione da workshop
% \midrule
% \multicolumn{6}{l}{\sc{Rep}} \\
% Swing &     251615 &     1825320 &   218565 & 18.66 & 34.72 \\ %&   38.76 \\
%  Safe &     112556 &      257236 &    22819 & 37.92 & 33.25 \\ %&   26.40 \\
 
% \midrule
% \multicolumn{6}{l}{\sc{Rep-Dem-Journ}} \\
% Swing &     200225 &      824322 &    80645 & 54.45 &  2.59 \\ %&   40.45 \\
% Safe &      58088 &       95627 &    11767 & 75.37 &  0.91 \\ %&   22.11 \\
\bottomrule
\end{tabular}
\end{table}
Here, we analyze the flow of disinformation in tweets associated with swing or safe states. We recall that a tweet is associated with a state if the name of the state is in the tweet text. Each tweet in our dataset contains only one state name, by construction.



% In questa sezione analizziamo il dataset dividendo il traffico in base alla tipologia di stato i.e., swing or safe. Un tweet viene associato alla categoria swing se nel testo del tweet (o del retweeted) e presente il nome di uno stato swing (vedi Tab \ref{tab:dataset_by_states}); analogamente viene fatto per i safe. Ricordiamo che per costruzione, ciascun tweet del nostro dataset puo contiene un solo nome di stato (che puo appartenere alla categoria swing or safe).

% In modo simile a come fatto in Section \ref{sec:reputationComm}, le nostre analisi si focalizzeranno dapprima sul capire come il traffico un-reputable (and reputable) si suddivide (i) tra swing e safe states e (ii) tra swing e safe considerando anche la community politica di appartenenza del tweet (i.e., {\sc Rep} or {\sc Rep-Dem-Journ}); cerceremo poi di evidenziare le eventuali differenze in termini viralita nella condivisione.

Table~\ref{tab:misinformation_in_swing_and_safe} gives statistics regarding number of accounts, tweets, and URLs w.r.t. the state associated to the tweets. %\cutforworkshop{ and the two main political communities.}
We observe that the vast majority of traffic is associated with tweets about swing states (about 88\% of the total, see row Dataset, column No. Tweets). Considering links pointing to non-trustworthy news sites (N), the  concentration for swing states - 23.47\% - is higher than that for safe ones - 18.33\%. The  concentration of trustworthy links (T) is higher for safe states - 50.87\% {\it vs} 29.84\% for swings.


% commentato per versione da workshop
% At community level, in agreement with the results in Section~\ref{sec:reputationComm}, we observe a higher concentration of links N in the {\sc Rep} community; however,  we do not notice substantial differences in percentage terms of links N between swing and safe states for both {\sc Rep} and {\sc Rep-Dem-Journ} (Table~\ref{tab:misinformation_in_swing_and_safe}, rightmost column).  For both the communities,  the highest concentration of trustworthy links (T) is in tweets associated to safe states (column T).

%commentato per versione workshop
% \begin{figure}[h]
%   \centering
%   \includegraphics[width=\linewidth]{IMG/sharing_behavoiours_swing_vs_safe_rep.png}
%   \Description{}
%   \caption{Distribution of the number of link shared per kind of state in {\sc Rep}. Values are normalized applying a log function.}\label{fig:url_sharing_behaviour_in_swing_and_comm}
% \end{figure}

% Figure~\ref{fig:url_sharing_behaviour_in_swing_and_comm} shows that, in {\sc Rep}, non-trustworthy links (N) are shared, on average, many more times in the debate associated with swing states. 
% Specifically, the average number of sharing is 66 times for  \emph{swing} and 22 times for  \emph{safe}. For trustworthy links (T), a similar but not as pronounced behavior is observed. 





%$[$ TODO or not $]$ Focus on swing state - N links - rep community, Figure\ref{fig:sharing_behaviours_swing_rep}: TODO potrebbe essere carina un analisi in piu.



\subsection{Social bots}
%commentato per versione da workshop
% \begin{table*}[ht!]
% \caption{Results of the Kolmogorov-Smirnov test about the bot scores distribution in the two main communities.} \label{tab:statistical_tests_ks}
%     \begin{tabular}{llrr}
% \toprule
%        dist$_A$ &        dist$_B$ &  KS test (dist$_A$,dist$_B$) &  p-value$_{KS}$ \\
% \midrule       
%         {\sc Both} &           {\sc Rep} &    0.021 &         $<10^{-319}$\\
%         {\sc Both} & {\sc Rep-Dem-Journ} &    0.047 &        $<10^{-319}$  \\
%         {\sc Rep-Dem-Journ} &           {\sc Rep} &    0.068 &          $<10^{-319}$  \\
% \bottomrule
% \end{tabular}
% \end{table*}


%commentato per versione da workshop
% \begin{table*}[ht!]
%     \centering
%         \caption{Results of the Mann-Whitney U test about the bot scores distribution in the two main communities.} \label{tab:statistical_tests_mwu}
%     \begin{tabular}{llrrr}
% \toprule
%        dist$_A$ &        dist$_B$ &  MWU test (dist$_A$,dist$_B$) &  MWU test (dist$_B$,dist$_A$)  &  p-value$_{MWU}$ \\
% \midrule

         
%         {\sc Both} &           {\sc Rep}  &    0.486 &    0.514 &           $<10^{-309}$ \\
%          {\sc Both} & {\sc Rep-Dem-Journ} &    0.532 &    0.468 &           $<10^{-309}$ \\
% {\sc Rep-Dem-Journ} &           {\sc Rep}  &    0.453 &    0.547 &           $<10^{-309}$ \\
% \bottomrule
% \end{tabular}
% \end{table*}



In this section, we investigate the relationship between disinformation flow and the nature of the accounts in our dataset.  We calculate the bot scores of the accounts using BotomerLite (details in Section~\ref{sec:botdetection}). The bot score provides a measure of how much an account has bot-like features, on a scale between 0 and 1 -the closer the score to 1, the more likely the account is bot.


%commentato per versione da workshop
% We conduct two types of analysis. The first aims to understand whether different types of users (in terms of bot scores) intervene in the discussions of the two main communities. 

%With the second analysis, 


%commentato per versione da workshop
% For the first analysis, we compare the bot score distributions in {\sc Rep} and {\sc Rep-Dem-Journ}, by applying the Mann-Whitney U~\cite{mann1947} and Kolmogorov-Smirnov~\cite{smirnov1939test} statistical tests. Both tests serve to determine whether two distributions differ and how. 
% The bot score distributions were constructed by keeping, for each tweet, the bot score of the account that posted it. 

 

%\begin{table*}[]
%    \centering
%    \begin{tabular}{llrrrrr}
%\toprule
%       dist$_A$ &        dist$_B$ &  KS test (dist$_A$,dist$_B$) &  p-value$_{KS}$ &  MWU test (dist$_A$,dist$_B$) &  MWU test (dist$_B$,dist$_A$)  &  p-value$_{MWU}$ \\
%\midrule
%         {\sc Both} &   {\sc Rep} &     \textcolor{red}{0.02} &         \textcolor{red}{0.0} &        0.49 &        0.51 &          \textcolor{red}{0.0} \\
%         {\sc Both} & {\sc Rep-Dem\_Journ} &     \textcolor{red}{0.05} &         \textcolor{red}{0.0} &        0.53 &        0.47 &          \textcolor{red}{0.0} \\
%         {\sc Rep-Dem\_Journ} & {\sc Rep} &     \textcolor{red}{0.07} &         \textcolor{red}{0.0} & 0.45 & 0.55 & \textcolor{red}{0.0}\\
%\bottomrule
%\end{tabular}
%    \caption{Results of the statistical test regarding the distribution of the bot score in the various communities.} \label{tab:statistical_tests}
%\end{table*}


% commentato per versione da workshop Figure~\ref{fig:traffic_bot_score_distribution}  shows the distributions of the bot scores related to the whole traffic (left) and that including URLs only (right).  Since the distributions associated with the two communities have fairly close mean values,  ({\sc Rep} $0.26$ and {\sc Rep-Dem-Journ} $0.23$ for the whole traffic;  {\sc Rep} $0.272$ and {\sc Rep-Dem-Journ} $0.238$ for URLs traffic), we performed the Kolmogorov-Smirnov and the Mann–Whitney U statistical tests to check if the distributions are statistically different.\\
% Kolmogorov-Smirnov (KS) test measures the distance of  two empirical distributions as the maximum difference of their cumulative distributions. The p-values of the Kolmogorov-Smirnov tests (see Table~\ref{tab:statistical_tests_ks}) say that the distributions of the bot scores in the two communities are significantly different with respect to the ones of the entire dataset (all p-values are lower than 
% $10^{-319}$) and that the {\sc Rep-Dem-Journ} bot score distribution is a little farther from the one of the entire dataset.\\ 
% Instead, the Mann–Whitney U (MWU) test captures the difference in location between distributions. Our results (see Table~\ref{tab:statistical_tests_mwu}) confirm that the distributions are significantly different (again, all p-values are lower than $10^{-309}$), but also that the values of the bot scores in {\sc Rep} are greater than the ones of the entire dataset and even much greater than the ones measured in the {\sc Rep-Dem-Journ} community. Those results suggest that tweets in the two communities are composed by users of different nature (in terms of bot scores).

%commentato per versione da workshop

% \begin{figure}[h]
%   \centering
%   \includegraphics[width=\linewidth]{IMG/traffic-bot-scoe-distribution.png}
%   \caption{Distributions of bot scores in both communities (left for each panel), {\sc Rep} (center) and {\sc Rep-Dem-Journ} (right). Green line is the mean, red line is the median. \label{fig:traffic_bot_score_distribution}}
%   \Description{}
% \end{figure}

% Nella seconda analisi, cercheremo di far luce sul ruolo dei bot nella condivisione di traffico un-reputable. 

% The second analysis aims at detecting non-trustworthy tweets posted by bot accounts. 
%
To determine which accounts are bots, we choose the conservative approach used in~\cite{Ferrara2020characterizing}: we classify as bots those accounts `that sit at the top end of the bot score distribution'. The advantage is twofold: on the one hand, we avoid misclassifying accounts with a borderline score; on the other hand, we focus on accounts that exhibit clear bot characteristics. 
Practically, we tag each account in the validated dataset via BotometerLite, we sort them from the lowest to the highest bot score, and isolate those with bot scores in the first and last decile. 
In the first decile we have genuine accounts, in the last decile we have bot accounts. The first decile includes accounts with bot score in [0, 0.04]; the last decile include accounts with bot score in [0.45, 1]. 


We take the tweets of each of the genuine accounts and the bots, with the aim of investigating responsibility of the non-trustworthy traffic attributable? Obviously, we are cutting many accounts from our validated dataset, since we do not consider those with bot scores in \{0.04, 0.45\}. 
Table~\ref{tab:human_bot_user_classification} shows some statistics for only the accounts that we have classified. 
Out of the total number of classified accounts, bots account for 47.19\%. 
% If only the {\sc Rep} community is considered, the percentage rises to 54.93\%, while in {\sc Rep-Dem-Journ} it drops to 37.35\%. 


\begin{table}
\caption{Genuine and bot accounts in the validated dataset \label{tab:human_bot_user_classification}}
\begin{tabular}{lccc}
\toprule
        Label &  No. Users &  No. Tweets &  No. URL \\
\midrule
        \multicolumn{4}{l}{\sc{Validated dataset}} \\ 
        human &      57797 &      228378 &    25422 \\
        bot &      51648 &      409449 &    53017 \\
        % \midrule
        % \multicolumn{4}{l}{\sc{Rep}} \\ 
        % human &      27624 &      147772 &    16156 \\
        % bot &      33663 &      315065 &    41383 \\
        % \midrule
        % \multicolumn{4}{l}{\sc{Rep-Dem-Journ}} \\ 
        % human &      30173 &       80606 &     9266 \\
        % bot &      17985 &       94384 &    11634 \\
\bottomrule
\end{tabular}

\end{table}

% Di qui in avanti faremo delle considerazioni basandoci sull'attivita dei soli account riconosciuti come bot - or not. In pratica escuderemo tutti tweets pubblicati dagli utenti con bot score nell'intervallo 0.04 a 0.45 (estremi non compresi).
% Dalla Tab \ref{tab:human_bot_user_classification} si osserva che in termini di numero di account, considerando entrambe le community (i.e., Both) i bot rappresentano il $47.19$\% degli utenti classificati; per la community {\sc Rep} rappresentano il $54.93$\%, mentre per la {\sc Rep-Dem-Journ} il $37.35$\%.  

In terms of posts, bots appear to be more active than genuine accounts (about twice as active) in both posting tweets and tweets with URLs. 
 Out of the total traffic from classified accounts, 
 bots produce 64.19\% of the traffic. 
 %68.07\% in {\sc Rep} and 53.94\% in {\sc Rep-Dem-Journ}.



We concentrate on the role played by bots in spreading links to low/non-trustworthy news stories. Table~\ref{tab:misinformation_for_bot_and_states} shows the percentages of (i) all, (ii) trustworthy (T) and (iii) non-trustworthy (N) URLs shared by users classified as bot or genuine. The table also considers the belonging to 
% a discursive community ({\sc Rep} or {\sc Rep-Dem-Journ}) and to 
a state category (swing or safe). 

% I risultati della classificazione verranno utilizzai per far luce sul ruolo dei bot nella condivisione di contenuti un-reputable (i) all'interno delle main communities (Sub-Section \ref{sec:BotComm}) e (ii) all'interno delle main communities condiderando anche la tipologia di stato a cui sono associati i.e., swing or safe (Sub-Section \ref{sec:BotStates}).


%commentato per versione da workshop
% \subsubsection{Disinformation, bots and discursive communities}\label{sec:BotComm}



    Focusing on the \emph{Swing \& Safe} column in Table~\ref{tab:misinformation_for_bot_and_states}, we see that about the 73\% of the non-trustworthy (N) traffic is generated by bots, %regardless of the community, 
    while, on the other hand, they are responsible for about $\sim63\%$  of tweet displaying trustworthy URLs.  
    % If we focus only on traffic generated in {\sc Rep}, bots spread 73.84\% of the N and 69.11\% of T links. 


\begin{table*}[]
%commentata caption per la versione workshop
   % \caption{Percentages of links shared, per reputability\sout{, per community} and per state type. \label{tab:misinformation_for_bot_and_states}}
    \caption{Percentages of links shared, per reputability and per state type. \label{tab:misinformation_for_bot_and_states}}

\begin{tabular}{lcccccccccccc}
\toprule
    &&&&& \multicolumn{2}{c}{\emph{\textbf{Swing \& Safe}}} && \multicolumn{2}{c}{\emph{\textbf{Swing}}} && \multicolumn{2}{c}{\emph{\textbf{Safe}}}\\
    \cmidrule{6-7}
    \cmidrule{9-10}
    \cmidrule{12-13}
    
    %Community
    Link type &  No. URL &  swing &  safe &&  bot &  human &&  bot &  human &&  bot &  human \\
    \midrule
    {\sc All Links} & 78439 &  89.92 & 10.08 &&      \textbf{67.59} &        32.41 &&   \textbf{67.87} &     32.13 &&   \textbf{65.06} &     34.94 \\
    %commentatate righe sotto per la versione workshop
    %\multicolumn{10}{l}{\textbf{All Links}} \\
    %{\sc Validated dataset} & 78439 &  89.92 & 10.08 &&      \textbf{67.59} &        32.41 &&   \textbf{67.87} &     32.13 &&   \textbf{65.06} &     34.94 \\
    % {\sc Rep} & 57539 &  90.78 &  9.22 &&      \textbf{71.92} &        28.08 &&   72.26 &     27.74 &&   68.63 &     31.37 \\
    % {\sc Rep-Dem-Journ} & 20900 &  87.54 & 12.46 &&      55.67 &       44.33 &&   55.36 &     44.64 &&   57.77 &     42.23 \\
    \midrule

    {\sc Trustworthy Links (T)} & 23036 &  83.07 & 16.93 &&      \textbf{62.90} &        37.10 &&   62.69 &     37.31 &&   63.96 &     36.04 \\
    %commentatate righe sotto per la versione workshop
    %\multicolumn{10}{l}{\textbf{Trustworthy Links (T)}} \\
    %     {\sc Validated dataset} & 23036 &  83.07 & 16.93 &&      \textbf{62.90} &        37.10 &&   62.69 &     37.31 &&   63.96 &     36.04 \\
%           {\sc Rep} & 11812 &  83.46 & 16.54 & &     \textbf{69.11} &        30.89 &&   68.84 &     31.16 &&   70.47 &     29.53 \\
% {\sc Rep-Dem-Journ} & 11224 &  82.65 & 17.35 & &     56.37 &        43.63 &&   56.15 &     43.85 &&   57.42 &     42.58 \\
    \midrule

    {\sc Non-trustworthy Links (N)}& 20627 &  \textbf{91.53} &  \textbf{8.47} & &     \textbf{73.69} &        26.31 &&   \textbf{74.15} &     25.85 &&   \textbf{68.75} &     31.25 \\
    %commentatate righe sotto per la versione workshop
    %\multicolumn{10}{l}{\textbf{Non-trustworthy Links (N)}} \\
    %     {\sc Validated dataset} & 20627 &  \textbf{91.53} &  \textbf{8.47} & &     \textbf{73.69} &        26.31 &&   \textbf{74.15} &     25.85 &&   \textbf{68.75} &     31.25 \\
%           {\sc Rep} & 20147 &  91.42 &  8.58 & &     \textbf{73.84} &        26.16 &&   74.33 &     25.67 &&   68.59 &     31.41 \\
% {\sc Rep-Dem-Journ} & 480 &  96.25 &  3.75 &  &    67.50 &        32.50 &&   66.88 &     33.12 &&   83.33 &     16.67 \\
\bottomrule
\end{tabular}
   
\end{table*}


% \subsubsection{Disinformation, bots, and swing states}\label{sec:BotStates}
% Here, we exploit the tweets of the accounts classified as bot or not (excluding those accounts with bot score between 0.04 and 0.45) to study the role of bots in the discussions associated to swing and safe states. 
If we focus on non-trustworthy links only, of the 91\% of the total in swing states, more than 74\% are posted or retweeted by bots. Furthermore, although non-trustworthy links associated with safe states are only a small part of the total (8.47\%), the vast majority of this traffic comes from bots accounts (68.75\%).





% In this regard, we focus on the two multi-column \emph{Swing} and \emph{Safe} in Table~\ref{tab:misinformation_for_bot_and_states} in which the traffic percentages associated with bots and humans are shown for both Swing and Safe associated tweets for the various levels of reputability and community.

%La quantita maggiore di un-reputable links (N) si concentra nelle discussioni relative a swing states. Considerando infatti i links (N) su entrambe le communities, in {\sc Both} row, il 91.53\% dei link N si concentra su swing states; di questo, il 74.15\%, ossia gran parte del traffico un-reputable, viene prodotto da bot per le discussioni relative a swing states. 



%Per entrambi i tipi di links, sia T che N, la maggior parte del traffico sta nelle discussioni associate agli swing state (colonna swing). Se ci concentriamo sui non trustworthy links only, del 91\% del totale negli stati swing, piu' del 74\% e' postato o retwittato da bots. Inoltre, sebbene i links non  trustworthy presenti associati agli stati safe siano solo una piccola parte del totale (8.47), la larga maggioranza  di questo traffico viene da account bots (68.75). 
%For both types of links, T and N, most of the traffic is in discussions associated with swing states (swing column). 
%If we focus on non-trustworthy links only, of the 91\% of the total in swing states, more than 74\% are posted or retweeted by bots. Furthermore, although non-trustworthy links associated with safe states are only a small part of the total (8.47\%), the vast majority of this traffic comes from bots accounts (68.75\%).


% The largest amount of non-trustworthy links (N) is concentrated in discussions related to swing states. Considering the links (N) on both communities, in the {\sc Both} row, 91.53\% of the N links are concentrated on swing states; of this, 74.15\%, i.e. most of the non-trustworthy traffic, is produced by bots for swing state related discussions. 



%\textbf{Il risultato piu interessante di questa analisi e che, se consideriamo il traffico di URL prodotto da bots nella community {\sc Rep},  la concentrazione maggiore di un-reputable link (N) si concentra in discussioni relative a swing states. Sebbene per gli stati safe ci sia un numero minore di dati, osserviamo una percentuale di traffico un-reputable pari a 36.28\% swing e 32.57\% per i safe. Nella stessa direzione notiamo che in generale per le discussioni associate a stati safe si osserva una concentrazione maggiore di reputable link (T).}\man{ALLINEARE NUMERI SU DISCUSSOIN E MAIN RESULTS}

\section{Discussion}
The analysis of disinformation in online social networks during election campaigns features several contributions, like~\cite{Becatti2019d, Bovet2019influence, budak2019happened, Ferrara2020characterizing, Georgacopoulos2020how,luceri2019evolution, mattei2022bowtie} to cite a few. Nevertheless, the spreading of non reputable content has been rarely compared to the peculiarities of a specific election system; most of the existing studies on disinformation focus on a single country. However, the election procedure seems to have a role in the way the online discussions evolve: the few results available so far~\cite{Bright2018,Urman2020,VanVliet2021,Praet2021, howard2018social} indicate that there are indeed some differences in the way accounts organise in online debates, i.e, according to more divisive or cohesive structures, in countries with majoritarian, proportional or plurality election systems.

In the present work, we still consider a single country, but we focus on (i) a characteristic of its presidential election system, i.e., the presence of swing and safe states and (ii) if and to which extent  this feature is reflected in the online disinformation spreading.

More in detail, each U.S. state  has a  number of presidential electors and, after the popular elections at state level, the faction that obtains the greatest number of votes, earns all of them, independently on the margin of the final result. Then, \emph{safe} states are those in which the electorate has a traditional orientation and the result of the election can be easily predicted, while \emph{swing} states are the ones to compete for in order to obtain the presidential election.

Therefore, we focused our analysis on the 2020 U.S. presidential elections, and we consider the Twitter debate associated with 8 states, 4 of them being safe ones (New Jersey, Indiana, Washington and Louisiana), the other 4 being swing ones (Arizona, Florida, Michigan and Pennsylvania). Then, we selected tweets displaying in their text the name of the presidential candidates (either Biden or Trump) and the name of one of the selected states.

Our first result is that 88\% tweets in our dataset is related to swing states. If we consider the population of the various states as a proxy for the estimate of the relative amount of traffic of the swing state, we will expect a percentage of 66\%: the mismatch witnesses a greater attention on the election campaigns on these states.

Secondly, from Table~\ref{tab:misinformation_in_swing_and_safe we observe that} the frequency of non-trustworthy URLs shared in the political debate of swing states (23.47\%) is greater than the analogous of safe states (18.33\%). Symmetrically, the frequency of trustworthy URLs is higher in safe states (50.87\%) than swing ones (29.84\%). 
In this sense, not only the debate, but also the diffusion of disinformation, is more intense in swing states, due to their importance for the election outcome. Summarising, we have that both the total flux of messages and the frequency of non reputable URLs are higher in swing states.

% Thirdly, we investigate the exposure to disinformation of the main discursive communities. Using techniques based on Information Theory and Statistical Mechanics of complex networks (see Section~\ref{sssec:DisCo}), we were able to distinguish between a great community of Republican supporters (the {\sc Rep} community) and a mixed one, including both Democrats and Republicans, as well as various journalists (the {\sc Rep-Dem-Journ} community). Remarkably, the {\sc Rep} community hosts 91\% of the total URLs pointing to  non-trustworthy news sources. Moreover, each non-trustworthy URL in the {\sc Rep} community is shared, on average, more times w.r.t. other types of URLs.

Thirdly, we investigate the contribution of automated accounts in the spreading of disinformation. Let the reader consider Table~\ref{tab:misinformation_for_bot_and_states}: bots appear to be more active than genuine accounts in posting tweets, both in swing and in safe states, with comparable percentages, i.e. $\sim$67\% vs. $\sim$65\%, respectively in swing and safe states. Regarding the non-trustworthy links shared in swing states, more than 74\% are posted or retweeted by bots.

% Nevertheless, their contribution to the diffusion of non-reputable URLs changes dramatically from swing to safe states, respectively 74.15\% and 68.75\%.\\
Our analyses were carried out by applying filtering to the initial dataset. We used techniques based on Information Theory and Statistical Mechanics of complex networks (see Section~\ref{sssec:DisCo}) to bring out political communities. In particular, we focused on the bipartite network that represents the retweet interaction between verified and unverified users. Using the BiCM as a benchmark we validate the projection of the bipartite network on the layer of verified users: we put a link between two of them if the number of common unverified retweeters is statistically significant. We then ran a community detection algorithm over the so-obtained network of verified users; we extended the communities to unverified Twitter users too, by exploiting the knowledge about verified ones and a label propagation procedure. With our validation method, we ensure that we consider interactions that cannot be explained by the degree sequence of the users. We emphasize the application of this filtering, which differentiates us from other work, as that in~\cite{howard2018social}, which analyzes disinformation flows in swing and safe states in 2016, but without applying entropy-based null models. 


Summarising, our hypothesis that the diffusion of disinformation is more intense in swing states is confirmed by data: due to their relevance for the outcome of the election, swing states both attract more tweets and, in percentage, are more exposed to disinformation campaigns than safe states. The relative impact of disinformation and the stronger flux of messages result in a particularly worrisome flux of disinformation messages. %The disinformation messages are mostly produced by the {\sc Rep} community.

\paragraph{Limitations and future work}
While our results are neat, there are still some limitations that call for further studies. First, we investigate only a limited amount of U.S. swing and safe states. Then, we just analyzed the 2020 U.S. presidential election, while a comparison with the 2012 and 2016 elections could confirm our conclusions or limit them to the 2020 competition only.\\
Moreover, by adopting a keyword-based data collection method, we do not know \emph{a priori} the exact content of the collected tweets (although, since there is both the state name and the candidate name, the tweet plausibly refers to the election and that state). 


Further, other plurality election systems have similarities with U.S., as the U.K. one: it would be interesting to study if analogous diffusion of disinformation on swing electoral constituencies are present. It would also be interesting to consider if the diffusion of disinformation at geographical level is present also in other election systems, featuring, e.g.,  the proportional (as in Germany and Spain), majoritarian (as in France) or mixed modes (as in Italy, South Korea and Japan). 
We argue we have contributed to a finer granularity study concerning the link between electoral systems, online debates, and the presence of online disinformation, and we release the dataset for the benefit of the scientific community.

\begin{comment}
Since the advent of social media, literature has been exploring whether and to what extent what happens in virtual life can affect what happens in real life. [...] [cit]
The literature  there are different opinions on the impact that a particular grouping of users in OSN
can have on their offline behavior

qui abbiamo cercato di fare l'esplorazione contraria. Puo' un meccanismo reale influenzare il comportamento virtuale?

TODO (collegare main results and results e dare take home message chiaro e semplice basandoci sugli esperimenti)

Main results (\textbf{la sezione Main results DEVE essere allineata}):
\begin{itemize}
    
    \item  The two most crowded community are the {\sc Rep} and {\sc Rep-Dem-Journ} communities composed by respectively, Republicans supporters and Republicans, Democrats and some journals and journalists with various political orientations.
    
    \item The {\sc Rep} community hosts most (91\%) of the total links posted by non-trustworthy news sources. Each link N in that community is shared, in mean, more times w.r.t. other types of links.
    
    \item Su tutto il dataset la maggior parte dei tweets - circa l'88\% del totale - e associata a stati swing. Per gli swing la concentrazione di non-trustworthy link (N) - 23.47\% - e maggiore rispetto a quella presente per i safe - 18.33\%. Nella stessa direzione, la percentuale di link trustworthy (T) e maggiore per gli stati safe - 50.87\% contro 29.84\% per gli swing. 
    
    \item \textbf{Se prendiamo in esame il SOLO traffico generato da utenti classificati come bot or not}:
    \begin{itemize}
        
        \item Table~\ref{tab:human_bot_user_classification}, bots appear to be more active than genuine accounts (about twice as active) in both posting tweets and tweets with URLs. Out of the total traffic from classified accounts on both communities, bots produce 64.19\% of the traffic; 68.07\% in {\sc Rep} and 53.94\% in {\sc Rep-Dem-Journ}.
    
        \item del traffico non-trustworthy i bot sono responsabili del 73.69\% (e del 62.9\% del traffico T. Nella community {\sc Rep} i bot producono il 71.92\% del traffico. In altre parole nella  {\sc Rep} i bot producono  il 73.84\% del traffico low-reputable; ed il 69.11\% del traffico T.
    
        \item Swing and Safe: \man{ La quantita maggiore di non-trustworthy links (N) si concentra nelle discussioni relative a swing states. Considerando i links (N) su entrambe le communities, in {\sc Both} row, il 91.53\% dei link N si concentra su swing states; di questo, il 74.15\%, ossia gran parte del traffico un-reputable, viene prodotto da bot per le discussioni relative a swing }.
    
        \item E importante notare che le il traffico generato dagli account classificati come bot or not rappresenta il 21.24\% del traffico generato da tutti gli utenti (con bot score compreso tra 0 e 1) presenti nelle due community principali (i.e., {\sc Rep} e {\sc Rep-Dem-Journ}). Questo e dovuto alla scelta di impiegare un approccio conservativo nella scelta delle soglie di classificazione che pero permette di tenere basso i false negaive/positive.
        
    \end{itemize}
     
\end{itemize}


\subsection{Limitations}
\begin{itemize}
    \item we focus on a limited number of swings and safe states.
    \item only on 2020, not on previous elections
    \item geolocalization rara, non sappiamo se un tweet che contiene il nome dello stato sia 1) stato scritto da quello stato e soprattutto 2) se non sia casuale la sua presenza
    \item few data for safe states.
    \item analisi (degli URL) non esaustiva, potrebbe essere arricchita con altre analisi NLP testo tweets, etc.
    \item ...
\end{itemize}


\section{Conclusions}
TODO (cosa aggiunge il nostro risultato e la parte discussion alla letteratura?)


\subsection{Future work}
\begin{itemize}
    \item TODO
    \item ...
\end{itemize}
\end{comment}

% \newpage

% \section{Template overview}

% As noted in the introduction, the ``\verb|acmart|'' document class can
% be used to prepare many different kinds of documentation --- a
% double-blind initial submission of a full-length technical paper, a
% two-page SIGGRAPH Emerging Technologies abstract, a ``camera-ready''
% journal article, a SIGCHI Extended Abstract, and more --- all by
% selecting the appropriate {\itshape template style} and {\itshape
%   template parameters}.

% This document will explain the major features of the document
% class. For further information, the {\itshape \LaTeX\ User's Guide} is
% available from
% \url{https://www.acm.org/publications/proceedings-template}.

% \subsection{Template Styles}

% The primary parameter given to the ``\verb|acmart|'' document class is
% the {\itshape template style} which corresponds to the kind of publication
% or SIG publishing the work. This parameter is enclosed in square
% brackets and is a part of the {\verb|documentclass|} command:
% \begin{verbatim}
%   \documentclass[STYLE]{acmconf}
% \end{verbatim}

% Journals use one of three template styles. All but three ACM journals
% use the {\verb|acmsmall|} template style:
% \begin{itemize}
% \item {\verb|acmsmall|}: The default journal template style.
% \item {\verb|acmlarge|}: Used by JOCCH and TAP.
% \item {\verb|acmtog|}: Used by TOG.
% \end{itemize}

% The majority of conference proceedings documentation will use the {\verb|acmconf|} template style.
% \begin{itemize}
% \item {\verb|acmconf|}: The default proceedings template style.
% \item{\verb|sigchi|}: Used for SIGCHI conference articles.
% \item{\verb|sigchi-a|}: Used for SIGCHI ``Extended Abstract'' articles.
% \item{\verb|sigplan|}: Used for SIGPLAN conference articles.
% \end{itemize}

% \subsection{Template Parameters}

% In addition to specifying the {\itshape template style} to be used in
% formatting your work, there are a number of {\itshape template parameters}
% which modify some part of the applied template style. A complete list
% of these parameters can be found in the {\itshape \LaTeX\ User's Guide.}

% Frequently-used parameters, or combinations of parameters, include:
% \begin{itemize}
% \item {\verb|anonymous,review|}: Suitable for a ``double-blind''
%   conference submission. Anonymizes the work and includes line
%   numbers. Use with the \verb|\acmSubmissionID| command to print the
%   submission's unique ID on each page of the work.
% \item{\verb|authorversion|}: Produces a version of the work suitable
%   for posting by the author.
% \item{\verb|screen|}: Produces colored hyperlinks.
% \end{itemize}

% This document uses the following string as the first command in the
% source file:
% \begin{verbatim}
% \documentclass[sigconf,authordraft]{acmart}
% \end{verbatim}



%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
\begin{acks}

This work was partially supported by project SERICS (PE00000014) under the MUR National Recovery and Resilience Plan funded by the European Union - NextGenerationEU, by the Integrated Activity Project TOFFEe (TOols for Fighting FakEs) \url{https://toffee.imtlucca.it/} and by the IIT-CNR funded Project re-DESIRE (DissEmination of ScIentific REsults 2.0).

\end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\begin{thebibliography}{54}

%%% ====================================================================
%%% NOTE TO THE USER: you can override these defaults by providing
%%% customized versions of any of these macros before the \bibliography
%%% command.  Each of them MUST provide its own final punctuation,
%%% except for \shownote{}, \showDOI{}, and \showURL{}.  The latter two
%%% do not use final punctuation, in order to avoid confusing it with
%%% the Web address.
%%%
%%% To suppress output of a particular field, define its macro to expand
%%% to an empty string, or better, \unskip, like this:
%%%
%%% \newcommand{\showDOI}[1]{\unskip}   % LaTeX syntax
%%%
%%% \def \showDOI #1{\unskip}           % plain TeX syntax
%%%
%%% ====================================================================

\ifx \showCODEN    \undefined \def \showCODEN     #1{\unskip}     \fi
\ifx \showDOI      \undefined \def \showDOI       #1{#1}\fi
\ifx \showISBNx    \undefined \def \showISBNx     #1{\unskip}     \fi
\ifx \showISBNxiii \undefined \def \showISBNxiii  #1{\unskip}     \fi
\ifx \showISSN     \undefined \def \showISSN      #1{\unskip}     \fi
\ifx \showLCCN     \undefined \def \showLCCN      #1{\unskip}     \fi
\ifx \shownote     \undefined \def \shownote      #1{#1}          \fi
\ifx \showarticletitle \undefined \def \showarticletitle #1{#1}   \fi
\ifx \showURL      \undefined \def \showURL       {\relax}        \fi
% The following commands are used for tagged output and should be
% invisible to TeX
\providecommand\bibfield[2]{#2}
\providecommand\bibinfo[2]{#2}
\providecommand\natexlab[1]{#1}
\providecommand\showeprint[2][]{arXiv:#2}

\bibitem[Becatti et~al\mbox{.}(2019)]%
        {Becatti2019d}
\bibfield{author}{\bibinfo{person}{Carolina Becatti}, \bibinfo{person}{Guido
  Caldarelli}, \bibinfo{person}{Renaud Lambiotte}, {and} \bibinfo{person}{Fabio
  Saracco}.} \bibinfo{year}{2019}\natexlab{}.
\newblock \showarticletitle{Extracting significant signal of news consumption
  from social networks: the case of Twitter in Italian political elections}.
\newblock \bibinfo{journal}{\emph{Palgrave Communications}}
  \bibinfo{volume}{5} (\bibinfo{date}{12} \bibinfo{year}{2019}),
  \bibinfo{pages}{1--16}.
\newblock
Issue 1.
\showISSN{20551045}
\urldef\tempurl%
\url{https://doi.org/10.1057/s41599-019-0300-3}
\showDOI{\tempurl}


\bibitem[Blondel et~al\mbox{.}(2008)]%
        {Blondel2008}
\bibfield{author}{\bibinfo{person}{Vincent~D. Blondel},
  \bibinfo{person}{Jean-Loup Guillaume}, \bibinfo{person}{Renaud Lambiotte},
  {and} \bibinfo{person}{Etienne Lefebvre}.} \bibinfo{year}{2008}\natexlab{}.
\newblock \showarticletitle{{Fast unfolding of communities in large networks}}.
\newblock \bibinfo{journal}{\emph{J. Stat. Mech. Theory Exp.}}
  \bibinfo{volume}{10008}, \bibinfo{number}{10} (\bibinfo{year}{2008}),
  \bibinfo{pages}{6}.
\newblock
\showISBNx{1742-5468}
\showISSN{1742-5468}
\urldef\tempurl%
\url{https://doi.org/10.1088/1742-5468/2008/10/P10008}
\showDOI{\tempurl}


\bibitem[Bovet and Makse(2019)]%
        {Bovet2019influence}
\bibfield{author}{\bibinfo{person}{Alexandre Bovet} {and}
  \bibinfo{person}{{Hern{\'{a}}n A.} Makse}.} \bibinfo{year}{2019}\natexlab{}.
\newblock \showarticletitle{Influence of fake news in {T}witter during the 2016
  US presidential election}.
\newblock \bibinfo{journal}{\emph{Nature Communications}} \bibinfo{volume}{10},
  \bibinfo{number}{7} (\bibinfo{year}{2019}).
\newblock


\bibitem[Bradshaw and Howard(2018)]%
        {Bradshaw2018junk}
\bibfield{author}{\bibinfo{person}{Samantha Bradshaw} {and}
  \bibinfo{person}{{Philip~N.} Howard}.} \bibinfo{year}{2018}\natexlab{}.
\newblock \showarticletitle{How does junk news spread so quickly across social
  media? {A}lgorithms, advertising and exposure in public life}.
\newblock \bibinfo{journal}{\emph{Oxford Internet Institute -- White Paper}}
  (\bibinfo{year}{2018}).
\newblock


\bibitem[Breiman(2001)]%
        {Breiman2001}
\bibfield{author}{\bibinfo{person}{Leo Breiman}.}
  \bibinfo{year}{2001}\natexlab{}.
\newblock \showarticletitle{Random Forests}.
\newblock \bibinfo{journal}{\emph{Machine Learning}} \bibinfo{volume}{45},
  \bibinfo{number}{1} (\bibinfo{date}{01 Oct} \bibinfo{year}{2001}),
  \bibinfo{pages}{5--32}.
\newblock
\urldef\tempurl%
\url{https://doi.org/10.1023/A:1010933404324}
\showDOI{\tempurl}


\bibitem[Bright(2018)]%
        {Bright2018}
\bibfield{author}{\bibinfo{person}{Jonathan Bright}.}
  \bibinfo{year}{2018}\natexlab{}.
\newblock \showarticletitle{{Explaining the Emergence of Political
  Fragmentation on Social Media: The Role of Ideology and Extremism}}.
\newblock \bibinfo{journal}{\emph{Journal of Computer-Mediated Communication}}
  \bibinfo{volume}{23}, \bibinfo{number}{1} (\bibinfo{date}{01}
  \bibinfo{year}{2018}), \bibinfo{pages}{17--33}.
\newblock
\showISSN{1083-6101}
\urldef\tempurl%
\url{https://doi.org/10.1093/jcmc/zmx002}
\showDOI{\tempurl}
\showeprint{https://academic.oup.com/jcmc/article-pdf/23/1/17/23822774/zmx002.pdf}


\bibitem[Broder et~al\mbox{.}(2000)]%
        {broder2000graph}
\bibfield{author}{\bibinfo{person}{Andrei Broder} {et~al\mbox{.}}}
  \bibinfo{year}{2000}\natexlab{}.
\newblock \showarticletitle{Graph structure in the web}.
\newblock \bibinfo{journal}{\emph{Comput. Netw.}} \bibinfo{volume}{33},
  \bibinfo{number}{1} (\bibinfo{year}{2000}), \bibinfo{pages}{309–320}.
\newblock


\bibitem[Budak(2019)]%
        {budak2019happened}
\bibfield{author}{\bibinfo{person}{Ceren Budak}.}
  \bibinfo{year}{2019}\natexlab{}.
\newblock \showarticletitle{What happened? the spread of fake news publisher
  content during the 2016 us presidential election}. In
  \bibinfo{booktitle}{\emph{The World Wide Web Conference}}.
  \bibinfo{pages}{139--150}.
\newblock


\bibitem[Caldarelli et~al\mbox{.}(2020)]%
        {caldarelli2020role}
\bibfield{author}{\bibinfo{person}{Guido Caldarelli}, \bibinfo{person}{Rocco
  De~Nicola}, \bibinfo{person}{Fabio Del~Vigna}, \bibinfo{person}{Marinella
  Petrocchi}, {and} \bibinfo{person}{Fabio Saracco}.}
  \bibinfo{year}{2020}\natexlab{}.
\newblock \showarticletitle{The role of bot squads in the political propaganda
  on Twitter}.
\newblock \bibinfo{journal}{\emph{Communications Physics}} \bibinfo{volume}{3},
  \bibinfo{number}{1} (\bibinfo{year}{2020}), \bibinfo{pages}{1--15}.
\newblock


\bibitem[Caldarelli et~al\mbox{.}(2021)]%
        {Caldarelli2021}
\bibfield{author}{\bibinfo{person}{Guido Caldarelli}, \bibinfo{person}{Rocco~De
  Nicola}, \bibinfo{person}{Marinella Petrocchi}, \bibinfo{person}{Manuel
  Pratelli}, {and} \bibinfo{person}{Fabio Saracco}.}
  \bibinfo{year}{2021}\natexlab{}.
\newblock \showarticletitle{Flow of online misinformation during the peak of
  the COVID-19 pandemic in Italy}.
\newblock \bibinfo{journal}{\emph{EPJ Data Science 2021 10:1}}
  \bibinfo{volume}{10} (\bibinfo{date}{7} \bibinfo{year}{2021}),
  \bibinfo{pages}{1--23}.
\newblock
Issue 1.
\showISSN{2193-1127}
\urldef\tempurl%
\url{https://doi.org/10.1140/EPJDS/S13688-021-00289-4}
\showDOI{\tempurl}


\bibitem[Cao et~al\mbox{.}(2014)]%
        {Cao:2014}
\bibfield{author}{\bibinfo{person}{Qiang Cao}, \bibinfo{person}{Xiaowei Yang},
  \bibinfo{person}{Jieqi Yu}, {and} \bibinfo{person}{Christopher Palow}.}
  \bibinfo{year}{2014}\natexlab{}.
\newblock \showarticletitle{Uncovering Large Groups of Active Malicious
  Accounts in Online Social Networks}. In \bibinfo{booktitle}{\emph{ACM SIGSAC
  Conference on Computer and Communications Security}}. ACM,
  \bibinfo{pages}{477--488}.
\newblock


\bibitem[Cimini et~al\mbox{.}(2018)]%
        {Cimini2018a}
\bibfield{author}{\bibinfo{person}{Giulio Cimini}, \bibinfo{person}{Tiziano
  Squartini}, \bibinfo{person}{Fabio Saracco}, \bibinfo{person}{Diego
  Garlaschelli}, \bibinfo{person}{Andrea Gabrielli}, {and}
  \bibinfo{person}{Guido Caldarelli}.} \bibinfo{year}{2018}\natexlab{}.
\newblock \showarticletitle{The Statistical Physics of Real-World Networks}.
\newblock \bibinfo{journal}{\emph{Nature Reviews Physics}}  \bibinfo{volume}{1}
  (\bibinfo{date}{1} \bibinfo{year}{2018}), \bibinfo{pages}{58--71}.
\newblock
Issue 1.
\showISSN{2522-5820}
\urldef\tempurl%
\url{https://doi.org/10.1038/s42254-018-0002-6}
\showDOI{\tempurl}


\bibitem[Clerck et~al\mbox{.}(2022a)]%
        {DeClerck2022b}
\bibfield{author}{\bibinfo{person}{Bart~De Clerck}, \bibinfo{person}{Luis E.~C.
  Rocha}, {and} \bibinfo{person}{Filip~Van Utterbeeck}.}
  \bibinfo{year}{2022}\natexlab{a}.
\newblock \showarticletitle{Maximum entropy networks for large scale social
  network node analysis}.
\newblock \bibinfo{journal}{\emph{Applied Network Science 2022 7:1}}
  \bibinfo{volume}{7} (\bibinfo{date}{9} \bibinfo{year}{2022}),
  \bibinfo{pages}{1--22}.
\newblock
Issue 1.
\showISSN{2364-8228}
\urldef\tempurl%
\url{https://doi.org/10.1007/S41109-022-00506-7}
\showDOI{\tempurl}


\bibitem[Clerck et~al\mbox{.}(2022b)]%
        {DeClerck2022a}
\bibfield{author}{\bibinfo{person}{Bart~De Clerck}, \bibinfo{person}{Filip~Van
  Utterbeeck}, \bibinfo{person}{Julien Petit}, \bibinfo{person}{Ben Lauwens},
  \bibinfo{person}{Wim Mees}, {and} \bibinfo{person}{Luis~E.C. Rocha}.}
  \bibinfo{year}{2022}\natexlab{b}.
\newblock \showarticletitle{Maximum Entropy Networks Applied on Twitter
  Disinformation Datasets}.
\newblock \bibinfo{journal}{\emph{Studies in Computational Intelligence}}
  \bibinfo{volume}{1016} (\bibinfo{year}{2022}), \bibinfo{pages}{132--143}.
\newblock
\showISBNx{9783030934125}
\showISSN{18609503}
\urldef\tempurl%
\url{https://doi.org/10.1007/978-3-030-93413-2_12/COVER}
\showDOI{\tempurl}


\bibitem[Cresci(2020)]%
        {cresci2020decade}
\bibfield{author}{\bibinfo{person}{Stefano Cresci}.}
  \bibinfo{year}{2020}\natexlab{}.
\newblock \showarticletitle{A decade of social bot detection}.
\newblock \bibinfo{journal}{\emph{Commun. {ACM}}} \bibinfo{volume}{63},
  \bibinfo{number}{10} (\bibinfo{year}{2020}), \bibinfo{pages}{72--83}.
\newblock


\bibitem[Cresci et~al\mbox{.}(2016)]%
        {IntSys2015}
\bibfield{author}{\bibinfo{person}{Stefano Cresci}, \bibinfo{person}{Roberto
  {Di Pietro}}, \bibinfo{person}{Marinella Petrocchi}, \bibinfo{person}{Angelo
  Spognardi}, {and} \bibinfo{person}{Maurizio Tesconi}.}
  \bibinfo{year}{2016}\natexlab{}.
\newblock \showarticletitle{{DNA}-inspired online behavioral modeling and its
  application to spambot detection}.
\newblock \bibinfo{journal}{\emph{IEEE Intelligent Systems}}
  \bibinfo{volume}{31}, \bibinfo{number}{5} (\bibinfo{year}{2016}),
  \bibinfo{pages}{58--64}.
\newblock


\bibitem[Cresci et~al\mbox{.}(2017)]%
        {Cresci2017paradigm}
\bibfield{author}{\bibinfo{person}{Stefano Cresci}, \bibinfo{person}{Roberto
  Di~Pietro}, \bibinfo{person}{Marinella Petrocchi}, \bibinfo{person}{Angelo
  Spognardi}, {and} \bibinfo{person}{Maurizio Tesconi}.}
  \bibinfo{year}{2017}\natexlab{}.
\newblock \showarticletitle{The paradigm-shift of social spambots: Evidence,
  theories, and tools for the arms race}. In
  \bibinfo{booktitle}{\emph{Proceedings of the 26th International Conference on
  World Wide Web Companion (WWW'17)}}. ACM, \bibinfo{pages}{963--972}.
\newblock


\bibitem[Cresci et~al\mbox{.}(2018)]%
        {cresci2018social}
\bibfield{author}{\bibinfo{person}{Stefano Cresci}, \bibinfo{person}{Roberto
  Di~Pietro}, \bibinfo{person}{Marinella Petrocchi}, \bibinfo{person}{Angelo
  Spognardi}, {and} \bibinfo{person}{Maurizio Tesconi}.}
  \bibinfo{year}{2018}\natexlab{}.
\newblock \showarticletitle{Social fingerprinting: detection of spambot groups
  through DNA-inspired behavioral modeling}.
\newblock \bibinfo{journal}{\emph{IEEE Transactions on Dependable and Secure
  Computing}} \bibinfo{volume}{15}, \bibinfo{number}{4} (\bibinfo{year}{2018}),
  \bibinfo{pages}{561--576}.
\newblock


\bibitem[{De Nicola} et~al\mbox{.}(2021)]%
        {DENICOLA2021102685}
\bibfield{author}{\bibinfo{person}{Rocco {De Nicola}},
  \bibinfo{person}{Marinella Petrocchi}, {and} \bibinfo{person}{Manuel
  Pratelli}.} \bibinfo{year}{2021}\natexlab{}.
\newblock \showarticletitle{On the efficacy of old features for the detection
  of new bots}.
\newblock \bibinfo{journal}{\emph{Information Processing and Management}}
  \bibinfo{volume}{58}, \bibinfo{number}{6} (\bibinfo{year}{2021}),
  \bibinfo{pages}{102685}.
\newblock
\showISSN{0306-4573}


\bibitem[{Edwards III}(2011)]%
        {Edwards2011why}
\bibfield{author}{\bibinfo{person}{{George C.} {Edwards III}}.}
  \bibinfo{year}{2011}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{Why the Electoral College is Bad for
  America (Second ed.).}}
\newblock \bibinfo{publisher}{New Haven and London: Yale University Press.}
\newblock


\bibitem[et~al.(2020)]%
        {cinelli2020info}
\bibfield{author}{\bibinfo{person}{{Cinelli, M.} et al.}}
  \bibinfo{year}{2020}\natexlab{}.
\newblock \showarticletitle{The COVID-19 social media infodemic}.
\newblock \bibinfo{journal}{\emph{Scientific Reports}} (\bibinfo{year}{2020}).
\newblock


\bibitem[Ferrara et~al\mbox{.}(2020)]%
        {Ferrara2020characterizing}
\bibfield{author}{\bibinfo{person}{Emilio Ferrara}, \bibinfo{person}{Herbert
  Chang}, \bibinfo{person}{Emily Chen}, \bibinfo{person}{Goran Muric}, {and}
  \bibinfo{person}{Jaimin Patel}.} \bibinfo{year}{2020}\natexlab{}.
\newblock \showarticletitle{Characterizing social media manipulation in the
  2020 US presidential election}.
\newblock \bibinfo{journal}{\emph{First Monday}} (\bibinfo{year}{2020}).
\newblock


\bibitem[Ferrara et~al\mbox{.}(2016)]%
        {Ferrara2016rise}
\bibfield{author}{\bibinfo{person}{Emilio Ferrara}, \bibinfo{person}{Onur
  Varol}, \bibinfo{person}{Clayton Davis}, \bibinfo{person}{Filippo Menczer},
  {and} \bibinfo{person}{Alessandro Flammini}.}
  \bibinfo{year}{2016}\natexlab{}.
\newblock \showarticletitle{The Rise of Social Bots}.
\newblock \bibinfo{journal}{\emph{Commun. ACM}} \bibinfo{volume}{59},
  \bibinfo{number}{7} (\bibinfo{date}{June} \bibinfo{year}{2016}),
  \bibinfo{pages}{96--104}.
\newblock
\showISSN{0001-0782}


\bibitem[Garlaschelli and Loffredo(2008)]%
        {Garlaschelli2008}
\bibfield{author}{\bibinfo{person}{Diego Garlaschelli} {and}
  \bibinfo{person}{Maria~I. Loffredo}.} \bibinfo{year}{2008}\natexlab{}.
\newblock \showarticletitle{Maximum likelihood: Extracting unbiased information
  from complex networks}.
\newblock \bibinfo{journal}{\emph{Physical Review E}}  \bibinfo{volume}{78}
  (\bibinfo{year}{2008}), \bibinfo{pages}{1--5}.
\newblock
Issue 1.
\showISBNx{1539-3755}
\showISSN{15393755}
\urldef\tempurl%
\url{https://doi.org/10.1103/PhysRevE.78.015101}
\showDOI{\tempurl}


\bibitem[Georgacopoulos and Mores(2020)]%
        {Georgacopoulos2020how}
\bibfield{author}{\bibinfo{person}{Christina Georgacopoulos} {and}
  \bibinfo{person}{Grayce Mores}.} \bibinfo{year}{2020}\natexlab{}.
\newblock \showarticletitle{How Fake News Affected the 2016 Presidential
  Election}.
\newblock \bibinfo{journal}{\emph{faculty.lsu.edu -- White Paper}}
  (\bibinfo{year}{2020}).
\newblock


\bibitem[Giatsoglou et~al\mbox{.}(2015)]%
        {Giatsoglou2015}
\bibfield{author}{\bibinfo{person}{Maria Giatsoglou}, \bibinfo{person}{Despoina
  Chatzakou}, \bibinfo{person}{Neil Shah}, \bibinfo{person}{Alex Beutel},
  \bibinfo{person}{Christos Faloutsos}, {and} \bibinfo{person}{Athena Vakali}.}
  \bibinfo{year}{2015}\natexlab{}.
\newblock \showarticletitle{{ND-Sync}: Detecting Synchronized Fraud
  Activities}.
\newblock In \bibinfo{booktitle}{\emph{PAKDD}}. \bibinfo{publisher}{Springer}.
\newblock


\bibitem[Howard et~al\mbox{.}(2018)]%
        {howard2018social}
\bibfield{author}{\bibinfo{person}{Philip~N Howard}, \bibinfo{person}{Bence
  Kollanyi}, \bibinfo{person}{Samantha Bradshaw}, {and}
  \bibinfo{person}{Lisa-Maria Neudert}.} \bibinfo{year}{2018}\natexlab{}.
\newblock \showarticletitle{Social media, news and political information during
  the US election: Was polarizing content concentrated in swing states?}
\newblock \bibinfo{journal}{\emph{arXiv preprint arXiv:1802.03573}}
  (\bibinfo{year}{2018}).
\newblock


\bibitem[Hui et~al\mbox{.}(2020)]%
        {DBLP:conf/icwsm/HuiYTM20}
\bibfield{author}{\bibinfo{person}{Pik{-}Mai Hui}, \bibinfo{person}{Kai{-}Cheng
  Yang}, \bibinfo{person}{Christopher Torres{-}Lugo}, {and}
  \bibinfo{person}{Filippo Menczer}.} \bibinfo{year}{2020}\natexlab{}.
\newblock \showarticletitle{BotSlayer: {DIY} Real-Time Influence Campaign
  Detection}. In \bibinfo{booktitle}{\emph{Proceedings of the Fourteenth
  International {AAAI} Conference on Web and Social Media, {ICWSM}}}.
  \bibinfo{publisher}{{AAAI} Press}, \bibinfo{pages}{980--982}.
\newblock
\urldef\tempurl%
\url{https://aaai.org/ojs/index.php/ICWSM/article/view/7370}
\showURL{%
\tempurl}


\bibitem[Jaynes(1957)]%
        {Jaynes1957}
\bibfield{author}{\bibinfo{person}{E.T. Jaynes}.}
  \bibinfo{year}{1957}\natexlab{}.
\newblock \showarticletitle{{Information Theory and Statistical Mechanics}}.
\newblock \bibinfo{journal}{\emph{Physical Review}} \bibinfo{volume}{106},
  \bibinfo{number}{4} (\bibinfo{year}{1957}), \bibinfo{pages}{620--630}.
\newblock
\showISBNx{1536-6065}
\showISSN{0031-899X}


\bibitem[Jiang et~al\mbox{.}(2016)]%
        {jiang2016}
\bibfield{author}{\bibinfo{person}{M. Jiang}, \bibinfo{person}{P. Cui}, {and}
  \bibinfo{person}{C. Faloutsos}.} \bibinfo{year}{2016}\natexlab{}.
\newblock \showarticletitle{Suspicious Behavior Detection: Current Trends and
  Future Directions}.
\newblock \bibinfo{journal}{\emph{IEEE Intelligent Systems}}
  \bibinfo{volume}{31}, \bibinfo{number}{1} (\bibinfo{year}{2016}),
  \bibinfo{pages}{31--39}.
\newblock


\bibitem[Luceri et~al\mbox{.}(2019a)]%
        {Luceri19red}
\bibfield{author}{\bibinfo{person}{Luca Luceri}, \bibinfo{person}{Ashok Deb},
  \bibinfo{person}{Adam Badawy}, {and} \bibinfo{person}{Emilio Ferrara}.}
  \bibinfo{year}{2019}\natexlab{a}.
\newblock \showarticletitle{Red Bots Do It Better: Comparative Analysis of
  Social Bot Partisan Behavior}. In \bibinfo{booktitle}{\emph{Companion
  Proceedings of The 2019 World Wide Web Conference}} (San Francisco, USA)
  \emph{(\bibinfo{series}{WWW '19})}. \bibinfo{publisher}{ACM},
  \bibinfo{pages}{1007–1012}.
\newblock
\showISBNx{9781450366755}
\urldef\tempurl%
\url{https://doi.org/10.1145/3308560.3316735}
\showDOI{\tempurl}


\bibitem[Luceri et~al\mbox{.}(2019b)]%
        {luceri2019evolution}
\bibfield{author}{\bibinfo{person}{Luca Luceri}, \bibinfo{person}{Ashok Deb},
  \bibinfo{person}{Silvia Giordano}, {and} \bibinfo{person}{Emilio Ferrara}.}
  \bibinfo{year}{2019}\natexlab{b}.
\newblock \showarticletitle{Evolution of bot and human behavior during
  elections}.
\newblock \bibinfo{journal}{\emph{First Monday}} (\bibinfo{year}{2019}).
\newblock


\bibitem[Mattei et~al\mbox{.}(2022)]%
        {mattei2022bowtie}
\bibfield{author}{\bibinfo{person}{M Mattei} {et~al\mbox{.}}}
  \bibinfo{year}{2022}\natexlab{}.
\newblock \showarticletitle{Bow-tie structures of Twitter discursive
  communities}.
\newblock \bibinfo{journal}{\emph{Scientific Reports}}  \bibinfo{volume}{12}
  (\bibinfo{year}{2022}).
\newblock


\bibitem[Mustafaraj and Metaxas(2010)]%
        {mustarafi10}
\bibfield{author}{\bibinfo{person}{Eni Mustafaraj} {and}
  \bibinfo{person}{P.~Takis Metaxas}.} \bibinfo{year}{2010}\natexlab{}.
\newblock \showarticletitle{From Obscurity to Prominence in Minutes: Political
  Speech and Real-Time Search}. In \bibinfo{booktitle}{\emph{Web Science:
  Extending the Frontiers of Society On-Line}}.
\newblock


\bibitem[Park and Newman(2004)]%
        {park2004statistical}
\bibfield{author}{\bibinfo{person}{Juyong Park} {and} \bibinfo{person}{Mark E~J
  Newman}.} \bibinfo{year}{2004}\natexlab{}.
\newblock \showarticletitle{{Statistical mechanics of networks}}.
\newblock \bibinfo{journal}{\emph{Phys. Rev. E}} \bibinfo{volume}{70},
  \bibinfo{number}{6} (\bibinfo{date}{dec} \bibinfo{year}{2004}),
  \bibinfo{pages}{66117}.
\newblock
\showISSN{1539-3755}
\urldef\tempurl%
\url{https://doi.org/10.1103/PhysRevE.70.066117}
\showDOI{\tempurl}


\bibitem[Pierri et~al\mbox{.}(2020)]%
        {pierri2020investigating}
\bibfield{author}{\bibinfo{person}{Francesco Pierri},
  \bibinfo{person}{Alessandro Artoni}, {and} \bibinfo{person}{Stefano Ceri}.}
  \bibinfo{year}{2020}\natexlab{}.
\newblock \showarticletitle{Investigating Italian disinformation spreading on
  Twitter in the context of 2019 European elections}.
\newblock \bibinfo{journal}{\emph{PloS one}} \bibinfo{volume}{15},
  \bibinfo{number}{1} (\bibinfo{year}{2020}), \bibinfo{pages}{e0227821}.
\newblock


\bibitem[Praet et~al\mbox{.}(2021)]%
        {Praet2021}
\bibfield{author}{\bibinfo{person}{Stiene Praet}, \bibinfo{person}{David
  Martens}, {and} \bibinfo{person}{Peter Van~Aelst}.}
  \bibinfo{year}{2021}\natexlab{}.
\newblock \showarticletitle{Patterns of democracy? Social network analysis of
  parliamentary {T}witter networks in 12 countries}.
\newblock \bibinfo{journal}{\emph{Online Social Networks and Media}}
  \bibinfo{volume}{24} (\bibinfo{year}{2021}).
\newblock
\urldef\tempurl%
\url{https://doi.org/10.1016/j.osnem.2021.100154}
\showDOI{\tempurl}


\bibitem[Radicioni et~al\mbox{.}(2021)]%
        {Radicioni2021a}
\bibfield{author}{\bibinfo{person}{Tommaso Radicioni}, \bibinfo{person}{Tiziano
  Squartini}, \bibinfo{person}{Elena Pavan}, {and} \bibinfo{person}{Fabio
  Saracco}.} \bibinfo{year}{2021}\natexlab{}.
\newblock \showarticletitle{Networked partisanship and framing: A
  socio-semantic network analysis of the Italian debate on migration}.
\newblock \bibinfo{journal}{\emph{PLOS ONE}}  \bibinfo{volume}{16}
  (\bibinfo{date}{3} \bibinfo{year}{2021}), \bibinfo{pages}{e0256705}.
\newblock
Issue 8.
\showISSN{1932-6203}
\urldef\tempurl%
\url{https://doi.org/10.1371/JOURNAL.PONE.0256705}
\showDOI{\tempurl}


\bibitem[Raghavan et~al\mbox{.}(2007)]%
        {Raghavan2007b}
\bibfield{author}{\bibinfo{person}{Usha~Nandini Raghavan},
  \bibinfo{person}{R{\'{e}}ka Albert}, {and} \bibinfo{person}{Soundar Kumara}.}
  \bibinfo{year}{2007}\natexlab{}.
\newblock \showarticletitle{{Near linear time algorithm to detect community
  structures in large-scale networks}}.
\newblock \bibinfo{journal}{\emph{Phys. Rev. E - Stat. Nonlinear, Soft Matter
  Phys.}} (\bibinfo{year}{2007}).
\newblock
\showISSN{15393755}
\urldef\tempurl%
\url{https://doi.org/10.1103/PhysRevE.76.036106}
\showDOI{\tempurl}


\bibitem[Saracco et~al\mbox{.}(2015)]%
        {Saracco2015}
\bibfield{author}{\bibinfo{person}{Fabio Saracco}, \bibinfo{person}{Riccardo
  {Di Clemente}}, \bibinfo{person}{Andrea Gabrielli}, {and}
  \bibinfo{person}{Tiziano Squartini}.} \bibinfo{year}{2015}\natexlab{}.
\newblock \showarticletitle{{Randomizing bipartite networks: the case of the
  World Trade Web}}.
\newblock \bibinfo{journal}{\emph{Sci. Rep.}} \bibinfo{volume}{5},
  \bibinfo{number}{1} (\bibinfo{date}{sep} \bibinfo{year}{2015}),
  \bibinfo{pages}{10595}.
\newblock
\showISSN{2045-2322}
\urldef\tempurl%
\url{https://doi.org/10.1038/srep10595}
\showDOI{\tempurl}


\bibitem[Saracco et~al\mbox{.}(2017)]%
        {Saracco2017}
\bibfield{author}{\bibinfo{person}{Fabio Saracco}, \bibinfo{person}{Mika~J.
  Straka}, \bibinfo{person}{Riccardo {Di Clemente}}, \bibinfo{person}{Andrea
  Gabrielli}, \bibinfo{person}{Guido Caldarelli}, {and}
  \bibinfo{person}{Tiziano Squartini}.} \bibinfo{year}{2017}\natexlab{}.
\newblock \showarticletitle{{Inferring monopartite projections of bipartite
  networks: An entropy-based approach}}.
\newblock \bibinfo{journal}{\emph{New J. Phys.}} (\bibinfo{year}{2017}).
\newblock
\showISSN{13672630}
\urldef\tempurl%
\url{https://doi.org/10.1088/1367-2630/aa6b38}
\showDOI{\tempurl}
\showeprint[arxiv]{1607.02481}


\bibitem[Sayyadiharikandeh et~al\mbox{.}(2020)]%
        {DBLP:conf/cikm/Sayyadiharikandeh20}
\bibfield{author}{\bibinfo{person}{Mohsen Sayyadiharikandeh} {et~al\mbox{.}}}
  \bibinfo{year}{2020}\natexlab{}.
\newblock \showarticletitle{Detection of Novel Social Bots by Ensembles of
  Specialized Classifiers}. In \bibinfo{booktitle}{\emph{{CIKM} '20: The 29th
  {ACM} International Conference on Information and Knowledge Management}}.
  \bibinfo{publisher}{{ACM}}, \bibinfo{pages}{2725--2732}.
\newblock


\bibitem[Shao et~al\mbox{.}(2018)]%
        {shao2018anatomy}
\bibfield{author}{\bibinfo{person}{Chengcheng Shao}, \bibinfo{person}{Pik-Mai
  Hui}, \bibinfo{person}{Lei Wang}, \bibinfo{person}{Xinwen Jiang},
  \bibinfo{person}{Alessandro Flammini}, \bibinfo{person}{Filippo Menczer},
  {and} \bibinfo{person}{Giovanni~Luca Ciampaglia}.}
  \bibinfo{year}{2018}\natexlab{}.
\newblock \showarticletitle{Anatomy of an online misinformation network}.
\newblock \bibinfo{journal}{\emph{Plos one}} \bibinfo{volume}{13},
  \bibinfo{number}{4} (\bibinfo{year}{2018}), \bibinfo{pages}{e0196087}.
\newblock


\bibitem[Sharma et~al\mbox{.}(2021)]%
        {sharma2020identifying}
\bibfield{author}{\bibinfo{person}{Karishma Sharma}, \bibinfo{person}{Yizhou
  Zhang}, \bibinfo{person}{Emilio Ferrara}, {and} \bibinfo{person}{Yan Liu}.}
  \bibinfo{year}{2021}\natexlab{}.
\newblock \showarticletitle{Identifying Coordinated Accounts on Social Media
  through Hidden Influence and Group Behaviours}. In
  \bibinfo{booktitle}{\emph{SIGKDD Conference on Knowledge Discovery and Data
  Mining}} \emph{(\bibinfo{series}{KDD '21})}. \bibinfo{publisher}{Association
  for Computing Machinery}, \bibinfo{pages}{1441–1451}.
\newblock


\bibitem[Squartini and Garlaschelli(2011)]%
        {Squartini2011a}
\bibfield{author}{\bibinfo{person}{Tiziano Squartini} {and}
  \bibinfo{person}{Diego Garlaschelli}.} \bibinfo{year}{2011}\natexlab{}.
\newblock \showarticletitle{Analytical maximum-likelihood method to detect
  patterns in real networks}.
\newblock \bibinfo{journal}{\emph{New Journal of Physics}}
  \bibinfo{volume}{13} (\bibinfo{year}{2011}), \bibinfo{pages}{083001}.
\newblock
\showISBNx{1367-2630}
\showISSN{13672630}
\urldef\tempurl%
\url{https://doi.org/10.1088/1367-2630/13/8/083001}
\showDOI{\tempurl}


\bibitem[Strauss(2022)]%
        {Strauss22war}
\bibfield{author}{\bibinfo{person}{{Barry S.} Strauss}.}
  \bibinfo{year}{2022}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{The War That Made the Roman Empire: Antony,
  Cleopatra, and Octavian at Actium}}.
\newblock \bibinfo{publisher}{Simon Schuster}.
\newblock


\bibitem[Urman(2020)]%
        {Urman2020}
\bibfield{author}{\bibinfo{person}{Aleksandra Urman}.}
  \bibinfo{year}{2020}\natexlab{}.
\newblock \showarticletitle{Context matters: political polarization on Twitter
  from a comparative perspective}.
\newblock \bibinfo{journal}{\emph{Media, Culture \& Society}}
  \bibinfo{volume}{42}, \bibinfo{number}{6} (\bibinfo{year}{2020}),
  \bibinfo{pages}{857--879}.
\newblock
\urldef\tempurl%
\url{https://doi.org/10.1177/0163443719876541}
\showDOI{\tempurl}
\showeprint{https://doi.org/10.1177/0163443719876541}


\bibitem[Van~Vliet et~al\mbox{.}(2021)]%
        {VanVliet2021}
\bibfield{author}{\bibinfo{person}{Livia Van~Vliet}, \bibinfo{person}{Petter
  Törnberg}, {and} \bibinfo{person}{Justus Uitermark}.}
  \bibinfo{year}{2021}\natexlab{}.
\newblock \showarticletitle{Political Systems and Political Networks: The
  Structure of Parliamentarians’ Retweet Networks in 19 Countries}.
\newblock \bibinfo{journal}{\emph{International Journal of Communication}}
  \bibinfo{volume}{15} (\bibinfo{year}{2021}), \bibinfo{pages}{2156 – 2176}.
\newblock


\bibitem[Varol et~al\mbox{.}(2017)]%
        {Varol2017}
\bibfield{author}{\bibinfo{person}{Onur Varol}, \bibinfo{person}{Emilio
  Ferrara}, \bibinfo{person}{Clayton~A. Davis}, \bibinfo{person}{Filippo
  Menczer}, {and} \bibinfo{person}{Alessandro Flammini}.}
  \bibinfo{year}{2017}\natexlab{}.
\newblock \showarticletitle{Online Human-Bot Interactions: Detection,
  Estimation, and Characterization}. In \bibinfo{booktitle}{\emph{Proceedings
  of the Eleventh International Conference on Web and Social Media, {ICWSM}
  2017, Montr{\'{e}}al, Qu{\'{e}}bec, Canada, May 15-18, 2017.}}
  \bibinfo{pages}{280--289}.
\newblock
\urldef\tempurl%
\url{https://aaai.org/ocs/index.php/ICWSM/ICWSM17/paper/view/15587}
\showURL{%
\tempurl}


\bibitem[Viswanath et~al\mbox{.}(2015)]%
        {viswanath2015}
\bibfield{author}{\bibinfo{person}{Bimal Viswanath} {et~al\mbox{.}}}
  \bibinfo{year}{2015}\natexlab{}.
\newblock \showarticletitle{Strength in Numbers: Robust Tamper Detection in
  Crowd Computations}. In \bibinfo{booktitle}{\emph{Proceedings of the 2015 ACM
  on Conference on Online Social Networks}}. ACM, \bibinfo{pages}{113--124}.
\newblock


\bibitem[Yang et~al\mbox{.}(2019)]%
        {FerraraArming2019}
\bibfield{author}{\bibinfo{person}{Kai{-}Cheng Yang}, \bibinfo{person}{Onur
  Varol}, \bibinfo{person}{Clayton~A. Davis}, \bibinfo{person}{Emilio Ferrara},
  \bibinfo{person}{Alessandro Flammini}, {and} \bibinfo{person}{Filippo
  Menczer}.} \bibinfo{year}{2019}\natexlab{}.
\newblock \showarticletitle{Arming the public with {AI} to counter social
  bots}.
\newblock \bibinfo{journal}{\emph{CoRR}}  \bibinfo{volume}{abs/1901.00912}
  (\bibinfo{year}{2019}).
\newblock
\urldef\tempurl%
\url{http://arxiv.org/abs/1901.00912}
\showURL{%
\tempurl}


\bibitem[Yang et~al\mbox{.}(2020)]%
        {DBLP:conf/aaai/YangVHM20}
\bibfield{author}{\bibinfo{person}{Kai{-}Cheng Yang}, \bibinfo{person}{Onur
  Varol}, \bibinfo{person}{Pik{-}Mai Hui}, {and} \bibinfo{person}{Filippo
  Menczer}.} \bibinfo{year}{2020}\natexlab{}.
\newblock \showarticletitle{Scalable and Generalizable Social Bot Detection
  through Data Selection}. In \bibinfo{booktitle}{\emph{The Thirty-Fourth
  {AAAI} Conference on Artificial Intelligence}}. \bibinfo{publisher}{{AAAI}
  Press}, \bibinfo{pages}{1096--1103}.
\newblock


\bibitem[Yardi et~al\mbox{.}(2010)]%
        {YardiRSB10}
\bibfield{author}{\bibinfo{person}{Sarita Yardi}, \bibinfo{person}{Daniel~M.
  Romero}, \bibinfo{person}{Grant Schoenebeck}, {and} \bibinfo{person}{Danah
  Boyd}.} \bibinfo{year}{2010}\natexlab{}.
\newblock \showarticletitle{Detecting Spam in a Twitter Network}.
\newblock \bibinfo{journal}{\emph{First Monday}} \bibinfo{volume}{15},
  \bibinfo{number}{1} (\bibinfo{year}{2010}).
\newblock


\bibitem[Yu et~al\mbox{.}(2015)]%
        {yu2015}
\bibfield{author}{\bibinfo{person}{Rose Yu}, \bibinfo{person}{Xinran He}, {and}
  \bibinfo{person}{Yan Liu}.} \bibinfo{year}{2015}\natexlab{}.
\newblock \showarticletitle{{GLAD}: Group Anomaly Detection in Social Media
  Analysis}.
\newblock \bibinfo{journal}{\emph{ACM Transactions on Knowledge Discovery from
  Data (TKDD)}} \bibinfo{volume}{10}, \bibinfo{number}{2}
  (\bibinfo{year}{2015}), \bibinfo{pages}{1--22}.
\newblock


\end{thebibliography}


%%
%% If your work has an appendix, this is the place to put it.
\appendix
% \section{Data}
% Table~\ref{tab:keywords} gives the list of keywords that drove our data collection. 
% \begin{table}[ht!]
% \caption{Keywords which drove the data collection phase  
% \label{tab:keywords}}

% \begin{tabular}{l}
% Keywords\\
% \hline
% \hline
% arizona biden\\
% arizona trump\\
% florida biden\\
% florida trump\\
% michigan biden\\
% michigan trump\\
% pennsylvania biden\\
% pennsylvania trump\\
% new jersey biden\\
% new jersey trump\\
% indiana biden\\
% indiana trump\\
% washington biden\\
% washington trump\\
% louisiana biden\\
% louisiana trump\\
% \hline
% \end{tabular}
% \end{table}


%\section{Methods}
%\section{Tags for domain reputation}

% \subsection{Entropy-based null-models for complex network analysis}
% Here, we provide the sketch of the definition of the entropy-based null-models and  their implementation for detecting discursive communities on the retweet network. For more details on the entropy-based techniques for complex networks, we forward the interested reader to the review in~\cite{Cimini2018a} and to the references therein.

% \subsubsection{Entropy-based null-models}
% Our aim is defining a benchmark for the analysis of a real network $G^*$ that 
% is maximally random, but for a set of topological constraints $\vec{C}$ observed on $G^*$.

% Thus, we define an \emph{ensemble} of graphs $\mathcal{G}$, i.e., the set of all possible graph configurations, from the empty graph to the fully connected one, all having the same number of nodes as in the real network. Then, we can assign a probability to every representative of the ensemble by maximising the relative Shannon entropy, i.e.,
% \begin{equation*}
%     S=-\sum_{G\in\mathcal{G}}P(G)\ln P(G),
% \end{equation*}
% under the constraint that the average over the ensemble of the vector $\vec{C}$ is exactly the value observed in the real network $G^*$, i.e., $\langle \vec{C}\rangle_\mathcal{G}=\vec{C}(G^*)$.
% The result of this procedure returns in an Exponential Random Graph, i.e. $P(G)\sim e^{-\vec{C}(G)\cdot\vec{\theta}}$, where $\vec{\theta}$ are the Lagrangian multipliers associated to the constrained maximisation~\cite{Jaynes1957,park2004statistical}. The maximisation of the likelihood, i.e., the probability of observing the real system, is then implemented to find the numerical values of $\vec{\theta}$~\cite{Garlaschelli2008,Squartini2011a}.

% \subsubsection{Discursive communities, Bipartite Configuration Model and Validated projections}\label{sssec:DisCo}
% The conceptual procedure described above can be applied for the practical detection of communities of users interacting among themselves via retweets, or \emph{discursive communities}~\cite{Becatti2019d,caldarelli2020role,Radicioni2021a}. The first observation is that most of the online debate is led by verified users,  i.e., accounts whose owners are certified by the platform itself. It is possible, therefore, to leverage this information to obtain proper discursive communities~\cite{Becatti2019d}: the intuition is that verified users with similar opinions in an online debate should have the same audience of `standard' users. Therefore we represent the retweet interactions between verified and unverified users as a bipartite network, i.e., networks in which nodes are divided in two sets, $\top$ and $\bot$ -called \emph{layers}- and connections are allowed only between layers; verified and unverified users are then represented by the two layers.

% We then project the bipartite network on the layer of verified users. Nevertheless, the projection only does not tell us so much: In fact, the common retweeters of two verified users could be many due to popularity of the latter or because the retweeters are retweeting many verified users.  We therefore need a benchmark that is maximally random and able to discount the effect of these two ingredients, which, in terms of the bipartite network defined above, are translated into the degree sequence of both layers. The entropy-based null-model for bipartite network discounting the information of the degree sequence is known as \emph{Bipartite Configuration Model} (BiCM,~\cite{Saracco2015}). 
% Using the BiCM as a benchmark, it is possible to validate the projection of the bipartite network on one of its layer: the co-occurrences observed in the real system are compared with the related BiCM distributions and, if they are statistically significant, they are validated~\cite{Saracco2017}. Therefore, the result of the validation procedure is a monopartite undirected unweighted network of verified users, in which two nodes are connected if the number of common retweeters is statistically significant, i.e., {\it it cannot be explain simply by the bipartite degree sequence.}

% We subsequently run the Louvain community detection algorithm~\cite{Blondel2008} on the validated network: the so-obtained labels are then propagated on the retweet network using the Raghavanan et al. algorithm~\cite{Raghavan2007b}, in order to provide all users a discursive community label. Several works, like~\cite{Becatti2019d,caldarelli2020role,Radicioni2021a,DeClerck2022a,DeClerck2022b} show that the procedure above is particularly effective in capturing the structure of Twitter online debate.

% \subsection{How we measure a news' domain reputation}
% All the domains in our Twitter dataset have been tagged according to their degree of credibility and transparency,  as indicated by the browser extension and mobile app NewsGuard\footnote{\url{https://www.newsguardtech.com/}}. 
% The NewsGuard initiative was born from the joint effort of journalists and software developers, aiming at evaluating news sites according to  criteria concerning credibility and transparency. For evaluating the credibility level, the metrics consider, e.g., whether the news source regularly publishes false news, does not distinguish between facts and opinions, does not correct a wrongly reported news. For transparency, instead, the toolkit takes into account, e.g., whether owners, founders or authors of the news source are publicly known, and whether advertisements are easily recognizable\footnote{Details on the procedure for the  evaluation  are available at: \url{https://www.newsguardtech.com/ratings/rating-process-criteria/}.}

% % Here, we report a series of analyses related to the domains that mostly appear in the tweets of the validated network of verified users. 


% We clarify that a domain, for us, corresponds to the so-called `second-level domain' name\footnote{\url{https://en.wikipedia.org/wiki/Domain_name}}, i.e., the name directly to the left of .com, .net, and any other top-level domains. For instance,  \url{nytimes.com} and \url{latimes.com} are considered as domains in the present manuscript.


% As a first step, we considered the network of verified accounts, whose communities and subcommunities have been shown
% in Figure~\ref{fig:subcomm_netwk}. On this topology, we labelled all domains that had been shared at least 20 times in tweets and retweets. 

% TABELLA TAGs SPOSTATA per WORKSHOP
%\subsection{Tags for domain reputation labeling}
%\begin{table}[ht!]
%\caption{Tags for domain reputation labeling. Tags are inherited from NewsGuard, the UNC tag indicates that NewsGuard has not yet tagged that domain. %(UNC = Unclassified)  
%\label{table:domains-tags}}
%\centering
%\begin{tabular}{c|l}
%label & \text{description}\\
%\hline
%\hline
%T & Trustworthy news domain\\
%%$\sim\text{R}$ & Quasi Reputable news source\\
%N & Non-trustworthy news domain\\
%P & Platform (e.g., reddit.com, twitter.com)\\
%S & Satire\\
%UNC & unclassified\\
%\hline
%\end{tabular}

%\smallskip

%\end{table}

%Table~\ref{table:domains-tags} shows the tags associated to the domains. In the main text, we are interested in quantifying reputation of news domains publishing during the period of interest. 
%Thus, we do not consider those sources corresponding to platforms (tag P). Also, we will not consider satiric news (tag S). 
% \fasa{; nevertheless, the information regarding their frequency are available for the interested readers in the Supplementary Material.} 
%Tags T and N in Table~\ref{table:domains-tags} are used only for news sites, be them newspapers, magazines, TV or radio social channels, and they stand for Trustworthy and Non-trustworthy, respectively. 


 





% \subsection{Part One}



% \subsection{Part Two}



\section{Online Resources}
The Twitter datasets used and analysed in the current study are here: \url{https://doi.org/10.7910/DVN/ANBPTC}. The data about the reliability of the various news sources -that support the findings of this study-  comes from NewGguard, but restrictions to their availability apply, since they were used under a NewsGuard license and they are not publicly available. These data could be however available upon reasonable request and with permission of Newsguard.


\end{document}
\endinput
%%
%% End of file `sample-authordraft.tex'.
