\subsection{Ablation Study}\label{sec:ablation}

In the ablation study conducted on CIFAR-100~\cite{krizhevsky2009learning} under the IDN settings~\cite{xia2020part} with a noise rate of \(0.5\), we present the performance of several clustering methods in~\cref{tab:ablation_cifar}, including K-means~\cite{ikotun2022k} and GMM~\cite{reynolds2009gaussian}. The performance of GMM~\cite{reynolds2009gaussian} appears to be relatively low, which could be attributed to issues related to overfitting and poor generalisation~\cite{cao2021risk}. Similarly, K-Means~\cite{ikotun2022k} does not lead to a significant improvement in results due to similar issues (as GMM) or measurement error~\cite{du2015robust}. We contend that Otsu's thresholding~\cite{otsu1979threshold} yields better results than GMM and K-Means. It is worth noting that using GMM~\cite{reynolds2009gaussian} and K-Means~\cite{ikotun2022k} offer improvements of approximately \(4\%\) accuracy w.r.t. the baseline method, DivideMix~\cite{li2020dividemix}. Nevertheless, using these clustering techniques can still restrict classification accuracy. Nevertheless
Otsu's thresholding~\cite{otsu1979threshold} enables a further improvement in accuracy of approximately \(10\%\). Moreover, we also ran DivideMix~\cite{li2020dividemix} with three classifiers (DivideMix-3C) using the aforementioned ablation noise settings with results  in~\cref{tab:ablation_cifar}, which shows an improvement of \(2\%\), compared with \(2\) classifiers, but still with a \(12\%\) gap with the use of PASS, demonstrating that our improvement cannot be explained solely by the use of \(3\) classifiers.~\cref{table:computation} specifies the training time of all baseline models as well as the baseline models incorporating PASS.
\begin{table}[htbp!]
        \centering
        \caption{This ablation study shows the test accuracy \(\%\) on CIFAR-100~\cite{krizhevsky2009learning} under IDN~\cite{xia2020part} at noise rate of \(0.5\). We show the result of our method using various clustering algorithms (Gaussian Mixture Model (GMM)~\cite{reynolds2009gaussian}, K-Means~\cite{ikotun2022k}, and  Otsu's thresholding~\cite{otsu1979threshold}) under the DivideMix~\cite{li2020dividemix} baseline. Moreover we also show the results of DivideMix~\cite{li2020dividemix} with three classifiers, namely the DivideMix-3C.
        }
        \label{tab:ablation_cifar}
        % \resizebox{0.4\textwidth}{!} {
        \begin{tabular}{l c}
            \toprule
            \bfseries DivideMix-PASS &  \bfseries Test Accuracy (\%) \\
            \midrule
            \textit{GMM} & 60.02 \\
            \textit{K-Means} & 62.56 \\
            \rowcolor{Gray!25} \textbf{\textit{OTSU}} & \textbf{72.27} \\
            \midrule
            \multicolumn{2}{l}{\bfseries With three classifiers in base model (no PASS)}\\
            \midrule
            DivideMix-3C~\cite{li2020dividemix} & 61.08\\
            \bottomrule
        \end{tabular}
\end{table}



\begingroup
\setlength{\tabcolsep}{4pt}
\begin{table}[htbp!]
        \caption{This table displays the training time of the base models, and base models with \textbf{PASS} (ours), measured in hours.}
        \label{table:computation}
        \centering
        \small
        \resizebox{0.4\textwidth}{!} 
        {
        \begin{tabular}{l c |c| c }
        \toprule
        \multirow{2}{*}{\bfseries Models} & \multirow{2}{*}{\textbf{Dataset}} & \multicolumn{2}{c}{\bfseries Time}  \\ 
        \cmidrule(lr){3-4} 
        & & \textbf{Base} & \textbf{PASS}  \\
        \midrule
        DivideMix~\cite{li2020dividemix} & CIFAR-100  & 6.4 & 9.8 \\
        InstanceGM~\cite{yao2021instance} & CIFAR-100 & 31.2 & 34\\
        SSR~\cite{feng2021ssr} & Animal-10N & 6.5 & 9.8\\
        FaMUS~\cite{xu2021faster} & Red Mini-Imagenet & 12.01 & 14.2 \\
        AugDesc~\cite{nishi2021augmentation} & Clothing1M & 29.6 & 30.1\\
        C2D~\cite{zheltonozhskii2022contrast} & Mini-Webvision & 42.2 & 44.1\\
        \bottomrule
        \end{tabular}}
\end{table} 
\endgroup

