\section{Introduction}
\label{sec:introduction}



In deep neural networks (DNNs) and machine learning, it is commonly recognized that having an adequate amount of labeled training data and computational resources leads to exceptional outcomes in various fields, such as computer vision~\cite{chen2022label}, natural language processing~\cite{trummer2022bert}, and in medical domain~\cite{kollias2023ai}. 
Nonetheless, the aforementioned outcomes have predominantly been attained through the utilization of meticulously curated datasets possessing labels of exceptional quality. The collection of such high-caliber labels, particularly for large datasets, can prove to be exorbitantly costly in real-world scenarios~\cite{song2022learning, litjens2017survey, yao2020dual}. Therefore, alternative cheaper labeling methods, including crowd-sourcing~\cite{song2022learning} and meta-data mining~\cite{feng2021ssr}, have gained traction, but they result in substandard labeling~\cite{gouleakis2018certified}. While these techniques aid in cost reduction and expedite the labeling process, they are susceptible to data mislabeling~\cite{rashtchian2010collecting}.
\begin{figure*}[t]
    \centering
    \includegraphics[scale = 0.8, keepaspectratio]{images/motivation-v13.pdf}
    \caption{Illustration of the comparison between various sample selection strategies, including small-loss~\cite{han2018co}, feature-based techniques~\cite{kim2021fine}, and our proposed \textbf{PASS}. 
    In small-loss~\cite{han2018co} we typically have two networks A \& B,
    with each model using the loss values of the samples to select
    clean and noisy instances, which are exchanged between the two networks for training them.
    FINE~\cite{kim2021fine} utilizes a feature-based selection approach based on the similarity to class specific eigenvectors in the representation space to select samples that are exchanged between two networks, A and B, for further training. Our \textbf{PASS} maintains three networks (A, B \& C), where the prediction agreements between two networks will select the clean samples to be used for training the third network. Note that during training, the two networks used for sample selection will rotate through the three available networks.
   }   
   % \gustavo{I find this figure a bit out of place because we're proposing a new sample selection mechanism. A think a better motivational figure would be one that compares small loss, feature-based and our feature selection.}\arpit{updated}}
    \label{fig:motivation}
\end{figure*}

Erroneous labels potentially degrade the performance of DNNs by inducing overfitting through the phenomenon of memorization~\cite{li2020dividemix, arpit2017closer, liu2020early, neyshabur2017exploring, zhang2021learning}. This issue has prompted the development of innovative learning algorithms aimed at tackling the problem of noisy labeling. 
Within the domain of noisy labels, many methods have emerged~\cite{li2020dividemix, Garg_2023_WACV}, each tailored to tackle the challenges posed by distinct settings of noise, namely instance-independent noise (IIN)~\cite{han2018co} and instance-dependent noise (IDN)~\cite{xia2020part}. Early studies in the field of noisy label operated under the presumption that label noise was IIN, that is, mislabeling occurred irrespective of the information regarding the visual classes present in images~\cite{han2018co}. In IIN, a transition matrix is generally employed, which comprises a pre-determined probability of flipping between pairs of labels~\cite{yao2020dual}. Nevertheless, recent studies have progressively redirected the field's attention toward the more realistic scenario of IDN~\cite{yao2021instance, cheng2022instance, Garg_2023_WACV}, where label noise depends on both the true class label and the image information.

Previous techniques for mitigating the impact of noisy label samples frequently involve the manual selection of clean samples to form a clean validation set~\cite{ren2018learning}. 
% \cuong{I don't quite understand the point here. The cited paper is about using a clean validation set to address the noisy labels, isn't it?}. 
The difficulty in obtaining clean validation samples~\cite{ipeirotis2010quality}, particularly for problems with many classes, motivated recent studies to leverage semi-supervised learning methods without relying on clean validation sets~\cite{li2020dividemix, cordeiro2021propmix}. 
% \cuong{Here, I don't see the contrary between semi-supervised learning and previous approach. Properly, we should say that these methods do not rely on clean validation set and employ semi-supervision to...}. 
Other approaches incorporate robust loss functions~\cite{olmin2022robustness}, designed specifically to operate effectively with either clean or noisy labels, as well as probabilistic modeling approaches that model the data generation process~\cite{yao2021instance, Garg_2023_WACV}. Furthermore, training regularization~\cite{liu2020early, wei2020combating} imposes a penalty term on the loss function during training, thereby reducing overfitting and ameliorating generalization. Various techniques integrate sample selection strategies as a key algorithmic step~\cite{Garg_2023_WACV, li2020dividemix, cordeiro2021propmix, cordeiro2023longremix}, allowing for the identification and segregation of noisy and clean labels. 
% \cuong{I do not understand this sentence}
One popular criterion for this sample selection process is the loss value between the prediction of the trained classifier and its label, whereby it is typically assumed that the noisy data exhibits a large loss~\cite{jiang2018mentornet, han2018co, wei2020combating, kim2021fine} or greater magnitude of the gradient during training~\cite{wang2019symmetric}. 
%\gustavo{Please also talk about feature-based methods}
Additionally, feature-based sample selection techniques based on the similarity to principal components of feature representations~\cite{kim2021fine} or K nearest neighbor (KNN) classification in the feature space~\cite{feng2021ssr} have also been considered for sample selection criteria.
%such as FINE~\cite{kim2021fine}, provide a theoretical framework of sampling using 
%principal components of latent representations, and SSR~\cite{feng2021ssr}, which employs feature representations to distinguish between clean data and noisy samples using a non-parametric KNN classifier.
Nonetheless, we empirically note that separating clean, but hard to classify samples from noisy label samples still remains challenging for these sample selection processes~\cite{wei2020combating}, particularly for problems of large noise rates. 
The use of peer classifiers for  noisy label learning problems have been investigated for enforcing  consistency in the training of the classifiers~\cite{malach2017decoupling,han2018co}, but not for selecting clean and noisy label samples. 
We argue in this paper that the prediction agreement between peer classifiers is more effective to select clean and noisy label samples than previous approaches because intuitively, such agreement is unlikely to happen, except when the classifiers agree on the clean label.

%the domain of sample selection techniques, without resorting to a clean validation set, remains under-explored~\cite{song2022learning}. Such sampling strategies have the potential to enhance the efficacy of noisy label techniques, particularly in intricate scenarios where clean, but hard to classify samples and noisy label samples are intertwined~\cite{wei2020combating}. 


% Other featur-based sample selection techniques include FINE~\cite{kim2021fine} which provides a theoretical framework related to the principal components of latent representations, and SSR~\cite{feng2021ssr}, that employs feature representations to separate clean data and noisy samples based on non-parametric KNN classifier. Notwithstanding, the results obtained from these methods are still adjudged as unsatisfactory.
% \cuong{I feel that this paragraph is too lengthy and lose its focus. I think we should concentrate on specifying that we study methods without clean samples and small loss, then mention its weaknesses. Those motivates our proposed method. Other sample selection approaches should be left at the related work. The reason is that we are listing many techniques, but do not really say the reason why we should do something different. The last sentence is quite vague, to me.}

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.5\linewidth]{iccv2023AuthorKit/images/motivation.pdf}
%     \caption{An illustration depicting the problem setting is presented herein. The clean samples, denoted by an orange shade, , while the noisy samples, represented by a purple shade. The red dots signify the false sampling cases, which are of interest to us. Our objective is to propose a novel approach to sample selection that would decrease the occurrence of these false cases. \cuong{I do not understand the point of this figure. It might mislead reviewers think that we could separate clean vs noisy in the overlapped zone. They might expect that we demonstrate something about it, while our method does not have anything to do with it. I suggest to remove this figure to reduce confusion.}}
%     \label{fig:motivation}
% \end{figure}

% In this paper, we propose a new sample selection technique to find noisy label samples, which can be readily integrated into existing noise-label learning models. 
% Our method is the peer-agreement sample selection (PASS), wherein peers of classifiers are utilized for selecting reliable (clean) and unreliable (noisy) samples during classifier training. 
% The peer-agreement is based on the sample posterior probability agreement between classifiers~\cite{artstein2008inter}, calculated  with cosine similarity. 
% Then, the sample selection relies on the global thresholding algorithm~\cite{Otsu1979threshold} to automatically determining the optimal threshold, that evaluates how well training samples can be selected into reliable (i.e., clean) or unreliable (i.e., noisy label). 
% %To assimilate our method for clustering, we require a measure of similarity or dissimilarity between samples. 
% %This measure can be based on any number of features, such as the sample's source reliability or the accuracy of the data it provides. 
% Given the need for a sample selection step, our approach can be readily adapted to multiple existing models, including DivideMix~\cite{li2020dividemix}, InstanceGM~\cite{Garg_2023_WACV}, SSR~\cite{feng2021ssr}, FaMUS~\cite{xu2021faster}, AugDesc~\cite{nishi2021augmentation}, and Contrast-to-Divide (C2D)~\cite{zheltonozhskii2022contrast} \cuong{When naming methods like these, please follow the chronological order}.

In this paper, we propose a new sample selection criterion based on the predictive probability agreement between peer classifiers, which has been shown in computational linguistics to be a sample reliability measure~\cite{artstein2008inter}.
%as an alternative to the small loss one to address the noisy label learning problem. 
%The main idea is to consider the agreement between peer classifiers as a criterion of sample cleanliness or reliability~\cite{artstein2008inter}
%samples with classification results agreed by peer classifiers to be reliable or most likely clean~\cite{artstein2008inter}. 
In light of implementation, we train three classifiers simultaneously by using the agreement between two classifiers to select samples to train the remaining classifier, as shown in~\cref{fig:motivation}.
%\rafa{This sentence it's not very clear to me -> } 
This sample selection relies on a thresholding algorithm~\cite{otsu1979threshold} that distinguishes samples based on how high the agreement between the peer classification predictions is. 
%We introduce a clustering algorithm strategy to pursue a global threshold tailored on the feature space during training~\cite{Otsu1979threshold}.
% \rafa{question: are you using a clustering (e.g. k-means) + Otsu -- or you are considering Otsu as a clustering algorithm?}\arpit{Otsu as clustering}
Our proposed method, named as \emph{peer-agreement based sample selection} (PASS), can readily be integrated into existing models in noisy label learning, such as InstanceGM~\cite{Garg_2023_WACV}, DivideMix~\cite{li2020dividemix}, SSR~\cite{feng2021ssr}, FaMUS~\cite{xu2021faster}, AugDesc~\cite{nishi2021augmentation}, and Contrast-to-Divide (C2D)~\cite{zheltonozhskii2022contrast}.
% \cuong{I would suggest to change the above as follows: We propose a new sample selection criterion based on the agreement of predictive probability between peer classifiers as an alternative to the small loss one to address the noisy label learning problem. The main idea is to consider samples with classification result agreed by peer classifiers to be reliable or most likely clean~\cite{artstein2008inter}. In light of implementation, we train three classifiers simultaneously by using the agreement between two classifiers to select samples to train the remaining classifier. In addition, we integrate a clustering algorithm, and in particular Otsu's global thresholding algorithm~\cite{Otsu1979threshold}, to automatically determine which samples are clean or noisy. Our proposed method, named as \emph{peer-agreement sample selection} (PASS), can readily be integrated into existing models in noisy label learning, such as....}
The primary contributions of our method can be delineated as follows: 
% \cuong{I believe that we have 2 contributions: agreement and Otsu. The remainings are the ones we must do. Overclaiming might result in a negative review.}
\begin{itemize}%[noitemsep,topsep=0pt]
\item We propose a new noisy label sample selection method, PASS, that differentiates clean and noisy label samples via the prediction agreement between peer classifiers. %s (other classifiers).
%\item Our method eliminates the need for a similarity threshold, or other hyper-parameters, for sample selection because we rely on a simple and computationally efficient global thresholding technique known as Otsu's method~\cite{Otsu1979threshold}.
% \item Furthermore, we validate through empirical analysis that our peer-agreement sample selection enables a better performance than the conventional small loss, establishing the superiority of our approach.
\item We demonstrate that our method can be easily adapted to existing models, including InstanceGM~\cite{Garg_2023_WACV}, DivideMix~\cite{li2020dividemix}, SSR~\cite{feng2021ssr}, FaMUS~\cite{xu2021faster}, AugDesc~\cite{nishi2021augmentation}, and C2D~\cite{zheltonozhskii2022contrast}, where we show that PASS enhances the performance of various SOTA approaches on various benchmarks, comprising both simulated and real-world datasets, such as CIFAR-100~\cite{krizhevsky2009learning}, CIFAR-N~\cite{wei2022learning}, Animal-10N~\cite{song2019selfie}, Red Mini-Imagenet from Controlled Noisy Web Labels (CNWL)~\cite{xu2021faster}, Clothing1M~\cite{xiao2015learning}, Mini-Webvision~\cite{li2017webvision}, and Imagenet~\cite{deng2009imagenet}.
\end{itemize}
It is imperative to provide clarity that our proposition does not entail the introduction of a new algorithm for the classification of noisy labels. Instead, we suggest a new method for selecting samples to substantially improve the efficacy of pre-existing noisy label learning algorithms, as shown by our experiments (\cref{sec:experiments}). 

% \gustavo{Add a motivation figure in page 1 to show how the new method works, in comparison with small loss and feature-based (e.g., FINE) methods.}~\arpit{updated}

%Moreover, we underscore that the potential implications of our proposed technique could be of immense consequence to the particular domain at hand.






