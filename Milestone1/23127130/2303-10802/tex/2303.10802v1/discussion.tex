\subsection{Discussion}
% \gustavo{This discussion is quite vague...}
Our proposed approach PASS has exhibited exceptional performance for noisy label classification. As~\cref{sec:experiments} shows, the integration of PASS into many SOTA noisy-label learning methods~\cite{Garg_2023_WACV, li2020dividemix, feng2021ssr, xu2021faster, nishi2021augmentation, zheltonozhskii2022contrast} 
% \gustavo{cite the methods we tried} 
has yielded noteworthy enhancements in their accuracy across multiple benchmarks~\cite{krizhevsky2009learning, wei2022learning, song2019selfie, xu2021faster, li2017webvision}, and has shown that our approach possesses remarkable adaptability to a diverse range of methods.
A limitation of PASS is the need for $3$ classifiers, which require $2\%$ to $50\%$ additional training time, as shown in~\cref{table:computation}.
Nevertheless, as shown in~\cref{tab:ablation_cifar}, PASS enables a \(12\%\) performance improvement over DivideMix-3C with $3$ classifiers, which justifies this increased need of resources.
%Additionally, using three classifiers increases the training time of the system. However, our results in~\cref{table:computation} show that the increase in training time is not significant. Therefore, we believe that the benefits of using two classifiers far outweigh the costs. Furthermore, 
We plan to work on techniques to reduce the training time with methods like dimensionality reduction~\cite{mackiewicz1993principal} or early stopping~\cite{liu2020early}. 
We have not identified any negative societal implications arising from our work. However, our proposed approach, PASS, has the potential to create positive societal impact by mitigating biases in resolving noisy labeled data.



% This study showcases that dependable classification results can be obtained despite operating in an untrustworthy environment with minimal assumptions . It does not necessitate a significant portion of classifiers to be reliable, nor does it presuppose that untrustworthy classifiers conform to a statistical model, as they may conspire to undermine the classification process. Furthermore, the study does not assume that the reliable classifier sampling mirrors the true sampling, but only approximate monotonicity. 
% % \rafa{This next sentence is what I meant in my comment in the Methodology section -> }Instead of relying on a "clean set" of data, the study employs a small number of reliable judgments obtained after classifiers provide their predictions on randomly chosen data, which could be sourced from expert classifiers or reputable networks. 
% Collectively, the findings of this study establish a solid groundwork for future research endeavors in the field of classification within untrustworthy environments. In addition, there exist several promising directions for future investigations, such as the implementation of crowdsourcing or active learning methodologies. Furthermore, the exploration of statistical methods to authenticate the dependability of classification models under unpredictable and demanding conditions warrants further investigation and is beyond the scope of our present work.

% \gustavo{reitarate that PASS is better than other sample selection methods.}

% \gustavo{The discussion should focus on the main issues of the approach, which in my opinion is the impact of adding a third classifier.  For instance, adding a third classifier is fair with other approaches?  If we had DivideMix with three classifiers, would we improve results?  Is the increased training time worth the performance improvement?  How can you decrease training time of the proposed method?}

% \gustavo{Is the agreed label the same as the training label?}

% \gustavo{Societal impact?}



