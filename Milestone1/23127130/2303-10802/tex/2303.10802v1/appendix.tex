\onecolumn
\appendix
\section*{Appendix}
\section{Empirical Analysis}\label{sec:appendix_empirical}
\subsection{Comparative Analysis of selecting samples}
\begin{figure}[h!]
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \begin{tikzpicture}
            \pgfplotstableread[col sep=comma, header=true]{supp_cifar0.4_csv/f1.tex} \myTable
            \begin{axis}[
                height = 0.6\linewidth,
                width = 0.8\linewidth,
                xlabel={\textnumero~of epochs},
                xlabel style={font=\footnotesize},
                xticklabel style = {font=\footnotesize},
                ylabel={F1-score},
                ylabel style={font=\footnotesize, yshift=-0.5em},
                yticklabel style = {font=\footnotesize},
                scale only axis
            ]
                \addplot[mark=none, MidnightBlue, thick, solid] table[x={epochs}, y={FINE}]{\myTable};
                \addplot[mark=none, BurntOrange, thick, densely dashed] table[x={epochs}, y={SmallLoss}]{\myTable};
                \addplot[mark=none, BrickRed, solid, thick, dashdotted] table[x={epochs}, y={PASS}]{\myTable};
            \end{axis}
        \end{tikzpicture}
        \caption{F1 Score}
        \label{fig:0.4_f1}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \begin{tikzpicture}
            \pgfplotstableread[col sep=comma, header=true]{supp_cifar0.4_csv/precision.tex} \myTable
            \begin{axis}[
                height = 0.6\linewidth,
                width = 0.8\linewidth,
                xlabel={\textnumero~of epochs},
                xlabel style={font=\footnotesize},
                xticklabel style = {font=\footnotesize},
                ylabel={Precision},
                ylabel style={font=\footnotesize, yshift=-0.5em},
                yticklabel style = {font=\footnotesize},
                scale only axis
            ]
                \addplot[mark=none, MidnightBlue, thick, solid] table[x={epochs}, y={FINE}]{\myTable};
                \addplot[mark=none, BurntOrange, thick, densely dashed] table[x={epochs}, y={SmallLoss}]{\myTable};
                \addplot[mark=none, BrickRed, solid, thick, dashdotted] table[x={epochs}, y={PASS}]{\myTable};
            \end{axis}
        \end{tikzpicture}
        \caption{Precision}
        \label{fig:0.4_precision}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \begin{tikzpicture}
            \pgfplotstableread[col sep=comma, header=true]{supp_cifar0.4_csv/clean.tex} \myTable

            \begin{axis}[
                height = 0.6\linewidth,
                width = 0.8\linewidth,
                xlabel={\textnumero~of epochs},
                xlabel style={font=\footnotesize},
                xticklabel style = {font=\footnotesize},
                ylabel={Ratio of clean data},
                ylabel style={font=\footnotesize, yshift=-0.5em},
                yticklabel style = {font=\footnotesize},
                legend entries={FINE, Small loss, PASS},
                legend style={draw=none, font=\scriptsize},
                legend image post style={scale=1.},
                legend cell align={left},
                legend pos=north east,
                scale only axis
            ]
                \addplot[mark=none, MidnightBlue, thick, solid] table[x={epochs}, y={FINE}]{\myTable};
                \addplot[mark=none, BurntOrange, thick, densely dashed] table[x={epochs}, y={SmallLoss}]{\myTable};
                \addplot[mark=none, BrickRed, solid, thick, dashdotted] table[x={epochs}, y={PASS}]{\myTable};

                % plot the ideal noise ratio
                \addplot[mark=none, style={densely dashed}] coordinates {
                    (50, 0.6)
                    (300, 0.6)
                };
                \node[below, color=Black, rotate=0, ] at (65, 0.6) {\scriptsize{ideal ratio}};
            \end{axis}
        \end{tikzpicture}
        \caption{Ratio of data classified as clean}
        \label{fig:0.4_clean}
    \end{subfigure}
    \caption{The figures presented above demonstrate a comparative analysis of the effectiveness of selecting clean or noisy samples, with reference to three metrics: \protect\subref{fig:0.4_f1}~F1-score, \subref{fig:0.4_precision}~precision, and \subref{fig:0.4_clean}~ratio of data classified as clean. The comparison is made between PASS (red) with small-loss approach~\cite{jiang2018mentornet} (yellow), FINE~\cite{kim2021fine} (blue) (all on base model DivideMix~\cite{li2020dividemix}), implemented on the CIFAR-100 dataset\cite{krizhevsky2009learning} at \(0.4\) IDN noise rate, as described in~\cite{xia2020part}.}
        \label{fig:supp_0.4}
\end{figure}
\begin{figure}[h!]
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \begin{tikzpicture}
            \pgfplotstableread[col sep=comma, header=true]{supp_cifar0.2_csv/f1.tex} \myTable
            \begin{axis}[
                height = 0.6\linewidth,
                width = 0.8\linewidth,
                xlabel={\textnumero~of epochs},
                xlabel style={font=\footnotesize},
                xticklabel style = {font=\footnotesize},
                ylabel={F1-score},
                ylabel style={font=\footnotesize, yshift=-0.5em},
                yticklabel style = {font=\footnotesize},
                scale only axis
            ]
                \addplot[mark=none, MidnightBlue, thick, solid] table[x={epochs}, y={FINE}]{\myTable};
                \addplot[mark=none, BurntOrange, thick, densely dashed] table[x={epochs}, y={SmallLoss}]{\myTable};
                \addplot[mark=none, BrickRed, solid, thick, dashdotted] table[x={epochs}, y={PASS}]{\myTable};
            \end{axis}
        \end{tikzpicture}
        \caption{F1 Score}
        \label{fig:0.2_f1}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \begin{tikzpicture}
            \pgfplotstableread[col sep=comma, header=true]{supp_cifar0.2_csv/precision.tex} \myTable
            \begin{axis}[
                height = 0.6\linewidth,
                width = 0.8\linewidth,
                xlabel={\textnumero~of epochs},
                xlabel style={font=\footnotesize},
                xticklabel style = {font=\footnotesize},
                ylabel={Precision},
                ylabel style={font=\footnotesize, yshift=-0.5em},
                yticklabel style = {font=\footnotesize},
                legend entries={FINE, Small loss, PASS},
                legend style={draw=none, font=\scriptsize},
                legend image post style={scale=1.},
                legend cell align={left},
                legend pos=south east,
                scale only axis
            ]
                \addplot[mark=none, MidnightBlue, thick, solid] table[x={epochs}, y={FINE}]{\myTable};
                \addplot[mark=none, BurntOrange, thick, densely dashed] table[x={epochs}, y={SmallLoss}]{\myTable};
                \addplot[mark=none, BrickRed, solid, thick, dashdotted] table[x={epochs}, y={PASS}]{\myTable};
            \end{axis}
        \end{tikzpicture}
        \caption{Precision}
        \label{fig:0.2_precision}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \begin{tikzpicture}
            \pgfplotstableread[col sep=comma, header=true]{supp_cifar0.2_csv/clean.tex} \myTable

            \begin{axis}[
                height = 0.6\linewidth,
                width = 0.8\linewidth,
                xlabel={\textnumero~of epochs},
                xlabel style={font=\footnotesize},
                xticklabel style = {font=\footnotesize},
                ylabel={Ratio of clean data},
                ylabel style={font=\footnotesize, yshift=-0.5em},
                yticklabel style = {font=\footnotesize},
                % legend entries={FINE, Small loss, PASS},
                % legend style={draw=none, font=\scriptsize},
                % legend image post style={scale=1.},
                % legend cell align={left},
                % legend pos=south east,
                scale only axis
            ]
                \addplot[mark=none, MidnightBlue, thick, solid] table[x={epochs}, y={FINE}]{\myTable};
                \addplot[mark=none, BurntOrange, thick, densely dashed] table[x={epochs}, y={SmallLoss}]{\myTable};
                \addplot[mark=none, BrickRed, solid, thick, dashdotted] table[x={epochs}, y={PASS}]{\myTable};

                % plot the ideal noise ratio
                \addplot[mark=none, style={densely dashed}] coordinates {
                    (50, 0.8)
                    (300, 0.8)
                };
                \node[above, color=Black, rotate=0, ] at (120, 0.8) {\scriptsize{ideal ratio}};
            \end{axis}
        \end{tikzpicture}
        \caption{Ratio of data classified as clean}
        \label{fig:0.2_clean}
    \end{subfigure}
    \caption{The figures presented above demonstrate a comparative analysis of the effectiveness of selecting clean or noisy samples, with reference to three metrics: \protect\subref{fig:0.2_f1}~F1-score, \subref{fig:0.2_precision}~precision, and \subref{fig:0.2_clean}~ratio of data classified as clean. The comparison is made between PASS (red) with small-loss approach~\cite{jiang2018mentornet} (yellow), FINE~\cite{kim2021fine} (blue) (all on base model DivideMix~\cite{li2020dividemix}), implemented on the CIFAR-100 dataset\cite{krizhevsky2009learning} at \(0.2\) IDN noise rate, as described in~\cite{xia2020part}.}
    \label{fig:supp_0.2}
\end{figure}

As discussed in~\cref{subsec:sample_selection}, we extended our empirical analysis to include other challenging IDN noise cases~\cite{xia2020part} at rates of $40\%$ and $20\%$, as shown in~\cref{fig:supp_0.4} and~\cref{fig:supp_0.2} on CIFAR-100~\cite{krizhevsky2009learning} respectively. \cref{fig:supp_0.4,fig:supp_0.2} display plots to measure the 
% \rafa{shouldn't be better agreement performance for our method, or selection performance for all the methods?}\gustavo{I think this is what is being shown here -- the clean sample selection performance by our agreement method, and other sample selection methods} 
classification performance of clean samples based on (a) F1 Score, (b) Precision, and (c) Ratio of data classified as clean. Plots compare our PASS against the small-loss~\cite{li2020dividemix} and FINE~\cite{kim2021fine} using DivideMix~\cite{li2020dividemix}. 

\cref{fig:0.4_clean,fig:0.2_clean} display the proportion of data classified as clean by the model at noise rates $40\%$ and $20\%$, respectively. It is clear that as training evolves, PASS gets closer to the ideal proportion of clean-label samples available for training than the small-loss~\cite{li2020dividemix} and FINE~\cite{kim2021fine}, which suggests that our approach 
%consistently yield a ratio of around $0.70-0.60$ during the training process, while PASS maintains a ratio of around $0.7-0.8$ for $20\%$ noise rate. All methods are very competitive at $0.4$ noise rate. This conveys that our approach 
is more capable of identifying the correct proportion of noisy label samples for the IDN noise. 
%\rafa{This conveys that our approach is robust on agreeing and samples that are more likely to be clean, independent of the noisy rate.}. 
This proportion alone does not imply accuracy. Hence, we also provide the graphs with F1 and precision scores, which help to highlight the advantages of using peer-agreement for sample selection. 
%However, that proportion alone does not ensure that the clean samples are accurately selected. Hence, we have also calculated the F1 score and precision, which show superior results by our approach.
More specifically, \cref{fig:0.4_f1,fig:0.2_f1} show that our strategy exhibits a consistently superior F1 score compared to other approaches for noise rates $40\%$ (\cref{fig:0.4_f1}) and $20\%$ (\cref{fig:0.2_f1}). PASS achieves a final result of $0.92$, which directly reflects on the improvement in performance of PASS, when compared to small-loss~\cite{li2020dividemix} and FINE~\cite{kim2021fine} with similar results of $0.8-0.85$ at noise rate $40\%$. Whilst FINE~\cite{kim2021fine} and PASS are very competitive in F1 score for noise rate $20\%$ with a value around $0.94$ but small-loss~\cite{li2020dividemix} stays around $0.89$.
Regarding the measure of precision, PASS shows an outstanding precision higher than $0.98$, while small-loss~\cite{li2020dividemix} and FINE~\cite{kim2021fine} show much smaller precision values of around $0.8$ for noise rate $40\%$ (\cref{fig:0.4_precision}). Moreover, all the methods are very competitive in terms of precision at low noise rate of $20\%$ (\cref{fig:0.2_precision}). Based on our empirical analysis, it appears that our method outperforms other competing approaches in correctly identifying positive and negative samples from the training set across all levels of noise.

\subsection{Clothing1M Analysis}

Although Clothing1M~\cite{xiao2015learning} offers a clean validation set, we did not incorporate it into our training process. However, we did leverage this clean validation set to assess and compare the effectiveness of PASS and baseline AugDesc~\cite{nishi2021augmentation}.
%Clothing1M~\cite{xiao2015learning} provides a clean validation set. We have not used that clean validation set in training. Additionally, we have use the clean validation set to compare the effectiveness between PASS and baseline AugDesc~\cite{nishi2021augmentation}. 
%\rafa{This sentence is confusing -> }
For training AugDesc with and without PASS, we have used the \emph{DM-AugDesc-WS-WAW} version of training as mentioned in AugDesc~\cite{nishi2021augmentation}. As mentioned in~\cref{table:clothing1M},  
%\rafa{This refernce is broken in the text -> }~\cref{table:Clothing1M} 
our results are competitive with the existing model. Although both baseline methods are competitive, PASS is still able to outperform based on F1 in~\cref{fig:cloth_f1}, precision in~\cref{fig:cloth_precision}, and ratio of clean data in~\cref{fig:cloth_ratio}.
%\cref{fig:cloth_f1,fig:cloth_precision} shows that both the methods are competitive but PASS is still better in both the scores. 
%\rafa{This sentence needs to be re-written -> }Concurrently, \cref{fig:cloth_ratio} that PASS is much better in selecting clean and noisy samples as compared to baseline. 
\begin{figure}[t]
    \centering
    \hspace{-5em}
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \begin{tikzpicture}
            \pgfplotstableread[col sep=comma, header=true]{clothing1m_csv/f1.tex} \myTable
            \begin{axis}[
                height = 0.6\linewidth,
                width = 0.8\linewidth,
                xlabel={\textnumero~of epochs},
                xlabel style={font=\footnotesize},
                xticklabel style = {font=\footnotesize},
                ylabel={F1-score},
                ylabel style={font=\footnotesize, yshift=-0.5em},
                yticklabel style = {font=\footnotesize},
                scale only axis
            ]
                \addplot[mark=none, BurntOrange, thick, densely dashed] table[x={epochs}, y={SmallLoss}]{\myTable};
                \addplot[mark=none, MidnightBlue, solid, thick, solid] table[x={epochs}, y={PASS}]{\myTable};
            \end{axis}
        \end{tikzpicture}
        \caption{F1 Score}
        \label{fig:cloth_f1}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\textwidth}
        \centering

        \begin{tikzpicture}
            \pgfplotstableread[col sep=comma, header=true]{clothing1m_csv/precision_.tex} \myTable

            \begin{axis}[
                height = 0.6\linewidth,
                width = 0.8\linewidth,
                xlabel={\textnumero~of epochs},
                xlabel style={font=\footnotesize},
                xticklabel style = {font=\footnotesize},
                ylabel={Precision},
                ylabel style={font=\footnotesize, yshift=-0.5em},
                yticklabel style = {font=\footnotesize},
                scale only axis
            ]
                \addplot[mark=none, BurntOrange, thick, densely dashed] table[x={epochs}, y={SmallLoss}]{\myTable};
                \addplot[mark=none, MidnightBlue, solid, thick, solid] table[x={epochs}, y={PASS}]{\myTable};
            \end{axis}
        \end{tikzpicture}
        \caption{Precision}
        \label{fig:cloth_precision}
    \end{subfigure}
    \begin{subfigure}[b]{0.3\textwidth}
        \centering

        \begin{tikzpicture}
            \pgfplotstableread[col sep=comma, header=true]{clothing1m_csv/clean.tex} \myTable
            \begin{axis}[
                height = 0.6\linewidth,
                width = 0.8\linewidth,
                xlabel={\textnumero~of epochs},
                xlabel style={font=\footnotesize},
                xticklabel style = {font=\footnotesize},
                ylabel={Ratio of clean data},
                ylabel style={font=\footnotesize, yshift=-0.5em},
                yticklabel style = {font=\footnotesize},
                legend entries={AugDesc, AugDesc-PASS},
                legend style={draw=none, font=\scriptsize},
                legend image post style={scale=1.},
                legend cell align={left},
                legend pos=south
                east,
                scale only axis
            ]
                \addplot[mark=none, BurntOrange, thick, densely dashed] table[x={epochs}, y={SmallLoss}]{\myTable};
                \addplot[mark=none, MidnightBlue, solid, thick, solid] table[x={epochs}, y={PASS}]{\myTable};
            \end{axis}
        \end{tikzpicture}
        \caption{Ratio of data classified as clean}
        \label{fig:cloth_ratio}
    \end{subfigure}
    \caption{The graphs presented above demonstrate a comparative analysis of the effectiveness of Clothing1M with clean validation set, metrics used are \protect\subref{fig:cloth_f1}~F1-score, \subref{fig:cloth_precision}~precision, and \subref{fig:cloth_ratio}~ratio of data classified as clean. The comparison is made between our approach AugDesc-PASS (blue) with baseline AugDesc approach~\cite{nishi2021augmentation} (yellow). We have used DM-AugDesc-WS-WAW version of training as mentioned in AugDesc~\cite{nishi2021augmentation}.}
        \label{fig:supp_Clothing1M}
\end{figure}



\section{Otsu}\label{sec:appendix_otsu}
%\rafa{I'm not sure whether adding Otsu is relevant -- it's suppose to be a well-known method in Computer Vision}
% This algorithm~\cite{otsu1979threshold} aims to estimate the threshold that partitions two parts by maximizing the between-class variance and minimizing the within-class variance. 
Otsu's algorithm~\cite{otsu1979threshold} aims to estimate the threshold that partitions data samples by maximizing the between-class variance and minimizing the within-class variance. Otsu's thresholding~\cite{otsu1979threshold}  stands out as a notably straight-forward and advantageous global thresholding approach. 
The Otsu's~\cite{otsu1979threshold} formula for finding the optimal threshold \(t*\) is the following: %maximises the between class variance:
% \begin{equation}\label{eq:Otsu}
%     \max_{t}(\sigma_B^2(t)) = \max_{t}( \sigma^2_{T}w_1(t)w_2(t) )
% \end{equation}
% The optimal threshold $t^*$ is the value of $t$ that maximizes the between-class variance:
% $$t^* = \arg\max_t \sigma_B^2(t)$$
\begin{equation}\label{eq:Otsu}
    t^* = \arg\max_{t}( \sigma_B^2(t) ),
\end{equation}
where $t$ is the threshold value, $\sigma_B^2(t)$ is the between-class variance for threshold $t$, computed as 
$$\sigma_B^2(t) = w_1(t)w_2(t)(\mu_1(t) - \mu_2(t))^2,$$
with $w_1(t)$ and $w_2(t)$ representing the weights of the clean and noisy classes (calculated as fractions of the data on each side of the threshold), and $\mu_1(t),\mu_2(t)$ representing the mean value of of samples in the clean and noisy  classes. Effectiveness of Otsu as compared to other approaches are mentioned in~\cref{sec:ablation}.

