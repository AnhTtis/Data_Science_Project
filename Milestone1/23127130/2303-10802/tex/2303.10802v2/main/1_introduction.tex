\section{Introduction}
\label{sec:introduction}
In deep neural networks (DNNs) and machine learning, it is commonly recognised that having an adequate amount of labelled training data and computational resources leads to exceptional outcomes in various fields~\cite{goodfellow2016deep}, such as computer vision, natural language processing, and in the medical domain. 
However, such positive outcomes have been achieved predominantly through the utilisation of meticulously curated datasets that possess labels of exceptional quality. The collection of such high-quality labels, particularly for large datasets, can be exorbitantly costly in real-world scenarios~\cite{song2022learning}. Therefore, cheaper alternative labelling methods, including crowd-sourcing~\cite{song2022learning} and meta-data mining~\cite{feng2021ssr}, have gained traction, but they result in substandard labelling~\cite{song2022learning}. Although these techniques reduce costs and expedite labelling, they are susceptible to data mislabelling~\cite{song2022learning}.
% \begin{figure*}[t]
%     \centering
%     \includegraphics[width=\linewidth]{images/motivation-v14.pdf}
%     \caption{A visual comparison between various sample selection strategies, including: \emph{(left)} the small-loss approaches~\cite{li2020dividemix} typically have two networks, where one model uses the loss values of samples to select clean and noisy instances to train the other and vice versa; \emph{(middle)} feature-based approaches~\cite{kim2021fine} detect outliers of features belonging to one class to detect noisy-label samples; \emph{(right)} PASS consists of three networks where samples agreed by two networks are considered as clean and used for training the third network.}   
%     \label{fig:motivation}
% \end{figure*}

Erroneous labels can potentially degrade the performance of DNNs by inducing overfitting through the phenomenon of memorisation~\cite{li2020dividemix, cordeiro2023longremix}. This issue has led to the development of innovative learning algorithms to tackle the problem of noisy-labelling. 
Within the domain of noisy-labels, many methods have emerged~\cite{li2020dividemix, Garg_2023_WACV}, each tailored to tackle the challenges posed by distinct noise settings, namely instance-independent noise (IIN)~\cite{li2020dividemix} and instance-dependent noise (IDN)~\cite{xia2020part}. Early studies of noisy-labels operated under the assumption that the label noise was IIN, where mislabelling occurred regardless of the information on the visual classes present in images~\cite{li2020dividemix}. Conventional IIN methods often employ a transition matrix which comprises a predetermined probability of flipping between pairs of labels~\cite{xia2020part}. However, recent studies have progressively redirected the field's attention towards the more realistic scenario of IDN~\cite{ Garg_2023_WACV}, where label noise depends on both clean-label and the image information.
% \input{main/main_figure_2}
% \input{main/probability_agreement_graph}

Previous techniques for mitigating the impact of noisy-label samples frequently involve manually selecting clean samples to form a clean validation set~\cite{ren2018learning}. The difficulty in obtaining clean validation samples, particularly for problems with many classes, has motivated recent studies to leverage semi-supervised learning methods without relying on clean validation sets~\cite{li2020dividemix, sachdeva2023scanmix}. Other approaches incorporate robust loss functions~\cite{song2022learning}, designed specifically to operate effectively with clean or noisy-labels, as well as probabilistic modeling approaches that model the data generation process~\cite{Garg_2023_WACV}. Furthermore, training regularisation~\cite{liu2020early} imposes a penalty term on the loss function during training, thus reducing overfitting and ameliorating generalisation. Various techniques integrate sample selection strategies as a key algorithmic step~\cite{Garg_2023_WACV, li2020dividemix}, allowing the detection of clean and noisy-label samples. 
A widespread criterion for this sample selection process is the loss value between the prediction of the trained classifier and its label, by which it is generally assumed that the noisy-label data exhibits a large loss~\cite{li2020dividemix,kim2021fine} or a higher magnitude of the gradient during training~\cite{song2022learning}.

Furthermore, feature-based sample selection techniques relying on the similarity to the principal components of feature representations~\cite{kim2021fine} or K nearest neighbor (KNN) classification in the feature space~\cite{feng2021ssr} have also been considered for the sample selection criteria.
However, we empirically show in \cref{fig:empirical_graph} that the separation of clean, but difficult-to-classify samples from noisy-label samples remains a challenge for these sample selection processes~\cite{wei2020combating}, particularly for problems with high noise rates. 
The use of peer classifiers for noisy-label learning problems has been investigated to avoid confirmation bias~\cite{han2018co, li2020dividemix}, but not to select clean and noisy-label samples. 
\input{final_figures/fig1}
We argue in this paper that the prediction agreement between peer classifiers is more effective in selecting clean and noisy-label samples than previous approaches, because, intuitively, such an agreement is unlikely to happen, except when the classifiers agree on the clean-label. 

In this paper, we propose a new sample selection criterion based on the predictive probability agreement between peer classifiers.
% , which has been shown in computational linguistics to be a sample reliability measure~\cite{artstein2008inter}.
In our proposed method, we train three classifiers simultaneously using the agreement between two classifiers to select samples to train the remaining classifier, as shown in~\cref{fig:motivation}.
This sample selection is based on a thresholding algorithm~\cite{otsu1979threshold} that distinguishes samples based on the degree of agreement between the peer classification predictions. Our proposed method, named as \emph{peer-agreement-based sample selection} (PASS), can easily be integrated into existing models in noisy-label learning, such as InstanceGM~\cite{Garg_2023_WACV}, DivideMix~\cite{li2020dividemix}, SSR~\cite{feng2021ssr}, FaMUS~\cite{xu2021faster}, AugDesc~\cite{nishi2021augmentation}, and Contrast-to-Divide (C2D)~\cite{zheltonozhskii2022contrast}. Our primary contributions can be delineated as follows:

\begin{itemize}
\item we propose a new noisy-label sample selection method, PASS, that differentiates clean and noisy-label samples through prediction agreement between peer classifiers, and
\item we demonstrate that our method can be easily adapted to existing models, including InstanceGM~\cite{Garg_2023_WACV}, DivideMix~\cite{li2020dividemix}, SSR~\cite{feng2021ssr}, FaMUS~\cite{xu2021faster}, AugDesc~\cite{nishi2021augmentation}, and C2D~\cite{zheltonozhskii2022contrast}, where we show that PASS enhances the performance of various SOTA approaches on various benchmarks, comprising both simulated and real-world datasets, such as CIFAR-100~\cite{krizhevsky2009learning}, CIFAR-N~\cite{wei2022learning}, Animal-10N~\cite{song2019selfie}, Red mini-ImageNet from Controlled Noisy Web Labels (CNWL)~\cite{xu2021faster}, Clothing1M~\cite{xiao2015learning}, mini-WebVision~\cite{li2017webvision}, and ImageNet~\cite{deng2009imagenet}.
\end{itemize}

It is imperative to clarify that our proposition does not involve the introduction of a new learning with noisy-label algorithm. Instead, we suggest a new method for selecting noisy-label training samples to substantially improve the efficacy of preexisting LNL algorithms, as shown in our experimental section. The empirical evidence supporting this selection mechanism is delineated 
% in~\cref{fig:empirical_graph} 
and elaborated in \cref{subsec:empirical_subsec_cifar} and \cref{subsec:empirical_subsec_clothing}. Upon completion of the selection phase, our approach adheres to a robust training algorithm specifically designed to handle noisy-labels, which facilitates the development of a more reliable model.
% (\ref{sec:experiments}). 
