% \vspace{-3mm}
\section{Experimental Results}
\label{Experiments}


% \begin{figure}[htbp]
% \centering
% \begin{minipage}[t]{0.42\textwidth}
% \centering
% \includegraphics[width=6cm]{figure/Plot1.pdf}
% \caption{World Map}
% \end{minipage}
% \begin{minipage}[t]{0.52\textwidth}
% \centering
% \includegraphics[width=6cm]{figure/Plot3.pdf}
% \caption{Concrete and Constructions}
% \end{minipage}
% \end{figure}





% \begin{figure}[htbp]
% \centering

% \includegraphics[width=6cm]{figure/Plot3.pdf}
% \caption{World Map}

% \end{figure}










In this section, we describe in detail the set of experiments performed to validate our proposed HGIB framework for prognosis prediction of Alzheimer's Disease.

%We aim to show the effectiveness and robustness of proposed HGIB on the task of prognosis prediction of Alzheimer's Disease.
% 
 

\subsection{Dataset Description}
We conduct  our evaluation on the  Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset\footnote{Data used in the preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (\url{adni.loni.usc.edu}).}.
% 
ADNI is a longitudinal multi-centre and multi-modality study designed for the early detection and tracking of Alzheimer’s disease. 
The dataset contains four categories: Normal Control (NC), early Mild Cognitive Impairment (EMCI), late Mild Cognitive Impairment (LMCI), and Alzheimer’s disease (AD) at the Baseline Visit while only three categories afterwards: NC, Mild Cognitive Impairment (MCI), and AD.
% 
We focus on patients diagnosed with MCI (EMCI/LMCI) at the baseline visit.
% 
The goal is to predict the diagnosis of MCI conversion within a fixed two-year window to identify whether subjects converted to NC and AD or not, based on the multi-modality data including MRI, PET, and Non-imaging information.
% 
The Non-imaging information consists of demographic, genetic, and cognitive features, \textit{e.g.,} age, gender, education, APOE4, MMSE, ADNI-MEM \cite{crane2012development}, ADNI-EF \cite{gibbons2012composite}.
% 
After the filter, we got 248 patients with complete three modalities from ADNI-2.
% 

\subsection{Dataset Pre-processing}
For the data pre-processing, all MRI volumes are processed following (1) anterior commissure (AC)-posterior commissure (PC) alignment, (2) skull stripping, (3) intensity correction, (4) cerebellum removal, and (5) linear alignment to a template MRI.
% 
The corresponding PET volumes are aligned to their MRI volume via linear registration.
% 
For the Non-imaging data, we normalise each feature in the range of [0,1] before feeding them into the network.


% All MR images were pre-processed via four steps: (1) anterior commissure (AC)-posterior commissure (PC) alignment, (2) skull stripping, (3) intensity correction, (4) cerebellum removal, and (5) linear alignment to a template MRI. Each PET image was also aligned to its corresponding MRI via linear registration. Hence, there is spatial correspondence between MRI and PET for each subject.

\subsection{Evaluation Protocol}
We  discuss the following conditions in our experiments: (1) the classification accuracy of HGIB compared with state-of-the-art hypergraph neural network methods; (2) performance comparison under different label counts of our method vs. existing techniques;
%with less annotations compared with others; 
(3) robustness analysis under two kinds of attacks. 
We follow standard protocol in the medical domain and use the area under the ROC curve (AUC), Positive predictive value (PPV \%), and negative predictive value (NPV \%) to measure the performance.
For the results, we report the average performance and standard deviation over five independent runs. 

We implemented our framework using PyTorch \cite{NEURIPS2019_9015} and DHG\footnote{\url{https://deephypergraph.com}} library on one NVIDIA A100 GPU. Our framework was optimised with the Adam algorithm for 2,000 epochs. The learning rate was set as  1× 10$^{-4}$ and decreased to 0. We set the number of neighbours as 20 when constructing the hypergraph.
% 
We empirically set the hyper-parameters $\mu$ and $\xi$ as 1 and 10 respectively.


\subsection{Results \& Discussion}

\textbf{Comparison to Other Hypergraph Neural Networks.}
We start evaluating our framework against 
%We compare our method with other 
three state-of-the-art hypergraph neural networks.
% 
HGNN~\cite{feng2019hypergraph} is a hypergraph neural network based on spectral convolution.
DHGNN \cite{jiang2019dynamic} exploits dynamically updating hypergraph structure on each layer.
% 
While HGNN+~\cite{gao2022hgnn} is an extended version of HGNN which is a general high-order multi-modal data correlation modelling framework.
% 

We report the quantitative comparison of our technique vs. existing techniques in Table
%The comparison results with the above methods are shown in Table 
\ref{tab:results-SOTA}.
In a closer look at this table, we observe that 
%It is observed that 
our HGIB framework reports the best AUC performance on NC and MCI categories and best average AUC and NPV results. 
% 
And the AUC performance of AD generates the comparable performance (0.8492) to the top value (0.8516).
% 
The highest NPV value of 76.19\% also indicates that HGIB is more reliable to identify true negative cases and avoiding false negatives.
% 
Across all the results, our framework demonstrates that
%it is demonstrating that 
utilising the information bottleneck can further improve the network prognosis prediction ability. To further support our experimental results, we ran  set of statistical tests. Firstly, we ran a non-parametric test for multiple comparisons. In particular, we use the Friedman test along with the Kendall's coefficient of concordance with 95\% confidence intervals as measure of the effect size for the Friedman test. The results are displayed in Fig.~\ref{fig2}(a). We can then conclude that there is a significant difference in performance $\chi^2_{Friedman} (3)= 5.16$. The effect size $W_{Kendall} = 0.11$ with 95\% CI.  We then performed a pair-wise comparison using the non-parametic Wilcoxon test yielding to $V_{Wilcoxon}= 17.50, 30, 40$ for DHGNN vs. HGIB, HGNN vs. HGIB and HGNN+ vs. HGIB, respectively. 

\begin{figure}[!t]
\centering
\setlength{\abovecaptionskip}{0pt}
\setlength{\belowcaptionskip}{-2pt}
\subfigure[]{\includegraphics[width=0.45\linewidth]{figure/Plot1.pdf}}
\subfigure[]{\includegraphics[width=0.53\linewidth]{figure/Plot3.pdf}}
\caption{Statistical analysis of our technique vs. 
existing ones. (a) Displays a outcome of the non-parametric Friedman test. (b) Displays pair-wise comparison performed using the Wilcoxon test.}
\label{fig2}
\end{figure}

  \begin{table*} [!t]
    \centering
    \caption{Comparison of our method (HGIB) and existing hypergraph techniques. 
    % All comparisons are run over 5 random times on the same conditions. 
    The top results are highlighted in \textbf{bold}.}
    \label{tab:results-SOTA}
    {
        % \setlength\tabcolsep{1.5pt}
        \setlength{\tabcolsep}{0.2mm}{
        \begin{tabular}{l|c|c|c|c|c|c}
            \toprule[1pt]
            
             \multirow{2}{*}{\textbf{Methods}} & \multicolumn{3}{c|}{\textbf{AUC}} &
             \multirow{2}{*}{\tabincell{c}{\textbf{AUC}\\ \textbf{average}}} & \multirow{2}{*}{\tabincell{c}{\textbf{PPV}\\ \textbf{average}}} & \multirow{2}{*}{\tabincell{c}{\textbf{NPV}\\ \textbf{average}}} \\
             % \tabincell{c}{\textbf{CIDDG}\\ \cite{li2018deep}}\\
             \cline{2-4}  & \textbf{NC} & \textbf{MCI} & \textbf{AD} &  \T \B \\
             \hline
            \T
            \textbf{DHGNN}~\cite{jiang2019dynamic} & $0.6437\pm 0.08$ & $0.5546\pm 0.09$     &$0.6841\pm 0.11$  & $0.6275$ & $50.88$  & $69.89$  \\ 
            
            \textbf{HGNN}~\cite{feng2019hypergraph} &  $0.7114\pm 0.02$ &  $0.6407\pm 0.04$   & \cellcolor[HTML]{D7FFD7}$\textbf{0.8516}\pm 0.03$  & $0.7346$ &\cellcolor[HTML]{D7FFD7}$\textbf{63.49}$  & $74.37$   \\ 

            \textbf{HGNN+}~\cite{gao2022hgnn} &  $0.7454\pm 0.04$ &  $0.6532\pm 0.07$   & $0.8325\pm 0.07$  & $0.7437$ &$55.07$  & $74.03$   \\ 

            \hline
            \textbf{HGIB} (Ours) &  \cellcolor[HTML]{D7FFD7}$\textbf{0.7504}\pm 0.03$ &  \cellcolor[HTML]{D7FFD7}$\textbf{0.6789}\pm 0.03$   & $0.8492\pm 0.05$  & $\cellcolor[HTML]{D7FFD7}\textbf{0.7595}$ &$60.98$  & $\cellcolor[HTML]{D7FFD7}\textbf{76.19}$   \\ 

            \toprule[1pt]
        \end{tabular}
    }}
\end{table*}

%\sj{add one para for the figure anlaysis statistical analysis}

  \begin{table*} [!t]
    \centering
    \caption{Comparison of our method (HGIB) and existing hypergraph techniques under different training sample settings. 
    % All comparisons are run 5 random times on the same conditions. 
    The top results are highlighted in \textbf{bold}.}
    \label{tab:results-efficient}
    {
        % \setlength\tabcolsep{1.5pt}
        % \resizebox{\textwidth}{
        \setlength{\tabcolsep}{0.5mm}{
        \begin{tabular}{l|c|c|c|c|c|c|c|c|c}
            \toprule[1pt]
            
             \multirow{2}{*}{\textbf{Methods}} & \multicolumn{3}{c|}{\textbf{80\% }} &  \multicolumn{3}{c|}{\textbf{60\% }} & \multicolumn{3}{c}{\textbf{40\% }} \\
             \cline{2-10}& \textbf{AUC} & \textbf{PPV}& \textbf{NPV} & \textbf{AUC} & \textbf{PPV}& \textbf{NPV} & \textbf{AUC} & \textbf{PPV}& \textbf{NPV} \\
             \hline
            \T
            \textbf{DHGNN}~\cite{jiang2019dynamic} & $0.7208$ & $56.08$     &$73.71$  & $0.6981$  & $53.20$ &$71.43$  & $0.6911$  & $47.05$ &$72.75$ \\ 
            
            \textbf{HGNN}~\cite{feng2019hypergraph} & $0.7346$ & \cellcolor[HTML]{D7FFD7}$\textbf{63.49}$     &$74.37$  & $0.7300$  & $55.60$ &$74.68$  & $0.7282$  & $58.84$ &$75.51$  \\ 

            \textbf{HGNN+}~\cite{gao2022hgnn} & $0.7437$ & $55.07$     &$74.03$  & $0.7425$  & $55.51$ &$74.71$  & $0.7162$  & $55.90$ &$73.62$   \\ \hline

            \textbf{HGIB} (Ours) & \cellcolor[HTML]{D7FFD7}$\textbf{0.7595}$ & $60.98$     &\cellcolor[HTML]{D7FFD7}$\textbf{76.19}$  & \cellcolor[HTML]{D7FFD7}$\textbf{0.7443}$  & \cellcolor[HTML]{D7FFD7}$\textbf{57.93}$ &\cellcolor[HTML]{D7FFD7}$\textbf{76.63}$  & \cellcolor[HTML]{D7FFD7}$\textbf{0.7393}$  & \cellcolor[HTML]{D7FFD7}$\textbf{60.81}$ &\cellcolor[HTML]{D7FFD7}$\textbf{76.22}$  \\ 

            \toprule[1pt]
        \end{tabular}
        }}
    % }
\end{table*}

\smallskip
\textbf{Performance Comparison over Different Label Counts.}
% To show the efficiency and effectiveness of the proposed method with limited labelled data, we ran another set of experiments under three different settings with different labels counts: 80\%/60\%/40\% training patients.
% % ; (2) 60\% training patients; and (3) 40\% training patients. 
% The numerical comparison results is reported in Table~\ref{tab:results-efficient}.
% % 
% We can observe that our proposed 
% %As we can see, 
% HGIB outperforms all compared techniques.
% Besides, even trained with fewer annotated data samples, we observed a slight decrease in performance compared to when the method was trained with the full set of annotated data.
% It suggests that our method has the ability to effectively learn from limited data and generalise well to the remaining testing data.
% This can be explained that HGIB can efficient use of available data and shows model ability to identify relevant features and patterns in the data, which is useful for  prognosis prediction.
% 
To demonstrate the effectiveness of our proposed method with limited labelled data, we conducted experiments with three different label counts (80\%, 60\%, and 40\% of training patients). The results are reported in Table 2, which shows that HGIB outperforms all compared techniques. We also observed that even when trained with fewer annotated data samples, our method still achieved good performance with a slight decrease compared to the full set of annotated data. This suggests that HGIB can effectively learn from limited data and generalize well to the remaining testing data by identifying relevant information (\textit{e.g.}, features and patterns), thus improving prognosis prediction.

\smallskip
\textbf{Robustness Analysis under Attacks.}
To study the robustness of the proposed HGIB under the hypergraph topology and feature tasks, we conduct experiments by (1) randomly drop 20\% hyperedges from the original hypergraph for structure attack; (2) randomly inject feature noise to the extracted feature embedding $X$ for feature attack. 
% 
Specifically, we define the mean of the maximum value of each vertex feature as $r$, random Gaussian noise as $\epsilon \sim  N(0,1)$, and feature noise ratio as $\rho$.
We then calculate noise according to $\eta=\rho \cdot r \cdot  \epsilon$. 
We set $\rho$ as 0.01 in the experiments.
The results are shown in Table~\ref{tab:results-robust}.
% 
% Our method HGIB consistently outperforms the previous state-of-the-art HGNN+ \cite{gao2022hgnn} when dropping hyperedges or adding feature noise.
% This shows that HGIB makes the model more robust for either structure or feature perturbations, and further supporting our proposed framework in terms of generalisation and robustness.
% 
The results, shown in Table 3, demonstrate that HGIB consistently outperforms the previous state-of-the-art HGNN+~\cite{gao2022hgnn} in both scenarios, indicating that HGIB enhances the model's robustness for structure and feature perturbations, supporting its effectiveness for generalization and robustness.






  \begin{table*} [!t]
    \centering
    \caption{Robustness Analysis.
    % We use two type of attacks topological and feature. 'Drop' means random drop 20\% hyperedges and Noise means noise injection  to the feature embedding. 
    The top results are highlighted in \textbf{bold} font.}
    \label{tab:results-robust}
    {
        % \setlength\tabcolsep{1.5pt}
        \setlength{\tabcolsep}{0.2mm}{
        \begin{tabular}{l||c|c||c|c||c|c}
            \toprule[1pt]
            \textbf{Methods} & \textbf{Attack} & \textbf{AUC} & \textbf{Attack} & \textbf{AUC} & \textbf{Attack} & \textbf{AUC}
              \T \B \\
             \hline
            \T
            \textbf{HGNN+}~\cite{gao2022hgnn} & - & $0.7437\pm0.05$ & Drop & $0.7155\pm0.02$ & Noise & $0.7061\pm0.04$   \\

             \textbf{HGIB} (Ours) &-  & $\textbf{0.7595}\pm 0.02$ & Drop &$\textbf{0.7452}\pm 0.02$  & Noise &$\textbf{0.7326}\pm 0.01$   \\ 
            \hline
            \toprule[1pt]
        \end{tabular}
    }}
\end{table*}