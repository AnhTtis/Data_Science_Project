
\vspace{-2mm}
\section{Proposed Framework} \label{method}
\vspace{-2mm}

\begin{figure}[!tbp]
\centering

\includegraphics[width=12cm]{figure/teaser.pdf}
\caption{Illustration of the whole workflow. (a) shows how hypergraph information bottleneck utilised to optimize the representation $Z$ to capture the minimal sufficient information within the input data $D=(G,I)$ to predict the MCI conversion label $Y$. (b) is the overall workflow integrating HGIB into the hypergraph neural network. HGNNP is a kind of hypergraph convolutional layer.}
\label{teaser}

\end{figure}

This section presents a detailed description of the crucial components of our proposed framework. Firstly, we elucidate the process of constructing the hypergraph from a given set of multi-modal data, and we delve into the specifics of the hypergraph convolution definition. Secondly, we explicate the fundamental principle of information bottleneck and integrate it into hypergraph neural networks.
The overview of the proposed method is illustrated in Fig.~\ref{teaser}.

% Introduction why using hypergraph for mult-modality learning + HGIB



% \Angie{to be updated}



\smallskip
\subsection{Hypergraph Modelling and Hypergraph Convolution}

To overcome the
challenges associated with multi-modality data ($I_1, I_2, ..., I_m$), we leverage a hypergraph
structure $G$ to represent the multi-modal features ($X_1, X_2, ..., X_m$) extracted from backbones. Subsequently, we employ a hypergraph neural network to predict MCI conversion.

% The main purpose of the proposed framework is to optimally balance the expressiveness and robustness of the learned representation of hypergraph structure data for accurate MCI conversion prediction.
% 
%Hypergraph is general framework to incorporate with multi-modality data which is common strategy for AD diagnosis.
% 
% To encourage the minimal and sufficient representation learning, we introduce  information bottleneck by applying this principle to hypergraph neural networks.
% 
%We will first elaborate hypergraph modelling and hypergraph convolution operation and then introduce the hypergraph information bottleneck.

\medskip
\noindent
\textbf{Hypergraph representation learning.}
We consider an undirected attributed hypergraph $G = (V, E, \textbf{H})$ with a vertex set $V$, a hyperedge set $E$, and an adjacency matrix $\textbf{H} \in \mathbb{R}^{|V| \times |E|}$ for hyperedge weight. 
% 
Each vertex in our hypergraph structure corresponds to a patient, while each hyperedge represents the relationship between a subset of vertices. Unlike in a graph structure, where an edge connects only two vertices, a hyperedge in a hypergraph connects multiple vertices, enabling the representation of higher-order relationships. This feature facilitates the grouping of subsets of vertices with common features or properties, enhancing the ability of the hypergraph to model complex relationships within the data.
% 
In our hypergraph structure, each vertex corresponds to a patient and each hyperedge represents the relationship between a subset of the vertices. Unlike in a graph structure, a hyperedge in a hypergraph connects multiple vertices instead of just two, allowing for the representation of higher-order relationships. This can be seen as the hyperedges grouping together subsets of vertices that have common features or properties.
% 
Specifically, the hyperedge weight between vertex $v$ and hyperedge $e$ can be defined as 
$h_{v,e}= 
\left\{ 
    \begin{array}{lc}
        1& \text{if} \  v \in e \\
        0& \text{otherwise}
    \end{array}
\right.
$.
Moreover, we denote the vertex attributes as $X$, which can be seen as a feature embedding. The input data can be represented as $D=(G, X)$. In the multi-modal setting, we assume $m$ modalities as input and denote them as $D=(G, (X_1, X_2, ..., X_m))$.
%the input data is
%can be overall 
%denoted as $D=(G, (X_1, X_2, ..., X_M))$ for M modalities
% and the hypergraph $G$.
%can represent high-order correlations of the data.

%How to generate the hypergraph 



% Given the input data $D$ with a hypergraph and corresponding embedding, 

% A crucial step in hypergraph learning is how to contruct the hypergraph structure. To do this, 
% %To generate such hypergraph structure, 
% we first obtain the feature embeddings $X$, from the given multi-modality data, using a pre-trained network backbone, as shown in Fig.~\ref{teaser}(b).
% We then use a neighbour strategy, in feature space, to generate the hyperedge groups following the same protocol as in \cite{gao2022hgnn}. Specifically, given a vertex as the centroid, its  k-nearest neighbours in the feature space can be connected by a hyperedge:
% \begin{equation}
%    E_k=\{N_{\text{KNN}_k}(v)|v \in V\}. 
% \end{equation}
% These hyperedge groups are further concatenated together to form a hypergraph for each modality data.
% To effectively utilize the multi-modality knowledge, we concat k different hypergraphs together to generate the final hypergraph. Specifically, the incidence matrices $H_k$ are concatenated directly, as $H=H_1\|H_2\|...\|H_k$.
% Then, we can feed the data D into Hypergraph Convolution Layer for further computation.



A crucial step in hypergraph learning is the construction of the hypergraph structure. To achieve this, we first obtain the feature embeddings $X=\{X_1, X_2, ...,\\ X_m\}$ from the multi-modality data using a pre-trained network backbone, as illustrated in Fig.~\ref{teaser}(b). We then employ a neighbor strategy in feature space to generate the hyperedge groups following the same protocol as described in \cite{gao2022hgnn}. Specifically, for each vertex, its $k$-nearest neighbors in the feature space are connected by a hyperedge, resulting in the set of hyperedges $E_k=\{N_{\text{KNN}_k}(v)|v \in V\}$.
% \begin{equation}
% E_k={N_{\text{KNN}_k}(v)|v \in V}.
% \end{equation}
% 
These hyperedge groups are concatenated together to form a hypergraph for each modality data. To effectively utilize the multi-modality knowledge, we concatenate $k$ different hypergraphs to generate the final hypergraph by $H=H_1\|H_2\|...\|H_k$. Then, we feed the resulting data $D$ into a Hypergraph Convolution Layer for further computation.

% To update the vertex information, we aggregate its neighbor vertex messages along the hyperpath:

\medskip
\noindent
\textbf{Hypergraph Convolution.}
We use spatial hypergraph convolution layers \cite{gao2022hgnn} for message aggregation. Messages can be passed either from vertex to hyperedge or from hyperedge to vertex using hyperpaths $P$, which is defined as $P(v_1,v_k) = (v_1,e_1,v_2,...,e_{k-1}, v_k)$.
% We utilise the Inter-Neighbor Relation $N$ of hypergraph $G$ as $N=\{ ( v,e  ) | w_{v,e}=1, v \in V, \ and\  e \in E \}$.
% 
% The vertex inter-neighbor set of hyperedge $e$ is  defined as $N_v(e)=\{v|vNe \}$ and the hyperedge inter-neighbor set of vertex is defined as $N_e(v)=\{e|vNe\}$.
% Therefore, to update the vertex information, we need to aggregate the messages from its hyperedge inter-neighbors $N_e(v)$. And the hyperedge inter-neighbor message is updated according to their vertex inter-neighbors $N_v(e)$. Such two-step message aggregation realises a closed message passing loop among vertices.
% Then the spatial hypergraph convolution layer reads:
% \begin{equation}
% h_e=w_e \cdot \sum_{v \in N_v(e)} \frac{x_v}{|N_v(e)|}, \ \ \ \ 
% y_v=\sigma \Bigg(\sum_{e \in N_e(v)} \frac{h_e}{|N_e(v)|} \cdot \Theta \Bigg),
% \end{equation}
% where $x_v$, $h_e$, and $y_v$ are the input, hidden, and output feature vectors. $w_e$ is a weight associated to hyperedge $e$, and $\Theta$ is a trainable parameter of current hypergraph convolution layer. $\sigma$ is a non-linear activation function,\textit{ e.g.}, ReLU($\cdot$). 
% 
We define the inter-neighbor relation $N$ of hypergraph $G$ as $N=\{ (v,e) | w_{v,e}=1, v \in V, \text{ and } e \in E \}$. The vertex inter-neighbor set of hyperedge $e$ is defined as $N_v(e)=\{v|vNe\}$, and the hyperedge inter-neighbor set of vertex $v$ is defined as $N_e(v)=\{e|vNe\}$. To update the vertex information, we aggregate the messages from its hyperedge inter-neighbors $N_e(v)$, and to update the hyperedge information, we use the vertex inter-neighbors $N_v(e)$.
% 
Thus, the spatial hypergraph convolution layer is defined as
\begin{equation}
f_e= \sum_{v \in N_v(e)} h_{v,e}  \cdot \frac{x_v}{|N_v(e)|}, \ \ \ \
{f}'_v=\sigma \Bigg(\sum_{e \in N_e(v)} \frac{f_e}{|N_e(v)|} \cdot \Theta \Bigg),
\end{equation}
where $x_v$, $f_e$, and ${f}'_v$ are the input, hidden, and output feature vectors. $\Theta$ is a trainable parameter of the current hypergraph convolution layer. $\sigma$ is a non-linear activation function, such as ReLU. The two-step message aggregation realizes a closed message passing loop among vertices, which enables the model to capture higher-order relationships between the vertices in the hypergraph.


\smallskip
\subsection{Hypergraph Information Bottleneck (HGIB)}
To balance the expressiveness and robustness of the model, we aim to optimize the vertex representation to capture the minimal sufficient information required for downstream tasks via the information bottleneck approach \cite{tishby2000information}. The Hypergraph Information Bottleneck (HGIB) approach, as shown in Fig. \ref{teaser}(a), is derived from the Graph Information Bottleneck \cite{wu2020graph}, which requires the node representation $Z_v$ to minimize the information from hypergraph-structured data $D$ while maximizing the information to prediction $Y$.
% 
% At the optimisation level, a major challenge for HGIB numerical realisation is
% is that the independent and identically distributed (IID) assumption of vertices are not feasible for many real-world scenarios.
% 
% Therefore, we rely on a local-dependence assumption for hypergraph-structural data: given the data related to the limited number of neighbours of vertex $v$, the data in the rest of the hypergraph is independent of $v$.
 % 
 However, a major challenge in realizing HGIB numerically is the assumption of independent and identically distributed (IID) vertices, which is not feasible for many real-world scenarios. Therefore, we rely on a local dependence assumption for hypergraph-structured data, whereby given data related to a limited number of neighbors of vertex $v$, the data in the rest of the hypergraph is independent of $v$.
 % 
 % 
 % The optimal representation follows the Markovian dependence. The representation of each vertex is updated by incorporating its neighbours with respect to the hypergraph representation $X$.
 We assume a Markovian dependence to obtain the optimal representation, whereby the representation of each vertex is updated by incorporating its neighbors with respect to the hypergraph representation $X$.
 % 
The information bottleneck seeks to optimise
 %is reduced to the following optimization:
\begin{equation}
\underset{\mathbb{P}(Z^l|D) \in \Omega }{min} \mathcal{L}_{\text{HGIB}}(X,Y;Z^l):= [-I(Y;Z^l)+\beta I(X;Z^l)],
\end{equation}
where $\Omega$ characterises the space of conditional distribution of $Z^l$ given data $D$, and $\beta$ is a balancing weight. $l$ represents the $l$-th hypergraph convolution layer. 

We now define the mutual information $I(X;Z^{l})$,  between the initial vertex embedding and updated vertex embedding, following~\cite{nguyen2010estimating}. This yield to the Cross-Entropy loss that reads:
\vspace{-2mm}
\begin{equation}
    I(Y;Z^l) \rightarrow -\sum_{v \in V} \text{CE}(Z_v^lW_{out};Y_v),
\end{equation}
% \vspace{-2mm}
where $W_{out}$ is the weight of projector to predict the MCI conversion labels.
%
%
% \subsubsection{HGIB Estimation}\\
% \\
% \textbf{Lemma 1} (Nguyen, Wainright & Jordan's bound) For any two random variables $X_1$, $X_2$, and any brivariate function $g:g(X_1, X_2) \in \mathbb{R}$, we have
% \begin{equation*}
% I(X_1, X_2) \geqslant \mathbb{E} [g(X_1, X_2)]-\mathbb{E}_{\mathbb{P}(X_1)\mathbb{P}(X_2)} [\text{exp}\left (g\left (X_1, X_2\right )-1\right )].
% \end{equation*}
% We use this lemma for $I(Y;Z^l)$ and set $g(Y,Z^l)=1+\text{log}\frac{\prod_{v \in V} Cat(Z^lW_{out})}{\mathbb{P}(Y)}$. Then $I(Y;Z^l)$ reduces to the Cross-Entropy loss by ignoring constants, \textit{i.e.,}
% $$
% I(Y;Z^l) \rightarrow -\sum_{v \in V} \text{CE}(Z_v^lW_{out};Y_v).
% $$
%
% \if 0
% \textbf{Proposition 1. }
% % 
% % \begin{equation*}
% % \underset{\mathbb{P}(X|D) \in \Omega }{min} \text{GIB} _\beta(D,Y;X):= [-I(Y;X)+\beta I(D;X)],
% % \end{equation*}
% % 
% $I(X;Z^{l})  \leqslant I(X;Z^{l-1})$.
%
% \textbf{Proof.} Since the conditional distribution of $Z_v^l$ depends only on 
% {$X,Z^{l-1},Z^l$} forms a Markov chain in this order $X \rightarrow Z^{l-1} \rightarrow Z^l$.
% According to data-processing inequality \cite{beaudry2011intuitive}, we have $I(X;Z^{l})  \leqslant I(X;Z^{l-1})$.
% \fi
%
% $I(X;Z^{l})$ measures the mutual information between the initial vertex embedding and updated vertex embedding. It has an upper bound and can be derived to a tractable objective to optimize as follow.
%
%\textbf{Proposition 1. } For any distribution $\mathbb{Q}(Z^l)$ for $Z^l$, we have 
%$I(X;Z^{l})  \leqslant  \text{KL}(\mathbb{P}(Z^l|X)\|\mathbb{Q}(Z^l))$.
%
%To specify the upper bound for $I(X;X^{l})$, we assume $\mathbb{Q}(Z^l)$ is a non-informative prior and the elements in $X^{l}$ are IID Bernoulli distributions: $Z^l = \bigcup_{i,j} \{ z_{i,j} \in  \{ 0,1  \} |z_{i,j}\overset{IID}{\sim } \text{Bernoulli(0.5)} \}$. We assume the elements in $\mathbb{Q}(Z^l)$ have a probability of 0.5. Thus the estimation of $I(X;X^{l})$ is written as
%$$I(X;X^{l})=\frac{1}{nm} \sum_{i=1}^{n}\sum_{j=1}^{m} \text{KL}\left (\text{Bernoulli}\left (z_{ij}^l\right)\| \text{Bernoulli}\left (0.5\right )\right ).$$
We then assume that the elements in $X^{l}$ are IID Bernoulli distributions: $Z^l = \bigcup_{i,j} \{ z_{i,j} \in  \{ 0,1  \} |z_{i,j}\overset{IID}{\sim } \text{Bernoulli(0.5)} \}$. So the mutual information can be defined as $I(X;Z^{l})=\frac{1}{nm} \sum_{i=1}^{n}\sum_{j=1}^{m} \text{KL}\left (\text{Bernoulli}\left (z_{ij}^l\right)\| \text{Bernoulli}\left (0.5\right )\right )$. Here, $\text{KL}$ denotes the Kullback-Leibler divergence between two Bernoulli distributions. 

\vspace{-2mm}
\subsection{Optimisation Scheme}
\vspace{-2mm}

Our main task is MCI prediction conversion. This problem is taken from the perspective of a three class prediction task (NC, MCI, and AD). We have as basis a cross-entropy loss for classification. In the medical domain, it is usual to encounter with the class imbalance problem. To address this issue, we incorporate a focal loss. We then define our overall optimisation scheme as
% 
%In this paper, we focus on the three class prediction task. So the cross entropy loss is basically applied for classification.
%Considering the class imbalance problem for the task setting, we further incorporate focal loss.
%Therefore, the final optimization loss function is the combination of CE loss, focal loss, and HGIB loss:
\begin{equation}
    \mathcal{L}_{total} = \frac{1}{|V|} \sum_{v \in V}\Bigl\{\text{CE}(P_v;Y_v) + \mu \left [-\alpha (1-P_v)^\gamma \text{log}(P_v) \right ]\Bigl\}  + \xi \frac{1}{L}\sum_{l=1}^{L} \mathcal{L}_{\text{HGIB}},
\end{equation}
where $\mu$ and $\xi$ are balancing parameters. $\alpha$ and $\gamma$ are two hyper-parameters for the focal loss~\cite{lin2017focal} in our experiments, we set their values to 2 and 0.5 respectively.
%nd been set as 2 and 0.5, respectively.