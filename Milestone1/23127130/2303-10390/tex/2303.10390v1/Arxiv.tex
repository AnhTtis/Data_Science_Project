% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{graphicx}
\usepackage{amsfonts,amssymb}

% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
\usepackage{color}
\usepackage{epstopdf}
\usepackage{tabularx,threeparttable}
\usepackage{array}
\usepackage[hidelinks]{hyperref}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{amssymb, amsmath, bm}
\usepackage{mathtools}
\usepackage{mathrsfs}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{cite}
\usepackage{url}
\usepackage{color}
\usepackage{dsfont}
\usepackage[table,xcdraw]{xcolor}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
%

\newcommand\T{\rule{0pt}{2.4ex}}       % Top strut
\newcommand\B{\rule[-1.2ex]{0pt}{0pt}} % Bottom strut
%\newcolumntype{?}[1]{!{\vrule width #1}}
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}  
\def\ie{\emph{i.e.}}
\def\eg{\emph{e.g.}}
\def\etal{{\em et al.}}
\def\etc{{\em etc.}} 



\newcommand{\TODO}[1]{{\color{red}{[TODO: #1]}}}
\newcommand{\sj}[1]{{\color{red}{[SJ:#1]}}}
\newcommand{\Angie}[1]{{\color{blue}{#1}}}

\begin{document}
%
% \title{Prognosis prediction hypergraph model for Alzheimer’s disease by Information bottleneck}
\title{HGIB: Prognosis for Alzheimer’s Disease via Hypergraph Information Bottleneck}
% \title{Leveraging Multi-Modality Data with Hypergraph Information Bottleneck for Prognosis Prediction in Alzheimer's Disease}
%
\titlerunning{HGIB}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%

% \author{Shujun Wang\inst{1}\orcidID{0000-1111-2222-3333} \and
% Angelica I Aviles-Rivero\inst{1}\orcidID{1111-2222-3333-4444} \and
% Zoe Kourtzi\inst{2}\orcidID{2222--3333-4444-5555}
% \and
% Carola-Bibiane Schönlieb\inst{1}\orcidID{2222--3333-4444-5555}}
\author{Shujun Wang\inst{1} \and
Angelica I Aviles-Rivero\inst{1} \and
Zoe Kourtzi\inst{2} 
\and \\
Carola-Bibiane Schönlieb\inst{1}}
%
\authorrunning{S. Wang et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{DAMTP, University of Cambridge, Cambridge, UK \\
\email{\{sw991,ai323,cbs31\}@cam.ac.uk}
\and
Department of Psychology, University of Cambridge, Cambridge, UK
\email{zk240@cam.ac.uk}}


%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
%Prognosis analysis of Alzheimer's disease (AD) 
Alzheimer's disease prognosis is critical for early 
%diagnosis of
Mild Cognitive Impairment patients 
%conversion 
for timely treatment to improve the patient's quality of life. Whilst existing prognosis techniques demonstrate potential results, they are highly limited in terms of using a single modality. Most importantly, they fail in considering a key element for prognosis: not all features extracted at the 
current moment
% baseline 
%Existing deep learning methods addressing this problem are limited to single modalities and ignore an essential clue: not all the features extracted from the current moment (\textit{e.g.}, captured MRI data) 
may contribute to the prognosis prediction several years later.
%, particularly under the multi-modality data setting. 
% 
To address the current drawbacks of the literature, we propose a novel hypergraph  framework based on an information bottleneck strategy (\textbf{HGIB}). Firstly, our framework seeks to discriminate irrelevant information, and therefore, solely focus on harmonising relevant information for future MCI conversion prediction (\textit{e.g.}, two years later). 
% \sj{The first drawback actually can combine with multi modality which after combination has many irrelavant information.}
% 
Secondly, our model simultaneously accounts for multi-modal data based on imaging and non-imaging modalities.
% 
HGIB uses a hypergraph structure to represent the multi-modality data and accounts for various data modality types.
%
Thirdly, the key of our model is based on a new optimisation scheme. It is based on modelling the principle of information bottleneck into loss functions that can be integrated into our hypergraph neural network.
% 
We demonstrate, through extensive experiments on ADNI, that our proposed HGIB framework
%We conduct extensive experiments on a public dataset (ADNI) for Alzheimer's disease prognosis prediction, where HGIB
outperforms existing state-of-the-art hypergraph neural networks for Alzheimer's disease prognosis. We showcase our model even under fewer labels.
%in normal supervised learning settings and settings with fewer annotations.
Finally, we further support the robustness and generalisation capabilities of our framework under both topological and feature perturbations. 
% Our results demonstrate the promise of HGIB for future research in Alzheimer’s disease prognosis prediction.

\keywords{Prognosis prediction  \and Alzheimer's disease \and Hypergraph \and Information bottleneck \and Multi-modality data}
\end{abstract}
%
%
%
\section{Introduction} \label{introduction}


Alzheimer's disease (AD) is a progressive and irreversible neurodegenerative disorder that results in a high level of dependence. The disease progresses through different stages, starting with Mild Cognitive Impairment (MCI), characterized by memory problems, and eventually leading to AD. However, not all patients diagnosed with MCI convert to Alzheimer's disease, and some may remain stable or even revert to normal. This distinction between MCI stables, MCI progressors, and MCI non-converters highlights the need for accurate prognosis prediction.
Although there is no known cure for AD, the development of algorithmic techniques for prognosis has attracted great interest from the medical community. Early treatment for MCI progress is crucial for improving patients' quality of life, making the value of accurate prognosis prediction evident. 


The literature has extensively investigated the task of predicting MCI to AD conversion from various perspectives. Early studies focused on analyzing a region of interest~\cite{mcevoy2009alzheimer,costafreda2011automated, davatzikos2011prediction}, different single modalities or neuropsychological evaluation~\cite{risacher2009baseline, qiu2009regional, fan2008structural}, and informative AD biomarkers~\cite{shaw2009cerebrospinal,hansson2006association}.
These have been widely explored using support vector machines (SVM) alone or in combination with Gaussian Radial functions~\cite{liu2022assessing,toussaint2012resting}. 
With the advent of deep learning, researchers have explored the use of convolutional neural networks (CNNs) for MCI conversion prediction employing transfer learning and pyramid networks~\cite{bae2021transfer, pan2020multi, shen2021heterogeneous,  syaifullah2021machine, zhu2021long}.



Although there have been promising results in MCI conversion prediction in the literature, there are two major drawbacks that limit their performance. 
% Firstly, existing techniques mainly rely on a single modality, such as MRI, PET, or non-imaging (genetics, magnetoencephalography) data, which may not capture the full picture of the disease progression. 
Firstly, existing techniques mainly rely on a single modality, which may not capture the full picture of the disease progression. 
% 
To address this, recent studies have emphasized the need to develop multi-modal techniques that can extract richer information~\cite{shigemizu2020prognosis,aviles2022multi,grueso2021machine}.
% 
Secondly, how to effectively extract discriminative information from the multi-modal data to facilitate conversion prediction and discard the irrelevant information from high heterogeneity multi-modality data has not been explored in the existing literature yet.



In this work, we propose a novel approach, namely the hypergraph information bottleneck strategy (HGIB), to address the existing limitations in Alzheimer's disease prognosis leveraging multi-modality data.
% 
% To overcome the challenges associated with multi-modality data, 
HGIB utilises a hypergraph structure to represent the multi-modal features and harmonises various modality data types.
% 
In contrast to existing techniques, HGIB focuses on learning discriminative representations that are meaningful with minimal but relevant information, by applying the principle of information bottleneck.
% 
\textit{To the best of our knowledge, this is the first hypergraph framework specifically designed for prognosis rather than diagnosis.}
% 
Experiments on the public ADNI dataset for Alzheimer's disease prognosis prediction demonstrate that HGIB outperforms other state-of-the-art hypergraph neural network architectures in supervised learning settings as well as with fewer annotations. Additionally, HGIB exhibits robustness against topological and feature perturbations, highlighting its potential for future research in this field.



\vspace{-2mm}
\section{Proposed Framework} \label{method}
\vspace{-2mm}

\begin{figure}[!tbp]
\centering

\includegraphics[width=12cm]{teaser.pdf}
\caption{Illustration of the whole workflow. (a) shows how hypergraph information bottleneck utilised to optimize the representation $Z$ to capture the minimal sufficient information within the input data $D=(G,I)$ to predict the MCI conversion label $Y$. (b) is the overall workflow integrating HGIB into the hypergraph neural network. HGNNP is a kind of hypergraph convolutional layer.}
\label{teaser}

\end{figure}

This section presents a detailed description of the crucial components of our proposed framework. Firstly, we elucidate the process of constructing the hypergraph from a given set of multi-modal data, and we delve into the specifics of the hypergraph convolution definition. Secondly, we explicate the fundamental principle of information bottleneck and integrate it into hypergraph neural networks.
The overview of the proposed method is illustrated in Fig.~\ref{teaser}.

% Introduction why using hypergraph for mult-modality learning + HGIB



% \Angie{to be updated}



\smallskip
\subsection{Hypergraph Modelling and Hypergraph Convolution}

To overcome the
challenges associated with multi-modality data ($I_1, I_2, ..., I_m$), we leverage a hypergraph
structure $G$ to represent the multi-modal features ($X_1, X_2, ..., X_m$) extracted from backbones. Subsequently, we employ a hypergraph neural network to predict MCI conversion.

% The main purpose of the proposed framework is to optimally balance the expressiveness and robustness of the learned representation of hypergraph structure data for accurate MCI conversion prediction.
% 
%Hypergraph is general framework to incorporate with multi-modality data which is common strategy for AD diagnosis.
% 
% To encourage the minimal and sufficient representation learning, we introduce  information bottleneck by applying this principle to hypergraph neural networks.
% 
%We will first elaborate hypergraph modelling and hypergraph convolution operation and then introduce the hypergraph information bottleneck.

\medskip
\noindent
\textbf{Hypergraph representation learning.}
We consider an undirected attributed hypergraph $G = (V, E, \textbf{H})$ with a vertex set $V$, a hyperedge set $E$, and an adjacency matrix $\textbf{H} \in \mathbb{R}^{|V| \times |E|}$ for hyperedge weight. 
% 
Each vertex in our hypergraph structure corresponds to a patient, while each hyperedge represents the relationship between a subset of vertices. Unlike in a graph structure, where an edge connects only two vertices, a hyperedge in a hypergraph connects multiple vertices, enabling the representation of higher-order relationships. This feature facilitates the grouping of subsets of vertices with common features or properties, enhancing the ability of the hypergraph to model complex relationships within the data.
% 
In our hypergraph structure, each vertex corresponds to a patient and each hyperedge represents the relationship between a subset of the vertices. Unlike in a graph structure, a hyperedge in a hypergraph connects multiple vertices instead of just two, allowing for the representation of higher-order relationships. This can be seen as the hyperedges grouping together subsets of vertices that have common features or properties.
% 
Specifically, the hyperedge weight between vertex $v$ and hyperedge $e$ can be defined as 
$h_{v,e}= 
\left\{ 
    \begin{array}{lc}
        1& \text{if} \  v \in e \\
        0& \text{otherwise}
    \end{array}
\right.
$.
Moreover, we denote the vertex attributes as $X$, which can be seen as a feature embedding. The input data can be represented as $D=(G, X)$. In the multi-modal setting, we assume $m$ modalities as input and denote them as $D=(G, (X_1, X_2, ..., X_m))$.
%the input data is
%can be overall 
%denoted as $D=(G, (X_1, X_2, ..., X_M))$ for M modalities
% and the hypergraph $G$.
%can represent high-order correlations of the data.

%How to generate the hypergraph 



% Given the input data $D$ with a hypergraph and corresponding embedding, 

% A crucial step in hypergraph learning is how to contruct the hypergraph structure. To do this, 
% %To generate such hypergraph structure, 
% we first obtain the feature embeddings $X$, from the given multi-modality data, using a pre-trained network backbone, as shown in Fig.~\ref{teaser}(b).
% We then use a neighbour strategy, in feature space, to generate the hyperedge groups following the same protocol as in \cite{gao2022hgnn}. Specifically, given a vertex as the centroid, its  k-nearest neighbours in the feature space can be connected by a hyperedge:
% \begin{equation}
%    E_k=\{N_{\text{KNN}_k}(v)|v \in V\}. 
% \end{equation}
% These hyperedge groups are further concatenated together to form a hypergraph for each modality data.
% To effectively utilize the multi-modality knowledge, we concat k different hypergraphs together to generate the final hypergraph. Specifically, the incidence matrices $H_k$ are concatenated directly, as $H=H_1\|H_2\|...\|H_k$.
% Then, we can feed the data D into Hypergraph Convolution Layer for further computation.



A crucial step in hypergraph learning is the construction of the hypergraph structure. To achieve this, we first obtain the feature embeddings $X=\{X_1, X_2, ...,\\ X_m\}$ from the multi-modality data using a pre-trained network backbone, as illustrated in Fig.~\ref{teaser}(b). We then employ a neighbor strategy in feature space to generate the hyperedge groups following the same protocol as described in \cite{gao2022hgnn}. Specifically, for each vertex, its $k$-nearest neighbors in the feature space are connected by a hyperedge, resulting in the set of hyperedges $E_k=\{N_{\text{KNN}_k}(v)|v \in V\}$.
% \begin{equation}
% E_k={N_{\text{KNN}_k}(v)|v \in V}.
% \end{equation}
% 
These hyperedge groups are concatenated together to form a hypergraph for each modality data. To effectively utilize the multi-modality knowledge, we concatenate $k$ different hypergraphs to generate the final hypergraph by $H=H_1\|H_2\|...\|H_k$. Then, we feed the resulting data $D$ into a Hypergraph Convolution Layer for further computation.

% To update the vertex information, we aggregate its neighbor vertex messages along the hyperpath:

\medskip
\noindent
\textbf{Hypergraph Convolution.}
We use spatial hypergraph convolution layers \cite{gao2022hgnn} for message aggregation. Messages can be passed either from vertex to hyperedge or from hyperedge to vertex using hyperpaths $P$, which is defined as $P(v_1,v_k) = (v_1,e_1,v_2,...,e_{k-1}, v_k)$.
% We utilise the Inter-Neighbor Relation $N$ of hypergraph $G$ as $N=\{ ( v,e  ) | w_{v,e}=1, v \in V, \ and\  e \in E \}$.
% 
% The vertex inter-neighbor set of hyperedge $e$ is  defined as $N_v(e)=\{v|vNe \}$ and the hyperedge inter-neighbor set of vertex is defined as $N_e(v)=\{e|vNe\}$.
% Therefore, to update the vertex information, we need to aggregate the messages from its hyperedge inter-neighbors $N_e(v)$. And the hyperedge inter-neighbor message is updated according to their vertex inter-neighbors $N_v(e)$. Such two-step message aggregation realises a closed message passing loop among vertices.
% Then the spatial hypergraph convolution layer reads:
% \begin{equation}
% h_e=w_e \cdot \sum_{v \in N_v(e)} \frac{x_v}{|N_v(e)|}, \ \ \ \ 
% y_v=\sigma \Bigg(\sum_{e \in N_e(v)} \frac{h_e}{|N_e(v)|} \cdot \Theta \Bigg),
% \end{equation}
% where $x_v$, $h_e$, and $y_v$ are the input, hidden, and output feature vectors. $w_e$ is a weight associated to hyperedge $e$, and $\Theta$ is a trainable parameter of current hypergraph convolution layer. $\sigma$ is a non-linear activation function,\textit{ e.g.}, ReLU($\cdot$). 
% 
We define the inter-neighbor relation $N$ of hypergraph $G$ as $N=\{ (v,e) | w_{v,e}=1, v \in V, \text{ and } e \in E \}$. The vertex inter-neighbor set of hyperedge $e$ is defined as $N_v(e)=\{v|vNe\}$, and the hyperedge inter-neighbor set of vertex $v$ is defined as $N_e(v)=\{e|vNe\}$. To update the vertex information, we aggregate the messages from its hyperedge inter-neighbors $N_e(v)$, and to update the hyperedge information, we use the vertex inter-neighbors $N_v(e)$.
% 
Thus, the spatial hypergraph convolution layer is defined as
\begin{equation}
f_e= \sum_{v \in N_v(e)} h_{v,e}  \cdot \frac{x_v}{|N_v(e)|}, \ \ \ \
{f}'_v=\sigma \Bigg(\sum_{e \in N_e(v)} \frac{f_e}{|N_e(v)|} \cdot \Theta \Bigg),
\end{equation}
where $x_v$, $f_e$, and ${f}'_v$ are the input, hidden, and output feature vectors. $\Theta$ is a trainable parameter of the current hypergraph convolution layer. $\sigma$ is a non-linear activation function, such as ReLU. The two-step message aggregation realizes a closed message passing loop among vertices, which enables the model to capture higher-order relationships between the vertices in the hypergraph.


\smallskip
\subsection{Hypergraph Information Bottleneck (HGIB)}
To balance the expressiveness and robustness of the model, we aim to optimize the vertex representation to capture the minimal sufficient information required for downstream tasks via the information bottleneck approach \cite{tishby2000information}. The Hypergraph Information Bottleneck (HGIB) approach, as shown in Fig. \ref{teaser}(a), is derived from the Graph Information Bottleneck \cite{wu2020graph}, which requires the node representation $Z_v$ to minimize the information from hypergraph-structured data $D$ while maximizing the information to prediction $Y$.
% 
% At the optimisation level, a major challenge for HGIB numerical realisation is
% is that the independent and identically distributed (IID) assumption of vertices are not feasible for many real-world scenarios.
% 
% Therefore, we rely on a local-dependence assumption for hypergraph-structural data: given the data related to the limited number of neighbours of vertex $v$, the data in the rest of the hypergraph is independent of $v$.
 % 
 However, a major challenge in realizing HGIB numerically is the assumption of independent and identically distributed (IID) vertices, which is not feasible for many real-world scenarios. Therefore, we rely on a local dependence assumption for hypergraph-structured data, whereby given data related to a limited number of neighbors of vertex $v$, the data in the rest of the hypergraph is independent of $v$.
 % 
 % 
 % The optimal representation follows the Markovian dependence. The representation of each vertex is updated by incorporating its neighbours with respect to the hypergraph representation $X$.
 We assume a Markovian dependence to obtain the optimal representation, whereby the representation of each vertex is updated by incorporating its neighbors with respect to the hypergraph representation $X$.
 % 
The information bottleneck seeks to optimise
 %is reduced to the following optimization:
\begin{equation}
\underset{\mathbb{P}(Z^l|D) \in \Omega }{min} \mathcal{L}_{\text{HGIB}}(X,Y;Z^l):= [-I(Y;Z^l)+\beta I(X;Z^l)],
\end{equation}
where $\Omega$ characterises the space of conditional distribution of $Z^l$ given data $D$, and $\beta$ is a balancing weight. $l$ represents the $l$-th hypergraph convolution layer. 

We now define the mutual information $I(X;Z^{l})$,  between the initial vertex embedding and updated vertex embedding, following~\cite{nguyen2010estimating}. This yield to the Cross-Entropy loss that reads:
\vspace{-2mm}
\begin{equation}
    I(Y;Z^l) \rightarrow -\sum_{v \in V} \text{CE}(Z_v^lW_{out};Y_v),
\end{equation}
% \vspace{-2mm}
where $W_{out}$ is the weight of projector to predict the MCI conversion labels.
%
%
% \subsubsection{HGIB Estimation}\\
% \\
% \textbf{Lemma 1} (Nguyen, Wainright & Jordan's bound) For any two random variables $X_1$, $X_2$, and any brivariate function $g:g(X_1, X_2) \in \mathbb{R}$, we have
% \begin{equation*}
% I(X_1, X_2) \geqslant \mathbb{E} [g(X_1, X_2)]-\mathbb{E}_{\mathbb{P}(X_1)\mathbb{P}(X_2)} [\text{exp}\left (g\left (X_1, X_2\right )-1\right )].
% \end{equation*}
% We use this lemma for $I(Y;Z^l)$ and set $g(Y,Z^l)=1+\text{log}\frac{\prod_{v \in V} Cat(Z^lW_{out})}{\mathbb{P}(Y)}$. Then $I(Y;Z^l)$ reduces to the Cross-Entropy loss by ignoring constants, \textit{i.e.,}
% $$
% I(Y;Z^l) \rightarrow -\sum_{v \in V} \text{CE}(Z_v^lW_{out};Y_v).
% $$
%
% \if 0
% \textbf{Proposition 1. }
% % 
% % \begin{equation*}
% % \underset{\mathbb{P}(X|D) \in \Omega }{min} \text{GIB} _\beta(D,Y;X):= [-I(Y;X)+\beta I(D;X)],
% % \end{equation*}
% % 
% $I(X;Z^{l})  \leqslant I(X;Z^{l-1})$.
%
% \textbf{Proof.} Since the conditional distribution of $Z_v^l$ depends only on 
% {$X,Z^{l-1},Z^l$} forms a Markov chain in this order $X \rightarrow Z^{l-1} \rightarrow Z^l$.
% According to data-processing inequality \cite{beaudry2011intuitive}, we have $I(X;Z^{l})  \leqslant I(X;Z^{l-1})$.
% \fi
%
% $I(X;Z^{l})$ measures the mutual information between the initial vertex embedding and updated vertex embedding. It has an upper bound and can be derived to a tractable objective to optimize as follow.
%
%\textbf{Proposition 1. } For any distribution $\mathbb{Q}(Z^l)$ for $Z^l$, we have 
%$I(X;Z^{l})  \leqslant  \text{KL}(\mathbb{P}(Z^l|X)\|\mathbb{Q}(Z^l))$.
%
%To specify the upper bound for $I(X;X^{l})$, we assume $\mathbb{Q}(Z^l)$ is a non-informative prior and the elements in $X^{l}$ are IID Bernoulli distributions: $Z^l = \bigcup_{i,j} \{ z_{i,j} \in  \{ 0,1  \} |z_{i,j}\overset{IID}{\sim } \text{Bernoulli(0.5)} \}$. We assume the elements in $\mathbb{Q}(Z^l)$ have a probability of 0.5. Thus the estimation of $I(X;X^{l})$ is written as
%$$I(X;X^{l})=\frac{1}{nm} \sum_{i=1}^{n}\sum_{j=1}^{m} \text{KL}\left (\text{Bernoulli}\left (z_{ij}^l\right)\| \text{Bernoulli}\left (0.5\right )\right ).$$
We then assume that the elements in $X^{l}$ are IID Bernoulli distributions: $Z^l = \bigcup_{i,j} \{ z_{i,j} \in  \{ 0,1  \} |z_{i,j}\overset{IID}{\sim } \text{Bernoulli(0.5)} \}$. So the mutual information can be defined as $I(X;Z^{l})=\frac{1}{nm} \sum_{i=1}^{n}\sum_{j=1}^{m} \text{KL}\left (\text{Bernoulli}\left (z_{ij}^l\right)\| \text{Bernoulli}\left (0.5\right )\right )$. Here, $\text{KL}$ denotes the Kullback-Leibler divergence between two Bernoulli distributions. 

\vspace{-2mm}
\subsection{Optimisation Scheme}
\vspace{-2mm}

Our main task is MCI prediction conversion. This problem is taken from the perspective of a three class prediction task (NC, MCI, and AD). We have as basis a cross-entropy loss for classification. In the medical domain, it is usual to encounter with the class imbalance problem. To address this issue, we incorporate a focal loss. We then define our overall optimisation scheme as
% 
%In this paper, we focus on the three class prediction task. So the cross entropy loss is basically applied for classification.
%Considering the class imbalance problem for the task setting, we further incorporate focal loss.
%Therefore, the final optimization loss function is the combination of CE loss, focal loss, and HGIB loss:
\begin{equation}
    % L = L_{\text{CE}} + \beta L_{\text{focal loss}} + \gamma L_{\text{HGIB}}.\\
    \mathcal{L}_{total} = \frac{1}{|V|} \sum_{v \in V}\left \Big\{\text{CE}(P_v;Y_v) + \mu \left [-\alpha (1-P_v)^\gamma \text{log}(P_v) \right ]\right \}  + \xi \frac{1}{L}\sum_{l=1}^{L} \mathcal{L}_{\text{HGIB}},
\end{equation}
where $\mu$ and $\xi$ are balancing parameters. $\alpha$ and $\gamma$ are two hyper-parameters for the focal loss~\cite{lin2017focal} in our experiments, we set their values to 2 and 0.5 respectively.
%nd been set as 2 and 0.5, respectively.

% \vspace{-3mm}
\section{Experimental Results}
\label{Experiments}


% \begin{figure}[htbp]
% \centering
% \begin{minipage}[t]{0.42\textwidth}
% \centering
% \includegraphics[width=6cm]{Plot1.pdf}
% \caption{World Map}
% \end{minipage}
% \begin{minipage}[t]{0.52\textwidth}
% \centering
% \includegraphics[width=6cm]{Plot3.pdf}
% \caption{Concrete and Constructions}
% \end{minipage}
% \end{figure}





% \begin{figure}[htbp]
% \centering

% \includegraphics[width=6cm]{Plot3.pdf}
% \caption{World Map}

% \end{figure}










In this section, we describe in detail the set of experiments performed to validate our proposed HGIB framework for prognosis prediction of Alzheimer's Disease.

%We aim to show the effectiveness and robustness of proposed HGIB on the task of prognosis prediction of Alzheimer's Disease.
% 
 

\subsection{Dataset Description}
We conduct  our evaluation on the  Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset\footnote{Data used in the preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (\url{adni.loni.usc.edu}).}.
% 
ADNI is a longitudinal multi-centre and multi-modality study designed for the early detection and tracking of Alzheimer’s disease. 
The dataset contains four categories: Normal Control (NC), early Mild Cognitive Impairment (EMCI), late Mild Cognitive Impairment (LMCI), and Alzheimer’s disease (AD) at the Baseline Visit while only three categories afterwards: NC, Mild Cognitive Impairment (MCI), and AD.
% 
We focus on patients diagnosed with MCI (EMCI/LMCI) at the baseline visit.
% 
The goal is to predict the diagnosis of MCI conversion within a fixed two-year window to identify whether subjects converted to NC and AD or not, based on the multi-modality data including MRI, PET, and Non-imaging information.
% 
The Non-imaging information consists of demographic, genetic, and cognitive features, \textit{e.g.,} age, gender, education, APOE4, MMSE, ADNI-MEM \cite{crane2012development}, ADNI-EF \cite{gibbons2012composite}.
% 
After the filter, we got 248 patients with complete three modalities from ADNI-2.
% 

\subsection{Dataset Pre-processing}
For the data pre-processing, all MRI volumes are processed following (1) anterior commissure (AC)-posterior commissure (PC) alignment, (2) skull stripping, (3) intensity correction, (4) cerebellum removal, and (5) linear alignment to a template MRI.
% 
The corresponding PET volumes are aligned to their MRI volume via linear registration.
% 
For the Non-imaging data, we normalise each feature in the range of [0,1] before feeding them into the network.


% All MR images were pre-processed via four steps: (1) anterior commissure (AC)-posterior commissure (PC) alignment, (2) skull stripping, (3) intensity correction, (4) cerebellum removal, and (5) linear alignment to a template MRI. Each PET image was also aligned to its corresponding MRI via linear registration. Hence, there is spatial correspondence between MRI and PET for each subject.

\subsection{Evaluation Protocol}
We  discuss the following conditions in our experiments: (1) the classification accuracy of HGIB compared with state-of-the-art hypergraph neural network methods; (2) performance comparison under different label counts of our method vs. existing techniques;
%with less annotations compared with others; 
(3) robustness analysis under two kinds of attacks. 
We follow standard protocol in the medical domain and use the area under the ROC curve (AUC), Positive predictive value (PPV \%), and negative predictive value (NPV \%) to measure the performance.
For the results, we report the average performance and standard deviation over five independent runs. 

We implemented our framework using PyTorch \cite{NEURIPS2019_9015} and DHG\footnote{\url{https://deephypergraph.com/#/}} library on one NVIDIA A100 GPU. Our framework was optimised with the Adam algorithm for 2,000 epochs. The learning rate was set as  1× 10$^{-4}$ and decreased to 0. We set the number of neighbours as 20 when constructing the hypergraph.
% 
We empirically set the hyper-parameters $\mu$ and $\xi$ as 1 and 10 respectively.


\subsection{Results \& Discussion}

\textbf{Comparison to Other Hypergraph Neural Networks.}
We start evaluating our framework against 
%We compare our method with other 
three state-of-the-art hypergraph neural networks.
% 
HGNN~\cite{feng2019hypergraph} is a hypergraph neural network based on spectral convolution.
DHGNN \cite{jiang2019dynamic} exploits dynamically updating hypergraph structure on each layer.
% 
While HGNN+~\cite{gao2022hgnn} is an extended version of HGNN which is a general high-order multi-modal data correlation modelling framework.
% 

We report the quantitative comparison of our technique vs. existing techniques in Table
%The comparison results with the above methods are shown in Table 
\ref{tab:results-SOTA}.
In a closer look at this table, we observe that 
%It is observed that 
our HGIB framework reports the best AUC performance on NC and MCI categories and best average AUC and NPV results. 
% 
And the AUC performance of AD generates the comparable performance (0.8492) to the top value (0.8516).
% 
The highest NPV value of 76.19\% also indicates that HGIB is more reliable to identify true negative cases and avoiding false negatives.
% 
Across all the results, our framework demonstrates that
%it is demonstrating that 
utilising the information bottleneck can further improve the network prognosis prediction ability. To further support our experimental results, we ran  set of statistical tests. Firstly, we ran a non-parametric test for multiple comparisons. In particular, we use the Friedman test along with the Kendall's coefficient of concordance with 95\% confidence intervals as measure of the effect size for the Friedman test. The results are displayed in Fig.~\ref{fig2}(a). We can then conclude that there is a significant difference in performance $\chi^2_{Friedman} (3)= 5.16$. The effect size $W_{Kendall} = 0.11$ with 95\% CI.  We then performed a pair-wise comparison using the non-parametic Wilcoxon test yielding to $V_{Wilcoxon}= 17.50, 30, 40$ for DHGNN vs. HGIB, HGNN vs. HGIB and HGNN+ vs. HGIB, respectively. 

\begin{figure}[!t]
\centering
\setlength{\abovecaptionskip}{0pt}
\setlength{\belowcaptionskip}{-2pt}
\subfigure[]{\includegraphics[width=0.45\linewidth]{Plot1.pdf}}
\subfigure[]{\includegraphics[width=0.53\linewidth]{Plot3.pdf}}
\caption{Statistical analysis of our technique vs. 
existing ones. (a) Displays a outcome of the non-parametric Friedman test. (b) Displays pair-wise comparison performed using the Wilcoxon test.}
\label{fig2}
\end{figure}

  \begin{table*} [!t]
    \centering
    \caption{Comparison of our method (HGIB) and existing hypergraph techniques. 
    % All comparisons are run over 5 random times on the same conditions. 
    The top results are highlighted in \textbf{bold}.}
    \label{tab:results-SOTA}
    {
        % \setlength\tabcolsep{1.5pt}
        \setlength{\tabcolsep}{0.2mm}{
        \begin{tabular}{l|c|c|c|c|c|c}
            \toprule[1pt]
            
             \multirow{2}{*}{\textbf{Methods}} & \multicolumn{3}{c|}{\textbf{AUC}} &
             \multirow{2}{*}{\tabincell{c}{\textbf{AUC}\\ \textbf{average}}} & \multirow{2}{*}{\tabincell{c}{\textbf{PPV}\\ \textbf{average}}} & \multirow{2}{*}{\tabincell{c}{\textbf{NPV}\\ \textbf{average}}} \\
             % \tabincell{c}{\textbf{CIDDG}\\ \cite{li2018deep}}\\
             \cline{2-4}  & \textbf{NC} & \textbf{MCI} & \textbf{AD} &  \T \B \\
             \hline
            \T
            \textbf{DHGNN}~\cite{jiang2019dynamic} & $0.6437\pm 0.08$ & $0.5546\pm 0.09$     &$0.6841\pm 0.11$  & $0.6275$ & $50.88$  & $69.89$  \\ 
            
            \textbf{HGNN}~\cite{feng2019hypergraph} &  $0.7114\pm 0.02$ &  $0.6407\pm 0.04$   & \cellcolor[HTML]{D7FFD7}$\textbf{0.8516}\pm 0.03$  & $0.7346$ &\cellcolor[HTML]{D7FFD7}$\textbf{63.49}$  & $74.37$   \\ 

            \textbf{HGNN+}~\cite{gao2022hgnn} &  $0.7454\pm 0.04$ &  $0.6532\pm 0.07$   & $0.8325\pm 0.07$  & $0.7437$ &$55.07$  & $74.03$   \\ 

            \hline
            \textbf{HGIB} (Ours) &  \cellcolor[HTML]{D7FFD7}$\textbf{0.7504}\pm 0.03$ &  \cellcolor[HTML]{D7FFD7}$\textbf{0.6789}\pm 0.03$   & $0.8492\pm 0.05$  & $\cellcolor[HTML]{D7FFD7}\textbf{0.7595}$ &$60.98$  & $\cellcolor[HTML]{D7FFD7}\textbf{76.19}$   \\ 

            \toprule[1pt]
        \end{tabular}
    }}
\end{table*}

%\sj{add one para for the figure anlaysis statistical analysis}

  \begin{table*} [!t]
    \centering
    \caption{Comparison of our method (HGIB) and existing hypergraph techniques under different training sample settings. 
    % All comparisons are run 5 random times on the same conditions. 
    The top results are highlighted in \textbf{bold}.}
    \label{tab:results-efficient}
    {
        % \setlength\tabcolsep{1.5pt}
        % \resizebox{\textwidth}{
        \setlength{\tabcolsep}{0.5mm}{
        \begin{tabular}{l|c|c|c|c|c|c|c|c|c}
            \toprule[1pt]
            
             \multirow{2}{*}{\textbf{Methods}} & \multicolumn{3}{c|}{\textbf{80\% }} &  \multicolumn{3}{c|}{\textbf{60\% }} & \multicolumn{3}{c}{\textbf{40\% }} \\
             \cline{2-10}& \textbf{AUC} & \textbf{PPV}& \textbf{NPV} & \textbf{AUC} & \textbf{PPV}& \textbf{NPV} & \textbf{AUC} & \textbf{PPV}& \textbf{NPV} \\
             \hline
            \T
            \textbf{DHGNN}~\cite{jiang2019dynamic} & $0.7208$ & $56.08$     &$73.71$  & $0.6981$  & $53.20$ &$71.43$  & $0.6911$  & $47.05$ &$72.75$ \\ 
            
            \textbf{HGNN}~\cite{feng2019hypergraph} & $0.7346$ & \cellcolor[HTML]{D7FFD7}$\textbf{63.49}$     &$74.37$  & $0.7300$  & $55.60$ &$74.68$  & $0.7282$  & $58.84$ &$75.51$  \\ 

            \textbf{HGNN+}~\cite{gao2022hgnn} & $0.7437$ & $55.07$     &$74.03$  & $0.7425$  & $55.51$ &$74.71$  & $0.7162$  & $55.90$ &$73.62$   \\ \hline

            \textbf{HGIB} (Ours) & \cellcolor[HTML]{D7FFD7}$\textbf{0.7595}$ & $60.98$     &\cellcolor[HTML]{D7FFD7}$\textbf{76.19}$  & \cellcolor[HTML]{D7FFD7}$\textbf{0.7443}$  & \cellcolor[HTML]{D7FFD7}$\textbf{57.93}$ &\cellcolor[HTML]{D7FFD7}$\textbf{76.63}$  & \cellcolor[HTML]{D7FFD7}$\textbf{0.7393}$  & \cellcolor[HTML]{D7FFD7}$\textbf{60.81}$ &\cellcolor[HTML]{D7FFD7}$\textbf{76.22}$  \\ 

            \toprule[1pt]
        \end{tabular}
        }}
    % }
\end{table*}

\smallskip
\textbf{Performance Comparison over Different Label Counts.}
% To show the efficiency and effectiveness of the proposed method with limited labelled data, we ran another set of experiments under three different settings with different labels counts: 80\%/60\%/40\% training patients.
% % ; (2) 60\% training patients; and (3) 40\% training patients. 
% The numerical comparison results is reported in Table~\ref{tab:results-efficient}.
% % 
% We can observe that our proposed 
% %As we can see, 
% HGIB outperforms all compared techniques.
% Besides, even trained with fewer annotated data samples, we observed a slight decrease in performance compared to when the method was trained with the full set of annotated data.
% It suggests that our method has the ability to effectively learn from limited data and generalise well to the remaining testing data.
% This can be explained that HGIB can efficient use of available data and shows model ability to identify relevant features and patterns in the data, which is useful for  prognosis prediction.
% 
To demonstrate the effectiveness of our proposed method with limited labelled data, we conducted experiments with three different label counts (80\%, 60\%, and 40\% of training patients). The results are reported in Table 2, which shows that HGIB outperforms all compared techniques. We also observed that even when trained with fewer annotated data samples, our method still achieved good performance with a slight decrease compared to the full set of annotated data. This suggests that HGIB can effectively learn from limited data and generalize well to the remaining testing data by identifying relevant information (\textit{e.g.}, features and patterns), thus improving prognosis prediction.

\smallskip
\textbf{Robustness Analysis under Attacks.}
To study the robustness of the proposed HGIB under the hypergraph topology and feature tasks, we conduct experiments by (1) randomly drop 20\% hyperedges from the original hypergraph for structure attack; (2) randomly inject feature noise to the extracted feature embedding $X$ for feature attack. 
% 
Specifically, we define the mean of the maximum value of each vertex feature as $r$, random Gaussian noise as $\epsilon \sim  N(0,1)$, and feature noise ratio as $\rho$.
We then calculate noise according to $\eta=\rho \cdot r \cdot  \epsilon$. 
We set $\rho$ as 0.01 in the experiments.
The results are shown in Table~\ref{tab:results-robust}.
% 
% Our method HGIB consistently outperforms the previous state-of-the-art HGNN+ \cite{gao2022hgnn} when dropping hyperedges or adding feature noise.
% This shows that HGIB makes the model more robust for either structure or feature perturbations, and further supporting our proposed framework in terms of generalisation and robustness.
% 
The results, shown in Table 3, demonstrate that HGIB consistently outperforms the previous state-of-the-art HGNN+~\cite{gao2022hgnn} in both scenarios, indicating that HGIB enhances the model's robustness for structure and feature perturbations, supporting its effectiveness for generalization and robustness.






  \begin{table*} [!t]
    \centering
    \caption{Robustness Analysis.
    % We use two type of attacks topological and feature. 'Drop' means random drop 20\% hyperedges and Noise means noise injection  to the feature embedding. 
    The top results are highlighted in \textbf{bold} font.}
    \label{tab:results-robust}
    {
        % \setlength\tabcolsep{1.5pt}
        \setlength{\tabcolsep}{0.2mm}{
        \begin{tabular}{l||c|c||c|c||c|c}
            \toprule[1pt]
            \textbf{Methods} & \textbf{Attack} & \textbf{AUC} & \textbf{Attack} & \textbf{AUC} & \textbf{Attack} & \textbf{AUC}
              \T \B \\
             \hline
            \T
            \textbf{HGNN+}~\cite{gao2022hgnn} & - & $0.7437\pm0.05$ & Drop & $0.7155\pm0.02$ & Noise & $0.7061\pm0.04$   \\

             \textbf{HGIB} (Ours) &-  & $\textbf{0.7595}\pm 0.02$ & Drop &$\textbf{0.7452}\pm 0.02$  & Noise &$\textbf{0.7326}\pm 0.01$   \\ 
            \hline
            \toprule[1pt]
        \end{tabular}
    }}
\end{table*}

\section{Conclusion}
\label{conclusion}


Our proposed HGIB demonstrated promising results in addressing the challenges associated with Alzheimer's disease prognosis leveraging multi-modal data. By utilising a hypergraph structure to represent the multi-modal features and enforcing learning discriminative representations with the help of the principle of information bottleneck, HGIB outperforms other state-of-the-art hypergraph neural network architectures in supervised learning settings and under  fewer annotations. Our results also demonstrated better robustness of HGIB under both topological and feature perturbations. The success of HGIB highlights the potential of hypergraph-based methods in the field of Alzheimer's disease prognosis prediction and sets a foundation for future research in this area.





\section{Acknowledgement}
This work was supported by grants to: 
SW from Wellcome Trust 221633/Z/20/Z;
AIAR from CMIH and CCIMI, University of Cambridge;
ZK acknowledges support from the Biotechnology and Biological Sciences Research Council H012508 and BB/P021255/1, Alan Turing Institute TU/B/000095, Wellcome Trust \\205067/Z/16/Z, 221633/Z/20/Z, Royal Society INF/R2/202107;
CBS from the Philip Leverhulme Prize, the Royal Society Wolfson Fellowship, the EPSRC advanced career fellowship EP/V029428/1, EPSRC grants EP/S026045/1 and EP/T003553/1, EP/N014588/1, EP/T017961/1,
the Wellcome Innovator Awards 215733/Z/19/Z and 221633/Z/20/Z, the European Union Horizon 2020 research and innovation programme under the Marie Skodowska-Curie grant agreement No. 777826 NoMADS,
the Cantab Capital Institute for the Mathematics of Information and the Alan Turing Institute.


% \clearpage





\bibliographystyle{splncs04}
\bibliography{ref}
%

\end{document}
