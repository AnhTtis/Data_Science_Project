%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf]{acmart}
%% Specific for WWW'20
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}


\usepackage{soul}

\usepackage{multirow}
\usepackage{enumitem}
\usepackage{microtype}
\usepackage{hyperref}

\usepackage{subcaption}

\newcommand\BibTeX{B\textsc{ib}\TeX}
\newcommand{\stitle}[1]{\noindent{\textbf{#1}}}

\DeclareMathAlphabet{\mathpzc}{OT1}{pzc}{m}{it}

% MACROS==========================================================
\newcommand{\one} {\mathpzc{1} }
\newcommand{\two} {\mathpzc{2} }
\newcommand{\four} {\mathpzc{4} }


\newcommand{\bigS} {\mathcal{S} }
\newcommand{\bigX} {\mathcal{X} }
\newcommand{\bigY} {\mathcal{Y} }
\newcommand{\bigJ} {J}
\newcommand{\bigK} {K}
\newcommand{\bigU} {\mathcal{U}}
\newcommand{\bigH} {\mathcal{H} }
\newcommand{\bigD} {\mathcal{D} }
\newcommand{\bigC} {\mathcal{C} }
\newcommand{\bigA} {\mathcal{A} }
\newcommand{\bigG} {\mathcal{G} }

\newcommand{\smalld} {\mathpzc{dim} }
\newcommand{\lstmd} {\mathpzc{d} }
\newcommand{\smallh} {h}
\newcommand{\smalli} {\mathpzc{i} }
\newcommand{\smallx} {x}
\newcommand{\smally} {y}
\newcommand{\smalls} {s}
\newcommand{\smalll} {l}
\newcommand{\smallz} {z}
\newcommand{\smalln} {n}
\newcommand{\smallj} {j}
\newcommand{\smallk} {k}
\newcommand{\smallu} {u}
\newcommand{\smalla} {a}
\newcommand{\smallt} {t}
\newcommand{\smallv} {v}
\newcommand{\smallb} {b}
\newcommand{\smallm} {m}
\newcommand{\smallq} {q}
\newcommand{\smallg} {g}
\newcommand{\smallr} {r}
\newcommand{\smallc} {c}
\newcommand{\smallf} {f}
\newcommand{\smalle} {e}
\newcommand{\smallp} {p}

\newcommand{\realR} {\mathbb{R} }
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\newcommand{\noiob} {$\mathpzc{w/o}~\mathtt{IOB}$}

\newcommand{\ourmodel}{$\mathsf{SCot}$}
\newcommand{\myvalue}[1] {$\mathtt{#1}$}
\newcommand{\subvalue}[1] {\mathtt{#1}}
\newcommand{\myspecial}[1] {\texttt{#1}}

\newcommand{\myNum}[1]{(\emph{#1})}
\def\wo{~\mathpzc{w/o}}
%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\copyrightyear{2023}
\acmYear{2023}
\setcopyright{acmlicensed}\acmConference[WWW '23]{Proceedings of the ACM Web Conference 2023}{May 1--5, 2023}{Austin, TX, USA}
\acmBooktitle{Proceedings of the ACM Web Conference 2023 (WWW '23), May 1--5, 2023, Austin, TX, USA}
\acmPrice{15.00}
\acmDOI{10.1145/3543507.3583541}
\acmISBN{978-1-4503-9416-1/23/04}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Toward Open-domain Slot Filling via Self-supervised Co-training}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.

\author{Adib Mosharrof}
\affiliation{%
  \institution{University of Kentucky}
  \city{Lexington}
  \state{KY}
  \country{USA}
}
\email{amo304@g.uky.edu}

\author{Moghis Fereidouni}
\affiliation{%
  \institution{University of Kentucky}
  \city{Lexington}
  \state{KY}
  \country{USA}
}
\email{mfe261@uky.edu}

\author{A.B. Siddique}
\affiliation{%
  \institution{University of Kentucky}
  \city{Lexington}
  \state{KY}
  \country{USA}
}
\email{siddique@cs.uky.edu}
%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
%\renewcommand{\shortauthors}{Trovato and Tobin, et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
Slot filling is one of the critical tasks in modern conversational systems.
The majority of existing literature employs supervised learning methods, which require labeled training data for each new domain.
Zero-shot learning and weak supervision approaches, among others, have shown promise as alternatives to manual labeling.
Nonetheless, these learning paradigms are significantly inferior to supervised learning approaches in terms of performance.
To minimize this performance gap and demonstrate the possibility of open-domain slot filling, we propose a \textbf{S}elf-supervised \textbf{Co}-\textbf{t}raining framework, called {\ourmodel}, that requires zero in-domain manually labeled  training examples and works in three phases.
Phase one acquires two sets of complementary pseudo labels automatically.
Phase two leverages the power of the pre-trained language model BERT, by adapting it for the slot filling task using these sets of pseudo labels.
In phase three, we introduce a self-supervised co-training mechanism, where both models automatically select high-confidence soft labels to further improve the performance of the other in an iterative fashion. 
Our thorough evaluations show that {\ourmodel}  outperforms state-of-the-art models by 45.57\% and 37.56\% on \myspecial{SGD} and \myspecial{MultiWoZ} datasets, respectively.
Moreover, our proposed framework {\ourmodel} achieves comparable performance when compared to state-of-the-art fully supervised models.

\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10010147.10010178.10010179.10003352</concept_id>
       <concept_desc>Computing methodologies~Information extraction</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010147.10010178.10010179.10010184</concept_id>
       <concept_desc>Computing methodologies~Lexical semantics</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
   <concept>
       <concept_id>10010147.10010257.10010258.10010262.10010277</concept_id>
       <concept_desc>Computing methodologies~Transfer learning</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Information extraction}
\ccsdesc[300]{Computing methodologies~Lexical semantics}
\ccsdesc[500]{Computing methodologies~Transfer learning}

% \keywords{open-domain slot filling, co-training, weak supervision.}%, slot filling,  natural language understanding, natural language processing.}


%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\input{intro}
\input{background}
\input{model}
\input{experiments}
\input{results}
\input{related}
\input{conclusion}
\balance



%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}

%\newpage
%\appendix
%\input{impl_details}

\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
