%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Docker is proven to be a must-have in the modern software development cycle.
% However, writing Dockerfiles is a time-consuming and error-prone activity for developers.
We evaluated the effectiveness of Deep Learning (and, specifically, \approach) for the automatic generation of Dockerfiles. 
The results show that, while \approach works very well on small Dockerfiles, it struggles with larger ones.
After having deeply analyzed this phenomenon, we identified two possible issues that must be addressed before deploying a working DL-based solution for this task. First, it is necessary to \textit{build a larger dataset}, which is not easy, given that we used the largest collection of open-source Dockerfiles available. Second, it is necessary to \textit{devise a different stopping criterion} for fine-tuning \approach since the one typically used for coding tasks (based on BLEU-4) likely causes an early stop, which does not allow the model to properly complete the learning process.

% Other interesting points to investigate as a future research agenda are (i) the generation of \textit{docker-compose} files, which are commonly used in Docker-based projects, and (ii) making context-aware generations, in terms of build and execution environment.
