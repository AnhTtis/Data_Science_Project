@INPROCEEDINGS{panayatov2015librispeech, author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},  booktitle={2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},   title={{Librispeech: An ASR corpus based on public domain audio books}},   year={2015},  volume={},  number={},  pages={5206-5210},  doi={10.1109/ICASSP.2015.7178964}}

@article{hermann2015teaching,
  title={Teaching machines to read and comprehend},
  author={Hermann, Karl Moritz and Kocisky, Tomas and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{rajpurkar-etal-2018-know,
    title = "Know What You Don{'}t Know: Unanswerable Questions for {SQ}u{AD}",
    author = "Rajpurkar, Pranav  and
      Jia, Robin  and
      Liang, Percy",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-2124",
    doi = "10.18653/v1/P18-2124",
    pages = "784--789",
    abstract = "Extractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuADRUn, a new dataset that combines the existing Stanford Question Answering Dataset (SQuAD) with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuADRUn, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuADRUn is a challenging natural language understanding task for existing models: a strong neural system that gets 86{\%} F1 on SQuAD achieves only 66{\%} F1 on SQuADRUn. We release SQuADRUn to the community as the successor to SQuAD.",
}


@inproceedings{merity2016pointer,
  title={Pointer sentinel mixture models},
  author={Merity, Stephen and Xiong, Caiming and Bradbury, James and Socher, Richard},
  booktitle={ICLR},
  year={2017}
}

@inproceedings{kudo2018subword,
  title={Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates},
  author={Kudo, Taku},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={66--75},
  year={2018}
}

@article{johnson2019billion,
  title={Billion-scale similarity search with {GPUs}},
  author={Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  journal={IEEE Transactions on Big Data},
  volume={7},
  number={3},
  pages={535--547},
  year={2019},
  publisher={IEEE}
}

@article{jegou2010product,
  title={Product quantization for nearest neighbor search},
  author={Jegou, Herve and Douze, Matthijs and Schmid, Cordelia},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={33},
  number={1},
  pages={117--128},
  year={2010},
  publisher={IEEE}
}

@article{gulcehre2015using,
  title={On using monolingual corpora in neural machine translation},
  author={Gulcehre, Caglar and others},
  journal={arXiv preprint arXiv:1503.03535},
  year={2015}
}

@inproceedings{Chorowski2017,
  author={Jan Chorowski and Navdeep Jaitly},
  title={Towards Better Decoding and Language Model Integration in Sequence to Sequence Models},
  year=2017,
  booktitle={Proc. Interspeech 2017},
  pages={523--527},
  doi={10.21437/Interspeech.2017-343},
  url={http://dx.doi.org/10.21437/Interspeech.2017-343}
}

@inproceedings{khandelwal2020generalization,
  title={{Generalization through Memorization: Nearest Neighbor Language Models}},
  author={Urvashi Khandelwal and Omer Levy and Dan Jurafsky and Luke Zettlemoyer and Mike Lewis},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2020}
}

@inproceedings{guu2020retrieval,
  title={Retrieval augmented language model pre-training},
  author={Guu, Kelvin and Lee, Kenton and Tung, Zora and Pasupat, Panupong and Chang, Mingwei},
  booktitle={International Conference on Machine Learning},
  pages={3929--3938},
  year={2020},
  organization={PMLR}
}

@inproceedings{he2021efficient,
  title={Efficient Nearest Neighbor Language Models},
  author={He, Junxian and Neubig, Graham and Berg-Kirkpatrick, Taylor},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={5703--5714},
  year={2021}
}

@article{graves2012sequence,
  title={Sequence transduction with recurrent neural networks},
  author={Graves, Alex},
  journal={arXiv preprint arXiv:1211.3711},
  year={2012}
}


@inproceedings{jain20_interspeech,
  author={Mahaveer Jain and Gil Keren and Jay Mahadeokar and Geoffrey Zweig and Florian Metze and Yatharth Saraf},
  title={{Contextual RNN-T for Open Domain ASR}},
  year=2020,
  booktitle={Proc. Interspeech 2020},
  pages={11--15},
  doi={10.21437/Interspeech.2020-2986}
}

@inproceedings{pundak2018deep,
  title={Deep context: end-to-end contextual speech recognition},
  author={Pundak, Golan and Sainath, Tara N and Prabhavalkar, Rohit and Kannan, Anjuli and Zhao, Ding},
  booktitle={2018 IEEE spoken language technology workshop (SLT)},
  pages={418--425},
  year={2018},
  organization={IEEE}
}

@inproceedings{sathyendra2022contextual,
  title={Contextual Adapters for Personalized Speech Recognition in Neural Transducers},
  author={Sathyendra, Kanthashree Mysore and others},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={8537--8541},
  year={2022},
  organization={IEEE}
}

@inproceedings{sathyendra2022contextual_,
  title={Contextual Adapters for Personalized Speech Recognition in Neural Transducers},
  author={Sathyendra, Kanthashree Mysore and Muniyappa, Thejaswi and Chang, Feng-Ju and Liu, Jing and Su, Jinru and Strimel, Grant P and Mouchtaris, Athanasios and Kunzmann, Siegfried},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={8537--8541},
  year={2022},
  organization={IEEE}
}

@inproceedings{gourav2021personalization,
  title={Personalization strategies for end-to-end speech recognition systems},
  author={Gourav, Aditya and others},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7348--7352},
  year={2021},
  organization={IEEE}
}

@inproceedings{gourav2021personalization_,
  title={Personalization strategies for end-to-end speech recognition systems},
  author={Gourav, Aditya and Liu, Linda and Gandhe, Ankur and Gu, Yile and Lan, Guitang and Huang, Xiangyang and Kalmane, Shashank and Tiwari, Gautam and Filimonov, Denis and Rastrow, Ariya and others},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7348--7352},
  year={2021},
  organization={IEEE}
}

@INPROCEEDINGS{kocour2021interspeech,
   author = "Martin Kocour and others",
   title = {{Boosting of Contextual Information in ASR for Air-Traffic Call-Sign Recognition}},
   pages = "3301--3305",
   booktitle = "Proceedings Interspeech 2021",
   journal = "Proceedings of Interspeech - on-line",
   volume = 2021,
   number = 8,
   year = 2021,
   location = "Brno, CZ",
   publisher = "International Speech Communication Association",
   ISSN = "1990-9772",
   doi = "10.21437/Interspeech.2021-1619",
   language = "english",
}

@INPROCEEDINGS{kocour2021interspeech_,
   author = "Martin Kocour and Karel Vesel\'{y} and Alexander Blatt and Juan Zuluaga-Gomez and Igor Sz\H{o}ke and Jan \v{C}ernock\'{y} and Dietrich Klakow and Petr Motl\'{i}\v{c}ek",
   title = {"Boosting of Contextual Information in ASR for Air-Traffic Call-Sign Recognition"},
   pages = "3301--3305",
   booktitle = "Proceedings Interspeech 2021",
   journal = "Proceedings of Interspeech - on-line",
   volume = 2021,
   number = 8,
   year = 2021,
   location = "Brno, CZ",
   publisher = "International Speech Communication Association",
   ISSN = "1990-9772",
   doi = "10.21437/Interspeech.2021-1619",
   language = "english",
}

@inproceedings{zhao2019shallow,
  title={{Shallow-Fusion End-to-End Contextual Biasing}},
  author={Zhao, Ding and others},
  booktitle={Interspeech},
  pages={1418--1422},
  year={2019}
}

@inproceedings{zhao2019shallow_,
  title={Shallow-Fusion End-to-End Contextual Biasing},
  author={Zhao, Ding and Sainath, Tara N and Rybach, David and Rondon, Pat and Bhatia, Deepti and Li, Bo and Pang, Ruoming},
  booktitle={Interspeech},
  pages={1418--1422},
  year={2019}
}

@inproceedings{wang21t_interspeech,
  author={Peidong Wang and Tara N. Sainath and Ron J. Weiss},
  title={{Multitask Training with Text Data for End-to-End Speech Recognition}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={2566--2570},
  doi={10.21437/Interspeech.2021-683}
}

@INPROCEEDINGS{yusuf22usted,
   author = "Bolaji Yusuf and Ankur Gandhe and Alex Sokolov",
   title = {{USTED: Improving ASR with a Unified Speech and Text Encoder-Decoder}},
   pages = "8297--8301",
   booktitle = "Proceedings of ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
   year = 2022,
   location = "Singapore, SG",
   publisher = "IEEE Signal Processing Society",
   ISBN = "978-1-6654-0540-9",
   doi = "10.1109/ICASSP43922.2022.9746554",
   language = "english",
   url = "https://www.fit.vut.cz/research/publication/12784"
}

@inproceedings{thomas2022integrating,
  title={{Integrating Text Inputs For Training and Adapting RNN Transducer ASR Models}},
  author={Thomas, Samuel and Kingsbury, Brian and Saon, George and Kuo, Hong-Kwang J},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={8127--8131},
  year={2022},
  organization={IEEE}
}

@inproceedings{variani2020hybrid,
  title={{Hybrid Autoregressive Transducer (HAT)}},
  author={Variani, Ehsan and Rybach, David and Allauzen, Cyril and Riley, Michael},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6139--6143},
  year={2020},
  organization={IEEE}
}

@inproceedings{meng2021internal,
  title={Internal Language Model Training for Domain-Adaptive End-To-End Speech Recognition},
  author={Meng, Zhong and others},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7338--7342},
  year={2021},
  organization={IEEE}
}

@inproceedings{mcdermott2019density,  author={McDermott, Erik and Sak, Hasim and Variani, Ehsan},  booktitle={2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},   title={{A Density Ratio Approach to Language Model Fusion in End-to-End Automatic Speech Recognition}},   year={2019},  volume={},  number={},  pages={434-441},  doi={10.1109/ASRU46091.2019.9003790}}

@article{raffel2020exploring,
  title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of Machine Learning Research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@inproceedings{fazel21_interspeech,
  author={Amin Fazel and Wei Yang and Yulan Liu and Roberto Barra-Chicote and Yixiong Meng and Roland Maas and Jasha Droppo},
  title={{SynthASR: Unlocking Synthetic Data for Speech Recognition}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={896--900},
  doi={10.21437/Interspeech.2021-1882}
}

@INPROCEEDINGS{feng2021_,
  author={Chang, Feng-Ju and Liu, Jing and Radfar, Martin and Mouchtaris, Athanasios and Omologo, Maurizio and Rastrow, Ariya and Kunzmann, Siegfried},
  booktitle={2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)}, 
  title={{Context-Aware Transformer Transducer for Speech Recognition}}, 
  year={2021},
  volume={},
  number={},
  pages={503-510},
  doi={10.1109/ASRU51503.2021.9687895}
  }

@INPROCEEDINGS{feng2021,
  author={Chang, Feng-Ju and others},
  booktitle={2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)}, 
  title={{Context-Aware Transformer Transducer for Speech Recognition}}, 
  year={2021},
  volume={},
  number={},
  pages={503-510},
  doi={10.1109/ASRU51503.2021.9687895}
  }

@Inproceedings{dingliwal2022,
 author = {Saket Dingliwal and Monica Sunkara and Srikanth Ronanki and Jeff Farris and Katrin Kirchhoff and Sravan Bodapati},
 title = {Personalization of CTC speech recognition models},
 year = {2022},
 url = {https://www.amazon.science/publications/personalization-of-ctc-speech-recognition-models},
 booktitle = {IEEE 2022 Workshop on Spoken Language Technology},
}