{
    "arxiv_id": "2303.12976",
    "paper_title": "NVAutoNet: Fast and Accurate 360$^{\\circ}$ 3D Visual Perception For Self Driving",
    "authors": [
        "Trung Pham",
        "Mehran Maghoumi",
        "Wanli Jiang",
        "Bala Siva Sashank Jujjavarapu",
        "Mehdi Sajjadi",
        "Xin Liu",
        "Hsuan-Chu Lin",
        "Bor-Jeng Chen",
        "Giang Truong",
        "Chao Fang",
        "Junghyun Kwon",
        "Minwoo Park"
    ],
    "submission_date": "2023-03-23",
    "revised_dates": [
        "2023-08-28"
    ],
    "latest_version": 3,
    "categories": [
        "cs.CV"
    ],
    "abstract": "Robust, real-time perception of 3D world is essential to the autonomous vehicle. We introduce an end-to-end surround camera perception system, named NVAutoNet, for self-driving. NVAutoNet is a multi-task, multi-camera network which takes a variable set of time-synced camera images as input and produces a rich collection of 3D signals such as sizes, orientations, locations of obstacles, parking spaces and free-spaces, etc. NVAutoNet is modular and end-to-end: 1) the outputs can be consumed directly by downstream modules without any post-processing such as clustering and fusion -- improving speed of model deployment and in-car testing 2) the whole network training is done in one single stage -- improving speed of model improvement and iterations. The network is carefully designed to have high accuracy while running at 53 fps on NVIDIA Orin SoC (system-on-a-chip). The network is robust to sensor mounting variations (within some tolerances) and can be quickly customized for different vehicle types via efficient model fine-tuning.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.12976v1",
        "http://arxiv.org/pdf/2303.12976v2",
        "http://arxiv.org/pdf/2303.12976v3"
    ],
    "publication_venue": null
}