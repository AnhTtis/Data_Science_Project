
@ARTICLE{Campos2020-ze,
  title    = "Improving {NCEP's} global-scale wave ensemble averages using
              neural networks",
  author   = "Campos, Ricardo Martins and Krasnopolsky, Vladimir and Alves,
              Jose-Henrique and Penny, Stephen G",
  abstract = "The quality of metocean forecasts at longer forecast ranges has a
              significant impact on maritime safety and offshore operations. A
              nonlinear ensemble averaging technique is demonstrated using
              neural networks applied to one year (2017) of Global ocean Wave
              Ensemble forecast System (GWES) data provided by NCEP.
              Post-processing algorithms are developed based on multilayer
              perceptron neural networks (NN) trained with altimeter data to
              improve the global forecast skill, from nowcast to forecast
              ranges up to 10 days, including significant wave height (Hs) and
              wind speed (U10). NNs are applied as an alternative to the
              typical use of the arithmetic ensemble mean (EM). NN models are
              constructed using six variables sourced from 21 ensemble members,
              plus latitude, sin/cos of longitude, sin/cos of time, forecast
              lead time, and GWES cycle. The NN outputs are the residues of Hs
              and U10, i.e., the difference from the EM to the observations.
              One hidden (intermediate) layer is evaluated in terms of the
              optimum number of neurons (complexity) to map the given problem.
              The sensitivity test considered 26 different numbers of neurons,
              10 seeds for initial conditions, and 3 equally-divided datasets;
              for a total of 780 NN experiments. Assessments using 2,507,099
              paired satellite/GWES fields show that a simple NN model with few
              neurons is able to reduce the systematic errors for short-range
              forecasts, while a NN with more neurons is required to minimize
              the scatter error at longer forecast ranges. The novel method
              shows that one single NN model with 140 neurons is able to
              improve the error metrics for the whole globe while covering all
              forecast ranges analyzed. The bias of the widely used EM of GWES
              that varies from -10\% to 10\% for Hs compared to altimeters can
              be reduced to values within 5\%. The RMSE of day-10 forecasts
              from the NN simulations indicated a gain of two days in
              predictability when compared to the EM, using a reasonably simple
              post-processing model with low computational cost.",
  journal  = "Ocean Model.",
  volume   =  149,
  pages    = "101617",
  month    =  may,
  year     =  2020,
  keywords = "Neural networks; Ensemble forecast; Non-linear ensemble
              averaging; Wave modeling; Altimeter data"
}

@ARTICLE{Carter1989-gi,
  title     = "Statistical Forecasts Based on the National Meteorological
               Center's Numerical Weather Prediction System",
  author    = "Carter, Gary M and Paul Dallavalle, J and Glahn, Harry R",
  abstract  = "Abstract The production of interpretive weather element
               forecasts from dynamical model output variables is now an
               integral part of the centralized guidance systems of weather
               services throughout the world. The statistical forecasting
               system in the United States probably generates the most
               extensive suite of operational products, although other nations
               including Australia, Canada, France, Italy, The Netherlands, and
               the United Kingdom also routinely provide guidance for many
               weather elements and locations. The United States' statistical
               guidance system has evolved throughout the past 20 yr. The two
               principal formulation methods that have been employed are the
               model output statistics (MOS) and ``perfect prog'' approaches.
               These techniques have advantages and disadvantages that
               influence both aggregate and specific day-to-day performance
               characteristics of the associated weather element forecasts.
               Verification results indicate that forecasts from both
               statistical approaches provide useful guidance for most weather
               elements and projections for locations throughout the contiguous
               United States and Alaska. The MOS forecasts have generally been
               superior to the perfect prog guidance; the drawback to MOS is
               the necessity to rely on a relatively stable numerical
               prediction model. As dynamical models change and increase in
               skill, the perfect prog approach may be preferred for some
               applications.",
  journal   = "Weather Forecast.",
  publisher = "American Meteorological Society",
  volume    =  4,
  number    =  3,
  pages     = "401--412",
  month     =  sep,
  year      =  1989,
  language  = "en"
}

@ARTICLE{Chapman2019-dn,
  title    = "Improving Atmospheric River Forecasts With Machine Learning",
  author   = "Chapman, W E and Subramanian, A C and Delle Monache, L and Xie, S
              P and Ralph, F M",
  abstract = "This study tests the utility of convolutional neural networks as
              a postprocessing framework for improving the National Center for
              Environmental Prediction's Global Forecast System's integrated
              vapor transport forecast field in the Eastern Pacific and western
              United States. Integrated vapor transport is the characteristic
              field of atmospheric rivers, which provide over 65\% of yearly
              precipitation at some western U.S. locations. The method reduces
              full-field root-mean-square error (RMSE) at forecast leads from 3
              hr to seven days (9--17\% reduction), while increasing
              correlation between observations and predictions (0.5--12\%
              increase). This represents an approximately one- to two-day lead
              time improvement in RMSE. Decomposing RMSE shows that random
              error and conditional biases are predominantly reduced.
              Systematic error is reduced up to five-day forecast lead, but
              accounts for a smaller portion of RMSE. This work demonstrates
              convolutional neural networks potential to improve forecast skill
              out to seven days for precipitation events affecting the western
              United States.",
  journal  = "Geophys. Res. Lett.",
  volume   =  46,
  number   = "17-18",
  pages    = "10627--10635",
  year     =  2019,
  keywords = "forecasting; machine learning; atmospheric river; convolutional
              neural network; postprocess"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Cho2022-rz,
  title    = "A novel ensemble learning for post-processing of {NWP} Model's
              next-day maximum air temperature forecast in summer using deep
              learning and statistical approaches",
  author   = "Cho, Dongjin and Yoo, Cheolhee and Son, Bokyung and Im, Jungho
              and Yoon, Donghyuck and Cha, Dong-Hyun",
  abstract = "A reliable and accurate extreme air temperature in summer is
              necessary to prepare for and respond to thermal disasters such as
              heatstroke and power outages. The numerical weather prediction
              (NWP) model is commonly used to forecast air temperature using
              dynamic mechanisms. Because of its high uncertainty from coarse
              spatial resolution and unstable parameterization, however, it
              requires post-processing. Recent studies have proposed advanced
              post-processing methods using machine learning and deep learning
              techniques. This study compared various individual
              post-processing models---multi-linear regression (MLR), support
              vector regression (SVR), gated recurrent units (GRU), and
              convolutional neural network (CNN). It also proposed a novel
              multi-model ensemble (MMESS) that aggregates individual
              post-processing models based on the skill score (SS) for the
              Local Data Assimilation and Prediction System (LDAPS, a local NWP
              model over Korea) model's next-day maximum air temperature (Tmax)
              forecast data in two different domains: South Korea and Seoul.
              The pressure and surface data of the present-day analysis and
              next-day forecast fields of LDAPS were used as input variables.
              As a result of hindcast validation, CNN showed good overall
              performance (root mean square error (RMSE) of 1.41 °C in South
              Korea and 1.50 °C in Seoul) among individual models. We found
              that CNN demonstrated lower RMSE (1.17--1.58 °C) than other
              post-processing models (1.43--2.17 °C) at stations where the bias
              of LDAPS changes, using surrounding spatial information. The
              proposed MMESS exhibited more reliable, robust results than the
              individual models did. A further comparison to the simple average
              ensemble and the constrained linear squares-based MMEsupported
              the proposed MMESS as a more suitable ensemble method for
              next-day Tmax forecast, considering the relative significance of
              the individual models.",
  journal  = "Weather and Climate Extremes",
  volume   =  35,
  pages    = "100410",
  month    =  mar,
  year     =  2022,
  keywords = "Post-processing; Maximum air temperature forecast; Model output
              statistics; Deep learning; Multi-model ensemble"
}

@ARTICLE{Cui2012-pb,
  title     = "Bias Correction for Global Ensemble Forecast",
  author    = "Cui, Bo and Toth, Zoltan and Zhu, Yuejian and Hou, Dingchen",
  abstract  = "Abstract The main task of this study is to introduce a
               statistical postprocessing algorithm to reduce the bias in the
               National Centers for Environmental Prediction (NCEP) and
               Meteorological Service of Canada (MSC) ensemble forecasts before
               they are merged to form a joint ensemble within the North
               American Ensemble Forecast System (NAEFS). This statistical
               postprocessing method applies a Kalman filter type algorithm to
               accumulate the decaying averaging bias and produces
               bias-corrected ensembles for 35 variables. NCEP implemented this
               bias-correction technique in 2006. NAEFS is a joint operational
               multimodel ensemble forecast system that combines NCEP and MSC
               ensemble forecasts after bias correction. According to
               operational statistical verification, both the NCEP and MSC
               bias-corrected ensemble forecast products are enhanced
               significantly. In addition to the operational calibration
               technique, three other experiments were designed to assess and
               mitigate ensemble biases on the model grid: a decaying averaging
               bias calibration method with short samples, a climate mean bias
               calibration method, and a bias calibration method using
               dependent data. Preliminary results show that the decaying
               averaging method works well for the first few days. After
               removing the decaying averaging bias, the calibrated NCEP
               operational ensemble has improved probabilistic performance for
               all measures until day 5. The reforecast ensembles from the
               Earth System Research Laboratory's Physical Sciences Division
               with and without the climate mean bias correction were also
               examined. A comparison between the operational and the
               bias-corrected reforecast ensembles shows that the climate mean
               bias correction can add value, especially for week-2 probability
               forecasts.",
  journal   = "Weather Forecast.",
  publisher = "American Meteorological Society",
  volume    =  27,
  number    =  2,
  pages     = "396--410",
  month     =  apr,
  year      =  2012,
  language  = "en"
}

@ARTICLE{Dueben2018-kl,
  title    = "Challenges and design choices for global weather and climate
              models based on machine learning",
  author   = "Dueben, Peter D and Bauer, Peter",
  abstract = "Abstract. Can models that are based on deep learning and trained
              on atmospheric data compete with weather and climate models that
              are based on physical principles and the basic equations of
              motion? This question has been asked often recently due to the
              boom in deep-learning techniques. The question is valid given the
              huge amount of data that are available, the computational
              efficiency of deep-learning techniques and the limitations of
              today's weather and climate models in particular with respect to
              resolution and complexity.In this paper, the question will be
              discussed in the context of global weather forecasts. A toy model
              for global weather predictions will be presented and used to
              identify challenges and fundamental design choices for a forecast
              system based on neural networks.",
  journal  = "Geoscientific Model Development",
  volume   =  11,
  number   =  10,
  pages    = "3999--4009",
  month    =  oct,
  year     =  2018
}

@ARTICLE{Espeholt2022-xe,
  title    = "Deep learning for twelve hour precipitation forecasts",
  author   = "Espeholt, Lasse and Agrawal, Shreya and S{\o}nderby, Casper and
              Kumar, Manoj and Heek, Jonathan and Bromberg, Carla and Gazen,
              Cenk and Carver, Rob and Andrychowicz, Marcin and Hickey, Jason
              and Bell, Aaron and Kalchbrenner, Nal",
  abstract = "Existing weather forecasting models are based on physics and use
              supercomputers to evolve the atmosphere into the future. Better
              physics-based forecasts require improved atmospheric models,
              which can be difficult to discover and develop, or increasing the
              resolution underlying the simulation, which can be
              computationally prohibitive. An emerging class of weather models
              based on neural networks overcome these limitations by learning
              the required transformations from data instead of relying on
              hand-coded physics and by running efficiently in parallel. Here
              we present a neural network capable of predicting precipitation
              at a high resolution up to 12 h ahead. The model predicts raw
              precipitation targets and outperforms for up to 12 h of lead time
              state-of-the-art physics-based models currently operating in the
              Continental United States. The results represent a substantial
              step towards validating the new class of neural weather models.",
  journal  = "Nat. Commun.",
  volume   =  13,
  number   =  1,
  pages    = "5145",
  month    =  sep,
  year     =  2022,
  language = "en"
}

@ARTICLE{Fan2021-jk,
  title     = "Using Artificial Neural Networks to Improve {CFS} Week 3-4
               Precipitation and 2-Meter Air Temperature Forecasts",
  author    = "Fan, Yun and Krasnopolsky, Vladimir and van den Dool, Huug and
               Wu, Chung-Yu and Gottschalck, Jon",
  abstract  = "Abstract Forecast skill from dynamical forecast models decreases
               quickly with projection time due to various errors. Therefore,
               post-processing methods, from simple bias correction methods to
               more complicated multiple linear regression-based Model Output
               Statistics, are used to improve raw model forecasts. Usually,
               these methods show clear forecast improvement over the raw model
               forecasts, especially for short-range weather forecasts.
               However, linear approaches have limitations because the
               relationship between predictands and predictors may be
               nonlinear. This is even truer for extended range forecasts, such
               as Week 3-4 forecasts. In this study, neural network techniques
               are used to seek or model the relationships between a set of
               predictors and predictands, and eventually to improve Week 3-4
               precipitation and 2-meter temperature forecasts made by the NOAA
               NCEP Climate Forecast System. Benefitting from advances in
               machine learning techniques in recent years, more flexible and
               capable machine learning algorithms and availability of big
               datasets enable us not only to explore nonlinear features or
               relationships within a given large dataset, but also to extract
               more sophisticated pattern relationships and co-variabilities
               hidden within the multi-dimensional predictors and predictands.
               Then these more sophisticated relationships and high-level
               statistical information are used to correct the model Week 3-4
               precipitation and 2-meter temperature forecasts. The results
               show that to some extent neural network techniques can
               significantly improve the Week 3-4 forecast accuracy and greatly
               increase the efficiency over the traditional multiple linear
               regression methods.",
  journal   = "Weather Forecast.",
  publisher = "American Meteorological Society",
  volume    = "-1",
  number    = "aop",
  month     =  jan,
  year      =  2021,
  language  = "en"
}

@ARTICLE{Glahn1972-sy,
  title     = {The Use of Model Output Statistics ({MOS}) in Objective Weather
               Forecasting},
  author    = {Glahn, Harry R and Lowry, Dale A},
  abstract  = "Abstract Model Output Statistics (MOS) is an objective weather
               forecasting technique which consists of determining a
               statistical relationship between a predictand and variables
               forecast by a numerical model at some projection time(s). It is,
               in effect, the determination of the ``weather related''
               statistics of a numerical model. This technique, together with
               screening regression, has been applied to the prediction of
               surface wind, probability of precipitation, maximum temperature,
               cloud amount, and conditional probability of frozen
               precipitation. Predictors used include surface observations at
               initial time and predictions from the Subsynoptic Advection
               Model (SAM) and the Primitive Equation model used operationally
               by the National Weather Service. Verification scores have been
               computed, and, where possible, compared to scores for forecasts
               from other objective techniques and for the official forecasts.
               MOS forecasts of surface wind, probability of precipitation, and
               conditional probability of frozen precipitation are being
               disseminated by the National Weather Service over teletype and
               facsimile. It is concluded that MOS is a useful technique in
               objective weather forecasting.",
  journal   = "J. Appl. Meteorol. Climatol.",
  publisher = "American Meteorological Society",
  volume    =  11,
  number    =  8,
  pages     = "1203--1211",
  month     =  dec,
  year      =  {1972},
  language  = "en"
}

@ARTICLE{Gneiting2005-uu,
  title     = "Calibrated Probabilistic Forecasting Using Ensemble Model Output
               Statistics and Minimum {CRPS} Estimation",
  author    = "Gneiting, Tilmann and Raftery, Adrian E and Westveld, Anton H
               and Goldman, Tom",
  abstract  = "Abstract Ensemble prediction systems typically show positive
               spread-error correlation, but they are subject to forecast bias
               and dispersion errors, and are therefore uncalibrated. This work
               proposes the use of ensemble model output statistics (EMOS), an
               easy-to-implement postprocessing technique that addresses both
               forecast bias and underdispersion and takes into account the
               spread-skill relationship. The technique is based on multiple
               linear regression and is akin to the superensemble approach that
               has traditionally been used for deterministic-style forecasts.
               The EMOS technique yields probabilistic forecasts that take the
               form of Gaussian predictive probability density functions (PDFs)
               for continuous weather variables and can be applied to gridded
               model output. The EMOS predictive mean is a bias-corrected
               weighted average of the ensemble member forecasts, with
               coefficients that can be interpreted in terms of the relative
               contributions of the member models to the ensemble, and provides
               a highly competitive deterministic-style forecast. The EMOS
               predictive variance is a linear function of the ensemble
               variance. For fitting the EMOS coefficients, the method of
               minimum continuous ranked probability score (CRPS) estimation is
               introduced. This technique finds the coefficient values that
               optimize the CRPS for the training data. The EMOS technique was
               applied to 48-h forecasts of sea level pressure and surface
               temperature over the North American Pacific Northwest in spring
               2000, using the University of Washington mesoscale ensemble.
               When compared to the bias-corrected ensemble,
               deterministic-style EMOS forecasts of sea level pressure had
               root-mean-square error 9\% less and mean absolute error 7\%
               less. The EMOS predictive PDFs were sharp, and much better
               calibrated than the raw ensemble or the bias-corrected ensemble.",
  journal   = "Mon. Weather Rev.",
  publisher = "American Meteorological Society",
  volume    =  133,
  number    =  5,
  pages     = "1098--1118",
  month     =  may,
  year      =  2005,
  language  = "en"
}

@ARTICLE{Gronquist2021-am,
  title    = "Deep learning for post-processing ensemble weather forecasts",
  author   = "Gr{\"o}nquist, Peter and Yao, Chengyuan and Ben-Nun, Tal and
              Dryden, Nikoli and Dueben, Peter and Li, Shigang and Hoefler,
              Torsten",
  abstract = "Quantifying uncertainty in weather forecasts is critical,
              especially for predicting extreme weather events. This is
              typically accomplished with ensemble prediction systems, which
              consist of many perturbed numerical weather simulations, or
              trajectories, run in parallel. These systems are associated with
              a high computational cost and often involve statistical
              post-processing steps to inexpensively improve their raw
              prediction qualities. We propose a mixed model that uses only a
              subset of the original weather trajectories combined with a
              post-processing step using deep neural networks. These enable the
              model to account for non-linear relationships that are not
              captured by current numerical models or post-processing methods.
              Applied to the global data, our mixed models achieve a relative
              improvement in ensemble forecast skill (CRPS) of over 14\%.
              Furthermore, we demonstrate that the improvement is larger for
              extreme weather events on select case studies. We also show that
              our post-processing can use fewer trajectories to achieve
              comparable results to the full ensemble. By using fewer
              trajectories, the computational costs of an ensemble prediction
              system can be reduced, allowing it to run at higher resolution
              and produce more accurate forecasts. This article is part of the
              theme issue 'Machine learning for weather and climate modelling'.",
  journal  = "Philos. Trans. A Math. Phys. Eng. Sci.",
  volume   =  379,
  number   =  2194,
  pages    = "20200092",
  month    =  apr,
  year     =  2021,
  keywords = "deep learning; ensemble post-processing; extreme weather events;
              weather uncertainty quantification",
  language = "en"
}

@ARTICLE{Haupt2021-er,
  title    = "Towards implementing artificial intelligence post-processing in
              weather and climate: proposed actions from the Oxford 2019
              workshop",
  author   = "Haupt, Sue Ellen and Chapman, William and Adams, Samantha V and
              Kirkwood, Charlie and Hosking, J Scott and Robinson, Niall H and
              Lerch, Sebastian and Subramanian, Aneesh C",
  abstract = "The most mature aspect of applying artificial intelligence
              (AI)/machine learning (ML) to problems in the atmospheric
              sciences is likely post-processing of model output. This article
              provides some history and current state of the science of
              post-processing with AI for weather and climate models. Deriving
              from the discussion at the 2019 Oxford workshop on Machine
              Learning for Weather and Climate, this paper also presents
              thoughts on medium-term goals to advance such use of AI, which
              include assuring that algorithms are trustworthy and
              interpretable, adherence to FAIR data practices to promote
              usability, and development of techniques that leverage our
              physical knowledge of the atmosphere. The coauthors propose
              several actionable items and have initiated one of those: a
              repository for datasets from various real weather and climate
              problems that can be addressed using AI. Five such datasets are
              presented and permanently archived, together with Jupyter
              notebooks to process them and assess the results in comparison
              with a baseline technique. The coauthors invite the readers to
              test their own algorithms in comparison with the baseline and to
              archive their results. This article is part of the theme issue
              `Machine learning for weather and climate modelling'.",
  journal  = "Philosophical Transactions of the Royal Society A: Mathematical,
              Physical and Engineering Sciences",
  volume   =  379,
  number   =  2194,
  pages    = "20200091",
  month    =  apr,
  year     =  2021,
  keywords = "weather; artificial intelligence; machine learning; climate;
              post-processing"
}

@ARTICLE{Hemri2014-mu,
  title     = "Trends in the predictive performance of raw ensemble weather
               forecasts",
  author    = "Hemri, S and Scheuerer, M and Pappenberger, F and Bogner, K and
               Haiden, T",
  abstract  = "Abstract This study applies statistical postprocessing to
               ensemble forecasts of near-surface temperature, 24 h
               precipitation totals, and near-surface wind speed from the
               global model of the European Centre for Medium-Range Weather
               Forecasts (ECMWF). The main objective is to evaluate the
               evolution of the difference in skill between the raw ensemble
               and the postprocessed forecasts. Reliability and sharpness, and
               hence skill, of the former is expected to improve over time.
               Thus, the gain by postprocessing is expected to decrease. Based
               on ECMWF forecasts from January 2002 to March 2014 and
               corresponding observations from globally distributed stations,
               we generate postprocessed forecasts by ensemble model output
               statistics (EMOS) for each station and variable. Given the
               higher average skill of the postprocessed forecasts, we analyze
               the evolution of the difference in skill between raw ensemble
               and EMOS. This skill gap remains almost constant over time
               indicating that postprocessing will keep adding skill in the
               foreseeable future.",
  journal   = "Geophys. Res. Lett.",
  publisher = "John Wiley \& Sons, Ltd",
  volume    =  41,
  number    =  24,
  pages     = "9197--9205",
  month     =  dec,
  year      =  2014,
  keywords  = "ensemble weather forecasts; statistical postprocessing; EMOS;
               model verification"
}

@ARTICLE{Hoffman2017-ec,
  title     = "An Empirical Cumulative Density Function Approach to Defining
               Summary {NWP} Forecast Assessment Metrics",
  author    = "Hoffman, Ross N and Boukabara, Sid-Ahmed and Krishna Kumar, V
               and Garrett, Kevin and Casey, Sean P F and {Robert Atlas}",
  abstract  = "Abstract The empirical cumulative density function (ECDF)
               approach can be used to combine multiple, diverse assessment
               metrics into summary assessment metrics (SAMs) to analyze the
               results of impact experiments and preoperational implementation
               testing with numerical weather prediction (NWP) models. The main
               advantages of the ECDF approach are that it is amenable to
               statistical significance testing and produces results that are
               easy to interpret because the SAMs for various subsets tend to
               vary smoothly and in a consistent manner. In addition, the ECDF
               approach can be applied in various contexts thanks to the
               flexibility allowed in the definition of the reference sample.
               The interpretations of the examples presented here of the impact
               of potential future data gaps are consistent with previously
               reported conclusions. An interesting finding is that the impact
               of observations decreases with increasing forecast time. This is
               interpreted as being caused by the masking effect of NWP model
               errors increasing to become the dominant source of forecast
               error.",
  journal   = "Mon. Weather Rev.",
  publisher = "American Meteorological Society",
  volume    =  145,
  number    =  4,
  pages     = "1427--1435",
  month     =  apr,
  year      =  2017,
  language  = "en"
}

@ARTICLE{Kirkwood2021-je,
  title    = "A framework for probabilistic weather forecast post-processing
              across models and lead times using machine learning",
  author   = "Kirkwood, Charlie and Economou, Theo and Odbert, Henry and
              Pugeault, Nicolas",
  abstract = "Forecasting the weather is an increasingly data-intensive
              exercise. Numerical weather prediction (NWP) models are becoming
              more complex, with higher resolutions, and there are increasing
              numbers of different models in operation. While the forecasting
              skill of NWP models continues to improve, the number and
              complexity of these models poses a new challenge for the
              operational meteorologist: how should the information from all
              available models, each with their own unique biases and
              limitations, be combined in order to provide stakeholders with
              well-calibrated probabilistic forecasts to use in decision
              making? In this paper, we use a road surface temperature example
              to demonstrate a three-stage framework that uses machine learning
              to bridge the gap between sets of separate forecasts from NWP
              models and the 'ideal' forecast for decision support:
              probabilities of future weather outcomes. First, we use quantile
              regression forests to learn the error profile of each numerical
              model, and use these to apply empirically derived probability
              distributions to forecasts. Second, we combine these
              probabilistic forecasts using quantile averaging. Third, we
              interpolate between the aggregate quantiles in order to generate
              a full predictive distribution, which we demonstrate has
              properties suitable for decision support. Our results suggest
              that this approach provides an effective and operationally viable
              framework for the cohesive post-processing of weather forecasts
              across multiple models and lead times to produce a
              well-calibrated probabilistic output. This article is part of the
              theme issue 'Machine learning for weather and climate modelling'.",
  journal  = "Philos. Trans. A Math. Phys. Eng. Sci.",
  volume   =  379,
  number   =  2194,
  pages    = "20200099",
  month    =  apr,
  year     =  2021,
  keywords = "artificial intelligence; data integration; decision theory; model
              stacking; quantile regression; uncertainty quantification",
  language = "en"
}

@ARTICLE{Krasnopolsky2012-or,
  title   = "A Neural Network Nonlinear Multimodel Ensemble to Improve
             Precipitation Forecasts over Continental {US}",
  author  = "Krasnopolsky, Vladimir M and Lin, Ying",
  journal = "Advances In Meteorology",
  volume  =  2012,
  pages   = "649450",
  month   =  sep,
  year    =  2012
}

@ARTICLE{Lorenz1982-gp,
  title    = "Atmospheric predictability experiments with a large numerical
              model",
  author   = "Lorenz, Edward N",
  abstract = "The instability of the atmosphere places an upper bound on the
              predictability of instantaneous weather patterns. The skill with
              which current operational forecasting procedures are observed to
              perform determines a lower bound. Estimates of both bounds are
              obtained by comparing the ECMWF operational forecast for each day
              of a 100-day sequence at one range with the operational forecast
              for the same day at another range, and with the analysis for that
              day. The estimated bounds are reasonably close together.
              Predictions at least ten days ahead as skilful as predictions now
              made seven days ahead appear to be possible. Additional
              improvements at extended range may be realized if the one-day
              forecast is capable of being improved significantly.",
  journal  = "Tellus",
  volume   =  34,
  number   =  6,
  pages    = "505--513",
  year     =  1982
}

@ARTICLE{Rasp2018-ec,
  title    = "Neural Networks for Postprocessing Ensemble Weather Forecasts",
  author   = "Rasp, Stephan and Lerch, Sebastian",
  abstract = "Abstract Ensemble weather predictions require statistical
              postprocessing of systematic errors to obtain reliable and
              accurate probabilistic forecasts. Traditionally, this is
              accomplished with distributional regression models in which the
              parameters of a predictive distribution are estimated from a
              training period. We propose a flexible alternative based on
              neural networks that can incorporate nonlinear relationships
              between arbitrary predictor variables and forecast distribution
              parameters that are automatically learned in a data-driven way
              rather than requiring prespecified link functions. In a case
              study of 2-m temperature forecasts at surface stations in
              Germany, the neural network approach significantly outperforms
              benchmark postprocessing methods while being computationally more
              affordable. Key components to this improvement are the use of
              auxiliary predictor variables and station-specific information
              with the help of embeddings. Furthermore, the trained neural
              network can be used to gain insight into the importance of
              meteorological variables, thereby challenging the notion of
              neural networks as uninterpretable black boxes. Our approach can
              easily be extended to other statistical postprocessing and
              forecasting problems. We anticipate that recent advances in deep
              learning combined with the ever-increasing amounts of model and
              observation data will transform the postprocessing of numerical
              weather forecasts in the coming decade.",
  journal  = "Mon. Weather Rev.",
  volume   =  146,
  number   =  11,
  pages    = "3885--3900",
  month    =  nov,
  year     =  2018
}

@ARTICLE{Ravuri2021-qa,
  title    = "Skilful precipitation nowcasting using deep generative models of
              radar",
  author   = "Ravuri, Suman and Lenc, Karel and Willson, Matthew and Kangin,
              Dmitry and Lam, Remi and Mirowski, Piotr and Fitzsimons, Megan
              and Athanassiadou, Maria and Kashem, Sheleem and Madge, Sam and
              Prudden, Rachel and Mandhane, Amol and Clark, Aidan and Brock,
              Andrew and Simonyan, Karen and Hadsell, Raia and Robinson, Niall
              and Clancy, Ellen and Arribas, Alberto and Mohamed, Shakir",
  abstract = "Precipitation nowcasting, the high-resolution forecasting of
              precipitation up to two hours ahead, supports the real-world
              socioeconomic needs of many sectors reliant on weather-dependent
              decision-making1,2. State-of-the-art operational nowcasting
              methods typically advect precipitation fields with radar-based
              wind estimates, and struggle to capture important non-linear
              events such as convective initiations3,4. Recently introduced
              deep learning methods use radar to directly predict future rain
              rates, free of physical constraints5,6. While they accurately
              predict low-intensity rainfall, their operational utility is
              limited because their lack of constraints produces blurry
              nowcasts at longer lead times, yielding poor performance on rarer
              medium-to-heavy rain events. Here we present a deep generative
              model for the probabilistic nowcasting of precipitation from
              radar that addresses these challenges. Using statistical,
              economic and cognitive measures, we show that our method provides
              improved forecast quality, forecast consistency and forecast
              value. Our model produces realistic and spatiotemporally
              consistent predictions over regions up to 1,536 km $\times$ 1,280
              km and with lead times from 5-90 min ahead. Using a systematic
              evaluation by more than 50 expert meteorologists, we show that
              our generative model ranked first for its accuracy and usefulness
              in 89\% of cases against two competitive methods. When verified
              quantitatively, these nowcasts are skillful without resorting to
              blurring. We show that generative nowcasting can provide
              probabilistic predictions that improve forecast value and support
              operational utility, and at resolutions and lead times where
              alternative methods struggle.",
  journal  = "Nature",
  volume   =  597,
  number   =  7878,
  pages    = "672--677",
  month    =  sep,
  year     =  2021,
  language = "en"
}

@ARTICLE{Taillardat2016-st,
  title   = "Calibrated Ensemble Forecasts Using Quantile Regression Forests
             and Ensemble Model Output Statistics",
  author  = "Taillardat, Maxime and Mestre, Olivier and Zamo, Micha{\"e}l and
             Naveau, Philippe",
  journal = "Monthly Weather Review",
  volume  =  144,
  number  =  6,
  pages   = "2375--2393",
  month   =  jun,
  year    =  2016
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Weyn2021-jl,
  title     = "Sub‐seasonal forecasting with a large ensemble of deep‐learning
               weather prediction models",
  author    = "Weyn, Jonathan A and Durran, Dale R and Caruana, Rich and
               Cresswell-Clay, Nathaniel",
  abstract  = "Abstract We present an ensemble prediction system using a Deep
               Learning Weather Prediction (DLWP) model that recursively
               predicts six key atmospheric variables with six-hour time
               resolution. This computationally efficient model uses
               convolutional neural networks (CNNs) on a cubed sphere grid to
               produce global forecasts. The trained model requires just three
               minutes on a single GPU to produce a 320-member set of six-week
               forecasts at 1.4° resolution. Ensemble spread is primarily
               produced by randomizing the CNN training process to create a set
               of 32 DLWP models with slightly different learned weights.
               Although our DLWP model does not forecast precipitation, it does
               forecast total column water vapor and gives a reasonable 4.5-day
               deterministic forecast of Hurricane Irma. In addition to
               simulating mid-latitude weather systems, it spontaneously
               generates tropical cyclones in a one-year free-running
               simulation. Averaged globally and over a two-year test set, the
               ensemble mean RMSE retains skill relative to climatology beyond
               two-weeks, with anomaly correlation coefficients remaining above
               0.6 through six days. Our primary application is to
               subseasonal-to-seasonal (S2S) forecasting at lead times from two
               to six weeks. Current forecast systems have low skill in
               predicting one- or 2-week-average weather patterns at S2S time
               scales. The continuous ranked probability score (CRPS) and the
               ranked probability skill score (RPSS) show that the DLWP
               ensemble is only modestly inferior in performance to the
               European Center for Medium Range Weather Forecasts (ECMWF) S2S
               ensemble over land at lead times of 4 and 5?6 weeks. At shorter
               lead times, the ECMWF ensemble performs better than DLWP.",
  journal   = "J. Adv. Model. Earth Syst.",
  publisher = "American Geophysical Union (AGU)",
  volume    =  13,
  number    =  7,
  month     =  jul,
  year      =  2021,
  copyright = "http://creativecommons.org/licenses/by/4.0/",
  language  = "en"
}

@ARTICLE{Wilks2007-fz,
  title     = "Comparison of {Ensemble-MOS} Methods Using {GFS} Reforecasts",
  author    = "Wilks, Daniel S and Hamill, Thomas M",
  abstract  = "Abstract Three recently proposed and promising methods for
               postprocessing ensemble forecasts based on their historical
               error characteristics (i.e., ensemble-model output statistics
               methods) are compared using a multidecadal reforecast dataset.
               Logistic regressions and nonhomogeneous Gaussian regressions are
               generally preferred for daily temperature, and for medium-range
               (6--10 and 8--14 day) temperature and precipitation forecasts.
               However, the better sharpness of medium-range ensemble-dressing
               forecasts sometimes yields the best Brier scores even though
               their calibration is somewhat worse. Using the long (15 or 25
               yr) training samples that are available with these reforecasts
               improves the accuracy and skill of these probabilistic forecasts
               to levels that are approximately equivalent to gains of 1 day of
               lead time, relative to using short (1 or 2 yr) training samples.",
  journal   = "Mon. Weather Rev.",
  publisher = "American Meteorological Society",
  volume    =  135,
  number    =  6,
  pages     = "2379--2390",
  month     =  jun,
  year      =  2007,
  language  = "en"
}
