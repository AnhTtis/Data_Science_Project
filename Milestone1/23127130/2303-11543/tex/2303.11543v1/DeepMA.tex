%\documentclass[]{article}  % list options between brackets
%\documentclass{IEEEtran}
\documentclass[12pt, draftclsnofoot, onecolumn]{IEEEtran}
%\documentclass[12pt,magazine,compsoc, onecolumn]{IEEEtran}
%\usepackage{}              % list packages between braces

\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{epstopdf}
\usepackage{subfigure}
\usepackage{amsmath}
\usepackage{url}
\usepackage{float}
\usepackage{colortbl}
\usepackage{makecell}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[table]{xcolor}

%\renewcommand{\Re}{\operatorname{Re}}
%\renewcommand{\Im}{\operatorname{Im}}
\begin{document}
\title{\huge{DeepMA: End-to-end Deep Multiple Access for Wireless Image Transmission in Semantic Communication}}
%\author{Wenyu Zhang, Kaiyuan Bai, Sherali Zeadally, Haijun Zhang, \emph{Fellow, IEEE}, Hua Shao, Hui Ma, Victor C. M. Leung, \emph{Life Fellow, IEEE}
\author{Wenyu Zhang, Kaiyuan Bai, Sherali Zeadally, Haijun Zhang, Hua Shao, Hui Ma, Victor C. M. Leung
\thanks{Wenyu Zhang, Hua Shao, and Hui Ma are with the School of Intelligence Science and Technology, and the Institute of Artificial Intelligence, University of Science and Technology Beijing, Beijing, 100083, China. Emails: wyzhang@ustb.edu.cn, shaohua@ustb.edu.cn, hui\_ma@ustb.edu.cn.}
\thanks{Kaiyuan Bai is with the China Telecom Research Institute, Beijing, 100096, China. Email: baiky1@chinatelecom.cn}
\thanks{Sherali Zeadally is with the College of Communication and Information, University of Kentucky, Lexington, KY 40506 USA. Email: szeadally@uky.edu}
\thanks{Haijun Zhang is with the with Institute of Artificial Intelligence, Beijing Advanced Innovation Center for Materials Genome Engineering, Beijing Engineering and Technology Research Center for Convergence Networks and Ubiquitous Services, University of Science and Technology Beijing, Beijing 100083, China. E-mail: haijunzhang@ieee.org.}
\thanks{Victor C. M. Leung is with the College of Computer Science and Software Engineering, Shenzhen University, Shenzhen 518060, China, and also with the Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, BC V6T 1Z4, Canada E-mail: vleung@ieee.org.}}


\maketitle
\begin{abstract}
Semantic communication is a new paradigm that exploits deep learning models to enable end-to-end communications processes, and recent studies have shown that it can achieve better noise resiliency compared with traditional communication schemes in a low signal-to-noise (SNR) regime. To achieve multiple access in semantic communication, we propose a deep learning-based multiple access (DeepMA) method by training semantic communication models with the abilities of joint source-channel coding (JSCC) and orthogonal signal modulation. DeepMA is achieved by a DeepMA network (DMANet), which is comprised of several independent encoder-decoder pairs (EDPs), and the DeepMA encoders can encode the input data as mutually orthogonal semantic symbol vectors (SSVs) such that the DeepMA decoders can recover their own target data from a received mixed SSV (MSSV) superposed by multiple SSV components transmitted from different encoders. We describe frameworks of DeepMA in wireless device-to-device (D2D), downlink, and uplink channel multiplexing scenarios, along with the training algorithm. We evaluate the performance of the proposed DeepMA in wireless image transmission tasks and compare its performance with the attention module-based deep JSCC (ADJSCC) method and conventional communication schemes using better portable graphics (BPG) and Low-density parity-check code (LDPC). The results obtained show that the proposed DeepMA can achieve effective, flexible, and privacy-preserving channel multiplexing process, and demonstrate that our proposed DeepMA approach can yield comparable bandwidth efficiency compared with conventional multiple access schemes.
\end{abstract}

\begin{IEEEkeywords}
Channel multiplexing, deep learning, multiple access, semantic communication, wireless image transmission
\end{IEEEkeywords}

\section{Introduction}

In a conventional communication system, the data processing process mainly includes the following three parts: source coding for improving transmission efficiency by reducing the information redundancy of the source data, channel coding for enhancing the transmitting reliability by using error-check or error-correcting coding techniques, and signal modulation for improving the channel resource utilization efficiency by enabling multiple users to transmit data over a shared physical channel, while transforming the digital signals as high-frequency waveforms that are suitable for wireless transmission \cite{tse2005fundamentals}. These processes are conducted by specific and separable functional blocks, which are designed independently without jointly considering the influences of other blocks. This separable architecture significantly reduces the design, development, and maintenance costs of the communication system, but it is suboptimal from the perspective of end-to-end optimization \cite{liu2022high}\cite{qin2021semantic}.


In recent years, the rapid development of artificial intelligence (AI), especially deep learning (DL)-based autoencoder models, has enabled us to achieve the end-to-end semantic communication process by leveraging the powerful data compression and noise resiliency capability of deep learning models. A typical semantic communication system (SCS) is mainly composed of a trainable semantic encoder, a non-trainable noisy physical communication channel, and a trainable semantic decoder \cite{qin2021semantic}\cite{kountouris2021semantics}. Both semantic encoder and semantic decoder are realized by using deep learning models, such as convolution neural networks (CNNs), recurrent neural networks (RNN), and attention networks. A typical semantic encoder automatically conducts the joint source-channel coding process to extract the semantic feature representation that is suitable for transmission over a noisy physical channel. Accordingly, a paired semantic decoder can automatically complete the inference task directly from the received semantic symbols corrupted by noises or interferences. If the inference task is recovering the original input data, then the decoder must perform the channel decoding and source decoding process jointly.

Recent studies \cite{qin2021semantic}\cite{bourtsoulatze2019deep}\cite{weng2021semantic}\cite{xie2021deep} have shown that semantic communication can achieve high communication efficiency and noise resiliency in various data transmission scenarios, such as video/image transmission \cite{tung2022deepwive}\cite{bourtsoulatze2019deep}, speech transmission \cite{weng2021semantic}, and text transmission \cite{xie2021deep}. More specifically, by utilizing the powerful feature extraction capability of deep learning models, semantic communication models can achieve a higher data compression ratio compared with classical data compression methods so that the amount of transmitted data can be further reduced. Second, deep learning models can be trained with powerful noise resiliency capability, which enables the semantic communication models to complete the inference task to obtain high-quality results when there is some noise interference. Semantic encoders and decoders are jointly trained end-to-end between the source input data at the transmitter and the final inference result at the receiver. Thus, the source channel encoding and decoding process are jointly optimized, and it is globally optimal compared with conventional communication systems with separate functional blocks. Semantic communication can achieve a relatively stronger noise resiliency in a low channel signal to noise ratio (SNR) regime, while in conventional separable communication schemes, the transmission reliability suffers from the 'cliff effect', i.e., the transmission performance drops sharply when the channel condition is poor, and even fails to transmit data.

In conventional communications, multiple access is a commonly used technology that enables multiple users to multiplex the communication channel without interfering with each other, which is helpful for improving the utilization efficiency of the channel resources, and typical methodologies include orthogonal frequency division multiple access (OFDMA) \cite{myung2006single}, time division multiple access (TDMA) \cite{ergen2010tdma}, code division multiple access (CDMA) \cite{gilhousen1991capacity}, and non-orthogonal multiple access (NOMA) \cite{dai2018survey}. Among them, OFDMA achieves multiplexing by allocating the dedicated frequency sources to the user equipments (UEs), and TDMA avoids interference by dividing and allocating UEs with different transmission timeslot resources. NOMA can support the co-frequency transmission by using a successive interference cancellation technique. CDMA is an orthogonal multiple access (OMA) method that can achieve channel multiplexing by modulating the data bits of multiple users using a set of orthogonal codes, such that the data can be transmitted over with the same frequency, and the receiver can recover the data by demodulating the received data with the same code. This OMA method enables multiple UEs to transmit data over a shared physical channel with the same frequency without worrying about collisions while protecting the data privacy when the basis code used is unknown to other UEs, and it has been widely used in conventional communication systems \cite{tse2005fundamentals}.

As a new communication paradigm, currently, semantic communication research mainly addresses the deep learning-based JSCC (DeepJSCC) problem for point-to-point communication tasks \cite{qin2021semantic}, and how to achieve multiple access to enable multiple semantic data streams to be transmitted simultaneously with the same frequency which remains an unexplored problem. If we can achieve DeepJSCC and orthogonal modulation in one OMA-enabled semantic communication model, then there is no need to use the conventional OFDMA or TDMA-based multiple access method because the semantic symbols are already orthogonal to each other, and the system complexity will be significantly reduced. On the other hand, conventional CDMA is only suitable for transmitting bit data but it is not suitable for semantic codes with continuous values. Moreover, from the perspective of bandwidth efficiency, CDMA is not an ideal choice because its spread spectrum process will decrease the bandwidth efficiency. As such, we must develop a new method that is suitable for semantic communication systems.

We summarize the main contributions of this work as follows:

\begin{itemize}

\item To achieve co-frequency OMA in semantic communication, we propose DeepMA to enable orthogonal channel multiplexing by exploiting the capabilities of the deep semantic communication models. We propose a channel multiplexing-enabled DeepMA network (DMANet), which is comprised of multiple DeepMA encoder-decoder pairs (EDP), and the EDPs are trained with the abilities of JSCC and orthogonal signal modulation. Similar to CDMA, a DMANet can support channel multiplexing by transmitting multiple orthogonal semantic symbol vectors (SSVs) simultaneously, and the DeepMA decoders can recover the target data from a received mixed SSV (MSSV) superposed by several different SSVs. In contras to CDMA, the orthogonal modulation process in DeepMA is learned by the model training process, and it is automatically conducted without the help of an orthogonal basis.
\item We conducted simulations to evaluate the performance of the proposed DeepMA in wireless image transmission tasks. First, we developed an attention module and residual structure-based DeepMA encoder and decoder models, and then trained the models by using CIFAR10 and ImageNet data. After training, we compare the peak-signal-to-noise (PSNR) performances of the proposed DeepMA models, ADJSCC models, and conventional communications schemes that use better portable graphics  (BPG) \cite{BPG} for source coding and low-density parity-check (LDPC) for channel coding \cite{liu2022high}. We used the ADJSCC model as the reference method for non-multiplexing semantic transmission to show how the multiple access process influences the transmission capacity of DeepMA. We used the conventional multiple access schemes as baselines to demonstrate the performance of our proposed DeepMA. To demonstrate the performance of the proposed DeepMA, we first present some illustrative examples to show the mutual orthogonality of the semantic symbol vectors (SSVs), which is also helpful for us to understand why DeepMA can achieve OMA. The illustrative examples show that a DeepMA decoder can effectively recover the target image from an MSSV that contains the SSV transmitted from the paired DeepMA encoder but cannot obtain any useful information if the paired DeepMA encoder does not send the SSV, showing that the proposed DeepMA can achieve flexible and privacy-protected multiple access. We compare the (PSNR) performances achieved by DeepMA, ADJSCC, and conventional BPG+LDPC schemes with different channel SNR, and the results demonstrate that the proposed can achieve high-quality recovered images with channel multiplexing, and show that DeepMA can achieve better noise-resiliency compared with conventional BPG+LDPC schemes in a very low SNR regime.
\end{itemize}

We organize the remainder of this paper as follows. Section 2 discusses related works. Section 3 presents our proposed DeepMA method along with the training algorithm. Section 4 presents the performance evaluation results on wireless image transmissions. We also describe the architecture of the DMANet used. Finally, Section 5 concludes the paper.

\emph{Notation}: $\mathbb{C}^n$ and $\mathbb{R}^n$ means the complex and real data with total dimensions $n$ respectively. $x\sim \mathcal{CN}(\mu_x, \sigma_x^2)$ designates variable $x$ follows a circularly-symmetric complex Gaussian distribution with mean $\mu_x$ and $\sigma_x^2$. Variables with bold fonts mean that they are matrices or vectors. $\mathbf{a}\cdot \mathbf{b}$ means the dot-product of vectors $\mathbf{a}$ and $\mathbf{b}$. $\mathbf{x}^*$ means the conjunct transpose of complex variable $\mathbf{x}$. Finally, $\mathbb{E}[x]$ means the expectation value of variable $x$, and $\mathbf{I}$ denotes the identity matrix.

\section{Related Work}

Semantic communication can be used for dealing with a broad range of intelligent inference tasks over the network \cite{qin2021semantic}\cite{shi2021semantic}. These tasks include answering visual questions \cite{xie2021task}, image retrieval \cite{jankowski2020wireless}, speech recognition \cite{weng2021semantic}, and video classification \cite{ozyilkan2020deep}.
In this paper, we mainly consider the semantic communication scenario with the goal of recovering the input data at the receiver, and the data modalities considered can be image/video, speech audio, and language text. For example, for text data transmission, Farsad et.al proposed a bidirectional long short-term memory (BLSTM) network to achieve JSCC. The proposed method achieved a lower word error rate compared with the traditional gzip and Huffman coding methods \cite{farsad2018deep}. Xie et.al \cite{xie2021deep} proposed a deep learning-based semantic communication (DeepSC) system that is built by the Transformer based semantic encoder/decoder along with a fully connected layer-based channel encoder/decoder. During the training process, DeepSC maximizes sentence similarity  by using the bilingual evaluation understudy (BLEU) score, and transfer learning is used for enabling the system to be applicable to different communication environments. Experimental results obtained demonstrate that the proposed SCS approach can achieve higher BLEU compared with traditional communication systems, especially in situations where the channel SNR is low. In a similar way, the authors of \cite{weng2021semantic} proposed DeepSC for speech (DeepSC-S) transmission, and the results demonstrated that DeepSC-S outperforms the traditional speech transmission schemes for both speech recovery quality and noise-resiliency.

In this paper, we focus on using semantic communication for solving wireless image transmission tasks, and related works have shown that DeepJSCC methods can achieve excellent data compression and noise resiliency abilities \cite{cui2021asymmetric}\cite{sujitha2021optimal}\cite{mentzer2020high}\cite{tung2022deepjscc}. In \cite{bourtsoulatze2019deep}, the authors proposed a DeepJSCC method for wireless image transmission. Simulation results showed that the proposed DeepJSCC outperforms the traditional JPEG and JPEG-2000 image compression methods in low SNR regimes. Compared with traditional digital communication schemes, DeepJSCC does not suffer from the 'cliff effect', and it has an strong noise resiliency capability against the degradation of channel SNR. To further improve the performance of JSCC, Kurka et.al \cite{kurka2020deepjscc} proposed the use of channel output feedback to enhance the reliability of the transmission process. The proposed method can achieve better image reconstruction quality but it requires multiple transmissions for one input data. Thus, the communication efficiency will be reduced. Later, the authors proposed the successive refinement-based DeepJSCC method to enhance the quality of the reconstructed images at the receiver \cite{kurka2021bandwidth}. From the perspective of ensemble learning \cite{sagi2018ensemble}, the performance improvements achieved by the above two methods comes from the integration of multiple DeepJSCC models with diverse DeepJSCC models and physical channels, and the quality of the final combined results can be improved compared with using only one single model \cite{yang2020image}\cite{su2020ensemble}.

The proposed DeepJSCC models above suffer from the SNR adaptation problem, i.e., a DeepJSCC model can only perform well when the channel SNR is similar to its training SNR. To achieve the best performance, we need to train several different DeepJSCC models to cover both low and high SNR regimes. To solve this problem, Xu et.al \cite{xu2021wireless} proposed an attention-based DeepJSCC (ADJSCC), which can adaptively adjust the joint source-channel coding process according to the variation of channel SNR. In a low SNR regime, the attention module can automatically guide the model to assign more coding resources to the channel coding process to enhance transmission reliability. On the other hand, in a high SNR regime, more encoding resources will be assigned to the source coding process to improve the compression ratio. Simulation results demonstrated that one ADJSCC model can achieve the best achievable performance of several DeepJSCC models training with different channel SNRs combined. Therefore, ADJSCC can greatly reduce the training and deployment cost of Deep learning-based JSCC models.

Except for the SNR adaptation problem, previous DeepJSCC models were trained with specific code rates or compression ratios, and cannot be changed after training. To achieve multi-rate transmission, in \cite{yang2022deep}, the authors proposed an adaptive DeepJSCC model that can automatically adjust its rate using a single network model. More specifically, in the proposed method the encoder is divided into two separate models: source encoder and channel encoder, and the semantic symbols obtained are divided into two parts: the non-selective part that is always active for transmission, and the selective part that can be active or inactive for transmission. A policy network is introduced for determining which selective channel codes are active for transmission according to the image contents and channel condition. In this way, the proposed method can support multi-rate transmission for semantic communication. In the above work, the proposed method cannot achieve an arbitrary transmission rate, and transmission quality cannot be guaranteed. In \cite{zhang2023predictive}, we proposed a predictive and adaptive deep coding (PADC) framework, which can flexibly adjust compression rates at the same time ensuring the transmission quality constraint for every single image thereby providing an effective solution for solving the rate adaptation problem in DeepJSCC.

All the works discussed above focus on the DeepJSCC problem for achieving point-to-point semantic communication with channel multiplexing, and the orthogonal multiple access problem has not been investigated. Though existing semantic communication systems have been demonstrated effective in conducting the DeepJSCC process, the problem of how to achieve OMA-based multiple access has not yet been investigated. As such, in this paper, we propose DeepMA to achieve channel multiplexing and demonstrate that, by leveraging deep learning, we can obtain effective OMA in semantic communication, and can reap better bandwidth efficiency compared with conventional multiple access schemes.

\begin{figure*}
\centering
\includegraphics[width=0.9\textwidth]{./Figs_new/DeepMA_framework.pdf}
\caption{Our proposed DeepMA for wireless D2D, downlink, and uplink transmissions with channel multiplexing.}
\label{DeepMA}
\end{figure*}

\section{The Proposed DeepMA}
In this section, we describe the design principles and training algorithm of DeepMA.


\subsection{DeepMA method}
DeepMA is inspired by the conventional CDMA-based channel multiplexing method, and the main idea is to train the network with the capability to recover the target data from a mixed semantic symbol vector(MSSV) superposed by several independent component SSVs. In this way, the system can transmit and recover multiple data instances simultaneously over a shared communication channel with the same frequency. To achieve this goal, we propose a DMANet model that is composed of $N$ different transceivers, denoted as $\mathcal{N} = \left\{1,\ldots,N \right\}$.
Accordingly, we have $N$ DeepMA encoder-decoder pairs (EDPs), denoted as $\mathcal{P} = \left\{(E_{\phi_1},D_{\theta_1}),\ldots, (E_{\phi_N},D_{\theta_N}) \right\}$, in which $E_{\phi_i}$ means the DeepMA encoder model of EDP $i$ parameterized by $\phi_i$, and $D_{\theta_i}$ designates the corresponding DeepMA decoder network parameterized by $\theta_i$. The $i$-th EDP corresponds to the $i$-th transceiver, and when $N=1$, DMANet is equivalent to a DeepJSCC network.

We require that a DeepMA decoder can only recover the original input data of the corresponding DeepMA encoder in the same EDP, but cannot recover the data of the unpaired DeepMA encoders.
For EDP $i \in \mathcal{P}$, we denote the input image data as $\mathbf{x}_i \in \mathbb{R}^L$, and before transmitting, it is encoded as a $K$-dimensional complex SSV $\mathbf{y}_i \in \mathbb{C}^{K}$ by using its DeepMA encoder $E_{\phi_i}$, i.e.,
\begin{equation}
\mathbf{y}_i = E_{\phi_i}(\mathbf{x}_i, \gamma_i),
\end{equation}
where $\gamma_i$ denotes the channel SNR. We note that the transmission performance of an EDP is also influenced by the channel condition, and the channel SNR will also be an input data to the Encoder. It is worth pointing out that in the above encoding process, the DeepMA Encoder not only conducts the JSCC process, but also conducts the orthogonal modulation process such that the SSVs obtained are orthogonal to each other.

Then, to meet the power constraint, the SSV to be transmitted is normalized as follows:
\begin{equation}\label{eq:p_norm}
\mathbf{z}_i  = \sqrt{K P_z} \frac{\mathbf{y}_i}{\mathbf{y}_i^{*} \mathbf{y}_i},
\end{equation}
where $P_z>0$ denotes the average transmitting power constraint. The average power constraint $P_z$ can be set to a proper value that is larger than 0, for example, $P_z = 1$. After the power normalization, the SSVs are transmitted to the decoder sides.

In practice, multiple access can be used in the following three wireless transmission scenarios: D2D, downlink, and uplink, and Fig. \ref{DeepMA} shows their corresponding system models. The channel models of the three scenarios are different, and we illustrate them as follows:
\begin{itemize}
  \item \textbf{D2D transmission}: As Fig.\ref{DeepMA}(a) shows, in D2D communication scenario, we ensure that there are $N$ UEs transmitting data, and accordingly there are $N$ UEs receiving data, and one UE transmitter has one and only one paired UE receiver. With the help of DeepMA, we hope to enable the D2D pairs to transmit data over the same shared frequency simultaneously. In all the three scenarios considered, we assume that all the nodes are synchronized and coordinated such that they can transmit the SSVs with the same code length within the same period of time. The SSV $\mathbf{z}_i$ is transmitted to the corresponding receiver, at the same time superposed with other SSVs, and corrupted with additive white gaussian noise (AWGN), and the MSSV received is given by:
    \begin{equation}\label{eq:fad_channel1}
    \mathbf{z}_i^{\text{rev}}  = \sum_{k=1}^{N}  h_{k,i} \mathbf{z}_k + \mathbf{n}_i,
    \end{equation}
    where $h_{k,i}\in \mathbb{C}$ denotes the channel fading coefficient between transmitter $k$ and receiver $i$, and $\mathbf{n}_i \in \mathcal{N}(0, \sigma_i^2 \mathbf{I})$ denotes the independent identically distributed (i.i.d) AWGN samples with power $\sigma_i^2$.
  \item \textbf{Downlink transmission}: For wireless downlink and uplink transmission scenarios, we considered a typical wireless communication scenario with one base station (BS) and $N$ user equipment (UEs), and we want to achieve channel multiplexing to enable the BS and UEs to transmit different data over a shared physical channel with the same transmitting frequency in one time slot. As Fig.\ref{DeepMA}(b) shows, in downlink transmission, all the DeepMA encoders are deployed at the BS, and only one DeepMA decoder is deployed at one UE. In the BS, the data arrived are first encoded as the SSVs by using the DeepMA encoders, then superposed as the MSSV, and subsequently transmitted to the UEs through the downlink channel. In this scenario, we have $h_{1,i}=\ldots=h_{N,i}=h_i$ for $i\in \mathcal{N}$, and the RMSSV is:
    \begin{equation}\label{eq:fad_channel2}
    \mathbf{z}_i^{\text{rev}}  =  h_i \sum_{k=1}^{N} \mathbf{z}_k + \mathbf{n}_i.
    \end{equation}
  \item \textbf{Uplink transmission}:  As Fig.\ref{DeepMA}(c) shows, in the uplink transmission scenario, each UE has one encoder, and the BS has all the decoders. In this scenario, we can know $h_{i,1}=\ldots=h_{i,N}=h_i$ for $i\in \mathcal{N}$. In addition, the AWGN of all RMSSVs are the same, i.e., $\mathbf{n}_N = \ldots=\mathbf{n}_N$. Then we can know the RMSSV as follows:
    \begin{equation}\label{eq:fad_channel3}
    \mathbf{z}_i^{\text{rev}}  =  h_i \sum_{k=1}^{N} \mathbf{z}_k + \mathbf{n}.
    \end{equation}
\end{itemize}

We note that the downlink and uplink transmissions are two specific cases of the general D2D communication scenario.
After the wireless transmission, we can obtain the recovered MSSV (RMSSV) as follows:
\begin{equation}
\tilde{\mathbf{z}}_i = \frac{\mathbf{z}_i^{\text{rev}}}{h_i},
\end{equation}
Finally, the DeepMA decoder $D_{\theta_i}$ can recover the input data by using the RMSSV $\tilde{\mathbf{z}}_i$ obtained, as given by:
\begin{equation}
\tilde{\mathbf{x}}_i = D_{\theta_i}(\tilde{\mathbf{z}}_i, \gamma_i).
\end{equation}
In the decoding process above, the DeepMA Decoder conducts joint orthogonal demodulation and source-channel decoding processes, such that the decoder can extract the target SSV and recover the input data from the RMSSV.


\subsection{DeepMA Training}
As we have previously mentioned, DeepMA can be used in D2D, downlink, and uplink transmission scenarios to achieve co-frequency channel multiplexing. In the model training process, there is no need to train specific models for the three scenarios because downlink and uplink transmissions are two specific cases of the D2D scenario, and one DMANet trained in the D2D scenario can cover all three scenarios.
In DeepMA, each EDP only transmits and recovers its target data $\mathbf{x}_i$, and its loss function is defined as:
\begin{equation}
\mathcal{L}(\theta_i, \phi_i; \mathbf{x}_i) = d(\mathbf{x}_i, \tilde{\mathbf{x}}_i),
\end{equation}
where $d(\mathbf{x}_i, \tilde{\mathbf{x}}_i)$ denotes the distortion metric between the original input $\mathbf{x}_i$ and the recovered result $\tilde{\mathbf{x}}_i$. In this paper, we use the mean square error (MSE) as the distortion metric, and therefore we have $d(\mathbf{x}_i, \tilde{\mathbf{x}}_i) = \Vert \mathbf{x}_i - \tilde{\mathbf{x}}_i \Vert^2 / L$, and $L$ denotes the dimension of input data $\mathbf{x}_i$. It is worth noting that the final result $\tilde{\mathbf{x}}_i$ is recovered from an RMSSV that is mixed by the SSVs transmitted by all the DeepMA encoders, as formulated in equation \eqref{eq:fad_channel1}. The loss function of the whole DMANet is quite simple, and it is set to minimize the average distortions between the input data and the recovered results of all the EDPs, as given by:
\begin{equation}\label{eq:loss}
\begin{aligned}
\mathcal{L}(\Phi, \Theta; \mathbf{X}) & = \frac{1}{N}\mathcal{L}(\theta_i, \phi_i; \mathbf{x}_i) =\frac{1}{N}\sum_{i=1}^{N} d(\mathbf{x}_i, \tilde{\mathbf{x}}_i),
\end{aligned}
\end{equation}
where $\Theta = \left\{\theta_1,\ldots, \theta_N\right\}$ and $\Phi = \left\{\phi_1,\ldots, \phi_N\right\}$ denote the parameters of DeepMA encoders and decoders respectively, $\mathbf{X} = \left\{\mathbf{x}_1,\ldots,\mathbf{x}_N \right\}$ means the input data samples. The loss function above enables us to train the decoders to recover their own target data from a received MSSV in wireless D2D transmission scenarios. By using a gradient descent algorithm, the parameters of the whole DMANet can be learned as:
\begin{equation}
 (\Phi^*, \Theta^*) = \text{argmin}_{\Phi, \Theta} \,\, \mathbb{E}_{\mathbf{x}} \left[\mathcal{L}(\Phi, \Theta; \mathbf{X})\right].
\end{equation}

We note that, except for source-channel coding/decoding, DeepMA encoders and decoders also will be trained with orthogonal modulation and demodulation processes, which are key enablers for achieving OMA-based multiple access with a shared physical channel. In the same way as existing DeepJSCC models, the proposed DeepMA is also trained in an end-to-end way. One main difference is that, since we want to achieve channel multiplexing over the same channel, in each training iteration the input data samples of each EDP must be different, such that the decoders can be trained with the ability to recover different data from an RMSSV. More specifically, if we have $M$ data samples for each DeepMA EDP, and we need $N$ different data batches, then in total, we prepare to get $K\times N$ different training data samples in each training iteration.

Algorithms 1 illustrate the process of one training iteration for DMANet-N in D2D transmission scenarios, in which $\mathcal{E}_{\Phi} = \left\{E_{\phi_1}, \ldots,E_{\phi_N}\right\}$ and $\mathcal{D}_{\Theta} = \left\{D_{\theta_1}, \ldots,D_{\theta_N}\right\}$ denote the DeepMA encoders and decoders respectively, $\mathbf{H} = [h_{i,j}]_{N\times N}$ means the channel state information (CSI) matrix, and $h_{i,j}\in \mathbb{C}$ denotes the CSI between the transmitter $i$ and the receiver $j$. In one training iteration, we first sample different data batches for different EDPs, then forward the data batches $\mathbf{x}_1, \ldots, \mathbf{x}_N$ through the DMANet, and compute the loss by using equation \eqref{eq:loss}, and further compute the gradients of all model parameters. At last, the parameters $ (\Phi, \Theta)$ of DMANet can be updated by using the gradients obtained, and one training iteration is finished. We repeat the training iteration until the loss achieves convergence.

\begin{algorithm}
\caption{One training iteration for DMANet-$N$.}
\begin{algorithmic}[1]
\STATE  \textbf{Input}: Training dataset $\mathbf{X}$, CSI $\mathbf{H}$, learning rate $\eta$;
\STATE  \textbf{Output}: Model parameters $(\Theta, \Phi)$ of DMANet-N;
\STATE  \textbf{Transmitters}:
\STATE  \quad \textbf{for each DeepMA encoder $E_{\phi_i} \in \mathcal{E}_{\Phi}$}:
\STATE  \quad \quad Sample a different training data batch $\mathbf{x}_i$ from $\mathbf{X}$;
\STATE  \quad \quad Compute SSV $\mathbf{y}_i \leftarrow E_{\phi_i}(\mathbf{x}_i)$;
\STATE  \quad \quad Power normalization $\mathbf{z}_i \leftarrow \sqrt{K P_z} \frac{\mathbf{y}_i}{\mathbf{y}_i^{*} \mathbf{y}_i}$;
\STATE  \quad \textbf{end for each}
\STATE  \textbf{Receivers}:
\STATE  \quad \textbf{for each DeepMA decoder $D_{\theta_i}\in \mathcal{D}_{\Theta}$}:
\STATE  \quad \quad Receive MSSV $\mathbf{z}_i^{\text{rev}}  = \sum_{k=1}^{N}  h_{k,i} \mathbf{z}_k + \mathbf{n}_i$;
\STATE  \quad \quad Compute RMSSV $\tilde{\mathbf{z}}_i \leftarrow {\mathbf{z}_i^{\text{rev}}}/{h_{i,i}}$;
\STATE  \quad \quad Recover data $\tilde{\mathbf{x}}_i \leftarrow D_{\theta_i}(\tilde{\mathbf{z}}_i)$;
\STATE  \quad \textbf{end for each}
\STATE  Compute loss $\mathcal{L}(\Phi, \Theta; \mathbf{X})\leftarrow \frac{1}{N} \sum_{i=1}^{N} d(\mathbf{x}_i, \tilde{\mathbf{x}}_i)$;
\STATE  Update model parameters by gradient descent: $$\Theta \leftarrow \Theta - \eta \triangledown_{\Theta} \mathcal{L}(\Phi, \Theta; \mathbf{X}), \Phi \leftarrow \Phi - \eta \triangledown_{\Phi} \mathcal{L}(\Phi, \Theta; \mathbf{X}).$$
\end{algorithmic}
\end{algorithm}


\section{DeepMA for Wireless Image Transmission}

In this section, we evaluate the performance of the proposed DeepMA by conducting simulations on DeepMA-enabled wireless image transmission tasks. First, we describe the architecture of the DMANet used and the experimental settings. Next, we describe the SSV orthogonality to explain why DeepMA can achieve channel multiplexing, at the same time showing its flexibility and privacy properties. We also discuss the user detection problem in DeepMA. Finally, we present the performance evaluation results, along with their analysis.

\begin{figure*}
\centering
\includegraphics[width=0.99\textwidth]{./Figs_new/Net_architecture.pdf}
\caption{Network architecture of one EDP of the DMANet used.}
\label{fig:network}
\end{figure*}

\subsection{Network Architecture}

Fig. \ref{fig:network} shows the architecture of the DMANet used for image transmission with channel multiplexing ability. First, we normalize the input image  with a value range [0, 1], and then passes it through the DeepMA encoder to obtain the SSV. The DeepMA encoder is used for conducting the joint source-channel coding and orthogonal signal modulation process, which is achieved by four residual convolutional blocks (RCBs) and three attention feature blocks (AFBs). The RCBs are used for extracting the image features by using convolutional operations, and the AFB is used for adjusting the image features obtained by the RCBs. In AFB, we first compute the channel-wise mean (CWM) values of the image features. By using the CWM and channel SNR information, we use a simple fully connection (FC) network to predict the importance weights of the feature channels and automatically adjust the learned features with the weights obtained. The authors of \cite{xu2021wireless} provide more detailed introduction of AFB. In each RCB, we use the generalized normalization transformation (GDN) as the normalization layer, which has been demonstrated effective in density modeling and image compression tasks \cite{balle2015density}\cite{balle2017end}. The RCB is designated as $m\times n \times c \,\,| \downarrow s$, where $m,n,c, s$ correspond to the height, width, output channel number, and downsampling stride length respectively of the convolutional layer used. When the stride length is $s=1$, then the shape of the output data is the same as the shape of the input data. When the stride length is $s=2$, the height and weight of the output data is half of the input data. For the channel number $c$, the maximum channel number is $256$, and in the first RCB, the channel number is $128$, which is helpful for reducing memory space when the input image is large. In the last RCB, the channel number $c$ is used for adjusting the data compression ratio, and a relatively larger value of $c$ produces a better image recovery quality, but the transmission efficiency will be reduced. We denote $H$ and $W$ as the height and width of the input image respectively because we have three downsampling operations with $s=2$. Then we know the shape of the output data of the last RCB which is ${H}/{8}\times{W}/{8} \times c$. In this way, we define the bandwidth efficiency performance as the following symbol per pixel (SPP) metric:
\begin{equation}
\text{SPP}(c) = \frac{{H}/{8}\times{W}/{8} \times c}{H \times W} = \frac{c}{64}.
\end{equation}
After the reshape operation, we transform the image feature as a $K$-dimensional complex SSV, and we can know $K = \frac{HW}{128}$. We note that a complex semantic symbol is composed of two real semantic features. Accordingly, we define complex SPP (CSPP) metric as follows:
\begin{equation}
\text{CSPP}(c) = \frac{c}{128}.
\end{equation}
We observe that $\text{SPP}(c) = 2\text{CSPP}(c)$. For DMANet-N, it can support at most $N$ transmissions simultaneously. Therefore the achievable minimal CSPP (MinSCPP) is:
\begin{equation}
\text{MinCSPP}(c, N) = \frac{c}{128N}.
\end{equation}
For example, if we set $c=128$, for an ADJSCC model or one EDP, the CSPP is 1, and for DMANet-2, the MinCSPP is 0.5. In this paper, when the MinCSPP of a DeepMA model is equal to the CSPP of an ADJSCC model, we say that their achievable code rates are the same.

The DeepMA decoder is used for conducting the joint signal filtering and channel-source decoding process to recover the original input image with the RMSSV obtained.
Like the DeepMA encoder, the architecture of a DeepMA decoder is composed of four residual transpose convolutional blocks (RTCB) and three AFBs. The main difference between RTCB and RCB is that RTCB uses a transconvolution operation for reconstructing the image and uses an inverse GDN (IGDN) operation for feature normalization. Accordingly, since we want to recover the original image from the RMSSVs received, in the last three RTCBs, we use three upsampling operations with stride length $s=2$ to ensure the size of the recovered image is the same as the original input image. Finally, we denormalize the output image as 8-bit integer pixels within the range [0, 255].


\subsection{Simulation Settings}


We evaluated the performances of our proposed DeepMA on CIFAR100 \cite{CIFAR} and Kodak24 \cite{Kodak24} data transmission tasks with channel multiplexing, and we also tested the performance of the state-of-the-art ADJSCC model for non-multiplexing transmissions.
For an EDP model and an ADJSCC model, when the model architecture and the achievable code rates are the same, we expect that ADJSCC will achieve better performance compared with the DeepMA model because achieving orthogonal modulation and filtering will incur additional model encoding and decoding resources, and the used model resource for joint source-channel coding will be reduced. Note that model resources in this paper means the black-box computation process of the model. We used the following simulation settings in our performance evaluation tests:

\textbf{CIFAR100 data transmission}: In this test, we will use CIFAR10 \cite{CIFAR10} data as the training data and validation data, and then test the transmission performance on CIFAR100 test data. Both CIFAR10 and CIFAR100 contain 60000 color image samples with size $32\times 32$, in which 5000 images are training samples, and the remaining 1000 images are test samples. We will first train the semantic communication models by using CIFAR10 training data, and at the end of each training epoch, we validate the performance of the current model using the CIFAR10 test data. We implement DMANet and the ADJSCC models in the Pytorch environment, the batch size per EDP is set as 64. The initial learning rate is set as $\eta = 5\times 10^{-4}$. After 100 epochs and 200 epochs, it is decreased as  $\eta = 1\times 10^{-4}$ and  $\eta = 5\times 10^{-5}$ respectively. The maximal number of training epochs is set as 400.
In each training epoch, we first update the model by training data, then evaluate the performance of the model on the validation data. If the achieved performance is better than the best performance previously achieved, we save the model as the final model, otherwise, the final model will not be updated. After training, we use CIFAR100 test data to test the transmission performance of the proposed DeepMA and ADJSCC models.

\textbf{Kodak24 data transmission}: In this test, we used the ImageNet \cite{deng2009imagenet} data to train the DeepMA and ADJSCC models pretrained on the CIFAR10 data. Since the model is previously trained on small-scale CIFAR10 data, the training time and the number of ImageNet training samples used can be reduced. The original ImageNet data has more than one million color images, and in this paper we only used ImageNet validation dataset as the training data and validation data, in which the first 45000 images are used as training samples and the remaining 5000 images are used as the validation dataset. The image size of ImageNet can be different, thus we set the input image size to $128\times 128$ by using the center-crop operation.
As pretrained models are used, the training epochs on ImageNet data are not required to be too large, and we set the maximal epoch number to 200. We set the initial learning rate to $\eta = 1\times 10^{-4}$, and then gradually decreasing to $5\times 10^{-5}$, $1\times 10^{-5}$, and $1\times 10^{-6}$ at the 100th, 160-th, and 190-th epochs respectively. In the same way with the CIFAR10 data training process, at the end of each training epoch, we tested the performance of the models obtained on the validation data, and if the performance is better than the best performance previously achieved, we updated the final model, otherwise, the final model remains unchanged.
After model training, we use the Kodak24 data to test the performance of the model obtained. The Kodak24 data is composed of 24 color images with size $768\times 512$, and it is a widely used benchmark for evaluating the image quality of image reconstruction tasks. Since the number of images is quite limited, we therefore used the average performance on 100 tests to avoid performance fluctuation caused by the uncertain SSV transmission process.

\subsection{Performance Evaluation Metrics}
To evaluate the quality of the images recovered, we used peak signal-to-noise ratio (PSNR) \cite{hore2010image} as the performance metric, and it is defined as:
\begin{equation}
\text{PSNR} = 10\log_{10} \frac{\text{MAX}^2}{\text{MSE}},
\end{equation}
where $\text{MSE}$ is the mean-squared error between the original input image and the image recovered, and $\text{MAX}$ means the allowable peak pixel value of the images. Since the images used is 8-bit per pixel, the signal peak value is $\text{MAX} = 2^8 -1=255$. A higher PSNR means better quality of the recovered image because the MSE becomes lower. In one DeepMA model, the PSNR performance results  of the EDPs can be slightly different from each other. Thus, we used the average value of the PSNRs of all EDPs as the PSNR performance of a DMANet.

During the transmission process, the channel SNR may significantly affect the quality of the image recovered, and the channel SNR of EDP $i$ is defined as:
\begin{equation}
\text{SNR} =  10\log_{10} \frac{P_z}{\sigma_i^2},
\end{equation}
where $P_z$ denotes the average transmitting power of the SSV $\mathbf{z}$, and as we have mentioned before we set $P_z=2P_0 = 2$.


\begin{figure*}
\centering
 \subfigure[Kodim22, $\mathbf{x}_1$, EDP $(E_{\phi_1}, D_{\theta_1})$]{
 \includegraphics[width=0.3\textwidth]{./Examples/kodak22_original.png}}
 \subfigure[Kodim23, $\mathbf{x}_2$, EDP $(E_{\phi_2}, D_{\theta_2})$]{
 \includegraphics[width=0.3\textwidth]{./Examples/kodak23_original.png}}
 \subfigure[Kodim24, $\mathbf{x}_3$, EDP $(E_{\phi_3}, D_{\theta_3})$]{
 \includegraphics[width=0.3\textwidth]{./Examples/kodak24_original.png}}
 \subfigure[$\mathbf{z}_1^{\text{rev}}  =\sum_{i=1}^{3} (h_{i,1}\mathbf{z}_i + \mathbf{n}_1)$, 33.53dB]{
 \includegraphics[width=0.3\textwidth]{./Examples/kodak22_rec.png}}
 \subfigure[$\mathbf{z}_2^{\text{rev}} =\sum_{i=1}^{3} (h_{i,2}\mathbf{z}_i + \mathbf{n}_2), D_{\theta_2}$, 36.47dB]{
 \includegraphics[width=0.3\textwidth]{./Examples/kodak23_rec.png}}
 \subfigure[$\mathbf{z}_3^{\text{rev}}=\sum_{i=1}^{3} (h_{i,3}\mathbf{z}_i + \mathbf{n}_3), D_{\theta_3}$, 35.01dB]{
 \includegraphics[width=0.3\textwidth]{./Examples/kodak24_rec.png}}
 \subfigure[$\mathbf{z}_1^{\text{rev}}=h_{1,1}\mathbf{z}_1 + \mathbf{n}_1, D_{\theta_1}$, 33.54dB]{
 \includegraphics[width=0.3\textwidth]{./Examples/kodak22_rec.png}}
 \subfigure[$\mathbf{z}_2^{\text{rev}}=h_{2,2}\mathbf{z}_2 + \mathbf{n}_2, D_{\theta_2}$, 36.35dB]{
 \includegraphics[width=0.3\textwidth]{./Examples/kodak23_rec.png}}
 \subfigure[$\mathbf{z}_3^{\text{rev}}=h_{3,3}\mathbf{z}_3 + \mathbf{n}_3, D_{\theta_3}$, 35.06dB]{
 \includegraphics[width=0.3\textwidth]{./Examples/kodak24_rec.png}}
 \subfigure[$\mathbf{z}_1^{\text{rev}}=\sum_{i=2}^{3} (h_{i,1}\mathbf{z}_i + \mathbf{n}_i), D_{\theta_1}$]{
 \includegraphics[width=0.3\textwidth]{./Examples/dec1_23.png}}
 \subfigure[$\mathbf{z}_2^{\text{rev}}=\sum_{i=1,i\neq 2}^{3} (h_{i,2}\mathbf{z}_i + \mathbf{n}_i), D_{\theta_2}$]{
 \includegraphics[width=0.3\textwidth]{./Examples/dec2_13.png}}
 \subfigure[$\mathbf{z}_3^{\text{rev}}=\sum_{i=1}^{2} (h_{i,3}\mathbf{z}_i + \mathbf{n}_i), D_{\theta_3}$]{
 \includegraphics[width=0.3\textwidth]{./Examples/dec3_12.png}}
\caption{Examples of the images reconstructed by DMANet-3 for wireless image transmission with slow Rayleigh fading channel, we set MinCSPP to 0.5, and the channel SNRs of EDPs $(E_{\phi_1}, D_{\theta_1})$, $(E_{\phi_2}, D_{\theta_2})$ and $(E_{\phi_3}, D_{\theta_3})$ to 8 dB, 12 dB, and 16 dB respectively.}
\label{fig:sma3_examples}
\end{figure*}


\subsection{Illustrative Examples of DMANet-3}

In this subsection, we present some image examples reconstructed by DMANet-3 for the D2D wireless image transmission scenario. Fig. \ref{fig:sma3_examples} shows the example images, in which subfigures (a)-(c) are the three original input images, and subfigures (d)-(l) are the reconstructed images obtained with different RMSSVs. The three example images used are kodim22, kodim23, and kodim24, and they are denoted as $\mathbf{x}_1$, $\mathbf{x}_2$, and $\mathbf{x}_3$ respectively. We transmitted three images independently by three different transmitters, and the EDPs used for $\mathbf{x}_1$, $\mathbf{x}_2$, and $\mathbf{x}_3$ are $(E_{\phi_1}, D_{\theta_1})$, $(E_{\phi_2}, D_{\theta_2})$, and $(E_{\phi_3}, D_{\theta_3})$ respectively. The corresponding normalized SSVs of the three images are $\mathbf{z}_1$, $\mathbf{z}_2$, and $\mathbf{z}_3$. We set the channel to a slow Rayleigh fading channel, and we set the channel SNRs of the three paths to 8dB, 12dB, and 16dB. Using the settings above, we conducted the following three tests:

\textbf{Test 1: Channel multiplexing}. In this test, the wireless channel is multiplexed by the three transceivers, and the received MSSV of the receiver $k$ is $\mathbf{z}_k^{\text{rev}}  =\sum_{i=1}^{3} (h_{i,k}  \mathbf{z}_i + \mathbf{n}_k)$. We then can compute the RMSSV of $D_{\theta_1}$, $D_{\theta_2}$, and $D_{\theta_3}$ as: $\tilde{\mathbf{z}}_1 = \mathbf{z}^{\text{rev}}/h_1$, $\tilde{\mathbf{z}}_2 = \mathbf{z}^{\text{rev}}/h_2$, and $\tilde{\mathbf{z}}_3 = \mathbf{z}^{\text{rev}}/h_3$ respectively. Finally, we can obtain the final reconstructed images as: $\tilde{\mathbf{x}}_1 = D_{\theta_1}(\tilde{\mathbf{z}}_1)$, $\tilde{\mathbf{x}}_2 = D_{\theta_2}(\tilde{\mathbf{z}}_2)$, and $\tilde{\mathbf{x}}_3 = D_{\theta_3}(\tilde{\mathbf{z}}_3)$, and subfigures (d)-(f) plot the results obtained.
Visually, we can observe that the recovered images are the same as their original input images. More precisely, the PSNRs of three recovered images $\tilde{\mathbf{x}}_1$, $\tilde{\mathbf{x}}_2$, and $\tilde{\mathbf{x}}_3$ are 35.53 dB, 36.47 dB, and 35.01 dB respectively, which demonstrate that DMANet3 can achieve the channel multiplexing process while at the same time yields good image reconstruction quality.

\textbf{Test 2: Dedicated communication}. In this test, the channel is dedicated to only one EDP. In other words, only one transmitter transmits data at a one-time slot. In this scenario, the SSVs received from the receivers $D_{\theta_1}$, $D_{\theta_2}$, and $D_{\theta_3}$ are $\mathbf{z}_1^{\text{rev}}=h_1\mathbf{z}_1 + \mathbf{n}_1$, $\mathbf{z}_2^{\text{rev}}=h_2\mathbf{z}_2 + \mathbf{n}_2$, and $\mathbf{z}_3^{\text{rev}}=h_3\mathbf{z}_3 + \mathbf{n}_3$ respectively, and the subfigures (g)-(i) show the corresponding reconstructed images. We observe that the PSNRs of the reconstructed images $\tilde{\mathbf{x}}_1$, $\tilde{\mathbf{x}}_2$, and $\tilde{\mathbf{x}}_3$ are 35.54 dB, 36.35 dB, and 35.06 dB respectively, which show that DMANet can recover the results in a dedicated communication scenario. It is also worth noting that the quality of the images recovered is the same as in the previous channel multiplexing scenario. These results show that, in the channel multiplexing scenario, the undesired SSVs received by one EDP decoder do not affect the final reconstructed result. This is because these SSVs are mutually orthogonal, and the decoders can automatically filter out the non-desired SSVs. In this way, we note that DeepMA can work in a flexible way to support both multiplexing and non-multiplexing transmissions.

\textbf{Test 3: Cross decoding}. In this test, a DeepMA encoder does not send any SSV to the channel, but its paired DeepMA decoder tries to recover the image from the received MSSVs transmitted from other unpaired DeepMA encoders. For example, we try to recover the result of $\mathbf{z}^{\text{rev}}=\sum_{i=2}^{3} (h_i  \mathbf{z}_i + \mathbf{n}_i)$ by using the DeepMA decoder $D_{\theta_1}$, and subfigure (j) shows the result obtained. We observe that the image obtained is pure black, and all the pixels are 0. Subfigures (k)(l) show similar results. From these results, we conclude that a DeepMA decoder can only recover images from the MSSVs containing the SSV component transmitted by the paired DeepMA encoder, otherwise, nothing useful can be obtained. Therefore, a DeepMA model itself can therefore achieve good privacy protection.

\subsection{SSV Orthogonality}

\begin{table}
\centering
\caption{Correlation matrix of the three complex SSVs}
\begin{tabular}{|c|c|c|c|} \hline
   & $\mathbf{z}_1$ & $\mathbf{z}_2$ & $\mathbf{z}_2$ \\ \hline
  $\mathbf{z}_1$ & 2 & $2.32\times 10^{-5}$ & $2.04 \times 10^{-5}$ \\ \hline
  $\mathbf{z}_2$ & $2.32\times 10^{-5}$ & 2 & $9.55 \times 10^{-5}$ \\ \hline
  $\mathbf{z}_3$ & $2.04 \times 10^{-5}$ & $9.55 \times 10^{-5}$ & 2 \\ \hline
\end{tabular}
\label{tab:Rz}%
\end{table}%

\begin{table}
\centering
\caption{Correlation matrix of the three real SSVs}
\begin{tabular}{|c|c|c|c|} \hline
   & $\mathbf{v}_1$ & $\mathbf{v}_2$ & $\mathbf{v}_2$ \\ \hline
  $\mathbf{v}_1$ & 1 & $-8.01\times 10^{-6}$ & $1.02 \times 10^{-5}$ \\ \hline
  $\mathbf{v}_2$ & $-8.01\times 10^{-6}$ & 1 & $-4.77\times 10^{-5}$ \\ \hline
  $\mathbf{v}_3$ & $1.02\times 10^{-5}$ & $-4.77 \times 10^{-5}$ & 1 \\ \hline
\end{tabular}
\label{tab:Rv}%
\end{table}%

\begin{figure}
\centering
\includegraphics[width=0.45\textwidth]{./Figs_new/SMA_deployment.pdf}
\caption{Using a SSV gate for solving the user detection problem.}
\label{fig:deployment}
\end{figure}

We have seen that DeepMA achieves a flexible, effective, and secure communication process with channel multiplexing. The reason why DeepMA can be so powerful is because the DeepMA model can achieve an orthogonal signal modulation process, such that the recovered results of one decoder will beare not influenced by other SSVs sent from the unpaired encoders. In this subsection, we provide an example to demonstrate the orthogonality of the SSVs. In this test, we used the environment settings as the test used in subfigures \ref{fig:sma3_examples}(d)(e)(f). To quantify the orthogonality, we first define the correlation metric between complex SSVs $\mathbf{z}_i$ and $\mathbf{z}_j$ as follows:
\begin{equation}\label{eq:R_z}
R_z(\mathbf{z}_i, \mathbf{z}_j) = \frac{1}{K} \mathbb{E} [\mathbf{z}_i^*\mathbf{z}_j],
\end{equation}
We can see that when $i=j$, the correlation metric above is equal to the average signal power of the SSV, i.e., $R(\mathbf{z}_i, \mathbf{z}_j) = P_z$. As we have mentioned before, in this paper, we set $P_z = 2$.
We compute the correlation matrix of the SSVs obtained from the DMANet3 on kodim22, kodim23, and kodim24, and Table \ref{tab:Rz} presents the results. We can observe that, for $i,j \in \left\{1,2,3\right\}$, when $i\neq j$, the value of $R(\mathbf{z}_i, \mathbf{z}_j)$ are very close to zero, which means that the three SSVs $\mathbf{z}_1$, $\mathbf{z}_2$, and $\mathbf{z}_3$ are orthogonal to each other.
Next, we transform the $K$-dimensional complex SSVs as $2K$-dimensional real SSVs as follows: $\mathbf{v}_i = [\text{Re}(\mathbf{z}_i); \text{Im}(\mathbf{z}_i)]$, then we can define the correlation metric between real SSVs $\mathbf{v}_i$ and $\mathbf{v}_j$ as follows:
\begin{equation}\label{eq:R_v}
R_v(\mathbf{v}_i, \mathbf{v}_j) = \frac{1}{2K} \langle\mathbf{v}_i,\mathbf{v}_j \rangle,
\end{equation}
where $\langle\mathbf{v}_i,\mathbf{v}_j \rangle$ means the inner product of $\mathbf{v}_i$ and $\mathbf{v}_j$. According to the above definition, we can expect that $R_z(\mathbf{z}_i, \mathbf{z}_j)=2R_v(\mathbf{v}_i, \mathbf{v}_j)$. Accordingly, we compute the correlation matrix of the three real SSVs, and Table \ref{tab:Rv} shows the result obtained. Again, we observe that the three real SSVs $\mathbf{v}_1$, $\mathbf{v}_2$, and $\mathbf{v}_3$ are orthogonal to each other. We note that the SSVs are not strictly orthogonal to each other, as we can see the average inner product of two different real SSVs is only close to zero, but not equal to zero.

From the results above, we can see that joint source-channel encoding and orthogonal modulation processes are jointly conducted in the DeepMA encoder, and the SSVs obtained are orthogonal to each other, which enables different transceivers to transmit data over a shared physical channel without causing mutual interferences. This SSV orthogonality can be used for solving the user detection problem in DeepMA. More specifically, if the received MSSV is not a desired one, i.e., it does not contain the SSV component transmitted from the paired DeepMA encoder, it is better to be abandoned to avoid unnecessary decoding computations to reduce energy cost. On the other hand, as we have seen in Fig. \ref{fig:sma3_examples}, the decoder will not be able to recover any useful information if the input RMSSV is not a desired one. Therefore, before the decoding process, we must conduct a user detection process to classify whether the received MSSV contains the target SSV that is sent from the paired DeepMA encoder. In DeepMA, the user detection problem can be solved by utilizing the SSV orthogonality. As Fig. \ref{fig:deployment} shows, when an MSSV is received, we then can compute the corresponding RMSSV according to the CSI, and subsequently, use an SSV gate to determine whether to accept the RMSSV to conduct the following decoding process. We need to prepare several reference SSV samples that are generated by the paired DeepMA encoder, and then determine whether the RMSSV is a target one by using equation \eqref{eq:R_z} or \eqref{eq:R_v}. If the average correlation metric obtained $R_z$ or $R_v$ is not close to 0, then the RMSSV is not a desired one, and it can be abandoned, otherwise, it is a target one, and further, we can use the DeepMA decoder to recover the input data.


\begin{figure*}
\centering
 \subfigure[]{
 \includegraphics[width=0.45\textwidth]{./Figures/CIFAR100_AWGN_025.eps}}
  \subfigure[]{
 \includegraphics[width=0.45\textwidth]{./Figures/CIFAR100_AWGN_050.eps}}
\caption{Comparison of the PSNR performances of DeepMA and ADJSCC on CIFAR100 data in the AWGN channel case.}
\label{fig:cifar_awgn}
\end{figure*}

\begin{figure*}
\centering
 \subfigure[]{
 \includegraphics[width=0.45\textwidth]{./Figures/CIFAR100_Fading_025.eps}}
  \subfigure[]{
 \includegraphics[width=0.45\textwidth]{./Figures/CIFAR100_Fading_050.eps}}
\caption{Comparison of the PSNR performances of DeepMA and ADJSCC on CIFAR100 data in the slow Rayleigh fading channel case.}
\label{fig:cifar_fading}
\end{figure*}

\subsection{Results on CIAFR100 Data}

In this subsection, we evaluate the PSNR performances of the proposed DeepMA and ADJSCC models on CIFAR100 data transmissions. Our main goal is to demonstrate that the proposed DeepMA can achieve effective channel multiplexing in wireless transmission scenarios, and at the same time show how the number of EDPs influences the performance of a DeepMA model. In a general D2D communication scenario, the SNRs of the transceivers can be different. To control the channel SNR and improve the legibility of the results, we set the SNRs of all transceivers to be the same. We note that, downlink and uplink transmissions are two specific cases of D2D transmissions, and we will test the performances of the D2D transmission case, and results of uplink and downlink transmission will not be presented due to the space limit.

Figs. \ref{fig:cifar_awgn} and \ref{fig:cifar_fading} show the PSNR performance results obtained with increasing channel SNRs. In all tests, the network architecture of the ADJSCC model used is the same as the EDP models of the DMANets used. For the ADJSCC model, we evaluated the PSNR performances with two code rates, namely CSPP=0.25 and CSPP=0.5, and the corresponding output channels of the encoder model are 32 and 64. For a DMANet-$N$ model, we also have $32N$ and $64N$. It is worth noting that, for one EDP, its CSPP is $N$ times the MinCSPP of DMANet-n, i.e., CSPP=$N\times$MinCSPP. We denote the two code choices as $\alpha=\left\{0.25, 0.5\right\}$, and from the two figures, we observ that, when the compression rates are the same, the proposed DMANet can even achieve higher PSNRs when the channel SNR is not very high, but the PSNR performances of ADJSCC can be higher when channel SNR is high. These results first demonstrate that the proposed DeepMA method can achieve an effective OMA process and a stronger transmission ability than ADJSCC models for point-to-point transmission in a low SNR regime. One plausible reason is because when the bandwidth efficiency of ADJSCC and DMANet-$N$ are the same, the code length of DMANet-$N$ is $N$ times than the SSV of ADJSCC, and therefore incurs more total code resources on the channel coding process. In addition, in the training process, an EDP is trained with the ability to recover data from the interferences of other EDPs, which may be helpful for further enhancing the noise-resiliency capability of the EDPs. When the channel SNR is very high (e.g., 25 dB), the impact of noises is quite limited, and the code resources will be mainly used for the source coding process. However, the DMANet also needs to allocate more resources to the orthogonal modulation process, and therefore its remaining source coding resources will be lower than ADJSCC, and the PSNR performance achieved will be relatively lower.

Next, we compare the PSNRs achieved by the DMANet models with different numbers of EDPs. We denote the $\text{PSNR}^{(N)}$ as the PSNR performance of the DMANet-$N$ model, and let $\text{PSNR}^{(1)}$ be the PSNR of the ADJSCC model. Then, from Fig. \ref{fig:cifar_awgn}, we can see that, in the low SNR regime, the PSNR performance rank is $\text{PSNR}^{(1)}>\text{PSNR}^{(2)}>\ldots>\text{PSNR}^{(5)}$, while in the high SNR regime, the PSNR performance rank is $\text{PSNR}^{(1)}<\text{PSNR}^{(2)}<\ldots<\text{PSNR}^{(5)}$. Possible reasons could include: with the increasing EDN number $N$, the code length of a DAMNet model becomes larger, and it is trained with a stronger ability for dealing with more complex interferences. It also can be possible that the DMANet model has more total channel coding resources which increase the noise-resiliency ability. When the channel SNR is high, the average source coding resources reduce because model resources for orthogonal modulation increase, and the source coding performance decreases. The results in Fig. \ref{fig:cifar_fading} are the same as those in Fig. \ref{fig:cifar_awgn} when the EDP number is smaller than 4. We observe that, in Fig. \ref{fig:cifar_fading}(a), the performance of DeepMA-$5$ is significantly lower than ADJSCC and other DeepMA schemes. Similarly, in Fig. \ref{fig:cifar_fading}(b), the performance of DeepMA-$4$ and DeepMA-$5$ are lower than the other schemes. This result again shows that achieving the orthogonal modulation and demodulation process requires non-negligible model resources, especially as the EDP number increases. From these results, we can conclude that, in a complex fading channel case, a too-large EDP number may cause a negative impact on the transmission performance, and it is not suggested to use a high EDP number to avoid significant performance loss.


\subsection{Results on Kodak24 Data}

In this subsection, we compare the PSNR performances of ADJSCC and the proposed DeepMA method achieved on the kodak24 data, whose resolution is much higher than the CIFAR100 data. For a fair comparison, in each test, the architecture of a used ADJSCC model is the same with one EDP of a DeepMA model, and the CSPP of the ADJSCC model is equal to the MinCSPP of the DeepMA model. Except for ADJSCC and DeepMA models, we also evaluated the performance of conventional wireless communications schemes that use BPG and LDPC codecs to achieve source coding and channel coding respectively. BPG is a well-known image \cite{BPG} codec based on discrete Fourier transform and intra-frame encoding, and it can achieve better image compression performance compared with the JPEG and the JPEG2000 standard \cite{BPG}. For LDPC, we used the channel coding scheme used in IEEE 802.11n protocol \cite{mahdi2020multirate}. We set the code block length to 1296, and we evaluated the performance of the following three code combinations $(648, 648)$, $(864, 432)$, and $(972, 324)$, and the corresponding code rates are 1/2, 2/3,  respectively. In general, a relatively larger code rate increases the transmission efficiency but decreases the noise resiliency capability.  For the conventional communications scheme, the term $\text{LDPC}(R)$ means that the code rate of the LDPC code is $R$, and $R\in \left\{1/2,2/3,3/4\right\}$. For signal modulation, we tested the following 3 modulation orders: 4QAM, 16QAM, and 64QAM, and the corresponding number of bits per symbol is 2, 4, and 6 respectively. we note that the modulation order also significantly influences transmission efficiency and reliability. A relatively larger modulation order means a higher transmission efficiency and a lower transmission reliability. For conventional multiple access schemes, we assume that the OFDMA and TDMA schemes are used, and we equally allocate the frequency or timeslot resources to the UEs, such that the code length of each UE in the transmission is the same as each other. The proposed DeepMA can support co-frequency transmission, while OFDMA and TDMA cannot do so because they must allocate dedicated transmission resources for each UE. We did not compare the performance to CDMA-based multiple access schemes, because CDMA uses orthogonal basis codes to represent 1-bit data, and this digital coding process will greatly reduce the transmission bandwidth efficiency. Given the same bandwidth efficiency, the PSNR performances achieved with CDMA-based multiple access will be much lower than OFDMA and TDMA.

\begin{figure*}
\centering
 \subfigure[]{
 \includegraphics[width=0.45\textwidth]{./Figures/AWGN_025.eps}}
  \subfigure[]{
 \includegraphics[width=0.45\textwidth]{./Figures/AWGN_050.eps}}
\caption{Comparison of the PSNR performances of DeepMA, ADJSCC, and conventional BPG+LDPC-based transmission schemes achieved on the  Kodak24 data in the AWGN channel case.}
\label{fig:kodark24_comp_awgn}
\end{figure*}

\begin{figure*}
\centering
 \subfigure[]{
 \includegraphics[width=0.45\textwidth]{./Figures/Fading_025.eps}}
  \subfigure[]{
 \includegraphics[width=0.45\textwidth]{./Figures/Fading_050.eps}}
\caption{Comparison of the PSNR performances of DeepMA, ADJSCC, and conventional BPG+LDPC-based transmission schemes achieved on the Kodak24 data in the slow Rayleigh fading channel case.}
\label{fig:kodark24_comp_fading}
\end{figure*}

Figs. \ref{fig:kodark24_comp_awgn} and \ref{fig:kodark24_comp_fading} show the results obtained in the case of the AWGN channel and the slow Rayleigh fading channel case. In a general D2D communication scenario, the SNRs of the transceivers can be different. Similar to the results in Figs. \ref{fig:cifar_awgn} and \ref{fig:cifar_fading}, we can observe that, compared with ADJSCC, in both AWGN and slow Rayleigh fading channels, the proposed DeepMA can achieve higher PSNR performances in the low SNR regime (e.g., 15dB in Fig. \ref{fig:kodark24_comp_awgn}(a)), but lower PSNR performances in a high SNR regime. In addition, we can also see that, in the slow Rayleigh fading channel case, a high EDP number will decrease the PSNR performance. We have explained the reasons for these results in the previous subsection, and we do not repeat the explanations here.

Finally, we compare the PSNR performances of the proposed DeepMA, ADJSCC, and conventional BPG+LDPC-based transmission schemes. We observe from, Figs. \ref{fig:kodark24_comp_awgn} and \ref{fig:kodark24_comp_fading}, that the performances of conventional schemes suffered from the cliff effect. Moreover, when the channel SNR is very low, e.g., lower than 0dB, the conventional schemes used even fail to transmit data. On the contrary, for both ADJSCC and the proposed DeepMA, the cliff effect does not exist, and they can still transmit data even when the channel SNR is very low. These results highlight the noise-resilience ability of ADJSCC and DeepMA. However, except for a very low SNR regime, the results obtained show that both ADJSCC and the proposed DeepMA can achieve better PSNR performances compared with conventional schemes. When MinCSPP is 0.25, conventional LDPC+BPG schemes with 64QAM can achieve much higher PSNR than DeepMA. This performance gap becomes much smaller when the MinCSPP is 0.5, and we note that DeepMA can achieve closer performance to conventional schemes. These results show that DeepMA still needs more effective deep learning models and training methods to improve its ability. However, in this work, our main goal is to demonstrate the effectiveness of DeepMA rather than achieving higher transmission performance than conventional BPG+LDPC schemes in all situations. In future work, we will explore the design of a more powerful network architecture to improve the transmission performance of the proposed DeepMA model.

\section{Conclusion}

In this paper, we have proposed DeepMA for achieving OMA-based channel multiplexing in semantic communication systems.
We formulated the DeepMA models for D2D, downlink, and uplink wireless communication scenarios, and we illustrated their training algorithm. We demonstrated the performance of the proposed DeepMA model on wireless image transmission tasks, and we presented the network architecture of the models used. We trained the ADJSCC and DeepMA models by using both low-resolution and small-scale CIFAR10 data and high-resolution and large-scale ImagNet data, and we evaluated the PSNR performances by using the CIFAR100 data and the kodak24 data. The results obtained show that the proposed DeepMA method can achieve effective, flexible, and privacy-preserved multiple access, and also showed that achieved orthogonal signal modulation will reduce performance compared with an ADJSCC model with the same encoding and decoding resources.


\bibliographystyle{unsrt}
\bibliography{References}

%\section{Biographies}
%\textbf{Wenyu Zhang} (wenyuzhang@bjtu.edu.cn) received the B.S. and M.S. degrees in communication engineering from Beijing Jiaotong University, Beijing, China, in 2013 and 2016, respectively, where he is currently working toward the Ph.D. degree in communication engineering. He has been a visiting student at the University of British Columbia since November, 2018. His research interests include edge/fog computing and machine learning algorithms.


\end{document} 