\begin{abstract}
Most recent test-time adaptation methods focus on only classification tasks, use specialized network architectures, destroy model calibration or rely on lightweight information from the source domain. To tackle these issues, this paper proposes a novel \textbf{Te}st-time \textbf{S}elf-\textbf{L}earning method with automatic \textbf{A}dversarial augmentation dubbed \textbf{TeSLA} for adapting a pre-trained source model to the unlabeled streaming test data. In contrast to conventional self-learning methods based on cross-entropy, we introduce a new test-time loss function through an implicitly tight connection with the mutual information and online knowledge distillation. Furthermore, we propose a learnable efficient adversarial augmentation module that further enhances online knowledge distillation by simulating high entropy augmented images. Our method achieves state-of-the-art classification and segmentation results on several benchmarks and types of domain shifts, particularly on challenging measurement shifts of medical images. TeSLA also benefits from several desirable properties compared to competing methods in terms of calibration, uncertainty metrics, insensitivity to model architectures, and source training strategies, all supported by extensive ablations. Our code and models are available on \href{https://github.com/devavratTomar/TeSLA}{GitHub}.\vspace{-0.5em}
\end{abstract}
%
%\behzad{TeSLA builds upon online knowledge distillation between the teacher and student networks. Our test-time objective minimizes flipped cross-entropy (\textit{f-$\mathbb{CE}$}) between the student model's prediction and the soft pseudo-labels obtained from the teacher and simultaneously maximizes the entropy of class-marginalized predictions. We show our objective's equivalence to mutual information maximization with implicit teacher-student distillation, further enhanced by the proposed automatic adversarial augmentations.}
% \begin{abstract}
% \Devavrat{For vision-related tasks, the test-time adaptation of pre-trained deep neural networks after deployment on the test domain is highly desirable but challenging as access to the source training dataset is restricted after model deployment. This paper proposes a novel test-time self-learning algorithm SLug that minimizes the cross-entropy of the model's predictions from their corresponding soft-pseudo labels obtained from an exponentially averaged teacher and maximizes class-marginalized entropy of the model's predictions. We show our method's equivalence to mutual information maximization with knowledge distillation from the teacher and further exploit it by enforcing consistency between the model's predictions on adversarially augmented images with their corresponding soft-pseudo labels. We learn the online adversarial augmentations that \textbf{expand} feature representations of augmented images toward the model's decision boundary, followed by enforcing consistency of predictions on the augmented images that helps better \textbf{separability} in the feature space. Moreover, our online adversarial augmentation module consistently improves other self-learning methods. We achieve state-of-the-art test time performance on several classifications and segmentation benchmark datasets.}
% \end{abstract}

% \Devavrat{This paper proposes adversarial data augmentations for test-time model adaptation using only unlabelled online target data. We progressively make the augmentations of the easy samples (low entropy with respect to the current model) harder using an adversarial setup and use these hard augmented views for self-training the model at test time. Our experiments on several benchmark datasets for classification and segmentation show the superiority of self-training with adversarial augmentations against the state-of-the art online test-time adaptation methods.}