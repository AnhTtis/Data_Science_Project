\section{Introduction}\label{sec:intro}
Deep neural networks (DNNs) perform exceptionally well when the training (\textit{source}) and test (\textit{target}) data follow the same distribution. However, distribution shifts are inevitable in real-world settings and propose a major challenge to the performance of deep networks after deployment. Also, access to the labeled training data may be infeasible at test time due to privacy concerns or transmission bandwidth. In such scenarios, \textbf{source-free domain adaptation} (\textbf{SFDA}) \cite{li2020model,agarwal2022unsupervised,kundu2020universal} and \textbf{test-time adaptation} (\textbf{TTA}) methods \cite{su2022revisiting,iwasawa2021test,liu2021ttt} aim to adapt the pre-trained source model to the unlabeled distributionally shifted target domain while easing access to source data. While SFDA methods have access to all full target data through multiple training epochs (offline setup), TTA methods usually process test images in an online streaming fashion and represent a more realistic domain adaptation. However, most of these methods are applied: (i) only to classification tasks, (ii) evaluated on the non-real-world domain shifts, e.g., the non-measurement shift; (iii) destroy model calibration—entropy minimizing with overconfident predictions \cite{wang2021tent} on incorrectly classified samples, and (iv) use specialized network architectures or rely on the source dataset feature statistics \cite{liu2021ttt}. 

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/fig1_rebuttal.pdf}
    \caption{\textbf{Knowledge distillation with adversarial augmentations.} \textbf{(a)} \textit{Easy} images with confident soft-pseudo labels and \textbf{(b)} \textit{Hard} images with unconfident soft-pseudo labels are adversarially augmented and pushed to the uncertainty region (high entropy) near the decision boundary. The model is updated for \textbf{(a)} to match its output on the augmented views with non-augmented views of \textit{Easy} test images using KL-Divergence $\mathcal{L}_\text{kd}\neq0$, while not updated for \textbf{(b)} as $\mathcal{L}_\text{kd}\sim0$ between \textit{Hard} images and their augmented views.
    \vspace{-0.5em}}
    \label{fig:kl_adver_aug}
\end{figure}

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=\linewidth]{latex/figures/fig1_rebuttal.pdf}
%     \caption{\textbf{Knowledge distillation with adversarial augmentations.} (a) \textit{Expansion phase:} adversarial augmented images are produced by pushing their feature representations closer to the frozen decision boundary. (b) \textit{Update Model stage:} ensures consistency between the soft-pseudo label and the model's prediction on the augmented image view. (c) \textit{Separation stage:} updated model better separates features into their respective classes. \vspace{-0.5em}}
%     \label{fig:kl_adver_aug}
% \end{figure}

We address these issues by proposing a new test-time adaptation method with automatic adversarial augmentation called \textbf{TeSLA}, under which we further define realistic TTA protocols. Self-learning methods often supervise the model adaptation on the unlabeled test images using their predicted pseudo-labels. As the model can easily overfit on its own pseudo-labels, a weight-averaged teacher
model (slowly updated by the student model) is employed for obtaining the pseudo-labels \cite{tarvainen2017mean,wang2022continual}. The student model is then trained with cross-entropy ($\mathbb{CE}$) loss between the one-hot pseudo-labels and its predictions on the test images. In this paper, we instead propose to minimize flipped cross-entropy between the student model's predictions and the soft pseudo-labels (notice the reverse order) with the negative entropy of its marginalized predictions over the test images. In Sec.~\ref{sec:method}, we show that the proposed formulation is an equivalence to mutual information maximization implicitly corrected by the teacher-student knowledge distillation via pseudo-labels, yielding performance improvement on various test-time adaptation protocols and compared to the basic $\mathbb{CE}$ optimization (cf. ablation in Fig. \ref{fig:ablation_components}-(1)).  


%\Devavrat{Traditionally, self-learning algorithms supervise the model adaptation on the unlabelled test images using its own predicted pseudo-labels. As the model can easily overfit on its own pseudo-labels, a weight-averaged teacher
%model (slowly updated by the student) is employed for obtaining the pseudo-labels \cite{tarvainen2017mean,wang2022continual}. The student model is then trained with cross-entropy ($\mathbb{CE}$) loss between the one-hot pseudo-labels and its predictions on the test images. In contrast to the traditional self-learning methods, we instead propose to minimize \textit{flipped} cross-entropy (\textit{f-$\mathbb{CE}$}) between the student model's predictions and the soft-pseudo labels (notice the order change), and negative entropy of its marginalized predictions over the test images. In Sec. \ref{sec:method}, we show that the proposed test-time loss function is an equivalence to mutual information maximization implicitly corrected by the teacher-student knowledge distillation via pseudo-labels, asserting its better suitability for self-learning. To further improve the quality of soft-pseudo labels, we propose to ensemble the teacher model's output on weakly augmented versions of the test images followed by the \textbf{nearest neighbor soft-voting scheme}.}

Motivated by teacher-student knowledge distillation, another central tenet of our method is to assist the student model during adaptation in improving its performance on the hard-to-classify (high entropy) test images. For this purpose, we propose learning \textbf{automatic adversarial augmentations} (see Fig. \ref{fig:kl_adver_aug}) as a proxy for simulating images in the uncertainty region of the feature space. The model is then updated to ensure consistency between {predictions} of high entropy augmented images and soft-pseudo labels from the respective non-augmented versions. Consequently, the model is self-distilled on \textit{Easy} test images with confident soft-pseudo labels (Fig. \ref{fig:kl_adver_aug}\textcolor{red}{a}). In contrast, the model update on \textit{Hard} test images is discarded (Fig. \ref{fig:kl_adver_aug}\textcolor{red}{b}), resulting in better class-wise feature separation. 
% In particular, we formulate learning adversarial data augmentation as a proxy for simulating data in the uncertainty region of the feature space (Fig. \ref{fig:kl_adver_aug}). The test-time adaptation is then performed to ensure consistency between model’s prediction on high entropy augmented images and the soft-pseudo labels from the respective non-augmented versions (Fig. \ref{fig:kl_adver_aug}- (b)). Consequently, the updated model better separates features into their respective classes (Fig. \ref{fig:kl_adver_aug}- (c)). 
%
%\Devavrat{ Our work focuses on the online setting of test-time model adaptation and is based on utilizing adversarial data augmentation for distilling knowledge from the source pre-trained model to the unlabelled test domain.}

%we propose a novel self-learning objective that implicitly maximizes mutual information corrected by soft-pseudo labels obtained from the teacher network.








%Data augmentation \cm{during the training} for training deep networks is widely utilized for expanding data variability and improving generalization. Several recent works in the supervised learning \cite{cubuk2018autoaugment, cubuk2020randaugment, lim2019fast, li2020dada, hataya2022meta} have proposed learnable data augmentation policies for training neural networks \cm{so that the trained model generalizes better} for better generalization at validation/test time. Nonetheless, emulating all possible test-time distribution shifts during training is often challenging (if not impossible).
%To overcome such limitations, other recent methods \cite{lyzhov2020greedy, tomar2022opttta, wang2019aleatoric} have introduced learnable test-time augmentation policies. Even though these methods have shown great promise in improving accuracy and robustness, they are computationally expensive in real-time settings. Thus, their applicability is limited to tasks where accuracy plays an important role, e.g., medical image analysis \cite{tomar2022opttta}. Furthermore, the optimal augmentation policies are learned for a specific frozen pre-trained model, and the cost requirement has to increase when learning new augmentation policies during model adaptation at test time.

%This paper proposes a test-time adversarial augmentation module that can be efficiently trained online and is several orders faster than the existing learnable test-time augmentation strategies. We formulate learning adversarial data augmentation as a proxy for simulating data in the uncertainty region of the feature space. The test-time model adaptation is then performed to correctly classify the uncertain augmented images using the pseudo labels obtained from the respective non-augmented versions as shown in Fig. \ref{fig:kl_adver_aug}. Thus, adopting the proposed self-learning strategy helps the model to learn to correct itself on the test images in the uncertainty region.

%\cm{We observe that} Self-learning using proposed adversarial data augmentations depends on the quality of the soft pseudo-labels predicted by the model. To achieve high-quality pseudo-labels, we propose to use online knowledge distillation from the teacher and student networks. The teacher network (slowly updated by the student) generates the pseudo-labels that are further refined by ensembling its output on weakly augmented versions of the test images followed by $n$ nearest neighbor soft-voting scheme. In addition, we propose a novel test-time self-learning objective \Devavrat{that implicitly maximizes mutual information corrected by soft-pseudo labels obtained from the teacher network} \cm{for updating the student network using the soft-pseudo labels obtained from the teacher network (Sec. \ref{sec:method})}. 

% \behzad{In contrast to the traditional self-learning methods that minimize cross-entropy ($\mathbb{CE}$) loss $H(\mathbf{\mathrm{1}}(\hat{y}); y|x)$ between one-hot pseudo labels $\mathrm{1}(\hat{y})$ and the student network's predictions $y$ on the image $x$, we instead propose minimizing flipped cross-entropy (\textit{f-$\mathbb{CE}$}) $H(y; \hat{y}|x)$ between the model predictions $y$ and soft-pseudo labels $\hat{y}$ along with negative class-marginalized entropy $H(y)$.}
%\cm{In Sec. \ref{sec:method}, we show the rationale behind the proposed \textit{f-$\mathbb{CE}$} and the equivalence of our test-time self-learning objective with mutual information maximization corrected by the student-teacher knowledge distillation, asserting its better suitability for self-learning.}
%
% I removed the citations, which otherwise our method seems to be incremental: We note that self-learning using the adversarial data augmentations is dependent on the quality of the pseudo-labels. To achieve good pseudo-labels, we propose to use student-teacher framework \cite{tarvainen2017mean, wang2022continual} where the teacher (slowly updated by the student) generates the pseudo-labels that are further refined by ensembling its output on weakly augmented versions (e.g. flipping, resize cropping) of the test images followed by $n$ nearest neighbor soft-voting \cite{chen2022contrastive}.
%
%
%\Devavrat{ We also propose a novel test-time self-learning objective for updating the student using the soft-pseudo labels obtained from the teacher. In contrast to the traditional self-learning methods that minimize cross entropy (\textit{CE}) loss $H(\mathbf{\mathrm{1}}(\hat{y}), y|x)$ between one-hot pseudo labels $\mathbb{1}(\hat{y})$ and the student's predictions $y$ on the image $x$, we instead minimize flipped cross entropy (\textit{f-CE}) $H(y, \hat{y}|x)$ between the model predictions $y$ and soft-pseudo labels $\hat{y}$ along with negative class-marginalized entropy $H(y)$. In section \ref{sec:method}, we show the equivalence of our test-time self-learning objective with mutual information maximization corrected by the student-teacher knowledge distillation, asserting its better suitability for self-learning.}
%
%\Devavrat{Existing test-time adaptation methods either rely on specialized neural network architectures or only updates partial parameters to perform well. For instance, TENT \cite{wang2021tent} works with Convolutional Neural Networks (CNNs) with batch normalization (BN) layers and only updates the parameters of BN, while SHOT \cite{liang2020we} and AdaContrast \cite{chen2022contrastive} use additional weight normalization layer with projection head to perform well. In contrast, we show our methods' superiority for a variety of different neural network architectures including both CNNs and ViTs without any additional architectural requirements, as well as different source training strategies. Moreover, we update all parameters of the model and our method is stable over wide range of hyper-parameters like learning rate. 
%
In summary, our contributions are: (i) we propose a novel test-time self-learning method based on \textit{flipped} cross-entropy (\textit{f-$\mathbb{CE}$}) through the tight connection with the mutual information between the model’s predictions and the test images; (ii) we propose an efficient \textit{plug-in} test-time automatic adversarial augmentation module used for online knowledge distillation from the teacher to the student network that consistently improves the performance of test-time adaptation methods, including ours; and (iii) TeSLA achieves new state-of-the-art results on several benchmarks, from common image corruption to realistic measurement shifts for classification and segmentation tasks. Furthermore, TeSLA outperforms existing TTA methods in terms of calibration and uncertainty metrics while making no assumptions about the network architecture and source domain's information, e.g., feature statistics or training strategy. 
