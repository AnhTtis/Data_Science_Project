\section{Conclusion}
Through an extensive empirical study on nine datasets spanning four IE tasks, we find that LLMs, despite their superiority in extreme low-resource scenarios, are not effective few-shot information extractors in general. They struggle with IE-related prompts, have limited demonstration capacity, and incur high inference costs. However, LLMs significantly improve the performance on \textit{hard} samples when combined with SLM.  Building on these insights, we propose an adaptive \textit{filter-then-rerank} paradigm to leverage the strengths of SLMs and LLMs and mitigate their limitations. This approach consistently achieves promising results, with an average 2.4\% F1 gain across multiple few-shot IE tasks, while minimizing latency and budget costs.
