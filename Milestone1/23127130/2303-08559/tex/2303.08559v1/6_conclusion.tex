\section{Conclusion}

We have conducted an extensive empirical study comparing LLMs and SLMs on eight datasets across three tasks. We show that LLMs are still not good few-shot information extractor due to the task format, limited sample capacity and oversized schema. Meanwhile, compared to SLMs, LLMs incur significant time and monetary costs. We discover, however, LLMs could largely help SLMs to rerank and correct \textit{hard} samples. Building on these findings, we propose an adaptive "filter-then-rerank" paradigm that leverages the strengths of both LLMs and SLMs while avoiding their limitations. This approach consistently yields promising results, with 2.1\% F1-gain on average on several few-shot IE tasks, while minimizing the cost of latency and budgets caused by calling LLM APIs.