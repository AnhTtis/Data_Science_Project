
\documentclass[10pt]{article} % For LaTeX2e
\usepackage[preprint]{tmlr}
% If accepted, instead use the following line for the camera-ready submission:
%\usepackage[accepted]{tmlr}
% To de-anonymize and remove mentions to TMLR (for example for posting to preprint servers), instead use the following:
%\usepackage[preprint]{tmlr}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage[hidelinks]{hyperref}
\usepackage{url}


% Our own packages
\usepackage{comment}
\usepackage{siunitx}
\usepackage{subcaption}
\usepackage{mathtools,amssymb,amsthm}
\usepackage{listings}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{dsfont}
\usepackage{soul}
\usepackage{tikz}
\usepackage{booktabs}
\usetikzlibrary{arrows, decorations.markings}
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\input{header}
\newcommand{\edit}{\textcolor{blue}}% for revision edits

\title{Unsupervised Domain Adaptation \\ by Learning Using Privileged Information}

% Authors must not appear in the submitted version. They should be hidden
% as long as the tmlr package is used without the [accepted] or [preprint] options.
% Non-anonymous submissions will be rejected without review.

\author{\name Adam Breitholtz \email adambre@chalmers.se \\
      \addr Department of Computer Science\\
       Chalmers University of Technology
      \AND
      \name Anton Matsson \email antmats@chalmers.se \\
      \addr Department of Computer Science\\
      Chalmers University of Technology
      \AND
      \name Fredrik D. Johansson \email fredrik.johansson@chalmers.se\\
      \addr Department of Computer Science\\
      Chalmers University of Technology
      }

% The \author macro works with any number of authors. Use \AND 
% to separate the names and addresses of multiple authors.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\def\month{MM}  % Insert correct month for camera-ready version
\def\year{YYYY} % Insert correct year for camera-ready version
\def\openreview{\url{https://openreview.net/forum?id=XXXX}} % Insert correct link to OpenReview for camera-ready version


\begin{document}


\maketitle

\begin{abstract}
   Successful unsupervised domain adaptation is guaranteed only under strong assumptions such as covariate shift and overlap between input domains. The latter is often violated in high-dimensional applications like image classification which, despite this limitation, continues to serve as inspiration and benchmark for algorithm development. In this work, we show that training-time access to side information in the form of auxiliary variables can help relax restrictions on input variables and increase the sample efficiency of learning at the cost of collecting a richer variable set. As this information is assumed available only during training, not in deployment, we call this problem unsupervised domain adaptation by learning using privileged information (DALUPI). To solve this problem, we propose a simple two-stage learning algorithm, inspired by our analysis of the expected error in the target domain, and a practical end-to-end variant for image classification. We propose three evaluation tasks based on classification of entities in photos and anomalies in medical images with different types of available privileged information (binary attributes and single or multiple regions of interest). We demonstrate across these tasks that using privileged information in learning can reduce errors in domain transfer compared to baselines, be robust to spurious correlations in the source domain, and increase sample efficiency.
\end{abstract}
\section{Introduction}
\label{sec:introduction}
%

Deployment of machine learning (ML) systems relies on generalization from training samples to new instances in a target domain. When these new instances differ in distribution from the source of training data, performance tends to degrade and guarantees are often weak. For example, a supervised ML model trained to identify medical conditions in X-ray images from one hospital may work poorly in another hospital if the two sites have different equipment or examination protocols~\citep{zech2018variable}. In the \emph{unsupervised domain adaptation} (UDA) problem~\citep{ben2006analysis}, \emph{no} labeled examples are available from the target domain and strong assumptions are needed for success. In this work, we ask: How can access to \emph{auxiliary variables} during training help solve the UDA problem and weaken the assumptions necessary to guarantee domain transfer?

% The overlap problem
In standard UDA, a common assumption is that the object of the learning task is identical in source and target domains but that input distributions differ~\citep{shimodaira2000improving}. This ``covariate shift'' assumption is plausible in our X-ray example above: Doctors are likely to give the same diagnosis based on X-rays of the same patient from similar but different equipment. %%less complex sentence
However, guarantees for consistent domain adaptation also require either distributional overlap between inputs from source and target domains or known parametric forms of the labeling function~\citep{ben2012hardness,wu2019domain,johansson2019support}. Without these, adaptation cannot be verified or guaranteed by statistical means.

Input domain overlap is implausible for the high-dimensional tasks that have become standard benchmarks in the UDA community, including image classification~\citep{long2013,ganin_domain-adversarial_2016} and sentence labeling~\citep{orihashi_unsupervised_2020}. If hospitals have different X-ray equipment, the probability of observing (near-)identical images from source and target domains is zero~\citep{zech2018variable}. Even when covariate shift and overlap are satisfied, large domain differences can have a dramatic effect on sample complexity~\citep{breitholtz2022practicality}. Despite promising developments~\citep{shen2022}, realistic guarantees for practical domain transfer remain elusive.

% LuPI as a potential solution
In supervised ML without domain shift, incorporating auxiliary variables in the training of models has been proposed to improve out-of-sample generalization. For example, learning using \emph{privileged information}~\citep{vapnik_new_2009,lopez-paz_unifying_2016}, variables available during training but unavailable in deployment, has been proven to require fewer examples compared to learning without these variables~\citep{karlsson_lupts}. In X-ray classification, privileged information (PI) can come from graphical annotations or clinical notes made by radiologists that are unavailable when the system is used. While PI has begun to see use in domain adaptation, see e.g., \citet{Sarafianos_2017_ICCV} or \citet{DADA2019}, and a theoretical analysis exists for linear classifiers~\citep{xie2020n}, the literature has yet to fully characterize the benefits of this practice.

We introduce \emph{unsupervised domain adaptation by learning using privileged information} (DALUPI), in which auxiliary variables, related to the outcome of interest, are leveraged during training to improve test-time adaptation when the variables are unavailable. We summarize our contributions below: %(Section~\ref{sec:pi_setup}) 
\begin{itemize}
\item We formalize the DALUPI problem and give conditions under which it is possible to solve it consistently, i.e., to learn a model using privileged information that predicts optimally in the target domain. Importantly, these conditions do not rely on distributional overlap between source and target domains in the input variable (Section~\ref{sec:analysis}), making consistent learning without privileged information (PI) generally infeasible. 
\item We propose practical learning algorithms for image classification in the DALUPI setting (Section~\ref{sec:method}), designed to handle problems with three different types of PI, see Figure~\ref{fig:illustration_examples} for examples. As common UDA benchmarks lack auxiliary variables related to the learning problem, we propose three new evaluation tasks spanning the three types of PI using data sets with real-world images and auxiliary variables.
\item On these tasks, we compare our methods to supervised learning baselines and well-known methods for unsupervised domain adaptation (Section~\ref{sec:experiments}). We find that our proposed models perform favorably to the alternatives for all types of PI, particularly when input overlap is violated and when training sets are small.
\end{itemize}

% 
% PROBLEM SETUP
%
\section{Privileged Information in Domain Adaptation}
%Benefits of privileged information in unsupervised domain adaptation}
\label{sec:setup}
\label{sec:uda_setup}
In unsupervised domain adaptation (UDA), the goal is to learn a hypothesis $h$ to predict outcomes (or labels) $Y \in \cY$ for problem instances represented by input covariates $X \in \cX$, drawn from a target domain with density $\cT(X,Y)$. During training, we have access to labeled samples $(x, y)$ only from a source domain $\cS(X,Y)$ and unlabeled samples $\tilde{x}$ from $\cT(X)$. As a running example, we think of $\cS$ and $\cT$ as radiology departments at two different hospitals, of $X$ as the X-ray image of a patient, and of $Y$ as the diagnosis made by a radiologist after analyzing the image.

We aim to learn a hypothesis $h \in \cH$ from a hypothesis set $\cH$ that minimizes the expected target-domain prediction error (risk) $R_\cT$, with respect to a loss function $L : \cY \times \cY \rightarrow \bbR_+$, i.e., to solve
\begin{equation}\label{eq:risk}
\min_{h \in \cH} R_\cT(h) \mbox{, }\;\; R_\cT(h) \coloneqq \E_{X,Y\sim \cT}[L(h(X), Y)]~.
\end{equation}
%
A consistent solution to the UDA problem returns a minimizer of Equation \ref{eq:risk} without ever observing labeled samples from $\cT$. However, if $\cS$ and $\cT$ are allowed to differ arbitrarily, finding such a solution cannot be guaranteed~\citep{ben2012hardness}. To make the problem feasible, we assume that \emph{covariate shift}~\citep{shimodaira2000improving} holds---that the labeling function is the same in both domains, but the covariate distributions differ.

\begin{thmasmp}[Covariate shift] \label{asmp:covshift}%
For domains $\cS, \cT$ on $\cX \times \cY$, \emph{covariate shift} holds w.r.t. $X$ if
$$
\exists x : \cT(x) \neq \cS(x) \;\;\mbox{and}\;\; \forall x : \cT(Y \mid x) = \cS(Y \mid x)~.
$$%
\end{thmasmp}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.7\columnwidth]{fig/dalupi_examples.pdf}
    \caption{Examples of domain adaptation tasks with different types of privileged information (PI). During training, input samples $X$ and PI $W$ are drawn from both source and target domains. Labels $Y$ are only available from the source domain. At test time, a target sample $X$ is observed. We consider three types of PI: binary attribute vectors, a single region of interest, and multiple regions of interest. 
    %PI is assumed available from both domains during training, but unavailable at test time. 
\label{fig:illustration_examples}}
\end{figure}%

In our example, covariate shift means that radiologists at either hospital would diagnose two patients with the same X-ray in the same way, but that the radiologists may encounter different distributions of patients and images. To guarantee consistent learning without further assumptions, these distributions cannot be \emph{too} different---the source domain input $\cS(x)$ must sufficiently \emph{overlap} the target input domain $\cT(x)$.
%
\begin{thmasmp}[Domain overlap]\label{asmp:overlap} A domain $\cS$ overlaps another domain $\cT$ w.r.t. $X$ on $\cX$ if
$$
\forall x \in \cX : \cT(X=x) > 0 \implies \cS(X=x) > 0~.
$$%
\end{thmasmp}
%
Covariate shift and domain overlap w.r.t. $X$ guarantee that the target risk $R_\cT$ can be identified by the sampling distribution described above, and thus, that a solution to Equation \ref{eq:risk} may be found. Hence, they have become standard assumptions, used by most informative guarantees~\citep{zhao2019learning}. 

Overlap is often violated in high-dimensional problems such as image classification, partly due to irrelevant information that has a spurious association with the label $Y$~\citep{beery2018recognition,d2021overlap}. %In MNIST vs MNIST-M~\citep{ganin_domain-adversarial_2016}, one image domain is black-and-white and the other in color, but the shapes of the digits are preserved in both domains. 
In X-ray classification, it may be possible to perfectly distinguish hospitals (domains) based on protocol or equipment differences manifesting in the images~\citep{zech2018variable}. There are no guarantees for optimal UDA in this case. Some guarantees based on distributional distances do not rely on overlap~\citep{ben2006analysis,long2013}, but do not guarantee optimal learning either~\citep{johansson2019support}. 

Still, an image $X$ may \emph{contain} information $W$ which is both \emph{sufficient for prediction} and \emph{supported in both domains}. For X-rays, this could be a region of pixels indicating a medical condition, ignoring parts that merely indicate differences in protocol~\citep{zech2018variable}. The learner does not know how to find this information a priori, but it can be supplied during training as added supervision. A radiologist could indicate regions of interest $W$ using bounding boxes during training~\citep{irvin2019chexpert}, but would not be available to annotate images at test time. As such, $W$ is \emph{privileged information}~\citep{vapnik_new_2009}.
%
% DALUPI + ANALYSIS
%
\subsection{Unsupervised Domain Adaptation With Privileged Information}\label{sec:pi_setup}
\label{sec:analysis}
Learning using privileged information, variables that are available only during training but not at test time, has been shown to improve sample efficiency in diverse settings~\citep{vapnik_learning_2015,pechyony_pi,jung2022efficient}. 
%
Next, we show that privileged information can also improve UDA by providing \emph{identifiability}
%\footnote{Identifiability of the target risk is an example of transportability of parameters~\citep{pearl2011transportability}.}
of the target risk---allowing it to be computed from the sampling distribution---even when overlap is not satisfied in $X$.

We define domain adaptation by learning using privileged information (DALUPI) as follows. During training, learners observe samples of covariates $X$, labels $Y$ and privileged information $W\in\mathcal{W}$ from $\cS$ in a dataset $D_\cS = \{(x_i, w_i, y_i)\}_{i=1}^m$, as well as samples of covariates and privileged information from $\cT$, $D_\cT = \{(\tilde{x}_i, \tilde{w}_i)\}_{i=1}^n$. \emph{At test time, trained models only observe covariates $\tilde{x} \sim \cT(X)$ and our learning goal remains to minimize the target risk, see Equation~\ref{eq:risk}}. 
%
We justify access to privileged information from $\cT$, but not labels, by pointing out that it is often easier to annotate observations with privileged information $W$ than with labels $Y$. For example, a non-expert may be able to reliably recognize the outline of an animal in an image, indicating the pixels $W$ corresponding to it, but not identify its species ($Y$); see Figure~\ref{fig:cat_illustration}, where it would likely be easier to identify the location of the cat in the image than to identify its breed.  

\def\cm{\checkmark}
\def\no{}
\begin{table}[t]
\caption{A summary of the different settings we consider in this work, what data is assumed to be available during training and if guarantees for identification are known for the setting under the assumptions of Proposition~\ref{prop:identification}. The parentheses around source samples for DALUPI indicate that we need not necessarily observe these for the setting. Note that at test time only $x$ from $\cT$ is observed. $^*$Under the more generous assumption of overlapping support in the input space $\cX$, guarantees exist for all these settings.}
\label{tab:settings}
\centering
\begin{tabular}{lccccccc}
\toprule
Setting &\multicolumn{3}{c}{Observed $\cS$} & \multicolumn{3}{c}{Observed $\cT$} & Guarantee\\
& $x$ & $w$ & $y$ & $\tilde{x}$ & $\tilde{w}$ & $\tilde{y}$ & for $R_\cT$\\  
\midrule
SL-T & \no & \no & \no & \cm & \no & \cm & \cm \\%
\midrule
SL-S & \cm & \no & \cm & \no & \no & \no & $^*$ \\%
UDA        & \cm & \no & \cm & \cm & \no & \no & $^*$ \\%
LUPI       & \cm & \cm & \cm & \no & \no & \no & $^*$ \\%
%DALuPI     & \no & \cm & \cm & \cm & \cm & \no & \cm \\%
DALUPI    & (\cm) & \cm & \cm & \cm & \cm & \no & \cm \\%
\bottomrule
\end{tabular}
\end{table}

To identify $R_\cT$ (Equation \ref{eq:risk}) without overlap in $X$, we make the assumption that $W$ is sufficient to predict $Y$ in the following sense.
%
\begin{thmasmp}[Sufficiency of privileged information]\label{asmp:sufficiency}
Privileged information $W$ is sufficient for the outcome $Y$ given covariates $X$ if $Y \perp X \mid W$ in both $\cS$ and $\cT$.
\end{thmasmp}
%

Assumption~\ref{asmp:sufficiency} is satisfied when $X$ provides no more information about $Y$ in the presence of $W$. If we consider $W$ to be a subset of image pixels corresponding to an area of interest, the other pixels in $X$ may be unnecessary to predict $Y$. This is illustrated in Figure \ref{fig:cat_illustration} where the privileged information $w_i$ is the region of interest indicated by the bounding box $t_i$. Here, overlap is more probable in $\cW$ than in $\mathcal{X}$, as the extracted pixels mostly show cats. Moreover, when $W$ retains more information, sufficiency becomes more plausible but domain overlap in $W$ is reduced.

Assumptions \ref{asmp:covshift}--\ref{asmp:overlap} holding with respect to privileged information $W$ instead of $X$, along with Assumption~\ref{asmp:sufficiency}, allows us to identify the target risk even for models $h \in \cH$ that do not use $W$ as input:

\begin{thmprop}\label{prop:identification}
Let Assumptions~\ref{asmp:covshift} and \ref{asmp:overlap} be satisfied w.r.t. $W$ (not necessarily w.r.t. $X$) and let Assumption~\ref{asmp:sufficiency} hold as stated. Then, the target risk $R_\cT$ is identified for hypotheses $h : \cX \rightarrow \cY$, 
\begin{align*}
R_\cT(h) & = \sum_{x} \cT(x) \sum_w \cT(w\mid x) \sum_{y} \cS(y\mid w) L(h(x), y)~,
\end{align*}%
and for $L$ the squared loss, a minimizer of $R_\cT$ is 
$
h_\cT^*(x)  = \sum_{w}\cT(w \mid x) \E_\cS[Y\mid w]~.
$
\end{thmprop}%
\begin{proofsketch}%
$R_\cT(h) = \sum_{x,y}\cT(x, y) L(h(x), y)$. We can then marginalize over $W$ to get
$\cT(x, y) = \cT(x) \E_{\cT(W\mid x)}[\cT(y\mid W) \mid x] = \cT(x) \sum_{w : \cS(w)>0} \cT(w \mid x) \cS(y\mid w)$, where the first equality follows by sufficiency and the second by covariate shift and overlap in $W$. $\cT(x), \cT(w \mid x)$ and $\cS(y\mid w)$ are observable through training samples. That $h^*_\cT$ is a minimizer follows from the first-order condition. 
%of setting the derivative of the risk with respect to $h$ to 0. 
See Appendix~\ref{app:identifiability}.
 %Note that identification is also possible to show when we have covariate shift w.r.t. $X$ instead, but it requires overlap. Using similar arguments we obtain $\cT(x, y) =  \cT(x) \sum_{w : \cS(w)>0} \cS(w \mid x) \cS(y\mid w).$
\end{proofsketch} 

%\hltodo{Talk about sufficiency being testable in the source by comparing methods using x and z or just z}

\begin{figure}[t]
    \centering
    \includegraphics[width=.8\columnwidth]{fig/cat_illustration.pdf}
    \caption{An illustration of domain overlap being more plausible when we consider appropriate forms of privileged information $W$, such as a region of interest of an image. Source and target domains $\cS, \cT$ are here indoor and outdoor images $X$ and the task is to identify the animal $Y$ in the image.\label{fig:cat_illustration}}%hltodo{Caption?}}
\end{figure}
Proposition~\ref{prop:identification} shows that there are conditions where privileged information allows for identification of target-optimal hypotheses where identification is not possible without it, i.e., when overlap is violated in $X$. $W$ guides the learner toward the information in $X$ that is relevant for the label $Y$. 
%This allows us to relax the standard assumptions on $X$ at the cost of collecting additional variables. 
When $W$ is deterministic in $X$, overlap in $X$ implies overlap in $W$, but not vice versa. In the same case, under Assumption~\ref{asmp:sufficiency}, if covariate shift holds for $X$, it holds also for $W$. Hence, if sufficiency can be justified, the requirements on $X$ are weaker than in standard UDA, at the cost of collecting $W$. Surprisingly, Proposition~\ref{prop:identification} does not require that $X$ is observed in the source domain as the result does not depend on $\cS(x)$. 


Figure~\ref{fig:illustration_examples} gives examples of problems with the DALUPI structure which we consider in this work. For comparison, we list related learning paradigms in Table~\ref{tab:settings}. Supervised learning (SL-S) refers to learning from labeled samples from $\cS$ without privileged information. SL-T refers to supervised learning with (infeasible)  access to labeled samples from $\cT$. UDA refers to the setting at the start of Section~\ref{sec:uda_setup} and LUPI to learning using privileged information without data from $\cT$~\citep{vapnik_new_2009}. We compare DALUPI to these alternative settings in our experiments in Section \ref{sec:experiments}.


\subsection{A Two-stage Algorithm and Its Risk}
\label{sec:twostage}
In light of Proposition~\ref{prop:identification}, a natural learning strategy is to model privileged information as a function of the input, $\cT(W \mid x)$, and the outcome as a function of privileged information, $\hg(w) \approx \E_\cS[Y\mid w]$, and combining these. In the case where $W$ is a deterministic function of $X$, $\cT(W \mid x)$ is a map $f : \cX \rightarrow \cW$, which may be estimated as a regression $\hf$ and combined with the outcome regression to form $\hh = \hg(\hf(X))$. We may find such functions $\hf$, $\hg$ by separately minimizing the empirical risks
%
\begin{equation}\label{eq:twostage_erm}
\begin{aligned}
%\hat{f} & \coloneqq \argmin_{f \in \cF} \hat{R}^{W}_{\cT}(f), \;\;\mbox{ where }\;\; 
\hat{R}^{W}_{\cT}(f) &= \frac{1}{n}\sum_{i=1}^{n}L(f(\tilde{x}_i), \tilde{w}_i) %\\
%\hat{g} & \coloneqq \argmin_{g \in \cG} \hat{R}^{Y}_{\cS}(g), \;\;\;\mbox{ where }\;\; 
\;\;\;\mbox{ and }\;\; 
\hat{R}^{Y}_{\cS}(g) &= \frac{1}{m} \sum_{i=1}^{m}L(g(w_i), y_i)~.\\
\end{aligned}
\end{equation}
Hypothesis classes $\cF, \cG$ may be chosen so that $\cH = \{h = g \circ f ; (f,g) \in \cF \times \cG\}$ has a desired form.

We can bound the generalization error of estimators $\hat{h} = \hat{g} \circ \hat{f}$ when $W \in \mathbb{R}^{d_W}$ and $L$ is the squared loss by placing an assumption of Lipschitz smoothness on the space of prediction functions: $\forall g\in \cG, w, w' \in \mathcal{W} :  \|g(w)-g(w')\|_2 \leq M \|w-w'\|_2$. To arrive at a bound, we first define the $\rho$-weighted empirical risk of the outcome model $g$ in the source domain, 
%R^{Y,\rho}_\cS(g) = \E_{\cS(W,Y)}[\rho(W)L(g(W), Y)]
%We define the empirical weighted risk  $\hat{R}^{Y,\rho}_S(g)$ analogously to the above.
$
\hat{R}^{Y,\rho}_\cS(g) = \frac{1}{m} \sum_{i=1}^m \rho(w_i)L(g(w_i), y_i)
$
where $\rho$ is the density ratio of $\cT$ and $\cS$, $\rho(w)=\frac{\cT(w)}{\cS(w)}$.  When the density ratio $\rho$ is unknown, we may use density estimation~\citep{sugiyama_density_2012} or probabilistic classifiers to estimate it. We arrive at the following result, proven for univariate $Y$ but generalizable to multivariate outcomes.
\begin{thmprop}\label{prop:bound}
Suppose that $W$ and $Y$ are deterministic in $X$ and $W$, respectively, and that Assumptions~\ref{asmp:covshift}--\ref{asmp:sufficiency} hold w.r.t. $W$. Let $\cG$ comprise $M$-Lipschitz mappings $g : \cW \rightarrow \cY$ with $\mathcal{W} \subseteq \bbR^{d_W}$, and let the loss be the squared Euclidean distance, assumed to be uniformly bounded over $\cW$. % by a constant $B$.
Let $\rho(w) = \cT(w)/\cS(w)$ and $d$ and $d'$ be the pseudo-dimensions of $\mathcal{G}$ and $\mathcal{F}$, respectively. Assume that there are $m$ labeled samples from $\cS$ and $n$ unlabeled samples from $\cT$. Then, for any $h = g \circ f \in \cG \times \cF$, with probability at least $1-\delta$, %\hltodo{Merge O-terms or have $m\neq n$?}
\begin{align*}
\frac{R_\cT(h)}{2}  &\leq \hat{R}^{Y,\rho}_\cS(g) +M^2 \hat{R}^W_\cT(f) + \mathcal{O}\left( \sqrt[3/8]{\frac{d\log\frac{m}{d}+\log \frac{4}{\delta}}{m}}
 + \sqrt{\frac{d'\log\frac{n}{d'} + \log\frac{d_W}{\delta}}{n}}\right)~.
\end{align*}
\end{thmprop}

% 2^{5/4}\sqrt{d_2(\cT\|\cS)}\sqrt[\frac{3}{8}]{\frac{d\log \frac{2me}{d}+\log \frac{4}{\delta}}{m}} \\
% & + d_\cW BM^2 \left(\sqrt{\frac{2d'\log \frac{en}{d'}}{n}}+\sqrt{\frac{\log\frac{d_{\cW}}{\delta}}{2n}} \right).
\begin{proofsketch}
Decomposing the risk of $h \circ \phi$ , we get 
\begin{align*}
R_\cT(h) &= \E_\cT[(g(f(X)) - Y)^2] \\
& \leq 2\E_\cT[(g(W) - Y)^2 + (g(f(X)) - g(W))^2] \\
& \leq 2\E_\cT[(g(W) - Y)^2 + M^2\|f(X)) - g(W)\|^2] \\
 & \leq 2\E_\cT[(g(W) - Y)^2] +  2M^2\E_\cT[\|(f(X) - W)\|^2] \\
& = 2R^Y_\cT(g) +  2M^2R^W_\cT(f) =2R^{Y,\rho}_S(g) +  2M^2R^W_\cT(f)~.
\end{align*}
The first inequality follows the relaxed triangle inequality, the second from the Lipschitz property, and the third equality from Overlap and Covariate shift. Treating each component of $\hat{w}$ as independent, using standard PAC learning results, and application of Theorem 3 from \citet{cortes2010} along with a union bound argument, we get the stated result. See Appendix \ref{app:proof} for a more detailed proof. %\hltodo{Move proof to appendix?}
\end{proofsketch}

When $\cF$ and $\cG$ contain the ground-truth mappings between $X$ and $W$ and between $W$ and $Y$, in the infinite-sample limit, minimizers of Equation \ref{eq:twostage_erm} minimize $R_\cT$ as well. 
%
%In experiments (Section~\ref{sec:exp_digit}), we verify Proposition~\ref{prop:identification} and the advantage of learning using privileged information by minimizing \eqref{eq:twostage_erm}. %under the name DALUPI-TS (two-stage) to learn an image classifier.
Our approach is not limited to classical PAC analysis but could, under suitable assumptions, be carried out under another framework, e.g. using PAC-Bayes analysis to obtain a bound that contains different sample complexity terms. However, such a bound would then hold in expectation over a posterior distribution on $\cH$ instead of uniformly over $\cH$. We sketch a proof of such a bound in Appendix~\ref{app:pacbayesproof}. %%% A first try, we should probably show a sketch in the appendix if we are to mention this...

Furthermore, if sufficiency is violated but it is plausible that the degree of insufficiency is comparable across domains, we can still obtain a bound on the target risk which may be estimated from observed quantities. We give such a result in Appendix~\ref{app:no_sufficiency}. 
%


% 
% METHOD
%
\section{Image Classification With Privileged Information}
\label{sec:method}

We use image classification, where $X$ is an image and $Y$ is a discrete label, as proof of concept for DALUPI. To show the versatility of our approach, we consider three different instantiations of privileged information $W$: a binary attribute vector, a single region of interest, or multiple regions of interest. We detail each setting below and illustrate them in Figure \ref{fig:illustration_examples}. %solving both multi-class and multi-label tasks where privileged information $W$ highlights regions of interest in the images $X$, related to the labels $Y$, in the form of pixels contained by bounding boxes with  coordinates $T$. 

\subsection{Binary Attributes as PI}
% we should talk about 
First, we consider the case where each image $x_i$ is accompanied by privileged information in the form of a binary vector $w_i \in \{0,1\}^d$ indicating the presence of $d$ attributes in the image. 
In this setting, we can directly apply our two-stage estimator ( Equation \ref{eq:twostage_erm}). For the first estimator $\hat{f}$, we use a convolutional neural network (CNN) trained on observations from $\cT$ (and possibly $\cS$) to output a binary vector of attributes $\hat{w}_i$ from the input $x_i$. For the second estimator $\hat{g}$, we use a classifier, trained on source domain observations, that predicts the image label $\hat{y}_i$ given the vector of attributes $w_i$. We use the categorical cross-entropy loss to train both $\hf$ and $\hg$. The resulting classifier, $\hh(x)=\hg(\hf(x))$, is then evaluated on target domain images.

\subsection{Single Region of Interest as PI}
Next, we consider privileged information as a subset of pixels $w_i$, taken from the image $x_i$ and associated with an object or feature that determines the label $y_i \in \{1, \ldots, K\}$. In our experiments, this PI is provided as a \textit{single} bounding box with coordinates $t_i\in\bbR^{4}$ enclosing the region of interest $w_i$. 
%we consider multi-class classification where each image $x_i$ has a single label $y_i \in \{1, \ldots, K\}$ determined by the presence of a single object or feature. Privileged information is given by a single bounding box with coordinates $t_i\in\bbR^{4}$ enclosing a subset of pixels $w_i$ corresponding to the object or features sufficient to determine the label. %For example, $x_i$ may be a photograph of a nature scene where $w_i$ contains the pixels depicting an animal and $y_i$ indicates its species. 
Here, we use two CNNs, $\hat{d}$ and $\hat{g}$, and a deterministic function $\phi$ to approximate the two-stage estimator, see Equation~\ref{eq:twostage_erm}.
%In this setting, we make use of a slightly modified version of the two-stage estimator \eqref{eq:twostage_erm}. We use two convolutional neural networks, $\hat{d}$ and $\hat{g}$, and a deterministic function $\phi$ to approximate the setting above.
The network $\hat{d}$ is trained to output bounding box coordinates $\hat{t}_i$ as a function of the input $x_i$, and the pixels $\hat{w}_i$ within the bounding box are extracted from $x_i$ and resized to pre-specified dimensions through $\phi$.
%The estimated PI is extracted by applying a deterministic function $\phi(x_i,t_i)$, which crops $x_i$ to $\hat{t}_i$ and resizes the result to given dimensions, resulting in a new image.
The composition of these two functions, $\hf(x_i)=\phi(x_i,\hat{d}(x_i))$, returns $\hat{w}_i$. The second network $\hg$ is trained to predict $y_i$ given the pixels $w_i$ contained in a bounding box $t_i$ based on observations from $\cS$. We use the mean squared error loss for $\hat{d}$ and the categorical cross-entropy loss for $\hg$. Finally, $\hh(x)=\hg(\hf(x))$ is evaluated on target domain images where the output of $\hf$ is used for prediction with $\hg$. For further details see Appendix \ref{app:twostage}.

\subsection{Multiple Regions of Interest as PI}
\label{sec:endtoend}
Finally, we consider a setting where privileged information indicates \emph{multiple} regions of interest in an image. We use this PI in multi-label classification problems where the image $x_i$ is associated with one or more categories $k$ from a set $\{1, \ldots, K\}$, encoded in a multi-category label $y_i \in \{0,1\}^K$ (e.g., indicating findings of one or more diseases). The partial label $y_i(k) = 1$ indicates the presence of features or objects in the image from category $k$. In our entity classification experiment, an object $j$ of class $k \in [K]$ in the image, say ``Bird'', will be annotated by a bounding box $t_{ij}\in\bbR^{4}$ surrounding the pixels of the bird, and an object label $u_{ij} = k$. In X-ray classification, $t_{ij}$ can indicate an abnormality $j$ in the X-ray image, and $u_{ij} \in \{1, \ldots, K\}$ the label of the finding (e.g., ``Pneumonia''). 

To make full use of privileged information, we train a deep neural network $\hh(x) = \hg(\hat{f}(x))$, where $\hf$ produces \emph{a set} of bounding box coordinates $\hat{t}_{ij}$ and extracts the pixels $\hat{w}_{ij}$ associated with each $\hat{t}_{ij}$, and where $\hg$ predicts a label $\hat{u}_{ij}$ for each $\hat{w}_{ij}$. %where $\hat{f}(x) = \psi(x,\hat{d}(x))$. 
%Here, $\hat{d}$ outputs \emph{a set} of bounding box coordinates $\hat{t}_i$, $\psi$, $\psi$   and $\hg$ predicts a label for the pixels $\hat{w}_i$ associated with each of these coordinates. 
For this, we adapt the Faster R-CNN architecture~\citep{ren2016faster} which uses a region proposal network (RPN) to generate regions that are fed to a detection network for classification and refined bounding box regression. 

The RPN in combination with region of interest pooling serves as the sub-network $\hat{f}$, producing estimates $\hat{w}_i$ of the privileged information for an image $x_i$. Privileged information adds supervision through per-object losses $L_{\text{reg}}(\hat{t}, t)$ and $L_{\text{cls}}(\hat{p}, u)$ for region proposals $\hat{t}$ and class probabilities $\hat{p}$, respectively. In Appendix~\ref{app:faster-rcnn}, we provide details of the learning objective and architecture and describe small modifications to the training procedure of Faster R-CNN to accommodate the DALUPI setting. Unlike the two-stage estimator, we train Faster R-CNN (both $\hf$ and $\hg$) end-to-end, minimizing both losses at once. In entity classification experiments (see Table~\ref{tab:coco_results} and Figure~\ref{fig:cocoexp}), we also train this model in a LUPI setting, where \emph{no} information from the target domain is used, but privileged information from the source domain is used.

%
% EXPERIMENTS
%
\section{Experiments} \label{sec:experiments}


We evaluate the empirical benefits of learning using privileged information, compared to the other data availability settings in Table~\ref{tab:settings}, across four UDA image classification tasks where PI is available in the forms described in Section \ref{sec:method}. Widely used datasets for UDA evaluation like OfficeHome~\citep{venkateswara2017deep} and large-scale benchmark suites like DomainBed~\citep{gulrajani2021in}, VisDA~\citep{peng2017visda} and WILDS~\citep{koh2021wilds} \emph{do not} include privileged information and cannot be used for evaluation here. Thus, we first compare our method to baselines on the recent CelebA task of~\citep{xie2020n} which includes PI in the form of binary attributes (Section \ref{sec:exp_celeb}). Additionally, we propose three new tasks based on well-known image classification data sets with regions of interest as PI (Section \ref{sec:exp_digit}--\ref{sec:chest}).


Our goal is to collect evidence that DALUPI improves adaptation bias and sample efficiency compared to methods that do not make use of PI. We choose baselines to illustrate these two disparate settings. First, we compare DALUPI to supervised learning baselines, SL-S and SL-T, trained on labeled examples from the source and target domain, respectively. SL-S is a simple but strong baseline: On benchmark suites like DomainBed and WILDS, there is still no UDA method that \emph{consistently} outperforms SL-S (ERM) without transfer learning \citep{gulrajani2021in, koh2021wilds}. SL-T serves as an oracle comparison since it uses labels from the target domain which are normally unavailable in UDA. Second, we compare DALUPI to two UDA methods---domain adversarial neural networks (DANN)~\citep{ganin_domain-adversarial_2016} and the margin disparity discrepancy (MDD)~\citep{zhang2019bridging}---which have theoretical guarantees but do not make use of PI. These baselines are all based on the ResNet architecture. In Section \ref{sec:exp_celeb}, we compare DALUPI also to In-N-Out \citep{xie2020n} which was designed to make use of auxiliary (privileged) attributes for training domain adaptation models. We do not include this model in other experiments as it was not designed to use regions of interest as privileged information. The exact architectures of all models and baselines are described in Appendix \ref{app:expdetails}, along with details on experimental setup and hyperparameters.
%

For each experimental setting, we train 10 models from each class using hyperparameters randomly selected from given ranges (see Appendix~\ref{app:expdetails}). For DANN and MDD, the trade-off parameter, which regularizes domain discrepancy in representation space, increases from 0 to 0.1 during training; for MDD, the margin parameter is set to 3. All models are evaluated on a held-out validation set from the source domain and the best-performing model in each class is then evaluated on held-out test sets from both domains. For SL-T, we use a held-out validation set from the target domain. We repeat this procedure over 5 or 10 seeds, controlling the data splits and the random number generation. We report accuracy and area under the ROC curve (AUC) with \SI{95}{\percent} confidence intervals computed by bootstrapping over the seeds.


%
\subsection{Celebrity Photo Classification With Binary Attributes as PI} \label{sec:exp_celeb}
For the case where privileged information is available as binary attributes, we follow \citet{xie2020n} who introduced a binary classification task based on the CelebA dataset~\citep{Liu2015}, where the goal is to predict whether the person in an image has been identified as male or female ($Y$) in one of the binary attributes that accompanies the data set's photos of celebrities ($X$). Like \citet{xie2020n}, we use 7 of the 40 other attributes (\verb|Bald|, \verb|Bangs|, \verb|Mustache|, \verb|Smiling|, \verb|5_o_Clock Shadow|, \verb|Oval_Face|, and \verb|Heavy_Makeup|) as a vector of privileged information $W \in \{0,1\}^7$. The target and source domains are defined by people wearing ($\cT$) and not wearing ($\cS$) a hat. More details can be found in Appendix \ref{app:celeb}.


Table \ref{tab:celeb_results} shows the target accuracy for each model. We see that DALUPI performs comparably to the In-N-Out models proposed by \citet{xie2020n}, while outperforming other baselines. Confidence intervals overlap for MDD, In-N-Out and DALUPI. The only variants of In-N-Out that achieve a higher average accuracy than DALUPI require four or more rounds of training to achieve their results (baseline, auxiliary input, auxiliary output pre-training, tuning and self-training)~\citep{xie2020n}. Both DALUPI and In-N-Out benefit from access to privileged information from both the source and target domain (pre/self-training for In-N-Out). 

Finally, it is worth noting that neither covariate shift, nor sufficiency are likely to hold w.r.t. to $W$ in this task. Specifically, photos with none of the 7 attributes active, $w = \mathbf{0}$, have different label rates and majority label in $\cS$ ($\bar{Y}=0.64$) and $\cT$ ($\bar{Y}=0.46$), i.e., covariate shift is violated. In addition, the best model we have found trained on $W$ alone achieves only \SI{65}{\percent} accuracy, compared to the results in Table~\ref{tab:celeb_results}---sufficiency is unlikely to hold. Thus, DALUPI is robust to violations of these assumptions. 


\subsection{Digit Classification With Single Region of Interest as PI}
\label{sec:exp_digit}


We construct a synthetic image dataset, based on the assumptions of Proposition~\ref{prop:identification}, to verify that there are problems where DALUPI is guaranteed successful transfer but standard UDA is not. Starting from CIFAR-10~\citep{cifar10} images upscaled to $128\times128$, we insert a random $28 \times 28$ digit image from the MNIST dataset~\citep{lecun_gradient-based_1998}, with a label in the range 0--4, into a random location of each CIFAR-10 image, forming the input image $X$ (see Figure~\ref{fig:illustration_examples} (top) for examples). The label $Y \in \{0,\dots,4\}$ is determined by the MNIST digit. We store the bounding box around the inserted digit image and use the pixels contained within it as privileged information $W$ during training. %This is done until no more digit images remain. 
% The domains are constructed using CIFAR-10's first five and last five classes as source and target backgrounds, respectively. Both source and target datasets contain \SI{15298} images each. We use \SI{20}{\percent} of the available source and target data for testing and \SI{20}{\percent} of the training data for validation.
To increase the difficulty of the task, we make the digit be the mean color of the dataset and make the digit background transparent so that the border of the image is less distinct. This may slightly violate Assumption~\ref{asmp:overlap} with respect to the region of interest $W$ since the backgrounds differ between domains. 

\begin{table}[t]
\begin{minipage}[c]{0.50\textwidth}%
    \centering
    \captionof{table}{Celebrity photo classification. DALUPI performs comparably to the In-N-Out models in \citet{xie2020n}. Note: In-N-Out results are reported as the average of 5 trials with \SI{90}{\percent} confidence intervals.}
    \label{tab:celeb_results}
    \begin{tabular}{lll}
    \toprule
    & Target accuracy \\ \midrule
    %SL-T & XX.X (XX.X, XX.X) \\ \midrule
    SL-S & 74.4 (73.1, 76.4) \\ 
    DANN & 73.9 (72.2, 76.5) \\ 
    MDD & 77.3 (75.2, 79.0) \\         
    In-N-Out (w/o pretraining) & 78.5  (77.2, 79.9)\\
    In-N-Out (w. pretraining) & 79.4  (78.7, 80.1)\\
    In-N-Out (rep. self-training) & 80.4  (79.7, 81.1)\\
    DALUPI ($W$ from $\cT$) & 78.3 (76.3, 80.3) \\ 
    DALUPI ($W$ from $\cS, \cT$)& 79.3 (76.9, 81.7) \\  
    \bottomrule
    \end{tabular}
\end{minipage}%
\hfill
\begin{minipage}{0.48\textwidth}%
    \centering
    \includegraphics[width=0.9\textwidth]{fig/mnist_target.pdf}
    \captionof{figure}{Digit classification. Target domain accuracy as a function of association $\epsilon$ between background and label in $\cS$. As the skew increases, the target-domain performance of the non-privileged models deteriorates. \label{fig:mnistexp}}
\end{minipage}%
\end{table}



To understand how successful transfer depends on domain overlap and access to sufficient privileged information, we include a \emph{skew parameter} $\epsilon\in [\frac{1}{c},1]$, where $c=5$ is the number of digit classes, which determines the correlation between digits and backgrounds. For a source image $i$ with digit label $Y_i \in \{0,\ldots,4\}$, we select a random CIFAR-10 image with class $B_i \in\{0,\ldots,4\}$ with probability
$P(B_i=b \mid Y_i = y) = \left\{
\epsilon, \;\mbox{if}\; b = y; \;\;
(1-\epsilon)/(c-1), \mbox{otherwise}
\right\}$.
%
For target images, digits and backgrounds are matched uniformly at random. The choice $\epsilon=\frac{1}{c}$ yields a uniform distribution and $\epsilon=1$ is equivalent to the background carrying as much signal as the privileged information. We hypothesize that $\epsilon=1$ is the worst possible case where confusion of the model is likely, which would lead to poor adaptation under domain shift.

In Figure \ref{fig:mnistexp}, we observe the conjectured behavior. As the skew $\epsilon$ and the association between background and label increases, the performance of SL-S decreases rapidly on the target domain. At $\epsilon=1$, it performs no better than random guessing, likely because the model has learned to associate spurious features in the background with the label of the digit. 
%This agrees with previous empirical evidence where background artifacts in X-ray images confused an image classifier applied to data from a new hospital~\citep{zech2018variable}. 
% See the saliency maps in Figure~\ref{fig:saliencymniste02}--\ref{fig:saliencymniste10} for an illustration of this behavior.
%
We also observe that DANN and MDD deteriorate in performance with increased correlation between the label and the background. In contrast, DALUPI is unaffected by the skew as the subset of pixels extracted by $\hat{f}$ only carries some of the background with it, while containing sufficient information to make good predictions. Interestingly, DALUPI also seems to be as good or slightly better than the oracle SL-T in this setting. This may be due to improved sample efficiency from using PI.


% MS-COCO
%
\subsection{Entitity Classification With Multiple Regions of Interest as PI} \label{sec:coco}

Next, we consider multi-label classification of the presence of four types of entities (persons, cats, dogs, and birds) indicated by a binary vector $Y \in \{0,1\}^4$ for images $X$ from the MS-COCO dataset~\citep{lin2014microsoft}. PI is used to localize regions of interest $W$ related to the entities, provided as bounding box annotations. We define source and target domains $\cS$ and $\cT$ as indoor and outdoor images, respectively. Indoor images are extracted by filtering out images from the  MS-COCO super categories ``indoor'' and ``appliance'' that also contain at least one of the four main label classes. Outdoor images are extracted using the super categories ``vehicle'' and ``outdoor''. In total, there are \SI{5231} images in the source and \SI{5719} images in the target domain; the distribution of labels is provided in Appendix \ref{app:coco}. 

\begin{table}[t]
\begin{minipage}{0.48\textwidth}%
    \centering
        \captionof{table}{Entity classification. UDA models have access to all unlabeled target samples, LUPI to all PI (source), and DALUPI to all PI (source and target). \label{tab:coco_results}}%
        \begin{tabular}[b]{llll}
        \toprule
         & Source AUC & Target AUC \\ \midrule
         SL-T & 60.1	(58.7,	61.5) & 69.0 (68.1, 69.9) \\ \midrule
         SL-S & 69.5	(68.6,	70.4) & 63.0 (61.6, 64.2) \\ 
         DANN & 68.1	(67.5,	68.7) & 62.5 (61.9, 63.1) \\ 
         MDD & 62.4	(61.1,	63.9) & 57.7 (56.3, 59.2) \\
         LUPI & 69.3	(68.5,	70.1) & 65.9 (65.0, 66.8) \\
         DALUPI & 71.4	(70.3,	72.4) & 68.2 (66.3, 70.1) \\   
         \bottomrule
        \end{tabular}
\end{minipage}%
\hfill
\begin{minipage}[c]{0.50\textwidth}%
\centering
\includegraphics[width=\textwidth]{fig/coco_target.pdf}
\captionof{figure}{Entity classification. Target domain AUC. The performance of SL-S and SL-T is extended across the x-axes for visual purposes. DANN and MDD use an increasing fraction of target samples $\tilde{x}$ but no PI.}
\label{fig:cocoexp}
\end{minipage}%
\end{table}


Sufficiency is likely to hold in this task because the pixels contained in a bounding box should be sufficient for an annotator to classify the entity according to the four categories above, irrespective of the pixels outside of the box. Similarly, covariate shift is likely to hold since the label attributed to the pixels in a bounding box should be the same, whether the entity is indoor or outdoor. 

We study the effect of adding privileged information by first training the end-to-end model in a LUPI setting, using all $(x, y)$ samples from the source domain and increasing the fraction of inputs for which PI is available, $n_{\text{PI}}(\mathcal{S})$, from 0 to 1. We then train the model in a DALUPI setting, increasing the fraction of $(\tilde{x}, \tilde{w})$ samples from the target domain, $n_{\text{PI}}(\mathcal{T})$, from 0 to 1, while keeping $n_{\text{PI}}(\mathcal{S})=1$. We train SL-S and SL-T using all available data and increase the fraction of unlabeled target samples used by DANN and MDD from 0.2 to 1 while using all data from the source domain.



Table \ref{tab:coco_results} shows the models' source and target domain AUC, averaged over the four entity classes, when the UDA models have access to all unlabeled target samples, LUPI to all PI from the source domain, and DALUPI to all PI from both domains. Clearly, DALUPI yields a substantial gain in adaptation.
%The models' test AUC, averaged over the four entity classes, in the target domain is shown in Figure \ref{fig:cocoexp}.
As we see in Figure \ref{fig:cocoexp}, the performance of LUPI increases as $n_{\text{PI}}(\mathcal{S})$ increases. When additional $(\tilde{x}, \tilde{w})$ samples from the target domain are added, DALUPI outperforms SL-S and approaches the performance of SL-T. DANN and MDD do not benefit as much from added unlabeled target samples as DALUPI. Their weak performance could be explained by difficulties in adversarial training. The gap between LUPI and SL-S for $n_{\text{PI}}(\mathcal{S})=0$ is anticipated; we do not expect the detection network to work well without bounding box supervision. 



%
% X-RAY EXPERIMENT
%
\subsection{X-ray Classification With Multiple Regions of Interest as PI} \label{sec:chest}
%
As a real-world application, we study detection of pathologies in chest X-ray images. We use the ChestX-ray8 dataset \citep{nih} as source domain and the CheXpert dataset \citep{irvin2019chexpert} as target domain.\footnote{
This study was granted IRB approval.} As PI, we use the regions of pixels associated with each found pathology, as annotated by domain experts using bounding boxes. For the CheXpert dataset, only pixel-level segmentations are available, and we create bounding boxes that tightly enclose the segmentations. It is not obvious that the pixels within such a bounding box are sufficient for classifying the pathology. For this reason, we suspect that some of the assumptions of Proposition~\ref{prop:identification} may be violated. However, as we find below, DALUPI improves empirical performance compared to baselines for small training sets, thereby demonstrating increased sample efficiency.


\begin{table}[t]
    \begin{minipage}{0.58\textwidth}
        \centering
        \captionof{table}{X-ray task. Test AUC for the three pathologies in the target domain for all considered models. Boldface indicates the best-performing feasible model; SL-T uses target labels.\label{tab:chestxray0}}%
        \begin{tabular}[b]{lccc}
        \toprule
            & ATL                             & CM                              & PE                              \\ \midrule
        SL-T         & \multicolumn{1}{l}{57 (56, 58)} & \multicolumn{1}{l}{59 (55, 63)} & \multicolumn{1}{l}{79 (78, 80)} \\ \midrule
        SL-S         & \textbf{55 (55, 56)}                     & 61 (58, 64)                     & 73 (70, 75)                     \\
        DANN         & 53 (51, 55)            & 55 (53, 58)                     & 55 (51, 61)                     \\
        MDD         & 49 (48, 50)            & 51 (51, 52)                     & 51 (48, 54)                     \\
        DALUPI & \textbf{55 (55, 56)}                     & \textbf{72 (71, 73)}            & \textbf{74 (72, 76)}            \\ \bottomrule
        \end{tabular}
    \end{minipage}
    \hfill
    \begin{minipage}{0.40\textwidth}
        \centering
        \includegraphics[width=\textwidth]{fig/lupi_vs_source_horiz.pdf}
        \captionof{figure}{Left: Example from the X-ray target test set with label CM. The red rectangle indicates the bounding box %with the highest probability as 
        predicted by DALUPI. %with no extra data. 
        Right: saliency map for CM for SL-S. %the corresponding SL-S.
        \label{fig:saliencychest1}}
    \end{minipage}
\end{table}

We consider the three pathologies that exist in both datasets and for which there are annotated findings: atelectasis (ATL: collapsed lung), cardiomegaly (CM: enlarged heart), and pleural effusion (PE: water around the lung). 
There are 457 and 118 annotated images in the source and target domain, respectively. We train DALUPI, DANN and MDD using all these images. SL-S is trained with the 457 source images and SL-T with the 118 target images as well as 339 labeled but non-annotated target images. 
%In the annotated images, there are 180/146/153 and 75/66/64 examples of ATL/CM/PE in each domain respectively.
Neither SL-S, SL-T, DANN, nor MDD support using privileged information.
%Validation and test sets are sampled from non-annotated images and contain \SI{10000} samples each.
The distributions of labels and bounding box annotations are given in Appendix \ref{app:chestxray}.

In Table \ref{tab:chestxray0}, we present the per-class AUCs in the target domain. DALUPI outperforms all baseline models, including the target oracle, in detecting CM. For ATL and PE, it performs similarly to or better than the other feasible models. That SL-T is better at predicting PE is not surprising because this pathology is most prevalent in the target domain. 
In Figure \ref{fig:saliencychest1}, we show a single-finding image from the target test set with ground-truth label CM. The predicted bounding box of DALUPI with the highest probability is added to the image. DALUPI identifies the region of interest (the heart) and makes a correct classification. The rightmost panel shows the saliency map for the ground truth class for SL-S. We see that the gradients are mostly constant, indicating that the model is uncertain. 
In Appendix \ref{app:additional_x-ray}, we show AUC for CM for the models trained with additional examples \emph{without} bounding box annotations. We find that SL-S reaches the performance of DALUPI when a large amount of labeled examples are provided. This indicates that identifiability is not the main obstacle for adaptation and that PI improves sample efficiency.

%
% RELATED WORK
%
\section{Related Work}
\label{sec:related}
%
Learning using privileged information was first introduced by \citet{vapnik_new_2009} for support vector machines (SVMs), and was later extended to empirical risk minimization~\citep{pechyony_pi}. Methods using PI, which is sometimes called hidden information or side information, has since been applied in many diverse settings such as healthcare~\citep{shaikh_transfer_2020}, finance~\citep{silva_financial_2010}, clustering~\citep{feyereisl_privileged_2012} and image recognition~\citep{DADA2019,hoffman_learning_2016}. Related concepts include knowledge distillation~\citep{Hinton2015DistillingTK,lopez-paz_unifying_2016}, where a teacher model trained on additional variables adds supervision to a student model, and weak supervision~\citep{robinson_strength_2020} where so-called weak labels are used to learn embeddings, subsequently used for the task of interest. The use of PI for deep image classification has been investigated by \citet{chen2017} and \citet{Han_2023_ICCV} but these works only cover regular supervised learning where source and target domains coincide. Further, \citet{sharmanska_learning_2014} used regions of interest in images as privileged information to improve the accuracy of image classifiers, but did not consider domain shift either. 

Domain adaptation using PI has been considered before with SVMs~\citep{Li2022,Sarafianos_2017_ICCV}, but not with more complex classifiers such as neural networks. \citet{DADA2019} used scene depth as PI in semantic segmentation using deep neural networks. However, they only used PI from the source domain and they did not provide any theoretical analysis. \citet{xie2020n} provide some theoretical results for a similar setup to ours. However, these are specifically for linear classifiers while our approach holds for any type of classifier.
\citet{mootianthesis} investigated PI and domain adaptation using the information bottleneck method for visual recognition. However, their setting differs from ours in that each observation comprises source-domain and target-domain features, a label and PI. Another related approach is that of subsidiary tasks \citep{kunda2022,Ye2022}. However, in these settings the additional tasks performed are used to build a representation that helps with the main task through domain alignment. Our approach instead seeks to use information which directly relates to the main task.

%
% Conclusion
%
\section{Discussion}
\label{sec:conclusion}
%
We have presented DALUPI: unsupervised domain adaptation by learning using privileged information (PI). The framework provides provable guarantees for adaptation under relaxed assumptions on the input features, at the cost of collecting a larger variable set, such as attribute or bounding box annotations, during training. Our analysis inspired practical algorithms for image classification which we evaluated using three kinds of privileged information. In our experiments we demonstrated tasks where our approach is successful while existing adaptation methods fail. We observed empirically also that methods using privileged information are more sample-efficient than comparable non-privileged learners, in line with the literature. In fact, DALUPI models occasionally even outperform oracle models trained using target labels due to their sample efficiency. Thus, we recommend considering these methods in small-sample settings.

% Contributions
The main contribution of the paper is the proposed learning paradigm for domain adaptation with privileged information. Since common benchmark datasets in UDA lack privileged information related to the learning problem, we created three new tasks for evaluating our framework, see Section \ref{sec:exp_digit}--\ref{sec:chest}, which itself is a notable contribution. We hope that this work inspires the community to develop additional datasets for UDA using privileged information.

To avoid assuming that domain overlap is satisfied with respect to input covariates, we require that the label is conditionally independent of the input features given the PI---that the PI is ``sufficient''. This is a limitation whenever sufficiency is difficult to verify. However, in our motivating example of image classification, a domain expert could \emph{choose} PI so that sufficiency is reasonably justified. Moreover, in experiments on CelebA, we see empirical gains from our approach even when sufficiency is known to be violated. Another limitation is that we still rely on overlap in the privileged information, $W$, which may also be violated in some circumstances. It is more likely that overlap holds for $W$ when, for example, it is a subset of $X$, as argued in Figure~\ref{fig:cat_illustration}.

The use of regions of interest as privileged information brings up an interesting point concerning the relationship between the label and the privileged information. In object detection tasks, it is natural to treat the bounding box coordinates as label information. In this work, however, the learning tasks were multi-class and multi-label image classification, not object detection. Producing a perfect box $W$ was not the goal of the learning task, and the bounding boxes were therefore neither critical for the task nor the labels. Instead, the bounding boxes were privileged information and our experiments in Section \ref{sec:exp_digit}--\ref{sec:chest} sought to quantify the value of this added information, compared to not having it. Therefore, we compared our method to image classification baselines. It is not obvious a priori that learning from object locations improves the adaptation of image classifiers.

In future work, our framework could be applied to a more diverse set of tasks, with different modalities of inputs and privileged information to investigate if the findings here can be replicated and extended. More broadly, using PI may be viewed as ``building in'' domain knowledge in the structure of the adaptation problem and we see this as a promising direction for further research.

\subsection*{Acknowledgements} This work was supported in part by the Wallenberg AI, Autonomous Systems and Software Program (WASP), funded by the Knut and Alice Wallenberg Foundation. The computations/data handling were enabled by resources provided by the National Academic Infrastructure for Supercomputing in Sweden (NAISS), partially funded by the Swedish Research Council through grant agreement no. 2022-06725.

\bibliography{references}
\bibliographystyle{tmlr}



\appendix
\section{Appendix}
\input{supplement}

\end{document}
