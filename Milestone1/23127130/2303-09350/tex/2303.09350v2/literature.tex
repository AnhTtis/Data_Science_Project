
Learning using privileged information (LUPI) was first introduced by \citet{vapnik_new_2009} for support vector machines (SVMs), and was later extended to empirical risk minimization~\citep{pechyony_pi}. Methods using PI, which is sometimes called hidden information or side information, has since been applied in many diverse settings such as healthcare~\citep{shaikh_transfer_2020}, finance~\citep{silva_financial_2010}, clustering~\citep{feyereisl_privileged_2012} and image recognition~\citep{DADA2019,hoffman_learning_2016}. Related concepts include knowledge distillation~\citep{Hinton2015DistillingTK,lopez-paz_unifying_2016}, where a teacher model trained on additional variables adds supervision to a student model, and weak supervision~\citep{robinson_strength_2020} where so-called weak labels are used to learn embeddings, subsequently used for the task of interest. The use of PI for deep image classification has been investigated by \citet{chen2017} but this only covered regular supervised learning. Finally, \citet{sharmanska_learning_2014} used regions of interest in images as privileged information to improve the accuracy of image classifiers, but did not consider domain shift. 

Domain adaptation using PI has been considered before with  SVMs~\citep{Li2022,Sarafianos_2017_ICCV}. \citet{DADA2019} used scene depth as PI in semantic segmentation using deep neural networks. However, they only use PI from the source domain and they do not provide any theoretical analysis. \citet{mootianthesis} investigate PI and domain adaptation using the information bottleneck method for visual recognition. However, their setting differs from ours in that each observation comprises source-domain and target domain features, a label and PI. 
