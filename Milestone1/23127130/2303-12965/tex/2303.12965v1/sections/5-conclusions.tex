\section{Discussions and Conclusions}

\noindent 
\textbf{Discussions}:
Our method leverage mesh as our core representation, which enables us efficiency for both training and rendering.
However, the resolution of mesh is fixed in our pipeline, preventing fine-grained geometry and texture reconstruction.
One possible solution could be tetrahedra grids sub-division~\cite{schaeferSmoothSubdivisionTetrahedral,gaoTetGANConvolutionalNeural2022,kalischekTetrahedralDiffusionModels2022a}.
But it may break the SDF values around the derived meshes 
since there is no regularization over the whole SDF field.
Our non-rigid modeling has less capacity, since we assume there is no topology change of mesh \textit{wrt.} the non-rigid motion.
Otherwise, we cannot query materials and motions in the canonical shape.
One can solve it via the dense correspondence between the meshes before and after applying non-rigid motions~\cite{ahmedDenseCorrespondenceFinding2008,zeng3DHumanMesh2021},
yet such an operation may increase computation drastically.


\noindent \textbf{Conclusions}: we present EMA, which learns human avatars through hybrid meshy neural fields efficiently.
EMA jointly learns hybrid canonical geometry, materials, lights, and motions via a rasterization-based differentiable renderer. 
It only requires one hour of training and can render in real-time with a triangle renderer.
Minutes of training can produce plausible results.
Our method enjoys flexibility from implicit representations and efficiency from explicit meshes.
Experiments on the standard benchmark indicate the competitive performance and generalization results of our method.
The digitized avatars can be directly used in downstream tasks.
We showcase examples including novel pose synthesis, material editing, and human relighting.
