\section{Limitations and Further Discussions}

\label{supp:limitation_discussions}

Our method is biased for shape-material ambiguity~\cite{wangARAHAnimatableVolume,liTAVATemplatefreeAnimatable2022,suANeRFArticulatedNeural2021,noguchiNeuralArticulatedRadiance2021,pengAnimatableNeuralRadiance2021,wangNeuSLearningNeural2021,zhangNeRFAnalyzingImproving2020}.
Taking subject 315 from ZJU-MoCap as an example, the strips in the T-shirt are modeled as ravines on the surface.
The high contrast color in the cloth surface makes our model biased for shape modeling.
That might be resolved by introducing additional surface regularizers or pre-defined parameters for the materials.

Need foreground mask to enable the mesh optimization, akin to shape-from-silhouette.
One future direction might be equipping our method with the ability to separate foreground and background automatically~\cite{jiangNeuManNeuralHuman2022,guoVid2Avatar3DAvatar2023b}.
It is also promising to model the background simultaneously during foreground subject optimization~\cite{jiangNeuManNeuralHuman2022,guoVid2Avatar3DAvatar2023b},
which eliminates the requirement of foreground mask processing.

Our method can digitize humans from visual footage, which may involve avatar misuse without the permission of the owners. 
Methods like implicit adversarial watermarks~\cite{chenFAWAFastAdversarial2021,liWatermarkingbasedDefenseAdversarial2021} that disable the neural nets inference could assist the video creation to protect their portrait rights.
Another concern is the deep fake misuse~\cite{nguyenDeepLearningDeepfakes2022}, which corrupts the identity in the visual footage rendered by our model.
Methods like deep fake detection~\cite{panDeepfakeDetectionDeep2020} could help to discover and prevent deep fake creations.
Besides, our method involves training with GPUs, which leads to carbon emissions and increasing global warming~\cite{pattersonCarbonEmissionsLarge2021}.