\section{Loss Functions}

\label{supp:loss_functions}

Our loss function $L = L_\mathrm{img} + L_\mathrm{mask} + L_\mathrm{reg}$ is composed of three parts: an image loss $L_\mathit{img}$ using $\ell_1$ norm on tone mapped colors, and mask loss $L_\mathrm{mask}$ using squared $\ell_2$, and regularization losses $L_\mathrm{reg}$ to improve the quality of canonical geometry, materials, lights, and motion.

\noindent \textbf{Image loss}: 
our renderer utilizes physically-based shading to produce high-dynamic range (HDR) images.
Then the complex materials and environmental lights are elaborately optimized.
Thus our loss function requires a full range of floating point values.
We follow~\cite{hasselgrenAppearanceDrivenAutomatic3D2021,munkbergExtractingTriangular3D2022,hasselgrenShapeLightMaterial2022} to compute $\ell_1$ norm on tone mapped colors.
Specifically, we first transform linear radiance values $i$ according to a tone-mapping operator $T(i)=\Gamma(\log (i+1))$, in which $\Gamma(i)$ is a linear RGB to sRGB transformation function~\cite{stokesStandardDefaultColor1996}:
\begin{equation}
\begin{aligned}
\Gamma(i) & = \begin{cases}12.92 i & i \leq 0.0031308 \\
(1+a) i^{1 / 2.4}-a & i>0.0031308\end{cases} \\
a & =0.055,
\end{aligned}
\end{equation}


\noindent \textbf{Mask loss}:
The renderer~\cite{laineModularPrimitivesHighPerformance2020} renders both the shaded images and the corresponding rasterization masks in a differentiable manner.
Therefore, we compute the $\ell_2$ norm between the masks and the preprocessed mattings (in both ZJU-MoCap and H36M benchmarks, we use the provided preprocessed subject masks from~\cite{pengNeuralBodyImplicit2021,gongInstanceLevelHumanParsing2018}), akin to the traditional shape-from-silhouette~\cite{maInvitation3DVision2004} technique.
The mask loss is parallel with the image loss, yet facilitates the course of shading optimization by making shape convergence super fast in about a hundred training steps.

\noindent \textbf{Regularizers}:
We need various priors to encourage the optimization to converge at a place where the geometry, materials, and lighting are well separated and smooth enough~\cite{munkbergExtractingTriangular3D2022,hasselgrenShapeLightMaterial2022}.
Therefore, we choose to minimize regularization during training.

\noindent We introduce smoothness to PBR materials in terms of albedo $\mathbf{k}_d$, specular parameters $\mathbf{k}_\mathrm{orm}$, and surface geometry nomral $\mathbf{n}$ as following:
\begin{equation}
L_{\mathbf{k}}=\frac{1}{\left|\mathbf{x}_{\text {surf }}\right|} \sum_{\mathbf{x}_{\text {surf }}}\left|\mathbf{k}\left(\mathbf{x}_{\text {surf }}\right)-\mathbf{k}\left(\mathbf{x}_{\text {surf }}+\mathbf{\epsilon}\right)\right|,
\end{equation}

\noindent where ${\left|\mathbf{x}_{\text {surf }}\right|}$ is a surface point on the surface in canonical space and $\mathbf{\epsilon} \sim \mathcal{N}(0,\sigma\!\!=\!\!0.01)$ is a small random offset.
We regularize the geometry normal on the surface of the canonical mesh derived from the SDF field for a seek of a smoother surface and avoidance of holes in the surface.

\noindent We regularize light by assuming the neutral spectrum in the real world.
Specifically, given the per-channel average radiance densities $\Bar{c_i}$, we penalize the color shifts as:
\begin{equation}
L_{\text {light }}=\frac{1}{3} \sum_{i=0}^3 \left| {c_i}-\frac{1}{3} \sum_{i=0}^3 {c_i} \right|,
\end{equation}

To encourage a watertight surface and reduce floating meshes both inside and outside the subject, 
we impose regularizations on the SDF field as:
\begin{equation}
\begin{aligned}
L_{\mathrm{sdf}}=\sum_{i, j \in \mathrm{S}_e} &H\left(\sigma\left(s_i\right), \operatorname{sign}\left(s_j\right)\right) \\
& +H\left(\sigma\left(s_j\right), \operatorname{sign}\left(s_i\right)\right),
\end{aligned}
\end{equation}

\noindent where $\mathrm{S}_e$ is the set of all vertex along their edges in which the signs of the SDF values are different (\ie, $\mathrm{sign}(s_i) \neq \mathrm{sign}(s_j)$).
To remove the floating meshes outside the surface, we impose an additional loss.
For a triangle surface $f$ extracted by marching tetrahedra, if $f$ is invisible, we encourage its SDF values to be positive as:
\begin{equation}
L_{\mathrm{invis}}=\sum_{i \in \mathrm{S}_{\mathrm{invis}}} H(\sigma\left(s_i\right), 1).
\end{equation}

We weigh the above terms and use the loss for all our experiments:
\begin{equation}
\begin{aligned}
	L &= L_\text{image} + L_\text{mask} \\
	&+ \underbrace{\lambda_{\mathbf{k}_{\mathrm{d}}}}_{=0.03} L_{\mathbf{k}_{\mathrm{d}}} 
	+ \underbrace{\lambda_{\mathbf{k}_{\mathrm{orm}}}}_{=0.05} L_{\mathbf{k}_{\mathrm{orm}}}
	+ \underbrace{\lambda_{\mathbf{n}}}_{=0.025} L_{\mathbf{n}} \\
	&+ \underbrace{\lambda_\text{light}}_{=0.005} L_\text{light}
 	+ \underbrace{\lambda_\text{sdf}}_{=0.02} L_\text{sdf}
  	+ \underbrace{\lambda_\text{invis}}_{=0.01} L_\text{invis}.
\end{aligned}
\end{equation}