\section{Introduction}

With the increasing attention given to large-scale language models, they have become an essential component in natural language processing. As the size of pre-trained models grows, their usage is also gradually changing. Different from models such as BERT \cite{devlin2018bert} and T5 \cite{raffel2020exploring}, which require fine-tuning with a small amount of data, models such as GPT-3 \cite{brown2020language}, require the prompt design to generate target outputs. The recent ChatGPT\footnote{https://chat.openai.com/} model, which employs Reinforcement Learning for Human Feedback (RLHF) \cite{christiano2017deep}, simplifies prompt design, enabling better utilization of the zero-shot ability of large-scale pre-trained models in a conversational way. Based on this, many works have begun to analyze the zero-shot ability of ChatGPT in various natural language processing tasks, such as information extraction \cite{wei2023zero}, text summarization \cite{wang2023cross}, and mathematical abilities \cite{frieder2023mathematical}. Due to ChatGPT's strong ability in code generation and the fact that code generation models usually require a large amount of annotated data to produce good results, a zero-shot code generation model is very important. This paper first conducts a comprehensive evaluation of ChatGPT's zero-shot performance on a challenging code generation task: Text-to-SQL.

The Text-to-SQL task involves converting user input text into SQL statements that can be executed on a database, allowing non-expert users to better access the contents of a database. The design of Text-to-SQL models is typically challenging because they need to work across different databases and consider various user text input text and database structures. Due to the complexity of the Text-to-SQL task, a comprehensive evaluation of its performance requires consideration of a variety of scenarios in addition to the classic Spider dataset \cite{yu2018spider}. For example, Spider-SYN \cite{gan2021towards} focuses on scenarios where the data schema mentioned in the user text input is synonymous with the database schema, Spider-DK \cite{gan2021exploring}  considers scenarios where the input question contains additional knowledge, Spider-CG \cite{gan-etal-2022-measuring-and} emphasizes the combination generalization ability of models, and ADVETA \cite{pi-etal-2022-towards} considers scenarios where column names in the database have been modified. Additionally, to better reflect real-world scenarios, SParC\cite{yu2019sparc} and CoSQL \cite{yu2019cosql} incorporate multi-turn interaction between the user and the system. Finally, to evaluate models' multilingual capabilities, CSpider \cite{min2019pilot} and DuSQL \cite{wang2020dusql} evaluate Text-to-SQL performance in Chinese.

During our experiments, we evaluate the ability of ChatGPT on 12 different Text-to-SQL benchmark datasets. Based on the experimental results, we conclude the following observations:
\begin{enumerate}
    \item Compared to the current state-of-the-art (SOTA) model that uses complete training data, ChatGPT without using task-specific training data only performs 14\% worse. This already demonstrates that ChatGPT is a strong zero-shot Text-to-SQL converter.
    \item The robustness of ChatGPT in generating SQL statements is very strong, and the performance gap between ChatGPT and the SOTA models is only 7.8\% on some robustness settings of the Spider dataset, which is lower than the 14\% gap on the standard Spider dataset.
    \item  In the ADVETA \cite{pi-etal-2022-towards} scenario where the column names in the database are adversarially modified, ChatGPT's performance even surpasses that of the current SOTA models by 4.1\%.
    \item The Exact Match metric of the data generated by ChatGPT is very low because there are many different ways to express SQLs with the same purpose. Therefore, we mainly use execution accuracy as the evaluation metric.
\end{enumerate}
Overall, our experiments demonstrate that ChatGPT has strong Text-to-SQL capabilities and robustness, and it outperforms SOTA models in certain scenarios.

% Existing works explore the compositional generalization of Text-to-SQL only in the scenario that precisely maps stand-alone utterances to SQL queries.  

%  \citet{shaw-etal-2021-compositional} define the atom and compound for SQL statements and propose the TMCD split to repartition the dataset.   \citet{gan-etal-2022-measuring} annotate the alignment of sub-sentence and sub-SQL in the spider dataset \cite{yu-etal-2018-spider} and then recombine these sub-SQLs and sub-sentences. 
% In these settings, the SQL statements and user questions in the constructed test split tend to be much more complex. However, it is difficult for users to express complex queries in a stand-alone sentence. In real scenarios, users often start with a simple query and continuously combine additional query conditions with subsequent questions.

% \begin{figure}
%   \includegraphics[width=0.5\textwidth]{figures/cg-intro.pdf}
%   \caption{ During the inference phase, the base queries and their modifications could be re-combined. Models with compositional generalization ability should successfully parse these novel combinations. }
%   \label{fig:intro}
%   \vspace{-0.2mm}
% \end{figure}

% In this work, we focus on the study of compositional generalization in context-dependent Text-to-SQL tasks, which is more natural and applicable. In the context-dependent Text-to-SQL task \cite{yu-etal-2019-sparc}, the generated SQL statements are refined based on the user input text during each interaction. The input text from each interaction can be viewed as component modifications to the previous SQL statement, which could be further extracted as the modification patterns.  Since these modification patterns could also be combined with other SQL statements, the models are supposed to have the compositional generalization to these novel combinations. For example, in Figure 1, the modifications and the queries of the first turn in the training phrase could be re-combined in the inference phrase. Applicable models are supposed to successfully parse these novel combinations.

% To better investigate compositional generalization in the context-dependent Text-to-SQL, we first construct compositional generalization benchmarks based on the existing datasets. First, we extract the modification patterns from the training dataset and then recombine them with the existing SQL statements in the development set. Note that in the compositional generalization setting, only the recombination results not existing in the training set are kept.  To generate the corresponding utterances, we use a semi-automatic approach. The utterances are initially generated by a pre-trained model fine-tuned on the training data, and then reviewed and verified by human experts. As a result, we create two benchmarks, \textsc{CoSQL-CG} and \textsc{Sparc-CG}, specifically for the datasets \textsc{CoSQL}\cite{yu-etal-2019-cosql} and \textsc{SParC}\cite{yu-etal-2019-sparc}. Our experiments reveal that current state-of-the-art models perform poorly on these benchmarks, emphasizing the significance of enhancing compositional generalization capabilities.

% After that, the corresponding utterance is generated with a semi-automatic method: the utterance is first generated by a pre-trained model fined tuned on the training data, and then the utterance is checked manually by human experts. We finally generate two benchmarks \textsc{CoSQL-CG} and \textsc{Sparc-CG} for \textsc{CoSQL}\cite{yu-etal-2019-cosql} and \textsc{SParC}\cite{yu-etal-2019-sparc} separately. Further experiments show that current competitive models struggle on our benchmarks, which illustrates the importance of improving the compositional generalization ability.




% We further explore how to improve the compositional generalization in context-dependent Text-to-SQL tasks. Inspired by the previous works to improve compositional generalization by fine-grained alignment of inputs and outputs \cite{DBLP:conf/acl/ZhengL22, DBLP:journals/corr/abs-2106-03993}, we propose a method to better align the current text with the previous SQL statements. We follow the common practice of most competitive
% Text-to-SQL models which take the concatenation of all utterances as input. Specifically, our proposed \texttt{p-align} method extracts the embedding of the text from each interaction after the encoding process and then decodes them into the corresponding SQL statements separately. Further experiment results show that our \texttt{p-align} method could effectively improve the compositional generalization of current models, which also demonstrates that better alignment of text and SQL statements and the introduction of previous SQL statements are of great importance.

% To summarize, the main contributions of our paper are as follows:
% \begin{itemize}
%     \item To the best of our knowledge, we are the first to explore  compositional generalization in context-dependent Text-to-SQL.
%     \item We construct two benchmarks named \textsc{CoSQL-CG} and \textsc{Sparc-CG} to better facilitate the relevant research.
%     \item We propose a simple and effective method named \texttt{p-align}  to improve the compositional generalization ability of models.
% \end{itemize}


% Since these modification patterns could be applied to various SQL statements, the model needs to have the ability to successfully parse the novel combination of the modification patterns and SQL statements, which could also be described as the compositional generalization for pattern modification. 
