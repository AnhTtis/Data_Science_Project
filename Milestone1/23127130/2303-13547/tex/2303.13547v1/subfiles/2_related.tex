\section{Related Work}

Text-to-SQL is an important semantic parsing task that converts natural language questions posed by users into SQL statements that can be executed on a database. On the classic Spider dataset \cite{yu2018spider}, many classic works such as RatSQL \cite{wang2019rat} and LGESQL \cite{cao2021lgesql} have achieved excellent results. Since Text-to-SQL is a very complex task involving both user input questions and database structure, the robustness of the model is crucial. To further explore this issue, \citet{gan2021towards} proposed the Spider-SYN dataset to evaluate the robustness of models under synonym substitution scenarios. Some works, such as Proton \cite{wang2022proton} and ISESL-SQL \cite{liu2022semantic}, are also devoted to improving the robustness of models in this scenario. Meanwhile, many works explore the robustness of the Text-to-SQL task in other scenarios. The Spider-DK dataset \cite{gan2021exploring} evaluates the robustness of models in scenarios requiring additional knowledge. The Spider-Realistic dataset \cite{deng2020structure} removes the explicit appearance of dataset schema information in user questions, thereby increasing the difficulty of the original task. The Spider-CG dataset \cite{gan-etal-2022-measuring-and} evaluates the robustness of models in compositional generalization scenarios. The ADVETA dataset \cite{pi-etal-2022-towards} evaluates the robustness of models in scenarios involving adversarial modifications of database table information. In addition, to verify the robustness of models in cross-lingual scenarios, CSpider \cite{min2019pilot} and DuSQL \cite{wang2020dusql} have been proposed to evaluate the robustness of models in the Chinese language. To evaluate the performance of Text-to-SQL in more realistic scenarios, SParC \cite{yu2019sparc} and CoSQL \cite{yu2019cosql} have been proposed to evaluate the performance of multi-turn Text-to-SQL. Models such as \textsc{STaR} \cite{cai2022star} and CQR-SQL \cite{xiao2022cqr} have also achieved good results in this scenario.

Currently, several methods have been attempted to explore the improvement of large-scale language models for Text-to-SQL models. The PICARD \cite{scholak2021picard} and  RASAT \cite{qi2022rasat} utilize the T5-3B model, but still require the training data for fine-tuning. \citet{rajkumar2022evaluating} investigated the Text-to-SQL capabilities of the GPT3 model in a zero-shot setting. \citet{cheng2022binding} proposed the BINDER model based on the GPT3 codex, which has similar Text-to-SQL generation capabilities with the need for in-context exemplar annotations. However, these works do not provide a comprehensive evaluation of Text-to-SQL and are limited to a few datasets without other robustness settings. In this work, we are the first to evaluate the comprehensive Text-to-SQL capabilities of ChatGPT.







