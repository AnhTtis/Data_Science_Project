\section{Conclusion}
% In this paper, we conduct the first exploration of compositional generalization in context-dependent Text-to-SQL scenarios. To facilitate the related research, we construct two benchmarks named \textsc{SParC-CG} and \textsc{CoSQL-CG} composed of out-of-distribution examples. Meanwhile, we propose the \texttt{p-align} method to improve the compositional generalization ability of current models. Further experiments show that current models perform very poorly on our constructed benchmarks and demonstrate the effectiveness of our \texttt{p-align} method.

In this work, we conducted a comprehensive analysis of ChatGPT's zero-shot ability in Text-to-SQL. We found that even without using any training data, ChatGPT still has strong Text-to-SQL ability, although there is still some gap compared to the current SOTA models. Additionally, ChatGPT demonstrated strong robustness, performing relatively better on most robustness benchmarks and even surpassing the current SOTA models on the ADVETA benchmark. Although this paper has made some findings, we only utilize a common prompt to evaluate ChatGPT's ability. And in future work, better prompts could be designed to explore ChatGPT's Text-to-SQL ability.

\section{Future work}

In future work, we will primarily consider the following two directions to further explore ChatGPT's capabilities in the Text-to-SQL task.
Firstly, we will conduct more interactions with ChatGPT to address the issue of generating non-executable SQL statements. We can design ChatGPT to engage in multi-turn dialogues with the provided database error messages to further ensure the validity of generated SQL statements.
Secondly, we will add more highly correlated in-context examples to the prompt to enhance ChatGPT's ability to generate Text-to-SQL.