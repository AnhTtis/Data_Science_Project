\section{Particle filter algorithm}

% Description and motivation of the main steps
% Discussion of issues related to the environemnt properties
% Link to the next section where they re addressed by our approach

As it was previously mentioned, the Kalman filter requires Gaussian distribution of motion and measurement noise and known initial state. 
If these requirements do not hold, the particle filter method~\cite{PF1996} can help.
This method successfully operates with arbitrary  distributions of state and measurement noise and even with the unknown initial state.

The idea of the particle filter method is to generate a set of trial state vectors $\rvx_{t=0}^{i} \in \mathbb{R}^d, \; i=1,\ldots,N$, which are called particles and the  corresponding weights~$w^i$ which are initialized as $1 / N$.
These vectors are used to approximate unknown distribution $p(\vx_t)$ and weights
\begin{equation}
    w^i_t = \mathbb{P}(\vx_{t} = \rvx_t^{i}).
\label{eq::weights}
\end{equation}
Then, the particle states are updated according to the motion equation: $\rvx_{t+1}^i= f(\rvx_t^i, \rvu_t, \boldsymbol{\eta}^i)$, where external control $\rvu_t$ is the same for all particles. 
At this stage, the information is partially lost due to the uncertainty $\boldsymbol{\eta}^i$ in the external control.

After that, we perform the measurement and obtain  $\rvz_{t+1}$.
Then, to estimate the uncertainty in the measured $\rvz_{t+1}$, we compute its conditional likelihood given state vector $\rvx_{t}$: 
\begin{equation}
    \mathcal{L}(\rvz_t|\rvx_t^i) = \prod_{j=1}^K p(\rvz^j_t|\rvx^i_t),
    \label{eq::likelihood}
\end{equation} 
where $K$ is a number of beacons, see Section~\ref{sec::problem_statement}. 
Here $p(\rvz^j_t|\rvx_t^i)$ is the probability to get measurement value $\rvz^j_t$ for beacon with index $j$ at time $t$ given the state $\rvx^i_t$.
In the general case, $p(\rvz|\rvx)$ is calculated from the distribution of the  measurement noise $\boldsymbol{\zeta}$.
In this study, the distribution of measurement noise is Gaussian, i.e. $\boldsymbol{\zeta}\sim\mathcal{N}(0, \mR)$, where $\mR = \sigma^2 \mI$. 
The predicted values of distances to $K$ beacons from the $i$-th particle are $\rvz_t^i = g(\rvx_t^{i}, \boldsymbol{\zeta})$.
At the same time, we perform measurement from the ground-truth object position to the $K$ nearest beacons and get values $z_1^*,\ldots,z_K^*$ stacked in the vector $\rvz_t^* \in \mathbb{R}^K$.
Therefore, we can estimate the likelihood~\eqref{eq::likelihood} with the following formula: 
$\mathcal{L}(\rvz_{t+1}|\rvx_{t+1}^i) = \frac{1}{(2\pi)^{K/2} \sqrt{\det{\mR}}} \exp \left(
% -\sum_{j=1}^{K}\frac{(z_{j, t+1}-\tilde{z}_{j, t+1}^i)^2}{2\sigma^2}
-\frac12 (\rvz^*_t - \rvz_t^{i})^\top \mR^{-1} (\rvz^*_t - \rvz_t^{i})
\right)$.
%, where $\rvz^*_t$ is the ground-truth measurement vector. 

Then, to compute the updated particles' weights $w^i_{t+1}$ we use likelihood~\eqref{eq::likelihood} and current weights: 
\begin{equation}
\label{eq::particle_weights}
w_{t+1}^i \sim \mathcal{L}(\rvz_{t+1}|\rvx_{t+1}^i) w_t^i,
\end{equation}
where $\sim$ indicates equality up to the normalization factor, i.e. $\sum_{i=1}^N w_{t+1}^i = 1$.
% Now, the updated weights $w_{t+1}^i$ are not normalized since resampling procedure affects them further.
From the updated weights $w^i_{t+1}$ the object state $\rvx_{t+1}$ can be estimated as expectation over the generated particles:
\begin{equation}
\begin{split}
& \rvx_{t+1} = \E [\vx_{t+1}] = \sum_{i=1}^N w^i_{t+1} \rvx_{t+1}^i.\\
% & \Var [\vx_t]=\sum_{i=1}^N w_t^i \rvx^{i2} - \left(\sum_{i=1}^N w_t^i \rvx_t^i\right)^2
\end{split}
\end{equation}
According to~\cite{proof} at a large enough number of particles and sufficiently large time steps, values $\rvx_t$ converge to known values $\rvx_t^*$. 
% However, at the finite number of particles and finite time steps even at noise-free measurements, this randomized approach may suffer from the impoverishment and degeneracy problems drawback~\cite{Frederick}. 

% Degeneracy problem occurs when due to measurements most particles have too low weights. To address it resampling is being applied. The idea of  resampling is to reduce the particles with low weights and duplicate those with higher weights so that the new weights of particles are more uniform. That may be achieved in many ways and there will discuss in ~\ref{resampling}. But the simplest way is to perform the sampling with repetitions of indices proportional to the particle weights.
% However, this may cause another problem -- impoverishment or loss of particles diversity. In this case, the majority of particles are concentrated within a small area.
% This may cause an incorrect representation of posterior distribution and finally incorrect state estimation. The situation will not be fixed regardless of the number of further time steps and measurements performed. 
% The problem of particle filter impoverishment is very broad and is a topic for separate research (see, for example~\cite{degeneracy}). 
As it was mentioned above, despite the simplicity of implementation and universality of this method, it has drawbacks such as degeneracy and impoverishment~\cite{fight}.
The formal measure of degeneracy is the number of effective particles:
\begin{equation}
    N_{eff} = \left\lfloor\frac{1}{\sum_{i=1}^{N} (w^i)^2}\right\rfloor,
\end{equation}
which varies from $1$ to $N$. 
The worst case is $N_{eff} = 1$, i.e. the single particle has non-zero weight. 
The best case is $N_{eff} = N$, i.e. all particles have the same values of weights $w^i = 1/N$. 
If $N_{eff}$ drops below a pre-defined threshold, for example, $N_{eff} \le N / 4$ or $N_{eff} \le  N / 2$, it indicates a degeneracy problem.
To address this problem, a resampling procedure is used.

The widespread resampling procedure is known as stochastic resampling~\cite{resamp1, Tutorial}. 
Formally it samples $N$ indices of particles from the multinomial distribution with repetitions.
The parameters of multinomial distributions are weights $w_t^i$.
After that, the $j$-th particle state is updated with the $i_j$ particle state, where $i_j$ is sampled index.
The described stochastic resampling procedure is summarized as follows:
\begin{equation}
\begin{split}
    &i_1,\ldots,i_N \sim Multinomial(w^1_{t+1},\ldots,w^N_{t+1})\\
    &\rvx^1_{t+1},\ldots,\rvx^N_{t+1} \leftarrow  \rvx^{i_1}_{t+1},\ldots,\rvx^{i_N}_{t+1}\\
    &w^i_{t+1}=\frac{1}{N}.
\end{split}
\label{eq::stoch_resampling}
\end{equation}
% The stochasticity can lead to reduce variability in the set of trial states and generate irrelevant states, which prevent proper convergence. 
% Moreover, as it is shown in ~\cite{towards} it is a biased procedure that could affect method performance. 
%One of the way to improve its performance is the replacement of random resampling by one of the deterministic methods~\cite{resamp1, towards}:
%\begin{equation}
%\begin{split}
%    &\rvx^1_t,\ldots,\rvx^N_t \leftarrow  %R(\rvx^{i_1}_t,\ldots,\rvx^{i_N}_t, w^1_t, \ldots,w^N_t  \mid %\boldsymbol{\evomega})\\
%    &w^i_t=\frac{1}{N},
%\end{split}
%\label{eq::stoch_resampling}
%\end{equation}
%where $R$ is a deterministic resampling function, which depends on parameter vector $\boldsymbol{\evomega}$.
% The other approach~\cite{curse_dim} uses the block particle filter approach that avoids impoverishment problems in particle filter in the case of high dimensional space. 

After the resampling of particles is done, few particles have the same states. 
Therefore, they represent the target probability density function poorly and particle filter may converge to the wrong state.
This problem is known as impoverishment~\cite{fight}. 
To improve the diversity of particles, random noise with sufficiently large variance is added to particle states~\cite{towards}.
The described particle filter method is summarized in Algorithm~\ref{alg::PF}.

% Add complete description of particle filter

\begin{algorithm}[!h]
\caption{Particle filter method with stochastic resampling.}
\label{alg::PF}
\begin{algorithmic}[1]
\REQUIRE Number of particles $N \geq 1$, number of beacons $K \geq 1$, motion and measurement equations $f$, $g$, covariance matrices $\mM$ and $\mR$ of motion and measurement noise.
\ENSURE predicted object states $\rvx_{t}$ for $t=1,\ldots,T$
\FOR{$i = 1$ to $N$}
    \STATE Initialize weights $w^i \gets 1/N$
    \STATE Initialize particle state $\rvx_1^i \gets \mathcal{U}(\rvx_{\min},\rvx_{\max})$
 \ENDFOR
\FOR{$t=1$ to $T$}
    \FOR{$i=1$ to $N$}
        \STATE Generate $\boldsymbol{\eta}^i \sim \mathcal{N}(0, \mM)$, $\boldsymbol{\zeta}^i \sim \mathcal{N}(0, \mR)$
        \STATE Update state $\rvx_{t+1}^i = f(\rvx_t^i,\rvu_t, \boldsymbol{\eta}^i)$ and perform measurements $\rvz^i_{t+1} = g(\rvx_{t+1}^i, \boldsymbol{\zeta}^i)$
        \STATE Compute likelihood $\mathcal{L}(\rvz_{t+1}|\rvx_{t+1}^i) = \frac{1}{(2\pi)^{K/2} \sqrt{\det{\mR}}}\exp \left( -\frac12 (\rvz^*_t - \rvz_t^{i})^\top \mR^{-1} (\rvz^*_t - \rvz_t^{i}) \right)$
        \STATE Update particle's weight $w_{t+1}^i \sim \mathcal{L}(\rvz_{t+1}|\rvx_{t+1}^i) w_t^i$
        %\STATE $i_1,\ldots,i_N \sim Multinomial(w^1_{t+1},\ldots,w^N_{t+1})$
        %\STATE $\rvx^1_{t+1},\ldots,\rvx^N_{t+1} \gets  \rvx^{i_1}_{t+1},\ldots,\rvx^{i_N}_{t+1}$
        %\STATE $w^i_t \gets\frac{1}{N}$
    \ENDFOR
    \STATE Perform resampling of the updated states according to~\eqref{eq::stoch_resampling}
    \STATE $\rvx_{t+1} \gets \sum_{i=1}^N w_{t+1}^i \rvx_{t+1}^i$
\ENDFOR
\end{algorithmic}
\end{algorithm}


The impoverishment problem might be especially severe in highly symmetric environments. 
In this case, consistent state representation in several similar subparts of the environment requires the number of particles proportional to the number of subparts, see Figure~\ref{fig::sym_env_example}~(left). 
Moreover, if the environment is highly symmetric, the filtered trajectory may coincide with the ground truth but only up to the symmetric subpart, see Figure~\ref{fig::symmetric_env_traj}, where the predicted trajectory is computed by the particle filter method.
\begin{figure}[!h]
    \centering
\includegraphics[width=0.5\textwidth]
    {{pics/_27_27.pdf}}
    \caption{Visualization of the symmetric test environment with the ground truth and filtered trajectories marked with circles and crosses, respectively. The measurements are performed from the five nearest beacons. The final positions are shown with a big circle and cross. Note that the final filtered points may differ from the corresponding points in the ground-truth trajectory, though they are identical up to symmetry. Number of particles $N=10000$.}
    %\textbf{MKF} algorithm is used, noise level $4\Sigma$
    \label{fig::symmetric_env_traj}
\end{figure}
To reduce the number of particles necessary for convergence in a symmetric environment, we suggest equipping every particle with equations~\eqref{eq::EKF} and~\eqref{eq::Qt_EKF} from the Extended Kalman filter. 
A detailed description of the proposed Multiparticle Kalman filter (MKF) is given in the next section.

% From our practical experience, we provide a list of a few simple recipes to address the impoverishment problem of the particle filter method:
% \begin{itemize}
%     \item increase number of particles $N$: the larger number of particles is, the higher probability to get particles with near-optimal states and thus ensure faster convergence; 
%     \item increase motion noise $\eta$: the motion noise should be sufficiently large, otherwise, the exploration ability of resampled particles is limited.
%     \item reduce the precision of measurements, i.e. eliminate instability in the computation of likelihood~(\ref{eq::likelihood}) 
%     \item tracking likelihood values, i.e. if the likelihood of measurement for all particles is sufficiently small, then regenerate trial states and restart method. 
% \end{itemize}

%The pseudocode of the particle filter is shown in Algorithm~\ref{al::PFAlg}. 
%Here $g(\rvz^i, \rvx^i)$ is a measurement function, $\Delta$ is a state noise $\eta$ amplitude, $T$ is the total time.

% The example of particle filter performance is shown in the same world, which is used for Kalman filter~(\ref{fig::pf_world1}). 
% Here there is one beacon only and the particle initial state is known within $1$ cell.
% Therefore, particles are randomly generated in this cell. 
% The filter converges for all such conditions in a few time steps. 

% \begin{figure}[!ht]
%     \centering
%     \begin{subfigure}{0.45\textwidth}
%     \centering
%     \includegraphics[scale=0.33]
%     {pics/SPF_1.pdf}
%     \caption{PF step 1}
%     \end{subfigure}
%     ~
%     \begin{subfigure}{0.45\textwidth}
%     \centering
%     \includegraphics[scale=0.33]
%     {pics/SPF_2.pdf}
%     \caption{PF step 2}
%     \end{subfigure}
%     \\
%     \begin{subfigure}{0.45\textwidth}
%     \centering
%     \includegraphics[scale=0.33]
%     {pics/SPF_25.pdf}
%     \caption{PF step 25}
%     \end{subfigure}
%     ~
%     \begin{subfigure}{0.45\textwidth}
%     \centering
%     \includegraphics[scale=0.33]
%     {pics/SPF_40.pdf}
%     \caption{PF step 40}
%     \end{subfigure}
% \caption{Particle filter performance example}
% \label{fig::pf_world1}
% \end{figure}


