\section{Multiparticle Kalman filter}

We propose a new natural combination of Kalman and particle filters. 
The goal of such a combination is to develop an algorithm, which deals with the unknown initial states like particle filter and accelerates convergence to an optimal state like the Kalman filter.
Since the symmetric environments are especially challenging for the particle filter, we will use them to illustrate the accelerated convergence of the proposed method.

The idea of the proposed method is to generate a set of trial state vectors (particles) $\rvx_{t=0}^{i} \in \mathbb{R}^d, \; i=1,\ldots,N$ with corresponding weights~$w_{t=0}^i = 1/N$, and also covariance matrices $\mP_{t=0}^i$.
Again, vectors $\rvx_t^{i}$ and weights $w_t^i$ play the same role as in the particle filter.

Then, we use the formulas from the Extended Kalman filter for every generated particle in parallel. 
In particular, equations~\eqref{eq::Kalman_x_update},~\eqref{eq::Kalman_P_update},~\eqref{eq::EKF},~\eqref{eq::Qt_EKF} are used to compute the updated state vector of every particle $\rvx^i_{t+1}$.
After that, to update weights $w_t^{i+1}$ we compute distances to the beacons from the updated states $\rvz_{t+1}^{i} = g(\rvx_{t+1}^{i+})$.
% \begin{itemize}
% \item Predict stage
% \begin{equation}
% \begin{split}
% &\rvx_{t+1}^{i-} = f(\rvx^i_t, \rvu_{t+1})\\
% &\mP_{t+1}^{i-} = \mF^i \mP^i_{t} \mF^{i\top} + \mQ^i_{t+1}\\
% &\mF^i = \left.\frac{\partial f(\rvx, \rvu_{t+1})}{\partial \rvx}\right|_{\rvx = \rvx^i_t}
% \end{split}
% \label{eq::kpf_predict}
% \end{equation}
% \item Update stage
%  \begin{equation}
%  \begin{split}
%  &\tilde{\rvz}^i_{t+1} = g(\rvx_{t+1}^{i-})\\ 
%  &\mH^i_{t+1} = \left.\frac{\partial g(\rvx)}{\partial \rvx}\right|_{\rvx = \rvx^{i-}_{t+1}}\\
%  &\mK^i_{t+1} = \mP_{t+1}^{i-} \mH_{t+1}^{i\top} (\mH_{t+1}^i \mP_{t+1}^{i-} \mH_{t+1}^{i\top} + \mR)^{-1}\\
%  &\rvx^{i+}_{t+1} = \rvx_{t+1}^{i-} + \mK^i_{t+1} (\rvz^*_{t+1} - \rvz^i_{t+1})\\
%  &\mP^{i+}_{t+1} = (\mI - \mK^i_{t+1} \mH^i_{t+1})\mP_{t+1}^{i-}
%  \end{split}
%  \label{eq::kpf_update}
%  \end{equation} 
% \end{itemize}
% The only difference with the Kalman filter algorithm are the outputs: new states and covariance matrices $\rvx^{i+}, \mP^{i+}_{t+1}$, which are not final for this time step yet.
% The particles are already moved, see~\eqref{eq::kpf_predict}, so that the particle filter predict stage is not needed. 
% In~(\ref{eq::kpf_update}), we perform update for every particle separately, and now we need update weights $w^i_t$. 
% For that we need an updated prediction of the distances to the beacons. 
% They can be found from new states $\rvz_{t+1}^{i} = g(\rvx_{t+1}^{i+})$.
Then the weights are updated in the same way as in the particle filter based on the likelihood 
\[
\mathcal{L}(\rvz_{t+1}|\rvx_{t+1}^{i+}) = \prod_{j=1}^K p(\rvz^j_{t+1}|\rvx^{i+}_{t+1}),
\]
where $K$ is the number of beacons, which are used to measure distances.
% In particular, if the measurement noise $\boldsymbol{\zeta} \sim \mathcal{N}(0, \mR)$, then likelihood has the following form: $\mathcal{L}(\rvz_{t+1}|\rvx_{t+1}^i)\sim\exp \left( -\frac12 (\rvz^*_t - \rvz_t^{i})^\top \mR^{-1} (\rvz^*_t - \rvz_t^{i}) \right)$.
Now, the updated weights are computed as follows:
\begin{equation}
w_{t+1}^i \sim \mathcal{L}^i(\rvz_{t+1}|\rvx_{t+1}^{i+}) w_t^i.
\end{equation}

To prevent the degeneracy phenomenon, we perform resampling of the obtained particle states.
We follow the resampling procedure used in the particle filter~\eqref{eq::stoch_resampling} and modify it to resample not only particle states $\rvx^{i}_t$ but also corresponding covariance matrices $\mP^i_{t+1}$. 
The modified resampling procedure used in the proposed method is summarized in~\eqref{eq::kpf_resampling}:
% This is performed in the same way as a stochastic resampling in the standard particle filter. Every particle is resampled with the probability proportional to its weight and then inherits from the original particle both state and covariance matrix:
\begin{equation}
\begin{split}
    &i_1,\ldots,i_N \sim Multinomial(w^1_{t+1},\ldots,w^N_{t+1})\\
    &\rvx^{1+}_{t+1},\ldots,\rvx^{N+}_{t+1} \leftarrow  \rvx^{i_1+}_{t+1},\ldots,\rvx^{i_N+}_{t+1}\\
    &\mP^{1}_{t+1},\ldots,\mP^{N}_{t+1} \leftarrow  \mP^{i_1+}_{t+1},\ldots,\mP^{i_N+}_{t+1}\\
    &w^i_{t+1}=\frac{1}{N}.
\end{split}
\label{eq::kpf_resampling}
\end{equation}
% These equations~(\ref{eq::kpf_resampling}) give the resulting values for the covariance matrices $\mP^i_{t+1}$ and weights~$w_{t+1}^i$. 
Now to address the impoverishment issue, we add noise to the resampled states: 
\begin{equation}
    %\rvx^{i}_{t+1} = \rvx^{i+}_{t+1} + \boldsymbol{\varepsilon}^i,
    \rvx^{i}_{t+1} = f(\rvx^{i+}_{t+1}, \boldsymbol{0}, \boldsymbol{\eta}^i),
\end{equation}
where $\boldsymbol{\eta}^i \sim \mathcal{N}(0, \mM)$, where $\mM$ is given covariance matrix.

% is computed according to~\eqref{eq::Qt_EKF} separately for every $i$-th particle.

Note that the per-iteration computational complexity of the presented algorithm is higher than the complexity of the standard particle filter. 
Indeed, in addition to the particle filter steps, the proposed method processes $d \times d$ matrices for every particle.
Therefore, to process every particle memory complexity is increased up to $O(d^2)$ caused by storing matrices, and computational complexity is increased up to $O(d^3)$ operations caused by matrix multiplications\footnote{This complexity can be slightly reduced to $O(d^{2.32})$ according to~\cite{duan2022faster}}. 
Despite this, we observe in the experiments (see Section~\ref{sec::experiments}) that it ensures faster convergence since requires fewer particles.




% ($O(Nd^3)$ and memory consumption $O(Nd^2)$ than the standard particle filter algorithm $O(N\, d)$, where $N$, and $d$ are particles number and problem dimension. 
% However despite of that as it will be shown later it may converge faster as usually requires significantly less particles number.

% Thus, we present the novel combination of extended Kalman filter and particle filter. In Section~\ref{sec::experiments} we demonstrate its superior performance compared to competitors.
% Below we discuss the proposed method and highlight its difference from the extended Kalman particle filter which relies on the same idea.  

% \paragraph{Discussion}
% The suggested method relies more on a particle filter part, while the Kalman step is used only for coordinates correction in an intermediate step. 

% The example of Kalman particle filter performance is shown in Figure~\ref{fig::kpf_world1}. 
% Here there is one beacon and the particle's initial location is known within a $1$ cell, the uncertainty is included in the covariance matrix. 
% The filter converges for all such conditions in a few time steps. 

% \begin{figure}[!ht]
%     \centering
%     \begin{subfigure}{0.45\textwidth}
%     \centering
%     \includegraphics[scale=0.33]
%     {pics/KPF_1.pdf}
%     \caption{KPF step 1}
%     \end{subfigure}
%     ~
%     \begin{subfigure}{0.45\textwidth}
%     \centering
%     \includegraphics[scale=0.33]
%     {pics/KPF_2.pdf}
%     \caption{KPF step 2}
%     \end{subfigure}
%     \\
%     \begin{subfigure}{0.45\textwidth}
%     \centering
%     \includegraphics[scale=0.33]
%     {pics/KPF_25.pdf}
%     \caption{KPF step 25}
%     \end{subfigure}
%     ~
%     \begin{subfigure}{0.45\textwidth}
%     \centering
%     \includegraphics[scale=0.33]
%     {pics/KPF_40.pdf}
%     \caption{KPF step 40}
%     \end{subfigure}
% \caption{Kalman particle filter performance example}
% \label{fig::kpf_world1}
% \end{figure}

% The other approach, combining particle and Kalman filter exist. 
% In~\cite{EPF_EKF} extended Kalman particle filter is described.
% This method is similar to the proposed one but differs in the weights update scheme.
% It updates weights according to the following equation
% \[
% w^i_{t+1} = \frac{p^i_{t+1} \mathcal{L}^i(\rvz_{t+1}|\rvx_{t+1}^{i+}) w^i_{t}}{d^i_{t+1}},
% \]
% where $d^i_{t+1} = \mathbb{P}(\boldsymbol{\xi} = \rvx^i_{t+1}-\rvx^{i+}_{t+1})$, where $\boldsymbol{\xi} \sim \mathcal{N}(0, \mP^i_{t+1})$ and $p^i_{t+1} = \mathbb{P}(\boldsymbol{\delta} = \rvx^i_{t+1}-\rvx^{i+}_{t+1})$, where $\boldsymbol{\delta} \sim \mathcal{N}(0, \mQ_{t+1}^i)$.
% The motivation of this scheme is to compensate small weights corresponding to the relevant particles with multipliers $d^i_{t+1}$ and $p^i_{t+1}$.
% The natural drawback of this scheme is that large weights are assigned to irrelevant particles due to possible inconsistency between covariance matrices $\mP_{t+1}^i$ and likelihood $\mathcal{L}^i$.
% Therefore, the convergence becomes slower.

% The next issue of this approach is in computing $p^i_{t+1}$ since for some environments corresponding covariance matrix can become singular.
% For example, if particles move on the plane, then states contain $3$ dimensions: two coordinates $x, y$ and angle $\phi$.
% Then, the process covariance matrix $\mQ_{t+1}^i$ is of the size $3 \times 3$.
% At the same time, noise $\boldsymbol{\eta}=(\eta_r, \eta_{\phi})$ independently affects angle and speed, and therefore has only two independent elements.
% Thus, the corresponding covariance matrix is a low rank, which leads to numerical instabilities.
% Although regularization can help, it requires more tuning of the hyperparameters.

% In~\cite{SHARIATI201932} the same method as we propose here has been applied for the identification of the nonlinear dynamic of an autonomous underwater vehicle. However, the covariance matrices are taken from experimental data fitting and they are diagonal. In the present paper we demonstrate applicability of the method for the classical object motion on the plane. It is shown that the classical filter performance depends significantly on the noise level chosen. At the same time, the proposed \textbf{PFKU} has higher immunity to the noise level and thus provides more robust results in case if the internal system noise is unknown. Moreover, the Kalman particle filter performs better at the same computational resources, and is much more accurate then particle filter at the same number of particles.
