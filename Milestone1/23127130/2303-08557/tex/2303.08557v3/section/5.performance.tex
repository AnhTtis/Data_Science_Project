\vspace{-0.2cm}
\section{Performance} \label{performance}
This section provides a comprehensive overview of the evaluation process for models in Cross-Domain Few-Shot Learning (CDFSL). To assess the effectiveness of these models, we first examine the relevant datasets and benchmarks in Section~\ref{benchmark}. In Section~\ref{per-com}, we offer a detailed analysis and comparison of the performance of various methods in CDFSL, highlighting the strengths and weaknesses of different approaches in tackling this complex problem.

\vspace{-0.2cm}
\subsection{Datasets \& Benchmarks} \label{benchmark}
The availability of annotated datasets enables fair comparison of CDFSL models and fosters the evaluation of various algorithms and architectures. The complexity, size, number of annotations, and transfer difficulty of these datasets present ongoing challenges that drive the development of innovative techniques. Table~\ref{dataset} lists the most widely used datasets for the CDFSL problem.
\begin{table}%[b]
\tiny
\centering
\vspace{-0.3cm}
\caption{Details of datasets in CDFSL.}
\vspace{-0.3cm}
\setlength{\tabcolsep}{1.2mm}{
\begin{tabular}{lcccccccc}
\hline
\textbf{Datasets} & \textbf{Derived from} & \textbf{Number of images} & \textbf{Image size} & \textbf{\makecell[c]{Number of \\ categories}} & \textbf{Content} & \textbf{Fields} & \textbf{Reference}     \\ 
 \hline
\textit{mini}ImageNet & ImageNet & 60000 & $84 \times 84$ & 100 & objects classification & natural scene & \cite{miniimagenet}    \\  
% \hline
\textit{tiered}ImageNet & ImageNet & 779165 & $84 \times 84$ & 608 & objects classification & natural scene & \cite{tieredimagenet}     \\
% \hline
Plantae  & iNat2017 & 196613 & varying & 2101 & plants \& animals classification & natural scene & \cite{plantae}  \\
% \hline
Places     & N/A & 10 million & $200 \times 200$ & 400+ & scene classification  & natural scene & \cite{places}   \\
% \hline
Stanford Cars     & N/A & 16185 & varying & 196 & cars fine-grained classification & natural scene &  \cite{cars}   \\
% \hline
CUB   & ImageNet & 11788 & $84 \times 84$ & 200 & birds fine-grained classification & natural scene &  \cite{cub}   \\  
% \hline
CropDiseases   & N/A & 87000 & $256 \times 256$ & 38 & crop leaves classification & natural scene &  \cite{cropdiseases}  \\
% \hline
EuroSAT   & Sentinel-2 satellite & 27000 & $64 \times 64$ & 10 & land classification & remote sensing &  \cite{eurosat}   \\
% \hline
ISIC 2018   & N/A & 11720 & $600 \times 450$ & 7 & dermoscopic lesion classification & medical &  \cite{isic1}   \\
% \hline
ChestX   & N/A & 100K & $1024 \times 1024$ & 15 & lung diseases classification & medical & \cite{chestx}  \\
% \hline
Omniglot   & N/A & 25260 & $28 \times 28$ & 1623 & characters classification & character &  \cite{omniglot}   \\
% \hline
FGVC-Aircraft   & N/A & 10200 & varying & 100 & Aircraft fine-grained classification & natural scene &  \cite{aircraft}   \\
% \hline
DTD   & N/A & 5640 & varying & 47 & textures classification & natural scene &  \cite{dtd}   \\
% \hline
Quick Draw   & Quick draw! & 50 million & $128 \times 128$ & 345 & drawing images classification & Art &  \cite{draw1}   \\
% \hline
Fungi   & N/A & 100000 & varying & 1394 & fungi fine-grained classification & natural scene &  \cite{fungi}   \\
% \hline
VGG Flower   & N/A & 8189 & varying & 102 & flowers fine-grained classification & natural scene &  \cite{vgg}   \\
% \hline
Traffic Signs   & N/A & 50000 & varying & 43 & Traffic signs classification & natural scene &  \cite{traffic}   \\
% \hline
MSCOCO   & N/A & 1.5 million & varying & 80 & objects classification & natural scene &  \cite{mscoco}   \\
\hline
\end{tabular}}
\vspace{-0.5cm}
\label{dataset}
\end{table}

Based on these datasets, several benchmarks have been established for the CDFSL problem, including \textit{mini}ImageNet \& CUB (mini-CUB), the standard fine-grained classification benchmark (FGCB), and BSCD-FSL~\cite{bscd-fsl}. Additionally, Meta-Dataset~\cite{meta-dataset} has been proposed to evaluate the cross-domain problem in FSL. Since mini-CUB is included in FGCB, we mainly focus on introducing the last three benchmarks.

\textit{FGCB}.
An early benchmark for Fine-grained CDFSL ($FG$) was established during the initial development of CDFSL. It includes five datasets: \textit{mini}ImageNet, Plantae~\cite{plantae}, Places~\cite{places}, Cars~\cite{cars}, and CUB~\cite{cub}, with \textit{mini}ImageNet typically serving as the source domain and the others as the target domains. The benchmark consists entirely of natural images. The main challenge across domains for this benchmark is transferring the category information from coarse to fine.

\textit{BSCD-FSL}~\cite{bscd-fsl}.
As a more challenging benchmark for imaging way-based CDFSL ($IW$), BSCD-FSL includes five datasets: \textit{mini}ImageNet, CropDisease~\cite{cropdiseases}, EuroSAT~\cite{eurosat}, ISIC~\cite{isic1,isic2}, and ChestX~\cite{chestx}. Considering \textit{mini}ImageNet as the source domain, the distribution distances between the source and target datasets increase in the order: CropDiseases, EuroSAT, ISIC, and ChestX. BSCD-FSL is designed to evaluate methods across both near-domain and distant-domain scenarios.

\textit{Meta-Dataset}~\cite{meta-dataset}.
Meta-Dataset is a large-scale, diverse benchmark. It includes 10 publicly available datasets spanning natural images, handwritten characters, and graffiti, making it suitable for addressing Fine-grained ($FG$) and art-based ($Art$) CDFSL problems. This benchmark goes beyond the limitations of traditional \textit{C-way K-shot} tasks. It also introduces real-world class imbalances by varying the number of classes and training set sizes for each task.

Some methods use benchmarks originally designed for domain adaptation (DA). The DomainNet benchmark~\cite{domainnet}, addressing art-based cross-domain problems, includes 6 domains with 345 object categories. The Office-Home benchmark~\cite{officehome}, used in some CDFSL studies, comprises 4 domains (art, clipart, product, and real world) with 65 categories each and a total of 15,500 images, averaging 70 images per class.

\vspace{-0.2cm}
\subsection{Performance Comparison and Analysis} \label{per-com}
This section compares the performance of CDFSL approaches across various categories, using prediction accuracy as the standard metric under settings like \textit{5-way 1-shot}, \textit{5-way 5-shot}, \textit{5-way 20-shot}, and \textit{5-way 50-shot}. To ensure fair evaluation, all results in this paper are directly sourced from the original studies, and follow the setup in \cite{bscd-fsl}, with $C$-way $K$-shot data randomly sampled and averaged over 600 trials for robustness. As a subfield of FSL, many classical FSL methods are applied to CDFSL. Table~\ref{fsl_mtd} shows that meta-learning methods (e.g., MatchingNet, ProtoNet, RelationNet, MAML) perform worse in CDFSL due to domain gaps, while simple fine-tuning methods perform better as \textit{K} increases.
\begin{table}
\tiny
\centering
\vspace{-0.3cm}
\caption{CDFSL performance on the classical FSL approaches with ResNet10 backbone. $K$ means \textit{5-way K-shot}.}
\vspace{-0.3cm}
\setlength{\tabcolsep}{1.8mm}{
\begin{tabular}{clcccccccc}
\hline 
\textbf{\textit{K}} & \textbf{Methods} & \textbf{CropDiseases} & \textbf{EuroSAT} & \textbf{ISIC} & \textbf{ChestX} & \textbf{Plantae} & \textbf{Places} & \textbf{Cars} & \textbf{CUB}   \\ 
% \cline{3-18}
\hline
\multirow{5}*{1}  & Fine-tuning~\cite{bscd-fsl} & 61.56±0.90 & 49.34±0.85 & 30.80±0.59 &  21.88±0.38 & 33.53±0.36 & 50.87±0.48 & 29.32±0.34 &  41.98±0.41    \\ 
  & MatchingNet~\cite{miniimagenet} & 48.47±1.01 & 50.67±0.88 & 29.46±0.56 & 20.91±0.30 & 32.70 ± 0.60 & 49.86±0.79 & 30.77±0.47 & 35.89±0.51 \\
% \cline{2-10}
%   &  MAML & - & - & - & - & - & - & - & -   \\ 
% \cline{2-10}
  &  RelationNet~\cite{relation} & 56.18±0.85 & 56.28±0.82 & 29.69±0.60 & 21.94±0.42 & 33.17±0.64 & 48.64±0.85 & 29.11±0.60 & 42.44±0.77 \\
% \cline{2-10}
  &  ProtoNet~\cite{proto} & 51.22±0.50 & 52.93±0.50 & 29.20±0.30 & 21.57±0.20 & - & - & - & - \\ 
% \cline{2-10}
  &  GNN~\cite{gnn} & \textbf{64.48±1.08} & \textbf{63.69±1.03} & \textbf{32.02±0.66} & \textbf{22.00±0.46} & \textbf{35.60±0.56} & \textbf{53.10±0.80} & \textbf{31.79±0.51} & \textbf{45.69±0.68}  \\ 
 \hline
\multirow{6}*{5}  & Fine-tuning~\cite{bscd-fsl} & \textbf{90.64±0.54} & 81.76±0.48 &  \textbf{49.68±0.36} & \textbf{26.09±0.96} & \textbf{47.40±0.36} & 66.47±0.41 & 38.91±0.38 &  58.75±0.36   \\ 
% \cline{2-10}
  & MatchingNet~\cite{miniimagenet} & 66.39±0.78 & 64.45±0.63 & 36.74±0.53 & 22.40±0.70 & 46.53±0.68 & 63.16±0.77 & 38.99±0.64 & 51.37±0.77   \\ 
% \cline{2-10}
  &  MAML~\cite{al21} & 78.05±0.68 & 71.70±0.72 & 40.13±0.58 & 23.48±0.96 & - & - & - & 47.20±1.10   \\ 
% \cline{2-10}
  &  RelationNet~\cite{relation} & 68.99±0.75 & 61.31±0.72 & 39.41±0.58 & 22.96±0.88 & 44.00±0.60 & 63.32±0.76 & 37.33±0.68 & 57.77±0.69  \\ 
% \cline{2-10}
  &  ProtoNet~\cite{proto} &  79.72±0.67 & 73.29±0.71 & 39.57±0.57 & 24.05±1.01 & - & - & - & \textbf{67.00±1.00}    \\ 
% \cline{2-10}
  &  GNN~\cite{gnn} & 87.96±0.67 & \textbf{83.64±0.77} & 43.94±0.67 & 25.27±0.46 & 52.53±0.59 & \textbf{70.84±0.65} & \textbf{44.28±0.63} & 62.25±0.65    \\ 
 \hline
\multirow{5}*{20}  & Fine-tuning~\cite{bscd-fsl} & \textbf{95.91±0.72} & \textbf{87.97±0.42} & \textbf{61.09±0.44} & \textbf{31.01±0.59} & - & - & - & - \\ 
% \cline{2-10}
  & MatchingNet~\cite{miniimagenet} & 76.38±0.67 & 77.10±0.57 &  45.72±0.53 & 23.61±0.86 & - & - & - & -  \\ 
% \cline{2-10}
  &  MAML~\cite{al21} & 89.75±0.42 & 81.95±0.55 & 52.36±0.57 & 27.53±0.43 & - & - & - & -    \\ 
% \cline{2-10}
  &  RelationNet~\cite{relation} & 80.45±0.64 & 74.43±0.66 & 41.77±0.49 &  26.63±0.92 & - & - & - & -  \\ 
% \cline{2-10}
  &  ProtoNet~\cite{proto}  &  88.15±0.51 & 82.27±0.57 & 49.50±0.55 & 28.21±1.15 & - & - & - & -    \\ 
% \cline{2-10}
%  &  GNN  & - & - & - & - & - & - & - & -  \\ 
 \hline
\multirow{4}*{50}  & Fine-tuning~\cite{bscd-fsl} & \textbf{97.48±0.56} & \textbf{92.00±0.56} & \textbf{67.20±0.59} & \textbf{36.79±0.53} & - & - & - & -  \\ 
% \cline{2-10}
  & MatchingNet~\cite{miniimagenet} & 58.53±0.73 & 54.44±0.67 &  54.58±0.65 & 22.12±0.88 & - & - & - & -   \\ 
% \cline{2-10}
%  &  MAML & - & - & - & - & - & - & - & -    \\ 
% \cline{2-10}
  &  RelationNet~\cite{relation} & 85.08±0.53 & 74.91±0.58 & 49.32±0.51 & 28.45±1.20 & - & - & - & -   \\ 
% \cline{2-10}
  &  ProtoNet~\cite{proto} & 90.81±0.43 & 80.48±0.57 & 51.99±0.52 & 29.32±1.12 & - & - & - & -    \\
% \cline{2-10}
%  &  GNN & - & - & - & - & - & - & - & -  \\ 
 \hline
\end{tabular}}
\vspace{-0.3cm}
\label{fsl_mtd}
\end{table}

Due to varying requirements (\eg, datasets, backbones) and configurations (\eg, training sets, modules) of current CDFSL methods, unified and fair comparisons are challenging. Table~\ref{repre_mtd} summarizes key details and performance of representative methods on FGCB and BSCD-FSL, highlighting the best (in blue and red) and sub-optimal (in light blue and light red) results for \textit{5-way 1-shot} and \textit{5-way 5-shot}. On BSCD-FSL, hybrid methods excel in near-domain scenarios, while $\Delta$-Adaptation methods perform best in distant-domain settings. $\mathcal{D}$-Extension methods show sub-optimal performance on BSCD-FSL but achieve the best results on FGCB, benefiting from information augmentation in fine-grained migration.

An emerging approach in CDFSL integrates plug-and-play modules into existing FSL paradigms like MatchingNet, RelationNet, and GNN. Figures~\ref{module-comp1} and~\ref{module-comp2} show five key findings: (1) GNN outperforms MatchingNet and RelationNet, excelling in CDFSL tasks; (2) performance drops as the domain distance increases (e.g., from CropDiseases to ChestX); (3) increasing samples (\textit{1-shot} to \textit{5-shot}) does not significantly improve distant-domain tasks; (4) Wave-SAN excels in near-domain tasks but shows diminishing returns with more data; and (5) MemREIN achieves the best results on fine-grained cross-domain datasets.


\begin{sidewaystable}%[ph!]
  \tiny
 \vspace{5.45in}
 \begin{center}
     \caption{The CDFSL performance of the proposed methods on BSCD-FSL and FGCB benchmarks. $K$ means \textit{5}-way \textit{K}-shot.}
     \vspace{-0.3cm}
% \centering
\setlength{\tabcolsep}{0.5mm}{
\begin{tabular} {c|lcccccccccccc|m{4cm}}
\Xhline{1.2pt}
\textbf{Type} & \textbf{Methods} & \textbf{Venue} & \textbf{Train set} & \textbf{Backbone} & \textbf{$K$} & \textbf{CropDiseases} & \textbf{EuroSAT} & \textbf{ISIC} & \textbf{ChestX} & \textbf{Plantae} & \textbf{Places} & \textbf{Cars} & \textbf{CUB} & \textbf{Highlight}  \\ 
\Xhline{1.2pt}
\multirow{14}*{\rotatebox{90}{$\mathcal{D}$-Extension}} & \multirow{3}*{NSAE~\cite{boosting}} & \multirow{3}*{ICCV} & \multirow{3}*{\textit{mini}ImageNet} & \multirow{3}*{ResNet10} & 5 &  93.31±0.42 & 84.33±0.55 & \color{red!50}{\textbf{55.27±0.62}} & 27.30±0.42 & 62.15±0.77 & 73.17±0.72 & 58.30±0.75 & 71.92±0.77 & \multirow{3}{4.1cm}{The latent noise information from the source domain is utilized to capture broader variations of the feature distributions.}
\\
& & &  &  & 20 &  98.33±0.18 &  92.34±0.35 & 67.28±0.61 & 35.70±0.47 & 77.40±0.65 & 82.50±0.59 & 82.32±0.50 & 88.09±0.48 &    \\
% \cline{6-14}
& & & &  & 50 &  99.29±0.14 & 95.00±0.26 & 72.90±0.55 & 38.52±0.71 & 83.63±0.60 & 85.92±0.56 & - & 91.00±0.79 &   \\
\cline{2-15}
& \multirow{2}*{RDC~\cite{feature_reweight_6}} & \multirow{2}*{CVPR} & \multirow{2}*{\textit{mini}ImageNet} & \multirow{2}*{ResNet10} & 1 & \color{blue!50}{\textbf{86.33±0.50}} & 71.57±0.50 & 35.84±0.40 & 22.27±0.20 & 44.33±0.60 & \color{blue!50}{\textbf{61.50±0.60}} & 39.13±0.50 & 51.20±0.50 & \multirow{2}{4.1cm}{Minimising task-irrelevant features by constructing subspace} \\ 
% \cline{6-14}
&  &  &  &  & 5 & 93.55±0.30 & 84.67±0.30 & 49.06±0.30 & 25.48±0.20 & 60.63±0.40 & 74.65±0.40 & 53.75±0.50 & 67.77±0.40 &    \\
\cline{2-15}
& \multirow{2}*{StyleAdv~\cite{feature_reweight_0}} & \multirow{2}*{CVPR} & \multirow{2}*{\textit{mini}ImageNet} & \multirow{2}*{ResNet10} & 1 & 80.69±0.28 & 72.92±0.75 & 35.76±0.52 & 22.64±0.35 & 41.13±0.67 & 58.58±0.83 & 35.09±0.55 & 48.49±0.72 & \multirow{2}{4.1cm}{A meta Style Adversarial training method and a style adversarial attack method} \\ 
% \cline{6-14}
&  &  &  &  & 5 & \color{red!50}{\textbf{96.51±0.28}} & \color{red!50}{\textbf{91.64±0.43}} & 53.05±0.54 & 26.24±0.35 & 64.10±0.64 & 79.35±0.61 & 56.44±0.68 & 70.90±0.63 &    \\
\cline{2-15}
& \multirow{2}*{ISSNet~\cite{data_multi_3}} & \multirow{2}*{ICIP} & \multirow{2}*{\makecell[c]{\textit{mini}ImageNet \\ other 7 datasets}} & \multirow{2}*{ResNet10} & 1 & 73.40±0.86 & 64.50±0.88 & 36.06±0.69 & 23.23±0.42 & - & - & - & - & \multirow{2}{4.1cm}{Transferring styles across multiple sources to broaden the distribution of labeled sources} \\
% \cline{6-14}
&  &  &  &  & 5 & 94.10±0.41 & 83.64±0.55 & 51.82±0.67 &  \color{red!50}{\textbf{28.79±0.48}} &  -  & - & - & - &   \\
\cline{2-15}
& \multirow{2}*{STARTUP~\cite{st}} & \multirow{2}*{ICLR} & \multirow{2}*{\makecell[c]{\textit{mini}ImageNet \\ target data}} & \multirow{2}*{ResNet10} & 1 & 75.93±0.80 & 63.88±0.84 & 32.66±0.60 & 23.09±0.43 & - & - & - & - & \multirow{2}{4.1cm}{Self-training a source representation using unlabeled data from the target domain}  \\ 
% \cline{6-14}
&  &  &  &  & 5 & 93.02±0.45 &  82.29±0.60 & 47.22±0.61 & 26.94±0.44 & - & - & - & - &   \\
\cline{2-15}
& \multirow{2}*{TGDM~\cite{tgdm}} & \multirow{2}*{ACM MM} & \multirow{2}*{\textit{mini}ImageNet} & \multirow{2}*{ResNet10} & 1 & - & - & - & - & \color{blue!50}{\textbf{52.39±0.25}} & \color{blue}{\textbf{61.88±0.26}} & 50.70±0.24 & \color{blue!50}{\textbf{64.80±0.26}} & \multirow{2}{4.1cm}{A method generates an intermediate domain generation to facilitate the FSL task}  \\
% \cline{6-14}
&  &  &  &  & 5 & - & - & - & - & 71.78±0.22 & \color{red}{\textbf{81.62±0.19}} & 70.99±0.21 & \color{red}{\textbf{84.21±0.18}} &   \\
\cline{2-15}
& HVM~\cite{parameter_weight_2} & ICLR & \makecell[c]{\textit{mini}ImageNet} & ResNet10 & 5 & 87.65±0.35 & 74.88±0.45 & 42.05±0.34 & 27.15±0.45 & - & - & - & - & Introducing a hierarchical prototype model and an alternative method to solve domain gaps by using features at different semantic levels  \\
\Xhline{1.2pt}



\multirow{11}*{\rotatebox{90}{$\mathcal{H}$-Constraint}} & \multirow{3}*{SB-MTL~\cite{parameter_fix_1}} & \multirow{3}*{arXiv} & \multirow{3}*{\textit{mini}ImageNet} & \multirow{3}*{ResNet10} & 5 & 96.01±0.40 & 87.30±0.68 &  53.50±0.79 &  28.08±0.50 & - & - & - & - & \multirow{3}{4.1cm}{Leveraging a first-order MAML algorithm to identify optimal initializations and employing a score-based GNN for prediction}    \\
% \cline{6-14}
& &  &  &  & 20 &  99.61±0.09 &  96.53±0.28 & 70.31±0.72 & 37.70±0.57 & - & - & - & - &  \\
% \cline{6-14}
& &  &  &  & 50 & 99.85±0.06 & 98.37±0.18 & 78.41±0.66 & 43.04±0.66 & - & - & - & - &   \\
 \cline{2-15}
& \multirow{2}*{ReFine~\cite{parameter_weight_1}} & \multirow{2}*{ICMLW} & \multirow{2}*{\textit{mini}ImageNet} & \multirow{2}*{ResNet10} & 1 & 68.93±0.84 & 64.14±0.82 & 35.30±0.59 & 22.48±0.41 & - & - & - & - & \multirow{2}{4.1cm}{Randomizing the fitted parameters from the source domain before adapting to target data}  \\ 
% \cline{6-14}
&  &  &  &  & 5 & 90.75±0.49 & 82.36±0.57 & 51.68±0.63 & 26.76±0.42 & - & - & - & - &   \\
\cline{2-15}
& \multirow{2}*{ME-D2N~\cite{data_target}} & \multirow{2}*{ACM MM} & \multirow{2}*{\textit{mini}ImageNet} & \multirow{2}*{ResNet10} & 1 & - & - & - & - & \color{blue}{\textbf{52.89±0.83}} & 60.36±0.86 & 49.53±0.79 & \color{blue}{\textbf{65.05±0.83}} & \multirow{2}{4.1cm}{AME-D2N utilizes a multi-expert learning approach to create a model}  \\ 
&  &  &  &  & 5 & - & - & - & - & \color{red}{\textbf{72.87±0.67}} & \color{red!50}{\textbf{80.45±0.62}} & 69.17±0.68 & \color{red!50}{\textbf{83.17±0.56}} &   \\
\cline{2-15}
 & \multirow{2}*{MC-TS~\cite{wang2024cross}} & \multirow{2}*{EngA} & \multirow{2}*{\textit{mini}ImageNet} & \multirow{2}*{ResNet10} & 1 & 74.36±0.88 &  63.21±0.88 & 33.87±0.59 & \color{blue!50}{\textbf{23.61±0.42}} & - & - & - & - & \multirow{2}{4.1cm}{Match the large and small image crops, which are predicted by teacher and student network} \\
&  &  &  &  & 5 & 92.20±0.54 & 81.52±0.60 & 47.68±0.62 & 27.06±0.37& - &  - & - & - &    \\
\cline{2-15}
&  \multirow{2}*{LRP~\cite{feature_reweight_1}} & \multirow{2}*{ICPR} & \multirow{2}*{\textit{mini}ImageNet} & \multirow{2}*{ResNet10} & 1 & - & - & - & - & 34.80±0.37 &  50.59±0.46 & 29.65±0.33 & 42.44±0.41 & \multirow{2}{4.1cm}{A training strategy guided by explanations is developed to identify important features} \\  
% \cline{6-14}
& &  &  &  & 5 & - & - & - & - & 48.09±0.35 & 66.90±0.40 & 39.19±0.38 & 59.30±0.40 & \\
% \cline{5-13}
\Xhline{1.2pt} % \hline



\multirow{20}*{\rotatebox{90}{$\Delta$-Adaptation}} 
&  \multirow{3}*{DARA~\cite{zhao2023dual}} & \multirow{3}*{TPAMI} & \multirow{3}*{\textit{mini}ImageNet} & \multirow{3}*{ResNet10} & 1 &  81.50±0.66 &  69.39±0.84 & \color{blue!50}{\textbf{38.49±0.66}} &  22.93±0.40 & 51.25±0.58 & 42.08±0.55 & \color{blue!50}{\textbf{52.70±0.83}} & 35.25±0.57 & \multirow{3}{4.1cm}{Focus on the fast adaptation capability of meta-learners by proposing an effective dual adaptive representation alignment approach} \\ 
% \cline{6-14}
&  &  &  &  & 5  &  96.23±0.34 & 87.67±0.54 & \color{red}{\textbf{57.54±0.68}} & 28.78±0.45 & \color{red!50}{\textbf{72.15±0.43}} & 65.40±1.95 & \color{red}{\textbf{77.51±0.65}} & 58.44±2.39 &   \\
% \cline{6-14}
&  &  &  &  & 20 &  99.21±0.11 & 94.40±0.27 & 68.43±0.54 & 36.20±0.43 & 83.12±0.54 & 79.54±0.64 & 89.60±0.43 & 81.38±0.59 &    \\
\cline{2-15}
&  \multirow{4}*{VDB~\cite{parameter_fix_6}} & \multirow{4}*{CVPRW} & \multirow{4}*{\textit{mini}ImageNet} & \multirow{4}*{ResNet10} & 1 &  71.98±0.82 &  63.60±0.87 & 35.32±0.65 &  22.99±0.44 & - & - & - & - & \multirow{4}{4.1cm}{Propose a source-free approach through ``Visual Domain Bridge'' concept to mitigate internal mismatches in BatchNorm during cross-domain settings} \\ 
% \cline{6-14}
&  &  &  &  & 5  &  90.77±0.49 & 82.06±0.63 & 48.72±0.65 & 26.62±0.45 &   & - & - & - &   \\
% \cline{6-14}
&  &  &  &  & 20 &  96.36±0.27 & 89.42±0.45 & 59.09±0.59 & 31.87±0.44 & - & - & - & - &    \\
% \cline{6-14}
&  &  &  &  & 50 & 97.89±0.19 & 92.24±0.35 & 64.02±0.58 & 35.55±0.45 & - & - & - & - &    \\
 \cline{2-15}
 & \multirow{2}*{MAP~\cite{parameter_select_2}} & \multirow{2}*{arXiv} & \multirow{2}*{\textit{mini}ImageNet} & \multirow{2}*{ResNet10} & 5 & 90.29±1.56 & 82.76±2.00 &  47.85±1.95 &  24.79±1.22 & 58.45±1.15 & 75.94±0.97 & 51.64±1.16 & 67.92±1.10 & \multirow{2}{4.1cm}{Selectively performs SOTA adaptation methods in sequence with modular adaptation method} \\  
 &  &  &  &  & 20 & 95.22±1.13 & 88.11±1.78 &  60.16±2.70 & 30.21±1.78 & - & - & - & - &   \\
 \cline{2-15}
& \multirow{3}*{TACDFSL~\cite{feature_reweight_4}} & \multirow{3}*{Symmetry} & \multirow{3}*{\textit{mini}ImageNet} & \multirow{3}*{WideResNet} & 5 & 93.42±0.55 & 85.19±0.67 & 45.39±0.67 & 25.32±0.48 & - & - & - & - & \multirow{3}{4.1cm}{Introducing the empirical marginal distribution measurement}  \\
% \cline{6-14}
&  &  &  &  & 20 & 95.49±0.39 & 87.87±0.49 & 53.15±0.59 & 29.17±0.52 & - & - & - & - &   \\
% \cline{6-14}
 &  &  &  &  & 50 & 95.88±0.35 & 89.07±0.43 &  56.68±0.58 & 31.75±0.51 & - & - & - & - &   \\
% \cline{5-13}
\cline{2-15}
& \multirow{2}*{IM-DCL~\cite{xu2024enhancing}} & \multirow{2}*{TIP} & \multirow{2}*{\makecell[c]{\textit{mini}ImageNet}} & \multirow{2}*{ResNet10} & 1 & 84.37±0.99 & \color{blue!50}{\textbf{77.14±0.71}} & 38.13±0.57 & \color{blue}{\textbf{23.98±0.79}} & - & - & - & - & \multirow{2}{4.1cm}{Enhancing information maximization with a distance-aware contrastive learning}  \\
% \cline{6-14}
&  &  &  &  & 5 & 95.73±0.38 & 89.47±0.42 & 52.74±0.69 & \color{red}{\textbf{28.93±0.41}} & - & - & - & - &   \\
\cline{2-15}
& \multirow{3}*{Confess~\cite{confess}} & \multirow{3}*{ICLR} & \multirow{3}*{\textit{mini}ImageNet} & \multirow{3}*{ResNet10} & 5 & 88.88±0.51 & 84.65±0.38 & 48.85±0.29 & 27.09±0.24 & - & - & - & - & \multirow{3}{4.1cm}{Investigating a contrastive learning and feature selection system to address domain gaps between base and novel categories} \\
% \cline{6-14}
&  &  &  &  & 20 & 95.34±0.48 & 90.40±0.24 & 60.10±0.33 & 33.57±0.31 & - & - & - & - &   \\
% \cline{6-14}
 &  &  &  &  & 50 & 97.56±0.43 & 92.66±0.36 & 65.34±0.45 & 39.02±0.12 & - & - & - & - &    \\
% \cline{4-9}
\cline{2-15}
& BL-ES~\cite{feature_reweight_2} & ICME & \makecell[c]{\textit{mini}ImageNet}  & ResNet18 & 5 & - & 79.78±0.83 & - & - & - & - & 50.07±0.84 & 69.63±0.88 & Proposing a bi-level episode strategy to train an inductive graph network  \\
\cline{2-15}
& \multirow{2}*{DSL~\cite{data_target_1}} & \multirow{2}*{ICLR} & \multirow{2}*{\makecell[c]{\textit{mini}ImageNet}} & \multirow{2}*{ResNet10} & 1 & - & - & - & - & 41.17±0.80 & 53.16±0.88 & 37.13±0.69 & 50.15±0.80 & \multirow{2}{4.1cm}{Incorporating the cross-domain scenario into the training stage by rapidly switching targets}  \\
% \cline{6-14}
&  &  &  &  & 5 & - & - & - & - & 62.10±0.75 & 74.10±0.72 & 58.53±0.73 & 73.57±0.65 &   \\
\Xhline{1.2pt} % \hline



\multirow{14}*{\rotatebox{90}{Hybrid}} & \multirow{2}*{FDMixup~\cite{hybrid_1}} & \multirow{2}*{ACM MM} & \multirow{2}*{\textit{mini}ImageNet} & \multirow{2}*{ResNet10} & 1 & 66.23±1.03 & 62.97±1.01 & 32.48±0.64 & 22.26±0.45 & 37.89±0.58 & 53.57±0.75 & 31.14±0.51 & 46.38±0.68 & \multirow{2}{4.1cm}{Utilizing few labeled target data to guide the model learning} \\ 
% \cline{6-14}
&  &  &  &  & 5 & 87.27±0.69 & 80.48±0.79 & 44.28±0.66 & 24.52±0.44 & 54.62±0.66 & 73.42±0.65 & 41.30±0.58 & 64.71±0.68 &    \\
\cline{2-15}
 & \multirow{2}*{TL-SS~\cite{hybrid_3}} & \multirow{2}*{AAAI} & \multirow{2}*{\textit{mini}ImageNet} & \multirow{2}*{ResNet10} & 1 & - &  65.73 & - & - & - & 55.83 & 33.22 & 45.92 & \multirow{2}{4.1cm}{Introducing a domain-irrelevant self-supervised learning method} \\
% \cline{6-14}
&  &  &  &  & 5 & - & 79.36 & - & - & - &  76.33 & 49.82 & 69.16 &    \\
\cline{2-15}
& \multirow{2}*{FGNN~\cite{parameter_fix_7}} & \multirow{2}*{KBS} & \multirow{2}*{\textit{mini}ImageNet} & \multirow{2}*{ResNet10} & 1 & - & - & -  & - & 41.44±0.69 & 56.74±0.82 & 34.37±0.60 & 52.97±0.75 & \multirow{2}{4.1cm}{Investigating instance normalization and the restitution module to enhance performance} \\  
% \cline{6-14}
&  &  &  &  & 5 & - & - & - & - & 60.81±0.66 & 76.12±0.63 & 50.19±0.69 & 71.99±0.64 &   \\
\cline{2-15}
% &  &  &  & 20 &  &  &  &  &    &&&   \\
% \cline{5-13}
% &  &  &  & 50 &  &  &  &  &     &&&   \\
& \multirow{2}*{DDA~\cite{dynamic}} & \multirow{2}*{NIPS} & \multirow{2}*{\makecell[c]{\textit{mini}ImageNet \\ target data}} & \multirow{2}*{ResNet10} & 1 & 82.14±0.78 & 73.14±0.84 & 34.66±0.58 & 23.38±0.43 & - & - & - & - & \multirow{2}{4.1cm}{Propose a dynamic distillation-based approach to enhance utilize unlabeled target data} \\
% \cline{6-14}
&  &  &  &  & 5 & 95.54±0.38 & 89.07±0.47 & 49.36±0.59 & 28.31±0.46 & - & - & - & - &    \\
\cline{2-15}
& \multirow{2}*{CLDFD~\cite{cdfsl231}} & \multirow{2}*{ICLR} & \multirow{2}*{\textit{mini}ImageNet} & \multirow{2}*{ResNet10} & 1 &  \color{blue}{\textbf{90.48±0.72}} & \color{blue}{\textbf{82.52±0.76}} & \color{blue}{\textbf{39.70±0.69}} & 22.39±0.44 & - & - & - & - & \multirow{2}{4.1cm}{A cross-level knowledge distillation method and feature denoising operation}  \\ 
&  &  &  &  & 5 & \color{red}{\textbf{96.58±0.39}} & \color{red}{\textbf{92.89±0.34}} &  52.29±0.62 & 25.98±0.43 & - & - & - & - &   \\
\cline{2-15}
 & \multirow{2}*{ProD~\cite{ma2023prod}} & \multirow{2}*{CVPR} & \multirow{2}*{\makecell[c]{\textit{mini}ImageNet}} & \multirow{2}*{ResNet10 \& ViT} & 1 & - & - & - & - & 42.86±0.59 & 53.92±0.72 & 38.02±0.63 & 53.97±0.71 & \multirow{2}{4.1cm}{Using the prompts to disentangle the domain-general and -specific knowledge} \\
% \cline{6-14}
&  &  &  &  & 5 & - & - & - & - & 65.82±0.65 & 75.00±0.72 & 59.49±0.68 & 79.19±0.59 &    \\
 \cline{2-15} 
 & \multirow{2}*{GMeta-FDMixup~\cite{hybrid_7}} & \multirow{2}*{TIP} & \multirow{2}*{\makecell[c]{\textit{mini}ImageNet \\ Labeled target data}} & \multirow{2}*{ResNet10} & 1 & - & - & - & - & 51.28±0.36 & 59.39±0.37 & \color{blue}{\textbf{53.10±0.35}} & 63.85±0.37 & \multirow{2}{4.1cm}{Utilize extra labeled target data and a Meta-FDMixup network to solve CDFSL} \\
% \cline{6-14}
&  &  &  &  & 5 & - & - & - & - & 69.45±0.30 & 78.80±0.28 & \color{red!50}{\textbf{71.80±0.30}} & 80.48±0.27 &    \\
\Xhline{1.2pt}
\end{tabular}}
\label{repre_mtd}
 \end{center}
 \end{sidewaystable}

\vspace{-0.2cm}
\subsubsection{Evaluation for $\mathcal{D}$-Extension Approaches}
Table~\ref{repre_mtd} highlights a noticeable trend where performance decreases as the distance between the target and source domains increases. For instance, the results of \cite{boosting} show a drop from 93.31\% on CropDiseases to 27.30\% on ChestX (\textit{5-way 5-shot}). The sub-optimal performances of \cite{feature_reweight_6} and \cite{feature_reweight_0} on CropDiseases (96.51\% for \cite{feature_reweight_0} on \textit{5-way 5-shot}) and EuroSAT (91.54\% for \cite{feature_reweight_0} on \textit{5-way 5-shot}) reveal that specific guidance in information extension can further improve performance in near-domain scenarios. Additionally, the optimal results on FGCB for \cite{tgdm} also indicate the positive effect of information augmentation on CDFSL. Furthermore, the results of \cite{st} on BSCD-FSL demonstrate that incorporating target domain data into the training process can improve performance in the target domain. However, this approach works better for near-domain transfer than for distant-domain transfer. For example, \cite{st} showed a 2.38\% improvement on CropDiseases and a 0.53\% improvement on EuroSAT, but a 2.46\% drop on ISIC and only a 0.85\% improvement on ChestX when compared to the classic fine-tuning method.

$\mathcal{D}$-Extension approaches for CDFSL are relatively simple in concept as they rely on adding supplementary information to enhance the model's generalization. However, their effectiveness is highly dependent on the choice of information used in the training process. If the additional information included in training greatly diverge from the target domain or the selected target domain samples are not representative, this fails to improve CDFSL performance.
\begin{figure}
	\centering
 \vspace{-0.3cm}
 \includegraphics[width=\linewidth]{response/fig12.pdf}
 \vspace{-0.6cm}
	\caption{\textcolor{black}{We group by different FSL paradigms, \ie, MatchingNet, RelationNet, and GNN. The performance of different methods on the BSCD-FSL benchmark is presented in (a) \textit{5-way 1-shot} and (b) \textit{5-way 5-shot} tasks. All methods use ResNet10 as the backbone. `CropD' refers to the dataset `CropDiseases'.}} 
 \vspace{-0.4cm}
	\label{module-comp1}
\end{figure}

\begin{figure}
	\centering
 \vspace{-0.3cm}
        \includegraphics[width=\linewidth]{response/fig13.pdf}
 \vspace{-0.5cm}
	\caption{\textcolor{black}{The performance of various approaches on the FGCB benchmark is presented in (a) \textit{5-way 1-shot} and (b) \textit{5-way 5-shot} tasks. All methods use ResNet10 as the backbone. `CropD' refers to the dataset `CropDiseases.'}}
 \vspace{-0.4cm}
	\label{module-comp2}
\end{figure}

\vspace{-0.2cm}
\subsubsection{Evaluation for $\mathcal{H}$-Constraint Approaches}
From the data presented in Table~\ref{repre_mtd}, it appears that the performance of $\mathcal{H}$-Constraint methods is generally subpar in comparison to the other two method types on BSCD-FSL. Using ResNet10 as the backbone, the results of ~\cite{parameter_fix_1} on BSCD-FSL (\textit{5-way 5-shot}) demonstrate this trend, with scores of 96.01\% (CropDiseases), 87.30\% (EuroSAT), 53.50\% (ISIC), and 28.08\% (ChestX). The results of other methods within this category are even lower. However,~\cite{wang2024cross} achieves sub-optimal results of 23.61\% on ChestX in the 5-way 1-shot task. Moreover,~\cite{data_target} performs best on FGCB, achieving optimal results of 52.89\% (Plantae), 65.05\% (CUB) in the 5-way 1-shot task, and 72.87\% (Plantae) in the 5-way 5-shot task. These findings demonstrate the potential of knowledge distillation in distant-domain scenarios.

Our analysis of Table~\ref{repre_mtd} shows that $\mathcal{H}$-Constraint methods generally underperform compared to other categories, likely due to their reliance on locally adjusting network parameters with limited additional parameters, which restricts adaptation to new domains~\cite{paszke2019pytorch}. While knowledge distillation methods achieve competitive results, $\mathcal{H}$-Constraint methods face challenges in solving the two-stage empirical risk minimization problem. Further exploration of knowledge distillation techniques is needed to enhance the performance of $\mathcal{H}$-Constraint methods in CDFSL.

\vspace{-0.2cm}
\subsubsection{Evaluation for $\Delta$-Adaptation Approaches}
The performance of recent $\Delta$-Adaptation approaches has a significant advantage on distant-domain tasks compared to other methods. This can be exemplified by comparing two representative approaches: \cite{zhao2023dual} achieved sub-optimal performance on ISIC in the 5-way 1-shot task (38.49\%) and optimal performance in the 5-way 5-shot task (57.54\%). Meanwhile, \cite{xu2024enhancing} obtained the best results for ChestX in both the 1-shot (23.98\%) and 5-shot (28.93\%) tasks. In addition to BSCD-FSL, $\Delta$-Adaptation approaches also show overwhelming performance advantages in fine-grained migration scenarios. For instance,~\cite{zhao2023dual} achieved competitive results on Plantae (72.15\% in the 5-way 5-shot task) and Cars (77.51\% in the 5-way 5-shot task). These observations suggest that $\Delta$-Adaptation methods are more effective than other approaches in addressing distant-domain tasks. However, not all methods in the $\Delta$-Adaptation category perform better, indicating that the design and application of $\Delta$-Adaptation strategies have a significant impact on performance.
In summary, compared to other strategies, $\Delta$-Adaptation is the most effective for addressing distant-domain tasks. Furthermore, $\Delta$-Adaptation is also effective in handling few-shot tasks in fine-grained migration scenarios.

\vspace{-0.2cm}
\subsubsection{Evaluation for Hybrid Approaches}
Hybrid methods demonstrate optimal performance on near-domain tasks. For instance, \cite{cdfsl231} achieves the best results on CropDiseases (90.48\% in the 1-shot task and 96.58\% in the 5-shot task) and EuroSAT (82.52\% in the 1-shot task and 92.89\% in the 5-shot task). However, this advantage diminishes as the domain gap widens. It is important to recognize that combining strategies from different categories introduces a degree of risk, as negative interactions between strategies can occur \cite{azevedo2024hybrid}. Thus, when selecting hybrid strategies, researchers must carefully consider the compatibility of different methods, especially regarding the precision required for alignment. Ultimately, the choice of approach depends on the specific task, available data, and the level of generalization and flexibility required by the model.

\vspace{-0.2cm}
\subsubsection{Evaluation on Meta-Dataset}
The techniques tested on Meta-Dataset~\cite{meta-dataset} used non-episodic training, with results summarized in Table~\ref{meta_per}. In the single-source setup (ImageNet as the source domain), \cite{feature_select_2} achieved the best performance on five target datasets, while \cite{parameter_weight_4, hybrid_2, yang2024leveraging} excelled on the other five. Deeper backbones like ResNet34~\cite{parameter_weight_4} outperformed shallower ones like ResNet18. In the multiple-source setup (first eight datasets as source domains), \cite{wang2023mmt} achieved the highest performance on three datasets, benefiting from effective feature transformation and multi-source combination. However, comparisons for \cite{parameter_weight_4} showed that while multiple datasets improved performance on seen datasets, gains on unseen datasets were modest, highlighting that adding domains without careful consideration may limit improvements. Overall, CDFSL technologies significantly outperform traditional FSL methods, effectively addressing $FG$ and $Art$ CDFSL challenges.
\begin{table}
\tiny
\centering
\vspace{-0.3cm}
\caption{The CDFSL performance of approaches on Meta-Dataset. Gray background means the results on the seen data set (source data set).}
\vspace{-0.3cm}
\setlength{\tabcolsep}{0.15mm}{
\begin{tabular}{lccccccc|cccccc}
\hline
 & \multicolumn{7}{c|}{\textbf{Single source}} & \multicolumn{6}{c}{\textbf{Multiple sources}}    \\ 
\cline{2-14}
 & ProtoNet~\cite{proto} & Pro-M~\cite{meta-dataset} & SUR~\cite{feature_select_2} & \multicolumn{2}{c}{TPA~\cite{parameter_weight_4}} & tri-M~\cite{hybrid_2} & ProLAD~\cite{yang2024leveraging} & RMFS~\cite{feature_select_1} & TPA~\cite{parameter_weight_4} & URL~\cite{hybrid_4} & TSA~\cite{sreenivas2023similar} & TA2-Net~\cite{guo2023task} & MMT~\cite{wang2023mmt}   \\ 
\hline
Backbone & ResNet18 & ResNet18 & ResNet18 & ResNet18 & ResNet34 & ResNet18 & ResNet18 & ResNet18 & ResNet18 & ResNet18 & ResNet18 & ResNet18 & ResNet18    \\ 
\hline
ImageNet & \cellcolor{gray!40}{44.5$\pm$1.1} & \cellcolor{gray!40}{47.9$\pm$1.1} & \cellcolor{gray!40}{57.2$\pm$1.1} & \cellcolor{gray!40}{\textbf{59.5$\pm$1.1}} & \cellcolor{gray!40}{63.7$\pm$1.0} & \cellcolor{gray!40}{58.6$\pm$1.0} & \cellcolor{gray!40}{57.2$\pm$1.1} & \cellcolor{gray!40}{\textbf{63.1$\pm$0.8}} & \cellcolor{gray!40}{59.5$\pm$1.0} & \cellcolor{gray!40}{58.8$\pm$1.1} & \cellcolor{gray!40}{59.5$\pm$1.0} & \cellcolor{gray!40}{59.6$\pm$1.0} & \cellcolor{gray!40}{59.6$\pm$1.1}   \\ 
\cline{2-8}
Omniglot & 79.6$\pm$1.1 & 82.9$\pm$0.9 & \textbf{93.2$\pm$0.8} & 78.2$\pm$1.2 & 82.6$\pm$1.1 & 92.0$\pm$0.6 & 84.1$\pm$1.2 & \cellcolor{gray!40}{\textbf{97.7$\pm$0.5}} & \cellcolor{gray!40}{94.9$\pm$0.4} & \cellcolor{gray!40}{94.5$\pm$0.4} & \cellcolor{gray!40}{94.9$\pm$0.4} & \cellcolor{gray!40}{95.5$\pm$0.4} & \cellcolor{gray!40}{94.4$\pm$0.4}   \\ 

Aircraft & 71.1$\pm$0.9 & 74.2$\pm$0.8 & \textbf{90.1$\pm$0.8} & 72.2$\pm$1.0 & 80.1$\pm$1.0 & 82.8$\pm$0.7 & 76.1$\pm$1.2 & \cellcolor{gray!40}{65.1$\pm$0.3} & \cellcolor{gray!40}{89.9$\pm$0.4} & \cellcolor{gray!40}{89.4$\pm$0.4} & \cellcolor{gray!40}{89.9$\pm$0.4} & \cellcolor{gray!40}{90.5$\pm$0.4} & \cellcolor{gray!40}{\textbf{91.9$\pm$0.5}}   \\ 

Birds & 67.0$\pm$1.0 & 70.0$\pm$1.0 & \textbf{82.3$\pm$0.8} & 74.9$\pm$ 0.9 & 83.4$\pm$0.8 & 75.3$\pm$0.8 & 75.5$\pm$1.0 & \cellcolor{gray!40}{\textbf{84.1$\pm$0.6}} & \cellcolor{gray!40}{81.1$\pm$0.8} & \cellcolor{gray!40}{80.7$\pm$0.8} & \cellcolor{gray!40}{81.1$\pm$0.8} & \cellcolor{gray!40}{81.4$\pm$0.8} & \cellcolor{gray!40}{82.7$\pm$0.5}   \\ 

Textures & 65.2$\pm$0.8 & 67.9$\pm$0.8 & 73.5$\pm$0.7 & \textbf{77.3$\pm$0.7} & 79.6$\pm$0.7 & 71.2$\pm$0.8 & 77.7$\pm$0.8 & \cellcolor{gray!40}{67.5$\pm$0.9} & \cellcolor{gray!40}{77.5$\pm$0.7} & \cellcolor{gray!40}{77.2$\pm$0.7} & \cellcolor{gray!40}{77.5$\pm$0.7} & \cellcolor{gray!40}{77.4$\pm$0.7} & \cellcolor{gray!40}{\textbf{78.2$\pm$0.9}}   \\ 

Quick Draw & 65.9$\pm$0.9 & 66.6$\pm$0.9 & \textbf{81.9$\pm$1.0} & 67.6$\pm$0.9 & 71.0$\pm$0.8 & 77.3$\pm$0.7 & 70.6$\pm$0.1 & \cellcolor{gray!40}{\textbf{86.2$\pm$0.5}} & \cellcolor{gray!40}{81.7$\pm$0.6} & \cellcolor{gray!40}{82.5$\pm$0.6} & \cellcolor{gray!40}{81.7$\pm$0.6} & \cellcolor{gray!40}{82.5$\pm$0.6} & \cellcolor{gray!40}{83.1$\pm$0.2}   \\ 

Fungi & 40.3$\pm$1.1 & 42.0$\pm$1.1 & \textbf{67.9$\pm$0.9} & 44.7$\pm$1.0 & 51.4$\pm$1.2 & 48.5$\pm$1.0 & 46.8$\pm$1.2 & \cellcolor{gray!40}{62.5$\pm$0.6} & \cellcolor{gray!40}{66.3$\pm$0.8} & \cellcolor{gray!40}{\textbf{68.1$\pm$0.9}} & \cellcolor{gray!40}{66.3$\pm$0.8} & \cellcolor{gray!40}{66.3$\pm$0.9} & \cellcolor{gray!40}{66.2$\pm$0.6}   \\ 

VGG Flower & 86.9$\pm$0.7 & 88.5$\pm$1.0 & 88.4$\pm$0.9 & 90.9$\pm$0.6 & 94.0$\pm$0.5 & 90.5$\pm$0.5 & \textbf{92.9$\pm$0.6} & \cellcolor{gray!40}{86.3$\pm$0.3} & \cellcolor{gray!40}{92.2$\pm$0.5} & \cellcolor{gray!40}{92.0$\pm$0.5} & \cellcolor{gray!40}{92.2$\pm$0.5} & \cellcolor{gray!40}{\textbf{92.6$\pm$0.4}} & \cellcolor{gray!40}{90.7$\pm$0.4}   \\ 
\cline{9-14}
Traffic Sign & 46.5$\pm$1.0 & 34.2$\pm$1.3 & 67.4$\pm$0.8 & 82.5$\pm$0.8 & 81.7$\pm$0.9 & 78.0$\pm$0.6 & \textbf{89.4$\pm$0.9} & 73.7$\pm$0.4 & 82.8$\pm$1.0 & 63.3$\pm$1.2 & 82.8$\pm$1.0 & \textbf{87.4$\pm$0.8} & 85.1$\pm$0.2   \\ 

MSCOCO & 39.9$\pm$1.1 & 24.1$\pm$1.1 & 51.3$\pm$1.0 & \textbf{59.0$\pm$1.0} & 61.7$\pm$0.9 & 52.8$\pm$1.1 & 55.4$\pm$1.1 & 56.2$\pm$0.7 & 57.6$\pm$1.0 & 57.3$\pm$1.0 & 57.6$\pm$1.0 & 57.9$\pm$0.9 & \textbf{58.9$\pm$0.5}   \\ 

MNIST & - & - & 90.8$\pm$0.5 & 93.9$\pm$0.6 & 94.6$\pm$0.5 & \textbf{96.2$\pm$0.3} & 95.8$\pm$0.5 & - & 96.7$\pm$0.4 & 94.7$\pm$0.4 & 96.7$\pm$0.4 & 97.0$\pm$0.4 & \textbf{97.3$\pm$0.3}   \\ 

CIFAR 10 & - & - & 66.6$\pm$0.8 & \textbf{82.1$\pm$0.7} & 86.0$\pm$0.6 & 75.4$\pm$0.8 & 79.7$\pm$0.8 & - & \textbf{82.9$\pm$0.7} & 74.2$\pm$0.8 & 82.9$\pm$0.7 & 82.1$\pm$0.8 & 82.0$\pm$0.6   \\ 

CIFAR 100 & - & - & 58.3$\pm$1.0 & \textbf{70.7$\pm$0.9} & 78.3$\pm$0.8 & 62.0$\pm$1.0 & 70.3$\pm$1.0 & - & 70.4$\pm$0.9 & 63.6$\pm$1.0 & 70.4$\pm$0.9 & 70.9$\pm$0.9 & \textbf{71.5$\pm$1.0}   \\ 
\hline
\end{tabular}}
\vspace{-0.3cm}
\label{meta_per}
\end{table}
