\section{Background} \label{background}
In this section, we introduce key concepts related to CDFSL in Section \ref{key}, followed by formal definitions of supervised learning, FSL, domain adaptation (DA), and CDFSL with examples in Section \ref{definition}. Section \ref{related} discusses the connections and differences between CDFSL and related problems. In Section \ref{unique}, we cover the challenges that make CDFSL difficult. Finally, Section \ref{taxonomy} presents a unified taxonomy based on how existing works address these challenges.

\subsection{\textcolor{black}{Key Concepts}} \label{key}
To formally define the CDFSL problem, we begin by considering two key concepts: \emph{domain} and \emph{task}~\cite{tfsurvey,tf_2020}. These terms are often used inconsistently in the community, but a clear distinction between them helps in studying different transfer learning subproblems. In this paper, we follow the definitions provided by Pan and Yang's surveys\cite{tfsurvey,tf_2020,tfsurvey_2020}.


\begin{MyDef}
\label{def:Domain}
\textbf{Domain.} Given a feature space $\mathcal{X}$ and a marginal probability distribution $P(X)$,  where each input instance $\emph{\textbf{x}}\in\mathcal{X}$, a domain $\mathcal{D}=\{\mathcal{X}, P(X)\}$ consists of $\mathcal{X}$ and $P(X)$.
\end{MyDef}


In practice, a domain is often observed by several labeled or unlabeled data samples $X=\{\emph{\textbf{x}}\}_{i=1}^{N}$, where $N$ indicates the number of instances. For instance, if our learning task is image classification, and each input image is represented as a feature vector $\textbf{\emph{x}}$, \eg, by a deep convolution neural network (DCNN), then $\mathcal{X}$ is the space underlying the extracted feature vector. In general,  two different domains can differ in the feature space or the marginal distribution.


\begin{MyDef}
\label{def:Task}
\textbf{Task.}  Given a domain $\mathcal{D} = \{\mathcal{X}, P(X)\}$, a task  is composed of two components: a label space $\mathcal{Y} $ and a decision  function $f(\cdot)$ mapping each input sample to its belonging label, and is denoted as $\mathcal{T}=\{\mathcal{Y},f(\cdot)\}$. 
\end{MyDef}


Specifically, the $\textbf{\emph{x}}$ and $y$ represent the input data and supervision target. For a classification task $\mathcal{T}$, all labels $\textit{Y}^{\mathcal{T}}=\{y^{\mathcal{T}}_{1}, y^{\mathcal{T}}_{2}, ..., y^{\mathcal{T}}_{m}\} \in \mathcal{Y}$ are in the label space $\mathcal{Y}$, and $f(\cdot)$ can be learned from the training data $\textit{D}$=$\{\textbf{\emph{x}}_{i}, y_{i}\}^{N}_{i=1}$, where $\textbf{\emph{x}}_{i} \in \textit{X}$ and $y_{i} \in \textit{Y}$. From a probabilistic viewpoint, $f(\cdot)$ can be illustrated as a conditional probability distribution \textit{P(Y|X)}.


Comparatively speaking, for a learning problem, the domain describes the feature space $\mathcal{X}$ and the marginal distribution $P(X)$, while the task describes the output space $\mathcal{Y}$ and the conditional distribution $P(Y|X)$.


\subsection{\textcolor{black}{Problem Definition}} \label{definition}
In this subsection, we begin by defining vanilla supervised learning, followed by the definitions of FSL and domain adaptation (DA). We then introduce the definition of CDFSL, considering it a subproblem of both FSL and DA.


\vspace{-0.5cm}
\textcolor{black}{
\begin{MyDef}
\label{def:SupLearn}
\textbf{Vanilla Supervised Learning~\cite{erm1,erm2}.} Given a domain $\mathcal{D}$, consider a supervised learning task $\mathcal{T}$, a training set $\textit{D}^{train}$, and a test set $\textit{D}^{test}$. The goal of vanilla supervised learning is to learn a function $f(\cdot)$ for $\mathcal{T}$ on $\textit{D}^{train}$, such that $f(\cdot)$ performs well on $\textit{D}^{test}$, where $\{\textit{D}^{train}, \textit{D}^{test}\} \subseteq \mathcal{D}$.
\end{MyDef}
}

For example, an image classification task involves categorizing test set images $\textit{D}^{test}$ into classes using a model trained on $\textit{D}^{train}$. In classic classification, $\textit{D}^{train}$ has sufficient samples per class, like ImageNet~\cite{imagenet1} with 1000 classes and over 1000 samples per class. Note that $\textit{D}$ refers to the dataset, not the domain $\mathcal{D}$. Figure \ref{dtfc} (a) illustrates a standard supervised classification problem.
\begin{figure}[t]
	\centering
	 \vspace{-0.3cm}
        \includegraphics[width=\linewidth]{response/crop_setcompare.pdf}
  \vspace{-0.5cm}
	\caption{(a) the standard classification, (b) few-shot classification, (c) unsupervised domain adaptation, and (d) cross-domain few-shot classification. The different shapes represent different categories. $\mathcal{D}$ means domain, $\mathcal{D}^{s}$ and $\mathcal{D}^{t}$ specifically represent the source and target domains, respectively. Green and blue illustrate the source and target data. Gray represents the unlabeled test data, and `?' indicates predicting the test data. Dotted arrows indicate the adaptation process.}
 \vspace{-0.5cm}
	\label{dtfc}
\end{figure}


Like in vanilla supervised learning, the goal of FSL~\cite{fslsurvey} is to learn a model from the training set $\textit{D}^{train}$ for testing new samples. However, the key difference is that $\textit{D}^{train}$ in FSL contains very limited supervised data, making it challenging. Due to the few samples, many standard algorithms fail, often due to overfitting. To address this, prior knowledge is introduced from an auxiliary task $\mathcal{T}^{s}$ (source task). Typically, the label sets of source task $\mathcal{T}^{s}$ and target task $\mathcal{T}^{t}$ are disjoint ($\mathcal{Y}^{s} \cap \mathcal{Y}^{t}=\varnothing$). A formal definition of FSL is given below.

%\vspace{-0.2cm}
\begin{MyDef}
\label{def:FSL}
\textbf{Few Shot Learning (FSL)}~\cite{tfsurvey,fslsurvey}. Given a domain $\mathcal{D}$, a task $\mathcal{T}^{t}$ described by a \textit{T}-specific data set $\textit{D}^{t}$ with only a few supervised information available, and the task(s) $\mathcal{T}^{s}$ described by \textit{T}-irrelevant auxiliary data set(s) $\textit{D}^{s}$ with sufficient supervised information, FSL aims to learn a function $f(\cdot)$ for $\mathcal{T}^{t}$ by utilizing the limited supervised information in $\textit{D}^{t}$ and the prior knowledge in $(\mathcal{T}^{s}, \textit{D}^{s})$, where $\{\textit{D}^{s}, \textit{D}^{t}\} \subseteq \mathcal{D}$, $\textit{D}^{s} \cap \textit{D}^{t}=\varnothing$, and $\mathcal{T}^{s} \ne \mathcal{T}^{t}$.
\end{MyDef}

Specifically, take a few-shot classification task $\mathcal{T}^{t}$ as an example, we use the corresponding few-shot data pairs $\{(\textit{x}_{i}, \textit{y}_{i})\}^{N^{t}}_{i=1}$ to represent the input data and supervision target. In addition, $\mathcal{T}^{s}$ and $\{(\textit{x}_{i}, \textit{y}_{i})\}^{N^{s}}_{i=1}$ are utilized to indicate the conventional classification task and auxiliary data pairs, where $N^s \gg N^t$. $\mathcal{T}^{t}$ follows a \textit{C-way K-shot} training principle (\textit{C} indicates the number of classes, \textit{K} represents the sample numbers in each class). We learn a function $f$($\cdot$) for $\mathcal{T}^{t}$ from $\textit{D}^{t}$ and $(\mathcal{T}^{s}, \textit{D}^{s})$. Figure \ref{dtfc} (b) shows the few-shot classification (FSC) problem.

Beyond the FSL challenge, domain adaptation (DA)~\cite{dasurvey,dasurvey1,dasurvey2} is another key aspect of vanilla supervised learning. Like vanilla supervised learning, DA trains a model from $\textit{D}^{train}$. However, unlike vanilla supervised learning, the training and test sets in DA come from two different domains $\mathcal{D}^{s}$ and $\mathcal{D}^{t}$, \ie $\mathcal{D}^{s} \ne \mathcal{D}^{t}$. This violates the assumption in vanilla supervised learning that data must be independently and identically distributed. A formal definition of DA is provided below.

%\vspace{-0.2cm}
\begin{MyDef}
\label{def:DA}
\textbf{Domain Adaptation (DA)}~\cite{farahani2021brief,dasurvey1}. Given multiple different domains $\mathcal{D}=\left\{\mathcal{D}_{i}\right\}$ ($1 \leq i \leq I$, where $I$ denotes the total number of domains), which include source domains $\mathcal{D}^{s}$ associated with corresponding learning tasks $\mathcal{T}^{s}$, and target domains $\mathcal{D}^{t}$ with their learning tasks $\mathcal{T}^{t}$, where $\mathcal{D}=\left\{\mathcal{D}^{s}, \mathcal{D}^{t}\right\}$ and $\mathcal{D}^{s} \cap \mathcal{D}^{t} = \varnothing$. The goal of DA is to learn a target predictive function $f(\cdot)$ on $\mathcal{D}^{t}$ using prior knowledge from $(\mathcal{T}^{s}, \mathcal{D}^{s})$, where $\mathcal{D}^{s} \ne \mathcal{D}^{t}$, and $\mathcal{T}^{s}$ and $\mathcal{T}^{t}$ share the same label space.
\end{MyDef}


Supervised domain adaptation has been widely studied~\cite{dasurvey,dasurvey1}, so we use classification tasks to explain the unsupervised domain adaptation (UDA) problem~\cite{dasurvey}, where the target domain samples are unlabeled, as shown in Figure~\ref{dtfc} (c). Specifically, the target task $\mathcal{T}^{t}$ and its unlabeled data $\left\{\textit{x}_{i}\right\}^{N^{t}}_{i=1} \in \mathcal{D}^{t}$ are supported by the source task $\mathcal{T}^{s}$ with labeled data pair $\left\{(\textit{x}_{i}, \textit{y}_{i})\right\}^{N^{s}}_{i=1} \in \mathcal{D}^{s}$. Here, $\mathcal{D}^{s} \ne \mathcal{D}^{t}$, but $\mathcal{T}^{s}$ and $\mathcal{T}^{t}$ share the same label space. The goal is to learn a function $f(\cdot)$ for $\mathcal{T}^{t}$ by leveraging the data from both $\textit{D}^{t}$ and $(\mathcal{T}^{s}, \textit{D}^{s})$. Figure \ref{dtfc} (c) illustrates the unsupervised domain adaptation (UDA) classification problem.


Combining the challenges of FSL and DA, CDFSL~\cite{feature-wise,parameter_weight_4} predicts new samples using a model trained on $\{(\textit{x}_{i}, \textit{y}_{i})\}^{N^{t}}_{i=1}$ with prior knowledge from $\{(\textit{x}_{i}, \textit{y}_{i})\}^{N^{s}}_{i=1}$, where $N^{s} \gg N^{t}$. In CDFSL, the data $\{(\textit{x}_{i}, \textit{y}_{i})\}^{N^{s}}_{i=1}$ and $\{(\textit{x}_{i}, \textit{y}_{i})\}^{N^{t}}_{i=1}$ are drawn from different domains, $\mathcal{D}^{s}$ and $\mathcal{D}^{t}$ respectively, and they do not share the same label space, meaning $\mathcal{D}^{s} \ne \mathcal{D}^{t}$ and $\mathcal{T}^{s} \ne \mathcal{T}^{t}$. Compared to the FSL problem, where the data should be independent and identically distributed (i.i.d.), and the DA problem, which requires that tasks share the same label space, CDFSL breaks these constraints. Therefore, CDFSL inherits the challenges of both FSL and DA, making it a more challenging problem.
A definition of CDFSL is formally given below.

%\vspace{-0.2cm}
\begin{MyDef}
\label{def:CDFSL}
\textbf{Cross-Domain Few-Shot Learning (CDFSL).} Considering multiple different domains $\mathcal{D}=\left\{\mathcal{D}_{i}\right\}$ (1 $\leq$ i $\leq$ I, where I means the number of domains), including source domains $\mathcal{D}^{s}$ with sufficient information, along with corresponding learning tasks $\mathcal{T}^{s}$, and the target domains $\mathcal{D}^{t}$ with limited supervised information and FSL tasks $\mathcal{T}^{t}$, where $\mathcal{D}=\left\{\mathcal{D}^{s}, \mathcal{D}^{t}\right\}$ and $\mathcal{D}^{s} \cap \mathcal{D}^{t} = \varnothing$.
The goal of CDFSL is to learn a target predictive function $f_T(\cdot)$ on $\mathcal{D}^{t}$ with the help of prior knowledge from $(\mathcal{D}^{s}, \mathcal{T}^{s})$, where $\mathcal{D}^{s} \ne \mathcal{D}^{t}$, and $\mathcal{T}^{s} \ne \mathcal{T}^{t}$.
\end{MyDef}

In a cross-domain few-shot classification (CDFSC) problem~\cite{data_target_1,data_multi_1,data_multi_2}, as shown in Figure \ref{dtfc} (d), we similarly denote a source and a target classification task by $\mathcal{T}^{s}$ and $\mathcal{T}^{t}$, respectively. They are described by the data pairs $\{(\boldsymbol{x}_i^s,y^s_i)\}_{i=1}^{N^s} \subseteq \mathcal{D}^s$ and $\{(\boldsymbol{x}_i^t,y^t_i)\}_{i=1}^{N^t} \subseteq \mathcal{D}^{t}$, where $N^s\gg N^t$, $y^s_i\in\mathcal{Y}^s$, $y^t_i\in\mathcal{Y}^t$, $\mathcal{Y}^t\bigcap\mathcal{Y}^s=\varnothing$ (\ie, the source and target domains do not share the label space). Note that $\mathcal{D}^t$ and $\mathcal{D}^s$ are sampled from two different probability distributions $p$ and $q$, respectively, where $p \ne q$. The objective of the CDFSC is learning a classifier $f_{T}$($\cdot$) for $\mathcal{T}^{t}$ using $\mathcal{D}^{t}$ and $(\mathcal{T}^{s}, \mathcal{D}^{s})$.

CDFSL can be grouped into three categories based on why the image distributions differ: Fine-grained CDFSL ($FG$)~\cite{feature-wise,hybrid_7}, Art-based CDFSL ($Art$)~\cite{meta-dataset}, and Imaging way-based CDFSL ($IW$)~\cite{bscd-fsl,st,dynamic}. $FG$ refers to fine-grained class differences between $\mathcal{D}^s$ and $\mathcal{D}^t$, where $\mathcal{D}^t$ contains subclasses of $\mathcal{D}^s$. $Art$ involves differences in artistic styles like sketches, stick figures, and paintings. $IW$ deals with differences in imaging modalities, such as natural images in $\mathcal{D}^s$ and medical X-rays in $\mathcal{D}^t$, making it the most challenging of the three.

\subsection{\textcolor{black}{Closely Related Problems}} \label{related}
Since CDFSL is a sub-problem of both FSL and DA, in this section, we primarily focus on the connections and distinctions between CDFSL and the other sub-problems within FSL and DA, as illustrated in Table~\ref{rela}.
\begin{table}
\footnotesize
\centering
\caption{The connections and distinctions between the core related problems and CDFSL. $\mathcal{D}^{s}$ and $\mathcal{D}^{t}$ mean the source and target domain, respectively. And $\mathcal{Y}^{s}$ and $\mathcal{Y}^{t}$ represent the label space in the source and target tasks.}
\vspace{-0.2cm}
\setlength{\tabcolsep}{1.3mm}{
\begin{tabular}{lcccc}
\hline
\textbf{Problem} & \textbf{$\mathcal{D}^{s} \ne \mathcal{D}^{t}$} & \textbf{$\mathcal{Y}^{s} \ne \mathcal{Y}^{t}$} & \textbf{Limited $\mathcal{D}^{t}$} & \textbf{\textbf{Labeled data in $\mathcal{D}^{t}$}}       \\ 
 \hline
Semi-supervised domain adaptation (Semi-DA)~\cite{dasurvey1} & \Checkmark & \XSolidBrush & \XSolidBrush &  \Checkmark  \\
Unsupervised domain adaptation (UDA)~\cite{dasurvey,officehome} & \Checkmark & \XSolidBrush & \XSolidBrush & \XSolidBrush  \\
Universal domain adaptation (UniDA)~\cite{you2019universal,saito2020universal} & \Checkmark & \Checkmark & \XSolidBrush & \XSolidBrush  \\
Domain generalization (DG)~\cite{generalization_theory,dg11} & \Checkmark & \XSolidBrush & \XSolidBrush & Unseen $\mathcal{D}^{t}$  \\
Multi-task learning (MTL)~\cite{mtl1} & \XSolidBrush & \Checkmark & \XSolidBrush & \Checkmark   \\
Few-shot learning (FSL)~\cite{fslsurvey} & \XSolidBrush & \Checkmark & \Checkmark & \Checkmark   \\
Domain adaptation few-shot learning (DAFSL)~\cite{dafsl1,feature_reweight_8} & \Checkmark & \XSolidBrush & \Checkmark & \Checkmark   \\   \rowcolor{gray!30}
\textbf{Cross-domain few-shot learning (CDFSL)} & \Checkmark & \Checkmark & \Checkmark & \Checkmark   \\   
\hline
\end{tabular}}
\vspace{-0.5cm}
\label{rela}
\end{table}

\textit{Semi-supervised Domain Adaptation (Semi-DA)~\cite{dasurvey1}.} Semi-DA uses a large amount of supervised data in $\mathcal{D}^{s}$, along with a few labeled and many unlabeled samples in $\mathcal{D}^{t}$, to improve the performance of $\mathcal{T}^{t}$, with $\mathcal{D}^{s} \ne \mathcal{D}^{t}$ but the same label space. Similarly, CDFSL~\cite{feature-wise} also uses large supervised data in $\mathcal{D}^{s}$ and limited labeled data in $\mathcal{D}^{t}$, but without using many unsupervised samples from the target domain. Additionally, CDFSL differs in that the label spaces of $\mathcal{D}^{s}$ and $\mathcal{D}^{t}$ are different.

\textit{Unsupervised Domain Adaptation (UDA)~\cite{dasurvey,officehome}.} UDA utilizes a large amount of supervised data in $\mathcal{D}^{s}$ and a large amount of unlabeled data in $\mathcal{D}^{t}$ to improve the performance of $\mathcal{T}^{t}$. The distributions between $\mathcal{D}^{s}$ and $\mathcal{D}^{t}$ are different but related, \ie, $\mathcal{D}^{s} \ne \mathcal{D}^{t}$. And they share the same learning tasks. Like UDA, CDFSL~\cite{feature-wise} also uses a large amount of supervised data in $\mathcal{D}^{s}$ to improve the performance of $\mathcal{T}^{t}$ in $\mathcal{D}^{t}$, $\mathcal{D}^{s} \ne \mathcal{D}^{t}$. However, $\mathcal{D}^{t}$ in CDFSL has only a few amounts of supervised data, and the tasks of $\mathcal{D}^{s}$ and $\mathcal{D}^{t}$ are different.

\textit{Universal Domain Adaptation (UniDA)~\cite{you2019universal,saito2020universal}.} In UniDA, the source and target domains are different ($\mathcal{D}^{s} \ne \mathcal{D}^{t}$) and there is no prior knowledge of the label sets, meaning the source label set $\mathcal{Y}^{s}$ and target label set $\mathcal{Y}^{t}$ may overlap but also contain their own unique labels, creating a category gap. Specifically, $\mathcal{Y}^{s} \cap \mathcal{Y}^{t} \neq \varnothing$ and $\mathcal{Y}^{s} \setminus \mathcal{Y}^{t} \neq \mathcal{Y}^{t} \setminus \mathcal{Y}^{s} \neq \varnothing$. UniDA requires a model to either correctly classify the target sample if it belongs to the common label set $\mathcal{Y}^{s} \cap \mathcal{Y}^{t}$, or mark it as "unknown" if it does not. Similarly, in CDFSL~\cite{feature-wise}, the tasks in $\mathcal{D}^{s}$ and $\mathcal{D}^{s}$ differ, but CDFSL involves a few labeled target samples, and $\mathcal{Y}^{s} \cap \mathcal{Y}^{t} = \varnothing$. Additionally, there is no `unknown' class in CDFSL.

\textit{Domain Generalization (DG)~\cite{generalization_theory,dg11}.} DG uses a large amount of supervised data in $\textit{M}$ source domains $\mathcal{D}^{s}=\{\mathcal{D}^{s}_{i}|i=1,...,M\}$ to improve the performance on the unseen $\mathcal{D}^{t}$. The distributions of $\mathcal{D}^{s}$ and $\mathcal{D}^{t}$ are different but related, \ie $\mathcal{D}^{s} \ne \mathcal{D}^{t}$, and the tasks between $\mathcal{D}^{s}$ and $\mathcal{D}^{t}$ are same. Similar to DG, CDFSL~\cite{feature-wise} also uses a large amount of supervised data in $\mathcal{D}^{s}$. However, CDFSL is designed to perform well on the special $\mathcal{D}^{t}$ but not all unseen $\mathcal{D}^{t}$. Furthermore, the tasks of $\mathcal{D}^{s}$ and $\mathcal{D}^{t}$ are different in CDFSL, \ie $\mathcal{T}^{s} \ne \mathcal{T}^{t}$.

\textit{Domain Adaptation Few-shot Learning (DAFSL)~\cite{dafsl1,feature_reweight_8}.} DAFSL leverages a significant amount of supervised data in the source domain $\mathcal{D}^{s}$ and a limited number of labeled data in the target domain $\mathcal{D}^{t}$ to enhance the performance on $\mathcal{D}^{t}$. Although $\mathcal{D}^{s} \ne \mathcal{D}^{t}$, the learning tasks remain the same. Similarly, CDFSL~\cite{feature-wise} utilizes the same data configurations in both domains to train the function for task $\mathcal{T}^{t}$. However, in contrast to DAFSL, the learning tasks in $\mathcal{D}^{s}$ and $\mathcal{D}^{t}$ differ in CDFSL.

\textit{Multi-task Learning (MTL)~\cite{mtl1}.} MTL utilizes $M$ tasks from $\mathcal{D}$ to improve the performance of every task $\mathcal{T}_i$ (0 < i $\leq$ $M$). All $\{\mathcal{T}_i\}^M_{i=1}$ are different but related. Different from MTL, the data of $\mathcal{T}^{s}$ and $\mathcal{T}^{t}$ in CDFSL is from different domains $\mathcal{D}^{s}$ and $\mathcal{D}^{t}$, \ie $\mathcal{D}^{s} \ne \mathcal{D}^{t}$ and $\mathcal{T}^{s} \ne \mathcal{T}^{t}$, and the supervised data in $\mathcal{D}^{t}$ is limited.


\subsection{\textcolor{black}{Unique Issue and Challenge}} \label{unique}
In machine learning, prediction errors are typically unavoidable, making it impossible to achieve perfect predictions~\cite{ml}, \ie, the problem of unreliable empirical risk minimization (ERM). In this section, we begin by explaining the concept of empirical risk minimization (ERM)~\cite{erm1,erm2}. Next, we investigate the two-stage empirical risk minimization problem (TSERM)~\cite{tltheory} for CDFSL. Finally, we examine the distinct issues and challenges posed by CDFSL.

\vspace{-0.2cm}
\subsubsection {Empirical Risk Minimization (ERM)~\cite{erm1,erm2}}
Given an input space $\mathcal{X}$ and label space $\mathcal{Y}$, in which $X$ and $Y$ satisfy the joint probability distribution $P(X,Y)$, a loss function $l(\hat{y},y)$, a hypothesis $h \in \mathcal{H}$~\footnote{Hypothesis space $\mathcal{H}$ consists of all functions that can be represented by some choice of values for the weights~\cite{ml}. A hypothesis $h$ is a function in Hypothesis space.}, the risk (expected risk) of hypothesis $h(x)$ is defined as the expected value of the loss function:
\begin{align}
R(h)=\mathbb{E}[l(h(x),y)]=\int l(h(x),y)dP(x,y),
\end{align}
The ultimate goal of the learning algorithm is to find the hypothesis $h^{\ast}$ that minimizes the risk $R(h)$ in the hypothesis space $\mathcal{H}$:
\begin{align}
h^{\ast}=\text{argmin}_{h\in \mathcal{H}}R(h),
\end{align}
Since $P(x,y)$ is unknown, we compute an approximation of $R(h)$ called empirical risk by averaging the loss function over the training set:
\begin{align}
\hat R(h)=\frac{1}{n}\sum_{i=1}^{n}l(h(x_{i}),y_{i}),
\end{align}
Therefore, the expected risk is usually infinitely approximated by empirical risk minimization ~\cite{erm1,erm2}, \ie, a hypothesis $\hat{h}$ is chosen to minimize the empirical risk:
\begin{align}
\hat{h}=\text{argmin}_{h\in \mathcal{H}}\hat{R}(h).
\end{align}

In FSL, due to limited supervised data, the empirical risk $\hat R(h)$ may poorly approximate the expected risk $h^{\ast}$, leading to overfitting of the empirical risk minimization hypothesis $\hat{h}$. In other words, the core problem of FSL is the unreliable empirical risk caused by insufficient supervised data~\cite{fslsurvey}. Current FSL approaches typically address this overfitting by incorporating additional datasets and tasks. However, as tasks differ between source and target domains, FSL also faces knowledge transfer challenges due to task shift. This is illustrated in the following two-stage empirical risk minimization problem.

\vspace{-0.2cm}
\subsubsection{Two-Stage Empirical Risk Minimization (TSERM)}
We assume that all tasks are different but related, and we extend the two-stage empirical risk minimization (TSERM) from~\cite{tltheory} to explain the CDFSL problem. TSERM aims to transfer prior knowledge from the source task to the target task. In the first stage, the focus is on learning the prior knowledge. The second stage then uses this learned prior knowledge to construct an optimal hypothesis for the target task.


Specifically, we use $\mathcal{D}^{s}$ and $\mathcal{D}^{t}$ to indicate the source and target domains, $\mathcal{T}^{s}$ and $\mathcal{T}^{t}$ to represent the source task and target task. TSERM learns two hypotheses $f$ and $h$~\footnote{both $f$ and $h$ are parametric models due to only limited supervised samples existing} in a hypothesis space $\mathcal{H}$, where $f$ learns the prior knowledge in the first stage, and $h$ utilizes it to adapt $\mathcal{T}^{t}$ in the second stage. For convenience, we use
\begin{itemize}
\item [(1)] $(h^{\dagger},f^{\ast})$~\footnote{we assume that there exists a common nonlinear feature representation $f^{\dagger}$ in $\mathcal{H}$, which means $f^{\ast}$=$f^{\dagger}$}=$\text{argmin}_{(f,h)}R(h, f)$ represents the function that minimizes the expected risk,

\item [(2)] $(h^{\ast},f^{\ast})$ =
$\text{argmin}_{(f,h)\in \mathcal{H}}R(h, f)$ means the function that minimizes the expected risk in $\mathcal{H}$,

\item [(3)] $(\hat{h},\hat{f})=
\text{argmin}_{(f,h)\in \mathcal{H}}\hat{R}(h, f)$ indicates the function that minimizes the empirical risk in $\mathcal{H}$.
\end{itemize}
Since $(h^{\dagger},f^{\ast})$ is unknown, it must be approximated by $(h, f)\in \mathcal{H}$. $(h^{\ast},f^{\ast})$ represents the most optimal approximation in $\mathcal{H}$, while $(\hat{h},\hat{f})$ represents the empirical risk minimization optimal hypothesis in $\mathcal{H}$. Suppose $(h^{\dagger},f^{\ast})$, $(h^{\ast},f^{\ast})$, $(\hat{h},\hat{f})$ are all unique. In the first stage, the empirical risk of $\mathcal{T}^{s}$ is given by the following formula:
\begin{align}
\hat{R}(h_s, f)=\frac{1}{N^{s}}\sum^{N^s}_{i=1}l(h_s\circ f(x_i^s),y_i^s),
\end{align}
where $l(\cdot, \cdot)$ is the loss function, $N^s$ represents the number of training samples in $\mathcal{D}^{s}$, and ($x_i^s$, $y_i^s$) represents the samples and corresponding labels in $\mathcal{D}^{s}$. $h_s$ is the hypothesis of $\mathcal{T}^{s}$. The prior knowledge extraction function $f^{'}(\cdot)$ is expressed as $(\hat{h}_{s},f^{'})=\text{argmin}_{(f,h_s)\in \mathcal{H}}\hat{R}(h_s,f)$. 
In the second stage, the empirical risk of $\mathcal{T}^{t}$ is defined as:
\begin{align}\hat{R}(h_t,f^{'})=\frac{1}{N^{t}}\sum^{N^t}_{i=1}l(h_t\circ f^{'}(x_i^t),y_i^t),
\end{align}
same as above, $h_t$ is the hypothesis of $\mathcal{T}^{t}$, $N^{t}$ denotes the number of training samples for $\mathcal{T}^{t}$, and $x_i^t$ and $y_i^t$ represent the samples and corresponding labels in $\mathcal{T}^{t}$, respectively. In the second stage, our goal is to estimate the optimal hypotheses $(\hat{h}_t,\hat{f})=\text{argmin}_{(f,h_t)\in \mathcal{H}}\hat{R}(h_t,f^{'})=\text{argmin}_{(f,h_t)\in \mathcal{H}}(\text{argmin}_{(f,h_s)\in \mathcal{H}}\hat{R}(h_s,f)+\lambda \Delta(\mathcal{T}^{s}, \mathcal{T}^{t}))$, where $\Delta(\mathcal{T}^{s}, \mathcal{T}^{t})$ means the distribution distance between $\mathcal{T}^{s}$ and $\mathcal{T}^{t}$, $\lambda$ represent the regularization parameter for weighting the distribution distance. We measure the function $(\hat{h_t},\hat{f})$ by the excess error~\cite{tltheory,fslsurvey} on $\mathcal{T}^{t}$, namely:
\begin{equation}
    \begin{aligned}
\mathbb{E}[R_{excess}] &  =\mathbb{E}[R(\hat{h_t},\hat{f})-R(h_t^{\dagger}, f^{\ast})] \\
& =\overbrace{\mathbb{E}[R(h^{\ast}_t,f^{\ast})-R(h^{\dagger}_ t,f^{\ast})]}^{\epsilon_{app}(\mathcal{H})}+\overbrace{\tilde{\mathbb{E}}[R(\hat{h}_t,\hat{f})-R(h^{\ast}_t,f^{\ast})]}^{\epsilon_{est}(\mathcal{H}, \mathcal{D}, \Delta)}.
\end{aligned}
\end{equation}
Among them, $R_{excess}$ represents the relationship between the expected risk of $(\hat{h_t},\hat{f})$ and the optimal prediction rule $(h_t^{\dagger},f^{\ast})$. The expectation $\mathbb{E}[\cdot]$ is with respect to the random choice of training data and training tasks. The approximation error $\epsilon_{app}(\mathcal{H})$ quantifies how well the functions in $\mathcal{H}$ approximate the optimal hypothesis $(h_t^{\dagger},f^{\ast})$. Meanwhile, the estimation error $\epsilon_{est}(\mathcal{H}, \mathcal{D}, \Delta)$ assesses the impact of minimizing the empirical risk $\hat{R}(h_t,f)$ in $\mathcal{H}$ instead of the expected risk $R(h_t,f)$, as shown by the orange dotted arrow in Figure \ref{issue1}. 
\begin{figure}
	\centering
  \vspace{-0.3cm}
	\includegraphics[width=\linewidth]{response/cdfsl1.pdf}
 \vspace{-0.4cm}
	\caption{Comparison of (a) vanilla supervised learning, (b) few-shot learning (FSL), and (c) cross-domain few-shot learning (CDFSL). The square represents the hypothesis space $\mathcal{H}$. Solid circles denote the datasets (the size means the amount of data, \ie $\mathcal{D}$), the large and small solid circles represent the auxiliary and limited target datasets, respectively. Dotted circles indicate the domain to which the target samples belongs, which means the auxiliary dataset is from the same domain with target domain in (b), and different but related domain in (c). The angle between the optimization directions of the two stages represents the difference between the source and target tasks $\Delta$, \ie, the larger the angle, the greater the difference.}
 \vspace{-0.2cm}
	\label{issue1}
\end{figure}

\vspace{-0.2cm}
\subsubsection{Unique Issue and Challenge} \label{challenge}
The approximation error $\epsilon_{app}(\mathcal{H})$, affected by $\mathcal{H}$, cannot be optimized due to the limitation of $\mathcal{H}$~\cite{fslsurvey}. Therefore, our goal is to optimize the estimation error $\epsilon_{est}(\mathcal{H}, \mathcal{D}, \Delta)$, which is affected by $\mathcal{H}$, amount of data in $\mathcal{D}$ (including $\mathcal{D}^{s}$ \& $\mathcal{D}^{t}$), and $\Delta$ ($\Delta$ is affected by the task shift and domain gap). This means $\epsilon_{est}(\mathcal{H}, \mathcal{D}, \Delta)$ can be reduced by increasing the amount of $\mathcal{D}$, constrain the complexity of $\mathcal{H}$, and having a small $\Delta$.


In Figure~\ref{issue1}, the solid black arrow expresses the learning of empirical risk minimization.  
Figure~\ref{issue1} (a) shows a vanilla supervised learning problem. It is easy to reduce $\epsilon_{est}(\mathcal{H}, \mathcal{D}, \Delta)$ in the case of large $\mathcal{D}$. The left part of (b) depicts the FSL problem, where ERM learning is suboptimal due to the insufficient data in $\mathcal{D}$. The existing FSL strategy, as shown in the right part of Figure \ref{issue1} (b), provides a large amount of auxiliary data from $\mathcal{D}$ and the corresponding different but relevant auxiliary task $\mathcal{T}^{s}$, here $\mathcal{T}^{s}\ne\mathcal{T}^{t}$, indicating only a task shift exists, \ie, $0 < \Delta \le \sigma$ where $\sigma$ is a small constant.


As a result of the domain gaps between the source and target datasets, a novel CDFSL problem emerges, as illustrated in Figure \ref{issue1} (c). It is evident that the CDFSL problem involves both domain gaps and task shift between the source and target domains, with limited supervised information available in $\mathcal{D}^{t}$. This means $\mathcal{D}^{t}$ is small and $\Delta$ is large in CDFSL, making $\epsilon_{est}(\mathcal{H}, \mathcal{D}, \Delta)$ large, leading to an unreliable TSERM (estimation error optimization) problem.

\vspace{-0.2cm}
\subsection{\textcolor{black}{Taxonomy}} \label{taxonomy}
According to the unique issues and challenges mentioned above, CDFSL aims to solve the  unreliable TSERM problem. Therefore, existing CDFSL methods address this issue, as shown in Figure~\ref{step2}, through: (1) $\mathcal{D}$-extension, \ie augmenting the information in $\mathcal{D}$, (2) $\mathcal{H}$-constraint, \ie constraining the complexity of the hypothesis space $\mathcal{H}$, (3) $\Delta$-adaptation, \ie reducing the distance $\Delta$ between $\mathcal{T}^{s}$ and $\mathcal{T}^{t}$, and (4) Hybrid approaches, \ie combining the above strategies.
\begin{figure}
	\centering
 \vspace{-0.2cm}
	\includegraphics[width=12cm]{response/crop_methods.pdf}
  \vspace{-0.3cm}
	\caption{The main taxonomy of cross-domain few-shot learning (CDFSL) methods: (a) $\mathcal{D}$-Extension, (b) $\mathcal{H}$-Constraint, and (c) $\Delta$-Adaptation.}
 \vspace{-0.3cm}
	\label{step2}
\end{figure}
Accordingly, existing works are categorized into a unified taxonomy, as shown in Figure~\ref{out}. In the following sections, we will detail each category, performances, future works, and conclusion.
 \begin{figure}[h]
	\centering
  \vspace{-0.3cm}
	\includegraphics[width=\linewidth]{response/crop_tree.pdf}
 \vspace{-0.3cm}
	\caption{The taxonomy of representative methods in CDFSL.}
 \vspace{-0.4cm}
	\label{out}
\end{figure}
