\section{Future work} \label{future}
Despite the significant progress made in CDFSL, it still presents unique challenges that require further investigation. Therefore, we outline several promising future research directions, focusing on problem setups, applications, and theoretical developments within the field.

\subsection{Problem Setups}
\textit{Active Learning based CDFSL.}
In Section~\ref{challenge}, we discussed the challenge of CDFSL, primarily due to domain gap and task shifts, which is especially problematic when the domains are vastly different and target domain data is scarce. Addressing this challenge requires expanding and efficiently utilizing shared information between these domains. Active learning (AL), which identifies the most informative samples for labeling, has gained attention in both domain adaptation~\cite{ac_da,ac_da1} and few-shot learning~\cite{ac_fsl,ac_fsl1}. For example, \cite{ac_da} improves target domain recognition by prioritizing samples with high uncertainty and diversity. Similarly, \cite{ac_fsl} integrates FSL and AL into FASL, an iterative platform for efficient text classification. Given the ability of AI to select the most informative samples, it is well-suited to enhance both cross-domain and cross-task learning in CDFSL, making it a promising area for future research.

\textit{Source-free CDFSL.} 
Most existing CDFSL methods focus on incorporating related strategies during the source domain training stage to address challenges. However, with growing concerns about data privacy, accessing source data in real-world scenarios may infringe on intellectual property rights. This has led to the exploration of source-free CDFSL, where algorithms improve FSL performance on the target domain using only a pre-trained source model, without access to the source data. While this approach is well-established in domain adaptation~\cite{sfda1,sfda2,sfda3}, it remains in its early stages for CDFSL. \textcolor{black}{Notable efforts include ~\cite{parameter_fix_6}, which adjusts batch normalization to align source and target distributions, and ~\cite{xu2024enhancing}, which uses information maximization for implicit alignment.} Given the unique challenges of CDFSL, further research in source-free settings is essential for safeguarding data privacy.
\iffalse
Transductive inference refers to the prediction of individual test samples by observing specific training samples. In cases where training samples are limited and test samples are abundant, the category discriminant model generated through inductive reasoning often yields suboptimal performance. Transductive reasoning, on the other hand, exploits information from unlabeled test samples to identify clusters and enhance classification accuracy. Numerous studies have successfully applied transductive inference to tackle FSL problems, resulting in promising outcomes~\cite{tfsl1,tfsl2,tfsl3}. As a subfield of FSL, utilizing transductive inference to improve CDFSL performance is an encouraging avenue to explore.
\fi

\textit{Prompt Tuning based CDFSL.} 
Fine-tuning is a common approach for adapting pre-trained models to target domains in CDFSL. However, as the size of pre-trained models grows, fine-tuning can become prohibitively expensive. To address this, a new paradigm called prompt learning has emerged in natural language processing (NLP) \cite{ptnlp}. Rather than fine-tuning all model parameters, prompt tuning (PT) uses minimal prompts to guide the model in understanding the target task. Additionally, in-context learning (ICL) \cite{iclsurvey}, a subclass of prompt learning, has been extensively studied in various applications. \textcolor{black}{ICL concatenates queries and limited context into a prompt, which aligns well with the FSL approach. PT has proven effective in FSL tasks in NLP~\cite{ptnlpfsl1,ptnlpfsl2} and has shown promise in solving domain adaptation problems~\cite{dapt1} in computer vision.} Thus, exploring the potential of PT in CDFSL, which combines DA and FSL challenges, represents a promising direction for future research.

\textit{Interpretability-guided CDFSL.}
Current CDFSL techniques rely heavily on black-box feature generation, making it difficult to identify the optimal features for generalization and what factors influence model performance. Recent work by \cite{parameter_weight_3} introduces attention mechanisms to highlight the importance of different areas in samples. However, this approach still requires further refinement to effectively work across different domains and tasks. More recent studies \cite{cr_1,cr_2} have introduced causal reasoning to clarify the causal relationships between factors in FSL, thereby enhancing model interpretability and improving its ability to acquire shared knowledge. For instance, \cite{cr_1} proposes a Structural Causal Model (SCM) to uncover causal relationships between pre-trained knowledge, sample features, and labels in FSL. Emphasizing interpretability-guided feature representation presents a promising avenue for enhancing the performance of CDFSL models.

\textit{Incremental CDFSL.}
Current CDFSL methodologies focus on addressing FSL tasks in the target domain but often suffer from catastrophic forgetting, where performance on the source domain declines. A robust model should retain knowledge from both domains and tasks. Thus, addressing catastrophic forgetting in CDFSL is a critical challenge. Recent advances in incremental and continuous learning have been applied in FSL to tackle task-incremental issues~\cite{cdfsil_1,cdfsil_2}. \textcolor{black}{For example, \cite{cdfsil_1} stabilizes network topology to minimize forgetting of previous classes, while \cite{cdfsil_2} focuses on updating classifiers incrementally, preventing the erasure of knowledge in the feature extractor.} Building on these techniques, exploring domain-incremental learning in CDFSL is crucial. The goal is to extend the model to accommodate new domains and tasks while maintaining performance on prior ones.

\iffalse
\textit{Multi-modal/Multi-view CDFSL.} 
We can enhance the performance of CDFSL by incorporating additional modal information from different modalities, as it has been proved in zero-shot learning~\cite{zsl} that information from diverse modalities can aid in processing unseen tasks. In particular, multi-modal CDFSL can furnish additional insights from varying viewpoints, further enhancing the performance of CDFSL. Therefore, exploring multi-modal CDFSL is a promising research direction to pursue.

\textit{Imbalanced CDFSL.} 
The current CDFSL tasks assume an equitable number of labeled samples in various categories, which may not accurately reflect real-world scenarios. Nonetheless, existing research in FSL has tackled data imbalance problems using techniques such as data augmentation and class imbalance loss. For instance,~\cite{im_fsl} proposes a data augmentation method to rebalance the original imbalanced data, while~\cite{im_fsl2} suggests a class imbalance loss to tackle the imbalance problem in FSL. Hence, such technologies can be adapted to address the imbalance issue in CDFSL.
\fi

\subsection{Applications}
As CDFSL addresses both domain and task shift problems alongside FSL challenges, it has found applications in various fields of computer vision where data is scarce. This section highlights promising CDFSL applications, including rare cancer detection, object tracking, intelligent fault diagnosis, and mitigating bias in AI algorithms~\cite{cancer,osl,app-diagnosis}. % These applications demonstrate the versatility and effectiveness of CDFSL in handling complex real-world scenarios with limited data.

\iffalse
\textbf{Computer Vision.}
At present, many practical applications in computer vision involve CDFSL, such as image segmentation~\cite{app-segmentation}, object detection~\cite{app-detection}, image generation~\cite{app-generation}, etc. Furthermore, it also has attracted a lot of attention in many emerging applications, such as re-identification, semantic segmentation~\cite{app_cv1}, etc. Although there have many applications of CDFSL in computer vision, its exploration is still in the early stage. Hence, there are still many exploration directions of CDFSL in computer vision applications.

\textbf{Natural Language Processing (NLP).} CDFSL currently has related applications in natural language processing, for instance intent classification~\cite{app_nlp1}, sentiment classification~\cite{app_nlp2}, etc. Nevertheless, there are still many fields in NLP that strongly demand CDFSL, such as machine translation for minority languages (ancient Chinese poems, Mongolian, Romanian, etc.). Generally, the application exploration of CDFSL on NLP needs to be more.

\textbf{Speech Signal Processing.} CDFSL also has related applications in speech signal processing~\cite{app_speech1,app_speech2}. However, its exploration in speech signal processing is still minimal. Combined with multimodal CDFSL, it has a wide range of application prospects in speech understanding and synthesis.

\textbf{Other Fields.} Furthermore, several CDFSL works in hyperspectral image processing~\cite{Hyperspectral1,parameter_fix_8}. Besides,~\cite{app-micro} applies CDFSL on micro-expression recognition. And the cross-domain few-shot facial expression recognition is solved in~\cite{app-rec2}. Currently, CDFSL still has application prospects in various fields, such as intelligent diagnosis~\cite{app-diagnosis,app-dia2}, agricultural~\cite{app_ag1}, marine~\cite{app_ma1}, etc.
\fi

\textit{Rare Cancer Detection.}  
Cancer is a serious disease that demands early detection, and detecting rare cancers is particularly challenging due to the limited availability of data. While FSL has been employed for rare cancer detection~\cite{rcd1}, gathering sufficient auxiliary data from the same distribution as the target data can be challenging. This makes CDFSL an ideal solution, as it allows for the use of auxiliary data from different domains.

\textit{Object Tracking.}  
Object tracking~\cite{ot} is a key computer vision task that involves predicting the location of selected objects in subsequent frames based on their initial position in the first frame. This task closely relates to FSL, as both involve solving problems with limited data. Researchers~\cite{ot1} have applied FSL to object tracking. However, there are domain gaps between auxiliary and target data due to variations in data collection devices and acquisition methods. Traditional FSL techniques have struggled to address these gaps effectively, making CDFSL a promising approach for overcoming object tracking challenges.

\textit{Intelligent Fault Diagnosis.}  
Intelligent fault diagnosis~\cite{app-diagnosis} involves detecting machine faults early using diagnostic methods. However, creating an ideal training dataset for diagnostic models is challenging. To address this challenge,~\cite{app-dia2} incorporated data from other domains and applied FSL algorithms. This makes intelligent fault diagnosis a promising application for CDFSL, allowing models to leverage auxiliary data and improve diagnostic accuracy in the face of limited training samples.

\textit{Solving Algorithmic Bias.}  
AI algorithms depend on training data to address many real-world problems, but inherent biases in the data can be learned and amplified by these algorithms. For example, when certain groups are underrepresented in a dataset, the algorithm may make poor predictions for those groups, which can lead to algorithmic bias~\cite{fairness}. This presents a critical ethical challenge in artificial intelligence. Ideally, AI systems should mitigate bias rather than exacerbate it. \textcolor{black}{CDFSL offers a potential solution by focusing on reducing bias in datasets and generalizing across domains and tasks, effectively addressing domain and task shifts.} Furthermore, CDFSL can mitigate performance loss caused by limited data from underrepresented groups, contributing to fairer outcomes.

\vspace{-3mm}
\subsection{Theories}
\textit{Invariant Risk Minimization (IRM).}  
Machine learning systems often capture all correlations in the training data, including spurious correlations arising from data biases. To ensure generalization to new environments, eliminating such spurious correlations is essential. Invariant Risk Minimization (IRM)~\cite{irm} is a learning paradigm that addresses this by estimating nonlinear, invariant, causal predictors across multiple training environments, reducing a systemâ€™s dependence on data biases. In CDFSL, spurious correlations learned in the source domain should be discarded when adapting to tasks in the target domain. \textcolor{black}{Thus, despite being in its early stages, IRM shows significant promise for CDFSL due to its emphasis on domain and task migration.}
%Machine learning systems can often pick up all correlations present in the training data, including those that are spurious due to existing data biases. To ensure generalization to new environments, it is crucial to discard such spurious correlations that do not hold in the future. Invariant Risk Minimization (IRM) is a learning paradigm proposed by~\cite{irm} that estimates nonlinear, invariant, causal predictors from multiple training environments to mitigate the over-reliance of machine learning systems on data biases. Although still in its early stages of exploration, IRM is crucial for CDFSL due to the migration of domains and tasks. In CDFSL, spurious correlations learned in the source domain must be discarded when adapting to the target domain tasks, making the development of IRM important for CDFSL. By exploring IRM for CDFSL, we can significantly enhance the performance on the target domain in CDFSL.

\textit{Multiple Source Domain Organization.}  
While some CDFSL approaches leverage multiple source domains to enhance FSL performance on the target domain, theoretical research on effectively organizing these source domains remains limited. Questions regarding how to select and optimize source domains for maximum FSL performance remain underexplored. \textcolor{black}{Advancing theoretical work in this area could significantly enhance multi-source domain applications in CDFSL. A promising reference is provided by~\cite{mul_theory}, which offers a theoretical foundation for organizing multi-source domains. This could pave the way for more effective and rational strategies in multi-source CDFSL.}

\textit{Domain Generalization.}  
\textcolor{black}{The ultimate goal of CDFSL is to generalize not only to specific domains but to all domains.} Theoretical research on domain generalization~\cite{generalization_theory} is crucial to achieving this. \textcolor{black}{Leveraging this research can enable CDFSL to evolve into a few-shot domain generalization problem, allowing models to generalize across a wide range of domains, thereby enhancing their robustness and adaptability.}