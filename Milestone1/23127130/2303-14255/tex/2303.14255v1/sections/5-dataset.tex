\section{New Virtual Agent Movement Dataset}
Using the AMASS \cite{AMASS:ICCV:2019} CMU MoCap \cite{cmuWEB} dataset, we used PACE to create a new dataset of virtual agent placements in cluttered indoor 3D scenes. We are releasing this dataset of tens of thousands of agent-scene pairs. We use the fitting loss, $E$, as a quality marker on the fitting and save pairings with a loss below a threshold value. Additionally, we filter the placements by the physical plausibility metric, ensuring that pairings with poor plausibility are not included. This filtering process allows us to filter out virtual agents that are poor fits for a given scene and would need an unnatural amount of alteration to fit properly. Completing this process with the full AMASS/CMU MoCap dataset alongside the PROX and Matterport3D-R \cite{zhangPLACEProximityLearning2020} room scans results in tens of thousands of samples. These samples are labeled by the original CMU MoCap data labels so users can filter by motion type. The motions included in our dataset include walking, jumping, stretching, sitting, navigating, among others. This dataset would be released at the time of publication.