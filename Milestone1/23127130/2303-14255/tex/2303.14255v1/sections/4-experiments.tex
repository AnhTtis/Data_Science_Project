
\section{Experiments}
\subsection{Datasets and Baseline}

For our PROX based evaluations, we randomly sample 10,000 motions from the 8 training scenes of PROX to use as our virtual agents. We then place these virtual agents into the 4 testing scenes. For our perceptive user study, these placement results are then shown to human raters in comparison with a baseline or ablative method. The rates are shown two placements in the same scene and asked to pick the more realistic of the two videos. For our quantitative evaluations of the physical plausibility metric all of the methods are used to generate results to be compared directly.

For our AMASS based evaluations, we randomly sample relevant virtual agent motion sequences from the CMU MoCap dataset. This means that we filter out motions that involve dancing, climbing, or those that would otherwise be unnatural in a cluttered indoor environment. We then use a HoloLens augmented reality headset to sample a local scene and populate that scene with a virtual agent using PACE. This was done as a proof of concept for how this could work in use. Additionally, we will be releasing a dataset we created using the AMASS/CMU dataset and scenes from PROX and Matterport3D \cite{Matterport3D}.

\begin{figure*}[ht]
	\begin{center}
		\includegraphics[width=\linewidth]{media/qual_ablate.pdf}
		\caption{Comparisons on placing the same virtual agent into the same scene across PACE, and two ablation studies. Specifically, we attempt to remove the $\mathcal{L}_{pose}$ and $\mathcal{L}_{mot}$ terms and evaluate the results. Note that two view angles of each interactions are provided. For the first interaction, notice how PACE places the agent such that it has direct, non-penetrative contact with the table and the ground that matches the motion of the agent. Conversely, removing $\mathcal{L}_{pose}$resulted in the agent seeming to float out of the scene, and contort in awkward ways, i.e. a non-plausible interaction. Removing $\mathcal{L}_{mot}$ resulted in no visible placement as each individual mesh was separated and thrown far from the scene. For placement 2, PACE successfully navigates the virtual agent around the chair, and even results in contact between the hand and the chair for support. In contrast, the virtual agents motion without $\mathcal{L}_{pose}$ resulted in some awkwardly leaned poses and a lack of contact for some of the meshes. Moreover, the motion sequence without $\mathcal{L}_{mot}$ became separated into pieces, not resembling a valid motion at all. Overall, $\mathcal{L}_{pose}$ and $\mathcal{L}_{mot}$ improve the plausibility of the interactions.}
		\label{fig:qual-ablate}
	\end{center}
\end{figure*}

We compare PACE with POSA, PAAK, a motion synthesis method, and ablations of PACE. We describe the baselines in greater detail below:

\textbf{POSA-T.} Hassan et al. \cite{hassanPopulating3DScenes2021} propose a method that places a single human mesh into a scene given its affordances. As this approach does not consider motion, we use PAAK's \cite{mullenjrPlacingHumanAnimations2022} POSA-T baseline which is modified to sum the placement loss over all the meshes in the motion sequence. It is labeled POSA-T for the addition of the time dimension.

\textbf{PAAK.} For PAAK, Mullen et al. \cite{mullenjrPlacingHumanAnimations2022} selects ``keyframes" from a virtual agent to focus on when optimizing the placement of the agent into a scene. 

\textbf{Motion Synthesis.} Wang et al. \cite{wangSynthesizingLongTerm3D2021} propose a motion synthesis method that accounts for the affordances of the scene in its motion creation. We used their approach as designed. We call this baseline Motion Synthesis.


\subsection{Evaluation}
A qualitative evaluation of PACE alongside PAAK and POSA-T can be found in \hyperref[fig:qual]{Figure 4}. Generally, we found that PACE generated improved interactions and fittings over the baselines, especially with regard to the details of each interaction. POSA-T was especially prone to invalid placements or interactions, like having the agent sitting in midair. PAAK placements tended to decrease in quality as the length of the virtual agents motion increases while its interactions were clumsy and inexact. This is likely due to its inability to alter the motion itself. This prevented it from tailoring the motion to the small, cluttered environments in the PROX dataset. These phenomenon can be seen in \hyperref[fig:qual]{Figure 4}. Anecdotally, as scene complexity increased, valid fittings tended to decrease. As a simple example, if you imagine a scene with a chair placed such that its right side is touching a wall, a motion that goes from sitting to standing, before immediately turning right and walking, will not have a valid fit location. These types of issues become more common as scene complexity increase, and are especially relevant for PAAK which cannot make small changes to the motion to accommodate the scene.

\begin{table}[t] \label{table:metric}
    \centering
    \begin{tabular}{l c c } 
        \hline\hline
        & Non-Collision $\uparrow$ & Contact $\uparrow$ \\ [0.5ex] 
        \hline\hline
        POSA-T & 0.983 & 0.733 \\ 
        \hline
        PAAK & 0.986 & 0.784 \\
        \hline
        \textbf{PACE} & \textbf{0.996} & \textbf{0.929} \\
        \hline
        PACE w/o $\mathcal{L}_{pose}$ & 0.995 & 0.610\\
        \hline
        PACE w/o $\mathcal{L}_{mot}$ & 1.00 & 0.340\\
        \hline
    \end{tabular}
    \vspace{5.0px}
    \caption{Evaluation of the physical plausibility metrics. A higher score is better for both the non-collision score and the contact score. PACE outperforms both of our baselines, especially in the contact metric. Moreover, PAAK results in a higher number of collisions between the virtual agent and the obstacles, while also having less meaningful interactions with the scene. Additionally, while the ablative methods without some of our loss terms perform well in the non-collision metric, they resulted in far lower contact scores than PACE.}
\end{table}


\textbf{Physical Plausibility.} Following the procedures utilized by \cite{hassanPopulating3DScenes2021, zhangPLACEProximityLearning2020, zhangGenerating3DPeople2020, mullenjrPlacingHumanAnimations2022}, we take 100 virtual agents and place them into the 4 test scenes of PROX. With the placements providing a body mesh relative to the scene, we use that and a scene signed distance field (SDF) to compute a non-collision score and contact score as defined originally in \cite{zhangGenerating3DPeople2020} and explained in section 3. The results are shown in \hyperref[table:metric]{Table 2}. A high non-collision score denotes that the meshes in each motion sequence do not penetrate the scene. PACE is an improvement over the baselines in the non-collision score.

The contact score is calculated as 1 if at least one vertex of the mesh is in direct contact with the scene. PACE is a significant improvement over the baselines, showcasing a unique ability to bend the virtual agents motion towards the geometry of the scene. The decrease in performance with PAAK and POSA-T are likely due to mismatches between the motion geometry in the scene geometry in things like seat size or exact object distances. For example, when standing up after sitting, if the seat size was not correct, the feet could be positioned above the floor instead of in contact with it. In contrast, PACE is able to ensure contact at each frame in the motion sequence, maximizing the contact metric. These results show that PACE creates more physically plausible placements than the baselines.

\begin{figure}[t]
	\begin{center}
		\includegraphics[width=0.8\columnwidth]{media/hololens.pdf}
		\caption{PACE evaluated in a real-world scene using HoloLens. Notice how the virtual agent smoothly navigates around the obstacles in the real-world environment.}
		\label{fig:hololens}
	\end{center}
\end{figure}

\textbf{Ablation Results.} We ablated PACE against the use of the $\mathcal{L}_{pose}$ and $\mathcal{L}_{mot}$ loss functions and compared the results qualitatively and with the physical plausibility metrics. For the physical plausibility metrics, both of these ablations resulted in similar or less collisions than PACE. However, the contact metric rapidly decreases. This makes sense when visualizing the results qualitatively in \hyperref[fig:qual-ablate]{Figure 5}. When ablating against $\mathcal{L}_{pose}$, we notice that the poses of the human itself rapidly decomposes to look unnatural and disfigured. The virtual agent itself also moves rapidly away from the scene as if taking flight. This allowed the optimizer to negate any penetration with the environment, at the cost of contacting it in any way and retaining realism in the motion. The results are also poor when ablating against $\mathcal{L}_{mot}$. As the translational location and motion of each mesh relative to the previous frame are no longer enforced, the virtual agent would often be moved entirely out of the frame by the optimizer. Some individual meshes would sometimes remain when there was important semantic contact.

\textbf{HoloLens Study.} We developed an augmented reality system for the Microsoft HoloLens where the application samples the geometry of its current environment, and places a virtual agent into it using PACE. \hyperref[fig:hololens]{Figure 6} shows an example of this implementation. We found a number of unique challenges, mostly related to the inaccuracies in the HoloLens room scans. It would box some things off incorrectly, resulting in conflicts. The HoloLens also does not classify the objects in the room semantically, making it more difficult to place virtual agents that want to specifically key in on this information. For example, a virtual agent with a laying interaction may lay on the floor despite there being a bed nearby. Anecdotal feedback suggests that users were impressed by the natural-looking motion of the virtual agents, but were not completely convinced they could be real people. Specifically, users noted that virtual agents seemed to often be walking around aimlessly which a real human would not typically do. After precomputing the scene and motion sequences, the final virtual agents can be populated into the HoloLens at 30 frames per second.

\begin{figure}[t]
	\begin{center}
		\includegraphics[width=0.8\columnwidth]{media/user_study.png}
		\caption{Example question shown to participants in our user study. Two videos are presented, one corresponding to PACE, the other corresponding to a baseline. Users would play each video as many times as they wished and would see the virtual agent move through the scene. Users would then have to choose which video was more realistic or plausible.}
		\label{fig:user-study}
	\end{center}
\end{figure}

\subsection{User Study}
We conduct a web-based user study to determine the quality of the virtual agent-scene pairings PACE creates compared to those created by the baselines.

\textbf{Procedure.}
We follow the protocols of Hassan et al. \cite{hassanPopulating3DScenes2021}, Zhang et al. \cite{zhangPLACEProximityLearning2020}, and Mullen et al. \cite{mullenjrPlacingHumanAnimations2022}. The study consisted of 60 questions taking participants approximately 30 minutes to complete. For each question, participants were shown two clips of a virtual agent placed into a cluttered 3D scene. They would play these two clips and decide which one they perceived to look more natural or realistic. An example user study question can be seen in \hyperref[fig:user-study]{Figure 7}. 

To generate our clips, we used the 4 testing scenes from the PROX dataset. We then took 100 virtual agent samples from the PROX training set for placement into the scenes. All of the methods, with the exclusion of the synthesis method, begin with a grid of potential placement locations and orientations in the scene with each location testing rotations every 30 degrees. We then find the optimal placement and alteration by minimizing $E_p$ and $E_{alt}$. We then render each agent-scene pair into a video from four different angles so the human raters can get a sense of the relationships between the agent, its motion, and the scene. 

We had a total of 400 agent-scene pairings for each method, 100 for each of the 4 utilized scenes. Users were shown a selection of these as to not make the study prohibitively long. Specifically, 5 clips from each of the four scenes, for each method, were selected. As we compared against 3 baseline methods, this resulted in 60 total questions per participant. Participants were not told which clip was from which method. Moreover, we made sure that PACE was not always placed above or below the baseline to prevent any selection bias. As the selection of clips was random, some clips were viewed and rated more frequently than others by participants.


\begin{table}[t] \label{table:direct}
    \centering
    \begin{tabular}{l c c } 
        \hline\hline
        & Baseline $\downarrow$ & PACE $\uparrow$ \\ [0.5ex] 
        \hline\hline
        POSA-T & 32.1\% & \textbf{67.9\%} \\ 
        \hline
        Motion Synthesis & 18.8\% & \textbf{81.2\%} \\
        \hline
        PAAK & 40.7\% & \textbf{59.3\%} \\
        \hline
    \end{tabular}
    \vspace{5.0px}
    \caption{PACE compared to POSA-T, Motion Synthesis \cite{wangSynthesizingLongTerm3D2021}, and PAAK. Subjects are shown pairs of motions placed into a 3D scene by PACE and by a baseline and must choose the most realistic one. A higher percentage indicates the scene-agent pairing subjects deemed more plausible and exhibits better interaction. Users preferred PACE over all of the baseline methods.}
\end{table}

\textbf{Evaluation.}
42 participants took part in our study. They were recruited by web advertisements and word of mouth. We did not record demographic information as to avoid any identifying information being collected. Additionally, unlike similar studies looking at emotion or gestures, demographic background should not impact whether a virtual agent's motion looks physically plausible.
As each participant responded to 60 questions, we had a total of 2520 responses. The results are shown in Table 2. 

PACE is an improvement over PAAK, with participants preferring it 59.3\% of the time. Participants sometimes found it difficult to fully notice the difference in some placements due to the low resolution of the video. Where users did see the difference is in the even more cluttered or smaller rooms where PAAK would often generate interactions that would penetrate the scene (i.e. collisions), or be entirely at an elevation that does not make realistic sense, like walking on a bed. This makes sense as PAAK was unable to modify the motion of the agent to properly respond to the unique characteristics of the environment, effectively shoehorning in motion that does not accurately fit into the scene. Participants perceived PACE as more natural-looking than POSA-T 67.9\% of the time. This is likely because POSA-T created much worse interactions with common occurrences including the virtual agent levitating or sitting in mid-air. The most plausible explanation for this being POSA-T's lack of frame weights and inability to alter the motion of the agent to properly fit the scene. Users strongly disliked the virtual agents created by the motion synthesis method, preferring PACE 81.2\% of the time. The most likely explanation for this is the motion synthesis method not consistently generating smooth, plausible motion. Individual frames of the motion generated by the synthesis method looked great but when it played as a video, like that shown to participants, the motion often looked unrealistic. Specifically, legs frequently did not move in a natural way when walking. This result emphasizes the importance of using motion-captured virtual agents to create the most natural-looking agent-scene pairings.

