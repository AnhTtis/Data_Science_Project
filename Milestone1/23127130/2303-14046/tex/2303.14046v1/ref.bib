@PREAMBLE{
 "\providecommand{\noopsort}[1]{}"
 # "\providecommand{\singleletter}[1]{#1}%"
}
@article{Langer2022,
author={Langer, Marcel F.
and Goe{\ss}mann, Alex
and Rupp, Matthias},
title={Representations of molecules and materials for interpolation of quantum-mechanical simulations via machine learning},
journal={npj Comput. Mater.},
year={2022},
month={Mar},
day={16},
volume={8},
number={1},
pages={41},
abstract={Computational study of molecules and materials from first principles is a cornerstone of physics, chemistry, and materials science, but limited by the cost of accurate and precise simulations. In settings involving many simulations, machine learning can reduce these costs, often by orders of magnitude, by interpolating between reference simulations. This requires representations that describe any molecule or material and support interpolation. We comprehensively review and discuss current representations and relations between them. For selected state-of-the-art representations, we compare energy predictions for organic molecules, binary alloys, and Al--Ga--In sesquioxides in numerical experiments controlled for data distribution, regression method, and hyper-parameter optimization.},
issn={2057-3960},
doi={10.1038/s41524-022-00721-x},
url={https://doi.org/10.1038/s41524-022-00721-x}
}


@misc{conda_forge,
  author       = {conda-forge community},
  title        = {{The conda-forge Project: Community-based Software
                   Distribution Built on the conda Package Format and
                   Ecosystem}},
  month        = jul,
  year         = 2015,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.4774216},
  url          = {https://doi.org/10.5281/zenodo.4774216},
  note         = {{Z}enodo. https://doi.org/10.5281/zenodo.4774217}
}

@article{ase-paper,
  author="Ask Hjorth Larsen and Jens J{\o}rgen Mortensen and Jakob Blomqvist and Ivano E Castelli and Rune Christensen and Marcin
Du{\l}ak and Jesper Friis and Michael N Groves and Bj{\o}rk Hammer and Cory Hargus and Eric D Hermes and Paul C Jennings and Peter
Bjerre Jensen and James Kermode and John R Kitchin and Esben Leonhard Kolsbjerg and Joseph Kubal and Kristen
Kaasbjerg and Steen Lysgaard and J{\'o}n Bergmann Maronsson and Tristan Maxson and Thomas Olsen and Lars Pastewka and Andrew
Peterson and Carsten Rostgaard and Jakob Schi{\o}tz and Ole Sch{\"u}tt and Mikkel Strange and Kristian S Thygesen and Tejs
Vegge and Lasse Vilhelmsen and Michael Walter and Zhenhua Zeng and Karsten W Jacobsen",
  title="The atomic simulation environment -- a {P}ython library for working with atoms",
  journal={J. Phys. Condens. Matter},
  volume={29},
  number={27},
pages={273002},
  year={2017},
}
@article{numpy,
 title         = {Array programming with {NumPy}},
 author        = {Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J.
                 van der Walt and Ralf Gommers and Pauli Virtanen and David
                 Cournapeau and Eric Wieser and Julian Taylor and Sebastian
                 Berg and Nathaniel J. Smith and Robert Kern and Matti Picus
                 and Stephan Hoyer and Marten H. van Kerkwijk and Matthew
                 Brett and Allan Haldane and Jaime Fern{\'{a}}ndez del
                 R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre
                 G{\'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and
                 Warren Weckesser and Hameer Abbasi and Christoph Gohlke and
                 Travis E. Oliphant},
 year          = {2020},
 month         = sep,
 journal       = {Nature},
 volume        = {585},
 number        = {7825},
 pages         = {357--362},
 doi           = {10.1038/s41586-020-2649-2},
 publisher     = {Springer Science and Business Media {LLC}},
 url           = {https://doi.org/10.1038/s41586-020-2649-2}
}
@article{scipy,
  author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
            Haberland, Matt and Reddy, Tyler and Cournapeau, David and
            Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and
            Bright, Jonathan and {van der Walt}, St{\'e}fan J. and
            Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and
            Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and
            Kern, Robert and Larson, Eric and Carey, C J and
            Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and
            {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and
            Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and
            Harris, Charles R. and Archibald, Anne M. and
            Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and
            {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
            Computing in Python}},
  journal = {Nat. Methods},
  year    = {2020},
  volume  = {17},
  pages   = {261--272},
  adsurl  = {https://rdcu.be/b08Wh},
  doi     = {10.1038/s41592-019-0686-2},
}

@misc{pybind11,
   author = {Wenzel Jakob and Jason Rhinelander and Dean Moldovan},
   year = {2017},
   note = {https://github.com/pybind/pybind11},
   title = {pybind11 -- Seamless operability between {C++11} and {P}ython}
}

@online{pypi,
  title={Python {P}ackage {I}ndex - {PyPI}},
  url={https://pypi.org/},
  note={{h}ttps://pypi.org/},
  urldate = {2021-03-28},
  publisher={Python Software Foundation}
}

@article{bisbo2020efficient,
  title = {Efficient Global Structure Optimization with a Machine-Learned Surrogate Model},
  author = {Bisbo, Malthe K. and Hammer, Bj\o{}rk},
  journal = {Phys. Rev. Lett.},
  volume = {124},
  issue = {8},
  pages = {086102},
  numpages = {6},
  year = {2020},
  month = {Feb},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.124.086102},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.124.086102}
}

@article{arrigoni2021evolutionary,
author={Arrigoni, Marco
and Madsen, Georg K. H.},
title={Evolutionary computing and machine learning for discovering of low-energy defect configurations},
journal={npj Comput. Mater.},
year={2021},
month={May},
day={20},
volume={7},
number={1},
pages={71},
abstract={Density functional theory (DFT) has become a standard tool for the study of point defects in materials. However, finding the most stable defective structures remains a very challenging task as it involves the solution of a multimodal optimization problem with a high-dimensional objective function. Hitherto, the approaches most commonly used to tackle this problem have been mostly empirical, heuristic, and/or based on domain knowledge. In this contribution, we describe an approach for exploring the potential energy surface (PES) based on the covariance matrix adaptation evolution strategy (CMA-ES) and supervised and unsupervised machine learning models. The resulting algorithm depends only on a limited set of physically interpretable hyperparameters and the approach offers a systematic way for finding low-energy configurations of isolated point defects in solids. We demonstrate its applicability on different systems and show its ability to find known low-energy structures and discover additional ones as well.},
issn={2057-3960},
doi={10.1038/s41524-021-00537-1},
url={https://doi.org/10.1038/s41524-021-00537-1}
}

@article{fung2021benchmarking,
author={Fung, Victor
and Zhang, Jiaxin
and Juarez, Eric
and Sumpter, Bobby G.},
title={Benchmarking graph neural networks for materials chemistry},
journal={npj Comput. Mater.},
year={2021},
month={Jun},
day={03},
volume={7},
number={1},
pages={84},
abstract={Graph neural networks (GNNs) have received intense interest as a rapidly expanding class of machine learning models remarkably well-suited for materials applications. To date, a number of successful GNNs have been proposed and demonstrated for systems ranging from crystal stability to electronic property prediction and to surface chemistry and heterogeneous catalysis. However, a consistent benchmark of these models remains lacking, hindering the development and consistent evaluation of new models in the materials field. Here, we present a workflow and testing platform, MatDeepLearn, for quickly and reproducibly assessing and comparing GNNs and other machine learning models. We use this platform to optimize and evaluate a selection of top performing GNNs on several representative datasets in computational materials chemistry. From our investigations we note the importance of hyperparameter selection and find roughly similar performances for the top models once optimized. We identify several strengths in GNNs over conventional models in cases with compositionally diverse datasets and in its overall flexibility with respect to inputs, due to learned rather than defined representations. Meanwhile several weaknesses of GNNs are also observed including high data requirements, and suggestions for further improvement for applications in materials chemistry are discussed.},
issn={2057-3960},
doi={10.1038/s41524-021-00554-0},
url={https://doi.org/10.1038/s41524-021-00554-0}
}

@article{zhou2022machine,
title = {Machine learning assisted design of FeCoNiCrMn high-entropy alloys with ultra-low hydrogen diffusion coefficients},
journal = {Acta Mater.},
volume = {224},
pages = {117535},
year = {2022},
issn = {1359-6454},
doi = {https://doi.org/10.1016/j.actamat.2021.117535},
url = {https://www.sciencedirect.com/science/article/pii/S1359645421009137},
author = {Xiao-Ye Zhou and Ji-Hua Zhu and Yuan Wu and Xu-Sheng Yang and Turab Lookman and Hong-Hui Wu},
keywords = {Machine learning, High entropy alloy, Hydrogen embrittlement, Material design},
abstract = {The broad compositional space of high entropy alloys (HEA) is conducive to the design of HEAs with targeted performance. Herein, a data-driven and machine learning (ML) assisted prediction and optimization strategy is proposed to explore the prototype FeCoNiCrMn HEAs with low hydrogen diffusion coefficients. The model for predicting hydrogen solution energies from local HEA chemical environments was constructed via ML algorithms. Based on the inferred correlation between atomic structures and diffusion coefficients of HEAs built using ML models and kinetic Monte Carlo simulations, we employed the whale optimization algorithm to explore HEA atomic structures with low hydrogen diffusion coefficients. HEAs with low H diffusion coefficients were found to have high Co and Mn content. Finally, a quantitative relationship between the diffusion coefficient and chemical composition is proposed to guide the design of HEAs with low H diffusion coefficients and thus strong resistance to hydrogen embrittlement.}
}

@article{pihlajamaki2020monte,
author={Pihlajam{\"a}ki, Antti
and H{\"a}m{\"a}l{\"a}inen, Joonas
and Linja, Joakim
and Nieminen, Paavo
and Malola, Sami
and K{\"a}rkk{\"a}inen, Tommi
and H{\"a}kkinen, Hannu},
title={Monte Carlo Simulations of \ce{Au38(SCH3)24} Nanocluster Using Distance-Based Machine Learning Methods},
journal={J. Phys. Chem. A},
year={2020},
month={Jun},
day={11},
publisher={American Chemical Society},
volume={124},
number={23},
pages={4827-4836},
issn={1089-5639},
doi={10.1021/acs.jpca.0c01512},
url={https://doi.org/10.1021/acs.jpca.0c01512}
}

@article{rahaman2020deep,
author = {Rahaman, Obaidur and Gagliardi, Alessio},
title = {Deep Learning Total Energies and Orbital Energies of Large Organic Molecules Using Hybridization of Molecular Fingerprints},
journal = {J. Chem. Inf. Model.},
volume = {60},
number = {12},
pages = {5971-5983},
year = {2020},
doi = {10.1021/acs.jcim.0c00687},
comment_note ={PMID: 33118351},

URL = {
        https://doi.org/10.1021/acs.jcim.0c00687

},
}

@article{sun2022machine,
author = {Sun, Qintao and Xiang, Yan and Liu, Yue and Xu, Liang and Leng, Tianle and Ye, Yifan and Fortunelli, Alessandro and Goddard, William A III and Cheng, Tao},
title = {Machine Learning Predicts the X-ray Photoelectron Spectroscopy of the Solid Electrolyte Interface of Lithium Metal Battery},
journal = {J. Phys. Chem. Lett.},
volume = {13},
number = {34},
pages = {8047-8054},
year = {2022},
doi = {10.1021/acs.jpclett.2c02222},
comment_note ={PMID: 35994432},

URL = {
        https://doi.org/10.1021/acs.jpclett.2c02222
},
}

@article{hirai2022machine-learning,
  title = {Machine-learning-based prediction of first-principles XANES spectra for amorphous materials},
  author = {Hirai, Haruki and Iizawa, Takumi and Tamura, Tomoyuki and Karasuyama, Masayuki and Kobayashi, Ryo and Hirose, Takakazu},
  journal = {Phys. Rev. Mater.},
  volume = {6},
  issue = {11},
  pages = {115601},
  numpages = {11},
  year = {2022},
  month = {Nov},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevMaterials.6.115601},
  url = {https://link.aps.org/doi/10.1103/PhysRevMaterials.6.115601}
}

@article{lourenco2021taking,
author={Louren{\c{c}}o, Maicon Pierre
and Herrera, Lizandra Barrios
and Hosta{\v{s}}, Ji{\v{r}}{\'i}
and Calaminici, Patrizia
and K{\"o}ster, Andreas M.
and Tchagang, Alain
and Salahub, Dennis R.},
title={Taking the multiplicity inside the loop: active learning for structural and spin multiplicity elucidation of atomic clusters},
journal={Theor. Chem. Acc.},
year={2021},
month={Aug},
day={02},
volume={140},
number={8},
pages={116},
abstract={Active learning (AL) has been successfully applied in materials science for the global optimization of clusters and defects in materials. Many important chemistry problems require the structural elucidation of molecules as a first step to the mechanistic elucidation of complex heterogeneous catalysis phenomena. Theoretical methods coupled with global optimization algorithms are successfully used for this purpose. However, it is challenging to find the global minimum structure together with the proper electronic spin multiplicity. In this work, we present an AL implementation for global optimization of atomic clusters where the spin multiplicity is considered in the search loop (SM@AL). The method was implemented in the QMLMaterial software, interfaced with the deMon2k program to perform local structure optimizations. In this work, we present applications of SM@AL for the global optimization, in terms of molecular structure and electronic spin of 3Al@Si11, where Si11 is doped by 3 Al, and Mo4C2 with spin multiplicities 2, 4 and 6 and 1, 3, 5, 7, 9 and 11, respectively.},
issn={1432-2234},
doi={10.1007/s00214-021-02820-2},
url={https://doi.org/10.1007/s00214-021-02820-2}
}

@article{sun2021ab,
author={Sun, Liang
and Zhou, Yu-Xing
and Wang, Xu-Dong
and Chen, Yu-Han
and Deringer, Volker L.
and Mazzarello, Riccardo
and Zhang, Wei},
title={Ab initio molecular dynamics and materials design for embedded phase-change memory},
journal={npj Comput. Mater.},
year={2021},
month={Feb},
day={08},
volume={7},
number={1},
pages={29},
abstract={The Ge2Sb2Te5 alloy has served as the core material in phase-change memories with high switching speed and persistent storage capability at room temperature. However widely used, this composition is not suitable for embedded memories---for example, for automotive applications, which require very high working temperatures above 300{\thinspace}{\textdegree}C. Ge--Sb--Te alloys with higher Ge content, most prominently Ge2Sb1Te2 (`212'), have been studied as suitable alternatives, but their atomic structures and structure--property relationships have remained widely unexplored. Here, we report comprehensive first-principles simulations that give insight into those emerging materials, located on the compositional tie-line between Ge2Sb1Te2 and elemental Ge, allowing for a direct comparison with the established Ge2Sb2Te5 material. Electronic-structure computations and smooth overlap of atomic positions (SOAP) similarity analyses explain the role of excess Ge content in the amorphous phases. Together with energetic analyses, a compositional threshold is identified for the viability of a homogeneous amorphous phase (`zero bit'), which is required for memory applications. Based on the acquired knowledge at the atomic scale, we provide a materials design strategy for high-performance embedded phase-change memories with balanced speed and stability, as well as potentially good cycling capability.},
issn={2057-3960},
doi={10.1038/s41524-021-00496-7},
url={https://doi.org/10.1038/s41524-021-00496-7}
}

@article{cheng2020mapping,
author = {Cheng, Bingqing and Griffiths, Ryan-Rhys and Wengert, Simon and Kunkel, Christian and Stenczel, Tamas and Zhu, Bonan and Deringer, Volker L. and Bernstein, Noam and Margraf, Johannes T. and Reuter, Karsten and Csanyi, Gabor},
title = {Mapping Materials and Molecules},
journal = {Acc. Chem. Res.},
volume = {53},
number = {9},
pages = {1981-1991},
year = {2020},
doi = {10.1021/acs.accounts.0c00403},
comment_note ={PMID: 32794697},

URL = {
        https://doi.org/10.1021/acs.accounts.0c00403
},
}

@article{monserrat2020liquid,
author={Monserrat, Bartomeu
and Brandenburg, Jan Gerit
and Engel, Edgar A.
and Cheng, Bingqing},
title={Liquid water contains the building blocks of diverse ice phases},
journal={Nat. Commun.},
year={2020},
month={Nov},
day={13},
volume={11},
number={1},
pages={5757},
abstract={Water molecules can arrange into a liquid with complex hydrogen-bond networks and at least 17 experimentally confirmed ice phases with enormous structural diversity. It remains a puzzle how or whether this multitude of arrangements in different phases of water are related. Here we investigate the structural similarities between liquid water and a comprehensive set of 54 ice phases in simulations, by directly comparing their local environments using general atomic descriptors, and also by demonstrating that a machine-learning potential trained on liquid water alone can predict the densities, lattice energies, and vibrational properties of the ices. The finding that the local environments characterising the different ice phases are found in water sheds light on the phase behavior of water, and rationalizes the transferability of water models between different phases.},
issn={2041-1723},
doi={10.1038/s41467-020-19606-y},
url={https://doi.org/10.1038/s41467-020-19606-y}
}

@article{valle2010crystal,
author = "Valle, Mario and Oganov, Artem R.",
title = "{Crystal fingerprint space {--} a novel paradigm for studying crystal-structure sets}",
journal = "Acta Crystallogr. A",
year = "2010",
volume = "66",
number = "5",
pages = "507--517",
month = "Sep",
doi = {10.1107/S0108767310026395},
url = {https://doi.org/10.1107/S0108767310026395},
abstract = {The initial aim of the crystal fingerprint project was to solve a very specific problem: to classify and remove duplicate crystal structures from the results generated by the evolutionary crystal-structure predictor {\it USPEX}. These duplications decrease the genetic diversity of the population used by the evolutionary algorithm, potentially leading to stagnation and, after a certain time, reducing the likelihood of predicting essentially new structures. After solving the initial problem, the approach led to unexpected discoveries: unforeseen correlations, useful derived quantities and insight into the structure of the overall set of results. All of these were facilitated by the project's underlying idea: to transform the structure sets from the physical configuration space to an abstract, high-dimensional space called the fingerprint space. Here every structure is represented as a point whose coordinates (fingerprint) are computed from the crystal structure. Then the space's distance measure, interpreted as structure `closeness', enables grouping of structures into similarity classes. This model provides much flexibility and facilitates access to knowledge and algorithms from fields outside crystallography, {\it e.g.} pattern recognition and data mining. The current usage of the fingerprint-space model is revealing interesting properties that relate to chemical and crystallographic attributes of a structure set. For this reason, the mapping of structure sets to fingerprint space could become a new paradigm for studying crystal-structure ensembles and global chemical features of the energy landscape.},
keywords = {crystal fingerprints, USPEX, structure classification, fingerprint space},
}

@article{behler2007generalized,
  title = {Generalized Neural-Network Representation of High-Dimensional Potential-Energy Surfaces},
  author = {Behler, J\"org and Parrinello, Michele},
  journal = {Phys. Rev. Lett.},
  volume = {98},
  issue = {14},
  pages = {146401},
  numpages = {4},
  year = {2007},
  month = {Apr},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.98.146401},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.98.146401}
}

@article{bartok2010gaussian,
  title = {Gaussian Approximation Potentials: The Accuracy of Quantum Mechanics, without the Electrons},
  author = {Bart\'ok, Albert P. and Payne, Mike C. and Kondor, Risi and Cs\'anyi, G\'abor},
  journal = {Phys. Rev. Lett.},
  volume = {104},
  issue = {13},
  pages = {136403},
  numpages = {4},
  year = {2010},
  month = {Apr},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.104.136403},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.104.136403}
}

@article{schutt2018schnet,
author = {Schütt,K. T.  and Sauceda,H. E.  and Kindermans,P.-J.  and Tkatchenko,A.  and Müller,K.-R. },
title = {{SchNet} – {A} deep learning architecture for molecules and materials},
journal = {J. Chem. Phys.},
volume = {148},
number = {24},
pages = {241722},
year = {2018},
doi = {10.1063/1.5019779},
URL = {
        https://doi.org/10.1063/1.5019779
},
}

@article{himanen2020dscribe,
title = {DScribe: Library of descriptors for machine learning in materials science},
journal = {Comput. Phys. Commun.},
volume = {247},
pages = {106949},
year = {2020},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2019.106949},
url = {https://www.sciencedirect.com/science/article/pii/S0010465519303042},
author = {Lauri Himanen and Marc O.J. Jäger and Eiaki V. Morooka and Filippo {Federici Canova} and Yashasvi S. Ranawat and David Z. Gao and Patrick Rinke and Adam S. Foster},
keywords = {Machine learning, Materials science, Descriptor, Python, Open source},
abstract = {DScribe is a software package for machine learning that provides popular feature transformations (“descriptors”) for atomistic materials simulations. DScribe accelerates the application of machine learning for atomistic property prediction by providing user-friendly, off-the-shelf descriptor implementations. The package currently contains implementations for Coulomb matrix, Ewald sum matrix, sine matrix, Many-body Tensor Representation (MBTR), Atom-centered Symmetry Function (ACSF) and Smooth Overlap of Atomic Positions (SOAP). Usage of the package is illustrated for two different applications: formation energy prediction for solids and ionic charge prediction for atoms in organic molecules. The package is freely available under the open-source Apache License 2.0.
Program summary
Program Title: DScribe Program Files doi: http://dx.doi.org/10.17632/vzrs8n8pk6.1 Licensing provisions: Apache-2.0 Programming language: Python/C/C++ Supplementary material: Supplementary Information as PDF Nature of problem: The application of machine learning for materials science is hindered by the lack of consistent software implementations for feature transformations. These feature transformations, also called descriptors, are a key step in building machine learning models for property prediction in materials science. Solution method: We have developed a library for creating common descriptors used in machine learning applied to materials science. We provide an implementation the following descriptors: Coulomb matrix, Ewald sum matrix, sine matrix, Many-body Tensor Representation (MBTR), Atom-centered Symmetry Functions (ACSF) and Smooth Overlap of Atomic Positions (SOAP). The library has a python interface with computationally intensive routines written in C or C++. The source code, tutorials and documentation are provided online. A continuous integration mechanism is set up to automatically run a series of regression tests and check code coverage when the codebase is updated.}
}

@article{rupp2012fast,
  title = {Fast and Accurate Modeling of Molecular Atomization Energies with Machine Learning},
  author = {Rupp, Matthias and Tkatchenko, Alexandre and M\"uller, Klaus-Robert and von Lilienfeld, O. Anatole},
  journal = {Phys. Rev. Lett.},
  volume = {108},
  issue = {5},
  pages = {058301},
  numpages = {5},
  year = {2012},
  month = {Jan},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.108.058301},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.108.058301}
}

@article{faber2015crystal,
author = {Faber, Felix and Lindmaa, Alexander and von Lilienfeld, O. Anatole and Armiento, Rickard},
title = {Crystal structure representations for machine learning models of formation energies},
journal = {Int. J. Quantum Chem.},
volume = {115},
number = {16},
pages = {1094-1101},
year = {2015},
keywords = {machine learning, formation energies, representations, crystal structure, periodic systems},
doi = {https://doi.org/10.1002/qua.24917},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/qua.24917},
abstract = {We introduce and evaluate a set of feature vector representations of crystal structures for machine learning (ML) models of formation energies of solids. ML models of atomization energies of organic molecules have been successful using a Coulomb matrix representation of the molecule. We consider three ways to generalize such representations to periodic systems: (i) a matrix where each element is related to the Ewald sum of the electrostatic interaction between two different atoms in the unit cell repeated over the lattice; (ii) an extended Coulomb-like matrix that takes into account a number of neighboring unit cells; and (iii) an ansatz that mimics the periodicity and the basic features of the elements in the Ewald sum matrix using a sine function of the crystal coordinates of the atoms. The representations are compared for a Laplacian kernel with Manhattan norm, trained to reproduce formation energies using a dataset of 3938 crystal structures obtained from the Materials Project. For training sets consisting of 3000 crystals, the generalization error in predicting formation energies of new structures corresponds to (i) 0.49, (ii) 0.64, and (iii) for the respective representations. © 2015 Wiley Periodicals, Inc.},
}

@article{huo2017unified,
  title={Unified Representation of Molecules and Crystals for Machine Learning},
  author={Huo, Haoyan and Rupp, Matthias},
  journal={arXiv:1704.06439},
  year={2017}
}

@article{behler2011atom-centered,
author = {Behler,Jörg },
title = {Atom-centered symmetry functions for constructing high-dimensional neural network potentials},
journal = {J. Chem. Phys.},
volume = {134},
number = {7},
pages = {074106},
year = {2011},
doi = {10.1063/1.3553717},
URL = {
        https://doi.org/10.1063/1.3553717
},
}

@article{bartok2013on,
  title = {On representing chemical environments},
  author = {Bart\'ok, Albert P. and Kondor, Risi and Cs\'anyi, G\'abor},
  journal = {Phys. Rev. B},
  volume = {87},
  issue = {18},
  pages = {184115},
  numpages = {16},
  year = {2013},
  month = {May},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevB.87.184115},
  url = {https://link.aps.org/doi/10.1103/PhysRevB.87.184115}
}

@article{bisbo2022global,
  title = {Global optimization of atomic structure enhanced by machine learning},
  author = {Bisbo, Malthe K. and Hammer, Bj\o{}rk},
  journal = {Phys. Rev. B},
  volume = {105},
  issue = {24},
  pages = {245404},
  numpages = {15},
  year = {2022},
  month = {Jun},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevB.105.245404},
  url = {https://link.aps.org/doi/10.1103/PhysRevB.105.245404}
}

@article{foiles1986embedded-atom-method,
  title = {Embedded-atom-method functions for the fcc metals \ce{Cu}, \ce{Ag}, \ce{Au}, \ce{Ni}, \ce{Pd}, \ce{Pt}, and their alloys},
  author = {Foiles, S. M. and Baskes, M. I. and Daw, M. S.},
  journal = {Phys. Rev. B},
  volume = {33},
  issue = {12},
  pages = {7983--7991},
  numpages = {0},
  year = {1986},
  month = {Jun},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevB.33.7983},
  url = {https://link.aps.org/doi/10.1103/PhysRevB.33.7983}
}

@article{thompson2022lammps,
title = {{LAMMPS} - a flexible simulation tool for particle-based materials modeling at the atomic, meso, and continuum scales},
journal = {Comput. Phys. Commun.},
volume = {271},
pages = {108171},
year = {2022},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2021.108171},
url = {https://www.sciencedirect.com/science/article/pii/S0010465521002836},
author = {Aidan P. Thompson and H. Metin Aktulga and Richard Berger and Dan S. Bolintineanu and W. Michael Brown and Paul S. Crozier and Pieter J. {in 't Veld} and Axel Kohlmeyer and Stan G. Moore and Trung Dac Nguyen and Ray Shan and Mark J. Stevens and Julien Tranchida and Christian Trott and Steven J. Plimpton},
keywords = {Molecular dynamics, Materials modeling, Parallel algorithms, LAMMPS},
abstract = {Since the classical molecular dynamics simulator LAMMPS was released as an open source code in 2004, it has become a widely-used tool for particle-based modeling of materials at length scales ranging from atomic to mesoscale to continuum. Reasons for its popularity are that it provides a wide variety of particle interaction models for different materials, that it runs on any platform from a single CPU core to the largest supercomputers with accelerators, and that it gives users control over simulation details, either via the input script or by adding code for new interatomic potentials, constraints, diagnostics, or other features needed for their models. As a result, hundreds of people have contributed new capabilities to LAMMPS and it has grown from fifty thousand lines of code in 2004 to a million lines today. In this paper several of the fundamental algorithms used in LAMMPS are described along with the design strategies which have made it flexible for both users and developers. We also highlight some capabilities recently added to the code which were enabled by this flexibility, including dynamic load balancing, on-the-fly visualization, magnetic spin dynamics models, and quantum-accuracy machine learning interatomic potentials.
Program Summary
Program Title: Large-scale Atomic/Molecular Massively Parallel Simulator (LAMMPS) CPC Library link to program files: https://doi.org/10.17632/cxbxs9btsv.1 Developer's repository link: https://github.com/lammps/lammps Licensing provisions: GPLv2 Programming language: C++, Python, C, Fortran Supplementary material: https://www.lammps.org Nature of problem: Many science applications in physics, chemistry, materials science, and related fields require parallel, scalable, and efficient generation of long, stable classical particle dynamics trajectories. Within this common problem definition, there lies a great diversity of use cases, distinguished by different particle interaction models, external constraints, as well as timescales and lengthscales ranging from atomic to mesoscale to macroscopic. Solution method: The LAMMPS code uses parallel spatial decomposition, distributed neighbor lists, and parallel FFTs for long-range Coulombic interactions [1]. The time integration algorithm is based on the Størmer-Verlet symplectic integrator [2], which provides better stability than higher-order non-symplectic methods. In addition, LAMMPS supports a wide range of interatomic potentials, constraints, diagnostics, software interfaces, and pre- and post-processing features. Additional comments including restrictions and unusual features: This paper serves as the definitive reference for the LAMMPS code.
References
[1]S. Plimpton, Fast parallel algorithms for short-range molecular dynamics. J. Comp. Phys. 117 (1995) 1–19.[2]L. Verlet, Computer experiments on classical fluids: I. Thermodynamical properties of Lennard–Jones molecules, Phys. Rev. 159 (1967) 98–103.}
}

@article{hoover1985canonical,
  title = {Canonical dynamics: Equilibrium phase-space distributions},
  author = {Hoover, William G.},
  journal = {Phys. Rev. A},
  volume = {31},
  issue = {3},
  pages = {1695--1697},
  numpages = {0},
  year = {1985},
  month = {Mar},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevA.31.1695},
  url = {https://link.aps.org/doi/10.1103/PhysRevA.31.1695}
}

@article{laakso2022compositional,
  title = {Compositional engineering of perovskites with machine learning},
  author = {Laakso, Jarno and Todorović, Milica and Li, Jingrui and Zhang, Guo-Xu and Rinke, Patrick},
  journal = {Phys. Rev. Mater.},
  volume = {6},
  issue = {11},
  pages = {113801},
  numpages = {10},
  year = {2022},
  month = {Nov},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevMaterials.6.113801},
  url = {https://link.aps.org/doi/10.1103/PhysRevMaterials.6.113801}
}

@misc{chollet2015keras,
  title={Keras},
  author={Chollet, Fran\c{c}ois and others},
  year={2015},
  howpublished={\url{https://keras.io}},
}

@article{abadi2015tensorflow,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
journal={arXiv:1603.04467},
comment_note={Software available from tensorflow.org},
author={
    Mart\'{i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}

@article{kingma2014adam,
  comment_doi = {10.48550/ARXIV.1412.6980},
  url = {https://arxiv.org/abs/1412.6980},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  journal = {arXiv.1412.6980},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Adam: A Method for Stochastic Optimization},
  publisher = {arXiv},
  year = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{stuke2019chemical,
author = {Stuke,Annika  and Todorović,Milica  and Rupp,Matthias  and Kunkel,Christian  and Ghosh,Kunal  and Himanen,Lauri  and Rinke,Patrick },
title = {Chemical diversity in molecular orbital energy predictions with kernel ridge regression},
journal = {J. Chem. Phys.},
volume = {150},
number = {20},
pages = {204121},
year = {2019},
doi = {10.1063/1.5086105},
URL = {
        https://doi.org/10.1063/1.5086105
},
}

@article{jiang2021topological,
author={Jiang, Yi
and Chen, Dong
and Chen, Xin
and Li, Tangyi
and Wei, Guo-Wei
and Pan, Feng},
title={Topological representations of crystalline compounds for the machine-learning prediction of materials properties},
journal={npj Comput. Mater.},
year={2021},
month={Feb},
day={05},
volume={7},
number={1},
pages={28},
abstract={Accurate theoretical predictions of desired properties of materials play an important role in materials research and development. Machine learning (ML) can accelerate the materials design by building a model from input data. For complex datasets, such as those of crystalline compounds, a vital issue is how to construct low-dimensional representations for input crystal structures with chemical insights. In this work, we introduce an algebraic topology-based method, called atom-specific persistent homology (ASPH), as a unique representation of crystal structures. The ASPH can capture both pairwise and many-body interactions and reveal the topology-property relationship of a group of atoms at various scales. Combined with composition-based attributes, ASPH-based ML model provides a highly accurate prediction of the formation energy calculated by density functional theory (DFT). After training with more than 30,000 different structure types and compositions, our model achieves a mean absolute error of 61{\thinspace}meV/atom in cross-validation, which outperforms previous work such as Voronoi tessellations and Coulomb matrix method using the same ML algorithm and datasets. Our results indicate that the proposed topology-based method provides a powerful computational tool for predicting materials properties compared to previous works.},
issn={2057-3960},
doi={10.1038/s41524-021-00493-w},
url={https://doi.org/10.1038/s41524-021-00493-w}
}

@article{de2016comparing,
  title={Comparing molecules and solids across structural and alchemical space},
  author={De, Sandip and Bart{\'o}k, Albert P and Cs{\'a}nyi, G{\'a}bor and Ceriotti, Michele},
  journal={Phys. Chem. Chem. Phys.},
  volume={18},
  number={20},
  pages={13754--13769},
  year={2016},
  publisher={Royal Society of Chemistry}
}
