\section{Related Work}
\noindent\textbf{Diffusion Models.}
%
Diffusion models~\cite{ho2020ddpm, sohl2015deep, song2020score, rombach2022ldm, gu2022vqdiffusion, song2020ddim} have become a mainstream approach for image synthesis~\cite{dhariwal2021beatgan, esser2021imagebart, meng2021sdedit} apart from GANs~\cite{goodfellow2014gan}, 
%
and have shown success in various domains such as video generation~\cite{harvey2022fdm,villegas2022phenaki,singer2022makeavideo,ho2022videoDM}, image restoration~\cite{saharia2022sr3, ho2022cascaded}, and many more~\cite{baranchuk2021label,graikos2022diffusion, amit2021segdiff, austin2021structured}.
%
In the diffusion-based approach, models are trained using score-matching objectives~\cite{hyvarinen2005estimation, vincent2011connection} at various noise levels, and sampling is done via iterative denoising. 
%
Text-to-Image (T2I) diffusion models~\cite{ramesh2022dalle2, rombach2022ldm, esser2021imagebart, gu2022vqdiffusion, jiang2022text2human, nichol2021glide, saharia2022imagen} demonstrated impressive results in converting a user-provided text description into images. 
%
Motivated by their success, we build our framework on a state-of-the-art T2I diffusion model, Stable Diffusion~\cite{rombach2022ldm}.



% Framework Figure
\begin{figure*}[t]
  \centering
   \includegraphics[width=0.99\textwidth]{figures/fig_framework.pdf}
    \vspace{-5pt}
   \caption{\textbf{ReVersion Framework}. Given exemplar images and their entities' coarse descriptions, our ReVersion framework optimizes the relation prompt \R to capture the relation that co-exists in all the exemplar images. During optmization, the \textit{relation-focal importance sampling} strategy encourages \R to focus on high-level relations, and the \textit{relation-steering contrastive learning} scheme induces the relation prompt \R towards our \textit{preposition prior} and away from entities or appearances. Upon optimization, \R can be used as a word in new sentences to make novel entities interact via the relation in exemplar images. 
   }
   \label{fig:framework}
\end{figure*}



\noindent\textbf{Relation Modeling.}
%
Relation modeling has been explored in discriminative tasks such as scene graph generation~\cite{xu2017scene,vg17ijcv,shang2017video,ji2020action, yang2022psg, yang2023pvsg} and visual relationship detection~\cite{lu2016visual, yu2017visual, zhuang2017towards}.
These works aim to detect visual relations between objects in given images and classify them into a predefined, closed-set of relations.
However, the finite relation category set intrinsically limits the diversity of captured relations.
In contrast, Relation Inversion regards relation modeling as a generative task, aiming to capture arbitrary, open-world relations from exemplar images and apply the resulting relation for content creation.



\noindent\textbf{Diffusion-Based Inversion.} Given a pre-trained T2I diffusion model, inversion~\cite{gal2022textualinversion, ruiz2022dreambooth, kumari2022customdiffusion, kawar2022imagic} aims to find a text embedding vector to express the concepts in the given exemplar images. 
%
For example, given several images of a particular \textit{``cat statue''}, 
Textual Inversion~\cite{gal2022textualinversion} learns a new word to describe the appearance of this item - finding a vector in LDM~\cite{rombach2022ldm}'s text embedding space, so that the new word can be composed into new sentences to achieve personalized creation.
Rather than inverting the appearance information (\eg, color, texture), our proposed \textbf{\textit{Relation Inversion}} task extracts high-level object relations from exemplar images, which is a harder problem as it requires comprehending image compositions and object relationships.
