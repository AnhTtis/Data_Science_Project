\section{Conclusion}

In this work, we take the first step forward and propose the \textbf{\textit{Relation Inversion}} task, which aims to learn a relation prompt to capture the relation that co-exists in multiple exemplar images. Motivated by the \textbf{\textit{preposition prior}}, our \textit{relation-steering contrastive learning} scheme effectively guides the relation prompt towards relation-dense regions in the text embedding space. We also contribute the \textbf{\textit{ReVersion Benchmark}} for performance evaluation. Our proposed \textbf{\textit{Relation Inversion}} task would be a good inspiration for future works in various domains such as generative model inversion, representation learning, few-shot learning, visual relation detection, and scene graph generation.

\noindent \textbf{Limitations}.
Our performance is dependent on the generative capabilities of Stable Diffusion. It might produce sub-optimal synthesis results for entities that Stable Diffusion struggles at, such as human body and human face. 


\noindent\textbf{Potential Negative Societal Impacts}.
The entity relational composition capabilities of \textit{ReVersion} could be applied maliciously on real human figures.
