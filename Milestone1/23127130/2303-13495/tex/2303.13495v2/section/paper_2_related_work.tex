\section{Related Work}


% Framework Figure
\begin{figure*}[t]
  \centering
  \vspace{6pt}
   \includegraphics[width=0.99\textwidth]{figures/fig_framework.pdf}
   \caption{\textbf{ReVersion Framework}. Given exemplar images and their entities' coarse descriptions, our ReVersion framework optimizes the relation prompt \R{} to capture the relation that co-exists in all the exemplar images. During optmization, the \textit{relation-focal importance sampling} strategy encourages \R{} to focus on high-level relations, and the \textit{relation-steering contrastive learning} scheme induces the relation prompt \R{} towards relation-dense regions and away from entities or appearances. Upon optimization, \R{} can be used as a word in new sentences to make novel entities interact via the relation in exemplar images. 
   }
   \label{fig:framework}
   \vspace{6pt}
\end{figure*}



\noindent\textbf{Diffusion Models.}
%
Diffusion models~\cite{ho2020ddpm, sohl2015deep, song2020score, rombach2022ldm, gu2022vqdiffusion, song2020ddim} have become a mainstream approach for image synthesis~\cite{dhariwal2021beatgan, esser2021imagebart, meng2021sdedit} apart from GANs~\cite{goodfellow2014gan}, 
%
and have shown success in various domains such as video generation~\cite{harvey2022fdm,villegas2022phenaki,singer2022makeavideo,ho2022videoDM, he2022lvdm, wu2022tuneavideo, blattmann2023videoldm}, image restoration~\cite{saharia2022sr3, ho2022cascaded}, and many more~\cite{baranchuk2021label,graikos2022diffusion, amit2021segdiff, austin2021structured}.
%
Diffusion models are usually trained using score-matching objectives~\cite{hyvarinen2005estimation, vincent2011connection} at various noise levels, and sampling is done via iterative denoising. 
%
Text-to-Image (T2I) diffusion models~\cite{ramesh2022dalle2, rombach2022ldm, esser2021imagebart, gu2022vqdiffusion, jiang2022text2human, nichol2021glide, saharia2022imagen} demonstrated impressive results in converting user-provided text descriptions into images. 
% 
%
Motivated by their success, we build our framework on a state-of-the-art T2I diffusion model, Stable Diffusion~\cite{rombach2022ldm}.






\noindent\textbf{Relation Modeling.}
%
Relation modeling has been explored in discriminative tasks such as scene graph generation~\cite{xu2017scene,vg17ijcv,shang2017video,ji2020action, yang2022psg, yang2023pvsg} and visual relationship detection~\cite{lu2016visual, yu2017visual, zhuang2017towards}.
These works aim to detect visual relations between objects in given images and classify them into a predefined, closed-set of relations.
However, the finite relation category set intrinsically limits the diversity of captured relations.
In contrast, \RI{} regards relation modeling as a generative task, aiming to capture arbitrary, open-world relations from exemplar images and apply the resulting relation for content creation.



\noindent\textbf{Diffusion-Based Inversion.} Given a pre-trained T2I diffusion model, \textit{inversion} aims to find a text embedding vector to express the concepts in the given exemplar images, via optimization-based~\extension{\cite{gal2022textualinversion, ruiz2022dreambooth, kumari2022customdiffusion, li2023generate, han2023svdiff, hu2022lora, choi2023custom, kawar2022imagic, voynov2023p+,alaluf2023neural}}, encoder-based~\cite{wei2023elite, jia2023tamingencoder, xu2023prompt, zhou2023enhancing, ma2023subject, ye2023ip}, or hybrid~\extension{\cite{gal2023encoder, chen2023disenbooth, gong2023talecrafter, arar2023domain, li2023blipdiffusion, ruiz2024hyperdreambooth}} approaches.
%
For example, given several images of a particular \textit{``cat statue''}, 
Textual Inversion~\cite{gal2022textualinversion} learns a new word to describe its appearance - finding a vector in Latent Diffusion Model (LDM)~\cite{rombach2022ldm}'s text embedding space, so that the new word can be composed into new sentences to achieve personalized creation.
Rather than inverting the appearance information (\eg, color, texture), our proposed \RI{} task extracts high-level object \textit{relations} from exemplar images, 
%
which can be harder as it requires comprehending image compositions and object relationships.

