

\section{The Relation Inversion Task}


\RI{} aims to extract the common relation \R{} from several exemplar images.
%
Let $\mathcal{I}\,{=}\, \{I_{1}, I_{2}, ... I_{n}\}$ be a set of exemplar images, and $E_{i,A}$ and $E_{i,B}$ be two dominant entities in image $I_i$. In \RI{}, we assume that the entities in each exemplar image interacts with each other through a common relation $R$. A set of coarse descriptions ${C}~{=}\, \{c_{1}, c_{2}, ... c_{n}\}$ is associated to the exemplar images, where \mbox{``${c}_i\,{=}\,E_{i, A}$ \R{} 
$E_{i, B}$''} denotes the caption corresponding to image $I_i$. Our objective is to optimize the relation prompt \R{} such that the co-existing relation can be accurately represented by the optimized prompt. 

An immediate application of \RI{} is relation-specific text-to-image synthesis. Once the prompt is acquired, one can generate images with novel objects interacting with each other following the specified relation. More generally, this task reveals a new direction of inferring relations from a set of exemplar images. This could potentially inspire future research in representation learning, few-shot learning, visual relation detection, scene graph generation, and many more.


\section{The ReVersion Framework}


\subsection{Preliminaries}

%-----------------------------------------------
\noindent \textbf{Stable Diffusion.}
%
Diffusion models are a class of generative models that gradually denoise the Gaussian prior $\bx_T$ to the data $\bx_0$ (\eg, a natural image). 
%
The commonly used training objective $L_\mathrm{DM}$~\cite{ho2020ddpm} is:
%
\begin{gather}
    L_\mathrm{DM}(\theta) \defeq \Eb{t, \bx_0, \bepsilon}{ \left\| \bepsilon - \bepsilon_\theta(\bx_t, t) \right\|^2}, \label{eq:training_objective_simple}
\end{gather}
%
where $\bx_t$ is an noisy image constructed by adding noise $\bepsilon \sim \mathcal{N}(\bzero, \bI)$ to the natural image $\bx_0$, and the network $\bepsilon_\theta(\cdot)$ is trained to predict the added noise.
%
To sample data $\bx_0$ from a trained diffusion model $\bepsilon_\theta(\cdot)$, we iteratively denoise $\bx_t$ from $t = T$ to $t = 0$ using the predicted noise $\bepsilon_\theta(\bx_t, t)$ at each timestep $t$.



LDM~\cite{rombach2022ldm}, the predecessor of Stable Diffusion, mainly introduced two changes to the vanilla diffusion model~\cite{ho2020ddpm}. First, instead of directly modeling the natural image distribution, LDM models images' projections in autoencoder's compressed latent space. Second, LDM enables text-to-image generation by feeding encoded text input to the UNet~\cite{ronneberger2015unet} $\bepsilon_\theta(\cdot)$. The LDM loss is:
%
\begin{gather}
    L_\mathrm{LDM}(\theta) \defeq \Eb{t, \bx_0, \bepsilon}{ { \left\| \bepsilon - \bepsilon_\theta(\bx_t, t, \tau_\theta(c)) \right\|^2}}, \label{eq:ldm_loss}
\end{gather}
% 
where $\bx$ is the autoencoder latents for images, and $\tau_\theta(\cdot)$ is the text encoder that encodes the text descriptions $c$ into the text embedding space.
%
Stable Diffusion extends LDM by training on the larger LAION dataset~\cite{schuhmann2022laion}, with some architectural and training changes.

%-----------------------------------------------
\noindent \textbf{Inversion on Text-to-Image Diffusion Models.} 
%
Existing inversion methods focus on appearance inversion. Given several images that all contain a specific entity, they~\cite{gal2022textualinversion, ruiz2022dreambooth, kumari2022customdiffusion} find a text embedding V* for the pre-trained T2I model. The obtained V* can then be used as a new word to generate this entity in different scenarios.

In this work, we aim to capture object relations instead. Given several exemplar images which share a common relation $R$, we aim to find a relation prompt \R{} to capture this relation, such that \mbox{``$E_{A}$ \R{} 
$E_{B}$''} can be used to generate an image where \textit{$E_{A}$} and \textit{$E_{B}$} interact via relation \textit{R}. 




\subsection{Relation-Steering Contrastive Learning} 
\label{sec: contrastive}

Recall that our goal is to acquire a relation prompt \R{} that accurately captures the co-existing relation in the exemplar images. 
A basic objective is to reconstruct the exemplar images using \R{}:
\begin{gather}
    \langle{R}\rangle = \argmin_{\langle{r}\rangle} \Eb{t, \bx_0, \bepsilon}{ { \left\| \bepsilon - \bepsilon_\theta(\bx_t, t, \tau_\theta(c)) \right\|^2}}, c~contains~\langle{r}\rangle \label{eq:ti_loss}
\end{gather}
where $\bepsilon \sim \mathcal{N}(\bzero, \bI)$, \R{} is the optimized text embedding, and $\bepsilon_\theta(\cdot)$ is a pre-trained text-to-image diffusion model whose weights are frozen throughout optimization. $\langle{r}\rangle$ is the relation prompt being optimized, and is fed into the pre-trained T2I model as part of the text description $c$. 

However, this pixel-level reconstruction loss mainly focus on reconstructing visual details, without emphasis on object relations. Consequently, we find that directly optimizing with Equation~\ref{eq:ti_loss} could lead the relation prompt $\langle{R}\rangle$ to be more associated with the look of objects  rather than the relation between them, undesirably leaking entity appearance from exemplar images into the generated images, and also causing wrong object relations.

To mitigate this problem, we propose the \textit{``relation-steering contrastive learning''} scheme, leveraging linguistic priors discussed in Section~\ref{sec:intro} 
%
to emphasis more on object relation during the optimization of $\langle{R}\rangle$. 
%
Specifically, we sample a set of prepositions as positives and use other Part-of-Speech (POS)' words (\eg, nouns, adjectives) in the text descriptions as negatives to steer the relation prompt towards a relation-dense text embedding subspace, and push it away from appearance-related semantics. Following InfoNCE~\cite{oord2018representation,miech2020end}, we formulate the Steering Loss by:



\begin{gather}
    L_\mathrm{steer} = -log\frac{\sum_{l=1}^{L}{e^{{\langle{r}\rangle}^{\top}\cdot P_{i}^l / \gamma}}}{\sum_{l=1}^{L}{e^{{\langle{r}\rangle}^{\top}\cdot P_{i}^l / \gamma}  + \sum_{m=1}^{M}e^{{\langle{r}\rangle}^{\top}\cdot N_i^m / \gamma}}},
    \label{eq:l_steer}
\end{gather}
%
where $\langle{r}\rangle$ is the relation embedding, and $\gamma$ is the temperature parameter. $P_i=\{P_i^1, ..., P_i^L\}$ (\ie,~positive samples) refers to a set of a randomly sampled preposition embeddings from basis prepositions (more details provided in Supplementary File) at the $i$-th optimization iteration, and $N_i=\{N_i^1, ..., N_i^M\}$ (\ie,~negative samples) are the embeddings of all other POS' words (\eg, nouns, adjectives) in the exemplars' text descriptions in the current batch. All embeddings are normalized to unit length. We find that our relation-steering contrastive learning scheme can effectively help $\langle{r}\rangle$ to focus on relation and mitigate the appearance leakage problem (see Figure~\ref{fig:ablation_comparison} and Section~\ref{subsec:ablation}).



\subsection{Relation-Focal Importance Sampling}
%
In the sampling process of diffusion models, high-level semantics usually appear first, and fine details emerge at later stages~\extension{\cite{wang2023diffusion, huang2023collaborative, patashnik2023localizing, liew2022magicmix}}. As our objective is to capture the relation (a high-level concept) in exemplar images, it is undesirable to focus too much on fine-grained visual details (\eg, color, texture) during optimization. Therefore, we further conduct an importance sampling strategy to encourage the learning of high-level relations. Specifically, unlike previous reconstruction objectives, which samples the timestep $t$ from a uniform distribution, we skew the sampling distribution so that a higher probability is assigned to a larger $t$. The Denoising Loss for \textit{``relation-focal importance sampling''} becomes:
%
\begin{gather}
\begin{split}
    L_\mathrm{denoise} &= \Eb{t\sim f(t),\bx_0, \bepsilon}{ { \left\| \bepsilon - \bepsilon_\theta(\bx_t, t, \tau_\theta(c)) \right\|^2}}, \qquad \\
    f(t)        &= \frac{1}{T}(1 - \alpha \cos{\frac{\pi t}{T}}),
    \label{eq:importance_sampling}
\end{split}
\end{gather}
%
where $f(t)$ is the importance sampling function, which characterizes the probability density function to sample $t$ from. The skewness of $f(t)$ increases with $\alpha\,{\in}\,(0, 1]$. We set $\alpha=0.5$ throughout our experiments.
%
The overall optimization objective of the \textbf{\textit{ReVersion Framework}} is:
\begin{gather}
    \langle{R}\rangle = \argmin_{\langle{r}\rangle} (\lambda_\mathrm{steer}L_\mathrm{steer} + \lambda_\mathrm{denoise}L_\mathrm{denoise}), \label{eq:overall_loss}
\end{gather}
%
where $\lambda_\mathrm{steer}$ and $\lambda_\mathrm{denoise}$ are the weighting factors. 




% ========== Qualitative Result Figure ==========
\begin{figure*}[t]
    \centering
     \includegraphics[width=1.00\linewidth]{figures/fig_results.pdf}
     \caption{\textbf{Qualitative Results}. Our ReVersion Framework successfully captures the relation that co-exists in the exemplar images, and applies the extracted relation prompt \R{} to compose novel entities. 
     }
     \label{fig:qualitative_results}
\end{figure*}
% ========== Qualitative Result Figure ==========