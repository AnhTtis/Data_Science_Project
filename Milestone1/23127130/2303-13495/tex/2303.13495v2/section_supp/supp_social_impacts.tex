
\section{Limitations}
\label{sec:limitations}

% Figure: Limitations
\begin{figure*}[t]
  \centering
   \includegraphics[width=0.99\linewidth]{figures_supp/fig_supp_limitation.pdf}
   \vspace{-10pt}
   \caption{
        \textbf{Limitations}. Although the \R{} inverted by ReVersion can be applied robustly to synthesize new scenes, the image quality is limited by the generative capability of the pre-trained text-to-image model. \textit{\textbf{Left:}} when tasked with depicting a ``rabbit'' and a ``cat'' together, Stable Diffusion (SD) creates entities that blend features of both - such as rabbit ears and cat-like fur color and texture. Despite ReVersion's ability in capturing the ``shake hand'' relation through \R, the resulting image still has the problem of concept blending. \textbf{\textit{Right:}} when SD attempts to render human faces and bodies, the outcomes are often less than ideal. Therefore, even though ReVersion effectively captures the ``sitting back to back'' relation, the quality of the faces and bodies of the two children remains suboptimal.}

   \label{fig:fig_supp_limitation}
\end{figure*}


\begin{table}[t]
  \centering
  \caption{\textbf{Basis Preposition Set.} We list the set of 56 basis prepositions.}
  \vspace{-0.5em}
  \small 
  \begin{tabular}{|l|l|l|l|}
    \hline
    aboard & astride & in & regarding \\ \hline
    about & at & including & round \\ \hline
    above & atop & inside & through \\ \hline
    across & before & into & throughout \\ \hline
    after & behind & near & to \\ \hline
    against & below & of & toward \\ \hline
    along & beneath & off & towards \\ \hline
    alongside & beside & on & under \\ \hline
    amid & between & onto & underneath \\ \hline
    amidst & beyond & opposite & up \\ \hline
    among & by & out & upon \\ \hline
    amongst & down & outside & versus \\ \hline
    anti & following & over & with \\ \hline
    around & from & past & within \\ \hline
  \end{tabular}
  \label{tab:preposition_words}
\end{table}



Our performance is capped by the generative capabilities of the pre-trained text-to-image model, Stable Diffusion (SD). This dependency might lead to suboptimal synthesis in scenarios where SD faces challenges, as shown in Figure~\ref{fig:fig_supp_limitation}.


\noindent \textbf{Concept Blending.}
SD suffers from the concept blending problem. This issue arises when the model generates multiple entities within a single scene, leading to a fusion of characteristics from different classes. For example, when tasked with depicting a ``rabbit'' and a ``cat'' together, SD creates entities that blend features of both - such as rabbit ears and cat-like fur color and texture. Consequently, when ReVersion applies the learned \R{} on two entities of different classes, the same issue might occur.


\noindent \textbf{Human.} When SD attempts to render human faces and bodies, the outcomes are often less than ideal. Consequently, even though ReVersion effectively captures the relation, the quality of the faces and bodies of the human subjects might remain suboptimal.

Given that these limitations are inherent to the pre-trained text-to-image model, exploring and developing better text-to-image diffusion models is an orthogonal direction for performance improvements.


\section{Potential Societal Impacts}
\label{sec:impact}


Although \textit{ReVersion} can generate diverse entity combinations through inverted relations, this capability can also be exploited to synthesize real human figures interacting in ways they never did. As a result, we strongly advise users to only use \textit{ReVersion} for proper recreational purposes.

The rapid advancement of generative models has unlocked new levels of creativity but has also introduced various societal concerns. First, it is easier to create false imagery or manipulate data maliciously, leading to the spread of misinformation. Second, data used to train these models might be revealed during the sampling process without explicit consent from the data owner~\cite{tinsley2021face}. Third, generative models can suffer from the biases present in the training data~\cite{esser2020note}. We used the pre-trained Stable Diffusion~\cite{rombach2022ldm} for \textit{ReVersion}, which has been shown to suffer from data bias in certain scenarios. For example, when prompted with the phrase \textit{``a professor''}, Stable Diffusion tends to generate human figures that are white-passing and male-passing. We hope that more research will be conducted to address the risks and biases associated with generative models, and we advise everyone to use these models with discretion.
