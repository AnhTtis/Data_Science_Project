{
    "arxiv_id": "2303.10126",
    "paper_title": "IRGen: Generative Modeling for Image Retrieval",
    "authors": [
        "Yidan Zhang",
        "Ting Zhang",
        "Dong Chen",
        "Yujing Wang",
        "Qi Chen",
        "Xing Xie",
        "Hao Sun",
        "Weiwei Deng",
        "Qi Zhang",
        "Fan Yang",
        "Mao Yang",
        "Qingmin Liao",
        "Baining Guo"
    ],
    "submission_date": "2023-03-17",
    "revised_dates": [
        "2023-06-29"
    ],
    "latest_version": 3,
    "categories": [
        "cs.CV"
    ],
    "abstract": "While generative modeling has been ubiquitous in natural language processing and computer vision, its application to image retrieval remains unexplored. In this paper, we recast image retrieval as a form of generative modeling by employing a sequence-to-sequence model, contributing to the current unified theme. Our framework, IRGen, is a unified model that enables end-to-end differentiable search, thus achieving superior performance thanks to direct optimization. While developing IRGen we tackle the key technical challenge of converting an image into quite a short sequence of semantic units in order to enable efficient and effective retrieval. Empirical experiments demonstrate that our model yields significant improvement over three commonly used benchmarks, for example, 22.9\\% higher than the best baseline method in precision@10 on In-shop dataset with comparable recall@10 score.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.10126v1",
        "http://arxiv.org/pdf/2303.10126v2",
        "http://arxiv.org/pdf/2303.10126v3"
    ],
    "publication_venue": null
}