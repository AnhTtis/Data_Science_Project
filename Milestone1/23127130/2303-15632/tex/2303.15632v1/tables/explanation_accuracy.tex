

\begin{table}[t]
\centering
\begin{tabular}{c|cc|cc|cc}
\toprule
\multicolumn{1}{l|}{} & \multicolumn{2}{c|}{Binary} & \multicolumn{2}{c|}{Grouped} & \multicolumn{2}{c}{Fine-grained} \\
\midrule
\multicolumn{1}{l|}{} & \SF & \LF & \SF & \LF & \SF & \LF \\
\midrule
\MU & 4.20 & 7.13 & 2.95 & 12.59 & 4.12 & 60.43 \\

\SU & 6.79 & 5.00 & 2.54 & 7.81 & 3.39 & 41.26 \\
\LU & \textbf{0.93} & 15.08 & \textbf{1.26} & 9.81 & \textbf{2.20} & 23.80 \\\bottomrule
\end{tabular}
\caption{\textbf{Gap between explanation and model outputs (\cref{sssec:faithfulness}).}
For three Places365 models (binary, grouped, and fine-grained), we report the mean L2 distance between the distributions output by the explanation and the model ($\downarrow$ is better) when varying levels of faithfulness and understandability.
% \textbf{Bolded} results are for the best explanation for each model ($\downarrow$ is better).
For each model, we \textbf{bold} the most faithful explanation, i.e., explanation with the lowest mean L2 distance. 
% Explanations are more faithful for the somewhat faithful (\SF) explanation (vs. least faithful [\LF]), as expected.
As expected, somewhat faithful (\SF) explanations have lower mean L2 distance than least faithful (\LF) explanations.
%It's also generally 
%The fraction of the model explained 
%The fraction explained is 
% It is also generally more faithful for the least understandable (\LU) explanation due to the flexibility of  encoding concepts continuously.
Also as expected, least understandable (\LU) explanations have lower mean L2 distance than somewhat understandable (\SU) and most understandable (\MU) explanations, demonstrating a faithfulness-vs-understandability tradeoff.
}
\label{tab:faithful}
\end{table}