\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{bbm}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage[table,dvipsnames]{xcolor}
\usepackage{array}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}p{#1}}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}
\newcommand{\smallsec}[1]{\vspace{0.04in} \noindent {\bf #1.}}
\newcommand{\olga}[1]{{\color{magenta} Olga: #1}}
\newcommand{\todo}[1]{{\color{red} TODO: #1}}
\newcommand{\vikram}[1]{{\color{ForestGreen} Vikram: #1}}
\newcommand{\ruth}[1]{{\color{BurntOrange} Ruth: #1}}
\newcommand{\sunnie}[1]{{\color{Violet} Sunnie: #1}}
\newcommand{\nicole}[1]{{\color{Cerulean} Nicole: #1}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand\rowincludegraphics[2][]{\raisebox{-0.5\height}{\includegraphics[#1]{#2}}}
\setlength{\belowcaptionskip}{-8pt}

%\newcommand{\MU}{$\bigcirc$\kern-0.75em{$\circ$\kern-0.38em$\cdot$\kern0.38em$\mathbf{U}$}} 
%\newcommand{\SU}{$\circ$\kern-0.38em$\cdot\mathbf{U}$  }
%\newcommand{\LU}{$\bullet\mathbf{U}$  }

%\newcommand{\MF}{$\bigcirc$\kern-0.75em{$\circ$\kern-0.38em$\cdot$\kern0.38em$\mathbf{F}$}}
%\newcommand{\SF}{$\circ$\kern-0.38em$\cdot\mathbf{F}$ }
%\newcommand{\LF}{$\bullet\mathbf{F}$}

%\newcommand{\MU}{\textcolor{black}{$\dddot{\textbf{U}}$}}

%\newcommand{\SU}{\textcolor{black}{$\ddot{\textbf{U}}$}}

%\newcommand{\LU}{\textcolor{black}{$\dot{\textbf{U}}$}}

%\newcommand{\MF}{\textcolor{black}{$\dddot{\textbf{F}}$}}
%\newcommand{\SF}{\textcolor{black}{$\ddot{\textbf{F}}$}}
%\newcommand{\LF}{\textcolor{black}{$\dot{\textbf{F}}$}}

\newcommand{\MU}{$\textbf{UUU}${}}

\newcommand{\SU}{$\textbf{UU}$}{}

\newcommand{\LU}{$\textbf{U}$}{}

\newcommand{\MF}{$\textbf{FFF}$}{}
\newcommand{\SF}{$\textbf{FF}$}{}
\newcommand{\LF}{$\textbf{F}$}{}



\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{3957} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi

\begin{document}

%%%%%%%%% TITLE
% \title{Method Name: Unifying Concept-Based Explanations for CNNs}
% \title{UFO: Controlling Understandability and Faithfulness Objectives in Concept-based Explanations for CNNs}
\title{UFO: A unified method for controlling Understandability and Faithfulness Objectives in concept-based explanations for CNNs}

\author{Vikram V. Ramaswamy, Sunnie S. Y. Kim, Ruth Fong, Olga Russakovsky\\
Princeton University\\
{\tt\small \{vr23, suhk, ruthfong, olgarus\}@cs.princeton.edu}
}

\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi

%%%%%%%%% ABSTRACT
\begin{abstract}
    Concept-based explanations for convolutional neural networks (CNNs) aim to explain model behavior and outputs using a pre-defined set of semantic concepts (e.g., the model recognizes scene class ``bedroom'' based on the presence of concepts ``bed'' and ``pillow'').
    However, they often do not faithfully (i.e., accurately) characterize the model's behavior and can be too complex for people to understand.
    Further, little is known about how faithful and understandable different explanation methods are, and how to control these two properties.
    In this work, we propose UFO, a unified method for controlling Understandability and Faithfulness Objectives in concept-based explanations. UFO formalizes understandability and faithfulness as mathematical objectives and unifies most existing concept-based explanations methods for CNNs. Using UFO, we systematically investigate how explanations change as we turn the knobs of faithfulness and understandability.
    Our experiments demonstrate a faithfulness-vs-understandability tradeoff: increasing understandability reduces faithfulness.
    We also provide insights into the ``disagreement problem'' in explainable machine learning, by analyzing when and how concept-based explanations disagree with each other.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
\label{sec:intro}
\input{sections/introduction.tex}

\section{Related work}
\label{sec:related}
\input{sections/related.tex}

\section{UFO: A unified method for generating concept-based explanations for CNNs}
\label{sec:method}
\input{sections/methods.tex}


\section{Experiments}
\label{sec:experiments}
\input{sections/experiments.tex}


\section{Conclusion}
\label{sec:conclusion}
\input{sections/conclusion.tex}

{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\appendix

In this appendix, we provide more details about our method, as well as some additional results. 

\section{Additional details about comparisons with prior work}
\label{sec:netdissect}
\input{supp_sections/netdissect.tex}

\section{More results}
\label{sec:more_res}
\input{supp_sections/visualizations.tex}


\end{document}
