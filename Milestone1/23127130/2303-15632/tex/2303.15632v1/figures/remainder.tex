\begin{figure*}
    \centering
    \begin{tabular}{c|c|c}
    \toprule
       & \multicolumn{1}{c|}{indoor-transport}  & \multicolumn{1}{c}{indoor-culture } \\
       \midrule
       sf, mu & \raisebox{-0.4\totalheight}{\includegraphics[width=0.4\textwidth]{images/remainder/scene3_0.eps}} & \raisebox{-0.4\totalheight}{\includegraphics[width=0.4\textwidth]{images/remainder/scene5_0.eps} }\\
    sf, su & \raisebox{-0.4\totalheight}{\includegraphics[width=0.4\textwidth]{images/remainder/scene3_1.eps}} & \raisebox{-0.4\totalheight}{\includegraphics[width=0.4\textwidth]{images/remainder/scene5_1.eps}} \\   
       sf, lu & \raisebox{-0.4\totalheight}{\includegraphics[width=0.4\textwidth]{images/remainder/scene3_2.eps}} & \raisebox{-0.4\totalheight}{\includegraphics[width=0.4\textwidth]{images/remainder/scene5_2.eps}} \\\bottomrule
    \end{tabular}
    \caption{\textbf{Visualizing the remainder.}
    For coarse-grained scene classes ``indoor-transport'' and ``indoor-cultural'', we compute  $v = F(x) - h_\text{pred} \circ h_\text{conc}(x)$ and show the top 5 images for which $v_k$ corresponding to those two classes is the largest (i.e., the images that are most poorly explained). 
    By inspection, this suggests that concepts like ``vehicle seats'', ``auditorium seats'', and ``arches'', if labelled in the probe dataset, may help to better explain this model. 
    }
    \label{fig:remainder}
\end{figure*}