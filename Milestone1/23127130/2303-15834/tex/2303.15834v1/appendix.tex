

\section{Appendix}
\label{sec:appendix:item_meta}

\subsection{Production Line Quality Prediction}
\label{sec:appendix:item_meta:production_line}

\subsubsection{Complete model}

\begin{table}[H]
\centering
\caption{Confusion matrix}
\begin{tabular}{llrr}
\toprule
\multicolumn{2}{c}{} & \multicolumn{2}{c}{predicted} \\ \cmidrule{3-4} 
\multicolumn{2}{c}{} & no scrap & scrap \\ \midrule
\multirow{2}{*}{actual} 
& no scrap & 1180766 & 2981 \\
& scrap & 5177 & 1702 \\ \bottomrule
\end{tabular}
\end{table}


\begin{table}[H]
%\small
\caption{Metrics}
\centering
\begin{tabular}{ll}
\toprule
MCC                  & 0.296544 \\
Accuracy             & 0.993148 \\
F1-Score (weighted)  & 0.992501 \\
Precision (weighted) & 0.991982 \\
Recall (weighted)    & 0.993148 \\
Cohen's Kappa        & 0.291095 \\ \bottomrule
\end{tabular}
\end{table}


%%%%%%%%%%%

\subsubsection{Meta model}

\begin{table}[H]
\centering
\caption{Confusion matrix}
\begin{tabular}{llrr}
\toprule
\multicolumn{2}{c}{} & \multicolumn{2}{c}{predicted} \\ \cmidrule{3-4} 
\multicolumn{2}{c}{} & no scrap & scrap \\ \midrule
\multirow{2}{*}{actual} 
& no scrap & 1180558 & 3189 \\
& scrap & 5231  & 1648 \\ \bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
%\small
\centering
\caption{Metrics}
\begin{tabular}{ll}
\toprule
MCC                  & 0.282242 \\
Accuracy             & 0.992928 \\
F1-Score (weighted)  & 0.992315 \\
Precision (weighted) & 0.991805 \\
Recall (weighted)    & 0.992928 \\
Cohen's Kappa        & 0.277880 \\ \bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
%\small{}
\centering
\caption{Sensitivity Analysis}
\begin{tabular}{lrccccc}
\toprule
 &     & \multicolumn{5}{c}{\textbf{\#estimators}}  
 \\ \cmidrule{3-7} 
 &     & \textbf{25}     & \textbf{50}     & \textbf{100}    & \textbf{200}    & \textbf{300}    \\ \midrule
\multicolumn{1}{l}{\multirow{5}{*}{\textbf{max depth}}} & \textbf{25}  & 0.2731 & \textbf{0.2822} & 0.2806 & 0.2752 & 0.2760 \\ 
\multicolumn{1}{l}{}                           & \textbf{50}  & 0.2648 & 0.2660 & 0.2531 & 0.2621 & 0.2519 \\ 
\multicolumn{1}{l}{}                           & \textbf{100} & 0.2469 & 0.2447 & 0.2490 & 0.2498 & 0.2492 \\ 
\multicolumn{1}{l}{}                           & \textbf{200} & 0.2313 & 0.2328 & 0.2298 & 0.2262 & 0.2199 \\ 
\multicolumn{1}{l}{}                           & \textbf{300} & 0.2374 & 0.2310 & 0.2294 & 0.2327 & 0.2134 \\ \bottomrule
\end{tabular}
\end{table}


%%%%%%%%%%%%

\subsubsection{Sub model 0}

\begin{table}[H]
\centering
\caption{Confusion matrix}
\begin{tabular}{llrr}
\toprule
\multicolumn{2}{c}{} & \multicolumn{2}{c}{predicted} \\ \cmidrule{3-4} 
\multicolumn{2}{c}{} & no scrap & scrap \\ \midrule
\multirow{2}{*}{actual} 
& no scrap & 1175324 & 8423 \\
& scrap & 5221   & 	1658 \\ \bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Metrics}
\begin{tabular}{ll}
\toprule
MCC                  & 0.193483 \\ 
Accuracy             & 0.988540 \\ 
F1-Score (weighted)  & 0.989614 \\ 
Precision (weighted) & 0.990776 \\ 
Recall (weighted)    & 0.988540 \\ 
Cohen's Kappa        & 0.189955 \\ \bottomrule
\end{tabular}
\end{table}


\subsubsection{Sub model 1}

\begin{table}[H]
\centering
\caption{Confusion matrix}
\begin{tabular}{llrr}
\toprule
\multicolumn{2}{c}{} & \multicolumn{2}{c}{predicted} \\ \cmidrule{3-4} 
\multicolumn{2}{c}{} & no scrap & scrap \\ \midrule
\multirow{2}{*}{actual} 
& no scrap & 1176646 & 7101 \\
& scrap & 5164   & 	1715 \\ \bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Metrics}
\begin{tabular}{ll}
\toprule
MCC                  & 0.215102 \\ 
Accuracy             & 0.989699 \\ 
F1-Score (weighted)  & 0.990330 \\ 
Precision (weighted) & 0.991002 \\
Recall (weighted)    & 0.989699 \\ 
Cohen's Kappa        & 0.213436 \\ \bottomrule
\end{tabular}
\end{table}

%%%%%%%%%%%%%%%

\subsubsection{Sub model 2}

\begin{table}[H]
\centering
\caption{Confusion matrix}
\begin{tabular}{llrr}
\toprule
\multicolumn{2}{c}{} & \multicolumn{2}{c}{predicted} \\ \cmidrule{3-4} 
\multicolumn{2}{c}{} & no scrap & scrap \\ \midrule
\multirow{2}{*}{actual} 
& no scrap & 1178458 & 5289 \\
& scrap & 5243    &	1636 \\ \bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Metrics}
\begin{tabular}{ll}
\toprule
MCC                  & 0.232585 \\ 
Accuracy             & 0.991154 \\ 
F1-Score (weighted)  & 0.991169 \\ 
Precision (weighted) & 0.991184 \\ 
Recall (weighted)    & 0.991154 \\ 
Cohen's Kappa        & 0.232584 \\ \bottomrule
\end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%

\subsubsection{Sub model 3}

\begin{table}[H]
\centering
\caption{Confusion matrix}
\begin{tabular}{llrr}
\toprule
\multicolumn{2}{c}{} & \multicolumn{2}{c}{predicted} \\ \cmidrule{3-4} 
\multicolumn{2}{c}{} & no scrap & scrap \\ \midrule
\multirow{2}{*}{actual} 
& no scrap & 1177577  &  6170 \\
& scrap & 5432 & 1447\\ \bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Metrics}
\begin{tabular}{ll}
\toprule
MCC                  & 0.195008 \\ 
Accuracy             & 0.990256 \\ 
F1-Score (weighted)  & 0.990502 \\ 
Precision (weighted) & 0.990755 \\ 
Recall (weighted)    & 0.990256 \\ 
Cohen's Kappa        & 0.194752 \\ \bottomrule
\end{tabular}
\end{table}


\subsection{Noising}
\label{sec:appendix:item_meta:noising}
Noising techniques strive to preserve confidentiality by adding noise to the critical data element. The predictive performance also drops significantly with increasing noising of data and therefore increasing data confidentiality. \Cref{fig:appendix:item_meta:noise} shows this effect, where a noise term of 0 means that there is no confidentiality at all (no noising) and a term of 1 means that the original data is obscured by white noise of the order of the standard deviation of the data itself. We assume that a sufficiently strong preservation of confidentiality accompanies this. We applied ascending noise terms to the data in 0.1 increments to highlight the trade-off between these two extremes.


\begin{figure}[htbp]
\centering\includegraphics[width=0.8\linewidth]{Figures/noise_sensitivity.pdf}
\caption{Sensitivity of model performance with an increased ratio of additive noise term}
\label{fig:appendix:item_meta:noise}
\end{figure}


\subsection{Robustness Check: Distributed Sensor Groups}
\label{sec:appendix:item_meta:robustness_check}

We evaluate the robustness of the proposed instantiation of IOMML by means of an additional use case in the field of operation and maintenance.

\subsubsection{Use Case Description}
As a second data set we consider an example, where the status of a function-critical component (seal) in a hydraulic application as well as corresponding sensor measurements are available. It is technically not possible to observe the condition of the component of interest directly---as, for instance, sensors cannot be mounted at the component. Therefore, data from sensors in the nearby environment of the component could be leveraged to infer the state of the seal by means of machine learning \citep{Martin2019}.

The data set consists of 2.230.992 instances of time-independent recording intervals. each with an associated state description \emph{(no failure. assembly failure and damage)} which are almost balanced \emph{(no failure: 48.36\%; assembly failure: 26.1\% and damage: 25.51\%)}. Overall, the data set contains 46 features which can each be assigned to one of six physically and logically separated groups of sensor measurement points. These groups are each assigned to different legal units due to structural separation and connection to separate gateways, as each sensor group originates from a different manufacturer with its own, proprietary IoT platform. 

The use case is well suited for our instantiation of IOMML, as it complies with design requirements 1 to 3: The separate sensor groups each represent independent entities (DR1). Because the gateways transmit data through bandwidth-limited communication channels such as CAN bus, the smallest possible transmission size is absolutely necessary (DR2). Likewise, preliminary interviews with the industry partner, who provides the data, have shown that the best possible prediction performance is an essential requirement to be able to initiate maintenance measures at an early stage (DR3).

\subsubsection{Artifact instantiation}
Equivalent to the procedure described in \Cref{sec:item_meta:evaluation}, a sub-prediction and a corresponding certainty value are generated for each sensor group, which is subsequently received by a meta unit and analyzed in aggregated form by a meta model. The result is a holistic state description of the functionally critical component. Also, here we compare the inter-organizational meta learning approach (scenario 2) to a separate isolated analysis of data in each unit (scenario 1) and a comprehensive analysis with a shared data pool and all data in one model (scenario 3). All classification models utilize the random forest algorithm and are validated in a nested cross-validation.

\subsubsection{Evaluation Episode 1: Technical Evaluation}
Since training of sub-models condenses the complex features of the sensors into a prediction about the state of the function-critical component, the original data cannot be reconstructed. Strictly speaking, the original features of the data set describe numerical values such as temperatures or pressures at certain locations within the system, while the results of the sub models only give a binary prediction result and its probability. Thus, data confidentiality is preserved in the scenario of meta machine learning (scenario 2) in contrast to scenario 3 (RQ1). Considering the calculation logic depicted in \Cref{table:item_meta:scenario_comparison}, scenario 3 results in a data volume of 46 times the volume of a single feature, while in scenario 2 this volume can be reduced to 12 (6 sub models times two output features) times the volume of a feature. Thus, the amount of data transferred in scenario 2 is reduced to 26\% of the amount of data in scenario 3.

\begin{table}[H]
%\small
\centering
\caption{Technical performance of method compared to other scenarios}
\begin{tabular}{ll}
\toprule
\textbf{Model} & \textbf{MCC} \\ \midrule
Sub-model sensor group 0 & 0.6677 \\ 
Sub-model sensor group 1 & 0.7250 \\ 
Sub-model sensor group 2 & 0.5393 \\ 
Sub-model sensor group 3 & 0.5249 \\ 
Sub-model sensor group 4 & 0.0744 \\ 
Sub-model sensor group 5 & 0.1812 \\ \midrule
Meta model & 0.7920 \\ \midrule
Complete model & 0.9543 \\ \bottomrule
\end{tabular}
\end{table}
\label{tab:appendix:item_meta:performance}

In terms of predictve performance, we observe a similar effect as in the production line case. In \Cref{tab:appendix:item_meta:performance}, we present the results for scenario 1 to 3 in terms of the respective MCC. We observe a performance gain from scenario 1 to scenario 2 for every sub-model. Hereby, the sub model from ``sensor group 4'' only reaches an MCC of 0.0744, and the model which is trained on data originating from sensor group 1 performs best with an MCC of 0.7250. In comparison, the aggregated meta model reaches an MCC of 0.7920, outperforming the worst sub-model by 970.27\% and the best by 9.24\%. Similarly, as in the previous case, we observe a performance loss from scenario 2 to scenario 3 of 17.00\%. for this use case. 


\subsubsection{Complete model}

\begin{table}[H]
\centering
\caption{Confusion matrix}
\begin{tabular}{llrrr}
\toprule
\multicolumn{2}{l}{{}}    & \multicolumn{3}{c}{predicted}         \\ \cmidrule{3-5} 
\multicolumn{2}{c}{}                     & no failure & assembly failure & damage \\ \midrule
\multirow{3}{*}{actual}  & no failure       & 1048299    & 16513            & 12980  \\
                        & assembly failure & 10170      & 562431           & 9687    \\
                        & damage           & 5490       & 9841             & 553349 \\ \bottomrule
\end{tabular}

\end{table}



\begin{table}[H]
\centering
\caption{Metrics}
\begin{tabular}{ll}
\toprule
MCC                  & 0.954285 \\ 
Accuracy             & 0.970979 \\ 
F1-Score (weighted)  & 0.971026 \\ 
Precision (weighted) & 0.971148 \\ 
Recall (weighted)    & 0.970979 \\ 
Cohen's Kappa        & 0.954239 \\ \bottomrule
\end{tabular}
\end{table}



\subsubsection{Meta model}

\begin{table}[H]
\centering
\caption{Confusion matrix}
\begin{tabular}{llrrr}
\toprule
\multicolumn{2}{l}{}    & \multicolumn{3}{c}{predicted}         \\ \cmidrule{3-5} 
\multicolumn{2}{c}{}                     & no failure & assembly failure & damage \\ \midrule
\multirow{3}{*}{actual} &no failure       & 986600     & 38605            & 52587  \\ 
                        & assembly failure & 66409      & 461343           & 54536  \\ 
                        & damage           & 32209      & 48990            & 487481 \\ \bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Metrics}
\begin{tabular}{ll} \toprule
MCC                  & 0.792021 \\ 
Accuracy             & 0.868386 \\ 
F1-Score (weighted)  & 0.868094 \\ 
Precision (weighted) & 0.868397 \\ 
Recall (weighted)    & 0.868386 \\ 
Cohen's Kappa        & 0.791788 \\ \bottomrule
\end{tabular}
\end{table}


\subsubsection{Sub model 0}

\begin{table}[H]
\centering
\caption{Confusion matrix}
\begin{tabular}{llrrr}
\toprule
\multicolumn{2}{l}{}    & \multicolumn{3}{c}{predicted}         \\ \cmidrule{3-5} 
\multicolumn{2}{c}{}                     & no failure & assembly failure & damage \\ \midrule
\multirow{3}{*}{actual} &no failure       & 926791     & 65712            & 85289  \\
                        & assembly failure & 100310     & 415950           & 66028  \\
                        & damage           & 64201      & 86228            & 418251 \\ \bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Metrics}
\begin{tabular}{ll}
\toprule
MCC                  & 0.667663 \\
Accuracy             & 0.790122 \\ 
F1-Score (weighted)  & 0.789722 \\ 
Precision (weighted) & 0.789413 \\ 
Recall (weighted)    & 0.790122 \\ 
Cohen's Kappa        & 0.667620 \\ \bottomrule
\end{tabular}
\end{table}


\subsubsection{Sub model 1}

\begin{table}[H]
\centering
\caption{Confusion matrix}
\begin{tabular}{llrrr}
\toprule
\multicolumn{2}{l}{}    & \multicolumn{3}{c}{predicted}         \\ \cmidrule{3-5} 
\multicolumn{2}{c}{}                     & no failure & assembly failure & damage \\ \midrule
\multirow{3}{*}{actual} &no failure       & 986704     & 42098            & 48990  \\
                        & assembly failure & 87540      & 439058           & 55690  \\ 
                        & damage           & 65418      & 85331            & 417931 \\ \bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Metrics}
\begin{tabular}{ll}
\toprule
MCC                  & 0.724988 \\ 
Accuracy             & 0.827228 \\ 
F1-Score (weighted)  & 0.825501 \\ 
Precision (weighted) & 0.825219 \\ 
Recall (weighted)    & 0.827228 \\ 
Cohen's Kappa        & 0.724221 \\ \bottomrule
\end{tabular}
\end{table}


\subsubsection{Sub model 2}

\begin{table}[H]
\centering
\caption{Confusion matrix}
\begin{tabular}{llrrr}
\toprule
\multicolumn{2}{l}{}    & \multicolumn{3}{c}{predicted}         \\ \cmidrule{3-5} 
\multicolumn{2}{c}{}                     & no failure & assembly failure & damage \\ \midrule
\multirow{3}{*}{actual} &no failure       & 847699     & 108553           & 121540 \\ 
                        & assembly failure & 99505      & 393083           & 89700  \\
                        & damage           & 98541      & 135690           & 334449 \\ \bottomrule
\end{tabular}
\end{table}


\begin{table}[H]
\centering
\caption{Metrics}
\begin{tabular}{ll}
\toprule
MCC                  & 0.539291 \\ 
Accuracy             & 0.706775 \\ 
F1-Score (weighted)  & 0.707651 \\ 
Precision (weighted) & 0.709522 \\ 
Recall (weighted)    & 0.706775 \\ 
Cohen's Kappa        & 0.538895 \\ \bottomrule
\end{tabular}
\end{table}


\subsubsection{Sub model 3}

\begin{table}[H]
\centering
\caption{Confusion matrix}
\begin{tabular}{llrrr}
\toprule
\multicolumn{2}{l}{}    & \multicolumn{3}{c}{predicted}         \\ \cmidrule{3-5} 
\multicolumn{2}{c}{}                     & no failure & assembly failure & damage \\ \midrule
\multirow{3}{*}{actual} &no failure       & 891411     & 100951           & 85430  \\
                        & assembly failure & 132810     & 353791           & 95687  \\ 
                        & damage           & 97820      & 153418           & 317442 \\ \bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Metrics}
\begin{tabular}{ll}
\toprule
MCC                  & 0.524877 \\ 
Accuracy             & 0.701127 \\ 
F1-Score (weighted)  & 0.698990 \\ 
Precision (weighted) & 0.698634 \\ 
Recall (weighted)    & 0.701127 \\ 
Cohen's Kappa        & 0.524224 \\ \bottomrule
\end{tabular}
\end{table}


\subsubsection{Sub model 4}

\begin{table}[H]
\centering
\caption{Confusion matrix}
\begin{tabular}{llrrr}
\toprule
\multicolumn{2}{l}{}    & \multicolumn{3}{c}{predicted}         \\ \cmidrule{3-5} 
\multicolumn{2}{c}{}                     & no failure & assembly failure & damage \\ \midrule
\multirow{3}{*}{actual} &no failure       & 637025     & 254065           & 186702 \\ 
                        & assembly failure & 231050     & 191655           & 159583 \\
                        & damage           & 218352     & 253680           & 96648  \\ \bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Metrics}
\begin{tabular}{ll}
\toprule
MCC                  & 0.074382 \\ 
Accuracy             & 0.415176 \\ 
F1-Score (weighted)  & 0.411569 \\ 
Precision (weighted) & 0.410816 \\ 
Recall (weighted)    & 0.415176 \\ 
Cohen's Kappa        & 0.074030 \\ \bottomrule
\end{tabular}
\end{table}


\subsubsection{Sub model 5}

\begin{table}[H]
\centering
\caption{Confusion matrix}
\begin{tabular}{llrrr}
\toprule
\multicolumn{2}{l}{}    & \multicolumn{3}{c}{predicted}         \\ \cmidrule{3-5} 
\multicolumn{2}{c}{}                     & no failure & assembly failure & damage \\ \midrule
\multirow{3}{*}{actual} &no failure       & 670710     & 198536           & 208546 \\
                        & assembly failure & 195684     & 148040           & 238564 \\
                        & damage           & 126985     & 203305           & 238390 \\ \bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Metrics}
\begin{tabular}{ll}
\toprule
MCC                  & 0.181204 \\ 
Accuracy             & 0.474318 \\ 
F1-Score (weighted)  & 0.478521 \\ 
Precision (weighted) & 0.485576 \\ 
Recall (weighted)    & 0.474318 \\ 
Cohen's Kappa        & 0.180575 \\ \bottomrule
\end{tabular}
\end{table}
