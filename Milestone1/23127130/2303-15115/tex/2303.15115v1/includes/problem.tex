\section{Preliminaries and Problem Formulation} \label{sec:proplemdef}

\subsection{Visual Action Planning} 
Let $\mathcal{O}$ be the set of all  possible observations, and $\mathcal{U}$ the set of all feasible actions of the system.
\begin{dfn}\label{defn::vap}
Given start and goal observations $O_s$ and $O_g$, respectively,  a Visual Action Plan (VAP)  $P=(P^o,P^u)$ consists of a visual plan $P^o$ and action plan $P^u$, where the visual plan $P^o=(O_s=O_0,O_1,...,O_n=O_g)$, with $O\in \mathcal{O}$, contains a sequence of $n$ observations showing intermediate states from start to goal, while the action plan $P^u=(u_0,u_1,...,u_{n-1})$ provides  the  respective actions to transition through the states, with $u\in \mathcal{U}$.
\end{dfn}

Note that in general, given start and goal observations, 
there are many potential plans that can feasibly transition the system from start to goal, i.e., VAPs may not be unique.

\subsection{Latent Space Roadmap-based system}\label{sec:SLSR}
The Latent Space Roadmap framework, presented 
in \cite{lippi2022enabling}, is an approach to realize visual action planning. 
The core idea of the method is to map the observations in a low dimensional structured latent space  $\mathcal{Z}$ where a roadmap is built to perform planning. 
More specifically, the latent space is structured to reflect the separation of the underlying states of the system, i.e., latent states associated to the same underlying system state are clustered together, while latent states associated to different system states are far apart; 
based on this latent space, a roadmap captures the possible transitions among the clusters and allows to find plans in the latent space. The plans generated in the latent space are then decoded to obtain visual plans. 
%
\begin{dfn}\label{defn::lsr}
    A Latent Space Roadmap-based system  \mbox{S-LSR$=\{\xi,\mathcal{G},\omega\} $} consists of a latent mapping function $\xi$, that maps observations to a low  dimensional structured latent space, $\xi:\mathcal{O} \to \mathcal{Z}$, a Latent Space Roadmap   $\mathcal{G}=\{\mathcal{V},\mathcal{E} \}$, that is a graph structure composed of the sets of nodes
    $\mathcal{V}$,  and edges  
    $\mathcal{E}$, and an observation generator function $\omega$, that maps latent representations $z\in \mathcal{Z}$ into observations, $\omega:\mathcal{Z}\to \mathcal{O}$.
\end{dfn}
We enclose the two functions $\xi$ and $\omega$ in a single module, which we refer to as Mapping Module (MM). 
 Note that by either changing the mapping module or the LSR we can obtain different S-LSR models, where the generic S-LSR$_i$ is defined as S-LSR$_i=\{\xi_i,\mathcal{G}_i,\omega_i\}$.
  For example, three S-LSRs are depicted in different colors in Fig. \ref{fig:en_overview}.


\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{figures/ensemble_explained_pj.png}
    \caption{Overview of our ensemble approach. The training tuples (with $a=1$) are mapped through different mapping modules into separate latent spaces, where individual LSRs are  built. Colors of the observations represent their underlying state.
    Given start and goal observations (bottom left), these are mapped into the latent spaces (grey circles) and all the possible visual action plans are extracted from the $m$ S-LSRs. Finally, a selection is made by the ensemble algorithm. }
    
    
    \label{fig:ensemble_explained}
\end{figure*}



\noindent
\textbf{Dataset and S-LSR building:} The S-LSR assumes a dataset $\mathcal{T}_o$ consisting of tuples $(O_i,O_j,\rho)$ where $O_i$ and $O_j$ are two observations and $\rho$ represents the action information between them.
In detail, 
$\rho=\{a,u\}$ comprises a binary indicator variable $a\in \{0,1\}$, which indicates if an action has taken place ($a=1$) or not ($a=0$), along with the respective action specification $u$, which is meaningful only in case $a=1$. 
This representation allows us to also model  variations in observations not caused by actions, such as changes in lighting conditions. For such task irrelevant factors of variation it holds $a=0$, i.e., no action took place, and the value of the variable $u$ is ignored. 
 Without loss of generality, we consider that the observations in the dataset are numbered and we refer to
  $i$ in $O_i$ as its index. 
Note that the dataset does not require any knowledge of the underlying system states in the observations, but only the information of the action  between them.







Briefly, based on the above dataset structure, the mapping functions $\xi$ and $\omega$ are realized with an  encoder-decoder based architecture. A contrastive loss term is introduced which exploits the action binary indicator variable: 
states in tuples with $a=1$ are encouraged to be spaced in the latent space, while states with $a=0$ are encouraged to be close\cite{lippi2022enabling}. 
The LSR $\mathcal{G}$  is then built in the latent space by clustering and connecting the latent states associated with the training dataset: each cluster is associated with a node, and edges are constructed if actions exist in the dataset to transition among the respective nodes. 
 For each node, we consider as its representative latent state the cluster centroid. 
Furthermore, according to the Action Averaging Baseline method from \cite{lippi2022enabling}, each edge is  endowed with the average action among all the actions between the respective nodes of the edge. 
According to the procedure in \cite[Algorithm 2]{lippi2022enabling}, the LSR building mainly  depends on a single parameter, $c_{\max}$,  that is  an upper bound on the number of weakly connected components of the graph. Intuitively, we build the LSR by maximizing the number of edges, in order to increase likelihood of finding plans,  while constraining the number of possible  disconnected components of the graph, in order to avoid fragmentation of the graph. 


\noindent
\textbf{Planning procedure:} 
Given a S-LSR and the start $O_s$ and goal $O_g$ observations, visual action planning is achieved by first mapping the given  start and end observations  into the structured latent space $\mathcal{Z}$ via the latent mapping function $\xi$. Then, the closest nodes in the graph $\mathcal{G}$ with  centroids in $z_s$ and $z_g$, respectively, are retrieved and the, possibly multiple, shortest paths in  $\mathcal{G}$  from $z_s$ to $z_g$ are computed. These paths provide both the sequences of latent states from start to goal, referred to as latent plans \mbox{$P^z=(z_s=z_0,z_1,...,z_n=z_g)$},  and the sequences of respective actions  $P^u$,  retrieved  from the graph edges $\mathcal{E}$. The latent plans are finally decoded into visual plans $P^o$ through the observation generator $\omega$. 
We re-iterate that multiple shortest paths can be found from $z_s$ to $z_g$ and denote by $q$ the number of these paths. 


\subsection{Problem Formulation}

Given a dataset $\mathcal{T}_o$, the correctness of plans suggested by a S-LSR mainly depends on two factors \cite{ccpaper}: \emph{i)} how well the latent space is structured, i.e., if states are properly separated, and \emph{ii)} how well the LSR is built, i.e., if nodes are 
representative of the underlying states of the system as well as if they are correctly connected according to the possible actions of the system. 
Both points are influenced by the choice of the respective hyperparameters, i.e., given the same dataset and same start and goal observations, two S-LSRs may provide distinct plans, which also differ in terms of correctness, depending on the used hyperparameters.   Among the hyperparameters, we also include the constitution of the overall dataset into validation and training parts. 
Our objective is to design a robust system that can perform visual action planning while mitigating high variance in the results arising with different parameters of the S-LSR. 
 

