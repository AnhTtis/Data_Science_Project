\section{Introduction}
\label{sec:intro}

Generating plans from raw observations can be more flexible than relying on handcrafted state extractors or modeling the system explicitly.
This can be particularly advantageous in complex tasks, such as manipulating deformable objects or operating in dynamic environments, where accurately defining the underlying system state can prove to be challenging.
Moreover, the generation of plans from raw observations offers the potential to create both visual and action plans, which we refer to as visual action plans. The visual plan captures the sequence of images that the system transitions through while executing the action plan.  This  allows human operators to easily comprehend the  plan and gain a better understanding of the system behavior.



Nonetheless, 
the high-dimensionality of raw observations 
challenges the effectiveness of classical planning approaches~\cite{bellman1961curse}. In this regard, representation learning  may help to retrieve compact representations from high-dimensional observations. Given these representations, classical planning approaches can be then employed. Based on this principle, we proposed in our previous works \cite{lippi2022enabling, lippi2022augment} a Latent Space Roadmap (LSR) framework.  
This involves training a deep neural network to learn a low-dimensional latent space of the high-dimensional observation space. 
A roadmap is then constructed within this space to capture the connectivity between different states, and is used to perform planning.


\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{figures/ens_fig1.png}
    \vspace{-15pt}
    \caption{Depiction of the Ensemble Latent Space Roadmap framework for a folding task. Given start and goal observations, multiple models produce different visual action plans, and the ones with the highest degree of similarity to one another are selected. 
}
    \label{fig:en_overview}
\end{figure}

 While utilizing learned models for representation is generally advantageous, they might lead to unreliable plans. For instance, this can occur when working with non-representative data samples during the training process.  
In this work, we aim to enhance the robustness of latent space planning by  incorporating 
the  ensemble paradigm \cite{rokach2019ensemble}: 
several models are collected and their plans are combined based on similarity measures. 
 To this aim, we 
 take into account both the sequence of actions and the composition of transited nodes in the latent space.
% 
 In line with majority voting ensemble approaches \cite{ruta2005classifier}, we select the plans which are the most similar to the others.
We name the resulting framework Ensemble LSR (ENS-LSR) and show an overview in Fig.~\ref{fig:en_overview}.
% 
We demonstrate its effectiveness  compared to \cite{lippi2022enabling, lippi2022augment} in simulated box stacking and grape harvesting tasks and on a real-world folding task. 
% 
In detail, our contributions are:
\begin{itemize}
    \item The design of a novel ensemble algorithm for latent space planning along with the definition of appropriate similarity measures. 
    \item An extensive performance comparison on multiple tasks, including a new simulated agricultural task and a real-world manipulation task with deformable objects.
    \item Extensive ablation studies analyzing different components of the algorithm. 
    \item The release of all datasets, code, and execution videos for real-world experiments on the project website\footnote{\label{fn:website} \url{https://visual-action-planning.github.io/ens-lsr/}}.
\end{itemize}
Note that, although we focus on LSR framework, the proposed algorithm can be  adapted to any latent space planning method. 




\section{Related Work} \label{sec:rw}

\subsection{Visual planning}
Visual planning  allows robots to generate plans and make decisions based on the visual information they perceive from their environment. 
Methods directly working in the image space have been proposed in the literature. For instance, the method in \cite{finn2017deep} is based on Long-Short Term Memory blocks to generate a video prediction model, which is  then integrated into a Model Predictive Control (MPC) framework to produce  visual plans; the approach in \cite{wang2019learning} produces visual foresight plans for rope manipulation using GAN models and then resorts to a learned rope inverse dynamics. 
However, as mentioned in the Introduction, latent spaces can be employed to reduce the high-dimensionality of the image space. For instance, an RRT-based algorithm in the latent space with collision checking  is adopted in \cite{Ichter2019}; interaction features conditioned on object images are learned and integrated within Logic-Geometric Programming for planning in \cite{Toussaint_ral2022};  model-free Reinforcement Learning (RL) in the off-policy case combined with auto-encoders is investigated in~\cite{yarats2021improving}. 
Despite the dimensionality reduction of the space, 
the approaches above typically require a large amount of data to operate. In contrast, the LSR framework is able to accomplish visual planning in a data-efficient manner by leveraging a contrastive loss to structure the latent space.   

\subsection{Ensemble methods}
While the ensemble principle has primarily been utilized within the machine learning community \cite{dong2020survey}, it has also been implemented in robotic planning to combine multiple planning algorithms or models and improve the overall performance of the system.
Multiple planners in parallel,  which work under diverse assumptions, are executed according to the method in  \cite{Scherer_ICRA2015}. An ensemble selection is then made based on learned priors on planning performance. The combination of multiple heuristics in greedy best-first search planning algorithm is investigated in \cite{Helmert_2021}. 
An online ensemble learning method based on different predictors is proposed instead in \cite{Zambelli_TCDS2017} to achieve an accurate robot forward model that can be beneficial for imitation behavior.   
The study in \cite{Adil_Access2020} adopts 
an ensemble framework with neural networks to mitigate the error in stereo vision systems and then performs planning for manipulation. 
 Finally, several applications of the ensemble paradigm to RL approaches can be found in the literature, such as in 
\cite{Wiering_TSMC2008,buckman2018sample,lee2021sunrise}. In detail, the ensemble method in \cite{Wiering_TSMC2008} combines the value functions of five different RL algorithms, the approach in \cite{buckman2018sample}  dynamically interpolates between rollouts with different horizon lengths, while the study in \cite{lee2021sunrise} proposes ensemble-based weighted Bellman backups. 
However, to the best of our knowledge, none of the above approaches is able to realize visual action planning. 








