

\section{Simulation results}\label{sec:exp}
We validate our ensemble LSR algorithm on two simulation tasks realized with Unity3D engine \cite{unitygameengine}: \emph{i)} a box stacking task, previously introduced in \cite{lippi2022enabling} (where it is referred to as hard box stacking task) and shown in Fig. \ref{fig:simu_setup} on the left, as well as a grape harvesting task, shown in Fig. \ref{fig:simu_setup} on the right. Actions in both tasks are expressed as pick and place operations, i.e., $u=(p,r)$ as reported in Sec.~\ref{sec:sim-measure}. 
 The datasets consist of $2500$ and $5000$ tuples for stacking and harvesting, respectively, and are available on the project website\usefootref{fn:website}.
The box stacking task consists of four different boxes, with similar textures, that can be stacked in a $3\times3$ grid. Varying lighting conditions and noise (up to $15\%$) in the box positioning are introduced in the observations as task irrelevant factors of variation. 
The following stacking rules apply: \emph{i)} only one box can be moved at the time, \emph{ii)} boxes cannot float or be placed outside of the grid, \emph{iii)}
only one box can be placed in a single cell, and \emph{iv)} a box can be moved only if the top cells are empty. All the actions are reversible in the task, i.e., if an action $u=(p,r)$ exists from observation $O_i$ to $O_j$, it follows that the transition from $O_j$ to $O_i$ using the reversed action \mbox{$u'=(r,p)$} is possible. 
This implies that the bidirectional edges in the LSRs are built.  


The grape harvesting task on the other hand consists of eight cells. Four cells are located in the box and the other four cells are on the vine. The scenario represents a small-scale harvesting task with four grapes, two of the white variety and two of the black one. 
As task irrelevant factors of variation, we introduce different lighting conditions, different scales of the bunches ($\pm 10\%$), positional noise inside the cells ($\pm 12.5\%$), different orientation inside the box ($\pm 180\degree $), and the bunch model is randomly chosen (with probability equal to $0.5$) between two that differ in number of grapes. 
The rules for the task are the following: \emph{i)} only one bunch can be moved at the time, \emph{ii)} only one bunch per cell and \emph{iii)} bunches can only be placed inside the box, i.e., a bunch cannot be moved from the box to the vine or from vine to vine. The last rule makes visual action planning for this task significantly more challenging compared to the box stacking task as it implies that actions are not reversible and the LSRs are directed graphs. Furthermore, several irrelevant factors of variations are introduced in this task compared to the box stacking one. Finally, it also highlights the broad  field of application of ENS-LSR, which is here deployed in an agricultural setting as in the  European  project CANOPIES.   


\begin{figure}
    \centering
    \includegraphics[width=0.7\linewidth]{figures/simu_setup.png}
\vspace{-1pt}
    \caption{Illustrations of the simulation setups: box stacking task on the left and grape harvesting on the right. Possible actions are highlighted with arrows from the picking positions (blue circles) to the release ones (green dots). 
    }
    \label{fig:simu_setup}
\end{figure}
In both tasks the system state is given by the arrangement of the objects in the cells. 
These two simulation setups are used to answer the following questions: 
\begin{enumerate}
    \item What is the improvement provided by ENS-LSR compared to individual S-LSRs with different mapping modules and how does the number $m$ of S-LSRs  affect the performance?
    \item Can ENS-LSR simplify the tuning of the LSR building parameter $c_{\max}$?
    \item What is the ensemble performance when alternative similarity measures are employed and what is the contribution of the individual similarity measures? 
\end{enumerate}


To evaluate the performance, 
 we use the same evaluation setting as in our previous works \cite{lippi2022enabling,lippi2022augment} and we refer to the quality measures \textit{\% any} and \textit{\% all}, where the former measures if any of the proposed plans results in a successful traversal from start to goal observation, while \textit{\% all} measure requires that all proposed paths are correct.  
Since our objective is to only output correct plans, we focus on the \textit{\% all} measure. 
We evaluate the performance by randomly selecting $1000$ different start and goal observations from a novel holdout set and, in case of harvesting, by checking that the path is feasible, e.g., the path is 
unfeasible if bunches are required to be moved from box to vine or from vine to vine to reach the goal observation. 
In the following, we access to the true system states for evaluation purposes only. 
 Unless specified otherwise, we use $c_{\max}=20$. 

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/simu_result_exe1.png}
\vspace{-20pt}
    \caption{Performance comparison of our ENS-LSR (in blue) with the individual models (in red, mean and variance are shown) and with the naive ensemble approach. Results for the box stacking task (left) and grape harvesting task (right) are reported. 
    }
    \label{fig:exe1_simu_results}
\end{figure}

\subsection{ENS-LSR via different mapping modules}
To answer question 1), we considered an ensemble of ten S-LSRs for each simulated task obtained by training ten different mapping modules. These were generated    
by randomly selecting $85\%$ of the training data. 
Results in terms of {\textit{\% all}} are reported in Fig. \ref{fig:exe1_simu_results}a for the box stacking task and in Fig. \ref{fig:exe1_simu_results}b for the grape harvesting task. In particular, the figure shows the performance of ENS-LSR (in blue) by increasing the number $m$ of S-LSRs from three to ten as well as it reports the performance achieved by the individual S-LSRs (in red) as well as by the naive ensemble approach (in orange) which outputs all possible VAPs, i.e., with $\mathcal{P}^*=\mathcal{P}$, as discussed in Sec.~\ref{sec:enslsr}. 

In both tasks, ENS-LSR significantly outperforms both the individual models and the naive ensemble approach. 
In particular, for the box stacking task, we can notice that simply combining all plans (naive approach) results in decreasing  performance as the number $m$ of S-LSRs increases.  In detail, it achieves $89.5\%$ with $m=3$ and $57.8\%$ with $m=10$. This is motivated by the fact that the higher $m$, 
the higher the likelihood that at least one wrong plan is suggested. 
As far as the individual models are concerned, we report both  mean (dots) and variance (shadow) of the performance obtained by utilizing $m$ S-LSRs. The figure highlights the significant variance arising from the individual models. 
 A slight performance drop can also be observed with the addition of the fifth S-LSR that only reaches $73.7\%$.
In contrast, 
our ensemble model ENS-LSR is not affected by the addition of this S-LSR and already scores $97.6\%$ with $m=3$ and  achieves $99.1\%$ with $m=10$. 


Regarding the grape harvesting task,  the individual S-LSRs only  achieve about $60\%$ performance on average for all numbers of S-LSRs   
since they are often unable to find a path. This is overcome by the naive ensemble method, where  only one of the S-LSRs needs to find a path, reaching $77.1$ with $m=3$. 
 However,  also in this task, a performance decrease is recorded with the naive approach as the number of S-LSRs increases and  a model underperforming compared to the average is included (here, the decrease occurs with $m=10$). 
Our method not only outperforms the naive approach and the individual S-LSRs, achieving  $83.3\%$ with $m=3$ and $92.6\%$ with $m=9$, but is also robust when low performing models  are included, obtaining  $92.4\%$  with $m=10$. 







\subsection{ENS-LSR via different LSR hyperparameters}
We investigated question 2) by considering an ensemble of ten S-LSRs differing with respect to the LSR hyperparameter $c_{\max}$, while employing the same mapping module. In detail, we studied  \mbox{$c_{\max}\in\{1, 10, 20, 30, 40, 50, 60, 70, 80, 90\}$}. 





\begin{table*}[t]
\centering
\resizebox{\textwidth}{!}{\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|c|}
\hline
{Stacking}  & {ENS-LSR} & $c_{\max}=1$ & $c_{\max}=10$ & $c_{\max}=20$ & $c_{\max}=30$ & $c_{\max}=40$ & $c_{\max}=50$ & $c_{\max}=60$ & $c_{\max}=70$ & $c_{\max}=80$ & $c_{\max}=90$ \\ \hline
{\textit{\% all}}   & \boldmath$98.8$ & $93.4$ & $96.4$ & $96.0$ & $94.5$ & $91.9$ & $88.5$ & $84.0$ & $80.3$ & $78.0$ & $75.4$ \\ \hline 
 {\textit{\% $\exists$ path}}   & \boldmath$100.0$ & \boldmath$100.0$ & $97.6$ & $96.9$ & $95.3$ & $92.9$ & $89.7$ & $85.2$ & $81.4$ & $79.1$ & $76.5$ \\ \hline 
\hline
\hline
{Harvesting}  & {ENS-LSR} & $c_{\max}=1$ & $c_{\max}=10$ & $c_{\max}=20$ & $c_{\max}=30$ & $c_{\max}=40$ & $c_{\max}=50$ & $c_{\max}=60$ & $c_{\max}=70$ & $c_{\max}=80$ & $c_{\max}=90$ \\ \hline 
{\textit{\% all}}   & \boldmath$69.6$ & $11.0$ & $57.6$ & $56.7$ & $54.8$ & $51.9$ & $48.2$ & $44.6$ & $40.9$ & $39.2$ & $38.5$ \\ \hline 
{\textit{\% $\exists$ path}}  & \boldmath$98.8$ & $98.1$ & $76.5$ & $65.1$ & $59.4$ & $54.4$ & $48.8$ & $44.7$ & $41.0$ & $39.3$ & $38.7$ \\ \hline 
\end{tabular}}
\vspace{-1pt}
\caption{Results in terms of \emph{\% all} performance and percentage of times a solution is found when considering 
different $c_{\max}$ hyperparameters. Both simulation tasks are reported (box stacking on top and grape harvesting on the bottom). Best results in bold.  } 
\label{tab:cmaxsimu_results}
\end{table*}
Table \ref{tab:cmaxsimu_results} summarizes the results of this analysis for both simulation tasks (stacking on top and harvesting on the bottom). 
Specifically, the performance index \textit{\% all} (second row of each block) and the percentage of times a VAP is found, denoted as \textit{\% $\exists$ path} (third row of each block), are reported for our ENS-LSR (second column) and for the individual S-LSRs (third to last column).
Results show that ENS-LSR outperforms any individual S-LSR in both tasks with regard to both metrics. More in detail, for the box stacking task, ENS-LSR achieves \textit{\% all} equal to $98.8\%$ outperforming the best individual model by $2.4\%$. Coherently  with results in \cite{lippi2022enabling}, best individual S-LSRs are obtained with $c_{\max}$  equal to $10$ and $20$ and a  performance decrease is obtained with higher $c_{\max}$ values, since more disconnected graphs are built, as well as with $c_{\max}=1$, since the method is not able to eliminate outliers in the training data. 
  The \textit{\% $\exists$ path} metric reaches maximum value with ENS-LSR, i.e., $100\%$, while for the individual S-LSRs, it starts from $100\%$ in case of a connected graph with $c_{\max}=1$ and then decreases as $c_{\max}$ increases. This is motivated by the fact that more disconnected graph components mean more risk of no path existing  from  start to goal nodes.

As far as the grape harvesting task is concerned, similar trends can be observed with ENS-LSR outperforming any 
individual S-LSR by at least $>10\%$ for \textit{\% all} and achieving $69.6\%$. Regarding the existence of a  solution, results show that ENS-LSR is able to plan a path most of the times, with \textit{\% $\exists$ path} equal to $98.8\%$, while it decreases for the individual S-LSRs as $c_{\max}$ increases,  dropping to $38.7\%$ with \mbox{$c_{\max}=90$}. 
Note that although $c_{\max}=1$ forces a single connected component, the corresponding S-LSR  only achieves $98.1\%$ for \textit{\% $\exists$ path} since it produces paths of zero length in $1.9\%$ of cases,  meaning that it incorrectly assumes that  starting and goal states have the same underlying state. 


Overall, we can summarize that our ENS-LSR is able to improve performance over individual S-LSRs both with different 
mapping module, where the maximum enhancement is achieved, and with different LSR $c_{\max}$ hyperparameter, making its tuning even easier. Example visual action plans for both simulations are shown in the accompanying video. 



\subsection{Similarity measure comparison}

 As for question 3), we analyzed  the influence of two additional action similarity measures and a node one and we conducted an ablation study on what part of Algorithm~\ref{alg::ensemble} is most beneficial to ENS-LSR.


Regarding the action similarity measures, first, we considered a simple baseline  based on the euclidean distance with action plans of same length, namely:
\begin{equation}
    s^u_{eucl}(P^u_{i,j},P^u_{k,l}) = -\|P^u_{i,j}-P^u_{k,l}\|, 
    \label{eq:dal2}
\end{equation}
which is $0$ when the plans are the same, and negative otherwise. 
In case the plans had different lengths, we assigned  no euclidean similarity measure. 
Next, we resorted to the edit similarity \cite{BILLE2005217}, which is commonly employed for comparing strings. In particular, this is based on counting the number of operations (insertion, deletion, or substitution) that are required to transform one plan into the other and weighting them according to given costs. To define if two actions $u_i$ and $u_j$ were the same, we required their euclidean distance to be lower than a threshold, i.e. $\|u_i-u_j\|<\tau$ where $\tau$ was set to $0.5$ in our tests. We employed the algorithm for the edit distance based on dynamic programming \cite{BILLE2005217} and considered costs for insertion and deletion  equal to $0.5$ and $1$, respectively. As far as the substitution cost is concerned, we set it equal 
As for the euclidean measure, we used as similarity measure the opposite of the distance. 


As far as the node similarity is concerned, we considered a baseline where the Jaccard similarity between \emph{individual} compositions of nodes in the plans is computed and then aggregated for all nodes. 
In case of plans with different lengths, we assigned no similarity measure. We refer to this baseline as $s^n_{indiv}$ and obtain it as: 
\begin{equation}
    s^n_{indiv}(P_{i,j}^z,P_{k,l}^z)=  \sum_{t=1}^{n} \frac{|C_{i,j,t} \cap C_{k,l,t}|}{|C_{i,j,t}\cup C_{k,l,t}|} 
\end{equation}
with 
$C_{i,j,t}$ and $C_{k,l,t}$ the compositions of the $t$\ts th node in the plans  $P_{i,j}^z$ and $P_{k,l}^z$, respectively. 



We compared the performance of the ensemble when using each similarity measure individually, i.e., by adding to the set $\mathcal{S}$ in line \ref{lst:line:addtos} of Algorithm~\ref{alg::ensemble} the respective measure.  
Results are shown in  Fig. \ref{fig:ablation_distance} for both simulation tasks (box stacking task on the left and grape harvesting task on the right). In particular, our ENS-LSR results, using the overall similarity, are shown in blue, the results with individual measures of action similarity based on cosine, $s^u$, euclidean distance, $s^u_{eucl}$, and edit distance, $s^u_{edit}$, are depicted in orange, green, and red, respectively, while the results with  measures of node similarity based on the path Jaccard similarity, $s^n$, and on the individual node-based Jaccard similarity, $s^n_{indiv}$, are represented in purple and brown, respectively. 


\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/simu_result_abilation.png}
\vspace{-20pt}
    \caption{Comparison with different similarity measures on the box stacking (left) and grape harvesting (right) tasks.
    }
    \label{fig:ablation_distance}
\end{figure}

For the box stacking task, we observe that all similarity measures lead to very high performance \textit{\% all}, but in general the ones requiring equal path lengths (i.e., $s^u_{eucl}$ and $s^n_{indiv}$) perform worse, while $s^n$ leads to more stable results compared to the action-based measures. Moreover, the figure shows that $s^u$ and $s^n$ generally lead to the best performance as action- and the node-based similarity measures, respectively. However, the overall similarity measure (i.e., $s^n+s^u$) outperforms all others and remains robust even if any individual similarity measure underperforms.
For the grape harvesting task, 
 a small distinction is recorded between methods that require equal path length and those that do not. This is mainly due to the fact that the S-LSRs generate noticeably fewer plans compared to the stacking task and may not find any plans in some cases, thus reducing the frequency of situations where plans of differing lengths need to be compared. 
However, we can notice  a clear performance difference between node-based similarity measures and action-based ones. Specifically, the former outperforms the latter by approximately $3\%$. 
This can be motivated by the fact that node-based similarity measures have much more fine-grained information 
compared to the action-based ones 
which is beneficial for a more accurate comparison. 
Finally, the figure shows that  $s^n+s^u$  does not lead to any undesirable performance drop for $m=10$ compared to  
$s^n_{indiv}$. 




\section{Folding results}\label{sec:exp_fold}
We validated the effectiveness of ENS-LSR in a real-world T-shirt folding task as in \cite{lippi2022augment}. This task consists of a start state, with the T-shirt spread on the table, and five goal states,  as shown in Fig. \ref{fig:folds}. Actions are expressed as pick-and-place operations as in the simulation tasks and are not reversible, leading to directed LSRs.  All execution videos and the dataset are available on the paper website\usefootref{fn:website}. 
To build the ENS-LSR we  leveraged the insights from the simulation tasks, where  a variety of mapping modules yielded to greater performance improvements compared to a variety of LSR hyperparameters only. We, therefore, constructed an ENS-LSR consisting of ten distinct mapping modules  and three different $c_{\max}$ values - specifically, $1$, $5$, and $10$, leading to $m=30$. 
We set the minimum number of nodes in a cluster to $4$ for all S-LSRs. At planning time, based on Algorithm~\ref{alg::ensemble}, the ENS-LSR  takes both the current T-shirt observation and a specified goal configuration as input, and produces one or more visual action plans as output $\mathcal{P}^*$. The first action of the plan is then executed with a Baxter robot, as shown in the accompanying video and on the project website\usefootref{fn:website}. After each action, a replanning step is made using the current state as start configuration. This procedure is repeated until ENS-LSR determines that the current state has the same underlying state as the desired goal state or when no path is found. It is worth noticing that, since ENS-LSR aims to suggest plans which are all correct, it eliminates the need for human selection as in \cite{lippi2022enabling, lippi2022augment}, but  simply  randomly selects and executes a VAP in $\mathcal{P}^*$.






\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/folds.png}
\vspace{-15pt}
    \caption{Start and goal configurations for the real-world folding task.}
    \label{fig:folds}
\end{figure}



\begin{table}[]
\resizebox{\linewidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|}
\hline
Framework & Fold 1 & Fold 2 & Fold 3 & Fold 4 & Fold 5 \\ \hline
ENS-LSR  &   \boldmath$5/5$     &     \boldmath$5/5$   &   \boldmath$4/5$     &  \boldmath$5/5$   &  $3/5$      \\ \hline
ACE-LSR   &    $4/5$    &   \boldmath$5/5$     &    $3/5$    &   $4/5$     &     \boldmath$4/5$   \\ \hline
\end{tabular}
}
\vspace{-1pt}
\caption{Performance results on the T-shirt folding task with ENS-LSR and ACE-LSR  on five different folds, each repeated five times. Best results in bold.  }
\label{tab:exe_fold}
%\vspace{-2pt}
\end{table}

We repeated the  execution  to each goal configuration five times as in our previous works and reported the system performance in Table \ref{tab:exe_fold}, where we compared it with our latest framework \cite{lippi2022augment}, i.e., ACE-LSR, which implements a paradigm for dealing with data scarcity. We employed for both models a dataset composed of $562$ tuples, which is $50\%$ of the training data used in \cite{lippi2022enabling}. 
Results show that ENS-LSR is generally more robust than ACE-LSR, successfully executing folds $1$, $2$, and $4$ at all times, and achieving overall performance of $88\%$, which  outperforms by $8\%$ the previously top-performing ACE-LSR model. 
A slight performance decrease is only recorded with 
Fold $5$, where ENS-LSR occasionally misses the final step that involves picking up a small T-shirt edge, as shown on the website\usefootref{fn:website}.
