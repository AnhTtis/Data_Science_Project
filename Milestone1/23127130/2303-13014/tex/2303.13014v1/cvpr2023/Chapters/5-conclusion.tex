\section{Conclusion}
In this paper, we have proposed a generalizable semantic field named Semantic Ray, which is able to learn from multiple scenes and generalize to unseen scenes. Different from Semantic NeRF which relies on positional encoding thereby limited to the specific single scene, we design a Cross-Reprojection Attention module to fully exploit semantic information from multiple reprojections of the ray. In order to capture dense connections of reprojected rays in an efficient manner, we decompose the problem into consecutive intra-view radial and cross-view sparse attentions to extract informative semantics with small computational costs. 
Extensive experiments on both synthetic and real-world datasets demonstrate the strong generalizability of our S-Ray and effectiveness of our Cross-Reprojection Attention module. With the generalizable semantic field, we believe that S-Ray will encourage more explorations of potential NeRF-based high-level vision problems in the future.

\noindent \textbf{Acknowledgements. }This work was supported in part by the National Natural Science Foundation of China under Grant 62206147, and in part by Deng Feng Fund.



