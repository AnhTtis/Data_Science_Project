%% EDITABLE LINK:
% https://www.overleaf.com/3989426424jdjdbgpsswjg
\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2020

% ready for submission
% \usepackage{neurips_2020}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2020}

% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2020}

% to avoid loading the natbib package, add option nonatbib:
\usepackage{misc/acl_2023}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\usepackage{times}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{cleveref}
\usepackage{caption}
%\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{bm}
\usepackage{soul}
\usepackage{subfig}

% increase line spacing to fill 8 pages
\renewcommand{\baselinestretch}{1.07} 

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}

\input{misc/macros.tex}

\usepackage[normalem]{ulem} % sout, uline
\usepackage{xcolor}
\def\XXX#1{\textcolor{red}{XXX #1}}
\def\repl#1#2{\textcolor{red}{XXX \sout{#1}}\textcolor{blue}{\uline{#2}}}


\title{Multimodal Shannon Game with Images}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{
Vilém Zouhar$^{\ufalletter\,\ethletter}_=$ \qquad
Sunit Bhattacharya$^{\ufalletter}_=$ \qquad
Ondřej Bojar$^{\ufalletter}$ \\ \\
$^{\ethletter}$ETH Zürich \qquad
$^{\ufalletter}$Institute of Formal and Applied Linguistics, Charles University \\
\texttt{\{\href{mailto:zouhar@ufal.mff.cuni.cz}{\textcolor{black}{zouhar}},\href{mailto:bhattacharya@ufal.mff.cuni.cz}{\textcolor{black}{bhattacharya}},\href{mailto:bojar@ufal.mff.cuni.cz}{\textcolor{black}{bojar}}\}@ufal.mff.cuni.cz}
}

\begin{document}

\maketitle

\begin{abstract}

The Shannon game has long been used as a thought experiment in linguistics and NLP, asking participants to guess the next letter in a sentence based on its preceding context.
We extend the game by introducing an optional extra modality in the form of image information.
To investigate the impact of multimodal information in this game, we use human participants and a language model (LM, GPT-2).

We show that the addition of image information improves both self-reported confidence and accuracy for  both humans and LM.
Certain word classes, such as nouns and determiners, benefit more from the additional modality information.
The priming effect in both humans and the LM becomes more apparent as the context size (extra modality information + sentence context) increases.
These findings highlight the potential of multimodal information in improving language understanding and modeling.

% In the Shannon game, the goal is to guess the next letter or word in a sentence based on the previous context.
% It has since become a widely known thought experiment on which many concepts in psycholinguistics, computational linguistics and NLP are based.
% We extend this thought experiment by including an optional extra modality in the form of image information and run an experiment on human participants and large language models (GPT-2). 
% \st{We extend this game by including an optional extra modality in the form of images and run an experiment on human participants. We replicate a version of this experiment on the GPT-2 family and compare the results in terms of accuracy and confidence to human counterparts.}
% We analyze the effects of addition of this extra information on a sentence completion task as an experiment in `priming' and present our observations. We also replicate a constrained version of the thought experiment in a text-only setting with GPT-2 models. We frame the experiments with GPT-2 as experiments on `prompting' and present our observations.
% \st{We find that the presence of an image greatly improves users’ confidence and accuracy across all POS including determiners (\emph{a, an, the}), which we expected should otherwise be predicted solely from the previous (left) context of the sentence.}

% We find that the presence of the extra modality information significantly improves the self-reported confidence and self-reported accuracy of the participants in the human experiment as well as in our experiments with GPT-2 models.
% . We also find a similar boost in the `confidence' and `accuracy' with the inclusion of the extra modality information in our GPT-2 experiments. 
% For both the human and machine experiments, word classes like nouns and determiners benefit from the additional modality information.
% Finally, the priming effect in both humans and the GPT-2 systems are far more noticeable as the context size (extra modality information + sentence context) increases.
% We find that the presence of an image greatly improves users' confidence and accuracy across all POS.

\end{abstract}

% GitHub logo
\hspace{-2mm}
\begin{minipage}[c]{5mm}
\includegraphics[width=\linewidth]{img/github_mark.pdf}
\end{minipage}
\hspace{0.1mm}
\begin{minipage}[c]{0.7\textwidth}
\fontsize{0.76em}{0.76em}\selectfont
Code: 
\begin{minipage}[c]{0.7\textwidth}
    \href
    {https://github.com/zouharvi/mmsg}
    {\texttt{github.com/zouharvi/mmsg}}
\end{minipage}
\end{minipage}

% Website logo
\hspace{-2mm}
\begin{minipage}[c]{5mm}
\includegraphics[width=\linewidth]{img/globe.pdf}
\end{minipage}
\hspace{0.1mm}
\begin{minipage}[c]{0.7\textwidth}
\fontsize{0.76em}{0.76em}\selectfont
Annotation demo: \href
{https://vilda.net/s/mmsg/?uid=demo}
{\texttt{vilda.net/s/mmsg?uid=demo}}
\end{minipage}


\let\svthefootnote\thefootnote
\let\thefootnote\svthefootnote
\let\svthefootnote\thefootnote
\newcommand\blankfootnote[1]{%
  \let\thefootnote\relax\footnotetext{#1}%
  \let\thefootnote\svthefootnote%
}

\blankfootnote{\hspace{-2mm}$^=$Co-first authors.}

\input{content.tex}

% \newpage

\bibliography{misc/bibliography}
\bibliographystyle{misc/acl_natbib}

\onecolumn

\appendix

\section*{Appendix}
% \clearpage

\input{appendix.tex}

\end{document}
