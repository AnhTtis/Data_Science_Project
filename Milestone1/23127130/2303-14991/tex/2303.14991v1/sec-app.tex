\clearpage

\section*{Appendix}
\appendix

\section{Dataset} \label{sec:dataset}

\paratitle{XOR-Retrieve.} XOR-Retrieve dataset is a cross-lingual retrieval dataset which aims to retrieve relevant passages from the English corpus for non-English queries. XOR-Retrieve data contains queries in seven typologically diverse languages: Arabic~(Ar), Bengali~(Bn), Finnish~(Fi), Japanese~(Ja), Korean~(Ko), Russian~(Ru), and Telugu~(Te). The statistics are presented in Table~\ref{tab:stat}.

\begin{table}[h] \small
\centering
\caption{Data statistics for XOR-Retrieve.}
\begin{tabular}{c|rrr} \toprule
    ~  & Train & Dev & Test \\ \midrule
    Ar & 2,574 & 350 & 137 \\
    Bn & 2,582 & 312 & 128 \\
    Fi & 2,088 & 360 & 530 \\
    Ja & 2,288 & 296 & 449 \\
    Ko & 2,469 & 299 & 646 \\
    Ru & 1,941 & 366 & 235 \\
    Te & 1,308 & 238 & 374 \\ \midrule
    Corpus size & \multicolumn{3}{c}{18,003,200} \\ \bottomrule
\end{tabular}
\label{tab:stat}
\end{table}

\paratitle{MKQA.} MKQA dataset is a translated dataset of 10,000 query-answer pairs from NQ to 26 different languages, and the dataset is only used for evaluation. In our experiments, since we measure the R@2kt score, we filter the samples which do not have span answers. Then, we get 6,620 parallel queries in each language. Finally, we directly evaluate the dual-encoder trained on XOR-Retrieve data and use the same corpus with XOR-Retrieve in the experiments. Note that Arabic~(Ar), English~(En), Finnish~(Fi), Japanese~(Ja), Korean~(Ko), and Russian~(Ru) are seen in the training stage and we only report the performance of the rest 20 languages. As a result, it has a total of 132,400 samples.

\section{Efficiency Report}

We list the time cost of training and inference in Table~\ref{tab:efficiency} which is made with 8 NVIDIA A100 GPUs.

\begin{table}[b] \small
\centering
\caption{Efficiency Report.}
\begin{tabular}{l|l|c} \toprule
     \multirow{5}{*}{Training} & Warm-up & 3h \\
     ~ & Per Iteration of Dual-Encoder & 1h \\
     ~ & Per Iteration of Generator & 0.3h \\
     ~ & Index Refresh & 0.35h \\
     ~ & Overall & 11.5h \\ \midrule
     \multirow{3}{*}{Inference} & Build Index & 0.35h \\
     ~ & Query Encoding & 40ns \\
     ~ & Dense Retrieval & 2ms \\ \midrule
\end{tabular}
\label{tab:efficiency}
\end{table}

\section{Hyper-parameters} \label{sec:param}

We present all hyper-parameters in Table~\ref{tab:params}. 

\begin{table}[t] \small
\centering
\caption{Hyper-parameters.}
\begin{tabular}{c|l|c} \toprule
     ~ & Parameters & Value \\ \midrule
     ~ & Max Query Length & 32 \\
     ~ & Max Passage Length & 128 \\ \midrule
     \multirow{8}{*}{\shortstack{Training \\ Warm-up \\ Dual-Encoder}} & Learning Rate & 1e-5 \\
     ~ & Batch Size & 128 \\
     ~ & Negative Size & 255 \\
     ~ & Optimizer & AdamW \\ 
     ~ & Scheduler & Linear \\
     ~ & Warmup Proportion & 0.1 \\
     ~ & Training Steps on NQ & 18400 \\
     ~ & Training Steps on XOR & 2000 \\\midrule
     \multirow{6}{*}{\shortstack{Training \\ Warm-up \\ Generator \\ on QG}} & Learning Rate & 1e-4 \\
     ~ & Batch Size & 64 \\
     ~ & Optimizer & AdamW \\ 
     ~ & Scheduler & Linear \\
     ~ & Warmup Proportion & 0.1 \\
     ~ & Training Steps & 5000 \\ \midrule
     \multirow{7}{*}{\shortstack{Training \\ Warm-up \\ Generator \\ on Re-ranking}} & Learning Rate & 1e-5 \\
     ~ & Batch Size & 32 \\
     ~ & Negative Size & 15 \\
     ~ & Optimizer & AdamW \\ 
     ~ & Scheduler & Linear \\
     ~ & Warmup Proportion & 0.1 \\
     ~ & Training Steps & 1000 \\ \midrule
     \multirow{10}{*}{\shortstack{Iteraively \\ Training of \\ Dual-Encoder}} & Learning Rate & 1e-5 \\
     ~ & Batch Size & 64 \\
     ~ & Candidate Size & 32 \\
     ~ & Optimizer & AdamW \\ 
     ~ & Scheduler & Linear \\
     ~ & Warmup Proportion & 0.1 \\
     ~ & Training Steps & 3000 \\
     ~ & Threshold $T$ in Eq.~\eqref{eq:thresh} & 0.3 \\
     ~ & Coefficient $\alpha$ in Eq.~\eqref{eq:final} & 0.5 \\
     ~ & \# of iterations & 5 \\ \midrule
     \multirow{8}{*}{\shortstack{Iteraively \\ Training of \\ Generator}} & Learning Rate & 1e-5 \\
     ~ & Batch Size & 32 \\
     ~ & Negative Size & 15 \\
     ~ & Optimizer & AdamW \\ 
     ~ & Scheduler & Linear \\
     ~ & Warmup Proportion & 0.1 \\
     ~ & Training Steps & 500 \\
     ~ & \# of iterations & 5 \\ \bottomrule
\end{tabular}
\label{tab:params}
\end{table}

\begin{figure}[t]
    \centering
    \subfigure[Threshold~($T$).]{
        \includegraphics[width=0.75\columnwidth]{figures/thresh.pdf}
    }
    \subfigure[Coefficient~($\alpha$).]{
        \includegraphics[width=0.75\columnwidth]{figures/alpha.pdf}
    }
    \caption{Parameter sensitivity.}
    \label{fig:sensitivity}
\end{figure}

\section{Additional Experiments} \label{sec:sens}

\subsection{Parameter Sensitivity}

In this section, we tune the parameters of the proposed method to analyze parameter sensitivity. We vary both the threshold $T$~(Eq.~\eqref{eq:thresh}) and the coefficient $\alpha$~(Eq.~\eqref{eq:final}) in the set $\{0.1,$ $0.3,$ $0.5,$ $0.7,$ $0.9\}$. We report the tuning results with both R@2kt and R@5kt on the XOR-Retrieve dev set in Figure~\ref{fig:sensitivity}. As we can see, $T = 0.3$ and $\alpha = 0.5$ lead to the optimal R@5kt which is the ordering basis on the leaderboard.

In addition, we find that the optimal R@2kt and R@5kt are led by different thresholds $T$. Because the two metrics have different sensitivities to data quality, low-quality data is helpful to R@5kt but harmful to R@2kt. As a result, a small threshold $T$ leads to more low-quality alignment training data and further leads to higher R@5kt but lower R@2kt. On the contrary, the optimal R@2kt and R@5kt are led by the same coefficient $\alpha$.

Overall, our model is relatively stable when varying the two parameters, and consistently better than Sentri and Dr.DECR w/o KD$_{PC}$.

\subsection{Effect of The Number of Candidates}

Here, we investigate the effect of the number of candidates which is demonstrated to have a significant effect on the final performance. As shown in Figure~\ref{fig:candidate}, a large number of candidates leads to better performance. And when the number surpasses 32, the improvement gradually slows down. The results indicate that 32 candidates can better represent the whole corpus.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.66\columnwidth]{figures/candidate.pdf}
    \caption{Effect of the number of candidate passages.}
    \label{fig:candidate}
\end{figure}

\subsection{Effect of Model Size}

\begin{table}[t] \small
\centering
\caption{Effect of model size.}
\begin{tabular}{c|cc|cc} \toprule
    \multirow{2.5}{*}{~} &\multicolumn{2}{c|}{XLM-R Base} & \multicolumn{2}{c}{XLM-R Large} \\ \cmidrule(lr){2-5}
    ~ & R@2kt & R@5kt & R@2kt & R@5kt \\ \midrule
    Ar & 52.8 & 63.8 & \textbf{64.4} & \textbf{72.2} \\
    Bn & 70.1 & 78.0 & \textbf{77.0} & \textbf{80.9} \\
    Fi & 62.2 & 65.3 & \textbf{67.0} & \textbf{70.1} \\
    Ja & 54.8 & 63.5 & \textbf{56.4} & \textbf{67.2} \\
    Ko & 62.8 & 69.8 & \textbf{67.4} & \textbf{73.3} \\
    Ru & 57.8 & 67.1 & \textbf{66.7} & \textbf{72.2} \\
    Te & 70.6 & 74.8 & \textbf{79.4} & \textbf{84.0} \\
    Avg & 61.3 & 68.9 & \textbf{68.4} & \textbf{74.3} \\ \bottomrule
\end{tabular}
\label{tab:large}
\end{table}

Following Sentri~\cite{soro2022ask}, we employ a shared encoder~(\ie the parameters of the query encoder and the passage encoder are the same) with large size as the dual-encoder and evaluate our method. As shown in Table~\ref{tab:large}, \name with XLM-R Large achieves a significant performance improvement, which further demonstrates the effectiveness of the proposed \name.

\subsection{Effect of Scheduled Sampling}

Previously, we demonstrate the effectiveness of the scheduled sampling by ablation study. Here, we present two generated samples to qualitatively analyze the scheduled sampling. As shown in Table~\ref{tab:example}, for the first case, the generated queries in other languages have the same semantics as the query from the source language. The sample is effective in alignment training and is helpful to achieve better performance. For the second case, the generated query in Finnish is relevant to  the query from the source language but not synonymous. The sample is harmful to the model training. These samples indicate that the scheduled sampling is necessary for alignment training. In this way, we can reduce the impact of the cases which do not have the same semantics and further achieve better performance.

\begin{table}[t] \footnotesize
\centering
\setlength\tabcolsep{4pt}
\caption{Two generated examples. The span answers are in bold.}
\begin{tabular}{p{0.95\columnwidth}} \toprule

    \textbf{Passage:} Johanna Maria Magdalena "Magda" Goebbels (née Ritschel; \textcolor{red}{\textbf{11 November 1901 – 1 May 1945}}) was the wife of Nazi Germany\'s Propaganda Minister Joseph Goebbels. A prominent member of the Nazi Party, she was a close ally, companion and political supporter of Adolf Hitler. Some historians refer to her as the unofficial "First Lady" of Nazi Germany, while others give that title to Emmy Göring. \\ \midrule
    \textbf{Source Query~(Ja):}\begin{CJK}{UTF8}{min}ヨハンナ・マリア・マクダレナ・ゲッベルスは何歳で死去した？\end{CJK} \\
    \textbf{Translation:} At what age did Johanna Maria McDalena Goebbels die? \\  \midrule
    \textbf{Generated Query~(Ru):} \foreignlanguage{russian}{В каком возрасте умерла Магда Геббельс?} \\
    \textbf{Translation:} At what age did Magda Goebbels die? \\ \midrule
    \textbf{Generated Query~(Fi):} Minä vuonna Magda Goebbels kuoli? \\
    \textbf{Translation:} In what year did Magda Goebbels die? \\  \midrule

    \textbf{Passage:} Charles V \textcolor{red}{\textbf{(24 February 1500 – 21 September 1558)}} was ruler of both the Holy Roman Empire from 1519 and the Spanish Empire (as Charles V of Spain) from 1516, as well as of the lands of the former Duchy of Burgundy from 1506. He stepped down from these and other positions by a series of abdications between 1554 and 1556. Through inheritance, he brought together under his rule extensive territories in western, central, and southern Europe, and the Spanish viceroyalties in the Americas and Asia. \\  \midrule
    \textbf{Source Query~(Ko):} \begin{CJK}{UTF8}{mj}신성 로마 제국 카를 5세 재위기간은 얼마나 되나요?\end{CJK} \\
    \textbf{Translation:} How long was the reign of Charles V of the Holy Roman Empire? \\ \midrule
    \textbf{Generated Query~(Ru):} \foreignlanguage{russian}{Сколько лет правил Карл V?} \\
    \textbf{Translation:} How many years did Charles V rule? \\ \midrule
    \textbf{Generated Query~(Fi):} Minä vuonna Charles V hallitsi Rooman valtakuntaa? \\
    \textbf{Translation:} In what year did Charles V rule the Roman Empire? \\
    
    \bottomrule 
\end{tabular}
\label{tab:example}
\end{table}

\begin{table}[t] \footnotesize
\centering
\setlength\tabcolsep{4pt}
\caption{A generated example with different input templates. The span answer is in bold. Here, ``QG'' denotes query generator.}
\begin{tabular}{p{0.95\columnwidth}} \toprule

    \textbf{Passage:} The Higgs boson is an elementary particle in the Standard Model of particle physics, produced by the quantum excitation of the Higgs field, one of the fields in particle physics theory. It is named after physicist \textcolor{red}{\textbf{Peter Higgs}}, who in 1964, along with five other scientists, proposed the mechanism which suggested the existence of such a particle. Its existence was confirmed in 2012 by the ATLAS and CMS collaborations based on collisions in the LHC at CERN. \\ \midrule
    \textbf{Generated Query by \uline{QG w/ span answer}~(Fi):} Kuka on kehittänyt Higgs-boson? \\
    \textbf{Translation:} Who developed the Higgs boson? \\  \midrule
    \textbf{Generated Query by \uline{QG w/ span answer}~(Ko):} \begin{CJK}{UTF8}{mj}히그슨을 처음 발견한 사람은 누구인가?\end{CJK} \\
    \textbf{Translation:} Who first discovered Higson? \\ \midrule
    
    \textbf{Generated Query by \uline{QG w/o span answer}~(Fi):} Milloin Higgs on löydetty? \\
    \textbf{Translation:} When was Higgs Found? \\  \midrule
    \textbf{Generated Query by \uline{QG w/o span answer}~(Ko):} \foreignlanguage{russian}{Кто был первым исследователем физики Higgs?} \\
    \textbf{Translation:} Who was Higgs' first physics researcher? \\ \bottomrule 
\end{tabular}
\label{tab:answer-example}
\end{table}

\subsection{Effect of Span Answer}

In our method, we employ the span answer to encourage the query generator to generate synonymous queries. Here, we conduct experiments to evaluate the effect of the span answer. Specially, we use another template: \emph{``generate [language] query: [content]''} where we only need to fill two placeholders with the language of the target query and the passage content. We also incorporate the cross-encoder for comparison. We use the re-rankers to re-rank the retrieved results of the warm-up dual-encoder initialized with XLM-R. Note that introducing the span answer into the cross-encoder makes the re-ranking task easier, because the cross-encoder only needs to check whether the passage contains the span answer. The scores of this cross-encoder almost degenerate into hard labels and it is difficult to effectively train the dual-encoder by distilling knowledge from this cross-encoder.

We show the results in Table~\ref{tab:re-ranker}. Based on these results, we have the following findings.
On the one hand, the query generator trained with span answers is better than the query generator without span answers. It shows that taking span answers as input leads to better performance on re-ranking tasks for the query generator.
On the other hand, both the two query generator is better than the cross-encoder when re-ranking top-1000 retrieved passages, it shows the effectiveness of the query generator  in the cross-lingual setting. 

\begin{table*}[t] \footnotesize
\centering
\setlength\tabcolsep{4pt}
\caption{Performance comparison of different re-rankers on XOR-Retrieve dev set. The best results are in bold. Here, ``QG'' denotes query generator.}
\begin{tabular}{l|ccccccc|c|ccccccc|c} \toprule
    \multirow{2.5}{*}{Methods} & \multicolumn{8}{c|}{R@2kt} & \multicolumn{8}{c}{R@5kt} \\ \cmidrule(lr){2-17}
    ~ & Ar & Bn & Fi & Ja & Ko & Ru & Te & Avg & Ar & Bn & Fi & Ja & Ko & Ru & Te & Avg \\ \midrule
    Dual-Encoder & 35.3 & 43.1 & 50.3 & 35.7 & 44.6 & 31.2 & 50.0 & 41.5 & 49.5 & 54.9 & 59.2 & 45.2 & 55.1 & 31.2 & 63.4 & 53.4 \\ \midrule 
    \multicolumn{17}{c}{Re-ranking top-100 retrieved passages} \\ \midrule
    QG w/ Answer & \textbf{51.1} & \textbf{57.2} & 53.5 & \textbf{43.2} & \textbf{55.1} & \textbf{43.9} & 61.8 & \textbf{52.3} & \textbf{56.6} & 60.5 & 60.5 & \textbf{51.0} & \textbf{60.7} & 46.4 & 67.6 & \textbf{57.6} \\
    QG w/o Answer & 48.9 & 55.6 & 54.1 & 41.9 & 53.3 & 43.5 & 61.8 & 51.3 & \textbf{56.6} & \textbf{60.9} & 59.9 & 49.8 & 59.3 & 46.8 & \textbf{68.1} & 57.3 \\
    Cross-Encoder & 49.2 & 53.6 & \textbf{57.6} & 41.1 & 54.0 & 41.4 & \textbf{63.0} & 51.4 & 55.3 & 59.9 & \textbf{62.1} & 49.8 & 60.4 & \textbf{47.3} & 66.4 & 57.3 \\
     \midrule
    \multicolumn{17}{c}{Re-ranking top-1000 retrieved passages} \\ \midrule
    QG w/ Answer & \textbf{53.7} & \textbf{66.1} & \textbf{56.7} & \textbf{52.3} & \textbf{59.3} & \textbf{56.1} & \textbf{68.9} & \textbf{59.0} & \textbf{61.2} & \textbf{71.1} & 62.1 & \textbf{58.1} & 65.6 & \textbf{61.6} & \textbf{74.4} & \textbf{64.9} \\
    QG w/o Answer & 52.4 & 62.8 & 56.1 & 49.0 & 58.2 & 55.7 & 64.3 & 56.9 & 59.9 & 70.7 & 62.1 & 57.3 & 64.9 & 59.9 & 73.5 & 64.0 \\
    Cross-Encoder & 50.8 & 58.2 & 55.1 & 45.2 & \textbf{59.3} & 50.6 & 65.5 & 55.0 & \textbf{61.2} & 67.4 & \textbf{63.4} & 53.5 & \textbf{66.3} & 56.1 & 73.9 & 63.1 \\ 
    \bottomrule 
\end{tabular}
\label{tab:re-ranker}
\end{table*}

In addition, we show queries generated by the two query generators in Table~\ref{tab:answer-example}. As we can see, for the query generator that does not take the span answer as input, the generated queries can be answered by the passage, but they focus on different segments of the passage and they are not synonymous. On contrary, for the query generator that takes the span answer as input, generated queries can be answered by the passage and they are synonymous. It shows that taking the span answer as input can effectively encourage the generator to generate synonymous queries.

\begin{table*}[t] \footnotesize
\centering
\caption{Detailed performance on MKQA test set. ``$\ast$'' denotes that the results are copied from the Sentri paper.}
\begin{tabular}{ccccccccccc} \toprule
    Methods & Da & De & Es & Fr & He & Hu & It & Km & Ms & Nl \\ \midrule
    CORA$^{\ast}$ & 44.5 & 44.6 & 45.3 & 44.8 & 27.3 & 39.1 & 44.2 & 22.2 & 44.3 & 47.3 \\
    BM25 + MT$^{\ast}$ & 44.1 & 43.3 & 44.9 & 42.5 & 36.9 & 39.3 & 40.1 & 31.3 & 42.5 & 46.5 \\
    Sentri$^{\ast}$ & 57.6 & 56.5 & 55.9 & 55.1 & 47.9 & 51.8 & 54.3 & 43.9 & 56.0 & 56.3 \\
    ~~~ w/ Bi-Encoder$^{\ast}$ & 50.0 & 47.8 & 48.7 & 47.4 & 37.7 & 43.4 & 41.8 & 37.8 & 49.5 & 47.3 \\ \midrule
    \name & 58.3 & 56.4 & 55.2 & 55.5 & 44.7 & 52.4 & 52.3 & 42.0 & 56.9 & 57.5 \\
    \name w/ LaBSE & \textbf{63.3} & \textbf{61.8} & \textbf{62.2} & \textbf{62.4} & \textbf{56.1} & \textbf{58.9} & \textbf{60.6} & \textbf{53.0} & \textbf{64.2} & \textbf{63.0} \\ \midrule
    No & Pl & Pt & Sv & Th & Tr & Vi & Zh-cn & Zh-hk & Zh-tw & Avg \\ \midrule
    48.3 & 44.8 & 40.8 & 43.6 & 45.0 & 34.8 & 33.9 & 33.5 & 41.5 & 41.0 & 41.1 \\
    43.3 & 46.5 & 45.7 & 49.7 & 46.5 & 42.5 & 43.5 & 37.5 & 37.5 & 36.1 & 42.0 \\
    56.5 & 55.8 & 54.8 & 56.9 & 55.3 & 53.0 & 54.4 & 50.2 & 50.7 & 49.4 & 53.3 \\
    49.1 & 47.0 & 47.7 & 50.0 & 46.5 & 45.6 & 47.3 & 42.6 & 41.5 & 41.0 & 45.3 \\\midrule
    57.0 & 54.9 & 54.7 & 58.0 & 55.7 & 53.9 & 54.9 & 50.4 & 49.3 & 48.9 & 53.4 \\
    \textbf{62.8} & \textbf{62.0} & \textbf{61.5} & \textbf{63.3} & \textbf{60.5} & \textbf{60.6} & \textbf{61.8} & \textbf{57.3} & \textbf{56.3} & \textbf{56.0} & \textbf{60.3} \\ \bottomrule
\end{tabular}
\label{tab:mkqa-lang}
\end{table*}


\begin{table*}[t] \footnotesize
\centering
\setlength\tabcolsep{4pt}
\caption{Detailed performance for ablation study on XOR-Retrieve dev set. }
\begin{tabular}{l|ccccccc|c|ccccccc|c} \toprule
    \multirow{2.5}{*}{~} & \multicolumn{8}{c|}{R@2kt} & \multicolumn{8}{c}{R@5kt} \\ \cmidrule(lr){2-17}
    ~ & Ar & Bn & Fi & Ja & Ko & Ru & Te & Avg & Ar & Bn & Fi & Ja & Ko & Ru & Te & Avg \\ \midrule
    \name & 52.8 & \textbf{70.1} & 60.2 & \textbf{54.8} & \textbf{62.8} & \textbf{57.8} & \textbf{70.6} & \textbf{61.3} & \textbf{63.8} & \textbf{78.0} & \textbf{65.3} & \textbf{63.5} & \textbf{69.8} & \textbf{67.1} & 74.8 & \textbf{68.9} \\ \midrule
    w/o Sampling & \textbf{53.1} & 68.4 & 60.2 & 50.2 & 61.1 & 55.7 & 68.1 & 59.5 & 63.4 & \textbf{78.0} & 64.6 & 60.6 & 68.1 & 63.7 & 74.4 & 67.5 \\
    w/o Alignment & 51.8 & 68.1 & \textbf{60.8} & 51.0 & 60.4 & 57.4 & 70.2 & 59.9 & 61.5 & 74.7 & 64.6 & 62.7 & 68.8 & 62.4 & \textbf{75.2} & 67.1 \\
    w/o Generation & 55.0 & 68.1 & 59.6 & 47.3 & 60.7 & 54.9 & 66.4 & 58.8 & 62.8 & 74.0 & 65.0 & 56.4 & 66.3 & 62.0 & 74.8 & 65.9 \\
    w/o All & 35.3 & 43.1 & 50.3 & 35.7 & 44.6 & 31.2 & 50.0 & 41.5 & 49.5 & 54.9 & 59.2 & 45.2 & 55.1 & 31.2 & 63.4 & 53.4 \\ \bottomrule 
\end{tabular}
\label{tab:ablation-lang}
\end{table*}

\begin{table*}[t] \footnotesize
\centering
\setlength\tabcolsep{4pt}
\caption{Detailed performance of alignment based on different pre-trained languages models. }
\begin{tabular}{l|ccccccc|c|ccccccc|c} \toprule
    \multirow{2.5}{*}{~} & \multicolumn{8}{c|}{R@2kt} & \multicolumn{8}{c}{R@5kt} \\ \cmidrule(lr){2-17}
    ~ & Ar & Bn & Fi & Ja & Ko & Ru & Te & Avg & Ar & Bn & Fi & Ja & Ko & Ru & Te & Avg \\ \midrule
    XLM-R & \textbf{52.8} & \textbf{70.1} & 60.2 & \textbf{54.8} & \textbf{62.8} & \textbf{57.8} & \textbf{70.6} & \textbf{61.3} & \textbf{63.8} & \textbf{78.0} & \textbf{65.3} & \textbf{63.5} & \textbf{69.8} & \textbf{67.1} & 74.8 & \textbf{68.9} \\
    w/o Alignment & 51.8 & 68.1 & \textbf{60.8} & 51.0 & 60.4 & 57.4 & 70.2 & 59.9 & 61.5 & 74.7 & 64.6 & 62.7 & 68.8 & 62.4 & \textbf{75.2} & 67.1 \\ \midrule
    LaBSE & \textbf{67.3} & \textbf{78.9} & \textbf{65.9} & \textbf{59.8} & 66.3 & \textbf{63.7} & \textbf{80.7} & \textbf{68.9} & 72.2 & \textbf{83.2} & \textbf{69.7} & \textbf{68.0} & 70.9 & \textbf{71.7} & \textbf{84.9} & \textbf{74.4} \\
    w/o Alignment & 65.7 & 78.3 & 65.0 & 58.9 & \textbf{67.0} & 62.9 & 77.3 & 67.9 & \textbf{72.5} & 80.9 & \textbf{69.7} & 66.8 & \textbf{71.9} & 70.5 & 84.5 & 73.8 \\ \bottomrule 
\end{tabular}
\label{tab:align-lang}
\end{table*}

\section{Detailed Results}

Due to the limited space, we only present average performance for some experiments in Section~\ref{sec:exp}. Here, we present the detailed performance in all languages of these experiments. Firstly, we present the detailed performance of all methods on the MKQA test set in Table~\ref{tab:mkqa-lang}. Secondly, we present the detailed performance of ablation results in Table~\ref{tab:ablation-lang}. Finally, we present the detailed performance for evaluating the effect of alignment in Table~\ref{tab:align-lang}.