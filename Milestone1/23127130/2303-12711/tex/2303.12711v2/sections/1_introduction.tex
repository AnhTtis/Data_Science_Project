

\chapter{Introduction}

\subsection*{Clinical Problem}

Within the field of machine learning, an increasing demand exists for applications to medical settings, such as brain imaging, drug discovery, and one of the most popular fields, oncological research. Here, advances in medical machine learning and deep learning have supported clinicians in making diagnoses, achieving high performance on, for instance breast cancer and brain cancer diagnosis tasks \cite{KOUROU20158}. One type of cancer that may benefit much from recent advances in machine learning is esophageal cancer. Its subtype Esophageal adenocarcinoma (EAC) specifically, is becoming increasingly common, but is often diagnosed at a late stage and does not have a good prognosis \cite{EAC}. Barrett’s Esophagus (BE), a phenomenon where the cells lining the esophagus change to resemble those lining the stomach, is the only known precursor. Barrett’s esophagus progresses in four stages from healthy squamous tissue, to benign metaplasia, to low-grade dysplasia, to high-grade dysplasia, and finally to cancer, as can also be seen in Figure \ref{fig:progression}. This means that there exists the possibility of preventing cancer if dysplasia is detected and treated early on. Detection of dysplasia is done by a pathologist, who examines endoscopic biopsies at cell tissue level and classes them into one of the different progression stages, thereby indicating patients at risk. However, this process is highly subjective, and reported progression rates from low-grade dysplasia to cancer vary significantly \cite{vanderwelBarrett}. 

Recently, advances in deep learning have been made to support the diagnosis of BE. Most work has focused on creating a “digital pathologist,” or a convolutional neural network that classifies biopsy regions into certain levels of dysplasia \cite{de2018survey, barretcnn1}.  While these models have achieved good results, they are also limited by the high level of interobserver variability present in training data and therefore cannot rise above real-life pathologists. This makes the clinical use case of these models limited. 

\begin{figure}[H]
    \centering
    \includegraphics[width=.8\textwidth]{images/related_work/Barret_progression.png}
    \caption{Examples of biopsies with different stages of progression. From left to right: regular squamous epithelium, non-dysplastic BE, low-grade dysplastic BE, high-grade dysplastic BE, and finally EAC (esophageal cancer).}
    \label{fig:progression}
\end{figure}

\subsection*{Technical Problem}
Unsupervised machine learning therefore presents itself as a promising research area. As the subfield of machine learning that does not train using any form of labeled data, it does not suffer from the high variance in labeling between different clinical professionals that characterizes the more common supervised techniques. Instead, unsupervised learning attempts to find a subset of meaningful features within the training data to accomplish its tasks, a subfield also known as \textit{representation learning} \cite{bengio2012representation}. Not only can representation learning be used to reduce the dimensionality of the data, but it can also be used to study what features are important for making accurate predictions. 

\subsubsection{Learning Meaningful Representations with Variational Autoencoders}
Analogous to how a pathologist does not use all the information observable within a biopsy to make diagnoses, but instead looks at specific features such as glands, number of cells, and the shape of the tissue, a machine learning model also does not require all the information present in the data and would benefit more from a lower-dimensional representation that only contains features useful to the diagnosis task. 
% \paragraph{Variational Autoencoders}
% This is not the only benefit to representation learning however. 
According to the manifold hypothesis, this set of useful features lies on a lower-dimensional space that is embedded in the entire data space, also known as a manifold. 
Variational Autoencoders (VAE), a generative type of deep neural network, are able to learn such a space. VAEs attempt to learn this manifold from the data following a process of compressing and decompressing the input data, such that it can be compressed and accurately reconstructed from the lower-dimensional manifold space \cite{maxkingma2013auto}. 

The great benefit of this type of modeling is that we can explore and interpret the manifold space, in which quantities such as placement or distance between data points hold semantic information. By learning to map histopathological data to such a manifold space,  we can therefore model the progression of Barrett’s esophagus.
% \paragraph{Exploring the Representation Space}
For instance, the VAE may learn a latent space in which different classes of precursor lesions are spatially separated, and points from the same class form clusters. Not only would this give insight into how different stages of BE relate to each other, but such a representation would also decrease the current reliance of classification models on hand-crafted labels, which are expensive to annotate and contain a large amount of bias. 
Moreover, the latent space can be used to generate interpolations between different data points and different progression stages. If the model is able to capture the variation in the morphological structure of cell tissue as the disease progresses, such interpolations will result in intermediate stages of dysplasia that occur in between the four different classes most commonly used now. Such interpolations would allow us to model the progression of BE in a more continuous manner and might reveal information that was previously unknown or not used by classifiers. 

Representation learning with variational autoencoders therefore seems like a promising direction for digital histopathology of BE, not only for improving the quality of supervised classification tasks, but also for its interpretability and possibility of gaining new medical insights. 

\subsubsection{Geometric Variational Autoencoders}
One issue with representations learned by VAEs, however, is that they tend to severely distort relationships between points, which significantly hinders their ability to model disease progression. This is most commonly attributed to the assumption of the latent manifold as a flat Euclidean space. Because of this distortion that the Euclidean assumption creates, relationships such as distance between points tend not to reflect semantic similarities well. This greatly reduces the interpretability of the representation space, hinders potential use for unsupervised learning of classes, and reduces the usefulness for application to downstream tasks. 

Recently, research has therefore attempted to solve this issue by proposing \textit{geometric variational autoencoders}. These types of models use alternative, non-Euclidean topologies of the latent space, aiming to structure the manifold in a more geometrically meaningful way. 
Two such methods, \textit{RHVAE} \citep{chadebec2020geometryaware} and \textit{\svae} \citep{davidson2018hyperspherical}, that subsequently assume Riemannian manifolds and hyperspherical manifolds, demonstrated promising results on image data and were expected to also extend well to a medical use case. Moreover, an extension of \svae to disentangle rotation information from latent representations was proposed by \cite{vadgama2022kendall}. The roto-equivariant group neural network at the basis of this work was earlier shown by \cite{lafarge2020orientation} to outperform regular VAEs on a histopathological dataset similar to this work, for example producing high-quality interpolations. 

Although all the above methods have demonstrated improved performance over regular VAEs in creating a meaningful, geometrically-aware latent space with improved clustering, generation, and interpolation ability, they have not been applied to many real-life datasets yet, and the potential for medical image analysis, especially histopathological data, has been relatively unexplored. 
Hence, this work will apply these methods, RHVAE, \svae and roto-equivariant \svae, to the use case of modeling Barrett’s esophagus progression and study whether the additional geometric structuring of the VAEs’ latent space improves the models’ ability to create meaningful representations. We hypothesize that the progression of healthy tissue to Barrett’s esophagus can be modeled in such a geometrically structured latent space, therefore allowing us to take a step further towards supporting histopathological diagnosis of esophageal cancer precursor lesions.


% The hypothesis is........
% The hypothesis is that we can characterize the continuous progression of healthy to unhealthy tissue using this learned latent manifold.

\section{Research Questions}
This work aims to answer the following research questions. 
\begin{itemize}
    \item In what way can we geometrically structure the latent space of a VAE such that it represents a modelling of the progression of healthy tissue to Barrett’s esophagus?
    \item Which of the different manifold topologies, Euclidean, Riemannian or hyperspherical, lead to the best performance in terms of reconstruction quality, classifiability of latent representations and quality of generated images?
    \item Does the disentanglement of rotation from the learned latent representations improve performance on the aforementioned tasks?
    \item Can we create a non-variational spherical autoencoder that is able to generate images of comparable quality to a variational model, while retaining the benefits of autoencoder models over variational models? 

\end{itemize}


\section{Contributions}
The key contributions of this work can be summarized as follows:

\begin{itemize}
    \item We study two different instances of latent manifold topologies, a Riemannian manifold and a hyperphysical manifold, through the use of RHVAE and \svae, and apply them to the novel use case of histopathological image data. 
    \item We evaluate both quantitatively and qualitatively how these models perform in comparison to a vanilla VAE by reporting reconstruction error, downstream classification accuracy, generative sampling quality, and interpolation quality. We show that \svae is able to create more meaningful representations, but is limited to a lower-dimensional latent space size. 
    \item We also investigate \textit{KS-VAE}, a rotation disentangled extension of \svae, and show how it can be used to improve structuring of the latent space by an increased amount over the non-disentangled models.
    \item We propose to use non-variational hyperspherical autoencoders as an alternative to \svae in higher dimensions, and show its increased stability and improved reconstruction quality over variational spherical models.  
    \item We take a first step towards the novel use of spherical autoencoders as a generative model, by introducing a custom loss function called spread loss. We show that \sae can be used to generate images comparable in quality to those of a variational model, while still retaining the qualities described above. 
\end{itemize}

\section{Outline}
This work consists of a total of five further sections. The first of these sections, Section \ref{background}, provides background for this study through some required clinical knowledge, a literature review on the field of representation learning, a more in-depth motivation of geometrically-structured latent spaces, and related work that has been done in this field. Secondly, Section \ref{section:method} will provide the technical details on the models used in this work. Next, the data and experimental setup will be discussed in Section \ref{experiments}, after which we report the results in Section \ref{results}. Finally, Section \ref{discussion} concludes this work with an analysis of the results and suggestions for future work.
