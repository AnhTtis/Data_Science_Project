\chapter{Results}\label{results}

This section will discuss the results of the experiments as described in Section \ref{ex:evaluation} on the spherical VAE, and its roto-equivariant and autoencoder variants. First, in Section \ref{results:reconstruction}, reconstruction quality will be assessed. Secondly, in Subsection \ref{results:classification} the results for classification tasks will be discussed. Next, Section \ref{results:generations} will provide the results of the generative experiments, first examining the quality of random generative sampling, then providing some examples of interpolations. Finally, Section \ref{results:spreadloss} will examine the potential of spherical autoencoders as a generative model, by showing generative samples, interpolations, reconstruction errors, and classification accuracies for models with spread loss implemented. 


\section{Reconstructions} \label{results:reconstruction}

    Using the training settings as discussed in the previous Section \ref{subsec:experiments}, we evaluate the models' ability to retain important features in their learned representations by reporting final reconstruction losses on the unseen Bolero test dataset for all models and latent dimensions sizes. For performance on training and validation set, see Appendix \ref{app:reconstruction}. Although spherical VAEs could not be trained for a latent size of 512, as discussed in Subsection \ref{ex:hyperparams}, we still include results for this dimension size for other model types. The results on the test set are shown in Table \ref{table:reconstructions}.  
    
    \begin{table}[]
    
    \caption{Reconstruction Losses on Test Dataset}
    \label{table:reconstructions}
    \begin{tabular}{@{}lrrrrrrrr@{}}
    \toprule
          & \multicolumn{4}{c}{Normal}                                                                                                                                                      & \multicolumn{4}{c}{Spherical}                                                                                                                                                   \\ \cmidrule(l){2-9} 
          & \multicolumn{2}{c}{Non-Equivariant}                                                & \multicolumn{2}{c}{Equivariant}                                                            & \multicolumn{2}{c}{Non-Equivariant}                                                & \multicolumn{2}{c}{Equivariant}                                                            \\ \cmidrule(l){2-9} 
    $M$   & \multicolumn{1}{c}{\nvae} & \multicolumn{1}{c}{\nae} & \multicolumn{1}{c}{Eq. \nvae} & \multicolumn{1}{c}{Eq. \nae} & \multicolumn{1}{c}{\svae} & \multicolumn{1}{c}{\sae} & \multicolumn{1}{c}{Eq. \svae} & \multicolumn{1}{c}{Eq. \sae} \\ \midrule
    $3$   & 1895.56                                  & 2013.46                                 & -                                            & -                                           & 1930.60                                  & 2089.98                                 & -                                            & -                                           \\
    $8$   & 1807.06                                  & 1769.14                                 & 2103.47                                      & 2103.35                                     & 1707.14                                  & 1743.25                                 & 2103.66                                      & 2103.27                                     \\
    $16$  & 1635.89                                  & 1621.97                                 & 1290.60                                      & 1252.64                                     & 1563.19                                  & 1607.79                                 & 1303.07                                      & 1313.58                                     \\
    $32$  & 1435.60                                  & 1428.11                                 & 1161.32                                      & 1134.30                                     & 1389.64                                  & 1403.93                                 & 1142.24                                      & 1135.50                                     \\
    $64$  & 1260.85                                  & 1273.44                                 & 993.94                                       & 988.42                                      & 1250.45                                  & 1258.50                                 & 1009.90                                      & 992.39                                      \\
    $128$ & 1092.88                                  & 1113.56                                 & 857.40                                       & 853.79                                      & 1133.33                                  & 1104.18                                 & 902.82                                       & 853.75                                      \\
    $256$ & 904.53                                   & 935.09                                  & 710.22                                       & 706.50                                      & 1056.68                                  & 925.07                                  & 826.10                                       & 703.88                                      \\
    $512$ & 748.42                                   & 736.92                                  & 562.11                                       & 556.61                                      & -                                        & 727.06                                  & -                                            & 540.13                                      \\ \midrule
          & \multicolumn{1}{l}{}                     & \multicolumn{1}{l}{}                    & \multicolumn{1}{l}{}                         & \multicolumn{1}{l}{}                        & \multicolumn{1}{l}{}                     & \multicolumn{1}{l}{}                    & \multicolumn{1}{l}{}                         & \multicolumn{1}{l}{}                       
    \end{tabular}
\end{table}
  
    From this data, we can observe multiple things. First of all, the higher the latent dimension size, the lower the reconstruction loss and the better quality the reconstruction is. Since a higher latent dimension allows for less compression of features, this is to be expected. To provide some context to these loss values, we show examples of reconstructed images for dimensions 8, 64, and 256 for the \svae model in Figure \ref{fig:reconsvae}. Here we can indeed observe the same trend of higher dimensions leading to better reconstructions. However, we can also see that even the highest dimension size that is currently possible to use for the \svae model, 256, still does not recover the original image completely. The same is true for the model with the lowest reconstruction error, the equivariant spherical autoencoder, as is shown in Figure \ref{fig:reconbest}. More details are recovered compared to for instance a latent size of 8, which only retains general shapes, but the reconstructions are still blurry compared to the originals. This suggests that the finer details are difficult to compress and that this fact should be taken into account when interpreting further experiments. 

    When comparing different model types, we first look at normal vs spherical types. In general, it becomes apparent that spherical models have an edge over normal-type models in the lower to medium dimensionality range. For instance, \nvae and \nae perform better than their spherical counterparts with a latent size of 3, but \svae and \sae perform better by a rather large margin in dimensions 8-32. From dimension sizes of 64 onward, this advantage becomes smaller, and from 128 to 512, normal-type models achieve lower reconstruction losses compared to spherical models. 

    Furthermore, comparing non-equivariant models to roto-equivariant models, it can be observed that equivariant models perform much better than non-equivariant ones in all dimensionalities except 3, where there is no data available, and 8.     
    Finally, comparing variational autoencoders to their non-variational variants, we see that autoencoders consistently obtain lower reconstruction errors. This effect becomes more apparent in higher dimensions. Moreover, the difference between variational and non-variational is especially noticeable between spherical models.

    \begin{figure}[]
        \centering
        \subfloat[a][Reconstructions of \svae model for latent dimension sizes of 8, 64 and 256.]{\includegraphics[width=0.8\textwidth]{images/experiments/reconstructions/reconstructions_S-VAE_rotated2_ps.png} \label{fig:reconsvae}}
        \\
        \subfloat[a][Reconstructions of equivariant \sae with $M=512$, the model with the lowest reconstruction error.]{\includegraphics[width=0.8\textwidth]{images/experiments/reconstructions/bestrecon.png}\label{fig:reconbest}}
        \caption{Examples of reconstructed image patches.}
        \label{fig:reconstructions}
    \end{figure}



% ------------------------------------------------------------------------------------------------
%  Classifications
% ------------------------------------------------------------------------------------------------
\section{Classifications}\label{results:classification}

    Having learned latent representations, we analyze their expressivity by reporting the test accuracy of a linear classifier network. The results of these experiments are shown in Table \ref{table:classifications}. First of all, in terms of latent dimension sizes, we see a different trend than for the reconstruction losses. Unlike in the reconstruction loss experiments, a higher latent dimension size does not lead to improved results. Although the lowest dimension sizes of 3 and 8 still lead to the poorest results overall, here dimensions 32 and 64 achieve the highest accuracy consistently over all models, with the overall best score being achieved by the equivariant spherical VAE of dimension size 32. Higher sizes such as 128 to 512 achieve comparable results on non-equivariant normal type models, but are considerably lower in case of the equivariant spherical autoencoder. For spherical models with a dimension size of 256 for example, non-equivariant versions achieve scores around 0.4, while the equivariant autoencoder only achieves 0.24, indicating a random guess in case of our four possible classes. 
    
    In terms of equivariance, it can be observed that for a latent dimension of size 32, equivariance improves the performance of both normal and spherical models. For spherical models in particular, equivariance has a slight positive effect on the accuracy scores in dimensions higher than 8. For normal-type models, equivariance does not differ much from non-equivariant accuracy scores in these dimension sizes. 
    Furthermore, we can also observe that in general, autoencoder-type models achieve comparable or slightly worse scores than their variational counterparts, suggesting that representations learned by variational models are slightly easier to classify. All in all, these trends differ from the ones observed in Table \ref{table:reconstructions}, suggesting that a representation having a lower reconstruction error does not necessarily correlate with it being easier to be classified. 

    \begin{table}
    \caption{Classification Accuracy of Latent Representations on Test Dataset}
        \begin{tabular}{@{}lllllllll@{}}
        \toprule
              & \multicolumn{4}{c}{Normal}                                                                                          & \multicolumn{4}{c}{Spherical}                                                                                       \\ \midrule
              & \multicolumn{2}{c}{Non-Equivariant}                  & \multicolumn{2}{c}{Equivariant}                              & \multicolumn{2}{c}{Non-Equivariant}                  & \multicolumn{2}{c}{Equivariant}                              \\ \cmidrule(l){2-9} 
        $M$   & \multicolumn{1}{c}{\nvae} & \multicolumn{1}{c}{\nae} & \multicolumn{1}{c}{Eq. \nvae} & \multicolumn{1}{c}{Eq. \nae} & \multicolumn{1}{c}{\svae} & \multicolumn{1}{c}{\sae} & \multicolumn{1}{c}{Eq. \svae} & \multicolumn{1}{c}{Eq. \sae} \\ \midrule
        $3$   & 0.248                     & 0.255                    & -                             & -                            & 0.250                     & 0.262                    & -                             & -                            \\
        $8$   & 0.333                     & 0.348                    & 0.342                         & 0.171                        & 0.363                     & 0.325                    & 0.228                         & 0.274                        \\
        $16$  & 0.387                     & 0.395                    & 0.394                         & 0.420                        & 0.400                     & 0.343                    & 0.351                         & 0.298                        \\
        $32$  & 0.408                     & 0.396                    & 0.466                         & 0.462                        & 0.414                     & 0.308                    & \textbf{0.478}                & 0.455                        \\
        $64$  & 0.454                     & 0.395                    & 0.398                         & 0.414                        & 0.391                     & 0.409                    & 0.417                         & 0.433                        \\
        $128$ & 0.422                     & 0.424                    & 0.398                         & 0.397                        & 0.396                     & 0.393                    & 0.412                         & 0.282                        \\
        $256$ & 0.422                     & 0.423                    & 0.380                         & 0.398                        & 0.400                     & 0.406                    & 0.408                         & 0.243                        \\
        $512$ & 0.382                     & 0.363                    & 0.380                         & 0.389                        & -                         & 0.371                    & -                             & 0.254                        \\ \bottomrule
        \end{tabular}
        \label{table:classifications}
        \end{table}

        To provide context for these accuracy scores, we also report accuracy scores on an image patch classification task using a CNN. These accuracy scores are shown in Table \ref{table:cnn}. In general, accuracy scores for the CNN lie around 0.45 to 0.55. Compared to the latent representations, they are more consistent over different dimension sizes, with the 256 having the best score overall for the non-equivariant CNN and the equivariant CNN reaching the highest score of 0.543 with a latent dimension of 64. The trend of the representations performing best in the mid-range of dimension sizes does not hold for the CNNs, although it is the case that equivariance improves results for both experiments.
        In general however, the CNN's results are only slightly higher than the best accuracy scores for the classification of latent representations, suggesting that these models learn representations that have not lost too much relevant information compared to the original images.

        \begin{table}[H] 
        \caption{Classification Accuracies of Image Patches on Test Dataset}
        \centering
        \begin{tabular}{@{}lll@{}}
        \toprule
        $M$   & Non-Equivariant & Equivariant \\ \midrule
        $3$   & 0.455           & -           \\
        $8$   & 0.478           & 0.452       \\
        $16$  & 0.474           & 0.518       \\
        $32$  & 0.460           & 0.495       \\
        $64$  & 0.450           & 0.543       \\
        $128$ & 0.469           & 0.512       \\
        $256$ & 0.505           & 0.496       \\
        $512$ & 0.465           & 0.514       \\ \bottomrule
        \end{tabular}\label{table:cnn}
        \end{table}
        
   
% ------------------------------------------------------------------------------------------------
%  GENERATING
% ------------------------------------------------------------------------------------------------
\section{Generative Quality} \label{results:generations}

    \subsection{Generative Random Sampling}

    To gain sights into the structure and general informedness of the learned latent spaces, we sample vectors from random latent locations for all trained models and dimension sizes. We include one such sample per model and dimension size in Figure \ref{fig:generations}, as we find that this shows the general difference between different models well. Additional samples, which show that the same trends observable in Figure \ref{fig:generations} persist over multiple samples, are included in Appendix \ref{app:generations}.    
    
    \begin{figure}[] 
       \centering
      \subfloat[a][\svae]{\includegraphics[width=0.75\textwidth]{images/experiments/generations/Small_Generations_S-VAE_ps.png}} \\
      \subfloat[b][\sae]{\includegraphics[width=0.75\textwidth]{images/experiments/generations/Small_Generations_S-AE_ps.png} \label{fig:b}} \\
      \subfloat[c][\nvae]{\includegraphics[width=0.75\textwidth]{images/experiments/generations/Small_Generations_N-VAE_ps.png} \label{fig:b}} \\
      \subfloat[d][\nae]{\includegraphics[width=0.75\textwidth]{images/experiments/generations/Small_Generations_N-AE_ps.png} \label{fig:b}}
    %   \caption{Non-Equivariant Models} \label{fig:AB}
    % \end{figure}
    % \begin{figure} \ContinuedFloat
    %   \centering 
    \\
      \subfloat[a][Equivariant \svae]{\includegraphics[width=0.75\textwidth]{images/experiments/generations/Small_Generations_Eq.S-VAE_ps.png}} \\
      \subfloat[b][Equivariant \sae]{\includegraphics[width=0.75\textwidth]{images/experiments/generations/Small_Generations_Eq.S-AE_ps.png} \label{fig:b}} \\
      \subfloat[c][Equivariant \nvae]{\includegraphics[width=0.75\textwidth]{images/experiments/generations/Small_Generations_Eq.N-VAE_ps.png} \label{fig:b}} \\
      \subfloat[d][Equivariant \nae]{\includegraphics[width=0.75\textwidth]{images/experiments/generations/Small_Generations_Eq.N-AE_ps.png} \label{fig:b}} 
      \caption{Randomly generated images from all model types. Each column shows one sample from a model trained with a specific latent dimension size.}
      \label{fig:generations}
    \end{figure}
    
    
    When comparing the generated images, one trend that is noticeable for almost all models, is that the images decrease in quality for higher dimension sizes. In lower dimensions such as 3, 8 and 16, images are mostly consistent with the appearance of reconstructions, that is, rough blurry shapes with little amount of detail. In higher dimensions, however, images start becoming less realistic, shapes are lost, and colors start appearing that are not originally present in the dataset. This effect seems amplified in equivariant models, most notably the normal vanilla autoencoder, that only produces noise in the highest dimensions. The only model types that do generate realistic images in higher dimensions, that are consistent with reconstructions, are the spherical VAE and its equivariant counterpart. Between these two models, equivariant \svae shows slightly more structures that resemble the biopsy patches.
    
\newpage
% ------------------------------------------------------------------------------------------------
%  Interpolations
% ------------------------------------------------------------------------------------------------

\subsection{Interpolations} \label{results:interpolations}

Next, we discuss the results of the interpolation experiments. For these experiments, one notable finding was that on average, interpolations were of higher quality than randomly generated images. All models, including normal types and autoencoders, produced interpolations that looked smooth, although some differences between models were also observed. First of all, interpolations of spherical-type models were often slightly more realistic in terms of structure than those of normal model types. Examples of this are shown in Figure \ref{fig:interpolationsA}. 
On each row in this figure, six images along the curve between image 1 and image 2 are decoded, including the start and end points, meaning that the second and seventh images are the reconstructions of the original input. Along the interpolation, we see image 1 slowly changing into image 2. 
 \begin{figure}[H]
      \centering
      \subfloat[\nvae with $M=256$]{\includegraphics[width=0.8\textwidth]{images/experiments/interpolations/NVAE_sq-hgd.png}\label{int:nvae}} \\
      \subfloat[\svae with $M=256$]{\includegraphics[width=0.8\textwidth]{images/experiments/interpolations/SVAE_sq-hgd.png} \label{int:svae}} \\
      \subfloat[\nvae with $M=256$]{\includegraphics[width=0.8\textwidth]{images/experiments/interpolations/Interpolations_.N-VAE_dim=256__squamous-HGD.png}\label{int:nvae2}} \\
      \subfloat[\svae with $M=256$]{\includegraphics[width=0.8\textwidth]{images/experiments/interpolations/Interpolations_.S-VAE_dim=256__squamous-HGD.png} \label{int:svae2}}
      % \caption{Another example of interpolations of \svae and \nvae models for a latent dimension size of 256} \label{fig:interpolationsB}
      \caption{Interpolations of \svae and \nvae models for a latent dimension size of 256. Original input images are shown on the far left and right. Next to each of the original images is their reconstructed version and in the middle of these, the four interpolated images. For the original images, their true class ($c$) is given, while for the other images, the predicted class ($p$) is shown.} \label{fig:interpolationsA}
\end{figure}
For the first interpolation made with \nvae, as shown in Figure \ref{int:nvae}, this transition is more fade-like, and we gradually see more parts of image 2 appearing in the interpolated images and features of image 1 slowly becoming less opaque. Comparing this to the same interpolation made by \svae, shown in \ref{int:svae}, however, we can see that the white shape of image 2 is recovered earlier in the interpolation already. Instead of seeing two images fading into each other, we see the shape and structure changing. The same can also be observed in Figures \ref{int:nvae2} and \ref{int:svae2}. Here too, structures are more noticeable along the interpolation, making them more true to real-life progression than normal type models. 

 \begin{figure}[H]
      \centering
      \subfloat[\nvae with $M=512$]{\includegraphics[width=0.8\textwidth]{images/experiments/interpolations/equihelps_N-VAE_dim=512.png}} \\
      \subfloat[\nvae with $M=512$]{\includegraphics[width=0.8\textwidth]{images/experiments/interpolations/equihelps_eq_N-VAE_dim=512.png} \label{fig:b}}
      \caption{Interpolations of \nvae and equivariant \nvae models for a latent dimension size of 512. The equivariant model produces clearer, more structured interpolations.} \label{fig:interpolations_equi}
    \end{figure}
 \begin{figure}[H]
      \centering
      \subfloat[\nae with $M=512$]{\includegraphics[width=0.8\textwidth]{images/experiments/interpolations/Interpolations_Equivariant.N-AE_dim=512__squamous-HGD.png}}\\
      \subfloat[\sae with $M=512$]{\includegraphics[width=0.8\textwidth]{images/experiments/interpolations/Interpolations_Equivariant.S-AE_dim=512__squamous-HGD.png} \label{fig:b}}
      \caption{Interpolations of equivariant \nae and equivariant \sae models for a latent dimension size of 512. Spherical autoencoders produce clear-looking results, unlike the more blurry interpolations of the normal type autoencoder.} \label{fig:interpolations_nae}
    \end{figure}

Furthermore, we observe that the roto-equivariant model types produce visually higher quality interpolations than their non-equivariant versions. This becomes especially apparent in normal-type VAEs. An example of this is shown in Figure \ref{fig:interpolations_equi}, but to a lesser extent in spherical VAEs. Moreover, normal autoencoders, both equivariant and non-equivariant, produce the lowest quality results, with interpolations generally having a blurry appearance, while spherical autoencoders do not suffer from this issue. An example of this is shown in Figure \ref{fig:interpolations_nae}.





    Finally, we also show predicted classes for each of the interpolated images. As became apparent in Subsection \ref{results:classification}, higher dimensional models, such as 256 and 512, did not achieve good results on the latent representation classification task. Class predictions included in earlier figures are therefore not reliable. For spherical models of dimension 32 however, accuracy scores were on average higher. We therefore include an example of an interpolation made by \svae with size 32 in Figure \ref{fig:interpolation_classes}. 
In this figure, it can be seen that, although the image quality is more blurry, predicted classes for images 1 and 2 are correct. A shift from squamous tissue to the first stage of Barrett's esophagus, NDBE, occurs towards the end of the interpolation, which ends at high-grade dysplasia. 

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/experiments/interpolations/dim64_correctclasses.png}
    \caption{Interpolation between squamous and high-grade dysplasia by model with latent dimension size of $M=32$. Although the quality of images is lower, the predicted classes are correct and show a more realistic progression.}
    \label{fig:interpolation_classes}
\end{figure}

\section{Spherical Autoencoder as Generative Model}

% ------------------------------------------------------------------------------------------------
%  SPREAD LOSS GENERATIONS
% ------------------------------------------------------------------------------------------------
\subsection{Random Sampling with Spread Loss} \label{results:spreadloss}

    Finally, to evaluate our novel \sae model and determine its potential as a generative model, we examine the effects of spread loss on the spherical autoencoder model. First and most importantly, we evaluate the quality of randomly generated images, as this will make clear if the model with spread loss can be used for generative tasks. To compare how spread loss affects models differently, we also provide samples generated by a variational spherical autoencoder trained with spread loss.
    
    \begin{figure}[H] 
      \centering
      \subfloat[a][Equivariant \svae model with Spread Loss]{\includegraphics[width=0.7\textwidth]{images/experiments/generations/Small_Generations_Eq.S-VAE_spreadloss_ps.png}} \\
      \subfloat[b][Equivariant \sae model with Spread Loss]{\includegraphics[width=0.7\textwidth]{images/experiments/generations/Small_Generations_Eq.S-AE_spreadloss_ps.png} \label{fig:b}} \\
      \subfloat[c][\svae model with Spread Loss]{\includegraphics[width=0.7\textwidth]{images/experiments/generations/Small_Generations_S-VAE_spreadloss_ps.png} \label{fig:b}} \\
      \subfloat[d][\sae model with Spread Loss]{\includegraphics[width=0.7\textwidth]{images/experiments/generations/Small_Generations_S-AE_spreadloss_ps.png} \label{fig:b}} 
      \caption{Randomly image samples generated by \svae and \sae with spread Loss, for a range of latent dimension sizes.}
      \label{fig:generate_spread}
    \end{figure}

In Figure \ref{fig:generate_spread}, we show one sample per dimension size of all spherical models with spread loss implemented. As can be observed from this figure, the visual quality of the images generated by the spherical autoencoder model types greatly improves compared to samples generated by the same models without spread loss (Figure \ref{fig:generations}. The images look more realistic and continue to do so up until the highest tested dimension sizes. This effect is most noticeable for the equivariant \sae model. For the variational models, spread loss does not have a large effect on the quality of samples, except for the images being slightly less sharp than before. 

Furthermore, when interpolating with models with spread loss, we do not see a noticeable improvement. This may be explained due to spherical autoencoders already generating good-quality interpolations without the extra loss function. In some rare cases, interpolations with spread loss result in low-quality images, such as the ones shown in Figure \ref{fig:interpolation_spread}. Here, interpolations do not model a smooth transition, suggesting that the spreading of encoded points can create some low-information areas in the latent space. This most commonly occurs in higher latent dimensions. 

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{images/experiments/interpolations/spreadlossgonewrong_nt.png}
    \caption{Interpolation generated by \sae model with spread loss and $M=512$. The interpolation does not appear smooth. }
    \label{fig:interpolation_spread}
\end{figure}

\subsection{Effects of Spread Loss on Quantitative Metrics}

Finally, having demonstrated the potential of the spherical autoencoder with spread loss as a generative model, we test if the extra loss function has a negative impact on quantitative measures by evaluating the performance on reconstruction loss and classification accuracy. Table \ref{table:spread_recon} shows the reconstruction losses earlier reported for the original autoencoder models on the left and the new loss values for the spread loss autoencoders on the right. It can be observed that spread loss does not have an adverse effect on reconstruction error, with the exception of the largest dimension sizes of 256 and 512. Across all other latent dimension sizes, spread loss actually shows improved performance over their models' original versions. 

\begin{table}[H]
\caption{Effect of Spread Loss on Reconstruction Error}
\centering
\begin{tabular}{@{}lrrrr@{}}
\toprule
      & \multicolumn{2}{c}{Original}                            & \multicolumn{2}{c}{Spread Loss}                         \\ \midrule
$M$   & \multicolumn{1}{c}{\sae} & \multicolumn{1}{c}{Eq. \sae} & \multicolumn{1}{c}{\sae} & \multicolumn{1}{c}{Eq. \sae} \\ \midrule
$3$   & \textcolor{darkgray}{2089.98}         & \textcolor{darkgray}{-}                   & 1881.539                 & -                            \\
$8$   & \textcolor{darkgray}{1743.25}         & \textcolor{darkgray}{2103.27}            & 1712.125                 & 2102.35                      \\
$16$  & \textcolor{darkgray}{1607.79}        & \textcolor{darkgray}{1313.58}             & 1539.761                 & 1271.64                      \\
$32$  & \textcolor{darkgray}{1403.93}        & \textcolor{darkgray}{1135.50}             & 1379.716                 & 1139.093                     \\
$64$  & \textcolor{darkgray}{1258.50}       & \textcolor{darkgray}{992.39}              & 1226.048                 & 1004.461                     \\
$128$ & \textcolor{darkgray}{1104.18}         & \textcolor{darkgray}{853.75}              & 1087.761                 & 874.803                      \\
$256$ & \textcolor{darkgray}{925.07}          & \textcolor{darkgray}{703.88}              & 956.545                  & 757.036                      \\
$512$ & \textcolor{darkgray}{727.06}          & \textcolor{darkgray}{540.13}             & 877.659                  & 624.188                      \\
\bottomrule
\end{tabular}
\label{table:spread_recon}
\end{table}
\begin{table}[H]
\caption{Effect of Spread Loss on Classification Accuracy}
\centering
\begin{tabular}{@{}lllll@{}}
\toprule
      & \multicolumn{2}{c}{Original}                                & \multicolumn{2}{c}{Spread Loss}                         \\ \midrule
$M$   & \multicolumn{1}{c}{\sae}     & \multicolumn{1}{c}{Eq. \sae} & \multicolumn{1}{c}{\sae} & \multicolumn{1}{c}{Eq. \sae} \\ \midrule
$3$   & \textcolor{darkgray}{ 0.262} & \textcolor{darkgray}{ -}     & 0.262                    & -                            \\
$8$   & \textcolor{darkgray}{ 0.325} & \textcolor{darkgray}{ 0.274} & 0.326                    & 0.198                        \\
$16$  & \textcolor{darkgray}{ 0.343} & \textcolor{darkgray}{ 0.298} & 0.344                    & 0.290                        \\
$32$  & \textcolor{darkgray}{ 0.308} & \textcolor{darkgray}{ 0.455} & 0.308                    & 0.250                        \\
$64$  & \textcolor{darkgray}{ 0.409} & \textcolor{darkgray}{ 0.433} & 0.413                    & 0.283                        \\
$128$ & \textcolor{darkgray}{ 0.393} & \textcolor{darkgray}{ 0.282} & 0.325                    & 0.361                        \\
$256$ & \textcolor{darkgray}{ 0.406} & \textcolor{darkgray}{ 0.243} & 0.430                    & 0.315                        \\
$512$ & \textcolor{darkgray}{ 0.371} & \textcolor{darkgray}{ 0.254} & 0.454                    & 0.422    \\ \bottomrule
\end{tabular}
\label{table:spread_class}
\end{table}

Additionally, Table \ref{table:spread_class} shows the test accuracies on the latent representation classification task for both original and spread loss autoencoders. For non-equivariant autoencoders, the accuracy scores obtained with spread loss are very comparable to the original scores. The only exceptions are the higher dimensions, 256 and 512, where the model with spread loss achieves a higher accuracy than the original \sae. Notably, this is the opposite pattern of the reconstruction losses, as the highest two dimensions score the worst there. For equivariant autoencoders, a different pattern can be observed. Before, a latent dimension size of 32 scored the highest, but here, that same model with spread loss scores is one of the lowest out of all dimension sizes. Instead, the best scoring size is the highest dimension size, 512. 


