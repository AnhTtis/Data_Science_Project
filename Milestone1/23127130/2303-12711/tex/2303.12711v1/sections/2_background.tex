\chapter{Background}\label{background}
The following section will provide the reader with a background for this research. First of all, Subsection \ref{bg:clinical} will give a short introduction to Barrett's Esophagus from a clinical point of view. We believe that understanding what the progression of \be looks like and following along with how a histopathologist makes their diagnoses, will greatly help in conveying what we eventually want our model to do, which is learning what features are important and using this knowledge to model the progression of the disease. Subsection \ref{bg:representation} will therefore focus on developments in the field of representation learning, which is concerned with learning meaningful features from high-dimensional data. Here we will also introduce manifold learning through variational autoencoders. Finally, Subsection \ref{bg:geovaes} will introduce geometrically-aware VAEs. We will explain why the lack of structuring in the latent space of regular autoencoder models can distort relationships between different data classes and propose to solve this issue by providing additional geometric structure to the latent space.

\section{Clinical Background: Barrett's Esophagus}\label{bg:clinical}
Esophageal adenocarcinoma (EAC), one of the most common subtypes of esophageal cancer, is an aggressive form of cancer with a poor prognosis. Only around 20\% of diagnosed patients survive past five years after their diagnosis. When it is discovered at an early stage however, this rate can increase to around 45\% \cite{EAC}. It is therefore essential that EAC is diagnosed early on in the disease progression. Currently, research into early-stage diagnosis has determined only one independent precursor lesion to esophageal adenocarcinoma: Barrett's Esophagus (BE). Barrett's esophagus is a condition that is characterized by a change of the cell tissue lining the esophagus (squamous epithelial cells) to cells that closely resemble those ordinarily lining the stomach (metaplastic columnar mucosa cells). 

Because of the importance of early diagnosis, all patients diagnosed with BE are accepted for endoscopic surveillance. The endoscopic screening procedure consists of taking multiple biopsies from the esophagus lining, staining these with hematoxylin and eosin (H\&E) coloring, and digitalizing these through a dedicated scanner \cite{vanderwelBarrett}. A histopathologist then examines these digital biopsies under a microscope and determines the severity of the dysplasia. Labeling the progression is done in accordance with the Vienna criteria, which were developed to reduce diagnostic differences between different practitioners. It should be noted that although these criteria helped standardize labeling systems, the interobserver variability for BE diagnoses is still very high \cite{bolero}. Following the criteria, Barrett’s esophagus is subdivided into three increasingly more severe classes of dysplasia: Non-Dysplastic Barrett’s Esophagus (NDBE), Low-Grade Dysplasia (LGD), and High-Grade Dysplasia (HGD), or into a fourth indefinite class when diagnoses are highly uncertain \cite{vanderwelBarrett}. 
Average progression rates of BE into EAC increase with the severity of the dysplasia in BE. While patients with non-dysplastic BE only have an annual conversion rate of less than 0.3\%, that rate increases up to 10\% for low-grade dysplasia and to more than 20\% for high-grade dysplasia. See also Figure \ref{fig:progression}. Treatment plans therefore are highly dependent on correct classifications of the different stages of BE. 



\citeauthor{vanderwelBarrett} cite five general features that allow pathologists to make accurate classifications. In order of importance, these are clonality, surface maturation, the architecture of the glandular structures, cytonuclear abnormalities, and inflammation. For example, abrupt transitions between nuclear features (clonality) are an important marker for dysplastic BE, as well as decreased surface maturation. For high-grade dysplasia specifically, the number of nuclei also increases, and they tend to form more complex growth patterns. Conversely, in non-dysplastic BE, the surface maturation and architecture remain intact, but glands can start to appear more uniform or rounded as compared to regular squamous epithelium \cite{ong2010biomarkers}. 

The disease progression is therefore characterized by changes in tissue morphology, which we want a machine-learning model to be able to capture. The following subsection will therefore give an introduction to the field of representation learning and motivate the choice of manifold learning through geometric variational autoencoders for modeling BE disease progression. Through this approach, it becomes possible to avoid the need for expensive and high-variance annotations made by pathologists, as mentioned earlier.

% ------------------------------------------------------
% ------- TECHNICAL BACKGROUND -------------------------
% ------------------------------------------------------

\section{Technical Background: Representation Learning} \label{bg:representation}
Machine learning has become increasingly successful at a multitude of tasks over the past few years. A part of that success can be attributed to developments in the field of \textit{representation learning}, or \textit{feature learning}, which attempts to learn meaningful representations or features of data \citep{bengio2012representation}. It is often hypothesized that different data representations can entangle different explanatory factors within the data, so choosing a representation that hides unimportant -or conversely highlights important factors allows deep learning methods to more easily make classifications. A well-known example of representation learning is the embedding of text into word vectors through models such as word2vec \citep{mikolov2013word2vec}, which has become the standard representation of words for downstream natural language processing tasks and has greatly improved the ability of NLP models to relate and reason about language. More recently, models such as BERT \citep{devlin2018bert} and GPT \citep{radford2018gpt} have also learned rich distributed representations from a language modeling task and have achieved state-of-the-art results on numerous NLP problems. 
Outside of the field of NLP, representation learning has been applied to many real-world data applications, such as images, speech signals, video, and bioinformatics, not only to learn richer representations of the data but also to reduce its often high dimensionality \citep{van2009dimensionality}. 

\subsection{Manifold Learning}
While classic examples of dimensionality reduction, such as
Principal Component Analysis (PCA) \citep{wold1987principal}, or Multi-Dimensional Scaling (MDS) \citep{cox2008multidimensional}, are able to learn linear embeddings, more recent developments have focused on methods of non-linear dimensionality reduction, also known as \textit{manifold learning}. This increasingly more popular subfield is based on the hypothesis that probability mass concentrates near regions that have a much smaller dimensionality than the space in which the original observed data lies \citep{cayton2005manifoldlearning}. The data can therefore be said to lie on a low-dimensional \textit{manifold}, a topological space that locally resembles Euclidean space, embedded in a higher-dimensional space. 
Such a manifold space reflects variations in the input data in its intrinsic coordinate system, i.e., quantities such as location and pairwise distances represent relationships between input data points. Manifold learning thus aims to learn the aforesaid data-supporting space, resulting in a representation that models relationships between data points in an inherently more geometric way as compared to other subfields of representation learning \citep{fefferman2016testing}. 

Intuitively, this hypothesis also has a basis in real-life concepts from psychology and biology. Taking the task of facial recognition as an example, it is generally assumed that a human perceiver has a priori access to a representation of stimuli in terms of some perceptually meaningful features that can support the relevant classification. High-dimensional, raw input signals are mapped to these features by some complex function, which is learned naturally by humans \citep{tenenbaum1997mapping}. Comparingly, machine learning models also receive high-dimensional input data: if for instance our facial images are grayscale and of size $28 \times 28$, then that means that they lie in a $784$-dimensional observation space, with a total of $256^784$ possible images. However, only a very small portion of this set of possible images corresponds to a meaningful, naturally-occurring representation of a face. These perceptually meaningful images can therefore be said to lie on a much lower-dimensional manifold, to which a machine learning model can learn a mapping. This also means that small variations in the naturally-occurring input images, such as changes in light, rotation, or texture, can be mapped to corresponding changes in the lower-dimensional manifold. Learning this structure of the manifold would therefore allow the model to reason more effectively about the data \citep{fefferman2016testing}. 

\subsubsection{The Non-Parametric Approach: Kernel Methods}\label{bg:krl}
Some classic examples of manifold learning fall into the family of kernel methods, or spectral methods,  which includes notable examples such as Isomap \citep{tenenbaum2000global}, Locally Linear Embedding (LLE) \citep{roweis2000nonlinear} and Diffusion Maps \citep{coifman2005geometric}. These methods have in common that they attempt to approximate the manifold by a local neighborhood graph, creating a lower-dimensional representation that preserves some of the underlying geometry between data points; for example, through pairwise geodesic distances in the case of Isomap, through linearity of neighborhoods in the case of LLE and through heat kernels in the case of diffusion maps. 

Kernel methods have been used for manifold learning and dimensionality reduction in a variety of medical tasks. \cite{souvenir2005isomap} for instance, apply isomap to MRI scans of heart and lungs and theorize that the manifold learned through isomap is able to parametrize the deformations of heart shape caused by patient’s breathing \citep{souvenir2005isomap}, therefore allowing for a lower-dimensional representation that captures meaningful morphological relationships between different images. Similarly, \cite{piella2014diffusion} applies kernel methods to the task of multimodal image registration and uses diffusion maps to map a dataset of brain scans to a manifold that reflects its geometry uniformly across modalities. Finding related images can then be solved by computing the similarity between them through a simple Euclidean distance metric \citep{piella2014diffusion}.


\subsubsection{The Parametric Approach: Autoencoders}
While the ability of kernel methods to preserve an underlying geometric structure enables them to learn efficient and meaningful low-dimensional data representations, they suffer from a major drawback: they are only able to map the input data to a fixed set of coordinates, making it impossible to naturally embed any new data point that was not used for fitting the model. This greatly restricts the use of these types of models. A manifold learning technique that does not suffer from this problem is the Autoencoder (AE) \citep{rumelhart1986learning}. In contrast to kernel methods, AEs learn a parametric function, which allows them to both perform inverse mappings and embed out-of-sample points. 

Autoencoders are a type of neural network that imposes a bottleneck on the network architecture, which has the effect of enforcing a compression on the input data. Specifically, the architecture consists of an \textit{encoder} part which encodes the input data into a lower-dimensional manifold space, also known as the latent space, and a \textit{decoder}, which learns to most accurately reconstruct the original input data from these latent vectors learned by the encoder. In this way, the quality of the reconstruction is directly influenced by the quality of the learned latent representation, and it becomes possible to visually assess the quality of the representation by observing the quality of the reconstructed output. 

Moreover, a more recent variant of the autoencoder model, the Variational Autoencoder (VAE), instead has the encoder learn to output parameters for a probability distribution characterizing each input data point from which latent vectors can then be sampled \citep{maxkingma2013auto, rezende2014stochastic}. Because the latent manifold space of a VAE is continuous, it becomes possible to not only learn accurate reconstructions of the input, but also to generate new unseen data points based on the input data. Moreover, by treating the knowledge within the learned representation as a hypothesis, it becomes possible to inspect reconstructions, generations, and visualizations of the latent space to assist in understanding what the model has learned and whether it corresponds to our own understanding of the world. 
It may even be used to learn of new structure within the data that is not apparent in the original form of the input. Such ability has great appeal for biomedical imaging applications and can in particular be of great help in understanding the complex problem of the histological diagnosis of disease.

Not only can VAEs be used to generate new data points in case of sparse available datasets, which is often the case in medicine, but there are numerous other benefits to the use of these models for a histopathological use case. First of all, they may learn a latent representation in which different classes of precursor lesions are spatially separated and points from the same class form \textit{clusters} \citep{wang2019extracting, zeune2020autoencodingtumors}. Finding such a representation would decrease the current reliance of classification models on hand-crafted labels, which are expensive to annotate and can contain a large amount of bias \citep{bolero}. Secondly, it becomes possible to generate \textit{interpolations} between different data points and different classes \citep{thomas2022representation, wang2019extracting}. By visually inspecting these interpolations, we can assess if the model is able to realistically capture the variation in morphological structure of cell tissue as it transforms into a malignant state. Finally, if the latter is the case, we can also perform \textit{extrapolation} to unseen states of the data, which might reveal information about the progression that was previously unknown. 

However, despite these properties, AEs often fail to accurately recover the geometry present in the data. This not only restricts their desirability to perform exploratory data analysis, but can also lead to poor-quality reconstructions over certain regions in the learned latent space where data is sparse, decreasing the quality of interpolations and generations. Previous research has often seen that the underlying shape of the manifold on which the input data lies is not preserved when mapping to the latent space \citep{duque2020extendable}. This has as a consequence that some of the underlying relations between data points, such as cell deformations and morphological characteristics of tissue in our current use case, are lost, which leads to less rich representations. Ideally, we would require a model that can preserve these properties when modeling the latent manifold space, but not in the limited way of creating neighborhood graphs like in the non-parametric approach. 

\section{Geometric Variational Autoencoders}\label{bg:geovaes}
Recent research has therefore looked into solving the distortion issues of VAEs, focusing on modeling the latent space in a non-Euclidean way and instead exploring alternative manifold topologies. Before we discuss the details of these geometric VAEs however, it is important to understand
the reasons behind the distortion of the latent space and how the Euclidean assumption relates to this problem. 

\subsubsection{The Distortion of the Latent Space}\label{bg:dst}
Formally, a VAE is a neural network architecture that aims at learning a parameterized probability distribution $p_{\theta }$ describing the input data $x$'s true distribution $P(x)$. To do so, we assume that the input data can be characterized by lower-dimensional latent vectors $\mathbf{z}$. The marginal likelihood can then be written as \begin{align} p_\theta(\mathbf{x}) = \int p_\theta(\mathbf{x}|\mathbf{z})q(\mathbf{z})d\mathbf{z}, \end{align} where $q(\mathbf{z})$ is a prior distribution over the latent variables, that in case of the vanilla VAE is chosen as a standard
normal distribution \(q(\mathbf{z})=\mathcal{N}\left(\mathbf{z} \mid \mathbf{0}, \mathbf{I}_{\mathbf{d}}\right)\).

The consequence of assuming a Gaussian prior is that this distribution tends to move clusters closer together in the latent space \citep{yang2018geodesic}. The architecture of the VAE is made to minimize the distance between the prior and posterior distribution, so learned latent variables can be forced to show structure based on the Gaussian prior, even if that structure was not originally present in the data. This can cause a distortion in the latent space that affects clustering, interpolation and more.
% % Before we dive further into geometric autoencoder, it is important to consider \textit{why} traditional VAE often fail to recover 
% One hypothesis on why classic VAEs often have trouble preserving the geometry of the data manifold is that they incorrectly assume a Euclidean latent space. 
Take for example the curved manifold of the observed input space shown on the right of Fig \ref{fig:interpolants_example} and its learned latent representation on the left. If we want to interpolate between two points by calculating the shortest distance between them, a natural choice of interpolant would be the green curve, as it follows the shape of the observed space and creates a well-informed path over the manifold. However, if we calculate the shortest distance between these same points in the latent space, we actually end up calculating a path that not only corresponds to a longer path in the observed space, but also crosses through areas containing points of a different class and areas where no data or information is present at all, leading to an interpolation of lower quality than the green curve. 

Similarly, in figure \ref{fig:clustering_example}, we observe the latent representation of two digits from the MNIST dataset learned by a vanilla VAE \citet{mnist}. Unintuitively, under this representation, points B and C are closer in distance than points A and B, even though the latter belong to the same class. However, following the same logic as above, we can assume that the real high-dimensional input data actually lives in a manifold where the relations between points are in fact meaningful, it is just due to the distortion of the latent space that these relations cannot become apparent. 

\begin{figure}
     \centering
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{images/related_work/curvedspaceexample.png}
         \caption{}
         \label{fig:interpolants_example}
     \end{subfigure}
    %  \hfill
     \begin{subfigure}[b]{0.34\textwidth}
         \centering
         \includegraphics[width=\textwidth]{images/related_work/mnistexample.png}
         \caption{}
         \label{fig:clustering_example}
     \end{subfigure}
     \centering
        \caption{Example of how the distortion of latent space influences interpolation paths and clustering.}
        \label{fig:example_of_curvedspace}
\end{figure}

Although the above is just a toy example, it becomes apparent that the distortion of the latent space influences interpolations, clustering and visual interpretability of the representations that are learned and that this impact becomes more significant with the magnitude of relative distortion present; the greater curvature there exists in the original input data, the more distorted the relationship between points in the latent space becomes. 
In the case of medical data, which is often high-dimensional and complex, finding a more geometrically relevant representation therefore becomes especially important \citep{krioukov2010hyperbolic}. 
If we can learn a latent representation that is more geometrically correct, this would improve interpolations, clusterings, latent probability distributions, sampling algorithms, interpretability and more. The question then becomes in what way we can construct such a geometrically meaningful space.

\paragraph{Challenging the Euclidean Assumption}
One popular direction of research has therefore put the assumption of Euclidean latent space up for debate. Natural image data in general has been shown to possess a strong non-Euclidean latent structure, because it is said to live on a “natural image manifold” of which an example was given earlier \cite{skopek2019mixed}, and also medical imaging specifically has been named as a domain that is naturally non-Euclidean \cite{bronstein2017geometric}. Assuming a non-Euclidean topology of the latent space therefore seems especially interesting in the context of the histopathological problem. 
Not only have Euclidean topologies shown to cause problems when learning manifolds with different topologies \citep{falorsi2018explorations}, but they are also not invariant arithmetically, which causes any deformations of the latent space to also lead to changes in the estimated data density. This leads to the \textit{identifiability problem} commonly observed in generative models, which entails that many configurations of the latent space can explain the observed data equally well \citep{bishop2006pattern, hauberg2018only}. The identifiability problem forms a significant drawback in the interpretability of the latent space, its robustness, and its potential to reveal unknown structures in the data. Alternatives to the Euclidean topology are therefore urgently needed.

\subsection{The Latent Space as General Riemannian Manifold}\label{bg:rie}
% As the latent space can be arbitrarily deformed it is not sensible to measure the curve length directly in the latent space, and the classic geometric approach is to instead measure the curve length after a mapping to input space
One commonly proposed method is to endow the latent space with a \textit{Riemannian metric}, making it possible to define geometric properties in the input space rather than the distorted latent manifold space. As this latent space can be arbitrarily deformed following the aforementioned infidelity problem, the notion of distance here would be unreliable for defining relationships between points. A solution would therefore be to not define distances in the distorted latent space, but instead in the original input space. Because VAEs in practice span a manifold embedded in the original input space, it becomes possible to measure distances along the shape of this manifold by endowing it with a Riemannian metric, therefore making it a \textit{Riemannian manifold} space \citep{tosi2014metrics, arvanitidis2017latent, chen2018metrics, shao2018riemannian}. 
Riemannian geometry, unlike Euclidean geometry, considers space to be curved. A Riemannian metric can be thought of as an extra structure or shape on a manifold that allows for locally defining properties such as angles, distances, and volume. \citep{riemann2016hypotheses} Endowing the latent space with such a metric makes it possible to ensure that distances between points in the latent space are identifiable, even if the coordinates themselves are not. We can thereby bypass the problem of distortion of the latent space. 

This idea has recently proven its potential for a multitude of problems. \cite{arvanitidis2017latent} show that using a Riemannian distance metric significantly improves clustering using K-means on the MNIST dataset and that the visual quality of interpolations substantially improves. These results are independently confirmed by \cite{chen2018metrics} and \cite{yang2018geodesic}. Furthermore, \cite{detlefsen2022learning} apply the method to one-hot encoded protein sequences and find that they are able to preserve the phylogenetic tree-structure originally present in the data, as well as create natural interpolations that follow along this tree-shaped manifold. Finally, \cite{beik2021learning} apply it to capturing relevant motion patterns in robotics and are capable of efficiently planning robot motions based on human demonstrations as well as designing new motion patterns that were not observed originally. Both of these applications suggest that the Riemannian manifold representation succeeds in capturing a morphological quality present in the data; motion-based in the case of robotics and an evolutionary morphology in the case of proteins. Such a method seems highly suitable to investigate for a histopathological use case, as we would ideally want to create representations that capture the morphology of cell tissue from healthy to cancerous. 

Nevertheless, these models all suffer from one common issue: obtaining a Riemannian metric involves the computation of a Jacobian, which requires solving a system of ordinary differential equations. Systems like these do not always have a closed-form solution and are hard to evaluate with standard deep-learning frameworks. Solutions approximating the Jacobian, such as finite difference methods, introduce bias into the network, while relying on automatic differentiation is computationally costly. This makes the utility of the proposed method especially limited for high-dimensional datasets such as those containing images and even more so for the high-resolution biopsy scans used in histopathology. \cite{chadebec2020geometryaware} therefore propose their model \textit{RHVAE} (Riemannian Hamiltonian Variational Autoencoder), which instead of computing the Riemannian metric numerically, \textit{learns} it from the data. Not only does this avoid the need for computing a Jacobian, but it also provides more flexibility since no prior knowledge about the structure of the manifold is imposed on the model. Besides showing improved quality of interpolations on MNIST and FashionMNIST, the authors also apply their method to a biomedical use case in a follow-up study \citep{chadebec2021data}. There, they use RHVAE to augment a small-scale dataset of MRI scans, containing healthy scans and scans of patients with Alzheimer’s disease and show that training a CNN on the newly generated images improves overall classification performance. 


\subsection{The Latent Space as Manifold of Constant Curvature}\label{bg:hs}
The approaches above intend to solve the problem of the distorted latent space by assuming it to be a Riemannian manifold instead of a Euclidean space and accomplish this by endowing it with a Riemannian metric. However, as discussed, many of these approaches are not computationally feasible due to a lack of closed-form solutions. An alternative to general Riemannian manifolds is therefore the use of manifolds of constant sectional curvature \cite{skopek2019mixed, bachmann2020constant, gu2018learning}. Constant curvature manifolds are one of the only types of Riemannian manifolds for which closed-form solutions to quantities such as distances and exponential maps exist. They consist of three different types, namely elliptic (positive curvature), Euclidean (zero curvature), or hyperbolic (negative curvature). In cases where Euclidean geometry fails to accurately represent the data, 
the hyperbolic and spherical spaces can possibly provide a better inductive bias for the respective data. For instance, the hyperbolic space can be thought of as a continuous tree. Intuitively, it would seem that a hyperbolic structuring of the latent space could therefore be beneficial for hierarchical or tree-structured data, such as text or protein sequences. VAE models that structure the latent space in a hyperbolic way have indeed seen improved results on tasks such as the creation of word embeddings, and possess the ability to naturally exploit the semantic structure present in natural language data \cite{tifrea2018poincar, nagano2019differentiable}. Conversely, the elliptic space can be thought of as a \textit{sphere} and as such, provides benefits for modeling cyclical or spherical data. Examples of naturally spherical data include meshes, radiation waves, and 3D scans in medical imaging. Moreover, spherical spaces have also been shown to be better fit any form of normalized data, which is a common preprocessing step in modern deep-learning problems \cite{davidson2018hyperspherical}.

Examples of models utilizing a spherical latent space are \citet{batmanghelich2016nonparametric} and \citet{xu2018spherical}, who apply it to natural language processing and \citet{davidson2018hyperspherical} who use it on image data. In this work, \citeauthor{davidson2018hyperspherical} replace the Gaussian prior and posterior of the vanilla VAE to a uniform distribution and a von Mises–Fisher (vMF) distribution respectively, therefore creating a spherical latent space over which embedded points are spread uniformly. Using the MNIST image dataset, they show that \svae has improved quality of clusterings and interpolations over a vanilla VAE, and even has the ability to generalize to non-spherical data manifolds. 

 % This makes me want to use it.

% In this paper, we propose to use the von Mises-Fisher (vMF)
% distribution as an alternative to the Gaussian distribution.
% This replacement leads to a hyperspherical latent space
% as opposed to a hyperplanar one, where the Uniform dis-
% tribution on the hypersphere is conveniently recovered as
% a special case of the vMF. Hence this approach allows
% for a truly uninformative prior, and has a clear advantage
% in the case of data with a hyperspherical interpretation.

\subsection{Equivariant Hyperspherical VAEs}\label{bg:eq}
One downside of the above geometric models and VAEs in general is that they may encode information present in the data that is not actually relevant to the representation. An example of this for medical images specifically is orientation. Biopsies can be scanned in any arbitrary orientation, so the information about rotation is not actually a relevant component of the encoded representation and can possibly be a disrupting factor in downstream tasks.
 % The information about rotation is not relevant to the representation of the sample because it can be scanned in any arbitrary orientation. 
\citet{lafarge2020orientation} therefore propose a rotation-equivariant VAE model ($SE$(2)-VAE). They extend the vanilla convolutional VAE to a group-convolutional neural network \cite{cohen2016group}, making the model invariant to arbitrary rotations. This allows the VAE to learn both a representation vector and an orientation of an input image. Such an equivariant network can therefore disentangle the rotation from the rest of the latent representation. \citeauthor{lafarge2020orientation} show that this is a very useful property for representation learning of histopathological image data, improving the quality of generated image interpolations over the vanilla VAE model. It is worth noting that there is not much research on representation learning for histopathological image data specifically, so the insights provided by \citeauthor{lafarge2020orientation} can prove valuable to the current work. However, as the model still assumes a Euclidean latent space, it suffers from the same distortion issue present in the original VAE.

Therefore, \citet{vadgama2022kendall} more recently combined the methods of \citeauthor{lafarge2020orientation} and the hyperspherical model of \citeauthor{davidson2018hyperspherical} to create a VAE that features a hyperspherical latent space, while also being an orientation-disentangled group-convolutional network. They show that such a model is able to correctly learn orientations of MNIST images and that the model outperforms both vanilla autoencoders and the non-equivariant hyperspherical \svae in terms of minimizing loss. Since the group-convolutional VAE of \citeauthor{lafarge2020orientation} was shown to produce good results on a histopathological image dataset, it would be interesting to see how this translates to the model of \citeauthor{vadgama2022kendall}. 


\centerline{$\thicksim$}

This section described three different types of geometric variational autoencoders, which all relate to medical imaging in some way. For the Riemannian VAEs, the model of \citeauthor{chadebec2021data} (RHVAE) showed promising results on brain scans. Moreover, for the constant curvature models, the hyperspherical manifold type, such as the \svae model used in \citeauthor{davidson2018hyperspherical}, seemed the most applicable to image data. An extension of the hyperspherical model that disentangles orientation (KS-VAE) was proposed by \citeauthor{vadgama2022kendall} and the equivariant VAE model at the basis of this method, originally proposed by \citeauthor{lafarge2020orientation}, was shown to achieve high-quality interpolations. We will therefore compare the RHVAE, \svae, and KS-VAE models and apply them to the novel use case of histopathological image data. 
