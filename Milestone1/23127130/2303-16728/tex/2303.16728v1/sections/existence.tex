
Taking inspiration from \cite{hart_schmeidler, nowak1992correlated, Nowak1993} and \cite[Appendix 1.B]{bonesini_thesis}, we associate a zero-sum game to the search of a mean field CCE.
Loosely speaking, the game should be of the following type: player A, the maximizer, chooses a correlated flow $(\Lambda,\mu)$, while player B chooses a deviating strategy $\beta \in \A$.
The payoff functional is the following:
\begin{equation}\label{existence:payoff_informale}
    F\quadre{(\Lambda,\mu),\beta}=\J(\beta,\mu)-\J(\Lambda,\mu).
\end{equation}
Player A aims at maximizing $F$, while player B chooses her strategy in order to minimize $F$.
In order to get an equilibrium, one should restrict to correlated flows $(\Lambda,\mu)$ so that the consistency condition \eqref{def_mean_field_sol:cons} is satisfied.
If we could show that the game has a positive value and player A has an optimal strategy $(\Lambda^*,\mu^*)$ , then we would have established that such a strategy would satisfy the optimality property \eqref{def_mean_field_sol:opt} as well, and therefore $(\Lambda^*,\mu^*)$ would be a mean field CCE.
In order to get a convenient structure for the sets of strategies and good continuity and convexity properties of the payoff functionals, we embed our auxiliary problem in a more general zero-sum game which, roughly speaking, extends the payoff functional in equation \eqref{existence:payoff_informale}.
Care is needed in dealing with the term depending both on $\beta$ and $\mu$, since it must reflect independent strategy choices of the opponents. Using Fan's minimax theorem, we will show that the auxiliary game has positive value and admits an optimal strategy for the maximizing player.
Finally, such an optimal strategy is used to induce a coarse correlated solution of the mean field game.

\subsection{Relaxed controls}\label{existence:sezione_crtl_rilassati}
Since we are going to use compactness arguments, it is useful to provide some information about relaxed controls before introducing the auxiliary zero-sum game in the next section.
Relaxed controls have a long history in control theory (see, e.g., \cite{el_karoui_compactification} and \cite{haussmann1990sicom}), and also in mean field games (see the series of works \cite{delarue16commonnoise,lacker2015martingale,lacker2016,lacker2020convergence}, or \cite{campi18absorption} in a slightly different framework).
We will use them in a similar way.
\medskip

Denote by $\mathcal{V}$ the set of positive measures $q$ on $[0,T] \times A$ so that the time marginal is equal to the Lebesgue measure, i.e., $q ([s,t]\times A)=t-s$ for every $0 \leq s \leq t \leq T$.
We endow $\mathcal{V}$ with the topology of weak convergence of measures, which makes $\mathcal{V}$ a Polish space.
It is a well known fact that, when the set $A$ is compact, $\mathcal{V}$ is compact as well.
Moreover, for every measure $q \in \mathcal{V}$, there exists a measurable map $[0,T] \ni t \mapsto q_t \in \mathcal{P}(A)$ so that $q(da,dt)=q_t(da)dt$, with $(q_t)_{t \in [0,T]}$ unique up to $Leb_{[0,T]}$-a.e. equality.
We can equip the measurable space $(\mathcal{V},\boreliani{\mathcal{V}})$ with the filtration $(\F^{\mathcal{V}}_t)_{t \in [0,T]}$ defined by
\begin{equation*}
    \F^{\mathcal{V}}_t = \sigma( \mathcal{V} \ni q \mapsto q(C): \; C \in \boreliani{[0,t]\times A}).
\end{equation*}
We observe that $\F^{\mathcal{V}}_t$ is countably generated for every $t \in [0,T]$, by reasoning as in the proof of \cite[Proposition 7.25]{bertsekas_shreve}.
Finally, one can prove that there exists an $\mathcal{F}_t^{\mathcal{V}}$-predictable process $\overline{q}:[0,T]\times\mathcal{V}\to\mathcal{P}(A)$ such that, for each $q \in \mathcal{V}$, $\overline{q}(t,q)=q_t$ for a.e. $t \in [0,T]$ (see, e.g., \cite[Lemma 3.2]{lacker2015martingale}).
By an abuse of notation, we write $q_t(da)=\overline{q}(t,q)(da)$.


\medskip
Consider a filtered probability space $(\Omega,\F,\mathbb{F},\prob)$.
A relaxed control $\mathfrak{r}$ is a $\mathcal{V}$-valued random variable.
We say that $\mathfrak{r}$ is $\mathbb{F}$-adapted if $\mathfrak{r}(C)$ is a real valued $\F_t$-measurable random variable for every $C \in \boreliani{[0,t]\times A}$.
Observe that every $A$-valued progressively measurable process $\alpha=(\alpha_t)_{t \in [0,T]}$, which is often referred to as strict control, induces a relaxed control by setting
\begin{equation*}
    \mathfrak{r}_t(da)dt=\delta_{\alpha_t}(da)dt.
\end{equation*}
Finally, using the map $\overline{q}$ described above, we can safely identify every $\mathbb{F}$-adapted relaxed control $\mathfrak{r}$ with the unique (up to $Leb_{[0,T]}$-a.e. equality) $\mathbb{F}$-progressively measurable process $(\mathfrak{r}_t)_{t \in [0,T]}$ with values in $\mathcal{P}(A)$ so that
\begin{equation*}
    \prob(\mathfrak{r}(da,dt)=\mathfrak{r}_t(da)dt)=1.
\end{equation*}
In the following, we will use mostly the notation $(\mathfrak{r}_t)_{t \in [0,T]}$ for a relaxed control and will make no distinction between a $\mathcal{V}$-valued random variable and a $\mathcal{P}(A)$-valued process.

\bigskip
\subsection{The auxiliary zero-sum game}
We now formally define and study the auxiliary zero-sum game.
\begin{definition}[Strategies for player A]\label{existence:strategie_max}
A \emph{strategy for player A} is a probability measure $\Gamma \in \mathcal{P}(\contrd \times \mathcal{V} \times \contpdue)$ so that there exists a tuple $\mathfrak{U}=((\Omega,\F,\mathbb{F},\prob),\xi,W,\mu,\mathfrak{r})$ with the following properties:
\begin{enumerate}[label=(\roman*)]
    \item $(\Omega,\F,\mathbb{F},\prob)$ is a filtered probability space satisfying the usual assumptions; $\Omega$ is Polish and $\F$ is its corresponding Borel $\sigma$-algebra.
    \item $W$ is an $\mathbb{F}$-Brownian motion and $\xi$ is an $\F_0$-measurable independent $\R^d$-valued random variable with law $\nu$.
    \item $\mu$ is an $\F_0$-measurable random variable with values in $\contpdue$; it is independent of both $\xi$ and $W$.
    \item $\mathfrak{r}$ is an $\mathbb{F}$-progressively measurable relaxed control $\mathfrak{r}=(\mathfrak{r}_t)_{t \in [0,T]}$ with values in $A$.
    \item Let $X$ be the solution of
    \begin{equation}\label{existence:eq_processo_K}
        dX_t=\int_A b(t,X_t,\mu_t,a)\mathfrak{r}_t(da)dt + dW_t, \; t \in [0,T], \quad X_0=\xi.
    \end{equation}
    Then $\mu_t(\cdot)=\prob(X_t \in \cdot \; \vert \; \mu)$ $\prob$-a.s for every $t \in [0,T]$.
    
    \item $\Gamma$ is the joint law under $\prob$ of  $X$, $\mu$ and $\mathfrak{r}$: $\Gamma=\prob\circ(X,\mathfrak{r},\mu)^{-1}$.
\end{enumerate}
We denote by $\mathcal{K}$ the set of strategies for player A.
\end{definition}
We observe that, by Assumptions \ref{standing_assumptions}, there exists a unique solution to equation \eqref{existence:eq_processo_K} for every tuple $\mathfrak{U}$ satisfying properties (i-iv).

\begin{definition}[Strategies for player B]\label{existence:strategie_min}
A stochastic kernel $\Sigma$ from $\contpdue$ to $\contrd \times \mathcal{V}$ is a \emph{strategy for player B} if there exists a tuple $\mathfrak{U}=((\Omega,\F,\mathbb{F},\prob),\xi,W,\mathfrak{r})$ so that
\begin{enumerate}[label=(\roman*)]
    \item $(\Omega,\F,\mathbb{F},\prob)$ is a filtered probability space satisfying the usual assumptions; $\Omega$ is Polish and $\F$ is its corresponding Borel $\sigma$-algebra.
    \item $W$ is an $\mathbb{F}$-Brownian motion and $\xi$ is an $\F_0$-measurable independent $\R^d$-valued random variable with law $\nu$.
    \item $\mathfrak{r}$ is an $\mathbb{F}$-progressively measurable relaxed control $\mathfrak{r}=(\mathfrak{r}_t)_{t \in [0,T]}$ with values in $A$.
    \item For every $m \in \contpdue$, $\Sigma(\cdot, m) \in \mathcal{P}(\contrd \times \mathcal{V})$ is the joint law under $\prob$ of $(X^m,\mathfrak{r})$, where $X^m$ is the solution to
    \begin{equation}\label{existence:eq_processo_Q}
    dX^m_t=\int_A b(t,X^m_t,m_t,a)\mathfrak{r}_t(da)dt + dW_t, \quad X_0=\xi,
    \end{equation}
    that is:
    \begin{equation}
        \Sigma(B,m)=\prob((X^m,\mathfrak{r}) \in B) \quad \forall m \in \contpdue, B \in \boreliani{\contrd} \otimes \boreliani{\mathcal{V}}.
    \end{equation}
\end{enumerate}
We denote by $\mathcal{Q}$ the set of strategies for player B.
\end{definition}
By Lemma \ref{existence:lemma_kernels}, the set of strategies $\mathcal{Q}$ for player B is well defined in the sense that
the map $\Sigma$ is truly a stochastic kernel.

\bigskip
We now define the payoff functional $\mathfrak{p}$ for the zero-sum game.
Let us introduce the function $\mathfrak{F}: \contrd \times \mathcal{V}\times \contpdue \to  \R$ defined by
\begin{equation}\label{existence:funzione_f}
\begin{aligned}
    \mathfrak{F} (y,q,m)=\int_0^T\int_A f(t,y_t,m_t,a)q_t(da)dt + g(y_T,m_T).
\end{aligned}
\end{equation}
\begin{definition}[Auxiliary zero-sum game]\label{existence:def_zerosum}
The \emph{auxiliary zero-sum game} is a zero-sum game where:
\begin{itemize}
    \item The set of strategies for player A, the maximizer, is the set $\mathcal{K}$ introduced in Definition \ref{existence:strategie_max}.
    \item The set of strategies for player B, the minimizer, is the set $\mathcal{Q}$ introduced in Definition \ref{existence:strategie_min}.
    \item The payoff functional is the function $\mathfrak{p}:\mathcal{K}\times\mathcal{Q}\to \R$ defined as
    \begin{equation}\label{existence:payoff_functional}
    \begin{aligned}
        \mathfrak{p}(\Gamma,\Sigma) = & \int_{\contrd \times \mathcal{V} \times \contpdue} \mathfrak{F} (y,q,m) \Sigma(dy,dq,m)\rho(dm)\\
        & - \int_{\contrd \times \mathcal{V} \times \contpdue} \mathfrak{F} (y,q,m) \Gamma(dy,dq,dm),
    \end{aligned}
    \end{equation}
    where $\rho$ denotes the marginal of $\Gamma$ on $\contpdue$.
\end{itemize}
We denote the lower and upper values of the game as, respectively, $v^A$ and $v^B$: 
\begin{equation*}
\begin{aligned}
    & v^A=\sup_{\Gamma \in \mathcal{K}} \inf_{\Sigma \in \mathcal{Q}} \mathfrak{p}(\Gamma,\Sigma), && \quad 
    v^B= \inf_{\Sigma \in \mathcal{Q}} \sup_{\Gamma \in \mathcal{K}} \mathfrak{p}(\Gamma,\Sigma).
\end{aligned}
\end{equation*}
If the lower and upper values of the game are equal, we set $v=v^A=v^B$ and call $v$ the value of the game.
We say that a strategy $\Gamma^* \in \mathcal{K}$ is optimal for player A if
\begin{equation*}
    \inf_{\Sigma \in \mathcal{Q}}\mathfrak{p}(\Gamma^*,\Sigma)=\max_{\Gamma \in \mathcal{K}}\inf_{\Sigma \in \mathcal{Q}}\mathfrak{p}(\Gamma,\Sigma).
\end{equation*}
\end{definition}

\subsection{Relationship between the zero-sum game and the mean field game}
The goal of this section is to show how to use an optimal strategy for the maximizing player of the auxiliary game to induce a coarse correlated solution to the mean field game.
The next proposition shows that, for every correlated flow $(\Lambda,\mu)$ so that consistency condition \eqref{def_mean_field_sol:cons} is satisfied and every deviation $\beta \in \A$, there exists a pair of strategies $(\Gamma,\Sigma) \in \mathcal{K}\times\mathcal{Q}$ so that the following equality holds:
\begin{equation}\label{existence:prop_relazione_mfg:equazione_payoffs}
        \mathfrak{p}(\Gamma,\Sigma)=\J(\Lambda,\mu)-\J(\beta,\mu)=F[(\Lambda,\mu),\beta].
\end{equation}

\begin{prop}\label{existence:prop_relazione_mfg}
Let $((\Omega^0,\F^{0-}$, $\prob^0),\Lambda,\mu)$ be a correlated flow.
Denote by $\rho$ the law of $\mu$.
Let $\lambda=(\lambda_t)_{t \in [0,T]}$ be the strategy associated to the admissible recommendation $\Lambda$ and let $\beta \in \A$.
\begin{enumerate}[label=(\roman*)]
    \item     Let $X$ be the solution to \eqref{dinamica_MF_no_deviazione}.
    Suppose that consistency condition \eqref{def_mean_field_sol:cons} is satisfied.
    For every $t \in [0,T]$, set $\mathfrak{r}_t(da)dt=\delta_{\lambda_t}(da)dt$.
    Then, the probability measure $\Gamma=\prob\circ(X,\mathfrak{r},\mu)^{-1}$ belongs to the set $\mathcal{K}$.

    \item \label{existence:prop_relazione_mfg:deviazioni}
    For every $t \in [0,T]$, set $\mathfrak{b}_t(da)dt=\delta_{\beta_t}(da)dt$.
    Denote by $Y$ the solution to \eqref{dinamica_MF_deviation}.
    Then, there exists $\Sigma \in \mathcal{Q}$ so that
    \begin{equation}\label{existence:prop_relazione_mfg:decomposizione}
        \prob((Y,\mathfrak{b},\mu)\in B \times S)=\int_S \Sigma(B,m)\rho(dm), \quad \forall B \in \boreliani{\contrd \times \mathcal{V}}, \; S \in \boreliani{\contpdue}.
    \end{equation}
    
    \item \label{existence:prop_relazione_mfg:relazione_payoffs}
    The pair of strategies $(\Gamma,\Sigma)$ satisfies equation \eqref{existence:prop_relazione_mfg:equazione_payoffs}.
\end{enumerate}
\end{prop}
\begin{proof}
In the following, we work on the probability space $(\Omega,\F,\mathbb{F},\prob)$ defined in point \eqref{mf:condizione_ammissibilita} of Definition \ref{mf:admissible_recommendation}.
Recall that, as pointed out in Remark \ref{finite_players:remark_estensioni}, we can think of $W$, $\xi$ and $\mu$ as independent random variables, each of them defined on the same probability space $(\Omega,\F,\mathbb{F},\prob)$.
Observe that the $\mathcal{P}(A)$-valued process $\mathfrak{r}=(\delta_{\lambda_t})_{t \in [0,T]}$ is $\mathbb{F}$-progressively measurable since $\Lambda$ is admissible by assumption.
Let $X$ be the solution to equation \eqref{dinamica_MF_no_deviazione}.
Since $X$ obviously satisfies \eqref{existence:eq_processo_K} for such a process $\mathfrak{r}$ and the condition $\mu_t(\cdot)=\prob(X_t \in \cdot \; \vert \; \mu)$ holds by assumption, $\Gamma=\prob\circ(X,\mu,\mathfrak{r})^{-1}$ belongs to $\mathcal{K}$.


As for point \ref{existence:prop_relazione_mfg:deviazioni}, recall from Remark \ref{finite_players:remark_estensioni} that we can regard $\beta$ as defined on the product space $(\Omega,\F,\prob)$, and that $\beta$ and $\mu$ are mutually independent by construction.
Therefore, the $\mathcal{P}(A)$-valued process $\mathfrak{b}=(\delta_{\beta_t}(da))_{t \in [0,T]}$ is independent of $\mu$.
Let $Y$ be the solution of equation \eqref{dinamica_MF_deviation}.
By Lemma \ref{existence:lemma_decomposizione} in Appendix \ref{appendix_existence}, equation \eqref{existence:prop_relazione_mfg:decomposizione} holds.

Finally, since $X$ and $Y$ are defined on the same filtered probability space $(\Omega,\F,\mathbb{F},\prob)$, we can write the integrals in $\mathfrak{p}$ as expectations:
\begin{equation*}
\begin{aligned}
    & \int \mathfrak{F} (y,q,m) \Gamma(dy,dq,dm) = \E\quadre{\int_0^T f(t,X_t,\mu_t,\lambda_t)dt + g(X_T,\mu_T)} = \J(\Lambda,\mu), \\
    & \int \mathfrak{F} (y,q,m) \Sigma(dy,dq,m)\rho(dm) = \E\quadre{\int_0^T  f(t,Y_t,\mu_t,\beta_t)dt + g(Y_T,\mu_T)}=\J(\beta,\mu).
\end{aligned}
\end{equation*}
This proves \eqref{existence:prop_relazione_mfg:equazione_payoffs}.
\end{proof}

The next result ensures existence of an optimal strategy for the maximizing player:
\begin{thm}[Existence of the value of the game and of an optimal strategy for the maximizing player]\label{existence:thm_esistenza_strategia_ottima}
Consider the game described in Definition \ref{existence:def_zerosum}.
The following holds:
\begin{enumerate}[label=(\roman*)]
    \item \label{existence:thm_esistenza_strategia_ottima:existence_value} The game has a value, i.e. $v^A=v^B$.
    
    \item \label{existence:thm_esistenza_strategia_ottima:optimal_strategy} There exists a strategy $\Gamma^* \in \mathcal{K}$ which is optimal for player $A$.

    \item \label{existence:thm_esistenza_strategia_ottima:positive_value} The value $v$ of the game is non negative: $v \geq 0$.

\end{enumerate}
\end{thm}
The proof of this theorem is deferred to Section \ref{existence:sezione_opt_strat_auxiliary}.
The following result is some sort of mimicking result: it will allow us to find, given any measure $\Gamma \in \mathcal{K}$, a probability measure $\hat{\Gamma}$ so that $\hat{\Gamma}$ and $\Gamma$ share the same payoff for every opponent's strategy $\Sigma \in \mathcal{Q}$ and $\hat{\Gamma}$ is induced by a correlated flow, as in Proposition \ref{existence:prop_relazione_mfg}:
\begin{lemma}\label{existence:lemma_mimicking}
Let $\Gamma \in \mathcal{K}$. There exists a measure $\hat{\Gamma} \in \mathcal{K}$ so that the following holds:
\begin{itemize}
    \item The marginal distributions of $\Gamma$ and $\hat{\Gamma}$ on $\contpdue$ are the same: $\Gamma(\contrd \times \mathcal{V} \times \cdot)=\hat{\Gamma}(\contrd \times \mathcal{V} \times \cdot)$.
    
    \item Let $(X,\mathfrak{r},\mu)$ be such that $\hat{\Gamma}=\prob\circ(X,\mathfrak{r},\mu)^{-1}$.
    Then $\mathfrak{r}$ is of the form $\mathfrak{r}_t=\hat{q}_t(X_t,\mu)$, where $\hat{q}:[0,T]\times\R^d\times\contpdue \to \mathcal{P}(A)$ is a measurable function.
    \item For every $\Sigma \in \mathcal{Q}$, it holds
    \begin{equation*}
        \mathfrak{p}(\Gamma,\Sigma)=\mathfrak{p}(\hat{\Gamma},\Sigma).
    \end{equation*}
\end{itemize}
\end{lemma}
The proof of this lemma is postponed to Appendix \ref{appendix_existence}.
In order to prove Theorem \ref{existence:main_theorem}, we need the  following additional assumption, which are standard when dealing with relaxed controls (see, e.g., \cite{haussmann1990sicom}):
\begin{customassumption}{\textbf{B}}\label{convexity_assumptions}
For every $(t,x,m) \in [0,T] \times \R^d \times \pwassspace{2}{\R^d}$, the set
\begin{equation}\label{convexity_assumptions:insieme_K}
    K(t,x,m)=\insieme{ (b(t,x,m,a),z): \; a \in A, \; f(t,x,m,a) \leq z} \subseteq \R^d \times \R
\end{equation}
is closed and convex.
\end{customassumption}

Finally, we prove the existence of a coarse correlated solution to the mean field game:
\begin{thm}[Existence of a coarse correlated solution of the MFG]\label{existence:main_theorem}
In addition to Assumptions \ref{standing_assumptions}, suppose that Assumption \ref{convexity_assumptions} holds.
Then there exists a coarse correlated solution of the mean field game.
\end{thm}
\begin{proof}
Let $\Gamma^* \in \mathcal{K}$ be an optimal strategy for player A, which exists by Theorem \ref{existence:thm_esistenza_strategia_ottima}.
Consider the strategy $\hat{\Gamma}^*$ given by Lemma \ref{existence:lemma_mimicking}, so that it holds
\begin{equation}\label{existence:main_thm:condizione_min_max}
    \inf_{\Sigma \in \mathcal{Q}}\mathfrak{p}(\hat{\Gamma}^*,\Sigma)=\inf_{\Sigma \in \mathcal{Q}}\mathfrak{p}(\Gamma^*,\Sigma)=\max_{\Gamma \in \mathcal{K}}\inf_{\Sigma \in \mathcal{Q}}\mathfrak{p}(\Gamma,\Sigma) \geq 0.
\end{equation}
Let $\mathfrak{U}=((\hat{\Omega},\hat{\F},\hat{\mathbb{F}},\hat{\prob}),\hat{\xi},\hat{W},\hat{\mu},\hat{\mathfrak{r}})$ 
be as in Definition \ref{existence:strategie_max}, so that $\hat{\Gamma}^*=\prob\circ(\hat{X},\hat{\mathfrak{r}},\hat{\mu})^{-1}$.
Recall that, by Lemma \ref{existence:lemma_mimicking}, $\hat{\mathfrak{r}}_t(da)dt=\hat{q}_t(\hat{X}_t,\hat{\mu})(da)dt$ $Leb_{[0,T]} \otimes \hat{\prob}$-a.s..
By Assumption \ref{convexity_assumptions}, the set $K(t,x,m_t)$ defined by \eqref{convexity_assumptions:insieme_K} is convex for every $(t,x,m) \in [0,T] \times \R^d \times \contpdue$.
Therefore, by a well known measurable selection argument (see, e.g., \cite[Lemma A.9]{haussmann1990sicom}) there exists a measurable function $\hat{\alpha}:[0,T]\times\R^d\times \contpdue \to A$ so that
\begin{equation}\label{existence:main_theorem:strict_ctrl}
\begin{aligned}
    \int_A b(t,x,m_t,a)\hat{q}_t(x,m)(da)=b(t,x,m_t,\hat{\alpha}(t,x,m)), \\
    f(t,x,m_t,\hat{\alpha}(t,x,m)) \leq \int_A f(t,x,m_t,a)\hat{q}_t(x,m)(da).
\end{aligned}
\end{equation}
It follows that $\hat{X}$ is a solution to equation
\begin{equation}\label{existence:main_theorem:opt_ctrled_eq}
    d\hat{X}_t=b(t,\hat{X}_t,\hat{\mu}_t,\hat{\alpha}(t,\hat{X}_t,\hat{\mu}))dt + d\hat{W}_t, \quad \hat{X}_0=\hat{\xi}
\end{equation}
as well, and the consistency condition \eqref{def_mean_field_sol:cons} is still satisfied.
By Lemma \ref{existence:mimicking:lemma_strong_existence}, we deduce that the solution $\hat{X}$ to equation \eqref{existence:main_theorem:opt_ctrled_eq} can be taken adapted to the $\hat{\prob}$-augmentation of the filtration $(\sigma(\hat{\mu}) \vee \sigma(\hat{\xi}) \vee \sigma(\hat{W}_s: \; s \leq t))_{t \in [0,T]}$, and therefore there exists a progressively measurable function $\Phi:\contpdue\times\R^d\times\contrd\to\contrd$ so that
\begin{equation}
    \hat{X}= \Phi(\hat{\mu},\hat{\xi},\hat{W}) \quad \hat{\prob}\text{-a.s.}
\end{equation}
Set
\begin{equation}\label{existence:main_theorem:ctrl_indotto}
\begin{aligned}
    & \begin{aligned}
        \hat{\lambda}:[0,T]\times\contpdue\times \R^d \times \contrd & \to A \\
    (t,m,x,w)&\mapsto \hat{\lambda}_t(m,x,w)=\hat{\alpha}_t(\Phi_t(m,x,w),m_t);
    \end{aligned} \\
    & \lambda =(\lambda_t)_{t \in [0,T]}=(\hat{\lambda}_t(\hat{\mu},\hat{\xi},\hat{W}))_{t \in [0,T]}.
\end{aligned}
\end{equation}
Then, the progressively measurable processes $(\hat{\alpha}_t(\hat{X}_t,\hat{\mu}))_{t \in [0,T]}$ and $(\hat{\lambda}_t(\hat{\mu},\hat{\xi},\hat{W}))_{t \in  [0,T]}$ are equal $Leb_{[0,T]}\otimes\hat{\prob}$-a.s., which implies that $\hat{X}$ solves 
\begin{equation*}
    d\hat{X}_t=b(t,\hat{X}_t,\hat{\mu}_t,\hat{\lambda}_t(\hat{\mu},\hat{\xi},\hat{W}))dt + d\hat{W}_t, \quad \hat{X}_0=\hat{\xi}
\end{equation*}
as well, and the consistency condition is still satisfied.
Set $(\Omega^0,\F^{0-},\prob^0)=(\contpdue,\boreliani{\contpdue},\rho)$.
By Lemma \ref{esempi:lemma_misurabile}, there exists a $\prob^0$-null set $N \subset \Omega^0$ so that the pair $(\Lambda^*,\mu*)$ defined by
\begin{equation}
\begin{aligned}
    \Lambda^*: \tonde{\contpdue,\boreliani{\contpdue},\rho} & \to (\A,\boreliani{\A}) \\
    m & \mapsto \Lambda^*(m)= \left\{ \begin{aligned}
        & (\hat{\lambda}_t(m,\cdot,\cdot))_{t \in [0,T]}, && m \in \Omega^0 \setminus N, \\
        & a_0  && m \in N,
        \end{aligned} \right. \\
    \mu^*=\text{Id}:\tonde{\contpdue,\boreliani{\contpdue},\rho} & \to \tonde{\contpdue,\boreliani{\contpdue},\rho}
\end{aligned}
\end{equation}
is a correlated flow, where $a_0$ is an arbitrary point in $A$.
Let $X^*$ be the solution of \eqref{dinamica_MF_deviation} on the product probability space $(\Omega,\F,\mathbb{F},\prob)$ defined in point \ref{mf:condizione_ammissibilita} of Definition \ref{mf:admissible_recommendation}.
Note that the strategy associated to the admissible recommendation $\Lambda^*$ strategy $\lambda^*$ is equal to $\hat{\lambda}_t(\mu^*,\xi,W)$ $Leb_{[0,T]}\otimes\prob$-almost surely.
Since uniqueness in law holds by Theorem \ref{teorema_di_unicita_legge}, it follows that
\begin{equation}\label{existence:main_thm:uguaglianza_leggi}
    \prob\circ(X^*,(\delta_{\lambda^*_t}(da))_{t \in [0,T]},\mu^*)^{-1}= \hat{\prob}\circ(\hat{X},(\delta_{\hat{\alpha}(t,\hat{X}_t,\hat{\mu})}(da))_{t \in [0,T]},\hat{\mu})^{-1},
\end{equation}
which implies that the consistency condition \eqref{def_mean_field_sol:cons} is satisfied.

\bigskip
Finally, we verify that the correlated flow just defined satisfy the optimality condition \eqref{def_mean_field_sol:opt}.
For any $\beta \in \A$, let $\Sigma \in \mathcal{Q}$ be as in point \ref{existence:prop_relazione_mfg:deviazioni} of Proposition \ref{existence:prop_relazione_mfg}.
Then, by \eqref{existence:main_thm:uguaglianza_leggi}, \eqref{existence:main_theorem:strict_ctrl} and \eqref{existence:main_thm:condizione_min_max}, for every $\Sigma \in \mathcal{Q}$ it holds
\begin{equation*}
\begin{aligned}
    \J & (\Lambda^*,\mu^*) = \E^{\hat{\prob}}\quadre{\int_0^T f(t,\hat{X}_t,\hat{\mu}_t,\hat{\alpha}(t,\hat{X}_t,\hat{\mu})) dt + g(\hat{X}_T,\hat{\mu}_T)} \\
    & \leq \E^{\hat{\prob}}\quadre{\int_0^T \int_A f(t,\hat{X}_t,\hat{\mu}_t,a)\hat{q}_t(\hat{X}_t,\hat{\mu}) dt + g(\hat{X}_T,\hat{\mu}_T)} = \int \mathfrak{F} (y,q,m) \hat{\Gamma}^*(dy,dq,dm) \\
    & \leq \int \mathfrak{F} (y,q,m) \Sigma(dy,dq,m)\rho(dm) = \J(\beta,\mu^*),
\end{aligned}
\end{equation*}
which proves that $(\Lambda^*,\mu^*)$ satisfies the optimality condition and therefore is a mean field CCE.
\end{proof}

\subsection{Proof of Theorem \ref{existence:thm_esistenza_strategia_ottima}.}
\label{existence:sezione_opt_strat_auxiliary}
The main instrument is the following Minimax Theorem, due to K. Fan:
\begin{thm}[ \cite{fan1953minimax}, Theorem 2 ] \label{thm_minimax}
Let $X$ be a compact Hausdorff space and $Y$ an arbitrary set (not topologized). Let $f:X\times Y\to \R$ be a real-valued function such that, for every $y \in Y$, $x \mapsto f(x,y)$ is lower semi-continuous on $X$.
If $f(\cdot,y)$ is concave on $X$ for every $y \in Y$ and $f(x,\cdot)$ convex on $Y$ for every $x \in X$, then
\begin{equation}
    \max_{x \in X} \inf_{y \in Y} f(x,y) = \inf_{y \in Y} \max_{x \in X} f(x,y).
\end{equation}
\end{thm}

The following results aims at verifying that the auxiliary zero-sum game in Definition \ref{existence:def_zerosum} satisfies the assumptions of Theorem \ref{thm_minimax}.
We start with some useful moment estimates for the solution to \eqref{existence:eq_processo_K}:
\begin{lemma}[Estimates]\label{lemma_stima_a_priori}
Let $\Gamma \in \mathcal{K}$, let $\mathfrak{U}=((\Omega,\F,\mathbb{F},\prob),\xi,W,\mu,\mathfrak{r})$ be the tuple associated to $\Gamma$, as in Definition \ref{existence:strategie_max}, and let $X$ be the solution to \eqref{existence:eq_processo_K}.
Then, for every $2 \leq p \leq \overline{p}$, there exists a constant $C=C(p,T,\nu,b,A)$ so that
\begin{equation}\label{lemma_stima_a_priori:stima}
    \attesa{\norm{X}_{\contrd}^p}\leq C.
\end{equation}
\end{lemma}
The proof is omitted as it is just a straightforward application of Gronwall's lemma.

\begin{lemma}\label{existence:lemma_tightness}
$\mathcal{K}$ is pre-compact in $(\mathcal{P}^2(\contrd \times \mathcal{V}\times \contpdue),\pwassmetric{2}{\contrd \times \mathcal{V}\times \contpdue}{})$.
\end{lemma}
\begin{proof}
Let $(\Gamma^n)_{n \geq 1}$ be a sequence in $\mathcal{K}$, let us show that it is pre-compact, which, by Lemma \ref{wass:equivalenze_convergenza} is equivalent to show that $(\Gamma^n)_{n \geq 1}$ is tight and condition \eqref{wass:uniforme_integrabilita} is satisfied.
Moreover, by \cite[Lemma A.2]{lacker2015martingale}, relative compactness of the sequence $(\Gamma^n)_{n \geq 1}$ is equivalent to the relative compactness of each sequence of marginals on $\contrd$, $\contpdue$ and $\mathcal{V}$.

Since $A$ is compact by Assumption \ref{standing_assumptions}, the space $\mathcal{V}$ is compact as well.
Then, we automatically get both tightness of the sequence of the marginals on $\mathcal{V}$ of $(\Gamma^n)_{n\geq 1}$ and property \eqref{wass:uniforme_integrabilita}.

In the following, for every $n\geq 1$, let $\mathfrak{U}^n=((\Omega^n,\F^n,\mathbb{F}^n,\prob^n),\xi^n,W^n,\mu^n,\mathfrak{r}^n)$ and $X^n$ be as in Definition \ref{existence:strategie_max}, so that $\Gamma^n=\prob^n\circ(X^n,\mu^n,\mathfrak{r}^n)^{-1}$.
Let $\Gamma^n_1$ be the law of $X^n$ under $\prob^n$.
We prove the tightness by means of Kolmogorov-\v{C}entsov criterion, as stated, e.g., in \cite[Corollary 16.9]{kallenberg_foundations}.
Let $2< p \leq \overline{p}$, $0\leq s < t \leq T$. We have:
\begin{equation*}
\begin{aligned}
    \E^n&\quadre{\abs{X^n_t - X^n_s}^p} \leq C\E^n\quadre{\int_s^t \int_A \abs{b(u,X^n_u,\mu^n_u,a)}^p \mathfrak{r}^n_u(da)du + \abs{W_t - W_s}^p} \\
    & \leq C\tonde{\abs{t-s}^{p-1}\int_s^t \E^n\quadre{ \int_A \abs{b(u,X^n_u,\mu^n_u,a)}^p \mathfrak{r}^n_u(da)}du + \abs{t-s}^\frac{p}{2}},
\end{aligned}
\end{equation*}
for some positive constant $C$ which is updated from line to line.
For every $u \in [0,T]$, we have
\begin{equation}\label{lemma_tightness:bound_uniforme}
\begin{aligned}
    \E^n&\quadre{ \int_A \abs{b(u,X^n_u,\mu^n_u,a)}^p \mathfrak{r}^n_u(da)} \\
    & \leq C\E^n\quadre{\abs{X^n_u}^p + \tonde{\int_{\R^d}\abs{y}^2 \mu^n_u(dy)}^\frac{p}{2} + \int_A \abs{a-a_0}^p \mathfrak{r}^n_u(da) + \abs{b(u,0,\delta_0,a_0)}^p } \\
    & \leq C\tonde{1 + \E^n\quadre{\abs{X^n_u}^p + \int_{\R^d}\abs{y}^p \mu^n_u(dy) } } = C\tonde{ 1 + \E^n\quadre{\abs{X^n_u}^p +\E^n\quadre{ \abs{X^n_u}^p \big \vert \mu^n }}} \\
    & = C\tonde{ 1 + 2\E^n\quadre{ \abs{X^n_u}^p } } \leq C \tonde{ 1 + \E^n\quadre{\sup_{u \in [0,T]} \abs{X^n_u}^p } } \leq  C,
\end{aligned}
\end{equation}
where the last inequality follows from Lemma \ref{lemma_stima_a_priori}, with $C$ independent of $n \geq 1$.
Such a uniform bound implies that
\begin{equation*}
\begin{aligned}
    \E^n&\quadre{\abs{X^n_t - X^n_s}^p} \leq C\tonde{\abs{t-s}^{p-1}\int_s^t \E^n\quadre{ \int_A \abs{b(u,X^n_u,\mu^n_u,a)}^p \mathfrak{r}^n_u(da)}du + \abs{t-s}^\frac{p}{2}} \\
    & \leq C\tonde{\abs{t-s}^{p-1}\abs{t-s}C(p,T,\nu,b,A) + \abs{t-s}^\frac{p}{2}} \leq C\tonde{\abs{t-s}^p + \abs{t-s}^{\frac{p}{2}}} \leq C \abs{t-s}^{\frac{p}{2}}.
\end{aligned}
\end{equation*}
Set $\beta=\sfrac{p}{2}-1$, so that we get
\begin{equation}\label{existence:lemma_tightness:stima_momenti}
    \E^n\quadre{\abs{X^n_t-X^n_s}^p}\leq C \abs{t-s}^{1+\beta},
\end{equation}
with $p,\beta>0$.
Since $\prob^n\circ(X_0^n)^{-1}= \nu \in \mathcal{P}^p(\R^d)$ for every $n\geq 1$, we have the tightness of the initial laws as well.
This concludes of the proof of the tightness of $(\Gamma^n_1)_{n \geq 1}$.
As for condition \eqref{wass:uniforme_integrabilita}, we have:
\begin{equation*}
    \begin{aligned}
        \lim_{r \to \infty} & \sup_n \int_{\insieme{y: \; \norm{y}_{\contrd}^2 > r}} \norm{y}_{\contrd}^2 \Gamma^n_1(dy)=\lim_{r \to \infty} \sup_n \E^n\quadre{\norm{X^n}_{\contrd}^2\1_{\insieme{\norm{X^n}_{\contrd}^2 > r}}} \\
        & \leq \lim_{r \to \infty} \sup_n \tonde{\E^n\quadre{\norm{X^n}_{\contrd}^{4}}}^\frac{1}{2}\prob^n\tonde{\norm{X^n}_{\contrd}^2 > r}^\frac{1}{2}\leq C \lim_{r \to \infty} \sup_n \prob^n\tonde{\norm{X^n}_{\contrd}^2 > r}^\frac{1}{2}
    \end{aligned}
\end{equation*}
for some positive constant $C$ independent of $n$.
By Markov's inequality and estimate \eqref{lemma_stima_a_priori:stima} again, we get
\begin{equation*}
    \lim_{r \to \infty} \sup_n \int_{\insieme{y: \; \norm{y}_{\contrd}^2 > r}} \norm{y}_{\contrd}^2 \Gamma^n_1(dy) \leq C \lim_{r \to \infty} \sup_n \E^n\quadre{\norm{X^n}_{\contrd}^2}^\frac{1}{2}r^{-\frac{1}{2}}=0.
\end{equation*}

Finally, we turn to the sequence $(\rho^n)_{n \geq 1}$, where $\rho^n=\prob^n\circ(\mu^n)^{-1}$.
Let $\prob^{n,m}(\cdot)=\prob^n( \cdot \; \vert \; \mu = m)$ be the regular conditional distribution of $\prob^n$ given $\mu^n=m$.
Then, $\mu^n_t=m_t$ $\prob^{n,m}$-a.s. and $\prob^{n,m} \circ (X^n_t)^{-1}= m_t$ $\rho$-a.e. for every $t \in [0,T]$, which implies that, for every $s,t \in [0,T]$, we have 
\begin{equation*}
    \E^{n,m}\quadre{\pwassmetric{2}{\R^d}{p}(\mu^n_t,\mu^n_s)}\leq \E^{n,m} \quadre{\abs{ X^n_t - X^n_s}^p }
\end{equation*}
for $\rho$-a.e. $m \in \contpdue$.
Integrating with respect to $\rho$ yields
\begin{equation*}
    \E^{n}\quadre{\pwassmetric{2}{\R^d}{p}(\mu^n_t,\mu^n_s)}\leq \E^{n} \quadre{\abs{ X^n_t - X^n_s}^p } \leq C \abs{t-s}^{1 + \beta}
\end{equation*}
where the last inequality follows from \eqref{existence:lemma_tightness:stima_momenti} with $\beta=\sfrac{p}{2}-1$.
Since $\prob^{n}\circ(\mu^n_0)^{-1}=\delta_{\nu}$, it is enough to apply again Kolmogorov-\v{C}entsov criterion and deduce the tightness of $(\rho^n)_{n \geq 1}$.
Finally, we verify condition \eqref{wass:uniforme_integrabilita}.
To this extent, we note that, for every $n \geq 1$, there exists a continuous modification of the process $(\E^n[\vert X^n_t \vert ^2\; \vert \; \mu^n])_{t \in [0,T]}$, so that it holds
\begin{equation*}
    \sup_{t \in [0,T]} \int_{\R^d} \abs{y}^2 \mu^n_t(dy) = \sup_{t \in [0,T]}\E^n\quadre{\abs{X^n_t}^2 \; \big\vert \; \mu^n_t } \quad \prob^n\text{-a.s.}
\end{equation*}
Indeed, estimate \eqref{existence:lemma_tightness:stima_momenti} on the moments of $X^n$ implies that the process $(\E^n[\vert X^n_t \vert ^2\; \vert \; \mu^n])_{t \in [0,T]}$ satisfies
\begin{equation*}
\begin{aligned}
    \E^n & \quadre{\abs{    \E^n\quadre{\abs{X^n_t}^2\; \vert \; \mu^n} - \E^n\quadre{\abs{X^n_s}^2\; \vert \; \mu^n}}^p} \leq \E^n \quadre{ \abs{ \abs{X^n_t}^2 - \abs{X^n_s}^2 } ^ p } \\
    & = \E^n \quadre{ \abs{X^n_t - X^n_s}^p \abs{X^n_t + X^n_s}^p } \leq \E^n \quadre{  \abs{X^n_t - X^n_s}^{2p}}^\frac{1}{2} \E^n \quadre{ \abs{X^n_t + X^n_s}^{2p} }^\frac{1}{2} \leq C\abs{t-s}^\frac{p}{2},
\end{aligned}
\end{equation*}
where we have used Cauchy-Schwartz inequality, \eqref{lemma_stima_a_priori:stima} and  \eqref{existence:lemma_tightness:stima_momenti} to bound $\E^n [ \vert X^n_t - X^n_s \vert ^{2p} ]^{\sfrac{1}{2}}$ and $\E^n [ \vert X^n_t + X^n_s \vert ^{2p} ]^{\sfrac{1}{2}}$, respectively.
Therefore, by choosing $2 < p < \sfrac{\overline{p}}{2}$ and $\beta=\sfrac{p}{2}-1$ as above, we deduce from \cite[Theorem 3.3]{kallenberg_foundations}, that there exists a continuous modification of $(\E^n[\vert X^n_t \vert ^2\; \vert \; \mu^n])_{t \in [0,T]}$.
Then, observe that
\begin{equation*}
    \int_{\R^d} \abs{y}^2 \mu^N_t (dy) = \E^n\quadre{\abs{X^n_t}^2\; \vert \; \mu^n} \quad \forall t \in [0,T] \cap \Q, \; \prob^n\text{-a.s.}
\end{equation*}
Since both processes are almost surely continuous, we can take the supremum over every $t \in [0,T]$ to conclude that
\begin{equation}\label{existence:lemma_tightness:stima_sup}
    \sup_{t \in [0,T]}\int_{\R^d} \abs{y}^2 \mu^N_t (dy) = \sup_{t \in [0,T]} \E^n\quadre{\abs{X^n_t}^2\; \vert \; \mu^n} \leq \E^n\quadre{\sup_{t \in [0,T]} \abs{X^n_t}^2  \; \bigg \vert \; \mu^n }  \quad \prob^n\text{-a.s.}
\end{equation}
We are now ready to show that \eqref{wass:uniforme_integrabilita} holds for $(\rho^n)_{n \geq 1}$: by applying \eqref{existence:lemma_tightness:stima_sup} in the first inequality, Cauchy-Schwartz and Markov inequalities, we have
\begin{equation*}
\begin{aligned}
    & \lim_{r \to \infty} \sup_n \int_{\insieme{m: \; \sup_{t \in [0,T]} \int_{\R^d} \abs{y}^2 m_t(dy) > r}} \sup_{t \in [0,T]} \int_{\R^d} \abs{y}^2 m_t(dy) \rho^n(dm) \\
    & \leq \lim_{r \to \infty} \sup_n \E^n\quadre{ \E^n \quadre{ \norm{X}_{\contrd}^2 \; \vert \; \mu^n } \1_{\insieme{\E^n \quadre{ \norm{X}_{\contrd}^2 \; \vert \; \mu^n } > r}}} \\
    & \leq \lim_{r \to \infty} \frac{1}{r^\frac{1}{2}} \sup_n \E^n\quadre{\norm{X^n}_{\contrd}^{4}}^\frac{1}{2}\E^n\quadre{\norm{X^n}_{\contrd}^{2}}^\frac{1}{2}  \leq \lim_{r \to \infty} C r^{-\frac{1}{2}}=0, 
    \end{aligned}
\end{equation*}
since the suprema over $n \geq 1$ are finite by Lemma \ref{lemma_stima_a_priori}.
\end{proof}


\begin{lemma}\label{existence:lemma_closedness}
$\mathcal{K}$ is closed in $(\mathcal{P}^{2}(\contrd \times \mathcal{V}\times \contpdue),\pwassmetric{2}{\contrd \times \mathcal{V}\times \contpdue}{})$.
\end{lemma}
\begin{proof}
It is enough to prove that, for every sequence $(\Gamma^n)_{n \geq 1}\subseteq \mathcal{K}$ converging to $\Gamma$ as $n \to \infty$ in $\pwassmetric{2}{\contrd \times \mathcal{V} \times \contpdue}{}$, we have $\Gamma \in \mathcal{K}$.
We work on the following canonical space: let $(\overline{\Omega},\overline{\mathcal{G}})$ be given by 
\begin{equation*}
    (\overline{\Omega},\overline{\mathcal{G}})=\tonde{\contrd \times \contpdue \times \mathcal{V} ,\boreliani{\contrd} \otimes \boreliani{\mathcal{V}} \otimes \boreliani{\contpdue}}.
\end{equation*}
We equip such a space with the filtration $\mathbb{G}=(\mathcal{G}_t)_{t \in [0,T]}$ given by
\begin{equation*}
    \mathcal{G}_t=\mathcal{B}_{t,\contrd} \otimes \F_t^{\mathcal{V}} \otimes \boreliani{\contpdue},
\end{equation*}
where $\mathcal{B}_{t,\contrd}=\sigma(\contrd \ni x \mapsto x_s: \; s \leq t)$.
Let $x$, $m$ and $q$ denote the projection from $\overline{\Omega}$ in $\contrd$, $\contpdue$ and $\mathcal{V}$, respectively.
Define the process $w=(w_t)_{t \in [0,T]}$ as
\begin{equation}\label{existence:lemma_closedness:brownian_motion}
    w_t=w_t(x,q,m)=x_t-x_0-\int_0^t\int_A b(s,x_s,m_s,a)q_s(da)ds.
\end{equation}
Observe that $w$ is a continuous process on $(\overline{\Omega},\overline{\F})$ and, by \cite[Corollary A.5]{lacker2015martingale}, for every $t \in [0,T]$ $w_t$ is a continuous with at most linear growth function of $(x,q,m)$.

For every $n\geq 1$, let $\mathfrak{U}^n=((\Omega^n,\F^n,\mathbb{F}^n,\prob^n),\xi^n,W^n,\mu^n,\mathfrak{r}^n)$ and $X^n$ be as in Definition \ref{existence:strategie_max}, so that $\Gamma^n=\prob^n\circ(X^n,\mu^n,\mathfrak{r}^n)^{-1}$.
Since $\Gamma^n \circ (x_0,w,m,q,x)^{-1}=\prob^n\circ(\xi^n,W^n,\mu^n,\mathfrak{r}^n,X^n)^{-1}$, we have that the tuple $\mathfrak{U}^n=((\overline{\Omega},\overline{\F},\overline{\mathbb{F}}^{\Gamma^n},\Gamma^n),x_0,w,m,q)$ satisfies the requirements of Definition \ref{existence:strategie_max}, where $\overline{\mathbb{F}}^{\Gamma^n}$ denotes the $\Gamma^n$-augmentation of the filtration $\mathbb{G}$.
We show that the tuple $\mathfrak{U}=((\overline{\Omega},\overline{\F},\overline{\mathbb{F}}^{\Gamma},\Gamma),x_0,w,m,q)$ satisfies the requirements of Definition \ref{existence:strategie_max}, which implies $\Gamma \in \mathcal{K}$.

We start by the independence property of $w$, $m$ and $q$ under $\Gamma$.
Let $(t^i)_{i=1}^{k} \subseteq [0,T]$, $\varphi^i \in \cbounded{\R^d}$ for $i=1,\dots,n$, $\psi \in \cbounded{\contpdue}$, $\phi \in \cbounded{\R^d}$ be bounded continuous functions.
Since $W^n$, $\mu^n$ and $\xi^n$ are independent under $\prob^n$ and $\Gamma^n \to \Gamma$ weakly, we have
\begin{equation*}
\begin{aligned}
    \E^{\Gamma^n} & \quadre{\prod_{i=1}^k\varphi^i\tonde{w_{t^i}(x,q,m)}\psi(m)\varphi\tonde{x_0}} \\
    & = \E^{\prob^n}\quadre{\prod_{i=1}^k\varphi^i\tonde{W^n_{t^i}}\psi(\mu^n)\varphi\tonde{\xi^n}}= \E^{\prob^n}\quadre{\prod_{i=1}^k\varphi^i\tonde{W^n_{t^i}}}\E^{\prob^n}\quadre{\psi(\mu^n)}\E^{\prob^n}\quadre{\varphi\tonde{\xi^n}}  \\
    & = \E^{\Gamma^n}\quadre{\prod_{i=1}^k\varphi^i\tonde{w_{t^i}(x,q,m)}}\E^{\Gamma^n}\quadre{\psi(m)}\E^{\Gamma^n}\quadre{\varphi\tonde{x_0}}
\end{aligned}
\end{equation*}
where the first equality holds since $w_t(X^n,\mathfrak{r}^n,\mu^n)=W^n_t$ for every $t \in [0,T]$ $\prob^n$-a.s..
Then, since $\phi^i \circ w_{t^i}$ is a continuous function of $(x,q,m)$ for every $i$, weak convergence implies that
\begin{equation}\label{existence:lemma_closedness:convergenze}
\begin{aligned}
    \lim_{n \to \infty} & \E^{\Gamma^n}\quadre{\prod_{i=1}^k\varphi^i\tonde{w_{t^i}(x,q,m)}\psi(m)\varphi\tonde{x_0}} = \E^{\Gamma}\quadre{\prod_{i=1}^k\varphi^i\tonde{w_{t^i}(x,q,m)}\psi(m)\varphi\tonde{x_0}}, \\
    \lim_{n \to \infty} & \E^{\Gamma^n}\quadre{\prod_{i=1}^k\varphi^i\tonde{w^n_{t^i}(x,q,m)}}\E^{\Gamma^n}\quadre{\psi(m)}\E^{\Gamma^n}\quadre{\varphi\tonde{\xi^n}} \\
    & = \E^{\Gamma}\quadre{\prod_{i=1}^k\varphi^i\tonde{w_{t^i}(x,q,m)}}\E^{\Gamma}\quadre{\psi(m)}\E^{\Gamma}\quadre{\varphi\tonde{x_0}}.
\end{aligned}
\end{equation}
This is enough to ensure the mutual independence under $\Gamma$ of $(w_{t^i})_{i=1,\dots,k}$, $x_0$ and $m$ for every $(t^i)_{i=1}^{k}\subset [0,T]$, which yields the independence of $w$, $x_0$ and $m$.
Moreover, by taking $\psi$ and $\phi$ identically equal to $1$, equation
\eqref{existence:lemma_closedness:convergenze} implies that $w$ is natural Brownian motion under $\Gamma$, since the finite dimensional distributions of $w$ coincide with the ones of a Brownian motion. 
Let us verify the independence of increments properties.
Let $s > t$, $\varphi \in \cbounded{\contrd}$ $\mathcal{B}_{t,\contrd}$-measurable, $\chi \in \cbounded{\mathcal{V}}$ $\F_t^{\mathcal{V}}$-measurable, $\psi \in \cbounded{\contpdue}$ and $\phi \in \cbounded{\R^d}$.
Then, we have:
\begin{equation*}
\begin{aligned}
    \E^{\Gamma} & \quadre{\phi\tonde{w_s-w_t}\varphi\tonde{x}\chi\tonde{q}\psi(m)} = \E^{\Gamma}  \quadre{\phi\tonde{w_s(x,q,m)-w_t(x,q,m)}\varphi\tonde{x}\chi\tonde{q}\psi(m)} \\
    & =\lim_{n \to \infty}\E^{\Gamma^n}\quadre{\phi\tonde{w_s(x,q,m)-w_t(x,q,m)}\varphi\tonde{x}\chi\tonde{q}\psi(m)} \\
    & = \lim_{n \to \infty}\E^{\prob^n}\quadre{\phi\tonde{w_s(X^n,\mathfrak{r}^n,\mu^n)-w_t(X^n,\mathfrak{r}^n,\mu^n)}\varphi(X^n)\chi\tonde{\mathfrak{r}^n}\psi(\mu^n)} \\
    & = \lim_{n \to \infty}\E^{\prob^n}\quadre{\phi\tonde{W^n_s-W^n_t}\varphi(X^n)\chi\tonde{\mathfrak{r}^n}\psi(\mu^n)} = 0,
\end{aligned}
\end{equation*}
where the last equality holds since $W^n$ is a $\mathbb{F}^n$-Brownian motion under $\prob^n$, $\mu^n$ is $\F_0^n$-measurable and $X^n$ and $\mathfrak{r}^n$ are both $\mathbb{F}^n$-adapted.
By working with an approximating sequence, this holds also for bounded measurable $\varphi$, $\chi$, $\psi$ and $\phi$, which is enough to conclude the independence of increments.
Finally, since $w$ is $\mathbb{G}$-Brownian motion, it remains so under the $\Gamma$-augmentation of $\mathbb{G}$.

Since $\Gamma^n \circ x_0^{-1}\equiv \nu$, we have that $\Gamma \circ x_0 = \nu$ as well.
Moreover, since $w$ is a $\overline{\mathbb{F}}^{\Gamma}$-Brownian motion and $x$ is $\overline{\mathbb{F}}^{\Gamma}$-adapted by definition of the filtration, equation \eqref{existence:lemma_closedness:brownian_motion} implies that $x$ is a solution to \eqref{existence:eq_processo_K}.

As for the consistency condition, observe that, for every $t \in [0,T]$, $\varphi \in \cbounded{\R^d}$, $\psi \in \cbounded{\contpdue}$, we have 
\begin{align*}
    \E^{\Gamma^n}\quadre{\int_{\R^d}\varphi(y)m_t(dy)\psi(m)} & = \E^{\prob^n}\quadre{\int_{\R^d}\varphi(y)\mu^n_t(dy)\psi(\mu^n)}\\
     &=\E^{\prob^n}\quadre{\E^{\prob^n}\quadre{\varphi(X^n_t)\psi(\mu^n)\; \vert \;  \mu^n}}\\
     & =\E^{\prob^n}\quadre{\varphi(X^n_t)\psi(\mu^n)}= \E^{\Gamma^n}\quadre{\varphi\tonde{x_t}\psi(m)},
\end{align*}
since $\mu^n_t$ is a version of the conditional law under $\prob^n$ of $X^n_t$ given $\mu^n$.
Therefore, by weak convergence we have both
\begin{equation*}
\begin{aligned}
    & \lim_{n \to \infty}\E^{\Gamma^n}\quadre{\varphi\tonde{x_t}\psi(m)} = \E^{\Gamma}\quadre{\varphi\tonde{x_t}\psi(m)}, \\
    & \lim_{n \to \infty}\E^{\Gamma^n}\quadre{\int_{\R^d}\varphi(y)m_t(dy)\psi(m)} = \E^{\Gamma}\quadre{\int_{\R^d}\varphi(y)m_t(dy)\psi(m)}
\end{aligned}
\end{equation*}
where the second limit holds since the function $m \mapsto \int_{\contrd}\varphi(y)m_t(dy) \in \cbounded{\contpdue}$, which implies
\begin{equation*}
    \E^{\Gamma}\quadre{\int_{\R^d}\varphi(y)m_t(dy)\psi(m)}=\E^{\Gamma}\quadre{\varphi\tonde{x_t}\psi(m)}.
\end{equation*}
This is enough to conclude that $m_t = \Gamma(x_t \in \cdot \; \vert \; m)$ $\Gamma$-a.s for every $t \in [0,T]$, since the random element $(x_t,m)$ takes values in a Polish space.
\end{proof}


\begin{lemma}[Convexity]\label{existence:lemma_cvx_strategie}
$\mathcal{K}$ and $\mathcal{Q}$ are convex.
\end{lemma}
\begin{proof}
We start by proving that $\mathcal{K}$ is convex.
Let $\Gamma^i$, $i=1,2$, be in $\mathcal{K}$, and let $\alpha \in (0,1)$.
Let $\mathfrak{U}^i=((\Omega^i,\F^i,\mathbb{F}^i,\prob^i),\xi^i,W^i,\mu^i,\mathfrak{r}^i)$ be as in Definition \ref{existence:strategie_max}, so that $\Gamma^i=\prob^i\circ(X^i,\mathfrak{r}^i,\mu^i)^{-1}$.
Set $\Xi^i=(\xi^i,W^i,\mu^i,\mathfrak{r}^i,X^i)$.
Without loss of generality, we can suppose that the tuples are defined on the same probability space $(\Omega,\F,\mathbb{F},\prob)$ which supports also a Bernoulli random variable $\eta \sim B(\alpha)$, so that $\eta$ and $(\Xi^i)_{i=1,2}$ are mutually independent.
If needed, we can enlarge the filtration so that $\eta$ is $\F_0$-measurable.
Let us consider the following random variables:
\begin{equation}\label{existence:lemma_cvx_strategie:combinazioni_variabili}
    \begin{aligned}
        & \xi^\alpha=\eta\xi^1 + \tonde{1-\eta}\xi^2, && \mu^\alpha=\eta\mu^1 + \tonde{1-\eta}\mu^2, \\
        & W^\alpha=\eta W^1 + \tonde{1-\eta}W^2, \; && \mathfrak{r}^\alpha=\eta \mathfrak{r}^1 + \tonde{1-\eta}\mathfrak{r}^2, \\
        & X^\alpha=\eta X^1 + \tonde{1-\eta}X^2.
    \end{aligned}
\end{equation}
Set $\Xi^\alpha=(\xi^\alpha,W^\alpha,\mu^\alpha,\mathfrak{r}^\alpha,X^\alpha)$ and $\Gamma^\alpha=\prob\circ(X^\alpha,\mathfrak{r}^\alpha,\mu^\alpha)^{-1}$.
Observe that the law of $\Xi^1$ under $\prob$ is the same as the law of $\Xi^\alpha$ conditionally to $\eta=1$, as the two tuples coincide on the set $\{\eta=1\}$, and analogously for $\eta=0$.
Therefore, for every Borel set $B$, we have
\begin{equation}\label{existence:lemma_cvx:combinazione_cvx}
\begin{aligned}
    \prob\tonde{\Xi^\alpha\in B}
    & = \prob\tonde{\Xi^\alpha \in B \big \vert  \eta =1}\prob\tonde{\eta=1} + \prob\tonde{ \Xi^\alpha \in B \big \vert  \eta =0}\prob\tonde{\eta=0} \\
    & = \prob\tonde{ \Xi^1 \in B }\prob\tonde{\eta=1} + \prob\tonde{\Xi^2 \in B }\prob\tonde{\eta=0} \\
    & = \alpha\prob\tonde{ \Xi^1 \in B } + (1-\alpha)\prob\tonde{ \Xi^2 \in B }.
\end{aligned}
\end{equation}
In particular, \eqref{existence:lemma_cvx:combinazione_cvx} implies that $\Gamma^\alpha=\alpha\Gamma^1 + (1-\alpha)\Gamma^2$.
Let us show that the tuple $\Xi^\alpha$ satisfies the requirements of Definition \ref{existence:strategie_max}.
By \eqref{existence:lemma_cvx:combinazione_cvx}, $\xi^\alpha$ has law $\nu$ and $W^\alpha$ is a natural Brownian motion.
To see that it is an $\mathbb{F}$-Brownian motion, let $s<t$, $G \in \F_s$, $B \in \boreliani{\R^d}$: then
\begin{equation*}
\begin{aligned}
    \E\quadre{\1_{B}\tonde{W^\alpha_t-W^\alpha_s}\1_G}  = & \E\quadre{\1_{B}\tonde{W^\alpha_t-W^\alpha_s}\1_G \1_{\insieme{\eta =1}}} + \E\quadre{\1_{B}\tonde{W^\alpha_t-W^\alpha_s}\1_G\1_{\insieme{\eta =0}}} \\
     = &  \E\quadre{\1_B\tonde{\eta \tonde{W^1_t-W^1_s} + \tonde{1-\eta}\tonde{W^2_t-W^2_s} \in B}\1_G\1_{\insieme{\eta =0}}} \\
    & + \E\quadre{\1_B\tonde{\eta \tonde{W^1_t-W^1_s} + \tonde{1-\eta}\tonde{W^2_t-W^2_s} \in B}\1_G\1_{\insieme{\eta =1}} }\\
     = &  \E\quadre{\1_B\tonde{W^1_t-W^1_s}\1_{G \cap\insieme{\eta =1}}} + \E\quadre{\1_B\tonde{W^1_t-W^1_s}\1_{G \cap\insieme{\eta =0}} }= 0,
\end{aligned}
\end{equation*}
since $\eta$ is $\F_0$-measurable by assumption.
As for the mutual independence of $\xi^\alpha$, $\mu^\alpha$ and $W^\alpha$, we have that the joint law factorizes in the product of the marginals: by using \eqref{existence:lemma_cvx:combinazione_cvx}, since $(\xi^i,W^i)_{i=1,2}$ share the same joint law, one gets 
\begin{equation*}
\begin{aligned}
    \prob (\mu^\alpha & \in A, W^\alpha \in B,\xi^\alpha \in C) \\
    = & \alpha\prob(\mu^1 \in A, W^1  \in B, \xi^1 \in C)  + (1-\alpha)\prob(\mu^2 \in A, W^2  \in B, \xi^2 \in C) \\
    = & \alpha\prob(\mu^1 \in A)\prob( W^1  \in B)\prob(\xi^1 \in C)  + (1-\alpha)\prob(\mu^2 \in A)\prob(W^2\in B)\prob(\xi^2 \in C) \\
    = & \left(\alpha\prob(\mu^1 \in A)  +(1-\alpha) \prob(\mu^2 \in A) \right)\wienermeasure(B)\nu(C) = \prob(\mu^\alpha \in A)\prob(W^\alpha\in B)\prob(\xi^\alpha \in C).
\end{aligned}
\end{equation*}
With similar arguments, one can show that for every $t \in [0,T]$, $g:\R^d \to \R$, $f:\contpdue \to \R$ bounded and measurable, it holds
\begin{equation*}
\begin{aligned}
    \E \quadre{ g\tonde{X^\alpha_t} f\tonde{\mu^\alpha}} = \E\quadre{ \int_{\contrd} g\tonde{ y } \mu^\alpha_t (dy) f\tonde{\mu^\alpha}  },
\end{aligned}
\end{equation*}
which implies that $\mu^\alpha_t$ is a version of the conditional distribution of $X^\alpha_t$ given $\mu^\alpha$.
Finally, consider the set
\begin{equation*}
    \Omega^1=\insieme{X^1_t = \xi^1 + \int_0^t \int_A b(s,X^1_s,\mu^1_s,a)\mathfrak{r}^1_s(da)ds + W^1_t \;\; \forall t \in [0,T]}\cap \insieme{\eta=1},
\end{equation*}
and define analogously $\Omega^2$.
We have that $\Omega^1 \cap \Omega^2 = \emptyset$ and $\prob(\Omega^1)=\alpha$, since $X^1$ satisfies the equation above $\prob$-a.s., and analogously $\prob(\Omega^2)=1-\alpha$, so that $\prob(\Omega^1 \cup \Omega^2)=1$.
On such a set, $X^\alpha$ satisfies the equation
\begin{equation*}
    X^\alpha_t = \xi^\alpha + \int_0^t \int_A b(s,X^\alpha_s,\mu^\alpha_s,a)\mathfrak{r}^\alpha_s(da)ds + W^\alpha_t, \; t \in [0,T].
\end{equation*}
Since $X^\alpha$ is $\mathbb{F}$-adapted, $X^\alpha$ is a solution to equation \eqref{existence:eq_processo_K}, which concludes this part of the proof.

\medskip
Let us turn to the convexity of the set $\mathcal{Q}$. Let $\Sigma^i$, $i=1,2$, be in $\mathcal{Q}$, and $\alpha \in (0,1)$.
Let $\mathfrak{U}^i=((\Omega^i,\F^i,\mathbb{F}^i,\prob^i)$, $\xi^i,W^i,\mathfrak{r}^i)$ be as in Definition \ref{existence:strategie_min} so that $\Sigma^i(\cdot,m)=\prob^i((X^{m,i},\mathfrak{r}^i)\in \cdot )$, where $X^{m,i}$ is the solution to equation \eqref{existence:eq_processo_Q} on $(\Omega^i,\F^i,\mathbb{F}^i,\prob^i)$ when $b$ is evaluated at $m \in \contpdue$.
Let $\Theta^i=\prob^i\circ(\xi^i,W^i,\mathfrak{r}^i)^{-1}$, and consider the maps $\mathcal{I}_{\Theta^i}$ defined by 
\begin{equation}
\begin{aligned}
    \mathcal{I}_{\Theta^i}: \contpdue  & \longrightarrow \mathcal{P}(\R^d \times \contrd \times \contrd \times \mathcal{V}) \\
    m & \longmapsto \mathcal{I}_{\Theta^i}(m)=\prob^i\circ(\xi^i,W^i,X^{m,i},\mathfrak{r}^i)^{-1}.
\end{aligned}
\end{equation}
Similarly as for the set $\mathcal{K}$, suppose that the tuples are defined on the same probability space $(\Omega,\F,\mathbb{F},\prob)$ supporting also a Bernoulli random variable $\eta \sim B(\alpha)$, so that $\eta$ and $(\xi^i,W^i,\mathfrak{r}^i)_{i=1,2}$ are mutually independent.
If needed, we can enlarge the filtration so that $\eta$ is $\F_0$-measurable.
Let $\xi^\alpha$, $W^\alpha$ and $\mathfrak{r}^\alpha$ be as in \eqref{existence:lemma_cvx_strategie:combinazioni_variabili}, and, for every $m \in \contpdue$, define
\begin{equation*}
    \begin{aligned}
        X^{\alpha,m}=\eta X^{1,m} + \tonde{1-\eta}X^{2,m}.
    \end{aligned}
\end{equation*}
Let $\Theta^\alpha=\prob^\alpha \circ ( \xi^\alpha,W^\alpha,\mathfrak{r}^\alpha)^{-1}$ and consider the map $\mathcal{I}_{\Theta^\alpha}$, defined analogously to above.
By point \ref{existence:lemma_kernels:kernel_ben_definito} of Lemma \ref{existence:lemma_kernels}, it induces a stochastic kernel $\Sigma^\alpha \in \mathcal{Q}$.
By working in the same way as in the case of $\mathcal{K}$, we can show that 
$\mathcal{I}_{\Theta^\alpha}(m) = \alpha\mathcal{I}_{\Theta^1}(m) + (1-\alpha)\mathcal{I}_{\Theta^2}(m)$ for each $m \in \contpdue$, which implies that $\Sigma^\alpha=\alpha \Sigma^1 + (1-\alpha)\Sigma^2 \in \mathcal{Q}$.
\end{proof}

\begin{prop}\label{existence:prop_payoff_continuo}
The map $\mathcal{K} \times \mathcal{Q} \ni (\Gamma,\Sigma) \mapsto \mathfrak{p}(\Gamma,\Sigma)$ is bilinear.
Moreover, $\mathcal{K} \ni \Gamma \mapsto \mathfrak{p}(\Gamma,\Sigma)$ is continuous for every $\Sigma \in \mathcal{Q}$.
\end{prop}
\begin{proof}
Bilinearity is clear, hence we focus on the continuity of $\mathfrak{p}(\cdot,\Sigma)$ for fixed $\Sigma$.
Take $(\Gamma^n)_{n\geq 1}$, $\Gamma$ in $\mathcal{K}$ and suppose $\Gamma^n \to \Gamma$ in the 2-Wasserstein distance.
We treat separately the term depending just upon $\Gamma \in \mathcal{K}$ and the term depending also upon $\Sigma \in \mathcal{Q}$ in \eqref{existence:payoff_functional}.

\medskip
By Proposition \ref{wass:equivalenze_convergenza}, $\Gamma^n \to \Gamma$ in 2-Wasserstein metrics if and only if
\begin{equation}
\int_{\contrd \times\mathcal{V} \times \contpdue}\psi(y,q,m)\Gamma^n(dy,dq,dm) \to \int_{\contrd \times\mathcal{V} \times \contpdue}\psi(y,q,m)\Gamma(dy,dq,dm),
\end{equation}
for every $\psi$ continuous with at most quadratic growth, hence we just need to show that the functional $\mathfrak{F}$ defined in \eqref{existence:funzione_f} is continuous with at most quadratic growth.
By Assumptions \ref{standing_assumptions} and \cite[Corollary A.5]{lacker2015martingale}, we have that $\mathfrak{F}(y,q,m)$ is continuous.
It is straightforward to verify that $\mathfrak{F}$ has at most quadratic growth, in the sense that
\begin{equation*}
    \mathfrak{F}(y,q,m) \leq C\tonde{1 + \norm{y}_{\contrd}^2 + \sup_{t \in [0,T]} \int_{\R^d} \abs{y}^2 m_t(dy) + \int_0^T \int_A \abs{a-a_0}^2 q_s(da)ds }.
\end{equation*}
Therefore, we get continuity of the term depending only upon $\Gamma$.

\medskip
Denote by $\rho^n$ and $\rho$ the marginal of $\Gamma^n$ and $\Gamma$ on $\contpdue$.
We can manipulate the term depending both upon $\Gamma$ and $\Sigma$ as
\begin{equation*}
    \begin{aligned}
        & \int_{\contrd\times \mathcal{V}\times \contpdue}  \mathfrak{F} (y,q,m) \Sigma(dy,dq,m)\rho(dm) \\
        & \: = \int_{\contpdue}\tonde{\int_{\contrd\times \mathcal{V}} \mathfrak{F} (y,q,m) \Sigma(dy,dq,m)}\rho(dm)= \int_{\contpdue} g(m)\rho(dm)
\end{aligned}
\end{equation*}
where we set
\begin{equation*}
    g(m)=\int_{\contrd\times \mathcal{V}} \mathfrak{F} (y,q,m) \Sigma(dy,dq,m).
\end{equation*}
We must show that $g: \contpdue\to\R$ is continuous with at most quadratic growth with respect to the 2-Wasserstein distance.
As for the growth condition, estimate \eqref{existence:lemma_continuita:bound_uniformi} in Lemma \ref{existence:lemma_kernels} proves that $g$ has at most quadratic growth in $m \in \contpdue$.
As for the continuity, let $(m^n)_{n \geq 1},m \in \contpdue$ so that $m^n \to m$ in $\pwassmetric{2}{\contrd}{}$.
Note that $\Sigma(dy,dq,m^n) \to \Sigma(dy,dq,m)$ in $\pwassmetric{2}{\contrd \times \mathcal{V}}{}$, as implied by Lemma \ref{existence:lemma_kernels}.
Define $\phi^n(y,q)=\mathfrak{F}(y,q,m^n)$.
Since the cost functions are locally Lipschitz, we have that $\phi^n$ converges to $\phi$ uniformly on bounded sets of $\contrd \times \mathcal{V}$.
This is enough to conclude that
\begin{equation*}
    g(m^n)=\int_{\contrd\times \mathcal{V}} \phi^n (y,q) \Sigma(dy,dq,m^n) \to \int_{\contrd\times \mathcal{V}} \phi (y,q) \Sigma(dy,dq,m)=g (m) \quad \text{ as } m^n \to m.
\end{equation*}
\end{proof}

We can now prove points \ref{existence:thm_esistenza_strategia_ottima:existence_value} and \ref{existence:thm_esistenza_strategia_ottima:optimal_strategy} of Theorem \ref{existence:thm_esistenza_strategia_ottima}: take $X=\mathcal{K}$, $Y=\mathcal{Q}$ and $f(x,y)=\mathfrak{p}(\Gamma,\Sigma)$ in the statement of Theorem \ref{thm_minimax}.
By Lemmata \ref{existence:lemma_tightness} and \ref{existence:lemma_closedness}, $\mathcal{K}$ is compact with the topology of convergence in 2-Wasserstein distance and both sets $\mathcal{K}$ and $\mathcal{Q}$ are convex by Lemma \ref{existence:lemma_cvx_strategie}.
By Proposition \ref{existence:prop_payoff_continuo}, the payoff $\mathfrak{p}$ is both concave and continuous in $\Gamma$ for every fixed $\Sigma \in \mathcal{Q}$ and convex in $\Sigma$ for every fixed $\Gamma$.
Therefore, Theorem \ref{thm_minimax} yields the existence of both the value $v$ of the auxiliary zero-sum game and an optimal strategy for player A. 
The next proposition proves point \ref{existence:thm_esistenza_strategia_ottima:positive_value}, concluding the proof of Theorem \ref{existence:thm_esistenza_strategia_ottima}.

\begin{prop}[Positivity of the value of the auxiliary zero-sum game]\label{existence:prop_positive_value}
Let $v$ be the value of the zero-sum game defined in Definition \ref{existence:def_zerosum} has a value $v$.
Then $v \geq 0$.
\end{prop}
\begin{proof}
We show that, for every $\Sigma \in \mathcal{Q}$ there exists a strategy $\Gamma_{\Sigma} \in \mathcal{K}$ so that $\mathfrak{p}(\Gamma_{\Sigma},\Sigma)=0$.
Fix $\Sigma \in \mathcal{Q}$, let $\mathfrak{U}=((\Omega,\F,\mathbb{F},\prob),\xi,W,\mathfrak{b})$ be a tuple as in Definition \ref{existence:strategie_min} so that $\Sigma(\cdot,m)=\prob((X^m,\mathfrak{b})\in\cdot)$, for every $m \in \contpdue$.
On this probability space, consider the following stochastic differential equation of McKean-Vlasov type:
\begin{equation}\label{existence:positivity_MKV_SDE}
   \begin{cases}
   dY_t=\int_A b(t,Y_t,p_t,a)\mathfrak{b}_t(da)dt + dW_t, \; t \in [0,T], \quad Y_0=\xi; \\
   \mathcal{L}(Y_t)=p_t, \: t \in [0,T], \quad p=(p_t)_{t \in [0,T]} \in \contpdue.
   \end{cases}
\end{equation}
Under Assumptions \ref{standing_assumptions}, there exists a unique pair $(Y,p)$ satisfying \eqref{existence:positivity_MKV_SDE}, where $Y=(Y_t)_{t \in [0,T]}$ is an $\mathbb{F}$-adapted continuous process so that $\E[\sup_{t \in [0,T]}\vert Y_t \vert ^2]<\infty$, as ensured by, e.g., \cite[Theorem 4.21]{librone_vol1}, which implies that $p$ actually belongs to $\contpdue$.
Define the deterministic flow of measures $\mu$ by setting $\mu=p$.
Define $\Gamma_{\Sigma}$ as $\prob\circ(Y,\mu,\mathfrak{b})^{-1}$.
Since $\mu=p$ is deterministic and $(Y,p)$ is a solution to \eqref{existence:positivity_MKV_SDE}, $\mu$ is $\F_0$-measurable and independent of $\xi$ and $W$, and consistency condition holds trivially.
This implies that $\Gamma_{\Sigma}$ belongs to $\mathcal{K}$.
By writing the integrals in $\mathfrak{p}$ as expectations, we have:
\begin{equation*}
\begin{aligned}
    \mathfrak{p}& (\Gamma_{\Sigma},\Sigma) =  \int_{\contrd\times \mathcal{V}\times \contpdue}  \mathfrak{F} (y,q,m) \Sigma(dy,dq,m)\rho_{\Sigma}(dm) - \int_{\contrd\times \mathcal{V}\times \contpdue} \mathfrak{F} (y,q,m)  \Gamma_{\Sigma}(dy,dq,dm) \\
    & =  \attesa{\int_0^T \int_A f(t,Y_t,p_t,a)\mathfrak{b}_t(da)dt + g(Y_T,p_T)} - \attesa{\int_0^T \int_A f(t,Y_t,p_t,a)\mathfrak{b}_t(da)dt + g(Y_T,p_T)} \\
    & = 0,
\end{aligned}
\end{equation*}
where $\rho_{\Sigma}(\cdot)=\delta_{p}(\cdot)$ denotes the marginal law of $\Gamma_{\Sigma}$ on $\contpdue$.
Since such a construction holds for every $\Sigma \in \mathcal{Q}$, we have 
\begin{equation*}
    \sup_{ \Gamma \in \mathcal{K}} \mathfrak{p}(\Gamma,\Sigma)  \geq \mathfrak{p}(\Gamma_{\Sigma},\Sigma) = 0 \quad \forall \Sigma \in \mathcal{Q}.
\end{equation*}
Taking the infimum with respect to $\Sigma \in \mathcal{Q}$,  we have 
\begin{equation*}
    \inf_{\Sigma \in \mathcal{Q}} \sup_{ \Gamma \in \mathcal{K}} \mathfrak{p}(\Gamma,\Sigma)  \geq \mathfrak{p}(\Gamma_{\Sigma},\Sigma)  \geq 0,
\end{equation*}
which shows that $v^B$ is non-negative.
Since $v^A=v^B=v$, this proves that the value of the auxiliary zero-sum game is non-negative.
\end{proof}