\section{Quantitative Results}
\subsection{Image Quality}\label{sec:im_qual}
At rendering, the image quality achieved by \methodname depends on the amount of texels,~\ie~pixels in the texture map, assigned to each triangle in the mesh.
Here, we report the effect that this variable has on image quality.
For assessing image quality, we measure the standard quality metrics~(PSNR, SSIM~\cite{SSIM} and LPIPS~\cite{LPIPS}) on both datasets~(\textit{Realistic Synthetic 360°} and \textit{360° Unbounded Tanks and Temples}).
% We compute standard measures of image quality for each scene and various texels numbers from \methodname. 
Here we report disaggregate per-scene measures of PSNR (\Table{PSNRsyn} and \Table{PSNRreal}), SSIM (\Table{SSIMsyn} and \Table{SSIMreal}), and LPIPS (\Table{LPIPSsyn} and \Table{LPIPSreal}) for \methodname.
% \sara{TODO}

The traditional configuration of texels is equally-sized triangles in a texture map.
Thus, the number of texels (\ie the column ``$\:\text{Tex.}$'' in Tables~\ref{tab:PSNRsyn}-\ref{tab:LPIPSreal}) increases quadratically w.r.t. the triangle's side.
Formally, \#$\:\text{Tex.} = \lceil\nicefrac{p^2}{2}\rceil$, where $p$ is the number of pixels in the triangle's side.

Naturally, across all metrics and datasets, image quality improves as the number of texels increases.
% For the Realistic Synthetic 360° dataset, the performance of \methodname can be improved by increasing the default number of texels from $13$ to $72$ for PSNR ($27.16 \to 27.62$), SSIM ($0.911 \to 0.917$), and LPIPS ($0.104 \to 0.089$).
% However, increasing the number of texels per triangle from $13$ to $72$, improves these metrics, correspondingly, to $27.62$, $0.917$, and $0.089$.
% Analogously, for the 360° Unbounded Tanks and Temples dataset, using the $72$ texels per triangle instead of the default $13$ improves PSNR ($17.78 \to 18.04$), SSIM ($0.521 \to 0.549$) and LPIPS ($0.523 \to 0.508$).
We find that \methodname provides competitive performance when using $18$ texels per triangle.
However, while performance improves by increasing the number of texels, the quadratic growth of texels makes performance gains rapidly reach diminishing returns.

\input{supplmat/imgs/composition.tex}
\input{supplmat/imgs/many_objects.tex}

\input{supplmat/tables/PSNR_syn.tex}
\input{supplmat/tables/PSNR_real.tex}
\input{supplmat/tables/SSIM_syn.tex}
\input{supplmat/tables/SSIM_real.tex}
\input{supplmat/tables/LPIPS_syn.tex}
\input{supplmat/tables/LPIPS_real.tex}
\input{supplmat/tables/FPS.tex}
\input{supplmat/tables/mesh.tex}
\input{supplmat/tables/Disk_syn.tex}
\input{supplmat/tables/Disk_real.tex}

\subsection{Rendering Speed} \label{sec:fps}

We report the disaggregated rendering speeds achieved by \methodname, measured in frames per second (FPS), in \Table{disaggregated_fps}.
For the Realistic Synthetic 360° dataset, \methodname attains an average speed of over 54 FPS even on a Samsung~S21.
% Notably, for both datasets, our method reaches the iPhone 12's limit of 60 FPS for all scenes.

% \sara{TODO}

\subsection{Mesh Size} \label{sec:mesh_size}
Table~4 in the main paper reports the average size (number of vertices and triangle faces) of the meshes used by \methodname.
We report the per-scene mesh sizes in \Table{mesh} for both datasets we experimented with. % , we report the number of vertices and triangle faces for meshes used by \methodname.
Overall, for the Realistic Synthetic 360° dataset (left columns), \methodname uses, on average, fewer than 205k faces and 99k vertices.
For the 360° Unbounded Tanks and Temples dataset, these numbers correspond to 250k faces and 120k vertices.
As such, these meshes are decidedly not particularly precise, and thus serve mostly as a collision mesh for \methodname to estimate where the scene's geometry is.

\subsection{Disk Space}\label{sec:disk_space}
The number of texels assigned to each triangle in the mesh affects the disk space used for representing a scene.
We vary the number of texels, and report the disk space used for each scene in \Table{Disksyn}~(for Realistic Synthetic 360°) and \Table{Diskreal}~(for 360° Unbounded Tanks and Temples).

For the Realistic Synthetic 360° dataset, \methodname's default of $18$ texels implies using an average disk space of $198.8$ MB.
Furthermore, all the objects (except ficus, lego and ship), use fewer than $200$ MB.
On the other hand, for the 360° Unbounded Tanks and Temples dataset, the default of $18$ texels makes all scenes use a disk space between $270$ and $310$ MB.
% \sara{TODO}

\input{supplmat/imgs/dim.tex}
% \sara{TODO}
\section{Qualitative Results}

\subsection{Image Quality}\label{sec:quali}
\input{supplmat/imgs/qualitative}
In \Figure{qlsyn}, and \Figure{qlsyn1}, we present the qualitative results obtained on a synthetic dataset. The images in the first column represent the ground truth (GT) data. In the second column, we show the results obtained using Re-ReND with quad size 72 and 32 components. Finally, in the third column, we display the results obtained using Re-ReND with quad size 18 and 32 components.

Upon visual inspection, we observe that Re-ReND with quad size 72 and 32 components produces more accurate and visually appealing results compared to Re-ReND with quad size 18 and 32 components. The former shows greater detail and smoother transitions between the different regions of the scene. However, Re-ReND with quad size 18 and 32 components still manages to produce decent results.

In addition to the synthetic dataset, we also present qualitative results on a real 360 dataset [See \Figure{qlsyn2}]. The images in the first column represent the ground truth (GT) data. In the second column, Re-ReND before discretization, while in the third column, Re-ReND with quad size 18 and 32 components.

It is worth noting that these qualitative results are obtained on a real 360 dataset, which presents more challenges compared to the synthetic dataset. The real-world scenario involves more complex lighting conditions, occlusions, and variations in scene geometry. 

\subsection{Meshes}\label{sec:meshes}\label{sec:meshi}
\input{supplmat/imgs/meshes.tex}
In \Figure{meshes}, we report the meshes we use in \methodname for both datasets.
All our meshes are simple and smooth.
Note that, for the 360° Unbounded Tanks and Temples dataset (last row in \Figure{meshes}), the scene is encapsulated within a semi-sphere and a plane mimicking the floor.

 \section{Validation of view-dependent effects}\label{sec:val}
 
 To validate the effect of view direction, we conducted an experiment comparing the performance of Re-ReND to a simple RGB textured mesh representation as a baseline. Due to the lack of ground truth RGB textures, we created a texture by assigning colors based on the intersected face's normal of a pretrained \methodname. The results showed that on both the Synthetic and Unbounded T\&T datasets, the RGB textured mesh PSNR was lower compared to Re-ReND. Specifically, the PSNR values were 22.82 dB and 14.79 dB for the RGB textured mesh representation, compared to Re-ReND's 29.00 dB and 17.77 dB, respectively.

This significant performance drop highlights the critical importance of modeling view-dependent effects for achieving high-quality image reconstruction. The Re-ReND approach, which takes into account view-dependent effects, was able to produce more accurate and visually appealing results than the simple RGB textured mesh representation. This finding suggests that the Re-ReND method is effective in modeling view-dependent effects and can lead to improved image reconstruction results.

 \section{Sensitivity to geometry variations}\label{sec:geo}
We conduct an experiment to evaluate the sensitivity of a Re-ReND to geometry quality. To do so, we use the ground truth meshes of the synthetic dataset to train Re-ReND, and we compared two sets of results: one using perfect geometry, and another using "cheap" meshes by marching cubes.

The results were then evaluated using three metrics before discretization: PSNR, SSIM, and LPIPS. The results for the perfect geometry case were 31.10, 0.954, and 0.0535 for PSNR, SSIM, and LPIPS, respectively. For the cheap mesh case, the results were 30.73, 0.946, and 0.0562 for the same metrics.

Analyzing the results, it appears that the Re-ReND is sensitive to geometry quality, as the results for the perfect geometry case were consistently better across all three metrics. This suggests that the method performs better when it has access to high-quality geometry information. However, even when using cheaper meshes, the Re-ReND method can still perform reasonably well. For example, the PSNR values were only slightly different between the perfect and cheap mesh cases, and the difference in LPIPS and SSIM values was within a reasonable range. This suggests that the Re-ReND method can perform very well without losing too much quality, even when the geometry information is not perfect.

 \section{Photo-metric quality depending on the dimensionality D}\label{sec:dim}
In \Figure{dim}, we report Re-ReND’s results for various dimensionalities of embedding. The dimensionality of the embedding is an important factor that can affect the performance of the model in various ways. On one hand, a higher dimensional embedding can potentially capture more complex textures and materials, leading to better PSNR. On the other hand, a higher dimensional embedding may also require more memory usage, making it slower and not apt for certain devices.

In practice, the choice of embedding dimensionality is often a trade-off between quality and efficiency, and depends on the specific requirements and constraints of the application. For example, in low-constraint devices, a lower dimensional embedding may be sufficient to achieve good performance, while for desktop, a higher dimensional embedding may be necessary to obtain better results in 8K resolution.
