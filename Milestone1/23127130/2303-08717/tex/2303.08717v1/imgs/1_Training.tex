\begin{figure*}[t!]
    % \centering
    % \includegraphics[width=\linewidth]{imgs/1_Training.png}
    \includegraphics[width=\linewidth]{imgs/1_Training3.png}
    \vspace{-0.4cm}
    \caption{
    \textbf{Training \methodname.} 
    \textbf{a)} Starting with a pre-trained NeRF, we extract a polygonal mesh and generate pseudo-images to train our factorized NeLF. 
    % These images correspond to outputs of rendering light fields of rays intersecting mesh points. 
    These images are generated by rendering the NeRF from various points of view.
    \textbf{b)} Our factorized NeLF consists of two MLPs ($L_\text{pos}$ and $L_\text{dir}$) that \textit{independently} compute position and direction embeddings. 
    $L_\text{pos}$ outputs position-dependent deep radiance embeddings $(\mathbf{u}, \mathbf{v}, \mathbf{w})$ for points \textit{on} the mesh's surface, while $L_\text{dir}$ outputs direction-dependent embeddings ($\boldsymbol\beta$). %  that weigh  those components. % given a ray direction as input. 
    % \sara{change Gpos and Gdir}
    Since this representation is amenable to ``baking'',~\ie~pre-computing and storing outputs, it allows us to dispose of MLPs for deployment. 
    \textbf{c)}~Under this formulation, computing pixel color amounts to a dot product of $(\mathbf{u}, \mathbf{v}, \mathbf{w})$ and $\boldsymbol\beta$. 
    \textbf{d)}~We optimize our framework with an MSE reconstruction loss w.r.t. to the pseudo-images we extracted from the pre-trained NeRF.
    % We (a) generate pseudo images and a polygonal mesh representation of an object or scene from a pretrained NeRF.
    % To train our network, we use all intersected points along rays on the mesh from all points of view.
    % In (b), the position-dependent network $G_{pos}$ outputs a deep radiance map $(u, v, w)$ consisting of $D$ components, while the $G_{dir}$ outputs the weights for those components $(\beta_1, ..., \beta_D)$ given a ray direction as input.
    % The network parameters can then be (c) optimized using the standard MSE reconstruction loss relative to the pseudo images. \sara{TODO}
    }
    \vspace{-0.5cm}
    \label{fig:Training}
\end{figure*}