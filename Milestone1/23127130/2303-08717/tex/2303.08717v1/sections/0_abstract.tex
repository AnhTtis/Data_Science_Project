% In this paper, we address the problem of rendering a trained NeRF in real-time on resource-constrained devices.
This paper proposes a novel approach for rendering a pre-trained Neural Radiance Field (NeRF) in real-time on resource-constrained devices.
We introduce \textbf{\methodname}, a method enabling \underline{Re}al-time \underline{Re}ndering of \underline{N}eRFs across \underline{D}evices. 
% \methodname achieves real-time performance by transforming a pre-trained NeRF into a representation that trivially runs on standard graphics pipelines. 
\methodname is designed to achieve real-time performance by converting the NeRF into a representation that can be efficiently processed by standard graphics pipelines.
% Specifically, our method distills the NeRF by extracting the learned density into a mesh, and the learned color information into a set of matrices that factorize the sceneâ€™s light field.
The proposed method distills the NeRF by extracting the learned density into a mesh, while the learned color information is factorized into a set of matrices that represent the scene's light field.
% Our usage of light fields results in computing pixel color with a single query---as opposed to hundreds when conducting volume rendering of NeRF---while the factorization implies that queries amount to inexpensive MLP-free matrix multiplications. 
Factorization implies the field is queried via inexpensive MLP-free matrix multiplications, while using a light field allows rendering a pixel by querying the field a single time---as opposed to hundreds of queries when employing a radiance field.
% We deploy our pipeline within a fragment shader compatible with standard rasterization frameworks.
% Since rendering our representation can be implemented with a fragment shader, our pipeline is directly compatible with standard rasterization frameworks.
Since the proposed representation can be implemented using a fragment shader, it can be directly integrated with standard rasterization frameworks.
% Our flexible implementation can thus render a NeRF in real-time at low memory costs in a wide variety of resource-constrained devices, including mobile phones and even AR/VR headsets. 
Our flexible implementation can render a NeRF in real-time with low memory requirements and on a wide range of resource-constrained devices, including mobiles and AR/VR headsets.
% Notably, we find that \methodname achieves over a $4\times$ boost in rendering speed without significant drops in quality. 
Notably, we find that \methodname can achieve over a 2.6-fold increase in rendering speed versus the state-of-the-art without perceptible losses in quality.
