
\section{Problem Formulation}
\label{sec:formulation}
Given a pre-trained NeRF, we aim at rendering it in real time on a variety of resource-constrained devices.
Our goal is to transform said NeRF into a representation that runs on standard mesh-rasterization pipelines.
% We opt for accelerating rendering by leveraging mesh-rasterization pipelines.
A NeRF is a function $R$ (parameterized by an MLP), which maps from a 3D location $\mathbf{p}$ and a 2D viewing direction $\mathbf{d}$ to an RGB emitted color $\mathbf{c}$ and volume density $\sigma$.
Formally, a NeRF implements $R~:~(\mathbf{p},\mathbf{d})~\mapsto~(\mathbf{c},\sigma)$.
To render a pixel, NeRF follows the classical volume rendering formulation.
In this formulation, the color assigned to a pixel with associated camera ray $\mathbf{r}(t) = \mathbf{o} + t\:\mathbf{d}$ is given by:
\begin{equation}\label{eq:color}
C(\mathbf{r}) = \int_{t_n}^{t_f}T(t)\:\sigma\left(\mathbf{r}(t)\right)\:\mathbf{c}(\mathbf{r}(t), \mathbf{d})\:\mathrm{d}t,
\end{equation}
where $T(t) = \exp\left(-\int_{t_n}^{t}\sigma\left(\mathbf{r}(s)\right)\:\mathrm{d}s\right)$ represents the transmittance accumulated along $\mathbf{r}$.

To reach our goal of real-time rendering of NeRFs in resource-constrained devices,
% mesh-rasterization pipelines, 
we must address the following three limitations of NeRFs:
% Further aggravating these issues, NeRFs are incompatible with widely-deployed graphics pipelines.
\textit{(i)}~their implicit nature % $C$ % (opposed to explicit representations such as voxelized scalar fields, points clouds or textured meshes) 
conflicts with the explicit representations demanded by mesh-rasterization pipelines, which request a mesh $\chi$ and a texture map $\mathbf{M}$, %  that demand inputs in the form of an explicit representation $\mathcal{R} = \{\chi,\mathcal{T}\}$, consisting of a mesh $\chi$ and a set~$\mathcal{T}$ of texture maps,
% The incompatibility stems from NeRFs' implicit representation of color $C$: in contrast to explicit representations (\eg voxelized scalar fields, points clouds, or textured meshes), NeRFs indirectly represent color and geometry as integrals over $F_\Theta$.
% This indirect representation conflicts with mesh-rasterization pipelines, which demand as input an explicit representation $\mathcal{R}$ consisting of a mesh $\chi$ and a set of texture maps~$\mathcal{T}$, that is, $\mathcal{R} = \{\chi,\mathcal{T}\}$. % , as these are efficiently rendered via mesh-rasterization.
% a pixel with NeRFs' formulation is expensive mainly because of two reasons: 
\textit{(ii)}~they compute color via Eq.~\eqref{eq:color}, thus requiring expensive numerical estimation of the integral, and % by sampling the ray $\mathbf{r}$, and 
\textit{(iii)}~computing the individual integrands for this estimate requires evaluating the MLP that parameterizes $R$.

% To enable real-time rendering of a pre-trained NeRF $F_\Theta$ on resource-constrained devices, 
We seek a method that transforms $R$'s knowledge into an alternative representation that circumvents these three limitations of NeRFs. 
That is, we require the method to output a rasterization-friendly representation,
to compute pixel color with a single query, 
and to entirely dispose of MLPs for modeling view-dependent effects.
Moreover, we require the method to effectively work on a wide variety of NeRFs.
% A solution complying with all these requirements would enjoy reduced computation across many dimensions, and should thus achieve high rendering speeds.
% address these issues \albert{at least say that this is explained in next section}
\vspace{-0.6cm}
\begin{comment}
We formulate this problem by tracing its roots to three properties of NeRFs:
% We achieve this end goal by organizing it into three objectives:
\textit{(i)}~they are incompatible with widely-used efficient graphics pipelines,
\textit{(ii)}~they query hundred of points across space to obtain a pixel's color, and
\textit{(iii)}~they require evaluating an expensive MLP for each spatial query.

Issue \textit{(i)}~stems from how NeRFs' representation of objects is inherently unfriendly to graphics pipelines, as these pipelines expect inputs following a mesh-texture map configuration. % for cross-device fast rendering across devices are implemented to work efficiently on .
Issue \textit{(ii)}~is a direct outcome of NeRFs' volumetric rendering, whereby radiance must be integrated along a camera ray to obtain the ray's color.
Finally, issue \textit{(iii)}~is the consequence of how NeRFs account for view-dependent effects with an MLP.


The NeLF is ``temporal''? ``temporary''?


Objective number \textit{(i)} can be achieved by transforming the scene learnt by the NeRF into a representation that is compatible with standard graphics pipelines.
In particular, we aim at modeling the scene in a mesh-texture map configuration, whereby the texture maps are filled with information capable of accounting for the scene's view-dependent effects.
Objective number \textit{(ii)} can be attained by disposing of NeRFs' 
\end{comment}


