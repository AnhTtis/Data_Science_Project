@inproceedings{adv2random,
  author    = {Fawzi, Alhussein and Moosavi-Dezfooli, Seyed-Mohsen and Frossard, Pascal},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Robustness of classifiers: from adversarial to random noise},
  url       = {https://proceedings.neurips.cc/paper/2016/file/7ce3284b743aefde80ffd9aec500e085-Paper.pdf},
  volume    = {29},
  year      = {2016}
}

@inproceedings{AdvColor,
  author    = {Zhengyu Zhao and Zhuoran Liu and Martha A. Larson},
  title     = {Adversarial Color Enhancement: Generating Unrestricted Adversarial Images by Optimizing a Color Filter},
  year      = {2020},
  cdate     = {1577836800000},
  url       = {https://www.bmvc2020-conference.com/assets/papers/0099.pdf},
  booktitle = {BMVC}
}


@inproceedings{bartlettAdversarialExamplesMultiLayer2021,
  title     = {Adversarial {{Examples}} in {{Multi-Layer Random ReLU Networks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author    = {Bartlett, Peter and Bubeck, Sebastien and Cherapanamjeri, Yeshwanth},
  year      = {2021},
  volume    = {34},
  pages     = {9241--9252},
  publisher = {{Curran Associates, Inc.}},
  }

@inproceedings{bubeckSingleGradientStep2021,
  title     = {A Single Gradient Step Finds Adversarial Examples on Random Two-Layers Neural Networks},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author    = {Bubeck, Sebastien and Cherapanamjeri, Yeshwanth and Gidel, Gauthier and {Tachet des Combes}, Remi},
  year      = {2021},
  volume    = {34},
  pages     = {10081--10091},
  publisher = {{Curran Associates, Inc.}},
  }

@article{classrobust,
  author    = {Alhussein Fawzi and
               Omar Fawzi and
               Pascal Frossard},
  title     = {Analysis of classifiers' robustness to adversarial perturbations},
  journal   = {Mach. Learn.},
  volume    = {107},
  number    = {3},
  pages     = {481--508},
  year      = {2018},
  url       = {https://doi.org/10.1007/s10994-017-5663-3},
  doi       = {10.1007/s10994-017-5663-3},
  timestamp = {Mon, 02 Mar 2020 16:28:44 +0100},
  biburl    = {https://dblp.org/rec/journals/ml/FawziFF18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{cubukIntriguingPropertiesAdversarial2017,
  title         = {Intriguing {{Properties}} of {{Adversarial Examples}}},
  author        = {Cubuk, Ekin D. and Zoph, Barret and Schoenholz, Samuel S. and Le, Quoc V.},
  year          = {2017},
  month         = nov,
  number        = {arXiv:1711.02846},
  eprint        = {1711.02846},
  eprinttype    = {arxiv},
  primaryclass  = {cs, stat},
  institution   = {{arXiv}},
    archiveprefix = {arXiv},
  keywords      = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file          = {/Users/godf974/OneDrive - PNNL/Documents/Papers/Gumby/Cubuk et al_2017_Intriguing Properties of Adversarial Examples.pdf;/Users/godf974/Zotero/storage/L9BE4GJL/1711.html}
}

@inproceedings{curse,
  author    = {Chattopadhyay, Nandish and Chattopadhyay,
               Anupam and Gupta, Sourav Sen and Kasper, Michael},
  booktitle = {2019
               International Joint Conference on Neural Networks (IJCNN)},
  title     = {Curse of
               Dimensionality in Adversarial Examples},
  year      = {2019},
  pages     = {1-8},
  doi       = {10.1109/IJCNN.2019.8851795}
}


@inproceedings{FunAttacks,
  author    = {Cassidy Laidlaw and
               Soheil Feizi},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {Functional Adversarial Attacks},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, December
               8-14, 2019, Vancouver, BC, Canada},
  pages     = {10408--10418},
  year      = {2019},
  url       = {https://proceedings.neurips.cc/paper/2019/hash/6e923226e43cd6fac7cfe1e13ad000ac-Abstract.html},
  timestamp = {Mon, 16 May 2022 15:41:51 +0200},
  biburl    = {https://dblp.org/rec/conf/nips/LaidlawF19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{geometryadvex,
  doi       = {10.48550/ARXIV.1811.00525},
  url       = {https://arxiv.org/abs/1811.00525},
  author    = {Khoury, Marc and Hadfield-Menell, Dylan},
  keywords  = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {On the Geometry of Adversarial Examples},
  publisher = {arXiv},
  year      = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{guoLowFrequencyAdversarial2019,
  title     = {Low {{Frequency Adversarial Perturbation}}},
  booktitle = {{{UAI}}},
  author    = {Guo, Chuan and Frank, Jared S. and Weinberger, Kilian Q.},
  date      = {2019},
    file      = {/Users/godf974/OneDrive - PNNL/Documents/Papers/DS/Guo et al_2019_Low Frequency Adversarial Perturbation.pdf}
}


@misc{GuoOrigins,
  doi       = {10.48550/ARXIV.2203.13779},
  url       = {https://arxiv.org/abs/2203.13779},
  author    = {Dohmatob, Elvis and Guo, Chuan and Goibert, Morgane},
  keywords  = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Origins of Low-dimensional Adversarial Perturbations},
  publisher = {arXiv},
  year      = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{haninComplexityLinearRegions2019a,
  title     = {Complexity of {{Linear Regions}} in {{Deep Networks}}},
  booktitle = {Proceedings of the 36th {{International Conference}} on {{Machine Learning}}},
  author    = {Hanin, Boris and Rolnick, David},
  year      = {2019},
  month     = may,
  pages     = {2596--2604},
  publisher = {{PMLR}},
  issn      = {2640-3498},
    langid    = {english},
  file      = {/Users/godf974/OneDrive - PNNL/Documents/Papers/Gumby/Hanin_Rolnick_2019_Complexity of Linear Regions in Deep Networks2.pdf;/Users/godf974/Zotero/storage/447IJKI5/Hanin and Rolnick - 2019 - Complexity of Linear Regions in Deep Networks.pdf}
}

@inproceedings{harness,
  title     = {Explaining and Harnessing Adversarial Examples},
  author    = {Ian Goodfellow and Jonathon Shlens and Christian Szegedy},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6572},
  booktitle = {International Conference on Learning Representations}
}

@inproceedings{intrigue,
  title     = {Intriguing properties of neural networks},
  author    = {Christian Szegedy and Wojciech Zaremba and Ilya Sutskever and Joan Bruna and Dumitru Erhan and Ian Goodfellow and Rob Fergus},
  year      = {2014},
  url       = {http://arxiv.org/abs/1312.6199},
  booktitle = {International Conference on Learning Representations}
}


@article{Jo2017MeasuringTT,
  title   = {Measuring the tendency of CNNs to Learn Surface Statistical Regularities},
  author  = {Jason Jo and Yoshua Bengio},
  journal = {ArXiv},
  year    = {2017},
  volume  = {abs/1711.11561}
}

@article{lecun1998mnist,
  title   = {MNIST handwritten digit database},
  author  = {LeCun, Yann and Cortes, Corinna and Burges, CJ},
  journal = {ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},
  volume  = {2},
  year    = {1998}
}

@inproceedings{madry2018towards,
  title     = {Towards Deep Learning Models Resistant to Adversarial Attacks},
  author    = {Aleksander Madry and Aleksandar Makelov and Ludwig Schmidt and Dimitris Tsipras and Adrian Vladu},
  booktitle = {International Conference on Learning Representations},
  year      = {2018},
  url       = {https://openreview.net/forum?id=rJzIBfZAb}
}

@article{MoosaviDezfooli2016DeepFoolAS,
  title   = {DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks},
  author  = {Seyed-Mohsen Moosavi-Dezfooli and Alhussein Fawzi and Pascal Frossard},
  journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year    = {2016},
  pages   = {2574-2582}
}

@inproceedings{pmlr-v84-franceschi18a,
  title     = {Robustness of classifiers to uniform $\ell_p$ and Gaussian noise},
  author    = {Franceschi, Jean-Yves and Fawzi, Alhussein and Fawzi, Omar},
  booktitle = {Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics},
  pages     = {1280--1288},
  year      = {2018},
  editor    = {Storkey, Amos and Perez-Cruz, Fernando},
  volume    = {84},
  series    = {Proceedings of Machine Learning Research},
  month     = {09--11 Apr},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v84/franceschi18a/franceschi18a.pdf},
  url       = {https://proceedings.mlr.press/v84/franceschi18a.html},
  }

@inproceedings{pmlr-v97-rahaman19a,
  title     = {On the Spectral Bias of Neural Networks},
  author    = {Rahaman, Nasim and Baratin, Aristide and Arpit, Devansh and Draxler, Felix and Lin, Min and Hamprecht, Fred and Bengio, Yoshua and Courville, Aaron},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  pages     = {5301--5310},
  year      = {2019},
  editor    = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume    = {97},
  series    = {Proceedings of Machine Learning Research},
  month     = {09--15 Jun},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v97/rahaman19a/rahaman19a.pdf},
  url       = {https://proceedings.mlr.press/v97/rahaman19a.html},
}


@inproceedings{pmlr-v97-simon-gabriel19a,
  title     = {First-Order Adversarial Vulnerability of Neural Networks and Input Dimension},
  author    = {Simon-Gabriel, Carl-Johann and Ollivier, Yann and Bottou, Leon and Sch{\"o}lkopf, Bernhard and Lopez-Paz, David},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  pages     = {5809--5817},
  year      = {2019},
  editor    = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume    = {97},
  series    = {Proceedings of Machine Learning Research},
  month     = {09--15 Jun},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v97/simon-gabriel19a/simon-gabriel19a.pdf},
  url       = {https://proceedings.mlr.press/v97/simon-gabriel19a.html},
  }


@inproceedings{shafahi2018are,
  title     = {Are adversarial examples inevitable?},
  author    = {Ali Shafahi and W. Ronny Huang and Christoph Studer and Soheil Feizi and Tom Goldstein},
  booktitle = {International Conference on Learning Representations},
  year      = {2019},
  url       = {https://openreview.net/forum?id=r1lWUoA9FQ}
}

@article{sharmaEffectivenessLowFrequency2019,
  title        = {On the {{Effectiveness}} of {{Low Frequency Perturbations}}},
  author       = {Sharma, Yash and Ding, G. and Brubaker, Marcus A.},
  date         = {2019},
  journaltitle = {IJCAI},
  doi          = {10.24963/ijcai.2019/470},
    file         = {/Users/godf974/OneDrive - PNNL/Documents/Papers/DS/Sharma et al_2019_On the Effectiveness of Low Frequency Perturbations.pdf}
}

@article{Stutz2019CVPR,
  author    = {David Stutz and Matthias Hein and Bernt Schiele},
  title     = {Disentangling Adversarial Robustness and Generalization},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  publisher = {IEEE Computer Society},
  year      = {2019}
}


@article{tramer2017space,
  title   = {The space of transferable adversarial examples},
  author  = {Tram{\`e}r, Florian and Papernot, Nicolas and Goodfellow, Ian and Boneh, Dan and McDaniel, Patrick},
  journal = {arXiv preprint arXiv:1704.03453},
  year    = {2017}
}

@inproceedings{YinFourier,
  author    = {Dong Yin and Raphael Gontijo Lopes and Jon Shlens and Ekin Dogus Cubuk and Justin Gilmer},
  title     = {A Fourier Perspective on Model Robustness in Computer Vision},
  year      = {2019},
  cdate     = {1546300800000},
  pages     = {13255-13265},
  url       = {http://papers.nips.cc/paper/9483-a-fourier-perspective-on-model-robustness-in-computer-vision},
  booktitle = {NeurIPS}
}

@inproceedings{ZhaoLL20,
  author    = {Zhengyu Zhao and Zhuoran Liu and Martha A. Larson},
  title     = {Adversarial Color Enhancement: Generating Unrestricted Adversarial Images by Optimizing a Color Filter},
  year      = {2020},
  cdate     = {1577836800000},
  url       = {https://www.bmvc2020-conference.com/assets/papers/0099.pdf},
  booktitle = {BMVC}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={IEEE}
}

@article{He2016DeepRL,
  title={Deep Residual Learning for Image Recognition},
  author={Kaiming He and X. Zhang and Shaoqing Ren and Jian Sun},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={770-778}
}

@inproceedings{Krizhevsky2009LearningML,
  title={Learning Multiple Layers of Features from Tiny Images},
  author={Alex Krizhevsky},
  year={2009}
}

@inproceedings{imagenet_cvpr09,
  title = {{{ImageNet}}: {{A}} Large-Scale Hierarchical Image Database},
  booktitle = {{{CVPR09}}},
  author = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and {Fei-Fei}, L.},
  year = {2009},
  bibsource = {http://www.image-net.org/papers/imagenet\textsubscript{c}vpr09.bib}
}


@article{gilmerDiscussionAdversarialExamples2019a,
  title = {A {{Discussion}} of '{{Adversarial Examples Are Not Bugs}}, {{They Are Features}}': {{Adversarial Example Researchers Need}} to {{Expand What}} Is {{Meant}} by '{{Robustness}}'},
  shorttitle = {A {{Discussion}} of '{{Adversarial Examples Are Not Bugs}}, {{They Are Features}}'},
  author = {Gilmer, Justin and Hendrycks, Dan},
  year = {2019},
  month = aug,
  journal = {Distill},
  volume = {4},
  number = {8},
  pages = {e00019.1},
  issn = {2476-0757},
  doi = {10.23915/distill.00019.1},
  abstract = {The main hypothesis in Ilyas et al. (2019) happens to be a special case of a more general principle that is commonly accepted in the robustness to distributional shift literature},
  langid = {english},
  file = {/Users/godf974/Zotero/storage/YWMQP3IU/response-1.html}
}

@misc{gilmerMotivatingRulesGame2018a,
  title = {Motivating the {{Rules}} of the {{Game}} for {{Adversarial Example Research}}},
  author = {Gilmer, Justin and Adams, Ryan P. and Goodfellow, Ian and Andersen, David and Dahl, George E.},
  year = {2018},
  month = jul,
  number = {arXiv:1807.06732},
  eprint = {1807.06732},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  abstract = {Advances in machine learning have led to broad deployment of systems with impressive performance on important problems. Nonetheless, these systems can be induced to make errors on data that are surprisingly similar to examples the learned system handles correctly. The existence of these errors raises a variety of questions about out-of-sample generalization and whether bad actors might use such examples to abuse deployed systems. As a result of these security concerns, there has been a flurry of recent papers proposing algorithms to defend against such malicious perturbations of correctly handled examples. It is unclear how such misclassifications represent a different kind of security problem than other errors, or even other attacker-produced examples that have no specific relationship to an uncorrupted input. In this paper, we argue that adversarial example defense papers have, to date, mostly considered abstract, toy games that do not relate to any specific security concern. Furthermore, defense papers have not yet precisely described all the abilities and limitations of attackers that would be relevant in practical security. Towards this end, we establish a taxonomy of motivations, constraints, and abilities for more plausible adversaries. Finally, we provide a series of recommendations outlining a path forward for future work to more clearly articulate the threat model and perform more meaningful evaluation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning}
}

@article{bahadurNoteQuantilesLarge1966,
  title = {A {{Note}} on {{Quantiles}} in {{Large Samples}}},
  author = {Bahadur, R. R.},
  year = {1966},
  month = jun,
  journal = {The Annals of Mathematical Statistics},
  volume = {37},
  number = {3},
  pages = {577--580},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0003-4851, 2168-8990},
  doi = {10.1214/aoms/1177699450},
  abstract = {The Annals of Mathematical Statistics},
  file = {/Users/godf974/OneDrive - PNNL/Documents/Papers/DS/Bahadur_1966_A Note on Quantiles in Large Samples.pdf;/Users/godf974/Zotero/storage/NGX887GI/1177699450.html}
}

@ARTICLE{2020SciPy-NMeth,
  author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
            Haberland, Matt and Reddy, Tyler and Cournapeau, David and
            Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and
            Bright, Jonathan and {van der Walt}, St{\'e}fan J. and
            Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and
            Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and
            Kern, Robert and Larson, Eric and Carey, C J and
            Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and
            {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and
            Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and
            Harris, Charles R. and Archibald, Anne M. and
            Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and
            {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
            Computing in Python}},
  journal = {Nature Methods},
  year    = {2020},
  volume  = {17},
  pages   = {261--272},
  adsurl  = {https://rdcu.be/b08Wh},
  doi     = {10.1038/s41592-019-0686-2},
}

@incollection{torch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@misc{mosaicml2022composer,
    author = {The Mosaic ML Team},
    title = {composer},
    year = {2021},
    howpublished = {\url{https://github.com/mosaicml/composer/}},
}

@inproceedings{torchvision,
author = {Marcel, S\'{e}bastien and Rodriguez, Yann},
title = {Torchvision the Machine-Vision Package of Torch},
year = {2010},
isbn = {9781605589336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1873951.1874254},
doi = {10.1145/1873951.1874254},
abstract = {This paper presents Torchvision an open source machine vision package for Torch. Torch is a machine learning library providing a series of the state-of-the-art algorithms such as Neural Networks, Support Vector Machines, Gaussian Mixture Models, Hidden Markov Models and many others. Torchvision provides additional functionalities to manipulate and process images with standard image processing algorithms. Hence, the resulting images can be used directly with the Torch machine learning algorithms as Torchvision is fully integrated with Torch. Both Torch and Torchvision are written in C++ language and are publicly available under the Free-BSD License.},
booktitle = {Proceedings of the 18th ACM International Conference on Multimedia},
pages = {1485â€“1488},
numpages = {4},
keywords = {face detection and recognition, machine learning, open source, pattern recognition, vision},
location = {Firenze, Italy},
series = {MM '10}
}

@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  volume={115},
  pages={211--252},
  year={2015},
  publisher={Springer}
}


@article{deng2012mnist,
  title={The mnist database of handwritten digit images for machine learning research},
  author={Deng, Li},
  journal={IEEE Signal Processing Magazine},
  volume={29},
  number={6},
  pages={141--142},
  year={2012},
  publisher={IEEE}
}

@inproceedings{xie2017adversarial,
  title={Adversarial examples for semantic segmentation and object detection},
  author={Xie, Cihang and Wang, Jianyu and Zhang, Zhishuai and Zhou, Yuyin and Xie, Lingxi and Yuille, Alan},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1369--1378},
  year={2017}
}

@inproceedings{kuppa2019black,
  title={Black box attacks on deep anomaly detectors},
  author={Kuppa, Aditya and Grzonkowski, Slawomir and Asghar, Muhammad Rizwan and Le-Khac, Nhien-An},
  booktitle={Proceedings of the 14th international conference on availability, reliability and security},
  pages={1--10},
  year={2019}
}

@article{maus2023adversarial,
  title={Adversarial Prompting for Black Box Foundation Models},
  author={Maus, Natalie and Chao, Patrick and Wong, Eric and Gardner, Jacob},
  journal={arXiv preprint arXiv:2302.04237},
  year={2023}
}

@misc{bachOptimizationSparsityInducingPenalties2011,
  title = {Optimization with {{Sparsity-Inducing Penalties}}},
  author = {Bach, Francis and Jenatton, Rodolphe and Mairal, Julien and Obozinski, Guillaume},
  year = {2011},
  month = nov,
  number = {arXiv:1108.0775},
  eprint = {1108.0775},
  eprinttype = {arxiv},
  primaryclass = {cs, math, stat},
  publisher = {{arXiv}},
  abstract = {Sparse estimation methods are aimed at using or obtaining parsimonious representations of data or models. They were first dedicated to linear variable selection but numerous extensions have now emerged such as structured sparsity or kernel selection. It turns out that many of the related estimation problems can be cast as convex optimization problems by regularizing the empirical risk with appropriate non-smooth norms. The goal of this paper is to present from a general perspective optimization tools and techniques dedicated to such sparsity-inducing penalties. We cover proximal methods, block-coordinate descent, reweighted \$\textbackslash ell\_2\$-penalized techniques, working-set and homotopy methods, as well as non-convex formulations and extensions, and provide an extensive set of experiments to compare various algorithms from a computational point of view.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning}
}
