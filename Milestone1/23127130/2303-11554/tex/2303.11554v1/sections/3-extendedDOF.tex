\section{Simulations}
% Present reconstruction results for dual-depth object reconstruction showcasing the extended-depth-of-field capabilities of the radial coded mask when comparing to other coded aperture types
The primary goal of a radial mask is to extend the DOF of a lensless imaging system. So far, we have only searched for the best parameters for such a coded mask, without investigating its extended DOF properties. In this section, we determine the extended DOF of a radial mask through simulations. We also show that the reconstructed image from the lensless camera can be electronically refocused, after the image sensor measurement capture, by changing the scaling of the PSF of the coded mask. 

\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth]{figs/DOF_simulation/SankenOU_diagram.pdf}
    \caption{Geometrical setup of simulations.
    The OU pattern object was positioned at a distance of $5.0$~cm away from the coded mask, while the farther object was at $30.0$~cm away.
    The distance between the image sensor and the coded mask was set to $4.0$ mm.}
    \label{fig:SimSetup}
\end{figure}

\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth, trim = 0cm 0cm 0cm 0cm]{figs/DOF_simulation/ADMM_UDN_analysis.pdf}
    \caption{Results of the imaging simulation.
    The top two rows present, respectively, the PSFs and sensor measurements.
    The next two rows are the reconstructed images using the ADMM algorithm and their close-ups of the OU pattern object, which cannot be correctly reconstructed by conventional methods.
    The next two rows are the reconstruction by the UDN algorithm and close-ups.
    From the left column, the results correspond to the ground truth, the radial mask, the FZA, and the random mask, respectively.
    }
    \label{fig:SimDOF_recon}
\end{figure}

\subsection{Conditions}
\label{subsec:DOF_sim}
The simulation was performed as a dual-depth object reconstruction, where we had two objects at two different distances from the lensless camera. We geometrically model the PSFs projected from both distances, and use them to generate the simulated sensor measurements for the full scene. The simulation of the sensing process was performed by calculating Eq.~\eqref{eq:3Dforward}. We then reconstructed an image from the full sensor measurements by using a single PSF, that could be from either of the distances. Generally, for any type of coded mask, it is expected that the object placed at the same distance at which the PSF was calibrated should be reconstructed with a higher quality than objects at different distances from the lensless camera.

As baselines for comparison against the radial mask, 
we used a Fresnel zone aperture~(FZA)~\cite{Shimano2018, Wu2020, Nakamura2020OE} and a random mask~\cite{Nakamura2019,Zheng2021,Boominathan2020} as examples.
The random mask is a naive design for 2D lensless imaging that has good MTF up to cutoff frequency.
The FZA is a coded mask with a structure only in the radial direction, opposite to the radial mask, and is suitable for digital refocusing applications.

For the lensless image reconstruction, we used two algorithms, namely the alternating direction method of multipliers (ADMM) method~\cite{boyd_etal_ADMM_NOW_2011}, and the untrained deep network (UDN) method~\cite{monakhova_etal_UDN_OptExp_2021}.
Both methods are based on the iterative error-minimization algorithm involving regularization.
For the regularization, the ADMM uses the minimization of 2D total variation~(TV)~\cite{Rubin1992} of a reconstructed image, while the UDN implements it by an untrained generative deep neural network, i.e., employment of deep image prior~\cite{DIP}.
Compared to learning-based methods~\cite{Sinha2017, Monakhova2019OE, Barba2019, Rego2022}, the results can be explainable and their precision is not restricted to a domain of learning.

Figure~\ref{fig:SimSetup} shows the simulated experimental setup.
It involves a planar plush toy and a planar OU pattern positioned $30.0~\mathrm{cm}$ and $5.0~\mathrm{cm}$ away from the coded mask, respectively.
The axial interval between the mask and an image sensor was set to $4.0~\mathrm{mm}$.
Figure~\ref{fig:SimDOF_recon} presents the mask patterns used for simulations, corresponding captured images, and reconstruction results with the ADMM and UDN algorithms using the PSF calibrated for a distance of $30.0~\mathrm{cm}$.
We set the size of the RGB captured measurements, simulated PSFs, and reconstructed images to $512 \times 612$ pixels.
In simulations, the noise was ignored to analyze the upper limit of the effect of the proposed methodology; however, a noise analysis can be drawn from the prototype camera experiments.
The coded masks used in the simulations are the same ones that were used for the prototype camera experiment.
In the reconstruction process, we used 150,000 iterations for the UDN algorithm and 100 iterations per channel for the ADMM algorithm.
The optimization code was implemented in Pytorch with a computational environment including a GPU (GeForce 3090 by NVIDIA), 32 GiB RAM, and a 10-core CPU (i9-10900K by Intel).


\subsection{Reconstruction Results}
We limited the effective area of the mask to approximately $50~\%$ in the central region for increasing the stability of reconstruction~\cite{Antipa2018}, and the remaining perimeter of the mask was light-shielded.
From the reconstruction results of Fig.~\ref{fig:SimDOF_recon}, we observed that the plush toy was correctly reconstructed by all three types of coded masks. This was expected, as the PSF used for reconstruction was the one calibrated for the same distance as the plush-toy distance. The OU pattern, however, was closer to the lensless system than the calibrated PSF and was only reconstructed properly by the radial mask. Additionally, we note that the peak signal-to-noise ratio (PSNR) of the radial-mask reconstruction was significantly higher than that of the FZA and random coded masks. Table~\ref{tab:SimAnalysis}(a) presents a quantitative analysis of the OU pattern reconstruction between the three types of coded masks shown in Fig.~\ref{fig:SimDOF_recon}. We note that the radial mask achieves the best reconstruction of the OU pattern in all metrics including SSIM~\cite{Wang2004} and LPIPS~\cite{Zhang2018}.

\begin{figure}[!t]
    \centering
    \includegraphics[scale=0.8]{figs/DOF_simulation/electronicRefocus.pdf}
    \caption{Demonstration of the refocusing ability of a lensless camera.
    The lensless sensor measurements were the same ones shown in Fig.~\ref{fig:SimDOF_recon}.
    The far-focus and close-focus PSFs indicate simulated PSFs created by a light source placed $30.0$~cm and $5.0$~cm away from the coded mask, respectively.
    The images were reconstructed by the ADMM algorithm.}
    \label{fig:ElectronicRefocus}
\end{figure}

\begin{table}[]
\centering
\caption{Quantitative analysis of the simulations.}
\label{tab:SimAnalysis}
\subcaption*{(a) Comparison of the quality of the reconstructed OU patterns for different types of coded masks, as presented in Figure~\ref{fig:SimDOF_recon}.}
\label{tab:ReconCompare}
\resizebox{\columnwidth}{!}{%

\begin{tabular}{lcccccc}
\multicolumn{1}{c}{}        &          & ADMM     &                                &          & UDN      &           \\
\multicolumn{1}{c|}{}       & PSNR (↑) & SSIM (↑) & \multicolumn{1}{c|}{LPIPS (↓)} & PSNR (↑) & SSIM (↑) & LPIPS (↓) \\ \hline
\multicolumn{1}{l|}{Radial} & \textbf{20.64} & \textbf{0.6151} & \multicolumn{1}{c|}{\textbf{0.2290}} & \textbf{19.71} & \textbf{0.6700} & \textbf{0.1451} \\
\multicolumn{1}{l|}{FZA}    & 15.38    & 0.4536   & \multicolumn{1}{c|}{0.4285}    & 14.99    & 0.5300   & 0.3876    \\
\multicolumn{1}{l|}{Random} & 14.97    & 0.4862   & \multicolumn{1}{c|}{0.6189}    & 15.04    & 0.5111   & 0.5493   
\end{tabular}%
}
\bigskip
\subcaption*{(b) Correlation between close focus and far focus PSFs presented in Fig.~\ref{fig:ElectronicRefocus}.}
\begin{tabular}{c|ccc}
    & Radial                                          & FZA                                             & Random                                           \\\hline
MAE & $1.37\times10^{-6}$ & $3.44\times10^{-6}$ & $3.54\times10^{-6}$
\end{tabular}%
\end{table}

\begin{figure*}[!t]
    \centering
    \includegraphics[width=\textwidth]{figs/DOF_exp/FullDofExpV2.pdf}
    \caption{(a)~A prototype of a lensless camera, with an SLM creating the radial mask, and an image sensor behind it.
    (b)~Setup for the experiment.
    (c)~Calibrated PSFs for the radial, FZA, and random mask.
    (d)~Experimentally obtained sensor measurements.
    Reconstruction results using the (e)~ADMM and (f)~UDN algorithm.
    (g) Close-ups of the OU pattern reconstructed by the UDN algorithm.}
    \label{fig:RealExp}
\end{figure*}

\subsection{Refocusing Ability}
Additionally, we present in Fig.~\ref{fig:ElectronicRefocus} the refocus of the reconstructed image after sensor measurements capture. We show that by changing the scaling of the PSF, it is possible to focus on either the closer object, or the farther object in the simulated scene. We note, however, that our optimized radial mask is capable of reconstructing both objects independently of the scaling used for the PSF. Table~\ref{tab:SimAnalysis}(b) presents a quantitative comparison between far-focus and close-focus PSFs for the three types of coded masks presented in Fig.~\ref{fig:ElectronicRefocus}. We note that the radial mask presents a lower mean absolute error~(MAE) between far and close-focus PSFs, when compared to FZA and random masks. This justifies why the reconstruction algorithm is capable of reconstructing both objects successfully using either of the calibrated radial PSFs, which is not the case for the other types of coded masks. 


\section{Optical Experiments with a Prototype Camera}

\subsection{Setup}
Finally, we create a prototype lensless camera, to validate the extended DOF of the radial mask in the real world.
Similarly to the simulation, this experiment consists of reconstructing two objects at different distances from the lensless imager, but in a real scenario.
Figure~\ref{fig:RealExp}(a) shows a frontal view of the prototype lensless camera, which consists of an axial stack of a coded mask and an image sensor.
The coded mask was implemented by a transmissive liquid-crystal SLM~(LC2012 by HOLOEYE Photonics) and two polarization plates in the crossed Nicols configuration.
All coded masks to be tested are originally binary, therefore, the light transmittance of the SLM was designed as binary, and central $188 \times 228$ pixels with $36 \times 36\ \mathrm{\mu m}$ pitches were used for implementing the coded masks.
The fill factor of the SLM was $58~\%$.
Approximately $4.0~\mathrm{mm}$ behind the modulation plane of the SLM, we placed a color CMOS image sensor~(BFS-U3-51S5C-BD by Teledyne FLIR) whose pixel count was $2048 \times 2448$ with $3.45~\mathrm{\mu m} \times 3.45~\mathrm{\mu m}$ pitches.
In the experiment, $8$-bit RGB captured images were readout and they were downsampled to $512 \times 612$ pixels for reconstruction.
As well as simulations, the periphery of the mask was shielded for increasing reconstruction stability where the effective area of the mask was approximately $50~\%$.
The center of the effective area of the SLM and the image sensor were aligned by translation stages, and the planes of the two elements were adjusted to be parallel.

Figure~\ref{fig:RealExp}(b) shows the experimental setup including the camera and targets to be imaged.
In front of a lensless camera prototype, we placed two diffuse reflective objects: a stuffed toy known as SANKEN, which is one of the symbols of Osaka University~(SANKEN plush toy), and a black tape with the letters 'OU' printed on it~(OU letters).
The SANKEN toy and the OU letters were placed at approximately $30$ and $9$ centimeters~(cm) away from the mask, respectively.
These objects were illuminated by a white LED light Installed around $12~\mathrm{cm}$ above the camera.

\subsection{PSF Calibration}
The top right in Fig.~\ref{fig:RealExp} shows the calibrated PSFs. The PSFs were calibrated by experimental capture of a spherical wave emitted from a light point source placed $30~\mathrm{cm}$ away from the camera, which was the same distance as the SANKEN toy. The light-point source we used was composed of a 
semiconductor laser whose central wavelength was 532~nm~(Stradus 532 by Vortran Laser Technology), followed by a spatial filter~(SFB-16DMRO-OBL40-25 by SIGMA KOKI) which contained a pinhole whose diameter was $25~\mathrm{\mu m}$. The combination of the laser with the spatial filter generated a spherical wave.

\subsection{Experiments}
%Capture
The second row of the right in Fig.~\ref{fig:RealExp} shows the captured lensless measurements.
Although the captured image cannot be recognized by human vision, the encoded images of objects at multiple distances were multiply recorded based on the physical model in Eq.~\eqref{eq:3Dforward}.
The captured image also contains color information.
Note that each coded image of Fig.~\ref{fig:RealExp} was normalized for visualization.

%Reconstruction
The PSF was calibrated by the point light source positioned $30~\mathrm{cm}$ away from the coded mask. Therefore, it was expected for the object at a $30~\mathrm{cm}$ distance to be correctly reconstructed for all three types of coded masks. The OU pattern object, however, was placed $9~\mathrm{cm}$ away from the coded mask and was expected to be more challenging to be reconstructed properly.
The coded masks and reconstruction algorithms used here were the same as those used in the simulations. The reconstructions for the radial, FZA, and random coded masks using the ADMM and UDN algorithms are shown in the third and fourth rows of the right part of Fig.~\ref{fig:RealExp}, respectively. The bottom row presents the close-up view of the OU letters reconstructed by the UDN algorithm. As expected, the plush toy was correctly reconstructed in all experiments, independently of the type of coded mask or the reconstruction algorithm employed. We note, however, that reconstruction with resolving the two letters on the OU pattern was only successful by the radial coded mask, due to its robustness against the scaling of its PSF, i.e., extended DOF characteristics. The reconstructions using the FZA and random masks, on the other hand, were blurred and the two letters seemed to mix together.


