\section{Introduction}
% 1-Present brief introduction about lensless imaging citing limitations
% 2-Present related works to coded mask optimization and depth-of-field imaging

% Introduce topic of lensless cameras (what they are, why use them)

\begin{figure*}[!t]
    \centering
    \includegraphics[width=\linewidth]{figs/introduction/CompleteIntroV4.pdf}
    \caption{(a)~Complete pipeline for a mask-based lensless imaging system, from the acquisition of the image sensor measurements to the reconstruction through a computational algorithm. The pipeline on top exemplifies the limitation of a non-radial coded mask at reconstructing objects at very different distances from the camera. On the bottom pipeline, we illustrate the extended DOF achieved by a radial type coded mask. (b)~Schematic diagram of the depth dependency of a PSF, as it radially scales up when a light point source becomes closer to a coded mask. 
    (c)~Concept on the scaling-invariant property of a radial mask, as its digital PSF observed by an image sensor (red square) remains unchanged even when the optical PSF becomes large. This does not hold true for a non-radial mask such as a random mask, as its observed digital PSF (red square) changes.}
    \label{fig:intro_complete}
\end{figure*}

\ifx\ManuscriptType\IEEEpaper
\IEEEPARstart{M}{ask-based} lensless cameras are formed by replacing the lenses from a traditional camera with a coded mask~\cite{Boominathan2022}. This replacement makes it possible to produce smaller, lighter, and cheaper cameras when compared to traditional lens-based ones. The most notable difference between these two types of cameras is that the coded mask of a lensless camera multiplexes the incoming light, mapping one point in the ambient scene to many pixels in the image sensor, thus encoding the ambient scene information in visually uninformative sensor measurements.
\else 
Mask-based lensless cameras are formed by replacing the lenses from a traditional camera with a coded mask~\cite{Boominathan2022}. This replacement makes it possible to produce smaller, lighter, and cheaper cameras when compared to traditional lens-based ones. The most notable difference between these two types of cameras is that the coded mask of a lensless camera multiplexes the incoming light, mapping one point in the ambient scene to many pixels in the image sensor, thus encoding the ambient scene information in visually uninformative sensor measurements.
\fi
% \IEEEPARstart{M}{ask-based} lensless cameras are formed by replacing the lenses from a traditional camera with a coded mask~\cite{Boominathan2022}. This replacement makes it possible to produce smaller, lighter, and cheaper cameras when compared to traditional lens-based ones. The most notable difference between these two types of cameras is that the coded mask of a lensless camera multiplexes the incoming light, mapping one point in the ambient scene to many pixels in the image sensor, thus encoding the ambient scene information in visually uninformative sensor measurements.

The sensor measurement formation process is often modeled as a two-dimensional~(2D) convolution between the point spread function~(PSF), which is an intensity impulse response in the spatial domain, of an optical system involving a coded mask and the incoming light from the scene~\cite{Goodman1996, Antipa2018}, as
\begin{equation}
    \textbf{b} = crop[\textbf{h}*\textbf{v}] = \textbf{A}\textbf{v},
    \label{eq:conv}
\end{equation}
where 
$\textbf{b} \in \mathbb{R}^{N_\mathrm{b} \times 1}$ is a vector representing the captured sensor measurements,
$crop[\cdot]$ is the cropping function of an image defined by the effective area of the pixel of an image sensor,
$\textbf{h} \in \mathbb{R}^{N_\mathrm{v} \times 1}$ is a vector representing a PSF, 
$*$ is the 2D convolution operator, and 
$\textbf{v} \in \mathbb{R}^{N_\mathrm{v} \times 1}$ is a vector representing the spatial light intensity of a scene.
$N_\mathrm{b} \in \mathbb{N}$ and $N_\mathrm{v}\in \mathbb{N}$ are the pixel count of captured and scene images, respectively.
We also define a matrix~$\textbf{A} \in \mathbb{R}^{N_\mathrm{b} \times N_\mathrm{v}}$ to simply denote the operations of 2D convolution followed by cropping. The model of Eq.~\eqref{eq:conv} assumes a shift-invariant system as an approximation~\cite{Martz1962}.

Ordinarily, the sensor measurements do not contain apparent visual information, and in order to reconstruct the scene information $\textbf{v}$, a reconstruction algorithm is employed.
In general, the regularized error-minimization method with iterative algorithms, which is stable against noise, is often employed as the image reconstruction method.
The minimization problem is defined as:
\begin{equation}
    \tilde{\textbf{v}} = 
    \operatorname*{argmin}_{\textbf{v}\geq 0}
    \| \textbf{b} - \textbf{A}\textbf{v} \|^2_2 
    + \tau \Psi(\textbf{v}),
\end{equation}
where $\Tilde{\textbf{v}} \in \mathbb{R}^{N_\mathrm{v} \times 1}$ is a vector representing a reconstructed image,
$\| \cdot \|_2$ is $\ell_2$-norm of a vector, 
$\tau$ is a constant value for controlling the effectiveness of the regularization,
$\Psi(\cdot)$ is a regularizer, which is often a combination of linear transformation and $\ell_1$-norm calculation.
%, often implemented as the total variation norm in the vertical and horizontal dimensions of the image.
Figure~\ref{fig:intro_complete}(a) illustrates the complete pipeline of a mask-based lensless camera. %Note that throughout this paper we use the terms \textit{coded aperture}, \textit{coded mask}, and simply \textit{mask} interchangeably, with all of them referring to an amplitude-based coded aperture mask.

% Explain DOF limitation from lensless imaging perspective (PSF depth-dependency) and motivate radial coded mask
\subsection{Depth of Field in Lensless Imaging}
Similarly to traditional lens-based cameras, mask-based lensless imagers have a limited depth of field~(DOF), especially when shooting scenes that include a large distance range~\cite{Tan2017}. 
For a lensless system, this limitation stems from the fact that the PSF as a shadow of a coded mask is depth dependent. As illustrated in Fig.~\ref{fig:intro_complete}(b), object planes at different distances produce different PSFs. 
Considering this, the generalized forward model for imaging 3D scene is modeled as follows:
\begin{equation}
    \textbf{b} = crop\left[\sum_{z} \textbf{h}_z*\textbf{v}_z\right] = \sum_z\textbf{A}_z\textbf{v}_z,
    \label{eq:3Dforward}
\end{equation}
where $z > 0$ is the distance of the object plane measured from the mask plane, and $\sum_z$ is the incoherent summation of the depth-dependent information.
% $\textbf{h}_z$, $\textbf{v}_z$, and $\textbf{A}_z$ are $z$-dependent vectors and a matrix of $\textbf{h}$, $\textbf{v}$, and $\textbf{A}$, respectively.
$\textbf{h}_z$ and $\textbf{v}_z$ are $z$-dependent vectors of $\textbf{h}$ and $\textbf{v}$, respectively, and $\textbf{A}_z$ is a $z$-dependent matrix of $\textbf{A}$.
Note that the effect of occlusion by opaque objects is ignored for simplicity.
The reconstruction process using a single PSF is as follows:
\begin{equation}
    \tilde{\textbf{v}}_{z{^*}} = 
    \operatorname*{argmin}_{\textbf{v}\geq 0}
    \| \textbf{b} - \textbf{A}_{z{^*}}\textbf{v} \|^2_2 
    + \tau \Psi(\textbf{v}),
    \label{eq:3Dinv}
\end{equation}
where $z^*$ is the distance value to be used for reconstruction, $\textbf{A}_{z{^*}} \in \mathbb{R}^{N_\mathrm{b} \times N_\mathrm{v}}$ is a matrix representing a forward operator corresponding to $z^*$, and $\tilde{\textbf{v}}_{z{^*}} \in \mathbb{R}^{N_\mathrm{v} \times 1}$ is a vector representing the reconstructed image with using $\textbf{A}_{z{^*}}$.
As indicated in Eq.~\eqref{eq:3Dinv}, only the depth range that matches an assumed depth in the reconstruction process $
z{^*}$ can be reconstructed correctly.
In other words, the gap between an object's real depth and the depth used for calibration of the PSF incurs a worse reconstruction.
This limitation on the correctly-reconstructable distance range with a single reconstruction filter can be defined as a DOF of the lensless imaging system.
This property is sometimes utilized in digital refocusing~\cite{Shimano2018}, depth-map acquisition~\cite{Zheng2020}, 3D imaging~\cite{Antipa2018,Adams2017, Tian2022}; however, it is undesirable in applications such as 2D image analysis because it impairs the spatial characteristics of the image.

%EDOF (shorten mask position, focal stack, compressive sensing)
To address this issue, the simplest way is to set the distance between the sensor and the mask closer. This method can extend the DOF in the same way as existing lens cameras; however, the angular resolution of the imaging system is sacrificed because the angle of view is also extended at the same time. 
Another simple method is to measure the PSFs at multiple distances in advance, reconstruct multiple images using all of the PSFs, and merge only the areas in focus from the resulting images into a single image~\cite{Hua2023}. This method is often used for lens-based imaging as called focal-stack photography~\cite{Kutulakos2009,Huang2022}. However, the challenges of lensless imaging are that it requires numerous reconstruction processes and contrast calculation processes, which are computationally expensive.
Furthermore, its synthesis accuracy depends on the complexity of the texture and structure of a scene.
A more advanced method is to use compressive holography~\cite{Brady2009} to reconstruct a 3D tomographic image~\cite{Antipa2018} and then generate an all-in-focus 2D image just by axial integration. Compressive holography reconstructs a sparse 3D tomographic image from a 2D image using a compressed sensing framework~\cite{Candes2008}.
This method is very interesting as a new method for tomography, but its computational cost is high because it needs to solve an ill-posed problem.
In addition, its accuracy severely depends on the sparsity of the scene.

%EDOF (mask design)
To extend the DOF in lensless imaging while avoiding the above problems, several methods have been proposed that take advantage of the design freedom of a mask in lensless imaging.
For example, Hua {\it et al.} proposed a method to realize an approximately depth-invariant PSF by sweeping the mask design during a single exposure, which, combined with post-imaging deconvolution, extends the DOF~\cite{Hua2020}.
This method called {\it SweepCam} can be said to be an application of the focal-sweep method~\cite{Kuthirummal2011} to lensless cameras.
This is a reasonable method to obtain an extended DOF image only with fast and stable computation, but it requires the use of a refreshable-type mask such as a liquid-crystal spatial light modulator~(SLM) and sacrifices temporal resolution.
As a method that can be realized with a fixed mask, Gill proposed the use of an odd-symmetry phase grating~\cite{Gill2013OL}. A lensless camera constructed using this mask has an extended DOF when compared to one using a normal mask~\cite{Gill2013}; However, one limitation is that the depth-invariant region of the PSF is limited to near the center of the mask, where incoming light of point-symmetric locations of the ambient scene are enforced to have their phases destructively interfere with each other at the image plane. As a result, the degree of depth-invariance is limited in principle.

On the other hand, in a past study, we proposed the radial coded mask whose PSF is the depth invariant in the whole area at the image plane~\cite{nakamura_etal_radial_IAOC_2020}. 
A radial mask is an amplitude-transmission mask that has structure only in the rotational direction and no structure in the radial direction.
Such a mask is usually used to measure optical transfer functions~\cite{Goodman1996} or to generate a non-diffracting beam~\cite{Rasouli2018}.
Figure~\ref{fig:intro_complete}(c) illustrates the concept of the depth-invariant PSF by a radial mask.
From a geometry-based point of view, the change of a PSF due to a change in the object distance is manifested as a radial scaling of a PSF as also shown in Fig.~\ref{fig:intro_complete}(b).
Therefore, by designing a coded mask that has no structure in the radial direction, it is possible to construct a lensless measurement system that cutoffs depth-dependent information, resulting in extended-DOF imaging using only a single deconvolution filter.
In a previous study~\cite{nakamura_etal_radial_IAOC_2020}, this effect was verified by simulations but not by optical experiments.
As for the structure of the radial mask, only one star-chart pattern with periodicity in the rotational direction was verified; however, the mask pattern should be optimized to maximize the goodness for spatial imaging while maintaining its characteristics of depth invariance.


% Motivate coded aperture optimization with paper citations (brief literature mention), mention our shape constraint (radial mask) throughout optimization
\subsection{Coded Mask Optimization (Related Works)}
A coded amplitude mask can be represented as a 2D tensor~$\textbf{M}\in\mathbb{R}^{N_\mathrm{y} \times N_\mathrm{x}}$ where the value of each element represents the light transmittance related to spatial coordinate~$(x, y)$ at the mask plane.
Here $N_\mathrm{y} \in \mathbb{N}$ and $N_\mathrm{x} \in \mathbb{N}$ are the vertical and horizontal pixel count of a spatially discretely represented mask. 
For the optimization of a light-transmittance pattern of a mask, i.e. the value of each element in a tensor~$\textbf{M}$, Horisaki~{\it et al.}~\cite{Horisaki_etal_DeeplyCoded_OL_2020} proposed a joint-optimization technique of the mask pattern and a reconstruction deep neural network.
This work is positioned as an application of the techniques known as end-to-end optimization~\cite{Sitzmann2018, Zhou2021} or deep optics~\cite{Hain2018,Chang2018} to the design of lensless cameras.
In the methodology, the simulation-based forward sensing model with mask variables and the reconstruction model based on a convolutional neural network~(CNN) are simultaneously optimally designed by supervised training using a large amount of prepared data pairs.

In lensless imaging, optical transmittance is preferred to be designed in binary form to facilitate the implementation of the coded mask; however, using a training algorithm based on continuous optimization, the output transmittance should be a continuous value.
Therefore, an additional technique is required to realize the binarization of mask variables.
To address this issue, Horisaki {\it et al.} simply binarized the mask variables after training~\cite{Horisaki_etal_DeeplyCoded_OL_2020}.
Instead of manual binarization, Bacca {\it et al.} also proposed the end-to-end optimization of the lensless imaging system, where they enforced mask parameters to be quantized, and these quantized values can be enforced to be $0$ and $1$~\cite{Bacca_etal_DeepCoded_IEEE_2021}.
%where they enforced a quantization constraint during training that enforces the mask parameters to fall into one of the multiple predetermined values, some of which may be 0 and 1~\cite{Bacca_etal_DeepCoded_IEEE_2021}.
To the best of our knowledge, the coded mask optimization processes proposed in previous studies have generated random coded masks because they do not impose any constraints on the shape in the spatial structure of the coded masks' parameters.
When considering DOF extension, it is reasonable to constrain the mask shape to be radial, based on prior knowledge of physics.

% Present motivation of this research (radial optimization, empirical validation), and overview of the paper (explain sections)
\subsection{Paper Overview}
%Even though the radial coded mask has been proposed in a previous work, it hasn't been further analyzed. The optimal parameters for it haven't been searched, and validation for the extended depth of field in real scenarios has not been shown. 
In this work, we address the optimization of the radial mask for lensless imaging and the verification of the extended-DOF lensless imaging by optical experiments with a prototype. Our contributions are: (1) we proposed a radial-shape-preserving optimization scheme, in order to systematically identify the best parameters considering modulation transfer function~(MTF) for a radial mask; (2) we quantitatively and qualitatively validated the extended DOF capabilities of the optimized radial coded mask through simulations; and (3) we built a prototype lensless camera and empirically validated the extended DOF of the radial coded mask.