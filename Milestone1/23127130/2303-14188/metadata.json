{
    "arxiv_id": "2303.14188",
    "paper_title": "Learning from Few Demonstrations with Frame-Weighted Motion Generation",
    "authors": [
        "Jianyong Sun",
        "Jihong Zhu",
        "Jens Kober",
        "Michael Gienger"
    ],
    "submission_date": "2023-03-24",
    "revised_dates": [
        "2023-03-30"
    ],
    "latest_version": 2,
    "categories": [
        "cs.RO"
    ],
    "abstract": "Learning from Demonstration (LfD) aims to encode versatile skills from human demonstrations. The field has been gaining popularity since it facilitates knowledge transfer to robots without requiring expert knowledge in robotics. During task executions, the robot motion is usually influenced by constraints imposed by environments. In light of this, task-parameterized LfD (TP-LfD) encodes relevant contextual information in reference frames, enabling better skill generalization to new situations. However, most TP-LfD algorithms require multiple demonstrations in various environment conditions to ensure sufficient statistics for a meaningful model. It is not a trivial task for robot users to create different situations and perform demonstrations under all of them. Therefore, this paper presents a novel concept for learning motion policies from few demonstrations by finding the reference frame weights which capture frame importance/relevance during task executions. Experimental results in both simulation and real robotic environments validate our approach.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.14188v1",
        "http://arxiv.org/pdf/2303.14188v2"
    ],
    "publication_venue": "Submitted to RA-L"
}