@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, V. and Kavukcuoglu, K. and Silver, D. and Rusu, A. A. and Veness, J. and Bellemare, M. G. and Graves, A. and Riedmiller, M. and Fidjeland, A. K and Ostrovski, G. and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}
 
@article{wolner2017enhancing,
  title={Enhancing skin cancer diagnosis with dermoscopy},
  author={Wolner, Zachary J and Y{\'e}lamos, Oriol and Liopyris, Konstantinos and Rogers, Tova and Marchetti, Michael A and Marghoob, Ashfaq A},
  journal={Dermatologic clinics},
  volume={35},
  number={4},
  pages={417--437},
  year={2017},
  publisher={Elsevier}
}

@article{acosta2022multimodal,
  title={Multimodal biomedical AI},
  author={Acosta, Juli{\'a}n N and Falcone, Guido J and Rajpurkar, Pranav and Topol, Eric J},
  journal={Nature Medicine},
  volume={28},
  number={9},
  pages={1773--1784},
  year={2022},
  publisher={Nature Publishing Group}
}

@article{b1,
  title={Global prevalence of glaucoma and projections of glaucoma burden through 2040: a systematic review and meta-analysis},
  author={Tham, Yih-Chung and Li, Xiang and Wong, Tien Y and Quigley, Harry A and Aung, Tin and Cheng, Ching-Yu},
  journal={Ophthalmology},
  volume={121},
  number={11},
  pages={2081--2090},
  year={2014},
  publisher={Elsevier}
}


@article{b2,
  title={The economic burden of major adult visual disorders in the United States},
  author={Rein, David B and Zhang, Ping and Wirth, Kathleen E and Lee, Paul P and Hoerger, Thomas J and McCall, Nancy and Klein, Ronald and Tielsch, James M and Vijan, Sandeep and Saaddine, Jinan},
  journal={Archives of ophthalmology},
  volume={124},
  number={12},
  pages={1754--1760},
  year={2006},
  publisher={American Medical Association}
}

@article{b3,
  title={The pathophysiology and treatment of glaucoma: a review},
  author={Weinreb, Robert N and Aung, Tin and Medeiros, Felipe A},
  journal={Jama},
  volume={311},
  number={18},
  pages={1901--1911},
  year={2014},
  publisher={American Medical Association}
}

@article{b4,
  title={Racial and socioeconomic differences in eye care utilization among Medicare beneficiaries with glaucoma},
  author={Halawa, Omar A and Kolli, Ajay and Oh, Gahee and Mitchell, William G and Glynn, Robert J and Kim, Dae Hyun and Friedman, David S and Zebardast, Nazlee},
  journal={Ophthalmology},
  volume={129},
  number={4},
  pages={397--405},
  year={2022},
  publisher={Elsevier}
}
@article{b5,
  title={Racial and ethnic disparities in adherence to glaucoma follow-up visits in a county hospital population},
  author={Murakami, Yohko and Lee, Bradford W and Duncan, Martin and Kao, Andrew and Huang, Jehn-Yu and Singh, Kuldev and Lin, Shan C},
  journal={Archives of Ophthalmology},
  volume={129},
  number={7},
  pages={872--878},
  year={2011},
  publisher={American Medical Association}
}
@article{b6,
  title={Race and ethnicity differences in disease severity and visual field progression among glaucoma patients},
  author={Halawa, Omar A and Jin, Qingying and Pasquale, Louis R and Kang, Jae H and Lorch, Alice C and Sobrin, Lucia and Miller, Joan W and Li, Yangjiani and Eslami, Mohammad and Wang, Mengyu and others},
  journal={American Journal of Ophthalmology},
  year={2022},
  publisher={Elsevier}
}
@article{b7,
  title={Artificial intelligence in health care: will the value match the hype?},
  author={Emanuel, Ezekiel J and Wachter, Robert M},
  journal={Jama},
  volume={321},
  number={23},
  pages={2281--2282},
  year={2019},
  publisher={American Medical Association}
}
@article{b8,
  title={Glaucoma management in the era of artificial intelligence},
  author={Devalla, Sripad Krishna and Liang, Zhang and Pham, Tan Hung and Boote, Craig and Strouthidis, Nicholas G and Thiery, Alexandre H and Girard, Michael JA},
  journal={British Journal of Ophthalmology},
  volume={104},
  number={3},
  pages={301--311},
  year={2020},
  publisher={BMJ Publishing Group Ltd}
}
@article{b9,
  title={Workforce H. National and Regional Projections of Supply and Demand for Surgical Specialty Practitioners: 2013-2025 The National Center for Health Workforce Analysis (the National Center) informs public and private-sector decision-making on the U National and Regional},
  author={Work, H.},
  year={2013--2025},
}
@article{sevastopolsky2017optic,
  title={Optic disc and cup segmentation methods for glaucoma detection with modification of U-Net convolutional neural network},
  author={Sevastopolsky, Artem},
  journal={Pattern Recognition and Image Analysis},
  volume={27},
  number={3},
  pages={618--624},
  year={2017},
  publisher={Springer}
}
@article{liao2019clinical,
  title={Clinical interpretable deep learning model for glaucoma diagnosis},
  author={Liao, WangMin and Zou, BeiJi and Zhao, RongChang and Chen, YuanQiong and He, ZhiYou and Zhou, MengJie},
  journal={IEEE journal of biomedical and health informatics},
  volume={24},
  number={5},
  pages={1405--1412},
  year={2019},
  publisher={IEEE}
}
@article{pascal2022multi,
  title={Multi-task deep learning for glaucoma detection from color fundus images},
  author={Pascal, Lucas and Perdomo, Oscar J and Bost, Xavier and Huet, Benoit and Ot{\'a}lora, Sebastian and Zuluaga, Maria A},
  journal={Scientific Reports},
  volume={12},
  number={1},
  pages={1--10},
  year={2022},
  publisher={Springer}
}
@article{akter2022glaucoma,
  title={Glaucoma diagnosis using multi-feature analysis and a deep learning technique},
  author={Akter, Nahida and Fletcher, John and Perry, Stuart and Simunovic, Matthew P and Briggs, Nancy and Roy, Maitreyee},
  journal={Scientific Reports},
  volume={12},
  number={1},
  pages={1--12},
  year={2022},
  publisher={Nature Publishing Group}
}
@article{veena2022novel,
  title={A novel optic disc and optic cup segmentation technique to diagnose glaucoma using deep learning convolutional neural network over retinal fundus images},
  author={Veena, HN and Muruganandham, A and Kumaran, T Senthil},
  journal={Journal of King Saud University-Computer and Information Sciences},
  volume={34},
  number={8},
  pages={6187--6198},
  year={2022},
  publisher={Elsevier}
}

@article{ajitha2021identification,
  title={Identification of glaucoma from fundus images using deep learning techniques},
  author={Ajitha, S and Akkara, John D and Judy, MV},
  journal={Indian Journal of Ophthalmology},
  volume={69},
  number={10},
  pages={2702},
  year={2021},
  publisher={Wolters Kluwer--Medknow Publications}
}

@inproceedings{shoukat2021deep,
  title={A Deep Learning-based Automatic Method for Early Detection of the Glaucoma using Fundus Images},
  author={Shoukat, Ayesha and Akbar, Shahzad and Safdar, Khadija},
  booktitle={2021 International Conference on Innovative Computing (ICIC)},
  pages={1--6},
  year={2021},
  organization={IEEE}
}

@article{hemelings2020accurate,
  title={Accurate prediction of glaucoma from colour fundus images with a convolutional neural network that relies on active and transfer learning},
  author={Hemelings, Ruben and Elen, Bart and Barbosa-Breda, Joao and Lemmens, Sophie and Meire, Maarten and Pourjavan, Sayeh and Vandewalle, Evelien and Van de Veire, Sara and Blaschko, Matthew B and De Boever, Patrick and others},
  journal={Acta ophthalmologica},
  volume={98},
  number={1},
  pages={e94--e100},
  year={2020},
  publisher={Wiley Online Library}
}

@article{maheshwari2017iterative,
  title={Iterative variational mode decomposition based automated detection of glaucoma using fundus images},
  author={Maheshwari, Shishir and Pachori, Ram Bilas and Kanhangad, Vivek and Bhandary, Sulatha V and Acharya, U Rajendra},
  journal={Computers in biology and medicine},
  volume={88},
  pages={142--149},
  year={2017},
  publisher={Elsevier}
}

@article{civit2020dual,
  title={Dual machine-learning system to aid glaucoma diagnosis using disc and cup feature extraction},
  author={Civit-Masot, Javier and Dom{\'\i}nguez-Morales, Manuel J and Vicente-D{\'\i}az, Saturnino and Civit, Anton},
  journal={IEEE Access},
  volume={8},
  pages={127519--127529},
  year={2020},
  publisher={IEEE}
}

@article{yu2019robust,
  title={Robust optic disc and cup segmentation with deep learning for glaucoma detection},
  author={Yu, Shuang and Xiao, Di and Frost, Shaun and Kanagasingam, Yogesan},
  journal={Computerized Medical Imaging and Graphics},
  volume={74},
  pages={61--71},
  year={2019},
  publisher={Elsevier}
}

@article{juneja2020automated,
  title={Automated detection of Glaucoma using deep learning convolution network (G-net)},
  author={Juneja, Mamta and Singh, Shaswat and Agarwal, Naman and Bali, Shivank and Gupta, Shubham and Thakur, Niharika and Jindal, Prashant},
  journal={Multimedia Tools and Applications},
  volume={79},
  number={21},
  pages={15531--15553},
  year={2020},
  publisher={Springer}
}

@article{phan2019evaluation,
  title={Evaluation of deep convolutional neural networks for glaucoma detection},
  author={Phan, Sang and Satoh, Shinâ€™ichi and Yoda, Yoshioki and Kashiwagi, Kenji and Oshika, Tetsuro},
  journal={Japanese journal of ophthalmology},
  volume={63},
  number={3},
  pages={276--283},
  year={2019},
  publisher={Springer}
}

@article{shibata2018development,
  title={Development of a deep residual learning algorithm to screen for glaucoma from fundus photography},
  author={Shibata, Naoto and Tanito, Masaki and Mitsuhashi, Keita and Fujino, Yuri and Matsuura, Masato and Murata, Hiroshi and Asaoka, Ryo},
  journal={Scientific reports},
  volume={8},
  number={1},
  pages={1--9},
  year={2018},
  publisher={Nature Publishing Group}
}

@article{christopher2018performance,
  title={Performance of deep learning architectures and transfer learning for detecting glaucomatous optic neuropathy in fundus photographs},
  author={Christopher, Mark and Belghith, Akram and Bowd, Christopher and Proudfoot, James A and Goldbaum, Michael H and Weinreb, Robert N and Girkin, Christopher A and Liebmann, Jeffrey M and Zangwill, Linda M},
  journal={Scientific reports},
  volume={8},
  number={1},
  pages={1--13},
  year={2018},
  publisher={Nature Publishing Group}
}

@article{raghavendra2018deep,
  title={Deep convolution neural network for accurate diagnosis of glaucoma using digital fundus images},
  author={Raghavendra, U and Fujita, Hamido and Bhandary, Sulatha V and Gudigar, Anjan and Tan, Jen Hong and Acharya, U Rajendra},
  journal={Information Sciences},
  volume={441},
  pages={41--49},
  year={2018},
  publisher={Elsevier}
}

@article{abbas2017glaucoma,
  title={Glaucoma-deep: detection of glaucoma eye disease on retinal fundus images using deep learning},
  author={Abbas, Qaisar},
  journal={International Journal of Advanced Computer Science and Applications},
  volume={8},
  number={6},
  year={2017},
  publisher={Science and Information (SAI) Organization Limited}
}

@article{b10,
  title={The changing face of primary open-angle glaucoma in the United States: demographic and geographic changes from 2011 to 2050},
  author={Vajaranant, Thasarat S and Wu, Shuang and Torres, Mina and Varma, Rohit},
  journal={American journal of ophthalmology},
  volume={154},
  number={2},
  pages={303--314},
  year={2012},
  publisher={Elsevier}
}
@article{b11,
  title={Blindness and glaucoma: a comparison of patients progressing to blindness from glaucoma with patients maintaining vision},
  author={Oliver, Jessica E and Hattenhauer, Matthew G and Herman, David and Hodge, David O and Kennedy, Robert and Fang-Yen, Michael and Johnson, Douglas H},
  journal={American journal of ophthalmology},
  volume={133},
  number={6},
  pages={764--772},
  year={2002},
  publisher={Elsevier}
}
@article{b12,
  title={Risk and risk factors for blindness from glaucoma},
  author={Chen, Philip P},
  journal={Current opinion in ophthalmology},
  volume={15},
  number={2},
  pages={107--111},
  year={2004},
  publisher={LWW}
}

@article{b13,
  title={History of artificial intelligence in medicine},
  author={Kaul, Vivek and Enslin, Sarah and Gross, Seth A},
  journal={Gastrointestinal endoscopy},
  volume={92},
  number={4},
  pages={807--812},
  year={2020},
  publisher={Elsevier}
}
@article{b14,
  title={Development and validation of a deep learning system for diabetic retinopathy and related eye diseases using retinal images from multiethnic populations with diabetes},
  author={Ting, Daniel Shu Wei and Cheung, Carol Yim-Lui and Lim, Gilbert and Tan, Gavin Siew Wei and Quang, Nguyen D and Gan, Alfred and Hamzah, Haslina and Garcia-Franco, Renata and San Yeo, Ian Yew and Lee, Shu Yen and others},
  journal={Jama},
  volume={318},
  number={22},
  pages={2211--2223},
  year={2017},
  publisher={American Medical Association}
}
@article{b15,
  title={Efficacy of a deep learning system for detecting glaucomatous optic neuropathy based on color fundus photographs},
  author={Li, Zhixi and He, Yifan and Keel, Stuart and Meng, Wei and Chang, Robert T and He, Mingguang},
  journal={Ophthalmology},
  volume={125},
  number={8},
  pages={1199--1206},
  year={2018},
  publisher={Elsevier}
}
@article{b16,
  title={Collaborative normal tension glaucoma study},
  author={Anderson, Douglas R},
  journal={Current opinion in ophthalmology},
  volume={14},
  number={2},
  pages={86--90},
  year={2003},
  publisher={LWW}
}
@article{b17,
  title={The global extent of undetected glaucoma in adults: a systematic review and meta-analysis},
  author={Soh, Zhi and Yu, Marco and Betzler, Bjorn Kaijun and Majithia, Shivani and Thakur, Sahil and Tham, Yih Chung and Wong, Tien Yin and Aung, Tin and Friedman, David S and Cheng, Ching-Yu},
  journal={Ophthalmology},
  volume={128},
  number={10},
  pages={1393--1404},
  year={2021},
  publisher={Elsevier}
}
@article{b18,
  title={Racial and Sociodemographic Disparities in the Detection of Narrow Angles before Detection of Primary Angle-Closure Glaucoma in the United States},
  author={Apolo, Galo and Bohner, Austin and Pardeshi, Anmol and Lung, Khristina and Toy, Brian and Wong, Brandon and Song, Brian and Camp, Andrew and Xu, Benjamin},
  journal={Ophthalmology Glaucoma},
  year={2022},
  publisher={Elsevier}
}
@article{b19,
  title={Multi-task deep learning for glaucoma detection from color fundus images},
  author={Pascal, Lucas and Perdomo, Oscar J and Bost, Xavier and Huet, Benoit and Ot{\'a}lora, Sebastian and Zuluaga, Maria A},
  journal={Scientific Reports},
  volume={12},
  number={1},
  pages={1--10},
  year={2022},
  publisher={Springer}
}
@article{b20,
  title={PAPILA: Dataset with fundus images and clinical data of both eyes of the same patient for glaucoma assessment},
  author={Kovalyk, Oleksandr and Morales-S{\'a}nchez, Juan and Verd{\'u}-Monedero, Rafael and Sell{\'e}s-Navarro, Inmaculada and Palaz{\'o}n-Cabanes, Ana and Sancho-G{\'o}mez, Jos{\'e}-Luis},
  journal={Scientific Data},
  volume={9},
  number={1},
  pages={1--12},
  year={2022},
  publisher={Nature Publishing Group}
}
@article{b21,
  title={From machine to machine: an OCT-trained deep learning algorithm for objective quantification of glaucomatous damage in fundus photographs},
  author={Medeiros, Felipe A and Jammal, Alessandro A and Thompson, Atalie C},
  journal={Ophthalmology},
  volume={126},
  number={4},
  pages={513--521},
  year={2019},
  publisher={Elsevier}
}
@article{b22,
  title={Artificial intelligence mapping of structure to function in glaucoma},
  author={Mariottoni, Eduardo B and Datta, Shounak and Dov, David and Jammal, Alessandro A and Berchuck, Samuel I and Tavares, Ivan M and Carin, Lawrence and Medeiros, Felipe A},
  journal={Translational vision science \& technology},
  volume={9},
  number={2},
  pages={19--19},
  year={2020},
  publisher={The Association for Research in Vision and Ophthalmology}
}
@article{b23,
  title={Prevalence of open-angle glaucoma and ocular hypertension in Latinos: the Los Angeles Latino Eye Study},
  author={Varma, Rohit and Ying-Lai, Mei and Francis, Brian A and Nguyen, Betsy Bao-Thu and Deneen, Jennifer and Wilson, M Roy and Azen, Stanley P and Los Angeles Latino Eye Study Group and others},
  journal={Ophthalmology},
  volume={111},
  number={8},
  pages={1439--1448},
  year={2004},
  publisher={Elsevier}
}
@article{b24,
  title={Ocular biometric determinants of dark-to-light change in angle width: the Chinese American eye study},
  author={Lifton, Jacob and Burkemper, Bruce and Jiang, Xuejuan and Pardeshi, Anmol A and Richter, Grace and McKean-Cowdin, Roberta and Varma, Rohit and Xu, Benjamin Y},
  journal={American Journal of Ophthalmology},
  volume={237},
  pages={183--192},
  year={2022},
  publisher={Elsevier}
}
@article{liu2019scaling,
  title={Scaling up teleophthalmology for diabetic eye screening: opportunities for widespread implementation in the USA},
  author={Liu, Yao and Torres Diaz, Alejandra and Benkert, Ramsey},
  journal={Current diabetes reports},
  volume={19},
  number={9},
  pages={1--10},
  year={2019},
  publisher={Springer}
}






























@inproceedings{allen2019convergence,
  title={A convergence theory for deep learning via over-parameterization},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
  booktitle={International Conference on Machine Learning},
  pages={242--252},
  year={2019},
  organization={PMLR}
}
@inproceedings{sharma2021connext,
  title={ConnExt-BioBERT: Leveraging Transfer Learning for Brain-Connectivity Extraction from Neuroscience Articles},
  author={Sharma, Ashika and Jayakumar, Jaikishan and Sankaran, Namrata and Mitra, Partha P and Chakraborti, Sutanu and Sreenivasa Kumar, P},
  booktitle={International Conference on Brain Informatics},
  pages={235--244},
  year={2021},
  organization={Springer}
}


@article{nelson2019embed,
  title={To embed or not: network embedding as a paradigm in computational biology},
  author={Nelson, Walter and Zitnik, Marinka and Wang, Bo and Leskovec, Jure and Goldenberg, Anna and Sharan, Roded},
  journal={Frontiers in genetics},
  volume={10},
  pages={381},
  year={2019},
  publisher={Frontiers}
}

@article{peng2019transfer,
  title={Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets},
  author={Peng, Yifan and Yan, Shankai and Lu, Zhiyong},
  journal={BioNLP 2019},
  pages={58},
  year={2019}
}

@inproceedings{scott2018adapted,
  title={Adapted deep embeddings: a synthesis of methods for k-shot inductive transfer learning},
  author={Scott, Tyler R and Ridgeway, Karl and Mozer, Michael C},
  booktitle={Proceedings of the 32nd International Conference on Neural Information Processing Systems},
  pages={76--85},
  year={2018}
}

@inproceedings{zhuang2015supervised,
  title={Supervised representation learning: Transfer learning with deep autoencoders},
  author={Zhuang, Fuzhen and Cheng, Xiaohu and Luo, Ping and Pan, Sinno Jialin and He, Qing},
  booktitle={Twenty-Fourth International Joint Conference on Artificial Intelligence},
  year={2015}
}

@article{stan2021privacy,
  title={Privacy Preserving Domain Adaptation for Semantic Segmentation of Medical Images},
  author={Stan, Serban and Rostami, Mohammad},
  journal={arXiv preprint arXiv:2101.00522},
  year={2021}
}

@article{rostami2021domain,
  title={Domain Adaptation for Sentiment Analysis Using Increased Intraclass Separation},
  author={Rostami, Mohammad and Galstyan, Aram},
  journal={arXiv preprint arXiv:2107.01598},
  year={2021}
}

 @inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}


@inproceedings{sun2019meta,
  title={Meta-transfer learning for few-shot learning},
  author={Sun, Qianru and Liu, Yaoyao and Chua, Tat-Seng and Schiele, Bernt},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={403--412},
  year={2019}
}

@article{pan2009survey,
  title={A survey on transfer learning},
  author={Pan, Sinno Jialin and Yang, Qiang},
  journal={IEEE Transactions on knowledge and data engineering},
  volume={22},
  number={10},
  pages={1345--1359},
  year={2009},
  publisher={IEEE}
}


@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}
@article{hendricks2021generating,
  title={Generating visual explanations with natural language},
  author={Hendricks, Lisa Anne and Rohrbach, Anna and Schiele, Bernt and Darrell, Trevor and Akata, Zeynep},
  journal={Applied AI Letters},
  volume={2},
  number={4},
  pages={e55},
  year={2021},
  publisher={Wiley Online Library}
}

@article{zhang2018top,
  title={Top-down neural attention by excitation backprop},
  author={Zhang, Jianming and Bargal, Sarah Adel and Lin, Zhe and Brandt, Jonathan and Shen, Xiaohui and Sclaroff, Stan},
  journal={International Journal of Computer Vision},
  volume={126},
  number={10},
  pages={1084--1102},
  year={2018},
  publisher={Springer}
}
@article{wang2020generalizing,
  title={Generalizing from a few examples: A survey on few-shot learning},
  author={Wang, Yaqing and Yao, Quanming and Kwok, James Tin Yau and Ni, Lionel Ming-Shuan},
  journal={ACM Computing Surveys},
  volume={53},
  number={3},
  pages={63},
  year={2020}
}
@article{vinyals2016matching,
  title={Matching networks for one shot learning},
  author={Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Wierstra, Daan and others},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{triantafillou2017few,
  title={Few-shot learning through an information retrieval lens},
  author={Triantafillou, Eleni and Zemel, Richard and Urtasun, Raquel},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


@inproceedings{koch2015siamese,
  title={Siamese neural networks for one-shot image recognition},
  author={Koch, Gregory and Zemel, Richard and Salakhutdinov, Ruslan and others},
  booktitle={ICML deep learning workshop},
  volume={2},
  pages={0},
  year={2015},
  organization={Lille}
}

@inproceedings{murabayashi2019towards,
  title={Towards explainable melanoma diagnosis: prediction of clinical indicators using semi-supervised and multi-task learning},
  author={Murabayashi, Seiya and Iyatomi, Hitoshi},
  booktitle={2019 IEEE International Conference on Big Data (Big Data)},
  pages={4853--4857},
  year={2019},
  organization={IEEE}
}
@article{shorfuzzaman2022explainable,
  title={An explainable stacked ensemble of deep learning models for improved melanoma skin cancer detection},
  author={Shorfuzzaman, Mohammad},
  journal={Multimedia Systems},
  volume={28},
  number={4},
  pages={1309--1323},
  year={2022},
  publisher={Springer}
}
@article{nigar2022deep,
  title={A Deep Learning approach based on Explainable Artificial Intelligence for Skin Lesion Classification},
  author={Nigar, Natasha and Umar, Muhammad and Shahzad, Muhammad Kashif and Islam, Shahid and Abalo, Douhadji},
  journal={IEEE Access},
  year={2022},
  publisher={IEEE}
}

@article{miyato2018virtual,
  title={Virtual adversarial training: a regularization method for supervised and semi-supervised learning},
  author={Miyato, Takeru and Maeda, Shin-ichi and Koyama, Masanori and Ishii, Shin},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={8},
  pages={1979--1993},
  year={2018},
  publisher={IEEE}
}

@article{willemink2020preparing,
  title={Preparing medical imaging data for machine learning},
  author={Willemink, Martin J and Koszek, Wojciech A and Hardell, Cailin and Wu, Jie and Fleischmann, Dominik and Harvey, Hugh and Folio, Les R and Summers, Ronald M and Rubin, Daniel L and Lungren, Matthew P},
  journal={Radiology},
  volume={295},
  number={1},
  pages={4--15},
  year={2020},
  publisher={Radiological Society of North America}
}

@article{ovadia2019can,
  title={Can you trust your model's uncertainty? Evaluating predictive uncertainty under dataset shift},
  author={Ovadia, Yaniv and Fertig, Emily and Ren, Jie and Nado, Zachary and Sculley, D and Nowozin, Sebastian and Dillon, Joshua and Lakshminarayanan, Balaji and Snoek, Jasper},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={13991--14002},
  year={2019}
}

@inproceedings{ren1meta,
  title={Meta-Learning for Semi-Supervised Few-Shot Classification},
  author={Ren, Mengye and Triantafillou, Eleni and Ravi, Sachin and Snell, Jake and Swersky, Kevin and Tenenbaum, Joshua B and Larochelle, Hugo and Zemel, Richard S},
  booktitle={Training},
booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{snell2017prototypical,
  title={Prototypical networks for few-shot learning},
  author={Snell, Jake and Swersky, Kevin and Zemel, Richard},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
 @inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1126--1135},
  year={2017},
  organization={PMLR}
}
@inproceedings{li2019large,
  title={Large-scale few-shot learning: Knowledge transfer with class hierarchy},
  author={Li, Aoxue and Luo, Tiange and Lu, Zhiwu and Xiang, Tao and Wang, Liwei},
  booktitle={Proceedings of the ieee/cvf conference on computer vision and pattern recognition},
  pages={7212--7220},
  year={2019}
}
@article{chen2021hierarchical,
  title={Hierarchical graph neural networks for few-shot learning},
  author={Chen, Cen and Li, Kenli and Wei, Wei and Zhou, Joey Tianyi and Zeng, Zeng},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  volume={32},
  number={1},
  pages={240--252},
  year={2021},
  publisher={IEEE}
}


 @article{rostami2022zero,
  title={Zero-shot image classification using coupled dictionary embedding},
  author={Rostami, Mohammad and Kolouri, Soheil and Murez, Zak and Owechko, Yuri and Eaton, Eric and Kim, Kuyngnam},
  journal={Machine Learning with Applications},
  volume={8},
  pages={100278},
  year={2022},
  publisher={Elsevier}
}


@inproceedings{iqbal2019actor,
  title={Actor-attention-critic for multi-agent reinforcement learning},
  author={Iqbal, Shariq and Sha, Fei},
  booktitle={International Conference on Machine Learning},
  pages={2961--2970},
  year={2019},
  organization={PMLR}
}

@inproceedings{wang2019sentence,
  title={Sentence Embedding Alignment for Lifelong Relation Extraction},
  author={Wang, Hong and Xiong, Wenhan and Yu, Mo and Guo, Xiaoxiao and Chang, Shiyu and Wang, William Yang},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={796--806},
  year={2019}
}


@article{wang2019domain,
  title={Domain adaptation with neural embedding matching},
  author={Wang, Zengmao and Du, Bo and Guo, Yuhong},
  journal={IEEE transactions on neural networks and learning systems},
  volume={31},
  number={7},
  pages={2387--2397},
  year={2019},
  publisher={IEEE}
}
 @inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}
@book{rostami2021transfer,
  title={Transfer Learning Through Embedding Spaces},
  author={Rostami, Mohammad},
  year={2021},
  publisher={CRC Press}
}


@article{da2019survey,
  title={A survey on transfer learning for multiagent reinforcement learning systems},
  author={Da Silva, Felipe Leno and Costa, Anna Helena Reali},
  journal={Journal of Artificial Intelligence Research},
  volume={64},
  pages={645--703},
  year={2019}
}

@article{chen2018lifelong,
  title={Lifelong machine learning},
  author={Chen, Zhiyuan and Liu, Bing},
  journal={Synthesis Lectures on Artificial Intelligence and Machine Learning},
  volume={12},
  number={3},
  pages={1--207},
  year={2018},
  publisher={Morgan \& Claypool Publishers}
}
@book{shalev2014understanding,
  title={Understanding machine learning: From theory to algorithms},
  author={Shalev-Shwartz, Shai and Ben-David, Shai},
  year={2014},
  publisher={Cambridge university press}
}

@article{ben2007analysis,
  title={Analysis of representations for domain adaptation},
  author={Ben-David, Shai and Blitzer, John and Crammer, Koby and Pereira, Fernando and others},
  journal={Advances in neural information processing systems},
  volume={19},
  pages={137},
  year={2007},
  publisher={MIT; 1998}
}
@inproceedings{zhang2017curriculum,
  title={Curriculum domain adaptation for semantic segmentation of urban scenes},
  author={Zhang, Yang and David, Philip and Gong, Boqing},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2020--2030},
  year={2017}
}
 
  @inproceedings{baktashmotlagh2013unsupervised,
  title={Unsupervised domain adaptation by domain invariant projection},
  author={Baktashmotlagh, M. and Harandi, M.  and Lovell, B. and Salzmann, M.},
  booktitle={ International Conference on Computer Vision},
  pages={769--776},
  year={2013}
}

@article{courty2017optimal,
  title={Optimal transport for domain adaptation},
  author={Courty, N. and Flamary, R. and Tuia, D. and Rakotomamonjy, A.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={39},
  number={9},
  pages={1853--1865},
  year={2017},
}

@article{dinu2014improving,
  title={Improving {ZSL} by mitigating the hubness problem},
  author={Dinu, G. and Lazaridou, A. and Baroni, M.},
  journal={arXiv preprint arXiv:1412.6568},
  year={2014}
}

@inproceedings{fernando2013unsupervised,
  title={Unsupervised visual domain adaptation using subspace alignment},
  author={Fernando, B. and Habrard, A. and Sebban, M. and Tuytelaars, T.},
  booktitle={  International Conference on Computer Vision},
  pages={2960--2967},
  year={2013}
} 

 
 
 @inproceedings{rostami2018uda,
  title={Learning a Domain-Invariant Embedding for Unsupervised Domain Adaptation Using Class-Conditioned Distribution Alignment},
  author={Gabourie, A. and Rostami, M. and Kolouri, S. and Kim, K.},
  booktitle={ Allerton Conference on Communication, Control, and Computing  },
  pages={352--359},
  year={2019},
}

 
 
 
 
  @inproceedings{ganin2014unsupervised,
  title={Unsupervised domain adaptation by backpropagation},
  author={Ganin, Y. and Lempitsky, V.},
  booktitle={Proceedings of International Conference on Machine Learning},
  year={2015}
}
@inproceedings{peng2019moment,
  title={Moment matching for multi-source domain adaptation},
  author={Peng, Xingchao and Bai, Qinxun and Xia, Xide and Huang, Zijun and Saenko, Kate and Wang, Bo},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1406--1415},
  year={2019}
}

@misc{CHAOSdata2019,
  title={CHAOS-Combined (CT-MR) Healthy Abdominal Organ Segmentation Challenge Data},
  author={Kavur, Ali Emre and Selver, M Alper and Dicle, Oguz and Bar{\i}s, Mustafa and Gezer, N Sinem},
  month        = {Apr},
  year         = {2019},
  publisher    = {Zenodo},
  version      = {v1.03},
  doi          = {10.5281/zenodo.3362844},
  url          = {https://doi.org/10.5281/zenodo.3362844}
}

@article{ZHUANG201677,
title = "Multi-scale patch and multi-modality atlases for whole heart segmentation of MRI",
journal = "Medical Image Analysis",
volume = "31",
pages = "77 - 87",
year = "2016",
issn = "1361-8415",
doi = "https://doi.org/10.1016/j.media.2016.02.006",
url = "http://www.sciencedirect.com/science/article/pii/S1361841516000219",
author = "Xiahai Zhuang and Juan Shen",
}
@inproceedings{ros2016synthia,
  title={The synthia dataset: A large collection of synthetic images for semantic segmentation of urban scenes},
  author={Ros, German and Sellart, Laura and Materzynska, Joanna and Vazquez, David and Lopez, Antonio M},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3234--3243},
  year={2016}
}

@inproceedings{cordts2016cityscapes,
  title={The cityscapes dataset for semantic urban scene understanding},
  author={Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3213--3223},
  year={2016}
}

 @inproceedings{richter2016playing,
  title={Playing for data: Ground truth from computer games},
  author={Richter, Stephan R and Vineet, Vibhav and Roth, Stefan and Koltun, Vladlen},
  booktitle={European conference on computer vision},
  pages={102--118},
  year={2016},
  organization={Springer}
}


@inproceedings{gupta2017learning,
  title={Learning invariant feature spaces to transfer skills with reinforcement learning},
  author={Gupta, A. and Devin, C. and Liu, Y. and Abbeel, P. and Levine, S.},
   booktitle={Proceedings of the  International Conference on Learning Representations},
  pages={1--122},
  year={2017}
}

 @inproceedings{huang2013cross,
  title={Cross-language knowledge transfer using multilingual deep neural network with shared hidden layers},
  author={Huang, J. and Li, J. and Yu, D. and Deng, L. and Gong, Y.},
  booktitle={International Conference on Acoustics, Speech, and Signal Processing},
  pages={7304--7308},
  year={2013},
}
@article{carass2020evaluating,
  title={Evaluating white matter lesion segmentations with refined S{\o}rensen-Dice analysis},
  author={Carass, Aaron and Roy, Snehashis and Gherman, Adrian and Reinhold, Jacob C and Jesson, Andrew and Arbel, Tal and Maier, Oskar and Handels, Heinz and Ghafoorian, Mohsen and Platel, Bram and others},
  journal={Scientific reports},
  volume={10},
  number={1},
  pages={1--19},
  year={2020},
  publisher={Nature Publishing Group}
}

@inproceedings{isele2016using,
  title={Using Task Features for Zero-Shot Knowledge Transfer in Lifelong Learning.},
  author={Isele, D. and Rostami, M. and Eaton, E.},
  booktitle={Proceedings of the International Joint Conferences on Artificial Intelligence},
  pages={1620--1626},
  year={2016}
}
 
  

@inproceedings{kodirov2015unsupervised,
  title={Unsupervised domain adaptation for zero-shot learning},
  author={Kodirov, E. and Xiang, T. and Fu, Z. and Gong, S.},
  booktitle={ International Conference on Computer Vision},
  pages={2452--2460},
  year={2015}
}

@inproceedings{kodirov2017semantic,
  title={Semantic autoencoder for zero-shot learning},
  author={Kodirov, E. and X., T. and Gong, S.},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year={2017},
  page = {3174--3183}
}

@article{Kumar2012,
author = {Kumar, A. and Daum{\'e}, H.},
journal = {Proceedings of International Conference on Machine Learning},
pages = {1383--1390},
title = {Learning task grouping and overlap in multi-task learning},
year = {2012}
}

@inproceedings{lampert2009learning,
  title={Learning to detect unseen object classes by between-class attribute transfer},
  author={Lampert, C. and Nickisch, H. and Harmeling, S.},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={951--958},
  year={2009},
}

@inproceedings{markatopoulou2016deep,
  title={Deep {MTL} with label correlation constraint for video concept detection},
  author={Markatopoulou, F. and Mezaris, V. and Patras, I.},
  booktitle={ ACM   conf. on Multimedia},
  pages={501--505},
  year={2016},
}
@inproceedings{rannen2017encoder,
 title={Encoder based lifelong learning},
  author={Rannen, A. and Aljundi, R. and Blaschko, M. and Tuytelaars, T.},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1320--1328},
  year={2017}
}
 @inproceedings{romera2015embarrassingly,
  title={An embarrassingly simple approach to {ZSL}},
  author={Romera-Paredes, B. and Torr, P.},
  booktitle={Proceedings of International Conference on Machine Learning},
  pages={2152--2161},
  year={2015}
}
@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

  @inproceedings{kolouri2018joint,
  title={Joint dictionaries for zero-shot learning},
  author={Kolouri, S. and Rostami, M. and Owechko, Y. and Kim, K.},
  booktitle={  Proceedings of the AAAI Conference on Artificial Intelligence  },
  pages = {3431--3439},
  year={2018}
}
 @inproceedings{rostami2018crowdsourcing,
  title={A crowdsourcing triage algorithm for geopolitical event forecasting},
  author={Rostami, M. and Huber, D. and Lu, T.},
  booktitle={ACM RecSys conference},
  pages={377--381},
  year={2018},
}

@inproceedings{rostami2018multi,
  title={Multi-Agent Distributed Lifelong Learning for Collective Knowledge Acquisition},
  author={Rostami, M. and Kolouri, S. and Kim, K. and Eaton, E.},
  booktitle={  International Conference on Autonomous Agents and Multiagent Systems},
  pages={712--720},
  year={2018},
 
}
@inproceedings{rostami2023,
  title={Overcoming Concept Shift in Domain-Aware Settings through Consolidated Internal Distributions},
  author={Rostami, M. and Galstyan, A.},
  booktitle={Thirty-Seventh AAAI Conference on Artificial Intelligence},
  year={2023},
}

@inproceedings{rostami2018fda,
  title={SAR Image Classification Using Few-shot Cross-domain Transfer Learning},
  author={Rostami, M. and Kolouri, S. and Kim, K. and Eaton, E.},
  booktitle={  Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  year={2019},
 
}

 @article{stan2021secure,
  title={Secure Domain Adaptation with Multiple Sources},
  author={Stan, Serban and Rostami, Mohammad},
  journal={arXiv preprint arXiv:2106.12124},
  year={2021}
}

 
@article{rostami2019joint,
  title={Joint Dictionaries for Zero-Shot Learning},
  author={ Rostami, M. and Kolouri, S. and Owechko, Y. and Eaton, R and Kim, K.},
 journal={ Pattern Recognition, under review  },
 year={2019}
}
@inproceedings{jin2021lifelong,
  title={Lifelong Learning of Few-shot Learners across NLP Tasks},
  author={Jin, Xisen and Rostami, Mohammad and Ren, Xiang},
  booktitle={Proceedings of Findings of the EMNLP Conference},
  year={2021}
}
@article{wang2018deep,
  title={Deep visual domain adaptation: A survey},
  author={Wang, Mei and Deng, Weihong},
  journal={Neurocomputing},
  volume={312},
  pages={135--153},
  year={2018},
  publisher={Elsevier}
}
@inproceedings{wei2018person,
  title={Person transfer gan to bridge domain gap for person re-identification},
  author={Wei, Longhui and Zhang, Shiliang and Gao, Wen and Tian, Qi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={79--88},
  year={2018}
}

@inproceedings{venkateswara2017deep,
  title={Deep hashing network for unsupervised domain adaptation},
  author={Venkateswara, Hemanth and Eusebio, Jose and Chakraborty, Shayok and Panchanathan, Sethuraman},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={5018--5027},
  year={2017}
}
@misc{visda2017,
    Author = {Xingchao Peng and Ben Usman and Neela Kaushik and Judy Hoffman and Dequan Wang and Kate Saenko},
    Title = {VisDA: The Visual Domain Adaptation Challenge},
    Year = {2017},
    Eprint = {arXiv:1710.06924},
}
@inproceedings{gong2012geodesic,
  title={Geodesic flow kernel for unsupervised domain adaptation},
  author={Gong, Boqing and Shi, Yuan and Sha, Fei and Grauman, Kristen},
  booktitle={2012 IEEE conference on computer vision and pattern recognition},
  pages={2066--2073},
  year={2012},
  organization={IEEE}
}

@book{muller2010imageclef,
  title={ImageCLEF: experimental evaluation in visual information retrieval},
  author={M{\"u}ller, Henning and Clough, Paul and Deselaers, Thomas and Caputo, Barbara},
  volume={32},
  year={2010},
  publisher={Springer Science \& Business Media}
}

@inproceedings{saenko2010adapting,
  title={Adapting visual category models to new domains},
  author={Saenko, Kate and Kulis, Brian and Fritz, Mario and Darrell, Trevor},
  booktitle={European conference on computer vision},
  pages={213--226},
  year={2010},
  organization={Springer}
}

@article{wilson2020survey,
  title={A survey of unsupervised deep domain adaptation},
  author={Wilson, Garrett and Cook, Diane J},
  journal={ACM Transactions on Intelligent Systems and Technology (TIST)},
  volume={11},
  number={5},
  pages={1--46},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@misc{rostami2020system,
  title={System and method for transferring electro-optical (eo) knowledge for synthetic-aperture-radar (sar)-based object detection},
  author={Rostami, Mohammad and Kolouri, Soheil},
  year={2020},
  month=aug # "~20",
  publisher={Google Patents},
  note={US Patent App. 16/752,527}
}


@inproceedings{rostami2020generative,
  title={Generative continual concept learning},
  author={Rostami, Mohammad and Kolouri, Soheil and Pilly, Praveen and McClelland, James},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={5545--5552},
  year={2020}
}

@inproceedings{rostami2019complementary,
  title={Complementary Learning for Overcoming Catastrophic Forgetting Using Experience Replay},
  author={Rostami, M. and Kolouri, S. and Pilly, P.},
  pages={3339--3345},
  booktitle={Proceedings of the International Joint Conferences on Artificial Intelligence},
  year={2019}
}
 

@inproceedings{stan2021unsupervised,
  title={Unsupervised Model Adaptation for Continual Semantic Segmentation},
  author={Stan, Serban and Rostami, Mohammad},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={3},
  pages={2593--2601},
  year={2021}
}
@inproceedings{ammar2014online,
  title={Online multi-task learning for policy gradient methods},
  author={Ammar, Haitham Bou and Eaton, Eric and Ruvolo, Paul and Taylor, Matthew},
  booktitle={International conference on machine learning},
  pages={1206--1214},
  year={2014},
  organization={PMLR}
}

@article{yin2016abcnn,
  title={Abcnn: Attention-based convolutional neural network for modeling sentence pairs},
  author={Yin, Wenpeng and Sch{\"u}tze, Hinrich and Xiang, Bing and Zhou, Bowen},
  journal={Transactions of the Association for Computational Linguistics},
  volume={4},
  pages={259--272},
  year={2016},
  publisher={MIT Press}
}
@inproceedings{gabourie2019learning,
  title={Learning a domain-invariant embedding for unsupervised domain adaptation using class-conditioned distribution alignment},
  author={Gabourie, Alexander J and Rostami, Mohammad and Pope, Philip E and Kolouri, Soheil and Kim, Kuyngnam},
  booktitle={2019 57th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
  pages={352--359},
  year={2019},
  organization={IEEE}
}


@article{ding2008convex,
  title={Convex and semi-nonnegative matrix factorizations},
  author={Ding, Chris HQ and Li, Tao and Jordan, Michael I},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={32},
  number={1},
  pages={45--55},
  year={2008},
  publisher={IEEE}
}

@inproceedings{noroozi2018boosting,
  title={Boosting self-supervised learning via knowledge transfer},
  author={Noroozi, Mehdi and Vinjimoor, Ananth and Favaro, Paolo and Pirsiavash, Hamed},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={9359--9367},
  year={2018}
}

 @article{isele2017using,
  title={Using Task Descriptions in Lifelong Machine Learning for Improved Performance and Zero-Shot Transfer},
  author={  Rostami,  M. and Isele, D. and Eaton, E.},
  journal={Journal of Artificial Intelligence Research},
  year={2020}
}
@inproceedings{shin2017continual,
  title={Continual learning with deep generative replay},
  author={Shin, H. and Lee, J. and Kim, J. and Kim, J.},
  booktitle={Proceedings of the Neural Information Processing Systems},
  pages={2990--2999},
  year={2017}
}
@inproceedings{rostami2021detection,
  title={Detection and Continual Learning of Novel Face Presentation Attacks},
  author={Rostami, Mohammad and Spinoulas, Leonidas and Hussein, Mohamed and Mathai, Joe and Abd-Almageed, Wael},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year={2021}
}

@article{wah2011caltech,
  title={The caltech-ucsd birds-200-2011 dataset},
  author={Wah, Catherine and Branson, Steve and Welinder, Peter and Perona, Pietro and Belongie, Serge},
  year={2011},
  publisher={California Institute of Technology}
}

 @inproceedings{zhang2017learning,
  title={Learning a deep embedding model for zero-shot learning},
  author={Zhang, Li and Xiang, Tao and Gong, Shaogang},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2021--2030},
  year={2017}
}
 

@article{huynh2022deep,
  title={Deep Learning Radiographic Assessment of Pulmonary Edema: Training with Serum Biomarkers},
  author={Huynh, Justin and Masoudi, Samira and Noorbakhsh, Abraham and Mahmoodi, Amin and Kligerman, Seth and Yen, Andrew and Jacobs, Kathleen and Hahn, Lewis and Hasenstab, Kyle and Pazzani, Michael},
  journal={IEEE Access},
  year={2022},
  publisher={IEEE}
}

@incollection{pazzani2022,
  title={Expert-Informed, User-Centric Explanations for Machine Learning},
  author={Michael Pazzani and Severine Soltani, Robert Kaufman and Samson Qian and Albert Hsiao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence-2022},
  year={2022},
  publisher={IOS Press}
}

@article{qian2021generating,
title = {Generating Explanations for Chest Medical Scan Pneumonia Predictions}, 
url = {https://par.nsf.gov/biblio/10326887}, 
journal = {COVID Information Commons}, 
author = {Samson Qian}, 
year = {2021}
}

@article{hurt2021radiologist,
author = {Hurt, Brian and Rubel, Meagan A and Masutani, Evan M and Jacobs, Kathleen and Hahn, Lewis and Horowitz, Michael and Kligerman, Seth and Hsiao, Albert},
journal = {Journal of Thoracic Imaging},
month = {Oct},
number = {00},
pages = {1--10},
title = {{Radiologist-supervised Transfer Learning}},
year = {2021}
}

@article{carlile2020deployment,
  title={Deployment of artificial intelligence for radiographic diagnosis of {COVID-19} pneumonia in the emergency department},
  author={Carlile, Morgan and Hurt, Brian and Hsiao, Albert and Hogarth, Michael and Longhurst, Christopher A and Dameff, Christian},
  journal={Journal of the American College of Emergency Physicians Open},
  volume={1},
  number={6},
  pages={1459--1464},
  year={2020},
  publisher={Wiley Online Library}
}
@book{tufte1997visual,
  title={Visual explanations},
  author={Tufte, Edward R and Robins, David},
  year={1997},
  publisher={Graphics Cheshire, CT}
}
@article{isic2018,
  author    = {Noel C. F. Codella and
               Veronica Rotemberg and
               Philipp Tschandl and
               M. Emre Celebi and
               Stephen W. Dusza and
               David A. Gutman and
               Brian Helba and
               Aadi Kalloo and
               Konstantinos Liopyris and
               Michael A. Marchetti and
               Harald Kittler and
               Allan Halpern},
  title     = {Skin Lesion Analysis Toward Melanoma Detection 2018: {A} Challenge
               Hosted by the International Skin Imaging Collaboration {(ISIC)}},
  journal   = {CoRR},
  volume    = {abs/1902.03368},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.03368},
  eprinttype = {arXiv},
  eprint    = {1902.03368},
  timestamp = {Tue, 29 Jun 2021 15:47:36 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1902-03368.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{dutta2016vgg,
  title={VGG image annotator (VIA)},
  author={Dutta, Abhishek and Gupta, Ankush and Zissermann, Andrew},
  journal={URL: http://www. robots. ox. ac. uk/vgg/software/via},
  volume={2},
  year={2016}
}
@article{kass2002ocular,
  title={The Ocular Hypertension Treatment Study: a randomized trial determines that topical ocular hypotensive medication delays or prevents the onset of primary open-angle glaucoma},
  author={Kass, Michael A and Heuer, Dale K and Higginbotham, Eve J and Johnson, Chris A and Keltner, John L and Miller, J Philip and Parrish, Richard K and Wilson, M Roy and Gordon, Mae O and Ocular Hypertension Treatment Study Group and others},
  journal={Archives of ophthalmology},
  volume={120},
  number={6},
  pages={701--713},
  year={2002},
  publisher={American Medical Association}
}
 @inproceedings{verma2018generalized,
  title={Generalized zero-shot learning via synthesized examples},
  author={Verma, Vinay Kumar and Arora, Gundeep and Mishra, Ashish and Rai, Piyush},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4281--4289},
  year={2018}
}
@inproceedings{xian2017zero,
  title={Zero-shot learning-the good, the bad and the ugly},
  author={Xian, Yongqin and Schiele, Bernt and Akata, Zeynep},
  booktitle={Proceedings of the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4582--4591},
  year={2017}
}
@article{rostami2019deep,
  title={Deep transfer learning for few-shot SAR image classification},
  author={Rostami, Mohammad and Kolouri, Soheil and Eaton, Eric and Kim, Kyungnam},
  journal={Remote Sensing},
  volume={11},
  number={11},
  pages={1374},
  year={2019},
  publisher={Multidisciplinary Digital Publishing Institute}
}


@inproceedings{schonfeld2019generalized,
  title={Generalized zero-and few-shot learning via aligned variational autoencoders},
  author={Schonfeld, Edgar and Ebrahimi, Sayna and Sinha, Samarth and Darrell, Trevor and Akata, Zeynep},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={8247--8255},
  year={2019}
}
@inproceedings{aljundi2018memory,
  title={Memory aware synapses: Learning what (not) to forget},
  author={Aljundi, Rahaf and Babiloni, Francesca and Elhoseiny, Mohamed and Rohrbach, Marcus and Tuytelaars, Tinne},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={139--154},
  year={2018}
}
@article{liu2017lifelong,
  title={Lifelong machine learning: a paradigm for continuous learning},
  author={Liu, Bing},
  journal={Frontiers of Computer Science},
  volume={11},
  number={3},
  pages={359--361},
  year={2017},
  publisher={Higher Education Press}
}

@article{pomponi2020efficient,
  title={Efficient continual learning in neural networks with embedding regularization},
  author={Pomponi, Jary and Scardapane, Simone and Lomonaco, Vincenzo and Uncini, Aurelio},
  journal={Neurocomputing},
  volume={397},
  pages={139--148},
  year={2020},
  publisher={Elsevier}
}

@article{he2019task,
  title={Task agnostic continual learning via meta learning},
  author={He, Xu and Sygnowski, Jakub and Galashov, Alexandre and Rusu, Andrei A and Teh, Yee Whye and Pascanu, Razvan},
  journal={arXiv preprint arXiv:1906.05201},
  year={2019}
}
@inproceedings{ebrahimi2020adversarial,
  title={Adversarial continual learning},
  author={Ebrahimi, Sayna and Meier, Franziska and Calandra, Roberto and Darrell, Trevor and Rohrbach, Marcus},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XI 16},
  pages={386--402},
  year={2020},
  organization={Springer}
}

@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Acad Sciences}
}

 @inproceedings{socher2013zero,
  title={Zero-shot learning through cross-modal transfer},
  author={Socher, R. and Ganjoo, M. and Manning, C. and Ng, A.},
  booktitle={Proceedings of the Neural Information Processing Systems},
  pages={935--943},
  year={2013}
}
@inproceedings{sorokin2008utility,
  title={Utility data annotation with amazon mechanical turk},
  author={Sorokin, Alexander and Forsyth, David},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition workshops},
  pages={1--8},
  year={2008},
  organization={IEEE}
}
@article{weiss2016survey,
  title={A survey of transfer learning},
  author={Weiss, Karl and Khoshgoftaar, Taghi M and Wang, DingDing},
  journal={Journal of Big data},
  volume={3},
  number={1},
  pages={1--40},
  year={2016},
  publisher={SpringerOpen}
}
@inproceedings{hadsell2006dimensionality,
  title={Dimensionality reduction by learning an invariant mapping},
  author={Hadsell, Raia and Chopra, Sumit and LeCun, Yann},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  volume={2},
  pages={1735--1742},
  year={2006},
  organization={IEEE}
}

@inproceedings{teh2017distral,
  title={Distral: Robust multitask reinforcement learning},
  author={Teh, Y. and Bapst, V. and Czarnecki, W. M and Quan, J. and Kirkpatrick, J. and Hadsell, R. and Heess, N. and Pascanu, R.},
  booktitle={Proceedings of the Neural Information Processing Systems},
  pages={4496--4506},
  year={2017}
}

@inproceedings{tommasi2012beyond,
  title={Beyond dataset bias: Multi-task unaligned shared knowledge transfer},
  author={Tommasi, T. and Quadrianto, N. and Caputo, B. and Lampert, C.},
  booktitle={Asian Conference on Computer Vision},
  pages={1--15},
  year={2012},
}
@inproceedings{fu2014transductive,
  title={Transductive multi-view embedding for zero-shot recognition and annotation},
  author={Fu, Yanwei and Hospedales, Timothy M and Xiang, Tao and Fu, Zhenyong and Gong, Shaogang},
  booktitle={European conference on computer vision},
  pages={584--599},
  year={2014},
  organization={Springer}
}
@article{van2020brain,
  title={Brain-inspired replay for continual learning with artificial neural networks},
  author={van de Ven, Gido M and Siegelmann, Hava T and Tolias, Andreas S},
  journal={Nature communications},
  volume={11},
  number={1},
  pages={1--14},
  year={2020},
  publisher={Nature Publishing Group}
}

@inproceedings{von2019continual,
  title={Continual learning with hypernetworks},
  author={von Oswald, Johannes and Henning, Christian and Sacramento, Jo{\~a}o and Grewe, Benjamin F},
  booktitle={International Conference on Learning Representations},
  year={2019}
}
 @article{lee1999learning,
  title={Learning the parts of objects by non-negative matrix factorization},
  author={Lee, Daniel D and Seung, H Sebastian},
  journal={Nature},
  volume={401},
  number={6755},
  pages={788--791},
  year={1999},
  publisher={Nature Publishing Group}
}
@article{ruder2019survey,
  title={A survey of cross-lingual word embedding models},
  author={Ruder, Sebastian and Vuli{\'c}, Ivan and S{\o}gaard, Anders},
  journal={Journal of Artificial Intelligence Research},
  volume={65},
  pages={569--631},
  year={2019}
}



@article{courty2016optimal,
  title={Optimal transport for domain adaptation},
  author={Courty, Nicolas and Flamary, R{\'e}mi and Tuia, Devis and Rakotomamonjy, Alain},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={39},
  number={9},
  pages={1853--1865},
  year={2016},
  publisher={IEEE}
}

@inproceedings{vielzeuf2018occam,
  title={An occam's razor view on learning audiovisual emotion recognition with small training sets},
  author={Vielzeuf, Valentin and Kervadec, Corentin and Pateux, St{\'e}phane and Lechervy, Alexis and Jurie, Fr{\'e}d{\'e}ric},
  booktitle={Proceedings of the 20th ACM International Conference on Multimodal Interaction},
  pages={589--593},
  year={2018}
}
@article{robins1995catastrophic,
  title={Catastrophic forgetting, rehearsal and pseudorehearsal},
  author={Robins, Anthony},
  journal={Connection Science},
  volume={7},
  number={2},
  pages={123--146},
  year={1995},
  publisher={Taylor \& Francis}
}
@inproceedings{narayanan2011multimodal,
  title={A multimodal real-time MRI articulatory corpus for speech research},
  author={Narayanan, Shrikanth and Bresch, Erik and Ghosh, Prasanta Kumar and Goldstein, Louis and Katsamanis, Athanasios and Kim, Yoon and Lammert, Adam and Proctor, Michael and Ramanarayanan, Vikram and Zhu, Yinghua},
  booktitle={Twelfth Annual Conference of the International Speech Communication Association},
  year={2011}
}
@article{Ye2021CrossFitAF,
  title={CrossFit: A Few-shot Learning Challenge for Cross-task Generalization in NLP},
  author={Qinyuan Ye and Bill Yuchen Lin and Xiang Ren},
  journal={ArXiv},
  year={2021},
  volume={abs/2104.08835}
}
@inproceedings{sarlin2020superglue,
  title={Superglue: Learning feature matching with graph neural networks},
  author={Sarlin, Paul-Edouard and DeTone, Daniel and Malisiewicz, Tomasz and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4938--4947},
  year={2020}
}

@inproceedings{wang2018glue,
  title={GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},
  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel},
  booktitle={Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
  pages={353--355},
  year={2018}
}
@article{SomComputationalMediaIntelligence:Human-centered,
 author = {Somandepalli, Krishna and Guha, Tanaya and Martinez, Victor and Kumar, Naveen and Adam, Hartwig and Narayanan, Shrikanth },
 doi = {https://doi.org/10.1109/JPROC.2020.3047978},
 journal = {Proceedings of IEEE},
 link = {http://sail.usc.edu/publications/files/CMI-ProcIEEE-2021.pdf},
 title = {Computational Media Intelligence: Human-centered Machine Analysis of Media},
 year = {2021}
}
@article{french1999catastrophic,
  title={Catastrophic forgetting in connectionist networks},
  author={French, Robert M},
  journal={Trends in cognitive sciences},
  volume={3},
  number={4},
  pages={128--135},
  year={1999},
  publisher={Elsevier}
}

@article{li2018survey,
  title={A survey of multi-view representation learning},
  author={Li, Yingming and Yang, Ming and Zhang, Zhongfei},
  journal={IEEE transactions on knowledge and data engineering},
  volume={31},
  number={10},
  pages={1863--1883},
  year={2018},
  publisher={IEEE}
}

@inproceedings{tzeng2017adversarial,
  title={Adversarial discriminative domain adaptation},
  author={Tzeng, E. and Hoffman, J. and Saenko, K. and Darrell, T.},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={7167--7176},
  year={2017}
}
@inproceedings{ruvolo2013ella,
  title={{ELLA}: An efficient lifelong learning algorithm},
  author={Ruvolo, P. and Eaton, E.},
  booktitle={Proceedings of International Conference on Machine Learning},
  pages={507--515},
  year={2013}
}

@inproceedings{zhang2015zero,
  title={Zero-shot learning via semantic similarity embedding},
  author={Zhang, Z. and Saligrama, V.},
  booktitle={ International Conference on Computer Vision},
  pages={4166--4174},
  year={2015}
}

@inproceedings{zhu2017unpaired,
  title={Unpaired image-to-image translation using cycle-consistent adversarial networks},
  author={Zhu, J. and Park, T. and Isola, P. and Efros, A.},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2223--2232},
  year={2017}
}

  

 


@inproceedings{stan2020unsupervised,
  title={Unsupervised Model Adaptation for Continual Semantic Segmentation},
  author={Stan, Serban and Rostami, Mohammad},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence },
  year={2021}
}


 
  
@article{zhao2018adversarial,
  title={Adversarial multiple source domain adaptation},
  author={Zhao, Han and Zhang, Shanghang and Wu, Guanhang and Moura, Jos{\'e} MF and Costeira, Joao P and Gordon, Geoffrey J},
  journal={Proceedings of the Neural Information Processing Systems},
  volume={31},
  pages={8559--8570},
  year={2018}
}

@inproceedings{goodfellow2014generative,
  title={Generative Adversarial Nets},
  author={Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron C and Bengio, Yoshua},
  booktitle={Proceedings of the Neural Information Processing Systems},
  year={2014}
}
 
 



























 
 
 
 
 































 
 
 
 
 































 
 
 
 
 



@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@inproceedings{devlin2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={NAACL-HLT (1)},
  year={2019}
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  pages={1097--1105},
  year={2012}
}

@article{atamna2019accuracy,
  title={The accuracy of a diagnosis of pneumonia in the emergency department},
  author={Atamna, Alaa and Shiber, Shachaf and Yassin, Muhammad and Drescher, Michael J and Bishara, Jihad},
  journal={International Journal of Infectious Diseases},
  volume={89},
  pages={62--65},
  year={2019},
  publisher={Elsevier}
}

@article{behzadi2020deep,
  title={Deep learning, reusable and problem-based architectures for detection of consolidation on chest X-ray images},
  author={Behzadi-Khormouji, Hamed and Rostami, Habib and Salehi, Sana and Derakhshande-Rishehri, Touba and Masoumi, Marzieh and Salemi, Siavash and Keshavarz, Ahmad and Gholamrezanezhad, Ali and Assadi, Majid and Batouli, Ali},
  journal={Computer methods and programs in biomedicine},
  volume={185},
  pages={105162},
  year={2020},
  publisher={Elsevier}
}

@article{bernheim2020chest,
  title={Chest {CT} findings in coronavirus disease-19 {(COVID-19)}: relationship to duration of infection},
  author={Bernheim, Adam and Mei, Xueyan and Huang, Mingqian and Yang, Yang and Fayad, Zahi A and Zhang, Ning and Diao, Kaiyue and Lin, Bin and Zhu, Xiqi and Li, Kunwei and others},
  journal={Radiology},
  pages={200463},
  year={2020},
  publisher={Radiological Society of North America}
}

 

@article{caruana1997multitask,
  title={Multitask learning},
  author={Caruana, Rich},
  journal={Machine learning},
  volume={28},
  number={1},
  pages={41--75},
  year={1997},
  publisher={Springer}
}

@inproceedings{cheng2020boundary,
  title={Boundary-preserving mask r-cnn},
  author={Cheng, Tianheng and Wang, Xinggang and Huang, Lichao and Liu, Wenyu},
  booktitle={European conference on computer vision},
  pages={660--676},
  year={2020},
  organization={Springer}
}

@article{duncan2021covid,
  title={{COVID-19} data sharing and collaboration},
  author={Duncan, Dominique},
  journal={Communications in Information and Systems},
  volume={21},
  number={3},
  pages={325--340},
  year={2021},
  publisher={International Press of Boston}
}

@incollection{feghahati2020cdeepex,
  title={CDeepEx: Contrastive Deep Explanations},
  author={Feghahati, Amir and Shelton, Christian R and Pazzani, Michael J and Tang, Kevin},
  booktitle={ECAI 2020},
  pages={1143--1151},
  year={2020},
  publisher={IOS Press}
}
 

@article{henry2020imaging,
  title={Imaging findings of vaping-associated lung injury},
  author={Henry, Travis S and Kligerman, Seth J and Raptis, Constantine A and Mann, Howard and Sechrist, Jacob W and Kanne, Jeffrey P},
  journal={American Journal of Roentgenology},
  volume={214},
  number={3},
  pages={498--505},
  year={2020},
  publisher={Am Roentgen Ray Soc}
}

@article{hurt2020augmenting,
  title={Augmenting interpretation of chest radiographs with deep learning probability maps},
  author={Hurt, Brian and Yen, Andrew and Kligerman, Seth and Hsiao, Albert},
  journal={Journal of thoracic imaging},
  volume={35},
  number={5},
  pages={285--293},
  year={2020},
  publisher={LWW}
}

@article{kligerman2020radiologic,
  title={Radiologic, pathologic, clinical, and physiologic findings of electronic cigarette or vaping product use--associated lung injury (EVALI): evolving knowledge and remaining questions},
  author={Kligerman, Seth and Raptis, Costa and Larsen, Brandon and Henry, Travis S and Caporale, Alessandra and Tazelaar, Henry and Schiebler, Mark L and Wehrli, Felix W and Klein, Jeffrey S and Kanne, Jeffrey},
  journal={Radiology},
  volume={294},
  number={3},
  pages={491--505},
  year={2020},
  publisher={Radiological Society of North America}
}

 

@ARTICLE{radloop1,
  author={Marvasti, Neda B. and YÃ¶rÃ¼k, Erdem and Acar, Burak},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Computer-Aided Medical Image Annotation: Preliminary Results With Liver Lesions in CT}, 
  year={2018},
  volume={22},
  number={5},
  pages={1561-1570},
  doi={10.1109/JBHI.2017.2771211}}

@article{radloop2,
  title={The ethical adoption of artificial intelligence in radiology},
  author={Mudgal, Keshav Shree and Das, Neelanjan},
  journal={BJR| Open},
  volume={2},
  number={1},
  pages={20190020},
  year={2020},
  publisher={The British Institute of Radiology.}
}

@article{radloop3,
  title={The future of radiology augmented with artificial intelligence: a strategy for success},
  author={Liew, Charlene},
  journal={European journal of radiology},
  volume={102},
  pages={152--156},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{irvin2019chexpert,
  title={Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison},
  author={Irvin, Jeremy and Rajpurkar, Pranav and Ko, Michael and Yu, Yifan and Ciurea-Ilcus, Silviana and Chute, Chris and Marklund, Henrik and Haghgoo, Behzad and Ball, Robyn and Shpanskaya, Katie and others},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  pages={590--597},
  year={2019}
}

@inproceedings{jing2015visual,
  title={Visual search at pinterest},
  author={Jing, Yushi and Liu, David and Kislyuk, Dmitry and Zhai, Andrew and Xu, Jiajing and Donahue, Jeff and Tavel, Sarah},
  booktitle={Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={1889--1898},
  year={2015}
}

@article{kim2019loni,
  title={The {LONI QC} system: a semi-automated, web-based and freely-available environment for the comprehensive quality control of neuroimaging data},
  author={Kim, Hosung and Irimia, Andrei and Hobel, Samuel M and Pogosyan, Mher and Tang, Haoteng and Petrosyan, Petros and Blanco, Rita Esquivel Castelo and Duffy, Ben A and Zhao, Lu and Crawford, Karen L and others},
  journal={Frontiers in neuroinformatics},
  volume={13},
  pages={60},
  year={2019},
  publisher={Frontiers}
}

@inproceedings{koh2020concept,
  title={Concept bottleneck models},
  author={Koh, Pang Wei and Nguyen, Thao and Tang, Yew Siang and Mussmann, Stephen and Pierson, Emma and Kim, Been and Liang, Percy},
  booktitle={International Conference on Machine Learning},
  pages={5338--5348},
  year={2020},
  organization={PMLR}
}
 
@article{lakhani2020endotracheal,
  title={Endotracheal Tube Position Assessment on Chest Radiographs Using Deep Learning},
  author={Lakhani, Paras and Flanders, Adam and Gorniak, Richard},
  journal={Radiology: Artificial Intelligence},
  volume={3},
  number={1},
  pages={e200026},
  year={2020},
  publisher={Radiological Society of North America}
}
@article{schaefer2020use,
  title={The use of machine learning in rare diseases: a scoping review},
  author={Schaefer, Julia and Lehne, Moritz and Schepers, Josef and Prasser, Fabian and Thun, Sylvia},
  journal={Orphanet journal of rare diseases},
  volume={15},
  number={1},
  pages={1--10},
  year={2020},
  publisher={Springer}
}
@article{shaban2021deep,
  title={A deep-learning framework for the detection of oil spills from SAR data},
  author={Shaban, Mohamed and Salim, Reem and Abu Khalifeh, Hadil and Khelifi, Adel and Shalaby, Ahmed and El-Mashad, Shady and Mahmoud, Ali and Ghazal, Mohammed and El-Baz, Ayman},
  journal={Sensors},
  volume={21},
  number={7},
  pages={2351},
  year={2021},
  publisher={Multidisciplinary Digital Publishing Institute}
}
 

@inproceedings{sung2018learning,
  title={Learning to compare: Relation network for few-shot learning},
  author={Sung, Flood and Yang, Yongxin and Zhang, Li and Xiang, Tao and Torr, Philip HS and Hospedales, Timothy M},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1199--1208},
  year={2018}
}

@article{pawar2019deep,
  title={Deep learning approaches for video-based anomalous activity detection},
  author={Pawar, Karishma and Attar, Vahida},
  journal={World Wide Web},
  volume={22},
  number={2},
  pages={571--601},
  year={2019},
  publisher={Springer}
}

@article{lassau2021integrating,
  title={Integrating deep learning CT-scan model, biological and clinical variables to predict severity of {COVID-19} patients},
  author={Lassau, Nathalie and Ammari, Samy and Chouzenoux, Emilie and Gortais, Hugo and Herent, Paul and Devilder, Matthieu and Soliman, Samer and Meyrignac, Olivier and Talabard, Marie-Pauline and Lamarque, Jean-Philippe and others},
  journal={Nature communications},
  volume={12},
  number={1},
  pages={1--11},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={Nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{li2020automated,
  title={Automated assessment and tracking of {COVID-19} pulmonary disease severity on chest radiographs using convolutional siamese neural networks},
  author={Li, Matthew D and Arun, Nishanth Thumbavanam and Gidwani, Mishka and Chang, Ken and Deng, Francis and Little, Brent P and Mendoza, Dexter P and Lang, Min and Lee, Susanna I and Oâ€™Shea, Aileen and others},
  journal={Radiology: Artificial Intelligence},
  volume={2},
  number={4},
  pages={e200079},
  year={2020},
  publisher={Radiological Society of North America}
}

@inproceedings{lundberg2017unified,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott M and Lee, Su-In},
  booktitle={Proceedings of the 31st international conference on neural information processing systems},
  pages={4768--4777},
  year={2017}
}

@article{ma2021image,
  title={Image matching from handcrafted to deep features: A survey},
  author={Ma, Jiayi and Jiang, Xingyu and Fan, Aoxiang and Jiang, Junjun and Yan, Junchi},
  journal={International Journal of Computer Vision},
  volume={129},
  number={1},
  pages={23--79},
  year={2021},
  publisher={Springer}
}

@article{noguerol2019strengths,
  title={Strengths, weaknesses, opportunities, and threats analysis of artificial intelligence and machine learning applications in radiology},
  author={Noguerol, Teodoro Mart{\'\i}n and Paulano-Godino, F{\'e}lix and Mart{\'\i}n-Valdivia, Mar{\'\i}a Teresa and Menias, Christine O and Luna, Antonio},
  journal={Journal of the American College of Radiology},
  volume={16},
  number={9},
  pages={1239--1247},
  year={2019},
  publisher={Elsevier}
}
@inproceedings{li2022multimodal,
  title={Multimodal information fusion for glaucoma and diabetic retinopathy classification},
  author={Li, Yihao and El Habib Daho, Mostafa and Conze, Pierre-Henri and Al Hajj, Hassan and Bonnin, Sophie and Ren, Hugang and Manivannan, Niranchana and Magazzeni, Stephanie and Tadayoni, Ramin and Cochener, B{\'e}atrice and others},
  booktitle={International Workshop on Ophthalmic Medical Image Analysis},
  pages={53--62},
  year={2022},
  organization={Springer}
}
@article{mehta2021multimodal,
  title={Multimodal etiology of drug induced angle closure with topical glaucoma therapy},
  author={Mehta, Aditya and Lewis, Andrew},
  journal={American Journal of Ophthalmology Case Reports},
  volume={23},
  pages={101152},
  year={2021},
  publisher={Elsevier}
}
@article{bowd2022primary,
  title={Primary Open-Angle Glaucoma Detection with Vision Transformer: Improved Generalization Across Independent Fundus Photograph Datasets},
  author={Bowd, Christopher and Fan, Rui and Alipour, Kamran and Christopher, Mark and Brye, Nicole and Proudfoot, James A and Goldbaum, Michael Henry and Belghith, Akram and Girkin, Christopher A and Fazio, Massimo A and others},
  journal={Investigative Ophthalmology \& Visual Science},
  volume={63},
  number={7},
  pages={2295--2295},
  year={2022},
  publisher={The Association for Research in Vision and Ophthalmology}
}
@inproceedings{touvron2021training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={International Conference on Machine Learning},
  pages={10347--10357},
  year={2021},
  organization={PMLR}
}
 @inproceedings{kim2021vilt,
  title={Vilt: Vision-and-language transformer without convolution or region supervision},
  author={Kim, Wonjae and Son, Bokyung and Kim, Ildoo},
  booktitle={International Conference on Machine Learning},
  pages={5583--5594},
  year={2021},
  organization={PMLR}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International Conference on Machine Learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}


@article{randhawa2021generalisability,
  title={Generalisability and performance of an OCT-based deep learning classifier for community-based and hospital-based detection of gonioscopic angle closure},
  author={Randhawa, Jasmeen and Chiang, Michael and Porporato, Natalia and Pardeshi, Anmol A and Dredge, Justin and Aroca, Galo Apolo and Tun, Tin A and Quah, Joanne HuiMin and Tan, Marcus and Higashita, Risa and others},
  journal={British Journal of Ophthalmology},
  year={2021},
  publisher={BMJ Publishing Group Ltd}
}

@article{lee2020clinical,
  title={Clinical applications of continual learning machine learning},
  author={Lee, Cecilia S and Lee, Aaron Y},
  journal={The Lancet Digital Health},
  volume={2},
  number={6},
  pages={e279--e281},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{srinivasan2022climb,
  title={CLiMB: A Continual Learning Benchmark for Vision-and-Language Tasks},
  author={Srinivasan, Tejas and Chang, Ting-Yun and Alva, Leticia Leonor Pinto and Chochlakis, Georgios and Rostami, Mohammad and Thomason, Jesse},
  booktitle={Conference on Neural Information Processing Systems},
  year={2022}
}


@article{fan2022detecting,
  title={Detecting Glaucoma from Fundus Photographs Using Deep Learning without Convolutions: Transformer for Improved Generalization},
  author={Fan, Rui and Alipour, Kamran and Bowd, Christopher and Christopher, Mark and Brye, Nicole and Proudfoot, James A and Goldbaum, Michael H and Belghith, Akram and Girkin, Christopher A and Fazio, Massimo A and others},
  journal={Ophthalmology Science},
  pages={100233},
  year={2022},
  publisher={Elsevier}
}
@article{thompson2020review,
  title={A review of deep learning for screening, diagnosis, and detection of glaucoma progression},
  author={Thompson, Atalie C and Jammal, Alessandro A and Medeiros, Felipe A},
  journal={Translational Vision Science \& Technology},
  volume={9},
  number={2},
  pages={42--42},
  year={2020},
  publisher={The Association for Research in Vision and Ophthalmology}
}
@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{wu2022seatrans,
  title={SeATrans: Learning Segmentation-Assisted Diagnosis Model via Transformer},
  author={Wu, Junde and Fang, Huihui and Shang, Fangxin and Yang, Dalu and Wang, Zhaowei and Gao, Jing and Yang, Yehui and Xu, Yanwu},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={677--687},
  year={2022},
  organization={Springer}
}

@article{song2021deep,
  title={Deep relation transformer for diagnosing glaucoma with optical coherence tomography and visual field function},
  author={Song, Diping and Fu, Bin and Li, Fei and Xiong, Jian and He, Junjun and Zhang, Xiulan and Qiao, Yu},
  journal={IEEE Transactions on Medical Imaging},
  volume={40},
  number={9},
  pages={2392--2402},
  year={2021},
  publisher={IEEE}
}

@article{deperlioglu2022explainable,
  title={Explainable framework for Glaucoma diagnosis by image processing and convolutional neural network synergy: analysis with doctor evaluation},
  author={Deperlioglu, Omer and Kose, Utku and Gupta, Deepak and Khanna, Ashish and Giampaolo, Fabio and Fortino, Giancarlo},
  journal={Future Generation Computer Systems},
  volume={129},
  pages={152--169},
  year={2022},
  publisher={Elsevier}
}

@article{kamal2022explainable,
  title={Explainable AI for Glaucoma Prediction Analysis to Understand Risk Factors in Treatment Planning},
  author={Kamal, Md Sarwar and Dey, Nilanjan and Chowdhury, Linkon and Hasan, Syed Irtija and Santosh, KC},
  journal={IEEE Transactions on Instrumentation and Measurement},
  volume={71},
  pages={1--9},
  year={2022},
  publisher={IEEE}
}

@article{oh2021explainable,
  title={Explainable machine learning model for glaucoma diagnosis and its interpretation},
  author={Oh, Sejong and Park, Yuli and Cho, Kyong Jin and Kim, Seong Jae},
  journal={Diagnostics},
  volume={11},
  number={3},
  pages={510},
  year={2021},
  publisher={MDPI}
}

@inproceedings{wang2022multimodal,
  title={Multimodal Token Fusion for Vision Transformers},
  author={Wang, Yikai and Chen, Xinghao and Cao, Lele and Huang, Wenbing and Sun, Fuchun and Wang, Yunhe},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12186--12195},
  year={2022}
}


@article{dalmaz2022resvit,
  author={Dalmaz, Onat and Yurt, Mahmut and {\c{C}}ukur, Tolga},
  journal={IEEE Transactions on Medical Imaging},
  volume={41},
  number={10},
  pages={2598--2614},
  year={2022},
  publisher={IEEE}
}
@article{orlando2020refuge,
  title={Refuge challenge: A unified framework for evaluating automated methods for glaucoma assessment from fundus photographs},
  author={Orlando, Jos{\'e} Ignacio and Fu, Huazhu and Breda, Jo{\~a}o Barbosa and van Keer, Karel and Bathula, Deepti R and Diaz-Pinto, Andr{\'e}s and Fang, Ruogu and Heng, Pheng-Ann and Kim, Jeyoung and Lee, JoonHo and others},
  journal={Medical image analysis},
  volume={59},
  pages={101570},
  year={2020},
  publisher={Elsevier}
}

@article{kovalyk2022papila,
  title={PAPILA: Dataset with fundus images and clinical data of both eyes of the same patient for glaucoma assessment},
  author={Kovalyk, Oleksandr and Morales-S{\'a}nchez, Juan and Verd{\'u}-Monedero, Rafael and Sell{\'e}s-Navarro, Inmaculada and Palaz{\'o}n-Cabanes, Ana and Sancho-G{\'o}mez, Jos{\'e}-Luis},
  journal={Scientific Data},
  volume={9},
  number={1},
  pages={1--12},
  year={2022},
  publisher={Nature Publishing Group}
}


@article{mehta2021automated,
  title={Automated detection of glaucoma with interpretable machine learning using clinical data and multimodal retinal images},
  author={Mehta, Parmita and Petersen, Christine A and Wen, Joanne C and Banitt, Michael R and Chen, Philip P and Bojikian, Karine D and Egan, Catherine and Lee, Su-In and Balazinska, Magdalena and Lee, Aaron Y and others},
  journal={American Journal of Ophthalmology},
  volume={231},
  pages={154--169},
  year={2021},
  publisher={Elsevier}
}


@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={International Conference on Medical image computing and computer-assisted intervention},
  pages={234--241},
  year={2015},
  organization={Springer}
}
@inproceedings{he2017mask,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2961--2969},
  year={2017}
}

@article{parida2018fuzzy,
  title={Fuzzy clustering based transition region extraction for image segmentation},
  author={Parida, Priyadarsan and Bhoi, Nilamani},
  journal={Engineering Science and Technology, an International Journal},
  volume={21},
  number={4},
  pages={547--563},
  year={2018},
  publisher={Elsevier}
}



@article{Xu2018fuzzy,
  title={Effectiveness of glaucoma screening and factors associated with follow-up adherence among glaucoma suspects in a safety net teleretinal screening program},
  author={Yuen, Jenay and  Xu, Benjamin and   Song1, Brian and  Daskivich, Lauren and  Rodman, John and   Wong, Brandon},
  journal={Ophthalmology},
  year={2022},
  publisher={Elsevier}
}


 Glaucoma

@article{saba2019region,
  title={Region extraction and classification of skin cancer: A heterogeneous framework of deep CNN features fusion and reduction},
  author={Saba, Tanzila and Khan, Muhammad Attique and Rehman, Amjad and Marie-Sainte, Souad Larabi},
  journal={Journal of medical systems},
  volume={43},
  number={9},
  pages={1--19},
  year={2019},
  publisher={Springer}
}


@article{nagao1979region,
  title={Region extraction and shape analysis in aerial photographs},
  author={Nagao, Makoto and Matsuyama, Takashi and Ikeda, Yoshio},
  journal={Computer Graphics and Image Processing},
  volume={10},
  number={3},
  pages={195--223},
  year={1979},
  publisher={Elsevier}
}


@article{duncan2021covid,
  title={{COVID-19} data sharing and collaboration},
  author={Duncan, Dominique},
  journal={Communications in Information and Systems},
  volume={21},
  number={3},
  pages={325--340},
  year={2021},
  publisher={International Press of Boston}
}


@article{he2021partimagenet,
  title={PartImageNet: A Large, High-Quality Dataset of Parts},
  author={He, Ju and Yang, Shuo and Yang, Shaokang and Kortylewski, Adam and Yuan, Xiaoding and Chen, Jie-Neng and Liu, Shuai and Yang, Cheng and Yuille, Alan},
  journal={arXiv preprint arXiv:2112.00933},
  year={2021}
}

@inproceedings{AhamedAverage,
  title={Ensembles for Improved Explanation of Image Classification},
  author={Ahamed,Aadil  and Alipour, Kamran  and Kumar, Sateesh  and Pazzani, Michael},
  booktitle={CVPR workshop on  Explainable Artificial Intelligence for Computer Vision (XAI4CV)},
  year={2022}
}
@misc{munera2019deep,
  title={Deep learning for chest radiography in the emergency department},
  author={Munera, Felipe and Infante, Juan C},
  year={2019},
  publisher={Radiological Society of North America}
}

@article{murphy2020covid,
  title={{COVID-19} on chest radiographs: a multireader evaluation of an artificial intelligence system},
  author={Murphy, Keelin and Smits, Henk and Knoops, Arnoud JG and Korst, Michael BJM and Samson, Tijs and Scholten, Ernst T and Schalekamp, Steven and Schaefer-Prokop, Cornelia M and Philipsen, Rick HHM and Meijers, Annet and others},
  journal={Radiology},
  volume={296},
  number={3},
  pages={E166--E172},
  year={2020},
  publisher={Radiological Society of North America}
}

@inproceedings{pazzani2018explaining,
  title={Explaining Contrasting Categories.},
  author={Pazzani, Michael J and Feghahati, Amir and Shelton, Christian R and Seitz, Aaron R},
  booktitle={IUI Workshops},
  year={2018}
}

@article{rajpurkar2018deep,
  title={Deep learning for chest radiograph diagnosis: A retrospective comparison of the CheXNeXt algorithm to practicing radiologists},
  author={Rajpurkar, Pranav and Irvin, Jeremy and Ball, Robyn L and Zhu, Kaylie and Yang, Brandon and Mehta, Hershel and Duan, Tony and Ding, Daisy and Bagul, Aarti and Langlotz, Curtis P and others},
  journal={PLoS medicine},
  volume={15},
  number={11},
  pages={e1002686},
  year={2018},
  publisher={Public Library of Science San Francisco, CA USA}
}

@inproceedings{domingos2000unified,
  title={A unified bias-variance decomposition},
  author={Domingos, Pedro},
  booktitle={Proceedings of 17th International Conference on Machine Learning},
  pages={231--238},
  year={2000}
}

@article{retson2020clinical,
  title={Clinical performance and role of expert supervision of deep learning for cardiac ventricular volumetry: a validation study},
  author={Retson, Tara A and Masutani, Evan M and Golden, Daniel and Hsiao, Albert},
  journal={Radiology: Artificial Intelligence},
  pages={e190064},
  year={2020},
  publisher={Radiological Society of North America}
}

@article{rex2003loni,
  title={The {LONI} pipeline processing environment},
  author={Rex, David E and Ma, Jeffrey Q and Toga, Arthur W},
  journal={Neuroimage},
  volume={19},
  number={3},
  pages={1033--1048},
  year={2003},
  publisher={Elsevier}
}

@article{reyes2020interpretability,
  title={On the interpretability of artificial intelligence in radiology: challenges and opportunities},
  author={Reyes, Mauricio and Meier, Raphael and Pereira, S{\'e}rgio and Silva, Carlos A and Dahlweid, Fried-Michael and Tengg-Kobligk, Hendrik von and Summers, Ronald M and Wiest, Roland},
  journal={Radiology: Artificial Intelligence},
  volume={2},
  number={3},
  pages={e190043},
  year={2020},
  publisher={Radiological Society of North America}
}

@InProceedings{10.1007/978-3-319-24574-4_28,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
}

@inproceedings{hume1996learning,
  title={Learning sets of related concepts: A shared task model},
  author={Hume, Tim and Pazzani, M},
  booktitle={Proceedings of the Eighteenth Annual Conference of the Cognitive Science Society},
  year={1996},
  organization={Citeseer}
}
@article{pazzani2001acceptance, 
  title={Acceptance of rules generated by machine learning among medical experts},
  author={Pazzani, Michael J and Mani, S and Shankle, William R},
  journal={Methods of information in medicine},
  volume={40},
  number={05},
  pages={380--385},
  year={2001},
  publisher={Schattauer GmbH}
}

@article{caruana2003benefitting,
  title={Benefitting from the variables that variable selection discards},
  author={Caruana, Rich and Sa, Virginia R de},
  journal={Journal of machine learning research},
  volume={3},
  number={Mar},
  pages={1245--1264},
  year={2003}
}

@article{samek2016evaluating,
  title={Evaluating the visualization of what a deep neural network has learned},
  author={Samek, Wojciech and Binder, Alexander and Montavon, Gr{\'e}goire and Lapuschkin, Sebastian and M{\"u}ller, Klaus-Robert},
  journal={IEEE transactions on neural networks and learning systems},
  volume={28},
  number={11},
  pages={2660--2673},
  year={2016},
  publisher={IEEE}
}

@article{shih2019augmenting,
  title={Augmenting the National Institutes of Health chest radiograph dataset with expert annotations of possible pneumonia},
  author={Shih, George and Wu, Carol C and Halabi, Safwan S and Kohli, Marc D and Prevedello, Luciano M and Cook, Tessa S and Sharma, Arjun and Amorosa, Judith K and Arteaga, Veronica and Galperin-Aizenberg, Maya and others},
  journal={Radiology: Artificial Intelligence},
  volume={1},
  number={1},
  pages={e180041},
  year={2019},
  publisher={Radiological Society of North America}
}
@article{jonas1998optic,
  title={Optic neuropathy resembling normal-pressure glaucoma in a teenager with congenital macrodiscs},
  author={Jonas, Jost B and Cursiefen, Claus and Budde, Wido M},
  journal={Archives of Ophthalmology},
  volume={116},
  number={10},
  pages={1384--1386},
  year={1998},
  publisher={American Medical Association}
}
@article{wang2019automated,
  title={Automated CT and MRI liver segmentation and biometry using a generalized convolutional neural network},
  author={Wang, Kang and Mamidipalli, Adrija and Retson, Tara and Bahrami, Naeim and Hasenstab, Kyle and Blansit, Kevin and Bass, Emily and Delgado, Timoteo and Cunha, Guilherme and Middleton, Michael S and others},
  journal={Radiology: Artificial Intelligence},
  volume={1},
  number={2},
  pages={180022},
  year={2019},
  publisher={Radiological Society of North America}
}

@inproceedings{wang2017chestx,
  title={Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases},
  author={Wang, Xiaosong and Peng, Yifan and Lu, Le and Lu, Zhiyong and Bagheri, Mohammadhadi and Summers, Ronald M},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2097--2106},
  year={2017}
}

@article{wehbe2021deepcovid,
  title={DeepCOVID-XR: an artificial intelligence algorithm to detect {COVID-19} on chest radiographs trained and tested on a large US clinical data set},
  author={Wehbe, Ramsey M and Sheng, Jiayue and Dutta, Shinjan and Chai, Siyuan and Dravid, Amil and Barutcu, Semih and Wu, Yunan and Cantrell, Donald R and Xiao, Nicholas and Allen, Bradley D and others},
  journal={Radiology},
  volume={299},
  number={1},
  pages={E167--E176},
  year={2021},
  publisher={Radiological Society of North America}
}

@article{wu2020comparison,
  title={Comparison of chest radiograph interpretations by artificial intelligence algorithm vs radiology residents},
  author={Wu, Joy T and Wong, Ken CL and Gur, Yaniv and Ansari, Nadeem and Karargyris, Alexandros and Sharma, Arjun and Morris, Michael and Saboury, Babak and Ahmad, Hassan and Boyko, Orest and others},
  journal={JAMA network open},
  volume={3},
  number={10},
  pages={e2022779--e2022779},
  year={2020},
  publisher={American Medical Association}
}

@article{zech2018variable,
  title={Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: a cross-sectional study},
  author={Zech, John R and Badgeley, Marcus A and Liu, Manway and Costa, Anthony B and Titano, Joseph J and Oermann, Eric Karl},
  journal={PLoS medicine},
  volume={15},
  number={11},
  pages={e1002683},
  year={2018},
  publisher={Public Library of Science San Francisco, CA USA}
}

@inproceedings{zhang2018similarity,
  title={Similarity-based active learning for image classification under class imbalance},
  author={Zhang, Chuanhai and Tavanapong, Wallapak and Kijkul, Gavin and Wong, Johnny and De Groen, Piet C and Oh, JungHwan},
  booktitle={2018 IEEE international conference on data mining (ICDM)},
  pages={1422--1427},
  year={2018},
  organization={IEEE}
}
@article{vinyals2016show,
  title={Show and tell: Lessons learned from the 2015 mscoco image captioning challenge},
  author={Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={39},
  number={4},
  pages={652--663},
  year={2016},
  publisher={IEEE}
}
@inproceedings{noh2015learning,
  title={Learning deconvolution network for semantic segmentation},
  author={Noh, Hyeonwoo and Hong, Seunghoon and Han, Bohyung},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1520--1528},
  year={2015}
}
@inproceedings{kim2018interpretability,
  title={Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav)},
  author={Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and others},
  booktitle={International conference on machine learning},
  pages={2668--2677},
  year={2018},
  organization={PMLR}
}
@article{zhu2020deep,
  title={Deep transfer learning artificial intelligence accurately stages {COVID-19} lung disease severity on portable chest radiographs},
  author={Zhu, Jocelyn and Shen, Beiyi and Abbasi, Almas and Hoshmand-Kochi, Mahsa and Li, Haifang and Duong, Tim Q},
  journal={PloS one},
  volume={15},
  number={7},
  pages={e0236621},
  year={2020},
  publisher={Public Library of Science San Francisco, CA USA}
}

@incollection{lesgold1988expertise,
  title={Expertise in a complex skill: Diagnosing x-ray pictures.},
  author={Alan Lesgold and Harriet Rubinson and  Paul Feltovich and Robert Glaser and Dale Klopfer and Yen Wang},
  year={1988},
  publisher={Lawrence Erlbaum Associates, Inc},
   pages        = {311--342},
  booktitle    = {The nature of expertise},
  editor       = {M. T. H. Chi and R. Glaser and M. J. Farr}

}


@article{kaufmann,
  title={Principles for Designing User-Centered XAI Explanation Interfaces for Radiology},
  author={Kaufmann, Robert and Pazzani, Michael},
  journal={ACM Transactions on Computer-Human Interaction (TOCHI)},
  year={submitted},
  publisher={ACM New York, NY}
}
   @inproceedings{li2022siamese,
  title={Siamese Contrastive Embedding Network for Compositional Zero-Shot Learning},
  author={Li, Xiangyu and Yang, Xu and Wei, Kun and Deng, Cheng and Yang, Muli},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9326--9335},
  year={2022}
}

@article{chicco2021siamese,
  title={Siamese neural networks: An overview},
  author={Chicco, Davide},
  journal={Artificial Neural Networks},
  pages={73--94},
  year={2021},
  publisher={Springer}
}

@article{pazzani1991influence,
  title={Influence of prior knowledge on concept acquisition: Experimental and computational results.},
  author={Pazzani, Michael J},
  journal={Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume={17},
  number={3},
  pages={416},
  year={1991},
  publisher={American Psychological Association}
}

@article{hurt2020deep,
  title={Deep learning localization of pneumonia: 2019 coronavirus {(COVID-19)} outbreak},
  author={Hurt, Brian and Kligerman, Seth and Hsiao, Albert},
  journal={Journal of Thoracic Imaging},
  volume={35},
  year={2020},
  publisher={Wolters Kluwer Health}
}

@article{shi2020review,
  title={Review of artificial intelligence techniques in imaging data acquisition, segmentation, and diagnosis for COVID-19},
  author={Shi, Feng and Wang, Jun and Shi, Jun and Wu, Ziyan and Wang, Qian and Tang, Zhenyu and He, Kelei and Shi, Yinghuan and Shen, Dinggang},
  journal={IEEE reviews in biomedical engineering},
  volume={14},
  pages={4--15},
  year={2020},
  publisher={IEEE}
}

@article{bai2020performance,
  title={Performance of radiologists in differentiating COVID-19 from non-COVID-19 viral pneumonia at chest CT},
  author={Bai, Harrison X and Hsieh, Ben and Xiong, Zeng and Halsey, Kasey and Choi, Ji Whae and Tran, Thi My Linh and Pan, Ian and Shi, Lin-Bo and Wang, Dong-Cui and Mei, Ji and others},
  journal={Radiology},
  volume={296},
  number={2},
  pages={E46--E54},
  year={2020},
  publisher={Radiological Society of North America}
}

@article{cruz2020composition,
  title={On the Composition and Limitations of Publicly Available COVID-19 X-Ray Imaging Datasets},
  author={Cruz, Beatriz Garcia Santa and S{\"o}lter, Jan and Bossa, Matias Nicolas and Husch, Andreas Dominik},
  journal={arXiv preprint arXiv:2008.11572},
  year={2020}
}

\textbf{Title: Principles for Designing User-Centered XAI Explanation Interfaces for Radiology
Authors: Robert Kaufman, David Kirsh, Michael Pazzani
Venue: ACM Transactions on Computer-Human Interaction (ToCHI)
under review}

@article{tests,
  title={Diagnostic Tests and Sample Techniques of {COVID-19}: A Review},
  author={Yujia Zhang and Rachael Garner and Sana Salehi and Marianna La Rocca and Dominique Duncan},
  journal={Future Virology},
   note={Submitted},
  year={2021}
}

@article{vaccine,
  title={{COVID-19} Vaccination Dynamics in the {US}: Coverage Velocity and Carrying Capacity Based on Socio-demographic Vulnerability Indices in {California}},
  author={Alexander Bruckhaus and Aidin Abedi and Trevor A. Pickering and Yujia Zhang and Aubrey Martinez and Matthew Lai and Rachael Garner and Dominique Duncan},
  journal={Journal of Immigrant and Minority Health},
   note={In press},
  year={2021}
}

@article{jiaju,
  title={Siamese Neural Networks for Detection of {COVID-19} in Computed Tomography Scans},
  author={Jiaju Liu and Rachael Garner and Marianna La Rocca and Sana Salehi and Dominique Duncan},
  journal={Computer Methods and Programs in Biomedicine},
   note={In revisions},
  year={2021}
}

@article{noor,
  title={Key radiological features of {COVID-19} chest {CT} scans with a focus on special subgroups: a literature review},
  author={Noor Nouaili and Rachael Garner and Sana Salehi and Marianna La Rocca and Dominique Duncan},
  journal={Current Problems in Diagnostic Radiology},
   note={In revisions},
  year={2021}
}

@article{aksh,
  title={Efficient and Visualizable Convolutional Neural Networks for {COVID-19} Classification Using Chest {CT} Expert Systems With Applications},
  author={Aksh Garg and Sana Salehi and Marianna La Rocca and Rachael Garner and Dominique Duncan},
  journal={Expert Systems with Applications},
   note={In revisions},
  year={2021}
}

@article{azrin,
  title={A Novel Threshold-Based Segmentation Method for Quantification of {COVID-19} Lung Infection},
  author={Azrin Khan and Rachael Garner and Marianna La Rocca and Dominique Duncan},
  journal={Signal, Image and Video Processing},
   note={Submitted},
  year={2021}
}

@article{alexis,
  title={Evaluation of transfer learning models on detection of {COVID-19} from chest {CT} scans},
  author={Alexis Bennett and Rachael Garner and Marianna La Rocca and Ali Valehi and Dominique Duncan},
  journal={Medical and Biological Engineering and Computing},
  note={Submitted},
  year={2021}
}


@article{aubrey,
  title={Post-Lockdown Infection Rates of {COVID-19} Following the Reopening of Public Businesses},
  author={Alexander Bruckhaus and Aubrey Martinez and Rachael Garner and Marianna La Rocca and Dominique Duncan},
  journal={Journal of Public Health},
  note={In Press},
  year={August 2021}
}

@article{zhang2021association,
  title={Association between {ABO} blood types and coronavirus disease 2019 {(COVID-19)}, genetic associations, and underlying molecular mechanisms: a literature review of 23 studies},
  author={Zhang, Yujia and Garner, Rachael and Salehi, Sana and La Rocca, Marianna and Duncan, Dominique},
  journal={Annals of Hematology},
  pages={1--10},
  year={2021},
  publisher={Springer}
}


@article{feghahati_cdeepex_2020,
	title = {{CDeepEx}: {Contrastive} {Deep} {Explanations}},
	shorttitle = {{CDeepEx}},
	doi = {10.3233/FAIA200212},
	urldate = {2022-01-14},
	journal = {ECAI 2020},
	author = {Feghahati, Amir and Shelton, Christian R. and Pazzani, Michael J. and Tang, Kevin},
	year = {2020},
	note = {Publisher: IOS Press},
	pages = {1143--1151},
	file = {Full Text PDF:C\:\\Users\\Severine\\Zotero\\storage\\UVHEPB7I\\Feghahati et al. - 2020 - CDeepEx Contrastive Deep Explanations.pdf:application/pdf;Snapshot:C\:\\Users\\Severine\\Zotero\\storage\\AS2NJ98W\\FAIA200212.html:text/html},
}

@article{petsiuk_rise_2018,
	title = {{RISE}: {Randomized} {Input} {Sampling} for {Explanation} of {Black}-box {Models}},
	shorttitle = {{RISE}},
	abstract = {Deep neural networks are being used increasingly to automate data analysis and decision making, yet their decision-making process is largely unclear and is difficult to explain to the end users. In this paper, we address the problem of Explainable AI for deep neural networks that take images as input and output a class probability. We propose an approach called RISE that generates an importance map indicating how salient each pixel is for the model's prediction. In contrast to white-box approaches that estimate pixel importance using gradients or other internal network state, RISE works on black-box models. It estimates importance empirically by probing the model with randomly masked versions of the input image and obtaining the corresponding outputs. We compare our approach to state-of-the-art importance extraction methods using both an automatic deletion/insertion metric and a pointing metric based on human-annotated object segments. Extensive experiments on several benchmark datasets show that our approach matches or exceeds the performance of other methods, including white-box approaches. Project page: http://cs-people.bu.edu/vpetsiuk/rise/},
	urldate = {2022-01-14},
	journal = {arXiv:1806.07421 [cs]},
	author = {Petsiuk, Vitali and Das, Abir and Saenko, Kate},
	year = {2018},
	note = {arXiv: 1806.07421},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\Severine\\Zotero\\storage\\JRUV6Q9L\\Petsiuk et al. - 2018 - RISE Randomized Input Sampling for Explanation of.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Severine\\Zotero\\storage\\VUY6KDMH\\1806.html:text/html},
}

@article{muddamsetty_introducing_2021,
	title = {Introducing and assessing the explainable {AI} ({XAI})method: {SIDU}},
	shorttitle = {Introducing and assessing the explainable {AI} ({XAI})method},
	abstract = {Explainable Artificial Intelligence (XAI) has in recent years become a well-suited framework to generate human understandable explanations of black box models. In this paper, we present a novel XAI visual explanation algorithm denoted SIDU that can effectively localize entire object regions responsible for prediction in a full extend. We analyze its robustness and effectiveness through various computational and human subject experiments. In particular, we assess the SIDU algorithm using three different types of evaluations (Application, Human and Functionally-Grounded) to demonstrate its superior performance. The robustness of SIDU is further studied in presence of adversarial attack on black box models to better understand its performance.},
	urldate = {2022-01-14},
	journal = {arXiv:2101.10710 [cs]},
	author = {Muddamsetty, Satya M. and Jahromi, Mohammad N. S. and Ciontos, Andreea E. and Fenoy, Laura M. and Moeslund, Thomas B.},
	year = {2021},
	note = {arXiv: 2101.10710},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence, Computer Scieamirnce - Human-Computer Interaction, Computer Science - Machine Learning},
	annote = {Comment: Preprint-submitted to Journal of Pattern Recognition (Elsevier)},
	file = {arXiv Fulltext PDF:C\:\\Users\\Severine\\Zotero\\storage\\PG29CJIV\\Muddamsetty et al. - 2021 - Introducing and assessing the explainable AI (XAI).pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Severine\\Zotero\\storage\\XWVAHHL4\\2101.html:text/html},
}

@inproceedings{SoltaniCogSci,
  title={User-Centric Enhancements to Explainable AI Algorithms for Image Classification},
  author={Severine Soltani and Robert Kaufman and Michael Pazzani},
  booktitle={Proceedings of the 44th Annual Conference of the Cognitive Science Society},
  year={2022},

}
@inproceedings{krizhevsky_imagenet_2012,
	title = {{ImageNet} {Classification} with {Deep} {Convolutional} {Neural} {Networks}},
	volume = {25},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	year = {2012},
}

@article{lapuschkin_lrp_2016,
	title = {The {LRP} {Toolbox} for {Artificial} {Neural} {Networks}},
	volume = {17},
	issn = {1533-7928},
	abstract = {The Layer-wise Relevance Propagation (LRP) algorithm explains a classifier's prediction specific to a given data point by attributing relevance scores to important components of the input by using the topology of the learned model itself. With the LRP Toolbox we provide platform-agnostic implementations for explaining the predictions of pre-trained state of the art Caffe networks and stand-alone implementations for fully connected Neural Network models. The implementations for Matlab and python shall serve as a playing field to familiarize oneself with the LRP algorithm and are implemented with readability and transparency in mind. Models and data can be imported and exported using raw text formats, Matlab's .mat files and the .npy format for numpy or plain text.},
	number = {114},
	urldate = {2022-01-14},
	journal = {Journal of Machine Learning Research},
	author = {Lapuschkin, Sebastian and Binder, Alexander and Montavon, GrÃ©goire and MÃ¼ller, Klaus-Robert and Samek, Wojciech},
	year = {2016},
	pages = {1--5},
	file = {Full Text PDF:C\:\\Users\\Severine\\Zotero\\storage\\9YAXYKAK\\Lapuschkin et al. - 2016 - The LRP Toolbox for Artificial Neural Networks.pdf:application/pdf},
}

@article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	copyright = {2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1476-4687},
	doi = {10.1038/nature14539},
	abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
	language = {en},
	number = {7553},
	urldate = {2022-01-14},
	journal = {Nature},
	author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	year = {2015},
	pages = {436--444},
	file = {Snapshot:C\:\\Users\\Severine\\Zotero\\storage\\WU9SDPCD\\nature14539.html:text/html},
}

@article{simonyan_very_2015,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	urldate = {2022-01-14},
	journal = {arXiv:1409.1556 [cs]},
	author = {Simonyan, Karen and Zisserman, Andrew},
	year = {2015},
	note = {arXiv: 1409.1556},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\Severine\\Zotero\\storage\\L3YBDCBW\\Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Severine\\Zotero\\storage\\6N7F2JEB\\1409.html:text/html},
}

@inproceedings{miller2017inmates,
  title={Explainable {AI}: Beware of Inmates Running the Asylum},
  author={Tim Miller and Piers Howe and Liz Sonenberg},
  booktitle={IJCAI 2017 Workshop on Explainable Artificial Intelligence (XAI)},
  year={2017},
}

@inproceedings{bau2017network,
  title={Network dissection: Quantifying interpretability of deep visual representations},
  author={Bau, David and Zhou, Bolei and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6541--6549},
  year={2017}
}

@article{mu2020compositional,
  title={Compositional explanations of neurons},
  author={Mu, Jesse and Andreas, Jacob},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={17153--17163},
  year={2020}
}
@article{zhou2018interpreting,
  title={Interpreting deep visual representations via network dissection},
  author={Zhou, Bolei and Bau, David and Oliva, Aude and Torralba, Antonio},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={9},
  pages={2131--2145},
  year={2018},
  publisher={IEEE}
}

@inproceedings{khorram2021igos++,
  title={iGOS++ integrated gradient optimized saliency by bilateral perturbations},
  author={Khorram, Saeed and Lawson, Tyler and Fuxin, Li},
  booktitle={Proceedings of the Conference on Health, Inference, and Learning},
  pages={174--182},
  year={2021}
}

@article{ribeiro_why_2016,
	title = {"{Why} {Should} {I} {Trust} {You}?": {Explaining} the {Predictions} of {Any} {Classifier}},
	shorttitle = {"{Why} {Should} {I} {Trust} {You}?},
	abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
	urldate = {2022-01-14},
	journal = {arXiv:1602.04938 [cs, stat]},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	year = {2016},
	note = {arXiv: 1602.04938},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Severine\\Zotero\\storage\\MQDK29G8\\Ribeiro et al. - 2016 - Why Should I Trust You Explaining the Predicti.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Severine\\Zotero\\storage\\6IG63PEK\\1602.html:text/html},
}

@inproceedings{selvaraju_grad-cam_2017,
	title = {Grad-{CAM}: {Visual} {Explanations} from {Deep} {Networks} via {Gradient}-{Based} {Localization}},
	shorttitle = {Grad-{CAM}},
	doi = {10.1109/ICCV.2017.74},
	abstract = {We propose a technique for producing `visual explanations' for decisions from a large class of Convolutional Neural Network (CNN)-based models, making them more transparent. Our approach - Gradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of any target concept (say logits for `dog' or even a caption), flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept. Unlike previous approaches, Grad- CAM is applicable to a wide variety of CNN model-families: (1) CNNs with fully-connected layers (e.g. VGG), (2) CNNs used for structured outputs (e.g. captioning), (3) CNNs used in tasks with multi-modal inputs (e.g. visual question answering) or reinforcement learning, without architectural changes or re-training. We combine Grad-CAM with existing fine-grained visualizations to create a high-resolution class-discriminative visualization, Guided Grad-CAM, and apply it to image classification, image captioning, and visual question answering (VQA) models, including ResNet-based architectures. In the context of image classification models, our visualizations (a) lend insights into failure modes of these models (showing that seemingly unreasonable predictions have reasonable explanations), (b) outperform previous methods on the ILSVRC-15 weakly-supervised localization task, (c) are more faithful to the underlying model, and (d) help achieve model generalization by identifying dataset bias. For image captioning and VQA, our visualizations show even non-attention based models can localize inputs. Finally, we design and conduct human studies to measure if Grad-CAM explanations help users establish appropriate trust in predictions from deep networks and show that Grad-CAM helps untrained users successfully discern a `stronger' deep network from a `weaker' one even when both make identical predictions. Our code is available at https: //github.com/ramprs/grad-cam/ along with a demo on CloudCV [2] and video at youtu.be/COjUB9Izk6E.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
	year = {2017},
	note = {ISSN: 2380-7504},
	keywords = {Cats, Computer architecture, Dogs, Knowledge discovery, Visualization},
	pages = {618--626},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Severine\\Zotero\\storage\\S6HWFS7J\\8237336.html:text/html;Submitted Version:C\:\\Users\\Severine\\Zotero\\storage\\ATIAQWS2\\Selvaraju et al. - 2017 - Grad-CAM Visual Explanations from Deep Networks v.pdf:application/pdf},
}

@inproceedings{zeiler_visualizing_2014,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Visualizing and {Understanding} {Convolutional} {Networks}},
	isbn = {978-3-319-10590-1},
	doi = {10.1007/978-3-319-10590-1_53},
	abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
	language = {en},
	booktitle = {Computer {Vision} â€“ {ECCV} 2014},
	publisher = {Springer International Publishing},
	author = {Zeiler, Matthew D. and Fergus, Rob},
	editor = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
	year = {2014},
	keywords = {Convolutional Neural Network, Input Image, Pixel Space, Stochastic Gradient Descent, Training Image},
	pages = {818--833},
	file = {Springer Full Text PDF:C\:\\Users\\Severine\\Zotero\\storage\\TUXNDJWE\\Zeiler and Fergus - 2014 - Visualizing and Understanding Convolutional Networ.pdf:application/pdf},
}

@article{binder_layer-wise_2016,
	title = {Layer-wise {Relevance} {Propagation} for {Neural} {Networks} with {Local} {Renormalization} {Layers}},
	abstract = {Layer-wise relevance propagation is a framework which allows to decompose the prediction of a deep neural network computed over a sample, e.g. an image, down to relevance scores for the single input dimensions of the sample such as subpixels of an image. While this approach can be applied directly to generalized linear mappings, product type non-linearities are not covered. This paper proposes an approach to extend layer-wise relevance propagation to neural networks with local renormalization layers, which is a very common product-type non-linearity in convolutional neural networks. We evaluate the proposed method for local renormalization layers on the CIFAR-10, Imagenet and MIT Places datasets.},
	language = {en},
	urldate = {2022-01-15},
	journal = {arXiv:1604.00825 [cs]},
	author = {Binder, Alexander and Montavon, GrÃ©goire and Bach, Sebastian and MÃ¼ller, Klaus-Robert and Samek, Wojciech},
	year = {2016},
	note = {arXiv: 1604.00825},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Binder et al. - 2016 - Layer-wise Relevance Propagation for Neural Networ.pdf:C\:\\Users\\Severine\\Zotero\\storage\\NWBBCL5H\\Binder et al. - 2016 - Layer-wise Relevance Propagation for Neural Networ.pdf:application/pdf},
}

@article{chattopadhyay_grad-cam_2018,
	title = {Grad-{CAM}++: {Improved} {Visual} {Explanations} for {Deep} {Convolutional} {Networks}},
	shorttitle = {Grad-{CAM}++},
	doi = {10.1109/WACV.2018.00097},
	abstract = {Over the last decade, Convolutional Neural Network (CNN) models have been highly successful in solving complex vision problems. However, these deep models are perceived as â€black boxâ€ methods considering the lack of understanding of their internal functioning. There has been a signiï¬cant recent interest in developing explainable deep learning models, and this paper is an effort in this direction. Building on a recently proposed method called Grad-CAM, we propose a generalized method called Grad-CAM++ that can provide better visual explanations of CNN model predictions, in terms of better object localization as well as explaining occurrences of multiple object instances in a single image, when compared to state-of-the-art. We provide a mathematical derivation for the proposed method, which uses a weighted combination of the positive partial derivatives of the last convolutional layer feature maps with respect to a speciï¬c class score as weights to generate a visual explanation for the corresponding class label. Our extensive experiments and evaluations, both subjective and objective, on standard datasets showed that Grad-CAM++ provides promising human-interpretable visual explanations for a given CNN architecture across multiple tasks including classiï¬cation, image caption generation and 3D action recognition; as well as in new settings such as knowledge distillation.},
	language = {en},
	urldate = {2022-01-15},
	journal = {2018 IEEE Winter Conference on Applications of Computer Vision (WACV)},
	author = {Chattopadhyay, Aditya and Sarkar, Anirban and Howlader, Prantik and Balasubramanian, Vineeth N.},
	year = {2018},
	note = {arXiv: 1710.11063},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {839--847},
	annote = {Comment: 17 Pages, 15 Figures, 11 Tables. Accepted in the proceedings of IEEE Winter Conf. on Applications of Computer Vision (WACV2018). Extended version is under review at IEEE Transactions on Pattern Analysis and Machine Intelligence},
	file = {1710.11063.pdf:C\:\\Users\\Severine\\Zotero\\storage\\BBMJ6XEW\\1710.11063.pdf:application/pdf},
}

@misc{noauthor_imagelime_2022,
	title = {{imageLIME}},
	shorttitle = {Explain network predictions using {LIME}},
	url = {https://www.mathworks.com/help/deeplearning/ref/imagelime.html},
	urldate = {2022-01-15},
	journal = {MathWorks},
	year = {2022},
	file = {Explain network predictions using LIME - MATLAB imageLIME:C\:\\Users\\Severine\\Zotero\\storage\\VCFCJAR2\\imagelime.html:text/html},
}

@incollection{kim_convolutional_2017,
	address = {Berkeley, CA},
	title = {Convolutional {Neural} {Network}},
	isbn = {978-1-4842-2845-6},
	abstract = {The importance of the deep neural network lies in the fact that it opened the door to the complicated non-linear model and systematic approach for the hierarchical processing of knowledge.},
	language = {en},
	urldate = {2022-01-15},
	booktitle = {{MATLAB} {Deep} {Learning}: {With} {Machine} {Learning}, {Neural} {Networks} and {Artificial} {Intelligence}},
	publisher = {Apress},
	author = {Kim, Phil},
	editor = {Kim, Phil},
	year = {2017},
	doi = {10.1007/978-1-4842-2845-6},
	keywords = {Convolutional Neural Network, Input Image, Deep Neural Network, Image Recognition, Neural Network},
	pages = {121--147},
	file = {Springer Full Text PDF:C\:\\Users\\Severine\\Zotero\\storage\\GWRGWNBT\\Kim - 2017 - Convolutional Neural Network.pdf:application/pdf},
}

@incollection{medin2019structural,
  title={Structural principles in categorization},
  author={Medin, Douglas L},
  booktitle={Perception, cognition, and development},
  pages={203--230},
  year={2019},
  publisher={Psychology Press}
}

@incollection{grice1975logic,
  title={Logic and conversation},
  author={Grice, Herbert P},
  booktitle={Speech acts},
  pages={41--58},
  year={1975},
  publisher={Brill}
}

@article{Rosch1975FamilyRS,
  title={Family resemblances: Studies in the internal structure of categories},
  author={Eleanor Rosch and Carolyn B. Mervis},
  journal={Cognitive Psychology},
  year={1975},
  volume={7},
  pages={573-605}
}

@article{Sagi2018EnsembleLA,
  title={Ensemble learning: A survey},
  author={Omer Sagi and Lior Rokach},
  journal={Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  year={2018},
  volume={8}
}

@incollection{medin_theory_1975,
	title = {A {Theory} of {Context} in {Discrimination} {Learning}},
	volume = {9},
	abstract = {Discrimination learning is a fundamental concept in psychology. At an initial stage in any theoretical analysis of discrimination learning, two fundamental issues arise, namely, the subjects learned when an organism masters a discrimination, and how the stimulus situation should be described. Both of these issues provoke a number of related issues, answers to which represent key choice points in theory construction. This chapter briefly reviews current discrimination-learning theories in light of these two issues, with the aim of demonstrating an important weakness in them. A new theory is presented to address these weaknesses and drawing on concepts from research on memory, processes are presented and their predictions assessed. Finally, some modifications of the theory designed to account for phenomena from research on selective attention in learning is developed and evaluated. The context model presented in the chapter succeeds in predicting performance in various problem formats without altering any basic assumptions, and with the addition of assumptions concerning attention, corresponds very well with data on selective learning.},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {Psychology of {Learning} and {Motivation}},
	publisher = {Academic Press},
	author = {Medin, Douglas L.},
	editor = {Bower, Gordon H.},
	year = {1975},
	doi = {10.1016/S0079-7421(08)60273-X},
	pages = {263--314},
	file = {ScienceDirect Snapshot:C\:\\Users\\Severine\\Zotero\\storage\\F7H8R6DX\\S007974210860273X.html:text/html},
}
@inproceedings{pazzani_explaining_2018,
  title={Explaining Contrasting Categories.},
  author={Pazzani, Michael J and Feghahati, Amir and Shelton, Christian R and Seitz, Aaron R},
  booktitle={Workshop on Explainable Smart Systems (EXSS), ACM Intelligent User Interface Conference},
  year={2018}
}


@inproceedings{SoltaniCVPR,
  title={Give Users What They Want: Labeled Arrows.},
  author={Severine Soltani and Michael Pazzani},
  booktitle={XAI4CV: Explainable Artificial Intelligence for Computer Vision: Workshop at CVPR 2022},
  year={2022}
}

@inproceedings{schallner2019effect,
  title={Effect of superpixel aggregation on explanations in LIME--a case study with biological data},
  author={Schallner, Ludwig and Rabold, Johannes and Scholz, Oliver and Schmid, Ute},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={147--158},
  year={2019},
  organization={Springer}
}

@article{rosch1999principles,
  title={Principles of categorization},
  author={Rosch, Eleanor},
  journal={Concepts: core readings},
  volume={189},
  pages={312--322},
  year={1999}
}

@article{corter1992explaining,
  title={Explaining basic categories: Feature predictability and information.},
  author={Corter, James E and Gluck, Mark A},
  journal={Psychological bulletin},
  volume={111},
  number={2},
  pages={291},
  year={1992},
  publisher={American Psychological Association}
}

@article{hoffman2018explaining,
  title={Explaining explanation, part 4: a deep dive on deep nets},
  author={Hoffman, Robert and Miller, Tim and Mueller, Shane T and Klein, Gary and Clancey, William J},
  journal={IEEE Intelligent Systems},
  volume={33},
  number={3},
  pages={87--95},
  year={2018},
  publisher={IEEE}
}

@article{Langley2021ExplanationIC,
  title={Explanation in Cognitive Systems},
  author={Pat Langley},
  journal={IEEE Intelligent Systems},
  volume={9},
  pages={3--12},
  year={2021}
}



@inproceedings{le_grace_2020,
	address = {New York, NY, USA},
	series = {{KDD} '20},
	title = {{GRACE}: {Generating} {Concise} and {Informative} {Contrastive} {Sample} to {Explain} {Neural} {Network} {Model}'s {Prediction}},
	isbn = {978-1-4503-7998-4},
	shorttitle = {{GRACE}},
	abstract = {Despite the recent development in the topic of explainable AI/ML for image and text data, the majority of current solutions are not suitable to explain the prediction of neural network models when the datasets are tabular and their features are in high-dimensional vectorized formats. To mitigate this limitation, therefore, we borrow two notable ideas (i.e., "explanation by intervention" from causality and "explanation are contrastive" from philosophy) and propose a novel solution, named as GRACE, that better explains neural network models' predictions for tabular datasets. In particular, given a model's prediction as label X, GRACE intervenes and generates a minimally-modified contrastive sample to be classified as Y, with an intuitive textual explanation, answering the question of "Why X rather than Y?" We carry out comprehensive experiments using eleven public datasets of different scales and domains (e.g., \# of features ranges from 5 to 216) and compare GRACE with competing baselines on different measures: fidelity, conciseness, info-gain, and influence. The user-studies show that our generated explanation is not only more intuitive and easy-to-understand but also facilitates end-users to make as much as 60\% more accurate post-explanation decisions than that of Lime.},
	booktitle = {Proceedings of the 26th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Le, Thai and Wang, Suhang and Lee, Dongwon},
	year = {2020},
	keywords = {contrastive samples, counterfactual samples, data generation, deep learning, explainability, interpretability, neural networks},
	pages = {238--248},
	file = {Full Text PDF:C\:\\Users\\Severine\\Zotero\\storage\\JBAJT94B\\Le et al. - 2020 - GRACE Generating Concise and Informative Contrast.pdf:application/pdf},
}



@inproceedings{pazzani2018explaining,
  title={Explaining Contrasting Categories.},
  author={Pazzani, Michael J and Feghahati, Amir and Shelton, Christian R and Seitz, Aaron R},
  booktitle={IUI Workshops},
  year={2018}
}
@book{murphy2004big,
  title={The big book of concepts},
  author={Murphy, Gregory},
  year={2004},
  publisher={MIT press}
}


@article{lipton1990contrastive,
  title={Contrastive explanation},
  author={Lipton, Peter},
  journal={Royal Institute of Philosophy Supplements},
  volume={27},
  pages={247--266},
  year={1990},
  publisher={Cambridge University Press}
}


@article{miller_explanation_2019,
	title = {Explanation in artificial intelligence: {Insights} from the social sciences},
	volume = {267},
	issn = {0004-3702},
	shorttitle = {Explanation in artificial intelligence},
	abstract = {There has been a recent resurgence in the area of explainable artificial intelligence as researchers and practitioners seek to provide more transparency to their algorithms. Much of this research is focused on explicitly explaining decisions or actions to a human observer, and it should not be controversial to say that looking at how humans explain to each other can serve as a useful starting point for explanation in artificial intelligence. However, it is fair to say that most work in explainable artificial intelligence uses only the researchers' intuition of what constitutes a â€˜goodâ€™ explanation. There exist vast and valuable bodies of research in philosophy, psychology, and cognitive science of how people define, generate, select, evaluate, and present explanations, which argues that people employ certain cognitive biases and social expectations to the explanation process. This paper argues that the field of explainable artificial intelligence can build on this existing research, and reviews relevant papers from philosophy, cognitive psychology/science, and social psychology, which study these topics. It draws out some important findings, and discusses ways that these can be infused with work on explainable artificial intelligence.},
	language = {en},
	journal = {Artificial Intelligence},
	author = {Miller, Tim},
	year = {2019},
	keywords = {Explainability, Explainable AI, Explanation, Interpretability, Transparency},
	pages = {1--38},
	file = {ScienceDirect Snapshot:C\:\\Users\\Severine\\Zotero\\storage\\4C2W7N2Y\\S0004370218305988.html:text/html;Submitted Version:C\:\\Users\\Severine\\Zotero\\storage\\YX7WF555\\Miller - 2019 - Explanation in artificial intelligence Insights f.pdf:application/pdf},
}


@article{miller2021contrastive,
  title={Contrastive Explanation: A Structural-Model Approach},
  author={Miller, Tim},
  journal={Knowledge Engineering Review},
  volume={36},
  pages={E14},
  year={2021},
  doi={https://doi.org/10.1017/S0269888921000102},
}

@article{gunning_darpas_2021,
	title = {{DARPA}'s explainable {AI} ({XAI}) program: {A} retrospective},
	volume = {2},
	issn = {2689-5595},
	shorttitle = {{DARPA}'s explainable {AI} ({XAI}) program},
	doi = {10.1002/ail2.61},
	abstract = {of Defense Advanced Research Projects Agency's (DARPA) explainable artificial intelligence (XAI) program from the program managers' and evaluator's perspective.},
	number = {4},
	urldate = {2022-01-29},
	journal = {Applied AI Letters},
	author = {Gunning, David and Vorm, Eric and Wang, Jennifer Yunyan and Turek, Matt},
	year = {2021},

	pages = {e61},
	file = {Full Text PDF:C\:\\Users\\Severine\\Zotero\\storage\\UJT6M6F9\\Gunning et al. - 2021 - DARPA's explainable AI (XAI) program A retrospect.pdf:application/pdf;Snapshot:C\:\\Users\\Severine\\Zotero\\storage\\92GPCKHZ\\ail2.html:text/html},
}

@article{nourani_effects_2019,
	title = {The {Effects} of {Meaningful} and {Meaningless} {Explanations} on {Trust} and {Perceived} {System} {Accuracy} in {Intelligent} {Systems}},
	volume = {7},
	copyright = {Copyright (c) 2019 Association for the Advancement of Artificial Intelligence},
	abstract = {Machine learning and artificial intelligence algorithms can assist human decision making and analysis tasks. While such technology shows promise, willingness to use and rely on intelligent systems may depend on whether people can trust and understand them. To address this issue, researchers have explored the use of explainable interfaces that attempt to help explain why or how a system produced the output for a given input. However, the effects of meaningful and meaningless explanations (determined by their alignment with human logic) are not properly understood, especially with users who are non-experts in data science. Additionally, we wanted to explore how explanation inclusion and level of meaningfulness would affect the userâ€™s perception of accuracy. We designed a controlled experiment using an image classification scenario with local explanations to evaluate and better understand these issues. Our results show that whether explanations are human-meaningful can significantly affect perception of a systemâ€™s accuracy independent of the actual accuracy observed from system usage. Participants significantly underestimated the systemâ€™s accuracy when it provided weak, less human-meaningful explanations. Therefore, for intelligent systems with explainable interfaces, this research demonstrates that users are less likely to accurately judge the accuracy of algorithms that do not operate based on human-understandable rationale.},
	language = {en},
	urldate = {2022-01-29},
	journal = {Proceedings of the AAAI Conference on Human Computation and Crowdsourcing},
	author = {Nourani, Mahsan and Kabir, Samia and Mohseni, Sina and Ragan, Eric D.},
	year = {2019},
	pages = {97--105},
	file = {Full Text PDF:C\:\\Users\\Severine\\Zotero\\storage\\AQHZB7HD\\Nourani et al. - 2019 - The Effects of Meaningful and Meaningless Explanat.pdf:application/pdf},
}


 @inproceedings{ribeiro2016should,
  title={" Why should i trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}


@inproceedings{gilpin2018explaining,
  title={Explaining explanations: An overview of interpretability of machine learning},
  author={Gilpin, Leilani H and Bau, David and Yuan, Ben Z and Bajwa, Ayesha and Specter, Michael and Kagal, Lalana},
  booktitle={2018 IEEE 5th International Conference on data science and advanced analytics (DSAA)},
  pages={80--89},
  year={2018},
  organization={IEEE}
}
@inproceedings{stan2021domain,
  title={Domain Adaptation for the Segmentation of Confidential Medical Images},
  author={Stan, Serban and Rostami, Mohammad},
  booktitle={Proceedings of the British Machine Vision Conference},
  year={2022}
}

@inproceedings{pope2019explainability,
  title={Explainability methods for graph convolutional neural networks},
  author={Pope, Phillip E and Kolouri, Soheil and Rostami, Mohammad and Martin, Charles E and Hoffmann, Heiko},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10772--10781},
  year={2019}
}
@article{stansecure,
  title={Secure Domain Adaptation with Multiple Sources},
  author={Stan, Serban and Rostami, Mohammad},
  journal={Transactions on Machine Learning Research}
}

@inproceedings{nguyen2015deep,
  title={Deep neural networks are easily fooled: High confidence predictions for unrecognizable images},
  author={Nguyen, Anh and Yosinski, Jason and Clune, Jeff},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={427--436},
  year={2015}
}
@article{mehrabi2021survey,
  title={A survey on bias and fairness in machine learning},
  author={Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={6},
  pages={1--35},
  year={2021},
  publisher={ACM New York, NY, USA}
}
@article{carter2019activation,
  title={Activation atlas},
  author={Carter, Shan and Armstrong, Zan and Schubert, Ludwig and Johnson, Ian and Olah, Chris},
  journal={Distill},
  volume={4},
  number={3},
  pages={e15},
  year={2019}
}
@inproceedings{shrikumar2017learning,
  title={Learning important features through propagating activation differences},
  author={Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
  booktitle={International conference on machine learning},
  pages={3145--3153},
  year={2017},
  organization={PMLR}
}
@inproceedings{sundararajan2017axiomatic,
  title={Axiomatic attribution for deep networks},
  author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  booktitle={International conference on machine learning},
  pages={3319--3328},
  year={2017},
  organization={PMLR}
}
@article{gwet2001handbook,
  title={Handbook of inter-rater reliability},
  author={Gwet, Kilem},
  journal={Gaithersburg, MD: STATAXIS Publishing Company},
  pages={223--246},
  year={2001}
}
@article{xiong2022multimodal,
  title={Multimodal machine learning using visual fields and peripapillary circular OCT scans in detection of glaucomatous optic neuropathy},
  author={Xiong, Jian and Li, Fei and Song, Diping and Tang, Guangxian and He, Junjun and Gao, Kai and Zhang, Hengli and Cheng, Weijing and Song, Yunhe and Lin, Fengbin and others},
  journal={Ophthalmology},
  volume={129},
  number={2},
  pages={171--180},
  year={2022},
  publisher={Elsevier}
}

@misc{REU,
  title = {REU Participation Encourages Students to Pursue Graduate Degrees},
  author={CRA},
  howpublished = {\url{https://cra.org/reu-participation-encourages-students-to-pursue-graduate-degrees/}},
  year = {2022},
  note = {Accessed: 2022-09-01}
}
@inproceedings{avramidis2022automating,
  title={Automating Detection of Papilledema in Pediatric Fundus Images with Explainable Machine Learning},
  author={Avramidis, Kleanthis and Rostami, Mohammad and Chang, Melinda and Narayanan, Shrikanth},
  booktitle={2022 International Conference on Image Processing, 2022. ICIP'22.},
  year={2022},
  organization={IEEE}
}
@article{carta2012accuracy,
  title={Accuracy of funduscopy to identify true edema versus pseudoedema of the optic disc},
  author={Carta, Arturo and Favilla, Stefania and Prato, Marco and Bianchi-Marzoli, Stefania and Sadun, Alfredo A and Mora, Paolo},
  journal={Investigative Ophthalmology \& Visual Science},
  volume={53},
  number={1},
  pages={1--6},
  year={2012},
  publisher={The Association for Research in Vision and Ophthalmology}
}
@article{galbraith2009popcorn,
  title={Popcorn lung and bronchiolitis obliterans: a critical appraisal},
  author={Galbraith, David and Weill, David},
  journal={International archives of occupational and environmental health},
  volume={82},
  number={3},
  pages={407--416},
  year={2009},
  publisher={Springer}
}
@article{sener2018multi,
  title={Multi-task learning as multi-objective optimization},
  author={Sener, Ozan and Koltun, Vladlen},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
@article{lan2011improving,
  title={Improving accuracy of microarray classification by a simple multi-task feature selection filter},
  author={Lan, Liang and Vucetic, Slobodan},
  journal={International journal of data mining and bioinformatics},
  volume={5},
  number={2},
  pages={189--208},
  year={2011},
  publisher={Inderscience Publishers}
}
@article{codella2017deep,
  title={Deep learning ensembles for melanoma recognition in dermoscopy images},
  author={Codella, Noel CF and Nguyen, Q-B and Pankanti, Sharath and Gutman, David A and Helba, Brian and Halpern, Allan C and Smith, John R},
  journal={IBM Journal of Research and Development},
  volume={61},
  number={4/5},
  pages={5--1},
  year={2017},
  publisher={IBM}
}
@article{li2018skin,
  title={Skin lesion analysis towards melanoma detection using deep learning network},
  author={Li, Yuexiang and Shen, Linlin},
  journal={Sensors},
  volume={18},
  number={2},
  pages={556},
  year={2018},
  publisher={MDPI}
}
@article{adegun2019deep,
  title={Deep learning-based system for automatic melanoma detection},
  author={Adegun, Adekanmi A and Viriri, Serestina},
  journal={IEEE Access},
  volume={8},
  pages={7160--7172},
  year={2019},
  publisher={IEEE}
}
@article{kassani2019comparative,
  title={A comparative study of deep learning architectures on melanoma detection},
  author={Kassani, Sara Hosseinzadeh and Kassani, Peyman Hosseinzadeh},
  journal={Tissue and Cell},
  volume={58},
  pages={76--83},
  publisher={Elsevier}
}
@article{zhang2017melanoma,
  title={Melanoma segmentation based on deep learning},
  author={Zhang, Xiaoqing},
  journal={Computer assisted surgery},
  volume={22},
  number={sup1},
  pages={267--277},
  year={2017},
  publisher={Taylor \& Francis}
}
@article{sharma2022segmentation,
  title={Segmentation-Based Classification Deep Learning Model Embedded with Explainable AI for COVID-19 Detection in Chest X-ray Scans},
  author={Sharma, Neeraj and Saba, Luca and Khanna, Narendra N and Kalra, Mannudeep K and Fouda, Mostafa M and Suri, Jasjit S},
  journal={Diagnostics},
  volume={12},
  number={9},
  pages={2132},
  year={2022},
  publisher={MDPI}
}

@article{premaladha2016novel,
  title={Novel approaches for diagnosing melanoma skin lesions through supervised and deep learning algorithms},
  author={Premaladha, J and Ravichandran, KS},
  journal={Journal of medical systems},
  volume={40},
  number={4},
  pages={1--12},
  year={2016},
  publisher={Springer}
}


@article{jojoa2021melanoma,
  title={Melanoma diagnosis using deep learning techniques on dermatoscopic images},
  author={Jojoa Acosta, Mario Fernando and Caballero Tovar, Liesle Yail and Garcia-Zapirain, Maria Begonya and Percybrooks, Winston Spencer},
  journal={BMC Medical Imaging},
  volume={21},
  number={1},
  pages={1--11},
  year={2021},
  publisher={BioMed Central}
}
@inproceedings{sultana2018recent,
  title={Recent deep learning methods for melanoma detection: a review},
  author={Sultana, Nazneen N and Puhan, Niladri B},
  booktitle={International Conference on Mathematics and Computing},
  pages={118--132},
  year={2018},
  organization={Springer}
}
@article{naeem2020malignant,
  title={Malignant melanoma classification using deep learning: datasets, performance measurements, challenges and opportunities},
  author={Naeem, Ahmad and Farooq, Muhammad Shoaib and Khelifi, Adel and Abid, Adnan},
  journal={IEEE Access},
  volume={8},
  pages={110575--110597},
  year={2020},
  publisher={IEEE}
}
@inproceedings{stieler2021towards,
  title={Towards domain-specific explainable AI: model interpretation of a skin image classifier using a human approach},
  author={Stieler, Fabian and Rabe, Fabian and Bauer, Bernhard},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1802--1809},
  year={2021}
}
@article{argenziano1998epiluminescence,
  title={Epiluminescence microscopy for the diagnosis of ABCD rule of dermatoscopy and a new 7-point checklist based on pattern analysis},
  author={Argenziano, G and Fabbrocini, G and Carli, P and Giorgi, V De and Sammarco, E and Delfino, M},
  journal={Archives of Dermatology},
  number={134},
  pages={1536--1570},
  year={1998}
}

@article{DBLP:journals/corr/abs-1902-03368,
  author    = {Noel C. F. Codella and
               Veronica Rotemberg and
               Philipp Tschandl and
               M. Emre Celebi and
               Stephen W. Dusza and
               David A. Gutman and
               Brian Helba and
               Aadi Kalloo and
               Konstantinos Liopyris and
               Michael A. Marchetti and
               Harald Kittler and
               Allan Halpern},
  title     = {Skin Lesion Analysis Toward Melanoma Detection 2018: {A} Challenge
               Hosted by the International Skin Imaging Collaboration {(ISIC)}},
  journal   = {CoRR},
  volume    = {abs/1902.03368},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.03368},
  eprinttype = {arXiv},
  eprint    = {1902.03368},
  timestamp = {Tue, 29 Jun 2021 15:47:36 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1902-03368.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1803-10417,
  author    = {Philipp Tschandl and
               Cliff Rosendahl and
               Harald Kittler},
  title     = {The {HAM10000} Dataset: {A} Large Collection of Multi-Source Dermatoscopic
               Images of Common Pigmented Skin Lesions},
  journal   = {CoRR},
  volume    = {abs/1803.10417},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.10417},
  eprinttype = {arXiv},
  eprint    = {1803.10417},
  timestamp = {Mon, 13 Aug 2018 16:48:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1803-10417.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{Tschandl2018-ft,
  title     = "The {HAM10000} dataset, a large collection of multi-source
               dermatoscopic images of common pigmented skin lesions",
  author    = "Tschandl, Philipp and Rosendahl, Cliff and Kittler, Harald",
  abstract  = "Training of neural networks for automated diagnosis of pigmented
               skin lesions is hampered by the small size and lack of diversity
               of available datasets of dermatoscopic images. We tackle this
               problem by releasing the HAM10000 (``Human Against Machine with
               10000 training images'') dataset. We collected dermatoscopic
               images from different populations acquired and stored by
               different modalities. Given this diversity we had to apply
               different acquisition and cleaning methods and developed
               semi-automatic workflows utilizing specifically trained neural
               networks. The final dataset consists of 10015 dermatoscopic
               images which are released as a training set for academic machine
               learning purposes and are publicly available through the ISIC
               archive. This benchmark dataset can be used for machine learning
               and for comparisons with human experts. Cases include a
               representative collection of all important diagnostic categories
               in the realm of pigmented lesions. More than 50\% of lesions
               have been confirmed by pathology, while the ground truth for the
               rest of the cases was either follow-up, expert consensus, or
               confirmation by in-vivo confocal microscopy.",
  journal   = "Sci. Data",
  publisher = "Springer Science and Business Media LLC",
  volume    =  5,
  number    =  1,
  pages     = "180161",
  month     =  aug,
  year      =  2018,
  copyright = "https://creativecommons.org/licenses/by/4.0",
  language  = "en"
}

@ARTICLE{Tschandl2018-xf,
  title     = "The {HAM10000} dataset, a large collection of multi-source
               dermatoscopic images of common pigmented skin lesions",
  author    = "Tschandl, Philipp and Rosendahl, Cliff and Kittler, Harald",
  abstract  = "Training of neural networks for automated diagnosis of pigmented
               skin lesions is hampered by the small size and lack of diversity
               of available datasets of dermatoscopic images. We tackle this
               problem by releasing the HAM10000 (``Human Against Machine with
               10000 training images'') dataset. We collected dermatoscopic
               images from different populations acquired and stored by
               different modalities. Given this diversity we had to apply
               different acquisition and cleaning methods and developed
               semi-automatic workflows utilizing specifically trained neural
               networks. The final dataset consists of 10015 dermatoscopic
               images which are released as a training set for academic machine
               learning purposes and are publicly available through the ISIC
               archive. This benchmark dataset can be used for machine learning
               and for comparisons with human experts. Cases include a
               representative collection of all important diagnostic categories
               in the realm of pigmented lesions. More than 50\% of lesions
               have been confirmed by pathology, while the ground truth for the
               rest of the cases was either follow-up, expert consensus, or
               confirmation by in-vivo confocal microscopy.",
  journal   = "Sci. Data",
  publisher = "Springer Science and Business Media LLC",
  volume    =  5,
  number    =  1,
  pages     = "180161",
  month     =  aug,
  year      =  2018,
  copyright = "https://creativecommons.org/licenses/by/4.0",
  language  = "en"
}

@ARTICLE{Combalia2019-te,
  title         = "{BCN20000}: Dermoscopic Lesions in the Wild",
  author        = "Combalia, Marc and Codella, Noel C F and Rotemberg, Veronica
                   and Helba, Brian and Vilaplana, Veronica and Reiter, Ofer
                   and Carrera, Cristina and Barreiro, Alicia and Halpern,
                   Allan C and Puig, Susana and Malvehy, Josep",
  abstract      = "This article summarizes the BCN20000 dataset, composed of
                   19424 dermoscopic images of skin lesions captured from 2010
                   to 2016 in the facilities of the Hospital
                   Cl\textbackslash'inic in Barcelona. With this dataset, we
                   aim to study the problem of unconstrained classification of
                   dermoscopic images of skin cancer, including lesions found
                   in hard-to-diagnose locations (nails and mucosa), large
                   lesions which do not fit in the aperture of the dermoscopy
                   device, and hypo-pigmented lesions. The BCN20000 will be
                   provided to the participants of the ISIC Challenge 2019,
                   where they will be asked to train algorithms to classify
                   dermoscopic images of skin cancer automatically.",
  month         =  aug,
  year          =  2019,
  copyright     = "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
  archivePrefix = "arXiv",
  primaryClass  = "eess.IV",
  eprint        = "1908.02288"
}

@misc{https://doi.org/10.48550/arxiv.1906.11031,
  doi = {10.48550/ARXIV.1906.11031},
  
  url = {https://arxiv.org/abs/1906.11031},
  
  author = {Shamir, Reuben R and Duchin, Yuval and Kim, Jinyoung and Sapiro, Guillermo and Harel, Noam},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Image and Video Processing (eess.IV), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  
  title = {Continuous Dice Coefficient: a Method for Evaluating Probabilistic Segmentations},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
