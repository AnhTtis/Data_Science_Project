\section{Related Work}
%das2007google, song2008real, chen2013terec, song2017multi, devooght2015dynamic, wang2018streaming, chang2017streaming
\subsection{Streaming Recommendation}
Due to the real-world dynamics like user preference continuous shift and ever-increasing users and items, conventional recommender systems trained on the static fixed datasets usually suffer from: predicting previous interactions and preferences, disregarding trends and shifting preferences, and ignoring real industrial constraints like few time and limited resources. To tackle these challenges, streaming recommendation is proposed in which data and recommendation model are both updated dynamically along the timeline~\citep{das2007google, song2008real, chen2013terec, song2017multi, devooght2015dynamic, wang2018streaming, chang2017streaming}. Early works recommend items to users based on the popularity, recency, and trend analysis~\citep{chandramouli2011streamrec,lommatzsch2015real, subbian2016recommendations} but pay few attention to the collaborative signal distilling. To extracting such information, some other works~\citep{rendle2008online, diaz2012real, devooght2015dynamic, chang2017streaming} introduce the classical recommendation algorithms like collaborative filtering and machine factorization into the streaming setting. In addition, there are also some recent works from the perspectives of online clustering of bandits and collaborative filtering bandits~\citep{ban2021local, shuai2019online, gentile2017context, gentile2014online, li2016collaborative} to perform streaming recommendation. Thanks to the great success of graph neural network on complex relationship modeling, how to apply GCN-based recommendation models to the streaming recommendation is attracting more and more attention recently~\citep{xu2020graphsail, wang2021graph, ahrabian2021structure, wang2020streaming, wang2022streaming}.  Besides, streaming recommendation algorithms have been successfully deployed to industrial online service platforms like Google, Huawei, and Tencent~\citep{das2007google, cai2022reloop, sima2022ekko}. However, for a long time, there lacks a standardized definition to streaming recommendation, especially in the deep model-based recommendation setting. In this paper, we draw intuitions from previous research and most recent progress, and then summarize a definition of the streaming recommendation.

%\subsection{Graph Neural Network for Recommendation}
%Graph neural networks (GNN), has been widely investigated and applied in recommender system benefiting from its strong capability on extracting topological features and modeling the complex relationships between different entities~\citep{ying2018graph, wang2019neural, he2020lightgcn, sun2019multi, ma2020memory, feng2022dc}. Graph convolution is one of the most important module in such GNN models. Pinsage~\citep{ying2018graph}, one of the first industrial GCN-based recommender systems, is built on GraphSage~\citep{hamilton2017inductive} and can perform on-the-fly convolutions. Though its successful application in Pinterest recommender system, Pinsage only convolutes on the item-item graph. Some more recent graph convolution-based models, like NGCF~\citep{wang2019neural} and  LightGCN~\citep{he2020lightgcn}, mainly focus on extracting collaborative signals from the user-item interaction graph via expressive modeling of the high-order connectivity. Furthermore, MGCCF~\citep{sun2019multi} encodes richer information from three graphs: user-item interaction graph, user-user graph, and item-item graph. However, existing GCN-based recommendation models are most trained on a fixed dataset first and then deployed to the online platform, without considering the fact that the users' preferences are shifting continuously and the numbers of users/items are increasing meanwhile. In this paper, we focus on how to train the GCN-based recommendation models in such dynamic environments to achieve a stable and satisfying performance.
 
\subsection{Continual Learning}
Continual learning was originally paid great attention in computer vision and nature language process areas in which different tasks come in sequence. Various methods have been proposed to prevent catastrophic forgetting and effectively transfer knowledge. The mainstream continual learning algorithms can be classified into three categories: \textit{experience replay}~\citep{chaudhry2019continual, isele2018selective, prabhu2020gdumb, rebuffi2017icarl, mi2020ader}, \textit{knowledge distillation/model regularization}~\citep{hinton2015distilling, rannen2017encoder, dhar2019learning, hou2019learning}, and \textit{model isolation}~\citep{xu2018reinforced, DEN,rusu2016progressive, ostapenko2021continual, wu2020firefly, qin2021bns, golkar2019continual}. Continual learning is often regarded as a trade-off between knowledge retention (stability) and knowledge expansion (plasticity)~\citep{ostapenko2021continual}, and \textit{model isolation}-based methods provide an more explicit control over such trade-off. Considering that graph-based models have been widely studied to model the complex data relationships, continual graph learning~\citep{ma2020streaming, wang2020streaming, wang2022streaming, EvolveGCN, liu2020overcoming, zhou2021overcoming, perini2022learning, cai2022multimodal} has also attracted more and more attentions recently. When it comes to the continual graph in recommendation setting~\citep{xu2020graphsail, wang2021graph, ahrabian2021structure, wang2020streaming}, we focus more on the data coming continuously in chronological order rather than the data with task boundaries. Different from the conventional continual learning, the continual graph learning for streaming recommendation which is studied in this work pays more attention to the effective knowledge transfer across the time segments rather than preventing catastrophic forgetting. This is because performance degradation on historical data makes no sense to a real recommender system.
 
 


