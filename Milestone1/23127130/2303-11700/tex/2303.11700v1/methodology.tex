\section{Methodology}
In this section, we introduce our \textbf{DEGC} method towards continual graph learning for streaming recommendation. We first model the temporal user preference to capture the preference shifts between segments, which will be utilized for the user embedding initialization of training. Then, we successively use two operations, \textit{historical graph convolution pruning and refining} as well as \textit{graph convolution expanding and pruning} (shown in Figure \ref{fig:overview}), in such a \textit{model isolation} way to obtain the best structure and optimal parameters of the graph convolution.
\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.88\textwidth]{Figures/Overview_1014.png}
    \caption{Overview to Dynamically Expandable Graph Convolution. Take 2-layer graph convolution as an example. Operations 1,2,3 correspond to the methods introduced in Sec.~\ref{sec:his}. And operations 4,5,6,7 illustrate the methods mentioned in Sec.~\ref{sec:gra}.
    }
    \Description{Overview to Dynamically Expandable Graph Convolution. Take 2-layer graph convolution as an example. Operations 1,2,3 correspond to the methods introduced in Sec.~\ref{sec:his}. And operations 4,5,6,7 illustrate the methods mentioned in Sec.~\ref{sec:gra}.}
    \label{fig:overview}
    \vspace{-0.3cm}
\end{figure*}
\subsection{Temporal User Preference Modeling as Initialization}
Conventional continual graph learning algorithms directly inherit the user embeddings trained in the previous segments as the initialization without considering the user preference shift between the time segments. This type of methods totally rely on the graph convolution network to capture the user preference shift which is far from the fine-grained user modeling. To explicitly model the user-level preference shift and provide a better embedding initialization for graph convolution model training, we propose a temporal attention (TA) module to model the user temporal preference shift. This is motivated by the Kalman filter~\citep{welch1995introduction, kumar2019predicting, beutel2018latent}, which is an effective way to model the temporal state change.  In recommender system, the user embedding $\mathbf{e}^u$ is utilized to represent the user $u$'s preference. At segment $t$, the preference shift of user $u$ can be estimated with the Hadamard product of a time-scaled attention vector and the previous user embedding:
\begin{equation}
\begin{aligned}
\Delta \mathbf{e}^{u}_t &= (\mathbf{W}_{TA} \Delta t) \odot \mathbf{e}^{u}_{t^{-}}, \Delta t = t - t^{-},\\ 
\end{aligned}
\label{equ:5}
\end{equation}
where $t^{-}$ is the last time segment that user $u$ appears and $\mathbf{W}_{TA}$ is a learnable linear matrix. The larger the time interval $\Delta t$, the larger the user preference shift. Note that the users who are intermittently active on the platform (e.g., $u_1$ and $u_2$ in Figure ~\ref{fig:tam}) can also be modeled. Summing the user preference shift vector $\Delta \mathbf{e}^{u}_t$ and the user's previous preference vector $\mathbf{e}^u_{t^{-}}$ gives the user's current preference $\mathbf{e}^{u}_t$:
\begin{equation}
\begin{aligned}
\mathbf{e}^{u}_t &= \mathbf{e}^u_{t^{-}} + \Delta \mathbf{e}^{u}_t.\\ 
\end{aligned}
\label{equ:6}
\end{equation}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.48\textwidth]{Figures/TAM_new.png}
    \caption{Temporal user preference modeling and new user initialization.
    }
    \Description{Temporal user preference modeling and new user initialization.}
    \label{fig:tam}
    \vspace{-0.3cm}
\end{figure}
As illustrated in Figure~\ref{fig:tam}, the preferences of existing users (have appeared in the historical segments) at segment $t$ can be estimated with the temporal attention module directly. As for new users (appears for the first time), their preference vectors are initialized with a one-hop neighbor aggregation from the user-user graph at segment $t$:
\begin{equation}
\begin{aligned}
 \mathbf{e}^{u}_t &= \frac{1}{|\mathcal{N}^u_t|}\underset{j \in \mathcal{N}^u_t}{\sum} \mathbf{e}^j_t,\\ 
\end{aligned}
\label{equ:7}
\end{equation}
where $j$ are existing users in user $u$'s one-hop neighbor on the user-user graph at segment $t$. The embeddings of existing users and new users will be utilized as the initial embeddings for graph convolution-based recommendation model training.

\subsection{Historical Graph Convolution Pruning and Refining}
\label{sec:his}
In the recommender system, a user's preference is often regarded as the combination of her long-term preference (LTP) and short-term preference (STP)~\citep{rendle2010factorizing, ma2019hierarchical, ma2020probabilistic}. The long-term preference will not change drastically along the time and can take effect at most segments. This kind of preference is often determined by users' gender, occupation, education, and so on. 
By contrast, the short-term preference varies quickly and can only take effect in a certain time segment. STP is often influenced by the recommendation context information, like user emotion. And the recommendation model parameters store both users' long-term preferences
and short-term preferences after learning on the interaction data. Previous continual graph learning methods for streaming recommendation inherit the parameters learned on the last segment indiscriminately and fine-tune them with the new data. However, these methods will preserve the outdated short-term preferences which only work for the last segment and hinder the model learning on the new segment, which corresponds to the \textit{over-stability} issue mentioned above. 

Based on the motivation of decoupling users' useful long-term preferences and outdated short-term preferences, we first design a spasification training method to disentangle LTP-related graph convolution parameters $\mathbf{W}^l_t$ and STP-related graph convolution parameters $\mathbf{W}^s_t$ at segment $t$. As shown in subfigure (1) of Figure~\ref{fig:overview}, we randomly initialize the topmost graph convolution layer $\mathbf{W}^K_t$ and fix the rest graph convolution layers with parameters $\mathbf{W}_{t-1}$ learned on $\Delta G_{t-1}$ and then only train the topmost graph convolution layer $\mathbf{W}^K_t$ with the new incremental interaction graph $\Delta G_{t}$:
\begin{equation}
    \underset{\mathbf{W}^K_t}{min} \quad \mathcal{L}_t(\mathbf{W}^K_t;\mathbf{W}^{1:K-1}_{t-1} , \mathbf{e}, \Delta G_t) + \lambda_1 \lVert \mathbf{W}^K_t \rVert_1.
    \label{equ:8}
\end{equation}
The $\mathbf{e}$ denotes the embeddings of graph nodes. The added $L1$ regulation term is to encourage the sparse connection between layer $K$ and layer $K-1$ illustrated in subfigure (2) of Figure~\ref{fig:overview}. Once obtaining sparse $\mathbf{W}^K_t$, we can identify the filters of $\mathbf{W}^{K-1}_{t-1}$ that have no connection with layer $K$. Starting from this, we can find all the parameters in layer $1: K-1$ that have no connection with convolution layer $K$ via breadth-first search. Because this sparsification effect is obtained by training on $\Delta G_{t}$, such parameters are actually the users' outdated short-term preference-related parameters $\mathbf{W}^s_{t-1}$ and cannot reflect users' current preferences at $t$. And the convolution parameters $\mathbf{W}^l_{t-1}$ that have connection with $\mathbf{W}^K_t$ represent another part of users' previous preferences that still takes effect at $t$, which is users' long-term preferences. Considering that the users' long-term preferences are also evolving along the time, we first remove the $\mathbf{W}^s_{t-1}$ to avoid the negative knowledge transfer and then fine-tune the remaining LTP-related graph convolution parameters $\mathbf{W}^l_{t}$ initialized with $\mathbf{W}^l_{t-1}$:
\begin{equation}
    \underset{\mathbf{W}^l_t}{min} \quad \mathcal{L}_t(\mathbf{W}^l_t , \mathbf{e}, \Delta G_t) + \lambda_2 \lVert \mathbf{W}^l_t \rVert_2.
    \label{equ:9}
\end{equation}
Here, we use $L2$ regularization to prevent the model overfitting. The operation of  removing $\mathbf{W}^s_{t-1}$ also corresponds to the best GNN structure search mentioned in Definition~\ref{def:cgl}. Note that only fine-tuning the preserved long-term preference parameters can reduce the computing overload which is of great significance in streaming recommendation setting.

\begin{algorithm}
 \caption{DEGC}
 \label{alg:algorithm}
 \KwIn{A sequence of user-item interaction graphs $\mathcal{G}$.}
 \KwOut{Graph convolution parameters $\mathbf{W}_t$, user embeddings $\mathbf{e}^u_t$, item embeddings $\mathbf{e}^i_t$.}
 \textbf{Process}:\;
\For{each $t$ = 1,2,...,$T$}{
   Initialize the user embeddings with Eqn.~\ref{equ:6} and ~\ref{equ:7}\;
   Train the topmost graph convolution layer $\mathbf{W}^K_t$ with Eqn.~\ref{equ:8}\;
   Obtain $\mathbf{W}^l_{t-1}$ and $\mathbf{W}^s_{t-1}$ with breadth-first search\;
   Refine the $\mathbf{W}^l_{t}$ initialized by $\mathbf{W}^l_{t-1}$ with Eqn.~\ref{equ:9}\;
   Expand the graph convolution layers and train the expanded filters $\Delta \mathbf{W}_t$ with Eqn.~\ref{equ:10}\;
   Prune the expanded filters and finetune the whole model with Eqn.~\ref{equ:11}\;
   Update the $\mathbf{W}_{TA}$ in Eqn.~\ref{equ:5}\;}
\end{algorithm}
\vspace{-0.3cm}
\subsection{Graph Convolution Expanding and Pruning}
\label{sec:gra}
Only the refined long-term preferences are not enough to reflect the users' comprehensive preferences. To extract users' current short-term preferences at segment $t$,  we expand the graph convolution layers and train the expanded part from scratch independently with new data after obtaining fine-tuned $\mathbf{W}^l_{t}$ via operations $1, 2, 3$ in Figure~\ref{fig:overview}. In detail, we add $N$ filters to each graph convolution layer. Then, we initialize the expanded graph convolution parameters $\Delta \mathbf{W}_t$ randomly and train them with $\Delta G_{t}$ while fixing the $\mathbf{W}^l_{t}$:
\begin{equation}
    \underset{\Delta \mathbf{W}_t}{min} \quad \mathcal{L}_t(\mathbf{W}^l_{t};\Delta \mathbf{W}_t , \mathbf{e},\Delta G_t) + \lambda_1 \lVert \Delta \mathbf{W}_t  \rVert_1 + \lambda_g \underset{g}{\sum} \lVert \Delta \mathbf{W}^g_t \rVert_2.
    \label{equ:10}
\end{equation}
Here, we use both $L1$ regularization and group sparse regularization (GSR)~\citep{wen2016learning} to sparsify the expanded convolution parameters $\Delta \mathbf{W}_t$. $g$ is the group consisting of the parameters of each newly added filter. The purpose of sparsification terms here is to prevent the convolution layer width explosion catastrophe if adding $N$ filters to each layer constantly at each segment. 

After obtaining sparsified $\Delta \mathbf{W}_t$ (operation $5$ in Figure~\ref{fig:overview}), we prune $\Delta \mathbf{W}^k_t$ at each layer $k$. Specifically, for each $\Delta \mathbf{W}^k_t$, we first search the filters whose weights are all zeros and remove such filters. Meanwhile, the corresponding parameters in $\Delta \mathbf{W}^{k+1}_t$ of layer $k+1$ are also pruned. In such way, we not only extract the current short-term preferences at segment $t$ but also eliminate the redundant expansion parameters. It needs to be mentioned that our expanding and pruning operations echo the GNN structure optimization in Definition~\ref{def:cgl} again. Finally, the fixed $\mathbf{W}^l_{t}$, the pruned $\Delta \mathbf{W}_t$, and the embeddings $\mathbf{e}$ will be finetuned:
\begin{equation}
    \underset{\mathbf{W}^l_{t}, \Delta \mathbf{W}_t, \mathbf{e}}{min} \quad \mathcal{L}_t(\mathbf{W}^l_{t}; \Delta \mathbf{W}_t, \mathbf{e}, \Delta G_t) + \lambda_1 (\lVert \mathbf{W}^l_{t} \rVert_1 + \lVert \Delta \mathbf{W}_t \rVert_1 ) + \lambda_2 \lVert  \mathbf{e} \rVert_2.
    \label{equ:11}
\end{equation}
The embeddings $\mathbf{e}$ include both user embeddings $\mathbf{e}^u$ and item embeddings $\mathbf{e}^i$. Here, the $L1$ regularization is to sparsify the whole graph convolution structure to facilitate the historical convolution pruning on the next segment $t+1$. The whole workflow of our method is illustrated in Algorithm~\ref{alg:algorithm}. Because our method is actually  orthogonal to previous methods like \textit{experience replay} and \textit{knowledge distillation}, we will combine our method with previous methods to demonstrate its advantages.









%\subsection{Preference-decoupled Model Training}
%The GNN skeleton design directly follows the classical GNN model design. But the filter number and parameters of each layer will be changed in each timestep. At timestep $t$, let controller first decide the GNN structure $S_t$, then update the parameters $W_t$ with:
%\begin{equation}
%\underset{W_t \backslash W_{t-1}, W_{t-1}}{min} \mathcal{L}_t(S_t, W_t; \Delta G_t|G_{t-1})
%\end{equation}
%The inherited \textit{long-term preference} parameters $W_{t-1}$ will be preserved softly and the newly added filters for extracting \textit{short-term preference} will be trained directly. 
%\subsubsection{Long-term preference parameter update}
%\begin{equation}
%\begin{aligned}
%W_{t-1} & \leftarrow W_{t-1} - \eta_l \Delta_{W_{t-1}} \mathcal{L}_t (when \; \lVert C(\Delta G_t) \rVert > \delta)
%\end{aligned}
%\end{equation}
%\subsubsection{Short-term preference parameter update}
% This part of parameters are updated directly with the propagated gradients without any special constraints. The newly added filters will be learned with stochastic gradient descent:
%\begin{equation}
%\begin{aligned}
%W_t \backslash W_{t-1} &\leftarrow W_t \backslash W_{t-1} - \eta_s \nabla_{W_t \backslash W_{t-1}} \mathcal{L}_t\\
%\end{aligned}
%\end{equation}.
%The user/item embeddings are updated normally with gradient descent. Parameters will influence the processed embeddings in each layer and further determine the preferences.\\

%The whole DEGC algorithm along the recommendation stream is summarized in algorithm~\ref{alg:algorithm1}. The algorithm~\ref{alg:algorithm2} provides a detailed description to DEGC at each timestep.