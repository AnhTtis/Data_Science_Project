% \begin{abstract}
% \end{abstract}

\section*{Keywords}

Gravitational Lensing; Simulation; Dark Matter

\section*{Abstract}

Gravitational lensing refers to the deflection of light by the
gravity of celestial bodies, often predominantly composed of
dark matter.  Seen through a gravitational lens, the images
of distant galaxies appear distorted.  
In this paper we discuss simulation of the image distortion
by gravitational lensing.
The objective is to enhance our understanding of how gravitational
lensing works through a simple tool to visualise hypotheses.
The simulator can also generate synthetic data for the purpose
of machine learning, which will hopefully allow us to invert
the distortion function, something which is not analytically
possible at present.

\section{Introduction}

One of the big questions in astrophysics is the mapping of the Universe.
Modern telescopes provide enormous amounts of images of the night sky,
but about $85\%$ of the mass is dark matter (DM).  Emitting no light,
this dark matter is not visible on the images.  However, because of
gravity, the dark matter can distort the light from more remote objects.
This is called a gravitational lens (GL)~\citep[e.g.][]{bertone18}, because
it works analogously to an optical lens.

The shape and location of gravitational lenses can be inferred by studying
images of galaxies which appear distorted from our viewpoint,
but the calculations are complex and may amount to days of
manual work for a single lens.
Attempts to automate this process, for instance using machine
learning \citep[e.g.][]{hezaveh17}, are promising but still
limited to selected cases.

In this paper we develop a framework for simulating gravitational lenses,
that is, to synthesise authentic distorted images, given an undistorted
source image and a lens model.
This has two purposes.  Firstly, it enables bulk generation of 
synthetic data sets which can be used for training in machine learning.
Secondly, it provides a graphical user interface where cosmologists can
experiment to test and explore hypotheses.
As simulation model we use the Roulettes formalism \citep{clarkson16a},
which is notable by unifying weak and strong lensing in one paradigm.
This formalism provides the forward calculation of the distorted image,
but is not analytically invertible, which means that we cannot immediately
infer the lens or source profiles from the distorted image.

\input bendavid
\input model

\section{The simulator software}

The simulator works with pixmap representations of the 
source image and the distorted image.
The Roulettes model maps Cartesian co-ordinates in the 
lens plane to polar co-ordinates in the source plane.
Hence it is trivial to generate the distorted image pixel
by pixel, by simply looking up the corresponding pixel
(light ray) in the source image.
Fractional pixel co-ordinates may be interpolated, but if high-resolution
images are used, this is not necessary.
Even though the distorted image is calculated in the lens plane 
according to the Roulettes formalism,
we project it back into the source plane,
so that the scale (size) is comparable to the source image.

\begin{figure*}
   \begin{center}
      \begin{minipage}{0.8\textwidth}
         \includegraphics[width=\textwidth]{gui}
      \end{minipage}
   \end{center}
   \caption{The GUI for the Simulator.}
   \label{fig:gui}
\end{figure*}

The simulator is implemented as a C++ library, using OpenCV for
image manipulation.  Front-end tools are implemted in Python, 
using Pybind11 to wrap the C++ library.
There is a GUI tool, as shown in Figure~\ref{fig:gui}, and a command
line tool to generate images in bulk.
The software is available in Open Source on github\footnote{%
   The release used in this paper is v2.0.2 at
   \url{https://github.com/CosmoAI-AES/CosmoSim/releases/tag/v2.0.2}.}.

% \subsection{Simulator Architecture}

The simulator is a very simple object-oriented structure, where new
lens and source models can easily be added.
The abstract \emph{Source} class represents the source image,
with concrete subclasses for spherical and ellipsoid lenses.
These classes store the source image which is generated upon
instantiation.
The abstract \emph{LensModel} class represents the gravitational
lens with subclasses for point mass and spherical (SIS) lenses.
These classes implement the distortion function 
${\mathcal{D}}(r,\phi)$,
and store the distorted image as well as a reference to the source object, 
An update method computes the distorted image, which can be retrieved
with a getter function.

The python wrapper does not expose the object model.  The \emph{CosmoSim}
class has setters for types of lens and source models as well as all the 
relevant parameters.
It exposes the Lens Model's update method and getters for
the distorted and the actual image.
This reduces code size and simplifies maintenance, since we do not have
to keep wrapper classes for all the classes in the C++ library.
Still it gives complete access to all the features of the simulator.

A critical step in the SIS model is to calculate all the
amplitudes $\alpha_s^m$ and $\beta_s^m$.
We use Python to pre-generate expressions for each $(m,s)$
pair up to some maximum truncation limit $m_0$, using the sympy
module to differentiate $\psi$.
The resulting algebraic expressions are loaded by the C++
code from a text file and evaluated numerically using the
symengine library.

\section{Results}

\begin{figure}
   \begin{subfigure}{41mm}
      \includegraphics[height=40mm]{Images/actual-4}
      \caption{Source Image}
      \label{fig1pm}
   \end{subfigure}
      \hfill
   \begin{subfigure}{41mm}
      \includegraphics[height=40mm]{Images/image-4}
      \caption{Exact model}
      \label{fig2pm}
   \end{subfigure}
   \begin{subfigure}{41mm}
      \includegraphics[height=40mm]{Images/image-5}
      \caption{Roulettes with 10 terms}
      \label{fig3pm}
   \end{subfigure}
      \hfill
   \begin{subfigure}{41mm}
      \includegraphics[height=40mm]{Images/image-6}
      \caption{Roulettes with 20 terms}
      \label{fig4pm}
   \end{subfigure}
   \caption{Examples with a spherical source and point mass lens;
      $D_\textrm{L}/D_\textrm{S}=50\%$, $\xi=22$, $\theta=45^\circ$, $R_\textrm{E}=14$, $\sigma=7$.}
   \label{fig:pm}
\end{figure}

The GUI interface (Figure~\ref{fig:gui}) allows the user quickly 
to experiment with different parameter settings, and visually
review resulting distorted images.
For the cosmologist on the team, this has proved an invaluable tool,
particularly to develop intuition and develop a deeper understanding
of both the phenomenon (GL) and the model (Roulettes).
A particular point where it proved useful was in understanding the
convergence ring and the spurious images which we discuss below.
Moreover, it has allowed us to verify the theory.

The spurious images is a model artifact.
Calculating the distorted images in the Roulettes formalism with
an even truncation threshold $m_0$ produces $m_0+1$ spurious
images in a ring roughly centred on the local origin $\boldsymbol{\xi}$.
The model is exact at the origin, and a good approximation in a 
neighhood around it.
This is clearly seen in the comparison of the exact point mass model
and the Roulettes approximations in Figure~\ref{fig:pm}.
On one hand, these simulations show how well the Roulettes formalism
matches the exact solution, something which can also be verified
quantitatively by computing difference images.
On the other hand it illustrates the convergence ring, outside of which
the model is meaningless, with the spurious images as a blatant example.

Asymptotically, when the number of terms $m_0$ tends to infinity, it can be
shown that this ring has radius $\xi$ centred on $\boldsymbol{\xi}$,
and that it approaches the limit from the outside.
This result is provided by~\citet{Clarkson_2016_II} 
and is called the ring of convergence.
We can also see in Figure~\ref{fig:pm} how the spurious images are
smaller for large $m_0$, as the light is distributed between more images.
When the number of images tends to infinity, the size of each one will
tend to zero.

\begin{figure}
   \begin{subfigure}{41mm}
      \includegraphics[height=40mm]{Images/actual-15}
      \caption{Source Image $\xi=20$}
      \label{fig1sis}
   \end{subfigure}
      \hfill
   \begin{subfigure}{41mm}
      \includegraphics[height=40mm]{Images/image-15}
      \caption{Distorted image $\xi=20$}
      \label{fig2sis}
   \end{subfigure}
   \begin{subfigure}{41mm}
      \includegraphics[height=40mm]{Images/actual-17}
      \caption{Source Image $\xi=5$}
      \label{fig3sis}
   \end{subfigure}
      \hfill
   \begin{subfigure}{41mm}
      \includegraphics[height=40mm]{Images/image-17}
      \caption{Distorted image $\xi=5$}
      \label{fig4sis}
   \end{subfigure}
   \caption{Examples with a spherical source and SIS lens,
      with different source positions;
      $D_\textrm{L}/D_\textrm{S}=50\%$, $\theta=45^\circ$, $\xi=24$, $\sigma=7$.}
   \label{fig:sis}
\end{figure}

Figure~\ref{fig:sis} shows an example of the behaviour for
different degrees on lensing.
When the distance $\xi$ between the lens and the distorted 
images is smaller, compared to the Einstein radius $R_\textrm{E}$, the
lensing effect is weaker.  If it is sufficiently small, the image
fits well inside the convergence ring and is a good representation
of the physical behaviour.
For stronger lensing effects (Figure~\ref{fig4sis}), we can see how
the image is drawn out towards the spurious image.
Thus we have demonstrated a limit for when the Roulettes formalism 
is satisfactory.
Even though the Roulettes unify weak and strong lensing in one
paradigm, it is not yet satisfactory in the case of very strong lenses.

\begin{figure}
   \begin{subfigure}{41mm}
      \includegraphics[height=40mm]{Images/actual-21}
      \caption{Source Image}
      \label{fig1ring}
   \end{subfigure}
      \hfill
   \begin{subfigure}{41mm}
      \includegraphics[height=40mm]{Images/image-21}
      \caption{10 terms}
      \label{fig2ring}
   \end{subfigure}
   \begin{subfigure}{41mm}
      \includegraphics[height=40mm]{Images/image-23}
      \caption{50 terms}
      \label{fig3ring}
   \end{subfigure}
      \hfill
   \begin{subfigure}{41mm}
      \includegraphics[height=40mm]{Images/image-24}
      \caption{150 terms}
      \label{fig4ring}
   \end{subfigure}
   \caption{Examples of the spurious images for various numbers 
      of terms;
      $D_\textrm{L}/D_\textrm{S}=50\%$, $\theta=135^\circ$, $\xi=12$, $R_\textrm{E}=8$, $\sigma=7$.}
   \label{fig:ring}
\end{figure}

Knowing the shape of the convergence ring, it is possible to mask away
everything close to or outside the ring.
This is important to speed up the simulation, as the distortion equation
\eqref{eqn:general mapping} is computationally expensive, although
it depends heavily on the image size and on $m_0$.
However, there is no reason to calculate pixels outside the convergence
ring, and taking this into account, we get a reasonably responsive GUI
for image size $512\times512$ and $m_0=50$.
This masking is made optional in the tools.
Without the masking, the GUI is usuable around $m_0=16$, but it quickly
gets irresponsive for $m_0\ge20$.
This tests have used a desktop computer with
an AMD Ryzen 9 5900X 12-Core Processor at 2195.8MHz.
The image size of $512\times 512$ is, of course, a lot higher 
than typical empirical images, but the high resolution may be 
important for the testing of the theory.

For a more objective performance test, we have done bulk
generation of images, using the same desktop computer.
Generating 1000 images at $400\times400$ resolution took
35Â½s walltime and 10 minutes 5 seconds CPU time for $m_0=16$.
% 32s walltime and 9 minutes 4 seconds CPU time for $m_0=15$.
For $m_0=50$, it took
4 minutes 38 seconds walltime and 81 minutes 24 seconds CPU time,
and for $m_0=150$, $44'41''$ waltime and 11h19 CPU time.
This is very acceptable, although interactive applications may
not be able to go much above $m_0=50$.
For the purpose of machine learning, the training set 
generation is negligible compared to the training time, 
as it should be.

\section{Impact and Conclusion}

Our simulation model provides a computational representation of the
algebraic Roulettes formalism~\citep{clarkson16a}.
An important motivation has been to bridge the gap between computer
scientists and physicists, by developing a model which is meaningful 
in both domains.
This is a necessary first step to open up this important research
field from cosmology for a wider community, most importantly for
machine learning which may be able to invert the distortion function.

Similar simulators have been reported in the literature, each with their
own limitations.
The lenstronomy package \citep{birrer18} is a comprehensive package,
with other features in addition to the generation of distorted images,
but it is limited to strong lensing.
Other works we have found do not provide source code or sufficient detail
to reproduce it, making them difficult to validate or extend.
Thus the present transparent simulation model with suppor for both weak
and strong lensing is a considerable step forward.
We provide the first computational implementation the Roulettes formalism, 
and also a framework which can be extended with new lens modelles,
be they expressed in the Roulettes formalism or other frameworks.

We have not given any results on machine learning.  The first rudimentary
tests are promising, but more work is needed before it is ready for discussion. 
The simulator has other uses, as a visual tool for testing and exploring
hypotheses in cosmology.  Somewhat unanticipated, our simulations have 
revealed problems and limitations in the Roulettes formalism, and thus
identified needs for further research.

This work is a mere starting point, leaving several interesting open problems.
Development of machine learning models to reconstruct the lens profile and 
possibly the source image has already been mentioned.
To achieve this, we will also have to adapt our system to simulate the noisy,
low-resolution data in real images of the night sky.
An independent line of research is computational models for a broader range of
lens models.
It would be particularly interesting if we could use sampled representations
of the lens potential $\psi$.

\section*{Acknowledgements}

The first prototype of the simulator was a final year project (BSc)
by four of the authors \citep{cosmoai2022bsc}, and the work would have 
been impossible without their initial work.
The models and prototypes have since been extended and improved
by the other two authors. Also, we would like to thank Chris Clarkson at QMUL for his various inputs.
