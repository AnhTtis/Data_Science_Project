{
    "arxiv_id": "2303.11932",
    "paper_title": "Using Explanations to Guide Models",
    "authors": [
        "Sukrut Rao",
        "Moritz BÃ¶hle",
        "Amin Parchami-Araghi",
        "Bernt Schiele"
    ],
    "submission_date": "2023-03-21",
    "revised_dates": [
        "2023-03-22"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
    ],
    "abstract": "Deep neural networks are highly performant, but might base their decision on spurious or background features that co-occur with certain classes, which can hurt generalization. To mitigate this issue, the usage of 'model guidance' has gained popularity recently: for this, models are guided to be \"right for the right reasons\" by regularizing the models' explanations to highlight the right features. Experimental validation of these approaches has thus far however been limited to relatively simple and / or synthetic datasets. To gain a better understanding of which model-guiding approaches actually transfer to more challenging real-world datasets, in this work we conduct an in-depth evaluation across various loss functions, attribution methods, models, and 'guidance depths' on the PASCAL VOC 2007 and MS COCO 2014 datasets, and show that model guidance can sometimes even improve model performance. In this context, we further propose a novel energy loss, show its effectiveness in directing the model to focus on object features. We also show that these gains can be achieved even with a small fraction (e.g. 1%) of bounding box annotations, highlighting the cost effectiveness of this approach. Lastly, we show that this approach can also improve generalization under distribution shifts. Code will be made available.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.11932v1"
    ],
    "publication_venue": "38 pages, 35 figures, 4 tables"
}