\section{Additional Qualitative Results (\vocs and \cocos)}
\label{supp:sec:quali}

\subsection{Qualitative Examples Across Losses, Attribution Methods, and Layers}
\label{supp:sec:main:qualitative:examples}

\input{supplement/tex_figures/quali_voc_1}
\input{supplement/tex_figures/quali_coco_1}
\input{supplement/tex_figures/quali_combined_full_page}

In \cref{fig:supp:quali_voc_1,fig:supp:quali_coco_1}, we visualize attributions across losses, attribution methods, and layers for the same set of examples from the \vocs and \cocos datasets respectively. As discussed in the main paper, we make the following observations.

First, when guiding models at the \emph{final layer}, we observe a marked improvement in the granularity of the attribution maps for all losses (\finding5), except for \ppceloss, for which we do not observe notable differences. The improvements are particularly noticeable on the \cocos dataset (\cref{fig:supp:quali_coco_1}, ``Final'' column), in which the objects tend to be smaller. \Eg, when looking at the airplane image (last row per model), we observe much fewer attributions in the background after applying model guidance.

Second, as the \lone loss optimizes for uniform coverage \emph{within} the bounding boxes, it provides coarser attributions that tend to fill the entire bounding box (cf.~\finding3). This can be observed particularly well for the large objects from the \vocs dataset: \eg, whereas models trained with the \epgloss and the \rrr loss highlight just a relatively small area within the bounding box of the cat (\cref{fig:supp:quali_voc_1}, "Final" column, third row), the \lone loss yields  much more distributed attributions for all models.

Third, at the input layer, the \bcos models show the most notable qualitative improvements (cf.~\finding4). In particular, although the \xdnn models show some reduction in noisy background attributions (\eg last rows in \cref{fig:supp:quali_voc_1:xdnn} and \cref{fig:supp:quali_coco_1:xdnn}), the attributions remain rather noisy for many of the images; for the \vanilla models, the improvements are even less pronounced (\cref{fig:supp:quali_voc_1:vanilla}, \cref{fig:supp:quali_coco_1:vanilla}). The \bcos models, on the other hand, seem to lend themselves better to such guidance being applied to the attributions at the input layer (\cref{fig:supp:quali_voc_1:bcos}, \cref{fig:supp:quali_coco_1:bcos}) and the resulting attributions show much more detail (\epgloss + \rrr) or an increased focus on the entire bounding box (\lone). Especially with the \epgloss, the \bcos models are able to clearly focus on even small objects, see \cref{fig:supp:quali_coco_1:bcos}.

For additional results from both the \vocs as well as the \cocos dataset, please see \cref{fig:supp:quali_combined}.


\clearpage
\subsection{Additional visualizations for training with coarse bounding boxes}
\label{supp:sec:main:qualitative:dilation}
In this section, we show more detailed and additional examples of models trained with coarser bounding boxes, \ie with bounding boxes that are purposefully dilated during training by various amounts (10\%, 25\%, or 50\%), see \cref{fig:supp:dilation_quali}. In accordance with our findings in the main paper (cf.~\finding8), we observe that the \epgloss loss is highly robust to such `annotation errors': the attribution maps improve noticeably in all cases (compare the \epgloss row with the respective baseline result). In contrast, the \lone loss seems more dependent on high-quality annotations, which we also observe quantitatively, see \cref{fig:supp:dilation_quanti}.
\input{supplement/tex_figures/quali_dilation}