\section{Discussion And Conclusion}
\label{sec:conclusion}
In this work, we comprehensively evaluated various models, attribution methods, and loss functions for their utility in guiding models to be ``right for the right reasons''.

In summary, we find that
guiding models via bounding boxes can significantly improve \epg and \iou performance of the optimized attribution method, with the \epgloss loss working best to improve the \epg score (\finding1) and the \lone loss yielding the highest gains in \iou scores (\finding2). While the \bcos models achieve the best results in \iou and \epg score at the input layer (\finding4), all tested model types (\vanilla, \xdnn, \bcos) lend themselves well to being optimized at the final layer (\finding5), which can even improve attribution maps at early layers (\finding9).
Further, we find that regularizing the explanations of the models and thereby `telling them where to look' can increase the object recognition performance (mAP/accuracy) of some models (\finding6), especially when strong spurious correlations are present (\cref{sec:results:waterbirds}).
Interestingly, those gains (\epg, \iou), can be achieved with relatively little additional annotation (\finding7).
Lastly, we find that by not assuming a uniform prior over the attributions within the annotated bounding boxes, training with the energy loss is more robust to annotation errors (\finding8) and results in models that produce attribution maps that are more focused on class-specific features (\finding3).
