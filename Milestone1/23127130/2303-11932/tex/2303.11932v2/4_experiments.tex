\section{Experimental Setup}
\label{sec:experiments}
\input{results/tex_figures/pareto_figure}
In this section, we describe our experimental setup
and how we select the best models across metrics; for full details, see supplement.
We evaluate across all possible
choices for each category, and discuss our results in \cref{sec:results}. 

\myparagraph{Datasets:} We evaluate on \voc \citeMain{everingham2009pascal} and \coco \citeMain{lin2014microsoft} for multi-label image classification. {In \cref{sec:results:waterbirds}, to understand the effectiveness of model guidance in mitigating spurious correlations, we also evaluate on the synthetically constructed Waterbirds-100 dataset \citeMain{sagawa2019distributionally,petryk2022guiding}, where landbirds are perfectly correlated with land backgrounds on the training and validation sets, but are equally likely to occur on land or water in the test set (similar for waterbirds and water). With this dataset, we evaluate model guidance for suppressing undesired features.}

\myparagraph{Attribution Methods and Architectures:} As described in \cref{sec:method:attributions}, we evaluate with \ixg \citeMain{shrikumar2017learning}, \intgrad \citeMain{sundararajan2017axiomatic}, \bcos \citeMain{bohle2022b,bohle2023b}, and \gradcam \citeMain{selvaraju2017grad} using models with a \resnet \citeMain{he2016deep} backbone. For \intgrad, we use an \xdnn \resnet \citeMain{hesse2021fast} to reduce the computational cost, and a \bcos \resnet for the \bcos attributions. To emphasize that the results generalize across different backbones, we further provide results for a \bcos ViT-S \citeMain{Dosovitskiy2021image,bohle2023b} and a \bcos DenseNet-121 \citeMain{huang2017densely,bohle2023b}. 
%
We evaluate optimizing the attributions at different network layers, such as at the input image and the last convolutional layers' output\footnote{As typically used in \ixg (input) and \gradcam (final) respectively.}, as well as at multiple intermediate layers. Within the main paper, we highlight some of the most representative and insightful results, the full set of results can be found in the supplement.
All models were pretrained on \imagenet \citeMain{imagenet}, and model guidance was applied when fine-tuning the models on the target dataset.

\myparagraph{Localization Losses:} As described in \cref{sec:method:losses}, we compare four localization losses in our evaluation: (i) \energyloss, (ii) \loneloss \citeMain{gao2022aligning,gao2022res}, (iii) \ppceloss \citeMain{shen2021human}, and (iv) \rrrloss (cf.~\cref{sec:method:losses}, \citeMain{ross2017right}).

\myparagraph{Evaluation Metrics:} As discussed in \cref{sec:method:metrics}, we evaluate both for classification and localization performance of the models. For classification, we report the F1 scores, similar results with \map scores can be found in the supplement. For localization, we evaluate using the \epg and \iou scores.

\myparagraph{Selecting the best models:} As we evaluate for two distinct objectives (classification + localization), it is not trivial to decide which models perform `the best', \eg a model that provides the best classification performance might provide significantly worse localization than a model that provides only slightly lower classification performance. 
Finding the right balance and deciding which of those models in fact constitutes the `better' model depends on the preference of the end user. 
Hence, instead of selecting models based on a single metric, we select the set of Pareto-dominant models \citeMain{pareto1894massimo,pareto2008maximum,backhaus1980pareto} across three metrics---F1, \epg, and \iou---for each training configuration, as defined by a combination of attribution method, layer, and loss. Specifically, as shown in \cref{fig:pareto_example}, we train each configuration using three different choices of $\lambda_\text{loc}$, and select the set of Pareto-dominant models among all checkpoints (epochs and $\lambda_\text{loc}$). This provides a more holistic view of the general trends on the effectiveness of model guidance for each configuration.