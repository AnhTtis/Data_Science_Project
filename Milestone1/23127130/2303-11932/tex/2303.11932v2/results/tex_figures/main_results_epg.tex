\begin{figure*}[t]
    \centering 

    \begin{subfigure}[c]{.95\textwidth}
    \includegraphics[width=\textwidth]{results/VOC/figures/loc/all_results_f1.pdf}
    \caption{\textbf{PASCAL VOC results for \energypg vs.~\fone.} 
    }
    \label{fig:epg_voc}
    \end{subfigure}
    \begin{subfigure}[c]{.95\textwidth}
    \includegraphics[width=\textwidth]{results/COCO/figures/loc/all_results_f1.pdf}
    \caption{\textbf{MS COCO results for \energypg vs.~\fone.}
    }
    \label{fig:epg_coco}
    \end{subfigure}
    \caption{\textbf{EPG vs.~\fone,} for different datasets (\textbf{(a)}: VOC; \textbf{(b)}: COCO), losses (\textbf{markers}) and models (\textbf{columns}), optimized at different layers (\textbf{rows}); additionally, we show the performance of the baseline model before fine-tuning and demarcate regions that strictly dominate (are strictly dominated by) the baseline performance in green (grey). 
    For each configuration, we show the Pareto fronts (cf.\ \cref{fig:pareto_example}) across regularization strengths $\lambda_\text{loc}$ and epochs (cf.\ \cref{sec:results} and \cref{fig:pareto_example}). 
    We find the \epgloss loss to give the best trade-off between \epg and \fone.
    }
    \label{fig:epg_results}
        \vspace{-.75em}
\end{figure*}
