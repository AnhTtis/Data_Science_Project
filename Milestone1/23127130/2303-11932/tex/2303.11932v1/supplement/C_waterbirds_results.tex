\section{Waterbirds Results}
\label{supp:sec:waterbirds}

\input{supplement/waterbirds_table}

As discussed in section \cref{sec:results:waterbirds}, we use the \waterbirds dataset \citeApp{sagawa2019distributionally,petryk2022guiding} to evaluate the effectiveness of model guidance in a setting where strong spurious correlations are present in the training data. This dataset consists of four groups---\textit{Landbird} on \textit{Land} (\textbf{G1}), \textit{Landbird} on \textit{Water} (\textbf{G2}), \textit{Waterbird} on \textit{Land} (\textbf{G3}), and \textit{Waterbird} on \textit{Water} (\textbf{G4})---of which only groups \textbf{G1} and \textbf{G4} appear during training and the background is thus perfectly correlated with the type of bird (\eg Landbird on land).

To evaluate the effectiveness of model guidance, we train the models on two binary classification tasks: to classify the type of birds (the \emph{conventional setting}) or the background (the \emph{reversed setting}, as described in \citeApp{petryk2022guiding}) and evaluate models without guidance (baselines), as well as with guidance: specifically, for guiding the models, we evaluate different models (\vanilla, \xdnn, \bcos) with different guidance losses (\epgloss, \lone) applied at different layers (Input and Final), see \cref{tab:supp:waterbirds_table}. {For each model, we use its corresponding attribution method, \ie \ixg for \vanilla, \intgrad for \xdnn, and \bcos for \bcos.}

In \cref{tab:supp:waterbirds_table} we present the classification performance for the individual groups (\textbf{G1-G4}) as well as the average over all samples  (`Overall') across all configurations; note that the group sizes differ in the test set and the average over the individual group acccuracies thus differs from the overall accuracy. For each row, the results are averaged over 4 runs (2 random training seeds and 2 different sets of 1\% annotated samples) with the exception of the baseline results being an average over 2 runs.

In almost all cases, we find that both of the evaluated losses (\epgloss, \lone) improve the models' classification performance over the baseline. As expected, these improvements are particularly pronounced in the groups not seen during training, \ie landbirds on water (\textbf{G2}) and waterbirds on land (\textbf{G3}). 

Further, in \cref{fig:supp:waterbirds_quali}, we show attribution maps of the baseline models, as well as the guided models. As can be seen, model guidance not only improves the accuracy, but is also reflected in the attribution maps: \eg, in row 1 of \cref{fig:supp:waterbirds_quali:a}, we see that while the baseline model originally focused on the background (water) to classify the image, it is possible to guide the model to use the desired features (\ie the bird in conventional setting and the background in the reversed setting) and consequently arrive at the desired classification decision. As this guidance is `soft', we also observe cases in which the model still focused on the wrong feature and thus arrived at the wrong prediction: \eg in \cref{fig:supp:waterbirds_quali:b} row 1 (reversed setting), the \epgloss-guided model still focuses on the bird and thus incorrectly predicts `Water', similar to the \lone-guided model in row 4. 

\input{supplement/tex_figures/quali_waterbirds}