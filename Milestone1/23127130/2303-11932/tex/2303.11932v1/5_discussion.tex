\section{Experimental Results}
\label{sec:results}

\input{results/tex_figures/main_results_epg}
\input{results/tex_figures/main_results_iou}

In this section, we discuss our experimental findings. In particular, in \cref{sec:results:epg+iou}, we first discuss the impact of the loss functions on the \epg and \iou scores of the models; in \cref{sec:results:layers+models}, we then analyze the impact of the models and attribution methods; further in \cref{sec:results:accuracy}, we show that 
guiding the models via their explanations can even lead to improved classification accuracy. In \cref{sec:results:ablations}, we present two ablation studies in which we evaluate and discuss the cost of model guidance approaches: in particular, we study model guidance with limited additional labels and with increasingly coarse bounding boxes.
Finally, in \cref{sec:results:waterbirds}, we show the utility of model guidance in improving accuracy in the presence of distribution shifts.
For easier reference, we further label our individual findings as \finding1--\finding8.

\myparagraph{Note.} To draw conclusive insights and highlight general and reliable trends in the experiments, we compare the Pareto curves (see \cref{fig:pareto_example}) of individual configurations. If the Pareto curve of a specific loss (\eg \epgloss in \cref{fig:epg_results}) consistently Pareto-dominates the Pareto curves of all other losses, we can confidently conclude that for the combination of evaluated metrics (\eg \epg vs.~\iou), this loss is the best choice.

\subsection{Comparing loss functions for model guidance}
\label{sec:results:epg+iou}


In the following, we highlight the main insights gained from the \emph{quantitative} evaluations. For a \emph{qualitative} comparison between the losses, please see \cref{fig:loss_comp}; note that we show examples for a \bcos models as the differences become clearest---full results are shown in the supplement.

\myparagraph{\finding1 The energy loss yields the best \epg scores.} 
In \cref{fig:epg_results}, we plot the Pareto curves for \epg vs.~\fone scores for a wide range of configurations (see \cref{sec:experiments}) on \vocs (a) and \cocos (b); specifically, we group the results by model type (\vanilla, \xdnn, \bcos), the layer depths at which the attribution was regularized (Input / Final), and the loss used during optimization (\energyloss, \loneloss, \ppceloss, \rrrloss). 
From these results it becomes apparent that the optimization with the energy loss yields the best trade-off between accuracy (\fone) and the \epg score: \eg, when looking at the upper right plot in \cref{fig:epg_voc} we can see that the \epgloss loss (red dots) improves over the baseline \bcos model (white cross) by improving the localization in terms of \epg score with only a minor cost in classification performance (\ie \fone score). Further trading off F1 scores yields even higher \epg scores. Importantly, the \epgloss loss Pareto-dominates all the other losses (\rrrloss: blue diamonds; \lone: green triangles; \ppceloss: yellow pentagons). This is is also true for the other networks (\vanilla \resnet, \cref{fig:epg_voc} (top left), and \xdnn, \cref{fig:epg_voc} (top center)) and at the final layer (bottom row). When comparing \cref{fig:epg_voc} and \cref{fig:epg_coco}, we find these results to be highly consistent between datasets.

\myparagraph{\finding2 The \lone loss yields the best \iou performance.} Similarly, in \cref{fig:iou_results}, we plot the Pareto curves of \iou vs.~\fone scores for various configurations at the final layer; for the \iou results at the input layer and on the \cocos dataset, please see the supplement. 
For \iou, the \lone loss provides the best trade-off and, with few exceptions, \lone-guided models Pareto-dominate all other models in all configurations.

\myparagraph{\finding3 The \epgloss loss focuses best on class-specific features.}
By not forcing the models to highlight \emph{all} features within the bounding boxes (see \cref{sec:method:energyloss}), we qualitatively find it to preserve more detail (cf.~\cref{fig:loss_comp,,fig:dilation_comp}) and to suppress background features also \emph{within} the bounding boxes. This qualitative observation is confirmed when measuring the Energy (\cref{eq:epg}) just withing the bounding boxes: for this, we take advantage of the segmentation mask annotations available for a subset of the \vocs test set. Specifically, we measure the energy contained in the segmentation masks versus the entire bounding box, which indicates how much of the attributions actually highlight on-object features. We find that the energy loss outperforms \lone across all models and configurations; for details, please see the supplement.

\input{results/tex_figures/loss_comparison}

In short, we find that the \epgloss loss works best for improving the \epg metric, whereas the \lone loss yields the highest gains in terms of \iou; depending on the use case, either of these losses could thus be recommendable. However, we find that the \epgloss loss is more robust to annotation errors (\finding8, \cref{sec:results:ablations}), and, as discussed in \finding3, the \epgloss loss more reliably focuses on object-specific features.

\subsection{Comparing models and attribution methods}
\label{sec:results:layers+models}
In the following, we highlight our findings with respect to differences between attribution methods and models.

\myparagraph{\finding4 At the input layer, \bcos explanations perform best.} We find that the \bcos models not only achieve the highest \epg/\iou performance before fine-tuning the models (`baselines'), but also obtain the highest gains in \epg and \iou and thus the highest overall performance (for \epg see \cref{fig:epg_results}, right; for \iou, see supplement): \eg, an Energy-based \bcos model achieves an \epg score of 71.7 @ 79.4\%\fone, thus significantly outperforming the best \epg scores of both other model types at a much lower cost in \fone (\vanilla: 55.8 @ 69.0\%, \xdnn: 62.3 @ 68.9\%). This is also observed \emph{qualitatively}, as we show in the supplement.

\myparagraph{\finding5 Regularizing at the final layer yields consistent gains.} As can be seen in \cref{fig:epg_results} (bottom) and \ref{fig:iou_results}, all models can be `guided' well when applying regularization at the final layer and show improvements in \iou as well as the \epg score.

In short, we find model guidance to work well across all tested models when optimizing at the final layer (\finding5), highlighting its wide applicability. However, to obtain highly detailed and well-localized attributions at the input layer, the model-inherent explanations of the \bcos models seem to lend themselves much better to such guidance (\finding4).

\subsection{Improving accuracy with model guidance}
\label{sec:results:accuracy}

\myparagraph{\finding6 Model guidance {can} improve accuracy.} For both the \vanilla models (final layer) and the \xdnns (input+final), we found models that improve the localization metrics \emph{and} the \fone score. These improvements are particularly pronounced for the \xdnn: \eg, we find models that improve the \epg and \fone scores by $\Delta\myeq7.2$ p.p.\  and $\Delta\myeq1.4$ p.p.\ respectively (\cref{fig:epg_results}, center top), or the \iou and \fone scores by $\Delta\myeq1.4$ p.p.\ and $\Delta\myeq11.9$ p.p.\ (\cref{fig:iou_results}, center).

However, overall we observe a trade-off between localization and accuracy (\cref{fig:epg_results,fig:iou_results}). Given the similarity of the training and test distributions, focusing on the object need not improve classification performance, as spurious features are also present at test time. Further, the guided model is discouraged from relying on contextual features, making the classification more challenging. In \cref{sec:results:waterbirds}, we show that guidance can significantly improve performance when there is a distribution shift between training and test.

\subsection{Efficiency and robustness considerations}
\label{sec:results:ablations}

Guiding models via bounding boxes of course requires additional annotation effort, increasing the cost of data collection. In this section, we therefore assess the robustness of guiding the model with a limited  number of annotations (\finding7) and with increasingly coarse annotations (\finding8).

\myparagraph{\finding7 Model guidance requires only few add.~annotations.} In \cref{fig:lim_local_input}, we show that the \epg score can be significantly improved with a very limited number of annotations; for \iou results, see supplement. Specifically, we find that when using only 1\% of the training data (25 annotated images) for \vocs, improvements of up to $\Delta\myeq23.0$ p.p.\ ($\Delta\myeq1.4$) in \epg (\iou) can be obtained, at a minor drop in \fone ($\Delta\myeq0.3$ p.p.\ and $\Delta\myeq2.5$ p.p.\ respectively). When annotating up to 10\% of the images, very similar results can be achieved as with full annotation (see \eg cols.~2+3 in \cref{fig:lim_local_input}).



\myparagraph{\finding8 The energy loss is highly robust to annotation errors.} As discussed in \cref{sec:method:energyloss}, the energy loss only `tells' the model which features \emph{not} to use and does not impose a uniform prior on the attributions within the bounding boxes. As a result, we find it to be much more stable to annotation errors: \eg, in \cref{fig:coarse_annotations}, we visualize how the \epg (top) and \iou (bottom) scores of the best performing models under the \epgloss (left) and \lone loss (right) evolve when using coarser bounding boxes; for this, we simply dilate the bounding box size by $p\myin\{10, 25, 50\}$\% during training, see \cref{fig:dilation_comp}. While the models optimized via the \lone loss achieve increasingly worse results (right),  the \epgloss-optimized models are essentially unaffected by the coarseness of the annotations.
\input{results/tex_figures/coarse_annotations}
\input{results/tex_figures/coarse_qualitative}

In short, we find that the models can be guided effectively at a low cost in terms of annotation effort, as only few annotations (\eg 25 for \vocs) are required (cf.\ \finding7), and, especially for the \epgloss loss, these annotations can be very coarse and do not have to be `pixel-perfect' (cf.\ \finding8).

\input{results/tex_figures/lim_anno_epg}

\subsection{Effectiveness against spurious correlations}
\label{sec:results:waterbirds}
To evaluate the potential for mitigating spurious correlations, we evaluate model guidance with the \epgloss and \lone losses on the synthetically constructed \waterbirds dataset \citeMain{sagawa2019distributionally,petryk2022guiding}. We perform model guidance under two settings: (1) the conventional setting to classify between landbirds and waterbirds, using the region within the bounding box as the mask; and (2) the reversed setting \cite{petryk2022guiding} to classify the background, \ie, land vs.\ water, using the region outside the bounding box as the mask. To simulate a limited annotation budget, we only use bounding boxes for a random 1\% of the training set, and report results averaged over four runs. We show the results for the worst-group accuracy (\ie, images containing a waterbird on land) and the overall accuracy using \bcos models in \cref{tab:waterbirds}; full results for all attributions and models can be found in the supplement.

Both losses consistently and significantly improve the accuracy in the conventional and the reversed settings by guiding the model to select the `right' features, \ie birds (conventional) or background (reversed). This guidance can also be observed qualitatively (cf.~\cref{fig:waterbirds}).
\input{results/tex_figures/waterbirds}

\input{results/table_waterbirds}
