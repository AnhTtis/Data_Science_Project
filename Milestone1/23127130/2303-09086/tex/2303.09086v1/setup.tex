\section{Preliminaries}\label{sec_prelim}



\noindent\textbf{Problem setup.}
Given a spreading process on a network, we are interested in designing algorithms to reduce the number of affected nodes.
Let $\cG = (\cV, \cE)$ be a weighted and possibly directed graph.
Let $\cV$ be the set of vertices and $\cE$ be the set of edges.
We use $W$ to denote a non-negative weight matrix over the edges, with $W_{i,j}$ being its $(i,j)$-th entry.
Given an \emph{arbitrary} edge-weight reduction budget $B$,
how should we allocate the budget across the edges?

To answer this question, we consider an eigenvalue optimization approach that has been the basis of prior works for unweighted graphs \cite{chakrabarti2008epidemic,prakash2012threshold,tong2012gelling,chen2015node}.
The idea behind eigenvalue optimization approaches is to modify the weight matrix $W$ so that its largest eigenvalue is most reduced.
We extend the eigenvalue minimization approach to weighted networks as follows.
Let $M$ be an $n$ by $n$ matrix, where $n$ is the number of nodes in $\cV$.
Given a rank $r$, let $\lambda_k(M)$ be the $k$-th largest singular value of $M$.
We consider the following problem:
{\small
\begin{align}
     \min_{M}~~&\quad f(M) = \sum_{k=1}^r \big(\lambda_k(M)\big)^2 \label{eq_convex} \\
    \mbox{s.t.}              
                                ~~&\,\, \sum_{(i,j)\in \cE} \big(W_{i, j} - M_{i,j}\big) \le B \nonumber \\
                                \quad&\quad 0 \le M_{i, j} \le W_{i, j},\, \forall\, (i, j)\in \cE, \nonumber \\
                                \quad~~&\quad M_{i,j}=0, \quad\quad\quad\,\,\, \forall\, (i, j)\notin \cE. \nonumber
\end{align}}%
After solving the above problem, we get a reduced weight matrix $M$ as the solution of our intervention strategy.
Notice that we approach this problem from an optimization perspective. Questions including interpreting the solution would be interesting questions for future work.
As a remark, the square of $\lambda_k(M)$ equals the $k$-th largest eigenvalue of $MM^{\top}$.
Thus, the objective in equation \eqref{eq_convex}  includes the top-$r$ eigenvalues (see also \citet{le2015met}).
The reason is that the other top eigenvalues could still affect the spreading process in subgraphs of $G$ \cite{andersen2006local,gleich2012vertex,le2015met,yu2021potion}. %
In Figure \ref{fig:scale_singular_values}, we first illustrate that reducing the largest singular value of $G$ reduces the number of infections during simulated spreading processes.
In Section \ref{sec:scalability}, we further demonstrate that having the freedom to choose the rank $r$ helps reduce the number of infections.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.3234\textwidth]{./figures/infected_vs_lambda_ny.pdf}%
  \caption{The number of infections strongly correlates with the largest singular value of the graph: more infections are observed for higher values of $\lambda_1(W)$ (by rescaling $W$). The spreading rate is denoted as $p$.}\label{fig:scale_singular_values}
\end{figure}

\noindent\textbf{Example.}
To give an example of weighted graphs in epidemic spreading, we can consider mobility networks, which describe the movements from groups of individuals to locations.
The graph is weighted by the number of movement records. %
For instance, \citet{chang2021mobility} introduces a mobility-based modeling approach to fit the observed number of infections.
Their approach involves fitting a metapopulation SEIR model with publicly available mobility records.
Recall that an SEIR model uses four compartments to capture a spreading process: Susceptible (S), Exposed (E), Infected (I), and Recovered (R).
In their case, the mobility network is bipartite: one side being points of interest (POIs) and the other being census block groups (CBGs).
One way to convert the weighted bipartite network to our problem setup is by joining the traffic across all POIs for every pair of CBGs via matrix multiplication.

\vspace{0.05in}
\smallskip
\noindent\textbf{Frank-Wolfe algorithm.}
The Frankâ€“Wolfe algorithm is an iterative first-order optimization algorithm for constrained convex optimization (see, e.g., \citet{nocedal2006numerical}).
There are two major steps in the design of this algorithm
First, there is a direction-finding subproblem that computes the descent direction with the smallest correlation with the gradient of the objective.
Second, based on this descent direction, the step size is determined (e.g., by a line search).
Lastly, a gradient descent update is performed using the determined step size and the descent direction.

