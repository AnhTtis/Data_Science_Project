\section{Trust}
%\cite{Hald2021} "explanations alone are not sufficient to increase human-computer trust after robot mistakes."

%\cite{Liu2021} "robot autonomy leads to a range of negative perceptions in humans. After watching videos of autonomous robots, people rated them as more difficult to control, more intelligent, less desirable, less user intention, and eerier."

%\cite{Aroyo2017} People will trust a robot to help if they ask it for help. However, they are reluctant to ask for help in the first place until they really need it.

%\cite{Esterwood2022} robot personality appears to have a significant and positive impact on acceptance.

Trust and acceptance are essential components of interaction with SARs. Transparent and clear explanations (for behavior and decisions) alone are insufficient to increase user trust after robots make mistakes\cite{Hald2021}. Instead, building trust involves more than simply communicating intentions. For example, caregiving SARs are expected to act with some degree of autonomy, as a human caregiver would. However, robot autonomy can lead to negative perceptions and a lack of trust; in a study by \citet{Liu2021}, participants rated autonomous robots as more difficult to control, less desirable, and eerier after seeing them on video. This is an example of how fostering trust in SARs requires a delicate balance between autonomy and compliance.

Moreover, using personal biometrics to authenticate users can ensure secure interactions between humans and robots. For instance, in therapeutic settings, ensuring that only authorized individuals can access confidential information such as personal medical records would enhance the sense of trust ~\cite{Kellmeyer2018}. Similarly, monitoring biometrics such as heart rate variability, skin conductance, and facial expressions can improve human-robot interaction by providing feedback on the user's emotional state, thus allowing the robot to adjust its behavior accordingly and offer more appropriate assistance\cite{Lin2020}.

\textbf{We conclude that building trust in SARs involves more than explainability. It requires understanding the user's privacy and security concerns. Personal biometrics can be an implicit part of intent communication and can be used to enhance security and improve the user's trust in SARs.}
