
\documentclass{article} % For LaTeX2e
\usepackage{iclr2024_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}



\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors

\usepackage{makecell}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{wrapfig}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\newcommand{\eg}{e.g.}
\newcommand{\etc}{etc}
% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{assumption}{Assumption}
\newtheorem{proposition}{Proposition}
\newtheorem{hypothesis}{Hypothesis}
\newtheorem{axiom}{Candidate Axiom}

\usepackage{listings}
\usepackage{xcolor}

\lstset{
  language=Python,
  basicstyle=\ttfamily,
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  stringstyle=\color{red},
  showstringspaces=false,
  breaklines=true,
  frame=single,
  escapeinside={(*@}{@*)}
}

\newcommand\indep{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}


\title{Indeterminate Probability Theory}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.
\iclrfinalcopy

\author{Tao Yang,
Chuang Liu,
Xiaofeng Ma,
Weijia Lu,
Ning Wu,
Bingyang Li, \\
\textbf{
Zhifei Yang,
Peng Liu,
Lin Sun,
Xiaodong Zhang,
Can Zhang }
\\
AI Lab, United Automotive Electronic Systems Co., Ltd. \\
Shanghai, China \\
\texttt{tao.yang9@uaes.com}
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle


\begin{abstract}
Complex continuous or mixed joint distributions (e.g., $P(Y \mid z_1,z_2,\dots,z_N)$) generally lack closed-form solutions, often necessitating approximations such as MCMC. 
This paper proposes \textbf{Indeterminate Probability Theory} (IPT), which makes the following contributions:
(1) An \textbf{observer-centered framework} in which experimental outcomes are represented as distributions combining ground truth with observation error;  
(2) The introduction of three independence candidate \textbf{axioms} that enable a two-phase probabilistic inference framework; 
(3) The derivation of \textbf{closed-form solutions} for arbitrary complex joint distributions under this framework.
Both the \textit{Indeterminate Probability Neural Network (IPNN)} model and the non-neural \textit{multivariate time series forecasting} application demonstrate IPT's effectiveness in modeling high-dimensional distributions, with successful validation up to 1000 dimensions.
Importantly, IPT is consistent with classical probability theory and subsumes the frequentist equation in the limit of vanishing observation error.
\footnote{Source code: \url{https://github.com/Starfruit007/ipnn}}

\end{abstract}

\section{Introduction}\label{sec:introduction}
Classical probability theory, particularly its frequentist interpretation, relies on observing and counting outcomes across repeated trials. Under this framework, each event/sample is assumed to be clearly defined and unambiguously observed — a prerequisite for computing stable frequency estimates that converge to well-defined probabilities.

However, this assumption often fails in real-world scenarios. Observations are often ambiguous, observer-dependent, or constrained by measurement limitations. For instance, in a coin toss experiment, while we may expect to observe either heads or tails, imperfect visibility or limited resolution can lead to uncertainty about the actual outcome. In such cases, the very notion of a discrete, uniquely determined sample point becomes questionable.
More generally, observations may not only be uncertain but also exhibit continuous variability. Again, in a coin toss experiment, an observer may interpret the outcome as e.g. a Gaussian distribution based on their special concerns or measurement context. This suggests that a more general theory is needed — one that can accommodate both discrete and continuous forms of observation uncertainty within a unified framework.

To address this need, we propose \textbf{Indeterminate Probability Theory} (IPT), a new framework that extends classical probability by explicitly modeling the observer's role and the uncertainty inherent in the observation process. Unlike traditional models that treat observations as direct proxies for truth, IPT begins from the premise that all knowledge arises from observation outputs, which reflect both the underlying system and the conditions under which it is observed.

This perspective leads to a structured two-phase approach:
\begin{itemize}
   \item \textbf{Observation Phase:} Rigorously defining conditional relationships among observable outputs (discrete, continuous, or mixed) via candidate Axiom~\ref{axm:A_X_independence} and Axiom~\ref{axm:Y_A_independence}.
   \item \textbf{Inference Phase:} Performing probabilistic inference with imperfect observable outputs based on Axiom~\ref{axm:Y_X_independence}.
\end{itemize}

We demonstrate the utility of IPT through two practical applications:

\begin{itemize}
   \item\textbf{IPNN (Indeterminate Probability Neural Network):} A discrete/continuous neural architecture achieving tractable inference in high-dimensional latent spaces (up to 1000 dimensions); \cite{cipnn} 
   \item \textbf{Non-neural multivariate time series forecasting:} IPT-based method outperforms LSTM and Transformer baselines by modeling observer-induced uncertainty.  \cite{seqip}
\end{itemize}

Importantly, IPT is not at odds with classical probability theory. Instead, it subsumes frequentist probability as a special case when observational error vanishes (Theorem~\ref{thm:classical_subsumption}), ensuring compatibility with existing methodologies. By bridging the gap between theoretical rigor and practical robustness, IPT offers a unified framework for probabilistic reasoning in uncertain environments.  


% Due to the absence of a general analytical equation for complex distributions, MCMC~\cite{monte_carlo} and variational inference methods~\cite{variational_method}
% as approximate solutions are well developed in the past.
% In this paper, we propose a new method to solve the complex distributions.

\section{A Toy Example}\label{sec:example}


To illustrate the concept of indeterminate probability theory (IPT), we present a coin toss experiment with three distinct observers.
This scenario demonstrates how IPT resolves questions intractable to classical probability theory when observation uncertainty exists. 
Experimental parameters are detailed in Table~\ref{tab:cipnn_example_background}.

\begin{table}[htbp]
    \caption{Coin Toss Experiment}
    \label{tab:cipnn_example_background}
    \begin{center}
    \begin{tabular}{cccccc}
    \hline
    Random Experiment ID $X$ & $x_{1}$ & $x_{2}$ &  $x_{3}$ &  $x_{4}$ &  $x_{5}$ \\
    &  $x_{6}$ &  $x_{7}$ &  $x_{8}$ &  $x_{9}$ &  $x_{10}$ \\ 
    \\[-1.5ex]
    Truth & $hd$ & $hd$ & $hd$ & $hd$ & $hd$ \\
    & $tl$ & $tl$ & $tl$ & $tl$ & $tl$ \\
    \\[-1.5ex]
    Record of Observer$_{1}$ $Y$ & $hd$ & $hd$ & $hd$ & $hd$ & $hd$ \\
    & $tl$ & $tl$ & $tl$ & $tl$ & $tl$ \\
    \\[-1.5ex]
    Equivalent Record $Y$ & 1, 0 & 1, 0 & 1, 0 & 1, 0 & 1, 0 \\
    & 0, 1 & 0, 1 & 0, 1 & 0, 1 & 0, 1 \\
    \\[-1.5ex]
    Record of Observer$_{2}$  $A$ & 0.8, 0.2 & 0.7, 0.3 & 0.9, 0.1 & 0.6, 0.4 & 0.8, 0.2 \\
    & 0.1, 0.9 & 0.2, 0.8 & 0.3, 0.7 & 0.1, 0.9 & 0.2, 0.8 \\
    \\[-1.5ex]
    Record of Observer$_{3}$ $z$ & $\mathcal{N}(3,1)$ & $\mathcal{N}(3,1)$ & $\mathcal{N}(3,1)$ & $\mathcal{N}(3,1)$ & $\mathcal{N}(3,1)$ \\
    & $\mathcal{N}(-3,1)$ & $\mathcal{N}(-3,1)$ & $\mathcal{N}(-3,1)$ & $\mathcal{N}(-3,1)$ & $\mathcal{N}(-3,1)$ \\  
    \hline
    \end{tabular}
    \end{center}
    Where $hd$ is for head, $tl$ is for tail. And conditioning on $x_{k}$ is the indeterminate probability, e.g.  $P(Y=hd|X=x_{3}) = 1$, $P(A=tl|X=x_{6}) = 0.9$ and $P(z|X=x_{8}) = \mathcal{N}(z;-3,1)$.
    \end{table}


\textbf{Observer\textsubscript{1}} records outcomes perfectly. The probability of heads is:
\begin{equation}
P(Y=hd)=\frac{\text{number of }(Y=hd)\text{ occurs}}{\text{number of random experiments}} = \frac{5}{10}
\end{equation}


By defining the experiment ID as a random variable $X$, we can also represent Observer$_{1}$'s record with equivalent form of $P(Y=hd|X=x_{k})$, lead to
\begin{equation}
        P(Y=hd)=\sum_{k=1}^{10}P(Y=hd|X=x_{k})\cdot P(X=x_{k}) = \frac{5}{10}  
\end{equation}

Note that random variable $X$ is special, only condition on $X$ has a special meaning for the observation of each coin toss.



\textbf{Observer\textsubscript{2}} outputs probability distributions. The head probability is:

\begin{equation}
    P(A=hd)=\sum_{k=1}^{10}P(A=hd|X=x_{k})\cdot P(X=x_{k}) = \frac{4.7}{10}
\end{equation}

This combines \textbf{ground truth} and \textbf{observation error}.


\textbf{Observer\textsubscript{3}} outputs Gaussian distributions $\mathcal{N}(z;\mu,1)$ with unknown mapping. 
The distribution is:

\begin{equation}
P(z)=\sum_{k=1}^{10}P(z|X=x_{k})\cdot P(X=x_{k})  
= \frac{5\cdot\mathcal{N}(z;3,1)+5\cdot\mathcal{N}(z;-3,1)}{10}
\end{equation}


The bimodal $P(z)$ raises a key question: How do we mathematically associate each mode with physical outcomes? 
Classical probability cannot resolve this in closed-form.


Using IPT's conditional independence Axiom~\ref{axm:Y_A_independence} (given X, z and Y is conditional independent in observation phase):

\begin{equation}
    \begin{aligned}
    P(Y=hd|z) = \frac{\sum_{k=1}^{10}P(Y=hd|X=x_{k})\cdot P(z|X=x_{k})}{\sum_{k=1}^{10}P(z|X=x_{k})} = \frac{\mathcal{N}(z;3,1)}{\mathcal{N}(z;3,1)+\mathcal{N}(z;-3,1)}
    \end{aligned}
\end{equation}


For a new toss $X_{11}$ with $P(z|X=x_{11})=\mathcal{N}(z;3,1)$, applying inference-phase independence Axiom~\ref{axm:Y_X_independence} (given z, X and Y is conditional independent in inference phase), along with Monte Carlo method:


\begin{equation}
   \label{eq:example_gauss_coin_toss}
    \begin{aligned}
    P^z(Y=hd|X=x_{11}) &= \int_{z} \left( P(Y=hd|z, X=x_{11})\cdot P(z|X=x_{11}) \right)\\
    &= \int_{z} \left( P(Y=hd|z)\cdot P(z|X=x_{11}) \right)\\
    &= \mathbb{E}_{z \sim P(z|X=x_{11})}\left [ P(Y=hd|z)  \right ] \approx \frac{1}{C}\sum_{c=1}^{C}P(Y=hd|z_{c}) \\
    &= \frac{1}{C}\sum_{c=1}^{C}\frac{\mathcal{N}(z_{c};3,1)}{\mathcal{N}(z_{c};3,1)+\mathcal{N}(z_{c};-3,1)} \approx 1,  z_{c} \sim \mathcal{N}(z;3,1)
    \end{aligned}
\end{equation}

Where superscript $P^z(Y=hd|X=x_{11})$ indicates that the inference is based on the latent variables $z$,
and $P(Y=hd|X=x_{11})$ indicates that the record of the observer$_{3}$.
$C$ represents the number of Monte Carlo samples. 
This identifies $\mathcal{N}(z;3,1)$ with heads.


\textbf{Extensions}: When Observer\textsubscript{3} is a neural network outputting multivariate Gaussians, this yields the CIPNN model~\cite{cipnn}. Directly modeling time series as Gaussians (without neural networks) gives the forecasting method~\cite{seqip}.


\section{Indeterminate Probability Theory}\label{sec:ip_theory}

Let $A^{1},A^{2},...,A^{N}$ and $Y$ denote distinct discrete, continuous or mixed random variables. For simplicity,
we present the theory using discrete random variables, though the framework applies equally to continuous or mixed cases.

Current methods lack general analytical solutions for complex conditional distributions $P  (Y=y_{l}\mid A^{1}=a_{i_{1}}^{1},\dots, A^{N}=a_{i_{N}}^{N}) $
(compactly written as $P \left (y_{l} |a_{i_{1}}^1,a_{i_{2}}^2,\dots,a_{i_{N}}^N \right )$\footnote{Compact notation used throughout; multivariate $Y$ is permitted}). 
Indeterminate probability theory addresses this gap.

\subsection{Definition of Indeterminate Probability}

Define a special random variable $X$ to represent the i.i.d. random experiments, where $X=x_{k}$ corresponds to the $k^{th}$ experiment:

\begin{equation}
   \label{eq:P_X}    
   P\left ( x_{k}   \right ) = \frac{1}{n}, k = 1,2,\dots,n. 
   \end{equation}



As discussed in Section~\ref{sec:introduction}, observations (by machines, models, or humans) yield probability distributions for each experiment. 
Indeterminate probability represents the observed outcome of the $k^{th}$ experiment as

\begin{equation}
   \label{eq:P_a_X}    
   \text{Indeterminate Probability}:= P\left (a_{i_{j} }^{j}\mid x_{k}   \right ) \in [0,1]
   \end{equation}

Conditioning on $X$ has a distinct interpretation:   
$P(A|X=x_k)$ signifies the likelihood of $A$ occurring in the $k^{th}$ experiment.
This differs fundamentally from conditioning on other variables.

In classical probability, event states are binary: $P(A^j = a_{i_j}^j \mid X = x_k) \in \{0,1\}$.
For example (Section~\ref{sec:example}), $P(Y = hd \mid X = x_3) = 1$.
This distinction renders frequency-based equations inapplicable.

For multivariate variables $\mathbb{A} = \left (A^{1},A^{2},\dots,A^{N} \right )$,
observations from different observers are independent.
Empirical evidence suggests that this independence also holds for the same observer  
considering $Y$ and $A^{1},A^{2},...,A^{N}$ from different perspectives. We have Axiom~\ref{axm:A_X_independence}:


\begin{axiom}
   \label{axm:A_X_independence}
   $A^{1} \indep A^{2}\indep,\dots, A^{N} \mid X : $
   Given $X$, $A^{1},A^{2},\dots,A^{N}$ are conditionally mutually independent.
   \end{axiom}

The joint indeterminate probability is

\begin{equation}
   \label{eq:P_A_X}  
   P\left (a_{i_{1}}^{1}, a_{i_{2}}^{2},\dots, a_{i_{N}}^{N}\mid x_{k}   \right ) 
   =   \prod_{j=1}^{N}  P\left ( a_{i_{j} }^{j}\mid x_{k}   \right ) \in [0,1]
   \end{equation}


Where it can be easily proved,
\begin{equation}
   \label{eq:Sum_P_A_X}    
   \sum_{\mathbb{A}} \prod_{j=1}^{N}  P\left ( a_{i_{j} }^{j}\mid x_{k}   \right ) = 1, k=1,2,\dots ,n.
   \end{equation}

In classical probability, the joint indeterminate probability ${\textstyle \prod_{j=1}^{N}}P\left ( a_{i_{j} }^{j}\mid x_{k}   \right ) \in \{0,1\}$.


\subsection{Observation Phase}

The conditional probability is:

\begin{equation}
   \label{eq:P_Y_A_1}
   P\left (y_{l} \mid a_{i_{1}}^{1},a_{i_{2}}^{2},\dots,a_{i_{N}}^{N} \right ) 
   =  \frac{P\left (y_{l},  a_{i_{1}}^{1},a_{i_{2}}^{2},\dots,a_{i_{N}}^{N} \right )}
   {P\left ( a_{i_{1}}^{1},a_{i_{2}}^{2},\dots,a_{i_{N}}^{N} \right )} 
   \end{equation}

Using the total probability theorem over $X$ with Equation~\ref{eq:P_X} and Equation~\ref{eq:P_A_X}:

\begin{equation}
   \label{eq:P_A}
   \begin{aligned}
   P\left (a_{i_{1}}^{1},a_{i_{2}}^{2},\dots,a_{i_{N}}^{N} \right ) 
   &=   {\textstyle \sum_{k=1}^{n}}
   \left ( P\left (a_{i_{1}}^{1},a_{i_{2}}^{2},\dots,a_{i_{N}}^{N} \mid x_{k}\right )\cdot P(x_{k})  \right ) \\
   &=  {\textstyle \sum_{k=1}^{n}}
   \left ( {\textstyle \prod_{j=1}^{N}}P\left ( a_{i_{j} }^{j}\mid x_{k}   \right )  \cdot P(x_{k})  \right ) \\
   &=\frac{   {\textstyle \sum_{k=1}^{n}} \left ( {\textstyle \prod_{j=1}^{N}}P\left ( a_{i_{j} }^{j}\mid x_{k}   \right ) \right ) }{n} 
   \end{aligned}
   \end{equation}

Since $Y$ and $A^j$ derive from different observational perspectives (or same observer with different perspectives):

\begin{axiom}
   \label{axm:Y_A_independence}
   $Y \indep A^{j} \mid X : $
   Given $X$, $A^{j}$ and $Y$ are conditionally mutually independent in the observation phase, $j=1,2,\dots,N$.
   \end{axiom}

Thus:

\begin{equation}
   \label{eq:P_YA}
   \begin{aligned}
   P\left (y_{l}, a_{i_{1}}^{1},a_{i_{2}}^{2},\dots,a_{i_{N}}^{N} \right )
   &= {\textstyle \sum_{k=1}^{n}}
   \left ( P\left (y_{l}, a_{i_{1}}^{1},a_{i_{2}}^{2},\dots,a_{i_{N}}^{N} \mid x_{k}\right )\cdot P(x_{k})  \right ) \\
   &=  {\textstyle \sum_{k=1}^{n}}
   \left ( P\left (y_{l}\mid x_{k}\right )\cdot {\textstyle \prod_{j=1}^{N}}P\left ( a_{i_{j} }^{j}\mid x_{k}   \right )  \cdot P(x_{k})  \right ) \\
   &=\frac{{\textstyle \sum_{k=1}^{n}}
   \left ( P\left (y_{l}\mid x_{k}\right )\cdot {\textstyle \prod_{j=1}^{N}}P\left ( a_{i_{j} }^{j}\mid x_{k}   \right ) \right )}{n} 
   \end{aligned} 
\end{equation}


Substitute Equation~\ref{eq:P_A} and Equation~\ref{eq:P_YA} into Equation~\ref{eq:P_Y_A_1}:  


\begin{equation}
   \label{eq:P_Y_A_2}
   P\left (y_{l}| a_{i_{1}}^{1},a_{i_{2}}^{2},\dots,a_{i_{N}}^{N} \right )
   = \frac{{\textstyle \sum_{k=1}^{n}} \left ( P\left (y_{l}\mid x_{k}\right )\cdot {\textstyle \prod_{j=1}^{N}}P\left ( a_{i_{j} }^{j}\mid x_{k}   \right ) \right )} 
   {  {\textstyle \sum_{k=1}^{n}} \left ( {\textstyle \prod_{j=1}^{N}}P\left ( a_{i_{j} }^{j}\mid x_{k}   \right ) \right ) }
   \end{equation}

Where it can be proved, 

\begin{equation}
   \label{eq:sum_P_A}
   {\textstyle \sum_{l=1}^{m}}P\left (y_{l} \mid a_{i_{1}}^{1},a_{i_{2}}^{2},\dots,a_{i_{N}}^{N} \right ) = 1  
   \end{equation}


Equation~\ref{eq:P_Y_A_2} provides an analytical solution for arbitrary conditional probabilities. 
When $P(a_{i_{j}}^{j}\mid x_{k}) \in\{0,1\}$ and $P(y_{l}\mid x_{k}) \in\{0,1\}$, it reduces to the classical frequency-based probability.
   

\subsection{Inference Phase}


\begin{figure}[htbp]
   \centering
         \begin{subfigure}[b]{0.3\linewidth}
               \centering
               \includegraphics[width=1\linewidth]{figures/Observation.pdf}
               \caption{observation phase}
               \label{fig:observation}
         \end{subfigure}
         \hfil
         \begin{subfigure}[b]{0.3\linewidth}
               \centering
               \includegraphics[width=1\linewidth]{figures/Inference.pdf}
               \caption{inference phase}
               \label{fig:inference}
         \end{subfigure}
         \caption{Independence illustration with Bayesian network.}
         \label{fig:probability_process}
   \end{figure}



Given $\mathbb{A}$ and using Equation~\ref{eq:P_Y_A_2} (based on passed experience), we can infer $Y=y_{l}$.
This inferred $y_{l}$ does not refer to any specific sample $x_{k}$, 
including new input sample $x_{n+1}$. We establish the following axiom:

\begin{axiom}
   \label{axm:Y_X_independence}
   $X \indep Y \mid \left (A^{1},A^{2},\dots,A^{N} \right ) : $
   Given $ \left (A^{1},A^{2},\dots,A^{N} \right )$, $X$ and $Y$ are conditionally mutually independent in the inference phase.
   \end{axiom}    

This phase distinction is necessary because $Y$ is unobserved for new $x_{n+1}$,
and avoids conflict between Axioms~\ref{axm:Y_A_independence} and~\ref{axm:Y_X_independence}.
   

For the next experiment $X=x_{n+1}$, by applying the total probability theorem 
over the joint sample space $\left (a_{i_{1}}^{1},a_{i_{2}}^{2},\dots,a_{i_{N}}^{N} \right ) \in \mathbb{A}$, 
and considering Axiom~\ref{axm:Y_X_independence}, Equation~\ref{eq:P_A_X} and Equation~\ref{eq:P_Y_A_2}, we derive the inference probability as

\begin{equation}
   \label{eq:P_Y_X_via_A}
   \begin{aligned}
   P^{\mathbb{A} } \left ( y_{l} \mid x_{n+1} \right ) &=\sum_{\mathbb{A}} 
   \left ( P\left ( y_{l},a_{i_{1}}^{1}, a_{i_{2}}^{2}  ,  \dots, a_{i_{N}}^{N} \mid x_{n+1} \right )  \right ) \\ 
   &=\sum_{\mathbb{A}} 
   \left ( P\left ( y_{l}\mid a_{i_{1}}^{1}, a_{i_{2}}^{2} ,  \dots, a_{i_{N}}^{N}\right ) \cdot P\left (a_{i_{1}}^{1}, a_{i_{2}}^{2} , \dots, a_{i_{N}}^{N} \mid x_{n+1} \right )  \right ) \quad \text{(Axiom~\ref{axm:Y_X_independence})}\\
   &=\sum_{\mathbb{A}} 
   \left (\frac{{\textstyle \sum_{k=1}^{n}} \left ( P\left (y_{l}\mid x_{k}\right )\cdot {\textstyle \prod_{j=1}^{N}}P\left ( a_{i_{j} }^{j}\mid x_{k}   \right ) \right )} 
   {  {\textstyle \sum_{k=1}^{n}} \left ( {\textstyle \prod_{j=1}^{N}}P\left ( a_{i_{j} }^{j}\mid x_{k}   \right ) \right ) } 
   \cdot\prod_{j=1}^{N}  P\left ( a_{i_{j} }^{j}\mid x_{n+1}   \right )  \right )
   \end{aligned}
\end{equation}

Where the superscript $\mathbb{A}$ denotes inference via latent variables $\mathbb{A}$.
$P^{\mathbb{A} } \left ( y_{l} \mid x_{n+1} \right )$ and $P\left ( y_{l} \mid x_{k} \right )$ are mathematically equivalent, representing inferred and observed indeterminate probabilities, respectively.

The discrete decision rule is:
\begin{equation}
   \label{eq:argmax}
   \hat{y} := { \underset{l\in \left \{ 1,2,\dots,m \right \}} {\arg\max} \,  P^{\mathbb{A} } \left ( y_{l} \mid x_{n+1} \right ) }  
   \end{equation}

\subsection{Phase Distinction}
   The framework operates in two distinct phases:
   
   \textbf{Observation Phase} builds probabilistic relationships exclusively from historical data $\mathcal{D} = \{(x_k, P(Y|x_k), P(\mathbb{A}|x_k))\}_{k=1}^n$. Under Axioms \ref{axm:A_X_independence} and \ref{axm:Y_A_independence}, it computes the core conditional distribution $P(Y|\mathbb{A})$ through Eq. \ref{eq:P_Y_A_2}. This phase requires complete distributional records $(P(Y|X), P(\mathbb{A}|X))$ for all $x_k \in \mathcal{D}$.
   
   \textbf{Inference Phase} utilizes $P(Y|\mathbb{A})$ for prediction on any i.i.d $x_t$ (including $x_t \notin \mathcal{D}$ or $x_t \in \mathcal{D}$). Given observer output $P(\mathbb{A}|X=x_t)$, it computes predictions via Eq. \ref{eq:P_Y_X_via_A} under Axiom \ref{axm:Y_X_independence}. Critically, this phase never modifies $P(Y|\mathbb{A})$ from the observation phase and
   treats $x_{\text{t}}$ as statistically independent of historical $Y$ given $\mathbb{A}$.


\subsection{Complexity Reduction}\label{sec:Complexity}

Equation~\ref{eq:P_Y_X_via_A} can be reformulated as an expectation.
Monte Carlo approximation reduces complexity from $O(m\prod_{j=1}^{N}M_{j})$ to $O(m n N C)$.


\begin{equation}
   \label{eq:P_Y_X_via_A_expectation}
   \begin{aligned}
   P^{\mathbb{A} } \left ( y_{l} \mid x_{n+1} \right )
   &=\mathbb{E}_{a_{i_{j} }^{j}\sim  P\left ( a_{i_{j} }^{j}\mid x_{n+1}   \right )}
   \left [\frac{{\textstyle \sum_{k=1}^{n}} \left ( P\left (y_{l}\mid x_{k}\right )\cdot {\textstyle \prod_{j=1}^{N}}P\left ( a_{i_{j} }^{j}\mid x_{k}   \right ) \right )} 
   {  {\textstyle \sum_{k=1}^{n}} \left ( {\textstyle \prod_{j=1}^{N}}P\left ( a_{i_{j} }^{j}\mid x_{k}   \right ) \right ) }  \right ] \\
   &\approx \frac{1}{C}\sum_{c=1}^{C} 
   \left (\frac{{\textstyle \sum_{k=1}^{n}} \left ( P\left (y_{l}\mid x_{k}\right )\cdot {\textstyle \prod_{j=1}^{N}}P\left ( a_{i_{j},c }^{j}\mid x_{k}   \right ) \right )} 
   {  {\textstyle \sum_{k=1}^{n}} \left ( {\textstyle \prod_{j=1}^{N}}P\left ( a_{i_{j},c }^{j}\mid x_{k}   \right ) \right ) }  \right ),
   \end{aligned}
\end{equation}



where $a_{i_{j},c}^{j}\sim  P\left ( a_{i_{j} }^{j}\mid x_{n+1}   \right )$ and $C$ represents the number of Monte Carlo samples.

Unlike Markov Chain Monte Carlo methods~\cite{monte_carlo}, which requires a large number of samples from a complex and high-dimensional space,
CIPNN achieves accurate results with $C=2$ even in 1000D latent spaces (see~\cite{cipnn}).

\subsection{Summary}\label{sec:summary}

\begin{theorem}[Frequency-based Probability Subsumption]\label{thm:classical_subsumption}
   When observation errors vanish such that all indeterminate probabilities become deterministic, i.e., 
   $P(a_{i_j}^j \mid x_k) \in \{0,1\}$ and $P(y_l \mid x_k) \in \{0,1\}$ 
   for all $j=1,\dots,N$, $l=1,\dots,m$, and $k=1,\dots,n, n+1$, 
   the inference probability $P^{\mathbb{A}}(Y=y_l \mid X=x_{n+1})$ in Equation~\ref{eq:P_Y_X_via_A} reduces to the classical frequency-based conditional probability.
   \end{theorem}
   
\begin{proof}
   Under deterministic observations:
   \begin{enumerate}
         \item The product $\prod_{j=1}^N P(a_{i_j}^j \mid x_k) \in \{0,1\}$ acts as an indicator function $\mathbb{I}_{\mathbb{A}}(x_k)$ for event $\mathbb{A}$ occurring in experiment $x_k$
         \item $P(y_l \mid x_k) \in \{0,1\}$ acts as indicator $\mathbb{I}_{y_l}(x_k)$ for outcome $y_l$ in $x_k$
         \item The observation-phase term simplifies to frequency counts:
         \[
         \frac{\sum_{k=1}^n \mathbb{I}_{y_l}(x_k) \cdot \mathbb{I}_{\mathbb{A}}(x_k)}{\sum_{k=1}^n \mathbb{I}_{\mathbb{A}}(x_k)} 
         = P_{\text{classical}}(y_l \mid \mathbb{A})
         \]
         \item For $x_{n+1}$, $\prod_{j=1}^N P(a_{i_j}^j \mid x_{n+1}) \in \{0,1\}$ selects the actual event $\mathbb{A}^*$ (1 when $\mathbb{A} = \mathbb{A}^*$, 0 otherwise)
         \item The inference sum collapses to the classical prediction:
         \[
         \sum_{\mathbb{A}} \left( P_{\text{classical}}(y_l \mid \mathbb{A}) \cdot \mathbb{I}_{\mathbb{A}}(x_{n+1}) \right) = P_{\text{classical}}(y_l \mid \mathbb{A}^*)
         \qedhere
         \]
   \end{enumerate}
   \end{proof}

Our core contribution is the tractable probability formulation:

\begin{align}   
&\boldsymbol{ P^{\mathbb{A}}\left ( Y=y_{l}\mid X=x_{n+1}\right )} \nonumber \\
\label{eq:eq1}
&=\sum_{\mathbb{A}}P\left ( y_{l},\mathbb{A}\mid x_{n+1}   \right ) \quad \text{(marginalization)}\\
\label{eq:eq2}
&=\sum_{\mathbb{A}}\left (P\left ( y_{l}\mid \mathbb{A} \right )
\cdot P(\mathbb{A}\mid x_{n+1}) \right ) \quad \text{(Axiom~\ref{axm:Y_X_independence})} \\
\label{eq:eq3}
&=\sum_{\mathbb{A}}\left (\frac{ {\textstyle \sum_{k=1}^{n}\left ( 
   P(y_{l}\mid x_{k})\cdot  P(\mathbb{A}\mid x_{k}) \right ) } } {{\textstyle \sum_{k=1}^{n}P(\mathbb{A}\mid x_{k})  } }
\cdot P(\mathbb{A}\mid x_{n+1}) \right ) \quad \text{(Axiom~\ref{axm:Y_A_independence})}\\
\label{eq:eq4}
&=\underset{\text{Inference phase}}{\underbrace{\sum\limits_{\mathbb{A}}\left (  
\underset{\text{Observation phase}}{\underbrace{\frac{ \sum\limits_{k=1}^{n}
   \left ( \boldsymbol{ P\left ( y_{l}\mid x_{k}   \right )}\cdot
\prod\limits_{j=1}^{N}P\left ( a_{i_{j} }^{j}\mid X=x_{k}   \right )   \right )}
{\sum\limits_{k=1}^{n}
   \left ( \prod\limits_{j=1}^{N}P\left ( a_{i_{j} }^{j}\mid x_{k}   \right )   \right )} }}
\cdot  \prod\limits_{j=1}^{N}P\left ( a_{i_{j} }^{j}\mid x_{n+1}   \right ) \right )}}   \quad \text{(Axiom~\ref{axm:A_X_independence})}
\end{align}


This formulation remains valid for continuous or mixed latent variables $\mathbf{z}$. In such cases, 
the summation $\sum_{\mathbb{A}}$ must be replaced by the appropriate integration:
\begin{itemize}
    \item For continuous $\mathbf{z}$: $\sum_{\mathbb{A}} \rightarrow \int_{\mathbf{z}} d\mathbf{z}$
    \item For mixed discrete-continuous $\mathbf{z}$: $\sum_{\mathbb{A}} \rightarrow \sum_{\mathbf{z}_{\text{disc}}} \int_{\mathbf{z}_{\text{cont}}} d\mathbf{z}_{\text{cont}}$
\end{itemize}

The three axioms of conditional independence are foundational but not formally provable.
Validation relies on empirical evidence, and we encourage counterexamples. 
Should even a toy dataset contradict these axioms, the validity of the proposed theory would be falsified.

Finally, Equation~\ref{eq:eq4} subsumes frequency-based probability as a special case when observation error vanishes
, as discussed in Theorem~\ref{thm:classical_subsumption}.
See Appendix~\ref{app:intuitive_explain} for intuition.



\section{Applications}\label{sec:applications}

\subsection{IPNN}\label{sec:ipnn}

For neural network tasks, $X=x_{k}$ is for the  $k^{th}$ input sample, $P(y_{l}|x_{k})=y_{l}(k)\in[0,1]$ is for the soft/hard label of train sample $x_{k}$, 
$P^{\mathbb{A}} \left ( y_{l} \mid x_{t} \right )$ is for the predicted label of test sample $x_{t}$.



\begin{figure}
  \centerline{\includegraphics[width=0.5\linewidth]{figures/ModelArchitecture.pdf}}
  \caption{IPNN model architecture. $P \left (y_{l} |a_{i_{1}}^1,a_{i_{2}}^2,\dots,a_{i_{N}}^N \right )$ is statistically calculated, not model weights.}
  \label{fig:ModelArchitecture}
  \end{figure}

  

Figure~\ref{fig:ModelArchitecture} shows IPNN model architecture, the output neurons of a general neural network 
(FFN, CNN, Resnet~\cite{resnet}, Transformer~\cite{Transformer}, Pretrained-Models~\cite{bert}, etc.) 
is split into N unequal/equal parts, the split shape is marked as Equation~\ref{eq:split_shape}, 
hence, the number of output neurons is the summation of the split shape ${\textstyle \sum_{j=1}^{N}M_{j}}$.
Next, each split part is passed to `softmax', so the output neurons can be defined as discrete random variable 
$A^{j} \in \left \{ a_{1}^{j} , a_{2}^{j} , \dots, a_{M_{j}}^{j} \right \},j=1,2,\dots,N$, and each neuron in $A^{j}$ is regarded as an event. 
After that, all the random variables together form the N-dimensional joint sample space, marked as $\mathbb{A} = (A^{1},A^{2},\dots,A^{N})$, and all the joint sample points are fully connected 
with all labels $Y \in \{y_{1},y_{2},\dots,y_{m} \}$ via conditional probability $P \left (y_{l} |a_{i_{1}}^1,a_{i_{2}}^2,\dots,a_{i_{N}}^N \right )$.


 

\begin{equation}
   \label{eq:split_shape}    
   \text{Split shape} := \{ M_{1},M_{2},\dots,M_{N} \} 
   \end{equation}


Given an input sample $x_{k}$, let $\alpha _{i_{j}}^{j}(k)$ be the model outputted value after `softmax'.
With Assumption~\ref{asm:random_variable}, the indeterminate probability (model output) is

\begin{equation}
   \label{eq:P_ipnn_Indeterminate}    
   P\left (a_{i_{j} }^{j}\mid x_{k}   \right ) := \alpha _{i_{j}}^{j}(k)
   \end{equation}

\begin{assumption}
   \label{asm:random_variable}    
   For neural networks, given an input sample $X=x_{k}$, 
   \textbf{IF} ${\textstyle \sum_{i_{j}=1}^{M_{j}}} \alpha _{i_{j}}^{j}(k) = 1$ and $\alpha _{i_{j}}^{j}(k)\in [0,1], k=1,2,\dots ,n$.
   \textbf{THEN},  
   $\left \{ a_{1}^{j} , a_{2}^{j} , \dots, a_{M_{j}}^{j} \right \}$ can be regarded as collectively exhaustive and exclusive events set, 
   they are partitions of the sample space of random variable $A^{j}, j=1,2,\dots,N$.
   \end{assumption}

According to Equation~\ref{eq:P_Y_X_via_A}, the prediction for test sample $x_{t}$ is

\begin{equation}
   \label{eq:P_Y_X_via_A_ipnn}    
   P^{\mathbb{A}} \left ( y_{l} \mid x_{t} \right ) = 
   \sum_{\mathbb{A}} 
   \left ( \frac{ \sum_{k=1}^{n}\left ( y_{l}(k)   \cdot { \prod_{j=1}^{N}}\alpha _{i_{j} }^{j}(k)  \right ) }
   {\sum_{k=1}^{n}\left ( { \prod_{j=1}^{N}}\alpha _{i_{j} }^{j}(k) \right ) } 
   \cdot\prod_{j=1}^{N}\alpha_{i_{j} }^{j}(t)  \right )
   \end{equation}


We use cross entropy as loss function:

\begin{equation}
   \label{eq:loss}
   \mathcal{L} =  -{\textstyle \sum_{l=1}^{m}} \left (  y_{l}(k)\cdot  \log P^{\mathbb{A} } \left ( y_{l} \mid x_{t} \right )\right ) 
   \end{equation}

More details on IPNN, including the introduction, related work, training Strategy, limitations, etc., can be found in Appendix~\ref{app:app_ipnn}.


\subsection{CIPNN and CIPAE}\label{sec:cipnn_and_cipae}

In \cite{cipnn}, we extended the indeterminate probability distribution to continuous random variable distribution.
We propose a general classification model called CIPNN, which works even for a 1000-dimensional latent space.

Besides, we propose a general auto-encoder called CIPAE, which do not even have the decoder component. The framework between
CIPAE and VAE~\cite{VAE} is almost the same, but VAE must use a neural network as the decoder. 
This is a special ability of our analytical solution.


\subsection{MTS forecasting}\label{sec:MTS_forecasting}

In \cite{seqip}, it shows how to consider multivariate point value as indeterminate probability distribution.
And the multivariate time series (MTS) forecasting problem is formulated as a complex distributions without relying on any neural models,
and the method even does not need any training process.
With our proposed theory, the complex distributions becomes analytical tractable, even in the presence of a 1000-dimensional latent space.

Although our proposed theory is motivated by design of new neural network architectures,
it is not limited to neural networks.
This is supported by our MTS forecasting method, which serves as strong evidence.


\section{Validations}\label{sec:experiment}

The validations in this section are focusing on our proposed axioms.
More validations or usefulness of our theory, you can also find in \cite{cipnn,seqip}.

\subsection {Evaluation on Datasets}

\begin{wrapfigure}{R}{0.6\columnwidth}    
   \centering
       \captionof{table}{Test accuracy with 3-D latent space; backbone is FCN for MNIST and Fashion-MNIST, Resnet50~\cite{resnet} for CIFAR10 and STL10.}
       \label{tab:test_accuracy}
       \begin{tabular}{cccc}
           \hline
           Dataset                    & CIPNN         & IPNN          & Simple-Softmax\\
           \hline
           MNIST                      & $95.9\pm 0.3$ & $95.8\pm 0.5$ & $97.6\pm 0.2$ \\
           \makecell{Fashion-\\MNIST} & $85.4\pm 0.3$ & $84.5\pm 1.0$ & $87.8\pm 0.2$ \\
           CIFAR10                    & $81.3\pm 1.6$ & $83.6\pm 0.5$ & $85.7\pm 0.9$ \\
           STL10                      & $92.4\pm 0.4$ & $91.6\pm 4.0$ & $94.7\pm 0.7$ \\
           \hline
       \end{tabular}   
   \end{wrapfigure}


Results on MNIST~\cite{mnist}, Fashion-MNIST~\cite{fashion_mnist}, CIFAR10~\cite{cifar10} and STL10~\cite{stl10} show that 
our proposed indeterminate probability theory is valid,
the backbone between IPNN, CIPNN and `Simple-Softmax' is the same, the last layer of the latter one is connected to softmax function. 
Although IPNN and CIPNN does not reach any SOTA, 
the results are very important evidences to our proposed mutual independence axioms, 
see Axiom~\ref{axm:A_X_independence}, Axiom~\ref{axm:Y_A_independence} and Axiom~\ref{axm:Y_X_independence}.


\subsection {Evaluation on Large Latent Space}

For IPNN, we cannot use Monte Carlo method to reduce the exponential complexity (Section~\ref{sec:Complexity}),
otherwise, IPNN will be not able to do back-propagation. Hence, we validate IPNN till to 20-D dimension.

Besides, for larger latent space, IPNN has also over-fitting problem when the dimension increases,
this is only the limitation of IPNN, not CIPNN.

\begin{table}[htbp]
   \caption{Average test accuracy of 10 times results on Large Latent Space on MNIST\@.}
   \label{tab:results_large_latent_space}
   \begin{center}
   \begin{tabular}{ccccccccc}
   \hline
   Latent space    & 5-D  & 10-D & 20-D &  50-D &  100-D &  200-D & 500-D & 1000-D \\
   IPNN            & 94.8 & 88.6 & 80.6 & - &  -  &  -  & -  & -   \\
   CIPNN           & 95.6 & 94.7 & 94.7 &  94.9 &  94.9  &  94.9  & 94.7  & 93.4 (2 times)  \\
   \hline
   \end{tabular}
   \end{center}
   \end{table}


\subsection {Evaluation with Duplicated Random Variable Inference}


If the latent variables are the same, i.e., $A^{1}$ is identical to $A^{2}$, then this is the most critical case for Axiom~\ref{axm:A_X_independence}. 

This is a critical example from Section~\ref{sec:example}.

Let $\mathbf{z} = (z,z,...)^{N}$, we use N same random variable z for the inference,
with Equation~\ref{eq:P_Y_A_2} we have

\begin{equation}
   \begin{aligned}
    P(Y=hd|z,z,...) &= \frac{\sum_{k=1}^{10}P(Y=hd|X=x_{k})\cdot P(z|X=x_{k})^{N}}{\sum_{k=1}^{10}P(z|X=x_{k})^{N}} \\
    &= \frac{\mathcal{N}(z;3,1)^{N}}{\mathcal{N}(z;3,1)^{N}+\mathcal{N}(z;-3,1)^{N}}
   \end{aligned}
\end{equation}

For next coin toss, let $P(z|X=x_{11})=\mathcal{N}(z;3,1)$, with Equation~\ref{eq:P_Y_X_via_A}, similar to Equation~\ref{eq:example_gauss_coin_toss}, we have


\begin{equation}
   P^{\mathbf{z}}(Y=hd|X=x_{11}) 
   = \frac{1}{C}\sum_{c=1}^{C}\frac{\mathcal{N}(z_{c};3,1)^{N}}{\mathcal{N}(z_{c};3,1)^{N}+\mathcal{N}(z_{c};-3,1)^{N}} \approx 1,  z_{c} \sim \mathcal{N}(z;3,1)
\end{equation}

We can see that even for duplicated random variables, our calculation results are also almost not effected.


Besides, in \cite{seqip}, we have duplicated the MTS dataset for abuse test of our theory, and results show that 
it has no negative effect to the forecasting performance.



\section{Related Work}\label{sec:related_work}

Indeterminate Probability Theory (IPT) is connected to probability foundations, uncertainty quantification, and observer-dependent frameworks. Key connections are formalized below:


\paragraph{Classical Probability Foundations} Kolmogorov's axiomatic framework~\cite{kolmogorov_probability} establishes the mathematical basis for both frequentist and Bayesian paradigms.
Frequentist approaches treat probability as long-run frequency under repeated trials, using clearly defined and unambiguously observations to infer underlying distributions.
Bayesian methods~\cite{bernardo_smith_bayesian_theory} treat probability as subjective belief, iteratively updating priors with observations to approximate reality. 
While classical frameworks model randomness in phenomena, IPT explicitly formalizes distortions from imperfect observation systems (e.g., sensor noise, cognitive biases), reducing to classical measures only when observation error vanishes (Theorem~\ref{thm:classical_subsumption}).

\paragraph{Uncertainty Modeling} Bayesian Methods, such as Bayesian Neural Networks~\cite{neal_bayes_network}, MC-Dropout~\cite{gal_mc_dropout}, and deep ensembles~\cite{lakshminarayanan_deep}, quantify model uncertainty via sampling.
Probabilistic Graphical Models (PGMs) encode conditional dependencies~\cite{pearl_bayes_network, koller_pgms} but require approximations for complex topologies. Fuzzy logic represents vagueness via membership functions~\cite{Goguen_funzzy_control}.
IPT's role provides closed-form solutions for high-dimensional $P(Y|\mathbf{z})$~\ref{sec:ip_theory} by jointly modeling system states and observer-induced distortions.

\paragraph{VAEs} Modern large-scale inference in complex probabilistic models often involves intractable posterior distributions. To address this, approximate inference techniques such as Markov Chain Monte Carlo (MCMC)~\cite{monte_carlo} and variational Bayesian methods~\cite{variational_method} have been widely adopted~\cite{VAE2}.
The Variational Autoencoder (VAE) framework provides an efficient estimator of the evidence lower bound (ELBO) for continuous latent variable models. Crucially, its encoder module functions as a stochastic observer that maps input data to parameters of an approximate posterior distribution, typically modeled as a diagonal-covariance multivariate Gaussian for simplicity~\cite{VAE}.
This diagonal covariance assumption explicitly embodies the latent dimension independence principle formalized in Axiom~\ref{axm:A_X_independence}.
Empirically, VAEs have demonstrated versatility across diverse domains including
image generation~\cite{VAE_use_image}, anomaly detection~\cite{VAE_use_anomaly} and de-noising tasks~\cite{VAE_use_denoise}~\cite{VAE_use_summary}, etc. These successful applications provide empirical support for the functional validity of Axiom~\ref{axm:A_X_independence} in practical observer implementations.


\section{Conclusion}\label{sec:conclusion}

This paper introduces \textbf{Indeterminate Probability Theory} (IPT), a novel framework for probabilistic reasoning under observation uncertainty. By explicitly modeling the interplay between ground truth and observer-dependent outputs, IPT provides a principled approach to handling discrete and continuous uncertainties within a unified formalism. The theory's conditional independence axioms (Axioms~\ref{axm:A_X_independence},\ref{axm:Y_A_independence},\ref{axm:Y_X_independence}) enable closed-form solutions for complex joint distributions, overcoming computational intractability in high-dimensional settings.

Two key applications validate IPT's efficacy:

\begin{itemize}
   \item The \textit{Indeterminate Probability Neural Network} (IPNN) enables tractable probabilistic inference in latent spaces of up to 1000 dimensions.
   \item In \textit{non-neural multivariate time series forecasting}, IPT outperforms LSTM and Transformer baselines by explicitly modeling observer-induced uncertainty.
\end{itemize}

Beyond these specific applications, IPT offers broader methodological implications across disciplines:
\begin{itemize}
\item Supervised classification may interpret data clusters as indeterminate distributions over labels.
\item Ensemble learning may formalize heterogeneous model outputs as indeterminate probabilities.
\item Physical systems may potentially benefit from IPT's observer-dependent formalism, particularly where inherent uncertainty exists (e.g., quantum measurement scenarios under Heisenberg's Uncertainty Principle \cite{uncertainty_principle}).
\end{itemize}

Notably, IPT is fully compatible with classical probability theory, subsuming it as a limiting case when observational error vanishes (see Theorem~\ref{thm:classical_subsumption}). More importantly, it provides a coherent extension for scenarios where measurements are inherently uncertain or context-dependent.

Future research directions include:
\begin{itemize}
\item Investigating theoretical connections to measure-theoretic probability and information geometry;
\item Exploring applications in causal inference and decision-making under ambiguity;
\item Conducting empirical validation in domains such as quantum measurement and nonlinear dynamical systems.
\end{itemize}

In summary, Indeterminate Probability Theory establishes a unified framework for probabilistic reasoning in contexts where observer effects cannot be neglected, offering both theoretical depth and practical utility.

\section*{Acknowledgment}

The authors would like to thank Mr. Jianlin Su for his insightful introduction to the VAE model\footnote{Available at: \url{https://kexue.fm/archives/5253}}.
The authors also gratefully acknowledge the helpful comments from anonymous reviewers of the previous submissions.

\bibliography{iclr2024_conference}
\bibliographystyle{iclr2024_conference}

\begin{appendix}

\input{ipnn_app.tex}

\end{appendix}

\end{document}
