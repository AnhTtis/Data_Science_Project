%%%%%%%% ICML 2023 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}
\pdfoutput=1
% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2023} with \usepackage[nohyperref]{icml2023} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2023}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2023}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}

\newcommand{\eg}{e.g.}
\newcommand{\etc}{etc}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Indeterminate Probability Neural Network}

\begin{document}

\twocolumn[
\icmltitle{Indeterminate Probability Neural Network}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2023
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}


\begin{icmlauthorlist}
\icmlauthor{Tao Yang}{yyy}
\icmlauthor{Chuang Liu}{}
\icmlauthor{Xiaofeng Ma}{}
\icmlauthor{Weijia Lu}{}
\icmlauthor{Ning Wu}{}
\icmlauthor{Bingyang Li}{} \\
\icmlauthor{Zhifei Yang}{}
\icmlauthor{Peng Liu}{}
\icmlauthor{Lin Sun}{}
\icmlauthor{Xiaodong Zhang}{}
\icmlauthor{Can Zhang}{}
\end{icmlauthorlist}

\icmlaffiliation{yyy}{All authors are from AI Lab, United Automotive Electronic Systems Co., Ltd. Shanghai, China}

\icmlcorrespondingauthor{Tao Yang}{tao.yang9@uaes.com} %yangtao2815@163.com

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Indeterminate Probability, Discrete Random Variable, Unsupervised Clustering, Classification, IPNN}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
    We propose a new general model called \textbf{IPNN} \textendash\enspace\textbf{I}ndeterminate \textbf{P}robability \textbf{N}eural \textbf{N}etwork, 
    which combines neural network and probability theory together. In the classical probability theory, 
    the calculation of probability is based on the occurrence of events, which is hardly used in current neural networks. 
    In this paper, we propose a new general probability theory, which is an extension of classical probability theory,
    and makes classical probability theory a special case to our theory.
    Besides, for our proposed neural network framework, the output of neural network is defined as probability events, and based on the statistical analysis 
    of these events, the inference model for classification task is deduced. IPNN shows new property: It can perform unsupervised clustering 
    while doing classification. Besides, IPNN is capable of making very large classification with very small neural network, \eg\enspace model with 100 output nodes can classify 10 billion categories. 
    Theoretical advantages are reflected in experimental results. (Source code: https://github.com/Starfruit007/ipnn)
\end{abstract}


\section{Introduction}\label{sec_introduction}


Humans can distinguish at least 30,000 basic object categories~\cite{ipnn:human_Recognition}, classification of all these 
would have two challenges: It requires huge well-labeled images; Model with softmax for large scaled datasets is computationally expensive.
Zero-Shot Learning \textendash\enspace ZSL~\cite{ipnn:ZSL,ipnn:ZSL_Summary} method provides an idea for solving the first problem, which is an attribute-based classification method. 
ZSL performs object detection
based on a human-specified high-level description of the target object instead of training images, like shape, color or even geographic information.
But labelling of attributes still needs great efforts and expert experience. Hierarchical softmax can solve the computationally expensive problem,
but the performance degrades as the number of classes increase~\cite{ipnn:softmax}.

Probability theory has not only achieved great successes in the classical area, 
such as Na\"{\i}ve Bayesian method~\cite{ipnn:bayes_study}, 
but also in deep neural networks (VAE~\cite{ipnn:VAE}, ZSL, etc.) over the last years.  
However, both have their shortages: Classical probability can not extract features from samples; 
For neural networks, the extracted features are usually abstract and cannot be directly used for numerical probability calculation.
What if we combine them?

There are already some combinations of neural network and bayesian approach, 
such as probability distribution recognition~\cite{ipnn:bayes_combine_recognition,ipnn:bayes_combine_timeseries},
Bayesian approach are used to improve the accuracy of neural modeling~\cite{ipnn:bayes_model}, \etc. However, current combinations
do not take advantages of ZSL method.

We propose an approach to solve the mentioned problems, and our contributions are summarized as follows:

\begin{itemize}
    \item We propose a new general probability theory \textendash\enspace indeterminate probability theory, which is an extension of classical probability theory,
    and makes classical probability theory a special case to our theory.
    \item We interpret the output neurons of neural network as events of discrete random variables, 
        and indeterminate probability is defined to describe the uncertainty of the probability event state.
    \item We propose a novel unified combination of (indeterminate) probability theory and deep neural network.
        The neural network is used to extract attributes which are defined as discrete random variables, and the inference model for classification task is derived.
        Besides, these attributes do not need to be labeled in advance.

\end{itemize}

The rest of this paper is organized as follows: In \cref{sec_background}, 
we first introduce a coin toss game as example of human cognition to explain the core idea of IPNN\@.
In \cref{sec_ipnn}, the model architecture and indeterminate probability is derived. 
\cref{sec_training} discusses the training strategy and related hyper-parameters. 
In \cref{sec_experiment}, we evaluate IPNN and make an impact analysis on its hyper-parameters.
Finally, we put forward some future research ideas and conclude the paper in \cref{sec_conclusion}.
% \footnote{Source code: https://github.com/Starfruit007/ipnn}



\section{Background}\label{sec_background}

Let's first introduce a small game \textendash\enspace coin toss: a child and an adult are observing the outcomes of each coin toss 
and record the results independently (heads or tails), the child can't always record the results correctly 
and the adult can record it correctly, in addition, the records of the child are also observed by the adult. 
After several coin tosses, the question now is, suppose the adult is not allowed to watch the next coin toss, 
what is the probability of his inference outcome of next coin toss via the child's record?


As shown in \cref{fig_example_background}, random variables X is the random experiment itself, and $X=x_{k}$ represent the $k^{th}$ random experiment. Y and A are defined to represent 
the adult's record and the child's record, respectively. And $hd, tl$ is for heads and tails. For example, after 10 coin tosses, 
the records are shown in \cref{tab_X_details}.

\begin{figure}[htbp]
    \vskip 0.2in
    \begin{center}
        \centerline{\includegraphics[width=0.6\columnwidth]{Example_Background.pdf}}
        \caption{Example of coin toss game.}
        \label{fig_example_background}
    \end{center}
    \vskip -0.2in
\end{figure}

\begin{table}[htbp]
    \caption{Example of 10 times coin toss outcomes}
    \label{tab_X_details}
    \vskip 0.15in
    \begin{center}
    \begin{small}
    \begin{sc}
    \begin{tabular}{cccc}
        \toprule
        Experiment & Truth & A &  Y \\
        $X=x_{1}$ & $hd$ & $A=hd$ & $Y=hd$ \\
        $X=x_{2}$ & $hd$ & $A=hd$ & $Y=hd$\\
        $X=x_{3}$ & $hd$ & $A=hd$ & $Y=hd$\\
        $X=x_{4}$ & $hd$ & $A=hd$ & $Y=hd$\\
        $X=x_{5}$ & $hd$ & $\mathbf{A=tl}$ & $Y=hd$\\
        $X=x_{6}$ & $tl$ & $A=tl$ & $Y=tl$\\
        $X=x_{7}$ & $tl$ & $A=tl$ & $Y=tl$\\
        $X=x_{8}$ & $tl$ & $A=tl$ & $Y=tl$\\
        $X=x_{9}$ & $tl$ & $A=tl$ & $Y=tl$\\
        $X=x_{10}$ & $tl$ & $A=tl$ & $Y=tl$\\
        $X=x_{11}$ & $hd$ & A=? & Y=?\\
        \bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
\vskip -0.1in
\end{table}

We formulate X compactly with the ground truth, as shown in \cref{tab_X} and \cref{tab_YA_X}.

\begin{table}[htbp]
    \caption{Outcomes of 10 times coin toss: $P(X)$}
    \label{tab_X}
    \vskip 0.15in
    \begin{center}
    \begin{small}
    \begin{sc}
    \begin{tabular}{ccc}
        \toprule
        $ \frac{\#(X)}{n} $    & $X=hd$ & $X=tl$ \\
        \midrule
        & 5/10    & 5/10    \\
        \bottomrule
    \end{tabular}
    \end{sc}
    \end{small}
    \end{center}
    \vskip -0.1in
\end{table}


\begin{table}[htbp]
    \caption{The adult's and child's records: $P(Y|X)$ and $P(A|X)$}
    \label{tab_YA_X}
    \vskip 0.15in
    \begin{center}
    \begin{small}
    \begin{sc}
    \begin{tabular}{ccc}
        \toprule
        $ \frac{\#(Y,X)}{\#(X)} $    & $Y=hd$ & $Y=tl$ \\
        \midrule
        $X=hd$ & 5/5    & 0   \\
        
        $X=tl$ & 0      & 5/5 \\
        \toprule
        $ \frac{\#(A,X)}{\#(X)} $    & $A=hd$ & $A=tl$\\
        \midrule
        $X=hd$ & 4/5    & 1/5 \\
        
        $X=tl$ & 0      & 5/5 \\
        \bottomrule
    \end{tabular}
    \end{sc}
    \end{small}
    \end{center}
    \vskip -0.1in
\end{table}

Through the adult's record Y and the child's records A, we can calculate the conditional probability of Y given A, as
shown in \cref{tab_Y_A}. We define this process as observation phase.

\begin{table}[htbp]
    \caption{Results of observation phase: $P(Y|A)$}
    \label{tab_Y_A}
    \vskip 0.15in
    \begin{center}
    \begin{small}
    \begin{sc}
    \begin{tabular}{ccc}
        \toprule
        $ \frac{\#(Y,A)}{\#(A)} $    & $Y=hd$ & $Y=tl$\\
        \midrule
        $A=hd$ & 4/4    & 0   \\
        $A=tl$ & 1/6    & 5/6 \\
        \bottomrule
    \end{tabular}
    \end{sc}
    \end{small}
    \end{center}
    \vskip -0.1in
\end{table}

For next coin toss ($X=x_{11}$), the question of this game is formulated as calculation of the probability $P^{A}(Y|X)$, 
superscript A indicates that Y is inferred via record A, not directly observed by the adult. 

For example, given the next coin toss $X = hd=x_{11}$, the child's record has then two situations: 
$P(A=hd|X = hd=x_{11})=4/5$ and $P(A=tl|X = hd=x_{11})=1/5$. With the adult's observation of the child's records, we have
$P(Y = hd|A = hd) = 4/4$ and $P(Y = hd|A = tl) = 1/6$. 
Therefore, given next coin toss $X = hd=x_{11}$, $P^{A}(Y = hd|X = hd=x_{11})$ is the summation of these two situations:
$\frac{4}{5}\cdot\frac{4}{4}+\frac{1}{5}\cdot\frac{1}{6}$.
\cref{tab_Y_X_via_A} answers the above mentioned question.

\begin{table}[ht]
    \caption{Results of inference phase: $P^{A}(Y|X)$}
    \label{tab_Y_X_via_A}
    \renewcommand{\arraystretch}{1.5}
    \vskip 0.15in
    \begin{center}
    \begin{small}
    \begin{sc}
    \begin{tabular}{ccc}
        \toprule
        $\sum_{A}\left ( \frac{\#(A,X)}{\#X} \cdot \frac{\#(Y,A)}{\#A} \right )$  & $Y=hd$ & $Y=tl$\\
        \midrule
        $X=hd=x_{11}$ & $\frac{4}{5}\cdot\frac{4}{4}+\frac{1}{5}\cdot\frac{1}{6}$    & $\frac{4}{5}\cdot 0 +\frac{1}{5}\cdot\frac{5}{6}$    \\

        $X=tl=x_{11}$ & $0\cdot\frac{4}{4}+\frac{5}{5}\cdot\frac{1}{6}$              & $0\cdot 0+\frac{5}{5}\cdot\frac{5}{6}$  \\
        \bottomrule
    \end{tabular}
    \end{sc}
    \end{small}
    \end{center}
    \vskip -0.1in
\end{table}

Let's go one step further, we can find that even the child's record is written in unknown language (\eg\enspace$A \in \{ZHENG, FAN\}$),
\cref{tab_Y_A} and \cref{tab_Y_X_via_A} can still be calculated by the man.
The same is true if the child's record is written from the perspective of attributes, such as color, shape, \etc.

Hence, if we substitute the child with a neural network and regard the adult's record as the sample labels, 
although the representation of the model outputs is unknown, the labels of input samples can still be inferred from these outputs. 
This is the core idea of IPNN\@.


\section{IPNN}\label{sec_ipnn}

\subsection{Model Architecture}\label{AA}

Let $X \in \{x_{1},x_{2},\dots,x_{n} \}$ be training samples  ($X=x_{k}$  is
understood as $k^{th}$ random experiment \textendash\enspace  select one train sample.) 
and $Y \in \{y_{1},y_{2},\dots,y_{m} \}$ consists of $m$ discrete labels (or classes),
$P(y_{l}|x_{k})=y_{l}(k) \in \{0,1\}$ describes the label of sample $x_{k}$.
For prediction, we calculate the posterior of the label for a given new input sample $x_{n+1}$, 
it is formulated as $P^{\mathbb{A} } \left ( y_{l} \mid x_{n+1} \right ) $, 
superscript $\mathbb{A}$ stands for the medium \textendash\enspace model outputs, 
via which we can infer label $y_{l},\enspace l=1,2,\dots,m$. After $P^{\mathbb{A} } \left ( y_{l} \mid x_{n+1} \right ) $ is calculated, 
the $y_{l}$ with maximum posterior is the predicted label.


\cref{fig_ModelArchitecture} shows IPNN model architecture, the output neurons of a general neural network 
(FFN, CNN, Resnet~\cite{ipnn:resnet}, Transformer~\cite{ipnn:Transformer}, Pretrained-Models~\cite{ipnn:bert}, \etc.) 
is split into N unequal/equal parts, the split shape is marked as \cref{eq_split_shape}, 
hence, the number of output neurons is the summation of the split shape, see \cref{eq_number_neurons}.
Next, each split part is passed to `softmax', so the output neurons can be defined as discrete random variable 
$A^{j} \in \left \{ a_{1}^{j} , a_{2}^{j} , \dots, a_{M_{j}}^{j} \right \},j=1,2,\dots,N$, and each neuron in $A^{j}$ is regarded as an event. 
After that, all the random variables together forms the N-dimensional joint sample space, marked as $\mathbb{A} = (A^{1},A^{2},\dots,A^{N})$, and all the joint sample points are fully connected 
with all labels $Y \in \{y_{1},y_{2},\dots,y_{m} \}$ via conditional probability $P\left (Y=y_{l} |A^{1}=a_{i_{1}}^1,A^{2}=a_{i_{2}}^2,\dots,A^{N}=a_{i_{N}}^N \right )$, 
or more compactly written as  $P \left (y_{l} |a_{i_{1}}^1,a_{i_{2}}^2,\dots,a_{i_{N}}^N \right )$\footnote{All the probability is formulated compactly in this paper.}.\footnote{Reading symbols see \cref{app_symbols}.}



\begin{equation}
    \label{eq_split_shape}    
    \text{Split shape} := \{ M_{1},M_{2},\dots,M_{N} \} 
    \end{equation}

\begin{equation}
    \label{eq_number_neurons}    
    \text{Number of model output neurons} := {\textstyle \sum_{j=1}^{N}M_{j}} 
    \end{equation}

\begin{equation}
    \label{eq_number_joint_points}    
    \text{Number of joint sample points} := {\textstyle \prod_{j=1}^{N}}M_{j}
    \end{equation}



\begin{figure}[ht]
    \vskip 0.2in
    \begin{center}
        \centerline{\includegraphics[width=1\columnwidth]{ModelArchitecture.pdf}}
        \caption{IPNN \textendash\enspace model architecture.
        With the increase of number of random variables, the joint sample points increases exponentially, see \cref{eq_number_joint_points}, but
        $P \left (y_{l} |a_{i_{1}}^1,a_{i_{2}}^2,\dots,a_{i_{N}}^N \right )$ is statistically calculated, not model weights.}
        \label{fig_ModelArchitecture}
    \end{center}
    \vskip -0.2in
\end{figure}


\subsection{Indeterminate Probability Theory}


In classical probability theory, given a sample $x_{k}$ (perform an experiment), its event or joint event has only two states: happened or not happened. 
However, for IPNN, the model only outputs the probability of an event and its state is indeterminate, that's why this paper is called IPNN\@. 
This difference makes the calculation of probability (especially joint probability) also different. 
\cref{eq_P_a_X} and \cref{eq_P_A_X} will later formulate this difference.

Given an input sample $x_{k}$, using \cref{asm_random_variable} the model outputs can be formulated as:

\begin{equation}
    \label{eq_P_a_X}    
    P\left ( a_{i_{j} }^{j}\mid x_{k}   \right ) = \alpha _{i_{j} }^{j}(k) 
    \end{equation}


\begin{assumption}
    \label{asm_random_variable}    
    Given an input sample $X=x_{k}$, 
    \textbf{IF} ${\textstyle \sum_{i_{j}=1}^{M_{j}}} \alpha _{i_{j}}^{j}(k) = 1$ and $\alpha _{i_{j}}^{j}(k)\in [0,1], k=1,2,\dots ,n$.
    \textbf{THEN},  
    $\left \{ a_{1}^{j} , a_{2}^{j} , \dots, a_{M_{j}}^{j} \right \}$ can be regarded as collectively exhaustive and exclusive events set, 
    they are partitions of the sample space of random variable $A^{j}, j=1,2,\dots,N$.
    \end{assumption}

    
In classical probability situation,  $\alpha _{i_{j}}^{j}(k)\in \{0,1\}$, which indicates the state of event is 0 or 1.

For joint event, given $x_{k}$, using \cref{asm_A_X_independence}
and \cref{eq_P_a_X}, the joint probability is formulated as:

\begin{equation}
    \label{eq_P_A_X}    
    P\left ( a_{i_{1}}^{1},a_{i_{2}}^{2},\dots,a_{i_{N}}^{N}\mid x_{k}   \right ) 
    =  {\textstyle \prod_{j=1}^{N}} \alpha _{i_{j} }^{j}(k) 
    \end{equation}

\begin{assumption}
   \label{asm_A_X_independence}
   Given an input sample $X=x_{k}$, $A^{1},A^{2},\dots,A^{N}$ is mutually independent.
   \end{assumption}

Where it can be easily proved,
\begin{equation}
    \label{eq_Sum_P_A_X}    
    {\textstyle \sum_{\mathbb{A}} \left ( {\textstyle \prod_{j=1}^{N}}\alpha _{i_{j} }^{j}(k)  \right )} = 1, k=1,2,\dots ,n.
    \end{equation}

In classical probability situation, ${\textstyle \prod_{j=1}^{N}}\alpha _{i_{j} }^{j}(k) \in \{0,1\}$, which indicates the state of joint event is 0 or 1.

\cref{eq_P_a_X} and \cref{eq_P_A_X}  describes the uncertainty of the state of event $ \left ( A^{j} = a_{i_{j}}^{j} \right )$
and joint event $ \left ( A^{1} = a_{i_{1}}^{1},A^{2} = a_{i_{2}}^{2},\dots,A^{N} = a_{i_{N}}^{N} \right )$.

\subsection{Observation Phase}

In observation phase, the relationship between all random variables $A^{1},A^{2},\dots,A^{N}$ 
and $Y$ is established after the whole observations, it is formulated as:

\begin{equation}
   \label{eq_P_Y_A_1}
   P\left (y_{l} \mid a_{i_{1}}^{1},a_{i_{2}}^{2},\dots,a_{i_{N}}^{N} \right ) 
   =  \frac{P\left (y_{l},  a_{i_{1}}^{1},a_{i_{2}}^{2},\dots,a_{i_{N}}^{N} \right )}
   {P\left ( a_{i_{1}}^{1},a_{i_{2}}^{2},\dots,a_{i_{N}}^{N} \right )} 
   \end{equation}

Because the state of joint event is not determinate in IPNN, 
we cannot count its occurrence like classical probability. 
Hence, the joint probability is calculated according to total probability theorem 
over all samples $X=(x_{1},x_{2},\dots,x_{n} )$, and with \cref{eq_P_A_X} we have:

\begin{multline}
   \label{eq_P_A}
   P\left (a_{i_{1}}^{1},a_{i_{2}}^{2},\dots,a_{i_{N}}^{N} \right ) \\
   \begin{aligned}
   &=   {\textstyle \sum_{k=1}^{n}}
   \left ( P\left (a_{i_{1}}^{1},a_{i_{2}}^{2},\dots,a_{i_{N}}^{N} \mid x_{k}\right )\cdot P(x_{k})  \right ) \\
   &=  {\textstyle \sum_{k=1}^{n}}
   \left ( {\textstyle \prod_{j=1}^{N}}P\left ( a_{i_{j} }^{j}\mid x_{k}   \right )  \cdot P(x_{k})  \right ) \\
    &=\frac{ {\textstyle \sum_{k=1}^{n}\left ({\textstyle \prod_{j=1}^{N}}\alpha _{i_{j} }^{j}(k)  \right ) } }{n} 
   \end{aligned}
   \end{multline}

Because $Y=y_{l}$ is sample label and $A^{j}=a_{i_{j}}^{j} $ comes from model, 
it means $A^{j}$ and Y come from different observer, so we can have \cref{asm_Y_A_independence} (see \cref{fig_observation}).

\begin{assumption}
    \label{asm_Y_A_independence}
    Given an input sample $X=x_{k}$, $A^{j}$ and Y is mutually independent in observation phase, $j=1,2,\dots,N$.
    \end{assumption}

\begin{figure}[htbp]
    \vskip 0.2in
    \begin{center}
        \centerline{\includegraphics[width=0.5\columnwidth]{Observation.pdf}}
        \caption{Independence illustration of observation phase with Bayesian network}
        \label{fig_observation}
    \end{center}
    \vskip -0.2in
\end{figure}


Therefore, according to  total probability theorem, \cref{eq_P_A_X} and the above assumption, we derive:

\begin{multline}
    \label{eq_P_YA}
    P\left (y_{l}, a_{i_{1}}^{1},a_{i_{2}}^{2},\dots,a_{i_{N}}^{N} \right ) \\
    \begin{aligned}
    &= {\textstyle \sum_{k=1}^{n}}
    \left ( P\left (y_{l}, a_{i_{1}}^{1},a_{i_{2}}^{2},\dots,a_{i_{N}}^{N} \mid x_{k}\right )\cdot P(x_{k})  \right ) \\
    &=  {\textstyle \sum_{k=1}^{n}}
    \left ( P\left (y_{l}\mid x_{k}\right )\cdot {\textstyle \prod_{j=1}^{N}}P\left ( a_{i_{j} }^{j}\mid x_{k}   \right )  \cdot P(x_{k})  \right ) \\
    &=\frac{ {\textstyle \sum_{k=1}^{n}\left ( y_{l}(k)\cdot  {\textstyle \prod_{j=1}^{N}}\alpha _{i_{j} }^{j}(k)  \right ) } }{n} 
    \end{aligned} 
\end{multline}


Substitute \cref{eq_P_A} and \cref{eq_P_YA} into \cref{eq_P_Y_A_1}, we have:  


\begin{equation}
    \label{eq_P_Y_A_2}
    P\left (y_{l}| a_{i_{1}}^{1},a_{i_{2}}^{2},\dots,a_{i_{N}}^{N} \right )
    = \frac{ {\textstyle \sum_{k=1}^{n}\left ( y_{l}(k)\cdot  {\textstyle \prod_{j=1}^{N}}\alpha _{i_{j} }^{j}(k)  \right ) } } 
    {{\textstyle \sum_{k=1}^{n}\left ( {\textstyle \prod_{j=1}^{N}}\alpha _{i_{j} }^{j}(k) \right ) } }
    \end{equation}

Where it can be proved, 

\begin{equation}
    \label{eq_sum_P_A}
    {\textstyle \sum_{l=1}^{m}}P\left (y_{l} \mid a_{i_{1}}^{1},a_{i_{2}}^{2},\dots,a_{i_{N}}^{N} \right ) = 1  
    \end{equation}



\subsection{Inference Phase}

Given $A^{j}$, with \cref{eq_P_Y_A_2} (passed experience) label $y_{l}$ can be inferred, 
this inferred $y_{l}$ has no pointing to any specific sample $x_{k}$, 
incl\@. also new input sample $x_{n+1}$, see \cref{fig_inference}. 
So we can have following assumption:

\begin{assumption}
    \label{asm_Y_X_independence}
    Given $A^{j}$, $X$ and $Y$ is mutually independent in inference phase, $j=1,2,\dots,N$.
    \end{assumption}    

\begin{figure}[htbp]
    \vskip 0.2in
    \begin{center}
        \centerline{\includegraphics[width=0.5\columnwidth]{Inference.pdf}}
        \caption{Independence illustration of inference phase with Bayesian network}
        \label{fig_inference}
    \end{center}
    \vskip -0.2in
\end{figure}


Therefore, given a new input sample $X=x_{n+1}$, according to total probability theorem 
over joint sample space $\left (a_{i_{1}}^{1},a_{i_{2}}^{2},\dots,a_{i_{N}}^{N} \right ) \in \mathbb{A}$, 
with \cref{asm_Y_X_independence}, \cref{eq_P_A_X} and \cref{eq_P_Y_A_2}, we have:

\begin{multline}
    \label{eq_P_Y_X_via_A}
    P^{\mathbb{A} } \left ( y_{l} \mid x_{n+1} \right ) \\
    \begin{aligned}
    &=\sum_{\mathbb{A}} 
    \left ( P\left ( y_{l},a_{i_{1}}^{1} ,  \dots, a_{i_{N}}^{N} \mid x_{n+1} \right )  \right ) \\
    &=\sum_{\mathbb{A}} 
    \left ( P\left ( y_{l}\mid a_{i_{1}}^{1},  \dots, a_{i_{N}}^{N}\right )  P\left (a_{i_{1}}^{1}, \dots, a_{i_{N}}^{N} \mid x_{n+1} \right )  \right ) \\
    &=\sum_{\mathbb{A}} 
    \left ( \frac{ \sum_{k=1}^{n}\left ( y_{l}(k)  { \prod_{j=1}^{N}}\alpha _{i_{j} }^{j}(k)  \right ) }
    {\sum_{k=1}^{n}\left ( { \prod_{j=1}^{N}}\alpha _{i_{j} }^{j}(k) \right ) } 
    \prod_{j=1}^{N}\alpha_{i_{j} }^{j}(n+1)  \right )
    \end{aligned}
\end{multline}

And the maximum posterior is the predicted label of an input sample:

\begin{equation}
    \label{eq_argmax}
    \hat{y} := { \underset{l\in \left \{ 1,2,\dots,m \right \}} {\arg\max} \,  P^{\mathbb{A} } \left ( y_{l} \mid x_{n+1} \right ) }  
    \end{equation}

\subsection{Discussion}\label{sec_discuss}

Our proposed theory is derived based on three our proposed conditional mutual independency assumptions, see \cref{asm_A_X_independence} \cref{asm_Y_A_independence} and \cref{asm_Y_X_independence}. 
However, in our opinion, these assumptions can neither be proved nor falsified, and we do not find any exceptions until now.
Since this theory can not be mathematically proved, we can only validate it through experiment.

Finally, our proposed indeterminate probability theory is an extension of classical probability theory, and classical probability theory is one special case to our theory.
More details to understand our theory, see \cref{app_intuitive_explain}.

\section{Training}\label{sec_training}

\subsection{Training Strategy}

Given an input sample $x_{t}$ from a mini batch,  with a minor modification of \cref{eq_P_Y_X_via_A}:

\begin{multline}
    \label{eq_P_Y_X_via_A_Train}
    P^{\mathbb{A} } \left ( y_{l} \mid x_{t} \right ) \\
    \begin{aligned}
    &= \sum_{\mathbb{A}} 
    \left ( \dfrac{ \sum_{k=b\cdot t_{0}+1}^{b\cdot t_{1}}\left ( y_{l}(k) { \prod_{j=1}^{N}}\alpha _{i_{j} }^{j}(k)  \right ) }
    {\sum_{k=b\cdot t_{0}+1}^{b\cdot t_{1}}\left ( { \prod_{j=1}^{N}}\alpha _{i_{j} }^{j}(k) \right ) } 
    \prod_{j=1}^{N}\alpha_{i_{j} }^{j}(t)  \right )  \\
    &\approx \sum_{\mathbb{A}}
    \left ( \frac{\max(H+h(t1),\epsilon)}
    {\max(G+g(t1),\epsilon)} \cdot { \prod_{j=1}^{N}}\alpha _{i_{j} }^{j}(t) \right )
    \end{aligned}
    \end{multline}

Where $b$ is for batch size, $t_{0} = \max(0,t_{1}-T)$, $t_{1} = \left \lceil \frac{t}{b}  \right \rceil , t = 1,2,\dots,n$. 
Hyper-parameter T is for forgetting use, i.e., $H$ and $G$ are calculated from the recent T batches. Hyper-parameter T is introduced because at 
beginning of training phase the calculated result with \cref{eq_P_Y_A_2} is not good yet. 
And the $\epsilon$ on the denominator is to avoid dividing zero, 
the $\epsilon$ on the numerator is to have an initial value of 1. Besides,

\begin{align} 
    \label{eq_hh}
    &h(t1)={\textstyle \sum_{k=b\cdot (t_{1}-1)+1}^{b\cdot t_{1}}}\left (  y_{l}(k)\cdot  
    {\textstyle  \prod_{j=1}^{N}}\alpha _{i_{j} }^{j}(k) \right )\\
    \label{eq_gg}
    &g(t1)= {\textstyle \sum_{k=b\cdot (t_{1}-1)+1}^{b\cdot t_{1}}}
    \left (  {\textstyle  \prod_{j=1}^{N}}\alpha _{i_{j} }^{j}(k) \right )\\
    \label{eq_H}
    &H= {\textstyle \sum_{k=\max(1,t_{1}-T)}^{t_{1}-1}} h(k),\text{for } t_{1}=2,3,\dots\\
    \label{eq_G}
    &G= {\textstyle \sum_{k=\max(1,t_{1}-T)}^{t_{1}-1}} g(k),\text{for } t_{1}=2,3,\dots
\end{align}

Where $H$ and $G$ are not needed for gradient updating during back-propagation.  


We use cross entropy as loss function:

\begin{equation}
    \label{eq_loss}
    \mathcal{L} =  -{\textstyle \sum_{l=1}^{m}} \left (  y_{l}(k)\cdot  \log P^{\mathbb{A} } \left ( y_{l} \mid x_{t} \right )\right ) 
    \end{equation}

The detailed algorithm implementation is shown in \cref{alg_train}.

\begin{algorithm}[tb]
    \caption{IPNN training}
    \label{alg_train}
    \textbf{Input}: A sample $x_{t}$ from mini-batch \\
    \textbf{Parameter}: Split shape, forget number $T$, $\epsilon$, learning rate $\eta$.\\
    \textbf{Output}: The posterior $P^{\mathbb{A} } \left ( y_{l} \mid x_{t} \right )$ 
    \begin{algorithmic}[1]
        \STATE Declare default variables: $H, G, hList, gList$
        \FOR{$i=1,2,\dots$ Until Convergence}
        \STATE Compute $h, g$ with \cref{eq_hh} and \cref{eq_gg}
        \STATE Record: $hList.append(h), gList.append(g)$
        \IF{$i>T$}
        \STATE Forget: $H = H - hList[0], G = G - gList[0]$
        \STATE Remove first element from $hList, gList$
        \ENDIF
        \STATE Compute posterior with \cref{eq_P_Y_X_via_A_Train}: $P^{\mathbb{A} } \left ( y_{l} \mid x_{t} \right )$ 
        \STATE Compute loss with \cref{eq_loss}: $\mathcal{L}(\theta )$
        \STATE Update model parameter: $\theta = \theta - \eta\nabla \mathcal{L}(\theta )$
        \STATE Update for next loop: $H=H+h, G=G+g$
        \ENDFOR
        \STATE \textbf{return} model and the posterior
    \end{algorithmic}
\end{algorithm}

With \cref{eq_P_Y_X_via_A_Train} we can get that $P^{\mathbb{A} } \left ( y_{l} \mid x_{1} \right )=1$ 
for the first input sample if $y_{l}$ is the ground truth and batch size is 1. 
Therefore, for IPNN the loss may increase at the beginning and fall back again while training.


\subsection{Multi-degree Classification (Optional)}\label{sec_classification}

In IPNN, the model outputs N different random variables $A^{1},A^{2},\dots,A^{N}$, 
if we use part of them to form sub-joint sample spaces, we are able of doing sub classification task, 
the sub-joint spaces are defined as $\Lambda^{1}\subset \mathbb{A} ,\Lambda^{2}\subset \mathbb{A} ,\dots$ 
The number of sub-joint sample spaces is:

\begin{equation}
    \label{eq_sub_joint_spaces}
    \sum_{j=1}^{N}\binom{N}{j} 
    =\sum_{j=1}^{N}\left ( \frac{N!}{j!(N-j)!}  \right ) 
    \end{equation}

If the input samples are additionally labeled for part of sub-joint sample spaces\footnote{It is labelling of input samples, not sub-joint sample points.},
defined as $Y^{\tau} \in \{y_{1}^{\tau},y_{2}^{\tau},\dots,y_{m^{\tau}}^{\tau} \}$.
The sub classification task can be represented as $\left \langle X,\Lambda^{1},Y^{1} \right \rangle ,\left \langle X,\Lambda^{2},Y^{2} \right \rangle,\dots$
With \cref{eq_loss} we have,

\begin{equation}
    \label{eq_sub_losses}
    \mathcal{L}^{\tau} = -{\textstyle \sum_{l=1}^{m^{\tau}}} \left (    y_{l}^{\tau}(k)\cdot  
    \log P^{\Lambda^{\tau} } \left ( y_{l}^{\tau} \mid x_{t} \right ) \right ), \tau = 1,2,\dots
    \end{equation}

Together with the main loss, the overall loss is $\mathcal{L}+\mathcal{L}^{1}+\mathcal{L}^{2}+\dots$
In this way, we can perform multi-degree classification task. 
The additional labels can guide the convergence of the joint sample spaces and speed up the training process, as discussed later in \cref{sec_avoiding_local_minimum}. 

\subsection{Multi-degree Unsupervised Clustering}\label{sec_cluster}

If there are no additional labels for the sub-joint sample spaces, the model are actually doing
unsupervised clustering while training.
And every sub-joint sample space describes one kind of clustering result, 
we have \cref{eq_sub_joint_spaces} number of clustering situations in total. 


\subsection{Designation of Joint Sample Space}\label{sec_split_shape}

As in \cref{app_glb_convergence} proved, we have following proposition:

\begin{proposition}
    \label{pps_convergence}
    IPNN converges to global minimum only when $P\left (y_{l}| a_{i_{1}}^{1},a_{i_{2}}^{2},\dots,a_{i_{N}}^{N} \right ) = 1,
    \text{ for } \prod_{j=1}^{N}\alpha_{i_{j} }^{j}(t)  > 0, i_{j} = 1,2,\dots,M_{j}$. In other word, each joint sample point corresponds to an unique category.
    However, a category can correspond to one or more joint sample points. 
\end{proposition}

\begin{corollary}
    \label{cor_condition}
    The necessary condition of achieving the global minimum is when the split shape defined in \cref{eq_split_shape} satisfies: 
    ${\textstyle \prod_{j=1}^{N}}M_{j} \ge m$, where $m$ is the number of classes. That is, for a classification task, 
    the number of all joint sample points is greater than the classification classes.
\end{corollary}

Besides, the unsupervised clustering (\cref{sec_cluster}) depends on the input sample distributions, the split shape shall not violate
from multi-degree clustering. For example, if the main attributes of one dataset shows three different colors, and your split shape is $\{M_{1}=2,M_{2}=2,\dots\}$,
this will hinder the unsupervised clustering, in this case, the shape of one random variable is better set to 3. And as in \cref{app_local_convergence} also analyzed, 
there are two local minimum situations, improper split shape will make IPNN go to local minimum.

In addition, the latter part from \cref{pps_convergence} also implies that IPNN may be able of doing further unsupervised classification task, this is beyond the scope of this discussion.


\section{Experiments and Results}\label{sec_experiment}

To evaluate the effectiveness of the proposed approach, we conducted experiments on MNIST~\cite{ipnn:mnist} 
and a self-designed toy dataset.


\subsection{Unsupervised Clustering}

As in \cref{sec_cluster} discussed, IPNN is able of performing unsupervised clustering, we evaluate it on MNIST\@.
The split shape is set to $\{M_{1}=2,M_{2}=10\}$, it means we have two random variables, and the first random variable is used to divide
MNIST labels $0,1,\dots 9$ into two clusters.
The cluster results is shown in \cref{fig_cluster_mnist}.

We find only when $\epsilon$ in \cref{eq_P_Y_X_via_A_Train} is set to a relative high value that IPNN prefers to put number 1,4,7,9 into one cluster and the rest into another cluster, 
otherwise, the clustering results is always different for each round training.
The reason is unknown, our intuition is that high $\epsilon$ makes that each category catch the free joint sample point more harder, categories have similar
attributes together will be more possible to catch the free joint sample point.


\begin{figure}[htbp]
    \vskip 0.2in
    \begin{center}
        \centerline{\includegraphics[width=1\columnwidth]{cluster_mnist.pdf}}
        \caption{Unsupervised clustering results on MNIST\@: $\epsilon = 2$, batch size $b=64$, forget number $T=5$, epoch is 5 per round.
        The test was repeated for 876 rounds with same configuration (different random seeds) in order to check the stability of clustering performance,
        each round clustering result is aligned using Jaccard similarity~\cite{ipnn:jaccard}, the percentage is calculated with \cref{eq_cluster_percent}.}
        \label{fig_cluster_mnist}
    \end{center}
    \vskip -0.2in
\end{figure}


\begin{equation}
    \label{eq_cluster_percent}
    \frac{1}{round}  \cdot \sum_{i=1}^{round} \frac{
    \begin{matrix}
    \text{ number of samples with label } l \\
    \text{ in one cluster at }  i^{th} \text{ round}
    \end{matrix}}
    {\text{number of samples with label }l}
    \end{equation}


\subsection{Avoiding Local Minimum with Multi-degree Classification} \label{sec_avoiding_local_minimum}
Another experiment is designed by us to check the performance of multi-degree classification (see \cref{sec_classification}): classification of binary vector into decimal value.
The binary vector is the model inputs from `000000000000' to `111111111111', which are labeled from 0 to 4095.
The split shape is set to $\{M_{1}=2,M_{2}=2,\dots, M_{12}=2\}$, which is exactly able of making a full classification.  
Besides, model weights are initialized as uniform distribution of $[-0.3,0.3]$, as discussed in \cref{app_local_convergence}.  

\begin{figure}[htb]
    \vskip 0.2in
    \begin{center}
        \centerline{\includegraphics[width=1\columnwidth]{multi_degree_classfication.pdf}}
        \caption{Loss of multi-degree classification of `binary to decimal' on train dataset. 
            Input samples are additionally labeled with $Y^{i} \in \{0,1\}$ for $i^{th}$ bit is 0 or 1, respectively. 
            $Y^{i}$ corresponds to sub-joint sample space $\Lambda^{i}$ with split shape $\{M_{i}=2\}, i = 1,2,\dots12$.  
            Batch size is 4096, forget number $T=5,\enspace \epsilon=10^{-6}$.}
        \label{fig_multi_classification}
    \end{center}
    \vskip -0.2in
\end{figure}

The result is shown in \cref{fig_multi_classification}, IPNN without multi degree
classification goes to local minimum with only $69.5\%$ train accuracy.
We have only additionally labeled for 12 sub-joint spaces, and IPNN goes to global minimum with $100\%$ train accuracy.

Therefore, with only ${\textstyle \sum_{1}^{12}} 2=24$ output nodes, IPNN can classify 4096 categories.
Theoretically, if model with 100 output nodes are split into 10 equal parts, it can classify 10 billion categories.
Hence, compared with the classification model with only one `softmax' function, IPNN has no computationally expensive problems (see \cref{sec_introduction}).



\subsection{Hyper-parameter Analysis}

IPNN has two import hyper-parameters: split shape and forget number T. In this section, we have analyzed it with test on MNIST, batch size is set to 64, $\epsilon = 10^{-6}$.
As shown in \cref{fig_split_shape}, if the number of joint sample points (see \cref{eq_number_joint_points}) is smaller than 10, IPNN is not able of making
a full classification and its test accuracy is proportional to number of joint sample points, as number of joint sample points increases over 10,
IPNN goes to global minimum for both 3 cases, this result is consistent with our analysis. However, we have exceptions, the accuracy of split shape with $\{M_{1}=2, M_{2}=5\}$ and $\{M_{1}=2, M_{2}=6\}$ is not high. From \cref{fig_cluster_mnist}
we know that for the first random variable, IPNN sometimes tends to put number 1,4,7,9 into one cluster and the rest into another cluster, 
so this cluster result request that the split shape need to be set minimums to $\{M_{1}=2, M_{2}\ge 6\}$ in order to have enough free joint sample points.
That's why the accuracy of split shape with $\{M_{1}=2, M_{2}=5\}$ is not high. (For $\{M_{1}=2, M_{2}=6\}$ case, only three numbers are in one cluster.)

Another test in \cref{fig_T} shows that IPNN will go to local minimum as forget number T increases and cannot go to global minimum without further actions,
hence, a relative small forget number T shall be found with try and error.

\begin{figure}[htbp]
    \vskip 0.2in
    \begin{center}
        \centerline{\includegraphics[width=1\columnwidth]{split_shape_analysis.pdf}}
        \caption{Impact Analysis of split shape with MNIST\@: accuracy on test dataset. 
                1D split shape is for $\{M_{1}=\tau\}, \tau = 2,3,\dots, 24$.
                2D split shape is for $\{M_{1}=2,M_{2}=\tau\}, \tau = 2,3,\dots, 12$.
                3D split shape is for $\{M_{1}=2,M_{2}=2,M_{3}=\tau\}, \tau = 2,3,\dots, 6$.
                The x-axis is the number of joint sample points calculated with \cref{eq_number_joint_points}.}
        \label{fig_split_shape}
    \end{center}
    \vskip -0.2in
\end{figure}

\begin{figure}[htbp]
    \vskip 0.2in
    \begin{center}
        \centerline{\includegraphics[width=1\columnwidth]{T_analysis.pdf}}
        \caption{Impact Analysis of forget number T with MNIST\@: accuracy on test dataset. 
                Split shape is  $\{M_{1}=10\}$.}
        \label{fig_T}
    \end{center}
    \vskip -0.2in
\end{figure}


\section{Conclusion}\label{sec_conclusion}

For a classification task, we proposed an approach to extract the attributes of input samples as random variables,
and these variables are used to form a large joint sample space. After IPNN converges to global minimum, each joint sample point will correspond
to an unique category, as discussed in \cref{pps_convergence}. As the joint sample space increases exponentially, the classification capability
of IPNN will increase accordingly.

We can then use the advantages of classical probability theory, for example,
for very large joint sample space, we can use the Bayesian network approach or mutual independence among variables
(see \cref{app_independent}) to simplify the model 
and improve the inference efficiency, in this way,
a more complex Bayesian network could be built for more complex reasoning task.


\section*{Acknowledgment}

Thanks to Mr\@. Su Jianlin for his good introduction of VAE model\footnote{Website: https://kexue.fm/archives/5253}, 
which motivates the implementation of this idea.


% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
% \nocite{langley00}

\bibliography{ipnn}
\bibliographystyle{icml2023}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn

\section{An Intuitive Explanation}\label{app_intuitive_explain}

Our most important contribution is that we propose a new general  \textbf{tractable} probability \cref{eq_P_Y_X_via_A}, rewritten here again:

\begin{multline}
\label{eq_main_equation}
P^{\mathbb{A}}\left ( Y=y_{l}\mid X=x_{n+1}\right ) = \\
\underset{\text{Inference phase}}{\underbrace{\sum_{\mathbb{A}}\left (  
\underset{\text{Observation phase}}{\underbrace{\frac{{\textstyle \sum_{k=1}^{n}}
   \left ( {\textstyle P\left ( Y=y_{l}\mid X=x_{k}   \right )\cdot
\prod_{j=1}^{N}}P\left ( A^{j}=a_{i_{j} }^{j}\mid X=x_{k}   \right )   \right )}
{{\textstyle \sum_{k=1}^{n}}
   \left ( {\textstyle \prod_{j=1}^{N}}P\left ( A^{j}=a_{i_{j} }^{j}\mid X=x_{k}   \right )   \right )} }}
\cdot  \prod_{j=1}^{N}P\left ( A^{j}=a_{i_{j} }^{j}\mid X=x_{n+1}   \right ) \right )}} 
\end{multline}

Where X is random variable and $X=x_{k}$ denote the $k^{th}$ random experiment (or model input sample $x_{k} $), $Y$ and $A^{j}$ are different random variables, for more reading symbols, see \cref{app_symbols}.

Since our proposed indeterminate probability theory is quite new, we will explain this idea by comparing it with classical probability theory, see below table:

\begin{table}[htbp]
    \caption{An intuitive comparison between classical probability theory and our proposed theory.}
    \label{tab_theory_comparison}
    \vskip 0.15in
    \begin{center}
    \begin{small}
    % \begin{sc}
    \begin{tabular}{ccc}
        \toprule
        Classical & Observation & $P\left ( Y=y_{l} \mid A^{j}=a_{i_{j}}^{j} \right ) = \frac{\text{number of event }(Y=y_{l}, A^{j}=a_{i_{j}}^{j})\text{ occurs}} {\text{number of event }(A^{j}=a_{i_{j}}^{j})\text{ occurs}}$    \\
        \midrule
        & Inference & $X=x_{n+1}\xrightarrow[\textbf{Determinate}]{P\left ( A^{j}=a_{i_{j}}^{j} \mid X=x_{n+1}\right )=1}A^{j}=a_{i_{j}}^{j}\xrightarrow[\text{infer}]{P\left ( Y=y_{l} \mid A^{j}=a_{i_{j}}^{j} \right )} Y=y_{l}$   \\
        \toprule
        Ours & Observation  & $P\left ( Y=y_{l} \mid A^{j}=a_{i_{j}}^{j} \right ) = \frac{\text{sum of event }(Y=y_{l}, A^{j}=a_{i_{j}}^{j})\text{ occurs, in decimal}} {\text{sum of event }(A^{j}=a_{i_{j}}^{j})\text{ occurs, in decimal}}$      \\
        \midrule
        & Inference & $X=x_{n+1}\to\left \{   \begin{matrix}    \xrightarrow[]{P\left ( A^{j}=a_{1}^{j} \mid X=x_{n+1}\right )\in[0,1]} & A^{j}=a_{1}^{j} &\xrightarrow[]{P\left ( Y=y_{l} \mid A^{j}=a_{1}^{j} \right )} \\ \xrightarrow[]{P\left ( A^{j}=a_{2}^{j} \mid X=x_{n+1}\right )\in[0,1]} & A^{j}=a_{2}^{j} &\xrightarrow[]{P\left ( Y=y_{l} \mid A^{j}=a_{2}^{j} \right )}\\ \xrightarrow[]{\dots}          & A^{j}=\dots     &\xrightarrow[]{\dots}\\ \xrightarrow[\textbf{Indeterminate}]{P\left ( A^{j}=a_{M_{j}}^{j} \mid X=x_{n+1}\right )\in[0,1]} & A^{j}=a_{M_{j}}^{j} &\xrightarrow[\text{infer}]{P\left ( Y=y_{l} \mid A^{j}=a_{M_{j}}^{j} \right )}\end{matrix}\right \}\to Y=y_{l} $ \\
        \bottomrule
        \multicolumn{3}{l}{Note: Replacing $A^{j}$ with joint random variable $(A^{1},A^{2},\dots,A^{N})$ is also valid for above explanation.}
    \end{tabular}
    % \end{sc}
    \end{small}
    \end{center}
    \vskip -0.1in
\end{table}

In other word, for classical probability theory, perform a random experiment $X=x_{k}$, 
the event state is Determinate (happened or not happened), 
the probability is calculated by counting the number of occurrences, 
we define this process here as observation phase. For inference, 
perform a new random experiment $X=x_{n+1}$, the state of $A^{j}=a_{i_{j}}^{j}$ is Determinate again, 
so condition on $X=x_{n+1}$ is equivalent to condition on $A^{j}=a_{i_{j}}^{j}$, 
that may be the reason why condition on $X=x_{n+1}$ is not discussed explicitly in the past.

However, for our proposed indeterminate probability theory, 
perform a random experiment $X=x_{k}$, the event state is Indeterminate (understood as partly occurs), the probability is calculated by summing the decimal value of occurrences in observation phase. For inference, perform a new random experiment $X=x_{n+1}$, the state of $A^{j}=a_{i_{j}}^{j}$ is Indeterminate again, each case contributes the inference of $Y=y_{l}$, so the inference shall be the summation of all cases. Therefore, condition on $X=x_{n+1}$ is now different with condition on $A^{j}=a_{i_{j}}^{j}$, we need to explicitly formulate it, see \cref{eq_main_equation}.

Once again, our proposed indeterminate probability theory does not have any conflict with classical probability theory, the observation and inference phase of classical probability theory is one special case to our theory.


\section{Global Minimum Analysis}\label{app_glb_convergence}

\begin{proof}[Proof of \cref{pps_convergence}]

    \cref{eq_P_Y_X_via_A} can be rewritten as:


\begin{equation}
    \label{eq_convergence_p}
    P^{\mathbb{A} } \left ( y_{l} \mid x_{t} \right )
    =\sum_{\mathbb{A}} 
    \left (p_{\mathbb{A}}\cdot   {\textstyle \prod_{j=1}^{N}\alpha_{i_{j} }^{j}(t) }  \right ) 
    \end{equation}


Where,

\begin{equation}
    \label{eq_p_Y_A_shorted}
    p_{\mathbb{A}} = P\left ( y_{l} \mid a_{i_{1}}^{1} , a_{i_{2}}^{2} , \dots, a_{i_{N}}^{N} \right ) 
    \end{equation}

Theoretically, model converges to global minimum when the train and test loss is zero~\cite{ipnn:convergence_paper}, 
and for the ground truth $y_{l}(t)=1$, with \cref{eq_loss} we have:

\begin{equation}
    \label{eq_p_equal_one}
    \sum_{\mathbb{A}} 
    \left (p_{\mathbb{A}}\cdot   {\textstyle \prod_{j=1}^{N}\alpha_{i_{j} }^{j}(t) }  \right )  = 1
    \end{equation}

Subtract the above equation from \cref{eq_Sum_P_A_X} gives:

\begin{equation}
    \label{eq_conv_eq_zero}
    \sum_{\mathbb{A}} 
    \left ( (1-p_{\mathbb{A}}) \cdot \prod_{j=1}^{N}\alpha_{i_{j} }^{j}(t) \right )  = 0
    \end{equation}

Because $\prod_{j=1}^{N}\alpha_{i_{j} }^{j}(t) \in [0,1]$ and $(1-p_{\mathbb{A}}) \in [0,1]$, 
The above equation is then equivalent to:

\begin{equation}
\label{eq_convergence_condition}
    p_{\mathbb{A}}  = 1, 
    \text{ for } \prod_{j=1}^{N}\alpha_{i_{j} }^{j}(t)  > 0, i_{j} = 1,2,\dots,M_{j}.
    \end{equation}

    
\end{proof}

\section{Local Minimum Analysis}\label{app_local_convergence}

\cref{eq_convergence_p} can be further rewritten as:

\begin{equation}
    \label{eq_local_p}
    P^{\mathbb{A} } \left ( y_{l} \mid x_{t} \right ) 
    % \begin{aligned}
    = \sum_{i_{\tau}=1}^{M_{\tau}}
    \left ( \alpha_{i_{\tau} }^{\tau}(t) \cdot \sum_{\Lambda} 
    \left ( p_{\mathbb{A}}\cdot   {\textstyle \prod_{j=1,j \ne \tau}^{N}\alpha_{i_{j} }^{j}(t)}   \right ) \right )  \\
    = {\textstyle \sum_{i_{\tau}=1}^{M_{\tau}}
    \left ( \alpha_{i_{\tau} }^{\tau}(t) \cdot p_{i_{\tau}} \right )}
    % \end{aligned}
\end{equation}


Where $\Lambda =(A^{1},\dots,A^{j},\dots,A^{N}) \subset \mathbb{A}, j \ne \tau$ and,

\begin{equation}
    p_{i_{\tau}} = {\sum_{\Lambda} \left (p_{\mathbb{A}}\cdot  {\textstyle \prod_{j=1,j \ne \tau}^{N}
    \alpha_{i_{j} }^{j}(t)  } \right ) }
    \end{equation}

Substitute \cref{eq_local_p} into \cref{eq_loss}, and for the ground truth
$y_{l}(t)=1$ the loss function can be written as:
    
\begin{equation}
    \label{eq_loss_for_analysis}
    \mathcal{L} = - \log({\textstyle \sum_{i_{\tau}=1}^{M_\tau}
        \left ( \alpha_{i_{\tau} }^{\tau}(t) \cdot p_{i_{\tau}} \right ) } )
    \end{equation}

Let the model output before softmax function be $z_{i_{j}}$, we have:

\begin{equation}
    \alpha_{i_{\tau}}^{\tau}(t) = 
    \frac{e^{z_{i_{\tau}}}}{ {\textstyle \sum_{i_{j}=1}^{M_{j}}e^{z_{i_{j}}}} } 
    \end{equation}

In order to simplify the calculation, we assume $p_{\mathbb{A}}$ defined in \cref{eq_p_Y_A_shorted} is constant during back-propagation.
so the gradient is:

\begin{equation}
    \label{eq_convergence_grad}
    \frac{\partial \mathcal{L}}{\partial z_{i_{\tau}}} 
    = - \frac{\alpha_{i_{\tau}}^{\tau}(t) \cdot {\textstyle \sum_{i_{j}=1,i_{j} \ne i_{\tau}}^{M_{j}}} \left ( e^{z_{i_{j}}}\cdot(p_{i_{\tau}}-p_{i_{j}}) \right )  }
    {\sum_{i_{j}=1}^{M_j} \left ( e^{z_{i_{j}}}\cdot p_{i_{j}} \right )  } 
    \end{equation}

Therefore, we have two kind of situations
that the algorithm will go to local minimum:

\begin{equation}
    \setlength{\nulldelimiterspace}{0pt}
    \frac{\partial \mathcal{L}}{\partial z_{i_{\tau}}} 
    =\begin{cases}
    \to 0,&\text{if } \left |  z_{i_{\tau}}-z_{i_{j}} \right | \to \infty \\
    0,&\text{if } p_{i_{\tau}}=p_{i_{j}}\\
    Nonezero, &o.w.%.
    \end{cases}
    \end{equation}

Where $i_{\tau} = 1,2,\dots,M_{\tau}$.

The first local minimum usually happens when \cref{cor_condition} is not satisfied,
that is, the number of joint sample points is smaller than the classification classes, the results are shown in \cref{fig_split_shape}.

If the model weights are initialized to a very small value, the second local minimum may happen at the beginning of training.
In such case, all the model output values are also small which will result in $\alpha_{1}^{j}(t) \approx \alpha_{2}^{j}(t) \approx  \dots \approx \alpha_{M_{j}}^{j}(t)$,
and it will further lead to all the $p_{i_{\tau}}$ be similar among each other.
Therefore, if the model loss reduces slowly at the beginning of training, the model weights is suggested to be initialized to an relative high value.
But the model weights shall not be set to too high values, otherwise it will lead to first local minimum. 

As shown in \cref{fig_weights_init}, if model weights are initialized to uniform distribution of $\left [ -10^{-6},10^{-6} \right ] $,
its convergence speed is slower than the model weights initialized to uniform distribution of $\left [ -0.3,0.3\right ]$. 
Besides, model weights initialized to uniform distribution of $\left [ -3,3\right ] $ get almost stuck at local minimum and cannot go to global minimum.
This result is consistent with our analysis.

\begin{figure}[htbp]
    \vskip 0.2in
    \begin{center}
        \centerline{\includegraphics[width=1\columnwidth]{weights_init.pdf}}
        \caption{Model weights initialization impact analysis on MNIST\@. 
        Split shape is $\{M_{1}=2,M_{2}=10\}$, batch size is 64, forget number $T=5,\enspace \epsilon=10^{-6}$.}
        \label{fig_weights_init}
    \end{center}
    \vskip -0.2in
\end{figure}


\section{Mutual Independency}\label{app_independent}

If we want the random variables $A^{1},A^{2},\dots,A^{N}$ partly or fully mutually independent, 
we can use their mutual information as loss function:

\begin{gather}
   \label{eq_loss_independent}
   \mathcal{L}^{*} = KL\left ( P(A^{1},A^{2},\dots,A^{N}), \prod_{j=1}^{N}P(A^{j})  \right ) 
   =\sum_{\mathbb{A}}\left (  P\left (a_{i_{1}}^{1} , \dots, a_{i_{N}}^{N} \right ) \cdot
   \log \frac{P\left (a_{i_{1}}^{1} , \dots, a_{i_{N}}^{N} \right )}{\prod_{j=1}^{N}P(a_{i_{j}}^{j})}  \right ) \\ \nonumber
   = \sum_{\mathbb{A}}
   \left (\frac{{\textstyle \sum_{k=1}^{n}}\left (  {\textstyle \prod_{j=1}^{N}} \alpha_{i_{j}}^{j}(k)  \right ) }{n}   \cdot
   \log\left ( \frac{\frac{{\textstyle \sum_{k=1}^{n}}\left (  {\textstyle \prod_{j=1}^{N}} \alpha_{i_{j}}^{j}(k)  \right ) }{n} }
   { \textstyle \prod_{j=1}^{N} \frac{ {\textstyle \sum_{k=1}^{n} \alpha_{i_{j}}^{j}(k)} }{n}}    \right )    \right ) 
\end{gather}

\section{Symbols}\label{app_symbols}

\begin{table}[htbp]
    \caption{Reading Symbols}
    \label{tab_reading_symbols}
    \vskip 0.15in
    \begin{center}
    \begin{small}
    % \begin{sc}
    \begin{tabular}{ccc}
        \toprule
        Symbol & Meaning\\
        \midrule
        $x_{k}$        &    input sample, $k = 1,2,\dots,n$ \\
        $y_{l}$        &    output label, $l = 1,2,\dots,m$ \\
        $A^{j}$        &    random variable, $j = 1,2,\dots,N$ \\
        $a_{i_{j}}^j$  &    event of $A^{j},i_{j} = 1,2,\dots,M_{j}$ \\
        $\mathbb{A}$   &    joint sample space \\
        $\Lambda$      &    sub-joint sample space \\
        \bottomrule
    \end{tabular}
    % \end{sc}
    \end{small}
    \end{center}
    \vskip -0.1in
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
