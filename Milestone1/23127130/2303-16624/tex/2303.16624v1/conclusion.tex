In this paper, we propose a novel Adaptive Spot-guided Transformer (ASTR) for consistent local feature matching.
To model local matching consistency, we design a spot-guided aggregation module to make most pixels avoid the impact of irrelevant areas, such as noisy and repetitive regions.
To better handle large scale variation, we use the calculated depth information to adaptively adjust the size of grids at the fine stage.
Extensive experimental results on five benchmarks demonstrate the effectiveness of the proposed method.

\noindent\textbf{Limitation.}
Although our adaptive scaling module is lightweight and pluggable, it demands camera pose estimation in the coarse stage, which requires the camera intrinsic parameters.
While camera intrinsic parameters are obtainable in standard datasets and most real-world scenarios, there are still some images from wild that lack them, rendering the adaptive scaling module disabled in such cases.

    % \noindent\textbf{Acknowledgement.} This work was partially supported by the National Nature Science Foundation of China (No. 62022078 and No. 62021001).
% , and Laboratory of Future Network of University of Science and Technology of China.