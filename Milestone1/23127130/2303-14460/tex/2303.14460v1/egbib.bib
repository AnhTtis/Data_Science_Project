@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}

@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@article{madry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={arXiv preprint arXiv:1706.06083},
  year={2017}
}

@inproceedings{xu2021robust,
  title={To be robust or to be fair: Towards fairness in adversarial training},
  author={Xu, Han and Liu, Xiaorui and Li, Yaxin and Jain, Anil and Tang, Jiliang},
  booktitle={ICML},
  year={2021}
}

@inproceedings{tian2021analysis,
  title={Analysis and applications of class-wise robustness in adversarial training},
  author={Tian, Qi and Kuang, Kun and Jiang, Kelu and Wu, Fei and Wang, Yisen},
  booktitle={KDD},
  year={2021}
}

@inproceedings{zhang2019theoretically,
  title={Theoretically principled trade-off between robustness and accuracy},
  author={Zhang, Hongyang and Yu, Yaodong and Jiao, Jiantao and Xing, Eric and El Ghaoui, Laurent and Jordan, Michael},
  booktitle={ICML},
  year={2019}
}

@article{tsipras2018robustness,
  title={Robustness may be at odds with accuracy},
  author={Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Turner, Alexander and Madry, Aleksander},
  journal={arXiv preprint arXiv:1805.12152},
  year={2018}
}

@inproceedings{papernot2016distillation,
  title={Distillation as a defense to adversarial perturbations against deep neural networks},
  author={Papernot, Nicolas and McDaniel, Patrick and Wu, Xi and Jha, Somesh and Swami, Ananthram},
  booktitle={SP},
  year={2016}
}

@article{das2017keeping,
  title={Keeping the bad guys out: Protecting and vaccinating deep learning with jpeg compression},
  author={Das, Nilaksh and Shanbhogue, Madhuri and Chen, Shang-Tse and Hohman, Fred and Chen, Li and Kounavis, Michael E and Chau, Duen Horng},
  journal={arXiv preprint arXiv:1705.02900},
  year={2017}
}

@inproceedings{xie2019feature,
  title={Feature denoising for improving adversarial robustness},
  author={Xie, Cihang and Wu, Yuxin and Maaten, Laurens van der and Yuille, Alan L and He, Kaiming},
  booktitle={CVPR},
  year={2019}
}

@inproceedings{bai2019hilbert,
  title={Hilbert-based generative defense for adversarial examples},
  author={Bai, Yang and Feng, Yan and Wang, Yisen and Dai, Tao and Xia, Shu-Tao and Jiang, Yong},
  booktitle={ICCV},
  year={2019}
}

@inproceedings{athalye2018obfuscated,
  title={Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples},
  author={Athalye, Anish and Carlini, Nicholas and Wagner, David},
  booktitle={ICML},
  year={2018}
}

@inproceedings{wu2020adversarial,
                        title={Adversarial Weight Perturbation Helps Robust Generalization},
                        author={Wu, Dongxian and Xia, Shu-Tao and Wang, Yisen},
                        booktitle={NeurIPS},
                        year={2020}}

@inproceedings{rice2020overfitting,
  title={Overfitting in adversarially robust deep learning},
  author={Rice, Leslie and Wong, Eric and Kolter, Zico},
  booktitle={ICML},
  year={2020}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada}
}

@article{balaji2019instance,
  title={Instance adaptive adversarial training: Improved accuracy tradeoffs in neural nets},
  author={Balaji, Yogesh and Goldstein, Tom and Hoffman, Judy},
  journal={arXiv preprint arXiv:1910.08051},
  year={2019}
}

@inproceedings{wang2023simple,
  title={Generalist: Decoupling Natural and Robust Generalization},
  author={Hongjun Wang and Yisen Wang},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{mo2022adversarial,
                      title={When Adversarial Training Meets Vision Transformers: Recipes from Training to Architecture},
                      author={Mo, Yichuan and Wu, Dongxian and Wang, Yifei and Guo, Yiwen and Wang, Yisen},
                      booktitle={NeurIPS},
                      year={2022}}

@inproceedings{wang2019improving,
  title={Improving adversarial robustness requires revisiting misclassified examples},
  author={Wang, Yisen and Zou, Difan and Yi, Jinfeng and Bailey, James and Ma, Xingjun and Gu, Quanquan},
  booktitle={ICLR},
  year={2019}
}


@inproceedings{zhang2020attacks,
  title={Attacks which do not kill training make adversarial learning stronger},
  author={Zhang, Jingfeng and Xu, Xilie and Han, Bo and Niu, Gang and Cui, Lizhen and Sugiyama, Masashi and Kankanhalli, Mohan},
  booktitle={ICML},
  year={2020}
}

@article{zhang2020geometry,
  title={Geometry-aware instance-reweighted adversarial training},
  author={Zhang, Jingfeng and Zhu, Jianing and Niu, Gang and Han, Bo and Sugiyama, Masashi and Kankanhalli, Mohan},
  journal={arXiv preprint arXiv:2010.01736},
  year={2020}
}

@article{bai2021clustering,
  title={Clustering effect of adversarial robust models},
  author={Bai, Yang and Yan, Xin and Jiang, Yong and Xia, Shu-Tao and Wang, Yisen},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={29590--29601},
  year={2021}
}

@inproceedings{DBLP:conf/uai/IzmailovPGVW18,
  author    = {Pavel Izmailov and
               Dmitrii Podoprikhin and
               Timur Garipov and
               Dmitry P. Vetrov and
               Andrew Gordon Wilson},
  title     = {Averaging Weights Leads to Wider Optima and Better Generalization},
  booktitle = {UAI},
  year      = {2018},
}

@inproceedings{wang2022self,
                        title={Self-Ensemble Adversarial Training for Improved Robustness},
                        author={Wang, Hongjun and Wang, Yisen},
                        booktitle={ICLR},
                        year={2022}}

@article{benz2021robustness,
  title={Robustness May Be at Odds with Fairness: An Empirical Study on Class-wise Accuracy},
  author={Benz, Philipp and Zhang, Chaoning and Karjauv, Adil and Kweon, In So},
  journal={arXiv preprint arXiv:2010.13365},
  year={2020}
}

@inproceedings{carlini2017towards,
  title={Towards evaluating the robustness of neural networks},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={2017 ieee symposium on security and privacy (sp)},
  pages={39--57},
  year={2017},
  organization={Ieee}
}

@inproceedings{croce2020reliable,
  title={Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks},
  author={Croce, Francesco and Hein, Matthias},
  booktitle={ICML},
  year={2020}
}

@article{wang2020unified,
  title={A unified approach to interpreting and boosting adversarial transferability},
  author={Wang, Xin and Ren, Jie and Lin, Shuyun and Zhu, Xiangming and Wang, Yisen and Zhang, Quanshi},
  journal={arXiv preprint arXiv:2010.04055},
  year={2020}
}

@article{wu2020skip,
  title={Skip connections matter: On the transferability of adversarial examples generated with resnets},
  author={Wu, Dongxian and Wang, Yisen and Xia, Shu-Tao and Bailey, James and Ma, Xingjun},
  journal={arXiv preprint arXiv:2002.05990},
  year={2020}
}
@inproceedings{bai2020improving,
  title={Improving query efficiency of black-box adversarial attack},
  author={Bai, Yang and Zeng, Yuyuan and Jiang, Yong and Wang, Yisen and Xia, Shu-Tao and Guo, Weiwei},
  booktitle={European Conference on Computer Vision},
  pages={101--116},
  year={2020},
  organization={Springer}
}
@inproceedings{li2019nattack,
  title={Nattack: Learning the distributions of adversarial examples for an improved black-box attack on deep neural networks},
  author={Li, Yandong and Li, Lijun and Wang, Liqiang and Zhang, Tong and Gong, Boqing},
  booktitle={International Conference on Machine Learning},
  pages={3866--3876},
  year={2019},
  organization={PMLR}
}


@article{xu2017feature,
  title={Feature squeezing: Detecting adversarial examples in deep neural networks},
  author={Xu, Weilin and Evans, David and Qi, Yanjun},
  journal={arXiv preprint arXiv:1704.01155},
  year={2017}
}
@inproceedings{ross2018improving,
  title={Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients},
  author={Ross, Andrew and Doshi-Velez, Finale},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{chen2015deepdriving,
  title={Deepdriving: Learning affordance for direct perception in autonomous driving},
  author={Chen, Chenyi and Seff, Ari and Kornhauser, Alain and Xiao, Jianxiong},
  booktitle={CVPR},
  year={2015}
}

@article{ma2019understanding,
  title={Understanding Adversarial Attacks on Deep Learning Based Medical Image Analysis Systems},
  author={Ma, Xingjun and Niu, Yuhao and Gu, Lin and Wang, Yisen and Zhao, Yitian and Bailey, James and Lu, Feng},
  journal={Pattern Recognition},
  year={2020}
}

@inproceedings{wang2021convergence,
  title={On the convergence and robustness of adversarial training},
  author={Wang, Yisen and Ma, Xingjun and Bailey, James and Yi, Jinfeng and Zhou, Bowen and Gu, Quanquan},
  booktitle={ICML},
  year={2019}
}

@article{cai2018curriculum,
  title={Curriculum adversarial training},
  author={Cai, Qi-Zhi and Du, Min and Liu, Chang and Song, Dawn},
  journal={arXiv preprint arXiv:1805.04807},
  year={2018}
}

@article{ding2018mma,
  title={Mma training: Direct input space margin maximization through adversarial training},
  author={Ding, Gavin Weiguang and Sharma, Yash and Lui, Kry Yik Chau and Huang, Ruitong},
  journal={arXiv preprint arXiv:1812.02637},
  year={2018}
}
@article{cheng2020cat,
  title={Cat: Customized adversarial training for improved robustness},
  author={Cheng, Minhao and Lei, Qi and Chen, Pin-Yu and Dhillon, Inderjit and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:2002.06789},
  year={2020}
}
@inproceedings{he2016identity,
  title={Identity mappings in deep residual networks},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={ECCV},
  year={2016}
}

@inproceedings{GAIR,
  author = {Zhang, Jingfeng and Zhu, Jianing and Niu, Gang and Han, Bo and Sugiyama, Masashi and Kankanhalli, Mohan},  
  title = {Geometry-aware Instance-reweighted Adversarial Training},
booktitle={ICLR},
  year = {2021}  
}

@inproceedings{
ma2022on,
title={On the Tradeoff Between Robustness and Fairness},
author={Xinsong Ma and Zekai Wang and Weiwei Liu},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=LqGA2JMLwBw}
}