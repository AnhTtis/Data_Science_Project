\section{Class-wise Calibrated Fair Adversarial Training}
With the above analysis, we introduce our proposed \textbf{C}lass-wise  calibrated \textbf{F}air \textbf{A}dversarial training (CFA) framework in this section.
Overall, the CFA framework consists of three main components: Customized Class-wise perturbation Margin (CCM), Customized Class-wise Regularization (CCR), and Fairness Aware Weight Averaging (FAWA).
The CCM and CCR customize appropriate training configurations for different classes, and FAWA modifies weight averaging to improve and stabilize fairness.

\subsection{Class-wise Calibrated Margin (CCM)}
\label{CCM}
In Sec.~\ref{margin analysis}, we have demonstrated that different classes prefer specific perturbation margin $\epsilon$ in adversarial training. However, it is impractical to directly find the optimal class-wise margin. Inspired by a series of instance-wise adaptive adversarial training approaches~\cite{ding2018mma,wang2019improving,balaji2019instance}, which customize train setting for each instance according to the model performance on current example, we propose to leverage the class-wise training accuracy as the measurement of difficulty.

Suppose the $k$-th class achieved train robust accuracy $t_k\in[0,1]$ in the last training epoch. 
In the next epoch, we aim to update the margin $\epsilon_k$ for class $k$ based on $t_k$.
Based on our analysis in Sec.~\ref{margin analysis}, we consider using a relatively smaller margin for the hard classes which are more vulnerable to attacks, and identify the \textit{difficulty} among classes by the train robust accuracy tracked from the previous epoch.
To avoid $\epsilon_k$ too small, we add a hyper-parameter $\lambda_1$ (called \textit{base perturbation budget}) on all $t_k$ and set the calibrated margin $\epsilon_k$ by multiply the coefficient on primal margin $\epsilon$:
\begin{equation}
    \epsilon_k\gets (\lambda_1 +  t_k)\cdot \epsilon,
    \label{ccm formula}
\end{equation}
where $\epsilon$ is the original perturbation margin, \textit{e.g.}, $8/255$ that is commonly used for CIFAR-10 dataset. 
Note that the calibrated margin $\epsilon_k$ can adaptively converge to find the proper range during the training phase, for example, 
 if the margin is too small for class $k$, the model will perform high train robust accuracy $t_k$ and then increase $\epsilon_k$ by schedule (\ref{ccm formula}). 

\subsection{Class-wise Calibrated Regularization (CCR)}
We further customize different robustness regularization $\beta$ of TRADES for different classes.
Recall the objective function (\ref{TRADES}) of TRADES, we hope the hard classes tend to bias more weight on its clean accuracy. Still, we measure the difficulty by the train robust accuracy $t_k$ for class $k$, 
and propose the following calibrated robustness regularization $\beta_k$:
\begin{equation}
    \beta_k\gets (\lambda_2 + t_k) \cdot \beta.
\end{equation}
where $\beta$ is the originally selected parameter.
The objective function (\ref{TRADES}) can be rewritten as:
\begin{equation}
\label{ccw objective}
    \mathcal L_{\boldsymbol\theta}(\beta;x,y)=
    \frac{\mathcal L(\boldsymbol\theta;x,y) + \beta_y\max\limits_{\|{x'}-{x}\|\le\epsilon} \mathcal{K} (f_{\boldsymbol\theta}({x}), f_{\boldsymbol\theta}({x'}))}{1+\beta_y}.
\end{equation}

To balance the weight between different classes, we add a denominator $1+\beta_y$ since $\beta_y$ is distinct among classes. Therefore, for the hard classes which have lower $\beta_y$ tend to bias higher weight $\frac 1 {1+\beta_y}$ on its natural loss $\mathcal L(\boldsymbol\theta;x,y)$. Note that simply replacing $\epsilon$ in (\ref{ccw objective}) with $\epsilon_k$ can combine the calibrated margin with this calibrated regularization.  On the other hand, for general adversarial training algorithms, our calibrated margin schedule (\ref{ccm formula}) can also be combined.

\subsection{Fairness Aware Weight Average (FAWA)}
\label{sec: fawa}
As plotted in Fig.~\ref{fig:worst and overall}(a), the worst class robustness changes largely, among which part of checkpoints performs extremely poor robust fairness. 
Previously, there are a series of weight averaging methods to make the model training stable, \textit{e.g.}, exponential moving average (EMA) \cite{DBLP:conf/uai/IzmailovPGVW18,wang2022self}, thus we hope to further improve the worst class robustness by fixing the weight average algorithm.

Inspired by the large fluctuation of the robustness fairness among checkpoints, we consider eliminating the \textit{unfair} checkpoints out in the weight averaging process. To this end, we propose a \textit{Fairness Aware Weight Average (FAWA)} approach, which sets a threshold $\delta$ on the worst class robustness of the new checkpoint in the EMA process. Specifically, we extract a validation set from the dataset, and each checkpoint is adopted in the weight average process if and only if its worst class robustness is higher than $\delta$. Fig.~\ref{fig:worst and overall}(b) shows the effect of the proposed FAWA. The difference between adjacent epochs is extremely small (less than 1\%), and the overall robustness also outperforms vanilla AT.

\begin{algorithm}[h]
    \caption{TRADES with CFA}
	\label{alg:cfa}
	\KwIn{A DNN classifier $f_{\boldsymbol\theta}(\cdot)$ with parameter $\boldsymbol\theta$; Train dataset $D=\{(x_i, y_i)\}_{i=1}^N$; Batch size $m$; Initial perturbation margin $\epsilon$ and robustness regularization $\beta$; Train epochs $N$; Batch size $m$; Learning rate $\eta$; Weight average decay rate $\alpha$; Fairness threshold $\delta$}
	\KwOut{A fair and robust DNN classifier $\bar{f}_{\bar{\boldsymbol\theta}}(\cdot)$}
	\tcc{Initialize parameters and datasets}
    Initialize $\boldsymbol\theta\gets\boldsymbol\theta_0, \bar{\boldsymbol\theta}\gets\boldsymbol\theta$\;
    Split $D=D_{\text{train}}\cup D_{\text{valid}}$\;
    \For{$y\in\mathcal Y$}{
    \tcc{Initialize $\epsilon_y$ and $\beta_y$}
    $\epsilon_y\gets\epsilon, \beta_y\gets\beta$\;
    }
    
    \For{$T\gets 1,2,\cdots N$}{
        \For{Every minibatch $(x,y)$ in $D_{\text{train}}$}{
        \tcc{Use $\epsilon_y$ and $\beta_y$ to train}
        $x'\gets \arg\max\limits_{x'\in\mathcal{B}(x,\epsilon_y)}\mathcal K (f_{\boldsymbol\theta}({x}), f_{\boldsymbol\theta}({x'}))$\;
        $\boldsymbol\theta \gets \boldsymbol\theta - \eta\nabla_{\boldsymbol\theta}\mathcal L_{\boldsymbol\theta}(\beta_y;x,y)$\;
        }
        \For{$y\in\mathcal Y$}{
        $t_y\gets Train\_Acc(f_\theta, T)$\;
        \tcc{Update $\epsilon_y,\beta_y$ with $t_y$}
        $\epsilon_y\gets (\lambda_1 + t_k)\cdot\epsilon$\;
        $\beta_y\gets (\lambda_2 + t_k)\cdot \epsilon$\;}
        \tcc{Fairness Aware Weight Average}
        \If{$\min_{y\in\mathcal Y} \mathcal{R}_{y}(f_{\boldsymbol\theta}, D_{\text{valid}})\ge \delta$}{
        \vspace{0.1cm}
        $\bar{\boldsymbol{\theta}}\gets \alpha\bar{\boldsymbol\theta}+(1-\alpha){\boldsymbol\theta}$\;}
    }
    \textbf{return} $\bar{f}_{\bar{\boldsymbol\theta}}$\;

\end{algorithm}

\subsection{Discussion}

Overall, by combining the above components, we accomplish our CFA framework. An illustration of incorporating CFA to TRADES is shown in Alg.~\ref{alg:cfa}. Note that for other methods like AT, we can still incorporate CFA by removing the CCR schedule specified for TRADES. Moreover, we discuss the difference between our proposed CFA and other works. 

\noindent \textbf{Comparison with Fair Robust Learning (FRL)~\cite{xu2021robust}.}
Here we highlight the differences between our CFA framework and Fair Robust Learning (FRL), the only existing adversarial training algorithm designed to improve the fairness of class-wise robustness. The FRL framework consists of two components: remargin and reweight. Initially, a robust model is trained, and a fairness constraint on the difference of robustness among classes is set. When the constraint is violated, the model is fine-tuned persistently by increasing the perturbation bound $\epsilon_k$ and weighting the loss of the hard classes. Although CFA also includes adaptive margin and regularization weight schedules, our work is fundamentally distinct from FRL. Firstly, as discussed in Sec.~\ref{margin analysis}, a larger margin only mitigates the robust over-fitting problem but does not provide higher peak performance. In contrast, our approach aims to customize the proper margin for each class, which boosts the best performance. Secondly, FRL improves robust fairness at the cost of reducing overall robustness, which could be seen as \textit{unfair} to other classes. However, our CFA framework improves both overall and worst class performance. In addition, FRL requires an initial robust model before fairness fine-tuning, resulting in extra computational burden. Finally, the fluctuation effect discussed in Sec.~\ref{fluctuate} is not considered in FRL. 

\noindent \textbf{Comparison with Instance-wise Adversarial Training.}
\label{dis:instance}
Though there exists a series of instance-wise adaptive adversarial training~\cite{ding2018mma,  balaji2019instance,wang2019improving,cheng2020cat, zhang2020attacks, GAIR, cai2018curriculum, wang2021convergence} toward better robust generalization, to the best of our knowledge, we are the first work to pursue this from a class-wise perspective. 
Here we demonstrate several differences between our class-wise and other instance-wise adversarial training algorithms. 
First of all, CFA focuses on improve both overall and the worst class robust accuracy, while all existing instance-wise approaches only focus on overall robustness. Unfortunately, as shown in Sec.~\ref{sec:experiment}, the instance-wise ones are not comparable with our CFA from the perspective of fairness. 
In addition, instance-wise methods can be seen as to find the solution for each individual sample, while class-wise ones are to find the solution for multiple samples. Thus, class-wise methods can alleviate the frequent fluctuation while remaining the specificity (a class of samples) of configurations among training samples. Therefore, our class-wise calibration achieves a better trade-off between flexibility and stability. Finally,  some instance-wise approaches can be well-combined with our CFA framework to further boost their performance. 
