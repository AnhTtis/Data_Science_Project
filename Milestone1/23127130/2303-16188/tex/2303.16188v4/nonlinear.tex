
\section{Extension for Solving Nonlinear Equations}
\begin{algorithm}[t]
\caption{Symmetric Rank-$k$ Method for Nonlinear Equation}\label{alg:SRK-NE}
\begin{algorithmic}[1]
\STATE \textbf{Input:} $\H_0$, $M$ and $k$. \\[0.15cm]
\STATE \textbf{for} $t=0,1\dots$\\[0.15cm]
\STATE \quad  $\z_{t+1}=\z_t-\H_t^{-1}\J(\z_t)^{\top}  \F(\z_t)$ \\[0.15cm]
\STATE \quad $r_t=\|\z_{t+1}-\z_{t}\|_2$ \\[0.15cm]
\STATE \quad $\tilde{\H}_{t}=(1+Mr_t)\H_t$ \\[0.1cm]
\STATE \quad construct $\U_t$ by $\left[\U_{t}\right]_{ij}\overset{\rm{i.i.d}}{\sim} {\fN(0,1)}$ \\[0.15cm]
\STATE \quad  $\H_{t+1}= \srk(\tilde{\H}_t, \J(\z_{t+1})^\top\J(\z_{t+1}),\U_t)$\\[0.15cm]
\STATE \textbf{end for}
\end{algorithmic}
\end{algorithm}

In this section, we apply \srk~methods to solve the nonlinear equations
\begin{align}
\label{eq:NE}
    \F(\z) =\0,
\end{align}
where $\F:\RB^{d}\to\RB^{d}$ is a differentiable vector-valued function. We use $\J(\vz)$ to represent the Jacobian of $\F(\cdot)$ at $\z\in\RB^d$ and impose the following assumptions.

\begin{assumption}
\label{ass:NElip}
We assume the vector-valued function
$F:\RB^{d}\to\RB^d$ is differentiable and its Jacobian is $\tilde L_2$-Lipschitz continuous, i.e., there exists some $\tilde L_2\geq 0$ such that 
\begin{align}
    \|\J(\z)-\J(\z')\|\leq \tilde L_2\|\z-\z'\|.
\end{align}
for any $\vz,\vz'\in\BR^d$.
\end{assumption}

\begin{assumption}
\label{ass:nonde}
We assume there exists equation (\ref{eq:NE}) has a solution $\z^*$ such that $\J(\z^*)$ is non-degenerate.
\end{assumption}

According to Assumption~\ref{ass:nonde}, we denote
\begin{align*}
    \tilde\mu \triangleq \frac{\sigma_{\min}(\J(\z^*))}{\sqrt{2}},\qquad \tilde L \triangleq 2\sigma_{\max}(\J(\z^*)) \qquad \text{and} \qquad {\tilde\kappa}\triangleq \frac{\tilde L}{\tilde \mu},
\end{align*}
where $\sigma_{\min}(\cdot)$ and $\sigma_{\max}(\cdot)$ are the smallest and the largest singular values of given matrix respectively. 

We present \srk~methods for solving nonlinear equations in Algorithm~\ref{alg:SRK-NE}.
The design of this algorithm is inspired by the recent work of~\citet{liu2022quasi}, which applies the quasi-Newton methods to estimate the information of non-degenerate indefinite matrix by its square.
We use the Euclidean norm $\tilde\lambda(\z)\triangleq\norm{\F(\z)}$ to measure the convergence of our algorithm. 
The advantage of block updates in \srk~updates results a faster superlinear convergence than~\citet{liu2022quasi}'s methods.
Following the analysis of \srk~methods for convex optimization, we obtain the results for solving nonlinear equations as follows.


\begin{theorem}
\label{thm:srk-NE}
Under {Assumption \ref{ass:NElip} and \ref{ass:nonde}}, we run Algorithm~\ref{alg:SRK-NE} with $k<d$, $\tilde M={2\tilde{\varkappa}^2 \tilde 
 L_2}/{\tilde L}$ and set the initial~$\vz_0$ and $\H_0$ such that
\begin{align*}
    \tilde \lambda(\z_0)\leq \frac{\ln 2}{8}\cdot \frac{ (d-k)\tilde{\mu}}{\tilde  M\eta_0 d^2{\tilde \varkappa}^2} 
    \qquad \text{and} \qquad 
    \J(\z_0)^{\top}\J(\z_0)\preceq\H_0\preceq \eta_0\J(\z_0)^{\top}\J(\z_0)
\end{align*} 
for some $\eta_0\geq 1$. 
Then we have
\begin{align*}
     \EBP{\frac{\tilde{\lambda}({\z}_{t+1})}{\tilde{\lambda}(\z_t)}}\leq 2d\tilde{\varkappa}^2\eta_0\left(1-\frac{k}{d}\right)^{t}.
\end{align*}

\end{theorem}