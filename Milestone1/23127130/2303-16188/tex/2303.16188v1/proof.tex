\section{The Proof of Section~\ref{sec:algorithm}}
%\subsection{Unified Proof of Superlinear Convergence}

We provide the proofs for the results of \srk~methods shown in Section~\ref{sec:algorithm}.


\subsection{Auxiliary Lemmas}
We first provide some auxiliary lemmas which will be used in our later proof.

\begin{lemma}
\label{lm:superlinear}
Let $\{\lambda_t\}$ and $\{\delta_t\}$ be two non-negative random sequences that satisfy
\begin{align}
\label{eq:supercondi}
  \lambda_{t+1}\leq (1+m\lambda_t)^2(\delta_t+b\lambda_t)\lambda_t, \qquad
  \lambda_{t}\leq \left(1-\frac{1}{\beta}\right)^t\lambda_0, \qquad
  \delta_0+a\lambda_0 \leq s
\end{align}
and 
\begin{align}
\label{eq:supercondi2}
    \BE_{t}\left[\delta_{t+1}\right]\leq \left(1-\frac{1}{\alpha}\right)(1+m\lambda_t)^2(\delta_t+c\lambda_t),
\end{align}
for some $b,c,m,s,\beta\geq 0$ and $\alpha>1$, where $a=\max\{b,c\}>1$ and $\EB_{t}[\,\cdot\,]\triangleq \EB[\,\cdot\,|\delta_0,\cdots,\delta_{t},\lambda_0,\cdots,\lambda_{t}]$. 
If $\lambda_0$ is sufficient small such that 
\begin{align}
\label{eq:supercondiini}
    \lambda_0\leq \frac{\ln 2}{\beta (2m+a(\alpha/(\alpha-1)))}
\end{align}
then it holds that
\begin{align*}
    \BE\left[\frac{\lambda_{t+1}}{\lambda_t}\right]\leq \left(1-\frac{1}{\alpha}\right)^{t}2s.
\end{align*}
\end{lemma}

\begin{proof}
We denote
\begin{align}
\label{eq:thetadef}
    \theta_t\triangleq \delta_t+a \lambda_t.
\end{align}
Since the index $t+1\geq 1$, we have
\begin{align}
\label{eq:lambdat_leq_thetat}
    \EB_{t}[\delta_{t+1}] \overset{\eqref{eq:supercondi2}}{\leq}\left(1-\frac{1}{\alpha}\right)(1+m\lambda_t)^2(\delta_t+a\lambda_t)\leq \left(1-\frac{1}{\alpha}\right){\rm e}^{2m\lambda_t}\theta_t
    \quad\text{and}\quad
    \lambda_{t+1} \overset{\eqref{eq:supercondi}}{\leq} {\rm e}^{2m\lambda_t}\theta_t\lambda_t.
\end{align}
Then it holds that
\begin{align}
\label{eq:thetat+1leqs}
\begin{split}
    \EB_{t}[\theta_{t+1}]&\overset{\eqref{eq:thetadef}}{\leq} \left(1-\frac{1}{\alpha}\right)\left(1+\frac{\alpha a}{\alpha-1}\lambda_t\right){\rm e}^{2m\lambda_t}\theta_t \leq\left(1-\frac{1}{\alpha}\right){\rm e}^{(2m+a\alpha/(\alpha-1))\lambda_t}\theta_t\\
    &=\left(1-\frac{1}{\alpha}\right){\rm e}^{m'\lambda_t}\theta_t
    \overset{\eqref{eq:supercondi}}{\leq} \left(1-\frac{1}{\alpha}\right){\rm e}^{m'(1-{1}/{\beta})^t\lambda_0}\theta_t,
    \end{split}
\end{align}
where $m'=2m+a\alpha/(\alpha-1)$.
Taking expectation on both sides of \eqref{eq:thetat+1leqs}, we have
\begin{align}
\label{eq:expthetat}
    \EB[\theta_{t+1}]\leq \left(1-\frac{1}{\alpha}\right){\rm e}^{m'(1-{1}/{\beta})^t\lambda_0}\EB[\theta_t],
\end{align}
where we use the fact $\EB[\EB_{t}[\delta_{t+1}]] = \EB[\delta_{t+1}]$.
Therefore, we have
\begin{align*}    
& \BE\left[\frac{\lambda_{t+1}}{\lambda_t}\right]
\overset{\eqref{eq:lambdat_leq_thetat}}{\leq} \BE[\ee^{2m\lambda_t}\theta_{t}] 
{\leq}  \left(1-\frac{1}{\alpha}\right){\rm e}^{m'(1-{1}/{\beta})^t\lambda_0}\EBP{\theta_{t}}
\overset{\eqref{eq:expthetat}}{\leq}  \left(1-\frac{1}{\alpha}\right){\rm e}^{(m'(1-{1}/{\beta})^t+m'(1-{1}/{\beta})^{t-1})\lambda_0}\EBP{\theta_{t}}\\
&\overset{\eqref{eq:expthetat}}{\leq}\left(1-\frac{1}{\alpha}\right)^{t} {\rm e}^{m'\sum_{p=0}^{t}(1-{1}/{\beta})^p\lambda_0}\EBP{\theta_0}
\overset{\eqref{eq:supercondiini}}{\leq}  \left(1-\frac{1}{\alpha}\right)^t {\rm e}^{m'\beta\lambda_0}\EBP{\theta_0}\overset{\eqref{eq:supercondi}}{\leq} \left(1-\frac{1}{\alpha}\right)^t 2s.
\end{align*}
\end{proof}






\begin{lemma}[{Following \citet[Theorem 4.7]{rodomanov2021greedy}  and \citet[Theorem 23]{lin2021greedy}}]
\label{lm:linear}
Let~$\{\lambda_t\}$ and $\{\tilde{\eta}_t\}$ be two positive sequences where $\tilde{\eta}_t\geq 1$ that satisfy
\begin{align}
\label{eq:lambda_t_1}
    \lambda_{t+1}\leq \left(1-\frac{1}{\tilde{\eta_t}}\right)\lambda_t + \frac{m_1}{2}\lambda_t^2 + \frac{m_1^2}{4\tilde{\eta}_t}\lambda_t^3~~~\text{and}~~~   \tilde{\eta}_{t+1}\leq (1+m_2\lambda_t)^2\tilde{\eta}_t,
\end{align}
for some $m_1$ and $m_2>0$.
If
\begin{align}
    \label{eq:linear_initial}
    m\lambda_0\leq \frac{\ln ({3}/{2})}{4\tilde{\eta}_0},
\end{align}
where $m\triangleq\max\{m_1,m_2\}$,
then it holds that
\begin{align}\label{eq:tilde_eta}
    \tilde{\eta}_t\leq {\rm e}^{2m\sum_{i=0}^{t-1}\lambda_t}\tilde{\eta}_0\leq \frac{3\tilde{\eta}_0}{2}
\end{align}
and
\begin{align}\label{eq:lambda_t_linear}
\lambda_t&\leq\left(1-\frac{1}{2\tilde{\eta}_0}\right)^t\lambda_0.
\end{align}
\end{lemma}
\begin{proof}
%see \citet{Lin2021greedy} Theorem 23
We prove results of \eqref{eq:tilde_eta} and \eqref{eq:lambda_t_linear} by induction. 
In the case of $t=0$, inequalities \eqref{eq:tilde_eta} and \eqref{eq:lambda_t_linear} are satisfied naturally. 
Now we suppose inequalities \eqref{eq:tilde_eta} and \eqref{eq:lambda_t_linear} holds for $t=0,\dots,t'$, then we have
\begin{align}    m\sum_{i=0}^{t'}\lambda_i\overset{\eqref{eq:lambda_t_linear}}{\leq} m\lambda_0\sum_{i=0}^{t'}\left(1-\frac{1}{2\tilde{\eta}_0}\right)^{i} \leq 2\tilde{\eta}_0 m \lambda_0 \overset{\eqref{eq:linear_initial}}{\leq} 1.
\end{align}
In the case of $t=t'+1$ we have
\begin{align}
\label{eq:simple_induct}
   \frac{ 1-{m_1\lambda_{t'}}/{2}}{\tilde{\eta}_{t'}}{\geq} \frac{\ee^{-m_1\lambda_{t'}}}{\tilde{\eta}_{t'}}\overset{\eqref{eq:tilde_eta}}{\geq} \frac{\ee^{-2m\sum_{i=0}^{t}\lambda_i}}{\tilde{\eta}_0}\geq \frac{2}{3\tilde{\eta}_0}\qquad\text{and}\qquad m\lambda_{t'}\leq m\lambda_0\overset{\eqref{eq:linear_initial}}{\leq} \frac{1}{8\tilde{\eta}_0}.
\end{align}
According to condition \eqref{eq:lambda_t_1}, we have
\begin{align*}
    \lambda_{t'+1}&\overset{\eqref{eq:lambda_t_1}}{\leq} \left(1+\frac{m_1\lambda_{t'}}{2}\right)\left(1-\frac{1-{m_1\lambda_{t'}}/{2}}{\tilde{\eta}_{t'}}\right)\lambda_{t'}\overset{\eqref{eq:simple_induct}}{\leq}\left(1-\frac{1}{2\tilde{\eta}_0}\right)\lambda_{t'}\leq \left(1-\frac{1}{2\tilde{\eta}_0}\right)^{{t'}+1}\lambda_0,
\end{align*}
where the last step is based on induction.
We also have
\begin{align*}
   \tilde{ \eta}_{t'+1}\overset{\eqref{eq:lambda_t_1}}{\leq}(1+m_2\lambda_{t'})^2\tilde{\eta}_t\leq \ee^{2m\lambda_{t'}}\tilde{\eta}_{t'} \overset{\eqref{eq:tilde_eta}}{\leq} \ee^{2m\sum_{i=0}^{t'}\lambda_{t'}}\tilde{\eta}_0\overset{\eqref{eq:linear_initial}}{\leq } \frac{3\tilde{\eta}_0}{2}.
\end{align*}
\end{proof}


%We also introduce some results of \citet{rodomanov2021greedy} and \citet{lin2021greedy}.

% \begin{lemma}[{\cite[Lemma 4.2 and Lemma 4.3]{rodomanov2021greedy}, \cite[Lemma 25]{lin2021greedy}}]
% \label{lm:strong_self}
% If the twice differentiable function $f:\BR^d\to\BR$ is $M$-strongly self-concordant and $\mu$-strongly convex, then it holds that
% \begin{align*}
%     \frac{\nabla^2 f(\x)}{1+M\|\y-\x\|_\x}\preceq\nabla^2 f(\y) \preceq (1+M\|\y-\x\|_\x) f(\x)
% \end{align*}
% for all $\x,\y\in\RB^d$. 
% \end{lemma}
\begin{lemma}[{\cite[Lemma 25]{lin2021greedy}}]
\label{lm:strong_self}
If the twice differentiable function $f:\BR^d\to\BR$ is $M$-strongly self-concordant and $\mu$-strongly convex and the positive definite matrix $\G\in\RB^{d\times d}$ and $\vx\in\BR^d$ satisfy $\nabla^2 f(\x)\preceq \G\preceq \eta\nabla^2 f(\x)$ for some $\eta>1$, then we have
\begin{align}
& \nabla^2 f(\x_{+})\preceq\tilde{\G}\preceq \eta(1+Mr)^2\nabla^2 f(\x_{+}), \label{eq:tilde_G_geq} \\
 & \sigma_{\nabla^2f(\x_{+})}(\tilde{\G})\leq (1+Mr)^2 (\sigma_{\nabla^2f(\x)}({\G})+2dMr),   \label{eq:delta_BFGS_lin}
\end{align}
and
\begin{align}
   \label{eq:delta_SRK_lin}
   \tau_{\nabla^2f(\x_{+})}(\tilde{\G})\leq (1+Mr)^2\left(\frac{\tau_{\nabla^2 f(\x)}(\G)}{\tr{\nabla^2f(\x)}}+2Mr\right)\tr{\nabla^2f(\x_{+})}
\end{align}
for any $\vx_+\in\BR^d$, where $\tilde{\G}=(1+Mr)\G$, $r=\|\x-\x_{+}\|_{\x}$ and the notations of $\tau_\H(\G)$ and $\sigma_\H(\G)$ follow the expressions of~\eqref{eq:measure_srk} and \eqref{eq:measurebfgs} respectively.
\end{lemma}

\begin{lemma}[{\cite[Lemma 25]{lin2021greedy}}]
\label{lm:GHneq}
For any positive definite symmetric matrices $\G,\H\in\RB^{d\times d}$ such that $\H\preceq\G$ , 
it holds that
\begin{align}
\label{eq:GHneq}
   \G\preceq (1+\sigma_{\H}(\G))\H~~~\text{and}~~~\G\preceq \left(1+\frac{\hat\varkappa d \tau_{\H}(\G)}{\tr{\H}}\right)\H,
\end{align}
where $\hat\varkappa$ is the condition number of $\H$ and the notations of $\tau_\H(\G)$ and $\sigma_\H(\G)$ follow the expressions of \eqref{eq:measure_srk} and \eqref{eq:measurebfgs} respectively.
\end{lemma}

\begin{lemma}
\label{lm:GHneq_2}
For any positive definite symmetric matrices $\G,\H\in\RB^{d\times d}$ such that $\H\preceq\G\preceq\eta\H$ for some~$\eta\geq 1$ , 
it holds that
\begin{align}
\label{eq:GHneq_2}
   \sigma_{\H}(\G)\leq d(\eta -1) \qquad\text{and}\qquad\frac{\tau_{\H}(\G)}{\tr{\H}} \leq \eta -1,
\end{align}
where the notations of $\tau_\H(\G)$ and $\sigma_\H(\G)$ follow the expressions of \eqref{eq:measure_srk} and \eqref{eq:measurebfgs} respectively.
\end{lemma}
\begin{proof}
We obtain the statements directly from the definition, that is
\begin{align*}
    \sigma_{\H}(\G)=\tr{\H^{-1}(\G-\H)}=\tr{\H^{-1/2}(\G-\H)\H^{-1/2}}\leq \tr{(\eta-1)\H^{-1/2}\H\H^{-1/2}} = (\eta-1)d,
\end{align*}
and
\begin{align*}
   \frac{\tau_{\H}(\G)}{\tr{\H}} =\frac{ \tr{(\G-\H)}}{\tr{\H}}{\leq} \frac{\tr{(\eta-1)\H}} {\tr{\H}}= \eta-1.
\end{align*}
\end{proof}

\begin{lemma}[{\cite[Lemma 26]{lin2021greedy}}]
\label{lm:randomsequence_lin}
Suppose the nonnegative random sequences $\{X_t\}$
satisfies $\EB[X_t]\leq a\left(1-{1}/{\alpha}\right)^t$ for all $t\geq0$ and some constants $a\geq 0$ and $\alpha>1$. 
Then for any $\delta\in(0,1)$, we have
\begin{align*}
    X_t\leq \frac{a\alpha^2}{\delta}\left(1-\frac{1}{1+\alpha}\right)^t
\end{align*}
for all $t$ with probability at least $1-\delta$. 
\end{lemma}
% \begin{lemma}[Extension of \citet{rodomanov2021greedy}, Theorem 4.7]
% Consider the update schemes with
% \begin{align}
%     \x_{t+1}=\x_t-\G_t^{-1}\nabla f(\x_t),
% \end{align}
% where $\G_t\in\RB^{d\times d}\succ \0$. 
% If for all $t$ it holds with
% \begin{align}
%     \nabla^2 f(\x_{t+1})\preceq\G_{t+1}\preceq (1+Mr_t)^2\eta_t\nabla^2 f(\x_{t+1}),~~~r_t\leq\lambda_t,
% \end{align}
% and 
% \begin{align}
%     \lambda_{t+1} \leq \left(1-\eta_t\right)\lambda_t + c\lambda_t^2 +c_2\lambda_t^3.
% \end{align}

% \end{lemma}



\subsection{The Proof of Theorem~\ref{thm:srklinear}}
\begin{proof}
We denote $\lambda_t\triangleq\lambda(\x_t)\qquad\text{and}\qquad\tilde{\eta}_t \triangleq \min_{\nabla^2 f(\x_t)\preceq \eta\G_t}\eta$,
% \begin{align*}
% \lambda_t\triangleq\lambda(\x_t)\qquad\text{and}\qquad\tilde{\eta}_t \triangleq \min_{\nabla^2 f(\x_t)\preceq \eta\G_t}\eta,
% \end{align*}
which means 
\begin{align*}
   \nabla^2f(\x_t)\preceq \G_t\preceq \tilde{\eta}_t\nabla^2 f(\x_t).
\end{align*}
According to Lemma~\ref{lm:linear-quadra}, we have
\begin{align*}
        \lambda_{t+1}\leq \left(1-\frac{1}{\tilde{\eta_t}}\right)\lambda_t + \frac{M}{2}\lambda_t^2 + \frac{M^2}{4\tilde{\eta}_t}\lambda_t^3.
\end{align*}
According to Lemma~\ref{lm:strong_self}, we have
\begin{align*}
      \nabla^2 f(\x_{t+1})\preceq\tilde{\G}_t\preceq (1+Mr_t)^2\tilde{\eta}_t\nabla^2 f(\x_t).
\end{align*}
According to Lemma~\ref{lm:sr1good}, we have
\begin{align*}
    \nabla^2 f(\x_{t+1})\overset{\eqref{eq:srk_good}}{\preceq} \G_{t+1}\overset{\eqref{eq:srk_good}}{\preceq} (1+Mr_t)^2\tilde{\eta}_t\nabla^2 f(\x_{t+1})\overset{\eqref{eq:linear-quadra}}{\preceq} (1+M\lambda_t)^2\tilde{\eta}_t\nabla^2 f(\x_{t+1}),
\end{align*}
which means
\begin{align*}
    \tilde{\eta}_{t+1}\leq (1+M\lambda_t)^2\tilde{\eta}_t.
\end{align*}
Hence, the sequences $\{\tilde{\eta}_t\}$ and $\{\lambda_t\}$ satisfy the conditions of Lemma~\ref{lm:linear} with $m_1=m_2=M$, then we obtain 
\begin{align*}
   \nabla^2 f(\x_t)\preceq \tilde{\G_t} \preceq \frac{3\tilde{\eta}_0}{2}\nabla^2f(\x_t)\preceq\frac{3{\eta}_0}{2}\nabla^2 f(\x_t),
\end{align*}
and 
\begin{align*}
    \lambda(\x_t)\leq \left(1-\frac{1}{2\tilde{\eta}_0}\right)^t\lambda(\x_0)\leq\left(1-\frac{1}{2{\eta}_0}\right)^t\lambda(\x_0).
\end{align*}
\end{proof}

\subsection{The Proof of Theorem~\ref{thm:srk}}

 \begin{proof}
 
Denote 
$g_t={\tr{\G_{t}-\nabla^2 f(\x_t)}}/{\tr{\nabla^2 f(\x_t)}}$, 
$\delta_t=d\varkappa g_t$,    
$\lambda_t=\lambda(\x_t)$
and
$\EB_{t}[\,\cdot\,]\triangleq \EB[\,\cdot\,|\,\U_0,\cdots,\U_{t-1}]$.
From Theorem~\ref{thm:matrix}, we have
\begin{align}
\label{eq:srk_G-H}
    \EB_{t}\left[\tr{\G_{t+1}-\nabla^2 f(\x_{t+1})}\right] \leq \left(1-\frac{k}{d}\right) \tr{\tilde{\G}_{t}-\nabla^2f(\x_{t+1})}, 
\end{align}
From Lemma~\ref{lm:strong_self}, we have
\begin{align*}
    \EB_t[\tau_{\nabla^2f(\x_{t+1})}(\tilde{\G}_t)]\overset{\eqref{eq:delta_SRK_lin}}{\leq} (1+Mr_t)^2(g_t + 2Mr_t)\tr{\nabla^2f(\x_{t+1})},
\end{align*}
which means
\begin{align}
      \EB_{t}[\delta_{t+1}]\overset{\eqref{eq:linear-quadra},\,\eqref{eq:srk_G-H}}{\leq}\left(1-\frac{k}{d}\right)(1+M\lambda_t)^2(\delta_t+2\varkappa dM\lambda_t).
\end{align}
% Next, we prove 
% \begin{align}
% \label{eq:GtsucceqHt}
%     \G_{t}\succeq\nabla^2 f(\x_t)
% \end{align}
% by induction. \eqref{eq:GtsucceqHt} holds for $t=0$ by the initial condition. Suppose it holds for $t=0,\cdots,t'$, then for $t=t'+1$, according to Lemma~\ref{lm:strong_self}, we have $\tilde{\G}_{t'}\succeq\nabla^2 f(\x_{t'})$. Combining with Lemma~\ref{lm:sr1good}, we have
% \begin{align*}
%     \G_{t'+1}\overset{\eqref{eq:srk_good}}{\succeq}\nabla^2 f(\x_{t'+1}),
% \end{align*}
% which finishes the induction.
 The initial condition \eqref{eq:initial} means 
  the results of Theorem~\ref{thm:srklinear} hold, that is
 \begin{align}
 \label{eq:linearrate}
        \lambda_{t}\leq \left(1-\frac{1}{2\eta_0}\right)^{t}\lambda_0\qquad\text{and}\qquad\nabla^2 f(\x_t)\preceq\G_t.
 \end{align}
According to Lemma~\ref{lm:GHneq} and the definition of $\delta_t$, we have
\begin{align*}
    \nabla^2 f(\x_{t})\overset{\eqref{eq:linearrate}}{\preceq} \G_t \overset{\eqref{eq:GHneq}}{\preceq} (1+\delta_t)\nabla^2 f(\x_t).
\end{align*}
According to Lemma~\ref{lm:linear-quadra}, we have
 \begin{align*}
         \lambda_{t+1}
        & \overset{\eqref{eq:linear-quadra}}{\leq} \left(1-\frac{1}{1+\delta_t}\right)\lambda_t +\frac{M}{\eta_t}\lambda_t^2 + \frac{M^2}{4\eta_t}\lambda_t^3\\ 
        &\,\,\leq \left(1+\frac{M\lambda_t}{2}\right)\frac{\delta_t + {M\lambda_t}/{2}}{1+\delta_t}\lambda_t \\ &\,\,\leq\left(1+M\lambda_t\right)^2\left(\delta_t+\frac{M}{2} \lambda_t\right)\lambda_t.
 \end{align*}
According to Lemma \ref{lm:GHneq_2} and the initial condition \eqref{eq:initial}, we have
\begin{align}
    \delta_0=d\varkappa g_0\overset{\eqref{eq:GHneq_2}}{\leq}(\eta_0-1)d\varkappa~~~\text{and}~~~ \theta_0=\delta_0+2d\varkappa M\lambda_0\overset{\eqref{eq:initial}}{\leq} \eta_0 d\varkappa. 
\end{align}
Hence, the random sequences of $\{\lambda_t\}$ and $\{\delta_t\}$ satisfies the conditions of Lemma~\ref{lm:superlinear} with
 \begin{align*}
    m=M,\quad b=\frac{M}{2}, \quad c=2\varkappa dM, 
     \quad \alpha=\frac{d}{k}, \quad\beta=\frac{1}{2\eta_0}\quad \text{and}\quad s=\eta_0 d\varkappa,
 \end{align*}
which means we can obtain inequality \eqref{eq:E_lambda_srk}.


% \quad\quad  (a) randomized strategy: $\left[\U_{t}\right]_{ij}\overset{\rm{i.i.d}}{\sim}{\fN(0,1)}$ \\[0.15cm]



Now, we prove the two-stage convergence of  \srk~methods. 
\begin{enumerate}
\item For \srk~method with randomized strategy $\left[\U_{t}\right]_{ij}\overset{\rm{i.i.d}}{\sim}{\fN(0,1)}$, we apply Lemma~\ref{lm:randomsequence_lin} with $\alpha = d/k$ and $a=2d\varkappa\eta_0$ to obtain
 \begin{align}
 \label{eq:rasrk_super}
    \frac{ \lambda_{t+1}}{\lambda_t}  \leq \frac{2d^2\varkappa\eta_0}{k\delta}\left(1-\frac{k}{d+k}\right)^{t}
 \end{align}
holds for all $t$ with probability at least $1-\delta$. 
Take $t_0= \OM(d\ln(\eta_0\varkappa d)/k)$, which satisfies that
\begin{align}
\label{eq:rasrk_t0}
    \frac{2d^2\varkappa\eta_0}{k\delta}\left(1-\frac{k}{d+k}\right)^{t_0}\leq\frac{1}{2},
\end{align}
together with the linear rate \eqref{eq:srklinear}, we have
\begin{align*}
\begin{split}
    \lambda_{t+t_0} &\overset{\eqref{eq:rasrk_super}}{\leq} \left(1-\frac{k}{d+k}\right)^{t+t_0}2d\varkappa\eta_0d\lambda_{t+t_0-1} \\
    & \overset{\eqref{eq:rasrk_t0}}{\leq} \left(1-\frac{k}{d+k}\right)^{t}\frac{1}{2}\lambda_{t+t_0-1}\leq \cdots \overset{\eqref{eq:rasrk_super},\eqref{eq:rasrk_t0}}{\leq} \left(1-\frac{k}{d+k}\right)^{t(t-1)/2}\left(\frac{1}{2}\right)^{t}\lambda_{t_0}\\
    &\overset{\eqref{eq:srklinear}}{\leq} \left(1-\frac{k}{d+k}\right)^{t(t-1)/2}\left(\frac{1}{2}\right)^t\left(1-\frac{1}{2\eta_0}\right)^{t_0}\lambda_0.
\end{split}
\end{align*}

with probability at least $1-\delta$.

    \item 
For \srk~method with greedy strategy $\U_t=\E_k(\tilde{\G}_t-\nabla^2 f(\x_{t+1}))$, we choose $t_0=\OM\left(d\ln(\eta_0\varkappa d)/k\right)$ such that
\begin{align}
\label{eq:grsrk_t0}
    \left(1-\frac{k}{d}\right)^{t_0}2d\varkappa\eta_0\leq \frac{1}{2},
\end{align}
together with the linear rate \eqref{eq:srklinear}, we have
\begin{align*}
\begin{split}
    \lambda_{t+t_0} &\overset{\eqref{eq:E_lambda_srk}}{\leq} \left(1-\frac{k}{d}\right)^{t+t_0}2d\varkappa\eta_0d\lambda_{t+t_0-1} \\
    & \overset{\eqref{eq:grsrk_t0}}{\leq} \left(1-\frac{k}{d}\right)^{t}\frac{1}{2}\lambda_{t+t_0-1}\leq \cdots \overset{\eqref{eq:E_lambda_srk},\eqref{eq:grsrk_t0}}{\leq} \left(1-\frac{k}{d}\right)^{t(t-1)/2}\left(\frac{1}{2}\right)^{t}\lambda_{t_0}\\
    &\overset{\eqref{eq:srklinear}}{\leq} \left(1-\frac{k}{d}\right)^{t(t-1)/2}\left(\frac{1}{2}\right)^t\left(1-\frac{1}{2\eta_0}\right)^{t_0}\lambda_0.
\end{split}
\end{align*}

\end{enumerate}
 \end{proof}
 
 \subsection{The Proof of Corollary~\ref{cor:recoverNewton} }
 \begin{proof}
According to Theorem~\ref{thm:srk}, we have
\begin{align*}
    \BE[\tau_{\nabla^2 f(\x_{t+1})}(\G_{t+1})]\overset{\eqref{ieq:srk-matrix}}{=}0.
\end{align*}
According to Theorem~\ref{thm:srklinear} and Lemma~\ref{lm:GHneq}, we have
\begin{align}
\label{eq:k=dlambdaneq}
  \nabla^2f(\x_{t+1})\overset{\eqref{eq:srklinear}}{\preceq}  \G_{t+1}\preceq \underbrace{\left(1+\frac{d\varkappa\tau_{\nabla^2 f(\x_{t+1})}(\G_{t+1})}{\tr{\nabla^2 f(\x_{t+1})}}\right)}_{a_{t+1}}\nabla^2 f(\x_{t+1})~~~\text{and}~~~\lambda_{t+1}\leq \lambda_0
\end{align}
and $\EB[a_{t+1}]=1$.
According to Lemma~\ref{lm:linear-quadra}, we have
\begin{align}
\label{eq:k=dlambda}
    \lambda_{t+2}\leq \underbrace{\left(1-\frac{1}{a_{t+1}}\right)}_{b_{t+1}}\lambda_{t+1} + \frac{M}{2}\lambda_t^2 + \frac{M^2}{4(a_{t+1})}\lambda_{t+1}^3.
\end{align}
Then it holds that
\begin{align*}
   0\leq \EB[b_{t+1}]=1 -\EB[1/(a_{t+1})]{\leq} 1-1/\EB[a_{t+1}]= 0,
\end{align*}
where the first inequality comes from the fact that $a_{t+1}\geq 1$ and the second inequality comes from the fact 
$\EB[1/X]\geq 1/\EB[X]$ for positive random variable $X>0$ by using Jensen's inequality.
Hence, we have proved~$\EB[b_{t+1}]=0$, which means
\begin{align*}
    \EB[\lambda_{t+2}]\overset{\eqref{eq:k=dlambda}}{\leq} \frac{M}{2}\lambda_{t+1}^2+ \frac{M^2}{4}\lambda_{t+1}^3\overset{\eqref{eq:k=dlambdaneq}}{\leq}  \frac{M}{2}\lambda_{t+1}^2+ \frac{M}{2}\lambda_{t+1}^2(M\lambda_{0}/2)\overset{\eqref{eq:k=dinitial}}{\leq} M\lambda_{t+1}^2,
\end{align*}
for all $t\geq0$.
 
% \begin{align}
%     \EBP{}
% \end{align}
 \end{proof}



