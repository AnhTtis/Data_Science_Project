\subsection{Spatial Trees} \label{sec:bvh}
n-body problems encompass all problems where every data point needs to interact with all other {\em n} data points to calculate some result. Examples of n-body problems include (1) force-directed graph drawing algorithms such as Spring Embedders\cite{Eades1984AHF}, where repulsive forces between all pairs of vertices are used to find stable graph layouts, (2) cosmology simulations, where the gravitational force exerted by stars in a galaxy is modeled, and (3) k-nearest neighbors \cite{Altman1992AnIT}, where the distance between all points in the dataset is calculated to identify the k-nearest neighbors, to name a few. The naive approach to solving n-body problems is to loop over the {\em n} data points and compute the effects of interaction with the other $n-1$ data points in a doubly nested loop, leading to an algorithm with $O(n^2)$ time complexity.

Barnes-Hut\cite{barnes86a} improved the complexity by introducing a tree representation of input data points called Spatial Index Tree. They built the tree by recursively grouping nearby points using spatial subdivision. The individual points formed the leaves of the tree and internal nodes represented groupings that estimated the effect of the points contained in them. With this representation, instead of computing the effect of each point on {\em all} other points, we compute the effect of a {\em group} of points on other {\em individual} points. Using this spatial tree optimization, the time complexity of n-body problems reduced from $O(n^2)$ to {\em O(n log n)}.

\subsubsection{Bounding Volume Hierarchy}
The grouping of points can be done by either spatial (R-Trees, Oct-trees) or object-based subdivision of the dataset (Bounding Volume Hierarchies). Ray tracing applications rely on Bounding Volume Hierarchies (BVH) to reduce the number of ray-object intersection tests performed to determine the coloration of a pixel. Analysis of ray tracing execution times shows that about 70\% of the total time is spent testing for intersections for simple scenes, and upto 95\% for complex scenes \cite{fuji}. The authors also state that the main reason for these percentages is the {\em number} of intersection tests that need to be performed. 
%It is evident that reducing the number of tests would result in drastic performance improvements, and this is where Bounding Volume Hierarchies come into play.  

\subsubsection{BVH Build}
In the initial stage of the ray tracing algorithm, all objects in the scene are enclosed in bounding volumes. It is possible for the bounding volumes to overlap if the objects are sufficiently close. A {\em bounding volume} is a closed volume that completely encompasses one or more objects. We use Axis-Aligned Bounding Boxes (AABBs) as the bounding volumes. The BVH is built bottom-up, starting with the leaves. Bounding volumes containing individual objects in the scene are the leaf nodes of the tree. Fig~\ref{fig:bvh_img_a} shows objects {\em A, B, G, H, D} and {\em E} enclosed in rectangular (shown in 2D) bounding boxes and Fig~\ref{fig:bvh_img_b} shows the corresponding bounding boxes as leaves of the tree. The bounding volumes containing individual objects are then recursively grouped together to create larger bounding volumes, forming internal tree nodes {\em C, J, F} and {\em K}. This process continues until a single bounding box, {\em M}, encloses every intermediate and individual bounding volume. In Fig~\ref{fig:bvh_img_a}, intermediate bounding volume {\em C} encloses bounding volumes {\em A} and {\em B}, and {\em J} encloses {\em G} and {\em H}. {\em C} is combined with bounding volume {\em J} to create {\em K}, which is further combined with {\em F} to create {\em M}, which encloses the entire scene. The corresponding hierarchical relationship is captured in Fig~\ref{fig:bvh_img_b}, with {\em C} as the parent of {\em A} and {\em B}, {\em J} as the parent of {\em G} and {\em H}, {\em K} as the parent of {\em C} and {\em J}, and {\em M} being the parent of {\em K} and {\em F}. 
\begin{figure}
     \centering
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[scale=0.5]{figures/bvh_a.png}
         \vspace{-0.5em}
         \caption{2D rectangular bounding boxes for the objects and intermediate bounding volumes}
         \label{fig:bvh_img_a}
     \end{subfigure}    
     \hfill
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[scale=0.5]{figures/bvh_b.png}
         \vspace{-0.5em}
         \caption{Bounding Volume Hierarchy built from the bounding boxes in (a)}
         \label{fig:bvh_img_b}
     \end{subfigure}
     \caption{Bounding Volume Hierarchy Construction}
     \label{fig:bvh_img}
     \vspace{-0.5em}
\end{figure}



\subsection{Ray Tracing Cores}\label{sec:rtx}
%\vani{cuda kernels under the hood}
The addition of Ray Tracing (RT) cores to GPUs has enabled hardware-accelerated real-time ray tracing in gaming applications. These accelerators co-exist with the traditional Streaming Multi-processors (SMs), and the Optix API (Section~\ref{sec:optix-api}) allows us to write code that can leverage both RT and shader cores of the GPU. The RT cores\cite{whitepaper} accelerate Bounding Volume Hierarchy traversal and ray-triangle intersection tests, which are crucial and expensive elements of the ray tracing pipeline. 

\subsubsection{BVH Traversal}\label{sec:bvh-traversal}
Given objects in the scene, the RT cores intelligently\footnote{Details of the actual hardware internals are not publicly available} build a Bounding Volume Hierarchy, similar to the description in Section~\ref{sec:bvh}. The reduction in the number of intersection tests performed comes from pruning large parts of the search space by performing intersection tests on {\em bounding volumes} rather than individual objects. During BVH traversal, if a ray does not intersect a bounding volume, it {\em cannot} intersect any of the volumes contained in it and traversal does not continue down that subtree. In Fig~\ref{fig:bvh_img}, if a ray does not intersect bounding volume {\em K}, we need not test for intersection against {\em C}, {\em J}, {\em A}, {\em B}, {\em G} or {\em H}.

\subsubsection{Optix Programming Model}\label{sec:optix-api}
The Optix API \cite{prog-guide} allows users to write custom shader programs in CUDA (processed as a single CUDA kernel), in addition to offloading BVH build and traversal to RT cores. Both the shader and RT cores in GPUs use the same device memory and work can be done in parallel on the two cores. If the GPU does not have an RT core, Optix programs can still be run, with BVH build and traversal being performed in software. 

Optix\footnote{All Optix kernels are also present in OWL\cite{owl}} allows users to set up their scene by providing support for triangles, spheres and other user-defined geometries. Once the scene is set up, the user can define a bounding volume program to enclose objects in the scene. For geometries such as spheres, axis-aligned bounding boxes are typically used. The bounding volumes are recursively combined by the RT cores to build the BVH, as explained in Section~\ref{sec:bvh}. With the BVH constructed, we can now create rays and trace their interactions with objects in the scene by traversing the BVH and performing intersection tests.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/optix_api.png}
    %\caption{Optix API pipeline. Operations performed in hardware are shown in blue. For triangles, the Ray-object intersection test is also performed in hardware.}
    \caption{Optix pipeline. The components shaded in blue are performed in hardware and are not programmable. The unshaded components can be defined by the user. In the case where objects are triangles, the Intersection Test is also performed in hardware}
    \label{fig:optix_api}
    \vspace{-1.5em}
\end{figure}

As ray tracing is an {\em embarrassingly parallel} problem where the color of each pixel can be computed independently, Optix allows multiple rays to be launched in parallel as separate CUDA threads. 
%The number of rays launched is equal to the size of the frame buffer. Recall that ray tracing is used to determine the color of a pixel and the size of the frame buffer {\em is} the number of pixels. 
The components of the Optix pipeline are shown in Fig~\ref{fig:optix_api} and each ray executes the various stages in parallel. The {\tt RayGen} program generates parallel rays with the given origin ($\Vec{o}$) and direction ($\Vec{d}$). The user also needs to specify the ray interval $[t_{min}, t_{max}]$, which determines the extent of the ray:
\[\Vec{r} = \Vec{o} + t\Vec{d}, t \in [t_{min}, t_{max}]\]

The generated rays both traverse the BVH and test for intersection with bounding volumes in hardware (shown in blue in Fig~\ref{fig:optix_api}). When the ray reaches a {\em leaf} bounding volume enclosing an object, the ray-{\em object} intersection test is performed in software or hardware, depending on the object. If the object is a triangle, the test is performed in hardware. Otherwise, the user specifies the {\tt Intersection} program to be used for ray-object intersection testing. The user can optionally specify an {\tt AnyHit} program to record information about all the intersected objects and to determine whether to continue or terminate BVH traversal. Once the BVH traversal has completed, the user can optionally call the {\tt ClosestHit} program to identify the object closest to the ray along its path or the {\tt Miss} program to handle cases with no ray-object intersections.
%Both {\tt ClosestHit} and {\tt Miss} programs are typically used to determine pixel coloration. 

\subsection{Density-Based Clustering of Applications with Noise} \label{sec:dbscan}
Cluster analysis is an unsupervised learning technique used to identify patterns in a dataset. Clustering techniques are widely used to provide targeted advertising to customers with similar purchase histories, identify faulty machines, detect anomalous financial transactions, and so on. {\em k}-means \cite{kmeans}, a popular clustering technique due to its simplicity and scalability, picks {\em k} centroids and forms clusters based on whether other points in the dataset are within a permissible distance to the centroids. However, it requires that the user specify the number of clusters ({\em k}) to be formed and performs poorly when the dataset is noisy. Density-Based Clustering of Applications with Noise (DBSCAN) addresses the disadvantages of {\em k}-means, as it does not require the user to specify the number of clusters to be formed\cite{Ester96adensity-based}. It has the added advantages of being able to form clusters of varying shapes and being unperturbed by noisy datasets. 

The DBSCAN algorithm takes two parameters as inputs: $\varepsilon$ and {\em minPts}, where $\varepsilon$ is the maximum permissible distance between any two points in a cluster and {\em minPts} is the minimum number of points within the $\varepsilon$-neighborhood required to form a cluster. A point is said to be a {\em Core Point} if it has {\em minPts} neighbors within $\varepsilon$ distance. A {\em Border Point} is not a core point but is {\em reachable} from a core point and is a part of a cluster. Reachability comes in two forms: (1) {\em directly reachable}, where point y is within a distance $\varepsilon$ from core point x, and (2) {\em reachable}, where y is connected to core point x through one or more core points. A {\em Noise Point} is neither a core nor a border point.  
\begin{algorithm2e}
\caption{Original DBSCAN}\label{alg:dbscan}
\For{UNASSIGNED point p} {$Neighbors \gets FindNeighbors(p)$ \\
\eIf{$Neighbors.length < minPts$}
{
    $p \gets NOISE$ \\
}{
    $p \gets CLUSTER\_ID$ \\
    $NeighborSet \gets Neighbors - \{p\}$ \\
    \For{$neighbor \in NeighborSet$} 
    {
        \If{neighbor == UNASSIGNED $\|$ \\ neighbor == NOISE} 
        {
            $neighbor \gets CLUSTER\_ID$ 
            $NewNeighbors \gets FindNeighbors(neighbor)$ \\
            \If{$NewNeighbors.length \ge minPts$} 
                {$NeighborSet \gets NeighborSet \bigcup NewNeighbors$}
        }
    }
}
}
\end{algorithm2e}
%\vspace{-0.5em}

Algorithm~\ref{alg:dbscan} shows the original DBSCAN algorithm. Initially, all points are considered UNASSIGNED as they have not been assigned to a cluster yet. The {\em FindNeighbors(p)} function in Line 2 identifies all points within $\varepsilon$ distance of {\em p}. In lines 3-6, we classify the point as a Core point or a Noise point based on whether the $\varepsilon$ neighborhood of {\em p} has {\em minPts} points. If the point is a Core point, we examine each neighbor and assign it the same Cluster\_ID as the core point, as shown in Lines 9-11. If the neighbor has already been assigned a Cluster\_ID, we ignore the point and move on to the next neighbor. In lines 13-16, we call the {\em FindNeighbors} function on the {\em neighbors} of point {\em p}. If the neighbor is a Core point, we add it to the set of neighbors and repeat the process until all points have either been assigned to a cluster or classified as noise.