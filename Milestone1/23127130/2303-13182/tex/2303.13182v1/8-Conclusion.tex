\section{Conclusion}\label{sec:conc}
We present a novel contact-based grasp representation for a three-finger robotic dexterous hand and propose an end-to-end neural network (CMG-Net) to predict the grasp pose for unknown objects from only one single-shot point cloud in a cluttered environment. To train CMG-Net, we generate a large-scale synthetic dataset for three-finger grasps. We have compared CMG-Net against the state-of-the-art methods and observed 20\% performance improvements in success rate.

There are a few limitations in our work. We mainly consider the grasping for static and rigid objects. This may limit its applications, especially in household scenes.
Our approach requires the fingertips having contacts with the given object. However, in some grasps, this requirement may be not necessary.
In the future, we would like to investigate the grasping representation and prediction for dynamical and soft objects.
though it is much more difficult to formulate the problem.
We would like to extend our approach to handle arbitrary grasps (i.e., with or without fingertip contacts).

Moreover, other possible future work may incorporate the grasping network into robotic manipulation skills, achieving more complex tasks with multi-finger hand, e.g., assembling or house cleaning.
%