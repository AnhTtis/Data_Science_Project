
\section{Related Work}\label{sec:related}

Grasping is a fundamental problem for robotic manipulation and has been extensively studied. Most work focuses on parallel-jaw grippers \cite{DBLP:conf/cvpr/FangWGL20,jiang2011efficient,DBLP:conf/iccv/MousavianEF19,DBLP:conf/icra/MuraliMEPF20,DBLP:conf/icra/SundermeyerMTF21}  due to their simplicity, low DoFs, and computational efficiency. However, parallel-jaw grippers are less efficient and less reliable for manipulating arbitrary-shaped objects. To achieve user-friendly interaction, multi-finger robotic hands and dexterous grasping remain a hot research topic in the field of robotic manipulation~\cite{rimon2019mechanics}. This research can be briefly divided into two categories: the traditional analytical sampling-based method and the data-driven method.

\textbf{Traditional analytical sampling-based methods}\cite{ciocarlie2007dexterous,DBLP:conf/icra/GoldfederALP07,DBLP:conf/iros/HangSK14,DBLP:conf/icra/MillerKCA03,DBLP:conf/icra/PelossofMAJ04} sampled various grasp candidates and evaluated them based on certain metrics considering the physical properties of objects such as wrench space~\cite{DBLP:conf/icra/BorstFH04}. In general, both the object model and environment are assumed to be known in advance~\cite{DBLP:journals/ram/MillerA04}. Eigengrasp~\cite{ciocarlie2007dexterous} reduced the dimensions of grasp search space by performing principal component analysis (PCA) on grasping pose and configuration data. Although the reduction increases the efficiency of generating grasps, the search space of the random sampling process for grasps is still very huge. As a result, these sampling-based methods are less efficient in practical use.

\textbf{Data-driven methods} fall into one of two primary types.
The one is an extension of the traditional sampling-based method~\cite{DBLP:conf/iros/VarleyWWA15,DBLP:conf/icra/BorstFH04}. Instead of computing physical metrics, this method directly estimates grasp quality metrics from trained deep models. The grasp success rate can be greatly improved since traditional metrics cannot be computed accurately from an incomplete view of a novel object without any contact feedback. However, they are still dependent on known object models and exhibit the problem of huge sampling and search space.
%
The other data-driven method is performed in an end-to-end manner~\cite{DBLP:conf/iros/HangSK14,DBLP:conf/rss/LiuP0GM20,DBLP:journals/corr/abs-1908-04293,DBLP:conf/iros/LiuP0GM19,DBLP:conf/icra/KapplerBS15,DBLP:conf/iros/VarleyWWA15,mahler2017dex}. Specifically, this method takes the image or point cloud data of a grasped object as input and outputs a high-quality grasp. These approaches are able to effectively generate grasps and are robust to unknown objects. However, many can only handle a single object. Grasping may often fail due to the potential collision between the gripper and the environment.
%
Some recent work~\cite{DBLP:conf/icra/LiWL0LZ22,DBLP:conf/icra/LundellCLVWRMK21,DBLP:journals/corr/abs-2103-04783} predicts
collision-free \mbox{6-DoF} grasping in clutter using multi-finger grippers. They only classify the grasp types and do not take into account of the properties of multi-finger grasps. Our approach considers the gripper's physical structure and does not rely on the grasp types. Using a novel grasping representation and an end-to-end deep neural network based on contacts, our approach significantly reduces the search space for grasping and can generate reliable grasp poses.
