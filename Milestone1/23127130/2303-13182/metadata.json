{
    "arxiv_id": "2303.13182",
    "paper_title": "CMG-Net: An End-to-End Contact-Based Multi-Finger Dexterous Grasping Network",
    "authors": [
        "Mingze Wei",
        "Yaomin Huang",
        "Zhiyuan Xu",
        "Ning Liu",
        "Zhengping Che",
        "Xinyu Zhang",
        "Chaomin Shen",
        "Feifei Feng",
        "Chun Shan",
        "Jian Tang"
    ],
    "submission_date": "2023-03-23",
    "revised_dates": [
        "2023-03-24"
    ],
    "latest_version": 1,
    "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
    ],
    "abstract": "In this paper, we propose a novel representation for grasping using contacts between multi-finger robotic hands and objects to be manipulated. This representation significantly reduces the prediction dimensions and accelerates the learning process. We present an effective end-to-end network, CMG-Net, for grasping unknown objects in a cluttered environment by efficiently predicting multi-finger grasp poses and hand configurations from a single-shot point cloud. Moreover, we create a synthetic grasp dataset that consists of five thousand cluttered scenes, 80 object categories, and 20 million annotations. We perform a comprehensive empirical study and demonstrate the effectiveness of our grasping representation and CMG-Net. Our work significantly outperforms the state-of-the-art for three-finger robotic hands. We also demonstrate that the model trained using synthetic data performs very well for real robots.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.13182v1"
    ],
    "publication_venue": "The first two authors are with equal contributions. Paper accepted by ICRA 2023"
}