\chapter{Quality control}
\label{chap:QC}

After presenting some of the contents of our catalogue of bulge-disk decompositions, we now turn towards demonstrating its robustness. For this, we first compare to previous works in Section~\ref{sec:prevwork}, including work on the same galaxy sample. Section~\ref{sec:simulations} then describes additional internal consistency checks and a detailed study of biases and systematic errors with bespoke simulations. Both of these sections are taken from \citet[their sections~5 and~6]{Casura2022} and are focused on the fitting results of \texttt{v04} of the \texttt{BDDecomp} catalogue. This has the great advantage that duplicate images of the same galaxy were fitted independently and therefore this overlap sample can serve to identify systematic uncertainties. The \texttt{v05} results have been anchored to those of \texttt{v04} in Chapter~\ref{chap:results}, such that the quality control presented here is applicable to that version as well and we do not repeat the analysis for \texttt{v05}. Quality control metrics and diagnostic plots of individual steps of our pipeline, in particular for the preparatory work, have been presented in Section~\ref{sec:pipelinedevelopment}. 

\section{Comparison to previous works}
\label{sec:prevwork}

This section begins the quality control by comparing to previous works. We start with an overview of the catalogue statistics and colours to corresponding literature values; then turn towards a more detailed comparison with the results from \citet{Lange2015} and \citet{Kelvin2012}, who also use GAMA galaxies. In addition, comparisons to \texttt{v04} of our catalogue are provided in \citet[their figure~B2]{Haeussler2022} for the single S\'ersic and double component models and in \citet[their figures~19 and~20]{Robotham2022} for single S\'ersic fits, both finding reasonable agreement. 


\subsection{Comparison of catalogue statistics}

As a first check, we compare our model selection statistics to those of other bulge-disk decomposition works, although care must be taken in judging these results since they will depend on the sample selection, data quality and observational band. 

\renewcommand{\arraystretch}{1.5}
\begin{table}[t!]
	\centering
	\caption{Comparison of our \texttt{v04} catalogue statistics to previous works (in the $r$-band unless stated otherwise). All values are given in percent.}
	\label{tab:stats}
	\setlength{\tabcolsep}{3pt}
	\begin{tabu}{p{0.26\textwidth}cccp{.43\textwidth}} % number of columns, alignment for each
	    \hline
	    reference & single & double & unsuitable & notes
	    \\ 
	    \hline
	    this work & 47 & 23 & 30 & double including 1.5-comp.; unsuitable including masking (20\,\%)\\
	    \citet{DominguezSanchez2022} & 42 & 55 & 3 & unsuitable corresponding to fit failure, single including galaxies where both single and double fits were acceptable\\
	    \citet{Hashemizadeh2022} & 48 & 45 & 7 & $I$-band; classification by prior visual inspection; difficult objects excluded in sample selection; double S\'ersic fits\\ 
	    \citet{Robotham2022} & 68 & 31 & 1 & stellar mass instead of light; simultaneous nine-band plus SED fit; unsuitable meaning fit failure; lower redshift limit \\
	    \citet{Barsanti2021} & 47 & 28 & 25 & cluster S0 galaxies\\
	    \citet{Dimauro2018} & 27 & 63 & 10 & mostly NIR filters; bright and massive galaxies only ($\log_{10}(M_*/M_\odot)$\,>\,10.3)\\
	    \citet{Lange2016} & 66 & 16 & 18 & selection based on visual morphology; unsuitable counting all flagged galaxies\\
	    \citet{Meert2015} & 44 & 39 & 17 & larger sample up to higher redshift but smaller magnitude range\\
	    \citet{Head2014} & 19 & 35 & 46 & $g$-band; early-type sample; more stringent criteria for ``good" fits\\
	    \citet{Lackner2012} & 35 & 29 & 36 & single corresponding to pure exponential or de Vaucouleurs; unsuitable corresponding to their ``S\'ersic" category\\
	    \citet{Simard2011} & 73 & 26 & 1 & unsuitable corresponding to failure rate of fitting routine; no selection of ``good" fits given\\
	    \citet{Allen2006} & 43 & 34 & 23 & $B$-band; unsuitable galaxies excluded through cuts in redshift, galaxy size and surface brightness \\
	    \hline	   
	\end{tabu}
 \end{table}
 \renewcommand{\arraystretch}{1}


Table~\ref{tab:stats} summarises the corresponding percentages including a few notes on the most important differences of the quoted works to ours (more details on the majority of these studies are given in Section~\ref{sec:prevcols}). In short, for the automated decomposition of large samples of galaxies in the $r$-band, most authors - including ourselves - class roughly half of all galaxies as being well-represented by a single S\'ersic model, with the other half split approximately evenly into double component fits and objects unsuitable for fitting with such simple models. This is also in broad agreement with the morphological classifications obtained by \citet{Driver2022}. 

\subsection{Comparison of component colours to literature}
\label{sec:prevcols}

$g-r$ colours of galaxy components, such as those we present in Figure~\ref{fig:colourplots} and Section~\ref{sec:colours}, are not found frequently in the literature, although a number of authors have presented bulge-disk decompositions in several bands. For example, \citet{Simard2011} perform bulge-disk decompositions for a large sample of galaxies in the SDSS $g$ and $r$ bands but only present colour-magnitude diagrams for the total galaxies (their figures 9 and 10). These are visually comparable to our total galaxy colours as indicated by the dot-dashed green contours in the right panel of Figure~\ref{fig:colourplots}. \citet{Mendel2014} add the SDSS $u$, $i$ and $z$ bands to the analysis of \citet{Simard2011} and present component masses in $ugriz$ but also do not study component colours. 

Similarly, \citet{Meert2015} present a large $r$-band catalogue which is extended to include the $g$ and $i$ bands in \citet{Meert2016}. Colour-magnitude diagrams, however, are again only presented for total galaxies, with the authors noting that component colours can be calculated from their catalogue but should be used with care since they are subject to large uncertainites. 

More recently, \citet{Dimauro2018} provide (UVJ) component colours in their catalogue but defer their study to future work; while \citet{Bottrell2019} present $ugriz$ colour-magnitude diagrams for total galaxies (colour-coded by B/T); but again not for individual components. \citet{DominguezSanchez2022} decompose a sample of $\sim$\,10\,000 galaxies in the $g, r$ and $i$ bands, but do not study the colours. %\\


Among the first to show component colours for a large sample of galaxies were \citet{Lackner2012} in their study of $\sim$\,70\,000 $z$\,<\,0.05 SDSS galaxies in the $g$, $r$ and $i$ bands. However, in contrast to our fits, their $g$ and $i$ band fits are not independent. Instead, in order to decrease the noisyness of the colours, the structural parameters are taken from the $r$-band and only the magnitude is adjusted. Additionally, \citet{Lackner2012} (along with e.g. \citealt{Mendel2014}) fix the S\'ersic index of the bulge to either 1 or 4 for their double component fits to limit the number of free parameters since the data is insufficient to constrain the bulge light profile. Keeping these differences in mind, their figure~32 showing the $g-r$ vs. $M_r$ colour-magnitude diagram for bulges and disks as contours superimposed on the greyscale background for all galaxies can be compared to the right panel of our Figure~\ref{fig:colourplots} (for a more detailed description of Figure~\ref{fig:colourplots}, see Section~\ref{sec:colours}). In general, both plots are very similar\footnote{For reference, the \citet{Lackner2012} cyan contours represent 6684 galaxies with a bulge S\'ersic index of 1 and the magenta contours show 14042 objects with a bulge S\'ersic index of 4. Also note that their $x$-axis is reversed with respect to ours.}: the grey background shows a large blue cloud and a well-separated red sequence. The double component fits populate the red sequence, green valley and the brighter part of the blue cloud. The bulges tend to be slightly redder than the red sequence but with a large scatter especially at the faint end. Disks spread from the red sequence towards the green valley with a smaller population also in the blue cloud. \citet{Lackner2012} also note the large scatter in colour for bulges in particular, despite their fitting constraints and lower reshift limit. Hence it is not surprising that even with the higher quality KiDS data and our new fitting routines, we get a large scatter in component colours, especially since we leave the bulge S\'ersic index free and perform independent fits in both bands. The latter can lead to very extreme colours since it is not guaranteed that the ``bulge" and ``disk" models actually fit the same features in both images (in particular when there are additional features present that are not fully captured by the models; see also Section~\ref{sec:colours}). 

\citet{Kim2016} found similar difficulties when performing $g$-band and $r$-band decompositions on $\sim$\,10\,000 large bright and approximately face-on SDSS galaxies. While they leave the S\'ersic index free as we do, the $g$-band structural parameters are again taken from the $r$-band fits with only the magnitudes adjusted. Despite this, they find it necessary to remove almost 40\,\% of their sample after fitting because they show excessively red bulge colours (combined with low B/T values in the $r$-band). After this cut, the $g-r$ vs. $M_r$ colour-magnitude diagram for bulges shown in their figure 7 is slightly less noisy than ours (Figure~\ref{fig:colourplots}), although still comparable. \citet{Kim2016} did not study the properties of the disks in their sample. 

One of the most direct comparisons to make is with \citet{Kennedy2016} who study GAMA galaxies in the G09 region (a subset of our sample) in the $ugrizYJHK$ bands from the SDSS \citep{York2000} and the United Kingdom Infra-red Telescope Infrared Deep Sky Survey (UKIDSS, \citealt{Lawrence2007}). They use the \texttt{MEGAMORPH} multi-band fitting method with \texttt{GALAPAGOS-2} and \texttt{GALFITM} \citep{Haeussler2013, Vika2013} to perform simultaneous S\'ersic plus exponential fits across all 9 bands. The structural parameters are constrained to be the same in all bands, with only the component magnitudes allowed to vary freely, therefore providing robust colours. While the paper focuses on studying $u-r$ colours, the corresponding catalogue on the GAMA database (\texttt{MegaMorph:MegaMorphCatv01}) contains the information for the fits in all 9 bands such that $g-r$ colours can easily be derived. 

This comparison is shown in Figure~\ref{fig:colourvskennedy} for those galaxies that were present in both catalogues and classified as double component fits (\texttt{NCOMP}\,=\,2) in the joint model selection of our fits (\citealt{Kennedy2016} perform neither model selection nor outlier rejection). In addition to the scatter plot directly comparing the component colours, we show the corresponding distributions in the left (this work) and top \citep{Kennedy2016} panels of Figure~\ref{fig:colourvskennedy}. As always, bulges are shown in red (points and dotted lines) and disks in blue (points and dashed lines). To aid the direct comparison of the distributions, we additionally show the \citet{Kennedy2016} bulge colour distribution in the left panel as a solid orange line and the disk distribution from this work in the top panel as a light blue solid line. Component colours are all corrected for Galactic extinction and limited to segment radii for our fits. % note for Kennedy, limiting to segment radii does not change anything since their structural parameters are fixed across bands and we're taking a difference between bands (= colour) here... for our results, it changes very little, I just do it for consistency with remaining paper. 

\begin{figure}[t!]
\begin{center}
    \includegraphics[width=0.8\textwidth]{plots/colourvskennedy}
    \caption{Our Galactic extinction-corrected $g-r$ component colours (limited to segment radii) compared against those from \citet{Kennedy2016} for a subsample of 390 objects that appear in both catalogues and were classified as double component fits in the joint \texttt{v04} model selection. The scatter plot shows the direct comparison, while the density plots show the respective distributions in both catalogues (ours on the left, \citealt{Kennedy2016} on the top). Bulges are again shown in red with dotted lines and disks in blue with dashed lines. To aid the direct comparison of the distributions, the lighter solid lines also show the \citet{Kennedy2016} bulge distribution on the left and our disk distribution on the top.}	
    \label{fig:colourvskennedy}
\end{center}
\end{figure}

Despite the large scatter, it can be seen that our component colours are generally in agreement with those from \citet{Kennedy2016} with no systematic differences. The scatter in both catalogues is also comparable, although \citet{Kennedy2016} perform multi-band simultaneous fits with fixed structural parameters that should lead to more robust component colours. This advantage of their work seems to be balanced by advantages of our work, such as the improved data quality of KiDS, the robustness of the fitting procedure with \texttt{ProFound} and \texttt{ProFit} and our post-processing steps (in particular outlier rejection and model selection). %\\

In addition to the large $g-r$ component colour studies discussed above, there are a number of publications focusing on the $g-i$ colours of bulges and disks for samples ranging between $\sim$\,100 and $\sim$\,1000 objects (i.e. roughly a factor of 10 smaller than ours), namely \citet{Gadotti2009, Head2014, Vika2014, Fernandez-Lorenzo2014, Cook2019, Barsanti2021}. We briefly compare our work to their results here, noting that all above authors have more stringent constraints on their fits than we do and also report problems in deriving bulge colours. For example, \citet{Fernandez-Lorenzo2014}, although they fit the galaxies in both bands, use fixed aperture photometry to derive more stable bulge colours. \citet{Vika2014}, while performing \emph{simultaneous} multi-band fits, do not allow for any variation of structural parameters (except magnitudes) with wavelength. \citet{Head2014}, in addition to varying magnitudes, allow for a trend in disk sizes with wavelength in approximately 30\,\% of their sample, noting that this leads to increased scatter. \citet{Cook2019}, who use \texttt{ProFit} like this work, allow disks to deviate slightly from the exponential profile but fix all bulges to be exactly round (axial ratio of 1), again only allow magnitudes and disk sizes to vary between bands and employ a sophisticated, visually-guided re-fitting procedure to obtain physically meaningful fits for ``difficult" objects. \citet{Barsanti2021}, also employing \texttt{ProFit}, additionally allow for differing bulge sizes and S\'ersic indices in the different bands (but fixing bulge and disk axial ratios and position angles and performing model selection in the $r$-band only), but class approximately half of their double component fits as ``unreliable". \citet{Gadotti2009}, fitting bulges, bars and disks to a sample of face-on, visually-selected ``well-behaved" galaxies refrain from automated fitting and instead treat each galaxy individually. 

After these notes on the inherent difficulties associated with deriving component colours, we can now turn to the corresponding results: \citet{Head2014}, in their study of early-type red-sequence galaxies in the Coma cluster, measure an average $g-i$ difference between bulges and disks of 0.09\,$\pm$\,0.01\,mag. Similarly, \citet{Barsanti2021} find a bulge-disk $g-i$ difference of 0.11\,$\pm$\,0.02\,mag for their sample of S0 cluster galaxies. \citet{Fernandez-Lorenzo2014}, on the other hand, have a sample of mostly late-type spirals (with B/T\,<\,0.1 for $\sim$\,66\,\% of their objects) and find a difference of 0.29\,mag in the median $g-i$ bulge and disk colours, i.e. a factor of $\sim$\,3 larger. In line with this, \citet{Vika2014} report that the bulge and disk colours are similar for early-type galaxies but differ significantly for late-types. The $g-i$ differences for the different morphological classes given in their table 2 range from 0.03\,$\pm$\,0.04\,mag for ellipticals to 0.28\,$\pm$\,0.06\,mag for late-type spirals; with the overall average (comprising approximately two thirds late-types) being 0.19\,$\pm$\,0.04\,mag. Similarly, the average $g-i$ colour difference of the \citet{Gadotti2009} sample of varying galaxy types amounts to 0.18\,$\pm$\,0.04\,mag (from the online-version of their table~2). 

Our results are perfectly in line with this: the median bulge-disk $g-i$ colour difference for our 1.5- or double component fits is 0.17\,$\pm$\,0.01\,mag, consistent with the \citet{Vika2014} and \citet{Gadotti2009} results. Limiting to objects with a total $g-i$\,>\,1 (red-sequence galaxies) reduces the value to 0.14\,$\pm$\,0.01\,mag; while focusing on 2-component fits only (excluding 1.5-component fits) yields 0.10\,$\pm$\,0.02\,mag, in agreement with \citet{Head2014} and \citet{Barsanti2021}. This is because our double component galaxies lie predominantly on the red sequence, as can be seen in Figure~\ref{fig:colourplots}. 1.5-component fits on the other hand, have very small (namely unresolved) bulges by definition and hence belong to the class of late-type spirals. In fact, 87\,\% of the 1.5-component objects have a ($g$-band) B/T ratio less than 0.1, with the median value as low as 0.02. Computing the bulge-disk $g-i$ colour difference for this sample of objects yields a value of 0.46\,$\pm$\,0.02\,mag, suggesting that the trend described in \citet{Vika2014} continues at very low B/T. %\\


From all of these comparisons we conclude that our component colours - although noisy - are in line with previous work. In order to increase the colour robustness while preserving the ability to capture physical trends with wavelength (i.e. not fixing the structural parameters to be the same in all bands), a simultaneous fit in all bands is needed. This has many advantages as shown by the \texttt{MEGAMORPH} project team using \texttt{GALAPAGOS} and \texttt{GALFITM} \citep{Haeussler2013, Vika2013, Haeussler2022}, especially for automated analyses, since it naturally ensures smooth wavelength trends while preserving physical variation and additionally allows more robust fits to fainter magnitudes. With \texttt{ProFit} v2.0.0, released in February 2021, now supporting a multi-band fitting mode - and the newly developed package \texttt{ProFuse} \citep{Robotham2022} even combining this with a spectral analysis - this is certainly an interesting avenue to explore in future work and could provide a valuable alternative. It would also solve some of the other challenges we faced during the individual fits, as we discuss in Sections~\ref{sec:jointfitting}, ~\ref{sec:manualcalibrationchanges} and~\ref{sec:outlierstats}. 
  



\subsection{Comparison to size-stellar mass relations of \citet{Lange2015}}
\label{sec:sizemass}


\begin{figure}
    \includegraphics[width=0.5\textwidth]{plots/sizemass}
    \includegraphics[width=0.5\textwidth]{plots/sizemassseg}
    \caption{The size-stellar mass relation for our $r$-band fits (dots) compared to the \citet{Lange2015} fits (lines). The sizes are obtained from our single S\'ersic effective radii (\textbf{left panel}: ex\-tra\-po\-la\-ted to infinity; \textbf{right panel}: limited to segment radii) and the distance moduli provided in the \texttt{DistancesFrames} catalogue originally described by \citet{Baldry2012}. The stellar masses are taken from the most recent version of the \texttt{StellarMasses} catalogue initially presented in \citet{Taylor2011}. The sample is limited to the redshift range 0.0001\,<\,$z$\,<\,0.06 (redshifts also from \texttt{DistancesFrames}) and the stellar mass range $M_*$\,>\,$10^9$\,$M_\odot$. Large circles with error bars indicate the running median with its error (usually smaller than the data point). Solid lines show the single exponential $M_*-R_e$ relation fits obtained by \citet{Lange2015} for their single component $r$-band sample, split by a S\'ersic index cut at $n$\,=\,2.5 (taken from their tables~2 and 3).}	
    \label{fig:sizemass}
\end{figure}

Figure \ref{fig:sizemass} shows the size-stellar mass relation obtained from our $r$-band single S\'ersic fits in combination with the redshifts and distance moduli of v14 of the \texttt{DistancesFrames} catalogue \citep{Baldry2012} and v19 of the \texttt{StellarMasses} catalogue \citep{Taylor2011}; both from the GAMA database. The aperture-derived stellar masses have been scaled to match the S\'ersic total flux using the \texttt{fluxscale} keyword provided in the \texttt{StellarMasses} catalogue. The $g$-band and $i$-band results are very similar to those from the $r$-band so we do not show them. 

The sample is limited to objects which were not flagged during our outlier rejection (Section~\ref{sec:postprocessing}) and split into early- and late-type galaxies according to our fitted S\'ersic index ($n\lessgtr2.5$; analogous to \citealt{Lange2015}). We also limit the redshift range to 0.0001\,<\,$z$\,<\,0.06 and the stellar mass range to $M_*$\,>\,$10^9$\,$M_\odot$, thus avoiding the need for volume corrections. For comparison, we show the $M_*-R_e$ relations obtained by \citet{Lange2015} by fitting a single power law to the single component $r$-band fits of \citet{Kelvin2012} (pre-release of \texttt{SersicPhotometry:SersicCatSDSSv09}) combined with an earlier version of the stellar masses catalogue of \citet{Taylor2011} (\texttt{StellarMasses:StellarMassesv16}). We note that the stellar masses did not change much between v16 and v19: the mean and standard deviation of $\Delta\log_{10}(M_*/M_\odot)$ are 0.006 and 0.07 respectively for our sample. The two panels show the results obtained with effective radii taken directly from the S\'ersic fits (left; extrapolated to infinity by definition) or limited to the segment radius within which they were fitted (right; see Section~\ref{sec:postprocessing}). To guide the eye, we also show the running median and its error for our data; where the error is taken as the 1$\sigma$-quantile divided by the square-root of data points within that bin (usually smaller than the size of the data points). 

In both cases, the slope of the mass-size relation obtained from our data agrees well with the \citet{Lange2015} fit results.\footnote{For reference, the slopes of the plotted lines are 0.21 and 0.44 for the late- and early-types respectively; taken from tables~2 and~3 of \citet{Lange2015}).} There is an offset in the absolute sizes, but those will inherently depend on the exact definition of the size measurement at hand as well as the (depth of the) data used. Already calculating effective radii within the segments within which we fitted for them (right panel) brings our results much closer to those of \citet{Lange2015}; although the measurements are then not directly comparable to their fits anymore since they use S\'ersic values extrapolated to infinity (which will, in turn, depend on the segment size used for fitting). We now discuss these issues further by directly comparing our fits to those of \citet{Kelvin2012}, which the \citet{Lange2015} results were based on. 


\subsection{Comparison to single S\'ersic fits of \citet{Kelvin2012}}
\label{sec:comparelee} 

\begin{figure}
    \includegraphics[width=0.5\textwidth]{plots/comparelee}
	\includegraphics[width=0.5\textwidth]{plots/compareleeseg}
    \caption{The difference $\Delta$ or quotient Q (for scale parameters) between the \citet{Kelvin2012} fits and our fits plotted against our fits for the three most important single-S\'ersic parameters magnitude, effective radius and S\'ersic index in the $r$-band. The top panels show the S\'ersic parameters extrapolated to infinity, while for the bottom panels we calculated the magnitude and radius within the segment radius for both our and the \citet{Kelvin2012} fits. Outliers are clipped to the plotting interval; which is the same in both cases. Black dots show all fits, red dots with error bars show the running median and its error in evenly spaced bins and horizontal blue lines indicate no difference between the fits. The numbers in the top left corners of the first row of panels show the median and 1$\sigma$-quantile of the respective distribution in the $y$-direction (which is identical for all panels of a row). The sample is limited to fits that are available in the \citet{Kelvin2012} catalogue and were classified as single component in our model selection.}	
    \label{fig:comparelee}
\end{figure}

To further investigate the size offset observed in Section~\ref{sec:sizemass}, we directly compared our fits to those of \citet{Kelvin2012} (\texttt{SersicPhotometry:SersicCatSDSSv09} on the GAMA database). Since \citet{Kelvin2012} do not provide double component fits, the analysis is limited to single S\'ersic fits. We again use the $r$-band as an example for the discussion, but note that results are very similar for the $g$ and $i$ bands. 

The \citet{Kelvin2012} fits are based on the Structural Investigation of Galaxies via Model Analysis (\texttt{SIGMA}) code applied to data from SDSS DR7. \texttt{SIGMA} is a wrapper around \texttt{Source Extractor} \citep{Bertin1996}, \texttt{PSF Extractor} \citep{Bertin2011} and \texttt{GALFIT 3} \citep{Peng2010} performing similar steps to what we do in our pipeline (Section~\ref{sec:pipelineoverview}), i.e. source identification, background subtraction, PSF estimation and 2D model fits to the surface brightness profile of the galaxies. The differences lie in the data and code used, where we upgrade SDSS to KiDS, \texttt{Source Extractor} to \texttt{ProFound}, \texttt{PSF Extractor} to a combination of \texttt{ProFound} and \texttt{ProFit} and \texttt{GALFIT} to \texttt{ProFit}; with all the advantages described in Sections~\ref{sec:kids}, \ref{sec:profit} and \ref{sec:profound}. In addition, we also perform multi-component fits and model selection. For the comparison to the \citet{Kelvin2012} results, we focus on the three most important single S\'ersic fit parameters: magnitude $m$, S\'ersic index $n$ and effective radius $R_e$, which tend to be the least ``well-behaved" (position, axial ratio and angle are generally more easily constrained and uncorrelated, see e.g. Figure~\ref{fig:resultsv04vsv05_R_S} in Section~\ref{sec:v05parameterdistributions}). 

Figure~\ref{fig:comparelee} shows the difference between our fits and the \citet{Kelvin2012} fits for these three parameters. In line with Figures~\ref{fig:resultsv04vsv05_R_S} to~\ref{fig:resultsv04vsv05_R_D_SEGRAD}, we show the difference in magnitudes (\citet{Kelvin2012} fits - our fits), while for the effective radius and S\'ersic index (scale parameters) we show the quotient (\citet{Kelvin2012} fits / our fits) on the $y$-axis; always plotted against our fitted values on the $x$-axis (in logarithmic space for scale parameters). Again, we show the results for S\'ersic parameters extrapolated to infinity (left panels) and for the magnitude and effective radii calculated within the segment radius (right panels), where we limit both our fits and those of \citet{Kelvin2012} to our fitting segment (which are generally smaller than the fitting regions used in \citet{Kelvin2012}) to obtain directly comparable results. %\\

For the S\'ersic parameters extrapolated to infinity (left panels), large differences can be seen in all fitted parameters, including systematic trends across the parameter space. Note the larger axis range relative to Figures~\ref{fig:resultsv04vsv05_R_S} to~\ref{fig:resultsv04vsv05_R_D_SEGRAD}. This shows once again that fitted S\'ersic parameters are not directly comparable given the differences in the data, code and processing steps with a wealth of potentially different systematic uncertainties (Section~\ref{sec:postprocessing}). However, when we limit the analysis to our segment sizes (bottom panels), the fits become much more comparable. On average, now, our fits are $\sim$\,0.03\,mag brighter and approximately 7\,\% larger than the \citet{Kelvin2012} fits to the same galaxies, which is not surprising given the increased depth and resolution of KiDS compared to SDSS and the numerous sources of different systematic uncertainties (e.g., differing sky subtraction and PSF estimation). Also, there are fewer trends across the parameter space, indicating that systematic differences arise mainly from the extrapolation to infinity. 

The exception to this is the S\'ersic index, which still shows some trends. The reason is that the S\'ersic index, unlike the magnitude and effective radius, cannot be corrected for different fitting regions. The \citet{Kelvin2012} fits, which were performed within larger fitting regions than our fits, will inevitably have to compromise more between the inner and outer regions of the galaxy to be fitted (unless the light profile truly follows a single S\'ersic profile with no deviations out to very large radii, which is rarely the case). Our tight fitting segments, on the other hand, will result in better fits to the inner regions of the galaxy at the expense of producing unphysical wings when extrapolated beyond the fitting segment (Section~\ref{sec:postprocessing}). Thus, fitted S\'ersic indices are always a weighted average (or compromise) across a range of radii and their absolute values will never be directly comparable between catalogues unless the fitting regions are exactly the same (or the galaxies studied follow perfect S\'ersic profiles). 








\section{Systematic uncertainties and biases}
\label{sec:simulations}

The MCMC chain errors returned by the fitting procedure do not include systematic uncertainties which arise due to galaxy features not accounted for in the models, nearby other objects, imperfect PSF estimation, background subtraction inaccuracies and similar effects. For an individual galaxy, the presence of such ``features" will systematically shift the fitted parameters away from the true values, thus introducing a bias. For a statistically large enough sample of galaxies, however, most of these effects are expected to cancel out on average since they are random from one galaxy to the next (e.g. nearby other sources shifting the fitted positions). These ``random systematics" can - for statistical samples - be accounted for by simply increasing the given parameter errors such that in most cases, the true values are included in the credible intervals again. Such systematics can be studied using overlap sample galaxies, i.e. those that appeared in more than one KiDS tile (cf. Section~\ref{sec:sampleselection}). In addition, there can be ``one-sided effects" that lead to an overall bias across the sample, e.g. due to excess flux from nearby objects. These can only be detected using simulations. In the following, we study both of these effects using our bespoke simulations, the overlap sample of real galaxies and the overlap sample of simulated galaxies; where we refer to the random systematics as ``error underestimates" and to the one-sided effects as ``biases". 

The final corrections for both of these effects are listed in Table~\ref{tab:errorunderestimate}. In short, biases are very small ($\lesssim$\,1\,\%), while systematic errors are a factor of 2-3 larger than the random MCMC errors alone. The error underestimate corrections are also applied to the released catalogues (for \texttt{v04} and \texttt{v05}), while the bias corrections are not since they are only valid for a large random subset of our galaxies and not for individual objects. Note that the systematic error studies were carried out on results from \texttt{v03} of the \texttt{BDDecomp} DMU, while the remainder of this chapter refers to \texttt{v04}. However, since \texttt{v04} is statistically identical to \texttt{v03} (see Section~\ref{sec:v04}), the results can directly be transferred. We would also like to point out that we focus on single S\'ersic $r$-band fits in this section. We expect individual components in the 1.5- and double component fits as well as the other bands to be affected by similar systematics. Effects are likely to become worse for fainter and/or less well-resolved objects (i.e. bulges in particular; and objects in the KiDS $u$ and the longer wavelength VIKING bands). 





\subsection{Overlap sample comparison}
\label{sec:overlapstudies}

\begin{figure}
    \includegraphics[width=0.5\textwidth]{plots/compareoverlap}
    \includegraphics[width=0.5\textwidth]{plots/compareoverlapseg}
    \caption{Similar to Figure~\ref{fig:comparelee} but now showing an internal consistency check of our catalogue using galaxies that were imaged (and successfully fitted) at least twice in the KiDS $r$-band. We pass these duplicate observations of the same physical objects through our pipeline independently and then compare the fit to the shallower image with the fit to the deeper (higher signal-to-noise ratio) image. Note the different plotting ranges relative to Figure~\ref{fig:comparelee} (especially on the $y$-axis).}	
    \label{fig:compareoverlap}
\end{figure}
As an internal consistency check, we compared the fit results obtained from multiple observations of the same physical object (Section~\ref{sec:sampleselection}) in Figure~\ref{fig:compareoverlap}. The plots are very similar to the ones in Figure~\ref{fig:comparelee} (see description in Section~\ref{sec:comparelee}; but note the different $y$-axis scale), except that we now show the differences between two of our own fits to different KiDS images of the same galaxy (in the overlap region between the KiDS tiles). Hence all fits shown in Figure~\ref{fig:compareoverlap} are based on KiDS data and use the exact same pipeline for analysis, though the different observations are treated entirely independently. We always use the deeper image as the reference image (the image depth at the edge of KiDS tiles can vary greatly depending on the number of dithers - between 1 and 5 - that cover the area). For the right set of panels, we evaluate the magnitude and effective radius within whichever of the two segment radii is smaller to avoid extrapolation and obtain consistent results. 

For both versions (S\'ersic parameters extrapolated to infinity on the left and truncated to segment radii on the right), there are very little differences between the two fits to the same galaxy; and there are no systematic trends across the parameter space. The running median is consistent with 0 (or 1, for scale parameters) in almost all bins, which shows that there are no inherent systematic differences in our fits related to image depth. This holds true despite the segments being systematically larger for the deeper images. The difference in segment size is too small on average to detect systematic trends across the entire sample: the median difference between the two segment radii is only 6\,\%. However, there are a number of outliers visible as rows of points at the top and bottom of the panels since they were clipped to the plotting intervals (for plotting only). These correspond to the fits where the segment sizes differ substantially. Evaluating both fits within the same region before comparison (right panels) removes those outliers and reduces the overall scatter. 


\subsection{Simulations: parameter recovery}
\label{sec:parameterrecovery}

As a final test of our pipeline, we ran simulations where we insert single S\'ersic model galaxies convolved with an appropriate PSF at random locations in the KiDS data. To obtain a realistic distribution of parameters for the model galaxies (including correlations), we use the fitted single S\'ersic parameters of a random sample of 1000 $r$-band galaxies that were not classified as outliers. The PSF to convolve with is taken as the model PSF that was fitted to the nearest real galaxy (at the position where the model galaxy is inserted), which is close to the real PSF at that image location. We then simply add the PSF-convolved galaxy to the KiDS data and run the resulting image through our entire pipeline (segmentation, sky subtraction, PSF estimation, galaxy fitting, outlier flagging, model selection). 

In this way we are able to check for intrinsic biases in our entire pipleline, with 3 exceptions: issues due to galaxy features not represented by our models (bars, spiral arms, disk breaks, mergers, etc.), problems in the data processing performed by the KiDS team (if any), and deviations of the true PSF from a Moffat function.%\\


\begin{figure}
    \includegraphics[width=0.5\textwidth]{plots/comparesimulations}
    \includegraphics[width=0.5\textwidth]{plots/comparesimulationsseg}
    \caption{Similar to Figure~\ref{fig:compareoverlap} but comparing the fitted parameters of simulated images to the true (input) parameters; both limited to segment radii for the right set of panels.}	
    \label{fig:comparesimulations}
\end{figure}

In Figure~\ref{fig:comparesimulations} we show the corresponding plots to Figures~\ref{fig:comparelee}~and~\ref{fig:compareoverlap}; where on the $x$-axis we now have the true (input) parameters of our simulated galaxies and on the $y$-axis the difference between the fitted and the true values; both limited to segment radii for the right set of panels. 

Generally, all parameters are recovered well, although for both versions of the plot the magnitudes show a slight offset of $\sim$\,0.01\,mag (with corresponding trends in effective radius and S\'ersic index since these parameters are correlated); worsening for faint objects. This offset is driven by a number of galaxies scattering to very low values, i.e. where the fit attributes significantly more flux to the galaxy than what we put into the simulation. Visual inspection of these simulated objects revealed that all of them have additional flux from other objects included in the segmentation maps. 
Figure~\ref{fig:examplebadsim} shows an example, where the difference between the fitted and the true magnitude is -0.17 for the values extrapolated to infinity and -0.14 for the segment truncated values. Truncating to segment radii only leads to limited improvement of the agreement since the cause of the offsets observed in Figure~\ref{fig:comparesimulations} is flux from nearby objects; and all simulated galaxies are intrinsically represented well by a single S\'ersic model as they were created as such.

Nearby objects affect approximately 5-10\,\% of our simulated fits in this way. Since it is a one-sided effect (there are no sources with negative flux), it results in a slight overall bias across the sample. This is expected to occur at a similar level also in the fits to real galaxies and could only be improved by simultaneously fitting nearby sources (see also the discussion of this issue in \citealt{Haeussler2007}). However, for this work we decided against this option as explained in Section~\ref{sec:galaxyfitting}. We may revisit this decision in future work. 

\begin{figure}
\begin{center}
    \includegraphics[width=0.8\textwidth]{plots/examplebadsim}
    \caption{An example fit to a simulated galaxy where the difference between the true and the fitted magnitude is large due to the wings of a nearby bright object and a small faint object included in the segmentation map. Panels are the same as the top two rows in Figure~\ref{fig:examplefit}.}	
    \label{fig:examplebadsim}
\end{center}
\end{figure}


\subsection{Simulations: model selection accuracy}
\label{sec:simulationsmodelselection}

Since we know that all of our input galaxies were perfect single S\'ersic systems, the model selection and outlier rejection statistics can be used to judge the failure rate of these routines (cf. also Sections~\ref{sec:postprocessing}~and~\ref{sec:statistics}). We simulated 1000 galaxies at random locations; which resulted in 1126 objects to be fit (due to the overlap regions between KiDS tiles). Of these, 262 (23\,\%) were skipped; which is similar to the fraction of skipped fits for real galaxies, as expected since the main reason for this are the KiDS masks. Of the remaining objects, 94\,\% are classified as single component fits, 3\,\% are 1.5- or double component fits and 3\,\% are flagged as outliers. 

The number of outliers is significantly less than the 11\,\% of real $r$-band galaxies flagged (Section \ref{sec:postprocessing}) because in the simulations all galaxies are intrinsically ``well-behaved". Figure~\ref{fig:exampleoutliersim} shows an example of the most commonly occuring reason for being flagged as an outlier (in the simulations), namely the mask of a nearby bright star chopping up the segmentation map. 

\begin{figure}
\begin{center}
    \includegraphics[width=0.8\textwidth]{plots/exampleoutliersim}
    \caption{An example fit to a simulated galaxy which was flagged as a bad fit due to a nearby masked area from a bright star chopping up the segmentation map. Panels are the same as the top two rows in Figure~\ref{fig:examplefit}.}
    \label{fig:exampleoutliersim}
\end{center}
\end{figure}

The fact that 97\,\% of non-outlier simulated galaxies are correctly classified as single component fits confirms that model selection is accurate provided the galaxy can be unambiguously assigned to the single S\'ersic model (cf. Section~\ref{sec:postprocessing}). We visually inspected the 3\,\% 1.5- and double component fits and found nearby interfering objects in all of them. Figure~\ref{fig:exampledoublesim} shows an example, where the fit attempts to capture the additional ``features" with the freedom of a second component. Note that since we only simulated single S\'ersic objects, we cannot comment on the accuracy of the model selection procedure for double component objects here. However, our model selection procedure was optimised on all types of real galaxies (not just single S\'ersic objects); and our comparison to visual inspection in Section~\ref{sec:postprocessing} also indicates a high accuracy for double component systems. 

\begin{figure}
\begin{center}
    \includegraphics[width=0.8\textwidth]{plots/exampledoublesim}
    \includegraphics[width=0.8\textwidth]{plots/exampledoublesim2}
    \caption{An example fit to a simulated galaxy which was classified as a double component fit. \textbf{First two rows:} the single S\'ersic fit. \textbf{Last three rows:} the double component fit. Panels are the same as in Figure~\ref{fig:examplefit}.} 
    \label{fig:exampledoublesim}
\end{center}
\end{figure}




\subsection{Systematic uncertainties}
\label{sec:systematics}


\begin{figure}
    \includegraphics[width=\textwidth]{plots/differrnorm}
    \caption{For all single S\'ersic parameters as labelled top to bottom: \textbf{Left column:} The distribution of the absolute difference between the fitted and true values for simulated galaxies; or between the fitted values to two versions of the same (simulated or real) galaxy in the overlap sample. The legend at the bottom indicates which difference is shown; scale parameters are treated in logarithmic space throughout. See text for details. \textbf{Middle column:} The error on the parameter difference shown in the left column. \textbf{Right column:} The parameter difference normalised by its error (i.e. left column divided by middle column).}
    \label{fig:differrnorm}
\end{figure}

Figure~\ref{fig:differrnorm} shows the results of our systematic error study, which we will now discuss in detail. Going from left to right we show three different plot types as labelled on the $x$-axis and described in more detail in the caption and below. Going from top to bottom, each plot type is shown for each single S\'ersic parameter as labelled in the left panels; and the colours of the lines in the plot indicate which sample was used according to the legend at the bottom of the figure. The left panels show the distribution of absolute differences between the values fitted to both versions of a galaxy (in the indicated units); the middle panels show the corresponding error distribution (errors added in quadrature for the two fits; in the same units as the fit); and the right panels show the distribution of the absolute difference divided by its error (unitless). The solid black lines labelled ``real data overlap" are using the overlap sample. The dashed dark blue lines labelled ``simulation overlap" show the same for the overlap sample in simulated galaxies, where we have run more simulations specifically to boost the number of simulated overlap galaxies to a similar value as we have for the real overlap sample ($\sim$\,700). The dashed light blue line labelled ``sim. overlap (t. PSF)" is the same as the dashed dark blue line, just that when fitting the galaxy, instead of the estimated PSF we passed in the true PSF (i.e. the one we used to convolve the model galaxy with originally). The dotted dark orange line labelled ``simulation fit vs. true" shows the difference between the fitted value and the true value (instead of between the two fitted values in the overlap region) for the same sample of galaxies. Note the errors here now are just the errors of the fit since the true values do not have errors. The dotted light orange line (``sim. fit vs. true (t. PSF)") is the same for the run that used the true PSFs.
 
All values are clipped to the plotting intervals (for plotting only). For scale parameters, all distributions are shown in logarithmic space (which the parameters were also fitted in). To make the scales comparable to the other parameters, the angle is shown in units of 30\degr\ (which it was also fitted in to make the MCMC step size comparable to the other parameters). For the magnitude and effective radius, we show both the fitted S\'ersic values and the segment truncated values. Comparing rows 3 and 4 (S\'ersic and segment magnitudes) or rows 5 and 6 (S\'ersic and segment effective radii) against each other, it becomes clear immediately that the distributions for the segment values are narrower, i.e. limiting to segment sizes increases the stability and reduces the scatter in those parameters as already observed in many previous sections. Note, though, that our simulated galaxies do follow perfect single S\'ersic profiles, so the differences between the segment and S\'ersic values are generally expected to be much smaller in the simulations than in real data (see Section~\ref{sec:postprocessing} for details). 

For each distribution, we also give the median of the absolute difference and the errors; and the 1$\sigma$-quantile (half of the range containing the central 68\,\% of data) of the normalised difference. These values (with uncertainties) are also given in Table~\ref{tab:errorunderestimate}. 


\subsubsection{Overlap sample: real vs. simulated}

Focusing on the real data and simulation overlap samples (solid black and dashed dark blue lines), which are most directly comparable, it can be seen that the distributions of the pa\-ra\-me\-ter differences (left column) are broader for the real galaxies than for the simulated galaxies for all parameters; i.e. for two versions of the same galaxy in the overlap sample, the fitted values are on average closer to each other in the simulation than in the real data. 
This could be due to two reasons: either irregular galaxy features in combination with noise (i.e. perfect single S\'ersic objects are just more easily constrained/less easily influenced by noise fluctuations); or differences in the KiDS data processing between tiles (e.g. inaccuracies in their background subtraction procedure) that affect the real galaxies but not the simulated ones since those were added later. In reality, it is probably a combination of these two effects (with the first one presumably dominating). All steps of our own analysis affect both the simulated and the real galaxies and on average will have the same effect on both. 

The errors (second column) do reflect this additional uncertainty in real galaxies in that they are larger by 0.2-0.3\,dex for all parameters. In fact, the errors on the simulated galaxies seem to be more severly underestimated than those on the real galaxies, which becomes clear when looking at the parameter differences normalised by the respective errors (third column). In an ideal world, these would all be Gaussians centred on zero with a standard deviation of 1. As there will always be a few outliers due to interfering objects or image artifacts, instead of the mean and standard deviation we will consider their more robust equivalents, the median and 1$\sigma$-quantile (shown in plots). All overlap sample distributions (simulated and real, i.e. black, dark blue and light blue lines) are centred on zero, as already expected from the results shown in Figure~\ref{fig:compareoverlap}. However, it can be seen that for all parameters except segment effective radius, the 1$\sigma$-quantile is larger than 1 both for the simulated and the real sample: values generally range between 2 and 3 with simulated galaxies performing slightly worse due to the underestimated errors (which are most likely caused by the PSFs, see discussion below). 

The exception to this is position (RA and Dec, top two rows), for which the normalised distribution is a factor of approximately 10 broader for real galaxies than for simulated ones. In fact, a considerable fraction of these distributions fall outside of the plotting range, such that the clipping to these intervals results in prominent peaks at the plot edges (top right two panels of Figure~\ref{fig:differrnorm}). We believe this to be mainly due to the accuracy of the astrometric solution of the KiDS data, which shows a scatter of approximately $0\farcs$04 in DR4.0 in both RA and Dec (\citealt{Kuijken2019}; and we also confirmed this using the KiDS $r$-band source catalogues). This is a factor of 4 larger than the median MCMC error on position (top two panels in the middle row of Figure~\ref{fig:differrnorm}). Accounting for this additional source of scatter between the tiles (which only affects real objects but not the simulations since those were inserted after the astrometric calibration) would bring the normalised error distribution for the real data overlap sample into much closer agreement with the simulated version. The remaining factor of $\sim$\,2-3 difference could also be due to the astrometry, considering that the overlap sample by definition sits at tile edges, where the astrometric solution is the most uncertain; or - as for all other parameters - due to irregular galaxy features in combination with noise (see discussion above). As a last point we would like to note that the absolute differences in position are usually still within 1 pixel ($0\farcs$2), i.e. although it stands out from the plot, this is a sub-pixel effect. 


\subsubsection{Simulated overlap: imperfect vs. true PSFs}

These distributions of the simulated overlap sample can be compared to their equivalent distributions using the true PSFs (dashed light blue lines in Figure~\ref{fig:differrnorm}). This allows us to determine which parameters are affected by imperfect PSF estimates. However, we note that we can only make qualitative and relative statements here since we do not know how close to the truth our estimated PSFs for the real galaxies are. When simulating our galaxies, we convolve it with the model PSF fitted to the nearest real galaxy, i.e. this is the true PSF (cf. Section~\ref{sec:parameterrecovery}). When processing the simulated galaxy through our pipeline, the estimated PSF is then obtained by fitting nearby stars in the usual way. The nearest galaxy (which the true PSF is based on) is typically around 200\arcsec\ away, with the distribution ranging between $\sim$\,0 and $\sim$\,500\arcsec. This is close enough to provide a realistic PSF for the position of interest since KiDS tiles are much larger than this ($\sim$\,1\,deg$^2$) and the PSF varies only slowly across the tiles. However, it is further away than the stars used to obtain the estimated PSF, which are typically within $\sim$\,100-200\arcsec\ and can at the very maximum be $\sqrt{2}$\,$\times$\,200\arcsec\ away since the large cutouts used for PSF fitting are 400\arcsec\ on each side. This is expected since the density of stars is much higher than that of GAMA galaxies in KiDS data. However, it implies that the deviations of the estimated to the true PSFs in the simulations will on average be larger than for real data, leading to the errors on simulated galaxies being more severely underestimated as noted above. 

Comparing the simulations with true PSFs to the real data, it can be seen that the simulations now perform better than the real data for all parameters except segment effective radius (1$\sigma$-quantiles between 1 and 2.8). In addition, comparing the simulations with the true and the false PSFs against each other, we can assess which parameters are most affected (relatively speaking): position angle and axial ratio are most severely influenced; followed by S\'ersic index, effective radius and magnitude, while the position is nearly unaffected. This makes sense: the axial ratio and position angle are very sensitive to mistakes in the ellipticity and orientation of the PSF; while the fitted S\'ersic index, effective radius and magnitude depend on the concentration and FWHM of the PSF. The position is only very weakly affected since the PSF is always centred and symmetric. 

Note that all 1$\sigma$-quantiles are still larger than 1 (ranging from 1.1 to 2.8) even for the simulations with true PSFs. This indicates that the error underestimates of these parameters are not exclusively caused by the effects studied so far (galaxy and/or image processing features not accounted for in the simulations and PSF uncertainties) but there is an additional contribution from features that are also present in the simulations such as nearby objects, noise fluctuations, background subtraction inaccuracies or image artifacts. 


\subsubsection{Simulated sample: fitted vs. true values}

Finally, for the simulated samples we can compare the fitted values to the true values (instead of the overlap sample comparison), which is shown as dotted orange lines in Figure~\ref{fig:differrnorm}. This allows us to detect biases, but is less directly comparable to the sample of real galaxies where the true value is unknown. Note the errors are generally slightly smaller compared to the overlap studies since for those, the errors for both fits were added in quadrature while the true values now do not have errors. Correspondingly, the normalised distributions are slightly broader even though the absolute differences between parameters are comparable. Most notably, however, the median of the distribution is now shifted away from zero for magnitude, effective radius and S\'ersic index (see also Table~\ref{tab:errorunderestimate}).
This is due to the bias caused by nearby objects already described in Section~\ref{sec:parameterrecovery}: magnitudes are too bright by $\sim$\,0.01\,mag; effective radii and S\'ersic indices too large by approximately 1\,\% (always a bit better for segment values and/or simulations using the true PSFs). All other parameters still have their distributions centred on zero, i.e. do not show any bias - at least not one that we can test with our simulations. This makes sense since position, axial ratio and angle will be influenced by nearby objects (and other effects) as well, but without any preferred direction and so on average this leads to an error underestimate rather than an overall bias. Using the true PSFs (dotted light orange lines) narrows all distributions slightly as expected; but again there is only an error underestimate rather than an overall bias introduced by the wrong PSFs since they are ``randomly wrong". 

One source of potential bias that we cannot test with the simulations are galaxy features not accounted for in the models. If, for example, there is a large population of galaxies that have bars; and these bars lead to the bulge axial ratios being systematically underestimated, this is again a one-sided effect that could lead to an overall bias. For this reason, we explicitly use the term ``bulge" in its broadest sense, including all kinds and possible combinations of central galaxy components. In addition, such features could further increase the error underestimate because they will tend to influence both fits to a galaxy in the overlap sample in the same way and hence are difficult to detect in the above analysis. If there are systematic one-sided deviations of the true PSFs from Moffat functions, these could lead to one-sided systematically wrong PSF estimates which could in turn also introduce an additional bias that cannot be tested by the simulations which use Moffat model PSFs. However, based on the PSF quality control, we do not believe that our PSF estimates are systematically wrong, see discussion in Section~\ref{sec:psfdetails}. 


\subsubsection{Corrections for systematics and their validity}

\begin{table}
	\centering
	\caption{Biases and error underestimates for all single S\'ersic parameters derived from our systematic error studies (Section~\ref{sec:systematics}). The bias is additive (indicated with $\pm$) for those parameters that were treated in linear space and multiplicative (indicated with $\divideontimes$) for those treated in logarithmic space. Error underestimates are always multiplicative. The column ``bias/$\sigma$" gives the significance of each bias.}
	\label{tab:errorunderestimate}
	\begin{tabular}{llrr} % number of columns, alignment for each
		\hline
		\multirow{2}{*}{param.} & \multicolumn{1}{c}{bias} & \multirow{2}{*}{bias/$\sigma$} & \multicolumn{1}{c}{error}\\
		 & \multicolumn{1}{c}{(using true PSFs)} & & \multicolumn{1}{c}{underest.}\\
		\hline
RA & $\pm\,\, (7 \pm 18) \times 10^{-5}$\,arcsec &   0.39 & $ 12.27 \pm 0.71 $ \\ 
 Dec & $\pm\,\, (10 \pm 19) \times 10^{-5}$\,arcsec &   0.56 & $ 10.98 \pm 0.53 $ \\ 
 $m$ & $\pm\,\, (-11.4 \pm 0.8) \times 10^{-3}$  & -13.83 & $  3.10 \pm 0.16 $ \\ 
 $m_{seg}$ & $\pm\,\, (-8 \pm 0.5) \times 10^{-3}$  & -14.92 & $  1.79 \pm 0.09 $ \\ 
 $R_{e}$ & $\divideontimes\,\, (1.0105 \pm 0.0009)$  &  11.61 & $  2.68 \pm 0.12 $ \\ 
 $R_{e, seg}$ & $\divideontimes\,\, (1.0074 \pm 0.0005)$  &  14.39 & $  1.01 \pm 0.05 $ \\ 
 $n$ & $\divideontimes\,\, (1.010 \pm 0.001)$  &  10.93 & $  2.49 \pm 0.10 $ \\ 
 PA & $\pm\,\, (-4 \pm 19) \times 10^{-3}$\,deg &  -0.19 & $  2.00 \pm 0.10 $ \\ 
 b/a & $\divideontimes\,\, (0.9993 \pm 0.0004)$  &  -2.07 & $  2.51 \pm 0.09 $ \\ 
        \hline
	\end{tabular}
\end{table}

Table~\ref{tab:errorunderestimate} summarises the results of the systematic error studies: for all single S\'ersic parameters (plus the segment magnitude and segment effective radius), we give the average bias and error underestimates with uncertainties. The bias is estimated from the median of the offset between fitted and true values in the simulation using the true PSFs (light orange numbers in the first column of Figure~\ref{fig:differrnorm}). The errors on the median are taken as the 1$\sigma$-quantiles of these distributions divided by the square-root of the number of data points ($\sim$\,2000). Loga\-rith\-mic parameters are converted back into linear space to simplify bias correction in the catalogue. Nonetheless, scale parameters have multiplicative correction factors while location parameters have additive corrections (in given units). In other words: to correct for the bias, subtract the values in Table~\ref{tab:errorunderestimate} from the catalogue values for position, magnitude and position angle; and divide by the given values for effective radius, S\'ersic index and axial ratio. Users should note, however, that due to the way these biases were estimated, they do not include all sources of potential bias (e.g. galaxy features such as bars and spiral arms; or systematically wrong PSFs). Also, we recommend to apply the bias correction only to statistically large and random samples; they are average values not applicable to individual galaxies as evident from Figure~\ref{fig:comparesimulations}. 

The next column in Table~\ref{tab:errorunderestimate} gives the significance of each bias, which is the deviation of the median from 0 (or 1 for scale parameters) divided by its error. It can be seen that position, position angle and axial ratio are not biased (consistent with 0/1 within 2$\sigma$), while magnitude, effective radius and S\'ersic index are biased (deviation from 0/1 of >\,5$\sigma$); as found and discussed before. 

Finally, the last column in Table~\ref{tab:errorunderestimate} gives the error underestimates estimated from the width of the distribution of the normalised difference between fits to two versions of the same galaxy in the overlap sample (black numbers in the last column of Figure~\ref{fig:differrnorm}). The uncertainties in this case were estimated by bootstrapping the distributions 1000 times each to get an estimate of the variation of the distribution width. Since these distributions were normalised (by the respective errors), there is no need to convert between linear and logarithmic space and the given values can directly be used as correction factors for the MCMC errors. We have applied the relevant correction to all quoted errors in the catalogue, but also give the original (purely random) errors for completeness. Also note that since these values are now based on real data, they do include PSF uncertainties (in contrast to the biases). Also, since the overlap sample is in many ways the worst in terms of data quality (sitting at tile edges), these are likely upper limits. However, they still do not include error underestimates caused by (galaxy) features not accounted for in the models such as bars, rings, spiral arms or similar, as well as nearby objects. Since these are physical (rather than related to the data taking or image processing), they will be present in both versions of the overlap sample galaxy and influence both fits in similar ways - leading to a (random) bias on individual galaxy fits; and hence an error underestimate for a large enough sample. These issues should be kept in mind when using the catalogue. 

