\chapter{Bulge-disk decomposition pipeline}
\label{chap:pipeline}

In this chapter, we present the bulge-disk decomposition pipeline we built around the \texttt{ProFound} and \texttt{ProFit} software packages. It consists of three main steps: preparatory work, galaxy surface brightness fitting and post-processing. The main inputs to the pipeline are a list of galaxies (GAMA CATAIDs) and the path to a directory containing (KiDS or VIKING) imaging files with associated weight maps and masks. The fully automated pipeline then performs all necessary steps to proceed from these basic inputs to a final catalogue of properties of the galaxies and their components, including numerous quality assessment parameters.%\\

We start with an overview of all steps of the pipeline in Section~\ref{sec:pipelineoverview}. This is based on section~3 in \citet{Casura2022} and describes the status quo at the time of submission, with \texttt{v04} being the corresponding \texttt{BDDecomp} DMU version on the GAMA database. It is limited to the processing of the KiDS $g$, $r$ and $i$ bands. Section~\ref{sec:pipelinedevelopment} details how we have arrived at all of the procedures and the evolution of the pipeline from \texttt{v01} through to \texttt{v04}. Most of these studies focused on the KiDS $r$-band only. Finally, in Section~\ref{sec:pipelineupdates} we summarise the changes made to the pipeline after the submission of \citet{Casura2022}. These updates were mainly performed in order to process VIKING data and resulted in \texttt{v05} of the \texttt{BDDecomp} DMU, which encompasses all 9 KiDS and VIKING bands ($u, g, r, i, Z, Y, J, H, K_s$).%\\
 
We use the free and open-source programming language \texttt{R} \citep{Rv3.6} for all scripting.
 

\section{Pipeline overview}
\label{sec:pipelineoverview}

This section is directly taken from section~3 in \citet{Casura2022} with very minor adjustments and gives an overview of the entire bulge-disk decomposition pipeline, including all preparatory steps, the actual galaxy fitting and the post-processing. It reflects the status of the data processing at the time of submission, meaning it refers to the processing of the KiDS $g$, $r$ and $i$ bands and \texttt{v04} of the corresponding \texttt{BDDecomp} DMU on the GAMA database. The adjustments relative to \citet{Casura2022} were mainly to fit the style of this thesis and to point to relevant further tests, examples and diagnostics in Section~\ref{sec:pipelinedevelopment} that are not contained in \citet{Casura2022}. 

\subsection{Preparatory steps} 
\label{sec:preparatorysteps}
The first part of our bulge-disk decomposition pipeline consists of several image processing steps that we group under the term ``preparatory work". 

\subsubsection{Cutouts and masking}

KiDS imaging tiles are registered to the same pixel grid across all four bands (with matching weight maps and masks), such that a joint analysis of the bands is straightforward. They are also aligned such that the $x$-axis corresponds to right ascencion (RA) and the $y$-axis to declination (Dec). Hence, we obtain a 400\arcsec\,$\times$\,400\arcsec\ cutout of the KiDS tile, associated weight map and mask for each object in our sample, and for each of the three KiDS bands we used ($g,r,i$). The masks of all three bands are then combined and all pixels which have a value greater than 0 in any of the masks are excluded from analysis. This results in approximately 20\,\% of all pixels being masked out. This large fraction of masking is primarily due to the reflection halos of bright stars that are also clearly visible in the data (see \citealt{deJong2015} for details). We combine the masks in this way to ensure that the pixels used for analysis are exactly the same in all bands and so the results are most directly comparable. Objects for which the central pixel is masked ($\sim$\,20\,\% of all galaxies) are skipped in the galaxy fitting. More details on the choice of KiDS data products and the cutout size to use are given in Section~\ref{sec:otherprepworkchoices}. 

\subsubsection{Image segmentation}

We perform image segmentation in order to determine which pixels to fit for each of our objects, identify other nearby sources, improve the background subtraction and obtain reasonable initial guesses for the galaxy parameters. This is performed on the joint $g, r, i$ cutouts with \texttt{ProFound} in several steps.  

First, we add the cutouts in the $g$, $r$, and $i$ bands using inverse variance weighting and compute the joint weight map. We then estimate the (joint $gri$) sky by running the stacked image through \texttt{profoundProFound} passing in the correct magnitude zeropoint, mask and weight, but leaving \texttt{skycut} on its default of 1. This means that all pixels with a flux at least 1$\sigma$ above the median are progressively assigned to segments (collections of pixels belonging to an object) using an iterative process: starting with the brightest pixel in the image, segments are grown by adding neighbouring pixels with lower flux; new segments are started when a pixel shows more flux than its neighbours (within some tolerance) or when all neighbouring pixels above the \texttt{skycut} value have been assigned. Once all pixels above \texttt{skycut} have been assigned, the resulting segments are additionally expanded until flux convergence is reached. For more details, see \citet{Robotham2018}. 

\begin{figure}[ht!]
  \begin{center}
	\includegraphics[width=0.8\textwidth]{plots/exampleseg}
    \caption{The \texttt{ProFound} segmentation map obtained for the GAMA galaxy 396740 overlaid on the KiDS $r$-band image. Note this is only a cutout of the full segmentation map showing the central 100\arcsec\,$\times$\,100\arcsec. Identified objects (segments) are shown with contours, coloured from red to blue according to the flux contained. Grey contours indicate the more dilated segmentation map used for the background subtraction. Masked areas are shaded red.} 
    \label{fig:exampleseg}
  \end{center}
\end{figure}

Along the way, \texttt{ProFound} estimates the sky background several times since object detection relies on accurate background subtraction and vice versa.\footnote{The sky variance can also be estimated, but in our case this is already provided as the KiDS weight maps and given to \texttt{ProFound} as an input.} For the final sky estimate, the already-dilated segments are expanded even further to ensure that no object flux will bias the background determination. This very aggressive object mask is indicated with grey contours in Figure \ref{fig:exampleseg}. We use it for the joint-$gri$ sky estimate here and also for the band-specific background determination detailed below (performed in the same way).  

For the galaxy fitting, however, we decided to use tighter segments that do not push that deeply into the sky. Besides speeding up the fit, this results in the best possible fit to the inner, high signal-to-noise regions of the galaxy that we are most interested in and reduces the sensitivity to background subtraction problems, flux from the wings of other objects and features that cannot be captured by our models such as disk breaks and flares, and edge-on disks requiring the inclined disk model \citep{vanderKruit1981}. Note, however, that this choice comes with some trade-offs, most notably that the fit frequently overpredicts the flux outside the segment boundary. We address this in more detail in Section~\ref{sec:postprocessing}. 

To obtain these tighter segmentation maps, we run \texttt{profoundProFound} again with the sky now fixed and a higher \texttt{skycut} value of 2. This means that only pixels with a flux at least 2$\sigma$ above the background level are considered in the segmentation, which ensures that fewer noise fluctuations are ``detected" and segment borders are smooth. In order to capture all flux of the galaxy wings, the segment for the object of interest (only) is then expanded further (using \texttt{profoundMakeSegimDilate}) such that its area increases by typically around 30\,\%. This last step also ensures unbiased smooth borders of the segment since it is entirely independent of noise fluctuations. The resulting segmentation map is indicated with coloured contours in Figure \ref{fig:exampleseg} and is used for galaxy fitting in all bands, so that exactly the same pixels are fitted in each band (the segmentation statistics are re-calculated in each band). 

Section~\ref{sec:segchoices} contains more details on the procedures for defining the segmentation map, reasons behind our decision to use different segmentation maps for background subtraction and galaxy fitting and the effect that different segment sizes have on galaxy fitting.
 
\subsubsection{Background subtraction}

KiDS tiles are background-subtracted already, however we opt to use the sky estimated by \texttt{ProFound} to even out inhomogeneities on smaller scales. For this, we split our 400\arcsec\,$\times$\,400\arcsec\ cutout into 16 square boxes and mask out all objects using the aggressively dilated segmentation map indicated with grey contours in Figure \ref{fig:exampleseg}. The sky is then estimated as the median of the remaining (background) pixels in each box independently; and the solutions between the boxes interpolated with a bicubic spline.\footnote{This is done by \texttt{profoundProFound} internally; with the box size and the order of the interpolation spline being some of the variables we set.} This is done for each band independently, however the segmentation maps used to mask out objects are the same in all bands.

This procedure for the background subtraction was chosen after extensive testing during pipeline development which is summarised in Section~\ref{sec:backgroundstudies}. In short, we found that the \texttt{ProFound} sky adopted here does not subtract object wings while still homogenising the background well enough to avoid having to fit it along with the object of interest (introducing possible parameter degeneracies). It also decreases the sensitivity of the fit to the chosen segment size. 

\subsubsection{Sigma maps}

Once the image segmentation and background subtraction is completed, we also calculate the sigma (error) map for each cutout (independently in each band). This is a combination of the KiDS weight map (where $\sigma$\,=\,1\,/\,$\sqrt{weight}$) and the object shot noise. The latter is estimated as $\sqrt{N}$, where $N$ is the number of photons per pixel (using positive-valued pixels only). This, in turn, is obtained by converting the image into counts using the gain provided in the meta-data associated with each KiDS tile.

\subsubsection{PSF estimation}

PSF fitting is performed on the background-subtracted 400\arcsec\,$\times$\,400\arcsec\ cutouts with corresponding masks and sigma maps in each band. The segmentation statistics returned by \texttt{ProFound} are used to identify isolated stars (round, bright, small and highly concentrated objects with few nearby segments). More details on the star candidate selection are given in Section~\ref{sec:psfdetails}. These objects are then fit with a \citet{Moffat1969} function using \texttt{ProFit}; fitting all parameters except boxyness, i.e. the position, magnitude, full width at half maximum (FWHM), concentration index, axial ratio and position angle. Scale parameters are fitted in logarithmic space, a Normal likelihood function is used, initial guesses are taken from the segmentation statistics and we use the \texttt{BFGS} algorithm from \texttt{optim} \citep{Rv3.6}, which is a fast downhill gradient optimisation using a quasi-Newton method published simultaneously by \citet{Broyden1970, Fletcher1970, Goldfarb1970, Shanno1970}. 

Some of the objects fitted above may not actually be suitable for PSF estimation as they can be too faint or bright (close to saturation), have irregular features, bad pixels or additional small objects included in the fitting segment. Unsuitable objects are excluded by a combination of hard cuts in reduced chi-squared ($\chi^2_\nu$), position and magnitude relative to the \texttt{ProFound} estimates and an iterative 2$\sigma$-clipping in FWHM, concentration index, angle and axial ratio. Again, more details can be found in Section~\ref{sec:psfdetails}. Finally, we take the median of the Moffat parameters of a maximum of 8 suitable stars (the closest 2 from each quadrant where possible to ensure an even distribution around the position of interest) and use these Moffat parameters to create a model PSF image. The size of the PSF image is adjusted to include at least 99\,\% of the total flux; or to a maximum of the median segment size within which the stars were fitted, with pixels in the corners of the image set to zero to avoid having a rectangular PSF. 

More details of the PSF fitting procedure and example diagnostic plots are given in Section~\ref{sec:psfdetails}, which also includes a description of other options we explored for obtaining PSFs, a summary of the PSF quality control and an overview of the PSF effects on galaxy fitting. 

\subsubsection{Outputs}

For the fitting, we are only interested in the central galaxy and the closest neighbouring sources (for potential simultaneous fitting and to gain a better overview during visual inspection). Hence, we do not save the entire 2000\,$\times$\,2000\,pix$^2$ cutouts used in the preparatory work as that would unnecessarily waste storage space and computational time used on reading and writing files. Instead, the image, corresponding mask, segmentation map, sigma map and sky image are cut down to the smallest possible size that includes the object of interest (centred) and its neighbouring (touching) segments before saving. These 5 files, the model PSF image and some ancillary information such as the segment statistics are the main outputs of the preparatory work pipeline and serve as inputs for the galaxy fitting, which we describe in Section~\ref{sec:galaxyfitting}. 


\subsection{Galaxy fitting}
\label{sec:galaxyfitting}
The second major step in the pipeline is the model fitting, based on the outputs of the preparatory work. 

\subsubsection{Inputs and models}

We use the Bayesian code \texttt{ProFit} \citep{Robotham2017} to perform 2-dimensional multi-component surface brightness modelling in each band independently, assuming elliptical geometry and a (combination of) S\'ersic function(s) as the radial profile. The \citet{Sersic1963} function is given in Equation~\ref{eq:sersic} and described by three main parameters: the S\'ersic index $n$ giving the overall shape (with special cases $n$\,=\,0.5: Gaussian; $n$\,=\,1: exponential and $n$\,=\,4: \citet{deVaucouleurs1948} profile), the effective radius $R_e$ including half of the total flux and the overall normalisation which we specify as total magnitude $m$. In addition, in 2 dimensions the axial ratio $b/a$ gives the ratio of the minor to the major axis of the elliptical model and the position angle PA its orientation, while $x$ and $y$ are used to define the position in RA and Dec. Throughout this thesis, $R_e$ refers to the effective radius along the major axis of the elliptical model. The S\'ersic model is detailed in \citet{Graham2005}; and see also Section~\ref{sec:sersicmodels}. 

The data inputs for \texttt{ProFit} are a background-subtracted image, corresponding mask, segmentation map, sigma map and PSF. All of these are obtained during the preparatory steps (Section~\ref{sec:preparatorysteps}). On the modelling side, the main choices are the profile(s) to fit with initial parameter guesses and priors, the likelihood function to use, the fitting algorithm and convergence criteria; which are detailed below. In short, we choose to fit each object with 3 different models in a four-step procedure: 
\begin{enumerate}[label=(\roman*)]
\item{Single component S\'ersic fits with initial guesses from segmentation statistics.}
\item{Double component S\'ersic bulge plus exponential disk fits with initial guesses from single component fits.}
\item{Double component re-fits for a subset of galaxies which seemed to have the bulge and disk components swapped in step (ii), see below.}
\item{``1.5-component" point source bulge plus exponential disk fits with initial guesses from double component fits.}
\end{enumerate} 
Further details on this choice of models are given in Sections~\ref{sec:sersicmodels} and~\ref{sec:modellingdecisions}. Note that, for brevity, we will call the central component ``bulge" throughout this work, even if it may not be a classical bulge. In particular, we do not distinguish classical bulges from pseudo-bulges, bars, AGNs, nuclear disks, combinations thereof or anything else that may emit light near the centre of a galaxy. Hence, we also use the term ``bulge" for 1.5-component fits where the central component is unresolved and for double component central components with low S\'ersic index and/or low axial ratios. 

\begin{table}[h]
	\centering
	\caption{The fitting parameters for each of our three models.}
	\label{tab:fittingparameters}
	\begin{tabular}{l l c l cc l cc} % alignment for each column
		\hline
		 && single && \multicolumn{2}{c}{double} && \multicolumn{2}{c}{1.5-comp.} \\
		 parameter && && bulge & disk && bulge & disk \\
		 \hline
		$x$-centre && free && \multicolumn{2}{c}{free} && \multicolumn{2}{c}{free} \\
		$y$-centre && free &&  \multicolumn{2}{c}{free} && \multicolumn{2}{c}{free}\\
		$m$ && free && free & free && free & free\\
		$\log_{10}(R_e)$&& free && free & free && N/A & free\\
		$\log_{10}(n)$ && free && free & 1 && N/A & 1 \\
		$\log_{10}(b/a)$&& free && free & free && N/A & free\\
		PA && free && free & free && N/A & free\\
		boxyness && 0 && 0 & 0 && N/A & 0\\
		\hline
	\end{tabular}
\end{table}

To implement our three models, we make use of two of the many models built into \texttt{ProFit}, namely the S\'ersic and point source models. We fit all parameters except \texttt{boxyness} (i.e. we do not allow deviations of components from an elliptical shape) and, for the double and 1.5-component models, tying the positions of the two components together. Exponential disks are implemented using a S\'ersic profile with the S\'ersic index fixed to 1. This leaves 7 free parameters for our single S\'ersic and 1.5-component models and 11 free parameters of the double component fits, which are summarised in Table~\ref{tab:fittingparameters}; and see also Section~\ref{sec:modellingdecisions}. Scale parameters (S\'ersic index, effective radius and axial ratio) are treated in logarithmic space throughout, i.e. the actual fitting parameters are $\log_{10}(X)$ for scale parameters $X$ (Section~\ref{sec:fittingspecifics}). 

The 1.5-component model is needed for around 15-30\,\% of our double component systems where the bulge is too small relative to the image resolution to meaningfully constrain its S\'ersic parameters (the exact number depends on the band due to the different PSF sizes). With the point source profile, at least we can determine the existence of a second component and constrain its magnitude and hence the bulge-to-total (or AGN-to-total, bar-to-total, etc.) flux ratio. An example is given in Figure~\ref{fig:examplefit1.5} (Section~\ref{sec:modellingdecisions}). 

If the centre of an object is masked or the PSF estimation failed (which happens if large fractions of the surrounding area are masked), then the object is skipped and no fits are obtained. This affects approximately 20\,\% of the galaxies. All other objects are fitted with all three models; and the best model is selected subsequently (see Section~\ref{sec:postprocessing} on details of the model selection and Section~\ref{sec:statistics} for the corresponding statistics).


\subsubsection{Initial guesses}

Since we use MCMC algorithms, our fits do not strongly depend on the initial guesses. However, reasonable starting parameters are still required for convergence within finite computing times. 

The initial guesses for the single component S\'ersic parameters are obtained directly from the segmentation statistics output by \texttt{profoundProFound} (Section~\ref{sec:profound}) where we use the position, magnitude, effective radius (\texttt{R50}), axial ratio and angle as given; and the inverse of the concentration (1/\texttt{con}) for the S\'ersic index. 

For the double component fits, we convert the single component fits into initial guesses as follows: the position is taken unchanged, the magnitude of the single component fit is split equally between the two components, the bulge and disk effective radii are taken as 1/2 and 1 times the single component effective radius respectively, the S\'ersic index of the bulge is set to 4 and its axial ratio to 1 (round), the disk axial ratio is set to the axial ratio of the single component fit and the position angles of both components are taken as that of the single component fit. See also Section~\ref{sec:modellingdecisions}. 

Initial guesses for the 1.5-component fits are taken from the double component fits (after making sure the components are not swapped, see below), where the bulge magnitude is used as the point source magnitude and the disk parameters are taken unchanged. 

\subsubsection{Priors, intervals, constraints}

All parameters are limited to fixed intervals. In addition, there can be constraints between parameters (such that, e.g., the bulge and disk positions can be tied together). If a (trial) parameter is outside the bounds of its interval or constraint during any step of the fitting process, \texttt{ProFit} moves it back onto the limit before the likelihood is evaluated.

The limits for single-component fits are given in Table~\ref{tab:singlefitlimits}. In addition, the position angle is constrained such that if it leaves its interval, it is not just moved back onto the limit but jumps back 180\degr\ (which is the same angle, just more in the centre of the fitting interval). 
\begin{table}
	\centering
	\caption{The fitting limits for single-component fits.}
	\label{tab:singlefitlimits}
	\begin{tabular}{lll} % four columns, alignment for each
		\hline
		parameter(s) & lower limit & upper limit \\
		\hline
		$x$- and $y$-centre & 0 & cutout side length\\
		magnitude & 10 & 25\\ 
		effective radius & 0.5 pixels & $\sqrt{2}$ cutout side length\\
		S\'ersic index & 0.1 & 20\\
		axial ratio & 0.05 & 1\\
		position angle & -90\degr\ & 270\degr\ \\
		\hline
	\end{tabular}
\end{table}

There are no additional priors or constraints for single component  fits. This means that in effect, we use unnormalised uniform priors which are 1 everywhere in the respective interval and zero otherwise. For scale  parameters (which are fitted in logarithmic space) the priors are uniform in logarithmic space, corresponding to \citet{Jeffreys1946}, i.e. uninformative, priors. 

The limits and constraints for double and 1.5-component fits are the same as for the single component fits (for both bulges and disks), except for the magnitude where the individual component magnitudes have infinity as their upper limit and instead the \emph{total} magnitude is constrained to be within  the magnitude limits. This is most consistent and also allows the fitting procedure to discard one of the two components for systems which can equally well be fitted with a single S\'ersic function (we then take this into account in the model selection). Further considerations on additional constraints between parameters (that we did not enforce in the end) are summarised in Section~\ref{sec:modellingdecisions}. 

Note that the above procedure results in unnormalised posteriors. The lack of normalization does not impede our analysis because the only time when we compare posteriors is during model selection, where we effectively fold the normalisation into the calibration during visual inspection (Section~\ref{sec:postprocessing}). 

\subsubsection{Likelihood function}

We use a Normal likelihood function for all fits. We have tested a t-distribution likelihood function which is less sensitive to outliers/unfittable regions; but found that the Normal likelihood function is better suited to our needs for several reasons. 

First of all, the t-distribution fits often preferred to use the freedom of the bulge parameters to fit disk features instead (e.g. rings, bumps, flares, etc. that cannot be captured by the exponential model), treating the bulge as an outlier since the t-distribution prefers a few strong outliers (the bulge pixels) over many weak ones. 

Second, the t-distribution fits fail for galaxies which are perfectly fitted by the model since then the errors truly are distributed Normally. This is a relatively common occurrence.

Hence some galaxies ($\sim$\,20\,\%) need to be fitted with a Normal distribution anyway, which, third, makes model selection much harder since the likelihood values obtained with different likelihood functions cannot easily be compared to each other. 

See Section~\ref{sec:fittingspecifics} for more details and examples.

\subsubsection{Fit and convergence}

All fits are performed on the sky-subtracted image within the galaxy segment only using the \texttt{convergeFit} function from the \texttt{AllStarFit} package \citep{AllStarFit}. 
This function uses a combination of different downhill gradient algorithms available in the \texttt{nloptr} package \citep{nloptr} followed by several MCMC fits with \texttt{LaplacesDemon} \citep{LaplacesDemon} until convergence is reached. The exact procedure is described in Section~\ref{sec:fittingspecifics}. 

The downhill gradient algorithms are used first to improve the initial guesses. The MCMC chain is not very sensitive to the initial guesses, but converges much faster if starting closer to the peak of the likelihood. Once the MCMC chains have converged, 2000 further likelihood points are collected to ensure a stationary sample for the subsequent analysis of the galaxy. We test this in Section~\ref{sec:fittingspecifics}. 

We only fit the primary object of interest. While simultaneously fitting neighbouring sources is possible in \texttt{ProFit} and might have improved the fit on a few objects, the effects are generally small since the galaxies we study are not in highly crowded fields and the segmentation process usually excludes the vast majority of the flux from other sources. This is especially true since we use tight fitting segments within which the galaxy flux is dominant (cf. Section~\ref{sec:preparatorysteps}); and considering that the watershed algorithm of \texttt{ProFound} cleanly separates even overlapping sources, so neighbours are automatically masked (Section~\ref{sec:profound}). Hence we opted for the simpler and computationally cheaper option of only fitting the main objects. We confirm that this does not lead to major biases in Section~\ref{sec:parameterrecovery}).

An example fit for an object which is well-represented by our 2-component model is shown in Figure~\ref{fig:examplefit}. 

\begin{figure}
	\includegraphics[width=\textwidth]{plots/examplefit}
    \caption{The result of the 2-component (S\'ersic bulge plus exponential disk) fit for the galaxy 611298 in the KiDS $r$-band. \textbf{Top row:} the data, 2-component model and residual between them shown in absolute values of flux given by the colour bar on the right. The green contour indicates the segment used for fitting. Note that the flux scaling here is non-linear and optimised to increase visibility of galaxy features, but is the same in all 3 panels. \textbf{Middle row:} goodness of fit statistics. The right panel is the normalised residual $Z$ (colour bar on the right) capped at $\pm$\,5$\sigma$. The left panel is the one-dimensional distribution (measured probability density function, PDF) of $Z$ within the segment; with blue and red curves showing a Normal distribution with a standard deviation of 1 and a Students-t distribution with the relevant degrees of freedom for comparison. The middle panel shows the measured PDF of $Z^2$ compared to a $\chi^2$-distribution of 1 degree of freedom (blue). The reduced chi-squared, $\chi^2_\nu$ (sum over $Z^2$ divided by the degrees of freedom of the fit) is given in the top right corner. \textbf{Bottom row:} The bulge and disk models in 2 dimensions on the same flux scale as the top row; and the bulge, disk, and total model compared against the data in one-dimensional form (azimuthally averaged over elliptical annuli). The FWHM of the PSF and the approximate 1$\sigma$ surface brightness limits are indicated by vertical and horizontal dotted lines for orientation. The vertical solid green line indicates the segment radius beyond which our model is extrapolated. The pixel scale is $0\farcs$2 for KiDS data, i.e. 1\arcsec\ corresponds to 5\,pix.} 
    \label{fig:examplefit}
\end{figure}

\subsubsection{Component swapping}

Approximately 20-30\,\% of the double component fits have their bulge and disk components swapped, i.e. the exponential component fitting the central region and the S\'ersic component fitting the wings (this is a common problem in galaxy fitting, first pointed out by \citealt{Allen2006}). In particular, the freedom of the S\'ersic component is often used to fit disks that do not follow pure exponential profiles while at the same time being the dominant component in terms of flux (which is the case for most galaxies). To solve this problem, we devised an empirical swapping procedure guided by the visual inspection of a subsample of our galaxies. 

First, we select the galaxies that are most likely to have swapped components based on a cut in the plane of the ratio of S\'ersic indices and the ratio of effective radii for the single component fits and the bulge of the double component fits. The reasoning for choosing this parameter space to calibrate the cut was that we would generally expect bulges alone to be more concentrated (i.e. smaller effective radius and higher S\'ersic index) than when mixed with their respective disks in the single S\'ersic fits. This results in approximately 30\,\% of our sample being flagged as possibly swapped, which we then re-fit in a second step.

The re-fit is performed in exactly the same way as the original fit, except that we now use the results of the previous double-component fit as initial guesses, swapping around the bulge and disk components (except for the bulge S\'ersic index for which we use a value of 4). While the MCMC chain is less sensitive to initial guesses than a downhill gradient algorithm, it will still show some dependency for finite run-times. In particular, in our double component model the two components are \emph{nearly} interchangeable with the only difference being the S\'ersic index (fixed to 1 for the disk, free for the bulge). Hence there will always be 2 high maxima in likelihood space, which are far apart in the 11-dimensional parameter space. Moving from one to the other would require changing 9 parameters (all except position) at once in the right direction and hence is statistically unlikely. Therefore, we assist the code in finding the other maximum by manually swapping the initial guesses. 

In approximately 5\,\% of all re-fits, the code still converges on the same fit as before the swapping, but in most cases we find another likelihood maximum which corresponds to the bulge and disk components being reversed. As a third step we then select between the old and the new fit to obtain the physically more appropriate one. For this we first check whether either of the fits has a bulge S\'ersic index smaller than 2 \emph{and} a bulge effective radius at least 10\,\% larger than the disk effective radius \emph{and} a bulge-to-total ratio above 0.7 (i.e. the ``bulge" component is close to exponential, larger than the disk and contains the majority of the flux). If this is the case for only one of the fits, we choose the other one. If it is true for both or neither of the fits, then we apply our main criterion, which is that we choose the fit with the higher absolute value of bulge flux in the central pixel. These selection criteria are again based on visual inspection guided by the notion that we expect the bulge to be smaller and steeper than the disk and have proven to work very well. Note that the fit we select in this way is the one that is physically better motivated (i.e. with the bulge at the centre), and not necessarily the one which is statistically better.

After this procedure, the number of galaxies which still have the bulge and disk components swapped (and are classified as double component fits in model selection) is reduced to $\sim$\,1-2\,\%. The corresponding diagnostic plot based on the visual inspection as well as an example are shown in Section~\ref{sec:swappingandoutliers} (Figures~\ref{fig:swapdiagnostic}, \ref{fig:examplefitswap1} and~\ref{fig:examplefitswap2}). 

\subsection{Post-processing}
\label{sec:postprocessing}
To assess and improve the quality of the fits, we perform a number of post-processing steps, namely the flagging of bad fits, model selection, and truncating fits to segment radii. 

\subsubsection{Flagging of bad fits}

After all three models have been fitted to all objects, we run them through our outlier flagging process (separately in each band). Each model is treated separately first; they are then combined during the model selection (see below). 

The criteria for flagging bad fits (outliers) are: a very irregular fitting segment, an extreme bulge-to-total flux ratio, numerical integration problems, a parameter hitting its fit limits, poor $\chi^2$ statistics, a large distance between the input and fitted positions and a small fraction of model flux within the fitting segment. Additionally, there are some cautionary flags that identify fits which should be treated with extra care. All criteria are derived from and calibrated against visual inspection and described in more detail below and in Section~\ref{sec:swappingandoutliers} (including diagnostic plots). For orientation, we give the percentage of affected $r$-band fits in parentheses for each criterion below. The corresponding percentages for the $g$ and $i$ band fits are given in Table~\ref{tab:v04outlierstats} in Section~\ref{sec:outlierstats}. Note, however, that bad fits tend to fall into multiple of these categories, so the total number of bad fits is smaller than the sum of flagged objects in each category. Overall, approximately 9\,\%, 11\,\% and 10\,\% of all non-skipped fits are flagged in the $g$, $r$ and $i$ bands, respectively (after model selection).

\begin{description}[font=\normalfont]
\item[Very irregular segment (5.4\,\%):]{we calculate the difference between the magnitude of the model contained within the segment and the magnitude contained within the ``segment radius", which is defined as the maximum distance between the centre of the fit and the edge of segment. Objects where this magnitude difference is larger than 0.3 are flagged, as this is an indication for irregular segments (shredded, partly masked or cut off by another object for example). Note this criterion often shows overlap with the criterion on the fraction of model flux contained within the segment (see description below).}


\item[Extreme bulge-to-total ratio (0.1\,\%):]{we flag double component and 1.5-component fits with a bulge-to-total ratio smaller than 0.001 or larger than 0.999 because in these cases the second component has negligible flux and a single component fit is better suited.}

\item[Numerical integration problems (0.2\,\%):]{\texttt{ProFit} includes an oversampling scheme for accurate pixel flux integration where pixels containing steep flux gradients are recursively oversampled up to an oversampling factor of 4096; in the central pixel even up to $\sim$\,$10^9$ \citep[for more details see][]{Robotham2017}. However, for very extreme model parameters, even this procedure may not be accurate enough anymore, leading to significant errors in the pixel flux calculations. This could be improved by changing the default oversampling values to achieve higher accuracy (at the cost of increased computational time), however we opted for simply excluding those cases since usually this only happens for unresolved bulges which are better represented by the 1.5-component fits anyway.}

\item[Parameter hitting limit (5.8\,\%):]{we flag objects where the magnitude, effective radius or S\'ersic index hit either of their limits (cf. Section~\ref{sec:galaxyfitting}); or the axial ratio hit its lower limit (for double component fits this applies to both components individually). The axial ratio upper limit is not flagged because fits are allowed to be exactly round, but there is a cautionary flag for all objects which hit any of its parameter limits (6.5\,\%). We also add a cautionary flag for suspiciously small or large errors on any parameter, where ``suspicious" is defined as being an outlier in the respective distribution of errors (2.1\,\%).}

\item[Poor $\chi^2$ statistics (0.1\,\%):]{we flag fits with a $\chi_\nu^2$ larger than 80; or where the $\chi^2$ in the central pixel is more than 1000 times larger than the average $\chi^2$ per pixel since that is an indication that the bulge was not fitted.}

\item[Large distance between input and output position (0.3\,\%):]{we flag fits with a distance between the input and output position of more than 2\arcsec\ (10\,pix), which are usually highly asymmetrical objects, mergers, objects with very nearby other objects (especially small objects embedded in the wings of much larger objects), or objects in regions of the image with unmasked instrumental effects. Often the fitted object then is not the one that we intended to fit. There is also a cautionary flag for offsets above 1\arcsec\ (1.3\,\%).}

\item[Small fraction of model flux within fitting segment (1.4\,\%):]{we flag fits where the amount of model flux (of any component) that falls within the fitting segment is less than 20\,\%. With so little flux to work on \texttt{ProFit} cannot constrain the parameters well anymore and these are often objects which are cut off by a masked region (e.g. a bright star) or other nearby objects. There is a cautionary flag for objects where the fraction of model flux (of any component) that falls within the segment is less than 50\,\% (9.3\,\%).}
\end{description} 


\subsubsection{Model selection}

As detailed in Section~\ref{sec:bayesiananalysis}, model selection in Bayesian analysis is performed by computing the posterior odds ratio, which in turn depends on the marginalised likelihoods for the two models in question. Since this is often difficult to compute in practice, many information criteria tests have been developed which are based on the (non-marginalised) likelihood (or $\chi^2$) combined with some penalty term depending on the number of model parameters. This penalty term serves to judge whether a more complicated model is justified and takes the role of Ockham's factor. Commonly used tests include the Akaike information criterion \citep[AIC,][]{Akaike1974}, the Bayesian information criterion \citep[BIC,][]{Schwarz1978}, or the deviance information criterion \citep[DIC,][]{Spiegelhalter2002}. We choose to use the deviance information criterion, which is usually recommended over the AIC or BIC in Bayesian analysis \citep{Hilbe2017} and straightforward to compute from an MCMC output. Brief tests using the BIC or the estimated log marginal likelihood output by \texttt{LaplacesDemon} showed similar results.

The DIC is a direct output of the \texttt{LaplacesDemon} function (see Section~\ref{sec:galaxyfitting}) and is defined as: 
\begin{equation}
\label{eq:dic}
\mathrm{DIC} = Dev + pD = Dev + \mathrm{var}(Dev)/2,
\end{equation}
where $pD$ is a measure of the number of free parameters in the model and $Dev$\,=\,$-2$\,$\times$\,log-likelihood is the deviance. In theory, then, if the DIC difference $\Delta$DIC between two models is negative, the first model is preferred and if it is positive, then the second model is preferred; with differences larger than approximately 4 being considered meaningful \citep{Hilbe2017}. However, for the case of galaxy fitting where many features are present that cannot be captured by the model (bars, spiral arms, disk breaks or flares, tidal tails, mergers, foreground objects, etc.), we want to choose the model that we consider physically more appropriate rather than better in a strictly statistical sense. This requires visual classification, logical filters, detailed simulations or a manual calibration of the $\Delta$DIC cut (or whichever other chosen diagnostic) by visual inspection of a representative sub-sample \citep[e.g.][]{Allen2006, Simard2011, Vika2014, Argyle2018, Kruk2018, Cook2019, Robotham2022}. We choose the latter approach, which has the added advantages that we do not need to worry about normalising our likelihoods (cf. Section~\ref{sec:galaxyfitting}), hence circumventing dependencies of the results on prior widths; nor the fact that our pixel values are correlated (due to the PSF) -- these effects are simply folded into the visual calibration. 

We use a random sample of $\sim$\,700 non-skipped objects per band (i.e. $\sim$\,2000 objects in total) for the calibration; and a further 1000 $r$-band objects that were previously inspected for cross-checking the results. In addition, our model selection procedure takes into account some of the outlier flagging. 
For each of the $\sim$\,700 objects in each band, we visually inspected the fits of all three models and classified the object into one of the categories: ``single component", ``1.5-component", ``double component", ``not sure if 1.5- or double component", ``not sure at all", ``unfittable" (outlier). We then calculate the DIC differences between all three models (i.e. $\Delta$DIC$_{1-1.5}$, $\Delta$DIC$_{1-2}$ and $\Delta$DIC$_{1.5-2}$) and calibrate them for model selection in two steps: first, we select between single component fit or not; of the ones that are not single component fits we then select between double component or 1.5-component fits.

For the first step of model selection calibration, the $\Delta$DIC$_{1-1.5}$ and $\Delta$DIC$_{1-2}$ cuts are optimised such that the minimum number of fits is classified wrongly. ``Wrong" in this case means a fit was manually classified as ``single" but is now a double/1.5; or a fit was manually classified as ``1.5", ``double", or ``not sure if 1.5 or double" but is now a single. ``Unfittable" and ``not sure at all" cases are ignored. For the second step of model selection calibration, the $\Delta$DIC$_{1.5-2}$ cut is optimised in the same way; where ``wrong" now means that the fit was manually classified as ``1.5" but is now a double or vice versa, with all other categories being ignored. For the two steps of the calibration, we bootstrap the manual sample 1000 and 500 times respectively and repeat the optimisation to get an estimate of the error on the chosen DIC cuts. These errors are chosen as the 1$\sigma$ quantiles (i.e. they contain the central 68\,\% of DIC cut distributions). Hence, all our calibrated DIC cuts have a median, a lower limit and an upper limit. Any object within these limits is flagged as unsure in the model selection, i.e. the DIC differences are not conclusive for this object. 

To perform the actual model selection, the calibrated DIC cuts in each band are then applied to the entire sample, again in a two-step procedure: the single component fit is selected if neither of the 1.5- or double component fits are significantly better (as indicated by the DIC differences). Double component fits need to be significantly better than 1.5-component fits, too. In all cases, if the DIC difference is very clear, we do the model selection first; then flag objects as outliers if needed.\footnote{This means that it is possible (and not uncommon) that a galaxy which is classified as an outlier has a non-flagged fit in another model (but the fit that was chosen was significantly better than the other one, despite it being an outlier).} In the unsure region of the DIC difference, we choose the model that is not flagged as outlier; if neither is flagged, the DIC cut is applied.  

Compared against visual inspection (keeping in mind that visual classification is not free of errors either), roughly 7\,\%, 9\,\% and 6\,\% of the galaxies end up in the wrong category in total in the $g$, $r$ and $i$ bands respectively (in both steps of model selection combined, ignoring cases which were visually classified as ``unsure"). Table~\ref{tab:modelselconfusionr} gives the detailed confusion matrix for the $r$-band. Note that we do not consider the success of the outlier flagging here, so for outliers we show what the galaxy would have been classified as if it were not flagged (absolute value of the \texttt{NCOMP} column in our catalogue). We highlight those galaxies that are correctly classified in bold and show those that were ignored during the model selection calibration process in grey font. The remaining (black) numbers add up to the 9\,\% quoted above. Corresponding confusion matrices for the $g$ and $i$ bands are given in Section~\ref{sec:swappingandoutliers} (Tables~\ref{tab:modelselconfusiong} and~\ref{tab:modelselconfusioni}).
Note that since we minimise the \emph{total} number of fits classed wrongly, there is a slight bias against the rarer categories in the automated model selection. For example, the relative fraction of true 1.5-component objects (as per the visual inspection) that is classified wrongly by the automated selection is higher simply because 1.5-component objects are much rarer than single or double component objects. 

\begin{table}
	\centering
	\caption{The confusion matrix for our model selection based on a DIC difference cut compared against visual inspection for the $r$-band. All values are in percent of the total number of visually inspected $r$-band galaxies. Bold font highlights galaxies classified correctly, while grey shows those that were ignored during the calibration.}
	\label{tab:modelselconfusionr}
	\begin{tabu}{lcrrrc} % number of columns, alignment for each
		\hline
		 & \multicolumn{5}{r}{number of components} \\
		visual classification & & 1 & 1.5 & 2 &\\
		\hline
		``single" && \textbf{41.6} & 0 & 2.7 &\\
		``1.5" && 2.2 & \textbf{2.4} & 0.9 &\\
		``double" && 3.1 & 0.1 & \textbf{9.2} &\\
		``1.5 or double" && 0.3 & \textbf{0.6} & \textbf{3.0} &\\
		\rowfont{\color{gray}}
		``unsure" && 16.1 & 0.4 & 13.1 &\\
		\rowfont{\color{gray}}
		``unfittable" && 0.9 & 0.6 & 2.7 & \\
        \hline
	\end{tabu}
\end{table}

In addition to this band-specific model selection, we perform a joint model selection for all three bands. For this, we sum the DIC values of all three bands for each model before computing the DIC differences. Then we perform the same optimisation procedure as for the single bands (using all $\sim$\,2000 visually classified objects across the three bands) to obtain cuts in DIC difference which we subsequently apply for the model selection. Note that the model selected in this way is by necessity a compromise between the different bands, which have different depth and seeing. In this procedure, approximately 9\,\% of fits are classified wrongly across all bands compared to visual classification. The corresponding confusion matrix is shown in Table~\ref{tab:modelselconfusionjoint} in Section~\ref{sec:swappingandoutliers}.

The accuracy of the model selection is also confirmed using simulations, to the extent to which our simulations allow us to do so (see Section~\ref{sec:simulationsmodelselection} for details).


\subsubsection{Truncating to segment radii}

As detailed in Section~\ref{sec:preparatorysteps}, we produce segmentation maps that define the fitting region, meaning that only pixels within the fitting segment are considered during the evaluation of the likelihood of the model (equivalent to giving all pixels outside the segment zero weight in the fit). We choose tight fitting segments (cf. Section~\ref{sec:preparatorysteps}) in order to obtain the best possible fit in the inner, high signal-to-noise ratio regions of the galaxies and be less sensitive to disk breaks, flares, nearby other objects, sky subtraction problems and similar. The disadvantage of this approach is that profiles are not necessarily forced to zero for large radii, i.e. our S\'ersic fits often show unphysically large effective radii combined with high S\'ersic indices. 

To mitigate this effect, we define a ``segment radius" for each galaxy segment, which is simply the maximum distance between the fitted galaxy centre and the edge of the segment and can be understood as the upper limit to within which our model is valid. We then calculate the ``segment magnitude", $m_{seg}$, which is the magnitude of the (intrinsic, not PSF-convolved) profile integrated to the segment radius (rather than infinity); and the ``segment effective radius", $R_{e, seg}$, which is the radius containing half of the flux defined by the segment magnitude. These values (and quantities derived from them, such as segment bulge-to-total flux ratios) are provided in the catalogue (labelled \texttt{*\_SEGRAD}) and we strongly recommend using these instead of the S\'ersic values integrated to infinity whenever they are available. For a direct parameter comparison to other works, the values in those catalogues should also be appropriately truncated.

In the following, we explain this recommendation in more detail; with further points to note in Sections~\ref{sec:segchoices}, \ref{sec:comparelee} and \ref{sec:systematics}.  %\\

\begin{figure}
    \includegraphics[width=0.5\textwidth]{plots/tightsegmyfit1}
    \includegraphics[width=0.5\textwidth]{plots/tightsegmyfit2}
    \includegraphics[width=0.5\textwidth]{plots/tightsegmyfit1b}
    \includegraphics[width=0.5\textwidth]{plots/tightsegmyfit2b}
    \includegraphics[width=0.5\textwidth]{plots/tightsegleesfit1}
    \includegraphics[width=0.5\textwidth]{plots/tightsegleesfit2}
    \includegraphics[width=0.5\textwidth]{plots/tightseg1Dfit1}
    \includegraphics[width=0.5\textwidth]{plots/tightseg1Dfit2}
    \caption{\textbf{Left:} detailed comparison of our single-S\'ersic fit, our fit using a larger segment, and the \citet{Kelvin2012} fit to the galaxy 214264, which in reality is a 1.5-component system. \textbf{Right:} the same for galaxy 3896188, which is well-described by a single S\'ersic component. \textbf{Top two rows:} our fit to the KiDS $r$-band data with panels the same as those in Figure~\ref{fig:examplefit}. \textbf{Rows three and four:} the fit we obtained by using a larger fitting segment as indicated. \textbf{Rows five and six:} the \citet{Kelvin2012} fits (originally performed on SDSS $r$-band data) evaluated on the KiDS $r$-band data, which use a fitting region larger than the cutout shown. \textbf{Bottom panels:} direct comparison of the one-dimensional profiles, see text for details.
    }
    \label{fig:tightseg}
\end{figure}

Figure~\ref{fig:tightseg} illustrates the effects produced by our tight fitting segments, how to mitigate those by truncating the magnitude and effective radius appropriately; and the circumstances under which this correction is necessary. For two example galaxies - 214264 and 3896188 - we show a detailed comparison of our single S\'ersic fit to both a fit using a larger segment (from \texttt{v05} of our pipeline, see Section~\ref{sec:pipelineupdates}) and to the fit obtained in \citet{Kelvin2012}. We present a more general (statistical) comparison of our fit results to those of \citet{Kelvin2012} in Section~\ref{sec:comparelee}, where we also give more details on how they derived their fits. For the purposes of the analysis in this section it suffices to say that \citet{Kelvin2012} used much larger fitting regions than we do, while the remaining analysis is in many ways analogous to ours (although they use different data, code and procedures in detail). 

Focusing on the left half of Figure~\ref{fig:tightseg}, the top two rows show the KiDS $r$-band data, our single S\'ersic model, the residual and various goodness of fit statistics as described in the caption of Figure~\ref{fig:examplefit}. Rows three and four show the same for a larger fitting segment as indicated by the green contour. Rows five and six again show the same for the \citet{Kelvin2012} fit, where we note that this was originally performed on $r$-band Sloan Digital Sky Survey (SDSS, \citealt{York2000}) data but is now evaluated on the $r$-band KiDS data. The \citet{Kelvin2012} fits were performed on cutouts larger than the size shown here, i.e. they include all visible pixels (and more) in the fit. Note that the reduced chi-squared value quoted in the bottom middle panel of each set of plots always is evaluated within the smallest segment so that they can be directly compared. 

Finally, the bottom panels show a direct comparison of the one-dimensional profiles of all three fits, which we will now study in detail. We show the surface brightness (azimuthally averaged over elliptical annuli) against the projected major axis for the data (solid black line with grey uncertainty region), our model fit for the fiducial segment (dashed blue line) and the larger segment (dash-dotted pink line) and the \citet{Kelvin2012} model fit (dotted orange line). The vertical green solid and dashed lines indicate the segment radii (for the two segment sizes respectively) beyond which our model is an extrapolation. The vertical dotted line shows the half width at half maximum (HWHM) of the PSF and the horizontal dotted line is the 1$\sigma$ surface brightness limit of the data. The inset in the bottom left of this plot shows the fitted magnitude $m$, effective radius $R_e$ in arcseconds and S\'ersic index $n$ values for our and the \citet{Kelvin2012} fits; and the corresponding segment-radius-truncated values for $m$ and $R_e$. Below that, we show the difference between all three models and the data (with errors): our fiducial fit in blue with a dashed line, the fit in the larger segment in pink with a dash-dotted line and the \citet{Kelvin2012} fit in orange with a dotted line.

Our model is a better fit to the inner regions of the galaxy than the \citet{Kelvin2012} fit (out to about 2\arcsec, also evident from the two-dimensional plots and from the reduced $\chi^2$-value within the segment decreasing from 1.84 to 1.08), owing to the higher S\'ersic index which better represents the steep bulge at the centre. However, it has a large effective radius and considerable amounts of model flux at large radii which are not observed in the data. In particular in the region beyond the segment radius, where our model is merely extrapolated, it is clearly oversubtracting the data (also visible in the 2-dimensional plots). Correnspondingly, the truncated segment quantities differ substantially from the fitted S\'ersic values. The \citet{Kelvin2012} fits, instead, use a larger fitting region and hence follow the data out to larger radii, which results in a worse fit of the central regions but does not contain such large amounts of excess flux beyond the surface brightness limit. Hence, truncating to segment radii has a smaller effect on the parameter values. The truncated values for both models are then in reasonable agreement with each other, except for the S\'ersic index, for which no truncated version exists as it would be unclear how to define such a value. Our fit in the larger segment is in between the two others in all respects, since it has a fitting region intermediate to the other two.

Note that the differences only come about when the model is not (in a formal statistical sense) a good representation of the data, i.e. when there is a need to compromise between fitting different regions. In the case of the left side of Figure~\ref{fig:tightseg}, the galaxy shown is better described by a 1.5-component model ($m^B$\,=\,20.47, $m^D$\,=\,18.79, $R_e^D$\,=\,1.89\arcsec), although in general there are many objects in our sample for which even a two-component model cannot capture all aspects of the data. For comparison, in the right half of Figure~\ref{fig:tightseg}, we show a galaxy that is well-described by a single S\'ersic model: here, both our and the \citet{Kelvin2012} fits arrive at virtually the same solution despite the different fitting regions. In fact, all three models and the data are nearly indistinguishable all the way down to the 1$\sigma$ surface brightness limit. 

In short, there is no perfect way to fit a S\'ersic function to an object which intrinsically does \emph{not} have a pure S\'ersic profile. For such objects, which unfortunately comprise the majority of our sample, the fitted parameters will always depend on the exact fitting region used as well as the quality of the data (its depth in particular). Most previous works, including \citet{Kelvin2012}, opted to use large fitting regions in order to include enough sky pixels to ensure that the profiles are constrained to approach zero flux at large radii (although a S\'ersic function technically never reaches zero exactly). Here, we choose a different approach by using smaller fitting segments. This means that the profiles are not constrained to approach zero flux at large radii. Instead more emphasis is placed on adequately representing the inner regions of the galaxies. We choose this approach since it is most appropriate for our science case, where we are primarily interested in comparing the high signal-to-noise regions of galaxies from the same data set amongst each other. 
In addition, it decreases the sensitivity of our fits to deviations from a S\'ersic profile in the low surface brightness wings of objects (arguably no galaxy truly follows a S\'ersic profile to infinity) as well as nearby other objects and inaccuracies in the sky subtraction. 
We stress that this means that our parameters are not directly comparable to other works using larger fitting segments. In particular, our S\'ersic indices tend to be systematically higher (see Section~\ref{sec:comparelee}) since high S\'ersic indices result in high amounts of flux at large radii and are hence suppressed when constraining the models to zero flux at large radii. Magnitudes and effective radii can be compared to those of other studies by truncating to segment radii.  






 
 
 
\section{Pipeline development}
\label{sec:pipelinedevelopment}
This section contains technical details on the development of the bulge-disk decomposition pipeline and the numerous tests performed at various stages during that process with a par\-ti\-cu\-lar focus on the preparatory work. Building on the brief overview over the final \texttt{v04} pipeline in Section~\ref{sec:pipelineoverview} \citep[reproduced from][their section~3; a summary of which can also be found in the description accompanying the \texttt{BDDecomp} DMU on the GAMA database]{Casura2022}, we provide additional information on each step. This includes supplementary tests and diagnostic plots as well as explanations of how we have arrived at each of the decisions listed in Section~\ref{sec:pipelineoverview} and what other options have been explored over the course of the pipeline development. Further, we detail the pipeline evolution from \texttt{v01} through to \texttt{v04}; while the changes made for \texttt{v05} are given in Section~\ref{sec:pipelineupdates}. A summary of the key changes between all five different versions is provided in Section~\ref{sec:bddecompdmu}. 

Note, however, that many of the procedures presented here have been developed in an iterative way since most choices are interconnected and influence or depend on each other (both within the preparatory work pipeline and also for the galaxy fitting). \texttt{ProFit} and even more so \texttt{ProFound} were also actively developed during the time of pipeline development with frequent changes in the procedures and default values, necessitating corresponding adaptations to our routines. Consequently, the decisions presented here were not done in any strict chronolocical order and instead many of the test runs varying all of those parameters were performed and repeated numerous times at different points during pipeline development. We do not describe all of those iterations here, but instead try to summarise the most important findings and give evidence of when each decision was made (be it originally or finally). Unless stated otherwise, the tests in this section have been carried out on the KiDS $r$-band data. 


\subsection{Data inputs and setup}
\label{sec:otherprepworkchoices}
We begin with a more detailed description on the general setup of the preparatory work pipeline and the data products it uses as inputs. 

\subsubsection{KiDS data products}

Before starting the data processing, we needed to decide which of the KiDS data products to use. The basic data unit for KiDS photometric data is a science tile. Each tile is approximately 1\,deg$^2$ or 18500\,$\times$\,19500\,pix$^2$ in size, is astrometrically and photometrically calibrated with a uniform pixel size of $0\farcs2$ and a magnitude zeropoint of zero. They are stacked images (coadds) composed of 5 (4 in $u$) slightly offset (dithered) frames taken in direct succession and arranged to close the gaps between the charge-coupled device (CCD) chips (see details in \citealt{deJong2015, deJong2017, Kuijken2019} and cf. also Section~\ref{sec:kids}). 

Since both re-gridding and stacking of individual exposures can result in problems for accurate photometry (e.g. correlations between pixels, abrupt changes in the background levels or PSF distortions), we briefly considered working with individual dithers instead of the science tiles. However, the dithers are not publicly available which means that they did not benefit from the same analysis and data reduction procedures as the full tiles. In particular, parts of the processing and quality control were performed on the full tiles and not at the individual dither level, see details in \citet{deJong2015, deJong2017, Kuijken2019}, leaving the dithers at a lower data quality. The science tiles, on the other hand, show a very high data quality despite the three main problems of re-gridded and stacked images listed above: pixel correlations are present, but limited to very small scales (see Section~\ref{sec:backgroundstudies}). Abrupt changes in the background levels at the edges of individual CCDs are very rare due to the careful background subtraction performed by the KiDS team before stacking. PSF distortions are minimal since all dithers were taken in direct temporal succession, so the seeing did not vary much between individual exposures. 

We concluded that it is more advisable to use the publicly available science tiles for KiDS, which the team themselves also use to create their photometric catalogues. This also significantly facilitated the data processing and galaxy fitting, especially since \texttt{ProFit} did not yet support multi-frame fitting at that stage. Note that for VIKING data, our decision was different and we decided to use the individual frames instead of the coadds (see Section~\ref{sec:vikingdataproducts}).

Each science tile has an associated weight map and flag image (mask). The weight images give the inverse variance for each pixel in the same flux units as the science tiles. They include information from the dithering pattern, flat fields, dark frames and the first step of the masking: defects that affect individual frames, such as cosmic rays, hot and cold pixels, saturated pixels or satellite tracks are masked in individual frames when adding them up to tiles, with the weight of that pixel (in the final co-add) being reduced accordingly \citep{deJong2015}.

We noted at various points during our analysis (see, e.g., Section~\ref{sec:backgroundstudies}), that the KiDS weight maps are conservatively estimated, i.e. the errors resulting from $1/\sqrt{weight}$ are slightly larger than the typical standard deviation of sky pixels (after our background subtraction and object masking routines). However, in view of the wealth of information included in the weight maps and in particular the strongly and abruptly varying weights across the tiling pattern, we decided it is still better to use those conservative weights than to not use them at all or try to estimate them using \texttt{ProFound}. Due to this, perfect fits (both for PSF estimation and galaxy fitting) usually have $\chi^2_\nu$ values around 0.7 to 0.9 instead of the nominal expectation value of unity. 

In addition to the weight maps, each KiDS tile has an associated mask image. These are mostly produced by an automated procedure developed specifically for the purpose of masking critical areas related to bright stars: saturated pixels, readout spikes due to saturated pixels, spikes caused by diffraction by the mirror supports and up to three reflection halos produced by the optics components \citep{deJong2015}. In addition, for DR1.0 and DR2.0, defects not related to bright stars were manually masked. In DR3.0 the manual masks were not included \citep{deJong2017}. For DR4.0 a semi-automatic procedure was then developed which includes the majority of these remaining issues with minimal manual intervention \citep{Kuijken2019}. 

The masks are binary flags where each of the affected areas has a different value. It is therefore possible to exclude only certain types of areas, such as saturated pixels, while still using those in others, e.g. weak tertiary reflection halos. However, we have decided against such an approach and instead mask all pixels with a flag value greater than zero. This results in approximately 20\,\% of pixels being masked out in $gri$ and correspondingly, $\sim$\,20\,\% of galaxies in our sample are skipped since their centre is masked. This is a large fraction, but it is not a limiting factor to our analysis. Our emphasis is on obtaining the most directly comparable fits to a statistically large sample of galaxies, for which it is optimal to use this highest data quality and treat all bands consistently. The sample size could instead be increased by including more galaxies at higher redshift if desired. 

If there is a particular interest in individual masked galaxies, it is still possible to re-run those ignoring some or all of the mask values. We have done this in the context of a Master's project focusing on AGN, of which there are only few in our sample (Targaczewski in prep.). However, this in turn required careful visual control of the resulting fits. For our own large scale automated analysis, it is hence preferable to use all flag values as masks. Importantly, the masks will randomly affect all types of galaxies and therefore not introduce any bias in our statistical analysis. 

In summary, we opt to use the KiDS science tiles with associated weight maps and masks, including all binary flag values. For \texttt{v01} and \texttt{v02} of the \texttt{BDDecomp} DMU we used KiDS DR1.0, DR2.0 and DR3.0, which were incremental data releases and together cover all of the GAMA equatorial regions. From \texttt{v03} onwards, we moved to KiDS DR4.0, which became newly available then. This did not add any tiles in our region of interest which was complete already in DR3.0. However, in contrast to the previous incremental data releases, DR4.0 was a complete re-release of all tiles with a number of processing changes. Most notably, the re-processing included a photometric homogenisation across all tiles (see \citealt{Kuijken2019}). DR4.0 therefore supersedes all previous KiDS data releases. 

\subsubsection{Pipeline setup}

Given the list of galaxies in our sample and the list of KiDS tiles with associated weight maps and masks, the first decision to make is whether one should work on a ``per-galaxy-basis", i.e. taking cutouts of the corresponding tile(s) for each galaxy or a ``per-tile-basis", i.e. treating all galaxies within a tile at the same time. We opted to work on the galaxy level, mostly due to computational memory limits since the tiles are rather large ($\sim$\,1.5\,GB each). Hence for each galaxy in our sample, we find the corresponding RA and Dec position from the GAMA database, identify the tile(s) that this position falls into and take a cutout around the galaxy position, with corresponding cutouts taken from the weight and mask images. 

This approach also has the advantage that the galaxies, which are the more physically meaningful quantity, are taken as the basis instead of the tiles, which can vary in different datasets. This allowed a relatively easy expansion from KiDS to VIKING data; and - in that context - a switch from treating several data matches to the same galaxy individually to treating them jointly (see Section~\ref{sec:pipelineupdates}). It also facilitates multi-band fitting, which we will attempt in future work. 

The relatively large cutout size of 400\arcsec\,$\times$\,400\arcsec\ was chosen to allow for a reasonable number of stars for PSF estimation (see Section~\ref{sec:psfdetails}); but is small enough to be handled computationally without problems. All preparatory work (image segmentation, background subtraction, PSF estimation) is carried out on these cutouts. We then further reduce the cutout size to only the region of interest around the galaxy itself before storage and subsequent galaxy fitting (see Section~\ref{sec:preparatorysteps}). 

Note that we have decided to split the pipeline into three main steps: the preparatory work, the galaxy fitting and the post-processing (Section~\ref{sec:pipelineoverview}). After each of these steps, the results are stored to disk. This has the advantages that the galaxies can be fitted with different models or procedures using the same preparatory work; and that the galaxy fitting is better reproducible since all inputs are stored in the preparatory work directory. Also, the post-processing is more flexible in the sense that e.g. model selection and outlier flagging can be re-calibrated without having to re-fit any galaxies. This is particularly important since the galaxy fitting takes the vast majority of computational time, with the preparatory work contributing around 2-3\,\% of the total run-time (6-7\,\% for VIKING) and the post-processing being negligible. Since each galaxy is treated independently of all other galaxies, the pipeline runs in parallel on many cores. 



\subsection{Background subtraction choices}
\label{sec:backgroundstudies}
After the trivial step of taking cutouts, the first main task of the preparatory work pipeline is to perform image segmentation to identify the pixels that belong to the object of interest and mask out neighbouring sources. This, however, is intimately linked to the background subtraction, since a reliable source identification needs a well-known background estimate and vice versa. Hence, the main function of \texttt{ProFound}, \texttt{profoundProFound}, iteratively performs image segmentation and background subtraction simultaneously by default. However, since KiDS image tiles are already background-subtracted, the question arose as to whether we should use this \texttt{ProFound}-estimated sky (e.g. to even out smaller-scale background inhomogeneities and to make the treatment of KiDS data more comparable to the treatment of VIKING data) or set it to zero a priori. 

In addition, \texttt{ProFit} has the option to fit a constant background along with the source(s) of interest, which could also be used for local sky estimates instead of or in addition to the \texttt{ProFound}-estimated sky. We will refer to the former as (\texttt{ProFit}) background fitting and the latter as (\texttt{ProFound}) sky subtraction. Note that the two methods are not equivalent and describe slightly different ``types" of sky: \texttt{ProFound} explicitly attempts to exclude faint undetected background sources and extended low-surface brightness wings of objects, while \texttt{ProFit} includes all undetected light in the background estimate (see details below).

Hence, the main choices to make with regards to background subtraction are whether or not to use the \texttt{ProFound}-estimated sky and/or fit a constant background with \texttt{ProFit} along with the source (in addition to the background subtraction already performed by the KiDS team); and if so, which algorithms and options to use for the background estimation. Interconnected choices are how deep to go in the object detection (most strongly influenced by the value of \texttt{skycut} in \texttt{profoundProFound}) and how large to make the segments for fitting objects. 

The decisions made with regards to these choices are summarised in Table~\ref{tab:bgdecisions}. In the following, we give more details on the metrics that we used to inform these choices. Note that these studies were only performed on KiDS $r$-band data. The final pipeline uses a joint treatment of the $g$, $r$ and $i$ bands as described in Section~\ref{sec:preparatorysteps} and has been updated in many other respects, too. However, the choices made at this stage remained. We also note that while we focus on the background subtraction in this section, we inevitably touch upon image segmentation, too. In particular, we discuss the choices made for object masking during background estimation, while the details of the segmentation maps used for the galaxy fitting are de-coupled (one of the choices made during the background studies) and explained in more detail in Section~\ref{sec:segchoices}. 

\begin{table}
\begin{center}
\caption{Sky subtraction/background fitting choices}
\label{tab:bgdecisions}
\begin{tabular}{|l|l|}
\hline
Choice to make & Decision made\\
\hline
Perform \texttt{ProFound} sky subtraction & Yes \\
Sky box size & 1/4 of large cutout side length, i.e. 500\,pix or 100\arcsec\\ 
Sky grid size & Equal to sky box size (default)\\
Interpolation type & Bilinear (default) \\
Clipping & Yes (default)\\
Type of sky estimate & Median (default)\\
\hline
Improve sky with FFT & Yes up to \texttt{BDDecomp v02}, then no\\
Object masking (for FFT) & Aggressive \\
\hline
Perform \texttt{ProFit} background fitting & No \\
Size of cutout to fit & Star segment only\\
Skycut value (see Section~\ref{sec:segchoices}) & 1 for sky subtraction, 2 for object fitting\\
\hline
\end{tabular}
\end{center}
\end{table}



\subsubsection{\texttt{ProFound} sky subtraction}

As a first metric to judge the effects of different sky subtraction options, we use the distribution of \texttt{ProFit} backgrounds fitted to stars used during PSF estimation around a test sample of $\sim$\,200 galaxies (one in each KiDS tile, approximately uniformly distributed across the galaxy magnitude range). The stars have the advantage that they show much less variation than galaxies and can usually be (near-)perfectly fitted with \citet{Moffat1969} functions. They also do not suffer from PSF uncertainties since they do not need PSFs; they are more numerous than our galaxies and fitting them is much faster since simple downhill gradient algorithms suffice for such simple systems. In the following, we give a brief overview of the main results of these detailed investigations. 

\begin{figure}
\begin{center}
	\includegraphics[width=0.8\textwidth]{plots/bgdistribution}
	\includegraphics[width=0.8\textwidth]{plots/bgdistexample}
    \caption{\textbf{Top panel:} the mean (circles), median (diamonds) and standard deviation (crosses) of the distribution of fitted \texttt{ProFit} backgrounds as a function of the fitting cutout size and with (blue) or without (red) previous \texttt{ProFound} sky subtraction. For the largest cutout size, we additionally show the effect of the chosen box size for sky subtraction (black, green, yellow). \textbf{Bottom panel:} the full distribution of backgrounds for the largest cutout size (corresponding to the rightmost set of symbols in the top panel).}
    \label{fig:bgdistribution}
\end{center}
\end{figure}


For Figure~\ref{fig:bgdistribution}, we fitted a constant background in addition to the Moffat parameters to a few thousand stars around a random test sample of galaxies using \texttt{ProFit}. We used all pixels within a square cutout around the star for fitting, except those that are identified as belonging to other objects during the segmentation procedure. The cutout side length ranges from 6 to 30 times the FWHM of the PSF given in the header of the corresponding KiDS tile, which is typically around 0.6-0.8\arcsec. The top panel shows the mean, median and standard deviation of the distribution of fitted backgrounds (in arbitrary units of flux since the cutouts were normalised before fitting) for different cutout sizes and for the two cases of also performing a \texttt{ProFound} sky subtraction before fitting (blue symbols) or not (red symbols). 
For the largest cutout size, we also show results for different sky box sizes, which is set to the fiducial value of 100\arcsec\ for all other runs: black symbols denote an increase in the box size by a factor of 2, while green and yellow symbols represent a decrease by a factor of 2 and 4 respectively. 
The bottom panel shows the full distribution of fitted backgrounds for the largest cutout size, corresponding to the rightmost set of symbols in the top panel. 

For small cutout sizes, the distributions are clearly biased positive (top panel of Figure~\ref{fig:bgdistribution}), i.e. the background fit is dominated by the wings of the star. For larger cutout sizes, the distributions then converge onto a slightly positive or negative value (with and without \texttt{ProFound} sky subtraction respectively). In general, the distributions with \texttt{ProFound} sky subtraction are slightly narrower and more symmetric than those without (i.e. the standard deviation is smaller and the mean and median are closer together). Due to these reasons (width, asymmetry and convergence onto negative values for non-\texttt{ProFound}-sky-subtracted images), we concluded that the \texttt{ProFound} sky subtraction is useful to even out smaller-scale inhomogeneities even though KiDS images are already background subtracted. In addition, it will make the comparison to VIKING data (which have potentially different backgrounds to KiDS) more consistent. 

The fact that the mean and median of the fitted distributions with previous sky subtraction converge onto a positive value instead of zero is expected due to the different ``types" of sky that are estimated by the two options: \texttt{ProFit} will estimate a slightly higher sky than \texttt{ProFound} because the former simply uses all non-object pixels while the latter explicitly tries to avoid being biased by undetected (wings of) objects by clipping outliers and using the part of the flux distribution smaller than the mode only to estimate the median and standard deviation of the background in each box. 
 
The box size should be chosen as small as possible to be able to detect small-scale inhomogeneities in the background, yet larger than the largest (complexes of) objects so as to not subtract their wings. For our purposes, we found a box size of 100\arcsec\ to be suitable. Increasing the box size by a factor of two only increases the standard deviation of the distribution, but does not change the mean or median. Decreasing the box size by a factor of two decreases the standard deviation but also shifts the mean away from the median, making the distribution more skewed. Decreasing the box size by a factor of four (i.e. to 25\arcsec) makes the distribution significantly more asymmetric and - upon visual inspection of a random sample of fitted backgrounds - also reveals clear correlations between the fitted background and the location of objects in the images. Hence the box size of 100\arcsec\ seems to be optimal in that it is independent of the object distribution yet still detects some small-scale background variations. 

We also varied other parameters to test their influence on the sky estimate (grid size on which to place the boxes, bilinear or bicubic interpolation between boxes, clipping outliers or not, using the mean or median for the sky estimate, dilating the object masks more or less) but have found either little influence or adverse effects on the sky estimate. Hence we decided to use the \texttt{profoundProFound}-defaults for these parameters, which were optimised for typical optical and NIR survey data (such as KiDS) during the development of \texttt{ProFound} \citep{Robotham2018}.

Finally, we should mention that we have also carried out tests where we divide each of the \texttt{ProFit} background fits by its respective error and investigate the resulting distributions. In theory, this should result in a Gaussian with mean zero and standard deviation one. A small positive shift away from the mean is to be expected according to the previous analysis, although much smaller than one standard deviation (Figure~\ref{fig:bgdistribution}). A standard deviation larger than one would indicate that the background offset (i.e. the positive shift) is not constant for different cutouts. This analysis, however, relies on realistically estimating the uncertainty of the fitted background value. We have tried this in two different ways: either during the downhill gradient fitting with \texttt{optim} (see Section~\ref{sec:preparatorysteps}) or directly from the KiDS weight map. Both methods have unresolved problems, so we did not use these results further and only add a short description here for completeness. 

In the first case, we use \texttt{optim}'s option to return the Hessian along with the best fit value of all parameters. The diagonal elements of the inverse of the Hessian matrix are the variances of the parameters and hence the entry corresponding to the background fit can be used to estimate its uncertainty (ignoring covariances and systematic uncertainties). For unknown reasons, however, the variance of the background was often negative, resulting in an imaginary standard deviation. Taking the absolute value before taking the square root gives errors of the correct order of magnitude, such that the normalised background distributions then have a standard deviation of approximately one and a slight positive offset.

For the second approach, we use the fact that each background pixel is drawn from a normal distribution with a standard deviation given by $\sigma$\,=\,1\,/\,$\sqrt{weight}$. \texttt{ProFit} essentially finds the mean of this background in each cutout weighted according to the errors ($\sigma$). The error on the mean (uncertainty coming from randomness that cannot be avoided) is $\sigma_{bg}$\,=\,$\overline{\sigma}/\sqrt{N}$ where $\overline{\sigma}$ is the mean of $\sigma$ and $N$ the number of pixels used to fit the background. This ignores any possible correlations between pixels or fitting parameters and assumes that the weight map is an accurate representation of the true errors on pixels. The problem with this estimate is that it results in background uncertainties that are approximately a factor of five smaller than those estimated from the Hessian; and the background fit distributions are correspondingly broader. 

It is unclear why the two methods provide such different results for the background uncertainty. There are correlations between pixels on small scales (see below) that will additionally contribute to the uncertainty estimated from the weight map, but this is unlikely to explain a factor of five. Correlations between parameters are ignored in both cases and hence cannot explain the difference. The weight maps tend to be on the conservative side compared to the true pixel errors (see Section~\ref{sec:otherprepworkchoices}), but this also does not explain a factor of five and moreover would tend to make the difference even larger if corrected for. Given these open issues, we decided to focus on the distribution of fitted backgrounds in absolute values as presented above; and did not consider the normalised distributions further. 


\subsubsection{\texttt{ProFit} background fitting}

Since the above analysis relies on the distribution of fitted \texttt{ProFit} backgrounds as a metric, it does not allow to decide whether or not the fitted background should be used in addition to the \texttt{ProFound} estimated sky. Therefore, as a further test, Figure~\ref{fig:psfstack} shows the systematic differences that occur in the PSF estimates as a function of the different background fitting and cutout size options. This now uses the model PSFs estimated for the 223 test galaxies (one in each KiDS tile within our region) rather than the fits to individual stars. For any two runs, the differences between the 223 pairs of model PSFs are calculated and then added together (stacked) to show systematic trends. Ideally, PSF estimates should be robust against changes in the processing details (e.g. the cutout sizes used for fitting them), such that the differences should be small. 


\begin{figure}[ht!]
	\includegraphics[width=\textwidth]{plots/psfstacks}
    \caption{Stacked differences between model PSFs obtained from test runs with different combinations of \texttt{ProFound} sky subtraction (sky sub), \texttt{ProFit} background fitting (bg fit) and cutout sizes as labelled. \textbf{Top row:} the difference between model PSFs obtained by fitting or not fitting a \texttt{ProFit} background for four different combinations of \texttt{ProFound} sky subtraction and cutout size as labelled in the panels. ``Small" cutouts refer to a side length of 6 times the PSF FWHM, ``large" means 18 times the FWHM. \textbf{Middle row:} the difference between model PSFs obtained with \texttt{ProFound} sky subtraction vs. those obtained without, for four different combinations of \texttt{ProFit} background fitting and cutout sizes, as indicated. \textbf{Bottom row:} the difference in model PSFs obtained from fitting large or small cutouts for four different combinations of \texttt{ProFound} sky subtraction and \texttt{ProFit} background fitting, as labelled.}
    \label{fig:psfstack}
\end{figure} 

The first row shows the difference between fitting a \texttt{ProFit} background or not for four different combinations of cutout size and \texttt{ProFound} sky subtraction as labelled in the panels. The larger cutouts (first and third panel) show less of a difference than the smaller cutouts. Note, for comparison to Figure~\ref{fig:bgdistribution}, that ``small" cutouts always mean 6 times the PSF FWHM given in the header, while ``large" cutouts refer to 18 times the PSF FWHM (we unfortunately did not perform these test runs with larger cutout sizes than this due to the order in which the decisions were originally taken). For both cutout sizes, there is also less of a difference in the fitted PSFs without \texttt{ProFound} sky subtraction (third and fourth panel) than with. This means that performing a \texttt{ProFit} background fit on the already-\texttt{ProFound}-sky-subtracted image systematically changes the PSF estimate - likely because there is no background left to fit and so the additional degrees of freedom are used to change (improve) the PSF fit instead. Note all residuals here are positive at the centre, indicating that fitting a \texttt{ProFit} background generally makes the PSFs more peaked at the centre.

The second row shows the difference between subtracting a \texttt{ProFound} sky or not for four different combinations of cutout size and \texttt{ProFit} background fitting. The second and fourth panels which show differences for small cutouts show negative residuals while the first and third panels (large cutouts) show positive residuals. In general, all residuals are small, which confirms that the PSF estimate is generally robust against performing a \texttt{ProFound} sky subtraction or not (i.e. the sky subtraction does not subtract the wings of the PSF or similar). The best results (i.e. smallest residuals) are obtained using the large cutouts and no \texttt{ProFit} background fitting (third panel). When using smaller cutouts there seem to be less residuals with \texttt{ProFit} background fitting (second panel) than without (fourth panel). This can be interpreted as follows: for small cutouts, the star dominates the cutout region, so the \texttt{ProFound} sky subtraction does not influence the fit of the star. This is even clearer when we additionally fit a background within the small cutout region. For larger cutouts, the PSF estimate is also robust against performing a \texttt{ProFound} sky subtraction or not, provided no additional \texttt{ProFit} background is fitted. An additional background fit makes the PSF estimate dependent on the sky subtraction (first panel), most likely because now the fit has too many degrees of freedom. 

The third row of Figure~\ref{fig:psfstack} shows the difference between a large and a small cutout for four different combinations of \texttt{ProFound} sky subtraction and \texttt{ProFit} background fitting. As observed before, the most robust results are obtained with \texttt{ProFound} sky subtraction only (third panel). Both results using \texttt{ProFit} background fitting (first two panels) are more dependent on the cutout size used.

As a result of these studies, we saw our decision to use the \texttt{ProFound} sky subtraction reinforced and decided to not use additional \texttt{ProFit} background fitting: after \texttt{ProFound} sky subtraction, the background is homogeneous enough that an additional \texttt{ProFit} background fitting changes the PSF rather than fitting the actual background. Also, as evident from Figure~\ref{fig:bgdistribution}, we need very large cutouts for robust \texttt{ProFit} background fits. This has problems on its own as it will necessarily lead to more contamination from the wings of other objects or undetected faint objects (masking is never perfect), increases the chance of hitting an image edge or masked area, and increases computational time. In addition, there is a degeneracy between the fitted background and the concentration index of the Moffat parameter in that it can never be unambiguously determined whether the background is used to fit the wings of the star or the wings of a low-concentration Moffat function are used to fit the background (or wings of other objects).\footnote{Similar arguments apply to the S\'ersic index of a galaxy.} For very large cutout sizes, the star may even become insignificant relative to the background so that the fitting does not focus on the main object of interest anymore (and instead the Moffat function is used primarily to even out background inhomogeneities). Fitting galaxies introduces a wealth of additional problems if their outskirts do not follow S\'ersic functions anymore, e.g. due to disk breaks, flares, rings and similar (cf. Section~\ref{sec:postprocessing}). 

In summary, we opted to use the \texttt{ProFound} estimated sky with default parameters except for the box size of 100\arcsec; but not to perform an additional \texttt{ProFit} background fit. This in turn allows to use tight segmentation maps for fitting. These choices were made before the first DMU release and hence did not change between \texttt{v01} and \texttt{v04}. 
 

\subsubsection{Pixel correlations}

To detect problems in the sky subtraction and object masking, an analysis of correlations between pixels can be useful. \texttt{ProFound} offers a set of functions to achieve this via a Fast Fourier Transform (FFT) of the normalised image (each pixel divided by its error) after sky subtraction and object masking. This FFT image gives information on the pixel correlations on different spatial scales. In the ideal case, this should result in pure uncorrelated white Gaussian noise. The idea then is that power on small scales represents undetected sources, while on larger scales it captures complex features of the sky background. 

For KiDS images, we expect some residual correlation on small spatial scales. This is mainly because before stacking, all KiDS frames have been re-gridded onto the same pixel scale of $0\farcs$2 from their native scales of $\sim$\,0$\farcs$21. This ensures that the tiles are pixel-matched across all four bands with the axes aligned in RA and Dec (see Sections~\ref{sec:kids}, \ref{sec:preparatorysteps} and \citealt{Kuijken2019}). However, it will also introduce correlations on very small scales. In addition, there can be intrinsic instrumental correlations, typically on the scale of a few pixels. Investigating these in detail goes beyond the scope of this work. The PSF, although it is several pixels across, is not expected to play a significant role for seeing-limited data such as KiDS since most noise is ``added" at a later stage. For perfect sky subtraction and object masking, we hence expect correlations to reach zero beyond the scale of a few pixels. In practice, we might expect a small positive excess resulting from very faint, individually undetectable objects. 

\begin{figure}
	\includegraphics[width=0.5\textwidth]{plots/pixcorrandom}
	\includegraphics[width=0.5\textwidth]{plots/pixcorregrid}
	\includegraphics[width=0.5\textwidth]{plots/pixcornormal}
	\includegraphics[width=0.5\textwidth]{plots/pixcornoskysub}
	\includegraphics[width=0.5\textwidth]{plots/pixcorfitseg}
	\includegraphics[width=0.5\textwidth]{plots/pixcornoseg}
	\includegraphics[width=\textwidth]{plots/pixcorlegend}
    \caption{Correlations between pixels for \textbf{A)} a random noise image, \textbf{B)} a random noise image with pixel upsampling by 5\,\%, \textbf{C)} a real image around the example galaxy 396740 (the same as in Figure~\ref{fig:exampleseg} for comparison) treated as in the final pipeline, \textbf{D)} the same real image as C), but leaving out the \texttt{ProFound} sky subtraction during treatment, \textbf{E)} the same real image as C) but using tighter segmentation maps for object masking (coloured instead of grey contours in Figure~\ref{fig:exampleseg}) and \textbf{F)} the same real image as C) without any object masking. The left panels always show the correlogram, i.e. pixel correlation versus pixel lag in $x$ and $y$, with the meaning of the different lines indicated by the legend at the bottom of the plot. The bottom panel is a zoom (on the $y$-axis) into the top panel. The images to the right of the correlograms show the corresponding FFT image, scaled such that excess power is white (phase ignored, asinh scaling) and small scales are at the centre of the image.}
    \label{fig:corplots}
\end{figure}

Figure~\ref{fig:corplots} shows the main diagnostic outputs produced by the \texttt{profoundPixelCorrelation} function for six different input images (A-F). In the left panel of each set of plots, we show a so-called correlogram: pixel correlation as a function of $x$ (RA) and $y$ (Dec) pixel lag (solid blue and red lines respectively). In addition, the dashed lines show the difference between the correlations of positive pixels and those of negative pixels (also in $x$ and $y$); while the dotted lines indicate the pixel lag implied relative standard deviation. All correlograms are shown once with a $y$-axis range of -1 to 1 (top of the left panels) and once as a zoom into the range -0.1 to 0.1 (bottom). The $x$-axis is the same for all correlograms, ranging from a lag of 1 pixel to 2000 (the image size) on a logarithmic scale. Generally, a positive excess in this plot indicates that object detection or sky subtraction are not aggressive enough, while systematically negative correlations suggest that the image contains large pools of negative pixels, hinting towards problems in the sky subtraction. To the right of each set of correlograms, we show the corresponding two-dimensional FFT image, where white colour means a relative excess power (phase ignored) and small scales are centrally located. Note the linear axes scales compared to the logarithmic $x$-axis of the correlogram; while conversely the colour scale now uses an asinh stretching instead of the linear $y$-axis of the correlogram. While the quantitative interpretation of these images is less straight-forward, they can be used to detect correlations at different scales and in different directions at least qualitatively. In both cases, masked pixels (including those identified as belonging to objects) are excluded from the analysis by \texttt{ProFound}. 

Starting from the top left, the first set of panels A), show the result obtained for a generated image of pure Gaussian noise with a mean of zero and standard deviation of one. As expected, the pixel correlations are zero on all scales, with the standard deviation being one. The exception is the last data point (at 2000 pixels), where the lines diverge due to unrealiable low number statistics once we reach the image size. We hence only consider values up to 1000\,pix on the $x$-axis for all correlograms. Correspondingly, the FFT image contains no structure (showing that the random number generator is working well). This respresents the ideal case which we would like to achieve for our real images (after sky subtraction and object masking), but are likely to never fully reach given the limitations explained above.

Panels B) show the first step of complications that is known to exist in real (KiDS) images: pixel correlations due to the resampling of the raw images before stacking. For this analysis, we have created a random noise image of slightly smaller dimension (1905\,$\times$\,1905\,pix$^2$), which we have then upsampled onto the usual 2001\,$\times$\,2001\,pix$^2$ grid and subsequently passed through the FFT analysis. This roughly corresponds to the upsampling performed by the KiDS team from a native instrumental pixel scale of $\sim$\,0$\farcs$21 to 0$\farcs$2 in the tiles. This introduces correlations on small scales (up to $\sim$\,3\,pix), which are clearly visible in the correlograms. Since positive and negative pixels are equally affected by the upsampling, the difference between positive and negative correlations (dashed lines) stay zero. Note, however, that since we have not corrected the weight map (which is uniformly one for a random image of standard deviation one), the pixel lag implied standard deviation is now below one (i.e. the true standard deviation of the upsampled pixels is smaller than one). 

Panels C) show the results obtained for one of our real images after sky subtraction and object masking with our final pipeline. We choose the same example galaxy as that shown in Figure~\ref{fig:exampleseg}, to allow a direct comparison with the segmentation maps. The most striking feature here is the characteristic pattern of correlations at very small scales, which - judging from panels B) - we mostly attribute to the upsampling (and possibly intrinsic instrumental effects on small scales, which we did not investigate). These features consistently persist for all images (although we only show one example here). Beyond a scale of $\sim$\,3\,pix, the correlation drops to zero rapidly, although a small excess can be seen at scales up to 10\,pix, maybe even up to 100\,pix. These correlations are also visible as a faint white dot at the centre of the FFT image. However, there seem to be no asymmetries in our analysis (no structure in the FFT, $x$ and $y$ correlations always the same, negative and positive pixels affected equally). Note that the standard deviation is also slightly below one here, implying that the true standard deviation of background pixels (after sky subtraction and object masking) is slightly smaller than that implied by the weight maps provided by KiDS. We discuss this further in Section~\ref{sec:otherprepworkchoices}.

Panels D) show the same as panels C), only that in this case, we do not perform the \texttt{ProFound} sky subtraction. The plots are nearly indistinguishable from those in panels C), demonstrating that pixel correlations are neither introduced nor removed by our sky subtraction procedure and instead correlations are primarily caused by remaining undetected objects. Since the box size of the sky substraction is 100\,\arcsec\ or 500\,pix (Section~\ref{sec:preparatorysteps}), we only expect effects on large scales here. 

We test the effect of undetected (wings of) objects in panels E), where we use a tighter segmentation map for object masking. Instead of the segmentation map generated for the background estimation, we use that produced for fitting the galaxies (cf. Section~\ref{sec:preparatorysteps} and Figure~\ref{fig:exampleseg}: here, we use the coloured contours instead of the grey ones for object masking). This goes less deep in both object detection and segment dilation. In other words, we mask less of the faintest objects; and the regions masked around each (bright or faint) object are smaller. This results in a clear positive excess at scales up to $\sim$\,100\,pix. The dashed lines also deviate from zero at these scales, indicating that positive pixels are more correlated on average than negative pixels (since the undetected sources of light are all positive). The FFT shows a corresponding white dot at its centre, but no additional two-dimensional structure. 

Finally, panels F) show the pathological case of ignoring the segmentation map alltogether, i.e. no objects are masked (except for those that are saturated and hence included in the KiDS masks already at an earlier stage). The correlation of pixels reaches values near unity for small scales and is substantial up to scales of 100\,pix or even beyond. The dashed lines closely follow the solid lines, indicating that this is entirely caused by correlations between positive pixels (i.e. there are no negative flux objects in the image). The asymmetry between $x$ and $y$ correlations at scales of $100-200$\,pix is unique to this particular image and not generally visible for other example galaxies. The corresponding FFT image also shows a large power excess at scales up to several hundred pixels. 

In conclusion, our procedure for background subtraction and object masking seems to remove the vast majority of correlations between pixels, with only the characteristic features of up-sampled pixels remaining at very small scales; and a slight excess caused by faint, individually undetectable objects at slightly larger scales. It is, however, important to use the very agressive, deep and highly dilated object mask that we generate for accurate background subtraction; rather than the tighter fitting segmentation map (for details on the latter, see Section~\ref{sec:segchoices}). For this reason, we eventually decided to use two separate segmentation maps for these two processes, to better accommodate the different aims that we try to achieve with them (cf. Section~\ref{sec:preparatorysteps}). This change came into effect with \texttt{v03} of the \texttt{BDDecomp} DMU. 

In addition to the above, it should be mentioned that \texttt{ProFound} offers a function to improve an already-estimated sky on the basis of an FFT analysis (\texttt{profoundSkySplitFFT}). The idea is that, on large scales, excess power captures complex features of the sky background that cannot be described by the bilinear or bicubic interpolation between boxes that is performed by \texttt{profoundProFound}. Hence, this part of the FFT image can be used to refine the sky estimate; the ``new" (refined) sky is returned by the function. In early versions of the pipeline (up to the release of \texttt{BDDecomp v02}), we have used this refined sky. However, starting from \texttt{v03} we reverted to using the ``original" sky estimated by \texttt{profoundProFound} since it turned out to be more robust especially in crowded fields and/or in the presence of nearby masked objects, image edges and artifacts. On the other hand, for ``well-behaved" fields there is very little structure to be removed on large scales (see Figure~\ref{fig:corplots}). Hence for most images, this additional step of sky refinement had very little effect, while for some fields it had adverse effects (also confirmed by simulations). For our large automated analysis with varying image properties and intrinsically relatively flat sky, we therefore found \texttt{profoundSkySplitFFT} to be unsuitable. %\\ 


\subsection{PSF estimation details}
\label{sec:psfdetails}
The last major step in the preparatory work pipeline is the PSF estimation. An accurate and precise estimate of the PSF is crucial to the success of the galaxy fitting. Any deviations of the model PSF from the truth will introduce systematic uncertainties in the galaxy parameters that are not easily accounted for. Unfortunately, however, the PSF estimation is not straight-forward as there are many uncertainties involved and choices to make: how to identify and select stars suitable for PSF estimation, which function and algorithm to fit them with (or whether to fit them in the first place), how many stars to use and how to combine the different estimates into a final model PSF for each galaxy of interest.

In view of these difficulties, we first contacted the KiDS team to ask whether they would be able to provide PSFs even though they are not publicly released. The team were willing to provide PSFs in the form of shapelet functions for each tile. However, these are not the PSFs that the team use for their own weak lensing analyses, since those are performed on individual pawprints rather than stacked tiles. They did therefore not undergo a detailed quality control. A brief comparison with a selection of stars in a number of test tiles showed that the shapelets did not fully capture the extended wings of some PSFs. In addition, we already anticipated the addition of VIKING data, for which there are no such shapelets available. We therefore decided that it would be best to devise our own method of PSF estimation to obtain consistent estimates in all bands and have full control over their quality. 

Since PSF estimation using \texttt{ProFound} and \texttt{ProFit} has not previously been performed, there were no established procedures for us to follow. Consequently, our treatment was developed as a mixture between theoretical considerations, procedures that have proven to work well with other software and a considerable fraction of trial and error combined with visual inspection of the results. A very brief overview of the resulting process is given in Section~\ref{sec:preparatorysteps}. Here, we describe the treatment in much more detail, explaining some of the reasons for our choices and other possibilities that we explored. We finish with an overview of the PSF quality control and its effects on the galaxy fitting.

Many of the details changed during the pipeline evolution. For example, the star candidate selection process depends on certain cuts that need to be adjusted when making significant changes to the way segments are defined (i.e. between \texttt{v02} and \texttt{v03} of the \texttt{BDDecomp} DMU). Since these cuts were mostly tuned by visual inspection and also changed frequently between test runs, we do not give detailed justifications for each pipeline version and instead focus on the status quo in \texttt{v04} (which is also what \citealt{Casura2022} is based on). We note that, while the detailed numbers may have changed several times, the overall procedure remained the same.


\subsubsection{Star candidate selection} 

The first decision to make is whether to estimate PSFs separately for each individual object of interest, or fit all stars in a large region (e.g. an entire KiDS tile) at once and then interpolate the solution for each position of interest. Both approaches have their advantages and disadvantages. We took the first approach, whereby for each position of interest we independently estimate a PSF. This has the benefits that local PSF variations are captured without worrying about interpolation uncertainties. It also allows to flexibly change or improve individual PSFs without having to re-fit all stars in the field; and it allows to use the independent PSF estimates of neighbouring galaxies for quality control (see below). In addition, it is straightforward to handle computationally since it can just be done along with the local background subtraction and other preparatory work that is run for each galaxy. 

Disadvantages of this approach are that each individual PSF estimate is based on a relatively low number of stars (to keep it local), potentially introducing more noise; and that there will be a number of galaxies with missing PSFs if no suitable nearby stars are available (for example because large areas in the vicinity of the galaxy are masked). However, the latter only affects less than 1\,\% of galaxies (see Table~\ref{tab:results} in Section~\ref{sec:statistics}) the majority of which tend to be in regions of decreased data quality (near bright, saturated stars, image edges or artifacts). To decrease the noise on our PSF estimates, we introduce a fitting step with \texttt{ProFit} instead of - as is sometimes done in other software - just averaging a large number of star cutouts. We find the fitted Moffat parameters for stars near each other to be very consistent (see below). 

In summary, we perform PSF estimation on the single-band 400\arcsec\,$\times$\,400\arcsec\ cutouts with associated sigma (error) maps and masks, after background subtraction and image segmentation. For \texttt{v04} of the pipeline, we use the segments from the stacked $gri$ images, but re-calculate the segment statistics for each individual band. For the test runs which this section is based on, we only used $r$-band images. 

From the segmentation statistics returned by \texttt{profoundProFound}, we select relatively round and isolated objects as follows: 
\begin{itemize}
\item objects that do not touch other segments, masked regions or image edges (edge fraction\,=\,1)
\item objects with a regular boundary geometry (edge excess <\,1) 
\item objects with an axial ratio (minor/major axis) larger than 0.5
\item objects which were not flagged as possibly spurious
\end{itemize}
These are trivial selections based on theoretical considerations to remove the segments with least reliable statistics; with the exception of the axial ratio. For the latter, we originally used an axial ratio cut based on the PSF ellipticity given in the header of KiDS science tiles. The header value refers to the average PSF ellipticity across the entire tile, which is typically very low (corresponding to axial ratios $\gtrsim$\,0.9). However, we found that the PSF can vary strongly locally across the tile and is often elongated significantly especially towards the tile corners (see Figure~\ref{fig:tileoverview}), with axial ratios as low as $\sim$\,0.6. Due to these local variations, a cut based on the average PSF ellipticity proved to be unsuitable and we instead decided to simply use a fixed cut of 0.5 on the axial ratio to remove very elongated objects from further analysis. 


Of these relatively round and isolated objects, a given fraction (depending on the depth of the image and source extraction, typically 4-8\,\%) are identified as star candidates via a joint cut in \texttt{R50} (semi-major axis containing half the flux) and the concentration (\texttt{R50/R90}, where \texttt{R90} is the semi-major axis containing 90\,\% of the total flux). A diagnostic plot of this step is returned with an example shown in Figure~\ref{fig:examplepsfseg}, again for galaxy 396740. We chose this cut based on the notion that we would expect stars to be small (i.e. low \texttt{R50}) and highly concentrated (i.e. low \texttt{R50/R90}). The plot of these two quantities coloured by axial ratio (example in Figure~\ref{fig:examplepsfseg}) typically shows a rather distinct population of objects that are constant in (small) \texttt{R50} and (high) axial ratio, with low \texttt{R50/R90}. To capture most of this population of objects without including too many others, we then empirically devised the joint cut in \texttt{R50} and \texttt{R50/R90} as indicated in Figure~\ref{fig:examplepsfseg}. 

We found the best results using a fixed percentage of objects to accommodate both crowded fields and those with only few objects and/or large masked areas. The chosen percentage depends on the depth of the source extraction (i.e. the \texttt{skycut} value in \texttt{profoundProFound}) and the depth of the image. For the stacked $gri$ KiDS images and a \texttt{skycut} value of 2, we found that classifying 4\,\% of all segments as star candidates delivers reasonable results for the vast majority of cutouts. While this does not always capture all stars in the frame, it is usually enough to allow for a robust PSF estimate. Conversely, for some frames it may include a few objects that are not actually stars, but as long as they are not the majority, they will be screened out at a later stage in the PSF estimation when we reject outliers.  

Note that since the number of segments and the fraction of how many of those are stars are determined by the segmentation map alone, this value can be used for images of varying depth as long as they use the same segmentation map. In other words, even though for example the $i$-band images are shallower than the $gri$ stacks; and the segment properties (including \texttt{R50} and \texttt{R90}) are re-calculated in the $i$-band, the 4\,\% selection cut is appropriate because we originally defined the segments on the $gri$ stacked image. Hence from \texttt{v03} of the pipeline onwards, when we started using the $gri$ stacks to define common segments for all bands and fixed \texttt{skycut} to two, we always use the 4\,\% selection cut (0.02\,$\times$\,\texttt{skycut}). Earlier (single-band) versions of the pipeline use 0.03\,$\times$\,\texttt{skycut} for $g$ and $r$, 0.04\,$\times$\,\texttt{skycut} for $i$ and 0.06\,$\times$\,\texttt{skycut} for $u$. 

\begin{figure}[ht!]
\begin{center}
	\includegraphics[width=0.8\textwidth]{plots/examplepsfseg}
    \caption{A diagnostic plot of the selection of star candidates for example galaxy 396740. Coloured points show the concentration \texttt{R50/R90} against \texttt{R50} (semi-major axis containing half of the total flux) for all segments in the 400\arcsec\,$\times$\,400\arcsec\ cutout around the galaxy; coloured by axial ratio. The joint selection cut in \texttt{R50} and \texttt{R50/R90} is indicated with a dashed line.}
    \label{fig:examplepsfseg}
\end{center}
\end{figure}

Around each of these star candidates, a smaller cutout is taken (side length equal to 2\,$\times$\,\texttt{R100}; 6\,$\times$\,\texttt{R100} if a background is to be fit as well) and a subsample selected:
\begin{itemize}
\item objects brighter than the 5-sigma point source detection limit and fainter than the saturation limit (both taken from the headers of the corresponding KiDS tile)
\item objects where less than 10\,\% of pixels in the cutout belong to other segments (rising to 30\,\% for the larger cutouts when fitting a background) 
\item objects where the star cutout does not overlap with the edge of the large cutout
\item objects with a positive sum of the cutout (excluding poorly background-subtracted and/or purely noise-dominated objects)
\end{itemize}
The cutout size is large enough to include the entire star segment, which are the pixels that we use for fitting the star. When additionally fitting a background, we need larger cutouts to include a sufficient number of sky pixels (see Section~\ref{sec:backgroundstudies}). This only affects a number of test runs related to Section~\ref{sec:backgroundstudies}; none of the full runs used additional background fitting. The remaining selection criteria then ensure that the stars are neither saturated nor too faint to produce a reliable fit; and that they are isolated and fully contained within the image. We also experimented with constraining the magnitude range further (e.g. fitting only stars that are at least 2\,mag brighter than the 5-sigma point source detection limit), but found that this does not significantly improve the fitting quality and instead can limit the number of stars too much for fields in which only few star candidates are available. 

The order in which we apply these selection cuts was essentially defined by trial and error: the cut in size and concentration (Figure~\ref{fig:examplepsfseg}) is best applied after a pre-selection of isolated relatively round objects, since otherwise the number of stars in crowded fields is reduced too much. This is because in these fields, the fraction of stars is usually higher, which we can at least partially account for by the pre-selection of round objects. However, the magnitude cuts should be applied after the concentration and size cuts since otherwise the assumed fraction of stars in the frame (4\,\%) needs to be carefully tuned to the chosen magnitude cuts. The reason here is that stars tend to belong to the brightest objects in the frames, so for example cutting 2\,mag off the faint end will increase the fraction of stars substantially. 

If no stars pass the above criteria (usually this only happens when the vast majority of the large cutout is masked), then a default perfectly round PSF is created with the FWHM taken from the KiDS header and a Moffat concentration index of 2.1 (the median of all measured $r$-band concentrations). If this is the case, a warning is given and an appropriate flag value added to the PSF quality flag, such that galaxies for which only this default (dummy) PSF exists are skipped during the fitting procedure. If more than 32 star candidates pass the above criteria, we limit the fitting to the 32 objects closest to the galaxy in order to save computational time. 

Ideally, we would use only those stars that are on the same detector chip as the galaxy of interest; or at least stars that have the same number of dithers as the galaxy. However, the KiDS instrumental setup and dithering pattern result in frequent changes of the number of dithers across a tile (cf. the darker stripes in the weight map of Figure~\ref{fig:exampleseg}). Trying to identify the corresponding stars is hence non-trivial and usually results in only very few star candidates being left. Moreover, different parts of the galaxy itself are often covered by different numbers of dithers, which would - to be consistent - then require the galaxy to be fit with different PSFs for different regions. These difficulties could be avoided by working at the pawprint level (like we do for VIKING, Section~\ref{sec:pipelineupdates}) instead of using the stacked science tiles. For reasons outlined in Section~\ref{sec:otherprepworkchoices}, we however decided to use the science tiles for KiDS. Since all dithers of a tile were taken in close temporal succession, they should have very similar PSFs in general. Therefore the stacking and the changing number of dithers across the field will not have a large effect on the PSF. Indeed we do find the PSF to vary only slowly across tiles, with no abrupt changes (cf. Figure~\ref{fig:tileoverview}). 


\subsubsection{Star fitting}

In the next step, the star candidate cutouts are normalised to a magnitude of 0, masked appropriately and fitted with a Moffat function using \texttt{ProFit} (see fitting details in Section~\ref{sec:preparatorysteps}). We choose a Normal likelihood function since we need near-perfect fits for adequate PSF representation and so the residuals are expected to be distributed Normally. The normalisation of the PSF to a magnitude of 0 brings the sum of the cutout close to 1 (for the KiDS magnitude zeropoint of 0) and so individual pixels mostly have values around a few $\times$\,$10^{-4}$. We found this to be close to the optimum in terms of fit accuracy when using the default tolerance levels for convergence in \texttt{optim} (it is also where the fitting time is longest). If no background is fitted, only the segment around the star is used for fitting; with a background fit the entire cutout is used but with all objects (except the segment of interest) masked. The diagnostic plot of the fit returned by \texttt{ProFit} is saved for each star and an example shown in Figure~\ref{fig:examplestarfit}. 

\begin{figure}
\begin{center}
	\includegraphics[width=0.8\textwidth]{plots/examplestarfit}
    \caption{The Moffat function fit to an example star near galaxy 396740. Panels are the same as the top two rows in Figure~\ref{fig:examplefit}.}
    \label{fig:examplestarfit}
\end{center}
\end{figure}

As briefly mentioned above, we introduce this fitting step (instead of a purely empirical estimate based on, e.g., simply averaging appropriately scaled cutouts around suitable stars) since it reduces the noise in our PSF estimate. This is particularly important given that we only use a relatively small number of stars to obtain the model PSF. Additionally, it gives an opportunity to easily remove outliers, so the star candidate selection process need not be perfect. It does, however, require finding a modelling function that can adequately represent the PSF, since otherwise one will introduce systematic biases. We chose to fit a \citet{Moffat1969} function since that is known to parameterise telescope PSFs well and, in fact, was devised for that exact purpose.

As one can see, a Moffat function is a perfect fit for the star shown in Figure~\ref{fig:examplestarfit}. The normalised residual $Z$ (bottom right panel) shows pure noise and its distribution follows a Gaussian function (bottom left panel), while $Z^2$ follows a chi-squared function as it should (bottom middle panel). The fact that the reduced chi-squared ($\chi^2_\nu$ given in the bottom middle panel) is below the ideal value of one is because the KiDS weight maps tend to slightly overestimate the true pixel error, see Section~\ref{sec:otherprepworkchoices}. 

Most isolated stars are represented very well by Moffat functions (like the example shown), with two exceptions. First, very bright stars sometimes show residuals at their cores, which can be systematic in the sense that all bright stars in a field show similar residuals. This indicates that a Moffat function is not able to capture the true shape of the PSF at the cores of bright stars. The residual pattern usually shows a red core surrounded by a blue ring or arc, often not entirely symmetric, see the example in the top panels of  Figure~\ref{fig:examplestarfitbright}.
Nonetheless, the parameters fitted to these bright stars are indistinguishable from the parameters fitted to fainter stars of the same field. In addition, these bright stars reach surface brightnesses close to the saturation limit, where CCD detectors are known to have a non-linear response function. It is therefore unclear whether the residuals are due to actual deviations of the seeing PSF from a Moffat function or are simply due to the CCD response function. 

\begin{figure}[t!]
\begin{center}
	\includegraphics[width=0.8\textwidth]{plots/examplestarfitbright}
	\includegraphics[width=0.8\textwidth]{plots/examplestarfitbright2}
    \caption{\textbf{Top two rows}: the Moffat function fit to a relatively bright example star near galaxy 7623. Panels are the same as the top two rows in Figure~\ref{fig:examplefit}. \textbf{Bottom two rows}: the double Moffat function fit to the same star.}
    \label{fig:examplestarfitbright}
\end{center}
\end{figure}

The former case would mean that we introduce a systematic bias into our galaxy parameters from systematically wrong PSFs, while the latter would not affect the galaxy fitting since the galaxies in our sample have much lower surface brightnesses, typically far from the saturation regime. While we cannot be sure, we assumed that the latter is the case and we need not worry about the brightest stars since they lie in a different regime of the dynamic range of the CCD than our galaxies. This belief was formed mainly by the observation that stars of intermediate brightness typically show no such systematic residuals (i.e. the residuals are not just weaker but disappear completely), while at the same time we obtain very consistent results for the fitting parameters across the stars of a field. We therefore focused on stars of intermediate brightness for which we can obtain perfect fits with a Moffat function. 

The second case where we see clear systematic residuals in the star fits is for very elongated objects near the corners of KiDS tiles. An example is shown in the top two rows of Figure~\ref{fig:examplestarfitegg}. 
Here, there are clear asymmetries in the residuals for stars of all brightnesses, which show that the true PSF is not perfectly elliptical but instead egg-shaped, with the wider part pointing towards the tile corner. Using the perfectly elliptical Moffat PSF will introduce a systematic uncertainty for the parameters of the corresponding galaxy. In particular we might bias the position angle and axial ratio, which are most severly influenced by incorrect PSFs (see Section~\ref{sec:systematics}). Due to the symmetry of the problem, however, only galaxies with a major axis oriented at approximately 45\degr\ with respect to the PSF elongation will be significantly affected. In addition, not all tile corners show elongated PSFs and for those that do the region is usually limited to the very outer edges of a tile. This also means that there are often multiple matches (i.e. the galaxy belongs to the overlap sample), not all of which are necessarily compromised. Therefore, the overall number of galaxies affected is low and limited to those objects suffering from the worst data quality in many other respects, too. 

\begin{figure}[t!]
\begin{center}
	\includegraphics[width=0.8\textwidth]{plots/examplestarfitegg}
	\includegraphics[width=0.8\textwidth]{plots/examplestarfitegg2}
    \caption{\textbf{Top two rows}: the Moffat function fit to an elongated, egg-shaped example star near galaxy 105600. Panels are the same as the top two rows in Figure~\ref{fig:examplefit}. \textbf{Bottom two rows}: the double Moffat function fit to the same star.}
    \label{fig:examplestarfitegg}
\end{center}
\end{figure}

In an attempt to improve the fits to very bright and/or elongated stars, we experimented with fitting double Moffat functions instead of just a single Moffat function to each star (following a suggestion by Dan Taranu, who uses this in the \texttt{AllStarFit} package). However, the success was limited: although the fit does improve owing to the increased number of parameters, in both cases residuals remained (see the bottom panels in Figures~\ref{fig:examplestarfitbright} and ~\ref{fig:examplestarfitegg}). In particular, the systematic residual due to the egg-shape of the elongated PSFs is still present and also the bright star still shows hints of the residual pattern visible in the single Moffat fit.
Conversely, the double Moffat fits (apart from increasing the computational time for PSF estimation by a factor of $\sim$\,20) often produced unreliable results for those stars that are perfectly represented by a single Moffat function, leaving the second Moffat function unconstrained. Fitting some stars with a double Moffat and some with a single Moffat function bears its own problems, starting with having to decide which star to fit with which function and ending with having to devise a method to combine the different estimates into a single model PSF for the galaxy. Additionally, there are always parameter degeneracies when fitting two identical functions. 

For these reasons, we concluded that fitting double Moffat functions to KiDS stars is only viable when jointly fitting all stars of a field. This increases the signal-to-noise ratio with respect to individual fits, so all parameters can be reasonably constrained; and eliminates the problem of combining the resulting PSFs, since there will only be one model. While this is the approach that e.g. \citet{Taranu2017} have taken (and was the original reason for the development of the \texttt{AllStarFit} package which we have used in other contexts), we decided against it for reasons outlined in Section~\ref{sec:psfdetails}. Therefore we decided to proceed with single Moffat PSFs despite its shortcomings for a small minority of galaxies; in particular since we believe that the imperfect fits to bright stars do not affect our analysis and so only a few galaxies in tile corners with very elongated PSFs are compromised. The test runs with double Moffat PSFs did also not show any significant or systematic improvement to the galaxy fits compared to galaxy fits with single Moffat PSFs. 


\subsubsection{Model PSF generation}

After fitting, suitable stars for PSF estimation are determined as follows:
\begin{itemize}
\item The fitted centre in x and y must be within $\pm$\,1 pixel of the centre of the cutout 
\item The fitted magnitude must be within $\pm$\,0.1\,mag of 0 
\item The reduced chi-squared ($\chi^2_\nu$) of the fit must be smaller than 3 (where $\chi^2_\nu$ is evaluated within the star segment only even if a larger region was fit)
\item FWHM, concentration index, angle, axial ratio and background (if fit) must not be equal to the fit limits (except for the axial ratio, which is allowed to be exactly 1 although this is the upper limit of the fit).
\item Outliers in any of FWHM, concentration index, angle, axial ratio or background are rejected via an iterative 2$\sigma$ clip (in logarithmic space where appropriate). 
\end{itemize}

The first two criteria of these are fixed hard cuts since the input image was centred on the star and normalised to a magnitude of 0 according to the segmentation statistics. Any deviation from these values indicates a difference in the position or magnitude estimated by \texttt{ProFound} and \texttt{ProFit} which likely points to bad segmentation, additional objects in the segment or a bad model fit. The cut in $\chi^2_\nu$ is also a hard cut, chosen to remove objects that visually appear as bad fits (mostly the very bright stars discussed earlier). Note that the example star shown in Figure~\ref{fig:examplestarfitbright} is well below this limit. The reason is that we show an example star from a test run here, in order to directly compare it to the double Moffat fit. In this test run, however, we also used an additional cut on the magnitude of star candidates, excluding the brightest objects (see above). Consequently, there are only stars of intermediate brightness in this test run, one of which we show in Figure~\ref{fig:examplestarfitbright}. During subsequent pipeline development, we have then changed the strategy and stopped using the magnitude cut, except for objects at the saturation limit (see discussion above). Instead, we now exclude these brightest stars with the cut in reduced chi-squared listed here. 

We also exclude stars that hit their fit limit since these parameter estimates are not reliable and all fitting intervals were chosen very generously (except for the upper bound on axial ratio, which has a physical limit at 1, meaning perfectly round). Finally, we remove outliers in the respective distribution of the main fitting parameters to exclude any remaining objects that are not true point sources. 

The stars fulfilling these criteria are classified as suitable, from which the selection is made: 
\begin{itemize} 
\item The closest two from each quadrant (8 in total) are selected to make sure they are roughly evenly distributed around the galaxy. 
\item If one or more quadrant contains less than two stars, the closest stars from any other quadrant (which are not already used) are taken instead to give 8 stars in total. A warning is given and the quality flag adjusted.
\item If there are less than 8 stars in total, all of them are used with a warning (and a quality flag adjustment)
\item If there are no stars classified as suitable, the default PSF mentioned above (round, FWHM from KiDS header, default Moffat concentration index) is used, with a warning and the corresponding flag.
\end{itemize}
There are two diagnostic plots summarising these selection steps (three if the background was fit as well), examples are shown in Figures~\ref{fig:examplepsfoutput} and ~\ref{fig:examplepsfmags}. A list of stars with the relevant segmentation parameters and the fit parameters is saved for later reference. 

\begin{figure}[t!]
\begin{center}
	\includegraphics[width=0.8\textwidth]{plots/examplepsfoutput}
    \caption{The result of the PSF fitting for the galaxy 396740 in the KiDS $r$-band with the dashed white square indicating the cutout shown in Figure~\ref{fig:exampleseg}. The greyscale image shows the $r$-band weight map with lighter colours meaning higher weight. Masked areas from the stacked $gri$-masks are shown in black (zero weight). The vertical and horizontal red line indicate the position of the object of interest (galaxy 396740) and split the image into its 4 quadrants. All fitted PSFs are shown as coloured ellipses with the size (FWHM multiplied by 20), axial ratio, orientation angle and concentration index (colour) taken from the fitted Moffat parameters. Stars selected for estimating the final model PSF have red borders; dashed red borders mean a fit was classified as suitable, but not selected because the maximum of 8 stars was already reached.}
    \label{fig:examplepsfoutput}
\end{center}
\end{figure}

\begin{figure}[t!]
\begin{center}
	\includegraphics[width=0.8\textwidth]{plots/examplepsfmags}
    \caption{The second main diagnostic plot for the PSF fitting result, again for galaxy 396740 in the KiDS $r$-band. Here, we show the magnitude fitted to the normalised image of each star on the $y$-axis against the magnitude from the \texttt{ProFound} segmentation statistics on the $x$-axis, with symbols coloured by the reduced chi-squared of the fit. The magnitude and $\chi^2_\nu$ selection cuts are shown as solid and dashed red lines respectively (the latter on the colour bar); stars classified and suitable and selected are indicated with dashed and solid red borders.}
    \label{fig:examplepsfmags}
\end{center}
\end{figure}

From Figure~\ref{fig:examplepsfoutput} it is obvious that the Moffat models fitted to all star candidates in the field are very consistent in all parameters (shape, orientation, size and concentration). This is true even for stars which were not classified as suitable for PSF estimation (symbols with black borders). We make the same observation in most cutouts, even though the PSFs themselves can vary greatly between frames (see Figure~\ref{fig:tileoverview}), with only occasional outliers appearing (which are subsequently excluded from the model PSF estimation). 

Figure~\ref{fig:examplepsfmags} shows that all star candidates of this frame are well-represented by a Moffat function. This is also generally the case except for very bright objects (close to the bright magnitude limit, of which there are none in this field), very elongated ones and those that have secondary objects included in their segmentation map. The latter of these are excluded either by the $\chi^2_\nu$ cut or by the magnitude cuts since they will generally show a disagreement between \texttt{ProFound} and \texttt{ProFit} magnitudes. Note there is a slight systematic offset for all stars in this field, too, in that all stars have fitted magnitudes smaller than zero. As a reminder, we use the \texttt{ProFound} segment magnitudes to normalise the star images to a magnitude of 0 before fitting, so any deviation from zero in the fitted magnitude indicates that \texttt{ProFit} and \texttt{ProFound} estimate different magnitudes for the same object. However, small deviations below $\sim$\,0.1\,mag are no reason for concern since there are inherent differences in the two estimates: the \texttt{ProFound} estimate is simply the sum of all flux within the segment, while the \texttt{ProFit} estimate is the total magnitude of the Moffat function integrated to infinity, which can easily be somewhat brighter. However, larger deviations are usually indications of a bad model fit, bad segmentation, intruding (wings of) nearby objects or image artifacts and hence are excluded from further consideration. 

Finally, the model PSF is created as an image of a two-dimensional Moffat function with parameters that are the medians of the selected stars. Exceptions are the centre of the star (in x and y), which is forced to the centre of the model image; the magnitude, which is forced to 0 and the background, which is ignored (i.e. set to 0 even if fit). The reason for forcing these values in the model PSF is to avoid systematic offsets when convolving the galaxy to be fit with its model PSF. The size of the image is adjusted to include at least 99\,\% of the flux; or to a maximum of the median segment size within which the stars were fitted (to avoid extrapolation). Pixels in the corners of the image are set to 0 to avoid having a rectangular PSF and the image is subsequently re-normalised to sum to 1. The model PSF is stored as a FITS file and an image of it is returned as well, with an example shown in Figure~\ref{fig:examplepsf}.

\begin{figure}[t!]
\begin{center}
	\includegraphics[width=0.8\textwidth]{plots/examplepsf}
    \caption{The model PSF obtained for galaxy 396740 in the KiDS $r$-band with asinh stretching of the flux scale. The green contours indicate the region beyond which the PSF is set to zero exactly.}
    \label{fig:examplepsf}
\end{center}
\end{figure}

There are many other ways in which we could have chosen to combine the individual PSF estimates into a final model PSF. We chose the approach of simply medianing the Moffat parameters mostly since it is practical, fast and robust. Taking the median ensures that we are not susceptible to outliers in the distribution (should there be any left after all of the above treatment), while working at the parameter level ensures that the resulting PSF is a smooth Moffat function with no abrupt changes. We avoid extrapolation of the model beyond the region in which it was fitted by limiting the size of the final PSF accordingly; and in turn ensure an approximately round PSF by setting the very small values in the corners to zero exactly. We sample the PSF onto the same pixel scale as the KiDS images, so it can be used for direct convolution. 

A first potential improvement to this procedure would be to finesample the PSF (and correspondingly the galaxy image) to allow a more accurate convolution. However, even the smallest possible oversampling factor of 3 (meaning a factor 9 increase in the number of pixels to convolve) leads to a prohibitive increase in the computational time for galaxy parameter estimation since the PSF convolution needs to be repeated for each model evaluation and constitutes a large fraction of the total computational time. Also, finesampling is only effective in increasing the accuracy of the convolution if the PSF is known to the level of accuracy implied by the finesampling. This can be achieved with PSF estimates based on large numbers of stars (best combined empirically or fit jointly) and/or theoretical knowledge about instrumental effects. In our case, where we fit only a relatively low number of stars individually, we cannot ensure or verify the PSF accuracy for significant finesampling factors. 

Another potential improvement in creating the model PSF would be to consider parameter correlations. Currently, these are ignored since we take the medians of all parameters individually. One shortcoming of this is that the median of the axial ratio is taken independently of its orientation angle; which could lead to artifically elongated PSFs. For example, suppose the true PSF is perfectly round. Due to noise, the fitted axial ratios could be less than 1 (at least for some of the stars), with associated orientation angles that are randomly distributed. Taking the median of these two parameters independently of each other could therefore lead to a slightly elongated model PSF profile oriented at a random angle. In theory, this effect could lead to our PSFs being systematically too elongated, especially since it does not work the other way around (i.e. we will not have estimates which are systematically too round for truly elongated PSFs, since that would require the noise to be distributed in the same way for all stars of a field, which is highly unlikely). 

After noticing this shortcoming, we have double-checked many of our model PSFs by studying the residual left after subtracting it from all stars that it was based on; and found no evidence of the PSF being systematically elongated. We also compared the average axial ratio of all model PSFs in a tile to the average PSF ellipticity given in the KiDS header of the same tile and found our estimates to be consistent with the KiDS value for individual tiles; and slightly rounder than the KiDS value on average across all tiles. Since the above effect cannot produce PSFs that are too round, we conclude that there are no systematic biases in our PSF shape introduced by our method. The difference between the KiDS values and our averages are likely because our average is based on the model PSFs which are the medians of a highly selected set of stars; while the KiDS value is computed as the average ellipticity of all individual stars in the field which is likely to be noisier (and therefore less round). 

While we conclude that the PSF estimates are not compromised by this effect, it would still be preferable to consider parameter correlations (between angle and axial ratio, but also other parameters) when computing the final model PSF. One way to achieve this is to perform a joint fit of several stars. This has the added advantages that it increases the signal-to-noise ratio relative to fitting individual stars, allowing to improve the PSF accuracy and possibly fitting more detailed models (e.g. a double Moffat function as mentioned above). We have briefly explored this route, but unfortunately it takes much longer than fitting the stars individually since the computational time scales non-linearly with the number of parameters and there are many parameters in a joint fit since each star needs its own position ($x$ and $y$) and magnitude to be fitted, even if the PSF shape is the same for all stars. Furthermore, implementing a joint fit requires significant improvements to the star candidate selection process, which is not critical in the current approach since outliers can easily be excluded after fitting. For a joint fit, this step would have to be replaced by an alternative - or else we would have to first fit stars individually, select suitable ones and then perform a joint fit of those (instead of medianing the parameters), additionally increasing computational time. For these reasons, we did not implement such an approach in the current work. Nonetheless, it remains an interesting avenue to explore in future work since it would solve several shortcomings of the PSF estimation at once. 

As a last point of how the PSF pipeline could potentially be improved, we would like to discuss the number of stars we chose for fitting. Generally, fitting a higher number of stars will result in a more robust PSF estimate. A competing effect is that stars closer to the galaxy will reflect the PSF at the galaxy position better than those further away. A robust local PSF estimate can therefore only include stars within a field small enough such the PSF does not vary significantly across it. Larger fields would require fitting multiple PSFs and interpolating between them, introducing additional uncertainties. The size of the large cutout to identify stars in (400\arcsec\,$\times$\,400\arcsec) is chosen to balance these two effects. It is small enough such that the PSF does not usually change significantly across it (see Figure~\ref{fig:examplepsfoutput}), since the PSF in KiDS tiles does vary, but slowly (Figure~\ref{fig:tileoverview}). At the same time, the cutout is large enough to contain a reasonable number of stars for PSF fitting ($\sim$\,10-20 on average) unless large fractions of the cutout are masked. In order to make the PSF estimates comparable for crowded fields (sometimes containing more than 30 stars) and sparse ones or those with masked areas (where there are often only a few stars available), we take a maximum of 8 stars for each PSF estimate even if more would be available. 


\subsubsection{PSF quality control}

As mentioned above, we produce a number of PSF quality control plots for each galaxy (Figures~\ref{fig:examplepsfseg}, \ref{fig:examplestarfit}, \ref{fig:examplepsfoutput}, \ref{fig:examplepsfmags}, \ref{fig:examplepsf}) which are stored on the GAMA file server for reference. In addition, we investigated the robustness of our estimates by comparing model PSFs for different galaxies in the same KiDS tile against each other. The main diagnostic plot of this comparison is shown in Figure~\ref{fig:tileoverview} for four different KiDS tiles. Similar to Figure~\ref{fig:examplepsfoutput}, we show the weight map as greyscale in the background with masked areas in black; and the PSFs as coloured contours with the size (FWHM\,$\times$\,100), axial ratio, orientation angle and concentration index (colour) taken from the model PSF estimated for the galaxy at this position. Note that in contrast to Figure~\ref{fig:examplepsfoutput}, the PSFs shown here are not fits to individual stars, but Moffat models created from the combination of several suitably selected stars. Therefore, the meaning of the red contours changed: solid red indicates model PSFs based on 8 stars, while dotted red means that less than 8 suitable stars were available. Black contours are drawn around default (dummy) model PSFs that had no suitable stars available and so should be ignored. Also, we now multiply the FWHM by 100 instead of 20 to enhance visibility in the much larger area ($\sim$\,1\,deg$^2$ instead of 400\arcsec\,$\times$\,400\arcsec). 

\begin{figure}[t!]
	\includegraphics[width=0.5\textwidth]{plots/tileoverview175.0_1.5}
	\includegraphics[width=0.5\textwidth]{plots/tileoverview216.0_-0.5}
	\includegraphics[width=0.5\textwidth]{plots/tileoverview130.0_1.5}
	\includegraphics[width=0.5\textwidth]{plots/tileoverview213.0_1.5}
    \caption{The model PSFs obtained for all galaxies in four different KiDS $r$-band tiles (top left: \texttt{KiDS\_DR4.0\_175.0\_1.5\_r\_sci.fits}, top right: \texttt{KiDS\_DR4.0\_216.0\_-0.5\_r\_sci.fits}, bottom left: \texttt{KiDS\_DR4.0\_130.0\_1.5\_r\_sci.fits}, bottom right: \texttt{KiDS\_DR4.0\_213.0\_1.5\_r\_sci.fits}). Similar to Figure~\ref{fig:examplepsfoutput}, the greyscale image shows the weight map with masked areas shown in black; while the coloured ellipses represent the PSFs (FWHM\,$\times$\,100, axial ratio, orientation angle and concentration index). The major difference to Figure~\ref{fig:examplepsfoutput} is that we now do not show fits to individual stars, but instead the model PSFs derived for the galaxy positions. Solid red contours now mean that the model PSF is based on 8 stars, while dotted red contours are drawn around PSF estimates based on less than 8 stars. Black contours mean this is a default (dummy) PSF and should not be considered further. The white rectancle in the top left tile indicates the region shown in Figure~\ref{fig:examplepsfoutput}.}
    \label{fig:tileoverview}
\end{figure}

The top left panel shows the tile \texttt{KiDS\_DR4.0\_175.0\_1.5\_r\_sci.fits} in which galaxy 396740 (our usual example galaxy) resides near the centre. For orientation, we indicate the 400\arcsec\,$\times$\,400\arcsec\ cutout that is shown in Figure~\ref{fig:examplepsfoutput} as a white rectangle. The top right panel shows a tile with generally much smaller PSFs, \texttt{KiDS\_DR4.0\_216.0\_-0.5\_r\_sci.fits}. On the bottom left we see \texttt{KiDS\_DR4.0\_130.0\_1.5\_r\_sci.fits}, which shows larger and more elongated PSFs and finally, the bottom right image shows \texttt{KiDS\_DR4.0\_213.0\_1.5\_r\_sci.fits} which has more pronounced PSF variations and is also the tile in which the example elongated star of Figure~\ref{fig:examplestarfitegg} resides (near the bottom right corner). 

Comparing all tiles we can see that the PSF differences between tiles are much larger than the variations within a tile. The latter are generally relatively small and smooth with no abrupt changes. This is what one would expect for KiDS data, since it is seeing-limited and the seeing will vary greatly with time (i.e. between tiles); while all dithers composing a tile were taken in close temporal succession. The fact that we can observe this in the overview plots is therefore reassuring. Remember that each PSF in Figure~\ref{fig:tileoverview} is a model PSF that was estimated entirely independently from all other model PSFs in the tile (except for galaxies very close to each other which could have some stars overlapping). The generally similar appearance of all model PSFs in a tile (with no clear outliers) combined with the slow variation across it is a sign of our PSF estimates being robust. 

Investigating the variation across the individual tiles further, it can be seen that generally, the PSFs tend to become more elongated towards tile edges and corners, with the concentration and FWHM also increasing. This effect is more pronounced in some tiles (e.g. bottom right) than in others. Also, even within a tile, not all corners are equally affected, our impression was that the bottom right and top right corners show elongated PSFs more often than the top left and bottom left corners. The orientation angle seems to rotate such that the major axis always points towards the corners. For tiles that have intrinsically elongated PSFs, this can result in PSFs actually becoming rounder towards corners (e.g. in the top right corner of the bottom left panel). 

\begin{figure}[t!]
	\includegraphics[width=0.5\textwidth]{plots/tilevaryfwhm}
	\includegraphics[width=0.5\textwidth]{plots/tilevarycon}
	\includegraphics[width=0.5\textwidth]{plots/tilevaryaxrat}
	\includegraphics[width=0.5\textwidth]{plots/tilevaryang}
    \caption{The variation of the FWHM (top left), Moffat concentration index (top right), axial ratio (bottom left) and position angle (bottom right) for model PSFs averaged across all KiDS $r$-band tiles. The position angle is measured anticlockwise (ACW) from the vertical axis and limited to the range between 0 and 180\degr\ due to symmetry.}
    \label{fig:tilevary}
\end{figure}

To gain a better understanding of these systematic trends, we stacked the results for all KiDS $r$-band tiles, the result of which can be seen in Figure~\ref{fig:tilevary}. As expected from the examples shown in Figure~\ref{fig:tileoverview} above, the stacked plots show that the FWHM and concentration index generally increase towards the corners of tiles, while the axial ratio decreases and the angle rotates such that the major axis always points towards the nearest corner. Our visual impression that the right side of the tiles seems to be more affected than the left side is also confirmed. Interestingly, there is also a region near the centre of the tiles where the FWHM and concentration index increase while the axial ratio decreases slightly, but with no clear corresponding trend in the position angle. The latter instead seems to be randomly distributed in the central tile region, such that averaging over all tiles results in a value of approximately 90\degr, i.e. the centre of the possible range of angles. 

We have also visually compared these tile overview plots to the PSF diagnostic plots available from the KiDS database and found the general trends to agree well. 


\subsubsection{PSF effects on galaxy fitting}

Besides the internal PSF consistency checks presented above, we investigated the effects that using different PSFs has on the fitted galaxy parameters. To this end, we fitted a test sample of galaxies with various different PSFs, sampled from the stars classified as suitable. An example can be seen in Figure~\ref{fig:islandplotpsf}. 
\begin{figure}
	\includegraphics[width=\textwidth]{plots/islandplotpsf}
    \caption{The effect of different PSFs on the fitted galaxy parameters for the galaxy 105723, which is part of the overlap sample. For each combination of the seven single S\'ersic parameters we show the distribution of the MCMC chain points in the upper left half of the plot; while the lower right half shows the corresponding contours including 50\,\%, 68\,\% and 95\,\% of the data for dashed, solid and dotted lines respectively. The diagonal shows the one-dimensional distribution for each parameter. Yellow and orange lines and points show the parameters fitted for the first match of this galaxy, where the former indicate the full distribution obtained by sampling from the PSFs and re-fitting the galaxy 8 times (16000 MCMC samples in total), while the latter shows the result using just the model PSF (i.e. the medianed version, 2000 MCMC samples). Light and dark blue lines and points show the same for the second match, i.e. for the same physical object but a different image since the galaxy sits in the overlap region between KiDS tiles. Crosses show the mean of each distribution. For RA and Dec, instead of the absolute values, we show the difference to the GAMA input positions in arcseconds (for readability).}
    \label{fig:islandplotpsf}
\end{figure}

We show the result of the fitted parameters for four different ``versions" of the same galaxy: yellow shows the result for an image of the galaxy using 8 different PSFs sampled from the suitable stars (2000 MCMC samples each, i.e. 16000 points in total). Orange is for the same image of the galaxy, just using the usual (medianed) model PSF (2000 points). Light blue and dark blue show the same for a different image of the same galaxy, since the galaxy sits in the overlap region between KiDS tiles. The top left half of the plot then shows the MCMC samples for each combination of the seven single S\'ersic parameters: position in RA and Dec, magnitude $m$, effective radius $R_e$, S\'ersic index $n$, the position angle PA and the axial ratio $b/a$. The bottom right half shows the corresponding contours, with dashed, solid and dotted lines including 50\,\%, 68\,\% and 95\,\% of the data. On the diagonal we show the one-dimensional distributions for each parameter. Crosses indicate the mean of each distribution. 

There is a clear discrepancy in the fitted RA and Dec centres for the two images, which is caused by the accuracy of the KiDS astrometric solution, see Section~\ref{sec:systematics}. Apart from that, all distributions overlap, with varying levels of consistency for the different parameters. The distributions sampling from the PSFs are broader than those using just the medianed model PSF. This shows that the PSF introduces systematic uncertainties which are not accounted for in the MCMC errors. The difference is larger for the second of the two images (blue), where the sample using the model PSF is also not centred on the same values as the sample obtained by varying the PSF. Nonetheless, the parameters fitted to the same image with different PSFs are in closer agreement than those fitted to different images. This is because for different images, there are additional sources of systematic uncertainties caused by, e.g., the background subtraction and different segment sizes. We investigate all of these systematic uncertainties in more detail in Section~\ref{sec:systematics}, where we derive the average systematic errors for each parameter using the overlap sample and point out parameter biases using simulations. 


\subsection{Segment sizes}
\label{sec:segchoices}
We have briefly discussed image segmentation in Sections~\ref{sec:preparatorysteps} and~\ref{sec:backgroundstudies}. One of the conclusions drawn there was that it is best to use two different segmentation maps for the background subtraction and the galaxy fitting due to the different aims that we would like to achieve with them. We make use of the different settings in \texttt{profoundProFound} to produce these segmentation maps. In the following, we detail the definition of the segmentation maps and how it has evolved over the time of pipeline development. We focus on the fitting segmentation map rather than the background subtraction segmentation map since that has already been discussed in Section~\ref{sec:backgroundstudies}. The latter part of the section then describes our own routine for segmentation map fixing, which also makes use of the fitted galaxy parameters. Hence this section is somewhat at the intersection between the preparatory work and the galaxy fitting choices. 

\subsubsection{\texttt{skycut} and dilation}

The most important parameter that influences the segmentation in \texttt{profoundProFound} is \texttt{skycut}, which determines how deep the source extraction pushes into the noise (see Section~\ref{sec:preparatorysteps} and \citealt{Robotham2018} for details). A lower value of \texttt{skycut} means that more (fainter) sources are detected and segments for individual sources are larger. In addition, already-defined segments can be dilated (expanded) with the \texttt{profoundMakeSegimDilate} function, which is also used internally by \texttt{profoundProFound} to achieve flux convergence during the segment growing phase and to obtain a more aggressive object mask by further dilating all segments after convergence. There are additional parameters that influence the segmentation, most notably \texttt{pixcut, tolerance} and \texttt{sigma} (minimum number of pixels needed for segment detection, the tolerance to use for merging segments and the radius within which to search for neighbouring objects). We experimented with varying all of those parameters, but their effect is secondary to \texttt{skycut}. In the end we reverted to using the \texttt{profoundProFound} defaults for these parameters and will not discuss their effects further. 

For the background subtraction, described in detail in Section~\ref{sec:backgroundstudies}, we use the rather low \texttt{skycut} value of one and the aggressive object mask returned by \texttt{profoundProFound} after additionally dilating the converged segments. This choice was mainly driven by theoretical considerations and ensures that we obtain a clean sample of sky pixels without (wings of) undetected objects for background subtraction. It may lead to an increased fraction of spurious detections and a significant number of sky pixels included in the segmentation maps, but this does not affect the background estimation as long as there are enough sky pixels remaining to obtain robust statistics. 

Up to \texttt{v02} of the pipeline, we used the same segmentation map for fitting objects, just without the additional dilation for aggressive object masking. However, this often resulted in very jagged segment borders which include noisy, slightly positive pixels but exclude slightly ne\-ga\-tive pixels, thus artificially biasing the flux in galaxy outskirts. This is particularly true for large, bright objects where the number of curve of growth iterations performed to reach flux convergence is often zero or one. For the background subtraction this problem is alleviated by the additional dilation performed to obtain the aggressive object mask, but it sometimes caused issues for the galaxy fitting where no such additional dilation is performed. 

From \texttt{v03} onwards, we therefore decided to run \texttt{profoundProFound} a second time to obtain the fitting segments. Here we use a higher \texttt{skycut} value of two resulting in smaller segments with smoother borders. We then perform an additional dilation of the galaxy segment, increasing its area by typically 30\,\%, which ensures that the edges are smooth and unbiased since the dilation is independent of the pixel values. These dilated segments starting with a \texttt{skycut} value of two are then approximately the same size as the previous undilated segments with a \texttt{skycut} value of one. An example of the difference can be seen in the last two panels of Figure~\ref{fig:segfixplot}, where we discuss the segmentation map fixing. At the same time we started defining all segments on the stacked $gri$ images instead of in individual bands, to ensure that the fitted pixels are exactly the same in all bands to make the measurements most directly comparable. 

We double-check the chosen \texttt{skycut} value based on the fraction of objects returned. Assuming a Normal distribution, the limit at which approximately 50\,\% of the object pixels actually belong to objects rather than the sky background is given by the Normal quantile of one minus the fraction of pixels identified as objects. \texttt{skycut} should be larger than this limit to ensure that the majority of ``object" pixels belong to real objects rather than spurious detections or overly extended segments pushing well beyond the object wings. But \texttt{skycut} should also not be much larger than this limit if one desires to detect faint sources and low surface brightness wings of extended objects. We therefore add a warning and raise a quality flag if the chosen value of \texttt{skycut} is below the ``50-50-limit", or if it is more than 1$\sigma$ above it. 

The computed ``50-50-limit" is around unity in most cases, confirming that our assumption of Normal statistics is valid. For the early version of the pipeline, using a \texttt{skycut} value of one, the flag was therefore raised frequently due to small random fluctuations. Raising the \texttt{skycut} value to two decreased the percentage of objects with this flag raised from approximately 65\,\% to 0.3\,\%. Visual inspection of those galaxies revealed they are in regions where large fractions of the background are masked, such that the object statistics are not reliable anymore.

We conclude that our approach for defining fitting segmentation maps is suitable for our purposes. The initially higher \texttt{skycut} value of two prevents noise fluctuations from being detected, while the additional segment dilation ensures that the majority of the flux from the galaxy wings is included. Note that the segments defined in this way are still relatively tight in that they do not include many sky pixels. This is a deliberate choice we made to obtain the best possible fit in the high signal to noise regions of the galaxy, at the expense of not necessarily normalising the fitted profile to zero at large radii. We discuss the benefits and drawbacks of this approach in detail in Section~\ref{sec:postprocessing}, also in comparison to previous works. 


\subsubsection{Systematics from segment sizes}

Complementary to the statistical discussions in Section~\ref{sec:postprocessing} and Section~\ref{sec:systematics}, we present a case-study on the systematic effect of different segment sizes here. 

Figure~\ref{fig:islandplotseg} shows a corner plot similar in nature to the one presented in Figure~\ref{fig:islandplotpsf}, also for the same galaxy 105723. The distributions of the fitted parameters are shown for all combinations of the seven single S\'ersic parameters, with MCMC samples in the top left half of the plot, corresponding contours in the bottom right half and one-dimensional distributions on the diagonal. Lines and points in colours ranging from red to orange to yellow show the parameters fitted to the first image of that galaxy for continuously increasing segment sizes. Blue through to green colours show the same for the second image of the galaxy. In both cases, the results are shown for five different segment sizes: no additional dilation after the \texttt{profoundProFound} run (red and blue) and dilations which increase the segment diameter by approximately factors of 1.5, 2, 2.5 and 3 respectively. 

Note that for our final \texttt{v04} pipeline, as described above, we settled on an additional dilation based on increasing the area of the segment by approximately 30\,\%. This corresponds to a diameter increase of less than 1.5, i.e. it is not shown in the plot. The reason we do not show the final version here is that the segment size studies have been carried out on a relatively early test run, with many changes in the subsequent pipeline development both for the preparatory work (e.g. background subtraction) and the fitting routines which were still under development at that stage. We therefore only use this case study to gain an intuitive understanding of the effect of different segment sizes and return to a more quantitative analysis of the final segment choice in Figure~\ref{fig:islandplotsegsim} using our simulations. 

\begin{figure}[t!]
	\includegraphics[width=\textwidth]{plots/islandplotseg}
    \caption{The effect of different segment sizes on the fitted galaxy parameters for the galaxy 105723, which is well-represented by a single S\'ersic fit. The general layout of the plot is the same as for Figure~\ref{fig:islandplotpsf}. Red to orange to yellow colours represent the parameters fitted for the first match of the galaxy for continuously increasing segment sizes. Blue through to green colours show the same for the second match of the galaxy.}
    \label{fig:islandplotseg}
\end{figure}

The most obvious feature in Figure~\ref{fig:islandplotseg} is that the RA and Dec positions fitted to the two different images of the galaxies disagree, as already seen in Figure~\ref{fig:islandplotpsf}. We believe this to be due to slightly different astrometric solutions for the two different KiDS tiles based on our investigation of the same issue in Section~\ref{sec:systematics}. For a given image, the fitted positions are in perfect agreement for all segment sizes. This is different for most other parameters, in particular for the highly correlated magnitude, effective radius and S\'ersic index: the fits using the smallest, undilated segments (shown in red and blue) are inconsistent with those using larger segments. As a general trend, also observed in other galaxies, fits to these small undilated segments tend to result in brighter and larger models with higher S\'ersic indices. 

This re-inforces our belief that for undilated segments, the galaxy flux in the outskirts is biased positive, increasing the fitted S\'ersic index. Extrapolating this to infinity to obtain the total S\'ersic magnitude then results in a model that is too bright since it includes significant amounts of flux beyond the segment borders where it is unconstrained, with a corresponding increase in effective radius. The position angle and axial ratio are uncorrelated to these three primary parameters and less affected by the segment size. For increasing segment sizes (with additional unbiased dilations) the models rapidly converge onto common values, with small differences between the two images due to other sources of systematic uncertainties. 

This rapid convergence is not achieved for all galaxies. Instead, it is only the case when the model is an adequate representation of the data, i.e. the galaxy (in this case) truly follows a single S\'ersic profile. For objects that have intrinsically different shapes than the profile(s) we try to fit to them, there is a continuous evolution of the fitted parameters with the segment size, as the focus of the fit is shifted more and more from the inner to the outer regions. The convergence regime is potentially never reached in these cases; or at a much later stage when the segment size is so large that the background normalisation dominates the fit rather than the galaxy itself. 

Figure~\ref{fig:islandplotseg2} shows an example of such a fit. The layout of the plot and the meaning of the colours are exactly the same as for Figure~\ref{fig:islandplotseg}, only that now we show a different galaxy, namely 107016. This galaxy is not well-represented by a single S\'ersic fit and instead needs (at least) two components.\footnote{The double component fit of the object is acceptable, although there are still slight residuals visible at the centre that may point to the existence of a bar.}. There is therefore no unambiguous, correct solution for a single S\'ersic fit to that galaxy and the fitted parameters will always depend on the exact segment size used. 

\begin{figure}[t!]
	\includegraphics[width=\textwidth]{plots/islandplotseg2}
    \caption{The same as Figure~\ref{fig:islandplotseg} for galaxy 107016, which is not well-represented by a single S\'ersic model.}
    \label{fig:islandplotseg2}
\end{figure}

This is a point we already made in Section~\ref{sec:postprocessing}, but it is re-inforced here. Choosing the optimal segment size is therefore non-trivial and depends on the science aim. Since our focus - as explained before - is on obtaining the best possible fits of the high signal to noise regions of galaxies, we do not want to make the segments very large. Nonetheless, they should be large enough to reach the convergence regime at least for cases where there is an unambiguous solution, such as that shown in Figure~\ref{fig:islandplotseg}. 

The best way to determine where the convergence regime begins is using simulations. These have two major advantages: we know that the fake galaxy is well-represented by a single S\'ersic fit if it was created as such; and we know the true parameter values used to create the galaxy. In addition, we know the true PSF used to convolve the generated galaxy with, eliminating PSF uncertainties from the analysis. We have created such simulations for our studies of systematic uncertainties in Section~\ref{sec:simulations}. More details on their creation can be found there, for the analysis in this section it suffices to say that they are all perfect single S\'ersic objects, but realistic in all other properties. After creation, we run them through our pipeline as if they were real galaxies. 

Figure~\ref{fig:islandplotsegsim} shows an example similar to Figures~\ref{fig:islandplotseg} and~\ref{fig:islandplotseg2} for a simulated galaxy. Since the simulations were run at a later stage during pipeline development than the segment size studies shown above, the colours have changed in meaning slightly: red to yellow still shows the fits to the first match of the simulated galaxy (which we also chose to lie in the overlap region) with increasing segment size; while blue to turquoise shows the same for the second match. There are now only three segment sizes shown: no additional dilation (red and blue), dilation such that the area increases by approximately 30\,\% (i.e. the version also used for the final \texttt{v04} pipeline, orange and light blue) and dilation with a kernel five times larger than the value used for \texttt{v04}, corresponding to an area increase by about a factor of 2.5 (yellow and turquoise). Green lines and crosses show the true parameter values.

\begin{figure}[t!]
	\includegraphics[width=\textwidth]{plots/islandplotsegsim}
    \caption{Similar to Figures~\ref{fig:islandplotseg} and~\ref{fig:islandplotseg2}, but now showing a random single S\'ersic simulated galaxy. Again, red through to yellow and blue through to turquoise colours show the fits obtained for the first and second match respectively for increasing segment sizes. The exact segment sizes shown differ from those in Figures~\ref{fig:islandplotseg} and~\ref{fig:islandplotseg2}, see text for details. Green crosses and lines indicate the true values used for generating the galaxy.} 
    \label{fig:islandplotsegsim}
\end{figure}

In contrast to Figures~\ref{fig:islandplotpsf} to~\ref{fig:islandplotseg2}, the RA and Dec values for both matches in Figure~\ref{fig:islandplotsegsim} are in perfect agreement since the fake galaxy was inserted after the astrometric solution had already been fixed. The agreement between the two matches and the true value for all other parameters is reasonable: the first match (red, orange, yellow) is generally closer to the truth than the second. It is also the deeper one of the two images, evidenced by its higher constraining power (narrower distributions). The second, shallower, image seems to suffer from some systematic uncertainty, possibly from the background subtraction (it cannot be due to the PSF since we use the true PSF used for generating the galaxy also for fitting). We do not investigate this in detail here but refer to Section~\ref{sec:systematics}, where we explore systematic uncertainties in more detail.

The differences between the different segment sizes are generally small. In particular, both versions of the dilated segments show a high degree of overlap despite their very different sizes (30\,\% area increase vs. a factor of 2.5). The undilated segment again tends to converge onto a solution that is brighter, larger and with higher S\'ersic index and differs more from the other two. This is despite it being relatively close in size to the first one of the dilated versions and again emphasises the importance of a dilation step that is independent of the pixel values to obtain an unbiased segment solution. 

In conclusion, an unbiased dilation step after the \texttt{profoundProFound} curve of growth convergence is necessary. A relatively small dilation, increasing the area only by approximately 30\,\% is sufficient to reach the parameter convergence regime for cases where there is an unambiguous solution, i.e. where the model represents the data well. At the same time it minimises influence from, e.g., background subtraction uncertainties or neighbouring objects that can become more dominant for larger segment sizes. It also ensures that when working with a model that is not a perfect fit to the data, the focus is on correctly representing the regions dominated by the galaxy flux rather than the low signal to noise outskirts or the sky background. 



\subsubsection{Segmentation map fixing}

Early versions of \texttt{ProFound} had a tendency to split up large, well-resolved galaxies with prominent substructure into several smaller segments. To combat this unwanted shredding effect, we devised a segmentation map fixing procedure using \texttt{ProFit}. This routine was used up to \texttt{v02} of the \texttt{BDDecomp} DMU. It then became redundant since we upgraded \texttt{ProFound} to its newest version which saw major changes in how the segmentation was performed. The updated version of \texttt{ProFound} was much less likely to shred galaxies, even for large and well-resolved cases with a lot of substructure. We therefore turned off our own segmentation map fixing from \texttt{v03} onwards since it was consuming unnecessary computational time and had the unwanted side effect of sometimes including faint and small sources in the segmentation map for the galaxy. Nonetheless, we briefly describe the segmentation map fixing routine here. 

After the \texttt{profoundProFound} run during the preparatory work, the galaxy is fitted with a single component S\'ersic model using the same fast downhill gradient algorithm used for the star fitting in PSF estimation (Section~\ref{sec:preparatorysteps}). Like for the ``real" galaxy fits (Section~\ref{sec:galaxyfitting}), we fit all parameters except boxyness, use only the pixels within the galaxy segment for fitting and take initial guesses from the segmentation statistics.

For each segment in the cutout around the galaxy, the flux it contains is then compared against the flux it should contain according to the fitted model: if the model flux accounts for more than 50\,\% of the total flux in the segment and the segment contains more than 1\,\% of the total model flux, then the segment is added to the galaxy segment. Point sources within the segment of interest are also identified by comparing to a smoothed version of the image and masked out. The galaxy is then re-fitted and the process repeated until no more segments are added. A diagnostic plot is returned and the fitted parameters are written to the header of the segmentation map to serve as better initial guesses in the galaxy fitting process.

Since the success of this segmentation map fixing crucially depends on the model fit, we repeat the process several times during the actual galaxy fitting. Therefore, after the first round of single S\'ersic MCMC fits, the new (better) model image is used to check again whether any segments need to be added to the galaxy segment. If this is the case, the object is flagged, the segmentation map is updated and the fit is repeated. The updated segmentation map and initial guesses (in the header) are saved along with a diagnostic plot and the final fits. This process is repeated a maximum of five times, if the galaxy segment still changes in the last round the object is flagged. 

The segmentation maps are then checked and fixed again on the basis of the model images resulting from the double component fits (using the same procedure). Galaxies where the segmentation map changed during this step are then re-fitted with single S\'ersic models to ensure that the single S\'ersic and double component fits are directly comparable (i.e. using the same segmentation map). The segmentation maps are not fixed again during this re-fitting step nor during any subsequent (1.5-component) fits of the galaxy. 

Figure~\ref{fig:segfixplot} shows an example for a galaxy with a nearby companion and two small point sources that led to it being split into several segments in \texttt{v02} of the pipeline. This can be seen in the first (leftmost) panel, where the galaxy segment is shown as a green contour and all other segments in blue. The second panel then shows the model fitted to that image during the segmentation fixing process, using the original galaxy segment only. In the third panel, we see the fixed segmentation map obtained after two iterations. Three segments have been added to the galaxy segment and two point sources masked out, such that the segmentation is now acceptable. It includes the majority of the galaxy flux, but excludes the neighbouring source. These first three panels are what is also shown in the segmentation map fixing diagnostic plot mentioned above. 

The fourth panel shows the result of the segmentation directly after upgrading \texttt{ProFound} with our own segmentation fixing routine turned off. While the segmentation is not perfect, it is much better than that shown in the first panel. The potential improvement obtained by running an additional segmentation map fixing would therefore not warrant the associated effort. Finally, the last panel shows the segmentation map obtained after all other updates and represents the one that was used for \texttt{v03} and \texttt{v04}. The main change here was the switch from a \texttt{skycut} value of one to two and the addition of a further segment dilation after flux convergence is reached (see above). The segment now has a smoother, less biased border than that in panel four, while still being of comparable size. 

\begin{figure}
	\includegraphics[width=\textwidth]{plots/segfixplot}
    \caption{An example of the segmentation map fixing for galaxy 544891. \textbf{First panel:} the galaxy segment (green) and all neighbouring segments (blue) obtained with the version of \texttt{ProFound} used up to \texttt{v02} of our pipeline overlaid on the galaxy image. \textbf{Second panel:} the model image fitted to the original galaxy segment during the segmentation map fixing procedure. \textbf{Third panel:} the galaxy segment obtained after two iterations of our segmentation map fixing procedure again overlaid on the galaxy image. \textbf{Fourth panel:} the segmentation obtained with the version of \texttt{ProFound} used from \texttt{v03} of the pipeline onwards, with all other parameters unchanged with respect to the third panel. \textbf{Fifth panel:} the final \texttt{v03} and \texttt{v04} segmentation after further updates to the procedure (see text for details). Note that for clarity we do not show neighbouring segments in panels two to five. }
    \label{fig:segfixplot}
\end{figure}



\subsection{Modelling decisions}
\label{sec:modellingdecisions}
Now that we have all the inputs defined, we move on to galaxy modelling. This is the second major step in the bulge-disk decomposition pipeline and described in some detail in Section~\ref{sec:galaxyfitting} and \citet{Casura2022}. An introduction to Bayesian analysis, the S\'ersic function and the most important reasoning for which models we choose is given in Sections~\ref{sec:bayesiananalysis} and~\ref{sec:sersicmodels}. Here, we expand on these sections by pointing out details that we did not previously cover. We assume the reader to be familiar with the contents of Sections~\ref{sec:bayesiananalysis}, ~\ref{sec:sersicmodels} and~\ref{sec:galaxyfitting} before reading this section.

\subsubsection{Free fitting parameters}

From a model selection perspective, it is advisable to have nested models, where the single S\'ersic model is entirely contained within the double component model (i.e. the double component model is an extension of the single S\'ersic fit). If this is not the case, then for some galaxies, the single S\'ersic fit may be more appropriate in some regions, while the double component fit is better in others, leaving the question of which region of the galaxy is ``more important" to fit. For nested models, the double component fit will always be at least as good as the single S\'ersic model and the only decision to make remains whether it is significantly better (i.e. so much better that the increased number of parameters is justified) or not. This can be determined by the Bayes factor (Section~\ref{sec:bayesiananalysis}) for models that accurately represent all features of the galaxy; or by simulations which capture all of said features; or by visual inspection as we did since we have neither perfect models nor perfect simulations for our diverse sample of galaxies. Having said that, we also considered some versions of non-nested models during pipeline development, as we outline below. 

The single S\'ersic function in two dimensions has a total of eight parameters. Six of those, namely position in $x$ and $y$, magnitude, effective radius, position angle and axial ratio definitely need to be fitted for all galaxies in the single S\'ersic fit, leaving only the S\'ersic index and the \texttt{boxyness} for consideration. Since our galaxy sample is diverse, containing classical elliptical galaxies as well as (pure) disk galaxies, double component galaxies and irregulars, we decided to leave the S\'ersic index of the single component fit as a free parameter for fitting. This allows to capture all of those different galaxy morphologies in just one fitting round and still leads to rapid convergence of the model parameters. 

We briefly experimented with fitting the \texttt{boxyness} as well, i.e. allowing deviations from an elliptical shape of the profile in two dimensions, at least for the single S\'ersic profile. However, this increased the time needed to achieve convergence by a factor of a few without major improvements in the fit quality determined from visual inspection. In addition, we would then need to allow for \texttt{boxyness} in the double component fits as well to keep the models nested, further increasing the fitting time and the problem of parameter degeneracies. Fixing the \texttt{boxyness} to zero leaves seven free parameters for the single S\'ersic fits, as mentioned previously.

The next complicated one of our three models is the 1.5-component model, which has a total of 11 parameters (eight for the S\'ersic function plus three for the point source). For the same reason as above, we did not consider \texttt{boxyness} and - as explained below for the double component model - we fixed the bulge and disk positions to lie on top of each other. Leaving the S\'ersic index free then results in an extension of the single S\'ersic model by just one parameter, namely the point source magnitude. However, the reason why we introduced the 1.5-component model was to fit unresolved bulges for double component galaxies, i.e. it was meant as a simplification of the double component fits and not an extension of the single S\'ersic fit. In fact, we originally added the 1.5-component fits after the single and double component fits for \texttt{v01} of the \texttt{BDDecomp} DMU were already processed, after noticing the $\sim$\,20\,\% of bulges with unconstrained parameters (very small or unrealistically large effective radii combined with excessively high or low S\'ersic indices and sometimes also low axial ratios, often hitting the fit limits in at least one of those parameters; see also Figures~\ref{fig:examplefit1.5} and~\ref{fig:examplefit1.5b}). 

To make the 1.5-component fits most directly comparable to the double component fits, we therefore fixed the disk S\'ersic index to 1. While it is still not strictly nested in the double component model, the 1.5-component model in this way simply replaces the S\'ersic bulge by a point source bulge (with just one parameter), thus serving its purpose of ``saving" the double component fits for which the bulge is ill-constrained. For the same reason, we also left the 1.5-component fits last in the order of processing even though in general it is advisable to start with simpler models and then increase complexity. Processing the 1.5-component fits last has the additional advantage that we need not worry about swapping of the bulge and disk since that has already been taken care of for the doubles (see below) and we can directly use the double component initial guesses. In summary, our 1.5-component model consists of a point source plus an exponential disk, tied to the same position. Note that this means the 1.5-component fit also has just 7 parameters and often results in a worse fit than the single S\'ersic model (e.g. for elliptical galaxies that cannot be represented well with an exponential disk).



\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth]{plots/examplefit15}
\caption{An example of a 1.5-component fit for galaxy 124052 in the KiDS $r$-band. Panels are the same as those in Figure~\ref{fig:examplefit}.}
\label{fig:examplefit1.5}
\end{center}
\end{figure}

\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.8\textwidth]{plots/examplefit15b}
\caption{The double component fit for galaxy 124052 (classified as 1.5-component object) in the KiDS $r$-band, for direct comparison to the 1.5-component fit in Figure~\ref{fig:examplefit1.5}. }
\label{fig:examplefit1.5b}
\end{center}
\end{figure}

An example of such a 1.5-component fit is shown in Figure~\ref{fig:examplefit1.5}, with panels the same as in Figure~\ref{fig:examplefit}. For direct comparison, we show the double component fit in Figure~\ref{fig:examplefit1.5b}. The two fits are visually indistinguishable and their disk parameters are very similar. However, the double component fit has a bulge S\'ersic index of 20 and an effective radius of 0.1\arcsec\ (0.5\,pix), combined with an axial ratio of 0.05, thereby hitting all three of those fit limits. These values (as well as the position angle) are meaningless, but they do influence the fitted magnitude, which is 21.5\,mag for the double component model. The point source model does not fit any of the meaningless parameters and instead produces a more robust magnitude estimate of 22.4\,mag. 

Both the single S\'ersic and 1.5-component fits tend to converge rapidly and without problems as there are only few parameter correlations. As explained above, the decisions for which parameters to fit were mostly done on a theoretical basis and straightforward. Most of the remaining discussion focuses on the double component models, where there are many more parameter correlations and degeneracies and therefore also more options to consider in how to limit those. 

The double component model has a total of 15 parameters (8 for the S\'ersic function and 7 for the exponential). Based on our experience with the single S\'ersic fits, we did not consider \texttt{boxyness} for either of the two components. Another natural choice to make is to tie the bulge and disk positions together due to the symmetry of ``typical" galaxies. Nonetheless, we also considered leaving the bulge and disk positions independent from each other to better capture disturbed morphologies. Unfortunately, this frequently led to one of the components wandering off to fit overlapping point sources or wings of other objects, specifically when the main part of the galaxy can be adequately represented by a single component. Conversely, it only significantly increased the fit quality for objects with an irregular morphology that are difficult to represent with our symmetrical models even when allowing offset bulges. Hence, we decided to tie the bulge and disk positions together to lie exactly on top of each other. This leaves a total of 11 free parameters for the double component model, which we also used in the end despite numerous considerations to limit the degrees of freedom further (see below). 



\subsubsection{Constraints on bulges}

Some of the considerations to reduce the degrees of freedom of the double component fit involved tying the position angle of the bulge to that of the disk or forcing the bulge to be round (i.e. setting the axial ratio to 1, or >\,0.8 or similar); and/or setting the S\'ersic index of the bulge to 4 or limiting it to be larger than, e.g., 2. All of these measures can be used to ensure that the bulge component does indeed fit a classical bulge and not other features such as pseudo-bulges or bars. However, as explained in Section~\ref{sec:sersicmodels}, it is not our aim to fit classical bulges only and instead we use the S\'ersic component of the model to explicitly fit all morphological features near the centre of the galaxy. Constraining the bulge to be round or have a high S\'ersic index would therefore be counterproductive.

Nonetheless, for versions of the pipeline up to \texttt{BDDecomp v02}, we used a lower limit on the bulge S\'ersic index of 1. The idea was that the bulge profile is then always steeper than the disk (or of the same steepness), so it is more likely that it will dominate the inner parts of the galaxy and not the outskirts (i.e. to avoid swapped fits). However, there were several problems with that approach. First of all, a significant fraction of bulges converged onto the lower limit ($\sim$\,18\,\%, with a further 33\,\% being consistent with the lower limit within errors, i.e. 51\,\% in total), thereby producing unreliable fits with unrealistic error estimates. Second, a number of pseudo-bulges, bars and broad cores (often galaxies with slightly disturbed morphologies, for which, however, acceptable fits are still achievable) could not be appropriately represented as they showed flattened profiles towards the centre. Third, we imposed the same lower limit on the single S\'ersic fits to keep the models nested, which led to $\sim$\,11\,\% of these converging onto the lower limit as well (with another 13\,\% consistent with the lower limit within errors, so 24\,\% in total). An example of a single S\'ersic object with a flattened core (S\'ersic index of 0.6) is shown in Figure~\ref{fig:examplefitlown}. For comparison, Figure~\ref{fig:examplefitlown2} shows the fit to the same galaxy in \texttt{v01} of the catalogue, where the S\'ersic index converged onto its lower limit of 1 and is clearly not able to capture the profile of the galaxy accurately. 

\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth]{plots/examplefitlown}
\caption{An example of a single S\'ersic fit with a low S\'ersic index (0.6) for galaxy 220084 in the KiDS $r$-band. Panels in the top two rows are the same as those in Figure~\ref{fig:examplefit}, while the bottom row shows the one-dimensional fit only, corresponding to the rightmost panel of the bottom row in Figure~\ref{fig:examplefit}.}
\label{fig:examplefitlown}
\end{center}
\end{figure}

\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.8\textwidth]{plots/examplefitlown2}
\caption{The \texttt{v01} single S\'ersic fit to galaxy 220084, where the S\'ersic index converged onto its (then) lower limit of unity; for direct comparison to Figure~\ref{fig:examplefitlown}.}
\label{fig:examplefitlown2}
\end{center}
\end{figure}

Finally, limiting the bulge S\'ersic index to be larger than one only helped in part against swapped fits since the flux ratio of the components is not solely determined by their respective S\'ersic indices but also by their relative effective radii, magnitudes and axial ratios; and high S\'ersic index bulges in particular can also dominate both the inner and the outer parts of the galaxy at the same time. From \texttt{v03} of the pipeline onwards, we therefore adjusted the S\'ersic index lower limit to 0.1 for all models. At the same time, we increased the upper limit on all S\'ersic indices from 12 to 20 to avoid fits hitting the limits (even though the difference in the actual profile is small at such high S\'ersic indices). This reduced the number of fits hitting either of the S\'ersic index limits to 0.3\,\% for the single S\'ersic models (including those consistent with the limit within errors), of which approximately two thirds were classified as outliers and the last third as 1.5-component fits. For the double S\'ersic models, 15\,\% still hit their bulge S\'ersic index limits, of which 60\,\% were classified as single S\'ersic fits, 14\,\% as 1.5-component fits and the remaining 26\,\% as outliers.

In another attempt to stop the bulge and disk components from swapping, we also ex\-pe\-ri\-men\-ted with limiting the effective radius of the bulge to be smaller than that of the disk. Unfortunately, this did also not have the desired effect, as the precise meaning of the effective radius strongly depends on the S\'ersic index and the two parameters (as well as the magnitude) are highly correlated. For example, a bulge with a high S\'ersic index can easily dominate the flux in the central parts of the galaxy even if its effective radius is comparable to or larger than that of the disk (with a S\'ersic index of 1). 

\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.8\textwidth]{plots/examplefitbulgere}
\caption{The double component fit to galaxy 136866, where the bulge effective radius is much larger than that of the disk. Panels are the same as in Figure~\ref{fig:examplefit}}
\label{fig:examplefitbulgere}
\end{center}
\end{figure}

An example is shown in Figure~\ref{fig:examplefitbulgere}. The bulge and disk clearly dominate the inner and outer parts of the galaxy respectively. Nonetheless, the bulge effective radius is a factor of more than six larger than that of the disk due to its high S\'ersic index of 15.8. This is frequently the case especially since we fit only the pixels in relatively small segments, so the extended wings of a high $n$ S\'ersic function fall beyond the fitting region and are effectively ignored.\footnote{On a side note, when limiting the effective radii to the segment values, the disk $R_e$ is a factor of about 2 larger than that of the bulge. However, since we truncate to segment radii in a post-processing step, we cannot use this during the fit itself.} 

Given the limited success of our attempts to avoid swapped components by constraining the bulge parameters, we have instead devised a separate routine to swap the components of galaxies where necessary, see Sections~\ref{sec:galaxyfitting} and~\ref{sec:swappingandoutliers}. 


\subsubsection{Priors and initial guesses}

One other route towards influencing the fit without imposing hard cuts is by using differing initial guesses, as we do in our swapping routine (Section~\ref{sec:galaxyfitting}). However, one of the main strengths of an MCMC analysis is that it is less dependent on initial guesses than e.g. downhill gradient fitting. When starting very close to a local maximum (as we do for the swapped fits), the fit is more likely to converge onto that. Similarly, when starting very far from any maximum (i.e. in the flat part of the likelihood space), convergence takes much longer and fails more frequently. For any ``reasonable" initial guesses, however, the fit result will not depend strongly on them. We obtain such reasonable initial guesses from the segmentation output of \texttt{profoundProFound} and further improve them via a fast downhill gradient algorithm before starting the MCMC (see Section~\ref{sec:fittingspecifics}). The details of, e.g., how to convert the \texttt{profoundProFound} concentration to a S\'ersic index initial guess, how to split the total flux between the bulge and disk initially, what ratio of effective radii to use and the starting value of the bulge S\'ersic index were the subject of several investigations but were found to have little effect on the fit results. 

Arguably the most ``Bayesian" way to constrain parameters is via priors. These can be hard cuts - like the fixed intervals that we use for fitting parameters - or soft, like for example Gaussian functions of a certain width centred on the most likely value. However, when imposing such informative priors, they should be based on previous knowledge (e.g. from previous data) rather than general trends or notions since they will directly affect the posterior and can even dominate over the likelihood if the prior is strong and/or the likelihood is weak due to a limited quality or quantity of data. To get the most unbiased estimate of the parameters based on the data alone it is therefore wise to choose uninformative, broad priors. 

We do this by imposing fixed limits, but using flat priors within these limits (in logarithmic space where appropriate). The limits are listed in Table~\ref{tab:singlefitlimits} and are deliberately very broad. Most of them are based on physical considerations (e.g. the axial ratio cannot be larger than 1) or limitations of the data (e.g. if the effective radius is less than 0.5\,pix, more than half of the total light of the profile is contained within a single pixel, at which point the accuracy of the PSF is very likely not sufficient anymore). The only exception to this is the S\'ersic index, for which we discuss the limits in some detail above. 

Note that as we mention in Section~\ref{sec:galaxyfitting}, we do not normalise our priors, leading to unnormalised posteriors. In theory, normalised posteriors are important to obtain meaningful Bayes' factors for model selection. In practice, we found that in our case even with normalised posteriors the model selection needs manual calibration due to the model inadequacy. Leaving the priors unnormalised has the advantage that the prior ranges do not influence the posterior and so we do not need to re-calibrate the model selection every time for different test runs with different prior intervals. It also allows to easily put infinity as the upper limit on component magnitudes and instead constrain the total magnitude of the double component fit, which otherwise would require a somewhat non-trivial joint prior to be normalisable.


\subsection{Fitting specifics}
\label{sec:fittingspecifics}
After the models are defined, there are a number of decisions to be made with regards to the actual fitting. These are summarised in Section~\ref{sec:galaxyfitting}. In the following, we point out additional details regarding the logarithmic fitting of scale parameters, the choice of likelihood function, the fitting algorithms and routine and the assessment of convergence. 

\subsubsection{Logarithmic fitting}

From a theoretical point of view, scale parameters (in our case those are the effective radius, S\'ersic index and axial ratio) are best fitted in logarithmic space, while location parameters (position, magnitude and angle) should be fitted in linear space. This is because a ``step size" for location parameters remains constant across the entire parameter range, so, e.g., the difference between a position angle of 5\degr\ and 10\degr\ is the same as that between 170\degr\ and 175\degr. For scale parameters, the step size changes across the parameter range (in linear space), for example the difference in profile shape between a S\'ersic index of 0.5 or 1 (Gaussian or exponential) is much larger than that between a S\'ersic index of 18.5 or 19 (nearly indistiguishable). Converting scale parameters into logarithmic space, i.e. fitting $\log_{10}(X)$ instead of $X$ for scale parameters $X$, equalises the step size across the (now logarithmic) parameter range again.\footnote{For the same reason, relative errors are more meaningful than absolute errors for scale parameters; and vice versa for location parameters.} Note that intensity or brightness are also scale parameters, but since magnitude is already a logarithmic measure of flux, it becomes a location parameter.\footnote{Hence why colours are calculated as magnitude differences rather than ratios.}

Given this theoretical background and the functionality of \texttt{ProFit} to easily specify which parameters should be fitted in logarithmic space (with conversions to and from logarithmic space performed internally), it seemed natural to fit scale parameters in logarithmic space. Nevertheless, we tested the effect of fitting in linear space for one or several of the scale parameters during our test runs. Fitting all parameters in linear space approximately doubled the computational time needed for single S\'ersic fits compared to logarithmic fitting of all scale parameters, while no systematic differences in the estimated parameters could be observed. 

The difference in computational time highlights the importance of choosing similar step sizes in all parameters for rapid convergence. With the logarithmic fitting of scale parameters and our chosen fitting intervals, we arrive at comparable step sizes for all parameters with one exception: the position angle. To ensure convergence of the position angle we therefore (linearly) re-scaled this parameter into units of 30\degr. All fitting parameters then have similar ranges in absolute terms (in their respective, potentially logarithmic, fitting units), as also evident from Figure~\ref{fig:differrnorm} (the absolute values of all parameters vary in a range of about $\pm$\,0.05 around the true value; and the absolute errors are on comparable scales for all parameters). 


\subsubsection{Likelihood function}

In Bayesian modelling, the probability of the observed data given an (assumed) model is called the likelihood (Section~\ref{sec:bayesiananalysis}). Calculating it requires knowing or assuming a likelihood function that takes the data and model as input and returns the corresponding probability. This can in theory be any function, but is most often a ``standard" function appropriate to the statistical problem at hand, such as a Gaussian, chi-squared, Poisson or Student's t-distribution, all of which are supported by \texttt{ProFit}. 

KiDS data is expected to have random Normal errors with pixel-specific standard deviations expressed in the sigma map (Section~\ref{sec:preparatorysteps}), which in turn is a combination of the KiDS weight maps and the object shot noise. For a perfect model, the log-likelihood can therefore simply be calculated as the sum of the Gaussian probabilities to obtain each measured flux value given the model flux value of the corresponding pixel and its error from the sigma map (\texttt{ProFit} does this internally). The correct likelihood function to use is therefore the Normal one, provided the model is a perfect fit to the data. 

To accommodate models that are not perfect fits to the data at hand (i.e. most of our models for the majority of our galaxies), \texttt{ProFit} supports the use of a Student's t-likelihood instead. This evaluates the probability of the data given the model and errors under the assumption of a Student's t-distribution rather than a Gaussian one, optimising the degrees of freedom of the Student's t-distribution at the same time. Due to the broader wings of the Student's t-distribution, this effectively downweights the regions of the galaxy that cannot be captured by the model during the fit. This makes it more robust for the purpose of galaxy fitting. 

\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.8\textwidth]{plots/examplefitnormvst1}
\caption{The Student's t-likelihood function single S\'ersic fit to galaxy 177705 (a double component object) in the KiDS $r$-band. Panels in the top two rows are the same as those in Figure~\ref{fig:examplefit}, while the bottom row shows the one-dimensional fit only, corresponding to the rightmost panel of the bottom row in Figure~\ref{fig:examplefit}.}
\label{fig:examplefitnormvst1}
\end{center}
\end{figure}

\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.8\textwidth]{plots/examplefitnormvst2}
\caption{The Normal likelihood function single S\'ersic fit to galaxy 177705, for direct comparison to Figure~\ref{fig:examplefitnormvst1}.}
\label{fig:examplefitnormvst2}
\end{center}
\end{figure}

As an example, we show the single S\'ersic fit to galaxy 177705 using a Student's t-likelihood in Figure~\ref{fig:examplefitnormvst1} and the fit to the same galaxy with a Normal likelihood in Figure~\ref{fig:examplefitnormvst2}. This galaxy needs two components to be accurately represented. Fitting it with just a single S\'ersic function gives different results for the two likelihood functions: the Student's t-likelihood is more likely to ``tolerate" a few pixels that are in high tension with the model (i.e. pixels belonging to the bulge) if this allows a better fit on average to the remainder of the galaxy. A normal likelihood instead ``tries harder" to avoid strong outliers and compromises more between fitting both components, even if that results in a generally slightly worse fit over larger areas such as the disk. While in the example here it is debatable which option is to be preferred, a Student's t-distribution is definitely prefereable if the pixels in high tension are - e.g. - an overlapping foreground point source or a clumpy component of a star-forming spiral arm. 

Since our models are generally a simplification of the true complexity of galaxies, we would expect a Student's t-distribution to be more suitable to our analysis. This was therefore the default likelihood we used initially. Unfortunately, though, it turned out to have several problems as already outlined in Section~\ref{sec:galaxyfitting}. For the final pipeline, we therefore use a Normal likelihood function for all galaxies. Since this decision was made entirely during the test runs, the \texttt{BDDecomp} DMU has only Normal likelihood function fits from \texttt{v01} onwards already. However, we still like to point out the development over the test runs, since this was a major point of concern and one aspect in which the final decision does not meet the theoretical expectations. 

\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.8\textwidth]{plots/examplefitnormvst3}
\caption{The Student's t-likelihood function single S\'ersic fit to galaxy 534802, which is well-represented by a single S\'ersic profile, in the KiDS $r$-band. Panels in the top two rows are the same as those in Figure~\ref{fig:examplefit}, while the bottom row shows the one-dimensional fit only, corresponding to the rightmost panel of the bottom row in Figure~\ref{fig:examplefit}.}
\label{fig:examplefitnormvst3}
\end{center}
\end{figure}

\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.8\textwidth]{plots/examplefitnormvst4}
\caption{The Normal likelihood function single S\'ersic fit to galaxy 534802, for direct comparison to Figure~\ref{fig:examplefitnormvst3}.}
\label{fig:examplefitnormvst4}
\end{center}
\end{figure}

\begin{figure}[hb!]
\begin{center}
\includegraphics[width=0.8\textwidth]{plots/normvsthist}
\caption{The distribution of the Student's t-distribution degrees of freedom for a set of test galaxies (solid black line) and for the subset of those that achieves a better fit with a Student's t-likelihood compared to a Normal likelihood (dashed orange line). The dotted blue line shows the selection cut for deciding which likelihood function to use.}
\label{fig:normvsthist}
\end{center}
\end{figure}

The first problem of using Student's t-distribution likelihood functions became apparent for galaxies that are perfectly represented by their respective model. In this case, as explained above, the errors truly are distributed Normally. The Student's t-distribution, however, ``expects" a certain fraction of pixels that are in tension with the model and - if they are not present - will artificially produce them by making the fit unnecessarily worse. An example for this is shown in Figures~\ref{fig:examplefitnormvst3} and~\ref{fig:examplefitnormvst4} for galaxy 534802. This object can be perfectly represented by a single S\'ersic component, as evident from the fit with a Normal likelihood function. The fit with the Student's t-likelihood, though, shows considerable residuals. 

We concluded that fitting all galaxies with a Student's t-likelihood is unsuitable and instead a certain fraction, namely those approximately 20\,\% of galaxies that are perfectly captured by one of our models, need a Normal likelihood function. The correct way to decide which likelihood function to use would be to fit each galaxy twice (once with each likelihood function) and then choose the one which achieves the better fit, i.e. the higher likelihood. However, we noticed that the degrees of freedom estimated for the Student's t-likelihood during the fit can provide a shortcut to save computational time. 

As the degrees of freedom of the Student's t-function approach infinity, its distribution approaches that of a Gaussian. It is therefore not surprising that the degrees of freedom converge onto a large value for those galaxies that would be better fitted by a Normal likelihood. First fitting all galaxies with a Student's t-likelihood therefore allows to select only a subset of galaxies for re-fitting with a Normal likelihood based on a cut in the degrees of freedom of the Students's t-function. 

We demonstrate this in Figure~\ref{fig:normvsthist} for a test sample of KiDS $r$-band galaxies that we fitted with both likelihood functions. The solid black histogram shows the degrees of freedom of the Student's t-distribution for all galaxies in the test sample. There is a clear peak encompassing the majority of galaxies at low values of degrees of freedom and a long tail to very large values (note the logarithmic scaling of both axes). With a dashed orange line, we overplot the subset of galaxies that are better fitted with a Student's t-likelihood, i.e. those that achieve a higher likelihood with a Student's t-likelihood than with a Normal one. This encompasses essentially all of the galaxies with low degrees of freedom and none of those with high values (for which a Normal likelihood function achieves a better fit). 

The dotted blue line indicates our selection cut for deciding which galaxies to re-fit with a Normal likelihood function, namely those for which the degrees of freedom of the Student's t-likelihood function fit converged to values larger than 100. Note that this cut is de\-li\-be\-ra\-te\-ly more to the left, since galaxies to the left of this line will only be fitted with a Student's t-\\\\distribution (therefore missing the best fit for any galaxies in that sample for which a Normal likelihood would be better suited), while those to the right of the line will be fitted with both likelihoods such that the optimal likelihood can still be chosen based upon which achieves the better fit (therefore only wasting a small amount of computational time on the galaxies in that sample for which a Student's t-likelihood is better suited).  

These distributions look similar for double component fits and in other bands, although the relative numbers of galaxies which are better fitted with a normal or a t-distribution likelihood function changes due to the different depths and seeing. In summary, at early stages during pipeline development, we first fitted all galaxies using a Student's t-likelihood function. Then, galaxies for which the degrees of freedom of the Student's t-distribution converged onto values larger than 100 were fitted again with a Normal likelihood function (for all models independently). For all galaxies fitted twice with the same model, we selected the better fit according to which achieved the higher likelihood. 

The exact order of processing (including the segmentation map fixing steps used in earlier versions of the pipeline, cf. Section~\ref{sec:segchoices}) was as follows:\footnote{We subsequently extended this procedure to include 1.5-component fits; and then simplified it again by first dropping the Student's t-likelihood fits and later also the segmentation map fixing; see Section~\ref{sec:galaxyfitting} for the final \texttt{v04} procedure.}
\begin{enumerate}[label=(\roman*)]
\item Run the galaxies through the preparatory work pipeline, including downhill-gradient single S\'ersic fits for the segmentation map fixing. 
\item Do single component Student's t-likelihood function fits on all galaxies using the output of the preparatory work as initial guesses (more precisely the fits from the segmentation fixing) and the corresponding segmentation maps. Check whether segmentation maps need fixing after the fit and iterate if needed.
\item Do double component Student's t-likelihood function fits on all galaxies now using the outputs of the previous step as initial guesses and also using the updated segmentation map. Again check whether the segmentation maps need updating and iterate if needed.
\item Re-run the single component Student's t-likelihood function fits for the galaxies for which the segmentation map changed again during the double component fits. This uses the output of the previous single component fit as initial guess, but takes the updated segmentation map (after the double component fit) to make all segmentation maps used consistent for model selection. Do not change the segmentation maps anymore in this run.
\item Run single component Normal likelihood function fits for the galaxies for which the degrees of freedom of the single component Student's t-likelihood fit were greater than 100 or the fit failed (which happened in a number of cases when the degrees of freedom reached infinity). Use the previous single component fits as initial guesses and do not change the segmentation maps. 
\item Run double component Normal likelihood function fits for the galaxies for which the degrees of freedom of the double component Student's t-likelihood fit were greater than 100 or the double component fit failed. Use the previous double component fits as initial guesses and do not change the segmentation maps.
\item Repeat these steps for all desired bands.
\end{enumerate}



This procedure solved the first problem that we encountered using Student's t-likelihood functions (the unnecessary residuals for perfect fits). There was, however, one other major problem which eventually prompted us to use Normal likelihood functions for all fits: the Student's t-likelihood function fits frequently missed the bulges in double component fits. 

\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.8\textwidth]{plots/examplefitnormvst5}
\caption{The Student's t-likelihood function double component fit to galaxy 595088 in the KiDS $r$-band. Panels are the same as those in Figure~\ref{fig:examplefit}.}
\label{fig:examplefitnormvst5}
\end{center}
\end{figure}

\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.8\textwidth]{plots/examplefitnormvst6}
\caption{The Normal likelihood function double component fit to galaxy 595088, for direct comparison to Figure~\ref{fig:examplefitnormvst5}.}
\label{fig:examplefitnormvst6}
\end{center}
\end{figure}

An example of this is shown in Figures~\ref{fig:examplefitnormvst5} and ~\ref{fig:examplefitnormvst6} for galaxy 595088. This is a bright and well-resolved object with clear evidence of a bulge, bar, disk, ring and spiral arms. Fitting only two components will not allow to capture all of these details, and the results obtained with the two different likelihood functions differ greatly. Similar to the single S\'ersic example in Figures~\ref{fig:examplefitnormvst1} and \ref{fig:examplefitnormvst2}, the Student's t-likelihood fit ignores the bulge and instead uses the freedom of the S\'ersic component to fit disk features that cannot be captured by the exponential model. This is because the Student's t-function ``prefers" a few strong outliers over many weak ones, which can be an advantage as explained above. In this case, though, this behaviour is highly undesirable since we explicitly intend the S\'ersic component of the double component fit to represent the central regions of the galaxy and not to capture deviations of the disk from an exponential profile. The Normal likelihood function fit instead fits both components, as desired. 

Many of our experiments with initial guesses, priors and constraints on bulge parameters (Section~\ref{sec:modellingdecisions}) were attempts to recover those ``missing" bulges. As explained above, they were not successful and in the end, the solution was to use a Normal likelihood function for all fits. This is therefore what we do in the current pipeline (and earlier versions including \texttt{v01} of the \texttt{BDDecomp} DMU). It has the added advantage that each model only needs to be fitted with one likelihood function, thereby saving computational time. In addition, it facilitates the manual calibration of the model selection, which is non-trivial if different galaxies and potentially also different models for the same galaxy use different likelihood functions. 


\subsubsection{Optimisation algorithm}

One of the main assets of \texttt{ProFit} (cf. Section~\ref{sec:profit}) is that its pixel integration is faster and more accurate than that of other commonly used algorithms, which allows us to use a more robust but also more computationally expensive MCMC algorithm instead of simple downhill gradient optimisers even for our relatively large sample of galaxies. As briefly mentioned before, \texttt{ProFit} allows great flexibility and can be combined with a variety of optimisation algorithms, including more than 60 variants of MCMC from the \texttt{LaplacesDemon} package as well as various downhill gradient optimisers and genetic algorithms. While we definitely want to make use of the advantages of the MCMC options, the questions remained whether it would be best to combine this with some of the other options, which MCMC variant(s) to use and how to ensure and assess convergence. 

Instead of devising our own routine, we opted to use the \texttt{convergeFit} function from the \texttt{AllStarFit} package \citep{AllStarFit}, which has already been optimised to achieve convergence within reasonable computational times by \citet{Taranu2017}. As briefly mentioned in Section~\ref{sec:galaxyfitting}, this function uses a combination of different downhill gradient optimisers followed by several MCMC fits until its internal convergence criterion is met. 

The downhill gradient optimisers are taken from the \texttt{nloptr} package \citep{nloptr} and are used first to improve the initial guesses with little computational effort. The MCMC chain is not very sensitive to the initial guesses, but converges much faster if starting close to the peak of the likelihood. In most cases, the downhill gradient algorithm will improve the initial guesses by moving closer to the peak of the likelihood, saving computational time. There can be cases where the downhill gradient moves in the ``wrong" direction and/or becomes stuck in a local maximum, in which case it may then take the MCMC chain slightly longer to leave the local maximum and find the globally best fit. However, since this only happens in a minority of cases and the time loss is small compared to the time savings in successful cases, we still save large amounts of computational time overall. Apart from that, even an MCMC algorithm would tend to first explore the local maximum if starting close to it, so skipping the downhill gradient step may not actually shorten fitting times for galaxies with initial guesses close to local maxima. 

After the downhill gradient algorithms have converged, \texttt{convergeFit} starts an MCMC chain with 500 iterations using the Hit-and-Run-Metropolis (HARM)\footnote{Both HARM and CHARM are variants of the Hit-And-Run algorithm introduced by \citet{Turchin1971}.} algorithm in the \texttt{LaplacesDemon} package \citep{LaplacesDemon}. This process is repeated until convergence is reached, where convergence is defined as the fractional change in the log-likelihood between two runs being less than $e$. We compare this criterion to other measures of convergence and stationarity below. 

As a last step, the Componentwise Hit-and-Run-Metropolis (CHARM), also from \texttt{LaplacesDemon}, is run with 2000 iterations and again repeated until convergence (usually only once since the chains have converged already using HARM). This algorithm is more robust but also a lot slower than HARM, hence it is only called in the end to collect likelihood samples around the peak which has already been found in previous steps. For further analysis of the galaxy it is then assumed that all samples returned by CHARM are stationary, see below for a test of this assumption.

On average, for the $r$-band fits of \texttt{v04} of the \texttt{BDDecomp} DMU, the entire fitting procedure takes 7.6\,minutes per galaxy for the single S\'ersic fits, 28.9\,minutes for the initial double component fits, 27.5\,minutes for the swapped double component fits (only performed on approximately one third of all galaxies) and 6.0\,minutes for the 1.5-component fits. In total, the computational time to fit all models and including the preparatory work and post-processing is just under one hour per galaxy, although with strong variations for individual objects depending on their size and complexity (i.e. how rapidly convergence can be reached) and whether or not they enter the second round of double component fits for swapping.

We also tested just using 10\,000 CHARM iterations, without any of the downhill gradient or HARM steps and simply assuming convergence is reached after such a large number of iterations. This is the approach taken in some other works based on \texttt{ProFit} fitting of galaxies, e.g. \citet{Cook2019} and \citet{Hashemizadeh2022}. Compared to the \texttt{convergeFit} function, this procedure drastically increased the computational time for the vast majority of our galaxies (by a factor of about four on average) with no systematic differences in the fit results and no improvements to the convergence or stationarity criteria. 


\subsubsection{MCMC convergence}

Judging the convergence (or equivalently, stationarity) of a chain is one of the main challenges in MCMC analysis with no universal solution.\footnote{We use the terms ``convergence" and ``stationarity" interchangeably here, although in detail they are not exactly the same.} Hence, all algorithms require user input regarding the stopping criterion; in the HARM and CHARM algorithms this is simply the number of iterations to perform. However, depending on the galaxy morphology, the number of iterations required to achieve chain convergence can be vastly different, so to achieve stationary results for all galaxies of a large sample while still retaining some computational efficiency, a fixed number of iterations is not suitable and a more flexible stopping criterion is needed. In the \texttt{convergeFit} function, this is implemented via repeated chains of 500 (or 2000 for CHARM) iterations each, which are judged for convergence comparing to the previous batch of 500 (2000) iterations: a chain is considered stationary if the fractional change in the log-likelihood obtained from the current batch is less than $e$ compared to the previous batch. The threshold ($e$) is somewhat arbitrary and has been chosen based on visual inspection (Dan Taranu, private communication). According to this criterion, all of our fits have converged. 

There are many other ways to assess stationarity, such as the BMK diagnostic \citep{Boone2014}, the Geweke Diagnostic \citep{Geweke1992}, the Heidelberger Diagnostic \citep{Heidelberger1981, Heidelberger1983}, or the Kolmogorov-Smirnov Convergence Diagnostic \citep{Brooks2003} to name just a few of the tools available in the \texttt{LaplacesDemon} package. All of them have in common that they are ultimately based on an arbitrary threshold of some form; and that there can be difficulties with multivariate chains, especially if correlations between parameters exist (which they do in our case, in particular the magnitude, S\'ersic index and effective radius are generally (anti-)correlated). Nonetheless, we investigated the first two of those in more detail. 

The BMK diagnostic is based on calculating the Hellinger distances \citep{Hellinger1909} between consecutive batches of the chain and is automatically computed when running \texttt{LaplacesDemon}. According to this criterion, 29\,\% of our $r$-band single component fits are not converged; and the majority of the double component fits. The Geweke diagnostic looks for trends or changes in moments in the given samples to assess stationarity and can easily be computed from the MCMC chain. According to this, 87\,\% of the $r$-band single component fits (and almost all double component fits) are non-stationary. Cross-comparing the two criteria shows that 30\,\% of the Geweke-non-stationary single component fits are not converged according to the BMK diagnostic; and vice versa 89\,\% of the BMK-non-converged single component fits are not stationary according to the Geweke diagnostic. These fractions are very similar to the fractions in the full sample (30\,\% vs. 29\,\% and 89\,\% vs. 87\,\%), so the two criteria seem only marginally (if at all) correlated. Also, the percentages are very similar when increasing the number of iterations; when re-fitting the galaxies using the previous fits as initial guesses and when using simulated galaxies for which we know that parameters are well-recovered (cf. Section~\ref{sec:simulations}). 

In addition, we visually inspected some of the chains that were flagged as converged/stationary by both criteria as well as some that are non-converged/non-stationary according to both criteria and could not see an obvious difference between the two samples. As a demonstration, we show the chains for the single component fits for two example galaxies in Figures~\ref{fig:islandplotconv1} and~\ref{fig:islandplotconv2}, where the chain that is not converged according to either criterion visually appears to be more stable than the one that is converged according to both criteria. \\

\begin{figure}[t!]
	\includegraphics[width=\textwidth]{plots/islandplotconv1}
    \caption{The MCMC chain for the $r$-band single component fit of galaxy 136524 that is neither converged according to the BMK diagnostic nor stationary according to the Geweke diagnostic. Panels are the same as in Figure~\ref{fig:islandplotpsf}.}	
    \label{fig:islandplotconv1}
\end{figure}

\begin{figure}[t!]
	\includegraphics[width=\textwidth]{plots/islandplotconv2}
    \caption{The MCMC chain for the $r$-band single component fit of galaxy 136851 that is converged/stationary according to both the BMK diagnostic and the Geweke diagnostic, for direct comparison to Figure~\ref{fig:islandplotconv1}.}	
    \label{fig:islandplotconv2}
\end{figure}

For all of these reasons, we decided to keep the default convergence criterion used in the \texttt{convergeFit} function rather than implementing a more complicated diagnostic with no obvious advantages. We assume the last 2000 CHARM samples are sufficiently stationary for our needs based on the visual inspection of a number of example chains and the simulations (Section~\ref{sec:simulations}). 




\subsection{Manual calibrations}
\label{sec:swappingandoutliers}
While the \texttt{v04} pipeline is fully automated, it depends on several tuning parameters that required manual calibrations based upon visual inspection during pipeline development. We point these out here as they may not be directly transferable to other bands or types of data with different depths and resolutions and therefore require special attention. We consequently also consider them separately in Section~\ref{sec:pipelineupdates}, where we introduce the VIKING data and hence need to re-calibrate some of the visual inspections (Section~\ref{sec:manualcalibrationchanges}). 

The first notable manual calibration is the selection of star candidates for the PSF estimation, which we describe in Section~\ref{sec:psfdetails}. It depends on the depth of the data used for the segmentation map and the exact segmentation procedure. We hence re-calibrated this for each of the individual bands as well as for the segmentation maps obtained from the stacked $gri$ images and double-checked the calibrations (adjusting when needed) every time when there were major changes in the segmentation procedure. See details in Section~\ref{sec:psfdetails}. 

The second manual calibration of the preparatory work pipeline is the $\chi^2_\nu$-cut to exclude stars which visually appear as a bad fit from the model PSF creation, see Section~\ref{sec:psfdetails}. Which cut is appropriate depends mainly on the segment size, since the reduced chi-squared within the segment will generally decrease for larger segments due to the larger number of background pixels with little deviations from the model. This effect is amplified by the fact that the KiDS weight maps are generally conservative, such that the true pixel errors tend to be smaller than the standard deviations quoted in the sigma map (cf. Section~\ref{sec:otherprepworkchoices}). We therefore re-calibrated this cut whenever there were major changes in the segmentation procedure, such as between \texttt{v02} and \texttt{v03} of the pipeline. 

Since we have described both of these manual calibrations in the preparatory work pipeline in detail before, we do not elaborate on them further here. However, there are three more procedures based upon visual inspection during the fitting and post-processing, namely the criteria for swapping components, those for flagging bad fits and the calibration of the DIC cuts for the model selection. These are listed in Sections~\ref{sec:galaxyfitting} and~\ref{sec:postprocessing}, with more details and diagnostic plots given below.

In addition to these manual calibrations, our estimation of systematic errors (Section~\ref{sec:systematics}) is based on simulations that were tuned to reproduce KiDS $r$-band single S\'ersic fits for our sample of galaxies with our pipeline. They may not be transferable to other bands, other models, a different pipeline or different samples of galaxies. 

\subsubsection{Swapping of components}

The two components of the double component model are nearly identical, with the only difference being the S\'ersic index, which is a free fitting parameter for the bulge and fixed to 1 (exponential) for the disk. This similarity of the profiles leads to frequent swapping of the two components, such that around 20-30\,\% of the double component fits have the ``disk" dominating the flux in the inner regions of the galaxy and the ``bulge" the outskirts. This is a common problem in galaxy fitting and usually requires some form of post-processing, see e.g. the logical filter in \citet{Allen2006}. We attempted to reduce the fraction of swapped fits by constraining the bulge parameters in various ways, see Section~\ref{sec:modellingdecisions}. These methods, which would solve the problem at the fitting stage, had very limited success. We therefore developed a separate routine for reducing the number of swapped components that is somewhat at the interface between fitting and post-processing: the double component models are fitted, then the swapping routine is applied, including an additional fitting step for a subsample of galaxies (about one third of the full sample). This routine is outlined in Section~\ref{sec:galaxyfitting} and results in the number of swapped fits being reduced to $\sim$\,1-2\,\%. We supplement Section~\ref{sec:galaxyfitting} here with more information on how the routine was developed and some diagnostic plots. 

Note that the 1.5-component fits do not suffer from swapped components for two reasons. First, they are last in the order of processing, such that the double component models have already been fitted and swapped where necessary. The 1.5-component fits benefit from these results as initial guesses and are therefore very unlikely to swap the components again. Second, and maybe even more importantly, the 1.5-component fits have much fewer degrees of freedom than the double component fits. The point source bulge is defined by just a single parameter - the magnitude - and offers very little flexibility to fit deviations of the disk from an exponential profile (which is the most common reason why the S\'ersic component in the double component model fits the disk rather than the bulge). We therefore only apply the swapping routine to the double component fits. 

As a reminder, the basic idea that solved the problem of swapping components is very simple: our two components are very similar and nearly interchangeable. In general, therefore, there will be two high maxima in likelihood space that are far apart. Moving from one to the other is statistically unlikely given limited run times as it requires changing 9 of the 11 double component parameters at once. The code - even the MCMC - is hence more likely to converge onto the maximum that is closer to the initial guesses. By swapping the initial guesses and re-fitting a galaxy, we can assist the code in finding the ``correct" maximum (not necessarily the statistically better one but the one we find physically more appropriate, i.e. with the bulge at the centre). 

Manual calibrations enter at two stages in this process, namely for selecting galaxies to enter the re-fit (to avoid having to fit all galaxies twice) and for selecting the better of the two fits after the re-fit. Both selection criteria were determined by visual inspections of $r$-band galaxies during pipeline development; and double-checked for their suitability to $g$- and $i$-band fits. 

\begin{figure}[t!]
\begin{center}
	\includegraphics[width=0.8\textwidth]{plots/swapdiagnostic}
    \caption{A diagnostic plot of the swapping procedure for a test sample of visually inspected $r$-band galaxies classified as double component systems. The $x$-axis shows the logarithm of the ratio of the bulge S\'ersic index to that of the single S\'ersic fit; while the $y$-axis shows the logarithm of the ratio of the single S\'ersic effective radius to that of the bulge in the double component fit. The yellow line show our selection cut for determining which galaxies to re-fit (those below the line). The colours of the points indicate the result of the visual inspection (performed after the swapping procedure) as detailed in the legend. Points encircled in pink represent galaxies that were swapped (i.e. they entered the swapping procedure and the new fit was considered better). Lighter points show the corresponding original fits (that were replaced during the swapping procedure), connected by grey arrows. Points encircled in black show galaxies that entered the swapping procedure but were not swapped (i.e. the original fit was considered better). They are connected to the points where they would have ended up if they were swapped by dashed grey arrows.}	
    \label{fig:swapdiagnostic}
\end{center}
\end{figure}

Figure~\ref{fig:swapdiagnostic} shows a diagnostic plot of the swapping results. We show the logarithm of the ratio of the single S\'ersic effective radius to that of the bulge in the double component fit on the $y$-axis against the logarithm of the ratio of the bulge S\'ersic index to that of the single S\'ersic fit on the $x$-axis. This is the plane in which we select galaxies to enter the swapping procedure (i.e. to be re-fitted). For un-swapped fits, we would expect both of these quantities to be larger than zero. To allow for some scatter, we do not cut exactly at zero, but instead re-fit all galaxies that have 2$x$\,+\,$y$\,<\,0.1 and 2$y$\,+\,$x$\,<\,0.1. This cut is indicated with the yellow line, any galaxies for which the original fit falls below the cut enter the re-fitting stage. 

We have experimented with many other parameter combinations also including the bulge-to-total flux ratio, the relative bulge and disk effective radii, the bulge and disk axial ratios and the chi-squared value of the central pixel, but have found the current procedure to produce the best results. Note that the exact cuts were refined several times during pipeline development, we only show the final \texttt{v04} versions here. Cuts for earlier version of the pipeline were made in the same plane and generally similar. We only adjusted them slightly based on new visual inspections (also making use of visual inspections done in the context of the other manual calibrations) to minimise the number of galaxies entering the swapping stage while at the same time minimising the number of galaxies with swapped components in the final catalogue. 

The coloured points show where the fits fall in this plane after the swapping procedure, with the colours indicating the result of the visual inspection (which was performed on the final fits, i.e. after the swapping procedure): green indicates unswapped fits, orange shows swapped fits and blue indicates those that were unclear, e.g. if both profiles are very similar, or the galaxy may better be represented by a single S\'ersic fit (i.e. a model selection fail) or because the galaxy is very irregular. 

The points encircled in pink are the ones that entered the swapping procedure and were swapped, i.e. these coloured points represent the new (better) fits after the swapping. The corresponding original fits for the same galaxies are shown as lighter points (of the same colour) connected by light grey arrows. All of the original fits lie below the selection cuts, while most of the re-fits lie above it; i.e. generally galaxies are moved towards the ``good" areas of the plot during the swapping procedure, even though this criterion is not applied in the selection of the better fit (see below). After the swapping, all fits are also considered un-swapped or at least unsure. Note that we did not do a visual calibration on the fits before swapping (so the colours of the lighter points just represent the final result for the galaxy after the swapping), but given that they changed their parameters significantly during the procedure it is very likely that they indeed had swapped components before.

The points encircled in black are those that entered the swapping procedure but were not swapped, i.e. the original fit was considered better. Light grey dotted arrows connect them to their corresponding re-fits in lighter colours (that were then discarded). There are only five such objects in the entire sample of 300 visually inspected galaxies, i.e. the number of re-fits done in vain is very small. Note one of these is actually above the selection cuts and only entered the re-fits because it is the second match of a galaxy in the overlap sample for which the first match required swapping (for ease of processing, we enter the entire galaxy for re-fitting if any of its matches were identified as being potentially swapped). Three more of these objects are close to the selection cut and either did not change their parameters much during the re-fit (for two of them) or were fine before the re-fit (the third). 

Finally, the last object that entered the swapping procedure and did not get swapped is one of the two objects (of a total of 300) that remain swapped after our procedure, i.e. a ``failed swap". For this object (partly covered by another object so the orange colour is difficult to see), the re-fit seems to have failed as indicated by the dotted grey arrow pointing far beyond the plotting region. The second of the failed swaps is the leftmost point in the plot and did not enter the swapping procedure. Reducing the number of swapped components from around one third to only two out of 300 can be seen as a success though. Further visual inspections indicate that the number of failed swaps is generally around $1-2\,\%$ in all bands. 

\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.8\textwidth]{plots/examplefitswap2}
\caption{The double component fit to galaxy 593119 in the KiDS $r$-band before it entered the swapping procedure. Panels are the same as those in Figure~\ref{fig:examplefit}.}
\label{fig:examplefitswap1}
\end{center}
\end{figure}

\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.8\textwidth]{plots/examplefitswap1}
\caption{The double component fit to galaxy 593119 after the swapping procedure, for direct comparison to Figure~\ref{fig:examplefitswap1}.}
\label{fig:examplefitswap2}
\end{center}
\end{figure}

The last point that remains to be explained is how we select the better one of the re-fits. This criterion is stated in Section~\ref{sec:galaxyfitting} and is a combination of physical considerations and visual inspections. To recap, if the ``bulge" component is close to exponential, larger than the disk and contains the majority of the flux for only one of the two fits, then we choose the other one. For all galaxies for which this criterion is met by both or neither of the fits (which is the majority), we select the one with the higher absolute value of bulge flux in the central pixel. We devised and calibrated these criteria during visual inspection of samples of galaxies that were fitted twice (once with initial guesses swapped), comparing the two fits against each other and flagging the physically most appropriate one. 

We also experimented with many different criteria for this selection, e.g. the higher absolute value of flux in central regions of differing sizes (instead of only one pixel), higher values of bulge flux relative to the disk flux (rather than absolute), chi-squared values in the central pixel(s), combinations of other parameters such as S\'ersic index, bulge-to-total ratio and effective radii or selections that are statistically better motivated, for example choosing the fit with the higher likelihood. In the end, the rather simple selection of the fit with the higher absolute value of bulge flux in the central pixel proved to be most suitable to our needs. 


Figures~\ref{fig:examplefitswap1} and~\ref{fig:examplefitswap2} show an example galaxy pre- and post-swapping. The resulting fit after the swapping procedure is not perfect (galaxies that can be perfectly represented by our models rarely suffer from swapped components) and in fact has a slightly higher reduced chi-squared value than the original fit, i.e. it is statistically worse. Still, the fit post-swapping is physically more appropriate than the original one as the bulge now dominates the flux in the central region and the disk that in the outskirts. 

\subsubsection{Outlier flagging}

Similar to the swapping procedure, the flagging of bad fits (outliers) proceeded in a very iterative way, experiencing multiple refinements during pipeline development. The basic procedure was to visually inspect a random sample of galaxies and flag them as outlier or not; then visualise the distributions of outliers and good fits as a function of many (combinations of) metrics that we would expect to capture some aspects of ``bad fits" either from a theoretical point of view or from the visual impression gained while inspecting our sample of galaxies. We then proceeded to visually inspect more (non-random) samples of galaxies in the regions where we identified possible metrics, to better define the exact cuts. 

This process or parts thereof were repeated several times when we changed the preparatory work procedure (in particular the segmentation) or revised some modelling decisions such as the fitting limits or parameter constraints. The resulting metrics that we used for outlier flagging in \texttt{v04} of the \texttt{BDDecomp} DMU are listed in Section~\ref{sec:postprocessing}, including an indication of how many fits they affect. They were all calibrated on the $r$-band fits, but double-checked and found to be suitable for the $g$ and $i$ band fits as well. 

Initially, the outlier flagging was heavily linked to the swapping and model selection calibration, since all three processes are interconnected. For these reasons, many of the calibrations are in fact based on the same visual inspections, where we flagged numerous categories such as ``the double component fit is swapped but could probably be a good fit if it were not", ``borderline between single/double component fit and outlier", ``this galaxy would need at least three components" or ``failed segmentation map (could maybe be a good fit otherwise)" along with more straight-forward categories for galaxies which can be appropriately represented by one of our models\footnote{The 1.5-component fits were not considered during most of this iterative process since they were added at a later stage during pipeline development. The outlier flagging was then only adapted slightly to accommodate the new model fits.}.

Once we had finalised the swapping procedure, the number of swapped components was very low such that this effect was de-coupled from the outlier flagging and model selection. The latter two remain connected though, since the decision of whether or not a given galaxy can be appropriately represented by one of the models depends on the available model fits. The visual inspection for the model selection therefore always included an ``outlier" category, which we in turn could also use to define the outlier criteria (with further refinements based on non-random samples as stated above; which did not enter the model selection calibration). Further details on the final order of processing of the model selection and outlier rejection routines are given in Section~\ref{sec:postprocessing}. 

Note that in contrast to the swapping procedure, the outlier flagging and model selection are entirely post-processing routines, i.e. they do not require any re-fits and also did not require specific test runs to be calibrated during pipeline development. Nonetheless, some of the visual inspections performed in the context of model selection and outlier flagging also influenced our modelling decisions such as the definition of the fitting limits for the S\'ersic index (cf. Section~\ref{sec:modellingdecisions}) and not least the addition of the 1.5-component models. 

\begin{figure}[t!]
\begin{center}
	\includegraphics[width=0.8\textwidth]{plots/modelseldiagnostic}
    \caption{A diagnostic plot of the outlier rejection and model selection routines. We show the number of components assigned by the automated routine (\texttt{NCOMP}) on the $y$-axis against the DIC difference between the single and double component fits on the $x$-axis. Each point represents one of the $\sim$\,700 galaxies used during model selection calibration, coloured by the result of the visual inspection as indicated in the legend. The vertical black dashed and dotted lines indicate the calibrated DIC cut with its bootstrap uncertainties.} 
    \label{fig:modelseldiagnostic}
\end{center}
\end{figure}

Figure~\ref{fig:modelseldiagnostic} shows a diagnostic plot of the combined outlier flagging and model selection. It shows the number of components assigmed by the automated routine against the DIC difference between the single and double component models, clipped to the plot limits (for simplicity, we do not show the other two DIC differences). As a reminder, \texttt{NCOMP} values of 1, 1.5 and 2 mean that the object was classified as single, 1.5- and double component fit respectively, while objects with negative \texttt{NCOMP} are outliers, where the absolute value indicates the category that the object would have been assigned to if it were not an outlier. Each coloured point is one of the $\sim$\,700 galaxies used for \texttt{v04} model selection calibration and sorted into one of the six categories indicated by the legend during visual inspection (cf. Section~\ref{sec:postprocessing}). If all routines were perfect, we would expect all yellow points to be in the lower part of the plot; while all blue, green and red points would be on the \texttt{NCOMP}\,=\,1, 1.5 and 2 lines respectively (except for the random scatter that we added for visibility). Pink points can either be on the 1.5 or 2 lines and grey points (unsure; excluded from all analyses) are allowed to be anywhere, though preferentially in the positive region. 

\begin{figure}[t!]
\begin{center}
	\includegraphics[width=0.8\textwidth]{plots/examplefit2}
    \caption{The double component fit to galaxy 278760, classified as outlier (\texttt{NCOMP}\,=\,$-2$) in the KiDS $r$-band. Panels are the same as those in Figure~\ref{fig:examplefit}.} 
    \label{fig:examplefit-2}
\end{center}
\end{figure}

We further investigate the model selection accuracy below. Focusing on just the outlier flagging, there are a total of three objects that were visually classified as outliers but are considered good fits in the automated selection. Vice versa, there are 20 objects classified as acceptable fits which are flagged as outliers by the automated routine. This amounts to a total of approximately 3\,\% of all objects being classified wrongly by the outlier flagging routine. A further 14 objects (2\,\%) are visually classified as ``unsure" and ended up being flagged as outlier. The ``unsure" category includes galaxies for which it was unclear which model is the best (since several models delivered equally good fits) as well as those for which it was unclear whether or not they are an outlier (borderline cases and/or several models delivered equally bad fits). The majority of the grey points should hence lie in the positive regions of the plot, but we cannot judge how many exactly are erroneously flagged as outliers. 

Depending on whether the ``unsure" category is considered or not, the outlier flagging routine has an overall accuracy of 95-97\,\% compared against visual inspection for the KiDS $r$-band. The corresponding fractions in the $g$ and $i$ bands are 94-97\,\% and 95-97\,\% respectively. An example of a galaxy classified as outlier is shown in Figure~\ref{fig:examplefit-2}. 



\subsubsection{Model selection calibration}

The third and arguably most important calibration based on visual inspection is that of the DIC difference cuts for model selection. As mentioned above, it is intrinsically linked to the flagging of outliers and to a lesser extent also to the swapping routine. The theoretical background for Bayesian model selection is given in Section~\ref{sec:bayesiananalysis}. Our model selection routine (including its visual calibration) is then explained on that basis in Section~\ref{sec:postprocessing}. 

We emphasize again that purely statistical measures cannot achieve the aim of our model selection, namely to select the physically most appropriate fit, especially in the context of our models being statistically inadequate for the majority of galaxies in our sample. A purely visually-based classification is possible (see, e.g., \citealt{Hashemizadeh2022} or \citealt{Driver2022}), but time-consuming for large samples of galaxies such as ours. This is particularly true because the visual classification would need to be repeated for each band individually as long as bands are also fitted individually. Classifying galaxies from e.g. colour images to determine the number of physically distinct components they contain, sometimes even before (or without subsequent) model fitting, is common in the galaxy fitting community (see e.g. \citet{Hashemizadeh2022}) and certainly desirable from a scientific perspective. From a statistical perspective though, if the single-band image used for the fit is too shallow to constrain two components, then a double component fit will not produce reliable parameters even for galaxies which physically do consist of two components. For this reason, we calibrate the model selection on single-band diagnostic plots comparing the fits achieved by our three models and selecting the best (or - if there are several equally good fits - simplest) one.

We then use the result of the visual inspection of a subsample of galaxies to calibrate a cut based on statistical measures (the DIC) that we subsequently apply to the full sample. This limits the number of galaxies that need visual inspection while overcoming the unsuitability of a statistical measure alone. Nonetheless, the model selection is limited by the statistical measure to some extent, as the statistical measure will never be able to distinguish between different ``kinds" of bad model fits. For example, the automated procedure based on a DIC cut will always select the double component fit if it is significantly better than the single component fit (where ``significantly better" is the part that we calibrate during visual inspection), irrespective of whether the bulge and disk components are swapped or for example the bulge dominates both the centre and the outskirts of the galaxy. 

To further limit these shortcomings of a DIC difference cut, we experimented with combining it with more physical measures, e.g. a $\Delta$DIC cut as a function of bulge S\'ersic index or bulge to total flux ratio (and many other versions). None of these more complicated joint cuts improved the model selection significantly, so we chose the simplest version of just a (one-dimensional) cut in $\Delta$DIC. The accuracy that we achieve compared against visual inspection (see confusion matrices in Section~\ref{sec:postprocessing} and below) is sufficient for our needs despite the intrinsic limitations of the method. The only viable technique to overcome such limitations in the future is machine learning, as investigated by e.g. \citet{Dimauro2018}. However, the majority of recent efforts to apply machine learning to the problem of galaxy classifications is focused on reproducing visual morphological classifications based on images alone (e.g. \citealt{Nolte2019, Turner2021, Tarsitano2022}), which are to be distinguished from model selection. 

Figure~\ref{fig:modelseldiagnostic}, which was already introduced above, shows the result of the model selection compared against visual calibration. Most single component galaxies (blue points) are correctly classified as such, especially for low $\Delta$DIC; while those with high $\Delta$DIC are correctly identified as being the double component fits (orange dots). The $\Delta$DIC cut with its uncertainty region (from bootstrapping) is indicated with vertical dashed and dotted black lines; and can also be inferred from the distribution of points in the \texttt{NCOMP}\,=\,1 and \texttt{NCOMP}\,=\,2 classes. Most confusion between the single and double component models is near those cuts, where coincidentally (but not entirely surprisingly) we can also find the highest number of galaxies classified as ``unsure". Interestingly, the 1.5-component models have intermediate values of $\Delta$DIC$_{1-2}$ (which is the quantity we show on the $x$-axis; we do not show $\Delta$DIC$_{1-1.5}$ or $\Delta$DIC$_{1.5-2}$ which are the relevant quantities for 1.5-component model selection). 

The last point to note about Figure~\ref{fig:modelseldiagnostic} is that most galaxies that are wrongly classified as outliers (i.e. blue, green, orange and pink points in the lower half of the plot) are at least classified in their correct model category, i.e. the majority of blue points in the lower half of the plot lies on the \texttt{NCOMP}\,=\,$-1$ line, while the majority of orange points is at \texttt{NCOMP}\,=\,$-2$. For this reason, and in an attempt to characterise the accuracy of the model selection alone rather than in combination with the reliability of the outlier rejection routine, we use absolute values of \texttt{NCOMP} for all model selection statistics and ignore the ``outlier" category (essentially adding the yellow points to the grey population). 

The full confusion matrix for the $r$-band model selection is given in Table~\ref{tab:modelselconfusionr} in Section~\ref{sec:postprocessing}. For completeness, we add the corresponding confusion matrices for the $g$ and $i$ bands and the joint model selection in Table~\ref{tab:modelselconfusiongijoint}, although the statistics are generally similar between bands. For reference, we also list the calibrated DIC difference cuts between all three models for all three bands and the joint model selection in Table~\ref{tab:v04diccuts}. As one would expect (due to Ockham's factor), the cuts are generally higher for models with larger differences in the numbers of parameters and for bands with better data quality. 

\begin{table}
\centering
\caption{The confusion matrices for our model selection based on a $\Delta$DIC cut compared against visual inspection for the $g$ and $i$ bands and the joint model selection. All values are in percent of the total number of visually inspected galaxies in the respective band(s). Bold font highlights galaxies classified correctly, while grey shows those that were ignored during the calibration.}
\label{tab:modelselconfusiongijoint}
\begin{subtable}{0.5\textwidth}
\centering
\caption{The $g$-band model selection confusion matrix.}
\label{tab:modelselconfusiong}
	\begin{tabu}{lcrrrc} % number of columns, alignment for each
		\hline
		 & \multicolumn{5}{r}{number of components} \\
		visual class. & & 1 & 1.5 & 2 &\\
		\hline
		``single" && \textbf{48.9} & 0.4 & 1.0 &\\
		``1.5" && 2.1 & \textbf{3.7} & 0.6 &\\
		``double" && 1.8 & 0.1 & \textbf{6.0} &\\
		``1.5 or double" && 0.4 & \textbf{1.5} & \textbf{1.9} &\\
		\rowfont{\color{gray}}
		``unsure" && 19.5 & 0.9 & 7.3 &\\
		\rowfont{\color{gray}}
		``unfittable" && 1.3 & 0.3 & 2.1 & \\
        \hline
	\end{tabu}
\end{subtable}%
\begin{subtable}{0.5\textwidth}
\centering
\caption{The $i$-band model selection confusion matrix.}
\label{tab:modelselconfusioni}
	\begin{tabu}{lcrrrc} % number of columns, alignment for each
		\hline
		 & \multicolumn{5}{r}{number of components} \\
		visual class. & & 1 & 1.5 & 2 &\\
		\hline
		``single" && \textbf{51.8} & 0.4 & 1.5 &\\
		``1.5" && 1.9 & \textbf{3.0} & 1.5 &\\
		``double" && 0.7 & 0 & \textbf{8.9} &\\
		``1.5 or double" && 0 & \textbf{1.0} & \textbf{1.9} &\\
		\rowfont{\color{gray}}
		``unsure" && 10.0 & 0.7 & 12.4 &\\
		\rowfont{\color{gray}}
		``unfittable" && 1.2 & 0.3 & 2.2 & \\
        \hline
	\end{tabu}
\end{subtable}%

\bigskip
\begin{subtable}{\textwidth}
\centering
\caption{The joint model selection confusion matrix.}
\label{tab:modelselconfusionjoint}
	\begin{tabu}{lcrrrc} % number of columns, alignment for each
		\hline
		 & \multicolumn{5}{r}{number of components} \\
		visual class. & & 1 & 1.5 & 2 &\\
		\hline
		``single" && \textbf{47.4} & 0.5 & 1.5 &\\
		``1.5" && 2.2 & \textbf{2.4} & 1.4 &\\
		``double" && 2.2 & 0.4 & \textbf{7.3} &\\
		``1.5 or double" && 0.3 & \textbf{1.1} & \textbf{2.1} &\\
		\rowfont{\color{gray}}
		``unsure" && 15.0 & 0.7 & 11.1 &\\
		\rowfont{\color{gray}}
		``unfittable" && 1.0 & 0.4 & 2.4 & \\
        \hline
	\end{tabu}
\end{subtable}%

\end{table}


\begin{table}
	\centering
	\caption{The calibrated DIC difference cuts used for \texttt{v04} of the \texttt{BDDecomp} DMU. For each band, we show the lower bound (LB), the actual cut and the upper bound (UB) for each of the three DIC differences between our models. For the joint model selection, the cuts refer to the differences between the summed DICs of all bands (cf. Section~\ref{sec:postprocessing}).}
	\label{tab:v04diccuts}
	\begin{tabu}{lrrrrrrrrrrrr} % number of columns, alignment for each
		\hline
		 && \multicolumn{3}{c}{$\Delta$DIC$_{1-1.5}$} && 
		 \multicolumn{3}{c}{$\Delta$DIC$_{1-2}$} &&
		 \multicolumn{3}{c}{$\Delta$DIC$_{1.5-2}$}\\
		band && LB & cut & UB && LB & cut & UB && LB & cut & UB\\
		\hline
		$g$ && 43 & 68 & 93 && 1760 & 2273 & 4856 && 551 & 817 & 940\\
		$r$ && 57 & 172 & 248 && 1463 & 2298 & 2636 && 690 & 853 & 947\\
		$i$ && 33 & 57 & 127 && 396 & 473 & 520 && 308 & 336 & 438\\
		joint && 183 & 255 & 341 && 5707 & 5751 & 5797 && 1650 & 1824 & 3104\\
        \hline
	\end{tabu}
\end{table}


\section{Pipeline updates}
\label{sec:pipelineupdates}
This section describes the updates to the pipeline performed when adding the processing of VIKING data, i.e. in between \texttt{v04} and \texttt{v05} of the \texttt{BDDecomp} DMU, the latter of which is to be released on the GAMA database alongside the publication of this thesis. At the same time we included the KiDS $u$-band, such that now our catalogue covers all 9 optical and near-infrared bands from KiDS and VIKING ($u$, $g$, $r$, $i$, $Z$, $Y$, $J$, $H$, $K_s$). This work has not been presented to date. 

\subsection{VIKING data products}
\label{sec:vikingdataproducts}
As for KiDS (see Section~\ref{sec:otherprepworkchoices}), we needed to decide which of the VIKING data products to use. VIKING provides data products at two different levels: pawprints and tiles, the latter of which are made of six pawprints stacked together to close the gaps between detector chips. In addition, for the $J$-band, there are ``deep stacks" composed of two tiles each, since the $J$-band tiles have been observed twice in the VIKING observing strategy (see Section~\ref{sec:viking}). All of these data products are astrometrically and photometrically calibrated. In contrast to KiDS, however, they are not re-gridded, so they have various pixel sizes (close to $0\farcs$34), are only approximately aligned in RA and Dec and are calibrated to differing Vega zeropoints given in the image headers. The frames are also not corrected for atmospheric extinction and the flux units still contain the exposure time. The sky background variations are subtracted, but only on large scales \citep{Edge2020}. 

The most important difference to KiDS images for our analysis, however, is that the pawprints making up a tile are not taken in direct succession but can be taken hours or even months apart. This leads to seeing variations and hence considerable PSF differences between the pawprints making up a tile \citep{Edge2020}. For accurate photometry, it is therefore necessary to apply an aperture correction that is a function of position in the tile, termed ``grouting". This is done by the VIKING team to obtain their photometric catalogue, but with various different pipeline versions as their data reduction procedure evolved during the time of the survey. The tiles themselves cannot easily be corrected for this and are hence left with potentially strongly and abruptly varying PSFs since different pairs of pawprints contribute to different areas of the tile given the VIKING dithering pattern, see \citet{Edge2020}.

This drove our decision to work at the pawprint level instead of using stacked image tiles, since a reliable PSF estimation is vital for an accurate galaxy fit. Very similar considerations led \citet{Wright2019} and \citet{Driver2016} to the same conclusion. Instead of downloading the pawprints and re-calibrating them ourselves, we decided to directly use the preprocessed detector chips of \citet{Wright2019} (who were following \citealt{Driver2016} in their analysis). They are not publicly available, but the KiDS team kindly provided them to us for this work. Given that the KiDS team use these re-processed chips for their own photometric analysis combining KiDS and VIKING data in \citet{Wright2019}, they seemed highly appropriate to use for our work as well. 

Wright (private communication) provided individual detector chips (i.e. each pawprint split into its 16 chips) with a size of $\sim$\,2200\,$\times$\,2200\,pix$^2$ or approximately 750\arcsec\,$\times$\,750\arcsec\. Apart from the data reduction already performed by VIKING, they have been re-calibrated with a multiplicative correction factor to account for atmospheric extinction, remove the exposure time from the image units and convert the images onto a common AB magnitude zeropoint of 30 (see \citealt{Wright2019} for details). In addition, the chips are rotated slightly such that their $x$ and $y$ axes align exactly in RA and Dec and at the same time the background is subtracted and a weight map created. This is performed using the SWarp software \citep{SWarp} after truncating the chip edges slightly to exclude unreliable pixels \citep[][and Wright, private communication]{Wright2019}. It results in a background-subtracted chip image with a corresponding weight map that is zero around the edges of the chips and has a uniform value elsewhere, giving the average inverse variance over the chip. Chips with unreliable photometry are then identified via a cut in the recalibration factor and discarded.

Note that \citet{Wright2019} do not use the VIKING confidence maps in their analysis. They exist for pawprints and tiles and give the pixel-by-pixel variation in exposure time, with a value of 100 referring to the median exposure time in the given band. They also include masking for detector artifacts such as bad pixels and the two ``bad patches" that do not flat-field well \citep{Edge2020}. Apart from these bad patches, the confidence maps are relatively uniform for individual chips, with variations for the tiles mostly caused by the dithering pattern. Since \citet{Wright2019} exclusively work at the detector level and use a weighted combination of the individual detector fluxes with outlier rejection, there was no need to consider the confidence maps in their analysis. 

Following the same arguments, we decided to simply use the uniform-valued weight maps of \citet{Wright2019} for our analysis as well. While we do not perform a weighted combination of fluxes with outlier rejection, each of our galaxy is covered by typically 3-4 VIKING exposures and up to 40 in the $J$-band overlap regions. Should any of these (partly) fall into a ``bad patch", it will likely not dominate the galaxy fit. The same applies to satellite tracks and similar artefacts that only affect individual chips. Nonetheless, a potential improvement of our analysis of the VIKING data would be to re-scale the \citet{Wright2019} weight maps with the corresponding confidence maps, after rotating the latter onto the same pixel grid. 

The last difference to the KiDS data that we would like to mention is that VIKING do not provide masks for bright stars and their possible reflection halos. These could be created following, e.g., the procedure in \citet{Barnett2021}, which is another potential improvement to our analysis of VIKING data. For the current work, we decided against such a procedure and instead rely on the rather conservative KiDS masks that were considered during image segmentation (see Section~\ref{sec:v05segmentation}). 

In summary, we opt to use the individual VIKING chips recalibrated by \citet{Wright2019} with associated uniform-valued weight maps and no bright star masks. This results in many data matches for each galaxy (a median of 3 in $Z, Y, H, K_s$ and 6 in $J$; although it can be more than 20 in overlap regions) with significantly different PSFs, making a joint fit necessary to avoid stacking. This became possible with the multi-frame fitting functionality of \texttt{ProFit v2.0.0}, released in February 2021. 


\subsection{Segmentation changes}
\label{sec:v05segmentation}
Most of the preparatory work remained unchanged between \texttt{v04} and \texttt{v05} of the pipeline, except for the technical details to enable the analysis of the VIKING data (e.g. differing naming conventions). We still take cutouts around each object for each data match, estimate the sigma maps and do the background subtraction and PSF estimation separately for each image. The only major difference is in the treatment of the segmentation maps and masks. 

For the KiDS $g$, $r$ and $i$ bands, we used a stacked image to define a joint segmentation map in all three bands, including a joint mask (see Section~\ref{sec:preparatorysteps}). This was straight-forward since all tiles are registered to the same pixel grid across all KiDS bands, so there is always an exact correspondence of a tile in the $r$-band to one in the $g$- and one in the $i$-band; and they can simply be added (apart from very slight variations in the tile sizes that are easily taken account of). The VIKING chips generally also cover similar areas of sky in the different bands (except for the ``missing chips", see Section~\ref{sec:jointfitting}), but they are not registered to the same grid and have differing pixel sizes. 

A joint analysis of all bands is still possible, but requires more care to correctly account for these effects. In addition, due to the large number of matches and the much smaller sizes of VIKING chips compared to KiDS tiles (750\arcsec\ vs. 1\degr\ per side), galaxies are more frequently covered only partly by individual exposures. Considering only the area covered (and not masked) by all exposures in all bands would unnecessarily decrease the amount of available data for fitting and result in no data being left in many cases (see also Figure~\ref{fig:v05matchseg}). Nonetheless, we want to have the same fitting regions in all bands, to avoid systematic effects due to different segment sizes (see Sections~\ref{sec:postprocessing} and~\ref{sec:segchoices}). 

For these reasons, we decided to define the KiDS $g$, $r$ and $i$ bands as our ``core" bands (cf. Section~\ref{sec:kids}) and perform the segmentation on the $gri$ stacks as for \texttt{v04}. For the $u, Z, Y, J, H$ and $K_s$ bands, we then simply transfer these $gri$ segmentation maps (one for sky subtraction and one for galaxy fitting) onto the corresponding world coordinates and pixel grid of the target image using \texttt{profoundSegimWarp}. In case there are several segmentation maps available for the same galaxy (i.e. for the overlap sample in $gri$), we use the first match for transferring to other bands.\footnote{We actually intended to use the largest segmentation map instead of the first match, but this did not work due to a small bug in our code. The bug is fixed for any future runs, but we did not consider this to be a problem that would justify re-processing the entire \texttt{v05} of the \texttt{BDDecomp} DMU.} Should the segmentation map extend beyond the edge of the target image, it is truncated accordingly. 

For the $u$-band, we then additionally apply the $u$-band mask, although the vast majority of areas masked in the $u$-band are already included in the stacked $gri$ masks that were considered during the segmentation. As mentioned before, we do not use any additional masks for VIKING data (apart from those included in the weight maps, see Section~\ref{sec:vikingdataproducts}). Stars that are saturated in KiDS data, as well as reflection haloes, are conservatively masked during our analysis (Section~\ref{sec:otherprepworkchoices}) and will automatically be excluded from the segmentation. We consider it very unlikely that a star would be saturated and/or produce significant reflection haloes in one of the VIKING bands while being unmasked in all of the KiDS $g$, $r$ and $i$ bands. This is particularly true since we use individual detector chip images for VIKING and stacked (hence much deeper) tiles for KiDS. 

This procedure ensures that the fitting regions across all bands are as similar as possible (and exactly identical in our three core bands), while maximising the available data for fitting. The result for an example galaxy can be seen in Figure~\ref{fig:v05matchseg}, where we give a qualitative impression of the matches available for each band and the corresponding segmentation maps. All images are shown on their native pixel scales and for this reason, the cutout sizes and flux scalings are also different. Since the figure is only meant to give a visual impression, we omit axis labels and colour bars. 

The galaxy shown is part of the overlap sample in the KiDS $g, r, i$ bands and also has many matches in the VIKING bands (we show the first eight for each band). The two segmentation maps for the two matches in $gri$ are similar, but not identical. For all other bands, the first of those was transferred to all matches. Matches for which the galaxy centre falls into a white region (missing data) are skipped, i.e. not used during the joint fit. Some further matches are skipped due to PSF failures, see Section~\ref{sec:jointfitting}. For the $r$-band, we additionally show the \texttt{v04} segmentation maps on the same axis scale as their corresponding \texttt{v05} versions for direct comparison (see below for reasons why the segment size increased in \texttt{v05}). 

Potential improvements to this segmentation procedure would be to jointly treat multiple matches in $gri$ (i.e. for the overlap sample, where we still produce separate segmentation maps for each match) and/or use the correct corresponding match in the $u$-band, which is also pixel-matched to the other KiDS bands (instead of simply transferring the larger segmentation map to all matches). Ideally, we would in the future consider a stack\footnote{Stacking is not a problem in this context, since PSF variations do not affect the segmentation heavily.} of all bands used for analysis to define the segmentation maps, with regions missing from individual frames (because they are masked or beyond the edge of the corresponding image) downweighted appropriately without excluding them entirely. This is not possible with the current version of \texttt{ProFound} and would be non-trivial to implement.%\\

\begin{figure}
	\includegraphics[width=\textwidth]{plots/v05matchseg}
    \caption{An example of the images and \texttt{v05} segmentation maps (green contours) used for fitting galaxy 544891 in all nine bands (the same object as that shown in Figure~\ref{fig:segfixplot}). This galaxy returned one data match in the $u$-band, two in $g, r, i$ (of which none were skipped), 14 in $Z$ (5 of which were skipped), 13 in $Y$ (5 skipped), 21 in $J$ (9 skipped), 8 in $H$ (5 skipped) and also 8 in $K_s$ (1 skipped). For the VIKING bands, we only show the first 8 matches each. White regions indicate missing data beyond the image edge or in the region of the chip that has zero weight assigned (cf. Section~\ref{sec:vikingdataproducts}). For the $r$-band, we also show the \texttt{v04} segmentation maps for direct comparison (the second of which corresponds to the rightmost panel in Figure~\ref{fig:segfixplot}). These are shown in the same cutout size as their corresponding \texttt{v05} versions for easier visual comparison. All other cutouts are shown in their original size (i.e. with differing numbers of pixels) and with individual flux scaling for best visibility (due to the different pixel scales). We omit axis labels and colour bars due to the qualitative nature of this plot.} 
    \label{fig:v05matchseg}
\end{figure}

% Z: 14, 5 skipped (2 masked, 3 PSF fails)
% Y: 13, 5 skipped (2 masked, 3 PSF fails)
% J: 21, 9 skipped (8 masked, 1 PSF fail)
% H:  8, 5 skipped (3 masked, 2 PSF fails)
% Ks: 8, 1 skipped (1 masked)

One last change in the \texttt{v05} segmentation maps came from two default changes in \texttt{profoundProFound}: the \texttt{skycut} default changed from 1 to 1.5 and the \texttt{SBdilate} default changed from \texttt{NULL} to 2. 

For the meaning and effect of \texttt{skycut}, see Section~\ref{sec:segchoices}. We use two different versions of segmentation maps for the background subtraction and galaxy fitting with explicitly different aims (see also Sections~\ref{sec:preparatorysteps}, \ref{sec:backgroundstudies} and \ref{sec:segchoices}) that are produced with \texttt{skycut} values of 1 and 2 respectively. This was the optimal procedure we found after numerous experiments with different \texttt{skycut} values, including 1.5. We therefore considered it best to discard the new default and instead set \texttt{skycut} to 1 explicitly in all places where it was previously left on its default. 

The \texttt{SBdilate} option specifies how many magnitudes to push beyond the surface brightness limit in segment dilation if the number of pixels to be added is larger than \texttt{SBN100} (with a default of 100 that we left unchanged). After defining initial segments, \texttt{profoundProFound} expands those until its convergence criterion is met. By default, the convergence criterion is that the total flux within the segment increases by less than 5\,\% during the dilation \citep{Robotham2018}. For bright and extended galaxies, this means the number of dilations is often zero or one (cf. Section~\ref{sec:segchoices}) since the flux already contained in the segment is large, so the fractional change during dilation is small. For these objects, the \texttt{SBdilate} option can be used to dilate the segments further and capture the low surface brightness flux in the extended wings. In detail, if the dilated annulus contains at least \texttt{SBN100} pixels and has a mean surface brightness brighter than the sky surface brightness limit plus \texttt{SBdilate}, then the segment dilation continues (i.e. the annulus will be added to the current segment even if it contributes less than 5\,\% additional flux). For the new default values this means that we assume that 100\,pix are sufficient to safely push the detection 2\,mag beyond the sky surface brightness limit of individual pixels.  

We had not previously considered the \texttt{SBdilate} option since it was not available in the early versions of \texttt{ProFound} that we used for most of the preparatory work pipeline development; and we did not re-visit this after \texttt{SBdilate} was introduced. After the most recent \texttt{ProFound} update, we considered simply setting it back to its previous default of \texttt{NULL}, meaning that the \texttt{SBdilate} routine is not triggered. However, we decided to adopt the new defaults for several reasons. First, the logic behind \texttt{SBdilate} seemed reasonable and we could indeed observe that it typically does not change the star segments (for PSF estimation) but does dilate most galaxy segments, especially those of bright and extended objects. For these objects we had also noticed (during the detailed analysis of the \texttt{v04} results) that the azimuthally averaged one-dimensional flux profiles often continue to be positive and well-defined beyond the \texttt{v04} segment region, see e.g. Figure~\ref{fig:examplefit}. This is an indication that while individual pixels are below the surface brightness limit, their sum is still above it (and would be sufficient to constrain the model profile to larger radii), i.e. we have not reached the actual sky background yet. While our aim is to have relatively tight segments that do not include many background pixels, we did not intend to discard the extended wings of galaxies. 

In addition, since we now use the segments defined on the $gri$ images also for the other bands, we need to allow for potential variations of object sizes as a function of wavelength. There can also be variations in depth between bands and even within the same band (in particular in the overlap regions) due to the fact that we now jointly fit all matches but still define segments on individual matches of the $gri$ stacks. For all of these reasons, it seemed safer to use somewhat larger, more dilated segments for \texttt{v05} compared to \texttt{v04} and we decided to adopt the new default of \texttt{SBdilate}.

An example of the resulting \texttt{v05} segmentation map can be seen in Figure~\ref{fig:v05matchseg} for galaxy 544891. This is the same object that we also showed in Figure~\ref{fig:segfixplot} to allow for a visual impression of the evolution of segmentation maps during pipeline development. For a direct comparison to the \texttt{v04} segmentation maps, we also show these in Figure~\ref{fig:v05matchseg} in the rightmost columns as indicated. They are shown in the same cutout size as their corresponding \texttt{v05} version. Clearly, the segment size increased due to the \texttt{SBdilate} procedure. 


\subsection{Joint fitting}
\label{sec:jointfitting}
Since we work at the individual exposure level for VIKING data, galaxies frequently have multiple data matches as can be seen in the top panel of Figure~\ref{fig:nmatchviking}. Due to our joint processing of the $g$, $r$ and $i$ bands (cf. Section~\ref{sec:v05segmentation}), these have the exact same number of matches (with a minimum and median of 1 and a maximum of 4). The $u$-band follows the $g$, $r$ and $i$ bands closely (also with a minimum and median of 1 and a maximum of 4 matches), while the VIKING bands have many more matches on average but also some missing matches. The $Z$, $Y$, $H$ and $K_s$ bands show similar distributions ranging from 0 to around 20 with medians of 3. The $J$ band has typically twice as many matches (a median of 6 and a maximum of 39 matches) due to the VIKING observing strategy, see Section~\ref{sec:viking}.

\begin{figure}[t!]
\begin{center}
	\includegraphics[width=0.8\textwidth]{plots/nmatchviking}
	\includegraphics[width=0.8\textwidth]{plots/nfitviking}
    \caption{\textbf{Top:} the number of data matches to each of our 13096 galaxies for all nine KiDS and VIKING bands as indicated in the legend. Note the logarithmic scaling on the $y$-axis. \textbf{Bottom:} the same but showing only non-skipped matches (i.e. those that were actually used for fitting).} 
    \label{fig:nmatchviking}
\end{center}
\end{figure}

The number of missing (zero) matches is very similar in all VIKING bands. They are due to small gaps in the VIKING data caused by a combination of incomplete sky coverage (see \citealt{Edge2020} and also figure 1 in \citealt{Wright2019}) and the quality control cuts applied by the VIKING team as well as by \citet{Wright2019}, see Section~\ref{sec:vikingdataproducts}. This affects approximately 5\,\% of the galaxies in our sample which are largely the same in all VIKING bands (cf. Table~\ref{tab:resultsv05}) and preferentially distributed around the edges of the three equatorial GAMA regions.  

Except for these ``missing objects", all matches pass through the preparatory work pipeline. However, some may be skipped at the fitting stage if the galaxy centre falls within a masked region or the PSF estimation failed. The number of images actually used for fitting each galaxy is shown in the bottom panel of Figure~\ref{fig:nmatchviking}. For the $g, r, i$ bands, around 20\,\% of individual matches are skipped due to the KiDS masking and a further $\sim$\,1\,\% due to PSF fails (cf. Table~\ref{tab:results}). Approximately 18\,\% of galaxies have no matches available for fitting and are skipped entirely (Table~\ref{tab:resultsv05}). 

For the $u$-band, the number of galaxies with no matches available is higher due to the additional masking, the decreased data quality and the slightly smaller footprint of the $u$-band tiles compared to the $g$, $r$ and $i$ bands (since the $u$-band tiles consist of only four dithers, while for the other bands it is five, cf. Section~\ref{sec:kids}). The smaller footprint by itself does not exclude any objects (i.e. there is no missing data in the $u$-band like in the VIKING bands), but it decreases the overlap regions between tiles. Hence galaxies in these regions are more often covered by only one exposure and/or less dithers (i.e. shallower data). These effects combined - plus the additional $u$-band masking - lead to more galaxies being skipped due to masking ($\sim$\,2\,\%) and PSF failures ($\sim$\,11\,\%), see also Table~\ref{tab:resultsv05} in Chapter~\ref{chap:results}. The latter effect in particular is very significant in the $u$-band due to the shallower data (not only in the overlap regions) in combination with our usage of the $gri$ segmentation maps: many candidate stars are too faint in $u$ to reliably estimate a PSF. Those that would be bright enough are masked, since they are saturated in the other bands. The median and maximum numbers of matches remain one and four respectively for all KiDS bands. 

Due to our use of the $gri$ segmentation maps, all galaxies that are skipped due to masking in the core bands (i.e. around 18\,\%) also have zero images available for fitting in the VIKING bands. Additionally, there are the $\sim$\,5\,\% of galaxies for which no matches were returned in the first place, such that the number of objects skipped entirely during the fit in the VIKING bands is slightly higher than that in the KiDS $g$, $r$ and $i$ bands, although still lower than in the $u$-band. The number of images available for fitting is, however, reduced significantly in all bands, especially for those objects with many data matches. This is mainly due to the truncation of chip edges by \citet{Wright2019}, whereby unreliable pixels around the edges of chips are assigned zero weight (Section~\ref{sec:vikingdataproducts}). A galaxy falling within this region of the chip is hence counted as a match, but may by covered only partly or not at all by the actual data. We count these objects as being ``masked" in all subsequent analysis. 

Since this affects the chip edges only (there are no additional masks for the VIKING data), it exclusively affects the VIKING overlap regions. In addition, some matches may be skipped due to PSF failures. This also preferentially affects the VIKING overlap regions where there are less stars available for fitting (both due to the missing data around the edge of each chip as well as the large cutouts used for PSF estimation extending beyond the actual edge of the chip). As we typically have many data matches available in the overlap regions, it is relatively rare that a galaxy ends up with zero matches due to either of these reasons (both combined contribute around 1-2\,\% in addition to the KiDS masking, cf. Table~\ref{tab:resultsv05}). The number of matches available for fitting therefore remains higher than for KiDS data, with values typically around two to four in the $Z, Y, H, K_s$ bands and a few more in the $J$-band (with medians of two and four respectively). The maximum number of matches is reduced to 18 in the $J$-band and around 10 in all other bands. An example of a galaxy with many matches is shown in Figure~\ref{fig:v05matchseg}. %\\

This high number of data matches made treating each match individually (as we did for \texttt{v04}) impractical from a computational point of view and - more importantly - unwise from a scientific point of view as we would lose too much depth of the data. Since we want to avoid stacking due to the different PSFs in VIKING frames, we perform a multi-frame fit whereby we jointly fit all images of the same galaxy in each band. Note the bands are still treated individually, though, i.e. we perform multi-frame rather than multi-band fits. For consistency, we also re-process the KiDS $g$, $r$ and $i$ bands.

This means that we pass all (individually sky-subtracted) images for the same physical object in the same band - with their corresponding masks, segmentation maps, sigma maps and PSFs - to \texttt{ProFit} at once. The model is then fitted to all images jointly, with appropriate weighting and taking account of the different PSFs. Since we treat each band individually, we do not allow any model parameters to vary between images, i.e. there is only one model applied to all images. The only additional user input needed is an additive offset between the individual images in $x$ and $y$ (in pixels) and in rotation angle (in degrees); as well as a multiplicative offset in pixel scale. 

The rotation angle offset is zero in our case since all KiDS tiles as well as all VIKING chips re-processed by \citet{Wright2019} are exactly aligned in RA and Dec. For KiDS data, the pixel scale offset is also zero. The VIKING chips have slightly varying pixels scales ranging between 0\farcs337 and 0\farcs341. We do not consider this since the early versions of the \texttt{ProFit} multi-frame fitting mode did not offer support for varying pixel scales (it does now, so we can improve this in the future). This means that the estimates of the effective radius (the only parameter that depends on the pixel scale) are inconsistent at the 1\,\% level. This is well within its uncertainty for the vast majority of galaxies, with the median relative error on single S\'ersic effective radius ranging from 4\,\% in the $Z$-band to 10\,\% in $K_s$. 

The only non-zero offsets in our analysis are the differences between the $x$ and $y$ positions of the galaxy centre in the different frames. These can be calculated easily from the world coordinate system headers of the corresponding images, assuming the astrometric solutions to be exact. The KiDS DR4.0 astrometric solutions show a scatter of approximately 0\farcs04 each in RA and Dec \citep{Kuijken2019}. As we discuss in Section~\ref{sec:systematics}, this - although it is well within the pixel scale of 0\farcs2 - is a factor of approximately four larger than the median MCMC error on position when fitting individual images (see also Figure~\ref{fig:differrnorm}; and examples of the same effect can be seen in Figures~\ref{fig:islandplotpsf} and~\ref{fig:islandplotseg}). For the joint fit, it is therefore possible to see visual offsets of the galaxy centre in the different matches for extreme cases. 

An example for such an extreme case in the $r$-band is shown in Figures~\ref{fig:examplefitoff1} and~\ref{fig:examplefitoff2}. There is a discrepancy in the astrometric solution between the two images: for the individual fits in \texttt{v04}, the difference in the fitted RA and Dec positions for the two images are 0\farcs1 and 0\farcs4 respectively. For the joint fit in \texttt{v05}, this leads to the shallower of the two fits in particular being offset with respect to the actual centre of the galaxy, showing up as red and blue regions in Figure~\ref{fig:examplefitoff1}. The fit to the other image (Figure~\ref{fig:examplefitoff2}) shows a corresponding offset in the other direction, although not as clearly visible since it is the deeper image and dominates the fit. This adds onto the systematic uncertainties. The vast majority of offsets are much smaller than the extreme case shown here and cannot be visually seen in the model fits. It also only affects the overlap sample in KiDS where there is more than one match; and at the same time the astrometric solutions as well as the overall data quality are worst. 

\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth]{plots/examplefitoff1}
\caption{The (joint \texttt{v05}) single S\'ersic fit to the first image of galaxy 345472 in the KiDS $r$-band. Panels in the top two rows are the same as those in Figure~\ref{fig:examplefit}, while the bottom row shows the one-dimensional fit only, corresponding to the rightmost panel of the bottom row in Figure~\ref{fig:examplefit}.}
\label{fig:examplefitoff1}
\end{center}
\end{figure}

\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.8\textwidth]{plots/examplefitoff2}
\caption{The (joint \texttt{v05}) single S\'ersic fit to the second image of galaxy 345472 in the KiDS $r$-band, for direct comparison to Figure~\ref{fig:examplefitoff1}.}
\label{fig:examplefitoff2}
\end{center}
\end{figure}

For VIKING data, the scatter of the astrometric solution is 0\farcs09 \citep{Edge2020}. This is a factor of about two larger than for KiDS. However, the pixel size is also a factor of approximately two larger and the median MCMC uncertainty on position ranges from 0\farcs03 in $Z$ to 0\farcs05 in $K_s$ in both $x$ and $y$. The systematic uncertainty from the astrometric solution is therefore only a factor of two to three larger than the random uncertainty, compared to a factor of four for KiDS. It is therefore likely that the astrometric uncertainty affects VIKING bands less than KiDS bands despite the increased number of matches for each galaxy. Our visual impression was also that offsets visible by eye (such as those shown in Figures~\ref{fig:examplefitoff1} and~\ref{fig:examplefitoff2}) are less frequent in VIKING bands than in the KiDS $g$, $r$ and $i$ bands. 

To account for the uncertainty in the astrometric solution, we would need to allow for varying $x$ and $y$ centres to be fitted to each image of the same galaxy. This was not supported by early versions of the \texttt{ProFit} multi-frame fitting mode and can have several caveats as it would need to be ensured that the fitted offset is indeed due to the astrometric solution and not due to differing noise, image artefacts or similar issues. We therefore did not implement this for \texttt{v05} of the pipeline. However, it could be added in future work, minimising the caveats for example by imposing a (Gaussian) prior with a width taken from the known scatter of the astrometric solution.%\\

There are no changes with respect to \texttt{v04} on the modelling side, except for some technical details, where, e.g., we needed to modify the \texttt{convergeFit} function to make it compatible with the \texttt{ProFit} multi-frame fitting mode. Other than that, we use the same three models, the same initial parameter guesses and priors, the Normal likelihood function and the same fitting algorithm and convergence criteria. The only difference is that we now obtain just a single fit for each physical object, referring to the first (non-skipped) data match where necessary (i.e. for $x$ and $y$ positions in our case; and potentially also for the position angle and effective radius for non-zero offsets in rotation angle and pixel scale). 

The advantage of this approach is that it makes full use of the data available for each physical object; and there is only one result for each object so there is no need to combine or choose between different measurements of the same galaxy. The disadvantage is that we lose the overlap sample for internal consistency checks and estimation of systematic uncertainties, as we have done in Section~\ref{sec:systematics} for the \texttt{v04} results. In addition, the method relies heavily on the accuracy of the astrometric solutions (see above). 

The natural next step would be to move to multi-band fits, i.e. fitting all matches from all bands for the same physical object jointly. This is the approach taken by the \texttt{MEGAMORPH} project team \citep{Haeussler2013, Vika2013, Haeussler2022} and has many advantages since it ensures smooth wavelength trends while preserving physical variation and additionally allows more robust fits to fainter magnitudes. We did not consider this approach initially due to the lack of support for multi-frame fitting in early versions of \texttt{ProFit}. With \texttt{ProFit v2.0.0} this is now possible, and certainly an interesting option for future work. We did not implement multi-band fitting for \texttt{v05} yet as it requires a major effort to be implemented computationally and above all requires the definition of how parameters can vary across wavelength. 

The newly developed package \texttt{ProFuse} \citep{Robotham2022}, combining \texttt{ProFit} with the spectral energy distribution fitting package \texttt{ProSpect} \citep{Robotham2020} is a first step towards fitting physically meaningful variations as a function of wavelength. However, like other works using simultaneous multi-band fits \citep[e.g.][]{Haeussler2022}, it (for now) fixes the structural parameters and only leaves the magnitudes free to vary. This is not an option for our work since variations in size as a function of wavelength are crucial for our science aim (Section~\ref{sec:scienceaims}). Hence the upgrade from \texttt{v04} to \texttt{v05} of our catalogue focused on expanding our previous work to all nine bands and to multi-frame fitting. It is a first step towards multi-band fitting and at the same time complementary to current works in that area; and can even serve to inform choices of ``allowed" variations in other parameters.


\subsection{Manual re-calibrations}
\label{sec:manualcalibrationchanges}
We point out the tuning parameters of the \texttt{v04} pipeline that are based on manual calibration steps in Section~\ref{sec:swappingandoutliers}. These may not all be directly transferable to VIKING data and hence we re-calibrated some of them for \texttt{v05}. There are five such calibrations in total. 

The first one is the cut chosen for the candidate star selection during PSF estimation (the percentage of all segments that are likely to be stars, see Section~\ref{sec:psfdetails}). It depends on the depth of the data used for the segmentation map and the total number of segments returned by the segmentation procedure. Since we use the $gri$ segmentation maps for the VIKING bands (and the \texttt{SBdilate} option only changes the size and not the number of segments), we do not need to re-calibrate this cut. We visually inspected a random sample of the diagnostic plots of this step (example shown in Figure~\ref{fig:examplepsfseg}) to ensure that the 4\,\% selection cut is indeed appropriate for the KiDS $u$ and all five VIKING bands provided that the $gri$ segmentations are used. 

The second visually tuned parameter is the cut in reduced chi-squared to exclude bad star fits from the model PSF creation (Section~\ref{sec:psfdetails}), which is influenced mainly by the segment size. While the galaxy segments for \texttt{v05} generally increased in size due to the \texttt{SBdilate} option (cf. Section~\ref{sec:v05segmentation}), the star segments did not change since stars are compact and not extended objects. We therefore also do not need to adjust this cut for \texttt{v05}.

The third manually tuned process is the swapping of bulge and disk components where ne\-ces\-sary. This procedure was developed with many visual inspections and test runs of $r$-band fits. However, the resulting procedure, described in detail in Sections~\ref{sec:galaxyfitting} and~\ref{sec:swappingandoutliers}, does not require any tuning parameters in absolute terms and instead relies only on relative quantities such as the ratio of the double component bulge effective radius to that of the single S\'ersic fit. It is therefore expected to work well for other bands, too, as long as the galaxies in that band show comparable properties as those in the $r$-band. We confirmed this in detail using the $g$ and $i$ band fits in \texttt{v04} by repeating all visual inspection steps. For the bands added in \texttt{v05}, we checked the most important statistics: the fraction of objects entering the swapping procedure and the fraction of those actually being swapped are very similar to the $r$ band fractions. The fraction of objects that remain swapped after the procedure is also very low in all bands based on the visual inspection of galaxies in the context of the model selection re-calibration (see below). We conclude that the swapping procedure is appropriate for all nine bands and does not require re-calibration. 

The fourth set of criteria that were developed with a large number of visual inspections are those for flagging bad fits (listed in Section~\ref{sec:postprocessing} with further details in Section~\ref{sec:swappingandoutliers}). Similar to the swapping procedure, we calibrated this on the $r$-band but found it to be appropriate for the $g$ and $i$ bands as well. We therefore assumed that it would work reasonably well for the $u$ and VIKING bands, too, and did not perform any re-calibration for \texttt{v05}. However, in contrast to the swapping procedure, there are a number of hard cuts in the outlier flagging that depend on the pixel scale and segment size or can be influenced by the depth of the data. We investigate this in detail in Section~\ref{sec:outlierstats}. In summary, we find that the outlier flagging is adequate for \texttt{v05} and only the flag value ``very irregular segment" could potentially have benefitted from a re-calibration. This can easily be added since the outlier flagging is a pure post-processing procedure and we provide the paramters for all model fits irrespective of their outlier status. We also provide full details of the criteria used for flagging outliers in the corresponding flag of the \texttt{BDDecomp} DMU. Users are therefore free to ignore certain flag values or discard our flagging entirely and perform their own identification of outliers.


The fifth and last manual calibration is that of the DIC difference cut for model selection, which is described in Sections~\ref{sec:postprocessing} and~\ref{sec:swappingandoutliers}. These are cuts in absolute values that are strong functions of data quality (depth; and to a lesser extent also seeing) and need to be re-calibrated for each band individually. We therefore visually inspected 200 randomly selected galaxies for each band (1800 objects in total) and re-calibrated all $\Delta$DIC cuts. The procedure is exactly the same as that used for \texttt{v04}, so we refer the reader to Sections~\ref{sec:postprocessing} and~\ref{sec:swappingandoutliers} for a description. Due to the differences in processing for \texttt{v04} and \texttt{v05} and for maximal consistency of the manual calibration between all nine bands, we also re-calibrated the three core bands. The differences between the $g$, $r$ and $i$ calibrations in \texttt{v04} and \texttt{v05} are investigated further in Section~\ref{sec:modelseldiffs}. Here, we focus on \texttt{v05} only.

Since we perform joint simultaneous fits on all images of the same object in a given band, the most consistent way to calibrate the model selection is on combined images composed of a stack of all individual frames. Otherwise it may be difficult to evaluate the model fit for objects that have many data matches (apart from having to look at 10 diagnostic plots for a single object), since the individual frames may be too shallow to visually identify two components, but the combination of all allows to constrain them during the fit. Note that since the stacking is performed after model fitting, we can avoid the problems with the different PSFs that led us to use joint fits in the first place. To this end, we first create model images for each individual frame using its native pixel scale and PSF. We then use the \texttt{magwarp} function to re-map these PSF-convolved model images, corresponding data images and sigma maps onto the world coordinate system (pixel grid) of the first data match. Subsequently, we stack all individual data frames and model frames, both weighted appropriately by the sigma maps. Like this, the model images and data images have undergone the exact same procedure and can be directly compared. An example of such a stacked diagnostic plot composed of 12 $J$-band images is shown in Figure~\ref{fig:examplefitstack} for galaxy 544891 (which we also show in Figure~\ref{fig:v05matchseg}). 


\begin{figure}[t!]
\begin{center}
\includegraphics[width=0.8\textwidth]{plots/examplefitstack}
\caption{The (joint \texttt{v05}) double component fit to the galaxy 544891 in the VIKING $J$-band. The diagnostic plot is composed of 12 individual frames for both the data and the model that are stacked in a consistent way, taking PSF differences into account. This is the same galaxy as that shown in Figure~\ref{fig:v05matchseg}, so the stacked version here can be compared to the individual frames shown in that figure. Panels are the same as those in Figure~\ref{fig:examplefit}.}
\label{fig:examplefitstack}
\end{center}
\end{figure}

We use the visual inspections to calibrate individual model selections for each band and two versions of joint model selections: one for the core bands only ($gri$, using the summed DICs from these three bands) and one for all bands ($ugriZYJHK_s$, summing all nine DICs). The resulting confusion matrices for all bands are listed in Table~\ref{tab:modelselconfusionv05} and the calibrated DIC cuts are given in Table~\ref{tab:v05diccuts}. The overall percentages of fits classified wrongly compared to visual inspection amount to $\sim$\,3, 15, 17, 9, 9, 3, 3, 5, 5, 17 and 18\,\% for the $u, g, r, i, Z, Y, J, H, K_s$ individual, $gri$ joint and $ugriZYJHK_s$ joint model selections respectively. The high fractions in the $g$, $r$ and joint selections are driven by large numbers of galaxies visually classified as double component fit that ended up in the \texttt{NCOMP}\,=\,1 category. We comment on this further in Section~\ref{sec:modelseldiffs}. For all other bands, the confusion rate is acceptable.

\begin{table}
\centering
\caption{The confusion matrices for the \texttt{v05} model selection based on a DIC difference cut compared against visual inspection for all nine KiDS and VIKING bands and the joint model selections in the core bands only as well as in all bands. All values are in percent of the total number of visually inspected galaxies in the respective band(s). Bold font highlights galaxies classified correctly, while grey shows those that were ignored during the calibration.}
\label{tab:modelselconfusionv05}
\begin{subtable}{1\textwidth}
\centering
	\begin{tabu}{lcrrrcrrrcrrrc} % number of columns, alignment for each
	& & \multicolumn{4}{c}{$u$-band} 
	& \multicolumn{4}{c}{$g$-band} 
	& \multicolumn{4}{c}{$r$-band}\\
	\hline
	& & \multicolumn{4}{c}{number of comps.} 
	& \multicolumn{4}{c}{number of comps.} 
	& \multicolumn{4}{c}{number of comps.}\\
		 
		visual class. & 
		& 1 & 1.5 & 2 &
		& 1 & 1.5 & 2 &
		& 1 & 1.5 & 2 &\\
		\hline
		
		``single" &
		& \textbf{91.5} & 0 & 0 &
		& \textbf{58.5} & 0 & 2.5 &
		& \textbf{47.5} & 0.5 & 2.5 &\\
		
		``1.5" &
		& 0 & \textbf{1.0} & 0 &
		& 1.5 & \textbf{0} & 1.5 &
		& 0.5 & \textbf{0.5} & 2.5 &\\
		
		``double" &
		& 2.5 & 0 & \textbf{0.5} &
		& 7.5 & 0.5 & \textbf{12.5} &
		& 10.5 & 0 & \textbf{23.0} &\\
		
		``1.5 or double" &
		& 0 & \textbf{0.5} & \textbf{0} &
		& 1.5 & \textbf{0.5} & \textbf{2.0} &
		& 0.5 & \textbf{0.5} & \textbf{2.0} &\\
		
		\rowfont{\color{gray}}
		``unsure" &
		& 2.5 & 0 & 0 &
		& 6.5 & 0 & 3.0 &
		& 4.0 & 0 & 3.5 &\\
		
		\rowfont{\color{gray}}
		``unfittable" &
		& 1.5 & 0 & 0 &
		& 1.5 & 0 & 0.5 &
		& 1.0 & 0 & 1.0 &\\
        \hline
	\end{tabu}
\end{subtable}%

\bigskip
\begin{subtable}{1\textwidth}
\centering
	\begin{tabu}{lcrrrcrrrcrrrc} % number of columns, alignment for each
	& & \multicolumn{4}{c}{$i$-band} 
	& \multicolumn{4}{c}{$Z$-band} 
	& \multicolumn{4}{c}{$Y$-band}\\
	\hline
	& & \multicolumn{4}{c}{number of comps.} 
	& \multicolumn{4}{c}{number of comps.} 
	& \multicolumn{4}{c}{number of comps.}\\
		 
		visual class. & 
		& 1 & 1.5 & 2 &
		& 1 & 1.5 & 2 &
		& 1 & 1.5 & 2 &\\
		\hline
		
		``single" &
		& \textbf{69.0} & 0.5 & 2.5 &
		& \textbf{63.5} & 2.0 & 1.5 &
		& \textbf{73.0} & 0 & 0 &\\
		
		``1.5" &
		& 1.0 & \textbf{1.0} & 1.0 &
		& 1.5 & \textbf{4.0} & 1.0 &
		& 0.5 & \textbf{4.0} & 0 &\\
		
		``double" &
		& 4.0 & 0 & \textbf{11.5} &
		& 2.5 & 0 & \textbf{12.0} &
		& 1.5 & 1.0 & \textbf{12.5} &\\
		
		``1.5 or double" &
		& 0 & \textbf{0} & \textbf{1.0} &
		& 0 & \textbf{1.5} & \textbf{1.0} &
		& 0 & \textbf{0} & \textbf{1.5} &\\
		
		\rowfont{\color{gray}}
		``unsure" &
		& 3.0 & 0 & 3.0 &
		& 4.0 & 1.0 & 2.0 &
		& 1.0 & 0.5 & 2.5 &\\
		
		\rowfont{\color{gray}}
		``unfittable" &
		& 2.0 & 0 & 0.5 &
		& 1.5 & 0 & 1.0 &
		& 1.0 & 0 & 1.0 &\\
        \hline
	\end{tabu}
\end{subtable}%

\bigskip
\begin{subtable}{1\textwidth}
\centering
	\begin{tabu}{lcrrrcrrrcrrrc} % number of columns, alignment for each
	& & \multicolumn{4}{c}{$J$-band} 
	& \multicolumn{4}{c}{$H$-band} 
	& \multicolumn{4}{c}{$K_s$-band}\\
	\hline
	& & \multicolumn{4}{c}{number of comps.} 
	& \multicolumn{4}{c}{number of comps.} 
	& \multicolumn{4}{c}{number of comps.}\\
		 
		visual class. & 
		& 1 & 1.5 & 2 &
		& 1 & 1.5 & 2 &
		& 1 & 1.5 & 2 &\\
		\hline
		
		``single" &
		& \textbf{76.5} & 0 & 0.5 &
		& \textbf{79.0} & 0.5 & 1.0 &
		& \textbf{75.0} & 0 & 1.0 &\\
		
		``1.5" &
		& 0.5 & \textbf{1.0} & 1.0 &
		& 0.5 & \textbf{5.5} & 1.0 &
		& 2.5 & \textbf{2.0} & 0.5 &\\
		
		``double" &
		& 0.5 & 0.5 & \textbf{14.0} &
		& 0.5 & 0.5 & \textbf{7.0} &
		& 0 & 0.5 & \textbf{13.5} &\\
		
		``1.5 or double" &
		& 0 & \textbf{0} & \textbf{1.0} &
		& 0.5 & \textbf{0} & \textbf{0.5} &
		& 0 & \textbf{0.5} & \textbf{0} &\\
		
		\rowfont{\color{gray}}
		``unsure" &
		& 1.5 & 0.5 & 1.0 &
		& 1.0 & 0 & 2.0 &
		& 2.0 & 0 & 2.0 &\\
		
		\rowfont{\color{gray}}
		``unfittable" &
		& 0.5 & 0.5 & 0.5 &
		& 0.5 & 0 & 0 &
		& 0.5 & 0 & 0 &\\
        \hline
	\end{tabu}
\end{subtable}%

\bigskip
\begin{subtable}{1\textwidth}
\centering
	\begin{tabu}{lcrrrcrrrc} % number of columns, alignment for each
	& & \multicolumn{4}{c}{joint $gri$} 
	& \multicolumn{4}{c}{joint $ugriZYJHK_s$}\\
	\hline
	& & \multicolumn{4}{c}{number of comps.} 
	& \multicolumn{4}{c}{number of comps.}\\
		 
		visual class. & 
		& 1 & 1.5 & 2 &
		& 1 & 1.5 & 2 &\\
		\hline
		
		``single" &
		& \textbf{59.4} & 0.3 & 1.5 &
		& \textbf{71.3} & 0.7 & 0.5 &\\
		
		``1.5" &
		& 0.8 & \textbf{1.2} & 1.2 &
		& 3.6 & \textbf{0} & 0.1 &\\
		
		``double" &
		& 10.9 & 1.7 & \textbf{10.7} &
		& 11.6 & 0.1 & \textbf{4.1} &\\
		
		``1.5 or double" &
		& 0.7 & \textbf{0.5} & \textbf{1.5} &
		& 1.4 & \textbf{0} & \textbf{0.1} &\\
		
		\rowfont{\color{gray}}
		``unsure" &
		& 5.5 & 0 & 2.2 &
		& 4.4 & 0.1 & 0.4 &\\
		
		\rowfont{\color{gray}}
		``unfittable" &
		& 1.5 & 0 & 0.5 &
		& 1.4 & 0 & 0.1 &\\
        \hline
	\end{tabu}
\end{subtable}%
\end{table}


\begin{table}
	\centering
	\caption{The calibrated DIC difference cuts used for \texttt{v05} of the \texttt{BDDecomp} DMU. For each band, we show the lower bound (LB), the actual cut and the upper bound (UB) for each of the three DIC differences between our models. For the joint model selection, the cuts refer to the differences between the summed DICs of all bands.}
	\label{tab:v05diccuts}
	\begin{tabu}{lrrrrrrrrrrrr} % number of columns, alignment for each
		\hline
		 && \multicolumn{3}{c}{$\Delta$DIC$_{1-1.5}$} && 
		 \multicolumn{3}{c}{$\Delta$DIC$_{1-2}$} &&
		 \multicolumn{3}{c}{$\Delta$DIC$_{1.5-2}$}\\
		band && LB & cut & UB && LB & cut & UB && LB & cut & UB\\
		\hline
		$u$ && 66 & 77 & 370 && 265 & $10^{18}$ & $10^{40}$ && 54 & 73 & 101\\
		$g$ && 32 & 63 & 106 && 2096 & 2612 & 3867 && $10^{-11}$ & 66 & 260\\
		$r$ && 29 & 39 & 64 && 645 & 1881 & 3146 && $10^{-13}$ & 116 & 228\\
		$i$ && 137 & 180 & $10^{17}$ && 1051 & 1247 & 1616 && 481 & 512 & 576\\
		$Z$ && 28 & 31 & 281 && 464 & 650 & 819 && 171 & 306 & 944\\
		$Y$ && 21 & 52 & 65 && 256 & 316 & 382 && 53 & 119 & 175\\
		$J$ && 106 & 116 & 223 && 524 & 743 & 944 && 61 & 77 & 442\\
		$H$ && 47 & 52 & 60 && 389 & 523 & 642 && 165 & 200 & 734\\
		$K_s$ && 44 & $10^{12}$ & $10^{35}$ && 190 & 264 & 447 && 329 & 395 & 520\\		
		$gri$ && 175 & 330 & 27391 && 15145 & 17827 & 18885 && $10^{-54}$ & $10^{-24}$ & $10^{-4}$\\
		$ugriZYJHK_s$ && $10^4$ & $10^8$ & $10^{19}$ && 59994 & 79722 & 82856 && $10^{-53}$ & $10^{-23}$ & $10^{-4}$\\
        \hline
	\end{tabu}
\end{table}

For the shallower bands (especially KiDS $u$), the data quality is not sufficient to constrain more than one component in most cases, so the fraction of single component fits increases drastically. In part, this is the reason for the low confusion rates in these bands: essentially all fits are (correctly) classified as single S\'ersic objects. This is enhanced even more by the fact that we minimise the absolute number of fits classified wrongly during the model selection calibration, resulting in a bias against the rarer categories (cf. Section~\ref{sec:postprocessing}). Additionally, the corresponding DIC difference cuts are often poorly constrained due to the low number of objects available for calibration in those rare categories. This is also apparent from Table~\ref{tab:v05diccuts}, where some of the cuts show large uncertainty regions or take on unreasonably large or small values (essentially tending to zero or infinity).\footnote{The lower cuts tend to zero rather than negative infinity because we calibrate the $\Delta$DIC cuts in logarithmic space.}
The latter problem could be alleviated by visually inspecting a larger subsample of galaxies in each band. 

The joint model selection encompassing all nine bands benefits from the high number of 1800 visually inspected galaxies for calibration. However, this does not solve the underlying problem of the bands being too shallow to constrain two components. Also, joint model selection is always a compromise between all bands by necessity. Since most bands have relatively high numbers of single S\'ersic fits, the joint model selection does, too. This means that for the deeper bands with the best seeing, many fits are classified as single S\'ersic objects in the joint model selection even though they do have two well-defined components. Vice versa, an object classified as double component fit in the joint model selection may well show unconstrained components in the shallowest bands. For this reason, the joint model selection should be used with care. The compromise becomes worse for greater differences in data quality between bands.

For this reason, we also added the second version of the joint model selection, concentrating on the core bands only (like in \texttt{v04}). These are most directly comparable not only in their treatment throughout our pipeline, but also in their data quality, so there are less caveats in their joint model selection (although it is still a compromise, see also Section~\ref{sec:postprocessing}). To avoid such inconsistencies, some works (e.g. \citealt{Lackner2012, Kim2016}) take the structural parameters from one band (e.g. the $r$-band) and simply impose them onto the other fitting bands without further adjustments; only fitting the component magnitudes. Others (e.g. \citealt{Simard2011, Kennedy2016}) use simultaneous multi-band fits but again only allow the magnitudes to vary between bands. While this may result in robust colours, it does not capture physical variations of structural parameters with wavelength, which are a key quantity we want to obtain. The only way to avoid these issues and successfully use shallower bands for multi-component fits (other than deeper observations) are simultaneous multi-band fits with varying parameters as a function of wavelength. Constraints on the ``allowed" structural variation between bands can be motivated by theory, simulations or previous work fitting bands individually, such as this one.


