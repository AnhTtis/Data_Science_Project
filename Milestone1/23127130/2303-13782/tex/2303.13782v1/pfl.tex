\documentclass[12pt, draftclsnofoot, onecolumn]{IEEEtran}
\usepackage{marvosym}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{epsfig}
\usepackage{epstopdf}
\usepackage{hhline}
\usepackage{stfloats}
\usepackage{cite}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[CJKbookmarks=true,
bookmarksnumbered=true,
bookmarksopen=true]{hyperref}  
\usepackage{multirow}
\usepackage{subfigure}
\begin{document}
\title{Communication-efficient Personalized Federated Edge Learning for Massive MIMO CSI Feedback}
\author{Yiming~Cui, \emph{Graduate Student Member}, \emph{IEEE},

~Jiajia~Guo, \emph{Graduate Student Member}, \emph{IEEE},

~Chao-Kai~Wen, \emph{Senior Member}, \emph{IEEE}, and~Shi~Jin, \emph{Senior Member}, \emph{IEEE}% <-this % stops a space
	
\thanks{ 	
Y. Cui and J. Guo are with the National Mobile Communications Research Laboratory, Southeast University, Nanjing 210096, China (e-mail: yiming.cui@outlook.com; jiajiaguo@seu.edu.cn).

S. Jin is with the National Mobile Communications Research Laboratory and Frontiers Science Center for Mobile Information Communication and Security, Southeast University, Nanjing 210096, China (e-mail: jinshi@seu.edu.cn).
		
C.-K. Wen is with the Institute of Communications Engineering, National Sun Yat-sen University, Kaohsiung 80424, Taiwan (e-mail: chaokai.wen@mail.nsysu.edu.tw).}

}		
\vspace{-3cm}


\maketitle

\begin{abstract}
Deep learning (DL)-based channel state information (CSI) feedback has received significant research attention in recent years. However, previous research has overlooked the potential privacy disclosure problem caused by the transmission of CSI datasets during the training process. In this work, we introduce a federated edge learning (FEEL)-based training framework for DL-based CSI feedback. This approach differs from the conventional centralized learning (CL)-based framework in which the CSI datasets are collected at the base station (BS) before training. Instead, each user equipment (UE) trains a local autoencoder network and exchanges model parameters with the BS. This approach provides better protection for data privacy compared to CL. To further reduce communication overhead in FEEL, we quantize uplink and downlink model transmission into different bits based on their influence on feedback performance. Additionally, since the heterogeneity of CSI datasets in different UEs can degrade the performance of the FEEL-based framework, we introduce a personalization strategy to improve feedback performance. This strategy allows for local fine-tuning to adapt the global model to the channel characteristics of each UE. Simulation results indicate that the proposed personalized FEEL-based training framework can significantly improve the performance of DL-based CSI feedback while reducing communication overhead.



\end{abstract}
\begin{IEEEkeywords}
Massive MIMO, CSI feedback, federated edge learning, neural network quantization, personalization.
\end{IEEEkeywords}


\section{Introduction}

Massive multiple-input multiple-output (MIMO) is one of the core technologies in the fifth generation (5G) and expected to unceasingly play an important role in future generations of cellular communication systems. A massive MIMO system typically includes a base station (BS) equipped with considerable antennas. To fully harvest the benefits of massive MIMO, such as spatial diversity and multiplexing gains, the acquisition of downlink channel state information (CSI) is necessary \cite{lu2014overview}. In time division duplex mode, the BS can acquire downlink CSI from uplink CSI in virtue of bi-directional reciprocity. However, in frequency division duplex (FDD) mode, the reciprocity no longer holds. User equipments (UEs) are required to transmit downlink CSI back to the BS through feedback links, which incurs excessive communication overhead due to large numbers of antennas at the BS \cite{liang2016fdd}. 

Several conventional methods are proposed to reduce feedback overhead, mainly including codebook-based and compressive sensing (CS)-based. Codebook-based feedback method has been standardized in current communication systems, such as Type I/II codebook in 5G new radio \cite{TYPE12}. The UE selects codewords in the codebook shared between the BS and UE, and transmits the corresponding index to the BS. The BS recovers the channel by looking up the codebook \cite{love2008overview}. However, codebook-based methods are only applicable for regular antenna arrays and the feedback overhead is approximately in proportional to the antenna number. Moreover, the codebook design becomes complicated when the antenna number is large. Differently, the CS-based feedback method compresses the CSI with random projection into low-dimensional codewords. The codewords are reconstructed at the BS by iterative algorithms such as BM3D-AMP \cite{metzler2016denoising}. However, the performance of CS-based method heavily depends on the sparsity of channel matrices, which may not always exist in real communication scenarios. Therefore, more efficient CSI feedback methods are expected to alleviate feedback overhead. 




To overcome the limitations of the aforementioned methods and further improve the feedback performance, deep learning (DL) is introduced to CSI feedback in \cite{wen2018deep}. The DL-based method utilizes an autoencoder neural network to automatically learn how to compress and reconstruct CSI from a large number of CSI samples. Compared with codebook-based and CS-based methods, the feedback performance is significantly boosted because environment knowledge can be extracted from CSI samples to assist compression and reconstruction. Moreover, the DL-based CSI feedback algorithm is highly parallel and can be significantly accelerated in virtue of specific computational devices such as graphics processing units (GPU) and tensor processing units. In addition, DL-based CSI feedback can work with different types of antenna arrays and have no dependence on channel sparsity. These advantages has elicited considerable research attention on DL-based CSI feedback from both academia and industry. In 2021, CSI feedback enhancement has been selected as a representative use case in the study item on artificial intelligence and machine learning for new radio air interface by the 3rd generation partnership project (3GPP) \cite{213599} in Release 18. The DL-based CSI feedback in \cite{wen2018deep} is regarded as a typical method in this use case and is widely recognized as a promising solution for future communication systems. In recent years, considerable extended research works have been conducted on DL-based CSI feedback \cite{guo2022overview}, which are briefly summarized in Table \ref{tab:relatedwork}.

\begin{table}[t]
    \renewcommand{\arraystretch}{1.0}
    \centering
    \caption{Recent research on DL-based CSI feedback}
    \begin{tabular}{l|l}
    \hline
    \hline
         Category & Related research \\
         \hline
         \multirow{3}{*}{Novel network architectures} & attention mechanism \cite{cai2019attention,zhang2022attention}\\
         & multiple-resolution designs \cite{lu2020multi}\\
         & non-local blocks \cite{yu2020ds}\\
         & generative networks \cite{tolba2020massive}\\
         \hline
         \multirow{4}{*}{Different types of correlation} & temporal correlation \cite{wang2018deep}\\
         & correlation between adjacent frequencies \cite{wang2021compressive}\\
         & bi-directional correlation \cite{liu2019exploiting}\\
         & correlation between nearby UEs \cite{mashhadi2020distributed} \\
         \hline
         \multirow{3}{*}{Joint design with other modules} & channel estimation \cite{chen2020deep}\\
         & UE selection \cite{mao2021dl} \\
         & beamforming \cite{guo2020deep} \\         
         \hline
         \multirow{4}{*}{Deployment problems} & bit-stream generation \cite{guo2020convolutional} \\
         & implicit feedback \cite{chen2021deep} \\
         & transmission errors \cite{ye2020deep} \\
         & complexity reduction \cite{lu2022binarized} \\
    \hline
    \hline

    \end{tabular}
    \label{tab:relatedwork}
\end{table}

First, a variety of novel neural network architectures adopted in the field of computer vision are introduced to autoencoder design, taking into account the similarity between CSI matrices and images. These architectures include attention mechanism \cite{cai2019attention,zhang2022attention}, multiple-resolution designs \cite{lu2020multi}, non-local blocks \cite{yu2020ds}, generative networks \cite{tolba2020massive}, and more.

Second, different types of correlation are introduced to CSI feedback to further improve feedback performance. For example, temporal correlation between CSI in coherence time is leveraged with long short-term memory modules \cite{wang2018deep}. The correlation between the magnitude of uplink and downlink channel is exploited in \cite{liu2019exploiting}. The correlation between the channel in adjacent subcarriers is leveraged by frequency domain downsampling in \cite{wang2021compressive}. The spatial correlation between nearby UEs are introduced in \cite{mashhadi2020distributed}. Furthermore, CSI feedback is jointly designed with other modules including channel estimation \cite{chen2020deep}, beamforming \cite{guo2020deep}, UE selection \cite{mao2021dl}, and more. 

Last but not least, practical deployment of DL-based CSI feedback is considered in numerous research works. The deployment topics include but not limited to bit-stream generation \cite{guo2020convolutional}, implicit feedback \cite{chen2021deep}, transmission errors \cite{ye2020deep}, and complexity reduction \cite{lu2022binarized}. Previous research works on DL-based CSI feedback mostly adopt offline training and assume the CSI datasets in the target environment can be accessed with no efforts. However, this assumption is hardly realized in real-world communication systems. An plain and intuitive method to resolve this problem is to train the autoencoder networks with datasets pre-collected in other environment or generated by channel generation software. However, these datasets usually fail to represent the real channel distribution, resulting in unfavorable feedback performance. Therefore, an efficient online training method is required to realize DL-based CSI feedback in practical system.

Conventionally, two approaches, individual learning (IL) and centralized learning (CL), can be adopted for online training in DL-based CSI feedback. For IL, each UE independently trains a private autoencoder network with the local CSI dataset for CSI compression and reconstruction. However, the channel observations of each local dataset are usually limited, leading to unfavorable generalization capability. In addition, the CSI samples stored at each UE may not always be sufficient to train an autoencoder network due to the limited storage, which can result in inferior feedback performance. For CL, a global autoencoder network is trained for all UEs instead. All UEs transmit their local CSI datasets to a center server, which mixes these datasets and trains the global autoencoder. The generalization capability of the global autoencoder is usually better than the private autoencoder networks trained by IL due to the enrichment of datasets. However, CL inevitably involves uploading CSI datasets, which is usually privacy-sensitive for UEs. The location of UEs can be inferred from CSI samples \cite{ma2019wifi,wang2016csi,wu2012csi}, and the user habits may also be indirectly revealed. Therefore, CL may incur potential privacy disclosure problems.\footnote{Although CSI is originally fed back to the BS in FDD systems, implementation of DL-based algorithms may involve other computation nodes to complete neural network training, therefore bringing potential risks of privacy leakage.} 

To simultaneously achieve favorable generalization and protect privacy, a distributed training method called federated learning (FL) \cite{mcmahan2017communication} can be adopted for online training in DL-based CSI feedback. Instead of CL where all datasets are collected together at the center server, the datasets are kept local in FL to protect data privacy. To realize model training, the center server iteratively schedules UEs to perform local training, and exchanges model parameters or gradient information with them. In the 3GPP discussion on AI-based CSI feedback enhancement, FL is regarded as a promising solution for autoencoder network training by many corporations \cite{2205556}. Notably, unlike prevalent applications such as next-word prediction \cite{hard2018federated}, healthcare\cite{antunes2022federated}, and recommendation systems \cite{yang2020federated}, where the center server is located at the cloud, the center server for physical layer applications is usually an edge server placed near the BS because the UEs participating in FL are in the same cells. Therefore, to emphasize the interaction between the BS and UEs, FL is usually referred to as federated edge learning (FEEL) in physical layer applications \cite{ren2020scheduling,zhu2019broadband,tak2020federated}. The FEEL-based training framework has been applied to DL-based channel estimation \cite{elbir2021federated}, detection \cite{yang2021federated}, beamforming \cite{elbir2020federated}, channel prediction \cite{hou2021federated}, and more. 

This work proposes a communication-efficient FEEL-based training framework for DL-based CSI feedback. In this framework, UEs collaborate to train a shared global autoencoder for CSI feedback under the coordination of the BS. Each UE first trains the autoencoder with local CSI datasets and uploads the gradient information to the BS. The BS aggregates the gradients to update the global autoencoder. The BS and UEs only exchange the model parameters (or gradient information) rather than CSI datasets, thereby better protecting the privacy of UEs. To reduce the communication overhead caused by model parameter transmission, a parameter quantization method is then introduced to FEEL. This method quantizes the gradients in uplink transmission and the global model in downlink transmission into different bits according to their influence on the feedback performance. In addition, a fine-tuning-based personalization method is proposed to further enhance feedback performance in the FEEL-based training framework. However, FEEL-based training framework tends to suffer from severe data heterogeneity in DL-based CSI feedback. Although UEs in a common cell share some similar channel features to a certain extent, they usually locate in various environments, and their channel distributions are different. Therefore, to improve the performance in heterogeneous settings, an alternative approach is to allow each UE to modify the global model with local CSI datasets to adapt to the surrounding environment, which is usually referred to as personalization \cite{tan2022towards} in the FEEL-based training framework. Finally, the communication-efficient FEEL-based training framework and the personalization strategy are evaluated with CSI datasets generated by QuaDRiGa channel generation software \cite{jaeckel2014quadriga}. 

This work makes the following contributions:
\begin{itemize}
    \item \textbf{Privacy-preserving}: A FEEL-based training framework is proposed for DL-based CSI feedback. Different from centralized training strategies, the FEEL-based training framework can effectively prohibit privacy disclosure problems while achieving comparable performance with the CL-based training framework.

    \item \textbf{Communication-efficient}: To further reduce the communication overhead in the FEEL-based training framework, a parameter quantization strategy is introduced, considering that model transmission is still a bottleneck of FEEL.

    \item \textbf{High-performance}: Previous research on the FEEL-based physical layer designs directly uses the global model. In this study, a fine-tuning-based personalization strategy is introduced to allow each UE to train a personalized model, which significantly improves the feedback performance on the basis of the FEEL-based training framework.
\end{itemize}

The remainder of this paper is organized as follows. Section II introduces the channel and signal model, as well as the framework of DL-based CSI feedback. Section III provides a FEEL-based training framework for DL-based CSI feedback, a neural network parameter quantization method to reduce communication overhead, and a personalization strategy to further improve feedback performance. Section V provides the simulation results. Section VI draws a conclusion to this work.

The notations in this paper are listed as follows. The letters in bold type represent vectors and matrices and the left indicates scalars. $(\cdot)^H$ is denoted as a Hermitian transpose operation. $\mathcal{C}^{s\times t}$ means $s$ by $t$-dimensional complex space. $\| \cdot \|_2$ represents the Euclidean norm. $|\cdot|$ denotes the cardinal number of a set.

\section{System Model}
The system model is introduced in this section. The channel model and signal model are first presented, and the DL-based CSI feedback framework is then discussed.

\subsection{Channel Model and Signal Model}
A single-cell FDD system using massive MIMO is considered, where the BS is equipped with a uniform linear array with $N_t \gg 1$ antennas and the UE is equipped with a single antenna. Orthogonal frequency division multiplexing is adopted with $N_{\rm c}$ subcarriers. The channel vector on the $n$th subcarrier $\tilde{\mathbf{h}}_n \in \mathbb{C}^{N_{\rm t}\times 1}$ can be expressed as follows:
\begin{equation}
	\tilde{\mathbf{h}}_n=\sum_{p=1}^{N_{\rm p}}\sum_{s=1}^{N_{\rm s}}\alpha_{p,s}\mathbf{\rm \mathbf{a}}({\theta_{p,s}}),
\end{equation}
where $N_{\rm p}$, $N_{\rm s}$, $\alpha_{p,s}$, and $\theta_{p,s}$ are the number of scattering clusters, the number of sub-paths for each cluster, the complex gain of each sub-path, and the angle of departure, respectively.  $\mathbf{a}(\cdot)$ is the steering vectors and $\mathbf{a}({\theta})$ is formulated as follows:
\begin{equation}
    \mathbf{a}({\theta})=[1,e^{j 2 \pi \frac{{\rm d}}{\rm \lambda}}{\rm sin}(\theta),...,e^{j 2 \pi \frac{(N_{\rm t}-1){\rm d}}{\rm \lambda}}{\rm sin}(\theta)],
\end{equation}
where $\rm d$ and $\rm \lambda$ are the distance between adjacent antennas and wavelength, respectively. The received signal $y_n \in \mathbb{C}$ on the $n$th subcarrier is as follows:
\begin{equation}
    y_n={\Tilde{\mathbf{h}}_n}^H \mathbf{v}_n x_n + z_n,
\end{equation}
where $\Tilde{\mathbf{h}}_n \in \mathbb{C}^{N_{\rm t}\times 1}$, $\mathbf{v}_n \in \mathbb{C}^{N_{\rm t}\times 1}$, $x_n\in \mathbb{C}$, and $z_n\in \mathbb{C}$ denotes the downlink channel vector, the beamforming vector, symbol transmitted in downlink, and additive noise on the $n$th subcarrier, respectively. The CSI matrix $\tilde{\mathbf{H}}$ is the row-stacking of the channel vectors at $N_{\rm c}$ subcarriers such that $\tilde{\mathbf{H}}=[\Tilde{\mathbf{h}}_1,...,\Tilde{\mathbf{h}}_{N_{\rm c}}] \in \mathbb{C}^{N_{\rm t}\times N_{\rm c}}$. The CSI matrix is composed of $2N_{\rm t}N_{\rm c}$ real-valued numbers, leading to overwhelming communication overhead. To make the CSI matrices more sparse for compression, discrete Fourier transformation (DFT) is performed to transform $\tilde{\mathbf{H}}$ into the angular-delay domain as follows:
\begin{equation}
    \mathbf{H}= \mathbf{F}_{\rm a}\tilde{\mathbf{H}}\mathbf{F}_{\rm d},
\end{equation}
where $\mathbf{F}_{\rm a} \in \mathbb{C}^{N_{\rm t}\times N_{\rm t}}$ and $\mathbf{F}_{\rm d} \in \mathbb{C}^{N_{\rm c} \times N_{\rm c}}$ are DFT matrices.

\subsection{DL-based CSI feedback}
Considering the CSI matrix $\mathbf{H}$ is overlarge for feedback, a DL-based data compression method is introduced to further alleviate feedback overhead. An autoencoder network is employed, which includes an encoder network deployed at the UE and a decoder network at the BS. The UE first compresses the CSI matrix $\mathbf{H}$ into a low-dimentional codeword ${\rm \mathbf{s}} \in \mathbb{R}^{N_{\rm s}}$, which can be written as follows:
\begin{equation}
    {\rm \mathbf{s}}=f_{\rm en}(\mathbf{H}),
\end{equation}
where $f_{\rm en}(\cdot)$ represents the encoder network function. The codeword is then fed back to the BS. The compression ratio is defined as $\gamma=N_{\rm s}/2N_{\rm t}N_{\rm c}$. The codeword is then transmitted to the BS through a feedback link. The channel of the feedback link is assumed to be perfect. Once receiving the codeword, the BS uses the decoder network to reconstruct the codeword into the CSI matrix, which is formulated as follows: 
\begin{equation}
    \mathbf{\hat{\mathbf{H}}}=f_{\rm de}({\rm \mathbf{s}}),
\end{equation}
where $\mathbf{\hat{\mathbf{H}}}$ is the reconstructed CSI and $f_{\rm en}(\cdot)$ is the decoder network function. After reconstruction, inverse DFT is performed to convert the CSI matrix back to the spatial-frequency domain.

To implement DL-based CSI feedback, some loss functions are employed to train autoencoder networks. Mean square error (MSE) is the most common loss function in previous related research, which can be formulated as follows:
\begin{equation}
    l_{\rm{MSE}}(\mathbf{H},\hat{\mathbf{H}})=\|\hat{\mathbf{H}}-\mathbf{H}\|_{2}^{2}.
\end{equation}
Considering that the CSI is usually used for beamforming design, cosine similarity is also taken as a metric of feedback quality. In this case, the negative of cosine similarity is employed as a loss function, which can be written as follows:
\begin{equation}
    l_{\rm{CS}}(\tilde{\mathbf{H}},\hat{\tilde{\mathbf{H}}})=-\frac{1}{N_{\rm c}}\sum_{n=1}^{N_{\rm c}}\frac{|\hat{\tilde{\mathbf{h}}}_n^H\tilde{\mathbf{h}}_n|}{\|\hat{\tilde{\mathbf{h}}}_n \|_2 \|\tilde{\mathbf{h}}_n \|_2}.
\end{equation}
where $\hat{\tilde{\mathbf{h}}}_n$ represents the reconstructed channel of the $n$th subcarrier.

\section{Communication-efficient Personalized FEEL for DL-based CSI Feedback}

In this section, a communication-efficient personalized FEEL is presented. First, a FEEL-based training framework is introduced to DL-based CSI feedback to protect data privacy. Considering the overwhelming communication overhead of the FEEL-based training framework, a neural network quantization method is proposed to reduce the communication overhead. Finally, a personalization strategy is introduced to the FEEL-based training framework to improve the performance of DL-based CSI feedback.


\subsection{Basic Autoencoder Architecture}
\begin{figure}[t]
    \centering
    \includegraphics[width=1\textwidth]{figure/csifeedback4.pdf}
    \caption{Illustration of the DL-based CSI feedback and the corresponding network architecture.}
    \label{fig:csi}
\end{figure}


In this work, a modified version of channel reconstruction network (CRNet) \cite{lu2020multi} is employed for DL-based CSI feedback.\footnote{Given that CRNet in \cite{lu2020multi} is a lightweight autoencoder and exhibits inferior feedback performance in complicated outdoor scenarios, we increase the width of certain convolutional layers in CRNet to enhance the performance.} The architecture of the autoencoder network is shown in Fig. \ref{fig:csi}. The real and imaginary parts of the CSI samples are separated into two channels and normalized between 0 and 1 for inputs. 

The input CSI is first processed by two branches of convolutional layers with different kernel sizes for multi-resolution feature extraction. The output features of the two branches are then concatenated and merged by a convolutional layer with 1$\times$1 kernels. The combined features are flattened and compressed into a $N_s$-dimensional real-valued vector referred to as a codeword by a dense layer. The compression ratio can be defined as follows:
\begin{equation}
    \gamma=\frac{N_{\rm s}}{2N_{\rm t}N_{\rm c}}.
\end{equation}
The codeword is then reconstructed by the decoder at the BS. A dense layer and a reshape layer are first employed to recover the shape of the CSI. Then, a head convolution with 5$\times$5 kernels are used for rough feature extraction. Next, two cascade CRBlocks are followed to refine the initially reconstructed CSI for better performance. Each CRBlock also adopts multi-resolution structure similar to the encoder. A residual structure is adopted to avoid gradient vanishing and explosion \cite{he2016deep}. To further accelerate the convergence, a ReZero module is added before skip connection, which includes a trainable scalar initialized as zero \cite{bachlechner2021rezero}. After the two CRBlocks, a Sigmoid activation is used to ensure the output value remains in the range $(0,1)$.


\subsection{FEEL-based Training Framework}
\subsubsection{Motivation}
In CL, the BS can collect CSI samples from different UEs in different areas to form a mixed datasets. However, the location information of UEs can also be partially or completely inferred on the basis of collected CSI. The uploading of CSI samples increases the risk of privacy disclosure. Therefore, FEEL is introduced to DL-based CSI feedback, where all UEs perform local training and iteratively exchange model parameters with the BS. Local CSI datasets are not uploaded to the BS, which protects the privacy of UEs.


\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\textwidth]{figure/FL2.pdf}
    \caption{Illustration of the FEEL-based CSI feedback.}
    \label{fig:fl}
\end{figure}


\subsubsection{Training Framework} 
Considering $K$ UEs indexed from $1$ to $K$ participate in FEEL to collaboratively train an autoencoder for DL-based CSI feedback, the $k$th UE has a local datasets $\mathcal{D}_k$ and the number of samples in dataset $\mathcal{D}_k$ is denoted as $n_k$, where $\sum_{k=1}^{K}n_k=n$. The optimization objective of FEEL can be formulated as follows:
\begin{equation}
    \min_{w \in \mathbb{R}^d}F(w)\quad {\rm s.t.}\quad F(w)=\sum_{k=1}^{K} \frac{n_k}{n} l_k(w),
    \label{equ:feel}
\end{equation}
where $w$ is the global model weight, $d$ is the number of network parameters, and $l_k(\cdot)$ is the loss on the local dataset $\mathcal{D}_k$. To solve the optimization problem in (\ref{equ:feel}) \cite{mcmahan2017communication}, a FEEL-based training framework is proposed for DL-based CSI feedback, which is illustrated in Fig. \ref{fig:fl}. The main steps of this framework is summarized as follows:
\begin{itemize}
    \item \textbf{Step 1 Model initialization}: The BS adopts a pretrained model $w_0$ to initialize the global model. The pretrained model is usually trained with the CSI datasets pre-collected in other scenarios or generated by the channel simulation software, which can reduce the training rounds of FEEL and the total communication overhead compared to training from scratch. 

    \item \textbf{Step 2 Transmitting global model}: The BS checks the availability of all UEs, and schedules $ M (M \leq K)$ available UEs $S_t=\{s_1,\cdots,s_{M}\} (1\leq s_i \leq K)$ to participate in the $t$th round of FEEL. The current global model $w^{t}$ are transmitted to scheduled UEs for initialization.
    
    \item \textbf{Step 3 Local update}: Each scheduled UE $s_i (1\leq i \leq M)$ initializes the local model with the received global model $w^{t}$, and trains the local model with local CSI datasets $\mathcal{D}_{s_i}$ for $E$ epochs. All UEs adopt the same training strategies including learning rate, optimizer, etc.
    
    \item \textbf{Step 4 Uploading model update}: After local training, the local model of the UE $s_i$ is updated from $w^t$ to $w^t_{s_i}$. The scheduled UEs report the model update $\Delta w^t_{s_i}=w^t_{s_i}-w^t (i=1,...,M)$ to the BS.
    
    \item \textbf{Step 5 Model aggregation}: When the BS received all updates $\Delta w^t_{s_i} (i=1,...,M)$ from the scheduled UEs, these updates are aggregated to generate a new global model $w^{t+1}$ by averaging weighted by the sample numbers in local datasets $n_{s_i}$. Then, the BS launch the next round of FEEL from Step 2 until the target rounds of FEEL are completed (or the global model reaches the performance requirements).
\end{itemize}
\begin{algorithm}[t]
	\caption{A FedAvg-based FEEL Algorithm for DL-based CSI Feedback}
	\label{alg:FEEL}
	\begin{algorithmic}[1]
		\REQUIRE $K$ UEs indexed $1,\cdots,K$ with local CSI datasets $\mathcal{D}_{1},\cdots,\mathcal{D}_{K}$. $M (M\leq K)$ UEs are scheduled in each round of FEEL. The local epoch number, batch size, local learning rate, and loss function are $ E $, $ B $, $\eta$, and $l(\cdot)$ respectively. 
		\STATE Initialize the global model parameters as $w_0$
		\FOR {$t=1,...,T$}	 
		\STATE The BS schedules $M$ UEs $ S_t=\{s_1,\cdots,s_{M}\} $ and transmits $w^t$ to $S_t$
		\FOR {$ s_i \in S_t $ in parallel}
		\STATE Divide $\mathcal{D}_{s_i}$ into batchs $\mathcal{B}=\{b_1,\cdots,b_{N}\}$ with batch size $ B $
		\FOR {$n$ from $1$ to $E$}
		\FOR {$b\in \mathcal{B}$}
		\STATE $w_{s_i}^t \leftarrow w_{s_i}^t - \eta \triangledown l(w_{s_i}^t;b)$
		\ENDFOR
		\ENDFOR
		\STATE $\Delta w^t_{s_i} \leftarrow w^t_{s_i}-w^t$
		\STATE Report $\Delta w^t_{s_i}$ to the BS
		\ENDFOR
		\STATE $w^{t+1} \leftarrow w^t + \sum_{i=1}^{M} \frac{n_{s_i}}{n} \Delta w^t_{s_i}$ 
		\ENDFOR
	\end{algorithmic}
\end{algorithm}
The algorithmic description of FEEL is shown in Algorithm \ref{alg:FEEL}. If each UE only conducts gradient descent for one-epoch, that is, $E=1$ in Algorithm \ref{alg:FEEL}, the optimization method is usually referred to as FederatedSGD. To further accelerate the convergence, the local update can be repeated for several epochs before uploading to the BS ($E>1$). The approach is termed as FederatedAveraging (FedAvg) by \cite{mcmahan2017communication}. In this work, we adopt the FedAvg algorithm to improve communication efficiency.

\subsection{Neural Network Quantization}
\subsubsection{Motivation}
FEEL provides a paradigm shift from collecting local datasets to exchanging model parameters (or updates), as compared to CL. However, the frequent transmission of model parameters presents a significant challenge for FEEL, particularly in the case of DL-based CSI feedback. Autoencoder networks typically have a large number of parameters, resulting in excessive communication overhead. 

In addition, transmitting model updates in the uplink direction presents an even greater challenge. Firstly, the bandwidth for uplink and downlink transmission is asymmetric. The uplink transmission speed is usually much slower than the downlink. Additionally, as highlighted by \cite{konevcny2016federated}, certain cryptographic protocols may be applied to further enhance privacy when UEs upload the model updates, leading to additional communication overhead. To address these issues and improve communication efficiency, the FEEL-based training framework incorporates neural network quantization.

\subsubsection{Key idea}
Autoencoder network parameters are typically stored as 32-bit float numbers, which is redundant for representing the network. To reduce communication overhead, this work employs parameter quantization for autoencoder networks, which involves representing the parameters using fewer bits \cite{choudhary2020comprehensive}. The quantization process is formulated as follows: 
\begin{equation}
      y=x_{\rm min} +{\rm round} \left( \frac{x-x_{\rm min}}{\rm \Delta} \right) \times {\rm \Delta},
     ~{\rm s.t.~\Delta}=\frac{x_{\rm max}-x_{\rm min}}{2^{n_b}-1},    
\end{equation}
where $x$ denotes the parameter to be quantized, $y$ represents the quantized parameter, $x_{\rm min}$ and $x_{\rm max}$ are the minimum and maximum of a parameter set, and ${n_b}$ denotes the number quantization bits for each parameter. 

In an autoencoder network, the quantity and influence on performance differ between different types of parameters. For instance, the parameters of a dense layer or a convolutional layer consist of weights and bias. Weights parameters typically constitute a large proportion of the total parameters and are less sensitive to quantization errors. Conversely, bias parameters are much fewer in number and more sensitive to quantization errors. Consequently, only weight parameters are quantized, while the bias weights are still stored as 32-bit floats. The quantization of batch normalization and ReZero layers has little impact on the total parameter count and is not taken into account.

The impact of quantization on uplink and downlink transmission is then analyzed. For uplink transmission, UEs transmit model updates to the BS. The updates from all UEs are then aggregated by averaging at the BS, which can mitigate the effects of quantization noise to a certain extent.  As a result, the quantization errors in uplink transmission has relatively small influence on feedback performance, allowing for lower precision quantization of the model update. In contrast, for downlink transmission, the BS transmits the global model to the UEs. The global model is directly used to initialize the autoencoder network for local update, making it more vulnerable to quantization errors. As a result, more bits are required to represent the global model to minimize the impact of quantization compared to the uplink model updates. 



\subsection{A Fine-tuning-based Personalization Strategy}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.75\textwidth]{figure/pfl3.pdf}
    \caption{Illustration of the fine-tuning-based personalization strategy for FEEL-based CSI feedback.}
    \label{fig:pfl3}
\end{figure}

\subsubsection{Motivation}
Data heterogeneity is one of the essential challenge in FEEL, which contradicts the common assumption that all training data is independent identically distributed (i.i.d.) in oridinary machine learning problems \cite{mcmahan2017communication}. In DL-based CSI feedback, the channel characteristics of each UE-BS links are predominantly dependent on the physical environments around UEs. For UEs in different positions within a cell, the channel characteristics can be substantially different. The data heterogeneity may cause performance degradation and poor convergence in FEEL. In previous studies on the FEEL, the performance of FEEL did not always outperforms IL, especially when each UEs poccess sufficient CSI samples as training datasets. Such unfavorable performance may disincentivize UEs from participating into FEEL.

As indicated in (\ref{equ:feel}), the objective of FEEL is to optimize the feedback performance of a large number of UEs in a cell simultaneously. After optimization, the autoencoder approaches an optimal in terms of averaging, resulting in a compromised result that maximizes the average performance of all UEs. This result is well-generalized to all UEs, but still suboptimal from the perspective of each UE. In contrast, IL aims to optimize the feedback performance of each UE, while ignoring the performance of the autoencoder on other UEs. Therefore, the performance of IL is usually relatively high but the generalization performance is unfavorable. An intuitive idea is to combine the ideas of FEEL and IL, which can leverage the advantages of both methods. To incorporate the advantage of IL into FEEL, the global model of FEEL can be treated as a well-generalized initialization and then retrained with local CSI datasets, similar to IL. Using this approach, a fine-tuning-based personalization strategy is proposed for FEEL.


\subsubsection{Training Framework} 
In conventional FEEL, all UEs share a global model for DL-based CSI feedback tasks, and the optimization objective can be written as (\ref{equ:feel}). In contrast, personalized FEEL enables each UE to optimize a personalized model to adapt to the local CSI dataset. The objective can be rewritten as follows:
\begin{equation}
    \min_{w_1,..., w_K \in \mathbb{R}^d}F(w_1,...,w_K),\quad {\rm where}\quad F(w_1,...,w_K)= \sum_{k=1}^{K} \frac{n_k}{n} f_k(w_k),
    \label{equ:pfeel}
\end{equation}

The personalization strategy is illustrated in Fig. \ref{fig:pfl3}. Once the global model achieves the expected performance, the BS stops performing the next iteration of FEEL and transmits the current global model to all UEs. Each UE fine-tunes the global model with its local dataset after receiving it, resulting in each UE having a different personalized model that is better suited for CSI compression and reconstruction in their specific surroundings. After personalization, since the strategy is executed at the UE side, all UEs need to transmit the personalized decoder networks back to the BS to replace the global decoder. Furthermore, after personalization, the feedback performance of the personalized models are monitored by the UEs with the latest CSI samples because the UEs may move to other environments. If the performance of a personalized model becomes worse than the global model, the personalized model is discarded, and the global model is restored.


\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\textwidth]{figure/PFLeg4.pdf}
    \caption{Illustration of the application of personalization in practical scenarios.}
    \label{fig:pfleg}
\end{figure}


Notably, there exists a trade-off between generalization capability and feedback performance in personalized FEEL. During the process of fine-tuning, the feedback performance of the certain UE increases, while the generalization capability gradually decreases. As shown in Fig. \ref{fig:pfleg}, UEs can flexibly select the numbers of fine-tuning epochs to determine whether to have a more generalized model or a high-performance model based on their surrounding environments. For example, in scenarios where UEs have high mobility, such as driving scenarios, the environments around them are changing rapidly, making it difficult to achieve better generalization, and thus no fine-tuning or only a small number of fine-tuning epochs can be employed to achieve better generalization. Conversely, for IoT devices (e.g., surveillance cameras and sensors) or UEs that remain only in a small area, the environments around them are relatively static, and more epochs of fine-tuning can be adopted to further enhance feedback performance.


\section{Simulation Results}
Firstly, the channel generation settings and the training strategies are presented. Secondly, the performance of FEEL for DL-based CSI feedback and the quantization method are analyzed. Lastly, the proposed personalization strategy is evaluated. 

\subsection{Simulation Settings}

\subsubsection{Channel Generation} 
The CSI datasets are generated by QuaDRiGa \cite{jaeckel2014quadriga}, which is a generation software employing geometry-based stochastic channel models.\footnote{\url{https://quadriga-channel-model.de}} Two different scenarios, RMa NLOS and UMi LOS, are utilized for pretraining and deployment, respectively. These scenarios correspond to the '3GPP\_38.901\_RMa\_NLOS' and '3GPP\_38.901\_UMi\_LOS' predefined in QuaDRiGa, and are compatible with 3GPP TR 38.901 \cite{38901}. The difference between the pretraining scenario and the deployment scenario is to simulate the case where the distribution of CSI in a practical scenario is different from that in a dataset collected or generated for pretraining. The cell range in both the RMa and UMi scenarios is set to 100 m. The center frequency and the bandwidth are set to 2.655 GHz and 70 MHz, which correspond to the operating band "n7" as specified in 3GPP TS 38.101-1 \cite{38101}. The specific settings are listed in Table \ref{tab:my_label}.

\begin{table}[t]
    \renewcommand{\arraystretch}{1.0}
    \centering
    \caption{Channel Generation Settings}
    \begin{tabular}{l|l}
    \hline
    \hline
        \multirow{2}{*}{Scenarios} & Pretraining: RMa NLOS \\
         & Deployment: UMi LOS\ \\
         \hline
         \multirow{2}{*}{Antenna settings}&BS: 32 omnidirectional antennas, ULA \\
         & UE: a single omnidirectional antenna \\
         \hline
         Operating system & FDD-OFDM system \\
         \hline
         Subcarrier number & 32 \\
         \hline
         Center frequency & 2.655 GHz \\
         \hline
         Bandwidth & 70 MHz \\
         \hline
         Cell range & 100 m \\
         \hline
         BS height & RMa: 25 m \quad UMi: 10 m \\
         \hline
         UE height &  1.5 m \\
         \hline
         Minimum BS-UE distance & 10 m \\
         \hline
         Correlation distance & RMa: 50 m \quad UMi: 12 m \\
    \hline
    \hline
    \end{tabular}
    \label{tab:my_label}
\end{table}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\textwidth]{figure/UEpos2.pdf}
    \caption{Illustration of the UE positions in the RMa and UMi scenarios. The black circle represents the cell boundary and the blue circles indicate the range of movement for the UEs.}
    \label{fig:umi}
\end{figure}

Fig. \ref{fig:umi} illustrates the generation of 50 UEs, indexed from 1 to 50, in the RMa and UMi scenarios. The BS is located at the center of the cell, and the positions of the UEs are uniformly distributed throughout the cell. Each UE is expected to walk randomly within a circular area with a radius of 5 m, and 10,000 CSI samples are generated in this area for each UE. The CSI datasets of all UEs are divided into training, validation, and test sets by the proportion 8:1:1.\footnote{In practical deployment, the BS require a validation and a test datasets to monitor the process of FEEL and select the best model trained by FEEL. The BS is assumed to poccess a small amount of CSI datasets from different UEs used for validation and test.} All CSI samples are normalized to the range of 0 to 1.



\subsubsection{NN Training Details}
All DL-based algorithm were implemented using TensorFlow 2.4.1 on DGX-1 workstation. The learning rate was initially set to $10^{-3}$ and then reduced to $10^{-4}$ when the loss function converged. A batch size of 32 was utilized, and the Adam optimizer was employed for both FEEL and personalization. In each round of FEEL, 5 UEs were randomly chosen from all available UEs for participation. The number of local epochs was set to 2. The normalized MSE (NMSE) is employed to evaluate the performance of CSI feedback as:
\begin{equation}
	\rm NMSE= \rm E\left\{\frac{\|\mathbf{H}-\hat{\mathbf{H}}\|_2^2}{\|\mathbf{H}\|_2^2}\right\}.
\end{equation}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\textwidth]{figure/FLcr2.pdf} 
    \caption{Comparison of IL, CL, and FEEL for DL-based CSI Feedback under different compression ratio. The number of UEs and samples per UE are 50 and 5,000, respectively.}
    \label{fig:feelcr}
\end{figure}

Two metrics are proposed to evaluate the performance of the FEEL-based training framework and the personalization strategy, respectively, based on NMSE. For the FEEL-based training framework, the global NMSE (G-NMSE) is used, which calculates the NMSE on the mixed datasets of all 50 UEs. This metric represents the feedback performance when a UE moves randomly within the cell and can also be interpreted as the generalization capability of a model. On the other hand, for the personalization strategy, the performance of the personalized models on the corresponding UE is concerned. Therefore, the mean individual NMSE (MI-NMSE) is also adopted as a metric, which uses the mean NMSE on each individual UE for evaluation.

Four different training framework are simulated for DL-based CSI feedback for comparison, including IL, CL, FEEL, and personalized FEEL. IL refers to the training of an autoencoder network independently by each UE using their respective CSI datasets. CL refers to the training of an autoencoder by the BS with the mixed datasets collected from all UEs. FEEL and personalized FEEL are simulated as described in Section III.

\subsection{Performance of FEEL for DL-based CSI Feedback}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\textwidth]{figure/FLue4.pdf}
    \caption{Performance of FEEL for DL-based CSI feedback under different numbers of UEs and samples per UE.  The compression ratio is set to 1/16.}
    \label{fig:feelue}
\end{figure}

First, the performance of IL, CL, and FEEL-based training frameworks is compared under different compression ratios. Fig. \ref{fig:feelcr} illustrates that the FEEL-based training framework exhibits comparable performance with CL, thereby demonstrating the effectiveness of FEEL-based training framework for DL-based CSI feedback. In addition, the performance of FEEL and CL-based training framework significantly outperforms IL-based training framework. While the autoencoder networks trained by CL and FEEL both exhibits favorable generalizations to different environments, the autoencoder networks trained by IL fail to generalize to new channel conditions. This emphasizes the significance of UE collaboration in DL-based CSI feedback. 


\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\textwidth]{figure/FLquan4.pdf}
    \caption{Performance of FEEL for DL-based CSI feedback under different quantization bits. The compression ratio and UE number are set to 1/16 and 50, respectively. 'Q', 'WQ', 'Up', 'Down' represents quantized FEEL, FEEL without quantization, uplink quantization, downlink quantization, respectively. The number in the legend denotes the number of samples per UE.}
    \label{fig:quan}
\end{figure}

In actual deployment, the UEs are usually storage-limited devices, and may not have sufficient storage capacity to save a large number of CSI samples for FEEL. In addition, unstable connections or other applications that consume significant bandwidth may prevent UEs from participating in FEEL. Therefore, the influence of sample numbers and UE numbers is investigated. Fig. \ref{fig:feelue} illustrates the feedback performance for different sample numbers per UE and UE numbers. The autoencoder network exhibits higher feedback performance as more UEs participate in FEEL, indicating that encouraging more UEs to participate in FEEL can enhance feedback performance due to the inclusion of more diverse channel observations in training. However, the sample numbers have a relatively small influence on FEEL. When each UE possesses 3,000 CSI samples, the G-NMSE only drops less than 1 dB compared to the case where each UE has 10,000 samples. Although each UE participating in FEEL only has a small number of training samples, the collaboration between UEs plays a role similar to data augmentation. Therefore, the total training samples of all UEs are usually sufficient. The results indicate that UEs do not have to store numerous CSI samples, and the storage of UEs can be conserved in practice.


\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\textwidth]{figure/PFLcr4.pdf}
    \caption{Comparison of IL, FEEL, and personalized FEEL for DL-based CSI Feedback under different compression ratios. The number of UEs and samples per UE are 50 and 5,000, respectively.}
    \label{fig:pfl}
\end{figure}

The performance of the FEEL-based training framework with neural network quantization is then evaluated. Different quantization bits are tested to determine the appropriate number of bits for uplink and downlink transmission, which can reduce the communication overhead while maintaining a relatively low performance drop. The results of the evaluation are shown in Fig. \ref{fig:quan}. It is found that at least 2 quantization bits are required when only the model updates in the uplink are quantized to maintain the performance, that is, less than 1 dB performance drops compared with non-quantized FEEL. The quantization of downlink global models is also considered, and at least 8 bits are required to achieve comparable performance with non-quantized FEEL. The difference between the two quantization strategies is mainly attributed to the aggregation process at the BS, which mitigates the influence of quantization noise in uplink to a certain extent. If 2-bit and 8-bit quantization are used for uplink and downlink respectively, the communication overhead in the FEEL-based training framework can be reduced approximately by a factor of 16 for the uplink and 4 for the downlink, significantly improving the communication efficiency. The influence of quantization bits is also validated with different sample numbers per UE, and the results show that the sample number makes little difference to the proposed quantization strategy.


\subsection{Performance of Personalized FEEL for DL-based CSI Feedback}


In Fig. \ref{fig:pfl}, the MI-NMSE of IL, FEEL, and personalized FEEL are compared under different compression ratios to evaluate the individual performance of autoencoder networks. Personalized FEEL shows a clear performance gain compared to FEEL, demonstrating that the proposed personalization strategy can effectively adapt the global model trained by FEEL to the environment surrounding each UE with local datasets. Notably, the simulation takes the worst case where UEs for personalization are randomly moves within certain ranges. In practical scenarios, UEs typically move along regular paths, such as walking along a street, where the performance gain brought by the personalization strategy may be even greater. Furthermore, personalized FEEL outperforms IL under different compression ratios, as FEEL can learn shared environment knowledge from other UEs and provide a better initialization for personalization compared to IL. 



Similarly, in Fig. \ref{fig:feelsample}(a), the influence of sample numbers on the performance of personalized FEEL is investigated, considering the limited storage of UEs. When 50 UEs participate in FEEL, the performance is relatively robust to the sample number due to the collaboration between a large number of UEs. However, the performance of IL is sensitive to the sample number and drops dramatically when the training samples are insufficient. For the current settings, IL requires approximately 3,000 training samples to outperform FEEL. The results also demonstrate that FEEL can improve feedback performance by collaboration in scenarios where there is a deficiency of samples. In addition, personalized FEEL shows evident performance gains for different sample numbers compared with FEEL and IL. When each UE has 10,000 training samples, the performance gain is more than 5 dB compared with FEEL. With more training samples for fine-tuning, the gains to FEEL also becomes larger. 

Considering a UE that launchs personalization in a certain environment may move to other environments in different periods, the generalization capability of personalized FEEL is also tested for different sample numbers, as shown in Fig. \ref{fig:feelsample}(b). The generalization capability of the personalized model degrades when more training samples are used for fine-tuning. However, the generalization capability of the personalized models is still much higher than the models trained by IL when the training sample number is large due to the enriched knowledge learned by the global model.

\begin{figure}[t]
	\centering 
	\subfigure [\label{fig_first_case1} ]{
		\includegraphics[width=0.48\linewidth]{figure/PFLsample4.pdf}}
	\subfigure [\label{fig_second_case1}]{
		\includegraphics[width=0.48\linewidth]{figure/PFLsampleG2.pdf}}	
		\caption{Comparison between the feedback performance and generalization capability of IL, FEEL, and personalized FEEL under different sample numbers. The compression ratio and UE number are 1/16 and 50, respectively.} 
	\label{fig:feelsample}
\vspace{-0.7cm}
\end{figure}

\begin{figure}[t]
	\centering 
	\subfigure [\label{fig_first_case2} ]{
		\includegraphics[width=0.48\linewidth]{figure/PFLacc4.pdf}}   
	\subfigure [\label{fig_second_case2}]{
		\includegraphics[width=0.48\linewidth]{figure/PFLgen2.pdf}}   	
	\caption{Performance-generalization tradeoff in personalized FEEL w/o quantization. The compression ratio, number of UEs, samples per UE, and quantization bits are set to 1/16, 50, 5,000, and 2, respectively.} 
	\label{fig:tradeoff}
\vspace{-0.7cm}
\end{figure}


Fig. \ref{fig:tradeoff} illustrates the tradeoff between the performance and generalization in personalized FEEL.\footnote{Because the aforementioned stepwise learning rate strategy is hard to perform if the training epoch of personalization is fixed, the learning rate is fixed to $10^{-3}$ in this simulation.} The MI-NMSE decreases with increasing training epochs during personalization, indicating improved feedback performance for each UE. However, the G-NMSE increases during personalization, suggesting that the generalization capability of the personalized models declines with more fine-tuning epochs. Despite the reduction in generalization capability, the G-NMSE is still lower than -5 dB, which is significantly better than that of the IL-based training framework (G-NMSE=-0.68 dB). In practical scenarios, UEs can choose an appropriate epoch number based on their surrounding environments. In addition, the effect of quantization on personalization is evaluated. A global model with 2-bit quantization in uplink is used for personalization. The results show that the feedback performance only slightly degrades when personalization is performed on the global model trained with quantization.



In actual deployment, the moving trails of UEs varies according to their types and status, which results in different performance gains of personalization. Therefore, the influence of the moving range of UEs on personalized FEEL is investigated. For each moving range, 50 different UEs are regenerated in the same cell, and each UE possesses 5,000 CSI samples. The results, as shown in Fig. \ref{fig:pflrange}, demonstrate that personalized FEEL always outperforms IL with different ranges of UEs. In addition, the feedback performance of personalized models increases with smaller moving ranges. When UEs remain in a relatively static environment (e.g., moving range is 1 m), the personalization gain reaches 13.23 dB based on the global model.\footnote{The environments of the UEs participating in FEEL is different with those of the UEs for personalization in this simulation. Therefore, the MI-NMSE of the global model exhibits degradation compared with previous simulations. Simulations show this degradation can be essentially mitigated ($<$ 1 dB) when the participating UEs is more than 200 in FEEL.} These results suggest that the personalization strategy is more suitable for UEs that remain in a small area. However, personalization can still bring evident performance gain even when the moving range is relatively large (e.g. 30 m). These findings suggest that the personalization strategy can be launched in various conditions in practice, because most conditions are subsets of the case where UEs are randomly walk in a circular area with a radius of 30 m.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\textwidth]{figure/PFLrange4.pdf}
    \caption{Performance of personalized FEEL for DL-based CSI feedback with different ranges of UEs. The compression ratio, number of UEs, and samples per UE are set to 1/16, 50, and 5,000, respectively.}
    \label{fig:pflrange}
\end{figure}

\subsection{FEEL and Meta-learning}

The influence of the local training epochs in FEEL is investigated in this subsection. The performance of FEEL and personalized FEEL are evaluated with varying local epochs. As shown in Fig. \ref{fig:feele}, the performance of personalized FEEL improves as the number of local epochs increases, while FEEL decreases when each UE conducts more local epochs. This implies that personalization gains become more evident when more local training is conducted in each round of FEEL. This phenomenon can be attributed to the similarity between FEEL and a first-order meta-learning algorithm called Reptile \cite{nichol2018first}. As demonstrated in \cite{jiang2019improving,nichol2018first}, the FEEL training process combines joint learning and meta-learning. When each UE trains its local model for fewer epochs, FEEL becomes more similar to joint learning, which optimizes the performance over all participated UEs and results in higher performance of FEEL. On the other hand, when local training is conducted for more epochs, FEEL becomes more similar to meta-learning, which optimizes the convergence of the subsequent fine-tuning in personalization, resulting in higher performance of personalized FEEL.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\textwidth]{figure/PFLe2.pdf}
    \caption{Performance of FEEL and personalized FEEL for DL-based CSI feedback with different numbers of local training epochs. The compression ratio, number of UEs, and samples per UE are set to 1/16, 50, and 5,000, respectively.}
    \label{fig:feele}
\end{figure}

\section{Conclusion}
This work proposes a novel communication-efficient personalized FEEL-based training framework that introduces a new efficient training paradigm for the classic DL-based CSI feedback algorithm. The proposed method offers a significant advantage as the autoencoder network can achieve high performance while maintaining moderate generalization. Firstly, a FEEL-based training framework is proposed to protect the privacy of UEs. Secondly, a neural network quantization method is introduced to reduce the communication overhead in FEEL. Lastly, a personalization strategy is proposed to enhance feedback performance. The performance of the aforementioned methods is tested using channel datasets generated by QuaDRiGa. The results demonstrate that the proposed methods can improve feedback performance while maintaining moderate generalization capability with high communication efficiency. The performance is higher when UEs remain in a more static environment and can be further improved with more samples per UE and local epochs. 


\bibliographystyle{IEEEtran}
\bibliography{refer1}

\end{document}
