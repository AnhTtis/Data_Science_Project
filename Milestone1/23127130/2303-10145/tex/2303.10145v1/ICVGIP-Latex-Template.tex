 \documentclass[sigconf]{acmart}
%Do not remove the review=true option for papers submitted for review to ICVGIP2021.
\usepackage{algorithm}% http://ctan.org/pkg/algorithms
\usepackage{algorithmic}

\usepackage{multirow}
\usepackage{subcaption}
\usepackage{xcolor}

\setcopyright{rightsretained}


% DOI  - Required only for Camera Ready  
\acmDOI{10.1145/3571600.3571634}
\acmArticle{34}
\copyrightyear{2022}
\acmYear{2022}
\setcopyright{acmcopyright}\acmConference[ICVGIP'22]{Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing}{December 8--10, 2022}{Gandhinagar, India}
\acmBooktitle{Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing (ICVGIP'22), December 8--10, 2022, Gandhinagar, India}
\acmPrice{15.00}
\acmDOI{10.1145/3571600.3571634}
\acmISBN{978-1-4503-9822-0/22/12}



\begin{document}

\title{Spectrum-inspired Low-light Image Translation for Saliency Detection}


\author{Kitty Varghese$^{1}$, Sudarshan Rajagopalan$^{2}$, Mohit Lamba$^{1}$, Kaushik Mitra$^1$}
\def \authors{Kitty Varghese, Sudarshan Rajagopalan, Mohit Lamba, Kaushik Mitra }
\affiliation{%
\institution{$^1$ Indian Institute of Technology, Madras
\country{India}}
}
\affiliation{%
  \institution{$^2$Madras Institute of Technology
  \country{India}}
}

\renewcommand{\shortauthors}{}


\begin{abstract}
Saliency detection methods are central to several real-world applications such as robot navigation and satellite imagery. 
However, the performance of existing methods deteriorate under low-light conditions because training datasets mostly comprise of well-lit images. 
 One possible solution is to collect a new dataset for low-light conditions. This involves pixel-level annotations, which is not only tedious and time-consuming but also infeasible if a huge training corpus is required. 
We propose a technique that performs classical band-pass filtering in the Fourier space
to transform well-lit images to low-light images and
use them as a proxy for real low-light images.
Unlike popular deep learning approaches which require learning thousands of parameters and enormous amounts of training data, the proposed transformation is fast and simple and easy to extend to other tasks such as low-light depth estimation.

Our experiments show that the state-of-the-art saliency detection and depth estimation networks trained on our proxy low-light images perform significantly better on real low-light images than networks trained using
existing strategies. 
\end{abstract}


\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10010147.10010178.10010224.10010245.10010246</concept_id>
       <concept_desc>Computing methodologies~Interest point and salient region detections</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Interest point and salient region detections}


\ccsdesc[500]{Computing methodologies~Interest point and salient region detections}

\keywords{Low-light and salient object detection}
\maketitle
\input{samplebody-conf}
\bibliographystyle{ACM-Reference-Format}
\bibliography{book1}




\end{document}
