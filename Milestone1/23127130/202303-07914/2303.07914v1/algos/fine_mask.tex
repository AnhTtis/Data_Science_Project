\begin{algorithm}[t]
\caption{Pseudocode of FAI strategy strategy in a PyTorch-like style.}
\label{algo:mask}
\definecolor{codeblue}{rgb}{0.25,0.5,0.5}
\lstset{
  backgroundcolor=\color{white},
  basicstyle=\fontsize{7.2pt}{7.2pt}\ttfamily\selectfont,
  columns=fullflexible,
  breaklines=true,
  captionpos=b,
  commentstyle=\fontsize{7.2pt}{7.2pt}\color{codeblue},
  keywordstyle=\fontsize{7.2pt}{7.2pt},
  escapeinside=``,
}
\begin{lstlisting}[language=python]
# model: an offline-trained ST model consists of a acoustic encoder Wav2vec2.0, a token boundary detector, a semantic encoder, and a decoder
# m: mask length, K: wait lagging, audio: audio waveform
# mask_emb: pre-trained mask embedding in Wav2vec 

N = 0   # the number of source text tokens
x = []  # streaming audio prefix
y = []  # translations
mask_embs = mask_emb.repate(m, 1)  # mask embeddings: `\fontsize{6.8pt}{6.8pt}\color{codeblue}{$m \times d$}`
while y[-1] != "<eos>":
    if x == audio:  # audio has been read
        y = y + model(a,y)  # write new target token
    elif N - len(y) < K:  # wait K detected source tokens
        x = x + read(audio)  # incrementally read audio 
        c = model.wav2vec2.cnn(x)  # audio tokens `\fontsize{6.8pt}{6.8pt}\color{codeblue}{$\tau\times d$}`
        
        c = torch.cat((c, mask_embs), dim=0) # concatenate audio tokens and mask embeddings, `\fontsize{6.8pt}{6.8pt}\color{codeblue}{$(\tau+m)\times d$}`
        a = model.wav2vec2.encoder(c)  # audio representations, `\fontsize{6.8pt}{6.8pt}\color{codeblue}{$(\tau+m)\times d$}`
        a = a[:a.shape[0] - m,:]  # discard the predicted representations, `\fontsize{6.8pt}{6.8pt}\color{codeblue}{$\tau \times d$}`
        
        if model.token_detector(a):  # source text token boundary is detected
            N += 1
    else:
        h = model.semantic_encoder(a)
        y = y + model.decoder(h, y)  # write new target token
\end{lstlisting}
\end{algorithm}
