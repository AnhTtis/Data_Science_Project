\section{Conclusion}


{%
We have presented a novel method to learn a disentangled 3D generative model for faces that allows the user to control the camera pose and the illumination, with only single views, and without the need of any manual annotation.
Our core idea is how we model {physics-based} rendering with a simplified Phong model, that integrates effectively to neural volume rendering. 
We demonstrate the effectiveness of our method on FFHQ, CelebA-HQ, and MetFaces dataset, providing photorealistic image quality.
}%

\paragraph{Limitations and future work.}
{Our method does not model all the physical aspects of the scene and rendering process.
Our setup is unsupervised, learned without any explicit control of the environment during the capture.
While this problem setup is difficult, we are capable of generating photorealistic faces under various diffuse/specular lighting.
The quality of the method may be further improved by modeling global illumination or subsurface scattering. 
For further improved factorization/specular quality, we may need higher frequency environment maps~\cite{han2007frequency} that are difficult to obtain in an unsupervised setting where manual annotation or specially designed capture setup would help.}
Further, our method uses estimation of illumination parameters and camera pose from existing methods~\cite{feng2021deca}.
As such, the accuracy of our method is limited by the performance of existing work. 
In \Figure{ffhq_samples}, it can be seen that the estimated illumination can sometimes be entangled with skin color, which is a limitation that we inherit from DECA~\cite{feng2021deca}.

\paragraph{Ethical Considerations.} We intend our work to be used for research purposes only and should not be used edit images of real people without their consent. The use of our method for developing applications should carefully consider privacy of the faces, as well as, bias present in the datasets.
