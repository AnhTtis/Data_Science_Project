\documentclass[9pt,a4paper]{article}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[english]{babel}
\usepackage[normalem]{ulem}
\usepackage{dsfont}

%\usepackage[dvipsnames]{xcolor}

\setlength\parindent{0pt} % noindent for whole document

\usepackage{amsmath,amsfonts,amssymb, amsthm} % beautiful math
\theoremstyle{plain}
\newtheorem{definition}{Definition}
%\newtheorem*{proof}{Proof}
\newtheorem{assumption}{Assumption}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{conjecture}{Conjecture}



%contribution box
\newcommand{\mybox}[4]{
    \begin{figure}[h]
        \centering
    \begin{tikzpicture}
        \node[anchor=text,text width=\columnwidth-1.2cm, draw, rounded corners, line width=1pt, fill=#3, inner sep=5mm] (big) {\\#4};
        \node[draw, rounded corners, line width=.5pt, fill=#2, anchor=west, xshift=5mm] (small) at (big.north west) {#1};
    \end{tikzpicture}
    \end{figure}
}

	
\usepackage{pdflscape} % landscape

\usepackage[%
    font={small,sf},
    labelfont=bf,
    format=hang,    
    format=plain,
    margin=0pt,
]{caption}

\usepackage{wrapfig}
\usepackage{subcaption}
\usepackage{bbm} % indicatrix
\usepackage[table,xcdraw, dvipsnames]{xcolor}

\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
 }
 
 % Fancy boxes 
 \usepackage[framemethod=TikZ]{mdframed}
\newcounter{takeaway}[section]\setcounter{takeaway}{0}
\renewcommand{\thetakeaway}{\arabic{section}.\arabic{takeaway}}
\newenvironment{takeaway}[2][]{%
    \refstepcounter{takeaway}
 
    % Code for box design goes here.
 
\begin{mdframed}[]\relax}{%
\end{mdframed}}
\ifstrempty{#1}%
% if condition (without title)
{\mdfsetup{%
    frametitle={%
        \tikz[baseline=(current bounding box.east),outer sep=0pt]
        \node[anchor=east,rectangle,fill=blue!20]
        {\strut Takeaways};}
    }%
% else condition (with title)
}{\mdfsetup{%
    frametitle={%
        \tikz[baseline=(current bounding box.east),outer sep=0pt]
        \node[anchor=east,rectangle,fill=blue!20]
        {\strut Takeaways};}%
    }%
}%
% Both conditions
\mdfsetup{%
    innertopmargin=10pt,linecolor=blue!20,%
    linewidth=2pt,topline=true,%
    frametitleaboveskip=\dimexpr-\ht\strutbox\relax%
}

 % Fancy boxes ENDS



\usepackage[list=true]{subcaption}


% TODO commands
\usepackage{snaptodo}
\setlength{\marginparwidth}{2cm}
\setlength{\marginparsep}{.02cm}
\snaptodoset{block rise=2em}
\snaptodoset{margin block/.style={font=\tiny}}

\newcommand{\gv}[1]{\snaptodo[margin block/.append style=green!50!black]{\sloppy\textbf{GV}: #1}}
\newcommand{\jj}[1]{\snaptodo[margin block/.append style=orange]{\sloppy\textbf{JJ}: #1}}
\newcommand{\bc}[1]{\snaptodo[margin block/.append style=yellow!50!black]{\sloppy\textbf{BC}: #1}}
\newcommand{\es}[1]{\snaptodo[margin block/.append style=magenta]{\sloppy\textbf{ES}: #1}}

% Uncomment below to erase all comments
%\renewcommand{\snaptodo}[2][1]{\relax}

%\usepackage[colorinlistoftodos,textwidth=2.1cm]{todonotes}
%\newcommand{\jj}[1]{\todo[color=orange, size=\tiny]{JJ: #1}}
%\newcommand{\bc}[1]{\todo[color=yellow, size=\tiny]{BC: #1}}
%\newcommand{\gv}[1]{\todo[color=green, size=\tiny]{GV: #1}}
%\newcommand{\es}[1]{\todo[color=magenta, size=\tiny]{ES: #1}}

\newcommand{\indep}{\perp \!\!\! \perp}

\usepackage{comment}

\usepackage{natbib}
\usepackage{here}

\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}







%%%%%%% for fancy formula


\usepackage{tikz}
\usetikzlibrary{backgrounds}
\usetikzlibrary{arrows,shapes}
\usetikzlibrary{tikzmark}
\usetikzlibrary{calc}


\usepackage{amssymb}
\usepackage{mathtools, nccmath}

% for custom commands
\usepackage{xspace}

% table alignment
\usepackage{array}
\usepackage{ragged2e}
\newcolumntype{P}[1]{>{\RaggedRight\hspace{0pt}}p{#1}}
\newcolumntype{X}[1]{>{\RaggedRight\hspace*{0pt}}p{#1}}

% color box
\usepackage{tcolorbox}


% for tikz
%\usetikzlibrary{trees}
\usetikzlibrary{arrows,shapes,positioning,shadows,trees,mindmap}
% \usepackage{forest}
\usepackage[edges]{forest}
\usetikzlibrary{arrows.meta}
\colorlet{linecol}{black!75}
\usepackage{xkcdcolors} % xkcd colors


% for colorful equation
\usepackage{tikz}
\usetikzlibrary{backgrounds}
\usetikzlibrary{arrows,shapes}
\usetikzlibrary{tikzmark}
\usetikzlibrary{calc}
% Commands for Highlighting text -- non tikz method
\newcommand{\highlight}[2]{\colorbox{#1!17}{$\displaystyle #2$}}
%\newcommand{\highlight}[2]{\colorbox{#1!17}{$#2$}}
\newcommand{\highlightdark}[2]{\colorbox{#1!47}{$\displaystyle #2$}}

% my custom colors for shading
\colorlet{mhpurple}{Plum!80}


% Commands for Highlighting text -- non tikz method
\renewcommand{\highlight}[2]{\colorbox{#1!17}{#2}}
\renewcommand{\highlightdark}[2]{\colorbox{#1!47}{#2}}
\renewcommand{\eqref}[1]{eq.\,\ref{#1}}

\title{Risk ratio, odds ratio, risk difference...  Which causal measure is easier to generalize?} %What are the safest causal effect metrics to use when trial and target population differs?
\author{B\'{e}n\'{e}dicte Colnet \thanks{Soda project-team,  Premedical project-team, INRIA (email: benedicte.colnet@inria.fr).}
  \and
Julie Josse\thanks{Premedical project team, INRIA Sophia-Antipolis, Montpellier, France.}
  \and
Ga\"{e}l Varoquaux\thanks{Soda project-team, INRIA Saclay, France.}
     \and 
Erwan Scornet \thanks{Centre de Math\'{e}mathiques Appliqu\'{e}es, UMR 7641, \'{E}cole polytechnique, CNRS, Institut Polytechnique de Paris, Palaiseau, France (email: erwan.scornet@polytechnique.edu).}
}



\date{\today}


\begin{document}

\maketitle
%\gv{Proposition de titre: "Summary measures of causal effects are not equal when facing population shifts", pour éviter le mot "metrics" qui a beaucoup de sens différents. Ou, pour un titre plus different "Causal effects with population shifts: summary measures are not equal", "Risk ratio, odds ratio, risk difference... Which summary measures of causal effects when facing population shifts?" pour un titre plus catchy, voir même "Risk ratio, odds ratio, risk difference... Which summary measures of causal effects for generalization?"}

\begin{abstract}
    There are many measures to report so-called treatment or causal effect: absolute difference, ratio, odds ratio, number needed to treat, and so on. The choice of a measure, \emph{eg} absolute versus relative, is often debated because it leads to different appreciations of the same phenomenon; but it also implies different heterogeneity of treatment effect. In addition some measures -- but not all -- have appealing properties such as collapsibility, matching the intuition of a population summary. We review common measures and their pros and cons typically brought forward. Doing so, we clarify notions of collapsibility and treatment effect heterogeneity, unifying different existing definitions. Our main contribution is to propose to reverse the thinking: rather than starting from the measure, we start from a non-parametric generative model of the outcome. 
    Depending on the nature of the outcome, some causal measures disentangle treatment modulations from baseline risk.
    Therefore, our analysis outlines an understanding of what heterogeneity and homogeneity of treatment effect mean, not through the lens of the measure, but through the lens of the covariates. Our goal is the generalization of causal measures. 
    We show that different sets of covariates are needed to generalize an effect to a different target population depending on \textit{(i)} the causal measure of interest,
\textit{(ii)} the nature of the outcome, and \textit{(iii)} the generalization's method itself (generalizing either conditional outcome or local effects).
%We show that some measures require less covariates for adjustment. %We provide all generalization identification formulae.
    %Our results are general as they build on non-parametric models.

       \vspace{12pt}
\textit{Keywords:} Standardization;  
Transportability; 
Collapsibility; 
Treatment effect modifier; 
Clinical trials.
\end{abstract}

%\tableofcontents

\section{The age-old question of how to report effects}


From the physician to the patient, the term \textit{effect} of a drug on an outcome usually appears very spontaneously, within a casual discussion or in scientific documents. % Désolée j'inaiste sur cette premiere phrase :)
Overall, everyone agrees that an effect is a comparison between two states: treated or not.
But there are various ways to report the main effect of a treatment.
%But, when looking for more details, and in particular at the quantitative ways of defining a so-called treatment effect, this notion is far from being a universal concept.
%Leaving aside the analysis of side effects, the main effect of a treatment can take several quantitative definitions, and as a consequence can be reported differently depending on the context or habits.
For example, the scale may be absolute (e.g. the number of migraine days per month is expected to diminishes by 0.8 taking Rimegepant \citep{Edvinsson2021Migraine}) or relative (e.g. the probability of having a thrombosis is expected to be multiplied by 3.8 when taking oral contraceptives \citep{Vandenbroucke1994thrombosis}).
Choosing one measure or the other has several consequences. 
First, it conveys a different impression of the same data to an external reader \citep{Forrow1992HowResultsAreSummarized, Cook2014UserGuide, xiao2022IsORPortable}. Such subjective impression may be even more prominent in newspapers, where most effects are presented in relative rather than absolute terms, creating a heightened sense of sensationalism \citep{moynihan2000coverage}. 
Second, the treatment effect heterogeneity -- i.e. different effects on sub-populations -- depends on the chosen measure \citep[see p.199]{Rothman2011bookEpidemiologyIntrod}. %\jj{reference oun phrase en dessous que je garderais, ou mettre voir annexe ou section }\bc{Aie je ne comprends pas la question ?}
%For instance, an effect presented as the absolute difference can be varying on two subgroups, while the ratio is not (as illustrated in Figure~\ref{fig:toyexamplesummary}).
%\gv{Referencer l'appendice aussi tôt dans l'introduction n'est pas très élègant. Une version super simple de cette figure ici?}.
The choice of the measure to report an effect is still actively discussed \citep{Spiegelman2017Modeling, Spiegelman2017letSubject, baker2018new, Changyong2019RelationsAmongThreePop, Doi2020callToChangePractice, doi2022TimeToDoAway, xiao2021odds, xiao2022IsORPortable, Huitfeldt2021ShallWe,Lapointe2022FromMathToMeaning, liu2022rejoinder}. 
Publications on the topic come with many diverging opinions and guidelines (see Appendix~\ref{appendix:different-point-of-views} for quotes).
And yet the question of the measure (or metric) of interest is not new; \cite{Sheps1958ShallWe} was already raising it in the \textit{New England Journal of Medicine} (see also \cite{Huitfeldt2021ShallWe}):
\begin{quote}
    `` We wish to decide whether we shall count the failures or the successes and whether we shall make relative or absolute comparisons " --
\end{quote}
%Note that this quote from Mindel C. Sheps does not only highlight the importance of the chosen measure, but also how we encode the outcome for binary outcomes of interest\footnote{We detail in this work how the choice of encoding can be seen as choosing one of the possible relative measures.}.
% \begin{wrapfigure}{r}{0.32\textwidth}
%  \begin{center}
%    \includegraphics[width=0.32\textwidth]{fig/toyexamplesummary.png}
%  \end{center}
%  \caption{Sub-groups' effects can vary or not depending on the chosen scale.}
%  \label{fig:toyexamplesummary}
%\end{wrapfigure} 
Beyond impression conveyed and heterogeneity captured, different causal measures lead to different generalizability towards populations \citep{huitfeldt2018choice}.
The problem of generalizability (or portability) encompasses a range of different scenarii, and refers to the ability of findings to be carried over to a broader population beyond the study sample. 

%It can also encompass issues related to the transferability of results from one research domain to another, or from research settings to real-world clinical practice. 
Generalizability of trials' findings is crucial as most often clinicians use causal effects from published trials \textit{(i)} to estimate the expected response to treatment for a specific patient based on his/her baseline risks, and \textit{(ii)} therefore to choose the best treatment. 
In this work we show that some effect measures are less sensitive than others to population's shift between the study sample and the target population.\\


Section~\ref{sec:formalization-and-key-contributions} starts with a didactic clinical example to introduces the question, the notation, and our main results. Reading it suffices for an executive summary of the paper.
%This part can be read as a whole to grasp the key results. 
For the mathematical underpinnings, each of the following sections (Section \ref{section:causal-metrics-properties}-\ref{sec:generalization}) is dedicated to one of the three contributions exposed in  %intermediate steps backing the main results exposed in
Section~\ref{sec:formalization-and-key-contributions}.
%, each section being linked to one contribution.
Section~\ref{section:causal-metrics-properties} first clarifies and discusses typical properties of causal measures such as treatment effect homogeneity, heterogeneity, and collapsibility and then explicitly links collapsibility with generalizability (\textit{i.e.} re-weighting of local effects to get the population effect).
%In this section we both clarify and enrich the different definitions available in the literature. 
%Doing so, Section~\ref{section:causal-metrics-properties} adopts the general approach taken in the literature while completing it.  
%Our findings are allowed thanks to 
In Section~\ref{section:generative-models}, we reverse the thinking; we propose to start from a non-parametric generative model of the outcome, and then observe what each measure captures. This approach leads to a new view on treatment effect heterogeneity: accounting for covariates that may act as treatment effect modulators, as opposed to those that only affect baseline levels.
%This enables another definition of heterogeneity, and in particular a new definition of heterogeneity. 
%Primarily, we show how the non-parametric generative models introduced help to have another definition of the heterogeneity of a treatment effect (some covariates acting only on the baseline level while others being also treatment effect modulators). 
%Our primary aim is to demonstrate how non-parametric generative models can provide an alternative approach to defining treatment effect heterogeneity. 
Section~\ref{sec:generalization} presents the consequences on the generalizability of a causal measure. 
We show that some measures are easier to generalize, in the sense that they require adjustment only on the treatment effect modulators introduced in Section~\ref{section:generative-models}, and not on all shifted prognostic covariates. 
%There is exactly one measure per situation: nature of the outcome and direction of the effect. 
Section~\ref{sec:simulations} illustrates the takeaways through simulations. %These simulations are inspired from a major public health issue: the effect of oral contraceptives and thrombosis.
% ask for less covariates.\bc{Julie dit "	in particular showing which variables are required for each measure to be generalisable by standardization? "} %required for each measure to be generalisable by standardization, while using properties detailed in Section~\ref{section:causal-metrics-properties}, and in particular collapsibility. %We show how this new definition of hetereogeneity can lead to the universal generalizability of one of the causal metric for each outcome. We also show how some metrics are easier to generalize to other population, in the sense that they require less covariate to generalize well.
%\jj{je pense qu'on aurait envie d'être plus précis ici pour donner envie au lecteur du genre risk difference generalise bien, ou quelque chose comme ça}\bc{Ce serait en partie 2, ça irait?}

%\tableofcontents





\section{Problem setting and key results}\label{sec:formalization-and-key-contributions}


\subsection{Causal effects in the potential outcomes framework}

%The current standard to report causal effect of a policy or treatment on a certain outcome can be denoted within the so-called potential outcome framework. 
We use the \emph{potential outcome} framework to characterize treatment (or causal) effects.
This framework has been proposed by Neyman in 1923 \citep[English translation in][]{SplawaNeyman1990Translation}, and popularized by Donald Rubin in the 70's \citep{imbens2015causal, hernan2020whatifbook}.
It formalizes the concept of an intervention by studying two possible values $Y^{(1)}_i$ and $Y^{(0)}_i$ for the outcome of interest (say the pain level of headache) for the two different situations where the individual $i$ has been exposed to the treatment ($A_i = 1$) or not ($A_i=0$) --we will only consider binary exposure.
The treatment has a causal effect if the potential outcomes are different, that is testing the assumption:
%
\begin{equation}
\label{eq:is_equal_indivi_treat_effect}
Y^{(1)}_i \stackrel{?}{=} Y^{(0)}_i.   
\end{equation}
Unfortunately, one cannot observe the two worlds for a single individual. Statistically, it can still be possible to compare the \emph{expected} values of each potential outcome $Y^{(a)}$ but it requires a population-level approach, broadening from a specific individual.
The paradigmatic example is a randomized experiment (called Randomized Controlled Trial --RCT-- in clinical research or A/B test in marketing): randomly assigning the treatment to half of the individuals enables the average comparison of the two situations.
Doing so, the previous question of interest amounts to \textit{comparing} or \textit{contrasting} two expectations:
%
\begin{equation}
\label{eq:is_equal_potential_expectation}
%Y^{(1)}_i \stackrel{?}{=} Y^{(0)}_i \quad 	\longrightarrow  \quad 
\mathbb{E}\left[Y^{(1)}\right] \stackrel{?}{=} \mathbb{E}\left[Y^{(0)}\right],
\end{equation}
%
where $\mathbb{E}[Y^{(a)}]$ is the expected counterfactual outcome had all individuals in the \textit{population} received the treatment level $a$. 
This quantity is defined with respect to a population: statistically the expectation is taken on a distribution, which we denote $P_{\text{\tiny S}}$ (reflecting the \textbf{s}ource or \textbf{s}tudy sample from which evidence comes from, for example a RCT). Many methodological efforts have focused on estimating the two expectations (namely $\hat{\mathbb{E}}\left[Y^{(1)}\right]$ and $\hat{\mathbb{E}}\left[Y^{(0)}\right]$). Our focus is different: we propose theoretical guidance for choosing among different measures 
to \textit{compare} those two expectations at the population level, e.g. ratio, difference, or odds. What are the properties of these measures? 
How do they impact the conclusions of a study?
%\jj{je dirais we do not focus on estimation moi je dirais même si on dit un mot à la fin car trop important pour ne pas en parler du tout}

%as if we had access to the true expectations (i.e. having access to an very large randomized controlled trial). 
%\es{pas clair clair, redire qu'on cherche à évaluer l'impact des différentes mesures}\bc{est-ce mieux?}

%\jj{section 2.1 pourrait être raccourcie mais c'est un détail}\bc{je suis d'accord. mais il me semble que pour des médecins c'est pas une section évidente. Or je suis restée dans l'optique qu'on vise un stat in medecine ou assimilé... Je me dis que cette demi page est le minimum pour mettre à bord une personne qui connait pas les PO, et que plus court on rate tout ce public. Qu'en penses tu ? }
\subsection{Comparing two averaged situations: different treatment effect measures}\label{subsec:causal-measures-presentation}

%To quantify how different the expected potential outcomes values from \eqref{eq:is_equal_potential_expectation} are, one can find several practices.
We focus on two types of outcomes: continuous  (e.g. headache pain level) and binary (e.g. death). 
%Usually within the medical field an event such as death is usually encoded $Y=1$ (and $Y=0$ for no event). 
%Later in the paper we will explain why encoding has an importance.
Binary outcomes are frequent in medical questions, often related to the occurrence of an event.
%Binary outcomes are often encountered within the medical domain, as they are well-suited to describe outcome such as remission or death. 
%Note that such outcome is always defined with respect to a duration, for example the death within 28 days, of the remission within 6 months \citep{Greenland1987Interpretation, Rothman2000ModernEpidemiology}. 
%\es{Considering directly the time of survival as the outcome of interest requires resorting to survival analysis, which is beyond the scope of this work. } 
%Considering directly the time of survival as the outcome of interest requires resorting to survival analysis, which is beyond the scope of this work.
%Willing to remove the time period into the binary outcome leads to a different notation and concept usually called survival. This work does not consider such outcomes. 

\paragraph{Continuous outcome}
 For continuous outcomes,  a common measure is the absolute difference (usually referred to as the Risk Difference - RD): 
\begin{equation*}
    \tau_{\text{\tiny RD}} := \mathbb{E}\left[Y^{(1)}\right] -  \mathbb{E}\left[Y^{(0)}\right].
\end{equation*}
A null effect corresponds to $\tau_{\text{\tiny RD}}=0$. If the outcomes are of constant sign and different from $0$ one can also consider relative measures\footnote{Allowing situations where the outcomes can be null or change sign is at risk of having undefined ratio due to $\mathbb{E}\left[Y^{(0)}\right]=0$. This is why, when considering relative measure we assume that the continuous outcome is of constant sign. Note that this is often the case in medicine. For example with blood glucose level, systolic blood pressure, etc.} such as the ratio (Risk Ratio - RR), or the (Excess Risk Ratio - ERR):
\begin{equation*}
   \tau_{\text{\tiny RR}} :=  \frac{\mathbb{E}\left[Y^{(1)}\right]}{\mathbb{E}\left[Y^{(0)}\right]}, \quad\qquad  \tau_{\text{\tiny ERR}} :=  \frac{\mathbb{E}\left[Y^{(1)}\right]-\mathbb{E}\left[Y^{(0)}\right]}{\mathbb{E}\left[Y^{(0)}\right]} = \tau_{\text{\tiny RR}} -1.
\end{equation*}
A null effect now corresponds to $\tau_{\text{\tiny RR}} =1$ or $\tau_{\text{\tiny ERR}}=0$. 
Note that the ranges of the three metrics are very different, for e.g. if $\mathbb{E}\left[Y^{(1)}\right] =200$ and $\mathbb{E}\left[Y^{(0)}\right]  = 100$. Then $ \tau_{\text{\tiny RD}} = 100$, while $ \tau_{\text{\tiny RR}} = 2$ and $ \tau_{\text{\tiny ERR}} = 1$. %In particular $\tau_{\text{\tiny RR}}$ and $\tau_{\text{\tiny ERR}}$ are dimensionless quantities. Also note that the relatives measures  $\tau_{\text{\tiny RR}}$ and $\tau_{\text{\tiny ERR}}$ make more sens if the outcome

\paragraph{Binary outcome}
Due to the binary nature of the outcome, the two expectations of \eqref{eq:is_equal_potential_expectation} can now also be understood as the probability of the event to occur, $\mathbb{P}\left[Y^{(a)} = 1\right] = \mathbb{E}\left[Y^{(a)}\right]$, and as a consequence $\mathbb{P}\left[Y^{(a)} = 0\right] = 1-\mathbb{E}\left[Y^{(a)}\right]$.
As long as the phenomenon is non-deterministic (i.e. $1 > \mathbb{P}\left[Y^{(a)} = 1\right] > 0$), previous relative measures $\tau_{\text{\tiny RR}}$ and $\tau_{\text{\tiny ERR}}$ can also be used with binary outcomes. 
But others measures exist when the outcome is binary. For example the Risk Ratio (RR) can be \textit{reversed}, rather counting the null events. It is called the Survival Ratio (SR). 
The Odds Ratio (OR) is another very common measure, in particular as it serves as a link between follow-up studies and case-control studies \citep{Greenland1987Interpretation, king2002estimating}.
Another measure called the Number Needed to Treat (NNT) has been proposed more recently \citep{Laupacis1988AnAssessmentOfClinically}; it helps the interpretation of the Risk Difference by counting how many individuals should be treated to observe one individual answering positively to treatment. Depending on the direction of the effect, NNT can also be called Number Needed to Harm (NNH) when the events are side effects or Number of Prevented Events (NPE) when it comes to prevention. For simplicity of the exposition, in this work we only consider NNT. The exact expression of the above measures are given here:  
\begin{equation*}
   \tau_{\text{\tiny SR}} :=  \frac{\mathbb{P}\left[Y^{(1)} = 0\right]}{\mathbb{P}\left[Y^{(0)} = 0\right]}, \qquad \tau_{\text{\tiny OR}}  := \frac{\mathbb{P}[Y^{(1)} = 1]}{\mathbb{P}[Y^{(1)} = 0]}\, \left(  \frac{\mathbb{P}[Y^{(0)} = 1]}{\mathbb{P}[Y^{(0)} = 0]}\right)^{-1}, \qquad \tau_{\text{\tiny NNT}}  := \tau_{\text{\tiny RD}}^{-1}.
\end{equation*}
Other measures can be found in the literature, such as the log Odds Ratio (log-OR). We recall each measure in Appendix~\ref{appendix:list-of-measures} where Figure~\ref{fig:big-plot-with-all-metrics} illustrates the differences between measures, for different values of the expected outcomes of controls and treated. We also compute all these measures on a clinical example in Section~\ref{subsec:illustrative-example-and-key-results}.
%\jj{dire qu'en dessous tu as un exemple où tu calcules pour un même cas toutes ces mesures?}
\paragraph{Treatment effects on subgroups}
%For now, we proposed marginal effect, that is effect at the population level.
Treatment effects can also be reported within subgroups of a population (i.e. stratified risks) to show how sub-populations react to the treatment. 
Therefore, one could also define each of the previously introduced measures on sub-populations.
For the rest of the work, we denote $X$ a set of baseline covariates\footnote{Those covariates are baseline or pre-treatment covariates. See \cite{VanderWeele2007FourTypes} for a detailed explanation.}. We denote $\tau(x)$ the treatment effect on the subpopulation $X=x$ for any causal measure. 
For example $\tau_{\text{\tiny RD}}(x)$ denotes the Risk Difference on the subgroup for which $X=x$. This quantity is often referred to as the Conditional Average Treatment Effect (CATE). %\bc{Julie, mis ici}
%Most of the time, the consideration of heterogeneity in applied clinical work is made ``\textit{one-variable-at-a-time}", for e.g. for male and female (in such a situation, $X$ is univariate and binary), even if some literature propose to change this practice to observe hetereogeneity along several covariates at a time \citep{Kent2019PATH1}. 

\subsection{Key messages: from effect measures to generalization}\label{subsec:illustrative-example-and-key-results}
\subsubsection{An illustrative example}
We consider clinical data assessing the benefit of antihyperintensive therapy ($A$) against stroke ($Y$) \citep{macmahon1990blood, Cook1995NNT}. We denote $Y=1$ a stroke, and $Y=0$ no stroke. Individuals can be categorized into two groups depending on their diastolic blood pressure: either moderate ($X=0$) or mild ($X=1$). Moderate patients have a higher baseline risk of stroke than mild patients, which corresponds to $\mathbb{P}\left[ Y^{(0)} = 1 \mid X =0\right]\ge\mathbb{P}\left[ Y^{(0)} =1\mid X =1\right]$. In particular in this example, $X=0$ (resp. $X=1$) corresponds to a baseline risks of 2 events for 10 individuals (resp. 15  events for 1,000 individuals). All the measures previously introduced are computed from values reported in the original articles and presented in Table~\ref{tab:introduction-diastolic}.\\

%$\mathbb{P}\left[Y^{(0)} \mid X =0 \right] = 0.2$, $\mathbb{P}\left[Y^{(1)} \mid X =0 \right] = 0.12$, $\mathbb{P}\left[Y^{(0)} \mid X = 1 \right] = 0.015$, $\mathbb{P}\left[Y^{(1)} \mid X =1 \right] = 0.009$$
\begin{figure}[!h]
	\begin{minipage}{.50\linewidth}
     \captionof{table}{\textbf{Different treatment measure give different impressions of the phenomenon}: The outcome is stroke in 5 years ($Y=1$ denoting stroke and $Y=0$ no stroke) and stratification is done along a binary covariate $X$ (moderate $X=0$ or mild $X=1$). Each measure are computed from aggregated data taken from \cite{macmahon1990blood, Cook1995NNT}. No confidence intervals are represented as our focus is the interpretation of the measure and not statistical significance.}
      \label{tab:introduction-diastolic}
    \end{minipage}
    \hspace{0.5cm}
    \begin{minipage}{.45\linewidth}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
      & $\tau_{\text{\tiny RD}}$ & $\tau_{\text{\tiny RR}}$ &  $\tau_{\text{\tiny SR}}$ &  $\tau_{\text{\tiny NNT}}$ & $\tau_{\text{\tiny OR}}$ \\ \hline \hline
\cellcolor[HTML]{CBCEFB}\textbf{All ($P_\text{\tiny S}$)} &   $-0.0452$ &   \textbf{0.6} &  $1.05$  &  $22$   &  $0.57$  \\ \hline \hline
\cellcolor[HTML]{ECF4FF}\textbf{X = 1} &   $-0.006$ &   \textbf{0.6} &  $1.01$  &  $167$   &  $0.6$  \\ \hline 
\cellcolor[HTML]{ECF4FF}\textbf{X = 0} &  $-0.08$  &  \textbf{0.6}  &  $1.1$  &  $13$   &  $0.545$ \\ \hline 
\end{tabular}
\end{center}
	\end{minipage}
\end{figure}
A risk ratio below 1 means there is an inverse association: is a decreased risk of stroke in the treated group compared with the treated group. 
More precisely, the treated group has 0.6 times the risk of having a stroke outcome when compared with the non-treated group.
On this example, one can also recover that the Odds Ratio approximates the Risk Ratio in a stratum where prevalence of the outcome is low ($X=1$), but not if the prevalence is higher ($X=0$) (derivations recalled in Appendix~\ref{appendix:list-of-measures}).
The survival ratio of 1.05 captures that there is an increased chance of not having a stroke when treated compared to the control by a factor 1.05.
Note that the Survival Ratio takes really different values than the Risk Ratio: it corresponds to the Risk Ratio where labels $Y$ are swapped for occurrences and non-occurrences, illustrating that Risk Ratio is not symmetric to the choice of outcome 0 and 1 --e.g. counting the living or the dead \citep{Sheps1958ShallWe}. This lack of symmetry is usually considered as a drawback of the survival ratio and risk ratio compared to the odds ratio. Indeed, the odds ratio is robust to a change of labels: swapping labels leads to changing the odds ratio $\tau_{\text{\tiny OR}}$ by its inverse $\tau_{\text{\tiny OR}}^{-1}$ (see Appendix~\ref{appendix:list-of-measures}). There is no such formula to understand the effect of a change of labels on the risk ratio or the survival ratio.

Finally, the Risk Difference translates the effect on a absolute scale: treatment reduces by $0.045$ the probability to suffer from a stroke when treated\footnote{When it comes to binary outcomes, such absolute effects are rather presented as reducing by 45 events over $1,000$ individuals.}.
The NNT is the number of patients you need to treat to prevent one additional bad outcome. Here the NNT is of 22, meaning that one has to treat 22 people with the drug to prevent one additional stroke.
The Number Needed to Treat represents the same Risk Difference on a way bigger amplitude than the Risk Difference, especially when looking at the effect on subgroups.
This is one of the interest of the NNT, making the measure more explicit than a difference of probabilities. %\jj{Je ferais des phrases avec les chiffres pour expliquer comment tu les lis, hyper important je pense}
%Both RD and NNT are highly dependent on the baseline, but not if the prevalence is getting higher ($X=0$). Finally, note that the Survival Ratio takes really different values than the Risk Ratio. As the Survival Ratio corresponds to the Risk Ratio where labels $Y$ are swapped for occurrences and non-occurrences, this illustrates the non-symmetry of the Risk Ratio. The Odds Ratio or the Risk Difference does not suffer from non-symmetry usually presented as an important drawback by practioners. 

\subsubsection{Contributions: considerations to choose an effect measure}
\paragraph{Contribution 1: A collapsible measure is needed to generalize local effects [Section~\ref{section:causal-metrics-properties}]}
If we were only provided subgroups' effects, and not the population effect ($P_\text{\tiny S}$ or \textbf{All} on Figure~\ref{tab:introduction-diastolic}), an intuitive procedure to obtain the population effect from local effects would be to average subgroups effects. More explicitly,
\begin{flalign}\label{eq:toy-example-collapsibility}
    \text{Collapsibility}
    &&
    \tau_{\text{\tiny RD}} =  \tikzmarknode{amp}{\highlight{ForestGreen}{\color{black} $p_\text{\tiny S}(X=1)$ }}\cdot\tau_{\text{\tiny RD}}(X=1) +  \tikzmarknode{amp}{\highlight{ForestGreen}{\color{black} $p_\text{\tiny S}(X=0)$  }}\cdot\tau_{\text{\tiny RD}}(X=0),&&
\end{flalign}%
\begin{tikzpicture}[overlay,remember picture,>=stealth,nodes={align=left,inner ysep=1pt},<-]
% For "t_{j+1}"
%\path (tj1.north) ++ (-3.85,-1.8em) node[anchor=north west,color=NavyBlue!85] (tj1text){\textsf{\footnotesize property of (j+1)\textsuperscript{th} item}};
\path (amp.north) ++ (-6,-1.8em) node[anchor=north west,color=ForestGreen] (sotext){\textsf{\footnotesize \% individuals with $X=1$} in $P_{\text{\tiny S}}$};
\path (amp.north) ++ (-1.4,-1.8em) node[anchor=north west,color=ForestGreen] (sotext){\textsf{\footnotesize \% individuals with  $X=0$} in $P_{\text{\tiny S}}$};
\end{tikzpicture}

denoting $P_{\text{\tiny S}}$ the \textbf{s}ource population from which the study was sampled, and $p_\text{\tiny S}(x)$ the proportion of individual with $X=x$ in this population. In our example study above $p_\text{\tiny S}(X=0)$ is $0.53$ \citep{Cook1995NNT}, thus for the risk difference the formula recovers the population effect from the sub-group effects: $-0.47\cdot0.006 - 0.53\cdot 0.08 = 0.0452$.
When a population-effect measure can be written as a weighted average of subgroup effects, it is said to be \textit{collapsible}, and \textit{directly collapsible} if the weights are equal to the population's proportions. 
While the Risk Difference is directly collapsible, this is not true for all measures (e.g. for the Number Needed to Treat, $0.47 \cdot 167 + 0.53 \cdot 13 = 85 \neq 22$). We precisely define collapsibility and which measures are collapsible (or not) in Section~\ref{subsec:collapsibility}, summarized in Table~\ref{tab:small-summary-measures}.\\

Collapsibility comes into play when one is interested in the population effect on a \textbf{t}arget population $P_{\text{\tiny T}}$ different from the original source population $P_{\text{\tiny S}}$, \emph{e.g.} with a different proportion of individuals with diastolic pressure ($\forall x \in \{0, 1\},\, p_\text{\tiny S}(x) \neq p_\text{\tiny T}(x) $).
%This practice of extending findings from a source population $P_{\text{\tiny S}}$ to a target population $P_{\text{\tiny T}}$ is found under the names \textit{generalization}, \textit{transportability}, \textit{portability}, or \textit{recoverability}. \jj{Il te manque les références}
Here, one must account for distributional shift across the two populations in baseline covariates that are prognostic of the outcome.

Intuitively, one would wish that the procedure from \eqref{eq:toy-example-collapsibility} remains valid, only changing the weights for example swapping $p_\text{\tiny S}(X=0)$ for $p_\text{\tiny S}(X=1)$ (resp. $p_\text{\tiny T}(X=0)$ for $p_\text{\tiny T}(X=1)$). More explicitly, 
\begin{flalign}\label{eq:toy-example-standardization}
    \text{Effect on target population}
    &&
    \tau_{\text{\tiny RD}}^{\text{\tiny T}} =  \tikzmarknode{amp}{\highlight{Bittersweet}{\color{black} $p_\text{\tiny T}(X=1)$ }}\cdot\tau_{\text{\tiny RD}}^{\text{\tiny S}} (X=1) +  \tikzmarknode{amp}{\highlight{Bittersweet}{\color{black} $p_\text{\tiny T}(X=0)$  }}\cdot\tau_{\text{\tiny RD}}^{\text{\tiny S}}(X=0),
    &&
\end{flalign}

\begin{tikzpicture}[overlay,remember picture,>=stealth,nodes={align=left,inner ysep=1pt},<-]
% For "t_{j+1}"
%\path (tj1.north) ++ (-3.85,-1.8em) node[anchor=north west,color=NavyBlue!85] (tj1text){\textsf{\footnotesize property of (j+1)\textsuperscript{th} item}};
\path (amp.north) ++ (-6,-1.8em) node[anchor=north west,color=Bittersweet] (sotext){\textsf{\footnotesize \% individuals with $X=1$} in $P_{\text{\tiny T}}$};
\path (amp.north) ++ (-1.4,-1.8em) node[anchor=north west,color=Bittersweet] (sotext){\textsf{\footnotesize \% individuals with  $X=0$} in $P_{\text{\tiny T}}$};
\end{tikzpicture}
\vspace{0.1cm}

where $ \tau_{\text{\tiny RD}}^{\text{\tiny T}}$ is the RD on the target population $P_{\text{\tiny T}}$ and $\tau_{\text{\tiny RD}}^{\text{\tiny S}}(x)$ are local effects in the source population $P_{\text{\tiny S}}$.
This procedure can be found under various names: \textit{standardization}, \textit{re-weighting}, \textit{recalibration}) \citep{miettinen1972standardization, Rothman2000ModernEpidemiology, Bareinboim2014ExternalValidity}. We will call it \underline{generalization}, as it is related to the work initiated by \cite{stuart2011use}. 
%This work also rely on standardization, but calling it generalization. 
We show that procedure from \eqref{eq:toy-example-standardization} is accurate, only if the causal measures are collapsible. %This contribution is detailed in Section~\ref{section:causal-metrics-properties}. %\jj{dire où tu donnes la def de collapsible et pointer vers le tableau qui donne quelle mesure sont collapsibles}. 




\paragraph{Contribution 2: A measure can disentangle treatment effect from baseline risk [Section~\ref{section:generative-models}]}

%In this work, we will present that, if the treatment effect diminishes the number of occurences, it is expected that the RR depends less on the baseline. The results comes from \textit{(i)} a re-writing of the outcome as a non-parametric generative model from baseline covariates and treatment \jj{redonne la section}, which \textit{(ii)} enables to express what each treatment effect measures grasps of it \jj{pas compris la fin de la phrase}. %As non-parametric models used depends on the nature of the outcome (continuous or binary), the measures's properties depend on the nature of the outcome too. 
%As a consequence the nature of the outcome and the direction of the effect dictate one measure as being a measure expressing only the modulation of the treatment effect without including the baseline's level. 
%A by-product is another way to define what treatment effect modulators are, with respect to the mechanism that generates $Y$ and not with respect to the measure.
Table~\ref{tab:introduction-diastolic} shows that the choice of the measure gives different impressions of the heterogeneity of the effect, i.e. how much the effects measures change on different subgroups. 
Such differences can be due to different baseline risks. For example, it seems that a higher number needed to treat on the subgroup with low prevalence ($X=1$) is expected as, even without the treatment, individuals already have a low risk of stroke.
Is it possible to disentangle the baseline variation with the treatment effect in itself? 
Surprisingly, in this example, one measure is constant (or \textit{homogeneous}) over the strata $X$: the risk ratio. We will show that this measure was the only one expected to behave like this.
More precisely, we will show that depending on the outcome nature and the direction of treatment effect (harmful or beneficial), there exists one treatment effect measure capable of disentangling the baseline level with the treatment effect itself: the RD for continuous outcome;   either the RR or the SR (depending on the direction of the treatment) for binary outcome. 
%If the outcome is continuous, then the RD is the measure enabling such disconnection. 
All other common measures entangle baseline level and treatment effect.
A by-product of this definition is a non-parametric way to define covariates being treatment effect modulators or only prognostic covariates.
%This contribution is detailed in Section~\ref{section:generative-models}.%\jj{paragraphe assez dur à comprendre... Si tu dis juste la dernière partie à partir de for each outcome's nature and direction j'ai l'impression que ça suffit, le reste est dur à lire sans le détails???}
%This leads to several contributions.
%In this work, we will show that even if the Risk Ratio has no reasons to be constant when stratified on subgroups, this measure is more likely to behave so if the outcome is binary and if the treatment effect is constantly beneficial (i.e. towards the reduction of occurrences of events).\bc{We show that depending on the nature of the outcome (binary or continuous), each  metric expresses something different. A non-intuitive but important result being this sensitivity to population's shift depends on the nature of the considered outcome.}

%\mybox{Contribution 1: Disentangling the influence of treatment effect modulators from baseline risk}{blue!20}{blue!10}{ 
%For each outcome's nature and direction of treatment effect (harmful or beneficial), it is is possible to prove that one treatment effect measure is able to disentangle the baseline level with the treatment effect itself.  When the outcome is binary, this is either the RR or the SR depending on the direction of the treatment.  If the outcome considered is continuous, then the RD is the measure enabling such disconnection.  All other common measures intricate baseline level and treatment effect.}
%\bc{Learning causal effect in one environment has interest when findings can be generalized to another population, in particular because most studies are conducted with the intention of applying the results elsewhere. \textit{Generalization} can also be found under the name \textit{Transportability}, \textit{Portability}, or \textit{Recoverability}, and refers to the external validity of a study. }\bc{This is particularly important as conclusions that are remembered and shared from clinical trials are causal, and therefore somehow considered as an invariant ground truth\footnote{We refer the reader to \cite{Pearl2000Book} (p. 182), talking about this practice: ``\textit{Once people interpret proportions as causal relations, they continue to process those relations by causal calculus and not by the calculus of proportions}".}. }
%Also, not all measures are collapsibles, and therefore procedure from \eqref{eq:toy-example-collapsibility} is not always valid. 

%To summarize: Aggregating subgroups effects to retrieve a population-effect is a property called collapsibility. Not all measures are collapsible. Collapsibility is necessary for generalization by standardization.

%\mybox{Contribution 2: Collapsibility is necessary for generalization by standardization}{blue!20}{blue!10}{Aggregating subgroups effects to retrieve a population-effect is a property called collapsibility. Not all measures are collapsible. Collapsibility is necessary for generalization by standardization.}

\paragraph{Contribution 3: Causal effect measures are not equal when facing population's shift [Section~\ref{sec:generalization}]} 
Collapsibility is needed when generalizing local effects to another target population using \eqref{eq:toy-example-standardization}. But which covariates $X$ must be accounted for in \eqref{eq:toy-example-standardization} for the procedure to be valid? %\gv{J'ai pas mal reformulé car je pense que la notion "set of covariates" n'était pas forcement évidente à rélier au paragraphe d'avant sans bien connaître la litérature à ce sujet. Vérifie la formulation}\bc{si tu trouves ça plus clair on garde. Plus d'avis ;) Ca fait 20 fois que je repasse sur les même phrases}\gv{Mais ce que j'ai écrit te fait sens à toi? Si oui, on garde}\bc{oui ça me va !!}
Current line of works usually advocate to adjust on all prognostic covariates being shifted between the two populations. 
Using Contribution 2, we will show that some collapsible measures are likely to be more easily generalizable than others, and in particular are likely to require less covariates to adjust on (only the treatment effect modulators, and not all shifted prognostic covariates). 
Illustration from Table~\ref{tab:introduction-diastolic} taken from a real clinical example is in perfect agreement with our findings. %For a binary outcome and a beneficial effect, the RR is expected to require less covariates to shift only if treatment effect modulators are shifted, but not prognostic covariate such as $X$. 
In this example, the RR is directly generalizable from $P_{\text{\tiny R}}$ to $P_{\text{\tiny T}}$, while the risk difference would need to be adjusted on $X$.
Note that Section~\ref{sec:generalization} also provides the formula to generalize relative measures such as the risk ratio, while the current literature mostly focuses on risk difference. %\jj{Plus formule pour RR pour généraliser}
% $X$ is the only prognostic covariate to be shifted between the two populations (called transportability assumption) are both licensing the following generalization procedure:
%where $ \tau_{\text{\tiny RD}}^{\text{\tiny T}}$ is the RD on the target population $P_{\text{\tiny T}}$ and $\tau_{\text{\tiny RD}}^{\text{\tiny S}}(x)$ are local effects in the source population $P_{\text{\tiny S}}$.
%Contribution~2 implies that not all measure are collapsible. 
%Hidden in the transportability assumption, is the fact that $X$ (here the diastolic blood pressure level) captures all the covariates modulating treatment effect that are shifted between the two population. Recall that contribution~1 details that some measure are able to disentangle baseline level from treatment effect itself, when some measure are not.
%Combining these two contributions leads to our key contribution: some measures are likely to be more easily generalizable than others, and in particular are likely to require less covariates for generalization by standardization.  In this illustration, this can be seen as the fact that the RR is directly generalizable from $P_{\text{\tiny R}}$ to $P_{\text{\tiny T}}$. \jj{Euh... là j'ai perdu le raisonnement comme tu nous parlais de RD avant?}%: that some treatment effect measure require less covariates to be generalized, and in particular only the covariates modulating the treatment effect and not the one only involved in the baseline risk.

%\mybox{Contribution 3: Causal effect measures are not equal when facing population's shift}{blue!20}{blue!10}{Some %measures are likely to be more easily generalizable than others, and in particular are likely to require less covariates for generalization by standardization.}



\subsection{Related work: many different viewpoints on effect measures}

\paragraph{The choice of measure, a long debate}
%Medicine and epidemiology lectures discuss at length the different treatment-effect measures \citep{Rothman2000ModernEpidemiology, Cook2014UserGuide}.
The question of which treatment-effect measure is most appropriate (RR, SR, RD, OR, NNT, log-OR, etc) is age old \citep{Sheps1958ShallWe, Greenland1987Interpretation,Laupacis1988AnAssessmentOfClinically,  Cook1995NNT, Sackett1996DownWO, davies1998can, king2002estimating, Schwartz2006ratio, Cummings2009RelativeMeritsRRAndOR}.
Health authorities advise to report both absolute and relative causal effect \citep[item 17b]{schulz2010consort}. 
And yet, the question is still a heated debate: in the last 5 years, numerous publications have advocated different practices \citep[see Appendix~\ref{appendix:different-point-of-views} for details]{Spiegelman2017Modeling, Spiegelman2017letSubject, lesko2018considerations, baker2018new, Changyong2019RelationsAmongThreePop, George2020WhatsTR, Doi2020callToChangePractice, doi2022TimeToDoAway, xiao2021odds, xiao2022IsORPortable, Huitfeldt2021ShallWe,Lapointe2022FromMathToMeaning}. 
Most of these works focus on the interpretation of the metrics and simple properties such as symmetry \citep{Cummings2009RelativeMeritsRRAndOR}, heterogeneity of effects \citep{Rothman2011bookEpidemiologyIntrod, VanderWeele2007FourTypes, lesko2018considerations}, or collapsibility \citep{simpson1951interpretation, Whittemore1978Collapsibility, Miettinen1981Essence, Greenland1987Interpretation, pearl1999collapsibility, Cummings2009RelativeMeritsRRAndOR, Greenland2011adjustments, Hernan2011unraveled, Sjolander2016NoteOnNoncollapsibility, Huitfeldt2019collapsible, Daniel2020MakingApple, liu2022rejoinder,Didelez2021collapsibility} --some works discuss the paradoxes induced by a lack of collapsibility without using this exact term, e.g. in oncology \citep{ding2016subgroup, liu2022correct}. We shed new light on this debate with a framing on generalization and non-parametric generative models of the outcome (Section~\ref{section:generative-models}).


\paragraph{Connecting to the generalization literature}

The problem of external validity is a growing concern in clinical research \citep{rothwell2005external,Rothman1013WhyRepresentativeness,Berkowitz2018GeneralizingBlood, Deeks2022IssuesInSelection}, related to
various methodological questions \citep{cook2002experimental, pearl2011transportability}. We focus on external validity concerns due to shifted baseline covariates between the trial's population and the target population, following the line of work initiated in \cite{imai2008misunderstandings} (see their definition of \textit{sample} effect versus \textit{population} effect), or Corollary 1 of \cite{Bareinboim2014ExternalValidity}).
%In other words, our work only considers generalization \underline{by standardization}, i.e. by re-weighting local treatment effect such as in \jj{tu dis ce qu'on considère mais ici on ne sait pas du coup ce qu'on ne considère pas ou ce qu'il y aurait d'autre } \eqref{eq:toy-example-collapsibility}. This formulae is also called the transport formulae or weighting \jj{je ne mettrais pas que pearl ici en référence si?} \citep{Bareinboim2014ExternalValidity}. 
Generalization by standardization (\eqref{eq:toy-example-standardization}, \textit{i.e.} re-weighting local effects) has been proposed before  in epidemiology \citep{Rothman2000ModernEpidemiology}, and in an even older line of work in the demography literature \citep{yule1934some}.
Note that \eqref{eq:toy-example-standardization} is very close to procedure from \eqref{eq:toy-example-collapsibility} which can be linked to post-stratification \citep{imbens2011experimental, miratrix2013adjusting}. Post-stratification is used to lower variance on a randomized controlled trial and therefore has no explicit link with generalization, despite using a similar statistical procedure.
Today, almost all statistical papers dealing with generalization focus on the estimation procedures that generalizes the risk difference $\tau_{\text{\tiny RD}}$ \citep{stuart2011use, tipton2013improving, Muircheartaigh2014GeneralizingApproach, kern2016assessing, lesko2017generalizing, nguyen2018sensitivitybis, Stuart2017ChapterBook, buchanan2018generalizing, dahabreh2020extending, ackerman2020generalization} (reviewed in \cite{Degtiar2021Generalizability, colnet2021causal}), seldom mentioning other measures. 
Other works focus on the generalization of the distribution of the treated outcome $\mathbb{E}\left[ Y^{(1)}\right]$ \citep{pearl2011transportability, Bareinboim2014ExternalValidity, CinelliGeneralizing2019}. A notable exception, \cite{huitfeldt2018choice}, details which choice of variables enables the standardization procedure for binary outcomes.
%While these authors exactly tackle the same question as we do, their conclusions only hold for binary outcomes. Our approach tackles \textit{(i)} a larger scope, while also \textit{(ii)} proposing different notations.
We extensively generalize the thought process of \cite{huitfeldt2018choice} revealing the interplay with choice of measure and role of covariates in heterogeneous settings, as well as continuous outcomes.
%Our conclusions are totally consistent when the scope is that of \cite{huitfeldt2018choice} (i.e. binary outcomes and monotonous effect)\gv{Can we say that, in a sense, our work extends \cite{huitfeldt2018choice}: role of covariates, continuous outcomes}.


\paragraph{Building up on causal research}
By writing the outcomes as generated by a non-parametric process disentangling the baseline from the treatment effect (in the spirit of \cite{robinson1988semiparam, nie2020quasioracle, Gao2021DINA}), we extend the usual assumptions for generalization.
In particular, \cite{Bareinboim2014ExternalValidity} state that their assumptions for generalization are
``\textit{the worst case analysis where every variable may potentially be an effect-modifier}''. Our work proposes more optimistic situations, by introducing a notion of effect-modifier without parametric assumptions. This enables the description of situations where fewer covariates are required for the generalization of certain measures, depending on the nature of the outcome
%While other works such as \cite{nguyen2018sensitivitybis} highlights that less covariates are necessary when considering the risk difference, this
%\footnote{See complete quote of \cite{Bareinboim2014ExternalValidity} ``\textit{The inferences licensed by Theorem 2 and 3 represent worst case analysis, since we have assumed, in the tradition of nonparametric modeling, that every variable may potentially be an effect-modifier (or moderator). If one is willing to assume that certain relationships are noninteractive, or monotonic as is the case in additive models, then additional transport licenses may be issued}".}. \jj{Alors là je ne comprends rien de ce paragraphe...Trop de Pearl c'est pour ça...} \bc{hihi ! J'ai supprimé !} 
\cite{CinelliGeneralizing2019} have proposed similar ideas, assuming monotonicity of the effect (i.e. the effect being either harmful or beneficial for everyone) \underline{and} the absence of shifted treatment effect modifiers, in order to generalize $\mathbb{E}\left[Y^{(1)} \right]$. More precisely they assumption that what they call \textit{probabilities of causation} $\mathbb{P}\left[Y^{(1)} = 0 \mid Y^{(0)} = 1\right]$ are invariant across populations. We relax this assumption to allow more general situations. Doing so, we also extend work from \cite{huitfeldt2018choice, Huitfeldt2019EffectHeterogeneity}, showing how those probabilities are linked with the causal measures of interest. %\jj{peut être être plus précise dans ce paragraphe sur ce que tu veux dire et en quoi tu étends ces travaux?}\bc{oui, je vais finir de rédiger la dernière partie, je laisse ton commentaire}
Interestingly, all our derivations retrieves \cite{Sheps1958ShallWe} intuition and results when the outcome is binary (which was the only situation described by Sheps). Our work also proposes conclusions for a continuous outcome which was not treated by \cite{Sheps1958ShallWe, CinelliGeneralizing2019, Huitfeldt2021ShallWe}.
%Shep's work was advocating different measure depending on the direction of the effect (harmful or beneficial). 
%Our results about which measure is easier to generalize (and therefore less sensitive to population's shift) is in complete accordance with Shep's work.
%Note that Mindel C. Sheps' work has been recently brought back at the front of the stage by \cite{Huitfeldt2021ShallWe}.
%Our work also extends \cite{CinelliGeneralizing2019}'s ``\textit{monotonicity}" assumption allowing transport and in particularly bounds on the transported distribution $\mathbb{E}\left[ Y^{(1)}\right]$ with extended assumptions from \citep{pearl2011transportability, Bareinboim2014ExternalValidity} (in particular using selection diagram). Our work also extends on the approach of \cite{huitfeldt2018choice, Huitfeldt2019EffectHeterogeneity}.
%And note that \cite{Bareinboim2014ExternalValidity, CinelliGeneralizing2019} focus on the estimation of the expectation of the treated potential outcome on the target population, and therefore do not explictly consider the generalization of one causal measure.
%For example, let's consider that a clinician has in mind the result from a trial conducted on a population with distribution $P_1$ stating that the efficacy of the drug on relative scale is $\hat \tau_{\text{\tiny Rel}} = 3$. But the clinician's typical patients are rather following a different distribution $P_2$.
%A intuitive practice is to multiply the baseline of a patient by this relative measure to obtain the estimated outcome under treatment for this patient. But if the clinician was rather provided a study with an absolute measure $\hat \tau_{\text{\tiny Abs}} = 3$, the process would be to add this effect to the baseline. %Generalization is what physician typically do, as they extend what they have learned through previous trials to a new population or a new patient.
%With respect to this practice, it is of major importance that the effect transposed to new situations has grasped something truly causal and somehow invariant. 
%\jj{pas si facile ici de suivre ton cheminement }
%In this work, we will establish that not all causal metrics ensure this practice to be correct, when adjustment has to be made, and when generalization is impossible. The major outcome of this work is to prove that some causal metrics convey a true causal invariant, while some others have to be standardized or when transport is not possible.\bc{phrase pas belle mais idée forte à mettre ici.}

%\subsection{Toy example}
%We show that depending on the nature of the outcome (binary or continuous), each  metric expresses something different.
%A non-intuitive but important result being this sensitivity to population's shift depends on the nature of the considered outcome.

%\begin{wrapfigure}{l}{0.38\textwidth}
%  \begin{center}
%    \includegraphics[width=0.35\textwidth]{fig/toyexamplesummary.png}
%  \end{center}
%  \caption{Synthetic results of a trial from a source population (left) and a target population (right). Different causal effect measures are reported: the risk ratio $\tau_{\text{\tiny RR}} = 32/45 = 21/30$ and the risk difference $\tau_{\text{\tiny RD}}$.}
%  \label{fig:toyexamplesummary}
%\end{wrapfigure} A clinical trial (or Randomized Controlled Trial - RCT) was conducted in a source population $P_{\text{\tiny S}}$ to assess the efficacy of a drug preventing death from a head trauma. 
%In particular investigators found 45\% deaths 28 days after admission to hospital in the placebo group and 32\% in the treated group.
%When reporting the so-called treatment effect, several scales (or measures) can be used: for e.g the ratio of the two risks ($\tau_{\text{\tiny RR}} = 0.7$) or the risk difference ($\tau_{\text{\tiny RD}} = -13\%$). 
%This trial soon became the international reference to advocate the treatment's usage, and many hospitals and countries started to use it as a standard-of-care. Years later, another trial was conducted in another population $P_{\text{\tiny T}}$ (for \textbf{t}arget), now revealing $\tau_{\text{\tiny RR}} = 0.7$ and $\tau_{\text{\tiny RD}} = -9\%$ (see Figure~\ref{fig:toyexamplesummary}).
%\textit{What could be the source of such a difference?}
%Because both trials did compare exact same treatment and outcome, investigators suspect the population to be different. Looking at the so-called Table~1, they observe that $P_{\text{\tiny T}}$ contains $20\%$ women (resp. $80\%$ men), while in $P_{\text{\tiny S}}$ is composed of  $50\%$ women and men. To confirm the assumption that the difference comes from the population's composition, investigators estimated the effect of the treatment on the subgroups. They found a constant risk ratio of $\tau_{\text{\tiny RR}}(M) = \tau_{\text{\tiny RR}}(F) = 0.7$ on each subgroups but $\tau_{\text{\tiny RD}}(F) = -22$ and $\tau_{\text{\tiny RD}}(M) = -6$ (F for \textbf{f}emale and M for \textbf{m}ale). 
%Note that as soon as the gender is the only baseline predictor accounting for the modulation of the response on the risk difference scale, it would be possible to generalize this measure by standardization (i.e. weighted average of $\tau_{\text{\tiny RD}}(F)$ and $\tau_{\text{\tiny RD}}(M)$ on the population of interest): Such a process is (surprisingly) not possible with all typical measures used by clinicians, such as the odds ratio or the number needed to treat. Why was the risk ratio more generalizable in this example? Is this property always expected? In this work we aim to answer such questions. Generalizability (or external validity) of a causal effect is a major property as most of the time clinicians use causal effects from previous trials \textit{(i)} to estimate the expected response to treatment for a specific patient based on his/her baseline risks, \textit{(ii)} to choose which treatment is the best. Therefore, it is of major importance that RCTs convey the most portable measure possible, or at least a measure that can be generalized to another population after standardization such as in \eqref{eq:toy.example.generalization}. This work aims at detailing which measures of effect are easier to generalize to another population.
%\es{je trouve cette partie super et très bien écrite!}\bc{*Ronronnements*}


\section{Causal metrics and their properties}\label{section:causal-metrics-properties}

\textit{This section uses notations introduced in Section~\ref{sec:formalization-and-key-contributions}, in particular the potential outcomes $Y^{(0)}$, $Y^{(1)}$ (which can be either binary or continuous), the binary treatment $A$, and the baseline covariates $X$. By default, all expectations are assumed to refer to a source population $P_\text{\tiny S}$. Only when generalizing (see Section~\ref{subsec:first-time-generalization} or Section~\ref{sec:generalization}), we also consider a target population $P_\text{\tiny T}$. For example $\tau^{\text{\tiny T}}_{\text{\tiny RR}}$ denotes the RR on the target population.}\\

%To illustrate this arguments, Figure~\ref{fig:big-plot-with-all-metrics} represents the ranges all the metrics from Table~\ref{tab:list-measures} can take when considering a binary outcome. \es{je mettrais la référence à la figure plus tard car elle ne concerne que l'hétérogénéité}
%Beyond the impression, the choice of the measure impacts how we perceive the heterogeneity of the effect. Another important property, the collapsibility, strongly depends on the measure considered. 
%Besides, important properties  while also having different properties such as collapsibility. 
In this section, we ground formally concepts such as homogeneity and heterogeneity of treatment effect, but also collapsibility, and its link to generalization. Those concepts are already described in the literature, via numerous and slightly different definitions  (see   Section~\ref{appendix:other-formal-definitions}).  
We unify existing definitions. For clarity, all definitions, assumptions, and lemmas that do not contain an explicit reference in the title are original. 

\subsection{Treatment effect heterogeneity depends on the measure chosen}\label{subsec:homogeneity}

Homogeneity or heterogeneity is linked to how the effects on subgroups of the population change. %For example, computing the average effect on women and men separately. This is also called stratification. 
If the effect amplitude and/or direction is different in some subgroups (not due to sampling noise as we only consider the true population's values), the treatment effect is said to be heterogeneous. 
In the literature, one can find several informal definitions of heterogeneity of a treatment effect % \citep[ such as the quote from  recalled in Section~\ref{appendix:other-formal-definitions} ]{Rothman2011bookEpidemiologyIntrod}, 
but formal definitions are scarce. From now on, we let $\mathbb{X}$ be the covariate space.  
%Note that this question of treatment-effect heterogeneity is of major interest when it comes to personalized medicine or when looking for optimal individual treatment regimes.
 %\jj{J'aurais gardé ici, ça dépend de ton positionnement mais si ton papier veut parler à des médecins tu as envie de la garder ++}
%For the rest of the work, we denote $X$ the set of baseline covariates\footnote{We insist on the fact that those covariates are baseline or pre-treatment covariates. See \cite{VanderWeele2007FourTypes} for a detailed explanation.}, and $\tau(x)$ the treatment effect on the subpopulation $X=x$ for any causal measure. Most of the time, the consideration of heterogeneity in applied clinical work is made ``\textit{one-variable-at-a-time}", for e.g. for male and female (in such a situation, $X$ is univariate and binary), even if some literature propose to change this practice to observe hetereogeneity along several covariates at a time \citep{Kent2019PATH1}. Our formalism allows both point of views. First, we define homogeneity as the absence of effect modification on the scale chosen.
%\es{la différence entre treatment effect et causal effect measure n'est pas très claire dans la définition}
%\gv{Derrière ces notions il y a la question de savoir si on peut raisonner à l'échelle individuelle}
%\bc{Gael: je compte mettre dans la partie generalization}
\begin{definition}[Treatment effect homogeneity]\label{def:homogeneity}
A causal effect measure $\tau$ is said to be homogeneous, if
\begin{equation*}
   \forall x_1, x_2 \in \mathds{X},\quad \tau(x_1) = \tau(x_2) = \tau.
\end{equation*}
\end{definition}

\begin{definition}[Treatment effect heterogeneity - \cite{VanderWeele2007FourTypes}] \label{def:heterogeneity}
Assuming a causal measure $\tau$ and a baseline covariate $X$, a treatment effect is said to be heterogeneous with respect to $X$ if,

\begin{equation*}
\exists\, x_1,x_2 \in \mathds{X},\, \quad \tau(x_1) \neq \tau(x_2) .
\end{equation*}
\end{definition}
Heterogeneity and homogeneity are properties defined with respect to \textit{(i)} baseline covariates and \textit{(ii)} a measure. Claiming \textit{hetereogeneity or homogeneity of a treatment effect} should always be completed by the information about the considered covariates and the  measure under study. For instance in the illustrative example from Table~\ref{tab:introduction-diastolic}, the treatment effect on the Risk Difference scale is heterogeneous with respect to the baseline diastolic blood pressure level $X$, while the treatment effect on the Risk Ratio scale is homogeneous with respect to $X$. 
%To be convinced of the latter phenomenon, we refer the reader to Figure 11–1 of \cite{Rothman2011bookEpidemiologyIntrod} (we reproduced a similar plot in Appendix, see Figure~\ref{fig:hetero-schematic}). %\jj{Ici reprendre ton exemple de figure 1 pour dire RR est ici homogène et les autres hétérogènes} ok ! C'est mieux oui.
%\jj{ce qui pourrait manquer avec ça, c'est qu'on a envie que tu dises laquelle fait plus de sens à interpréter et pourquoi  pour le médecin tu lui dis dans ton cas précis toi de regarder quelle mesure et pourquoi? }\bc{Ah par contre là je ne vois pas ce que tu voudrais que j'ajoute}
%\jj{Ou en fait bizarreemnt ce paragraphe n'est pas assez lié à la suite du travail autant collapsibilité tu le dis clairement autant hétérogénéité c'est moins clair}\bc{oui, je vais amélirer cela.}\bc{}
Below we link homogeneity of treatment effect with the generalizability of a causal measure.
%Assessing the heterogeneity of an effect can be done via testing for interaction between covariates and treatment in a model. The link function of statistical model encodes the scale on which the treatment effect heterogeneity is tested \citep{lesko2018considerations}.\gv{Ces deux dernières phrases me paraissent pas coeurs au raisonnement que nous menont, et donc je le retirerais}
%Finally, note that testing for heterogeneity or homogeneity of an effect can be linked with testing for interaction when relying on a linear generative model.%R\bc{Arg Julie? J'ai oublié de mentionner ça. Qu'en dis tu ?}
\subsection{Not all measures are collapsible}\label{subsec:collapsibility}

\paragraph{Intuition}
Collapsibility is intuitively linked to heterogeneity.
Indeed, to investigate for heterogeneity, one looks up the treatment effect on subgroups of the population. 
Collapsibility is the opposite process, where local information is aggregated to obtain a global information (i.e. on a population). One might expect the global effect on a population to be an average of the subgroups effects, with weights corresponding to proportions of each subgroup in the target population of interest as in \eqref{eq:toy-example-collapsibility}.
Counter-intuitively, this procedure is valid only for certain causal effect measures.
For example, if the treatment effect is reported as an Odds Ratio, it is possible to find bewildering situations, such as that of the synthetic example detailed on Table~\ref{tab:odds-ratio-simpson}. 
%We propose a synthetic example in Table~\ref{tab:odds-ratio-simpson}. 
On this example, the Odds Ratio is measured on the overall population (Table~\ref{tab:odds-ratio-simpson} (a)) and on the two subpopulations if female ($F=1$) or not ($F=0$) (Table~\ref{tab:odds-ratio-simpson} (b)).
Here, the drug's effect (on the OR scale) is found almost equal on both males (0.166) and females (0.167); however the average effect on the overall population appears much more efficient (0.26).
The value Odds Ratio at the population level is not even \emph{between} that of Odds Ratio of sub-populations. The situation mimics a randomized controlled trial conducted with exact population proportions and with $F$ being a baseline covariate, so the phenomenon observed is not an effect of counfounding.\\

\begin{table}[H]
    \centering
    \caption{\textbf{Non-collapsibility of the odds ratio on a toy example}: The tables below represent the exact proportion of an hypothetical population, considering two treatment level $A \in \{0, 1\}$ and a binary outcome. The proportion are as if a randomized controlled trial was conducted on this population. This population can be stratified in two strata $F \in \{0, 1\}$. The odds ratio can be measured on the overall population (a), or on each of the sub-population, namely $F=0$ or $F=1$ (b). Surprisingly, on each sub-population the odds ratios are similar, but on the overall population the odds ratio is almost two times bigger than on each sub-population. This example is largely inspired from \cite{Greenland1987Interpretation}, but several similar examples can be found elsewhere, for example in \cite{hernan2020whatifbook} (see their Fine point 4.3) or in \cite{pearl1999collapsibility} (see their Table 1). Another didactic example is provided in \cite{Daniel2020MakingApple} (see their Figure 1), with a geometrical argument.}
    \begin{subtable}{.3\linewidth}
        \centering
        \caption{Overall population, $\tau_{\text{\tiny OR}}  \approx 0.26$}

        \begin{tabular}{c|cc|}
        \cline{2-3}
                          & \multicolumn{1}{c|}{Y=0} & Y=1 \\ \hline
\multicolumn{1}{|c|}{A=1} & 1005                      & 95 \\ \cline{1-1}
\multicolumn{1}{|c|}{A=0} & 1074                       & 26  \\ \hline
        \end{tabular}

    \end{subtable}%
    \begin{subtable}{.6\linewidth}
        \caption{$\tau_{\text{\tiny OR}\mid F=1} \approx 0.167$ and $\tau_{\text{\tiny OR}\mid F=0} \approx 0.166$}
        \centering
\begin{tabular}{c|cc|lc|cc|}
\cline{2-3} \cline{6-7}
\textbf{F= 1}             & \multicolumn{1}{c|}{Y=0} & Y=1 &                       & \textbf{F=0} & \multicolumn{1}{c|}{Y=0} & Y=1 \\ \cline{1-3} \cline{5-7} 
\multicolumn{1}{|c|}{A=1} &              40          & 60  & \multicolumn{1}{l|}{} & A=1          & 965                       &  35 \\ \cline{1-1} \cline{5-5}
\multicolumn{1}{|c|}{A=0} & 80                       & 20  & \multicolumn{1}{l|}{} & A=0          & 994                      & 6  \\ \cline{1-3} \cline{5-7} 
\end{tabular}

    \end{subtable}% 
    \label{tab:odds-ratio-simpson}
\end{table}
This apparent paradox is due to what is called non-collapsibility\footnote{This definition and phenomenon has been observed long ago by Simpson. See also the \cite{Hernan2011unraveled} for a discussion of Simpson's original paper with modern statistical framework. Note that \cite{Pearl2000Book} (page 176) mentions that collapsibility has been discussed earlier, for example by Pearson in 1899.} of the Odds Ratio. That the average effect on a population could not be written as a weighted sum of effects on sub-populations is somehow going against the ``\textit{implicit assumptions that drive our causal intuitions}'' (\cite{Pearl2000Book}, page 180). 
On the contrary, an effect measure is said to be collapsible when the population effect measure can be expressed as a weighted average of the stratum-specific measures.
%\citep{simpson1951interpretation}, and described multiple times in articles \citep{Whittemore1978Collapsibility, Miettinen1981Essence, Greenland1987Interpretation, pearl1999collapsibility, Cummings2009RelativeMeritsRRAndOR, Greenland2011adjustments, Hernan2011unraveled, Sjolander2016NoteOnNoncollapsibility, Huitfeldt2019collapsible, Daniel2020MakingApple, Didelez2021collapsibility}, and also outside of the field of causality as this phenomenon can also be encountered for regression models.
Note that non-collapsibility and confounding are two different concepts, as explained in several papers e.g. in \cite{pearl1999collapsibility}\footnote{``\textit{
%Nonetheless, 
the two concepts are distinct: confounding may occur with or without noncollapsibility and noncollapsibility may occur with or without confounding.}"}.
%or more recently in \cite{Daniel2020MakingApple}\footnote{``\textit{We aim to provide an educational summary of issues surrounding (non)collapsibility from a causal inference perspective and to promote the idea that the words `conditional' and `adjusted' (likewise `marginal' and `unadjusted') should not be used inter- changeably.}"}.
%, even if without any context about the covariates status and the treatment assignment regime, collapsibility and confounding can not be dissociated from the association tables. \es{on peut être plus affirmatif ici, si on est vraiment dans une assignation complètement aléatoire non ? }
%In this article, we propose two formal definitions of collapsibility. 
%Those two definitions are streamlining the different formalizations we found in the literature, and aim at unifying them. Indeed, 
\paragraph{Formalizing the problem} In various formal definitions found in the literature (see Section~\ref{appendix:other-formal-definitions}), collapsibility relates to the possibility of writing the marginal effect as a weighted sum of conditional effects on each subgroups. Yet two definitions coexist, depending on whether weights are forced to be equal to the proportion of individuals in each subgroup or not. We outline various definitions and their links:

\begin{definition}[Direct collapsibility - adapted from \cite{Pearl2000Book}] \label{def:direct-collapsibility}
Let $\tau$ be a measure of effect and $P(Y^{(0)}, Y^{(1)}, X)$ a joint distribution with $X$ a set of baseline covariate. $\tau$ is said to be directly collapsible, if
\begin{equation*}
   \mathbb{E}\left[  \tau(X)\right] = \tau.
\end{equation*}
\end{definition}
Some authors present a concept called strict collapsibility (see Definition~\ref{def:strict-collaps-pearl-greenland} in Appendix), which corresponds to our definition of homogeneity (Definition~\ref{def:homogeneity}) \citep{pearl1999collapsibility, liu2022correct, Didelez2021collapsibility}. A homogeneous treatment effect along $X$ has indeed its marginal effect equal to all subgroups effects. 
%We do not consider such definition as the property of collapsibility, as it rather refers to both a measure property and a peculiar data generative process at hand (where homogeneity is observed along a certain baseline covariate like in Table~\ref{tab:introduction-diastolic}). \es{je ne comprends pas la phrase d'avant}\bc{Je suis d'accord, je fais référence à des travaux qui ont défini collapsibilité autrement. On peut enlever je pense} 
%Our proposed definition of collapsibility rather refers to a measure property only.
Our direct collapsibility definition encompasses such phenomenons.

%\es{On met une référence dans le lemme, si le résultat a déjà été montré?}
\begin{lemma}[Direct collapsibility of the risk difference (RD) -- \citep{pearl1999collapsibility}]\label{lemma:direct-collapsibility-RD}
The Risk Difference $\tau_{\text{\tiny RD}}$ is directly collapsible.
\end{lemma}
%The direct collapsbility is the most intuitive apprach to aggregate local effects to a population effect. 
This result has been much discussed; it grounds \eqref{eq:toy-example-collapsibility} in the illustrative example.
In the literature, more flexible definitions of collapsibility can be found, keeping the intuition of the population effect being a weighted sum of effects on subpopulation, with certain constraints on the weights such as positivity and normalization.
\begin{definition}[Collapsibility - adapted from \cite{Huitfeldt2019collapsible}] \label{def:indirect-collapsibility}
Let $\tau$ be a measure of effect and $X$ a set of baseline covariates. The measure $\tau$ is said to be collapsible if there exist weights $g(X, P(X,Y^{(0)}))$ such that for all distributions $P(X, Y^{(0)}, Y^{(1)})$ we have
\begin{equation*}
\mathbb{E}\left[ g(X, P(X,Y^{(0)}))\, \tau(X) \right] = \tau,\qquad \text{with }   g \ge 0,\, \text{and} \quad  \mathbb{E}\left[  g(X, P(X,Y^{(0)}))\right] = 1.
\end{equation*}
\end{definition}
%In other words, the Definition~\ref{def:indirect-collapsibility} of collapsibility means that $\tau$ is collapsible if it can be written as a weighted average of the conditional associational measures on variable $X$. Note that an alternative writting could have been considered with,
%\begin{equation*}
%   \int_{\mathds{X}} \tau \left(P(Y^{(0)}, Y^{(1)}\mid X\right) w(x)\,dx = \tau \left(P(Y^{(0)}, Y^{(1)})\right). 
%\end{equation*}
%Note that would Definition~\ref{def:indirect-collapsibility} allows for the weights to depend on $Y^{(1)}$, then all measures would be collapsible with weights also depending on the joint distribution $P(X, Y^{(0)}, Y^{(1)})$. The weights would corresponds to $\tau/\tau(X)$. This is why, one has to put constraints on the weights in Definition~\ref{def:indirect-collapsibility} to respect the idea of a re-standardization of the local effect to the global effect, where 
Note that here weights depends on the density of $X$ and the distribution of controls $P(X, Y^{(0)})$. %\jj{On a envie de savoir pourquoi tu dis ça}\bc{je ne suis pas moi même convaincue de mon explication... qu'en dis tu ?}
The direct collapsibility is therefore a specific case of the more general version of collapsibility from Definition~\ref{def:indirect-collapsibility}, where $ g(X, P(X,Y^{(0)}))$ corresponds to $1$. 
This definition enables more treatment effect measures to be collapsible.
\begin{lemma}[Collapsibility of the risk ratio and survival ratio - extending \cite{Huitfeldt2019collapsible}]\label{lemma:collapsibility-of-RR-SR}
The risk ratio and survival ratio are collapsible measures. In particular, assume  that almost surely $0 < \mathbb{E}[Y^{(0)}|X] < 1$. Then, the conditional risk ratio and conditional survival ratio are defined and satisfy %\jj{est-ce qu'on les numeroterait pas? tu ne les utilises pas après?}\bc{je peux dire "formula of Lemme 2" ?}
\begin{equation*}
    \mathbb{E}\left[ \tau_\text{\tiny RR}(X) \frac{\mathbb{E}\left[Y^{(0)} \mid X \right]}{\mathbb{E}\left[Y^{(0)}\right]}\right] = \tau_\text{\tiny RR} \qquad \textrm{and} \qquad \mathbb{E}\left[\tau_\text{\tiny SR}(X) \frac{1-\mathbb{E}\left[ Y^{(0)} \mid X \right]}{1-\mathbb{E}\left[ Y^{(0)}\right] }\right] = \tau_\text{\tiny SR}.
\end{equation*}
\end{lemma}
Appendix~\ref{proof:collapsibilty} gives proofs along with other measures. 
%Note that  introduced in Appendix (see Section~XX) follows directly from the collapsibility of $ \tau_\text{\tiny RR}$ and $ \tau_\text{\tiny SR}$.
\cite{Huitfeldt2019collapsible} or \cite{ding2016subgroup} (see their Equation 2.3) also recall these results but only for a binary outcome and categorical baseline covariate\footnote{Note that it is possible to find this result under slightly forms such as in \cite{huitfeldt2018choice, Didelez2021collapsibility}, with a categorical $X$ and using Bayes formula, $\tau_\text{\tiny RR} = \sum_x \tau_\text{\tiny RR}(x)\, \mathbb{E}\left[X=x \mid Y^{(0)} = 1 \right]$.}.   %, alongside with proof for the risk ratio and risk difference when the baseline covariate used is categorical and when the outcome is binary.
Lemma~\ref{lemma:collapsibility-of-RR-SR} extends the derivations for any type of covariate $X$ and outcome $Y$ (continuous or binary).
Note Lemma~\ref{lemma:collapsibility-of-RR-SR} is consistent with the illustrative example in Table~\ref{tab:introduction-diastolic} where   
\begin{equation*}
   \tau_{\text{\tiny RR}} = \mathbb{E}\left[ \tau_\text{\tiny RR}(X) \frac{\mathbb{E}\left[Y^{(0)} \mid X \right]}{\mathbb{E}\left[Y^{(0)}\right]}\right]  = \mathbb{E}\left[ 0.6\,\frac{\mathbb{E}\left[Y^{(0)} \mid X \right]}{\mathbb{E}\left[Y^{(0)}\right]}\right] =  0.6\cdot \underbrace{\mathbb{E}\left[\frac{\mathbb{E}\left[Y^{(0)} \mid X \right]}{\mathbb{E}\left[Y^{(0)}\right]}\right]}_{=1} = 0.6.
\end{equation*}


\begin{lemma}[Non-collapsibility of the OR, log-OR, and NNT]\label{lemma:non-collapsibility}    
The odds ratio $\tau_{\text{\tiny OR}}$,  log odds ratio $\tau_{\text{\tiny log-OR}}$, and Number Needed to Treat $\tau_{\text{\tiny NNT}}$ are non-collapsible measures.
\end{lemma}
%\es{mentionner ici que la preuve pour OR et log OR n'est pas nouvelle, avec la référence}
 The proof is in Appendix~\ref{proof:collapsibilty}. Note that the proof for the Odds Ratio and the log Odds Ratio are not new (in particular we recall the one from \cite{Daniel2020MakingApple}).
While the non-collapsibility of the odds ratio has been reported multiple times (see references above and the example from Table~\ref{tab:odds-ratio-simpson}), we have not found references stating results about the NNT.  While the NNT is not-collapsible, this measure does not show the same paradoxical behavior as the OR (see Table~\ref{tab:odds-ratio-simpson}). %\jj{là j'enlève tes interprétations de c'est peut être parce que c'est une mesure récente, du coup tu peux dire quelque chose sur NNT?. }
%What can be observed on the OR can be seen as against \textit{logic}. 
When considering the OR, the marginal effect $\tau$ can indeed be smaller or bigger than the range of local effects $\tau(x)$.

\begin{definition}[Logic-respecting measure -- \cite{liu2022correct}]\label{def:logic-respecting}
A measure $\tau$ is said to be logic-respecting if %\es{il ne faut pas rajouter ``with respect to a set of baseline covariates''?}
\begin{equation*}
    \tau \in \left[\min_{x}(\tau(x)), \max_{x}(\tau(x)) \right].
\end{equation*}
\end{definition}

\begin{lemma}[All collapsible measures are logic-respecting, but not the opposite]\label{lemma:logic-respecting-measures} Several properties can be noted:
\begin{itemize}
    \item \textit{(i)} All collapsible measures are logic-respecting measures.
    \item \textit{(ii)} The Number Needed to Treat is a logic-respecting measure.
    \item \textit{(iii)} The OR and the log-OR are not logic-repecting measures.
\end{itemize}
%\es{vérifier que c'est bien cohérent par rapprot aux définitions $X$ ou sans $X$}
\end{lemma}

Proof is in Appendix~\ref{proof:logic-respecting}. The numerous mentions of paradoxes with the OR are probably more driven the fact that it is not logic-respecting than by its non-collapsibility. This also probably explains why some definitions of collapsibility proposed in the literature do not explicitly separate the notion of collapsibility and logic-respecting measure as they do not detail how weights are defined (see for example Definitions~\ref{def:collapsibility-huitfeldt} or \ref{def:collapsibility-didelez} in Appendix). All properties of this section are summarized in Table \ref{tab:small-summary-measures}.

\begin{figure}[!h]
	\begin{minipage}{.30\linewidth}
    \captionof{table}{\textbf{Causal measures and their properties}: highlighting the properties of collapsibility (Definition~\ref{def:indirect-collapsibility}) and logic respecting (Definition~\ref{def:logic-respecting}). An exhaustive table is available in Appendix (see Table~\ref{tab:list-measures-with-all-properties}).}
  \label{tab:small-summary-measures}
    \end{minipage}
    \hspace{0.3cm}
    \begin{minipage}{.65\linewidth}
 \begin{center}
\begin{tabular}{|
>{\columncolor[HTML]{ECF4FF}}c |
>{\columncolor[HTML]{E0FAE0}}c |
>{\columncolor[HTML]{E0FAE0}}c |}
\hline
\cellcolor[HTML]{CBCEFB}\textbf{Measure} & \cellcolor[HTML]{CBCEFB}\textbf{Collapsible} & \cellcolor[HTML]{CBCEFB}\textbf{Logic-respecting} \\ \hline
Risk Difference (RD)                                       & Yes                                          & Yes                                               \\
Number Neeeded to Treat (NNT)                                      & \cellcolor[HTML]{FCF1F1}No                                           & Yes                                               \\
Risk Ratio (RR)                                       & Yes                                          & Yes                                               \\
Survival Ratio (SR)                                       & Yes                                          & Yes                                               \\
Odds Ratio (OR)                                       & \cellcolor[HTML]{FCF1F1}No                   & \cellcolor[HTML]{FCF1F1}No                        \\ \hline
\end{tabular}

\end{center}

	\end{minipage}
\end{figure}



\subsection{Generalizability or portability of a causal measure}\label{subsec:first-time-generalization}

As highlighted above (Section~\ref{sec:formalization-and-key-contributions}), an RCT conducted in a population $P_{\text{\tiny S}}$  allows for the estimation of a treatment effect $\tau^{\text{\tiny S}}$ on this population. What would the result be if the individuals in the trial were rather sampled from a population $P_{\text{\tiny T}}$ with different baseline covariates distribution? 
%
This question is linked to external validity, and more precisely to a sub-problem of external validity being \textit{generalizability} or \textit{transportability}. We say that findings from a trial sampled from $P_{\text{\tiny S}}$ can be generalized to $P_{\text{\tiny T}}$ when $\tau^{\text{\tiny T}}$ can be estimated without running a trial on $P_{\text{\tiny T}}$, but only using data from the RCT and baseline information on the target population $P_{\text{\tiny T}}$ (the covariates $X$, and sometimes also the control outcome $Y^{(0)}$), as summarized on Figure~\ref{fig:observed-data}. 

\begin{figure}[!h]
	\begin{minipage}{.28\linewidth}
    \caption{\textbf{Generalization in practice}: We typically consider a situation where the treatment effect is estimated from a Randomized Controlled Trial (RCT) where individuals are sampled from a population $P_{\text{\tiny S}}$. When willing to extend these findings to $P_{\text{\tiny T}}$, we assume to have access to a representative sample of the patients of interest, with information on their covariates $P_{\text{\tiny T}}(X)$, and also \underline{maybe} the outcome under no treatment $P_{\text{\tiny T}}(X, Y^{(0)})$.}
    \label{fig:observed-data}
    \end{minipage}
    \hspace{0.8cm}
    \begin{minipage}{.70\linewidth}
    \centering
    \includegraphics[width= 0.98\textwidth]{fig/observed-data.png}
    \end{minipage}
\end{figure}



There exists two identification strategies, generalizing \textit{(i)} the conditional outcomes or \textit{(ii)} the local effect measure itself, leading to different assumptions required for generalizing.
For both strategies we consider the settings where information gathered on the source population covers at least the support of the target population. 

\begin{assumption}[Overlap or positivity]\label{a:overlap}
The support of the target population is included in the source population:
$\operatorname{supp}(P_{\text{\tiny T}}) \subset \operatorname{supp}(P_{\text{\tiny S}})$.
\end{assumption}


\subsubsection{Generalizing via a conditional-outcome model}\label{subsection:generalizing-conditional-expectation}
The rational is to generalize conditional expectations of the potential outcomes $\mathbb{E}_{\text{\tiny S}}\left[ Y^{(a)} \mid X\right]$ to the target population. This procedure is valid only under the following assumption.


\begin{assumption}[Transportability or S-ignorability or Exchangeability between populations]\label{a:transportability-wide}
for all $x$ in the support of both populations
$(\, \forall x \in \operatorname{supp}(P_{\text{\tiny T}}) \, \cap \, \operatorname{supp}(P_{\text{\tiny S}}), \; \forall a \in \{0,1 \})$, $$\mathbb{E}_{\text{\tiny S}}\left[ Y^{(a)} \mid X = x \right] = \mathbb{E}_{\text{\tiny T}}\left[ Y^{(a)} \mid X = x\right].$$
\end{assumption}
%\es{j'ai enlevé les a.s.: soit tu écris la formule avec des conditionnements par rapport à des variables aléatoires, auquel cas tu peux laisser a.s., soit tu écris pour tout $x$ et tu n'as pas besoin de a.s.}\bc{d'accord, merci Erwan !!}
This assumption\footnote{This assumption is also commonly found expressed as $Y^{(0)}, Y^{(1)} \indep  I \mid X$, where $I$ is an indicator of the population membership \citep{stuart2011use, pearl2015findings, lesko2017generalizing}. Such assumptions can also be expressed using selection diagram \citep{pearl2011transportability}.} boils down to: $X$ contains all the baseline covariates that are \textit{both} shifted between the two populations $P_{\text{\tiny R}}$ and $P_{\text{\tiny T}}$ \textit{and}  prognostic of the outcome.  
%\gv{Est ce que on a besoin de rentrer dans autant de détail sur les autres manières d'écrire l'hypothèse? Peut-être pour se prémunir d'un reviewer pointilleux (mais à stats in medicine, je ne vois pas ça), mais par contre cela rajoute de la longueur et des lourdeurs.} 
%With these two assumptions\gv{rephrase} any causal measure 
Such assumption enables the identification of $\tau^{\text{\tiny T}}$ using information from $P_{\text{\tiny S}}(X,A,Y)$ and only the covariates information in the target population $P_{\text{\tiny T}}(X)$.

\begin{proposition}[Generalizing conditional outcomes]\label{proposition:generalization-density}
Consider two populations $P_{\text{\tiny S}}$ and $P_{\text{\tiny T}}$ satisfying Assumptions~\ref{a:overlap} and \ref{a:transportability-wide}. Then, the conditional outcomes are generalizable:
\begin{align*}
    \forall a \in  \{0,1\}\, \quad \mathbb{E}_{\text{\tiny T}}\left[ Y^{(a)}\right] &=  \mathbb{E}_{\text{\tiny T}}\left[ \mathbb{E}^{\text{\tiny S}}\left[ Y^{(a)} \mid X\right]  \right] && \text{G-formula} \\
    &= \mathbb{E}_{\text{\tiny S}}\left[ \frac{p_{\text{\tiny T}}(X)}{p_{\text{\tiny S}}(X)}\mathbb{E}_{\text{\tiny S}}\left[ Y^{(a)} \mid X\right]  \right] %&& \text{Re-weighting.}
\end{align*}
where $\frac{p_{\text{\tiny T}}(X)}{p_{\text{\tiny S}}(X)}$ corresponds to the density ratio between the source and target populations.
Doing so, any causal measure $\tau^{\text{\tiny T}}$ can be identified from $P_{\text{\tiny S}}(X,A,Y)$ and $P_{\text{\tiny T}}(X)$ as any causal measure on the target population can be computed from the generalized outcomes $   \mathbb{E}_{\text{\tiny T}}\left[Y^{(0)} \right] $ and $   \mathbb{E}_{\text{\tiny T}}\left[Y^{(1)} \right] $.
\end{proposition}

Appendix~\ref{proof:generalizability-section-3} derives this result.
The first formula of proposition \ref{proposition:generalization-density} connects to a classic estimation strategy, plug-in g-formula \citep[see][for a review on the Risk Difference]{colnet2021causal}. Yet under these assumptions, estimation can also be performed by re-weighting the observations \citep{stuart2011use}. 
%(this is also highlighted when doing meta-analysis \citep{vo2019novel}).
%One can also find this method under the name Subgroup Mixable Estimation (SME) \citep{ding2016subgroup}.
%\jj{On va vérifier toutes les deux mais je pense que la deuxième c'est pas IPSW, ça serait la 2 dans l'approche 2}

\subsubsection{Generalizing a collapsible measure via local effects}\label{subsection:generalizing-local-effects}

When the measure is collapsible, rather than using a conditional outcome model, one can rely on the local effects $\tau^{\text{\tiny R}}(x)$ to get the target population's effect $\tau^{\text{\tiny T}}$, such as in Equation~\ref{eq:toy-example-standardization}. Importantly  Assumption~\ref{a:transportability-wide} can then be relaxed into a new, less restrictive, Assumption~\ref{a:transportability}.
%We call this procedure \underline{generalization by standardization} to refer to the principle of \cite{Rothman2000ModernEpidemiology}. 
%\subsubsection{What do we mean by generalizability?}
%Learning causal effect in one environment has interest when findings can be generalized to another population, in particular because most studies are conducted with the intention of applying the results elsewhere.
%\textit{Generalization} can also be found under the name \textit{Transportability}, \textit{Portability}, \textit{Recoverability}, and refers to the external validity of a study. 
%Generalization is what physician typically do, as they extend what they have learned through previous trials to a new population or a new patient.
%Finally, one concerns about causal effect measures is linked to their generalizability.  In other words, how far can an investigator extends his/her learning from a trial to another population of interest? Are there measures expected to more generalizable than others? This is particularly important as conclusions that are remembered and shared from clinical trial are causal, and therefore somehow considered as an invariant ground truth\footnote{We refer the reader to \cite{Pearl2000Book} (p. 182), talking about this practice: ``\textit{Once people interpret proportions as causal relations, they continue to process those relations by causal calculus and not by the calculus of proportions}".}. For example, let's consider that  a clinician has in mind the result from a trial conducted on a population with distribution $P_1$ stating that the efficacy of the drug if $\hat \tau_{\text{\tiny RR}} = 3$. But the clinician has patients that are following a different distribution $P_2$. A intuitive practice is to multiply the baseline of the patient $i$ by the risk ratio $\hat \tau_{\text{\tiny RR}}$ to obtain the estimated outcome under treatment for this patient. This process can be found under the name \textit{effect function} in \cite{Huitfeldt2021ShallWe}. Namely,\bc{Discussion avec Erwan, est-ce qu'on met du conditionnel?}
%\begin{equation*}
%    \mathbb{E}\left[ Y_i^{(1)} \right] =   \hat \tau_{\text{\tiny RR}}\,  \mathbb{E}\left[ Y_i^{(0)} \right].
%\end{equation*}
%If the clinician was rather provided a study with a risk difference, the process would be,
%\begin{equation*}
%    \mathbb{E}\left[ Y_i^{(1)} \right] =   \hat \tau_{\text{\tiny RD}} +   \mathbb{E}\left[ Y_i^{(0)} \right].
%\end{equation*}
%But, to me more or less accurate, this process require an homogeneity assumption:  \textit{(i)} Either the causal effect obtained from the trial $\hat \tau$ is assumed to be the same for every individual. In such situation, this process is accurate for every patient the clinician face, and also true for any population. \textit{(ii)}  Or, if the effect obtained from the trial $\hat \tau$ is expected to be true on average on $P_2$. Then, this process is accurate on average.
%While \textit{(i)} will guide us toward a strict version of generalizability, \textit{(ii)}  will require some additional assumptions. 
%In this Section we show how results from Section~\ref{section:generative-models} should encourage the usage of certain metrics rather than other to hope that such practice is not completely misleading.



%\begin{definition}[Generalizability by standardization]
%Let $\tau$ be a measure of effect and $X$ a set of baseline covariates. A treatment effect $\tau$ is said to be generalizable from a source population $P_{\text{\tiny S}}$ to a target population $P_{\text{\tiny T}}$ with respect to causal effect measure $\tau$, if there exists positive weights $w(X, P_{\text{\tiny S}}(X), P_{\text{\tiny T}}(X, Y^{(0)}))$ such that for all source distribution $P_{\text{\tiny S}}$ and target distribution $P_{\text{\tiny T}}$, 
%\begin{align*}
%\tau^{\text{\tiny T}} = \mathbb{E}_{\text{\tiny S}} \left[\tau^{\text{\tiny S}}(X)\, w(X, P_{\text{\tiny S}}(X), P_{\text{\tiny T}}(X, Y^{(0)})) \right].
%\end{align*}

%\end{definition}

\begin{assumption}[Transportability of the treatment effect]\label{a:transportability}
for all $x$ in the support of both populations $(\forall x \in \operatorname{supp}(P_{\text{\tiny T}}) \cap \operatorname{supp}(P_{\text{\tiny S}}))$, $$\quad \tau^{\text{\tiny S}}(x) = \tau^{\text{\tiny T}}(x).$$
\end{assumption}
Here, the transportability assumption\footnote{This assumption is also commonly found expressed as $Y^{(0)}- Y^{(1)} \indep I \mid X$ when it comes to the generalization of the risk difference ($I$ being an indicator of the population membership).
Note that the transportability assumptions conveys the idea of some homogeneity assumption (close to the spirit of Definition~\ref{def:homogeneity}). This is highlighted by \cite{huitfeldt2018choice} who refer to Assumptions~\ref{a:transportability-wide} and \ref{a:transportability} as ``\textit{different homogeneity conditions to operationalize standardization}".} can be phrased as: $X$ contains all the baseline covariates that are \textit{both} shifted between the two populations $P_{\text{\tiny R}}$ and $P_{\text{\tiny T}}$ \textit{and}  treatment effect modulators. %\es{jai repris la formulation d'au-dessus pour le lecteur, ça vous va? }\bc{parfait pour moi!}
%all treatment effect modulators of the treatment effect that are shifted between the two data sources are measured and used for adjustment.
  %In other words, it is possible to transport some information from the source population to the target because locally this information is the same. 
%\jj{c'est pas un théoreme la proposition 1?}
%\begin{proposition}[Non-collapsibility prevents generalizability]\label{prop:noncollaps-prevents-standardization}
   % Consider two population $P_{\text{\tiny S}}$ and $P_{\text{\tiny T}}$, and any causal measure $\tau$. If $\tau$ is not collapsible, then $\tau$ is not generalizable by standardization, even if Assumptions~\ref{a:transportability} and \ref{a:overlap} are granted.
%\end{proposition}\bc{Problème de preuve}
%But when collapsibility is granted, Assumption~\ref{a:transportability} and Assumption~\ref{a:overlap} license \jj{encore license?} generalizability of $\tau$ from $P_{\text{\tiny S}}$ to $P_{\text{\tiny T}}$.


\begin{proposition}[Generalizing local effects]\label{prop:generalization-of-local-effects}
Consider two population $P_{\text{\tiny S}}$ and $P_{\text{\tiny T}}$ and a causal measure satisfying Assumptions~\ref{a:overlap} and \ref{a:transportability}. If $\tau$ is collapsible, 

\begin{align*}
    \tau^{\text{\tiny T}}  &= \mathbb{E}_{\text{\tiny T}}\left[ g_{\text{\tiny T}}(Y^{(0)}, X) \tau^{\text{\tiny S}}(X)  \right] \\%&& \text{G-formula}\\
    &= \mathbb{E}_{\text{\tiny S}}\left[ \frac{p_{\text{\tiny T}}(X)}{p_{\text{\tiny S}}(X)} \, g_{\text{\tiny T}}(Y^{(0)}, X) \, \tau^{\text{\tiny S}}(X)  \right] && \text{Re-weighting.}
\end{align*}
where $\frac{p_{\text{\tiny T}}(X)}{p_{\text{\tiny S}}(X)}$ corresponds to the density ratio between the source and target populations and $g_{\text{\tiny T}}(Y^{(0)}, X)$ corresponds to the collapsibility weights of $\tau$ on the target population. Doing so, any collapsible causal measure can be identified from $P_{\text{\tiny S}}(X,A,Y)$ and $P_{\text{\tiny T}}(X, Y^{(0)})$ (if not directly collapsible).


\end{proposition}
%\jj{On a envie de savoir si ces poids on été exprimées pour toutes les mesures et si c'est estimable et implémenté? peut être dans ta partie géneralisation?}
Appendix~\ref{proof:generalizability-section-3} derives this result.
Here the first formula suggests the classical re-weighting estimation strategy also called IPSW (see  \cite{colnet2021causal} for a review on the Risk Difference).

\subsubsection{One assumption needs less covariates than the other}

The two above sections (\ref{subsection:generalizing-conditional-expectation} and \ref{subsection:generalizing-local-effects}) mirror each other with two different strategies relying on two different assumptions. However,
it is very important to note that \underline{Assumption~\ref{a:transportability} is lighter than Assumption~\ref{a:transportability-wide}} as highlighted in \cite{nguyen2018sensitivitybis, huitfeldt2018re, colnet2022sensitivity}.
As a consequence,
using local effects -- Proposition~\ref{prop:generalization-of-local-effects} -- as opposed to conditionnal-outcomes --Proposition~\ref{proposition:generalization-density} -- may allow generalizing a causal measure \emph{with less covariates}. This is at the cost of generalizing only collapsible measures (RD, RR, SR -- Table~\ref{tab:small-summary-measures}), and having access to $Y^{(0)}$ in the target population if the measure is not directly collapsible such as the RR and SR.
%In the worst case, covariates $X$ needed to ensure Assumption~\ref{a:transportability} are the same as Assumption~\ref{a:transportability-wide} (all shifted prognostic covariates being also modulator in the treatment effect scale chosen). %\bc{Still, moving from generalizing the densities to generalizing by standardization is not for free, as this also require that the treatment effect measure of interest has to be collapsible. }
%\jj{à la fin ici on a envie de redire quelles mesures est généralisable par standardizatiuon}
%Even if a strong generalizability is not possible, solutions can be proposed. When facing a distribution shift, a solution is to standardize the trial's findings toward a new population of interest. In particular, the intuition is that there exists a weight function $w$ such that $\tau_T = \mathbb{E}[\tau_R(X) w(X)]$, then, under the assumption that $\tau_R(x) = \tau_T(x)$ for all $x$, we obtain that $\tau_T =  \mathbb{E}[\tau_T(X) w(X)]$ is collapsible. Note that Using a ratio of proportion as weights for generalizability is only valid if the causal measure is directly collapsible. Otherwise, the weights to use should probably be a ratio involving elements that appear in the collapsible definition of the measure (see formula in Lemma~\ref{lemma:collapsibility-of-RR-SR}). \bc{J'ai laissé les remarques de Erwan ici.}
\paragraph{Final comment} %\es{on peut peut-être ajouter ici que chaque équation mène à des procédures d'estimations différentes et les détailler pour une mesure non collnon collapsible (en annexe). Je trouve toujours les calculs en note de bas de page difficile à lire}\bc{ok, je laisse pour qu'on en parle, je voulais mettre cela dans la partie simulation ?}
The two procedures are equivalent when it comes to the Risk Difference, thanks to the direct generalization of this measure and linearity of expectation,
\begin{equation}\label{eq:equivalence-risk-difference}
    \tau^{\text{\tiny T}}_{\text{\tiny RD}}  =\mathbb{E}_{\text{\tiny T}}\left[ g_{\text{\tiny T}}(Y^{(0)}, X) \tau^{\text{\tiny S}}_{\text{\tiny RD}}(X)  \right]= \mathbb{E}_{\text{\tiny T}}\left[ 1 \cdot \tau^{\text{\tiny S}}_{\text{\tiny RD}}(X)  \right] = \mathbb{E}_{\text{\tiny T}}\left[  \mathbb{E}_{\text{\tiny S}}\left[Y^{(1)} \mid X = x \right] \right] - \mathbb{E}_{\text{\tiny T}}\left[  \mathbb{E}_{\text{\tiny S}}\left[Y^{(0)} \mid X = x \right] \right].
\end{equation}
We discuss how to transform identification into estimation in the simulations' part (see Section~\ref{appendix:comments-on-estimation})


\section{Reverse the thinking: using working models}\label{section:generative-models}

%Without any assumption on the generative model, except a zero-mean error model, one can propose to consider the outcome $Y$ as being generated from a very general working model. 
We now propose to reverse the thinking: rather than starting from a given metric, we propose to reason from generic generative models (for continuous and binary outcomes). Such models allow us to disentangle covariates that affect only baseline level from those that modulate treatment effects. %\bc{je couperais la dernière phrase} Consequently, we express each causal measure as a function of the baseline and the treatment effect modulation, showing that some measures depend on the treatment effect only (and not on the baseline). 
%and observe what each metric expresses. Doing so, we are able to 
%
%The goal of this section is to introduce another deﬁnition of heterogeneity of effects, proposing to distentangle covariates affecting only baseline level and covariates modulating treatment effects. 
Such phenomenon
%(that we call disentanglement) 
will be used later on in Section~\ref{sec:generalization}  to determine which measures are easier to generalize.
%\es{j'ai modifié ici}\bc{ok! merci !}
%observe which transportability assumptions is more likely to hold.
Note that our generative models are very general, since no parametric assumptions are made. %Consequently, the conclusions drawn from our analysis are thought to be valid for a broad class of applications. 
As the models depend on the nature of the outcome considered, this section is organized accordingly.


%This will allow to explain how the subgroup effect from the illustrative example in Table~\ref{tab:introduction-diastolic} moves with baseline level.
%This enables to observe how causal measures are dependent (or not) with the baseline level. %distentangle covariates affecting only baseline level and covariates modulating treatment effects. %Doing so, we link the heterogeneity of effect (Definition~\ref{def:heterogeneity}) %: showing that some effects are heterogeneous when conditoned on any prognostic covariates, while some subgroups effects are only modulated along covariates modulators of the treatment effect.

%Finally, not that our generative models are very general, since no parametric assumptions are made. %Consequently, the conclusions drawn from our analysis are thought to be valid for a broad class of applications. %\jj{Il faut dire quand même ici encore à quoi ça te servira en particulier dans une section 5}
%As the models depends on the nature of the outcome considered, this section is organized accordingly.
%\jj{Ici dire le but de cette section déméler les effets} ok phrase ajoutée.
\subsection{Continuous outcomes}
%\es{j'intègrerais peut-être l'hypothèse dans le lemme 3 : dit comme cela, on ne voit pas très bien que c'est quelque chose de très générique, alors que l'hypothèse se traduit seulement par $\mathbb{E}[|Y^{(1)}| | X] < \infty$ et $\mathbb{E}[|Y^{(1)}| | X] < \infty$}
%Considering a continous outcome, one can figure out the problem as the one depicted on Figure~\ref{fig:alteration.png}: when facing a treatment or not, two possible expected responses are possible for individual with characteristics $X$. This idea is formalized in Lemma~\ref{lemma:working-model-continuous-Y}.
Considering a continuous outcome, using the binary nature of $A$ it is possible to decompose the response $Y$ in two parts: baseline level and modification induced by the treatment. Such decomposition is generic and does not rely on any parametric assumptions. 

\begin{lemma}
\label{lemma:working-model-continuous-Y}
Assuming that $\mathbb{E}\bigl[|Y^{(1)}| \,\bigl| X\bigr] < \infty$ and $\mathbb{E}\bigl[|Y^{(0)}|\, \bigl| X\bigr] < \infty$, there exists two functions $b, m:\mathcal{X} \to \mathbb{R}$ such that
 \begin{align*}
 Y^{(a)} = b(X) + a\,m(X) + \varepsilon_a,
 \end{align*}

 where $ b(X) :=\mathbb{E}[Y^{(0)} \mid X]$, $ m(X) :=\mathbb{E}[Y^{(1)}-Y^{(0)} \mid X]$ and a noise $\varepsilon_A$ satisfying $\mathbb{E}\left[ \varepsilon_A \mid X \right] = 0$ almost surely.
\end{lemma}
Proof is in appendix~\ref{proof:lemma:working-model-continuous-Y}. This result is related to the Robinson decomposition \citep{robinson1988semiparam}.
This model allows to interpret the difference between the distributions of treated and control groups as the alteration $m(X)$ of a generative model $b(X)$  by the treatment. The function $b$ corresponds to the \textbf{b}aseline, and $m$ to the \textbf{m}odifying function due to treatment. Figure~\ref{fig:alteration.png} gives the intuition backing Lemma~\ref{lemma:working-model-continuous-Y}.
Note that a very weak assumption suffices: a bounded outcome $Y$ --which is expected in clinical applications. 


\begin{figure}[!h]
    \begin{minipage}{.34\linewidth}
	\caption{\textbf{Intuition behind Lemma~\ref{lemma:working-model-continuous-Y}}: This illustration highlights that, for a given set of baseline covariates $X$, one can assume that there exist two functions accounting for the expected outcome value for any individual with baseline characteristics $X$. Then, it is possible to denote $m(X)$ as the alteration or \textbf{m}odification of the \textbf{b}aseline $b(X):=  \mathbb{E}[Y^{(0)} \mid X]$ response.}
	\label{fig:alteration.png}
    \end{minipage}%
    \hfill%
    \begin{minipage}{.65\linewidth}
    \includegraphics[width=0.8\textwidth]{fig/alteration.png}
    \end{minipage}
\end{figure}



From this non-parametric model, one can observe what each causal metric captures of these functions.
\begin{lemma}[Expression of the causal measures]\label{lemma:expression-of-causal-quantities-under-generative-model-continuous-outcome}
Under the assumptions of  Lemma~\ref{lemma:working-model-continuous-Y}, we have
 \begin{equation*}
     \tau_{\text{\tiny RD}}= \mathbb{E}\left[ m(X)\right],\qquad 
     \tau_{\text{\tiny RR}} = 1 + \frac{\mathbb{E}\left[m(X) \right]}{\mathbb{E}\left[b(X) \right]},\qquad \text{and}\quad 
     \tau_{\text{\tiny ERR}} = \frac{\mathbb{E}\left[m(X) \right]}{\mathbb{E}\left[b(X) \right]}.
 \end{equation*}
\end{lemma}
Proof is in appendix~\ref{proof:lemma-causal-quantities-continuous-outcome}. Lemma~\ref{lemma:expression-of-causal-quantities-under-generative-model-continuous-outcome} illustrates how the relative measures $ \tau_{\text{\tiny RR}}$ and $ \tau_{\text{\tiny ERR}}$ depend on both the effect $m(X)$ \textbf{and}  the baseline $b(X)$. On the contrary, $ \tau_{\text{\tiny RD}}$ is independent of the baseline.

%\paragraph{Comment on the non-parametric model for a continuous outcome}

\paragraph{Comment: Linear generative model} %\jj{je dirais plus un c as particulier est un modèle paramétriuque complètement linéaire et dans ce cas on retrouve}
    A decomposition such as in Lemma~\ref{proof:lemma:working-model-continuous-Y} is often used in the literature. For example, many applied works or introductory books \citep{angrist2008mostlyharmless} propose completely linear models such as
\begin{equation}\label{eq:typical-model-used-continuous-Y}
    \mathbb{E}[ Y \mid X, A] =  \beta_0 + \langle \boldsymbol{\beta}, \boldsymbol{X} \rangle  + A\,m,
\end{equation}
where $m(X) := m $ is a constant and $b(X)$ a linear model of the covariates. Assuming this model as the true generative model, Lemma~\ref{lemma:expression-of-causal-quantities-under-generative-model-continuous-outcome} leads to

 \begin{equation*}
     \tau_{\text{\tiny RD}}= m,\qquad 
     \tau_{\text{\tiny RR}} = 1 + \frac{m}{\beta_0 + \langle\boldsymbol{\beta}, \mathbb{E}\left[ X\right] \rangle},\qquad \text{and}\quad 
     \tau_{\text{\tiny ERR}} = \frac{m}{\beta_0 + \langle\boldsymbol{\beta}, \mathbb{E}\left[ X\right]\rangle}.
 \end{equation*}
%This illustrates the Lemma~\ref{lemma:expression-of-causal-quantities-under-generative-model-continuous-outcome} on a typical example.
As expected, one can recover that under such model, $  \tau_{\text{\tiny RD}}$ is homogeneous according to Definition~\ref{def:homogeneity}, while $ \tau_{\text{\tiny RR}}$ and $ \tau_{\text{\tiny ERR}}$ are not.
%This explain why, under appropriate causal assumptions and parametric (here linearity) assumption, the parameter $m$ is sometimes said to be causal.\\


%This highlights why \eqref{eq:typical-model-used-continuous-Y} ensures that under the RD measure the effect is homogeneous as it does not depend on $X$ anymore. \jj{là je te suis pas} \bc{oui pas clair}\bc{Marine dit qu'ici on a envie d'en savoir plus, sur comment "attraper" le m(X) quelque soit sa forme. "Regression adjustment"}
%Note that  Here we only highlight that very light assumptions are required. Also note that a usual assumption made is the one of treatment effect homogeneity along with a linear generative model, corresponding to
%\es{Peut-être écrire les mesures plus haut dans le cas de ce modèle linéaire, pour bien montrer que seul $\tau_{RD}$ est indépendant de $b$?}
%\jj{Ce qui manque c'est OK tu ecris RD, RR, ERR mais tu commentes pas, il faut des exemples, ça implique quoi en pratique selon les valeurs de baseline?} 

\subsection{Binary outcomes}

With binary outcomes, one cannot simply write the outcome model as a function of the baseline plus the treatment alteration,
%such as in Lemma~\ref{lemma:simplified-nonparametric-causal-model}
due to the fact that the  probability of an event ($Y=0$ or $Y=1$) is bounded by zero and one. 
%Or at least, this could be done, but the range of values of the modifying function $m(X)$ would depend on the baseline value $b(X)$. 
Figure~\ref{fig:alteration-binary.png} illustrates the situation.
As a consequence, another non-parametric generative model than Lemma~\ref{lemma:working-model-continuous-Y} is needed to disentangle baseline risk with treatment effect.
%Indeed, when considering a binary outcome and in practice, one can intuitively think of a treatment effect as the probability that the treatment can save (or kill) the patient or not.  %Can we propose a model that makes sense of such a principle? \jj{tu peux enlever la question? }
%\es{Il faudrait plutôt remplacer le "there exists a function" par for all $x$, for all $a \in \{0,1\},$ $0 < \mathbb{P}(Y^{(a)} = 1 \mid X=x) < 1$} 
\begin{figure}[H]
    \begin{minipage}{.35\linewidth}
	\caption{\textbf{Intuition for a binary outcome}: Symmetric illustration than the one proposed in Figure~\ref{fig:alteration.png}, but highlighting that for a binary outcome the quantity to consider is rather the conditional probabilities of the counterfactual events $\mathbb{P}[Y^{(a)}=1 \mid X] $. The two probabilities are bounded by $0$ and $1$.}
	\label{fig:alteration-binary.png}
    \end{minipage}%
    \hspace{2cm}
    \begin{minipage}{.6\linewidth}
    \includegraphics[width=0.85\textwidth]{fig/alteration-binary.png}
    \end{minipage}
\end{figure}


\subsubsection{Intuition of the entanglement model}%\gv{On devrait pas dire "entanglement" ici, plutôt que "intrication", sachant que "intrication", c'est un mot Français qui veut dire "entanglement"}
%Such models allow to disentangle the treatment effect from the baseline.
%This enables to analyze what each metric expresses of the effect, and in particular this puts in evidence that some measures grasp both the baseline and the effect, while only one measure only catch the effect of the treatment itself.
%Because the non-parametric model allowing to disentangle treatment effect from the baseline depends on the nature of the outcome, the generalizability properties one can not conclude on the properties of the measure only, but in the context of a certain outcome.
%Note that when using the term \textit{generative models}, we want to insist on the fact that those models do not rely on parametric assumption, and are thus valid in all generality.
%A by-product of our analysis is another way of understanding what heterogeneity means, not through the %lens of the metric, but through the lens of the working model.

 
To illustrate the workings of a binary-outcome model that disentangles the baseline risk with the effect of a treatment, we borrow the intuitive example of the Russian Roulette from \cite{Huitfeldt2019LessWrong}, further used by \cite{CinelliGeneralizing2019}.
When playing the Russian Roulette, everyone has the same probability of $1/6$ to die each time they play.
We know this because of the intrinsic mechanism of the Russian Roulette. 
Now, assume that we have not access to this information. 
In biology, medicine, or economy this is often the case, as the systems under study are too complex. 
Therefore, one has to empirically estimate this effect. 
%Somehow, we have the intuition that the treatment effect is \textit{homogeneous}, and that ideally some treatment effect measure should convey this phenonemon.
Consider a hypothetical randomized trial to estimate the effect of the Russian Roulette: a random set of individuals is forced to play Russian Roulette, and the others just wait.
For logistic reasons, the experiment is done on a certain time frame.
During this time frame, individuals can die from other reasons, such as diseases or poor health conditions.
For an individual with characteristics $x$, denoting $b(x)$ his/her probability to die without the Russian Roulette, and counting a death as $Y=1$ and survival $Y=0$, one has:
\begin{align}\label{eq:intuition-of-intrication}
    \mathbb{P}\left[ Y^{(a)} = 1 \mid X = x\right] &= b(x) + a\,\underbrace{\textcolor{RoyalBlue}{\left(1-b\left(x \right)\right)}}_\textrm{Entanglement}\, \frac{1}{6}.
\end{align}
This equation \footnote{This equation comes from $ \mathbb{P}\left[ Y^{(a)} = 1 \mid X = x\right] = \mathbb{P}\left[ Y^{(0)} = 1 \mid X = x\right] \cup \mathbb{P}\left[ Y^{(1)} = 1 \mid X = x\right] =  b(X) + 1/6 - (1/6)\cdot b(X)$.} simply states the fact that each individual $X=x$ has a certain probability to die $b(x)$ by default. When getting treatment, an individual can also die from Russian Roulette if affected in the treated group $a=1$, but only if not dead otherwise (see the multiplication by $\left(1-b(x)\right)$, while in the continuous outcome this was just the sum of the two effects).
In this equation, one can explicitly observe that the effect is \textit{entangled} with the baseline, due to the binary nature of the outcome. As a consequence, the risk difference no longer captures the modification as it was the case for a continuous outcome (see Lemma~\ref{lemma:expression-of-causal-quantities-under-generative-model-continuous-outcome}), but rather:
\begin{equation*}
    \tau_{\text{\tiny RD}} = \frac{1}{6}\left(1 - \mathbb{E}\left[b(x) \right]  \right), \quad \text{and in particular}\quad  \lim\limits_{\mathbb{E}[b(x)] \rightarrow 1} \tau_{\text{\tiny RD}} = 0.
\end{equation*}
The risk difference measured depends on the population's baseline. In a population with a high baseline, the measured effect vanishes along the risk difference scale.
In other words, it seems that when considering the RD, the effect of the treatment can only be observed on people that would not have died otherwise. 
This could seem a bit odd, as the Russian Roulette example contains the idea of an \textit{homogeneous} treatment effect, that should not vary over different populations. Still, one measure, the survival ratio, shows an interesting property,
\begin{equation*}
     \tau_{\text{\tiny SR}} = 1 - \frac{\mathbb{E}\left[\left( 1- b\left( X\right) \right) \frac{1}{6} \right]}{\mathbb{E}\left[\left( 1- b\left( X\right) \right) \right]} = \frac{5}{6}.
\end{equation*}
The Survival Ratio thus captures the idea of homogeneity: no matter the baseline risk, the Russian Roulette acts in the same way for everyone, as noticed by \cite{Huitfeldt2019LessWrong}. Appendix~\ref{appendix:more-details-on-the-intrication-model} explores this example in details.
%This property is interesting as one can \textit{remove} the baseline and only capture the effect of the Russian Roulette. %The consequence of SR is that it is making sense of the idea of homogeneity, while allowing to carry a truly causal effect (as a parameter) and not population's effect (in this example health conditions of individuals).
%Below, we propose a formalization of this intuition, into a model capturing all situations, especially both deleterious and positive effects.

\subsubsection{Formal analysis}
%Based on the previous intuition, we propose a non-parametric model that allows to model baseline risk and homogeneity (or not) of treatment effect. 
The intuitive model presented in \eqref{eq:intuition-of-intrication} does not allow catching all phenomena. In particular, we want to describe positive or deleterious effects of the treatment while Equation~\ref{eq:intuition-of-intrication} only describes harmful situations. %But in some real-world situations, treatment effect can go in different directions and be benefical.% For example the seat belts could be protective for taller individuals (mostly men) but could be deleterious for smaller individuals (mostly women). 
In addition, we want a model able to encode situations where there is heterogeneity of the treatment effect. E.g. stressed out people could have a higher effect of the Russian Roulette because the prospect of playing would create cardiac arrests. Or on a more concrete example: the seat belts could be protective for taller individuals but less protective (or even deleterious) for smaller individuals because of the design. 

\begin{lemma}[Entanglement Model]\label{lemma:intrication_model}%\gv{AMHA on retire "intrication" :)}
Considering a binary outcome $Y$, assume that 
\begin{equation*}
     \forall x \in \mathds{X},\, \forall a \in \{0,1\},\quad 0 < p_a(x) < 1,\quad \text{where } p_a(x)  :=  \mathbb{P}\left[Y^{(a)} = 1 \mid X=x\right].
 \end{equation*}
Introducing
\begin{equation*}
    m_g(x):= \mathbb{P}\left[ Y^{(1)} = 0 \mid Y^{(0)} = 1, X = x\right] \quad \text{and} \quad m_b(x):= \mathbb{P}\left[ Y^{(1)} = 1 \mid Y^{(0)} = 0, X = x\right],
\end{equation*}
allows to have
\begin{align*}
     \mathbb{P}\left[ Y^{(a)} = 1 \mid X = x\right]  &= b(x)+  a\, \left( \left( 1-b\left(x\right) \right) m_b\left(x\right) -  b\left(x\right)m_g\left(x\right) \right),\quad \text{where } b(x):=p_0(x).
\end{align*}
\end{lemma}
Proof is available in Appendix~\ref{proof:intrication_model}.
Usually $Y=1$ denotes death or deleterious events, therefore the subscripts $b$ (resp. $g$) stands for \textit{bad} (resp. \textit{good}) events. $m_b$ (resp. $m_g$) corresponds to  the probability that a person who was previously not destined (resp. destined) to experience the outcome, does (resp. does not) experience the outcome in response to treatment. They represent the outcome switch depending on the position at baseline\footnote{Such parameters can be found to be close to the “\textit{counterfactual outcome state transition}” (COST) in \cite{huitfeldt2018choice}. For example $m_b$ would correspond to the quantity denoted $1-H$. Also note that the intrication model also allows to apprehend what has been done by \cite{CinelliGeneralizing2019}, where the quantity they introduce being $PS_{01} := \mathbb{P}\left[ Y^{(1)} = 1 \mid Y^{(0)} = 0\right]$ corresponds to $m_b$. While their work mostly rely on the formalism of selection diagram, they define $PS_{01}$ (and therefore $m_b$) as the probability of fatal treatment among those who would survive had they not been assigned to for treatment. And conversely, $PS_{10} := \mathbb{P}\left[ Y^{(1)} = 0 \mid Y^{(0)} = 1\right]$ (corresponding to $m_g$) stands for the probability that the treatment is sufficient to save a person who would die if defined. As far as we understand, in both of these works these probabilities are not taken conditionally to $X$.}.
It is possible to propose an equivalent of Lemma~\ref{lemma:expression-of-causal-quantities-under-generative-model-continuous-outcome}.

\begin{lemma}[Expression of the causal measures]\label{lemma:expression-of-causal-quantities-under-generative-model-binary-outcome-intrication-model}
Ensuring conditions of Lemma~\ref{lemma:intrication_model} leads to,
\begin{equation*}
  \tau_{\text{\tiny RD}}= \mathbb{E}\left[ \left( 1-b\left(X\right) \right) m_b\left(X\right)\right] -  \mathbb{E}\left[ b\left(X\right)m_g\left(X\right) \right],\qquad 
     \tau_{\text{\tiny NNT}} =  \frac{1}{\mathbb{E}\left[ \left( 1-b\left(X\right) \right) m_b\left(X\right)\right] -  \mathbb{E}\left[ b\left(X\right)m_g\left(X\right) \right] }
\end{equation*}
 \begin{equation*}
     \tau_{\text{\tiny RR}} = 1  + \frac{ \mathbb{E}\left[  \left( 1-b\left(X\right) \right) m_b\left(X\right) \right] }{ \mathbb{E}\left[ b(X)\right]} - \frac{\mathbb{E}\left[ b(X) m_g\left(X\right)\right]}{\mathbb{E}\left[ b(X)\right]},\quad 
     \tau_{\text{\tiny SR}} = 1 - \frac{\mathbb{E}\left[ \left( 1-b\left(X\right) \right) m_b\left(X\right) \right]}{\mathbb{E}\left[ 1- b(X)\right]} + \frac{\mathbb{E}\left[ b\left(X\right)m_g\left(X\right) \right]}{\mathbb{E}\left[ 1- b(X)\right]},
 \end{equation*}

 \begin{equation*}
     \tau_{\text{\tiny OR}} =\frac{\mathbb{E}\left[ b(X) \right]+  \mathbb{E}\left[\left( \left( 1-b\left(X\right) \right) m_b\left(X\right) \right]-  \mathbb{E}\left[b\left(X\right)m_g\left(X\right) \right)\right] }{\mathbb{E}\left[ 1- b(X) \right] - \mathbb{E}\left[ \left( 1-b\left(X\right) \right) m_b\left(X\right)  \right]+  \mathbb{E}\left[b\left(X\right)m_g\left(X\right) \right] }  \frac{\mathbb{E}\left[1-b(X)\right]}{ \mathbb{E}\left[b(X)\right]} .
 \end{equation*}

\end{lemma}%\bc{C'est moche non ?}


Proof is detailed in appendix~\ref{proof:expression-of-causal-quantities-under-generative-model-binary-outcome-intrication-model}. 
%\jj{Là on ne sait plus où on va et ce qu'on doit retenir intérpréter?}
At first sight Lemma~\ref{lemma:expression-of-causal-quantities-under-generative-model-binary-outcome-intrication-model} appears to be very complex. Still, this allows to recover some intuitions. For example, if the treatment is always beneficial ($m_b(x)=0$), and assuming that $m_g(x)$ is lower bounded by a positive constant (i.e there is always a positive effect, even if small), then
\begin{equation*}
     \tau_{\text{\tiny NNT}} = \frac{1}{-  \mathbb{E}\left[ b\left(X\right)m_g\left(X\right) \right] }, \qquad \text{such that, } \lim\limits_{\mathbb{E}[b(X)] \rightarrow 0}  | \tau_{\text{\tiny NNT}} |  = \infty.
\end{equation*}
Recall that in the illustrative example of Table~\ref{tab:introduction-diastolic}, the Number Needed to Treat is way higher on the population with a low baseline. If the population is at low risk, the effect of a beneficial treatment is indeed perceived as very small\footnote{We recall that a high NNT corresponds to a small effect.} because individuals have already no reason to suffer from the outcome.
%does not appear to be much more simpler than the results under the logistic model (see Lemma~\ref{lemma:expression-of-causal-quantities-under-generative-model-binary-outcome}) \jj{c'est pour ça qu'il faut le mettre}. 
Lemma~\ref{lemma:expression-of-causal-quantities-under-generative-model-binary-outcome-intrication-model} can be simplified under some situations, in particular when only  monotonous effects are involved.


\subsubsection{Notion of monotonous effect}
We introduce the assumption of monotonous effects, where either $\forall x, m_b(x) = 0$ or $\forall x, m_g(x) = 0$ \citep{huitfeldt2018choice, CinelliGeneralizing2019}. Such situations corresponds to situation where the treatment is only beneficial or deleterious\footnote{In particular, the Russian Roulette corresponds to a situation where $\forall x, m_g(x) = 0$ (Russian Roulette makes no good).}, but cannot be both. If the treatment is always beneficial (i.e. $\forall x, m_b(x) = 0$) then the probability $p_1(x)$ is lower than the baseline. Respectively, if the treatment is always deleterious  (i.e. $\forall x, m_g(x) = 0$) then the probability $p_1(x)$ is higher than the baseline.
This can be summarized in,

\begin{align*}
    \mathbb{P}\left[ Y^{(a)} = 1 \mid X = x\right] &= b(x)\, \underbrace{+ \, a\,  \left( 1-b\left(x\right) \right) m_b\left(x\right)}_{\nearrow} \, \underbrace{- \,a\, b\left(x\right)m_g\left(x\right) }_{\searrow} ,
\end{align*}
where arrows indicate whether each term of the equation is increasing or decreasing the probability of occurrences.
This equation highlights that the entanglement is not the same depending on the nature of the treatment (deleterious or not). A beneficial effect ($m_b(x)=0$) is more visible on a high baseline population ($b(x)$ close to 1). On the opposite, a deleterious effect ($m_g(x)=0$) is visible only on the population with low baseline  ($1-b(x)$ close to 1). %All this reasoning can be made considering the situation as increasing occurences or not. 
In other words, an effect increasing the probability of occurences acts only on individuals on which occurences has not already happened yet. %\jj{un peu dure la phrase}\bc{mieux ? sinon je supprime. Moi j'aime bien cette lecture, mais c'est clairement pas necessaire}
%\es{Je suis d'accord avec le modèle :). Il faudrait rajouter une phrase pour faire le lien avec la roulette russe plus haut (justifier $m_g=0$) et mettre les calculs que tu as fait ci-dessous dans un joli Lemme.}

\begin{lemma}[Risk Ratio and Survival Ratio under a monotonous effect]\label{lemma:monotonous-effect}
Ensuring conditions of Lemma~\ref{lemma:intrication_model}, 



\begin{itemize}
    \item Assuming that the treatment is beneficial (i.e. $\forall x, m_b(x) = 0$), then

    \begin{equation*}
     \tau_{\text{\tiny RR}} = 1  - \frac{\mathbb{E}\left[  b(X) m_g(X)\right]}{\mathbb{E}\left[ b(X)\right]}.
 \end{equation*}

 \item  Assuming that the treatment is harmful (i.e. $\forall x, m_g(x) = 0$), then


 \begin{equation*}
     \tau_{\text{\tiny SR}} = 1  - \frac{\mathbb{E}\left[ \left( 1-b(X) \right) m_b(X)\right]}{\mathbb{E}\left[ 1-b(X)\right]}.
 \end{equation*}
\end{itemize}


 

\end{lemma}


%\jj{Ce qui me perturbe encore ici c'est que tu ne disantangle pas les effets si?}
Lemma~\ref{lemma:monotonous-effect} is still disappointing as it does not allow to disentangle baseline risk and treatment effect ($m_b(.)$ or $m_g(.)$) such as for the continuous outcome situation.
%Indeed, such result further highlights that for a population with similar baseline risks, then either the SR or the RR are taking simpler expressions.
Still, looking at local effect $x$, for example on the Risk Ratio scale, one has
\begin{equation*}
    \tau_{\text{\tiny RR}}(x) = 1-\frac{b(x)m_g(x)}{b(x)} = 1-m_g(x).
\end{equation*}
Therefore, if willing to compute subgroup effects on covariates $X$ affecting only the baseline level $b(.)$, one would observe a constant effect. %\es{on pourrait aussi dire qu'il suffit de faire des sous groupes telle que la baseline soit la même sur tous les sous-groupes}\bc{?}
This explains the illustrative example from Table~\ref{tab:introduction-diastolic}, where the Risk Ratio is constant over strata with varying baseline (here diastolic blood pressure).%, which also suggest a constant probability $m_g(x)$ over the baseline covariate of diastolic blood pressure.
%For example, considering a beneficial (resp. harmful) effect, and if there exist a subset of $X$, denoted $X_b$ only implied in the baseline risk $b(X_b)$, then $m_g(x)$ (resp. $m_b(x)$) is a constant (i.e. no modulation of the treatment effect) on the space $X_b$. 
%In other words, Lemma~\ref{lemma:monotonous-effect} confirms that Risk Ratio (resp. SR) is constant on these subgroups even if the baseline risk moves.
 %If the population concerned are such that $m_b(X)$ or $m_g(X)$ are constant (i.e. no modulation of the treatment effect), then either the RR or the SR takes a very simple value. For e.g. in the Russian Roulette case, the treatment effect increases the number of events, and is such that $m_g(X)=0$ and $m_b(X)$ is constant, such that the SR is an homogeneous measure (Definition~\ref{def:homogeneity}).
 
 These results formalize what has been proposed several times in the literature, for example by \cite{Sheps1958ShallWe}, and later by \cite{huitfeldt2018choice, Huitfeldt2021ShallWe}, or with what has been called the \textit{Generalised Relative Risk Reduction} \citep{baker2018new}. In particular, Sheps finishes her paper with the following quote
 \begin{quote}
   `` A beneficial or harmful effect may be estimated from the proportions of persons affected. The absolute measure does not provide a measure of this sort. The choice of an appropriate measure resolves itself largely into the choice of an appropriate base or denominator for a relative comparisons. [$\dots$] the appropriate denominator consists of the number of persons who could have been affected by the factor in question".
 \end{quote}
This recommendation is consistent with Lemma~\ref{lemma:monotonous-effect}. In other words, direction of the effect dictates on which labels the relative comparison should be made to obtain a treatment effect measure as less as possible entangled by the baseline. If the effect is harmful, this will be the SR (like the Russian Roulette). If the effect is beneficial, this is the RR. 
The comment of Sheps about absolute measure holds for binary outcome, but we showed that RD has good properties when considering a continuous outcome. Doing so, we justified and extended the scope of her conclusions. In other words, depending on the direction of the effect (harmful or beneficial) it is possible to define an equivalent of the Risk Difference for the continuous outcome, but in the world of binary outcome. Such definitions also enable a meaningful interpretation of what constitutes a homogeneous treatment effect when dealing with binary outcomes.. %Indeed, the well-known
%\jj{Il me faudrait une phrase soit avec un exemple, soit avec ce que tu me conseilles de faire en pratique}\bc{d'accord. Je t'avoue que je ne sais pas trop quoi faire de cette partie. Je la garde pour notre point. je me demande si il ne faut pas raccourcir cette partie pour faire une concusion générale apres}

\subsubsection{What about non-monotonous effect?}

While the situation of monotonous effect can lead to simpler expression of RR or SR, the situation remains complex when it comes to treatment being both beneficial and harmful (such as the seat belt example, and depending on the individuals). In fact, in such a situation $m_b(X)$ and $m_g(X)$ are not identifiable \citep{Pearl2000Book, huitfeldt2018choice}. As a consequence, the interesting model to consider would be

%\bc{ici j'aimerais bien aller relire qqch. je laisse un commentaire pour y penser}
\begin{equation*}
    \mathbb{P}\left[ Y^{(a)} = 1 \mid X = x \right] = b(x)\,+  a\, \tau(x), \quad \text{where } \tau(x):= \left( 1-b(x) \right) m_b(x)- b(x)m_g(x).
\end{equation*}
This expression is close to the generative model for a continuous outcomes (Lemma~\ref{lemma:working-model-continuous-Y}). Still, $\tau(x)$ now contains covariates linked to both baseline level and the treatment effect modulators. In such a situation, all measures now depend on the baseline level, and it is no longer possible to find a measure that decomposes baseline from the effect. 

\subsubsection{Why not a logistic model?} %\jj{Et il n'y a pas et quand un modèle logistique est adapté?? aussi}\bc{ajouté avec les avantages mis clairement}
A common practice is to adopt a logistic regression model (or any model encapsulating a function taking values in $\mathbb{R}$), for example a logistic model such as:
\begin{equation}\label{eq:typical-model-used-binary-Y-main}
   \operatorname{ln}\left( \frac{\mathbb{P}(Y^{(a)} = 1 \mid X)}{\mathbb{P}(Y^{(a)} = 0 \mid X) } \right) = \beta_0 + \langle \boldsymbol{\beta}, \boldsymbol{X} \rangle + A\,m.
\end{equation}
where $\beta_0, \boldsymbol{\beta}$ and $m$ are the coefficients of a linear model.
When the generative model from Equation~\ref{eq:typical-model-used-binary-Y-main} holds, some nice properties arise.
Notably, one can show that this implies constant conditional odds ratio $\tau_{\text{\tiny log-OR}} (x) = m$ and $\tau_{\text{\tiny OR}} (x) = e^{m}$. Beyond \eqref{eq:typical-model-used-binary-Y-main} it is possible to encapsulate non-parametric functions in the logit. Such decomposition is present in the literature \citep{Gao2021DINA} (and see Section~\ref{appendix:usual-point-of-view}, and in particular Lemma~\ref{lem:conditional-odds-ratio} for details).
%It would also have been possible to introduce two functions $b(.)$ and $m(.)$ encapsulated in the logistic model to extend the Equation~\ref{eq:typical-model-used-binary-Y-main} into a complete non-parametric spirit (see in Appendix the Lemma~\ref{lemma:generative-model-binary-Y}).
%We recall and describe such approach in Appendix. We show that such model can also be seen non-parametrically.  Such logistic models are often proposed as - \textit{under certain parametric assumption} - they enable a rather simple interpretation of the \underline{conditional} Odds Ratio (see Lemma~\ref{lem:conditional-odds-ratio} for a proof, or the proof for non-collapsibility of the OR in Section~\ref{proof:collapsibilty}) \citep{xiao2022IsORPortable}.
But interpretation of all other metrics than the conditional odds ratio is clearly not obvious (see Lemma~\ref{lemma:expression-of-causal-quantities-under-generative-model-binary-outcome} in Section~\ref{appendix:usual-point-of-view})
%, being the equivalent of Lemma~\ref{lemma:expression-of-causal-quantities-under-generative-model-continuous-outcome} for a logit model.
In other words, it seems that such logistic models are rather forcing all covariates and treatment to interact through the link function, preventing any simple interpretation of the causal measure (except conditional OR). This is even more problematic as the odds ratio is a non logic-respecting measure.
%While such model is well-known and largely used, we have found that such model rather entangle all prognostic covariates
%As an illustration, the equivalent of Lemma~\ref{lemma:expression-of-causal-quantities-under-generative-model-continuous-outcome} for a logit-linear model is complex and can not be easily interpreted (see Lemma~\ref{lemma:expression-of-causal-quantities-under-generative-model-binary-outcome}). In other words, it seems that such logistic model are rather forcing all covariates and treatment to interact through the link function. 
Finally, the logistic model is a very restrictive model, unable to describe accurately many real-life situation; for instance the Russian Roulette -- thought being simple -- cannot take simple or intuitive expressions in the logistic model approach:
%linked to the baseline risks (i.e. the probability of an event when no treatment is given, see $p_0(x)$) \jj{ce qui est entre parenthèse ça vient un peu tard car tu en parles depuis le début?} with the treatment effect itself. 
%To make sens of a physician intuition of a treatment effect being homogeneous on some population, 
%Finally, we want to highlight that the problem of the Russian Roulette -- thought being simple -- can not take simple or intuitive implementation in the regular logistic model approach (see details in Appendix, Section~\ref{appendix:link-intrication-Russian-Roulette}).
%\jj{Il m'en faut plus, on comprend pas assez le problème}
%\jj{et les metriques?}
\begin{equation*}
   \operatorname{ln}\left( \frac{\mathbb{P}(Y^{(a)} = 1 \mid X = x)}{\mathbb{P}(Y^{(a)} = 0 \mid X =x) } \right) = \operatorname{ln}\left( \frac{b(x)}{1-b(x)}\right)+ A\, \operatorname{ln}\left( \frac{\left(\frac{1}{6} + b(x) \right)}{1-\left(\frac{1}{6} + b(x))(1-b(x))\right)} \cdot \frac{1-b(x)}{b(x)} \right),
\end{equation*}
is the equivalent to Equation~\ref{eq:intuition-of-intrication}.
More details are provided in Appendix~\ref{appendix:link-intrication-Russian-Roulette}.
%Below, we propose another way to characterize the generative model of binary outcome. We name it \textit{intrication} model. The motivation is to \textit{(i)} recover a situation where an homogeneous treatment effect can be recovered if it exists \jj{pas facile de voir ce que tu veux dire}, and \textit{(ii)} where another metric than the conditional odds ratio has a simple interpretation. In particular, we will show that the \textit{intrication} model highlight how the RR and SR can convey true invariant of the generative models when it exists. \jj{ou là c'est abstrait ici tu veux dire quoi? }
%\jj{C'est bien! Le seul truc que je me demande c'est combien il vaut TauOR dans ce cas là? }\bc{vu par appel}


\section{Are some measures easier to generalize than others?}\label{sec:generalization}



Section~\ref{section:causal-metrics-properties} exposes two transportability assumptions depending on which conditional quantity from the source population is generalized: the conditional outcome (Assumption~\ref{a:transportability-wide}) or the local effect (Assumption~\ref{a:transportability}). 
The first approach assuming having observed all covariates being prognostic and shifted in the two populations, while the second approach only requires to adjust on all covariates modulating treatment effect and shifted.
%shifted covariates modulating the treatment effect on the chosen scale.
By disentangling the baseline level and the treatment effect, Section~\ref{section:generative-models} paves the way toward establishing which transportability assumption is more likely to hold, depending on the outcome nature and the causal measure considered. 
Recall that Assumption~\ref{a:transportability} means
\begin{equation*}
   \forall x \in \operatorname{supp}(P_{\text{\tiny T}}) \, \cap \, \operatorname{supp}(P_{\text{\tiny S}}), \quad   \tau^{\text{\tiny R}}(x) =  \tau^{\text{\tiny T}}(x).
\end{equation*}

If the outcome is continuous, Lemma~\ref{lemma:expression-of-causal-quantities-under-generative-model-continuous-outcome} ensures $\tau_{\text{\tiny RD}}(x) = m(x)$. Therefore, if considering a continuous outcome, Assumption~\ref{a:transportability} is satisfied as soon as we adjust on the shifted covariates implied in $m(.)$ (regardless of the covariates implied in the baseline level $b(.)$).\\

To formalize which covariates are implied in local treatment effect, we introduce notations to distinguish covariates status, either intervening on the baseline level or modulating the effect. %Following Section~\ref{section:generative-models}, we now understand the set of prognostic covariates $X$ 

%ici que les variables qui interviennent dans B et M. 
\begin{definition}[Two kind of covariates]\label{def:two-kind-covariates}
Recall that $b: \mathcal{X} \to \mathbb{R}$ and $m:  \mathcal{X} \to \mathbb{R}$ are defined in Lemma~\ref{lemma:working-model-continuous-Y} for a continuous outcome or in Lemma~\ref{lemma:intrication_model} (here, $m$ referring for $m_b$ and $m_g$). For all $J \subset \{1, \hdots, d\}$, we let $X_J$ the subvector of $X$ composed of components of $X$ indexed by $J$. Accordingly, we let $X_B$ (resp. $X_M$) the minimal set of variables involved in the function $b$ (resp. the function $m$), such that, for all $x \in \mathds{R}$,  
\begin{align*}
\mathbb{E}\left[b\left(X\right) | X = x \right] = \mathbb{E}\left[b\left(X\right) | X_B = x_B\right] \quad \textrm{and} \quad  \mathbb{E}\left[m\left(X\right) | X = x\right] =  \mathbb{E}\left[m(X) | X_M = x_M\right].
\end{align*}
\end{definition}
Then, within the set of baseline covariate $X$, some covariates may be shifted between the two populations or not. 
%\es{ici la définition est celle d'un shift univarié, on peut imaginer des cas où la structure de dépendance varie mais pas les distributions univariées}

\begin{definition}[Shifted covariates set]\label{def:shidted-covariates}
We let $\textrm{Sh} \subset \{1, \hdots, d \}$ the set of indices corresponding to the components of $X$ that are shifted between the source and the target population, that is, 
%for all $j \in \textrm{Shift}$, there exists $x_j \in \mathds{R}$ such that 
for all integrable function $f: \mathcal{X} \to \mathbb{R}$, almost surely, 
\begin{align*}
    \mathbb{E}^{\text{\tiny S}}[ f(X) | X_{Sh}] =  \mathbb{E}^{\text{\tiny T}}[ f(X) | X_{Sh}]
\end{align*}
%\begin{align*}
 %   p_{\text{\tiny S}}(x_j) \neq  p_{\text{\tiny T}}(x_j).
%\end{align*}
\end{definition}

Generalizing conditional outcomes requires to have access to all shifted prognostic covariates.

\begin{theorem}\label{theorem:all-covariates}
    Under the assumptions of Lemma~\ref{lemma:working-model-continuous-Y} or \ref{lemma:intrication_model}, for any causal measure, generalization of the conditional outcomes is possible if one has access to all shifted covariates of $X_{B\cup M}$, provided such a set satisfies the overlap assumption (Assumption~\ref{a:overlap}).
\end{theorem}

To illustrate what are the different covariate sets, we introduce the data generative model of the simulations (see Section~\ref{sec:simulations}), where we assume that six covariates are prognostic and that data are generated as
\begin{equation}\label{eq:simulation-continuous-generative-model}
    Y=b\left(X_1, X_2, X_3, X_4, X_5, X_6\right) + A\, m\left(X_1, X_2, X_5\right) + \varepsilon.
\end{equation}
 Doing so, $B=(1,2,3,4,5,6)$, and $M = (1,2,5)$. In addition, the two populations are constructed such that $X_1, \dots X_4$ are shifted covariates, but not $X_5, X_6$. Figure~\ref{fig:illustration-shifted} illustrates what shifted and non-shifted means.  Theorem~\ref{theorem:all-covariates} states that generalization of the conditional outcomes is possible when observing  $X_1, \dots X_4$.
 \begin{wrapfigure}{r}{0.38\textwidth}
\centering
    \includegraphics[width=0.35\textwidth]{fig/illustration-shifted.png}
    \caption{$2 \in \textrm{Shift}$, and $6 \not\in \textrm{Shift}$.}
    \label{fig:illustration-shifted}
\end{wrapfigure}
%\jj{Yes, je mettrais ça comme un théoreme!!!}hihi!
%Such approach does not put constraints on the properties of the causal measure such as collapsibility. 
Having access to all shifted prognostic covariates in the \underline{two} data samples seems challenging (and maybe too optimistic). This situation could explain all the numerous recent research works about sensitivity analysis when necessary covariates are not observed or partially observed when generalizing \citep{nguyen2018sensitivitybis, nie2021covariate, colnet2022sensitivity}. In such a context, Assumption~\ref{a:transportability} is appealing as it potentially reduces the needed covariates. 
In fact, not all measures can be easier to generalize than others.
%To keep general results forces to distinguish causal measures that are easier to generalize than others.
%But is is most likely that all baseline covariates between populations are shifted, and that many covariates are prognostic \jj{la phrase but me perturbe? tu veux dire quoi?}.
%We propose to define such situations in which less covariates are required for generalization. 

%Building on Section~\ref{section:generative-models}, we decompose the set of baseline covariates to distinguish the set of covariate $X_{\text{b}}$ being prognostic of the outcome, and  $X_{\text{\tiny m}}$ being covariates modulating treatment effect. More precisely, we say that  $b(X) = b(X_{\text{b}})$ and $m(X) = m(X_{\text{m}})$ for $b(.)$ and $m(.)$ being the non-parametric functions proposed in Lemma~\ref{lemma:expression-of-causal-quantities-under-generative-model-continuous-outcome} (continuous $Y$) or Lemma~\ref{lemma:intrication_model} (binary outcome). By definition $X = X_{\text{b}} \cup X_{\text{m}}$. While the most optimistic scenarii are that $X_{\text{m}} \subsetneq X$,  it is also possible that $X_{\text{m}} = X$.
%being coll why some measures can not be generalized by standardization due to their non-collapsibility (for e.g. Odds Ratio or Number Needed to Treat). Section~\ref{section:generative-models} shows us how one can think of a non-parametric model disentangling the baseline level and the treatment effect on the outcome. This puts in evidence that each of the treatment effect measures catches something different from the model. In particular, each of the measures contains the modifying part of the generative model $m(X)$, but some contains both parts $b(X)$ and $m(X)$. \jj{doit être dit avant le début de la section 4 sinon on ne sait pas où on va ni pourquoi} \\
\begin{theorem}\label{theorem:restricted-set-for-Y-continuous-RD}
Consider a continuous outcome $Y$. Under the assumptions of Lemma~\ref{lemma:working-model-continuous-Y}, observing  all shifted covariates of $X_{M}$ is sufficient for generalizing $\tau_{\text{\tiny RD}}$, provided such a set of covariates satisfies the overlap assumption (Assumption~\ref{a:overlap}).

\end{theorem}
Theorem~\ref{theorem:restricted-set-for-Y-continuous-RD} reveals that Assumption~\ref{a:transportability} is expected to be more likely to hold for the Risk Difference only. Back to \eqref{eq:simulation-continuous-generative-model}, one would require only $X_1$ and $X_2$ to generalize the Risk Difference. Willing to generalize Risk Ratio or Excess Risk Ratio would still require $X_1, X_2, X_3, X_4$ for identification, no matter the approach (generalizing conditional outcomes or local effects). %, while all other measures would require adjustment on all shifted covariates of $X_{B\cup M}$ (here $X_1, X_2, X_3, X_4$) no matter the identification strategies (generalizing conditional outcomes or local effects).

\begin{theorem}\label{theorem:restricted-set-for-Y-binary-SR-RR} 
Consider a binary outcome $Y$. Under Assumptions of Lemma~\ref{lemma:intrication_model}, if the effect is beneficial (resp. harmful), having access to all covariates $X_{M \cap \textrm{Sh}}$ that are shifted and  treatment effect modifiers and to the distribution $\mathbb{E}^{\text{\tiny T}}\left[ Y^{(0)} \mid X_{M \cap \textrm{Sh}} \right]$ in the target population is sufficient  for generalizing $\tau_{\text{\tiny RR}}$ (resp. $\tau_{\text{\tiny SR}}$), provided such a set of covariates satisfies the overlap assumption (Assumption~\ref{a:overlap}).
\end{theorem}
In the simulations (Section~\ref{sec:simulations}) we enrich the example of the Russian Roulette assuming that the effect of the Russian Roulette itself is modulated by baseline covariates.
We adapt the generative model of \eqref{eq:intuition-of-intrication} into
\begin{equation}\label{eq:simulation-binary-generative-model}
    \mathbb{P}\left[ Y^{(a)} = 1 \mid X = x \right] = b(X_1, X_2, X_3) + a\,\left(1-b\left(X_1, X_2, X_3\right)\right)\,m_b(X_2, X_3),
\end{equation}

where $X_1=\texttt{lifestyle}$, $X_2=\texttt{stress}$, and $X_3=\texttt{gender}$, a situation where individuals' baseline risk of death depends on their lifestyle, stress, and gender. We assume that the effect of the Russian Roulette can be modulated by stress (imagine individuals having a heart attack as soon as the gun is approaching their head) and gender (the executioner being more merciful when facing a women). We further assume that \texttt{gender} is the only covariate with no shift between the two populations. Therefore Theorem~\ref{theorem:restricted-set-for-Y-binary-SR-RR} tells us that the Survival Ratio can be generalized to another target population having at hand only \texttt{stress}, without adjusting on \texttt{lifestyle} and \texttt{gender}. Willing to generalize all other measures (no matter the method) would require \texttt{lifestyle} \underline{and} \texttt{stress}. \\

 

%\jj{est-ce qu'il faudrait pas un exemple pour voir qui est XM et XB dans le cas binaire comme l 'equation 8?}\bc{oui ! je peux remonter le coup du stress et la roulette russe :)}
Finally, note that if some measures are easier to generalize (i.e. needs less baseline covariates to adjust on), then a by-product of this result is that they should be less sensitive to a population's shift. \cite{Spiegelman2017Modeling} does mention that empirically the Risk Ratio seems to be more constant accross populations. The illustrative example (Table~\ref{tab:introduction-diastolic}) in introduction perfectly illustrates this phenomenon too.% We think that this should be further investigated, to confirm if what theory suggests is indeed recovered in nature.

%These lemmas are closed in the spirit to lemmas from \cite{huitfeldt2018choice} (and by the way, to obtain the lemma similar derivations as us are made, see Appendix 2 were we can find the intrication working model as an intermediate tool but without the X). Big difference is that we had the conditioning on $X$. A difference is that we claim that there is more chance that RR and SR are portable (equal in a different setting) because due to the intrication model and the Lemma, we need less covariates for standardization. We do not base this conclusion on the fact that intrication model contains a biological mechanism, even if we recognize that this model encode how a treatment effect on a binary outcome is perceived by a clinician better than logistic model family. Take-away: some homogeneity conditions can be proposed on the working model. If so, then it is possible to obtain one measure being strictly generalizable. The homogeneity conditions proposed in Section~\ref{sec:strict-generalizability} allows to link the homogeneity from Definition~\ref{def:homogeneity}, and with collapsibility to obtain one invariant causal measure. Interestingly, this can be seen on the working model.

\section{Illustration through simulations}\label{sec:simulations}

We use synthetic simulations to illustrate Theorems~\ref{theorem:all-covariates}, \ref{theorem:restricted-set-for-Y-continuous-RD}, and \ref{theorem:restricted-set-for-Y-binary-SR-RR}: that is different covariates sets are required to retrieve the target population effect depending on \textit{(i)} the causal measure of interest, \textit{(ii)} the nature of the outcome, and \textit{(iii)} the method to generalize. 
%In appendix we propose one additional simulation set-up, close to a stunning clinical questions from the 2000's: the effect of oral contraceptive on thrombosis (see Section~\ref{appendix:pill-scare-simulation}). 
Appendix~\ref{appendix:comments-on-estimation} gives comments on how to transform identification formula (see Propositions~\ref{proposition:generalization-density} and \ref{prop:generalization-of-local-effects}) into estimation. 
The code to reproduce the simulations is available on \href{https://github.com/BenedicteColnet/ratio-versus-difference}{github} (see repository \texttt{BenedicteColnet/ratio-versus-difference}).
 \begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\textwidth]{fig/simulations-continuous-April-2023.png}
    \caption{\textbf{Results of the simulations for a continuous outcomes}: where generative corresponds to \eqref{eq:simulation-continuous-generative-model}. Column 1 corresponds to generalizing conditional outcome, column 2 corresponds to generalizing local effect with the proper collapsibility weights. For these two approaches we use different covariates set, with \textcolor{Goldenrod}{\textbf{shifted treatment effect modulators}}($X_1$, $X_2$), \textcolor{RedOrange}{\textbf{shifted prognostic covariates}}($X_1$, $X_2$, $X_3$, and $X_4$), and all \textcolor{Mahogany}{\textbf{prognostic covariates}}  ($X_1$, $X_2$, $X_3$, $X_4$, $X_4$ and $X_6$). According to Theorems~\ref{theorem:all-covariates} and \ref{theorem:restricted-set-for-Y-continuous-RD}, only the Risk Difference can be generalized with a restricted covariates set. Simulations are performed with $1000$ repetitions, a source sample size of $500$ and target sample size of $1,000$. Estimation is performed with plug-in g-formula modeling all responses with an OLS approach.}
    \label{fig:simulations-continuous-Y}
\end{figure}




\subsection{Continuous outcome}
We propose a situation where the continuous outcome is generated from six baseline prognostic covariates $X_1, \dots X_6$ as detailed in \eqref{eq:simulation-continuous-generative-model}. More precisely, $B=(1,2,3,4,5,6)$, and $M = (1,2,5)$, while only covariates $X_1, X_2, X_3, X_4$ are shifted between $P_{\text{\tiny S}}$ and $P_{\text{\tiny T}}$. Both $b(.)$ and $m(.)$ are linear functions of the covariates. We adopt a plug-in g-formula estimation approach. Figure~\ref{fig:simulations-continuous-Y} presents results. As the outcome $Y$ is continuous, and according to Theorem~\ref{theorem:restricted-set-for-Y-continuous-RD}, we expect that only the Risk Difference $\tau_{\text{\tiny RD}}$ can be generalized using the shifted treatment effect modulators, namely $X_1$ and $X_2$. For this, both procedures (generalizing the conditional outcomes or the local effects) are equivalent due to the linearity of the expectation (the second row of Figure~\ref{fig:simulations-continuous-Y} is identical across procedures). We indeed observe that only the RD can be recovered with the smaller covariates set composed of shifted treatment effect modulators. All other causal measures require access to all shifted covariates of $X_{B\cup M}$. %We further added a third method\gv{Retrospectivement, je ne suis pas certain que cela soit utile. J'ai peur que cela dilue le message.} corresponding to a generalization of local effects with $g(X, P(X,Y^{(0)}))=1$. This is equivalent to a naive approach where the local effects are averaged without the proper collapsibility weights (third column of Figure~\ref{fig:simulations-continuous-Y}). This confirms that naively aggregating ratio can lead to a bias. 
Note that adding only shifted covariates seems to increase variance, while adding all prognostic covariates lead to more precision, in accordance with what is proposed in \cite{colnet2022reweighting} for the risk difference. 
%\jj{la figure n'est pas commentée}
%\jj{Tu ne dis pas ce que c'est le truc naive}



\subsection{Binary outcome}

For the binary outcome, we extend the Russian Roulette situation, introducing effects' heterogeneity. See \eqref{eq:simulation-binary-generative-model} for the generative model chosen with three prognostic covariates: \texttt{lifestyle}, \texttt{gender}, and \texttt{stress}. We assume that the source population $P_{\text{\tiny S}}$ contains the same proportion of men and women as in the target population $P_{\text{\tiny T}}$, but that the two other covariates (\texttt{lifestyle} and \texttt{stress}) are shifted. In particular, we suppose that $P_{\text{\tiny S}}$ is composed of more people with a good lifestyle but are very stressed, while in $P_{\text{\tiny T}}$ individuals have a poor lifestyle but a low stress. We therefore expect the effect of the Russian Roulette to be higher in the source population than in the target population due to both different baseline level and heterogeneity of treatment effect. 
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.90\textwidth]{fig/simulations-binary-April-2023.png}
    \caption{\textbf{Simulation with binary outcome $Y$}: for a monotonous and deleterious effect. Therefore conditions of Lemma~\ref{lemma:monotonous-effect} are satisfied, allowing to generalize the Survival Ratio with fewer covariates, and in particular only \textcolor{Goldenrod}{\textbf{shifted treatment effect modulators}}, here \texttt{stress}. Adding all \textcolor{RedOrange}{\textbf{shifted prognostic covariates}} (\texttt{stress} and \texttt{lifestyle}), or even more with all \textcolor{Mahogany}{\textbf{prognostic covariates}} (\texttt{stress, lifestyle,} and \texttt{gender}) enables generalization of all causal measures by generalization of the conditional outcome or re-weighting of local effect if possible (only for collapsible measures, namely RR, SR, and RD). %Most of the time, naively re-weighting local effects does not allow to retrieve the causal effect, see for example in the third column the NNT, OR, or RR. 
    On this simulation, estimation is done with IPSW estimator, source (resp. target) sample being of size $n=5\,000$ (resp. $m=20,000$), with $1000$ repetitions.} 
    \label{fig:simulations-binary-Y-russian-roulette}
\end{figure}


Doing so, Theorem~\ref{theorem:restricted-set-for-Y-binary-SR-RR} states that the Survival Ratio is identifiable having at hand only the covariate \texttt{stress} when generalizing local effects, while all other causal measures require to have access to all shifted prognostic covariates (\texttt{stress} and \texttt{lifestyle}). Simulations indeed confirm the model and results are exposed on Figure~\ref{fig:simulations-binary-Y-russian-roulette}, where the true effect is recovered with a smaller subset of covariates only for the SR. %As for the continuous outcomes we added a third column for a naive generalization of local effects, showing that most of the time this approach leads to biased estimates (see for example NNT or RR). 
Adding all shifted prognostic covariates allows to recover all effect measures, in particular generalizing conditional outcomes. Generalizing local effects work only for collapsible measure, information on $Y^{(0)}$ and with the appropriate weights (see RR, SR, and RD).


%\jj{Il faudra mettre une footnote qui pointe vers ton papier d'avant, pour dire attention quand on estimera par la suite, si on met plus de variables ça peut desfois améliorer la variance? }\bc{oui ! tout à fait. Je pensais dans la partie simulation. je déplace ton commentaire pour ne pas oublier.}

\section{Conclusion}


The choice of a population-level measure of treatment effect has been much debated. We bring a new argument: a well-chosen measure is easier to generalize to a population different from that of the initial study or to sub-populations, crucial to make decisions based on this measure. Indeed, as the probability of different outcomes often varies across individuals, the average treatment effect typically depends on the population considered. A \emph{collapsible} measure --such as the risk difference, the risk ratio or the survival ratio but not the odds ratio-- can be computed from local effects, on strata of the population. Reweighting these strata then adapts the measure to a new population. Stratification must be done along the individual's characteristics that modulate the probability of outcomes: treatment-effect modifying covariates. But less stratification is needed for a good choice of population-level measure, one that is not affected by covariates that modulated only the baseline risk, common to treated and non-treated individuals. We showed that if the outcome is continuous, then the Risk Difference only depends on the expectation of the modification, while the Risk Ratio or Excess Risk Ratio highly depends on the baseline (Lemma~\ref{lemma:expression-of-causal-quantities-under-generative-model-continuous-outcome} and Theorem~\ref{theorem:restricted-set-for-Y-continuous-RD}). But if the outcome is binary, relative measures such as the Risk Ratio or the Survival Ratio can remove the baseline level (Lemma~\ref{lemma:monotonous-effect} and Theorem~\ref{theorem:restricted-set-for-Y-binary-SR-RR}). The Risk Ratio is the appropriate measure when the effect is beneficial (i.e. reduces events), while the Survival Ratio has better properties when the effect is harmful (i.e. increases events). If the treatment is beneficial and harmful at the same time, none of the measures can remove the baseline level. Likewise, in the absence of the control outcome in the target population, any measure of treatment effect can be generalized through the conditional outcome, which however typically requires more covariates (Theorem~\ref{theorem:all-covariates}). %\gv{Todo: rajouter les ref des lemmes et equation}

So, which is the best measure to summarize a causal effect across a population but facilitate reasoning at the individual level? It depends. For continuous outcomes, the Risk Difference is not modulated by a varying baseline risk. For binary outcomes, prefer a Risk Ratio for beneficial effects and a Survival Ratio for harmful ones.


%Bullet points of what come into my mind into take home message and contribution and futur works, to reorganize, and need to add the story of deletarious or not effect
%\begin{itemize}
%\item With continuous outcome, RD could be seen as the measure to recommand as enjoying many nice property, directly collapsible, easily generalizable (without knowledge of Y(0)) using either only treatment effect modifiers that are shifted, or if we don't know which are the treatment effect modifier using all prognostic variables shifted (Note that it may impact the variance in estimation, cf Béné). The baseline and modulation effetcs are not mixed which may facilitate the interpretation of the causal measure. 
%\item With binary outcome, RR and SR can be seen has having more interesting properties: collapsible, the baseline and modulation of the effect can be disantangled \jj{En fait pas certaine...}, can be generalized by reweighting the effect if Y(0) is known and using less variables only treatment effect modifiers shifted or if Y(0) unknown can be generalized by condition outcome formulae with more variables. 
%\item As the litterature has focused on generalization of RD only, here we generalize all the other measures
%\item Coming back at table 1, our alternative way of thinking about heterogeneity can be understood as follow, RR manage to disantangle the effect between baseline and modifier of the effect and here is homogénéous, whereas RD just simply does not manage to disantangle the effetcs. 
%\item From an individual point of view, this mixing of baseline and modifier is not necessarely a bad thing
%\item Futur works involve looking at estimation, in particular for generalization of RR
%\item If the effect is no longer monotone, we are a bit lost....
%\item Contribution: unifying a large part of the litterature on the different metrics with the  suggestion of  a new model + linking collapsibility and a certain notion of generalization + discussing other generalization
%\item g-formula plus simple à la fin? pas de choix de variable à faire, moins difficile? car dure de savoir si modifiers ou non?, marche qu'on soit collapsible ou non
%\item je fais quoi quand je sais pas si l'effet est délétaire ou beneficique?
%\end{itemize}\bc{autre bullet point: extension à la survie ?}\bc{need for empirical assessment of these results looking at large trials. Luckyly, this assumptions could be tested.}
%In particular, we wonder whether some treatment effect measures are more or less sensitive to a change of distribution. In other words: What measure is equal in a different setting? The absolute augmentation of the deaths? Or its tripling? Or the division of survival?




\section*{Acknowledgments} 
First of all we would like to thank clinician François-Xavier \textsc{Ageron} who first raised our interest on generalizability and the choice of measure. %This highlights how interdisciplinarity research work can lead to original and fundamental research questions.
We also would like to thank fruitful discussions with our clinicians collaborators, in particular with François-Camille \textsc{Grolleau} and Raphaël \textsc{Porcher}.
We thank Maxime \textsc{Fosset} and Marine \textsc{Le Morvan} who gave precious comments on the manuscript. Thank you also to Wouter \textsc{van Amsterdam} for careful proofreading.
Finally, we would like to thank Anders \textsc{Huitfieldt}: his research papers (and blog articles) have been precious sources of inspiration for our work.







\bibliographystyle{chicago}
\bibliography{references}

\appendix





\newpage

\begin{center}
    {\Large \textbf{Appendix}}
\end{center}

\section{Treatment effect measures}\label{appendix:list-of-measures}

\textit{This section completes Section~\ref{sec:formalization-and-key-contributions} (and more specially Section~\ref{subsec:causal-measures-presentation}) by exposing the different treatment (or causal) effect measures.}

\subsection{A formal definition of a treatment or causal effect measure}

In this section we recall the definition of all measures used in this paper or that can be found in applied medical work.
As all of these measures correspond to a combination of the two potential outcomes expectations, such that the concept of causal effect measures could be written in a general way. This is not exposed in the main article, but a causal measure can be defined in a general way.

\begin{definition}[Causal effect measures -- \cite{Pearl2000Book}]\label{def:causal-measure}
Assuming a certain joint distribution of potential outcomes $P(Y^{(0)}, Y^{(1)})$, which implies that a certain treatment $A$ of interest is considered, we denote $\tau^P$ any functional of the joint distribution of potential outcomes. More precisely,

\begin{align}
\mathcal{P} \quad & \rightarrow \mathbb{R} \\
P(Y^{(0)}, Y^{(1)}) & \mapsto \tau^{P}
\end{align}
\end{definition}
This definition is also valid for any subpopulation, as for any baseline covariate $X$, $\tau^{P}(X)$ is defined as a functional of $P(Y^{(0)}, Y^{(1)}\mid X)$.
Note that this definition could admit many more causal measures than the one presented in this work.
Introducing a definition is meant for \textit{(i)} generality of the definition and \textit{(ii)} to highlight what kind of mathematical object is a causal measure. For instance, this definition highlights the fact that a so-called treatment or causal effect naturally depends on \emph{the population considered}.
The notation $\tau^{P}$ highlights this dependency. For lighter notation, and when there is no doubt on the population of interest, we will also denote this quantity without the superscript $\tau$. \\


\textit{Why do we say that those measures are causal?} Note that the same definition could have been made on the distribution $P(A,Y)$, comparing expectation on two distributions: $P(Y \mid A=1)$ and $P(Y \mid A=0)$. For example, within the statistical community, the odds ratio is often known as the strength of the association between two events, $A=1$ and $A=0$ and therefore defined as:

\begin{align*}
    OR := \frac{P(Y = 1 \mid A=1)}{P(Y = 0 \mid A=1)} \cdot \frac{P(Y = 0 \mid A=0)}{P(Y = 1 \mid A=0)}.
\end{align*}

In such a situation, the OR measure would be an associational measure and not a causal measure, except if there is no confounding in the distribution considered (for e.g. in the case of a Randomized Controlled Trial). To avoid discussion about confounding, in this paper we never consider distribution such as $Y \mid A, X$ or $Y \mid A$. We rather consider $Y^{(a)}  \mid X$. For any new reader discovering the potential outcomes framework, we refer to the first chapters of \cite{imbens2015causal} for a clear and complete exposition of this notations inherited from Neyman. Note that \cite{Didelez2021collapsibility} make the same distinction when discussing collapsibility questions.

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.45\linewidth}
\includegraphics[width=\linewidth]{fig/RD-plot.png}
\caption{\textbf{Risk Difference (RD)}}\label{fig:RD}
\end{subfigure}%
\hspace{1cm}
\begin{subfigure}{.45\textwidth}% glorified minipage
\includegraphics[width=\linewidth]{fig/NNT-plot.png}
\caption{\textbf{Number Needed to Treat (NNT)}}\label{fig:NNT}
\end{subfigure}%
\\
\vspace{0.5cm}
\begin{subfigure}{.45\linewidth}
\includegraphics[width=\linewidth]{fig/RR.png}
\caption{\textbf{Risk Ratio (RR)}}\label{fig:RR}
\end{subfigure}%
\hspace{1cm}
\begin{subfigure}{.45\linewidth}% glorified minipage
\includegraphics[width=\linewidth]{fig/SR.png}
\caption{\textbf{Survival Ratio (SR)}}\label{fig:SR}
\end{subfigure}%
\\
\vspace{0.5cm}
\begin{subfigure}{.45\linewidth}
\includegraphics[width=\linewidth]{fig/odds-plot.png}
\caption{\textbf{Odds Ratio (OR)}}\label{fig:OR}
\end{subfigure}%
\hspace{1cm}
\begin{subfigure}{.45\linewidth}% glorified minipage
\includegraphics[width=\linewidth]{fig/log-odds-plot.png}
\caption{\textbf{Log Odds Ratio (log-OR)}}\label{fig:logOR}
\end{subfigure}%
\\
\vspace{1cm}
\begin{minipage}{0.39\textwidth}
\caption{\textbf{Plots of the ranges of the different metrics as a function of the proportion of events in control group}, namely $\mathbb{E}[ Y^{(0)}]$ (x-axis), and of the proportion of events in treated group, namely $\mathbb{E}[ Y^{(1)}]$ (y-axis). See Subfigure~\ref{fig:how-to-read}. As both the colors and the different scale illustrate, the ranges of the effect considerably differ with the metric chosen. Note that for the NNT (Figure~\ref{fig:NNT}) we only represented the quarter of the plot when an event encodes death as usually done in the medical field, with threshold at 20 for readability of the scale. Similar plots can be found under the name "\textit{L'Abbé plots}" \citep{Labbe1987MetaAnalysis, Jimnez1997GraphicalDisplayUseful,Deeks2022IssuesInSelection} in research works related to meta-analysis. In this domain those plots help representing estimates from different studies.}\label{fig:big-plot-with-all-metrics}
\end{minipage}
\begin{minipage}{0.59\textwidth}
  \begin{flushright}
    \begin{subfigure}{0.99\linewidth}
\centering
\includegraphics[width=\textwidth]{fig/how-to-read.png}
\caption{\textbf{Legend}}\label{fig:how-to-read}
\end{subfigure}%
  \end{flushright}
\end{minipage}
\end{figure}



\subsection{Common treatment effect measures}

As highlighted by Definition~\ref{def:causal-measure}, many measures could be proposed. Here we detail common measures found in applied works and propose an illustration for the case of binary outcomes (Figure~\ref{fig:big-plot-with-all-metrics}). 
Most of the time, the distinction is made on whether or not the measure is an absolute or a relative effect.

\subsubsection{Absolute measures}

\begin{definition}[Risk Difference (RD)]
The risk difference is a causal effect measure defined as the difference of the expectations (also called risks),

\begin{equation*}
    \tau_{\text{\tiny RD}} = \mathbb{E}[Y^{(1)}] - \mathbb{E}[Y^{(0)}].
\end{equation*}

%Note that the risk difference can also be written, $\tau_{\text{\tiny RD}} = \mathbb{E}[ Y^{(1)} - Y^{(0)}] = \mathbb{P}[Y^{(1)} = 1] - \mathbb{P}[Y^{(0)} = 1]$.
\end{definition}
RD is also named Absolute Risk Reduction (ARR), Absolute Effect (AE), Absolute Difference (AD), or Excess Risk (ER).



\begin{definition}[Number Needed to Treat (NNT)]\label{def:nnt}

The number needed to treat (NNT) is a causal effect measure defined as the average number of individuals or observations who need to be treated to prevent one additional outcome,

\begin{equation*}
  \tau_{\text{\tiny NNT}}  = \frac{1}{\mathbb{E}[Y^{(1)}= 1] - \mathbb{E}[Y^{(0)}=1]}
\end{equation*}

\end{definition}
 The Number Needed to Treat (NNT) has been proposed as a measure rather recently \citep{Laupacis1988AnAssessmentOfClinically}. A harmful treatment is usually called the Number Needed to Harm (NNH) and made positive.

\subsubsection{Relative measures}

\begin{definition}[Risk Ratio]
The risk ratio is a causal effect measure defined as the ratio of the expectations,

\begin{equation*}
     \tau_{\text{\tiny RR}} = \frac{\mathbb{E}[Y^{(1)}]}{\mathbb{E}[Y^{(0)}]} 
\end{equation*}

\end{definition}

The Risk Ratio (RR) is also named Relative Risk (RR), Relative Response (RR), or Incidence Proportion Ratio (IPR)

\begin{definition}[Survival Ratio]
The survival ratio is a causal effect measure defined as the Risk Ratio were labels are swapped,

\begin{equation*}
     \tau_{\text{\tiny SR}} = \frac{1-\mathbb{E}[Y^{(1)}]}{1-\mathbb{E}[Y^{(0)}]} 
\end{equation*}

\end{definition}

It is possible to introduce a measure that captures both the Risk Difference, but normalized by the baseline.


\begin{definition}[Excess relative risk (ERR)]

\begin{equation*}
  \tau_{\text{\tiny ERR}}  = \frac{\mathbb{E}[Y^{(1)}] - \mathbb{E}[Y^{(0)}]}{\mathbb{E}[Y^{(0)}]}
\end{equation*}

\end{definition}

The Excess relative risk (ERR) has been proposed by \cite{cole1971attributable}. Note that,

\begin{equation*}
    \tau_{\text{\tiny ERR}}   = \tau_{\text{\tiny RR}} - 1 .
\end{equation*}


\begin{definition}[Relative Susceptibility (RS)]
\begin{equation*}
    \tau_{\text{\tiny RS}}  := \frac{\mathbb{E}[Y^{(1)}] - \mathbb{E}[Y^{(0)}]}{1-\mathbb{E}\left[Y^{(0)}\right]}.
\end{equation*}
\end{definition}

Note that,

\begin{equation*}
      \tau_{\text{\tiny RS}} =  1 - \tau_{\text{\tiny SR}}.
\end{equation*}

Finally, another measure is often used based on odds. Odds are a way of representing probability in particular for betting. For example a throw with a die will produce a one with odds 1:5. The odds is the ratio of the probability that the event occurs to the probability it does not. 


\begin{definition}[Odds Ratio (OR)]
The odds ratio is a causal effect measure defined as the ratio of the odds of the treated and control groups,
\begin{equation*}
     \tau_{\text{\tiny OR}} := \frac{\mathbb{P}[Y^{(1)} = 1]}{1-\mathbb{P}[Y^{(1)} = 1]}\, \left(  \frac{\mathbb{P}[Y^{(0)} = 1]}{1-\mathbb{P}[Y^{(0)} = 1]}\right)^{-1}.
\end{equation*}

\end{definition}
Odds Ratio (OR) is sometimes named Marginal Causal Odds Ratio (MCOR). This is by opposition to a conditional Odds Ratio, being defined as,


\begin{equation*}
     \tau_{\text{\tiny OR}}(X) := \frac{\mathbb{E}[Y^{(1)} = 1 \mid X = x]}{1-\mathbb{E}[Y^{(1)} = 1\mid X = x]}\, \left(  \frac{\mathbb{E}[Y^{(0)} = 1\mid X = x]}{1- \mathbb{E}[Y^{(0)} = 1\mid X = x]}\right)^{-1},
\end{equation*}

often used due to its homogeneity when considering a logistic generative model of the outcome (see Section~\ref{proof:non-collapsibility-OR} for a detailed proof).
The OR is known to approximate the RR at low baseline (see for example the illustrative example of Table~\ref{tab:introduction-diastolic}).


\begin{proof}
{\footnotesize {\color{Blue} 
    $
   \mathbb{P}[Y^{(1)} = 1] \le \mathbb{P}[Y^{(0)} = 1] \ll 1 \implies \tau_{\text{\tiny OR}}  = \frac{\mathbb{P}[Y^{(1)} = 1]}{1-\mathbb{P}[Y^{(1)} = 1]}\cdot  \frac{1-\mathbb{P}[Y^{(0)} = 1]}{\mathbb{P}[Y^{(0)} = 1]} \approx\frac{\mathbb{P}[Y^{(1)} = 1]}{1}\cdot \frac{1}{\mathbb{P}[Y^{(0)} = 1]} =  \tau_{\text{\tiny RR}}$. }}
\end{proof}

These derivations can be found as late as in the 50's in case-control studies about lung cancer \citep{cornfield1951method}.
Also note that,


\begin{equation*}
    \tau_{\text{\tiny OR}} = \tau_{\text{\tiny RR}} \cdot \tau_{\text{\tiny SR}}^{-1} .
\end{equation*}


\begin{proof}

{\footnotesize {\color{Blue} 
    \begin{align*}
           \tau_{\text{\tiny OR}}  &= \frac{\mathbb{P}[Y^{(1)} = 1]}{1-\mathbb{P}[Y^{(1)} = 1]}\, \left(  \frac{\mathbb{P}[Y^{(0)} = 1]}{1-\mathbb{P}[Y^{(0)} = 1]}\right)^{-1} \\
           &= \frac{\mathbb{P}[Y^{(1)} = 1]}{\mathbb{P}[Y^{(1)} = 0]}\, \left(  \frac{\mathbb{P}[Y^{(0)} = 1]}{\mathbb{P}[Y^{(0)} = 0]}\right)^{-1}\\
           &=  \frac{\mathbb{P}[Y^{(1)} = 1]}{\mathbb{P}[Y^{(1)} = 0]}\,  \frac{\mathbb{P}[Y^{(0)} = 0]}{\mathbb{P}[Y^{(0)} = 1]}\\
           &= \frac{\mathbb{P}[Y^{(1)} = 1]}{\mathbb{P}[Y^{(0)} = 1]}\,  \frac{\mathbb{P}[Y^{(0)} = 0]}{\mathbb{P}[Y^{(1)} = 0]} \\
           &=  \tau_{\text{\tiny RR}} \cdot \tau_{\text{\tiny SR}}^{-1} 
    \end{align*}
    }}
\end{proof}

One can observe on Figure~\ref{fig:big-plot-with-all-metrics} (see subplots Figures~\ref{fig:OR} and \ref{fig:logOR}) the range on which the OR varies depends on the direction of the effect. Therefore, the OR is often presented encapsulated in a logarithm.
\begin{definition}[Log Odds Ratio (log-OR)]
    \begin{equation*}
        \tau_{\text{\tiny log-OR}}  := \operatorname{log}\left( \frac{\mathbb{P}[Y^{(1)} = 1]}{\mathbb{P}[Y^{(1)} = 0]}\right) - \operatorname{log}\left( \frac{\mathbb{P}[Y^{(0)} = 1]}{\mathbb{P}[Y^{(0)} = 0]}\right)
    \end{equation*}
\end{definition}





\section{Definitions found in the literature}\label{appendix:other-formal-definitions}

This section completes Section~\ref{section:causal-metrics-properties} (and in particular Sections~\ref{subsec:homogeneity} and \ref{subsec:collapsibility}) with formalization of homogeneity of effects, heterogeneity of effects, and collapsibility we have found in the literature. Doing so, we highlight that definitions can be more or less formal, and therefore can lead to different apprehension of phenomenons, in particular collapsibility. The Definitions we propose in Section~\ref{section:causal-metrics-properties} aims to account for the intuitions behind all previously proposed definitions, while uniformizing them.


\subsection{Effect modification}

\textit{This section supports definitions proposed in Section~\ref{subsec:homogeneity}.}

Note that effect modification or heterogeneity is mentioned in many places, but now always clearly defined.

\begin{quote}
    We searched the National Library of Medicine Books, National Library of Medicine Catalog, Current Index to Statistics database, ISI web of science, and websites of 25 major regulatory agencies and organizations for papers and guidelines on study design, analysis and interpretation of treatment effect heterogeneity. Because there is not standard terminology for this topic, a structured search strategy was not sensitive nor specific and we found many resources through “snowball” searching, that is, reviewing citations in, and citations of, key methodological and policy papers. -- \citep{lesko2018considerations}
\end{quote}

\subsubsection{Definitions found in the literature}

\begin{definition}[\cite{Rothman2011bookEpidemiologyIntrod}, page 51]\label{def-heterogeneity-Greenland}
    Suppose we divide our cohort into two or more distinct categories, or strata. In each stratum, we can construct an effect measure of our choosing. These stratum-specific effect measures may or may not equal on another. Rarely would we have any reason to suppose that they do equal one another.
    If indeed they are not equal, we say that the effect measure is \textit{heterogeneous} or \textit{modified} across strata.
    If they are equal we say that the measure is \textit{homogeneous}, \textit{constant}, or \textit{uniform} across strata.
    A major point about effect-measure modification is that, if effects are present, it will usually be the case that only one or none of the effect measures will be uniform across strata.
\end{definition}


\begin{definition}[\cite{VanderWeele2007FourTypes}]\label{def-VanderWeele2007FourTypes}
We say that a variable $Q$ is a treatment effect modifier for the causal risk difference of $A$ on $Y$ if $Q$ is not affected by $A$ and if there exist two levels of $A$, $a_0$ and $a_1$, such that $\mathbb{E}\left[ Y^{(a_1)}   \mid Q = q\right]-\mathbb{E}\left[ Y^{(a_0)}   \mid Q = q\right]$ is not constant in $q$.
\end{definition}


\subsubsection{Effect heterogeneity depends on the chosen scale: an illustration}

A treatment effect heterogeneity depends on the causal measure $\tau$ chosen (the scale). 
This idea is well-known in epidemiology \citep{Rothman2011bookEpidemiologyIntrod, lesko2018considerations}.
To be convinced by such phenomenon, the drawing in Figure~\ref{fig:hetero-schematic} illustrates what could be two data generative models leading to two different homogeneity and heterogeneity patterns.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{fig/hetero-schematic.png}
    \caption{\textbf{Heterogeneity of a treatment effect depends on the scale}: Illustrative schematics where the data generative model on the left leads to a constant treatment effect on the absolute scale (RD) when conditioning on $X$, while on the data generative model on the right leads to an homogeneous treatment effect on the relative scale (RR). In both of the situations, homogeneity of treatment effect of one scale (RR or RD) leads to heterogeneity on the other scale. Note that a similar schematic is presented in \cite{Rothman2011bookEpidemiologyIntrod} (see their Figure 11–1, p. 199)}
    \label{fig:hetero-schematic}
\end{figure}


\subsection{Different definitions of collapsibility in the literature}


\textit{This section supports definitions proposed in Section~\ref{subsec:collapsibility}.}
\subsubsection{Unformal definitions}
We have found many unformal definitions in the literature, such as:

\begin{quote}
    In a single study with a non-confounding stratification variable, if the stratum-specific effects are homogenous, then they are expected to be the same as the crude effect, a desirable property known as collapsibility of an effect measure.  -- \citep{xiao2022IsORPortable}
\end{quote}


\begin{quote}
    RR but, not OR, have a mathematical property called collapsibility; this means the size of the risk ratio will not change if adjustment is made for a variable that is not a confounder. -- \citep{Cummings2009RelativeMeritsRRAndOR}
\end{quote}


and

\begin{quote}
    Collapsibility means that in the absence of confounding, a weighted average of stratum-specific ratios (e.g., using Mantel-Haenszel methods) will equal the ratio from a single 2 by 2 table of the pooled (collapsed) counts from the stratum-specific tables. This means that a crude (unadjusted) ratio will not change if we adjust for a variable that is not a confounder.  -- \citep{Cummings2009RelativeMeritsRRAndOR}
\end{quote}


\subsubsection{Formal definitions}
\begin{definition}[Strict collapsibility \cite{pearl1999collapsibility}]\label{def:strict-collaps-pearl-greenland}
We say a measure of association between $ Y^{(0)}$ and $ Y^{(1)}$ is strictly collapsible accross $X$ if it is constant accross the strata (subtables) and this constant value equals the value obtained from the marginal table.
\end{definition}
Similar definition as Definition~\ref{def:strict-collaps-pearl-greenland} have been proposed in \cite{liu2022correct, Didelez2021collapsibility}.
\begin{definition}[\cite{Pearl2000Book}]\label{def:collapsibility-pearl}
Let $\tau \left(P\left( Y^{(0)}, Y^{(1)} \right) \right)$ be any functional that measures the association between $Y^{(0)}$ and $Y^{(1)}$ in the joint distribution  $P\left( Y^{(0)}, Y^{(1)} \right)$. We say that $\tau$ is collapsible on a variable $V$ if

\begin{align*}
    \mathbb{E}\left[ \tau \left(P\left( Y^{(0)}, Y^{(1)} \mid V \right)  \right) \right] = \tau \left(P\left( Y^{(0)}, Y^{(1)} \right) \right)
\end{align*}
\end{definition}

Note that in his book, Judea Pearl rather present the definition of collapsibility with respect two any two covariates, not necessarily potential outcomes. Indeed, collapsibility is a statistical concept at first. As in this work we are explicitely concerned with causal metrics, this definition has been written here with potential outcomes.

\begin{definition}
[\cite{Huitfeldt2019collapsible}]\label{def:collapsibility-huitfeldt}
Let $\tau \left(P\left( Y^{(0)}, Y^{(1)} \right) \right)$ be any function of the parameters $Y^{(0)}$ and $Y^{(1)}$ in the joint distribution $P\left( Y^{(0)}, Y^{(1)} \right)$. We say that $\tau$ is collapsible on a variable $V$ with weights $w_v$ if,

\begin{align*}
    \frac{\sum_v w_v \tau \left(P\left( Y^{(0)}, Y^{(1)} \right) \mid V = v \right)}{\sum_v w_v} &= \tau \left(P\left( Y^{(0)}, Y^{(1)} \right) \right)
\end{align*}
 \end{definition}



\begin{definition}[\cite{Didelez2021collapsibility}]\label{def:collapsibility-didelez}
Let $\tau=\tau \left(P\left( Y^{(0)}, Y^{(1)} \right) \right)$ be a measure of association between $Y^{(0)}$ and $Y^{(1)}$; that is, $\tau$ is a functional of the joint distribution $P\left( Y^{(0)}, Y^{(1)} \right)$. Let $\tau_x= \tau(Y,A\mid X=x)$  be a measure of conditional association between $Y$ and $A$ given $X=x$; that is, $\tau_x$ is a functional of the conditional distribution $P(Y,A \mid X = x)$. The measure $\tau$ is called \textit{collapsible over $X$}, if $\tau$ is a weighted average of $\tau_x$ for $x \in \mathds{X}$. Strict collapsibility demands that $\tau=\tau_x$.
\end{definition}
%Note that under this definition, collapsibility seems to be defined over a certain covariate $X$. Doing the odds-ratio could be defined as a strictly collapsible as soon as the outcome is generated from a parametric logistic model such as in \eqref{eq:typical-model-used-binary-Y} (this is explicitely given as an example in their work). Note that in our work we define collapsibility differently, such that OR can not be considered as a collapsible measure.



\section{Proofs}

In this section we detail all the derivations needed to understand the results of this article. 

\subsection{Collapsibility}\label{proof:collapsibilty}

\textit{Note that not all proofs are novel work. Collapsibility results have been reported multiple times as explained in the main paper. For clarity we still recall them. We indicate when the proofs are not novel or when similar proofs exist elsewhere. When we indicate nothing, this means that we have not found those results in other published work.}

\subsubsection{Proof of Lemma~\ref{lemma:direct-collapsibility-RD}}

\textit{N.B: The proof for the direct collapsibility of the RD \underline{is not} a novel contribution.}

\begin{proof}

\begin{align*}
    \tau_{\text{\tiny RD}}&= \mathbb{E}\left[Y^{(1)} - Y^{(0)}  \right] && \text{By definition} \\
&= \mathbb{E}\left[  \mathbb{E}\left[Y^{(1)} - Y^{(0)} \mid X  \right]  \right] && \text{Law of total expectation} \\
&= \mathbb{E}\left[ \tau_{\text{\tiny RD}}\left(X \right) \right].
\end{align*}


\end{proof}


\paragraph{Remark} To observe the phenomenon as weighting, one can also write this last quantity as an integral.


\begin{align*}
   \mathbb{E}\left[  \mathbb{E}\left[Y^{(1)} - Y^{(0)} \mid X  \right]  \right] 
&=  \int_{\mathds{X}}  \mathbb{E}\left[Y^{(1)} - Y^{(0)} \mid X  \right] f(x)\,dx  &&\text{Re-writing} \\
&= \int_{\mathds{X}}  \tau_{\text{\tiny RD}}\left( x \right)f(x)\,dx.
\end{align*}

Here, one can observe that weights are the density of $x$ in the population. Most of the time \citep{pearl2011transportability, huitfeldt2018choice, Didelez2021collapsibility} express such quantity on categorical covariates $X$, therefore using a sum.

\subsubsection{Proof of Lemma~\ref{lemma:collapsibility-of-RR-SR}}

\textit{N.B: The proof for the collapsibility of the RR and SR are extensions of \cite{Huitfeldt2019collapsible}.}


\paragraph{General comment}
In this subsection we detail the proof for collapsibility of the RR, and SR. 
Before detailing the proof, we want to highlight why the RR (and SR) is not directly collapsible.


\begin{align*}
    \tau_{\text{\tiny RR}} &= \frac{\mathbb{E}\left[ Y^{(1)}\right]}{\mathbb{E}\left[ Y^{(0)}\right]}  \\
    &= \frac{\mathbb{E}\left[ \mathbb{E}\left[ Y^{(1)} \mid X  \right]\right]}{\mathbb{E}\left[ \mathbb{E}\left[ Y^{(0)} \mid X  \right]\right]}  \\
    & \neq \mathbb{E}\left[ \frac{\mathbb{E}\left[ Y^{(1)} \mid X\right]}{\mathbb{E}\left[ Y^{(0)} \mid X\right]}\right],
\end{align*}
%\es{ici, on a envie d'être un peu plus précis : donner des cas dans lesquels ce n'est pas vrai}
in all generality. For example, assuming that $\mathbb{E}\left[ Y^{(0)} \mid X\right]$ and $\mathbb{E}\left[ Y^{(1)} \mid X\right]$ are independent, we have 
\begin{align*}
\mathbb{E}\left[ \frac{\mathbb{E}\left[ Y^{(1)} \mid X\right]}{\mathbb{E}\left[ Y^{(0)} \mid X\right]}\right] & = \mathbb{E}[Y^{(1)}]\mathbb{E}\left[ \frac{1}{\mathbb{E}\left[ Y^{(0)} \mid X\right]}\right] > \frac{\mathbb{E}[Y^{(1)}]}{\mathbb{E}[Y^{(0)}]} = \tau_{\text{\tiny RR}},
\end{align*}
by Jensen inequality, assuming additionally that $\mathbb{E}\left[ Y^{(0)} \mid X\right] > 0$. 

\paragraph{Risk Ratio (RR)}

\begin{proof}


\begin{align*}
    \tau_{\text{\tiny RR}} &= \frac{\mathbb{E}\left[ Y^{(1)}\right]}{\mathbb{E}\left[ Y^{(0)}\right]}  && \text{By definition of the RR}\\
    &= \frac{\mathbb{E}\left[ \mathbb{E}\left[ Y^{(1)} \mid X \right]\right]}{\mathbb{E}\left[ Y^{(0)}\right]}  && \text{Law of total expectation used on $\mathbb{E}\left[ Y^{(1)}\right]$} \\
    &= \frac{\mathbb{E}\left[\frac{ \mathbb{E}\left[ Y^{(1)} \mid X \right]}{ \mathbb{E}\left[ Y^{(0)} \mid X \right]} \mathbb{E}\left[ Y^{(0)} \mid X \right]\right]}{\mathbb{E}\left[ Y^{(0)}\right]}  && \text{$\mathbb{E}\left[ Y^{(0)} \mid X \right] \neq 0$ ~almost surely} \\
    &= \mathbb{E}\left[\frac{ \mathbb{E}\left[ Y^{(1)} \mid X \right]}{ \mathbb{E}\left[ Y^{(0)} \mid X \right]} \frac{\mathbb{E}\left[ Y^{(0)} \mid X \right]}{\mathbb{E}\left[ Y^{(0)}\right] }\right] && \text{$\mathbb{E}\left[ Y^{(0)}\right]$ is a constant} \\
    &= \mathbb{E}\left[\tau_\text{\tiny RR}(X) \frac{\mathbb{E}\left[ Y^{(0)} \mid X \right]}{\mathbb{E}\left[ Y^{(0)}\right] }\right]. && \text{$\frac{ \mathbb{E}\left[ Y^{(1)} \mid X \right]}{ \mathbb{E}\left[ Y^{(0)} \mid X \right]}:= \tau_\text{\tiny RR}(X)$ }
\end{align*}





\end{proof}

\paragraph{Survival Ratio (SR)}

\begin{proof}
\begin{align*}
    \tau_{\text{\tiny SR}} &= \frac{1-\mathbb{E}\left[ Y^{(1)}\right]}{1-\mathbb{E}\left[ Y^{(0)}\right]}  && \text{By definition of the SR}\\
    &= \frac{1-\mathbb{E}\left[ \mathbb{E}\left[ Y^{(1)} \mid X \right]\right]}{1-\mathbb{E}\left[ Y^{(0)}\right]}  && \text{Law of total expectation} \\
    &= \frac{\mathbb{E}\left[\frac{1- \mathbb{E}\left[ Y^{(1)} \mid X \right]}{ 1-\mathbb{E}\left[ Y^{(0)} \mid X \right]} \left( 1-\mathbb{E}\left[ Y^{(0)} \mid X \right] \right)\right]}{1-\mathbb{E}\left[ Y^{(0)}\right]}  && \text{$1-\mathbb{E}\left[ Y^{(0)} \mid X \right] \neq 0$~ almost surely} \\
    &= \mathbb{E}\left[\tau_\text{\tiny SR}(X) \frac{1-\mathbb{E}\left[ Y^{(0)} \mid X \right]}{1-\mathbb{E}\left[ Y^{(0)}\right] }\right] && \text{$1-\mathbb{E}\left[ Y^{(0)}\right]$ is a constant}
    \end{align*}


\end{proof}


The Excess Risk Ratio (ERR) (resp. Risk Susceptibility) collapsibility are proven using the same derivations than RR (resp. SR).

\paragraph{Excess Risk Ratio (ERR)}

\begin{proof}
\begin{align*}
    \tau_{\text{\tiny ERR}} & =\frac{ \mathbb{E}\left[ Y^{(1)} - Y^{(0)} \right]}{ \mathbb{E}\left[  Y^{(0)} \right]} \\
    &= \frac{ \mathbb{E}\left[  \mathbb{E}\left[  Y^{(1)} - Y^{(0)} \mid X  \right]\right]}{ \mathbb{E}\left[  Y^{(0)} \right]} \\
    &=  \mathbb{E}\left[  \frac{\mathbb{E}\left[  Y^{(1)} - Y^{(0)} \mid X  \right]}{ \mathbb{E}\left[  Y^{(0)} \right]}\right]\\
    &= \mathbb{E}\left[  \frac{\mathbb{E}\left[  Y^{(1)} - Y^{(0)} \mid X  \right]}{ \mathbb{E}\left[  Y^{(0)} \right]} \frac{\mathbb{E}\left[  Y^{(0)} \mid X \right]}{\mathbb{E}\left[  Y^{(0)} \mid X \right]}  \right]\\
    &= \mathbb{E}\left[   \tau_{\text{\tiny ERR}}(X) \frac{\mathbb{E}\left[  Y^{(0)} \mid X \right]}{ \mathbb{E}\left[  Y^{(0)} \right]} \right]
\end{align*}
\end{proof}

\paragraph{Risk Susceptibility (RS)}

\begin{proof}
\begin{align*}
    \tau_{\text{\tiny RS}} & = \frac{ \mathbb{E}\left[ Y^{(1)} - Y^{(0)} \right]}{ 1- \mathbb{E}\left[  Y^{(0)} \right]} \\
    &=  \frac{ \mathbb{E}\left[\mathbb{E}\left[ Y^{(1)} - Y^{(0)} \mid X \right] \right]}{ 1- \mathbb{E}\left[  Y^{(0)} \right]} \\
    &=  \mathbb{E}\left[ \frac{ \mathbb{E}\left[ Y^{(1)} - Y^{(0)} \mid X \right]}{1- \mathbb{E}\left[  Y^{(0)} \right]}  \right] \\
    &=  \mathbb{E}\left[ \frac{ \mathbb{E}\left[ Y^{(1)} - Y^{(0)} \mid X \right]}{1- \mathbb{E}\left[  Y^{(0)} \right]} \frac{1- \mathbb{E}\left[  Y^{(0)} \mid X \right]}{1-\mathbb{E}\left[  Y^{(0)} \mid X \right]}  \right] \\
    &= \mathbb{E}\left[\tau_{\text{\tiny RS}}(X) \frac{1- \mathbb{E}\left[  Y^{(0)} \mid X \right]}{1- \mathbb{E}\left[  Y^{(0)}\right]} \right]
\end{align*}
\end{proof}


\subsubsection{Proof of Lemma~\ref{lemma:non-collapsibility}: Non-collapsibility of the OR, log-OR, and NNT}\label{proof:non-collapsibility-OR}



\textbf{Odds Ratio (OR).}
According to the first point of Lemma~\ref{lemma:logic-respecting-measures}, all collapsible measure are logic-respecting. However, according to the third point of Lemma~\ref{lemma:logic-respecting-measures}, OR is not logic-respecting. Therefore OR is not collapsible. 

\medskip 

\textbf{Log Odds Ratio (log-OR).}
The same reasoning as above holds for the log Odds Ratio. 

\medskip 
%\textit{N.B: the proof for the non collapsibility of the OR and log-OR \underline{is not} a novel contribution}\\

%See proof showing that OR is not logic-respecting in Section~\ref{proof:logic-respecting}, which leads to non-collapsibility of the OR. If a measure is not logic-respecting, then the population's effect can not be written as a weighted sum of local effects with positive weights. \\


\textbf{Number Needed to Treat (NNT).} \\

\begin{proof}
Recall that 
\begin{align}
\tau_{\text{\tiny  NNT}} = \frac{1}{\mathbb{E}[Y^{(1)}] - \mathbb{E}[Y^{(0)}]} \quad \textrm{and} \quad \tau_{\text{\tiny  NNT}}(X) = \frac{1}{\mathbb{E}[Y^{(1)}| X ] - \mathbb{E}[Y^{(0)} | X]}.
\end{align}

Assume that the NNT causal measure is collapsible, that is there exist weights $g(X, P(X,Y^{(0)}))$ such that for all distributions $P(X, Y^{(0)}, Y^{(1)})$ we have
\begin{align}
\mathbb{E}\left[ g(X, P(X,Y^{(0)}))\, \tau_{\text{\tiny  NNT}}(X) \right] = \tau_{\text{\tiny  NNT}},\qquad \text{with }   g \ge 0,\, \text{and} \quad  \mathbb{E}\left[  g(X, P(X,Y^{(0)}))\right] = 1. \label{eq_proof_NNT_def_collapsible}
\end{align}

Note that 
\begin{align}
\tau_{\text{\tiny  NNT}} = \frac{1}{\mathbb{E}\left[ \frac{1}{\tau_{\text{\tiny  NNT}}(X)}\right]},
\end{align}
which, combined with the previous equation, leads to 
\begin{align}
\mathbb{E}\left[ g(X, P(X,Y^{(0)}))\, \tau_{\text{\tiny  NNT}}(X) \right] = \frac{1}{\mathbb{E}\left[ \frac{1}{\tau_{\text{\tiny  NNT}}(X)}\right]}.
\end{align}
Assuming that $\tau_{\text{\tiny  NNT}}(X) \geq 0$, by Jensen inequality, we have 
\begin{align}
\mathbb{E}\left[ g(X, P(X,Y^{(0)}))\, \tau_{\text{\tiny  NNT}}(X) \right] & \leq \mathbb{E}\left[ \tau_{\text{\tiny  NNT}}(X)\right]\\
\mathbb{E}\left[ \left( g(X, P(X,Y^{(0)})) - 1 \right) \, \tau_{\text{\tiny  NNT}}(X) \right] & \leq 0. \label{eq_proof_NNT1}
\end{align}
Fix $\varepsilon >0$. Assume now that there exists a measurable set $B \subset \mathcal{X}$ with positive measure, such that for all $x \in B$, $g(X, P(X,Y^{(0)})) > 1+ \varepsilon$. By choosing the distribution of $Y^{(1)}$ such that $\mathbb{E}[Y^{(1)} | X]$ is arbitrary close to $\mathbb{E}[Y^{(0)} | X]$ on $B$, one has that $\tau_{\text{\tiny  NNT}}(X)$ is arbitrary large, so that $\left( g(X, P(X,Y^{(0)})) - 1 \right) \, \tau_{\text{\tiny  NNT}}(X) $ is arbitrary large on $B$, which contradicts  \eqref{eq_proof_NNT1}. This proves that $g(X, P(X,Y^{(0)})) \leq 1$ almost surely. Since $\mathbb{E}[g(X, P(X,Y^{(0)}))] =1$, this implies that almost surely $g(X, P(X,Y^{(0)})) = 1$. Thus, one should have 
\begin{align}
\mathbb{E}\left[ \tau_{\text{\tiny  NNT}}(X) \right] = \frac{1}{\mathbb{E}\left[ \frac{1}{\tau_{\text{\tiny  NNT}}(X)}\right]}, 
\end{align}
which, according to Jensen inequality, holds only if $\tau_{\text{\tiny  NNT}}(X)$ is constant. Thus the Number Needed to Treat satisfies the collapsibility equation \eqref{eq_proof_NNT_def_collapsible} only in the specific case of homogeneous treatment effect. This proves that the NNT is not collapsible. 

%\begin{align*}
%      \tau_{\text{\tiny NNT}}&= \frac{1}{ \mathbb{E}\left[ Y^{(1)} - Y^{(0)} \right]}  \\
%      &=  \frac{1}{ \mathbb{E}\left[ \mathbb{E}\left[ Y^{(1)} - Y^{(0)} \mid X \right] \right]}\\ 
 %     &= \mathbb{E}\left[ \frac{1}{\tau_{\text{\tiny NNT}}(X)}   \right]^{-1}.
%\end{align*}
 
\end{proof}


\subsection{Proof of Lemma~\ref{lemma:logic-respecting-measures} (about logic-respecting measures)}\label{proof:logic-respecting}


\subsubsection{All collapsible measures are logic respecting}
\begin{proof}
    We recall from Definition~\ref{def:indirect-collapsibility} that a measure $\tau$ is said to be collapsible (directly or not), if there exist positive weights $g(Y^{(0)}, X)$ verifying  $\mathbb{E}\left[g(Y^{(0)}, X)\right] = 1$, such that
   
    \begin{equation*}
        \tau = \mathbb{E}\left[g(Y^{(0)}, X)\tau(X)  \right].
    \end{equation*}


    Then,

    \begin{align*}
         \tau &\le  \mathbb{E}\left[g(Y^{(0)}, X)\max_x \left( \tau(X) \right)  \right]\\
         \tau &\le  \mathbb{E}\left[g(Y^{(0)}, X)\right] \max_x \left( \tau(x) \right)  \\
         \tau &\le\max_x \left( \tau(x) \right)
    \end{align*}

    using the properties of the weights. Similarly, one can show that,

  \begin{align*}
        \mathbb{E}\left[g(Y^{(0)}, X) \min_x \left( \tau(x) \right)  \right] &\le  \tau.
    \end{align*}

    This proves that $\tau$ is logic-respecting, according to Definition~\ref{def:logic-respecting}.
    
\end{proof}

\subsubsection{Number Needed to Treat is a logic-respecting measure}


\begin{proof}

   First, note that,
\begin{align*}
      \tau_{\text{\tiny NNT}}&= \frac{1}{ \mathbb{E}\left[ Y^{(1)} - Y^{(0)} \right]}  \\
      &=  \frac{1}{ \mathbb{E}\left[ \mathbb{E}\left[ Y^{(1)} - Y^{(0)} \mid X \right] \right]} && \text{Law of total expectation}\\ 
      &= \mathbb{E}\left[ \frac{1}{\tau_{\text{\tiny NNT}}(X)}   \right]^{-1} . && \text{$\tau_{\text{\tiny NNT}}(X):= 1/\mathbb{E}\left[ Y^{(1)} - Y^{(0)} \mid X \right]$}
\end{align*}


By definition, $\min_x \left(\tau_{\text{\tiny NNT}}(x) \right) \le \tau_{\text{\tiny NNT}}(X)$ almost surely, such that taking the inverse and the expectation leads to

\begin{equation*}
  \mathbb{E}\left[\frac{1}{\tau_{\text{\tiny NNT}}(X) }  \right] \le  \mathbb{E}\left[\frac{1}{\min_x \left(\tau_{\text{\tiny NNT}}(x) \right)} \right] = \frac{1}{\min_x \left(\tau_{\text{\tiny NNT}}(x) \right)}, 
\end{equation*}
%as $\min_x \left(\tau_{\text{\tiny NNT}}(X) \right)$ is a constant. 
which implies
%Taking again the inverse of $ \mathbb{E}\left[\frac{1}{\tau_{\text{\tiny NNT}}(X) }  \right] $ allows to recover the marginal $\tau_{\text{\tiny NNT}}$, so that
\begin{equation*}
  \min_x \left(\tau_{\text{\tiny NNT}}(x) \right)\le  \tau_{\text{\tiny NNT}}.
\end{equation*}
The exact same reasoning leads to 
\begin{equation*}
  \tau_{\text{\tiny NNT}} \le \max_x \left(\tau_{\text{\tiny NNT}}(x) \right).
\end{equation*}
Consequently, 
\begin{equation*}
  \min_x \left(\tau_{\text{\tiny NNT}}(x) \right)\le  \tau_{\text{\tiny NNT}} \le \max_x \left(\tau_{\text{\tiny NNT}}(x) \right),
\end{equation*}
which concludes the proof.
\end{proof}


\subsubsection{OR and log-OR are not logic-respecting}
%\es{je mettrais la preuve ici et ferai référence au Lemme 4 et à ce résultat dans la partie précédente}


Proving that the OR is not logic-respecting can be done with a counter-example as in Table~\ref{tab:odds-ratio-simpson}. 
 Previous works propose to understand non-collapsibility through the non-linearity of a function linking the baseline (control) and response functions. This link function is named the \textit{characteristic collapsibility function} (CCF) and have been proposed by \cite{Neuhaus1993GeometricApproach} and is nicely recalled in \cite{Daniel2020MakingApple} (see their Appendix 1A). This proof relies on Jensen inequality. The proof we recall here is largely inspired from these works, but written within the formalism of our paper.

 
%On the contrary, some measures are not collapsible. In particular for the odds ratio, this can be viewed through the example from Table~\ref{tab:odds-ratio-simpson}. It is possible to understand non-collapsibility through the non-linearity of a function linking the baseline (control) and response functions. This link function is named the \textit{characteristic collapsibility function} (CCF) and have been proposed by \cite{Neuhaus1993GeometricApproach} and is nicely recalled in \cite[Appendix 1A]{Daniel2020MakingApple}. \es{of what ?}\bc{Erwan: j'ai mis ici}

\begin{proof}
    
Assume a generative model such as

\begin{equation}\label{eq:proof-gen-model-non-collapsible}
    \operatorname{logit}\left( \mathbb{P}(Y^{(a)} =1 \mid X, A=a) \right) = b(X) + a\,m,
\end{equation}

where $b(X)$ can be any function of the vector $X$ to $\mathbb{R}$, and where $m$ is a non-null constant. Without loss of generality, one can further assume that $m>0$. Under such model, on has a property on the conditional log-OR or OR, being that:

\begin{equation}\label{eq_proof_local_ORx}
    \tau_{\text{\tiny log-OR}}(X) =  \operatorname{log}\left( \frac{\mathbb{P}(Y^{(1)} =1 \mid X)}{1- \mathbb{P}(Y^{(1)} =1 \mid X)} \cdot \left ( \frac{\mathbb{P}(Y^{(0)} =1 \mid X)}{1- \mathbb{P}(Y^{(0)} =1 \mid X)} \right)^{-1} \right) =  b(X) + m - b(X) =  m,
\end{equation}

or similarly that 

\begin{equation*}
     \tau_{\text{\tiny OR}}(X) = e^{b(X) + m}\cdot e^{-b(X)} =  e^{m}.
\end{equation*}

In other words, for any $x$ the OR $\tau_{\text{\tiny OR}}(x)$ (resp. log-OR) is the same and equal to $e^{m}$ (resp. $m$).\\

Now, we propose to go from this conditional causal measure to the marginal measure. When looking for the marginal OR, one can first estimate $\mathbb{P}(Y^{(1)}=1)$ and $\mathbb{P}(Y^{(0)}=1)$, and then compute the OR. To do so, we propose to rewrite $ \mathbb{P}(Y^{(1)}=1 \mid X)$ as a function of $ \mathbb{P}(Y^{(0)}=1 \mid X)$. From \eqref{eq:proof-gen-model-non-collapsible} one has,

\begin{equation*}
   \operatorname{logit}\left( \mathbb{P}(Y^{(0)}=1 \mid X) \right) =  b(X) ,
\end{equation*}
so that 
\begin{align}\label{eq:proof-non-collapsible}
 \operatorname{logit}\left( \mathbb{P}(Y^{(1)}=1 \mid X) \right)  &=  \operatorname{logit}\left( \mathbb{P}(Y^{(0)}=1 \mid X) \right) + m ,
\end{align}
which is equivalent to
\begin{align}\label{eq:proof-non-collapsible}
  \mathbb{P}(Y^{(1)}=1 \mid X) &=\operatorname{expit}\left(  \operatorname{logit}\left(   \mathbb{P}(Y^{(0)}=1 \mid X) \right) + m \right).
\end{align}

Letting, for all $z \in [0,1]$, 
\begin{align}\label{eq:proof-non-collapsible}
  f(z) &=\operatorname{expit}\left(  \operatorname{logit}\left(   z \right) + m \right),
\end{align}
we have
\begin{align}\label{eq:proof-non-collapsible}
  \mathbb{P}(Y^{(1)}=1 \mid X) &=f \left(  \mathbb{P}(Y^{(0)}=1 \mid X) \right) .
\end{align}
Note that the function $f$ is concave for positive $m$ (it is possible to derive it, but we propose an illustration on Figure~\ref{fig:schema-proof-non-collapsible} to help to be convinced). Then, using Jensen inequality, we obtain,



\begin{align*}
 \mathbb{P}(Y^{(1)}=1) 
 &=   \mathbb{E}\left[   \mathbb{P}(Y^{(1)}=1 \mid X )\right]\\
 &= \mathbb{E}\left[ f \left(  \mathbb{P}(Y^{(0)}=1 \mid X) \right) \right] \\
 %& = \mathbb{E}\left[   f(X) \right]\\
 & < f(\mathbb{E}\left[   \mathbb{P}(Y^{(0)}=1 \mid X) \right]\\
   %&= \mathbb{E}\left[  \operatorname{expit}\left(  \operatorname{logit}\left(   \mathbb{P}(Y^{(0)}=1 \mid X) \right) + m \right) \right]\\
     &= \operatorname{expit}\left(  \operatorname{logit}\left(  \mathbb{E}\left[  \mathbb{P}(Y^{(0)}=1 \mid X) \right]\right) + m \right) && \text{Jensen and $m >0 $} \\
     &= \operatorname{expit}\left(  \operatorname{logit}\left( \mathbb{P}(Y^{(0)}=1 )\right) + m \right),
\end{align*}

and because the $ \operatorname{logit}$ is a monotonous function, then,

\begin{align*}
     \operatorname{logit}\left( \mathbb{P}(Y^{(1)}=1)\right) &<  \operatorname{logit}\left( \mathbb{P}(Y^{(0)}=1 )\right) + m,
\end{align*}


so that 

\begin{align*}
     \operatorname{logit}\left( \mathbb{P}(Y^{(1)}=1)\right) - \operatorname{logit}\left( \mathbb{P}(Y^{(0)}=1 )\right) = \tau_{\text{\tiny log-OR}}  &< m,
\end{align*}
where $m=\tau_{\text{\tiny log-OR}}(x)$ (see \eqref{eq_proof_local_ORx}).
This allows to conclude that there exist a data generative process for which the odds ratio at the population level can not be written as a positively weighted sum of conditional odds ratio. 
%Would $m$ be strictly negative, then the function would be convex and the inequality would be in the other direction. \es{on peut enlever cette remarque je pense}

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{fig/schema-proof-non-collapsible.png}
    \caption{Implementation of the formulae from \eqref{eq:proof-non-collapsible} for different values of $m$. This illustrates the concavity of the function linking $\mathbb{P}(Y^{(0)}=1 \mid X) $ to $\mathbb{P}(Y^{(1)}=1 \mid X)$ when assuming the generative model of \eqref{eq:proof-gen-model-non-collapsible}. }
    \label{fig:schema-proof-non-collapsible}
\end{figure}


Note that the example provided in Table~\ref{tab:odds-ratio-simpson} is for a negative $m$, showing constant effect on the two substrata and a higher effect on the marginal population.
\end{proof}


\subsection{Proofs related to generalizability}\label{proof:generalizability-section-3}


\subsubsection{Proof of Proposition~\ref{proposition:generalization-density}}



\begin{proof}

   Consider $a\in \{0,1 \}$, then
\begin{align*}
   \mathbb{E}_{\text{\tiny T}}\left[Y^{(a)} \right] &=   \mathbb{E}_{\text{\tiny T}}\left[\mathbb{E}_{\text{\tiny T}}\left[Y^{(a)}\mid X=x \right]\right] && \text{Total expectation}\\
   &=  \mathbb{E}_{\text{\tiny T}}\left[\mathbb{E}_{\text{\tiny S}}\left[Y^{(a)}\mid X=x \right]\right] && \text{G-formula identification -- Assumptions~\ref{a:transportability-wide}}\\
   &= \mathbb{E}_{\text{\tiny R}}\left[ \frac{p_{\text{\tiny T}}(X)}{p_{\text{\tiny S}}(X)}  \mathbb{E}_{\text{\tiny S}}\left[Y^{(a)}\mid X=x \right]\right] && \text{Identification by re-weighting -- Assumptions~\ref{a:overlap}} \\
\end{align*} 


\end{proof}

\subsubsection{Proof of Proposition~\ref{prop:generalization-of-local-effects}}

\begin{proof}

If $\tau$ is collapsible, then there exists weights $g_{\text{\tiny T}}(Y^{(0)}, X)$ (defined on $P_{\text{\tiny T}}$) such that

\begin{align*}
   \tau^{\text{\tiny T}}&= \mathbb{E}_{\text{\tiny T}}\left[ g_{\text{\tiny T}}(Y^{(0)}, X) \tau^{\text{\tiny T}} (X)\right] && \text{Collapsibility}\\
   &= \mathbb{E}_{\text{\tiny T}}\left[ g_{\text{\tiny T}}(Y^{(0)}, X) \tau^{\text{\tiny R}} (X)\right] && \text{G-formula identification -- Assumption~\ref{a:transportability}}\\
   &= \mathbb{E}_{\text{\tiny R}}\left[ \frac{p_{\text{\tiny T}}(X)}{p_{\text{\tiny R}}(X)} g_{\text{\tiny T}}(Y^{(0)}, X) \tau^{\text{\tiny R}} (X)\right] && \text{Identification by re-weighting -- Assumption~\ref{a:overlap}}.
\end{align*}
\end{proof}




\subsection{Proofs related to non-parametric generative models (Section~\ref{section:generative-models})}


\textit{As we have not found elsewhere the approach of writing non-parametric models and to relate them to measures of effect,  to the best of our knowledge, all proofs in this subsection are novel.}

\subsubsection{Proof of Lemma~\ref{lemma:working-model-continuous-Y} (continuous outcomes)}\label{proof:lemma:working-model-continuous-Y}


\begin{proof}
By assumption, we know that  to $\mathbb{E}\left[\left|Y^{(1)}\right| \mid X\right] < \infty$. Therefore, one can write
\begin{equation*}
    Y^{(0)} = f(0,X) + \varepsilon_0, 
\end{equation*}
where $ f(0,X) = \mathbb{E}\left[Y^{(0)} \mid X\right]$ and $\mathbb{E}\left[\varepsilon_0 \mid X\right]=0$ almost surely. In the exact same way, we have 
\begin{equation*}
    Y^{(1)} = f(1,X) + \varepsilon_1, 
\end{equation*}
where $ f(1,X) = \mathbb{E}\left[Y^{(1)} \mid X\right]$ and $\mathbb{E}\left[\varepsilon_1 \mid X\right]=0$ almost surely. Note that the two previous equations are equivalent  to 
\begin{equation*}
    Y^{(A)} = \underbrace{f(0,X)}_{:=b(X)} + A\,\underbrace{\left(  f(1,X) - f(0,X)\right) }_{:=m(X)}  
 +\, \underbrace{A \varepsilon_1 + (1-A) \varepsilon_0}_{:=\varepsilon_A}.
\end{equation*}
Note that 
\begin{align*}
\mathbb{E}\left[\varepsilon_A \mid X\right] & = \mathbb{E}\left[A \varepsilon_1 + (1-A) \varepsilon_0 \mid X\right] \\
& =  \mathbb{E}\left[ A \mathbb{E}\left[ \varepsilon_1 \mid A, X\right] \mid X \right] +  \mathbb{E}\left[ (1-A) \mathbb{E}\left[ \varepsilon_0 \mid A, X \right] \mid X \right] \\
& =  \mathbb{E}\left[ A \mathbb{E}\left[ \varepsilon_1 \mid  X\right] \mid X \right] +  \mathbb{E}\left[ (1-A) \mathbb{E}\left[ \varepsilon_0 \mid X \right] \mid X \right] \\
& =  \mathbb{E}\left[ A  \mid X \right] \mathbb{E}\left[ \varepsilon_1 \mid  X\right] +  \mathbb{E}\left[ (1-A)  \mid X \right] \mathbb{E}\left[ \varepsilon_0 \mid X \right]\\
& = 0,
\end{align*}
and
\begin{align*}
\mathbb{E}\left[\varepsilon_A \mid X, A\right] & = \mathbb{E}\left[A \varepsilon_1 + (1-A) \varepsilon_0 \mid X, A\right] \\
& =  A \mathbb{E}\left[ \varepsilon_1 \mid A, X\right]  +  (1-A)  \mathbb{E}\left[ \varepsilon_0 \mid A, X \right]  \\
& = 0.
\end{align*}
Consequently, we have 
\begin{equation*}
    Y^{(A)} = b(X) + A\,m(X)
 +\, \varepsilon_A, 
\end{equation*}
with $\mathbb{E}\left[\varepsilon_A \mid X, A\right] =0$ almost surely and 
\begin{align*}
    b(X) &=   \mathbb{E}\left[ Y^{(0)} \mid X \right],\\
    m(X) &=  \mathbb{E}\left[ Y^{(1)} \mid X \right] -  \mathbb{E}\left[ Y^{(0)} \mid X \right] =  \mathbb{E}\left[ Y^{(1)} -  Y^{(0)}  \mid X \right].
\end{align*}
%The assumption stating that $\mathbb{E}\left[\left|Y^{(1)}\right| \mid X\right] < \infty$ and $\mathbb{E}\left[\left|Y^{(0)}\right| \mid X\right] < \infty$ in Lemma~\ref{lemma:working-model-continuous-Y} can also be seen as the assumption of a zero-mean additive-error representations \es{je ne comprends pas}. This implies that one can consider that the potential outcomes are generated according to:\begin{equation}\label{eq_proof_working_model_continuous_Y}
%    Y^{(A)} = f(A,X) + \varepsilon_A, 
%\end{equation}
%for some function $f \in \mathbf{L}^1\left(\{0,1\} \times \mathcal{X} \to \mathbb{R}\right)$ and a noise $\varepsilon_A$ satisfying $\mathbb{E}\left[ \varepsilon_A \mid X \right] = 0$ almost surely.\\


%Thanks to the binary nature of $A$, one has
%\begin{equation*}
%    Y^{(A)} = \underbrace{f(0,X)}_{:=b(X)} + A\,\underbrace{\left(  f(1,X) - f(0,X)\right) }_{:=m(X)}   +\,\varepsilon_A.
%\end{equation*}
%Noting that, taking the expectation around \eqref{eq_proof_working_model_continuous_Y}
%\begin{equation*}
%    Y^{(0)} = f(0,X) + \varepsilon_0, 
%\end{equation*}

%so that 
%\begin{equation*}
%    \mathbb{E}\left[ Y^{(0)} \mid X \right] = f(0,X),
%\end{equation*}
%and 

%\begin{equation*}
%   Y^{(1)} = f(1,X) + \varepsilon_1, 
%\end{equation*}

%so that
%\begin{equation*}
%    \mathbb{E}\left[ Y^{(1)} \mid X \right] = f(1,X),
%\end{equation*}

%it is possible to observe that $b(X)$ and $m(X)$ correspond to

%\begin{align*}
 %   b(X) &=   \mathbb{E}\left[ Y^{(0)} \mid X \right],\\
 %   m(X) &=  \mathbb{E}\left[ Y^{(1)} \mid X \right] -  \mathbb{E}\left[ Y^{(0)} \mid X \right] =  \mathbb{E}\left[ Y^{(1)} -  Y^{(0)}  \mid X \right].
%\end{align*}
\end{proof}

\subsubsection{Proof of Lemma~\ref{lemma:expression-of-causal-quantities-under-generative-model-continuous-outcome}}\label{proof:lemma-causal-quantities-continuous-outcome}
\begin{proof}
Assume that $Y$ is a continuous outcome. Under the conditions of Lemma~\ref{lemma:working-model-continuous-Y}, we have
 \begin{align*}
 Y^{(a)} = b(X) + a\,m(X) + \varepsilon_a,
 \end{align*}
 where $ b(X) :=\mathbb{E}[Y^{(0)} \mid X]$, $ m(X) :=\mathbb{E}[Y^{(1)}-Y^{(0)} \mid X]$ and a noise $\varepsilon_A$ satisfying $\mathbb{E}\left[ \varepsilon_A \mid X \right] = 0$ almost surely. With these relations in mind, one can compute each of the causal measures.

\paragraph{Risk Difference}

\begin{align*}
\tau_{\text{\tiny RD}}&= \mathbb{E} [Y^{(1)} - Y^{(0)}   ] && \text{By definition} \\
&=    \mathbb{E}\left[ b(X) + m(X) +  \varepsilon_1 - b(X) -  \varepsilon_0\right]  \\
&=  \mathbb{E}\left[ m(X)\right] +  \mathbb{E}\left[ \varepsilon_1\right] -  \mathbb{E}\left[ \varepsilon_0\right] \\
&=  \mathbb{E}\left[ m(X)\right] && \text{$ \mathbb{E}\left[ \varepsilon_a\right] =0$}
\end{align*}


%Risk Ratio and Excess Risk Ratio use similar steps.

\paragraph{Risk Ratio}
\begin{align*}
    \tau_{\text{\tiny RR}}&= \frac{\mathbb{E}\left[ Y^{(1)}\right]}{\mathbb{E}\left[ Y^{(0)}\right]}&& \text{By definition}  \\
    &= 1 + \frac{\mathbb{E}\left[m(X) \right]}{\mathbb{E}\left[b(X) \right]}.
\end{align*}

\paragraph{Excess Risk Ratio}
\begin{align*}
       \tau_{\text{\tiny ERR}}&= \frac{ \mathbb{E}\left[ m(X)\right] }{ \mathbb{E}\left[ b(X)\right] }.
\end{align*}
\end{proof}





\subsubsection{Proof of Lemma~\ref{lemma:intrication_model} (binary outcomes)}\label{proof:intrication_model}


\begin{proof}
Consider a binary outcome $Y$. We further assume that,
 \begin{equation*}
     \forall x \in \mathds{X},\, \forall a \in \{0,1\},\quad 0 < p_a(x) < 1,\quad \text{where } p_a(x)  := \mathbb{P}\left[Y^{(a)} = 1 \mid X=x\right],
 \end{equation*}
which means that the outcome is non-deterministic. Using the law of total expectation, one has


\begin{align*}
 p_1(x) &= \mathbb{P}\left[Y^{(1)} = 1 \mid X=x\right]\\
  & = \mathbb{P}\left[ Y^{(1)} = 1 \mid Y^{(0)} = 0, X = x\right] \mathbb{P}\left[ Y^{(0)} = 0\mid X = x\right]  + \mathbb{P}\left[ Y^{(1)} = 1 \mid Y^{(0)} = 1, X = x\right] \mathbb{P}\left[ Y^{(0)} = 1\mid X = x\right] \\
  &= \mathbb{P}\left[ Y^{(1)} = 1 \mid Y^{(0)} = 0, X = x\right] (1- p_0(x) )+ \mathbb{P}\left[ Y^{(1)} = 1 \mid Y^{(0)} = 1, X = x\right]  p_0(x) .
\end{align*}

Denoting
\begin{equation*}
    m_g(x):= \mathbb{P}\left[ Y^{(1)} = 0 \mid Y^{(0)} = 1, X = x\right] \quad \text{and} \quad m_b(x):= \mathbb{P}\left[ Y^{(1)} = 1 \mid Y^{(0)} = 0, X = x\right],
\end{equation*}
we finally obtain
\begin{align*}
 p_1(x) &=m_b(x) (1- p_0(x) ) + (1-  m_g(x))  p_0(x) \\
 &= p_0(x) +  m_b(x) (1- p_0(x) )  - p_0(x)m_g(x).
\end{align*}
Therefore, for all $a\in \{0,1\}$, 
\begin{align*}
 p_a(x)  &= p_0(x) +  a \left( m_b(x) (1- p_0(x) )  - p_0(x)m_g(x) \right).
\end{align*}
\end{proof}

\subsubsection{Proof of Lemma~\ref{lemma:expression-of-causal-quantities-under-generative-model-binary-outcome-intrication-model}}\label{proof:expression-of-causal-quantities-under-generative-model-binary-outcome-intrication-model}

\begin{proof}


Consider a binary outcome $Y$. Under the assumptions of  Lemma~\ref{lemma:intrication_model}, there exist probabilities $b(x)$, $ m_g(x)$, and $m_b(x)$ such that 
\begin{align*}
     \mathbb{P}\left[ Y^{(a)} = 1 \mid X = x\right]  &= b(x) +  a\, \left( \left( 1-b\left(x\right) \right) m_b\left(x\right) -  b\left(x\right)m_g\left(x\right) \right).
\end{align*}

Using such a decomposition, one has

    \begin{align*}
        \tau_{\text{\tiny RD}} &=  \mathbb{E}\left[ b(X)+  \left( \left( 1-b\left(X\right) \right) m_b\left(X\right) -  b\left(x\right)m_g\left(X\right) \right)\right] -  \mathbb{E}\left[ b(X)\right]\\
        &=  \mathbb{E}\left[ \left( 1-b\left(X\right) \right) m_b\left(X\right)\right] -  \mathbb{E}\left[ b\left(X\right)m_g\left(X\right) \right], \\
        \tau_{\text{\tiny NNT}} &=  \frac{1}{\mathbb{E}\left[ \left( 1-b\left(X\right) \right) m_b\left(X\right)\right] -  \mathbb{E}\left[ b\left(X\right)m_g\left(X\right) \right] },\\
         \tau_{\text{\tiny RR}} &= \frac{ \mathbb{E}\left[ b(X)+  \left( \left( 1-b\left(X\right) \right) m_b\left(X\right) -  b\left(X\right)m_g\left(X\right) \right)\right] }{ \mathbb{E}\left[ b(X)\right]} \\
         &= 1  + \frac{ \mathbb{E}\left[  \left( 1-b\left(X\right) \right) m_b\left(X\right) \right] }{ \mathbb{E}\left[ b(X)\right]} - \frac{\mathbb{E}\left[ b(X) m_g\left(X\right)\right]}{\mathbb{E}\left[ b(X)\right]}, \\
         \tau_{\text{\tiny SR}} &= \frac{ 1- \mathbb{E}\left[ b(X)+  \left( \left( 1-b\left(X\right) \right) m_b\left(X\right) -  b\left(X\right)m_g\left(X\right) \right)\right] }{ 1- \mathbb{E}\left[ b(X)\right]} \\
         &= \frac{\mathbb{E}\left[ 1 - b(X) -  \left( \left( 1-b\left(X\right) \right) m_b\left(X\right) +  b\left(X\right)m_g\left(X\right) \right)\right] }{ \mathbb{E}\left[ 1- b(X)\right]} \\
         &= 1 - \frac{\mathbb{E}\left[ \left( 1-b\left(X\right) \right) m_b\left(X\right) \right]}{\mathbb{E}\left[ 1- b(X)\right]} + \frac{\mathbb{E}\left[ b\left(X\right)m_g\left(X\right) \right]}{\mathbb{E}\left[ 1- b(X)\right]}, \\
    \tau_{\text{\tiny OR}}  &= \frac{\mathbb{P}[Y^{(1)} = 1]}{\mathbb{P}[Y^{(1)} = 0]}\, \left(  \frac{\mathbb{P}[Y^{(0)} = 1]}{\mathbb{P}[Y^{(0)} = 0]}\right)^{-1} \\
    &= \frac{\mathbb{E}\left[ b(X)+  \left( \left( 1-b\left(X\right) \right) m_b\left(X\right) -  b\left(X\right)m_g\left(X\right) \right)\right] }{1- \mathbb{E}\left[ b(X)+  \left( \left( 1-b\left(X\right) \right) m_b\left(X\right) -  b\left(X\right)m_g\left(X\right) \right)\right] }  \left(  \frac{\mathbb{E}\left[b(X)\right]}{1- \mathbb{E}\left[b(X)\right]}\right)^{-1} \\
    &=     \frac{\mathbb{E}\left[ b(X)+  \left( \left( 1-b\left(X\right) \right) m_b\left(X\right) -  b\left(X\right)m_g\left(X\right) \right)\right] }{\mathbb{E}\left[ 1- b(X) -  \left( \left( 1-b\left(X\right) \right) m_b\left(X\right) +  b\left(X\right)m_g\left(X\right) \right)\right] }  \frac{\mathbb{E}\left[1-b(X)\right]}{ \mathbb{E}\left[b(X)\right]} \\
    &=     \frac{\mathbb{E}\left[ b(X) \right]+  \mathbb{E}\left[\left( \left( 1-b\left(X\right) \right) m_b\left(X\right) \right]-  \mathbb{E}\left[b\left(X\right)m_g\left(X\right) \right)\right] }{\mathbb{E}\left[ 1- b(X) \right] - \mathbb{E}\left[ \left( 1-b\left(X\right) \right) m_b\left(X\right)  \right]+  \mathbb{E}\left[b\left(X\right)m_g\left(X\right) \right] }  \frac{\mathbb{E}\left[1-b(X)\right]}{ \mathbb{E}\left[b(X)\right]} \\
    &= \left( 1  + \frac{ \mathbb{E}\left[  \left( 1-b\left(X\right) \right) m_b\left(X\right) \right] }{ \mathbb{E}\left[ b(X)\right]} - \frac{\mathbb{E}\left[ b(X) m_g\left(X\right)\right]}{\mathbb{E}\left[ b(X)\right]} \right) \left( 1 - \frac{\mathbb{E}\left[ \left( 1-b\left(X\right) \right) m_b\left(X\right) \right]}{\mathbb{E}\left[ 1- b(X)\right]} + \frac{\mathbb{E}\left[ b\left(X\right)m_g\left(X\right) \right]}{\mathbb{E}\left[ 1- b(X)\right]}\right)^{-1}.
\end{align*}
\end{proof}




\subsection{Proofs of Section~\ref{sec:generalization}}


\subsubsection{Proof of Theorem~\ref{theorem:all-covariates}}

\begin{proof}
\textbf{Continuous outcome}. Consider a continuous outcome $Y$. Under assumptions of Lemma~\ref{lemma:working-model-continuous-Y}, 
 \begin{align*}
 Y^{(a)} = b(X) + a\,m(X) + \varepsilon_a,
 \end{align*}
 where $ b(X) :=\mathbb{E}[Y^{(0)} \mid X]$, $ m(X) :=\mathbb{E}[Y^{(1)}-Y^{(0)} \mid X]$ and $\varepsilon_A$ satisfies $\mathbb{E}\left[ \varepsilon_A \mid X \right] = 0$.\\



%Further assume Assumptions~\ref{a:transportability-wide} and \ref{a:overlap}. 

Let $a \in \{0, 1\}$, %and denote $Z$ any set of baseline covariates,
\begin{align*}
    \mathbb{E}_{\text{\tiny T}}\left[Y^{(a)} \right] &=   \mathbb{E}_{\text{\tiny T}}\left[  Y^{(a)} \right]\\
     &=     \mathbb{E}_{\text{\tiny T}}\left[  b(X) + a\,m(X) + \varepsilon_a \right]&& \text{Lemma~\ref{lemma:working-model-continuous-Y}} \\
    &=    \mathbb{E}_{\text{\tiny T}}\left[  b(X)  \right]+ a\,   \mathbb{E}_{\text{\tiny T}}\left[  m(X) \right].
\end{align*}
Generalizing conditional outcomes to the target population means that we can compute  $\mathbb{E}_{\text{\tiny T}} [Y^{(a)} ]$ for $a \in \{0,1\}$, which is equivalent to computing 
\begin{align}
     \mathbb{E}_{\text{\tiny T}}\left[  b(X) \right],  \quad \text{and }\quad \mathbb{E}_{\text{\tiny T}}\left[  m(X) \right],
\end{align}
that is generalizing $b(X)$ and $m(X)$. According to Definitions~\ref{def:two-kind-covariates} and \ref{def:shidted-covariates}, we have 
\begin{align}
     \mathbb{E}_{\text{\tiny T}}\left[  b(X) \right] &=  \mathbb{E}_{\text{\tiny T}}\left[   \mathbb{E}_{\text{\tiny T}}\left[  b(X) \mid X_{\textrm{Sh}} \right] \right] \\
     & = \mathbb{E}_{\text{\tiny T}}\left[   \mathbb{E}_{\text{\tiny S}}\left[  b(X) \mid X_{\textrm{Sh}} \right] \right] \\
     & = \mathbb{E}_{\text{\tiny T}}\left[   \mathbb{E}_{\text{\tiny S}}\left[  b(X) \mid X_{B \cap \textrm{Sh}} \right] \right], \label{proof_th1_eq1}
\end{align}
and similarly, 
\begin{align}
     \mathbb{E}_{\text{\tiny T}}\left[  m(X) \right] &=  \mathbb{E}_{\text{\tiny T}}\left[   \mathbb{E}^{\text{\tiny T}}\left[  m(X) \mid X_{\textrm{Sh}} \right] \right] \\
     & = \mathbb{E}_{\text{\tiny T}}\left[   \mathbb{E}_{\text{\tiny S}}\left[  m(X) \mid X_{\textrm{Sh}} \right] \right] \\
     & = \mathbb{E}_{\text{\tiny T}}\left[   \mathbb{E}_{\text{\tiny S}}\left[  m(X) \mid X_{M \cap \textrm{Sh}} \right] \right]. \label{proof_th1_eq2}
\end{align}
Having access to $X_{(M \cup B) \cap \textrm{Sh}}$ that is all shifted covariates that are treatment effect modifiers or related to the baseline risk is then sufficient to generalize $b$ and $m$ and thus to generalize $ \mathbb{E}_{\text{\tiny T}}\left[Y^{(a)} \right]$ for all $a\in \{0,1\}$.


%The covariate set $Z$ satisfying 
%\begin{equation*}
%     \mathbb{E}^{\text{\tiny T}}\left[  b(X) \mid Z\right] =     \mathbb{E}^{\text{\tiny S}}\left[  b(X) \mid Z \right],  \quad \text{and }\quad \mathbb{E}^{\text{\tiny T}}\left[  m(X) \mid Z\right] =     \mathbb{E}^{\text{\tiny S}}\left[  m(X) \mid Z \right],
%\end{equation*}
%is thus the minimal set required to generalize the conditional outcomes. 

%\bigskip 
%According to Definitions~\ref{def:two-kind-covariates} and \ref{def:shidted-covariates}, we introduce the sets of indices $M, B, \textrm{Sh} \subset \{1, \hdots, d \}$ such that $X_B$ and $X_M$ are the minimal sets of variables satisfying    
%\begin{align*}
%\mathbb{E}\left[b\left(X\right) | X = x \right] = \mathbb{E}\left[b\left(X\right) | X_B = x_B\right] \quad \textrm{and} \quad  \mathbb{E}\left[m\left(X\right) | X = x\right] =  \mathbb{E}\left[m(X) | X_M = x_M\right].
%\end{align*}
%ensuring that any causal quantity can be generalized by generalizing conditional outcomes with $Z$ as the conditional set.
%But any smaller set would prevent to generalize either $b(X)$ and / or $m(X)$:

%\begin{equation*}
%     \mathbb{E}^{\text{\tiny T}}\left[  b(X) \mid Z\right] \neq     \mathbb{E}^{\text{\tiny S}}\left[  b(X) \mid Z \right],  \quad \text{and / or } \mathbb{E}^{\text{\tiny T}}\left[  m(X) \mid Z\right] \neq     \mathbb{E}^{\text{\tiny S}}\left[  m(X) \mid Z \right],
%\end{equation*}
%and therefore prevents the generalization of $\mathbb{E}^{\text{\tiny T}}\left[  Y^{(a)} \mid Z \right]$.\\

\bigskip 

\textbf{Binary outcome.} Consider a binary outcome $Y \in \{0,1\}$, and let
\begin{equation*}
    m_g(x):= \mathbb{P}\left[ Y^{(1)} = 0 \mid Y^{(0)} = 1, X = x\right] \quad \text{and} \quad m_b(x):= \mathbb{P}\left[ Y^{(1)} = 1 \mid Y^{(0)} = 0, X = x\right].
\end{equation*}
Under Assumptions of Lemma~\ref{lemma:intrication_model}, we have, for all $a \in \{0,1\},$
\begin{align*}
     \mathbb{P}\left[ Y^{(a)} = 1 \mid X = x\right]  &= b(x)+  a\, m(x), 
\end{align*}
with $b(x)=p_0(x) $ and 
\begin{align*}
   m(x) =    \left( 1-b\left(x\right) \right) m_b\left(x\right) -  b\left(x\right)m_g\left(x\right).
\end{align*}
For all  $a \in \{0, 1\}$, we have, as above, 
\begin{align*}
    \mathbb{E}_{\text{\tiny T}}\left[Y^{(a)} \right] &= \mathbb{E}_{\text{\tiny T}}\left[  \mathbb{P}\left[ Y^{(a)} = 1 \mid X \right]  \right]\\
     &=  \mathbb{E}_{\text{\tiny T}}\left[    b(X)+  a\, m(X), \right] \\
     &=  \mathbb{E}_{\text{\tiny T}}\left[    b(X) \right] +  a\,\mathbb{E}_{\text{\tiny T}}\left[ m(X), \right]. 
    %&=  \mathbb{E}^{\text{\tiny T}}\left[  \mathbb{E}^{\text{\tiny T}}\left[  b(X) \mid Z\right] \right]+ a\, \mathbb{E}^{\text{\tiny T}}\left[  \mathbb{E}^{\text{\tiny T}}\left[ \left( 1-b\left(X\right) \right) m_b\left(X\right) \mid  Z\right]\right] - a\, \mathbb{E}^{\text{\tiny T}}\left[  \mathbb{E}^{\text{\tiny T}}\left[ b\left(X\right)m_g\left(X\right) \mid Z \right] \right].
\end{align*}
Having access to $X_{(M \cup B) \cap \textrm{Sh}}$ that is all shifted covariates that are treatment effect modifiers or related to the baseline risk is then sufficient to generalize $b$ and $m$ and thus to generalize $ \mathbb{E}_{\text{\tiny T}}\left[Y^{(a)} \right]$ for all $a\in \{0,1\}$.

%As soon as the set $Z = (X_B \cup X_M ) \cap \textrm{Shift}$, then one has,
%\begin{equation}\label{eq_proof_1}
%     \mathbb{E}^{\text{\tiny T}}\left[  b(X) \mid Z\right] =     \mathbb{E}^{\text{\tiny S}}\left[  b(X) \mid Z \right],
%\end{equation}
%and
%\begin{equation}\label{eq_proof_2}
%   \quad \mathbb{E}^{\text{\tiny T}}\left[  \left( 1-b\left(X\right) \right) m_b\left(X\right) \mid Z\right] =     \mathbb{E}^{\text{\tiny S}}\left[ \left( 1-b\left(X\right) \right) m_b\left(X\right) \mid Z \right],
%\end{equation}
%along with
%\begin{equation}\label{eq_proof_3}
%   \quad \mathbb{E}^{\text{\tiny T}}\left[ b\left(X\right)m_g\left(X\right) \mid Z\right] =     \mathbb{E}^{\text{\tiny S}}\left[b\left(X\right)m_g\left(X\right) \mid Z \right].
%\end{equation}

%This ensures to have,

%\begin{align*}
%    \mathbb{E}^{\text{\tiny T}}\left[Y^{(a)} \right]
%    &=  \mathbb{E}^{\text{\tiny T}}\left[  \mathbb{E}^{\text{\tiny S}}\left[  b(X) \mid Z\right] \right]+ a\, \mathbb{E}^{\text{\tiny T}}\left[  \mathbb{E}^{\text{\tiny S}}\left[ \left( 1-b\left(X\right) \right) m_b\left(X\right) \mid  Z\right]\right] - a\, \mathbb{E}^{\text{\tiny T}}\left[  \mathbb{E}^{\text{\tiny S}}\left[ b\left(X\right)m_g\left(X\right) \mid Z \right] \right]\\
%    &= \mathbb{E}^{\text{\tiny T}}\left[   \mathbb{E}^{\text{\tiny S}}\left[ b(X)+  a\, \left( \left( 1-b\left(X\right) \right) m_b\left(X\right) -  b\left(X\right)m_g\left(X\right) \right)  \mid Z \right] \right]\\
%    &= \mathbb{E}^{\text{\tiny T}}\left[   \mathbb{E}^{\text{\tiny S}}\left[  Y^{(a)} \mid Z \right] \right].
%\end{align*}


%Any smaller set than $Z$ would prevent at least \eqref{eq_proof_1}, \eqref{eq_proof_2}, or \eqref{eq_proof_3} to hold, and therefore would not enable the transport formula to hold without further assumptions.
\end{proof}


\subsubsection{Proof of Theorem~\ref{theorem:restricted-set-for-Y-continuous-RD}}

\begin{proof}


In this proof $Y$ is assumed continuous. We consider a set of baseline shifted covariates $X_M$ defined in Definitions~\ref{def:two-kind-covariates} and \ref{def:shidted-covariates}.\\


 \textbf{Risk Difference}
We start by proving that Assumption~\ref{a:transportability} is satisfied for $\tau_{\text{\tiny RD}}(X_{M \cap \textrm{Sh}})$. We have
\begin{align*}
\tau^{\text{\tiny T}}_{\text{\tiny RD}}(X_{M \cap \textrm{Sh}}) & = \mathbb{E}_{\text{\tiny T}}\left[ Y^{(1)} - Y^{(0)} \mid X_{M \cap \textrm{Sh}} \right] && \\
& = \mathbb{E}_{\text{\tiny T}}\left[    m(X) \mid X_{M \cap \textrm{Sh}} \right] && \text{Lemma~\ref{lemma:working-model-continuous-Y}} \\
& = \mathbb{E}_{\text{\tiny T}}\left[    m(X) \mid X_{\textrm{Sh}} \right] && \text{Definition~\ref{def:two-kind-covariates}} \\
& = \mathbb{E}_{\text{\tiny S}}\left[    m(X) \mid X_{\textrm{Sh}} \right] && \text{Definition~\ref{def:shidted-covariates}} \\
& = \mathbb{E}_{\text{\tiny S}}\left[    m(X) \mid X_{M \cap \textrm{Sh}} \right] && \text{Definition~\ref{def:two-kind-covariates}}\\
& = \tau^{\text{\tiny S}}_{\text{\tiny RD}}(X_{M \cap \textrm{Sh}}) .
 \end{align*}
Thus, Assumption~\ref{a:transportability} is verified for $\tau_{\text{\tiny RD}}$ with covariates $X_{M \cap \textrm{Sh}}$. Furthermore, by assumption in Theorem~\ref{theorem:restricted-set-for-Y-continuous-RD}, Assumption~\ref{a:overlap} is verified with  covariates $X_{M \cap \textrm{Sh}}$. Thus, by Proposition~\ref{prop:generalization-of-local-effects}, $\tau_{\text{\tiny RD}}$ is generalizable with covariates $X_{M \cap \textrm{Sh}}$.

\bigskip 

Below, we give insights explaining why the risk ratio does not satisfy a similar property. Indeed, in the same manner as above, the risk ratio satisfies

 
 \begin{align*}
\tau^{\text{\tiny S}}_{\text{\tiny RR}}(X_{M \cap \textrm{Sh}})  &= \frac{\mathbb{E}_{\text{\tiny S}}\left[ Y^{(1)} \mid X_{M \cap \textrm{Sh}} \right]}{\mathbb{E}_{\text{\tiny S}}\left[ Y^{(0)} \mid X_{M \cap \textrm{Sh}}\right]} \\
&= \frac{\mathbb{E}_{\text{\tiny S}}\left[ b(X) + m(X) \mid X_{M \cap \textrm{Sh}} \right]}{\mathbb{E}_{\text{\tiny S}}\left[  b(X) \mid X_{M \cap \textrm{Sh}} \right]} && \text{Lemma~\ref{lemma:working-model-continuous-Y}}\\
%&= \frac{\mathbb{E}^{\text{\tiny S}}\left[ \mathbb{E}^{\text{\tiny S}}\left[b(X) + m(X) \mid X \right] \mid X_M \cap \textrm{Shift} \right]}{\mathbb{E}^{\text{\tiny S}}\left[  \mathbb{E}^{\text{\tiny S}}\left[b(X) \mid X \right] \mid X_M \cap \textrm{Shift} \right]} && \\
&= 1 + \frac{ \mathbb{E}_{\text{\tiny T}}\left[ m(X) \mid X_{M \cap \textrm{Sh}} \right]}{\mathbb{E}_{\text{\tiny S}}\left[b(X) \mid X_{M \cap \textrm{Sh}} \right]}. && \text{ Definitions~\ref{def:shidted-covariates}} \\
%&= 1 + \frac{ \mathbb{E}^{\text{\tiny T}}\left[ m(X) \mid X_{M \cap \textrm{Sh}} \right]}{\mathbb{E}^{\text{\tiny S}}\left[b(X) \mid X_{M \cap \textrm{Sh}} \right]},
 \end{align*}
For Assumption~\ref{a:overlap} to hold, we need $\tau^{\text{\tiny S}}_{\text{\tiny RR}}(X_{M \cap \textrm{Sh}}) = \tau^{\text{\tiny T}}_{\text{\tiny RR}}(X_{M \cap \textrm{Sh}})$, which, given the previous calculation, is equivalent to 
\begin{align*}
\mathbb{E}_{\text{\tiny S}}\left[b(X) \mid X_{M \cap \textrm{Sh}} \right] = \mathbb{E}_{\text{\tiny T}}\left[b(X) \mid X_{M \cap \textrm{Sh}} \right],    
\end{align*}
which has no reason to be valid in general, since in all generality, $X_{M \cap \textrm{Sh}}  \not\subset X_{B \cap \textrm{Sh}}$. A similar reasoning holds for the Excess Risk Ratio (ERR), as it is defined as a function of $\tau_{\text{\tiny RR}}$.
%,  requires that 
% but there is no reason that $\mathbb{E}^{\text{\tiny S}}\left[b(X) \mid X_M \cap \textrm{Shift} \right] = \mathbb{E}^{\text{\tiny T}}\left[b(X) \mid X_M \cap \textrm{Shift} \right]$, preventing Assumption~\ref{a:transportability} to hold. 


\end{proof}

\subsubsection{Proof of Theorem~\ref{theorem:restricted-set-for-Y-binary-SR-RR}}

\begin{proof}
Recall that we consider a  binary output $Y \in \{0,1\}$. Recall that, by Lemma~\ref{lemma:intrication_model}, we have, for all $a \in \{0,1\},$
\begin{align*}
     \mathbb{P}\left[ Y^{(a)} = 1 \mid X = x\right]  &= b(x)+  a\, \left(   \left( 1-b\left(x\right) \right) m_b\left(x\right) -  b\left(x\right)m_g\left(x\right) \right), 
\end{align*}
with $b(x)=p_0(x)$. The proof of Lemma~\ref{lemma:intrication_model} can be adapted for any subset of covariates of $X$, so that 
\begin{align*}
     \mathbb{E}\left[ Y^{(a)}  \mid X_{M \cap \textrm{Sh}}\right]  &= b(X_{M \cap \textrm{Sh}})+  a\, \left(   \left( 1-b\left(X_{M \cap \textrm{Sh}}\right) \right) m_b\left(X_{M \cap \textrm{Sh}}\right) -  b\left(X_{M \cap \textrm{Sh}}\right)m_g\left(X_{M \cap \textrm{Sh}}\right) \right), 
\end{align*}
with 
\begin{align*}
b(X_{M \cap \textrm{Sh}}) & = \mathbb{P}\left[ Y^{(0)} = 1 \mid X_{M \cap \textrm{Sh}}\right]\\
m_g\left(X_{M \cap \textrm{Sh}}\right) & = \mathbb{P}\left[ Y^{(1)} = 0 \mid Y^{(0)} = 1, X_{M \cap \textrm{Sh}}\right] \\
 m_b\left(X_{M \cap \textrm{Sh}}\right) & = \mathbb{P}\left[ Y^{(1)} = 1 \mid Y^{(0)} = 0, X_{M \cap \textrm{Sh}}\right].    
\end{align*}


\textbf{First case.} Assume that, for all $x$, $m_b(x)=0$. According to the calculation above, we have

\begin{align}
    \tau^{\text{\tiny S}}_{\text{\tiny RR}}(X_{M \cap \textrm{Sh}})
    &= \frac{\mathbb{E}_{\text{\tiny S}}\left[ Y^{(1)} | X_{M \cap \textrm{Sh}} \right] }{\mathbb{E}_{\text{\tiny S}}\left[ Y^{(0)} | X_{M \cap \textrm{Sh}} \right]} \\
    %&= \frac{\mathbb{E}^{\text{\tiny S}}\left[ \mathbb{E}^{\text{\tiny S}}\left[ Y^{(1)} | X \right] | X_{M \cap \textrm{Sh}} \right] }{\mathbb{E}^{\text{\tiny S}}\left[  \mathbb{E}^{\text{\tiny S}}\left[ Y^{(0)} | X \right] | X_{M \cap \textrm{Sh}} \right]} \\
    & = \frac{b(X_{M \cap \textrm{Sh}}) - b(X_{M \cap \textrm{Sh}}) m_g\left(X_{M \cap \textrm{Sh}}\right)  }{b(X_{M \cap \textrm{Sh}})} && \text{Lemma~\ref{lemma:intrication_model}}\\
    & = 1 - m_g\left(X_{M \cap \textrm{Sh}}\right)\\
    & = 1 - \mathbb{P}_{\text{\tiny S}}\left[ Y^{(1)} = 0 \mid Y^{(0)} = 1, X_{M \cap \textrm{Sh}}\right] \\
    & = 1 - \mathbb{P}_{\text{\tiny S}}\left[ Y^{(1)} = 0 \mid Y^{(0)} = 1, X_{\textrm{Sh}}\right] && \text{Definition~\ref{def:two-kind-covariates}}\\
    & = 1 - \mathbb{P}_{\text{\tiny T}}\left[ Y^{(1)} = 0 \mid Y^{(0)} = 1, X_{\textrm{Sh}}\right] && \text{Definition~\ref{def:shidted-covariates}}\\
    & = 1 - \mathbb{P}_{\text{\tiny T}}\left[ Y^{(1)} = 0 \mid Y^{(0)} = 1, X_{M \cap \textrm{Sh}} \right] && \text{Definition~\ref{def:two-kind-covariates}}\\
    & = \tau^{\text{\tiny T}}_{\text{\tiny RR}}(X_{M \cap \textrm{Sh}}). \label{eq1_proof_RR_generalization_section5}
\end{align}
Following the proof of Lemma~\ref{lemma:collapsibility-of-RR-SR}, we have 
\begin{align*}
    \tau^{\text{\tiny T}}_{\text{\tiny RR}} &= \frac{\mathbb{E}_{\text{\tiny T}}\left[ Y^{(1)}\right]}{\mathbb{E}_{\text{\tiny T}}\left[ Y^{(0)}\right]}  && \text{By definition of the RR}\\
    &= \frac{\mathbb{E}_{\text{\tiny T}}\left[ \mathbb{E}_{\text{\tiny T}}\left[ Y^{(1)} \mid X_{M \cap \textrm{Sh}} \right]\right]}{\mathbb{E}_{\text{\tiny T}}\left[ Y^{(0)}\right]}  && \text{Law of total expectation used on $\mathbb{E}_{\text{\tiny T}}\left[ Y^{(1)}\right]$} \\
    &= \frac{\mathbb{E}_{\text{\tiny T}}\left[\frac{ \mathbb{E}_{\text{\tiny T}}\left[ Y^{(1)} \mid X_{M \cap \textrm{Sh}} \right]}{ \mathbb{E}_{\text{\tiny T}}\left[ Y^{(0)} \mid X_{M \cap \textrm{Sh}} \right]} \mathbb{E}_{\text{\tiny T}}\left[ Y^{(0)} \mid X_{M \cap \textrm{Sh}} \right]\right]}{\mathbb{E}_{\text{\tiny T}}\left[ Y^{(0)}\right]}  && \text{$\mathbb{E}_{\text{\tiny T}}\left[ Y^{(0)} \mid X_{M \cap \textrm{Sh}} \right] \neq 0$ ~almost surely} \\
    %&= \mathbb{E}\left[\frac{ \mathbb{E}\left[ Y^{(1)} \mid X \right]}{ \mathbb{E}\left[ Y^{(0)} \mid X \right]} \frac{\mathbb{E}\left[ Y^{(0)} \mid X \right]}{\mathbb{E}\left[ Y^{(0)}\right] }\right] && \text{$\mathbb{E}\left[ Y^{(0)}\right]$ is a constant} \\
    &= \mathbb{E}_{\text{\tiny T}}\left[\tau^{\text{\tiny T}}_\text{\tiny RR}(X_{M \cap \textrm{Sh}}) \frac{\mathbb{E}_{\text{\tiny T}}\left[ Y^{(0)} \mid X_{M \cap \textrm{Sh}} \right]}{\mathbb{E}_{\text{\tiny T}}\left[ Y^{(0)}\right] }\right]\\
    &= \mathbb{E}_{\text{\tiny T}}\left[\tau^{\text{\tiny S}}_\text{\tiny RR}(X_{M \cap \textrm{Sh}}) \frac{\mathbb{E}_{\text{\tiny T}}\left[ Y^{(0)} \mid X_{M \cap \textrm{Sh}} \right]}{\mathbb{E}_{\text{\tiny T}}\left[ Y^{(0)}\right] }\right] && \text{By \eqref{eq1_proof_RR_generalization_section5}}\\
    &= \mathbb{E}_{\text{\tiny S}}\left[\tau^{\text{\tiny S}}_\text{\tiny RR}(X_{M \cap \textrm{Sh}}) \frac{\mathbb{E}_{\text{\tiny T}}\left[ Y^{(0)} \mid X_{M \cap \textrm{Sh}} \right]}{\mathbb{E}_{\text{\tiny T}}\left[ Y^{(0)}\right] } \frac{p_{\text{\tiny T}}(X_{M \cap \textrm{Sh}})}{p_{\text{\tiny S}}(X_{M \cap \textrm{Sh}})} \right] && \text{ Since Assumption~\ref{a:overlap} holds}\\
\end{align*}
 Thus, $\tau_{\text{\tiny RR}}$ is generalizable with covariates $X_{M \cap \textrm{Sh}}$ when $m_b=0$, if one has access to $\mathbb{E}_{\text{\tiny T}}\left[ Y^{(0)} \mid X_{M \cap \textrm{Sh}} \right]$.

\bigskip 

\textbf{Second case.}
Assume that, for all $x$, $m_g(x)=0$. As above, we have
\begin{align*}
    \tau^{\text{\tiny S}}_{\text{\tiny SR}}(X_{M \cap \textrm{Sh}})
    &= \frac{1 - \mathbb{E}_{\text{\tiny S}}\left[ Y^{(1)} | X_{M \cap \textrm{Sh}} \right] }{1 - \mathbb{E}_{\text{\tiny S}}\left[ Y^{(0)} | X_{M \cap \textrm{Sh}} \right]} \\
    & = \frac{1 - b(X_{M \cap \textrm{Sh}}) - (1 - b(X_{M \cap \textrm{Sh}})) m_b\left(X_{M \cap \textrm{Sh}}\right)  }{1 - b(X_{M \cap \textrm{Sh}})} && \text{Lemma~\ref{lemma:intrication_model}}\\
    & = 1 - m_b\left(X_{M \cap \textrm{Sh}}\right)\\
    & = 1 - \mathbb{P}_{\text{\tiny S}}\left[ Y^{(1)} = 1 \mid Y^{(0)} = 0, X_{M \cap \textrm{Sh}}\right] \\
    & = 1 - \mathbb{P}_{\text{\tiny S}}\left[ Y^{(1)} = 1 \mid Y^{(0)} = 0, X_{\textrm{Sh}}\right] && \text{Definition~\ref{def:two-kind-covariates}}\\
    & = 1 - \mathbb{P}_{\text{\tiny T}}\left[ Y^{(1)} = 1 \mid Y^{(0)} = 0, X_{\textrm{Sh}}\right] && \text{Definition~\ref{def:shidted-covariates}}\\
    & = 1 - \mathbb{P}_{\text{\tiny T}}\left[ Y^{(1)} = 1 \mid Y^{(0)} = 0, X_{M \cap \textrm{Sh}} \right] && \text{Definition~\ref{def:two-kind-covariates}}\\
    & = \tau^{\text{\tiny T}}_{\text{\tiny RR}}(X_{M \cap \textrm{Sh}}).
\end{align*}
As above, one can use the arguments in the proof of Lemma~\ref{lemma:collapsibility-of-RR-SR} to show that 
\begin{align*}
    \tau^{\text{\tiny T}}_{\text{\tiny SR}} &=\mathbb{E}_{\text{\tiny S}}\left[\tau^{\text{\tiny S}}_\text{\tiny SR}(X_{M \cap \textrm{Sh}}) \frac{1-\mathbb{E}_{\text{\tiny T}}\left[ Y^{(0)} \mid X_{M \cap \textrm{Sh}} \right]}{1-\mathbb{E}_{\text{\tiny T}}\left[ Y^{(0)}\right] } \frac{p_{\text{\tiny T}}(X_{M \cap \textrm{Sh}})}{p_{\text{\tiny S}}(X_{M \cap \textrm{Sh}})}\right],
    \end{align*}
which proves that $\tau^{\text{\tiny T}}_{\text{\tiny SR}}$ is generalizable with covariates $X_{M \cap \textrm{Sh}}$ when $m_g=0$, if one has access to $\mathbb{E}_{\text{\tiny T}}\left[ Y^{(0)} \mid X_{M \cap \textrm{Sh}} \right]$.


%All others causal measure would not allow such equalities due to their intrication with the baseline. For example,
%\begin{align*}
 %   \tau^{\text{\tiny S}}_{\text{\tiny RD}}(X_M \cap \textrm{Shift})
%    &= \mathbb{E}\left[ \left( 1-b\left(X\right) \right) m_b\left(X\right)\right] -  \mathbb{E}\left[ b\left(X\right)m_g\left(X\right) \right]&& \text{Lemma~\ref{lemma:expression-of-causal-quantities-under-generative-model-binary-outcome}} \\
%    &= 1-\mathbb{E}^{\text{\tiny S}}\left[ Y^{(1)}=1 \mid Y^{(0)}=0, X \cap \textrm{Shift} \right] && \text{Definition~\ref{def:two-kind-covariates}} \\
%    &= 1-\mathbb{E}^{\text{\tiny T}}\left[ Y^{(1)}=1 \mid Y^{(0)}=0, X \cap \textrm{Shift} \right] \\
 %   &=  \tau^{\text{\tiny T}}_{\text{\tiny SR}}(X_M \cap \textrm{Shift}).
%\end{align*}


\end{proof}

\section{Usual point of view for a binary outcome: logistic regression}\label{appendix:usual-point-of-view}


\subsection{A very general generative model}
The general habit when considering binary outcome is to consider a logistic regression model (see in the main document the example of a typical log-linear model in Equation~\ref{eq:typical-model-used-binary-Y}.
While such log-linear model rely on parametric assumptions, one would wish to keep the logistic approach but with no modeling assumption in the spirit of what is done for a continuous outcome $Y$ (see Lemma~\ref{lemma:working-model-continuous-Y}).
Positing very weak assumptions allows to write the response model with a ``baseline" function and a ``modification" function, encapsulated in a link function, usually a logit. Doing so, it is possible to model the outcome non-parametrically.


\begin{lemma}[Logit generative model for a binary outcome]\label{lemma:generative-model-binary-Y}
 Considering a binary outcome $Y$, assume that 
 
 \begin{equation*}
     \forall x \in \mathds{X},\, \forall a \in \{0,1\},\quad 0 < p_a(x) < 1,\quad \text{where } p_a(x)  = \mathbb{P}(Y^{(a)} = 1 \mid X=x).
 \end{equation*}

 Then, there exist two functions $b, m:\mathcal{X} \to \mathbb{R}$ such that

\begin{equation*}
\operatorname{ln}\left( \frac{\mathbb{P}(Y^{(a)} = 1 \mid X)}{\mathbb{P}(Y^{(a)} = 0 \mid X) } \right) = b(X) + a\, m(X).
\end{equation*}
\end{lemma}


Similarly than for the continuous outcomes, the assumption allowing the existence of such functions is very weak, only asking for the counterfactual probabilities to be distinct from $0$ and $1$.
The notations have been chosen to reflect the previous idea of a \textit{baseline} $b(x)$ and the \textit{modification} $m(x)$ induced by the treatment $A$. Still, we point out that in this model, $p_0(x) \neq  b(x)$, and that due to the link function, $b(x)$ and $m(x)$ can not be disentangled.





\begin{proof}
{\footnotesize {\color{Blue} Consider $a \in \{0,1\}$, and assume that their exists a function $p_a:\mathbb{R}^d \to ]0,1[$ such that,

\begin{equation*}
    \mathbb{P}(Y^{(a)} = 1 \mid X) = p_a(X).
\end{equation*}


Because $p_a$ takes values in  $]0,1[$ the odds can be considered, so that,

\begin{equation*}
    \operatorname{ln}\left(\frac{\mathbb{P}(Y^{(a)} = 1 \mid X)}{\mathbb{P}(Y^{(a)} = 0 \mid X) }\right) =   \operatorname{ln}\left(\frac{p_a(X)}{1-p_a(X)}\right).
\end{equation*}

Denoting, 

\begin{equation*}
    b(X) := \operatorname{ln}\left(\frac{p_0(X)}{1-p_0(X)}\right),
\end{equation*}

and

\begin{equation*}
   m(X) \ := \operatorname{ln}\left(\frac{p_1(X)}{1-p_1(X)}\right) - \operatorname{ln}\left(\frac{p_0(X)}{1-p_0(X)}\right) = \operatorname{ln}\left(\frac{p_1(X)}{1-p_1(X)}\, \frac{1-p_0(X)}{p_0(X)} \right),
\end{equation*}

one can write the log-odds as

\begin{equation*}
    \operatorname{ln}\left(\frac{\mathbb{P}(Y^{(a)} = 1 \mid X)}{\mathbb{P}(Y^{(a)} = 0 \mid X) }\right) =   b(X) + A\, m(X).
\end{equation*}

Note that another link function could have been chosen, which impacts how $b(x)$ and $m(x)$ are defined.}}
\end{proof}



\paragraph{Comment on the usual practice}
In many papers it is possible to find this very common assumption
\begin{equation}\label{eq:typical-model-used-binary-Y}
   \operatorname{ln}\left( \frac{\mathbb{P}(Y^{(a)} = 1 \mid X)}{\mathbb{P}(Y^{(a)} = 0 \mid X) } \right) = \beta_0 + \langle \boldsymbol{\beta}, \boldsymbol{X} \rangle + A\,m,
\end{equation}
which corresponds to a linear function $b(X)$ and a constant function $m(X)$ \citep{Daniel2020MakingApple}. In particular, it is easy to derive from \eqref{eq:typical-model-used-binary-Y} that for any $X\in \mathds{X}$, one has $\tau_{\text{\tiny log-OR}} (x) = m$ and $\tau_{\text{\tiny OR}} (x) = e^{m}$. And more generally,

\begin{lemma}[Conditional log odds ratio]\label{lem:conditional-odds-ratio}
Ensuring conditions of Lemma~\ref{lemma:generative-model-binary-Y} leads to,

\begin{equation*}
     \mathbb{E}\left[ \tau_{\text{\tiny log-OR}} (X) \right]:= \mathbb{E}\left[\operatorname{ln}\left( \frac{\mathbb{P}(Y^{(1)} = 1 \mid X)}{\mathbb{P}(Y^{(1)} = 0 \mid X) } \, \left( \frac{\mathbb{P}(Y^{(0)} = 1 \mid X)}{\mathbb{P}(Y^{(0)} = 0 \mid X) }  \right)^{-1} \right) \right]=  \mathbb{E}\left[m(X)\right].
\end{equation*}


\end{lemma}

This result is apparently satisfying, where $\mathbb{E}\left[ \tau_{\text{\tiny log-OR}} (X) \right]$ somehow only grasps the modification function. Still, note that due to non-collapsibility of the odds ratio, this \underline{does not imply} that $\tau_{\text{\tiny log-OR}} = \tau$ (i.e. $\tau_{\text{\tiny OR}}= e^{\tau}$) because $ \mathbb{E}\left[ \tau_{\text{\tiny log-OR}} (X) \right] \neq  \tau_{\text{\tiny log-OR}}$ (except if treatment effect is null or if the outcome does not depend on $X$, that is $b(X)$ and $m(X)$ are both scalars). As an intermediary conclusion, the working model from Lemma~\ref{lemma:generative-model-binary-Y} leads to complex expression of causal measures, except for $\mathbb{E}\left[ \tau_{\text{\tiny log-OR}} (X) \right]$, but with the default that this measure shows bad property of non-collapsibility.







\subsection{The equivalent of Lemma~\ref{lemma:expression-of-causal-quantities-under-generative-model-continuous-outcome}}

\begin{lemma}\label{lemma:expression-of-causal-quantities-under-generative-model-binary-outcome}
Ensuring conditions of Lemma~\ref{lemma:generative-model-binary-Y} leads to,
\begin{equation}
  \begin{split}
     \tau_{\text{\tiny RD}} &= \mathbb{E}\left[ \frac{e^{b(X) + m(X)}}{1+e^{b(X) + m(X)}}  \right] - \mathbb{E}\left[ \frac{e^{b(X)}}{1+e^{b(X)}}  \right]  \\
       \tau_{\text{\tiny ERR}} &= \mathbb{E}\left[ \frac{e^{b(X) + m(X)}}{1+e^{b(X) + m(X)}}  \right] \left(\mathbb{E}\left[ \frac{e^{b(X)}}{1+e^{b(X)}}  \right]  \right)^{-1} -1  \\ 
      \tau_{\text{\tiny NNT}} &= \left( \mathbb{E}\left[ \frac{e^{b(X) + m(X)}}{1+e^{b(X) + m(X)}}  \right] - \mathbb{E}\left[ \frac{e^{b(X)}}{1+e^{b(X)}}  \right] \right)^{-1}   
       \end{split}
       \qquad
       \begin{split}
     \tau_{\text{\tiny RR}} &= \mathbb{E}\left[ \frac{e^{b(X)+m(X)}}{1+e^{b(X)+m(X)}}\right] \left( \mathbb{E}\left[ \frac{e^{b(X)}}{1+e^{b(X)}}\right] \right)^{-1} \\
     \tau_{\text{\tiny SR}} &= \mathbb{E}\left[ \left( 1 + e^{b(X)+m(X)} \right)^{-1}  \right] \left(\mathbb{E}\left[ \left(1 + e^{b(X)}  \right)^{-1} \right]\right)^{-1} \\
     \tau_{\text{\tiny OR}} &= \frac{\mathbb{E}\left[ \frac{e^{b(X)+m(X)}}{1 +e^{b(X)+m(X)} }\right]}{\mathbb{E}\left[ \frac{1}{1+e^{b(X)+m(X)}}\right]} \frac{\mathbb{E}\left[ \frac{1}{1 + e^{b(X)} }\right]}{\mathbb{E}\left[ \frac{e^{b(X)}}{1+e^{b(X)}}\right]} 
\end{split}
\end{equation}
\end{lemma}

For example the rather simple expression of RD for the continuous outcome now shows bewildering and complex forms when having a binary outcome.
For example, a working model such that $m(x) = m$ is a constant don't lead to any measures to be constant.
All expressions from Lemma~\ref{lemma:expression-of-causal-quantities-under-generative-model-binary-outcome} now involve both $b(.)$ and $m(x)$. All other metrics show complex relation between the two functions. 


\subsection{Link between the intrication model and the logistic model}\label{appendix:link-intrication-Russian-Roulette}

Denoting $b_1(X)$ and $m_1(X)$ the functions for the intrication model, and $b_2(X)$ and $m_2(X)$ for the logistic model, one has:


\begin{equation*}
   b_2(X) = \operatorname{ln}\left(\frac{b_1(X)}{1-b_1(X)}\right)
\end{equation*}

and 


\begin{align*}
    m_2(X) &= \operatorname{ln}\left( \frac{\left(m_1(X) + b_1(X))(1-b_1(X))\right)}{1-\left(m_1(X) + b_1(X))(1-b_1(X))\right)}\right)  -   \operatorname{ln}\left(\frac{b_1(X)}{1-b_1(X)}\right)
\end{align*}


Taking the case of the Russian Roulette, one has

\begin{equation*}
    b_1(X) := p_0(X), \quad m_1(X) = \frac{1}{6}
\end{equation*}

so that 
\begin{equation*}
     b_2(X) := \operatorname{ln}\left(\frac{X}{1-X}\right)
\end{equation*}

and

\begin{equation*}
     m_2(X) := \operatorname{ln}\left( \frac{\left(\frac{1}{6} + p_0(X) \right)}{1-\left(\frac{1}{6} + p_0(X))(1-p_0(X))\right)}\right)  -   \operatorname{ln}\left(\frac{p_0(X)}{1-p_0(X)}\right).
\end{equation*}

Despite a rather simple example, it is non-intuitive to encode it into the logistic model due to the link function.



\section{Complements on the intrication model}\label{appendix:more-details-on-the-intrication-model}

\textbf{Origin of the example}\\


\textit{Here we provide more details on how the Russian Roulette is stated in \cite{CinelliGeneralizing2019}. Note that the first reference we have found of this problem is in \cite{Huitfeldt2019LessWrong}. This section is just meant to recall how the problem was initially introduced by \cite{Huitfeldt2019LessWrong}.}\\


Suppose the city of Los Angeles decides to run a randomized control trial.  Running the experiment, the mayor of Los Angeles discovers that “Russian Roulette” is harmful: among those assigned to play Russian Roulette, 17.5\% of the people died, as compared to only 1\% among those who were not assigned to play the game (people can die due to other causes during the trial, for example, prior poor health conditions). This example is a good toy example as the mechanism is well-known, with a chance of one over six to die when playing. Even if it seems counter-intuitive, we consider the treatment as being forced to play to the russian roulette (we consider the player plays only one time). 
We denote $\Pi$ the population from Los Angeles. In that case, we can already note that the RR is $17.5$ and the ATE is $0.165$ (outcome being $Y$ equals to 1 if death before the end of the period). With this notation $\mathrm{E}[Y^{(0)} | pop = \Pi] = 0.01$ and $\mathrm{E}[Y^{(1)} | pop = \Pi] = 0.175$\\

After hearing the news about the Los Angeles experiment, the mayor of New York City (a dictator, and we propose to denote the population of New York City $\Pi^*$) wonders what the overall mortality rate would be if the city forced everyone to play Russian Roulette. Currently, the practice of Russian Roulette is forbidden in New York, and its mortality rate is at 5\% (4\% higher than LA, being $\mathrm{E}[Y^{(0)} | pop = \Pi^*] = 0.05$). The mayor thus asks the city’s statistician to decide whether and how one could use the data from from Los Angeles to predict the mortality rate in New York, once the new policy is implemented. But in fact, knowing the mechanism of the russian roulette we can already compute the value of interest being $\mathrm{E}[Y^{(1)} | pop = \Pi^*]$. Results are presented in Table~\ref{tab:summmary_russian_roulette}. Here we used the fact that mortality is a consequence of two “independent” processes (the game of Russian Roulette and prior health conditions of the individual), and while the first factor remains unaltered across cities, the second intensifies by a known amount (5\% vs 1\%).  Moreover, we can safely assume that the two processes interact disjunctively, namely, that death occurs if and only if at least one of the two processes takes effect. We can also - within the two cities - compute the associated RR, ATE and survival ratio (SR). We can observe they are not the same, but only the survival ratio comparing how many people dies with treatment on how many people would have died without treatement, transport the \textit{mechanism} of the Russian Roulette (note that $\frac{5}{6} \sim 0.83$).


\begin{table}[!h]
\begin{center}
\begin{tabular}{l|l|l}
\hline
Population &  Los Angeles ($\Pi$) & New York city ($\Pi^*$)  \\ \hline \hline
$\mathrm{E}\left[Y^{(0)}\right]$ & 0.01 & 0.05 \\ \hline
$\mathrm{E}\left[Y^{(1)}\right]$ & $\frac{1}{6}0.99 + 0.01 = 0.175$ & $\frac{1}{6}0.95 + 0.05 = 0.208$ \\ \hline
RR & 17.5  & 4.16 \\ \hline
ATE & 0.165 & 0.158 \\ \hline
SR & 0.83 & 0.83 \\
\end{tabular}
\caption{Summary of the different values. Note that none of the transport equation is applied, everything is computed within each population taking into account a distinct mechanism between the two reasons to die. SR corresponds to the survival ratio.}
\label{tab:summmary_russian_roulette}
\end{center}
\end{table}


\textbf{A limit case, when $b(x) \ll m(x)$}\\

We recall the intuitive model we have proposed in \eqref{eq:intuition-of-intrication}. 

\begin{align*}
    \mathbb{P}\left[ Y^{(a)} = 1 \mid X = x\right] &= b(x) + a\,\underbrace{\textcolor{RoyalBlue}{\left(1-b\left(x \right)\right)}}_\textrm{Intrication}\, \frac{1}{6}.
\end{align*}


Comparing the intrication model from \eqref{eq:intuition-of-intrication}, one can observe that, compared to the working model of the continuous outcome (Lemma~\ref{lemma:working-model-continuous-Y}) the baseline and the effect of the treatment are entangled. Interestingly, if  $b(x) \ll m(x)$ (in particular, the baseline is close to $0$) then it is possible to have:
\begin{equation*}
    \text{If,  } p_0(x) \ll 1, \quad \text{then,} \quad \mathbb{P}\left[ Y^{(a)} \mid X = x\right] \approx b(x) + a\,m(x),
\end{equation*}
such that we retrieved the intuition of the continuous outcome model, and remove the entanglement as expected.


Application of Lemma~\ref{lemma:expression-of-causal-quantities-under-generative-model-binary-outcome-intrication-model} for the Russian Roulette example gives:
\begin{equation*}
\begin{aligned}
    &\tau_{\text{\tiny RD}} = \frac{1}{6}\left(1 - \mathbb{E}\left[b(x) \right]  \right),\quad   \tau_{\text{\tiny NNT}} = \frac{6}{1-  \mathbb{E}\left[b(x) \right] }  ,\quad 
    \tau_{\text{\tiny RR}} = \frac{5}{6} + \frac{1}{ \mathbb{E}\left[b(x) \right] } \frac{1}{6},\quad \tau_{\text{\tiny SR}} =\frac{5}{6}, \\ 
    &\text{and}\quad \tau_{\text{\tiny OR}} = \left(1 + \frac{\mathbb{E}\left[(1-b(X)) \right]}{\mathbb{E}\left[ b(X)\right]} \frac{1}{6} \right) \frac{\mathbb{E}\left[1-b(X) \right]}{\mathbb{E}\left[(1-b(X)) \right]}\frac{6}{7}.
    \end{aligned}
\end{equation*}




\section{Different points of view}\label{appendix:different-point-of-views}

\textit{This section gathers quotes from research papers or books. The aim is to illustrate how diverse opinions are.}

\paragraph{General remarks about the choice of measure}
\begin{quote}
    Physicians, consumers, and third-party payers may
be more enthusiastic about long-term preventive treatments when benefits are stated as relative, rather than absolute, reductions in the risk of adverse events.
Medical-journal editors have said that reporting only relative reductions in risk is usually inadequate in scientific articles and have urged the news media to consider the importance of discussing both absolute and relative risks. For example, a story reporting that
in patients with myocardial infarction, a new drug
reduces the mortality rate at two years from 10 percent to 7 percent may help patients weigh both the
3 percent absolute and the 30 percent relative reduction in risk against the costs of the drug and its side
effects. -- \citep{moynihan2000coverage}
\end{quote}

\begin{quote}
    In general, giving only the absolute or only the relative benefits does not tell the full story; it is more
informative if both researchers and the media make
data available in both absolute and relative terms.  -- \citep{moynihan2000coverage}
\end{quote}

\begin{quote}
    The promotion of a measure often reflects personal preferences – those who are keen to promote the use of research in practice emphasize issues of interpretability of risk ratios and risk differences, those who are keen to ensure mathematical rules are always obeyed emphasize the limitations and inadequacies of the same measures. -- \citep{Deeks2022IssuesInSelection}
\end{quote}

\begin{quote}
    Failing to report NNT may influence the interpretation of study results. For example reporting RR alone may lead a reader to believe that a treatment effect is larger than it really is. -- \citep{Nuovo2002ReportingNNT}
\end{quote}

\begin{quote}
    As \textit{evidence-based practitioners}, we must decide which measure of association deserves our focus. Does it matter? The answer is yes. The same results, when presented in different ways, may lead to different treatment decisions. -- \citep{Cook2014UserGuide}
\end{quote}

\begin{quote}
    You must, however, distinguish between the RR and the RD. The reason is that the RR is generally far larger than the RD, and presentations of results in the form of RR (or RRR) can convey a misleading message. -- (focusing on binary outcome) \citep{Cook2014UserGuide}
\end{quote}

\begin{quote}
    Standard measures of effect, including the risk ratio, the odds ratio, and the risk difference, are associated with a number of well-described shortcomings, and no consensus exists about the conditions under which investigators should choose one effect measure over another. -- \citep{huitfeldt2018choice}
\end{quote}

\begin{quote}
    Additive treatment effect heterogeneity is also most informative for guiding public health policy that aims to maximize the benefit or minimize the harm of an exposure by targeting subgroups. The relative scale (risk ratios or odds ratios) can tend to overstate treatment benefits or harms. -- \citep{lesko2018considerations}
\end{quote}

\begin{quote}
   The way to express and measure risk may appear to be a pure technicality. In fact, it is a crucial element of the risk-benefit balance that underlies the dominant medical discourse on contraception. Its influence on the perception and communication of risk is decisive, especially among people without a solid statistical education, like most patients and doctors who prescribe the pill (mostly generalists and gynaecologists). The dispute over \textit{Non-rare thrombophilia} (NRT) screening sets an important difference between the absolute risk, the number of events occurring per time unit and the relative risk, which is the ratio between two absolute risks. Practically, whereas the relative risk may sound alarming, the absolute risk looks more reassuring. -- \citep{Bourgain2021Appraising}
\end{quote}

\begin{quote}
    We believe if an efficacy measure is
    \begin{itemize}
        \item well defined,
        \item understandable by human,
        \item desired by patients and clinicians,
        \item proven to be logic-respecting\footnote{see Definition~\ref{def:logic-respecting}.},
        \item readily implementable computationally,
    \end{itemize}

    them it is worthy of consideration. -- \citep{liu2022rejoinder}
\end{quote}


\paragraph{The odds ratio as a complex measure to interpret}


\begin{quote}
    Odds ratios and parameters of multivariate models will often be useful in serving as or in constructing the estimates, but should not be treated as the end product of a statistical analysis of epidemiologic data or as summaries of effect in themselves. -- \citep{Greenland1987Interpretation}
\end{quote}


\begin{quote}
   The concept of the odds ratio is now well-established in epidemiology, largely because it serves as a link between results obtainable from follow-up studies and those obtainable from case-control studies. [$\dots$] This ubiquity, along with certain technical considerations, has led some authors to treat the odds ratio as perhaps a ``universal" measure of epidemiologic effect, in that they would estimate odds ratios in follow-up studies as well as case-control studies; others have expressed reservations about the utility of the odds ratio as something other than an estimate of an incidence ratio. I believe that such controversy as exists regarding the use of the odds ratio arises from its inherent disadvantages compared with the other measures for biological inference, and its inherent advantages for statistical inference.  -- \citep{Greenland1987Interpretation}
\end{quote}


\begin{quote}
   There is a problem with odds: unlike risks, they are difficult to understand.  -- \citep{davies1998can}
\end{quote}


\begin{quote}
    Another measure often used to summarise effects of treatment is the odds ratio. This is defined as the odds of an event in the active treatment group divided by the odds of an event in the control group. Though this measure has several statistical advantages and is used extensively in epidemiology, we will not pursue it here as it is not helpful in clinical decision making. -- \citep{Cook1995NNT}
\end{quote}

\begin{quote}
    In logit and other multiplicative intercept models (but not generally), OR also has the attractive feature of being invariant with respect to the values at which control variables are held constant. The disadvantage of OR is understanding what it means, and when OR is not the quantity of interest then its ‘advantages’ are not suficient to recommend its use. Some statisticians seem comfortable with OR as their ultimate quantity of interest, but this is not common. Even more unusual is to find anyone who feels more comfortable with OR than the other quantities defined above; we have found no author who claims to be more comfortable communicating with the general public using an odds ratio. -- \citep{king2002estimating}
\end{quote}


\begin{quote}
    The OR lacks any interpretation as an average. -- \citep{Cummings2009RelativeMeritsRRAndOR}
\end{quote}
\begin{quote}
    As is well established, the odds ratio is not a parameter of interest in public health research. -- \citep{Spiegelman2017Modeling}
\end{quote}

\begin{quote}
    Because of the exaggeration present, it is important to avoid representing ORs as RRs, and similarly, it is important to recognize that a reported OR rarely provides a good approximation of relative risks but rather simply provides a measure of correlation. -- \citep{George2020WhatsTR}
\end{quote}


\begin{quote}
    We agree with Liu et al. (2020) that (causal) odds ratios and hazard ratios are problematic as causal contrasts. The non-collapsibility of these parameters is a mathematical property which makes their interpretation awkward, and this is amplified for hazard by their conditioning on survival. Thus they are also unsuitable measures for transportability between different populations (Martinussen \& Vansteelandt, 2013). It is particularly concerning that meta-analyses pool odds ratios or hazard ratios from different studies each possibly using different variables for adjustment where the issue of non-collapsibility is typically ignored. -- \citep{Didelez2021collapsibility}
\end{quote}


\begin{quote}
    ORs are notoriously difficult to interpret. When people hear “odds” they think of “risks” and this leads to the common misinterpretation of the OR as a RR by scientists and the public, which is a serious concern. For example, an OR of 2 is not generally a doubling of risk (if the risk in the control group is 20\% and the OR is 2, then the risk in the treated group is 33.3\% not 40\%). In contrast, the RD and RR offer clearer interpretations. -- \citep{xiao2022IsORPortable}
\end{quote}

\begin{quote}
    The admitted mathematical niceties of the OR are not reason enough to accept such a confusing state of affairs. Of course, when the outcome is rare, the OR approximates the RR and is, therefore, approximately collapsible.-- \citep{xiao2022IsORPortable}
\end{quote}

\begin{quote}
    Because of the interpretability issues and lack of collapsibility, we urge researchers to avoid ORs when either the RD or RR is available. -- \citep{xiao2022IsORPortable} 
\end{quote}

\begin{quote}
    Odds ratios provoke similar discomfort—only 19\% of learners and 25\% of speakers at an annual meeting of the Canadian Society of Internal
Medicine (CSIM) understood odds ratios well enough to explain them to others. -- \citep{Lapointe2022FromMathToMeaning}
\end{quote}

\paragraph{The OR is a better metric to use than RR}

\begin{quote}
    The results demonstrate the need to a) end the primary use of the RR in clinical trials and meta-analyses as its direct interpretation is not meaningful; b) replace the RR by the OR; and c) only use the post-intervention risk recalculated from the OR for any expected level of baseline risk in absolute terms for purposes of interpretation such as the number needed to treat. -- \citep{Doi2020callToChangePractice}
\end{quote}

\begin{quote}
    We can no longer accept the commonly argued for view that the relative risk is easier to understand. Once we realize that the RR depends more on prevalence than the exposure-outcome association, its interpretation becomes much more difficult to comprehend than the odds ratio. It is well known that, for common events, large values of the risk ratio are impossible and this should have rung the alarm bells much earlier regarding whether the RR is more a measure of prevalence than a measure of effect. However this was not the main focus of the derivation outlined previously and the latter was aimed at demonstrating why the OR is a true measure of effect against which the RR can be compared. -- \citep{Doi2020callToChangePractice}
\end{quote}


\begin{quote}
    Our response to this is that, although this is certainly a problem, there is an even bigger problem – \textit{the RR is not a portable measure of effect}. By "portable" we mean a numerical value that is not dependent on baseline risk and not transportability in causal inference. --- \citep{doi2022TimeToDoAway}
\end{quote}



\paragraph{Relative versus absolute measures}
\begin{quote}
    In reviewing the different ways that benefit and harm can be expressed, we conclude that the RD is superior to the RR because it incorporates both the baseline risk and the magnitude of the risk reduction. -- \citep{Laupacis1988AnAssessmentOfClinically}
\end{quote}


\begin{quote}
    For clinical decision making, however, it is more meaningful to use the measure “number needed to treat.” This measure is calculated on the inverse of the absolute risk reduction. It has the advantage that it conveys both statistical and clinical significance to the doctor. Furthermore, it can be used to extrapolate published findings to a patient at an arbitrary specified baseline risk when the relative risk reduction associated with treatment is constant for all levels of risk. -- \citep{Cook1995NNT}
\end{quote}



\begin{quote}
    Medical journals need to be conscious that they will contribute to scaremongering newspaper headlines if they do not request authors to quantify Adverse Drug Reactions (ADR) into best estimates of absolute numbers. -- \citep{Mills1999PillScare}
\end{quote}


\begin{quote}
    As a relative measure of effect, the RR is most directly estimated by the multiplicative model when it fits the data. The risk difference is an absolute measure of effect, most directly estimated by the additive model when it fits the data. -- \citep{Spiegelman2017Modeling}
\end{quote}

\paragraph{About portability or generalizability of causal effects}



\begin{quote}
    The numbers needed to treat method still presents a
problem when applying the results of a published
randomised trial in patients at one baseline risk to a
particular patient at a different risk. -- \citep{Cook1995NNT}
\end{quote}
\begin{quote}
    Some authors prefer odds ratios because they believe a constant (homogeneous) odds ratio may be more plausible than a constant risk ratio when outcomes are common. -- \citep{Cummings2009RelativeMeritsRRAndOR}
\end{quote} 

\begin{quote}
    All of this assumes a constant RR across risk groups; fortunately, a more or less constant RR is usually the case, and we suggest you make that assumption unless there is evidence that suggests it is incorrect. -- \citep{Cook2014UserGuide}
\end{quote}



\begin{quote}
    Although further and more formal quantitative work evaluating the relative degree of heterogeneity for risk ratio versus risk differences may be important, the previously mentioned considerations do seem to provide some indication that, for whatever reason, risk ratio modification is uncommon. -- \citep{Spiegelman2017Modeling}
\end{quote}

\begin{quote}
    It is commonly believed that the risk ratio is a more homogeneous effect measure than the risk difference, but recent methodological discussion has questioned the evidence for the conventional wisdom. -- \citep{huitfeldt2018choice}
\end{quote}

\begin{quote}
    In the real world of clinical medicine, doctors are usually given information about the effects of a drug on the risk ratio scale (the probability of the outcome if treated, divided by the probability of the outcome if untreated). With information on the risk ratio, a doctor may make a prediction for what will happen to the patient if treated, by multiplying the risk ratio and patient's risk if untreated (which is predicted informally based on observable markers for the patient's condition).  -- \citep{Huitfeldt2019LessWrong}
\end{quote}


\begin{quote}
    In this article we will show that the RR is not a measure of the magnitude of the intervention-outcome association alone because it as stronger relationship with prevalence and therefore is not generalizable beyond the baseline risk of the population in which it is computed. -- \citep{Doi2020callToChangePractice}
\end{quote}


\begin{quote}
    It is possible that no effect measure is “portable” in a meta-analysis. In cases where portability of the effect measure is challenging to satisfy, we suggest presenting the conditional effect based on the baseline risk using a bivariate generalized linear mixed model. The bivariate generalized linear mixed model can be used to account for correlation between the effect measure and baseline disease risk. Furthermore, in addition to the overall (or marginal) effect, we recommend that investigators also report the effects conditioning on the baseline risk. -- \citep{xiao2022IsORPortable}
\end{quote}

\begin{quote}
    Despite some concerns, the RR has been widely used because it is considered a measure with “portability” across varying outcome prevalence, especially when the outcome is rare. -- \citep{Suhail2022CallForChange}
\end{quote}


\section{Comments and answers to related article}

As highlighted by the length of the references or even by Section~\ref{appendix:different-point-of-views}: the literature on the choice of causal measures is prolific. In this Section, we propose comments or answers to previous articles in order to show how our contributions either complete what was said or shed lights on a different apprehension of the problem.

\subsection{Comments of \cite{Cook1995NNT}}

 \cite{Cook1995NNT}'s widely cited paper promotes the usage of absolute measure versus relative measure for clinical decision. In particular they advocate the NNT as it is easier to interpret than a difference of probabilities (RD). For example, we quote such a section:

 \begin{quote}
    \textit{ For example, an estimated relative risk reduction of 50\% might be statistically significant and clinically important for patients at moderate to high risk of a particular adverse event. However, for patients with a low probability of an event the risk reduction might not be sufficient to warrant the toxicity and cost of active treatment. This is the main criticism of relative measures of treatment effect for the purposes of clinical decision making.}
 \end{quote}


We agree on the fact that for a binary outcome an absolute measure better (such as the NNT) incorporates the baseline level, and therefore may be more informative for a patient (see for example Lemma~\ref{lemma:expression-of-causal-quantities-under-generative-model-binary-outcome}). In this article authors use clinical data on which the risk ratio is constant across subgroups, and the treatment effect is beneficial. Interestingly, this what we show with the intrication model, that if one measure is more likely to be constant across different populations or subgroup: this is the RR (or the SR depending on the direction of the effect). These qualitative observations are completely coherent with Lemmas~\ref{lemma:expression-of-causal-quantities-under-generative-model-binary-outcome-intrication-model} and \ref{lemma:monotonous-effect}.



\subsection{Comments of \cite{Cummings2009RelativeMeritsRRAndOR}}

\cite{Cummings2009RelativeMeritsRRAndOR} propose a review of how the OR and the RR differ. In particular, they review typical arguments for pro and cons, while providing examples. In this section, we want to comment how the intrication model (Lemma~\ref{lemma:intrication_model}) allows to formalize many of their arguments and examples.


\begin{quote}
    \textit{Some authors prefer odds ratios because they believe a constant (homogeneous) odds ratio may be more plausible than a constant risk ratio when outcomes are common. Risk range from 0 to 1. Risk ratios greater than 1 have an upper limit constrained by the risk when not exposed. For example the risk when not exposed is $0.5$, the risk ratio when exposed cannot exceed $2: 5\cdot 2 = 1$. In a population with an average risk ratio of $2$ for outcome $Y$ among those exposed to $X$, assuming that the risk for $Y$ if not exposed to $X$ varies from .1 to .9, the average risk ratio must be less than $2$ for those with risks greater than  $0.5$ when not exposed. Because the average risk ratio for the entire population is $2$, the average risk ratio must be more than $2$ for those with risks less than $.5$ when not exposed. Therefore, a risk ratio of $2$ cannot be constant (homogeneous) for all individuals in a population if risk when not exposed is sometimes greater than $.5$. More generally, if the average risk ratio is greater than $1$ in a population, the individual risk ratios cannot be constant (homogeneous) for all persons if any of them have risks when not exposed that exceed 1/average risk ratio. }
\end{quote}

The authors claim that if $\tau_{\text{\tiny RR}} > 1$, then

\begin{itemize}
    \item The RR has an upper limit linked to the risk of the unexposed ($p_0(x) = b(x)$),
    \item Or, the RR cannot be constant on every individuals if their risk is above a certain threshold being equal to 1/average risk ratio.
\end{itemize}

The intrication model perfectly describes such a situation, and we propose to illustrate why. As authors consider that $\tau_{\text{\tiny RR}} > 1$, then we use Lemma~\ref{lemma:intrication_model} with $\forall x,\,  m_g(x)=0$. More specifically, the authors mention that for $\tau_{\text{\tiny RR}} > 1$ (that we rather model as $\forall x,\,  m_g(x)=0$), it is not possible to have a constant RR on each subgroup. We recall that, 

\begin{align}\label{eq:cumming1}
 \forall x, \,   \tau_{\text{\tiny RR}}(x) =  1 + \frac{1-b(x)}{b(x)}m_b(x)
\end{align}
If $\tau_{\text{\tiny RR}}(x)$ is assumed constant, one can plot the probability $m_b(x)$ as a function of $b(x)$ and observe that indeed this quantity is bounded and/or that $m_b(x)$ can not exist for all baseline $b(x)$. We illustrate this equation on Figure~\ref{fig:cumming1}.


\begin{figure}[H]
    \begin{minipage}{.35\linewidth}
	\caption{\textbf{Illustration of the impossibility of having a constant $\tau_{\text{\tiny RR}}(x) > 1$ if allowing all ranges for baseline risks $p_0(x)$}: This plot illustrates \eqref{eq:cumming1} for several constant values of $\tau_{\text{\tiny RR}}(x)$ (from $1.2$ to $4$), showing how the baseline risk $p_0(x)$ implies different values of $m_b(x)$. If the baseline risk is too high, then there is no plausible $m_b(x)$ (the upper limit is highlighted with the dashed red line). The dark vertical dashed line illustrate the precise example of \cite{Cummings2009RelativeMeritsRRAndOR} with $\tau_{\text{\tiny RR}}(x)=2$.}
	\label{fig:cumming1}
    \end{minipage}%
    \hfill%
    \begin{minipage}{.62\linewidth}
     \includegraphics[width = 0.8\textwidth]{fig/cumming1.png}
    \end{minipage}
\end{figure}


We want to add that, as the treatment effect is assumed to increase the occurence of the event, then a better measure to use (at least if willing to maximise the chance to have a constant value for each individuals as claimed by the author) is the survival ratio (see Theorem~\ref{theorem:restricted-set-for-Y-binary-SR-RR}). In particular, the Figure~\ref{fig:cumming1} can be adapted when considering a constant SR (see Figure~\ref{fig:cumming2}). One can observe that all ranges of the baseline risks are allowed.

\begin{figure}[H]
    \begin{minipage}{.35\linewidth}
	\caption{\textbf{Illustration of the possibility to have a constant $\tau_{\text{\tiny SR}}(x) < 1$ when allowing all ranges for baseline risks $p_0(x)$}: This plot illustrates how several constant values of $\tau_{\text{\tiny SR}}(x)$ (from $0.2$ to $0.9$) is allowed for any baseline values $p(x)$. Note that this implies a constant $m_b(x)$.}
	\label{fig:cumming2}
    \end{minipage}%
    \hfill%
    \begin{minipage}{.62\linewidth}
     \includegraphics[width = 0.8\textwidth]{fig/cumming2.png}
    \end{minipage}
\end{figure}


Then, authors add the following comment.

\begin{quote}
   \textit{ Odds range from $0$ to infinity. Odds ratios greater than $1$ have no upper limit, regardless of the outcome odds for persons not exposed. If we multiply any unexposed outcome odds by an exposure odds ratio greater than 1 and convert the resulting odds when exposed to a risk, that risk will fall between $0$ and $1$. Thus, it is always hypothetically possible for an odds ratio to be constant for all individuals in a population.}
\end{quote}

We agree that it is always hypothetically possible for an odds ratio to be constant for all individuals (this corresponds to Lemma~\ref{lem:conditional-odds-ratio}, and $m(x)=m$ in the logistic working models). But note that this does not mean that the odds ratio at the individual level is then the same for the population level due to non-collapsibility. 


\begin{quote}
    \textit{\textbf{Possibility of Constancy for Risk Ratios Less Than 1}. For both risk and odds, the lower limit is 0. For any level of risk or odds under no exposure, multiplication by a risk or odds ratio less than 1 will produce a risk or odds given exposure that is possible: 0 to 1 for risks and 0 to infinity for odds. Thus, a constant risk or odds ratio is possible for ratios less than 1. If the risk ratio comparing exposed persons with those not exposed is greater than 1, the ratio can be inverted to be less than 1 by comparing persons not exposed with those exposed. Therefore, a constant risk ratio less than 1 is hypothetically possible. This argument has been used to rebut the criticism of the risk ratio in the previous argument.}
\end{quote}

To us, this argument is a consequence of Lemma~\ref{lemma:monotonous-effect} accounting for the fact that a RR less than $1$ is comparable to $m_b(x) = 0$.



\begin{comment}
    \subsection{Link with model from \cite{Daniel2020MakingApple}}

In \cite{Daniel2020MakingApple} collapsibility is characterized differently, and this appendix aims at binding the two points of view. This follows what was also described in \cite{Neuhaus1993GeometricApproach} to assess bias due to omitted covariates in generalized linear models. Indeed, collapsibility also concerns coefficients of a model. Keeping the notation of the paper, the idea of \cite{Daniel2020MakingApple} is to write the outcome model if treated as a function of the outcome if control. More formally, for a binary outcome, recall that one can have several working model. For example taking the logistic one from Lemma~\ref{lemma:generative-model-binary-Y}, it is possible to note that there exist a function

The odds ratio is non-collapsible, and therefore the marginal effect can not be written as a weighted sum of the conditional effect. If willing to go from conditional effect to marginal effect, other methods should be used, such as fitting a logistic regression with covariates \citep{Daniel2020MakingApple}, which comes with parametric assumptions on the generative model and necessity to observe all covariates affecting the outcome.


\end{comment}



\subsection{Comment on Appendix 3 of \cite{huitfeldt2018choice}}

Many of our insight can also be found in \cite{huitfeldt2018choice} (and in particular in their Appendix). Differences come from the way the model is introduced, along with the dependency in $X_B$ and $X_M$ we highlight in the intrication model (and with the fact that we also deal with continuous outcomes). In this section, we transpose their example from Appendix 3.
What we want to highlight is that our notations and framework enable another view of the problem. First, we quote the authors.

\begin{quote}
    For illustration, we will consider an example concerning the effect of treatment with antibiotics ($A$), on mortality ($Y$). We will suppose that response to treatment is fully determined by bacterial susceptibility to that antibiotic ($X$). In the following, we will suppose that attribute $X$ has the same prevalence in populations s and t (for example because the two populations share the same bacterial gene pool) and that treatment with $A$ has no effect in the absence of $X$. Further, suppose that this attribute is independent of the baseline risk of the outcome (for example, old people at high risk of death may have the same strains of the bacteria as young people at low risk).
\end{quote}



Within the intrication model, and denoting $X=0$ the absence of the mutation, this means that:
\begin{itemize}
    \item ``attribute $X$ has the same prevalence in populations s and t" which corresponds to Definition~\ref{def:shidted-covariates};
    \item``treatment with $A$ has no effect in the absence of $X$" $m_b(X=0) = m_g(X=0) = 0$,
    \item ``Further, suppose that this attribute is independent of the baseline risk of the outcome" Here, we think that this assumption could be easily transposed in our intrication model, clearly decomposing $X_B$ and $X_M$.
\end{itemize}




\subsection{Comment on the research work from Cinelli \& Pearl}

The way \cite{CinelliGeneralizing2019} deals with the problem is to encode the assumption of the problem with selection diagrams. In particular selection diagrams are an extension of DAGs with selection nodes, those nodes are used by the
analyst to indicate which local mechanisms are suspected to differ between two environments (in our example, the mortality mechanism is suspected to differ between Los Angeles and New York, but not the mechanism).\\

A first difference to our work is that authors rather whant to predict in a target population $P_{\text{\tiny T}}$, $\mathbb{E}_{\text{\tiny T}}\left[Y^{(1)} \right]$ from $\mathbb{E}_{\text{\tiny T}}\left[Y^{(0)} \right]$ and $ \text{PS}_{01}$ and $ \text{PS}_{10}$ detailed below. Another difference is that authors mostly reason marginally, while in our work we link subpopulations with larger populations relying on collapsibility.

Cinelli and Pearl introduce the following quantities:


\begin{equation*}
    \text{PS}_{01} := \mathbb{P}\left[ Y^{(1)} = 1 \mid Y^{(0)} = 0 \right],\quad \text{and}\quad   \text{PS}_{10} := \mathbb{P}\left[ Y^{(1)} = 0 \mid Y^{(0)} = 1 \right].
\end{equation*}


Those quantity corresponds to $m_b$ and $m_g$ defined in Lemma~\ref{lemma:intrication_model}, considering those quantities are not depending on $X$. Therefore, their equation,

\begin{equation*}
    \mathbb{P}^{\Pi^*}\left[ Y^{(1)} = 1\right] = (1-\text{PS}_{10})  \mathbb{P}^{\Pi^*}\left[ Y^{(0)} = 1\right] + \text{PS}_{01}(1-\mathbb{P}^{\Pi^*}\left[ Y^{(0)} = 1\right]),
\end{equation*}

is completely equivalent to the intrication model, noting that $\mathbb{P}^{\Pi^*}\left[ Y^{(0)} = 1\right]$ corresponds to $\mathbb{E}_{\text{\tiny T}}\left[ b(x) \right]$. The intrication model rather highlight the dependencies to covariates (i.e. chracteristics), while their equation rather models the fact that only the baseline risk is necessary to be known if 

\begin{equation*}
    Y^{(1)} \indep I \mid Y^{(0)},
\end{equation*}
where $I$ is the indicator of population's membership and if effect is monotonous (and they denote $Y^{(1)} \le Y^{(0)}$ or conversely depending on the direction assumed).

In our work, such assumption is equivalent with assuming monotonicity (either $m_b(x)=0$ or $m_g(x)=0$) and that all treatment effect modifiers are not shifted.

Authors then propose to soften their assumptions deriving bounds on the target quantity $ \mathbb{P}^{\Pi^*}\left[ Y^{(1)} = 1\right] $. Our work rather keeps on targeting causal measure themselves, and  assume that we have access to the shifted covariates of $X_M$. We think this could be stated as,


\begin{equation*}
    Y^{(1)} \indep I \mid Y^{(0)}, X_M,
\end{equation*}
along with the monotonicity assumption.




\section{Details about the simulations}

\subsection{Comments on estimation}\label{appendix:comments-on-estimation}
In this paper, we have been focusing on identification rather than estimation. In this simulation, we illustrate the two approaches that can be taken when transforming identification formula (see Propositions~\ref{proposition:generalization-density} and \ref{prop:generalization-of-local-effects}) into estimation: Plug-in g-formula or Inverse Propensity Sampling Weighting (IPSW).
Existing consistency results of these approaches for the Risk Difference are reviewed in \cite{colnet2021causal}.
We assume that the data sampled from $P_{\text{\tiny S}}$ is a randomized trial $\mathcal{R}$ of size $n$ and the data sampled from $P_{\text{\tiny T}}$ is a cohort $\mathcal{T}$ of size $m$ which contains covariates information $X$ and possibly $Y^{(0)}$.

\subsubsection{Plug-in formula}

When considering \textit{generalization of the conditional outcome}, the plug-in g-formula consists in estimating the two surface responses $\mathbb{E}\left[ Y^{(a)} \mid X\right]$ using the RCT data from $P_{\text{\tiny T}}$. We denote $\hat \mu_{a, n}(X)$ the estimates ($n$ is added to indicate that estimation is performed on the trial). Any approach can be proposed, for e.g. OLS or non-parametric learners. These models are then used on the target sample to estimate the averaged expected responses,

\begin{equation}\label{estimator-cond-outcome-g-formula}
    \hat{\mathbb{E}}_{\text{\tiny T}}\left[ Y^{(a)} \right] = \frac{1}{m} \sum_{i \in \mathcal{T}} \hat \mu_{a,n}(X),
\end{equation}
where $m$ denotes the target sample size. Doing so this estimate depends on the two sample sizes, $n$ and $m$. Finally, $ \hat{\mathbb{E}}_{\text{\tiny T}}\left[ Y^{(0)} \right]$ and $ \hat{\mathbb{E}}_{\text{\tiny T}}\left[ Y^{(1)} \right]$ are then used to estimate any causal measures on the target population: RD, RR, OR, and so on. Consistency of procedure \eqref{estimator-cond-outcome-g-formula} has been proven for any consistent estimator $\hat \mu_a$ of $\mathbb{E}\left[ Y^{(a)} \mid X\right]$ in \cite{colnet2022sensitivity}.

\textit{Generalizing local effects} using a plug-in formula suggests to estimate the local treatment effect (or CATE) $\hat \tau_n(x)$ using $\mathcal{S}$. This can be done using the previously introduced $\hat \mu_{a}(X)$ too (this is called T-learner), and then making a difference or a ratio of the two depending on the causal measure someone wants to generalize. Then, one has to estimate $\hat  g_m(X, P(X,Y^{(0)}))$ using $\mathcal{T}$, for exemple using a linear model (or any other model). Finally, one can obtain the target treatment effect with


\begin{equation}\label{estimtator-local-effect-g-formula}
    \hat \tau = \frac{1}{m}\sum_{i \in \mathcal{T}} \hat g_m(X_i, P(X_i,Y_i^{(0)})) \hat \tau_n(X_i),
\end{equation}

where $m$ denotes the target sample size. Note that \eqref{estimtator-local-effect-g-formula} relies on the estimation of $\tau(X)$ directly.
While the estimation of the conditional risk difference is well described in the literature \citep{wager2018estimation, nie2020quasioracle} (to name a few), estimation of conditional ratios is way less described. We have found only one recent work dealing with such questions \citep{yadlowsky2021estimation}. Consistency of such procedure for another metric than the Risk Difference is an open research question.


\subsubsection{Inverse Propensity Sampling Weighting (IPSW)}
IPSW uses the ratio of densities to re-weight individual observation in the trial. Denoting $r(X):=\frac{p_{\text{\tiny T}}(X)}{p_{\text{\tiny S}}(X)}$ the density ratio, one has first to learn this ratio $\hat r_{n,m}(X)$ using both data set $\mathcal{S}$ and $\mathcal{T}$. 
One can \textit{generalize conditional outcomes} doing:

\begin{equation*}
    \hat{\mathbb{E}}_{\text{\tiny T}}\left[ Y^{(a)} \right] = \frac{1}{n} \sum_{i \in \mathcal{S}} \hat{r}_{n,m}(X_i)A_iY_i.
\end{equation*}
Those estimates ($\hat{\mathbb{E}}_{\text{\tiny T}}\left[ Y^{(0)} \right]$ and $\hat{\mathbb{E}}_{\text{\tiny T}}\left[ Y^{(a1} \right]$) are then used to estimate any causal measures on the target population. 



Now, considering \textit{generalizing local effects} using a re-weighing approach rather suggest to also estimate $\hat  g_m(X, P(X,Y^{(0)}))$ using $\mathcal{T}$ (for example using a linear model). Then, for e.g when considering the Risk Difference, this consists in doing

\begin{equation*}
\hat \tau_{\text{\tiny RD}} = \frac{1}{n} \sum_{i \in \mathcal{S}}\hat{r}(X_i) \left( A_iY_i - (1-A_i)Y_i\right),
\end{equation*}

or when considering the Risk Ratio, a procedure could be

\begin{equation*}
\operatorname{ln}\left(\hat  \tau_{\text{\tiny RR}} \right) =  \frac{1}{n} \sum_{i \in \mathcal{S}}\hat{r}(X_i) \left( \operatorname{ln}\left(A_iY_i\right) - \operatorname{ln}\left((1-A_i)Y_i\right) \right) \hat  g_m(X_i, P(X_i,Y_i^{(0)})).
\end{equation*}
 We use these weighting approaches for the simulation with a binary outcomes. As the purpose is not estimation, we propose a simulation with categorical covariates only, in particular to propose an estimation of $\hat r_{n,m}(X)$ as in \cite{colnet2022reweighting}. $\hat  g_m(X, P(X,Y^{(0)}))$ is estimating by computing the empirical mean of $\mathbb{E}\left[ Y^{(0)} \mid X\right]$ in each category. %Note that if covariates are categorical, \cite{colnet2022reweighting} proposes a finite and large sample characterization of IPSW when it comes to risk difference. Other works have been proposed.




\subsection{Continuous outcomes}\label{appendix:continuous}

\paragraph{Data generative process}
We assume that the outcome is generated linearly from six covariates in the two populations
\begin{equation}
\label{eq:Ymodel-simulation-continuous}
    Y(a) = 0.05 X_1 +  0.04 X_2 + 2 X_3 + X_4 + 2 X_5 - 2 X_6 + a\cdot \left(1.5 X_1 + 2 X_2 + X_5 \right) +\epsilon \mbox{ with } \epsilon \sim \mathcal{N}(0,2).
\end{equation}

The two data samples are directly sampled from two different baseline distributions.

Covariates $X_1, X_2, X_3$ are generated from 

\begin{equation*}
    \mathcal{N}\left(\left[\begin{array}{l}
6 \\
5 \\
8
\end{array}\right],\left[\begin{array}{lll}
1 & 0  & 0.5 \\
0 & 1 & 0.2 \\
0.5 & 0.2 & 1 
\end{array}\right]\right)
\end{equation*}

in $P_\text{\tiny S}$, and in 


\begin{equation*}
    \mathcal{N}\left(\left[\begin{array}{l}
15 \\
7 \\
10
\end{array}\right],\left[\begin{array}{lll}
1 & 0  & 0.5 \\
0 & 1 & 0.2 \\
0.5 & 0.2 & 1 
\end{array}\right]\right)
\end{equation*}

for $P_\text{\tiny T}$. $X_4$ is such that $X_4 \sim \mathcal{B}(1, 0.8)$ in $P_\text{\tiny S}$ and $X_4 \sim \mathcal{B}(1, 0.3)$ in $P_\text{\tiny T}$. Then, $X_5$ and $X_6$ are non-shifted covariates, where $X_5 \sim \mathcal{B}(1, 0.8)$ and $X_6 \sim \mathcal{N}(4, 1)$ in both populations.

Within the trial sample of size $n$ we generate the treatment according to a Bernoulli distribution with probability equals to $0.5$.

\paragraph{Estimation}
For this simulation we applied a plug-in g-formula approach, using Ordinary Least Squares (OLS) to estimate $\hat \mu_{a,n}$ and $\hat  g_m(X, P(X,Y^{(0)}))$. $\hat \tau_n$ is estimated combining $\hat \mu_{a,n}$ as a difference or ratio or else (T-learner).


\subsection{Binary outcomes}\label{appendix:simulation-binary}

\paragraph{Data generative process}
For this simulation the baseline covariates are categorical to ease the estimation strategy. The data generative model is build on top of \eqref{eq:intuition-of-intrication}, and adapted to give,
\begin{equation*}
    \mathbb{P}\left[ Y^{(a)} = 1 \mid X = x \right] = b(X_1, X_2, X_3) + a\,\left(1-b\left(X_1, X_2, X_3\right)\right)\,m_b(X_2, X_3),
\end{equation*}
where $X_1=\texttt{lifestyle}$, $X_2=\texttt{stress}$, and $X_3=\texttt{gender}$.

Each of the three covariates are sampled following a Bernoulli distribution. 
In $P_\text{\tiny S}$, one has $X_1 \sim \mathcal{B}(1, 0.4)$, $X_2 \sim \mathcal{B}(1, 0.8)$, and $X_3 \sim \mathcal{B}(1, 0.5)$. In $P_\text{\tiny T}$, one has $X_1 \sim \mathcal{B}(1, 0.6)$, $X_2 \sim \mathcal{B}(1, 0.2)$, and $X_3 \sim \mathcal{B}(1, 0.5)$.

The outcome is defined such as,

  \begin{equation*}
    b(X) =  \operatorname{ifelse}(X_1 = 1, 0.2, 0.05) \cdot  \operatorname{ifelse}(X_2  = 1, 2, 1) \cdot  \operatorname{ifelse}(X_3 = 1, 0.5, 1), 
  \end{equation*}

where $ \operatorname{ifelse}$ corresponds to the function with the same name in \texttt{R}. And,

  \begin{equation*}
    m_b(X) = \operatorname{ifelse}(X_2 = 1, 1/4, \operatorname{ifelse}(X_3 = 1, 1/10, 1/6)).
  \end{equation*}

Within the trial sample of size $n$ we generate the treatment according to a Bernoulli distribution with probability equals to $0.5$. 

\paragraph{Estimation} We estimate the density ratio as in \cite{colnet2022reweighting}, namely 


\begin{equation*}
   \forall x \in \mathcal{X},\;\; \hat p_{\text{\tiny T},m} (x):=  \frac{1}{m}\sum_{i \in \mathcal{T}} \mathbbm{1}_{X_i = x}\;\; \text{ and,    }\,\hat p_{\text{\tiny R},n}(x) := \frac{1}{n}\sum_{i \in \mathcal{R}} \mathbbm{1}_{X_i = x}.
\end{equation*}

As the covariates are categorical, we apply the same strategy: estimate the local effect in each combination of categories.

\begin{comment}

\subsection{Another motivating example: the pill scare of the 2000's}\label{appendix:pill-scare-simulation}
In the early 90's the rise of genetic methods leaded to the identification of several genetic mutations associated to a higher prevalence of certain diseases. 
A well-known example is the mutation called \textit{Factor V Leiden} that was associated to the resistance to a certain protein (named APC resistance), leading to an enhanced susceptibility to thrombosis (a disease that can be followed by death). 
This APC resistance was found to be rather common, for e.g. a prevalence 3 to 5 \% was found in the general Netherlands population \citep{bertina1994mutation}, but population's proportions varies across the world and can be almost absent in some populations but can reach 12\% \citep{Rees1995WorldLeiden}.
This enhanced risk of thrombosis was shown to be even greater within young women using oral contraceptives (case-control study by \cite{Vandenbroucke1994thrombosis}).
This discovery leaded to one of the most prescribed genetic test called \textit{Non-rare thrombophilia} (NRT) \citep{Bourgain2021Appraising}, even if initial investigators did not support universal screening before oral contraceptives prescription \citep{vandenbroucke1996factor}. The reasons invoked where due to the low prevalence of the mutation along with low susceptibility to thrombosis even as a carrier of the mutation. But the RR exposed in \cite{Vandenbroucke1994thrombosis} are pretty alarming, with $\tau_{\text{\tiny RR}} = 5$ for women taking oral contraceptives and carrier of the mutation.\\
Our results rather advoCATE the use of $\tau_{\text{\tiny SR}}$ for those typology of outcomes and effect. This measure was not computed at the time, and we propose to shed light on this paper with other measures than the $\tau_{\text{\tiny RR}}$ initially reported\footnote{The original paper is a case-control study \citep{Vandenbroucke1994thrombosis}. Usually absolute risks and other quantities cannot be computed in a case-control study due to the lack of knowledge of the population incidence fraction, even if modern methods have been proposed to circumvent the problem \citep{king2002estimating}. Looking back to the original publication, authors indeed computed a OR which was reported as an RR. The low prevalence of thrombosis within young women, ($2.1$ for $10,000$ per year) enabling the low prevalence assumption $\tau_{\text{\tiny OR}} \sim \tau_{\text{\tiny RR}}$. Luckily, authors also computed the population's incidence thrombosis with all the combinations (oral contraceptive and/or factor V mutation), which enables us to re-compute other measures. In this illustration we do not provide confidence intervals as we aim at illustrating how the measure's choice leads to amplitude differences.}.


\begin{table}[]
\begin{center}
\begin{tabular}{c|cc|cc|}
\cline{2-5}
                            & \multicolumn{2}{c|}{X = 1} & \multicolumn{2}{c|}{X = 0} \\ \cline{2-5} 
                            & Y = 1       & Y = 0        & Y = 1       & Y = 0        \\ \hline
\multicolumn{1}{|c|}{A = 1} & 25          & 8,732        & 84          & 275,774      \\ \cline{1-1}
\multicolumn{1}{|c|}{A = 0} & 10          & 17,505       & 36          & 437,834      \\ \hline
\end{tabular}
\end{center}
\end{table}



Follow-up works rather claimed that the actual absolute risk was rather low, and that the widespread use of the NRT rather leaded to what is called a \textit{pill scare}, i.e. women stopping oral contraception \citep{Mills1999PillScare}. 
This example of clinical discoveries can not be reduced to the way the treatment effect is reported. It also involves socio-culturel consequences \citep{Bourgain2021Appraising}, or cost-benefit analysis related to the generalization of tests \citep{Creinin1999Cost}.


We show that - still being non-parametric - one can propose heterogeneity. 


\end{comment}


\newpage
\begin{landscape}

\bgroup
\def\arraystretch{2}%  1 is the default, change whatever you need
 \begin{table}
  \footnotesize
 \begin{center}
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline

 \multicolumn{1}{|c|}{\textbf{Name}} &  \multicolumn{1}{|c|}{\textbf{Outcome type}} & \multicolumn{1}{c|}{\textbf{Definition}} & \multicolumn{1}{c|}{\textbf{Collapsibility}} &  \multicolumn{1}{c|}{\textbf{Logic respecting}} & \multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Invariant\\ to encoding\end{tabular}}} & \multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Covariate set\\ for generalization\end{tabular}}} \\ \hline \hline
 Risk Difference  (RD)       & Continuous           &     $\tau_{\text{\tiny RD}} := \mathbb{E}\left[Y^{(1)}\right] - \mathbb{E}\left[Y^{(0)}\right]$        &                                                       Directly collapsible  & Logic-respecting                      &  Not applicable      &  $X_{M \cap \textrm{Sh}}$                                                                                                    \\ \hline
Risk Ratio (RR)            & Continuous                 &       $\tau_{\text{\tiny RR}} := \mathbb{E}\left[Y^{(1)}\right] / \mathbb{E}\left[Y^{(0)}\right]$                                                                   & Collapsible         & Logic-respecting                      &   Not applicable                   &  $X_{(M \cup B) \cap \textrm{Sh}}$                                                                                                   \\ \hline
 Excess Risk Ratio (ERR)       & Continuous               &    $\tau_{\text{\tiny ERR}}  := \tau_{\text{\tiny RD}}/\mathbb{E}\left[Y^{(0)}\right] = \tau_{\text{\tiny RR}} - 1 $                                                                    & Collapsible     & Logic-respecting                         &        Not applicable                & $X_{(M \cup B) \cap \textrm{Sh}}$                                                                                                  \\ \hline \hline  \hline 
Risk Difference (RD)       & Binary                 &               $\tau_{\text{\tiny RD}} := \mathbb{P}\left[Y^{(1)} = 1\right] - \mathbb{P}\left[Y^{(0)} = 1\right]$                                            &  Directly collapsible    & Logic-respecting                       & Multiplied by $-1$ &        $X_{(M \cup B) \cap \textrm{Sh}}$                                                                                                                                     \\ \hline
 Number Needed to Treat (NNT)    & Binary         &  $\tau_{\text{\tiny RD}} := 1 / \left( \mathbb{P}\left[Y^{(1)} = 1\right] - \mathbb{P}\left[Y^{(0)} = 1\right] \right)$   & \textbf{Not} collapsible  & Logic-respecting                   &  Multiplied by $-1$    &     $X_{(M \cup B) \cap \textrm{Sh}}$                                                                                                                                         \\ \hline
Risk Ratio (RR)        & Binary              &  $\tau_{\text{\tiny RR}} := \mathbb{P}\left[Y^{(1)} = 1\right] / \mathbb{P}\left[Y^{(0)} = 1\right]$   &      Collapsible   & Logic-respecting                    &   $= \tau_{\text{\tiny SR}}$    &     If $m_b(x)=0$, $X_{M \cap \textrm{Sh}}$                                                                                             \\ \hline
Survival Ratio (SR)      & Binary              &   $\tau_{\text{\tiny SR}} := \mathbb{P}\left[Y^{(1)} = 0\right] / \mathbb{P}\left[Y^{(0)} = 0\right]$  &  Collapsible   & Logic-respecting                   &      $= \tau_{\text{\tiny RR}}$      &                If $m_g(x)=0$, $X_{M \cap \textrm{Sh}}$                                                                                                                                \\ \hline
Excess Risk Ratio (ERR)    & Binary                 &    $\tau_{\text{\tiny ERR}}  := \tau_{\text{\tiny RD}}/\mathbb{P}\left[Y^{(0)} = 1\right] = \tau_{\text{\tiny RR}} - 1 $                                                                    & Collapsible     & Logic-respecting                        &        $= \tau_{\text{\tiny SR}} - 1$                   & If $m_b(x)=0$, $X_{M \cap \textrm{Sh}}$                                                                                                    \\ \hline 
Relative Susceptibility (RS)      & Binary             &    $\tau_{\text{\tiny RS}}  := \tau_{\text{\tiny RD}}/\mathbb{P}\left[Y^{(0)} = 0\right] = 1 - \tau_{\text{\tiny SR}}$                                                                    & Collapsible     & Logic-respecting                        &        $= 1-\tau_{\text{\tiny RR}}$                   & If $m_g(x)=0$, $X_{M \cap \textrm{Sh}}$                                                                                                     \\ \hline 
Odds Ratio (OR)  & Binary   &$\tau_{\text{\tiny OR}}  := \frac{\mathbb{P}[Y^{(1)} = 1]}{\mathbb{P}[Y^{(1)} = 0]}\, \left(  \frac{\mathbb{P}[Y^{(0)} = 1]}{\mathbb{P}[Y^{(0)} = 0]}\right)^{-1}  = \tau_{\text{\tiny RR}} \cdot \tau_{\text{\tiny SR}}^{-1}$&  Non collapsible   & \textbf{Not} logic-respecting                  &  Reciprocal    &     $X_{(M \cup B) \cap \textrm{Sh}}$                                                                                                                                   \\ \hline
Log Odds Ratio (log-OR)     & Binary           & $\tau_{\text{\tiny log-OR}}  := \operatorname{log}\left( \frac{\mathbb{P}[Y^{(1)} = 1]}{\mathbb{P}[Y^{(1)} = 0]}\right) - \operatorname{log}\left( \frac{\mathbb{P}[Y^{(0)} = 1]}{\mathbb{P}[Y^{(0)} = 0]}\right)$ &  Non collapsible   & \textbf{Not} logic-respecting                   &  Multiplied by $-1$    &  $X_{(M \cup B) \cap \textrm{Sh}}$                                                                                                                                                                                                                                   \\ \hline
\end{tabular}
\caption{\textbf{Typical causal measures reported in clinical practice}: The upper part of the Table mentions the three typical measures found when the outcome is ordinal or continuous, and the lower part mentions measures for binary outcomes. For each measure we provide the explicit formulae, and propoerties such as collapsibility (see Definitions~\ref{def:direct-collapsibility} and \ref{def:indirect-collapsibility}), invariance to encoding (also called symetry in the literature), and whether the covariate set for generalization by standardization is extended or not. All these properties are defined in this article, and prooved for each of the measures.}
\label{tab:list-measures-with-all-properties}
\end{center}
\end{table}   


\egroup
\end{landscape}
\end{document}
