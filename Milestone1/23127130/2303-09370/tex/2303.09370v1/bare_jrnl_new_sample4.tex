\documentclass[lettersize,journal]{IEEEtran}
\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}
% \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{multirow}
\usepackage{color,xcolor}
\usepackage{array}
\usepackage{booktabs}
\usepackage{epsfig}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{subcaption}
% \usepackage{subfigure}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}

% Hide or show our comments
\newif\ifshowcomments
\showcommentstrue
%\showcommentsfatlse

% Coloring for our comments (use showcommentstrue or showcommentsfalse above to show/hide)
\ifshowcomments
\newcommand{\TMM}[1]{{\color{red}{[TMM: #1]}}}
\newcommand{\ACMMM}[1]{{\color[rgb]{0.2,0.7,0.2}{[ACMMM: #1]}}}
\else
\newcommand{\TMM}[1]{}
\newcommand{\ACMMM}[1]{}
\fi
% updated with editorial comments 8/9/2021

\begin{document}

\title{Learning Physical-Spatio-Temporal Features for Video Shadow Removal}

% \author{IEEE Publication Technology,~\IEEEmembership{Staff,~IEEE,}
        % <-this % stops a space
% \author{Z. Chen, L. Wang, and Y. Xiao are with the School of Computer Science and Technology, College of Intelligence and Computing, Tianjin University, Tianjin 300350, China. Email: zh_chen@tju.edu.cn, fnxyf@tju.edu.cn, lwan@tju.edu.cn.}
\author{Zhihao Chen, Liang Wan$^\dag$ \textit{Member, IEEE}\thanks{Z. Chen, L. Wang$^\dag$, and Y. Xiao are with the College of Intelligence and Computing, Tianjin University, Tianjin 300350, China. Email: zh\_chen@tju.edu.cn, lwan@tju.edu.cn, fnxyf@tju.edu.cn.}, Yefan Xiao, Lei Zhu \textit{Member, IEEE}\thanks{L. Zhu is with The Hong Kong University of Science and Technology (Guangzhou), Nansha, Guangzhou, 511400, Guangdong, China and The Hong Kong University of Science and Technology, Hong Kong SAR, China  (Email: leizhu@ust.hk) }, Huazhu Fu \textit{Senior Member, IEEE}\thanks{H. Fu is with the Institute of High Performance Computing (IHPC), Agency for Science, Technology and Research (A*STAR), Singapore 138632. (E-mail: hzfu@ieee.org)}\\
% }
% \thanks{This paper was produced by the IEEE Publication Technology Group. They are in Piscataway, NJ.}% <-this % stops a space
% \thanks{Manuscript received April 19, 2021; revised August 16, 2021.}
}

% The paper headers
% \markboth{IEEE Transactions on Circuits and Systems for Video Technology, IN SUBMISSION}%
\markboth{IN SUBMISSION}%
{Shell \MakeLowercase{\textit{et al.}}: A Sample Article Using IEEEtran.cls for IEEE Journals}

% \IEEEpubid{0000--0000/00\$00.00~\copyright~2021 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.

\maketitle

\begin{abstract}
Shadow removal in a single image has received increasing attention in recent years. However, removing shadows over dynamic scenes remains largely under-explored.  In this paper, we propose the first data-driven video shadow removal model, termed PSTNet, by exploiting three essential characteristics of video shadows, i.e., physical property, spatio relation, and temporal coherence. Specifically, a dedicated physical branch was established to conduct local illumination estimation, which is more applicable for scenes with complex lighting and textures, and then enhance the physical features via a mask-guided attention strategy. Then, we develop a progressive aggregation module to enhance the spatio and temporal characteristics of features maps, and effectively integrate the three kinds of features. Furthermore, to tackle the lack of datasets of paired shadow videos, we synthesize a dataset (SVSRD-85) with aid of the popular game GTAV by controlling the switch of the shadow renderer. Experiments against 9 state-of-the-art models, including image shadow removers and image/video restoration methods, show that our method improves the best SOTA in terms of RMSE error for the shadow area by $14.7\%$. In addition, we develop a lightweight model adaptation strategy to make our synthetic-driven model effective in real world scenes. The visual comparison on the public SBU-TimeLapse dataset verifies the generalization ability of our model in real scenes.
% Shadow removal in a single image has recently received great research interest. However, the shadow removal over dynamic scenes is still under-exploring.
%%
%Different with the existing methods mainly based on the spatial and temporal characteristics featuring by CNN feature and optical flow, we introduce a novel physical characteristic to present the relation between the complex lighting and object shadow. 
%%
% In this paper, we develop the first data-driven video shadow removal model, termed PSTNet, by fusing three important representations of video shadows (i.e., physical, saptio and temporal). Specifically, PSTNet construct three independent branches to learn physical, saptio and temporal features and then fuse them to refine the the final video shadow removal results in a progressive manner. 
% %
% The physical branch uses a linear illumination transformation to model the shadow effects, which consider the illumination similarity of the shadow regions. In addition, to avoid the problem that global uniform lighting estimation is not applicable in scenes dealing with complex lighting and textures, we propose the Adaptive Exposure Estimation Module (AEEM) to construct the linear illumination transformation for different shadow regions. Next, the spatio and temporal branches are introduced to maintain the spatial resolution and temporal coherence of the removal results, respectively.
% Our method exploits three kinds of characteristics related to shadows in dynamic scenes, i.e. the physical characteristic, spatial characteristic, and temporal characteristic. 
%%
% We resort to the physical characteristic branch to mine the differences between shadow and non-shadow regions in the illumination model.
%mine the relation between complex lighting/texture conditions and image shadows. 
%
% In addition, to maintain the spatial resolution and temporal coherence of the prediction results, we introduce the spatio and temporal characteristic branches, respectively. 
%and develop an adaptive exposure estimation module and a mask-guided supervised attention module to extract reliable physical features. 
% And then, a dedicated feature fusion module aggregates multi-characteristic features to refine the shadow removal results in a progressive manner. 
% %%
% Furthermore, facing the lack of well-established datasets of paired shadow videos, we synthesize a dataset (SVSRD-85) in the popular game GTAV by controlling the switch of the shadow renderer.
% %%%
% Experiments in SVSRD-85 against 9 state-of-the-art models, including single image shadow removers and image/video restoration methods, 
% %%
% show that our method improves the state-of-the-art in terms of RMSE error for the shadow area by $14.7\%$.
% %%
% In addition, we propose a model transformation strategy to make our synthetic-driven model effective in real world scenes. The visual comparison in SBU-TimeLapse dataset can evaluate the generalization ability of our model in real scenes.

%Last, we also evaluate PSTNet on the SBU-Timelapse dataset that provides unpaired real shadow scenes, to prove the generalizability of our method.
\end{abstract}

\begin{IEEEkeywords}
Video shadow removal, physical-spatio-temporal features, synthetic scenes.
\end{IEEEkeywords}

\input{section1-introduction}
\input{section2-relatedworks}
\input{section3-dataset}
\input{section4-method}
\input{section5-experiments}
\input{section6-limitations}
\input{section7-conclusion}

\bibliographystyle{IEEEtran}
\bibliography{sample-base}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Figures/photos/czh.jpg}}]{Zhihao Chen}
received the B.S. degree in software engineering from the Tianjin University, Tianjin, China, in 2017. He is currently pursuing the Ph.D. degree in College of Intelligence and Computing from the Tianjin University, China. His research interests include computer vision and deep learning, specifically for shadow detection shadow removal, and medical image segmentation.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Figures/photos/wl.jpg}}]{Liang Wan}
% is a full Professor in the College of Intelligence Computing, and deputy director of Medical College, Tianjin University, P. R. China. She obtained a Ph.D. degree in computer science and engineering from The Chinese University of Hong Kong in 2007ï¼Œand worked as a PostDoc Research Associate/Fellow at City University of Hong Kong from 2007 to 2011. Her current research interests focus on image processing and computer vision, including image segmentation, low-level image restoration, and medical image analysis.
is a full Professor in the College of Intelligence Computing, and deputy director of Medical College, Tianjin University, P. R. China. She obtained a Ph.D. degree in computer science and engineering from The Chinese University of Hong Kong in 2007, and worked as a PostDoc Research Associate/Fellow at City University of Hong Kong from 2007 to 2011. Her current research interests focus on image processing and computer vision, including image segmentation, low-level image restoration, and medical image analysis.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Figures/photos/xyf.png}}]{Yefan Xiao}
received the bachelor degree in software engineering from the Tianjin University, Tianjin, China, in 2020. He is currently pursuing the master degree in Tianjin University. His research interests include computer vision and deep learning, specifically for image polyp segmentation and video semantic segmentation.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Figures/photos/zl.png}}]{Lei Zhu}
received the Ph.D. degree from the Department
of Computer Science and Engineering, The
Chinese University of Hong Kong. He is currently
working as an Assistant Professor with the ROAS
Thrust, HKUST (GZ), and also an affiliated Assistant
Professor in ECE with HKUST. Before that,
he was a Postdoctoral Researcher at DAMTP, University
of Cambridge. His research interests include
computer graphics, computer vision, medical image
processing, and deep learning.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Figures/photos/fhz.png}}]{Huazhu Fu}
(SM'18) is a senior scientist at Institute of High Performance Computing (IHPC), A*STAR, Singapore. He received his Ph.D. from Tianjin University in 2013. Previously, he was a Research Fellow (2013-2015) at NTU, Singapore, a Research Scientist (2015-2018) at I2R, A*STAR, Singapore, and a Senior Scientist (2018-2021) at Inception Institute of Artificial Intelligence, UAE. His research interests include computer vision, AI in healthcare, and trustworthy AI. He received the Best Paper Award from ICME 2021. He has served as the AE of IEEE TMI, IEEE TNNLS, and IEEE JBHI, AC/Senior-PC for MICCAI, IJCAI, and AAAI. He is also a Member of the IEEE BISP TC.
\end{IEEEbiography}

\newpage
\vfill

\end{document}


