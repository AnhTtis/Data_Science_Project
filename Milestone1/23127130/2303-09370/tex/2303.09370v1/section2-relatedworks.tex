\section{Related Works}
\label{sec:relatedworks}
%\noindent
\subsection{Image Shadow Removal}
Early research on image shadow removal employ prior information, e.g., gradient~\cite{gryka2015learning}, illumination~\cite{shor2008shadow,xiao2013fast,zhang2015shadow}, and region~\cite{guo2012paired,vicente2017leave}, for removing shadows. 
%%
However, conventional prior
based methods can just handle high-quality images with certain constraints of real scenes (e.g. ample lighting conditions and simple textures).
%%
In recent years, deep learning based methods boost the removal performance~\cite{qu2017deshadownet,ding2019argan,hu2019direction,cun2020towards}, since CNN networks have built-in inductive biases that make them well-suited to a wide variety of computer vision applications~\cite{liu2022convnet}. 
%%
In more detail, DeshadowNet~\cite{qu2017deshadownet} proposes a multi-context architecture, where the  shadow matte is predicted by embedding information from three different perspectives, i.e. global localization, appearance modeling and semantic modeling.
%%
ST-CGAN~\cite{wang2018stacked} leverages two stacked conditional GANs to jointly train shadow detection and removal tasks.
%%
DSC\cite{hu2019direction} designs direction-aware context to improve shadow detection and removal.
%%
DHAN~\cite{cun2020towards} analyses two types of shadow ghosts and proposes a dual hierarchical aggregation network and shadow augmentation method to boost shadow removal.
%%
%ARGAN~\cite{ding2019argan} treats shadow removal as a progressive optimization process and designs an attentive recurrent generative adversarial network to recover shadow free image step-by-step.
Zhu et al.~\cite{zhu2022bijective} argued that shadow removal and generation are interrelated. They proposed BMNet, which couples the learning procedures of shadow removal and shadow generation in a unified parameter-shared framework.

In the literature, some methods consider physical models of shadow formation and embed such information in the end-to-end deep learning manner. 
%%
SID~\cite{le2021physics} uses a linear illumination transformation to model the shadow effects in the image, which expresses the shadow image as a combination of the shadow-free image, the shadow parameters, and a matte layer. It then uses two deep networks to predict the shadow parameters and the shadow matte respectively.
%%
Fu et al.~\cite{fu2021auto} extended SID via employing multi-exposure image fusion strategy and proposes a boundary-aware RefineNet to eliminate the remaining ghost shadow further. 

In addition, to alleviate the requirements of capturing paired data, some GAN based methods~\cite{hu2019mask,liu2021LG,liu2021G2R} perform image shadow removal on unpaired shadow and shadow-free images.
%%
MaskShadowGAN~\cite{hu2019mask} learns to produce a shadow mask from the input shadow image and then takes the mask to guide the shadow generation via re-formulated cycle-consistency constraints. LG-ShadowNet~\cite{liu2021LG} improves MaskShadowGAN by introducing a brightness guidance strategy. G2R-ShadowNet~\cite{liu2021G2R} generates unpaired data given a set of shadow images and their corresponding shadow masks. Gao et al.~\cite{gao2022towards} proposed a shadow simulation method to simulate shadow on the grayscale, which can be applied to arbitrary shadow-free images and masks to generate corresponding shadow images.
%
However, due to the lack of accurate pixel-level shadow-free supervision, those unpaired-based methods still suffer from artifacts and image blur, and hence there exists a certain gap in performance compared to the fully supervised approaches on benchmarks.

%\noindent
\subsection{Video Shadow Removal}
Video shadow removal aims to remove shadows from each frame of a video. Existing methods almost all rely on hand-crafted features and there is no deep-learning based method for video shadow removal. 
%%
Existing methods usually assume that the background is relatively stationary, allowing the moving objects and shadows to be separated. 
%%
Nadimi \& Bhanu~\cite{nadimi2004physical} separated moving cast shadows from the moving objects in an outdoor environment. This approach is based on a spatio-temporal albedo test and dichromatic reflection model which accounts for both the sun and the sky illuminations. 
%%
Jung et al.~\cite{jung2009efficient} presented a statistical method for background subtraction and shadow removal for grayscale video sequences. 
%The background image is modeled using statistical descriptors, and a noise estimate is obtained. Foreground pixels are extracted, and a statistical approach combined with geometrical constraints are adopted to detect and remove shadows. 
%%
Wang et al.~\cite{wang2009real} presented an approach of moving vehicle detection and cast shadow removal for video based traffic monitoring. Based on conditional random field, spatial and temporal dependencies in traffic scenes are formulated under a probabilistic discriminative framework.
%, where contextual constraints during the detection process can be adaptively adjusted in terms of data-dependent neighborhood interaction. 

The above methods are suitable for surveillance videos with static backgrounds, but not applicable to remove shadows in scenes with rich motion conditions. In this paper, we develop the first deep-learning based method for video shadow removal. Furthermore, we  bypass the strict requirements of collecting paired videos from real scenes, and built one virtual dataset of paired shadow and shadow-free videos in synthetic scenes.

%The success of deep learning methods in image shadow removal task is inseparable from the successive proposals of several large-scale datasets~\cite{qu2017deshadownet,wang2018stacked,hu2019mask}. However, as for video shadow removal, no available dataset with paired shadow and shadow-free videos can be used to train a data-driven video shadow removal model. Paired videos in real-world scenes are difficult to collect, as it is impossible to reproduce the dynamics exactly as the first shot at the second shot. 
%In this paper, we bypass the collect paired videos from real scenes. Instead, we synthesize video pairs in synthetic scene via twice rendering with controlling the switch of shadow. In this way, we made it possible to perform video shadow removal by robust data-driven models.

% \noindent
% \textbf{Computer vision using synthetic scene}

