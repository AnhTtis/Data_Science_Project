\section{Introduction}
\label{sec::introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Background
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Shadows, created wherever an object obscures the light source, are one ubiquitous natural phenomenon in our daily life. 
%%
They can provide useful hints for extracting scene geometry~\cite{okabe2009attached,karsch2011rendering}, light direction~\cite{lalonde2009estimating}, and camera location and its parameters~\cite{junejo2008estimating}. 
%%
However, shadows can also hinder the performance of those downstream high-level computer vision tasks, such as object/change detection~\cite{surkutlawar2013shadow,muller2019brightness,su2016shadow}, face recognition~\cite{zhang2018improving}, due to spurious edges on the boundaries of shadows and confusion between albedo and shading.
%%
%Therefore, realistic shadow manipulation is an integral part of media editing~\cite{wang2020people,chuang2003shadow} and can greatly improve performance on various computer vision tasks.
The last two decades have witnessed a rapid development in image shadow removal.
%~\cite{zhu2018bidirectional,chen2020multi,chen2021triple} 
%in particular the image shadow removal. 
%%
Early works usually examine illumination and gradients priors~\cite{gryka2015learning,finlayson2005removal,shor2008shadow,yang2012shadow}. 
%%
With the aids of the datasets of the real world shadow and shadow-free images, researchers developed many data-driven CNN-based approaches, which are learnt in an end-to-end manner~\cite{qu2017deshadownet,wang2018stacked,hu2019direction,cun2020towards}. In recent years, several research works combine the physical priors and CNN models to transform the shadow removal task to an image decomposition issue~\cite{le2021physics,fu2021auto,le2020shadow}.

In striking contrast with the flourishing development of image shadow removal, few works have been explored in shadow removal over dynamic scenes. 
%%
As one type of video restoration tasks, 
video shadow removal can benefit various downstream high-level tasks, such as dynamic scene understanding~\cite{jung2009efficient,wang2009real} and object tracking~\cite{nadimi2004physical}. 
%%
On the other hand, we also notice that many other video restoration tasks have received significant research interests in recent years, including video super-resolution\cite{chan2021basicvsr,isobe2020video1,isobe2020video2}, video deblur~\cite{kim2017dynamic,zhang2018adversarial}, video denoise~\cite{maggioni2021efficient,yue2020supervised}, video derain~\cite{yue2021semi,kim2015video}, etc.
%%
Hence, it is of great importance to address the problem of video shadow removal. 
%%
The brute-force solution is directly using existing image shadow removers in videos, however, it may ignore the potential effect that temporal information can bring, and is prone to generate unstable predictions between adjacent video frames~\cite{le2021physics}.

In this work, we propose a novel video shadow removal method, termed \textbf{PSTNet}, by exploiting three main characteristics related to shadows, i.e. physical, spatio, and temporal characteristics, simultaneously.
%%
\textcircled{1} Physical characteristic depicts the shadows by a simplified linear illumination model. Some ralated works~\cite{le2021physics, le2020shadow} pointed out that employing the physical characteristic of shadows can make shadow removal mapping easier to constrain.
%since it is strictly defined by a simplified linear illumination model. 
%%
\textcircled{2} Spatio characteristic depicts the position-sensitive semantic information of shadows, which reflects fine textures in the image.
%The ability of the model to distinguish shadow and non-shadow regions is a primary condition for completing the shadow removal task. 
%%
\textcircled{3} Temporal characteristic depicts the motion condition of shadows. Other video restoration tasks~\cite{wang2019edvr,chan2021basicvsr} have shown that the temporal-continuity knowledge is able to facilitate the prediction for the current frame given continuous frames.
%%
To be specific, we use three parallel branches to extract the embedded features from physical, spatio, and temporal characteristics, respectively. 
%%
Physical branch model the shadow removal problem as the over-exposure problem which represented by the linear regression function, following SID~\cite{le2021physics}. To overcome the inability of SID to solve complex lighting and texturing problems, we equip the physical branch with an adaptive exposure estimation module, which considers exposure bias in different shadow regions. 
%
Meanwhile, a mask-guided supervised attention module is leveraged to guide our model pay more attention to the features in shadow regions rather than non-shadow regions. 
In addition, to maintain the spatial resolution and temporal coherence of the prediction results, we introduce the spatio and temporal characteristic branches, respectively. 
%%
Finally, we design a dedicated feature fusion module to aggregate those features to refine the final shadow removal results in a progressive manner.
%%

It is worth pointing out there is no dataset with paired shadow and shadow-free videos, since it is almost impossible to reproduce dynamics exactly between two shots in real-world scenes. 
%%
Hence, in this work, we synthesize one video shadow removal dataset, termed \textbf{SVSRD-85}, for training and evaluating our model.
%%
SVSRD-85 collects paired shadow and shadow-free videos in the popular game GTAV~\cite{GTAV2015} by controlling the switch of shadow renderer.
%%
It contains 85 videos with 4250 frames, covering different object categories and  vairous motion/illumination conditions, while 
all the frames have their corresponding high-quality shadow-free ground-truth. 
%%
We hope that the release of this dataset will facilitate research on video shadow removal. To demonstrate the effectiveness of our method, we present a comprehensive evaluation against 9 state-of-the-art related models on our SVSRD-85 dataset. Results show that our model significantly outperforms existing methods, including single image shadow removers~\cite{guo2012paired,gong2014interactive, hu2019direction,le2021physics, cun2020towards,fu2021auto}, image restoration methods~\cite{zamir2021multi}, and video restoration methods~\cite{wang2019edvr,chan2021basicvsr}.

Finally, to make the model trained in synthetic data effective in a real-world scenes, we propose a lightweight model transformation strategy, termed S2R, to adapt the synthetic-driven models to the real world scenes without retraining. Visualization Comparison proves the effectiveness of our method.

% \ACMMM{Finally, we present a comprehensive evaluation against 9 state-of-the-art related models on our SVSRD-85 dataset. 
% %%
% Results show that our model significantly outperforms existing methods, including single image shadow removers~\cite{guo2012paired,gong2014interactive, hu2019direction,le2021physics, cun2020towards,fu2021auto}, image restoration methods~\cite{zamir2021multi}, and video restoration methods~\cite{wang2019edvr,chan2021basicvsr}. 
% %%
% In addition, to evaluate the generalisation ability of our method, we also conduct experiments on the public SBU-Timelapse dataset~\cite{le2021physics}, which provides unpaired real shadow scenes. 
% %In summary, our our work provide a new view for video shadow removal. 
% % \textcolor{red}{Our dataset and codes have been released at:} \url{https://github.com/eraserNut/PSTNet}.
% We will release the SVSRD-85 dataset and our codes later.}
