\begin{table}[!htb]
    \begin{center}
        \centering
        \resizebox{0.8\linewidth}{!}{
            \begin{tabular}{l|c}
                \bf Setting & \bf Value  \\
                \midrule
                Batch size & 1024 \\
                Optimizer & AdamW~\cite{loshchilov2017decoupled} \\
                Learning rate: \\
                \quad Schedule & Constant \\
                \quad Peak & 2e-3 \\
                \quad Layerwise decay~\cite{clark2020electra, bao2021beit} & 0.75 \\
                \quad Warmup Schedule & Linear \\
                \quad Warmup Fraction & 5\% \\
                Weight decay & 0.05 \\
                Optimizer Momentum & $\beta_1=0.9,\beta_2=0.999$ \\
                DropPath~\cite{huang2016deep} & 0.2 \\
                EMA~\cite{polyak1992acceleration} & 1e-4 \\
                Augmentations: \\
                \quad {\tt RandomResizedCrop} \\
                \qquad {\tt size} & 518px \\
                \qquad {\tt scale} & [0.08, 1.00] \\
                \qquad {\tt ratio} & [0.75, 1.33] \\
                \qquad {\tt interpolation} & Bicubic \\
                \quad {\tt RandomHorizontalFlip} & $p=0.5$ \\
                \quad {\tt Normalize} \\
                \quad {\tt mixup~\cite{zhang2017mixup}} & 0.8 \\
                \quad {\tt CutMix~\cite{yun2019cutmix}} & 1.0 \\
                \quad {\tt LabelSmoothing~\cite{szegedy2016rethinking}} & 0.1 \\
            \end{tabular}
        }
    \end{center}
    \vspace{-0.15in}
    \caption{
        \textbf{\mae Image finetuning hyperparameters.} We train for 50 epochs on \inetOneKShort and 100 epochs on
        \inatShort.
    }
    \label{tab:mae_image_ft_settings}
\end{table}
