

\begin{figure}[!htb]
  \centering
  \include{plots/mae_scaling_lin_in1k}
    \ifarxiv
        \vspace{-0.23in}
    \else
        \vspace{-0.38in}
    \fi
    \caption{\textbf{Scaling MAE with model and dataset size}. \mae's linear performance on \inetOneKShort when pretrained on 
    \inetOneKShort or \igShort, while scaling model size. \mae \inetOneKShort starts off much better, since the pretraining
    is performed on the same dataset used for linear probing. But the scaling behavior for \mae-\igSizeShort is exciting, showing
    linear performance improvements as we scale model sizes, with the potential to outperform \inetOneKShort pretraining if 
    scaled out further.
    }
  \label{fig:mae_scaling_in1k_lin}
\end{figure}
