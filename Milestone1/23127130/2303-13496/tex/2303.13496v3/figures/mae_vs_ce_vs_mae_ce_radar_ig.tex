

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{plots/mae_vs_ce_vs_mae_ce_radar_ig.pdf}
    \ifarxiv
        \vspace{-0.2in}
    \else
        \vspace{-0.2in}
    \fi
  \caption{\textbf{\mae \prept improves performance}.
  Transfer performance of a \vitL architecture trained with self-supervised  pretraining (\mae), weakly supervised pretraining on billions of images (\ce), and our \prept (\ours) that initializes the model with \mae and then pretrains with \ce.
  \Prept consistently improves performance.
  }
  \label{fig:mae_vs_ce_vs_mae_ce_ig}
\end{figure}
