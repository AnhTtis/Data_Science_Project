\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{3pt}
    \resizebox{\linewidth}{!}{
    \begin{tabu}{llcH|ccc|ccc}
        \centering
        \multirow{2}{*}{\bf Method} & \multirow{2}{*}{\bf Dataset} & \multirow{2}{*}{\bf Arch.} & \bf Protocol & \multicolumn{3}{c|}{\bf \inetOneKShort} & \multicolumn{3}{c}{\bf \inatShort} \\ 
        & & & & \bf 1-shot & \bf 5-shot & \bf 10-shot & \bf 1-shot & \bf 5-shot & \bf 10-shot \\
        \midrule
        \multicolumn{6}{l}{\em Results with different pretraining datasets} \\
        \clip \cite{radford2021learning} & \wit & \vitL & Linear & 41.3 & 66.2 & 71.3 & 21.9 & 49.0 & 58.5 \\
        \openclip \cite{ilharco_gabriel_2021_5143773} & \laionTwoB & \vitH & Adapter & 44.3 & 70.0 & 74.9 & 26.0 & 54.6 & 63.7 \\
        \openclip \cite{ilharco_gabriel_2021_5143773} & \laionTwoB & \vitG & Adapter & 46.3 & 72.9 & 77.2 & 26.3 & 55.7 & 65.1 \\
        \scaleViT\textsuperscript{\textdagger}\cite{zhai2022scaling} & \jftThreeB & \vitG & Linear & -- & \textbf{83.0} & \textbf{84.9} & -- & -- & -- \\
        \midrule
        \dino \cite{caron2021emerging} & \inetOneKShort & ViT-B/8 & Linear & 45.8 & 64.6 & 69.0 & 19.8 & 45.9 & 55.9 \\
        \msn \cite{assran2022masked} & \inetOneKShort & ViT-L/7 & Linear & 57.1 & 72.1 & 74.4 & 17.0 & 38.0 & 48.1 \\
        \mae\cite{he2021masked} & \inetOneKShort & \vitH & Finetune & -- & 57.9 & 70.8 & -- & 48.5 & 68.2 \\
        \swag\cite{singh2022revisiting} & IG-3.6B & \vitH & Adapter & 59.4 & 78.7 & 81.0 & 30.1 & 62.8 & 72.3 \\
        \ours & \igSizeShort & \vitH & Adapter & 57.1 & 79.8 & 82.5 & 31.7 & 67.8 & 76.1 \\
        \ours & \igSizeShort & \vitTwoB & Adapter & \textbf{62.1} & 81.5 & 83.7 & \textbf{35.5} & \textbf{72.8} & \textbf{80.3} \\
    \end{tabu}%
    }
    \caption{
        \textbf{Low shot image classification.} We compare the performance of our models using just a few examples per class for 
        \inetOneK and \inat. \ours excels at classification even with just 1 example per class. Pretraining on large scale data 
        can outperform techniques designed to work well in the low data regime, like \msn.
        We evaluate and report results for each technique with the best protocol, except for when the checkpoints are not 
        available\textsuperscript{\textdagger}.
    }
    \label{tab:low_shot_image_classification}
\end{table}
