@Article{NestSpok17,
  Title                    = {Random Gradient-Free Minimization of Convex Functions},
  Author                   = {Nesterov, Yurii and Spokoiny, Vladimir},
  Journal                  = {Foundations of Computational Mathematics},
  Year                     = {2017},
  Number                   = {2},
  Pages                    = {527--566},
  Volume                   = {17},

  Abstract                 = {In this paper, we prove new complexity bounds for methods of convex optimization based only on computation of the function value. The search directions of our schemes are normally distributed random Gaussian vectors. It appears that such methods usually need at most n times more iterations than the standard gradient methods, where n is the dimension of the space of variables. This conclusion is true for both nonsmooth and smooth problems. For the latter class, we present also an accelerated scheme with the expected rate of convergence {\$}{\$}O{\backslash}Big ({\{}n^2 {\backslash}over k^2{\}}{\backslash}Big ){\$}{\$} O ( n 2 k 2 ) , where k is the iteration counter. For stochastic optimization, we propose a zero-order scheme and justify its expected rate of convergence {\$}{\$}O{\backslash}Big ({\{}n {\backslash}over k^{\{}1/2{\}}{\}}{\backslash}Big ){\$}{\$} O ( n k 1 / 2 ) . We give also some bounds for the rate of convergence of the random gradient-free methods to stationary points of nonconvex functions, for both smooth and nonsmooth cases. Our theoretical results are supported by preliminary computational experiments.},
  Optdoi                   = {10.1007/s10208-015-9296-2},
  Optissn                  = {1615-3383},
  Opturl                   = {http://dx.doi.org/10.1007/s10208-015-9296-2}
}

@article{doi:10.1137/120894464,
author = {Nedi\'{c}, Angelia and Lee, Soomin},
title = {On Stochastic Subgradient Mirror-Descent Algorithm with Weighted Averaging},
journal = {SIAM Journal on Optimization},
volume = {24},
number = {1},
pages = {84-107},
year = {2014}

}

@book{clarke1983oan,
  added-at = {2010-02-09T09:41:26.000+0100},
  author = {Clarke, F.H.},
  biburl = {https://www.bibsonomy.org/bibtex/2438a06b2cfa8000f094c332735985ebb/qmerigot},
  interhash = {67a252327c8ec3b339e961e2152bb0b2},
  intrahash = {438a06b2cfa8000f094c332735985ebb},
  keywords = {imported},
  publisher = {Wiley New York},
  timestamp = {2010-02-09T09:41:29.000+0100},
  title = {{Optimization and Nonsmooth Analysis}},
  year = 1983
}

@ARTICLE{prasanth9736646,
  author={Bhavsar, Nirav and L. A. Prashanth},
  journal={IEEE Transactions on Automatic Control}, 
  title={Non-asymptotic bounds for stochastic optimization with biased noisy gradient oracles}, 
  year={2022},
  volume={},
  number={},
  pages={},
  doi={10.1109/TAC.2022.3159748}}

@article{DBLP:journals/corr/abs-2008-00051,
  author    = {Ahmad Ajalloeian and
               Sebastian U. Stich},
  title     = {Analysis of {SGD} with Biased Gradient Estimators},
  journal   = {CoRR},
  volume    = {abs/2008.00051},
  year      = {2020},
  url       = {https://arxiv.org/abs/2008.00051},
  eprinttype = {arXiv},
  eprint    = {2008.00051},
  timestamp = {Fri, 07 Aug 2020 15:07:21 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2008-00051.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@INPROCEEDINGS{8264532,  author={Z. {Zhou} and P. {Mertikopoulos} and A. L. {Moustakas} and N. {Bambos} and P. {Glynn}},  booktitle={IEEE 56th Annual Conference on Decision and Control (CDC)},   title={Mirror descent learning in continuous games},   year={2017},  volume={},  number={},  pages={5776-5783}, 
address = {Melbourne, Australia},
doi={10.1109/CDC.2017.8264532}}

@book{10.5555/548484,
author = {Duflo, Marie and Wilson, Stephen S.},
title = {Random Iterative Models},
year = {1997},
isbn = {3540571000},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
edition = {1st},
}

@article{10.1093/comjnl/3.3.175,
    author = {Rosenbrock, H. H.},
    title = "{An automatic method for finding the greatest or least Value of a function}",
    journal = {The Computer Journal},
    volume = {3},
    number = {3},
    pages = {175-184},
    year = {1960},
    month = {01},
    abstract = "{The greatest or least value of a function of several variables is to be found when the variables are restricted to a given region. A method is developed for dealing with this problem and is compared with possible alternatives. The method can be used on a digital computer, and is incorporated in a program for Mercury.}",
    issn = {0010-4620},
    doi = {10.1093/comjnl/3.3.175},
    eprint = {https://academic.oup.com/comjnl/article-pdf/3/3/175/988633/030175.pdf},
}


@article{10.1214/aoms/1177699070,
author = {Vaclav Fabian},
title = {{Stochastic approximation of minima with improved asymptotic speed}},
volume = {38},
journal = {The Annals of Mathematical Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {191 -- 200},
year = {1967},
doi = {10.1214/aoms/1177699070},
}


@book{brent2002algorithms,
  added-at = {2012-04-02T13:58:41.000+0200},
  author = {Brent, R.P.},
  biburl = {https://www.bibsonomy.org/bibtex/24b09b7d18ebf1b6427ac646fe7d56946/thorade},
  interhash = {4c0d2a19c5c5b2136c03a82e05bae0b9},
  intrahash = {4b09b7d18ebf1b6427ac646fe7d56946},
  isbn = {0-13-022335-2},
  keywords = {1973 algorithm mathematics},
  publisher = {Prentice-Hall},
  timestamp = {2012-04-02T13:59:54.000+0200},
  title = {Algorithms for minimization without derivatives},
  year = 1973
}

@article{10.1561/2400000013,
author = {Hazan, Elad},
title = {Introduction to Online Convex Optimization},
year = {2016},
issue_date = {8 2016},
publisher = {Now Publisher Inc.},
address = {Hanover, MA, USA},
volume = {2},
number = {3–4},
issn = {2167-3888},
abstract = {This monograph portrays optimization as a process. In many practical applications the environment is so complex that it is infeasible to lay out a comprehensive theoretical model and use classical algorithmic theory and mathematical optimization. It is necessary as well as beneficial to take a robust approach, by applying an optimization method that learns as one goes along, learning from experience as more aspects of the problem are observed. This view of optimization as a process has become prominent in varied fields and has led to some spectacular success in modeling and systems that are now part of our daily lives.},
journal = {Foundation and Trends in  Optimization},
month = aug,
pages = {157–325},
numpages = {169}
}

@inbook{doi:https://doi.org/10.1002/0471722138.ch5,

publisher = {John Wiley and Sons, Ltd},
isbn = {9780471722137},
title = {Stochastic Gradient Form of Stochastic Approximation},
booktitle = {Introduction to Stochastic Search and Optimization},
chapter = {},
pages = {126-149}
}


@Book{ConnScheVice09,
  Title                    = {Introduction to Derivative-Free Optimization},
  Author                   = {Andrew R. Conn and Katya Scheinberg and Luis N. Vicente},
  Publisher                = {SIAM},
  Year                     = {2009},

  Address                  = {Philadelphia, PA, USA}
}

@article{Nedic2009,
	author = {Nedic, Angelia and Ozdaglar, Asuman},
	journal = {IEEE Transactions on Automatic Control},
	month = {Jan},
	number = {1},
	pages = {48--61},
	title = {Distributed Subgradient Methods for Multi-Agent Optimization},
	volume = {54},
	year = {2009}
}

@article{article,
author = {Nedic, Angelia and Liu, Ji},
year = {2018},
month = {May},
pages = {77-103},
title = {Distributed Optimization for Control},
volume = {1},
journal = {Annual Review of Control, Robotics, and Autonomous Systems},
doi = {10.1146/annurev-control-060117-105131}
}

@ARTICLE{8409957,  author={T. T. {Doan} and S. {Bose} and D. H. {Nguyen} and C. L. {Beck}},  journal={IEEE Control Systems Letters},   title={Convergence of the Iterates in Mirror Descent Methods},   year={2019},  volume={3},  number={1},  pages={114-119},  doi={10.1109/LCSYS.2018.2854889}}

@article{10.1561/2200000050,
author = {Bubeck, S\'{e}bastien},
title = {Convex Optimization: Algorithms and Complexity},
year = {2015},
issue_date = {11 2015},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {8},
number = {3–4},
issn = {1935-8237},
journal = {Foundation and Trends in Machine  Learning},
month = nov,
pages = {231–357},
numpages = {127}
}

@article{anik,
author = {Beck, Amir and Teboulle, Marc},
title = {Mirror Descent and Nonlinear Projected Subgradient Methods for Convex Optimization},
year = {2003},
issue_date = {May, 2003},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {31},
number = {3},
issn = {0167-6377},
journal = {Operation Research Letter},
month = may,
pages = {167–175},
numpages = {9},
keywords = {Relative entropy, Nonlinear projections, Projected subgradient methods, Complexity analysis, Global rate of convergence, Nonsmooth convex minimization, Mirror descent algorithms}
}


@ARTICLE{7004065,  author={G. {Raskutti} and S. {Mukherjee}},  journal={IEEE Transactions on Information Theory},   title={The Information Geometry of Mirror Descent},   year={2015},  volume={61},  number={3},  pages={1451-1457},  doi={10.1109/TIT.2015.2388583}}


@ARTICLE{9186148,  author={Liu, Sijia and Chen, Pin-Yu and Kailkhura, Bhavya and Zhang, Gaoyuan and Hero III, Alfred O. and Varshney, Pramod K.},  journal={IEEE Signal Processing Magazine},   title={A Primer on Zeroth-Order Optimization in Signal Processing and Machine Learning: Principals, Recent Advances, and Applications},   year={2020},  volume={37},  number={5},  pages={43-54},  doi={10.1109/MSP.2020.3003837}}

@ARTICLE{7055287,
  author={Duchi, John C. and Jordan, Michael I. and Wainwright, Martin J. and Wibisono, Andre},
  journal={IEEE Transactions on Information Theory}, 
  title={Optimal Rates for Zero-Order Convex Optimization: The Power of Two Function Evaluations}, 
  year={2015},
  volume={61},
  number={5},
  pages={2788-2806},
  doi={10.1109/TIT.2015.2409256}}
  
 @article{doi:10.1137/120880811,
author = {Ghadimi, Saeed and Lan, Guanghui},
title = {Stochastic First- and Zeroth-Order Methods for Nonconvex Stochastic Programming},
journal = {SIAM Journal on Optimization},
volume = {23},
number = {4},
pages = {2341-2368},
year = {2013},
doi = {10.1137/120880811},
eprint = { 
    
        https://doi.org/10.1137/120880811
    
    

}
,
    abstract = { In this paper, we introduce a new stochastic approximation type algorithm, namely, the randomized stochastic gradient (RSG) method, for solving an important class of nonlinear (possibly nonconvex) stochastic programming problems. We establish the complexity of this method for computing an approximate stationary point of a nonlinear programming problem. We also show that this method possesses a nearly optimal rate of convergence if the problem is convex. We discuss a variant of the algorithm which consists of applying a postoptimization phase to evaluate a short list of solutions generated by several independent runs of the RSG method, and we show that such modification allows us to improve significantly the large-deviation properties of the algorithm. These methods are then specialized for solving a class of simulation-based optimization problems in which only stochastic zeroth-order information is available. }
}


@ARTICLE{6870494,
  author={Yuan, Deming and Ho, Daniel W. C.},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Randomized Gradient-Free Method for Multiagent Optimization Over Time-Varying Networks}, 
  year={2015},
  volume={26},
  number={6},
  pages={1342-1347},
  doi={10.1109/TNNLS.2014.2336806}}
  
  @INPROCEEDINGS{8619028,  author={Pang, Yipeng and Hu, Guoqiang},  booktitle={ IEEE Conference on Decision and Control (CDC)},   title={Exact Convergence of Gradient-Free Distributed Optimization Method in a Multi-Agent System},     volume={},  number={},  pages={5728-5733}, 
  address = {Florida,USA},
  year={2018},
  doi={10.1109/CDC.2018.8619028}}
  
  @ARTICLE{8703066,
  author={Pang, Yipeng and Hu, Guoqiang},
  journal={IEEE Transactions on Automatic Control}, 
  title={Randomized Gradient-Free Distributed Optimization Methods for a Multiagent System With Unknown Cost Function}, 
  year={2020},
  volume={65},
  number={1},
  pages={333-340},
  doi={10.1109/TAC.2019.2914025}}
  
  @article{doi:10.1137/18M119046X,
author = {Wang, Yinghui and Zhao, Wenxiao and Hong, Yiguang and Zamani, Mohsen},
title = {Distributed Subgradient-Free Stochastic Optimization Algorithm for Nonsmooth Convex Functions over Time-Varying Networks},
journal = {SIAM Journal on Control and Optimization},
volume = {57},
number = {4},
pages = {2821-2842},
year = {2019}
}



@article{stochsubgraded93658984324067920e3b4ad87eae70,
title = "Distributed Stochastic Subgradient Projection Algorithms for Convex Optimization",
keywords = "Convex optimization, Distributed algorithm, Stochastic approximation, Subgradient methods",
author = "S. Sundhar Ram and A. Nedi{\'c} and Veeravalli, {V. V.}",
year = "2010",
month = dec,
doi = "10.1007/s10957-010-9737-7",
language = "English (US)",
volume = "147",
pages = "516--545",
journal = "Journal of Optimization Theory and Applications",
issn = "0022-3239",
publisher = "Springer New York",
number = "3",
}


@inproceedings{Duchi2018IntroductoryLO,
  title={Introductory lectures on stochastic optimization},
  author={John C. Duchi},
  year={2018}
}

@ARTICLE{9416872,  author={Yu, Zhan and Ho, Daniel W. C. and Yuan, Deming},  journal={IEEE Transactions on Automatic Control},   title={Distributed Randomized Gradient-Free Mirror Descent Algorithm for Constrained Optimization},   year={2022},  volume={67},  number={2},  pages={957-964},  doi={10.1109/TAC.2021.3075669}}

@article{doi:10.1137/19M1259225,
author = {Gorbunov, Eduard and Dvurechensky, Pavel and Gasnikov, Alexander},
title = {An Accelerated Method for Derivative-Free Smooth Stochastic Convex Optimization},
journal = {SIAM Journal on Optimization},
volume = {32},
number = {2},
pages = {1210-1238},
year = {2022},
doi = {10.1137/19M1259225},

URL = { 
        https://doi.org/10.1137/19M1259225
    
},
eprint = { 
        https://doi.org/10.1137/19M1259225
    
}
,
    abstract = { We consider an unconstrained problem of minimizing a smooth convex function which is only available through noisy observations of its values, the noise consisting of two parts. Similar to stochastic optimization problems, the first part is of stochastic nature. The second part is additive noise of unknown nature but bounded in absolute value. In the two-point feedback setting, i.e., when pairs of function values are available, we propose an accelerated derivative-free algorithm together with its complexity analysis. The complexity bound of our derivative-free algorithm is only by a factor of \$\sqrt{n}\$ larger than the bound for accelerated gradient-based algorithms, where \$n\$ is the dimension of the decision variable. We also propose a nonaccelerated derivative-free algorithm with a complexity bound similar to the stochastic gradient--based algorithm; that is, our bound does not have any dimension-dependent factor except logarithmic. Notably, if the difference between the starting point and the solution is a sparse vector, for both our algorithms, we obtain a better complexity bound if the algorithm uses an 1-norm proximal setup rather than the Euclidean proximal setup, which is a standard choice for unconstrained problems. }
}

@ARTICLE{9224135,  author={Doan, Thinh T. and Maguluri, Siva Theja and Romberg, Justin},  journal={IEEE Transactions on Automatic Control},   title={Convergence Rates of Distributed Gradient Methods Under Random Quantization: A Stochastic Approximation Approach},   year={2021},  volume={66},  number={10},  pages={4469-4484},  doi={10.1109/TAC.2020.3031018}}


@incollection{ROBBINS1971233,
title = {A CONVERGENCE THEOREM FOR NON-NEGATIVE ALMOST SUPERMARTINGALES AND SOME APPLICATIONS},
editor = {Jagdish S. Rustagi},
booktitle = {Optimizing Methods in Statistics},
publisher = {Academic Press},
pages = {233-257},
year = {1971},
isbn = {978-0-12-604550-5},
doi = {https://doi.org/10.1016/B978-0-12-604550-5.50015-8},
author = {H. Robbins and D. Siegmund},
abstract = {Publisher Summary
This chapter discusses a convergence theorem for nonnegative almost supermartingales and some applications. It discusses a unified treatment of a number of almost sure convergence theorems by exploiting the fact that the processes involved possess a common almost supermartingale properties. The inequalities are simple and useful generalizations of well-known results in martingale theory. Dvoretzky proved a general convergence theorem that includes Blum's result for the Robbins–Monro process and the corresponding result for the Kiefer–Wolfowitz method for estimating the maximum of a regression function as special cases.}
}

@article{articlejands,
author = {Bauschke, Heinz and Borwein, Jonathan (Jon)},
year = {2001},
month = {December},
pages = {23-36},
title = {Joint and Separate Convexity of the {B}regman Distance},
volume = {8},
journal = {Studies in Computational Mathematics},
}



@article{10.1214/aos/1176345632,
author = {Charles M. Stein},
title = {{Estimation of the Mean of a Multivariate Normal Distribution}},
volume = {9},
journal = {The Annals of Statistics},
number = {6},
publisher = {Institute of Mathematical Statistics},
pages = {1135 -- 1151},
keywords = {Bayes estimate, confidence region, James-Stein estimate, Minimax estimate, moving average, multivariate normal mean, simultaneous estimation, trimmed mean},
year = {1981},
doi = {10.1214/aos/1176345632},
URL = {https://doi.org/10.1214/aos/1176345632}
}

@ARTICLE{9084356,
  author={Nedic, Angelia},
  journal={IEEE Signal Processing Magazine}, 
  title={Distributed Gradient Methods for Convex Machine Learning Problems in Networks: Distributed Optimization}, 
  year={2020},
  volume={37},
  number={3},
  pages={92-101},
  doi={10.1109/MSP.2020.2975210}}

  @misc{https://doi.org/10.48550/arxiv.1809.064741,
  doi = {10.48550/ARXIV.1809.06474},

  
  author = {Balasubramanian, Krishnakumar and Ghadimi, Saeed},
  
  keywords = {Optimization and Control (math.OC), Data Structures and Algorithms (cs.DS), Machine Learning (cs.LG), Statistics Theory (math.ST), Machine Learning (stat.ML), FOS: Mathematics, FOS: Mathematics, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Zeroth-order Nonconvex Stochastic Optimization: Handling Constraints, High-Dimensionality and Saddle-Points},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.2008.00051,
  doi = {10.48550/ARXIV.2008.00051},
  
  url = {https://arxiv.org/abs/2008.00051},
  
  author = {Ajalloeian, Ahmad and Stich, Sebastian U.},
  
  keywords = {Machine Learning (cs.LG), Optimization and Control (math.OC), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
  
  title = {On the Convergence of SGD with Biased Gradients},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.1309.5549,
  doi = {10.48550/ARXIV.1309.5549},
 
  
  author = {Ghadimi, Saeed and Lan, Guanghui},
  
  keywords = {Optimization and Control (math.OC), Computational Complexity (cs.CC), Machine Learning (stat.ML), FOS: Mathematics, FOS: Mathematics, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Stochastic First- and Zeroth-order Methods for Nonconvex Stochastic Programming},
  
  publisher = {arXiv},
  
  year = {2013},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{https://doi.org/10.48550/arxiv.1809.06474,
author = {Balasubramanian, Krishnakumar and Ghadimi, Saeed},
title = {Zeroth-Order Nonconvex Stochastic Optimization: Handling Constraints, High Dimensionality, and Saddle Points},
year = {2022},
issue_date = {Feb 2022},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {22},
number = {1},
issn = {1615-3375},
abstract = {In this paper, we propose and analyze zeroth-order stochastic approximation algorithms for nonconvex and convex optimization, with a focus on addressing constrained optimization, high-dimensional setting, and saddle point avoiding. To handle constrained optimization, we first propose generalizations of the conditional gradient algorithm achieving rates similar to the standard stochastic gradient algorithm using only zeroth-order information. To facilitate zeroth-order optimization in high dimensions, we explore the advantages of structural sparsity assumptions. Specifically, (i) we highlight an implicit regularization phenomenon where the standard stochastic gradient algorithm with zeroth-order information adapts to the sparsity of the problem at hand by just varying the step size and (ii) propose a truncated stochastic gradient algorithm with zeroth-order information, whose rate of convergence depends only poly-logarithmically on the dimensionality. We next focus on avoiding saddle points in nonconvex setting. Toward that, we interpret the Gaussian smoothing technique for estimating gradient based on zeroth-order information as an instantiation of first-order Stein’s identity. Based on this, we provide a novel linear-(in dimension) time estimator of the Hessian matrix of a function using only zeroth-order information, which is based on second-order Stein’s identity. We then provide a zeroth-order variant of cubic regularized Newton method for avoiding saddle points and discuss its rate of convergence to local minima.},
journal = {Foundations of Computational Mathematics},
month = {Feb.},
pages = {35–76},
numpages = {42},
keywords = {Complexity bounds, Conditional gradient methods, Newton method, 90C15, Zeroth-order methods, 90C26, Nonconvex optimization, 90C56, Stochastic optimization, 49M15, 65K05}
}

@article{10.5555/1046920.1194902,
author = {Banerjee, Arindam and Merugu, Srujana and Dhillon, Inderjit S. and Ghosh, Joydeep},
title = {Clustering with Bregman Divergences},
year = {2005},
issue_date = {12/1/2005},
publisher = {JMLR.org},
volume = {6},
issn = {1532-4435},
abstract = {A wide variety of distortion functions, such as squared Euclidean distance, Mahalanobis distance, Itakura-Saito distance and relative entropy, have been used for clustering. In this paper, we propose and analyze parametric hard and soft clustering algorithms based on a large class of distortion functions known as Bregman divergences. The proposed algorithms unify centroid-based parametric clustering approaches, such as classical <tt>kmeans</tt>, the Linde-Buzo-Gray (LBG) algorithm and information-theoretic clustering, which arise by special choices of the Bregman divergence. The algorithms maintain the simplicity and scalability of the classical <tt>kmeans</tt> algorithm, while generalizing the method to a large class of clustering loss functions. This is achieved by first posing the hard clustering problem in terms of minimizing the loss in Bregman information, a quantity motivated by rate distortion theory, and then deriving an iterative algorithm that monotonically decreases this loss. In addition, we show that there is a bijection between regular exponential families and a large class of Bregman divergences, that we call regular Bregman divergences. This result enables the development of an alternativeOn interpretation of an efficient EM scheme for learning mixtures of exponential family distributions, and leads to a simple soft clustering algorithm for regular Bregman divergences. Finally, we discuss the connection between rate distortion theory and Bregman clustering and present an information theoretic analysis of Bregman clustering algorithms in terms of a trade-off between compression and loss in Bregman information.},
journal = {Journal of Machine Learning Research.},
month = dec,
pages = {1705–1749},
numpages = {45}
}
