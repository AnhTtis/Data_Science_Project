\section{
%Setting 
Framework and Problem Statement}
\label{sec:setting}

We start with a reminder of key concepts in ranking data analysis and \textit{Robust Statistics}. The interested reader can refer to \citet{AY14,Huber} for more details. Here and throughout,
%\paragraph{Notation.} A 
a ranking over a set of $n\geq 1$ items is represented as a permutation $\sigma \in \pS$ where $\pS$ is the symmetric group. By convention, the rank $r$ of an item $i\in[n]$ is $r=\sigma(i)$. For any measurable space $\cX$, $\cM^1_+(\cX)$ is the set of probability measures on $\cX$, ${\rm TV}(p,q)$ the total variation distance between $p$ and $q$ in $\cM^1_+(\cX)$.

\subsection{Ranking Data and Summary Statistics}

The descriptive analysis of probability distributions, or datasets for their empirical counterparts, is a fundamental problem in statistics. For distributions on Euclidean spaces such as $\lR^d$, this problem has been widely studied and covered by the literature, with the study of statistics ranging from the simplistic sample mean to more sophisticated data functionals, such as $U/L/R/M$-statistics or depth functions for instance \cite{vdV98}. 

Defining similar notions for probability distributions on $\pS$, the space of rankings, is challenging due to the absence of vector space structure. However, fueled by the recent surge of applications using preference data, such as \textit{e.g.} recommender systems, the statistical analysis of ranking data has recently regained attention and certain classic problems have been revisited, as for instance those related to consensus rankings and their generalization ability (see \textit{e.g.}~\citet{Korba2017} and the references therein) or to the extension of depth functions to ranking data \cite{goibert2022depthranking}.

\paragraph{Central tendency or location.} Statistics measuring centrality, such as the mean (or the median for univariate distribution), can be seen as barycenters of the sampling observations w.r.t a certain distance. Consensus Ranking / Ranking Aggregation extends this idea to probability distributions on $\pS$ \cite{Deza}. Given a (pseudo-)metric $d$ defined on $\pS$ and a distribution $p\in\distribs$, a \emph{ranking median} $\sigma^{\rm med}_{p,d}\in\pS$ can be defined as
\begin{align}
    \label{eq:ranking_median}
    \sigma^{\rm med}_{d}(p) := \argmin_{\sigma \in \pS} \lE_{\Sigma \sim p}(d(\sigma, \Sigma)).
\end{align}
A well-studied instance of ranking median is the \emph{Kemeny consensus}, which corresponds to the situation where $d$ is the \emph{Kendall Tau} distance: for all $\sigma,\;  \nu$ in $\pS$,
\begin{align}
    d_{\tau}(\sigma, \nu) = \frac{2}{n(n-1)}\sum_{i<j}\indicator{\sigma(i)<\sigma(j)}\indicator{\nu(i) > \nu(j)}
    \label{eq:kendall_tau}
\end{align}
Another common choice is the \emph{Borda count} when $d$ is the \emph{Spearman Rho}, see \cref{app:additional_metrics} for more details. %\clem{Add something about median scalability.}
Moreover, when $d$ is the Kendall tau, Borda is a $O(n \log n)$, 5-approximation of the Kemeny ranking~\cite{Caragiannis2013,JKS16,Coppersmith:2010}, which is a NP-hard to compute~\cite{Dwork}. 
%Such median is a simple, yet effective, method to define \emph{location} for the ranking distribution w.r.t. the metric $d$. 



\paragraph{More complex statistics based on ranking data.} Often, the information carried by a location statistic must be complemented. For instance, a notion of \emph{dispersion} or \emph{shape} is generally key to assessing convergence results or building confidence regions. To this end, the notion of \emph{statistical depth function} has been developed for multivariate data (in Euclidean spaces) (see \cite{ZuoSerfling00} and the references therein) and recently adapted to ranking, refer to \cite{goibert2022depthranking}.
However, as more complex statistics are more likely to exhibit robustness issues, we focus on simple statistics estimating location for ranking distribution.

\subsection{Robust Statistics}

To evaluate the robustness of a statistic, the notion of \textit{breakdown function} has been introduced in the seminal work of \cite{huber1964robust}. Informally, the breakdown function for a statistic $T$ on a distribution $p$ measures the minimal attack budget required for an adversarial distribution to change the outcome of the statistic $T$ by an amount at least $\delta > 0$. 

% \begin{definition}
%     {\sc{Breakdown Point}.} The breakdown point of level $\delta$, for distance on rankings $d$ is denoted by $\varepsilon^\star_{\delta, d}: \Delta^{\frak{S}_n} \times \mathcal{T} \to \mathbb{R}_{+}$ and defined by:

%     $$ \varepsilon^\star_{\delta, d}(p,T) = \inf \left\{ \varepsilon > 0 \, | \, \sup_{q | TV(p,q) \leq \varepsilon} d(T(p), T(q)) \geq \delta \right\} $$
% \end{definition}

\begin{restatable}{definition}{defbreakdownfunction}\label{def:breakdown_function}
    {\sc{(Breakdown Function)}} Let $\cX$ and $\cY$ be measurable spaces, $p\in\cM^1_+(\cX)$, $T: \cM^1_+(\cX) \to \cY$ a measurable function and $d$ a metric on $\cY$.
    For any level $\delta \geq 0$, the breakdown function of the functional $T$ at $p$ is 
    \begin{align*}
        \varepsilon^\star_{d, p,T}(\delta) = \inf \left\{ \varepsilon > 0 \, \middle| \, \sup_{q : {\rm TV}(p,q) \leq \varepsilon} d(T(p), T(q)) \geq \delta \right\}.
    \end{align*}
\end{restatable}
In the traditional case $\cX=\cY=\mathbb{R}$, the level $\delta$ is generally set to $+\infty$ and the budget required is referred to as \emph{breakdown point}. 
In the extreme case, when $T$ is the identity and $\delta = 0^+$, $\varepsilon^\star$ quantifies the budget of attack under which \emph{identifiability} of the distribution is possible (which requires the additional knowledge that $p$ belongs to some family). 


\paragraph{Application to Ranking Data.} In \citet{agarwal2020rank} such a study on identifiability is provided for the Bradley-Terry-Luce \cite{BT1952, Luce59} model under a budget constraint on pairwise marginals rather than the Total Variation, and \citet{jin2018} on the Heterogeneous Thurstone Models \cite{thurstone1927}.
However, summary statistics, such as a central tendency, are generally harder to break than the full distribution itself, so the breakdown function provides a finer quantification of robustness than the identifiability of the distribution.
Since the distances on $\pS$ are bounded, in general, the full breakdown function needs to be considered and one cannot focus only on a particular level such as $\delta = 0^+$ or $\delta = +\infty$. From here and throughout, the distance $d$ and the attack amplitude $\delta$ are normalized to lie between $0$ and $1$. 

The robustness of the median statistic when an adversary is allowed to attack with any strategy a pairwise model has also been studied ~\cite{datar2022byzantine}. They characterize the robustness of two statistics in terms of the L2 distance on distributions. We propose in Definition~\ref{def:breakdown_function} a more general and natural measure for robustness as a function of  the distance between the true and a corrupted statistic. 

\paragraph{Bucket Rankings as a robustness candidate.} In rankings, adversarial attacks often target pairs of items that are ``close" in some sense \cite{agarwal2020rank}: consecutive ranks, a pairwise marginal probability close to $\frac{1}{2}$, \ldots Thus, a simple and efficient way to robustify a ranking median is to accept \emph{ties}, rather than being restricted to a strict order.



\subsection{Challenges and Contributions}



% Robustness of ranking medians -- breakdown function (CONTEXT)
% Often no closed-form for the median (CHALLENGE)
% General lower bound + upper bound for Kemeny (CONTRIBUTION)
There is a wide number of median statistic studies motivated by the lack of analytical expression and the computational and statistical challenges that arise in the estimation process.
However, robustness results for ranking statistics are rare and not rigorous enough for comparing different estimators. % or even studying the most prominent rule, Kemeny. 


\begin{contribution}
Using \cref{def:breakdown_function} with the Kendall tau distance provides a straightforward measure of robustness for ranking medians.
In \cref{sec:bd_kem} we provide a lower-bound on the breakdown function for a ranking median (\cref{thm:ubbreakdownfunctionmedian}) and a tight upper-bound for the Kemeny consensus (\cref{thm:ubbreakdownfunctionmedian}). %We conclude that there is not one median that is universally more robust than another.
\end{contribution}


% Extension of breakdown functions to bucket rankings (CONTEXT)
% Need to extend metrics and to handle the non-continuity of the objective (CHALLENGE)
% An empirical estimator for the breakdown function (CONTRIBUTION)
Moreover, slight perturbations in the pairwise relations of items that are similar to each other can imply breaking a median estimator, showing a lack of robustness. It is natural to propose more robust estimators by allowing pairs of items to be ``equally ranked", i.e., by considering bucket ranking statistics. However, generalizations of the breakdown function for bucket rankings require the use of Kendall tau for buckets, which is  computationally impractical. 

\begin{contribution}
In \cref{sec:buckets} we propose an extension of the breakdown function for bucket rankings which is built upon a Hausdorff generalization of the Kendall tau distance. We also develop an optimization algorithm to approximate this breakdown function that overcomes the computational issue of having a piece-wise constant objective function.
%for which we propose a computationally efficient algorithm. The close form expression is difficult to obtain in general since it requires optimizing a piece-wise constant function. However, we propose an empirical estimator building on Lagrangian relaxation to overcome the computational issues. 
\end{contribution}


% How to robustify classical ranking medians with bucket rankings (CONTEXT)
% Direct extension of notion of median to \wO is intractable (CHALLENGE)
% A plug-in method to robustify ranking medians backed with XP (CONTRIBUTION)

We illustrate and show empirically that bucket rankings are more robust median estimators than rankings. However, finding the optimal bucket order statistic requires exhaustively searching the space of bucket rankings $\wO$, which is even larger than the space of permutations, of factorial cardinality, and therefore, it is totally infeasible. 

\begin{contribution}
In \cref{sec:our_stats} we propose a general method for robustifying medians: given a ranking median, our algorithm successively merges ``similar'' items together into the same bucket. 
We evaluate this statistic in \cref{sec:exps}, showing an improvement of robustness w.r.t. Kemeny's median without sacrificing its precision. 
\end{contribution}




% \subsection{Main Contributions}

%  We develop our framework both theoretically and experimentally, and provide a method to evaluate said robustness in practice.

% Our main contributions are thus the following:
% \begin{itemize}
%     \item We extend the notions of distances and statistics to bucket rankings.
%     \item We provide a definition and a practical algorithm to estimate robustness for summary statistics that output a bucket ranking.
%     \item We provide an in-depth comparison of different relevant statistics, both in terms of accuracy and robustness.
% \end{itemize}


% \subsection{Accuracy and Robustness of Statistics}
% Several criteria are usually considered to compare summary statistics. 

% \begin{definition}
%     {\sc{Accuracy}.} Let $d: \frak{S}_n \to \mathbb{R}$ be a (pseudo-) distance. The accuracy of a statistic $T$ is defined by:

%     $$ \text{Acc}_{p,d}(T) := - \mathbb{E}_{\Sigma \sim p}(d(T(p), \Sigma)) $$
% \end{definition}

% By definition, the ERM statistic is optimal with respect to the accuracy criteria.

% However, the evolution of the applications using preference data have shed lights on the problems raised by malevolent manipulation of data (e.g. fake comments), which justify the need for \textit{robust} statistics.

% In $\mathbb{R}$, robust statistics have been studied since the seminal works of Huber, in which the classical attacks consists of \textit{adversarial attacks}, and the classical way to evaluate the robustness of a statistic is to compute its \textit{breakdown point.}

% In the field of rankings, very few works have started to analyze statistics through the scope of robustness. Agarwal \intodo{Add limitations}. Depth functions paper \intodo{Add limitations}.



%From the representation compactness point of view, bucket rankings are similar to rankings (strict orders), as they can be encoded by a vector of $n$ scores that generates the order by sorting them, one per item, where ties are represented by equal scores. 

%In terms of expressiveness to summarize distributions over permutations, bucket orders have a strong advantage over strict orders that goes further than the fact that strict orders are a particular case of bucket orders. A bucket order $\pi \in \wO$ can be seen as a uniform distribution over a subset of permutations (those generated by breaking ties of $\pi$ uniformly at random). Because $|\wO| \gg |\pS|$, bucket orders are providing a much finer way to grid the simplex $\Delta^\pS$ than strict orders which only lies at the corners. Hence, as a summary statistic, bucket orders can be more precise (closer to the summarized distribution). \clem{I'm not happy with this paragraph. The idea is here, but badly explained.}
