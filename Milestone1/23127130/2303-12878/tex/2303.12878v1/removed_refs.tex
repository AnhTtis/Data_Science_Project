
\begin{itemize}
    \item We generalize the Kendall tau distance to bucket rankings. We propose a meaningful extension for the adversarial context, in which its possible to differentiate the attacks that \emph{include} more permutations in the statistic from those attacks that \emph{remove} permutations from it. Moreover, its computed in $O(n^2)$.
    \item %adapt metric from $\pS$ to $\wO$ in a meaningful way (metric vs pseudo-metric). 
    We adapt the breakdown function for RANKINGS  bucket ranking spaces $\wO$ based upon the previously metric. 
    \item %practical estimation of $\varepsilon^\star$ is not easy due to the dimension of $\cM_+^1(\pS)$
    An optimal search for $\varepsilon^\star$ is infeasible for medium-sized problems due to the factorial cardinality of the space of permutations. We propose a tractable approximation of quadratic complexity and show empirical evidences of its performance. 
\end{itemize}


EXTENSION TO BUCKET RANKINGS

For the summary statistic:
\begin{itemize}
    \item In the presence of adversarial attacks ranking statistics are not robust, as shown in Section~\ref{sec:bd_kem} for the Kemeny ranking statistic. 
    \item We propose two more robust statistics defining central tendency with bucket rankings.
%    \item As distribution $p$ is on $\pS$, central tendency cannot be defined as a median on $\wO$.
%    \item introducing first tie may be easy
%    \item then transitivity problem
%    \item We propose several ways to define central tendency of a distribution which outputs a bucket ranking
\end{itemize}

We empirically compare the different central tendency statistics and their robustness.
 
\section{Refs}

Boutillier





Byzantine Spectral Ranking,  \url{https://arxiv.org/pdf/2211.07902.pdf}: (see references therein, statistical approach for more efinitions of ROBUSTNESS and ADVERSARIAL, its similar to standard R-Manipulation, defined below). They say that: 
We first show that the popular spectral ranking based Rank-Centrality algorithm, though optimal for the BTL model, does not perform well even when a small constant fraction of the voters are Byzantine. We introduce the Byzantine Spectral Ranking Algorithm (and a faster variant of it), which produces a reliable ranking when the number of good voters exceeds the number of Byzantine voters

Fast and Robust Rank Aggregation against Model Misspecification \url{https://jmlr.org/papers/volume23/20-315/20-315.pdf}



Other manipulation measures/setting

Here\cite{ANSHELEVICH201827} DISTORION is defined as the worst-case ratio between the performance of an alternative selected by the rule and that of an optimal alternative. The goal of our paper is to quantify the distortion of well-known voting rules. For positional (s.a. Borda) they can not be bounded. THIS CAN BE MORE SIMILAR TO BREAKDOWN POINTS

The following closer to the social choice literature: 
The related concepts on manipulation, from \cite{Faliszewski2010}

\begin{definition}
    Let R be a voting rule. In R- MANIPULATION we are given an election E=(C,V+W ), where voters in V have fixed preference orders and the preference orders of voters in W remain to be set, and a designated candidate $p\in C$; we ask if there is a way to set the votes in W so that p is a winner. 
\end{definition}

\begin{definition}
    Let R be a voting rule. In the R-BRIBERY problem we are given an election E = (C, V ), a designated candidate $p\in C$, and a natural number B. We ask if it is possible to ensure that p is an R-winner of E via changing the votes of at most B voters. 
\end{definition}


The second is more similar to the definition of adversarial distributions. The first one (or more generally, the optimization version of this decision problem: given a collection of honest votes, which is the smallest set of manipulated votes necessary so that a given candidate becomes the winner?) is the standard setting, which is described in the following paragraphs. (Voting rules are functions to aggregate votes, to get the winner of an election. In social choice are the counterpart of statististics $T$.  'adversarial' is denoted usually 'strategic', `robust estimator` will be something like 'strategyproof voting rule')


The Gibbard-Satterthwaite \cite{Gibbard1973, satterthwaite1975strategy} theorem states that every reasonable voting rule (there is a distinguished voter who has a dictatorial power, or if the rule limits the possible outcomes to two options only) can be manipulated. Following this result, the community focused on characterizing the worst-case complexity of the voting rules, claiming that if a voting rule is hard to manipulate then it is safe. This is justified given that manipulation problems are carried out in large and online environments in which the efficiency in the computation of the results is crucial. For the Borda voting rule and many other voting rules, the complexity is NP-hard \cite{Davies2011, Brandt2016}.

The previous results show that finding the smallest collection of permutations that change the results for the Borda voting rule is difficult {in the worst case}. However, manipulating Borda is {``easy in practice''}. For example, the \texttt{ReverseBorda} algorithm introduced by \cite{Zuckerman2009} is able to find a near-optimal solution in polynomial time. Here, near-optimal means that the number of manipulated votes will be optimal or at most one more than optimal. 

summary of complexity \cite{Davies2011}


Francois Durand, 
Paris-Saclay, France
(works on voting systems and their manipulability (tactical voting), using computer simulations and tools from game theory). He has a python package to generate manipulations for different voting rules, \url{https://www.bell-labs.com/about/researcher-profiles/francois-durand/#gref}


\section{Blop}

With the recent growth of applications using preference data (recommendation systems, etc.), the analysis of ranking data has gained much attention. \\

\subsection{Notations}

Rankings are usually denoted by $\sigma$ and live in the symmetric group $\frak{S}_n$ composed of $n$ items indexed by $\{1, ..., n \}$. Our data typically consists in a distribution $p \in \Delta^{\frak{S}_n}$, or alternatively its empirical counterpart when considering a finite dataset. To extend the notion of rankings, we recall here the notion of \textit{weak orders}, which can be intuitively described as sets of rankings (under some constraints), and are usually denoted by $\pi \in \Pi_n$:

\begin{definition}
    {\sc{Weak orders}} Go check \cite{fagin2006comparing}
\end{definition}

Distances or pseudo-distances between rankings (and weak orders) will be denoted by $d$. Several distances on $\frak{S}_n$ are widely used in the literature, like Kendall-tau, Spearman's footrule or Spearman's rho distances. However, note that such distances require specific extensions to be used on the space of weak orders. \\

A statistic (also called method) to compute a median from a distribution of rankings $p$ is a function denoted by $T: \Delta^{\frak{S}_n} \to \frak{S}_n \cup \Pi_n$, which outputs a unique ranking or weak order. The space of rankings median statistics will be denoted by $\mathcal{T}$. \\

Algebraic / vectorial representation ?? \intodo{I think it is better to include it} 


\subsection{Consensus Ranking / Ranking Aggregation - Accuracy}

% SST distributions --> uniqueness of Kemeny's aggreagtion. Put SST and pairwise probabilities there.

The problem of summarizing probability distributions on the symmetric group by a single ranking, known as Consensus Ranking / Ranking Aggregation, has been widely studied (\intodo{Add refs}), specifically with a metric-based approach: a (pseudo-) distance $d$ is defined on $\frak{S}_n$ and a barycentric ranking called median is computed to summarize $p$. Several optimization methods $T$ can be defined, but the most studied one is the Empirical Risk Minimization (ERM) statistic, which outputs a relevant median.

\begin{definition}
    {\sc{ERM objective}.}  Let $d: \frak{S}_n \to \mathbb{R}$ be a (pseudo-) distance on $\frak{S}_n$, $p \in \Delta^{\frak{S}_n}$ a distribution on rankings. The ERM objective is defined by:

    $$ L^{\text{ERM}}(p,d) := \min_{\sigma \in \frak{S}_n} \mathbb{E}_{\Sigma \sim p}(d(\sigma, \Sigma)) $$

    The median for the ERM objective is denoted by $\sigma^{\text{ERM}}_{p,d} := \argmin_{\sigma \in \frak{S}_n} \mathbb{E}_{\Sigma \sim p}(d(\sigma, \Sigma))$
\end{definition}

The ERM objective outputs an ERM median which is optimal in terms of accuracy:

\begin{definition}
    {\sc{Accuracy}.} Let $d: \frak{S}_n \to \mathbb{R}$ be a (pseudo-) distance. The accuracy of a statistic $T$ is defined by:

    $$ \text{Acc}_{p,d}(T) := - \mathbb{E}_{\Sigma \sim p}(d(T(p), \Sigma)) $$
\end{definition}

However, the ERM does not incorporate at all any notion of robustness against attacks.

% Add robustness in R, Huber, etc.
% Show the previous "questions" in the literature and then the pb we attack

\section{Defintion of Robustness in Rankings}

% We want to extend Huber's work to rankings. This is not easy because of... We can compute for ERM, but we have to approximate for the other objectives. How do we approximate...

% Accuracy is nice (intro to ERM) but need for robustness --> Intro to robust stats (Huber, breakdown points).

% Weak orders: def, usefulness, extension of kendall distance

% Main question: what type of objectives would provide the best compromise between accuracy and robustness?

In this paper, we focus on comparing the accuracy and robustness performances of several optimization objectives (including the ERM). However, such notions are poorly defined in the field of ranking data.

\subsection{Adversarial Distributions}

In the field of ranking data, very few works have studied adversarial attacks (\intodo{Add refs}). In this paper, we will focus on poising attacks, where the attacker is allowed to modify the original distribution $p$ by a budget $\varepsilon$, in order to fool the Ranking Aggregation statistic $T$.

\begin{definition}
    {\sc{Adversarial Distribution}.} An adversarial distribution against the probability distribution $p \in \Delta^{\frak{S}_n}$ for statistic $T$ with budget $\varepsilon$, shortened $(p, T, \varepsilon)$-adversarial distribution, is a probability distribution $q_{P, T, \varepsilon}$ such that:
    
    1) the budget constraint is satisfied: $\text{TV}(p, q_{P, \varepsilon}) = \frac{1}{2} \sum_{\sigma \in \frak{S}_n} |p(\sigma) - q_{P, T, \varepsilon}(\sigma)| \leq \varepsilon$, where $\text{TV}$ is the total-variation distance, and $\varepsilon \geq 0$ is the attack budget.

    2) If possible, $q_{p, T, \varepsilon}$ fools the statistics $T$: $T(p) \neq T(q_{p, T, \varepsilon})$.
\end{definition}

To improve readability, whenever the context is clear, the adversarial distribution $q_{p, T, \varepsilon}$ bill be simply denoted by $q$.

\subsection{Evaluating Robustness}

To evaluate the robustness of a statistic $T$, the seminal work of Huber (\intodo{Add refs}) has introduced the notion of \textit{breakdown points} in $\mathbb{R}$. \intodo{Do I recall the def in R?}

We adapt this definition to ranking data.

\begin{definition}
    {\sc{Breakdown Point}.} The breakdown point of level $\delta$, for distance on rankings $d$ is denoted by $\varepsilon^{*}_{\delta, d}: \Delta^{\frak{S}_n} \times \mathcal{T} \to \mathbb{R}^{*}$ and defined by:

    $$ \varepsilon^{*}_{\delta, d}(p,T) = \inf \left\{ \varepsilon > 0 \, | \, \sup_{q | TV(p,q) \leq \varepsilon} d(T(p), T(q)) \geq \delta \right\} $$
\end{definition}

%\subsection{Weak orders}

%The goal of Consensus Ranking / Ranking Aggregation is to summarize a distribution $P$ with a median ranking. For improving the robustness of the median, an interesting strategy is to allow for indifferences \intodo{fuzziness}. Instead of outputting a unique permutation, the optimization objective / statistic could then output a set of permutations. In the extreme case, if the median is the whole set $\frak{S}_n$, then the robustness is maximal (no adversarial distribution could fool the statistic). \\

%Weak orders / bucket orders are a good compromise / intermediary between $\frak{S}_n$ and $2^{\frak{S}_n}$. The space of weak orders is denoted by $\Pi_n$. Following \cite{fagin2006comparing}, \intodo{... Go check how this is defined and reuse same notations for bucket orders}. \\

%As weak orders are sets of rankings and not rankings, the distances $d$ cannot be use directly on such objects. However, we can generalize the distances $d$ the following way: \intodo{def of generalized hausdorff-average kendall, etc.} \\


\noindent\fbox{%
    \parbox{\textwidth}{%
        The goal of our paper is to study the tradeoffs between Accuracy and Robustness in the context of Consensus Ranking. More specifically, we develop several statistics in addition to the ERM, and compare them both in terms of robustness (breakdown points) and accuracy (expected loss). We provide experimental algorithms to compute statistics and evaluate our medians with theoretical convergence guarantees.
    }%
}

\section{An introductory example: evaluating the ERM}
%An introductory example, and theoretical results --> Theoretic accuracy vs robustness plot

As previously mentioned, the ERM is optimal in terms of accuracy. Here, we theoretically evaluate its breakdown point. Let us write $\sigma^{R}$ the opposite ranking compare to $\sigma$.

Let us define the following distribution:

\begin{equation*}
  \tilde{p} = \tilde{p}_{\sigma, \varepsilon}(\mu) :=
    \begin{cases}
      p(\mu) & \; \forall \, \mu \neq \sigma, \sigma^{R} \\
      p(\sigma) + \varepsilon/2 & \; \text{if } \mu = \sigma \\
      p(\sigma^{R}) - \varepsilon/2 & \; \text{if } \mu = \sigma^{R}
    \end{cases}       
\end{equation*}

Then we have $$ \mathbb{E}_{\Sigma \sim \Tilde{p}}(d(\sigma, \Sigma)) = \mathbb{E}_{\Sigma \sim p}(d(\sigma, \Sigma)) - \frac{\varepsilon}{2} d(\sigma, \sigma^{R})$$ 

Thus, $\tilde{p}_{\sigma, \varepsilon}$ is the optimal distribution to make $\sigma$ the ERM median while under budget constraint $\varepsilon$ \intodo{(there is a factor 2 to handle here because of exact TV def)}.

To create $\delta$ inversions between the medians for distribution $p$ and its adversarial counterpart for the ERM statistic, we thus need enough budget such that $\mathbb{E}_{\Sigma \sim \Tilde{p}}(d(\sigma, \Sigma)) < \mathbb{E}_{\Sigma \sim \Tilde{p}}(d(\mu, \Sigma)) \, \forall \mu$ "in-between" $\sigma$ and $\sigma^{\text{ERM}}_{p,d}$, i.e. $(p^T d \sigma - p^T d \mu)/(\sigma^T d \mu) < \varepsilon \; \forall \mu \text{ s.t. } d(\sigma^{ERM}_{p,d}, \mu) \leq \delta$. \\

Thus, the breakdown point for the ERM is:
\begin{equation}
    \varepsilon^{*}_{\delta, d}(P,\text{ERM}) = \min_{\sigma | d(\sigma^{ERM}_{P,d}, \sigma) = \delta} \; \; \max_{\mu | d(\sigma^{ERM}_{P,d}, \mu) \leq \delta} \frac{p^T L \sigma - p^T L \mu}{\sigma^T L \mu}
    \label{eq:bkdwn_pt_erm}
\end{equation}

An immediate implication of equation \ref{eq:bkdwn_pt_erm} is that, when $p$ is the uniform distribution and $d$ is \intodo{property like sum of distance from a ranking to all the others is constant} (e.g. Kendall-tau, Spearman's footrule and Spearman's rho), then the breakdown point for any $\delta \geq 1$ is $0$. In that case, the ERM objective provides no robustness at all.

\section{Robust objectives}

\subsection{(Stritly) Stochastically Transitive Distributions}

\subsection{Distributionally Robust Optimization statistic}

The Distributionally Robust Optimization (DRO) objective function is a well-known approach for reaching robustness \intodo{Add refs}. In the context of Consensus Ranking, we define the DRO statistic as such:

\begin{definition}
    {\sc{DRO statistic}.} Let $d : \frak{S}_n \to \mathbb{R}$ be a (pseudo-) distance on $\frak{S}_n$, $p \in \Delta^{\frak{S}_n}$ a distribution on rankings. The DRO objective is defined by:

    $$ L^{DRO}(p,d) := \min_{\pi \in \Pi_n} \max_{q \, | \, TV(p,q) \leq \varepsilon} \mathbb{E}_{\Sigma \sim q}(d(\pi, \Sigma)) $$

    The median for the DRO objective is denoted by $\pi^{DRO}_{p,d} := \argmin_{\pi \in \Pi_n} \max_{q \, | \, TV(p,q) \leq \varepsilon} \mathbb{E}_{\Sigma \sim q}(d(\pi, \Sigma))$ 
\end{definition}

A first remark about the DRO statistic is that it can output a weak order as the optimum, which was not possible with the ERM statistic. Intuitively, under some conditions detailed later, the fuzziness incorporated by the use of weak orders (compare to rankings) allows for a compromise in this two-player game. \intodo{Add the property and the proof}.

Obtaining a closed-form expression for the optimal adversarial distribution $q$ from the max part (inner problem) is a difficult problem, mainly because it is hard to derive practical constraint from the definition of weak orders. To circumvent this issue, we will use empirical approximation of the accuracy and the breakdown points for the DRP statistic.

\subsection{Merge and Maxpair algorithms}

As we can express the ERM median for a distribution $p$ solely with its pairwise probability matrix, an intuitive idea to get a robust median is to merge items that are close, i.e. with a pairwise probability close to $1/2$. Do do so, we first introduce the Merge statistic.

\intodo{Add algo}

A strong limitation of the merge algorithm is that, for some SST distributions $p$, it can't reach the optimal solution for the depth problem \intodo{should we even mention that?}. To overcome this limitation, we derived a more complex version of this algorithm, called the Maxpair statistic.

\intodo{Add algo}

\subsection{Functional Distance between Depths}

A depth function for a distribution $p$ and distance $d$, denoted by $D_{p,d}: \frak{S}_n  \to \mathbb{R}_+$, is a function that gives an idea of the \textit{centrality} of a ranking $\sigma$ with respect to the distribution $p$. It has been defined and studied in the context of ranking aggregation by \cite{goibert2022depthranking}, where they show that depth function can be relevant to improve robustness.

\intodo{Should we comment on the fact that finding a dirac/mixture of diracs is the same as finding a median}

Thus, we define the Distance Between Depths (DBD) statistic as:

\begin{definition}
    {\sc{DBD statistic}.} Let $d : \frak{S}_n \to \mathbb{R}$ be a (pseudo-) distance on $\frak{S}_n$, $p \in \Delta^{\frak{S}_n}$ a distribution on rankings. The DBD objective is defined by:

    $$ L^{DBD}(p,d) := \min_{q \in \Delta^{\Pi_n}} || D_{p,d}(.) - D_{q,d}(.) || $$

    The median for the DBD objective is denoted by $\pi^{DBD}_{p,d} := \argmin_{q \in \Delta^{\Pi_n}} || D_{p,d}(.) - D_{q,d}(.) ||$ 
\end{definition}


\section{Empirical evaluation of robustness}

Explanations about smoothing, relaxations, etc.

Plots.

\begin{figure}
\centering
\includegraphics[width=8cm]{img/pareto_front_9nov.png}
\end{figure}
