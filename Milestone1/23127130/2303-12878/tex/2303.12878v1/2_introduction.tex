\section{Introduction}

One of the keys to the path of a trustworthy AI is undeniably the design of statistical learning techniques that can resist, to a certain extent, possible corruptions of the training dataset. The analysis of the influence of atypical observations on the outputs of machine-learning algorithms has received increasing interest in the AI literature these last few years and has recently motivated a wide variety of dedicated works (refer to \citet{lugosi2019risk,monk} for instance), revisiting in particular seminal concepts in \textit{Robust Statistics} such as the $\varepsilon$-contamination model, where the training dataset is supposedly contaminated by a fraction $\varepsilon\in (0,1)$ of outliers \cite{huber1964robust}. It is the goal of this paper to investigate the statistical analysis of ranking data from the perspective of robustness. Ranking data are indeed ubiquitous in modern technologies such as search engines or recommending systems and the question of their reliability in presence of corrupted data is a scientific challenge. Given the nature of preference data, observable in the form of permutations (complete rankings, \textit{i.e.} elements of the symmetric group $\mathfrak{S}_n$) in the simplest case, informative statistics based on the latter are far from being simple. This is mainly due to the lack of vector space structure on $\mathfrak{S}_n$ and the impossibility of averaging directly such data. A major problem in ranking data analysis referred to as \textit{Consensus Ranking} or \textit{Ranking Aggregation}, and which the present article focuses on, consists in its simplest formulation in summarizing a ranking distribution (\textit{i.e.} a probability distribution on $\mathfrak{S}_n$) by a \textit{median ranking} \cite{Kemeny59}. Even though this problem has a long history in social choice theory, see \textit{e.g.} \citet{de2014essai,de1781memoire}, it has been the subject of much attention within the machine-learning community, see \textit{e.g.} \citet{procaccia2016optimal,JKS16} among many others, references being far too numerous to be listed exhaustively. While most documented works concern the issue of computing (approximately) median rankings with theoretical guarantees, this paper studies in contrast the robustness properties of consensus ranking methods by means of a novel approach, extending that developed in \citet{Huber} for multivariate data. We emphasize that this angle is original to the best of our knowledge and distinguishes itself from related results in social choice theory, where median rankings are identified with \textit{voting rules}. 
%Bottom line: we want to study robustness of central tendency / location statistics in ranking.
%\paragraph{Social choice perspective}
%This work also builds upon classical social choice theory. We approach from an statistical perspective one of the fundamental problems: analysing statistics, which are denoted voting rules in social choice. 
In line with these works, the well-known Gibbard-Satterthwaite theorem~\cite{gibbard1973manipulation, satterthwaite1975strategy}  states that every reasonable voting rule can be manipulated. We point out that there has been a wide body of research devoted to characterizing the complexity of computing manipulations, NP-hardness result on manipulation being considered as a guarantee for robustness \cite{bartholdi1989computational, Davies2011, Brandt2016}. However, beyond-worst-case analysis shows that the problems are easy in practice \cite{Zuckerman2009}. In the present article, we complement these works on the issue of robustness to vote manipulation by investigating how the seminal concept of \textit{breakdown point}, a popular measure of robustness of estimators in multivariate statistical analysis, may apply to consensus ranking. Basically, it can be defined as the proportion of outliers or (possibly deliberately) corrupted observations that can contaminate the data sample without jeopardizing the statistic. As will be shown, one of the main difficulties faced in the context considered here lies in the fact that consensus rankings are often obtained by solving an optimization problem and no closed analytical form for the solutions is available in general. Consequently, the computation of breakdown points of ranking statistics is generally a computational challenge. Our main proposal here consists in relaxing the constraint stipulating that the summary of a ranking distribution should be necessarily represented by a single ranking (\textit{i.e.} a strict order on the set of items indexed by $i\in \{1,\;\ldots,\; n \}$), or equivalently by a point mass on $\mathfrak{S}_n$. Instead, we suggest summarizing a ranking distribution by a \textit{bucket ranking} (\textit{i.e.} a weak order on the set $\{1,\;\ldots,\; n \}$), the possibility of observing ties in the orderings considered being shown to have crucial advantages regarding robustness.


The paper is organized as follows. In \cref{sec:setting}, basics in ranking aggregation and the notion of breakdown function are introduced, as well as the contributions of our paper. \cref{sec:robustness} focus on robustness, by detailing our theoretical results on the breakdown functions for the classical median, extending this concept to bucket rankings, and providing an optimization algorithm to estimate it in practice. \cref{sec:our_stats} is dedicated to the definition of our robust statistic, called the Downward Merge statistic. Finally, experiments are done in \cref{sec:exps} to highlight the usefulness of our Downward Merge statistic for solving Robust Consensus Ranking tasks.

%contribute in this line proposing new statistical analysis techniques of ranking data on the question of robustness to manipulation.


% Robustness pb --> ML def. of attacks Generalization to rankings, and classical median pbs.

% Add a subsection in the preliminary on distance on weak order / symmetric vs non-symmetric
