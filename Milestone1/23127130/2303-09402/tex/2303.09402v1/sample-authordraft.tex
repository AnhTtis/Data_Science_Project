%%
%% This is file `sample-manuscript.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `manuscript')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-manuscript.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass command.
%%%% Small single column format, used for CIE, CSUR, DTRAP, JACM, JDIQ, JEA, JERIC, JETC, PACMCGIT, TAAS, TACCESS, TACO, TALG, TALLIP (formerly TALIP), TCPS, TDSCI, TEAC, TECS, TELO, THRI, TIIS, TIOT, TISSEC, TIST, TKDD, TMIS, TOCE, TOCHI, TOCL, TOCS, TOCT, TODAES, TODS, TOIS, TOIT, TOMACS, TOMM (formerly TOMCCAP), TOMPECS, TOMS, TOPC, TOPLAS, TOPS, TOS, TOSEM, TOSN, TQC, TRETS, TSAS, TSC, TSLP, TWEB.
\documentclass[acmsmall]{acmart}
% \documentclass[manuscript,screen,review]{acmart}


%%%% Large single column format, used for IMWUT, JOCCH, PACMPL, POMACS, TAP, PACMHCI
% \documentclass[acmlarge,screen]{acmart}

%%%% Large double column format, used for TOG
% \documentclass[acmtog, authorversion]{acmart}

%%%% Generic manuscript mode, required for submission
%%%% and peer review
% \documentclass[manuscript,screen,review]{acmart}
%% Fonts used in the template cannot be substituted; margin 
% %% adjustments are not allowed.
% %%
% %% \BibTeX command to typeset BibTeX logo in the docs
% \AtBeginDocument{%
%   \providecommand\BibTeX{{%
%     \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

% %% Rights management information.  This information is sent to you
% %% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
% \setcopyright{acmcopyright}
% \copyrightyear{2018}
% \acmYear{2018}
% \acmDOI{XXXXXXX.XXXXXXX}

% %% These commands are for a PROCEEDINGS abstract or paper.
%\acmConference[A Workshop at CHI 2023]{Make sure to enter the correct
%   conference title from your rights confirmation emai}{}
% %
% %  Uncomment \acmBooktitle if th title of the proceedings is different
% %  from ``Proceedings of ...''!
% %
% \acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%  June 03--05, 2018, Woodstock, NY} 
% \acmPrice{15.00}
% \acmISBN{978-1-4503-XXXX-X/18/06}
% \settopmatter{printacmref=false}
% \settopmatter{printacmref=false}
% \setcopyright{none}
% \renewcommand\footnotetextcopyrightpermission[1]{}
% \pagestyle{plain}
% \begin{teaserfigure}
%  \centering
%   \includegraphics[width=\textwidth, height=0.38\textheight]{workshop.png}
%   \caption{ToxVis Interactive System}
%   \Description{Enjoying the baseball game from the third-base
%   seats. Ichiro Suzuki preparing to bat.}
%   \label{fig:teaser}
% \end{teaserfigure}


% \begin{figure}[!h]
%   \centering
%   \includegraphics[width=\textwidth]{test.png}
%   \caption{Caption of the figure.}
%   \label{fig:labelname}
% \end{figure}
%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}
\usepackage{graphicx}
%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{\textcolor{red}{Tox}\textcolor{teal}{Vis}: Enabling Interpretability of Implicit vs. Explicit Toxicity
Detection Models with Interactive Visualization}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.

% \author{Ben Trovato}
% \email{umsush}
% \orcid{1234-5678-9012}
% \author{G.K.M. Tobin}
% \authornotemark[1]
% \email{webmaster@marysville-ohio.com}
% \affiliation{%
%   \institution{Virginia Tech}
% }

\author{Uma Gunturi*}
\affiliation{%
    \authornote{Both authors contributed equally to this research.}
  \institution{Department of Computer Science, Virginia Tech}
  \city{Blacksburg}
  \country{USA}}
\email{umasushmitha@vt.edu}

\author{Xiaohan Ding*}
\affiliation{%
  \institution{Department of Computer Science, Virginia Tech}
  \city{Blacksburg}
  \country{USA}}
\email{xiaohan@vt.edu}

\author{Eugenia H. Rho}
\affiliation{%
  \institution{Department of Computer Science, Virginia Tech}
  \city{Blacksburg}
  \country{USA}}
\email{eugenia@vt.edu}

% \author{Valerie B\'eranger}
% \affiliation{%
%   \institution{Inria Paris-Rocquencourt}
%   \city{Rocquencourt}
%   \country{France}
% }

% \author{Aparna Patel}
% \affiliation{%
%  \institution{Rajiv Gandhi University}
%  \streetaddress{Rono-Hills}
%  \city{Doimukh}
%  \state{Arunachal Pradesh}
%  \country{India}}

% \author{Huifen Chan}
% \affiliation{%
%   \institution{Tsinghua University}
%   \streetaddress{30 Shuangqing Rd}
%   \city{Haidian Qu}
%   \state{Beijing Shi}
%   \country{China}}

% \author{Charles Palmer}
% \affiliation{%
%   \institution{Palmer Research Laboratories}
%   \streetaddress{8600 Datapoint Drive}
%   \city{San Antonio}
%   \state{Texas}
%   \country{USA}
%   \postcode{78229}}
% \email{cpalmer@prl.com}

% \author{John Smith}
% \affiliation{%
%   \institution{The Th{\o}rv{\"a}ld Group}
%   \streetaddress{1 Th{\o}rv{\"a}ld Circle}
%   \city{Hekla}
%   \country{Iceland}}
% \email{jsmith@affiliation.org}

% \author{Julius P. Kumquat}
% \affiliation{%
%   \institution{The Kumquat Consortium}
%   \city{New York}
%   \country{USA}}
% \email{jpkumquat@consortium.net}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
% \renewcommand{\shortauthors}{Anonymous Authors}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
% \begin{abstract}
% With the widespread use of toxic language online, platforms are increasingly using automated systems that leverage advances in natural language processing to automatically flag and remove toxic comments. However, most automated systems—when detecting and moderating toxic language fail to differentiate implicit language from explicit language leading to disproportionate content moderation practices. Moreover, these systems do not provide feedback to their users, let alone provide an avenue of recourse for these users to make actionable changes. We present our work, ToxVis, an interactive, open-sourced web tool for distinguishing and visualizing the the models’ toxic predictions, while providing in-depth understanding of how each token contributes to the model's output.
  
% \end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
% \begin{CCSXML}
% <ccs2012>
%  <concept>
%   <concept_id>10010520.10010553.10010562</concept_id>
%   <concept_desc>Human Centered Computing~Empirical studies in collaborative and social computing</concept_desc>
%   <concept_significance>500</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>10010520.10010575.10010755</concept_id>
%   <concept_desc>Human Centered Computing~computer supported cooperative work</concept_desc>
%   <concept_significance>300</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>10003033.10003083.10003095</concept_id>
%   <concept_desc>Social and professional topics~Race and Ethnicity</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
% </ccs2012>
% \end{CCSXML}
% \ccsdesc[500]{Human Centered Computing~Empirical studies in collaborative and social computing}
% \ccsdesc[300]{Human Centered Computing~computer supported cooperative work}
% \ccsdesc{Social and professional topics~Race and Ethnicity}
% \ccsdesc[100]{Networks~Network reliability}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
% \keywords{natural language processing, NLP, race, racism, microaggressions, discourse, social media}

% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
% Motivation 1: why do we need to distinguish implicit vs. explicit M1: read Diyi's paper

% Implicit goes undetected even though it's toxic - this is false negative.  What is the danger of leaving false negatives online? Garbage that looks harmless, but is polluting the environment Hate speech is prevalent on social media. As a result, most platforms use content moderation systems to ban offensive content and cultivate safe online spaces for users [cite]. While prior efforts focused extensively on identifying overt or explicit hate speech [cite, cite], recent research has begun to draw attention to implicit forms of hate speech, such as microaggressions, which are typically disguised through humor [cite], insider expressions [cite], and neologisms [cite] that frequently go unnoticed by moderators and researchers. 

% The goal of ToxViz is to help users building a common-ground understanding around what is implicitly hateful in a visual manner.; n turn, this can help build common-ground understanding around what is implicitly hateful in a visual manner, thereby this can improve moderation challenges and failures by; By making DL-based hatespeech classification around various degrees of hateful texts \textit{explainable}, we believe can improve moderation challenges and failures by 

 % uma's version In this work, we address these challenges by developing an interactive tool called \textit{ToxVis}. The goal of ToxVis is to leverage state-of-the-art transformers to classify hate speech into three categories (implicitly hateful, explicitly hateful, and non-hateful) within a specific piece of text. Unlike the publicly available, generic off-the-shelf toxicity detectors that merely provide a score without an underlying explanation, in our work, we go beyond just classifying between the two, by leveraging interpretation techniques in deep learning (DL) to explain our classification results. Specifically, we address the lack of interpretive insight, typically associated with large pretrained language models, by using Integrated Gradients \cite{sundararajan_axiomatic_2017} to help contextualize as to which words of a hateful text contribute to the classification decision. 
 \maketitle
 \textcolor{orange}{\textbf{WARNING:}} This paper contains some content which is offensive in nature.
\section{Introduction}
 
 People’s judgment of hateful online content is inherently subjective and multi-faceted as interpretations around what is and is not hateful can depend on personal values, social identities, and culture \cite{nockleby2000hate}. Hence, as opposed to explicit hate-speech or profanity-laden attacks where the offender’s mal intent is expressed in black and white language, it is more challenging to effectively respond to, or mitigate harms caused by \textit{implicit} hatespeech. This is because implicit toxicity often takes form as humour \cite{fortuna2018survey}, insider expressions,  neologisms \cite{cscw-humour}, and microaggressions, \cite{Espaillat2019AnES},  (e.g. "Black people seem to think everything revolves around them being royalty" (from r/unpopularopinion). Hence, human moderators and content moderation systems have difficulty understanding, recognizing, and responding to implicit hatespeech \cite{wright2021recast}, resulting in moderation failures where false negatives (harmful, yet undetected texts) are left unmoderated \cite{10.1145/3479610}. Furthermore, most hate-classification research, including those that examine implicit hatespeech, often use black-box deep learning (DL) models that lack interpretability, failing to explain why a content was classified as hateful. In this work, we aim to address these challenges by developing a visually interactive and explainable tool called \textit{ToxVis} (Fig.1). We built ToxVis by using RoBERTa [cite], XLNET [cite], and GPT-3 [cite] and fine-tuning two transformer-based models to classify hatespeech into three categories of hatespeech: implicit, explicit, and non-hateful. We then used DL interpretation techniques to make the classification results explainable. Through ToxVis, users can \textbf{(1)} type in a potentially hateful text into the system. The system will then \textbf{(2)} classify the input text into one of the three categories of hatespeech (implicit, explicit, or non-hateful). The user can then click on the classification results  \textbf{(3)} to see which words from the input text contributed most to the classification decision, as well as the model's prediction confidence score. Live demo of ToxVis is available \href{https://tinyurl.com/4zybmwkx}{\color{blue}{here}}.

\section{ToxVis Interactive System}
\textbf{Data collection and pre-processing}. We collected existing hate speech datasets from multiple sources: ETHOS  \cite{mollas2020ethos}, AbuseEval \cite{caselli-etal-2020-feel}, and a microaggressions dataset from Tumblr \cite{breitfeller-etal-2019-finding}. The combined corpora had multiple labeling structures (implicit vs. explicit; hate vs. non-hate). Hence, we limited our sample to those that contained explicit, implicit, and non-hate labels. Three researchers then manually verified a randomized sample into three categories: explicit hate, implicit hate, and non-hate. Through this process, we eliminated previously mislabeled instances. We further eliminated instances with urls, and special characters, leaving us with 14,473 posts. 

\hspace{-4mm}\textbf{Training and interpretation}. We fine-tuned transformer-based models (BERT, RoBERTa, XLNET, GPT-3) on our data (train:dev:test split of 33:33:33) for a multi-class classification task (label 1: \textit{explicit hate}, label 2: \textit{implicit hate}, label 3: \textit{non-hate}). We implemented the models using the HuggingFace Transformers \cite{wolf_huggingfaces_2020} and PyTorch libraries \cite{NEURIPS2019_9015}. We then evaluated the fine-tuned models on a held-out test set using standard evaluation metrics (accuracy, precision, recall, and F1). We further improved model performance through hyperparameter tuning with multiple learning rates ($lr = $ 1e-5, 2e-5 or 3e-5), batch sizes ($n_{bs} = $ 16, 32, or 64), and the number of epochs ($n_{epoch} = $ $3$, $4$, or $5$). 
\begin{figure}[h]
\centering
    % width = 0.5 can move this image to page 2
   \includegraphics[width=0.92\textwidth]{workshop.png}
   \caption{The \textit{ToxVis} user interface. The system leverages three different Transformer-based models A. XLNet B. RoBERTa C. OpenAI's GPT-3. For A and B, the system displays  (1) the model's predicted label (explicit, implicit, non-hateful), (2) the contribution of each input word to the predicted label, and (3) the model's confidence score of the predicted label. For C, the system displays (1) the classification label, (2) the prediction confidence score, and (3) the predictive tokens.}
   \label{fig:teaser}
\end{figure}
\vspace{-2mm}
To make the classification results explainable, we used Integrated Gradients (IG) \cite{sundararajan_axiomatic_2017}, a post-hoc model interpretability technique, to investigate the contribution of individual tokens to the classified label. In other words, we wanted to understand how much a given word from the input text contributed to whether the text was classified as 1. explicitly hateful, 2. implicitly hateful, or 3. non-hateful. For this task, we used IG to calculate the gradient of each input token to analyze the attribution score (ranging from -1 to 1) on the final label. Positive attribution scores indicate a given token's positive contribution towards the predicted label, whereas negative attribution values of a given token do not contribute  to the predicted label. 
%By adopting this method, we were able to evaluate the importance of each token in the classification process, thereby advancing the interpretability and transparency of our model.

\begin{table}[!h]
\centering
\caption{Comparison of F1 score, Precision, Recall, and Accuracy among different language models.}
\label{tab:langmodels}
\scalebox{0.8}{
\begin{tabular}{|c|c|c|c|c|}
\hline $\begin{gathered}\text { Model }
\text { Name }\end{gathered}$ & F1 Score & Precision & Recall & Accuracy \\
\hline BERT & $0.750$ & $0.724$ & $0.778$ & $0.755$ \\
\hline RoBERTa & $0.848$ & $0.829$ & $0.869$ & $0.820$ \\
\hline XLNet & $0.804$ & $0.745$ & $0.873$ & $0.791$ \\
\hline $\begin{gathered}\text { GPT-3 } 
\text { (davinci) }\end{gathered}$ & $0.976$ & $0.981$ & $0.971$ & $0.977$ \\
\hline
\end{tabular}}
\end{table}

% \vspace{-1

% \vspace{2mm}
\hspace{-4mm} \textbf{Interactive System}. After completing the training and evaluation processes, we deployed our explainable multi-label classification system on a cloud server utilizing Python Flask. The user-interface design goals of ToxVis (Fig.1) was to empower users by allowing them to interactively compare the classificaiton results of three different linguistic DL classifiers. We also visualized the input tokens by different colors according to their contribution to the output prediction: \textcolor{blue}{blue} indicating negative and \textcolor{teal}{green} indicating positive contribution to the predicted labels. We instructed GPT-3 to identify and list words from the input sentence that contributed most (in descending order of importance) in conveying the harmful aspect of the input sentence. 

% PROMPT that we gave to the model: Generate a list of key terms that are relevant to the understanding of predictive labels. (FYI - as a general rule, the most important words in a sentence are typically the subject and the main verb, as they establish the core idea being conveyed. Other important words may include adjectives and adverbs that provide further description or context. Additionally, conjunctions and prepositions can also be crucial in establishing relationships between different parts of the sentence. Ultimately, the key to identifying the most important words in a sentence is to consider their role in conveying the overall meaning and purpose of the sentence.)

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}



\end{document}
\endinput
%%
%% End of file `sample-authordraft.tex'.
