\section{Analysis on UIT-ViQuAD 2.0}
\input{sections/tables/viquadhard}
\subsection{Overall Performance}
Table \ref{overall-performane} shows the performance of models on the development set of UIT-ViQuAD 2.0 \cite{viquad20}. XLM-RoBERTa outperforms other three models on EM, F1 and Recall\textsubscript{unanswerable} while slightly underperforms PhoBERT on Recall\textsubscript{answerable}.

The development set of UIT-ViQuAD 2.0 was used as the public test for VLSP2021: Machine Reading Comprehension \cite{viquad20}. Based on the results published after the shared task, our fine-tuned mBERT substantially outperforms the mBERT baseline of the organizers. 
\subsection{Performance on Unanswerable Questions}
We then analyze the performances of models on different unanswerable types of unanswerable questions (see Table \ref{tab:categories} in \ref{sec:appendix1} for examples). We closely follow unanswerable question types defined by \citet{viquad20}. However, based on our observation, when using \textit{Entity Swap} for creating unanswerable questions, annotators might unintentionally reverse the relation of entities in the original questions. Therefore, in order to exploit these important questions for revealing language weaknesses of monolingual models, we define \textit{Relation Reverse} as a new unanswerable type for our analysis and analyze it separately from \textit{Entity Swap} type. Results from our analysis (Table \ref{tab:hard-unanswerable-result}) show that questions of \textit{Relation Reverse} type are much more challenging for models than those of \textit{Entity Swap} type.

Results from our analysis successfully reveal some language weaknesses of monolingual models. As reported in Table \ref{tab:hard-unanswerable-result}, the performances of Vietnamese monolingual models on \textit{Entity Swap} and \textit{Relation Reverse} types are significantly lower than those of multilingual models. This result shows us that the ability to represent the relationships between different entities in the context of Vietnamese monolingual models are significantly inferior than multilingual models.

However, monolingual models show strong performances on \textit{Modifiers Swap type} which requires language models to have a good ability in understanding the modified relationships between different words in the sentence. In other words, Vietnamese monolingual models acquire a better ability in low-level lexical and grammatical features of Vietnamese than multilingual counterparts do. We hypothesize that the unusual characteristics of the Vietnamese language  pose significant challenges for multilingual models. If an adjective is used as a noun modifier in Vietnamese, the adjective must go after the main noun instead of before, as in English and many other resource-rich languages.

On the other hand, monolingual and multilingual models show little difference in their performances on unanswerable question types of \textit{Antonym}, \textit{Overstatement \& Understatement}, and \textit{Adverbial Clause Swap}. However, we are concerned that the number of high-quality unanswerable questions of those types in the development set of UIT-ViQuAD 2.0 is not enough to reveal weaknesses of language models in these aspects of language. Therefore, we annotate a new small high-quality benchmark on the corpus of UIT-VinewsQA \citep{van2020new}, which is another high-quality Vietnamese MRC dataset. 
