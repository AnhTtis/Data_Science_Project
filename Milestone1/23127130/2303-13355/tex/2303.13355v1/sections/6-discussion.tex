\section{Future Directions}
Based on the results from our analysis, we suggest several future directions for both Vietnamese monolingual language models and Vietnamese MRC benchmarks.
\subsection{Language Models}
Our analysis shows that monolingual models, especially PhoBERT, acquire comparable abilities in recognizing the differences in lexical information between unanswerable questions and the given context. However, monolingual models show poor performances when encountering unanswerable questions that require the ability to comprehend a bigger ``picture''. For example, while monolingual models perform very well on unanswerable questions that use explicit antonyms, they often have difficulties in recognizing unanswerable questions when these questions are created using implicit antonyms. We explain this phenomenon by the findings of \citet{zhang-etal-2021-need} as pre-training language models on larger text copora results in significant improvement on downstream tasks that require high-level semantic and factual knowledge such as Machine Reading Comprehension. Therefore, when encountering unanswerable questions that require ability to grasp big ``picture,'' models pre-trained with smaller text corpora will show lower performances. Hence, the small size of pre-training corpora of PhoBERT and WikiBERT may be the main reason for their poor performances in MRC.

Scaling the pre-training data size of PhoBERT will further develop this model and empower it to achieve state-of-the-art performances on different benchmarks of Machine Reading Comprehension. Besides, we believe that introducing a new unsupervised task for the pre-training phase that focuses on improving the high-level semantic and factual knowledge of pre-trained models also plays an integral role in developing language models in the future.
\subsection{Benchmarks}
\textbf{Unanswerable Questions. } Although UIT-ViQuAD 2.0 successfully further introduced new types of artificially unanswerable questions, our work in Section 5 shows that current unanswerable questions in the development test of UIT-ViQuAD 2.0 are still not challenging enough. In order to increase the challenging levels of unanswerable questions, we believe that more high-quality works on adversarial human annotation for unanswerable questions are needed. These works can follow the guidelines of adversarial human annotation for answerable questions \cite{bartolo-etal-2020-beat}. Results of these works can reveal different techniques to annotate hard unanswerable questions and therefore be valuable for improving the guidelines for unanswerable questions annotation for Machine Reading Comprehension.\\
\textbf{Quality of Benchmark. } On the other hand, as we have shown in section 5, although PhoBERT and XLM-RoBERTa achieve high performances on the UIT-VinewsQA development set, our unanswerable questions reveal that these two models do not truly understand the context to give the correct answer for questions in the original development set. We hypothesize that questions in UIT-VinewsQA enable machine reading comprehension systems with shortcut learning knowledge \cite{lai-etal-2021-machine} to achieve high performance due to biases in annotating process. Therefore, we believe that studies on how Vietnamese machine reading comprehension systems are currently evaluated are important for tracking the progress of Vietnamese language systems.
