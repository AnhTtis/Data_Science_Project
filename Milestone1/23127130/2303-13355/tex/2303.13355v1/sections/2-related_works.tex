\section{Related Work}
\textbf{Unanswerable Questions. } Unanswerable questions in MRC draw much attention from the research community after the publication of SQuAD 2.0 \cite{rajpurkar-etal-2018-know}. Following the guidelines proposed by \citet{rajpurkar-etal-2018-know}, unanswerable questions in MRC are introduced in MRC of other languages such as French in FQuAD 2.0 \cite{fquad20} and Vietnamese in UIT-ViQuAD 2.0 \cite{viquad20}. The research community commonly refers to unanswerable questions in SQuAD, FQuAD, and UIT-ViQuAD as "artificial unanswerable questions" because annotators are instructed to intentionally create questions that cannot be answered using the information provided in the given context. On the other hand, unanswerable questions that naturally arise are also introduced recently in Natural Questions \cite{kwiatkowski-etal-2019-natural} and TyDi QA \cite{clark-etal-2020-tydi}, in which the evidence documents are provided after the questions are written by annotators.\\
\textbf{Multilingual versus Monolingual Models. } \citet{vulic-etal-2020-probing} probe an empirical analysis on monolingual BERTs and mBERT across six languages and five different lexical tasks. They show that Monolingual BERT encodes significantly more lexical information than mBERT.

Besides, \citet{rust-etal-2021-good} compare pre-trained multilingual language models with monolingual counterparts regarding their monolingual task performances in nine languages and five tasks to reveal the reason for the gap between the performances of monolingual models and multilingual models. This comprehensive analysis later reveals that while pre-training data size played a vital role in the performances of language models on downstream tasks, the monolingual tokenizers designed by native speakers are also an important reason for the high performances of monolingual models in single-language settings. Results from this analysis show that \citet{nguyen-tuan-nguyen-2020-phobert} significantly contributed to the development of Vietnamese language models with a high-quality tokenizer that is suitable for the unique linguistic features of Vietnamese.
\input{sections/tables/viquadperform}