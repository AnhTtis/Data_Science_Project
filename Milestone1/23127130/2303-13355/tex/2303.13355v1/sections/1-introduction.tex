\section{Introduction}
\textbf{Pretraining models} Language models that are designed based on the architecture of Transformers are often pre-trained on enormous amount of text data. These models when fine-tuned on many downstream tasks acquires superhuman performances.

\textbf{Multilingual models} mBERT is published together with BERT. Conneau later prove that mBERT was underpretrained as multilingual models require more text data than monolingual models in English. XLM-RoBERTa is introduced as a new state-of-the-art multilingual model and empowers Natural Language Processing in many low-resource languages to develop.\\
\textbf{Monolingual models} Follow the success of BERT and RoBERTa in English, researchers from all over the world start to develop monolingual BERT in many other languages such as French, German, Korean, Vietnamese, etc.

Recent works in Machine Reading Comprehension (MRC) show that monolingual models in different languages can achieve higher performances in extractive question answering than multilingual models. For example, the state-of-the-art multilingual models XLM-RobERTa \cite{conneau-etal-2020-unsupervised} underperforms CamemBERT \cite{martin-etal-2020-camembert} and GELECTRA \cite{chan-etal-2020-germans} on FQuAD \cite{dhoffschmidt-etal-2020-fquad,fquad20} and GermanQuAD \cite{moller-etal-2021-germanquad}, respectively. The limitations in performance of multilingual models are explained by the curse of multilinguality as Conneau et al. \shortcite{conneau-etal-2020-unsupervised} discovered that pre-training a multilingual model with fixed capacity on an increasing number of languages only improves its performances up to a certain point.

Multilingual models also underperform monolingual models in several tasks in Vietnamese Natural Language Processing, such as Part-of-speech tagging, Name-entity recognition, Dependency parsing and Natural language Inference \cite{nguyen-tuan-nguyen-2020-phobert}. However, in a recent shared task in Vietnamese Machine Reading Comprehension, five highest-ranked teams all use XLM-RoBERTa \cite{conneau-etal-2020-unsupervised} as the core of their systems. Besides, the experiments on fine-tuned models also show that XLM-RoBERTa substantially outperforms monolingual counterparts on UIT-ViQuAD 2.0 \cite{viquad20}, the dataset used for the shared task. These results, together with the limited number of works on Vietnamese monolingual models, suggest that more high-quality research into Vietnamese monolingual models are urgently needed. Therefore, in order to suggest new directions for these future works, we attempt to reveal the language weaknesses of monolingual models through analyzing performances of monolingual models in comparison with those of multilingual ones. Thanks to the diversity of unanswerable types in UIT-ViQuAD 2.0, we can analyze performances of models on unanswerable questions in this dataset to obtain insights into effects that different linguistic aspects have on performances of models.

Nguyen et al. \shortcite{viquad20} introduced a new annotating process for unanswerable questions in extractive question answering, which successfully empowers annotators to focus on linguistic aspects while creating unanswerable questions. As a result, many unanswerable types were introduced to the research community. For example, besides using antonym to create an unanswerable question, annotators also use technique of overstatement and understatement, which slightly change the meanings of the corresponding word in the original question. This type of unanswerable questions challenges language models on aspects of recognizing the small difference in the meaning of Vietnamese words.
% Recent works on multilingual NLP have discovered limitations of multilingual models. Conneau et al. \shortcite{conneau-etal-2020-unsupervised} show that pre-training a multilingual model with fixed capacity on an increasing amount of languages only improves its performance up to a certain point, which is referred as the curse of multilinguality. Due to this limitation, the performance of current state-of-the-art multilingual model XLM-RoBERTa underperforms monolingual models of French and German on FQuAD \cite{unknown} and GermanQuAD \cite{moller-etal-2021-germanquad}. This phenomenon also existed in Vietnamese NLP for tasks of Part-of-speech tagging, Dependency parsing, Named-entity recognition and Natural language inference \cite{nguyen-tuan-nguyen-2020-phobert}. However, on a new benchmark introduced recently in a shared task for Vietnamese Machine Reading Comprehension, multilingual models significantly outperforms  Vietnamese monolingual models \textbf{cite}. Therefore, in order to suggest new directions for future works on Vietnamese monolingual models, in this work, we will analyze performances of monolingual models in comparison with performances of multilingual models to reveal the language weaknesses of monolingual models. To obtain insights into effects that different linguistic aspects have on models, we study performances of models on unanswerable questions in UIT-ViQuAD 2.0 because this dataset greatly facilitates our analysis as Nguyen et al. (2021) introduced new annotating pipeline for unanswerable questions in extractive questions answering, which successfully empower annotators to focus on linguistic aspects in creating unanswerable questions. As a result, many unanswerable types were introduced. For example, instead of just using antonym to create unanswerable questions, annotators for UIT-ViQuAD 2.0 also use overstatement and understatement, which just overstate or understate a word in the original question to create an unanswerable question. This type of unanswerable questions challenges language models on aspects of recognizing the small difference in the meaning of Vietnamese words.\\
In this work, we first analyze performances of monolingual and multilingual models on UIT-ViQuAD 2.0 development set. However, we are then concerned that the development set of UIT-ViQuAD 2.0 is not challenging enough to reveal language weaknesses of models on certain aspects. Therefore, we annotate a new set of high-quality unanswerable questions on an out-of-domain corpus to further analyze language abilities of monolingual and multilingual models.

Our contributions are summed as follows:
\begin{enumerate}
    \item Our work successfully discovers different language weaknesses and strengths of Vietnamese monolingual models. Results from our work provides good directions for future works on more robust Vietnamese monolingual models.
    \item To more accurately assess language abilities of models, we propose a new method for annotating high-quality unanswerable questions that successfully further challenges current systems in MRC. 
    \item Results from our analysis reveal that new high-quality benchmarks in Vietnamese Machine Reading Comprehension are urgently needed.
\end{enumerate}
