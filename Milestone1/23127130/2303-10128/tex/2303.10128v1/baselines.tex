In our statistical setting, the null hypothesis states that compression (minimization of word lengths) has no effect on word lengths. The alternative hypothesis states that compression has an effect on word lengths as Zipf hypothesized. If the null hypothesis is rejected then word lengths are shorter than expected by chance. 

\begin{table}[ht]
  \caption{\label{tab:example} Matrix indicating the frequency and length of three types. The mean type length is $L = \frac{235}{125}=1.88$. } 
  
  \begin{center} 
  \begin{tabular}{lll}
      &       &       \\ 
  $i$ & $f_i$ & $l_i$ \\ 
  \hline 
  1   &  100  & 2  \\         
  2   &  20   & 1  \\
  3   &  5    & 3
  \end{tabular}
  \end{center}
\end{table}


Consider a matrix with two columns, $f_i$ and $l_i$, that are used to compute the average word length $L$. The matrix in \autoref{tab:example} gives $L = \frac{235}{125} = 1.88$. 
We consider the null hypothesis of a random mapping of probabilities into lengths, namely that the ordering of the $f_i$'s or the $l_i$'s in \autoref{tab:example} is arbitrary and results from a random shuffling of one of these variables or both. We use $f_i'$, $l_i'$ and
$p_i'$ for the new values of $f_i$, $l_i$ and $p_i$ that result from one of these shufflings. 

This null hypothesis was introduced in research on compression in human language and animal communication to test if $L$ is significantly small using a permutation test \parencite{Ferrer2012d,Heesen2019a}. Later, it was used to estimate the degree of optimality of word lengths \parencite{Moreno2021a,Pimentel2021a}. Our new contribution here is a precise mathematical characterization of the null hypothesis and the derivation of a simple formula the expected word length. 

In the context of computing average word length, the matrix in \autoref{tab:example} is equivalent to a matrix where the column $f_i$ is replaced by a column with $p_i$ thanks to 
$$p_i' = \frac{f_i'}{T}.$$ 
Indeed, the null hypothesis has three variants 
\begin{enumerate}
    \item 
    Single column shuffling. Only the column of $f_i$ or $p_i$ is shuffled. 
    \item
    Single column shuffling. Only the column of $l_i$ is shuffled. 
    \item
    Dual column shuffling. The column of $f_i$ or $p_i$ and the column of $l_i$ are both shuffled. 
\end{enumerate}
In each of the variants, all random shufflings of a specific column are equally likely. In case of dual shuffling, the shuffling of one column is independent of the shuffling of the other column. 
The outcome of a dual shuffling on \autoref{tab:example} is shown in \autoref{tab:example_shuffling}. 


\begin{table}[ht]
  \caption{\label{tab:example_shuffling} Matrix indicating the frequency and length of three types. The mean type length is $L = \frac{345}{125}=2.76$. } 
  
  \begin{center} 
  \begin{tabular}{lll}
      &       &       \\ 
  $i$ & $f_i'$ & $l_i'$ \\ 
  \hline 
  1   &  20    & 2  \\         
  2   &  100   & 3  \\
  3   &  5     & 1
  \end{tabular}
  \end{center}
\end{table}

The random baseline, $L_r$, is the expected value of $L$ under the null hypothesis  \footnote{Notice that $L$ is indeed the expected value of the length of a token but under a distinct setting (a distinct null hypothesis), where one picks a token uniformly at random over all tokens of a text and looks at its length. }.
$L_r$ can be defined in more detail in two main equivalent ways:
\begin{enumerate}
    \item
    The value of $L$ that is expected if $L$ is recomputed after pairing the $f_i$'s and the $l_i$'s at random and recomputing $L$. The new value of $L$ depends on the variant of the null hypothesis. When shuffling the column for $f_i$ in the matrix (\autoref{tab:example}), the new $L$ is 
    \begin{equation*}
    L'= \frac{1}{T} \sum_{i = 1}^n f_i' l_i.
    \end{equation*}    
    When shuffling the column for $l_i$  and recomputing $L$, the new $L$ is 
    \begin{equation*}
    L' = \frac{1}{T} \sum_{i = 1}^n f_i l_i'.
    \end{equation*}        
    When shuffling both columns, the new $L$ is 
    \begin{equation*}
    L' = \frac{1}{T} \sum_{i = 1}^n f_i' l_i'.
    \end{equation*}
    \item 
    The average value of $L$ that is expected over all possible shufflings in one of the variants of the null hypothesis. 
    In the example in \autoref{tab:all_mappings}, on shuffling only the $l_i$ column, 
$$ L_r = \frac{\frac{155}{125} + \frac{170}{125} + \frac{235}{125} + \frac{265}{125} + \frac{330}{125} + \frac{345}{125}}{6} = \frac{155 + 170 + 235 + 265 + 330 + 345}{125 \cdot 6} = 2.$$
\end{enumerate}
We use $\expect[X]$ to refer to the expected value of a random variable $X$ under some variant of the null hypothesis above. Then $$L_r = \expect[L'],$$
where $L'$ is the value of $L$ resulting from some shuffling.

In quantitative linguistics, the mean length of tokens ($L$) is also known as dynamic word length \parencite{Chen2015a} and corresponds to the mean length of the words in a text. The mean length of types ($M$), defined as
$$M = \frac{1}{n} \sum_{i=1}^n l_i,$$
is also known as the static word length and corresponds to average length of the headwords in a dictionary \parencite{Chen2015a}.
Interestingly, the following property states that $L_r$ turns out to be $M$ independently of the variant of the null hypothesis under consideration.

\begin{property}
The expected value of $L'$ under any variant of the null hypothesis is $L_r = M$.
\label{prop:random_baseline}
\end{property}
\begin{proof}
We analyze $\expect[L']$ under each of the variants of the null hypothesis. 

{\em Dual shuffling.} Applying the linearity of expectation and independence between the shuffling of the  $p_i$ column of the that of the $l_i$ column, we obtain
\begin{eqnarray*}
\expect[L'_1] & = & \expect\left[\sum_{i=1}^n p_i' l_i' \right] \\
           & = & \sum_{i=1}^n \expect[p_i' l_i'] \\
           & = & \sum_{i=1}^n \expect[p_i'] \expect [l_i'].      
\end{eqnarray*}
Noting that
\begin{eqnarray*}
\expect[p_i'] & = & \frac{1}{n} \sum_{i=1}^n p_i = \frac{1}{n} \\
\expect[l_i'] & = & \frac{1}{n} \sum_{i=1}^m l_i = M,
\end{eqnarray*}
we finally obtain
\begin{equation}
\expect[L'] = \sum_{i=1}^n \frac{M}{n} = M.
\end{equation}

{\em Single shuffling of the $l_i$ column}. 
Applying the linearity of expectation and the fact that the column of $p_i$ remains constant, we obtain
\begin{eqnarray*}
\expect[L'_1] & = & \expect\left[\sum_{i=1}^n p_i l_i' \right] \\
           & = & \sum_{i=1}^n p_i \expect[l_i']. 
\end{eqnarray*}
Recalling $\expect[l_i'] = M$,
we finally obtain
\begin{equation}
\expect[L'] = M \sum_{i=1}^n p_i = M.
\end{equation}



{\em Single shuffling of the $p_i$ column}.  
Applying the linearity of expectation and the fact that the column of $l_i$ remains constant, we obtain
\begin{eqnarray*}
\expect[L'_1] & = & \expect\left[\sum_{i=1}^n p_i' l_i \right] \\
           & = & \sum_{i=1}^n \expect[p_i'] l_i. 
\end{eqnarray*}
Recalling $\expect[p_i'] = \frac{1}{n}$,
we finally obtain
\begin{equation}
\expect[L'] = \frac{1}{n} \sum_{i=1}^n l_i =  M.
\end{equation}

\end{proof}
The previous finding indicates that the random baseline for $L$ is equivalent to assuming that all word types are equally likely, namely, replacing each $p_i$ by $1/n$.

\begin{table}
  \caption{\label{tab:all_mappings} All the $3! = 6$ permutations of the column $l_i$ in \protect \autoref{tab:example} that can be produced. Each permutation is indicated with letters from A to F. 
  % A is the one minimizing $L$.
  $L'$, the mean length of types in a shuffling, is shown at the bottom for each permutation. } 
  
  \begin{center} 
  \begin{tabular}{llllllll}
      &       & A     & B     & C     & D     & E     & F    \\
  $i$ & $f_i$ & $l_i'$ & $l_i'$ & $l_i'$ & $l_i'$ & $l_i'$ & $l_i'$\\
  \hline 
  1   &  100  & 1     & 1     & 2     & 2     & 3     & 3    \\         
  2   &  20   & 2     & 3     & 1     & 3     & 1     & 2    \\
  3   &  5    & 3     & 2     & 3     & 1     & 2     & 1    \\
  \hline  
  \\
      &  $L'$  & $\frac{155}{125}=1.24$   & $\frac{170}{125}=1.36$   & $\frac{235}{125}=1.88$   & $\frac{265}{125}=2.12$   & $\frac{330}{125}=2.64$   & $\frac{345}{125}=2.76$  \\ 
  \end{tabular}
  \end{center}
\end{table}
