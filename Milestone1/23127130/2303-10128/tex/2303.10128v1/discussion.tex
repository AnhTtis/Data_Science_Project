\subsection{The universality of Zipf's law}

The first step of our analysis consisted in checking the universality of the law of abbreviation in the languages of our samples through a Kendall $\tau$ correlation test. Here, we introduced two methodological improvements with respect to previous research: using the Bonferroni-Holm correction for $p$-values, as well as word length in time given spoken utterances, rather than just characters in written form \parencite{Bentz2016a}. We also computed Pearson correlations for two reasons: (a) to verify the robustness of the conclusions and (b) to check the significance of the gap between $L$ and $L_r$ ((b) is addressed in the next subsection). We find that the law of abbreviation holds in nearly all languages in our sample at a 95\% confidence level, independently from how word length is measured, and even after controlling for multiple testing. The only exception is Panjabi in CV, but only when length is measured in duration and Pearson $r$ correlation is used. Panjabi is also the language suffering most from under-sampling (only 98 tokens). 
Therefore, Panjabi cannot be considered a true exception to the law of abbreviation. 

Given the rather scarce evidence of the law of abbreviation in word durations in human language \parencite{Torre2019a}, we have taken step forward by providing evidence of it in 46 languages from 14 linguistic families. The massive agreement of the law of abbreviation even when orthographic word lengths are replaced by word durations in human languages provides stronger support for the law of abbreviation as a potentially universal pattern of human languages with respect to previous research relying on word length in characters \parencite{Bentz2016a} and often on a small number of linguistic families \parencite{Piantadosi2011a,Levshina2022a,Meylan2021a, Koplenig2022a}.


%Overall, these analyses indicate that the strength of the law is remarkable.
%In almost every language and collection, the negative relation is significant at a 99\% confidence level (\autoref{fig:corr_significance}). Concerning Kendall $\tau$ (\autoref{fig:corr_significance} (a,b)) the only exceptions, significant at a 95\% confidence level, are found in CV: Dhivehi when length is measured in characters, and Abkhazian, Dhivehi, Panjabi, and Vietnamese when length is measured in duration. Concerning Pearson correlation (\autoref{fig:corr_significance} (c,d)), with respect to Kendall correlation there are some losses and gains in significance. The languages losing significance are Panjabi, which ceases to be significant at a 95\% confidence level in CV (duration), and Chinese as measured in strokes in PUD, which becomes significant at a 95\% confidence level. On the other hand, in CV (characters) Dhivehi becomes now significant at a 99\% confidence level.
%Thus, the only language in which we could not robustly detect the presence of the law of abbreviation is Panjabi, the language most suffering from under-sampling. Indeed the sample size clearly plays a crucial role, as the languages consistently showing a lower significance are those with the smallest samples. 

\subsection{Direct evidence of compression}

We have found that word lengths are shorter than expected by chance ($L < L_r$) in all languages in every collection (\autoref{fig:mean_word_length_versus_random_baseline}). Such a systematic finding is unlikely to be accidental and strongly indicates that compression is acting in all languages in our sample. Crucially, the finding holds independently of how word length is measured.
The ample evidence of compression even when orthographic word lengths are replaced by word durations in human languages provides stronger support for compression as a universal principle of the organization of languages with respect to previous research relying on word length in characters \parencite{Ferrer2012d}. 


It could be argued that these findings constitute evidence of compression in ensembles of language but not in individual languages. The reason is that $L < L_r$ does not imply that the difference between the actual word length and the random baseline is statistically significant for a single language. However, we have shown that the Pearson correlation is indeed a linear function of $L$ and $L_r$ (Appendix \ref{app:theory}) and thus $L$ is significantly small in every language where the law of abbreviation has been confirmed using a Pearson correlation test. 

% To our knowledge, $L_r$ has never been computed with the compact formula for $M$ above. However, previous research on word length in Chinese characters, shows that $M < L$ over two millennia \parencite[Fig. 4]{Chen2015a}, which can be reinterpreted as a sign of compression of word lengths in Chinese in light of our theoretical findings. 

Finally, the direct correspondence we have established between the average length of types ($M$) and the random baseline sheds new light on previous research. For instance, it has been shown that $M < L$ in Chinese characters in six time periods spanning two millennia \parencite[Fig. 4]{Chen2015a}, which now can be reinterpreted as a sign of compression of word lengths in Chinese in light of our theoretical findings. 

\subsection*{Future research}

In this article, we have introduced a new random baseline and unveiled a systematic gap between that random baseline and real mean word lengths that we have interpreted as direct evidence of compression. \autoref{fig:mean_word_length_versus_random_baseline} suggests that the gap is wider when word lengths are measured in duration rather than in characters. 
However, we have not quantified the magnitude of that gap and we have neither taken into consideration the gap between actual mean words lengths and the minimum baseline, that would be defined as the minimum word length that could be achieved under certain constraints \parencite{Cover2006a, Ferrer2019c, Pimentel2021a}. Future research should quantify the first gap in relation to the minimum baseline. As the random baseline is crucial to asses the degree of optimality of word lengths, we have paved the way for exploring the degree of optimality of word lengths in characters or duration in languages.
