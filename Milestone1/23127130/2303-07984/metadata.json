{
    "arxiv_id": "2303.07984",
    "paper_title": "Asymptotically Sharp Upper Bound for the Column Subset Selection Problem",
    "authors": [
        "Jian-Feng Cai",
        "Zhiqiang Xu",
        "Zili Xu"
    ],
    "submission_date": "2023-03-14",
    "revised_dates": [
        "2023-03-15"
    ],
    "latest_version": 1,
    "categories": [
        "cs.DS",
        "math.FA"
    ],
    "abstract": "This paper investigates the spectral norm version of the column subset selection problem. Given a matrix $\\mathbf{A}\\in\\mathbb{R}^{n\\times d}$ and a positive integer $k\\leq\\text{rank}(\\mathbf{A})$, the objective is to select exactly $k$ columns of $\\mathbf{A}$ that minimize the spectral norm of the residual matrix after projecting $\\mathbf{A}$ onto the space spanned by the selected columns. We use the method of interlacing polynomials introduced by Marcus-Spielman-Srivastava to derive an asymptotically sharp upper bound on the minimal approximation error, and propose a deterministic polynomial-time algorithm that achieves this error bound (up to a computational error). Furthermore, we extend our result to a column partition problem in which the columns of $\\mathbf{A}$ can be partitioned into $r\\geq 2$ subsets such that $\\mathbf{A}$ can be well approximated by subsets from various groups. We show that the machinery of interlacing polynomials also works in this context, and establish a connection between the relevant expected characteristic polynomials and the $r$-characteristic polynomials introduced by Ravichandran and Leake. As a consequence, we prove that the columns of a rank-$d$ matrix $\\mathbf{A}\\in\\mathbb{R}^{n\\times d}$ can be partitioned into $r$ subsets $S_1,\\ldots S_r$, such that the column space of $\\mathbf{A}$ can be well approximated by the span of the columns in the complement of $S_i$ for each $1\\leq i\\leq r$.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.07984v1"
    ],
    "publication_venue": null
}