
\section{Discussion} \label{section:discussion}

Our results show that the failure to realize high fidelity quantum communication is a result from short memory lifetime. 
It is generally not a good strategy to simply increase the number of hops along the path to increase the end-to-end Bell pair production rate as it unavoidably induces more errors in the system due to imperfections of the applied operations.
A lower number of quantum repeaters also leads to the decoherence of qubits due to increased waiting times during which quantum memories are locked.

Our proposed solution is to use a hybrid approach.
\cref{fig:fidelity} shows that in order to deliver high fidelity Bell pairs to the application, it is desirable to distribute physical Bell pairs with 0G between end nodes followed by purification to increase their fidelity, before finally encoding them as logical Bell pairs.
% As the Bell pairs can be generated beforehand and consumed by the application on demand, the key idea of delivering long live high fidelity, as \cref{fig:fidelity} suggests, is to distribute physical Bell pairs directly with 0G to the end nodes, then use purification to increase the fidelity of a physical Bell pair to be encoded as a logical Bell pair.
End-to-end Bell pairs can be generated by the quantum network in advance and then consumed on demand by the application.
Using purification and QEC helps preserve the fidelity of the end-to-end Bell pair until it is needed by the application.
Compared to [\textbf{E2E-1G}], using a pure strategy in a 1G or 2G network is not sufficient to suppress errors in the system.

It would be interesting to consider [\textbf{0G}] to distribute Bell pairs for encoding at the destination nodes, or other purification schemes \cite{fujii2009entanglement, dur2007epa}.
As our memory error model is quite simple, more advanced models might reveal other interesting behavior of the network.