
\section{Related Work}

\paragraph{Image generation}
has long been dominated by GANs which are still state-of-art on many datasets~\cite{karras2020training, karras2019style, karras2020analyzing, sauer2022stylegan, walton2022stylenat}.
Transformers have also been used successfully to model image~\cite{ramesh2021zero, ding2021cogview} or video~\cite{singer2022makeavideo} distributions, allowing higher diversity at the cost of increased inference time. 
Images are typically converted to a list of tokens with vector-quantized architectures~\cite{esser2021taming, razavi2019generating, yu2021vector}. 
These generative models rely on an image decoder at the end, making Stable Signature directly applicable to such methods.

Diffusion models~\cite{dhariwal2021diffusion, ho2020denoising, nichol2021improved, song2020denoising} have brought huge improvements in text-conditional image generation, 
being now able to synthesize high-resolution photo-realistic images for a wide variety of text prompts~\cite{balaji2022ediffi, ho2022imagenvideo, ramesh2022hierarchical, rombach2022high, saharia2022photorealistic}. 
They can also perform conditional image generation tasks -- like inpainting or text-guided image editing -- by fine-tuning the diffusion model with additional conditioning, \eg masked input image, segmentation map, etc.~\cite{lugmayr2022repaint, saharia2022palette}. 
Because of their iterative denoising algorithm, diffusion models can also be adapted for image editing in a zero-shot fashion by guiding the generative process~\cite{couairon2022diffedit, hertz2022prompt, kawar2022imagic, mokady2022null, valevski2022unitune,  wu2022unifying}.
All these methods, when applied on top of Stable Diffusion, operate in the latent space of images, requiring a latent decoder to produce an RGB image. 

\paragraph{Detection of AI-generated/manipulated images}
is notably active in the context of deep-fakes~\cite{guarnera2020deepfake, zhao2021multi}. 
Many works focus on the detection of GAN-generated images~\cite{chai2020makes, gragnaniello2021gan, wang2020cnn, zhang2019detecting}.
One way is to detect inconsistencies in the generated images, via lights, perspective or physical objects~\cite{farid2022lighting, farid2022perspective, li2018exposing, ma2022totems, wang2019detecting}. 
These approaches are restricted to photo-realistic images or faces but do not cover artworks where objects are not necessarily physically correct.

Other approaches use traces left by the generators in the spatial~\cite{marra2019gans, yu2019attributing} or frequency~\cite{frank2020leveraging, zhang2019detecting} domains.
They have extended to diffusion models in recent works~\cite{corvi2022detection, sha2022fake}, and showed encouraging results.
However purely relying on forensics and passive detection is limiting. 
As an example, the best performing method to our knowledge~\cite{corvi2022detection} is able to detect $50\%$ of generated images for an FPR around $1$/$100$.
Put differently, if a user-generated content platform were to receive $1$ billion images every day, it would need to wrongly flag $10$ million images to detect only half of the generated images.
Besides, passive techniques cannot trace images from different versions of the same model, conversely to active ones like watermarking.

\vspace*{-0.3cm}
\paragraph{Image watermarking} 
has long been studied in the context of tracing and intellectual property protection~\cite{cox2007digital}.
More recently, deep learning encoder/extractor alternatives like HiDDeN~\cite{ahmadi2020redmark, lee2020resolution, luo2020distortion, zhang2020udh, zhu2018hidden} or iterative methods by Vukoti\'c~\etal~\cite{fernandez2022sslwatermarking,kishore2021fixed, vukotic2018deep} showed competitive results in terms of robustness to a wide range of transformations, namely geometric ones.

In the specific case of \textbf{generative models}, some works deal with watemarking the training set on which the generative model is learned~\cite{yu2021artificial}.
It is highly inefficient since every new message to be embedded requires a new training pipeline.
Merging the watermarking and the generative process is a recent idea~\cite{lin2022cycleganwm, wu2020watermarking, yu2022responsible, zhang2020model}, that is closer to the model watermarking litterature~\cite{uchida2017embedding}.
They suffer from two strong limitations.
First, these methods only apply to GAN, while LDM are beginning to replace them in most applications. 
Second, watermarking is incorporated in the training process of the GAN from the start. 
This strategy is very risky because the generative model training is more and more costly\footnote{Stable Diffusion training costs $\sim$\$600k of cloud compute (\href{https://en.wikipedia.org/wiki/Stable_Diffusion}{Wikipedia}).}.
Our work shows that a quick fine-tuning of the latent decoder part of the generative model is enough to achieve a good watermarking performance, provided that the watermark extractor is well chosen.







