
\section{Conclusion \& Discussion}\label{sec:conclusion}

By a quick fine-tuning of the decoder of Latent Diffusion Models, we can embed watermarks in all the images they generate.
This does not alter the diffusion process, making it compatible with most of LDM-based generative models.
These watermarks are robust, invisible to the human eye and can be employed to \emph{detect} generated images and \emph{identify} the user that generated it, with very high performance.

The public release of image generative models already has an important societal impact.
With this work, we put to light the usefulness of using watermarking instead of relying on passive detection methods.
We hope it will encourage researchers and practitioners to employ similar approaches before making their models publicly available.

\section*{Ethical Statement}

\subsection*{Societal Impact}

The public release of image generative models already has an important societal impact.
There is a risk of misuse of these models, when employed to (1) generate fake content presented as real (2) generate small variations of copyrighted images and sell them as originals. 
However, this work makes it possible for researchers and practitioners to distribute their models and at the same time to trace back images to the model that generated them.
Therefore, it can be seen as a mitigation for the societal risks posed by image generation.

Watermarking in general improves the traceability of content. 
This traceability can have negative consequences, for example when it is used to trace  political opponents in authoritarian regimes or whistleblowers in secretive companies. 
We believe that this risk is mitigated in our use case since generated images do not have much political content in general. 

\subsection*{Environmental Impact}
We do not expect any environmental impact specific from this work.
The cost of the experiments and the method is high, though order of magnitudes less than other computer vision fields. 
We roughly estimated that the total GPU-days used for running all our experiments to $2000$, or $\approx 50000$ GPU-hours.
This amounts to total emissions in the order of 10 tons of CO$_2$eq.
This is excluding the training of the generative model itself, since we did not perform that training. 
Estimations are conducted using the \href{https://mlco2.github.io/impact#compute}{Machine Learning Impact calculator} presented by Lacoste~\etal\cite{lacoste2019quantifying}.
We do not consider in this approximation: memory storage, CPU-hours, production cost of GPUs/ CPUs, etc. 


\section*{Reproducibility Statement}

The code to reproduce the experiments will be open-sourced. 
Although the diffusion-based generative model has been trained on proprietary data, we use the KL auto-encoder from LDM~\cite{rombach2022ldm} with compression factor $f=8$.
This is the same one that is used in open-source alternatives.












