\twocolumn[{%
 \noindent
 \LARGE Supplementary Material\\[0.5em]
 \large The Stable Signature: Rooting Watermarks in Latent Diffusion Models\\[1em]
}]


\section{Implementation Details \& Parameters}\label{app:implementation-details}

\subsection{Details on the watermark encoder/extractor}\label{app:hidden}

\paragraph*{Architectures of the watermark encoder/extractor.}\label{app:archi-hidden}
We keep the same architecture as in HiDDeN~\cite{zhu2018hidden}, which is a simple convolutional encoder and extractor.
The encoder consist of $4$ Conv-BN-ReLU blocks, with $64$ output filters, $3\times 3$ kernels, stride $1$ and padding $1$.
The extractor has $7$ blocks, followed by a block with $k$ output filters ($k$ being the number of bits to hide), an average pooling layer, and a $k\times k$ linear layer.
For more details, we refer the reader to the original paper~\cite{zhu2018hidden}.

\paragraph{Optimization.}
We train on the MS-COCO dataset~\cite{lin2014microsoft}, with $256 \times 256$ images.
The number of bits is $k=48$, and the scaling factor is $\alpha=0.3$.
The optimization is carried out for $300$ epochs on $8$ GPUs, with the Lamb optimizer~\cite{you2019lamb} (it takes around a day). 
The learning rate follows a cosine annealing schedule with $5$ epochs of linear warmup to $10^{-2}$, and decays to $10^{-6}$.
The batch size per GPU is $64$.

\paragraph*{Attack simulation layer.}\label{app:hidden-attack}
The attack layer produces edited versions of the watermarked image to improve robustness to image processing.
It takes as input the image output by the watermark encoder $x_w = \mathcal{W}_E(x_o)$ and outputs a new image $x'$ that is fed to the decoder $\mathcal{W}$.
This layer is made of cropping, resizing, or identity chosen at random in our experiments, unless otherwise stated.
The parameter for the crop or resize is set to $0.3$ or $0.7$ with equal probability.
This is followed by a JPEG compression with probability $0.5$.
The parameter for the compression is set to $50$ or $80$ with equal probability.
This last layer is not differentiable, therefore we back-propagate only through the difference between the uncompressed and compressed images:
$x'= x_{\mathrm{aug}} + \mathrm{nograd}(x_{\mathrm{aug}, \mathrm{JPEG}} - x_{\mathrm{aug}})$~\cite{zhang2021asl}.

\paragraph*{Whitening.}\label{app:hidden-centering}
At the end of the training, we whiten the output of the watermark extractor to make the hard thresholded bits independently and identically Bernoulli distributed on vanilla images (so that the assumption of~\ref{subsec:statistical-test} holds better, see App.~\ref{app:assumption}).
We perform the PCA of the output of the watermark extractor on a set of $10$k vanilla images, and get the mean $\mu$ and eigendecomposition of the covariance matrix $\Sigma= U\Lambda U^T$. 
The whitening is applied with a linear layer with bias $-\Lambda^{-1/2}U^T\mu$ and weight $\Lambda^{-1/2}U^T$, appended to the extractor. 


\begin{figure*}
    \centering
    \resizebox{0.85\linewidth}{!}{
    \begin{tabular}{*{5}{l}}
        Crop 0.1 & JPEG 50 & Resize 0.7 & Brightness 2.0 & Contrast 2.0 \\ 
        \begin{minipage}{.16\linewidth}\centering \includegraphics[width=0.3\linewidth]{figs/transformations/002_crop_01.jpg}\end{minipage} &  
        \begin{minipage}{.16\linewidth}\includegraphics[width=\linewidth]{figs/transformations/002_jpeg_50.jpg}\end{minipage} &  
        \begin{minipage}{.16\linewidth}\centering\includegraphics[width=0.8\linewidth]{figs/transformations/002_resize_07.jpg}\end{minipage} &  
        \begin{minipage}{.16\linewidth}\includegraphics[width=\linewidth]{figs/transformations/002_brightness_2.jpg}\end{minipage} &
        \begin{minipage}{.16\linewidth}\includegraphics[width=\linewidth]{figs/transformations/002_contrast_2.jpg}\end{minipage} 
        \\ \\
        Saturation 2.0 & Sharpness 2.0 & Rotation $90$ & Text overlay & Combined \\
        \begin{minipage}{.16\linewidth}\includegraphics[width=\linewidth]{figs/transformations/002_saturation_2.jpg}\end{minipage} &  
        \begin{minipage}{.16\linewidth}\includegraphics[width=\linewidth]{figs/transformations/002_sharpness_2.jpg}\end{minipage} &  
        \begin{minipage}{.16\linewidth}\includegraphics[width=\linewidth]{figs/transformations/002_rot_90.jpg}\end{minipage} &  
        \begin{minipage}{.16\linewidth}\includegraphics[width=\linewidth]{figs/transformations/002_overlay_text.jpg}\end{minipage} &  
        \begin{minipage}{.16\linewidth}\includegraphics[width=\linewidth]{figs/transformations/002_comb.jpg}\end{minipage} 
        \\ \\
    \end{tabular}
    }
\caption{Illustration of all transformations evaluated in sections~\ref{sec:application} and \ref{sec:experiments}.}
\vspace{-0.5cm}
\label{fig:all-transformations}
\end{figure*}

\subsection{Image transformations}\label{app:transformations}
We evaluate the robustness of the watermark to a set of transformations in sections~\ref{sec:application}, \ref{sec:experiments} and \ref{sec:supp-robustness}.
They simulate image processing steps that are commonly used in image editing software.
We illustrate them in \autoref{fig:all-transformations}.
For crop and resize, the parameter is the ratio of the new area to the original area.
For rotation, the parameter is the angle in degrees.
For JPEG compression, the parameter is the quality factor (in general 90\% or higher is considered high quality, 80\%-90\% is medium, and 70\%-80\% is low).
For brightness, contrast, saturation, and sharpness, the parameter is the default factor used in the PIL and Torchvision~\cite{marcel2010torchvision} libraries.
The text overlay is made through the AugLy library~\cite{papakipos2022augly}, and adds a text at a random position in the image.
The combined transformation is a combination of a crop $0.5$, a brightness change $1.5$, and a JPEG $80$ compression.


\subsection{Generative tasks}\label{app:evaluation}

\paragraph*{Text-to-image.}
In text-to-image generation, the diffusion process is guided by a text prompt. 
We follow the standard protocol in the literature~\cite{ramesh2022hierarchical, ramesh2021zero, rombach2022high, saharia2022photorealistic} and evaluate the generation on prompts from the validation set of MS-COCO~\cite{lin2014microsoft}.
To do so, we first retrieve all the captions from the validation set, keep only the first one for each image, and select the first $1000$ or $5000$ captions depending on the evaluation protocol.
We use guidance scale $3.0$ and $50$ diffusion steps.
If not specified, the generation is done for $5000$ images.
The FID is computed over the validation set of MS-COCO, resized to $512\times 512$.

\vspace{-0.2cm}
\paragraph*{Image edition.}
DiffEdit~\cite{couairon2022diffedit} takes as input an image, a text describing the image and a novel description that the edited image should match. 
First, a mask is computed to identify which regions of the image should be edited. 
Then, mask-based generation is performed in the latent space, before converting the output back to RGB space with the image decoder. 
We use the default parameters used in the original paper, with an encoding ratio of 90\%, and compute a set of $5000$ images from the COCO dataset, edited with the same prompts as the paper~\cite{couairon2022diffedit}.
The FID is computed over the validation set of MS-COCO, resized to $512\times 512$.

\vspace{-0.2cm}
\paragraph*{Inpainting.}
We follow the protocol of LaMa~\cite{suvorov2022resolution}, and generate $5000$ masks with the ``thick'' setting, at resolution $512\times 512$, each mask covering $1-50\%$ of the initial image (with an average of $27\%$).
For the diffusion-based inpainting, we use the inference-time algorithm presented in \cite{song2020score}, also used in Glide~\cite{nichol2021glide}, which corrects intermediate estimations of the final generated image with the ground truth pixel values outside the inpainting mask. 
For latent diffusion models, the same algorithm can be applied in latent space, by encoding the image to be inpainted and downsampling the inpainting mask. 
In this case, we consider $2$ different variations: (1) inpainting is performed in the latent space and the final image is obtained by simply decoding the latent image; and (2) the same procedure is applied, but after decoding, ground truth pixel values from outside the inpainting mask are copy-pasted from the original image. 
The latter allows to keep the rest of the image perfectly identical to the original one, at the cost of introducing copy-paste artifacts, visible in the borders. 
Image quality is measured with an FID score, computed over the validation set of ImageNet~\cite{deng2009imagenet}, resized to $512\times 512$.

\vspace{-0.4cm}
\paragraph*{Super-resolution.}
We follow the protocol suggested by Saharia~\etal~\cite{saharia2022image}.
We first resize $5000$ random images from the validation set of ImageNet to $128\times 128$ using bicubic interpolation, and upscale them to $512\times 512$.
The FID is computed over the validation set of ImageNet, cropped and resized to $512\times 512$.


\begin{figure*}[b]
    \centering
    \scriptsize
    \newcommand{\imwidth}{0.165\textwidth}
    \setlength{\tabcolsep}{0pt}
    \begin{tabular}{cc@{\hskip 2pt}cc@{\hskip 2pt}cc}
        \toprule
        $\lambda_i = 0.025$ &  & $\lambda_i = 0.05$ &  & $\lambda_i = 0.1$ &  \\
        \midrule
        \includegraphics[width=\imwidth]{figs/supp/lambda-i/1_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/lambda-i/1_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/lambda-i/2_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/lambda-i/2_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/lambda-i/3_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/lambda-i/3_diff.jpg} \\
    \end{tabular}
    \begin{tabular}{c@{\hskip 2pt}ccccc}
        \toprule
        Original & Watson-VGG & Watson-DFT & LPIPS & MSE & LPIPS + $0.1\cdot$MSE \\
        \midrule
        \includegraphics[width=\imwidth]{figs/supp/loss-i/0_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/loss-i/0_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/loss-i/1_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/loss-i/2_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/loss-i/3_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/loss-i/4_w.jpg} \\
        \bottomrule \\
    \end{tabular}
    \caption{
        Qualitative influence of the perceptual loss during LDM fine-tuning. 
        (Top): we show images generated with the LDM auto-encoder fine-tuned with different $\lambda_i$, and the pixel-wise difference ($\times 10$) with regards to the image obtained with the original model.
        PSNR are $24$dB, $26$dB, $28$dB from left to right. 
        (Bottom): we change the perceptual loss and fix $\lambda_i$ to have approximately the same bit accuracy of $0.95$ on the ``combined'' augmentation. 
    }
    \label{fig:supp-lossi}
\end{figure*}



\subsection{Watermarking methods}\label{app:watermarking}
For Dct-Dwt, we use the implementation of \href{https://github.com/ShieldMnt/invisible-watermark}{https://github.com/ShieldMnt/invisible-watermark} (the one used in Stable Diffusion).
For SSL Watermark~\cite{fernandez2022sslwatermarking} and FNNS~\cite{kishore2021fixed} the watermark is embedded by optimizing the image, such that the output of a pre-trained model is close to the given key (like in adversarial examples~\cite{goodfellow2014adversarial}).
The difference between the two is that in SSL Watermark we use a model pre-trained with DINO~\cite{caron2021dino}, while FNNS uses a watermark or stenography model.
For SSL Watermark we use the default pre-trained model of the original paper. 
For FNNS we use the HiDDeN extractor used in all our experiments, and not SteganoGan~\cite{zhang2019steganogan} as in the original paper, because we want to extract watermarks from images of different sizes.
We use the image optimization scheme of Active Indexing~\cite{fernandez2022active}, \ie we optimize the distortion image for $10$ iterations, and modulate it with a perceptual just noticeable difference (JND) mask.
This avoids visible artifacts and gives a PSNR comparable with our method ($\approx 30$dB).
For HiDDeN, we use the watermark encoder and extractor from our pre-training phase, but the extractor is not whitened and we modulate the encoder output with the same JND mask.
Note that in all cases we watermark images one by one for simplicity. 
In practice the watermarking could be done by batch, which would be more efficient. 


\subsection{Attacks}\label{app:attacks}

\paragraph*{Watermark removal.} 
The perceptual auto-encoders aim to create compressed latent representations of images.
We select $2$ state-of-the-art auto-encoders from the CompressAI library zoo~\cite{begaint2020compressai}: the factorized prior model~\cite{balle2018variational} and the anchor model variant~\cite{cheng2020learned}.
We also select the auto-encoders from Esser~\etal~\cite{esser2021taming} and Rombach~\etal~\cite{rombach2022ldm}.
For all models, we use different compression factors to observe the trade-off between quality degradation and removal robustness.
For \texttt{bmshj2018}: $1$, $4$ and $8$, for \texttt{cheng2020}: $1$, $3$ and $6$, for \texttt{esser2021}: VQ-$4$, $8$ and $16$, for \texttt{rombach2022} KL-$4$, $8$, $16$ and $32$ (KL-$8$ being the one used by SD v1.4).
We generate $1$k images from text prompts with our LDM watermarked with a $48$-bits key.
We then try to remove the watermark using the auto-encoders, and compute the bit accuracy on the extracted watermark.
The PSNR is computed between the original image and the reconstructed one, which explains why the PSNR does not exceed $30$dB (since the watermarked image already has a PNSR of $30$dB).
If we compared between the watermarked image and the image reconstructed by the auto-encoder instead, the curves would show the same trend but the PSNR would be $2$-$3$ points higher.

\paragraph*{Watermark removal (white-box).} 
In the white-box case, we assume have access to the extractor model.
The adversarial attack is performed by optimizing the image in the same manner as~\cite{fernandez2022sslwatermarking}.
The objective is a MSE loss between the output of the extractor and a random binary message fixed beforehand. 
The attack is performed for $10$ iterations with the Adam optimizer~\cite{kingma2014adam} with learning rate $0.1$.

\paragraph*{Watermark removal (network-level).} 
We use the same fine-tuning procedure as in Sec.~\ref{subsec:finetuning}.
This is done for different numbers of steps, namely $100$, $200$, and every multiple of $200$ up to $1600$.
The bit accuracy and the reported PSNR are computed on $1$k images of the validation set of COCO, for the auto-encoding task.

\paragraph*{Model collusion.} 
The goal is to observe the decoded watermarks on the generation when $2$ models are averaged together.
We fine-tune the LDM decoder for $10$ different $48$-bits keys (representing $10$ Bobs).
We then randomly sample a pair of Bobs and average the $2$ models, with which we generate $100$ images.
We then extract the watermark from the generated images and compare them to the $2$ original keys.
We repeat this experiment $10$ times, meaning that we observe $10\times 100 \times 48=48000$ decoded bits.

In the inline figure, the rightmost skewed normal is fitted with the Scipy library and the corresponding parameters are $a:6.96, e:0.06, w:0.38$. 
This done over all bits where Bobs both have a $1$.
The same observation holds when there is no collusion, with approximately the same parameters.
When the bit is not the same between Bobs, we denote by $m_1^{(i)}$ the random variable representing the output of the extractor in the case where the generative model only comes from Bob$^{(i)}$,
and by $m_2$ the random variable representing the output of the extractor in the case where the generative model comes from the average of the two Bobs.
Then in our model $m_2 = 0.5 \cdot ( m_1^{(i)} + m_1^{(j)})$, and the pdf of $m_2$ is the convolution of the pdf of $m_1^{(i)}$ and the pdf of $m_1^{(j)}$, rescaled in the x axis because of the factor $0.5$.



\newcommand{\rota}[1]{\rotatebox{0}{\footnotesize\hspace{-0cm}#1}}
\begin{table*}[t]
\centering
\caption{
    Watermark robustness on different tasks and image transformations applied before decoding.
    We report the bit accuracy, averaged over $10\times1$k images generated with $10$ different keys.
    The combined transformation is a combination Crop $50\%$, Brightness $1.5$ and JPEG $80$.
    More detail on the evaluation is available in the supplement~\ref{app:evaluation}. \\
    }\label{tab:supp-robustness}
\resizebox{1.0\linewidth}{!}{
    \footnotesize
    \begin{tabular}{ *{2}{l} *{11}{p{1.0cm}} }
    \toprule
    \multirow{2}{*}{Task}                       & \multirow{2}{*}{}       & \multicolumn{9}{c}{Image transformation} \\ \cmidrule{3-12}
                                                &                       &  \rota{None} & \rota{Crop $0.1$} & \rota{JPEG $50$} & \rota{Resi. $0.7$} & \rota{Bright. $2.0$} & \rota{Cont. $2.0$} & \rota{Sat. $2.0$} & \rota{Sharp. $2.0$} & \rota{Text over.} & \rota{Comb.}\\ \midrule
     Text-to-Image          & LDM~\cite{rombach2022ldm}                         & $0.99$ & $0.95$ & $0.88$ & $0.91$ & $0.97$ & $0.98$ & $0.99$ & $0.99$ & $0.99$ & $0.92$ \\ \midrule
     Image Edition          & DiffEdit~\cite{couairon2022diffedit} & $0.99$ & $0.95$ & $0.90$ & $0.91$ & $0.98$ & $0.98$ & $0.99$ & $0.99$ & $0.99$ & $0.94$\\ \midrule
     Inpainting - Full      & \multirow{2}{*}{Glide~\cite{nichol2021glide}}     & $0.99$ & $0.97$ & $0.88$ & $0.90$ & $0.98$ & $0.99$ & $0.99$ & $1.00$ & $0.99$ & $0.93$ \\ 
    {\color{white}Inpa} - Mask only   &                                         & $0.89$ & $0.76$ & $0.73$ & $0.77$ & $0.84$ & $0.86$ & $0.89$ & $0.91$ & $0.89$ & $0.78$ \\  \midrule
     Super-Resolution & LDM~\cite{rombach2022ldm} & $0.98$ & $0.93$ & $0.86$ & $0.85$ & $0.96$ & $0.96$ & $0.97$ & $0.98$ & $0.98$ & $0.92$\\ 
    \bottomrule
    \end{tabular}
}
\end{table*}

\begin{figure*}[b]
    \begin{minipage}{0.67\textwidth}
        \centering
        \scriptsize
        \newcommand{\imheight}{0.33\textwidth}
        \setlength{\tabcolsep}{0pt}
        \begin{tabular}{lll}
            Before whitening: & After whitening: & Bernoulli simulation: \\
            \includegraphics[height=\imheight, trim=2cm 0.5cm 3.7cm 1cm, clip]{figs/supp/assump/cov_nowhit.pdf} &
            \includegraphics[height=\imheight, trim=2cm 0.5cm 3.7cm 1cm, clip]{figs/supp/assump/cov_whit.pdf} &
            \includegraphics[height=\imheight, trim=2cm 0.5cm 1.5cm 1cm, clip]{figs/supp/assump/cov_bern.pdf} \\
        \end{tabular}
        \caption{Covariance matrices of the bits output by the watermark decoder $\mathcal{W}$ before and after whitening.}
        \label{fig:supp-assumption}
    \end{minipage}\hfill
    \begin{minipage}{0.27\textwidth}
        \centering
        \includegraphics[width=0.99\textwidth, trim=0 0 0 0, clip]{figs/supp/fprcheck.pdf}
        \caption{FPR Empirical check.}
        \label{fig:supp-fpr-check}
    \end{minipage}
\end{figure*}



\section{Additional Experiments}

\subsection{Perceptual loss}\label{sec:supp-percep-loss}
The perceptual loss of \eqref{eq:loss2} affects the image quality.
\autoref{fig:supp-lossi} shows how the parameter $\lambda_i$ affects the image quality.
For high values, the image quality is very good. %
For low values, artifacts mainly appear in textured area of the image. 
It is interesting to note that this begins to be problematic only for low PSNR values (around 25 dB).

\autoref{fig:supp-lossi} shows an example of a watermarked image for different perceptual losses: Watson-VGG~\cite{czolbe2020loss}, Watson-DFT~\cite{czolbe2020loss}, LPIPS~\cite{zhang2018unreasonable}, MSE, and LPIPS+MSE.
We set the weight $\lambda_i$ of the perceptual loss so that the watermark performance is approximately the same for all types of loss, and such that the degradation of the image quality is strong enough to be seen.
Overall, we observe that the Watson-VGG loss gave the most eye-pleasing results, closely followed by the LPIPS.
When using the MSE, images are blurry and artifacts appear more easily, even though the PSNR is higher.





\subsection{Additional results on watermarks robustness}\label{sec:supp-robustness}

In \autoref{tab:supp-robustness}, we report the same table as in \autoref{tab:quality-watermarking} that evaluates the watermark robustness in bit accuracy on different tasks, with additional image transformations.
They are detailed and illustrated in App.~\ref{app:evaluation}.
As a reminder, the watermark is a $48$-bit binary key.
It is robust to a wide range transformations, and most often yields above $0.9$ bit accuracy.
The resize and JPEG $50$ transformations seems to be the most challenging ones, and sometimes get bellow $0.9$.
Note that the crop location is not important but the visual content of the crop is, \eg there is no way to decode the watermark on crops of blue sky (this is the reason we only show center crop).



\subsection{Additional network level attacks}\label{sec:supp-network-level}

Tab.~\ref{tab:supp-network-level} reports robustness of the watermarks to different quantization and pruning levels for the LDM decoder. 
Quantization is performed naively, by rounding the weights to the closest quantized value in the min-max range of every weight matrix.
Pruning is done using PyTorch~\cite{paszke2019pytorch} pruning API, with the L1 norm as criterion.
We observe that the network generation quality degrades faster than WM robustness. 
To reduce bit accuracy lower than 98\%, quantization degrades the PSNR $<$25dB, and pruning $<$20dB.

\begin{table}[t]
    \caption{
        Bit accuracy after network attacks, observed over 10$\times$1k images generated from text prompts.
    }\label{tab:supp-network-level}
    \centering
    \setlength{\tabcolsep}{6pt}
    \vspace*{0.2cm}
    \resizebox{0.95\linewidth}{!}{
        \begin{tabular}{ll|ll}
            % & \rot{Gauss. noise ($\sigma=10$)} & \rot{Med. filter ($k=7$)} & \rot{Gauss. blur ($\sigma=2$)} & \rot{Upscale} & \rot{Collage} & \rot{Face} & \rot{Quant.}  
            \toprule
            Quantization (8-bits) & 0.99 & Pruning L1 ($30\%$) & 0.99 \\
            Quantization (4-bits)  & 0.99 & Pruning L1 ($60\%$) & 0.95 \\
            \bottomrule
        \end{tabular}
    }
    \vspace*{-0.3cm}
\end{table}



\subsection{Scaling factor at pre-training.} 
The watermark encoder does not need to be perceptually good and it is beneficial to degrade image quality during pre-training.
In the following, ablations are conducted on a shorter schedule of $50$ epochs, on $128\times 128$ images and $16$-bits messages.
In \autoref{tab:encoder-quality}, we train watermark encoders/extractors for different scaling factor $\alpha$ (see Sec.~\ref{subsec:pre-training}), and observe that $\alpha$ strongly affects the bit accuracy of the method.
When it is too high, the LDM needs to generate low quality images for the same performance because the distortions seen at pre-training by the extractor are too strong.
When it is too low, they are not strong enough for the watermarks to be robust: the LDM will learn how to generate watermarked images, but the extractor won't be able to extract them on edited images.

\begin{table}[t]
    \centering
    \caption{
        Influence of the (discarded) watermark encoder perceptual quality. P$_{1,2}$ stands for Phase 1 or 2.
    }\label{tab:encoder-quality}\vspace{0.2cm}
    \resizebox{0.95\linewidth}{!}{
    \begin{tabular}{l *{5}{l}}
        \toprule
        Scaling factor $\alpha$ & $0.8$ & $0.4$ & $0.2$ & $0.1$ & $0.05$ \\ 
        \midrule
        (P$_{1}$) - PSNR $\uparrow$  & $16.1$ & $21.8$ & $27.2$ & $33.5$ & $39.3$ \\
        (P$_{2}$) - PSNR $\uparrow$  & $27.9$ & $30.5$ & \textbf{30.8} & $28.8$ & $27.8$ \\
        \midrule
        (P$_{1}$) - Bit acc. $\uparrow$ on `none'& $1.00$ & $1.00$ & $0.86$ & $0.72$ & $0.62$ \\
        (P$_{2}$) - Bit acc. $\uparrow$ on `none'& $0.98$ & \textbf{0.98} & $0.91$ & $0.90$ & $0.96$ \\
        (P$_{2}$) - Bit acc.  $\uparrow$ on `comb.'& \textbf{0.86} & $0.73$ & $0.82$ & $0.81$ & $0.69$ \\
        \bottomrule 
    \end{tabular}
    }
\end{table}

\subsection{Are the decoded bits i.i.d. Bernoulli random variables?}
\label{app:assumption}
The FPR and the $p$-value \eqref{eq:p-value} are computed with the assumption that, for vanilla images (not watermarked),
the bits output by the watermark decoder $\mathcal{W}$ are independent and identically distributed (i.i.d.) Bernoulli random variables with parameter $0.5$.
This assumption is not true in practice, even when we tried using regularizing losses in the training at phase one~\cite{bardes2022vicreg, sablayrolles2018catalyser}.
This is why we whiten the output at the end of the pre-training.

\autoref{fig:supp-assumption} shows the covariance matrix of the hard bits output by $\mathcal{W}$ before and after whitening. 
They are computed over $5$k vanilla images, generated with our LDM at resolution $512\times512$ (as a reminder the whitening is performed on $1$k vanilla images from COCO at $256\times256$).
We compare them to the covariance matrix of a Bernoulli simulation, where we simulate $5k$ random messages of $48$ Bernoulli variables.
We observe the strong influence of the whitening on the covariance matrix, although it still differs a little from the Bernoulli simulation.
We also compute the bit-wise mean and observe that for un-whitened output bits, some bits are very biased.  
For instance, before whitening, one bit had an average value of $0.95$ (meaning that it almost always outputs $1$).
After whitening, the maximum average value of a bit is $0.68$.
For the sake of comparison, the maximum average value of a bit in the Bernoulli simulation was $0.52$.
It seems to indicate that the distribution of the generated images are different than the one of vanilla images, and that it impacts the output bits.
Therefore, the bits are not perfectly i.i.d. Bernoulli random variables. 
We however found they are close enough for the theoretical FPR computation to match the empirical one (see next section) -- which was what we wanted to achieve.

\subsection{Empirical check of the FPR}\label{app:fpr-check}
In \autoref{fig:tpr-fpr}, we plotted the TPR against a theoretical value for the FPR, with the i.i.d. Bernoulli assumption.
The FPR was computed theoretically with \eqref{eq:p-value}.
Here, we empirically check on smaller values of the FPR (up to $10^{-7}$) that the empirical FPR matches the theoretical one (higher values would be too computationally costly).
To do so, we use the $1.4$ million vanilla images from the training set of ImageNet resized and cropped to $512\times512$, and perform the watermark extraction with $\mathcal{W}$.
We then fix $10$ random $48$-bits key $m^{(1)},\cdots, m^{(10)}$, and, for each image, we compute the number of matching bits $d(m', m^{(i)})$ between the extracted message $m'$ and the key $m^{(i)}$, and flag the image if $d(m', m^{(i)})\geq \tau$.

\autoref{fig:supp-fpr-check} plots the FPR averaged over the $10$ keys, as a function of the threshold $\tau$.
We compare it to the theoretical one obtained with \eqref{eq:p-value}.
As it can be seen, they match almost perfectly for high FPR values. 
For lower ones ($<10^{-6}$), the theoretical FPR is slightly higher than the empirical one.
This is a good thing since it means that if we fixed the FPR at a certain value, we would observe a lower one in practice.

\section{Additional Qualitative Results}\label{app:qualitative}

\begin{figure*}
\centering
    \scriptsize
    \newcommand{\imwidth}{0.165\textwidth}
        \setlength{\tabcolsep}{0pt}
        \begin{tabular}{c@{\hskip 2pt}ccccc}
        \toprule
        Original & Stable Signature & Dct-Dwt & SSL Watermark & FNNS & HiDDeN \\
        \midrule
        \includegraphics[width=\imwidth]{figs/supp/txt2img/00_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/txt2img/00_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/watermark/dctdwt/00_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/watermark/ssl/00_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/watermark/fnns/00_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/watermark/hidden/00_w.jpg} \\

         &
        \includegraphics[width=\imwidth]{figs/supp/txt2img/00_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/watermark/dctdwt/00_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/watermark/ssl/00_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/watermark/fnns/00_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/watermark/hidden/00_diff.jpg} \\
        \rule{0pt}{6ex}%

        \includegraphics[width=\imwidth]{figs/supp/txt2img/01_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/txt2img/01_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/watermark/dctdwt/01_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/watermark/ssl/01_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/watermark/fnns/01_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/watermark/hidden/01_w.jpg} \\

         &
        \includegraphics[width=\imwidth]{figs/supp/txt2img/01_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/watermark/dctdwt/01_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/watermark/ssl/01_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/watermark/fnns/01_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/watermark/hidden/01_diff.jpg} \\
    \\
    \end{tabular}
\caption{\label{fig:supp-watermark} Qualitative results for different watermarking methods on generated images at resolution $512$.}
\end{figure*}

\begin{figure*}
\centering
    \scriptsize
    \newcommand{\imwidth}{0.165\textwidth}
        \setlength{\tabcolsep}{0pt}
        \begin{tabular}{ccc@{\hskip 2pt}ccc}
        \toprule
        Original & Watermarked & Difference & Original & Watermarked & Difference \\
        \midrule
        \includegraphics[width=\imwidth]{figs/supp/txt2img/00_nw.jpg} &
       \includegraphics[width=\imwidth]{figs/supp/txt2img/00_w.jpg} &
       \includegraphics[width=\imwidth]{figs/supp/txt2img/00_diff.jpg} &
       \includegraphics[width=\imwidth]{figs/supp/txt2img/01_nw.jpg} &
       \includegraphics[width=\imwidth]{figs/supp/txt2img/01_w.jpg} &
       \includegraphics[width=\imwidth]{figs/supp/txt2img/01_diff.jpg} \\
       \rule{0pt}{6ex}%

       \includegraphics[width=\imwidth]{figs/supp/txt2img/03_nw.jpg} &
       \includegraphics[width=\imwidth]{figs/supp/txt2img/03_w.jpg} &
       \includegraphics[width=\imwidth]{figs/supp/txt2img/03_diff.jpg} &
       \includegraphics[width=\imwidth]{figs/supp/txt2img/06_nw.jpg} &
       \includegraphics[width=\imwidth]{figs/supp/txt2img/06_w.jpg} &
       \includegraphics[width=\imwidth]{figs/supp/txt2img/06_diff.jpg} \\
       \rule{0pt}{6ex}%

       \includegraphics[width=\imwidth]{figs/supp/txt2img/08_nw.jpg} &
       \includegraphics[width=\imwidth]{figs/supp/txt2img/08_w.jpg} &
       \includegraphics[width=\imwidth]{figs/supp/txt2img/08_diff.jpg} &
       \includegraphics[width=\imwidth]{figs/supp/txt2img/09_nw.jpg} &
       \includegraphics[width=\imwidth]{figs/supp/txt2img/09_w.jpg} &
       \includegraphics[width=\imwidth]{figs/supp/txt2img/09_diff.jpg} \\
       \rule{0pt}{6ex}%

        \includegraphics[width=\imwidth]{figs/supp/txt2img/10_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/txt2img/10_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/txt2img/10_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/txt2img/14_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/txt2img/14_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/txt2img/14_diff.jpg} \\
        \rule{0pt}{6ex}%
        
        \includegraphics[width=\imwidth]{figs/supp/txt2img/15_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/txt2img/15_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/txt2img/15_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/txt2img/16_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/txt2img/16_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/txt2img/16_diff.jpg} \\
        \rule{0pt}{6ex}%

        \includegraphics[width=\imwidth]{figs/supp/txt2img/17_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/txt2img/17_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/txt2img/17_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/txt2img/18_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/txt2img/18_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/txt2img/18_diff.jpg} \\
    \bottomrule \\
    \end{tabular}
\caption{\label{fig:supp-txt2img} Qualitative results on prompts of the validation set of MS-COCO, at resolution $512$ and for a $48$-bits signature.
Images are generated from the same latents, with original or watermarked generative models.}
\end{figure*}
    
        
\begin{figure*}
    \centering
    \scriptsize
    \newcommand{\imwidth}{0.124\textwidth}
    \setlength{\tabcolsep}{0pt}
    \begin{tabular}{cc@{\hskip 2pt}ccc@{\hskip 2pt}ccc}
        \toprule
        Image to inpaint & Mask & Original & Watermarked & Difference & Original & Watermarked & Difference \\
        \midrule
        \hspace{0pt}
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/00_ori.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/00_mask.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/00_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/00_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/00_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-mask/00_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-mask/00_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-mask/00_diff.jpg} \\
        \rule{0pt}{6ex}

        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/01_ori.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/01_mask.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/01_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/01_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/01_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-mask/01_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-mask/01_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-mask/01_diff.jpg} \\
        \rule{0pt}{6ex}

        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/02_ori.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/02_mask.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/02_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/02_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/02_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-mask/02_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-mask/02_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-mask/02_diff.jpg} \\
        \rule{0pt}{6ex}

        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/03_ori.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/03_mask.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/03_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/03_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/03_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-mask/03_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-mask/03_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-mask/03_diff.jpg} \\
        \rule{0pt}{6ex}

        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/04_ori.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/04_mask.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/04_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/04_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/04_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-mask/04_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-mask/04_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-mask/04_diff.jpg} \\
        \rule{0pt}{6ex}

        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/05_ori.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/05_mask.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/05_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/05_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-full/05_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-mask/05_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-mask/05_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/inpaint-mask/05_diff.jpg} \\
        \bottomrule \\
    \end{tabular}
    \caption{
        \label{fig:supp-inpaint} Qualitative results for inpainting on ImageNet, with masks created from LaMa protocol~\cite{suvorov2022resolution}, with original or watermarked generative models.
        We consider 2 scenarios: 
        (middle) the full image is modified to fill the masked area, 
        (rigtht) only the masked area is filled.
        Since our model is not fine-tuned for inpainting, the last scenario introduces copy-paste artifacts.
        From a watermarking point of view, it is also the more interesting, since the watermark signal is only present in the masked area (and erased wherever the image to inpaint is copied).
        Even in this case, the watermark extractor achieves bit accuracy significantly higher than random.
    }
\end{figure*}


\begin{figure*}
    \centering
    \scriptsize
    \newcommand{\imwidth}{0.124\textwidth}
    \setlength{\tabcolsep}{0pt}
    \begin{tabular}{cccc@{\hskip 2pt}cccc}
        \toprule
        Low resolution & Original & Watermarked & Difference & Low resolution & Original & Watermarked & Difference \\
        \midrule
        \hspace{0pt}
        \includegraphics[width=\imwidth]{figs/supp/sr/00_ori.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/00_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/00_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/00_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/05_ori.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/05_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/05_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/05_diff.jpg} \\
        \rule{0pt}{6ex}

        \includegraphics[width=\imwidth]{figs/supp/sr/01_ori.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/01_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/01_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/01_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/06_ori.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/06_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/06_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/06_diff.jpg} \\
        \rule{0pt}{6ex}

        \includegraphics[width=\imwidth]{figs/supp/sr/03_ori.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/03_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/03_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/03_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/07_ori.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/07_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/07_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/07_diff.jpg} \\
        \rule{0pt}{6ex}

        \includegraphics[width=\imwidth]{figs/supp/sr/04_ori.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/04_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/04_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/04_diff.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/08_ori.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/08_nw.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/08_w.jpg} &
        \includegraphics[width=\imwidth]{figs/supp/sr/08_diff.jpg} \\
        \bottomrule \\
    \end{tabular}
    \caption{
        \label{fig:supp-sr} Qualitative results for super-resolution on ImageNet, with original and watermarked generative models.
        Low resolution images are $128\times128$, and upscaled to $512\times512$ with an upscaling factor $f=4$.
    }
\end{figure*}