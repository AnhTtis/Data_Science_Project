
\begin{figure*}[b]
    \centering
    \includegraphics[width=1.0\textwidth, trim={0cm 0.7cm 0cm 0cm}, clip]{figs/method.pdf}
    \caption{
        Steps of the method.
        (a) We pre-train a watermark encoder $\mathcal{W}_E$ and extractor $\mathcal{W}$, to extract binary messages.
        (b) We fine-tune the decoder $\mathcal{D}$ of the LDM's auto-encoder with a fixed signature $m$ such that all the generated images (c) lead to $m$ through $\mathcal{W}$.
        }
    \label{fig:method}
\end{figure*}

\section{Problem Statement \& Background}

\autoref{fig:fig1} shows a model provider \emph{Alice} who deploys a latent diffusion model to users \emph{Bobs}.
Stable Signature embeds a binary signature into the generated images. 
This section derives how Alice can use this signature for two scenarios:
\vspace{-0.6em}
\begin{itemize}[leftmargin=*, labelindent=0pt, label=\textbullet, itemsep=-4pt]
    \item 
    \emph{Detection: ``Is it generated by my model?''.} 
    Alice detects if an image was generated by her model.
    As many generations as possible should be flagged, while controlling the probability of flagging a natural image. 
    \item 
    \emph{Identification: ``Who generated this image?''.} 
    Alice monitors who created each image, while avoiding to mistakenly identifying a Bob who did not generate the image.
\end{itemize}

\subsection{Image watermarking for detection}
Alice embeds a $k$-bit binary signature into the generated images.
The watermark extractor then decodes messages from the images it receives and detects when the message is close to Alice's signature.
An example application is to block AI-generated images on a content sharing platform. 


\vspace{-0.3cm}
\paragraph{Statistical test}\label{subsec:statistical-test}
Let $m\in \{ 0,1 \}^{k}$ be Alice's signature. 
We extract the message $m'$ from an image $x$ and compare it to $m$.
As done in previous works~\cite{lin2022cycleganwm, yu2021artificial},
the detection test relies on the number of matching bits $M(m,m')$: if
\vspace{-0.3cm}
\begin{equation} 
M\left(m,m'\right) \geq \tau \,\,\textrm{ where }\,\, \tau\in 
\{0,\ldots,k\}, \vspace{-0.3cm}
\label{eq:detectiontest}
\end{equation}
then the image is flagged.
This provides a level of robustness to imperfections of the watermarking. 

Formally, we test the statistical hypothesis $H_1$: ``$x$ was generated by Alice's model'' 
against the null hypothesis $H_0$: ``$x$ was not generated by Alice's model''.
Under $H_0$ (\ie for vanilla images), we assume that bits $m'_1,\ldots, m'_k$ are (i.i.d.) Bernoulli random variables with parameter $0.5$.
Then $M(m, m')$ follows a binomial distribution with parameters ($k$, $0.5$).
We verify this assumption experimentally in App.~\ref{app:assumption}.
The False Positive Rate (FPR) is the probability that $M(m, m')$ takes a value bigger than the threshold $\tau$.
It is obtained from the CDF of the binomial distribution, and a closed-form can be written with the regularized incomplete beta function $I_x(a;b)$:
\vspace{-0.2cm}
\begin{align}\label{eq:p-value}
    \text{FPR}(\tau) & = \mathbb{P}\left(M > \tau | H_0\right) = I_{1/2}(\tau+1, k - \tau). 
    % \text{FPR}(\tau) & = \mathbb{P}\left(M(m, m') > \tau | H_0\right) = \frac{1}{2^k}\sum_{i=\tau+1}^k \binom{k}{i} \nonumber \\[-6pt]
    % & = I_{1/2}(\tau+1, k - \tau). 
\end{align}


\subsection{Image watermarking for identification}
Alice now embeds a signature $m^{(i)}$ drawn randomly from $\{0,1\}^k$ into %
the model distributed to
Bob$^{(i)}$ (for $i=1\cdots N$, with $N$ the number of Bobs).
Alice can trace any misuse of her model: generated images violating her policy (gore content, deepfakes) are linked back to the specific Bob by comparing the extracted message to Bobs' signatures.

\vspace{-0.2cm}
\paragraph{Statistical test}\label{subsec:statistical-test-identification}
We compare the message $m'$ from the watermark extractor to $ \left( m^{(1)},\dots, m^{(N)} \right)$. %
There are now $N$ detection hypotheses to test.
If the $N$ hypotheses are rejected, we conclude that the image was not generated by any of the models.
Otherwise, we attribute the image to $\textrm{argmax}_{i=1..N} M\left(m', m^{(i)}\right)$.
With regards to the detection task, false positives are more likely since there are $N$ tests. 
The global FPR at a given threshold $\tau$ is:
\vspace{-0.2cm}
\begin{equation}\label{eq:globalFPR}
    \text{FPR}(\tau,N) = 1-(1-\text{FPR}(\tau))^N\approx N.\text{FPR}(\tau).
\vspace{-0.2cm}
\end{equation}

Equation~\eqref{eq:globalFPR} (resp.~\eqref{eq:p-value}), is used reversely: we find threshold $\tau$ to achieve a required FPR for identification (resp.~detection). 
Note that these formulae hold only under the assumption of i.i.d. Bernoulli bits extracted from vanilla images. 
This crucial point is enforced in the next section. 
