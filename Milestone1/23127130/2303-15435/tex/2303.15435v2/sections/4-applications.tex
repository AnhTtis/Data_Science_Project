
\begin{figure*}[b]
    \begin{minipage}{0.33\textwidth}
        \centering
        \includegraphics[width=1.0\textwidth, trim={0cm 0cm 0cm 0cm}, clip]{figs/tpr_fpr.pdf}
        \caption{
            \textbf{Detection results}. TPR/FPR curve of the detection under different transformations.
            Forensics$^\dagger$ indicates passive detection (without watermark)~\cite{corvi2022detection}.
        }\label{fig:tpr-fpr}
    \end{minipage}\hspace{0.4cm}
    \begin{minipage}{0.33\textwidth}
        \centering
        \includegraphics[width=1.0\textwidth, trim={0cm 0cm 0cm 0cm}, clip]{figs/identification.pdf}
        \caption{
            \textbf{Identification results}. 
            Proportion of well-identified users.
            Detection with FPR=$10^{-6}$ is run beforehand, and we consider it an error if the image is not flagged.
        }\label{fig:identification}
    \end{minipage}\hfill
    \begin{minipage}{0.28\textwidth}
        \centering
        \includegraphics[width=1.0\textwidth, trim={0cm 0cm 0cm 0cm}, clip]{figs/aug.pdf}
        \caption{
            Transformations evaluated in Sec.~\ref{sec:application} \&~\ref{sec:experiments}.
            `Combined' is made of crop $50\%$, brightness adjustment $1.5$ and JPEG $80$ compression.
        }\label{fig:transformations}
    \end{minipage}
\end{figure*}


\section{Text-to-Image Watermarking Performance }\label{sec:application}
This section shows the potential of our method for detection and identification or images generated by a Stable-Diffusion-like model~\cite{rombach2022ldm}\footnote{
    We refrain from experimenting with pre-existing third-party generative models, such as Stable Diffusion or LDMs, and instead use a large diffusion model (2.2B parameters) trained on an internal dataset of 330M licensed image-text pairs.
}.
We apply generative models watermarked with $48$-bit signatures on prompts of the MS-COCO~\cite{lin2014microsoft} validation set.
We evaluate detection and identification on the outputs, as illustrated in~\autoref{fig:fig1}.

We evaluate their robustness to different transformations applied to generated images:
strong cropping ($10\%$ of the image remaining), 
brightness shift (strength factor $2.0$), 
as well as a combination of crop $50\%$, brightness shift $1.5$ and JPEG $80$. 
This covers typical geometric and photometric edits (see Fig.~\ref{fig:transformations} for visual examples).

The performance is partly obtained from experiments and partly by extrapolating small-scale measurements.



\subsection{Detection results}
For detection, we fine-tune the decoder of the LDM with a random key $m$, generate $1000$ images and use the test of Eq.~\eqref{eq:detectiontest}.
We report the tradeoff between True Positive Rate (TPR), \ie the probability of flagging a generated image and the FPR, while varying $\tau\in \{0, .. ,48\}$.
For instance, for $\tau=0$, we flag all images so $\textrm{FPR}=1$, and $\textrm{TPR}=1$.
The TPR is measured directly. 
In contrast the FPR is inferred from Eq.~\eqref{eq:p-value}, because it would otherwise be too small to be measured on reasonably sized problems 
(this approximation is validated experimentally in App.~\ref{app:fpr-check}).
The experiment is run on $10$ random signatures and we report averaged results.

\autoref{fig:tpr-fpr} shows the tradeoff under image transformations.
For example, when the generated images are not modified, Stable Signature detects $99\%$ of them, while only $1$ vanilla image out of $10^9$ is flagged.
At the same $\textrm{FPR}=10^{-9}$, Stable Signature detects $84\%$ of generated images for a crop that keeps $10\%$ of the image, 
and $65\%$ for a transformation that combines a crop, a color shift, and a JPEG compression.
For comparison, we report results of a state-of-the-art passive method~\cite{corvi2022detection}, applied on resized and compressed images.
As to be expected, we observe that these baseline results have orders of magnitudes larger FPR than Stable Signature, which actively marks the content. 


\subsection{Identification results}
Each Bob has its own copy of the generative model. 
Given an image, the goal is to find if any of the $N$ Bobs created it (detection) and if so, which one (identification).
There are $3$ types of error: 
\emph{false positive}: flag a vanilla image; 
\emph{false negative}: miss a generated image; 
\emph{false accusation}: flag a generated image but identify the wrong user.

For evaluation, we fine-tune $N'=1000$ models with random signatures.
Each model generates $100$ images.
For each of these $100$k watermarked images, we extract the Stable Signature message, compute the matching score with all $N$ signatures and select the user with the highest score. 
The image is predicted to be generated by that user if this score is above threshold $\tau$.
We determined $\tau$ such that $\textrm{FPR}=10^{-6}$, see Eq.~\eqref{eq:globalFPR}. 
For example, for $N=1$, $\tau=41$ and for $N=1000$, $\tau=44$.
Accuracy is extrapolated beyond the $N'$ users by adding additional signatures and having $N > N'$ (\eg users that have not generated any images).

\autoref{fig:identification} reports the per-transformation identification accuracy.
For example, we identify a user among $N$=$10^{5}$ with $98\%$ accuracy when the image is not modified.
Note that for the combined edit, this becomes $40\%$.
This may still be dissuasive:
if a user generates $3$ images, he will be identified $80\%$ of the time.
We observe that at this scale, the false accusation rate is zero, \ie we never identify the wrong user.
This is because $\tau$ is set high to avoid FPs, which also makes false accusations unlikely.
We observe that the identification accuracy decreases when $N$ increases, because the threshold $\tau$ required to avoid false positives is higher when $N$ increases, as pointed out by the approximation in~\eqref{eq:globalFPR}.
In a nutshell, by distributing more models, Alice trades some accuracy of detection against the ability to identify users.
