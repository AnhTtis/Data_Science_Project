
\section{Conclusion \& Discussion}\label{sec:conclusion}

By a quick fine-tuning of the decoder of Latent Diffusion Models, we can embed watermarks in all the images they generate.
This does not alter the diffusion process, making it compatible with most of LDM-based generative models.
These watermarks are robust, invisible to the human eye and can be employed to \emph{detect} generated images and \emph{identify} the user that generated it, with very high performance.

The public release of image generative models has an important societal impact.
With this work, we put to light the usefulness of using watermarking instead of relying on passive detection methods.
We hope it will encourage researchers and practitioners to employ similar approaches before making their models publicly available.

\vspace{-0.3cm}
\paragraph{Reproducibility Statement.}

Although the diffusion-based generative model has been trained on an internal dataset of licensed images, we use the KL auto-encoder from LDM~\cite{rombach2022ldm} with compression factor $f=8$.
This is the one used by open-source alternatives.
Code is available at \href{https://github.com/facebookresearch/stable_signature}{github.com/facebookresearch/stable\_signature}.

\vspace{-0.3cm}
\paragraph{Environmental Impact.}
We do not expect any environmental impact specific from this work.
The cost of the experiments and the method is high, though order of magnitudes less than other computer vision fields. 
We roughly estimated that the total GPU-days used for running all our experiments to $2000$, or $\approx 50000$ GPU-hours.
This amounts to total emissions in the order of 10 tons of CO$_2$eq.
This is excluding the training of the generative model itself, since we did not perform that training. 
Estimations are conducted using the \href{https://mlco2.github.io/impact#compute}{Machine Learning Impact calculator} presented by Lacoste~\etal\cite{lacoste2019quantifying}.
We do not consider in this approximation: memory storage, CPU-hours, production cost of GPUs/ CPUs, etc. 
