\section{Previous Work and Comparison Algorithms}
\label{sec:previous}
The canonical local planner algorithm for ROS is the Dynamic Window Approach~\cite{fox1997dynamic}. At each instant, DWA calculates a set of achievable $(v,\omega)$ pairs based on the current velocities and achievable acceleration characteristics of the robot. For each velocity pair 
%(which corresponds to a circular arc), 
DWA calculates a score based on how closely the arc follows the global plan, and on how far the arc is from any obstacle. It then chooses the best velocity pair based on this score. 

Multiple recent papers have investigated how well local planner behavior can be learned via RL. G\"uldenring et al.~\cite{guldenring2019applying} developed a framework that has been followed by many subsequent papers in which the global plan is partitioned into waypoints and the task of the RL agent is to get to the next waypoint. 
%Our work also follows Guldenring's basic approach but we extend with polar-based image states and also investigate more recent RL algorithms. 

Patel et al.~\cite{patel2021dwa} combines the DWA and RL approaches. The resulting DWA-RL algorithm calculates a cost for each potential velocity pair, but then uses RL to select the best pair based on the full spectrum of costs, rather than just picking the lowest cost pair. The work of K\"astner et al.~\cite{KastnerML20} distinguishes between humans, robots and static objects and uses an RL state that is a combination of the raw LiDAR input, the distance/angle to the goal, the position of nearby humans and the position of nearby robots. A follow-up paper~\cite{KastnerZBLSLM21} looks at different methods for choosing the next waypoint, and compares the fixed partition of  G\"uldenring et al.~\cite{guldenring2019applying,GuldenringGHJ20}, with alternative methods that choose the waypoint more dynamically. The work of Liu et al.~\cite{liu2020robot} uses a similar RL state. The main difference is that they represent pedestrian and robot movement using the CrowdNav algorithm of \cite{chen2019crowd}, and they represent the LiDAR information via both the raw LiDAR values and an Occupancy Grid.

In many of these papers the success rate of the trained agent is significantly under 100\%. For example, the agent of \cite{guldenring2019applying} converges to a rate less than 70\%. Moreover, this prior work typically provides trajectory plots from a Gazebo simulation. Our goal is to train an agent with close to 100\% success, and then analyze trajectories from a real-world deployment (with the associated imperfections in sensing and localization). We also observe that if the goal is to get to the next waypoint, then an alternative is to repeatedly calculate a shortest path in the Occupancy Grid. We have found that modern python implementations of Dijkstra's algorithm can do this sufficiently fast, and so we also compare against a local planner that uses the next segment of the shortest path to define the robot velocities. Note however that the shortest path will change over time as the robot and obstacles move.  