\section{Introduction}\label{sec:Introduction}

The soundscape approach to noise control, as defined in ISO 12913, recommends assessments of the ``acoustic environment as perceived or experienced and/or understood by a person or people, in context'' \cite{InternationalOrganizationforStandardization2014}. Accordingly, soundscape practitioners often focus on interventions that alter the \textit{perception} of acoustic environments, mindful that simply reducing the sound pressure level of a noisy environment may not correlate well with improved perception \cite{DePaivaVianna2015NoiseStudy, Kang2019}. One such intervention is \textit{soundscape augmentation}, which introduces ``maskers'' as additional sounds via electroacoustic systems to improve the perception of the acoustic environment. 
The choice of maskers can be done manually, in an expert-driven \cite{Coensel2011} or participant-driven fashion~\cite{VanRenterghem2020}, but autonomous systems, such as those described in \cite{Jahani2021AnAreas} and \cite{Wong2022DeploymentAugmentation}, can reduce the time and labor required in manual approaches.

However, a weakness of existing autonomous systems is the absence of consideration for the \textit{context} of perception, which is crucial for modeling perceptual attributes, such as the perceived pleasantness of soundscapes \cite{Mitchell2021b}. Contextual factors known to affect soundscape assessments include listener- or participant-linked demographic variables, such as age \cite{Yang2005AcousticSpaces}, responses to self-reported psychological questionnaires \cite{Aletta2018, Ratcliffe2021}, and the present activity while experiencing the soundscape \cite{Mitchell2020TheInformation}. In addition, factors related to the visual environment, such as the physical objects present in a scene \cite{Preis2015}, or the proportion of landscape elements like greenery and buildings \cite{PuyanaRomero2016, Tan2022TheCity},  may also affect soundscape assessments.

Hence, this study aims to improve the performance of a model deployable in an autonomous soundscape augmentation system, by additionally fusing visual and participant-linked information to the existing acoustic information captured by the model. We use an attention-based deep neural network (DNN) architecture previously designed for a purely-acoustic prediction model of perceptual soundscape attributes \cite{Watcharasupat2022AutonomousGain}, and propose new approaches for the DNN to \textit{optionally} exploit the visual and participant-linked information when available or desired. These approaches naturally extend the functions of existing model components performing feature augmentation and probabilistic output prediction, while having a threefold advantage over the pre-existing model: (a) the modified models are backward-compatible with the pre-existing audio-only version as detailed in \Cref{sec:Proposed Method}, (b) their use of additional modalities can improve model performance in mean squared error (MSE) of predictions based on our validation experiments described in \Cref{sec:Validation Experiments}, and (c) they can be used to explain perceptual differences based on participant-linked factors as illustrated in \Cref{sec:Results and Discussion}. 