\pdfoutput=1

% Template for ICASSP-2023 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{spconf}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{float}
\usepackage{siunitx}
\usepackage{enumitem}
\usepackage{placeins}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{bm}
\usepackage{comment}
\usepackage{mathtools}
\usepackage{xcolor}
\usepackage{lipsum}

\usepackage{hyperref}
\usepackage{cleveref}

\crefname{figure}{Fig.\@}{Fig.\@}

\sisetup{detect-mode=false, mode=text}

% Title.
% ------
\title{Autonomous Soundscape Augmentation\\with Multimodal Fusion of Visual and Participant-linked Inputs}
%
% Single address.
% ---------------
\name{
    Kenneth Ooi$^1$,
    Karn N. Watcharasupat$^2$,
    Bhan Lam$^1$,
    Zhen-Ting Ong$^1$,
    Woon-Seng Gan$^1$
\thanks{This research is supported by the Singapore Ministry of National Development and the National Research Foundation,  Prime Minister's Office under the Cities of Tomorrow Research Programme (Award No.\@ COT-V4-2020-1). 
Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not reflect views of the National Research Foundation and Ministry of National Development, Singapore.
}
}
\address{
    $^1$School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore\\
    $^2$Center for Music Technology, Georgia Institute of Technology, Atlanta, GA, USA\\ % 
    Emails: wooi002@e.ntu.edu.sg, kwatcharasupat@gatech.edu, \{bhanlam, ztong, ewsgan\}@ntu.edu.sg
}

\usepackage{fancyhdr}

\fancypagestyle{firstpage}{
     \renewcommand{\headrulewidth}{0pt}%
     \fancyhf{}
     \fancyhead[L]{Submitted to the 2023 IEEE International Conference on Acoustics, Speech and Signal Processing.}
     \fancyfoot[L]{\footnotesize\textcopyright 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.}
}
 
\thispagestyle{firstpage}

\begin{document}
\ninept
\maketitle

\input{sections/00abstractkw.tex}

\input{sections/01introduction.tex}

\vspace{-1.5mm}

\input{sections/02relatedwork.tex}

\input{sections/03proposedmethod.tex}

\vspace{-1mm}

\input{sections/04experiments.tex}

\input{sections/05results.tex}

\input{sections/06conclusion.tex}

\FloatBarrier

\bibliographystyle{IEEEbib}
\begin{thebibliography}{10}
	\setlength{\parskip}{0pt}
	\setlength{\itemsep}{6pt plus 4pt minus 5pt}
	
	\providecommand{\url}[1]{#1}
	\def\UrlFont{\rmfamily}
	\providecommand{\newblock}{\relax}
	\providecommand{\bibinfo}[2]{#2}
	\providecommand\BIBentrySTDinterwordspacing{\spaceskip=0pt\relax}
	\providecommand\BIBentryALTinterwordstretchfactor{4}
	\providecommand\BIBentryALTinterwordspacing{\spaceskip=\fontdimen2\font plus
		\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
		\fontdimen4\font\relax}
	\providecommand\BIBforeignlanguage[2]{{%
			\expandafter\ifx\csname l@#1\endcsname\relax
			\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
			\typeout{** loaded for the language `#1'. Using the pattern for}%
			\typeout{** the default language instead.}%
			\else
			\language=\csname l@#1\endcsname
			\fi
			#2}}
	
	\bibitem{InternationalOrganizationforStandardization2014}
	{International Organization for Standardization},
	\emph{{{ISO 12913-1:2014 - Acoustics - Soundscape - Part
				1: Definition and conceptual framework}}}.\hskip 1em plus 0.5em minus
	0.4em\relax Geneva, Switzerland: International Organization for
	Standardization, 2014.
	
	\bibitem{DePaivaVianna2015NoiseStudy}
	K.~M. De~Paiva~Vianna, M.~R. Alves~Cardoso, and R.~M.~C. Rodrigues, ``{Noise
		pollution and annoyance: An urban soundscapes study},''
	\emph{{Noise Heal.}}, vol.~17, no.~76, pp.
	125--133, 2015.
	
	\bibitem{Kang2019}
	J.~Kang, \emph{et~al.}, ``{Towards soundscape indices},'' in
	\emph{{23rd Int. Congr. Acoust.}}, 2019,
	pp. 2488--2495.
	
	\bibitem{Coensel2011}
	B.~De~Coensel, S.~Vanwetswinkel, and D.~Botteldooren, ``{Effects of natural
		sounds on the perception of road traffic noise},''
	\emph{{JASA Express Lett.}}, vol. 129, no.~4, pp.
	148--153, 2011.
	
	\bibitem{VanRenterghem2020}
	T.~Van~Renterghem, \emph{et~al.}, ``{Interactive soundscape augmentation by
		natural sounds in a noise polluted urban park},''
	\emph{{Landsc. Urban Plan.}}, vol. 194, p.
	103705, 2020.
	
	\bibitem{Jahani2021AnAreas}
	A.~Jahani, S.~Kalantary, and A.~Alitavoli, ``{An application of artificial
		intelligence techniques in prediction of birds soundscape impact on
		tourists’ mental restoration in natural urban areas},''
	\emph{{Urban For. Urban Green.}}, vol.~61, no.
	February, 2021.
	
	\bibitem{Wong2022DeploymentAugmentation}
	T.~Wong, \emph{et~al.}, ``{Deployment of an IoT System for Adaptive In-Situ
		Soundscape Augmentation},'' in \emph{{Proc.
			Inter-Noise}}, 2022.
	
	\bibitem{Mitchell2021b}
	A.~Mitchell, \emph{ et~al.}, ``{Investigating urban soundscapes of the COVID-19
		lockdown: A predictive soundscape modeling approach},''
	\emph{{J. Acoust. Soc. Am.}},
	vol. 150, no.~6, pp. 4474--4488, 2021.
	
	\bibitem{Yang2005AcousticSpaces}
	W.~Yang and J.~Kang, ``{Acoustic comfort evaluation in urban open public
		spaces},'' \emph{{Appl. Acoust.}}, vol.~66, no.~2,
	pp. 211--229, 2005.
	
	\bibitem{Aletta2018}
	\BIBentryALTinterwordspacing
	F.~Aletta, \emph{et~al.}, ``{The relationship between noise sensitivity and
		soundscape appraisal of care professionals in their work environment: a case
		study in Nursing Homes in Flanders, Belgium},'' in
	\emph{{Proc. Euro-Noise}}, 2018.
	
	\bibitem{Ratcliffe2021}
	E.~Ratcliffe, ``{Sound and Soundscape in Restorative Natural Environments: A
		Narrative Literature Review.}'' \emph{{Front.
			Psychol.}}, vol.~12, p. 570563, 2021.
	
	\bibitem{Mitchell2020TheInformation}
	A.~Mitchell, \emph{et~al.}, ``{The Soundscape Indices (SSID) Protocol: A Method
		for Urban Soundscape Surveys — Questionnaires with Acoustical and
		Contextual Information},'' \emph{{Appl. Sci.}},
	vol.~10, no. 2397, pp. 1--27, 2020.
	
	\bibitem{Preis2015}
	A.~Preis and H.~Hafke-dys, ``{Audio-visual interactions in environment
		assessment},'' \emph{{Sci. Total.
			Environ.}}, vol. 523, pp. 191--200, 2015.
	
	\bibitem{PuyanaRomero2016}
	\BIBentryALTinterwordspacing
	V.~Puyana~Romero, \emph{et~al.}, ``{Modelling the soundscape quality of urban
		waterfronts by artificial neural networks},''
	\emph{{Appl. Acoust.}}, vol. 111, pp. 121--128,
	2016.
	\BIBentrySTDinterwordspacing
	
	\bibitem{Tan2022TheCity}
	\BIBentryALTinterwordspacing
	J.~K.~A. Tan, \emph{ et~al.}, ``{The effects of visual landscape and traffic
		type on soundscape perception in high-rise residential estates of an urban
		city},'' \emph{{Appl. Acoust.}}, vol. 189, p.
	108580, 2022.
	\BIBentrySTDinterwordspacing
	
	\bibitem{Watcharasupat2022AutonomousGain}
	\BIBentryALTinterwordspacing
	K.~N. Watcharasupat, \emph{ et~al.}, ``{Autonomous In-Situ Soundscape
		Augmentation via Joint Selection of Masker and Gain},''
	\emph{{IEEE Signal Process. Lett.}}, pp. 1--5, 2022.
	\BIBentrySTDinterwordspacing
	
	\bibitem{Baltrusaitis2019MultimodalTaxonomy}
	T.~Baltrusaitis, C.~Ahuja, and L.~P. Morency, ``{Multimodal Machine Learning: A
		Survey and Taxonomy},'' \emph{{IEEE Transactions
			Pattern Analysis and Mach. Intell.}}, vol.~41, no.~2, pp. 423--443,
	2019.
	
	\bibitem{Okazaki2021AVariants}
	S.~Okazaki, Q.~Kong, and T.~Yoshinaga, ``{A Multi-Modal Fusion Approach for
		Audio-Visual Scene Classification Enchanced by CLIP Variants},'' in
	\emph{{6th Workshop Detect. Classif.
			Acoust. Scenes Events}}, 2021, pp. 1--4.
	
	\bibitem{Naranjo-Alcazar2021Squeeze-ExcitationClassification}
	\BIBentryALTinterwordspacing
	J.~Naranjo-Alcazar, \emph{et~al.}, ``{Squeeze-Excitation Convolutional
		Recurrent Neural Networks for Audio-Visual Scene Classification},'' in
	\emph{{6th Workshop Detect. Classif.
			Acoust. Scenes Events}}, 2021, pp. 16--20.
	
	\bibitem{Priyasad2020AttentionRecognition}
	D.~Priyasad, \emph{ et~al.}, ``{Attention Driven Fusion for Multi-Modal Emotion
		Recognition},'' in \emph{{Proc. IEEE ICASSP}},
	2020, pp. 3227--3231.
	
	\bibitem{Ma2019AttnSense:Recognition}
	H.~Ma, \emph{ et~al.}, ``{AttnSense: Multi-level attention mechanism for
		multimodal human activity recognition},'' in
	\emph{{Int. Jt. Conf. Artif.
			Intell.}}, 2019, pp. 3109--3115.
	
	\bibitem{Lionello2020ASoundscapes}
	M.~Lionello, F.~Aletta, and J.~Kang, ``{A systematic review of prediction
		models for the experience of urban soundscapes},''
	\emph{{Appl. Acoust.}}, vol. 170, p. 107479, 2020.
	
	\bibitem{Huang2017AuditorySoundscapes}
	\BIBentryALTinterwordspacing
	N.~Huang and M.~Elhilali, ``{Auditory salience using natural soundscapes},''
	\emph{{The J. Acoust. Soc.
			Am.}}, vol. 141, no.~3, pp. 2163--2176, 2017.
	\BIBentrySTDinterwordspacing
	
	\bibitem{Ooi2022ProbablyAugmentation}
	K.~Ooi, \emph{et~al.}, ``{Probably Pleasant? A Neural-Probabilistic Approach to
		Automatic Masker Selection for Urban Soundscape Augmentation},'' in
	\emph{{Proc. IEEE ICASSP 2022}}, 2022, p.~5.
	
	\bibitem{Chen2015Multi-modalNetworks}
	S.~Chen and Q.~Jin, ``{Multi-modal dimensional emotion recognition using
		recurrent neural networks},'' \emph{{Proc.
			5th Int. Workshop Audio/Visual Emot. Chall.}}, pp. 49--56,
	2015.
	
	\bibitem{Ooi2022ARAUS:Soundscapes}
	\BIBentryALTinterwordspacing
	K.~Ooi, \emph{et~al.}, ``{ARAUS: A Large-Scale Dataset and Baseline Models of
		Affective Responses to Augmented Urban Soundscapes},'' Tech. Rep., 2022.
	[Online]. Available: \url{https://arxiv.org/abs/2207.01078v2}
	\BIBentrySTDinterwordspacing
	
	\bibitem{DeCoensel2017UrbanMind}
	B.~De~Coensel, K.~Sun, and D.~Botteldooren, ``{Urban Soundscapes of the World:
		Selection and reproduction of urban acoustic environments with soundscape in
		mind},'' in \emph{{Proc. Inter-Noise}}, 2017.
	
	\bibitem{Ooi2021AutomationHead}
	\BIBentryALTinterwordspacing
	K.~Ooi, \emph{et~al.}, ``{Automation of binaural headphone audio calibration on
		an artificial head},'' \emph{{MethodsX}}, vol.~8, no.
	February, pp. 1--12, 2021.
	\BIBentrySTDinterwordspacing
	
	\bibitem{Weinstein1978}
	N.~D. Weinstein, ``{Individual differences in reactions to noise: A
		longitudinal study in a college dormitory},''
	\emph{{J. Appl. Psychol.}}, vol.~63, no.~4,
	pp. 458--466, 1978.
	
	\bibitem{Gamst1988DevelopmentScales}
	G.~Gamst, \emph{et~al.}, ``{Development and Validation of Brief Measures of
		Positive and Negative Affect: The PANAS Scales},''
	\emph{{J. Pers. Soc. Psychol.}},
	vol.~54, no.~6, pp. 1063--1070, 1988.
	
	\bibitem{Luong2015EffectiveTranslation}
	M.-T. Luong, H.~Pham, and C.~D. Manning, ``{Effective Approaches to
		Attention-based Neural Machine Translation},'' in
	\emph{{Proc. Conf. Empir.
			Methods Nat. Lang. Process.}}, 2015, pp. 471--482.
	
	\bibitem{Ricciardi2015SoundData}
	\BIBentryALTinterwordspacing
	P.~Ricciardi, \emph{et~al.}, ``{Sound quality indicators for urban places in
		Paris cross-validated by Milan data},'' \emph{{J.
			Acoust. Soc. Am.}}, vol. 138, no.~4, pp. 2337--2348,
	2015.
	\BIBentrySTDinterwordspacing
	
\end{thebibliography}

\end{document}
