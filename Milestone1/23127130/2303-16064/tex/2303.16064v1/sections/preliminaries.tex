\section{Preliminaries}
\label{sec:preliminaries}

% \subsection{Acronyms/Initialisms}
\input{sections/acronym}

\subsection{Notation}

% \urg{Fill in the notation}

The $n$-dimensional real Euclidean space is $\R^n$. The set of natural numbers is $\N$, and its subset of natural numbers between $1$ and $N$ is $1..N$. The set of $n$-multi-indices is $\N^n$. The degree of a multi-index $\alpha \in \N^n$ is $\abs{\alpha} = \sum_{i=1}^n \alpha_i$. 
A monomial is a term $x^\alpha = \prod_{i=1}^n x_i^{\alpha_i}$ with degree $\deg{x^\alpha} = \abs{\alpha}$. A polynomial $p(x) \in \R[x]$ may be uniquely represented in terms of multi-indices $\alpha$ and coefficients $p_\alpha$ as $p(x) = \sum_{\alpha \in \mathscr{J}} p_\alpha x^\alpha$ for some finite set $\mathscr{J} \in \N^n$. The degree of a vector of polynomials ($f \in (\R[x])^N$) is the maximum degree of any coordinate ($\deg f = \max_{i\in 1..N} \deg f_i$). The vector space of polynomials of degree at most $d$ is 
$\R[x]_{\leq d}$ and its dimension is $\binom{n+d}{d}$.
%The set of \ac{SOS} polynomials is $\Sigma[x],$ and its degree-$2d$-bounded subset is $\Sigma[x]_{\leq 2d} \subset \R[x]_{\leq 2d}$. 
The \acf{SOC} (or Lorentz cone)  is $Q^n = \{(s, \kappa) \in \R^n \times \R_+: \ \kappa \geq \norm{s}_2\}$, where $\norm{s}_2 = (s_1^2 + \ldots + s_n^2)^{1/2}$ denotes the Euclidean norm.

The vector space of continuous functions over a topological space $X$ is $C(X)$, and its nonnegative subcone is $C_+(X)$. The topological dual of a Banach space $V$ is $V^*$. The cone of (nonnegative) Borel measures supported over $X$ is $\Mp{X}$ and the vector space of signed Borel measures supported on $X$ is $\mathcal{M}(X) = \Mp{X} - \Mp{X}$. When $X$ is compact, $C(X)$ and $\mathcal{M}(X)$ are topological dual spaces that have a duality product by Lebesgue integration: for $f \in C(X), \ \mu \in \mathcal{M}(X)$ the duality product is $\inp{f}{\mu} = \int_{X} f(x) d \mu(x)$. This duality product also induces a duality pairing between $C_+(X)$ and $\Mp{X}$. As a slight abuse of notation, we extend this duality product to all Borel measurable functions $f$: $\inp{f}{\mu} = \int_X f(x) d\mu(x)$.
The set of $k$-times continuously differentiable functions over $X$ is $C^k(X)$.

The indicator function of a set $A \subseteq X$ is $I_A: X \rightarrow \{0, 1\}$, and has the values $I_A(x)=0$ for $x \not\in A$ and $I_A(x)=1$ for $x \in A$. The measure of $A$ with respect to $\mu \in \Mp{X}$ is defined as $\mu(A) = \inp{I_A}{\mu}$. The mass of a measure $\mu \in \Mp{X}$ is $\mu(X) = \inp{1}{\mu}$, and $\mu$ is a probability measure if this mass is 1. The support of a measure $\mu$ is the set of all points $x$ such that each open neighborhood $N_x$ of $x$ obeys $\mu(N_x) > 0$.
The Dirac delta $\delta_{x'}$ supported only at the point $x'$ is a probability measure such that $\inp{f}{\delta_{x'}} = f(x')$ for all $f \in C(X)$. Given two measures $\mu \in \Mp{X}$ and $\nu \in \Mp{Y}$, the product measure $\mu \otimes \nu$ is the unique measure that satisfies $\forall A \subseteq X, \ B \subseteq Y: \ (\mu \otimes \nu)(A \times B) = \mu(A) \nu(B)$. The pushforward of a function $Q: X \rightarrow Y$ along a measure $\mu(x)$ is $Q_\# \mu(y)$ and satisfies the relation $\forall g \in C(Y): \ \inp{g(y)}{Q_\# \mu(y)} = \inp{g(Q(x))}{\mu(x)}$.

% The pushforward of a map $Q: \rw{S}\rightarrow Y$ along a measure $\mu\rev{(\rw{s})}$ is $Q_\# \mu\rev{(y)}$, which satisfies 
% $\forall f \in C(Y): \ \inp{f(y)}{Q_\# \mu(y)} = \inp{f(Q(\rw{s}))}{\mu(\rw{s})}$.

The operator $\wedge$ will be used to denote the minimum of two quantities (stopping times) as $a \wedge b = \min(a,b)$. The adjoint of a linear operator $\Lie: X \rightarrow Y$ is $\Lie^\dagger: Y^* \rightarrow X^*$.

\subsection{Probability Tail Bounds and Value-at-Risk}

Let $\xi$ be a univariate probability measure $\xi(\omega) \in \Mp{\R}$ for a coordinate $\omega \in \R$, with $\inp{1}{\xi} = 1$ and $\abs{\inp{\omega}{\xi}}, \inp{\omega^2}{\xi} < \infty$ (finite first and second moments). 
In this paper, we define the $\epsilon$-\ac{VAR} of $\xi$ as follows:
%The $\epsilon$-\ac{VAR} of $\xi$ is the unique number $VaR_\epsilon(\xi)$  with \cite{jorion2000value}
%\begin{subequations}
%\begin{align}
%    &\textrm{Prob}_\xi{(\omega \geq VaR_\epsilon(\xi))} = \xi([VaR_\epsilon(\xi),\infty)) = \epsilon, \label{eq:var_center}
%\end{align}
\begin{align}
    &VaR_\epsilon(\xi) = \sup\left\{
    \lambda \in \R \; | \; \xi([\lambda,\infty)) \geq \epsilon
    \right\}. \label{eq:var_center}
\end{align}
%\end{subequations}
%     &\textrm{Prob}_\xi{(\omega - \inp{\omega}{\xi} \geq  VaR_\epsilon(\xi) - \inp{\omega}{\xi})} = \epsilon. \label{eq:var_shift}
%We will treat the $\epsilon$-\ac{VAR} and $(1-\epsilon)$-quantile statistic as indistinguishible concepts. 
Let $\sigma^2 = \inp{\omega^2}{\xi} - \inp{\omega}{\xi}^2$ be the variance of the probability distribution $\xi$.
\begin{subequations}
\label{eq:tail_bounds}
\begin{align}
\intertext{The Cantelli bound  for \ac{VAR} is \cite{cantelli1929sui}} 
    VaR_\epsilon(\xi) &\leq \sigma \sqrt{1/(\epsilon)- 1}+\inp{\omega}{\xi} = VaR_\epsilon^{cant}(\xi). \label{eq:var_cant}\\    \intertext{
    The \ac{VP} bound for the \ac{VAR} is \cite{vysochanskij1980justification}}
    VaR_\epsilon(\xi) &\leq \sigma \sqrt{4/(9\epsilon) - 1} +\inp{\omega}{\xi}= VaR_\epsilon^{VP}(\xi). \label{eq:var_vp}
\end{align}
\end{subequations}
%mercadier2021one

The Cantelli bound is applicable for any probability distribution $\xi(\omega)$ and value $\epsilon \in [0, 1].$ The \ac{VP} bound is sharper than the Cantelli bound, but is only valid when  $\xi$ is unimodal and $\epsilon \leq 1/6$.



\subsection{Stochastic Differential Equations}

Let $(\Omega, \mathcal{F}, \mathcal{P})$ be a probability space with time-indexed filtration $\mathcal{F}_t$,  $X \subset \R^n$  be a compact set, and $w$ be $n$-dimensional Wiener process.
An \ito \ac{SDE} with a drift function $f$ and diffusion function $g$ is \cite{gardiner2009stochastic}
% Let $x(t)$ follow an It\^{o} SDE where $w$ represents brownian motion (Wiener process),
\begin{equation}
\label{eq:sde}
    dx = f(t, x) dt + g(t, x) dw.
\end{equation}

In this paper, trajectories will start from an initial set $X_0 \subseteq X$ and will remain within $X$ in times $t \in [0, T]$ by virtue of stopping at the boundary $\partial X$.
Define $\tau_X$ as a stopping time (random variable) corresponding to the time at which the process \eqref{eq:sde} starting from $X_0$ first touches the boundary $\partial X$ for the first time. A process of \eqref{eq:sde} starting from an initial condition $x(0) \in X_0$ in times $t \in [0, T]$ is
\begin{equation}
\label{eq:sde_sol}
    x(t) = x(0) + \int_{t=0}^{\tau_X \wedge T} f(t, x) dt + \int_{t=0}^{\tau_X \wedge T} g(t, x) dw.
\end{equation}
 
 Solutions of \eqref{eq:sde_sol} are unique if there exists finite constants $C, D > 0$ such that for all $(t, x, x') \in [0, T] \times X^2$,  the following Lipschitz and Growth conditions hold \cite{oksendal2003stochastic}:
 \begin{align}
    D \norm{x-x'}_2 &\geq \norm{f(t,x)-f(t,x')}_2 + \norm{g(t, x)-g(t,x')}_2  \nonumber \\
     C (1+\norm{x}_2) & \geq \norm{f(t,x)}_2 + \norm{g(t, x)}_2. \label{eq:lip_growth}
 \end{align}
The Lipschitz and Growth conditions will hold if $(f,g)$ are locally Lipschitz and the set $X$ is compact.
Distributions of the densities of \eqref{eq:sde_sol} may be computed by solving a Fokker-Planck equation with absorbing boundary conditions on $\partial X$ \cite{furth1917einige, hwang2014fokker}.
 
The generator $\Lie$ associated with the \ac{SDE} is a linear operator that satisfies $\forall v(t,x) \in C^2([0, T] \times X)$ \cite{oksendal2003stochastic}:
%  For every function $v \in C^2([0, T] \times X)$,  in \eqref{eq:sde} satisfies,
\begin{equation}
\label{eq:lie}
    \Lie v(t, x) = \partial_t v + f(t, x) \cdot \nabla_x v + \frac{1}{2} g(t, x)^T \left(\nabla^2_{xx}v\right)  g(t, x).
\end{equation}
 
The $\nabla_{xx}^2 v$ term arises from the \ito Lemma. Let $\tau$ be a stopping time adapted to the filtration, defined by $\tau = \tau_X \wedge T$. The occupation measure $\mu \in \Mp{[0, T] \times X}$ corresponding to the stopping time $\tau$, initial distribution $\mu_0 \in \Mp{X_0}$, and dynamics \eqref{eq:sde} is $\forall A \subseteq [0, T], \  B \subseteq X$ is 
\begin{equation}
    \label{eq:avg_free_occ}
    \mu(A \times B) = \int_{X_0} \int_{t=0}^\tau  I_{A \times B}\left((t, x(t \mid x_0))\right) dt \, d\mu_0(x_0).
\end{equation}

The initial measure $\mu_0 \in \Mp{X_0}$, the occupation measure $\mu$ from  \eqref{eq:avg_free_occ}, and the terminal measure $\mu_\tau \in \Mp{[0, T] \times X}$ defined by following the \ac{SDE} \eqref{eq:sde} from initial conditions $x_0 \sim \mu_0$ until the stopping time $\tau$, are all related by Dynkin's formula \cite{dynkin1965markov}
\begin{align}
\label{eq:dynkin_strong}
    \inp{v}{\mu_\tau} &= \inp{v(0, x)}{\mu_0(x)} + \inp{\Lie v}{\mu} & & \forall v \in C^2.
\end{align}

Dynkin's formula is an \ac{SDE} generalization of the Liouville equation for \acp{ODE}. Equation \eqref{eq:dynkin_strong} may be equivalently written in weak form as
\begin{align}
    \mu_\tau &= \delta_{0} \otimes \mu_0 + \Lie^\dagger \mu. \label{eq:dynkin}
\end{align}
 
 
An expectation-maximizing optimal stopping problem for the \ac{SDE} in \eqref{eq:sde} with a reward function of $p(x)$ in the region $[0, T] \times X$, when starting at the initial condition $x(0)\sim\mu_0 \in \Mp{X_0}$, is $P^* = \sup \E_{\mu_0}[p(x(\tau))]$. The work in \cite{cho2002linear} presents an infinite-dimensional \ac{LP} in measures to solve this stopping problem
\begin{subequations}
\label{eq:peak_meas}
\begin{align}
p^* = & \ \sup \quad \inp{p}{\mu_\tau} \label{eq:peak_meas_obj} \\
    & \mu_\tau = \delta_0 \otimes\mu_0 + \Lie^\dagger \mu \label{eq:peak_meas_flow}\\
    & \inp{1}{\mu_0} = 1 \label{eq:peak_meas_prob}\\
    & \mu, \mu_\tau \in \Mp{[0, T] \times X} \label{eq:peak_meas_peak}\\
    & \mu_0 \in \Mp{X_0}. \label{eq:peak_meas_init}
\end{align}
\end{subequations}

Any $\mu$ that is part of a feasible solution $(\mu, \mu_0, \mu_\tau)$ for \eqref{eq:peak_meas_flow}-\eqref{eq:peak_meas_init} will be referred to as a \textit{relaxed} occupation measure. Program \eqref{eq:peak_meas} satisfies $p^* \geq P^*$, and tightness $(p^*=P^*)$ is achieved under the assumptions of  Lipschitz continuity and Growth \eqref{eq:lip_growth}, compactness of $[0, T] \times X$, and continuity of $p(x)$.


 
% Compare \acp{ODE} and \acp{SDE}. \ito integral, \itos Lemma.

% Possibly talk about the Fokker-Planck equation.

% \subsection{Occupation Measures and Peak Estimation}

% Definition of an Occupation measure for an \ac{SDE}

% Dynkin's rule using \itos lemma. We need to be consistent about generators and the factor of 1/2 in \itos Lemma.

% Presentation of peak-expectation program


% % \subsection{Sum of Squares}
% % \urg{Fill in \ac{SOS} background for proofs of polynomial nonnegativity}

% % Putinar Psatz \cite{putinar1993compact}


% Scherer Psatz for Matrices \cite{scherer2006matrix}

