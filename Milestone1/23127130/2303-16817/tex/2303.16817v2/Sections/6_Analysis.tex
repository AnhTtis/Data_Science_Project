\section{Analyses of adaptive superpixels}
\iffalse
We propose novel achievable metrics to explore the suitable superpixels for active learning (Section~\ref{sec:confusion-matrix}).
% These metrics aid in the understanding of suitable superpixels in active learning.
In addition, we conduct quantitative analyses of adaptive superpixels under varying $\epsilon$ (Section~\ref{sec:merging-criteria}).
All analyses are conducted on Cityscapes with an average superpixel size of 256 pixels.
% , and propose novel evaluation metrics that leverages the concept of confusion matrix between superpixels (Sec. \ref{sec:confusion-matrix}). 
% These metrics aid in the understanding of suitable superpixels in active learning.
% All analyses are conducted on Cityscapes images with an average superpixel size of 256.
\fi
We propose new evaluation metrics to measure the quality of superpixel as a labeling unit for active segmentation, and utilize it to analyze our adaptive superpixels (Section~\ref{sec:confusion-matrix}).
We also conduct analyses about the effect $\epsilon$ to our adaptive superpixels (Section~\ref{sec:merging-criteria}).
All analyses are conducted on Cityscapes with an average superpixel size of 256 pixels.

%  "SEEDS-8192": "superpixels/cityscapes/seeds_8192/train/eval",
%  "SLIC-8192": "superpixels/cityscapes/slic_8192/train/eval",
%  "Merged": "superpixels/cityscapes/8192_50k_v1_1_0.1_n/batch_0/eval",
%  "Merged*": "superpixels/cityscapes/fully_supervised_0.1/batch_4/eval",
%  "Merged**": "superpixels/cityscapes/8192_50k_v1_1/batch_4/eval",
%  "Oracle": "superpixels/cityscapes/gt+cc/train_eval"

% method,"AP(S,G)","AR(S,G)","AF(S,G)","AP(G,S)","AR(G,S)","AF(G,S)"
% SEEDS-8192,0.9685278763157271,0.00944764185694861,0.015103662987981875,0.38984238812341504,0.6600796465570821,0.30383087714682183
% SLIC-8192,0.9669473415289306,0.009415040831816318,0.015099003350290411,0.3906495849442768,0.639211928803373,0.2869039011117395
% Merged,0.8865089939003424,0.05117077851397858,0.07443633838756358,0.557199300697873,0.4446767314247057,0.32516267833525603
% Merged*,0.8764754579460934,0.05679783920008234,0.07938870496244818,0.5960247899504775,0.4560895306795322,0.35717680061132884
% Merged**,0.8808070747209297,0.05421189109551843,0.07568508168660537,0.609627614057426,0.42518010038050813,0.3380525082597775

%('SEEDS-8192', 0.9690463904372785),
% ('SLIC-8192', 0.9650739536766244),
% ('Merged', 0.8770279046066669),
% ('Merged*', 0.8560000140727068),
% ('Merged**', 0.8508005807379715)]




% \omh{
% In Table \ref{tab:merging-methods}, we evaluate different merging criteria. Consider a superpixel $s$ is merged to $s'$. We say that $s$ is merged correctly if $\text{D}(s)=\text{D}(s')$. It is apparent that using ground-truth, all superpixels are merged correctly. Using pseudo dominant label shows worst quality of merging. This is because ... JSD outperforms ED. Why?
% }

%We count the number of superpixels that change in their dominant label due to merging and that remain unchanged.
% In Table \ref{tab:merging-methods}, we
% However, since the model is incomplete, superpixels with different dominant labels may still be merged.
% We study the accuracy of the merging in various scenarios, including region size, number of rounds, and merging methods.
% We study the accuracy of merging under various situations, considering merging methods and $\epsilon$.
% Our algorithm is critically dependent on the hyperparameter $\epsilon$, which is used for merging.
% and the sieving technique allows us to control the quality of labels, resulting in robustness across a wide range of $\epsilon$.
% Additionally, the sieving technique can be advantageous under the large initialized superpixels that often comprise a mixture of different classes.
% We merge superpixels that are closer than a specified threshold $\epsilon$ into a single superpixel using an embedded space, i.e., the softmax output of a trained model.

\begin{table*}[!t]
  \centering
  \setlength\tabcolsep{4pt}
  \begin{tabular}{l|cc|ccc|ccc|c}
    \toprule
    Methods & ASA$(S;G)$ & ASA$(G;S)$ & AP$(S;G)$ & AR$(S;G)$ & AF$(S;G)$ & AP$(G;S)$ & AR$(G;S)$ & AF$(G;S)$ & mIoU \\ 
    \midrule
    $\text{SLIC}_{4096}$ & 0.887 & 0.082 & 0.897 & 0.046 & 0.066 & 0.695 & 0.259 & 0.185 & 53.18 \\
    $\text{SEEDS}_{4096}$ & 0.909 & 0.082 & 0.900 & 0.050 & 0.070 & 0.665 & 0.309 & 0.221 & 57.61 \\
    $\text{SLIC}_{256}$ & 0.956 & 0.013 & 0.958 & 0.007 & 0.012 & 0.400 & 0.622 & 0.278 & 58.04 \\
    $\text{SEEDS}_{256}$ & 0.961 & 0.014 & 0.960 & 0.007 & 0.012 & 0.395 & 0.647 & 0.297 & 58.97 \\
    \rowcolor{Gray}
    $\text{Merged}_2$ & 0.898 & 0.515 & 0.883 & 0.042 & 0.063 & 0.553 & 0.472 & 0.333 & \underline{60.00} \\
    \rowcolor{Gray}
    $\text{Merged}_4$ & 0.898 & 0.496 & 0.883 & 0.042 & 0.062 & 0.548 & 0.484 & 0.340 & \textbf{61.36} \\
    \midrule
    $\text{Merged}^*$ & 0.899 & 0.597 & 0.880 & 0.045 & 0.066 & 0.547 & 0.510 & 0.359 & 61.85 \\
    Oracle & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 70.81 \\
    \bottomrule
  \end{tabular}
  % \caption{{\em Evaluation metrics of superpixels.} Superpixels are generated using SLIC \cite{achanta2012slic} and SEEDS \cite{van2012seeds}, with the subscript indicating the average size of superpixels. Our merged superpixels are evaluated, with the subscript value implying the round that used the superpixels and * representing full supervision. To compute the mIoU, we train a model with 100k randomly selected superpixels.}
  \caption{{\em Evaluation metrics of superpixels.}
  % Superpixel quality is measured by various evaluation metrics, where each superpixel is generated from  SLIC~\cite{achanta2012slic}, SEEDS~\cite{van2012seeds}, our adaptive merging (Merged), and the ground-truth (Oracle).
  The subscript indicates the average size of the superpixel for SLIC~\cite{achanta2012slic} and SEEDS~\cite{van2012seeds}, while it indicates the round for Merged.
  $\text{Merged}^*$ indicates superpixel merged by a model trained with full supervision.
  To compute the mIoU, we train a model with 100k randomly selected superpixels.}
  \label{tab:quantitative}
  % \vspace{-3mm}
\end{table*}




\subsection{Achievable metrics}
\label{sec:confusion-matrix}
\iffalse
Superpixels are evaluated by various metrics, but to our best knowledge, all metrics are related to the degree of over-segmentation.
For instance, achievable segmentation accuracy (ASA) \cite{liu2011entropy} measures the segmentation accuracy when each superpixel $s \in S$ is assigned to the corresponding dominant label, which is the ground-truth of the oracle superpixel $g \in G$ with the highest overlap. The ASA is calculated as follows:
\begin{equation}
\text{ASA}(S; G) := \frac{\sum_{s \in S} \max_g |s \cap g|}{\sum_{s \in S} |s|} \;,
\end{equation}
where $S$ and $G$ represent the generated and oracle superpixels from the same image, respectively. 
As an image becomes more over-segmented, \ie., the superpixel size becomes smaller, the ASA value increases. 
However, active learning aims to achieve the maximum benefit with the least amount of labeling effort, and therefore, the number of labels should be taken into account. 
Additionally, the ASA is heavily biased towards classes with a relatively large number of pixels.
\fi
While various evaluation metrics for superpixel are presented~\cite{giraud2017robust,liu2011entropy,machairas2014waterpixels,schick2012measuring,van2012seeds}, most of them aims to measure the quality of over-segmentation.
For instance, achievable segmentation accuracy (ASA) \cite{liu2011entropy} measures
the segmentation accuracy when each superpixel $s \in S$ is associated with the oracle superpixel with the largest overlap.
% the segmentation precision when each superpixel $s \in S$ is associated with the oracle superpixel with the largest overlap.
The ASA is calculated as follows:
\begin{equation}
\text{ASA}(S; G) := \frac{\sum_{s \in S} \max_{g \in G} |s \cap g|}{\sum_{s \in S} |s|} \;,
\end{equation}
where $S$ and $G$ represent the generated and oracle superpixels from the same image, respectively. 
As an image becomes more over-segmented, \ie., the superpixel size becomes smaller, the ASA value increases. 
However, active learning (AL) aims to achieve the maximum benefit with the least amount of labeling effort, and therefore, the number of labels should be taken into account. 
In addition, the ASA is heavily biased towards classes with a large number of pixels.




In order to measure the suitability of superpixels for AL, we introduce precision and recall between generated and oracle superpixels. 
A generated superpixel can be viewed as positive on the inside and negative on the outside, and its precision and recall with respect to the corresponding oracle one can be calculated.
For all generated superpixels, we define the achievable precision (AP) as follows:
\begin{equation}
\text{AP}(S;G) := \frac{1}{|S|} \sum_{s \in S} \frac{\max_{g \in G} |s \cap g|}{|s|} \;,
\end{equation}
where the summation is performed in superpixels, unlike in ASA, which implies pixel-wise precision.
As we put the same weight on each superpixel, AP is less influenced by large objects than ASA.
We note that AP is different to average precision \cite{everingham2009pascal, salton1983introduction}, used in object detection, which utilize the precision and recall curve.
We also define the achievable recall (AR) and F1-score (AF) as:
\begin{equation}
\text{AR}(S;G) := \frac{1}{|S|} \sum_{s \in S} \frac{\max_{g \in G} |s \cap g|}{|g'(s; G)|} \;, 
\end{equation}
\begin{equation}
\text{AF}(S;G) := \frac{2}{|S|} \sum_{s \in S} \frac{\max_{g \in G} |s \cap g|}{|s| + |g'(s; G)|} \;,
\end{equation}
where $g'(s; G) := \argmax_{g \in G} \left|s \cap g \right|$ 
%(\omh{$g'_j := \argmax_{g_j\in G} \left|s_i \cap g_j\right|$})
refers to the corresponding oracle superpixel.
Details are in Appendix \ref{fig:sup-metrics}.

\begin{figure}[!t]
    % \captionsetup[subfigure]{font=scriptsize,labelfont=scriptsize,aboveskip=0.05cm,belowskip=-0.15cm}
    \centering
    \hspace{-5mm}
    \begin{subfigure}{.47\linewidth}
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                legend style={nodes={scale=0.35}, at={(0.03, 0.24)}, anchor=west}, 
                xlabel={ASA$(S;G)$},
                ylabel={mIoU (\%)},
                width=1.23\linewidth,
                height=1.23\linewidth,
                ymin=50.8,
                ymax=63.2,
                ytick={51, 53, 55, 57, 59, 61, 63},
                xlabel style={yshift=0.15cm},
                % ylabel style={yshift=-0.6cm},
                ylabel style={yshift=-0.2cm},
                legend columns=2,
                xmin=0.882,
                xmax=0.967,
                label style={font=\scriptsize},
                tick label style={font=\scriptsize},
                x tick label style={
                    /pgf/number format/.cd,
                        fixed,
                }
            ]
            \addplot[cdeepBP, only marks] table[col sep=comma, x=ASASG, y=mIoU]{Data/correlation_asasg.csv};
            \addplot[very thick, orange] table[col sep=comma, x=ASASG, y={create col/linear regression = {y=mIoU}}
            ]{Data/correlation_asasg.csv};
            \draw (0.5\linewidth, 0.35\linewidth) node {\scriptsize$\text{Corr} = 0.05$};
            \end{axis}
        \end{tikzpicture}
        % \caption{ASA(S;G) vs mIoU}
    \end{subfigure}
    \hspace{1mm}
    \begin{subfigure}{.47\linewidth}
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                legend style={nodes={scale=0.35}, at={(0.03, 0.24)}, anchor=west}, 
                xlabel={AF$(G;S)$},
                ylabel={mIoU (\%)},
                width=1.23\linewidth,
                height=1.23\linewidth,
                ymin=50.8,
                ymax=63.2,
                xlabel style={yshift=0.15cm},
                % ylabel style={yshift=-0.6cm},
                ylabel style={yshift=-0.2cm},
                ytick={51, 53, 55, 57, 59, 61, 63},
                legend columns=2,
                xmin=0.174,
                xmax=0.371,
                label style={font=\scriptsize},
                tick label style={font=\scriptsize},
                x tick label style={
                    /pgf/number format/.cd,
                        fixed,
                }
            ]
            \addplot[cdeepBP, only marks] table[col sep=comma, x=AFGS, y=mIoU]{Data/correlation_afgs.csv};
            \addplot[very thick, orange] table[col sep=comma, x=AFGS, y={create col/linear regression = {y=mIoU}}
            ]{Data/correlation_afgs.csv};
            \draw (0.5\linewidth, 0.35\linewidth) node {\scriptsize$\text{Corr}=0.95$};
            \end{axis}
        \end{tikzpicture}
    \end{subfigure}
    \caption{{\em Relationship between metrics and mIoU.} The correlation between ASA$(S;G)$ and mIoU is low, while the correlation between AF$(G;S)$ and mIoU is high. For the correlation calculation, \textit{Oracle} in Table \ref{tab:quantitative} is excluded.}
    % \caption{{\em Relationship between metrics and mIoU.}
    % \hsh{mIoU of actively learned model using superpixels versus the quality of the corresponding superpixels measured with ASA~\cite{liu2011entropy} and proposed achievable F1-score (AF).}}
    \label{fig:co-relation}
    % \vspace{-4mm}
\end{figure}







All the metrics evaluate generated superpixels in comparison to oracle ones. 
However, the size of superpixels is also important besides their quality in AL.
Therefore, it is necessary to evaluate the oracle superpixels against the generated superpixels, \ie., ASA$(G;S$), AP$(G;S)$, AR$(G;S)$ and AF$(G;S)$. We hence propose AF$(G;S)$
%which is the harmonic mean of   AP$(G;S)$, AR$(G;S)$, 
defined as:
\begin{equation}
\text{AF}(G;S) := \frac{2}{|G|} \sum_{g \in G} \frac{\max_{s \in S} |g \cap s|}{|g| + |s'(g; S)|} \;,
\end{equation}
where $s'(g; S) := \argmax_{s \in S} \left|g \cap s \right|$ refers to the generated superpixel with the highest overlap, which is linked to the maximum amount of labeling we receive.
Table~\ref{tab:quantitative} evaluates various superpixels through eight metrics.
Although our merged superpixels have a relatively low ASA$(S;G)$, they exhibit high ASA$(G;S)$ and AF$(G;S)$.
% Qualitative results for metrics are in Appendix \ref{fig:sup-qual}. 
% Fig.~\ref{fig:qualitative}

% \begin{figure*}[h!]
%     \captionsetup[subfigure]{font=normalsize}
%     \centering
%     \begin{subfigure}[h!]{.24\linewidth}
%         \centering
%         \includegraphics[scale=0.08]{Figures/cityscapes_merged_round1.jpg}
%     \end{subfigure}
%     \hspace{-1mm}
%     \begin{subfigure}[h!]{.24\linewidth}
%         \centering
%         \includegraphics[scale=0.08]{Figures/cityscapes_merged_round1.jpg}
%     \end{subfigure}
%     \hspace{-1mm}
%     \begin{subfigure}[h!]{.24\linewidth}
%         \centering
%         \includegraphics[scale=0.08]{Figures/cityscapes_merged_round1.jpg}
%     \end{subfigure}
%     \begin{subfigure}[h!]{.24\linewidth}
%         \centering
%         \includegraphics[scale=0.08]{Figures/cityscapes_merged_round1.jpg}
%     \end{subfigure}
%     \hspace{-1mm}

%     \begin{subfigure}[h!]{.24\linewidth}
%         \centering
%         \includegraphics[scale=0.08]{Figures/cityscapes_merged_round1.jpg}
%     \end{subfigure}
%     \hspace{-1mm}
%     \begin{subfigure}[h!]{.24\linewidth}
%         \centering
%         \includegraphics[scale=0.08]{Figures/cityscapes_merged_round1.jpg}
%     \end{subfigure}
%     \hspace{-1mm}
%     \begin{subfigure}[h!]{.24\linewidth}
%         \centering
%         \includegraphics[scale=0.08]{Figures/cityscapes_merged_round1.jpg}
%     \end{subfigure}
%     \begin{subfigure}[h!]{.24\linewidth}
%         \centering
%         \includegraphics[scale=0.08]{Figures/cityscapes_merged_round1.jpg}
%     \end{subfigure}
%     \hspace{-1mm}

%     \captionsetup[subfigure]{font=scriptsize,labelfont=scriptsize,aboveskip=0.05cm,belowskip=-0.15cm}
%     \begin{subfigure}{.24\linewidth}
%         \begin{tikzpicture}
%             \begin{axis}[
%                 area style,
%                 scale only axis,
%                 ymin=0,
%                 legend pos=north west,
%                 width=0.8\linewidth,
%                 ymax=52,
%                 xlabel={The number of superpixels},
%                 ylabel={Counts},
%                 xlabel style={yshift=0.15cm},
%                 ylabel style={yshift=-0.6cm},
%                 label style={font=\scriptsize}
%             ]
%                 \addplot+[hist={bins=15, data max=470, data min=0}, fill=brown, draw=black, thin] table[col sep=comma, y=temp]{Data/dataset_hist.csv};
%             \end{axis}
%         \end{tikzpicture}
%         \caption{Initial superpixels}
%     \end{subfigure}
%     \begin{subfigure}{.24\linewidth}
%         \begin{tikzpicture}
%             \begin{axis}[
%                 area style,
%                 scale only axis,
%                 ymin=0,
%                 legend pos=north west,
%                 width=0.8\linewidth,
%                 ymax=52,
%                 xlabel={The number of superpixels},
%                 ylabel={Counts},
%                 xlabel style={yshift=0.15cm},
%                 ylabel style={yshift=-0.6cm},
%                 label style={font=\scriptsize}
%             ]
%                 \addplot+[hist={bins=15, data max=470, data min=0}, fill=brown, draw=black, thin] table[col sep=comma, y=temp]{Data/dataset_hist.csv};
%             \end{axis}
%         \end{tikzpicture}
%         \caption{Initial superpixels}
%     \end{subfigure}
%     \begin{subfigure}{.24\linewidth}
%         \begin{tikzpicture}
%             \begin{axis}[
%                 area style,
%                 scale only axis,
%                 ymin=0,
%                 legend pos=north west,
%                 width=0.8\linewidth,
%                 ymax=52,
%                 xlabel={The number of superpixels},
%                 ylabel={Counts},
%                 xlabel style={yshift=0.15cm},
%                 ylabel style={yshift=-0.6cm},
%                 label style={font=\scriptsize}
%             ]
%                 \addplot+[hist={bins=15, data max=470, data min=0}, fill=brown, draw=black, thin] table[col sep=comma, y=temp]{Data/dataset_hist.csv};
%             \end{axis}
%         \end{tikzpicture}
%         \caption{Initial superpixels}
%     \end{subfigure}
%     \begin{subfigure}{.24\linewidth}
%         \begin{tikzpicture}
%             \begin{axis}[
%                 area style,
%                 scale only axis,
%                 ymin=0,
%                 legend pos=north west,
%                 width=0.8\linewidth,
%                 ymax=52,
%                 xlabel={The number of superpixels},
%                 ylabel={Counts},
%                 xlabel style={yshift=0.15cm},
%                 ylabel style={yshift=-0.6cm},
%                 label style={font=\scriptsize}
%             ]
%                 \addplot+[hist={bins=15, data max=470, data min=0}, fill=brown, draw=black, thin] table[col sep=comma, y=temp]{Data/dataset_hist.csv};
%             \end{axis}
%         \end{tikzpicture}
%         \caption{Initial superpixels}
%     \end{subfigure}
%     \caption{{\em Distribution of the number of superpixels.} As round }
%     \label{fig:distribution}
% \end{figure*}



\smallskip\noindent\textbf{Correlation of metrics and mIoU.}
\iffalse
The selection of a suitable superpixel algorithm or superpixels is crucial for superpixel-based active learning. 
Given several available superpixels as shown in Table~\ref{tab:quantitative}, we randomly choose 100k superpixels to train a model and measure the resulting mIoU.
As observed by the strong correlation between AF$(G;S)$ and mIoU in Figure~\ref{fig:co-relation}, one can utilize superpixels with high AF$(G;S)$ values for the initial pool in active learning.
Further details are provided in the appendix.
\fi
To show the proposed metric can accurately evaluate the superpixel quality for active segmentation, we measure the correlation between various evaluation metric and the performance of actively learned model in Table~\ref{tab:quantitative} and Figure~\ref{fig:co-relation}.
We observe that the proposed AF$(G;S)$ shows the highest correlation to the performance of the actively learned model.
We except AF$(G;S)$ can select suitable superpixel algorithm for active learning, where the details are provided in Appendix \ref{fig:sup-metrics}.
% and determine a $\epsilon$ for merging in our algorithm with some validation images. 




% Average Precision (AP)
% \begin{equation}
% \text{AP}(G;S) : \frac{1}{|G|} \sum_{g_i \in G} \frac{\max_j |g_i \cap s_j|}{|g_i|} \;,
% \end{equation}

% ASA$(S;G)$ is an important metric in the literature of superpixel generation, however, it is 
% we note that the objective of active learning is to achieve the greatest gain with a single click.
% Thus, we suggest a measure of how many regions are labeled with a single click for each oracle superpixel $g$ as:
% \begin{equation}
% \text{ASA}(G ; S) = \frac{\sum_{g_j \in G} \max_i |s_i \cap g_j|}{\sum_{g_j \in G} |g_j|} \;.
% \end{equation}
% Note that both metrics have the same denominator.
% For a simplicity, we suggest the average of ASA (AASA) as:
% \begin{equation}
% \text{AASA}(S, G) = \frac{\text{ASA}(S;G) + \text{ASA}(G;S)}{2} \;.
% \end{equation}
% In Table 







\subsection{Ablation studies on epsilon} 
% Ablation studies on epsilon
\label{sec:merging-criteria}


\smallskip\noindent\textbf{Epsilon sensitivity.}
\iffalse
We evaluate the sensitivity of our method to the choice of $\epsilon$, which determines the amount of the merging process.
% Furthermore, our algorithm generates distinct superpixels depending on the value of $\epsilon$. 
% Similar to the superpixel size, a large epsilon increases the number of labels by boosting the average size of the superpixels, while a small epsilon improves the quality of the labels by reducing the number of incorrect merges. 
In Figures~\ref{fig:(c)-robustness} and \ref{fig:(d)-robustness}, we observe that our merging approach not only exhibits robustness to $\epsilon$ but also outperforms the baseline over a wide range of $\epsilon$.
\fi
In Figures~\ref{fig:(c)-robustness} and \ref{fig:(d)-robustness}, we evaluate the sensitivity of our method to $\epsilon$, which determines the amount of the merging.
Proposed method show robustness to the change of $\epsilon$, where the change of mIoU is less than 2\% for both Citycapes and PASCAL when $\epsilon$ is between 0.05 and 0.2.
We observe that for every investigated $\epsilon$ values, \textit{AMSP+S} surpasses the performance of the previous art~\cite{cai2021revisiting}.

\smallskip\noindent\textbf{Adaptive epsilon.}
We fix $\epsilon$ to 0.10 in all quantitative experiments, but there may exist an optimal $\epsilon$ for each round. 
% To ensure a fair comparison, we exclude validation images from the experiments. 
% Nonetheless, 
% We analyze $\epsilon$ that maximizes the proposed AF$(G;S)$ metric for each round by assuming the existence of 10 validation images with fully pixel-wise annotations.
% As the round progresses, the improvement of the model enables us to merge aggressively, which is related to the increase in $\epsilon$ that maximizes AF$(G;S)$ over the rounds in Table \ref{tab:adaptive-epsilon}.
In Table \ref{tab:adaptive-epsilon}, we analyze $\epsilon$ that maximizes AF$(G;S)$ metric for each round by assuming the existence of 10 validation images with ground truth. 
As the round increases, the optimal $\epsilon$ increases as well, which implies that the improvement of the model enables us to merge aggressively.





\smallskip\noindent\textbf{Effect of epsilon.}
\iffalse
% To merge superpixels, we should determine the similarity metric and proximity threshold $\epsilon$.
% In this study,
% We study the statistics of correct and incorrect merging under various $\epsilon$; 0.05, 0.10, and 0.15.
We study the statistics of correct and incorrect merging under various $\epsilon$.
% criteria by examining the statistics of correct and incorrect merging.
In addition, we adjust merging criteria including 
\textit{Ground Truth} using ground-truth to merge superpixels with the same dominant labels, 
\textit{Pseudo Label} merging superpixels with the same pseudo dominant labels from a model, 
\textit{Euclidean Distance} (ED) merging superpixels if their ED is less than $\epsilon$, and 
\textit{Jensen-Shannon Divergence} (JSD) merging superpixels if their JSD is less than $\epsilon$.
% We experiment with three values of $\epsilon$: 0.05, 0.10, and 0.1.
When a superpixel $s$ is merged to $s'$, we consider the merge to be correct if the dominant labels of $s$ and $s'$ are the same.
% \ie., $\text{D}(s)=\text{D}(s')$.
Table \ref{tab:merging-methods} presents the evaluation results of different merging criteria and $\epsilon$.
It is apparent that using ground-truth, all superpixels are merged correctly.
However, using pseudo labels leads to lower-quality merging as it ignores other minor classes.
Since we utilize the class distribution as a feature space, 
% in \eqref{eq:feature-space}, 
JSD proves to be more effective than ED.
As $\epsilon$ increases, the correct ratio decreases due to the aggressive merging of superpixels.
We emphasize that $\epsilon$ can determine the trade-off between the quantity and quality of labels.  
% For all subsequent experiments, we adopt JSD for similarity metric and set $\epsilon$ to 0.1.
% Table \ref{tab:merging-methods} presents the evaluation results of different merging criteria.
% \smallskip\noindent\textbf{Class-wise mIoU}
% adaptive merging vs merging
\fi
Table \ref{tab:merging-methods} presents the quality of the merging algorithm under various criteria, defining correctness based on the agreement of dominant labels in paired superpixels.
We merge a pair of superpixels when their ground-truth label is identical (Ground Truth), when their dominant top-1 model prediction is identical (Pseudo Label), and when the Euclidean Distance (ED) or Jensen-Shannon Divergence (JSD) of their averaged predictive probability is smaller than~$\epsilon$.
% 
% It is apparent that when using the ground truth, all superpixels are merged correctly.
% However, using pseudo labels leads to lower-quality merging as it ignores other minor classes.
Using pseudo labels leads to lower-quality merging as it ignores other minor classes.
% Since we utilize the class distribution as a feature space, 
Since we utilize the predicted class probability as a feature space, 
% in \eqref{eq:feature-space}, 
JSD proves to be more effective than ED.
As $\epsilon$ increases, the correct ratio decreases due to the aggressive merging of superpixels.
We emphasize that $\epsilon$ can determine the trade-off between the quantity and quality of labels.  




\subsection{Implementation remarks for practitioners}
\smallskip\noindent\textbf{Fast merging.}
% \subsection{Rationale for line~\ref{line:order} of Algorithm \ref{algorithm2}}
\label{fig:sup-descend}
% \begin{table}[!ht]
% \centering
% \setlength\tabcolsep{6pt}
% \begin{tabular}{l|c}
% \toprule
% Methods & mIoU \\ \midrule
% \textit{SP} \cite{cai2021revisiting} & 63.77 \\ \midrule
% \textit{AMSP+S} (ascending, 10\%) & 64.33 \\ \midrule
% \textit{AMSP+S} (descending, 10\%) & \underline{65.99} \\ \midrule
% \rowcolor{Gray}
% \textit{AMSP+S} (descending, 100\%) & \textbf{66.53} \\ \midrule
% \bottomrule
% \end{tabular}
% \caption{{\em Various merging order.} Experiments are conducted on Cityscapes dataset with an average superpixel size of 256, using 100k costs for two rounds.}
% \label{tab:descending}
% \end{table}
% We utilize a graph to merge superpixels by converting them into nodes and edges.
% However,
% We explain the rationale behind traversing nodes in the descending order of uncertainty in line~\ref{line:order} of Algorithm \ref{algorithm2}.
% We first convert superpixels into a graph for merging, where
The completion of the merging process for an image 
essentially requires
a linear time complexity in the number of the base superpixels.
However, to reduce this,
the complete merging can be 
replaced with a {\it partial merging}
that scans only a subset of base superpixels with high uncertainties
as roots.
This is considerable since 
we will eventually query only a subset of the merged superpixels 
according to 
the acquisition function~\eqref{acquisition_function},
which prioritizes those with high uncertainties.
% To complete the merging process for an image, we require a linear time complexity in the size of the base superpixels graph.
% However, this complexity can be significantly reduced by employing a subgraph comprising solely of base superpixels with high uncertainties.
% }
% the square of the number of superpixels $|S|$ as we compare pairs of superpixels to build an adjacency matrix, \ie $O(|S|^2)$.
% For experiments, we divide a Cityscapes image into 8,192 superpixels, however, the number of superpixels can vary depending on the image resolution.
% By merging in descending order of uncertainty, we can obtain merged superpixels with high uncertainty at the initial merging steps.
% As our acquisition function in~\eqref{acquisition_function} prioritizes superpixels with high uncertainty, merging a part of the most uncertain base superpixels results in the acquisition function behaving similarly to what all merged superpixels are given.
% Based on prioritizing superpixels with high uncertainty in the acquisition function, we propose a technique that firstly merges high-uncertainty superpixels.
% To alleviate this dependency, we only merge high-uncertainty superpixels.
% Note that the acquisition function prioritizes superpixels with high uncertainty.
% we note that the acquisition function prioritizes superpixels with high uncertainty, and only merging these superpixels can be enough. 
% as the superpixels with low uncertainty are unnecessary to the model.
% \khy{
% Given a budget $b$ for a round, we only convert $\frac{b}{N}$ nodes, the average number of superpixels for $N$ images, into a graph, where the complexity reduces to $O(\frac{b^2}{N^2})$.
% We convert $\frac{b}{N}$ superpixels, instead of $|S|$, into a graph,
% where $b$ is a budget and $N$ is the total number of images.
% The complexity reduces to $O(\frac{b^2}{N^2})$, where $|S| \gg b$ in active learning.
% }
% Details are in the appendix.
% In Table~\ref{tab:xx}, we
% compare the complete and partial mergings, which scan certain portions of the base superpixels in ascending or descending order 
% of their uncertainties.
In Table~\ref{tab:descending}, we
compare the complete and partial mergings in terms of the mIoU at 100k clicks.
As expected, the partial merging on  base superpixels with
top-10\% uncertainty
has only a small gap to the complete merging.
In addition, 
we find that by employing the partial merging, the time complexity is reduced significantly by a factor of 25.98
\footnote{
The per-image runtime of the merging process (CPU-intensive) for Cityscapes is reduced from 12.42s to 0.48s
on a server with two AMD EPYC 7513 32-core processors.
}.
The partial merging is a useful suggestion to save computation resource for practitioners.
% \khy{
A further investigation and discussion on the partial merging are presented in
Appendix~\ref{sec:rationale-merging}.
\begin{figure}[!t]
    % \captionsetup[subfigure]{font=footnotesize,labelfont=footnotesize,aboveskip=0.05cm,belowskip=-0.15cm}
    \centering
    \hspace{-3mm}
    \begin{subfigure}{.47\linewidth}
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                legend style={nodes={scale=0.5}, at={(0.48, 0.3)}, anchor=west}, 
                xlabel={$\epsilon$},
                ylabel={mIoU (\%)},
                width=1.23\linewidth,
                height=1.23\linewidth,
                ymin=62.4,
                ymax=67.2,
                ytick={62, 63, 64, 65, 66, 67},
                xlabel style={yshift=0.15cm},
                % ylabel style={yshift=-0.6cm},
                ylabel style={yshift=-0.2cm},
                legend columns=1,
                xmin=0.03,
                xmax=0.22,
                label style={font=\scriptsize},
                tick label style={font=\scriptsize},
                x tick label style={
                    /pgf/number format/.cd,
                        fixed,
                }
            ]
            \addplot[cdeepBP, very thick, mark=diamond*, mark size=2pt, mark options={solid}] table[col sep=comma, x=x, y=ours]{Data/wrong_merging_cityscapes.csv};
            \addplot[cdeepMF, very thick, mark=triangle*, mark size=2pt, mark options={solid}] table[col sep=comma, x=x, y=revisiting] {Data/wrong_merging_cityscapes.csv};
            \legend{AMSP+S,SP}
            \end{axis}
        \end{tikzpicture}
        \caption{Cityscapes}
        \label{fig:(c)-robustness}
    \end{subfigure}
    \hspace{1mm}
    \begin{subfigure}{.47\linewidth}
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                legend style={nodes={scale=0.35}, at={(0.03, 64)}, anchor=west}, 
                xlabel={$\epsilon$},
                ylabel={mIoU (\%)},
                width=1.23\linewidth,
                height=1.23\linewidth,
                ymin=60.8,
                ymax=63.7,
                ytick={61, 62, 63, 64},
                % ymax=63.5,
                xlabel style={yshift=0.15cm},
                % ylabel style={yshift=-0.6cm},
                ylabel style={yshift=-0.2cm},
                legend columns=2,
                xmin=0.02,
                xmax=0.22,
                label style={font=\scriptsize},
                tick label style={font=\scriptsize},
                x tick label style={
                    /pgf/number format/.cd,
                        fixed,
                }
            ]
            \addplot[cdeepMF, very thick, mark=triangle*, mark size=2pt, mark options={solid}] table[col sep=comma, x=x, y=revisiting] {Data/wrong_merging_pascal.csv};
            \addplot[cdeepBP, very thick, mark=diamond*, mark size=2pt, mark options={solid}] table[col sep=comma, x=x, y=ours]{Data/wrong_merging_pascal.csv};
            \end{axis}
        \end{tikzpicture}
        \caption{PASCAL}
        \label{fig:(d)-robustness}
    \end{subfigure}
    \caption{{\em Epsilon sensitivity.} We experiment on superpixels with varying $\epsilon$ and demonstrate the robustness of our \textit{AMSP+S}, while \textit{SP} is independent of $\epsilon$. Each experiment is conducted on the second round.}
    % \caption{{\em Epsilon sensitivity.} \hsh{mIoU of the proposed method and the baseline varying hyper-parameter $\epsilon$.
    % Each experiment is conducted on the second round.}}
    \label{fig:multi-rounds}
    % \vspace{-2mm}
\end{figure}

\begin{table}[!t]
\centering
\setlength\tabcolsep{6pt}
\begin{tabular}{l|ccccc}
\toprule
Epsilon & 0.04   & 0.05 & 0.06 & 0.07 & 0.08 \\ \midrule 
$\text{Merged}_1$ & 0.344 & \textbf{0.346} & 0.344 & 0.340 & 0.336 \\
$\text{Merged}_2$ & 0.347 & 0.346 & \textbf{0.348} & 0.345 & 0.344 \\
$\text{Merged}_3$ & 0.346 & 0.349 & 0.350 & \textbf{0.351} & 0.349 \\
$\text{Merged}_4$ & 0.347 & 0.347 & 0.347 & \textbf{0.348} & 0.346 \\
\bottomrule
\end{tabular}
\caption{{\em Adaptive epsilon.} AF$(G;S)$ for adaptive superpixels generated by varying $\epsilon$ is reported. The subscript indicates the round.} 
\label{tab:adaptive-epsilon}
% \vspace{-5mm}
\end{table}

\begin{table}[!t]
\centering
\setlength\tabcolsep{6pt}
\begin{tabular}{l|c|cc}
\toprule
Method                             & Epsilon & Correct & Incorrect \\ \midrule
Ground Truth                       &    -    & 1.000   & 0.000       \\ \midrule
Pseudo Label                 &    -    & 0.832 & 0.168   \\ \midrule
\multirow{3}{*}{ED}        & 0.05    & 0.915        & 0.085      \\
                                           & 0.10    & 0.901        & 0.099      \\
                                           & 0.15    & 0.891        & 0.109      \\ \midrule
\multirow{3}{*}{JSD} & 0.05    & 0.934        & 0.066      \\
                                           & 0.10    & 0.911        & 0.089      \\
                                           & 0.15    & 0.896        & 0.104      \\
\bottomrule
\end{tabular}
\caption{{\em Various merging criteria.} Using JSD performs more accurate merging than using ED. As $\epsilon$ increases, the rate of incorrect merging increases. }
%\omh{For each method and $\epsilon$, superpixel-meging results are evaluated by the ratio of superpixels that are merged correctly or incorrectly.}
% \caption{{\em Various merging criteria.}
% \hsh{Quality of the superpixel generated from merging algorithm, where a pair of superpixel are merged when their ground-truth label is identical (Ground-truth), when their top-1 model prediction is identical (Pseudo Label), and when the euclidean distance (ED) or jensan-shannon distance (JSD) of their feature is smaller than $\epsilon$.}}
\label{tab:merging-methods}
% \vspace{-5mm}
\end{table}


% in Figure~\ref{fig:(b)-partial} and Figure~\ref{fig:(c)-partial}, we can observe that superpixels within the cyan boxes yield similarly merged superpixels with high acquisition values, which are chosen by the acquisition function.
% Although the proposed method investigates all the base superpixels in the descending order of uncertainty in Figure~\ref{fig:(c)-partial}, 
% For example, 
% we can only merge a part of base superpixels of highest uncertainty (say top $10\%)$ to generate query candidates in Figure~\ref{fig:(b)-partial}.
% Furthermore, appendix~\ref{sec:rationale-merging} shows the partial merging in the descending order of uncertainty results in only a small gap to the full merging.
% To reduce the computational complexity,
% it is possible to merge a {\it part} of 
% base superpixels of highest uncertainty (say top $10\%$)
% to generate query candidates, although the proposed method investigates
% {\it all} the base superpixels in the descending order of uncertainty.
% although we propose 
% Instead of exploring all nodes in a graph, we only inspect nodes in order of high uncertainty to reduce the time complexity of graph preprocessing.
%To compare our algorithm which explores all nodes in descending order of uncertainty, 
% Table~\ref{tab:descending}
% shows the partial merging in the descending order of uncertainty results in only a small gap to the full merging.
% This suggests a tip to save computation resource for practitioners.
% % \khy{
% Upon closer examination, we find that by employing the base superpixels from the upper 10\% uncertainty, the time complexity decreases significantly by a factor of 25.98
% \footnote{
% The per-image runtime of the merging process (CPU-intensive) for Cityscapes is reduced from 12.42s to 0.48s
% on a server with two AMD EPYC 7513 32-core processors.
% }.
% resulting in a remarkable reduction from 12.42 seconds to 0.48 seconds per image}

\begin{table}[!t]
\centering
\setlength\tabcolsep{6pt}
\begin{tabular}{l|c}
\toprule
Methods & mIoU \\ \midrule
\textit{SP}  \cite{cai2021revisiting} & 63.77 \\ \midrule
% \textit{AMSP+S} (bottom 10\%) & 64.33 \\ \midrule
\textit{AMSP+S} (top 10\%) & \underline{65.99} \\ \midrule
\rowcolor{Gray}
\textit{AMSP+S} (complete 100\%) & \textbf{66.53} \\ \midrule
\bottomrule
\end{tabular}
\caption{{\em Various levels of partial merging.} Experiments are conducted under the same setting of Figure~\ref{fig:(a)-effect} with 100k clicks (Cityscapes, superpixel size of 256).}
\label{tab:descending}
\end{table}

\smallskip\noindent\textbf{Compatibility with other base superpixels.}
% \begin{table}[!t]
% \centering
% \setlength\tabcolsep{6pt}
% \begin{tabular}{l|l|c}
% \toprule
% Superpixel algorithm & Method & mIoU \\ \midrule
% \multirow{2}{*}{SEEDS} & \textit{SP}~\cite{cai2021revisiting} & 63.77 \\
%                        & \textit{AMSP+S} (Ours) & \textbf{66.53} \\ \midrule
% \multirow{2}{*}{SLIC}  & \textit{SP}~\cite{cai2021revisiting} & 65.97 \\
%                        & \textit{AMSP+S} (Ours) & \textbf{67.56} \\
% \bottomrule
% \end{tabular}
% \caption{{\em Other base superpixels.} 
% Experiments are carried out under the identical settings, as presented in Table \ref{tab:sieving}.}
% \label{tab:slic}
% \end{table}
For a fair comparison to the previous study~\cite{cai2021revisiting}, we have employed the same superpixel algorithm called SEEDS~\cite{van2012seeds} to generate base superpixels at the beginning.
% However, our algorithm also works with other choices of base superpixels since our merging and sieving processes can be applied on top of any base superpixels. 
However, our merging and sieving processes can be applied on top of any other base superpixels.
Indeed, in Figure~\ref{fig:(c)-effect} (and Appendix~\ref{sec:base-superpixel-sizes}), 
our method consistently shows gains over SP~\cite{cai2021revisiting} when using base superpixels of different sizes.
Furthermore, 
we compare SP and AMSP+S (ours)
when using SLIC instead of SEEDS
in the same setting of Figure~\ref{fig:(a)-effect},
where 
the mIoU's at 100k clicks of
SP and ours have 65.97\% and 67.56\%, respectively,
% our algorithm with different
% under the same setting in Figure~\ref{fig:(a)-effect}, we conduct experiments with SLIC~\cite{achanta2012slic} instead of SEEDS, where the mIoU's at 100k clicks are Ours+SLIC (67.56\%) and SP+SLIC (65.97\%),
\ie., the merging and sieving are also effective with SLIC as they were with SEEDS.
% In addition, without relying on specific superpixel algorithms like SEEDS or SLIC,
We believe that our proposed method can work with any base superpixels
even when they are from 
an unsupervised segmentation method~\cite{ke2022unsupervised} or a foundation model~\cite{kirillov2023segment}.
% which are image partitions obtained from unsupervised segmentation methods~\cite{ke2022unsupervised} or foundation models~\cite{kirillov2023segment}.
% This flexibility opens up interesting avenues for exploring the effectiveness of our proposed approach with different types of superpixels.


\iffalse
In addition, Table~\ref{tab:descending}
and Figure~\ref{fig:descend}
show that it is important to prioritize the merging highly uncertain superpixels.
In Table~\ref{tab:descending},
merging along the ascending order of uncertainty degenerates the performance.
In Figure~\ref{fig:descend},
we examplify the merged superpixels
from the partial merging in the ascending or descending order of uncertainty,
and the full merging, where
the cyan boxes contain
higher values of acquisition function
than the red boxes.
The partial merging with the ascending order of uncertainty regrettably merges
the superpixels that would not be selected in AL, while that with the ascending order
efficiently combines the base superpixels
of which selection is highly like.
This difference indeed results in a huge gap in the final performance as shown in Table~\ref{tab:descending}.
\fi

\iffalse
\vspace{-3mm}
\smallskip\noindent\textbf{Reducing time complexity.}
% We utilize a graph to merge superpixels by converting them into nodes and edges.
% However, 
We convert superpixels into a graph for merging, where the time and space increase proportionally to the square of the number of superpixels $|S|$ as we compare pairs of superpixels to build an adjacency matrix, i.e., $O(S^2)$.
% For experiments, we divide a Cityscapes image into 8,192 superpixels, however, the number of superpixels can vary depending on the image resolution.
Based on prioritizing superpixels with high uncertainty in the acquisition function, we propose a technique that only merges high-uncertainty superpixels.
% To alleviate this dependency, we only merge high-uncertainty superpixels.
% Note that the acquisition function prioritizes superpixels with high uncertainty.
% we note that the acquisition function prioritizes superpixels with high uncertainty, and only merging these superpixels can be enough. 
% as the superpixels with low uncertainty are unnecessary to the model.
% Given a budget $b$ for a round, we only convert $\frac{b}{N}$ nodes, the average number of superpixels for $N$ images, into a graph, where the complexity reduces to $O(\frac{b^2}{N^2})$.
We convert $\frac{b}{N}$ superpixels, instead of $|S|$, into a graph, where $b$ is a budget and $N$ is the total number of images.
The complexity reduces to $O(\frac{b^2}{N^2})$, where $|S| \gg b$ in active learning.
Details are in the appendix.
\fi
% Given a budget $b$ for a round, $\frac{b}{N}$ superpixels are selected from each image on average, where $N$ is the total number of images.
% We then require $\frac{b}{N}$ nodes for the graph, which reduces the time and space complexity to $O(\frac{b^2}{N^2})$.
% Additionally, active learning typically aims to select only a few samples compared to all samples, i.e., $|S| \gg b$.
% Our appendix provides empirical evidence that merging only superpixels with high uncertainty has comparable performance.


% \smallskip\noindent\textbf{Class-distribution}
% of different acquisition function