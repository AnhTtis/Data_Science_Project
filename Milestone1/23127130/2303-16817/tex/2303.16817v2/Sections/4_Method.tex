% Active learning with adaptive superpixels}
% \begin{algorithm*}[t!]
% \caption{Adaptive Superpixel (version 1)}
% \begin{algorithmic}[1]
% \Require
% \State Initialize superpixels $S_0$ with an existing algorithm (EAM)
% \State Obtain a noisy dataset $D_0 \leftarrow$ Oracle-Query($S_0$, Big Superpixels)
% \For{each round $t = 0, 1, \dots, T$}
% \State Initialize $\theta_t$ and update a model $\theta_t \leftarrow \theta_t - \eta \nabla_{\theta_t} \ell \left( \theta_t; D_t \right)$
% \State Modify superpixels $S_{t+1} \leftarrow $ Adaptive-Superpixel$(S_t, \theta_t)$
% \State Remain reliable pixels in $D_t := \{ (x,\tilde y) \in D_t$ where $p(y=\tilde y \mid x, \theta_t) > \epsilon_1 \}$ \Comment{Confidence-based pixel removal}
% \State Obtain a noisy dataset $D_{t+1} \leftarrow D_t \; \cup $ Oracle-Query$(S_{t+1}$, Class-balanced$)$
% \EndFor
% \\
% \Procedure{Oracle-Query}{$S, A$}
% \State $x \leftarrow$ pixels of $k$ superpixel regions in $S$ selected by an acquisition function $A$
% \State $\tilde y \leftarrow$ noisy dominant labels for the selected superpixel regions labeled by an oracle \\
% \Return $D = \{x, \tilde y\}$
% \EndProcedure
% \\
% \Procedure{Adaptive-Superpixel}{$S, \theta$}
% \State Obtain pixel impurity $I_p$ and region impurity $I_r$ via
% \State Merge two regions $s_1, s_2 \in S$ where $\tilde{Do}(s_1) == \tilde{Do}(s_2)$ and $I_r(s_1), I_r(s_2) < \epsilon_2$
% \State Split regions $s \in S$ where $I_r(s) > \epsilon_3$ via cycle generation \\
% \Return $S$
% \EndProcedure
% \end{algorithmic}
% \end{algorithm*}

% \begin{algorithm*}[t!]
% \caption{Adaptive Superpixel (version 2)}
% \begin{algorithmic}[1]
% \Require
% \State Initialize superpixels $S_0$ with an empty set of labels by an existing algorithm
% \State Update superpixels $S_0 \leftarrow$ Oracle-Query($S_0$, Big Superpixels) \Comment{Initial noisy labels}
% \For{each round $t = 0, 1, \dots, T$}
% \State Initialize $\theta_t$ and update a model $\theta_t \leftarrow \theta_t - \eta \nabla_{\theta_t} \ell \left( \theta_t; S_t \right)$ until convergence
% \State Modify superpixels $S_{t+1} \leftarrow $ Adaptive-Superpixel$(S_t, \theta_t)$
% \State Update superpixels $S_{t+1} \leftarrow $ Oracle-Query$(S_{t+1}$, Class-balanced$)$
% \EndFor
% \\
% \Procedure{Oracle-Query}{$S, A$}
% \State $s \leftarrow$ $c$ superpixel regions in $S$ selected by an acquisition function $A$
% \State $x \leftarrow$ pixels of the selected superpixels $s$
% \State $\tilde y \leftarrow$ noisy dominant labels of the selected superpixels $s$ labeled by an oracle \\
% \Return $S = \{s, x, \tilde y\}$
% \EndProcedure
% \\
% \Procedure{Adaptive-Superpixel}{$S, \theta$}
% \State Obtain impurity of pixel $I_p$ and region $I_r$ via
% \State Merge two regions $s_1, s_2 \in S$ where $\tilde{D_r}(s_1) == \tilde{D_r}(s_2)$
% \State Split regions $s \in S$ into $s_1$ and $s_2$ via \\
% \Return $S$
% \EndProcedure
% \end{algorithmic}
% \end{algorithm*}

% \begin{algorithm*}[t!]
% \caption{Adaptive Superpixel (v2-1)}
% \begin{algorithmic}[1]
% \Require
% \State Initialize superpixels $S_0$ with an empty set of labels by an existing algorithm
% \State Update superpixels $S_0 \leftarrow$ Oracle-Query($S_0$, Big Superpixels) \Comment{Initial noisy labels}
% \For{each round $t = 0, 1, \dots, T$}
% \State Initialize $\theta_t$ and update a model $\theta_t \leftarrow \theta_t - \eta \nabla_{\theta_t} \ell \left( \theta_t; S_t \right)$ until convergence
% \State Obtain impurity of pixel $I_p$ and region $I_r$ from $\theta_t$ via
% \State Merge two reliable regions $s_1$ and $s_2 \in S_t$ via
% \State Split unreliable regions $s \in S_t$ into $s_1$ and $s_2$ via
% \State Update superpixels $S_{t+1} \leftarrow $ Oracle-Query$(S_{t}^{'}$, Class-balanced$)$
% \EndFor
% \\
% \Procedure{Oracle-Query}{$S, A$}
% \State $s \leftarrow$ $c$ superpixel regions in $S$ selected by an acquisition function $A$
% \State $x \leftarrow$ pixels of the selected superpixels $s$
% \State $\tilde y \leftarrow$ noisy dominant labels of the selected superpixels $s$ labeled by an oracle \\
% \Return $S = \{s, x, \tilde y\}$
% \EndProcedure
% \end{algorithmic}
% \end{algorithm*}

% \begin{algorithm*}[t!]
% \caption{Adaptive Superpixel (v3)}
% \begin{algorithmic}[1]
% \Require
% \State Initialize superpixels $S_0$ with an empty set of labels by an existing algorithm
% \State Update superpixels $S_0 \leftarrow$ Oracle-Query($S_0$, Big Superpixels) \Comment{Initial noisy labels}
% \For{each round $t = 0, 1, \dots, T$}
% \State Initialize $\theta_t$ and update a model $\theta_t \leftarrow \theta_t - \eta \nabla_{\theta_t} \ell \left( \theta_t; S_t \right)$ until convergence
% \State Obtain impurity of pixel $I_p$ and region $I_r$ from $\theta_t$ via
% \State Merge two reliable regions $s_1$ and $s_2 \in S_t$ via
% \State Split unreliable regions $s \in S_t$ into $s_1$ and $s_2$ via
% \State Update superpixels $S_{t+1} \leftarrow $ Oracle-Query$(S_{t}^{'}$, Class-balanced$)$
% \EndFor
% \\
% \Procedure{Oracle-Query}{$S, A$}
% \State $s \leftarrow$ $c$ superpixel regions in $S$ selected by an acquisition function $A$
% \State $x \leftarrow$ pixels of the selected superpixels $s$
% \State $\tilde y \leftarrow$ noisy dominant labels of the selected superpixels $s$ labeled by an oracle \\
% \Return $S = \{s, x, \tilde y\}$
% \EndProcedure
% \end{algorithmic}
% \end{algorithm*}

% \begin{algorithm}[t!]
% \caption{Adaptive Superpixel (v4)}
% \begin{algorithmic}[1]
% \Require Per-round budget: $b$, 
% Total rounds: $T$,
% Noisy dataset: $N_t$,
% Sieved dataset: $N'_t$,
% Model parameters: $\theta_t$
% \State Initialize superpixels $S_0$ with an existing algorithm
% \State Merge superpixels $S_0$ based on color via
% \State Obtain dataset $N'_0$ with $b$ labels from Acq 1
% \For{each round $t = 1, 2, \dots, T$}
% \State Initialize and train a model $\theta_t$ with $N'_t$ via
% \State Compute impurity of regions via
% \State Split high-impurity regions on superpixels $S_t$ via
% \State Merge superpixels $S_t$ based on feature via
% \State Obtain dataset $N_{t+1}$ with $b$ labels from Acq 2
% \State Obtain sieved dataset $N'_{t+1}$ via \\
% \Return $\theta_T$
% \EndFor
% \end{algorithmic}
% \end{algorithm}

% \begin{algorithm}[t!]
% \caption{Superpixel Merging}
% \begin{algorithmic}[1]
% \Require Per-round budget: $b$, 
% Total rounds: $T$,
% Noisy dataset: $N_t$,
% Sieved dataset: $N'_t$,
% Model parameters: $\theta_t$
% \State Initialize superpixels $S_0$ with an existing algorithm
% \State Merge superpixels $S_0$ based on color via
% \State Obtain dataset $N'_0$ with $b$ labels from Acq 1
% \For{each round $t = 1, 2, \dots, T$}
% \State Initialize and train a model $\theta_t$ with $N'_t$ via
% \State Compute impurity of regions via
% \State Split high-impurity regions on superpixels $S_t$ via
% \State Merge superpixels $S_t$ based on feature via
% \State Obtain dataset $N_{t+1}$ with $b$ labels from Acq 2
% \State Obtain sieved dataset $N'_{t+1}$ via \\
% \Return $\theta_T$
% \EndFor
% \end{algorithmic}
% \end{algorithm}

\iffalse
set of unlabeled images to train a segmentation model which predicts pixel-wise label $c \in \mathcal{C} :=\{1,2,\dots,C\}$ with a limited budget and rounds.
For round 1, we initially divide the unlabeled images into superpixels $\mathcal{S}_1$ with the SEEDS \cite{van2012seeds} algorithm.
% Given a large set of unlabeled images $\mathcal{X}$ and budget $b$ per round,
% active learning selects $b$ samples to obtain labels in each round $t$.
% In superpixel-based active learning, we initially divide the unlabeled images into superpixels $\mathcal{S}_1$ using a superpixel-partitioning function $\mathcal{P}$, with the SEEDS \cite{van2012seeds} algorithm being utilized for this purpose, as it works without requiring a training process that uses ground-truths.
We next obtain the dominant labels for $b$ randomly selected superpixels $\mathcal{B}_1 \subset \mathcal{S}_1$, where $|\mathcal{B}_1| = b$.
The dominant label of a superpixel indicates that a single class label for a superpixel is obtained through an oracle supervision.
Using the labeled superpixels, we train a model $\theta_1$, which we leverage in the next round.
In what follows, we introduce adaptive merging (Section~\ref{sec:adaptive-merging}) and sieving (Section~\ref{sec:sieving-technique}) with the previously trained model.
The overall procedure is summarized in Figure~\ref{fig:method} and Algorithms \ref{algorithm1}, \ref{algorithm2}.
\fi
%\subsection{Overall Framework}

\section{Proposed framework}

Given an unlabeled image set $\set{I}$, we consider an active learning scenario with dominant labeling, 
where a query asks an oracle annotator for the dominant class label $\text{D}(s) \in \set{C} := \{1,2,..., C\}$ of an associated superpixel $s$,
and we issue a batch $\set{B}_t$ of $B$ queries for each round $t$. 
Once we enquire the batch $\set{B}_t$, we train a model $\theta_t$ based on the annotations obtained so far.
Recalling a superpixel $s$ is a cluster of neighboring pixels,
the dominant labeling demands much less annotation effort 
than the pixel-wise labeling on every individual pixel $x$ in the same superpixel $s$ or manual segmentation to indicate boundaries separating semantics. The benefit becomes greater with larger superpixels.
Meanwhile, it is prone to noisy labeling as superpixels can be blunt, \ie., including pixels of different semantics.
% In order to fully enjoy the benefit in terms of annotation cost 
% while suppressing the risk of noisy labels, 
% we adaptively merge pixels with similar {\it learned} features on semantics.
% This means that our superpixels evolve round by round as the model improves while superpixels from existing methods cannot as they are based on innate pixel features (e.g., color or position).
% We also devise a sieving mechanism to exclude pixels of high risk of noisy labeling from training.

In order to fully enjoy the benefit in terms of annotation cost while suppressing the risk of noisy labels, 
our framework begins with a warm-up round ($t = 0$; Section~\ref{sec:warm-up}; line \ref{alg1-line1}-\ref{alg1-line2} in Algorithm \ref{algorithm1}) to prepare an initial model from random querying  and iterates
subsequent rounds ($t = 1, 2, \dots$) with the adaptive merging (Section~\ref{sec:adaptive-merging}; line \ref{alg1-line4}-\ref{alg1-line5} in Algorithm \ref{algorithm1}) and sieving (Section~\ref{sec:sieving-technique}; line \ref{alg1-line6}-\ref{alg1-line7} in Algorithm \ref{algorithm1}) methods
to evolve superpixels for dominant labeling round by round and filter out annotations with the high risk of noisy labels given the latest model.
The overall procedure is summarized in Figure~\ref{fig:method} and Algorithm~\ref{algorithm1}. %, \ref{algorithm2}.

\subsection{Warm-up round}
\label{sec:warm-up}
The adaptive merging and sieving methods demand a trained model.
To obtain an initial model, 
we start with a canonical warm-up round, which is identical to the first round of previous work \cite{cai2021revisiting}.
We first use an off-the-shelf superpixel algorithm, namely SEEDS \cite{van2012seeds}, to partition the pixels in each image $i \in \set{I}$
into a set ${S}_0(i)$ of superpixels,
and to produce a base segmentation $\set{S}_0:= \bigcup_{i \in \set{I}} {S}_0(i)$.
Querying a batch~$\set{B}_0$ of $B$ superpixels randomly selected from $\set{S}_0$, we then train a model $\theta_0$ using the dominant labels for $\set{B}_0$. Specifically, % in each round $t=0,1,2,...$, 
to obtain $\theta_0$,
we first initialize $\theta$ at a model pretrained on ImageNet,
and then train it to minimize the following cross-entropy (CE) loss:
\begin{equation}
%\ell_{\text{CE}} =
\hat{\mathbb{E}}_{(x, y) \sim {\mathcal{D}}_0} [ \text{CE}(y, f_\theta (x))] \;,
\end{equation}
where $\set{D}_0 := \{(x, y) : 
\exists s \in \set{B}_0,
x \in s, y(c) = \mathbbm{1}{[c = \text{D}(s)]}$

\!\!\!\!\!\!\!$ \forall c \in \set{C}\}$
is the training data for round $t=0$ without sieving,
and $\! f_\theta( x ) \! \in \! \mathbb{R}^{\! |\set{C}| \!}\!$ is $\! \theta$'s estimate of class probability on pixel $ x $.
%where \text{CE} implies pixel-wise cross entropy between one-hot vector with only one for true dominant label $y$ and predicted label $\tilde y$, where $y, \tilde y \in \mathbb{R}^{|\mathcal{C}|}$.

%\ok{Why SEEDS?}
We remark that we use the initial model $\theta_0$ for round $t=1$.
%and also reuse $\set{S}_0$ as the base superpixels for the entire rounds $t\ge 1$.
In our framework, SEEDS to generate $\set{S}_0$ can be replaced with any other unless $\set{S}_0$ is a fair over-segmentation of semantics 
with a low risk of noisy labeling while partially enjoying the benefit of low annotation cost. 
We note that SEEDS clusters neighboring pixels of similar 
% (relative)
colors
while a semantic consists of multiple colors, typically.
SEEDS, ready-to-use in OpenCV \cite{opencv_library}, easily provides the desired over-segmentation \cite{cai2021revisiting} and a decent performance of $\theta_0$.
%For practitionor, it makes sense (ready-to-use, algorithmic complexity, budget efficiency...)
In addition, the warm-up round with SEEDS corresponds to that in existing work \cite{cai2021revisiting}. Hence, this also enables a fair comparison of our main contributions, \ie., adaptive merging and sieving methods, to existing works. 
% In addition, 
% The base segmentation $\set{S}_0$ 
%  SEEDS is prone to over-segmentation, but it increases the budget efficiency






% \subsection{Splitting High Impurity Regions}
% For better labels, we split superpixels containing many classes.
% We split high-impurity regions using an existing superpixel algorithm.
% \smallskip\noindent\textbf{Region impurity}
% Impurity of region $s$ \cite{xie2022towards}
% \begin{equation}
% I(s) := - \sum_{c=1}^C \frac{N(s,c)}{|s|} \log \frac{N(s,c)}{|s|} \;, 
% \end{equation}
% \begin{equation}
% I(s) := \frac{1}{| s |} \sum_{x \in s} 1 - p(y = \tilde{D_r}(s) \mid x,\theta) 
% \end{equation}
% High impurity regions contain many classes

% \begin{algorithm}[t!]
% \caption{Adaptive Merging Algorithm}
% \begin{algorithmic}[1]
% \Require 
% Unlabeled superpixels $S_t$,
% selected superpixels $D_t$,
% per-round budget $b$,
% model parameters $\theta_t$,
% total rounds $T$,
% and hyperparameter $\epsilon$
% \State Initialize superpixels $S_1$ with an existing algorithm
% \State Randomly select $b$ superpixels $D_1 \subset S_1$
% \State Obtain dominant labels for $D_1$ from an oracle
% \State Initialize and train a model $\theta_1$ with labeled $D_1$
% \For{each round $t = 2, \dots, T$}
% \State Convert superpixels into a graph for all images
% \State Merge superpixels $S_1$ into $S_t$ with $\theta_{t-1}$ 
% %\omh{(if $t=1$ then what?) 
% and $\epsilon$
% \State Select $b$ superpixels $D_t \subset S_t$ via \eqref{acquisition_function}
% \State Obtain dominant labels for $D_t$ from an oracle
% \State Make a sieved dataset $\tilde{D}_t$ from $D_t$ via \eqref{sieved-superpixel}
% \State Initialize and train a model $\theta_t$ with $\tilde{D}_t$ via \eqref{cross-entropy} \\
% \Return $\theta_T$
% \EndFor
% \end{algorithmic}
% \label{algorithm}
% \end{algorithm}




\subsection{Adaptive merging}
\label{sec:adaptive-merging}
%\ok{we merge base superpixels for algorithmic complexity}
% Given a model $\theta_{t-1}$ at round $t$ 
% We here describe the procedure 
In advance of dominant labeling in round $t \ge 1$, we first merge the base superpixels in $\set{S}_0$ to obtain $\set{S}_t$ using the model $\theta_{t-1}$ from the previous round. We then select a batch $\set{B}_t$ of $B$ superpixels from $\set{S}_t$ to be annotated using an acquisition function that prioritizes uncertain superpixels of rare class labels.
For simplicity, we often omit the subscript $t-1$
and write $\theta$ for $\theta_{t-1}$.


\begin{algorithm}[t!]
\caption{Proposed Framework}
\begin{algorithmic}[1]
\Require 
  Image set $\mathcal{I}$,
  %superpixel-partitioning function $\mathcal{P}$,
  batch size $B$, and final round~$T$.  
\State Produce base superpixels $\set{S}_0 := \bigcup_{i \in \set{I}}\set{S}_0(i)$ \label{alg1-line1}
%\State Query dominant label $\text{D}(s)$, $\forall s\in\mathcal{B}_1$
%\State $\mathcal{D} \gets \{(s,y[s])\colon s\in\mathcal{B}_1\}$
\State Obtain model $\theta_0$ training with $\mathcal{D}_0$ \label{alg1-line2}
%:= \{(x, \text{D}(s))\colon x \in s, s\in\mathcal{B}_0\}$ 
% querying randomly select $B$ superpixels $\mathcal{B}_0 \subset \mathcal{S}_0$  
% \Comment{Warm-up round}
  \For {$t = 1, 2, \dots, T$}
    \State Adaptively merge the base superpixels and obtain \label{alg1-line4}
    
    \;\;\;\;$\mathcal{S}_t \gets \bigcup_{i \in \set{I}} \Call{AM}{{S}_0(i),\theta_{t-1}}$
    %\{s\in \Call{Adapt}{{S}_0(i),\theta_{t-1}} \colon i\in\set{I}\}$
    % \State Convert superpixels into a graph for all images
    % \State $\mathcal{S}_t \gets \{s\in\mathcal{A}_t(X) \colon X\in\mathcal{X}\}$
    
    \State Select and query $B$ superpixels $\mathcal{B}_t \subset \mathcal{S}_t$ with \eqref{acquisition_function} 
    %for dominant labeling
    \label{alg1-line5}
    %\State Query dominant label $\text{D}(s)$, $\forall s\in\mathcal{B}_t$ \label{alg1-line6}
    \State Sieve %the dominant labeling on every queried superpixel 
    $s \in \bigcup_{t'=0}^{t} \mathcal{B}_{t'}$ and 
    obtain $\set{D}_t$ in \eqref{sieved-superpixel}
    %$s, \forall s \in \bigcup_{ \in [t]} \mathcal{B}_{i}$ via \eqref{sieved-superpixel} 
    \label{alg1-line6}
    % \State Sieve, $\forall (s,y[s]) \in D_t$ into $(\tilde s, y[s]) \in \tilde{D}_t$ via \eqref{sieved-superpixel}
    \State Obtain model $\theta_t$ training with the sieved ${\mathcal{D}}_{t}$ \label{alg1-line7} 
    %and the loss in \eqref{cross-entropy}
    %using the loss in \eqref{eq:final-loss} \label{alg1-line8}
    % := \{(\tilde s,\text{D}(s)) : s \in \mathcal{B}_{[t]} \} $ 
    % via \eqref{cross-entropy} \\
    %\Comment{Main round}
  \EndFor
\State \Return $\theta_T$ \label{alg1-line8} 
\end{algorithmic}
\label{algorithm1}
\end{algorithm}

\smallskip\noindent\textbf{Adaptive merging.} 
To obtain $\set{S}_t := \bigcup_{i \in \set{I}} {S}_t(i)$,
the merging process converts base superpixels $S_0(i)$ into merged ones $S_t(i)$ for each image $i \in \set{I}$.
We hence focus on how we merge given base superpixels $S$ for an image.
To begin with, we convert the superpixels $S$ into a connected graph $\set{G}(S) \! = \! (S, \set{E}(S))$
where $S$ is the set of nodes, each of which corresponds to a base superpixel $s \in S$, and $\set{E}(S)$ is the edge set such that
$(s, n) \in \set{E}(S)$ if a pair of superpixels $s, n \in S$
are adjacent.
Starting from a root node $s \in S$, we then merge neighboring superpixels of similar class predictions with the root $s$ along the breadth-first search tree.
To be specific, a neighbor $n$ is amalgamated with root $s$
only if 
\begin{equation}
d_\text{JS} \big( f_\theta(s) \parallel f_\theta(n) \big) < \epsilon \;,
\label{eq:jsd}
\end{equation}
where  $f_\theta(s) := \frac{\sum_{x \in s} f_\theta(x)}{|\{x : x\in s\}|}$
is the averaged class prediction of superpixel $s \in S$,
and $d_\text{JS}$ is 
a symmetric %\footnote{Asymmetric discrepancy such as KL divergence often causes unstable merging.} 
measure of discrepancy between two distributions, namely
the square root of Jensen-Shannon (JS) divergence.
More formally, 
%between $f_\theta(s)$ and $f_\theta(n)$. 
\begin{equation}
d_\text{JS}(p \parallel q) := \sqrt{\frac{d_\text{KL}(p \parallel \frac{p+q}{2}) + d_\text{KL}(q \parallel \frac{p+q}{2})}{2}} \;,
\end{equation}
where $d_{\text{KL}}$ is the Kullback-Leibler divergence.
Once every node has been either merged to a root
or played as a root, we collect the merged superpixels into $S_t(i)$.
The merging process is formally described in Algorithm~\ref{algorithm2}.


Recalling \eqref{eq:jsd} and the fact that $d_{\text{JS}}$ is a distance metric,
we can guarantee that any pair of superpixels $s$ and $n$ 
has the prediction discrepancy at most $2 \epsilon$ and thus similar uncertainty and predicted label if they are merged.
Hence, the threshold $\epsilon$ governs the impurity of predictions in a merged superpixel.
We also remark that 
the merging process is fully dedicated to collecting pixels of similar predictions
as a part of saving the annotation budget for querying similar pixels repeatedly.
Hence, the merged superpixels can have various sizes differently from existing superpixel algorithms that regularize the superpixel size to be even \cite{giraud2017robust,machairas2014waterpixels,schick2012measuring}.
% implicitly or explicitly








% For merging, we define the class probability of a superpixel $s$ as the average of the corresponding values of the pixels that it contains as follows:
% \begin{equation}
% f_\theta(s) := \frac{\sum_{x \in s} f_\theta(x)}{|\{x: x\in s\}|}\;, \;\;
% \label{eq:feature-of-superpixel}
% \end{equation}
% where $|s| := |\{x: x\in s\}|$ is the size of superpixel $s$.


\iffalse

% To begin with, we extract a connected graph $\set{G}(S)$ connection information among superpixels in $S$ into a connected graph $G()$,
% As a superpixel consists of multiple pixels
Prior to merging, all nodes are initialized as unexplored, and we explore them sequentially.
% The merging order based on high uncertainty is related to the time complexity, which we describe later.
% We merge two base superpixels $s, s' \in S$ if they are adjacent and their class predictions $f_\theta(s)$ and $f_\theta(s')$ are close enough:
Starting from a node $s$, we merge it with a neighbor node $n$ when the 
We repeat the merging until there are no neighboring nodes left to merge.
The merging process continues until all base superpixels are explored.
We merge two base superpixels $s, s' \in S$ if they are adjacent and their class predictions $f_\theta(s)$ and $f_\theta(s')$ are close enough.
\fi
% Since a superpixel consists of multiple pixels, we define the feature of a superpixel $s$ as the average of the corresponding values of the pixels that it contains as follows:
% \begin{equation}
% f_\theta(s) := \frac{\sum_{x \in s} f_\theta(x)}{|s|}\;, \;\;
% \end{equation}
% where $|s| := |\{x: x\in s\}|$ is the size of superpixel $s$.
% To be specific, we first convert the base segmentation ${S}_0(i)$ into a connected graph $G()$, where each base superpixel corresponds to a node and each pair of adjacent base superpixels has an edge connecting them. In addition, the nodes 
% We manage two attributes of 
% $\set{S}_0 (i)$
% of similar predictions of $\theta$. 
% The weight of an edge connecting superpixels $s_1$ and $s_2$ is defined as the similarity between their features, calculated using the squared Jensen-Shannon divergence:
% \begin{equation}
% w(s_1, s_2) := \text{D}_\text{JS} \left( f_\theta \left( s_1 \right) \parallel f_\theta \left( s_2 \right) \right) \;,
% \end{equation}
% where $d_\text{JSD}$ is the  a symmetric metric defined as:
% \begin{equation}
% d_\text{JSD}(p \parallel q) = \sqrt{\frac{d_\text{KL}(p \parallel \frac{p+q}{2}) + d_\text{KL}(q \parallel \frac{p+q}{2})}{2}} \;,
% \end{equation}
% and $d_{\text{KL}}$ denotes the Kullback-Leibler divergence.
% We repeat the process until there are no neighboring superpixels left to merge with the starting node
\iffalse
, and then we choose the next superpixel with the highest uncertainty among the ones that not merged yet as the new starting node.
\fi
% We continue to merge until there are no more adjacent superpixels to be merged.
% To perform efficient merging, we assign the feature of the starting superpixel $s$ to the adjacent node $n$, and proceed with recursive merging from the node $n$.



%base superpixels in $\set{S}_0$ 

%We are given a model $\theta_{t-1}$ at round $t$.
% For simplicity, we omit the subscript $t-1$ in subsequent equations.
% We first define the feature of a pixel $x$ as its class probability parameterized by a model $\theta$, i.e.,
% \begin{equation}
% f_\theta(x) := p(y \mid x, \theta) \;,
% \label{eq:feature-space}
% \end{equation}
% where $f_\theta(x) \in \mathbb{R}^{|\mathcal{C}|}$.
% The feature of a pixel $x$ is determined by its class probability given a model $\theta$, i.e., $p(y \mid x, \theta)$.

%
% \omh{
% \begin{equation}
%     u(x;\theta_{t-1}) = \frac{\max_{c\in [C]\setminus\{c^*\}} {p(y=c\,|\,x,\theta)}}{p(y=c^*\,|\,x,\theta)}
% \end{equation}
% %
% where $c^*=\argmax_{c\in [C]} p(y=c\,|\,x,\theta_{t-1})$
% }
%
% where $y_\theta(x):= \argmax_{c\in \mathcal{C}} f_\theta (c;x)$ is 
% $\theta$'s prediction on the label of pixel $x$.
% We note that the uncertainty $u_\theta(x) \in \mathbb{R}$ depends on the given current model $\theta$. 
% Since a superpixel consists of multiple pixels, we can define the feature and uncertainty of a superpixel $s$ as the average of the corresponding values of the pixels that it contains as follows:
% \begin{equation}
% f_\theta(s) := \frac{\sum_{x \in s} f_\theta(x)}{|s|}\;, \;\;
% \end{equation}
% where $|s| := |\{x: x\in s\}|$ is the size of superpixel $s$.
%$f_\theta(s) \in \mathbb{R}^{|\mathcal{C}|}$ relates to the estimated class probability of a superpixel $s$.



% This approach allows us to only evaluate the edges once.
% We continue the merging process in order of high uncertainty until all superpixels are merged.
% The merging in order of high uncertainty is related to the time complexity that we describe later.



\begin{algorithm}[t!]
\caption{Adaptive Merging (\textsc{AM})} %(\Call{AM}{a})}
\begin{algorithmic}[1]
\Require Base superpixels $S$, model $\theta$, and threshold $\epsilon$. 
% \Ensure Pairwise disjoint family $\mathcal{S}_t(X)$ of superpixels, each representing merged one
%\Procedure{Adapt}{$S$, $\theta$}
  \State Set $S' \gets \emptyset$ and $\mathcal{G}(S) \gets (S, \set{E}(S))$
    \State Mark $s$ as unexplored for each $s\in S$
  % \EndFor
  \For {$s\in S$ in descending order of $u_\theta(s)$} \label{line:order} 
    \If {$s$ is unexplored}
      \State $S' \gets S' \cup \{\text{\Call{Merge}{$s$, $f_\theta(s)$; $\set{G}$, $\theta$}}\}$
    \EndIf
  \EndFor
  \State \Return $S'$
%\EndProcedure
\Procedure{Merge}{$s$, $f$; $\mathcal{G}$, $\theta$}
  \State Mark $s$ as explored and set $s' \gets s$
  \For {each neighbor $n$ of $s$ in $\set{G}$}
    \If {$n$ is unexplored and $d_\text{JS}(f \!\parallel\! f_\theta(n))<\epsilon$}
      \State $s' \gets s' \cup \text{\Call{Merge}{$n$, $f$; $\mathcal{G}$, $\theta$}}$
    \EndIf
  \EndFor
  \State \Return $s'$
\EndProcedure
\end{algorithmic}
\label{algorithm2}
\end{algorithm}

\smallskip\noindent\textbf{Acquisition function.} 
From the merged superpixels $\set{S}_t$, 
we then select a batch $\set{B}_t \subset \set{S}_t$
of size $B$ to be labeled, according to an acquisition function
that estimates the benefit from labeling a merged superpixel,
where the benefit would be huge for uncertain superpixels of rare class labels.
In what follows, we define an uncertainty measure of superpixel
in \eqref{eq:uncertainty}
and a popularity estimate of class in \eqref{eq:size-aware-class-balance}, and then introduce an acquisition function in \eqref{acquisition_function}.

Recalling $f_\theta(x) \! \in \! \mathbb{R}^{|\set{C}|}$
is the probability such that $f_\theta(c; x)$ is the estimated probability
that the class $c$ of pixel $x$,
we adapt best-versus-second-best~\cite{joshi2009multi}
for uncertainty measures of pixel $x$ and superpixel $s$ as follows:
% which disregards low probabilities of insignificant classes:
\begin{align}
u_\theta(x) &:= \frac{\max_{c \in \mathcal{C} \setminus\{y_\theta(x)\}} {f_\theta(c; x)}}{\max_{c \in \set{C} }f_\theta(c;x)}\;, \\
u_\theta(s) &:= \frac{\sum_{x \in s} u_\theta(x)}{|\{x: x \in s\}|} \;, 
\label{eq:uncertainty}
\end{align}
% \begin{equation}
% u_\theta(x)\!:=\!\frac{\underset{c \in \mathcal{C} \setminus\{y_\theta(x)\}}{\text{max}} {f_\theta(c; x)}}{\max_{c \in \set{C} }f_\theta(c;x)},
% u_\theta(s) \!:=\! \frac{\sum_{x \in s} u_\theta(x)}{|\{x: x \in s\}|}, 
% \label{eq:uncertainty}
% \end{equation}
where $y_{\theta}(x) := \argmax_{c \in \set{C}} f_\theta(c;x)$ is the estimated dominant label of pixel $x$ in a given model $\theta$.
% and $u_\theta(s)$ is the uncertainty of superpixel $s$.
% To reduce the time complexity, we merge superpixels in descending of the uncertainty in Algorithm.~\ref{algorithm2}.
% The merging order based on high uncertainty is related to the time complexity, which we describe later.
% Each denominator and numerator indicate the best and the second-best value of the feature $f_\theta(x)$, respectively.
% Similar to the class distributions of a superpixel $s$ in \ref{eq:feature-of-superpixel}, we define the uncertainty as: 
% \begin{equation}
% u_\theta(s) := \frac{\sum_{x \in s} u_\theta(x)}{|s|}\;. 
% \end{equation}
% From the merged nodes, we generate adaptive superpixels $\mathcal{S}_t$ for round $t$.
% We next use an acquisition function to select $b$ superpixels from $\mathcal{S}_t$ to obtain labels.

We then define a popularity estimate $p(c; \theta)$ of class $c \in \set{C}$
given $\theta$ as follows: 
%  we calculate the posterior of the class distribution based on the number of pixels that make up superpixels:
\begin{equation}
p(c;\theta) := \frac{|\{ x : \exists s \in \mathcal{S}_t, \text{D}_\theta(s) = c, x \in s\}|}{|\{x : \exists s \in \mathcal{S}_t, x \in s \}|} \;,
\label{eq:size-aware-class-balance}
\end{equation}
where $\text{D}_\theta(s) :=\argmax_{c \in \mathcal{C}} | \{x \in s : y_\theta(x) = c \} |$ is the majority of predicted labels in superpixel $s$. We note that low $p(c;\theta)$ implies that class $c$ is rare in the prediction of $\theta$. It is noteworthy that we compute the class popularity
in pixel-level due to the various sizes of our merged superpixels,
while the previous work \cite{cai2021revisiting}
proposes a superpixel-wise class popularity, 
$\frac{|\{ s : \text{D}_\theta(s) = c, s \in \mathcal{S}_t\}|}{|\{s : s \in \mathcal{S}_t \}|} \;$, assuming superpixels of uniform size.


Using the uncertainty $u_\theta(s)$ in \eqref{eq:uncertainty}
and the class popularity $p(c;\theta)$ in \eqref{eq:size-aware-class-balance}, 
we define the following acquisition function 
$a(s; \theta)$
prioritizing uncertain superpixels of rare classes:
\begin{equation}
a(s; \theta):= u_\theta(s) \exp \big({-p(\text{D}_\theta(s) ; \theta)} \big)\;.
\label{acquisition_function}
\end{equation}
We select $B$ superpixels of highest values of $a(s; \theta_{t-1})$
from the merged $\set{S}_t$ for query batch $\set{B}_t$. 



% \begin{equation}
% s^* = \argmax_{s \in \mathcal{S}_t} ~u_\theta(s) \exp({-p(\text{D}_\theta(s) ; \theta)})\;,
% \label{acquisition_function}
% \end{equation}

% where the latter weights to the rare class, and we repeat $B$ times while excluding the selected superpixels in $\set{S}_t$.
% described in \eqref{eq:size-aware-classbalance}.
% where we repeat $B$ times.
% The former measures the uncertainty of a superpixel, and the latter estimates the probability of the estimated dominant label of a superpixel.
%We first estimate the dominant label of a pixel $x$ as:
% \begin{equation}
% \text{D}_\theta(x) = \argmax_{c \in \mathcal{C}} p(y=c \mid x, \theta) \;.
% \end{equation}
%From the estimated dominant labels of pixels, 
% We note that  vs Revisiting
% where $S$ denotes the total merged superpixels in all images.






% \begin{algorithm}[t!]
% \caption{Merging Process (BFS version)}
% \omh{
% \begin{algorithmic}[1]
% \Require
%   Round $t$, Graph $\mathcal{G}(X)$, Similarity threshold $\epsilon$
% \Ensure
%   Pairwise disjoint family $\mathcal{S}_t(X)$ of sets of superpixels, each representing a merging group

%   \State Let $\mathcal{V}$ be the nodes of $\mathcal{G}(X)$ 
%   \State Let $\mathcal{N}(u)$, $\forall u\in\mathcal{V}$, be the neighboring nodes of $u$ 
%   \State $\mathcal{S}_t(X) \gets \emptyset$
%   \State Sort $\mathcal{V}$ in descending order of $u(s;\theta_{t-1}),\forall s\in \mathcal{V}$
%   \For {each unvisited $s$ taken from the sorted list}
%       \State Mark $s$ as visited, $Q \gets \{s\}$, $\mathcal{C}(s) \gets \{s\}$
%       \State $P(s) \gets p(y\,|\,s,\theta_{t-1})$
%       \While {$Q \neq \emptyset$}
%         \State $u \gets \text{\Call{dequeue}{$Q$}}$
%         \For {each unvisited neighbor $v$ of $u$}
%           \State $P(v) \gets p(y\,|\,v,\theta_{t-1})$
%           \If {$\mathrm{JSD}(P(u) \lVert P(v)) < \epsilon$}
%             \State Mark $v$ as visited,
%             \State \Call{enqueue}{$Q$, $v$}, $\mathcal{C}(s) \gets \mathcal{C}(s)\cup \{v\}$
%             \State $P(v) \gets P(u)$
%           \EndIf
%         \EndFor
%       \EndWhile
%       \State $\mathcal{S}_t(X) \gets \mathcal{S}_t(X) \cup \{\mathcal{C}(s)\} $
%   \EndFor
% \end{algorithmic}
% }
% \label{alg:PerSN}
% \end{algorithm}

% Once the graph is constructed, we identify the node $s_h$ with the highest uncertainty and merge it with its adjacent node $s_a$ to create a new merged superpixel $s_m$ if the following condition is satisfied:
% \begin{equation}
% \text{if  } w(s_h, s_a) < \epsilon, \;\;\; s_m = s_h \cup s_a \;,
% \label{eq:epsilon}
% \end{equation}

% The average color of a region $s$ is defined as:
% \begin{equation}
% C(s) := \frac{1}{|s|} \sum_{x \in s} [x] \;,
% \end{equation}
% where $[x]$ denotes the RGB color value of a pixel $x$.

% \begin{figure*}[t!]
%     \captionsetup[subfigure]{font=footnotesize}
%     \centering
%     \begin{subfigure}{.33\linewidth}
%         \centering
%         \includegraphics[scale=0.5]{Figures/fig4_a_1.png}
%         % \caption{$\text{ASA}(S;G)=0.021, \; \text{AF}(G;S)=0.355$}
%         % \vspace{2mm}
%         % \label{(a)-qualitative}
%     \end{subfigure}
%     \begin{subfigure}{.33\linewidth}
%         \centering
%         \includegraphics[scale=0.5]{Figures/fig4_b_1.png}
%         % \caption{$\text{ASA}(S;G)=0.89, \; \text{AF}(G;S)=0.283$}
%         % \vspace{2mm}
%         % \label{(b)-qualitative}
%     \end{subfigure}
%     \begin{subfigure}{.33\linewidth}
%         \centering
%         \includegraphics[scale=0.5]{Figures/fig4_c_1.png}
%         % \caption{$ASA(S;G)=1.00, \; AF(G;S)=1.00$}
%         % \vspace{2mm}
%         % \label{(c)-qualitative}
%     \end{subfigure}
%     \begin{subfigure}{.33\linewidth}
%         \centering
%         \includegraphics[scale=0.5]{Figures/fig4_a_2.png}
%         \caption{Over-segmented superpixels~\cite{van2012seeds}}
%         \label{(a)-qualitative}
%     \end{subfigure}
%     \begin{subfigure}{.33\linewidth}
%         \centering
%         \includegraphics[scale=0.5]{Figures/fig4_b_2.png}
%         \caption{Adaptive superpixels (Ours)}
%         \label{(b)-qualitative}
%     \end{subfigure}
%     \begin{subfigure}{.33\linewidth}
%         \centering
%         \includegraphics[scale=0.5]{Figures/fig4_c_2.png}
%         % \caption{$ASA(S;G)=1.00, \; AF(G;S)=1.00$}
%         \caption{Oracle superpixels}
%         \label{(c)-qualitative}
%     \end{subfigure}
%     \caption{{\em Qualitative results of adaptive superpixels.} As the round progresses, (a) over-segmented superpixels becomes (b) adaptively merged ones, and they resemble (c) oracle superpixels, especially for the classes that the model is confident about. 
%     % \todo{Value analysis}
%     }
%     \label{fig:qualitative}
% \end{figure*}

\smallskip\noindent\textbf{Remarks.}
We note that it is possible to produce $\set{S}_t$ from scratch
rather than from base segmentation $\set{S}_0$.
To reduce the computational cost for the adaptive merging process,
we however compose $\set{S}_t$ by merging base superpixels in $\set{S}_0$
from SEEDS, which is known to generate an over-segmentation of semantics.
Moreover, it is computationally expensive to explore all the possible mergers
and obtain $\set{S}_t$ followed by the query selection.
We hence conduct the merging process only for a certain portion of base superpixels with the highest values of uncertainty (c.f., line~\ref{line:order} in Algorithm~\ref{algorithm2}) and then
select $\set{B}_t$ to be queried since the acquisition function would select 
merged superpixels of high uncertainty in the end.
% Details are in the appendix.
Further details are presented in Appendix~\ref{sec:rationale-merging}.

% To reduce the time complexity of converting superpixels into a graph, we explore and merge superpixels with high uncertainty. Details are in the appendix.



\subsection{Sieving}
\label{sec:sieving-technique}
% After obtaining the dominant label on batch $\mathcal{B}_t$,


% % The dataset for round $t$ is represented as follows:
% % \begin{equation}
% % \!\!\!\! \mathcal{D}_{t} := \{(x, y) : x \in s \in \bigcup_{i \in [t]} \mathcal{B}_{i}, y(c) = \mathbbm{1} [c = \text{D}(s)] \} \;, 
% % % ... 
% % % (s_{t \times b}, \text{D}(s_{t \times b})), 
% % % \text{  where  } s \in \bigcup_{i \in [t]} \mathcal{B}_{t} \}\;,
% % \end{equation}
% % which consists of all superpixels selected prior to round $t$.

% We sieve

% Then, training.
% analog to ... 

% \smallskip\noindent\textbf{Adaptive sieving}


% \smallskip\noindent\textbf{Training.} 


% %$\text{D}(s)$ indicates a dominant label from ground-truth.

Despite the sophisticated design of the adaptive merging,
a queried superpixel can inevitably include 
pixels of classes different from the dominant one,
in particular, as we select superpixels of which model predictions are unsure. Hence, the dominant labeling is liable to make noisy annotations.
% Even when we collect the dominant labels from an oracle, who always tells truth, it is possible that 
% the labeling is noisy for pixels 
% Furthermore, our merging algorithm occasionally combines superpixels with different dominant labels, which can exacerbate the label noise.
% While previous studies have addressed noisy labels in segmentation \cite{acuna2019devil, liu2022adaptive, oh2021background}, these methods deal with a different type of noise than that caused by the imperfection of superpixels.
To alleviate such side effects of the dominant labeling, we propose a simple sieving technique that 
filter out pixels that have high potential risks of being 
different classes than the dominant one.
We observe that
for a queried superpixel $s$ and given model $\theta$, 
the risk of %noisy labeling on pixel $x$
mismatch between the dominant label $D(s)$ and the true label of pixel $x \in s$
would be high when $f_\theta \big( \text{D}(s); x \big)$
is low.
From this observation, we define 
\begin{equation}
h(s;\theta) := \{ x \in s: f_\theta \big( \text{D}(s); x \big) \geq \phi(s; \theta) \} \;,
\label{eq:sieving}
\end{equation}
% \begin{equation}
% \tilde s := \{ x \in s: f_\theta \big( \text{D}(s); x \big) \geq k(s) \} \;,
% \end{equation}
where 
%for superpixel $s$ given model $\theta$,
$\phi(s; \theta)$ is a knee point of the cumulative distribution function of values of $f_\theta \big( \text{D}(s); x \big)$ in superpixel $s$, detected by
Kneedle algorithm~\cite{satopaa2011finding}.
 In addition, 
the knee point detection allows us to have a tailored sieving threshold to each superpixel. This is important to avoid the case that the remained pixels are heavily biased to relatively easy labels after sieving.
Further details are in Appendix \ref{fig:sup-sieving}.
% Further details and examples of knee points are in the appendix.

We revisit all the queried superpixel $s \in \bigcup_{t'=0}^{t} \mathcal{B}_{t'}$ and sieve them using \eqref{eq:sieving}
with the latest model $\theta_{t-1}$
since the model evolves round by round.
%This enables that the sieving can evolve over rounds as model $\theta$ improves.
We finally obtain the following sieved dataset ${\mathcal{D}}_{t}$ for round $t \ge 1$:
\begin{equation}
{\mathcal{D}}_{t} := \left\{(x, y) : 
\begin{aligned}
&\exists s \in \cup_{t'=0}^{t} \mathcal{B}_{t'}, \ x \in h(s;\theta_{t-1}), \\
&y(c) = \mathbbm{1}{[c = \text{D}(s)]} \ \forall c\in\set{C} 
\end{aligned}
\right\} \;.
\label{sieved-superpixel}
\end{equation}
Analogously to the warm-up round, 
initializing model $\theta$ at a model pretrained on ImageNet, we obtain $\theta_t$ trained to mainly minimize the following CE loss:
% \begin{equation}
% \mathcal{L}_{\text{CE}} = - \frac{1}{|\tilde{\mathcal{D}}_{[t]}|} \sum_{(\tilde{s}, y_s) \in \tilde{\mathcal{D}}_{[t]}} \sum_{x \in \tilde{s}} y_s \log p(y \mid x, \theta_t) \;,
% \label{cross-entropy}
% \end{equation}
\begin{equation}
\hat{\mathbb{E}}_{(x,y) \sim {\mathcal{D}}_t} [ \text{CE}(y, f_\theta (x))] \;.
\label{eq:final-loss}
\end{equation}

% Setting the same confidence threshold $\phi(s)$ for every
% superpixel $s$ is prone to generate class imbalance by leaving relatively easy
% classes, and using the same threshold for each class reduces
% regional diversity as only relatively easy superpixels remain in each class.

\iffalse
However, applying the same confidence threshold to all pixels causes class
imbalance by leaving relatively easy classes, and using the same threshold for each class reduces regional diversity as only relatively easy superpixels remain in each class.
We thus introduce an adaptive sieving technique where different confidence thresholds are calculated per round for each superpixel $s$ as:
% in superpixel units, where different confidence thresholds for superpixel are calculated per round.
% only retains pixels with high confidence in the dominant label $\text{D}(s)$ of a superpixel $s$:
\begin{equation}
h(s;\theta) := \{ x \in s: f_\theta \big( \text{D}(s); x \big) \geq \phi(s) \} \;,
\end{equation}
% \begin{equation}
% \tilde s := \{ x \in s: f_\theta \big( \text{D}(s); x \big) \geq k(s) \} \;,
% \end{equation}
where $\phi(s)$ denotes the confidence threshold of a superpixel $s$ parameterized by $\phi$. 
% which balance the trade-off between the number of labeled pixels and its noisiness.
As $\phi(s)$ increases, only a few pixels remain, but the label noise decreases.
For the $\phi$, 
\fi
  %


% \begin{equation}
% \tilde{\mathcal{D}}_{t} = \{(\tilde{s}, \text{D}( s )) : s \in \mathcal{B}_{t} \}\;.
% \label{sieved-superpixel}
% \end{equation}


% \subsection{Splitting High Impurity Regions}
% For better labels, we split superpixels containing many classes.
% We split high-impurity regions using an existing superpixel algorithm.
% \smallskip\noindent\textbf{Region impurity}
% Impurity of region $s$ \cite{xie2022towards}
% \begin{equation}
% I(s) := - \sum_{c=1}^C \frac{N(s,c)}{|s|} \log \frac{N(s,c)}{|s|} \;, 
% \end{equation}
% \begin{equation}
% I(s) := \frac{1}{| s |} \sum_{x \in s} 1 - p(y = \tilde{D_r}(s) \mid x,\theta) 
% \end{equation}
% High impurity regions contain many classes

% \subsection{Feature-based Adaptive Superpixel}
% \smallskip\noindent\textbf{Impurity. (version 1)}
% 1) Impurity of pixel $x$, class $c$, model $\theta$
% \begin{equation}
% I_p(x) := - \frac{1}{|C|} \sum_{c \in C} \left\{ p(y=c \mid x, \theta) - \sum_{c \in C} \frac{p(y=c \mid x, \theta)}{|C|} \right\}^2
% \end{equation}
% Impurity of region $s$
% \begin{equation}
% I_r(s) := \frac{1}{|s|} \sum_{x \in s} I_p(x)     
% \end{equation}
% 2) Region impurity (cvpr, oral, 22)
% \begin{equation}
% \mathcal{N}_k^c(i, j)=\left\{(u, v) \in \mathcal{N}_k(i, j) \mid \widehat{\mathbf{Y}}_t^{(u, v)}=c\right\}
% \end{equation}
% \begin{equation}
% \mathcal{P}^{(i, j)}=-\sum_{c=1}^C \frac{\left|\mathcal{N}_k^c(i, j)\right|}{\left|\mathcal{N}_k(i, j)\right|} \log \frac{\left|\mathcal{N}_k^c(i, j)\right|}{\left|\mathcal{N}_k(i, j)\right|},
% \end{equation}

% \smallskip\noindent\textbf{Splitting. (version 1)}
% Edge weight is defined as KL divergence between two impurities of two pixels.
% \begin{equation}
% E(x_1, x_2) := D_{\mathrm{KL}}(p(y \mid x_1, \theta), p(y \mid x_2, \theta)) 
% \end{equation}
% \begin{equation}
% E(x_1, x_2) := I_p(x_1) + I_p(x_2) 
% \end{equation}
% Cycle generation

%\smallskip\noindent\textbf{Impurity. (v2)}
% Impurity of pixel $x$
% \begin{equation}
% I_p(x) := 1 - p \left( y = \tilde{D_p}(x) \mid x, \theta \right)
% \end{equation}

% Impurity of edge between two pixels $x_1$ and $x_2$
% \begin{equation}
% I_e(x_1, x_2) := I_p(x_1) + I_p(x_2)
% \end{equation}
% \begin{equation}
% I_e(x_1, x_2) := 1 - S_C \big( p(y \mid x_1, \theta), p(y \mid x_2, \theta) \big) 
% \end{equation}
% where $S_c$ denotes the cosine similarity between two vectors.

% \begin{equation}
% I_r(s) := \frac{1}{| s |} \sum_{x \in s} I_p(x)
% \end{equation}
% \begin{equation}
% I_r(s) := \frac{1}{| s |} \sum_{x \in s} 1 - p(y = \tilde{D_r}(s) \mid x,\theta) 
% \end{equation}

% We restrict the impurity of all superpixels as:
% \begin{equation}
% I_r(s) < \epsilon_1 \;\; \forall s \in S \;,
% \end{equation}
% where $\epsilon_1$ determines the number of superpixels (small $\epsilon_1$, large number of superpixels)

% \smallskip\noindent\textbf{Repetitive Splitting. (v3)}
% To split high-impurity superpixel $s$ into $s_1$ and $s_2$, we select edges inside the superpixel in the order of weight until a cycle is generated., into four regions, we select an edge with the highest weight among horizontal edges and vertical edges, respectively. 
% We split high-impurity superpixel $s$ using EAM

% \smallskip\noindent\textbf{Repetitive Merging. (v3)}
% Merge adjacent two regions $s_1$ and $s_2$ to $s$ as: 
% \begin{equation}
% s := {s_1 \cup s_2}
% \end{equation}
% where
% $\tilde{D_r}(s_1) == \tilde{D_r}(s_2)$
% and $I_r(s_1), I_r(s_2) < \epsilon_1$

% \vspace{1mm}
% Impurity of merged region $s$
% \begin{equation}
% I_r(s) = \frac{|s_1| \cdot I_r(s_1) + |s_2| \cdot I_r(s_2)}{|s_1|+|s_2|} < \epsilon_1
% \end{equation}

% \smallskip\noindent\textbf{Repetitive Merging. (v2)}
% Merge adjacent two regions $s_1$ and $s_2$ to $s$ as: 
% \begin{equation}
% s := {s_1 \cup s_2}
% \end{equation}
% where
% $\tilde{D_r}(s_1) == \tilde{D_r}(s_2)$
% and
% $I_r(s_1), I_r(s_2) < \epsilon_1$

% \vspace{1mm}
% Impurity of region $s$
% \begin{equation}
% I_r(s) = \frac{|s_1| \cdot I_r(s_1) + |s_2| \cdot I_r(s_2)}{|s_1|+|s_2|} < \epsilon_1
% \end{equation}

% \smallskip\noindent\textbf{Repetitive Splitting. (v2-1)}
% Split $s$ into $s_1$ (dominant label) and $s_2$ (others) as:
% \begin{equation}
% s_1 := \{ x : I_p(x) < \epsilon_2 \text{ and } x \in s \}
% \end{equation}
% where $I_r(s_1) < \epsilon_1$ ($\epsilon_2$ is determined by $\epsilon_1$)
% \begin{equation}
% s_2 := \{ x : I_p(x) < \epsilon_3 \text{ and } x \in s - s_1 \}
% \end{equation}
% where
% $I_r(s_2) < \epsilon_1$ ($\epsilon_3$ is determined by $\epsilon_1$)
% \begin{equation}
% s_3 := \{ x : I_p(x) < \epsilon_4 \text{ and } x \in s - s_1 - s_2 \}
% \end{equation}
% where
% $I_r(s_3) < \epsilon_1$ ($\epsilon_4$ is determined by $\epsilon_1$)

% \smallskip\noindent\textbf{Splitting. (v2)}
% Split $s$ into $s_1$ (dominant label) and $s_2$ (others) as:
% \begin{equation}
% s_1 := \{ x : I_p(x) \geq \epsilon_2 \text{ and } x \in s \}
% \end{equation}
% \begin{equation}
% s_2 := \{ x : I_p(x) < \epsilon_2 \text{ and } x \in s \}
% \end{equation}
% where
% $I_r(s) \geq \epsilon_1$

% \subsection{Sieved Dataset}
% % sieve (ICLR, 21) We manage noisy dominant labels, 
% $N_t$ denotes the noisy dataset obtained at round $t$

% \begin{gather}
% N'_{t-1} := \nonumber \\ \left\{ (x,\tilde{y}) : p(y=\tilde{y} \mid x, \theta_{t-1}) > \epsilon_2
% \text{ and } (x,\tilde{y}) \in \{ N_i \}_{i=1}^{t-1} \right\}
% \end{gather}

% \begin{equation}
% N'_t := N_t \cup N'_{t-1}
% \end{equation}

% Cross Entropy Loss (CE) at round $t$
% \begin{equation}
% \mathcal{L}_{CE} = - \sum_{I \in N'_t} \sum_{x \in I} \tilde{y} \log p(y \mid x, \theta) 
% \end{equation}

% \smallskip\noindent\textbf{Big Superpixels.}
% cold starting problem, cannot use $\theta_t$, big superpixels, more information
% Pixel $x$
% \begin{equation}
% a(s) := |\{x : x \in s\}| 
% \end{equation}

% Class weight (revisiting), big object consists of many superpixels
% \begin{equation}
% w(c) \propto |\{s: \tilde{D_r}(s) == c\}|
% \end{equation}

% Weight (revisiting), seeds, big object consists of many superpixels
% \begin{equation}
% p(c l s) \propto |\{s: D o(s)==c l s\}|
% \end{equation}

% \begin{equation}
% p(c l s) \propto |\{x: \arg\max p(y \mid x, \theta) == cls \}|.
% \end{equation}
