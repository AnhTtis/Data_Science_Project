
\let\hl=\undefined
\newcommand\hl[1]{\textcolor{blue}{#1}}

\begin{figure}[!t]
    % \captionsetup[subfigure]{font=footnotesize}
    \centering
    \begin{subfigure}[h!]{.49\linewidth}
        \centering
        % \includegraphics[scale=0.078]{Figures/aachen_000000_000019.jpg}
        \includegraphics[scale=0.231]{Figures/fig1/fig_1_a.png}
        % \includegraphics[scale=0.121]{Figures/fig1/fig1_a.png}
        \caption{Over-segmented $(t=0)$}
        \label{(a)-adaptive}
        \vspace{2mm}
    \end{subfigure}
    \begin{subfigure}[h!]{.49\linewidth}
        \centering
        % \includegraphics[scale=0.078]{Figures/cityscapes_merged_round1.jpg}
        \includegraphics[scale=0.231]{Figures/fig1/fig_1_b_v2.png}
        % \includegraphics[scale=0.121]{Figures/fig1/fig1_b.png}
        \caption{Adaptive merged $(t=2)$}
        \label{(b)-adaptive}
        \vspace{2mm}
    \end{subfigure}
    \begin{subfigure}[h!]{.49\linewidth}
        \centering
        % \includegraphics[scale=0.078]{Figures/cityscapes_merged_round1.jpg}
        \includegraphics[scale=0.231]{Figures/fig1/fig_1_c_v2.png}
        % \includegraphics[scale=0.121]{Figures/fig1/fig1_c.png}
        \caption{Adaptive merged $(t=4)$}
        \label{(c)-adaptive}
    \end{subfigure}
    \begin{subfigure}[h!]{.49\linewidth}
        \centering
        % \includegraphics[scale=0.078]{Figures/cityscapes_merged_round1.jpg}
        \includegraphics[scale=0.231]{Figures/fig1/fig_1_d_v4.jpg}
        % \includegraphics[scale=0.121]{Figures/fig1/fig1_d.png}
        \caption{Oracle}
        \label{fig:(d)_adaptive_merged_superpixels}
    \end{subfigure}
    \caption{{\em Examples of adaptive superpixels.} (a) We begin active learning with over-segmented superpixels. (b, c) In each round $t$, we merge superpixels in an adaptive manner using the model from the previous round. % $t-1$. 
    (d) As the round progresses, adaptive superpixels look similar to oracle ones.}
    \label{fig:adaptive_merged_superpixels}
    % \vspace{-3mm}
\end{figure}

\begin{figure*}[t!]
    \centering
    \includegraphics[scale=0.52]{Figures/overall_arch_share_v7.pdf}
    \caption{{\em An overview of the proposed framework.} In each round $t$, we merge superpixels with a graph using the latest model, and obtain dominant labels for selected superpixels. The dominant labels are selectively propagated to pixels with confidence above the detected knee point, resulting in the creation of a sieved dataset. Finally, we train a model with the sieved one.}
    \label{fig:method}
    % \vspace{-2mm}
\end{figure*}

\section{Introduction}
With the advent of deep learning, many computer vision tasks including semantic segmentation have dramatically evolved in recent years.
Such advances are thanks to complex deep network models that can learn huge datasets. However, labeling such large datasets is prohibitively time-consuming and labor-intensive, in particular, for semantic segmentation tasks that demand a dense annotation on each pixel \cite{Cordts2016Cityscapes, everingham2015pascal}. Active learning (AL) offers an approach to alleviate the annotation cost  by selectively querying only the most informative samples to annotators.

%selectively obtaining labels for the most informative pixels determined by a well-designed acquisition function.
%In general, the acquisition function prioritizes the selection of unlabeled samples that a model is uncertain about, in order to improve the performance.
% =====
% what is efficient query?
% reviisiting
% =====

Designing an effective form of annotation query is critical in practice 
as it determines the actual annotation cost such as the number of clicks required
and the informativeness per annotation query.
For semantic segmentation, an image-wise query can be asked for a complete annotation on the semantic of every pixel in an image~\cite{chengliang2020suggestive,desai2022active,sinha2019variational,xie2020deal,yang2017suggestive}.
This is a daunting task requiring an enormous amount of clicks to indicate boundaries (using polygons or contours) for each semantic segment or to annotate semantic pixel-wisely, while 
the diversity of contexts which we can observe in a single image is restricted. 
Alternatively, one can design a {\it region-based}
query enquiring only about the dominant label of a small region such as rectangle patch \cite{casanova2019reinforced,qiao2022cpral,xie2022towards} or superpixel 
%(a cluster of neighboring superpixels of similar color )
\cite{cai2021revisiting,siddiqui2020viewal}. 
This is known to be simple yet effective 
as it requires only a single click per query while enabling AL to put more focus on significant regions
and to avoid annotation wastes.

% partition an image into multiple regions and request each region as a query~\cite{qiao2022cpral,mackowiak2018cereals,casanova2019reinforced,siddiqui2020viewal}. 
%This way is often useful since learning procedure can put more focus on important regions avoiding waste of annotation effort.
% Additionally, the labeling mechanism can be further optimized based on the shape of regions.
% Also, based on the shape of regions, labeling mechanism can be further optimized. 
% With rectangular partitioning, a sparse set of clicks (\ie., polygon vertices on the segmentation contour and class assignment) can recover dense pixel-wise annotations for each patch~\cite{colling2020metabox+,mackowiak2018cereals}.
% With boundary-preserving partitioning (\eg., superpixels), only one click is sufficient for labeling each queried region
% ~\cite{cai2021revisiting} since answering the majority class of pixels within each region is enough. 
% We refer to that label obtained in that way as the dominant label.


\iffalse
In AL for semantic segmentation, it is possible to request dense pixel-wise annotation~\cite{casanova2019reinforced,qiao2022cpral,yang2017suggestive} 
%to an oracle who always provides correct labels, 
while it makes the annotation process daunting due to the direct proportionality between the required number of clicks and the query's granularity (\eg., images or regions).
Instead, one can partition each unlabeled image into boundary-preserving pixel groups (\ie., superpixels), and request labels for them.
Using superpixels as the units for querying allows for efficient labeling, as only one click is needed to label each queried superpixel~\cite{cai2021revisiting}. This is due to the fact that determining the majority class of pixels within a superpixel is sufficient for labeling purposes. We refer to a label obtained by the majority click as the dominant label.
\fi

%However, under realistic click-based annotation costs~\cite{cai2021revisiting,colling2020metabox+,mackowiak2018cereals}, the oracle should click in proportion to the number of pixels in the patches, which causes increased costs as the patch size increases.
%The leverage of superpixels in AL facilitates the labeling of one semantic category per region with a click by grouping neighboring pixels into perceptually meaningful regions~\cite{cai2021revisiting, siddiqui2020viewal}.
%The annotation of a superpixel is conducted by obtaining the majority class of pixels within the superpixel, known as dominant labeling.
%Recent research demonstrates that using superpixels reduces the click budgets compared to using rectangles~\cite{cai2021revisiting}.


\iffalse
In the context of AL for semantic segmentation, there exist two query granularities: rectangle and superpixel units. 
% In AL for semantic segmentation, granularity of query is typically two-kinds: image-level, or regional units. 
Using each image as a query~\cite{chengliang2020suggestive,desai2022active,sinha2019variational,xie2020deal,yang2017suggestive} requires annotators to assign semantic categories to each pixel in the entire image, leading to a high annotation burden.
Alternatively, one can partition an image into multiple regions and request each region as a query~\cite{qiao2022cpral,mackowiak2018cereals,casanova2019reinforced,siddiqui2020viewal}. 
%This way is often useful since learning procedure can put more focus on important regions avoiding waste of annotation effort.
This approach is frequently beneficial as AL can put more focus on significant regions, avoiding wasting annotation effort.
% preventing unnecessary annotation efforts from being wasted.
Additionally, the labeling mechanism can be further optimized based on the shape of regions.
% Also, based on the shape of regions, labeling mechanism can be further optimized. 
With rectangular partitioning, a sparse set of clicks (\ie., polygon vertices on the segmentation contour and class assignment) can recover dense pixel-wise annotations for each patch~\cite{mackowiak2018cereals,colling2020metabox+}.
With boundary-preserving partitioning (\eg., superpixels), only one click is sufficient for labeling each queried region
~\cite{cai2021revisiting} since answering the majority class of pixels within each region is enough. 
We refer to that label obtained in that way as the dominant label.
\fi

\iffalse
Pixel-wise annotations are obtained for the most informative patches with the help of an oracle who always provides correct labels.
However, under realistic click-based annotation costs~\cite{cai2021revisiting,colling2020metabox+,mackowiak2018cereals}, the oracle should click in proportion to the number of pixels in the patches, which causes increased costs as the patch size increases.
The leverage of superpixels in AL facilitates the labeling of one semantic category per region with a click by grouping neighboring pixels into perceptually meaningful regions~\cite{cai2021revisiting, siddiqui2020viewal}.
The annotation of a superpixel is conducted by obtaining the majority class of pixels within the superpixel, known as dominant labeling.
Recent research demonstrates that using superpixels reduces the click budgets compared to using rectangles~\cite{cai2021revisiting}.
\fi

% ^~~ dominant labeling
% ^~~ polygon clicks, intersection clicks, etc.
% =====
% oversegmentation, throuput problem
% =====


AL with the region-based query needs a delicate generation of candidate regions to be queried. A small region size dilutes the budget efficiency, whereas the dominant labeling even by a perfect annotator is prone to give noisy labels when regions are too large to be consisting of pixels with a single class. However, the previous works~\cite{casanova2019reinforced,qiao2022cpral,siddiqui2020viewal}
rely on a fixed candidate set of regions of uniform size, while we could adjust the size and shape of candidate regions as we train the semantic segmentation model over rounds of AL. This limitation remains even in recent work \cite{cai2021revisiting}
with superpixel candidates providing less 
risk of noisy labels than rectangle ones
since the superpixels are produced, only at the beginning, by a conventional superpixel algorithm,
where conventional superpixel algorithms ~\cite{achanta2012slic,jianbo2000normalized,van2012seeds} cluster adjacent pixels of similar innate features (\eg., color) with implicit or explicit regularization to make similar sizes or shapes of superpixels, \ie., limited freedom of query region.



%\vspace{-.4mm}

\let\oldparskip=\parskip
\parskip=0mm

In this paper, to fully enjoy the benefit in terms of annotation cost while suppressing the risk of noisy labels, 
we devise an AL framework, illustrated in Figure~\ref{fig:method}, consisting of adaptive merging and sieving methods.
The adaptive merging method % (Figure~\ref{fig:method})
repeatedly evolves the candidate superpixels for dominant labeling at every round with the latest model and no explicit regularization on the size and shape of superpixels.
% we propose an adaptive merging algorithm~(Figure~\ref{fig:method}) that aims to increase labeling efficiency by merging adjacent and similar superpixels using a trained model. 
This indeed enables the continual improvement 
of
the superpixels' ability to accurately capture the boundaries of semantic objects~(Figure~\ref{(b)-adaptive} and \ref{(c)-adaptive}),
and a proper variation in the sizes and shapes of superpixels, \ie., larger superpixels being attached to larger semantic objects (\eg., road and building) and smaller ones to smaller objects (\eg., human and vehicle) as shown in the ideal ones~(Figure~\ref{fig:(d)_adaptive_merged_superpixels}).


% where the former
% evolves the candidate superpixels for dominant labeling at every round,
% and the latter identifies and leaves out annotations with the high risk of noisy labels given the latest model.

% In the merging process, superpixels with different dominant labels may be merged, and even if superpixels are merged accurately, noisy labels can exist due to the inherent imperfectness of superpixels.
% As the dominant label of a superpixel propagates to its constituent pixels, the ground-truth of a pixel and the dominant label can differ.

Given the adaptive superpixels, we establish
a corresponding acquisition function being aware of irregular superpixel sizes.
It prioritizes uncertain superpixels of rare classes
in order to query the most informative superpixels while balancing class distributions in the entire annotations. In addition, 
to alleviate the inevitable noise in the dominant labeling, we propose a sieving technique 
that excludes labeled pixels of high potential risks of being different classes than the dominant one. 
To be specific, we identify such pixels of potentially noisy labels by 
per-superpixel sieving with distinct thresholds over superpixels. This provides stabler denoising 
than uniform sieving with a constant threshold, which might aggravate class imbalance in the sieved annotations. 
%the  provides class imbalance.

%relatively unsure pixels within each queried superpixel from training. 
%The remaining labeled areas are then utilized for training the model.
%Here, the per-superpixel sieving provides class imbalance.

% prevents class imbalance 
% since the noise is recognized using a distinct threshold for each superpixel.

\parskip=\oldparskip

\iffalse
The adoption of superpixel-wise dominant labeling in AL for semantic segmentation significantly reduces the annotation burden~\cite{cai2021revisiting}.
However, conventional algorithms for superpixel generation~\cite{achanta2012slic,jianbo2000normalized,van2012seeds} are unsuitable for AL. 
This is because superpixels are designed for over-segmenting images into regions that are regular in shape and size~\cite{levinshtein2009turbopixels} (Figure~\ref{(a)-adaptive}), which can constrain the formation of more effective queries.
Since the throughput of every query is bounded by the number of pixels in the smallest semantic area in the dataset, it is necessary to discard the regularity constraints from the process of superpixel generation in order to reflect the actual size of semantic objects in the dataset. 
%Moreover, the size of superpixels significantly influences the quality of partitioning, which in turn affects the performance of AL.
%From a perspective of labeling efficacy, diverse size of superpixels reflecting the actual size of objects is necessary.
% However, determining the optimal superpixel size in advance of AL rounds is a challenging task.



In order to fully enjoy the benefits of dominant labels, we propose an adaptive approach that updates the base superpixels by merging adjacent and similar superpixels into a single one per round, based on a model trained in the previous round~(Figure~\ref{fig:method}).
% we propose an adaptive merging algorithm~(Figure~\ref{fig:method}) that aims to increase labeling efficiency by merging adjacent and similar superpixels using a trained model. 
Additionally, we repeatedly perform such consolidation in an adaptive manner to improve the superpixels' ability to accurately capture the boundaries of semantic objects~(Figure~\ref{(b)-adaptive} and \ref{(c)-adaptive}). 
This approach results in a variation in the sizes of superpixels, with larger superpixels being attached to larger semantic objects (\eg., road and building) and smaller ones to smaller objects (\eg., human and vehicle). 
By repeating the adaptive merging at each round, superpixels become more similar to the ideal ones~(Figure~\ref{fig:(d)_adaptive_merged_superpixels}).

% Superpixel-wise dominant labeling dramatically reduce annotation burden in AL for segmentation,
% however, conventional superpixel generation algorithms
% Also, choice of the common size of superpixels hugely affects the quality of partitioning \cite{goh2021sizes}, which in turn affects the performance in AL. 
% However, it is difficult
% (or even impossible), in practice, 
% to find the best choice of superpixel size in advance of AL rounds. 
% for active semantic segmentation
% ^~~~ 좀 더 명확한 문장으로
% static 관련 얘기 들어가야됨
% =====
% importance of "adaptive" "merging"
% =====
%To fully enjoy dominant labeling, our motivation is two-fold: removing uniformity in superpixel size, by merging them with the aid of a trained model, can make labeling more efficient (Figure~\ref{(b)-adaptive}); and adaptively repeating such consolidation can make superpixels align with the ideal ones (Figure~\ref{(c)-adaptive} and \ref{fig:(d)_adaptive_merged_superpixels}). 
%To fully enjoy the dominant labeling, our objective is two-fold: to remove uniformity in superpixel size, by merging them with the aid of a trained model, to make labeling more efficient (Figure~\ref{(b)-adaptive}); and to adaptively repeate such consolidation to make superpixels better capture the boundaries of ideal superpixels (Figure~\ref{(c)-adaptive} and \ref{fig:(d)_adaptive_merged_superpixels}).
%\todo{In order to fully utilize the dominant labeling, our objective is two-fold. Firstly, to increase labeling efficiency, we aim to eliminate uniformity in superpixel size by merging them with the assistance of a trained model~(Figure~\ref{(b)-adaptive}). Secondly, we aim to repeatedly perform this consolidation in an adaptive manner, thereby enhancing the ability of the superpixels to accurately capture the boundaries of ideal superpixels~(Figure~\ref{(c)-adaptive} and \ref{fig:(d)_adaptive_merged_superpixels}). With this approach, size of superpixels becomes varied in a way that lager superpixels are attached to larger semantic objects (\eg., road and building) and smaller ones to smaller objects (\eg., human and vehicle).}
% [More details here?]
% By repeating the adaptive merging at each round, we can achieve superpixels that closely resemble the ideal ones~(Figure~\ref{fig:(d)_adaptive_merged_superpixels}).
%our objective is two-fold. Firstly, to increase labeling efficiency, we aim to eliminate uniformity in superpixel size by merging them with the assistance of a trained model~(Figure~\ref{(b)-adaptive}). Secondly, we aim to repeatedly perform this consolidation in an adaptive manner, thereby enhancing the ability of the superpixels to accurately capture the boundaries of ideal superpixels~(Figure~\ref{(c)-adaptive} and \ref{fig:(d)_adaptive_merged_superpixels}).


% =====
% noise, how to?
% =====

%The merging procedure seems efficient, though merged superpixels may contain severe noise that degrades model performance. 
%The merging procedure could save annotation budget, while merged superpixels may contain noise that degrades model performance.
In the merging process, superpixels with different dominant labels may be merged, and even if superpixels are merged accurately, noisy labels can exist due to the inherent imperfectness of superpixels.
As the dominant label of a superpixel propagates to its constituent pixels, the ground-truth of a pixel and the dominant label can differ.
To alleviate the side effect of noisy labels, we propose a sieving technique~(Figure~\ref{fig:method}) 
that identifies less certain areas within each labeled superpixel and eliminates them. 
The remaining labeled areas are then utilized for training the model.
This denoising approach prevents class imbalance 
% and preserves region diversity 
since the noise is recognized using a distinct threshold for each superpixel.
\fi
% By denoising the labels in this manner, we can prevent class imbalance and remain region diversity since the noise is detected using different criteria for each superpixel.
% that only uses the annotation on pixels with high confidence to the dominant label.
% The merging process can help to save annotation cost, but it may introduce noise into the merged superpixels, which can degrades the performance of the model.
%Such noise occurs when superpixels with different majority classes are merged, which can be frequent at early rounds due to model instability; or is retained when over-segmented base superpixels, generated before active learning starts, fail to preserve the exact boundary of semantic objects. 
% This type of noise arises when superpixels with distinct majority classes are combined, which can be common during the early rounds due to the instability of the model,
% or when over-segmented base superpixels, produced prior to active learning, fail to preserve the exact boundaries of semantic objects.
% TOO LONG...
%To mitigate the effect of noise, we propose an adaptive sieving technique that detects less-confident parts for each of the labeled superpixels, and throws such parts away from them. 
% To reduce the impact of noise, we propose an adaptive sieving technique~(Figure~\ref{fig:method}) that identifies less confident areas within each labeled superpixels and eliminates them. The remaining labeled areas are then fed into the model for training.
%Denoising labels in such a way can avoid class imbalance since noise is detected with different criteria for different superpixels, and gradually improves as the rounds proceed.
% By denoising the labels in this manner, we can prevent class imbalance since the noise is detected using different criteria for each superpixel.
% , and gradually improves as the rounds progress.

% =====
% performance improvements
% 8192 > 512
% (intution, justification) new metric -> look-ahead performance -> (inspection) choice of base superpixel
% =====

Through the integration of adaptive merging and sieving into an AL framework, we achieve improved 
accuracy and budget-efficiency over a baseline method. 
% that relies solely on the dominant labels of superpixels.
% Notably, the merging is effective under small superpixels and the sieving is effective under large superpixels, which is related to the qunantity and quality of labels, respectively.
Notably, the merging demonstrates effectiveness under small-sized superpixels, while the sieving plays a critical role given large-sized superpixels.
%which are associated with the quantity and quality of labels, respectively.
Moreover, we show a consistent improvement 
over existing methods in various settings. %independent of the base size.
% Notably, the benefits are apparent when the size of base superpixels is small. 
% as the merging of adjacent and similar superpixels becomes more effective.
% In addition, we show a consistent improvement independent of the base size.
% minimal performance guarantee that is invariant to the choice of the base size.
We provide a thorough justification of the proposed method using various quantitative measures, 
where we introduce 
a new evaluation metric for superpixel algorithms 
that assesses both (achievable) accuracy and recall,
where the recall is overlooked in 
the existing one, the achievable segmentation accuracy~(ASA)~\cite{liu2011entropy}
but important in the context of AL.
This may give new insights into developing superpixel algorithms.
% This may give a new insight 
% being aware of annotation cost and 
% in the context
% of AL, while ,
% irrespective of 
% which assesses the quality of labels,
% % the consistency within a superpixel
% and a modified version of the ASA metric, which enables us to also assess the quantity of labels.
\iffalse
We thoroughly inspect
\fi

% the look-ahead performance of the superpixels.

% consistent improve
% We also introduce a modified version of ASA, specifically designed to evaluate superpixels in the context of our proposed framework.
% We demonstrate improved performance over a baseline method, which utilizes only static superpixels and dominant labeling, by incorporating adaptive merging and sieving into the active learning framework. The benefits are particularly noticeable when the size of the base superpixels is small, as the merging of adjacent and similar superpixels becomes more effective.
% Also, we show minimal guarantee on performance boost which is invariant to the choice of the base size.
%Furthermore, we provide a minimal performance boost guarantee that is independent of the choice of the base size.
%In addition, to explain such advancement, we inspect superpixels with various quantitative measures: achievable semantic segmentation~(ASA)~\cite{liu2011entropy} which evaluates consistency within a superpixel; and achievable precision~(AP), recall~(AR) and F1-score~(AF) which are introduced to take into account both quality and throughput since the need for reflecting superpixel size is brought about by the merging algorithm.
% To analyze such advancement, we inspect superpixels using various quantitative measures, including the achievable semantic segmentation~(ASA)~\cite{liu2011entropy} which assesses the consistency within a superpixel. 
% We also introduce a modified version of ASA, specifically designed to evaluate superpixels in the context of our proposed framework.
% \todo{In addition, we propose new evaluation metrics for superpixels, which are more suitable under the proposed framework.
% Conventionally, superpixels are evaluated by the consistency and boundary alignment within a superpixel \cite{achanta2012slic,jampani2018superpixel,yang2020superpixel}, both of which focus on the quality of superpixels. 
% However, the need for reflecting superpixel size is brought about by the merging algorithm. 
% Therefore, we suggest quantitative metric based on F1-score, taking into account both the quality and throughput.
% Furthermore, we show high correlation between the metric and AL performance, thereby providing an effective tool to look-ahead consequence of base superpixel selection.}

Our main contributions are summarized as follows:
\begin{itemize}
    \item We propose an adaptive merging algorithm where superpixels are updated at each round (Section~\ref{sec:adaptive-merging}), and show the effectiveness of adaptive merging rather than only merging once (Section~\ref{sec:effect-of-adaptive}).
    \item We alleviate the side effect of noisy labels via a sieving technique (Section~\ref{sec:sieving-technique}), and demonstrate especially efficient under large superpixels (Section~\ref{sec:effect-of-adaptive}).
    \item
    In various realistic experiments, we demonstrate the consistent improvement of the proposed AL framework, consisting of the adaptive merging and sieving methods with the dedicated acquisition function, over existing ones (Section~\ref{sec:effect-of-adaptive}).
    \item
    We provide an insightful analysis on proper superpixels for AL with 
    the new evaluation metric of superpixel algorithms being aware of usage in AL (Section~\ref{sec:confusion-matrix}).
    % \vspace{-1mm}
    % \item
    % and quantitatively analyze adaptive superpixels for reasoning of the improvement (Section~\ref{sec:confusion-matrix}).
    %\item We improve performance with adaptive merging and sieving (Section~\ref{sec:effect-of-adaptive}), and propose new metrics as analysis tools for their effectiveness (Section~\ref{sec:confusion-matrix}).
    % \item We present an oracle superpixel baseline as an upper bound (Section~\ref{para:oracle-superpixels}), and propose novel achievable metrics to evaluate the suitability of superpixels in active learning (Section~\ref{sec:confusion-matrix}).
\end{itemize}

\iffalse
Designing a form of annotation query is critical in practice of AL
as it determines the actual annotation cost, \eg., number of clicks, for query. In AL for semantic segmentation, annotation tasks 
\ok{pixel-wise vs. superpixel-wise. trade-off in superpixel: our main focus.}

% can be given image-wise \cite{sinha2019variational,yang2017suggestive, xxx} or region-based \cite{cai2021revisiting, casanova2019reinforced,colling2020metabox+,mackowiak2018cereals, xxx}. 
% An image-wise task asks to identify all the semantic labels per pixel given an image. The region-based one is associated with a region (such as pixel, rectangle and superpixel) in images and enquires about the label of majority pixels within the region. It is 

% ====
% oversegmentation, throuput problem

\ok{3. Limitations in previous works with superpixel: superpixel algorithm for over-segmentation, which are conservative...}

% =====
% importance of merge

\ok{4. To fully enjoy.... we address this, we provide an adaptive merging.}

% ===
% noise, how to?

\ok{5. sieving for denoising...}

% =====
% performance improvements
% 8192 > 512
% (intution, justification) new metric -> look-ahead performance -> (inspection) choice of base superpixel
% 

\ok{6. aggregation of merging + sieving, evaluation. in particular, the benefit is large when over-segmentation base... ASA, AP... tool can be used for superpixel algorithms.}
\fi


\iffalse
In AL for semantic segmentation, unlabeled samples are considered as individual images or regions within images.
Region-based approaches~\cite{cai2021revisiting, casanova2019reinforced,colling2020metabox+,mackowiak2018cereals} typically outperform image-wise sampling~\cite{sinha2019variational,yang2017suggestive} by increasing the diversity of data through dividing images into multiple regions. 
In a specific, images are divided into small rectangular patches and pixel-wise annotations are obtained for the most informative patches with the help of an oracle who always provides correct labels.
However, under realistic click-based annotation costs~\cite{cai2021revisiting,colling2020metabox+,mackowiak2018cereals}, the oracle should click in proportion to the number of pixels in the patches, which causes increased costs as the patch size increases.

\fi

\iffalse
The leverage of superpixels in AL facilitates the labeling of one semantic category per region with a click by grouping neighboring pixels into perceptually meaningful regions~\cite{cai2021revisiting, siddiqui2020viewal}.
The annotation of a superpixel is conducted by obtaining the majority class of pixels within the superpixel, known as dominant labeling.
Recent research demonstrates that using superpixels reduces the click budgets compared to using rectangles~\cite{cai2021revisiting}.
% is more efficient in reducing click-based annotation costs compared to rectangles \cite{cai2021revisiting}.
However, it should be emphasized that superpixels are primarily employed for image over-segmentation~\cite{achanta2012slic, ren2003learning, van2012seeds}, while the goal of AL is to minimize annotation costs.
% and the degree of over-segmentation is closely related to the size of superpixels.
\fi
\iffalse
Superpixel-based AL has employed over-segmented superpixels as a base pool that remains unchanged throughout the rounds (Figure~\ref{(a)-adaptive}).
The over-segmentation of superpixels enhances the consistency of pixel labels within a superpixel, leading to superior quality of dominant labels.
However, over-segmentation reduces the size of superpixels, resulting in a decrease in the number of labels obtained with a click.
To address the tradeoff between the quality and quantity of labels in AL, we propose an adaptive approach that updates the base superpixels by merging multiple superpixels into a single one per round, based on a model trained in the previous round.
The adaptively merged superpixels reflect the actual size of objects in an image, such as larger superpixels for larger objects and smaller ones for smaller objects (Figures~\ref{(b)-adaptive} and \ref{(c)-adaptive}), which increases the labeling efficiency under limited labeling costs.
\fi

% Therefore, an adaptive superpixel size reflecting the actual size of objects in an image is necessary, such as larger superpixels for larger objects and smaller ones for smaller objects.
% However, these static superpixels require several clicks for receiving labels of large regions.
% the static superpixels increase costs as it is impossible to receive labels for large regions at once.
% fail to reflect the diversity in the number of instances and the actual size of objects in images.
% To address the limitation, we introduce an adaptive approach that updates the pool of superpixels by merging multiple superpixels into one based on the latest model

\iffalse
In the merging process, superpixels with different dominant labels may be merged, and even if superpixels are merged correctly, noisy labels can exist due to the characteristic of dominant labeling.
As a dominant label of a superpixel propagates to its constituent pixels, the ground-truth of a pixel and the dominant label can be different.
To alleviate the side effect of noisy labels, we propose an adaptive sieving technique that only uses the annotation on pixels with high confidence to the dominant label.
In addition, we evaluate the adaptive superpixels with quantitative metrics.
% In addition, we propose novel achievable metrics to enhance the understanding of superpixels suitable for AL.
The conventional ones measure the consistency and boundary alignment within a superpixel~\cite{achanta2012slic,jampani2018superpixel,yang2020superpixel}.
Both metrics evaluate the quality of superpixels compared with ground-truth, but the consideration of the size of superpixels is excluded, which is important in AL.
% Both metrics increase as an image is over-segmented, and neither of the metrics considers the amount of labels.
% where they disregard the quantity of labels important in AL. 
% which is far from AL, where the quantity of labeling is also important.
We thus propose novel achievable metrics, including precision, recall and F1-score, which take into account both the quality and quantity of labels. 
% The constituent pixels of a superpixel have noisy labels, i.e., the difference between the ground-truth of a pixel and the dominant label of a superpixel can occur.
% but our sieving minimizes the impact of noisy labels resulting from incorrect merging.
% To address the limitation, we introduce an adaptive approach that updates the pool of superpixels by merging multiple superpixels into one based on the latest model 
% Acquiring a substantial number of labels with a single click is essential in AL.
% the over-segmentation decreases the quantity of labels, where 
% Superpixel-based AL relies on using uniformly over-segmented superpixels as the initial pool, which remains unchanged throughout the rounds (Figure~\ref{(a)-adaptive}).
% while the goal of AL is to minimize annotation costs.
% and the degree of over-segmentation, which is closely related to the initial size of superpixels, is significantly important.
% the goal of active learning is to minimize annotation costs, i.e., over-segmentation increase the costs as requiring more clicks for the same number of pixels.

% The over-segmentation of superpixels is related to conventional evaluation metrics which include the consistency of ground-truth within a superpixel and the alignment of superpixel boundaries with ground-truth \cite{achanta2012slic,jampani2018superpixel,yang2020superpixel}.
% Although higher consistency and alignment can lead to superior dominant labels and benefit active learning, over-segmentation of large regions incurs higher labeling costs.
% Furthermore, we propose novel achievable metrics based on the confusion matrix to evaluate the suitability of the generated superpixels for active learning.
% Our metrics consider the amount of labels instead of the conventional metric that includes achievable segmentation accuracy and boundary recall, which increases with the degree of over-segmentation.

% Acquiring a substantial number of labels with a single click is essential in AL.
% However, large initial superpixels may result in mixed classes, lowering the quality of dominant labels.
% Consequently, the constituent pixels of a superpixel have noisy labels, i.e., the difference between the ground-truth of a pixel and the dominant label of a superpixel can occur.
% To alleviate the side effect of noisy labels, we propose a superpixel-wise sieving technique that only leverages pixels with high confidence to the dominant label.
% While the sieving is robust to the initial size of the superpixels, superpixel algorithms tend to produce uniformly-sized superpixels~\cite{achanta2012slic,liu2011entropy}, which are insufficient for detecting small object classes. 
% A recent study merges squares of varying sizes into a superpixel through a breadth-first search on a color embedding space~\cite{an2020extract}.
% However, this method involves substantial computational time, making it impractical for use in multiple rounds of AL.

% Superpixel-based AL relies on using uniformly over-segmented superpixels as the initial pool, which remains unchanged throughout the rounds (Figure~\ref{(a)-adaptive}).
% However, these static superpixels require several clicks for receiving labels of large regions.
% the static superpixels increase costs as it is impossible to receive labels for large regions at once.
% fail to reflect the diversity in the number of instances and the actual size of objects in images.
% To address the limitation, we introduce an adaptive approach that updates the pool of superpixels by merging multiple superpixels into one based on the latest model 
% a model trained in the previous round 
% (Figures~\ref{(b)-adaptive} and \ref{(c)-adaptive}).
% In the process, superpixels with different dominant labels may merge, but our sieving minimizes the impact of noisy labels resulting from incorrect merging.
% In addition, we evaluate the adaptively merged superpixels with quantitative metrics.
% In addition, we propose novel achievable metrics to enhance the understanding of superpixels suitable for AL.
% The conventional ones measure the consistency and boundary alignment within a superpixel~\cite{achanta2012slic,jampani2018superpixel,yang2020superpixel}.
% Both metrics increase as an image is over-segmented, where they disregards the quantity of labels important in AL. 
% which is far from AL, where the quantity of labeling is also important.
% We thus propose novel achievable metrics, including precision, recall and F1-score, which take into account both the quality and quantity of labels. 
% As an image is over-segmented, the consistency and alignment increase, which leads to the improvement of the quality of the dominant label.
% However, the over-segmentation of large regions incurs higher labeling costs, which degrades the performance in AL.
% To evaluate how suitable a given superpixel is for AL, from a concept of a confusion matrix, we propose novel evaluation metrics which take into account both the quantity and quality of labeling.
% The conventional evaluation metrics that measure the consistency and boundary alignment within a superpixel \cite{achanta2012slic,jampani2018superpixel,yang2020superpixel} are far from active learning, since they tend to increase as the image becomes over-segmented.
% The conventional evaluation metrics including the consistency and boundary alignment within a superpixel are unsuitable for active learning, which 
% superpixel consistency and boundary alignment within a superpixel are less suitable for active learning, which emphasizes the quantity of labeling, as they tend to increase as the image becomes over-segmented.
% As the image is over-segmented, the consistency and alignment increase, which leads to the improvement of the quality of the dominant label.
% However, the over-segmentation of large regions incurs higher labeling costs, which degrades the performance in AL.
% To evaluate how suitable a given superpixel is for AL, from a concept of a confusion matrix, we propose novel evaluation metrics which take into account both the quantity and quality of labeling.
% \khy{achievable metric}
% Furthermore, we propose novel achievable metrics based on the confusion matrix to evaluate the suitability of the generated superpixels for active learning.
% Our metrics consider the amount of labels instead of the conventional metric that includes achievable segmentation accuracy and boundary recall, which increases with the degree of over-segmentation.
\fi

\iffalse
\ok{Contributions...}
Our main contributions are summarized as follows:
\begin{itemize}
    \item We propose an adaptive merging algorithm where superpixels are updated at each round (Section~\ref{sec:adaptive-merging}), and we show the effectiveness of adaptive superpixels in various realistic AL scenarios (Section~\ref{sec:effect-of-adaptive}).
    \item We alleviate the side effect of noisy labels via an adaptive sieving (Section~\ref{sec:sieving-technique}), and demonstrate especially efficient under large superpixels (Section~\ref{sec:effect-of-adaptive}).
    \item We improve performance with adaptive merging and sieving (Section~\ref{sec:effect-of-adaptive}), and quantitatively analyze adaptive superpixels for reasoning of the improvement (Section~\ref{sec:confusion-matrix}).
    % \item We improve performance with adaptive merging and sieving (Section~\ref{sec:effect-of-adaptive}), and propose new metrics as analysis tools for their effectiveness (Section~\ref{sec:confusion-matrix}).
    % \item We present an oracle superpixel baseline as an upper bound (Section~\ref{para:oracle-superpixels}), and propose novel achievable metrics to evaluate the suitability of superpixels in active learning (Section~\ref{sec:confusion-matrix}).
\end{itemize}
\fi

% Before starting active learning, images should first be divided into superpixels.
% However, it is uncertain what the optimal level of over-segmentation should be to determine the initial size of superpixels.
% In practice, the initial size of superpixels can greatly influence the performance of a model \cite{cai2021revisiting}.
% While smaller superpixels can provide more detailed information, they also increase annotation workload and take longer to process.
% Larger superpixels, while more efficient and reducing the number of regions to label, can result in less detailed information and make it harder to accurately classify certain areas of the image.

% In general, superpixel algorithms require a targeted number of regions and group surrounding pixels into perceptually meaningful regions according to the number.
% As a result, one superpixel can be classified as one semantic category, and this phenomenon becomes more pronounced as we divide images into many superpixels.
% Recently, cost saving have been demonstrated in superpixel-based active learning, which utilizes dominant labels, i.e., the majority class of pixels in superpixels \cite{cai2021revisiting}.
% However, regardless of the degree of the trained model, only the initial superpixels generated before active learning are leveraged, which causes a problem that all images have the same number of superpixels, although the number of instances contained in each image varies.