
\let\hl=\undefined
\newcommand\hl[1]{\textcolor{blue}{#1}}

\begin{figure}[!tbp]
    \captionsetup[subfigure]{font=footnotesize}
    \centering
    \begin{subfigure}[h!]{.49\linewidth}
        \centering
        \includegraphics[scale=0.231]{Figures/fig1/fig_1_a.png}
        \caption{Over-segmented $(t=0)$}
        \label{(a)-adaptive}
        \vspace{2mm}
    \end{subfigure}
    \begin{subfigure}[h!]{.49\linewidth}
        \centering
        \includegraphics[scale=0.231]{Figures/fig1/fig_1_b_v2.png}
        \caption{Adaptive merged $(t=2)$}
        \label{(b)-adaptive}
        \vspace{2mm}
    \end{subfigure}
    \begin{subfigure}[h!]{.49\linewidth}
        \centering
        \includegraphics[scale=0.231]{Figures/fig1/fig_1_c_v2.png}
        \caption{Adaptive merged $(t=4)$}
        \label{(c)-adaptive}
    \end{subfigure}
    \begin{subfigure}[h!]{.49\linewidth}
        \centering
        \includegraphics[scale=0.231]{Figures/fig1/fig_1_d_v4.jpg}
        \caption{Oracle}
        \label{fig:(d)_adaptive_merged_superpixels}
    \end{subfigure}
    \caption{{\em Examples of adaptive superpixels.} (a) We begin active learning with over-segmented superpixels. (b, c) In each round $t$, we merge superpixels in an adaptive manner using the model from the previous round. %
    (d) As the round progresses, adaptive superpixels look similar to oracle ones.}
    \label{fig:adaptive_merged_superpixels}
    \vspace{-3mm}
\end{figure}

\begin{figure*}[t!]
    \centering
    \includegraphics[scale=0.52]{Figures/overall_arch_share_v7.pdf}
    \caption{{\em An overview of the proposed framework.} In each round $t$, we merge superpixels with a graph using the latest model, and obtain dominant labels for selected superpixels. The dominant labels are selectively propagated to pixels with confidence above the detected knee point, resulting in the creation of a sieved dataset. Finally, we train a model with the sieved one.}
    \label{fig:method}
    \vspace{-2mm}
\end{figure*}

\section{Introduction}
With the advent of deep learning, many computer vision tasks including semantic segmentation have dramatically evolved in recent years.
Such advances are thanks to complex deep network models that can learn huge datasets. However, labeling such large datasets is prohibitively time-consuming and labor-intensive, in particular, for semantic segmentation tasks that demand a dense annotation on each pixel \cite{Cordts2016Cityscapes, everingham2015pascal}. Active learning (AL) offers an approach to alleviate the annotation cost  by selectively querying only the most informative samples to annotators.


Designing an effective form of annotation query is critical in practice 
as it determines the actual annotation cost such as the number of clicks required
and the informativeness per annotation query.
For semantic segmentation, an image-wise query can be asked for a complete annotation on the semantic of every pixel in an image~\cite{chengliang2020suggestive,desai2022active,sinha2019variational,xie2020deal,yang2017suggestive}.
This is a daunting task requiring an enormous amount of clicks to indicate boundaries (using polygons or contours) for each semantic segment or to annotate semantic pixel-wisely, while 
the diversity of contexts which we can observe in a single image is restricted. 
Alternatively, one can design a {\it region-based}
query enquiring only about the dominant label of a small region such as rectangle patch \cite{casanova2019reinforced,qiao2022cpral,xie2022towards} or superpixel 
\cite{cai2021revisiting,siddiqui2020viewal}. 
This is known to be simple yet effective 
as it requires only a single click per query while enabling AL to put more focus on significant regions
and to avoid annotation wastes.










AL with the region-based query needs a delicate generation of candidate regions to be queried. A small region size dilutes the budget efficiency, whereas the dominant labeling even by a perfect annotator is prone to give noisy labels when regions are too large to be consisting of pixels with a single class. However, the previous works~\cite{casanova2019reinforced,qiao2022cpral,siddiqui2020viewal}
rely on a fixed candidate set of regions of uniform size, while we could adjust the size and shape of candidate regions as we train the semantic segmentation model over rounds of AL. This limitation remains even in recent work \cite{cai2021revisiting}
with superpixel candidates providing less 
risk of noisy labels than rectangle ones
since the superpixels are produced, only at the beginning, by a conventional superpixel algorithm,
where conventional superpixel algorithms ~\cite{achanta2012slic,jianbo2000normalized,van2012seeds} cluster adjacent pixels of similar innate features (\eg., color) with implicit or explicit regularization to make similar sizes or shapes of superpixels, \ie., limited freedom of query region.




\let\oldparskip=\parskip
\parskip=0mm

In this paper, to fully enjoy the benefit in terms of annotation cost while suppressing the risk of noisy labels, 
we devise an AL framework, illustrated in Figure~\ref{fig:method}, consisting of adaptive merging and sieving methods.
The adaptive merging method %
repeatedly evolves the candidate superpixels for dominant labeling at every round with the latest model and no explicit regularization on the size and shape of superpixels.
This indeed enables the continual improvement 
of
the superpixels' ability to accurately capture the boundaries of semantic objects~(Figure~\ref{(b)-adaptive} and \ref{(c)-adaptive}),
and a proper variation in the sizes and shapes of superpixels, \ie., larger superpixels being attached to larger semantic objects (\eg., road and building) and smaller ones to smaller objects (\eg., human and vehicle) as shown in the ideal ones~(Figure~\ref{fig:(d)_adaptive_merged_superpixels}).




Given the adaptive superpixels, we establish
a corresponding acquisition function being aware of irregular superpixel sizes.
It prioritizes uncertain superpixels of rare classes
in order to query the most informative superpixels while balancing class distributions in the entire annotations. In addition, 
to alleviate the inevitable noise in the dominant labeling, we propose a sieving technique 
that excludes labeled pixels of high potential risks of being different classes than the dominant one. 
To be specific, we identify such pixels of potentially noisy labels by 
per-superpixel sieving with distinct thresholds over superpixels. This provides stabler denoising 
than uniform sieving with a constant threshold, which might aggravate class imbalance in the sieved annotations. 



\parskip=\oldparskip



Through the integration of adaptive merging and sieving into an AL framework, we achieve improved 
accuracy and budget-efficiency over a baseline method. 
Notably, the merging demonstrates effectiveness under small-sized superpixels, while the sieving plays a critical role given large-sized superpixels.
Moreover, we show a consistent improvement 
over existing methods in various settings. %
We provide a thorough justification of the proposed method using various quantitative measures, 
where we introduce 
a new evaluation metric for superpixel algorithms 
that assesses both (achievable) accuracy and recall,
where the recall is overlooked in 
the existing one, the achievable segmentation accuracy~(ASA)~\cite{liu2011entropy}
but important in the context of AL.
This may give new insights into developing superpixel algorithms.



Our main contributions are summarized as follows:
\begin{itemize}
    \vspace{-1mm}
    \item We propose an adaptive merging algorithm where superpixels are updated at each round (Section~\ref{sec:adaptive-merging}), and show the effectiveness of adaptive merging rather than only merging once (Section~\ref{sec:effect-of-adaptive}).
    \vspace{-1mm}
    \item We alleviate the side effect of noisy labels via a sieving technique (Section~\ref{sec:sieving-technique}), and demonstrate especially efficient under large superpixels (Section~\ref{sec:effect-of-adaptive}).
    \vspace{-1mm}
    \item
    In various realistic experiments, we demonstrate the consistent improvement of the proposed AL framework, consisting of the adaptive merging and sieving methods with the dedicated acquisition function, over existing ones (Section~\ref{sec:effect-of-adaptive}).
    \vspace{-1mm}
    \item
    We provide an insightful analysis on proper superpixels for AL with 
    the new evaluation metric of superpixel algorithms being aware of usage in AL (Section~\ref{sec:confusion-matrix}).
    

\end{itemize}









