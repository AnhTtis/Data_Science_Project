
\let\hl=\undefined
\newcommand\hl[1]{\textcolor{blue}{(#1)}}

\section{Related work}



\paragraph{Active learning for segmentation.}

To reduce the labeling cost of semantic segmentation, AL for segmentation selectively collects labels among unlabeled samples, and they utilize different predefined labeling units.
Early approaches~\cite{sinha2019variational,yang2017suggestive} perform image-wise selection and mask labeling.
Patch-based methods~\cite{casanova2019reinforced,colling2020metabox+,golestaneh2020importance,mackowiak2018cereals,xie2022towards} divide images into rectangular patches and provide mask label~\cite{casanova2019reinforced,golestaneh2020importance,xie2022towards} or polygon overlay of an object~\cite{colling2020metabox+,mackowiak2018cereals} within the selected patch.
Recently, superpixel-based approaches~\cite{cai2021revisiting, siddiqui2020viewal} split images to perceptually meaningful regions called superpixel by running an off-the-shelf over-segmentation algorithm~\cite{achanta2012slic, ren2003learning, van2012seeds}.
Each superpixel is labeled with a single dominant class, and thus it can be obtained efficiently~\cite{cai2021revisiting}, while a label noise may occur depending on the quality of the superpixel.
We present a new efficient labeling unit, that is initialized with the superpixel but its quality continuously improves by the proposed merging algorithm.
To the best of our knowledge, the proposed method is the first approach to improve the labeling units during AL for segmentation.




\vspace{-3mm}
\paragraph{Learning from noisy labels for segmentation.}
Considering its difficulty in acquiring high-quality labels~\cite{Cordts2016Cityscapes}, semantic segmentation often suffers from noisy annotations.
Previous studies address this label noise by using
gradient similarity to the clean label~\cite{yaolearning},
structural constraints~\cite{acuna2019devil,li2021superpixel}, and
noise-aware loss~\cite{oh2021background, yang2020learning}.
A recent approach captures the moment when different classes memorize noisy labels~\cite{liu2022adaptive}.
Most of these methods~\cite{li2021superpixel, oh2021background, yang2020learning} utilize a single confidence threshold to detect label noise within data.
Unlike previous approaches, we propose to detect a superpixel-adaptive confidence threshold using the Kneedle algorithm~\cite{satopaa2011finding}.
Filtering with this sample-adaptive threshold prevents superpixels with low overall confidence or superpixels containing minor classes from being ignored.








\vspace{-3mm}
\paragraph{Superpixel evaluation.}
Numerous studies segment an image into superpixels to reduce the computation burden of pixels.
Cut-based approaches~\cite{liu2011entropy,jianbo2000normalized,veksler2010superpixels,zhang2011superpixels} create superpixels by adding multiple minimum cuts into a graph with pixel nodes.
Other methods evolve homogeneous clusters from the initial set of points~\cite{achanta2012slic,levinshtein2009turbopixels}.
For real-time applications, a simple hill-climbing optimization is utilized to enforce color similarity~\cite{van2012seeds}.
The generated superpixels are typically evaluated using achievable segmentation accuracy and boundary recall compared with ground truth~\cite{liu2011entropy, van2012seeds} or by examining the regularity in superpixel shape~\cite{giraud2017robust,machairas2014waterpixels,schick2012measuring}.
To our best knowledge, all metrics exclude the consideration of the amount of labels.
To evaluate the suitability of superpixels in AL, we propose achievable precision and recall metrics that consider the size of superpixels.







