






\section{Proposed framework}
Given an unlabeled image set $\set{I}$, we consider an active learning scenario with dominant labeling, 
where a query asks an oracle annotator for the dominant class label $\text{D}(s) \in \set{C} := \{1,2,..., C\}$ of an associated superpixel $s$,
and we issue a batch $\set{B}_t$ of $B$ queries for each round $t$. 
Once we enquire the batch $\set{B}_t$, we train a model $\theta_t$ based on the annotations obtained so far.
Recalling a superpixel $s$ is a cluster of neighboring pixels,
the dominant labeling demands much less annotation effort 
than the pixel-wise labeling on every individual pixel $x$ in the same superpixel $s$ or manual segmentation to indicate boundaries separating semantics. The benefit becomes greater with larger superpixels.
Meanwhile, it is prone to noisy labeling as superpixels can be blunt, \ie., including pixels of different semantics.

In order to fully enjoy the benefit in terms of annotation cost while suppressing the risk of noisy labels, 
our framework begins with a warm-up round ($t = 0$; Section~\ref{sec:warm-up}; line \ref{alg1-line1}-\ref{alg1-line2} in Algorithm \ref{algorithm1}) to prepare an initial model from random querying  and iterates
subsequent rounds ($t = 1, 2, \dots$) with the adaptive merging (Section~\ref{sec:adaptive-merging}; line \ref{alg1-line4}-\ref{alg1-line5} in Algorithm \ref{algorithm1}) and sieving (Section~\ref{sec:sieving-technique}; line \ref{alg1-line6}-\ref{alg1-line7} in Algorithm \ref{algorithm1}) methods
to evolve superpixels for dominant labeling round by round and filter out annotations with the high risk of noisy labels given the latest model.
The overall procedure is summarized in Figure~\ref{fig:method} and Algorithm~\ref{algorithm1}. %

\subsection{Warm-up round}
\label{sec:warm-up}
The adaptive merging and sieving methods demand a trained model.
To obtain an initial model, 
we start with a canonical warm-up round, which is identical to the first round of previous work \cite{cai2021revisiting}.
We first use an off-the-shelf superpixel algorithm, namely SEEDS \cite{van2012seeds}, to partition the pixels in each image $i \in \set{I}$
into a set ${S}_0(i)$ of superpixels,
and to produce a base segmentation $\set{S}_0:= \bigcup_{i \in \set{I}} {S}_0(i)$.
Querying a batch~$\set{B}_0$ of $B$ superpixels randomly selected from $\set{S}_0$, we then train a model $\theta_0$ using the dominant labels for $\set{B}_0$. Specifically, %
to obtain $\theta_0$,
we first initialize $\theta$ at a model pretrained on ImageNet,
and then train it to minimize the following cross-entropy (CE) loss:
\begin{equation}
\hat{\mathbb{E}}_{(x, y) \sim {\mathcal{D}}_0} [ \text{CE}(y, f_\theta (x))] \;,
\end{equation}
where $\set{D}_0 := \{(x, y) : 
\exists s \in \set{B}_0,
x \in s, y(c) = \mathbbm{1}{[c = \text{D}(s)]}$

\!\!\!\!\!\!\!$ \forall c \in \set{C}\}$
is the training data for round $t=0$ without sieving,
and $\! f_\theta( x ) \! \in \! \mathbb{R}^{\! |\set{C}| \!}\!$ is $\! \theta$'s estimate of class probability on pixel $ x $.

We remark that we use the initial model $\theta_0$ for round $t=1$.
In our framework, SEEDS to generate $\set{S}_0$ can be replaced with any other unless $\set{S}_0$ is a fair over-segmentation of semantics 
with a low risk of noisy labeling while partially enjoying the benefit of low annotation cost. 
We note that SEEDS clusters neighboring pixels of similar 
colors
while a semantic consists of multiple colors, typically.
SEEDS, ready-to-use in OpenCV \cite{opencv_library}, easily provides the desired over-segmentation \cite{cai2021revisiting} and a decent performance of $\theta_0$.
In addition, the warm-up round with SEEDS corresponds to that in existing work \cite{cai2021revisiting}. Hence, this also enables a fair comparison of our main contributions, \ie., adaptive merging and sieving methods, to existing works. 











\subsection{Adaptive merging}
\label{sec:adaptive-merging}
In advance of dominant labeling in round $t \ge 1$, we first merge the base superpixels in $\set{S}_0$ to obtain $\set{S}_t$ using the model $\theta_{t-1}$ from the previous round. We then select a batch $\set{B}_t$ of $B$ superpixels from $\set{S}_t$ to be annotated using an acquisition function that prioritizes uncertain superpixels of rare class labels.
For simplicity, we often omit the subscript $t-1$
and write $\theta$ for $\theta_{t-1}$.


\begin{algorithm}[t!]
\caption{Proposed Framework}
\begin{algorithmic}[1]
\Require 
  Image set $\mathcal{I}$,
  batch size $B$, and final round~$T$.  
\State Produce base superpixels $\set{S}_0 := \bigcup_{i \in \set{I}}\set{S}_0(i)$ \label{alg1-line1}
\State Obtain model $\theta_0$ training with $\mathcal{D}_0$ \label{alg1-line2}
  \For {$t = 1, 2, \dots, T$}
    \State Adaptively merge the base superpixels and obtain \label{alg1-line4}
    
    \;\;\;\;$\mathcal{S}_t \gets \bigcup_{i \in \set{I}} \Call{AM}{{S}_0(i),\theta_{t-1}}$
    
    \State Select and query $B$ superpixels $\mathcal{B}_t \subset \mathcal{S}_t$ with \eqref{acquisition_function} 
    \label{alg1-line5}
    \State Sieve %
    $s \in \bigcup_{t'=0}^{t} \mathcal{B}_{t'}$ and 
    obtain $\set{D}_t$ in \eqref{sieved-superpixel}
    \label{alg1-line6}
    \State Obtain model $\theta_t$ training with the sieved ${\mathcal{D}}_{t}$ \label{alg1-line7} 
  \EndFor
\State \Return $\theta_T$ \label{alg1-line8} 
\end{algorithmic}
\label{algorithm1}
\end{algorithm}

\vspace{-3mm}
\paragraph{Adaptive merging.} 
To obtain $\set{S}_t := \bigcup_{i \in \set{I}} {S}_t(i)$,
the merging process converts base superpixels $S_0(i)$ into merged ones $S_t(i)$ for each image $i \in \set{I}$.
We hence focus on how we merge given base superpixels $S$ for an image.
To begin with, we convert the superpixels $S$ into a connected graph $\set{G}(S) \! = \! (S, \set{E}(S))$
where $S$ is the set of nodes, each of which corresponds to a base superpixel $s \in S$, and $\set{E}(S)$ is the edge set such that
$(s, n) \in \set{E}(S)$ if a pair of superpixels $s, n \in S$
are adjacent.
Starting from a root node $s \in S$ in an arbitrary order,
we then merge neighboring superpixels of similar class predictions with the root $s$ along the breadth-first search tree.
To be specific, a neighbor $n$ is amalgamated with root $s$
only if 
\begin{equation}
d_\text{JS} \big( f_\theta(s) \parallel f_\theta(n) \big) < \epsilon \;,
\label{eq:jsd}
\end{equation}
where  $f_\theta(s) := \frac{\sum_{x \in s} f_\theta(x)}{|\{x : x\in s\}|}$
is the averaged class prediction of superpixel $s \in S$,
and $d_\text{JS}$ is 
a symmetric %
measure of discrepancy between two distributions, namely
the square root of Jensen-Shannon (JS) divergence.
More formally, 
\begin{equation}
d_\text{JS}(p \parallel q) := \sqrt{\frac{d_\text{KL}(p \parallel \frac{p+q}{2}) + d_\text{KL}(q \parallel \frac{p+q}{2})}{2}} \;,
\end{equation}
where $d_{\text{KL}}$ is the Kullback-Leibler divergence.
Once every node has been either merged to a root
or played as a root, we collect the merged superpixels into $S_t(i)$.
The merging process is formally described in Algorithm~\ref{algorithm2}.


Recalling \eqref{eq:jsd} and the fact that $d_{\text{JS}}$ is a distance metric,
we can guarantee that any pair of superpixels $s$ and $n$ 
has the prediction discrepancy at most $2 \epsilon$ and thus similar uncertainty and predicted label if they are merged.
Hence, the threshold $\epsilon$ governs the impurity of predictions in a merged superpixel.
We also remark that 
the merging process is fully dedicated to collecting pixels of similar predictions
as a part of saving the annotation budget for querying similar pixels repeatedly.
Hence, the merged superpixels can have various sizes differently from existing superpixel algorithms that regularize the superpixel size to be even \cite{giraud2017robust,machairas2014waterpixels,schick2012measuring}.





















\begin{algorithm}[t!]
\caption{Adaptive Merging (\textsc{AM})} %
\begin{algorithmic}[1]
\Require Base superpixels $S$, model $\theta$, and threshold $\epsilon$. 
  \State Set $S' \gets \emptyset$ and $\mathcal{G}(S) \gets (S, \set{E}(S))$
    \State Mark $s$ as unexplored for each $s\in S$
  \For {$s\in S$ in descending order of $u_\theta(s)$} \label{line:order} 
    \If {$s$ is unexplored}
      \State $S' \gets S' \cup \{\text{\Call{Merge}{$s$, $f_\theta(s)$; $\set{G}$, $\theta$}}\}$
    \EndIf
  \EndFor
  \State \Return $S'$
\Procedure{Merge}{$s$, $f$; $\mathcal{G}$, $\theta$}
  \State Mark $s$ as explored and set $s' \gets s$
  \For {each neighbor $n$ of $s$ in $\set{G}$}
    \If {$n$ is unexplored and $d_\text{JS}(f \!\parallel\! f_\theta(n))<\epsilon$}
      \State $s' \gets s' \cup \text{\Call{Merge}{$n$, $f$; $\mathcal{G}$, $\theta$}}$
    \EndIf
  \EndFor
  \State \Return $s'$
\EndProcedure
\end{algorithmic}
\label{algorithm2}
\end{algorithm}

\vspace{-3mm}
\paragraph{Acquisition function.} 
From the merged superpixels $\set{S}_t$, 
we then select a batch $\set{B}_t \subset \set{S}_t$
of size $B$ to be labeled, according to an acquisition function
that estimates the benefit from labeling a merged superpixel,
where the benefit would be huge for uncertain superpixels of rare class labels.
In what follows, we define an uncertainty measure of superpixel
in \eqref{eq:uncertainty}
and a popularity estimate of class in \eqref{eq:size-aware-class-balance}, and then introduce an acquisition function in \eqref{acquisition_function}.

Recalling $f_\theta(x) \! \in \! \mathbb{R}^{|\set{C}|}$
is the probability such that $f_\theta(c; x)$ is the estimated probability
that the class $c$ of pixel $x$,
we adapt best-versus-second-best~\cite{joshi2009multi}
for uncertainty measures of pixel $x$ and superpixel $s$ as follows:
\begin{equation}
u_\theta(x) \!:=\! \frac{\max_{c \in \mathcal{C} \setminus\{y_\theta(x)\}} {f_\theta(c; x)}}{\max_{c \in \set{C} }f_\theta(c;x)},
u_\theta(s) \!:=\! \frac{\sum_{x \in s} u_\theta(x)}{|\{x: x \in s\}|}, 
\label{eq:uncertainty}
\end{equation}
where $y_{\theta}(x) := \argmax_{c \in \set{C}} f_\theta(c;x)$ is the estimated dominant label of pixel $x$ in a given model $\theta$.

We then define a popularity estimate $p(c; \theta)$ of class $c \in \set{C}$
given $\theta$ as follows: 
\begin{equation}
p(c;\theta) := \frac{|\{ x : \exists s \in \mathcal{S}_t, \text{D}_\theta(s) = c, x \in s\}|}{|\{x : \exists s \in \mathcal{S}_t, x \in s \}|} \;,
\label{eq:size-aware-class-balance}
\end{equation}
where $\text{D}_\theta(s) :=\argmax_{c \in \mathcal{C}} | \{x \in s : y_\theta(x) = c \} |$ is the majority of predicted labels in superpixel $s$. We note that low $p(c;\theta)$ implies that class $c$ is rare in the prediction of $\theta$. It is noteworthy that we compute the class popularity
in pixel-level due to the various sizes of our merged superpixels,
while the previous work \cite{cai2021revisiting}
proposes a superpixel-wise class popularity, 
$\frac{|\{ s : \text{D}_\theta(s) = c, s \in \mathcal{S}_t\}|}{|\{s : s \in \mathcal{S}_t \}|} \;$, assuming superpixels of uniform size.


Using the uncertainty $u_\theta(s)$ in \eqref{eq:uncertainty}
and the class popularity $p(c;\theta)$ in \eqref{eq:size-aware-class-balance}, 
we define the following acquisition function 
$a(s; \theta)$
prioritizing uncertain superpixels of rare classes:
\begin{equation}
a(s; \theta):= u_\theta(s) \exp \big({-p(\text{D}_\theta(s) ; \theta)} \big)\;.
\label{acquisition_function}
\end{equation}
We select $B$ superpixels of highest values of $a(s; \theta_{t-1})$
from the merged $\set{S}_t$ for query batch $\set{B}_t$. 















\vspace{-3mm}
\paragraph{Remarks.}
We note that it is possible to produce $\set{S}_t$ from scratch
rather than from base segmentation $\set{S}_0$.
To reduce the computational cost for the adaptive merging process,
we however compose $\set{S}_t$ by merging base superpixels in $\set{S}_0$
from SEEDS, which is known to generate an over-segmentation of semantics.
Moreover, it is computationally expensive to explore all the possible mergers
and obtain $\set{S}_t$ followed by the query selection.
We hence conduct the merging process only for a certain portion of base superpixels with the highest values of uncertainty (c.f., line~\ref{line:order} in Algorithm~\ref{algorithm2}) and then
select $\set{B}_t$ to be queried since the acquisition function would select 
merged superpixels of high uncertainty in the end.
Further details are presented in Appendix \ref{fig:sup-descend}.




\subsection{Sieving}
\label{sec:sieving-technique}










Despite the sophisticated design of the adaptive merging,
a queried superpixel can inevitably include 
pixels of classes different from the dominant one,
in particular, as we select superpixels of which model predictions are unsure. Hence, the dominant labeling is liable to make noisy annotations.
To alleviate such side effects of the dominant labeling, we propose a simple sieving technique that 
filter out pixels that have high potential risks of being 
different classes than the dominant one.
We observe that
for a queried superpixel $s$ and given model $\theta$, 
the risk of %
mismatch between the dominant label $D(s)$ and the true label of pixel $x \in s$
would be high when $f_\theta \big( \text{D}(s); x \big)$
is low.
From this observation, we define 
\begin{equation}
h(s;\theta) := \{ x \in s: f_\theta \big( \text{D}(s); x \big) \geq \phi(s; \theta) \} \;,
\label{eq:sieving}
\end{equation}
where 
$\phi(s; \theta)$ is a knee point of the cumulative distribution function of values of $f_\theta \big( \text{D}(s); x \big)$ in superpixel $s$, detected by
Kneedle algorithm~\cite{satopaa2011finding}.
 In addition, 
the knee point detection allows us to have a tailored sieving threshold to each superpixel. This is important to avoid the case that the remained pixels are heavily biased to relatively easy labels after sieving.
Further details are in Appendix \ref{fig:sup-sieving}.

We revisit all the queried superpixel $s \in \bigcup_{t'=0}^{t} \mathcal{B}_{t'}$ and sieve them using \eqref{eq:sieving}
with the latest model $\theta_{t-1}$
since the model evolves round by round.
We finally obtain the following sieved dataset ${\mathcal{D}}_{t}$ for round $t \ge 1$:
\begin{equation}
{\mathcal{D}}_{t} := \left\{(x, y) : 
\begin{aligned}
&\exists s \in \cup_{t'=0}^{t} \mathcal{B}_{t'}, \ x \in h(s;\theta_{t-1}), \\
&y(c) = \mathbbm{1}{[c = \text{D}(s)]} \ \forall c\in\set{C} 
\end{aligned}
\right\} \;.
\label{sieved-superpixel}
\end{equation}
Analogously to the warm-up round, 
initializing model $\theta$ at a model pretrained on ImageNet, we obtain $\theta_t$ trained to mainly minimize the following CE loss:
\begin{equation}
\hat{\mathbb{E}}_{(x,y) \sim {\mathcal{D}}_t} [ \text{CE}(y, f_\theta (x))] \;.
\label{eq:final-loss}
\end{equation}



























