\section{Analyses of adaptive superpixels}
We propose new evaluation metrics to measure the quality of superpixel as a labeling unit for active segmentation, and utilize it to analyze our adaptive superpixels (Section~\ref{sec:confusion-matrix}).
We also conduct analyses about the effect $\epsilon$ to our adaptive superpixels (Section~\ref{sec:merging-criteria}).
All analyses are conducted on Cityscapes with an average superpixel size of 256 pixels.










\subsection{Achievable metrics}
\label{sec:confusion-matrix}
While various evaluation metrics for superpixel are presented~\cite{giraud2017robust,liu2011entropy,machairas2014waterpixels,schick2012measuring,van2012seeds}, most of them aims to measure the quality of over-segmentation.
For instance, achievable segmentation accuracy (ASA) \cite{liu2011entropy} measures
the segmentation accuracy when each superpixel $s \in S$ is associated with the oracle superpixel with the largest overlap.
The ASA is calculated as follows:
\begin{equation}
\text{ASA}(S; G) := \frac{\sum_{s \in S} \max_{g \in G} |s \cap g|}{\sum_{s \in S} |s|} \;,
\end{equation}
where $S$ and $G$ represent the generated and oracle superpixels from the same image, respectively. 
As an image becomes more over-segmented, \ie., the superpixel size becomes smaller, the ASA value increases. 
However, active learning (AL) aims to achieve the maximum benefit with the least amount of labeling effort, and therefore, the number of labels should be taken into account. 
In addition, the ASA is heavily biased towards classes with a large number of pixels.

\begin{figure}[t]
    \captionsetup[subfigure]{font=scriptsize,labelfont=scriptsize,aboveskip=0.05cm,belowskip=-0.15cm}
    \centering
    \hspace{-5mm}
    \begin{subfigure}{.47\linewidth}
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                legend style={nodes={scale=0.35}, at={(0.03, 0.24)}, anchor=west}, 
                xlabel={ASA$(S;G)$},
                ylabel={mIoU (\%)},
                width=1.23\linewidth,
                height=1.23\linewidth,
                ymin=50.8,
                ymax=63.2,
                ytick={51, 53, 55, 57, 59, 61, 63},
                xlabel style={yshift=0.15cm},
                ylabel style={yshift=-0.2cm},
                legend columns=2,
                xmin=0.882,
                xmax=0.967,
                label style={font=\scriptsize},
                tick label style={font=\scriptsize},
                x tick label style={
                    /pgf/number format/.cd,
                        fixed,
                }
            ]
            \addplot[cdeepBP, only marks] table[col sep=comma, x=ASASG, y=mIoU]{Data/correlation_asasg.csv};
            \addplot[very thick, orange] table[col sep=comma, x=ASASG, y={create col/linear regression = {y=mIoU}}
            ]{Data/correlation_asasg.csv};
            \draw (0.5\linewidth, 0.35\linewidth) node {\scriptsize$\text{Corr} = 0.05$};
            \end{axis}
        \end{tikzpicture}
    \end{subfigure}
    \hspace{1mm}
    \begin{subfigure}{.47\linewidth}
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                legend style={nodes={scale=0.35}, at={(0.03, 0.24)}, anchor=west}, 
                xlabel={AF$(G;S)$},
                ylabel={mIoU (\%)},
                width=1.23\linewidth,
                height=1.23\linewidth,
                ymin=50.8,
                ymax=63.2,
                xlabel style={yshift=0.15cm},
                ylabel style={yshift=-0.2cm},
                ytick={51, 53, 55, 57, 59, 61, 63},
                legend columns=2,
                xmin=0.174,
                xmax=0.371,
                label style={font=\scriptsize},
                tick label style={font=\scriptsize},
                x tick label style={
                    /pgf/number format/.cd,
                        fixed,
                }
            ]
            \addplot[cdeepBP, only marks] table[col sep=comma, x=AFGS, y=mIoU]{Data/correlation_afgs.csv};
            \addplot[very thick, orange] table[col sep=comma, x=AFGS, y={create col/linear regression = {y=mIoU}}
            ]{Data/correlation_afgs.csv};
            \draw (0.5\linewidth, 0.35\linewidth) node {\scriptsize$\text{Corr}=0.95$};
            \end{axis}
        \end{tikzpicture}
    \end{subfigure}
    \caption{{\em Relationship between metrics and mIoU.} The correlation between ASA$(S;G)$ and mIoU is low, while the correlation between AF$(G;S)$ and mIoU is high. For the correlation calculation, \textit{Oracle} in Table \ref{tab:quantitative} is excluded.}
    \label{fig:co-relation}
    \vspace{-4mm}
\end{figure}


In order to measure the suitability of superpixels for AL, we introduce precision and recall between generated and oracle superpixels. 
A generated superpixel can be viewed as positive on the inside and negative on the outside, and its precision and recall with respect to the corresponding oracle one can be calculated.
For all generated superpixels, we define the achievable precision (AP) as follows:
\begin{equation}
\text{AP}(S;G) := \frac{1}{|S|} \sum_{s \in S} \frac{\max_{g \in G} |s \cap g|}{|s|} \;,
\end{equation}
where the summation is performed in superpixels, unlike in ASA, which implies pixel-wise precision.
As we put the same weight on each superpixel, AP is less influenced by large objects than ASA.
We note that AP is different to average precision \cite{everingham2009pascal, salton1983introduction}, used in object detection, which utilize the precision and recall curve.
We also define the achievable recall (AR) and F1-score (AF) as:
\begin{equation}
\text{AR}(S;G) := \frac{1}{|S|} \sum_{s \in S} \frac{\max_{g \in G} |s \cap g|}{|g'(s; G)|} \;, 
\end{equation}
\begin{equation}
\text{AF}(S;G) := \frac{2}{|S|} \sum_{s \in S} \frac{\max_{g \in G} |s \cap g|}{|s| + |g'(s; G)|} \;,
\end{equation}
where $g'(s; G) := \argmax_{g \in G} \left|s \cap g \right|$ 
refers to the corresponding oracle superpixel.
Details are in Appendix \ref{fig:sup-metrics}.

All the metrics evaluate generated superpixels in comparison to oracle ones. 
However, the size of superpixels is also important besides their quality in AL.
Therefore, it is necessary to evaluate the oracle superpixels against the generated superpixels, \ie., ASA$(G;S$), AP$(G;S)$, AR$(G;S)$ and AF$(G;S)$. We hence propose AF$(G;S)$
defined as:
\begin{equation}
\text{AF}(G;S) := \frac{2}{|G|} \sum_{g \in G} \frac{\max_{s \in S} |g \cap s|}{|g| + |s'(g; S)|} \;,
\end{equation}
where $s'(g; S) := \argmax_{s \in S} \left|g \cap s \right|$ refers to the generated superpixel with the highest overlap, which is linked to the maximum amount of labeling we receive.
Table~\ref{tab:quantitative} evaluates various superpixels through eight metrics.
Although our merged superpixels have a relatively low ASA$(S;G)$, they exhibit high ASA$(G;S)$ and AF$(G;S)$.
Qualitative results for metrics are in Appendix \ref{fig:sup-qual}. 




\begin{figure}[t!]
    \captionsetup[subfigure]{font=footnotesize,labelfont=footnotesize,aboveskip=0.05cm,belowskip=-0.15cm}
    \centering
    \hspace{-3mm}
    \begin{subfigure}{.47\linewidth}
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                legend style={nodes={scale=0.5}, at={(0.48, 0.3)}, anchor=west}, 
                xlabel={$\epsilon$},
                ylabel={mIoU (\%)},
                width=1.23\linewidth,
                height=1.23\linewidth,
                ymin=62.4,
                ymax=67.2,
                ytick={62, 63, 64, 65, 66, 67},
                xlabel style={yshift=0.15cm},
                ylabel style={yshift=-0.2cm},
                legend columns=1,
                xmin=0.03,
                xmax=0.22,
                label style={font=\scriptsize},
                tick label style={font=\scriptsize},
                x tick label style={
                    /pgf/number format/.cd,
                        fixed,
                }
            ]
            \addplot[cdeepBP, very thick, mark=diamond*, mark size=2pt, mark options={solid}] table[col sep=comma, x=x, y=ours]{Data/wrong_merging_cityscapes.csv};
            \addplot[cdeepMF, very thick, mark=triangle*, mark size=2pt, mark options={solid}] table[col sep=comma, x=x, y=revisiting] {Data/wrong_merging_cityscapes.csv};
            \legend{AMSP+S,SP}
            \end{axis}
        \end{tikzpicture}
        \caption{Cityscapes}
        \label{fig:(c)-robustness}
    \end{subfigure}
    \hspace{1mm}
    \begin{subfigure}{.47\linewidth}
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                legend style={nodes={scale=0.35}, at={(0.03, 64)}, anchor=west}, 
                xlabel={$\epsilon$},
                ylabel={mIoU (\%)},
                width=1.23\linewidth,
                height=1.23\linewidth,
                ymin=60.8,
                ymax=63.7,
                ytick={61, 62, 63, 64},
                xlabel style={yshift=0.15cm},
                ylabel style={yshift=-0.2cm},
                legend columns=2,
                xmin=0.02,
                xmax=0.22,
                label style={font=\scriptsize},
                tick label style={font=\scriptsize},
                x tick label style={
                    /pgf/number format/.cd,
                        fixed,
                }
            ]
            \addplot[cdeepMF, very thick, mark=triangle*, mark size=2pt, mark options={solid}] table[col sep=comma, x=x, y=revisiting] {Data/wrong_merging_pascal.csv};
            \addplot[cdeepBP, very thick, mark=diamond*, mark size=2pt, mark options={solid}] table[col sep=comma, x=x, y=ours]{Data/wrong_merging_pascal.csv};
            \end{axis}
        \end{tikzpicture}
        \caption{PASCAL}
        \label{fig:(d)-robustness}
    \end{subfigure}
    \caption{{\em Epsilon sensitivity.} We experiment on superpixels with varying $\epsilon$ and demonstrate the robustness of our \textit{AMSP+S}, while \textit{SP} is independent of $\epsilon$. Each experiment is conducted on the second round.}
    \label{fig:multi-rounds}
    \vspace{-2mm}
\end{figure}

\vspace{-4mm}
\paragraph{Correlation of metrics and mIoU.}
To show the proposed metric can accurately evaluate the superpixel quality for active segmentation, we measure the correlation between various evaluation metric and the performance of actively learned model in Table~\ref{tab:quantitative} and Figure~\ref{fig:co-relation}.
We observe that the proposed AF$(G;S)$ shows the highest correlation to the performance of the actively learned model.
We except AF$(G;S)$ can select suitable superpixel algorithm for active learning, where the related details are provided in Appendix \ref{fig:sup-metrics}.










\begin{table}[tbp]
\centering
\setlength\tabcolsep{6pt}
\begin{tabular}{l|ccccc}
\toprule
Epsilon & 0.04   & 0.05 & 0.06 & 0.07 & 0.08 \\ \midrule 
$\text{Merged}_1$ & 0.344 & \textbf{0.346} & 0.344 & 0.340 & 0.336 \\
$\text{Merged}_2$ & 0.347 & 0.346 & \textbf{0.348} & 0.345 & 0.344 \\
$\text{Merged}_3$ & 0.346 & 0.349 & 0.350 & \textbf{0.351} & 0.349 \\
$\text{Merged}_4$ & 0.347 & 0.347 & 0.347 & \textbf{0.348} & 0.346 \\
\bottomrule
\end{tabular}
\caption{{\em Adaptive epsilon.} AF$(G;S)$ for adaptive superpixels generated by varying $\epsilon$ is reported. The subscript indicates the round.} 
\label{tab:adaptive-epsilon}
\vspace{-5mm}
\end{table}

\subsection{Ablation studies on epsilon} 
\label{sec:merging-criteria}

\paragraph{Epsilon sensitivity.}
In Figures~\ref{fig:(c)-robustness} and \ref{fig:(d)-robustness}, we evaluate the sensitivity of our method to $\epsilon$, which determines the amount of the merging.
Proposed method show robustness to the change of $\epsilon$, where the change of mIoU is less than 2\% for both Citycapes and PASCAL when $\epsilon$ is between 0.05 and 0.2.
We observe that for every investigated $\epsilon$ values, \textit{AMSP+S} surpasses the performance of the previous art~\cite{cai2021revisiting}.

\begin{table}[tbp]
\centering
\setlength\tabcolsep{6pt}
\begin{tabular}{l|c|cc}
\toprule
Method                             & Epsilon & Correct & Incorrect \\ \midrule
Ground Truth                       &    -    & 1.000   & 0.000       \\ \midrule
Pseudo Label                 &    -    & 0.832 & 0.168   \\ \midrule
\multirow{3}{*}{ED}        & 0.05    & 0.915        & 0.085      \\
                                           & 0.10    & 0.901        & 0.099      \\
                                           & 0.15    & 0.891        & 0.109      \\ \midrule
\multirow{3}{*}{JSD} & 0.05    & 0.934        & 0.066      \\
                                           & 0.10    & 0.911        & 0.089      \\
                                           & 0.15    & 0.896        & 0.104      \\
\bottomrule
\end{tabular}
\caption{{\em Various merging criteria.} Using JSD performs more accurate merging than using ED. As $\epsilon$ increases, the rate of incorrect merging increases. }
\label{tab:merging-methods}
\vspace{-5mm}
\end{table}

\vspace{-4mm}
\paragraph{Adaptive epsilon.}
We fix $\epsilon$ to 0.10 in all quantitative experiments, but there may exist an optimal $\epsilon$ for each round. 
In Table \ref{tab:adaptive-epsilon}, we analyze $\epsilon$ that maximizes AF$(G;S)$ metric for each round by assuming the existence of 10 validation images with ground truth. 
As the round increases, the optimal $\epsilon$ increases as well, which implies that the improvement of the model enables us to merge aggressively.

\vspace{-4mm}
\paragraph{Effect of epsilon.}
In Table \ref{tab:merging-methods}, we measure the quality of the merging algorithm when using different criteria, where the merging is considered to be correct when the dominant labels of the paired superpixels are identical.
We investigate merging a pair of superpixels when their ground-truth label is identical (Ground Truth), when their dominant top-1 model prediction is identical (Pseudo Label), and when the Euclidean Distance (ED) or Jensen-Shannon Divergence (JSD) of their averaged predictive probability is smaller than $\epsilon$.
Using pseudo labels leads to lower-quality merging as it ignores other minor classes.
Since we utilize the predicted class probability as a feature space, 
JSD proves to be more effective than ED.
As $\epsilon$ increases, the correct ratio decreases due to the aggressive merging of superpixels.
We emphasize that $\epsilon$ can determine the trade-off between the quantity and quality of labels.  



