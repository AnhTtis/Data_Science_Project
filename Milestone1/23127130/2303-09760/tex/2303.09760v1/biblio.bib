@inproceedings{kingma2014,
  author    = {Diederik P. Kingma and
               Max Welling},
  title     = {Auto-Encoding Variational Bayes},
  booktitle = {2nd International Conference on Learning Representations},
  year      = {2014}
}

@inproceedings{ho2020,
  author    = {Jonathan Ho and
               Ajay Jain and
               Pieter Abbeel},
  title     = {Denoising Diffusion Probabilistic Models},
  booktitle = {Advances in Neural Information Processing Systems 33},
  year      = {2020},
}

@article{nichol2021,
  author    = {Alex Nichol and
               Prafulla Dhariwal},
  title     = {Improved Denoising Diffusion Probabilistic Models},
  journal   = {CoRR},
  year      = {2021},
}

@inproceedings{song2019,
  author    = {Yang Song and
               Stefano Ermon},
  title     = {Generative Modeling by Estimating Gradients of the Data Distribution},
  booktitle = {Advances in Neural Information Processing Systems 32},
  year      = {2019},
}

@article{rusu2018meta,
  title={Meta-learning with latent embedding optimization},
  author={Rusu, Andrei A and Rao, Dushyant and Sygnowski, Jakub and Vinyals, Oriol and Pascanu, Razvan and Osindero, Simon and Hadsell, Raia},
  journal={arXiv preprint arXiv:1807.05960},
  year={2018}
}

@article{edwards2016towards,
  title={Towards a neural statistician},
  author={Edwards, Harrison and Storkey, Amos},
  journal={arXiv preprint arXiv:1606.02185},
  year={2016}
}

@inproceedings{wu2020meta,
  title={Meta-Amortized Variational Inference and Learning.},
  author={Wu, Mike and Choi, Kristy and Goodman, Noah D and Ermon, Stefano},
  booktitle={AAAI},
  pages={6404--6412},
  year={2020}
}

@inproceedings{ravi2018amortized,
  title={Amortized bayesian meta-learning},
  author={Ravi, Sachin and Beatson, Alex},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{van2017neural,
  title={Neural discrete representation learning},
  author={van den Oord, Aaron and Vinyals, Oriol and others},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6306--6315},
  year={2017}
}

@article{kipf2018compositional,
  title={Compositional Imitation Learning: Explaining and executing one task at a time},
  author={Kipf, Thomas and Li, Yujia and Dai, Hanjun and Zambaldi, Vinicius and Grefenstette, Edward and Kohli, Pushmeet and Battaglia, Peter},
  journal={arXiv preprint arXiv:1812.01483},
  year={2018}
}

@article{falorsi2018explorations,
  title={Explorations in homeomorphic variational auto-encoding},
  author={Falorsi, Luca and de Haan, Pim and Davidson, Tim R and De Cao, Nicola and Weiler, Maurice and Forr{\'e}, Patrick and Cohen, Taco S},
  journal={arXiv preprint arXiv:1807.04689},
  year={2018}
}

% compression__________________________________________________________________

@article{schmidhuber1992learning,
  title={Learning factorial codes by predictability minimization},
  author={Schmidhuber, J{\"u}rgen},
  journal={Neural Computation},
  volume={4},
  number={6},
  pages={863--879},
  year={1992},
  publisher={MIT Press}
}

@inproceedings{graves2011practical,
  title={Practical variational inference for neural networks},
  author={Graves, Alex},
  booktitle={Advances in neural information processing systems},
  pages={2348--2356},
  year={2011}
}


@article{wang2018dataset,
  title={Dataset Distillation},
  author={Wang, Tongzhou and Zhu, Jun-Yan and Torralba, Antonio and Efros, Alexei A},
  journal={arXiv preprint arXiv:1811.10959},
  year={2018}
}

% compression__________________________________________________________________
@article{schmidhuber1996semilinear,
  title={Semilinear predictability minimization produces well-known feature detectors},
  author={Schmidhuber, J{\"u}rgen and Eldracher, Martin and Foltin, Bernhard},
  journal={Neural Computation},
  volume={8},
  number={4},
  pages={773--786},
  year={1996},
  publisher={MIT Press}
}

@inproceedings{masci2011stacked,
  title={Stacked convolutional auto-encoders for hierarchical feature extraction},
  author={Masci, Jonathan and Meier, Ueli and Cire{\c{s}}an, Dan and Schmidhuber, J{\"u}rgen},
  booktitle={International Conference on Artificial Neural Networks},
  pages={52--59},
  year={2011},
  organization={Springer}
}

@inproceedings{graves2011practical,
  title={Practical variational inference for neural networks},
  author={Graves, Alex},
  booktitle={Advances in neural information processing systems},
  pages={2348--2356},
  year={2011}
}

@article{graves2018acn,
  author    = {Alex Graves and
               Jacob Menick and
               A{\"{a}}ron van den Oord},
  title     = {Associative Compression Networks for Representation Learning},
  journal   = {CoRR},
  volume    = {abs/1804.02476},
  year      = {2018},
  url       = {http://arxiv.org/abs/1804.02476},
  archivePrefix = {arXiv},
  eprint    = {1804.02476},
  timestamp = {Mon, 13 Aug 2018 16:47:16 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1804-02476},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{wang2018dataset,
  title={Dataset Distillation},
  author={Wang, Tongzhou and Zhu, Jun-Yan and Torralba, Antonio and Efros, Alexei A},
  journal={arXiv preprint arXiv:1811.10959},
  year={2018}
}

% structure____________________________________________________________________

@inproceedings{van2017neural,
  title={Neural discrete representation learning},
  author={van den Oord, Aaron and Vinyals, Oriol and others},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6306--6315},
  year={2017}
}

@article{kipf2018compositional,
  title={Compositional Imitation Learning: Explaining and executing one task at a time},
  author={Kipf, Thomas and Li, Yujia and Dai, Hanjun and Zambaldi, Vinicius and Grefenstette, Edward and Kohli, Pushmeet and Battaglia, Peter},
  journal={arXiv preprint arXiv:1812.01483},
  year={2018}
}


% relaxations_____________________________________________________
@inproceedings{plotz2018neural,
  title={Neural nearest neighbors networks},
  author={Pl{\"o}tz, Tobias and Roth, Stefan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1095--1106},
  year={2018}
}

% uncertainty___________________________________________________________________

@article{bradshaw2017adversarial,
  title={Adversarial examples, uncertainty, and transfer testing robustness in gaussian process hybrid deep networks},
  author={Bradshaw, John and Matthews, Alexander G de G and Ghahramani, Zoubin},
  journal={arXiv preprint arXiv:1707.02476},
  year={2017}
}

@inproceedings{lakshminarayanan2017simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6402--6413},
  year={2017}
}

@article{blundell2015weight,
  title={Weight uncertainty in neural networks},
  author={Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
  journal={arXiv preprint arXiv:1505.05424},
  year={2015}
}

@article{devries2018learning,
  title={Learning Confidence for Out-of-Distribution Detection in Neural Networks},
  author={DeVries, Terrance and Taylor, Graham W},
  journal={arXiv preprint arXiv:1802.04865},
  year={2018}
}

@article{guo2017calibration,
  title={On calibration of modern neural networks},
  author={Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q},
  journal={arXiv preprint arXiv:1706.04599},
  year={2017}
}

@article{garnelo2018neural,
  title={Neural processes},
  author={Garnelo, Marta and Schwarz, Jonathan and Rosenbaum, Dan and Viola, Fabio and Rezende, Danilo J and Eslami, SM and Teh, Yee Whye},
  journal={arXiv preprint arXiv:1807.01622},
  year={2018}
}

@article{garnelo2018conditional,
  title={Conditional neural processes},
  author={Garnelo, Marta and Rosenbaum, Dan and Maddison, Chris J and Ramalho, Tiago and Saxton, David and Shanahan, Murray and Teh, Yee Whye and Rezende, Danilo J and Eslami, SM},
  journal={arXiv preprint arXiv:1807.01613},
  year={2018}
}

@inproceedings{gal2015modern,
  title={On modern deep learning and variational inference},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={Advances in Approximate Bayesian Inference workshop, NIPS},
  volume={2},
  year={2015}
}

% disentanglement______________________________________________

@article{kim2018disentangling,
  title={Disentangling by factorising},
  author={Kim, Hyunjik and Mnih, Andriy},
  journal={arXiv preprint arXiv:1802.05983},
  year={2018}
}

@article{chen2018isolating,
  title={Isolating Sources of Disentanglement in Variational Autoencoders},
  author={Chen, Tian Qi and Li, Xuechen and Grosse, Roger and Duvenaud, David},
  journal={arXiv preprint arXiv:1802.04942},
  year={2018}
}

@article{ansari2018hyperprior,
  title={Hyperprior Induced Unsupervised Disentanglement of Latent Representations},
  author={Ansari, Abdul Fatir and Soh, Harold},
  journal={arXiv preprint arXiv:1809.04497},
  year={2018}
}

@article{hahn2018disentangling,
  title={Disentangling Latent Factors with Whitening},
  author={Hahn, Sangchul and Choi, Heeyoul},
  journal={arXiv preprint arXiv:1811.03444},
  year={2018}
}

@article{burgess2018understanding,
  title={Understanding disentangling in $\beta$-VAE},
  author={Burgess, Christopher P and Higgins, Irina and Pal, Arka and Matthey, Loic and Watters, Nick and Desjardins, Guillaume and Lerchner, Alexander},
  journal={arXiv preprint arXiv:1804.03599},
  year={2018}
}

@article{higgins2016beta,
  title={beta-vae: Learning basic visual concepts with a constrained variational framework},
  author={Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and Lerchner, Alexander},
  year={2016}
}

@article{higgins2016beta,
  title={beta-vae: Learning basic visual concepts with a constrained variational framework},
  author={Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and Lerchner, Alexander},
  year={2016}
}

@article{kumar2018consistent,
  title={Consistent Jumpy Predictions for Videos and Scenes},
  author={Kumar, Ananya and Eslami, SM Ali and Rezende, Danilo and Garnelo, Marta and Viola, Fabio and Lockhart, Edward and Shanahan, Murray},
  year={2018}
}


@article{zhao2017infovae,
  title={Infovae: Information maximizing variational autoencoders},
  author={Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
  journal={arXiv preprint arXiv:1706.02262},
  year={2017}
}

@article{higgins2018towards,
  title={Towards a Definition of Disentangled Representations},
  author={Higgins, Irina and Amos, David and Pfau, David and Racaniere, Sebastien and Matthey, Loic and Rezende, Danilo and Lerchner, Alexander},
  journal={arXiv preprint arXiv:1812.02230},
  year={2018}
}

@article{kumar2017variational,
  title={Variational inference of disentangled latent concepts from unlabeled observations},
  author={Kumar, Abhishek and Sattigeri, Prasanna and Balakrishnan, Avinash},
  journal={arXiv preprint arXiv:1711.00848},
  year={2017}
}

% dataset____________________________________________________________________________________
@misc{dsprites17,
author = {Loic Matthey and Irina Higgins and Demis Hassabis and Alexander Lerchner},
title = {dSprites: Disentanglement testing Sprites dataset},
howpublished= {https://github.com/deepmind/dsprites-dataset/},
year = "2017",
}

@inproceedings{aubry2014seeing,
  title={Seeing 3d chairs: exemplar part-based 2d-3d alignment using a large dataset of cad models},
  author={Aubry, Mathieu and Maturana, Daniel and Efros, Alexei A and Russell, Bryan C and Sivic, Josef},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3762--3769},
  year={2014}
}

@inproceedings{liu2015deep,
  title={Deep learning face attributes in the wild},
  author={Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={3730--3738},
  year={2015}
}

@inproceedings{paysan20093d,
  title={A 3D face model for pose and illumination invariant face recognition},
  author={Paysan, Pascal and Knothe, Reinhard and Amberg, Brian and Romdhani, Sami and Vetter, Thomas},
  booktitle={Advanced video and signal based surveillance, 2009. AVSS'09. Sixth IEEE International Conference on},
  pages={296--301},
  year={2009},
  organization={Ieee}
}

@article{velickovic2017graph,
  title={Graph attention networks},
  author={Velickovic, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Lio, Pietro and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1710.10903},
  volume={1},
  number={2},
  year={2017}
}

@article{gregor2015draw,
  title={Draw: A recurrent neural network for image generation},
  author={Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
  journal={arXiv preprint arXiv:1502.04623},
  year={2015}
}


% factorisation_____________________________________________________________________________
@article{schmidhuber1996semilinear,
  title={Semilinear predictability minimization produces well-known feature detectors},
  author={Schmidhuber, J{\"u}rgen and Eldracher, Martin and Foltin, Bernhard},
  journal={Neural Computation},
  volume={8},
  number={4},
  pages={773--786},
  year={1996},
  publisher={MIT Press}
}

@article{kim2011independently,
  title={Independently controllable dual-band bandpass filters using asymmetric stepped-impedance resonators},
  author={Kim, Chan Ho and Chang, Kai},
  journal={IEEE Transactions on Microwave Theory and Techniques},
  volume={59},
  number={12},
  pages={3037--3047},
  year={2011},
  publisher={IEEE}
}

@article{thomas2017independently,
  title={Independently Controllable Features},
  author={Thomas, Valentin and Pondard, Jules and Bengio, Emmanuel and Sarfati, Marc and Beaudoin, Philippe and Meurs, Marie-Jean and Pineau, Joelle and Precup, Doina and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1708.01289},
  year={2017}
}

% VAE
@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

% Variational Inference
@article{wainwright2008graphical,
  title={Graphical models, exponential families, and variational inference},
  author={Wainwright, Martin J and Jordan, Michael},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={1},
  number={1--2},
  pages={1--305},
  year={2008},
  publisher={Now Publishers, Inc.}
}



@article{bengio2009learning,
  title={Learning deep architectures for AI},
  author={Bengio, Yoshua and others},
  journal={Foundations and trends{\textregistered} in Machine Learning},
  volume={2},
  number={1},
  pages={1--127},
  year={2009},
  publisher={Now Publishers, Inc.}
}

@inproceedings{hoffman2016elbo,
  title={Elbo surgery: yet another way to carve up the variational evidence lower bound},
  author={Hoffman, Matthew D and Johnson, Matthew J},
  booktitle={Workshop in Advances in Approximate Bayesian Inference, NIPS},
  year={2016}
}

@article{he2019lagging,
  title={Lagging Inference Networks and Posterior Collapse in Variational Autoencoders},
  author={He, Junxian and Spokoyny, Daniel and Neubig, Graham and Berg-Kirkpatrick, Taylor},
  journal={arXiv preprint arXiv:1901.05534},
  year={2019}
}

@article{jang2016categorical,
  title={Categorical reparameterization with gumbel-softmax},
  author={Jang, Eric and Gu, Shixiang and Poole, Ben},
  journal={arXiv preprint arXiv:1611.01144},
  year={2016}
}

@article{makhzani2015adversarial,
  title={Adversarial autoencoders},
  author={Makhzani, Alireza and Shlens, Jonathon and Jaitly, Navdeep and Goodfellow, Ian and Frey, Brendan},
  journal={arXiv preprint arXiv:1511.05644},
  year={2015}
}

@article{watanabe1960information,
  title={Information theoretical analysis of multivariate correlation},
  author={Watanabe, Satosi},
  journal={IBM Journal of research and development},
  volume={4},
  number={1},
  pages={66--82},
  year={1960},
  publisher={IBM}
}

@inproceedings{chen2016infogan,
  title={Infogan: Interpretable representation learning by information maximizing generative adversarial nets},
  author={Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
  booktitle={Advances in neural information processing systems},
  pages={2172--2180},
  year={2016}
}

@article{kumar2017variational,
  title={Variational inference of disentangled latent concepts from unlabeled observations},
  author={Kumar, Abhishek and Sattigeri, Prasanna and Balakrishnan, Avinash},
  journal={arXiv preprint arXiv:1711.00848},
  year={2017}
}

@article{locatello2018challenging,
  title={Challenging common assumptions in the unsupervised learning of disentangled representations},
  author={Locatello, Francesco and Bauer, Stefan and Lucic, Mario and Gelly, Sylvain and Sch{\"o}lkopf, Bernhard and Bachem, Olivier},
  journal={arXiv preprint arXiv:1811.12359},
  year={2018}
}

%__________________________________________________________________________________________________________

@inproceedings{chen2018sparse,
  title={The Sparse Manifold Transform},
  author={Chen, Yubei and Paiton, Dylan and Olshausen, Bruno},
  booktitle={Advances in Neural Information Processing Systems},
  pages={10534--10545},
  year={2018}
}

@inproceedings{cohen2016group,
  title={Group equivariant convolutional networks},
  author={Cohen, Taco and Welling, Max},
  booktitle={International conference on machine learning},
  pages={2990--2999},
  year={2016}
}

@article{achille2018emergence,
  title={Emergence of invariance and disentanglement in deep representations},
  author={Achille, Alessandro and Soatto, Stefano},
  journal={The Journal of Machine Learning Research},
  volume={19},
  number={1},
  pages={1947--1980},
  year={2018},
  publisher={JMLR. org}
}

@article{achille2018information,
  title={Information dropout: Learning optimal representations through noisy computation},
  author={Achille, Alessandro and Soatto, Stefano},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={40},
  number={12},
  pages={2897--2905},
  year={2018},
  publisher={IEEE}
}

@inproceedings{achille2018life,
  title={Life-long disentangled representation learning with cross-domain latent homologies},
  author={Achille, Alessandro and Eccles, Tom and Matthey, Loic and Burgess, Chris and Watters, Nicholas and Lerchner, Alexander and Higgins, Irina},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9895--9905},
  year={2018}
}

@article{bengio2013representation,
  title={Representation learning: A review and new perspectives},
  author={Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={35},
  number={8},
  pages={1798--1828},
  year={2013},
  publisher={IEEE}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@article{gers1999learning,
  title={Learning to forget: Continual prediction with LSTM},
  author={Gers, Felix A and Schmidhuber, J{\"u}rgen and Cummins, Fred},
  year={1999},
  publisher={IET}
}

@inproceedings{graves2009offline,
  title={Offline handwriting recognition with multidimensional recurrent neural networks},
  author={Graves, Alex and Schmidhuber, J{\"u}rgen},
  booktitle={Advances in neural information processing systems},
  pages={545--552},
  year={2009}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5998--6008},
  year={2017}
}


@inproceedings{srivastava2015unsupervised,
  title={Unsupervised learning of video representations using lstms},
  author={Srivastava, Nitish and Mansimov, Elman and Salakhudinov, Ruslan},
  booktitle={International conference on machine learning},
  pages={843--852},
  year={2015}
}

@inproceedings{klapper2001unsupervised,
  title={Unsupervised learning in LSTM recurrent neural networks},
  author={Klapper-Rybicka, Magdalena and Schraudolph, Nicol N and Schmidhuber, J{\"u}rgen},
  booktitle={International Conference on Artificial Neural Networks},
  pages={684--691},
  year={2001},
  organization={Springer}
}

@inproceedings{finn2016unsupervised,
  title={Unsupervised learning for physical interaction through video prediction},
  author={Finn, Chelsea and Goodfellow, Ian and Levine, Sergey},
  booktitle={Advances in neural information processing systems},
  pages={64--72},
  year={2016}
}

@article{schmidhuber1996semilinear,
  title={Semilinear predictability minimization produces well-known feature detectors},
  author={Schmidhuber, J{\"u}rgen and Eldracher, Martin and Foltin, Bernhard},
  journal={Neural Computation},
  volume={8},
  number={4},
  pages={773--786},
  year={1996},
  publisher={MIT Press}
}

@inproceedings{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2672--2680},
  year={2014}
}

@article{rezende2015variational,
  title={Variational inference with normalizing flows},
  author={Rezende, Danilo Jimenez and Mohamed, Shakir},
  journal={arXiv preprint arXiv:1505.05770},
  year={2015}
}

@inproceedings{van2016conditional,
  title={Conditional image generation with pixelcnn decoders},
  author={Van den Oord, Aaron and Kalchbrenner, Nal and Espeholt, Lasse and Vinyals, Oriol and Graves, Alex and others},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4790--4798},
  year={2016}
}

@article{oord2016wavenet,
  title={Wavenet: A generative model for raw audio},
  author={Oord, Aaron van den and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1609.03499},
  year={2016}
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@article{van2018relational,
  title={Relational neural expectation maximization: Unsupervised discovery of objects and their interactions},
  author={van Steenkiste, Sjoerd and Chang, Michael and Greff, Klaus and Schmidhuber, J{\"u}rgen},
  journal={arXiv preprint arXiv:1802.10353},
  year={2018}
}


@article{chang2016compositional,
  title={A compositional object-based approach to learning physical dynamics},
  author={Chang, Michael B and Ullman, Tomer and Torralba, Antonio and Tenenbaum, Joshua B},
  journal={arXiv preprint arXiv:1612.00341},
  year={2016}
}

@article{olshausen2004sparse,
  title={Sparse coding of sensory inputs},
  author={Olshausen, Bruno A and Field, David J},
  journal={Current opinion in neurobiology},
  volume={14},
  number={4},
  pages={481--487},
  year={2004},
  publisher={Elsevier}
}


@inproceedings{mairal2009online,
  title={Online dictionary learning for sparse coding},
  author={Mairal, Julien and Bach, Francis and Ponce, Jean and Sapiro, Guillermo},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={689--696},
  year={2009},
  organization={ACM}
}

@book{schweizer2011probabilistic,
  title={Probabilistic metric spaces},
  author={Schweizer, Berthold and Sklar, Abe},
  year={2011},
  publisher={Courier Corporation}
}


@inproceedings{esteves2018learning,
  title={Learning so (3) equivariant representations with spherical cnns},
  author={Esteves, Carlos and Allen-Blanchette, Christine and Makadia, Ameesh and Daniilidis, Kostas},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={52--68},
  year={2018}
}

@article{cohen2018spherical,
  title={Spherical cnns},
  author={Cohen, Taco S and Geiger, Mario and K{\"o}hler, Jonas and Welling, Max},
  journal={arXiv preprint arXiv:1801.10130},
  year={2018}
}


@article{eslami2018neural,
  title={Neural scene representation and rendering},
  author={Eslami, SM Ali and Rezende, Danilo Jimenez and Besse, Frederic and Viola, Fabio and Morcos, Ari S and Garnelo, Marta and Ruderman, Avraham and Rusu, Andrei A and Danihelka, Ivo and Gregor, Karol and others},
  journal={Science},
  volume={360},
  number={6394},
  pages={1204--1210},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

@article{ha2018world,
  title={World models},
  author={Ha, David and Schmidhuber, J{\"u}rgen},
  journal={arXiv preprint arXiv:1803.10122},
  year={2018}
}

@article{hafner2018learning,
  title={Learning Latent Dynamics for Planning from Pixels},
  author={Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James},
  journal={arXiv preprint arXiv:1811.04551},
  year={2018}
}

@article{karl2016deep,
  title={Deep variational bayes filters: Unsupervised learning of state space models from raw data},
  author={Karl, Maximilian and Soelch, Maximilian and Bayer, Justin and van der Smagt, Patrick},
  journal={arXiv preprint arXiv:1605.06432},
  year={2016}
}

@inproceedings{watter2015embed,
  title={Embed to control: A locally linear latent dynamics model for control from raw images},
  author={Watter, Manuel and Springenberg, Jost and Boedecker, Joschka and Riedmiller, Martin},
  booktitle={Advances in neural information processing systems},
  pages={2746--2754},
  year={2015}
}

@article{dilokthanakul2016deep,
  title={Deep unsupervised clustering with gaussian mixture variational autoencoders},
  author={Dilokthanakul, Nat and Mediano, Pedro AM and Garnelo, Marta and Lee, Matthew CH and Salimbeni, Hugh and Arulkumaran, Kai and Shanahan, Murray},
  journal={arXiv preprint arXiv:1611.02648},
  year={2016}
}


@inproceedings{kingma2014semi,
  title={Semi-supervised learning with deep generative models},
  author={Kingma, Durk P and Mohamed, Shakir and Rezende, Danilo Jimenez and Welling, Max},
  booktitle={Advances in neural information processing systems},
  pages={3581--3589},
  year={2014}
}

@inproceedings{kingma2016improved,
  title={Improved variational inference with inverse autoregressive flow},
  author={Kingma, Durk P and Salimans, Tim and Jozefowicz, Rafal and Chen, Xi and Sutskever, Ilya and Welling, Max},
  booktitle={Advances in neural information processing systems},
  pages={4743--4751},
  year={2016}
}

@inproceedings{sonderby2016ladder,
  title={Ladder variational autoencoders},
  author={S{\o}nderby, Casper Kaae and Raiko, Tapani and Maal{\o}e, Lars and S{\o}nderby, S{\o}ren Kaae and Winther, Ole},
  booktitle={Advances in neural information processing systems},
  pages={3738--3746},
  year={2016}
}

@article{chen2016variational,
  title={Variational lossy autoencoder},
  author={Chen, Xi and Kingma, Diederik P and Salimans, Tim and Duan, Yan and Dhariwal, Prafulla and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1611.02731},
  year={2016}
}

@article{tomczak2017vae,
  title={VAE with a VampPrior},
  author={Tomczak, Jakub M and Welling, Max},
  journal={arXiv preprint arXiv:1705.07120},
  year={2017}
}

@article{maaloe2019biva,
  title={BIVA: A Very Deep Hierarchy of Latent Variables for Generative Modeling},
  author={Maal{\o}e, Lars and Fraccaro, Marco and Li{\'e}vin, Valentin and Winther, Ole},
  journal={arXiv preprint arXiv:1902.02102},
  year={2019}
}

@article{zhao2017towards,
  title={Towards deeper understanding of variational autoencoding models},
  author={Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
  journal={arXiv preprint arXiv:1702.08658},
  year={2017}
}

@article{gulrajani2016pixelvae,
  title={Pixelvae: A latent variable model for natural images},
  author={Gulrajani, Ishaan and Kumar, Kundan and Ahmed, Faruk and Taiga, Adrien Ali and Visin, Francesco and Vazquez, David and Courville, Aaron},
  journal={arXiv preprint arXiv:1611.05013},
  year={2016}
}

%______________________________________________________________________
% datasets

@article{lecun1998mnist,
  title={The MNIST database of handwritten digits},
  author={LeCun, Yann},
  journal={http://yann. lecun. com/exdb/mnist/},
  year={1998}
}

@article{xiao2017fashion,
  title={Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms},
  author={Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  journal={arXiv preprint arXiv:1708.07747},
  year={2017}
}

@article{cohen2017emnist,
  title={EMNIST: an extension of MNIST to handwritten letters},
  author={Cohen, Gregory and Afshar, Saeed and Tapson, Jonathan and van Schaik, Andr{\'e}},
  journal={arXiv preprint arXiv:1702.05373},
  year={2017}
}

@article{krizhevsky2010convolutional,
  title={Convolutional deep belief networks on cifar-10},
  author={Krizhevsky, Alex and Hinton, Geoff},
  journal={Unpublished manuscript},
  volume={40},
  number={7},
  year={2010}
}

@article{netzer2011reading,
  title={Reading digits in natural images with unsupervised feature learning},
  author={Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
  year={2011}
}

@inproceedings{johnson2017clevr,
  title={Clevr: A diagnostic dataset for compositional language and elementary visual reasoning},
  author={Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Fei-Fei, Li and Lawrence Zitnick, C and Girshick, Ross},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2901--2910},
  year={2017}
}

@article{bregman1967relaxation,
  title={The relaxation method of finding the common point of convex sets and its application to the solution of problems in convex programming},
  author={Bregman, Lev M},
  journal={USSR computational mathematics and mathematical physics},
  volume={7},
  number={3},
  pages={200--217},
  year={1967},
  publisher={Elsevier}
}

@article{arvanitidis2017latent,
  title={Latent space oddity: on the curvature of deep generative models},
  author={Arvanitidis, Georgios and Hansen, Lars Kai and Hauberg, S{\o}ren},
  journal={arXiv preprint arXiv:1710.11379},
  year={2017}
}

@article{hauberg2018only,
  title={Only Bayes should learn a manifold (on the estimation of differential geometric structure from data)},
  author={Hauberg, S{\o}ren},
  journal={arXiv preprint arXiv:1806.04994},
  year={2018}
}

@article{lake2015human,
  title={Human-level concept learning through probabilistic program induction},
  author={Lake, Brenden M and Salakhutdinov, Ruslan and Tenenbaum, Joshua B},
  journal={Science},
  volume={350},
  number={6266},
  pages={1332--1338},
  year={2015},
  publisher={American Association for the Advancement of Science}
}

@article{burgess2019monet,
  title={MONet: Unsupervised Scene Decomposition and Representation},
  author={Burgess, Christopher P and Matthey, Loic and Watters, Nicholas and Kabra, Rishabh and Higgins, Irina and Botvinick, Matt and Lerchner, Alexander},
  journal={arXiv preprint arXiv:1901.11390},
  year={2019}
}

@article{greff2019multi,
  title={Multi-Object Representation Learning with Iterative Variational Inference},
  author={Greff, Klaus and Kaufmann, Rapha{\"e}l Lopez and Kabra, Rishab and Watters, Nick and Burgess, Chris and Zoran, Daniel and Matthey, Loic and Botvinick, Matthew and Lerchner, Alexander},
  journal={arXiv preprint arXiv:1903.00450},
  year={2019}
}

@article{kalman1960new,
  title={A new approach to linear filtering and prediction problems},
  author={Kalman, Rudolph Emil},
  journal={Journal of basic Engineering},
  volume={82},
  number={1},
  pages={35--45},
  year={1960},
  publisher={American Society of Mechanical Engineers}
}

@article{burda2015importance,
  title={Importance weighted autoencoders},
  author={Burda, Yuri and Grosse, Roger and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1509.00519},
  year={2015}
}

@article{bayer2014learning,
  title={Learning stochastic recurrent networks},
  author={Bayer, Justin and Osendorfer, Christian},
  journal={arXiv preprint arXiv:1411.7610},
  year={2014}
}

@inproceedings{lucas2018auxiliary,
  title={Auxiliary guided autoregressive variational autoencoders},
  author={Lucas, Thomas and Verbeek, Jakob},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={443--458},
  year={2018},
  organization={Springer}
}

@article{razavi2019preventing,
  title={Preventing Posterior Collapse with delta-VAEs},
  author={Razavi, Ali and Oord, A{\"a}ron van den and Poole, Ben and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1901.03416},
  year={2019}
}

@article{de2019hierarchical,
  title={Hierarchical Autoregressive Image Models with Auxiliary Decoders},
  author={De Fauw, Jeffrey and Dieleman, Sander and Simonyan, Karen},
  journal={arXiv preprint arXiv:1903.04933},
  year={2019}
}

@inproceedings{zaheer2017deep,
  title={Deep sets},
  author={Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Ruslan R and Smola, Alexander J},
  booktitle={Advances in neural information processing systems},
  pages={3391--3401},
  year={2017}
}

@article{salimans2017pixelcnn++,
  title={Pixelcnn++: Improving the pixelcnn with discretized logistic mixture likelihood and other modifications},
  author={Salimans, Tim and Karpathy, Andrej and Chen, Xi and Kingma, Diederik P},
  journal={arXiv preprint arXiv:1701.05517},
  year={2017}
}


@article{dhillon2007weighted,
  title={Weighted graph cuts without eigenvectors a multilevel approach},
  author={Dhillon, Inderjit S and Guan, Yuqiang and Kulis, Brian},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={29},
  number={11},
  pages={1944--1957},
  year={2007},
  publisher={IEEE}
}

@inproceedings{fey2018splinecnn,
  title={SplineCNN: Fast geometric deep learning with continuous B-spline kernels},
  author={Fey, Matthias and Eric Lenssen, Jan and Weichert, Frank and M{\"u}ller, Heinrich},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={869--877},
  year={2018}
}

@article{fey2019fast,
  title={Fast Graph Representation Learning with PyTorch Geometric},
  author={Fey, Matthias and Lenssen, Jan Eric},
  journal={arXiv preprint arXiv:1903.02428},
  year={2019}
}

@inproceedings{monti2017geometric,
  title={Geometric deep learning on graphs and manifolds using mixture model cnns},
  author={Monti, Federico and Boscaini, Davide and Masci, Jonathan and Rodola, Emanuele and Svoboda, Jan and Bronstein, Michael M},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={5115--5124},
  year={2017}
}

@article{bloice2017augmentor,
  title={Augmentor: an image augmentation library for machine learning},
  author={Bloice, Marcus D and Stocker, Christof and Holzinger, Andreas},
  journal={arXiv preprint arXiv:1708.04680},
  year={2017}
}

@article{oja1989neural,
  title={Neural networks, principal components, and subspaces},
  author={Oja, Erkki},
  journal={International journal of neural systems},
  volume={1},
  number={01},
  pages={61--68},
  year={1989},
  publisher={World Scientific}
}

@inproceedings{gretton2007kernel,
  title={A kernel method for the two-sample-problem},
  author={Gretton, Arthur and Borgwardt, Karsten and Rasch, Malte and Sch{\"o}lkopf, Bernhard and Smola, Alex J},
  booktitle={Advances in neural information processing systems},
  pages={513--520},
  year={2007}
}

@article{zellinger2017central,
  title={Central moment discrepancy (cmd) for domain-invariant representation learning},
  author={Zellinger, Werner and Grubinger, Thomas and Lughofer, Edwin and Natschl{\"a}ger, Thomas and Saminger-Platz, Susanne},
  journal={arXiv preprint arXiv:1702.08811},
  year={2017}
}

@article{muller1997integral,
  title={Integral probability metrics and their generating classes of functions},
  author={M{\"u}ller, Alfred},
  journal={Advances in Applied Probability},
  volume={29},
  number={2},
  pages={429--443},
  year={1997},
  publisher={Cambridge University Press}
}

@article{louizos2015variational,
  title={The variational fair autoencoder},
  author={Louizos, Christos and Swersky, Kevin and Li, Yujia and Welling, Max and Zemel, Richard},
  journal={arXiv preprint arXiv:1511.00830},
  year={2015}
}

@article{sriperumbudur2012empirical,
  title={On the empirical estimation of integral probability metrics},
  author={Sriperumbudur, Bharath K and Fukumizu, Kenji and Gretton, Arthur and Sch{\"o}lkopf, Bernhard and Lanckriet, Gert RG and others},
  journal={Electronic Journal of Statistics},
  volume={6},
  pages={1550--1599},
  year={2012},
  publisher={The Institute of Mathematical Statistics and the Bernoulli Society}
}

@article{oord2016pixel,
  title={Pixel recurrent neural networks},
  author={Oord, Aaron van den and Kalchbrenner, Nal and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1601.06759},
  year={2016}
}

@article{chen2017pixelsnail,
  title={Pixelsnail: An improved autoregressive generative model},
  author={Chen, Xi and Mishra, Nikhil and Rohaninejad, Mostafa and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1712.09763},
  year={2017}
}

@inproceedings{sabour2017dynamic,
  title={Dynamic routing between capsules},
  author={Sabour, Sara and Frosst, Nicholas and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={3856--3866},
  year={2017}
}

@article{lesort2018state,
  title={State representation learning for control: An overview},
  author={Lesort, Timoth{\'e}e and D{\'\i}az-Rodr{\'\i}guez, Natalia and Goudou, Jean-Franois and Filliat, David},
  journal={Neural Networks},
  year={2018},
  publisher={Elsevier}
}

@article{kim2019attentive,
  title={Attentive neural processes},
  author={Kim, Hyunjik and Mnih, Andriy and Schwarz, Jonathan and Garnelo, Marta and Eslami, Ali and Rosenbaum, Dan and Vinyals, Oriol and Teh, Yee Whye},
  journal={arXiv preprint arXiv:1901.05761},
  year={2019}
}

@article{hochreiter1999feature,
  title={Feature extraction through LOCOCODE},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural Computation},
  volume={11},
  number={3},
  pages={679--714},
  year={1999},
  publisher={MIT Press}
}

@book{ambrosio2008gradient,
  title={Gradient flows: in metric spaces and in the space of probability measures},
  author={Ambrosio, Luigi and Gigli, Nicola and Savar{\'e}, Giuseppe},
  year={2008},
  publisher={Springer Science \& Business Media}
}

@book{boyd2004convex,
  title={Convex optimization},
  author={Boyd, Stephen and Vandenberghe, Lieven},
  year={2004},
  publisher={Cambridge university press}
}

@inproceedings{schulman2015gradient,
  title={Gradient estimation using stochastic computation graphs},
  author={Schulman, John and Heess, Nicolas and Weber, Theophane and Abbeel, Pieter},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3528--3536},
  year={2015}
}

@article{rezende2014stochastic,
  title={Stochastic backpropagation and approximate inference in deep generative models},
  author={Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
  journal={arXiv preprint arXiv:1401.4082},
  year={2014}
}

@inproceedings{lenssen2018group,
  title={Group equivariant capsule networks},
  author={Lenssen, Jan Eric and Fey, Matthias and Libuschewski, Pascal},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8844--8853},
  year={2018}
}

@inproceedings{sermanet2018time,
  title={Time-contrastive networks: Self-supervised learning from video},
  author={Sermanet, Pierre and Lynch, Corey and Chebotar, Yevgen and Hsu, Jasmine and Jang, Eric and Schaal, Stefan and Levine, Sergey and Brain, Google},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1134--1141},
  year={2018},
  organization={IEEE}
}

@inproceedings{hadsell2006dimensionality,
  title={Dimensionality reduction by learning an invariant mapping},
  author={Hadsell, Raia and Chopra, Sumit and LeCun, Yann},
  booktitle={2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)},
  volume={2},
  pages={1735--1742},
  year={2006},
  organization={IEEE}
}

@article{cirecsan2012multi,
  title={Multi-column deep neural networks for image classification},
  author={Cire{\c{s}}an, Dan and Meier, Ueli and Schmidhuber, J{\"u}rgen},
  journal={arXiv preprint arXiv:1202.2745},
  year={2012}
}

@article{Ciresan2010DeepBS,
  title={Deep, Big, Simple Neural Nets for Handwritten Digit Recognition},
  author={Dan C. Ciresan and Ueli Meier and Luca Maria Gambardella and J{\"u}rgen Schmidhuber},
  journal={Neural Computation},
  year={2010},
  volume={22},
  pages={3207-3220}
}

@inproceedings{chopra2005learning,
  title={Learning a similarity metric discriminatively, with application to face verification},
  author={Chopra, Sumit and Hadsell, Raia and LeCun, Yann and others},
  booktitle={CVPR (1)},
  pages={539--546},
  year={2005}
}

@inproceedings{hyvarinen2016unsupervised,
  title={Unsupervised feature extraction by time-contrastive learning and nonlinear ica},
  author={Hyvarinen, Aapo and Morioka, Hiroshi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3765--3773},
  year={2016}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@inproceedings{ciresan2011flexible,
  title={Flexible, high performance convolutional neural networks for image classification},
  author={Ciresan, Dan Claudiu and Meier, Ueli and Masci, Jonathan and Gambardella, Luca Maria and Schmidhuber, J{\"u}rgen},
  booktitle={Twenty-Second International Joint Conference on Artificial Intelligence},
  year={2011}
}

@book{bishop2006pattern,
  title={Pattern recognition and machine learning},
  author={Bishop, Christopher M},
  year={2006},
  publisher={springer}
}

@inproceedings{ranganath2014black,
  title={Black box variational inference},
  author={Ranganath, Rajesh and Gerrish, Sean and Blei, David},
  booktitle={Artificial Intelligence and Statistics},
  pages={814--822},
  year={2014}
}

@article{hoffman2013stochastic,
  title={Stochastic variational inference},
  author={Hoffman, Matthew D and Blei, David M and Wang, Chong and Paisley, John},
  journal={The Journal of Machine Learning Research},
  volume={14},
  number={1},
  pages={1303--1347},
  year={2013},
  publisher={JMLR. org}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{gregor2016towards,
  title={Towards conceptual compression},
  author={Gregor, Karol and Besse, Frederic and Rezende, Danilo Jimenez and Danihelka, Ivo and Wierstra, Daan},
  booktitle={Advances In Neural Information Processing Systems},
  pages={3549--3557},
  year={2016}
}

@incollection{bottou2018geometrical,
  title={Geometrical insights for implicit generative modeling},
  author={Bottou, Leon and Arjovsky, Martin and Lopez-Paz, David and Oquab, Maxime},
  booktitle={Braverman Readings in Machine Learning. Key Ideas from Inception to Current State},
  pages={229--268},
  year={2018},
  publisher={Springer}
}

@article{mohamed2016learning,
  title={Learning in implicit generative models},
  author={Mohamed, Shakir and Lakshminarayanan, Balaji},
  journal={arXiv preprint arXiv:1610.03483},
  year={2016}
}

@article{satorras2019combining,
  title={Combining Generative and Discriminative Models for Hybrid Inference},
  author={Satorras, Victor Garcia and Akata, Zeynep and Welling, Max},
  journal={arXiv preprint arXiv:1906.02547},
  year={2019}
}

@article{bloem2019probabilistic,
  title={Probabilistic symmetry and invariant neural networks},
  author={Bloem-Reddy, Benjamin and Teh, Yee Whye},
  journal={arXiv preprint arXiv:1901.06082},
  year={2019}
}

@article{wood1996representation,
  title={Representation theory and invariant neural networks},
  author={Wood, Jeffrey and Shawe-Taylor, John},
  journal={Discrete applied mathematics},
  volume={69},
  number={1-2},
  pages={33--60},
  year={1996},
  publisher={Elsevier}
}



@inproceedings{diaconis1988sufficiency,
  title={Sufficiency as statistical symmetry},
  author={Diaconis, Persi},
  booktitle={Proceedings of the AMS Centennial Symposium},
  pages={15--26},
  year={1988}
}

@article{orbanz2014bayesian,
  title={Bayesian models of graphs, arrays and other exchangeable random structures},
  author={Orbanz, Peter and Roy, Daniel M},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={37},
  number={2},
  pages={437--461},
  year={2014},
  publisher={IEEE}
}

@article{kosiorek2019stacked,
  title={Stacked Capsule Autoencoders},
  author={Kosiorek, Adam R and Sabour, Sara and Teh, Yee Whye and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1906.06818},
  year={2019}
}

@article{nalisnick2019hybrid,
  title={Hybrid models with deep and invertible features},
  author={Nalisnick, Eric and Matsukawa, Akihiro and Teh, Yee Whye and Gorur, Dilan and Lakshminarayanan, Balaji},
  journal={arXiv preprint arXiv:1902.02767},
  year={2019}
}

@article{graves2013generating,
  title={Generating sequences with recurrent neural networks},
  author={Graves, Alex},
  journal={arXiv preprint arXiv:1308.0850},
  year={2013}
}

@article{oord2016wavenet,
  title={Wavenet: A generative model for raw audio},
  author={Oord, Aaron van den and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1609.03499},
  year={2016}
}


@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}

@article{battaglia2018relational,
  title={Relational inductive biases, deep learning, and graph networks},
  author={Battaglia, Peter W and Hamrick, Jessica B and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and others},
  journal={arXiv preprint arXiv:1806.01261},
  year={2018}
}

@article{bronstein2017geometric,
  title={Geometric deep learning: going beyond euclidean data},
  author={Bronstein, Michael M and Bruna, Joan and LeCun, Yann and Szlam, Arthur and Vandergheynst, Pierre},
  journal={IEEE Signal Processing Magazine},
  volume={34},
  number={4},
  pages={18--42},
  year={2017},
  publisher={IEEE}
}

@article{sharma2019dynamics,
  title={Dynamics-Aware Unsupervised Discovery of Skills},
  author={Sharma, Archit and Gu, Shixiang and Levine, Sergey and Kumar, Vikash and Hausman, Karol},
  journal={arXiv preprint arXiv:1907.01657},
  year={2019}
}

@article{kulkarni2019unsupervised,
  title={Unsupervised Learning of Object Keypoints for Perception and Control},
  author={Kulkarni, Tejas and Gupta, Ankush and Ionescu, Catalin and Borgeaud, Sebastian and Reynolds, Malcolm and Zisserman, Andrew and Mnih, Volodymyr},
  journal={arXiv preprint arXiv:1906.11883},
  year={2019}
}

@article{gregor2018temporal,
  title={Temporal difference variational auto-encoder},
  author={Gregor, Karol and Papamakarios, George and Besse, Frederic and Buesing, Lars and Weber, Theophane},
  journal={arXiv preprint arXiv:1806.03107},
  year={2018}
}

@article{han2019learning,
  title={Learning to Discover Novel Visual Categories via Deep Transfer Clustering},
  author={Han, Kai and Vedaldi, Andrea and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1908.09884},
  year={2019}
}

@inproceedings{dwibedi2019temporal,
  title={Temporal Cycle-Consistency Learning},
  author={Dwibedi, Debidatta and Aytar, Yusuf and Tompson, Jonathan and Sermanet, Pierre and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1801--1810},
  year={2019}
}

@article{gregor2019shaping,
  title={Shaping Belief States with Generative Environment Models for RL},
  author={Gregor, Karol and Rezende, Danilo Jimenez and Besse, Frederic and Wu, Yan and Merzic, Hamza and Oord, Aaron van den},
  journal={arXiv preprint arXiv:1906.09237},
  year={2019}
}

@article{brock2018large,
  title={Large scale gan training for high fidelity natural image synthesis},
  author={Brock, Andrew and Donahue, Jeff and Simonyan, Karen},
  journal={arXiv preprint arXiv:1809.11096},
  year={2018}
}

@inproceedings{schlag2018learning,
  title={Learning to reason with third order tensor products},
  author={Schlag, Imanol and Schmidhuber, J{\"u}rgen},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9981--9993},
  year={2018}
}

@inproceedings{sutskever2009using,
  title={Using matrices to model symbolic relationship},
  author={Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1593--1600},
  year={2009}
}

@inproceedings{snell2017prototypical,
  title={Prototypical networks for few-shot learning},
  author={Snell, Jake and Swersky, Kevin and Zemel, Richard},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4077--4087},
  year={2017}
}

@article{watters2019spatial,
  title={Spatial Broadcast Decoder: A Simple Architecture for Learning Disentangled Representations in VAEs},
  author={Watters, Nicholas and Matthey, Loic and Burgess, Christopher P and Lerchner, Alexander},
  journal={arXiv preprint arXiv:1901.07017},
  year={2019}
}


@article{guo2018neural,
  title={Neural predictive belief representations},
  author={Guo, Zhaohan Daniel and Azar, Mohammad Gheshlaghi and Piot, Bilal and Pires, Bernardo A and Pohlen, Toby and Munos, R{\'e}mi},
  journal={arXiv preprint arXiv:1811.06407},
  year={2018}
}

@article{kullback1951information,
  title={On information and sufficiency},
  author={Kullback, Solomon and Leibler, Richard A},
  journal={The annals of mathematical statistics},
  volume={22},
  number={1},
  pages={79--86},
  year={1951},
  publisher={JSTOR}
}

@article{khemakhem2019variational,
  title={Variational autoencoders and nonlinear ica: A unifying framework},
  author={Khemakhem, Ilyes and Kingma, Diederik P and Hyv{\"a}rinen, Aapo},
  journal={arXiv preprint arXiv:1907.04809},
  year={2019}
}

@inproceedings{nalisnick2018learning,
  title={Learning priors for invariance},
  author={Nalisnick, Eric and Smyth, Padhraic},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={366--375},
  year={2018}
}

@techreport{anselmi2014representation,
  title={Representation learning in sensory cortex: a theory},
  author={Anselmi, Fabio and Poggio, Tomaso},
  year={2014},
  institution={Center for Brains, Minds and Machines (CBMM)}
}

@techreport{poggio2015theory,
  title={I-theory on depth vs width: hierarchical function composition},
  author={Poggio, Tomaso and Anselmi, Fabio and Rosasco, Lorenzo},
  year={2015},
  institution={Center for Brains, Minds and Machines (CBMM)}
}

@ARTICLE{Poggio:2013,
AUTHOR = {Poggio, T.  and Serre, T. },
TITLE   = {{M}odels of visual cortex},
YEAR    = {2013},
JOURNAL = {Scholarpedia},
VOLUME  = {8},
NUMBER  = {4},
PAGES   = {3516},
DOI     = {10.4249/scholarpedia.3516},
NOTE    = {revision \#149958}
}

@article{shu2019weakly,
  title={Weakly Supervised Disentanglement with Guarantees},
  author={Shu, Rui and Chen, Yining and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  journal={arXiv preprint arXiv:1910.09772},
  year={2019}
}

@inproceedings{li2015generative,
  title={Generative moment matching networks},
  author={Li, Yujia and Swersky, Kevin and Zemel, Rich},
  booktitle={International Conference on Machine Learning},
  pages={1718--1727},
  year={2015}
}

@article{satorras2019combining,
  title={Combining Generative and Discriminative Models for Hybrid Inference},
  author={Satorras, Victor Garcia and Akata, Zeynep and Welling, Max},
  journal={arXiv preprint arXiv:1906.02547},
  year={2019}
}

@inproceedings{tran2017hierarchical,
  title={Hierarchical implicit models and likelihood-free variational inference},
  author={Tran, Dustin and Ranganath, Rajesh and Blei, David},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5523--5533},
  year={2017}
}

@article{papamakarios2019neural,
  title={Neural density estimation and likelihood-free inference},
  author={Papamakarios, George},
  journal={arXiv preprint arXiv:1910.13233},
  year={2019}
}

@article{papamakarios2018sequential,
  title={Sequential neural likelihood: Fast likelihood-free inference with autoregressive flows},
  author={Papamakarios, George and Sterratt, David C and Murray, Iain},
  journal={arXiv preprint arXiv:1805.07226},
  year={2018}
}

@article{marr1978representation,
  title={Representation and recognition of the spatial organization of three-dimensional shapes},
  author={Marr, David and Nishihara, Herbert Keith},
  journal={Proceedings of the Royal Society of London. Series B. Biological Sciences},
  volume={200},
  number={1140},
  pages={269--294},
  year={1978},
  publisher={The Royal Society London}
}

@book{marr,
  title={Vision: a computational investigation into the human representation and processing of visual
information},
  author={Marr, David},
  year={1982},
  publisher={W H Freeman}
}

@inproceedings{hinton1981parallel,
  title={A parallel computation that assigns canonical object-based frames of reference},
  author={Hinton, Geoffrey F},
  booktitle={Proceedings of the 7th international joint conference on Artificial intelligence-Volume 2},
  pages={683--685},
  year={1981}
}

@article{olshausen1995multiscale,
  title={A multiscale dynamic routing circuit for forming size-and position-invariant object representations},
  author={Olshausen, Bruno A and Anderson, Charles H and Van Essen, David C},
  journal={Journal of Computational Neuroscience},
  volume={2},
  number={1},
  pages={45--62},
  year={1995},
  publisher={Springer}
}

@article{anderson1987shifter,
  title={Shifter circuits: a computational strategy for dynamic aspects of visual processing},
  author={Anderson, Charles H and Van Essen, David C},
  journal={Proceedings of the National Academy of Sciences},
  volume={84},
  number={17},
  pages={6297--6301},
  year={1987},
  publisher={National Acad Sciences}
}

@book{zee2016group,
  title={Group theory in a nutshell for physicists},
  author={Zee, Anthony},
  year={2016},
  publisher={Princeton University Press}
}

@article{weyl1927quantenmechanik,
  title={Quantenmechanik und gruppentheorie},
  author={Weyl, Hermann},
  journal={Zeitschrift f{\"u}r Physik},
  volume={46},
  number={1-2},
  pages={1--46},
  year={1927},
  publisher={Springer}
}

@book{kondor2008group,
  title={Group theoretical methods in machine learning},
  author={Kondor, Imre Risi},
  volume={2},
  year={2008},
  publisher={Columbia University}
}

@article{mallat2012group,
  title={Group invariant scattering},
  author={Mallat, St{\'e}phane},
  journal={Communications on Pure and Applied Mathematics},
  volume={65},
  number={10},
  pages={1331--1398},
  year={2012},
  publisher={Wiley Online Library}
}

@article{bruna2013invariant,
  title={Invariant scattering convolution networks},
  author={Bruna, Joan and Mallat, St{\'e}phane},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={35},
  number={8},
  pages={1872--1886},
  year={2013},
  publisher={IEEE}
}

@inproceedings{hinton2011transforming,
  title={Transforming auto-encoders},
  author={Hinton, Geoffrey E and Krizhevsky, Alex and Wang, Sida D},
  booktitle={International conference on artificial neural networks},
  pages={44--51},
  year={2011},
  organization={Springer}
}

@book{klein2016elementary,
  title={Elementary mathematics from a higher standpoint},
  author={Klein, Felix},
  year={2016},
  publisher={Springer}
}

@book{klein,
  title={Vergleichende Betrachtungen ber neuere geometrische Forschungen},
  author={Klein, Felix},
  year={1872},
  publisher={Erlangen}
}

@book{wigner1931gruppentheorie,
  title={Gruppentheorie und ihre Anwendung auf die Quantenmechanik der Atomspektren},
  author={Wigner, Eugene Paul},
  year={1931},
  publisher={Springer}
}

@book{zee2016group,
  title={Group theory in a nutshell for physicists},
  author={Zee, Anthony},
  year={2016},
  publisher={Princeton University Press}
}

@book{kowalski2014introduction,
  title={An introduction to the representation theory of groups},
  author={Kowalski, Emmanuel},
  volume={155},
  year={2014},
  publisher={American Mathematical Society}
}

@book{robinson2012course,
  title={A Course in the Theory of Groups},
  author={Robinson, Derek JS},
  volume={80},
  year={2012},
  publisher={Springer}
}

@article{jordan1999introduction,
  title={An introduction to variational methods for graphical models},
  author={Jordan, Michael I and Ghahramani, Zoubin and Jaakkola, Tommi S and Saul, Lawrence K},
  journal={Machine learning},
  volume={37},
  number={2},
  pages={183--233},
  year={1999},
  publisher={Springer}
}

@inproceedings{gershman2014amortized,
  title={Amortized inference in probabilistic reasoning},
  author={Gershman, Samuel and Goodman, Noah},
  booktitle={Proceedings of the annual meeting of the cognitive science society},
  volume={36},
  number={36},
  year={2014}
}

@article{parascandolo2017learning,
  title={Learning independent causal mechanisms},
  author={Parascandolo, Giambattista and Kilbertus, Niki and Rojas-Carulla, Mateo and Sch{\"o}lkopf, Bernhard},
  journal={arXiv preprint arXiv:1712.00961},
  year={2017}
}

@article{scholkopf2019causality,
  title={Causality for Machine Learning},
  author={Sch{\"o}lkopf, Bernhard},
  journal={arXiv preprint arXiv:1911.10500},
  year={2019}
}

@article{cohen2014transformation,
  title={Transformation properties of learned visual representations},
  author={Cohen, Taco S and Welling, Max},
  journal={arXiv preprint arXiv:1412.7659},
  year={2014}
}

@article{scholkopf2012causal,
  title={On causal and anticausal learning},
  author={Sch{\"o}lkopf, Bernhard and Janzing, Dominik and Peters, Jonas and Sgouritsa, Eleni and Zhang, Kun and Mooij, Joris},
  journal={arXiv preprint arXiv:1206.6471},
  year={2012}
}

@book{peters2017elements,
  title={Elements of causal inference: foundations and learning algorithms},
  author={Peters, Jonas and Janzing, Dominik and Sch{\"o}lkopf, Bernhard},
  year={2017},
  publisher={MIT press}
}

@article{detlefsen2019explicit,
  title={Explicit disentanglement of appearance and perspective in generative models},
  author={Detlefsen, Nicki Skafte and Hauberg, S{\o}ren},
  journal={arXiv preprint arXiv:1906.11881},
  year={2019}
}

@article{affNIST,
    title={The affNIST dataset},
    url={http://www.cs.toronto.edu/~tijmen/affNIST},
    year={2013},
    author={Tijmen Tieleman}
}
 
@article{suter2018robustly,
  title={Robustly disentangled causal mechanisms: Validating deep representations for interventional robustness},
  author={Suter, Raphael and Miladinovi{\'c}, {\DJ}or{\dj}e and Sch{\"o}lkopf, Bernhard and Bauer, Stefan},
  journal={arXiv preprint arXiv:1811.00007},
  year={2018}
}

@article{tolstikhin2017wasserstein,
  title={Wasserstein auto-encoders},
  author={Tolstikhin, Ilya and Bousquet, Olivier and Gelly, Sylvain and Schoelkopf, Bernhard},
  journal={arXiv preprint arXiv:1711.01558},
  year={2017}
}

@inproceedings{caselles2019symmetry,
  title={Symmetry-Based Disentangled Representation Learning requires Interaction with Environments},
  author={Caselles-Dupr{\'e}, Hugo and Ortiz, Michael Garcia and Filliat, David},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4608--4617},
  year={2019}
}

@article{memisevic2012multi,
  title={On multi-view feature learning},
  author={Memisevic, Roland},
  journal={arXiv preprint arXiv:1206.4609},
  year={2012}
}

@book{mezard2009information,
  title={Information, physics, and computation},
  author={Mezard, Marc and Mezard, Marc and Montanari, Andrea},
  year={2009},
  publisher={Oxford University Press}
}

@inproceedings{memisevic2007unsupervised,
  title={Unsupervised learning of image transformations},
  author={Memisevic, Roland and Hinton, Geoffrey},
  booktitle={2007 IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1--8},
  year={2007},
  organization={IEEE}
}

@inproceedings{liu2015faceattributes,
 title = {Deep Learning Face Attributes in the Wild},
 author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
 booktitle = {Proceedings of International Conference on Computer Vision (ICCV)},
 month = {December},
 year = {2015} 
}

@article{brakel2017learning,
  title={Learning independent features with adversarial nets for non-linear ica},
  author={Brakel, Philemon and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1710.05050},
  year={2017}
}

@inproceedings{michalski2014modeling,
  title={Modeling deep temporal dependencies with recurrent grammar cells""},
  author={Michalski, Vincent and Memisevic, Roland and Konda, Kishore},
  booktitle={Advances in neural information processing systems},
  pages={1925--1933},
  year={2014}
}

@inproceedings{kuleshov2017neural,
  title={Neural variational inference and learning in undirected graphical models},
  author={Kuleshov, Volodymyr and Ermon, Stefano},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6734--6743},
  year={2017}
}

@article{dai2019diagnosing,
  title={Diagnosing and enhancing vae models},
  author={Dai, Bin and Wipf, David},
  journal={arXiv preprint arXiv:1903.05789},
  year={2019}
}

@book{lie1871over,
  title={Over en classe geometriske transformationer},
  author={Lie, Marius Sophus},
  year={1871}
}

@book{zee2016group,
  title={Group theory in a nutshell for physicists},
  author={Zee, Anthony},
  year={2016},
  publisher={Princeton University Press}
}

@book{pearl2009causality,
  title={Causality},
  author={Pearl, Judea},
  year={2009},
  publisher={Cambridge university press}
}

@inproceedings{lucas2018auxiliary,
  title={Auxiliary guided autoregressive variational autoencoders},
  author={Lucas, Thomas and Verbeek, Jakob},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={443--458},
  year={2018},
  organization={Springer}
}

@article{grant2018recasting,
  title={Recasting gradient-based meta-learning as hierarchical bayes},
  author={Grant, Erin and Finn, Chelsea and Levine, Sergey and Darrell, Trevor and Griffiths, Thomas},
  journal={arXiv preprint arXiv:1801.08930},
  year={2018}
}

@article{rezende2016one,
  title={One-shot generalization in deep generative models},
  author={Rezende, Danilo Jimenez and Mohamed, Shakir and Danihelka, Ivo and Gregor, Karol and Wierstra, Daan},
  journal={arXiv preprint arXiv:1603.05106},
  year={2016}
}

@article{xu2019metafun,
  title={MetaFun: Meta-Learning with Iterative Functional Updates},
  author={Xu, Jin and Ton, Jean-Francois and Kim, Hyunjik and Kosiorek, Adam R and Teh, Yee Whye},
  journal={arXiv preprint arXiv:1912.02738},
  year={2019}
}

@inproceedings{masrani2019thermodynamic,
  title={The Thermodynamic Variational Objective},
  author={Masrani, Vaden and Le, Tuan Anh and Wood, Frank},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11525--11534},
  year={2019}
}

@article{marino2018iterative,
  title={Iterative amortized inference},
  author={Marino, Joseph and Yue, Yisong and Mandt, Stephan},
  journal={arXiv preprint arXiv:1807.09356},
  year={2018}
}

@inproceedings{bartunov2018few,
  title={Few-shot generative modelling with generative matching networks},
  author={Bartunov, Sergey and Vetrov, Dmitry},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={670--678},
  year={2018}
}

@inproceedings{vinyals2016matching,
  title={Matching networks for one shot learning},
  author={Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Wierstra, Daan and others},
  booktitle={Advances in neural information processing systems},
  pages={3630--3638},
  year={2016}
}

@inproceedings{sung2018learning,
  title={Learning to compare: Relation network for few-shot learning},
  author={Sung, Flood and Yang, Yongxin and Zhang, Li and Xiang, Tao and Torr, Philip HS and Hospedales, Timothy M},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1199--1208},
  year={2018}
}

@inproceedings{choi2019meta,
  title={Meta-amortized variational inference and learning},
  author={Choi, Kristy and Wu, Mike and Goodman, Noah and Ermon, Stefano},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{reed2017few,
  title={Few-shot autoregressive density estimation: Towards learning to learn distributions},
  author={Reed, Scott and Chen, Yutian and Paine, Thomas and Oord, A{\"a}ron van den and Eslami, SM and Rezende, Danilo and Vinyals, Oriol and de Freitas, Nando},
  journal={arXiv preprint arXiv:1710.10304},
  year={2017}
}

@book{thrun2012learning,
  title={Learning to learn},
  author={Thrun, Sebastian and Pratt, Lorien},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@inproceedings{andrychowicz2016learning,
  title={Learning to learn by gradient descent by gradient descent},
  author={Andrychowicz, Marcin and Denil, Misha and Gomez, Sergio and Hoffman, Matthew W and Pfau, David and Schaul, Tom and Shillingford, Brendan and De Freitas, Nando},
  booktitle={Advances in neural information processing systems},
  pages={3981--3989},
  year={2016}
}

@inproceedings{hochreiter2001learning,
  title={Learning to learn using gradient descent},
  author={Hochreiter, Sepp and Younger, A Steven and Conwell, Peter R},
  booktitle={International Conference on Artificial Neural Networks},
  pages={87--94},
  year={2001},
  organization={Springer}
}

@article{li2017meta,
  title={Meta-sgd: Learning to learn quickly for few-shot learning},
  author={Li, Zhenguo and Zhou, Fengwei and Chen, Fei and Li, Hang},
  journal={arXiv preprint arXiv:1707.09835},
  year={2017}
}


@article{ravi2016optimization,
  title={Optimization as a model for few-shot learning},
  author={Ravi, Sachin and Larochelle, Hugo},
  year={2016}
}

@article{garcia2017few,
  title={Few-shot learning with graph neural networks},
  author={Garcia, Victor and Bruna, Joan},
  journal={arXiv preprint arXiv:1711.04043},
  year={2017}
}

@article{oreshkin2018tadam,
  title={Tadam: Task dependent adaptive metric for improved few-shot learning},
  author={Oreshkin, Boris and Rodr{\'\i}guez L{\'o}pez, Pau and Lacoste, Alexandre},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  pages={721--731},
  year={2018}
}

@article{schaul2010metalearning,
  title={Metalearning},
  author={Schaul, Tom and Schmidhuber, J{\"u}rgen},
  journal={Scholarpedia},
  volume={5},
  number={6},
  pages={4650},
  year={2010}
}

@phdthesis{schmidhuber1987evolutionary,
  title={Evolutionary principles in self-referential learning, or on learning how to learn: the meta-meta-... hook},
  author={Schmidhuber, J{\"u}rgen},
  year={1987},
  school={Technische Universit{\"a}t M{\"u}nchen}
}

@article{schmidhuber2015deep,
  title={Deep learning in neural networks: An overview},
  author={Schmidhuber, J{\"u}rgen},
  journal={Neural networks},
  volume={61},
  pages={85--117},
  year={2015},
  publisher={Elsevier}
}



@article{li2006one,
  title={One-shot learning of object categories},
  author={Li, Fei-Fei and Fergus, Rob and Perona, Pietro},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={28},
  number={4},
  pages={594--611},
  year={2006},
  publisher={IEEE}
}

@article{fei2006one,
  title={One-shot learning of object categories},
  author={Fei-Fei, Li and Fergus, Rob and Perona, Pietro},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={28},
  number={4},
  pages={594--611},
  year={2006},
  publisher={IEEE}
}

@inproceedings{fe2003bayesian,
  title={A Bayesian approach to unsupervised one-shot learning of object categories},
  author={Fe-Fei, Li and others},
  booktitle={Proceedings Ninth IEEE International Conference on Computer Vision},
  pages={1134--1141},
  year={2003},
  organization={IEEE}
}

@phdthesis{tenenbaum1999bayesian,
  title={A Bayesian framework for concept learning},
  author={Tenenbaum, Joshua Brett},
  year={1999},
  school={Massachusetts Institute of Technology}
}

@article{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1703.03400},
  year={2017}
}

@inproceedings{lake2011one,
  title={One shot learning of simple visual concepts},
  author={Lake, Brenden and Salakhutdinov, Ruslan and Gross, Jason and Tenenbaum, Joshua},
  booktitle={Proceedings of the annual meeting of the cognitive science society},
  volume={33},
  number={33},
  year={2011}
}

@article{perez2017film,
  title={Film: Visual reasoning with a general conditioning layer},
  author={Perez, Ethan and Strub, Florian and De Vries, Harm and Dumoulin, Vincent and Courville, Aaron},
  journal={arXiv preprint arXiv:1709.07871},
  year={2017}
}

@article{hewitt2018variational,
  title={The variational homoencoder: Learning to learn high capacity generative models from few examples},
  author={Hewitt, Luke B and Nye, Maxwell I and Gane, Andreea and Jaakkola, Tommi and Tenenbaum, Joshua B},
  journal={arXiv preprint arXiv:1807.08919},
  year={2018}
}

@inproceedings{thrun1996learning,
  title={Is learning the n-th thing any easier than learning the first?},
  author={Thrun, Sebastian},
  booktitle={Advances in neural information processing systems},
  pages={640--646},
  year={1996}
}

@article{giannone2019no,
  title={No Representation without Transformation},
  author={Giannone, Giorgio and Saremi, Saeed and Masci, Jonathan and Osendorfer, Christian},
  journal={arXiv preprint arXiv:1912.03845},
  year={2019}
}

@inproceedings{lee2019set,
  title={Set transformer: A framework for attention-based permutation-invariant neural networks},
  author={Lee, Juho and Lee, Yoonho and Kim, Jungtaek and Kosiorek, Adam and Choi, Seungjin and Teh, Yee Whye},
  booktitle={International Conference on Machine Learning},
  pages={3744--3753},
  year={2019},
  organization={PMLR}
}

@inproceedings{qi2017pointnet,
  title={Pointnet: Deep learning on point sets for 3d classification and segmentation},
  author={Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={652--660},
  year={2017}
}

@article{qi2017pointnet++,
  title={Pointnet++: Deep hierarchical feature learning on point sets in a metric space},
  author={Qi, Charles R and Yi, Li and Su, Hao and Guibas, Leonidas J},
  journal={arXiv preprint arXiv:1706.02413},
  year={2017}
}

@article{bloem2020probabilistic,
  title={Probabilistic symmetries and invariant neural networks},
  author={Bloem-Reddy, Benjamin and Teh, Yee Whye},
  journal={Journal of Machine Learning Research},
  volume={21},
  number={90},
  pages={1--61},
  year={2020},
  publisher={Journal of Machine Learning Research}
}

@inproceedings{bloem2018neural,
  title={Neural network models of exchangeable sequences},
  author={Bloem-Reddy, Benjamin and Teh, Yee Whye},
  booktitle={NeurIPS Workshop on Bayesian Deep Learning},
  year={2018}
}

@article{korshunova2018bruno,
  title={Bruno: A deep recurrent model for exchangeable data},
  author={Korshunova, Iryna and Degrave, Jonas and Husz{\'a}r, Ferenc and Gal, Yarin and Gretton, Arthur and Dambre, Joni},
  journal={arXiv preprint arXiv:1802.07535},
  year={2018}
}

@incollection{de20209,
  title={9. On the Condition of Partial Exchangeability},
  author={De Finetti, Bruno},
  booktitle={Studies in Inductive Logic and Probability Volume 2},
  pages={193--206},
  year={2020},
  publisher={University of California Press}
}

@misc{mulitdigitmnist,
  author = {Sun, Shao-Hua},
  title = {Multi-digit MNIST for Few-shot Learning},
  year = {2019},
  journal = {GitHub repository},
  url = {https://github.com/shaohua0116/MultiDigitMNIST},
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}



@article{hospedales2020meta,
  title={Meta-learning in neural networks: A survey},
  author={Hospedales, Timothy and Antoniou, Antreas and Micaelli, Paul and Storkey, Amos},
  journal={arXiv preprint arXiv:2004.05439},
  year={2020}
}

@article{lake2017building,
  title={Building machines that learn and think like people},
  author={Lake, Brenden M and Ullman, Tomer D and Tenenbaum, Joshua B and Gershman, Samuel J},
  journal={Behavioral and brain sciences},
  volume={40},
  year={2017},
  publisher={Cambridge University Press}
}

@article{ullman2020bayesian,
  title={Bayesian models of conceptual development: Learning as building models of the world},
  author={Ullman, Tomer D and Tenenbaum, Joshua B},
  journal={Annual Review of Developmental Psychology},
  volume={2},
  pages={533--558},
  year={2020},
  publisher={Annual Reviews}
}

@article{tenenbaum2011grow,
  title={How to grow a mind: Statistics, structure, and abstraction},
  author={Tenenbaum, Joshua B and Kemp, Charles and Griffiths, Thomas L and Goodman, Noah D},
  journal={science},
  volume={331},
  number={6022},
  pages={1279--1285},
  year={2011},
  publisher={American Association for the Advancement of Science}
}


@inproceedings{vahdat2020NVAE,
  title={{NVAE}: A Deep Hierarchical Variational Autoencoder},
  author={Vahdat, Arash and Kautz, Jan},
  booktitle={Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{child2020very,
  title={Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images},
  author={Child, Rewon},
  journal={arXiv preprint arXiv:2011.10650},
  year={2020}
}

@inproceedings{kim2021setvae,
  title={SetVAE: Learning Hierarchical Composition for Generative Modeling of Set-Structured Data},
  author={Kim, Jinwoo and Yoo, Jaehoon and Lee, Juho and Hong, Seunghoon},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15059--15068},
  year={2021}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10012--10022},
  year={2021}
}

@article{song2020denoising,
  title={Denoising diffusion implicit models},
  author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  journal={arXiv preprint arXiv:2010.02502},
  year={2020}
}

@inproceedings{nichol2021improved,
  title={Improved denoising diffusion probabilistic models},
  author={Nichol, Alexander Quinn and Dhariwal, Prafulla},
  booktitle={International Conference on Machine Learning},
  pages={8162--8171},
  year={2021},
  organization={PMLR}
}

@article{choi2021ilvr,
  title={Ilvr: Conditioning method for denoising diffusion probabilistic models},
  author={Choi, Jooyoung and Kim, Sungwon and Jeong, Yonghyun and Gwon, Youngjune and Yoon, Sungroh},
  journal={arXiv preprint arXiv:2108.02938},
  year={2021}
}

@article{watson2021learning,
  title={Learning to efficiently sample from diffusion probabilistic models},
  author={Watson, Daniel and Ho, Jonathan and Norouzi, Mohammad and Chan, William},
  journal={arXiv preprint arXiv:2106.03802},
  year={2021}
}


@inproceedings{rasul2021autoregressive,
  title={Autoregressive denoising diffusion models for multivariate probabilistic time series forecasting},
  author={Rasul, Kashif and Seward, Calvin and Schuster, Ingmar and Vollgraf, Roland},
  booktitle={International Conference on Machine Learning},
  pages={8857--8868},
  year={2021},
  organization={PMLR}
}

@article{austin2021structured,
  title={Structured denoising diffusion models in discrete state-spaces},
  author={Austin, Jacob and Johnson, Daniel and Ho, Jonathan and Tarlow, Daniel and van den Berg, Rianne},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{song2020improved,
  title={Improved techniques for training score-based generative models},
  author={Song, Yang and Ermon, Stefano},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12438--12448},
  year={2020}
}

@article{durkan2021maximum,
  title={On maximum likelihood training of score-based generative models},
  author={Durkan, Conor and Song, Yang},
  journal={arXiv e-prints},
  pages={arXiv--2101},
  year={2021}
}

@article{huang2021variational,
  title={A variational perspective on diffusion-based generative models and score matching},
  author={Huang, Chin-Wei and Lim, Jae Hyun and Courville, Aaron C},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{vahdat2021score,
  title={Score-based generative modeling in latent space},
  author={Vahdat, Arash and Kreis, Karsten and Kautz, Jan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{sheynin2021hierarchical,
  title={A hierarchical transformation-discriminating generative model for few shot anomaly detection},
  author={Sheynin, Shelly and Benaim, Sagie and Wolf, Lior},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={8495--8504},
  year={2021}
}

@article{sinha2021d2c,
  title={D2C: Diffusion-Decoding Models for Few-Shot Conditional Generation},
  author={Sinha, Abhishek and Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}


@article{nichol2021glide,
  title={Glide: Towards photorealistic image generation and editing with text-guided diffusion models},
  author={Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
  journal={arXiv preprint arXiv:2112.10741},
  year={2021}
}

@article{dhariwal2021diffusion,
  title={Diffusion models beat gans on image synthesis},
  author={Dhariwal, Prafulla and Nichol, Alexander},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{song2020score,
  title={Score-based generative modeling through stochastic differential equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  journal={arXiv preprint arXiv:2011.13456},
  year={2020}
}


@article{rombach2021high,
  title={High-Resolution Image Synthesis with Latent Diffusion Models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  journal={arXiv preprint arXiv:2112.10752},
  year={2021}
}

@inproceedings{sheynin2021hierarchical,
  title={A hierarchical transformation-discriminating generative model for few shot anomaly detection},
  author={Sheynin, Shelly and Benaim, Sagie and Wolf, Lior},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={8495--8504},
  year={2021}
}

@article{giannone2021hierarchical,
  title={Hierarchical Few-Shot Generative Models},
  author={Giannone, Giorgio and Winther, Ole},
  journal={arXiv preprint arXiv:2110.12279},
  year={2021}
}

@inproceedings{giannone2022scha,
  title={SCHA-VAE: Hierarchical Context Aggregation for Few-Shot Generation},
  author={Giannone, Giorgio and Winther, Ole},
  booktitle={International Conference on Machine Learning},
  pages={7550--7569},
  year={2022},
  organization={PMLR}
}

@article{ho2022cascaded,
  title={Cascaded diffusion models for high fidelity image generation},
  author={Ho, Jonathan and Saharia, Chitwan and Chan, William and Fleet, David J and Norouzi, Mohammad and Salimans, Tim},
  journal={Journal of Machine Learning Research},
  volume={23},
  number={47},
  pages={1--33},
  year={2022}
}

@article{pandey2022diffusevae,
  title={DiffuseVAE: Efficient, Controllable and High-Fidelity Generation from Low-Dimensional Latents},
  author={Pandey, Kushagra and Mukherjee, Avideep and Rai, Piyush and Kumar, Abhishek},
  journal={arXiv preprint arXiv:2201.00308},
  year={2022}
}

@article{kingma2021variational,
  title={Variational diffusion models},
  author={Kingma, Diederik P and Salimans, Tim and Poole, Ben and Ho, Jonathan},
  journal={arXiv preprint arXiv:2107.00630},
  year={2021}
}

@article{kingma2021density,
  title={On Density Estimation with Diffusion Models},
  author={Kingma, Diederik and Salimans, Tim and Poole, Ben and Ho, Jonathan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{luo2021diffusion,
  title={Diffusion probabilistic models for 3d point cloud generation},
  author={Luo, Shitong and Hu, Wei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2837--2845},
  year={2021}
}

@article{lee2021vision,
  title={Vision Transformer for Small-Size Datasets},
  author={Lee, Seung Hoon and Lee, Seunghyun and Song, Byung Cheol},
  journal={arXiv preprint arXiv:2112.13492},
  year={2021}
}

@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}

@article{van2017neural,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{razavi2019generating,
  title={Generating diverse high-fidelity images with vq-vae-2},
  author={Razavi, Ali and Van den Oord, Aaron and Vinyals, Oriol},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{ashual2022knn,
  title={KNN-Diffusion: Image Generation via Large-Scale Retrieval},
  author={Ashual, Oron and Sheynin, Shelly and Polyak, Adam and Singer, Uriel and Gafni, Oran and Nachmani, Eliya and Taigman, Yaniv},
  journal={arXiv preprint arXiv:2204.02849},
  year={2022}
}

@article{blattmann2022retrieval,
  title={Retrieval-Augmented Diffusion Models},
  author={Blattmann, Andreas and Rombach, Robin and Oktay, Kaan and Ommer, Bj{\"o}rn},
  journal={arXiv preprint arXiv:2204.11824},
  year={2022}
}

@article{lee2021priorgrad,
  title={Priorgrad: Improving conditional denoising diffusion models with data-driven adaptive prior},
  author={Lee, Sang-gil and Kim, Heeseung and Shin, Chaehun and Tan, Xu and Liu, Chang and Meng, Qi and Qin, Tao and Chen, Wei and Yoon, Sungroh and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:2106.06406},
  year={2021}
}

@article{casanova2021instance,
  title={Instance-conditioned gan},
  author={Casanova, Arantxa and Careil, Marl{\`e}ne and Verbeek, Jakob and Drozdzal, Michal and Romero Soriano, Adriana},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{sehwag2022generating,
  title={Generating High Fidelity Data from Low-density Regions using Diffusion Models},
  author={Sehwag, Vikash and Hazirbas, Caner and Gordo, Albert and Ozgenel, Firat and Ferrer, Cristian Canton},
  journal={arXiv preprint arXiv:2203.17260},
  year={2022}
}


@article{bao2022analytic,
  title={Analytic-dpm: an analytic estimate of the optimal reverse variance in diffusion probabilistic models},
  author={Bao, Fan and Li, Chongxuan and Zhu, Jun and Zhang, Bo},
  journal={arXiv preprint arXiv:2201.06503},
  year={2022}
}



@article{ho2022video,
  title={Video Diffusion Models},
  author={Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J},
  journal={arXiv preprint arXiv:2204.03458},
  year={2022}
}


@article{salimans2022progressive,
  title={Progressive distillation for fast sampling of diffusion models},
  author={Salimans, Tim and Ho, Jonathan},
  journal={arXiv preprint arXiv:2202.00512},
  year={2022}
}



@article{hoogeboom2021argmax,
  title={Argmax flows and multinomial diffusion: Learning categorical distributions},
  author={Hoogeboom, Emiel and Nielsen, Didrik and Jaini, Priyank and Forr{\'e}, Patrick and Welling, Max},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{hoogeboom2022equivariant,
  title={Equivariant Diffusion for Molecule Generation in 3D},
  author={Hoogeboom, Emiel and Satorras, Victor Garcia and Vignac, Cl{\'e}ment and Welling, Max},
  journal={arXiv preprint arXiv:2203.17003},
  year={2022}
}

@article{xie2021crystal,
  title={Crystal Diffusion Variational Autoencoder for Periodic Material Generation},
  author={Xie, Tian and Fu, Xiang and Ganea, Octavian-Eugen and Barzilay, Regina and Jaakkola, Tommi},
  journal={arXiv preprint arXiv:2110.06197},
  year={2021}
}

@article{xu2022geodiff,
  title={Geodiff: A geometric diffusion model for molecular conformation generation},
  author={Xu, Minkai and Yu, Lantao and Song, Yang and Shi, Chence and Ermon, Stefano and Tang, Jian},
  journal={arXiv preprint arXiv:2203.02923},
  year={2022}
}

@article{jing2022subspace,
  title={Subspace Diffusion Generative Models},
  author={Jing, Bowen and Corso, Gabriele and Berlinghieri, Renato and Jaakkola, Tommi},
  journal={arXiv preprint arXiv:2205.01490},
  year={2022}
}


@article{kong2020diffwave,
  title={Diffwave: A versatile diffusion model for audio synthesis},
  author={Kong, Zhifeng and Ping, Wei and Huang, Jiaji and Zhao, Kexin and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:2009.09761},
  year={2020}
}


@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}

@inproceedings{caron2021emerging,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9650--9660},
  year={2021}
}

@article{he2021masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  journal={arXiv preprint arXiv:2111.06377},
  year={2021}
}

@article{bao2021beit,
  title={Beit: Bert pre-training of image transformers},
  author={Bao, Hangbo and Dong, Li and Wei, Furu},
  journal={arXiv preprint arXiv:2106.08254},
  year={2021}
}

@article{hassani2021escaping,
  title={Escaping the big data paradigm with compact transformers},
  author={Hassani, Ali and Walton, Steven and Shah, Nikhil and Abuduweili, Abulikemu and Li, Jiachen and Shi, Humphrey},
  journal={arXiv preprint arXiv:2104.05704},
  year={2021}
}

@inproceedings{touvron2021training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={International Conference on Machine Learning},
  pages={10347--10357},
  year={2021},
  organization={PMLR}
}

@article{zhou2021deepvit,
  title={Deepvit: Towards deeper vision transformer},
  author={Zhou, Daquan and Kang, Bingyi and Jin, Xiaojie and Yang, Linjie and Lian, Xiaochen and Jiang, Zihang and Hou, Qibin and Feng, Jiashi},
  journal={arXiv preprint arXiv:2103.11886},
  year={2021}
}

@article{liu2021efficient,
  title={Efficient Training of Visual Transformers with Small Datasets},
  author={Liu, Yahui and Sangineto, Enver and Bi, Wei and Sebe, Nicu and Lepri, Bruno and Nadai, Marco},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{baranchuk2021label,
  title={Label-Efficient Semantic Segmentation with Diffusion Models},
  author={Baranchuk, Dmitry and Rubachev, Ivan and Voynov, Andrey and Khrulkov, Valentin and Babenko, Artem},
  journal={arXiv preprint arXiv:2112.03126},
  year={2021}
}

@inproceedings{sohl2015deep,
  title={Deep unsupervised learning using nonequilibrium thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle={International Conference on Machine Learning},
  pages={2256--2265},
  year={2015},
  organization={PMLR}
}

@article{dinh2016density,
  title={Density estimation using real nvp},
  author={Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
  journal={arXiv preprint arXiv:1605.08803},
  year={2016}
}

@article{papamakarios2021normalizing,
  title={Normalizing flows for probabilistic modeling and inference},
  author={Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={57},
  pages={1--64},
  year={2021}
}



@article{kingma2019introduction,
  title={An introduction to variational autoencoders},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1906.02691},
  year={2019}
}

@article{child2019generating,
  title={Generating long sequences with sparse transformers},
  author={Child, Rewon and Gray, Scott and Radford, Alec and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1904.10509},
  year={2019}
}

@inproceedings{arjovsky2017wasserstein,
  title={Wasserstein generative adversarial networks},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  booktitle={International conference on machine learning},
  pages={214--223},
  year={2017},
  organization={PMLR}
}


@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={International Conference on Medical image computing and computer-assisted intervention},
  pages={234--241},
  year={2015},
  organization={Springer}
}

@article{liu2018large,
  title={Large-scale celebfaces attributes (celeba) dataset},
  author={Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
  journal={Retrieved August},
  volume={15},
  number={2018},
  pages={11},
  year={2018}
}

@article{heusel2017gans,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{kynkaanniemi2019improved,
  title={Improved precision and recall metric for assessing generative models},
  author={Kynk{\"a}{\"a}nniemi, Tuomas and Karras, Tero and Laine, Samuli and Lehtinen, Jaakko and Aila, Timo},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{nash2021generating,
  title={Generating images with sparse representations},
  author={Nash, Charlie and Menick, Jacob and Dieleman, Sander and Battaglia, Peter W},
  journal={arXiv preprint arXiv:2103.03841},
  year={2021}
}


@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{kim2021diffusionclip,
  title={Diffusionclip: Text-guided image manipulation using diffusion models},
  author={Kim, Gwanghyun and Ye, Jong Chul},
  journal={arXiv preprint arXiv:2110.02711},
  year={2021}
}


@article{kong2021fast,
  title={On fast sampling of diffusion probabilistic models},
  author={Kong, Zhifeng and Ping, Wei},
  journal={arXiv preprint arXiv:2106.00132},
  year={2021}
}

@article{jolicoeur2021gotta,
  title={Gotta go fast when generating data with score-based models},
  author={Jolicoeur-Martineau, Alexia and Li, Ke and Pich{\'e}-Taillefer, R{\'e}mi and Kachman, Tal and Mitliagkas, Ioannis},
  journal={arXiv preprint arXiv:2105.14080},
  year={2021}
}


@article{preechakul2021diffusion,
  title={Diffusion Autoencoders: Toward a Meaningful and Decodable Representation},
  author={Preechakul, Konpat and Chatthee, Nattanat and Wizadwongsa, Suttisak and Suwajanakorn, Supasorn},
  journal={arXiv preprint arXiv:2111.15640},
  year={2021}
}


@article{choi2022perception,
  title={Perception Prioritized Training of Diffusion Models},
  author={Choi, Jooyoung and Lee, Jungbeom and Shin, Chaehun and Kim, Sungwon and Kim, Hyunwoo and Yoon, Sungroh},
  journal={arXiv preprint arXiv:2204.00227},
  year={2022}
}

@inproceedings{shyam2017attentive,
  title={Attentive recurrent comparators},
  author={Shyam, Pranav and Gupta, Shubham and Dukkipati, Ambedkar},
  booktitle={International Conference on Machine Learning},
  pages={3173--3181},
  year={2017},
  organization={PMLR}
}

@article{gordon2019convolutional,
  title={Convolutional conditional neural processes},
  author={Gordon, Jonathan and Bruinsma, Wessel P and Foong, Andrew YK and Requeima, James and Dubois, Yann and Turner, Richard E},
  journal={arXiv preprint arXiv:1910.13556},
  year={2019}
}

@article{requeima2019fast,
  title={Fast and flexible multi-task classification using conditional neural adaptive processes},
  author={Requeima, James and Gordon, Jonathan and Bronskill, John and Nowozin, Sebastian and Turner, Richard E},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{harvey2022flexible,
  title={Flexible Diffusion Modeling of Long Videos},
  author={Harvey, William and Naderiparizi, Saeid and Masrani, Vaden and Weilbach, Christian and Wood, Frank},
  journal={arXiv preprint arXiv:2205.11495},
  year={2022}
}

@article{saharia2022photorealistic,
  title={Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily and Ghasemipour, Seyed Kamyar Seyed and Ayan, Burcu Karagol and Mahdavi, S Sara and Lopes, Rapha Gontijo and others},
  journal={arXiv preprint arXiv:2205.11487},
  year={2022}
}

@article{ho2022classifier,
  title={Classifier-free diffusion guidance},
  author={Ho, Jonathan and Salimans, Tim},
  journal={arXiv preprint arXiv:2207.12598},
  year={2022}
}

@article{griffiths2003hierarchical,
  title={Hierarchical topic models and the nested Chinese restaurant process},
  author={Griffiths, Thomas and Jordan, Michael and Tenenbaum, Joshua and Blei, David},
  journal={Advances in neural information processing systems},
  volume={16},
  year={2003}
}

@article{blei2003latent,
  title={Latent dirichlet allocation},
  author={Blei, David M and Ng, Andrew Y and Jordan, Michael I},
  journal={Journal of machine Learning research},
  volume={3},
  number={Jan},
  pages={993--1022},
  year={2003}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

@article{sigmund200199,
  title={A 99 line topology optimization code written in Matlab},
  author={Sigmund, Ole},
  journal={Structural and multidisciplinary optimization},
  volume={21},
  pages={120--127},
  year={2001},
  publisher={Springer}
}

@article{sigmund2013topology,
  title={Topology optimization approaches: A comparative review},
  author={Sigmund, Ole and Maute, Kurt},
  journal={Structural and Multidisciplinary Optimization},
  volume={48},
  number={6},
  pages={1031--1055},
  year={2013},
  publisher={Springer}
}

@book{bendsoe2003topology,
  title={Topology optimization: theory, methods, and applications},
  author={Bendsoe, Martin Philip and Sigmund, Ole},
  year={2003},
  publisher={Springer Science \& Business Media}
}

@article{yan2022deep,
  title={Deep learning driven real time topology optimisation based on initial stress learning},
  author={Yan, Jun and Zhang, Qi and Xu, Qi and Fan, Zhirui and Li, Haijiang and Sun, Wei and Wang, Guangyuan},
  journal={Advanced Engineering Informatics},
  volume={51},
  pages={101472},
  year={2022},
  publisher={Elsevier}
}


@article{maze2022topodiff,
  title={TopoDiff: A Performance and Constraint-Guided Diffusion Model for Topology Optimization},
  author={Maze, Francois and Ahmed, Faez},
  journal={arXiv preprint arXiv:2208.09591},
  year={2022}
}

@article{woldseth2022use,
  title={On the use of artificial neural networks in topology optimisation},
  author={Woldseth, Rebekka V and Aage, Niels and B{\ae}rentzen, J Andreas and Sigmund, Ole},
  journal={Structural and Multidisciplinary Optimization},
  volume={65},
  number={10},
  pages={294},
  year={2022},
  publisher={Springer}
}

@article{bendsoe1988generating,
  title={Generating optimal topologies in structural design using a homogenization method},
  author={Bends{\o}e, Martin Philip and Kikuchi, Noboru},
  journal={Computer methods in applied mechanics and engineering},
  volume={71},
  number={2},
  pages={197--224},
  year={1988},
  publisher={Elsevier}
}

@article{rozvany1992generalized,
  title={Generalized shape optimization without homogenization},
  author={Rozvany, George IN and Zhou, Ming and Birker, Torben},
  journal={Structural optimization},
  volume={4},
  pages={250--252},
  year={1992},
  publisher={Springer}
}

@article{bendsoe1989optimal,
  title={Optimal shape design as a material distribution problem},
  author={Bends{\o}e, Martin P},
  journal={Structural optimization},
  volume={1},
  pages={193--202},
  year={1989},
  publisher={Springer-Verlag}
}

@inproceedings{ahmed2016discovering,
  title={Discovering diverse, high quality design ideas from a large corpus},
  author={Ahmed, Faez and Fuge, Mark and Gorbunov, Lev D},
  booktitle={International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
  volume={50190},
  pages={V007T06A008},
  year={2016},
  organization={American Society of Mechanical Engineers}
}

@article{nobari2021pcdgan,
  title={Pcdgan: A continuous conditional diverse generative adversarial network for inverse design},
  author={Nobari, Amin Heyrani and Chen, Wei and Ahmed, Faez},
  journal={arXiv preprint arXiv:2106.03620},
  year={2021}
}

@article{regenwetter2022deep,
  title={Deep generative models in engineering design: A review},
  author={Regenwetter, Lyle and Nobari, Amin Heyrani and Ahmed, Faez},
  journal={Journal of Mechanical Design},
  volume={144},
  number={7},
  pages={071704},
  year={2022},
  publisher={American Society of Mechanical Engineers}
}

@article{nie2021topologygan,
  title={Topologygan: Topology optimization using generative adversarial networks based on physical fields over the initial domain},
  author={Nie, Zhenguo and Lin, Tong and Jiang, Haoliang and Kara, Levent Burak},
  journal={Journal of Mechanical Design},
  volume={143},
  number={3},
  year={2021},
  publisher={American Society of Mechanical Engineers Digital Collection}
}

@article{liu2014efficient,
  title={An efficient 3D topology optimization code written in Matlab},
  author={Liu, Kai and Tovar, Andr{\'e}s},
  journal={Structural and Multidisciplinary Optimization},
  volume={50},
  pages={1175--1196},
  year={2014},
  publisher={Springer}
}

@book{xie1997basic,
  title={Basic evolutionary structural optimization},
  author={Xie, Y Mike and Steven, Grant P and Xie, YM and Steven, GP},
  year={1997},
  publisher={Springer}
}

@article{allaire2002level,
  title={A level-set method for shape optimization},
  author={Allaire, Gr{\'e}goire and Jouve, Fran{\c{c}}ois and Toader, Anca-Maria},
  journal={Comptes Rendus Mathematique},
  volume={334},
  number={12},
  pages={1125--1130},
  year={2002},
  publisher={Elsevier}
}

@book{greenberg2015applications,
  title={Applications of Green's functions in science and engineering},
  author={Greenberg, Michael D},
  year={2015},
  publisher={Courier Dover Publications}
}

@book{duffy2015green,
  title={Green's functions with applications},
  author={Duffy, Dean G},
  year={2015},
  publisher={Chapman and Hall/CRC}
}

@book{barton1989elements,
  title={Elements of Green's functions and propagation: potentials, diffusion, and waves},
  author={Barton, Gy{\"o}rgy and Barton, Gabriel},
  year={1989},
  publisher={Oxford University Press}
}

@string{JAIR = {{J. Artif. Intell. Res.(JAIR)}}}

@string{AIJ = {{Artificial Intelligence}}}

@string{IEEE = {{Proc. of the IEEE}}}

@string{ECAI = {{Proc. of European Conference on Artificial Intelligence}}}

@string{IJCAI = {{Proc. of International Joint Conference on Artificial Intelligence (IJCAI)}}}

@string{KEPS = {{Proc. of the ICAPS Workshop on Knowledge Engineering for Planning and Scheduling(KEPS)}}}

@string{SPARK = {{Proc. of the ICAPS Workshop on Scheduling and Planning Applications (SPARK)}}}

@string{PRL = {{Proc. of the ICAPS Workshop on Bridging the Gap Between AI Planning and Reinforcement Learning (PRL)}}}

@string{ICAPS = {{Proc. of the International Conference on Automated Planning and Scheduling (ICAPS)}}}

@string{IPC = {{Proc. of the International Planning Competition}}}

@string{ECP = {{Proc. of European Conference on Planning}}}

@string{AIPS = {{Proc. of the International Conference on Artificial Intelligence Planning and Scheduling}}}

@string{SOCS = {{Proc. of Annual Symposium on Combinatorial Search}}}

@string{SARA = {{Proc. of Symposium on Abstraction, Reformulation, and Approximation}}}

@string{AAAI = {{Proc. of AAAI Conference on Artificial Intelligence}}}

@string{IAAI = {{Proc. of the Innovative Applications of Artificial Intelligence Conference}}}

@string{ICRA = {{Proc. of IEEE International Conference on Robotics and Automaton (ICRA)}}}

@string{IROS = {{Proc. of IEEE International Workshop on Intelligent Robots and Systems (IROS)}}}

@string{AAMAS = {{Proc. of the International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS)}}}

@string{UAI = {{Proc. of the International Conference on Uncertainty in Artificial Intelligence (UAI)}}}

@string{NIPS = {{Advances in Neural Information Processing Systems}}}

@string{ICML = {{Proc. of the International Conference on Machine Learning}}}

@string{ICLR = {{Proc. of the International Conference on Learning Representations}}}

@string{CVPR = {{Proc. of IEEE Conference on Computer Vision and Pattern Recognition}}}

@string{ICASSP = {{Proc. of IEEE Conference on Acoustics, Speech and Signal Processing}}}

@string{IJCCI = {{Proc. of International Joint Conference on Computational Intelligence (IJCCI)}}}

@string{ILP = {{Proc. of International Conference on Inductive Logic Programming ({ILP})}}}

@string{SIGMOD = {{Proc. of the International Conference on Management of Data (SIGMOD)}}}

@string{SIGKDD = {{Proc. of ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD)}}}

@string{ECCV = {{Proc. of the European Conference on Computer Vision (ECCV)}}}

@string{ICPR = {{Proc. of the International Conference on Pattern Recognition (ICPR)}}}

@string{TPAMI = {{IEEE Transactions on Pattern Analysis and Machine Intelligence}}}

@string{ACL = {{Proc. of the Annual Meeting of the Association for Computational Linguistics}}}

@string{COLING = {{Proc. of the International Conference on Computational Linguistics}}}

@string{COMPINT = {Computational Intelligence}}

@string{ECML = {{Proc. of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases}}}

@string{AMAI = {{Annals of Mathematics and Artificial Intelligence}}}

@string{AISTATS = {Proc. of the International Conference on Artificial Intelligence and Statistics (AISTATS)}}

@string{ICCV = {Proc. of the IEEE International Conference on Computer Vision}}


@article{Nie2021,
    author = {Nie, Zhenguo and Lin, Tong and Jiang, Haoliang and Kara, Levent Burak},
    title = "{TopologyGAN: Topology Optimization Using Generative Adversarial Networks Based on Physical Fields Over the Initial Domain}",
    journal = {Journal of Mechanical Design},
    volume = {143},
    number = {3},
    year = {2021},
    month = {02},
    abstract = "{In topology optimization using deep learning, the load and boundary conditions represented as vectors or sparse matrices often miss the opportunity to encode a rich view of the design problem, leading to less than ideal generalization results. We propose a new data-driven topology optimization model called TopologyGAN that takes advantage of various physical fields computed on the original, unoptimized material domain, as inputs to the generator of a conditional generative adversarial network (cGAN). Compared to a baseline cGAN, TopologyGAN achieves a nearly 3  reduction in the mean squared error and a 2.5  reduction in the mean absolute error on test problems involving previously unseen boundary conditions. Built on several existing network models, we also introduce a hybrid network called U-SE(Squeeze-and-Excitation)-ResNet for the generator that further increases the overall accuracy. We publicly share our full implementation and trained network.}",
    issn = {1050-0472},
    doi = {10.1115/1.4049533},
    url = {https://doi.org/10.1115/1.4049533},
    note = {031715},
    eprint = {https://asmedigitalcollection.asme.org/mechanicaldesign/article-pdf/143/3/031715/6633125/md\_143\_3\_031715.pdf},
}

@InProceedings{dickstein2015,
  title = 	 {Deep Unsupervised Learning using Nonequilibrium Thermodynamics},
  author = 	 {Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {2256--2265},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/sohl-dickstein15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/sohl-dickstein15.html},
  abstract = 	 {A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.}
}

@inproceedings{ho2020denoising,
 author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {6840--6851},
 publisher = {Curran Associates, Inc.},
 title = {Denoising Diffusion Probabilistic Models},
 url = {https://proceedings.neurips.cc/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf},
 volume = {33},
 year = {2020}
}

%NO BETTER BIBTEX
@article{sdesong,
  author    = {Yang Song and
               Jascha Sohl{-}Dickstein and
               Diederik P. Kingma and
               Abhishek Kumar and
               Stefano Ermon and
               Ben Poole},
  title     = {Score-Based Generative Modeling through Stochastic Differential Equations},
  journal   = {CoRR},
  volume    = {abs/2011.13456},
  year      = {2020},
  url       = {https://arxiv.org/abs/2011.13456},
  eprinttype = {arXiv},
  eprint    = {2011.13456},
  timestamp = {Wed, 02 Dec 2020 10:10:16 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-13456.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

%NO BETTER BIBTEX
@inproceedings{
ho2021classifierfree,
title={Classifier-Free Diffusion Guidance},
author={Jonathan Ho and Tim Salimans},
booktitle={NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications},
year={2021},
url={https://openreview.net/forum?id=qw8AKxfYbI}
}

@misc{Hunter2007william,
  author = {Hunter, William and others},
  title = {ToPy - Topology optimization with Python},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/williamhunter/topy}},
  }

  @article{huang2009bi,
  title={Bi-directional evolutionary topology optimization of continuum structures with one or multiple materials},
  author={Huang, Xiaodong and Xie, Yi Min},
  journal={Computational Mechanics},
  volume={43},
  number={3},
  pages={393--401},
  year={2009},
  publisher={Springer}
}

@software{solidspy,
 title = {SolidsPy: 2D-Finite Element Analysis with Python},
 version = {1.0.16},
 author = {Guarn-Zapata, Nicols and Gmez, Juan},
 year = 2020,
 keywords = {Python, Finite elements, Scientific computing, Computational mechanics},
 abstract = {SolidsPy is a simple finite element analysis code for
   2D elasticity problems. The code uses as input simple-to-create text
   files defining a model in terms of nodal, element, material and
   load data.},
 url = {https://github.com/AppliedMechanics-EAFIT/SolidsPy},
 doi = {http://doi.org/10.5281/zenodo.4029270}
}

@article{WANG2022115060,
title = {IH-GAN: A conditional generative model for implicit surface-based inverse design of cellular structures},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {396},
pages = {115060},
year = {2022},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2022.115060},
url = {https://www.sciencedirect.com/science/article/pii/S0045782522002699},
author = {Jun Wang and Wei (Wayne) Chen and Daicong Da and Mark Fuge and Rahul Rai},
keywords = {Inverse design, Cellular structure design, Homogenization, Generative adversarial network, Topology optimization},
abstract = {Variable-density cellular structures can overcome connectivity and manufacturability issues of topologically optimized structures, particularly those represented as discrete density maps. However, the optimization of such cellular structures is challenging due to the multiscale design problem. Past work addressing this problem generally either only optimizes the volume fraction of single-type unit cells but ignoring the effects of unit cell geometry on properties, or considers the geometryproperty relation but builds this relation via heuristics. In contrast, we propose a simple yet more principled way to accurately model the property to geometry mapping using a conditional deep generative model, named Inverse Homogenization Generative Adversarial Network (IH-GAN). It learns the conditional distribution of unit cell geometries given properties and can realize the one-to-many mapping from properties to geometries. We further reduce the complexity of IH-GAN by using the implicit function parameterization to represent unit cell geometries. Results show that our method can 1)generate various unit cells that satisfy given material properties with high accuracy (R2-scores between target properties and properties of generated unit cells >98%) and 2)improve the optimized structural performance over the conventional variable-density single-type structure. In the minimum compliance example, our IH-GAN generated structure achieves a 79.7% reduction in concentrated stress and an extra 3.03% reduction in displacement. In the target deformation examples, our IH-GAN generated structure reduces the target matching error by 86.4% and 79.6% for two test cases, respectively. We also demonstrated that the connectivity issue for multi-type unit cells can be solved by transition layer blending.}
}

@article{gantl,
    author = {Behzadi, Mohammad Mahdi and Ilie, Horea T.},
    title = "{GANTL: Toward Practical and Real-Time Topology Optimization With Conditional Generative Adversarial Networks and Transfer Learning}",
    journal = {Journal of Mechanical Design},
    volume = {144},
    number = {2},
    year = {2021},
    month = {12},
    abstract = "{A number of machine learning methods have been recently proposed to circumvent the high computational cost of the gradient-based topology optimization solvers. By and large, these methods show tight generalizability to unseen boundary and external loading conditions, require prohibitively large datasets for training, and do not take into consideration topological constraints of the predictions, which results in solutions with unpredictable connectivity. To address these limitations, we propose a design exploration framework for topology optimization that exploits the knowledge transfer capability of the transfer learning methods and the generative power of conditional generative adversarial networks (GANs). We show that the proposed framework significantly exceeds the generalization ability of current methods. Moreover, the proposed architecture is capable of reusing the knowledge learned on low-resolution and computationally inexpensive samples, which notably reduces both the size of the required high-resolution training datasets and the demand on the computational infrastructure needed to generate the training data. Finally, we propose and evaluate novel approaches to improve the structural connectivity of the predicted optimal topology by including topological metrics into the loss function. We show that by including the bottleneck distance between the persistence diagrams of the predicted and ground truth structures, we significantly improve the connectivity of the prediction. Together, our results reveal the ability of generative adversarial networks implemented in a transfer learning environment to serve as powerful and practical real-time design exploration tools in topology optimization.}",
    issn = {1050-0472},
    doi = {10.1115/1.4052757},
    url = {https://doi.org/10.1115/1.4052757},
    note = {021711},
    eprint = {https://asmedigitalcollection.asme.org/mechanicaldesign/article-pdf/144/2/021711/6806350/md\_144\_2\_021711.pdf},
}

@article{SIMP1988,
title = {Generating optimal topologies in structural design using a homogenization method},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {71},
number = {2},
pages = {197-224},
year = {1988},
issn = {0045-7825},
doi = {https://doi.org/10.1016/0045-7825(88)90086-2},
url = {https://www.sciencedirect.com/science/article/pii/0045782588900862},
author = {Martin Philip Bendse and Noboru Kikuchi},
abstract = {Optimal shape design of structural elements based on boundary variations results in final designs that are topologically equivalent to the initial choice of design, and general, stable computational schemes for this approach often require some kind of remeshing of the finite element approximation of the analysis problem. This paper presents a methodology for optimal shape design where both these drawbacks can be avoided. The method is related to modern production techniques and consists of computing the optimal distribution in space of an anisotropic material that is constructed by introducing an infimum of periodically distributed small holes in a given homogeneous, isotropic material, with the requirement that the resulting structure can carry the given loads as well as satisfy other design requirements. The computation of effective material properties for the anisotropic material is carried out using the method of homogenization. Computational results are presented and compared with results obtained by boundary variations.}
}

%NO BETTER BIBTEX
@article{SIMP1992,
  title={Generalized shape optimization without homogenization},
  author={G. I. N. Rozvany and M. Zhou and Torben Birker},
  journal={Structural optimization},
  year={1992},
  volume={4},
  pages={250-252}
}

%NO BETTER BIBTEX
@article{sigmund_review,
title = "Topology optimization approaches: A comparative review",
abstract = "Topology optimization has undergone a tremendous development since its introduction in the seminal paper by Bends{\o}e and Kikuchi in 1988. By now, the concept is developing in many different directions, including density, level set, topological derivative, phase field, evolutionary and several others. The paper gives an overview, comparison and critical review of the different approaches, their strengths, weaknesses, similarities and dissimilarities and suggests guidelines for future research.",
keywords = "Structural optimization, Topology optimization, Density methods, Level set methods, Phase field methods, Topological derivatives",
author = "Ole Sigmund and Kurt Maute",
year = "2013",
doi = "10.1007/s00158-013-0978-6",
language = "English",
volume = "48",
pages = "1031--1055",
journal = "Structural and Multidisciplinary Optimization",
issn = "1615-147X",
publisher = "Springer",
number = "6",
}

%NO BETTER BIBTEX
@article{99code_matlab,
author = {Sigmund, O.},
title = {A 99 Line Topology Optimization Code Written in Matlab},
year = {2001},
issue_date = {April     2001},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {2},
issn = {1615-147X},
url = {https://doi.org/10.1007/s001580050176},
doi = {10.1007/s001580050176},
abstract = {The paper presents a compact Matlab implementation of a topology optimization code for compliance minimization of statically loaded structures. The total number of Matlab input lines is 99 including optimizer and Finite Element subroutine. The 99 lines are divided into 36 lines for the main program, 12 lines for the Optimality Criteria based optimizer, 16 lines for a mesh-independency filter and 35 lines for the finite element code. In fact, excluding comment lines and lines associated with output and finite element analysis, it is shown that only 49 Matlab input lines are required for solving a well-posed topology optimization problem. By adding three additional lines, the program can solve problems with multiple load cases. The code is intended for educational purposes. The complete Matlab code is given in the Appendix and can be down-loaded from the web-site http://www.topopt.dtu.dk.},
journal = {Struct. Multidiscip. Optim.},
month = {apr},
pages = {120127},
numpages = {8},
keywords = {world-wide web, Key words: topology optimization, Matlab code, education, optimality criteria}
}

%NO BETTER BIBTEX
@article{computational_time_trad_TO,
title = "On reducing computational effort in topology optimization: how far can we go?",
abstract = "An approximate approach to solving the nested analysis equations in topology optimization is proposed. The procedure consists of only one matrix factorization for the whole design process and a small number of iterative corrections for each design cycle. The approach is tested on 3D topology optimization problems. It is shown that the computational cost can be reduced by one order of magnitude without affecting the outcome of the optimization process.",
keywords = "Approximations, Topology optimization, Nested approach",
author = "Oded Amir and Ole Sigmund",
year = "2011",
doi = "10.1007/s00158-010-0586-7",
language = "English",
volume = "44",
pages = "25--29",
journal = "Structural and Multidisciplinary Optimization",
issn = "1615-147X",
publisher = "Springer",
number = "1",
}

%NO BETTER BIBTEX
@Inproceedings{Guo2018,
  Title                    = {An Indirect Design Representation for Topology Optimization Using Variational Autoencoder and Style Transfer},
  Author                   = {Guo, Tinghao and Lohan, Danny J and Cang, Ruijin and Ren, Max Yi and Allison, James T},
  Booktitle                = {2018 AIAA/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference, AIAA SciTech Forum},
  Month                    = jan,
  Year                     = {2018},
  Number                   = {AIAA 2018-0804},
  Doi                      = {10.2514/6.2018-0804},
  Pdf                      = {http://systemdesign.illinois.edu/publications/Guo2018a.pdf},
  Esdlid                   = {C53},
}

@article{Lin2018,
title = {Investigation into the topology optimization for conductive heat transfer based on deep learning approach},
journal = {International Communications in Heat and Mass Transfer},
volume = {97},
pages = {103-109},
year = {2018},
issn = {0735-1933},
doi = {https://doi.org/10.1016/j.icheatmasstransfer.2018.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0735193318301593},
author = {Qiyin Lin and Jun Hong and Zheng Liu and Baotong Li and Jihong Wang},
keywords = {Conductive heat transfer, Deep learning, Topology optimization, SIMP},
abstract = {A deep learning approach combining with the traditional solid isotropic material with penalization (SIMP) method is presented in this paper to accelerate the topology optimization of the conductive heat transfer. This deep learning predictor is structured based on the deep fully convolutional neural network. The validity and accuracy of this deep learning approach is investigated based on the typical Volume-Point heat conduction problems. The time consumption of the optimization process will be reduced significantly by introducing the deep learning approach.}
}

%NO BETTER BIBTEX
@article{Sosnovik2019,
author = {Ivan Sosnovik and Ivan Oseledets},
doi = {doi:10.1515/rnam-2019-0018},
url = {https://doi.org/10.1515/rnam-2019-0018},
title = {Neural networks for topology optimization},
journal = {Russian Journal of Numerical Analysis and Mathematical Modelling},
number = {4},
volume = {34},
year = {2019},
pages = {215--223},
lastchecked = {2022-08-02}
}

@article{Yu2018,
	doi = {10.1007/s00158-018-2101-5},
	url = {https://doi.org/10.1007%2Fs00158-018-2101-5},
	year = 2018,
	month = {oct},
	publisher = {Springer Science and Business Media {LLC}
},
	volume = {59},
	number = {3},
	pages = {787--799},
	author = {Yonggyun Yu and Taeil Hur and Jaeho Jung and In Gwun Jang},
	title = {Deep learning for determining a near-optimal topological design without any iteration},
	journal = {Structural and Multidisciplinary Optimization}
}

@article{Rawat2019,
  author    = {Sharad Rawat and
               M.{-}H. Herman Shen},
  title     = {A Novel Topology Optimization Approach using Conditional Deep Learning},
  journal   = {CoRR},
  volume    = {abs/1901.04859},
  year      = {2019},
  url       = {http://arxiv.org/abs/1901.04859},
  eprinttype = {arXiv},
  eprint    = {1901.04859},
  timestamp = {Fri, 01 Feb 2019 13:39:59 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1901-04859.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Li2019,
title = {Non-iterative structural topology optimization using deep learning},
journal = {Computer-Aided Design},
volume = {115},
pages = {172-180},
year = {2019},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2019.05.038},
url = {https://www.sciencedirect.com/science/article/pii/S001044851930185X},
author = {Baotong Li and Congjia Huang and Xin Li and Shuai Zheng and Jun Hong},
keywords = {Topology optimization, Deep learning, Generative adversarial network, Hierarchical refinement, Heat conduction},
abstract = {This paper presents a non-iterative topology optimizer for conductive heat transfer structures with the help of deep learning. An artificial neural network is trained to deal with the black-and-white pixel images and generate near-optimal structures. Our design is a two-stage hierarchical predictionrefinement pipeline consisting of two coupled neural networks: a generative adversarial network (GAN) for predicting a low resolution near-optimal structure and a super-resolution generative adversarial network (SRGAN) for predicting the refined structure in high resolution. Training datasets with given boundary conditions and the optimized pixel image structures are obtained after simulating a big amount of topology optimization procedures. For more effective training and inference, these datasets are generated with two different resolutions. Experiments demonstrated that our learning based optimizer can provide accurate estimation of the conductive heat transfer topology using negligible computational time. This effective incorporation of deep learning into topology optimization could enable promising applications in large-scale engineering structure design.}
}

@article{10.1007/s00158-020-02748-4,
author = {Chandrasekhar, Aaditya and Suresh, Krishnan},
title = {TOuNN: Topology Optimization Using Neural Networks},
year = {2021},
issue_date = {Mar 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {63},
number = {3},
issn = {1615-147X},
url = {https://doi.org/10.1007/s00158-020-02748-4},
doi = {10.1007/s00158-020-02748-4},
abstract = {Neural networks, and more broadly, machine learning techniques, have been recently exploited to accelerate topology optimization through data-driven training and image processing. In this paper, we demonstrate that one can directly execute topology optimization (TO) using neural networks (NN). The primary concept is to use the NNs activation functions to represent the popular Solid Isotropic Material with Penalization (SIMP) density field. In other words, the density function is parameterized by the weights and bias associated with the NN, and spanned by NNs activation functions; the density representation is thus independent of the finite element mesh. Then, by relying on the NNs built-in backpropogation, and a conventional finite element solver, the density field is optimized. Methods to impose design and manufacturing constraints within the proposed framework are described and illustrated. A byproduct of representing the density field via activation functions is that it leads to a crisp and differentiable boundary. The proposed framework is simple to implement and is illustrated through 2D and 3D examples. Some of the unresolved challenges with the proposed framework are also summarized.},
journal = {Struct. Multidiscip. Optim.},
month = {mar},
pages = {11351149},
numpages = {15},
keywords = {Topology optimization, Neural networks, Machine learning}
}

@inproceedings{parrott2022multi,
  title={Multi-Head Self-Attention GANs for Multiphysics Topology Optimization},
  author={Parrott, Corey and Abueidda, Diab and James, Kai A},
  booktitle={AIAA AVIATION 2022 Forum},
  pages={3726},
  year={2022}
}

@article{Sharpe2019,
    author = {Sharpe, Conner and Seepersad, Carolyn Conner},
    title = "{Topology Design With Conditional Generative Adversarial Networks}",
    volume = {Volume 2A: 45th Design Automation Conference},
    series = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
    year = {2019},
    month = {08},
    abstract = "{Deep convolutional neural networks have gained significant traction as effective approaches for developing detailed but compact representations of complex structured data. Generative networks in particular have become popular for their ability to mimic data distributions and allow further exploration of them. This attribute can be utilized in engineering design domains, in which the data structures of finite element meshes for analyzing potential designs are well suited to the deep convolutional network approaches that are being developed at a rapid pace in the field of image processing. This paper explores the use of conditional generative adversarial networks (cGANs) as a means of generating a compact latent representation of structures resulting from classical topology optimization techniques. The constraints and contextual factors of a design problem, such as mass fraction, material type, and load location, can then be specified as input conditions to generate potential topologies in a directed fashion. The trained network can be used to aid concept generation, such that engineers can explore a variety of designs relevant to the problem at hand with ease. The latent variables of the generator can also be used as design parameters, and the low dimensionality enables tractable computational design without analytical sensitivities. This paper demonstrates these capabilities and discusses avenues for further developments that would enable the engineering design community to further leverage generative machine learning techniques to their full potential.}",
    doi = {10.1115/DETC2019-97833},
    url = {https://doi.org/10.1115/DETC2019-97833},
    note = {V02AT03A062},
    eprint = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-pdf/IDETC-CIE2019/59186/V02AT03A062/6453126/v02at03a062-detc2019-97833.pdf},
}

@article{Zhang2022,
author = {Dalei Wang and Cheng Xiang and Yue Pan and Airong Chen and Xiaoyi Zhou and Yiquan Zhang},
title = {A deep convolutional neural network for topology optimization with perceptible generalization ability},
journal = {Engineering Optimization},
volume = {54},
number = {6},
pages = {973-988},
year  = {2021},
publisher = {Taylor & Francis},
doi = {10.1080/0305215X.2021.1902998},
URL = { 
        https://doi.org/10.1080/0305215X.2021.1902998
},
eprint = { 
        https://doi.org/10.1080/0305215X.2021.1902998   
}
}

@article{PyTorch,
  author    = {Adam Paszke and
               Sam Gross and
               Francisco Massa and
               Adam Lerer and
               James Bradbury and
               Gregory Chanan and
               Trevor Killeen and
               Zeming Lin and
               Natalia Gimelshein and
               Luca Antiga and
               Alban Desmaison and
               Andreas K{\"{o}}pf and
               Edward Z. Yang and
               Zach DeVito and
               Martin Raison and
               Alykhan Tejani and
               Sasank Chilamkurthy and
               Benoit Steiner and
               Lu Fang and
               Junjie Bai and
               Soumith Chintala},
  title     = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  journal   = {CoRR},
  volume    = {abs/1912.01703},
  year      = {2019},
  url       = {http://arxiv.org/abs/1912.01703},
  eprinttype = {arXiv},
  eprint    = {1912.01703},
  timestamp = {Tue, 02 Nov 2021 15:18:32 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1912-01703.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{image_gen,
  author    = {Alexander Quinn Nichol and
               Prafulla Dhariwal},
  editor    = {Marina Meila and
               Tong Zhang},
  title     = {Improved Denoising Diffusion Probabilistic Models},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning,
               {ICML} 2021, 18-24 July 2021, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {139},
  pages     = {8162--8171},
  publisher = {{PMLR}},
  year      = {2021},
  url       = {http://proceedings.mlr.press/v139/nichol21a.html},
  timestamp = {Wed, 25 Aug 2021 17:11:17 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/NicholD21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@proceedings{hertlein2022,
    author = {Hertlein Nathan and Gillman Andrew and Buskohl Philip R.},
    title = "{Generative Adversarial Design Analysis of Non-Convexity in Topology Optimization}",
    volume = {Volume 3B: 48th Design Automation Conference (DAC)},
    series = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
    year = {2022},
    month = {08},
    abstract = "{Material penalization and filtering schemes are key strategies applied to topology optimization (TO) to promote more discrete and manufacturable designs. However, these modifications introduce fluctuations in the design landscape that amplify non-convexity and influence the local minima identified by TO. Harnessing the machine learning approach of generative adversarial networks (GAN), we investigate the role of penalization and filtering by comparing the designs between TO and GAN-based TO surrogates. A total of 17 GANs were constructed to predict 2D minimum compliance topologies across a set of penalization factors and filters, each interpolating a design space of 270,000 boundary condition and loading scenarios. The prevalence of GAN-predicted topologies with better compliance than TO-calculated topologies was estimated via a random sampling of the design space. GAN over-performance occurs across material penalization and filtering conditions, where the frequency tends to increase as penalization increases. Analysis of this test set is leveraged to highlight trends regarding the conditions under which this over-performance occurs, and the geometric characteristics these designs exhibit. Collectively, this study presents an alternative method to characterize the effects of penalization and filtering on design outcomes and motivates the use of data-driven surrogates to augment traditional approaches.}",
    doi = {10.1115/DETC2022-89997},
    url = {https://doi.org/10.1115/DETC2022-89997},
    note = {V03BT03A044},
    eprint = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-pdf/IDETC-CIE2022/86236/V03BT03A044/6943222/v03bt03a044-detc2022-89997.pdf},
}


@article{oh2019,
    author = {Oh, Sangeun and Jung, Yongsu and Kim, Seongsin and Lee, Ikjin and Kang, Namwoo},
    title = "{Deep Generative Design: Integration of Topology Optimization and Generative Models}",
    journal = {Journal of Mechanical Design},
    volume = {141},
    number = {11},
    year = {2019},
    month = {09},
    abstract = "{Deep learning has recently been applied to various research areas of design optimization. This study presents the need and effectiveness of adopting deep learning for generative design (or design exploration) research area. This work proposes an artificial intelligent (AI)-based deep generative design framework that is capable of generating numerous design options which are not only aesthetic but also optimized for engineering performance. The proposed framework integrates topology optimization and generative models (e.g., generative adversarial networks (GANs)) in an iterative manner to explore new design options, thus generating a large number of designs starting from limited previous design data. In addition, anomaly detection can evaluate the novelty of generated designs, thus helping designers choose among design options. The 2D wheel design problem is applied as a case study for validation of the proposed framework. The framework manifests better aesthetics, diversity, and robustness of generated designs than previous generative design methods.}",
    issn = {1050-0472},
    doi = {10.1115/1.4044229},
    note = {111405},
    eprint = {https://asmedigitalcollection.asme.org/mechanicaldesign/article-pdf/141/11/111405/6578473/md\_141\_11\_111405.pdf},
}

@inproceedings{text_to_image1,
  author    = {Alexander Quinn Nichol and
               Prafulla Dhariwal and
               Aditya Ramesh and
               Pranav Shyam and
               Pamela Mishkin and
               Bob McGrew and
               Ilya Sutskever and
               Mark Chen},
  editor    = {Kamalika Chaudhuri and
               Stefanie Jegelka and
               Le Song and
               Csaba Szepesv{\'{a}}ri and
               Gang Niu and
               Sivan Sabato},
  title     = {{GLIDE:} Towards Photorealistic Image Generation and Editing with
               Text-Guided Diffusion Models},
  booktitle = {International Conference on Machine Learning, {ICML} 2022, 17-23 July
               2022, Baltimore, Maryland, {USA}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {162},
  pages     = {16784--16804},
  publisher = {{PMLR}},
  year      = {2022},
  url       = {https://proceedings.mlr.press/v162/nichol22a.html},
  timestamp = {Tue, 12 Jul 2022 17:36:52 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/NicholDRSMMSC22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{text_to_image2,
  author    = {Gwanghyun Kim and
               Jong Chul Ye},
  title     = {DiffusionCLIP: Text-guided Image Manipulation Using Diffusion Models},
  journal   = {CoRR},
  volume    = {abs/2110.02711},
  year      = {2021},
  url       = {https://arxiv.org/abs/2110.02711},
  eprinttype = {arXiv},
  eprint    = {2110.02711},
  timestamp = {Thu, 21 Oct 2021 16:20:08 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2110-02711.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{image_segmentation,
  author    = {Tomer Amit and
               Eliya Nachmani and
               Tal Shaharabany and
               Lior Wolf},
  title     = {SegDiff: Image Segmentation with Diffusion Probabilistic Models},
  journal   = {CoRR},
  volume    = {abs/2112.00390},
  year      = {2021},
  url       = {https://arxiv.org/abs/2112.00390},
  eprinttype = {arXiv},
  eprint    = {2112.00390},
  timestamp = {Tue, 07 Dec 2021 12:15:54 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2112-00390.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{image_editing,
  author    = {Chenlin Meng and
               Yang Song and
               Jiaming Song and
               Jiajun Wu and
               Jun{-}Yan Zhu and
               Stefano Ermon},
  title     = {SDEdit: Image Synthesis and Editing with Stochastic Differential Equations},
  journal   = {CoRR},
  volume    = {abs/2108.01073},
  year      = {2021},
  url       = {https://arxiv.org/abs/2108.01073},
  eprinttype = {arXiv},
  eprint    = {2108.01073},
  timestamp = {Thu, 12 Aug 2021 17:50:35 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2108-01073.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ahmed2013constructive,
  title={Constructive solid geometry based topology optimization using evolutionary algorithm},
  author={Ahmed, Faez and Bhattacharya, Bishakh and Deb, Kalyanmoy},
  booktitle={Proceedings of seventh international conference on bio-inspired computing: theories and applications (BIC-TA 2012)},
  pages={227--238},
  year={2013},
  organization={Springer}
}

@inproceedings{speed_DM1,
author = {Ma, Hengyuan and Zhang, Li and Zhu, Xiatian and Feng, Jianfeng},
title = {Accelerating Score-Based Generative Models withPreconditioned Diffusion Sampling},
year = {2022},
isbn = {978-3-031-20049-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-20050-2_1},
doi = {10.1007/978-3-031-20050-2_1},
abstract = {Score-based generative models (SGMs) have recently emerged as a promising class of generative models. However, a fundamental limitation is that their inference is very slow due to a need for many (e.g., 2000) iterations of sequential computations. An intuitive acceleration method is to reduce the sampling iterations which however causes severe performance degradation. We investigate this problem by viewing the diffusion sampling process as a Metropolis adjusted Langevin algorithm, which helps reveal the underlying cause to be ill-conditioned curvature. Under this insight, we propose a model-agnostic preconditioned diffusion sampling (PDS) method that leverages matrix preconditioning to alleviate the aforementioned problem. Crucially, PDS is proven theoretically to converge to the original target distribution of a SGM, no need for retraining. Extensive experiments on three image datasets with a variety of resolutions and diversity validate that PDS consistently accelerates off-the-shelf SGMs whilst maintaining the synthesis quality. In particular, PDS can accelerate by up to 29\texttimes{} on more challenging high resolution (1024\texttimes{}1024) image generation.},
booktitle = {Computer Vision  ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 2327, 2022, Proceedings, Part XXIII},
pages = {116},
numpages = {16},
keywords = {Ill-conditioned curvature, Matrix preconditioning, Score-based generative model, Image synthesis},
location = {Tel Aviv, Israel}
}

@misc{speed_DM2,
  doi = {10.48550/ARXIV.2206.05173},
  
  url = {https://arxiv.org/abs/2206.05173},
  
  author = {Franzese, Giulio and Rossi, Simone and Yang, Lixuan and Finamore, Alessandro and Rossi, Dario and Filippone, Maurizio and Michiardi, Pietro},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {How Much is Enough? A Study on Diffusion Times in Score-based Generative Models},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{speed_DM3,
  doi = {10.48550/ARXIV.2206.04029},
  
  url = {https://arxiv.org/abs/2206.04029},
  
  author = {Ma, Hengyuan and Zhang, Li and Zhu, Xiatian and Zhang, Jingfeng and Feng, Jianfeng},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Accelerating Score-based Generative Models for High-Resolution Image Synthesis},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{speed_DM4,
  doi = {10.48550/ARXIV.2205.15463},
  
  url = {https://arxiv.org/abs/2205.15463},
  
  author = {Giannone, Giorgio and Nielsen, Didrik and Winther, Ole},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Few-Shot Diffusion Models},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{speed_DM5,
  doi = {10.48550/ARXIV.2205.12524},
  
  url = {https://arxiv.org/abs/2205.12524},
  
  author = {Lyu, Zhaoyang and XU, Xudong and Yang, Ceyuan and Lin, Dahua and Dai, Bo},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Accelerating Diffusion Models via Early Stop of the Diffusion Process},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@InProceedings{UNet,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}

@Article{         numpy,
 title         = {Array programming with {NumPy}},
 author        = {Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J.
                 van der Walt and Ralf Gommers and Pauli Virtanen and David
                 Cournapeau and Eric Wieser and Julian Taylor and Sebastian
                 Berg and Nathaniel J. Smith and Robert Kern and Matti Picus
                 and Stephan Hoyer and Marten H. van Kerkwijk and Matthew
                 Brett and Allan Haldane and Jaime Fern{\'{a}}ndez del
                 R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre
                 G{\'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and
                 Warren Weckesser and Hameer Abbasi and Christoph Gohlke and
                 Travis E. Oliphant},
 year          = {2020},
 month         = sep,
 journal       = {Nature},
 volume        = {585},
 number        = {7825},
 pages         = {357--362},
 doi           = {10.1038/s41586-020-2649-2},
 publisher     = {Springer Science and Business Media {LLC}},
 url           = {https://doi.org/10.1038/s41586-020-2649-2}
}

@Article{matplotlib,
  Author    = {Hunter, J. D.},
  Title     = {Matplotlib: A 2D graphics environment},
  Journal   = {Computing in Science \& Engineering},
  Volume    = {9},
  Number    = {3},
  Pages     = {90--95},
  abstract  = {Matplotlib is a 2D graphics package used for Python for
  application development, interactive scripting, and publication-quality
  image generation across user interfaces and operating systems.},
  publisher = {IEEE COMPUTER SOC},
  doi       = {10.1109/MCSE.2007.55},
  year      = 2007
}

@misc{tensorflow,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}



@inproceedings{pcdgan,
author = {Heyrani, Amin Nobari and Chen, Wei and Ahmed, Faez},
title = {{PcDGAN}: A Continuous Conditional Diverse Generative Adversarial Network For Inverse Design},
year = {2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
booktitle = {Proceedings of the 27th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining, {KDD-21}},
location = {Virtual Event},
series = {KDD '21}
}


@article{nobari2022range,
  title={Range-Constrained Generative Adversarial Network: Design Synthesis Under Constraints Using Conditional Generative Adversarial Networks},
  author={Nobari, Amin Heyrani and Chen, Wei and Ahmed, Faez},
  journal={Journal of Mechanical Design},
  volume={144},
  number={2},
  year={2022},
  publisher={American Society of Mechanical Engineers Digital Collection},
}

@article{regenwetter2022biked,
  title={{BIKED}: A Dataset for Computational Bicycle Design With Machine Learning Benchmarks},
  author={Regenwetter, Lyle and Curry, Brent and Ahmed, Faez},
  journal={Journal of Mechanical Design},
  volume={144},
  number={3},
  year={2022},
  publisher={American Society of Mechanical Engineers Digital Collection}
}

@article{10.1115/1.4053859,
    author = {Regenwetter, Lyle and Nobari, Amin Heyrani and Ahmed, Faez},
    title = {Deep Generative Models in Engineering Design: A Review},
    journal = {Journal of Mechanical Design},
    volume = {144},
    number = {7},
    year = {2022},
    month = {03},
    issn = {1050-0472},
    doi = {10.1115/1.4053859},
    url = {https://doi.org/10.1115/1.4053859},
    note = {071704},
    eprint = {https://asmedigitalcollection.asme.org/mechanicaldesign/article-pdf/144/7/071704/6866682/md\_144\_7\_071704.pdf},
}

% BibTeX database for the paper asme2e.tex
%% bibtexfile{
%% author    = 
"Harry H. Cheng",
%% version   =  "2",
%% date      =  "January  01,
2003",
%% filename  =  "asme2e.bib",
%% address   =  "Integration
Engineering Laboratory
%%              Department of Mechanical and
Aeronautical Engineering
%%              University of California
%%        
     Davis, CA 95616",
%% telephone =  "(530) 752-5020 (office)
%%          
    (530) 752-1028 (lab)
%%               (530) 752-4158 (Fax:)",
%% email  
  =  "<hhcheng at ucdavis.edu>" }

@article{art,
	author	=	"A. Author and
B. Author and C. Author",
	title	=	"Article title",
	journal =   "Journal
{N}ame",
	volume  =	1,
	number	=	5,
	pages   =   "1--3",
	month   =  
"May",
	year	=	1994}

@book{latex,
	author	  =	"L. Lamport",
	title	 
=	"\LaTeX: a Document Preparation System",
	publisher =
"Addison-Wesley",
	year	  =	1986,
	address   =	"Reading,
MA"}

@book{goosens,
	author	  =	"M. Goosens and F. Mittelbach and A.
Samarin",
	title	  =	"The \LaTeX\ Companion",
	publisher
=	"Addison-Wesley",
	address	  =	"Reading, MA",
	year	 
=	1994}

@booklet{blt,
	author	=	"A. Booklet",
	title	=	"Booklet
title",
	howpublished =   "On the WWW",
	address =	"at
\verb+http://www.abc.edu+",
	note	=	"PDF file",
	month   =  
"May",
	year	=	1994}

@inbook{ibk,
	editor    =	"A. Inbook",
	title	 
=	"Book title",
	chapter   = 1,
	pages     = "1--3",
	volume 
=	2,
	series	=	"{Series Title}",
	edition = "$1^{st}$",
	type    =
"{Chap.}",
	publisher =	"Publisher {N}ame",
	address   =	"Publisher
address",
	note      = "See also URL \verb+http://www.abc.edu+",
	year	 
=	1991}

@incollection{icn,
	author    =	"A. Incollection",
	title	 
=	"Article title",
	editor    =	"A. Editor",
	booktitle =	"Collection
{T}itle",
	chapter   = 1,
	pages     = "1--3",
	volume 
=	2,
	series	=	"Series title",
	month   =   "May",
	edition =
"$3^{rd}$",
	type    = "{C}hapter",
	publisher =	"Publisher
{N}ame",
	address   =	"Publisher address",
	note      = "See also URL
\verb+http://www.abc.edu+",
	year	  =	1991}

@inproceedings{ips,
	author   
=	"A. Inproceedings",
	title	  =	"Article title",
	editor    =	"A. Editor
and B. Editor",
	booktitle =	"Proceedings {T}itle",
	volume  =	"{\bf
1}",
	series	=	"Series name",
	pages     = "1--3",
	address   =	"Publisher
address",
	month   =   "May",
	organization =	"Organization
{N}ame",
	publisher =	"Publisher {N}ame",
	note      = "Paper number
1234",
	year	  =	1991}

@manual{asmemanual,
	author    =	"{ASME}",
	title	 
=	"{ASME} Manual {MS-4}, An {ASME} Paper",
	organization =	"The American
Society of Mechanical Engineers",
	edition  = "latest",
	address   =	"New
York",
	note      = "See also URL
\verb+http://www.asme.org/pubs/MS4.html+",
	year	 
=	2003}

@mastersthesis{mts,
     author = "A. Mastersthesis",
     title =
"{Thesis Title}",
     school = "University of Higher Education",
     year
= 2003,
     type = "{MS Thesis}",
     address = "Cambridge, {MA}",
    
month = "May",
     note = "See also URL
\verb+http://www.abc.edu+"}

@misc{mis,
     author = "A. Misc",
     title 
= "Miscellaneous {T}itle",
     howpublished = "On the WWW",
     month =
"May",
     year = "2003",
     note = "URL
\verb+http://www.abc.edu+"}

@phdthesis{pts,
     author = "A. Phdthesis",
 
   title = "{Thesis Title}",
     school = "University of Higher
Education",
     year = 2003,
     type = "{PhD Thesis}",
     address =
"Cambridge, {MA}",
     month = "May",
     note = "See also URL
\verb+http://www.abc.edu+"}

@inproceedings{pro,
	title	  =	"Volume
{T}itle",
	year	  =	1991,
	editor    =	"A. Proceedings",
	volume   
=	1,
	series	  =	"Proceedings {S}eries",
	address   =	"Publisher
address",
	month   =   "May",
	organization =	"Organization
{N}ame",
	publisher =	"Publisher {N}ame",
	note      = "See also URL
\verb+http://www.abc.edu+"}

@techreport{trt,
     author = "A.
Techreport",
     title = "{Techreport title}",
     institution =
"University of Higher Education",
     year = "2003",
     type = "Progress
report",
     number = "1",
     address = "Cambridge, {MA}",
     month =
"May",
     note = "See also URL
\verb+http://www.abc.edu+"}

@unpublished{upd,
     author = "A.
Unpublished",
     title = "{Unpublished document title}",
     note = "See
also URL \verb+http://www.abc.edu+",
     month = "May",
     year = 2003}




@article{gao2019sdm,
  title={SDM-NET: Deep generative network for structured deformable mesh},
  author={Gao, Lin and Yang, Jie and Wu, Tong and Yuan, Yu-Jie and Fu, Hongbo and Lai, Yu-Kun and Zhang, Hao},
  journal={ACM Transactions on Graphics (TOG)},
  volume={38},
  number={6},
  pages={1--15},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@article{mo2019structurenet,
  title={StructureNet: hierarchical graph networks for 3D shape generation},
  author={Mo, Kaichun and Guerrero, Paul and Yi, Li and Su, Hao and Wonka, Peter and Mitra, Niloy J and Guibas, Leonidas J},
  journal={ACM Transactions on Graphics},
  volume={38},
  number={6},
  pages={1--19},
  year={2019}
}

@inproceedings{groueix2018papier,
  title={A papier-m{\^a}ch{\'e} approach to learning 3d surface generation},
  author={Groueix, Thibault and Fisher, Matthew and Kim, Vladimir G and Russell, Bryan C and Aubry, Mathieu},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={216--224},
  year={2018}
}

@article{li2017grass,
  title={Grass: Generative recursive autoencoders for shape structures},
  author={Li, Jun and Xu, Kai and Chaudhuri, Siddhartha and Yumer, Ersin and Zhang, Hao and Guibas, Leonidas},
  journal={ACM Transactions on Graphics (TOG)},
  volume={36},
  number={4},
  pages={1--14},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@inproceedings{zou20173d,
  title={3d-prnn: Generating shape primitives with recurrent neural networks},
  author={Zou, Chuhang and Yumer, Ersin and Yang, Jimei and Ceylan, Duygu and Hoiem, Derek},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={900--909},
  year={2017}
}

@inproceedings{brock2016context,
  title={Context-Aware Content Generation for Virtual Environments},
  author={Brock, Andrew and Lim, Theodore and Ritchie, James Millar and Weston, Nick},
  booktitle={International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
  volume={50084},
  pages={V01BT02A045},
  year={2016},
  organization={American Society of Mechanical Engineers}
}

@article{chang2015shapenet,
  title={Shapenet: An information-rich 3d model repository},
  author={Chang, Angel X and Funkhouser, Thomas and Guibas, Leonidas and Hanrahan, Pat and Huang, Qixing and Li, Zimo and Savarese, Silvio and Savva, Manolis and Song, Shuran and Su, Hao and others},
  journal={arXiv preprint arXiv:1512.03012},
  year={2015}
}

@inproceedings{mo2019partnet,
  title={Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding},
  author={Mo, Kaichun and Zhu, Shilin and Chang, Angel X and Yi, Li and Tripathi, Subarna and Guibas, Leonidas J and Su, Hao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={909--918},
  year={2019}
}

@inproceedings{wu20153d,
  title={3d shapenets: A deep representation for volumetric shapes},
  author={Wu, Zhirong and Song, Shuran and Khosla, Aditya and Yu, Fisher and Zhang, Linguang and Tang, Xiaoou and Xiao, Jianxiong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1912--1920},
  year={2015}
}

@article{creswell2018generative,
  author={Creswell, Antonia and White, Tom and Dumoulin, Vincent and Arulkumaran, Kai and Sengupta, Biswa and Bharath, Anil A.},

  journal={IEEE Signal Processing Magazine}, 

  title={Generative Adversarial Networks: An Overview}, 

  year={2018},

  volume={35},

  number={1},

  pages={53-65},

  doi={10.1109/MSP.2017.2765202}}



@inproceedings{choi2020stargan,
  author={Choi, Yunjey and Uh, Youngjung and Yoo, Jaejun and Ha, Jung-Woo},

  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 

  title={StarGAN v2: Diverse Image Synthesis for Multiple Domains}, 

  year={2020},

  volume={},

  number={},

  pages={8185-8194},

  doi={10.1109/CVPR42600.2020.00821},

  location = {Seattle, WA, USA}
}
@inproceedings{CycleGAN2017,
author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},

  booktitle={2017 IEEE International Conference on Computer Vision (ICCV)}, 

  title={Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks}, 

  year={2017},

  volume={},

  number={},

  pages={2242-2251},

  doi={10.1109/ICCV.2017.244},

  location = {Venice, Italy}
}

@inproceedings{karras2020analyzing,
author={Karras, Tero and Laine, Samuli and Aittala, Miika and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},

  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 

  title={Analyzing and Improving the Image Quality of StyleGAN}, 

  year={2020},

  volume={},

  number={},

  pages={8107-8116},

  doi={10.1109/CVPR42600.2020.00813},
  location = {Seattle, WA, USA}
}
  
@article{arjovsky2017towards,
  title={Towards principled methods for training generative adversarial networks},
  author={Arjovsky, Martin and Bottou, L{\'e}on},
  journal={arXiv preprint arXiv:1701.04862},
  year={2017}
}

@inproceedings{salimans2016improved,
author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
title = {Improved Techniques for Training GANs},
year = {2016},
isbn = {9781510838819},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3\%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.},
booktitle = {Proceedings of the 30th International Conference on Neural Information Processing Systems},
pages = {22342242},
numpages = {9},
location = {Barcelona, Spain},
series = {NIPS'16}
}

  
@inproceedings{gulrajani2017improved,
author = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron},
title = {Improved Training of Wasserstein GANs},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only poor samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models with continuous generators. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {57695779},
numpages = {11},
location = {Long Beach, California, USA},
series = {NIPS'17}
}
  

@article{yang2018microstructural,
  title={Microstructural materials design via deep adversarial learning methodology},
  author={Yang, Zijiang and Li, Xiaolin and Catherine Brinson, L and Choudhary, Alok N and Chen, Wei and Agrawal, Ankit},
  journal={Journal of Mechanical Design},
  volume={140},
  number={11},
  year={2018},
  publisher={American Society of Mechanical Engineers Digital Collection}
}

@inproceedings{chen2019aerodynamic,
  title={Aerodynamic design optimization and shape exploration using generative adversarial networks},
  author={Chen, Wei and Chiu, Kevin and Fuge, Mark},
  booktitle={AIAA Scitech 2019 Forum},
  pages={2351},
  year={2019}
}

@article{chen2021padgan,
  title={Padgan: Learning to generate high-quality novel designs},
  author={Chen, Wei and Ahmed, Faez},
  journal={Journal of Mechanical Design},
  volume={143},
  number={3},
  pages={031703},
  year={2021},
  publisher={American Society of Mechanical Engineers}
}

@inproceedings{burnap2016estimating,
  title={Estimating and exploring the product form design space using deep generative models},
  author={Burnap, Alexander and Liu, Ye and Pan, Yanxin and Lee, Honglak and Gonzalez, Richard and Papalambros, Panos Y},
  booktitle={International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
  volume={50107},
  pages={V02AT03A013},
  year={2016},
  organization={American Society of Mechanical Engineers}
}

@article{shu20203d,
  title={3d design using generative adversarial networks and physics-based validation},
  author={Shu, Dule and Cunningham, James and Stump, Gary and Miller, Simon W and Yukish, Michael A and Simpson, Timothy W and Tucker, Conrad S},
  journal={Journal of Mechanical Design},
  volume={142},
  number={7},
  pages={071701},
  year={2020},
  publisher={American Society of Mechanical Engineers}
}

@inproceedings{qi2017pointnet,
  title={Pointnet: Deep learning on point sets for 3d classification and segmentation},
  author={Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={652--660},
  year={2017}
}



@inproceedings{isola2017image,
  title={Image-to-image translation with conditional adversarial networks},
  author={Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1125--1134},
  year={2017}
}

@inproceedings{hu2018squeeze,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7132--7141},
  year={2018}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}
@inproceedings{long2015fully,
  title={Fully convolutional networks for semantic segmentation},
  author={Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3431--3440},
  year={2015}
}

@article{zhu2016topology,
  title={Topology optimization in aircraft and aerospace structures design},
  author={Zhu, Ji-Hong and Zhang, Wei-Hong and Xia, Liang},
  journal={Archives of Computational Methods in Engineering},
  volume={23},
  number={4},
  pages={595--622},
  year={2016},
  publisher={Springer}
}

@article{xia2017recent,
  title={Recent advances on topology optimization of multiscale nonlinear structures},
  author={Xia, Liang and Breitkopf, Piotr},
  journal={Archives of Computational Methods in Engineering},
  volume={24},
  number={2},
  pages={227--249},
  year={2017},
  publisher={Springer}
}

@article{borrvall2003topology,
  title={Topology optimization of fluids in Stokes flow},
  author={Borrvall, Thomas and Petersson, Joakim},
  journal={International journal for numerical methods in fluids},
  volume={41},
  number={1},
  pages={77--107},
  year={2003},
  publisher={Wiley Online Library}
}

@article{zhou2008variational,
  title={A variational level set method for the topology optimization of steady-state Navier--Stokes flow},
  author={Zhou, Shiwei and Li, Qing},
  journal={Journal of Computational Physics},
  volume={227},
  number={24},
  pages={10178--10195},
  year={2008},
  publisher={Elsevier}
}

@article{zegard2016bridging,
  title={Bridging topology optimization and additive manufacturing},
  author={Zegard, Tom{\'a}s and Paulino, Glaucio H},
  journal={Structural and Multidisciplinary Optimization},
  volume={53},
  number={1},
  pages={175--192},
  year={2016},
  publisher={Springer}
}

@article{langelaar2016topology,
  title={Topology optimization of 3D self-supporting structures for additive manufacturing},
  author={Langelaar, Matthijs},
  journal={Additive Manufacturing},
  volume={12},
  pages={60--70},
  year={2016},
  publisher={Elsevier}
}

@article{dbouk2017review,
  title={A review about the engineering design of optimal heat transfer systems using topology optimization},
  author={Dbouk, Talib},
  journal={Applied Thermal Engineering},
  volume={112},
  pages={841--854},
  year={2017},
  publisher={Elsevier}
}

@article{koga2013development,
  title={Development of heat sink device by using topology optimization},
  author={Koga, Adriano A and Lopes, Edson Comini C and Nova, Helcio F Villa and De Lima, C{\'\i}cero R and Silva, Em{\'\i}lio Carlos Nelli},
  journal={International Journal of Heat and Mass Transfer},
  volume={64},
  pages={759--772},
  year={2013},
  publisher={Elsevier}
}

@article{cazacu2014overview,
  title={Overview of structural topology optimization methods for plane and solid structures},
  author={Cazacu, Razvan and Grama, Lucian},
  journal={Annals of the University of Oradea, Fascicle of Management and Technological Engineering},
  volume={23},
  number={3},
  pages={1583--1591},
  year={2014},
  publisher={Citeseer}
}

@article{oh2019deep,
  title={Deep generative design: Integration of topology optimization and generative models},
  author={Oh, Sangeun and Jung, Yongsu and Kim, Seongsin and Lee, Ikjin and Kang, Namwoo},
  journal={Journal of Mechanical Design},
  volume={141},
  number={11},
  year={2019},
  publisher={American Society of Mechanical Engineers Digital Collection}
}

@article{berthelot2017began,
  title={Began: Boundary equilibrium generative adversarial networks},
  author={Berthelot, David and Schumm, Thomas and Metz, Luke},
  journal={arXiv preprint arXiv:1703.10717},
  year={2017}
}

@inproceedings{chen2016infogan,
  title={Infogan: Interpretable representation learning by information maximizing generative adversarial nets},
  author={Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
  booktitle={Proceedings of the 30th International Conference on Neural Information Processing Systems},
  pages={2180--2188},
  year={2016}
}

@article{chen2019synthesizing,
  title={Synthesizing designs with interpart dependencies using hierarchical generative adversarial networks},
  author={Chen, Wei and Fuge, Mark},
  journal={Journal of Mechanical Design},
  volume={141},
  number={11},
  pages={111403},
  year={2019},
  publisher={American Society of Mechanical Engineers}
}

@article{chen2018b,
  title={B{\'e}zierGAN: Automatic Generation of Smooth Curves from Interpretable Low-Dimensional Parameters},
  author={Chen, Wei and Fuge, Mark},
  journal={arXiv preprint arXiv:1808.08871},
  year={2018}
}

@article{gielis2003generic,
  title={A generic geometric transformation that unifies a wide range of natural and abstract shapes},
  author={Gielis, Johan},
  journal={American journal of botany},
  volume={90},
  number={3},
  pages={333--338},
  year={2003},
  publisher={Wiley Online Library}
}

@article{mirza2014conditional,
  title={Conditional generative adversarial nets},
  author={Mirza, Mehdi and Osindero, Simon},
  journal={arXiv preprint arXiv:1411.1784},
  year={2014}
}

@inproceedings{oh2018design,
  title={Design automation by integrating generative adversarial networks and topology optimization},
  author={Oh, Sangeun and Jung, Yongsu and Lee, Ikjin and Kang, Namwoo},
  booktitle={International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
  volume={51753},
  pages={V02AT03A008},
  year={2018},
  organization={American Society of Mechanical Engineers}
}

@inproceedings{sharpe2019topology,
  title={Topology design with conditional generative adversarial networks},
  author={Sharpe, Conner and Seepersad, Carolyn Conner},
  booktitle={International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
  volume={59186},
  pages={V02AT03A062},
  year={2019},
  organization={American Society of Mechanical Engineers}
}

@inproceedings{karnewar2020msg,
  title={Msg-gan: Multi-scale gradients for generative adversarial networks},
  author={Karnewar, Animesh and Wang, Oliver},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7799--7808},
  year={2020}
}

@inproceedings{greminger2020generative,
  title={Generative Adversarial Networks With Synthetic Training Data for Enforcing Manufacturing Constraints on Topology Optimization},
  author={Greminger, Michael},
  booktitle={International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
  volume={84003},
  pages={V11AT11A005},
  year={2020},
  organization={American Society of Mechanical Engineers}
}

@inproceedings{zhang20193d,
  title={3D shape synthesis for conceptual design and optimization using variational autoencoders},
  author={Zhang, Wentai and Yang, Zhangsihao and Jiang, Haoliang and Nigam, Suyash and Yamakawa, Soji and Furuhata, Tomotake and Shimada, Kenji and Kara, Levent Burak},
  booktitle={International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
  volume={59186},
  pages={V02AT03A017},
  year={2019},
  organization={American Society of Mechanical Engineers}
}

@article{katoch2021review,
  title={A review on genetic algorithm: past, present, and future},
  author={Katoch, Sourabh and Chauhan, Sumit Singh and Kumar, Vijay},
  journal={Multimedia Tools and Applications},
  volume={80},
  number={5},
  pages={8091--8126},
  year={2021},
  publisher={Springer}
}

@inproceedings{dering2018physics,
  title={A physics-based virtual environment for enhancing the quality of deep generative designs},
  author={Dering, Matthew and Cunningham, James and Desai, Raj and Yukish, Michael A and Simpson, Timothy W and Tucker, Conrad S},
  booktitle={International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
  volume={51753},
  pages={V02AT03A015},
  year={2018},
  organization={American Society of Mechanical Engineers}
}

@inproceedings{ha2018neural,
  title={A Neural Representation of Sketch Drawings},
  author={Ha, David and Eck, Douglas},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{lopez2018human,
  title={Human validation of computer vs human generated design sketches},
  author={Lopez, Christian and Miller, Scarlett R and Tucker, Conrad S},
  booktitle={International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
  volume={51845},
  pages={V007T06A015},
  year={2018},
  organization={American Society of Mechanical Engineers}
}

@inproceedings{cunningham2018validation,
  title={A Validation Neural Network (VNN) metamodel for predicting the performance of deep generative designs},
  author={Cunningham, James and Tucker, Conrad S},
  booktitle={International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
  volume={51760},
  pages={V02BT03A037},
  year={2018},
  organization={American Society of Mechanical Engineers}
}

@article{jongejan2016quick,
  title={The quick, draw!-ai experiment},
  author={Jongejan, Jonas and Rowley, Henry and Kawashima, Takashi and Kim, Jongmin and Fox-Gieg, Nick},
  journal={Mount View, CA, accessed Feb},
  volume={17},
  number={2018},
  pages={4},
  year={2016}
}

@inproceedings{sohn2015learning,
author = {Sohn, Kihyuk and Yan, Xinchen and Lee, Honglak},
title = {Learning Structured Output Representation Using Deep Conditional Generative Models},
year = {2015},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
abstract = {Supervised deep learning has been successfully applied to many recognition problems. Although it can approximate a complex many-to-one function well when a large amount of training data is provided, it is still challenging to model complex structured output representations that effectively perform probabilistic inference and make diverse predictions. In this work, we develop a deep conditional generative model for structured output prediction using Gaussian latent variables. The model is trained efficiently in the framework of stochastic gradient variational Bayes, and allows for fast prediction using stochastic feed-forward inference. In addition, we provide novel strategies to build robust structured prediction algorithms, such as input noise-injection and multi-scale prediction objective at training. In experiments, we demonstrate the effectiveness of our proposed algorithm in comparison to the deterministic deep neural network counterparts in generating diverse but realistic structured output predictions using stochastic inference. Furthermore, the proposed training methods are complimentary, which leads to strong pixel-level object segmentation and semantic labeling performance on Caltech-UCSD Birds 200 and the subset of Labeled Faces in the Wild dataset.},
booktitle = {Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2},
pages = {34833491},
numpages = {9},
location = {Montreal, Canada},
series = {NIPS'15}
}

  

@article{kullback1951information,
  title={On information and sufficiency},
  author={Kullback, Solomon and Leibler, Richard A},
  journal={The annals of mathematical statistics},
  volume={22},
  number={1},
  pages={79--86},
  year={1951},
  publisher={JSTOR}
}

@article{deshpande2019computational,
  title={Computational creativity via assisted variational synthesis of mechanisms using deep generative models},
  author={Deshpande, Shrinath and Purwar, Anurag},
  journal={Journal of Mechanical Design},
  volume={141},
  number={12},
  year={2019},
  publisher={American Society of Mechanical Engineers Digital Collection}
}

@article{lee2019case,
  title={A case study of deep reinforcement learning for engineering design: Application to microfluidic devices for flow sculpting},
  author={Lee, Xian Yeow and Balu, Aditya and Stoecklein, Daniel and Ganapathysubramanian, Baskar and Sarkar, Soumik},
  journal={Journal of Mechanical Design},
  volume={141},
  number={11},
  pages={111401},
  year={2019},
  publisher={American Society of Mechanical Engineers}
}


@article{van2016deep, title={Deep Reinforcement Learning with Double Q-Learning}, volume={30}, url={https://ojs.aaai.org/index.php/AAAI/article/view/10295}, abstractNote={ &lt;p&gt; The popular Q-learning algorithm is known to overestimate action values under certain conditions. It was not previously known whether, in practice, such overestimations are common, whether they harm performance, and whether they can generally be prevented. In this paper, we answer all these questions affirmatively. In particular, we first show that the recent DQN algorithm, which combines Q-learning with a deep neural network, suffers from substantial overestimations in some games in the Atari 2600 domain. We then show that the idea behind the Double Q-learning algorithm, which was introduced in a tabular setting, can be generalized to work with large-scale function approximation. We propose a specific adaptation to the DQN algorithm and show that the resulting algorithm not only reduces the observed overestimations, as hypothesized, but that this also leads to much better performance on several games. &lt;/p&gt; }, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={van Hasselt, Hado and Guez, Arthur and Silver, David}, year={2016}, month={Mar.} }

@article{kulesza2012determinantal,
  title={Determinantal Point Processes for Machine Learning},
  author={Kulesza, Alex and Taskar, Ben and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={5},
  number={2--3},
  pages={123--286},
  year={2012},
  publisher={Now Publishers, Inc.}
}

@inproceedings{sharma2020path,
  title={Path Synthesis of Defect-Free Spatial 5-SS Mechanisms Using Machine Learning},
  author={Sharma, Shashank and Purwar, Anurag},
  booktitle={International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
  volume={83990},
  pages={V010T10A034},
  year={2020},
  organization={American Society of Mechanical Engineers}
}

@techreport{rawat2019application,
  title={Application of adversarial networks for 3d structural topology optimization},
  author={Rawat, Sharad and Shen, MH Herman},
  year={2019},
  institution={SAE Technical Paper}
}

@article{yu2019deep,
  title={Deep learning for determining a near-optimal topological design without any iteration},
  author={Yu, Yonggyun and Hur, Taeil and Jung, Jaeho and Jang, In Gwun},
  journal={Structural and Multidisciplinary Optimization},
  volume={59},
  number={3},
  pages={787--799},
  year={2019},
  publisher={Springer}
}

@article{kaelbling1996RL,
author = {Kaelbling, Leslie Pack and Littman, Michael L. and Moore, Andrew W.},
title = {Reinforcement Learning: A Survey},
year = {1996},
issue_date = {Jnauary 1996},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {4},
number = {1},
issn = {1076-9757},
abstract = {This paper surveys the field of reinforcement learning from a computer-science perspective.
It is written to be accessible to researchers familiar with machine learning. Both
the historical basis of the field and a broad selection of current work are summarized.
Reinforcement learning is the problem faced by an agent that learns behavior through
trial-and-error interactions with a dynamic environment. The work described here has
a resemblance to work in psychology, but differs considerably in the details and in
the use of the word "reinforcement." The paper discusses central issues of reinforcement
learning, including trading off exploration and exploitation, establishing the foundations
of the field via Markov decision theory, learning from delayed reinforcement, constructing
empirical models to accelerate learning, making use of generalization and hierarchy,
and coping with hidden state. It concludes with a survey of some implemented systems
and an assessment of the practical utility of current methods for reinforcement learning.},
journal = {J. Artif. Int. Res.},
month = may,
pages = {237285},
numpages = {49}
}

@book{sutton_barto_2012, place={Cambridge, MA}, title={Reinforcement learning: an introduction}, publisher={The MIT Press}, author={Sutton, Richard S. and Barto, Andrew G.}, year={2012}}

@inproceedings{guo2018indirect,
  title={An indirect design representation for topology optimization using variational autoencoder and style transfer},
  author={Guo, Tinghao and Lohan, Danny J and Cang, Ruijin and Ren, Max Yi and Allison, James T},
  booktitle={2018 AIAA/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference},
  pages={0804},
  year={2018}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{Markov1953-MARTTO-31,
	number = {4},
	journal = {Journal of Symbolic Logic},
	publisher = {Association for Symbolic Logic},
	title = {The Theory of Algorithms},
	author = {A. A. Markov},
	year = {1953},
	doi = {10.2307/2266585},
	volume = {18},
	pages = {340--341}
}

@InProceedings{QRL,
author="Melo, Francisco S.
and Ribeiro, M. Isabel",
editor="Bshouty, Nader H.
and Gentile, Claudio",
title="Q-Learning with Linear Function Approximation",
booktitle="Learning Theory",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="308--322",
abstract="In this paper, we analyze the convergence of Q-learning with linear function approximation. We identify a set of conditions that implies the convergence of this method with probability 1, when a fixed learning policy is used. We discuss the differences and similarities between our results and those obtained in several related works. We also discuss the applicability of this method when a changing policy is used. Finally, we describe the applicability of this approximate method in partially observable scenarios.",
isbn="978-3-540-72927-3"
}

@inproceedings{10.1115/DETC2018-85529,
    author = {Vermeer, Kaz and Kuppens, Reinier and Herder, Justus},
    title = "{Kinematic Synthesis Using Reinforcement Learning}",
    volume = {Volume 2A: 44th Design Automation Conference},
    series = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
    year = {2018},
    month = {08},
    abstract = "{The presented research demonstrates the synthesis of two-dimensional kinematic mechanisms using feature-based reinforcement learning. As a running example the classic challenge of designing a straight-line mechanism is adopted: a mechanism capable of tracing a straight line as part of its trajectory. This paper presents a basic framework, consisting of elements such as mechanism representations, kinematic simulations and learning algorithms, as well as some of the resulting mechanisms and a comparison to prior art. Series of successful mechanisms have been synthesized for path generation of a straight line and figure-eight.}",
    doi = {10.1115/DETC2018-85529},
    url = {https://doi.org/10.1115/DETC2018-85529},
    note = {V02AT03A009},
    eprint = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-pdf/IDETC-CIE2018/51753/V02AT03A009/2475681/v02at03a009-detc2018-85529.pdf},
}

@inproceedings{gatys2016image,
  title={Image style transfer using convolutional neural networks},
  author={Gatys, Leon A and Ecker, Alexander S and Bethge, Matthias},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2414--2423},
  year={2016}
}

@article{cang2018improving,
  title={Improving direct physical properties prediction of heterogeneous materials from imaging data via convolutional neural network and a morphology-aware generative model},
  author={Cang, Ruijin and Li, Hechao and Yao, Hope and Jiao, Yang and Ren, Yi},
  journal={Computational Materials Science},
  volume={150},
  pages={212--221},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{liu2018learning,
  title={Learning a hierarchical latent-variable model of 3d shapes},
  author={Liu, Shikun and Giles, Lee and Ororbia, Alexander},
  booktitle={2018 International Conference on 3D Vision (3DV)},
  pages={542--551},
  year={2018},
  organization={IEEE}
}

@inproceedings{yilmaz2020conditional,
  title={Conditional generative adversarial network framework for airfoil inverse design},
  author={Yilmaz, Emre and German, Brian},
  booktitle={AIAA aviation 2020 forum},
  pages={3185},
  year={2020}
}


@inproceedings{larsen2016autoencoding,
  title={Autoencoding beyond pixels using a learned similarity metric},
  author={Larsen, Anders Boesen Lindbo and S{\o}nderby, S{\o}ren Kaae and Larochelle, Hugo and Winther, Ole},
  booktitle={International conference on machine learning},
  pages={1558--1566},
  year={2016},
  organization={PMLR}
}

@article{li2021learning,
  title={Learning the aerodynamic design of supercritical airfoils through deep reinforcement learning},
  author={Li, Runze and Zhang, Yufei and Chen, Haixin},
  journal={AIAA Journal},
  pages={1--14},
  year={2021},
  publisher={American Institute of Aeronautics and Astronautics}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{sosnovik2019neural,
  title={Neural networks for topology optimization},
  author={Sosnovik, Ivan and Oseledets, Ivan},
  journal={Russian Journal of Numerical Analysis and Mathematical Modelling},
  volume={34},
  number={4},
  pages={215--223},
  year={2019},
  publisher={De Gruyter}
}

@article{LI2019172,
title = {Non-iterative structural topology optimization using deep learning},
journal = {Computer-Aided Design},
volume = {115},
pages = {172-180},
year = {2019},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2019.05.038},
url = {https://www.sciencedirect.com/science/article/pii/S001044851930185X},
author = {Baotong Li and Congjia Huang and Xin Li and Shuai Zheng and Jun Hong},
keywords = {Topology optimization, Deep learning, Generative adversarial network, Hierarchical refinement, Heat conduction},
abstract = {This paper presents a non-iterative topology optimizer for conductive heat transfer structures with the help of deep learning. An artificial neural network is trained to deal with the black-and-white pixel images and generate near-optimal structures. Our design is a two-stage hierarchical predictionrefinement pipeline consisting of two coupled neural networks: a generative adversarial network (GAN) for predicting a low resolution near-optimal structure and a super-resolution generative adversarial network (SRGAN) for predicting the refined structure in high resolution. Training datasets with given boundary conditions and the optimized pixel image structures are obtained after simulating a big amount of topology optimization procedures. For more effective training and inference, these datasets are generated with two different resolutions. Experiments demonstrated that our learning based optimizer can provide accurate estimation of the conductive heat transfer topology using negligible computational time. This effective incorporation of deep learning into topology optimization could enable promising applications in large-scale engineering structure design.}
}

@inproceedings{ledig2017photo,
  title={Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network},
  author={Ledig, Christian and Theis, Lucas and Husz{\'a}r, Ferenc and Caballero, Jose and Cunningham, Andrew and Acosta, Alejandro and Aitken, Andrew and Tejani, Alykhan and Totz, Johannes and Wang, Zehan and others},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={105--114},
  year={2017},
  organization={IEEE}
}

@article{ZHANG2021103041,
title = {ScaffoldGAN: Synthesis of Scaffold Materials based on Generative Adversarial Networks},
journal = {Computer-Aided Design},
volume = {138},
pages = {103041},
year = {2021},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2021.103041},
url = {https://www.sciencedirect.com/science/article/pii/S001044852100052X},
author = {Hui Zhang and Lei Yang and Changjian Li and Bojian Wu and Wenping Wang},
keywords = {3D shape synthesis, Generative adversarial networks, Deep learning, Scaffold material, Complex structure},
abstract = {Digitally synthesizing scaffold-like materials with complex structures, e.g., bones or metal foam, is a fundamental yet challenging task in tissue engineering and other biomedical applications, because it is difficult to generate synthesized results with equal visual complexity, strong spatial coherence, and similar statistical metrics. To handle these challenges, we present ScaffoldGAN, an efficient end-to-end framework based on generative adversarial networks (GANs) for synthesizing three-dimensional (3D) materials with complex internal structures resembling the given exemplar. Specifically, we propose a novel structural loss to enforce strong spatial coherence in the synthesized results by leveraging the deep features learned by our networks. To demonstrate the effectiveness of our model and the proposed structural loss term, we collected example data containing various structural complexities, covering two categories of materials, i.e., bones and metal foams. Extensive comparative experiments on these collected data showed that our method outperforms state-of-the-art methods, producing synthesized results with better visual quality and desirable statistical metrics. The ablation study proves the structural loss is the main contributor to the performance gain, validating our design choice.}
}

@article{gatys2015texture,
  title={Texture synthesis using convolutional neural networks},
  author={Gatys, Leon and Ecker, Alexander S and Bethge, Matthias},
  journal={Advances in neural information processing systems},
  volume={28},
  pages={262--270},
  year={2015}
}

@article{BEHZADI2021103014,
title = {Real-Time Topology Optimization in 3D via Deep Transfer Learning},
journal = {Computer-Aided Design},
volume = {135},
pages = {103014},
year = {2021},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2021.103014},
url = {https://www.sciencedirect.com/science/article/pii/S0010448521000257},
author = {Mohammad Mahdi Behzadi and Horea T. Ilie},
}

@article{KESHAVARZZADEH2021102947,
title = {Image-Based Multiresolution Topology Optimization Using Deep Disjunctive Normal Shape Model},
journal = {Computer-Aided Design},
volume = {130},
pages = {102947},
year = {2021},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2020.102947},
url = {https://www.sciencedirect.com/science/article/pii/S0010448520301408},
author = {Vahid Keshavarzzadeh and Mitra Alirezaei and Tolga Tasdizen and Robert M. Kirby},
keywords = {Topology optimization, Multiresolution analysis, Image-based segmentation, Deep neural networks},
abstract = {We present a machine learning framework for predicting the optimized structural topology designs using multiresolution data. Our approach primarily uses optimized designs from inexpensive coarse mesh finite element simulations for model training and generates high resolution images associated with simulation parameters that are not previously used. Our cost-efficient approach enables the designers to effectively search through possible candidate designs in situations where the design requirements rapidly change. The underlying neural network framework is based on a deep disjunctive normal shape model (DDNSM) which learns the mapping between the simulation parameters and segments of multi resolution images. Using this image-based analysis we provide a practical algorithm which enhances the predictability of the learning machine by determining a limited number of important parametric samples (i.e. samples of the simulation parameters) on which the high resolution training data is generated. We demonstrate our approach on benchmark compliance minimization problems including the 3D topology optimization where we show that the high-fidelity designs from the learning machine are close to optimal designs and can be used as effective initial guesses for the large-scale optimization problem.}
}

@article{KIM2021102932,
title = {Object Synthesis by Learning Part Geometry with Surface and Volumetric Representations},
journal = {Computer-Aided Design},
volume = {130},
pages = {102932},
year = {2021},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2020.102932},
url = {https://www.sciencedirect.com/science/article/pii/S0010448520301251},
author = {Sangpil Kim and Hyung-gun Chi and Karthik Ramani},
keywords = {Deep learning, Conditional generative model, Multi-task learning, Object synthesis},
abstract = {We propose a conditional generative model, named Part Geometry Network (PG-Net), which synthesizes realistic objects and can be used as a robust feature descriptor for object reconstruction and classification. Surface and volumetric representations of objects have complementary properties of three-dimensional objects. Combining these modalities is more informative than using one modality alone. Therefore, PG-Net utilizes complementary properties of surface and volumetric representations by estimating curvature, surface area, and occupancy in voxel grids of objects with a single decoder as a multi-task learning. Objects are combinations of multiple parts, and therefore part geometry (PG) is essential to synthesize each part of the objects. PG-Net employs a part identifier to learn the part geometry. Additionally, we augmented a dataset by interpolating individual functional parts such as wings of an airplane, which helps learning part geometry and finding local/global minima of PG-Net. To demonstrate the capability of learning object representations of PG-Net, we performed object reconstruction and classification tasks on two standard large-scale datasets. PG-Net outperformed the state-of-the-art methods in object synthesis, classification, and reconstruction in a large margin.}
}

@article{CANG201912,
title = {One-shot generation of near-optimal topology through theory-driven machine learning},
journal = {Computer-Aided Design},
volume = {109},
pages = {12-21},
year = {2019},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2018.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S0010448518303828},
author = {Ruijin Cang and Hope Yao and Yi Ren},
keywords = {Topology optimization, Meta-learning, Active learning},
abstract = {We introduce a theory-driven mechanism for learning a neural network model that performs generative topology design in one shot given a problem setting, circumventing the conventional iterative process that computational design tasks usually entail. The proposed mechanism can lead to machines that quickly respond to new design requirements based on its knowledge accumulated through past experiences of design generation. Achieving such a mechanism through supervised learning would require an impractically large amount of problemsolution pairs for training, due to the known limitation of deep neural networks in knowledge generalization. To this end, we introduce an interaction between a student (the neural network) and a teacher (the optimality conditions underlying topology optimization): The student learns from existing data and is tested on unseen problems. Deviation of the students solutions from the optimality conditions is quantified, and used for choosing new data points to learn from. We call this learning mechanism theory-driven, as it explicitly uses domain-specific theories to guide the learning, thus distinguishing itself from purely data-driven supervised learning. We show through a compliance minimization problem that the proposed learning mechanism leads to topology generation with near-optimal structural compliance, much improved from standard supervised learning under the same computational budget.}
}

@article{wang_peng_li_chen_wu_wang_childs_guo_2019, title={Human-in-the-Loop Design with Machine Learning}, volume={1}, DOI={10.1017/dsi.2019.264}, number={1}, journal={Proceedings of the Design Society: International Conference on Engineering Design}, publisher={Cambridge University Press}, author={Wang, Pan and Peng, Danlin and Li, Ling and Chen, Liuqing and Wu, Chao and Wang, Xiaoyi and Childs, Peter and Guo, Yike}, year={2019}, pages={25772586}}

@inproceedings{odena2017conditional,
  title={Conditional image synthesis with auxiliary classifier gans},
  author={Odena, Augustus and Olah, Christopher and Shlens, Jonathon},
  booktitle={International conference on machine learning},
  pages={2642--2651},
  year={2017},
  organization={PMLR}
}


@inproceedings{dering2017generative,
  title={Generative adversarial networks for increasing the veracity of big data},
  author={Dering, Matthew L and Tucker, Conrad S},
  booktitle={2017 IEEE International Conference on Big Data (Big Data)},
  pages={2595--2602},
  year={2017},
  organization={IEEE}
}


@article{praveen2009low,
  title={Low cost PSO using metamodels and inexact pre-evaluation: Application to aerodynamic shape design},
  author={Praveen, C and Duvigneau, Regis},
  journal={Computer Methods in Applied Mechanics and Engineering},
  volume={198},
  number={9-12},
  pages={1087--1096},
  year={2009},
  publisher={Elsevier}
}

@inproceedings{cang2017scalable,
  title={Scalable microstructure reconstruction with multi-scale pattern preservation},
  author={Cang, Ruijin and Vipradas, Aditya and Ren, Yi},
  booktitle={International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
  volume={58134},
  pages={V02BT03A010},
  year={2017},
  organization={American Society of Mechanical Engineers}
}

@inproceedings{lee2009convolutional,
  title={Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations},
  author={Lee, Honglak and Grosse, Roger and Ranganath, Rajesh and Ng, Andrew Y},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={609--616},
  year={2009}
}

@article{bostanabad2018computational,
  title={Computational microstructure characterization and reconstruction: Review of the state-of-the-art techniques},
  author={Bostanabad, Ramin and Zhang, Yichi and Li, Xiaolin and Kearney, Tucker and Brinson, L Catherine and Apley, Daniel W and Liu, Wing Kam and Chen, Wei},
  journal={Progress in Materials Science},
  volume={95},
  pages={1--41},
  year={2018},
  publisher={Elsevier}
}

@article{yu2017characterization,
  title={Characterization and design of functional quasi-random nanostructured materials using spectral density function},
  author={Yu, Shuangcheng and Zhang, Yichi and Wang, Chen and Lee, Won-kyu and Dong, Biqin and Odom, Teri W and Sun, Cheng and Chen, Wei},
  journal={Journal of Mechanical Design},
  volume={139},
  number={7},
  pages={071401},
  year={2017},
  publisher={American Society of Mechanical Engineers}
}

@inproceedings{regenwetter2021biked, title={{BIKED}: A Dataset and Machine Learning Benchmarks for Data-Driven Bicycle Design}, author={Regenwetter, Lyle and Curry, Brent and Ahmed, Faez}, booktitle={International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, {IDETC-21}}, organization={ASME}, day = {17-20},month = {Aug}, address = {Virtual, Online}, year={2021}}

@article{regenwetter2022biked,
  title={BIKED: A Dataset for Computational Bicycle Design With Machine Learning Benchmarks},
  author={Regenwetter, Lyle and Curry, Brent and Ahmed, Faez},
  journal={Journal of Mechanical Design},
  volume={144},
  number={3},
  year={2022},
  publisher={American Society of Mechanical Engineers Digital Collection}
}

@inproceedings{nobari2021creativegan, title={CreativeGAN: Editing Generative Adversarial Networks for Creative Design Synthesis}, author={Amin Heyrani Nobari and Muhammad Fathy Rashad and Faez Ahmed}, booktitle={International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, {IDETC-21}}, organization={ASME}, day = {17-20},month = {Aug}, address = {Virtual, Online}, year={2021}}

@misc{hunter2017topy,
  title={Topy-topology optimization with python},
  author={Hunter, William and others},
  year={2017}
}

@article{li2020designing,
  title={Designing phononic crystal with anticipated band gap through a deep learning based data-driven method},
  author={Li, Xiang and Ning, Shaowu and Liu, Zhanli and Yan, Ziming and Luo, Chengcheng and Zhuang, Zhuo},
  journal={Computer Methods in Applied Mechanics and Engineering},
  volume={361},
  pages={112737},
  year={2020},
  publisher={Elsevier}
}

@article{liu2020hybrid,
  title={A hybrid strategy for the discovery and design of photonic structures},
  author={Liu, Zhaocheng and Raju, Lakshmi and Zhu, Dayu and Cai, Wenshan},
  journal={IEEE Journal on Emerging and Selected Topics in Circuits and Systems},
  volume={10},
  number={1},
  pages={126--135},
  year={2020},
  publisher={IEEE}
}

@article{ma2019probabilistic,
  title={Probabilistic representation and inverse design of metamaterials based on a deep generative model with semi-supervised learning strategy},
  author={Ma, Wei and Cheng, Feng and Xu, Yihao and Wen, Qinlong and Liu, Yongmin},
  journal={Advanced Materials},
  volume={31},
  number={35},
  pages={1901111},
  year={2019},
  publisher={Wiley Online Library}
}

@inproceedings{tang2020generative,
  title={Generative deep learning model for a multi-level nano-optic broadband power splitter},
  author={Tang, Yingheng and Kojima, Keisuke and Koike-Akino, Toshiaki and Wang, Ye and Wu, Pengxiang and Tahersima, Mohammad and Jha, Devesh and Parsons, Kieran and Qi, Minghao},
  booktitle={2020 Optical Fiber Communications Conference and Exhibition (OFC)},
  pages={1--3},
  year={2020},
  organization={IEEE}
}

@article{malkiel2018plasmonic,
  title={Plasmonic nanostructure design and characterization via deep learning},
  author={Malkiel, Itzik and Mrejen, Michael and Nagler, Achiya and Arieli, Uri and Wolf, Lior and Suchowski, Haim},
  journal={Light: Science \& Applications},
  volume={7},
  number={1},
  pages={1--8},
  year={2018},
  publisher={Nature Publishing Group}
}

@article{molesky2018inverse,
  title={Inverse design in nanophotonics},
  author={Molesky, Sean and Lin, Zin and Piggott, Alexander Y and Jin, Weiliang and Vuckovi{\'c}, Jelena and Rodriguez, Alejandro W},
  journal={Nature Photonics},
  volume={12},
  number={11},
  pages={659--670},
  year={2018},
  publisher={Nature Publishing Group}
}

@article{lee2021virtual,
  title={Virtual microstructure design for steels using generative adversarial networks},
  author={Lee, Jin-Woong and Goo, Nam Hoon and Park, Woon Bae and Pyo, Myungho and Sohn, Kee-Sun},
  journal={Engineering Reports},
  volume={3},
  number={1},
  pages={e12274},
  year={2021},
  publisher={Wiley Online Library}
}

@article{tan2020deep,
  title={A deep learning--based method for the design of microstructural materials},
  author={Tan, Ren Kai and Zhang, Nevin L and Ye, Wenjing},
  journal={Structural and Multidisciplinary Optimization},
  volume={61},
  number={4},
  pages={1417--1438},
  year={2020},
  publisher={Springer}
}

@article{li2018transfer,
  title={A transfer learning approach for microstructure reconstruction and structure-property predictions},
  author={Li, Xiaolin and Zhang, Yichi and Zhao, He and Burkhart, Craig and Brinson, L Catherine and Chen, Wei},
  journal={Scientific reports},
  volume={8},
  number={1},
  pages={1--13},
  year={2018},
  publisher={Nature Publishing Group}
}

@article{wang2020deep,
  title={Deep generative modeling for mechanistic-based learning and design of metamaterial systems},
  author={Wang, Liwei and Chan, Yu-Chin and Ahmed, Faez and Liu, Zhao and Zhu, Ping and Chen, Wei},
  journal={Computer Methods in Applied Mechanics and Engineering},
  volume={372},
  pages={113377},
  year={2020},
  publisher={Elsevier}
}

@article{chan2021metaset,
  title={METASET: Exploring shape and property spaces for data-driven metamaterials design},
  author={Chan, Yu-Chin and Ahmed, Faez and Wang, Liwei and Chen, Wei},
  journal={Journal of Mechanical Design},
  volume={143},
  number={3},
  pages={031707},
  year={2021},
  publisher={American Society of Mechanical Engineers}
}

@article{wang2021data,
  title={Data-Driven Multiscale Design of Cellular Composites with Multiclass Microstructures for Natural Frequency Maximization},
  author={Wang, Liwei and van Beek, Anton and Da, Daicong and Chan, Yu-Chin and Zhu, Ping and Chen, Wei},
  journal={arXiv preprint arXiv:2106.06478},
  year={2021}
}

@inproceedings{zhang2020meshingnet,
  title={MeshingNet: a new mesh generation method based on deep learning},
  author={Zhang, Zheyan and Wang, Yongxing and Jimack, Peter K and Wang, He},
  booktitle={International Conference on Computational Science},
  pages={186--198},
  year={2020},
  organization={Springer}
}

@inproceedings{ranjan2018generating,
  title={Generating 3D faces using convolutional mesh autoencoders},
  author={Ranjan, Anurag and Bolkart, Timo and Sanyal, Soubhik and Black, Michael J},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={704--720},
  year={2018}
}

@article{cheng2019meshgan,
  title={Meshgan: Non-linear 3d morphable models of faces},
  author={Cheng, Shiyang and Bronstein, Michael and Zhou, Yuxiang and Kotsia, Irene and Pantic, Maja and Zafeiriou, Stefanos},
  journal={arXiv preprint arXiv:1903.10384},
  year={2019}
}

@book{linsen2001point,
  title={Point cloud representation},
  author={Linsen, Lars},
  year={2001},
  publisher={Univ., Fak. f{\"u}r Informatik, Bibliothek Technical Report, Faculty of Computer~}
}

@article{willis2021fusion,
  title={Fusion 360 gallery: A dataset and environment for programmatic cad construction from human design sequences},
  author={Willis, Karl DD and Pu, Yewen and Luo, Jieliang and Chu, Hang and Du, Tao and Lambourne, Joseph G and Solar-Lezama, Armando and Matusik, Wojciech},
  journal={ACM Transactions on Graphics (TOG)},
  volume={40},
  number={4},
  pages={1--24},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{iren2021aachen,
  title={Aachen-Heerlen annotated steel microstructure dataset},
  author={Iren, Deniz and Ackermann, Marc and Gorfer, Julian and Pujar, Gaurav and Wesselmecking, Sebastian and Krupp, Ulrich and Bromuri, Stefano},
  journal={Scientific Data},
  volume={8},
  number={1},
  pages={1--9},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{larmuseau2020compact,
  title={Compact representations of microstructure images using triplet networks},
  author={Larmuseau, Michiel and Sluydts, Michael and Theuwissen, Koenraad and Duprez, Lode and Dhaene, Tom and Cottenier, Stefaan},
  journal={npj Computational Materials},
  volume={6},
  number={1},
  pages={1--11},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{decost2017uhcsdb,
  title={UHCSDB: ultrahigh carbon steel micrograph database},
  author={DeCost, Brian L and Hecht, Matthew D and Francis, Toby and Webler, Bryan A and Picard, Yoosuf N and Holm, Elizabeth A},
  journal={Integrating Materials and Manufacturing Innovation},
  volume={6},
  number={2},
  pages={197--205},
  year={2017},
  publisher={Springer}
}

@inproceedings{sangpil2020large, title={A Large-scale Annotated Mechanical Components Benchmark for Classification and Retrieval Tasks with Deep Neural Networks}, author={Kim, Sangpil and Chi, Hyung-gun and Hu, Xiao and Huang, Qixing and Ramani, Karthik}, booktitle={Proceedings of 16th European Conference on Computer Vision (ECCV)}, year={2020},}

@article{remondino2003point,
  title={From point cloud to surface: the modeling and visualization problem},
  author={Remondino, Fabio},
  journal={International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  volume={34},
  year={2003},
  publisher={ISPRS}
}

@article{daneshmand20183d,
  title={3d scanning: A comprehensive survey},
  author={Daneshmand, Morteza and Helmi, Ahmed and Avots, Egils and Noroozi, Fatemeh and Alisinanoglu, Fatih and Arslan, Hasan Sait and Gorbova, Jelena and Haamer, Rain Eric and Ozcinar, Cagri and Anbarjafari, Gholamreza},
  journal={arXiv preprint arXiv:1801.08863},
  year={2018}
}

@inproceedings{VeeGAN,
 author = {Srivastava, Akash and Valkov, Lazar and Russell, Chris and Gutmann, Michael U. and Sutton, Charles},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {3308--3318},
 publisher = {Curran Associates, Inc.},
 title = {VEEGAN: Reducing Mode Collapse in GANs using Implicit Variational Learning},
 url = {https://proceedings.neurips.cc/paper/2017/file/44a2e0804995faf8d2e3b084a1e2db1d-Paper.pdf},
 volume = {30},
 year = {2017}
}

@inproceedings{improvinggan,
 author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi and Chen, Xi},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {2234--2242},
 publisher = {Curran Associates, Inc.},
 title = {Improved Techniques for Training GANs},
 url = {https://proceedings.neurips.cc/paper/2016/file/8a3363abe792db2d8761d6403605aeb7-Paper.pdf},
 volume = {29},
 year = {2016}
}

@inproceedings{ding2020ccgan,
  author    = {Xin Ding and
               Yongwei Wang and
               Zuheng Xu and
               William J. Welch and
               Z. Jane Wang},
  title     = {CcGAN: Continuous Conditional Generative Adversarial Networks for
               Image Generation},
  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021,
               Virtual Event, Austria, May 3-7, 2021},
  publisher = {OpenReview.net},
  year      = {2021},
  url       = {https://openreview.net/forum?id=PrzjugOsDeE},
  timestamp = {Wed, 23 Jun 2021 17:36:39 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/DingWXW021.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{dong2019inverse,
title = {Inverse design of two-dimensional graphene/h-BN hybrids by a regressional and conditional GAN},
journal = {Carbon},
volume = {169},
pages = {9-16},
year = {2020},
issn = {0008-6223},
doi = {https://doi.org/10.1016/j.carbon.2020.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S0008622320306734},
author = {Yuan Dong and Dawei Li and Chi Zhang and Chuhan Wu and Hong Wang and Ming Xin and Jianlin Cheng and Jian Lin},
abstract = {Design of materials with desired properties is currently laborious and heavily relies on intuition of researchers through a trial-and-error process. To tackle this challenge, we propose a novel regressional and conditional generative adversarial network (RCGAN) for inverse design of representative two-dimensional materials, the graphene and boron-nitride (BN) hybrids. RCGAN incorporates a supervised regressor network, thus overcoming the common technical barrier in the traditional unsupervised GANs, which cannot generate data when fed with continuous and quantitative labels. RCGAN can autonomously generate graphene/BN hybrids given any target bandgap values. These structures are distinguished from the ones used for training and exhibit high diversity for a given bandgap. Moreover, they exhibit high fidelity, yielding bandgaps within 10% MAEF of the desired bandgaps as validated by density functional theory (DFT) calculations. Analysis by the principle component analysis (PCA) and modified locally linear embedding (MLLE) reveals that the generator has successfully generated structures following the statistical distribution of the real structures. It implies the possibility of the RCGAN in recognizing physical rules hidden in the high-dimensional data. The novel strategy for designing regressional GAN architecture together with the successful application to inverse design of materials would inspire further exploration in research fields beyond materials.}
}

@article{pcdgan,
   title={PcDGAN: A Continuous Conditional Diverse Generative Adversarial Network For Inverse Design},
   ISBN={9781450383325},
   url={http://dx.doi.org/10.1145/3447548.3467414},
   DOI={10.1145/3447548.3467414},
   journal={Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
   publisher={ACM},
   author={Heyrani Nobari, Amin and Chen, Wei and Ahmed, Faez},
   year={2021},
   month={Aug}
}

@inproceedings{park2019deepsdf,
  title={Deepsdf: Learning continuous signed distance functions for shape representation},
  author={Park, Jeong Joon and Florence, Peter and Straub, Julian and Newcombe, Richard and Lovegrove, Steven},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={165--174},
  year={2019}
}


@article{rangegan,
    author = {Heyrani Nobari, Amin and Chen, Wei (Wayne) and Ahmed, Faez},
    title = "{RANGE-GAN: Design Synthesis Under Constraints Using Conditional Generative Adversarial Networks}",
    journal = {Journal of Mechanical Design},
    pages = {1-16},
    year = {2021},
    month = {09},
    abstract = "{Typical engineering design tasks require the effort to modify designs iteratively until they meet certain constraints, i.e., performance or attribute requirements. Past work has proposed ways to solve the inverse design problem, where desired designs are directly generated from specified requirements, thus avoid the trial and error process. Among those approaches, the conditional deep generative model shows great potential since 1) it works for complex high-dimensional designs and 2) it can generate multiple alternative designs given any condition. In this work, we propose a conditional deep generative model, Range-GAN, to achieve automatic design synthesis subject to range constraints. The proposed model addresses the sparse conditioning issue in data-driven inverse design problems by introducing a label-aware self-augmentation approach. We also propose a new uniformity loss to ensure generated designs evenly cover the given requirement range. Through a real-world example of constrained 3D shape generation, we show that the label-aware self-augmentation leads to an average improvement of14\\% on the constraint satisfaction for generated 3D shapes, and the uniformity loss leads to a 125\\% average increase on the uniformity of generated shapes' attributes. This work laid the foundation for data-driven inverse design problems where we consider range constraints and there are sparse regions in the condition space.}",
    issn = {1050-0472},
    doi = {10.1115/1.4052442},
    url = {https://doi.org/10.1115/1.4052442},
    eprint = {https://asmedigitalcollection.asme.org/mechanicaldesign/article-pdf/doi/10.1115/1.4052442/6756741/md-21-1243.pdf},
}

@misc{GCN,
      title={Deep Convolutional Networks on Graph-Structured Data}, 
      author={Mikael Henaff and Joan Bruna and Yann LeCun},
      year={2015},
      eprint={1506.05163},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{li2017gated,
      title={Gated Graph Sequence Neural Networks}, 
      author={Yujia Li and Daniel Tarlow and Marc Brockschmidt and Richard Zemel},
      year={2017},
      eprint={1511.05493},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{GAT,
  title={Graph Attention Networks},
  author={Veli{\v{c}}kovi{\'c}, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Li{\`o}, Pietro and Bengio, Yoshua},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{GTN,
 author = {Yun, Seongjun and Jeong, Minbyul and Kim, Raehyun and Kang, Jaewoo and Kim, Hyunwoo J},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Graph Transformer Networks},
 url = {https://proceedings.neurips.cc/paper/2019/file/9d63484abb477c97640154d40595a3bb-Paper.pdf},
 volume = {32},
 year = {2019}
}

@inproceedings{vashishth2019composition,
  title={Composition-based Multi-Relational Graph Convolutional Networks},
  author={Vashishth, Shikhar and Sanyal, Soumya and Nitin, Vikram and Talukdar, Partha},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{schmidt_cagan_1997, title={GGREADA: A graph grammar-based machine design algorithm}, volume={9}, DOI={10.1007/bf01589682}, number={4}, journal={Research in Engineering Design}, author={Schmidt, Linda C. and Cagan, Jonathan}, year={1997}, pages={195213}}


@inproceedings{10.1115/DETC2020-22355,
    author = {Cao, Weijuan and Robinson, Trevor and Hua, Yang and Boussuge, Flavien and Colligan, Andrew R. and Pan, Wanbin},
    title = "{Graph Representation of 3D CAD Models for Machining Feature Recognition With Deep Learning}",
    volume = {Volume 11A: 46th Design Automation Conference (DAC)},
    series = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
    year = {2020},
    month = {08},
    abstract = "{In this paper, the application of deep learning methods to the task of machining feature recognition in CAD models is studied. Four contributions are made:1. An automatic method to generate large datasets of 3D CAD models is proposed, where each model contains multiple machining features with face labels.2. A concise and informative graph representation for 3D CAD models is presented. This is shown to be applicable to graph neural networks.3. The graph representation is compared with voxels on their performance of training deep neural networks to segment 3D CAD models.4. Experiments are also conducted to evaluate the effectiveness of graph-based deep learning for interacting feature recognition.Results show that the proposed graph representation is a more efficient representation of 3D CAD models than voxels for deep learning. It is also shown that graph neural networks can be used to recognize individual features on the model and also identify complex interacting features.}",
    doi = {10.1115/DETC2020-22355},
    url = {https://doi.org/10.1115/DETC2020-22355},
    note = {V11AT11A003},
    eprint = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-pdf/IDETC-CIE2020/84003/V11AT11A003/6587023/v11at11a003-detc2020-22355.pdf},
}

@article{10.1115/1.4038303,
    author = {Yang, Wenjian and Ding, Huafeng and Zi, Bin and Zhang, Dan},
    title = "{New Graph Representation for Planetary Gear Trains}",
    journal = {Journal of Mechanical Design},
    volume = {140},
    number = {1},
    year = {2017},
    month = {11},
    abstract = "{Planetary gear trains (PGTs) are widely used in machinery to transmit angular velocity ratios or torque ratios. The graph theory has been proved to be an effective tool to synthesize and analyze PGTs. This paper aims to propose a new graph model, which has some merits relative to the existing ones, to represent the structure of PGTs. First, the rotation graph and canonical rotation graph of PGTs are defined. Then, by considering the edge levels in the rotation graph, the displacement graph and canonical displacement graph are defined. Each displacement graph corresponds to a PGT having the specified functional characteristics. The synthesis of five-link one degree-of-freedom (1DOF) PGTs is used as an example to interpret and demonstrate the applicability of the present graph representation in the synthesis process. The present graph representation can completely avoid the generation of pseudo-isomorphic graphs and can be used in the computer-aided synthesis and analysis of PGTs.}",
    issn = {1050-0472},
    doi = {10.1115/1.4038303},
    url = {https://doi.org/10.1115/1.4038303},
    note = {012303},
    eprint = {https://asmedigitalcollection.asme.org/mechanicaldesign/article-pdf/140/1/012303/6231560/md\_140\_01\_012303.pdf},
}


@article{10.1115/1.2916916,
    author = {Hsu, Cheng-Ho and Lam, Kin-Tak},
    title = "{A New Graph Representation for the Automatic Kinematic Analysis of Planetary Spur-Gear Trains}",
    journal = {Journal of Mechanical Design},
    volume = {114},
    number = {1},
    pages = {196-200},
    year = {1992},
    month = {03},
    abstract = "{The purpose of this paper is to propose a new graph representation to represent the kinematic structure of a planetary spur-gear train efficiently. Based on the graph representation, the kinematic analysis of planetary spur-gear trains is largely simplified. An interactive computer program is developed for the kinematic analysis of planetary spur-gear trains with any number of degrees of freedom. By only inputting the graph representation of a planetary spur-gear train and the data for the mating gear pairs, all possible fundamental circuits are determined and the rotational displacement equations are derived and solved automatically.}",
    issn = {1050-0472},
    doi = {10.1115/1.2916916},
    url = {https://doi.org/10.1115/1.2916916},
    eprint = {https://asmedigitalcollection.asme.org/mechanicaldesign/article-pdf/114/1/196/5506580/196\_1.pdf},
}


@article{LEE1996831,
title = {Geometric reasoning for knowledge-based parametric design using graph representation},
journal = {Computer-Aided Design},
volume = {28},
number = {10},
pages = {831-841},
year = {1996},
issn = {0010-4485},
doi = {https://doi.org/10.1016/0010-4485(96)00016-4},
url = {https://www.sciencedirect.com/science/article/pii/0010448596000164},
author = {Jae Yeol Lee and Kwangsoo Kim},
keywords = {parametric design, geometric reasoning, constraint graph, geometric constraints},
abstract = {A promising approach to parametric design is based on the knowledge-based technique. However, one of the major drawbacks in this approach is that the inference process is computationally expensive to be applied to the interactive and intelligent cad systems. This paper presents a new approach to geometric reasoning for knowledge-based parametric design using graph representation to improve the inference process. The geometric reasoning procedure consists of three steps: (1) representing a well-constrained design model and geometric rules into graphs; (2) selecting appropriate subgraphs from the design graph which may be used to induce new facts; and (3) selectively searching for the rule graphs having the same keys as the model subgraphs. The proposed approach is simple in concept, yet realizes significant inference time reduction. The concept presented here has been implemented on an IRIS Indigo workstation, and some implementation results are given to show the efficiency of the proposed approach.}
}


@inproceedings{10.1115/DETC2014-35652,
    author = {Coatana, Eric and Nonsiri, Sarayut and Christophe, Francois and Mokammel, Faisal},
    title = "{Graph Based Representation and Analyses for Conceptual Stages}",
    volume = {Volume 1A: 34th Computers and Information in Engineering Conference},
    series = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
    year = {2014},
    month = {08},
    abstract = "{What is the fundamental similarity between investing in stock of a company, because you like the products of this company, and selecting a design concept, because you have been impressed by the esthetic quality of the presentation made by the team developing the concept?Except that both decisions are based on a surface analysis of the situations, they both reflect a fundamental humans cognitive feature. Human brain is profoundly trying to minimize the efforts required to solve a cognitive task and is using when possible an automatic mode relying on recognition, memory, and causality. This mode is even used in some occasion without the engineer being conscious of it. Such type of tendencies are naturally pushing engineers to rush into known solutions, to avoid analyzing the context of a design problem, to avoid modelling design problems and to take decision based on isolated evidences. Those behaviors are familiar to experience teachers and engineers. This tendency is magnified by the time pressure imposed to the engineering design process. Early phases in particular have to be kept short despite the large impact of decisions taken at this stage. Few support tools are capable of supporting a deep analysis of the early design conditions and problems regarding the fuzziness and complexity of the early stage. The present article is hypothesizing that the natural ability of humans to deal with cause-effects relations push toward the massive usage of causal graphs analysis during the design process and specifically during the early phases. A global framework based on graphs is presented in this paper to efficiently support the early stages. The approach used to generate graphs, to analyze them and to support creativity based on the analysis is forming the central contribution of this paper.}",
    doi = {10.1115/DETC2014-35652},
    url = {https://doi.org/10.1115/DETC2014-35652},
    note = {V01AT02A071},
    eprint = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-pdf/IDETC-CIE2014/46285/V01AT02A071/4257819/v01at02a071-detc2014-35652.pdf},
}

@inproceedings{Patalano2013AGS,
  title={A Graph-based Software Tool for the CAD Modeling of Mechanical Assemblies},
  author={S. Patalano and F. Vitolo and A. Lanzotti},
  booktitle={GRAPP/IVAPP},
  year={2013}
}

@inproceedings{NEURIPS2019_d0921d44,
 author = {Liao, Renjie and Li, Yujia and Song, Yang and Wang, Shenlong and Hamilton, Will and Duvenaud, David K and Urtasun, Raquel and Zemel, Richard},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Efficient Graph Generation with Graph Recurrent Attention Networks},
 url = {https://proceedings.neurips.cc/paper/2019/file/d0921d442ee91b896ad95059d13df618-Paper.pdf},
 volume = {32},
 year = {2019}
}
@inproceedings{bojchevski2018netgan,
  title={NetGAN: Generating Graphs via Random Walks},
  author={Bojchevski, Aleksandar and Shchur, Oleksandr and Z{\"u}gner, Daniel and G{\"u}nnemann, Stephan},
  booktitle={International Conference on Machine Learning},
  pages={609--618},
  year={2018}
}
@inproceedings{you2018graphrnn,
  title={Graphrnn: Generating realistic graphs with deep auto-regressive models},
  author={You, Jiaxuan and Ying, Rex and Ren, Xiang and Hamilton, William and Leskovec, Jure},
  booktitle={International conference on machine learning},
  pages={5708--5717},
  year={2018},
  organization={PMLR}
}

@misc{li2018learning,
      title={Learning Deep Generative Models of Graphs}, 
      author={Yujia Li and Oriol Vinyals and Chris Dyer and Razvan Pascanu and Peter Battaglia},
      year={2018},
      eprint={1803.03324},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{decao2018molgan,
      title={MolGAN: An implicit generative model for small molecular graphs}, 
      author={Nicola De Cao and Thomas Kipf},
      year={2018},
      eprint={1805.11973},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
@inproceedings{you2018graph,
  title={Graph convolutional policy network for goal-directed molecular graph generation},
  author={You, Jiaxuan and Liu, Bowen and Ying, Rex and Pande, Vijay and Leskovec, Jure},
  booktitle={Proceedings of the 32nd International Conference on Neural Information Processing Systems},
  pages={6412--6422},
  year={2018}
}


@inproceedings{10.1115/DETC2013-13058,
    author = {Hooshmand, Amir and Campbell, Matthew I.},
    title = "{Topology Optimization of Fluid Channels Using Generative Graph Grammars}",
    volume = {Volume 3A: 39th Design Automation Conference},
    series = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
    year = {2013},
    month = {08},
    abstract = "{This paper presents a new technique for topology optimization of fluid channels using generative design methods. The proposed method uses the generative abilities of graph grammars with simulation and analysis power of conventional CFD methods. The graph grammar interpreter GraphSynth is used to carry out graph transformations, which define different topologies for a given multi-inlet multi-outlet problem. The generated graphs are first transformed into meaningful 3D shapes. These solutions are then analyzed by a CFD solver to find the optimum. The effectiveness of the proposed method is checked by solving a variety of available test problems and comparing them with those found in the literature. Furthermore by solving complex problems the robustness and effectiveness of the method is tested.}",
    doi = {10.1115/DETC2013-13058},
    url = {https://doi.org/10.1115/DETC2013-13058},
    note = {V03AT03A009},
    eprint = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-pdf/IDETC-CIE2013/55881/V03AT03A009/4253648/v03at03a009-detc2013-13058.pdf},
}

@article{chen2021mopadgan,
  title={MO-PaDGAN: Reparameterizing Engineering Designs for augmented multi-objective optimization},
  author={Chen, Wei and Ahmed, Faez},
  journal={Applied Soft Computing},
  volume={113},
  pages={107909},
  year={2021},
  publisher={Elsevier}
}

@article{FEA1, title={A deep learning approach to estimate stress distribution: a fast and accurate surrogate of finite-element analysis}, volume={15}, DOI={10.1098/rsif.2017.0844}, number={138}, journal={Journal of The Royal Society Interface}, author={Liang, Liang and Liu, Minliang and Martin, Caitlin and Sun, Wei}, year={2018}, pages={20170844}}

@inproceedings{FEA2,
    author = {Jiang, Haoliang and Nie, Zhenguo and Yeo, Roselyn and Farimani, Amir Barati and Kara, Levent Burak},
    title = "{StressGAN: A Generative Deep Learning Model for 2D Stress Distribution Prediction}",
    volume = {Volume 11B: 46th Design Automation Conference (DAC)},
    series = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
    year = {2020},
    month = {08},
    abstract = "{Using deep learning to analyze mechanical stress distributions has been gaining interest with the demand for fast stress analysis methods. Deep learning approaches have achieved excellent outcomes when utilized to speed up stress computation and learn the physics without prior knowledge of underlying equations. However, most studies restrict the variation of geometry or boundary conditions, making these methods difficult to be generalized to unseen configurations. We propose a conditional generative adversarial network (cGAN) model for predicting 2D von Mises stress distributions in solid structures. The cGAN learns to generate stress distributions conditioned by geometries, load, and boundary conditions through a two-player minimax game between two neural networks with no prior knowledge. By evaluating the generative network on two stress distribution datasets under multiple metrics, we demonstrate that our model can predict more accurate high-resolution stress distributions than a baseline convolutional neural network model, given various and complex cases of geometry, load and boundary conditions.}",
    doi = {10.1115/DETC2020-22682},
    url = {https://doi.org/10.1115/DETC2020-22682},
    note = {V11BT11A023},
    eprint = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-pdf/IDETC-CIE2020/84010/V11BT11A023/6587193/v11bt11a023-detc2020-22682.pdf},
}


@inproceedings{FEA3,
    author = {Nie, Zhenguo and Jiang, Haoliang and Kara, Levent Burak},
    title = "{Stress Field Prediction in Cantilevered Structures Using Convolutional Neural Networks}",
    volume = {Volume 1: 39th Computers and Information in Engineering Conference},
    series = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
    year = {2019},
    month = {08},
    abstract = "{The demand for fast and accurate structural analysis is becoming increasingly more prevalent with the advance of generative design and topology optimization technologies. As one step toward accelerating structural analysis, this work explores a deep learning based approach for predicting the stress fields in 2D linear elastic cantilevered structures subjected to external static loads at its free end using convolutional neural networks (CNN). Two different architectures are implemented that take as input the structure geometry, external loads, and displacement boundary conditions, and output the predicted von Mises stress field. The first is a single input channel network called SCSNet as the baseline architecture, and the second is the multi-channel input network called StressNet. Accuracy analysis shows that StressNet results in significantly lower prediction errors than SCSNet on three loss functions, with a mean relative error of 2.04\\% for testing. These results suggest that deep learning models may offer a promising alternative to classical methods in structural design and topology optimization. Code and dataset are available at https://github.com/zhenguonie/stress\_net.}",
    doi = {10.1115/DETC2019-98472},
    url = {https://doi.org/10.1115/DETC2019-98472},
    note = {V001T02A011},
    eprint = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-pdf/IDETC-CIE2019/59179/V001T02A011/6452733/v001t02a011-detc2019-98472.pdf},
}

@article{FEA4,
  title={Generalizable surrogate model features to approximate stress in 3D trusses},
  author={M. Nourbakhsh and J. Irizarry and J. Haymaker},
  journal={Eng. Appl. Artif. Intell.},
  year={2018},
  volume={71},
  pages={15-27}
}

@article{FEA5, title={Deep learningbased stress prediction for bottom-up SLA 3D printing process}, volume={102}, DOI={10.1007/s00170-019-03363-4}, number={5-8}, journal={The International Journal of Advanced Manufacturing Technology}, author={Khadilkar, Aditya and Wang, Jun and Rai, Rahul}, year={2019}, pages={25552569}}

@article{FEA6, title={Prediction of residual stresses in girth welded pipes using an artificial neural network approach}, volume={150}, DOI={10.1016/j.ijpvp.2017.01.002}, journal={International Journal of Pressure Vessels and Piping}, author={Mathew, J. and Moat, R.j. and Paddea, S. and Fitzpatrick, M.e. and Bouchard, P.j.}, year={2017}, pages={8995}}

@article{FEA7, title={Shear stress distribution prediction in symmetric compound channels using data mining and machine learning models}, volume={14}, DOI={10.1007/s11709-020-0634-3}, number={5}, journal={Frontiers of Structural and Civil Engineering}, author={Khozani, Zohreh Sheikh and Khosravi, Khabat and Torabi, Mohammadamin and Mosavi, Amir and Rezaei, Bahram and Rabczuk, Timon}, year={2020}, pages={10971109}}

@article{FEA8,
   title={Stress Field Prediction in Cantilevered Structures Using Convolutional Neural Networks},
   volume={20},
   ISSN={1944-7078},
   url={http://dx.doi.org/10.1115/1.4044097},
   DOI={10.1115/1.4044097},
   number={1},
   journal={Journal of Computing and Information Science in Engineering},
   publisher={ASME International},
   author={Nie, Zhenguo and Jiang, Haoliang and Kara, Levent Burak},
   year={2019},
   month={Sep}
}

@article{FEA9, title={Bridging Finite Element and Machine Learning Modeling: Stress Prediction of Arterial Walls in Atherosclerosis}, volume={141}, DOI={10.1115/1.4043290}, number={8}, journal={Journal of Biomechanical Engineering}, author={Madani, Ali and Bakhaty, Ahmed and Kim, Jiwon and Mubarak, Yara and Mofrad, Mohammad R. K.}, year={2019}}

@article{CFD1, title={Machine learningaccelerated computational fluid dynamics}, volume={118}, DOI={10.1073/pnas.2101784118}, number={21}, journal={Proceedings of the National Academy of Sciences}, author={Kochkov, Dmitrii and Smith, Jamie A. and Alieva, Ayya and Wang, Qing and Brenner, Michael P. and Hoyer, Stephan}, year={2021}}

@article{CFD2, title={Reynolds averaged turbulence modelling using deep neural networks with embedded invariance}, volume={807}, DOI={10.1017/jfm.2016.615}, journal={Journal of Fluid Mechanics}, publisher={Cambridge University Press}, author={Ling, Julia and Kurzawski, Andrew and Templeton, Jeremy}, year={2016}, pages={155166}}

@article{CFD3,
author = {Duraisamy, Karthik and Iaccarino, Gianluca and Xiao, Heng},
title = {Turbulence Modeling in the Age of Data},
journal = {Annual Review of Fluid Mechanics},
volume = {51},
number = {1},
pages = {357-377},
year = {2019},
doi = {10.1146/annurev-fluid-010518-040547},

URL = { 
        https://doi.org/10.1146/annurev-fluid-010518-040547
    
},
eprint = { 
        https://doi.org/10.1146/annurev-fluid-010518-040547
    
}
,
    abstract = { Data from experiments and direct simulations of turbulence have historically been used to calibrate simple engineering models such as those based on the Reynolds-averaged NavierStokes (RANS) equations. In the past few years, with the availability of large and diverse data sets, researchers have begun to explore methods to systematically inform turbulence models with data, with the goal of quantifying and reducing model uncertainties. This review surveys recent developments in bounding uncertainties in RANS models via physical constraints, in adopting statistical inference to characterize model coefficients and estimate discrepancy, and in using machine learning to improve turbulence models. Key principles, achievements, and challenges are discussed. A central perspective advocated in this review is that by exploiting foundational knowledge in turbulence modeling and physical constraints, researchers can use data-driven approaches to yield useful predictive models. }
}

@article{CFD4,
   title={Subgrid modelling for two-dimensional turbulence using neural networks},
   volume={858},
   ISSN={1469-7645},
   url={http://dx.doi.org/10.1017/jfm.2018.770},
   DOI={10.1017/jfm.2018.770},
   journal={Journal of Fluid Mechanics},
   publisher={Cambridge University Press (CUP)},
   author={Maulik, R. and San, O. and Rasheed, A. and Vedula, P.},
   year={2018},
   month={Nov},
   pages={122144}
}

@article{CFD5,
   title={Deep Fluids: A Generative Network for Parameterized Fluid Simulations},
   volume={38},
   ISSN={1467-8659},
   url={http://dx.doi.org/10.1111/cgf.13619},
   DOI={10.1111/cgf.13619},
   number={2},
   journal={Computer Graphics Forum},
   publisher={Wiley},
   author={Kim, Byungsoo and Azevedo, Vinicius C. and Thuerey, Nils and Kim, Theodore and Gross, Markus and Solenthaler, Barbara},
   year={2019},
   month={May},
   pages={5970}
}

@misc{CFD6,
      title={Towards Physics-informed Deep Learning for Turbulent Flow Prediction}, 
      author={Rui Wang and Karthik Kashinath and Mustafa Mustafa and Adrian Albert and Rose Yu},
      year={2020},
      eprint={1911.08655},
      archivePrefix={arXiv},
      primaryClass={physics.comp-ph}
}

@inproceedings{CFD7,
  title={Accelerating eulerian fluid simulation with convolutional networks},
  author={Tompson, Jonathan and Schlachter, Kristofer and Sprechmann, Pablo and Perlin, Ken},
  booktitle={International Conference on Machine Learning},
  pages={3424--3433},
  year={2017},
  organization={PMLR}
}


@inproceedings{CFD8,
author = {Obiols-Sales, Octavi and Vishnu, Abhinav and Malaya, Nicholas and Chandramowliswharan, Aparna},
title = {CFDNet: A Deep Learning-Based Accelerator for Fluid Simulations},
year = {2020},
isbn = {9781450379830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3392717.3392772},
doi = {10.1145/3392717.3392772},
abstract = {CFD is widely used in physical system design and optimization, where it is used to
predict engineering quantities of interest, such as the lift on a plane wing or the
drag on a motor vehicle. However, many systems of interest are prohibitively expensive
for design optimization, due to the expense of evaluating CFD simulations.To render
the computation tractable, reduced-order or surrogate models are used to accelerate
simulations while respecting the convergence constraints provided by the higher-fidelity
solution. This paper introduces CFDNet - a physical simulation and deep learning coupled
framework, for accelerating the convergence of Reynolds Averaged Navier-Stokes simulations.
CFDNet is designed to predict the primary physical properties of the fluid including
velocity, pressure, and eddy viscosity using a single convolutional neural network
at its core. We evaluate CFDNet on a variety of use-cases, both extrapolative and
interpolative, where test geometries are observed/not-observed during training. Our
results show that CFDNet meets the convergence constraints of the domain-specific
physics solver while outperforming it by 1.9 - 7.4X on both steady laminar and turbulent
flows. Moreover, we demonstrate the generalization capacity of CFDNet by testing its
prediction on new geometries unseen during training. In this case, the approach meets
the CFD convergence criterion while still providing significant speedups over traditional
domain-only models.},
booktitle = {Proceedings of the 34th ACM International Conference on Supercomputing},
articleno = {3},
numpages = {12},
keywords = {deep learning, AI for science, physics-machine learning coupled framework, computational fluid dynamics, turbulent flows},
location = {Barcelona, Spain},
series = {ICS '20}
}

@misc{CFD9,
      title={Using Machine Learning to Augment Coarse-Grid Computational Fluid Dynamics Simulations}, 
      author={Jaideep Pathak and Mustafa Mustafa and Karthik Kashinath and Emmanuel Motheau and Thorsten Kurth and Marcus Day},
      year={2020},
      eprint={2010.00072},
      archivePrefix={arXiv},
      primaryClass={physics.comp-ph}
}

@inproceedings{elgammal2017can,
  title={CAN: Creative adversarial networks generating Art by learning about styles and deviating from style norms},
  author={Elgammal, Ahmed and Liu, Bingchen and Elhoseiny, Mohamed and Mazzone, Marian},
  booktitle={8th International Conference on Computational Creativity, ICCC 2017},
  year={2017},
  organization={Georgia Institute of Technology}
}

@article{SARKAR2011348,
title = {Assessing design creativity},
journal = {Design Studies},
volume = {32},
number = {4},
pages = {348-383},
year = {2011},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2011.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X11000111},
author = {Prabir Sarkar and Amaresh Chakrabarti},
keywords = {creativity, engineering design, measure creativity},
abstract = {Creativity is crucial for designing products and enabling innovation. Assessing creativity can help identify innovative designers and products, and support improvement of both. The literature variously defines creativity as a function of degree of novelty, usefulness, or both. Most methods for assessing creativity, however, focus only on assessing novelty of products. This research proposes a new method for assessing the creativity of products as a function of their novelty and usefulness. We develop individual methods for assessing novelty and usefulness of products, and then combine these into a method for assessing creativity of products. The proposed methods have been evaluated by benchmarking them, and other methods available from literature, against the collective, intuitive assessment of product creativity of experienced designers.}
}

@misc{franceschelli2021creativity,
      title={Creativity and Machine Learning: A Survey}, 
      author={Giorgio Franceschelli and Mirco Musolesi},
      year={2021},
      eprint={2104.02726},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{CFD10,
  title={Learning Mesh-Based Simulation with Graph Networks},
  author={Pfaff, Tobias and Fortunato, Meire and Sanchez-Gonzalez, Alvaro and Battaglia, Peter},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{xue2020machine,
  title={Machine learning generative models for automatic design of multi-material 3D printed composite solids},
  author={Xue, Tianju and Wallin, Thomas J and Menguc, Yigit and Adriaenssens, Sigrid and Chiaramonte, Maurizio},
  journal={Extreme Mechanics Letters},
  volume={41},
  pages={100992},
  year={2020},
  publisher={Elsevier}
}

@article{jung2021super,
  title={Super-resolving material microstructure image via deep learning for microstructure characterization and mechanical behavior analysis},
  author={Jung, Jaimyun and Na, Juwon and Park, Hyung Keun and Park, Jeong Min and Kim, Gyuwon and Lee, Seungchul and Kim, Hyoung Seop},
  journal={npj Computational Materials},
  volume={7},
  number={1},
  pages={1--11},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{stump2019spatial,
  title={Spatial Grammar-Based Recurrent Neural Network for Design Form and Behavior Optimization},
  author={Stump, Gary M and Miller, Simon W and Yukish, Michael A and Simpson, Timothy W and Tucker, Conrad},
  journal={Journal of Mechanical Design},
  volume={141},
  number={12},
  year={2019},
  publisher={American Society of Mechanical Engineers Digital Collection}
}

@inproceedings{jiang2017variational,
  title={Variational deep embedding: an unsupervised and generative approach to clustering},
  author={Jiang, Zhuxi and Zheng, Yin and Tan, Huachun and Tang, Bangsheng and Zhou, Hanning},
  booktitle={Proceedings of the 26th International Joint Conference on Artificial Intelligence},
  pages={1965--1972},
  year={2017}
}

@inproceedings{chen2021geometry, title={GEOMETRY ENHANCED GENERATIVE ADVERSARIAL NETWORKS FOR RANDOM
HETEROGENEOUS MATERIAL REPRESENTATION}, author={Chen, Hongrui and Liu, Xingchen}, booktitle={International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, {IDETC-21}}, organization={ASME}, day = {17-20},month = {Aug}, address = {Virtual, Online}, year={2021}}

@article{fokina2020microstructure,
  title={Microstructure synthesis using style-based generative adversarial networks},
  author={Fokina, Daria and Muravleva, Ekaterina and Ovchinnikov, George and Oseledets, Ivan},
  journal={Physical Review E},
  volume={101},
  number={4},
  pages={043308},
  year={2020},
  publisher={APS}
}

@inproceedings{karras2019style,
  author={Karras, Tero and Laine, Samuli and Aila, Timo},

  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 

  title={A Style-Based Generator Architecture for Generative Adversarial Networks}, 

  year={2019},

  volume={},

  number={},

  pages={4396-4405},

  doi={10.1109/CVPR.2019.00453},
  location = {Long Beach, CA, USA}
}

@article{volkhonskiy2019reconstruction,
  title={Reconstruction of 3d porous media from 2d slices},
  author={Volkhonskiy, Denis and Muravleva, Ekaterina and Sudakov, Oleg and Orlov, Denis and Belozerov, Boris and Burnaev, Evgeny and Koroteev, Dmitry},
  journal={arXiv preprint arXiv:1901.10233},
  year={2019}
}

@article{mosser2017reconstruction,
  title={Reconstruction of three-dimensional porous media using generative adversarial neural networks},
  author={Mosser, Lukas and Dubrule, Olivier and Blunt, Martin J},
  journal={Physical Review E},
  volume={96},
  number={4},
  pages={043309},
  year={2017},
  publisher={APS}
}


@article{cang2017microstructure,
  title={Microstructure representation and reconstruction of heterogeneous materials via deep belief network for computational material design},
  author={Cang, Ruijin and Xu, Yaopengxiao and Chen, Shaohua and Liu, Yongming and Jiao, Yang and Yi Ren, Max},
  journal={Journal of Mechanical Design},
  volume={139},
  number={7},
  pages={071404},
  year={2017},
  publisher={American Society of Mechanical Engineers}
}

@inproceedings{xu2021a,
	title="A Bayesian-Symbolic Approach to Learning and Reasoning for Intuitive Physics",
	author="Kai {Xu} and Akash {Srivastava} and Dan {Gutfreund} and Felix {Sosa} and Tomer {Ullman} and Joshua B. {Tenenbaum} and Charles {Sutton}",
	booktitle="",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/3130844156",
	year="2021"
}

@article{liu2019case,
  title={A case study on homogeneous and heterogeneous reservoir porous media reconstruction by using generative adversarial networks},
  author={Liu, Siyan and Zhong, Zhi and Takbiri-Borujeni, Ali and Kazemi, Mohammad and Fu, Qinwen and Yang, Yuhao},
  journal={Energy Procedia},
  volume={158},
  pages={6164--6169},
  year={2019},
  publisher={Elsevier}
}

@article{dilokthanakul2016deep,
  title={Deep unsupervised clustering with gaussian mixture variational autoencoders},
  author={Dilokthanakul, Nat and Mediano, Pedro AM and Garnelo, Marta and Lee, Matthew CH and Salimbeni, Hugh and Arulkumaran, Kai and Shanahan, Murray},
  journal={arXiv preprint arXiv:1611.02648},
  year={2016}
}

@inproceedings{Wang2021gaussian, 
title={A GAUSSIAN MIXTURE VARIATIONAL AUTOENCODER-BASED APPROACH FOR 
DESIGNING PHONONIC BANDGAP METAMATERIALS}, author={Wang, Zihan and Xian, Weikang and Baccouche, M. Ridha and Lanzerath, Horst and Li, Ying and Xu, Hongyi}, booktitle={International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, {IDETC-21}}, organization={ASME}, day = {17-20},month = {Aug}, address = {Virtual, Online}, year={2021}}

@inproceedings{Valdez2021framework, title={A FRAMEWORK FOR INTERACTIVE STRUCTURAL DESIGN EXPLORATION}, author={Valdez, Sofia and Seepersad, Carolyn and Kambampati, Sandilya}, booktitle={International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, {IDETC-21}}, organization={ASME}, day = {17-20},month = {Aug}, address = {Virtual, Online}, year={2021}}

@inproceedings{NIPS2017_3f5ee243,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@inproceedings{song2021denoising,
title={Denoising Diffusion Implicit Models},
author={Jiaming Song and Chenlin Meng and Stefano Ermon},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=St1giarCHLP}
}

@misc{ramesh2021zeroshot,
      title={Zero-Shot Text-to-Image Generation}, 
      author={Aditya Ramesh and Mikhail Pavlov and Gabriel Goh and Scott Gray and Chelsea Voss and Alec Radford and Mark Chen and Ilya Sutskever},
      year={2021},
      eprint={2102.12092},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@InProceedings{pmlr-v119-chen20s,
  title = 	 {Generative Pretraining From Pixels},
  author =       {Chen, Mark and Radford, Alec and Child, Rewon and Wu, Jeffrey and Jun, Heewoo and Luan, David and Sutskever, Ilya},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {1691--1703},
  year = 	 {2020},
  editor = 	 {III, Hal Daum and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/chen20s/chen20s.pdf},
  url = 	 {https://proceedings.mlr.press/v119/chen20s.html},
  abstract = 	 {Inspired by progress in unsupervised representation learning for natural language, we examine whether similar models can learn useful representations for images. We train a sequence Transformer to auto-regressively predict pixels, without incorporating knowledge of the 2D input structure. Despite training on low-resolution ImageNet without labels, we find that a GPT-2 scale model learns strong image representations as measured by linear probing, fine-tuning, and low-data classification. On CIFAR-10, we achieve 96.3\% accuracy with a linear probe, outperforming a supervised Wide ResNet, and 99.0\% accuracy with full fine-tuning, matching the top supervised pre-trained models. We are also competitive with self-supervised benchmarks on ImageNet when substituting pixels for a VQVAE encoding, achieving 69.0\% top-1 accuracy on a linear probe of our features.}
}
@misc{dhariwal2020jukebox,
      title={Jukebox: A Generative Model for Music}, 
      author={Prafulla Dhariwal and Heewoo Jun and Christine Payne and Jong Wook Kim and Alec Radford and Ilya Sutskever},
      year={2020},
      eprint={2005.00341},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}


@article{raina2021goal,
  title={Goal-Directed Design Agents: Integrating Visual Imitation With One-Step Lookahead Optimization for Generative Design},
  author={Raina, Ayush and Puentes, Lucas and Cagan, Jonathan and McComb, Christopher},
  journal={Journal of Mechanical Design},
  volume={143},
  number={12},
  pages={124501},
  year={2021},
  publisher={American Society of Mechanical Engineers}
}

@article{raina2019learning,
  title={Learning to design from humans: Imitating human designers through deep learning},
  author={Raina, Ayush and McComb, Christopher and Cagan, Jonathan},
  journal={Journal of Mechanical Design},
  volume={141},
  number={11},
  year={2019},
  publisher={American Society of Mechanical Engineers Digital Collection}
}

@article{mccomb2018data,
  title={Data on the design of truss structures by teams of engineering students},
  author={McComb, Christopher and Cagan, Jonathan and Kotovsky, Kenneth},
  journal={Data in brief},
  volume={18},
  pages={160--163},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{puentes2020modeling,
  title={Modeling A Strategic Human Engineering Design Process: Human-Inspired Heuristic Guidance Through Learned Visual Design Agents},
  author={Puentes, L and Raina, A and Cagan, J and McComb, C},
  booktitle={Proceedings of the Design Society: DESIGN Conference},
  volume={1},
  pages={355--364},
  year={2020},
  organization={Cambridge University Press}
}

@article{yukish2020using,
  title={Using Recurrent Neural Networks to Model Spatial Grammars for Design Creation},
  author={Yukish, Michael A and Stump, Gary M and Miller, Simon W},
  journal={Journal of Mechanical Design},
  volume={142},
  number={10},
  pages={104501},
  year={2020},
  publisher={American Society of Mechanical Engineers}
}


@inproceedings{10.1115/DETC2016-59404,
    author = {Cang, Ruijin and Ren, Max Yi},
    title = "{Deep Network-Based Feature Extraction and Reconstruction of Complex Material Microstructures}",
    volume = {Volume 2B: 42nd Design Automation Conference},
    series = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
    year = {2016},
    month = {08},
    abstract = "{Computational material design (CMD) aims to accelerate optimal design of complex material systems by integrating material science and design automation. For tractable CMD, it is required that (1) a feature space be identified to allow reconstruction of new designs, and (2) the reconstruction process be property-preserving. Existing solutions rely on the designers understanding of specific material systems to identify geometric and statistical features, which could be insufficient for reconstructing physically meaningful microstructures of complex material systems. This paper develops a feature learning mechanism that automates a two-way conversion between microstructures and their lower-dimensional feature representations. The proposed model is applied to four material systems: Ti-6Al-4V alloy, Pb-Sn alloy, Fontainebleau sandstone, and spherical colloids, to produce random reconstructions that are visually similar to the samples. This capability is not achieved by existing synthesis methods relying on the Markovian assumption of material systems. For Ti-6Al-4V alloy, we also show that the reconstructions preserve the mean critical fracture force of the system for a fixed processing setting. Source code and datasets are available.}",
    doi = {10.1115/DETC2016-59404},
    url = {https://doi.org/10.1115/DETC2016-59404},
    note = {V02BT03A008},
    eprint = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-pdf/IDETC-CIE2016/50114/V02BT03A008/2471310/v02bt03a008-detc2016-59404.pdf},
}

@article{10.1115/1.4048422,
    author = {Deshpande, Shrinath and Purwar, Anurag},
    title = "{An Image-Based Approach to Variational Path Synthesis of Linkages}",
    journal = {Journal of Computing and Information Science in Engineering},
    volume = {21},
    number = {2},
    year = {2020},
    month = {10},
    abstract = "{This paper brings together computer vision, mechanism synthesis, and machine learning to create an image-based variational path synthesis approach for linkage mechanisms. An image-based approach is particularly amenable to mechanism synthesis when the input from mechanism designers is deliberately imprecise or inherently uncertain due to the nature of the problem. In addition, it also lends itself naturally to the creation of a unified approach to mechanism synthesis for different types of mechanisms, since for example, images are formed from a collection of pixels, which themselves could be generated from a four-bar or six-bar. Path synthesis problems have generally been solved for a set of precision points on the intended path such that the designed mechanism passes through those points. This approach usually leads to a small set of over-fitted solutions to particular precision points. However, most kinematic synthesis problems are concept generation problems, where a designer cares more about generating a large number of plausible solutions, which could reach given precision points only approximately. This paper models the input curve as a probability distribution of image pixels and employs a probabilistic generative model to capture the inherent uncertainty in the input. In addition, it gives feedback on the input quality and provides corrections for a more conducive input. The image representation allows for capturing local spatial correlations, which plays an important role in finding a variety of solutions with similar semantics as the input curve. This approach is also conducive to implementation for pressure-sensitive touch-based design interfaces, where the input is not a zero-thickness curve, but the sweep of a small patch on the finger.}",
    issn = {1530-9827},
    doi = {10.1115/1.4048422},
    url = {https://doi.org/10.1115/1.4048422},
    note = {021005},
    eprint = {https://asmedigitalcollection.asme.org/computingengineering/article-pdf/21/2/021005/6577132/jcise\_21\_2\_021005.pdf},
}

@inproceedings{10.1115/DETC2019-97711,
    author = {Lopez, Christian E. and Ashour, Omar and Tucker, Conrad S.},
    title = "{Reinforcement Learning Content Generation for Virtual Reality Applications}",
    volume = {Volume 1: 39th Computers and Information in Engineering Conference},
    series = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
    year = {2019},
    month = {08},
    abstract = "{This work presents a Procedural Content Generation (PCG) method based on a Neural Network Reinforcement Learning (RL) approach that generates new environments for Virtual Reality (VR) learning applications. The primary objective of PCG methods is to algorithmically generate new content (e.g., environments, levels) in order to improve user experience. Researchers have started exploring the integration of Machine Learning (ML) algorithms into their PCG methods. These ML approaches help explore the design space and generate new content more efficiently. The capability to provide users with new content has great potential for learning applications. However, these ML algorithms require large datasets to train their generative models. In contrast, RL based methods take advantage of simulation to train their models. Moreover, even though VR has become an emerging technology to engage users, there have been few studies that explore PCG for learning purposes and fewer in the context of VR. Considering these limitations, this work presents a method that generates new VR environments by training an RL agent using a simulation platform. This PCG method has the potential to maintain users engagement over time by presenting them with new environments in VR learning applications.}",
    doi = {10.1115/DETC2019-97711},
    url = {https://doi.org/10.1115/DETC2019-97711},
    note = {V001T02A009},
    eprint = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-pdf/IDETC-CIE2019/59179/V001T02A009/6452689/v001t02a009-detc2019-97711.pdf},
}


@inproceedings{10.1115/DETC2020-22624,
    author = {Cunningham, James and Lopez, Christian and Ashour, Omar and Tucker, Conrad S.},
    title = "{Multi-Context Generation in Virtual Reality Environments Using Deep Reinforcement Learning}",
    volume = {Volume 9: 40th Computers and Information in Engineering Conference (CIE)},
    series = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
    year = {2020},
    month = {08},
    abstract = "{In this work, a Deep Reinforcement Learning (RL) approach is proposed for Procedural Content Generation (PCG) that seeks to automate the generation of multiple related virtual reality (VR) environments for enhanced personalized learning. This allows for the user to be exposed to multiple virtual scenarios that demonstrate a consistent theme, which is especially valuable in an educational context. RL approaches to PCG offer the advantage of not requiring training data, as opposed to other PCG approaches that employ supervised learning approaches. This work advances the state of the art in RL-based PCG by demonstrating the ability to generate a diversity of contexts in order to teach the same underlying concept. A case study is presented that demonstrates the feasibility of the proposed RL-based PCG method using examples of probability distributions in both manufacturing facility and grocery store virtual environments. The method demonstrated in this paper has the potential to enable the automatic generation of a variety of virtual environments that are connected by a common concept or theme.}",
    doi = {10.1115/DETC2020-22624},
    url = {https://doi.org/10.1115/DETC2020-22624},
    note = {V009T09A072},
    eprint = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-pdf/IDETC-CIE2020/83983/V009T09A072/6586781/v009t09a072-detc2020-22624.pdf},
}

@article{chakrabarti2011computer,
    author = {Chakrabarti, Amaresh and Shea, Kristina and Stone, Robert and Cagan, Jonathan and Campbell, Matthew and Hernandez, Noe Vargas and Wood, Kristin L.},
    title = "{Computer-Based Design Synthesis Research: An Overview}",
    journal = {Journal of Computing and Information Science in Engineering},
    volume = {11},
    number = {2},
    year = {2011},
    month = {06},
    abstract = "{One of the hallmarks of engineering design is the design synthesis phase where the creativity of the designer most prominently comes into play as solutions are generated to meet underlying needs. Over the past decades, methodologies for generating concepts and design solutions have matured to the point that computation-based synthesis provides a means to explore a wider variety of solutions and take over more tedious design tasks. This paper reviews advances in function-based, grammar-based, and analogy-based synthesis approaches and their contributions to computational design synthesis research in the last decade.}",
    issn = {1530-9827},
    doi = {10.1115/1.3593409},
    url = {https://doi.org/10.1115/1.3593409},
    note = {021003},
    eprint = {https://asmedigitalcollection.asme.org/computingengineering/article-pdf/11/2/021003/5566343/021003\_1.pdf},
}
@article{deng2014deep,
author = {Deng, Li and Yu, Dong},
title = {Deep Learning: Methods and Applications},
year = {2014},
issue_date = {June 2014},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {7},
number = {34},
issn = {1932-8346},
url = {https://doi.org/10.1561/2000000039},
doi = {10.1561/2000000039},
abstract = {This monograph provides an overview of general deep learning methodology and its applications to a variety of signal and information processing tasks. The application areas are chosen with the following three criteria in mind: (1) expertise or knowledge of the authors; (2) the application areas that have already been transformed by the successful use of deep learning technology, such as speech recognition and computer vision; and (3) the application areas that have the potential to be impacted significantly by deep learning and that have been experiencing research growth, including natural language and text processing, information retrieval, and multimodal information processing empowered by multi-task deep learning.},
journal = {Found. Trends Signal Process.},
month = {jun},
pages = {197387},
numpages = {191},
keywords = {Computer vision, Hybrid deep networks, Machine learning, Deep stacking networks, Artificial intelligence, Natural language processing, Deep learning, Unsupervised learning, Supervised learning, Neural networks, Deep neural networks, Multi-task learning, Autoencoders, Language models, Multi-modal processing, Object recognition}
}

@inproceedings{toh2013exploring,
  title={Exploring the utility of product dissection for early-phase idea generation},
  author={Toh, Christine A and Miller, Scarlett R},
  booktitle={International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
  volume={55928},
  pages={V005T06A034},
  year={2013},
  organization={American Society of Mechanical Engineers}
}

@article{guest_editorial,
    author = {Panchal, Jitesh H. and Fuge, Mark and Liu, Ying and Missoum, Samy and Tucker, Conrad},
    title = "{Special Issue: Machine Learning for Engineering Design}",
    journal = {Journal of Mechanical Design},
    volume = {141},
    number = {11},
    year = {2019},
    month = {10},
    abstract = "{Modern machine learning (ML) techniques are transforming many disciplines ranging from transportation to healthcare by uncovering patterns in data, developing autonomous systems that mimic human abilities, and supporting human decision-making. Modern ML techniques, such as deep neural networks, are fueling the rapid developments in artificial intelligence. Engineering design researchers have increasingly used and developed ML techniques to support a wide range of activities from preference modeling to uncertainty quantification in high-dimensional design optimization problems. This special issue brings together fundamental scientific contributions across these areas.}",
    issn = {1050-0472},
    doi = {10.1115/1.4044690},
    url = {https://doi.org/10.1115/1.4044690},
    note = {110301},
    eprint = {https://asmedigitalcollection.asme.org/mechanicaldesign/article-pdf/141/11/110301/6578324/md\_141\_11\_110301.pdf},
}


@article{zhao2018nanomine,
  title={NanoMine schema: An extensible data representation for polymer nanocomposites},
  author={Zhao, He and Wang, Yixing and Lin, Anqi and Hu, Bingyin and Yan, Rui and McCusker, James and Chen, Wei and McGuinness, Deborah L and Schadler, Linda and Brinson, L Catherine},
  journal={APL Materials},
  volume={6},
  number={11},
  pages={111108},
  year={2018},
  publisher={AIP Publishing LLC}
}

@misc{regenwetter2022framed,
      title={FRAMED: Data-Driven Structural Performance Analysis of Community-Designed Bicycle Frames}, 
      author={Lyle Regenwetter and Colin Weaver and Faez Ahmed},
      year={2022},
      eprint={2201.10459},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{giannone2022few,
  title={Few-shot diffusion models},
  author={Giannone, Giorgio and Nielsen, Didrik and Winther, Ole},
  journal={arXiv preprint arXiv:2205.15463},
  year={2022}
}

@article{meng2022distillation,
  title={On distillation of guided diffusion models},
  author={Meng, Chenlin and Gao, Ruiqi and Kingma, Diederik P and Ermon, Stefano and Ho, Jonathan and Salimans, Tim},
  journal={arXiv preprint arXiv:2210.03142},
  year={2022}
}

@article{Bangaetal2018,
    title = {{3D Topology Optimization using Convolutional Neural Networks}},
    year = {2018},
    journal = {Preprint},
    author = {Banga, Saurabh and Gehani, Harsh and Bhilare, Sanket and Patel, Sagar and Kara, Levent},
    month = {8},
    url = {http://arxiv.org/abs/1808.07440},
    arxivId = {1808.07440}
}

@article{WangZhaoZhou2021,
    title = {{A comprehensive review of educational articles on structural and multidisciplinary optimization}},
    year = {2021},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Wang, Chao and Zhao, Zhi and Zhou, Ming and Sigmund, Ole and Zhang, Xiaojia Shelly},
    number = {5},
    month = {11},
    pages = {2827--2880},
    volume = {64},
    doi = {10.1007/s00158-021-03050-7},
    issn = {1615-147X}
}

@article{Nguyenetal2010,
    title = {{A computational paradigm for multiresolution topology optimization (MTOP)}},
    year = {2010},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Nguyen, Tam H. and Paulino, Glaucio H. and Song, Junho and Le, Chau H.},
    number = {4},
    month = {4},
    pages = {525--539},
    volume = {41},
    url = {http://link.springer.com/10.1007/s00158-009-0443-8},
    doi = {10.1007/s00158-009-0443-8},
    issn = {1615-147X},
    keywords = {Density mesh, Design variable, Finite element mesh, Multiresolution, Projection scheme, Topology optimization}
}

@article{UluZhangKara2016,
    title = {{A data-driven investigation and estimation of optimal topologies under variable loading configurations}},
    year = {2016},
    journal = {Computer Methods in Biomechanics and Biomedical Engineering: Imaging {\&} Visualization},
    author = {Ulu, Erva and Zhang, Rusheng and Kara, Levent Burak},
    number = {2},
    month = {3},
    pages = {61--72},
    volume = {4},
    publisher = {Taylor and Francis Ltd.},
    url = {http://www.tandfonline.com/doi/full/10.1080/21681163.2015.1030775},
    doi = {10.1080/21681163.2015.1030775},
    issn = {2168-1163},
    keywords = {data-driven design, dimensionality reduction, topology optimisation}
}

@article{Zhangetal2019,
    title = {{A deep convolutional neural network for topology optimization with perceptible generalization ability}},
    year = {2021},
    journal = {Engineering Optimization},
    author = {Wang, Dalei and Xiang, Cheng and Pan, Yue and Chen, Airong and Zhou, Xiaoyi and Zhang, Yiquan},
    month = {3},
    pages = {1--16},
    url = {https://www.tandfonline.com/doi/full/10.1080/0305215X.2021.1902998},
    doi = {10.1080/0305215X.2021.1902998},
    issn = {0305-215X}
}

@article{WangXiangetal2021,
    title = {{A deep convolutional neural network for topology optimization with perceptible generalization ability}},
    year = {2021},
    journal = {Engineering Optimization},
    author = {Wang, Dalei and Xiang, Cheng and Pan, Yue and Chen, Airong and Zhou, Xiaoyi and Zhang, Yiquan},
    month = {3},
    pages = {1--16},
    publisher = {Taylor and Francis Ltd.},
    url = {https://www.tandfonline.com/doi/full/10.1080/0305215X.2021.1902998},
    doi = {10.1080/0305215X.2021.1902998},
    issn = {0305-215X},
    keywords = {Convolutional neural network, deep learning, generalization ability, machine learning, topology optimization}
}

@article{QiuDuYang2021,
    title = {{A deep learning approach for efficient topology optimization based on the element removal strategy}},
    year = {2021},
    journal = {Materials {\&} Design},
    author = {Qiu, Cheng and Du, Shanyi and Yang, Jinglei},
    month = {12},
    pages = {110179},
    volume = {212},
    publisher = {Elsevier BV},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0264127521007346},
    doi = {10.1016/j.matdes.2021.110179},
    issn = {02641275}
}

@article{Barmadaetal2021,
    title = {{A Deep Learning Surrogate Model for Topology Optimization}},
    year = {2021},
    journal = {IEEE Transactions on Magnetics},
    author = {Barmada, Sami and Fontana, Nunzia and Formisano, Alessandro and Thomopulos, Dimitri and Tucci, Mauro},
    number = {6},
    month = {6},
    pages = {1--4},
    volume = {57},
    publisher = {Institute of Electrical and Electronics Engineers Inc.},
    url = {https://ieeexplore.ieee.org/document/9367238/},
    doi = {10.1109/TMAG.2021.3063470},
    issn = {0018-9464},
    keywords = {Deep learning (DL), inverse problems, optimization}
}

@article{TanZhangYe2020,
    title = {{A deep learningbased method for the design of microstructural materials}},
    year = {2020},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Tan, Ren Kai and Zhang, Nevin L. and Ye, Wenjing},
    number = {4},
    month = {4},
    pages = {1417--1438},
    volume = {61},
    publisher = {Springer},
    url = {http://link.springer.com/10.1007/s00158-019-02424-2},
    doi = {10.1007/s00158-019-02424-2},
    issn = {1615-147X},
    keywords = {Convolutional neural network, Deep learning, Generative adversarial network, Material design, Microstructural materials}
}

@article{NoratoBendsoe2004,
    title = {{A geometry projection method for shape optimization}},
    year = {2004},
    journal = {International Journal for Numerical Methods in Engineering},
    author = {Norato, J. and Haber, R. and Tortorelli, D. and Bends{\o}e, M. P.},
    number = {14},
    month = {8},
    pages = {2289--2312},
    volume = {60},
    url = {https://onlinelibrary.wiley.com/doi/10.1002/nme.1044},
    doi = {10.1002/nme.1044},
    issn = {0029-5981}
}

@article{Wangetal2003,
    title = {{A level set method for structural topology optimization}},
    year = {2003},
    journal = {Computer Methods in Applied Mechanics and Engineering},
    author = {Wang, Michael Yu and Wang, Xiaoming and Guo, Dongming},
    number = {1-2},
    month = {1},
    pages = {227--246},
    volume = {192},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782502005595},
    doi = {10.1016/S0045-7825(02)00559-5},
    issn = {00457825}
}

@article{Allaireetal2002,
    title = {{A level-set method for shape optimization}},
    year = {2002},
    journal = {Comptes Rendus Mathematique},
    author = {Allaire, Grgoire and Jouve, Franois and Toader, Anca-Maria},
    number = {12},
    month = {1},
    pages = {1125--1130},
    volume = {334},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S1631073X02024123},
    doi = {10.1016/S1631-073X(02)02412-3},
    issn = {1631073X}
}

@article{YueYangDuetal2021,
    title = {{A mechanistic-based data-driven approach to accelerate structural topology optimization through finite element convolutional neural network (FE-CNN)}},
    year = {2021},
    journal = {Preprint},
    author = {Yue, Tianle and Yang, Hang and Du, Zongliang and Liu, Chang and Elkhodary, Khalil I. and Tang, Shan and Guo, Xu},
    month = {6},
    url = {http://arxiv.org/abs/2106.13652},
    arxivId = {2106.13652}
}

@techreport{ParkAdeli1995,
    title = {{A NEURAL DYNAMICS MODEL FOR STRUCTURAL OPTIMIZATION-APPLICATION TO PLASTIC DESIGN OF STRUCTURES}},
    year = {1995},
    booktitle = {Compurers {\&} Smrrures},
    author = {Park, Hyo Seon and Adeli, H},
    number = {3},
    pages = {391--399},
    volume = {57},
    isbn = {00457949/95}
}

@article{AdeliPark1995,
    title = {{A neural dynamics model for structural optimizationTheory}},
    year = {1995},
    journal = {Computers {\&} Structures},
    author = {Adeli, H. and Park, Hyo Seon},
    number = {3},
    month = {11},
    pages = {383--390},
    volume = {57},
    url = {https://linkinghub.elsevier.com/retrieve/pii/004579499500048L},
    doi = {10.1016/0045-7949(95)00048-L},
    issn = {00457949}
}

@article{ShenChen2019,
    title = {{A New CGAN Technique for Constrained Topology Design Optimization}},
    year = {2019},
    journal = {Preprint},
    author = {Shen, M. -H. Herman and Chen, Liang},
    month = {1},
    url = {http://arxiv.org/abs/1901.07675},
    arxivId = {1901.07675}
}

@article{Zhouetal2020,
    title = {{A new data-driven topology optimization framework for structural optimization}},
    year = {2020},
    journal = {Computers {\&} Structures},
    author = {Zhou, Ying and Zhan, Haifei and Zhang, Weihong and Zhu, Jihong and Bai, Jinshuai and Wang, Qingxia and Gu, Yuantong},
    month = {10},
    pages = {106310},
    volume = {239},
    publisher = {Elsevier Ltd},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0045794920301139},
    doi = {10.1016/j.compstruc.2020.106310},
    issn = {00457949},
    keywords = {Constitutive model, Data-driven computational mechanics, Material data set, Moving least square, Topology optimization}
}

@article{ChenShen2021,
    title = {{A New Topology Optimization Approach by Physics-Informed Deep Learning Process}},
    year = {2021},
    journal = {Advances in Science, Technology and Engineering Systems Journal},
    author = {Chen, Liang and Shen, Mo-How Herman},
    number = {4},
    month = {7},
    pages = {233--240},
    volume = {6},
    url = {https://astesj.com/v06/i04/p27/},
    doi = {10.25046/aj060427},
    issn = {24156698}
}

@article{RawatShen2018,
    title = {{A novel topology design approach using an integrated deep learning network architecture}},
    year = {2018},
    journal = {Preprint},
    author = {Rawat, Sharad and Shen, M. H. Herman},
    month = {8},
    url = {http://arxiv.org/abs/1808.02334},
    arxivId = {1808.02334},
    keywords = {()}
}

@article{RawatShen2019,
    title = {{A Novel Topology Optimization Approach using Conditional Deep Learning}},
    year = {2019},
    journal = {Preprint},
    author = {Rawat, Sharad and Shen, M. -H. Herman},
    month = {1},
    url = {http://arxiv.org/abs/1901.04859},
    arxivId = {1901.04859}
}

@article{DengTo2021,
    title = {{A Parametric Level Set Method for Topology Optimization based on Deep Neural Network (DNN)}},
    year = {2021},
    journal = {Preprint},
    author = {Deng, Hao and To, Albert C.},
    month = {1},
    url = {http://arxiv.org/abs/2101.03286},
    arxivId = {2101.03286}
}

@article{PantzTrabelsi2008,
    title = {{A Post-Treatment of the Homogenization Method for Shape Optimization}},
    year = {2008},
    journal = {SIAM Journal on Control and Optimization},
    author = {Pantz, O. and Trabelsi, K.},
    number = {3},
    month = {1},
    pages = {1380--1398},
    volume = {47},
    url = {http://epubs.siam.org/doi/10.1137/070688900},
    doi = {10.1137/070688900},
    issn = {0363-0129}
}

@article{WeinDunningNorato2020,
    title = {{A review on feature-mapping methods for structural optimization}},
    year = {2020},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Wein, Fabian and Dunning, Peter D. and Norato, Julin A.},
    number = {4},
    month = {10},
    pages = {1597--1638},
    volume = {62},
    doi = {10.1007/s00158-020-02649-6},
    issn = {1615-147X}
}

@article{Hashemietal2021,
    title = {{A supervised machine learning approach for accelerating the design of particulate composites: Application to thermal conductivity}},
    year = {2021},
    journal = {Computational Materials Science},
    author = {Hashemi, Mohammad Saber and Safdari, Masoud and Sheidaei, Azadeh},
    month = {9},
    pages = {110664},
    volume = {197},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0927025621003918},
    doi = {10.1016/j.commatsci.2021.110664},
    issn = {09270256}
}

@article{Pouyanfaretal2018,
    title = {{A Survey on Deep Learning}},
    year = {2019},
    journal = {ACM Computing Surveys},
    author = {Pouyanfar, Samira and Sadiq, Saad and Yan, Yilin and Tian, Haiman and Tao, Yudong and Reyes, Maria Presa and Shyu, Mei-Ling and Chen, Shu-Ching and Iyengar, S. S.},
    number = {5},
    month = {9},
    pages = {1--36},
    volume = {51},
    publisher = {Association for Computing Machinery},
    url = {https://dl.acm.org/doi/10.1145/3234150},
    doi = {10.1145/3234150},
    issn = {0360-0300},
    keywords = {Big data, Deep learning, Distributed processing, Machine learning, Neural networks, Survey}
}

@article{Kallioras2020,
    title = {{Accelerated topology optimization by means of deep learning}},
    year = {2020},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Kallioras, Nikos Ath. and Kazakis, Georgios and Lagaros, Nikos D.},
    number = {3},
    month = {9},
    pages = {1185--1212},
    volume = {62},
    publisher = {Springer},
    url = {http://link.springer.com/10.1007/s00158-020-02545-z},
    doi = {10.1007/s00158-020-02545-z},
    issn = {1615-147X},
    keywords = {Deep belief networks, Deep learning, Pattern recognition, Restricted Boltzmann machines, SIMP, Topology optimization}
}

@article{QianYe2020,
    title = {{Accelerating gradient-based topology optimization design with dual-model artificial neural networks}},
    year = {2021},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Qian, Chao and Ye, Wenjing},
    number = {4},
    month = {4},
    pages = {1687--1707},
    volume = {63},
    publisher = {Springer Science and Business Media Deutschland GmbH},
    url = {http://link.springer.com/10.1007/s00158-020-02770-6},
    doi = {10.1007/s00158-020-02770-6},
    issn = {1615-147X},
    keywords = {Artificial neural network, Deep learning, SIMP, Structural and metamaterial design, Topology optimization}
}

@article{Mukherjeeetal2021,
    title = {{Accelerating Large-scale Topology Optimization: State-of-the-Art and Challenges}},
    year = {2021},
    journal = {Archives of Computational Methods in Engineering},
    author = {Mukherjee, Sougata and Lu, Dongcheng and Raghavan, Balaji and Breitkopf, Piotr and Dutta, Subhrajit and Xiao, Manyu and Zhang, Weihong},
    number = {7},
    month = {12},
    pages = {4549--4571},
    volume = {28},
    publisher = {Springer Science and Business Media B.V.},
    url = {https://link.springer.com/10.1007/s11831-021-09544-3},
    doi = {10.1007/s11831-021-09544-3},
    issn = {1134-3060}
}

@article{YeLietal2021,
    title = {{Acceleration Design for Continuum Topology Optimization by Using Pix2pix Neural Network}},
    year = {2021},
    journal = {International Journal of Applied Mechanics},
    author = {Ye, Hong-Ling and Li, Ji-Cheng and Yuan, Bo-Shuai and Wei, Nan and Sui, Yun-Kang},
    number = {04},
    month = {5},
    pages = {2150042},
    volume = {13},
    url = {https://www.worldscientific.com/doi/abs/10.1142/S1758825121500423},
    doi = {10.1142/S1758825121500423},
    issn = {1758-8251}
}

@article{ZhengFanetal2021,
    title = {{Accurate and real-time structural topology prediction driven by deep learning under moving morphable component-based framework}},
    year = {2021},
    journal = {Applied Mathematical Modelling},
    author = {Zheng, Shuai and Fan, Haojie and Zhang, Ziyu and Tian, Zhiqiang and Jia, Kang},
    month = {9},
    pages = {522--535},
    volume = {97},
    publisher = {Elsevier Inc.},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0307904X21002092},
    doi = {10.1016/j.apm.2021.04.009},
    issn = {0307904X},
    keywords = {Attention-Res-U-Net, Deep learning, Moving morphable component (MMC), Real-time optimization, Topology optimization}
}

@article{XuDarve2020,
    title = {{ADCME: Learning Spatially-varying Physical Fields using Deep Neural Networks}},
    year = {2020},
    journal = {Preprint},
    author = {Xu, Kailai and Darve, Eric},
    month = {11},
    url = {http://arxiv.org/abs/2011.11955},
    arxivId = {2011.11955}
}

@article{Kurakinetal2016,
    title = {{Adversarial Machine Learning at Scale}},
    year = {2016},
    journal = {Preprint},
    author = {Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
    month = {11},
    url = {http://arxiv.org/abs/1611.01236},
    arxivId = {1611.01236}
}

@article{GarreltsHuberetal2021,
    title = {{AI-Based Topology Optimization of Freehand Sketches}},
    year = {2021},
    journal = {Procedia CIRP},
    author = {Garrelts, Enno and Huber, Marco and Roth, Daniel and Binz, Hansgeorg},
    pages = {1316--1321},
    volume = {104},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S2212827121011197},
    doi = {10.1016/j.procir.2021.11.221},
    issn = {22128271}
}

@article{Radeetat2020,
    title = {{Algorithmically-consistent deep learning frameworks for structural topology optimization}},
    year = {2021},
    journal = {Engineering Applications of Artificial Intelligence},
    author = {Rade, Jaydeep and Balu, Aditya and Herron, Ethan and Pathak, Jay and Ranade, Rishikesh and Sarkar, Soumik and Krishnamurthy, Adarsh},
    month = {11},
    pages = {104483},
    volume = {106},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0952197621003316},
    doi = {10.1016/j.engappai.2021.104483},
    issn = {09521976}
}

@article{MunozChinesta2022,
    title = {{Allying topology and shape optimization through machine learning algorithms}},
    year = {2022},
    journal = {Finite Elements in Analysis and Design},
    author = {Mu{\~{n}}oz, D. and Nadal, E. and Albelda, J. and Chinesta, F. and R{\'{o}}denas, J.J.},
    month = {7},
    pages = {103719},
    volume = {204},
    doi = {10.1016/j.finel.2021.103719},
    issn = {0168874X}
}

@article{Langelaar2017,
    title = {{An additive manufacturing filter for topology optimization of print-ready designs}},
    year = {2017},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Langelaar, Matthijs},
    number = {3},
    month = {3},
    pages = {871--883},
    volume = {55},
    url = {http://link.springer.com/10.1007/s00158-016-1522-2},
    doi = {10.1007/s00158-016-1522-2},
    issn = {1615-147X}
}

@article{Halleetal2020,
    title = {{An Artificial IntelligenceAssisted Design Method for Topology Optimization without Pre-Optimized Training Data}},
    year = {2021},
    journal = {Applied Sciences},
    author = {Halle, Alex and Campanile, Lucio Flavio and Hasse, Alexander},
    number = {19},
    month = {9},
    pages = {9041},
    volume = {11},
    url = {https://www.mdpi.com/2076-3417/11/19/9041},
    doi = {10.3390/app11199041},
    issn = {2076-3417}
}

@article{Napieretal2020,
    title = {{An Artificial Neural Network Approach for Generating High-Resolution Designs From Low-Resolution Input in Topology Optimization}},
    year = {2020},
    journal = {Journal of Mechanical Design},
    author = {Napier, Nicholas and Sriraman, Sai-Aksharah and Tran, Huy T. and James, Kai A.},
    number = {1},
    month = {1},
    volume = {142},
    publisher = {ASME International},
    url = {https://asmedigitalcollection.asme.org/mechanicaldesign/article/doi/10.1115/1.4044332/955332/An-Artificial-Neural-Network-Approach-for},
    doi = {10.1115/1.4044332},
    issn = {1050-0472}
}

@techreport{Marcus2019,
    title = {{An Epidemic of AI Misinformation}},
    year = {2019},
    author = {Marcus, Gary F.},
    url = {https://thegradient.pub/an-epidemic-of-ai-misinformation/[04-12-2019}
}

@article{LuoZhouetal2021,
    title = {{An Improved Data-Driven Topology Optimization Method Using Feature Pyramid Networks with Physical Constraints}},
    year = {2021},
    journal = {Computer Modeling in Engineering {\&} Sciences},
    author = {Luo, Jiaxiang and Li, Yu and Zhou, Weien and Gong, Zhiqiang and Zhang, Zeyu and Yao, Wen},
    number = {3},
    pages = {823--848},
    volume = {128},
    publisher = {Tech Science Press},
    url = {https://www.techscience.com/CMES/v128n3/44011},
    doi = {10.32604/cmes.2021.016737},
    issn = {1526-1506},
    keywords = {Deep learning, Feature pyramid networks, Finite element analysis, Physical constraints, Topology optimization}
}

@inproceedings{Guoetal2018,
    title = {{An Indirect Design Representation for Topology Optimization Using Variational Autoencoder and Style Transfer}},
    year = {2018},
    booktitle = {2018 AIAA/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference},
    author = {Guo, Tinghao and Lohan, Danny J. and Cang, Ruijin and Ren, Max Yi and Allison, James T.},
    month = {1},
    publisher = {American Institute of Aeronautics and Astronautics},
    url = {https://arc.aiaa.org/doi/10.2514/6.2018-0804},
    address = {Reston, Virginia},
    isbn = {978-1-62410-532-6},
    doi = {10.2514/6.2018-0804}
}

@inproceedings{RawShe2019,
    title = {{Application of Adversarial Networks for 3D Structural Topology Optimization}},
    year = {2019},
    booktitle = {SAE Technical Papers},
    author = {Rawat, Sharad and Shen, MH Herman},
    number = {April},
    month = {4},
    volume = {2019-April},
    publisher = {SAE International},
    url = {https://www.sae.org/content/2019-01-0829/},
    doi = {10.4271/2019-01-0829}
}

@book{AuligOlhofer2015,
    title = {{Applications of Evolutionary Computation}},
    year = {2015},
    booktitle = {Applications of Evolutionary Computation, 18th European Conference, EvoApplications 2015, Copenhagen, Denmark, April 810, 2015},
    author = {Aulig, Nikola and Olhofer, Markus},
    editor = {Mora, Antonio M. and Squillero, Giovanni},
    pages = {655--666},
    series = {Lecture Notes in Computer Science},
    volume = {9028},
    publisher = {Springer International Publishing},
    url = {http://link.springer.com/10.1007/978-3-319-16549-3},
    address = {Cham},
    isbn = {978-3-319-16548-6},
    doi = {10.1007/978-3-319-16549-3}
}

@article{GuoYang2021,
    title = {{Artificial intelligence and machine learning in design of mechanical materials}},
    year = {2021},
    journal = {Materials Horizons},
    author = {Guo, Kai and Yang, Zhenze and Yu, Chi-Hua and Buehler, Markus J.},
    number = {4},
    pages = {1153--1172},
    volume = {8},
    url = {http://xlink.rsc.org/?DOI=D0MH01451F},
    doi = {10.1039/D0MH01451F},
    issn = {2051-6347}
}

@article{LinLin2005,
    title = {{Artificial neural network based hole image interpretation techniques for integrated topology and shape optimization}},
    year = {2005},
    journal = {Computer Methods in Applied Mechanics and Engineering},
    author = {Lin, Chyi-Yeu and Lin, Shin-Hong},
    number = {36-38},
    month = {9},
    pages = {3817--3837},
    volume = {194},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782504004657},
    doi = {10.1016/j.cma.2004.09.005},
    issn = {00457825},
    keywords = {Artificial neural networks, Configuration design, Hole image interpretation, Shape optimization, Shape templates, Topology optimization}
}

@article{Bonfatietal2020,
    title = {{Automatic design of mechanical metamaterial actuators}},
    year = {2020},
    journal = {Nature Communications},
    author = {Bonfanti, Silvia and Guerra, Roberto and Font-Clos, Francesc and Rayneau-Kirkhope, Daniel and Zapperi, Stefano},
    number = {1},
    month = {12},
    pages = {4162},
    volume = {11},
    url = {https://www.nature.com/articles/s41467-020-17947-2},
    doi = {10.1038/s41467-020-17947-2},
    issn = {2041-1723}
}

@inproceedings{EckHoppe1996,
    title = {{Automatic reconstruction of B-spline surfaces of arbitrary topological type}},
    year = {1996},
    booktitle = {Proceedings of the 23rd annual conference on Computer graphics and interactive techniques  - SIGGRAPH '96},
    author = {Eck, Matthias and Hoppe, Hugues},
    pages = {325--334},
    publisher = {ACM Press},
    address = {New York, New York, USA},
    isbn = {0897917464},
    doi = {10.1145/237170.237271}
}

@article{YimLeeKim2021,
    title = {{Big data approach for the simultaneous determination of the topology and end-effector location of a planar linkage mechanism}},
    year = {2021},
    journal = {Mechanism and Machine Theory},
    author = {Yim, Neung Hwan and Lee, Jongjun and Kim, Jungho and Kim, Yoon Young},
    month = {9},
    pages = {104375},
    volume = {163},
    publisher = {Elsevier Ltd},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0094114X21001336},
    doi = {10.1016/j.mechmachtheory.2021.104375},
    issn = {0094114X},
    keywords = {Big data approach, End-effector location, Mechanism synthesis, Planar linkages, Shape optimization, Topology}
}

@inproceedings{Pumarola2020,
    title = {{C-Flow: Conditional Generative Flow Models for Images and 3D Point Clouds}},
    year = {2020},
    booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    author = {Pumarola, Albert and Popov, Stefan and Moreno-Noguer, Francesc and Ferrari, Vittorio},
    month = {6},
    pages = {7946--7955},
    publisher = {IEEE},
    isbn = {978-1-7281-7168-5},
    doi = {10.1109/CVPR42600.2020.00797}
}

@article{Baandrup2020,
    title = {{Closing the gap towards super-long suspension bridges using computational morphogenesis}},
    year = {2020},
    journal = {Nature Communications},
    author = {Baandrup, Mads and Sigmund, Ole and Polk, Henrik and Aage, Niels},
    number = {1},
    month = {12},
    pages = {2735},
    volume = {11},
    doi = {10.1038/s41467-020-16599-6},
    issn = {2041-1723}
}

@article{Lee_etal2020,
    title = {{CNN-based image recognition for topology optimization}},
    year = {2020},
    journal = {Knowledge-Based Systems},
    author = {Lee, Seunghye and Kim, Hyunjoo and Lieu, Qui X. and Lee, Jaehong},
    month = {6},
    pages = {105887},
    volume = {198},
    publisher = {Elsevier B.V.},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705120302379},
    doi = {10.1016/j.knosys.2020.105887},
    issn = {09507051},
    keywords = {Compliance, Convolutional neural network, GPU computing, Topology analysis, Topology image recognition}
}

@inproceedings{PantzTrabelsi2010,
    title = {{Construction of minimization sequences for shape optimization}},
    year = {2010},
    booktitle = {2010 15th International Conference on Methods and Models in Automation and Robotics},
    author = {Pantz, Olivier and Trabelsi, Karim},
    month = {8},
    pages = {278--283},
    publisher = {IEEE},
    url = {http://ieeexplore.ieee.org/document/5587222/},
    isbn = {978-1-4244-7828-6},
    doi = {10.1109/MMAR.2010.5587222}
}

@article{Glaeseneretal2020,
    title = {{Continuum representation of nonlinear three-dimensional periodic truss networks by on-the-fly homogenization}},
    year = {2020},
    journal = {International Journal of Solids and Structures},
    author = {Glaesener, Raphal N. and Tr{\"{a}}ff, Erik A. and Telgen, Bastian and Canonica, Renato M. and Kochmann, Dennis M.},
    month = {12},
    pages = {101--113},
    volume = {206},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0020768320303127},
    doi = {10.1016/j.ijsolstr.2020.08.013},
    issn = {00207683}
}

@article{Satoetal2019,
    title = {{Data mining based on clustering and association rule analysis for knowledge discovery in multiobjective topology optimization}},
    year = {2019},
    journal = {Expert Systems with Applications},
    author = {Sato, Yuki and Izui, Kazuhiro and Yamada, Takayuki and Nishiwaki, Shinji},
    month = {4},
    pages = {247--261},
    volume = {119},
    publisher = {Elsevier Ltd},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S095741741830705X},
    doi = {10.1016/j.eswa.2018.10.047},
    issn = {09574174},
    keywords = {Association analysis, Clustering, Data mining, Optimum design, Topology optimization}
}

@article{HorvitzMullign2015,
    title = {{Data, privacy, and the greater good}},
    year = {2015},
    journal = {Science},
    author = {Horvitz, Eric and Mulligan, Deirdre},
    number = {6245},
    month = {7},
    pages = {253--255},
    volume = {349},
    publisher = {American Association for the Advancement of Science},
    url = {https://www.science.org/doi/10.1126/science.aac4520},
    doi = {10.1126/science.aac4520},
    issn = {0036-8075}
}

@article{Daetal2022,
    title = {{Data-driven and topological design of structural metamaterials for fracture resistance}},
    year = {2022},
    journal = {Extreme Mechanics Letters},
    author = {Da, Daicong and Chan, Yu-Chin and Wang, Liwei and Chen, Wei},
    month = {1},
    pages = {101528},
    volume = {50},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S2352431621002078},
    doi = {10.1016/j.eml.2021.101528},
    issn = {23524316}
}

@article{Hoangetal2022,
    title = {{Data-driven geometry-based topology optimization}},
    year = {2022},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Hoang, Van-Nam and Nguyen, Ngoc-Linh and Tran, Dat Q. and Vu, Quang-Viet and Nguyen-Xuan, H.},
    number = {2},
    month = {2},
    pages = {69},
    volume = {65},
    doi = {10.1007/s00158-022-03170-8},
    issn = {1615-147X}
}

@article{WangBeckDa2021,
    title = {{Data-driven multiscale design of cellular composites with multiclass microstructures for natural frequency maximization}},
    year = {2022},
    journal = {Composite Structures},
    author = {Wang, Liwei and van Beek, Anton and Da, Daicong and Chan, Yu-Chin and Zhu, Ping and Chen, Wei},
    month = {1},
    pages = {114949},
    volume = {280},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0263822321013805},
    doi = {10.1016/j.compstruct.2021.114949},
    issn = {02638223}
}

@article{Yamasakietal2021,
    title = {{Data-driven topology design using a deep generative model}},
    year = {2021},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Yamasaki, Shintaro and Yaji, Kentaro and Fujita, Kikuo},
    number = {3},
    month = {9},
    pages = {1401--1420},
    volume = {64},
    publisher = {Springer Science and Business Media Deutschland GmbH},
    url = {https://link.springer.com/10.1007/s00158-021-02926-y},
    doi = {10.1007/s00158-021-02926-y},
    issn = {1615-147X},
    keywords = {Data-driven design, Deep generative model, Estimation of distribution algorithm, Multi-objective methodology, Sensitivity-free methodology, Topology optimization}
}

@article{ZheKumKoch2021,
    title = {{Data-driven topology optimization of spinodoid metamaterials with seamlessly tunable anisotropy}},
    year = {2021},
    journal = {Computer Methods in Applied Mechanics and Engineering},
    author = {Zheng, Li and Kumar, Siddhant and Kochmann, Dennis M.},
    month = {9},
    pages = {113894},
    volume = {383},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782521002310},
    doi = {10.1016/j.cma.2021.113894},
    issn = {00457825}
}

@article{GuChenBuehler2018,
    title = {{De novo composite design based on machine learning algorithm}},
    year = {2018},
    journal = {Extreme Mechanics Letters},
    author = {Gu, Grace X. and Chen, Chun-Teh and Buehler, Markus J.},
    month = {1},
    pages = {19--28},
    volume = {18},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S2352431617301256},
    doi = {10.1016/j.eml.2017.10.001},
    issn = {23524316}
}

@article{Elingaard2021,
    title = {{De-homogenization using convolutional neural networks}},
    year = {2022},
    journal = {Computer Methods in Applied Mechanics and Engineering},
    author = {Elingaard, Martin Ohrt and Aage, Niels and B{\ae}rentzen, Jakob Andreas and Sigmund, Ole},
    month = {1},
    pages = {114197},
    volume = {388},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782521005284},
    doi = {10.1016/j.cma.2021.114197},
    issn = {00457825}
}

@article{OhJungKim2019,
    title = {{Deep Generative Design: Integration of Topology Optimization and Generative Models}},
    year = {2019},
    journal = {Journal of Mechanical Design},
    author = {Oh, Sangeun and Jung, Yongsu and Kim, Seongsin and Lee, Ikjin and Kang, Namwoo},
    number = {11},
    month = {11},
    volume = {141},
    publisher = {American Society of Mechanical Engineers (ASME)},
    url = {https://asmedigitalcollection.asme.org/mechanicaldesign/article/doi/10.1115/1.4044229/955342/Deep-Generative-Design-Integration-of-Topology},
    doi = {10.1115/1.4044229},
    issn = {1050-0472},
    keywords = {Deep learning, Design automation, Design exploration, Design methodology, Design optimization, Expert systems, Generative adversarial networks, Generative design, Generative models, Product design, Topology optimization}
}

@article{WangChanAhmedetal2020,
    title = {{Deep generative modeling for mechanistic-based learning and design of metamaterial systems}},
    year = {2020},
    journal = {Computer Methods in Applied Mechanics and Engineering},
    author = {Wang, Liwei and Chan, Yu-Chin and Ahmed, Faez and Liu, Zhao and Zhu, Ping and Chen, Wei},
    month = {12},
    pages = {113377},
    volume = {372},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782520305624},
    doi = {10.1016/j.cma.2020.113377},
    issn = {00457825}
}

@article{Raissi2018,
    title = {{Deep Hidden Physics Models: Deep Learning of Nonlinear Partial Differential Equations}},
    year = {2018},
    journal = {Preprint},
    author = {Raissi, Maziar},
    month = {1},
    url = {http://arxiv.org/abs/1801.06637},
    arxivId = {1801.06637}
}

@book{Goodfellow2016,
    title = {{Deep Learning}},
    year = {2016},
    author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
    publisher = {The MIT Press},
    isbn = {0262035618}
}

@article{YanZhangXuetal2022,
    title = {{Deep learning driven real time topology optimisation based on initial stress learning}},
    year = {2022},
    journal = {Advanced Engineering Informatics},
    author = {Yan, Jun and Zhang, Qi and Xu, Qi and Fan, Zhirui and Li, Haijiang and Sun, Wei and Wang, Guangyuan},
    month = {1},
    pages = {101472},
    volume = {51},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S1474034621002226},
    doi = {10.1016/j.aei.2021.101472},
    issn = {14740346}
}

@article{YuHurJungJang2019,
    title = {{Deep learning for determining a near-optimal topological design without any iteration}},
    year = {2019},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Yu, Yonggyun and Hur, Taeil and Jung, Jaeho and Jang, In Gwun},
    number = {3},
    month = {3},
    pages = {787--799},
    volume = {59},
    publisher = {Springer Verlag},
    url = {http://link.springer.com/10.1007/s00158-018-2101-5},
    doi = {10.1007/s00158-018-2101-5},
    issn = {1615-147X},
    keywords = {Convolutional neural network, Deep learning, Generative adversarial network, Generative model, Machine learning, Topology optimization}
}

@article{Kollmannetal2020,
    title = {{Deep learning for topology optimization of 2D metamaterials}},
    year = {2020},
    journal = {Materials {\&} Design},
    author = {Kollmann, Hunter T. and Abueidda, Diab W. and Koric, Seid and Guleryuz, Erman and Sobh, Nahil A.},
    month = {11},
    pages = {109098},
    volume = {196},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S026412752030633X},
    doi = {10.1016/j.matdes.2020.109098},
    issn = {02641275}
}

@article{KimYang2021,
    title = {{Deep learning framework for material design space exploration using active transfer learning and data augmentation}},
    year = {2021},
    journal = {npj Computational Materials},
    author = {Kim, Yongtae and Kim, Youngsoo and Yang, Charles and Park, Kundo and Gu, Grace X. and Ryu, Seunghwa},
    number = {1},
    month = {12},
    pages = {140},
    volume = {7},
    url = {https://www.nature.com/articles/s41524-021-00609-2},
    doi = {10.1038/s41524-021-00609-2},
    issn = {2057-3960}
}

@article{KalliorasNordasLagaros2021,
    title = {{Deep Learning-Based Accuracy Upgrade of Reduced Order Models in Topology Optimization}},
    year = {2021},
    journal = {Applied Sciences},
    author = {Kallioras, Nikos Ath. and Nordas, Alexandros N. and Lagaros, Nikos D.},
    number = {24},
    month = {12},
    pages = {12005},
    volume = {11},
    url = {https://www.mdpi.com/2076-3417/11/24/12005},
    doi = {10.3390/app112412005},
    issn = {2076-3417}
}

@article{NakamuraSuzuki2020,
    title = {{Deep learning-based topological optimization for representing a user-specified design area}},
    year = {2020},
    journal = {Preprint},
    author = {Nakamura, Keigo and Suzuki, Yoshiro},
    month = {4},
    url = {http://arxiv.org/abs/2004.05461},
    arxivId = {2004.05461}
}

@article{ZhangYe2019,
    title = {{Deep learningbased inverse method for layout design}},
    year = {2019},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Zhang, Yujie and Ye, Wenjing},
    number = {2},
    month = {8},
    pages = {527--536},
    volume = {60},
    publisher = {Springer Verlag},
    url = {http://link.springer.com/10.1007/s00158-019-02222-w},
    doi = {10.1007/s00158-019-02222-w},
    issn = {1615-147X},
    keywords = {Artificial neural network, Deep learning, Inverse method, Layout design, Variational autoencoder}
}

@article{ZhangYe2019b,
    title = {{Deep learningbased inverse method for layout design}},
    year = {2019},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Zhang, Yujie and Ye, Wenjing},
    number = {2},
    month = {8},
    pages = {527--536},
    volume = {60},
    url = {http://link.springer.com/10.1007/s00158-019-02222-w},
    doi = {10.1007/s00158-019-02222-w},
    issn = {1615-147X}
}

@article{LiKirbyZhe2020,
    title = {{Deep Multi-Fidelity Active Learning of High-dimensional Outputs}},
    year = {2020},
    journal = {Preprint},
    author = {Li, Shibo and Kirby, Robert M. and Zhe, Shandian},
    month = {12},
    url = {http://arxiv.org/abs/2012.00901},
    arxivId = {2012.00901}
}

@article{JiangChenFan2021_nano2,
    title = {{Deep neural networks for the evaluation and design of photonic devices}},
    year = {2021},
    journal = {Nature Reviews Materials},
    author = {Jiang, Jiaqi and Chen, Mingkun and Fan, Jonathan A.},
    number = {8},
    month = {8},
    pages = {679--700},
    volume = {6},
    url = {https://www.nature.com/articles/s41578-020-00260-1},
    doi = {10.1038/s41578-020-00260-1},
    issn = {2058-8437}
}

@article{SuiGuoetal2021,
    title = {{Deep Reinforcement Learning for Digital Materials Design}},
    year = {2021},
    journal = {ACS Materials Letters},
    author = {Sui, Fanping and Guo, Ruiqi and Zhang, Zhizhou and Gu, Grace X. and Lin, Liwei},
    number = {10},
    month = {10},
    pages = {1433--1439},
    volume = {3},
    url = {https://pubs.acs.org/doi/10.1021/acsmaterialslett.1c00390},
    doi = {10.1021/acsmaterialslett.1c00390},
    issn = {2639-4979}
}

@article{Wangetal2020,
    title = {{Deep super-resolution neural network for structural topology optimization}},
    year = {2021},
    journal = {Engineering Optimization},
    author = {Wang, Chunpeng and Yao, Song and Wang, Zhangjun and Hu, Jie},
    number = {12},
    month = {12},
    pages = {2108--2121},
    volume = {53},
    publisher = {Taylor and Francis Ltd.},
    url = {https://www.tandfonline.com/doi/full/10.1080/0305215X.2020.1846031},
    doi = {10.1080/0305215X.2020.1846031},
    issn = {0305-215X},
    keywords = {Deep learning, super-resolution network, topology optimization}
}

@article{Dinh2016,
    title = {{Density estimation using Real NVP}},
    year = {2016},
    author = {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
    month = {5},
    arxivId = {1605.08803}
}

@phdthesis{Sigmund1994,
    title = {{Design of Material Structures Using Topology Optimization}},
    year = {1994},
    author = {Sigmund, Ole},
    month = {12},
    url = {https://www.researchgate.net/publication/261173987_Design_of_Material_Structures_Using_Topology_Optimization},
    school = {Technical University of Denmark},
    address = {Kongens Lyngby, Denmark}
}

@article{KalliorasLagaros2020,
    title = {{DL-SCALE: a novel deep learning-based model order upscaling scheme for solving topology optimization problems}},
    year = {2021},
    journal = {Neural Computing and Applications},
    author = {Kallioras, Nikos Ath. and Lagaros, Nikos D.},
    number = {12},
    month = {6},
    pages = {7125--7144},
    volume = {33},
    publisher = {Springer},
    url = {https://link.springer.com/10.1007/s00521-020-05480-8},
    doi = {10.1007/s00521-020-05480-8},
    issn = {0941-0643},
    keywords = {Deep belief networks, Deep learning, Pattern recognition, Restricted Boltzmann machines, SIMP, Topology optimization}
}

@article{Guoetal2014,
    title = {{Doing Topology Optimization Explicitly and GeometricallyA New Moving Morphable Components Based Framework}},
    year = {2014},
    journal = {Journal of Applied Mechanics},
    author = {Guo, Xu and Zhang, Weisheng and Zhong, Wenliang},
    number = {8},
    month = {8},
    volume = {81},
    url = {https://asmedigitalcollection.asme.org/appliedmechanics/article/doi/10.1115/1.4027609/370419/Doing-Topology-Optimization-Explicitly-and},
    doi = {10.1115/1.4027609},
    issn = {0021-8936}
}

@article{Andreassenetal2011,
    title = {{Efficient topology optimization in MATLAB using 88 lines of code}},
    year = {2011},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Andreassen, Erik and Clausen, Anders and Schevenels, Mattias and Lazarov, Boyan S. and Sigmund, Ole},
    number = {1},
    month = {1},
    pages = {1--16},
    volume = {43},
    url = {http://link.springer.com/10.1007/s00158-010-0594-7},
    doi = {10.1007/s00158-010-0594-7},
    issn = {1615-147X},
    keywords = {Computational efficiency, Education, MATLAB, Topology optimization}
}

@article{Xueetal2021,
    title = {{Efficient, high-resolution topology optimization method based on convolutional neural networks}},
    year = {2021},
    journal = {Frontiers of Mechanical Engineering},
    author = {Xue, Liang and Liu, Jie and Wen, Guilin and Wang, Hongxin},
    number = {1},
    month = {3},
    pages = {80--96},
    volume = {16},
    publisher = {Higher Education Press Limited Company},
    url = {http://link.springer.com/10.1007/s11465-020-0614-2},
    doi = {10.1007/s11465-020-0614-2},
    issn = {2095-0233},
    keywords = {convolutional neural network, density-based, high resolution, topology optimization}
}

@article{WangLiuDaChanChenZhu2021,
    title = {{Enhancing Data-driven Multiscale Topology Optimization with Generalized De-homogenization}},
    year = {2021},
    journal = {Preprint},
    author = {Wang, Liwei and Liu, Zhao and Da, Daicong and Chan, Yu-Chin and Chen, Wei and Zhu, Ping},
    month = {12},
    url = {http://arxiv.org/abs/2112.02506},
    arxivId = {2112.02506}
}

@article{Gurguisetal2020,
    title = {{Evolutionary Black-Box Topology Optimization: Challenges and Promises}},
    year = {2020},
    journal = {IEEE Transactions on Evolutionary Computation},
    author = {Guirguis, David and Aulig, Nikola and Picelli, Renato and Zhu, Bo and Zhou, Yuqing and Vicente, William and Iorio, Francesco and Olhofer, Markus and Matusiks, Wojciech and Coello Coello, Carlos Artemio and Saitou, Kazuhiro},
    number = {4},
    month = {8},
    pages = {613--633},
    volume = {24},
    publisher = {Institute of Electrical and Electronics Engineers Inc.},
    url = {https://ieeexplore.ieee.org/document/8906012/},
    doi = {10.1109/TEVC.2019.2954411},
    issn = {1089-778X},
    keywords = {CADCAM, design automation, design optimization, evolutionary computation, large scale optimization, product design, topology, topology optimization}
}

@inproceedings{AuligOlhofer2013,
    title = {{Evolutionary generation of neural network update signals for the topology optimization of structures}},
    year = {2013},
    booktitle = {Proceedings of the 15th annual conference companion on Genetic and evolutionary computation},
    author = {Aulig, Nikola and Olhofer, Markus},
    month = {7},
    pages = {213--214},
    publisher = {ACM},
    url = {https://dl.acm.org/doi/10.1145/2464576.2464685},
    address = {New York, NY, USA},
    isbn = {9781450319645},
    doi = {10.1145/2464576.2464685},
    keywords = {Evolutionary learning, Evolutionary strategy, Neural net- work, Structural optimization, Topology optimization, Update signal}
}

@book{XieSteven1997,
    title = {{Evolutionary Structural Optimization}},
    year = {1997},
    author = {Xie, Y. M. and Steven, G. P.},
    publisher = {Springer London},
    url = {http://link.springer.com/10.1007/978-1-4471-0985-3},
    address = {London},
    isbn = {978-1-4471-1250-1},
    doi = {10.1007/978-1-4471-0985-3}
}

@article{BehzadiIllies2021,
    title = {{GANTL: Towards Practical and Real-Time Topology Optimization with Conditional GANs and Transfer Learning}},
    year = {2021},
    journal = {Journal of Mechanical Design},
    author = {Behzadi, Mohammad Mahdi and Ilies, Horea T.},
    month = {10},
    pages = {1--32},
    url = {https://asmedigitalcollection.asme.org/mechanicaldesign/article/doi/10.1115/1.4052757/1121902/GANTL-Towards-Practical-and-Real-Time-Topology},
    doi = {10.1115/1.4052757},
    issn = {1050-0472}
}

@techreport{GroenTraeffetal2020,
    title = {{General rights Simple single-scale interpretations of optimal designs in the context of extremal stiffness}},
    year = {2019},
    author = {Groen, Jeroen ; and Tr{\"{a}}ff, Erik ; and Wang, Yiqiang ; and Sigmund, Ole},
    url = {https://orbit.dtu.dk/en/publications/simple-single-scale-interpretations-of-optimal-designs-in-the-con}
}

@article{BendsoeKikuchi1988,
    title = {{Generating optimal topologies in structural design using a homogenization method}},
    year = {1988},
    journal = {Computer Methods in Applied Mechanics and Engineering},
    author = {Bends{\o}e, Martin Philip and Kikuchi, Noboru},
    number = {2},
    month = {11},
    pages = {197--224},
    volume = {71},
    url = {https://linkinghub.elsevier.com/retrieve/pii/0045782588900862},
    doi = {10.1016/0045-7825(88)90086-2},
    issn = {00457825}
}

@article{ZhengHeLiu2021,
    title = {{Generating three-dimensional structural topologies via a U-Net convolutional neural network}},
    year = {2021},
    journal = {Thin-Walled Structures},
    author = {Zheng, Shuai and He, Zhenzhen and Liu, Honglei},
    month = {2},
    pages = {107263},
    volume = {159},
    publisher = {Elsevier Ltd},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0263823120311319},
    doi = {10.1016/j.tws.2020.107263},
    issn = {02638231},
    keywords = {Computational efficiency, Convolutional neural network, Three dimensions, Topology optimization, Variable design domain}
}

@article{Hertleinetal2021,
    title = {{Generative adversarial network for early-stage design flexibility in topology optimization for additive manufacturing}},
    year = {2021},
    journal = {Journal of Manufacturing Systems},
    author = {Hertlein, Nathan and Buskohl, Philip R. and Gillman, Andrew and Vemaganti, Kumar and Anand, Sam},
    month = {4},
    pages = {675--685},
    volume = {59},
    publisher = {Elsevier B.V.},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S027861252100087X},
    doi = {10.1016/j.jmsy.2021.04.007},
    issn = {02786125},
    keywords = {Additive manufacturing, Deep learning, Generative adversarial network, Topology optimization}
}

@article{LiShietal2021,
    title = {{Generative adversarial network guided topology optimization of periodic structures via Subset Simulation}},
    year = {2021},
    journal = {Composite Structures},
    author = {Li, Min and Jia, Gaofeng and Cheng, Zhibao and Shi, Zhifei},
    month = {3},
    pages = {113254},
    volume = {260},
    publisher = {Elsevier Ltd},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0263822320331809},
    doi = {10.1016/j.compstruct.2020.113254},
    issn = {02638223},
    keywords = {Frequency bandgap, Generative adversarial network, Machine learning, Periodic structures, Subset Simulation, Topology optimization}
}

@inproceedings{Greminger2020,
    title = {{Generative Adversarial Networks With Synthetic Training Data for Enforcing Manufacturing Constraints on Topology Optimization}},
    year = {2020},
    booktitle = {Volume 11A: 46th Design Automation Conference (DAC)},
    author = {Greminger, Michael},
    month = {8},
    publisher = {American Society of Mechanical Engineers},
    url = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings/IDETC-CIE2020/84003/Virtual,%20Online/1090207},
    organization = {Proceedings of the ASME 2020 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference.},
    isbn = {978-0-7918-8400-3},
    doi = {10.1115/DETC2020-22399},
    keywords = {Topology optimization, deep learning, design for manufacturability, generative adversarial networks, manufacturing constraints}
}

@article{ChenGu2020,
    title = {{Generative Deep Neural Networks for Inverse Materials Design Using Backpropagation and Active Learning}},
    year = {2020},
    journal = {Advanced Science},
    author = {Chen, ChunTeh and Gu, Grace X.},
    number = {5},
    month = {3},
    pages = {1902607},
    volume = {7},
    url = {https://onlinelibrary.wiley.com/doi/10.1002/advs.201902607},
    doi = {10.1002/advs.201902607},
    issn = {2198-3844}
}

@article{JangYooKang2020,
    title = {{Generative Design by Reinforcement Learning: Enhancing the Diversity of Topology Optimization Designs}},
    year = {2022},
    journal = {Computer-Aided Design},
    author = {Jang, Seowoo and Yoo, Soyoung and Kang, Namwoo},
    month = {5},
    pages = {103225},
    volume = {146},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0010448522000239},
    doi = {10.1016/j.cad.2022.103225},
    issn = {00104485}
}

@article{SunMa2020,
    title = {{Generative Design by Using Exploration Approaches of Reinforcement Learning in Density-Based Structural Topology Optimization}},
    year = {2020},
    journal = {Designs},
    author = {Sun, Hongbo and Ma, Ling},
    number = {2},
    month = {5},
    pages = {10},
    volume = {4},
    publisher = {MDPI AG},
    url = {https://www.mdpi.com/2411-9660/4/2/10},
    doi = {10.3390/designs4020010},
    issn = {2411-9660},
    keywords = {Bi-directional evolutionary optimization, Exploration, Generative design, Reinforcement learning, Solid isotropic microstructure with penalization, Structural topology optimization}
}

@article{JiengFan2019_nano1,
    title = {{Global Optimization of Dielectric Metasurfaces Using a Physics-Driven Neural Network}},
    year = {2019},
    journal = {Nano Letters},
    author = {Jiang, Jiaqi and Fan, Jonathan A.},
    number = {8},
    month = {8},
    pages = {5366--5372},
    volume = {19},
    url = {https://pubs.acs.org/doi/10.1021/acs.nanolett.9b01857},
    doi = {10.1021/acs.nanolett.9b01857},
    issn = {1530-6984}
}

@inproceedings{LiWuChrysathouetal2011,
    title = {{GlobFit}},
    year = {2011},
    booktitle = {ACM SIGGRAPH 2011 papers on - SIGGRAPH '11},
    author = {Li, Yangyan and Wu, Xiaokun and Chrysathou, Yiorgos and Sharf, Andrei and Cohen-Or, Daniel and Mitra, Niloy J.},
    pages = {1},
    publisher = {ACM Press},
    address = {New York, New York, USA},
    isbn = {9781450309431},
    doi = {10.1145/1964921.1964947}
}

@article{LiWuetal2011,
    title = {{GlobFit}},
    year = {2011},
    journal = {ACM Transactions on Graphics},
    author = {Li, Yangyan and Wu, Xiaokun and Chrysathou, Yiorgos and Sharf, Andrei and Cohen-Or, Daniel and Mitra, Niloy J.},
    number = {4},
    month = {7},
    pages = {1--12},
    volume = {30},
    doi = {10.1145/2010324.1964947},
    issn = {0730-0301}
}

@article{Kingma2018,
    title = {{Glow: Generative Flow with Invertible 1x1 Convolutions}},
    year = {2018},
    author = {Kingma, Diederik P. and Dhariwal, Prafulla},
    month = {7},
    arxivId = {1807.03039}
}

@article{MaZeng2020,
    title = {{High-risk prediction localization: evaluating the reliability of black box models for topology optimization}},
    year = {2020},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Ma, Fulei and Zeng, Zhi},
    number = {6},
    month = {12},
    pages = {3053--3069},
    volume = {62},
    publisher = {Springer Science and Business Media Deutschland GmbH},
    url = {https://link.springer.com/10.1007/s00158-020-02648-7},
    doi = {10.1007/s00158-020-02648-7},
    issn = {1615-147X},
    keywords = {Error distribution, Neural network, Topology optimization}
}

@article{Groen16,
    title = {{Higher-order multi-resolution topology optimization using the finite cell method}},
    year = {2017},
    journal = {International Journal for Numerical Methods in Engineering},
    author = {Groen, Jeroen P. and Langelaar, Matthijs and Sigmund, Ole and Ruess, Martin},
    number = {10},
    month = {6},
    pages = {903--920},
    volume = {110},
    publisher = {John Wiley and Sons Ltd},
    url = {https://onlinelibrary.wiley.com/doi/10.1002/nme.5432},
    doi = {10.1002/nme.5432},
    issn = {00295981},
    keywords = {finite cell method, higher-order FEM, topology optimization}
}

@article{Groen18,
    title = {{Homogenization-based topology optimization for high-resolution manufacturable microstructures}},
    year = {2018},
    journal = {International Journal for Numerical Methods in Engineering},
    author = {Groen, Jeroen P. and Sigmund, Ole},
    number = {8},
    month = {2},
    pages = {1148--1163},
    volume = {113},
    publisher = {John Wiley and Sons Ltd},
    url = {https://onlinelibrary.wiley.com/doi/10.1002/nme.5575},
    doi = {10.1002/nme.5575},
    issn = {00295981},
    keywords = {high-resolution, homogenization, manufacturing constraints, topology optimization}
}

@techreport{Tiwarietal2018,
    title = {{How Artificial Intelligence, Machine Learning and Deep Learning are Radically Different?}},
    year = {2018},
    booktitle = {International Journals of Advanced Research in Computer Science and Software Engineering},
    author = {Tiwari, Tanya and Tiwari, Tanuj and Tiwari, Sanjay},
    number = {2},
    pages = {2277--128},
    url = {www.ijarcsse.com,},
    keywords = {Artificial Intelligence, Deep Learning, Machine Learning}
}

@article{KesAliTas2021,
    title = {{Image-Based Multiresolution Topology Optimization Using Deep Disjunctive Normal Shape Model}},
    year = {2021},
    journal = {Computer-Aided Design},
    author = {Keshavarzzadeh, Vahid and Alirezaei, Mitra and Tasdizen, Tolga and Kirby, Robert M.},
    month = {1},
    pages = {102947},
    volume = {130},
    publisher = {Elsevier Ltd},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0010448520301408},
    doi = {10.1016/j.cad.2020.102947},
    issn = {00104485},
    keywords = {Deep neural networks, Image-based segmentation, Multiresolution analysis, Topology optimization}
}

@article{Krizhevskyetal2017,
    title = {{ImageNet classification with deep convolutional neural networks}},
    year = {2017},
    journal = {Communications of the ACM},
    author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
    number = {6},
    month = {5},
    pages = {84--90},
    volume = {60},
    url = {https://dl.acm.org/doi/10.1145/3065386},
    doi = {10.1145/3065386},
    issn = {0001-0782}
}

@article{Nguyenetal2012,
    title = {{Improving multiresolution topology optimization via multiple discretizations}},
    year = {2012},
    journal = {International Journal for Numerical Methods in Engineering},
    author = {Nguyen, Tam H. and Paulino, Glaucio H. and Song, Junho and Le, Chau H.},
    number = {6},
    month = {11},
    pages = {507--530},
    volume = {92},
    url = {https://onlinelibrary.wiley.com/doi/10.1002/nme.4344},
    doi = {10.1002/nme.4344},
    issn = {00295981},
    keywords = {Adaptive optimization, Density mesh, Design variable, Finite elements, Multiresolution, Multiresolution topology optimization (MTOP)}
}

@article{WuAageetal2018,
    title = {{Infill Optimization for Additive ManufacturingApproaching Bone-Like Porous Structures}},
    year = {2018},
    journal = {IEEE Transactions on Visualization and Computer Graphics},
    author = {Wu, Jun and Aage, Niels and Westermann, Rudiger and Sigmund, Ole},
    number = {2},
    month = {2},
    pages = {1127--1140},
    volume = {24},
    doi = {10.1109/TVCG.2017.2655523},
    issn = {1077-2626}
}

@article{Yildizetal2003,
    title = {{Integrated optimal topology design and shape optimization using neural networks}},
    year = {2003},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Yildiz, A.R. and {\"{O}}zt{\"{u}}rk, N. and Kaya, N. and {\"{O}}zt{\"{u}}rk, F.},
    number = {4},
    month = {10},
    pages = {251--260},
    volume = {25},
    url = {http://link.springer.com/10.1007/s00158-003-0300-0},
    doi = {10.1007/s00158-003-0300-0},
    issn = {1615-147X},
    keywords = {Feature recognition, Neural networks, Shape optimization, Topology optimization}
}

@article{Yooetal2021,
    title = {{Integrating deep learning into CAD/CAE system: generative design and evaluation of 3D conceptual wheel}},
    year = {2021},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Yoo, Soyoung and Lee, Sunghee and Kim, Seongsin and Hwang, Kwang Hyeon and Park, Jong Ho and Kang, Namwoo},
    number = {4},
    month = {10},
    pages = {2725--2747},
    volume = {64},
    publisher = {Springer Science and Business Media Deutschland GmbH},
    url = {https://link.springer.com/10.1007/s00158-021-02953-9},
    doi = {10.1007/s00158-021-02953-9},
    issn = {1615-147X},
    keywords = {Artificial intelligence, CAD, CAE, Deep learning, Generative design, Topology optimization}
}

@article{Vulimirietal2021,
    title = {{Integrating Geometric Data into Topology Optimization via Neural Style Transfer}},
    year = {2021},
    journal = {Materials},
    author = {Vulimiri, Praveen S. and Deng, Hao and Dugast, Florian and Zhang, Xiaoli and To, Albert C.},
    number = {16},
    month = {8},
    pages = {4551},
    volume = {14},
    publisher = {MDPI AG},
    url = {https://www.mdpi.com/1996-1944/14/16/4551},
    doi = {10.3390/ma14164551},
    issn = {1996-1944},
    keywords = {Additive manufacturing, Neural network, Neural style transfer, Topology optimization}
}

@article{Duetal2018,
    title = {{InverseCSG}},
    year = {2018},
    journal = {ACM Transactions on Graphics},
    author = {Du, Tao and Inala, Jeevana Priya and Pu, Yewen and Spielberg, Andrew and Schulz, Adriana and Rus, Daniela and Solar-Lezama, Armando and Matusik, Wojciech},
    number = {6},
    month = {12},
    pages = {1--16},
    volume = {37},
    doi = {10.1145/3272127.3275006},
    issn = {0730-0301}
}

@article{Linetal2018,
    title = {{Investigation into the topology optimization for conductive heat transfer based on deep learning approach}},
    year = {2018},
    journal = {International Communications in Heat and Mass Transfer},
    author = {Lin, Qiyin and Hong, Jun and Liu, Zheng and Li, Baotong and Wang, Jihong},
    month = {10},
    pages = {103--109},
    volume = {97},
    publisher = {Elsevier Ltd},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0735193318301593},
    doi = {10.1016/j.icheatmasstransfer.2018.07.001},
    issn = {07351933},
    keywords = {Conductive heat transfer, Deep learning, SIMP, Topology optimization}
}

@article{LazarovSigmund2016,
    title = {{Length scale and manufacturability in density-based topology optimization}},
    year = {2016},
    journal = {Archive of Applied Mechanics},
    author = {Lazarov, Boyan S. and Wang, Fengwen and Sigmund, Ole},
    number = {1-2},
    month = {1},
    pages = {189--218},
    volume = {86},
    url = {http://link.springer.com/10.1007/s00419-015-1106-4},
    doi = {10.1007/s00419-015-1106-4},
    issn = {0939-1533}
}

@article{ChandraSuresh2022,
    title = {{Length Scale Control in Topology Optimization using Fourier Enhanced Neural Networks}},
    year = {2021},
    journal = {Preprint},
    author = {Chandrasekhar, Aaditya and Suresh, Krishnan},
    month = {9},
    url = {http://arxiv.org/abs/2109.01861},
    arxivId = {2109.01861}
}

@article{Janieschetal2021,
    title = {{Machine learning and deep learning}},
    year = {2021},
    journal = {Electronic Markets},
    author = {Janiesch, Christian and Zschech, Patrick and Heinrich, Kai},
    number = {3},
    month = {9},
    pages = {685--695},
    volume = {31},
    publisher = {Springer Science and Business Media LLC},
    url = {https://link.springer.com/10.1007/s12525-021-00475-2},
    doi = {10.1007/s12525-021-00475-2},
    issn = {1019-6781}
}

@article{Jiangetal2020,
    title = {{Machine Learning based parameter tuning strategy for MMC based topology optimization}},
    year = {2020},
    journal = {Advances in Engineering Software},
    author = {Jiang, Xinchao and Wang, Hu and Li, Yu and Mo, Kangjia},
    month = {11},
    pages = {102841},
    volume = {149},
    publisher = {Elsevier Ltd},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0965997820300363},
    doi = {10.1016/j.advengsoft.2020.102841},
    issn = {09659978},
    keywords = {Extra-Trees, Image classification, Machine Learning, Moving morphable component, Parameter tuning, Topology optimization}
}

@article{XuGaoSteven2021,
    title = {{Machine learning based topology optimization of fiber orientation for variable stiffness composite structures}},
    year = {2021},
    journal = {International Journal for Numerical Methods in Engineering},
    author = {Xu, Yanan and Gao, Yunkai and Wu, Chi and Fang, Jianguang and Sun, Guangyong and Steven, Grant P. and Li, Qing},
    number = {22},
    month = {11},
    pages = {6736--6755},
    volume = {122},
    url = {https://onlinelibrary.wiley.com/doi/10.1002/nme.6809},
    doi = {10.1002/nme.6809},
    issn = {0029-5981}
}

@article{Sanchezetal2020,
    title = {{Machine learning in structural engineering}},
    year = {2020},
    journal = {Scientia Iranica A},
    author = {Amezquita-Sanchez, J P and Valtierra-Rodriguez, M and Adeli, H},
    number = {6},
    pages = {2645--2656},
    url = {http://scientiairanica.sharif.edu},
    doi = {10.24200/sci.2020.22091},
    keywords = {Civil structures, Deep learning, Machine learning, Prediction, Structural design, Structural engineering, Structural health monitoring, System identiication, Vibration control}
}

@article{Lynchetal2019,
    title = {{Machine Learning to Aid Tuning of Numerical Parameters in Topology Optimization}},
    year = {2019},
    journal = {Journal of Mechanical Design},
    author = {Lynch, Matthew E. and Sarkar, Soumalya and Maute, Kurt},
    number = {11},
    month = {11},
    volume = {141},
    publisher = {American Society of Mechanical Engineers (ASME)},
    url = {https://asmedigitalcollection.asme.org/mechanicaldesign/article/doi/10.1115/1.4044228/955325/Machine-Learning-to-Aid-Tuning-of-Numerical},
    doi = {10.1115/1.4044228},
    issn = {1050-0472},
    keywords = {Bayesian optimization, Conceptual design, Design automation, Design optimization, Machine learning, Meta learning, Metamodeling, Topology optimization}
}

@article{KimLeeYoo2021,
    title = {{Machine learning-combined topology optimization for functionary graded composite structure design}},
    year = {2021},
    journal = {Computer Methods in Applied Mechanics and Engineering},
    author = {Kim, Cheolwoong and Lee, Jaewook and Yoo, Jeonghoon},
    month = {12},
    pages = {114158},
    volume = {387},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782521004898},
    doi = {10.1016/j.cma.2021.114158},
    issn = {00457825}
}

@article{Leietal2019,
    title = {{Machine Learning-Driven Real-Time Topology Optimization Under Moving Morphable Component-Based Framework}},
    year = {2019},
    journal = {Journal of Applied Mechanics},
    author = {Lei, Xin and Liu, Chang and Du, Zongliang and Zhang, Weisheng and Guo, Xu},
    number = {1},
    month = {1},
    volume = {86},
    publisher = {American Society of Mechanical Engineers (ASME)},
    url = {https://asmedigitalcollection.asme.org/appliedmechanics/article/doi/10.1115/1.4041319/423490/Machine-LearningDriven-RealTime-Topology},
    doi = {10.1115/1.4041319},
    issn = {0021-8936},
    keywords = {machine learning, moving morphable component (MMC), real-time optimization, topology optimization}
}

@article{ZhuGuoetal2021,
    title = {{Machine-specified ground structures for topology optimization of binary trusses using graph embedding policy network}},
    year = {2021},
    journal = {Advances in Engineering Software},
    author = {Zhu, Shaojun and Ohsaki, Makoto and Hayashi, Kazuki and Guo, Xiaonong},
    month = {9},
    pages = {103032},
    volume = {159},
    publisher = {Elsevier Ltd},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0965997821000612},
    doi = {10.1016/j.advengsoft.2021.103032},
    issn = {09659978},
    keywords = {Binary trusses, Graph embedding, Machine-specified ground structures, Reinforcement learning, Topology optimization}
}

@article{Goodfellowetal2018,
    title = {{Making machine learning robust against adversarial inputs}},
    year = {2018},
    journal = {Communications of the ACM},
    author = {Goodfellow, Ian and McDaniel, Patrick and Papernot, Nicolas},
    number = {7},
    month = {6},
    pages = {56--66},
    volume = {61},
    url = {https://dl.acm.org/doi/10.1145/3134599},
    doi = {10.1145/3134599},
    issn = {0001-0782}
}

@article{LazarovWang2017,
    title = {{Maximum length scale in density based topology optimization}},
    year = {2017},
    journal = {Computer Methods in Applied Mechanics and Engineering},
    author = {Lazarov, Boyan S. and Wang, Fengwen},
    month = {5},
    pages = {826--844},
    volume = {318},
    publisher = {Elsevier B.V.},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782516302699},
    doi = {10.1016/j.cma.2017.02.018},
    issn = {00457825},
    keywords = {Length scale, Manufacturability, Robust design, Topology optimization}
}

@article{ChandraSuresh2021,
    title = {{Multi-Material Topology Optimization Using Neural Networks}},
    year = {2021},
    journal = {Computer-Aided Design},
    author = {Chandrasekhar, Aaditya and Suresh, Krishnan},
    month = {7},
    pages = {103017},
    volume = {136},
    publisher = {Elsevier Ltd},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0010448521000282},
    doi = {10.1016/j.cad.2021.103017},
    issn = {00104485},
    keywords = {Multi-material, Neural networks, SIMP, Thin features, Topology optimization}
}

@article{Bieleckietal2021,
    title = {{Multi-stage deep neural network accelerated topology optimization}},
    year = {2021},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Bielecki, Dustin and Patel, Darshil and Rai, Rahul and Dargush, Gary F.},
    number = {6},
    month = {12},
    pages = {3473--3487},
    volume = {64},
    url = {https://link.springer.com/10.1007/s00158-021-03028-5},
    doi = {10.1007/s00158-021-03028-5},
    issn = {1615-147X}
}

@article{Yilinetal2021,
    title = {{Multiscale topology optimisation with nonparametric microstructures using three-dimensional convolutional neural network (3D-CNN) models}},
    year = {2021},
    journal = {Virtual and Physical Prototyping},
    author = {Yilin, Guo and Fuh Ying Hsi, Jerry and Wen Feng, Lu},
    number = {3},
    month = {5},
    pages = {306--317},
    volume = {16},
    url = {https://www.tandfonline.com/doi/full/10.1080/17452759.2021.1913783},
    doi = {10.1080/17452759.2021.1913783},
    issn = {1745-2759}
}

@article{Djourachkovitchetal2021,
    title = {{Multiscale topology optimization of 3D structures: A micro-architectured materials database assisted strategy}},
    year = {2021},
    journal = {Computers {\&} Structures},
    author = {Djourachkovitch, Tristan and Blal, Nawfal and Hamila, Nahiene and Gravouil, Anthony},
    month = {10},
    pages = {106574},
    volume = {255},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0045794921000961},
    doi = {10.1016/j.compstruc.2021.106574},
    issn = {00457949}
}

@article{Whiteetal2018,
    title = {{Multiscale topology optimization using neural network surrogate models}},
    year = {2019},
    journal = {Computer Methods in Applied Mechanics and Engineering},
    author = {White, Daniel A. and Arrighi, William J. and Kudo, Jun and Watts, Seth E.},
    month = {4},
    pages = {1118--1135},
    volume = {346},
    publisher = {Elsevier B.V.},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S004578251830450X},
    doi = {10.1016/j.cma.2018.09.007},
    issn = {00457825},
    keywords = {Material models, Multiscale analysis, Neural networks, Topology optimization}
}

@article{SosnovikOseledets2017,
    title = {{Neural networks for topology optimization}},
    year = {2017},
    journal = {Preprint},
    author = {Sosnovik, Ivan and Oseledets, Ivan},
    month = {9},
    url = {http://arxiv.org/abs/1709.09578},
    arxivId = {1709.09578}
}

@article{Hoyeretal2019,
    title = {{Neural reparameterization improves structural optimization}},
    year = {2019},
    journal = {Preprint},
    author = {Hoyer, Stephan and Sohl-Dickstein, Jascha and Greydanus, Sam},
    month = {9},
    url = {http://arxiv.org/abs/1909.04240},
    arxivId = {1909.04240}
}

@article{LiBetal2019,
    title = {{Non-iterative structural topology optimization using deep learning}},
    year = {2019},
    journal = {Computer-Aided Design},
    author = {Li, Baotong and Huang, Congjia and Li, Xin and Zheng, Shuai and Hong, Jun},
    month = {10},
    pages = {172--180},
    volume = {115},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S001044851930185X},
    doi = {10.1016/j.cad.2019.05.038},
    issn = {00104485},
    keywords = {Deep learning, Generative adversarial network, Heat conduction, Hierarchical refinement, Topology optimization}
}

@article{Kobyzev2021,
    title = {{Normalizing Flows: An Introduction and Review of Current Methods}},
    year = {2021},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    author = {Kobyzev, Ivan and Prince, Simon J.D. and Brubaker, Marcus A.},
    number = {11},
    month = {11},
    pages = {3964--3979},
    volume = {43},
    doi = {10.1109/TPAMI.2020.2992934},
    issn = {0162-8828}
}

@article{Zehnderetal2021,
    title = {{NTopo: Mesh-free Topology Optimization using Implicit Neural Representations}},
    year = {2021},
    journal = {Preprint},
    author = {Zehnder, Jonas and Li, Yue and Coros, Stelian and Thomaszewski, Bernhard},
    month = {2},
    url = {http://arxiv.org/abs/2102.10782},
    arxivId = {2102.10782}
}

@article{WangLazSig11,
    title = {{On projection methods, convergence and robust formulations in topology optimization}},
    year = {2011},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Wang, Fengwen and Lazarov, Boyan Stefanov and Sigmund, Ole},
    number = {6},
    month = {6},
    pages = {767--784},
    volume = {43},
    url = {http://link.springer.com/10.1007/s00158-010-0602-y},
    doi = {10.1007/s00158-010-0602-y},
    issn = {1615-147X},
    keywords = {Compliant mechanisms, Manufacturing constraints, Robust design, Topology optimization}
}

@article{AmirSigmund2011,
    title = {{On reducing computational effort in topology optimization: how far can we go?}},
    year = {2011},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Amir, Oded and Sigmund, Ole},
    number = {1},
    month = {7},
    pages = {25--29},
    volume = {44},
    url = {http://link.springer.com/10.1007/s00158-010-0586-7},
    doi = {10.1007/s00158-010-0586-7},
    issn = {1615-147X}
}

@article{LeeGeMa2017,
    title = {{On the ability of neural nets to express distributions}},
    year = {2017},
    author = {Lee, Holden and Ge, Rong and Ma, Tengyu and Risteski, Andrej and Arora, Sanjeev},
    month = {2},
    arxivId = {1702.07028}
}

@article{SigmundGA2011,
    title = {{On the usefulness of non-gradient approaches in topology optimization}},
    year = {2011},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Sigmund, Ole},
    number = {5},
    month = {5},
    pages = {589--596},
    volume = {43},
    url = {http://link.springer.com/10.1007/s00158-011-0638-7},
    doi = {10.1007/s00158-011-0638-7},
    issn = {1615-147X}
}

@article{CanYaoRen2019,
    title = {{One-shot generation of near-optimal topology through theory-driven machine learning}},
    year = {2019},
    journal = {Computer-Aided Design},
    author = {Cang, Ruijin and Yao, Hope and Ren, Yi},
    month = {4},
    pages = {12--21},
    volume = {109},
    publisher = {Elsevier Ltd},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0010448518303828},
    doi = {10.1016/j.cad.2018.12.008},
    issn = {00104485},
    keywords = {Active learning, Meta-learning, Topology optimization}
}

@article{Bendsoe1989,
    title = {{Optimal shape design as a material distribution problem}},
    year = {1989},
    journal = {Structural Optimization},
    author = {Bends{\o}e, M. P.},
    number = {4},
    month = {12},
    pages = {193--202},
    volume = {1},
    url = {http://link.springer.com/10.1007/BF01650949},
    doi = {10.1007/BF01650949},
    issn = {0934-4373}
}

@article{AdeliPark1995b,
    title = {{Optimization of space structures by neural dynamics}},
    year = {1995},
    journal = {Neural Networks},
    author = {Adeli, Hojjat and Park, Hyo Seon},
    number = {5},
    month = {1},
    pages = {769--781},
    volume = {8},
    url = {https://linkinghub.elsevier.com/retrieve/pii/089360809500026V},
    doi = {10.1016/0893-6080(95)00026-V},
    issn = {08936080},
    keywords = {Design automation, Lyapunov function, Neural networks, minimum weight design, optimization, trusses}
}

@article{Raissietal2019,
    title = {{Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations}},
    year = {2019},
    journal = {Journal of Computational Physics},
    author = {Raissi, M. and Perdikaris, P. and Karniadakis, G.E.},
    month = {2},
    pages = {686--707},
    volume = {378},
    publisher = {Academic Press Inc.},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999118307125},
    doi = {10.1016/j.jcp.2018.10.045},
    issn = {00219991},
    keywords = {Data-driven scientific computing, Machine learning, Nonlinear dynamics, Predictive modeling, RungeKutta methods}
}

@article{YangHuangHao2019,
    title = {{PointFlow: 3D Point Cloud Generation with Continuous Normalizing Flows}},
    year = {2019},
    author = {Yang, Guandao and Huang, Xun and Hao, Zekun and Liu, Ming-Yu and Belongie, Serge and Hariharan, Bharath},
    month = {6},
    arxivId = {1906.12320}
}

@article{Garlandtetal2021,
    title = {{Pragmatic generative optimization of novel structural lattice metamaterials with machine learning}},
    year = {2021},
    journal = {Materials {\&} Design},
    author = {Garland, Anthony P. and White, Benjamin C. and Jensen, Scott C. and Boyce, Brad L.},
    month = {5},
    pages = {109632},
    volume = {203},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0264127521001854},
    doi = {10.1016/j.matdes.2021.109632},
    issn = {02641275}
}

@article{AbueiddaAlsmarietal2019,
    title = {{Prediction and optimization of mechanical properties of composites using convolutional neural networks}},
    year = {2019},
    journal = {Composite Structures},
    author = {Abueidda, Diab W. and Almasri, Mohammad and Ammourah, Rami and Ravaioli, Umberto and Jasiuk, Iwona M. and Sobh, Nahil A.},
    month = {11},
    pages = {111264},
    volume = {227},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0263822319312383},
    doi = {10.1016/j.compstruct.2019.111264},
    issn = {02638223}
}

@article{Behzadi_Ilies2021,
    title = {{Real-Time Topology Optimization in 3D via Deep Transfer Learning}},
    year = {2021},
    journal = {Computer-Aided Design},
    author = {Behzadi, Mohammad Mahdi and Ilie{\c{s}}, Horea T.},
    month = {6},
    pages = {103014},
    volume = {135},
    publisher = {Elsevier Ltd},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0010448521000257},
    doi = {10.1016/j.cad.2021.103014},
    issn = {00104485},
    keywords = {Deep learning, Design space explorations, Real-time predictions, Topology optimization, Transfer learning}
}

@book{MarcusDavis2019,
    title = {{Rebooting AI: Building Artificial Intelligence We Can Trust}},
    year = {2019},
    author = {Marcus, Gary and Davis, Ernest},
    publisher = {Pantheon Books},
    address = {USA},
    isbn = {1524748250}
}

@article{PanYuYietal2019,
    title = {{Recent Progress on Generative Adversarial Networks (GANs): A Survey}},
    year = {2019},
    journal = {IEEE Access},
    author = {Pan, Zhaoqing and Yu, Weijie and Yi, Xiaokai and Khan, Asifullah and Yuan, Feng and Zheng, Yuhui},
    pages = {36322--36333},
    volume = {7},
    publisher = {Institute of Electrical and Electronics Engineers Inc.},
    url = {https://ieeexplore.ieee.org/document/8667290/},
    doi = {10.1109/ACCESS.2019.2905015},
    issn = {2169-3536},
    keywords = {Deep learning, generative adversarial networks, machine learning, unsupervised learning}
}

@book{Balasetal2020,
    title = {{Recent Trends and Advances in Artificial Intelligence and Internet of Things}},
    year = {2020},
    author = {Balas, Valentina E and Kumar, Raghvendra and Srivastava, Rajshree},
    editor = {Balas, Valentina E. and Kumar, Raghvendra and Srivastava, Rajshree},
    series = {Intelligent Systems Reference Library},
    volume = {172},
    publisher = {Springer International Publishing},
    url = {http://link.springer.com/10.1007/978-3-030-32644-9},
    address = {Cham},
    isbn = {978-3-030-32643-2},
    doi = {10.1007/978-3-030-32644-9}
}

@article{HayashiOhsaki2020,
    title = {{Reinforcement Learning and Graph Embedding for Binary Truss Topology Optimization Under Stress and Displacement Constraints}},
    year = {2020},
    journal = {Frontiers in Built Environment},
    author = {Hayashi, Kazuki and Ohsaki, Makoto},
    month = {4},
    volume = {6},
    publisher = {Frontiers Media S.A.},
    url = {https://www.frontiersin.org/article/10.3389/fbuil.2020.00059/full},
    doi = {10.3389/fbuil.2020.00059},
    issn = {2297-3362},
    keywords = {binary-type approach, graph embedding, machine learning, reinforcement learning, stress and displacement constraints, topology optimization, truss}
}

@article{PapaLaga2002,
    title = {{Reliability-based structural optimization using neural networks and Monte Carlo simulation}},
    year = {2002},
    journal = {Computer Methods in Applied Mechanics and Engineering},
    author = {Papadrakakis, Manolis and Lagaros, Nikos D},
    number = {32},
    month = {6},
    pages = {3491--3507},
    volume = {191},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782502002876},
    doi = {10.1016/S0045-7825(02)00287-6},
    issn = {00457825},
    keywords = {Evolution strategies, Monte Carlo simulation, Neural networks, Parallel computations, Reliability analysis, Structural optimization}
}

@article{ChanDaWang2021,
    title = {{Remixing Functionally Graded Structures: Data-Driven Topology Optimization with Multiclass Shape Blending}},
    year = {2021},
    journal = {Preprint},
    author = {Chan, Yu-Chin and Da, Daicong and Wang, Liwei and Chen, Wei},
    month = {12},
    url = {http://arxiv.org/abs/2112.00648},
    arxivId = {2112.00648}
}

@article{Buonamici2018,
    title = {{Reverse engineering modeling methods and tools: a survey}},
    year = {2018},
    journal = {Computer-Aided Design and Applications},
    author = {Buonamici, Francesco and Carfagni, Monica and Furferi, Rocco and Governi, Lapo and Lapini, Alessandro and Volpe, Yary},
    number = {3},
    month = {5},
    pages = {443--464},
    volume = {15},
    doi = {10.1080/16864360.2017.1397894},
    issn = {1686-4360}
}

@article{KesKirNara2021,
    title = {{Robust topology optimization with low rank approximation using artificial neural networks}},
    year = {2021},
    journal = {Computational Mechanics},
    author = {Keshavarzzadeh, Vahid and Kirby, Robert M. and Narayan, Akil},
    number = {6},
    month = {12},
    pages = {1297--1323},
    volume = {68},
    publisher = {Springer Science and Business Media Deutschland GmbH},
    url = {https://link.springer.com/10.1007/s00466-021-02069-3},
    doi = {10.1007/s00466-021-02069-3},
    issn = {0178-7675},
    keywords = {Artificial neural networks, Design under uncertainty, Low rank approximation, Robust topology optimization}
}

@techreport{Kothlow2021,
    title = {{Siemens blogs: 4 Myths about AI in CFD}},
    year = {2021},
    author = {Kothlow, Christina},
    url = {https://blogs.sw.siemens.com/simcenter/4-myths-about-ai-in-cfd/}
}

@article{Traffetal2019,
    title = {{Simple single-scale microstructures based on optimal rank-3 laminates}},
    year = {2019},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Tr{\"{a}}ff, E. and Sigmund, O. and Groen, J. P.},
    number = {4},
    month = {4},
    pages = {1021--1031},
    volume = {59},
    url = {http://link.springer.com/10.1007/s00158-018-2180-3},
    doi = {10.1007/s00158-018-2180-3},
    issn = {1615-147X}
}

@article{ZhangChiPaulinoetal2021,
    title = {{Speeding up Computational Morphogenesis with Online Neural Synthetic Gradients}},
    year = {2021},
    journal = {Preprint},
    author = {Zhang, Yuyu and Chi, Heng and Chen, Binghong and Tang, Tsz Ling Elaine and Mirabella, Lucia and Song, Le and Paulino, Glaucio H.},
    month = {4},
    url = {http://arxiv.org/abs/2104.12282},
    arxivId = {2104.12282}
}

@techreport{Tyflopoulosetal2018,
    title = {{State of the art of generative design and topology optimization and potential research needs}},
    year = {2018},
    booktitle = {NordDesign},
    author = {Tyflopoulos, Evangelos and Flem, David Tollnes and Steinert, Martin and Olsen, Anna},
    url = {https://www.researchgate.net/publication/334974685_State_of_the_art_of_generative_design_and_topology_optimization_and_potential_research_needs},
    isbn = {9789176851852},
    keywords = {design, finite element analysis 2, product development, topology optimization}
}

@article{NieJiangKara2020,
    title = {{Stress Field Prediction in Cantilevered Structures Using Convolutional Neural Networks}},
    year = {2020},
    journal = {Journal of Computing and Information Science in Engineering},
    author = {Nie, Zhenguo and Jiang, Haoliang and Kara, Levent Burak},
    number = {1},
    month = {2},
    volume = {20},
    publisher = {American Society of Mechanical Engineers (ASME)},
    url = {https://asmedigitalcollection.asme.org/computingengineering/article/doi/10.1115/1.4044097/955168/Stress-Field-Prediction-in-Cantilevered-Structures},
    doi = {10.1115/1.4044097},
    issn = {1530-9827},
    keywords = {CNN, Stress fields, StressNet, deep learning}
}

@techreport{Papadrakakis1998,
    title = {{Structural optimization using evolution strategies and neural networks}},
    year = {1998},
    booktitle = {Comput. Methods Appl. Mech. Engrg},
    author = {Papadrakakis, Manolis and Lagaros, Nikos D and Tsompanakis, Yiannis},
    pages = {309--333},
    volume = {156},
    isbn = {00457825/98}
}

@article{ZhouRozvany1991,
    title = {{The COC algorithm, Part II: Topological, geometrical and generalized shape optimization}},
    year = {1991},
    journal = {Computer Methods in Applied Mechanics and Engineering},
    author = {Zhou, M. and Rozvany, G.I.N.},
    number = {1-3},
    month = {8},
    pages = {309--336},
    volume = {89},
    url = {https://linkinghub.elsevier.com/retrieve/pii/0045782591900469},
    doi = {10.1016/0045-7825(91)90046-9},
    issn = {00457825}
}

@article{Thompsonetal2020,
    title = {{The Computational Limits of Deep Learning}},
    year = {2020},
    journal = {Preprint},
    author = {Thompson, Neil C. and Greenewald, Kristjan and Lee, Keeheon and Manso, Gabriel F.},
    month = {7},
    url = {http://arxiv.org/abs/2007.05558},
    arxivId = {2007.05558}
}

@article{Svanberg1987,
    title = {{The method of moving asymptotesa new method for structural optimization}},
    year = {1987},
    journal = {International Journal for Numerical Methods in Engineering},
    author = {Svanberg, Krister},
    number = {2},
    month = {2},
    pages = {359--373},
    volume = {24},
    doi = {10.1002/nme.1620240207},
    issn = {0029-5981}
}

@article{ZhangZhao2021,
    title = {{TONR: An exploration for a novel way combining neural network with topology optimization}},
    year = {2021},
    journal = {Computer Methods in Applied Mechanics and Engineering},
    author = {Zhang, Zeyu and Li, Yu and Zhou, Weien and Chen, Xiaoqian and Yao, Wen and Zhao, Yong},
    month = {12},
    pages = {114083},
    volume = {386},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S004578252100414X},
    doi = {10.1016/j.cma.2021.114083},
    issn = {00457825}
}

@article{Herath2021,
    title = {{Topologically optimal design and failure prediction using conditional generative adversarial networks}},
    year = {2021},
    journal = {International Journal for Numerical Methods in Engineering},
    author = {Herath, Sumudu and Haputhanthri, Udith},
    number = {23},
    month = {12},
    pages = {6867--6887},
    volume = {122},
    publisher = {John Wiley and Sons Ltd},
    url = {https://onlinelibrary.wiley.com/doi/10.1002/nme.6814},
    doi = {10.1002/nme.6814},
    issn = {0029-5981},
    keywords = {Von-Mises stress, conditional generative adversarial networks, data-driven topology optimization, stress prediction, topology optimization}
}

@article{Sasaki2019,
    title = {{Topology Optimization Accelerated by Deep Learning}},
    year = {2019},
    journal = {IEEE Transactions on Magnetics},
    author = {Sasaki, Hidenori and Igarashi, Hajime},
    number = {6},
    month = {6},
    pages = {1--5},
    volume = {55},
    publisher = {Institute of Electrical and Electronics Engineers Inc.},
    url = {https://ieeexplore.ieee.org/document/8673771/},
    doi = {10.1109/TMAG.2019.2901906},
    issn = {0018-9464},
    keywords = {Approximate computing, convolutional neural network (CNN), deep learning (DL), interior permanent magnet (IPM) motor, topology optimization}
}

@article{SigmundMaute2013,
    title = {{Topology optimization approaches}},
    year = {2013},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Sigmund, Ole and Maute, Kurt},
    number = {6},
    month = {12},
    pages = {1031--1055},
    volume = {48},
    url = {http://link.springer.com/10.1007/s00158-013-0978-6},
    doi = {10.1007/s00158-013-0978-6},
    issn = {1615-147X}
}

@article{DenTo2020,
    title = {{Topology optimization based on deep representation learning (DRL) for compliance and stress-constrained design}},
    year = {2020},
    journal = {Computational Mechanics},
    author = {Deng, Hao and To, Albert C.},
    number = {2},
    month = {8},
    pages = {449--469},
    volume = {66},
    publisher = {Springer},
    url = {https://link.springer.com/10.1007/s00466-020-01859-5},
    doi = {10.1007/s00466-020-01859-5},
    issn = {0178-7675},
    keywords = {Deep learning, Geometry complexity, Stress-constrained, Topology optimization}
}

@article{Abueiddaetal2020,
    title = {{Topology optimization of 2D structures with nonlinearities using deep learning}},
    year = {2020},
    journal = {Computers {\&} Structures},
    author = {Abueidda, Diab W. and Koric, Seid and Sobh, Nahil A.},
    month = {9},
    pages = {106283},
    volume = {237},
    publisher = {Elsevier Ltd},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0045794920300869},
    doi = {10.1016/j.compstruc.2020.106283},
    issn = {00457949},
    keywords = {Adjoint sensitivity, Finite element analysis (FEA), Machine learning, Neo-Hookean materials, Stress constraint}
}

@article{WuSigGro21,
    title = {{Topology optimization of multi-scale structures: a review}},
    year = {2021},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Wu, Jun and Sigmund, Ole and Groen, Jeroen P.},
    number = {3},
    month = {3},
    pages = {1455--1480},
    volume = {63},
    url = {http://link.springer.com/10.1007/s00158-021-02881-8},
    doi = {10.1007/s00158-021-02881-8},
    issn = {1615-147X}
}

@incollection{Harishetal2020,
    title = {{Topology Optimization Using Convolutional Neural Network}},
    year = {2020},
    booktitle = {Lecture Notes in Mechanical Engineering},
    author = {Harish, Baki and Eswara Sai Kumar, Kandula and Srinivasan, Balaji},
    pages = {301--307},
    publisher = {Springer},
    url = {http://link.springer.com/10.1007/978-981-15-5432-2_26},
    doi = {10.1007/978-981-15-5432-2{\_}26},
    keywords = {Convolutiondeconvolution network, Machine learning, Topology optimization}
}

@article{Luoetal2020,
    title = {{Topology optimization using material-field series expansion and Kriging-based algorithm: An effective non-gradient method}},
    year = {2020},
    journal = {Computer Methods in Applied Mechanics and Engineering},
    author = {Luo, Yangjun and Xing, Jian and Kang, Zhan},
    month = {6},
    pages = {112966},
    volume = {364},
    publisher = {Elsevier B.V.},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782520301493},
    doi = {10.1016/j.cma.2020.112966},
    issn = {00457825},
    keywords = {Kriging surrogate model, Material-field series expansion, Non-gradient, Topology optimization}
}

@article{Nieetal2020,
    title = {{TopologyGAN: Topology Optimization Using Generative Adversarial Networks Based on Physical Fields Over the Initial Domain}},
    year = {2020},
    journal = {Preprint},
    author = {Nie, Zhenguo and Lin, Tong and Jiang, Haoliang and Kara, Levent Burak},
    month = {3},
    url = {http://arxiv.org/abs/2003.04685},
    arxivId = {2003.04685}
}

@article{ChandrasekharSuresh2020,
    title = {{TOuNN: Topology Optimization using Neural Networks}},
    year = {2021},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Chandrasekhar, Aaditya and Suresh, Krishnan},
    number = {3},
    month = {3},
    pages = {1135--1149},
    volume = {63},
    publisher = {Springer Science and Business Media Deutschland GmbH},
    url = {http://link.springer.com/10.1007/s00158-020-02748-4},
    doi = {10.1007/s00158-020-02748-4},
    issn = {1615-147X},
    keywords = {Machine learning, Neural networks, Topology optimization}
}

@article{AtesGorguluarslan2021,
    title = {{Two-stage convolutional encoder-decoder network to improve the performance and reliability of deep learning models for topology optimization}},
    year = {2021},
    journal = {Structural and Multidisciplinary Optimization},
    author = {Ates, Gorkem Can and Gorguluarslan, Recep M.},
    number = {4},
    month = {4},
    pages = {1927--1950},
    volume = {63},
    publisher = {Springer Science and Business Media Deutschland GmbH},
    url = {http://link.springer.com/10.1007/s00158-020-02788-w},
    doi = {10.1007/s00158-020-02788-w},
    issn = {1615-147X},
    keywords = {Convolutional neural network, Deep learning, Encoder and decoder network, Neural network, Topology optimization}
}

@article{JooYuJang2021,
    title = {{Unit Module-Based Convergence Acceleration for Topology Optimization Using the Spatiotemporal Deep Neural Network}},
    year = {2021},
    journal = {IEEE Access},
    author = {Joo, Younghwan and Yu, Yonggyun and Jang, In Gwun},
    pages = {149766--149779},
    volume = {9},
    url = {https://ieeexplore.ieee.org/document/9599692/},
    doi = {10.1109/ACCESS.2021.3125014},
    issn = {2169-3536}
}

@article{ChiZhangetal2021,
    title = {{Universal machine learning for topology optimization}},
    year = {2021},
    journal = {Computer Methods in Applied Mechanics and Engineering},
    author = {Chi, Heng and Zhang, Yuyu and Tang, Tsz Ling Elaine and Mirabella, Lucia and Dalloro, Livio and Song, Le and Paulino, Glaucio H.},
    month = {3},
    pages = {112739},
    volume = {375},
    publisher = {Elsevier B.V.},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782519306292},
    doi = {10.1016/j.cma.2019.112739},
    issn = {00457825}
}

@article{KesBidKel2020,
    title = {{V-Dream: Immersive Exploration of Generative Design Solution Space}},
    year = {2020},
    journal = {Preprint},
    author = {Keshavarzi, Mohammad and Bidgoli, Ardavan and Kellner, Hans},
    month = {6},
    url = {http://arxiv.org/abs/2006.11044},
    arxivId = {2006.11044}
}

@article{PerKesWhi2020,
    title = {{Visualization of topology optimization designs with representative subset selection}},
    year = {2020},
    journal = {Preprint},
    author = {Perry, Daniel J and Keshavarzzadeh, Vahid and Elhabian, Shireen Y and Kirby, Robert M and Gleicher, Michael and Whitaker, Ross T},
    month = {12},
    url = {http://arxiv.org/abs/2012.14901},
    arxivId = {2012.14901}
}

@misc{Copeland2016,
    title = {{Whats the Difference Between Artificial Intelligence, Machine Learning and Deep Learning?}},
    year = {2016},
    booktitle = {NVIDIA blog (accessed 13/08/2021)},
    author = {Copeland, Michael},
    month = {7},
    url = {https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/}
}

@article{Heaven2019,
    title = {{Why deep-learning AIs are so easy to fool}},
    year = {2019},
    journal = {Nature},
    author = {Heaven, Douglas},
    number = {7777},
    month = {10},
    pages = {163--166},
    volume = {574},
    url = {http://www.nature.com/articles/d41586-019-03013-5},
    doi = {10.1038/d41586-019-03013-5},
    issn = {0028-0836}
}

@book{budynas2011shigley,
  title={Shigley's mechanical engineering design},
  author={Budynas, Richard Gordon and Nisbett, J Keith and others},
  volume={9},
  year={2011},
  publisher={McGraw-Hill New York}
}

@article{shigley1985mechanical,
  title={Mechanical engineering design},
  author={Shigley, Joseph Edward and Mitchell, Larry D and Saunders, H},
  year={1985}
}

@article{buede2016engineering,
  title={The engineering design of systems: models and methods},
  author={Buede, Dennis M and Miller, William D},
  year={2016},
  publisher={John Wiley \& Sons}
}

@article{garabedian1960partial,
  title={Partial differential equations with more than two independent variables in the complex domain},
  author={Garabedian, PR},
  journal={Journal of Mathematics and Mechanics},
  pages={241--271},
  year={1960},
  publisher={JSTOR}
}

@book{friedman2008partial,
  title={Partial differential equations of parabolic type},
  author={Friedman, Avner},
  year={2008},
  publisher={Courier Dover Publications}
}

@book{bers1964partial,
  title={Partial differential equations},
  author={Bers, Lipman and John, Fritz and Schechter, Martin},
  year={1964},
  publisher={American Mathematical Soc.}
}

@book{hale2013introduction,
  title={Introduction to functional differential equations},
  author={Hale, Jack K and Lunel, Sjoerd M Verduyn},
  volume={99},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@inproceedings{keldysh1951characteristic,
  title={On the characteristic values and characteristic functions of certain classes of non-self-adjoint equations},
  author={Keldysh, Mstislav Vsevolodovich},
  booktitle={Dokl. Akad. Nauk SSSR},
  volume={77},
  number={1},
  pages={11--14},
  year={1951}
}

@book{evans2022partial,
  title={Partial differential equations},
  author={Evans, Lawrence C},
  volume={19},
  year={2022},
  publisher={American Mathematical Society}
}

@article{manica2022gt4sd,
  title={GT4SD: Generative Toolkit for Scientific Discovery},
  author={Manica, Matteo and Cadow, Joris and Christofidellis, Dimitrios and Dave, Ashish and Born, Jannis and Clarke, Dean and Teukam, Yves Gaetan Nana and Hoffman, Samuel C and Buchan, Matthew and Chenthamarakshan, Vijil and others},
  journal={arXiv preprint arXiv:2207.03928},
  year={2022}
}

@article{song2023multi,
  title={Multi-modal Machine Learning in Engineering Design: A Review and Future Directions},
  author={Song, Binyang and Zhou, Rui and Ahmed, Faez},
  journal={arXiv preprint arXiv:2302.10909},
  year={2023}
}

@article{xiang2022accelerated,
  title={Accelerated topology optimization design of 3D structures based on deep learning},
  author={Xiang, Cheng and Wang, Dalei and Pan, Yue and Chen, Airong and Zhou, Xiaoyi and Zhang, Yiquan},
  journal={Structural and Multidisciplinary Optimization},
  volume={65},
  number={3},
  pages={99},
  year={2022},
  publisher={Springer}
}

@article{kench2021generating,
  title={Generating three-dimensional structures from a two-dimensional slice with generative adversarial network-based dimensionality expansion},
  author={Kench, Steve and Cooper, Samuel J},
  journal={Nature Machine Intelligence},
  volume={3},
  number={4},
  pages={299--305},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@article{sabiston20203d,
  title={3D topology optimization for cost and time minimization in additive manufacturing},
  author={Sabiston, Graeme and Kim, Il Yong},
  journal={Structural and Multidisciplinary Optimization},
  volume={61},
  number={2},
  pages={731--748},
  year={2020},
  publisher={Springer}
}

@article{behzadi2021real,
  title={Real-time topology optimization in 3d via deep transfer learning},
  author={Behzadi, Mohammad Mahdi and Ilie{\c{s}}, Horea T},
  journal={Computer-Aided Design},
  volume={135},
  pages={103014},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{chen2022concurrent,
  title={Concurrent build direction, part segmentation, and topology optimization for additive manufacturing using neural networks},
  author={Chen, Hongrui and Whitefoot, Kate S and Kara, Levent Burak},
  booktitle={International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
  volume={86229},
  pages={V03AT03A029},
  year={2022},
  organization={American Society of Mechanical Engineers}
}

@article{chandrasekhar2022gm,
  title={GM-TOuNN: Graded Multiscale Topology Optimization using Neural Networks},
  author={Chandrasekhar, Aaditya and Sridhara, Saketh and Suresh, Krishnan},
  journal={arXiv preprint arXiv:2204.06682},
  year={2022}
}

@article{mlejnek1992some,
  title={Some aspects of the genesis of structures},
  author={Mlejnek, HP},
  journal={Structural optimization},
  volume={5},
  pages={64--69},
  year={1992},
  publisher={Springer}
}

@article{sokolowski1999topological,
  title={On the topological derivative in shape optimization},
  author={Sokolowski, Jan and Zochowski, Antoni},
  journal={SIAM journal on control and optimization},
  volume={37},
  number={4},
  pages={1251--1272},
  year={1999},
  publisher={SIAM}
}

@article{bourdin2003design,
  title={Design-dependent loads in topology optimization},
  author={Bourdin, Blaise and Chambolle, Antonin},
  journal={ESAIM: Control, Optimisation and Calculus of Variations},
  volume={9},
  pages={19--48},
  year={2003},
  publisher={EDP Sciences}
}

@article{guest2004achieving,
  title={Achieving minimum length scale in topology optimization using nodal design variables and projection functions},
  author={Guest, James K and Pr{\'e}vost, Jean H and Belytschko, Ted},
  journal={International journal for numerical methods in engineering},
  volume={61},
  number={2},
  pages={238--254},
  year={2004},
  publisher={Wiley Online Library}
}

@article{sigmund2007morphology,
  title={Morphology-based black and white filters for topology optimization},
  author={Sigmund, Ole},
  journal={Structural and Multidisciplinary Optimization},
  volume={33},
  pages={401--424},
  year={2007},
  publisher={Springer}
}

@article{wang2011projection,
  title={On projection methods, convergence and robust formulations in topology optimization},
  author={Wang, Fengwen and Lazarov, Boyan Stefanov and Sigmund, Ole},
  journal={Structural and multidisciplinary optimization},
  volume={43},
  pages={767--784},
  year={2011},
  publisher={Springer}
}

@article{xu2010volume,
  title={Volume preserving nonlinear density filter based on heaviside functions},
  author={Xu, Shengli and Cai, Yuanwu and Cheng, Gengdong},
  journal={Structural and Multidisciplinary Optimization},
  volume={41},
  pages={495--505},
  year={2010},
  publisher={Springer}
}

@article{jumper2021highly,
  title={Highly accurate protein structure prediction with AlphaFold},
  author={Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\v{Z}}{\'\i}dek, Augustin and Potapenko, Anna and others},
  journal={Nature},
  volume={596},
  number={7873},
  pages={583--589},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@article{bond2021deep,
  title={Deep generative modelling: A comparative review of vaes, gans, normalizing flows, energy-based and autoregressive models},
  author={Bond-Taylor, Sam and Leach, Adam and Long, Yang and Willcocks, Chris G},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  year={2021},
  publisher={IEEE}
}