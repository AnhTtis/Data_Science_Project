\section{Results and Discussions}
\subsection{Baselines}
We selected two existed cutting-edge cough event detection methods as baselines. 

\begin{enumerate}
    \item \textbf{HearCough~\cite{WANG2022}.} HearCough is the first effective end-to-end continuous cough event detection method that can be deployed on commodity hearables. However, this work did not consider subject-awareness. We re-implemented and evaluated the model on our constructed dataset.
    \item \textbf{EOCD~\cite{Rahman2019effi}.} EOCD is an efficient online cough detection model deployed on smartphones. This method developed specific modules for subject-awareness and achieved outstanding subject cough event detection performance on in-lab dataset. 
\end{enumerate}

\subsection{Evaluation Metrics}
We considered the following evaluation metrics: 1) detection performance, 2) space requirement, 3) time complexity. 
\begin{itemize}
    \item \textbf{Detection performance.} We used overall accuracy and F-1 score in distinguishing subject coughs and other samples as the major metrics. Further, since subject-awareness is the ability to distinguish subject coughs and environmental coughs, we also used overall accuracy and F-1 score in distinguishing subject coughs and environmental coughs as another pair of performance metrics.
    \item \textbf{Space requirement.} Since the edge computing unit has limited on-board storage that stores the model and the temporary inputs and outputs at each layer, we used space requirement as on-chip metrics, which indicate the deployablility of the techniques.
    \item \textbf{Time complexity.} Real-time detection is an essential ability for cough event detection methods. As a result, less inference time is required, which can be represented by the less time complexity of the model. We used the FLOPs of the model as the metric of time complexity.
\end{itemize}

\subsection{Results and Findings}
We present major evaluation results of all the variants of EarCoughNet and the two baseline methods in Table ~\ref{table:evals} and Table ~\ref{table:evals_2}.

\begin{table}[H]
\begin{center}
 \caption{Evaluation results of effectiveness.}
 \small
 \begin{tabular}{c c c c c c c c c} 
 \hline
 \hline
 \textbf{Model} & \textbf{Input Size} & \textbf{Acc.-1$^+$} & \textbf{F1.-1$^+$} & \textbf{Acc.-2$^\#$} & \textbf{F1.-2$^\#$}\\ 
 \hline
 EarCoughNet & 0.5s @ 48 kHz & 93.37\% & 89.80\% & 96.9\% & 96.8\% \\ 
 \hline
 EarCoughNet & 0.5 s @ 24 kHz & 95.01\% & 92.66\% & 96.4\% & 96.2\% \\ 
 \hline
 EarCoughNet & 0.5 s @ 16 kHz & 95.23\% & 92.25\% & 95.5\% & 96.3\% \\ 
 \hline
 EarCoughNet & 0.5 s @ 8 kHz & 95.35\% & 92.89\% & 95.5\% & 94.6\% \\ 
 \hline
 EOCD$^*$ & 0.6 s @ 44.1 kHz & 94.20\% & 93.70\% & -- & -- \\ 
 \hline
 HearCough & 0.5 s @ 11 kHz & 87.88\% & 88.04\% & 51.64\% & 45.70\%\\ 
 \hline
 \hline
 
\multicolumn{6}{l}{\small $^+$ Acc. and F1. for distinguishing subject coughs and other audio samples.} \\

\multicolumn{6}{l}{\small $^\#$ Acc. and F1. for distinguishing subject coughs and environmental coughs.} \\

\multicolumn{6}{l}{\small $^*$ Unreported values in this row were not evaluated in the original work.} \\

\end{tabular}
\label{table:evals}
\end{center}
\end{table}


\begin{table}[H]
\begin{center}
 \caption{Evaluation results of computing and space requirements.}
 \small
 \begin{tabular}{c c c c c c c c c} 
 \hline
 \hline
 \textbf{Model} & \textbf{Input Size} & \textbf{Flops (M)} & \textbf{Space (kB)}\\
 \hline
 EarCoughNet & 0.5s @ 48 kHz &  73.91 & 1665\\ 
 \hline
 EarCoughNet & 0.5 s @ 24 kHz & 36.88 & 897\\ 
 \hline
 EarCoughNet & 0.5 s @ 16 kHz & 24.53 & 641\\ 
 \hline
 EarCoughNet & 0.5 s @ 8 kHz & 12.20 & 385\\ 
 \hline
 EOCD$^*$ & 0.6 s @ 44.1 kHz & -- & 99000\\ 
 \hline
 HearCough & 0.5 s @ 11 kHz & 16.20 & 480\\ 
 \hline
 \hline
\multicolumn{4}{l}{\small $^*$ Unreported values in this row were not evaluated in the original work.} \\

\end{tabular}
\label{table:evals_2}
\end{center}
\end{table}



\textbf{EarCoughNet is effective for subject cough event detection}. As shown in Table~\ref{table:evals} and ~\ref{table:evals_2}, EarCoughNet achieves comparable detection performance when compared to the EOCD model. However, as an end-to-end model, EarCoughNet has significantly less requirement in computing resources and storage space. Compared to HearCough, EarCoughNet yields higher detection performance at all sampling rates. Worth mentioning, EarCoughNet significantly outperforms HearCough in terms of subject-awareness, which reflects the weakness for works not considering subject-awareness. Since HearCough at an 11 kHz sampling rate can be deployed on the popular microcontroller of commodity hearables, EarCoughNet at 8kHz sampling rate potentially enables real-time on-board subject cough event detection with even less space and computing power compared to HearCough.

\textbf{A sampling rate at 8 kHz is sufficient for subject cough event detection using end-to-end deep learning model}. Coughing sounds have a spectral distribution between 350 Hz and 4 kHz~\cite{Shin_2009}. In order to retent the information of coughs, the sampling rate should be higher than 8kHz according to Nyquist's law. A higher sampling rate provides more high-frequency features, which are unnecessary for cough detection and even introduce more confusing information about cough-like sounds emitted by human beings, including laughter and speaking. According to the analysis of the results, EarCoughNet with a higher sampling rate increases the error rate of misidentifying cough as laughter and speaking, which causes a significant performance drop at the sampling rate of 48kHz. Compared to EarCoughNet with a sampling rate of 16 kHz or 24 kHz, EarCoughNet at the sampling rate of 8 kHz achieves equivalent detection performance with less computing power and space requirement, which showed that 8 kHz is sufficient for subject cough event detection.

\textbf{Effective subject-awareness of EarCoughNet comes from the difference of dual-channel audio}. An ablation study was conducted to investigate the reason for EarCoughNet's outstanding performance in subject-awareness. Specifically, we varied the input of EarCoughNet from dual-channel to single-channel audio from either the feedback microphone or the feed-forward microphone. As shown in ~\ref{tab:fuse_coughres}, single-channel audio-based EarCoughNet suffers from a performance drop in subject-awareness compared to the dual-channel audio-based EarCoughNet, which demonstrated that the difference between the dual-channel audio benefits the performance of subject-awareness.

\begin{table}[H]
\centering
\caption{Ablation study results of EarCoughNet}
\label{tab:fuse_coughres}
\begin{tabular}{ccc}
\hline
\hline
\textbf{Input of EarCoughNet} & \textbf{Acc.$^\#$} & \textbf{F1.$^\#$}\\ 
\hline
Dual-channel audio & 95.50\% & 94.60\% \\ 
\hline
Feed-forward microphone's audio & 88.87\% & 82.15\%  \\ 
\hline
Feedback microphone's audio & 89.77\% & 89.14\% \\ 
\hline
\hline
\multicolumn{3}{l}{\small $^\#$ Acc. and F1. for distinguishing subject coughs and environmental coughs.} \\
\end{tabular}
\end{table}

