\section{Introduction}\label{sec:intro}

% Deep learning has achieved impressive success on object detection~\cite{girshick2015fast,ren2015faster}. 
Recent years have witnessed the tremendous growth of object detection through deep neural models and large-scale training~\cite{ren2015faster,carion2020end,redmon2016you,zhu2020deformable,zhang2022dino,sun2021sparse,R_RPN,han2018semi,SSD_TDR}. However, the success of detection models heavily relies on the amount and quality of annotations, which requires expensive annotation cost and time. In addition, traditional object detection models perform worse on the classes with a limited number of annotations~\cite{wang2020frustratingly,Han_2022_CVPR,yan2019meta}, while human are able to learn from few observations. In order to close the gap between human vision system and detection models, recent studies have investigated how to generalize well on rare classes under the few-shot object detection (FSOD) setting.
% , where the base classes have plenty of data but the novel classes have extremely limited training data (\eg, 5 shot). 
Specifically, given many-shot (\textit{base}) classes with plenty of training data and few-shot (\textit{novel}) classes with extremely limited training data (\eg, 5 annotated instances per class), FSOD expects the model to detect the objects in the novel classes well.

\begin{figure}
    \centering
    \includegraphics[width=0.95\linewidth]{results/concept.pdf}
    % \vspace{-2mm}
    \caption{Performance on few-shot object detection on Pascal VOC~\cite{pascal-voc-2007}. 
    % For each method, the precision under \{3,5,10\}-shot are compared. 
    Previous transfer-learning approaches (\textcolor{cyan}{blue}) balancing the training data by aggressively down-sampling the base set and may result in overfitting. Instead, we (\textcolor{red}{red}) use the full train set, aiming to both maintain precise base detection but learn discriminative features from the limited annotations for few-shot classes.
    }
    \label{fig:concept}
    % \vspace{-4mm}
\end{figure}
% The detection precision for \textit{base} and \textit{novel} classes are represented by x- and y-axis respectively. 

% tackle the challenge of
To improve the generalization ability on novel-class detection, recent studies~\cite{sun2021fsce,wang2020frustratingly,fan2021generalized} conduct transfer learning in a two-step manner. In detail, the model is pre-trained on the whole set of base classes, and then fine-tuned on the union of the set of novel classes and an aggressively down-sampled base subset.
% \rephrase{a base subset down-sampled from the pre-train set where the numbers of annotations for all classes are the same.}
However, the efficient few-shot adaptation is often achieved at the expense of sacrificing precision on base detection (Fig.~\ref{fig:concept}).
Being aware of this limitation, Fan \etal~\cite{fan2021generalized} proposed to evaluate the performance of both base and novel classes in the generalized few-shot object detection (GFSOD) setting. In addition, they proposed a consistency regularization to emphasize the pre-trained base knowledge during fine-tuning and employed an ensembling strategy.
However, they design different classifiers for base and novel classes, and the adaptation on novel classes is impeded due to a complex ensembling process.


In this paper, we pointed out that the devil is in insufficient discriminative feature learning for few-shot object detection, including inefficient knowledge adaptation to novel classes and unexpected knowledge forgetting of base classes. First, as the novel instances are extremely limited during training, it is hard to capture the representative visual information of novel classes and adapt the knowledge learned from base classes to novel classes.
As a result, the model cannot distinguish between the novel classes, which weakens the few-shot adaptation. Secondly, balanced training strategies such as down-sampling fail to utilize the diverse training samples from base set. Thus, it is hard to preserve the complete knowledge of base classes, which leads to overfitting and further decreases the detection scores.

To tackle these challenges, we proposed a new training framework, \textbf{\approach{}}, to make the best of both worlds for generalized few-shot object detection, \ie, improving generalization on novel classes without hurting the detection of base classes. Our motivation is to learn \textbf{Di}scriminative \textbf{Geo}metry-aware features via \textit{inter-class separation} and \textit{intra-class compactness}. For inter-class separation, we expect the class centers~\cite{wen2016discriminative} to be well distinct from each other. 
Motivated by the symmetric geometry of simplex equiangular tight frame (ETF)~\cite{papyan2020prevalence}, we proposed to use ETF as classifier to guide the separation of features. To be specific, we derive an offline ETF whose weights are maximally \& equivalently separated (\ie, independent from the training data distribution) and are assigned as fixed centers for all classes.
For intra-class compactness, we expect the features to be closed to the class centers for a clear decision boundary. 
In practice, we add class-specific margins to output logits during training to 
% strengthen the optimization power and 
push the features close to the class centers.
% To achieve the compactness, we add margins to the logits output during training to strengthen the optimization power and push the features close to the class centers.
The margins are based on instance distribution prior and are then adaptively adjusted though self-distillation. Meanwhile, we consider the huge imbalance between \textit{base} set and \textit{novel} set, and up-sample the \textit{novel} set to facilitate the feature extraction.


We validate the effectiveness of \approach{} under the GFSOD setting on Pascal VOC~\cite{pascal-voc-2007,pascal-voc-2012} and MS COCO~\cite{lin2014microsoft}.
% several benchmark datasets, including XXX. 
Compared to existing methods, we can both achieve precise detection on base classes and sufficiently improve the adaptation efficiency on novel classes using a single model. 
% our XXX is the first to achieve the best of both worlds, \ie, improving the performance on both base classes and novel classes. 
Furthermore, our \approach{} can be intuitively extended to long-tailed object detection. Experimental results on LVIS datasets demonstrate the generalizibility of our approach.
Our contributions are summarized as follows:
\vspace{-2.5mm}
\begin{itemize}[leftmargin=*]
    \item We revisit few-shot object detection from a perspective of discriminative feature learning, and point out that existing methods fail in knowledge adaptation to novel classes and suffer from knowledge forgetting of base classes.
    \vspace{-2.5mm}
    \item We propose \approach{} to pursue an desired feature geometry, \ie, inter-class separation and intra-class compactness, which consistently improves the performance on both base and novel classes.
    % \updated{We employ ETF as a fixed classifier to guide the separation and learn class-specific margins to tighten the clusters adaptively.}
    \vspace{-2.5mm}
    \item We conduct extensive experiments on three benchmark datasets for few-shot object detection and long-tailed object detection to verify the generalizability of \approach{}.
    % which demonstrates that our XXX is the first to simultaneously improve the performances of both base and novel classes for few-shot object detection.  
    % Comprehensive ablation studies with visualizations are provided to justify the design of each component.
\end{itemize}
