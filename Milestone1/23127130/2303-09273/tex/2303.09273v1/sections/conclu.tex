\section{Conclusions}\label{sec:conclu}
We have presented \SystemName, a framework that enhances the capability of DNN-based traffic forecasting models to quantify the uncertainty of their predictions. Specifically, \SystemName generates upper and lower bounds of the prediction, which is useful in tasks like emergency route planning to ensure the worst-case arrival time. Our framework is generic, applicable to any DNN model, and does not alter the DNN model's underlying architecture during deployment. \SystemName builds on conformalized quantile regression (CQR) and utilizes a dedicated loss function to train a quantile function that generates a prediction confidence interval for the single-point output of the DNN model. It advances standard CQR by  dynamically adjusting the prediction interval based on individual locations or sensor nodes of the test samples, leading to a more accurate PI with valid coverage.

We evaluate \SystemName by applying it to six representative DNN architectures for traffic forecasting and compare it against five uncertainty quantification methods. Experimental results show that \SystemName has good generalization ability, delivering better performance than the competing methods across the evaluated DNN models. This outcome underscores the significance of \SystemName as one of the first attempts to develop a generic framework for modeling uncertainties in traffic forecasting.

We will publish the code and data of \SystemName upon acceptance. We hope that \SystemName will enable more research into robust traffic forecasting by providing a means to quantify uncertainty in DNN-based models.
