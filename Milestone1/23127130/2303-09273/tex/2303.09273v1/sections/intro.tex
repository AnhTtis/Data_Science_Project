\section{Introduction}\label{sec:intro}

Accurate prediction of future traffic information, including traffic volume, congestion levels, traffic speed, and travel time, is crucial for a variety of transportation applications, such as congestion control \cite{akhtar2021review}, travel time estimation\cite{9905416}, emergent route planning\cite{tian2018research}, and taxi demand prediction\cite{9945629}. It also supports effective transportation planning and management, enabling policy-makers to optimize traffic flow and emergency response planning while providing road users with a safer and more efficient travel experience.

In recent years, there has been a growing interest in the development of advanced predictive models for traffic information using data-driven approaches such as deep neural networks (\textbf{DNNs}) \cite{9112608}.  Multiple studies have shown that traffic forecasting models based on DNNs outperform classical machine learning methods by a large margin \cite{9352246, DL2021Jiang}. However, these models are typically trained to minimize the averaged prediction error, resulting in a considerable variation in performance across test samples \cite{SurveyJohnson}. This variation poses significant challenges for individual use cases where precise traffic prediction is critical but difficult to achieve. For instance, accurately predicting traffics at crossroads with high traffic volumes during rush hours is crucial for urban travel but can be challenging due to complex traffic patterns \cite{thulasidasan2019mixup}. As the accuracy of traffic forecasting can fluctuate over time \cite{3403294}, it is crucial to model and quantify the prediction uncertainty of the model for individual roads, locations, and sensors for a given prediction window (e.g., traffic predictions for the next $n$ minutes).

Modeling and quantifying traffic forecasting uncertainties have real-world use cases in transportation management. For example, in emergency response situations, having knowledge of the upper bound of a traffic flow prediction can help emergency responders avoid congested roads and take the quickest and safest route to their destination. Similarly, knowing the earliest and worst-case travel times enables users to make informed decisions about their travel plans, such as selecting the most convenient transportation method while minimizing the likelihood of being late to an appointment or arriving too early. Therefore, by quantifying the forecasting uncertainty, we can improve the reliability of traffic prediction and traffic management efficiency. Unfortunately, despite the huge benefits of uncertainty modeling, prior research on traffic forecasting has largely overlooked this issue. This is a massively missed opportunity.

The recent studies presented in \cite{Estimating2021} and \cite{Qian2023} were among the first attempt to model uncertainties in traffic forecasting. The work presented in \cite{Estimating2021} uses a classical statistical method to quantify the uncertainties associated with average daily traffic volume forecasts. However, this approach requires manual tuning and selecting a set of features for each dataset to fit a linear model. Its requirement of intensive expert involvement thus limits the practicability. 
In \cite{Qian2023}, a method based on variational inference and deep ensembling  is employed to estimate both the data and model uncertainties in traffic forecasting. This approach provides a more comprehensive understanding of the uncertainties involved, but it requires significant changes to the original model architectures, which limits its generalization ability.

In this paper, we present \SystemName, a generic framework for quantifying the prediction uncertainties of a DNN-based traffic forecasting model.  Unlike prior work \cite{Estimating2021,Qian2023}, \SystemName is designed to minimize engineering efforts and expert involvement. It  can work with any DNN model without changing the underlying architecture during deployment. By producing a prediction interval 
{(\textbf{PI})} that captures the range in which the true value (such as travel time) is likely to fall, \SystemName enhances the capability of a standard DNN to capture prediction uncertainties. 

At the core of \SystemName is a quantile function built upon the recently proposed Conformalized Quantile Regression (\textbf{CQR})  algorithm~\cite{romano2019conformalized}. The quantile function estimates the PI of a given model output based on the data distribution and validation errors observed during the standard DNN model training process. \SystemName is designed to simplify the training and usage of the quantile function. The process involves attaching a linear layer to the last layer of the base DNN model and using a pinball loss function \cite{Koenker2001Quantile} during standard DNN training. Once trained, the base DNN model and the quantile function can be used as standalone components during deployment. During inference, the quantile function generates an initial PI based on the DNN model's single-point prediction. Then, an adjustment is made to refine it and improve its accuracy. The goal is to increase the coverage of the PI while simultaneously minimizing the width between its upper and lower bounds.

Unlike standard CQR that uses a global constant value to adjust the initial PI, \SystemName develops an adaptive scheme to tailor the adjustment value applied to the initial PI for the specific location (or sensor node) of the test sample within a given prediction window. This allows the uncertainty method to consider the prediction difficulty of each test sample. For example, locations that are known to have high variability in traffic patterns may require a larger adjustment to achieve accurate PIs, while those with more predictable traffic patterns may require a smaller  value. We achieve this by utilizing a calibration table that is automatically constructed using an optimization function on a calibration dataset. This table provides the optimal adjustment for a node-prediction-window combination, enabling \SystemName to account for unique prediction challenges in each test sample. By using differentiated residues to adjust the initial PI, we achieve greater precision and reliability over the standard CQR. 

We have implemented a working prototype of \SystemName, which will be open-sourced upon acceptance of this work. We evaluate \SystemName by applying it to five representative DNN architectures \cite{Yu2018spatio, ijcai_WuPLJZ19, aaai_ZhengFW020,sigir_LaiCYL18,  wu2020connect} for traffic forecasting. We then test the \SystemName-enhanced DNN model on seven public datasets for traffic speed and flow prediction. We compare \SystemName against five state-of-the-art uncertainty modeling methods \cite{Vladimir2005,Blundell2015weight, pmlr-v48-gal16, Roger1978, Mach2008Tutorial} and a classical method based on historical data. Experimental results show that \SystemName consistently outperforms competing baselines across DNN models and datasets, delivering better and more robust performance for uncertainty quantification. 

This paper makes the following contributions:
\begin{itemize}
\item It presents a generic framework to model prediction uncertainty for DNN-based traffic forecasting models, requiring no change to the base DNN model architecture (\cref{sec:method}).
\item It develops an adaptive scheme to tackle the prediction challenge of individual locations, leading to more robust results than standard uncertainty modeling methods (\cref{subsec: component}).
\item It provides a large independent study to highlight the importance of uncertainty modeling of traffic forecasting. We hope our study can encourage further research along this line (\cref{sec:results}). 
\end{itemize}
