\section{Related Work}
\label{sec:relatedwork}


\subsection{Modelling Interactive Behaviour in HCI}
Classical HCI approaches include descriptive models, e.g., Fitts's Law~\cite{accot1997beyond}, and predictive models, e.g., the keystroke-level model (KLM)~\cite{card1980keystroke}. %
However, they are limited in strict controls and modelling simple tasks like pointing to a target or routine tasks that have to be specified step by step~\cite{card1980keystroke}.
Recent research used 1D convolutional neural networks (CNN)~\cite{hu2020dgaze,hu2021FixationNet}, long short-term memory (LSTM)~\cite{hu2022EHTask} and gated recurrent unit (GRU)~\cite{hu2022EHTask} to encode gaze and head behaviour, based on the sequential structure, while others focused on spatial analysis and modelling~\cite{hu2019sgaze,hu2020dgaze}.
Specifically, Xu et al.\ modelled mouse and keyboard behaviour by accumulating cursor positions into binary attention maps~\cite{xu2016spatio}.
Other researchers modelled interactive behaviour from a statistical perspective.
For example, Borji et al.\ used Hidden Markov Models (HMM) to encode motor actions including mouse clicks, mouse positions, and joystick positions in video games~\cite{borji2012probabilistic}, while Sun et al.\ applied Gaussian mixture models (GMM) on keystrokes in text editing tasks~\cite{sun2016shared}.
Researchers also encoded eye movements~\cite{bulling08_pervasive} or gestures~\cite{wang2009human,shirahama2017generality} into strings for activity recognition.
Given that interactive behaviour has a sequential and hierarchical structure, which may resemble natural language, we explored modelling interactive behaviour from an NLP perspective.

\subsection{Encoding Methods for Natural Language}
Recent attractive success in NLP has been largely attributed to methods that efficiently encode characters~\cite{kim2016character}, words~\cite{Pennington2014GloVeGV} or sentences~\cite{Reimers2019SentenceBERTSE} into a vector representation. 
HCI researchers also followed this trend to model GUIs~\cite{Li2021Screen2VecSE,%
Wang2021Screen2WordsAM} or behavioural differences over time~\cite{han2020modelling}.
A key requirement for such methods is %
to encode or tokenise the input to generate a usable vocabulary of concepts. 
Due to the clear structure of natural language, %
NLP methods encode at the character, subword or word level.
One popular approach is n-gram, which uses $n$ words in a sequence to determine the context where commonly $n = 2$ or $3$~\cite{han2020modelling}.
However, such a method is limited by the choice of $n$, and the exponential increase of vocabulary size along $n$.
More promising approaches learn a vocabulary of subwords, among which BPE has been widely used given that it allows rich and flexible vocabulary and understanding rare or unseen words~\cite{Wang2020NeuralMT,kudo2018subword,radford2019language,raffel2020exploring}.
Consequently, we employ BPE as the NLP method to create a vocabulary for interactive behaviour.

\subsection{Analysis and Modelling of Mouse and Keyboard Behaviour}
The mouse and keyboard are among the most widely used input modalities in daily interactions with computers~\cite{xu2016spatio,sun2016shared}.
Some researchers only focused on one modality, i.e., mouse or keyboard.
Arapakis et al.\ explored different representations of mouse movements in web search tasks, including time series, heatmaps, and trajectory-based images~\cite{arapakis2020mouse}, while Antal et al.\ employed 1D CNN to encode mouse actions including clicks and drag~\cite{antal2021sapimouse}.
Dhakal et al.\ analysed keystroke patterns in a transcription typing task by correlation analysis~\cite{dhakal2018observations}, while Acien et al.\ employed LSTM to encode keystroke sequences in free text typing~\cite{acien2020typenet}.
In contrast, Sun et al.\ explored both mouse and keyboard actions in two typing tasks, yet the work was limited to fully controlled laboratory settings~\cite{sun2016shared}. %
