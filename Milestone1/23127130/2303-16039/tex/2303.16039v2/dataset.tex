\section{Datasets for Evaluation}
Although interactive behaviour, and specifically mouse and keyboard data, has been widely studied in HCI~\cite{sun2016shared,xu2016spatio}, most existing datasets have been collected in strictly controlled laboratory settings.
Laboratory settings have the advantages of control and internal validity, but their ecological validity is highly limited~\cite{apaolaza2013understanding}.
Our out-of-the-lab data collection did not control where, when, how long and via which laptop or desktop participants could join, allowing more natural behaviour~\cite{mazilu2015wearable,petersen2021pedagogical}.
In addition, most datasets only include either mouse or keyboard data, while
we opted for evaluations on both modalities. %
As such, we analysed mouse and keyboard behaviour from the in-the-lab Buffalo dataset~\cite{sun2016shared} and EMAKI, a novel multimodal out-of-the-lab dataset that we collected specifically for this purpose, given lacking suitable publicly available data.
To evaluate constraints in data collection from a time perspective, \textit{task} and \textit{study} completion times were calculated.
The former only counts the time spent on tasks, while
the latter refers to finishing the entire study, including pauses. %

\subsection{The Buffalo Dataset}
\label{sec:Buffalo}
To the best of our knowledge, Buffalo~\cite{sun2016shared} is the largest publicly available in-the-lab dataset containing both mouse and keyboard interactions.
The dataset was collected with standalone keyboards over three sessions. %
148 participants performed two typing tasks: transcribing a pre-defined text and typical office activities, such as answering predefined questions and sending emails.
The average number of mouse actions and keystrokes per participant exceeded 19\,K and 17\,K, respectively.
75 participants completed both tasks with the same keyboard, while the remaining used three keyboards across sessions.
Data from the former 75 participants were used in this work for a more controlled condition, following~\cite{xiaofeng2019continuous}.
The average \textit{task} completion time was 41.71\,mins ($\mathrm{SD}=6.34$), while the average \textit{study} completion time was slightly longer, 41.81\,mins ($\mathrm{SD}=6.27$), indicating that participants barely took breaks in this constrained setting.

\subsection{The EMAKI Dataset}
\label{sec:Ourdataset}
We opted for an online study %
including three tasks: text entry and editing, image editing, and questionnaire completion.
These tasks can be found in a wide range of interactive applications and UIs, and cover varying types of mouse and keyboard actions~\cite{xu2016spatio,sun2016shared}.
Furthermore, the tasks are neither limited to a particular real-world application \cite{chuda2014usage,brown2014finding} nor too controlled or artificial %
\cite{dhakal2018observations,zhang2022predicting,zhao2020reading}, different from the typing-focused tasks in Buffalo. %
Two short assessments were designed to analyse if participants show different proficiencies in using mouse and keyboard.

The study was implemented as a web application and hosted on our university server. The link to the study was sent directly to the participants.
The frontend was implemented in JavaScript, while the backend consisted of a Node.js server and an SQLite database. %
We recorded clicks and key presses with separate events for press and release, mouse movements and their associated timestamps.

\paragraph{\textbf{Participants}}
\label{sec:participants}
We recruited 52 participants through university mailing lists and social networks.
12 participants who did not finish the study and one teenage participant were filtered out, leading to \numberParticipants participants in the end (18 female, 18 male and 3 ``other gender'').
Their ages ranged between 18 and 54 years ($\mathrm{M}=25.05, \mathrm{SD}=6.51$).
Participants completed the study from 16 countries.
On average, they reported having used mouse and keyboard for 13.64 years ($\mathrm{SD}=6.80$).
15 participants used laptop touchpads, while the others used traditional mice.
28 participants used laptop keyboards and the rest used standalone keyboards.

\paragraph{\textbf{Interactive Tasks}}

\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{main-tasks-cut.pdf}
    \vspace{-0.5cm}
    \caption{Screenshots of the three interactive tasks %
    in our online study: (a) text entry and editing, %
    (b) image editing, %
    and (c) questionnaire completion.%
    }
    \label{fig:main-tasks}
\end{figure}

In \textcolor{\reviewcolor}{task} \textit{text entry and editing}, participants wrote a piece of text in English in a text editor\footnote{\url{https://github.com/tinymce/tinymce}} for one trial (Fig.~\ref{fig:main-tasks}a).
We did not specify the topic but offered suggestions, such as ``summarise a movie/TV series/documentary that you recently watched'' or ``describe your pet''.
We asked participants to write %
$\geq$200 words and apply %
$\geq$15 formatting rules, e.g. change font size or alignment.
\textcolor{\reviewcolor}{We allowed any operation provided by the editor, such as copy-paste and undo.}
Two counters in the top left showed the number of words they already typed and formatting operations they applied.
These counters were initially red and turned green once the minimum thresholds were reached.

In \textcolor{\reviewcolor}{task} \textit{image editing}, participants were presented with two images shown side-by-side in an image editor\footnote{\url{https://github.com/nhn/tui.image-editor}} (Fig.~\ref{fig:main-tasks}b).
The image on the left was a real photograph, whereas the image on the right was a sketch.
\textcolor{\reviewcolor}{On either or both sides, participants performed operations provided by the editor in any order they wanted.
Candidate operations are drawing, cropping, flipping, rotating, adding icons and adding filters.}
To proceed to the next task, they had to perform at least 100 editing operations.
In addition, we asked them to add at least one text box that contained a minimum of 10 characters.
Similarly to the previous task, counters showed the task progress.

\textit{Questionnaire completion} involved participants in completing four questionnaires\footnote{\url{https://github.com/surveyjs/survey-library}}, leading to four trials (Fig.~\ref{fig:main-tasks}c).
These questionnaires served a dual purpose: providing information about participants, which can serve as metadata for future work on the dataset, while at the same time allowing us to record naturalistic mouse and keyboard data.
The first questionnaire focused on demographics and included questions on gender, age, country of origin, country of residence, experience in using mouse and keyboard, and whether participants had any visual impairments. 
Afterwards were %
three widely-used personality questionnaires: BFI-44 (Big Five)\footnote{\url{https://www.ocf.berkeley.edu/~johnlab/bfi.php}}, BIS-11 (Barratt Impulsiveness Scale)\footnote{\url{http://www.impulsivity.org/measurement/bis11}} and BIS-BAS (the Behavioural Inhibition and Approach System)\footnote{\url{https://local.psy.miami.edu/people/faculty/ccarver/availbale-self-report-instruments/bisbas-scales/}}.%

\paragraph{\textbf{Procedure}}
\label{sec:userstudy-procedure}
Before starting with the tasks, participants were asked to carefully read the study goals and task descriptions.
They were then asked whether they were using a mouse or touchpad, and a laptop or standalone keyboard.
To start the study, participants had to click two checkboxes to confirm that (1) they had read and understood the goals of the study, and (2) their data may be published and analysed for research purposes.
Afterwards, participants performed %
tasks in fullscreen.
If %
they left the fullscreen mode during a task, the task was restarted.
We opted for the design to discourage participants from multitasking. %
To reduce potential effects of task order, half of the initial 52 participants performed the text entry and editing task first, followed by the image editing task, while the other half performed %
in the inverse order.
After data filtering, 24 participants did the text task and then image task, while the other 15 in the inverse order. %
We always showed questionnaires at the end, following studies that also collected personality questionnaires~\cite{hoppe2018eye,muller2018detecting}. 
Detailed guidelines for tasks were available to participants throughout the study.
Participants could contact us whenever they had questions, felt uncomfortable or unsure of any task or wanted to withdraw.
Upon completion of the study, participants were shown their results of personality questionnaires as compensation.
No monetary compensation was made.

\paragraph{\textbf{Dataset Statistics}}
\label{sec:taskduration}
The average task completion time was 37.40\,mins ($\mathrm{SD}=13.91$), in which 16.60\,mins ($\mathrm{SD}=8.51$) were spent on text entry and editing, 6.15\,mins ($\mathrm{SD}=3.60$) on image editing, and 9.84\,mins ($\mathrm{SD}=4.48$) on questionnaires.
The average study completion time was significantly longer, 55.33\,mins ($\mathrm{SD}=29.32$).
In total, we collected 1.14\,M mouse actions and 205\,K keyboard actions.
38\% of mouse actions were generated from the image editing task, 43\% from questionnaire completion, while only 19\% came from the text entry and editing task.
Text entry and editing contributed 92\% of the keyboard actions, while only 8\% were from the other two tasks (image editing: 3\%, questionnaire completion: 5\%).

\paragraph{\textbf{Assessments of Proficiency}}
\label{sec:proficiency}

\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{calibration-tasks.pdf}
    \caption{Two proficiency assessments: (a) text typing and (b) move and click.
    }
    \label{fig:calibration-tasks}
\end{figure}

Before interactive tasks, our study also included two short assessments to analyse if participants who used different types of input devices showed different proficiencies in using mouse and keyboard.
The two assessments were \textit{text typing} for keyboard proficiency and \textit{move and click} for mouse proficiency, shown in Fig.~\ref{fig:calibration-tasks}.
\textit{Text typing} involved copying a short piece of text ($\sim$100 words, Fig.~\ref{fig:calibration-tasks}a) as quickly as possible~\cite{grabowski2008internal}.
The average duration of key presses and the number of keys pressed per minute were calculated as keyboard metrics~\cite{grabowski2008internal}.
\textit{Move and click} was inspired by a Fitts's Law task~\cite{soukoreff2004towards}, where participants clicked an orange dot that randomly appeared at a predefined location as quickly as possible over multiple rounds.
Once clicked, the orange dot turned grey and another random dot turned orange (Fig.~\ref{fig:calibration-tasks}b).
Fitts's law~\cite{fitts1954information} models movement time as $MT=a+b \log_{2} \left(\frac{2d}{w}\right)$,
where $d$ is the distance between the centre of the target and the starting point;
$w$ is the width of the target; %
$a$ and $b$ are constants that can be interpreted as the delay and the acceleration.
Based on $d$, $w$ and $MT$ recorded in \textit{move and click}, we computed $a$ and $b$ via linear regression and used them as metrics of mouse proficiency.

Based on the type of mouse (touchpad vs. traditional mouse), we split participants into two groups and then calculated mouse metrics from data collected in the mouse assessment.
A Mann-Whitney U test showed that both metrics were significantly different between the two groups.
One reason is that touchpad and traditional mouse lead to different pointing speeds and accuracies~\cite{hertzum2013effect}.
Then, we split participants into two groups based on using a laptop or standalone keyboard.
No significant difference was found in keyboard metrics calculated from the keyboard assessment.