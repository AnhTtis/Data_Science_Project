\section{Real-World Applicability}
The experimental results in Section~\ref{sec:results} are encouraging for the feasibility of our proposed technology, however they were performed in a controlled laboratory setting. Specifically, for all those experiments the sensor pinned in a static position on the table during data acquisition. In order to expand the experimental set up of CTS gesture pads and evaluate their functionality and accurately in a setup resembling the  real world, there are many many other aspects to be considered. In this section, we begin discussing and investigating some of these possibilities, even though further explorations are necessary. First, we conduct a new study, with subjects wearing the sensor while inputting gesture data. Next, we evaluate the effect that washing and drying have on the resistance of the sensor. Finally, we discuss the application potential and integration of this system.  

\subsection{Model Performance While the Sensor is Being Worn}
\label{sec:wearing_sensor}
One of the main ways the proposed sensor is expected to be used in the real world is via clothing integration, which is facilitated by the compact sensing area. The sensor in proximity to the human body induces capacitance, which is the principle upon which its circuit design relies. When worn near the skin, there is an additional capacitance induced, greater than the baseline parasitic capacitance. Ideally, when worn, the skin should not contact the sensor. Shielding the sensor from underside contact is currently achieved by knitting a back layer on the sensor and routing conductive yarn only on the top layer. 

\begin{figure*}[ht]
    \centering
    \subfigure[]{\raisebox{5.5mm}
    {\includegraphics[height=0.285\textwidth]{src/figures/wearing_sensor_connected-min.pdf}\label{fig:sensor_wearing_forearm}}}
    \hfill
    \subfigure[]
    {\includegraphics[width=0.495\textwidth]{src/figures/final_wearing_heatmap.pdf}\label{fig:wearing_confusion}}
    \hfill
    \caption{User study to test model performance while knitted sensor is being worn. The setup in \emph{(a)} shows the knitted sensor fixed on a removable Velcro-strapped pad to be worn on the forearm. Four electrodes are connected to the corners of the sensing area, similarly to Figure~\ref{fig:capturing_gesture} for data collection. The heatmap generated in \emph{(b)} shows the classification results for each gesture pathway. The matrix rows denote the true row categories of the gestures, while the columns show the ones predicted during evaluation. There is a clear difference between this figure and the heatmaps in Figure~\ref{fig:Confusion_Matrices}. However the diagonal in the middle is still distinguishable from the rest of the values.}
    \label{fig:wearing_sensor}
    \Description{This figure shows a user touching on a knitted sensor while wearing it on their forearm in (a). Figure (b) shows the gesture classification matrix, with the diagonal values being higher than the rest of the values, but less pronounced than the diagonals of Figure 10.}
\end{figure*}

\subsubsection{Methods and Results}
In order to further examine the robustness of the gesture recognizing model introduced above and its usefulness in the real world, we conducted a new user study with 3 subjects. The study is similar in design and analysis to the cross-validation and evaluation studies described in Sections~\ref{sec:experiments} and~\ref{sec:results}, but in this case, the subjects were wearing the sensor on their forearm while performing the same 12 gestures as in the studies above. The sensor was pinned on another Velcro-strapped pad as shown in Figure~\ref{fig:sensor_wearing_forearm}. Subjects were not moving while collecting the data, but some motion of their arms would be expected. Each subject performed each of the 12 gestures 20 times, with a total of 720 samples, or 60 per class collected. This dataset was tested against the already trained models from the cross-validation study. No additional training was performed to account for this new condition.

\begin{table}[h]
  \centering
  \caption{Classification results for gestures performed while the sensor was being worn.}~\label{tab:wearing_results}
  \vspace{0.5cm}
  \begin{tabular}{l|cccc}
    & {\small \textit{Accuracy}} & {\small \textit{F1-Score}} & {\small \textit{Precision}} & {\small \textit{Recall}}\\
    \midrule
    \small{CNN + LSTM} & 58.0\% & 58.2\% & 61.2\% & 58.0\% \\
    \Description{This table shows the evaluation performance measures of the sensor while it is being worn using trained CNN-LSTM model. The performance measures are accuracy, precision, recall, and F1-score. The evaluation accuracy is 58.0\%.}
  \end{tabular}
\end{table}

Table~\ref{tab:wearing_results} demonstrates the results computed for the same performance measures as the studies above, including: \emph{accuracy}, \emph{precision}, \emph{recall}, and \emph{F1-score}. Figure~\ref{fig:wearing_confusion} illustrates the classification matrix of the real and predicted gestures. The computed accuracy is $58.0\%$, which is lower than both the cross-validation and testing accuracy, however well above chance accuracy (8.3\%). We would expect increased accuracy with training that includes samples collected while the sensor is being worn. For a complete system implementation, training should be performed under a large variety of conditions to ensure robustness to different real-world circumstances.

\subsection{Effect of Washing and Drying on Sensor Resistance}
\label{sec:washing_drying}
Another aspect in evaluating the robustness for use of a knitted sensor is the effect of washing and drying on its conductivity. 
%First, it should be noted that some distortion is to be expected to occur after washing and drying the fabric component for the first time, due to the fabric shrinking in size to some extent. 
The resistance of the sensor is an important property in representing the resulting signal, and subsequently building a gesture-recognizing learning model~\cite{Vallett2016a,Vallett2019a,mcdonald2020knitted}. Minor changes in resistance from activities like folding and stretching are anticipated and can be accounted for within the sensing and signal processing pipeline. Furthermore, laundering is an essential post-processing step in the manufacturing process that permanently sets physical yarn properties, such as expanding heat-bulking Nylon fibers, which in turn alter the baseline electrical conductivity. The sample tested has been washed and dried before these experiments, in addition to being steamed, as part of its manufacturing process. In this experiment, we first measure the baseline resistance across every pair of connection points illustrated in Figure~\ref{fig:sensor_sketch}. Then, we wash and dry the sensor for five cycles, measuring the resistance across the same pairs of points after each cycle.

Planar conductivity involving multiple connection points is described using the symmetric matrix shown in (\ref{eqn:Conductivity_Matrix}), which is an extrapolation of \emph{Kirchhoff's Current Law} stating that the sum of the currents entering a node is equivalent to the sum of the currents exiting it. In this application, conductivity, $G$, is directly proportional to current, $I$, and inversely proportional to resistance, $R$, such that $I \simeq G=R^{-1}$. The inverse of the resistance values indicated in Figure~\ref{fig:sensor_sketch} comprise the non-diagonal elements of the conductivity matrix. The change in conductivity is assumed to be scalar in that the values of the conductivity matrix will change proportionally. In practice, these values vary due to local changes in conductivity. Therefore, the average change in values is used to describe the cumulative change in conductivity.

\small
\begin{equation}
    G_{ABCD} = 
    \begin{bmatrix}
        -\left(G_{AB} + G_{AC} + G_{AD}\right) && G_{AB} && G_{AC} && G_{AD} \\
        G_{AB} && -\left(G_{AB} + G_{BC} + G_{BD}\right) && G_{BC} && G_{BD} \\
        G_{AC} && G_{BC} && -\left(G_{BC} + G_{AC} + G_{CD}\right) && G_{CD} \\
         G_{AD} && G_{BD} && G_{CD} && -\left(G_{AD} + G_{BD} + G_{CD}\right)
    \end{bmatrix}
    \label{eqn:Conductivity_Matrix}
\end{equation}

\normalsize
\begin{wrapfigure}{l}{0.35\linewidth}
  \centering
    \includegraphics[width=0.8\linewidth]{src/figures/Planar_Touchpad_Resistance_Diagram.pdf}
    \captionof{figure}{Annotated sketch of the knitted sensor, showing points along which resistance was measured.}~\label{fig:sensor_sketch}
    \Description{This figure shows the sketch of the knitted sensor, illustrating four electrode connection points, A, B, C, D, each in one corner of the rectangular area. The edges and diagonals of the figure are annotated to show a resistance between each each pair of points.}
\end{wrapfigure}

\subsubsection{Procedure and Results}
The sensor was washed according to the American Association of Textile Chemists and Colorists (AATCC) Laboratory Procedure 1-2018 Home Laundering: Machine Washing protocol~\cite{AATCC}. This protocol specifies a 35 minute wash duration with $1.8$ kg of laundry and $66 \pm 1$ g of detergent, and a standard tumble drying protocol with a temperature of $68 \pm 6^\circ C$. This protocol was chosen as appropriate for everyday laundering of clothing.

For the proposed sensor, we measured 6 resistance values for each of the two conditions: \emph{baseline ($b$)}, and \emph{washing and drying ($d_n$)}, where $n =$ 1 to 5 indicates the cycle number. The values were measured between every pair of corners in the sensor, annotated as $A, B, C$ and $D$ in Figure~\ref{fig:sensor_sketch}, which represent the connection points to the measurement hardware. To fully characterize the resistance across the conductive area of the sensor the resistance between each pair of connection points is necessary. For each resistance measurement, 100 samples were captured using a Keysight 34465A digital multi-meter, which were then averaged to represent the value of that measurement. The results are included in Table~\ref{tab:wash_dry_resistance}. For each test, the percent change in resistance between the baseline measurements and measurements after each washing and drying cycle was calculated as $\%\Delta R_{(b,d_n)} = (R_{d_n} - R_b) / R_b$. In this case, $R_{d_n}$ stands for the resistance value between the two points after the $n^{-th}$ washing and drying cycle $(d_n)$, and $R_b$ for the baseline resistance value between those same points, before any of the washing and drying cycles recorded. 
%In order to provide an overall view of the resistance change across the sensor, the absolute values of resistance changes across all point pairs were averaged. 
The cumulative change in resistance is calculated from the cumulative average of the element-wise matrix division of the baseline and drying cycle conductivity matrices formed using the relation in (\ref{eqn:Conductivity_Matrix}), where $\%\Delta R_{\left(b,d_{n}\right)} = avg\left(G_{b} / \left(G_{d_{n}} - G_{b}\right)\right)$.

\vspace{0.2cm}
\begin{table*}[ht]
  \caption{The percent change in resistance ($\%\Delta R$) between the \emph{baseline ($b$)} and each of the experiments after \emph{washing and drying ($d$)} is reported. The resistance values are measured between all pairs of the sensor's connection points. The cumulative change in resistance is also reported.}~\label{tab:wash_dry_resistance}
  \begin{tabular}{c|cccccc|c}
    & {\small $[A, B]$} & {\small $[A, C]$} & {\small $[A, D]$} & {\small $[B, C]$} & {\small $[B, D]$} & {\small $[C, D]$} & {\small $Cumulative$}\\
    
    \midrule
    
    \small \textit{$\%\Delta R_{(b, d1)}$} & \DeltaRBDryOneAB & \DeltaRBDryOneAC & \DeltaRBDryOneAD & \DeltaRBDryOneBC & \DeltaRBDryOneBD & \DeltaRBDryOneCD & $8.10\%$ \\
    \small \textit{$\%\Delta R_{(b, d2)}$} & \DeltaRBDryTwoAB & \DeltaRBDryTwoAC & \DeltaRBDryTwoAD & \DeltaRBDryTwoBC & \DeltaRBDryTwoBD & \DeltaRBDryTwoCD & $22.16\%$ \\
    \small \textit{$\%\Delta R_{(b, d3)}$} & \DeltaRBDryThreeAB & \DeltaRBDryThreeAC & \DeltaRBDryThreeAD & \DeltaRBDryThreeBC & \DeltaRBDryThreeBD & \DeltaRBDryThreeCD & $9.69\%$ \\
    \small \textit{$\%\Delta R_{(b, d4)}$} & \DeltaRBDryFourAB & \DeltaRBDryFourAC & \DeltaRBDryFourAD & \DeltaRBDryFourBC & \DeltaRBDryFourBD & \DeltaRBDryFourCD & $11.23\%$ \\
    \small \textit{$\%\Delta R_{(b, d5)}$} & \DeltaRBDryFiveAB & \DeltaRBDryFiveAC & \DeltaRBDryFiveAD & \DeltaRBDryFiveBC & \DeltaRBDryFiveBD & \DeltaRBDryFiveCD & $3.19\%$ \\
    % \midrule
    % \small \textit{$\%\Delta R_{(b, w1)}$} & $0\%$ & $0\%$ & $0\%$ & $0\%$ & $0\%$ & $0\%$ & $0\%$ \\
    % \small \textit{$\%\Delta R_{(b, w5)}$} & $0\%$ & $0\%$ & $0\%$ & $0\%$ & $0\%$ & $0\%$ & $0\%$ \\
    \Description{This table shows the effect that washing and drying have on the resistance. The rows show the change in resistance between the baseline, and values measured after each washing and drying cycle 1-5. The columns show the point pairs along which the resistance is measured: [A,B], [A,C], [A,D], [B,C], [B,D], [C,D], and additionally the cumulative resistance change value. Most of the cumulative results values are between 3\% and 11\%, while in the rest of the table, values range from 1\% to 31\%.}
  \end{tabular}
\end{table*}

The results in Table~\ref{tab:wash_dry_resistance} show that there is stability in the resistance measurements of the sensor after washing and drying it. However, there is a change in the cumulative resistance across washing and drying trials. The fact that the change in overall resistance does not substantially increase from trial to trial is promising. However, the change in resistance varies from approximately from 1\% to 31\% for individual connection point pairs. In addition, values in the second washing and drying trial $d_2$ seem higher compared to previous and subsequent trials, possibly due to a measurement error. Further testing is necessary to investigate the effects of washing and drying more comprehensively, and this observed variability needs to be incorporated into the model design, so that gestures recognition is stable for any applications depending on it. 


\subsection{Building Interactive Applications with Gesture-Recognizing Knitted Sensors}
\label{sec:application_potential}

The system components described in Section~\ref{sec:system_design} create the foundation for building an interactive system that uses a knitted sensing area to accept gesture input and a machine learning model to determine the gesture performed by the user. In a real-time system, gestures can subsequently be interpreted by the specific application to trigger different events. This technology enables many kinds of applications, and additionally offers extensibility. Figure~\ref{fig:interactive_system} shows two related views of the system. On the left, it illustrates how data can be collected from users to train and evaluate a machine learning model. Gestures can be determined by the application needs, and the experiments and results in this work show that it is possible to recognize even relatively complex gestures, such as letters and numbers, with high accuracy. This allows great flexibility in the choice of gesture sets for training, even on a small-sized sensing area. Training happens offline on a server and after the cross-validation results achieve the required accuracy, the trained model is further evaluated, and then deployed on a smaller system, such as the NVIDIA Jetson computer. 

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{src/figures/Interactive_System_Model_Deployment_Workflow.pdf}
    \caption{Processes and component interactions that describe the model creation and the working of an interactive gesture recognition system. Data collection, training and evaluation happen off-line and typically require more time and computing power. Once a model is trained to high accuracy, it can be deployed on lightweight hardware to recognize gestures in real time, supporting different interactive applications.}
    \label{fig:interactive_system}
    \Description{This figure illustrates two related process with their respective components: model training and evaluation on the left, and building an interactive system on the right. In the center, there are two components, a knitted sensor and embedded micro-controller, which are part of both processes. On the left, gesture sets for training and evaluation are depicted, gathered through user interaction with the knitted sensor. The sensor passes that information to the embedded micro-controller, and the data from there is used for training in a server computer. The server outputs a trained model, which is then deployed to the NVIDIA Jetson system-on-module, found on the right side of the figure, in the interactive system part. That process starts with the user performing a gesture on the knitted sensor, which is connected to the embedded micro-controller. The latter transmits the signal to the NVIDIA Jetson board, which, through its trained model, returns a gesture type. This gesture is then interpreted by an application, which gives a custom response to the user.}
\end{figure}

On the right side of Figure~\ref{fig:interactive_system}, the implementation of an interactive system based on this technology is illustrated. A user enters a gesture input on the knitted sensing area, connected to an embedded system for signal acquisition and pre-processing. This system would communicate in real time with the NVIDIA Jetson board hosting the trained gesture recognition model, capable of interpreting the signal as the gesture the user intended. The application relying on this technology would then respond to the user based on the meaning assigned to the particular gesture. %Signal acquisition and processing in Figure~\ref{fig:interactive_system} is illustrated through a micro-controller, for both the interactive system, and general data collection. In this work, data was collected using an oscilloscope as described in the setup in Figure~\ref{fig:Planar_CTS_Gesture_Data_Example}, but previous work~\cite{mcdonald2020knitted} has 

This system configuration is extensible in the types of gestures recognized, since the model can be re-trained offline and re-deployed on existing hardware, allowing for large-scale production. Previous work~\cite{Vallett2019a,mcdonald2020knitted} has explored the potential of similarly-constructed sensors, and has introduced prototypes to illustrate their possible functionalities. The developments introduced in this work also hold promise for creating innovative applications. Some potential examples are broadly described below:

\begin{itemize}
    \item[-] \emph{Character Recognition:} The gesture examples used for recognition in this work are a subset of the character set of the English language. They were used to explore the feasibility of constructing a character recognition system. Having a system trained on the whole character set would allow written messages captured through fabric sensors to be transmitted. Since letters already have meaning embedded in them by convention, such an application would be intuitive, easy-to-use, and have great expressive power. 
    
    \item[-] \emph{Controllers:} Another category of applications that can be built using this sensor is that of controllers. This sensor allows the emulation of existing controller functionality, but with the added flexibility of fabric. For example, users can control their phone functionalities such as accepting or rejecting a phone call, changing the music, and more, through knitted interactive areas in their clothes, capable of recognizing gestures. Home automation is another potential application area, with such sensors integrated into furniture, pillows, or blankets, giving controllers a softer, more tactile-friendly quality. Gaming could benefit from application where knitted sensors are used as portable, foldable, and lightweight alternatives to hard-electronic controllers. Additionally, pressure sensitivity, an aspect of these sensors only explored in a limited way so far~\cite{Vallett2016a,Vallett2019a,mcdonald2020knitted}, could offer new interactive modalities for gaming and other applications.
    
    \item[-] \emph{Gestures in 3D Space:} Gestures do not need to be confined into a 2D plane. Knitted fabric can flex, fold, stretch, and move dynamically. Instead of only considering those fundamental aspects of fabric behaviour as qualities to design out, in order to maintain stability of touch or gesture representation, for certain applications we can also choose to design with these qualities at the center. For example, stretching could be given a specific meaning in a interactive system, and so can folding the fabric, twisting, or pinching it. An important aspect that needs to be considered while designing for such use cases however, is that capacitive sensing, the sensing strategy on which these sensors are designed, requires the presence of two conductors in proximity. In the typical cases, also explored in this work, the two conductors are the conductive yarn and human skin. 

    \item[-] \emph{Virtual and Augmented Reality (VR/AR) Applications:} Knitted sensors with gesture recognition technology integrated into them can be useful for VR/AR environments. It is easy to imagine objects that can be designed somewhat generically using knitted fabric with interactive gesture-sensing areas, with their functionality depending on the specific VR/AR application. This sensor's construction process allows for scalable design, resulting in interactive shapes capable of being built in different sizes. Therefore a whole environment could be composed of soft, knitted interactive objects, which take a different meaning and functionality, depending on the application and visuals overlayed on them. Additionally, such applications could be especially useful for kids, since they offer more safety than potential hard-electronic equivalents.
\end{itemize}