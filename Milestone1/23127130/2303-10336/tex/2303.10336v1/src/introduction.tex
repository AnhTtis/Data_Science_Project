\section{Introduction}
Innovation based on fabric sensors has the potential to enable many interactive applications. Through machine learning, this work advances gesture recognition in capacitive knitted sensors, designed to rely on one conductive yarn and few external connections. The ultimate goal in developing the underlying technology of these sensors is allowing them to behave like fabric in the real world~\cite{gemperle1998design}, while producing accurate real-time outputs that model complex behavior, upon which it is possible to develop interactive applications. 

Large-scale manufacturing outside a lab is important for real-world relevance of this technology, and has been addressed by many~\cite{Poupyrev2016a,chen2020design,Wicaksono2020KnittedKeyboard,Vallett2016a,Vallett2019a}. In order to create a sensor less susceptible to malfunctioning, needing few fabric-to-wire connections, and able to be manufactured at scale through an easily repeatable process, we use digital weft knitting, in a process similar to other work~\cite{Vallett2016a, Vallett2019a, mcdonald2020knitted}. A conductive, carbon-coated nylon yarn is routed together with other yarns in the fabric construction process according to a pre-programmed design pattern. There are four external connection points to this fabric component.

The limited number of external connections in these sensors makes manufacturing easier, while improving the sensors' robustness and flexibility, which in turn enhance their usability. However, this minimalism also creates the need for more complex computational models to process reduced information output from the system. We rely on a combination of Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) neural network architectures to capture the important aspects of the signal generated from different gestures. CNNs learn local relationships, while LSTMs focus on the sequential aspect of the time series signal data. Prior work~\cite{Vallett2019a, mcdonald2020knitted} has explored accurate touch location identification on a 36-button knitted touchpad, which uses the same design principles and construction process. However, those systems still do not offer gesture recognition capabilities. 


This work builds the foundations for creating an \emph{interactive gesture recognition system}, which would enable many applications. We introduce a \emph{sensor pattern} designed, through programmatically routing the carbon-fiber yarn, for gesture input, containing one solid sensing area and 4 electrodes to connect to external hardware; a \emph{supervised CNN-LSTM neural network model} to classify 12 relatively complex gestures performed on a knitted sensor, which are a subset of the characters of English language; \emph{results from three user studies} for training, evaluation of the model under normal lab conditions, and evaluation of the model while the sensor is being worn. Additionally, to get closer to real-world use, we present \emph{results from an experiment} investigating the effect of washing and drying on the sensor's resistance, an important property related to its circuit design and ultimately trained machine learning model.  

In the section below, we describe related work, followed by introducing our gesture recognition system composed of the knitted component, signal measurement circuit, signal processing pipeline, the gesture recognition model, and the deployment hardware. Our user studies, in the successive section, serve to collect data for training the model, and to evaluate its stability with new data. Next, we explore the applicability of this work in the real world, by furthering its technical evaluations and discussing the necessary processes and components to build applications relying on the gesture recognition capabilities of such a system. Following these explorations, the remaining sections provide more context, limitations, and future directions.  


