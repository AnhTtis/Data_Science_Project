%File: formatting-instructions-latex-2023.tex
%release 2023.0
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai23}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage[lined,ruled,vlined,commentsnumbered]{algorithm2e}
%\usepackage{algorithm}
%\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{times}
\usepackage{helvet}
\usepackage{courier}
\usepackage{epsfig}
\usepackage{mathrsfs}
\usepackage{multirow}
\usepackage{color}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{tabularx}
\usepackage{gensymb}
\usepackage{arydshln}
\usepackage{pifont}

\newcommand{\ljx}[1]{\textcolor{black}{#1}}
\newcommand{\seasons}[1]{\textcolor{black}{#1}}


%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
%\usepackage{newfloat}
%\usepackage{listings}
%\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
%\lstset{%
%	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
%	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
%	aboveskip=0pt,belowskip=0pt,%
%	showstringspaces=false,tabsize=2,breaklines=true}
%\floatstyle{ruled}
%\newfloat{listing}{tb}{lst}{}
%\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
/TemplateVersion (2023.1)
}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai23.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{APPENDIX for SpatialFormer}
\author {
    % Authors
    Jinxiang Lai \textsuperscript{\rm 1},
    Siqian Yang \textsuperscript{\rm 1},
    Wenlong Wu \textsuperscript{\rm 1},
    Tao Wu \textsuperscript{\rm 1},
    Guannan Jiang \textsuperscript{\rm 2},
    Xi Wang \textsuperscript{\rm 2},
    Jun Liu \textsuperscript{\rm 1},
    Bin-Bin Gao \textsuperscript{\rm 1},
    Wei Zhang \textsuperscript{\rm 2},
    Yuan Xie\thanks{Corresponding Author} \textsuperscript{\rm 3},
    Chengjie Wang\textsuperscript{*} \textsuperscript{\rm 1, 4}
}
\affiliations {
    % Affiliations
    \textsuperscript{\rm 1} Tencent Youtu Lab, China \quad
    
    \textsuperscript{\rm 2} CATL, China \quad
    
    \textsuperscript{\rm 3} East China Normal University, China \quad
    
    \textsuperscript{\rm 4} Shanghai Jiao Tong University, China\\
    
    \{jinxianglai, seasonsyang, ezrealwu, tobinwu\}@tencent.com, \{jianggn, wangx30, zhangwei\}@catl.com \\
    \{junsenselee, csgaobb\}@gmail.com, yxie@cs.ecnu.edu.cn, jasoncjwang@tencent.com
}

% REMOVE THIS: bibentry
% This is only needed to show inline citations in the guidelines document. You should not need it and can safely delete it.
\usepackage{bibentry}
% END REMOVE bibentry

\begin{document}
\maketitle


\section{Algorithm of STANet}
The algorithm of STANet is presented in Algorithm~\ref{alg:episode}.
The STANet contains six parts: embedding backbone ${f_\theta}$, Semantic and Target Attentions (STA) ${f_{STA}}$ module, Metric ${f_M}$ and Novel ${f_N}$ few-shot classifiers, and auxiliary Rotation ${f_R}$ and Global ${f_G}$ classifiers.
The training and inference of STANet can be divided into two steps: \textbf{Step 1}, train the base model ${f_{base}={[f_\theta,f_{STA},f_M,f_G,f_R]}}$ on the base set ${X^{base}}$; \textbf{Step 2}, fine-tune the Novel Classifier ${f_N}$ and make predictions with ${f_{MN}={[f_\theta,f_{STA},f_M,f_N]}}$ on the novel set ${X^{novel}}$.

\begin{algorithm}
\caption{STANet training and inference}
\label{alg:episode}
\SetAlgoLined
\SetKwInput{KwData}{Input}
\SetKwInput{KwModel}{Model}
\SetKwInput{KwResult}{Output}
 \KwData{$(\mathcal{S},\mathcal{Q}) \in {X^{base}}$; $(\mathcal{S{'}},\mathcal{Q{'}}) \in {X^{novel}}$; training and testing epochs $E_{1}$ and $E_{2}$}
 \KwModel{${f_\theta}$; ${f_{STA}}$; ${f_M}$; ${f_G}$; ${f_R}$; ${f_N}$}
 \KwResult{Inference accuracy $Acc$ on ${X^{novel}}$}
 \Begin{
 \textbf{Step 1:} Model training on base set.
 
 \For{i \textbf{from} 1 \textbf{to} $E_{1}$}{
 Sample training data $(\mathcal{S},\mathcal{Q}) \in {X^{base}}$\;
 Calculate loss $\mathcal{L}=\mathcal{L}_M+\mathcal{L}_G+\mathcal{L}_R$\;
 Optimize [${f_\theta}$,${f_{STA}}$,${f_M}$,${f_G}$,${f_R}$] with SGD\;
  }

 \textbf{Step 2:} Fine-tuning and inference on novel set.
 Freeze [${f_\theta}$,${f_{STA}}$,${f_M}$,${f_G}$,${f_R}$]; $acc$ = [];
 
 \For{j \textbf{from} 1 \textbf{to} $E_{2}$}{
 Sample testing data $(\mathcal{S{'}},\mathcal{Q{'}}) \in {X^{novel}}$\;
 Calculate cross entropy loss $\mathcal{L}_{N}$ for ${\mathcal{S{'}}}$\;
 Optimize ${f_N}$ with SGD\;
 Update the output of ${f_\theta}$ by NTA\;
 Predict $\mathcal{Q{'}}$\ with model [${f_\theta}$,${f_{STA}}$,${f_M}$,${f_N}$]\;
 Calculate accuracy and append it to $acc$\;
  }
calculate accuracy $Acc$\ with $acc$\;
\textbf{return}  $Acc$.}
\end{algorithm}


\renewcommand\thetable{6}
\renewcommand{\tabcolsep}{2.0pt}
\begin{table}[ht]
\caption{Comparison on 5-way classification task on CIFAR-FS dataset with ResNet-12 backbone.} 
\centering
%\vspace{-0.2cm}
\begin{tabular}{ l | c | c c}
\hline
\multicolumn{1}{l|}{\multirow{2}*{Model}}  & \multicolumn{2}{c}{CIFAR-FS} \\   
\cline{2-3}
\multicolumn{1}{c|}{ } & 1-shot &5-shot \\
\hline
RFS~\cite{tian2020rethinking} &71.50 $\pm$ 0.80 &86.00 $\pm$ 0.50 \\
MetaOpt~\cite{lee2019meta} &72.60 $\pm$ 0.70 &84.30 $\pm$ 0.50 \\
DSN-MR~\cite{simon2020adaptive} &75.60 $\pm$ 0.90 &86.20 $\pm$ 0.60 \\
IENet~\cite{rizve2021exploring} &76.83 $\pm$ 0.82 &89.26 $\pm$ 0.58 \\
\hdashline
\textbf{Our STANet} &\textbf{79.53 $\pm$ 0.47} &\textbf{89.87 $\pm$ 0.32} \\
\hline
\end{tabular}
%\vspace{-0.2cm}
\label{table:SOTA_cifar}
\end{table}

\renewcommand\thefigure{6}
\begin{figure}[ht]
\centering
\includegraphics[width=0.9\linewidth]{figs/visual.png}
%\vspace{-2mm}
\caption{The visualizations of SFSA, SFTA and STA.}
\label{fig:visual_compair}
%\vspace{-4mm}
\end{figure}

\renewcommand\thefigure{7}
\begin{figure}[ht]
\centering
\includegraphics[width=0.99\linewidth]{figs/visual2.png}
%\vspace{-2mm}
\caption{The visualizations of STA.}
\label{fig:visual_STA}
%\vspace{-4mm}
\end{figure}


\section{Comparison with SOTAs on CIFAR-FS}
CIFAR-FS dataset is constructed by randomly splitting the 100 classes of the CIFAR-100 dataset into 64, 16, and 20 categories for train, validation, and test.
Tab.~\ref{table:SOTA_cifar} shows that our STANet outperforms the existing SOTAs on CIFAR-FS dataset, which demonstrates the strength of our approach.


\section{Visualizations}
The visualizations of SFSA, SFTA and STA are shown in Fig.~\ref{fig:visual_compair} and Fig.~\ref{fig:visual_STA}.
The proposed SFSA and SFTA modules, are utilized to highlight the mutual similar object and obtain target-aware information, respectively. With their combination, the derived STA module is able to enhance target object while alleviate background distraction.

\section{More Discussions}
\subsection{More Explanations for \emph{Problem \ding{172}} and \emph{Problem \ding{173}}}
(I) \emph{Problem \ding{172}} means that the current CNN-based method models correlation between pairs based on local features, which produces inaccurate attention maps due to the target object is located randomly with different scale among the image.
(II) \emph{Problem \ding{172}} focuses on how to better measure the simlarity between pair features, while \emph{Problem \ding{173}} points out the distraction of similar backgrounds, i.e. even if \emph{Problem \ding{172}} is perfectly solved, \emph{Problem \ding{173}} is still exist.


\subsection{Parameters Comparison}
(I) The parameters of SpatialFormer and Transformer are the same since SpatialAttention is a non-parameter operator. As illustrated in Tab.~2, Our SpatialFormer-based SFSA and SFTA obtain large accuracy improvements than Transformer-based LoFTR and SuperGlue.
(II) The parameters with backbones of \{ResNet12, WRN28\} are listed as follows: ProtoG = \{7.75M, 35M\}, LoFTR = SuperGlue = SFSA = SFTA = \{9.25M, 36.5M\}, STA=\{10.75M, 38M\}. 
The parameters of a single SpatialFormer layer is 1.5M. Removing $\{W_Q,W_K,W_V\}$ reduces the parameters of SpatialFormer into 1M, while causes very slight influence on accuracy.


\subsection{Further Applications of SpatialFormer}
(I) We have further explored the applications of our SpatialFormer on few-shot segmentation and object detection tasks, and have achieved competitive improvements. 
(II) In detail, we further derive a SpatialFormer Embedding Attention (SFEA), via replacing the classifier weights $W_G$ of SFTA in Eq.~(7) to the learnable query embedding $W_E$ (pytorch code is $W_E$ = $nn.Embedding(C^{base}, c)$). Then, the SFEA can enhance the target regions of input features that are semantically similar to $W_E$, i.e. $f' = f_{SFEA}(f) = SpatialFormer(f,W_E)$.
(III) Stacking the SFEA after the backbone, we achieve improvements on: (a) PASCAL-5i segmentation: RePRI+ResNet50 (59.3/64.8 on 1/5 shot) vs. +SFEA (61.1/65.9). (b) VOC (Novel Set 1) detection with G-FSOD setting: DeFRCN+ResNet101 (40.2/63.6 on 1/5 shot) vs. +SFEA (43.1/65.7).


% Use \bibliography{yourbibfile} instead or the References section will not appear in your paper
%\nobibliography{aaai23}
%\newpage
\bibliography{aaai23}
\end{document}
