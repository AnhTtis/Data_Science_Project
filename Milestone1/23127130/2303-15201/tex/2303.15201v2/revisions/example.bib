

@Article{Gauss1857,
  Title                    = {Theory of the motion of the heavenly bodies moving about the sun in conic sections},
  Author                   = {Carl Friedrich Gauss and Charles Henry Davis},
  Journal                  = {Gauss's Theoria Motus},
  Year                     = {1857},
  Number                   = {1},
  Pages                    = {5--23},
  Volume                   = {76}
}

@Book{Lagrange1788,
  title		= {M{\'e}canique Analytique},
  author	= {Joseph-Louis Lagrange},
  publisher	= {Desaint, Paris},
  year		= {1788}
}

@article{yamaguchi2018identification,
  title={Identification of animal behavioral strategies by inverse reinforcement learning},
  author={Yamaguchi, Shoichiro and Naoki, Honda and Ikeda, Muneki and Tsukada, Yuki and Nakano, Shunji and Mori, Ikue and Ishii, Shin},
  journal={PLoS computational biology},
  volume={14},
  number={5},
  pages={e1006122},
  year={2018},
  publisher={Public Library of Science San Francisco, CA USA}
}

@article{sadigh2018planning,
  title={Planning for cars that coordinate with people: leveraging effects on human actions for planning and active information gathering over human internal state},
  author={Sadigh, Dorsa and Landolfi, Nick and Sastry, Shankar S and Seshia, Sanjit A and Dragan, Anca D},
  journal={Autonomous Robots},
  volume={42},
  pages={1405--1426},
  year={2018},
  publisher={Springer}
}

@article{jara2019theory,
  title={Theory of mind as inverse reinforcement learning},
  author={Jara-Ettinger, Julian},
  journal={Current Opinion in Behavioral Sciences},
  volume={29},
  pages={105--110},
  year={2019},
  publisher={Elsevier}
}

@article{rust1987optimal,
  title={Optimal replacement of GMC bus engines: An empirical model of Harold Zurcher},
  author={Rust, John},
  journal={Econometrica: Journal of the Econometric Society},
  pages={999--1033},
  year={1987},
  publisher={JSTOR}
}

@book{russell2019human,
  title={Human compatible: Artificial intelligence and the problem of control},
  author={Russell, Stuart},
  year={2019},
  publisher={Penguin}
}

@inproceedings{kuefler2017imitating,
  title={Imitating driver behavior with generative adversarial networks},
  author={Kuefler, Alex and Morton, Jeremy and Wheeler, Tim and Kochenderfer, Mykel},
  booktitle={2017 IEEE Intelligent Vehicles Symposium (IV)},
  pages={204--211},
  year={2017},
  organization={IEEE}
}

@inproceedings{ross2010efficient,
  title={Efficient reductions for imitation learning},
  author={Ross, St{\'e}phane and Bagnell, Drew},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={661--668},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{chan2021scalable,
  title={Scalable bayesian inverse reinforcement learning},
  author={Chan, Alex J and van der Schaar, Mihaela},
  journal={arXiv preprint arXiv:2102.06483},
  year={2021}
}

@article{kostrikov2019imitation,
  title={Imitation learning via off-policy distribution matching},
  author={Kostrikov, Ilya and Nachum, Ofir and Tompson, Jonathan},
  journal={arXiv preprint arXiv:1912.05032},
  year={2019}
}

@article{garg2021iq,
  title={IQ-Learn: Inverse soft-Q Learning for Imitation},
  author={Garg, Divyansh and Chakraborty, Shuvam and Cundy, Chris and Song, Jiaming and Ermon, Stefano},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={4028--4039},
  year={2021}
}

@article{nachum2019dualdice,
  title={Dualdice: Behavior-agnostic estimation of discounted stationary distribution corrections},
  author={Nachum, Ofir and Chow, Yinlam and Dai, Bo and Li, Lihong},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{das2020model,
  title={Model-based inverse reinforcement learning from visual demonstrations},
  author={Das, Neha and Bechtle, Sarah and Davchev, Todor and Jayaraman, Dinesh and Rai, Akshara and Meier, Franziska},
  journal={arXiv preprint arXiv:2010.09034},
  year={2020}
}

@article{rafailov2021visual,
  title={Visual adversarial imitation learning using variational models},
  author={Rafailov, Rafael and Yu, Tianhe and Rajeswaran, Aravind and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={3016--3028},
  year={2021}
}

@article{chang2021mitigating,
  title={Mitigating Covariate Shift in Imitation Learning via Offline Data With Partial Coverage},
  author={Chang, Jonathan and Uehara, Masatoshi and Sreenivas, Dhruv and Kidambi, Rahul and Sun, Wen},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={965--979},
  year={2021}
}

@inproceedings{herman2016inverse,
  title={Inverse reinforcement learning with simultaneous estimation of rewards and dynamics},
  author={Herman, Michael and Gindele, Tobias and Wagner, J{\"o}rg and Schmitt, Felix and Burgard, Wolfram},
  booktitle={Artificial Intelligence and Statistics},
  pages={102--110},
  year={2016},
  organization={PMLR}
}

@inproceedings{schmitt2017see,
  title={I see what you see: Inferring sensor and policy models of human real-world motor behavior},
  author={Schmitt, Felix and Bieg, Hans-Joachim and Herman, Michael and Rothkopf, Constantin A},
  booktitle={Thirty-First AAAI Conference on Artificial Intelligence},
  year={2017}
}

@article{wu2018inverse,
  title={Inverse Rational Control: Inferring What You Think from How You Forage},
  author={Wu, Zhengwei and Schrater, Paul and Pitkow, Xaq},
  journal={arXiv preprint arXiv:1805.09864},
  year={2018}
}

@article{kwon2020inverse,
  title={Inverse rational control with partially observable continuous nonlinear dynamics},
  author={Kwon, Minhae and Daptardar, Saurabh and Schrater, Paul R and Pitkow, Xaq},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={7898--7909},
  year={2020}
}

@article{wu2020rational,
  title={Rational thoughts in neural codes},
  author={Wu, Zhengwei and Kwon, Minhae and Daptardar, Saurabh and Schrater, Paul and Pitkow, Xaq},
  journal={Proceedings of the National Academy of Sciences},
  volume={117},
  number={47},
  pages={29311--29320},
  year={2020},
  publisher={National Acad Sciences}
}

@article{makino2012apprenticeship,
  title={Apprenticeship learning for model parameters of partially observable environments},
  author={Makino, Takaki and Takeuchi, Johane},
  journal={arXiv preprint arXiv:1206.6484},
  year={2012}
}

@article{reddy2018you,
  title={Where do you think you're going?: Inferring beliefs about dynamics from behavior},
  author={Reddy, Siddharth and Dragan, Anca D and Levine, Sergey},
  journal={arXiv preprint arXiv:1805.08010},
  year={2018}
}

@inproceedings{gong2020you,
  title={What is it you really want of me? generalized reward learning with biased beliefs about domain dynamics},
  author={Gong, Ze and Zhang, Yu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={03},
  pages={2485--2492},
  year={2020}
}

@inproceedings{baker2011bayesian,
  title={Bayesian theory of mind: Modeling joint belief-desire attribution},
  author={Baker, Chris and Saxe, Rebecca and Tenenbaum, Joshua},
  booktitle={Proceedings of the annual meeting of the cognitive science society},
  volume={33},
  number={33},
  year={2011}
}

@inproceedings{jarrett2021inverse,
  title={Inverse decision modeling: Learning interpretable representations of behavior},
  author={Jarrett, Daniel and H{\"u}y{\"u}k, Alihan and Van Der Schaar, Mihaela},
  booktitle={International Conference on Machine Learning},
  pages={4755--4771},
  year={2021},
  organization={PMLR}
}

@inproceedings{shah2019feasibility,
  title={On the feasibility of learning, rather than assuming, human biases for reward inference},
  author={Shah, Rohin and Gundotra, Noah and Abbeel, Pieter and Dragan, Anca},
  booktitle={International Conference on Machine Learning},
  pages={5670--5679},
  year={2019},
  organization={PMLR}
}

@article{armstrong2018occam,
  title={Occam's razor is insufficient to infer the preferences of irrational agents},
  author={Armstrong, Stuart and Mindermann, S{\"o}ren},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{chan2019assistive,
  title={The assistive multi-armed bandit},
  author={Chan, Lawrence and Hadfield-Menell, Dylan and Srinivasa, Siddhartha and Dragan, Anca},
  booktitle={2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  pages={354--363},
  year={2019},
  organization={IEEE}
}

@article{desai2018negotiable,
  title={Negotiable reinforcement learning for pareto optimal sequential decision-making},
  author={Desai, Nishant and Critch, Andrew and Russell, Stuart J},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{rigter2022rambo,
  title={Rambo-rl: Robust adversarial model-based offline reinforcement learning},
  author={Rigter, Marc and Lacerda, Bruno and Hawes, Nick},
  journal={arXiv preprint arXiv:2204.12581},
  year={2022}
}

@article{uehara2021pessimistic,
  title={Pessimistic model-based offline reinforcement learning under partial coverage},
  author={Uehara, Masatoshi and Sun, Wen},
  journal={arXiv preprint arXiv:2107.06226},
  year={2021}
}

@article{neu2017unified,
  title={A unified view of entropy-regularized markov decision processes},
  author={Neu, Gergely and Jonsson, Anders and G{\'o}mez, Vicen{\c{c}}},
  journal={arXiv preprint arXiv:1705.07798},
  year={2017}
}

@inproceedings{geist2019theory,
  title={A theory of regularized markov decision processes},
  author={Geist, Matthieu and Scherrer, Bruno and Pietquin, Olivier},
  booktitle={International Conference on Machine Learning},
  pages={2160--2169},
  year={2019},
  organization={PMLR}
}

@book{ziebart2010modeling,
  title={Modeling purposeful adaptive behavior with the principle of maximum causal entropy},
  author={Ziebart, Brian D},
  year={2010},
  publisher={Carnegie Mellon University}
}

@inproceedings{ziebart2008maximum,
  title={Maximum entropy inverse reinforcement learning.},
  author={Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K and others},
  booktitle={Aaai},
  volume={8},
  pages={1433--1438},
  year={2008},
  organization={Chicago, IL, USA}
}

@article{levine2018reinforcement,
  title={Reinforcement learning and control as probabilistic inference: Tutorial and review},
  author={Levine, Sergey},
  journal={arXiv preprint arXiv:1805.00909},
  year={2018}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@article{haarnoja2018softv2,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@article{ho2016generative,
  title={Generative adversarial imitation learning},
  author={Ho, Jonathan and Ermon, Stefano},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{zeng2022structural,
  title={Structural Estimation of Markov Decision Processes in High-Dimensional State Space with Finite-Time Guarantees},
  author={Zeng, Siliang and Hong, Mingyi and Garcia, Alfredo},
  journal={arXiv preprint arXiv:2210.01282},
  year={2022}
}

@article{zeng2023understanding,
  title={Understanding Expertise through Demonstrations: A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning},
  author={Zeng, Siliang and Li, Chenliang and Garcia, Alfredo and Hong, Mingyi},
  journal={arXiv preprint arXiv:2302.07457},
  year={2023}
}

@article{yue2023clare,
  title={CLARE: Conservative model-based reward learning for offline inverse reinforcement learning},
  author={Yue, Sheng and Wang, Guanbo and Shao, Wei and Zhang, Zhaofeng and Lin, Sen and Ren, Ju and Zhang, Junshan},
  journal={arXiv preprint arXiv:2302.04782},
  year={2023}
}

@article{borkar1997stochastic,
  title={Stochastic approximation with two time scales},
  author={Borkar, Vivek S},
  journal={Systems \& Control Letters},
  volume={29},
  number={5},
  pages={291--294},
  year={1997},
  publisher={Elsevier}
}

@article{hong2020two,
  title={A two-timescale framework for bilevel optimization: Complexity analysis and application to actor-critic},
  author={Hong, Mingyi and Wai, Hoi-To and Wang, Zhaoran and Yang, Zhuoran},
  journal={arXiv preprint arXiv:2007.05170},
  year={2020}
}

@article{gleave2022primer,
  title={A Primer on Maximum Causal Entropy Inverse Reinforcement Learning},
  author={Gleave, Adam and Toyer, Sam},
  journal={arXiv preprint arXiv:2203.11409},
  year={2022}
}

@inproceedings{ghasemipour2020divergence,
  title={A divergence minimization perspective on imitation learning methods},
  author={Ghasemipour, Seyed Kamyar Seyed and Zemel, Richard and Gu, Shixiang},
  booktitle={Conference on Robot Learning},
  pages={1259--1277},
  year={2020},
  organization={PMLR}
}

@inproceedings{ke2021imitation,
  title={Imitation learning as f-divergence minimization},
  author={Ke, Liyiming and Choudhury, Sanjiban and Barnes, Matt and Sun, Wen and Lee, Gilwoo and Srinivasa, Siddhartha},
  booktitle={International Workshop on the Algorithmic Foundations of Robotics},
  pages={313--329},
  year={2021},
  organization={Springer}
}

@article{finn2016connection,
  title={A connection between generative adversarial networks, inverse reinforcement learning, and energy-based models},
  author={Finn, Chelsea and Christiano, Paul and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.03852},
  year={2016}
}

@inproceedings{finn2016guided,
  title={Guided cost learning: Deep inverse optimal control via policy optimization},
  author={Finn, Chelsea and Levine, Sergey and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={49--58},
  year={2016},
  organization={PMLR}
}

@article{fu2017learning,
  title={Learning robust rewards with adversarial inverse reinforcement learning},
  author={Fu, Justin and Luo, Katie and Levine, Sergey},
  journal={arXiv preprint arXiv:1710.11248},
  year={2017}
}

@article{chua2018deep,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{janner2019trust,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{jafferjee2020hallucinating,
  title={Hallucinating value: A pitfall of dyna-style planning with imperfect environment models},
  author={Jafferjee, Taher and Imani, Ehsan and Talvitie, Erin and White, Martha and Bowling, Micheal},
  journal={arXiv preprint arXiv:2006.04363},
  year={2020}
}

@article{luo2018algorithmic,
  title={Algorithmic framework for model-based deep reinforcement learning with theoretical guarantees},
  author={Luo, Yuping and Xu, Huazhe and Li, Yuanzhi and Tian, Yuandong and Darrell, Trevor and Ma, Tengyu},
  journal={arXiv preprint arXiv:1807.03858},
  year={2018}
}

@article{yu2020mopo,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James Y and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={14129--14142},
  year={2020}
}

@article{kidambi2020morel,
  title={Morel: Model-based offline reinforcement learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={21810--21823},
  year={2020}
}

@article{yu2021combo,
  title={Combo: Conservative offline model-based policy optimization},
  author={Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={28954--28967},
  year={2021}
}

@inproceedings{lu2021revisiting,
  title={Revisiting design choices in offline model based reinforcement learning},
  author={Lu, Cong and Ball, Philip and Parker-Holder, Jack and Osborne, Michael and Roberts, Stephen J},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{cao2021identifiability,
  title={Identifiability in inverse reinforcement learning},
  author={Cao, Haoyang and Cohen, Samuel and Szpruch, Lukasz},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={12362--12373},
  year={2021}
}

@article{rolland2022identifiability,
  title={Identifiability and generalizability from multiple experts in Inverse Reinforcement Learning},
  author={Rolland, Paul and Viano, Luca and Sch{\"u}rhoff, Norman and Nikolov, Boris and Cevher, Volkan},
  journal={arXiv preprint arXiv:2209.10974},
  year={2022}
}

@inproceedings{kim2021reward,
  title={Reward identification in inverse reinforcement learning},
  author={Kim, Kuno and Garg, Shivam and Shiragur, Kirankumar and Ermon, Stefano},
  booktitle={International Conference on Machine Learning},
  pages={5496--5505},
  year={2021},
  organization={PMLR}
}

@article{amin2017repeated,
  title={Repeated inverse reinforcement learning},
  author={Amin, Kareem and Jiang, Nan and Singh, Satinder},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{hinton2002training,
  title={Training products of experts by minimizing contrastive divergence},
  author={Hinton, Geoffrey E},
  journal={Neural computation},
  volume={14},
  number={8},
  pages={1771--1800},
  year={2002},
  publisher={MIT Press}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@inproceedings{welling2011bayesian,
  title={Bayesian learning via stochastic gradient Langevin dynamics},
  author={Welling, Max and Teh, Yee W},
  booktitle={Proceedings of the 28th international conference on machine learning (ICML-11)},
  pages={681--688},
  year={2011}
}

@article{vemula2023virtues,
  title={The Virtues of Laziness in Model-based RL: A Unified Objective and Algorithms},
  author={Vemula, Anirudh and Song, Yuda and Singh, Aarti and Bagnell, J Andrew and Choudhury, Sanjiban},
  journal={arXiv preprint arXiv:2303.00694},
  year={2023}
}

@article{iyengar2005robust,
  title={Robust dynamic programming},
  author={Iyengar, Garud N},
  journal={Mathematics of Operations Research},
  volume={30},
  number={2},
  pages={257--280},
  year={2005},
  publisher={INFORMS}
}

@article{nilim2005robust,
  title={Robust control of Markov decision processes with uncertain transition matrices},
  author={Nilim, Arnab and El Ghaoui, Laurent},
  journal={Operations Research},
  volume={53},
  number={5},
  pages={780--798},
  year={2005},
  publisher={INFORMS}
}

@inproceedings{ramachandran2007bayesian,
  title={Bayesian Inverse Reinforcement Learning.},
  author={Ramachandran, Deepak and Amir, Eyal},
  booktitle={IJCAI},
  volume={7},
  pages={2586--2591},
  year={2007}
}

@article{du2020improved,
  title={Improved contrastive divergence training of energy based models},
  author={Du, Yilun and Li, Shuang and Tenenbaum, Joshua and Mordatch, Igor},
  journal={arXiv preprint arXiv:2012.01316},
  year={2020}
}

@inproceedings{asadi2018lipschitz,
  title={Lipschitz continuity in model-based reinforcement learning},
  author={Asadi, Kavosh and Misra, Dipendra and Littman, Michael},
  booktitle={International Conference on Machine Learning},
  pages={264--273},
  year={2018},
  organization={PMLR}
}

@article{choi2011map,
  title={Map inference for bayesian inverse reinforcement learning},
  author={Choi, Jaedeug and Kim, Kee-Eung},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ international conference on intelligent robots and systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@article{fu2020d4rl,
  title={D4rl: Datasets for deep data-driven reinforcement learning},
  author={Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.07219},
  year={2020}
}

@article{lambert2020objective,
  title={Objective mismatch in model-based reinforcement learning},
  author={Lambert, Nathan and Amos, Brandon and Yadan, Omry and Calandra, Roberto},
  journal={arXiv preprint arXiv:2002.04523},
  year={2020}
}

@inproceedings{farahmand2017value,
  title={Value-aware loss function for model-based reinforcement learning},
  author={Farahmand, Amir-massoud and Barreto, Andre and Nikovski, Daniel},
  booktitle={Artificial Intelligence and Statistics},
  pages={1486--1494},
  year={2017},
  organization={PMLR}
}

@article{grimm2020value,
  title={The value equivalence principle for model-based reinforcement learning},
  author={Grimm, Christopher and Barreto, Andr{\'e} and Singh, Satinder and Silver, David},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5541--5552},
  year={2020}
}

@article{zeng2022maximum,
  title={Maximum-Likelihood Inverse Reinforcement Learning with Finite-Time Guarantees},
  author={Zeng, Siliang and Li, Chenliang and Garcia, Alfredo and Hong, Mingyi},
  journal={arXiv preprint arXiv:2210.01808},
  year={2022}
}
