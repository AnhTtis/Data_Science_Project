\section{Analysis}\label{sec:ablation}
In this section, we first analyze the impact of different backbones in \cref{sec:ablation_backbone}.
conduct comprehensive ablation studies of multiple granularity contrastive loss and pseudo-label generation in \cref{sec:ablation_loss,sec:ablation_pseudo}.
Moreover, we analyze our limitations and broader impact. 

\subsection{Ablation of Backbone}

\label{sec:ablation_backbone}
As \cref{tab:backbone} shown, our method based on CLIP-ViT obtains the best performance compared with other backbones. In addition, results indicate that fine-grained and multi-grained losses improve performance under weak supervision and supervision, respectively.
\input{tables/backbone.tex}
\subsection{Ablation of Multiple Granularity Contrastive Loss}
\label{sec:ablation_loss}

In this section, we conduct comprehensive ablation studies to investigate the effects of our multiple granularity contrastive loss.
To better demonstrate the superiority of our method, we present the loss ablation experiments on the sequence verification task under supervision with classification in \cref{tab:loss}. As shown, both coarse-grained contrastive loss $L_{\text{coarse}}$ and fine-grained loss $L_{\text{fine}}$ are crucial. Specifically, the method with coarse-grained and fine-grained contrastive loss surpasses the method without them by 3.34\%. 
\input{tables/loss.tex}
Introducing the fine-grained loss $L_{\text{fine}}$ brings 2.6\% performance improvement compared to only using coarse-grained contrastive loss $L_{\text{coarse}}$. Comparing only uses $L_\text{coarse}$ or uses  $L_\text{fine}$, the result indicates that the model training with more fine-grained information is better than coarse information. 
% Fine-grained contrastive loss restricts the video representation in frame-sentence level latent space, which could help the model learn more discriminative video representations.
By restricting the video representation to frame-sentence level latent space, the fine-grained contrastive loss can help the model learn more discriminative video representations.

\input{fig/visualization/visualization}
\vspace{-1.0em}
The visualization of the ablation study about fine-grained loss, as shown in \cref{fig:vis}, illustrates fine-grained contrastive loss implements the alignment between frames and sentences. 

\subsection{Ablation of the Pseudo-Label Generation}
\label{sec:ablation_pseudo}

\noindent \textbf{Splitting.} 
Splitting means we split the sequence of frame representations or sentence representations uniformly into several parts to keep the sequence length of frame representations or sentence representations equal.
The values belonging to the same part will be added and then averaged. After that, we get a square matrix and output probability distribution of prediction. The elements along the diagonal are regarded as pseudo labels. Then calculate the fine-grained contrastive loss as \cref{eq:fine2}. This process is shown in \cref{fig:1d}, and the blue boxes represent the pseudo-labels.
\input{tables/gumbel.tex}
\vspace{-0.2em}
We conduct ablation studies about three methods of pseudo-label generation in the fine-grained loss $L_\text{fine}$ showing in \cref{tab:gumbel}. Specifically, we validate the effectiveness of different kinds of coarse-grained contrastive loss on the weakly supervised video verification task. 
The results show the algorithms of maximum-index sorting and Viterbi are performing better than splitting. The method of splitting matrices into several parts and aligning sequences along the diagonal is too simple and crude .

\noindent \textbf{Broader Impact and Limitations.}
\label{sec:limitation}
In realistic sequential videos, sub-actions could be repeated. It could mislead the model to generate biased pseudo-labels and lead to the deterioration of performance.More analysis can be seen in  supplementary materials. Moreover, the proposed method will likely be applied to behavior detection, healthcare, online education, industrial generation, etc. 

% While our method performs well on the major part of the data, there still are some failure cases. In realistic sequential videos, sub-actions are often repeated. In that case, there are multiple sentences with high similarity to a frame. It could mislead the model to generate biased pseudo-labels, which will lead to the deterioration of performance. For example, the occurrence of a large number of repetitive actions repetitive action might hidden achieving further performance. More details can be seen in supplementary materials. Moreover, the proposed method will likely be applied to behavior detection, health management, industrial generation, online education, etc. 