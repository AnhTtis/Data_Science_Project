\section{Conclusion \& Discussion}
\label{sec:discussion}

In conclusion, demonstrations have proven to be an effective way of improving the performance of agents in reinforcement learning and planning tasks. They offer valuable insights into the desired behavior of an agent, and can help accelerate the learning process. This survey has highlighted the various methods and approaches for utilizing demonstrations, especially in the context of embodied AI.

Despite the growing interest in demonstrations, there are still many challenges to overcome. One major issue is scaling up the demonstration collection process, which is currently hindered by limited scalability of teleoperation-based methods and quality control issues in learning-based autonomous pipelines. A promising solution could be the development of human-in-the-loop autonomous systems that can improve over time.

In addition to the collection of demonstrations, there is also a need to consider the types of demonstrations that are required. Questions such as the necessity of near-optimal demonstrations, the potential of learning from different embodiments, and the use of abstract demonstrations like natural language need to be addressed.

Another critical problem is the integration of offline and online learning. While some initial attempts have been made, there is still a need for solutions that can accommodate different forms and qualities of demonstrations in a variety of scenarios, particularly in partially observed and cross-domain contexts.

Overall, demonstrations have the potential to significantly enhance the performance of reinforcement learning and planning algorithms in real-world settings. However, there is still much to be explored and discovered in this area, and numerous opportunities exist for further research and development.