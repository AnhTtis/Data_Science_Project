{
    "arxiv_id": "2303.16459",
    "paper_title": "GNNBuilder: An Automated Framework for Generic Graph Neural Network Accelerator Generation, Simulation, and Optimization",
    "authors": [
        "Stefan Abi-Karam",
        "Cong Hao"
    ],
    "submission_date": "2023-03-29",
    "revised_dates": [
        "2023-03-30"
    ],
    "latest_version": 1,
    "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
    ],
    "abstract": "There are plenty of graph neural network (GNN) accelerators being proposed. However, they highly rely on users' hardware expertise and are usually optimized for one specific GNN model, making them challenging for practical use . Therefore, in this work, we propose GNNBuilder, the first automated, generic, end-to-end GNN accelerator generation framework. It features four advantages: (1) GNNBuilder can automatically generate GNN accelerators for a wide range of GNN models arbitrarily defined by users; (2) GNNBuilder takes standard PyTorch programming interface, introducing zero overhead for algorithm developers; (3) GNNBuilder supports end-to-end code generation, simulation, accelerator optimization, and hardware deployment, realizing a push-button fashion for GNN accelerator design; (4) GNNBuilder is equipped with accurate performance models of its generated accelerator, enabling fast and flexible design space exploration (DSE). In the experiments, first, we show that our accelerator performance model has errors within $36\\%$ for latency prediction and $18\\%$ for BRAM count prediction. Second, we show that our generated accelerators can outperform CPU by $6.33\\times$ and GPU by $6.87\\times$. This framework is open-source, and the code is available at https://anonymous.4open.science/r/gnn-builder-83B4/.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.16459v1"
    ],
    "publication_venue": "10 pages, 7 figures, 4 tables, 3 listings"
}