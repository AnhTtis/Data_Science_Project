\section{Introductions}
Task-Oriented Dialog (ToD) systems facilitate users to achieve their goals through the utilization of human-like language interactions.
Traditionally, ToD systems have employed diverse modular architectures~\cite{molich1990improving}, incorporating separate components for Natural Language Understanding (NLU)~\cite{mairesse2009spoken,lee2019convlab}, Dialogue State Tracking (DST)~\cite{ren2018towards,lee2013structured}, Dialogue Policy (POL)~\cite{peng2018deep,le2021predictable,le2021generating}, and Natural Language Generation (NLG)~\cite{wen2015semantically,peng2020few} that are connected in a pipeline. 
Other variations of the pipeline also exist where NLU and DST are merged into a single module, named Word-DST~\cite{ramadan2018large}, while POL and NLG are integrated into a single module, called Word-POL~\cite{chen2019semantically,budzianowski2018towards}.
Moreover, End-to-End (E2E) systems have emerged, producing a natural language response directly from the user's input without using intermediate stages~\cite{bordes2016learning}. 
E2E ToD systems that include intermediate outputs (e.g., DST, POL) have gained increasing popularity recently since such systems can utilize intermediate outputs to facilitate effective communication with external APIs~\cite{zhang2020task}.

\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth]{assets/approach.pdf}
    \vspace{-10pt}
    \caption{
%Overview of how a task-oriented dialog system works using domain schema.
Overview of {\oursys}: the domain schema facilitates estimating dialog state, system actions, and system response irrespective of whether the model was trained on that domain or not.
Parts of the schema that assist in the generation are grouped by similar colors.
       % Given a dialog history consisting of the user and system utterances and the domain schema, for the current turn the dialog state, system actions and system response is generated.
       % Parts of the schema that assist in the generation are grouped by similar colors.
    }
    
    \label{fig:approach}
    \vspace{-12pt}
\end{figure}

\begin{figure*}[t]
   \centering
   \includegraphics[width=0.95\linewidth]{assets/our_model.pdf}
   \vspace{-15pt}
   \caption{
       Overview of our approach. A GPT-2 model is fed the dialog state of the previous turn, the last user utterance, relevant schemas, database search results, and a list of system action names.
       As output, the model autoregressively generates the current dialog state, user actions, system actions, and system response.
   }
   \vspace{-15pt}
   \label{fig:our_model}
\end{figure*}

The state-of-the-art (SOTA) approaches in ToD systems formulate the problem as a conditional sequence generation task and finetune pre-trained causal language models in a supervised manner using single-domain or multi-domain datasets~\cite{HosseiniAsl2020ASL,Peng2021SoloistBT,Lee2020SUMBTLaRLEN,Yang2020UBARTF,Jeon2021DORATP,Sun2022BORTBA,Yang2022UBARv2TM}.
These systems feed the dialog history to the model as input and the output is a cascaded generation~\cite{su2021multi} of the DST, POL, and NLG.
%
%Traditional ToD systems were built using a pipeline approach, where each component (e.g., Dialog State Tracking (DST)~\cite{wang-etal-2016-inner}) was created separately and then integrated into the system.
%However, with the adaptation of large pre-trained language models (LLMs)~\cite{Devlin2019BERTPO,Radford2019LanguageMA},
%researchers have moved towards building end-to-end systems~\cite{HosseiniAsl2020ASL,Peng2021SoloistBT,Lee2020SUMBTLaRLEN,Yang2020UBARTF,Jeon2021DORATP,Sun2022BORTBA,Yang2022UBARv2TM}.
%
Such systems are typically trained using large amounts of labeled data. %, which means that each dialog turn has been manually labeled with the appropriate response. 
In order for a dialog system to perform well on a specific task or in a specific domain, it needs to be trained on a large amount of labeled data that is specific to that task or domain.
%\todo{Maybe we can remove this example to save space. This is repeated in the first sentence of the next paragraph}
%For example, if a company wants to develop a ToD system that can assist customers with reserving a table at a restaurant, it would need to collect a large amount of dialog data that includes examples of customer utterances and the appropriate responses. The ToD system would then be trained on this data to learn how to respond to similar user utterances in the future.
%However, if the company later wants to use the same ToD system for a different task, such as booking hotel rooms, it would not be able to perform well without additional training. 
%This is because the system has not been exposed to any labeled data that is specific to the task of booking hotel rooms. 
%Therefore, it would not be able to generalize to this new task without additional training on labeled data specific to booking hotel rooms.
A major drawback of most of these systems is that they fail to generalize to unseen domains and acquiring data for each new domain is prohibitively laborious and expensive, which motivates zero-shot generalizable ToD systems.
Recently, researchers have shown the possibility of building zero-shot generalizable individual components like the DST, next action prediction, and response generation, for ToD systems~\cite{Lee2021DialogueST,siddique2021linguistically,Mehri2021SchemaGuidedPF,siddique2021generalized}.
Nonetheless, to the best of our knowledge there has been no work on building zero-shot generalizable end-to-end ToD systems.

%In this work, we propose a novel schema-guided zero-shot generalizable end-to-end ToD system using context summarization.
%\todo{Adib: please discuss:  1. Figure 1 in detail and show how schema can facilitate zero-shot generalization; 2. why we introduce the concise summary of the DST; 3. why we need two-step training; 4. talk about results. Expand on the first three points for your Section 2.3 (training).}
%\tododone{Completed}
%that outperforms existing state-of-the-art systems.
%zero-shot generalizable components for ToD systems have 
%Researchers have shown promising 
%Some work has been done to create more general systems~\cite{Feng2020ASA,Lee2021DialogueST,Noroozi2020AFA,Mosig2020STARAS,Mehri2021SchemaGuidedPF},
%for individual components like the DST, next action prediction and response generation, but there has been no work on generalizable end-to-end systems.
%interact with users in the form of dialog using natural language, to accomplish user tasks.
%The system needs to understand user needs and provide the best possible response to the user.
%The task of extracting user intent and goals from conversations by filling belief slots is called Dialog State Tracking (DST)~\cite{wang-etal-2016-inner}.
%Using DST and dialog history, the system needs to decide what actions to take and then convey that action in the form of natural language to the user.
%Traditional ToD systems were built using a pipeline approach, where each component is created separately and then integrated into the system.
%However, with the adaptation of large pretrained language models~\cite{Devlin2019BERTPO,Radford2019LanguageMA},
%researchers have moved towards end-to-end systems~\cite{HosseiniAsl2020ASL,Peng2021SoloistBT,Lee2020SUMBTLaRLEN,Yang2020UBARTF,Jeon2021DORATP,Sun2022BORTBA,Yang2022UBARv2TM},
%In these systems, the dialog history is fed to the model as input and the output is a cascaded generation~\cite{su2021multi} of the DST, System Actions and System Response.
%In the real-world setting, ideally, a system
%should have the capablity to adjust to new domains. Domain knowledge in dialogs can be represented by incorporating schemas, which
%lists possible intents, slot names and slot values. An overview of how a TOD system works by incorporating schema is shown in Figure~\ref{fig:approach}.
%Some work has been done to create more general systems~\cite{Feng2020ASA,Lee2021DialogueST,Noroozi2020AFA,Mosig2020STARAS,Mehri2021SchemaGuidedPF},
%for individual components like the DST, next action prediction and response generation, but there has been no work on generalizable end-to-end systems.
%Another drawback in most systems is that they perform poorly in dialogs that have many turns. As the number of turns increases,
%the dialog history becomes very long, repetitive and slot values could be updated multiple times in different turns depending on the needs of the user.
%This makes it difficult for systems to correctly model long-range semantic dependencies~\cite{sun2022mars}.
% To address the aforementioned challenges, we propose a novel Schema Guided Zero-Shot Generalizable End-to-End TOD system using Context Summarization
% that outperforms existing state-of-the-art systems. We replace the dialog history with the dialog state as it contains the summary
% of the dialog history and is a more compact, efficient and informative representation of the dialog history.
% Since the input size is smaller, we can feed additional relevant information to the model, such as the schema, database search results and a list of
% system action names, which allows the model to better understand the dialog and generalize to new domains.
% We also propose a two step training process, where the first step focuses on understanding the structure of the
% data, and the second step focuses on generating the correct output. We conduct experiments on the Schema-Guided Dialog~(SGD) dataset
% and provide an ablation study to show the effectiveness of our approach. To the best of our knowledge,
% this is the first Zero-Shot End-to-End TOD system designed for the SGD dataset.

We propose a novel \textbf{Z}ero-\textbf{S}hot generalizable end-to-end \textbf{ToD} system, {\oursys}\footnote{The code is available at \url{https://github.com/MultifacetedNLP/ZS-ToD}}, using context summarization and domain schema.
The domain information can be represented in the form of a schema, which contains a set of intents and the 
relevant set of slots needed to fulfill a given intent.
The domain schema can facilitate zero-shot generalization to unseen domains in ToD systems. 
Figure~\ref{fig:approach} shows
a few example turns from a dialog, the intermediate outputs consisting of the DST, user actions, system actions, and the domain schema for that dialog.
In the first turn, the schema guides the system to infer the user intent, and the first few system actions are based on the required slots of the schema.
As the conversation continues, the user makes additional queries that are part of the optional slots. 
Similarly, when the system queries the database using the query parameters from the DST, the results contain the slot names listed in the result slots. 
The top search result is usually offered to the user and if the user rejects
the offered item, the next option from the search results is offered.

SOTA ToD systems use dialog history as the context to generate a response for a given turn. 
Generally, the dialog history consist of multiple turns (e.g., more than 20 turns) often containing conflicting information. For example, a slot value can be updated in later turns or the active intent of the user could change. 
%and in many turns information about slots are updated and in multi-intent dialogs, the active intent of the user could change at any point. 
At each turn, the system needs to model long as well as short range dependencies in the dialog context to accurately predict the current dialog state, and any errors made at any step would propagate to future steps. 
To alleviate this problem, we propose to replace the dialog history with the
dialog state from the previous turn, as this would provide a concise summary of all the previous turns and allow the system to focus on the current state rather than previous states.
Using a summarized context reduces the context size by a significant amount, thus allowing us to feed extra information, such as domain schema, database results and list of system action types, which otherwise would not have been possible without using a larger language model.

% \tododone{new style, with our solution first}
The goal of ToD systems is to generate a response (and intermediate outputs if needed), so there should be an explicit focus on the loss calculation for the response.
To fulfill this requirement, we propose a two-step training process, where the first step focuses on understanding the structure of the dialog data, and the second step focuses on generating the correct response. 
SOTA {\tod} models are passed an input prompt (i.e, dialog history) and generate a response for the given prompt.
However, these systems are trained using a {\celoss} over the whole sequence, i.e, dialog history and response. 
This kind of loss calculation for optimization might give the model superfluous rewards for correctly predicting the input prompt.

% \todo{old writing}
% SOTA ToD models are passed an input prompt (i.e., dialog history) and they generate a response for the given prompt.
% These systems are trained using cross-entropy loss over the whole sequence, i.e., dialog history as well as response.
% This kind of loss calculation for optimization might give the model extra reward for correctly predicting the input prompt. 
% Whereas, the goal of ToD systems is to generate a response (and intermediate outputs if needed), so there should be an explicit focus on the loss calculation for the response. 
% To fulfill this requirement, we propose a two-step training process, where the first step focuses on understanding the structure of the dialog data, and the second step focuses on generating the correct response.

To evaluate the effectiveness of our proposed model, we conducted extensive evaluations using Schema Guided Dialogue (SGD) and SGD-X dataset that span multi-domain dialogs across 20 domains.
{\oursys} outperforms existing baseline systems across key metrics, particularly with a \textbf{+17\% joint goal accuracy} and \textbf{+5 inform} improvement over prior work, demonstrating the feasibility of our approach for {\zs} generalizable {\etoe} {\tod} systems.

%which contains the input prompt. Since ToD systems receive the dialog history, schemas and other 
%information as input prompt, using a cross entropy loss function over the whole sequence for optimization might give the model extra reward for correctly predicting the 
%input prompt. The goal of ToD systems should be to generate intermediate steps and a response, so there should be an explicit focus on the newly generated text. To fulfill this 
%requirement, we propose a two step training process, where the first step focuses on understanding the structure of the data, and the second step focuses on generating the correct output.
%\todo{Adib: 4. talk about results. with percentages, better than this and that...}\tododone{Done}