\algrenewcommand\algorithmicindent{1.0em}%
\begin{algorithm}[H]
  \caption{\textbf{Sampling}} \label{alg:sampling}
  \small
\begin{algorithmic}[1]
     \State Trained diffusion model $\theta$, $\bm{x}_T \sim \mathcal{N}(\bm{0}, \bm{I})$
    \For{$t=T, \dotsc, 1$}
      \State $\hat{\bm{\epsilon}}_\theta = \bm{\epsilon}_\theta(\bm{x}_t, t) + s \cdot (\bm{\epsilon}_{\theta}(\bm{x}_t, \bm{c}, t) - \bm{\epsilon}_\theta(\bm{x}_t, t))$
        \State $\bm{z}_0(t) \sim \mathcal{N}(\bm{0}, \sigma^2_a(t)  \bm{I})$ 
        \For{$i=1, \dotsc, N$}
        \State $\bm{z}_i(t) \sim \mathcal{N}(\bm{z}_0(t) , (1-\sigma^2_a(t)) \bm{I})$ 
    \EndFor
      \State $\bm{z}(t)=\{\bm{z}_1(t),\dots,\bm{z}_N(t)\}$, if $t > 1$, else $\bm{z}(t) = \bm{0}$
      \State $\bm{x_{t-1}} = \frac{1}{\sqrt{\alpha_t}}\left( \bm{x_t} - \frac{1-\alpha_t}{\sqrt{1-\bar\alpha_t}} \hat{\bm{\epsilon}}_\theta \right) + \sigma_t \bm{z}(t)$
    \EndFor
    \State \textbf{return} $\bm{x}_0$
  \end{algorithmic}
\end{algorithm}