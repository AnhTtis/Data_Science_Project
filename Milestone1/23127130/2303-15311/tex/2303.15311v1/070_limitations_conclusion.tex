% \vspace{-1mm}
\section{CONCLUSION}
We present \ours, a dynamic tree structure for clustering-based approximations of the softmax distribution. Our algorithm efficiently gives provably accurate samples for training dual-encoders with cross-entropy loss. 
Empirically, \ours outperforms state-of-the-art on datasets with over twenty million targets, reducing error by half compared to an exhaustive oracle. 
We find that our dynamic maintenance of the tree structure can be 8x faster than exhaustive re-indexing. Furthermore, our approach outperforms state-of-the-art while using 150x less accelerator memory.

