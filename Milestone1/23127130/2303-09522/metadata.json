{
    "arxiv_id": "2303.09522",
    "paper_title": "$P+$: Extended Textual Conditioning in Text-to-Image Generation",
    "authors": [
        "Andrey Voynov",
        "Qinghao Chu",
        "Daniel Cohen-Or",
        "Kfir Aberman"
    ],
    "submission_date": "2023-03-16",
    "revised_dates": [
        "2023-03-28"
    ],
    "latest_version": 2,
    "categories": [
        "cs.CV",
        "cs.CL",
        "cs.GR",
        "cs.LG"
    ],
    "abstract": "We introduce an Extended Textual Conditioning space in text-to-image models, referred to as $P+$. This space consists of multiple textual conditions, derived from per-layer prompts, each corresponding to a layer of the denoising U-net of the diffusion model.\n  We show that the extended space provides greater disentangling and control over image synthesis. We further introduce Extended Textual Inversion (XTI), where the images are inverted into $P+$, and represented by per-layer tokens.\n  We show that XTI is more expressive and precise, and converges faster than the original Textual Inversion (TI) space. The extended inversion method does not involve any noticeable trade-off between reconstruction and editability and induces more regular inversions.\n  We conduct a series of extensive experiments to analyze and understand the properties of the new space, and to showcase the effectiveness of our method for personalizing text-to-image models. Furthermore, we utilize the unique properties of this space to achieve previously unattainable results in object-style mixing using text-to-image models. Project page: https://prompt-plus.github.io",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.09522v1",
        "http://arxiv.org/pdf/2303.09522v2"
    ],
    "publication_venue": null
}