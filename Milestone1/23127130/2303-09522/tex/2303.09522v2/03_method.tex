\section{Extended Conditioning Space}

% \cq{\subsection{Motivation}}

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{figures/swap.pdf}
    \caption{{\bf Per-layer Prompting.} We provide different text prompts (a precursor to $\PromptP$) to different cross-attention layers in the denoising U-net. We see that color (\texttt{"red"}, \texttt{"green"}) is determined by the fine outer layers and content (\texttt{"cube"}, \texttt{"lizard"}) is determined by the coarse inner layers.
    % By conditioning the denoising U-net with distinct prompts for coarse-resolution and fine-resolution layers, the network demonstrates disentanglement within the space of extended prompts.
    }
    \label{fig:swap}
    \vspace{-10pt}
\end{figure}

To engage the reader, we begin with a simple experiment on the publicly available Stable Diffusion model \cite{Rombach_2022_CVPR}.
We partitioned the cross-attention layers of the denoising U-net into two subsets: coarse layers with low spatial resolution and fine layers with high spatial resolution. We then used two conditioning prompts: \texttt{"red cube"} and \texttt{"green lizard"}, and injected one prompt into one subset of cross-attention layers, while injecting the second prompt into the other subset.
The resulting generated images are provided in Figure \ref{fig:swap}. Notably, at the first run the model generates a red lizard, by taking the subject from the coarse layers' text conditioning, and appearance from the fine layers' conditioning. Similarly, in the second run it generates the green cube, once again taking the appearance from the fine layers and the subject from the coarse layers. This experiment suggests that the conditioning mechanism at different resolutions processes prompts differently, with different attributes exerting greater influence at different levels. With this in mind, our work aims to further explore this phenomena and its potential applications.


% \av{In particular, this example demonstrates the disentanglement of synthesized image attributes with respect to different layers conditioning.}
% \cq{These experiments demonstrate that content and appearance can be disentangled along different U-net cross-attention layers.}

In the following parts, we introduce the Extended Textual Conditioning space (\ourmethod) and its key properties. We then detail how this space can be utilized to perform textual inversion for a given set of images.

\subsection{$\mathbfcal{P}+$ Definition}

% In this section we describe in details the proposed extended prompts mechanism. In most of the popular diffusion generative models architectures, the denoising U-net model text conditioning is implemented with the cross-attention layers \cite{TODO}.


Let $\Prompt$ denote the \textit{textual-conditioning space}. $\Prompt$ refers to the space of token embeddings that are passed into the text encoder in a text-to-image diffusion model. To clarify the definition of this space, we provide a brief overview of the process that a given text prompt undergoes in the model before being injected into the denoising network.

Initially, the text tokenizer splits an input sentence into tokens, with a special token marking the end of the sentence (EOS). Each token corresponds to a pre-trained embedding that is retrieved from the embedding lookup table. Subsequently, these embeddings are concatenated and passed through a pre-trained text encoder, then injected to the cross attention layers of the U-net model. In our work, we define $\Prompt$ as the set of individual token embeddings that are passed to the text encoder. The process of injecting a text prompt into the network for a particular cross-attention layer is illustrated in Figure~\ref{fig:cross_attention}.

We next present the \textit{Extended Textual Conditioning} space, denoted by $\PromptP$, which is defined as follows:
\begin{equation}
\PromptP  \coloneqq \left\{p_1, p_2, ... p_n\right\},
\end{equation}
where $p_i\in\Prompt$ represents an individual token embedding corresponding to the $i$-th cross-attention layer in the denoising U-net. Figure~\ref{fig:unet} illustrates the conceptual difference between the two spaces, $\Prompt$ (left) and $\PromptP$ (right).


\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\columnwidth]{figures/ca.pdf}
    \caption{{\bf Text-conditioning mechanism of a denoising diffusion model.} The prompt \texttt{"a cat"} is processed with a sentence tokenization, by a pretrained textual encoder, and fed into a cross-attention layer. Each of the three bars on the left represents a token embedding in $\Prompt$.
    % \kac{We can mark on the figure that an individual token embedding (one of the 3 bars) as $p\in\Prompt$} \dc{I would not.. it will make the figure too cluttered. I think it is clear now.}
    }
    \label{fig:cross_attention} 
\end{figure}

% In this architecture, all of the cross-attention layers share the same text embedding, shown in Figure \ref{fig:unet} (left).
% % , a single text prompt \cqc{change to text embedding} is passed to multiple layers of the denoising U-net.
% We propose to expand this conditioning by passing different \cq{text embeddings} to each cross-attention layer, as illustrated in Figure \ref{fig:unet} (right).


%With the definition of the new space, our diffusion model, previously conditioned on a single prompt $U(x | t, p)$, can now synthesize images in the extended space $U(x | t, {p_1, \dots, p_n})$, where $t$ denotes the denoising timestep.

%As $\Prompt$ is a subspace of $\PromptP$, we naturally inquire about the advantages of synthesizing in the extended space. In Section~\ref{sec:exp}, we present an analysis of the properties of the new space, which showcases a higher degree of control over various attributes. Specifically, different layers are found to dominate different attributes, such as style, color, and shape.

%Revised version:

With the definition of the new space, our diffusion model, previously conditioned on a single prompt $U(x | t, p)$, can now synthesize images in the extended space $U(x | t, {p_1, \dots, p_n})$, where $t$ denotes the denoising timestep.

As $\Prompt$ is a subspace of $\PromptP$, we naturally inquire about the advantages of synthesizing in the extended space. In Section~\ref{sec:exp}, we present an analysis of the properties of the new space, which showcases a higher degree of control over various attributes. Specifically, different layers are found to dominate different attributes, such as style, color, and structure.

A notable benefit of this space is its potential for enhancing textual inversion. We next demonstrate how the extended space can be utilized to represent subjects with greater fidelity, while maintaining the capability for editing.



% \cq{As one of our primary goals is improving textual inversion, the expansion of the conditioning space might simplify the inversion task.}
% First, as in many neural architectures, different layers are responsible for different abstraction levels \cite{karras2019style, bau2020units, voynovrpgan, zeiler2014visualizing}. It is natural to expect similar behaviour in the diffusion denoising U-net backbone as well. Thus, different textual descriptions might be useful at different layers. 
% Second, as one of our primary goals is the textual inversion improvement, the expansion of the conditioning space might simplify the inversion task. 
% Formally, the original model $U(x | t, \texttt{p})$ is conditional to a textual prompt $\texttt{p}$ and a noise level $t$. We turn it to the conditional model $U(x | t, \{\texttt{p}_1, \dots, \texttt{p}_n\})$ conditioned with the set of per-cross-attention layer prompts $\{\texttt{p}_1, \dots, \texttt{p}_n\}$ with $n$ being the number of the models' text cross-attention layers.
% \cq{Formally, the original model $U(x | t, p)$ is conditioned on text embeddings $p$ and a noise level $t$. We turn it to the conditional model $U(x | t, \{p_1, \dots, p_n\})$ conditioned with the set of per-cross-attention layer text embeddings $\{{p}_1, \dots, {p}_n\}$ where $n$ is the number of cross-attention layers.}
% \cqc {I changed this to text embedding instead of prompt, original is commented out}

\subsection{Extended Textual Inversion (XTI)}

% This section describes our Extended Textual Inversion approach, coined XTI, which is a generalized Textual Inversion) algorithm. First, let us recall the . 
Given a set of images $\mathcal{I} = \{I_1, \dots, I_k\}$ of a specific subject, the goal of the Textual Inversion (TI) operation \cite{gal2022image} is to find a representation of the object in the conditioning space $\Prompt$. We next explain how we extend the TI approach and perform the inversion into \ourmethod. This process is coined Extended Textual Inversion (XTI). 

First, we add $n$ new textual tokens $\texttt{t}_1, \dots, \texttt{t}_n$ to the tokenizer model, associated with $n$ new token embeddings lookup-table elements $e_1, \dots, e_n$. Then, similarly to \cite{gal2022image}, we optimize the token embeddings with the objective to predict the noise of a noisy images from $\mathcal{I}$, while the token embeddings are injected to the network. 

% In practice, we employ a collection of placeholder sentences denoted by $\Pi = \{P_1, \dots, P_m\}$, each containing a special placeholder symbol "\texttt{\{\}}" to represent the location where one of the additional tokens $\texttt{t}_1, \dots, \texttt{t}_n$ is inserted (e.g. "\texttt{A photograph of \{\}}"). We denote by $P_i(\texttt{t}_1, \dots, \texttt{t}_n)$  the set of $n$ sentences, where the special symbol "\texttt{\{\}}" is substituted with the tokens $\texttt{t}_1, \dots, \texttt{t}_n$. We suppose that the denoising U-net is parametrized with a set of parameters $\theta$, and operates in the extended conditioning space, as described above. The reconstruction objective for the embeddings $e_1, \dots, e_n$ associated with the tokens $\texttt{t}_1, \dots, \texttt{t}_n$ is then defined as
Assuming that the denoising U-net is parameterized by a set of parameters denoted by $\theta$, and operates within the extended conditioning space as previously described, we define the reconstruction objective for the embeddings $e_1, \dots, e_n$ that correspond to the tokens $\texttt{t}_1, \dots, \texttt{t}_n$ as follows:

\[ \mathcal{L}_{\mathrm{XTI}} = \mathop{\mathbb{E}}_{\begin{subarray} _P\sim \Pi,\ I \sim \mathcal{I},\\ \varepsilon \sim \mathcal{N}(0, 1),\ t\end{subarray}} \|\varepsilon - \varepsilon_\theta(I_t | t, P(\texttt{t}_1, \dots, \texttt{t}_n))\|_2^2 \]
where $I_t$ is the image $I$ noised with the additive noise $\varepsilon$ according to the noise level $t$. Once we operate with a latent diffusion model, we always suppose that $I$ is a latent image representation. The new look-up table embeddings $e_1, \dots, e_n$ that correspond to $\texttt{t}_1, \dots, \texttt{t}_n$ are optimized w.r.t. $\mathcal{L}_\mathrm{XTI}$.
This optimization is applied independently to each cross-attention layer.
% \dc{Why do we need to make this last claim here?}

% \subsection{Inversion Regularization}
% \kac{Add motivation - TI token grabs high attention, and it overrides other words in the sentence / ``composabiltiy". Then we propose a solution that doesn't work in TI but works in XTI. Provide a good explanation about why it doesn't work with TI - in TI it's editable but it comes on the reconstruction quality, unlike XTI.}
% We found out that in the original textual inversion algorithm, the objective always leads the optimized token embedding to be out of the original tokenizer token embeddings. In particular, this commonly leads to quality degradation, once an image is synthesized with the optimized inversion token in a complex sentence. It is common that the optimized token takes too much attention and as the result, the synthesized image lacks some of details provided in a prompt (see Fig.\ref{fig:TODO}). For further exploration of this effect, we perform the kernel-based density estimation (KDE) in the look-up table tokens embeddings space. Let us define $\mathcal{E}$ to be the set of all original tokens look-up table embeddings, before adding the extra optimized token. In assumption that $\mathcal{E}$ is sampled from some continuous distribution, one can define the approximation of its density function at a point $x$ as:

% \begin{equation}
% \log p_{\mathcal{E}}(x) \approx \frac{1}{|\mathcal{E}|} \sum_{e \in \mathcal{E}} K(x - e), \label{eq:kde}    
% \end{equation}
% where $K$ is the Gaussian kernel density function (see e.g., \cite{TODO}). As for the embeddings optimized with the original textual inversion algorithm, this quantity always appears to be significantly smaller compared to the densities at the original embeddings $\mathcal{E}$. Fig. \ref{fig:TODO} illustrates the original tokens density distribution, and the textual inversion tokens densities. Once being optimized with the density $\log p_\mathcal{E}$ maximization penalty, original textual inversion notably suffers from the inversion quality degradation. In particular, even with a small scale this regularization induces significant inversion simplification, as shown in Fig.\ref{TODO}. Surprisingly, the opposite happens for the proposed XTI: in that case the regularization notably improves the alignment of images synthesized with the inverted tokens with complex textual descriptions, while not harming the inversion quality. This regularization enforces the added tokens embeddings to stay on the "natural" tokens embeddings manifold. Thus, our final XTI objective takes the form
% \begin{equation}
% \mathcal{L}_{\mathrm{XTI}} = \mathcal{L}_\mathrm{TI} - \lambda \cdot \sum_{i=1}^l \log p_{\mathcal{E}}(e_i)
% \end{equation}
% where $\lambda$ is the regularization strength.