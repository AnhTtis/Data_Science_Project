\section{Conclusions, Limitations, and Future work}

We have presented, $\PromptP$, an extended conditional space, which provides 
% \dc{larger}
\cq{increased} expressivity and control.
We have analyzed this space and showed that the denoising U-net demonstrates  disentanglement, where different layers exhibit different sensitivity to \cq{shape or appearance} attributes
% ., which are more related to shape or appearance. 

The competence of $\PromptP$ is 
% manifested 
\cq{demonstrated} in the Textual Inversion problem. Our Extended Textual Inversion (XTI) is shown to be more accurate, more expressive, more controllable, and significantly faster. Yet surprisingly, we have not observed any reduction in editability.

The performance of XTI, although impressive, is not flawless. Firstly, it does not perfectly reconstruct the concept in the image, and in that respect, it is still inferior to the reconstruction that can be achieved by fine-tuning the model. Secondly, although XTI is significantly faster than TI, it is a rather slow process. Lastly, the disentanglement among the layers of U-net is not perfect, limiting the degree of control that can be achieved through prompt mixing.

An interesting research avenue is to develop encoders to invert one or a few images into $\PromptP$, possibly in the spirit of \cite{gal2023designing}, or to study the impact of applying fine-tuning in conjunction of operating in $\PromptP$. 

\section{Acknowledgement}
We thank Eric Tabellion, Rinon Gal, Miki Rubinstein, Matan Cohen and Jason Baldridge and Yael Pritch for their valuable inputs that helped improve this work.