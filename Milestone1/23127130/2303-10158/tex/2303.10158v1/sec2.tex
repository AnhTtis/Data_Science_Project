\section{Background of Data-centric AI}
\label{sec:2}

This section provides a background of data-centric AI. Section~\ref{sec:2:1} defines the relevant concepts. Section~\ref{sec:2:2} discusses why data-centric AI is needed. Section~\ref{sec:2:3} draws a big picture of the related tasks and presents a goal-driven taxonomy to organize the existing literature. Section~\ref{sec:2:4} focuses on automation and human participation in data-centric AI.

\subsection{Definitions}
\label{sec:2:1}

Researchers have described data-centric AI in different ways. Ng et al. defined it as ``the discipline of systematically engineering the data used to build an AI system''~\cite{datacentricaihub}. Polyzotis and Zaharia described it as ``an exciting new research field that studies the problem of constructing high-quality datasets for machine learning''~\cite{polyzotis2021can}. Jarrahi et al. mentioned that data-centric AI ``advocates for a systematic and iterative approach to dealing with data issues''~\cite{jarrahi2022principles}. Miranda noted that data-centric AI focuses on the problems that ``do not only involve the type of model to use, but also the quality of data at hand''~\cite{miranda2021towards}. While all these descriptions have emphasized the importance of data, the scope of data-centric AI remains ambiguous, i.e., what tasks and techniques belong to data-centric AI. Such ambiguity could prevent us from grasping a concrete picture of this field. Before starting the survey, it is essential to define some relevant concepts:

\begin{itemize}
    \item \textbf{Artificial Intelligence (AI)}: AI is a broad and interdisciplinary field that tries to enable computers to have human intelligence to solve complex tasks~\cite{winston1984artificial}. A dominant technique for AI is machine learning, which leverages data to train predictive models to accomplish some tasks.
    \item \textbf{Data}: Data is a very general concept to describe a collection of values that convey information. In the context of AI, data is used to train machine learning models or serve as the model input to make predictions. Data can appear in various formats, such as tabular data, images, texts, audio, and video.
    \item \textbf{Training Data}: Training data is the data used in the training phase of machine learning models. The model leverages training data to adjust its parameters and make predictions.
    \item \textbf{Inference Data}: Inference data is the data used in the inference phase of machine learning models. On the one hand, it can evaluate the performance of the model after it has been trained. On the other hand, tuning the inference data can help obtain the desirable outputs, such as tuning prompts for language models~\cite{liu2023pre}.
    % It is used to measure the performance of the model after it has been trained. The evaluation data often does not overlap with the training data, so it can assess how well the model generalizes to unseen scenarios~\cite{reitermanova2010data}.
    \item \textbf{Data Maintenance}: Data maintenance refers to the process of maintaining the quality and reliability of data, which often involves efficient algorithms, tools, and infrastructures to understand and debug data. Data maintenance plays a crucial role in AI since it ensures training and inference data are accurate and consistent~\cite{jain2020overview}.
    \item \textbf{Data-centric AI}: Data-centric AI refers to a framework to develop, iterate, and maintain data for AI systems~\cite{zha2023data}. Data-centric AI involves the tasks and methods for building effective training data, designing proper inference data, and maintaining the data.
\end{itemize}


\subsection{Need for Data-centric AI} 
\label{sec:2:2}

In the past, AI was often viewed as a model-centric field, where the focus was on advancing model designs given fixed datasets.
%The research and development in the model-centric paradigm were largely driven by benchmark datasets, such as ImageNet~\cite{deng2009imagenet}, SQuAD~\cite{rajpurkar2016squad}, and Switchboard~\cite{bollacker2008freebase}.
%and Freebase~\cite{godfrey1992switchboard}.
However, the overwhelming reliance on fixed datasets does not necessarily lead to better model behavior in real-world applications, as it overlooks the breadth, difficulty, and fidelity of data to the underlying problem~\cite{mazumder2022dataperf}. Moreover, the models are often difficult to transfer from one problem to another since they are highly specialized and tailored to specific problems. Furthermore, undervaluing data quality could trigger data cascades~\cite{sambasivan2021everyone}, causing negative effects such as decreased accuracy and persistent biases~\cite{buolamwini2018gender}. This can severely hinder the applicability of AI systems, particularly in high-stakes domains.
 
Consequently, the attention of researchers and practitioners has gradually shifted toward data-centric AI to pursue data excellence~\cite{aroyo2022data}. 
% In contrast to model-centric AI, which merely focuses on iterating the model to improve performance using unchanged datasets,
Data-centric AI places a greater emphasis on enhancing the quality and quantity of the data with the model relatively more fixed. While this transition is still ongoing, we have already witnessed several accomplishments that shed light on its benefits. For example, the advancement of large language models is greatly dependent on the use of huge datasets~\cite{kenton2019bert,radford2018improving,radford2019language,brown2020language}. Compared to GPT-2~\cite{radford2019language}, GPT-3~\cite{brown2020language} only made minor modifications in the neural architecture while spending efforts collecting a significantly larger high-quality dataset for training. ChatGPT~\cite{ouyang2022training}, a remarkably successful application of GPT-3, adopts a similar neural architecture as GPT-3 and uses a reinforcement learning from human feedback procedure~\cite{christiano2017deep} to generate high-quality labeled data for fine-tuning. A new approach, known as prompt engineering~\cite{liu2023pre}, has seen significant success by focusing solely on tuning data inputs. The benefits of data-centric approaches can also be validated by practitioners~\cite{landingai,snorkelai,scaleai}. For instance, Landing AI, a computer vision company, observes improved accuracy, reduced development time, and more consistent and scalable methods from the adoption of data-centric approaches~\cite{landingai}. All these achievements demonstrate the promise of data-centric AI.

% Additionally, data-centric AI requires an in-depth understanding of the target problem domain and underlying data. Domain-specific data work, as an integral component in DCAI, is supplemented by model-centric techniques for the development of AI-based systems. Despite these essential differences between data-centric and model-centric AI,  the two paradigms are inherently complementary toward effective and efficient AI-based systems development.



% However, higher model performance on predefined and unchanged datasets does not necessarily means better model behavior. Moreover, the models are often difficult to transfer from one problem to another, as they are highly specialized and tailored to specific problems. 

%\dc{[Data-centric vs. Model-centric AI, extend the BlueSky track paper]}

%In previous years, model-centric AI (e.g., model structure design or advanced training strategy) has attracted much attention from academic research and industry.

%However, the maturity of model-centric AI leading to higher model performance in ``predefined" and unchanged test dataset does not necessarily results in better model behavior in practice.

%To overcome the susceptibility of data, the focus of researchers and practitioners gradually shifted toward data-centric AI emphasizing the role of data development and maintenance toward building effective and efficient AI-based systems.

% Data-centric AI differs from model-centric AI in terms of the main focus and data quality understanding. Specifically, data-centric AI generally holds the model fixed while optimizing data. Performance improvement is achieved by improving the quality and quantity of the data. Additionally, data-centric AI requires an in-depth understanding of the target problem domain and underlying data. Domain-specific data work, as an integral component in DCAI, is supplemented by model-centric techniques for the development of AI-based systems. Despite these essential differences between data-centric and model-centric AI,  the two paradigms are inherently complementary toward effective and efficient AI-based systems development.

% \dc{[Evidence showing that data-centric AI is the right direction. Citations]}

%Machine learning (ML) research facilitates massive progress in ML model architectures given a dataset that serves as benchmark to evaluate models. For example, large public datasets, such as ImageNet~\cite{deng2009imagenet}, SQuAD~\cite{rajpurkar2016squad}, Switchboard~\cite{bollacker2008freebase} and Freebase~\cite{godfrey1992switchboard}, compass ML research and facilitate model-centric AI developments. However, the overwhelming focus of benchmarking model performance in fixed large public datasets does not necessarily lead to better model behavior in real-world applications due to neglecting the breadth, difficulty, and fidelity of data to the underlying problem~\cite{mazumder2022dataperf}.

% With the plateaued development of model-centric AL development, data cascades problem in the real world has become evident and a key bottleneck for AI-based system development. Therefore, pursuing better data quality and data excellence ~\cite{aroyo2022data} are increasingly necessary and important. For example, as the model trained offline enter to wild, performance discrepancies, such as accuracy degradation and persistent bias issue~\cite{buolamwini2018gender,mehrabi2021survey,denton2020bringing}, usually appear in many applications. Such deployment discrepancy impedes the applicability of AI-based systems, such as health~\cite{wilkinson2020time} and data reuse~\cite{koch2021reduced}, where problems often resulting not from the model but the data that trained the models.

It is noteworthy that data-centric AI does not diminish the value of model-centric AI. Instead, these two paradigms are complementarily interwoven in building AI systems. On the one hand, model-centric methods can be used to achieve data-centric AI goals. For example, we can utilize a generation model, such as GAN~\cite{goodfellow2020generative,zhang2019self} and diffusion model~\cite{ho2020denoising,kingma2021variational,rombach2022high}, to perform data augmentation and generate more high-quality data. On the other hand, data-centric AI could facilitate the improvement of model-centric AI objectives. For instance, the increased availability of augmented data could inspire further advancements in model design. Therefore, in production scenarios, data and models tend to evolve alternatively in a constantly changing environment~\cite{polyzotis2021can}.



% \dc{[How to position data-centric AI?] Data-centric AI does not imply a negation of model-centric AI. Both are important. In practice, model-centric methods can be used to achieve data-centric AI goals. For example, we use GAN to do data augmentation, which uses a model for data-centric AI.}

%Domain-specific data work, as an integral component in DCAI, is supplemented by model-centric techniques for the development of AI-based systems. Despite these essential differences between data-centric and model-centric AI,  the two paradigms are inherently complementary toward effective and efficient AI-based systems development. The data-centric paradigm emerges from the ML community. The role of data-centric AI does not imply a negation of model-centric AI. Instead, data-centric and model-centric AI are indispensable and complementary to building effective AI-based systems. In practice, model-centric methods can be used to achieve data-centric AI goals. For example, we can adopt a generation model (e.g., GAN~\cite{goodfellow2020generative,zhang2019self} and diffusion model~\cite{ho2020denoising,kingma2021variational}) to conduct data augmentation. Therefore, more valuable samples are generated by model-centric AI for data-centric AI.  Similarly, data-centric AI can also facilitate the improvement of model-centric AI. For example, feature selection~\cite{li2017feature} and feature engineering~\cite{zheng2018feature,nargesian2017learning} are widely adopted to further advance model-centric AI performance in the industry. Many research discussions around data-centric or model-centric AI focus on how to generate high-quality data (e.g., diverse image collection~\cite{birnbaum2004human}, class definition, annotation strategy selection~\cite{wang2009multi,chong2009simultaneous}) or high-performance models (e.g, model structure design~\cite{he2016deep,ren2015faster}, loss function design~\cite{lin2017focal}) for specific ML problems once. However, for most production applications, data-centric and model-centric AI are usually alternatively evolved with each other. In other words, the datasets and models need to be updated alternatively and continuously. The key reason is that the environment that AI-based systems serve is inherently dynamic leading to dynamic gathered data. Additionally, the target problem definitions (e.g., identifying more diseases~\cite{stenton2020genetics}) can also change depending on customer demand or stakeholder stratagem.

\begin{figure}[t]
  \centering
    \includegraphics[width=0.85\textwidth]{figures/taxonomy.pdf}
  \caption{Data-centric AI framework.}
  \label{fig:taxonomy}
\end{figure}

\subsection{Tasks in Data-centric AI} 
\label{sec:2:3}



The ambitious movement to data-centric AI can not be achieved without making progress on concrete and specific tasks. Unfortunately, most of the existing literature has been focused on discussing the foundations and perspectives of data-centric AI without clearly specifying the associated tasks~\cite{polyzotis2021can,jarrahi2022principles,jakubik2022data,seedat2022dc}. As an effort to resolve this ambiguity, the recently proposed DataPerf benchmark~\cite{mazumder2022dataperf} has defined six data-centric AI tasks: training set creation, test set creation, selection algorithm, debugging algorithm, slicing algorithm, and valuation algorithm. However, this flat taxonomy can only partially cover the existing data-centric AI literature. For example, some crucial tasks such as data labeling~\cite{zhang2022survey} are not included. The selection algorithm only addresses instance selection but not feature selection~\cite{li2017feature}. The test set creation is restricted to selecting items from a supplemental set rather than generating a new set~\cite{saporta2002data}. Thus, a more nuanced taxonomy is necessary to fully encompass data-centric AI literature.

To gain a more comprehensive understanding of data-centric AI, we draw a big picture of the related tasks and present a goal-driven taxonomy to organize the existing literature in Figure~\ref{fig:taxonomy}. We divide data-centric AI into three goals: training data development, inference data development, and data maintenance, where each goal is associated with several sub-goals, and each task belongs to a sug-goal. We give a high-level overview of these goals below.




%Data-centric AI is a class of systematic techniques that develop, iterate, and maintain data for AI systems. ML community has continuously developed techniques to enhance data in many aspects. For example, active learning has been developed for decades to improve data label quality and efficiency~\cite{settles2009active}. Feature selection~\cite{li2017feature} aims to generate cleaner and more understandable data. Despite these individual initiatives for data, a comprehensive and systematic view of DCAI is still missing. In this paper, we provide a big picture of DCAI in Figure~\ref{fig:overview}, including training data development, evaluation data development, and data maintenance.

%The goal of DCAI is to establish up-to-date data benchmarks for model training and evaluation in the wild, which is beyond the role of training data construction. The reason behind the goal is two-fold. First, it is equally or even more crucial to build a trustful evaluation set for the purpose of model evaluation. Second, data is never created at once but rather in continuous maintenance in industrial applications. Therefore, it is essential to develop an infrastructure (e.g., efficient algorithms, and tools) to organize, store, understand, and debug data. We also provide a brief overview of these three key components, i.e., training data development, evaluation data development, and data maintenance, as follows.
\begin{itemize}
    \item \textbf{Training data development}: The goal of training data development is to collect and produce rich and high-quality training data to support the training of machine learning models. It consists of five sub-goals, including 1) data collection for gathering raw training data, 2) data labeling for adding informative labels, 3) data preparation for cleaning and transforming data, 4) data reduction for decreasing data size with potentially improved performance, and 5) data augmentation for enhancing data diversity without collecting more data.

    \item \textbf{Inference data development}: The objective is to create novel evaluation sets that can provide more granular insights into the model or trigger a specific capability of the model with engineered data inputs.
    %beyond relying solely on performance metrics (e.g., accuracy)
    There are three sub-goals in this effort: 1) in-distribution evaluation and 2) out-of-distribution evaluation aim to generate samples that adhere to or differ from the training data distribution, respectively, while 3) prompt enginerring tunes the prompt in language models to get the desired predictions. The tasks in inference data development are relatively open-ended since they are often designed to assess or unlock various capabilities of the model.
    % various aspects of the model, such as transferability, robustness, etc.
    
    % model-centric paradigm usually relies on some metrics (e.g., accuracy) calculated based on validation or test datasets. However, such evaluation sets do not necessarily reflect the actual model performance in the wild.  


    \item \textbf{Data maintenance}: In real-world applications, data is not created once but rather necessitates continuous maintenance. The purpose of data maintenance is to ensure the quality and reliability of data in a dynamic environment. It involves three essential sub-goals: 1) data understanding, which targets providing visualization and valuation of the complex data, enabling humans to gain valuable insights, 2) data quality assurance, which develops quantitative measurements and quality improvement strategies to monitor and repair data, and 3) data acceleration, which aims to devise efficient algorithms to supply the data in need via properly allocating resources and efficiently processing queries. Data maintenance plays a fundamental and supportive role in the data-centric AI framework, ensuring that the data in training and inference is accurate and reliable.
\end{itemize}

Following the three general goals, we survey various data-centric AI tasks, summarized in Table~\ref{tbl:tasksummary}.



\begin{table}[t]
\centering
\caption{Representative tasks under the data-centric AI framework.}
\footnotesize	
\label{tbl:tasksummary}
\setlength{\tabcolsep}{0.2pt}
\begin{tabular}{l|l|l} \toprule
\textbf{Goal} & \textbf{Sub-goal} & \textbf{Tasks} \\
\midrule

\multirow{6}{*}{\shortstack[l]{Training data\\ development}} & \cellcolor{gray!10}Collection & \cellcolor{gray!10}Dataset discovery~\cite{bogatu2020dataset}, data integration~\cite{stonebraker2018data}, raw data synthesis~\cite{lai2021revisiting}\\


~ & ~ & Crowdsourced labeling~\cite{kutlu2020annotator}, semi-supervised labeling~\cite{zoph2020rethinking}, active learning~\cite{ren2021survey}, \\

~ & \multirow{-2}{*}{Labeling} & data programming~\cite{ratner2016data}, distant supervision~\cite{mintz2009distant} \\

~ & \cellcolor{gray!10}Preparation & \cellcolor{gray!10}Data cleaning~\cite{zhang2016missing}, feature extraction~\cite{salau2019feature}, feature transformation~\cite{ali2014data}  \\

~ & Reduction & Feature selection~\cite{li2017feature}, dimensinality reduction~\cite{abdi2010principal}, instance selection~\cite{riquelme2003finding} \\

~ & \cellcolor{gray!10}Augmentation &  \cellcolor{gray!10}Basic manipulation~\cite{zhang2018mixup}, augmentation data synthesis~\cite{frid2018synthetic}, upsampling~\cite{zha2022towards}\\

\midrule

\multirow{3}{*}{\shortstack[l]{Inference data\\ development}} & In-distribution & Data slicing~\cite{chung2019slice}, algorithmic recourse~\cite{karimi2021algorithmic}\\
~ & \cellcolor{gray!10}Out-of-distribution & \cellcolor{gray!10}Generating adversarial samples~\cite{moosavi2016deepfool}, generating samples with distribution shift~\cite{koh2021wilds}\\
~ & Prompt engineering & Manual prompt engineering~\cite{schick2020few}, automated prompt engineering~\cite{wallace2019universal} \\

\midrule

\multirow{4}{*}{\shortstack[l]{Data\\ maintenance}} & \cellcolor{gray!10}~ & \cellcolor{gray!10}Visual summarization~\cite{burch2014benefits}, clustering for visualization~\cite{fahad2014survey}, \\
~ & \cellcolor{gray!10}\multirow{-2}{*}{Understanding} & \cellcolor{gray!10}visualization recommendation~\cite{wongsuphasawat2015voyager}, valuation~\cite{ghorbani2020distributional} \\
~ & Quality assurance & Quality assessment~\cite{sadiq2018data}, quality improvement~\cite{baylor2017tfx}\\
~ & \cellcolor{gray!10}Storage \& retrieval & \cellcolor{gray!10}Resource allocation~\cite{herodotou2011starfish}, query index selection~\cite{sun2019end}, query rewriting~\cite{baik2019bridging} \\

\bottomrule
\end{tabular}
\end{table}

\subsection{Automation and Human Participation in Data-centric AI} 

\label{sec:2:4}

% \dc{TODO: Add some discussion about why we need automation (because of the data size is too large)}

Data-centric AI consists of a spectrum of tasks related to different data lifecycle stages. To keep pace with the ever-growing size of the available data, in some data-centric AI tasks, it is imperative to develop automated algorithms to streamline the process. For example, there is an increasing interest in automation in data augmentation~\cite{cubuk2019autoaugment,zha2022towards}, and feature transformation~\cite{khurana2018feature}. Automation in these tasks will improve not only efficiency but also accuracy~\cite{mazumder2022dataperf}. Moreover, automation can facilitate the consistency of the results, reducing the chance of human errors. Whereas for some other tasks, human involvement is essential to ensure the data is consistent with our intentions. For example, humans often play an indispensable role in labeling data~\cite{zhang2022survey}, which helps machine learning algorithms learn to make the desired predictions. Whether human participation is needed depends on whether our objective is to align data with human expectations. In this survey, we categorize each paper into \emph{automation} and \emph{collaboration}, where the former focuses on automating the process, and the latter concerns human participation. Automation-oriented methods usually have different automation objectives. We can identify several levels of automation from the existing methods:

% In some tasks and the associated methods, human involvement is essential to ensure the data is consistent with our intentions. For example, humans play an indispensable role in labeling data~\cite{zhang2022survey}, which helps machine learning algorithms learn to make the desired predictions. Whereas for some other tasks, such as feature selection~\cite{li2017feature}, there is an increasing interest in automation to deal with a large amount of data more effectively and efficiently~\cite{liu2021automated}. Whether human participation is needed depends on whether our objective is to align data with human expectations, which is often determined by the nature of the tasks. In this survey, we categorize each task into \emph{automation} and \emph{collaboration} based on its objective, where the former focuses on automating the process, and the latter concerns human participation.



\begin{itemize}
    % \item \textbf{No automation:} Manually generating, processing, or debugging data based on domain knowledge from scratch.
    \item \textbf{Programmatic automation:} Using programs to deal with the data automatically. The programs are often designed based on some heuristics and statistical information.
    \item \textbf{Learning-based automation:} Learning automation strategies with optimization, e.g., minimizing an objective function. The methods at this level are often more flexible and adaptive but require additional costs for learning.
    %For example, AutoAugemnt or using GAN for data augmentation.
    \item \textbf{Pipeline automation:} Integrating and tuning a series of strategies across multiple tasks, which could help identify globally optimal strategies. However, tuning may incur significantly more costs.
\end{itemize}


% \dc{For some tasks, human participation is expected (e.g., ``labeling"), which leads to \emph{collaboration} between humans and machines. Some other tasks can be achieved without human involvement, which leads to \emph{automation}.}

% We defined different levels of collaboration as follows:

% \dc{Human participation depends on the nature of how the problem is formulated rather than methods that tackle the problems. For example, ``active XXX" or ``interactive XXX" often suggests that the problem must have human participation, no matter what methods we use.}

%We categorize the role of humans in a task as follows.


%\begin{itemize}
%    \item \textbf{No participation:} Humans do not participate in the task. The algorithms can accomplish tasks based on the data or resources without humans. For example, data augmentation.
%    \item \textbf{Partial participation:} Humans partially participate in the task. 
%    \item \textbf{Full participation:} Human involvement is required. Humans often need to supply information to achieve the goal. For example, data labeling and some tasks in data collection.
    
%\end{itemize}


% \dc{Automation is defined based on techniques but not problems. An active learning algorithm can also be very automated, even if it requires human involvement. For example, we can do meta-learning for active learning}

Note that this categorization does not intend to differentiate good and bad methods. For example, a pipeline automation method may not necessarily be better than programmatic automation solutions since it could be over-complicated in many scenarios. Instead, we aim to show insight into how automation has been applied to different data-centric goals and understand the literature from a global view. From another perspective, collaboration-oriented methods often require human participation in different forms. We can identify several degrees of human participation:



\begin{figure}[t]
  \centering
    \includegraphics[width=0.85\textwidth]{figures/survey_strategy.pdf}
  \caption{Data-centric AI papers are categorized into automation and collaboration depending on whether human participation is needed. Each method has a different level of automation or requires a different degree of human participation.}
  \label{fig:surveystrategy}
\end{figure}

\begin{itemize}
    % \item \textbf{Naive collaboration:} Manually generating, processing, or debugging data based on domain knowledge from scratch.
    \item \textbf{Full participation:} Humans fully control the process. The method assists humans in making decisions. The methods that require full participation can often align well with human intentions but can be costly.
    \item \textbf{Partial participation:} The method is in control of the process. However, humans need to intensively or continuously supply information, e.g., by providing a large amount of feedback or frequent interactions.
    \item \textbf{Minimum participation:} The method is in full control of the whole process and only consults humans when needed. Humans only participate when prompted or asked to do so. The methods that belong to this degree are often more desirable when encountering a massive amount of data and a limited budget for human efforts.
\end{itemize}

Similarly, the degree of human participation, to a certain extent, only reflects the tradeoff between efficiency (less human labor) and effectiveness (better aligned with humans). The selection of methods depends on the application domain and stakeholders' needs. To summarize, we design Figure~\ref{fig:surveystrategy} to organize the existing data-centric AI papers. We assign each paper to either a level of automation or a degree of human participation.
% In the following sections, we will review the existing methods and label them based on Figure~\ref{fig:surveystrategy}.


Some previous surveys only focus on specific scopes of data-centric AI, such as data augmentation~\cite{feng2021survey,wen2021time,shorten2019survey}, data labeling~\cite{zhang2022survey}, and feature selection~\cite{li2017feature}. The novelty of our paper is that it provides a holistic view of the tasks, methods, and benchmarks by providing a goal-driven taxonomy to organize the tasks followed by an automation- and collaboration-oriented design to categorize methods. Moreover, we discuss the needs, challenges, and future directions from the broad data-centric AI view, aiming to motivate collective initiatives to push forward this field.

% In the following sections, we will survey the literature under each data-centric AI goal following this structure.




 %\begin{itemize}
 %       \item \textbf{Indirect objectives:} Optimizing a proxy for learning. For example, we use GAN to learn to synthesize samples for data augmentation with GAN's objective, which forces the generated images to be similar to the original ones. However, this objective may not necessarily mean better augmentation performance.
 %       \item \textbf{Direct objectives:} Optimizing the true objective directly. For example, AutoAugment learns a policy to decide which augmentation strategies to use based on the validation performance. We could auto-tune the hyperparameters of GAN to maximize the performance metrics.
 %   \end{itemize}


%\subsection{Human Involvement in Data-centric ML (Remove)} 

%While many automated algorithms have been developed for data-centric ML, human involvement is essential in many scenarios, such as business understanding and data labeling.


