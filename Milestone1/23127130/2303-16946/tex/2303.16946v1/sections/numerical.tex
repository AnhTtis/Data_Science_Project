\section{A Numerical Study}
\label{sec:numerical}

We now present a (non-exhaustive) numerical analysis of the NoRA tensor network using the Clifford stabilizer formalism discussed previously. Our primary focus is the scaling of the (relative) code distance with $N$, and how it differs between having the space of ground states scale with $L$ and having it fixed.

The stabilizer simulation used to generate the following data was written in Python 3.10.4 using Numpy 1.21.6 (linear algebra) \cite{harris2020array} and Galois 0.1.1 (finite field arithmetic) \cite{Hostetter_Galois_2020}, and is based on the projective symplectic representation discussed in appendix \ref{sec:phase_space}. The algorithm used to randomly sample symplectic matrices for Clifford operators is based on \cite{doi:10.1063/1.4903507}, but was generalized to work for any choice of qudit dimension $d$ that is a power of an odd prime. The complete code can be found at
\url{https://github.com/vbettaque/qstab}.

All data in this paper was generated using a 2021 MacBook Pro with M1 Pro processor and 16 GB RAM. If the computation involved random sampling, an average of 1000 samples is displayed together with the error on the mean\footnote{Note that occasionally the error on the mean is so small that it is not visible in the figures.}. In general we also chose a qudit dimension of $d=3$, a growth rate of $r=2$ per layer, and a (naive) layer circuit growth rate of $q=2$.

\subsection{Fixing the Ground Space}
\label{sec:gs_fixed}

We begin our analysis with the case where the size of the ground space is fixed. The other case, where the size of the ground space grows with $L$, more closely resembles SYK, but the fixed size case is also interesting as a starting point and for the codes it produces. In such cases, the rate $k/N$ of the code approaches zero exponentially fast with the total layer number. However, the complexity still increases exponentially in $L$ according to
\begin{equation}
    \text{total gates} = \frac{D}{q} \frac{r}{r-1} \cdot N + \mathcal{O}(\log N),
\end{equation}
suggesting that distances scaling with $N$ should be achievable. The vanishing rate is also not inherently problematic as this is also the case for other popular error-correcting codes like the $[[2A^2, 2, A]]$ toric code \cite{Kitaev_2003}.

For most of our analysis we set the ground space dimension to be $k=2$, unless stated otherwise. The number of layers is also in general fixed to be $L=7$ (or less).

\subsubsection{Code Distance}
\label{sec:fixed_distance}

The first part of our analysis deals with determining how the average code distance depends on the layer-circuit depth $D$. This is of interest to us since for error correction we want to choose $D$ to be as small as possible while still having $\delta$ as large as possible on average. Looking at figure \ref{fig:d_against_D}, this seems to be the case for $D_{\min} = 3,4,5$, depending on the tolerated margin of error between $\delta$ and $\delta_{\max}$.

\begin{figure}[htb]
    \centering
    \includegraphics[width=.8\textwidth]{figures/d_against_D.png}
    \caption{The average code distance $\delta$ with regard to the circuit depth $D$ of the NoRA network with fixed ground space and default parameters. Due to the approximately exponential trend of the data, the average distance is already close to its saturated maximum of $\delta_{\max} = 64.43 \pm 0.09$ if the layer circuits have a depth of $D=3$. Larger depths therefore provide little to no improvement. However, the maximum average distance is still several standard deviations less than the theoretical maximum provided by the quantum singleton bound $\delta_{\text{qsb}}$, though we expect them to be somewhat closer (but not necessarily equal) at large $D$ and $L$.}
    \label{fig:d_against_D}
\end{figure}

In general one could assume that $D_{\min}$ depends on $L$ as well as all other parameters. However, using statements from section \ref{sec:code_structure} and appendix \ref{sec:growth_factor} we can argue that $D_{\min}$ is largely independent of $L$ and should only strongly depend on $d$, $q$ and $r$. For that we remind ourselves that the weight of an operator increases on average by a factor of $g^{D_{\min}}$ (where $g \approx q \cdot (d^2 - 1)/d^2$ only depends strongly on $d$ and $q$) when subjected to a single random circuit layer. But since we have  $n_{\ell+1}/n_{\ell} = (k + r^{\ell+1})/(k + r^{\ell}) \approx r$ for $k$ and $\ell$ such that $r^{\ell} \gg k$, the system increases by a roughly constant factor at each layer. Given that we start with a Pauli string with close to maximum weight i.e.\ $w_{\ell} \approx n_{\ell}$, then for the subsequent string to have maximum weight we require that $w_{\ell+1} \approx n_{\ell + 1} \approx g^{D_{\min}} \cdot n_{\ell}$ and hence
\begin{equation}
    D_{\min} \approx \log_g(r), 
\end{equation}
which does not depend strongly on $L$. Additional numerical evidence for this heuristic is provided by figure \ref{fig:syk_weight_diff} in section \ref{sec:weight_results}.

Figure \ref{fig:d_against_D} shows that the tensor network can (on average) achieve distances that are quite close to the theoretical maximum:
\begin{equation}
    \delta_{\text{qsb}} = \frac{N - k}{2} + 1 = \frac{N}{2} = 2^{L-1} + 1.
\end{equation}
This maximum is assumed if the quantum singleton bound $N - k \geq 2 (\delta-1)$ is saturated. To reach it (or at least come close to it) requires states with volume law entanglement, thus verifying our previous expectations. It would be interesting to understand how close the average code distance comes to $\delta_{\text{qsb}}$ as a function of $L$ and $D$. However the computing time scales exponentially with $N$ and therefore double-exponentially with $L$, making it more difficult to gather data for larger system sizes. But for now our results do indeed suggest a possible approximate distance saturation with more layers, as shown in figure \ref{fig:dn_n_inv} for one specific example\footnote{Note that $\delta_{\text{qsb}}/N$ is not necessarily independent of $N$. This is only the case here because we chose $k=2$. An example for a $N$-dependent relative distance is given in the next section.}. We say approximate because for reasonable choices of $D$ we expect the system to reach a steady state after a certain number of layers, meaning that for subsequent layers the scrambling rate of the layer circuit and the rate of new thermal qudits form an equilibrium and thus keep the relative distance constant. Depending on the choice of parameters, this equilibrium does not necessarily have to coincide with $\delta_{\text{qsb}}/N$. However, we expect this to be the case for unreasonably large scrambling rates $g^D \gg r$ due to the network then being effectively reduced to a single volume circuit.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth]{figures/dn_n_inv.png}
    \caption{Average relative code distance $\delta/N$ with regard to the system size $N$ and its inverse $1/N$, with $D = 4$. Even though the depicted data trends are only approximate, they do suggest approximate convergence of the relative distance towards the (relative) quantum singleton bound $\delta_{\text{qsb}}/N = 0.5$ for larger $N$.}.
    \label{fig:dn_n_inv}
\end{figure}

Finally we consider how the code distance $\delta$ scales when the number of logical qudits $k$ is increased while keeping the number of layers $L$ fixed. Doing so provides another heuristic as to whether the tensor network exhibits volume-law entanglement or not, since we expect a linear decrease of the entanglement entropy and therefore distance with increasing $k$ in that case. As shown in figure \ref{fig:d_against_k} this seems to be indeed the case on average and for our choice of parameters.

\begin{figure}[htb]
    \centering
    \includegraphics[width=.8\textwidth]{figures/d_against_k.png}
    \caption{Change of the code distance with regard to increasing ground space size $k$, and keeping the number of layers fixed to be $L = 6$ with circuit depth $D = 3$. The approximately linear decrease of the distance is indicative of the tensor network being able to create volume-law entanglement. }.
    \label{fig:d_against_k}
\end{figure}

\subsubsection{Stabilizer Weights}
\label{sec:weight_results}

Besides the average code distance of our tensor network ansatz, it is also interesting to consider the weight distribution of the (naive)stabilizer basis describing the code. For the purpose of performing error correction, having a low-weight code (meaning a code with a low weight generating set for the stabilizer group) is desirable since it means the syndrome can be obtained by measuring low-weight operators. If many of the stabilizers are high weight, it might be infeasible to measure the entire syndrome before too many errors accumulate. Moreover, the commuting projector Hamiltonian whose ground space coincides with the code space is only local (few-body) if the code is low-weight.

To analyze the whole stabilizer basis, we first consider how the tensor network affects the weight of a single Pauli string with unit weight. The non-identity operator is here at the beginning of the string, which means that it is acted on non-trivially by all layers of the circuit. The resulting averaged weight evolution is depicted for different choices of $D$ in figure \ref{fig:syk_weight_diff} in terms of its relative difference to the expected maximum weight which is given at each layer $\ell$ by
\begin{equation}
    w_{\ell}^{\max} = \frac{d^2 - 1}{d^2} \cdot n_{\ell}.
\end{equation}
What can be seen is that for all choices of $D>1$ the weight differences reach an equilibrium\footnote{We expect this to happen for $D=1$ as well, however at larger $L$ and with a large relative difference compared to the other circuit depths. More on that later in this section.}, barely changing for later layers. The same circuit depth therefore always approximately produces the same relative weight, regardless of the actual number of layers $L$. We already used this argument in section \ref{sec:fixed_distance} to argue that the minimal depth $D$ to achieve a good distance $\delta$ does not depend on $L$ because distance and weight usually have correlating behaviors.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth]{figures/pauli_weight_diff.png}
    \caption{(Logarithmic) relative difference between the actual weights of a single Pauli string and their expected maximum for the tensor network ansatz with a variable number of layers $L$ and depths $D$. Already for a circuit depth of $D=2$ does the relative difference seemingly converge towards a constant value, with larger depths resulting in even faster convergence and smaller differences. This shows that the relative weight (and therefore the ideal circuit depth to maximize the code distance) does only depend strongly on $d$, $q$ and $r$, but not $L$.}
    \label{fig:syk_weight_diff}
\end{figure}

However when considering a complete set of stabilizer states, not all of them are acted on non-trivially immediately since they might correspond to thermal qudits introduced only in later layers. We therefore expect the stabilizer weights to obey a distribution with its dominant peaks around 1 and $w_{\ell}^{\max}$. This is indeed approximately the case as seen from the specific example depicted in figure \ref{fig:stab_weights}. It also shows that with increased circuit depth $D$ more and more basis weights approach saturation, as expected.

Note though that for $D=1$ all stabilizers fail to come anywhere close to maximum weight. This aligns with the predictions that are coming up in section \ref{sec:syk_distance_weight}, where we suggest that some sort of phase transition should occur in the relative stabilizer weight distribution (and hence distance) when going from the regime of $g^D < r$ to $g^D > r$, and considering large $L$. In the former case we expect the average stabilizer weight to be small to negligible compared to the total size, while in the latter case we predict complete weight saturation for all elements. For the specific example in figure \ref{fig:stab_weights} we assumed $g = q \cdot (d^2 - 1)/d^2 = 16/9 < 2$ (as shown in appendix \ref{sec:growth_factor}) and $r = 2$, meaning that we should have $g^D < r$ for $D=1$ and $g^D > r$ for $D>1$. And since the relative weights for $D=1$ are comparatively small, this indicates that this transition does indeed take place. In the future we intend to explore this behavior in more detail by looking at other examples in the parameter space.

Comparing the weight analysis with our results from the previous section we can therefore conclude that the stabilizer bases with the lowest weights and highest distances are achieved when choosing $D=3$ as the layer circuit depth. Choosing $D=1$ could also be beneficial though at a significant cost of distance. Either way, the relative number of high-weight stabilizers is significant, thought we expect there to be potential for further reducing the weights, as will be explained in section \ref{sec:weight_reduction}.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth]{figures/stab_weights.png}
    \caption{Relative stabilizer weight distributions at each layer of the tensor network ansatz with $L=6$ total layers. The green distributions correspond to circuit depth $D=1$, the orange ones to $D=2$ and the blue ones to $D=3$. The dashed lines indicate where the expected maximum weight averages $w_{\ell}^{\max}$ are located for each layer. Note that as expected the distribution corresponding to $D=1$ does converge towards saturation due to the rate $r$ of new qudits being added outweighing the scrambling rate $g^D$ of the circuits at each layer.}
    \label{fig:stab_weights}
\end{figure}

\subsection{Enabling Ground Space Scaling}

To model a situation like SYK where the number of ground state qudits is proportional to the total number of qudits, and where we have a thermodynamic limit where both numbers go to infinity, we want to take $L \sim \log_r k$, although this is not an integer in general. So consider as a simple model the case where $k=r^a$ and $L=a+b$ for two integers $a$ and $b$. Then the total number of qudits is 
\begin{equation}
    N = r^a + r^{a+b},
\end{equation}
and the ratio between ground state qudits and the total number of qudits is therefore
\begin{equation}
    \frac{k}{N} = \frac{1}{1 + r^b},
\end{equation}
which is independent of $a$. The limit $a \rightarrow \infty$ can thus be viewed as a thermodynamic limit in which $N$ and $k$ diverge but with a fixed finite ratio. By varying $b$ we can then adjust the relative number of ground state qudits. 

Many of our previous arguments that assume the number of layers to be fixed therefore apply here as well and will not be repeated. Of primary interest to us is therefore how our code's distance and weight scale with $N = r^a + r^{a+b}$ where $a$ increases and $b$ is fixed. In addition to the previously made choices for $d$, $q$ and $r$, we also assume $D=3$ and $b = 1$ for the following examples.

\subsubsection{Code Distance}

Before considering explicit simulations, we can again use the quantum singleton bound to find an upper bound for the expected relative code distances. This bound turns out to be
\begin{equation}
    \frac{\delta_{\text{qsb}}}{N} = \frac{(N-k)/2 + 1}{N} = \frac{1}{2 \, (1 + r^{-b})} + \frac{1}{N} \stackrel{b=1}{=} \frac{1}{3} + \frac{1}{N},
\end{equation}
which unlike the fixed case is necessarily dependent on $N$, although only weakly at large $N$. For large system sizes the relative distance therefore approaches the fixed value of $1/3$ for $b=1$. Comparing this to numerical approximations of the average distance and its trend as shown (in orange) in figure \ref{fig:d_rel_scaling}, we can see that both trends might coincide in that very limit, or at least come close.  
\begin{figure}[htb]
    \centering
    \includegraphics[width=.8\textwidth]{figures/d_rel_scaling.png}
    \caption{Average relative code distance $\delta/N$ with regard to the inverse system size $1/N$ for the tensor network ansatz with ground space scaling. Both the quantum singleton bound (in grey) and the approximate trend of the generated data (in orange) could coincide in the limit of $N \rightarrow \infty$ ($a \rightarrow \infty$), where we have $\delta / N = 1/3$. However more data is needed to be able to prove this. Overall, better relative distances can only be achieved by increasing $b$ at the cost of reducing the rate. }
    \label{fig:d_rel_scaling}
\end{figure}

\subsubsection{Stabilizer Weights}

As seen in figure \ref{fig:syk_stab_weights} the weight distributions for the SYK-like NoRA model don't differ significantly from the case of a fixed ground space. The only significant difference lies in the origin of the distributions: In the case of a scaling ground space we extracted the weights from circuits with different choices for $a$, while in the fixed case we depicted the weights at each layer of a single circuit. That both cases nevertheless produce similar figures is due to the fact that our tensor network ansatz exhibits self-similarity.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth]{figures/syk_stab_weights.png}
    \caption{Relative stabilizer weight distributions of the tensor network ansatz with scaling ground space and different choices of $a$. The green distributions correspond to circuit depth $D=1$, the orange ones to $D=2$ and the blue ones to $D=3$. These distribution are not dissimilar to what we already encountered in \ref{fig:stab_weights} for the individual layers of a single circuit, highlighting the self-similarity of our ansatz.}
    \label{fig:syk_stab_weights}
\end{figure}

It remains to be shown that this trend occurs for different choices of $g$ and $r$ and continues as expected for larger $a$ and $b$. We are also interested in exploring the phase transition at hand in the limit of large $L$.%, which might give us the opportunity to extract its critical exponent and the corresponding conformal theory. 
Those are things we intend to explore in future work.


\subsection{Summary}

Through extensive numerical simulations, we verified that the stabilizer codes obtained from the random Clifford layers indeed have relative distance approaching a non-zero constant in the thermodynamic limit $N\rightarrow \infty$. This corresponds to distance proportional to $N$ which in turn implies volume law entanglement. The relative distance depends on the model parameters, especially the depth $D$, with the result coming close to the relative singleton bound in both the fixed $k$ case and the $k \propto N$ case as $D$ is increased. We also found a broad distribution of stabilizer weights, with a few high weight stabilizers coming from the near-IR thermal qudits and a larger number of low weight stabilizes coming from the near-UV thermal qudits. Our architecture with random layers is therefor capable of producing a family of codes indexed by $N$ with non-vanishing relative distance and rate at the cost of having some high weight stabilizers (although significantly fewer than in a fully random code).