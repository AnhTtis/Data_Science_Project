\section{Scaling of the Stabilizer Entropy}
\label{sec:entropy_scaling}

\subsection{The Stabilizer Hamiltonian}

Every set of stabilizers fixing a quantum state or a space of quantum states can be expressed as a projective Hamiltonian that has said states as part of its (degenerate) ground space.

Let $N$ be the total number of physical qudits and $k \leq N$ the number of logical qudits needed to represent the code word $\ket{\psi}_{\text{code}}$. The case of $N = k$ is not interesting to us so we assume we have $N - k > 0$ ancillary qudits. Every quantum code can then be written as a unitary $U$ satisfying
\begin{equation}
    \ket{\Psi} = U \left( \ket{\psi}_{\text{code}} \otimes \ket{0}_{\text{anc}}^{\otimes \, (N - k)} \right),
\end{equation}
where $\ket{\Psi}$ is the code word encoded in the space of physical qudits. The ancillary thermal qudits can each be fixed to be $\ket{0}$ without loss of generality.

Before applying the encoding unitary, it is easy to see that the generating set of stabilizers fixing the code space spanned by all possible choices of $\ket{\psi}_{\text{code}} \otimes \ket{0}_{\text{anc}}^{\otimes \, (N-k)}$ is given by
\begin{equation}
\label{eq:pre_code_stab}
    Z_i \equiv I_{\text{code}} \otimes I^{\otimes \, (i-1)} \otimes Z \otimes  I^{\otimes \, (N-k-i)}, \quad i = 1,\ldots,N-k, 
\end{equation}
where the $Z$ acts on the $i$th qudit of the ancillary system. From this it immediately follows that the stabilizers acting on the physical qudits can be retrieved by applying the code unitary such that
\begin{equation}
    \widetilde{Z}_i = U \, Z_i \, U^{\dagger}.
\end{equation}

To construct the stabilizer Hamiltonian though, we have to use the (disjoint) projectors associated to our chosen stabilizer basis. Analogously to the previous case, before encoding the state they are
\begin{equation}
\label{eq:pre_code_proj}
    P_i \equiv I_{\text{code}} \otimes I^{\otimes \, (i-1)} \otimes \ket{0}\bra{0} \otimes I^{\otimes \, (N-k-i)}, \quad i = 1,\ldots,N-k, 
\end{equation}
and after the encoding they become
\begin{equation}
    \widetilde{P}_i = U \, P_i \, U^{\dagger}.
\end{equation}

With that, the general stabilizer Hamiltonian has the form of
\begin{equation}
\label{eq:stab_hamil}
    H = - \sum_{i = 1}^{N-k} J_i \cdot \widetilde{P}_i, \quad J_i > 0
\end{equation}
The coefficients $J_i$ can be arbitrarily chosen and determine the energy scales of the system, but since they are necessarily positive-definite, this do not affect the space of ground states i.e. the space of valid physical qudit states. Excitations away from a ground states then correspond to errors being present in the state, which is because of the one-to-one relation between projectors and stabilizers.

\subsection{General Thermodynamic Quantities}

Using the Hamiltonian derived in the previous section, we can now compute the associated Gibbs state
\begin{equation}
    \rho_{\beta} = \frac{1}{Z} e^{-\beta H}, \quad Z = \Tr[e^{-\beta H}]
\end{equation}
and some of its properties, including the entropy.

First, it is straightforward to show that
\begin{align}
\begin{split}
\label{eq:gibbs_exp}
    e^{-\beta H} &= \exp\left( \beta \sum_{i = 1}^{N-k} J_i \cdot \widetilde{P}_i \right) \\
    &= \prod_{i = 1}^{N-k} \exp\left(\beta J_i \cdot \widetilde{P}_i\right) \\
    &= \prod_{i = 1}^{N-k} \left[ \sum_{n=0}^{\infty} \frac{1}{n!} \left(\beta J_i \cdot \widetilde{P}_i \right)^n \right] \\
    &= \prod_{i = 1}^{N-k} \left[ I + \sum_{n=1}^{\infty} \frac{1}{n!} \left(\beta J_i\right)^n \cdot \widetilde{P}_i\right] \\
    &= \prod_{i = 1}^{N-k} \left[ I + \left(e^{\beta J_i} - 1 \right) \cdot \widetilde{P}_i\right] \\
    &= \sum_{n=0}^{N-k} \, \sum_{1 \leq i_1 < \ldots < i_n \leq N-k} \, \prod_{\{i_a\}} \left( e^{ \beta J_{i_a}} - 1\right)\cdot \widetilde{P}_{i_a},
\end{split}
\end{align}
where in the last line we used a generalization of the binomial theorem and the fact that the projection operators commute by definition. Computing the partition function $Z$ using the final expression in \eqref{eq:gibbs_exp} can be done in the following way:
\begin{align}
\begin{split}
    Z &= \Tr[e^{-\beta H}] \\
    &= \sum_{n=0}^{N-k} \, \sum_{1 \leq i_1 < \ldots < i_n \leq N-k} \, \prod_{\{i_a\}} \left( e^{ \beta J_{i_a}} - 1 \right) \cdot \Tr \bigg[ \prod_{\{i_a\}}\widetilde{P}_{i_a} \bigg] \\
    &= \sum_{n=0}^{N-k} \, \sum_{1 \leq i_1 < \ldots < i_n \leq N-k} d^{N-n} \cdot \prod_{\{i_a\}} \left( e^{ \beta J_{i_a}} - 1 \right) \\
    &= d^{k} \cdot \sum_{n=0}^{N-k} \, \sum_{1 \leq i_1 < \ldots < i_n \leq N-k} d^{N-k-n} \cdot \prod_{\{i_a\}} \left( e^{ \beta J_{i_a}} - 1 \right) \\
    &= d^k \cdot \prod_{i=1}^{N-k} \left( e^{ \beta J_i} + d - 1 \right).
\end{split}
x\end{align}
Note that in the second line we used the definition \eqref{eq:pre_code_proj} for the projection operators, which implies that $\Tr[\widetilde{P}_{i_1} \cdots \widetilde{P}_{i_n}] = d^{N-n}$ given that none of the indices $i_a$ coincide. Going from the penultimate line to the last one we then again applied the generalized binomial theorem.

From the partition function it is then easy to determine all other thermodynamic quantities, of which the most important one for us is the von-Neumann entropy
\begin{align}
\begin{split}
    S &\equiv - \Tr[\rho_{\beta} \log(\rho_{\beta})] \\
    &= \beta \cdot \braket{E}_{\beta} + \log(Z) \\
    &= (1 - \beta \cdot \partial_{\beta}) \log(Z),
\end{split}
\end{align}
where the second and third lines are well-known equivalent expressions and we assume $\log$ to refer to the natural logarithm. Therefore, by using the fact that
\begin{align}
    \log(Z) &= k \cdot \log(d) + \sum_{i=1}^{N-k} \log\left( e^{ \beta J_i} + d - 1 \right), \\
    - \beta \cdot \partial_{\beta} \log(Z) &= - \sum_{i=1}^{N-k} \frac{\beta J_i \cdot e^{\beta J_i}}{e^{\beta J_i} + d - 1},
\end{align}
and after doing some rearranging, we arrive at
\begin{equation}
    S_{\text{stab}} = \left( k \log(d) + \sum_{i=1}^{N-k} p_i \log(d-1) \right) + \sum_{i=1}^{N-k} S(p_i),
\end{equation}
where
\begin{equation}
    S(p_i) \equiv - p_i \cdot \log(p_i)) - (1-p_i) \cdot \log(1-p_i)
\end{equation}
is the binary Shannon entropy associated to the probability distributions $\{p_i, 1-p_i\}_i$ which are defined in terms of
\begin{equation}
\label{eq:shannon_prob}
    p_i \equiv \frac{d-1}{e^{\beta J_i} + d - 1} \in \left(0, \frac{d-1}{d}\right).
\end{equation}
Note that in the case of qubits ($d = 2$), $p_i$ is the Fermi-Dirac distribution associated to $J_i$. Hence we can interpret the sum in the leading term as an occupation number such that
\begin{equation}
    \braket{N-k} \equiv \sum_{i=1}^{N-k} p_i, \quad S_{\text{stab}} = \log\left(d^k \cdot (d-1)^{\braket{N-k}}\right) + \sum_{i=1}^{N-k} S(p_i).
\end{equation}
Ignoring that leading term, the total entropy of the Gibbs ensemble therefore decouples into a sum of entropies associated with each energy level $J_i$ and therefore each element of the stabilizer basis \eqref{eq:pre_code_stab}. This is not unexpected though, as each term in the stabilizer Hamiltonian \eqref{eq:stab_hamil} commutes with every other one, making the system completely diagonalizable.

\subsection{Entropy Scaling for the NoRA Model}

So far all the calculations we did hold for error-correcting stabilizer codes in general. To actually get some results unique to the NoRA network discussed in this paper, we have to make some assumptions about the distribution of energy levels $J_i$.

One obvious such assumption is that the level distribution should only depend strongly on the layer $\ell$ at which associated stabilizer elements are first acted on in a non-trivial way by the encoding unitary. Hence we move from $J_i$ to $J_{\ell}$ (and therefore from $p_i$ to $p_{\ell}$),  ignoring (for now) that the energy might actually vary slightly for different stabilizers at the same level. Because of this the expression for the entropy becomes
\begin{equation}
\label{eq:level_entr_discrete}
    S_{\text{stab}} = \log\left(d^k \cdot (d-1)^{\braket{N-k}}\right) + \sum_{\ell=1}^{L} \Delta n_{\ell} \cdot S(p_{\ell}),
\end{equation}
where $n_{\ell}$ is the number of stabilizer basis elements with the same associated energy level:
\begin{align}
\begin{split}
\label{eq:stab_distribution}
    \Delta n_{\ell=1} &= r, \\
    \Delta n_{\ell > 1} &= r^{\ell} - n_{\ell - 1} = (r - 1) \cdot r^{\ell - 1}.
\end{split}
\end{align}
with $1 \leq \ell \leq L$ and $r^L = N - k$. It is easy to see that this distribution therefore does indeed satisfy $\sum_{\ell} \Delta n_{\ell} = N - k$.

The other assumption we are making is that the distribution of energies $J_{\ell}$ increases exponentially with increasing $\ell$, giving it the form of
\begin{equation}
\label{eq:energy_distribution_disc}
    J_{\ell} = \Lambda \cdot e^{-\gamma \cdot (L - \ell)}
\end{equation}
for some UV energy scale $\Lambda > 0$ and rate of increase $\gamma > 0$. This is an artificial but reasonable choice because we want the circuit to obey renormalization invariance while going from the IR to UV limit in the same was as MERA networks generally do.

\subsubsection{Moving to the Continuum Limit}

To determine the scaling of the entropy close to the zero temperature (i.e. $\beta \rightarrow \infty$) limit, it is useful to consider the continuum limit of \eqref{eq:level_entr_discrete} in addition to the other assumptions we made. The stabilizer difference $\Delta n_{\ell}$ therefore becomes the stabilizer density
\begin{equation}
    \rho(\ell) = 
    \rho_0 \cdot e^{\alpha \cdot \ell}, \quad \ell \in [0, L],
\end{equation}
where $\alpha > 0$ can be chosen arbitrarily\footnote{One could of course choose $\alpha = \log(r)$ in the spirit of \eqref{eq:stab_distribution}, but we will refrain from making a specific choice here for the sake of generality. This specific case will be considered later when comparing the approximation with the actual entropy formula.} and $\rho_0$ is fixed by the density having to satisfy
\begin{equation}
    N-k \stackrel{!}{=} \int_0^L d\ell \, \rho(\ell) = \frac{\rho_0}{\alpha} \left( e^{\alpha \cdot L} - 1 \right) \quad \Longleftrightarrow \quad \rho_0 = \frac{\alpha \cdot (N-k)}{e^{\alpha \cdot L} - 1}.
\end{equation}
Because the distribution of the energy levels \eqref{eq:energy_distribution_disc} can be left untouched when moving to the continuum limit, the stabilizer entropy can be naively approximated as
\begin{equation}
\label{eq:level_entr_cont}
    S_{\text{stab}} \approx S_{\text{cont}} = \log\left(d^{k} \cdot (d-1)^{\braket{N-k}}\right) + \int_0^L d\ell \, \rho(\ell) \cdot S(p(\ell)),
\end{equation}
with $p(\ell)$ being of the same form as $p_{\ell}$ in \eqref{eq:shannon_prob}, but now considered as a continuous function of $\ell$. But to make the upcoming calculations easier, we perform a change of variables, integrating over $J = J(\ell)$ instead of $\ell$. To do that, we first note that from \eqref{eq:energy_distribution_disc} it follows that
\begin{equation}
    \ell(J) = L + \frac{1}{\gamma} \cdot \log\left( \frac{J}{\Lambda} \right),
\end{equation}
and hence
\begin{equation}
    d \ell = \frac{d \ell}{d J} \, dJ = \frac{dJ}{\gamma \cdot J} .
\end{equation}
This also allows us to express the stabilizer density as a function dependent on $J$:
\begin{equation}
    \rho(J) = \rho_0 \cdot e^{\alpha L} \cdot \left( \frac{J}{\Lambda} \right)^{\alpha/\gamma}.
\end{equation}
Finally, the continuous entropy as an integral over $J$ is
\begin{align}
\begin{split}
\label{eq:S_cont}
    S_{\text{cont}} &= \log\left(d^{k} \cdot (d-1)^{\braket{N-k}}\right) + \int_{
    \Lambda \cdot e^{-\gamma  L}}^{\Lambda} dJ \, \frac{\rho(J)}{\gamma \cdot J} \cdot S(p(J)) \\
    &= \log\left(d^{k} \cdot (d-1)^{\braket{N-k}}\right) + \frac{\rho_0 }{\gamma} \cdot e^{\alpha  L} \cdot \int_{
    \Lambda \cdot e^{-\gamma L}}^{\Lambda} \frac{dJ}{\Lambda}  \left( \frac{J}{\Lambda} \right)^{\alpha/\gamma - 1} \cdot S(p(J)).
\end{split}
\end{align}
Note that the lower integration bound acts as an effective IR cutoff for the integral. This is necessary for us to be able to make the following approximations..

\subsubsection{Low-Temperature Limit}

Computing the integral in \eqref{eq:S_cont} is in general hard, but since we are only interested in the limit of small $T/J$ (or equivalently large $\beta J$), we can approximate the binary entropy $S(p(J))$ that occurs in the integral as
\begin{align}
\begin{split}
\label{eq:binS_approx}
    S(p(J)) &= - \frac{d-1}{e^{\beta J} + d - 1} \cdot \log \left( \frac{d-1}{e^{\beta J} + d - 1} \right) -  \frac{e^{\beta J}}{e^{\beta J} + d - 1} \cdot \log \left( \frac{e^{\beta J}}{e^{\beta J} + d - 1} \right) \\ 
    &\stackrel{\beta J \rightarrow \infty}{=} (d-1) \cdot \frac{\beta J}{e^{\beta J}} + \mathcal{O}(e^{-\beta J}),
\end{split}
\end{align}
which is straightforward to prove. To realize this limit it is necessary to choose the right parameters since it follows from \eqref{eq:energy_distribution_disc} that
\begin{equation}
    \beta J = \beta \Lambda \cdot e^{- \gamma (L-\ell)} \gg 1 \quad \forall \, \ell
\end{equation}
and hence
\begin{equation}
    \beta \Lambda \cdot e^{-\gamma L} \gg 1 \quad \Longleftrightarrow \quad \gamma L \ll \log(\beta \Lambda).
\end{equation}

Plugging \eqref{eq:binS_approx} into \eqref{eq:S_cont} and noting that $\braket{N-k} = \sum_i p_i = 0$ in that limit then leaves us with an expression that can be further simplified using a change of variables:
\begin{align}
\begin{split}
\label{eq:S_cont_2}
    S_{\text{cont}} &\approx k \log(d) + (d-1) \cdot \frac{\rho_0 \cdot e^{\alpha L}}{\gamma}  \int_{
    \Lambda \cdot e^{-\gamma L}}^{\Lambda} \frac{dJ}{\Lambda} \frac{\beta J}{e^{\beta J}} \left( \frac{J}{\Lambda} \right)^{\alpha/\gamma - 1} \\
    &= k \log(d) + (d-1) \cdot \frac{\rho_0 \cdot e^{\alpha L}}{\gamma} \cdot (\beta \Lambda)^{-\alpha/\gamma} \int_{\beta \Lambda \cdot e^{-\gamma L}}^{\beta \Lambda} dt \, t^{\alpha/\gamma} \cdot e^{-t} \\
    &= k \log(d) + (d-1)(N-k) \cdot \frac{\alpha}{\gamma} \cdot \frac{e^{\alpha L}}{e^{\alpha L} - 1} \cdot (\beta \Lambda)^{-\alpha/\gamma} \int_{\beta \Lambda \cdot e^{-\gamma L}}^{\beta \Lambda} dt \, t^{\alpha/\gamma} \cdot e^{-t} \\
    &\stackrel{\alpha L \gg 1}{\approx} k \log(d) + (d-1) (N-k) \cdot \frac{\alpha}{\gamma} \cdot (\beta \Lambda)^{-\alpha/\gamma} \int_{\beta \Lambda \cdot e^{-\gamma L}}^{\beta \Lambda} dt \, t^{\alpha/\gamma} \cdot e^{-t}
\end{split}
\end{align}
Let's consider the trailing integral. Up to the integration bounds it is the same as the gamma function $\Gamma(\alpha/\gamma + 1)$, whose integrand is positive everywhere. We can therefore get an upper bound for $S_{\text{cont}}$ (that we also expect to be approximately saturated for certain domains of $\beta \Lambda$) by substituting the \enquote{incomplete} gamma function with the proper one. Thus we have
\begin{equation}
\label{eq:S_cont_3}
    S_{\text{cont}} \lessapprox  k \log(d) + (d-1) (N-k) \cdot \frac{\alpha}{\gamma} \cdot \Gamma\left(\frac{\alpha}{\gamma} + 1\right) \cdot (\beta \Lambda)^{-\alpha/\gamma}, 
\end{equation}
which only scales with $(\beta \Lambda)^{-\alpha/\gamma} = (T/\Lambda)^{\alpha/\gamma}$, indicating that the entropy could indeed follow a power law, at least for certain low-temperature regimes. To show how well both continuous approximations hold up against the discrete stabilizer entropy with equivalent parameters ($N-k = r^L$, $\alpha=\log(r)$), we display both in logarithmic plots over $\log(T/\Lambda)$ and with different choices of $\gamma$, which is the only significant free parameter. These plots are depicted in figure \ref{fig:entropy_scaling_appendix} and indeed confirm that our low-temperature approximations are good at predicting aspects of the actual entropy, including its power-law growth.

\begin{figure}[hbt]
    \centering
    \includegraphics[width=\textwidth]{figures/entropy_scaling_appendix.png}
    \caption{Logarithmic scaling of exact stabilizer entropies $S_{\text{stab}}$ and their continuous approximations $S_{\text{cont}}$ (with and without the gamma function correction) for $L=20$, $N-k=r^L$, $k=1$, $d=2$, $r=2$, $\alpha = \log(r)$, $\Lambda=1$ and $\gamma \in \{0.1, 0.4, 1, 3\}$. In the first two figures it can be seen that our continuous approximation from \eqref{eq:S_cont_2} matches almost exactly with the discrete stabilizer entropy for $\gamma \ll 1$ and small $T/\Lambda$. Even though the second figure shows less behavior than the first one, we expect that it will behave similarly for even lower relative temperatures. While the last two approximations with $\gamma \geq 0$ also receive their primary contribution from the polynomial term, it is more apparent that they don't completely align with the actual data anymore. Especially in the last figure where $\gamma = 2$ the trend of the stabilizer entropy is not strictly polynomial anymore. Still, each figure has at least a regime where its growth is either exactly polynomial or follows a polynomial trend that aligns with our theoretical predictions up to a total constant factor.}  
    \label{fig:entropy_scaling_appendix}
\end{figure}


