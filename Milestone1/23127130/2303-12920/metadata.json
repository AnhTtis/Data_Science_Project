{
    "arxiv_id": "2303.12920",
    "paper_title": "VRMoVi: Towards an Expressive Visualization for Human Motion and Object Interaction in Virtual Reality",
    "authors": [
        "Di Qi",
        "LouAnne Boyd",
        "Scott Fitzpatrick",
        "Meghna Raswan"
    ],
    "submission_date": "2023-03-22",
    "revised_dates": [
        "2023-03-24"
    ],
    "latest_version": 1,
    "categories": [
        "cs.HC",
        "cs.GR"
    ],
    "abstract": "Virtual reality (VR)-based immersive analysis has become an alternative to traditional approaches for analyzing complex, multidimensional human motion data. However, existing VR-based methods lack detailed information about hand motion and object interaction, which is essential for interpreting human activities and identifying their needs. To address that, we present a new VR system, VRMoVi, with a unique design of three expressive visualization layers: 1) a 3D tube layer for hand/object general motion, 2) a hand-object avatar layer for hand-object interaction animation, and 3) a particle-with-arrow layer for detailed hand positions and orientations. We validated VRMoVi with a real-world VR human motion dataset and conducted a user study with 24 participants. Compared with other visualization conditions, VRMoVi performed significantly better than the traditional 2D condition and slightly better than the standard VR-based condition; users found VRMoVi to be comprehensible, immersive, easy to use, and useful for interpreting human activity data.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.12920v1"
    ],
    "publication_venue": "10 pages, 5 figures, and 2 tables"
}