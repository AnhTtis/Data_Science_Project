\section{Experiments}

In this section, we assess the performance of DnX and FastDnX on several popular benchmarks, including artificial and real-world datasets. We have implemented experiments using PyTorch~\citep{pytorch} and Torch Geometric~\citep{torch_geometric}. Our code is available at \url{https://github.com/tamararruda/DnX}.

\subsection{Experimental setup}

\paragraph{Datasets.} We consider six synthetic datasets broadly used for evaluating explanations of GNNs: BA-House-Shapes, BA-Community, BA-Grids, Tree-Cycles,  Tree-Grids, and BA-Bottle-Shaped. These datasets are available in \citep{GNNexplainer} and \citep{PGMExplainer}. 
%
Each dataset is a single graph with multiple copies of identical motifs connected to base subgraphs. These subgraphs either consists of random sample graphs from the Barabási–Albert (BA) model \citep{Barabasi1999} or 8-level balanced binary trees.
%
An explanation associated with a motif-node must only include motif elements.
%
Thus, base nodes denote information irrelevant to the prediction of any node.


We also use two real-world datasets: Bitcoin-Alpha and Bitcoin-OTC~\citep{bitcoin-otc-alpha2016,bitcoin-otc-alpha2018}. These datasets denote networks in which nodes correspond to user accounts that trade Bitcoin. A directed edge $(u,v)$ (between users $u$ and $v$) denotes the degree of reliability assigned by $u$ to $v$, i.e., each edge has a score denoting the degree of trust.
%
\autoref{append:implementation} provides more details regarding datasets. 

\paragraph{Baselines.} 


We compare DnX against three baseline explainers: GNNExplainer \citep{GNNexplainer}, PGExplainer \citep{PGExplainer}, and PGMExplainer \citep{PGMExplainer}.
%
To ensure a valid comparison, we closely follow guidelines and the evaluation setup from the original works.
%
We first generate explanations for a 3-layer GCN~\citep{GCN} with ReLU activation. We also consider three additional architectures: graph isomorphism networks (GIN) \citep{xu2018gin}, gated graph sequence neural networks (GATED) \citep{li2015gated} and auto-regressive moving average GNNs (ARMA) \citep{ARMA}
%
This allows for evaluating the robustness and performance of explainers across GNNs of different complexities.


%
\input{tables/result_syn_node}

\paragraph{Implementation details.} We use an 80/10/10\% (train/val/test) split for all datasets. All GNNs have 3 layers and are trained for $1000$ epochs, with early stopping if the validation accuracy does not improve in $100$ consecutive epochs.  We train all baseline GNNs using Adam~\citep{adam} with a learning rate of 0.01 with a weight decay of $5.0 \times 10^{-4}$.
%
We show the performance of these GNNs on the benchmark datasets in the supplementary material.
%
Importantly, we observe accuracy $\geq 95\%$ for most data/model combinations.


For the distillation phase in DnX, we use an SGC model with $3$ layers. We use the predictions for all nodes to train the surrogate SGC. For the optimization, we use AdamW~\citep{AdamW} with a learning rate of $0.1$ with a weight decay of $5.0 \times 10^{-6}$ and $10000$ epochs.

It is worth mentioning that PGExplainer and GNNExplainer --- as described in the experimental section of their respective papers --- output edge-level explanations, so their results are not immediately comparable to that of our methods and PGMExplainer. More specifically, the two former output importance scores for each edge. On the other hand, our methods and PGMExplainer output node importance scores.
Therefore, we convert edge-level explanations to node-level ones by averaging over the scores of all edges incident in a node. For completeness, we  provide additional results doing the reverse transformation (i.e., node- to edge-level explanations) in  the Supplement.


\subsection{Results} \autoref{tab:result_exp_node} compares the performance of DnX and FastDnX against previous art in terms of explanation accuracy, i.e., the number of nodes in method's output that are also in the ground-truth explanations divided by the total number of nodes in the latter. Overall, FastDnX is the best-performing method for all network architectures (GCN, ARMA, GATED, and GIN) on all datasets but Tree-Cycles and Tree-Grids. For Tree-Grids, FastDnX places second for GCN, ARMA and GATED whereas PGMExplainer obtains the highest accuracies. We also note that, while DnX is often better than GNNExplainer and PGExplainer, its performance bests FastDnX only in $12.5\%$ of cases. GNN- and PGExplainer do not appear in the comparison for GIN since they require propagating edge masks, and Torch Geometric does not support edge features for GIN. 


\autoref{tab:result_exp_bitcoin_node} reports the performance of all explainers on the Bitcoin-Alpha and Bitcoin-OTC datasets. Following previous work \citep{PGMExplainer}, we use average precision (AP) as evaluation metric, i.e., the percentage of top-$k$ nodes obtained from each explainer that are correct, averaged over all nodes to be explained. While running the experiments, we noticed that the evaluation protocol employed by \citet{PGMExplainer} obtains explanations for a 3-layer GCN but only considers 1-hop candidate nodes during the explanation phase. This implies that some potentially relevant  nodes are discarded by design. \autoref{tab:result_exp_bitcoin_node} shows results for both 1-hop and 3-hop settings. DnX is the best-performing method, and its fast variant is the second-best across all experiments. For 3-hop candidate nodes, the absolute precision gap between DnX and the best baseline is at least 14\% for Bitcoin-Alpha and 11\% for Bitcoin-OTC. Overall, DnX outperforms GNNExplainer and PGMExplainer by a large margin. Note that the performance of PGMExplainer drops considerably when going from 1- to 3-hop. We report additional results in the Appendix.

\input{tables/result_bitcoin_gcn}

\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{images/times.pdf}
    \caption{Time comparison. The bar plots show the average time each method takes to explain a prediction from GCN. FastDnX is consistently the fastest method, often by a large margin. For the datasets with largest average degree (Bitcoin datasets), FastDnX is 4 orders of magnitude faster than PGMExplainer and 2 orders faster than the other methods.}
    \label{fig:times}
\end{figure*}

\paragraph{Time comparison.} To demonstrate the computational efficiency of DnX/FastDnX,
\autoref{fig:times} shows the time each method takes to explain a single GCN prediction.
%
For a fair comparison, we also take into account the distillation step in DnX/FastDnX. 
%
In particular, we add a fraction -- one over the total number of nodes we wish to explain -- of the distillation time and add it to the time DnX and FastDnX actually take to generate an explanation.
%
Notably, both DnX and FastDnX are consistently much faster than GNNExplainer and PGMExplainer.
%
For instance, FastDnX is more than forty thousand times faster than PGMExplainer in Bitcoin-Alpha and Bitcoin-OTC.


\paragraph{Distillation results.} For completeness, \autoref{tab:distillation_gcn} shows the distillation accuracy achieved by our linear network $\Psi$ when $\Phi$ is a GCN,  for both the synthetic and the real datasets. Here, we measure accuracy using the predictions of the model $\Phi$ as ground truth. For all cases, we observe accuracy superior to $86\%$. \autoref{tab:distillation_gcn} also shows the time elapsed during the distillation step.
Similar results are achieved when distilling ARMA, GATED and GIN models, these results are shown and described in the Appendix.
%\textcolor{red}{\bf Appendix ? shows similar results for ARMA, GATED, and GIN.}



\begin{table}[!htb]
\centering
\caption{Distillation accuracy and time for GCN. For all cases, accuracy $>86\%$ and the distillation phase takes considerably less than 1 minute.} 
% \adjustbox{width=\columnwidth}{
\begin{tabular}{lcc}
\toprule
\textbf{Dataset} & \textbf{Accuracy} & \textbf{Time (s)} \\
\midrule
BA-House & $94.2 \pm{1.2}$ & $13.996$ \\
BA-Community  & $86.6\pm{0.1}$ & $16.447$ \\
BA-Grids & $99.9\pm{0.1}$ & $2.721$ \\
Tree-Cycles & $97.7\pm{0.2}$ & $3.820$\\
Tree-Grids & $98.0\pm{0.2}$ & $3.803$\\
BA-Bottle & $98.5\pm{0.2}$ & $3.181$\\
Bitcoin-Alpha & $90.4\pm{0.1}$ & $28.317$\\
Bitcoin-OTC & $89.1\pm{0.2}$ & $32.414$\\
\bottomrule
%
% &\multicolumn{7}{c}{Average Time (s)} \\ \hline
% 13.996 & 16.347 & 2.721 & 3.820 & 3.803 & 3.181 & 28.317 & 32.414 \\
\end{tabular}
% }
\label{tab:distillation_gcn}
\end{table}



Interestingly, although BA-community is the dataset with the lowest distillation accuracy (86.6\%), DnX and FastDnX achieve significantly better results than the previous state-of-the-art (cf. \autoref{tab:result_exp_node}). The rationale for these counter-intuitive results is that the distiller can differentiate between motif nodes and base nodes, and this is enough to get good explanations -- since  the evaluation set comprises motif nodes only. More concretely, the confusion matrix in \autoref{fig:conf_mat} reveals that, despite the low distillation accuracy, the surrogate model $\Psi$ correctly predicts the base nodes (classes 1 and 5). Therefore, $\Psi$ achieves high accuracy for the binary classification problem of distinguishing motif and base nodes, supporting our hypothesis.


\begin{figure}[thb]
\centering
\includegraphics[width=0.8\columnwidth]{images/conf_mat/BA-Community-conf_matrix.pdf}
\caption{Confusion matrix of the distillation process for the BA-Community dataset. Classes 1 and 5 correspond to base nodes. While the surrogate misclassifies many motif nodes, it is able to correctly predict almost all base ones.}
\label{fig:conf_mat}
\end{figure}


\paragraph{Fidelity results.}


\input{tables/result_syn_fidelity}
\input{tables/result_real_fidelity}
To further assess the quality of explanations, we consider a fidelity metric --- we use \emph{Fidelity-} as in \citep{Yuan2022}. This metric measures how the GNN's predictive performance (accuracy) fluctuates when we classify nodes based only on the subgraph induced by the explanations. When the fidelity is positive, there is a decrease in performance. When it is negative, using ``only the explanation'' yields better predictions on average. 
%
Tables \ref{tab:result_exp_node_fidelity} and \ref{tab:result_real_fidelity} report fidelity for the synthetic and the real datasets, respectively.
%
Note that we have considered three additional real-world datasets (citation networks): Cora, Citeseer, and Pubmed. 
%
Results obtained from DnX for the synthetic datasets are the best ones in 50\% of the cases.
%
It is interesting to observe that for Tree-Cycles and Tree-Grids, DnX/FastDnX are not the best performing ones wrt accuracy (Table 1), but are the best ones wrt fidelity (Table 4). 
%
For real datasets, in most cases, either DnX or FastDnX achieves the best results overall. 
%
Importantly, this corroborates the results we observed for the precision metric on Bitcoin-Alpha/OTC datasets. 
%
We note that it was infeasible to run PGMExplainer on Pubmed as explaining one prediction with it can take up to an hour in our local hardware.
