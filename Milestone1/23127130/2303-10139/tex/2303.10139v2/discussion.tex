\section{Discussion}\label{sec:discussion}
\vspace{-12pt}
\paragraph{Are benchmarks too simple?} Given that DnX/FastDnX often achieve remarkable performance by explaining simple surrogates, a natural questions arises: \emph{are these popular benchmarks for GNN explanations too simple?} Since these benchmarks rely on model-agnostic ground-truth explanations, we now investigate inductive biases behind these explanations, and show that they can be easily captured. 

\autoref{fig:degree} reports the degree distribution of motif and base nodes for all synthetic datasets. Recall that, by design, ground-truth explanations are always given by motif nodes. Note also that support for the distributions motif and base nodes have almost no overlap for most datasets (except Tree-Cycles \& Tree-Grids). Thus, any explainer capable of leveraging degree information would obtain high accuracy.  
%

To make this more concrete, we propose a very simple baseline "explainer" that outputs explanations based on the normalized adjacency matrix. 
%
In particular, we define the importance of node $j$ to the prediction of node $i$ as the $(i,j)$-entry of $\widetilde{A}^{L}$, with $L=3$. With this simple baseline, we obtain the following accuracy values: 99.9\% (BA-House), 98.1\% (BA-Community), 99.9\% (BA-Grids), 95.9\% (Tree-Cycles), 90.4\% (Tree-Grids), and 99.9\% (BA-Bottle). Notably, this baseline would rank 1 if included as 
an explanation method for GCNs in Table 1. 


\citet{Faber2021} have also raised issues regarding these benchmarks, proposing alternative datasets as well. We have run FastDnX to explain a 2-layer GCN model for two of their proposed datasets (\emph{Community} and \emph{Negative evidence}), and obtained remarkably good accuracy results: 94.0\% and 99.5\%, respectively. Also, simply ranking nodes based on the entries of $\widetilde{A}^{L}$ ($L=2$) achieves accuracy of 93.0\% (\emph{Community}) and 99.6\% (\emph{Neg. evidence}).

\begin{figure}[thb]
\centering
\includegraphics[width=0.88\columnwidth]{images/degree/degree.pdf}
%  \centering
%  \adjustbox{width=0.5\textwidth}{
%      \subfloat{\includegraphics[width=\textwidth]{images/degree/BA-House-degree.png}}
%      \subfloat{\includegraphics[width=\textwidth]{images/degree/BA-Community-degree.png}}}\\
% \adjustbox{width=0.5\textwidth}{
%     \subfloat{\includegraphics[width=\textwidth]{images/degree/BA-Grids-degree.png}}
%     \subfloat{\includegraphics[width=\textwidth]{images/degree/BA-Bottle-degree.png}}}\\
% \adjustbox{width=0.5\textwidth}{    \subfloat{\includegraphics[width=\textwidth]{images/degree/Tree-Cycles-degree.png}}
%     \subfloat{\includegraphics[width=\textwidth]{images/degree/Tree-Grids-degree.png}}}
 \caption{Degree distribution of motif and base nodes. While we can overall distinguish motif and base nodes from degree information on BA-based datasets, there is a significant overlap on Tree-Cycles and Tree-Grids.}
 \label{fig:degree}

\end{figure}


\paragraph{Limitations.} While simple graph models (like SGC) have been shown to achieve good performance on node-level classification tasks, they fail to rival recent GNNs for graph-level prediction tasks \citep{CS, SGC}. Naturally, we would not expect DnX and FastDnX to work well out-of-the-shelf to explain graph-level predictions.  However, our methods could be easily extended to use more powerful linear GNNs that incorporate different types of diffusion operators~\citep{sign}, or use long-range residual connections \citep{SimpleDeep}.

