Pre-processing is the first step of stochastic GW data analysis, in which data are read, downsampled and high-pass filtered. %
The pipeline can use public data available from the \gls{gwosc}~\cite{gwosc}, private data (data stored on the \gls{lvk} servers restricted to members of the collaboration), or local data. %
Data are read using existing {\tt gwpy}~\cite{gwpy} {\tt TimeSeries} methods. %
we denote the raw data measured at detector $I$ over the time period $T$ by $s_I (t_k)$ in what follows, where $t_k$ are discrete times given by $t_k \equiv k \delta t$. %
The values of $k$ are positive integers between 0 and $T/\delta t - 1$ and $\delta t$ is the sampling period, which in \gls{ligo}, Virgo and KAGRA interferometers is 1/(16384 Hz). %
The raw strain data from the two interferometers, $s_I (t_k)$ and $s_J (t_k)$, are downsampled to a user-defined sampling frequency $f_{\rm samp}$, 
using a user-defined re-sampling window (a \textit{Hamming} window by default). %
The downsampling is performed to reduce the memory and computational requirements of the analysis. %
This is achieved using an existing {\tt gwpy TimeSeries} filtering method for strain data. %
Note that selecting an $f_{\rm samp}$ implies fixing a Nyquist frequency of $ f_{\rm Nyquist} = f_{\rm samp}/2$ for the analysis. %
The Nyquist frequency is the highest frequency included in the Fourier expansion at a given sampling rate. Hence, frequencies above it cannot be probed. %, to be able to fully reconstruct the signal. %
To avoid this becoming a limitation, $f_{\rm samp}$ should be chosen high enough to contain the full spectrum of the signal of interest, within reasonable sensitivity of the detector. %

\begin{figure}
    \centering
    \includegraphics[width=0.55\linewidth]{preprocessing_1.pdf}
    \caption{Comparison between the amplitude spectral density (ASD) of a raw (blue solid line) and pre-processed (orange solid line) 192 s segment of \gls{ligo} Livingston O3 data. Pre-processing consists of downsampling the data to 4096 Hz and then removing the low frequency content below 10 Hz.}
    \label{fig:downsampled_highpassed}
\end{figure}


The low-frequency content of ground-based interferometer data (in particular below 10Hz) is % louder than at the frequencies of interest (between 20-1726Hz \cite{PhysRevD.104.022004}) due to 
dominated by seismic and control noise~\cite{PhysRevD.102.062003}. %
For this reason, frequencies below a given (user-defined) cutoff frequency are high-pass filtered, i.e., excluded from the analysis. %The default cut-off is $11~\rm Hz$. 
In previous isotropic \gls{gwb} searches~\cite{LIGO_S5, LIGO_O1, LIGO_O2, LIGO_O3}, the input data are high-pass filtered  using a $16$th-order Butterworth filter with a specific knee frequency. %
A 16th-order Butterworth filter is built by first computing its transfer function (in zero-pole-gain form) using the {\tt scipy} library and then filtering the data with the relevant {\tt gwpy TimeSeries} method. The design of the high-pass filter is fixed in the module, only allowing the user to specify the knee frequency. %
The default value of the knee frequency is $11$ Hz, which  was chosen to avoid the spectral leakage from the noise power spectrum below $20$ Hz~\cite{LIGO_O3}. 
See Fig.~\ref{fig:downsampled_highpassed} for an example of data before and after pre-processing. %

At this point, the data may also be screened for large bursts of power in the detector data with high SNR, or \textit{glitches}, due to instrumental or environmental disturbances, which are known to bias estimates of stochastic analyses~\cite{Usman:2015kfa,Pankow:2018qpo,LIGO:2021ppb,Virgo:2022kwz,Davis:2022dnd}. %
Historically, segments with loud glitches were flagged and excluded from analysis by non-stationarity cuts (see Sec.~\ref{Sec:DeltaSigma}). % 
In O3, a series of exceptionally loud glitches appeared in the data that led to large fractions of data being removed by previously employed non-stationarity cuts~\cite{LIGO_O3}. %
Hence, an alternative technique called \textit{gating} was employed to address these loud glitches, and drastically reduce the amount of data removed \cite{gatingStudy}. %
Gating is performed internally by {\tt pygwb} by multiplying the data by an inverse {\it Planck-taper} window~\cite{McKechan:2010kp}.
Time periods around samples in the whitened data that have an absolute value above a chosen threshold are marked for gating independently for each interferometer. %
The width of the gate must be sufficiently large to remove the entirety of the relevant glitch. The required width may change based on the data quality of the specific data in the analysis and hence must be empirically determined. %
The tapering length of the window must also be sufficiently long to minimize the addition of artifacts by the gating; 0.25 seconds is found to be sufficient~\cite{Davis:2022dnd}. %
This technique is generically beneficial for the analysis of data that are non-Gaussian, such as real gravitational-wave detector data. % 
Gating implemented in {\tt pygwb} is highly customizable to the specific needs of the analysis; default gating parameters are shown below in Table~\ref{tab:parameters}. %
For more details on gating and parameter choices see~\cite{Davis:2022dnd}. %

Finally, the module also allows to perform a time-shifted analysis in which one of the two timeseries is shifted in time by an integer number of seconds before the cross-correlation is performed. %
This technique is employed as a detector noise characterization tool, since it removes the potential correlation due to a broadband \gls{gwb}, while preserving instrumental correlations with coherence times greater than the applied time shift, like nearly-sinusoidal spectral artifacts from, e.g. electronics~\cite{Covas_2018} \footnote{It is worth noting that this time shift will probably not help identify correlated broadband stochastic noise, such as correlated magnetic noise from Schumann resonances, as this is largely caused by lightning strikes and the correlation between detectors is due to seeing the same stochastic signal in both detectors. This is in contrast to chance coherence between coincident periodic artifacts ({\it lines}) at multiple sites that one can find by implementing time shifts.}. % 
The time shift is a user defined parameter which should always be greater than the light travel time between detectors (i.e., 10 ms for the LIGO Hanford and Livingston detectors) and smaller than the segment duration. %
Typically, a time shift of 1s is used. \\

%The time shift is done with the function {\tt shift\_timeseries}, which uses the {\tt numpy} method {\tt roll} over one of the timeseries. This method, as the name indicates, rolls array elements along a given axis and brings back to the beginning of the array the last piece of data. \\

