\documentclass[prl,twocolumn,longbibliography,preprintnumbers,superscriptaddress,amsmath,amssymb]{revtex4-1}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{mathrsfs}
\usepackage{amsfonts}
\usepackage{times}
\usepackage{amsmath}
\usepackage{leftidx}
\usepackage{color}
\usepackage[colorlinks,linkcolor=blue,citecolor=blue]{hyperref}
\newcommand{\tocite}[1]{{[Cite: #1]}}
\newcommand{\ind}{\operatorname{ind}}
\newcommand{\Tr}{\operatorname{Tr}}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\usepackage{bbold}
\usepackage{braket}
\usepackage{mathtools}
\usepackage{siunitx}
\usepackage{CJKutf8}

\begin{document}
\title{Maxwell's Demon for Quantum Transport}
\author{Kangqiao Liu}
\email{kqliu@cat.phys.s.u-tokyo.ac.jp}
\affiliation{Department of Physics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-0033, Japan}
\author{Masaya Nakagawa}
\affiliation{Department of Physics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-0033, Japan}
\author{Masahito Ueda}
\affiliation{Department of Physics, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-0033, Japan}
\affiliation{RIKEN Center for Emergent Matter Science, 2-1, Hirosawa, Wako-shi, Saitama, 351-0198, Japan}
\affiliation{Institute for Physics of Intelligence, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-0033, Japan}
\date{\today}

% Abstract
\begin{abstract}
Maxwell's demon can be utilized to construct quantum information engines. While most of the existing quantum information engines harness thermal fluctuations, quantum information engines that utilize quantum fluctuations have recently been discussed. We propose a new type of genuinely quantum information engine that harnesses quantum fluctuations to achieve cumulative storage of useful work and unidirectional transport of a particle. Our scheme does not require thermalization, which eliminates the ambiguity in evaluating the power and velocity of our proposed engine in contrast to other existing quantum information engines that can transport a particle. We find a tradeoff relationship between the maximum achievable power and the maximum velocity. We also propose an improved definition of efficiency by clarifying all possible energy flows involved in the engine cycle.
\end{abstract}
\maketitle


%%%%% Introduction

%\section{Introduction}

%[TODO: list the uniqueness of our work. (1) compared with \cite{Toyabe2010}, ours is quantum version, harness quantum ``fluctuation", derive a similar fluctuation theorem equality; (2) we can transport, surpass the unique feature of Bloch oscillation which does not exist in classical case; (3) how fast can we transport? can we surpass the Lieb-Robinson bound? Maybe by looking at $\Delta=0$ case.]

% Quantum fluctuations have several different meanings which depend on the context.
% One simple situation in which quantum fluctuations appear is quantum systems at zero temperature.
% For example, suppose that a particle is in the ground state in a harmonic potential.
% In this state, even if the temperature is zero, the position of the particle involves fluctuations (i.e., zero-point oscillations). This is a quantum fluctuation (because there is no thermal fluctuation at zero temperature).
% In general, physical quantities of a quantum state have fluctuations even if the state is a pure state (i.e., not a mixed state); These are also called quantum fluctuations, which arise from the probabilistic nature of quantum mechanics.
% In our case, I think that the probability distribution of the position before measurement is clearly due to quantum fluctuations, since the probability distribution (or fluctuations in the position) is formed only through a quantum-mechanical unitary time evolution rather than a stochastic process caused by some environment.

% The virtual energy you mentioned is also sometimes called quantum fluctuation. But I think that this is just a special case of quantum fluctuations in energy, which can be related to the uncertainty relation between energy and time.
\emph{Introduction.---} A heat engine does mechanical work by harnessing thermal energy. The amount of extractable work is limited by the second law of thermodynamics. A thought experiment to overcome this limit was conceived by James Clerk Maxwell who, in modern language, realized that feedback control permits information-to-work conversion. An important application of Maxwell's demon is to help an engine extract more work than a Carnot engine. This type of engine is called an information heat engine. A quintessential classical information heat engine is the Szilard engine \cite{Szilard1964decrease} which can extract work beyond the second law of thermodynamics by harnessing \textit{thermal} fluctuations. Besides extracting energy and doing work in every engine cycle, one may also utilize the extracted energy cumulatively to transport a particle uphill against a potential barrier. This type of Maxwell's-demon-assisted transport was experimentally realized with a classical Brownian particle by Toyabe \textit{et al} \cite{Toyabe2010}. The power and the efficiency of a heat engine, and the velocity of particle transport, have been investigated in Ref.~\cite{Sahae2023356118}.


\begin{figure}[t!]
\begin{center}
\includegraphics[width=\columnwidth]{setup.pdf}
\end{center}\vspace{0mm}
\caption{Setup of our model. A single particle hops on a 1D lattice subject to an external linear field. If a projective position measurement finds the particle at site $j$, the potential at site $j-1$ is instantly raised by $V\gg \Delta, J$. This barrier prevents the particle from hopping downstairs. We next let the particle undergo a unitary evolution with a new Hamiltonian \eqref{eq: our limiting H} during a time $t$. Then we perform the next projective position measurement on the particle. If the particle is located at site $j+l$ with $l\in \mathbb{N}_0$, we successfully store $l\Delta$ energy. Finally, we erase the memory of the measurement outcomes stored in the probe and start the next cycle.}\vspace{0mm}
\label{fig: setup}
\end{figure}

Maxwell's demon has been extended to the quantum regime. Many types of quantum information engine have been theoretically proposed \cite{Scully2003extracting,Kim2011quantum,Park2013heat,Abah2014efficiency,Zhang2014quantum,Brandner2015coherence,Uzdin2015equivalence,Chapman2015how,Niedenzu2016operation,Manzano2016entropy,Yi2017single,Alexia2017engine,Elouard2018efficient,Ding2018measurement,Buffoni2019quantum,Seah2020maxwell,Alexia2021short,Bhandari2023quantum} and experimentally implemented \cite{Camati2016experimental,Cottet2017observing,Masuyama2017information,Naghiloo2018information,Wang2018realization,Najera-Santos2020autonomous,Hern2022autonomous,Yan2022verification}. However, most of them still extract work from a \textit{thermal} reservoir \cite{Scully2003extracting,Kim2011quantum,Park2013heat,Abah2014efficiency,Zhang2014quantum,Brandner2015coherence,Uzdin2015equivalence,Chapman2015how,Niedenzu2016operation,Manzano2016entropy,Yi2017single,Seah2020maxwell,Bhandari2023quantum} and thermal equilibration is required for every cycle of operations. While the apparent distinction from a classical engine is that the working agent is a quantum system, it is unclear what quantum nature of the engine plays a role. Recently, quantum information engines that utilize only \textit{quantum} fluctuations with no heat reservoir coupled to the working agent have been proposed \cite{Alexia2017engine, Alexia2021short}. The system gains energy directly from projective measurements on those observables which do not commute with the system Hamiltonian and a unit efficiency can be achieved. However, in Ref.~\cite{Alexia2017engine}, the energy extracted in one feedback loop must be released at the end of the loop to reset the engine. The lack of ability to utilize cumulatively stored energy on demand greatly limits the utility and strength of an information engine. Reference~\cite{Elouard2018efficient} proposes a new type of quantum information engine that can store energy and transport a particle against a potential. However, it still requires a heat bath to prepare an equilibrium state and the thermalization time is usually unknown. Therefore, it is hard to evaluate the power and the transport velocity. In this Letter, we construct a new type of quantum information engine with a tilted one-dimensional (1D) lattice that can store energy cumulatively from purely quantum fluctuations without resorting to thermalization and allows one to evaluate its power and velocity. We find that the maximum power and the maximum velocity obey a tradeoff relationship which implies that a large power can be obtained at the expense of a small velocity and vice versa. Our engine runs in pure states which are usually far from equilibrium. Transport is highly nontrivial because without Maxwell's demon a particle in a tilted 1D lattice would undergo Bloch oscillations which are interrupted by Zener transitions \cite{Bloch1929oscillation,Breid2006bloch}. Our information engine can transport a particle beyond the realm of Bloch oscillations without resorting to Zener transitions. We finally discuss an improved definition of the efficiency of our information engine by considering both the energy cost of measurement and that of information erasure; the former is not included in Refs.~\cite{Alexia2017engine, Elouard2018efficient, Alexia2021short}, and the later is missing in Refs.~\cite{Brandner2015coherence,Yi2017single}. 


\begin{figure}[t!]
\begin{center}
\includegraphics[width=\columnwidth]{p_v_max.pdf}
\end{center}\vspace{0mm}
\caption{(a) Maximum power as a function of the dimensionless step height $\alpha:=\Delta/J$ of the ladder potential. The blue curve shows the numerical results and the orange dashed line shows the prediction of the large-$\alpha$ limit. The maximum power monotonically increases and becomes saturated at a constant value for $\alpha \gg 1$, while it tends to vanish in the small-$\alpha$ regime. The inset plots the power as a function of time with $\alpha=1$, indicating that the optimal time is finite and can be used to evaluate the maximum power. (b) The maximum velocity of particle transport shows a trend opposite to the maximum power and saturates in the small-$\alpha$ regime.}\vspace{0mm}
\label{fig: maximum p and v}
\end{figure}

\emph{Setup.---}
We consider a quantum particle in a 1D ladder potential as illustrated in Fig.~\ref{fig: setup}. It is described by the Wannier-Stark (WS) Hamiltonian $H_{\rm WS} = -J\sum_{n=-\infty}^{+\infty}\ket{n}\bra{n+1}+\ket{n+1}\bra{n}) + \Delta \sum_{n=-\infty}^{+\infty}n\ket{n}\bra{n}$, where $J$ is the hopping amplitude, $\Delta:=Fd$ the energy difference between two adjacent sites, $F$ the strength of the gradient force, $d$ the lattice constant, and $\{\ket{n}\}$ the Wannier states. We aim at pumping up a particle against a linear potential to accumulate energy in the form of the potential energy and achieve directed motion by measurement and feedback, which is a quantum analog of Ref.~\cite{Toyabe2010}. We achieve this goal by the following four steps.

\textbf{Step 1 -- measurement:} A projective position measurement is performed in the basis of Wannier states $\{\ket{n}\}$.

\textbf{Step 2 -- feedback control:} If the particle is located at site $j$, the potential at site $j-1$ is instantly raised by $V\gg \Delta, J$ to prevent the particle from hopping downstairs.

\textbf{Step 3 -- unitary evolution:} The particle undergoes a unitary evolution during time $t$ according to the Hamiltonian $H_j = H_{\rm WS} + V\ket{j-1}\bra{j-1}$. A sufficiently large $V$ effectively imposes a rigid wall at site $j-1$ such that $\Psi(n)=0$ for $\forall n\le j-1$. The effective Hamiltonian is then given by
\begin{equation}\label{eq: our limiting H}
    H_j=-J\sum_{n=j}^{N-1}(\ket{n}\bra{n+1}+\ket{n+1}\bra{n})+\Delta\sum_{n=j}^{N}n\ket{n}\bra{n},
\end{equation}
where the upper limit of the summation is truncated because a long but finite chain with $N$ sites is used in numerical simulations. This truncation is valid if $N\gg \langle n \rangle:= \sum_n n|\braket{n|\psi(t)}|^2$ during the simulation where the time-evolved state is $\ket{\psi(t)} = \exp{(-iH_j t/\hbar)}\ket{j}$.

\textbf{Step 4 -- information erasure:} We erase the information of measurement outcomes that is stored in the memory of the probe and start the next cycle.

We are interested in the average rate of energy storage (power $p$), the average rate of particle transport (velocity $v$), and the efficiency $\eta$ which will be defined later. We first demonstrate that the average power in a long time is defined by $p:=E/t$ where $E$ is the average energy stored in one feedback loop. We consider a trajectory of $M$ feedback loops with the total time $T:=Mt$. The total accumulated energy gain is $W:=\sum_{i=1}^M w_i$, where $w_i$ is the energy stored in the $i$th loop which is a stochastic variable. The power for this trajectory is given by $r:=W/T$. In the limit of $T\to+\infty$, the power converges to $p=\lim_{T\to+\infty}r=\lim_{M\to+\infty}\frac{\sum_{i=1}^{M}w_i}{Mt}=\frac{M E}{Mt}=\frac{E}{t}$, where the law of large numbers is used to obtain $\lim_{M\to+\infty}\sum_{i=1}^{M}w_i=M E$.


Let us introduce a rescaled gradient $\alpha:= \Delta/J$ and time $\tau:= Jt/\hbar$. The dimensionless Hamiltonian is $\tilde{H}_j:=H_j/J=-\sum_{n=j}^{N-1}(\ket{n}\bra{n+1}+\ket{n+1}\bra{n})+\alpha \sum_{n=j}^{N}n\ket{n}\bra{n})$, and the average stored energy is $E:= \sum_{i=1}^{N}i\Delta P(j+i)$, where $P(j+i) := |\braket{j+i | \psi(t)}|^2$ is the probability of measurement outcome $j+i$. The dimensionless energy gain is $\tilde{E} := E/J$. We define the dimensionless power to be $\tilde{p}:= \tilde{E}/\tau = p\hbar/J^2$. The average velocity is defined as the number of traveled sites per second $v:= \sum_{i=1}^{N}iP(j+i) / t$. Therefore, the dimensionless velocity is $\tilde{v}:= v\hbar/J$. The maximum power and velocity share the same optimal time for a fixed value of $\alpha$. We first present numerical results.
%The numerical simulations are performed with QuTiP \cite{JOHANSSON2012qutip,JOHANSSON2013qutip}.





\emph{Results.---} In Fig.~\ref{fig: maximum p and v}, we plot the maximum power (a) and the maximum velocity (b) achievable by changing $\tau$ for each value of $\alpha$. The blue curves show numerical results. The maximum power exhibits a monotonic increase with increasing $\alpha$, and an opposite trend is seen for the maximum velocity, indicating a tradeoff relationship between the maximum power and the maximum velocity. To achieve a large power, a large gradient should be used, which suppresses the velocity; conversely, to achieve a large velocity, the gradient should be made small, which reduces the power. 

Let us analyze the two limiting cases. 

\textbf{Small-$\alpha$ regime.} For $\alpha\ll 1$, the maximally achievable power approaches zero and the maximum velocity saturates to a constant value. To understand the saturation constant for the velocity, we consider a flat lattice in the $\alpha\to 0$ limit and assume that the particle is initially at site $n=1$ with a rigid wall placed at $n=0$. After a short transient dynamics, the wave packet of the particle travels in the right direction with a constant velocity [see Fig.~\ref{fig: optimal time}(a)]. For a semi-infinite chain, the velocity is kept constant. For a finite chain as used in the numerical simulation, the right boundary will eventually reflect the wave packet to decrease the velocity. The physics underlying the value of this constant velocity can be qualitatively understood from Heisenberg's uncertainty principle. Since the particle is initially localized at site 1, the momentum fluctuates due to Heisenberg's uncertainty relation, providing the energy for the particle to move to the right. Because the expectation value of the kinetic energy $K$ for the initial state is 0, the variance of it is ${\rm Var}[K]=\bra{\psi(0)}H_1^2\ket{\psi(0)} = J^2$. Its standard deviation is $\sigma(K)=J$. The velocity is then expected to be $\tilde{v}=\frac{v\hbar}{Jd}=\frac{\hbar}{Jd}\sqrt{\frac{2 \sigma(K)}{m^*}} = 2$ with $m^*= \frac{\hbar^2}{2Jd^2}$ being the effective mass. This value is close to the numerically obtained result of 1.7. For a finite $\alpha$, the average velocity multiplied by $\alpha$ gives the power, which makes the maximum power vanish in the small-$\alpha$ regime.

\textbf{Large-$\alpha$ regime.} For $\alpha\gg 1$, the dynamics is effectively confined within neighboring sites which are described by a two-dimensional Hilbert space. This approximation allows exact calculations by using an effective Hamiltonian $H_{\rm eff} = -J(\ket{0}\bra{1}+ \ket{1}\bra{0}) + \Delta \ket{1}\bra{1}$. The leading two terms of energy gain within time $t$ are $\tilde{E} 
    % = \frac{2\alpha}{4+\alpha^2}\left[1-\cos (\sqrt{4+\alpha^2}\tau)\right]\nonumber\\
    % & 
    = \frac{2}{\alpha}\left[1-\cos (\alpha\tau)\right]$. The maximum value $4/\alpha$ is obtained for the running time $\tau^*=(2n-1)\pi/\alpha$ with $n\in \mathbb{N}$. The power is given by
\begin{align}
    \tilde{p} 
    % &= \frac{2\alpha}{4+\alpha^2}\frac{1-\cos(\sqrt{4+\alpha^2}\tau)}{\tau}\nonumber\\
    % & 
    = 2 \frac{1-\cos(\alpha\tau)}{\alpha\tau}.
\end{align}
The maximum value is independent of $\alpha$ and close to $2\times 0.72 = 1.44$ at $\alpha \tau^* \approx 2.33$, which is consistent with the numerical results as plotted in Figs.~\ref{fig: maximum p and v}(a) and \ref{fig: optimal time}(b). As $\alpha$ increases, the maximum velocity decreases as $1.44/\alpha$ as shown in Fig.~\ref{fig: maximum p and v}(b).

\begin{figure}[t!]
\begin{center}
\includegraphics[width=\columnwidth]{optimal_times.pdf}
\end{center}\vspace{0mm}
\caption{(a) Velocity as a function of time for a flat lattice with $\alpha=0$ and $N=10000$ sites. The inset shows the time evolution of the displacement $\langle n \rangle := \sum_n nP(n)$. After a short transient dynamics, the velocity reaches a constant value at about 1.7 until the wave packet propagates close to the right boundary as plotted in the inset. (b) Optimal time for the maximum power and velocity as a function of the gradient $\alpha$. In the large-$\alpha$ regime, our theory predicts a linear relation. In the small-$\alpha$ regime, we obtain $\tau^* \propto\alpha^{-0.64}$ from fitting.\vspace{0mm}}
\label{fig: optimal time}
\end{figure}

\emph{Efficiency.---} Another important measure for an engine is efficiency. For a classical heat engine, the efficiency is defined as the work output by the working agent divided by the heat absorbed from the hot heat bath. Following this logic, we clarify the energy flow involved in our engine and define the efficiency $\eta$ [see Fig.~\ref{fig: efficiency}(a)]. There are two steps involving energy inputs. First, during the unitary evolution, the kinetic energy is converted to the potential energy. Then the quantum measurement increases the internal energy of the particle [$S$ in Fig.~\ref{fig: efficiency}(a)] by $E$ which compensates for a decrease in the kinetic energy, and a correlation between the probe $M$ and the particle is established. This quantum measurement requires an energy input $E_{\rm meas}$, which is especially important for a quantum system because quantum measurement may directly alter the energy. We assume that applying the feedback control protocol, i.e., raising a potential, is ideal and cost-free. This assumption has widely been made in the context of Maxwell's demon \cite{Sagawa2008second, Sagawa2009minimal, Sagawa2011erratum, Bhandari2023quantum, Parrondo2015thermodynamics, Elouard2018efficient, Alexia2021short}. The second step is information erasure. To start the next cycle, the information stored in the measurement probe must be discarded in contact with a heat bath with temperature $T$. This requires an amount of energy $E_{\rm eras}$ according to Landauer's principle \cite{Landauer1961irreversibility, Bennett1982thermodynamics}. Therefore, the energy resource required for our engine is given by $E_{\rm cost} = E_{\rm meas} + E_{\rm eras}$. There is no fundamental limit to the energy cost of each individual process of measurement and erasure. However, there exists a fundamental bound on the total energy cost \cite{Sagawa2009minimal,Sagawa2011erratum}. In Refs.~\cite{Alexia2017engine, Elouard2018efficient, Alexia2021short}, $E_{\rm meas}$ is not included in the resource, and in Refs.~\cite{Brandner2015coherence,Yi2017single}, $E_{\rm eras}$ is not considered. For example, in Refs.~\cite{Alexia2017engine,Elouard2018efficient,Alexia2021short}, the efficiency is defined as $\eta' := (E-E_{\rm eras})/E$ without $E_{\rm meas}$. However, information erasure can, in principle, be performed without work \cite{Sagawa2009minimal}, which makes it possible to achieve $\eta' = 1$ regardless of details of the engine. We, therefore, define the efficiency of our quantum information engine as
\begin{equation}\label{eq: efficiency}
    \eta := \frac{E}{E_{\rm cost}}.
\end{equation}

This total energy cost can be calculated using standard techniques in information thermodynamics \cite{Jacobs2009second, Sagawa2009minimal, Sagawa2011erratum, Jacobs2012quantum,Faist2015minimal, Abdelkhalek2016quantum, Deffner2016quantum, Mohammady2021classicality}. The total energy cost considered here includes both heat and work because it is difficult to make a clear-cut distinction about the form of the energy for a quantum system. This, on the other hand, allows one to obtain an equality for this cost, rather than an inequality for heat or work alone. For projective measurements, the total energy cost is \cite{Abdelkhalek2016quantum}
\begin{equation}\label{eq: total cost}
    E_{\rm cost} = \Delta E^S_{\rm meas} + k_B T H,
\end{equation}
where $\Delta E^S_{\rm meas} = E$ is an internal energy change in the system due to the quantum measurement, $T$ is the temperature of the heat bath coupled to the probe, and $H:= -\sum_{i} P(i) \ln P(i)$ is the Shannon entropy of the measurement outcomes $\{P(i)\}$. Because the Shannon entropy is positive for any nonzero time $t$, the efficiency $\eta$ is bound within $[0,1]$. We note that we cannot simply replace $E_{\rm eras}$ by $E_{\rm cost}$ in $\eta'$ defined in Refs.~\cite{Alexia2017engine,Elouard2018efficient,Alexia2021short} to make the definition of the efficiency complete since we would then have a negative efficiency. With the proposed new definition \eqref{eq: efficiency}, such a problem is circumvented and the efficiencies for the engines in Refs.~\cite{Alexia2017engine,Elouard2018efficient,Alexia2021short} are again bounded within $[0,1]$. The values of the optimal efficiencies and the required conditions also remain the same.

We now examine the behavior of the maximally achievable efficiency plotted in Fig.~\ref{fig: efficiency}(b). The numerically obtained curves increase almost monotonically with increasing $\alpha$, except for a small bump in the middle. As the gradient becomes steeper, the maximum efficiency increases and becomes closer to unity. The efficiency in this large-$\alpha$ regime can analytically be calculated to be
\begin{equation}
    \eta = \frac{\frac{4J}{\alpha} \sin^2\frac{\alpha\tau}{2}}{\frac{4J}{\alpha} \sin^2\frac{\alpha\tau}{2}+ k_B T H\left(\frac{4}{\alpha^2}\sin^2\frac{\alpha\tau}{2}\right)},
\end{equation}
where $H(x):= -x\ln x - (1-x) \ln (1-x)$. It is clear that for a fixed $\alpha$, the maximum $\eta$ is obtained at $\tau^*=(2n-1)\pi/\alpha$ with $n\in \mathbb{N}$ which agrees with the optimal time for energy gain. The maximum efficiency is given by
\begin{equation}
    \eta_{\rm max} = \frac{1}{1+\frac{k_B T}{4J}\alpha H\left(\frac{4}{\alpha^2}\right)},
\end{equation}
which approaches unity for large $\alpha$ because $\frac{\alpha}{4}H\left(\frac{4}{\alpha^2}\right) \to \frac{2\ln\alpha}{\alpha}\to 0$. This possible unity efficiency is similar to the engines discussed in Refs.~\cite{Alexia2017engine,Elouard2018efficient}. The reason is that the Shannon entropy of measurement outcomes is so small that little heat is dissipated into the environment. Almost all of the energy input is converted into the potential energy of the particle.

\begin{figure}[t!]
\begin{center}
\includegraphics[width=\columnwidth]{eta_max.pdf}
\end{center}\vspace{0mm}
\caption{(a) Energy flow diagram for our engine. Analogously to the classical heat engine, the measurement probe $M$ (demon) is treated as a working agent which resets after each cycle. Differently from the classical heat engine, however, the energy resource is not a heat bath. The total energy $E_{\rm cost}$ required to run this engine consists of two parts: the cost for performing measurements and erasing information stored in the probe. Neither of them arises from a heat bath. In the erasure process, heat $Q:= E_{\rm cost} - E$ should be dissipated into a heat bath coupled to the probe. The feedback (FB) control process stores work $E$ in the form of the potential energy of the particle $S$. The efficiency \eqref{eq: efficiency} for our engine is defined analogously to the classical one. (b) The maximum efficiency for different values of $\alpha$ for $k_B T = 0.1J$ (blue), $J$ (orange), and $10J$ (green). The efficiency increases almost monotonically except for a small bump in the middle. The maximum efficiency reaches unity for a large $\alpha$. The dashed curves show the large-$\alpha$ approximation where a spurious divergence occurs at $\alpha=2$.\vspace{0mm}}
\label{fig: efficiency}
\end{figure}


\emph{Discussions.---} Our engine possesses several unique features and advantages compared with other information engines. First, it has a well-defined finite optimal time according to the task [see Fig.~\ref{fig: optimal time}(b)], which is beneficial to experiments and performance evaluation, while the thermalization time is unspecified in Ref.~\cite{Elouard2018efficient}. The optimal time is basically of the order of the Bloch oscillation period $2\pi/\alpha$ due to the competition between hopping to the right by $J$ and reflection by $\Delta$. This makes a sharp contrast with the cases in Refs.~\cite{Alexia2017engine,Sahae2023356118} where the maximum values are attained within a vanishingly short time.

Second, we find a crucial dependence on the gradient which was not analyzed in the continuous-space linear engine in Ref.~\cite{Elouard2018efficient}. The power-velocity tradeoff relationship can guide experimentalists in tuning gradient and evolution time. For example, to have the largest maximum power, one needs to use a relatively large gradient, meaning a short evolution time which may also be advantageous experimentally because a shorter implementation time means less decoherence.

Another advantage of this engine is that every step in the engine cycle can be implemented with existing experimental techniques. The Hamiltonian may be experimentally realized with an ultracold atom in an optical lattice \cite{Preiss2015strongly,Ueda2020quantum} or a qubit in a superconducting quantum processor \cite{Guo2021observation}. The projective position measurement with the single-site resolution can be achieved by quantum gas microscopy \cite{Bakr2009quantum,Sherson2010single,Haller2015single,Cheuk2015quantum,Parsons2015site,Yamamoto2017site,Okuno2020schemes,Yamamoto2020single} and the single-site addressing \cite{Weitenberg2011addressing,Viscor2012single,Fukuhara2013quantum,Wang2015coherent,Zupancic2016ultra,Koepsell2019imaging,Ji2021coupling} might be used to perform the feedback control.

A single particle on an infinite 1D tilted lattice can only oscillate within a constrained range around the initial position due to Bloch oscillations \cite{Bloch1929oscillation, Hartmann2004dynamics}. This is in stark contrast to the classical case where the particle tends to move downstairs due to a potential gradient \cite{Toyabe2010} and the quantum continuous-space linear potential where no Bloch oscillation occurs \cite{GeaBanacloche1999bouncing,Vallee2000comment,Elouard2018efficient}. However, by measurement and feedback control, we can achieve a finite velocity of unidirectional motion even for a long time. We can transport a particle beyond the realm of Bloch oscillations without resorting to Zener transitions.

% Finally, we propose a new definition of efficiency \eqref{eq: efficiency} by fully considering every possible energy flow involved in the engine cycle and clarifying their roles.


% In Fig.~\ref{fig: maximum energy, power, speed}, we show the results for the maximum value of the expected energy, power, and speed that we can get for different values of $\alpha$. It suggests that we need to choose different regimes of $\alpha$ to obtain the largest maximum power (a very large $\alpha$) and the largest maximum speed (a very small $\alpha$). The largest maximum power of our engine is shown to be $1.4492 J^2/\hbar$. The maximum power for the classical engine in Ref.~\cite{Sahae2023356118} is about $0.29 k_B T/\tau_r$ where $\tau_r$ is the relaxation time of their model. The maximum power for the quantum engine in Ref.~\cite{Alexia2017engine} is $0.5\Omega \hbar \omega_0$, where $\Omega$ is the Rabi frequency to extract energy and $\hbar\omega_0$ is the energy gap. 
%Although the systems of theirs and ours are different, it seems that the largest maximum power of our engine outperforms.

\emph{Outlook.---} In this work, we have only used projective measurements. It is interesting to continuously monitor the dynamics \cite{Ashida2017multiparticle,Bernard2018transport,Ashida2020book,Manzano2022quantum,Belenchia2020entropy,Yada2022quantum} and apply feedback control constantly as done classically \cite{Sahae2023356118}. We have also assumed cost-free feedback control. However, in modeling the feedback controller \cite{Ehrich2022energetic} or when the feedback protocol inevitably alters the quantum state \cite{Kim2011quantum}, the energy flow due to feedback control should also be considered. Another interesting direction is to investigate fundamental bounds on the performance of our engine \cite{Barato2015thermodynamic,Pietzonka2018universal,Liu2020thermodynamic,Gong2022bounds,Hamazaki2022speed}.
% [TODO: finite temperature. $\hbar\to 0$ is classical, $T\to 0$ is quantum. Maybe large $\alpha$ limit.] 

% \cite{nikiforov1988special}

%%% Acknowledgement %%%
\begin{acknowledgments}
We acknowledge David A. Sivak, Shoki Sugimoto, and Koki Shiraishi for fruitful discussions. K.L. is supported by the Global Science Graduate Course (GSGC) program of the University of Tokyo. M.N. is supported by JSPS KAKENHI Grant No. JP20K14383. M.U. is supported by KAKENHI Grant No. JP22H01152 from the Japan Society for the Promotion of Science.
\end{acknowledgments}



\bibliography{ref}

\end{document}

% We then analyze the small-$\alpha$ limit. Because in this limit the particle may spread through a relatively large range of sites, we approximate the discrete-space model by a continuous model which is a linear potential with a rigid wall at the left edge, namely the quantum bouncing ball model \cite{Gea-Banacloche1999bouncing}. Such continuous model has been used in Ref.~\cite{Elouard2018efficient} to construct a quantum information engine which is similar to our strategy. 



% While there is no wall, the energy dispersion is $E(\kappa) = -2J\cos(\kappa d)$, where $\kappa$ is the quasi-momentum and $d$ is the lattice constant. Expanding to the second order yields a kinetic-energy-like term $E(\kappa)=-2J + Jd^2\kappa^2 + \mathcal{O}(\kappa^4 d^4)$. This suggests that the effective mass can be defined as $m^* :=\frac{\hbar^2}{2Jd^2}$. We rewrite the spacial coordinates $n$ to $x:=nd$. We have the following approximated continuous-space Schrodinger equation
% \begin{equation}
%     -Jd^2\frac{{\rm d}^2\psi_{\epsilon}(x)}{{\rm d}x^2}+Fx\psi_{\epsilon}(x)=(\epsilon+2J)\psi_{\epsilon}(x),
% \end{equation}
% with the boundary condition $\psi_{\epsilon}(0)=0$. This can be solved by standard techniques. By defining $y:=x/x_0$ and $a= (\epsilon+2J)/\epsilon_0$, where $x_0:=\left(Jd^2/F\right)^{1/3}$ and $\epsilon_0:= (Jd^2 F^2)^{1/3}$, the equation is transformed into the standard Airy equation
% \begin{equation}
%     \frac{{\rm d}^2\psi_{a}(z)}{{\rm d}z^2}-z\psi_{a}(z)=0,
% \end{equation}
% where $z:=y-a$. The solution is the Airy function $\psi_{a}(z)=N_a {\rm Ai}(z)$ with boundary condition ${\rm Ai}(-a)=0$. The $m$-th ($m\ge 1$) zero of the Airy function is
% \begin{equation}
%     f_m = -f\left[\frac{3\pi}{8}(4m-1)\right],
% \end{equation}
% where $f(z):=\sum_{k=0}^{\infty}3^k \left(\frac{1}{3}\right)_k\frac{z^{3k}}{(3k)!}$ with the Pochhammer symbols defined as $\left(\alpha+\frac{1}{3}\right)_0 = 1$ and $3^k \left(\alpha+\frac{1}{3}\right)_k = (3\alpha+1)(3\alpha+4)\cdots(3\alpha+3k-2)$, for an arbitrary $\alpha$ and $k\in\mathbb{N}^+$. Therefore, the eigenvalue and the corresponding eigenfunction are
% \begin{align}
%     & \epsilon_m = -\alpha^{\frac{2}{3}}Jf_m-2J,\\
%     & \psi_m(x) = N_m {\rm Ai}\left(\alpha^{\frac{1}{3}}\frac{x}{d} +f_m\right),
% \end{align}
% where $N_m = \frac{\alpha^{\frac{1}{6}}}{\sqrt{d}{\rm Ai}'(f_m)}$ is the normalization constant for quantum state $\ket{\psi_m}$ \cite{Gea-Banacloche1999bouncing, Vallee2000comment, Goodmanson2000recursion, Robinett2010stark}.

% The initial state is $\psi(x,0)$. The state at time $t$ is
% \begin{align}
%     \ket{\psi(t)} & = U \ket{\psi(0)}\nonumber\\
%     & = \sum_{m}e^{-\frac{i\epsilon_m t}{\hbar}}g_m\ket{\psi_m},
% \end{align}
% where $g_m:= \braket{\psi_m | \psi(0)}$.

% % \begin{align}
% %     \psi(x,t) & = \bra{x} U \ket{\psi(0)}\nonumber\\
% %     & = \sum_{m}\psi_m(x) \braket{\psi_m|\psi(0)}e^{-\frac{i\epsilon_m t}{\hbar}}\nonumber\\
% %     & = \sum_m \psi_m(x) \psi_m^* (d) e^{-\frac{i\epsilon_m t}{\hbar}}.
% % \end{align}

% The expected potential energy is then
% \begin{align}
%     V(t) & = \bra{\psi(t)}F\hat{x}\ket{\psi(t)} \nonumber\\
%     & = \sum_{m,m'}g_m g_{m'} e^{-i(\epsilon_m - \epsilon_{m'})t/\hbar}\bra{\psi_{m'}}F\hat{x}\ket{\psi_m}\nonumber\\
%     & = \sum_{m,m'}g_m g_{m'} e^{i\alpha^{\frac{2}{3}}(f_m - f_{m'})\tau}\bra{\psi_{m'}}F\hat{x}\ket{\psi_m}.
% \end{align}
% We have \cite{Albright1977integrals,Goodmanson2000recursion,Robinett2010stark} for $m=m'$, $\bra{\psi_{m}}F\hat{x}\ket{\psi_m} = -\frac{2}{3}J\alpha^{\frac{2}{3}}f_m$; and for $m\ne m'$, $\bra{\psi_{m'}}F\hat{x}\ket{\psi_m}  = -\frac{2J\alpha^{\frac{2}{3}}}{(f_m-f_{m'})^2}$.


% % Because $\bra{\psi_{m'}}F\hat{x}\ket{\psi_m} = \frac{-2\alpha^{\frac{2}{3}}J}{(f_{m}-f_{m'})^2}$ for $m\ne m'$ and $\bra{\psi_{m}}F\hat{x}\ket{\psi_m} = -\frac{2}{3}\alpha^{\frac{2}{3}}J f_m$ \cite{Goodmanson2000recursion,Robinett2010stark}, we have the dimensionless potential energy
% % \begin{align}
% %     \tilde{V}(\tau) & = 2 \alpha^{\frac{2}{3}} \left[-\frac{1}{3}\sum_{m=1}^{+\infty}g_m^2 f_m -\sum_{m\ne m'} g_m g_{m'} \frac{e^{i\alpha^{\frac{2}{3}}(f_m - f_{m'})\tau}}{(f_m - f_{m'})^2}\right].
% % \end{align}


% Suppose that the initial state is a Gaussian wave packet located around $x=d$ within a narrow range, i.e., $\psi(x,0) = (\pi\sigma)^{-\frac{1}{4}}e^{-\frac{(x-d)^2}{2\sigma}}$ with $\sqrt{\sigma}\ll d$. We have \cite{Vallee2000comment,Katori2009zeros}
% \begin{align}
%     g_m & = \int_0^{+\infty}{\rm d}x (\pi\sigma)^{-\frac{1}{4}}e^{-\frac{(x-d)^2}{2\sigma}}\psi_m(x) \nonumber\\
%     & \approx \int_{-\infty}^{+\infty}{\rm d}x (\pi\sigma)^{-\frac{1}{4}}e^{-\frac{(x-d)^2}{2\sigma}}\psi_m(x)\nonumber\\
%     & = (4\pi\sigma)^{\frac{1}{4}} N_m \exp\left[\frac{\sigma}{2d^2}\left(\alpha^{\frac{2}{3}} f_m +\alpha +\frac{\sigma^2}{6d^4}\alpha^2 \right)\right] \nonumber\\
%     & \quad \times {\rm Ai}\left(f_m + \alpha^{\frac{1}{3}} + \frac{\sigma^2}{4d^4}\alpha^{\frac{4}{3}}\right) .
% \end{align}
% Nothing will be changed because the $-2J$ shift in the Hamiltonian is a constant such that the eigenfunctions are still the same while the time evolution of the potential energy depends only on the differences between two eigenvalues.

% [TODO: WKB \cite{Yakovenko1998edge}]

% We have $\sum_{m':m'\ne m}\frac{1}{(f_m-f_{m'})^2} = -\frac{f_m}{3}$ \cite{Belloni2009constraints}.

% % we have
% % \begin{align}
% %     \tilde{V}(0) & = 2 \alpha^{\frac{2}{3}} \left[-\frac{1}{3}\sum_{m=1}^{+\infty}g_m^2 f_m -\sum_{m\ne m'}  \frac{g_m g_{m'}}{(f_m - f_{m'})^2}\right]\nonumber\\
% %     & \approx 4 \alpha^{\frac{5}{3}}\frac{\sqrt{\pi \sigma}}{d}\left[-\frac{1}{3}\sum_m f_m + \frac{1}{3}\sum_m f_m\right]\nonumber\\
% %     & = 0.
% % \end{align}



% Because $\tilde{V}(0) = \alpha$, we can simplify the potential energy as
% \begin{align}
%     \tilde{V}(\tau) &= \alpha +2\alpha^{\frac{2}{3}}\sum_{m\ne m'} g_m g_{m'} \frac{1 - e^{i\alpha^{\frac{2}{3}}(f_m - f_{m'})\tau}}{(f_m - f_{m'})^2}\nonumber\\
%     & = \alpha + 8\alpha^{\frac{2}{3}}\sum_{m>m'}g_m g_{m'} \frac{\sin^2\left[\frac{1}{2}\alpha^{\frac{2}{3}}(f_m - f_{m'})\tau\right]}{(f_m - f_{m'})^2}.
% \end{align}
% Therefore the gained energy is
% \begin{equation}
%     \tilde{E}(\tau) = 8\alpha^{\frac{2}{3}}\sum_{m>m'}g_m g_{m'} \frac{\sin^2\left[\frac{1}{2}\alpha^{\frac{2}{3}}(f_m - f_{m'})\tau\right]}{(f_m - f_{m'})^2}.
% \end{equation}

% The time-average of the sine squared is $\langle \sin^2 (\omega t) \rangle = \frac{1}{2}-\frac{\sin(2\omega T)}{4\omega T}$ where $T$ is left to be chosen. To let the second term vanish for all $m$ and $m'$, it means that $\omega_{mm'} T = 2n\pi$ where $\omega_{mm'} := \frac{1}{2}\alpha^{\frac{2}{3}}(f_m-f_{m'})$. However, this seems impossible because as conjectured by Prof. Nicholas Wheeler in his essay because all $\frac{f_p-f_q}{f_r-f_s}$ seem irrational.

% % Therefore, the long-time-averaged energy is
% % \begin{equation}
% %     \langle\tilde{E}\rangle =  8\alpha^{\frac{5}{3}}\frac{\sqrt{\pi \sigma}}{d} \sum_{m>m'}\frac{1}{(f_m-f_{m'})^2}.
% % \end{equation}



% % \textbf{Question :} If the probability density $|\psi(\tilde{x},0)|^2 = \delta(\tilde{x}-1)$, then $\ket{\psi(\tau)} = 0$ because $\sqrt{\delta(x)}=0$. How to solve?

% % \textbf{Question 1:} The maximum value seems to be proportional to $\alpha$ rather than a constant? And it seems not convergent? Plot $E_{\rm max}-\tau^*$.

% % \textbf{Question 2:} The Fourier transform also suggests that the positions of the peaks are proportional to $\alpha^{2/3}$ rather than $\alpha$. Can we see this from numerical results?


% % Applying the Fourier transform with respect to $\tau$ yields
% % \begin{align}
% %     \tilde{E}(f) &= \alpha\sum_{m,m'}\delta\left(f + \left(\frac{\alpha^2}{2}\right)^{\frac{1}{3}}\frac{a_m - a_{m'}}{2\pi} \right) \nonumber\\
% %     &\quad \times \psi_{m}(1)\psi_{m'}(1)\int \tilde{x}\psi_{m}(\tilde{x})\psi_{m'}(\tilde{x}){\rm d}\tilde{x}
% % \end{align}
% % This suggests that the position of the peak is proportional to $\alpha^{2/3}$ rather than $\alpha$.

% \textbf{Zero-$\alpha$ case.} While there is no external gradient, the Hamiltonian is
% \begin{equation}
%     H = -J\sum_{n=1}^{+\infty}(\ket{n}\bra{n+1}+\ket{n+1}\bra{n}),
% \end{equation}
% with the boundary condition $\psi(n=0)=0$. We are interested in the expected speed which is defined as
% \begin{equation}
%     v(t):= \frac{\sum_{n=1}^{+\infty}\bra{\Psi(t)}n\ket{n}\braket{n|\Psi(t)}}{t}=:\frac{\langle n(t) \rangle}{t}.
% \end{equation}

% The eigenvalues and the corresponding eigenstates can be solved. We first consider a finite chain with $N-1$ sites and then take $N\to \infty$. The eigenstates are assumed to take the form of $\psi(n) = c_1 e^{ikn}+ c_2 e^{-ikn}$. The left boundary condition $\psi(n=0) =0$ gives $c_1=-c_2$. The other boundary condition $\psi(N)=0$ yields $k = \frac{m \pi}{N}$ with $m\in [1,N-1]$. Therefore, the normalized eigenstates are
% \begin{equation}
%     \psi_m(n) = \sqrt{\frac{2}{N}}\sin\frac{mn\pi}{N}.
% \end{equation}
% Multiplying $\bra{n}$ to the left of the eigenvalues equation $H\ket{\psi_m} = E_m \ket{\psi_m}$ gives
% \begin{equation}
%     -J\left[\sin\frac{m(n+1)\pi}{N}+\sin\frac{m(n-1)\pi}{N}\right] = E_m \sin\frac{mn\pi}{N}.
% \end{equation}
% This gives the eigenvalues
% \begin{equation}
%     E_m = -2J\cos\frac{m \pi}{N}.
% \end{equation}
% The eigenvalue spectrum agrees perfectly with the numerical diagonalization.

% The initial state is localized at site $1$, i.e., the leftmost site. The evolved state at time $t$ is
% \begin{align}
%     \ket{\Psi(t)} &= e^{-\frac{iHt}{\hbar}}\ket{\Psi(0)}\nonumber\\
%     & = \sum_{m=1}^{N-1} \psi_m(1)e^{-\frac{iE_m t}{\hbar}}\ket{\psi_m}.
% \end{align}

% We first look at the expected displacement $\langle n(t) \rangle$. It is
% \begin{align}
%     \langle n(t) \rangle &= \sum_{n=1}^{N-1}\bra{\Psi(t)}n\ket{n}\braket{n|\Psi(t)}\nonumber\\
%     & = \sum_{n=1}^{N-1}n\left|\sum_{m=1}^{N-1}\psi_m(1)\psi_m(n)e^{-\frac{iE_m t}{\hbar}}\right|^2\nonumber\\
%     & = \sum_{n=1}^{N-1}n\left|\sum_{m=1}^{N-1}\frac{2}{N} \sin\frac{m\pi}{N} \sin\frac{mn\pi}{N} e^{-2i\tau\cos\frac{m\pi}{N}} \right|^2.
% \end{align}




% We first check the initial condition $\langle n(0) \rangle = 1$. Because we have $\sum_{m=1}^{N-1}\frac{2}{N} \sin\frac{m\pi}{N} \sin\frac{mn\pi}{N} = \delta_{n1}$, it is obvious that the initial condition is ensured. We then try to calculate $\langle n(t) \rangle$. Because the summations over $m$ cannot be taken easily, we first consider the summation over $n$. There will be a factor $\sum_{n=1}^{N-1}n\sin\frac{mn\pi}{N}\sin\frac{m'n\pi}{N}$. Mathematica gives the results for $m\ne m'$
% \begin{widetext}
% \begin{equation}
%     \sum_{n=1}^{N-1}n\sin\frac{mn\pi}{N}\sin\frac{m'n\pi}{N}= \frac{1}{8} \left[(-1)^{m'+m}-1\right] \sin \frac{m\pi  }{M} \sin \frac{m'\pi  }{M} \csc ^2\frac{ \left(m-m'\right)\pi }{2 M}
%   \csc ^2\frac{ \left(m'+m\right)\pi }{2 M},
% \end{equation}
% \end{widetext}
% and for $m=m'$
% \begin{equation}
%     \sum_{n=1}^{N-1}n\sin\frac{mn\pi}{N}\sin\frac{mn\pi}{N}= \frac{N^2}{4}.
% \end{equation}
% Therefore, we have
% \begin{widetext}
% \begin{equation}
%     \langle n(t) \rangle = \frac{N}{2}+ \frac{1}{2N^2}\sum_{m\ne m'}^{N-1} \left[(-1)^{m'+m}-1\right]\sin^2\frac{m\pi}{N}\sin^2\frac{m'\pi}{N} \csc ^2\frac{ \left(m-m'\right)\pi }{2 M}
%   \csc ^2\frac{ \left(m'+m\right)\pi }{2 M}  e^{-2i\tau\left(\cos\frac{m\pi}{N}-\cos\frac{m'\pi}{N}\right)}.
% \end{equation}
% \end{widetext}

% An alternative way is to use the Riemann sum to convert the summation into an integral. The Riemann sum is defined as
% \begin{equation}
%     \lim_{N\to \infty}\sum_{k=1}^{N}f\left(a+\frac{b-a}{N}k\right)\frac{b-a}{N}=\int_{a}^{b}f(x){\rm d}x.
% \end{equation}
% The summation over $n$ is then
% \begin{widetext}
% \begin{align}
%     \lim_{N\to \infty}\sum_{n=1}^{N-1}\frac{n}{N^2}\sin\frac{mn\pi}{N}\sin\frac{m'n\pi}{N} = \frac{1}{\pi^2}\int_{0}^{\pi}x\sin mx \sin m'x {\rm d}x = 
%     \begin{cases}
%     \frac{2}{\pi^2}\left[(-1)^{m+m'}-1\right]\frac{mm'}{\left(m^2-m'^2\right)^2},\qquad m\ne m';\\
%     \frac{1}{4}, \qquad m=m'.
%     \end{cases}
% \end{align}
% \end{widetext}
% We arrive at
% \begin{widetext}
% \begin{equation}
%     \langle n(t) \rangle = \frac{N}{2}+ \frac{8}{\pi^2}\sum_{m\ne m'}^{N-1}\sin\frac{m\pi}{N}\sin\frac{m'\pi}{N} e^{-2i\tau\left(\cos\frac{m\pi}{N}-\cos\frac{m'\pi}{N}\right)}\left[(-1)^{m+m'}-1\right]\frac{mm'}{\left(m^2-m'^2\right)^2}.
% \end{equation}
% \end{widetext}

% We also have
% \begin{align}
%     &\lim_{N\to \infty}\sum_{m=1}^{N-1}\frac{2}{N}\sin\frac{m\pi}{N}\sin\frac{mn\pi}{N}e^{-2i\tau\cos\frac{m\pi}{N}} \nonumber\\
%     &= \frac{2}{\pi}\int_0^{\pi}{\rm d}xe^{-2i\tau\cos x}\sin x \sin nx .
% \end{align}
% Using this we can also obtain $\langle n(0) \rangle=1$.





% \begin{figure}[t!]
% \begin{center}
% \includegraphics[width=\columnwidth]{plot/eta_max.png}
% \end{center}\vspace{0mm}
% \caption{Maximum efficiency.}\vspace{0mm}
% \label{fig: efficiency}
% \end{figure}


