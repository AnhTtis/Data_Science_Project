{
    "arxiv_id": "2303.12718",
    "paper_title": "Strategy Synthesis in Markov Decision Processes Under Limited Sampling Access",
    "authors": [
        "Christel Baier",
        "Clemens Dubslaff",
        "Patrick Wienh√∂ft",
        "Stefan J. Kiebel"
    ],
    "submission_date": "2023-03-22",
    "revised_dates": [
        "2023-03-23"
    ],
    "latest_version": 1,
    "categories": [
        "cs.LG"
    ],
    "abstract": "A central task in control theory, artificial intelligence, and formal methods is to synthesize reward-maximizing strategies for agents that operate in partially unknown environments. In environments modeled by gray-box Markov decision processes (MDPs), the impact of the agents' actions are known in terms of successor states but not the stochastics involved. In this paper, we devise a strategy synthesis algorithm for gray-box MDPs via reinforcement learning that utilizes interval MDPs as internal model. To compete with limited sampling access in reinforcement learning, we incorporate two novel concepts into our algorithm, focusing on rapid and successful learning rather than on stochastic guarantees and optimality: lower confidence bound exploration reinforces variants of already learned practical strategies and action scoping reduces the learning action space to promising actions. We illustrate benefits of our algorithms by means of a prototypical implementation applied on examples from the AI and formal methods communities.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.12718v1"
    ],
    "publication_venue": "Accepted for publication at NASA Formal Methods (NFM) 2023. This is an extended version with the full appendix containing proofs, further pseudocode with explanations and additional experiment figures"
}