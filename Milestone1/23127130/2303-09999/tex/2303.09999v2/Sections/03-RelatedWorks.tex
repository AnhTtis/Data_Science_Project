\section{Related Works}
\label{sec:relatedworks}

The need for the automatic processing of CTI reports and retrieving entities and relations has pushed researchers to adopt Information Extraction methods in the field. However, this is not an easy task due to many reasons. First, information in raw text reports can be conveyed differently through semantics, and bulletin styles can differ from vendor to vendor. Furthermore, reports might (and frequently do) include new entities, making the usage of a static and non-interactive database of entity templates inefficient. Moreover, ever-changing Indicators of Compromise (IOCs, e.g., IP addresses, hashes, URLs, Bitcoin addresses) must be recognized and linked to their respective actor or malware. For these reasons, many different models have been proposed to push research on constructing a Knowledge Graph in Cybersecurity~\cite{9480953}. One of the aspects that can be noticed in the current literature on IE techniques applied to CTI reports is that many of the proposed models focus on one or a few types of entities/relations at a time while neglecting the others. This allows researchers to obtain impressive results in a narrow domain that does not always reflect the whole needs of the CTI community. Moreover, while being very efficient, using Machine Learning and Deep Learning models in Information Extraction has a few drawbacks. First, it is not easily scalable on wider domains to include more entity types and thus requires fully retraining the model while making changes to the architecture. Secondly, the training dataset might be annotated with just a few entity types, and to include other STIX types, analysts should perform the procedure all over again. This is quite time-consuming and can become very costly for companies and organizations.

In You et al.~\cite{You2022}, researchers have developed a model that can retrieve Tactics, Techniques, and Procedures (TTPs) with an accuracy of 0.941, which constitutes the state-of-the-art for this task. However, not only do TTPs not reflect the overall spectrum of Cybersecurity entities that should be extracted in a report, but the number of these TTPs is just 6. At the same time, the MITRE ATT\&CK Knowledge Base indicates at least 14 tactics and 191 techniques (just in enterprise environments and thus neglecting mobile and ICS attacks).

Similar work has been previously done by Legoy et al. with rcATT, a Python tool used to predict MITRE ATT\&CK tactics and techniques from cyber threat reports~\cite{https://doi.org/10.48550/arxiv.2004.14322}. It has a maximum precision of around 0.75 in both tactics and techniques. These reduced performance levels are justified by an increased number of labels, comprising 215 MITRE ATT\&CK techniques and 12 tactics. However, this work was published in 2020, and the MITRE ATT\&CK framework has changed with new techniques and tactics, so careful reparametrization is needed, and (as stated in the future work's sections of the paper) retraining it on a bigger dataset might improve its performance.

A more general approach that can tackle a broader domain of entities is the work of Gasmi et al.~\cite{app9193945}, which includes both entity extraction and relation extraction on data from the National Vulnerability Database (NVD)\footnote{\url{https://nvd.nist.gov/}}. Researchers addressed seven common entity types and six relationship types. This database contains CVE items, i.e., disclosed cybersecurity vulnerabilities specifically formatted to be more easily cataloged, evaluated, and shared among the community. The tool reaches a precision value of 89\% on the entity extraction task and 92\% on the relation extraction task. However, the data used for training and testing consists of vulnerability descriptions that, while written in natural language, present a common structure and thus do not reflect the variance that might be present in more common CTI reports or bulletins.

While some proposed works leverage Machine Learning models, which perform particularly well in narrow domains, other string tagging techniques can tackle the entity extraction task.

\begin{itemize}
    \item \textbf{Name-Matching Strings}: if a Knowledge Base containing the entity names is already in place inside the platform, it can match words inside a text. Even though the construction of the KB can be time-consuming, there are a lot of public sources from which to retrieve information on these entities, and it is also possible to provide aliases for each of them, thus being able to recognize pseudonyms and still link them to the correct entity.
    \item \textbf{RE-Matching Strings}: Indicators of Compromises can be found by their particular structure constant across the same type of IOC. For example, IP(v4) addresses are always be written in the format \texttt{XXX.XXX.XXX.XXX}, i.e., four sets of numbers from 0 to 255 separated by a dot character. Different rules apply to different types of entities. Still, in the domain of words with distinct character structures, it is possible to use regular expression tools to identify and extract them.
    \item \textbf{Verb-Related String}: this technique is used when the other two fail in extracting entities like companies and new malware names, which do not present any particular character structure and might not be present inside the Knowledge Base. These entities can be retrieved by analyzing each sentence through POS Tagging and Dependency Parsing. After that, we can retrieve the verb to match it with a predefined set of words that might indicate the presence of an entity.
\end{itemize}

STIXnet expands these results and further generalizes the entities and relationships that can be extracted in a document to comprise all STIX entities and relationships, which most closely represent the information an analyst should extract from CTI reports.