\section{Introduction}
\label{sec:introduction}

The increasing number of cyberattacks has concerned many people and organizations, which, now more than ever, are potentially exposing their data to breaches and attacks. In particular, companies must be aware of Advanced Persistent Threats (APTs), stealthy actors that establish a persistent presence in networks to steal information. APTs constitute one of the biggest concerns for most organizations since they are hard to identify and use complex attacks that are difficult to prevent~\cite{10.1007/978-3-662-44885-4_5}. Security experts use various types of intelligence to track their movements, motivations, and behavior to counter them. To do this, researchers analyze previous breaches to understand the techniques that APTs use, the vulnerabilities and malwares they exploit, and the tools used for their deployment~\cite{bianco2013pyramid}.

The collection and distribution of these kinds of data fall in the Cyber Threat Intelligence (CTI) field. Many researchers are involved in this discipline since, through this intelligence, companies can proactively defend against specific threat actors that might target them. In this way, organizations can protect specific assets more at risk than others and redirect their security budget in the best possible way~\cite{6657147}. For these reasons, companies must be up-to-date on the latest attacks, malwares, and techniques. To do so, they must collect intelligence by analyzing previous incidents or using external sources. Indeed, the distribution of this intelligence is provided by different vendors through reports and bulletins or by Open Source Intelligence (OSINT, i.e., any data that can be gathered for free). These reports are usually written in English and contain all the information on a particular incident or actor~\cite{WAGNER2019101589}.

The extraction of relevant information from these reports is usually performed by CTI analysts, trained to recognize the entities of interest and the relations between them. Once identified, intelligence must be annotated following certain standards to ensure machine readability and compatibility during distribution. One of the community's most popular and recognized standards is the Structured Threat Information Expression (STIX) language~\cite{barnum2012standardizing}, categorizing intelligence into different entities and relations types. However, this action can be time-consuming, given the reports' length and increased publication frequency in the last few years. To solve this issue, many attempts have been made to extract entities automatically and relations~\cite{You2022, https://doi.org/10.48550/arxiv.2004.14322, app9193945}. However, most state-of-the-art models focus on extracting a single or a few types of intelligence at a time, in which they obtain excellent results~\cite{10.1007/978-3-319-17040-4_24, 9023758}. In most real-world scenarios, the extraction of only a subset of entities and relations might not be enough to fully characterize the data contained in a report. Despite that, merging the results of different models is not trivial since conflicts might appear in the extracted data, and intelligence is often displayed through different standards and paradigms.

\textbf{Contribution.} In this paper, we present STIXnet, the first modular and extensible system for the automated extraction of all STIX entities and relationships in CTI reports. STIXnet works by leveraging different techniques, such as Natural Language Processing (NLP), to extract threat intelligence from the text of the report and identify the relevant pieces of information while also retrieving the relations among them. Our tool uses a rich Knowledge Base (KB) that contains CTI data from various sources and previous report extractions. The Knowledge Base can be enlarged with each execution and provide data for training Machine Learning (ML) and Deep Learning (DL) models used in some STIXnet modules. Through a graphical interface, the results of the STIXnet processing can be visualized as a graph in which nodes constitute entities and edges constitute relations. Each node can then be expanded with additional information stored in the database and thus provide a quick and interactive overview for each entity in the Knowledge Base. The architecture of our solution allows for the extraction of all entities and relations compliant with the STIX standard without running into structural constraints such as model retraining and dataset reannotation. In Table~\ref{tab:entities}, we show in more detail the types of entities that STIXnet can extract with respect to other models in the literature. It is worth noting that some of the models used for the comparison do not focus on STIX entities in particular, but their labels can be translated according to the STIX standard. Furthermore, in the comparison, we consider only entities that can be extracted from a report. Still, through our platform, it is possible to include entities compliant with the latest STIX 2.1 standard.

\input{Tables/01-Entities}

The main contributions of our work can be summarized as follows:
\begin{itemize}
    \item We propose the first system for automatically extracting \textbf{all} types of STIX entities (18) and relations (more than 100).
    \item We propose a novel framework for managing and coordinating several modules for Information Extraction.
    \item We propose a methodology for integrating results from different modules through a confidence value and with minimal supervision.
    \item We make our testbed (dataset and annotated reports through LabelStudio\footnote{\url{https://labelstud.io/}}) and the code for some modules available at \url{https://anonymous.4open.science/r/STIXnet-7710}.
\end{itemize}

\textbf{Organization.} The rest of the paper is organized as follows. In Section~\ref{sec:background}, we present some background on Natural Language Processing techniques and Cyber Threat Intelligence. Section~\ref{sec:relatedworks} presents a review of previous works on Information Extraction (IE) from natural language reports in the field of CTI. The proposed methodology and the pipeline are presented in Section~\ref{sec:methodology}, followed by a formal analysis of the results in Section~\ref{sec:results}. Finally, Section~\ref{sec:conclusions} concludes this work.