\chapter{Preliminary Results}\label{chap:holderchap}
%\thispagestyle{fancy} %Uncomment to put header on chapter page


The H\"older spaces play a central role in this work, so we begin by establishing some of their important properties and collecting results that will be useful in the subsequent chapters. The following expository section outlines the basic characteristics of H\"older spaces -- in Sections \ref{sec:nn} and \ref{sec:malg} we restrict attention to non-negative H\"older continuous functions, which enjoy some special pointwise properties.


\section{Elementary Properties of H\"older Spaces}


Given a connected set \(\Omega\subseteq\mathbb{R}^n\) and a positive number \(\alpha\leq 1\), a real-valued function \(f\) defined on \(\Omega\) is said to be uniformly \(\alpha\)-H\"older continuous if 
\begin{equation}\label{eq:snd}
    [f]_{\alpha,\Omega}=\sup_{\substack{x,y\in \Omega,\\x\neq y}}\frac{|f(x)-f(y)|}{|x-y|^\alpha}<\infty.
\end{equation}
The H\"older space \(C^\alpha(\Omega)\) is defined as the set of uniformly \(\alpha\)-H\"older continuous functions on \(\Omega\). Similarly, \(f\) is said to be locally \(\alpha\)-H\"older on \(\Omega\) if \([f]_{\alpha,K}<\infty\) for every compact subset \(K\) of \(\Omega\), and we denote the class of locally \(\alpha\)-H\"older functions by \(C^{\alpha}_\mathrm{loc}(\Omega)\).


Usually we write \([f]_\alpha\) if the underlying set is unambiguous. Given \(f,g\in C^\alpha(\Omega)\) it follows from \eqref{eq:snd} and the triangle inequality that \([f+g]_\alpha\leq [f]_\alpha+[g]_\alpha\), and for any \(c\in\mathbb{R}\) the homogeneity identity \([cf]_\alpha=|c|[f]_\alpha\) is also easy to verify. Therefore \eqref{eq:snd} defines a semi-norm and \(C^\alpha(\Omega)\) is a vector space under pointwise addition. Note however that this is not a proper norm, since \([f]_{\alpha,\Omega}=0\) whenever \(f\) is a constant function on \(\Omega\). 


H\"older continuity is stronger than uniform continuity, and when \(\alpha=1\) inequality \eqref{eq:snd} holds for the uniformly Lipschitz functions on \(\Omega\). We denote the space of Lipschitz functions by \(C^{0,1}(\Omega)\) to avoid confusion with \(C^1(\Omega)\), the space of continuously differentiable functions on \(\Omega\). Analogously, we write \(C^{0,1}_\mathrm{loc}(\Omega)\) to denote the space of locally Lipschitz functions.


For any \(0<\alpha\leq 1\), a simple example of an \(\alpha\)-H\"older continuous function is \(f(x)=|x|^\alpha\). A more interesting example is the Cantor function, which belongs to \(C^{\log(2)/\log(3)}([0,1])\) as we show in \Cref{sec:holdexamples}. If \(\alpha>1\) then the semi-norm \eqref{eq:snd} is only finite if \(f\) is constant; to see this, observe that if \(\alpha>1\) and \(x\in\Omega\) then
\[
    \lim_{|h|\rightarrow0}\frac{|f(x+h)-f(x)|}{|h|}\leq [f]_\alpha\lim_{|h|\rightarrow0}\frac{|h|^\alpha}{|h|}=0.
\]
It follows that all directional derivatives of \(f\) exist and are identically zero, meaning that the space \(C^\alpha(\Omega)\) is comprised of constant functions. Due to this uninteresting behaviour we do not consider \(C^\alpha(\Omega)\) for \(\alpha>1\), and henceforth we restrict our attention to \(C^\alpha(\Omega)\) for \(0<\alpha\leq 1\). 


In general, larger values of \(\alpha\) correspond to stronger continuity, with \(C^{0,1}(\Omega)\) functions being differentiable almost everywhere in \(\Omega\) by Rademacher's Theorem; see \Cref{thm:rad}. Further, if \(\Omega\) is bounded then \(C^{\beta}(\Omega)\subset C^{\alpha}(\Omega)\) whenever \(0<\alpha<\beta\). Indeed, if \(f\in C^{\beta}(\Omega)\) and \(d=\sup_{\Omega}|x-y|\) denotes the diameter of \(\Omega\), then for \(x,y\in\Omega\) we have
\[
    |f(x)-f(y)|\leq [f]_\beta|x-y|^\beta\leq [f]_\beta d^{\beta-\alpha}|x-y|^{\alpha}.
\]
Thus \([f]_\alpha\leq[f]_\beta d^{\beta-\alpha}\) and \(f\in C^\alpha(\Omega)\). Even when \(\Omega\) may be unbounded, if \(f\in C^{\alpha}(\Omega)\cap C^{\beta}(\Omega)\) for \(0<\alpha<\beta\) then \(f\in C^{\gamma}(\Omega)\) whenever \(\alpha<\gamma<\beta\). This is because for distinct points \(x,y\in\Omega\),
\begin{equation}\label{eq:sninterp}
    \bigg(\frac{|f(x)-f(y)|}{|x-y|^\gamma}\bigg)^{\beta-\alpha}=\bigg(\frac{|f(x)-f(y)|}{|x-y|^\alpha}\bigg)^{\beta-\gamma}\bigg(\frac{|f(x)-f(y)|}{|x-y|^\beta}\bigg)^{\gamma-\alpha}.
\end{equation}
From this estimate it follows after taking a supremum that \([f]_\gamma^{\beta-\alpha}\leq [f]_\alpha^{\beta-\gamma}[f]_\beta^{\gamma-\alpha}\). 


For many applications it is useful to restrict one's attention to the set of bounded \(\alpha\)-H\"older continuous functions defined on \(\Omega\), and we denote the set of these functions by \(C^\alpha_b(\Omega)\). Clearly \(C^\alpha_b(\Omega)\subseteq C^\alpha(\Omega)\), and the two spaces are equal when \(\Omega\) is compact. The vector space of bounded \(\alpha\)-H\"older continuous functions, unlike \(C^\alpha(\Omega)\), can be equipped with the following norm
\[
    \|f\|_{C_b^{\alpha}(\Omega)}=\sup_\Omega|f|+[f]_{\alpha,\Omega}.
\]
Indeed, given this norm \(C_b^{\alpha}(\Omega)\) is a Banach space, as we discuss later in the chapter. 

For the purpose of our main results, a boundedness condition is often needlessly restrictive since it is not satisfied even by simple functions like \(f(x)=|x|^\alpha\) defined over \(\mathbb{R}^n\). Thus, most of the time we work with the simplest H\"older space \(C^\alpha(\Omega)\), and it is only for some results like \Cref{thm:almostthere} that we find it necessary to restrict attention to \(C^\alpha_b(\Omega)\). In passing however, we note that the norm on \(C^\alpha_b(\Omega)\) defined above enjoys the following interpolation property.


\begin{lem}
If \(f\in C_b^\alpha(\Omega)\cap C_b^\beta(\Omega)\) and \(0<\alpha<\gamma<\beta\) then \(\|f\|_{C_b^\gamma(\Omega)}^{\beta-\alpha}\leq \|f\|_{C_b^\alpha(\Omega)}^{\beta-\gamma}\|f\|_{C_b^\beta(\Omega)}^{\gamma-\alpha}\).
\end{lem}


\begin{proof} The semi-norm interpolation given by \eqref{eq:sninterp} shows that if \(s=\frac{\gamma-\alpha}{\beta-\alpha}\) and \(\lambda=\frac{[f]_\alpha}{\|f\|_{C_b^\alpha(\Omega)}}\), then
\[
    [f]_\gamma+\sup_\Omega|f|\leq [f]_\alpha^{1-s}[f]_\beta^s+\sup_\Omega|f|^{1-s}\sup_\Omega|f|^s=\|f\|_{C_b^\alpha(\Omega)}^{1-s}\bigg(\lambda\bigg(\frac{[f]_\beta}{\lambda}\bigg)^s+(1-\lambda)\bigg(\frac{\sup_\Omega|f|}{1-\lambda}\bigg)^s\bigg).    
\]
The mapping \(t\mapsto t^s\) is concave since \( 0<s< 1\), and as \(\lambda\leq 1\) it follows from \Cref{lem:convexity} that
\[
     \lambda\bigg(\frac{[f]_\beta}{\lambda}\bigg)^s+(1-\lambda)\bigg(\frac{\sup_\Omega|f|}{1-\lambda}\bigg)^s\leq \big([f]_\beta+\sup_\Omega|f|\big)^s=\|f\|_{C_b^\beta(\Omega)}^s.
\]
Therefore \(\|f\|_{C_b^\gamma(\Omega)}\leq \|f\|_{C_b^\alpha(\Omega)}^{1-s}\|f\|_{C_b^\beta(\Omega)}^{s}\), which yields the claimed interpolation.
\end{proof}


Some other norm inequalities for uniformly bounded H\"older functions are worth noting. If \(f,g\in C_b^\alpha(\Omega)\) for a set \(\Omega\subseteq\mathbb{R}^n\) not necessarily bounded, we have for \(x,y\in\Omega\) that
\[
    |f(x)g(x)-f(y)g(y)|\leq \sup_\Omega|f||g(x)-g(y)|+\sup_\Omega|g||f(x)-f(y)|.
\]
It follows that \([fg]_\alpha\leq \sup_\Omega|f|[g]_\alpha+\sup_\Omega|g|[f]_\alpha\) and \(\|fg\|_{C_b^\alpha(\Omega)}\leq \|f\|_{C_b^\alpha(\Omega)}\|g\|_{C_b^\alpha(\Omega)}\), meaning that the norm of \(C_b^\alpha(\Omega)\) is sub-multiplicative. Additionally, if \(\alpha<\beta\) then from Young's inequality (see \Cref{cor:young}) it follows that
\[
    \|g\|_{C_b^\alpha(\Omega)}=\sup_\Omega|g|+\sup_{\substack{x,y\in \Omega,\\x\neq y}}\frac{|g(x)-g(y)|}{|x-y|^\alpha}\leq \frac{\alpha}{\beta}\sup_{\substack{x,y\in \Omega,\\x\neq y}}\frac{|g(x)-g(y)|}{|x-y|^\beta}+\bigg(3-\frac{2\alpha}{\beta}\bigg)\sup_\Omega|g|\leq 3\|g\|_{C_b^\beta(\Omega)}.
\]
Thus if \(f\in C_b^{\alpha}(\Omega)\) and \(g\in C_b^{\beta}(\Omega)\), and if \(\gamma=\min\{\alpha,\beta\}\), then \(\|fg\|_{C_b^{\gamma}(\Omega)}\leq 3\|f\|_{C_b^{\alpha}(\Omega)}\|g\|_{C_b^{\beta}(\Omega)}\). %This shows that a product of H\"older continuous functions is at least as strongly continuous as its worst factor. Note that none of these estimates requires boundedness of the domain \(\Omega\).


Next we discuss higher-order H\"older spaces, denoting by \(C^{k,\alpha}(\Omega)\) the set of \(k\)-times continuously differentiable functions on \(\Omega\) whose \(k^\mathrm{th}\)-order derivatives are \(\alpha\)-H\"older continuous on \(\Omega\). To describe these spaces concisely, it is convenient to introduce multi-index notation. A multi-index of length \(n\) is an \(n\)-tuple of non-negative integers \(\beta=(\beta_1,\dots,\beta_n)\), and addition of multi-indices is defined entry-wise. The order of \(\beta\) is given by \(|\beta|=\beta_1+\cdots+\beta_n\) so that \(|\beta+\gamma|=|\beta|+|\gamma|\), and the \(\beta\)-derivative of a function \(f\) is then defined as the order-\(|\beta|\) derivative given by
\[
    \partial^\beta f=\frac{\partial^{|\beta| }f}{\partial^{\beta_1}x_1\cdots\partial^{\beta_n}x_n}.
\]
If \(|\beta|=0\) then \(\beta=(0,\dots,0)\), and to keep notation simple in this case we set \(\partial^\beta f=f\). 


Equipped with multi-index notation, we say that a function \(f\) belongs to \(C^{k,\alpha}(\Omega)\) if \([\partial^\beta f]_{\alpha,\Omega}\) is finite for every multi-index \(\beta\) of order \(|\beta|=k\). Likewise, we define \(C^{k,\alpha}_\mathrm{loc}(\Omega)\) to be the vector space of functions \(f\) for which \([\partial^\beta f]_{\alpha,K}\) is finite whenever \(K\) is a compact subset of \(\Omega\) and \(|\beta|=k\). Finally, we denote by \(C_b^{k,\alpha}(\Omega)\) the subspace of \(C^{k,\alpha}(\Omega)\) comprised of uniformly bounded functions on \(\Omega\). It is easy to see that these three spaces coincide when \(\Omega\) is compact, but in general they are distinct.


By indexing over \(|\beta|\leq k\), we mean to reference every multi-index of a fixed length \(n\) whose order is at most \(k\). Adopting this convention we can define the following norm on \(C_b^{k,\alpha}(\Omega)\),
\begin{equation}\label{eq:holdernorm}
    \|f\|_{C^{k,\alpha}_b(\Omega)}=\sum_{|\beta|\leq k}\sup_\Omega|\partial^\beta f|+\sum_{|\beta|=k}[\partial^\beta f]_{\alpha,\Omega}.
\end{equation}
Once again, for the purposes of our later decomposition results it is unnecessary to restrict attention to bounded \(C^{k,\alpha}(\Omega)\) functions except in some special settings. Wherever a boundedness condition is needed, we state the requirement explicitly.


To express our main results more concisely, we explain exactly what we mean when we refer to `half-regular' spaces of functions. Fixing a H\"older space \(C^{k,\alpha}(\Omega)\), we define
\begin{equation}\label{eq:rootspaces}
    C^{\frac{k+\alpha}{2}}(\Omega)=\begin{cases}
    \hfil C^{\frac{k}{2},\frac{\alpha}{2}}(\Omega) & k\textrm{ even},\\
    C^{\frac{k-1}{2},\frac{1+\alpha}{2}}(\Omega) & k\textrm{ odd}.
    \end{cases}
\end{equation}
This space consists of functions which are essentially `half' as differentiable as those in \(C^{k,\alpha}(\Omega)\), and likewise the highest-order derivatives of said functions retain `half' of the H\"older continuity.


Our main result in the next chapter demonstrates that remarkably, every non-negative \(C^{k,\alpha}(\mathbb{R}^n)\) function can be written as a finite sums of squares of functions belonging to the half-regular space whenever \(k\leq 3\), and \(0<\alpha\leq 1\). This is true in any number of dimensions, and our results further show that the functions \(g_1,\dots,g_m\) in \eqref{eq:sos} and their derivatives can be controlled pointwise in a straightforward way -- see \Cref{thm:c3main} and the ensuing discussion. For \(k\geq 4\) matters are more complicated, as we discuss in \Cref{chap:higher}, but nevertheless we recover some partial results even in that more difficult setting.


In proving the aforementioned decomposition results we will frequently use a sub-product rule for H\"older semi-norms, like that employed by Sawyer \& Korobenko in \cite[Eq. (3.10)]{SOS_I} to prove a \(C^{4,\alpha}(\mathbb{R}^n)\) decomposition result. Before stating this rule, we must introduce some additional multi-index notation. On the collection of multi-indices of a fixed length \(n\), there exists a natural partial ordering given by writing \(\beta\leq \gamma\) for \(\beta=(\beta_1,\dots,\beta_n)\) and \(\gamma=(\gamma_1,\dots,\gamma_n)\) if \(\gamma_j\leq \beta_j\) for each \(j=1,\dots,n\). If \(\gamma\leq \beta\) then \(\beta-\gamma=(\beta_1-\gamma_1,\dots,\beta_n-\gamma_n)\) is also a multi-index, and we can define a generalized binomial coefficient by setting 
\begin{equation}\label{eq:binom}
    \binom{\beta}{\gamma}=\frac{\beta!}{\gamma!(\beta-\gamma)!},
\end{equation}
where \(\beta!=\beta_1!\cdots\beta_n!\) is a multi-index factorial. To indicate that we are summing over all multi-indices \(\gamma\) that are below \(\beta\) in the partial ordering described above, we use the subscript \(\gamma\leq\beta\). The utility of this notation is illustrated by the following well-known generalization of the product rule, whose proof we omit.


\begin{lem}[General Leibniz Rule]\label{lem:Leib}
Let \(f,g\in C^k(\mathbb{R}^n)\), and suppose that \(|\beta|\leq k\). Then
\[
    \partial^\beta(fg)=\sum_{\gamma\leq\beta}\binom{\beta}{\gamma}(\partial^\gamma f)(\partial^{\beta-\gamma}g).
\]
\end{lem}


Equipped with this result and the versatile notation afforded by multi-indices, we now state and prove the aforementioned sub-product rule of Sawyer \& Korobenko for H\"older semi-norms.


\begin{lem}\label{lem:subprod}
Let \(f,g\in C^{k,\alpha}(\Omega)\) for \(0<\alpha\leq 1\). If \(\beta\) is any multi-index for which \(|\beta|\leq k\) then 
\[
    [\partial^\beta(fg)]_{\alpha,\Omega}\leq\sum_{\gamma\leq\beta}\binom{\beta}{\gamma}([\partial^{\beta-\gamma}f]_{\alpha,\Omega}\sup_{\Omega}|\partial^\gamma g|+[\partial^{\beta-\gamma}g]_{\alpha,\Omega}\sup_{\Omega}|\partial^\gamma f|).
\]
\end{lem}


\begin{proof}
Using \Cref{lem:Leib}, we first expand the difference \(\partial^\beta(fg)(x)-\partial^\beta(fg)(y)\) as follows,
\begin{align*}
    |\partial^\beta(fg)(x)-&\partial^\beta(fg)(y)|=\bigg|\sum_{\gamma\leq\beta}\binom{\beta}{\gamma}(\partial^{\beta-\gamma}f(x)\partial^\gamma g(x)-\partial^{\beta-\gamma}f(y)\partial^\gamma g(y))\bigg|\\
    &=\bigg|\sum_{\gamma\leq\beta}\binom{\beta}{\gamma}((\partial^{\beta-\gamma}f(x)-\partial^{\beta-\gamma}f(y))\partial^\gamma g(x)+(\partial^\gamma g(x)-\partial^\gamma g(y))\partial^{\beta-\gamma} f(y))\bigg|.
\end{align*}
Using the triangle inequality, we see now that \(|\partial^\beta(fg)(x)-\partial^\beta(fg)(y)|\) is bounded from above by
\[
    \sum_{\gamma\leq\beta}\binom{\beta}{\gamma}(|\partial^{\beta-\gamma}f(x)-\partial^{\beta-\gamma}f(y)|\sup_\Omega|\partial^\gamma g|+|\partial^\gamma g(x)-\partial^\gamma g(y)|\sup_\Omega|\partial^{\beta-\gamma} f|).
\]
Dividing this sum by \(|x-y|^\alpha\) and taking a supremum over \(x,y\in\Omega\), the claimed semi-norm estimate for \(\partial^\beta(fg)\) follows immediately from sub-additivity of the supremum. 
\end{proof}


In \cite{Bony2}, Bony introduces a pointwise variant of the \(\alpha\)-H\"older semi-norm, which is also employed by Sawyer \& Korobenko in \cite{SOS_I}. This operator is defined for \(0<\alpha\leq 1\) by setting
\begin{equation}\label{eq:pwop}
    [f]_{\alpha}(x)=\limsup_{y,z\rightarrow x}\frac{|f(y)-f(z)|}{|y-z|^\alpha}.
\end{equation}
We use this pointwise operator, rather than the standard H\"older semi-norm, in order to extend pointwise H\"older estimates to global ones in \Cref{chap:decomps}, without fixing an underlying set. Like the usual H\"older semi-norm, this pointwise variant is subadditive, homogeneous, and it can be used to recover the usual H\"older semi-norm via the identity 
\[
    [f]_{\alpha,\Omega}=\sup_{x\in\Omega}[f]_{\alpha}(x).
\]
Moreover, \eqref{eq:pwop} satisfies a sub-product rule just like the usual H\"older semi-norm. The proof of the following variant of this inequality is identical to that of \Cref{lem:subprod}, so we omit it.


\begin{lem}\label{lem:sharpsubprod}
Let \(f,g\in C^{k,\alpha}(\Omega)\) for \(0<\alpha\leq 1\). If \(\beta\) is any multi-index for which \(|\beta|\leq k\) then
\[
    [\partial^\beta(fg)]_{\alpha}(x)\leq\sum_{\gamma\leq\beta}\binom{\beta}{\gamma}([\partial^{\beta-\gamma}f]_{\alpha}(x)|\partial^\gamma g(x)|+[\partial^{\beta-\gamma}g]_{\alpha}(x)|\partial^\gamma f(x)|).
\]
\end{lem}


Such objects as the local semi-norm allow us to argue locally in terms of the pointwise behaviour, before combining local estimates and taking a supremum over a larger domain to recover global H\"older estimates. The utility of this approach will become apparent in the proof of \Cref{thm:c3main}. 


For completeness of this expository section, we also state some more advanced properties of the higher-order H\"older spaces. The first is a well-known and often useful property of the H\"older spaces of uniformly bounded functions; its proof is a standard exercise in graduate analysis, and we furnish a straightforward argument using the Fundamental Theorem of Calculus.


\begin{thm}
The space \(C_b^{k,\alpha}(\Omega)\) equipped with the norm \eqref{eq:holdernorm} is a Banach space.
\end{thm}



\begin{proof} Recall that a Banach space is a complete normed vector space. We have already established that \(C_b^{k,\alpha}(\Omega)\) is a normed vector space, leaving us to show completeness. If \(\{f_j\}\) is Cauchy in \(C_b^{k,\alpha}(\Omega)\) equipped with the norm \eqref{eq:holdernorm}, and if \(|\beta|\leq k\), then \(\{\partial^\beta f_j\}\) is Cauchy in \(C_b^0(\Omega)\), the space of uniformly continuous functions on \(\Omega\) equipped with the supremum norm. Since \(C^0_b(\Omega)\) is complete, we conclude that \(\{\partial^\beta f_j\}\) converges uniformly to a function \(f_\beta\in C_b^0(\Omega)\). For convenience, we define \(f=\displaystyle\lim_{j\rightarrow\infty}f_j\), noting that \(f\in C^0_b(\Omega)\).


Using induction on \(m\), we next show that \(\partial^\beta f=f_\beta\) for every \(\beta\) of order \(m\leq k\). In other words, the limits of the derivatives of the sequence \(\{f_j\}\) agree with the derivatives of its limits.  If \(m=0\) this follows from our definition of \(f\), giving a base case. Suppose now that \(\partial^\beta f=f_\beta\) whenever \(|\beta|=m\), and let \(\partial^\mu =\partial_i\partial^\beta \) be a derivative of order \(m+1\). Let \(e_i\) denote the \(i^\textrm{th}\) basis vector of \(\mathbb{R}^n\), and for \(x\) belonging to the interior of \(\Omega\) choose \(h\in\mathbb{R}\) small enough that \(x+he_i\in\Omega\). Proceeding with these selections, we see from the Fundamental Theorem of Calculus Part II that
\[
    \partial^\beta f(x+he_i)-\partial^\beta f(x)=\lim_{j\rightarrow\infty}\int_0^h\partial_{i}\partial^\beta f_j(x+te_i)dt
\]
Moreover, since \(\{\partial^\mu f_j\}\) is Cauchy in \(C^{0}_b(\Omega)\) we see that \(\sup_\Omega|\partial_i\partial^\beta f_j|\) is bounded independent of \(j\). It follows from the Dominated Convergence Theorem that
\[
    \partial^\beta f(x+he_i)-\partial^\beta f(x)=\int_0^h\lim_{j\rightarrow\infty}\partial_{i}\partial^\beta f_j(x+te_i)dt=\int_0^h f_\mu(x+te_i)dt.
\]
Taking a derivative of the identity above, the Fundamental Theorem of Calculus Part I shows that \(\partial^\mu f=f_\mu\). Hence \(\partial^\beta f=f_\beta\) whenever \(|\beta|\leq k\), meaning that \(\partial^\beta f_j\) converges uniformly to \(\partial^\beta f\) and the space \(C^k_b(\Omega)\) is complete.


It remains to show that \(\partial^\beta f\in C^\alpha_b(\Omega)\) whenever \(|\beta|=k\). For \(x,y\in\Omega\) we have
\[
        \frac{|\partial^\beta f(x)-\partial^\beta f(y)|}{|x-y|^\alpha}=\lim_{j\rightarrow\infty}\frac{|\partial^\beta f_j(x)-\partial^\beta f_j(y)|}{|x-y|^\alpha}\leq \limsup_{j\rightarrow\infty}\;[\partial^\beta f_j]_{\alpha,\Omega} \leq \lim_{j\rightarrow\infty}\|f_j\|_{C_b^{k,\alpha}(\Omega)}.
\]
The limit on the right converges since \(\{f_j\}\) is Cauchy in \(C_b^{k,\alpha}(\Omega)\), so by taking a supremum over \(x,y\in\Omega\) we find that \([\partial^\beta f]_\alpha<\infty\) whenever \(|\beta|=k\), showing that \(f\in C_b^{k,\alpha}(\Omega)\). Since \(\{f_j\}\) was any Cauchy sequence, it follows that \(C_b^{k,\alpha}(\Omega)\) is complete as claimed.
\end{proof}


Earlier we showed that if \(\alpha< \beta\), then the space \(C^{\beta}(\Omega)\) is embedded in \(C^{\alpha}(\Omega)\), provided that either \(\Omega\) is bounded or that we restrict to uniformly bounded functions. It is worth noting that the latter is a compact embedding, meaning that if \(\{f_j\}\) is a bounded sequence in the norm of \(C_b^\alpha(\Omega)\) then it has a subsequence convergent in the norm of \(C_b^\beta(\Omega)\). More generally we have the following result, which is a standard but more advanced property of H\"older spaces that is stated and proved in \cite[Lemma 6.33]{GilbargTrudinger} as well as in \cite[Theorem 24.14]{Driver}.


\begin{lem}\label{lem:cptmb}
Let \(0<\alpha,\beta\leq 1\), and let \(j\) and \(k\) be non-negative integers. If \(k+\alpha<j+\beta\) then \(C_b^{j,\beta}(\Omega)\) is compactly embedded in \(C_b^{k,\alpha}(\Omega)\).
\end{lem}


Indeed, \cite{GilbargTrudinger} and \cite{Driver} both contain a thorough development of the properties of H\"older spaces that go beyond the scope of this thesis, but which are relevant to the widespread applications of H\"older spaces in the study of partial differential equations. The reader wishing to explore these spaces further is encouraged to consult the works cited throughout this chapter, and also to see \Cref{sec:holdexamples} for some interesting examples of \(\alpha\)-H\"older continuous functions. 


Next, we establish a useful property of the Taylor polynomials of H\"older continuous functions.


\begin{lem}\label{lem:Taylorest}
Let \(f\in C^{k,\alpha}(\Omega)\). If \(|\beta|<k\) then there exists a constant \(C\) such that for any \(x,y\in\Omega\) the following inequality holds,
\begin{equation}\label{eq:taylorest}
    |\partial^\beta f(x)-\partial^\beta f(y)|\leq \sum_{0\leq |\gamma|\leq k-|\beta|}\frac{1}{\gamma!}|x-y|^{|\gamma|}|\partial^{\beta+\gamma} f(x)|+C|x-y|^{k-|\beta|+\alpha}.    
\end{equation}
\end{lem}


\begin{proof}
Let \(\beta\) be any multi-index of length \(n\) and order \(|\beta|<k\). We begin by using \Cref{thm:taylorthm} to form a Taylor expansion for \(\partial^\beta f\) evaluated at \(y\in\Omega\) and centred at \(x\in\Omega\),
\[
    \partial^\beta f(y)=\sum_{0\leq |\gamma|<k-|\beta|}\frac{1}{\gamma!}\partial^{\beta+\gamma} f(x)(y-x)^\gamma+\sum_{|\gamma|=k-|\beta|}\frac{|\gamma|}{\gamma!}(y-x)^\gamma\int_0^1(1-t)^{|\gamma|-1}\partial^{\beta+\gamma}f(x+t(y-x))dt.
\]
To refine this, we observe that the integral on the right-hand side can be rewritten in the form
\[
    \frac{1}{|\gamma|}\partial^{\beta+\gamma}f(x)+\int_0^1(1-t)^{|\gamma|-1}(\partial^{\beta+\gamma}f(x+t(y-x))-\partial^{\beta+\gamma}f(x))dt.
\]
Consequently, if \(|\beta|+|\gamma|=k\) we may use that \(f\in C^{k,\alpha}(\Omega)\) by assumption to make the estimate 
\[
    |\gamma|\int_0^1(1-t)^{|\gamma|-1}\partial^{\beta+\gamma}f(x+t(y-x))dt\leq |\partial^{\beta+\gamma}f(x)|+[\partial^{\beta+\gamma}f]_{\alpha,\Omega}|\gamma||x-y|^\alpha\int_0^1(1-t)^{|\gamma|-1}t^\alpha dt.
\]
The integral on the right-hand side is bounded by \(1/|\gamma|\), meaning that the item on the left is bounded by \(\partial^{\beta+\gamma}f(x)+[\partial^{\beta+\gamma}f]_{\alpha,\Omega}|x-y|^\alpha\). Rearranging our initial Taylor expansion and applying this estimate affords \eqref{eq:taylorest} with \(C=\sum_{|\gamma|=k-|\beta|}[\partial^{\beta+\gamma}f]_{\alpha,\Omega}/\gamma!\).
\end{proof}


Much can be gleaned from the Taylor polynomials of functions belonging to H\"older spaces, and in the next section we exploit several useful properties of the Taylor polynomials of non-negative H\"older continuous functions. To close this section, we prove a useful `recombination' result which will be important in our later construction of sum of squares decompositions. Recall that two functions are said to have disjoint supports if they are not both nonzero at any point.


\begin{lem}\label{lem:recomb}
Let \(\{f_j\}\) be a countable collection of non-negative \(C^{k,\alpha}(\Omega)\) functions with pairwise disjoint supports. Assume that for each \(\beta\) with \(|\beta|\leq k \), the bound \([\partial^\beta f_j]_\alpha\leq C\) holds for a \(C\) independent of \(j\). Then the following function is also in \(C^{k,\alpha}(\Omega)\),
\[
    F=\sum_{j=1}^\infty f_j.
\]
\end{lem}


\begin{proof}
%Fix a multi-index \(\beta\) of order \(|\beta|\leq k\) and observe that for each \(x\in\Omega\) we can write \(\partial^\beta F(x)=\partial^\beta f_j(x)\) for some \(j\in\mathbb{N}\), meaning that \(|\partial^\beta F(x)|\leq C_1\) owing to the bound on \(\sup_\Omega|f_j|\). Since \(x\) was arbitrary, we conclude that \(\sup_\Omega|\partial^\beta F|\leq C_1\).

Fix a multi-index \(\beta\) of order \(k\) and let \(x,y\in\Omega\). Assume without loss of generality that \(F(x)=f_i(x)\) and \(F(y)=f_j(y)\) for some \(i,j\in\mathbb{N}\). If \(i=j\) then 
\[
    \frac{|\partial^\beta F(x)-\partial^\beta F(y)|}{|x-y|^\alpha}=\frac{|\partial^\beta f_i(x)-\partial^\beta f_i(x)|}{|x-y|^\alpha}\leq C.
\]
On the other hand, if \(i\neq j\) then \(\partial^\beta F(x)=\partial^\beta f_i(x)+\partial^\beta f_j(x)\) and \(\partial^\beta F(y)=\partial^\beta f_i(y)+\partial^\beta f_j(y)\), since the functions comprising \(f\) have pairwise disjoint support. Thus the triangle inequality,
\[
    \frac{|\partial^\beta F(x)-\partial^\beta F(y)|}{|x-y|^\alpha}\leq \frac{|\partial^\beta f_i(x)-\partial^\beta f_i(y)|}{|x-y|^\alpha}+\frac{|\partial^\beta f_j(x)-\partial^\beta f_j(y)|}{|x-y|^\alpha}\leq 2C.
\]
Since \(x\) and \(y\) were arbitrary points in \(\Omega\), we conclude that \([\partial^\beta F]_\alpha\leq 2C\) as required. 
\end{proof}


\section{Non-Negative Functions in H\"older Spaces}\label{sec:nn}


For the remainder of this thesis, we work to decompose non-negative functions in H\"older spaces -- accordingly, in this section we investigate the pointwise properties of such functions. Perhaps the most useful result we obtain is a set of inequalities which essentially show that the functions we study are controlled pointwise by their even-order derivatives. An early result of this type is an inequality of Malgrange, which is often attributed to Glaeser who published it in \cite{Glaeser}. Malgrange found that if \(f\in C^2(\mathbb{R})\) is non-negative and \(\sup_\mathbb{R}|f''|\leq M\), then
\begin{equation}\label{eq:ogmalg}
    |f'(x)|\leq \sqrt{2Mf(x)}    
\end{equation}
for every \(x\in\mathbb{R}\). By working in H\"older spaces we can refine this estimate and remove the boundedness condition. Moreover, we can obtain generalizations of \eqref{eq:ogmalg} to higher dimensions. These estimates will be critical to our study of \(C^{1,\alpha}(\mathbb{R}^n)\) functions.


Before moving on to more advanced estimates, we establish some basic properties of non-negative H\"older continuous functions. We begin with the observation that if \(f\in C^\alpha(\Omega)\) for an arbitrary domain \(\Omega\), then \(|f|\in C^\alpha(\Omega)\) with \([|f|]_\alpha\leq [f]_\alpha\). This is because
\[
    ||f(x)|-|f(y)||\leq |f(x)-f(y)|\leq [f]_\alpha|x-y|^\alpha.
\]
For \(k\geq 1\) however, it is not true in general that \(|f|\in C^{k,\alpha}(\Omega)\) whenever \(f\in C^{k,\alpha}(\Omega)\). Indeed if \(f\) is a function in \(C^{1,\alpha}(\Omega)\) which has a zero that is not also a local minimum point, then \(|f|\) will have a cusp. It follows that a first-order derivative of \(|f|\) may not even be continuous, let alone \(\alpha\)-H\"older continuous for some \(\alpha>0\). 


We avoid this difficulty by restricting attention to non-negative functions for the remainder of this chapter.Our first result concerning the behaviour of the powers and roots of non-negative H\"older continuous functions is the following.


\begin{lem}\label{lem:smallpow}
Suppose that \(f\) is a non-negative function and let \(0\leq\beta\leq 1\). Then for any \(x,y\) in the domain of \(f\),
\begin{equation}\label{eq:concave}
    |f(x)^\beta-f(y)^\beta|\leq |f(x)-f(y)|^\beta.
\end{equation}
\end{lem}


\begin{proof}
First we show that if \(\beta\leq 1\) then \((a+b)^\beta\leq a^\beta+b^\beta\) for \(a,b\geq 0\). Set \(k=a^\beta/(a^\beta+b^\beta)\), and observe that \(k\leq k^\beta\) and \((1-k)\leq (1-k)^\beta\) since \(k\leq 1\). Therefore
\[
    \frac{(a+b)^\beta}{a^\beta+b^\beta}=(k^\frac{1}{\beta}+(1-k)^\frac{1}{\beta})^\beta\leq (k+1-k)^\beta=1,
\]
giving the claimed estimate. Now we take \(a=|f(x)-f(y)|\) and \(b=f(y)\) to obtain the bound
\[
    f(x)^\beta \leq (|f(x)-f(y)|+|f(y)|)^\beta\leq |f(x)-f(y)|^\beta+f(y)^\beta.
\]
Thus \(f(x)^\beta-f(y)^\beta\leq |f(x)-f(y)|^\beta\), and interchanging \(x\) and \(y\) gives inequality \eqref{eq:concave}.
\end{proof}


\begin{cor}\label{cor:easycase}
If \(f\in C^\alpha(\Omega)\) is non-negative and \(\beta\leq 1\), then \(f^\beta\in C^{\alpha\beta}(\Omega)\) and \([f^\beta]_{\alpha\beta}\leq [f]_\alpha^\beta\). In particular, if \(f\in C^\alpha(\Omega)\) then \(\sqrt{f}\in C^\frac{\alpha}{2}(\Omega)\).
\end{cor}


We can obtain a similar estimate, albeit a slightly more complicated one, when \(\beta>1\).


\begin{lem}\label{lem:almostLipschitz}
Suppose that \(f\in C^{\alpha}(\Omega)\) is non-negative and let \(\beta>1\) and \(\varepsilon>0\). Then for any two points \(x,y\in\Omega\),
\[
    |f(x)^\beta-f(y)^\beta|\leq \frac{(1+\varepsilon)[f]_\alpha^\beta}{((1+\varepsilon)^\frac{1}{\beta-1}-1)^{\beta-1}}|x-y|^{\alpha\beta}+\varepsilon\max\{f(x)^\beta,f(y)^\beta\}.
\]
\end{lem}


\begin{proof}
For a number \(0<\lambda<1\) to be chosen momentarily, observe that Jensen's inequality gives
\[
    f(x)^\beta\leq\frac{1}{\lambda^\beta}(\lambda|f(x)-f(y)|+\lambda f(y))^\beta\leq \frac{1}{\lambda^{\beta-1}}|f(x)-f(y)|^\beta+\frac{1}{(1-\lambda)^{\beta-1}} f(y)^\beta.
\]
Rearranging and applying the H\"older estimate \(|f(x)-f(y)|^\beta\leq [f]_\alpha^\beta|x-y|^{\alpha\beta}\) thus shows that
\[
    f(x)^\beta-f(y)^\beta\leq \frac{[f]_\alpha^\beta}{\lambda^{\beta-1}}|x-y|^{\alpha\beta}+\bigg(\frac{1}{(1-\lambda)^{\beta-1}}-1\bigg)f(y)^\beta.
\]
Next select \(\lambda=1-(1+\varepsilon)^{-\frac{1}{\beta-1}}\), so that the coefficient on the last term is exactly \(\varepsilon\) and
\[
    f(x)^\beta-f(y)^\beta\leq \frac{(1+\varepsilon)[f]_\alpha^\beta}{((1+\varepsilon)^\frac{1}{\beta-1}-1)^{\beta-1}}|x-y|^{\alpha\beta}+\varepsilon f(y)^\beta.
\]
Interchanging \(x\) and \(y\) and then taking a maximum, we obtain the desired result.
\end{proof}


By taking \(\beta=\frac{1}{\alpha}\) we obtain the following special case that will be useful to us in \Cref{chap:decomps}.


\begin{cor}
If \(f\in C^\alpha(\Omega)\) is non-negative, then \(f^\frac{1}{\alpha}\) is `almost' Lipschitz, in the sense that for every \(\varepsilon>0\) there exists a constant \(C_\varepsilon\) such that for all \(x,y\) in the domain of \(f\), 
\[
    |f(x)^\frac{1}{\alpha}-f(y)^\frac{1}{\alpha}|\leq C_\varepsilon|x-y|+\varepsilon\max\{f(x),f(y)\}^\frac{1}{\alpha}.
\]
\end{cor}


A critical property of non-negative H\"older functions is that they satisfy some pointwise derivative estimates. Before making this idea precise in \Cref{thm:cauchylike}, we introduce some helpful notation that will be employed throughout the rest of this work. 

By \(\nabla^kf\) we mean a vector comprised of all \(k^\mathrm{th}\)-order derivatives of \(f\), and for our purposes their ordering within the vector is not important. Given \(\xi\in\mathbb{R}^n\) with \(|\xi|=1\), we denote by \(\partial^k_\xi f\) the \(k^{th}\)-order directional derivative of \(f\) in the direction of \(\xi\). Explicitly this directional operator can be written using in the form
\begin{equation}\label{eq:directionalop}
    \partial^k_\xi=(\xi\cdot\nabla)^k=\sum_{|\beta|=k}\frac{k!}{\beta!}\xi^\beta\partial^\beta,
\end{equation}
where \(\nabla\) is the usual gradient operator and \(\xi^\beta=\xi_1^{\beta_1}\cdots\xi_n^{\beta_n}\). For a real-valued function \(f\) we define the positive part of \(f\) as \([f]_+=\max\{f,0\}\). Using this notation we can compactly express the maximal positive \(k^\mathrm{th}\)-order directional derivative of \(f\) at a point \(x\in\mathbb{R}^n\) by writing
\[
    \sup_{|\xi|=1}[\partial^j_\xi f(x)]_+.
\]
This quantity appears frequently in the next chapter. It is also worth noting that the functions \(|\nabla^k f(x)|\) and \(\displaystyle\sup_{|\xi|=1}|\partial^j_\xi f(x)|\) are equivalent, in the sense that
\[
    c|\nabla^k f(x)|\leq \sup_{|\xi|=1}|\partial^k_\xi f(x)|\leq C|\nabla^k f(x)|
\]
for \(x\) in the domain of \(f\) and for constants \(c\) and \(C\) which depend only on \(n\) and \(k\). 


Following a standard convention in analysis, we henceforth use \(C\) to denote a positive finite constant which depends only on fixed parameters such as \(n\), \(k\) and \(\beta\). The value of such constants may change from line-to-line, and our only concern is that they are finite. This is because the constants we encounter are often complicated, unwieldy, and far from sharp -- for our purposes, their values are also usually unimportant.


Momentarily we state the main result of this section, which allows us to control the derivatives of non-negative functions in higher-order H\"older spaces by their even-order derivatives. This idea is not new; Fefferman \& Phong point out in \cite{Fefferman-Phong} that the even-order terms that appear in the Taylor series of non-negative function control the odd-order terms, and it is a straightforward consequence of this fact that similar control estimates hold for the Taylor polynomials of H\"older continuous functions. There are results to this effect in \cite{Tataru}, \cite{SOS_I}, and \cite{Bony2}, and in many other works.


Our next result makes this control explicit for non-negative \(C^{k,\alpha}(\mathbb{R}^n)\) functions and it generalizes several results in the aforementioned works. The main difficulty in its proof is the selective cancellation of odd-order terms from Taylor polynomials, which we overcome by employing the very useful weighted summation identities that we establish in \Cref{thm:specialodds}.


\begin{thm}\label{thm:cauchylike}
If \(f\in C^{k,\alpha}(\mathbb{R}^n)\) is non-negative, then for every \(\ell\leq k\) there exists a constant \(C\) for which the following estimate holds on \(\mathbb{R}^n\),
\[
    |\nabla^\ell f(x)|\leq C\max_{\substack{0\leq j\leq k\\j\;\mathrm{even}}}\bigg\{\sup_{|\xi|=1}[\partial^j_\xi f(x)]_+^\frac{k-\ell+\alpha}{k-j+\alpha}\bigg\}.
\]
\end{thm}


\textit{Remark}: Recall that for notational convenience we regard \(f\) as a zero-order derivative of itself. If \(k=1\) the inequality above reduces to the Malgrange inequality for \(C^{1,\alpha}(\mathbb{R}^n)\), a sharper form of which is proved in \Cref{sec:malg}. The bound above is somewhat complicated, however we actually apply this result using the considerably simpler inequality of \Cref{cor:controlbound}.


\begin{proof}
For an even number \(\ell\leq k\), we begin by bounding the negative part of the \(\ell^\mathrm{th}\)-order directional derivatives of \(f\). To do this we use non-negativity of the Taylor polynomial of \(f\) to obtain the following inequality for \(\lambda\in\mathbb{R}\) and \(\mathbb{\xi}\in\mathbb{R}^n\) satisfying \(|\xi|=1\),
\[
    0\leq f(x+\lambda\xi)\leq  \sum_{j=0}^k\frac{\lambda^j}{j!}\partial^j_\xi f(x)+\frac{1}{k!}[\nabla^k f]_\alpha|\lambda|^{k+\alpha}.
\]
Additionally we can use the fact that \(0\leq f(x-\lambda\xi)\), to see that the same estimate holds when \(\lambda\) is replaced with \(-\lambda\), and summing the Taylor polynomials of \(f\) at \(x+\lambda\xi\) and \(x-\lambda\xi\), we see for any \(\lambda>0\) that the following estimate holds,
\[
    0\leq \sum_{\substack{0\leq j\leq k,\\ j\;\textrm{even}}}\frac{\lambda^j}{j!}\partial^j_\xi f(x)+\frac{2}{k!}[\nabla^k f]_\alpha\lambda^{k+\alpha}\leq \sum_{\substack{0\leq j\leq k,\\ j\;\textrm{even}}}\frac{\lambda^j}{j!}[\partial^j_\xi f(x)]_++\frac{2}{k!}[\nabla^k f]_\alpha\lambda^{k+\alpha}.
\]
The second inequality above holds since \(\partial^j_\xi f(x)\leq [\partial^j_\xi f(x)]_+\) for all \(j\) an \(x\in\mathbb{R}^n\). Rearranging the inequality above gives
\[
    -\partial_\xi^\ell f(x)\leq\sum_{\substack{0\leq j\leq k,\\ j\;\textrm{even},\;j\neq\ell}}\frac{\ell!}{j!}\lambda^{j-\ell}[\partial^j_\xi f(x)]_++\frac{2\ell!}{k!}[\nabla^k f]_\alpha\lambda^{k-\ell+\alpha}
\]
for even \(\ell\leq k\).
Taking \(\lambda=\displaystyle\max_{\substack{0\leq j\leq k,\\ j\;\textrm{even},\;j\neq\ell}}[\partial^j_\xi f(x)]_+^\frac{1}{k-j+\alpha}\), we have \(\lambda^{j-\ell}[\partial^j_\xi f(x)]_+\leq \lambda^{k-\ell+\alpha}\) and so
\[
    -\partial_\xi^\ell f(x)\leq C\lambda^{k-\ell+\alpha}=C\max_{\substack{0\leq j\leq k,\\ j\;\textrm{even},\;j\neq\ell}}\bigg\{[\partial^j_\xi f(x)]_+^\frac{k-\ell+\alpha}{k-j+\alpha}\bigg\}.
\]
Taking a supremum over all \(\xi\in\mathbb{R}^n\) such that \(|\xi|=1\), and using equivalence of the norms \(|\nabla^kf(x)|\) and \(\sup_{|\xi|=1}|\partial^k_\xi f(x)|\), we see now that for even values of \(\ell\)
\[
    |\nabla^\ell f(x)|\leq C\sup_{|\xi|=1}[\partial_\xi^\ell f(x)]_++C\max_{\substack{0\leq j\leq k,\\ j\;\textrm{even},\;j\neq\ell}}\bigg\{\sup_{|\xi|=1}[\partial^j_\xi f(x)]_+^\frac{k-\ell+\alpha}{k-j+\alpha}\bigg\}.
\]
The the first term on the right-hand side above can be absorbed into the second, at the expense of making \(C\) larger. It follows that the claimed estimate holds for derivatives of even order.


For derivatives of odd order, matters are slightly more complicated since we cannot begin by cancelling out all odd terms simultaneously. Once again we begin by using a Taylor expansion and non-negativity of \(f\) to see that for any \(\lambda\in\mathbb{R}\), the following holds when \(|\xi|=1\),
\[
    0\leq \sum_{j=0}^k\frac{\lambda^j}{j!}\partial^j_\xi f(x)+\frac{1}{k!}[\nabla^kf]_\alpha|\lambda|^{k+\alpha}.
\]
This inequality continues to hold if we replace \(\lambda\) with \(\eta\lambda\) for any \(\eta\in\mathbb{R}\), since \(f\) is non-negative everywhere. First let \(\ell\) be the largest odd number that is less than or equal to \(k\) and set \(s=\frac{\ell+1}{2}\). Replacing  \(\lambda\) with \(\eta_1\lambda\) through \(\eta_s\lambda\) for some real numbers \(\eta_1,\dots,\eta_s\) to be chosen momentarily, and adding the resulting inequalities scaled by positive constants \(q_1,\dots,q_s\) which we also select below, we find that
\[
    0\leq \sum_{j=0}^k\bigg(\sum_{i=1}^sq_i\eta_i^j\bigg)\frac{\lambda^j}{j!}\partial^j_\xi f(x)+C\lambda^{k+\alpha}.
\]
The preceding inequality continues to hold if we replace \(\lambda\) with \(-\lambda\), allowing us to write
\[
    \bigg|\sum_{\substack{1\leq j\leq \ell,\\ j\;\textrm{odd}}}\bigg(\sum_{i=1}^sq_i\eta_i^j\bigg)\frac{\lambda^j}{j!}\partial^j_\xi f(x)\bigg|\leq C\bigg(\sum_{\substack{0\leq j\leq k,\\ j\;\textrm{even}}}\lambda^j\partial^j_\xi f(x)+\lambda^{k+\alpha}\bigg)
\]
for every \(\lambda>0\). For brevity we denote by \(F_\lambda(x)\) the function on the right-hand side above, and we next wish to choose the numbers \(q_i\) and \(\eta_i\) so that all but one term in the sum on the left vanishes. This affords a pointwise bound on an odd-order derivative by \(F_\lambda\). Using the technical \Cref{thm:specialodds}, we choose the numbers \(\eta_1,\dots,\eta_s\in\mathbb{R}\) and \(q_1,\dots,q_s\geq 0\) so that \(\sum_{i=1}^sq_i\eta_i^j=0\) for every odd \(j<\ell\), and so that \(\sum_{i=1}^sq_i\eta_i^\ell=1\). With these selections, get \(|\lambda^\ell\partial^\ell_\xi f(x)|\leq C F_\lambda(x)\).


Equipped with this estimate, we can repeat the argument above using different constants \(\tilde{q}_1,\dots,\tilde{q}_{s-1}\geq 0\) and \(\tilde{\eta}_1,\dots\tilde{\eta}_{s-1}\in\mathbb{R}\), and by combining non-negative Taylor polynomials we get
\[
    \bigg|\sum_{\substack{1\leq j\leq \ell-2,\\ j\;\textrm{odd}}}\bigg(\sum_{i=1}^{s-1}\tilde{q}_i\tilde{\eta}_i^j\bigg)\frac{\lambda^j}{j!}\partial^j_\xi f(x)\bigg|\leq C|\lambda^\ell\partial^\ell_\xi f(x)|+CF_\lambda(x)\leq CF_\lambda(x).\\
\]
Using \Cref{thm:specialodds} once more, we can choose the constants \(\tilde{q}_i\) and \(\tilde{\eta}_i\) so that the right-hand side above reduces to \(|\lambda^{\ell-2}\partial^{\ell-2}_\xi f(x)|\). This gives \(|\lambda^{\ell-2}\partial^{\ell-2}_\xi f(x)|\leq CF_\lambda(x)\), and we see by repeating this argument that for each odd \(\ell\leq k\) and \(\lambda>0\),
\[
    |\partial_\xi^\ell f(x)|\leq  CF_\lambda(x)\leq  C\bigg(\sum_{\substack{0\leq j\leq k,\\ j\;\textrm{even}}}\lambda^{j-\ell}[\partial^j_\xi f(x)]_++\lambda^{k-\ell+\alpha}\bigg).
\]
Taking \(\lambda=\displaystyle\max_{\substack{0\leq j\leq k,\\ j\;\textrm{even}}}\{|\partial_\xi^jf(x)|^\frac{1}{k-j+\alpha}\}\) in this estimate gives \(|\partial_\xi^\ell f(x)|\leq C\lambda^{k-\ell+\alpha}\), and it follows that
\[
    |\nabla^\ell f(x)|\leq C\sup_{|\xi|=1}|\partial^\ell_\xi f(x)|\leq C\sup_{|\xi|=1}\lambda^{k-\ell+\alpha}\leq C\max_{\substack{0\leq j\leq k\\j\;\mathrm{even}}}\bigg\{\sup_{|\xi|=1}[\partial^j_\xi f(x)]_+^\frac{k-\ell+\alpha}{k-j+\alpha}\bigg\}.
\]
Thus the claimed derivative estimates hold for every order \(\ell\leq k\), and we are finished.
\end{proof}


We note in passing that for the small values of \(k\), it is possible to avoid invoking \Cref{thm:specialodds} in the preceding proof, and instead to combine inequalities methodically and thereby achieve the appropriate cancellation of odd-order terms. We chose to prove the result above in greater generality than is needed in \Cref{chap:holderchap}, since \Cref{thm:cauchylike} is useful when generalizing sum of squares theorems to \(C^{k,\alpha}(\mathbb{R}^n)\). The result has applications elsewhere, for instance in studying the coefficients of non-negative polynomials.


\section{Generalized Malgrange Inequalities}\label{sec:malg}


In this section we study pointwise control of derivatives of non-negative \(C^{1,\alpha}(\mathbb{R}^n)\) functions. The classical Malgrange inequality in \(\mathbb{R}\) states that \(|f'(x)|\leq C\sqrt{f(x)}\) provided that \(f''(x)\) exists and is bounded on the real line. As we noted above, this inequality is often attributed to Glaeser in the literature, however Glaeser credits it to Malgrange in \cite{Glaeser}, so we refer to the similar pointwise estimates we prove in this section as generalized Malgrange inequalities. 


The inequality we now prove was also found by Ghisi \& Gobbino in \cite{Gobbino}, and their work was made known to the author after it was discovered independently in this work. Our result for functions defined on \(\mathbb{R}\) is not as strong as that in \cite{Gobbino}, however our proof is considerably shorter and our subsequent generalizations do appear to be new to the literature.


\begin{thm}\label{thm:malgrangeineq}
Suppose that \(f\in C^{1,\alpha}(\mathbb{R})\) is non-negative. Then for each \(x\in\mathbb{R}\), 
\begin{equation}\label{eq:malg}
    |f'(x)|\leq \frac{\alpha+1}{\alpha^\frac{\alpha}{1+\alpha}}[f']_\alpha^\frac{1}{1+\alpha}f(x)^\frac{\alpha}{1+\alpha}.    
\end{equation}
\end{thm}


\begin{proof} 
For any \(x,h\in\mathbb{R}\), we first have by Taylor's Theorem and non-negativity of \(f\) that
\[
    0\leq f(x+h)\leq f(x)+hf'(x)+[f']_\alpha|h|^{1+\alpha}.
\]
Since \(0\leq f(x-h)\), we can replace \(h\) with \(-h\) to get \(|hf'(x)|\leq f(x)+|h|^{1+\alpha}[f']_\alpha\). Taking \(h=(f(x)/[f']_\alpha)^\frac{1}{1+\alpha}\alpha^{-\frac{1}{1+\alpha}}\), we find that
\[
    |f'(x)|\leq \frac{f(x)}{|h|}+|h|^\alpha[f']_\alpha=[f']_\alpha^\frac{1}{1+\alpha}f(x)^\frac{\alpha}{1+\alpha}(\alpha^{\frac{1}{1+\alpha}}+\alpha^{-\frac{\alpha}{1+\alpha}}).
\]
Simplifying the right-hand side gives inequality \eqref{eq:malg}.
\end{proof}


In fact, a simple modification of the preceding proof shows that for any \(\eta>0\) and \(x,\xi\in\mathbb{R}\) the following slightly stronger estimate actually holds:
\[
    |f'(\xi)|\leq \frac{1}{\eta}f(x)^\frac{\alpha}{1+\alpha}+[f']_\alpha(\eta f(x)^\frac{1}{1+\alpha}+|x-\xi|)^\alpha.
\]
\Cref{thm:malgrangeineq} follows as a special case. Taking \(\alpha=1\) we get \(|f'(x)|\leq 2\sqrt{[f']_1f(x)}\) whenever \(f\in C^{1,1}(\Omega)\), which resembles the classical Malgrange inequality. Later, we will find conditional extensions of this inequality to higher dimensions as well as to higher-order derivatives. We note in passing that we cannot simply apply the preceding estimate to \(f''(x)\) and iterate \eqref{eq:malg} for higher-order derivative estimates, since this would require \(f\) to be monotone. 


This generalization of Malgrange's inequality yields several interesting consequences. An application of Young's inequality to \eqref{eq:malg} affords the pointwise bound \(|f'(x)|\leq [f']_\alpha+f(x)\), from which it follows that \(\|f'\|_\infty\leq [f']_\alpha+\|f\|_\infty\). Hence the norm on \(C^{1,\alpha}_b(\mathbb{R})\) defined in \eqref{eq:holdernorm} is equivalent to \(\|f\|_\infty+[f']_\alpha\) on the cone of non-negative \(C^{1,\alpha}(\mathbb{R})\) functions. Using the Malgrange inequality, we are also able to discuss the regularity (i.e. the degree of smoothness) of square roots of \(C^{1,\alpha}(\mathbb{R})\) functions.


\begin{thm}\label{thm:rootsin}
Let \(f\in C^{1,\alpha}(\mathbb{R})\) be non-negative. Then \(\sqrt{f}\in C^{\frac{1+\alpha}{2}}(\mathbb{R})\).
\end{thm}


\begin{proof}
We first use the Malgrange inequality to show that \(f^\frac{1}{1+\alpha}\in C^{0,1}(\mathbb{R})\). To this end, we apply \Cref{lem:smallpow} to get
\[
    |\sqrt{f(x)}-\sqrt{f(y)}|^\frac{2}{1+\alpha}\leq |f(x)^\frac{1}{1+\alpha}-f(y)^\frac{1}{1+\alpha}|.
\]
Applying the mean value theorem on the right-hand side and then applying inequality \eqref{eq:malg} at some intermediate point \(\xi\) between \(x\) and \(y\) gives
\[
    |f(x)^\frac{1}{1+\alpha}-f(y)^\frac{1}{1+\alpha}|= \frac{1}{1+\alpha}\frac{|f'(\xi)|}{f(\xi)^\frac{\alpha}{1+\alpha}}|x-y|\leq \frac{[f']_\alpha^\frac{1}{1+\alpha}}{\alpha^\frac{1}{1+\alpha}}|x-y|.
\]
Combining the preceding inequalities we get \(|\sqrt{f(x)}-\sqrt{f(y)}|^\frac{2}{1+\alpha}\leq[f']_\alpha^\frac{1}{1+\alpha}|x-y|/\alpha^\frac{1}{1+\alpha}\), which gives the required estimate after taking a root.
\end{proof}

In addition to showing that \(\sqrt{f}\) is half as regular as \(f\) in the sense of \eqref{eq:rootspaces}, the proof above also yields the semi-norm estimate 
\[
    \big[\sqrt{f}\big]_{\frac{1+\alpha}{2}}\leq \sqrt{\frac{[f']_\alpha}{\alpha}}.
\]


As a special case of the preceding theorem, we also have the following result.


\begin{cor}
If \(f\) is non-negative and \(f'\) is Lipschitz then \(\sqrt{f}\) is also Lipschitz.
\end{cor}


In summary, if \(f\in C^{\alpha}(\mathbb{R})\) then \(\sqrt{f}\in C^\frac{\alpha}{2}(\mathbb{R})\), while if \(f\in C^{1,\alpha}(\mathbb{R})\) then \(\sqrt{f}\in C^\frac{1+\alpha}{2}(\mathbb{R})\). This result is essentially sharp, in the sense that it does not hold in higher-order H\"older spaces. Recall from \Cref{chap:intro} that in \cite{Bony}, Bony gives an example of a \(C^\infty(\mathbb{R})\) function whose root is not \(C^{1,\alpha}(\mathbb{R})\) for any \(\alpha>0\).


Indeed, if \(f\in C^\infty(\mathbb{R})\) them \(\sqrt{f}\) need not even belong to \(C^1(\mathbb{R})\). It follows that if \(f\in C^{k,\alpha}(\mathbb{R})\) for \(k\geq 2\) then we cannot even expect continuity of the derivative of \(\sqrt{f}\), let alone H\"older continuity. For instance, the function 
\begin{equation}\label{eq:badroot}
    f(x)=\begin{cases}
    x^2e^\frac{1}{x^2-1} & |x|<1,\\
    0 & |x|\geq 1
    \end{cases}
\end{equation}
is a bounded and non-negative \(C^\infty(\mathbb{R})\) function, however \(\sqrt{f}\) is not continuously differentiable at the origin. In \(\mathbb{R}^n\) we can similarly define \(F(x)=f(x_1)\cdots f(x_n)\) for \(f\) as above to obtain a bounded and non-negative \(C^\infty(\mathbb{R}^n)\) function whose square root is not in \(C^1(\mathbb{R}^n)\).


In any number of dimensions, a sum of squares decomposition of \(f\in C^{k,\alpha}(\mathbb{R}^n)\) for \(k\geq 2\) will in general require more than one root function if those roots are to retain half of the regularity of \(f\). Before moving on to the task of constructing such decompositions, we first verify that the \(C^{1,\alpha}(\mathbb{R})\) results proved in this section hold also in \(\mathbb{R}^n\) for \(n\geq 2\).


\begin{thm}
Suppose that \(f\in C^{1,\alpha}(\mathbb{R}^n)\) is non-negative everywhere. Then \(f\) satisfies 
\[
    |\nabla f(x)|\leq \frac{\alpha+1}{\alpha^\frac{\alpha}{1+\alpha}}[\nabla f]_\alpha^\frac{1}{1+\alpha}f(x)^\frac{\alpha}{1+\alpha}.
\]
\end{thm}


\begin{proof}
Using a Taylor expansion in \(\mathbb{R}^n\) for non-negative \(f\), we have for any \(x,h\in\mathbb{R}^n\) and some \(\xi\) on the line segment between \(x\) and \(x+h\) that
\[
    0\leq f(x+h)=f(x)+h\cdot\nabla f(\xi)=f(x)+h\cdot\nabla f(x)+h\cdot(\nabla f(\xi)-\nabla f(x)).
\]
Applying the Cauchy-Schwarz inequality on the last term above and also using the fact that \(|\nabla f|\in C^{\alpha}(\mathbb{R}^n)\), we get
\[
    0\leq f(x)+h\cdot\nabla f(x)+|h||\nabla f(x)-\nabla f(\xi)|\leq f(x)+h\cdot\nabla f(x) +[\nabla f]_\alpha|h|^{1+\alpha}.
\]
Since \(f\) is non-negative everywhere, an identical estimate holds if we replace \(h\) with \(-h\), showing that \(|h\cdot\nabla f(x)|\leq f(x) +[\nabla f]_\alpha|h|^{1+\alpha}\). Taking \(h=\lambda\nabla f(x)\) for \(\lambda>0\) gives \(h\cdot\nabla f(x)=\lambda|\nabla f(x)|^2\), and we find that
\[
    \lambda|\nabla f(x)|^2\leq f(x) +\lambda^{1+\alpha}[\nabla f]_\alpha|\nabla f(x)|^{1+\alpha}.
\]
Now choosing \(\lambda=(f(x)/\alpha[\nabla f]_\alpha)^\frac{1}{1+\alpha}/|\nabla f(x)|\) gives \(|\nabla f(x)|\leq [\nabla f]_\alpha^\frac{1}{1+\alpha}f(x)^\frac{\alpha}{1+\alpha}(\alpha^\frac{1}{1+\alpha}+\alpha^{-\frac{\alpha}{1+\alpha}})\). Hence \eqref{eq:malg} continues to hold in \(\mathbb{R}^n\) as claimed.
\end{proof} 

As in the one-dimensional case, this pointwise estimate gives us information about the square roots of non-negative \(C^{1,\alpha}(\mathbb{R}^n)\) functions.

\begin{cor}
Let \(f\in C^{1,\alpha}(\mathbb{R}^n)\). If \(f\) is non-negative then \(\sqrt{f}\in C^{\frac{1+\alpha}{2}}(\mathbb{R}^n)\).
\end{cor}


The proof is identical to that of \Cref{thm:rootsin}, so we do not repeat it. Further generalizations of the Malgrange inequality, in particular to a general modulus of continuity, have been obtained by the author. However, such estimates go beyond the scope of this thesis, so we do not discuss them here. 


We close this section by noting that we may weaken the hypothesis of non-negativity in the Malgrange inequality, and assume simply that \(f\) is bounded below. Specifically, given \(f\in C^{1,\alpha}(\mathbb{R}^n)\), not necessarily non-negative but bounded below, we can replace \(f\) with \(f-\inf_{\mathbb{R}^n}f\), and this is a non-negative \(C^{1,\alpha}(\mathbb{R}^n)\) function. An application of inequality thus \eqref{eq:malg} gives
\[
    |\nabla f(x)|\leq C\big(f(x)-\inf_{\mathbb{R}^n} f\big)^\frac{\alpha}{1+\alpha}
\]
for every \(x\in\mathbb{R}^n\). For non-negative functions this is actually stronger than \eqref{eq:malg}, and a similar generalization can easily be obtained for functions that are bounded above.


In summary, we have shown that if \(f\in C^{k,\alpha}(\mathbb{R}^n)\) is non-negative then \(\sqrt{f}\in C^\frac{k+\alpha}{2}(\mathbb{R}^n)\) for \(k=0\) and \(k=1\). Now we are free to focus on the cases \(k=2\) and \(k=3\), in which taking a single root does not suffice for a decomposition to preserve regularity.


\section{Multivariate Calculus Identities}


For the remainder of this section we generalize the chain rule from elementary differential calculus, and adapt it to arbitrary derivatives of functions defined on \(\mathbb{R}^n\). The identities we prove are critical for showing that the functions \(g_1,\dots,g_m\) appearing in \Cref{thm:c3main} of \Cref{chap:decomps} have the desired regularity properties. 


The main technique we use in this section involves expressing derivatives of compositions of functions by summing over multi-index partitions. This idea was introduced by Hardy in \cite{hardy} in a study of the combinatorics induced by higher-order derivatives. A similar and equally effective result is given in \cite[Eq. (3.4)]{SOS_I} and proved in \cite{masur}, and we emphasize that many expressions for these higher-order derivatives can be found in the literature and are fairly well-known. Our contribution is to make the computation of the corresponding coefficients explicit, rather than defining them recursively or via a difficult combinatorial exercise.


Further, we generalize our result to compositions of two functions of multiple variables, whereas many well-known versions of the chain rule consider compositions of multivariate functions with a function of a single variable. In particular, we require this generalization to study implicitly defined functions and their derivatives. 


To state these general variants of the chain rule in closed form and prove them using appropriate combinatorial arguments, we introduce some notation. Recall that a multi-index \(\beta\) of length \(n\) is an \(n\)-tuple of non-negative integers. A multi-set \(\Gamma\) that is comprised of multi-indices is called a partition of \(\beta\) if each \(\gamma\in\Gamma\) is a proper multi-index (i.e. each entry of \(\gamma\) is a non-negative integer and at least one is non-zero), and if
\[
    \sum_{\gamma\in\Gamma}\gamma=\beta.
\]
Multi-sets permit repetition, so several multi-indices in the sum above can be identical. 

We identify the support of a partition \(\Gamma\), denoted \(\mathrm{supp}(\Gamma)\), as the set obtained by omitting repetition from \(\Gamma\). We let \(m(\Gamma,\gamma)\) be the number of times that a multi-index \(\gamma\) appears in \(\Gamma\), and counting repetition, we let \(|\Gamma|\) denote the cardinality of the multi-set \(\Gamma\) so that
\[
    \sum_{\gamma\in\mathrm{supp}(\Gamma)}m(\Gamma,\gamma)=\sum_{\gamma\in\Gamma}1=|\Gamma|.
\]
Finally we denote by \(P(\beta)\) the collection of all unordered partitions of \(\beta\). For instance, if \(\beta=(1,2)\) then this partition set is given explicitly by
\[
    P(\beta)=\big\{\{(1,2)\},\{(1,1),(0,1)\},\{(1,0),(0,2)\}\\
    \{(1,0),(0,1),(0,1)\}
    \big\}.
\]
Thankfully, for our purposes it is unnecessary to actually compute the partition set of a given multi-index; we simply use their intrinsic properties and the concise formulas they afford.


Briefly we recall some notation introduced in the previous section, which will be employed heavily to prove the subsequent results. Given a multi-index \(\beta=(\beta_1,\dots,\beta_n)\) of length \(n\) we write \(\beta!=\beta_1!\cdots\beta_n!\), and if \(\gamma\) is another multi-index we say that \(\gamma\leq\beta\) if \(\gamma_j\leq\beta_j\) for each \(j=1,\dots,n\), and \(\gamma<\beta\) if \(\gamma\leq\beta\) and \(\gamma\neq\beta\). Given \(\gamma\leq\beta\) we can define a generalized binomial coefficient as in \eqref{eq:binom}, and with this notation we express the following result.


\begin{lem}[Generalized Chain Rule]\label{lem:genchain}
Let \(f:\mathbb{R}^{n+1}\rightarrow\mathbb{R}\) and \(g:\mathbb{R}^{n}\rightarrow\mathbb{R}\) both be \(k\) times differentiable, and define \(h:\mathbb{R}^n\rightarrow\mathbb{R}\) by setting \(h(x)=f(x,g(x))\). For any multi-index \(\beta\) of order \(|\beta|\leq k\) and length \(n\), there exist constants \(C_{\beta,\Gamma}\) for which
\begin{equation}\label{eq:holycow}
    \partial^\beta h =\sum_{0\leq\eta\leq\beta}\sum_{\Gamma\in P(\eta)}C_{\beta,\Gamma}(\partial^{\beta-\eta}\partial^{|\Gamma|}_{n+1}f)\prod_{\gamma\in\Gamma}\partial^\gamma g,
\end{equation}
where \(\partial^\beta h\) is evaluated at \(x\) and the functions on the right-hand side are evaluated at \((x,g(x))\). Moreover, the constant \(C_{\beta,\Gamma}\) in \eqref{eq:holycow} is given explicitly by the formula
\begin{equation}\label{eq:cm}
    C_{\beta,\Gamma}=\eta!\binom{\beta}{\eta}\bigg(\prod_{\gamma\in\Gamma}\gamma!\bigg)^{-1}\bigg(\prod_{\gamma\in\mathrm{supp}(\Gamma)}m(\Gamma,\gamma)!\bigg)^{-1}.
\end{equation}
\end{lem}


\begin{proof}
We use induction on \(k\) to prove that \eqref{eq:holycow} holds with the appropriate constants. The case \(k=1\) follows from the usual chain rule. For an inductive hypothesis assume that the claimed formula holds for derivatives up to order \(k\) and let \(\mu\) be a derivative of order \(k+1\), so that we can write \(\partial^\mu=\partial^\nu\partial^\beta\) for \(|\nu|=1\) and \(|\beta|=k\). By the inductive hypothesis and linearity we have
\[
    \partial^\mu h=\partial^\nu\partial^\beta h=\sum_{0\leq \eta\leq\beta}\sum_{\Gamma\in P(\eta)}C_{\beta,\Gamma}\partial^\nu\bigg((\partial^{\beta-\eta}\partial^{|\Gamma|}_n f)\prod_{\gamma\in\Gamma}\partial^\gamma g\bigg),
\]
where each function on the right-hand side is evaluated at \((x,g(x))\). The derivative with respect to \(\nu\) on the right-hand side is first-order, so applying the standard form of the product rule gives
\[
    \partial^\mu h=\sum_{0\leq\eta\leq\beta}\sum_{\Gamma\in P(\eta)}C_{\beta,\Gamma}\bigg(\partial^\nu(\partial^{\beta-\eta}\partial^{|\Gamma|}_nf)\prod_{\gamma\in\Gamma}\partial^\gamma g+(\partial^{\beta-\eta}\partial^{|\Gamma|}_n f)\prod_{\gamma\in\Gamma}\partial^\gamma g\sum_{\gamma\in\Gamma}\frac{\partial^{\gamma+\nu }g}{\partial^\gamma g}\bigg).
\]
To simplify this, we first observe that by the standard chain rule we have the identity
\[
    \partial^\nu(\partial^{\beta-\eta}\partial^{|\Gamma|}_n f(x,g(x)))=\partial^{\mu-\eta}\partial^{|\Gamma|}_n f(x,g(x))+\partial^{\beta-\eta}\partial^{|\Gamma|+1}_nf(x,g(x))\partial^\nu g(x).
\]
Using this identity together with the calculation preceding it, we obtain the expansion
\begin{equation}\label{eq:lots}
\begin{split}
    \partial^\mu h&=\sum_{0\leq\eta\leq\beta}\sum_{\Gamma\in P(\eta)}C_{\beta,\Gamma}(\partial^{\mu-\eta}\partial^{|\Gamma|}_n f)\prod_{\gamma\in\Gamma}\partial^\gamma g\\
    &\qquad+\sum_{0\leq\eta\leq\beta}\sum_{\Gamma\in P(\eta)}C_{\beta,\Gamma}(\partial^{\mu-(\eta+\nu)}\partial^{|\Gamma|+1}_nf)\partial^\nu g\prod_{\gamma\in\Gamma}\partial^\gamma g\\
    &\qquad+\sum_{0\leq\eta\leq\beta}\sum_{\Gamma\in P(\eta)}C_{\beta,\Gamma}(\partial^{\mu-(\eta+\nu)}\partial^{|\Gamma|}_n f)\prod_{\gamma\in\Gamma}\partial^\gamma g\sum_{\gamma\in\Gamma}\frac{\partial^{\gamma+\nu }g}{\partial^\gamma g}.
\end{split}
\end{equation}


Each term in \eqref{eq:lots} takes the form \(\partial^{\mu-\eta}\partial^{|\Gamma|}_nf\prod_{\gamma\in\Gamma}\partial^\gamma g\) for some \(\eta\leq \mu\) and \(\Gamma\in P(\eta)\), meaning that after grouping common terms we can write \(\partial^\mu h\) in the form of identity \eqref{eq:holycow} for some new constants which we denote by \(C_{\mu,\Gamma}\). Now we compute these coefficients and show that they satisfy \eqref{eq:cm}. To this end we fix \(\eta\leq\mu\) and \(\Gamma\in P(\eta)\), and for brevity, we also define 
\[
    G=\prod_{\gamma\in\Gamma}\gamma!\qquad\textrm{and}\qquad M=\prod_{\gamma\in\mathrm{supp}(\Gamma)}m(\Gamma,\gamma)!.
\]
Consider the term of the form \(\partial^{\mu-\eta}\partial^{|\Gamma|}_nf\prod_{\gamma\in\Gamma}\partial^\gamma g\) in \eqref{eq:lots}, and note that for each \(\gamma\in\mathrm{supp}(\Gamma)\) such that \(\gamma>\nu\), the constant \(C_{\beta,\Gamma\setminus\{\gamma\}\cup\{\gamma-\nu\}}\) appears as a coefficient to this term in the third sum in \eqref{eq:lots} once for every time \(\gamma-\nu\) appears in the partition \(\Gamma\setminus\{\gamma\}\cup\{\gamma-\nu\}\) of \(\beta\). There are exactly \(m(\Gamma\setminus\{\gamma\}\cup\{\gamma-\nu\},\gamma-\eta)\) of these terms. Additionally, \(C_{\Gamma\setminus\{\nu\}}\) appears once as a coefficient from the second sum, and \(C_{\beta,\Gamma}\) once as a coefficient in the first sum of \eqref{eq:lots}. Altogether then, we have the following recursive identity for \(C_{\mu,\Gamma}\),
\begin{equation}\label{eq:murecur}
    C_{\mu,\Gamma}=\sum_{\substack{\gamma\in\mathrm{supp}(\Gamma)\\\gamma>\nu}}m(\Gamma\setminus\{\gamma\}\cup\{\gamma-\nu\},\gamma-\eta)C_{\beta,\Gamma\setminus\{\gamma\}\cup\{\gamma-\nu\}}+C_{\beta,\Gamma\setminus\{\nu\}}+C_{\beta,\Gamma}.
\end{equation}
Fix \(\tilde{\gamma}\in\mathrm{supp}(\Gamma)\) and write \(\tilde{\Gamma}=\Gamma\setminus\{\tilde{\gamma}\}\cup\{\tilde{\gamma}-\nu\}\). By our inductive hypothesis we have
\[
    C_{\beta,\tilde{\Gamma}}=\frac{\beta!}{(\mu-\eta)!}\bigg(\prod_{\gamma\in\tilde{\Gamma}}\gamma!\bigg)^{-1}\bigg(\prod_{\gamma\in\mathrm{supp}(\tilde{\Gamma})}m(\tilde{\Gamma},\gamma)!\bigg)^{-1}.
\]
To simplify \eqref{eq:murecur}, we set \(\nu=(0,\dots,1,\dots,0)\), with the one in position \(\ell\), so that \(\prod_{\gamma\in\tilde{\Gamma}}\gamma!= \frac{G}{\tilde{\gamma}_\ell}\). Similarly, by counting multiplicities of multi-indices in \(\Gamma\) and \(\tilde{\Gamma}\) respectively, we find that
\[
    m(\tilde{\Gamma},\gamma)=\begin{cases}
    m(\Gamma,\gamma)+1 & \gamma=\tilde{\gamma}-\nu,\\
    m(\Gamma,\gamma)-1 & \gamma=\tilde{\gamma},\\
    m(\Gamma,\gamma) & \mathrm{otherwise}.
    \end{cases}
\]
Therefore we have the identity \(\prod_{\gamma\in\mathrm{supp}(\tilde{\Gamma})}m(\tilde{\Gamma},\gamma)!=\frac{m(\Gamma,\tilde{\gamma}-\nu)+1}{m(\Gamma,\tilde{\gamma})}M\). Equipped with these formulas, we see that the coefficients of the sum in the recursive identity \eqref{eq:murecur} can be written as \(m(\tilde{\Gamma},\tilde{\gamma}-\nu)C_{\beta,\tilde{\Gamma}}=\frac{\beta!\tilde{\gamma}_\ell m(\Gamma,\tilde{\gamma})}{(\mu-\eta)!GM}\). Using the inductive hypothesis with \eqref{eq:cm} we also find that
\[
     C_{\beta,\Gamma\setminus\{\nu\}}=\frac{\beta!}{(\mu-\eta)!}\bigg(\prod_{\gamma\in\Gamma\setminus\{\nu\}}\gamma!\bigg)^{-1}\bigg(\prod_{\gamma\in\mathrm{supp}(\Gamma\setminus\{\nu\})}m(\Gamma\setminus\{\nu\},\gamma)!\bigg)^{-1}.
\]
Since \(\nu!=1\) and \(\prod_{\gamma\in\mathrm{supp}(\Gamma\setminus\{\nu\})}m(\Gamma\setminus\{\nu\},\gamma)!=\frac{M}{m(\Gamma,\nu)}\), we have \(C_{\beta,\Gamma\setminus\{\nu\}}=\frac{\beta!m(\Gamma,\nu)}{(\mu-\eta)!GM}\). 


Similarly, the inductive hypothesis and \eqref{eq:cm} give \(C_{\beta,\Gamma}=\frac{\beta!(\mu_\ell-\eta_\ell)}{(\mu-\eta)!GM}\), and from \eqref{eq:murecur} we get
\[
    C_{\mu,\Gamma}=\frac{\beta!}{(\mu-\eta)!GM}\bigg(\sum_{\gamma\in\mathrm{supp}(\Gamma)}\tilde{\gamma}_\ell m(\Gamma,\tilde{\gamma})+\mu_\ell-\eta_\ell\bigg)=\frac{\mu!}{(\mu-\eta)!GM}.
\]
The right-hand side takes the form of \eqref{eq:cm}, and since \(\Gamma\) and \(\eta\) were arbitrary we see that \eqref{eq:holycow} holds with \(\mu\) in place of \(\beta\). Moreover, \(\mu\) was any multi-index of order \(k+1\), and it follows by induction that \eqref{eq:holycow} holds for all derivatives of \(h\).
\end{proof}


For the remainder of this section, we explore some direct consequences of \Cref{lem:genchain}. The first of these is the following somewhat less general form of the chain rule.


\begin{cor}[Chain Rule]\label{cor:chain2}
Let \(f:\mathbb{R}\rightarrow\mathbb{R}\) and  \(g:\mathbb{R}^n\rightarrow\mathbb{R}\) both be \(k\) times differentiable, and define \(h:\mathbb{R}^n\rightarrow\mathbb{R}\) by setting \(h(x)=f(g(x))\). If \(|\beta|\leq k\), then 
\begin{equation}\label{eq:orderedcr}
    \partial^\beta h =\sum_{\Gamma\in P(\beta)}C_{\beta,\Gamma}f^{(|\Gamma|)}(g)\prod_{\gamma\in\Gamma}\partial^\gamma g,
\end{equation}
where the constants \(C_{\beta,\Gamma}\) are given by \eqref{eq:cm}.
\end{cor}


By taking the function \(f\) in this corollary to be a square root, we get the following.


\begin{cor}\label{cor:rootscor}
Let \(g:\mathbb{R}^n\rightarrow\mathbb{R}\) be non-negative and \(k\) times differentiable. For \(|\beta|\leq k\),
\[
    \partial^\beta \sqrt{g} =\sum_{\Gamma\in P(\beta)}C_{\beta,\Gamma}g^{\frac{1}{2}-|\Gamma|}\prod_{\gamma\in\Gamma}\partial^\gamma g,
\]
where the constants \(C_{\beta,\Gamma}\) are given by
\[
    C_{\beta,\Gamma}=\frac{(-1)^{1+|\Gamma|}\beta!\left(2|\Gamma|-2\right)!}{2^{2|\Gamma|-1}(|\Gamma|-1)!}\bigg(\prod_{\gamma\in\Gamma}\gamma!\bigg)^{-1}\bigg(\prod_{\gamma\in\mathrm{supp}(\Gamma)}m(\Gamma,\gamma)!\bigg)^{-1}.
\]
\end{cor}

Ultimately the form of the constants above is unimportant for our work; we only include explicit formulas for the convenience of the reader interested in using them for other calculations. The supplementary calculus results established in this section are sufficient for the remainder of the work, and we now move on to establishing results needed to prove out main theorems.


One such result is a recursive formula for the derivatives an implicitly defined function. For completeness, we state the well-known Implicit Function Theorem before providing this recursive formula. In the subsequent proof and henceforth in this thesis, we use the notation \(x=(x',x_n)\) for \(x\in\mathbb{R}^n\).


\begin{thm}[Implicit Function Theorem]\label{thm:IFT}
Let \(G\in C^k(\mathbb{R}^n)\) and let \(x_0\in\mathbb{R}^n\) be a point at which \(G(x_0)=0\) and \(\frac{\partial G}{\partial x_n}(x_0)>0\). There exists a unique \(g\in C^k(U)\), for some neighbourhood \(U\subset\mathbb{R}^{n-1}\) of \(x_0'\), such that \(G(x',g(x'))=0\) for every \(x'\in U\). Further, the derivatives of \(g\) are given recursively by
\[
    \partial^\beta g=-\frac{1}{\partial_{n}G}\sum_{0\leq\eta\leq\beta}\sum_{ \substack{\Gamma\in P(\eta),\\\Gamma\neq \{\beta\}}}C_{\beta,\Gamma}(\partial^{\beta-\eta}\partial^{|\Gamma|}_nG)\prod_{\gamma\in\Gamma}\partial^\gamma g,
\]
where for functions on the right are evaluated at \((x',g(x'))\) and \(C_{\beta,\Gamma}\) is given by \eqref{eq:cm}.
\end{thm}


\begin{proof}
The first part is the standard Implicit Function Theorem, a proof of which can be found in \cite[Theorem 3.2.1]{IFTref}. Since \(G(x',g(x'))\) is identically zero on \(U\), so too are all if its derivatives, meaning that \(\partial^\beta G(x',g(x'))=0\). On the other hand, using \Cref{lem:genchain} we can write 
\[
    \partial^\beta G(x',g(x'))=\sum_{\eta\leq\beta}\sum_{\Gamma\in P(\eta)}C_{\beta,\Gamma}(\partial^{\beta-\eta}\partial^{|\Gamma|}_nG(x',g(x')))\prod_{\gamma\in\Gamma}\partial^\gamma g(x').
\]
The derivative \(\partial^\beta g\) appears in only one term on the right-hand side, namely when \(\eta=\beta\) and \(\Gamma=\{\beta\}\), meaning we can combine the two identities for \(\partial^\beta G(x',g(x'))\) and rearrange to get the claimed derivative formula.
\end{proof}


Due to the recursive nature of the formula above it is a straightforward exercise, albeit a computationally difficult one, to solve for the derivatives of \(g\) in terms of \(G\) alone. For our purposes, such a closed form is unnecessary and the recursive formula given above suffices. 