\documentclass[%
 reprint,
 amsmath,amssymb,
 aps,
]{revtex4-2}
\usepackage{graphicx}% Include figure files
\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
\usepackage{hyperref}% add hypertext capabilities
\usepackage[nice]{nicefrac}
\usepackage{amsmath}
\usepackage[]{quantikz}
\usepackage[ruled,linesnumbered]{algorithm2e}
\usepackage[]{float}
\newcommand{\rf}[1]{Figure~\ref{#1}}
\newcommand{\rs}[1]{Section~\ref{#1}}
\newcommand{\ra}[1]{Algorithm~\ref{#1}}
\newcommand{\re}[1]{Equation~\ref{#1}}

\begin{document}


\title{Towards Mixed Quantum-Classical Dynamics on Quantum Computers}

\author{Daniel Bultrini}
 \email{daniel.bultrini@uni-heidelberg.de}
  \affiliation{Theoretische Chemie, Physikalisch-Chemisches Institut, Heidelberg}
\author{Oriol Vendrell}
 \email{oriol.vendrell@uni-heidelberg.de}
 \affiliation{Theoretische Chemie, Physikalisch-Chemisches Institut, Heidelberg University}%
\affiliation{Interdisciplinary Center for Scientific Computing, Heidelberg University
}



\begin{abstract}
Mixed quantum-classical dynamics is a set of methods often used to understand systems too complex to treat fully quantum mechanically. Many techniques exist for full quantum mechanical evolution on quantum computers, but mixed quantum-classical dynamics are less explored. We present a modular algorithm for general mixed quantum-classical dynamics where the quantum subsystem is coupled with the classical subsystem. We test it on a modified Shin-Metiu model in the first quantization through Ehrenfest propagation. We find that the Time-Dependent Variational Time Propagation algorithm performs well for short-time evolutions and retains qualitative results for longer-time evolutions.\end{abstract}

\maketitle


\section{Introduction}

Quantum computers have found great success in electronic structure theory through the variational quantum eigensolver (VQE) \cite{peruzzoVariationalEigenvalueSolver2014} and subsequent algorithms known as variational quantum algorithms (VQAs) \cite{cerezoVariationalQuantumAlgorithms2020}. Adding additional electrons to a system greatly increases its complexity, this is something we hope quantum computers could handle. If one were to also consider the full nuclear dynamics, the problem becomes unmanageable much faster, potentially even for quantum computers \cite{ollitraultMolecularQuantumDynamics2021}. One way to reconcile this is to partition the system into interacting quantum and classical parts. This is the realm of mixed quantum-classical (MQC) approaches, which are a widely used set of tools for understanding chemical systems \cite{curchodInitioNonadiabaticQuantum2018,kirranderEhrenfestMethodsElectron2020}. In quantum computing, this area is less researched than the electronic structure problem, but it is of course actively being explored \cite{ollitraultNonadiabaticMolecularQuantum2020,ollitraultMolecularQuantumDynamics2021,sokolovMicrocanonicalFinitetemperatureInitio2021}. In this work we propose and explore noisy intermediate-scale quantum (NISQ) friendly algorithm that can be used to study MQC dynamics. 

Time-dependent phenomena are extremely interesting in both physics and chemistry, so it is natural that this class of problems has been tackled by many sophisticated numerical tools. The most accurate and general of which is exact diagonalization. But, just as the Hilbert space of a problem scales exponentially with the number of components, so do the resources required by exact diagonalization. Specific classes of problems can be expressed and solved quite well. Tensor networks, specifically matrix product state (MPS) based techniques \cite{baiardiLargeScaleQuantumDynamics2019}  such as the density matrix renormalization group (DMRG) \cite{baiardiElectronDynamicsTimeDependent2021}, have achieved great results when entanglement growth is limited. For chemical dynamics in particular, tree-tensor network techniques in the family of (Multi-Layer) Multi Configuration Time Dependent Hartree (ML-MCTDH) methods \cite{meyerMulticonfigurationalTimedependentHartree1990,mantheMultilayerMulticonfigurationalTimedependent2008,wangMultilayerFormulationMulticonfiguration2003,vendrellMultilayerMulticonfigurationTimedependent2011} can be used to solve full quantum dynamics for many particles, especially for model Hamiltonians. Most implementations are limited by the requirement for the Hamiltonian operator to be in a sum of products form, and algorithms have to be specifically developed to fit the potential \cite{jackleProductRepresentationPotential1996,schroderTransformingHighdimensionalPotential2020}. 

Irrespective of the powerful tools described above, simulating full quantum dynamics is an exceptionally hard problem computationally. To go beyond small systems it is necessary to make approximations. In MQC the idea is that we can partition the system into quantum and classical parts, but there are many ways to make this partition. In quantum mechanics/molecular mechanics (QM/MM) simulations only a small 'region of interest' has its electronic structure computed with some level of quantum theory, and the rest of the electrons are approximated by an effective classical force field, and all nuclei are treated classically. In some classical non-adiabatic molecular dynamics (NAMD) approximations we can choose to propagate the nuclei classically with algorithms such as surface hopping methods \cite{jainPedagogicalOverviewFewest2022} or Ehrenfest methods \cite{kirranderEhrenfestMethodsElectron2020}. 

Quantum computers have access to an exponentially growing computational space for each additional qubit in the system \cite{nielsenQuantumComputationQuantum2010}. Current machines have access to hundreds of qubits, which would ideally allow them to already outperform current supercomputers. This is not the case due to noise coming from interactions with the environment and imperfect gate implementations. As such, NISQ algorithms \cite{bhartiNoisyIntermediatescaleQuantum2021} have to contend with limits on the number of imperfect operations that can be made. But even if this were not the case, we probably will always want to tackle a problem bigger than current machines can handle, which is why various approximations would have to be made. 

Current supercomputers by far outperform existing quantum computers in handling large quantum-chemistry problems, allowing NAMD of large atomistic models. Here we explore the  general concept of performing NAMD on near-term quantum computers. Applications to chemical problems will have to be deferred until there is a provable advantage in NISQ machines or fault-tolerant machines (near-ideal quantum computers which are fully error corrected) become a reality.

We propose a general algorithm to tackle NAMD by offloading the QM part to a quantum computer. Observables from the QM subsystem are measured and used to update the classical system, which in turn will update the time-dependent Hamiltonian that is used to evolve the QM state. The algorithm is demonstrated in the Shin-Metiu model \cite{shinNonadiabaticEffectsCharge1995}, which is often used to test various non-adiabatic techniques \cite{albaredaUniversalStepsQuantum2016,erdmannCombinedElectronicNuclear2003,falgeQuantumWavePacketDynamics2012,gosselNumericalSolutionExact2019}. We modify this to be a NAMD-like problem by partitioning the system into a classical nucleus and quantum electron and we evolve it through pure Erhenfest propagation. 


\section{\label{sec:theory}Theory}

\subsection{\label{ssec:SM}Shin Metiu Model}

The Shin-Metiu model is a numerically exactly solvable minimal model which captures essential nonadiabatic effects \cite{shinNonadiabaticEffectsCharge1995}. It is often used as a benchmark system for new techniques and is used to study the effects of different environments as has been done for polaritonic dynamics, coupling to cavities, and the effect of electromagnetic fields \cite{albaredaUniversalStepsQuantum2016,erdmannCombinedElectronicNuclear2003,falgeQuantumWavePacketDynamics2012,flickCavityBornOppenheimer2017}. It is simple to change its parameters for it to exhibit adiabatic to strongly non-adiabatic dynamics.

In its simplest and original conception, the model shown in Fig. \ref{fig:shin-metiu} consists of two stationary ions separated by a distance of \(L\), specifically located at \(\frac{L}{2}\) and \(\frac{-L}{2}\). These  enclose a mobile ion \(p\)  of mass \(M\) at distance \(R\) from the origin and an electron \(e^-\)  at distance \(r\). The "softened" Coulomb potential is parameterized by the constants \(R_{l},\ R_{r} \text{ and } R_{f} \), as shown in Eq. \ref{eq:shin_metiu}. 


\begin{figure}[h]
    \centering
    \includegraphics[width=1\columnwidth]{figures/shin_metiu.pdf}
    \caption{Illustration of the Shin-Metiu model with fixed ions at \(\frac{-L}{2},\ \frac{L}{2} \) as stationary boundaries, the mobile ion \(p\) of mass \(M\)  at distance \(R\) from the origin and the electron \(e^-\)  at distance \(r\) from the origin. \(R_{l} ,\ R_{r} \text{ and } R_{f} \) are constants for the "softened" Coulomb potential. }
    \label{fig:shin-metiu}
\end{figure}

The full Hamiltonian of the system is 
\[
    H=-\frac{1}{2M}\frac{\partial }{\partial R^2} +H_e(r,R),
\]
with the electronic part being
\begin{align}\label{eq:shin_metiu}
    \begin{split}
    H_e=&-\frac{1}{2m}\frac{\partial ^2}{\partial r^2} + 
    \frac{1}{\left\vert \frac{L}{2} -R  \right\vert }+\frac{1}{\left\vert \frac{L}{2} + R  \right\vert  }-\\
    &-\frac{ \text{erf} (\nicefrac{\left\vert \frac{L}{2} -r \right\vert }{R_r})}{\left\vert \frac{L}{2} -r \right\vert  }-
    \frac{ \text{erf} (\nicefrac{\left\vert \frac{L}{2} +r \right\vert }{R_l})}{\left\vert \frac{L}{2} +r \right\vert  }-
    \frac{\text{erf} (\nicefrac{\left\vert R -r  \right\vert }{R_f})}{\left\vert R-r \right\vert }.
    \end{split}
\end{align}
The equation uses atomic units, setting \(e=Z=\hbar=1\), we also take \(m=1\) and \(M=1836\) in the simulation. The constants 
\(R_{l},\ R_{r} \text{ and } R_{f} \), as shown in \rf{fig:shin-metiu}
are chosen to create specific adiabatic surfaces with transitions we would like to observe, as in \rf{fig:shin-metiu_BOPES}.

We use the values \(R_f=5.0,\ R_l=4.0\) and \(R_r=3.2\), which resulting in avoided crossing around  \(R=-1.9\) when the distancebetween the ions is \(L=19\). These parameters were chosen to be similar to those used in several studies of the model \cite{gosselNumericalSolutionExact2019,albaredaUniversalStepsQuantum2016}. The shape of the Born-Oppenheimer potential energy surfaces (BO-PES) can be seen in Fig.~\ref{fig:shin-metiu_BOPES} 

\begin{figure}[h]
    \centering
    \includegraphics[width=1\columnwidth]{figures/energy_levels.pdf}
    \caption{Potential energy surfaces for the coefficients \(R_f=5.0,\ R_l=4.0\) and \(R_r=3.2\) showing the crossing around position \(R=-2\) with \(L=19\) .}
    \label{fig:shin-metiu_BOPES}
\end{figure}
\subsection{Ehrenfest propagation of the model}

To perform Ehrenfest propagation of the Shin-Metiu model, we split the system in two. The  nucleus (\(p\) ) and the electron (\(e^-\) ). The electron subsystem is treated as a quantum particle described by Hamiltonian ~\ref{eq:shin_metiu}, where \(H_e\) is parameterized by the nuclear position (\(R\)). The nuclear subsystem is treated classically by tracking parameters of position (\(R\)) and velocity (\(\dot{R}\)). 

For initial coordinates \(R_0\text{ and }  \dot R_0\), we first prepare the electronic Hamiltonian \(H_e(R_0)\), which is used to compute the initial state of the electron \(\ket{\psi_0} \). Thanks to the simplicity of the model, we can use exact diagonalization to compute the eigenvectors and choose any arbitrary superposition of eigenvectors as the initial state.

The nucleus is evolved using the velocity Verlet method \cite{swopeComputerSimulationMethod1982} with the acceleration being computed from the Coulombic repulsion from the fixed ions and the force from the electronic state. The electronic state is evolved by unitary time evolution with the Hamiltonian at the nuclear position. We use a timestep \(\Delta t\), and the system state at timestep \(i\)  is denoted by under scripts \(i\), where the time is simply \(i\cdot \Delta t\). We set our initial conditions at timestep 0, and for the \(i^{\text{th} } \) step, we compute 

\begin{align}
\begin{split}
    F(q, \ket{\psi } ) &= - \bra{\psi} \frac{\partial H_e(q)}{\partial R}  
    \ket{\psi},  \\ 
\end{split}\\
\begin{split}
    R_i &= R_{i-1}+\dot R_{i-1} \Delta t +\frac{F_e}{M}(R_{i-1})\Delta t^2,\\\end{split}\\
\begin{split}
    \ket{\psi _i} &=  e^{-iH_{el}(R_{i-1})\Delta t}
                        \ket{\psi _{i-1}},\\
\end{split}\\
\begin{split}
  \dot R_i&=\dot R_{i-1} + \frac{F(R_{i-1},\ket{\psi_{i-1}} )+F(R_{i},\ket{\psi_{i}} )}{2M}\Delta t. \\ 
\end{split}
\end{align}



\subsection{Grid-based mapping to qubits}

We treat the Shin-Metiu system on the quantum computer in first quantization. We use a finite difference method on an equidistant grid. For low-dimensional problems, this is an appropriate approximation, but in general discrete variable representations (DVR) are a better choice for problems in higher dimensions. In quantum computing DVRs have been used to explore first quantization simulations in \cite{leeVariationalQuantumSimulation2022} using the Colbert and Miller DVR \cite{colbertNovelDiscreteVariable1992}. Issues exist with using DVRs on quantum computers as they generally require a full matrix Hamiltonian which is costly to measure and implement on quantum computers, and alternatives have been proposed \cite{ollitraultQuantumAlgorithmsGridbased2022}.  

Quantum computing in first quantization has the advantage that $n_g$ grid points can be represented by $N=\log_2(n_g)$ qubits. We choose $n_g=2^N$ to maximize the use of the $N$ available qubits. In the simplest finite differences method each position is an integer multiple $g$ of $\nicefrac{L}{n_g}$. The gird point $g$ is represented as $\ket{g\nicefrac{L}{n_g}}$ and mapped as
\begin{equation}
    \ket{g\nicefrac{L}{n_g}}=\ket{j_0}\otimes\dots\otimes\ket{j_k}\otimes\dots\otimes\ket{j_N},
\end{equation}
where $j$ is the binary representation of $i$ and $j_k$ is the bit value at position $g$. The potential operator \(\hat{V} \) is diagonal in this representation, simply sampling the potential at each grid point. The kinetic energy Hamiltonian is not diagonal in the position representation, and although one could use the split operator method \cite{hermannSplitoperatorSpectralMethod1988} to make it diagonal in momentum space would require a quantum Fourier transform implementation, which, as far as we know, cannot be effectively implemented on existing quantum devices. 

In the finite differences method, the one-dimensional potential and the Laplacian form of the kinetic energy can be written as
    \begin{align}
        V_{j,j^\prime } & = V(x_j)\delta_{j,j^\prime} \\ 
        T_{j,j^\prime } &= \frac{-\partial ^2 }{\partial r^2} \frac{1}{2m_{el}}f,\ f 
        \begin{dcases}
            -2, &\text{ if } j=j^\prime  ;\\
            1, &\text{ if }  j=j^\prime \pm 1.
        \end{dcases} \\
    \end{align}

The tridiagonal matrix that results has the same value on the off-diagonal terms, which allows them to be decomposed into Pauli strings through an elegant recursive form that can be seen in Appendix \ref{app:tridiagonal}. This is important because the number of non-zero entries is related to the number of terms in the Pauli decomposition, which should be kept minimal to reduce the length of the Trotterized time evolution operator and observable measurements. 

Although not implemented in this paper, there are algorithms that can make the time evolution of Hamiltonians with this form more efficient on near-term devices \cite{kalevQuantumAlgorithmSimulating2021}. Depending on the particular Hamiltonian one chooses to study in this way, different efficient algorithms exist to lessen the cost of the  time evolution such as variational fast forwarding and qubitization \cite{cirstoiuVariationalFastForwarding2020,lowHamiltonianSimulationQubitization2019}.   
 

\subsection{Circuit compression}

A key building block of the presented algorithm and a fundamental aspect of quantum circuit optimization is the concept of circuit compression \cite{rakytaEfficientQuantumGate2022}. Any operation on a quantum computer must be a unitary operation \(\hat{U} \), but the quantum computer only has a finite set of few-qubit gates. An arbitrary \(\hat{U} \) must be expressed, or compiled, into a set of native gates \cite{nielsenQuantumComputationQuantum2010}, this can always be done, but it is an NP-hard problem. If you allow yourself to implement an approximation of \(\hat{U} \) within some threshold, you may find \(\tilde{U}\) which might have a shorter circuit length than even an optimal decomposition of \(\hat{U} \). This latter definition is what is generally known as circuit compression, although the term is sometimes used to refer to more optimal perfect decompositions \cite{kokcuAlgebraicCompressionQuantum2022}.

With a perfect quantum computer, one could in theory implement gates as required if time allows. But noise is a problem on current machines, and short circuits are greatly favored in NISQ hardware as shorter circuits have a lower probability of an error occurring. Furthermore, designing optimal hardware ansatze for VQAs is an unsolved problem \cite{fedorovVQEMethodShort2022}. This means that for most purposes we use a heuristic ansatze \(\hat{C} \) parameterized by some vector \(\theta \) to bring the initial computational state \(\ket{0} \) to a desired state \(\ket{\psi } \) via \(\hat{C} (\theta )\ket{0} =\ket{\psi } \). But \(\hat{C} (\theta )\) may be overparameterized, which means that it may be possible that for some unitary \(\hat{U} \), \(\hat{U} \hat{C} (\theta )\ket{0} \approx\hat{C} (\theta ^\prime)\ket{0}\), which is what is exploited by \cite{linRealImaginaryTimeEvolution2021,barisonEfficientQuantumAlgorithm2021, berthusenQuantumDynamicsSimulations2022}. This follows from the property of unitary matrices, namingly

\begin{equation}\label{eq:unitary}
    UU^\dagger=U^\dagger U=I,
\end{equation}  
when we do not know the form of \(U\), the process of finding either the exact or approximate \(U^{dagger}\) is sometimes known as 'uncomputation'.   

Another approach is to approximate an initial state with such an ansatz and then perform a short-time evolution via Trotterization of the time-evolved operator. The adjoint of the ansatz is appended to the circuit and its parameters varied such that the machine state is 'uncomputed' to its initial state. If one must assume that the chosen circuit ansatz is expressive enough to capture the entire state's time evolution, then such an approach is guaranteed to work. One then simply needs this new set of parameters and the original ansatz to express the new timestep without the time evolution operator, hence compressing the circuit. This idea have been implemented almost concurrently by Lin et al. \cite{linRealImaginaryTimeEvolution2021}, and a little later by an algorithm called "projected variational quantum dynamics" (p-VQD) \cite{barisonEfficientQuantumAlgorithm2021}, and subsequent works, as for example \cite{berthusenQuantumDynamicsSimulations2022}, have built on their work.  




\section{Time-Dependent Hamiltonian Variational Quantum Propagation }


The time-dependent variational quantum propagation (TDVQP) algorithm builds on the circuit compression idea of "projected variational quantum dynamics" \cite{barisonEfficientQuantumAlgorithm2021} by allowing the Hamiltonian to be time-dependent. For many large problems of interest to theoretical chemistry, especially in MD, it is impossible to fully simulate the system of interest quantum mechanically. As such, the system is subdivided into classical and quantum components. The evolution of both systems occurs in locked steps, with the classical system defining the Hamiltonian for the quantum evolution, and the quantum system then feeding back into the classical system in the way of a force, as in Eq. (2)-(5). Of course, one mustn't limit themselves to molecular or even physical systems, as this algorithm would work with any set of observables that can be used to update a classical system. 

The algorithm first initializes a chosen electronic state $\ket{\psi_0}$ according to a Hamiltonian based on an initial vector of classical parameters $\vec q_0$ of the nuclear coordinates, which we denote $H(\vec q_0):=H_0$. This is done by choosing some sufficiently expressive parameterized circuit ansatz $\hat C(\vec\theta)$ which takes the quantum computer's initial state, denoted \(\ket{0} \), to \(\ket{\psi _0} \). This can be done using a VQA to find a chosen state with respect to $H_0$. which would return the circuit parameters $\vec\theta_0$. Then $\ket{\psi_0}=\hat C(\vec\theta_0)\ket{0}$. A chosen set of observables $ \{\hat O^{(s)}(q_0)\}:=\{\hat O^{(s)}_0\}$ are measured from $\ket{\psi_0}$, which return a set of expectation values $\{O^{(s)}_0\}$. These observables are  used to evolve the classical state of the system, generating a new vector of classical parameters $\vec q_1$. These can then be used to generate $H_1$ and $\{\hat O^{(s)}_1\}$. Now, one evolves the state from $\ket{\psi_0}$ to $\ket{\psi_1}$ by applying the time evolution operator to the state as such $\ket{\psi_1}=\exp{(-i\hat H_0\Delta t)}\ket{\psi_0}$. In this work, we simply use $\hat H_0$ to evolve the state, but it is possible to use some other combination, such as $(\hat H_0+\hat H_1)/2$. Now we compress the time-evolved state by optimizing with respect to the following cost function:

\begin{equation}\label{eq:optimization}
    \max_{\vec\theta_0^\prime}|\bra{0}\hat  C(\vec\theta_0^\prime)^\dagger \exp{(-i\hat H_0\Delta t)} \hat C(\vec\theta_0)\ket{0}|^2.
\end{equation}

This process generates the new circuit parameters $\theta_1$ that allow $\ket{\psi_1}\approx \hat C(\theta_1)\ket{0}$ to some desired treshold. This process is repeated until the desired timestep is reached. The entire process is more precisely described in Algorithm~\ref{alg:TDVQP}, and a depiction of the quantum circuit can be seen in Fig.~\ref{fig:TDVQP}. 


 \begin{figure}[h]
     \centering
    \begin{quantikz}
        \lstick[]{$\ket{0}$}&\gate[]{C(\theta_i)}\slice{$\ket{\psi_{i}}$}\qwbundle[alternate]{}
        &
        \gate[]{e^{-iH_i\Delta t}}\slice{$\ket{\psi_{i+1}}$}\qwbundle[alternate]{} &\qwbundle[alternate]{}&
        \gate{C(\theta_i)^\dagger}\qwbundle[alternate]{}&
        \qwbundle[alternate]{} \rstick[]{$\approx\ket{0}$}\\
        \lstick[]{$\ket{0}$}&\gate[]{C(\theta_i)}\qwbundle[alternate]{}
        &
        \gate[]{e^{-iH_i\Delta t}}\qwbundle[alternate]{} &\qwbundle[alternate]{}&
        \gate{C(\theta_i^\prime)^\dagger}\gategroup[wires=1,steps
=1,label style={label position=below,yshift=-4,anchor=north}]{When optimized $\theta_i^\prime=\theta_{i+1}$}\qwbundle[alternate]{}&
        \qwbundle[alternate]{} \rstick[]{$\ket{0}$}
    \end{quantikz}  
    \begin{quantikz}
        \lstick[]{$\ket{0}$}&\gate[]{C(\theta_{i+1})}\slice{$\ket{\psi_{i+1}}$}\qwbundle[alternate]{}
        &\gate[]{\hat O}\qwbundle[alternate]{}&\meter{}\qwbundle[alternate]{}
    \end{quantikz}
     \caption{Sketch of the TDVQP process with slices showing the state after each gate at the initial condition and final condition. Both the initial and final states are the $\ket{0}$ at the end of the optimization, the initial guess for the parameter vector $\theta_i^\prime$ is $\theta_i$ and its final value is denoted $\theta_{i+1}$. Then observables $\hat O$ can be measured on $\ket{\psi_{i+1}}$ to update the Hamiltonian or the classical state of the system.}
     \label{fig:TDVQP}
 \end{figure}  



 TDVQP should be thought of as a meta-algorithm that has replaceable components. The most directly replaceable part is the choice of ansatz \(\hat C(\vec \theta )\) , which at the moment is generally a heuristic choice for most problems for NISQ devices. More advanced ansatze such as the family of adaptive ansatze, which changes the ansatz throughout the evolution would work, but could not use the previous step's $\theta$ parameters as effectively.  The very costly time evolution is currently a trotterized form of the time evolution operator, as in this work, and in \cite{barisonEfficientQuantumAlgorithm2021, berthusenQuantumDynamicsSimulations2022}. This can be replaced by a plethora of more NISQ-friendly time evolutions as is done in \cite{lowHamiltonianSimulationQubitization2019, cirstoiuVariationalFastForwarding2020} if the form of the Hamiltonian allows this. Furthermore, on the classical evolution side, the choice of integrator and the actual Hamiltonian used in the time evolution will depend on the type of problem and desired accuracy. TDVQP becomes exact when \(\hat{C} (\vec\theta )\) can express the system perfectly for any configuration of classical parameters \(\vec q\), given that the exact parameters \(\theta \) can be found by optimization.     

\begin{algorithm}\label{alg:TDVQP}
    \caption[short]{Time-Dependent Variational Quantum Propagation (TDVQP)}
    \SetKwFunction{ecost}{EvalCost}
    \SetKwFunction{eval}{ExpectationValue}
    \SetKwFunction{force}{MeasureObs}
    \SetKwFunction{update}{UpdateParameters}
    \SetKwFunction{upfun}{UpdateFunction}
    \SetKwFunction{upang}{UpdateAngles}
    \SetKwFunction{vqe}{VQE}

    \SetKwBlock{rep}{repeat}{}

    \SetKwProg{Fn}{Function}{:}{}
    \KwIn{$\hat H_{\text{gen}}(\vec q\ )$, \(C(\vec\theta)\ \), $ \{{\hat O}^{(s)}_{\text{gen}}(\vec q)\}$, \ecost, \(\vec q_{\text{0} } \)}
    \Fn{\vqe($\hat{H}_{\text{gen} }(\vec{q} ) $, $C(\vec\theta)$, $\vec q $) }{
        \(\vec\theta^\prime   = \mathop{\min}_{\theta } \) \eval(\((\hat{H} _\text{gen} (\vec q ),C(\vec\theta)\)))\; 
        \KwRet \(\vec\theta^\prime  \) 
    }
    \Fn{\update(\(\vec O(\vec q\ )\), $\vec q$)}{
        \(\vec {q^\prime } \)  = \upfun ($\vec{q} $, \(\vec O(\vec q\ )\))\;
        \KwRet \(\vec {q^\prime } \) 
    }
    \Fn{\upang(\(C(\vec\theta\ ),\ \hat{H} ,\ \Delta t\))}{
        \(\vec{\theta }\) = \(\mathop{\min} _{\vec{\theta_i^\prime } }\) \ecost(\( C(\vec{\theta_{\text{i}}^\prime })\exp(i\hat{H}\Delta t) C(\vec{\theta_{\text{i} } })^{\dagger}\)) \;
        \KwRet \(\vec{\theta }\)
    }

    \Fn{\force($\{{\hat O}^{(s)}_{\text{gen}}(\vec q)\}$, \(C(\vec\theta\ )\))}{
        for s in number of observables \rep{
        \( O^{(s)}\) =  \eval(\(\hat O_{\text{gen} }^{(s)}(\vec q\ ) \), \(C(\vec\theta\ )\)) \;}
        \KwRet \( {O_i^{(s)}}\) 
    }
    \Fn{TDVQP($H_{\text{gen} }(\vec q\ ) $, \(C(\vec\theta )\), \(\vec q_{0 }\))}{
        store all \(\vec \theta _i,\  \{O^{(s)}_i\},\ \vec{q} _i \) in arrays \(\pmb{\theta ,\ O,\ q} \) \; 
        \(\vec\theta_0\) = \vqe (\(\hat{H} _\text{gen} (\vec{q} _0)\), \(C(\vec{\theta} )\))  \;
        \(\{ O_0^{(s)}\}\)  =  \force ($\{\hat O^{(s)}_{\text{gen} }(\vec q_0)\}$, \(C(\vec \theta_0)\))\;
        for \(i = 1\) to \(n_t\) timesteps \rep{
            \(\vec q_i\) = \update ($\{ O_{i-1}^{(s)}\}$, $\vec q_{i-1}$) \;
            \(\vec \theta _i\) = \upang ($C(\theta _{i-1}), \hat{H}_{\text{gen} }(\vec{q}_{i-1}), \Delta t$) \;
            \(\{ O_i^{(s)}\}\)  =  \force ($\{\hat O_{\text{gen}}^{(s)}(\vec q_i)\}$, \(C(\vec \theta_i)\))\;
        }
        \KwRet \(\pmb{\theta ,\ O,\ q} \) 

    }

\end{algorithm}


\section{Numerical simulations}

\subsection{Simulation Parameters}\label{sec:simparam}
To gauge the performance of the scheme we implement the Shin-Metiu model as described in Section~\ref{ssec:SM}. In the BOPES, we see an avoided crossing at around \(R=-1.9\) a.u. We initialize the system with the nucleus at an initial position of \(R=-2\) a.u. and an initial velocity of \(v_0=1.14\cdot 10^{-3}\) a.u., the average nuclear velocity from the Boltzmann distribution at 300K. The electronic system is initialized through the VQE with a random set of parameters and is allowed 300 iterations to approximate the ground state. The system is then evolved through the TDVQP algorithm with a timestep of \(\Delta t=0.5\) a.u. Each quantum time evolution step is allowed up to 100 iterations or a fidelity threshold of $1-10^{-5}$ to find the optimal circuit parameters to approximate the previous time evolved state. All simulations are done on 16 grid points that can be represented by 4 qubits. 

We examine two different situations. First, keep the initial conditions constant but to sample different VQE ground state approximations, which we call the "Single Initial Condition" case. In the second case we examine in depth is the MD-type approach, where we sample a normal distribution of initial conditions for the initial velocity of the nucleus and allow one TDVQP evolution per sample. The velocity distribution is sampled from the Boltzmann distribution, only keeping positive velocities so that the nuclei approach the avoided crossing. The results shown are 100 samples that are evolved for 1000 timesteps which bring the classical trajectory beyond the avoided crossing point. 

Additional examples are provided for longer-time evolutions as well as for non-ground state evolution in Appendix~\ref{app:longtime}. Excited states and superpositions are prepared by using the uncomputation step of the TDVQP, but instead of starting the state with a known circuit from the VQE, the simulator is simply initialized to a desired arbitrary state, and the optimizer attempts to uncompute it with the ansatz and then those parameters are used as the initial step in place of the VQE. Various techniques to prepare excited states exist \cite{gochoExcitedStateCalculations2023,mccleanHybridQuantumclassicalHierarchy2017a}, but are not the focus of this work. 

We use two different metrics to establish the accuracy of the TDVQP algorithm: the so-called "Ideal" evolution begins at the desired state to numerical precision and is evolved by exact diagonalization. But, precise state preparation is another area of intense study \cite{aulicinoStatePreparationEvolution2022}. To better gauge the performance of the TDVQP in isolation, we also perform an "Exact" evolution, which uses the VQE-optimized initial state for evolution via exact diagonalization. This allows us to remove any bias from a poorly optimized ground state. 

The VQE uses an ansatz of the form shown in Figure~\ref{fig:ansatz}, which was heuristically chosen as it can achieve ground state fidelities of up to \(1-1^{-5} \) on this system with 4 layers. Various ansatze can be used, and for first quantization problems, in particular, there are some examples of how several different heuristic ansatze perform in \cite{ollitraultQuantumAlgorithmsGridbased2022}. The number of repetitions of the Trotterization layer is another important parameter, but as the decomposition of the Trotterized operator into native gates is deep, we limit ourselves to one. Although for full quantum dynamics, this would be very inaccurate for larger timesteps, the interaction with a classical system actually necessitates that we use short time steps, so that the Hamiltonian of the system is kept up to date with the classical state of the system. This means that a single trotter step is actually all that is needed, and the number of layers of the ansatz can compensate as shown in Appendix~\ref{app:trotlay}.

\begin{figure}
    \centering
    \begin{quantikz}
        \lstick[]{$q_0$}&\gate{R_x(\theta_{0})}
        &\ctrl{1}[label position=above]{\theta_3}&\qw&
        \gate[]{R_y(\theta_{5})} &\ctrl{1}[label position=above]{\theta_8}&\qw&\qw\\
        \lstick[]{$q_1$}&\gate[]{R_x(\theta_{1})}
        &\control{}&\ctrl{1}[label position=above]{\theta_4}&
        \gate[]{R_y(\theta_{6})}&\control{}&\ctrl{1}[label position=above]{\theta_9}&\qw\\
        \lstick[]{$q_2$}&\gate[]{R_x(\theta_{2})}
        &\qw&\control{}&
        \gate[]{R_y(\theta_{7})}&\qw&\control{}&\qw\\
    \end{quantikz}
    \caption{One layer of the ansatz used for the VQE and TDVQP for three qubits. If multiple layers are used then the above circuit is repeated. If more qubits are used then the vertical motif is continued. In both cases, more parameters can be added as needed and \(\vec \theta\) refers to the list of all parameters.}
    \label{fig:ansatz}
\end{figure}

The simulations were run on the Qiskit statevector simulator (version 0.28) using the parameter-shift rule \cite{crooksGradientsParameterizedQuantum2019, wierichsGeneralParametershiftRules2022} to determine the analytic gradients required for gradient-descent based optimization. Although it is always interesting to see how an algorithm behaves under noisy conditions, the performance of p-VQD under noise has been explored for full quantum dynamics in \cite{berthusenQuantumDynamicsSimulations2022}. This work focuses on the interplay between the scheme under the effect of a Hamiltonian which depends on the measured observables.   

\subsection{Results}

\subsubsection*{Single initialized state}

The results pertaining to the evolution of a single set of initial conditions are meant to represent the precision of this algorithm to exactly reproduce a quantum-classical system. Although this is not the intended use case of TDVQP, it is nonetheless the most instructive to determine its behavior. 

An important gauge for the validity of simulations of closed systems is whether they conserve energy or not. We use a symplectic integrator in the classical system (velocity Verlet), and in the exact diagonalization case, we see energy conservation for up to 50,000 timesteps. As can be seen in Figure~\ref{fig:Senergy} the TDVQP algorithm does not conserve energy. This is due to the fact that higher energy levels are populated more and more as the system evolves, as the optimization is limited to a finite number of iterations. The effect of this can be seen clearly in Figure~\ref{fig:Spop}, where it can be seen that the population in higher states increases much faster than in the ideal case. Although it is not shown, starting the exact evolution from the VQE state does begin with some "population" in the higher energy levels, but this does not change as the evolution progresses. 

\begin{figure}[h]
    \centering
    \includegraphics[width=1\columnwidth]{figures/timestep_comparison_energy.pdf}
    \caption{Figure showing the mean relative TDVQP energy in blue for "Single" initialization and orange for "MD" initialization. The highlighted area showing the standard deviation of the distribution of 100 separate runs of 1000 timesteps of $0.5$ a.u. The other lines show the ideal initial state energy evolution. The energy continually increases in the TDVQP as higher energy levels are increasingly populated.}
    \label{fig:Senergy}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\columnwidth]{figures/single_populations.pdf}
    \caption{Graph showing the observed electron force between the ideal simulation and 100 instances of TDVQP evolution over 1000 timesteps of $0.5$ a.u. The populated states are the same as those seen in Figure~\ref{fig:shin-metiu_BOPES}. The main graph is in logarithmic scale showing faint lines for higher energy levels populated by TDVQP, with the inset showing a linear scale of the two most populated levels.}
    \label{fig:Spop}
\end{figure}

As a consequence of the higher energy levels being increasingly populated as the evolution progresses, it is the case that the fidelity decreases gradually. This is indeed the case and can be seen in \rf{fig:Mfidelity}. Of course, this general degradation of quality is not optimal. Strategies could be employed in the optimization to mitigate this, such as measuring the energy and allowing the cost function to penalize when the system is not conserving energy, but this would require measuring the expectation value of the system Hamiltonian which would increase the shot cost of this algorithm dramatically.  


Despite the problem with energy conservation, using such an algorithm to measure an observable such as the force exerted on the nucleus by the electron (\(F_{el}\)) can still lead to reasonable results. \rf{fig:Sforce} shows the distribution of the electron force measurements from TDVQP compared to the ideal state. It is clear that the mean value slowly deviates from the ideal evolution until the mean is further than one standard deviation from the TDVQP results. Nonetheless, MD simulations generally don't start with a single set of initial conditions but rather, a thermal distribution of the nuclear positions, velocities, and electronic states \cite{hanggiReactionrateTheoryFifty1990}. This means that the imperfections of the algorithm may not be a problem in an MD-like simulation setting.   

\begin{figure}[h]
    \centering
    \includegraphics[width=1\columnwidth]{figures/single_force.pdf}
    \caption{Graph showing the observed electron force between the ideal simulation and 100 instances of TDVQP evolution over 1000 timesteps of $0.5$ a.u. In this case, the exact and ideal results are nearly identical to the mean. The ideal results are black with a dash-dash-dot line, and the TDVQP mean results are in orange, with the standard deviation shown as a highlight. The upper and lower quartiles of the TDVQP results are also shown, as well as faint lines representing individual evolutions.}
    \label{fig:Sforce}
\end{figure}

\subsubsection*{Molecular Dynamics inspired initialized states}

For this MD simulation, we instead use a single TDVQP evolution per trajectory. The trajectories are picked from random pairs of normal distributions around the same initial state as the 'single initialized state', with the specific values written in \rs{sec:simparam}. We see in \rf{fig:Mfidelity} that the MD fidelity decays similarly to the single case on average. On a run-by-run basis, this is due to the same leakage to higher energy levels.  

\begin{figure}
    \centering
    \includegraphics[width=1\columnwidth]{figures/Comparison_fidelity.pdf}
    \caption{Graph showing the mean fidelity between the exact diagonalization evolution of the VQE initialized state and the TDVQP evolution over 1000 timesteps of $0.5$ a.u. for 100 different MD-like trajectories in blue (solid line) and 100 single initializations (dashed orange line). The highlighted area represents one standard deviation of the distribution.}
    \label{fig:Mfidelity}
\end{figure}

Where we do see a marked improvement is in the measurement of the electron force. This is shown in \rf{fig:Mforce}, where now the ideal simulation also has a distribution owing to the different trajectories. Here both means lie well within their respective standard deviations, and the distributions fall well within each other. Since some randomness is actually desired in the different trajectories, it could very well be the case that a true advantage can be gained from using quantum computers to compute the quantum mechanical parts of an MD simulation. Many problems that occur due to short coherence times for full quantum systems are avoided. Only being able to use a single trotter step on a NISQ device is a detriment to full quantum evolutions, but is essential to MD simulations of this kind, where there is an exchange of information between the classical and quantum simulations. The random noise and imperfections of both the TDVQP and the quantum computer can also be washed out by the averaging done in such simulations. 

\begin{figure}
    \centering
    \includegraphics[width=1\columnwidth]{figures/MD_force.pdf}
    \caption{Graph showing the observed electron force between the ideal simulation and 100 instances of TDVQP evolution over 1000 timesteps of $0.5$ a.u. for 100 different 'MD' trajectories. Because of this, both results have a distribution. The ideal results are black with a dash-dash-dot line with the standard deviation of the ideal trajectories shown as a dark highlight. The TDVQP mean results are shown as an orange solid line, with upper and lower quartiles of the TDVQP results shown as blue and red dashed lines, as well as faint lines representing individual TDVQP evolutions.}
    \label{fig:Mforce}
\end{figure}

It is also the case that in this simple model, the energy levels are well separated and we begin in the ground state. This results in a strong contribution consisting of leakage from higher-lying energy levels. In a more complex molecule, one would begin from a thermal ensemble of not only velocities but also states. In turn, the leakage would then result in deviations from both higher and lower energy levels and be less detrimental to the ensemble average than here. Strategies to mitigate this do exist, but require additional resources. 

\section{discussion}

Time-dependent evolution is an exceptionally interesting problem that can be well explored through quantum computers. There are many techniques that can be used for full quantum systems \cite{cirstoiuVariationalFastForwarding2020a,leeVariationalQuantumSimulation2022,lowHamiltonianSimulationQubitization2019,yaoAdaptiveVariationalQuantum2021,berthusenQuantumDynamicsSimulations2022,barisonEfficientQuantumAlgorithm2021} which are suitable to both near term and fault-tolerant machines. 

Algorithms that are suitable for MQC dynamics do require efficient and accurate full quantum dynamics, but the interplay between the classical and quantum systems brings a new spate of challenges. To exchange information, one must measure observables from the quantum system, which is expensive and destroys the state, requiring at minimum an efficient way to measure energy gradients, which is an area of active research \cite{obrienEfficientQuantumComputation2022}. This is a disadvantage, but it also means that one is limited to short-time evolutions between measurements. This makes it possible that a single trotter step is accurate enough \cite{babbushChemicalBasisTrotterSuzuki2015,trotterProductSemiGroupsOperators1959}, which is beneficial to near-term devices. 

Even though larger timesteps may be possible, the longer the time evolution, the longer the optimizer takes to find the time-evolved ansatz parameters. This is because the previous timestep parameters are no longer as close to the evolved ones. At the same time, most classical MQC methods do not update the parameters that govern the classical system's evolution at the small time intervals we use \cite{curchodInitioNonadiabaticQuantum2018}. One could do multiple compression steps with short-time Trotterizations using a constant Hamiltonian and only measuring the desired observables after the quantum system has evolved for the standard timestep of your classical problem, performing updates after this point. This can even accelerate the computation because the optimizer might find the optimal state faster.  

The algorithm we present takes advantage of the above facts and is highly modular. Although the results are shown using an algorithm like p-VQD \cite{barisonEfficientQuantumAlgorithm2021} with trotterization of the operator, there is no reason that other efficient time evolution algorithms couldn't be used. This is especially true if the time evolution operator could be efficiently represented by techniques other than Trotterization of the Hamiltonian. The update step used here measures the Pauli string decomposition of the \(\frac{dH}{dR}\) matrix to compute forces, but other techniques exist \cite{obrienCalculatingEnergyDerivatives2019,obrienEfficientQuantumComputation2022}. Of course, the classical propagation itself and its interplay with the quantum system is a rich field with numerous approximations and techniques that exist and are continuously being improved in both QM/MM and NAMD simulations \cite{curchodInitioNonadiabaticQuantum2018,groenhofIntroductionQMMM2013}. 

The main issue with TDVQP is the fact that throughout the time evolution, there is leakage to the higher states as in \rf{fig:Spop}. The ansatz and algorithm do not have any restraints related to the modeled system, and so the inevitable inaccuracies in optimization are equivalent to 'populating' other energy levels in the desired system. This has the direct consequence that Energy is not conserved, even though in the ideal simulation this is the case as shown in \rf{fig:Senergy}. The fact that it is increasing constantly is due to the fact that the quantum system is initialized in the ground state, and all leakage is to higher energy levels. In Appendix~\ref{app:longtime} there is an example where higher energy states are eventually populated, such that leakage to lower energy levels lowers the overall energy of the system. Regardless of this, the qualitative state population evolution follows the ideal case closely, but the fidelity to the ideal case falls as the evolution continues.

These problems could be fixed by either increasing the threshold of the uncomputation step or by measuring the energy and penalizing the optimizer when energy is not conserved. Another option that may be possible is designing an ansatz with problem-specific constraints \cite{gardEfficientSymmetrypreservingState2020}. Such ansatze take into consideration properties such as particle preservation within their structure, which may remove the need for expensive additional iteration steps or additional measurements. Furthermore, it may be possible to replace the p-VQD propagation with other compression methods \cite{berthusenQuantumDynamicsSimulations2022}. 


Overall we have introduced the TDVQP algorithm for MQC dynamics with the quantum subsystem computed on a quantum computer and have explored it on the Shin-Metiu model as an example of Ehrenfest dynamics in first quantization, although it is not limited to this setting. It reproduces the expected observables and state evolution qualitatively. The algorithm is modular and refinements to it may be tackled in future research. Inaccuracies of the quantum computer can also be mitigated when computing ensemble averages of the classical properties. This work shows that MQC simulations may be practically feasible on noisy quantum computers if it is proven that variational quantum algorithms can have an advantage in chemical problems. 

\begin{acknowledgments}
This work was supported by the European Union’s Horizon 2020 research and innovation programme under the Marie Sk\l{}odowska-Curie grant agreement No. 955479. Computing resources were provided by the state of Baden-Württemberg through bwHPC and the German Research Foundation (DFG) through grant INST 35/1597-1 FUGG.
\end{acknowledgments}
\bibliography{Library.bib}
\clearpage
\newpage

\appendix 
\section{Tridiagonal decomposition}
\label{app:tridiagonal}
% \section{Recursive expression of a tridiagonal matrix in the Pauli basis}
The real-space Hamiltonian for the Shin Metiu model is tridiagonal. There is a recursive solution to expressing tridiagonal hermitian matrices in the Pauli basis. The off-diagonal matrices can be expressed as:

\begin{align*}
A_1 = & X\\
    A_n  =& I_{2} \otimes A_{n-1} +(X \otimes I_{2^{n-1}} )\otimes \\
    & \left[ \frac{1}{2^n}
    \sum_{t=0}^{\lfloor \nicefrac{n}{2}\rfloor} (-1)^t \sum_{\pi}S_\pi\left( X^{\otimes(n-2t)}\otimes Y^{\otimes 2t}\right) \right]\otimes\\
    &(X\otimes I_{2^{n-1}}),
\end{align*}

Where X and Y are the Pauli matrices, and $S_{\pi}$ is the permutation function that returns a unique combination $\pi$ of the Pauli string. That is to say that if we have the string $XYY$, we would get the sum $XYY+YXY+YYX$. This grows exponentially, but with a qubit-wise recursive largest first commutator, it grows as $\mathcal{O}(2^{\nicefrac{n}{2}})$ and if we look at the fully commuting largest first approach, then the number of terms grows as $\mathcal{O}(n)$. The diagonal matrix is then the \(2^{n} \) term weighted linear combination of all possible \(n\) length Pauli strings comprising of \(I\) and \(Z\) matrices. 


\section{On Trotterization and ansatz layers}
\label{app:trotlay}
\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{figures/depth_trotter_fidelity.pdf}
    \caption{Mean fidelity with respect to the depth of the ansatz and the number of trotter steps in the evolution for 10 samples of 200 timesteps. The lowest depth is 3 (blue), while the next step is of depth 4 (orange), and the deepest is 5 (green). The different Trotter approximations are various dashed or solid lines, but since the time evolution is short, this has little effect compared to the depth of the ansatz.}
    \label{fig:fid_comp}
\end{figure}

Although one can have a near infinite amount of variability in the heuristic form of the ansatz, which we have chosen to be the one shown in \rf{fig:ansatz}. But even for a single ansatz it is important to find what the optimal depth is for a given problem, and in this algorithm, we also want to see the importance of the number of steps in the Trotter approximation. \rf{fig:fid_comp} shows that in the modified Shin-Metiu model we use the timestep of 0.05 a.u. the order of the Trotterization has a small effect compared to the depth of the ansatz. This is not unexpected, as the timestep is very small. For the simulations, we have used a depth of 5 and a single Trotter step for the best compromise between depth and precision. 

Another important point is whether it is beneficial to use longer timesteps within the limits of the chosen trotterization depth or to use conservatively short steps. To see the effect of this, we can look at the fidelity of the same simulation as the single case in the main text but with 500 steps of \(\Delta t=0.5\) [a.u.] and 5000 steps of \(\Delta t=0.05\) [a.u.]. Both have a total time of 250 [a.u.], but as should be evident from Figure~\ref{fig:timestep_comp} the two approaches show very different behaviours. When looking at the quality over 'simulated time', choosing larger timesteps is obvious. But if you look at fidelity over the number of timesteps, the shorter timesteps do have an advantage. The reason for this is because the optimizer has a fidelity treshold of \(\phi\) compared to its previous step; as a first approximation, one can assume this fidelity is reached exactly at each timestep \(T\), then after \(T\) steps we would have a fidelity of \(\phi ^T\) compared to our ideal situation. 

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{figures/fidelityVStimesteps.pdf}
    \caption{An example of the difference between many small timesteps and fewer large timesteps for an evolution like that described for the single case in the main text.}
    \label{fig:timestep_comp}
\end{figure}

Realistically, the size of the timestep also has a large effect on the iterations the optimizer must take to converge. $1,000$ steps of $\Delta t=0.5$ take longer than $10,000$ steps of $\Delta t=0.05$ given the same treshold. There is also such a thing as a 'golden' initial state, which has the property that many parameters in the ansatz are initialized in such a way that they stay constant or vary smoothly throughout the evolution. Such initializations optimize faster and retain higher fidelities than initial parameters that have much more chaotic 'spiky' evolutions. Although this is hard to quantify, it is something that could be used to filter out badly behaving initializations early on in the evolution.   

\section{Additional examples}
\label{app:longtime}

\subsection{Multiple transitions}
The simulation parameters for these examples are synthetic, with a \(\Delta t=0.05\) and an initial velocity of \(v=0.2\), which allows us to see if the algorithm can deal with more complex dynamics within 700 timesteps. All other parameters are kept as in the main text. Figure~\ref{fig:single_pop_long} shows the dynamics of the populations with 4 population crossings that are well described between states 0,1 and 2. 
\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{figures/single_populations_long.pdf}
    \caption{Initializing the simulation of the Shin-Metiu model beginning in the ground state, and evolved for 700 steps of \(\Delta t=0.05\). The lines show the mean BOPES state populations with faint lines represent higher energy levels of the TDVQP.}
    \label{fig:single_pop_long}
\end{figure}

What is particularly interesting is that around the end of the simulation (\(t>17\)) we see that there is a fall in occupation of the second state and an increase in the first state. This is nicely matched by what we can see in the energy in Figure~\ref{fig:energy_long}. Indeed, we see that now that the state is highly excited, population loss to lower energy states causes a drop in the energy rather than the increase we have generally seen. 

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{figures/S_energy_long.pdf}
    \caption{Change in the energy of the TDVQP algorithm as it progresses over 700 timesteps of \(\Delta t=0.05\) starting in the ground state, but with a fast-moving proton (with an initial velocity of \(v=0.2\)).}
    \label{fig:energy_long}
\end{figure}

This fall in energy is not accompanied by an increase in fidelity, and as \rf{fig:fidelity_long} shows, the fidelity keeps decreasing at a steady rate, although likely that at very long times it would begin to oscillate at around 0.5.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{figures/idelity_long.pdf}
    \caption{Plot showing the fall in the fidelity of the TDVQP wavefunctions compared to the exact evolution of the initial state for 700 timesteps of \(\Delta t=0.05\). It can be seen that it falls over time quite steadily.}
    \label{fig:fidelity_long}
\end{figure}


\subsection{Arbitrary state evolution}
To prepare an arbitrary state we use the fact that we expect to be able to find some unitary \(U\) that can operate on a state \(\ket{\psi } \) such that \(U\ket{\psi } =\ket{0} \). If we make this circuit have the form of our desired ansatz and only allow ourselves to vary the parameters \(\theta \). We decide on some threshold or number of iterations and optimize the expression \(\mathop{\min} _\theta  (1-|\bra{\psi }U(\theta )\ket{0}|^{2}) \) to some threshold. This is done by running the circuit in \rf{fig:arbitrary_prep}, where we simply initialize the quantum computer with the excited state in some way. For our simulation, we simply set the starting state to be our desired state, and we show an example for initializing in the first excited state in \rf{fig:excited_pop} and a superposition of the two lowest BOPES in \rf{fig:superposition_pop}. 
\begin{figure}[h]
    \centering
   \begin{quantikz}
       \lstick[]{$\ket{\psi_{\text{desired}  }}$}&
       \gate{U(\theta)^\dagger}\qwbundle[alternate]{}&
       \qwbundle[alternate]{} \rstick[]{$\approx\ket{0}$}\\
   \end{quantikz}
    \caption{Sketch of computing the ansatz parameters for arbitrary state preparation. The quantum simulator is initialized in the desired state, and the ansatz \(U\)  parameters \(\theta \) are varied until the final state is close to \(\ket{0} \). }
    \label{fig:arbitrary_prep}
\end{figure}  


\begin{figure}[H]
    \centering
    \includegraphics[width=\columnwidth]{figures/Excited_populations_long.pdf}
    \caption{Initializing the simulation of the Shin-Metiu model in the first excited state, and evolved for 700 steps of \(\Delta t=0.05\). Initial conditions are the same as in \rs{sec:simparam} and the lines show the mean BOPES state populations. The faint lines represent higher energy levels of the TDVQP.}
    \label{fig:excited_pop}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\columnwidth]{figures/Superposition_populations_long.pdf}
    \caption{Initializing the simulation of the Shin-Metiu model with an equal superposition of the 0 and 1 state showing the mean BOPES state populations, and evolved for 700 steps of \(\Delta t=0.05\).  Initial conditions are the same as in \rs{sec:simparam} and the lines show the mean BOPES state populations. The faint lines represent higher energy levels of the TDVQP.}
    \label{fig:superposition_pop}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\columnwidth]{figures/alternate_fidelity_long.pdf}
    \caption{Fidelity over the evolution of the equal superposition of the lowest BOPES states (solid, blue) and first excited state (orange, dashed).}
    \label{fig:superposition_en}
\end{figure}


\begin{figure}[H]
    \centering
    \includegraphics[width=\columnwidth]{figures/alternate_force_long.pdf}
    \caption{Force measurements for an equal superposition of the lowest BOPES states (solid, blue) and first excited state (orange, dashed) compared to their respective ideal simulations (black).}
    \label{fig:superposition_for}
\end{figure}



Figures \ref{fig:arbitrary_prep} and \ref{fig:excited_pop} both show that the states of interest are initially well represented by the algorithm. As the evolution continues the evolution remains qualitatively similar, but degrades, especially when populations approach the 'noise floor' of the algorithm around \(10^{-3}\) where the higher energy levels are populated. \rf{fig:superposition_en} shows a very sharp decrease in fidelity in the first timesteps and quite a large standard deviation compared to ground state results shown in Figure \ref{fig:fidelity_long}. This may either be due to not being able to initialize the ansatz as well in non-ground state settings with our approach here. Forces are still well followed qualitatively as in \rf{fig:superposition_for}.




\end{document}
