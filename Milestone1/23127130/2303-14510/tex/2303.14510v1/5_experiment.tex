\section{Performance Evaluation}  \label{sec:experiment}

The TMKU algorithm was evaluated by a series of tests on various types of datasets. By comparing the results, the correctness and efficiency of the TMKU algorithm are proved. The TMKU algorithm, as previously noted, is the first to discover the top-$k$ HUIs that include a target pattern. All the current top-$k$ HUIM algorithms cannot successfully tackle the challenge of considering the user's needs. As a result, none of the existing methods can be compared to analyze and evaluate the proposed TMKU algorithm.

On the one hand, to determine the accuracy of the algorithm, we compared the results of the TMKU algorithm with those of the TargetUM algorithm after post-processing on various datasets. On the other hand, we conducted various experiments on six datasets to determine the efficiency of TMKU in a comprehensive manner and evaluated three variants using different pruning strategies. It is worth noting that TMKU$_{V1}$ only uses the Strategy \ref{lab:one} and Strategy \ref{lab:three}, and TMKU$_{V2}$ uses the Strategy \ref{lab:two} and Strategy \ref{lab:three}. When all pruning strategies are used, TMKU is obtained. As a result, three versions are used to evaluate the efficiency of TMKU.

\subsection{Experimental setup}

All the algorithms were programmed in Java. The PC used for experiments is equipped with 8.0 GB of RAM, 64-bit Windows 10, and an AMD Ryzen 5 3600 CPU.

To assess the effectiveness and scalability of the TMKU algorithm, experiments were carried out on a variety of datasets, including real and synthetic databases. The SPMF data mining library is the source of all the datasets\footnote{http://www.philippe-fournier-viger.com/spmf/}. These datasets have different characteristics, which makes it beneficial to observe the performance of the algorithm in different situations. Table \ref{table:data} lists all the features of the experimental datasets. A brief description is given below.


\begin{itemize}
	\item \textbf{Retail} is a real-life dataset with many items in each transaction. Transactions come from a store in Belgium and the utility values are synthetic.
	
	\item \textbf{Foodmart} is a transaction dataset from a grocery store where items are sparse and transactions are short.
	
	\item \textbf{Chainstore} is a transaction dataset containing over a million transactions from a chain store in California.
	
	\item \textbf{Ecommerce} is a transactional dataset that contains all the transactions of an online retail store and has real utility values.
	
	\item \textbf{Mushroom} is a dense and real-world database with over 8,000 transactions, where the \textit{MaxLen} and \textit{AvgLen} are the same, and utility values are synthetic.
	
	\item \textbf{T10I4D100K} is synthetic data generated by the IBM Data Generators, which contains 8,124 transactions.
\end{itemize} 

\begin{table}[h]   
	\begin{center}   
		\caption{The characteristics of datasets}  
		\label{table:data} 
		\begin{tabular}{|m{2.8cm}<{\centering}|m{2.8cm}<{\centering}|m{2.8cm}<{\centering}|m{2.8cm}<{\centering}| m{2.8cm}<{\centering}|}   
			\hline   \textbf{Dataset} & \textbf{Size} & \textbf{Trans} & \textbf{MaxLen} & \textbf{AvgLen}\\   
			\hline  foodmart & 176 & 4141  & 4.4 & 14 \\
			
			\hline  retail & 1845 & 24735 & 10.3 & 74\\ 
			
			\hline  ecommerce & 1968 & 14976 & 11.6 & 29  \\  
			
			\hline  chainstore & 81102 & 1112950 & 7.2 & 170  \\ 
			
			\hline  mushroom & 1309 & 8124 & 23 & 23  \\
			
			\hline  T10I4D100K & 8267 & 100000 & 29 & 10.1  \\  
			\hline   
		\end{tabular}   
	\end{center}   
\end{table}

\subsection{Experiments on itemset}

The output of the TMKU algorithm is the top-$k$ THUIs. To evaluate the accuracy of the results, an experiment was done to compare the output of TMKU with that of TargetUM after post-processing the results. Here, $u_1$ represents the lowest utility in TMKU's result set, and $u_2$ denotes the same for the post-processed results from the TargetUM algorithm. We tested various $k$ values for different datasets due to the different numbers and features of each dataset.

The results mainly demonstrate the effect of changing the $k$-value by comparing the minimum utility in the dataset. Table \ref{table:right} indicates that $u_1$ and $u_2$ have the same value, which becomes smaller and smaller as $k$ is increased. Besides, it is found that the results are the same for both algorithms. For example, we randomly select watermelon as the user-selected target pattern for the retail database, so $T^\prime$ is set as \{976\} which represents the watermelon. Then, the experiment compares the minimum utility value for different $k$ values and $u_1$ and $u_2$.

It is found that when $k$ is increased from 10 to 110, the minimum utility value decreases from 4,325 to 1,389. TMKU described in this paper can successfully discover the top-$k$ THUIs, depending on the aforementioned analysis. Table \ref{table:candidate} displays the number of candidates in the six databases for different $k$ values. For example, we set $T^\prime$ = \{110\} for the mushroom database, which indicates the flavor of a certain type of mushroom. When $k$ is increased from 1,000 to 6,000, the number of candidate itemsets increases from 16,978 to 65,512. As the $k$-value increases, obviously, the number of candidate itemsets increases as well. This is in line with the expected results of the top-$k$ algorithm.

\begin{table}[h]
	\centering
	\caption{The minimum utility of TMKU with different $k$ values}
	\label{table:right}
	\begin{tabular}{c|c|lllllll}
		
		\hline \hline
		\multirow{2}{*}{\textbf{Dataset}} & \multirow{2}{*}{\textbf{u}} &
		\multicolumn{6}{c}{\textbf{\# minimum utility by varying $k$}} \\ \cline{3-8}
		& &$k_1$ & $k_2$ & $k_3$ & $k_4$ & $k_5$ & $k_6$ \\ \hline
		chainstore & $u_1$ & 1643,851 & 697,152 & 488,009 & 407,079 & 348,233 & 310,306\\
		\{16967\} & $u_2$ & 1643,851 & 697,152 & 488,009 & 407,079 & 348,233 & 310,306\\ \hline
		ecommerce & $u_1$ & 976,618 & 954,154 & 940,042 & 929,362 & 920,962 & 913,834 \\
		\{150561222\} & $u_2$ & 976,618 & 954,154 & 940,042 & 929,362 & 920,962 & 913,834 \\ \hline
		retail & $u_1$ & 1,381  & 1,379 & 1,377 & 1,377 & 1,376 & 1,375 \\
		\{976\} & $u_2$ & 1,381  & 1,379 & 1,377 & 1,377 & 1,376 & 1,375 \\ \hline
		foodmart& $u_1$ & 6,266 & 4,319 & 5,541 & 6,530 & 7,420 & 7,978 \\
		\{1340\} & $u_2$ & 6,266 & 4,319 & 5,541 & 6,530 & 7,420 & 7,978 \\\hline
		mushroom & $u_1$ & 449,193 & 358,323 & 256,158 & 125,079 & 93,238 & 73,171 \\
		\{110\} & $u_2$ & 449,193 & 358,323 & 256,158 & 125,079 & 93,238 & 73,171 \\\hline
		T10I4D100K & $u_1$ & 93,238 & 39,273 & 30,843 & 27,984 & 26,228 & 25,716 \\
		\{71\} & $u_2$ & 93,238 & 39,273 & 30,843 & 27,984 & 26,228 & 25,716 \\
		 \hline 
		\hline
	\end{tabular}
\end{table}


\begin{table}[h]
	\centering
	\caption{The number of candidates of TMKU with different $k$ values}
	\label{table:candidate}
	\begin{tabular}{c|c|c|c|c|c|l}
		
		\hline \hline
		\multirow{1}{*}{\textbf{Dataset}}  &
		\multicolumn{6}{c}{\textbf{\# the number of candidates by varying $k$}} \\ \cline{2-7}
		 &$k_1$ & $k_2$ & $k_3$ & $k_4$ & $k_5$ & $k_6$ \\ \hline
		chainstore \{16967\}  & 75 & 193 & 233 & 254 & 261 & 267 \\
		  \hline
		ecommerce \{150561222\}  & 43,509 & 84,230 & 123,914 & 160,464 & 196,604 & 231,791 \\ \hline
		retail \{976\} & 4,430  & 7,771 & 10,557 & 13,064 & 15,193 & 17,242 \\ \hline
		foodmart \{1340\} & 2,653 & 4,319 & 5,541 & 6,530 & 7,420 & 7,978 \\\hline
		mushroom \{110\} & 461 & 676 & 997 & 1248 & 1345 & 1456 \\\hline
		T10I4D100K \{71\} & 7,761 & 13,678 & 18,639 & 23,178 & 27,431 & 31,569 \\\hline 
		\hline
	\end{tabular}
\end{table}

\subsection{Experiments on runtime}

Experiments were also done to compare the running times of several versions of the algorithm as $k$ is changed. Figure \ref{runtime} shows the trend of the execution time of the algorithm for various $k$ values on the six datasets. It is worth noting that the top-$k$ algorithm has only one parameter, which could result in varying performances. In general, for the TMKU task, it is tough to determine an appropriate value of $k$ to find the optimal threshold that provides the best performance. As a result, the $k$-value in the TMKU algorithm is totally determined by the user's needs in most scenarios. This study is of great significance in targeted mining to consider the subjective needs of users and provide them with a positive experience.

The performance of the three algorithms on distinct datasets was recorded in the experiment to have a fair evaluation, which is depicted in Figure \ref{runtime}. The results reveal that when all the strategies are applied, the running time of the TMKU algorithm is shorter than that of other versions. The entire runtime increases as $k$ grows. Due to the limitations of the TP-tree, the runtime of the three versions does not reflect significant differences. However, we can observe that this difference can be expressed in Figure \ref{runtime} (a) and (d). Both the foodmart and chainstore datasets are sparse, with the chainstore dataset being particularly sparse. In different $k$ settings, therefore, the running time difference of three variants can be clearly observed. The distinction between the retail database and the e-commerce database is not immediately obvious.

In summary, the algorithm performs better on sparse datasets with pruning strategies. For example, in the chainstore dataset, when $k$ = 210, the proposed algorithm with all pruning strategies clearly takes less time than TMKU$_{V1}$ and TMKU$_{V2}$. TMKU takes 1,010 seconds to discover all the top-$k$ THUIs, while TMKU$_{V1}$ and TMKU$_{V2}$ need 1,019 seconds and 1,025 seconds to finish this task, respectively. This result demonstrates that all the strategies are effective for mining the top-$k$ THUIs. Furthermore, Strategy \ref{lab:one} and Strategy \ref{lab:two} work on the prefix and suffix of itemset, separately, which are crucial in speeding up the query. Strategy \ref{lab:three} has a pruning effect for the case when the target pattern $|$$T^\prime$$| >$ 1, as mentioned in the TargetUM task.

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{pics/runtimes.pdf} 
	\caption{Runtime under varied $k$. (a) foodmart ($T^\prime$ = \{1340\}). (b) retail ($T^\prime$ = \{1370\}). (c) Ecommerce ($T^\prime$ = \{150561222\}). (d) Chainstore ($T^\prime$ = \{16967\}). (e) Mushroom ($T^\prime$ = \{110\}). (f) T10I4D100K ($T^\prime$ = \{71\})}. 
	\label{runtime} 
\end{figure}


\subsection{Experiments on memory}

Additional tests were done to check how much memory is used by each version of the algorithm when the $k$ parameter is varied, and Figure \ref{memory} shows the detailed results. We can clearly see that the algorithm that uses all pruning strategies consumes less memory than the other variants. This is due to the fact that some memory is consumed during the first phase of the TP-tree construction, but the memory impact of these pruning strategies is not significant. In addition, the overall memory usage of TMKU increases as $k$ increases in all three versions, eventually reaching equilibrium. Since the top-$k$ THUIs are mined by using the Strategy \ref{sur} and Strategy \ref{riu} to save the items and real utility values of items, more storage space is necessary in the second step of the algorithm. However, under certain conditions, the algorithm can fluctuate slightly in the amount of memory consumed while running. For example, for the foodmart dataset, as $k$ is gradually increased from 1,000 to 6,000, the memory usage is also gradually increasing. However, when $k$ is set to 4,000 in the T10I4D100K database, the memory usage is slightly less than before. In addition, the memory usage is more stable for datasets like chainstore where the number of transactions is high, and the utility values are concentrated. In general, the TMKU algorithm has pretty good capability in terms of memory usage.


\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{pics/memories.pdf} 
	\caption{Memory for varied $k$ values. (a) foodmart ($T^\prime$ = \{1340\}). (b) retail ($T^\prime$ = \{1370\}). (c) Ecommerce ($T^\prime$ = \{150561222\}). (d) Chainstore ($T^\prime$ = \{16967\}). (e) Mushroom ($T^\prime$ = \{110\}).  (f) T10I4D100K ($T^\prime$ = \{71\})}.
	\label{memory} 
\end{figure}


\subsection{Experiments on scalability}

Finally, to better assess the performance of the TMKU algorithm, the scalability of TMKU was tested on the chainstore dataset. The size of the chainstore dataset was increased linearly from 100K to 1,100K. The experimental results in terms of execution time and memory for the three variants of the TMKU algorithm are shown in Figure \ref{extend} for the case of $k$ = 50. Overall, the TMKU algorithm performs the best among the three algorithms. It can be clearly seen that as the number of transactions in the database increases, the execution time increases as well. For instance, when the chainstore database size grows from 300K to 900K, the execution time of TMKU increases from 242.86s to 923.79s. When compared to TMKU$_{V1}$ and TMKU$_{V2}$, TMKU takes the least time. As far as memory usage is concerned, we can observe that memory consumption in general also increases as the data set size increases. However, the performance of strategies adopted by TMKU is subject to fluctuations due to the instability of memory consumption. When the dataset size is 500K, for example, TMKU's memory consumption differs very little from that of TMKU$_{V1}$ and TMKU$_{V2}$. Figure \ref{extend} clearly shows that the runtime and memory consumption increase linearly with the size of the dataset. Besides, the TMKU algorithm is less time-consuming and space-consuming than the other two variants, so it has good scalability.

\begin{figure}
	\centering
	\includegraphics[scale=0.3]{pics/extend.pdf} 
	\caption{The runtime and memory scalability of variants on Chainstore ($T^\prime$ = \{16967\}, $k$ = 50)}.
	\label{extend} 
\end{figure}