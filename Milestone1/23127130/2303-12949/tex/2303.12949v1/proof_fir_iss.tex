%
\label{app_a}
%
	\textbf{Proof of Theorem~\ref{prop_fir}}. Consider any maximal solution $\xi$ to \eqref{eq_sys_hyb}. 
%
	Note that $\hat{x}_o(\tvar_j^+) = x_o(\tvar_j^+) = x_o(\tvar_j)$ and thus $e(\tvar_j^+) = e_o(\tvar_j^+) = e_o(\tvar_j)$.
%
	Obviously, $\bar{h} \geq \delta T_{\max}(\gamma_1,L_1+\frac{\epsilon_1}{2}) = t_{\min}$ in Algorithm~\ref{algo_trig_window} and thus $\svar_{j+1}-\svar_j = \Gamma(x_o(\tvar_j),\eta(\tvar_j)) \geq t_{\min}$ holds for all $j\in\dom~\xi$, i.e. the minimum time between two triggering instants is strictly positive. 
%
%
	Because of the update of $\bar{h}$ in Algorithm~\ref{algo_trig_window}, for each $j\in\dom~\xi$, there is  an $\ivar \in\left\lbrace 1,\dots, n_\tpar \right\rbrace$ such that  $\svar_{j+1}-\svar_j \leq T_{\max}\left(\gamma_\ivar,\max\left\lbrace L_\ivar+\frac{\epsilon_\ivar}{2}, 1-\delta \right\rbrace\right)$ and $\svar_{j+1}-\svar_j \leq t_{\max} \coloneqq \underset{i\in\left\lbrace 1,\dots,n_{\tpar}\right\rbrace}{\max} \delta T_{\max}(\gamma_i,\max\left\lbrace L_i+\frac{\epsilon_i}{2}, 1-\delta \right\rbrace)$. 
%
	Proposition~\ref{prop_hybrid} thus implies for $\svar_j\leq t \leq \svar_{j+1}$ with $x_p(\tvar_{j}^+) = x_p(\tvar_{j})$ and $e(\tvar_j^+) = e_o(\tvar_j)$ that 
	\begin{equation}
		\label{eq_V_dec_fir}
		\begin{split}
			&V(x_p(\svar,j)) \leq U_\ivar(\xi(t,j\change{+1}{}))	
			\leq 	e^{ -\epsilon_\ivar (t-\svar_j)}U_\ivar(\xi(\tvar_j^+))\\ %
			=& e^{ -\epsilon_\ivar (t-\svar_j)}\left(V(x_p(\tvar_j)) + \gamma_\ivar \lambda_\ivar^{-1} W^2(e_o(\tvar_j)) \right).	
		\end{split}
	\end{equation}
%
%
	Here $U_\ivar(\xi)$ is the respective function according to \eqref{eq_def_u} from Proposition~\ref{prop_hybrid} for $\gamma = \gamma_\ivar$, $L = L_\ivar, \epsilon = \epsilon_\ivar$ and some sufficiently small $\lambda\in\left(0,1\right)$.
%

	We will now use this to investigate the evolution of $V(x_p)$ depending on the time between sampling instants. We distinguish between two possible outcomes for $\ivar$ in Algorithm~\ref{algo_trig_window}.
%
	Suppose first $\ivar = 1$, i.e., the fallback strategy is used. Then
	\begin{equation*}
		e^{-\epsilon_\ivar(\svar_{j+1}-\svar_{j})} V(x_p(\tvar_j)) \leq e^{-\epsilon_\refer(\svar_{j+1}-\svar_{j})} V(x_p(\tvar_j)) 
	\end{equation*}
	holds since $\epsilon_1 \geq \epsilon_\refer > 0$ and $\svar_{j+1}-\svar_j < T_{\max}(\gamma_1,L_1+\frac{\epsilon_1}{2})$. This implies with \eqref{eq_V_dec_fir} that 
	\begin{equation}
		\label{eq_bound_i1}
		\begin{split}
			V(x_p(\tvar_{j+1})) 
			\leq& e^{-\epsilon_\refer(\svar_{j+1}-\svar_{j})} V(x_p(\tvar_j))  + \alpha_1(\abs{e_o(\tvar_j)})	
%
		\end{split}
	\end{equation}
	for some $\alpha_1\in\mathcal{K}$. Here we used that $\underset{i\in\left\lbrace 1,\dots,n_{\tpar}\right\rbrace}{\max}e^{ -\epsilon_i (\svar_{j+1}-\svar_j)} \in \R_{>0}$ due to the upper bound $t_{\max}$ on $t_{j+1}-t_j$. 
		
	Next, suppose that $\ivar > 1$. In this case, Algorithm~\ref{algo_trig_window} chooses $\svar_{j+1}-\svar_j$ such that $\svar_{j+1}-\svar_j < T_{\max}(\gamma_\ivar,L_\ivar+\frac{\epsilon_\ivar}{2})$ and
	\begin{equation}
		\label{eq_Vo_bound}
		\begin{split}
			e^{-\epsilon_\ivar(\svar_{j+1}-\svar_{j})} V(x_o(\tvar_j)) \leq& e^{-\epsilon_\refer(\svar_{j+1}-\svar_j)} C(x_o(\tvar_j),\eta(\tvar_j))\\
%
		\end{split}		
	\end{equation}
	hold. Further note that $\ivar > 1$ is only possible if $V(x_o(\tvar_j)) \leq C(x_o(\tvar_j),\eta(\tvar_j)) \leq V_{\max}$ due to Line~\ref{line_for_start} of Algorithm~\ref{algo_trig_window} and our choice of $C(x_p,\eta)$ according to \eqref{eq_C_def}.
%
%
%
%
%
%
%
%
Observe that
	\begin{equation*}
		\begin{split}
			V(x_p(\tvar_j)) =& V(x_o(\tvar_j) - e_o(\tvar_j))\\
%
			\leq& V(x_o(\tvar_j)) +\mathfrak{L}(\abs{e_o(\tvar_j)}) \abs{e_o(\tvar_j)}
		\end{split}
	\end{equation*}
	where $\mathfrak{L}(p)$ is a (local) Lipschitz constant of $V$ that satisfies
	\begin{equation}
		\label{eq_def_L}
	\abs{V(x_o(\tvar_j)-e_o(\tvar_j)) - V(x_o(\tvar_j))}\leq \mathfrak{L}(p) \abs{e_o(\tvar_j)}
	\end{equation}
	for all $e_o(\tvar_j)$ with $\abs{e_o(\tvar_j)} \leq p$ and $x_o$ with $V(x_o) \leq V_{\max}$. Note that $\mathfrak{L}(p)$ is non-decreasing and bounded for all $p \geq 0$ since $V$ is locally Lipschitz. We thus obtain for some  $\alpha_{2}\in\mathcal{K}$
	\begin{equation}
		\label{eq_bound_op}
		V(x_p(\tvar_j)) \leq V(x_o(\tvar_j)) + \alpha_{2}(\abs{e_o(\tvar_j)}).
	\end{equation}
	Using \eqref{eq_Vo_bound} and \eqref{eq_bound_op} we obtain from \eqref{eq_V_dec_fir} for $t = t_{j+1}$
	\begin{equation}
		\label{eq_bound_ij}
		\begin{split}
			&V(x_p(\tvar_{j+1}))	\\
			\leq& e ^{-\epsilon_\refer(t_{j+1}-t_j)} C(x_o(\tvar_j),\eta(\tvar_j))\\
			 &+ e^{ -\epsilon_\ivar (\svar_{j+1}-\svar_j)}\left( \alpha_{2}(\abs{e_o(\tvar_{j})}) + \gamma_\ivar \lambda_\ivar^{-1} W^2(e_o(\tvar_j)) \right)	\\
%
			\leq& e ^{-\epsilon_\refer(t_{j+1}-t_j)} C(x_o(\tvar_j),\eta(\tvar_j)) + \alpha_3(\abs{e_o(\tvar_j)})\\
%
		\end{split}
	\end{equation}
for some $\alpha_3\in\mathcal{K}$, where we used again that \linebreak $\underset{i\in\left\lbrace 1,\dots,n_{\tpar}\right\rbrace}{\max}e^{ -\epsilon_i (\svar_{j+1}-\svar_j)} \in \R_{>0}$ due to the upper bound $t_{\max}$ on $t_{j+1}-t_j$. 
%
From \eqref{eq_C_def}, we obtain with the update of $\eta$ according to \eqref{eq_S_window_2} that\footnote{Note that the second sum is only relevant for $j < m-1$ to capture the effect of the initial condition on $\eta$.}
\begin{equation}
	\label{eq_C_decomp}
	\begin{split}
		&C(x_o(\tvar_{{j}}),\eta(\tvar_{{j}})) = \frac{1}{m} V(x_o(\tvar_{{j}})) + \sum_{k=1}^{m-1} \eta_k(\tvar_{{j}}) \\
		\leq & \frac{1}{m}V(x_o(\tvar_{{j}}))\\
		 &+ \frac{1}{m}\sum_{k=1}^{\min\left\lbrace m-1 , j \right\rbrace} e^{-\epsilon_\refer(t_{{j}}-t_{{j}-k})} \min\left\lbrace V(x_o(\tvar_{{{j}}-k})), V_{\max} \right\rbrace\\
		 &+ \frac{1}{m}\sum_{k = \min\left\lbrace j,m-1\right\rbrace+1}^{m-1} e^{-\epsilon_\refer(t_{{j}}-t_{0})}\eta_{m-k}.
	\end{split}
\end{equation}

If $V(x_o(\tvar_{j-k})) \leq V_{\max},$ we obtain similar as in \eqref{eq_bound_op} that
\begin{equation*}
	\begin{split}
			&\min\left\lbrace V(x_o(\tvar_k)), V_{\max} \right\rbrace\\
			 =& V(x_p(\tvar_{j-k})) + V(x_o(\tvar_{j-k})) - V(x_o(\tvar_{j-k}) - e_o(\tvar_{j-k}))\\
		\leq& V(x_p(\tvar_{j-k})) + \alpha_{2}(\abs{e_o(\tvar_{j-k})}).
	\end{split}
\end{equation*} 
If $V(x_o(\tvar_{j-k})) > V_{\max},$ then either $V(x_p(\tvar_{j-k})) > V_{\max}$ and $\min\left\lbrace V(x_o(\tvar_{j-k})), V_{\max} \right\rbrace \leq V(x_p(\tvar_{j-k})) + \alpha_{2}(\abs{e_o(\tvar_{j-k})})$ trivially holds or $V(x_p(\tvar_{j-k})) \leq V_{\max}$. In the latter case, we can again use the same argumentation that precedes \eqref{eq_bound_op} and obtain
\begin{equation}
	\label{eq_bound_op2}
	\min\left\lbrace V(x_o(\tvar_{j-k})), V_{\max} \right\rbrace \leq V(x_p(\tvar_{j-k})) + \alpha_{2}(\abs{e_o(\tvar_{j-k})}).
\end{equation}
Thus \eqref{eq_bound_op2} holds in all cases.
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
Using it in \eqref{eq_C_decomp}, we obtain 
\begin{equation}
	\label{eq_C_bound_pre}
	\begin{split}
		&C(x_o(\tvar_{{j}}),\eta(\tvar_{{j}}))\\
		 \leq& \frac{1}{m}\sum_{k=1}^{\min\left\lbrace m-1 , j \right\rbrace} e^{-\epsilon_\refer(t_{{j}}-t_{{j}-k})} V(x_p(\tvar_{{{j}}-k}))\\
		  &+\frac{1}{m}\sum_{k=1}^{\min\left\lbrace m-1 , j \right\rbrace} e^{-\epsilon_\refer(t_{{j}}-t_{{j}-k})}  \alpha_{2}(\abs{e_o(\tvar_{j-k})})\\
		  &+ \frac{1}{m}\sum_{k = \min\left\lbrace j,m-1\right\rbrace+1}^{m-1} e^{-\epsilon_\refer(t_{{j}}-t_{0})}\eta_{m-k}.
	\end{split}
\end{equation}		  
With \eqref{eq_obs_er} from Assumption~\ref{as_obs_er} in the second sum of \eqref{eq_C_bound_pre}, and $t_{k+1}-t_k \leq t_{\min}~\forall k\in\dom\xi$, we further obtain
\begin{equation}
	\label{eq_C_bound}
	\begin{split}		  
		 &C(x_o(\tvar_{{j}}),\eta(\tvar_{{j}}))\\
		   \leq & \frac{1}{m}\sum_{k=1}^{\min\left\lbrace m-1 , j \right\rbrace} e^{-\epsilon_\refer(t_{{j}}-t_{{j}-k})} V(x_p(\tvar_{{{j}}-k}))\\
		   	   &+ \frac{1}{m}\sum_{k = \min\left\lbrace j,m-1\right\rbrace+1}^{m-1} e^{-\epsilon_\refer(t_{{j}}-t_{0})}\eta_{m-k}\\
		   	   &+    \alpha_{2}\left(\beta_o\left(\abs{e_o(\tnn)},\max\left\lbrace (j-m+1)t_{\min},0\right\rbrace\right)\right).
	\end{split}
\end{equation}

	
	
	Now we show by induction based on \eqref{eq_bound_i1} and \eqref{eq_bound_ij} that
	\begin{equation}
		\label{eq_ind_as}
		\begin{split}
			&V(x_p(\tvar_j)) 
			\\ \leq& e^{-\epsilon_\refer t_j} \max\left\lbrace V(x_p(0,0)),\abs{\eta(0,0)}\right\rbrace\\
%
			&+ \sum_{k=0}^{j-1}\left(e^{-\epsilon_\refer t_{\min}(j- k -1)}\right. \\
			&\cdot \left.\alpha_5\left(\beta_o\left(\abs{e_o(\tnn)},\max\left\lbrace (k-m+1)t_{\min},0\right\rbrace\right)\right) \vphantom{e^{-\epsilon_\refer t_{\min}(j- k)}}\right)
		\end{split}		
	\end{equation}
%
%
%
%
%
%
%
%
%
%
	holds for all $j\in\dom~\xi$ with $\alpha_5(\cdot) \coloneqq \alpha_1(\cdot)+\alpha_{2}(\cdot)+\alpha_3(\cdot) \in\mathcal{K}$. It trivially holds for $j = 0$. Suppose it holds for all $j \leq \tilde{j}$ for some $\tilde{j}\in\dom~\xi$. 
	
	We first consider the case $i_{\tilde{j}} \geq 1$. Note that \eqref{eq_ind_as} for $j\leq \tilde{j}$ implies with \eqref{eq_C_bound} that
	\begin{equation*}
		\begin{split}
			&C(x_o(\tvar_{\tilde{j}}),\eta(\tvar_{\tilde{j}}))\\
			\leq&  e^{-\epsilon_\refer t_{\tilde{j}}} \max\left\lbrace V(x_p(0,0)),\abs{\eta(0,0)}\right\rbrace\\
%
			&+ \sum_{k=0}^{{\tilde{j}-1}}\left(e^{-\epsilon_\refer t_{\min}({\tilde{j}}- k-1)}\right. \\
			&~\cdot \left.\alpha_5\left(\beta_o\left(\abs{e_o(\tnn)},\max\left\lbrace (k-m+1)t_{\min},0\right\rbrace\right)\right) \vphantom{e^{-\epsilon_\refer t_{\min}(j- k)}}\right)\\
			&+ \alpha_{2}\left(\beta_o\left(\abs{e_o(\tnn)},\max\left\lbrace (\tilde{j}-m+1)t_{\min},0\right\rbrace\right)\right).
		\end{split}
	\end{equation*}
	Plugging this in \eqref{eq_bound_ij}, we obtain
	\begin{equation}
		\label{eq_ind_ii}
		\begin{split}
			&V(x_p(\tvar_{\tilde{j}+1})) \\
			\leq& e^{-\epsilon_\refer (t_{\tilde{j}+1}-t_{\tilde{j}})} e^{-\epsilon_\refer t_{\tilde{j}}} \max\left\lbrace V(x_p(0,0)),\abs{\eta(0,0)}\right\rbrace\\
%
			& + \alpha_3\left(\abs{e_o(\tvar_{\tilde{j}})}\right)
			+ e^{-\epsilon_\refer (t_{\tilde{j}+1}-t_{\tilde{j}})} \sum_{k=0}^{{\tilde{j}-1}}\left(e^{-\epsilon_\refer t_{\min}({\tilde{j}}- k-1)}\right. \\
			&~\cdot \left.\alpha_5\left(\beta_o\left(\abs{e_o(\tnn)},\max\left\lbrace (k-m+1)t_{\min},0\right\rbrace\right)\right) \vphantom{e^{-\epsilon_\refer t_{\min}(j- k)}}\right)\\
			&+  e^{-\epsilon_\refer (t_{\tilde{j}+1}-t_{\tilde{j}})}\alpha_{2}\left(\beta_o\left(\abs{e_o(\tnn)},\max\left\lbrace (\tilde{j}-m+1)t_{\min},0\right\rbrace\right)\right).
		\end{split}
	\end{equation}
%
	Note that
	\begin{equation*}
%
		\begin{split}
			& \alpha_3\left(\abs{e_o(\tvar_{\tilde{j}})}\right)\\
			 &+ e^{-\epsilon_\refer (t_{\tilde{j}+1}-t_{\tilde{j}})}\alpha_{2}\left(\beta_o\left(\abs{e_o(\tnn)},\max\left\lbrace (\tilde{j}-m+1)t_{\min},0\right\rbrace\right)\right)\\
			\leq & \alpha_5(\beta_o\left(\abs{e_o(\tnn)},\max\left\lbrace (\tilde{j}-m+1)t_{\min},0\right\rbrace\right))
		\end{split}
	\end{equation*}
holds since 
\begin{equation*}
	\begin{split}
		\abs{e_o(\tvar_{\tilde{j}})} &\leq \beta_o\left(\abs{e_o(\tnn)},\svar_{\tilde{j}}\right)\\
		 &\leq \beta_o\left(\abs{e_o(\tnn)},\max\left\lbrace (\tilde{j}-m+1)t_{\min},0\right\rbrace\right),
	\end{split}
\end{equation*} since $e^{-\epsilon_\refer (t_{\tilde{j}+1}-t_{\tilde{j}})} < 1$ and due to the definition of $\alpha_5$. 
	
	Using this and  $e^{-\epsilon_\refer(\svar_{\tilde{j}+1}-\svar_{\tilde{j}})} \leq e^{-\epsilon_\refer t_{\min}} $ in \eqref{eq_ind_ii}, we obtain 
	\begin{equation*}
		\begin{split}
			&V(x_p(\tvar_{\tilde{j}+1})) \\
			\leq & e^{-\epsilon_\refer t_{\tilde{j}+1}} \max\left\lbrace V(x_p(0,0)),\abs{\eta(0,0)}\right\rbrace\\
			%
			&+ \sum_{k=0}^{{\tilde{j}}}\left(e^{-\epsilon_\refer t_{\min}({\tilde{j}}- k)}\right. \\
			&~\cdot \left.\alpha_5\left(\beta_o\left(\abs{e_o(\tnn)},\max\left\lbrace (k-m+1)t_{\min},0\right\rbrace\right)\right) \vphantom{e^{-\epsilon_\refer t_{\min}(j- k)}}\right),
		\end{split}
	\end{equation*}
	i.e., \eqref{eq_ind_as} also holds for $j=\tilde{j}+1$ in this case.
	
	
%
%
	
%
%
%
%
%
%
%
%
%
	
	
	
	Now we consider the remaining case $i_{\tilde{j}} = 1$. In this case, \eqref{eq_bound_i1} holds and hence with \eqref{eq_ind_as} for $j=\tilde{j}$, we obtain
	\begin{equation*}
		\begin{split}
			&V(x(\tvar_{\tilde{j}+1}))\\ \leq& e^{-\epsilon_\refer(\svar_{\tilde{j}+1}-\svar_{\tilde{j}})} V(x_p(\tvar_{\tilde{j}}))  + \alpha_1\left(\abs{e_o(\tvar_{\tilde{j}})}\right)	\\
%
%
%
%
%
%
%
			\leq& e^{-\epsilon_\refer t_{\tilde{j}+1}} \max\left\lbrace V(x_p(0,0)),\abs{\eta(0,0)}\right\rbrace\\
%
			&+ \sum_{k=0}^{\tilde{j}}\left(e^{-\epsilon_\refer t_{\min}(\tilde{j}- k)}\right. \\
			&\cdot \left.\alpha_5\left(\beta_o\left(\abs{e_o(\tnn)},\max\left\lbrace (k-m+1)t_{\min},0\right\rbrace\right)\right) \vphantom{e^{-\epsilon_\refer t_{\min}(j- k)}}\right)
		\end{split}
	\end{equation*}
	where we used that $ e^{-\epsilon_\refer t_{\tilde{j}+1}} \leq e^{-\epsilon_\refer t_{\min}}$ and that
	\begin{equation*}
		\begin{split}
			&\alpha_1\left(\abs{e(\tvar_{\tilde{j}})}\right) \leq \alpha_1\left(\beta_o\left(\abs{e_o(\tnn)},\svar_{\tilde{j}}\right)\right)  \\
			 \leq& \alpha_1\left(\beta_o\left(\abs{e_o(\tnn)},\max\left\lbrace (\tilde{j}-m+1)t_{\min},0\right\rbrace\right)\right)\\
			 \leq&  \alpha_5\left(\beta_o\left(\abs{e_o(\tnn)},\max\left\lbrace (\tilde{j}-m+1)t_{\min},0\right\rbrace\right)\right).
		\end{split}
	\end{equation*}
%
%
%
	 As a result, we can conclude that $\eqref{eq_ind_as}$ holds also for $j = \tilde{j}+1$ if $i_{\tilde{j}} = 1$.
	
	It thus follows by induction that \eqref{eq_ind_as} holds for all $j\in\dom~\xi$. Together with the fact that $t_{\min}\leq t_{j+1}-t_j\leq t_{\max}$ this further implies that $\xi$ is $t$-complete.  
	
	Next, we discuss that \eqref{eq_ind_as} implies that $U_{\ivar}$ is bounded by a $\mathcal{K}\mathcal{L}\mathcal{L}$ function. 
%
%
	Observe 
	\newlength\mylen
	\settoheight\mylen{$+ \frac{1}{1-e^{-\epsilon_\refer t_{\min}}} \beta_o\left(\abs{e_o(\tnn)},\max\left\lbrace \left(\frac{t}{2t_{\max}}-m+1\right)t_{\min},0\right\rbrace\right)$}
	\begin{equation}
		\label{eq_sum_bound_1}
		\begin{split}
			&\sum_{k=0}^{j-1}e^{-\epsilon_\refer t_{\min}(j-k-1)}\\
			&\cdot \alpha_5\left(\beta_o\left(\abs{e_o(\tnn)},\max\left\lbrace (k-m+1)t_{\min},0\right\rbrace\right)\right) \\			
%
%
%
%
%
%
%
%
%
%
		\leq&  e^{-\epsilon_\refer t_{\min} \frac{j}{2}} \alpha_5({\beta_o(\abs{e(\tnn)},0)}) \sum_{k=0}^{\frac{j}{2}}e^{-\epsilon_\refer t_{\min}({\frac{j}{2}}- k-1)}\\
		&+ \alpha_5\left(\beta_o\left(\abs{e(\tnn)},\max\left\lbrace \left(\frac{j}{2}-m+1\right)t_{\min},0\right\rbrace\right)\right)\\
		&\cdot \sum_{k=\frac{j}{2}}^{j-1}e^{-\epsilon_\refer t_{\min}({j}- k-1)}\\
		\leq& e^{-\epsilon_\refer \frac{t_{\min}}{t_{\max}} \frac{t}{2}} \frac{1}{1-\epsilon_\refer t_{\min}}\beta_o(\abs{e_o(\tnn)},0)\\
		&\resizebox{\linewidth}{.95\mylen}{$+ \frac{1}{1-e^{-\epsilon_\refer t_{\min}}} \beta_o\left(\abs{e_o(\tnn)},\max\left\lbrace \left(\frac{t}{2t_{\max}}-m+1\right)t_{\min},0\right\rbrace\right)$}\\
		\eqqcolon& \beta_2(\abs{e_o(\tnn)},t) \in \mathcal{K}\mathcal{L},
		\end{split}
	\end{equation} 
	where we used the geometric series and the fact that $j \geq \frac{t}{t_{\max}}$ since $t_{j+1}-t_j \leq t_{\max}$. 
	
	Plugging this into \eqref{eq_ind_as}, we can conclude that for some $\beta_3\in\mathcal{K}\mathcal{L}$,
%
	$	V(x(\tvar_j)) \leq \beta_3\left(\abs{
			\begin{bmatrix} 				
				x_p(0,0)\\ 
				e(0,0)\\ 				
				\eta(0,0) 		\end{bmatrix}},\svar_j\right)$
%
	holds for all $j\in\R_{>0}$. Using again \eqref{eq_V_dec_fir}, this implies together with Assumption~\ref{as_obs_er} for $k_1 = \underset{i\in\left\lbrace 1,\dots,n_{\tpar}\right\rbrace}{\max}e^{ -\epsilon_i (\svar_{j+1}-\svar_j)} \in \R_{>0}$ for some $\beta_4 \in\mathcal{K}\mathcal{L}\mathcal{L}$ that
	\begin{equation*}
		\begin{split}
			U_\ivar(t,j) \leq& k_1 \left(\beta_3\left(\abs{
				\begin{bmatrix} 				
					x_p(0,0)\\ 
					e(0,0)\\ 				
					\eta(0,0) 		\end{bmatrix}},\max\left\lbrace t - t_{\max}, 0 \right\rbrace\right)\right.\\
				&\left.+ \gamma_\ivar\lambda_\ivar^{-1} W^2(\beta_0(\abs{e_0(0,0)}, \max\left\lbrace t - t_{\max}, 0 \right\rbrace)  \vphantom{\begin{bmatrix} 				
						x_p(0,0)\\ 
						e(0,0)\\ 				
						\eta(0,0) 		\end{bmatrix}}\right)\\
					&\leq \beta_4\left(\begin{bmatrix} 				
						x_p(0,0)\\ 
						e(0,0)\\ 				
						\eta(0,0) 		\end{bmatrix},t,j\right),
		\end{split}		
	\end{equation*}
	where we used that $t \geq \frac{t}{2} + jt_{\min}$ holds for all $(t,j)\in\dom~\xi$. 
	
	Finally, with the bounds on $V$ and $W$ from Assumption~\ref{asum_hybrid_lyap}, the fact that $\phi_\ivar \in \left[\lambda,\lambda^{-1}\right]$ for sufficient small $\lambda\in\left(0,1\right)$, the definition of $U_\ivar$ according to \eqref{eq_def_u} for the respective $\gamma_\ivar$, $L_\ivar$ and $\epsilon_\ivar$ and since the observer state converges to the plant state according to Assumption~\ref{as_obs_er}, UGAS of the set $\left\lbrace \left(x_p,x_c,e,\eta,\tau,\auxvar\right): x_p = 0, x_c = 0, e= 0, \eta = 0 \right\rbrace$ follows similar as in \cite{hertneck21robust_arxiv}. \hfill\hfill\qed
	


%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%



%
%
%
%
%
%
%

	
	
	
	
	
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
	
%