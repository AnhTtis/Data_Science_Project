@article{num1vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{aed,
  title={End-to-end continuous speech recognition using attention-based recurrent NN: First results},
  author={Chorowski, Jan and Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.1602},
  year={2014}
}

@inproceedings{num3zhang2020transformer,
  title={Transformer transducer: A streamable speech recognition model with transformer encoders and rnn-t loss},
  author={Zhang, Qian and Lu, Han and Sak, Hasim and Tripathi, Anshuman and McDermott, Erik and Koo, Stephen and Kumar, Shankar},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7829--7833},
  year={2020},
  organization={IEEE}
}

@inproceedings{num4miao2020transformer,
  title={Transformer-based online CTC/attention end-to-end speech recognition architecture},
  author={Miao, Haoran and Cheng, Gaofeng and Gao, Changfeng and Zhang, Pengyuan and Yan, Yonghong},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6084--6088},
  year={2020},
  organization={IEEE}
}

@article{num6gao2022paraformer,
  title={Paraformer: Fast and Accurate Parallel Transformer for Non-autoregressive End-to-End Speech Recognition},
  author={Gao, Zhifu and Zhang, Shiliang and McLoughlin, Ian and Yan, Zhijie},
  journal={arXiv preprint arXiv:2206.08317},
  year={2022}
}

@article{num7li2019jasper,
  title={Jasper: An end-to-end convolutional neural acoustic model},
  author={Li, Jason and Lavrukhin, Vitaly and Ginsburg, Boris and Leary, Ryan and Kuchaiev, Oleksii and Cohen, Jonathan M and Nguyen, Huyen and Gadde, Ravi Teja},
  journal={arXiv preprint arXiv:1904.03288},
  year={2019}
}

@inproceedings{num8kriman2020quartznet,
  title={Quartznet: Deep automatic speech recognition with 1d time-channel separable convolutions},
  author={Kriman, Samuel and Beliaev, Stanislav and Ginsburg, Boris and Huang, Jocelyn and Kuchaiev, Oleksii and Lavrukhin, Vitaly and Leary, Ryan and Li, Jason and Zhang, Yang},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6124--6128},
  year={2020},
  organization={IEEE}
}


@article{num10majumdar2021citrinet,
  title={Citrinet: Closing the gap between non-autoregressive and autoregressive end-to-end models for automatic speech recognition},
  author={Majumdar, Somshubra and Balam, Jagadeesh and Hrinchuk, Oleksii and Lavrukhin, Vitaly and Noroozi, Vahid and Ginsburg, Boris},
  journal={arXiv preprint arXiv:2104.01721},
  year={2021}
}

@article{num11gulati2020conformer,
  title={Conformer: Convolution-augmented transformer for speech recognition},
  author={Gulati, Anmol and Qin, James and Chiu, Chung-Cheng and Parmar, Niki and Zhang, Yu and Yu, Jiahui and Han, Wei and Wang, Shibo and Zhang, Zhengdong and Wu, Yonghui and others},
  journal={arXiv preprint arXiv:2005.08100},
  year={2020}
}

@inproceedings{num12li2022ead,
  title={EAD-Conformer: a Conformer-Based Encoder-Attention-Decoder-Network for Multi-Task Audio Source Separation},
  author={Li, Chenxing and Wang, Yang and Deng, Feng and Zhang, Zhuo and Wang, Xiaorui and Wang, Zhongyuan},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={521--525},
  year={2022},
  organization={IEEE}
}

@inproceedings{num13narayanan2021cross,
  title={Cross-attention conformer for context modeling in speech enhancement for ASR},
  author={Narayanan, Arun and Chiu, Chung-Cheng and O'Malley, Tom and Wang, Quan and He, Yanzhang},
  booktitle={2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={312--319},
  year={2021},
  organization={IEEE}
}

@inproceedings{num14chen2021continuous,
  title={Continuous speech separation with conformer},
  author={Chen, Sanyuan and Wu, Yu and Chen, Zhuo and Wu, Jian and Li, Jinyu and Yoshioka, Takuya and Wang, Chengyi and Liu, Shujie and Zhou, Ming},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5749--5753},
  year={2021},
  organization={IEEE}
}

@article{num21kim2022squeezeformer,
  title={Squeezeformer: An Efficient Transformer for Automatic Speech Recognition},
  author={Kim, Sehoon and Gholami, Amir and Shaw, Albert and Lee, Nicholas and Mangalam, Karttikeya and Malik, Jitendra and Mahoney, Michael W and Keutzer, Kurt},
  journal={arXiv preprint arXiv:2206.00888},
  year={2022}
}

@article{num15tay2020efficient,
  title={Efficient transformers: A survey},
  author={Tay, Yi and Dehghani, Mostafa and Bahri, Dara and Metzler, Donald},
  journal={ACM Computing Surveys (CSUR)},
  year={2020},
  publisher={ACM New York, NY}
}

@article{num16su2021roformer,
  title={Roformer: Enhanced transformer with rotary position embedding},
  author={Su, Jianlin and Lu, Yu and Pan, Shengfeng and Wen, Bo and Liu, Yunfeng},
  journal={arXiv preprint arXiv:2104.09864},
  year={2021}
}

@article{num17wang2020linformer,
  title={Linformer: Self-attention with linear complexity},
  author={Wang, Sinong and Li, Belinda Z and Khabsa, Madian and Fang, Han and Ma, Hao},
  journal={arXiv preprint arXiv:2006.04768},
  year={2020}
}

@article{num18huang2019interlaced,
  title={Interlaced sparse self-attention for semantic segmentation},
  author={Huang, Lang and Yuan, Yuhui and Guo, Jianyuan and Zhang, Chao and Chen, Xilin and Wang, Jingdong},
  journal={arXiv preprint arXiv:1907.12273},
  year={2019}
}

@article{num19qin2022cosformer,
  title={cosFormer: Rethinking Softmax in Attention},
  author={Qin, Zhen and Sun, Weixuan and Deng, Hui and Li, Dongxu and Wei, Yunshen and Lv, Baohong and Yan, Junjie and Kong, Lingpeng and Zhong, Yiran},
  journal={arXiv preprint arXiv:2202.08791},
  year={2022}
}

@article{num20choromanski2020rethinking,
  title={Rethinking attention with performers},
  author={Choromanski, Krzysztof and Likhosherstov, Valerii and Dohan, David and Song, Xingyou and Gane, Andreea and Sarlos, Tamas and Hawkins, Peter and Davis, Jared and Mohiuddin, Afroz and Kaiser, Lukasz and others},
  journal={arXiv preprint arXiv:2009.14794},
  year={2020}
}


@article{num22wu2021u2++,
  title={U2++: Unified two-pass bidirectional end-to-end model for speech recognition},
  author={Wu, Di and Zhang, Binbin and Yang, Chao and Peng, Zhendong and Xia, Wenjing and Chen, Xiaoyu and Lei, Xin},
  journal={arXiv preprint arXiv:2106.05642},
  year={2021}
}

@inproceedings{num23graves2006connectionist,
  title={Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks},
  author={Graves, Alex and Fern{\'a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={369--376},
  year={2006}
}

@inproceedings{num25dauphin2017language,
  title={Language modeling with gated convolutional networks},
  author={Dauphin, Yann N and Fan, Angela and Auli, Michael and Grangier, David},
  booktitle={International conference on machine learning},
  pages={933--941},
  year={2017},
  organization={PMLR}
}

@article{num26shi2021darts,
  title={Darts-conformer: Towards efficient gradient-based neural architecture search for end-to-end asr},
  author={Shi, Xian and Zhou, Pan and Chen, Wei and Xie, Lei},
  journal={arXiv preprint arXiv:2104.02868},
  year={2021}
}

@article{num27liu2018darts,
  title={Darts: Differentiable architecture search},
  author={Liu, Hanxiao and Simonyan, Karen and Yang, Yiming},
  journal={arXiv preprint arXiv:1806.09055},
  year={2018}
}

@inproceedings{num28ding2021repvgg,
  title={Repvgg: Making vgg-style convnets great again},
  author={Ding, Xiaohan and Zhang, Xiangyu and Ma, Ningning and Han, Jungong and Ding, Guiguang and Sun, Jian},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13733--13742},
  year={2021}
}

@inproceedings{num29panayotov2015librispeech,
  title={Librispeech: an asr corpus based on public domain audio books},
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5206--5210},
  year={2015},
  organization={IEEE}
}

@article{num30kudo2018sentencepiece,
  title={Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing},
  author={Kudo, Taku and Richardson, John},
  journal={arXiv preprint arXiv:1808.06226},
  year={2018}
}

@article{num31park2019specaugment,
  title={Specaugment: A simple data augmentation method for automatic speech recognition},
  author={Park, Daniel S and Chan, William and Zhang, Yu and Chiu, Chung-Cheng and Zoph, Barret and Cubuk, Ekin D and Le, Quoc V},
  journal={arXiv preprint arXiv:1904.08779},
  year={2019}
}

@article{num32loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}