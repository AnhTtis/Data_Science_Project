\section{\sys Architecture and API}
\label{engineering}
\sys is a system that facilitates prediction applications on streaming data.

\subsection{\sys Overall Workflow}
The key difference between \sys and model serving systems is that \sys takes streams as the unit of operations.
Existing model serving services all follow the request-response API design, which requires that the prediction results be sent back to the caller.
This might not be suitable for streaming use cases, as users likely prefer results elsewhere for decision-making purposes.
\sys simply routes results to another message topic that could be consumed by any node.
% Each prediction task in \sys has \emph{locality constraints}, which describe where data are created and where the final predictions must be delivered. 
% Within these constraints, the system has a significant amount of flexibility to optimize for different objectives.
% For example, model inference need not be placed on the delivery node, and might be better suited for another node on the network that supports hardware acceleration.
% While data routing for stream processing is well-studied, there are key nuances that arise in the machine learning context (explained in the next section).

% While there are many interesting aspects to this architecture, we focus this paper on the ``execution layer'', the technical issues such a system faces.
Existing model serving systems use RESTful APIs to handle inputs and outputs: they take each input data item as an HTTP request and issue a prediction as the HTTP response back to the caller.
Requests and responses always appear in pairs. This 1:1 relationship makes it impossible to issue one multi-modal prediction based on multiple data inputs.
The only workaround would be to join those data manually and send the joined result as the HTTP request.
\sys, on the other hand, uses message queues to route data around. Each data modality forms its own message queue and they can be joined in real time as tuples before passing to the model. The prediction result, depending on how many outputs it consists of, is routed to one or more message queues for downstream operators to consume.

\subsection{Execution Layer API}
\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\columnwidth]{figures/streamserve-execution-small.pdf}
    \caption{\sys's execution layer. Data from data streams 1 and 2 (D1, D2) are paired together since both streams are grouped into topic A.}
    \label{fig:data-stream-model}
\end{figure}
% \sys uses the high-level network specification described above to generate low-level code that can stream data and predictions.
\sys runs as a process on every node in the network. 
Every node running \sys can potentially create and consume data streams, and run model inference.
One of the nodes is designated as the \emph{leader node} running our message broker backend.
\sys extends Apache Pulsar~\cite{apachepulsar} to build a low-latency message broker backend to transfer messages between nodes.
This is the node that coordinates message routing and maintains a canonical clock for the network.
This leader can be selected through a leader election algorithm (e.g., ~\cite{malpani2000leader}), or can simply be selected by the user.
The leader is also responsible for dispatching user-written code to the other nodes on the network.
\sys assumes that these nodes are connected via a standard TCP/IP network and every node can directly communicate with the leader.
While \sys does not require all-to-all communication, having this capability can be advantageous, especially with large payloads.
This is because an optimization technique known as \textit{lazy data routing} (\S\ref{sec:lazy}) utilizes all-to-all communication.

\vspace{0.5em} \noindent \textbf{Data Streams API: }
Any node on the network, including the leader, can register globally-visible data streams to the network.
All data in \sys are represented as infinite streams of data. 
These streams can be of any serializable data type and leverage Python iterator syntax.
To invoke \sys, the user simply needs to wrap each data stream as a Python generator and register the stream with the leader.
Other nodes on the network can read from this stream of data by accessing an iterator-like interface.

Streams are further grouped into ``topics'' representing joint predictive tasks, as illustrated in Figure~\ref{fig:data-stream-model}.
For example, the streams from ``packet capture 1'' and ``packet capture 2'' could be combined for a particular model.
Grouping streams into topics gives the system information on which streams have to be synchronized and joined together.
Each message contains details about its originating data stream and associated topic.
% Data Streams are node-specific since they connect to particular hardware and software resources. 

\vspace{0.5em} \noindent \textbf{Models API: }
Over these streams of data, we would like to compute different machine learning inferences. A ``model'' object encapsulates such computation. A model consumes one or more input data streams from the same topic, and outputs one or more data streams.
We take a general view of what a model is: a model is simply a unit of computation that is performed synchronously over a stream of data.
In \sys, a ``model'' is just an operator that produces predictions triggered by the input streams. 
This stream of predictions can be further combined into topics that other models consume. 
The same model object can represent a sub-model (e.g., one member of an ensemble), or a featurizer (e.g., a function that computes a set of features).
% Models define our main unit of computation (unlike general data streams).

Models that process these streams take multiple data streams as input, e.g., a multi-modal model. These data streams need to be temporally synchronized before going to the model.
This logic is encapsulated in a component called a ``joiner''.
A joiner fills the gap between data streams and the multimodal model.
It consumes data from multiple streams and produces a single iterator interface for models.
We discuss more details on the joiner in \S\ref{sec:join}.

Our model API is specifically designed to simplify decentralized deployments where the output of one set of models is consumed by others (e.g., an ensemble). 
We treat ensembling just like another model, which takes other models' predictions as inputs, and our system is able to combine them together in a time-synchronized way. 
Users only need to focus on the actual ensembling algorithm and leave communication and placement details to our system.
