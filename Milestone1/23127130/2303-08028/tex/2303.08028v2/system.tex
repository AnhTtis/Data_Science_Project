\section{\sys Architecture and API}
\label{engineering}
\sys is a system that facilitates decentralized prediction applications.

\subsection{\sys Overall Workflow}
In \sys, models are functions that are repeatedly applied to streams of data.
Models can consume multiple streams of data, whereas data streams from multiple nodes may have to be aggregated in a central place.
A prediction task consists of utilizing the results of one or more models.
Each prediction task in \sys has \emph{locality constraints}, which describe where data are created and where the final predictions must be delivered. 
Within these constraints, the system has a significant amount of flexibility to optimize for different objectives.
For example, model inference need not be placed on the delivery node, and might be better suited for another node on the network that supports hardware acceleration.
While data routing for stream processing is well-studied, there are key nuances that arise in the machine learning context (explained in the next section).

\iffalse
While there are many interesting aspects to this architecture, we focus this paper on the data routing challenges such a system faces. They are a small part of a bigger workflow:
\begin{enumerate}
    \item (Specification) The user specifies the location of data sources (streams) on the network, the models that use these streams, and the location where results should be delivered.
    % \textbf{Addressed in prior work~\cite{shaowang2021declarative}}.
    \item (Optimization) The system turns this high-level specification into a placement plan where models are assigned to nodes in the network.
    % \textbf{Addressed in prior work~\cite{shaowang2021declarative}}.
    \item \textbf{(Execution, Focus of This Paper) The data streams are efficiently routed from sources to models to prediction destinations}.
\end{enumerate}
\fi


\subsection{Execution Layer API}
\sys uses the high-level network specification described above to generate low-level code that can stream data and predictions.
\sys runs as a process on every node in the network. 
Every node running \sys can potentially create and consume data streams, and run model inference.
One of the nodes is designated as the \emph{leader node} running our message broker backend.
\sys extends Apache Pulsar~\cite{apachepulsar} to build a low-latency message broker backend to transfer messages between nodes.
This is the node that coordinates message routing and maintains a canonical clock for the network.
This leader can be selected through a leader election algorithm (e.g., ~\cite{malpani2000leader}), or can simply be selected by the user.
The leader is also responsible for dispatching user-written code to the other nodes on the network.
\sys assumes that these nodes are connected via a standard TCP/IP network. It does not assume all-to-all communication, but simply that every node can directly communicate with the leader.

\subsubsection{Data Streams API}
Any node on the network, including the leader, can register globally-visible data streams to the network.
All data in \sys are represented as infinite streams of data. 
These streams can be of any serializable data type and leverage Python iterator syntax.
To invoke \sys, the user simply needs to wrap each data stream as a Python generator and register the stream with the leader.
Other nodes on the network can read from this stream of data by accessing an iterator-like interface.

Streams are further grouped into ``topics'', which describe joint predictive tasks.
For example, the streams from ``packet capture 1'' and ``packet capture 2'' might be used for a particular model.
Grouping streams into a list of topics gives the system information on which streams have to be synchronized.
Data Streams are node-specific since they connect to particular hardware and/or software resources. 

\subsubsection{Models}
Over these streams of data, we would like to compute different machine learning inferences. A ``model'' object encapsulates such computation. A model consumes one or more input data streams, and outputs another data stream.
We take a general view on what a model is: a model is simply a unit of computation that is performed synchronously over a stream of data.
In \sys, a ``model'' is just a type of data stream that produces predictions triggered by the input streams. 
This stream of predictions can be further combined into topics that other models consume. 
The same model object can represent a sub-model (e.g., one member of an ensemble), or a featurizer (e.g., a function that computes a set of features).
Models define our main moveable unit of computation (unlike general data streams).

Our model API is specifically designed to simplify decentralized deployments where the output of one set of models is consumed by others (e.g., an ensemble). 
We treat ensembling just like another model, which takes other models' predictions as inputs, and our system is able to combine them together in a time-synchronized way. Users only need to focus on the actual ensembling algorithm and leave the communication/placement details to our system.


