\section{Adaptive Rate Control}\label{sec:rate-control}
The previous section described how to design the execution layer for \sys through lazy data routing and stream alignment. Next, we show how to ensure this execution layer can meet particular model-serving SLOs. We leverage statistical approximations that exploit temporal similarity in typical data streams.

% Our algorithm is like this:
% For each new data item d_i arriving at the prediction node (from whatever data source node):
%     If a minimal interval has passed from the last prediction:
%         Combine d_i with last known data item of all other data sources
%         Run prediction task for this combination
%     Else:
%         Log d_i locally as the last known data item for that specific data source


\subsection{Automatic Data Skipping}
In classical data streaming systems, ``back pressure'' is a mechanism used to control the rate at which data is processed by the system in order to prevent overload and ensure stability (e.g., as in Apache Flink~\cite{carbone2015apache}). Back pressure is usually applied when there is a mismatch between the rate at which data is being produced by the data source and the rate at which it can be processed by the downstream components of the system. In such cases, the system may experience a backlog of data that has yet to be processed, leading to increased latency and decreased throughput.

Similarly, model-serving systems are rate-limited by the decision processes that consume their predictions. This might be a monitoring dashboard subject to visualization refresh rates, or an SLO describing a desired reaction time. In \sys, users can annotate models with a \emph{target prediction frequency}. This prediction frequency downsamples data if the data arrival rate exceeds what is attainable (i.e., like back-pressure). 
Conversely, if some data arrive slower than this target frequency, it provides a timeout for how long we have to wait for asynchronous messages.

To see how this works, let's work with a simple single-model example. Assume the following data stream arrives in the system:
\[
(\textsf{time}, \text{data}) = (1,x_1),(3,x_3),(4,x_4),(6,x_6)
\]
Without a target frequency, the system would yield the following predictions for each arriving example at the corresponding times:
\[
(\textsf{time}, \text{res}) = (1,f(x_1)),(3,f(x_3)),(4,f(x_4)),(6,f(x_6))
\]

Instead of synchronizing predictions on data arrival, a prediction frequency target synchronizes predictions based on a timer. It yields a prediction from the last known observation at that timer.
Let us consider the case where a user wants to rate-limit the system. For example, a frequency of $2$ in the example above would yield predictions at (2,4,6).
The latest data is always used to produce this prediction.
\[
(\textsf{time}, \text{res}) = (2, f(x_1)),(4,f(x_4)),(6,f(x_6)))
\]

As we can see in this example, if the prediction frequency is slower than the data arrival rate, substantial data skipping is possible.
It gives us an additional knob to optimize data transfer, where the system need not yield predictions faster than the desired target.
For the example above, time-step $3$ is never consumed by the inference node.
This means that certain header messages are ignored, and thus lazy data routing saves us from transferring those data payloads.
A significant amount of communication can be saved if some data streams arrive faster than the desired prediction frequency.
However, there is a natural trade-off of staleness that arises with this approach. 

\subsection{Tolerating Incomplete Messages}
Target frequencies can also be used to tolerate variable or fault-prone data streams.
Suppose one sets the target frequency to be at the P95 data arrival rate; it can be used to generate a timeout on the message broker.
If new data from one source has not arrived before the timeout, the timer will have to short-circuit with a partial message only containing data from a subset of the sources.
Such anomalies can happen if there is a temporary failure on one of the data source nodes, or a large network delay.

In these cases, we do not want the system to fail.
\sys provides a number of fail-soft mechanisms to rectify the issue, such as dropping the tuple and imputing the missing values with a last known good observation.
In our experiments, we use last-known-good-data as our primary fail-soft strategy.
In the example above with a target of $2$, suppose the following stream of data had a failure at example $t=3$:
\[
(\textsf{time}, \text{data}) = (1,f(x_1)),(3,\blacksquare),(4,f(x_4)),(6,f(x_6))
\]
The system would yield the following predictions:
\[
(\textsf{time}, \text{result}) = (2, f(x_1)),(4,f(x_4)),(6,f(x_6))
\]
Now, suppose the target was $1$, the result would be:
\[
(\textsf{time}, \text{result}) = (1,f(x_1)),(2,f(x_1)),(3,f(x_1)),...,(6,f(x_6))
\]
In dense streams of data, such a strategy leverages temporal correlations where the last known observation is likely similar to the missing data.
This allows the prediction stream to fail-soft in the presence of jitter and temporary failures.
