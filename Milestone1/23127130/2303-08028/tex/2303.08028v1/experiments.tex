\section{Experiments}\label{sec:exp}
We evaluate \sys in both end-to-end experiments and micro-benchmarks.
% In short, we find that current distributed machine learning frameworks do not have the right communication primitives for distributed inference tasks.
% \sys outperforms PyTorch distributed in the decentralized prediction setting.
To summarize our experiments:

\begin{itemize}
    \item In real-world settings, decentralized model placement gives us higher real-time accuracy, lower backlog latency across all prediction frequencies. (Section~\ref{sec:exp-opportunity})
    \item Effective downsampling ensures the timeliness of incoming data, and thus significantly improves real-time accuracy while preserving near-zero backlog. (Section~\ref{sec:exp-opportunity})
    \item Lazy data routing significantly reduces communication time when data payloads are large and data skipping is applied. It also reduces contention when there is congestion at the leader node. (Section~\ref{sec:exp-lazy})
    \item \sys's queuing system offers more flexible data routing, supports more network topologies, and has comparable system overhead as PyTorch distributed. (Section~\ref{sec:exp-network})
\end{itemize}

\subsection{Experimental Setup}\label{sec:exp-setup}
All of our experiments are on a private ``edge cluster''.
Our hardware setup consists of 5 NVIDIA Jetson Nano Developer Kits and 4 Intel Skylake NUC computers. Each NUC is equipped with an Intel Core i3-6100U CPU, 16 GB memory and M.2 SSD.
Figure~\ref{fig:network-topology} shows the network topologies of our experiment setup.
Network topology 1 in Figure~\ref{fig:network-topology-1} uses only one prediction node, which is supported by both \sys and PyTorch, and is the default network topology in our micro-benchmark (Section~\ref{sec:exp-lazy}).
Network topology 2 in Figure~\ref{fig:network-topology-2} has 3 additional prediction nodes, and all these 4 prediction nodes can consume a shared message queue at the same time in ``Parallel'' experiments thanks to \sys.
Network topology 3 in Figure~\ref{fig:network-topology-3} takes advantage of model decomposition described in Section~\ref{sec:model-decomposition} and uses local data source nodes as local prediction nodes too. The node making prediction in topology 1 and 2 now only has to gather local predictions and take a majority vote.
All topologies have 4 data source nodes, from which we use 3 NUCs (in yellow) and 1 Jetson Nano (in black) to reflect the heterogeneity of real-world edge devices. The other NUC is set up as the leader node, or the ``master'' node in terms of PyTorch distributed. The rest of Jetson Nanos are prediction nodes where the actual computation is done, and one of them is designated as the destination node where final results should be sent.
All nine devices are interconnected via 1Gbps Ethernet.

\begin{figure}[t]
    \captionsetup[subfigure]{justification=centering}
    \centering
    \begin{subfigure}{0.29\columnwidth}
        \includegraphics[width=\columnwidth]{figures/network-topology-1.pdf}
        \caption{Topology 1\\ (Centralized)}
        \label{fig:network-topology-1}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.38\columnwidth}
        \includegraphics[width=\columnwidth]{figures/network-topology-2.pdf}
        \caption{Topology 2\\ (Parallel)}
        \label{fig:network-topology-2}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.29\columnwidth}
        \includegraphics[width=\columnwidth]{figures/network-topology-3.pdf}
        \caption{Topology 3\\ (Decentralized)}
        \label{fig:network-topology-3}
    \end{subfigure}
    \caption{Network topologies used in our experimental edge network. Topology 2 takes advantage of multiple prediction nodes consuming a shared message queue at the same time, and is only used in ``Parallel'' experiments.}
    \label{fig:network-topology}
\end{figure}

As a primary baseline, we have also configured PyTorch distributed~\cite{pytorch-distributed} on our edge cluster, with Gloo as the distributed communication backend.
We run PyTorch in both a centralized mode (traditional model serving) as well as a decentralized mode when possible.
We have also implemented an architecture similar to ROS~\cite{quigley2009ros} within our framework to understand the key design decisions.
ROS is widely used in the sensor and robotics communities and provides a centralized message broker service.
However, ROS does not support lazy data routing, distributed stream alignment, and adaptive rate control.
We excluded Tensorflow from this evaluation because  we found that the TensorFlow Distributed did not give us the fine-grained control over communication needed for fair experiments.
For synchronization-sensitive experiments, we set up a local NTP server to make sure all nine nodes share a global wall clock time.

\subsection{Evaluation Metrics}\label{sec:exp-metrics}
The following three metrics will serve as key measurements of \sys system performance:

\subsubsection{Backlog.}
We will refer to a metric called ``backlog'' measured in time. Intuitively, this metric captures whether a particular deployment can serve a certain rate of data arrival in a timely manner.
Specifically, we measure the total amount of time the last example takes to go from data source to leader to prediction nodes.
Backlog is an important metric because all kinds of delays can easily accumulate, which causes outdated predictions for later examples in a real-time inference scenario.
% Over all these pathways and different data streams, we use the total wall clock time spent on a task, from the first example gets collected until the last example gets predicted, as the proxy of end-to-end latency.
The lower bound of the backlog is near-zero, when there is no delay along the path from the data source to prediction nodes.
Ideally, such lower bound is achievable if data arrive slower than the rate our computational power can serve, or we might have to skip some data points to keep the predictions in time.
% If data were to arrive significantly faster than this metric, we would not be able to serve predictions to every data point.
% Admittedly, this metric does conflate communication and computation.
% But it is the easiest to understand across different use cases.

\subsubsection{Real-time Accuracy.} When it comes to real-time prediction tasks, the timeliness of predictions becomes a key concern of user experience. For latency-sensitive tasks, late prediction is incorrect prediction. To evaluate the timeliness of predictions, we define ``real-time accuracy'' to be the accuracy of predictions compared with last known label at prediction time.
For example, suppose a prediction is made temporally between two consecutive labels with timestamps $t_1$ and $t_2$ ($t_1 \leq t_2$). In that case, we compare the prediction result to the ground truth at $t_1$ to calculate the real-time accuracy.
Since we assume adjacent examples are likely similar, we expect roughly correct prediction results when the examples arrive slightly late. However, if the examples arrive significantly late, they are likely outdated and yield incorrect predictions.

\subsubsection{Excess Examples Processed.} Asynchronous messaging systems like \sys will naturally have to tolerate jitter and out-of-order messages. We evaluate the degree of these effects in terms of excess examples processed.
In a synchronous system, a certain number of inferences will be served.
We measure how many extra inferences the system computes to hit the prediction frequency target.
If the number of examples processed is less than 0, it means \sys performed downsampling to ensure timely predictions.



% We evaluate \sys based on two use cases: (1) network intrusion detection and (2) human activity recognition.
% For use case 1, we demonstrate how \sys is able to handle distributed prediction in a traditional workload that maximizes throughput as its goal.
% In this case, we ignore the complexity of data movement and assume the entire dataset is readily available upon request. Experiments show that \sys outperforms PyTorch distributed in such scenarios by 4x with a message broker and lazy data routing.
% For use case 2, we evaluate stream alignment and automatic rate matching offered by \sys. Data continuously comes in real time, and we need to aggregate data from multiple sources in order to make predictions in real time. \sys is able to align multiple streams of data in a time-synchronized way and produce predictions at the rate requested by the user.



\subsection{Human Activity Recognition}\label{sec:exp-opportunity}
We use the Opportunity dataset for human activity recognition~\cite{opportunity-dataset,opportunity-challenge} as an example to demonstrate our performance in a latency-sensitive scenario.
Data from multiple motion sensors were collected about every 33ms while users were executing typical daily activities. For each subject, there are five activity of daily living (ADL) runs, and each run lasts 15-30 minutes.
We take the first subject's first four ADL runs as the training set and the last ADL run as the testing set. When played at 2x speed, the last ADL run takes 8 minutes and 22 seconds.
We use the first 134 columns and partition these columns vertically into four disjoint subsets, as if they come from different data source nodes: 1-37 (accelerometers), 38-76 (IMU back and right arm), 77-102 (IMU left arm), and 103-134 (IMU shoes).
Data from multiple data source nodes need to be combined in order to make a prediction.
We train an aggregated random forest model with scikit-learn~\cite{scikit-learn} for all 134 features, and also four separate random forest models for each subset of features to evaluate an ensemble method.
For the inference stage, we simulate the generation of data at 2x the original speed and measure the latency between data collection and prediction completion.
In this experiment, we evaluate three ways the task can possibly be done: (Centralized, topology 1) transfer the entire dataset from data source nodes to the destination node, which also acts as the prediction node and does all computations in a centralized way; (Parallel, topology 2) transfer incoming data to a message queue where four prediction nodes can pull data from when they become available; (Decentralized, topology 3) make predictions locally at data source nodes and only transfer local predictions to the destination node, which then combines local predictions by a majority vote.
In our best-effort PyTorch implementation, we use the \texttt{gather()} API to aggregate data from multiple data source nodes.
PyTorch distributed requires all tensors to be the same size to be gathered, so we have to pad each local tensor to the maximum size with zeros.
Since there is no message queue in PyTorch, it is not possible to compare the Parallel (topology 2) strategy between \sys and PyTorch. However, we can still compare centralized and decentralized strategies across these two frameworks. 

% Unlike the NIDS example in Section~\ref{sec:exp-network}, time synchronization is an important challenge in this experiment.
In this experiment, the individual streams are fast enough that misalignments can occur due to queuing delays.
However, PyTorch enforces that multiple data sources are always perfectly synchronized, as we do not begin actual computation until data from all data sources has been gathered, and we only gather new data after finishing previous data items.
Such strict requirement does not exist in \sys, as we set a reasonable time interval that allows us to tolerate some amount of skew in examples.



\subsubsection{\sys Reduces Serving Backlog.}
\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\columnwidth]{figures/exp-opportunity-latency.pdf}
    \caption{Measure of backlog in the activity recognition dataset. Higher target frequencies are on the left side and lower frequencies are on the right side. Without a queuing system and rate control, a serving system will quickly develop a backlog (un-processed examples).}
    \label{fig:exp-opportunity-latency}
\end{figure}
First, we evaluate the backlog latency of the last example as defined in Section~\ref{sec:exp-metrics}, and the results are shown in figure~\ref{fig:exp-opportunity-latency}. The horizontal axis is the target prediction rate designated by the end-user, where a larger number means a lower frequency; the vertical axis is the backlog for each of the serving systems over this dataset, from data collection time to inference completion time.
The compute part of the task itself takes about 23ms to complete, and a near-zero number in backlog means the inference is processed in real time.
However, if there are a lot of examples yet to be processed, the last example would have to wait in line for a long time.
Since PyTorch does not offer a message queue and target frequency control, it has to process every single example one by one and does data aggregation in a synchronous manner.
For a wide range of prediction frequency targets, \sys offers a no-backlog queue (until the target is unattainable due to computational latencies).
For both \sys and PyTorch, we see a lower backlog for decentralized model placements because we are able to make the most of local data source nodes and save communication costs.
Parallelism helps reduce the backlog when the task is compute-bound, for example, when the target prediction frequency is too frequent (left on the x-axis). However, the speedup in latency is limited once compute is no longer the bottleneck (right on the x-axis).

% Numbers are reported as fractions of real-time. \sys is able to serve real-time predictions in both centralized and decentralized settings. This is a ceiling on performance as it does not need to predict any faster than the data arrival rate. On the other hand, PyTorch is unable to serve real-time predictions for this example (running at about 75\% of real-time). Note that decentralized prediction can still save communication costs to reduce latency for PyTorch distributed. This shows the value of such decentralized architectures.

\iffalse
\begin{table}[]
\centering
\begin{tabular}{l|l|l}
End-to-end latency           & PyTorch  & \sys \\ \hline
Centralized             & 1.46x    & 1x (real-time)      \\
Decentralized        & 1.35x    & 1x (real-time)
\end{tabular}
\caption{End-to-end latency for human activity recognition task, from generating the first piece of data until finishing the entire workload. \sys is able to process incoming data in real time while PyTorch does computation based on stale data. Both involve the same task with different model placement methods.}
\label{tab:exp-opportunity-latency}
\end{table}
\fi

\subsubsection{Decentralized Models Are More Accurate}\label{sec:exp-accuracy}
\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\columnwidth]{figures/exp-opportunity-accuracy.pdf}
    \caption{Overall real-time accuracy for human activity recognition task measured in F-1 score. Higher target frequencies are on the left side and lower frequencies are on the right side.}
    \label{fig:exp-opportunity-accuracy}
\end{figure}
The last set of experiments shows that decentralized models offer a wider operational range of serving in real time. Next, we show that these models can also be substantially more accurate because they offer more timely predictions.
Figure~\ref{fig:exp-opportunity-accuracy} shows the real-time accuracy (as defined in Section~\ref{sec:exp-metrics}) of \sys and PyTorch across different model placement strategies and requested output rates.
PyTorch distributed is not able to issue accurate predictions because data is communicated in a synchronous manner and it does not downsample the input stream even if the node is overloaded, making most of its predictions outdated.
On the other hand, even though messages processed by \sys might not be perfectly aligned temporally, \sys issues much more accurate predictions when the target prediction frequency is infrequent enough for the prediction node(s) to make predictions immediately after new data comes in.
For \sys decentralized, the real-time accuracy is still desirable even when the user requests very frequent outputs. There are several reasons behind this. First, local models are usually smaller and takes a shorter time to run. This enables \sys to downsample more incoming data at a certain prediction frequency, so the local models can catch up with data arrival rate better than in a centralized mode. Second, the heterogeneous nature of local data source nodes also plays a role. In our experiment, some data source nodes have better computational power than others and are able to finish local computations faster. After the early nodes complete their local work, the ensemble method would not be able to aggregate over all local predictions due to missing data, and thus stop issuing outdated predictions.

\iffalse
\subsubsection{Compute Utilization}
\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\columnwidth]{figures/exp-opportunity-compute-percentage.pdf}
    \caption{Compute utilization for different model placement strategies and user requested output frequencies. Higher target frequencies are on the left side and lower frequencies are on the right side.}
    \label{fig:exp-opportunity-compute-percentage}
\end{figure}
We have defined how we measure compute utilization in Section~\ref{sec:exp-metrics}, and figure~\ref{fig:exp-opportunity-compute-percentage} shows how compute utilization changes with different user-defined output rates.
Unlike most training workloads, decentralized prediction tasks are usually not compute-bound, at least not on all nodes. A certain amount of time is always spent on communication, time-synchronization or aggregation of different data sources, rather than mostly on computation.
In the case of \sys centralized, the prediction node is compute-bound when user-defined output rate is too high, but gradually becomes relaxed when the user asks for a lower output rate.
Decentralized model placements usually have a higher compute utilization because local data source nodes also do actual computations.
Note that higher compute utilization is not necessarily a good thing, because we might be working more than we need to. Remember our goal is to give accurate predictions in real time, and that usually means a certain amount of buffer is required to ensure timeliness. In the case of PyTorch decentralized, it does a lot of computational work but still fails to achieve our requirements for end-to-end latency and real-time accuracy.
\fi


% Now, it is true that this is not a completely fair comparison between PyTorch and \sys, since message misalignments can affect accuracy in \sys.
% However, we find this effect negligible. Figure \ref{fig:exp-opportunity-accuracy} shows the F1-score for \sys and Pytorch in both centralized and decentralized deployments. It is worth noting that there is a subtle issue of ``temporal'' accuracy because PyTorch is slower than real-time.  We ignore the fact that most predictions made with PyTorch distributed are outdated and compare them with the ground truths sequentially anyway. In \sys, however, we do care about the timeliness of predictions and treat outdated results as inaccurate results. Even under this strict definition of accuracy, we find that the communication optimizations in \sys are highly beneficial with a negligible impact on results.

\iffalse
\begin{table}[]
\centering
\begin{tabular}{l|l|l}
F-1 score   & PyTorch  & \sys \\ \hline
Centralized             & 0.90   & 0.90     \\
Decentralized         & 0.91   & 0.91
\end{tabular}
\caption{Overall accuracy for human activity recognition task measured in F-1 score. Despite message misalignments and rate-matching, \sys achieves the same accuracy as a fully-synchronized deployment.}
\label{tab:exp-opportunity-accuracy}
\end{table}
\fi


\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\columnwidth]{figures/exp-opportunity-examples.pdf}
    \caption{Number of examples processed for different strategies and user requested output frequencies. Higher target frequencies are on the left side and lower frequencies are on the right side. \sys is able to automatically downsample/upsample incoming data in order to catch up with requested output rate.}
    \label{fig:exp-opportunity-examples}
\end{figure}


\subsubsection{Decentralized Models Reduce Excess Work.}
Now, we look at the number of excess examples that are processed to better understand how \sys automatically upsamples/downsamples the incoming data stream to match the rate of prediction.
As can be seen from Figure~\ref{fig:exp-opportunity-examples}, PyTorch (either centralized or decentralized), as a baseline, is marked as zero on the y-axis because it always processes a fixed number of examples equal to the input size.
In both centralized and parallel settings, \sys is very sensitive to target prediction frequency because it no longer has to upsample the incoming data stream when such target is relaxed. Therefore, we see a rapidly decreasing excess work from left to right when the target prediction frequency is set to be more infrequent.
On the other hand, in a decentralized setting, \sys is not sensitive to such change in prediction frequency request because of the same reason why \sys decentralized maintains a high real-time accuracy discussed in Section~\ref{sec:exp-accuracy}. The highest frequency request of every 25ms is already longer than the typical compute time of a local model on faster local nodes, so downsampling is already performed even at the highest frequency. After faster nodes finish local predictions in almost real-time, the ensemble method simply skips further local predictions made by slower nodes because they are too far behind the last known message sent by each faster node.
As a result, decentralized models only process a small number of examples, even when the target prediction frequency is high enough.



\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\columnwidth]{figures/exp-opportunity-stdev.pdf}
    \caption{Standard deviation of actual prediction frequency for decentralized model placement. Higher target frequencies are on the left side and lower frequencies are on the right side. \sys maintains a lower variability in actual prediction frequencies.}
    \label{fig:exp-opportunity-stdev}
\end{figure}

\subsubsection{\sys Issues Prediction Results More Stably.}
Lastly, we look at the variability in actual prediction frequencies in decentralized settings between \sys and PyTorch.
In figure~\ref{fig:exp-opportunity-stdev}, we see a much higher variability in actual prediction frequencies for PyTorch than \sys across all user-defined rates.
This is because PyTorch communicates in a synchronous fashion, and has to account for the variability of all 4 nodes making local predictions with local data streams.
For \sys, since our data routing is asynchronous, the variability of \sys mostly comes from the imputations of the last known observation and the downsampling of incoming data streams. This variability continues to exist as long as the data arrivals are unpredictable.

% We set different \texttt{predition\_freq} parameters for the same task with (a) full transfer method. Table~\ref{tab:exp-rate-matching} shows the end-to-end latency and overall accuracy with the number of samples processed by \sys with different parameter settings. With a higher prediction frequency like 1ms, \sys automatically upsamples incoming data in order to make more frequent predictions. However, since the prediction process takes much longer than 1ms, upsampled data queues up and makes the end-to-end latency even worse. The prediction accuracy also gets worse because the data we use for predictions is outdated. With a lower prediction frequency closer to the actual model throughput, \sys automatically downsamples incoming data to match the given frequency. Since the queue is clear, we always make predictions based on the latest data to achieve better accuracy with lower end-to-end latency, only with a smaller number of samples.

\iffalse
\begin{table}[]
\centering
\begin{tabular}{l|l|l}
\# of samples processed    & PyTorch  & \sys \\ \hline
Centralized             & 30127   & 7920 (26\%)     \\
Decentralized         & 30127   & 11671 (39\%)
\end{tabular}
\caption{Overall number of samples for human activity recognition task. \sys is able to automatically downsample incoming data in order to catch up with data incoming rate.}
\label{tab:exp-opportunity-matching}
\end{table}
\fi

% \subsection{Micro-Benchmarks}
% First, we evaluate key design decisions of \sys as micro-benchmarks. Specifically, we show the benefits of (1) lazy data routing and (2) flexible data routing provided by a message broker.


\subsection{Benefits of Lazy Data Routing}\label{sec:exp-lazy}
In Section~\ref{sec:lazy}, we described our lazy data routing model, which is especially beneficial when (1) the leader node is busy with network requests, or (2) a lot of data is skipped by the backpressure method. This experiment shows how valuable this contribution can be with the network topology 1 described in Section\ref{sec:exp-setup}. We specifically construct a task where the message payload is large (real-time inference over video streams). In the previous set of experiments, we largely evaluated \sys in terms of its end-to-end benefits in model serving. In this experiment, we focus specifically on the queuing and messaging system, and use ROS as the primary baseline.

In this experiment, two webcams capture the same moving QR code from different positions. 
Both videos are 150 frames long at 1920x1080 resolution.
Each camera is connected to a different node on the network.
For multi-camera tracking, the QR code has to be detected in both streams and corresponded in time-aligned frames from both cameras.
We simulate a congestion scenario where the network bandwidth at the leader node is limited.
Note that the rest of the network retains its full speed; the only congestion is at the ``leader'' node.
We measure the total working duration of our system versus a ROS-like system that transfers raw data through a centralized broker (without lazy routing). 

Table~\ref{tab:congestion} illustrates the results.
With no congestion, the system can process in both lazy and eager data routing process 1 frame roughly every 1.3 seconds. With congestion, the story is very different. Our system is tolerant, while transferring raw frames in a ROS-style communication pattern can be extremely slow when the network is congested. The total working duration increases by a factor 7 simply due to congestion. Without care, distributed, multi-sensor deployments can easily lose real-time processing capabilities if the broker becomes a point of contention. These experiments illustrate the value of \sys in a controlled scenario, where we can isolate performance differences.

\begin{table}[t]
\centering
\begin{tabular}{l|l|l}
                          & Rate limit (up/down) & Time    \\ \hline
Lazy (ours) & No limit                       & 3m 10s  \\
Lazy (ours) & 1 Mbps / 1 Mbps                & 3m 12s  \\
Eager (similar to ROS)       & No limit                       & 3m 16s  \\
Eager (similar to ROS)         & 20 Mbps / 20 Mbps              & 21m 32s
\end{tabular}
\caption{Total working duration with network bandwidth limits.}
\label{tab:congestion}
\end{table}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\columnwidth]{figures/exp-lazy-vs-eager.pdf}
    \caption{Lazy data routing saves a lot of time in data communication when some data is skipped.}
    \label{fig:exp-lazy-vs-eager}
\end{figure}

Even without network congestion, lazy data routing is valuable when data skipping is employed to ensure the timeliness of prediction results.
We take one of the 150-frame videos mentioned before and transfer these frames from one node to another. Each frame is about 6 MB in its uncompressed form. No actual computation is performed as we are only interested in the communication cost. We measure the total duration from when the first frame is sent out until the last frame is delivered, and call it the total communication time.
In Figure~\ref{fig:exp-lazy-vs-eager}, we illustrate how much communication cost can be saved by lazy data routing.
On the x-axis, we have variable percentage of frames skipped due to adaptive rate control described in Section~\ref{sec:rate-control}; on the y-axis, we measure the total communication time as defined earlier.
Even when no frames are skipped, our lazy data routing performs better than a ROS-style eager routing pattern due to eliminated overhead of transferring a large amount of data through the leader node.
When more frames are skipped, our lazy data routing saves communication time almost linearly to the number of frames skipped by the downstream node.
That means the overhead of transferring headers through the leader node is negligible.
On the other hand, the ROS-style eager routing pattern spends roughly the same time on communication even if most of the frames are skipped by the downstream prediction node, because it would transfer the entire data payload upfront anyway.

\subsection{\sys Enables New Serving Topologies}\label{sec:exp-network}
\sys natively allows multiple producers and multiple consumers to operate on the same message queue at the same time, which is an essential communication paradigm in decentralized prediction but not currently supported by PyTorch or TensorFlow.
In this experiment, we show the benefits and overheads of routing data with a message queue, without further optimizations such as backpressure.
Unlike the human activity recognition example in Section~\ref{sec:exp-opportunity}, we are not interested in time-synchronization in this experiment. So we choose a pre-aggregated non-streaming workload that maximizes throughput as its goal.

Network intrusion detection systems (NIDS) monitor network traffic and detect malicious activity by identifying suspicious patterns in incoming packets.
Consider an NIDS monitoring traffic in an organization's private cloud.
On different nodes in this network, there are network packet captures that are tracking that node's incoming and outgoing network traffic.
All of this data is aggregated into a set of features that are fed into a predictive model that predicts whether the system is under attack or not.

We use a public Network Intrusion Detection dataset from Canadian Institute for Cybersecurity (CIC-IDS2017)~\cite{cic-ids2017} and an existing model to differentiate malicious traffic from benign network traffic~\cite{kostas2018}.
Specifically, we partition the data horizontally into four disjoint subsets by ``Source IP'' for our four data source nodes. The underlying assumption is that network traffic from different source IP addresses may be collected separately.

If a web attack is detected, the related network packet needs to be sent to a specific destination node, but the actual computation can be done anywhere. 
Similar to methods (a)-(c) in Section~\ref{sec:exp-opportunity}, we can choose from the following three strategies: (Centralized, topology 1) transfer all data to the prediction node that does all computations in a centralized way; (Parallel, topology 2) transfer all data from data source nodes to an intermediate message queue, where four prediction nodes can pull data from when they become available, and they need to inform the destination node if an attack is detected; or (Decentralized, topology 3) data source nodes do computations locally and only transfer data to the destination node if an attack is detected.  

In our best-effort PyTorch implementation, we use \texttt{send()} and \texttt{recv()} APIs to communicate between nodes, where data source nodes send data to the destination node, and the destination node receives data from all other nodes. However, to the best of our knowledge, there does not exist an API in the current PyTorch distributed framework where we can send/receive data to/from a shared pool, so Parallel (topology 2) strategy can only be implemented in \sys.

\iffalse
\begin{table}[]
\centering
\begin{tabular}{l|l|l|l}
Method   & Nodes & \begin{tabular}[c]{@{}l@{}}PyTorch\\ samples/sec\end{tabular} & \begin{tabular}[c]{@{}l@{}}\sys\\ samples/sec\end{tabular} \\ \hline
a) Centralized           & 4+1+1  & 41.94    & 47.58 (+13.4\%)      \\
b) Parallel              & 4+1+4  & - & 182.57 (3.84x)      \\
c) Decentralized         & 4+1+0 & 181.33 (4.32x)   & 197.30 (+8.8\%, 4.15x)
\end{tabular}
\caption{Throughput for network intrusion detection task. (a)-(c) involve the same task with different model placement methods. The nodes column shows the number of nodes involved, with $x+y+z$ denoting $x$ number of data source nodes, $y$ number of leader nodes, and $z$ number of prediction nodes. Both parallel (b) and decentralized (c) methods utilize four prediction nodes, whereas centralized (a) utilizes only one. Percentages in parentheses are relative to PyTorch distributed; speedups in parentheses are relative to centralized (a).\todo{this experiment is really confusing because we partition the dataset horizontally, with no aggregation required. In the later experiment we partition the dataset vertically, so aggregation is required.}}
\label{tab:exp-network}
\end{table}
\fi

In a centralized setting, PyTorch distributed is able to process 41.94 examples per second, while \sys can process 47.58 examples per second.
This is the baseline setting of both systems, and the performances of both systems are comparable.
In a Parallel setting that is only supported by \sys thanks to its queuing design, 182.57 examples are processed per second, which is almost a linear (3.84x) speedup compared to a centralized setting given that we now have 4 prediction nodes.
In a decentralized setting, we make all 4 data source nodes also local prediction nodes, and PyTorch achieves 181.33 examples per second while \sys takes 197.30 examples per second. For both systems, superlinear speedup (4.32x and 4.15x compared to centralized, respectively) is achieved by making the most of local computational resources and communicating only local prediction results instead of the entire dataset.
Since we use the same model/sub-models for both \sys and PyTorch without synchronization issues, the accuracies of predictions between both systems are the same.

In short, the results of this experiment can be summarized as follows: (1) the baseline performance of \sys is at least comparable to PyTorch, (2) \sys offers a wider range of decentralized prediction topologies, and (3) decentralized prediction can significantly improve overall prediction performance for both PyTorch and \sys.




\iffalse
\begin{table}[ht]
\centering
\begin{tabular}{l|l|l}
\begin{tabular}[c]{@{}l@{}}\sys parameter\\ \texttt{predition\_freq}\end{tabular} & \begin{tabular}[c]{@{}l@{}}End-to-end\\ latency\end{tabular}  & \begin{tabular}[c]{@{}l@{}}F-1 score\\ (\# of samples)\end{tabular} \\ \hline
30ms             & 1x (real-time)      & 0.90 (7920, 26\%)      \\
10ms             & 1x (real-time)      & 0.90 (11857, 39\%)     \\
5ms              & 1.84x   & 0.22 (31631, 105\%)     \\
1ms              & 6.98x   & 0.20 (120490, 400\%)    \\
\end{tabular}
\caption{End-to-end latency and overall accuracy with the number of samples for the same human activity recognition task. Latency numbers are relative to the actual data incoming rate, where 1x means real-time processing of streaming data. The number of samples is relative to the PyTorch baseline without downsampling/upsampling. Different \texttt{predition\_freq} parameters are applied to demonstrate the effect of adaptive SLO control.}
\label{tab:exp-rate-matching}
\end{table}
\fi





\iffalse

\section{Experiments: Multi-Camera Tracking}
% Full experiments: https://hackmd.io/@swjz/rJ1nfwi3i
% Spreadsheet and figures: https://docs.google.com/spreadsheets/d/1ebVHpCJEicbJ0IQzw15sqvJAuKCvkWpHMAvcoJAiSeQ/edit?usp=sharing
Our goal for this paper is to simulate a synchronization sensitive task and demonstrate the trade-off between latency, accuracy and communication. In order to achieve this goal, we set up a QR code detector where two webcams capture the same QR code from different positions. We move the physical position of the QR code along a horizontal axis and observe the QR code positions detected by both cameras. We compare the trajectory of positions to a centralized baseline where both cameras collect data on the same node to evaluate accuracy. 

\iffalse
\begin{figure}[t]
    \centering
    \includegraphics[width=1\columnwidth]{figures/offset.pdf}
    \caption{Illustration of QR code offset.}
    \label{fig:offset}
\end{figure}
\fi


\subsection{Hardware Setup}\label{sec:exp-setup}
Our hardware setup consists of two 1080p webcams and four Intel Skylake NUC computers, each equipped with an Intel Core i3-6100U CPU, 16 GB memory and M.2 SSD. In a centralized setting (Sec.~\ref{sec:centralized}), only one NUC computer is used and it is connected to both webcams. In a distributed setting (Sec.~\ref{sec:distributed}), all four NUC computers are used: two of them are connected to two webcams respectively serving as data source nodes, one of them serves as a message broker and the other NUC serves as the compute node taking input from data source nodes. All four NUCs are interconnected via 100Mbps Ethernet.

\subsection{Software Setup}\label{sec:software}
We use Apache Pulsar~\cite{apachepulsar} as the message broker to transfer messages between NUC computers. For small messages such as a 2D array, we transfer them directly via Pulsar. For larger files such as images, we create FTP paths for them and transfer those paths in messages for the compute node to download, saving traffic on the message broker side. For QR code detection, we use an OpenCV resolution with two CNN-based Caffe models: an object detection model to detect the QR code with a bounding box and a super-resolution model to zoom in the QR code when it is small.
Videos are collected in advance to ensure reproducibility and we simulate real-time streaming of these videos.
All results present the average values of 3 experiments.
All videos used in the following experiments are of 1920x1080 resolution, 5 seconds long at 30 FPS unless otherwise specified. The size of QR code is about 200x200.

\subsection{Metrics and Ground Truth}
In this experiment, we define accuracy as pixel-level `error', which is the difference between ground truth trajectory and the experiments in both x and y axes in the unit of absolute pixels, averaged over all frames. The smaller the absolute number of `error', the more accurate the target experiment is. The ground truth of such offset is defined as the offset between two videos in a centralized setup without compression (Table~\ref{tab:centralized}(a)-(d)). If there is no QR code detected from a certain frame in the target experiment, we use the last known QR code position for that camera. For down-sample experiments, we up-sample the missing frames with the last known frame when measuring accuracy as well.
We also define latency as the time period from the timestamp when the first piece of data is transferred until the timestamp when the prediction for the last piece of data is issued. Since all of our videos have the same length of 5 seconds, this metric is a proxy for ``timeliness'' defined before.

\subsection{Centralized Compute}
\label{sec:centralized}
As a baseline, we consider a scenario where the computation is centralized. There is no communication or synchronization issue in this case. Therefore, we treat the result from this run as ground truth and running time as a baseline. We demonstrate the intrinsic characteristics between fast and slow movements of the QR code and explore the latency component of disk I/O to get a better understanding of the task.

\begin{table}[]
\centering
\begin{tabular}{l|l|l}
                 & Fast movement & Slow movement \\ \hline
a) Memory       & 9.92s                 & 10.52s        \\
%b) Write as BMP     & 11.60s (+1.68s, 17\%)       & 12.04s (+1.52s, 14\%)        \\
%c) Read from BMP    & 12.07s (+2.15s, 22\%)       & 12.42s (+1.90s, 18\%)        \\
b) Disk (uncompressed)  & 13.53s (+3.61s, 36\%)       & 13.75s (+3.23s, 31\%)       \\
c) Disk (jpeg) & 29.76s (+19.84s, 200\%)       & 31.16s (+20.64s, 196\%)
\end{tabular}
\caption{Latency from a centralized compute: (a)-(c) involve the same task with different level of disk access. Numbers and percentages in parentheses are relative to (a).}
\label{tab:centralized}
\end{table}

Table~\ref{tab:centralized} shows the latency from centralized multi-camera tracking example: (a) both streams are captured and passed to \sys in memory; (b) the camera streams are stored to disk in an uncompressed format and incrementally retrieved by \sys; and (c) the camera streams are stored to disk in a JPEG format and incrementally retrieved by \sys.

First, we look at the differences between fast movement and slow movement columns. When we move the QR code too fast, quite a few frames are too blurry for the detector to recognize anything so the decoding step is skipped. Therefore, it takes a little shorter time to finish the computation in fast movement cases. Second, we compare Table~\ref{tab:centralized}(b) against (a) to measure the latency of disk I/O. Specifically, reading and writing image files from/to disk takes about the same amount of time and they add up to about 30-40\% of compute time. We see from Table~\ref{tab:centralized}(c) that disk I/O with JPEG runs significantly longer because extra time is spent on compression and decompression.

It should be noted that images in BMP format are lossless and the size of each BMP file is about 6 MB. JPEG compression is lossy but could significantly reduce file size to 200-300 KB. The accuracy of JPEG compression is shown in Table~\ref{tab:jpeg-accuracy}. In both axes, we see an average error of less than 1 pixel, which is nearly perfect. Fast movement is worse because some blurry frames that are recognizable as BMP files are no longer recognizable after JPEG compression.

\begin{table}[]
\centering
\begin{tabular}{l|l|l}
JPEG accuracy & Fast movement & Slow movement \\ \hline
x-axis        & 0.5931px      & 0.0050px     \\
y-axis        & 0.3868px      & 0.0022px     
\end{tabular}
\caption{Errors introduced by JPEG compression.}
\label{tab:jpeg-accuracy}
\end{table}

\subsection{Distributed Edge Cluster}\label{sec:distributed}
As described in Sec.~\ref{sec:exp-setup}, we construct an Edge cluster and do the same QR code detection task, where data is collected on different nodes.
% Both data sources need to arrive at the compute node in an aligned manner.
We build a queue for each data source at the message broker and they are aggregated to make a prediction as soon as there is new data coming in from any data source. A data point may be reused to make a joint prediction if it is still the latest from an infrequent data source.
Jitter in the network, variability in processing times, and queuing delays can introduce extra errors. We compare these errors to the sub-pixel errors introduced by lossy compression above.

% Slow movement results
% \begin{table}[]
% \centering
% \begin{tabular}{l|l|l|l|l}
%               & Size   & Time                                                      & x-axis error & y-axis error \\ \hline
% BMP (30 FPS)  & 1.7 GB & \begin{tabular}[c]{@{}l@{}}3m 10s\\ (2m 41s)\end{tabular} & -31.216px    & 1.4522px     \\
% BMP (10 FPS)  & 593 MB & \begin{tabular}[c]{@{}l@{}}1m 4s\\ (53.8s)\end{tabular}   & -14.6671px   & 0.6375px     \\
% JPEG (30 FPS) & 72 MB  & \begin{tabular}[c]{@{}l@{}}52.7s\\ (8.35s)\end{tabular}   & 4.7356px     & -0.0940px    \\
% JPEG (10 FPS) & 27 MB  & \begin{tabular}[c]{@{}l@{}}17.9s\\ (3.2s)\end{tabular}    & 0.4415px     & -0.0150px   
% \end{tabular}
% \caption{BMP, JPEG and downsampling comparison. Numbers in parentheses are time spent purely on data download, measured by \texttt{wget}.}
% \label{tab:distributed}
% \end{table}

% Fast movement results
\begin{table}[]
\centering
\begin{tabular}{l|l|l|l|l}
              & Size   & Time                                                      & x-axis error & y-axis error \\ \hline
BMP (30 FPS)  & 1.7 GB & \begin{tabular}[c]{@{}l@{}}3m 11s\\ (2m 41s)\end{tabular} & 22.8402px   & 4.1812px     \\
BMP (10 FPS)  & 593 MB & \begin{tabular}[c]{@{}l@{}}1m 4s\\ (53.8s)\end{tabular}   & 7.3501px    & 1.7942px     \\
BMP (5 FPS)   & 297 MB & \begin{tabular}[c]{@{}l@{}}32.1s\\ (27.1s)\end{tabular}   & 29.4458px    & 1.5753px     \\
JPEG (30 FPS) & 72 MB  & \begin{tabular}[c]{@{}l@{}}49.8s\\ (8.3s)\end{tabular}    & 4.0714px     & 0.4754px     \\
JPEG (10 FPS) & 24 MB  & \begin{tabular}[c]{@{}l@{}}16.6s\\ (2.9s)\end{tabular}    & 6.6651px    & 2.7245px     \\
JPEG (5 FPS)  & 12 MB  & \begin{tabular}[c]{@{}l@{}}8.2s\\ (1.6s)\end{tabular}    & 29.4797px    & 1.6021px    
\end{tabular}
\caption{BMP, JPEG and down-sampling comparison. Numbers in parentheses are time spent purely on data download, measured by \texttt{wget}.}
\label{tab:distributed}
\end{table}

% \vspace{0.25em} \noindent \emph{Effect of Down-Sampling and Compression on Accuracy.}
\subsubsection{Effect of Down-sampling and Compression on Accuracy.}\label{sec:exp-downsample}
Counter-intuitively, degrading the quality of the data collected from the sensors can lead to better results in the distributed setting.
We compare compression and effects of down-sampling in Table~\ref{tab:distributed}. We find that down-sampling can almost linearly improve latency because it directly reduces data transfer. It also forces synchronization on the data source side to improve accuracy until it reaches a sweet spot, after which we lose so much information between frames that accuracy starts to decrease. JPEG compression has a similar effect of reducing data transfer significantly, which also improves latency compared to BMP counterparts. Since JPEG compression takes a while (as shown in Table~\ref{tab:centralized}), it acts as a rate limit at the data source, similar to the down-sampling method, which also forces synchronization. The accuracy `sweet spot' for JPEG is reached at the original sampling rate and further down-sampling would only decrease accuracy.
% Alternatively, we could also manually set a rate limit at compute node, which buffers input data but does not issue predictions until all data sources are fully synchronized.

% Slow movement results
% \begin{table}[]
% \centering
% \begin{tabular}{l|l|l|l}
% Ensemble method      & Time  & x-axis error & y-axis error \\ \hline
% Original 30 FPS   & 6.55s & 58.911px     & 0.2834px     \\
% Downsampled to 10 FPS & 6.35s & -11.273px    & 0.8657px
% \end{tabular}
% \caption{Latency and accuracy for Ensemble method.}
% \label{tab:ensemble}
% \end{table}

% Fast movement results
\begin{table}[]
\centering
\begin{tabular}{l|l|l|l}
Endpoint-Placement & Time  & x-axis error & y-axis error \\ \hline
Original 30 FPS       & 5.79s & 22.4691px    & 2.7398px    \\
Down-sampled to 10 FPS & 5.93s & 24.7646px   & 5.6231px     \\
Down-sampled to 5 FPS  & 5.55s & 29.5273px   & 1.7011px
\end{tabular}
\caption{Latency and accuracy for Endpoint-Placement.}
\label{tab:ensemble}
\end{table}

% \vspace{0.25em} \noindent \emph{Compute Placement and Synchronization Errors.}
\subsubsection{Compute Placement and Synchronization Errors.}\label{sec:exp-placement}
It is a natural thought that moving inference closer to the point of data collection is desirable in edge computing; this is not always the case in multimodal prediction.
Instead of transferring frames over the network, we could also run the model at data source nodes and only transfer coordinates over the network. This method makes use of model parallelism and spare resources on data source nodes to save communication between data source nodes and compute node(s). Such an ``Endpoint-Placement'' method is perfectly suitable for our use case because we have light models but heavy communication. Table~\ref{tab:ensemble} shows that this method improves latency by 33x compared to BMP (30 FPS) in Table~\ref{tab:distributed}.

However, Endpoint-Placement methods can be a source of misalignment as well, especially when a model runs faster for some data points but slower for other data points. The variability in model inference latency across nodes can add up to become a synchronization problem and reduces accuracy. In Table~\ref{tab:ensemble}, we see higher synchronization errors because of this variability.


% \vspace{0.25em} \noindent \emph{Effect of Queuing Strategy.}
\subsubsection{Effect of Lazy Data Routing.}\label{sec:exp-queuing}
In Sec.~\ref{sec:software} we described how we use FTP to transfer large data directly from data source to compute node and only pass pointers to data over the message broker. This is especially beneficial when the message broker is busy with network requests. We simulate a congestion scenario where the network bandwidth at the message broker is limited and measure the end-to-end latency of our system versus a ROS-like system that transfers raw data through a centralized broker. Table~\ref{tab:congestion} shows that our system is tolerant to slow network bandwidth while transferring raw frames can be extremely slow when the network is congested.

\begin{table}[]
\centering
\begin{tabular}{l|l|l}
                          & Rate limit (up /down) & Time    \\ \hline
Lazy (ours) & No limit                       & 3m 10s  \\
Lazy (ours) & 1 Mbps / 1 Mbps                & 3m 12s  \\
Eager (similar to ROS)       & No limit                       & 3m 16s  \\
Eager (similar to ROS)         & 20 Mbps / 20 Mbps              & 21m 32s
\end{tabular}
\caption{Latency with network bandwidth limits.}
\label{tab:congestion}
\end{table}

\fi