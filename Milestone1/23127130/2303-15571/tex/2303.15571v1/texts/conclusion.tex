\section{Conclusion and Future Work} \label{sec: conclusion}
In this work, we propose a novel adversarial detection framework, EMShepherd, leveraging the EM side-channel of model execution. 
%novel electromagnetic-based detection technique against DNN adversarial examples, based on the observation that EM emanation leaks the data-dependent inference information.
EM traces embody rich input (class)-dependent inference information, well suited for classification and anomaly detection. 
Our framework extracts EM feature invariants for different classes and use them for unsupervised anomaly detection. 
%We develop an innovative detection framework to extract  EM invariants from multiple layers and integrate them for anomaly detection.
The adversarial detector can be deployed as an air-gapped, third-party, PnP system in the proximity of the victim system in operation. It is totally passive and noninvasive without probing the model execution or retraining the model. 
The performance of our black-box adversarial detector is comparable to the state-of-the-art software-based white-box detection method, but has a much broader and more general application to diverse DNN implementations and applications.

Our future work will adapt the framework for the detection of more attacks, such as Trojan attacks, backdoor attacks, and data poisoning attacks. 
The EM side-channel leakage of deep learning engines during execution can be further leveraged for more applications, e.g., membership inference attacks where the input categories are reverse engineered. 

\if false 
\noindent\textbf{EM Side Channel Attack} 
Previous studies on DNN EM side-channel attacks explore the possibility of recovering the model structures and parameters~\cite{yu2020deepem}. 
In addition, we also find that EM emanation may also contain category dependency.
It is possible to explore data confidentiality attacks such as membership inference attacks~\cite{shokri2017membership}.

\noindent\textbf{Adaptive Adversaries}
Software-based detection methods should consider adaptive adversarial attacks when the attacker realizes the detection framework and adjusts inputs to fool the detector. 
Such attacks may encounter difficulties when targets at EMShepred, where the adaptive adversarial samples are too complex to craft. 
Future researchers can study the insights of how embedding devices leak computation patterns via EM for effective adaptive attacks.

\noindent\textbf{Data Poisoning Attacks} 
The trojan attack is another insidious variant of data poisoning attacks, which exploits a backdoor to DNN models to misclassify any inputs signed with the trojan trigger. 
EMShepred can be extended to other data poisoning attacks on DNN to build a comprehensive attack defense system.
\fi 
