{
    "arxiv_id": "2303.09199",
    "paper_title": "A Generative Model for Digital Camera Noise Synthesis",
    "authors": [
        "Mingyang Song",
        "Yang Zhang",
        "Tunç O. Aydın",
        "Elham Amin Mansour",
        "Christopher Schroers"
    ],
    "submission_date": "2023-03-16",
    "revised_dates": [
        "2023-03-20"
    ],
    "latest_version": 2,
    "categories": [
        "cs.CV",
        "eess.IV"
    ],
    "abstract": "Noise synthesis is a challenging low-level vision task aiming to generate realistic noise given a clean image along with the camera settings. To this end, we propose an effective generative model which utilizes clean features as guidance followed by noise injections into the network. Specifically, our generator follows a UNet-like structure with skip connections but without downsampling and upsampling layers. Firstly, we extract deep features from a clean image as the guidance and concatenate a Gaussian noise map to the transition point between the encoder and decoder as the noise source. Secondly, we propose noise synthesis blocks in the decoder in each of which we inject Gaussian noise to model the noise characteristics. Thirdly, we propose to utilize an additional Style Loss and demonstrate that this allows better noise characteristics supervision in the generator. Through a number of new experiments, we evaluate the temporal variance and the spatial correlation of the generated noise which we hope can provide meaningful insights for future works. Finally, we show that our proposed approach outperforms existing methods for synthesizing camera noise.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.09199v1",
        "http://arxiv.org/pdf/2303.09199v2"
    ],
    "publication_venue": null
}