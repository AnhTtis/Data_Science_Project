\section{Related Work}

% \noindent\textbf{Mainstream HPS methods with weak-perspective cameras.}
\noindent\textbf{Mainstream 3D human mesh reconstruction methods.}
3D human pose estimation from a single RGB image is essentially an ill-posed problem. To obtain more realistic and manipulable human bodies, a parametric body model SMPL~\cite{smpl} was proposed, which uses 3D rotation representation to model human joint motions with defined LBS weights. To reconstruct human mesh from RGB images, there exist two mainstream pipelines: optimization-based methods and learning-based methods.

Optimization-based methods~\cite{smplify,fang2021mirrored} directly fit the body model parameters to 2D evidence via gradient back-propagation in an iterative manner.
Learning-based approaches~\cite{hmr,Pavlakos,decomr,pare} leverage a deep neural network to regress the human body model parameters or 3D coordinates of the human mesh, which can be further divided into model-based and model-free methods.
Inspired by 3D mesh reconstruction tasks\cite{c-axis, topdown, close, rfeps, global, avatarclip, sherf}, Model-based methods works~\cite{hmr,spec,pare,hybrik,smoothnet,deciwatch} utilize SMPL parameters to recover the human pose and shape. The milestone method HMR~\cite{hmr} takes it as a direct regression task.
% Some other works try to utilize the help from intermediate representations, \eg 2D/3D joint heatmaps~\cite{skeleton2mesh,Pavlakos}, silhouettes~\cite{pare} and IUV map~\cite{pymaf}.

Model-free works~\cite{graphcmr, meshgraphormer, fastmetro, tore} directly reconstructing 3D meshes from single view images. 
% GraphCMR~\cite{graphcmr} and FastMETRO~\cite{fastmetro} learn the relations among the vertices for better reconstruction.

\begin{figure}[t]
\begin{center}
    \includegraphics[width=0.8\linewidth]{pictures/camera_systems.pdf}
\end{center}
\caption{
\textbf{Comparison of 4 different camera models in 3DHMR task}.
For HMR~\cite{hmr}, the focal length is fixed as 5000 pixels. Most methods follow this setting. For SPEC~\cite{spec}, the focal length is estimated by a network $R_{f}$ pre-trained on other datasets. For CLIFF~\cite{cliff}, during training, if without ground-truth focal length, will use the length of diagonal length. For \Ours, we use the estimated z-axis translation \emph{z}, camera parameter \emph{s}, and image height \emph{h} to calculate focal length.
}
\label{fig:camera}
\end{figure}


\noindent\textbf{Human mesh reconstruction with specific camera systems.} 
In the previous trend led by HMR~\cite{hmr}, the intrinsic camera model is formed as a weak-perspective camera, with a constant focal length of $5,000$ pixels. However, this assumption does not hold well when the person is close to the camera center, resulting in errors in the reconstructed 3D shape and pose. To address this issue, several recent works such as BeyondWeak~\cite{beyondweak}, SPEC~\cite{spec}, and CLIFF~\cite{cliff} have proposed different camera system assumptions. SPEC predicts camera parameters (pitch, yaw, and FoV) from a single-view image, but its asymmetric Softargmax-$\mathcal{L}_2$ loss tends to overestimate focal length and translation, which is not suitable for distorted images. Moreover, SPEC regresses camera parameters through environmental information, which can sometimes be meaningless when the background lacks geometry information. CLIFF focuses on joint rotation variance caused by horizontal shift but has not conditioned the distance from the human body to the camera. CLIFF, following BeyondWeak\cite{beyondweak}, uses the diagonal length of the image as the focal length, which is not a close assumption for distorted problems since the focal length can be easily adjusted during image capture.


Compared to these methods, our framework estimates the z-axis translation from 2D human distortion features, and obtains a more accurate focal length from the estimated translation, leading to much better reconstruction accuracy on distorted images. See a comparison of the camera models in \cref{fig:camera}.
In the Sup. Mat., we quantitatively demonstrate the bad re-projection influence caused by a wrongly formulated projection matrix.
