{
    "arxiv_id": "2303.15892",
    "paper_title": "Head3D: Complete 3D Head Generation via Tri-plane Feature Distillation",
    "authors": [
        "Yuhao Cheng",
        "Yichao Yan",
        "Wenhan Zhu",
        "Ye Pan",
        "Bowen Pan",
        "Xiaokang Yang"
    ],
    "submission_date": "2023-03-28",
    "revised_dates": [
        "2023-03-29"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "Head generation with diverse identities is an important task in computer vision and computer graphics, widely used in multimedia applications. However, current full head generation methods require a large number of 3D scans or multi-view images to train the model, resulting in expensive data acquisition cost. To address this issue, we propose Head3D, a method to generate full 3D heads with limited multi-view images. Specifically, our approach first extracts facial priors represented by tri-planes learned in EG3D, a 3D-aware generative model, and then proposes feature distillation to deliver the 3D frontal faces into complete heads without compromising head integrity. To mitigate the domain gap between the face and head models, we present dual-discriminators to guide the frontal and back head generation, respectively. Our model achieves cost-efficient and diverse complete head generation with photo-realistic renderings and high-quality geometry representations. Extensive experiments demonstrate the effectiveness of our proposed Head3D, both qualitatively and quantitatively.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.15892v1"
    ],
    "publication_venue": null
}