\section{Conclusion}
%In this paper, we present Head3D, a full head generator via tri-plane feature distillation. First, we revisit the framework of EG3D, highlighting tri-plane as the semantic information carrier. Then, We find the decoupling of tri-plane through experiments, and identity is controlled by $xy$ plane. Last, we propose tri-plane feature distillation and dual-discriminators for training head generators. Extensive experiments have verified the effectiveness of our proposed method. We hope that this work could be an inspiration to guide the joint training on 2D data and 3D data, to achieve diverse and high-quality full head generation.

This paper presents Head3D, a method for generating complete heads trained with limited data. We first revisit the EG3D framework and emphasize the importance of tri-plane as a semantic information carrier. Through experiments, we demonstrate that tri-plane decoupling is achievable, with identity information controlled by the $xy$-plane. We then propose a tri-plane feature distillation approach and a dual-discriminator method for training head generators. Extensive experiments confirm the effectiveness of our proposed method. We hope that our work will inspire further researches in generating diverse and high-quality 3D complete heads from limited and uncorrelated images.

% \noindent\textbf{Limitation.} 
% Although our work can achieve complete head generation based on a small number of multi-view images and face prior, the number of hairstyles is insufficient to ensure correspondence with the faces, \eg wearing hats and glasses. Besides, camera parameters in rendering should be close to the pre-trained face generator, which limits the process of data collection. Finally, this method is only applicable to tri-plane-based generators, and cannot be generalized to all face generators.

% \noindent\textbf{Ethical Considerations.} 
% The multi-view 3D GAN inversion in head reconstruction may suffer the risk of being abused on real humans. We strongly condemn applying our work to undermine social rules. In addition, facial prior depends on EG3D. As mentioned in its paper, a lack of generation diversity or data bias may occur.