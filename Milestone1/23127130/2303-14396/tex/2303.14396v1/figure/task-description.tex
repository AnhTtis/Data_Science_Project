\begin{figure*}[t]
\vspace{-0.1in}
\centering
    \includegraphics[width=0.93\textwidth]{resource/adaptation-and-inference-new.pdf}
\caption{\textbf{Overview of the proposed Image-Free Segmentation (IFSeg) task.} 
\textbf{(a) Training:} Artificial training data is constructed by randomly sampling words from the segmentation vocabulary $\mathcal{V}_\mathtt{seg}=\{v_0, v_1\}$ (\emph{e.g.}, ``$v_0$: grass'' and ``$v_1$: giraffe''). Sub-word tokens (\emph{e.g.}, ``-gir'' and ``-affe'') are managed by averaging their embeddings. Given the artificial image token $\mathbf{x}_\mathtt{I}$ and the prompt $\mathbf{x}_\mathtt{T}$, we adapt a pre-trained VL encoder-decoder to predict the corresponding word for each region of the artificial image token in a self-supervised manner (\emph{i.e.}, $\mathbf{y}_\mathtt{gt}=\mathbf{x}_\mathtt{I}$).
\textbf{(b) Inference:} During the inference on a real image $\mathcal{X}_\mathtt{I}$, the real image token is generated using the image backbone $f_\mathtt{img}(\mathcal{X}_\mathtt{I})$. The adapted VL encoder-decoder predicts the semantic category words for individual image regions (or pixels).}
\label{fig3:ifseg_overview}
\vspace{-0.15in}
\end{figure*}