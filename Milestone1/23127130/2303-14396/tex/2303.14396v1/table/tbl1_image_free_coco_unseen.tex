\begin{table}[t]
\centering
\small
\scalebox{1.0}
{
\begin{tabular}{llcc}
    \toprule
    Method & Backbone & Image Dataset & mIoU \\
    \midrule
    MaskCLIP+ \cite{zhou2022extract} & ResNet-101 & COCO (118k) & 48.7 \\
    \midrule
    CLIP \cite{radford2021learning,zhou2022extract} & ResNet-101 & \xmark & 12.3 \\
    OFA \cite{wang2022ofa}  & ResNet-101  & \xmark & {6.8} \\ 
    MaskCLIP\cite{zhou2022extract}  & ResNet-101 & \xmark & 24.8 \\
    IFSeg (ours) & ResNet-101  & \xmark & \textbf{55.6} \\
    \bottomrule
\end{tabular}
}
\caption{\textbf{Comparison with zero-shot and image-free baselines.} We report the mIoU metric of the baselines and our model predicting the 15 unseen semantic categories of the COCO Stuff benchmark.
 “Image Dataset” denotes required images for training.
Our post-processing has been applied to all results for a fair comparison.}
\label{tbl1:coco_unseen}
\vspace{-0.1in}
\end{table}
