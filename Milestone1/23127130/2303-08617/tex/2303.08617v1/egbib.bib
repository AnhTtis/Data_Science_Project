@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

@book{mehrabian1974approach,
  title={An approach to environmental psychology.},
  author={Mehrabian, Albert and Russell, James A},
  year={1974},
  publisher={the MIT Press}
}

@article{wen2021distract,
  title={Distract your attention: Multi-head cross attention network for facial expression recognition},
  author={Wen, Zhengyao and Lin, Wenzhong and Wang, Tao and Xu, Ge},
  journal={arXiv preprint arXiv:2109.07270},
  year={2021}
}
@inproceedings{she2021dive,
  title={Dive into ambiguity: Latent distribution mining and pairwise uncertainty estimation for facial expression recognition},
  author={She, Jiahui and Hu, Yibo and Shi, Hailin and Wang, Jun and Shen, Qiu and Mei, Tao},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6248--6257},
  year={2021}
}

@inproceedings{li2022towards,
  title={Towards semi-supervised deep facial expression recognition with an adaptive confidence margin},
  author={Li, Hangyu and Wang, Nannan and Yang, Xi and Wang, Xiaoyu and Gao, Xinbo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4166--4175},
  year={2022}
}
@inproceedings{zeng2022face2exp,
  title={Face2exp: Combating data biases for facial expression recognition},
  author={Zeng, Dan and Lin, Zhiyuan and Yan, Xiao and Liu, Yuting and Wang, Fei and Tang, Bo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={20291--20300},
  year={2022}
}
@article{li2022crs,
  title={CRS-CONT: A Well-Trained General Encoder for Facial Expression Analysis},
  author={Li, Hangyu and Wang, Nannan and Yang, Xi and Gao, Xinbo},
  journal={IEEE Transactions on Image Processing},
  volume={31},
  pages={4637--4650},
  year={2022},
  publisher={IEEE}
}
@inproceedings{lukov2022teaching,
  title={Teaching with Soft Label Smoothing for Mitigating Noisy Labels in Facial Expressions},
  author={Lukov, Tohar and Zhao, Na and Lee, Gim Hee and Lim, Ser-Nam},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XII},
  pages={648--665},
  year={2022},
  organization={Springer}
}
@inproceedings{zhang2022learn,
  title={Learn from all: Erasing attention consistency for noisy label facial expression recognition},
  author={Zhang, Yuhang and Wang, Chengrui and Ling, Xu and Deng, Weihong},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXVI},
  pages={418--434},
  year={2022},
  organization={Springer}
}

@inproceedings{li2017reliable,
  title={Reliable crowdsourcing and deep locality-preserving learning for expression recognition in the wild},
  author={Li, Shan and Deng, Weihong and Du, JunPing},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2852--2861},
  year={2017}
}

@article{mollahosseini2017affectnet,
  title={Affectnet: A database for facial expression, valence, and arousal computing in the wild},
  author={Mollahosseini, Ali and Hasani, Behzad and Mahoor, Mohammad H},
  journal={IEEE Transactions on Affective Computing},
  volume={10},
  number={1},
  pages={18--31},
  year={2017},
  publisher={IEEE}
}

@inproceedings{yu2015image,
  title={Image based static facial expression recognition with multiple deep network learning},
  author={Yu, Zhiding and Zhang, Cha},
  booktitle={Proceedings of the 2015 ACM on international conference on multimodal interaction},
  pages={435--442},
  year={2015}
}


@inproceedings{kollias2023abaw,
  title={Abaw: Learning from synthetic data \& multi-task learning challenges},
  author={Kollias, Dimitrios},
  booktitle={European Conference on Computer Vision},
  pages={157--172},
  year={2023},
  organization={Springer}
}
 

D. Kollias: "ABAW: Valence-Arousal Estimation, Expression Recognition, Action Unit Detection & Multi-Task Learning Challenges", IEEE CVPR, 2022
@inproceedings{kollias2022abaw, title={Abaw: Valence-arousal estimation, expression recognition, action unit detection \& multi-task learning challenges}, author={Kollias, Dimitrios}, booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages={2328--2336}, year={2022} } 

 

D. Kollias, et. al.: "Distribution Matching for Heterogeneous Multi-Task Learning: a Large-scale Face Study", 2021
@article{kollias2021distribution, title={Distribution Matching for Heterogeneous Multi-Task Learning: a Large-scale Face Study}, author={Kollias, Dimitrios and Sharmanska, Viktoriia and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:2105.03790}, year={2021} }

 

D. Kollias, et. al.: "Analysing Affective Behavior in the second ABAW2 Competition". ICCV, 2021
@inproceedings{kollias2021analysing, title={Analysing affective behavior in the second abaw2 competition}, author={Kollias, Dimitrios and Zafeiriou, Stefanos}, booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages={3652--3660}, year={2021}}

 

D. Kollias,S. Zafeiriou: "Affect Analysis in-the-wild: Valence-Arousal, Expressions, Action Units and a Unified Framework, 2021
@article{kollias2021affect, title={Affect Analysis in-the-wild: Valence-Arousal, Expressions, Action Units and a Unified Framework}, author={Kollias, Dimitrios and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:2103.15792}, year={2021}}

 

D. Kollias, et. al.: "Analysing Affective Behavior in the First ABAW 2020 Competition". IEEE FG, 2020

@inproceedings{kollias2020analysing,
  title={Analysing affective behavior in the first abaw 2020 competition},
  author={Kollias, Dimitrios and Schulc, Attila and Hajiyev, Elnar and Zafeiriou, Stefanos},
  booktitle={2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020)},
  pages={637--643},
  year={2020},
  organization={IEEE}
}
 

D. Kollias, S. Zafeiriou: "Expression, Affect, Action Unit Recognition: Aff-Wild2, Multi-Task Learning and ArcFace". BMVC, 2019
@article{kollias2019expression, title={Expression, Affect, Action Unit Recognition: Aff-Wild2, Multi-Task Learning and ArcFace}, author={Kollias, Dimitrios and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:1910.04855}, year={2019}}

 

D. Kollias, et at.: "Face Behavior a la carte: Expressions, Affect and Action Units in a Single Network", 2019
@article{kollias2019face,title={Face Behavior a la carte: Expressions, Affect and Action Units in a Single Network}, author={Kollias, Dimitrios and Sharmanska, Viktoriia and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:1910.11111}, year={2019}}

 

D. Kollias, et. al.: "Deep Affect Prediction in-the-wild: Aff-Wild Database and Challenge, Deep Architectures, and Beyond". International Journal of Computer Vision (IJCV), 2019
@article{kollias2019deep, title={Deep affect prediction in-the-wild: Aff-wild database and challenge, deep architectures, and beyond}, author={Kollias, Dimitrios and Tzirakis, Panagiotis and Nicolaou, Mihalis A and Papaioannou, Athanasios and Zhao, Guoying and Schuller, Bj{\"o}rn and Kotsia, Irene and Zafeiriou, Stefanos}, journal={International Journal of Computer Vision}, pages={1--23}, year={2019}, publisher={Springer} }

 

S. Zafeiriou, et. al. "Aff-Wild: Valence and Arousal in-the-wild Challenge". IEEE CVPR, 2017
@inproceedings{zafeiriou2017aff, title={Aff-wild: Valence and arousal ‘in-the-wild’challenge}, author={Zafeiriou, Stefanos and Kollias, Dimitrios and Nicolaou, Mihalis A and Papaioannou, Athanasios and Zhao, Guoying and Kotsia, Irene}, booktitle={Computer Vision and Pattern Recognition Workshops (CVPRW), 2017 IEEE Conference on}, pages={1980--1987}, year={2017}, organization={IEEE} } 

@misc{insightface,
  author = {Guo, Jia},
  title = {InsightFace: 2D and 3D Face Analysis Project},
  howpublished = {\url{https://github.com/deepinsight/insightface}},
  year = {Accessed on Month Day, Year}
}

@article{tian2011facial,
  title={Facial expression recognition},
  author={Tian, Yingli and Kanade, Takeo and Cohn, Jeffrey F},
  journal={Handbook of face recognition},
  pages={487--519},
  year={2011},
  publisher={Springer}
}

@article{2010Expression,
  title={Expression Recognition Methods Based on Feature Fusion},
  author={ Chang, S.  and  Deng, J.  and  Yong, Y.  and  Wang, G. },
  journal={DBLP},
  year={2010},
}

@book{2006Face,
  title={Face, expression, and iris recognition using learning-based approaches /},
  author={ Guo, G. },
  publisher={Face, Expression, and Iris Recognition Using Learning-Based Approaches},
  year={2006},
}


@article{2005Feature,
  title={Feature Selection Using Adaboost for Face Expression Recognition},
  author={ Silapachote, P.  and  Karuppiah, D. R.  and  Hanson, A. R. },
  journal={feature selection using adaboost for face expression recognition},
  year={2005},
}

@article{2004Feature,
  title={Feature Synthesis Using Genetic Programming for Face Expression Recognition},
  author={ Bhanu, B.  and  Yu, J.  and  Tan, X.  and  Lin, Y. },
  journal={DBLP},
  year={2004},
}

@inproceedings{chen2021understanding,
  title={Understanding and mitigating annotation bias in facial expression recognition},
  author={Chen, Yunliang and Joo, Jungseock},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={14980--14991},
  year={2021}
}

@inproceedings{chang2021learning,
  title={Learning facial representations from the cycle-consistency of face},
  author={Chang, Jia-Ren and Chen, Yong-Sheng and Chiu, Wei-Chen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9680--9689},
  year={2021}
}

@inproceedings{xue2021transfer,
  title={Transfer: Learning relation-aware facial expression representations with transformers},
  author={Xue, Fanglei and Wang, Qiangchang and Guo, Guodong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3601--3610},
  year={2021}
}

@inproceedings{zeng2018facial,
  title={Facial expression recognition with inconsistently annotated datasets},
  author={Zeng, Jiabei and Shan, Shiguang and Chen, Xilin},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={222--237},
  year={2018}
}

@article{wu2021rethinking,
  title={Rethinking infonce: How many negative samples do you need?},
  author={Wu, Chuhan and Wu, Fangzhao and Huang, Yongfeng},
  journal={arXiv preprint arXiv:2105.13003},
  year={2021}
}

@article{sohn2020fixmatch,
  title={Fixmatch: Simplifying semi-supervised learning with consistency and confidence},
  author={Sohn, Kihyuk and Berthelot, David and Carlini, Nicholas and Zhang, Zizhao and Zhang, Han and Raffel, Colin A and Cubuk, Ekin Dogus and Kurakin, Alexey and Li, Chun-Liang},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={596--608},
  year={2020}
}

@inproceedings{zhang2022transformer,
  title={Transformer-based multimodal information fusion for facial expression analysis},
  author={Zhang, Wei and Qiu, Feng and Wang, Suzhen and Zeng, Hao and Zhang, Zhimeng and An, Rudong and Ma, Bowen and Ding, Yu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2428--2437},
  year={2022}
}

@inproceedings{jeong2022classification,
  title={Classification of facial expression in-the-wild based on ensemble of multi-head cross attention networks},
  author={Jeong, Jae-Yeop and Hong, Yeong-Gi and Kim, Daun and Jeong, Jin-Woo and Jung, Yuchul and Kim, Sang-Ho},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2353--2358},
  year={2022}
}
@inproceedings{savchenko2022video,
  title={Video-based frame-level facial analysis of affective behavior on mobile devices using EfficientNets},
  author={Savchenko, Andrey V},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2359--2366},
  year={2022}
}

@inproceedings{xue2022coarse,
  title={Coarse-to-fine cascaded networks with smooth predicting for video facial expression recognition},
  author={Xue, Fanglei and Tan, Zichang and Zhu, Yu and Ma, Zhongsong and Guo, Guodong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2412--2418},
  year={2022}
}

@inproceedings{an2021partial,
  title={Partial fc: Training 10 million identities on a single machine},
  author={An, Xiang and Zhu, Xuhan and Gao, Yuan and Xiao, Yang and Zhao, Yongle and Feng, Ziyong and Wu, Lan and Qin, Bin and Zhang, Ming and Zhang, Debing and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1445--1449},
  year={2021}
}
@article{kollias2018aff,
  title={Aff-wild2: Extending the aff-wild database for affect recognition},
  author={Kollias, Dimitrios and Zafeiriou, Stefanos},
  journal={arXiv preprint arXiv:1811.07770},
  year={2018}
}

@inproceedings{cubuk2020randaugment,
  title={Randaugment: Practical automated data augmentation with a reduced search space},
  author={Cubuk, Ekin D and Zoph, Barret and Shlens, Jonathon and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops},
  pages={702--703},
  year={2020}
}
@article{zhang2018facial,
  title={From facial expression recognition to interpersonal relation prediction},
  author={Zhang, Zhanpeng and Luo, Ping and Loy, Chen Change and Tang, Xiaoou},
  journal={International Journal of Computer Vision},
  volume={126},
  pages={550--569},
  year={2018},
  publisher={Springer}
}

@inproceedings{guo2016ms,
  title={Ms-celeb-1m: A dataset and benchmark for large-scale face recognition},
  author={Guo, Yandong and Zhang, Lei and Hu, Yuxiao and He, Xiaodong and Gao, Jianfeng},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part III 14},
  pages={87--102},
  year={2016},
  organization={Springer}
}

@inproceedings{deng2019arcface,
  title={Arcface: Additive angular margin loss for deep face recognition},
  author={Deng, Jiankang and Guo, Jia and Xue, Niannan and Zafeiriou, Stefanos},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4690--4699},
  year={2019}
}

@inproceedings{huang2008labeled,
  title={Labeled faces in the wild: A database forstudying face recognition in unconstrained environments},
  author={Huang, Gary B and Mattar, Marwan and Berg, Tamara and Learned-Miller, Eric},
  booktitle={Workshop on faces in'Real-Life'Images: detection, alignment, and recognition},
  year={2008}
}

@inproceedings{tan2019efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International conference on machine learning},
  pages={6105--6114},
  year={2019},
  organization={PMLR}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{lee2013pseudo,
  title={Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks},
  author={Lee, Dong-Hyun and others},
  booktitle={Workshop on challenges in representation learning, ICML},
  pages={896},
  year={2013}
}


@inproceedings{xie2020self,
  title={Self-training with noisy student improves imagenet classification},
  author={Xie, Qizhe and Luong, Minh-Thang and Hovy, Eduard and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10687--10698},
  year={2020}
}

@article{bachman2014learning,
  title={Learning with pseudo-ensembles},
  author={Bachman, Philip and Alsharif, Ouais and Precup, Doina},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{laine2016temporal,
  title={Temporal ensembling for semi-supervised learning},
  author={Laine, Samuli and Aila, Timo},
  journal={arXiv preprint arXiv:1610.02242},
  year={2016}
}

@article{sajjadi2016regularization,
  title={Regularization with stochastic transformations and perturbations for deep semi-supervised learning},
  author={Sajjadi, Mehdi and Javanmardi, Mehran and Tasdizen, Tolga},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}
@article{chen2012cross,
  title={Cross-entropy measure of uncertain variables},
  author={Chen, Xiaowei and Kar, Samarjit and Ralescu, Dan A},
  journal={Information Sciences},
  volume={201},
  pages={53--60},
  year={2012},
  publisher={Elsevier}
}

@article{zhang2018generalized,
  title={Generalized cross entropy loss for training deep neural networks with noisy labels},
  author={Zhang, Zhilu and Sabuncu, Mert},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
@article{ho2019real,
  title={The real-world-weight cross-entropy loss function: Modeling the costs of mislabeling},
  author={Ho, Yaoshiang and Wookey, Samuel},
  journal={IEEE access},
  volume={8},
  pages={4806--4813},
  year={2019},
  publisher={IEEE}
}
@article{zhang2021flexmatch,
  title={Flexmatch: Boosting semi-supervised learning with curriculum pseudo labeling},
  author={Zhang, Bowen and Wang, Yidong and Hou, Wenxin and Wu, Hao and Wang, Jindong and Okumura, Manabu and Shinozaki, Takahiro},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={18408--18419},
  year={2021}
}
@article{parkhi2015deep,
  title={Deep face recognition},
  author={Parkhi, Omkar M and Vedaldi, Andrea and Zisserman, Andrew},
  year={2015},
  publisher={British Machine Vision Association}
}