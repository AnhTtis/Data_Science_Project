\section{Proposed Method: FLANDERS}
\label{sec:method}

\subsection{Matrix Autoregressive Model (MAR)}
\label{subsec:mar}
We assume the temporal evolution of the local models sent by FL clients at each round is captured by a matrix autoregressive model (MAR). 
In its most generic form, MAR($w$) is a $w$-order autoregressive model defined as follows:
%In its most generic form, the matrix autoregressive model MAR($p$) is a $p$-order autoregressive model: %defined as follows:
\begin{equation}
\small
    \Params_t = {\bm A}_1 \Params_{t-1} {\bm B}_1 + \cdots + {\bm A}_w \Params_{t-w} {\bm B}_w + {\bm E}_t,
    \label{eq:mar-w}
\end{equation}
where $\Params_t$ is the $d\times h$ matrix of observations at time $t$, $\bm{\Omega} = \{{\bm A}_i, {\bm B}_i\}_{i=1}^w$ are $d\times d$ and $h\times h$ autoregressive coefficient matrices, and ${\bm E}_t$ is a $d\times h$ white noise matrix.
In this work, we consider the simplest MAR($1$)\footnote{Unless otherwise specified, whenever we refer to MAR, we assume MAR($1$).} Markovian forecasting model, i.e., ${\Params}_t = {\bm A} {\Params}_{t-1} {\bm B} + {\bm E}_t$, where the matrix of local updates at time $t$ depends only on the matrix observed at time step $t-1$, namely $w=1$.
%\\
%There are different ways of interpreting the parameters of this model, i.e., the coefficient matrices ${\bm A}$ and ${\bm B}$.
%Roughly speaking, the left matrix ${\bm A}$ reflects row-wise interactions (e.g., interactions among weather stations), and the right matrix ${\bm B}$ captures column-wise dependencies (e.g., relationships between atmospheric measurements).

Let $\widetilde{\Params}_t \approx \Params_t$ be the {\em predicted} matrix of observations at time $t$, according to a model $f$ parameterized by $\widetilde{\bm{\Omega}} = \{\widetilde{{\bm A}},\widetilde{{\bm B}}\}$, i.e., $\widetilde{\Params}_t = f(\Params_{t-1};\widetilde{\bm{\Omega}}) = \widetilde{{\bm A}} \Params_{t-1}\widetilde{{\bm B}}$.
If we have access to $l > 0$ historical observations, we can estimate the best coefficients ${\hat{\bm \Omega}} = \{\hat{{\bm A}}, \hat{{\bm B}}\}$ by solving the following objective: 
\begin{equation}
\small
    {\hat{\bm \Omega}} = \hat{{\bm A}}, \hat{{\bm B}} = \argmin_{\widetilde{{\bm A}}, \widetilde{{\bm B}}}
    %\Big\{\sum_{j=0}^{p-1} ||{\Params}_{t-j} - {\widetilde{\Params}}_{t-j}||^2_{\text F} \Big\} = \argmin_{\widetilde{{\bm A}}, \widetilde{{\bm B}}}
    \Big\{\sum_{j=0}^{l-1} ||{\Params}_{t-j} - \widetilde{{\bm A}}{\Params}_{t-j-1}\widetilde{{\bm B}}||^2_{\text F} \Big\},
    \label{eq:mar-opt}
\end{equation}
where $||\cdot||_{\text F}$ indicates the Frobenius norm. 
Note that $l$ impacts only the size of the training set used to estimate the optimal coefficients $\hat{\bm A}$ and $\hat{\bm B}$; it does not affect the order of the autoregressive model, which will remain MAR($1$) and \textit{not} MAR($l$).
The optimal coefficients $\hat{\bm A}$ and $\hat{\bm B}$ can thus be estimated via alternating least squares (ALS) optimization~\cite{koren2009ieeecomp}.
Further details are provided in Appendix~\ref{app:mar}.

\subsection{MAR-based Anomaly Score}
\label{subsec:mar-anomaly-score}
Our approach consists of two primary steps: $(i)$ \textit{MAR estimation} and $(ii)$ \textit{anomaly score computation}. %, detailed below.
\\
\noindent{{\bf {\em MAR Estimation.}}}
At the first FL round ($t=1$), the server sends the initial global model $\params^{(1)}$ to the set of $m$ selected clients $\mathcal{C}^{(1)}$ and collects from them the $d\times m$ matrix of updated models $\Params_1$. Hence, it computes the \textit{new} global model $\params^{(2)} = \phi(\{\params_{c}^{(1)}~|~c\in \mathcal{C}^{(1)}\})$, where $\phi = \text{Krum}$ or any other existing robust aggregation heuristic.
For any other FL round $t > 1$, the server can use the past $l > 0$ historical observations $\Params_{t-l:t-1}$ to estimate the best MAR coefficients $\hat{\bm{\Omega}} = \{\hat{\bm{A}},\hat{\bm{B}}\}$ according to~(\ref{eq:mar-opt}). 
In general, $1\leq l\leq t-1$; however, if we assume $l$ fixed at each round, the server will consider $\Params_{\max(1,t-l):t-1}$ past observations.
Again, independently of the value of $l$, MAR will learn to predict the current matrix of weights \textit{only} from the previously observed matrix.
Therefore, each matrix used for training $\{\Params_{t-j-1}\}_{j=0}^{l-1}$ has the same size $d\times m$, as it contains exclusively the $m$ updates received at the round $t-j-1$. 
Of course, employing a higher order MAR($w$) model with $w > 1$ would require extending each observed matrix to $d\times h$ ($m < h \leq K)$, as detailed in Section~\ref{subsec:ts-models}. This is to track the local updates sent by selected clients across multiple historical rounds.
\\
\noindent{{\bf {\em Anomaly Score Computation.}}}
At the generic FL round $t > 1$, we compute the anomaly score using the estimated MAR forecasting model as follows. 
Let $\Params_{t}$ be the matrix of observed weights. 
This matrix may contain one or more corrupted local models from malicious clients.
Then, we compute the $m$-dimensional anomaly score vector ${\bm s}^{(t)}$, where ${\bm s}^{(t)}[c] = s_c^{(t)}$, as in~(\ref{eq:anomaly-score}).
A critical choice concerns the function $\delta$ used to measure the distance between the observed vector of weights sent by each selected client and the vector of weights predicted by MAR.
In this work, we set $\delta (\bm{u}, \bm{v}) = ||\bm{u} - \bm{v}||_2^2$, where $||\cdot||_2^2$ is the squared $L^2$-norm. %i.e., the squared $L^2$-norm. 
Other functions can be used (e.g., {\em cosine distance}), especially in high dimensional spaces, where $L^p$-norm with $p\in (0,1)$ has proven effective~\cite{aggarwal2001icdt}. 
Choosing the best $\delta$ is outside the scope of this work, and we leave it to future study.
%In this work, we set $\delta = ||\cdot||^2$ L^2$-norm; other functions can also be used (e.g., {\em cosine distance}).
% \begin{figure}[htb!]
%     \centering
%     \includegraphics[width=.6\columnwidth]{./img/flanders}
%     \caption{Overview of FLANDERS.}
%     \label{fig:flanders}
%     %\vspace{-4mm}
% \end{figure}
\\
According to one of the filtering strategies discussed in Section~\ref{subsec:ts-outliers}, we retain only the $k$ clients with the smallest anomaly scores. The remaining $m-k$ clients are considered malicious; thus, they 
are discarded and do not contribute to the aggregation run by the server as if they were never selected.
\\
At the next round $t+1$, we may want to refresh our estimation of the MAR model, i.e., to update the coefficient matrices $\hat{{\bm A}}$ and $\hat{{\bm B}}$.
We do so by considering the latest observed $\Params_{t}$ and the other $l-1$ previous matrices of local updates, using the same sliding window of size $l$.
Since the observed matrix $\Params_{t}$ contains $m-k$ potentially malicious clients, we cannot use it as-is. Otherwise, \textit{if any of the spotted malicious clients is selected again at round $t+1$}, we may alter the estimation of $\hat{{\bm A}}$ and $\hat{{\bm B}}$ with possibly corrupted matrix columns.
To overcome this problem, we replace the original $\Params_{t}$ with $\Params'_{t}$ {\em before}, feeding it to train the new MAR model. 
Specifically, $\Params'_{t}$ is obtained from $\Params_{t}$ by substituting the $m-k$ anomalous columns either with the parameter vectors from the same clients observed at time $t-1$, which are supposed to be still legitimate \textit{or} the current global model.
%if none are available. % removed because in the experiments we saw that the best strategy is to replace with the global model
%result of the aggregation function computed only on the $k$ columns considered legitimate.
The advantage of this solution is twofold. 
On the one hand, a client labeled as malicious at FL round $t$ would likely still be considered so at $t+1$ if it keeps perturbing its local weights, thus improving robustness.
On the other hand, our solution allows malicious clients to alternate legitimate behaviors without being banned, speeding up model convergence.
Notice that the two considerations above might not be valid if we updated the MAR model using the original, partially corrupted $\Params_{t}$. 
Indeed, in the first case, the 
%squared $L^2$-norm 
distance between two successive poisoned models by the same client would reasonably be small. So, the client's anomaly score will likely drop to non-alarming values, thereby increasing the number of false negatives.
In the second case, the 
%squared $L^2$-norm 
distance between a corrupted and a legitimate model would likely be large. 
Thus, a malicious client will maintain its anomaly score high even if it acts honestly, impacting the number of false positives.
%\\
%A comprehensive overview of how FLANDERS works along with its pseudocode is in Appendix~\ref{app:flanders}.

\subsection{A Step-by-Step Example}
\label{subsec:example}
% In Fig.~\ref{fig:tensor}, we show how local model updates collected by the server from each selected client at every FL round can be organized into a tensor, spanning over a time window $T$.
% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=.8\textwidth]{./img/tensor}
%     \caption{The $d$-dimensional vector of parameters $\params_c^{(t)}$ sent by client $c$ at round $t$ (left). The $d\times m$ matrix $\Params_t$ of {\em all} the $m$ client updates sent at round $t$ (middle). The $d\times m\times T$ tensor $\Params_{1:T}$ of all the client updates after $T$ rounds (right).}
%     \label{fig:tensor}
% \end{figure}
In Figure~\ref{fig:flanders}, we depict how FLANDERS computes the anomaly score vector $\bm{s}^{(t)}$ at the generic FL round $t$. Specifically, the server $S$ uses its current MAR($1$) forecasting model $f$ whose best parameters $\hat{\bm{\Omega}} = \{\hat{\bm A}, \hat{\bm B}\}$ are estimated from $l$ previous historical observations of local models received in the previous rounds $t-l,\ldots, t-1$. It applies $f$ to the previously observed matrix $\bm{\Params}_{t-1}$ to get the next predicted matrix of local models $\bm{\hat{\Params}}_{t}$, i.e., $\bm{\hat{\Params}}_{t} = f(\bm{\Params}_{t-1};\hat{\bm{\Omega}}) = \hat{\bm A}\bm{\Params}_{t-1} \hat{\bm B}$. Then, it compares this predicted matrix $\bm{\hat{\Params}}_{t}$ with the actual matrix of local updates received $\bm{\Params}_{t}$. 
The final anomaly score vector is calculated by measuring the distance $\delta$ between each column of those two matrices, according to Eq.~\ref{eq:anomaly-score}.

It is worth remarking that, in general, only some clients are selected at every round. In particular, if a client $c_{\text{new}}$ -- whether it is honest or malicious -- is selected by the server for the first time at round $t$, the MAR forecasting model $f$ will not be able to make any prediction for it due to a cold start problem (i.e., the predicted matrix $\bm{\hat{\Params}}_{t}$ will not contain a column corresponding to $c_{\text{new}}$). 
In such a case, we must adopt a fallback strategy. Without any historical information for a client, the most sensible thing to do is to compute the distance $\delta$ between the local model update it sent and the current global model.
\begin{figure}[htb!]
    \centering
    \includegraphics[width=\columnwidth]{./img/flanders}
    \caption{Overview of FLANDERS.}
    \label{fig:flanders}
\end{figure}

%\begin{algorithm}
%\caption{FillEmptyValues}\label{alg:empty-values}
%\begin{algorithmic}[1]
%    \Require Tensor $\Theta = \{\theta_1..\theta_c\}$; selected clients $C_t$; number of historical observations $w$; round number $t$.
%    \Ensure $\Theta_{t}$
%    
%    \ForAll{$c \in C_t$} \Comment{Look up in the history of $c$}
%        \If{$\theta^{c}_{t-1} \neq \bot$}
%            \State $\theta^{t}_c \gets \theta^{t-1}_c$
%        \ElsIf{$\theta^{t-j}_c \neq \bot$ where $j \in \{1..w\}$}
%            \State $\theta^{t}_c \gets \params^{t-j}_c$ %\Comment{It can either be the global model or the last update of client $c$}
%        \EndIf
%    \If{$\theta^{t}_c = \bot$} \Comment{Cold start for $c$}
%        \State $\theta_c \gets \theta^{t-1}$ \Comment{Assign the current global model}
%    \EndIf
%    \EndFor
%    \State $\Theta^t \gets \{\theta^{t}_1..\theta^{t}_c\}$
%    \State \textbf{return} $\Theta^t$
%\end{algorithmic}
%\end{algorithm}

To better clarify how FLANDERS works, consider the following practical example.
\\
Suppose an FL system consists of a centralized server and $10$ clients $c_1,\ldots, c_{10}$; furthermore, at each round, $4$ of those clients are randomly chosen for training. 
At the very first round ($t=1$), let $\mathcal{C}^{(1)} = \{c_2, c_3, c_7, c_9\}$ be the set of $4$ clients selected by the server. Hence, the server sends the current global model $\params^{(1)} \in \R^d$ to each of those clients and collects the $d\times 4$ matrix of updated local models $\Params_1 = [\params_2^{(1)}, \params_3^{(1)}, \params_7^{(1)}, \params_9^{(1)}]$. 
Therefore, it computes the \textit{new} global model $\params^{(2)} = \phi(\{\params_{c}^{(1)}~|~c\in \mathcal{C}^{(1)}\})$.
Notice that, at this stage, no anomaly score can be computed as FLANDERS cannot take advantage of any historical observations of local model updates. As such, if one (or more) selected clients in the very first round are malicious, plain FedAvg may not detect those. To overcome this problem, FLANDERS should be paired with one of the existing robust aggregation heuristics at $t=1$. For example, $\phi = \{\text{Trimmed Mean, Krum, Bulyan}\}$.

At the next round ($t=2$), FLANDERS can start using past observations (i.e., only $\Params_1$) to estimate the best MAR coefficients $\hat{\bm{\Omega}} = \{\hat{\bm{A}},\hat{\bm{B}}\}$ according to Eq.~(\ref{eq:app-mar-opt}) above. 
Suppose $\mathcal{C}^{(2)} = \{c_1, c_3, c_6, c_9\}$ is the set of $4$ clients selected by the server at the second round.
Let $\Params_2 = [\params_1^{(2)}, \params_3^{(2)}, \params_6^{(2)}, \params_9^{(2)}]$ be the local models sent by the clients to the server.
Moreover, $\hat{\Params}_2 = f(\Params_1;\hat{\bm{\Omega}}) = [\hat{\params}_2^{(2)}, \hat{\params}_3^{(2)}, \hat{\params}_7^{(2)}, \hat{\params}_9^{(2)}]$ are the local models predicted by MAR, using the previous set of observations. 

It is worth noting that $\mathcal{C}^{(1)} \cap \mathcal{C}^{(2)} = \{c_3, c_9\}$; the other two clients, $c_1$ and $c_6$, are considered ``cold-start'' since they are selected for the first time or, in any case, they do not appear in the historical observations used by MAR for predictions (i.e., in the previous $w=1$ matrices).
Thus, we calculate the following anomaly scores, according to Eq.~\ref{eq:mar-w}:
\begin{itemize}
\item $s_3^{(2)} = \delta(\params_3^{(2)}, \hat{\params}_3^{(2)})$ and $s_9^{(2)} = \delta(\params_9^{(2)}, \hat{\params}_9^{(2)})$, i.e., we measure the distance between the models actually sent by $c_3$ and $c_9$ and those predicted by MAR using the previous observations (\textit{first condition});
\item $s_1^{(2)} = \delta(\params^{(2)}, \params_1^{(2)})$ and $s_6^{(2)} = \delta(\params^{(2)}, \params_6^{(2)})$, i.e., we measure the distance between the models actually sent by $c_1$ and $c_6$ and the current global model at time $t=2$, as those clients were never picked before (\textit{second condition});
\item $s_2^{(2)} = s_4^{(2)} = s_5^{(2)} = s_7^{(2)} = s_8^{(2)} = s_{10}^{(2)} = \perp$, i.e., these clients were not selected at round $t=2$, and therefore they will not contribute to computing the new global model $\params^{(3)}$ anyway (\textit{third condition}).
\end{itemize}
Let us assume that $c_3$ is a malicious client controlled by an attacker. Moreover, suppose that this client started sending poisoned models since the very first round, i.e., $\params_3^{(1)}$ was already corrupted. 
In such a case, it is evident that if we had used plain FedAvg at $t=1$, this would have likely polluted the global model $\params^{(2)}$ and, therefore, FLANDERS might fail to recognize this as a malicious client due to a relatively low anomaly score $s_3^{(2)}$. As stated before, the consequences of this edge situation in which one or more malicious clients are picked at the beginning of the FL training can be mitigated by replacing FedAvg with one of the robust aggregation strategies available in the literature, such as Trimmed Mean, Krum, or Bulyan. 

However, suppose $c_3$ is correctly spotted as malicious at the end of round $t=2$ due to its high anomaly score $s_3^{(2)}$. Therefore, $c_3$ (actually, $\params_3^{(2)}$) will be discarded from the aggregation at the server's end. Hence, FedAvg can now safely be used; more generally, the server can restart running FedAvg from $t=2$ on, i.e., once FLANDERS can compute \textit{valid} anomaly scores.
The server can now compute the updated global model as $\params^{(3)} = \phi(\{\params_{c}^{(2)}~|~c\in \mathcal{C}_*^{(2)}\})$, where $\mathcal{C}_*^{(2)} \subset \mathcal{C}^{(2)}$ contains the clients with the $k$ smallest anomaly scores. 
For instance, if $k=2$ and $\mathcal{C}_*^{(2)} = \{c_1, c_9\}$, $\params^{(3)} = 1/2 * (\params_1^{(2)} + \params_9^{(2)})$.

At the next round ($t=3$), FLANDERS can use the previous two observations $\Params_1$ and $\Params_2$ to refine the estimation of the best MAR coefficients, again solving Eq.~(\ref{eq:app-mar-opt}).\footnote{In general, FLANDERS uses $l$ past observations $\Params_{\text{max}(1,t-l):t-1}$.} 
However, $\Params_2$ cannot be fed as-is to re-train MAR since one of its components -- i.e., the local model $\params_3^{(2)}$ sent by client $c_3$ -- has been flagged as malicious. 
Otherwise, the resulting updated MAR coefficients could be unreliable due to the propagation of local poisoned models.

To overcome this problem, FLANDERS replaces the local model marked as suspicious $\params_3^{(2)}$ with either one of the previously observed models from the same client that is supposedly legitimate \textit{or} the current global model. 
Since, in this example, we assume $c_3$ has been malicious from the first round, we use the latter approach. 
Specifically, we change $\Params_2$ with $\Params'_2 = [\params_1^{(2)}, \underline{\params_{}^{(2)}}, \params_6^{(2)}, \params_9^{(2)}]$, where $\params^{(2)}$ substitutes $\params_3^{(2)}$.
As discussed at the end of Section~\ref{subsec:mar-anomaly-score}, this fix allows FLANDERS to work even when a malicious client is picked for two or more rounds consecutively.

We can now compute $\hat{\Params}_3 = f(\Params'_2;\hat{\bm{\Omega}}) = [\hat{\params}_1^{(3)}, \hat{\params}_3^{(3)}, \hat{\params}_6^{(3)}, \hat{\params}_9^{(3)}]$ using the updated MAR, leveraging the previous set of amended observations. 
Let $\mathcal{C}^{(3)} = \{c_2, c_3, c_4, c_5\}$ denote the set of clients selected at round $3$ and $\Params_3 = [\params_2^{(3)}, \params_3^{(3)}, \params_4^{(3)}, \params_5^{(3)}]$ be the local models sent by the clients to the server. 
Thus, $\mathcal{C}^{(2)} \cap \mathcal{C}^{(3)} = \{c_3\}$. The remaining three clients -- $c_2$, $c_4$, and $c_5$ -- are treated as ``cold-start.'' Specifically, $c_4$ and $c_5$ are selected for the first time, while $c_2$, even though previously selected in the first round, was not chosen at the previous round ($2$). As $c_2$ was not part of the historical observations used by MAR($1$) to make predictions, we need to treat it as if it were a cold-start client.

Therefore, anomaly scores are updated as follows:
\begin{itemize}
\item $s_3^{(3)} = \delta(\params_3^{(3)}, \hat{\params}_3^{(3)})$, i.e., we measure the distance between the models actually sent by $c_3$ and those predicted by MAR using the previous observations (\textit{first condition});
\item $s_2^{(3)} = \delta(\params^{(3)}, \params_2^{(3)})$, $s_4^{(3)} = \delta(\params^{(3)}, \params_4^{(3)})$, and $s_5^{(3)} = \delta(\params^{(3)}, \params_5^{(3)})$ i.e., we measure the distance between the models actually sent by $c_2$, $c_4$, and $c_5$ and the current global model at time $t=3$, as those clients were never picked before or did not appear in the previous observations used to make predictions (\textit{second condition});
\item $s_1^{(3)} = s_6^{(3)} = s_7^{(3)} = s_8^{(3)} = s_9^{(3)} = s_{10}^{(3)} = \perp$, i.e., these clients were not selected at round $t=3$, and therefore they will not contribute to computing the new global model $\params^{(4)}$ anyway (\textit{third condition}).
\end{itemize}
Generally, the process above continues until the global model converges.


\subsection{FLANDERS' Pseudocode}
\label{subsec:pseudocode}
We present the pseudocode of a hypothetical FL server that integrates FLANDERS into the model aggregation stage. 
The main server-side loop is shown in Algorithm~\ref{alg:server}, whereas Algorithm~\ref{alg:flanders} details the computation of anomaly scores, which is at the heart of the FLANDERS filter.

\begin{algorithm}
    \caption{\texttt{\textsc{FLANDERS-Server}}}\label{alg:server}
    \begin{algorithmic}[1]
        \Require The aggregation function ($\phi$); the number of randomly selected clients at each FL round ($m$); the number of local models to keep as legitimate ($k$); the autoregressive order of MAR ($w$); the number of historical observations used to train MAR ($l$); the number of MAR training iterations ($N$); the number of total FL rounds ($T$).
        \Ensure The global model $\bm{\theta}^{(T)}$.%
        \Procedure{\texttt{FLANDERS-Server}}{$\phi$, $m$, $k$, $w$, $l$, $N$, $T$}
            \State $\bm{\theta}^{(1)} \gets $ A randomly initialized model
            
            \ForAll {$t \in \{1,2,\ldots T\}$}
                \State $\mathcal{C}^{(t)} \gets $ sample a subset of $m$ clients from $\mathcal{C}$
                \State Send the global model $\bm{\theta}^{(t)}$ to every  $c\in \mathcal{C}^{(t)}$
                \State $\bm{\Theta}_t \gets [\bm{\theta}^{(t)}_1, \ldots, \bm{\theta}^{(t)}_m]$ \Comment{Receive the $m$ local models trained by each $c\in \mathcal{C}^{(t)}$}
                \If{$t==1$}
                    \LComment{At the very first round, use the designated fallback aggregation strategy (e.g., FedAvg)}
                    \State $\mathcal{C}^{(t)}_* \gets \texttt{\textsc{Fallback}}(\bm{\Theta}_{t})$
                \Else
                    \LComment{Returns the set of clients classified as legitimate}
                    \State $\mathcal{C}^{(t)}_* \gets \texttt{\textsc{FLANDERS}}(\bm{\Theta}_{t-l:t-1}, \mathcal{C}^{(t)}, k, w, N)$
                \EndIf
                \State $\params^{(t+1)} \gets \phi(\{\params_c^{(t)}~|~c\in \mathcal{C}_*^{(t)}\})$
            \EndFor
        \EndProcedure
    \end{algorithmic}%
\end{algorithm}%

\begin{algorithm}
    \caption{\texttt{\textsc{FLANDERS-Filter}}}\label{alg:flanders}
    \begin{algorithmic}[1]
        \Require The tensor containing the local models of selected clients observed from $l$ past FL rounds ($\bm{\Theta}_{t-l:t-1}$); the clients selected at round $t$ ($\mathcal{C}^{(t)}$); the autoregressive order of MAR ($w$); the number of local models to keep as legitimate ($k$); the number of MAR training iterations ($N$).
        \Ensure The set of $k$ clients classified as legitimate in round $t$ $\mathcal{C}^{(t)}_{*}$.
        \Procedure{\texttt{FLANDERS}}{$\bm{\Theta}_{t-l:t-1}, \mathcal{C}^{(t)}, k, w, N$}
            \LComment{MAR($w$) estimation via ALS training ($N$ iterations)}
            \State $\hat{\bm{\Theta}}_{t} \gets \texttt{MAR}(\bm{\Theta}_{t-l:t-1}, w, N)$
            \State $\bm{s}^{(t)} \gets \delta(\bm{\Theta}_t, \hat{\bm{\Theta}}_t)$ \Comment{Anomaly score vector}
            \State $\mathcal{C}^{(t)}_{*} \gets \{c \in \mathcal{C}^{(t)}~|~s_{c}^{(t)} \leq s_k^{(t)}\}$ \Comment{$s^{(t)}_k$ is the $k$-th smallest anomaly score}
            %\State $\Theta^{*}_t \gets \{\theta^t \in \Theta_t~|~s_{c}^{t} \leq s_k^{t}\}$
            %\State $\theta^{t+1} \gets \phi(\Theta^{*}_t, |C^{t}_{*}|)$
            \State \textbf{return} $\mathcal{C}^{(t)}_{*}$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}


%% MOVED BACK IN APPENDIX
%\subsection{A Step-by-Step Example}
%\label{subsec:example}
%In Fig.~\ref{fig:flanders}, we depict how FLANDERS computes the anomaly score vector $\bm{s}^{(t)}$ at the generic FL round $t$. Specifically, the server $S$ uses its current MAR($1$) forecasting model $f$ whose best parameters $\hat{\bm{\Omega}} = \{\hat{\bm A}, \hat{\bm B}\}$ are estimated from $l$ previous historical observations of local models received in the previous rounds $t-l,\ldots, t-1$. It applies $f$ to the previously observed matrix $\bm{\Params}_{t-1}$ to get the next predicted matrix of local models $\bm{\hat{\Params}}_{t}$, i.e., $\bm{\hat{\Params}}_{t} = f(\bm{\Params}_{t-1};\hat{\bm{\Omega}}) = \hat{\bm A}\bm{\Params}_{t-1} \hat{\bm B}$. Then, it compares this predicted matrix $\bm{\hat{\Params}}_{t}$ with the actual matrix of local updates received $\bm{\Params}_{t}$. 
%The final anomaly score vector is calculated by measuring the distance $\delta$ between each column of those two matrices, according to (\ref{eq:anomaly-score}).

%It is worth remarking that, in general, only some clients are selected at every round. In particular, if a client $c_{\text{new}}$ -- whether it is honest or malicious -- is selected by the server for the first time at round $t$, the MAR forecasting model $f$ will not be able to make any prediction for it due to a cold start problem (i.e., the predicted matrix $\bm{\hat{\Params}}_{t}$ will not contain a column corresponding to $c_{\text{new}}$). 
%In such a case, as already stated, we must adopt a fallback strategy. Without any historical information for a client, the most sensible thing to do is to compute the distance $\delta$ between the local model update it sent and the current global model.
%\begin{wrapfigure}{R}{0.5\textwidth}
%    \centering
%    \includegraphics[width=0.5\textwidth]{./img/flanders}
%    \caption{Overview of FLANDERS.}
%    \label{fig:flanders}
%\end{wrapfigure}
%
%To better clarify how FLANDERS works, consider the following practical example.
%
%Suppose an FL system consists of a centralized server and $10$ clients $c_1,\ldots, c_{10}$; furthermore, at each round, $4$ of those clients are randomly chosen for training. 
%At the very first round ($t=1$), let $\mathcal{C}^{(1)} = \{c_2, c_3, c_7, c_9\}$ be the set of $4$ clients selected by the server. Hence, the server sends the current global model $\params^{(1)} \in \R^d$ to each of those clients and collects the $d\times 4$ matrix of updated local models $\Params_1 = [\params_2^{(1)}, \params_3^{(1)}, \params_7^{(1)}, \params_9^{(1)}]$. 
%Therefore, it computes the \textit{new} global model $\params^{(2)} = \phi(\{\params_{c}^{(1)}~|~c\in \mathcal{C}^{(1)}\})$.
%Notice that, at this stage, no anomaly score can be computed as FLANDERS cannot take advantage of any historical observations of local model updates. As such, if one (or more) selected clients in the very first round are malicious, plain FedAvg may not detect those. To overcome this problem, FLANDERS should be paired with one of the existing robust aggregation heuristics at $t=1$. For example, $\phi = \{\text{Trimmed Mean, Krum, Bulyan}\}$.
%
%At the next round ($t=2$), FLANDERS can start using past observations (i.e., only $\Params_1$) to estimate the best MAR coefficients $\hat{\bm{\Omega}} = \{\hat{\bm{A}},\hat{\bm{B}}\}$ according to (\ref{eq:mar-opt}) above. 
%Suppose $\mathcal{C}^{(2)} = \{c_1, c_3, c_6, c_9\}$ is the set of $4$ clients selected by the server at the second round.
%Let $\Params_2 = [\params_1^{(2)}, \params_3^{(2)}, \params_6^{(2)}, \params_9^{(2)}]$ be the local models sent by the clients to the server.
%Moreover, $\hat{\Params}_2 = f(\Params_1;\hat{\bm{\Omega}}) = [\hat{\params}_2^{(2)}, \hat{\params}_3^{(2)}, \hat{\params}_7^{(2)}, \hat{\params}_9^{(2)}]$ are the local models predicted by MAR, using the previous set of observations. 
%
%Note that $\mathcal{C}^{(1)} \cap \mathcal{C}^{(2)} = \{c_3, c_9\}$; the other two clients, $c_1$ and $c_6$, are considered ``cold-start'' since they are selected for the first time or, in any case, they do not appear in the historical observations used by MAR for predictions (i.e., in the previous $w=1$ matrices).
%Thus, we calculate the following anomaly scores using (\ref{eq:anomaly-score}):
%\begin{itemize}
%\item $s_3^{(2)} = \delta(\params_3^{(2)}, \hat{\params}_3^{(2)})$ and $s_9^{(2)} = \delta(\params_9^{(2)}, \hat{\params}_9^{(2)})$, i.e., we measure the distance between the models actually sent by $c_3$ and $c_9$ and those predicted by MAR using the previous observations (\textit{first condition});
%\item $s_1^{(2)} = \delta(\params^{(2)}, \params_1^{(2)})$ and $s_6^{(2)} = \delta(\params^{(2)}, \params_6^{(2)})$, i.e., we measure the distance between the models actually sent by $c_1$ and $c_6$ and the current global model at time $t=2$, as those clients were never picked before (\textit{second condition});
%\item $s_2^{(2)} = s_4^{(2)} = s_5^{(2)} = s_7^{(2)} = s_8^{(2)} = s_{10}^{(2)} = \perp$, i.e., these clients were not selected at round $t=2$, and therefore they will not contribute to computing the new global model $\params^{(3)}$ anyway (\textit{third condition}).
%\end{itemize}
%
%Let us assume that $c_3$ is a malicious client controlled by an attacker. Moreover, suppose that this client started sending poisoned models since the very first round, i.e., $\params_3^{(1)}$ was already corrupted. 
%In such a case, it is evident that if we had used plain FedAvg at $t=1$, this would have likely polluted the global model $\params^{(2)}$ and, therefore, FLANDERS might fail to recognize this as a malicious client due to a relatively low anomaly score $s_3^{(2)}$. As stated before, the consequences of this edge situation in which one or more malicious clients are picked at the beginning of the FL training can be mitigated by replacing FedAvg with one of the robust aggregation strategies available in the literature. %, such as Trimmed Mean, Krum, or Bulyan. 
%However, suppose $c_3$ is correctly spotted as malicious at the end of round $t=2$ due to its high anomaly score $s_3^{(2)}$. Therefore, $c_3$ (actually, $\params_3^{(2)}$) will be discarded from the aggregation at the server's end. Hence, FedAvg can now safely be used; more generally, the server can restart running FedAvg from $t=2$ on, i.e., once FLANDERS can compute \textit{valid} anomaly scores.
%The server can now compute the updated global model as $\params^{(3)} = \phi(\{\params_{c}^{(2)}~|~c\in \mathcal{C}_*^{(2)}\})$, where $\mathcal{C}_*^{(2)} \subset \mathcal{C}^{(2)}$ contains the clients with the $k$ smallest anomaly scores. 
%For instance, if $k=2$ and $\mathcal{C}_*^{(2)} = \{c_1, c_9\}$, $\params^{(3)} = 1/2 * (\params_1^{(2)} + \params_9^{(2)})$.
%
%At the next round ($t=3$), FLANDERS can use the previous two observations $\Params_1$ and $\Params_2$ to refine the estimation of the best MAR coefficients, again solving (\ref{eq:mar-opt}).\footnote{In general, FLANDERS uses $l$ past observations $\Params_{\text{max}(1,t-l):t-1}$.} 
%However, $\Params_2$ cannot be fed as-is to re-train MAR since one of its components -- i.e., the local model $\params_3^{(2)}$ sent by client $c_3$ -- has been flagged as malicious. 
%Otherwise, the resulting updated MAR coefficients could be unreliable due to the propagation of local poisoned models.
%
%To overcome this problem, FLANDERS replaces the local model marked as suspicious $\params_3^{(2)}$ with either one of the previously observed models from the same client that is supposedly legitimate \textit{or} the current global model. 
%Since, in this example, we assume $c_3$ has been malicious from the first round, we use the latter approach. 
%Specifically, we change $\Params_2$ with $\Params'_2 = [\params_1^{(2)}, \underline{\params_{}^{(2)}}, \params_6^{(2)}, \params_9^{(2)}]$, where $\params^{(2)}$ substitutes $\params_3^{(2)}$.
%As discussed at the end of Section~\ref{subsec:mar-anomaly-score}, this fix allows FLANDERS to work even when a malicious client is picked for two or more rounds consecutively.
%
%We can now compute $\hat{\Params}_3 = f(\Params'_2;\hat{\bm{\Omega}}) = [\hat{\params}_1^{(3)}, \hat{\params}_3^{(3)}, \hat{\params}_6^{(3)}, \hat{\params}_9^{(3)}]$ using the updated MAR, leveraging the previous set of amended observations. 
%Let $\mathcal{C}^{(3)} = \{c_2, c_3, c_4, c_5\}$ denote the set of clients selected at round $3$ and $\Params_3 = [\params_2^{(3)}, \params_3^{(3)}, \params_4^{(3)}, \params_5^{(3)}]$ be the local models sent by the clients to the server. 
%Thus, $\mathcal{C}^{(2)} \cap \mathcal{C}^{(3)} = \{c_3\}$. The remaining three clients -- $c_2$, $c_4$, and $c_5$ -- are treated as ``cold-start.'' Indeed, $c_4$ and $c_5$ are selected for the first time, while $c_2$, even though selected in the first round, was not chosen at the previous round ($2$). As $c_2$ was not part of the historical observations used by MAR($1$) to make predictions, we need to treat it as if it were a cold-start client.
%Therefore, anomaly scores are updated as follows:
%\begin{itemize}
%\item $s_3^{(3)} = \delta(\params_3^{(3)}, \hat{\params}_3^{(3)})$, i.e., we measure the distance between the models actually sent by $c_3$ and those predicted by MAR using the previous observations (\textit{first condition});
%\item $s_2^{(3)} = \delta(\params^{(3)}, \params_2^{(3)})$, $s_4^{(3)} = \delta(\params^{(3)}, \params_4^{(3)})$, and $s_5^{(3)} = \delta(\params^{(3)}, \params_5^{(3)})$ i.e., we measure the distance between the models actually sent by $c_2$, $c_4$, and $c_5$ and the current global model at time $t=3$, as those clients were never picked before or did not appear in the previous observations used to make predictions (\textit{second condition});
%\item $s_1^{(3)} = s_6^{(3)} = s_7^{(3)} = s_8^{(3)} = s_9^{(3)} = s_{10}^{(3)} = \perp$, i.e., these clients were not selected at round $t=3$, and therefore they will not contribute to computing the new global model $\params^{(4)}$ anyway (\textit{third condition}).
%\end{itemize}
%The process above continues until the global model converges.

\subsection{Computational Complexity Analysis}
\label{subsec:complexity}
%The computational complexity of FLANDERS can be estimated as follows. 
To train our MAR forecasting model, we first need to run the ALS algorithm, which estimates the coefficient matrices $\hat{{\bm A}}$ and $\hat{{\bm B}}$. 
ALS iteratively performs two steps to compute $\hat{{\bm A}}$ and $\hat{{\bm B}}$, respectively. 
At the generic $i$-th iteration, computing the $i$-th $d\times d$ matrix $\hat{{\bm A}}$ costs $O(d^3) + O(dm^2)$; similarly, computing the $i$-th $m\times m$ matrix\footnote{It is worth remarking that, using MAR($1$), $h = m$ and thus $\hat{{\bm B}}$ has size $m\times m$.} $\hat{{\bm B}}$ costs $O(m^3) + O(d^2m)$.
Thus, a single iteration costs $O(d^3) + O(dm^2) + O(m^3) + O(d^2m)$, namely $O(d^3)$ \textit{or} $O(m^3)$,\footnote{$O(d^{2.376})$ \textit{or} $O(m^{2.376})$ using the Coppersmith-Winograd algorithm~\cite{coppersmith1990jsc}.} %as one of the two terms will dominate 
depending what term dominates between $d$ (the number of weights) and $m$ (the number of clients). 
ALS performs the two steps above for $N$ iterations (e.g., in this work, we set $N=100$).
Second, the computation of the anomaly score costs $O(md)$ as it measures the distance between observed and predicted local updates from all the $m$ selected clients.
Third, every time the MAR model is refreshed, we need to rerun ALS; in the worst-case scenario, we might want to re-estimate $\hat{{\bm A}}$ and $\hat{{\bm B}}$ at every single FL round.
\\
It is worth noticing that performing ALS directly on high dimensional parameter space ($d$) in standard FL settings with loads of clients ($m$) may be unfeasible (e.g., when $d$ and $m$ range from $10^6$ to $10^9$).
To keep the computational cost tractable (and limit the impact of the curse of dimensionality), in our experiments, where $d \gg m$, we reduce dimensionality via random sampling on the parameter space, as proposed by~\cite{shejwalkar2021ndss}. Specifically, we sample $\tilde{d} < d$ model parameters for ALS, with $\tilde{d}$ set to $500$.