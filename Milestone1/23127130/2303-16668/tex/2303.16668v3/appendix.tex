\section*{Appendix}
\label{sec:appendix}
The (anonymous) GitHub repository with the code and the data to replicate the results discussed in this work is accessible at the following link: \\\url{https://anonymous.4open.science/r/flanders_exp-7EEB}

%%% NOTE ON THE TERMINOLOGY
\section{A Note on the Terminology Used}
\label{app:terminology}
The type of model poisoning attacks we consider here are often referred to as \textit{Byzantine} attacks in the literature (\cite{blanchard2017nips,fang2020usenix,barroso2023if}). 
Although, in this work, we adhere to the taxonomy proposed by~\cite{barroso2023if}, the research community has yet to reach a unanimous consensus on the terminology. 
In fact, some authors use the word ``Byzantine'' as an umbrella term to broadly indicate \textit{any} attack involving malicious clients (e.g., targeted data poisoning like backdoor attacks \textit{and} untargeted model poisoning as in~\cite{hu2021arxiv}).
Therefore, to avoid confusion and hurting the feelings of some readers who have already debated on that and found the term inappropriate or disrespectful,\footnote{\small{\url{https://openreview.net/forum?id=pfuqQQCB34&noteId=5KAMwoI2cC}}} we have decided \textit{not} to use the word ``Byzantine'' to refer to our attack model.

%%% IMPACT OF MALICIOUS CLIENTS
\section{The Impact of Malicious Clients at each FL Round}
\label{app:impact}
Under our assumptions, the FL system contains $K$ clients, where $b$ of them are malicious and controlled by an attacker ($0\leq b\leq K$).
In addition, at each FL round, $m$ clients ($1 \leq m \leq K$) are selected, and thus, some of the $m$ model updates received by the central server may be corrupted.
The probability of this event can actually be computed by noticing that the outcome of the client selection at each round can be represented by a random variable $X\sim \text{Hypergeometric}(K, b, m)$, whose probability mass function is:
\[p_X(x) = \Pr(X=x) = \frac{\binom{b}{x} \binom{K-b}{m-x}}{\binom{K}{m}}.
\]
The chance that, at a single round, {\em at least one} of the $b$ malicious clients ends up in the list of $m$ clients randomly picked by the server is equal to:
\[\Pr(X\geq 1) = 1 - \Pr(X=0) = 1 - \frac{\binom{b}{0}\binom{K-b}{m-0}}{\binom{K}{m}}= 1 - \frac{ \binom{K-b}{m}}{\binom{K}{m}}.
\]
For example, if the total number of clients is $K=100$, $b=5$ of them are malicious, and $m=20$ must be drawn at each round, then $\Pr(X\geq 1) \approx 68\%$. 
In other words, there are about two out of three chances that at least one malicious client is selected at {\em every} FL round.

In our FL simulation environment, Flower, we can set a fixed proportion of malicious clients in the system (e.g., $20\%$). However, it is important to note that these clients may not remain constant across different FL rounds. In other words, a client who is selected in one round and acts legitimately could become malicious in another round of the FL process.

%%% INTUITIVE EXPLANATION OF FLANDERS
%\section{The Intuition behind FLANDERS: Predictability of Legitimate vs. Malicious Local Models}
%\label{app:legit-vs-malicious}
%
%In this section, we elaborate further on our findings discussed in Section~\ref{subsec:intuition}.
%
%We begin by considering again two clients $i,j \in \mathcal{C}$, where client $i$ is assumed to be a legitimate participant, while client $j$ acts maliciously. 
%We assume that both clients are selected by the server over a sequence of consecutive $T$ FL rounds to train a global model on the \textit{MNIST} dataset.
%Therefore, we examine the local models sent to the server at each round $t \in \{1,2,\ldots,T\}$ by clients $i$ and $j$.  
%Specifically, these are $d$-dimensional vectors of real-valued parameters $\params_i^{(t)}, \params_j^{(t)} \in \R^d$, such that $\params_i^{(t)} = (\theta_{i,1}^{(t)}, \ldots, \theta_{i,d}^{(t)})$ and $\params_j^{(t)} = (\theta_{j,1}^{(t)}, \ldots, \theta_{j,d}^{(t)})$, respectively.
%
%To mimic the behavior of a hypothetical optimal FLANDERS filter, and therefore avoid the propagation of poisoned local models sent by client $j$ across the $T$ rounds, we assume that, at each round $t$, the global model from which both clients start their local training process is polished from any malicious updates received at the previous round $t-1$.
%Next, we calculate the average time-delayed mutual information (TDMI) for each pair of observed local models $(\params_i^{(t)}, \params_i^{(t')})$ and $(\params_j^{(t)}, \params_j^{(t')})$ across $T=50$ rounds, where $t' > t$, for both client $i$ and $j$.
%
%Firstly, we consider the special case where $t'=t+1$ and compute the average TDMI between each pair of \textit{consecutive} local models sent by the legitimate client and the malicious client, when this runs one of the four attacks considered in this work, namely GAUSS, LIE, OPT, and AGR-MM. 
%In Figure~\ref{fig:avg-tdmi-density}, we plot the empirical distributions of the observed average TDMI for the legitimate and malicious clients. 
%\begin{figure*}[ht!]
%    \centering
%    \includegraphics[width=.6\textwidth]{./img/tdmi-density}
%    \caption{Empirical distributions of average TDMI computed between each pair of \textit{consecutive} local models sent by the legitimate client $i$ $(\params_i^{(t)}, \params_i^{(t+1)})$ and the malicious client $j$ $(\params_j^{(t)}, \params_j^{(t+1)})$, when this runs one of the four attacks considered in this work, namely GAUSS, LIE, OPT, and AGR-MM.}
%    \label{fig:avg-tdmi-density}
%\end{figure*}
%
%To validate our claim that legitimate models are more predictable than malicious ones, we compute the mean of the empirical distributions for the legitimate and malicious client, $\bar{\params_i}$ and $\bar{\params_j}^{atk}$, respectively, where $atk=\{$GAUSS, LIE, OPT, AGR-MM$\}$. Then, we run a one-tailed $t$-test against the null hypothesis $H_0: \bar{\params_i} = \bar{\params_j}^{atk}$, where the alternative hypothesis is $H_a: \bar{\params_i} > \bar{\params_j}^{atk}$. 
%The results of these statistical tests are illustrated in Table~\ref{tab:t-test}, showing that, in all four cases, there is enough evidence to reject the null hypothesis at a confidence level $\alpha=0.01$.
%
%\begin{table*}[htb!]
%\centering
%\caption{One-tailed $t$-test against the null hypothesis $H_0: \bar{\boldsymbol{\theta}_i} = \bar{\boldsymbol{\theta}_j}^{atk}$. Each cell contains the $p$-value for the statistical test corresponding to a specific attack. In all four cases, there is enough evidence to reject the null hypothesis at a confidence level $\alpha=0.01$ ($p$-value $\ll 0.01$).}
%\label{tab:t-test}
%\begin{tabular}{c|c|c|c|c|}
%\cline{2-5}
%& \multicolumn{4}{c|}{$atk$}\\
%\cline{2-5}
%& GAUSS & LIE & OPT & AGR-MM \\
%\hline
%\multicolumn{1}{|c|}{$H_0: \bar{\boldsymbol{\theta}_i} = \bar{\boldsymbol{\theta}_j}^{atk}$} & $5.67*10^{-38}$ & $8.33*10^{-5}$ & $6.70*10^{-18}$ & $4.20*10^{-12}$\\
%\hline
%\end{tabular}
%\end{table*}

% Furthermore, we build two upper triangular matrices $\bm{I}\in \R^{T\times T}$ and $\bm{J}\in \R^{T\times T}$ associated with client $i$ and $j$, respectively, and defined as follows:
% \begin{equation}
% \label{eq:matrix-I}
% \bm{I}[t,t'] =
% \begin{cases}
% \text{TDMI}(\params_i^{(t)}, \params_i^{(t')}),\text{ if }t' > t\\
% 1, \text{ if }t = t'\\
% \perp, \text{ otherwise }.
% \end{cases}
% \hfill
% \bm{J}[t,t'] =
% \begin{cases}
% \text{TDMI}(\params_j^{(t)}, \params_j^{(t')}),\text{ if }t' > t\\
% 1, \text{ if }t = t'\\
% \perp, \text{ otherwise }.
% \end{cases}
% \end{equation}
% In Fig.~\ref{fig:tdmi-matrices}, we report the heatmap corresponding to the matrix $\bm{I}$ built from the models sent by the legitimate client $i$, and four matrices $\bm{J}$ generated by a malicious client $j$ employing the same four attacks mentioned above, i.e., GAUSS, LIE, OPT, and AGR-MM.
% We can note the following observations. Firstly, the matrix $\bm{I}$ corresponding to the legitimate client $i$ generally shows a higher average TDMI at every time lag ($t'$), as indicated by the lighter yellow-green color. Secondly, as expected, the average TDMI tends to be higher for smaller time lags, i.e., between consecutive ($t' = t+1$) or closely spaced rounds.
% \begin{figure}
% \begin{subfigure}{\linewidth}
% \centering
% \includegraphics[width=0.33\textwidth,trim=4 4 4 4,clip]{./img/tdmi-matrix-legitimate.png}
% \caption{Average TDMI (legitimate client $i$)}
% \label{fig:tdmi-legit}
% \end{subfigure}
% \begin{subfigure}{.5\linewidth}
% \centering
% \includegraphics[width=0.66\textwidth,trim=4 4 4 4,clip]{./img/tdmi-matrix-gauss.png}
% \caption{Average TDMI (malicious client $j$, GAUSS attack)}
% \label{fig:tdmi-gauss}
% \end{subfigure}%
% \begin{subfigure}{.5\linewidth}
% \centering
% \includegraphics[width=0.66\textwidth,trim=4 4 4 4,clip]{./img/tdmi-matrix-lie.png}
% \caption{Average TDMI (malicious client $j$, LIE attack)}
% \label{fig:tdmi-lie}
% \end{subfigure}
% \begin{subfigure}{.5\linewidth}
% \centering
% \includegraphics[width=0.66\textwidth,trim=4 4 4 4,clip]{./img/tdmi-matrix-opt.png}
% \caption{Average TDMI (malicious client $j$, OPT attack)}
% \label{fig:tdmi-opt}
% \end{subfigure}%
% \begin{subfigure}{.5\linewidth}
% \centering
% \includegraphics[width=0.66\textwidth,trim=4 4 4 4,clip]{./img/tdmi-matrix-agr-mm.png}
% \caption{Average TDMI (malicious client $j$, AGR-MM attack)}
% \label{fig:tdmi-lie}
% \end{subfigure}\\[1ex]
% \caption{Heatmaps of Average TDMI derived from legitimate matrix $\bm{I}$ and four malicious matrices $\bm{J}$, one for each attack.}
% \label{fig:tdmi-matrices}
% \end{figure}

%%% MAR
\section{Matrix Autoregressive Model (MAR)}
\label{app:mar}
This work assumes the temporal evolution of the local models sent by clients at each FL round exhibits a bilinear structure captured by a \textit{matrix autoregressive model} of order $1$, i.e., a Markovian forecasting model denoted by MAR($1$) and defined as follows:
\[
{\bm \Params}_{t} = {\bm A}{\bm \Params}_{t-1}{\bm B} + {\bm E}_t,
\]
where ${\bm E}_t$ is a white noise matrix, i.e., its entries are iid normal with zero-mean and constant variance.
To approximate such a behavior, we consider a parametric forecasting model $f$, in the form:
\[
\widetilde{\bm{\Params}}_t = f(\Params_{t-1};\bm{\widetilde{\Omega}}) = \widetilde{{\bm A}} {\bm{\Params}}_{t-1}\widetilde{{\bm B}}\approx {\bm \Params}_{t},
\]
where $\widetilde{\bm{\Params}}_t$ is the {\em predicted} matrix of observations at time $t$ according to $f$ when parametrized by coefficient matrices $\bm{\widetilde{\Omega}} = \{\widetilde{{\bm A}},\widetilde{{\bm B}}\}$.
Thus, the key question is how to estimate the best model $f$, namely the best coefficient matrices $\hat{{\bm\Omega}} = \{\hat{{\bm A}},\hat{{\bm B}}\}$.
For starters, we define an instance-level loss function that measures the cost of approximating the true (yet unknown) data generation process with our model $f$ as follows:
\begin{equation}
%\small
\begin{split}
\loss(\bm{\widetilde{\Omega}};{\bm \Params}_{t}) & = ||{\bm \Params}_{t} - \widetilde{{\bm \Params}}_{t}||^2_{\text F} \\
& = ||{\bm \Params}_{t} - f(\Params_{t-1};\bm{\widetilde{\Omega}})||^2_{\text F} \\
& = ||{\bm \Params}_{t} - \widetilde{{\bm A}}{\bm \Params}_{t-1}\widetilde{{\bm B}}||^2_{\text F} \\
& = \loss(\widetilde{{\bm A}},\widetilde{{\bm B}}; {\bm \Params}_{t}),
\end{split}
\label{eq:app-inst-loss}
\end{equation}
where $||\cdot||_{\text F}$ indicates the Frobenius norm of a matrix.
More generally, if we have access to $l > 0$ historical matrix observations, we can compute the overall loss function below:
\begin{equation}
\Loss(\widetilde{{\bm A}},\widetilde{{\bm B}}; {\bm \Params}_{t},l) = \sum_{j=0}^{l-1} \loss(\widetilde{{\bm A}},\widetilde{{\bm B}}; {\bm \Params}_{t-j}).
\label{eq:app-loss}
\end{equation}
Notice that $l$ here affects only the size of the training set \textit{not} the order of the autoregressive model. In other words, the forecasting model $f$ will still be MAR($1$) and not MAR($l$), i.e., the matrix of local updates at time $t$ (${\bm \Params}_{t}$) depends \textit{only} on the previously observed matrix at time step $t-1$ (${\bm \Params}_{t-1}$).

Eventually, the best estimates $\hat{\bm A}$ and $\hat{\bm B}$ can be found as the solutions to the following objective:
\begin{equation}
\label{eq:app-mar-opt}
\begin{split}
    \hat{{\bm\Omega}} = \hat{\bm A}, \hat{\bm B} & = \argmin_{\widetilde{{\bm A}}, \widetilde{{\bm B}}}\Big\{\Loss(\widetilde{{\bm A}},\widetilde{{\bm B}}; {\bm \Params}_{t},l) \Big\} \\
    & = \argmin_{\widetilde{{\bm A}}, \widetilde{{\bm B}}}\Big\{\sum_{j=0}^{l-1} ||{\bm \Params}_{t-j} - \widetilde{{\bm A}}{\bm \Params}_{t-j-1}\widetilde{{\bm B}}||^2_{\text F} \Big\}.
\end{split}
\end{equation}
Before solving the optimization task defined in Eq.~(\ref{eq:app-mar-opt}) above, we replace $\widetilde{{\bm A}}$ with ${\bm A}$ and $\widetilde{{\bm B}}$ with ${\bm B}$ to ease the reading. Hence, we observe the following.
A closed-form solution to find $\hat{\bm A}$ can be computed by taking the partial derivative of the loss w.r.t. ${\bm A}$, setting it to $0$, and solving it for ${\bm A}$. In other words, we search for $\hat{\bm A}={\bm A}$, such that:
\begin{equation}
    \label{eq:app-partial-a}
\frac{\partial{\Loss({\bm A},{\bm B}; {\bm \Params}_{t},l)}}{\partial{{\bm A}}} = 0.
\end{equation}

Using Eq.~(\ref{eq:app-loss}) and Eq.~(\ref{eq:app-inst-loss}), the left-hand side of Eq.~(\ref{eq:app-partial-a}) can be rewritten as follows:
\begin{equation}
\label{eq:app-partial}
\small
\begin{split}
\frac{\partial{\Loss({\bm A},{\bm B}; {\bm \Params}_{t},l)}}{\partial{{\bm A}}} & = \frac{\partial{\sum_{j=0}^{l-1} ||{\bm \Params}_{t-j} - {\bm A}{\bm \Params}_{t-j-1}{\bm B}||^2_{\text F}}}{\partial{{\bm A}}}= \\
& = -2 \sum_{j=0}^{l-1}({\bm \Params}_{t-j} - {\bm A}{\bm \Params}_{t-j-1}{\bm B}^T){\bm B}{\bm \Params}^T_{t-1}= \\
& = -2 \Bigg[\Bigg(\sum_{j=0}^{l-1} {\bm \Params}_{t-j}{\bm B}{\bm \Params}^T_{t-j-1}\Bigg) \\
& - {\bm A}\Bigg(\sum_{j=0}^{l-1}{\bm \Params}_{t-j-1}{\bm B}^T{\bm B}{\bm \Params}^T_{t-j-1}\Bigg)\Bigg].
\end{split}
\end{equation}
If we set Eq.~(\ref{eq:app-partial}) to $0$ and solve it for ${\bm A}$, we find:
\begin{equation}
\footnotesize
\begin{split}
    -2 \Bigg[\Bigg(\sum_{j=0}^{l-1} {\bm \Params}_{t-j}{\bm B}{\bm \Params}^T_{t-j-1}\Bigg) - {\bm A}\Bigg(\sum_{j=0} ^{l-1}{\bm \Params}_{t-j-1}{\bm B}^T{\bm B}{\bm \Params}^T_{t-j-1}\Bigg)\Bigg] = 0 \nonumber
\end{split}
\end{equation}
 \[ \iff \]
\begin{equation}
\footnotesize
\begin{split}
    \Bigg(\sum_{j=0}^{l-1} {\bm \Params}_{t-j}{\bm B}{\bm \Params}^T_{t-j-1}\Bigg) - {\bm A}\Bigg(\sum_{j=0}^{l-1}{\bm \Params}_{t-j-1}{\bm B}^T{\bm B}{\bm \Params}^T_{t-j-1}\Bigg) = 0. \nonumber
\end{split}
\end{equation}

Hence:

\begin{equation}
\footnotesize
\begin{split}
\Bigg(\sum_{j=0}^{l-1} {\bm \Params}_{t-j}{\bm B}{\bm \Params}^T_{t-j-1}\Bigg)  
- {\bm A}\Bigg(\sum_{j=0}^{l-1}{\bm \Params}_{t-j-1}{\bm B}^T{\bm B}{\bm \Params}^T_{t-j-1}\Bigg) = 0
\end{split}
\end{equation}

\begin{equation}
\footnotesize
\begin{split}
\Bigg(\sum_{j=0}^{l-1} {\bm \Params}_{t-j}{\bm B}{\bm \Params}^T_{t-j-1}\Bigg) = 
{\bm A}\Bigg(\sum_{j=0}^{l-1}{\bm \Params}_{t-j-1}{\bm B}^T{\bm B}{\bm \Params}^T_{t-j-1}\Bigg) \label{eq:app-A-imp}
\end{split}
\end{equation}

\begin{equation}
\footnotesize
\begin{split}
{\bm A} = \Bigg(\sum_{j=0}^{l-1} {\bm \Params}_{t-j}{\bm B}{\bm \Params}^T_{t-j-1}\Bigg) 
\Bigg(\sum_{j=0}^{l-1}{\bm \Params}_{t-j-1}{\bm B}^T{\bm B}{\bm \Params}^T_{t-j-1}\Bigg)^{-1}.
\label{eq:app-A}
\end{split}
\end{equation}

Notice that Eq.~(\ref{eq:app-A}) is obtained by multiplying both sides of Eq.~(\ref{eq:app-A-imp}) by $\Big(\sum_{j=0}^{l-1}{\bm \Params}_{t-j-1}{\bm B}^T{\bm B}{\bm \Params}^T_{t-j-1}\Big)^{-1}$.

If we apply the same reasoning, we can also find a closed-form solution to compute $\hat{\bm B}$. That is, we take the partial derivative of the loss w.r.t. ${\bm B}$, set it to $0$, and solve it for ${\bm B}$:
\begin{equation}
\label{eq:app-partial-b}
\frac{\partial{\Loss({\bm A},{\bm B}; {\bm \Params}_{t},l)}}{\partial{{\bm B}}} = 0.
\end{equation}
Eventually, we obtain the following:
\begin{equation}
\small
\begin{split}
\label{eq:app-B}
{\bm B} = \Bigg(\sum_{j=0}^{l-1} {\bm \Params}^T_{t-j}{\bm A}{\bm \Params}_{t-j-1}\Bigg) 
\Bigg(\sum_{j=0}^{l-1}{\bm \Params}^T_{t-j-1}{\bm A}^T{\bm A}{\bm \Params}_{t-j-1}\Bigg)^{-1}.
\end{split}
\end{equation}
We now have two closed-form solutions; one for ${\bm A}$ (see Eq.~(\ref{eq:app-A})) and one for ${\bm B}$ (see Eq.~(\ref{eq:app-B})).
However, the solution to ${\bm A}$ involves ${\bm B}$, and the solution to ${\bm B}$ involves ${\bm A}$. In other words, we must know ${\bm B}$ to compute ${\bm A}$ and vice versa.

We can use the standard Alternating Least Squares (ALS) algorithm (\cite{koren2009ieeecomp}) to solve such a problem. 
The fundamental idea of ALS is to iteratively update the least squares closed-form solution of each variable alternately, keeping the other fixed. At the generic $i$-th iteration, we compute:
\begin{equation}
\scriptsize
\begin{split}
    {\bm A}^{(i+1)} = \Bigg(\sum_{j=0}^{l-1} {\bm \Params}_{t-j}{\bm B}^{(i)}{\bm \Params}^T_{t-j-1}\Bigg) \Bigg(\sum_{j=0}^{l-1}{\bm \Params}_{t-j-1}({\bm B}^{(i)})^T{\bm B}^{(i)}{\bm \Params}^T_{t-j-1}\Bigg)^{-1};\nonumber
\end{split}
\end{equation}
\begin{equation}
\scriptsize
\begin{split}
    {\bm B}^{(i+1)} = \Bigg(\sum_{j=0}^{l-1} {\bm \Params}^T_{t-j}{\bm A}^{(i+1)}{\bm \Params}_{t-j-1}\Bigg) \Bigg(\sum_{j=0}^{l-1}{\bm \Params}^T_{t-j-1}({\bm A}^{(i+1)})^T{\bm A}^{(i+1)}{\bm \Params}_{t-j-1}\Bigg)^{-1};\nonumber
\end{split}
\end{equation}
ALS repeats the two steps above until some convergence criterion is met, e.g., after a specific number of iterations $N$ or when the distance between the values of the variables computed in two consecutive iterations is smaller than a given positive threshold, i.e., $d({\bm A}^{(i+1)}-{\bm A}^{(i)}) < \varepsilon$ and $d({\bm B}^{(i+1)}-{\bm B}^{(i)}) < \varepsilon$, where $d(\cdot)$ is any suitable matrix distance function and $\varepsilon \in \R_{>0}$.

Eventually, if ${\bm A}^{(\infty)}$ and ${\bm B}^{(\infty)}$ are the parameters of the MAR model upon convergence, we set $\hat{\bm A} = {\bm A}^{(\infty)}$ and $\hat{\bm B} = {\bm B}^{(\infty)}$ as the best coefficient matrices.

%\section{How Does FLANDERS Work?}
%\label{app:flanders}
%%% ALGORITHM
%\subsection{FLANDERS' Pseudocode}
%\label{sec:algorithm}
%To enhance clarity, we illustrate the pseudocode of a hypothetical FL server that integrates FLANDERS into the model aggregation stage. 
% The main server-side loop is shown in Algorithm~\ref{alg:server}, whereas the anomaly score computation at the core of the FLANDERS filter is described in Algorithm~\ref{alg:flanders}.

% % In Algorithm~\ref{alg:server}, the central server ($S$) initializes the global model $\params^{(0)}$ and sends it to all clients. Then, it samples a set of clients ${\mathcal{C}}^{(t)}\subseteq \mathcal{C}$ and instructs them to start the local training. Once they complete it, $S$ collects all local models $\params^{(t)}_c$ $\forall c \in \mathcal{C}^{(t)}$ (lines 4-5). Subsequently, the server updates the matrix $\Params_t$ with the local models received by $\mathcal{C}^{(t)}$ (line 6), serving as the ground truth for MAR. Next, $S$ retrieves from its memory the history of local updates sent by all clients in $c \in \mathcal{C}^{(t)}$ in past rounds to form the tensor $\Params$ (line 7). It then checks if any of the selected clients has been chosen by the server for the first time. If so, it updates the tensor $\Params_{t-l:t-1}$ with the global model $\params^{t-1}$ (ColdStart algorithm on the right), as discussed in Section~4.2 and Appendix~\ref{app:example}. This step is necessary because otherwise, the server would not be able to analyze the history of clients selected for the first time in line 9.

% % In Algorithm~\ref{alg:flanders} we first compute $\hat{\Params}_t$, defined as the matrix of round $t$ estimated by MAR, composed by vectors of models $\hat{\params^t}$. We use this matrix to compute the anomaly score vector $s^t$, where each entry is a number associated with a client. Note that we left $\delta(\cdot)$ to be any distance function, as mentioned in Section~5.2. This vector is used to select the $k$ clients and models with the smallest anomaly scores (lines 3-4; however note that this mechanism can be replaced with a threshold-based one, as shown in Section~4.2). Finally, the models selected are aggregated by $\phi(\cdot)$ (line 5; in our case, $\phi(\cdot)$ corresponds to FedAvg) and we return both the global model $\params^t$ and the set of selected clients $C^{t}_*$.

% % Back to Algorithm~\ref{alg:server}, for those clients that have not been selected for the aggregation, the server does not save their originally sent model $\params^{t}_c$, but it replaces it with the global model $\params^t$ (line 10) since saving a potentially perturbed model can lead to misclassification of future updates, as discussed in Section~5.2 and Appendix~\ref{app:example}. 
% % %Note that we can choose to save the last legit models sent by these clients instead, since they alternate rounds where they behave maliciously and rounds where they don't.

% \begin{algorithm}
%     %\small
%     \caption{\texttt{\textsc{FLANDERS-Server}}}\label{alg:server}
%     %\begin{multicols}{2}
%     \begin{algorithmic}[1]
%         \Require The aggregation function ($\phi$); the number of randomly selected clients at each FL round ($m$); the number of local models to keep as legitimate ($k$); the autoregressive order of MAR ($w$); the number of historical observations used to train MAR ($l$); the number of MAR training iterations ($N$); the number of total FL rounds ($T$).
%         \Ensure The global model $\bm{\theta}^{(T)}$.

%  \Procedure{\texttt{FLANDERS-Server}}{$\phi$, $m$, $k$, $w$, $l$, $N$, $T$}
%         \State $\bm{\theta}^{(1)} \gets $ A randomly initialized model
        
%         \ForEach {$t \in \{1,2,\ldots T\}$}
%             \State $\mathcal{C}^{(t)} \gets $ sample a subset of $m$ clients from $\mathcal{C}$
%             \State Send the global model $\bm{\theta}^{(t)}$ to every  $c\in \mathcal{C}^{(t)}$
%             %\State Receive the $m$ local models trained by each $c\in \mathcal{C}^{(t)}$
%             \State $\bm{\Theta}_t \gets [\bm{\theta}^{(t)}_1, \ldots, \bm{\theta}^{(t)}_m]$ \Comment{Receive the $m$ local models trained by each $c\in \mathcal{C}^{(t)}$}
%             %\State $\Theta_t \gets \{\theta^{t}_{c_1}..\theta^{(t)}_{c_m}\}$ $\forall c \in C^{(t)}$
%             %\State $\Params_t \gets FillEmptyValues(\Params, C_t, w, t)$
%             %\State $\Theta \gets \{\Theta[:, c_1]..\Theta[:, c_m]\}$
%             %\State $\Theta_{{t-w:t-1}} \gets ColdStart(\Theta, C_t, w, t)$
%             \State $\mathcal{C}^{(t)}_* \gets \texttt{\textsc{FLANDERS-Filter}}(\bm{\Theta}_{t-l:t-1}, \mathcal{C}^{(t)}, k, w, N)$ \Comment{Returns the set of clients classified as legitimate}
%             \State $\params^{(t+1)} \gets \phi(\{\params_c^{(t)}~|~c\in \mathcal{C}_*^{(t)}\})$
%         \EndFor
%     \EndProcedure
%     \end{algorithmic}

%     %\columnbreak
    
%     %\begin{algorithmic}[1]
%     %    \Require Tensor \bm{$\Theta$} of selected clients' past observations; selected clients \bm{$C^{t}$}; number of historical observations \bm{$w$}; round number \bm{$t$}.
%     %    \Ensure Updated \bm{$\Theta_{t-w:t-1}$}.

%     %    \ForAll{$c \in C_t$} \Comment{Look up in the history of $c$}
%     %        %\If{$\theta^{t-1}_c = \bot$}
%     %            \If{$\nexists \theta^{t-j}_c \neq \bot$ where $j \in \{1..w\}$}
%     %                \State $\theta^{t-j}_c \gets \theta^{t-1}$ where $j \in \{1..w\}$
%     %            \EndIf
%     %            %\If{$\exists \theta^{t-j}_c \neq \bot$ where $j \in \{2..w\}$}
%     %            %    \State $\theta^{t-1}_c \gets \theta^{t-j}_c$ %\Comment{It can either be the global model or the last update of client $c$}
%     %            %\Else \Comment{First time $c$ has been selected}
%     %            %    \State $\theta^{t-1}_c \gets \theta^{t-1}$ %\Comment{Assign current global model}
%     %            %\EndIf
%     %        %\EndIf
%     %    \EndFor
%     %    \State $\Theta_{t-w:t-1} \gets \{\Theta_{t-w:t-1}[:,c]..\Theta_{t-w:t-1}[:,c]\}$ $\forall c \in C^{t}$ %\Comment{Update $\Theta_t$}
%     %    \State \textbf{return} $\Theta_{t-w:t-1}$

%     %\end{algorithmic}
%     %\end{multicols}
% \end{algorithm}

% %\begin{wrapfigure}[16]{R}{0.5\textwidth}
% %\begin{minipage}{0.5\textwidth}
%     \begin{algorithm}
%     \caption{\texttt{\textsc{FLANDERS-Filter}}}\label{alg:flanders}
%     \begin{algorithmic}[1]
%         \Require The tensor containing the local models of selected clients observed from $l$ past FL rounds ($\bm{\Theta}_{t-l:t-1}$); the clients selected at round $t$ ($\mathcal{C}^{(t)}$); the autoregressive order of MAR ($w$); the number of local models to keep as legitimate ($k$); the number of MAR training iterations ($N$)
%         \Ensure The set of $k$ clients classified as legitimate in round $t$ $\mathcal{C}^{(t)}_{*}$.
%  \Procedure{\texttt{FLANDERS-Filter}}{$\bm{\Theta}_{t-l:t-1}, \mathcal{C}^{(t)}, k, w, N$}
%         \State $\hat{\bm{\Theta}}_{t} \gets \texttt{MAR}(\bm{\Theta}_{t-l:t-1}, w, N)$ \Comment MAR($w$) estimation via ALS training ($N$ iterations)
%         \State $\bm{s}^{(t)} \gets \delta(\bm{\Theta}_t, \hat{\bm{\Theta}}_t)$ \Comment{Anomaly score vector}
%         \State $\mathcal{C}^{(t)}_{*} \gets \{c \in \mathcal{C}^{(t)}~|~s_{c}^{(t)} \leq s_k^{(t)}\}$ \Comment{$s^{(t)}_k$ is the $k$-th smallest anomaly score}
%         %\State $\Theta^{*}_t \gets \{\theta^t \in \Theta_t~|~s_{c}^{t} \leq s_k^{t}\}$
%         %\State $\theta^{t+1} \gets \phi(\Theta^{*}_t, |C^{t}_{*}|)$
%         \State \textbf{return} $\mathcal{C}^{(t)}_{*}$
% \EndProcedure
%     \end{algorithmic}
%     \end{algorithm}
%\end{minipage}
%\end{wrapfigure}

%%% OVERVIEW OF FLANDERS
%\subsection{A Step-by-Step Example}
%\label{app:example}
%% In Fig.~\ref{fig:tensor}, we show how local model updates collected by the server from each selected client at every FL round can be organized into a tensor, spanning over a time window $T$.
%% \begin{figure}[ht]
%%     \centering
%%     \includegraphics[width=.8\textwidth]{./img/tensor}
%%     \caption{The $d$-dimensional vector of parameters $\params_c^{(t)}$ sent by client $c$ at round $t$ (left). The $d\times m$ matrix $\Params_t$ of {\em all} the $m$ client updates sent at round $t$ (middle). The $d\times m\times T$ tensor $\Params_{1:T}$ of all the client updates after $T$ rounds (right).}
%%     \label{fig:tensor}
%% \end{figure}
%In Figure~\ref{fig:flanders}, we depict how FLANDERS computes the anomaly score vector $\bm{s}^{(t)}$ at the generic FL round $t$. Specifically, the server $S$ uses its current MAR($1$) forecasting model $f$ whose best parameters $\hat{\bm{\Omega}} = \{\hat{\bm A}, \hat{\bm B}\}$ are estimated from $l$ previous historical observations of local models received in the previous rounds $t-l,\ldots, t-1$. It applies $f$ to the previously observed matrix $\bm{\Params}_{t-1}$ to get the next predicted matrix of local models $\bm{\hat{\Params}}_{t}$, i.e., $\bm{\hat{\Params}}_{t} = f(\bm{\Params}_{t-1};\hat{\bm{\Omega}}) = \hat{\bm A}\bm{\Params}_{t-1} \hat{\bm B}$. Then, it compares this predicted matrix $\bm{\hat{\Params}}_{t}$ with the actual matrix of local updates received $\bm{\Params}_{t}$. 
%The final anomaly score vector is calculated by measuring the distance $\delta$ between each column of those two matrices, according to Eq.~(4) defined in the main paper.
%
%It is worth remarking that, in general, only some clients are selected at every round. In particular, if a client $c_{\text{new}}$ -- whether it is honest or malicious -- is selected by the server for the first time at round $t$, the MAR forecasting model $f$ will not be able to make any prediction for it due to a cold start problem (i.e., the predicted matrix $\bm{\hat{\Params}}_{t}$ will not contain a column corresponding to $c_{\text{new}}$). 
%In such a case, as already stated in the main submission, we must adopt a fallback strategy. Without any historical information for a client, the most sensible thing to do is to compute the distance $\delta$ between the local model update it sent and the current global model.
%\begin{figure}[htb!]
%    \centering
%    \includegraphics[width=\columnwidth]{./img/flanders}
%    \caption{Overview of FLANDERS.}
%    \label{fig:flanders}
%\end{figure}
%
%%\begin{algorithm}
%%\caption{FillEmptyValues}\label{alg:empty-values}
%%\begin{algorithmic}[1]
%%    \Require Tensor $\Theta = \{\theta_1..\theta_c\}$; selected clients $C_t$; number of historical observations $w$; round number $t$.
%%    \Ensure $\Theta_{t}$
%%    
%%    \ForAll{$c \in C_t$} \Comment{Look up in the history of $c$}
%%        \If{$\theta^{c}_{t-1} \neq \bot$}
%%            \State $\theta^{t}_c \gets \theta^{t-1}_c$
%%        \ElsIf{$\theta^{t-j}_c \neq \bot$ where $j \in \{1..w\}$}
%%            \State $\theta^{t}_c \gets \params^{t-j}_c$ %\Comment{It can either be the global model or the last update of client $c$}
%%        \EndIf
%%    \If{$\theta^{t}_c = \bot$} \Comment{Cold start for $c$}
%%        \State $\theta_c \gets \theta^{t-1}$ \Comment{Assign the current global model}
%%    \EndIf
%%    \EndFor
%%    \State $\Theta^t \gets \{\theta^{t}_1..\theta^{t}_c\}$
%%    \State \textbf{return} $\Theta^t$
%%\end{algorithmic}
%%\end{algorithm}
%
%To better clarify how FLANDERS works, consider the following practical example.
%\\
%Suppose an FL system consists of a centralized server and $10$ clients $c_1,\ldots, c_{10}$; furthermore, at each round, $4$ of those clients are randomly chosen for training. 
%At the very first round ($t=1$), let $\mathcal{C}^{(1)} = \{c_2, c_3, c_7, c_9\}$ be the set of $4$ clients selected by the server. Hence, the server sends the current global model $\params^{(1)} \in \R^d$ to each of those clients and collects the $d\times 4$ matrix of updated local models $\Params_1 = [\params_2^{(1)}, \params_3^{(1)}, \params_7^{(1)}, \params_9^{(1)}]$. 
%Therefore, it computes the \textit{new} global model $\params^{(2)} = \phi(\{\params_{c}^{(1)}~|~c\in \mathcal{C}^{(1)}\})$.
%Notice that, at this stage, no anomaly score can be computed as FLANDERS cannot take advantage of any historical observations of local model updates. As such, if one (or more) selected clients in the very first round are malicious, plain FedAvg may not detect those. To overcome this problem, FLANDERS should be paired with one of the existing robust aggregation heuristics at $t=1$. For example, $\phi = \{\text{Trimmed Mean, Krum, Bulyan}\}$.
%
%At the next round ($t=2$), FLANDERS can start using past observations (i.e., only $\Params_1$) to estimate the best MAR coefficients $\hat{\bm{\Omega}} = \{\hat{\bm{A}},\hat{\bm{B}}\}$ according to Eq.~(\ref{eq:app-mar-opt}) above. 
%Suppose $\mathcal{C}^{(2)} = \{c_1, c_3, c_6, c_9\}$ is the set of $4$ clients selected by the server at the second round.
%Let $\Params_2 = [\params_1^{(2)}, \params_3^{(2)}, \params_6^{(2)}, \params_9^{(2)}]$ be the local models sent by the clients to the server.
%Moreover, $\hat{\Params}_2 = f(\Params_1;\hat{\bm{\Omega}}) = [\hat{\params}_2^{(2)}, \hat{\params}_3^{(2)}, \hat{\params}_7^{(2)}, \hat{\params}_9^{(2)}]$ are the local models predicted by MAR, using the previous set of observations. 
%
%It is worth noting that $\mathcal{C}^{(1)} \cap \mathcal{C}^{(2)} = \{c_3, c_9\}$; the other two clients, $c_1$ and $c_6$, are considered ``cold-start'' since they are selected for the first time or, in any case, they do not appear in the historical observations used by MAR for predictions (i.e., in the previous $w=1$ matrices).
%Thus, we calculate the following anomaly scores, according to Eq.~(4) in the main body:
%\begin{itemize}
%\item $s_3^{(2)} = \delta(\params_3^{(2)}, \hat{\params}_3^{(2)})$ and $s_9^{(2)} = \delta(\params_9^{(2)}, \hat{\params}_9^{(2)})$, i.e., we measure the distance between the models actually sent by $c_3$ and $c_9$ and those predicted by MAR using the previous observations (\textit{first condition});
%\item $s_1^{(2)} = \delta(\params^{(2)}, \params_1^{(2)})$ and $s_6^{(2)} = \delta(\params^{(2)}, \params_6^{(2)})$, i.e., we measure the distance between the models actually sent by $c_1$ and $c_6$ and the current global model at time $t=2$, as those clients were never picked before (\textit{second condition});
%\item $s_2^{(2)} = s_4^{(2)} = s_5^{(2)} = s_7^{(2)} = s_8^{(2)} = s_{10}^{(2)} = \perp$, i.e., these clients were not selected at round $t=2$, and therefore they will not contribute to computing the new global model $\params^{(3)}$ anyway (\textit{third condition}).
%\end{itemize}
%Let us assume that $c_3$ is a malicious client controlled by an attacker. Moreover, suppose that this client started sending poisoned models since the very first round, i.e., $\params_3^{(1)}$ was already corrupted. 
%In such a case, it is evident that if we had used plain FedAvg at $t=1$, this would have likely polluted the global model $\params^{(2)}$ and, therefore, FLANDERS might fail to recognize this as a malicious client due to a relatively low anomaly score $s_3^{(2)}$. As stated before, the consequences of this edge situation in which one or more malicious clients are picked at the beginning of the FL training can be mitigated by replacing FedAvg with one of the robust aggregation strategies available in the literature, such as Trimmed Mean, Krum, or Bulyan. 
%
%However, suppose $c_3$ is correctly spotted as malicious at the end of round $t=2$ due to its high anomaly score $s_3^{(2)}$. Therefore, $c_3$ (actually, $\params_3^{(2)}$) will be discarded from the aggregation at the server's end. Hence, FedAvg can now safely be used; more generally, the server can restart running FedAvg from $t=2$ on, i.e., once FLANDERS can compute \textit{valid} anomaly scores.
%The server can now compute the updated global model as $\params^{(3)} = \phi(\{\params_{c}^{(2)}~|~c\in \mathcal{C}_*^{(2)}\})$, where $\mathcal{C}_*^{(2)} \subset \mathcal{C}^{(2)}$ contains the clients with the $k$ smallest anomaly scores. 
%For instance, if $k=2$ and $\mathcal{C}_*^{(2)} = \{c_1, c_9\}$, $\params^{(3)} = 1/2 * (\params_1^{(2)} + \params_9^{(2)})$.
%
%At the next round ($t=3$), FLANDERS can use the previous two observations $\Params_1$ and $\Params_2$ to refine the estimation of the best MAR coefficients, again solving Eq.~(\ref{eq:app-mar-opt}).\footnote{In general, FLANDERS uses $l$ past observations $\Params_{\text{max}(1,t-l):t-1}$.} 
%However, $\Params_2$ cannot be fed as-is to re-train MAR since one of its components -- i.e., the local model $\params_3^{(2)}$ sent by client $c_3$ -- has been flagged as malicious. 
%Otherwise, the resulting updated MAR coefficients could be unreliable due to the propagation of local poisoned models.
%
%To overcome this problem, FLANDERS replaces the local model marked as suspicious $\params_3^{(2)}$ with either one of the previously observed models from the same client that is supposedly legitimate \textit{or} the current global model. 
%Since, in this example, we assume $c_3$ has been malicious from the first round, we use the latter approach. 
%Specifically, we change $\Params_2$ with $\Params'_2 = [\params_1^{(2)}, \underline{\params_{}^{(2)}}, \params_6^{(2)}, \params_9^{(2)}]$, where $\params^{(2)}$ substitutes $\params_3^{(2)}$.
%As discussed at the end of Section~5.2 of the main body, this fix allows FLANDERS to work even when a malicious client is picked for two or more rounds consecutively.
%
%We can now compute $\hat{\Params}_3 = f(\Params'_2;\hat{\bm{\Omega}}) = [\hat{\params}_1^{(3)}, \hat{\params}_3^{(3)}, \hat{\params}_6^{(3)}, \hat{\params}_9^{(3)}]$ using the updated MAR, leveraging the previous set of amended observations. 
%Let $\mathcal{C}^{(3)} = \{c_2, c_3, c_4, c_5\}$ denote the set of clients selected at round $3$ and $\Params_3 = [\params_2^{(3)}, \params_3^{(3)}, \params_4^{(3)}, \params_5^{(3)}]$ be the local models sent by the clients to the server. 
%Thus, $\mathcal{C}^{(2)} \cap \mathcal{C}^{(3)} = \{c_3\}$. The remaining three clients -- $c_2$, $c_4$, and $c_5$ -- are treated as ``cold-start.'' Specifically, $c_4$ and $c_5$ are selected for the first time, while $c_2$, even though previously selected in the first round, was not chosen at the previous round ($2$). As $c_2$ was not part of the historical observations used by MAR($1$) to make predictions, we need to treat it as if it were a cold-start client.
%
%Therefore, anomaly scores are updated as follows:
%\begin{itemize}
%\item $s_3^{(3)} = \delta(\params_3^{(3)}, \hat{\params}_3^{(3)})$, i.e., we measure the distance between the models actually sent by $c_3$ and those predicted by MAR using the previous observations (\textit{first condition});
%\item $s_2^{(3)} = \delta(\params^{(3)}, \params_2^{(3)})$, $s_4^{(3)} = \delta(\params^{(3)}, \params_4^{(3)})$, and $s_5^{(3)} = \delta(\params^{(3)}, \params_5^{(3)})$ i.e., we measure the distance between the models actually sent by $c_2$, $c_4$, and $c_5$ and the current global model at time $t=3$, as those clients were never picked before or did not appear in the previous observations used to make predictions (\textit{second condition});
%\item $s_1^{(3)} = s_6^{(3)} = s_7^{(3)} = s_8^{(3)} = s_9^{(3)} = s_{10}^{(3)} = \perp$, i.e., these clients were not selected at round $t=3$, and therefore they will not contribute to computing the new global model $\params^{(4)}$ anyway (\textit{third condition}).
%\end{itemize}
%Generally, the process above continues until the global model converges.
%
%
%\subsection{FLANDERS' Pseudocode}
%We present the pseudocode of a hypothetical FL server that integrates FLANDERS into the model aggregation stage. 
%The main server-side loop is shown in Algorithm~\ref{alg:server}, whereas Algorithm~\ref{alg:flanders} details the computation of anomaly scores, which is at the heart of the FLANDERS filter.
%
%\begin{algorithm}
%    \caption{\texttt{\textsc{FLANDERS-Server}}}\label{alg:server}
%    \begin{algorithmic}[1]
%        \Require The aggregation function ($\phi$); the number of randomly selected clients at each FL round ($m$); the number of local models to keep as legitimate ($k$); the autoregressive order of MAR ($w$); the number of historical observations used to train MAR ($l$); the number of MAR training iterations ($N$); the number of total FL rounds ($T$).
%        \Ensure The global model $\bm{\theta}^{(T)}$.%
% \Procedure{\texttt{FLANDERS-Server}}{$\phi$, $m$, $k$, $w$, $l$, $N$, $T$}
%        \State $\bm{\theta}^{(1)} \gets $ A randomly initialized model
%        
%        \ForEach {$t \in \{1,2,\ldots T\}$}
%            \State $\mathcal{C}^{(t)} \gets $ sample a subset of $m$ clients from $\mathcal{C}$
%            \State Send the global model $\bm{\theta}^{(t)}$ to every  $c\in \mathcal{C}^{(t)}$
%            \State $\bm{\Theta}_t \gets [\bm{\theta}^{(t)}_1, \ldots, \bm{\theta}^{(t)}_m]$ \Comment{Receive the $m$ local models trained by each $c\in \mathcal{C}^{(t)}$}
%            \If{$t==1$}
%            \State $\mathcal{C}^{(t)}_* \gets \texttt{\textsc{Fallback}}(\bm{\Theta}_{t})$ \Comment{At the very first round, use the designated fallback aggregation strategy (e.g., FedAvg)}
%            \Else
%            \State $\mathcal{C}^{(t)}_* \gets \texttt{\textsc{FLANDERS-Filter}}(\bm{\Theta}_{t-l:t-1}, \mathcal{C}^{(t)}, k, w, N)$ \Comment{Returns the set of clients classified as legitimate}
%            \EndIf
%            \State $\params^{(t+1)} \gets \phi(\{\params_c^{(t)}~|~c\in \mathcal{C}_*^{(t)}\})$
%        \EndFor
%    \EndProcedure
%    \end{algorithmic}%
%\end{algorithm}%
%\begin{algorithm}
%    \caption{\texttt{\textsc{FLANDERS-Filter}}}\label{alg:flanders}
%    \begin{algorithmic}[1]
%        \Require The tensor containing the local models of selected clients observed from $l$ past FL rounds ($\bm{\Theta}_{t-l:t-1}$); the clients selected at round $t$ ($\mathcal{C}^{(t)}$); the autoregressive order of MAR ($w$); the number of local models to keep as legitimate ($k$); the number of MAR training iterations ($N$).
%        \Ensure The set of $k$ clients classified as legitimate in round $t$ $\mathcal{C}^{(t)}_{*}$.
% \Procedure{\texttt{FLANDERS-Filter}}{$\bm{\Theta}_{t-l:t-1}, \mathcal{C}^{(t)}, k, w, N$}
%        \State $\hat{\bm{\Theta}}_{t} \gets \texttt{MAR}(\bm{\Theta}_{t-l:t-1}, w, N)$ \Comment MAR($w$) estimation via ALS training ($N$ iterations)
%        \State $\bm{s}^{(t)} \gets \delta(\bm{\Theta}_t, \hat{\bm{\Theta}}_t)$ \Comment{Anomaly score vector}
%        \State $\mathcal{C}^{(t)}_{*} \gets \{c \in \mathcal{C}^{(t)}~|~s_{c}^{(t)} \leq s_k^{(t)}\}$ \Comment{$s^{(t)}_k$ is the $k$-th smallest anomaly score}
%        %\State $\Theta^{*}_t \gets \{\theta^t \in \Theta_t~|~s_{c}^{t} \leq s_k^{t}\}$
%        %\State $\theta^{t+1} \gets \phi(\Theta^{*}_t, |C^{t}_{*}|)$
%        \State \textbf{return} $\mathcal{C}^{(t)}_{*}$
%\EndProcedure
%    \end{algorithmic}
%    \end{algorithm}

%%% SETUP
\section{Datasets, Tasks, and FL Models}
\label{app:setup}

In Table~\ref{tab:setup}, we report the full details of our experimental setup concerning the datasets used, their associated tasks, and the models (along with their hyperparameters) trained on the simulated FL environment, i.e., Flower\footnote{\url{https://flower.dev/}} (see Appendix~\ref{app:fl-env}). Table~\ref{tab:hyp} shows the description of the hyperparameters.

\begin{table*}[ht]
\centering
\caption{Experimental setup: datasets, tasks, and FL models considered.
}
\label{tab:setup}
%\vspace{2mm}
\scalebox{1}{
%\footnotesize
\begin{tabular}{cccccc}
\toprule
\textbf{Dataset}        & \thead{\textbf{N. of Instances}\\\textbf{(training/test)}} & \textbf{N. of Features} & \textbf{Task} & \textbf{FL Model} & \textbf{Hyperparameters}\\
\midrule
% \thead{\textit{Income}~\citeyear{income-ds}}  & $39,074$/$9,768$                      & \thead{$14$\\(numerical+categorical)}          & \thead{binary\\classification} & LogReg & \{$\lambda_1$=$1.0$; $\lambda_2$=$0.0$; {\tt opt}=CCD\} \\ \hline 
\thead{\textit{MNIST}~\cite{mnist-ds}} & $60,000$/$10,000$ & \thead{$28$x$28$\\(numerical)} & \thead{multiclass\\classification} & MLP & \thead{\{{\tt batch}=$32$; {\tt layers}=$2$;\\{\tt opt}=Adam; $\eta$=$10^{-3}$\}}\\
\midrule
\thead{\textit{Fashion-MNIST}~\cite{fashionmnist-ds}} & $60,000$/$10,000$ & \thead{$28$x$28$\\(numerical)} & \thead{multiclass\\classification} & MLP & \thead{\{{\tt batch}=$32$; {\tt layers}=$4$;\\{\tt opt}=Adam; $\eta$=$10^{-3}$\}}\\
\midrule
\thead{\textit{CIFAR-10}~\cite{cifar10-100-ds}} & $50,000$/$10,000$ & \thead{$32$x$32$x$3$\\(numerical)} & \thead{multiclass\\classification} & CNN & \thead{\{{\tt batch}=$32$; {\tt layers}=$6$;\\{\tt opt}=SGD; $\eta$=$10^{-2}$; $\mu$=$0.9$\}}\\
\midrule
\thead{\textit{CIFAR-100}~\cite{cifar10-100-ds}} & $50,000$/$10,000$ & \thead{$32$x$32$x$3$\\(numerical)} & \thead{multiclass\\classification} &  CNN (MobileNet) & \thead{\{{\tt batch}=$32$; {\tt layers}=$28$;\\{\tt opt}=SGD; $\eta$=$10^{-2}$; $\mu$=$0.9$\}}\\
\bottomrule
%\thead{\textit{California Housing}~\citeyear{california-housing-ds}} & $15,740$/$3,935$                      & \thead{$18$\\(numerical)}              & regression & LinReg & \{$\lambda_1$=$0.5$; $\lambda_2$=$0.5$; {\tt opt}=CCD\}\\ \hline
\end{tabular}
}
\end{table*}

\begin{table}[ht!]
\centering
\caption{Description of hyperparameters.
}
\label{tab:hyp}
%\vspace{2mm}
\scalebox{1}{
\begin{tabular}{cc}
    \toprule
    \textbf{Hyperparameter}        & \textbf{Description} \\ 
    \midrule
    % $\lambda_1$ & $L^1$-regularization term (LASSO)\\ 
    % \hline
    % $\lambda_2$ & $L^2$-regularization term (Ridge)\\
    % \hline
    $\eta$ & learning rate\\
    \midrule
    $\mu$ & momentum\\
    \midrule
    {\tt opt} & optimizer: stochastic gradient descent (SGD); Adam\\
    \midrule
    {\tt batch} & batch size\\
    \midrule
    {\tt layers} & number of neural network layers\\
    \bottomrule
    % {\tt dropout} & neural network node's dropout probability\\
    % \hline
    \end{tabular}
}
\end{table}

% LogReg and LinReg are optimized via cyclic coordinate descent (CCD) by minimizing $L^1$-regularized binary cross-entropy loss and $L^1$/$L^2$-regularized mean squared error, respectively.
The MLP for the \textit{MNIST} dataset is a $2$-layer fully connected feed-forward neural network, whereas the MLP for the \textit{Fashion-MNIST} dataset is a $4$-layer fully connected feed-forward neural network. Both MLPs are trained by minimizing multiclass cross-entropy loss using Adam optimizer with batch size equal to $32$~\cite{li2022blades}.
%The two CNNs used for \textit{CIFAR-10} and \textit{CIFAR-100} are $6$-layer and $28$-layer convolutional neural networks, respectively. They are both trained by minimizing multiclass cross-entropy loss via stochastic gradient descent (SGD) with batch size equal to $32$~[\citeyear{pytorch-cifar-10}].
The CNN used for \textit{CIFAR-10} is a $6$-layer convolutional neural network, while the CNN used for \textit{CIFAR-100} is the well-known MobileNet architecture~\cite{howard2017mobilenets}. Both CNNs are trained by minimizing multiclass cross-entropy loss via stochastic gradient descent (SGD) with batch size equal to $32$~\cite{pytorch-cifar-10}.

% For LogReg and LinReg, at each FL round, every client performs one iteration of CCD (i.e., each model parameter is updated independently from the others).
% Instead, for 
At each FL round, every client performs one training epoch of Adam/SGD, which corresponds to the number of iterations needed to ``see'' all the training instances once, when divided into batches of size $32$.
In any case, the updated local model is sent to the central server for aggregation.

We run our experiments on a machine equipped with an AMD Ryzen 9, 64 GB RAM, and an NVIDIA 4090 GPU with 24 GB VRAM.
%4-node cluster; each node has a 48-core 64-bit AMD CPU running at 3.6 GHz with 512 GB RAM and an NVIDIA A100 GPU with 40 GB VRAM.

%%% FL SIMULATION ENVIRONMENT
\section{FL Simulation Environment}
\label{app:fl-env}
To simulate a realistic FL environment, we integrate FLANDERS into Flower. Moreover, we implement in Flower every other defense baseline considered in this work that the framework does not natively provide.
Other valid FL frameworks are available (e.g., TensorFlow Federated\footnote{\scriptsize{\url{https://www.tensorflow.org/federated}}} and PySyft\footnote{\scriptsize{\url{https://github.com/OpenMined/PySyft}}}), but Flower turned out the most flexible.
%\label{app:fl-env}
%\begin{table}[ht!]
%\centering
%\caption{Main properties of our FL environment simulated on Flower.
%}
%\label{tab:fl-env}
%%\vspace{2mm}
%\scalebox{1}{
%    \begin{tabular}{lc}
%    \toprule
%    \textbf{Total N. of Clients}        & $K = 100$ \\
%    \midrule
%    \textbf{N. of Selected Clients (at each round)} & $m = K = 100$\\
%    \midrule
%    \textbf{Ratio of Malicious Clients} & $r=\{0, 0.2, 0.6, 0.8\}$ \\
%    \midrule
%    \textbf{Total N. of FL Rounds} & $T=50$ \\ \hline
%    % \textbf{N. of Legitimate FL Rounds (with no attacks)} & $L=30$ \\ \hline
%    \textbf{Autoregressive Order of MAR} & $w=1$ \\
%    \midrule
%    \textbf{Historical Window Size of Past FL Rounds} & $l=2$ \\
%    \midrule
%    \textbf{Non-IID Dataset Distribution across Clients} & $\alpha_D = 0.5$  \\
%    \bottomrule
%    \end{tabular}
%}
%\end{table}

We want to remark that within Flower, only the \textit{number} of malicious clients in each FL round remains constant, while the framework manages their selection. This implies that a single client can alternate between legitimate and malicious behavior over successive FL rounds.

% Each training portion of the datasets listed in Table~\ref{tab:setup} is distributed across the FL clients so that every client observes the same local data distribution. 
% For example, in the case of {\em MNIST}, we let each client observe the same proportion of digit samples.
% % In addition, we experiment with two different settings: iid vs. non-iid local training datasets. 
% %The former simply assumes every client has the same local data distribution. 
% %For example, in the case of the {\em MNIST} dataset, this means that each client observes the same proportion of samples in each class.
% However, this setting -- known as iid -- may be an unrealistic scenario in FL systems, and, most likely, local training datasets on different clients follow different distributions, i.e., they are {\em non}-iid
% Notice that there are many types of ``non-iid-ness'' that may involve: {\em(i) labels}, {\em (ii) number of instances}, and {\em (iii) features}. 
% Concerning {\em(i)}, this occurs when the distribution of labels is very unbalanced across clients (i.e., each client observes only a subset of the possible outputs). 
% As for {\em (ii)}, this happens when some clients have more data than others. 
% Finally, {\em (iii)} represents a situation where similar feature patterns are grouped and shared amongst a few clients.
% In this work, we experiment with the first type of non-iid-ness limitedly to the {\em CIFAR-10} dataset, which is already implemented in Flower (see Appendix~\ref{app:non-iid}).

We report the main properties of our FL environment simulated on Flower in Table~\ref{tab:fl-env}.

% \subsection{A Clarification on the Role of $L$}
% \label{subapp:legit-rounds}
% In a real-world scenario, a honest FL server would not know if and when malicious clients start poisoning their local models. 
% Indeed, an adversary might initiate its attack from the very beginning of the FL training.
% This, however, does not make FLANDERS impractical. As we detailed in Appendix~\ref{app:example}, the MAR model is learned starting from the very first FL round and it is kept updated even while the system is possibly under attack. 
% The only exceptional situation arises when malicious clients are active (and chosen by the server) in the very first round.  
% In such a case, heuristic-based robust aggregation schemes, such as Trimmed Mean, Krum, or Bulyan, should be considered as valid fallback strategies.

% Since FLANDERS is a robust aggregation method that requires ``continuous'' learning from historical data,\footnote{The optimal training frequency for MAR presents an intriguing challenge, as it necessitates a delicate equilibrium between accuracy in detecting malicious activity and operational efficiency.} we set a number $L = 30$ of attack-free FL rounds just to bootstrap our initial MAR model.

% It is worth noticing that this ``clean'' initialization process could be achieved with preliminary bootstrap stage performed offline in a controlled environment. This could involve using available FL simulation environments, such as Flower, which allows direct control over simulated client behavior. Besides, testing the FL system offline in such environments before production deployment is a common practice. During the offline phase, any number of legitimate rounds ($L$) can be executed to bootstrap the MAR model. The primary goal is not to precisely estimate $L$, but rather to initiate the process.

%%% ATTACK SETTINGS
%\section{Attack Settings}
%\label{app:attacks}
%Below, we describe the critical parameters for
%each attack considered, which are also summarized in Table~\ref{tab:attacks}.
%
%\noindent{{\bf {\em GAUSS}}{\bf.}} This attack has only one parameter: the magnitude $\sigma$ of the perturbation to apply. We set $\sigma=10$ for all the experiments.
%
%\noindent{{\bf {\em LIE}}{\bf.}} This method has no parameters to set.
%
%\noindent{{\bf {\em OPT}}{\bf.}} The parameter $\tau$ represents the minimum value that $\lambda$ can assume. Below this threshold, the halving search stops. As suggested by the authors, we set $\tau=10^{-5}$.
%
%\noindent{{\bf {\em AGR-MM}}{\bf.}} In addition to the threshold $\tau$, AGR-MM uses the perturbation vectors ($\nabla^p$) in combination with the scaling coefficient $\gamma$ to optimize. We set $\tau=10^{-5}$ and $\nabla^p = \{std\}$, which is the vector obtained by computing the parameters' inverse of the standard deviation. For Krum, we set $\nabla^p = \{uv\}$, which is the inverse unit vector perturbation.
%\begin{table}[ht]
%\centering
%\caption{Key parameter settings for each attack strategy considered.
%}
%\label{tab:attacks}
%%\vspace{2mm}
%\begin{tabular}{cc}
%    \toprule
%    \textbf{Attack}        & \textbf{Parameters} \\
%    \midrule
%    {\bf {\em GAUSS}} & $\sigma=10$\\
%    \midrule
%    {\bf {\em LIE}} & N/A\\
%    \midrule
%    {\bf {\em OPT}} & $\tau=10^{-5}$\\
%    \midrule
%    {\bf {\em AGR-MM}} & $\tau=10^{-5}; \nabla^p = \{uv, std\}; \gamma=5$\\
%    \bottomrule
%\end{tabular}
%\end{table}

%%% DEFENSE SETTINGS
\section{Defense Settings}
\label{app:defenses}
Below, we describe the critical parameters for
each non-trivial baseline considered.

\noindent{{\bf {\em Trimmed Mean}}{\bf.}} 
The key parameter of this defense strategy is $\beta$, which is used to cut the parameters on the edges. In this work, we set $\beta = 0.2$.

\noindent{{\bf {\em FedMedian}}{\bf.}}
This method has no parameters to set.

\noindent{{\bf {\em Multi-Krum}}{\bf.}} 
We set the number of local models to keep for the aggregation (FedAvg) after the Krum filtering as $k=(b-m)$

\noindent{{\bf {\em Bulyan}}{\bf.}}
The two crucial parameters of this hybrid robust aggregation rule are $\alpha$ and $\beta$. The former determines the number of times Krum is applied to generate $\alpha$ local models; the latter is used to determine the number of parameters to select closer to the median.
In this work, we set $\alpha = m - 2 \cdot b, \beta = \alpha - 2 \cdot b$, where $b=\{0,20\}$.

\noindent{{\bf {\em DnC}}{\bf.}}
This is an iterative algorithm that has three parameters: we set $niters = 5$ as suggested by the authors, and the filtering fraction $c = 1$ to keep exactly one model (i.e., the one with the best anomaly score). Furthermore, we set $\widetilde{d} = 500$ on \textit{CIFAR-100} to sample $500$ local model weights.

\noindent{{\bf {\em FLDetector}}{\bf.}}
We set the window size $N=20$, and we let FLDetector know how many local models to keep, i.e., $k=(m-b)$, as we did for the other baselines.

% \noindent{{\bf {\em FLTrust}}{\bf.}}
% A key parameter is the so-called root dataset. In this work, we assume the server samples the root dataset from the union of the clients' clean local training data uniformly at random as in~\cite{cao2020fltrust}. We set the global learning rate to $\alpha=2\times10^{-3}$ for \emph{MNIST} and \emph{CIFAR-10} and $\alpha=1.0$ for \emph{Income} and \emph{California Housing}. Furthermore, the number of training epochs performed by the server is the same as that performed by the clients, i.e., $R_l=1$.

% \noindent{{\bf {\em MSCRED}}{\bf.}}
% Since MSCRED is designed to work with vector-valued rather than  matrix-valued time series, we need to adapt it to work in our setting. 
% Specifically, we transform (i.e., flatten) our matrix observations into vectors and apply MSCRED by setting $w=1$. Note, however, that $w$ is the size of the window used to compute the signature matrices, meaning that the generic signature matrix is dependent on the previous one. In FLANDERS, instead, it indicates the number of previous steps to consider for estimating the coefficient matrices $\hat{\bm{\Omega}} = \{\hat{\bm{A}},\hat{\bm{B}}\}$.

\noindent{{\bf {\em FLANDERS}}{\bf.}}
For a fair comparison with other baselines, we set the sliding window size $l=2$, and the number of clients to keep at every round $k=(m-b)$, where $m$ is the number of clients selected at each round and $b$ the total number of malicious clients in the FL system. Furthermore, we use a sampling value $\widetilde{d}\leq d$ that indicates how many parameters we store in the history, the number $N$ of ALS iterations, and $\alpha$ and $\beta$ which are regularization factors. Random sampling is used to select the subset of parameters considered. This is a common strategy proposed in the literature~\cite{shejwalkar2021ndss} to lower the model size to train and save the server's memory. On the other hand, the regularization factors are needed when the model parameters, the number of clients selected, or $\widetilde{d}$ cause numerical problems in the ALS algorithm, whose number of iterations is set to $N=100$. We always set $\alpha=1$ and $\beta=1$, meaning that there is no regularization since, in our experience, it reduces the capability of predicting the right model. For this reason, we set $\widetilde{d}=500$.
Finally, we set the distance function $\delta$ used to measure the difference between the observed vector of weights sent to the server and the predicted vector of weights output by MAR to squared $L^2$-norm. 
In future work, we plan to investigate other distance measures, such as cosine or mutual information distance.

Table~\ref{tab:defenses} summarizes the values of the key parameters discussed above and those characterizing our method FLANDERS.
%\vspace{-8mm}
\begin{table*}[h]
\centering
\caption{Key parameter settings for each defense strategy considered.
}
\label{tab:defenses}
\vspace{2mm}
\scalebox{0.95}{
    \begin{tabular}{cc}
    \toprule
    \textbf{Defense}        & \textbf{Parameters} \\ 
    \midrule
    {\bf {\em FedAvg}} & N/A\\ 
    \midrule
    {\bf {\em Trimmed Mean}} & $\beta=0.2$\\ 
    \midrule
    {\bf {\em FedMedian}} & N/A\\ 
    \midrule
    {\bf {\em Multi-Krum}} & $b=\{0,20\}; k=(m-b)$\\ 
    \midrule
    {\bf {\em Bulyan}} & $b=\{0,20\}; \alpha = m - 2 \cdot b; \beta = \alpha - 2 \cdot b$\\ 
    \midrule
    {\bf {\em DnC}} & $\widetilde{d}=500; niters=5; c=1$ \\ 
    \midrule
    {\bf {\em FLDetector}} & $N=20; k=(m-b)$ \\
    \midrule
    % {\bf {\em FLTrust}} & $\alpha = \{1.0, 2 \times 10^{-3}\}; R_l=1;$ {\em root dataset} randomly sampled from $\bigcup_{c=1}^K \dataset_c$\\ \hline % actually FLTrust takes the entire dataset and tests the model against it, but I suppose is equivalent to say that it's randomly sampled
    %{\bf {\em MSCRED}} & $w=1$\\ \hline
    {\bf {\em FLANDERS}} & $l=2$; $k=(m-b)$; $\widetilde{d}=\{0, 500\}$; $N=100$; $\alpha=1$; $\beta=1$; $\delta = \text{squared } L^2$-norm  \\
    \bottomrule
    \end{tabular}
}
\end{table*}

%\section{Additional Experimental Results}
%\label{app:extra-eval}

% \subsection{Consistency of Performance Beyond 50\% Malicious Clients} 
% \label{app:stability}
% One of the most remarkable findings of FLANDERS is its resilience, even in scenarios where the proportion of malicious clients surpasses that of honest FL clients (i.e., exceeding $50\%$).
% At first glance, this outcome might appear counterintuitive: when the majority of FL clients are malicious, one would expect the outliers to be the legitimate ones.
% However, FLANDERS does not operate in isolation; it takes into account the historical evolution of observed local model parameters to identify potential malicious clients.
% Of course, as discussed in Appendix~\ref{app:example} and Appendix~\ref{subapp:legit-rounds}, FLANDERS might not be effective in extreme cases where the FL system starts with the majority of clients being malicious. Nonetheless, in such situations, no defense strategy might be practically useful.

% In this section, we further show how stable is the robustness of FLANDERS even under highly severe attack scenarios.

% Specifically, for each dataset/task, we plot the distribution of the global model's accuracy obtained with all the FL aggregation rules considered in two attack settings: when the ratio of malicious clients is {\em below} $50\%$ (see Fig.~\ref{fig:boxplot-below}) or {\em equal to or above} $50\%$ (see Fig.~\ref{fig:boxplot-above}). 
% We may notice that FLANDERS exhibits a low variance across the two settings, thus indicating high stability (i.e., more predictable behavior) compared to other baselines.
% \begin{figure*}[htb!]
%     \centering
%     \includegraphics[width=\textwidth]{./img/boxplot_below}
%     \caption{Distribution of the global model's performance as measured with all the FL aggregation strategies under every attack when the ratio of malicious client is {\em below} $50\%$.}
%     \label{fig:boxplot-below}
% \end{figure*}
% \begin{figure*}[htb!]
%     \centering
%     \includegraphics[width=\textwidth]{./img/boxplot_above}
%     \caption{Distribution of the global model's performance as measured with all the FL aggregation strategies under every attack when the ratio of malicious client is {\em equal to or above} $50\%$.}
%     \label{fig:boxplot-above}
% \end{figure*}

% \subsection{Robustness vs. Cost}
% \label{app:rob-vs-cost}
% Showing the global model's performance drift before and after the attack helps understand the robustness of a specific FL aggregation scheme.
% However, this may not consider a possible cost due to the degradation introduced by the secure FL aggregation when no attack occurs. 
% Indeed, any robust FL aggregation strategy may sacrifice the global model's performance when no attack occurs. In other words, there is a price to pay in exchange for the level of security guaranteed.  
% For instance, suppose that the best global model's accuracy without attack is obtained with plain FedAvg, and let this value be $0.92$. Then, suppose that the accuracy drops to $0.65$ when malicious clients enter the FedAvg-based FL system. Undoubtedly, this is a remarkable accuracy loss.
% Now, consider some robust FL aggregation that achieves an accuracy of $0.71$ when no attack occurs and $0.66$ under attack.
% Clearly, this is far more robust than FedAvg as the accuracy values measured before and after the attack are closer than those obtained with FedAvg. In fact, we would draw a similar conclusion even if the accuracy under attack was $0.63$ instead of $0.66$ (i.e., if it was lower than the value observed with FedAvg). 
% Still, we should also consider the accuracy drop observed with no attack (from $0.92$ to $0.71$).

% Inspired by~\cite{shejwalkar2021ndss}, we design a unified metric that combines both the {\em robustness} and {\em cost} of an FL aggregation strategy.
% Specifically, let $v^*_{\text{pre}}$ be the overall best global model's performance as measured within the $L$-th round (i.e., before {\em any} attack) for the generic task.
% Then, we compute $v^{\phi}_{\text{pre}}$ and $v^{\phi}_{\text{post}}$, namely the global model's performance observed before and after a specific attack, using a fixed aggregation strategy $\phi$, where $\phi$ = \{FedAvg, FedMedian, Trimmed Mean, Krum, Bulyan, DnC, FLTrust, MSCRED, FLANDERS\}.

% Thus, we define $R^{\phi}$ and $C^{\phi}$ respectively as the robustness and the cost of the aggregation strategy $\phi$, as follows:\footnote{We assume $v^{\phi}_{\text{pre}} \neq 0$.}
% \[
% R^{\phi} = \frac{v^{\phi}_{\text{post}}}{v^{\phi}_{\text{pre}}};~~~C^{\phi} = \frac{v^*_{\text{pre}}}{v^{\phi}_{\text{pre}}} - 1.
% \]
% The former captures the resiliency of an aggregation strategy to a given attack; the latter quantifies the drop in the optimal model's performance under no attack.  
% Notice that $R^{\phi} = 1$ iff the performance of the global model is unaffected by the attack, i.e., it is the same before and after the attack. Otherwise, $R^{\phi} < 1$ indicates the defense mechanism struggles to compensate for the attack, and if $R^{\phi} > 1$, the aggregation is so robust that the model keeps improving its performance even under attack.
% On the other hand, assuming $v^*_{\text{pre}}\geq v^{\phi}_{\text{pre}}$ for any $\phi$, $C^{\phi} \geq 0$ and $C^{\phi} = 0$ iff the aggregation strategy achieves optimal performance under no attack.
% Eventually, we can calculate the net gain $G^{\phi}$ of an aggregation strategy as:
% \[
% G^{\phi} = R^{\phi} - C^{\phi}.
% \]
% Obviously, the larger $G^{\phi}$ the better. 

% It is worth remarking that, for each classification task, we measure the global model's accuracy, whereas, for the regression task associated with the {\em California Housing} dataset, we compute the global model's one minus mean absolute percentage error (1-MAPE). 
% We report the result of this analysis in Table~\ref{tab:gain}, focusing on two attack settings: when the ratio of malicious clients is $20\%$ and $80\%$, i.e., when $b=20$ and $b=80$.

% \begin{table*}[htb!]
% \centering
% \caption{Evaluation of all the FL aggregation strategies on every dataset/task under four types of attack and two malicious settings: $20\%$ and $80\%$ malicious clients. The value in each cell is computed as the difference between the {\em robustness} and the {\em cost} of a specific defense mechanism as defined above, or N/A if that defense does not support the attack. Higher figures correspond to better performance.}
% \label{tab:gain}
% \vspace{2mm}
% \scalebox{0.8}{
%     \begin{tabular}{ |c|c|c||c|c||c|c||c|c||c|c| } 
%     \hline
%     \multirow{2}{*}{{\bf Dataset}} & \multirow{2}{*}{{\bf FL Aggregation}} & \multirow{2}{*}{{\bf No Attack}} & \multicolumn{2}{c||}{\textbf{GAUSS}} & \multicolumn{2}{c||}{\textbf{LIE}} & \multicolumn{2}{c||}{\textbf{OPT}} & \multicolumn{2}{c|}{\textbf{AGR-MM}} \\\cline{4-11}
%     &  &  & $b=20$ & $b=80$ & $b=20$ & $b=80$ & $b=20$ & $b=80$ & $b=20$ & $b=80$ \\
%     \hline
%     \multirow{9}{*}{\textit{Income}} 
%     & FedAvg & ${\bf 1.00}$ & $0.94$ & $0.94$ & $0.94$ & $0.94$ & $0.94$ & $0.29$ & $0.95$ & $0.94$ \\
%     & FedMedian & $0.98$ & $0.98$ & $0.99$ & $0.99$ & $0.94$ & $0.98$ & $0.93$ & $0.99$ & $0.94$ \\
%     & Trimmed Mean & $0.99$ & ${\bf 1.00}$ & $0.99$ & ${\bf 1.00}$ & $0.94$ & $0.99$ & $0.29$ & $0.99$ & $0.94$ \\
%     & Krum & $0.99$ & $0.99$ & N/A & $0.99$ & N/A & $0.99$ & N/A & $0.99$ & N/A \\
%     & Bulyan & ${\bf 1.00}$ & ${\bf 1.00}$ & N/A & ${\bf 1.00}$ & N/A & $0.99$ & N/A & ${\bf 1.00}$ & N/A \\
%     & DnC & $0.99$ & ${\bf 1.00}$ & ${\bf 1.00}$ & $0.99$ & $0.99$ & $0.99$ & $0.99$ & $0.99$ & $0.99$ \\
%     & FLTrust & ${\bf 1.00}$ & $0.99$ & $0.96$ & ${\bf 1.00}$ & $0.99$ & $0.99$ & $0.95$ & ${\bf 1.00}$ & ${\bf 1.00}$ \\
%     & MSCRED & ${\bf 1.00}$ & $0.99$ & $0.98$ & ${\bf 1.00}$ & $0.94$ & ${\bf 1.00}$ & ${\bf 1.00}$ & $0.99$ & $0.94$ \\
%     & FLANDERS & ${\bf 1.00}$ & ${\bf 1.00}$ & ${\bf 1.00}$ & $0.99$ & ${\bf 1.00}$ & $0.99$ & $0.99$ & $0.99$ & ${\bf 1.00}$ \\
%     \hline\hline
%     \multirow{9}{*}{\textit{MNIST}} 
%     & FedAvg & $1.01$ & $0.11$ & $0.10$ & $1.00$ & $0.12$ & $NaN$ & $0.07$ & $0.97$ & $0.10$ \\
%     & FedMedian & ${\bf 1.02}$ & ${\bf 1.01}$ & $0.97$ & ${\bf 1.01}$ & $0.10$ & ${\bf 1.01}$ & $0.02$ & ${\bf 1.01}$ & $0.11$ \\
%     & Trimmed Mean & $1.01$ & $0.98$ & ${\bf 1.00}$ & $1.00$ & $0.09$ & $0.99$ & $-0.01$ & $0.99$ & $0.08$ \\
%     & Krum & $1.00$ & $0.99$ & N/A & $1.00$ & N/A & $0.99$ & N/A & $0.97$ & N/A \\
%     & Bulyan & $1.01$ & ${\bf 1.01}$ & N/A & ${\bf 1.01}$ & N/A & ${\bf 1.01}$ & N/A & $1.00$ & N/A \\
%     & DnC & $0.98$ & $0.97$ & $0.97$ & $0.98$ & ${\bf 1.00}$ & $0.99$ & ${\bf 0.99}$ & $0.98$ & ${\bf 1.00}$ \\
%     & FLTrust & $0.61$ & $0.42$ & $0.54$ & $0.53$ & $0.44$ & $0.69$ & $0.60$ & $0.47$ & $0.51$ \\
%     & MSCRED & $1.00$ & $0.11$ & $0.10$ & $0.11$ & $0.10$ & $1.00$ & $0.97$ & $0.10$ & $0.10$ \\
%     & FLANDERS & $0.96$ & $0.91$ & $0.96$ & $0.99$ & $0.96$ & $0.95$ & $0.98$ & $0.99$ & $0.97$ \\
%     \hline\hline
%     \multirow{9}{*}{\textit{CIFAR-10}} 
%     & FedAvg & ${\bf 1.14}$ & $0.20$ & $0.20$ & $0.94$ & $0.21$ & $0.24$ & $0.21$ & ${\bf 1.10}$ & ${\bf 0.65}$ \\
%     & FedMedian & $1.12$ & ${\bf 1.16}$ & ${\bf 0.96}$ & ${\bf 1.10}$ & $0.16$ & $1.08$ & $0.21$ & $1.08$ & $0.37$ \\
%     & Trimmed Mean & $1.00$ & $1.02$ & $0.95$ & $0.98$ & $0.10$ & $0.99$ & $0.09$ & $0.97$ & $0.17$ \\
%     & Krum & $0.98$ & $0.99$ & N/A & $0.99$ & N/A & $0.92$ & N/A & $1.00$ & N/A \\
%     & Bulyan & ${\bf 1.14}$ & $1.14$ & N/A & $1.14$ & N/A & ${\bf 1.12}$ & N/A & $1.07$ & N/A \\
%     & DnC & $-2.20$ & $-1.42$ & $-2.18$ & $-1.62$ & $-2.38$ & $-1.92$ & $-2.09$ & $-2.09$ & $-2.40$ \\
%     & FLTrust & $-2.16$ & $-1.96$ & $-2.42$ & $-2.08$ & $-2.40$ & $-2.21$ & $-2.40$ & $-2.21$ & $-2.42$ \\
%     & MSCRED & $0.89$ & $0.28$ & $0.18$ & $0.26$ & $0.23$ & $0.28$ & $0.77$ & $0.43$ & $0.37$ \\
%     & FLANDERS & $0.83$ & $0.92$ & $0.86$ & $0.81$ & ${\bf 0.80}$ & $0.58$ & ${\bf 0.79}$ & $0.79$ & $0.25$ \\
%     \hline\hline
%     \multirow{9}{*}{\shortstack[l]{{\em California}\\{\em Housing}}} 
%     & FedAvg & $0.90$ & $0.90$ & $0.90$ & $0.91$ & $0.91$ & $-0.09$ & $-0.09$ & $0.96$ & $0.96$ \\
%     & FedMedian & $0.90$ & $0.90$ & $0.90$ & $0.90$ & $0.90$ & $0.91$ & $-0.07$ & $0.93$ & $0.96$ \\
%     & Trimmed Mean & $0.91$ & $0.91$ & $0.91$ & $0.90$ & $0.91$ & $0.93$ & $-0.09$ & $0.93$ & $0.96$ \\
%     & Krum & $0.91$ & $0.91$ & N/A & $0.90$ & N/A & $0.91$ & N/A & $0.91$ & N/A \\
%     & Bulyan & $0.91$ & $0.91$ & N/A & $0.91$ & N/A & $0.91$ & N/A & $0.93$ & N/A \\
%     & DnC & $0.92$ & $0.92$ & $0.92$ & $0.94$ & $0.98$ & $0.93$ & $0.95$ & $0.97$ & $0.97$ \\
%     & FLTrust & N/A & N/A & N/A & N/A & N/A & N/A & N/A & N/A & N/A \\
%     & MSCRED & $0.94$ & $0.94$ & $0.93$ & $0.99$ & ${\bf 1.00}$ & $0.94$ & $0.90$ & $0.96$ & $0.96$ \\
%     & FLANDERS & ${\bf 1.00}$ & ${\bf 1.00}$ & ${\bf 1.00}$ & ${\bf 1.00}$ & ${\bf 1.00}$ & ${\bf 1.01}$ & ${\bf 0.99}$ & ${\bf 1.00}$ & ${\bf 1.00}$ \\
%     \hline
%     \end{tabular}
%     }
%     %\vspace{-2mm}
% \end{table*}

% % ADDITIONAL BOXPLOT(?)
% %%% I'm talking about the boxplots  
% % First of all, we assess the robustness of FLANDERS against several combinations of attack type and strength (i.e., proportion of malicious clients in the FL system). The result of this experiment is shown in Fig.~\ref{fig:cifar-robustness}, Fig.~\ref{fig:mnist-robustness}, Fig.~\ref{fig:income-robustness} and Fig.~\ref{fig:house-robustness}.

% % Fig.~\ref{fig:cifar-robustness} shows that for $b < 50$ Flanders does not achieve the best accuracy compared to the other defenses in CIFAR-10, but for $b >= 50$ it reaches a greater median accuracy under LIE, OPT and AGR-MM, while the box shadow is narrower, meaning that the attacks have a smaller impact on Flanders. Note that FLTrust is the worst performing given its slow convergence time: according to \cite{cao2020fltrust} it needs thousands of rounds. Gaussian attack does not affect the accuracy that much and this is probably caused by the low magnitude chosen. Moreover, FedAvg performs unexpectedly good under AGR-MM attack: this maybe the cause of a non-optimal choice of the perturbation vector. When no attack occurs, FedAvg and FedMedian are the best performing defenses because they build the global model considering all the local models received, while other baselines pick one of the local model to be the global one. 
% % In the case of Flanders, the slow convergence is caused by the fact that it always picks the model with the smallest change from the previous FL round. Using a bigger \emph{k} would help the convergence speed.
% % The same reasoning applies with the next datasets.

% % Fig.~\ref{fig:mnist-robustness} shows that Flanders on MNIST has almost the same behaviour of the previous dataset, with worst performances on $b<50$ and better ones on $b>=50$ compared to the other baselines. In the latter case it is indeed clear how the shadow of the box becomes very large for all the baselines, but Flanders and FLTrust. This is in line with the results achieved by FLTrust's authors, although the slow convergence time leads it to the worst performance.

% % In Fig.~\ref{fig:income-robustness} (Income) ($b<50$) the defenses studied in this experiment are robust in almost every case with the exception of FLTrust, while FedAvg and Bulyan show a slightly wider variance. The situation turns in favor of Flanders when $b>=50$: in LIE and OPT it is the most stable model, while under AGR-MM FLTrust and Flanders are the best ones. Moreover our results show in almost every defense a smaller variance. This could be due to the fact that the objective function has a lot of local optima so it is harder for the attack strategies to find a point where the functions has a lower accuracy. In this case, only OPT achieve a successful attack against FedAvg, TrimmedMean and Bulyan.

% % Finally, on California Houses (Fig.~\ref{fig:house-robustness}) Flanders shows a much more stable behaviour than its competitors under all the given scenarios. FLTrust fails to find a working global model, while Krum performs incredibly good even when $b>=50$, although it does not achieve the best MAPE. This is an analogous situation of before, where only OPT finds a solution capable of decreasing the global model metrics on most defences.

% \subsection{Non-IID Local Training Data}
% \label{app:non-iid}
% We simulate non-iid local training
% data distributions of the {\em CIFAR-10} dataset using the built-in capabilities of Flower.
% Specifically, Flower includes a dataset partitioning method based on Dirichlet sampling to simulate non-iid label distribution across federated clients as proposed by~\cite{hsu2019LDA}.
% Note that this is a common practice in FL research to obtain synthetic federated datasets~\cite{wang2020neurips, reddi2021iclr}.

% We assume every client training example is drawn independently with class labels following a categorical distribution over $N$ classes parameterized by a vector $\bm{q}$ such that $q_i \geq 0, i \in [1,\ldots,N]$ and $||\bm{q}||_1 = 1$.
% \begin{figure*}[htb!]
%     \centering
%     \includegraphics[width=\textwidth]{./img/non-iid-20-all}
%     \caption{Global model's accuracy on {\em CIFAR-10} dataset with $20\%$ malicious clients and non-iid local training data using FLANDERS when $k=1$ (left), $k=5$ (middle), and $k=20$ (right).}
%     \label{fig:non-iid-20-all}
% \end{figure*}
% To synthesize a population of non-identical clients, we draw $\bm{q} \sim \text{Dir}(\alpha_D, \bm{p})$ from a Dirichlet distribution, where $\bm{p}$ characterizes a prior class distribution over $N$ classes, and $\alpha_D > 0$ is a {\em concentration} parameter controlling the identicalness amongst clients. 
% With $\alpha_D \rightarrow \infty$, all clients have identical label distributions; on the other extreme, with $\alpha_D \rightarrow 0$, each client holds examples from only one class chosen at random. 
% In our experiment, we set $\alpha_D = 0.5$ to simulate a strong class label imbalance amongst clients.
% Specifically, the \textit{CIFAR-10} dataset contains $60,000$ images ($50,000$ for training and $10,000$ for testing) from $N=10$ classes. 
% We start from balanced populations consisting of $K=100$ clients, each holding $500$ images. Then, we set the prior distribution $\bm{p}$ to be uniform across $10$ classes. 
% For every client, we sample $\bm{q} \sim \text{Dir}(0.5, \bm{p})$ and assign the client with the corresponding number of images from $10$ classes.

% We analyze the impact of non-iid training data on FLANDERS by measuring how the global model's accuracy changes with the number of FL rounds, both under attack and with no malicious clients. In the first case, we consider all the attacks described in Section~6.2 of the main body with $20\%$ of malicious clients (i.e., $b=20$), and we vary the number of clients deemed to be legitimate at each round as $k\in \{1, 5, 20\}$.
% The result of this study is shown in Fig.~\ref{fig:non-iid-20-all}.
% We may observe that model training under a highly non-iid setting results in low and oscillating accuracy, disregarding the type of attack when the number of clients deemed to be legitimate is small (i.e., when $k=1$). 
% The negative impact of non-iid is mitigated when we increase the number of legitimate clients $k$ included in the aggregation, except for the OPT attack, which preserves its detrimental effect on the global model's accuracy. 
% This result can be explained as follows. 
% Intuitively, the more (legitimate) client updates we consider for aggregation, the better we cope with possible parameter variation due to local non-iid training.

\section{Additional Results}
\label{app:further-results}

\subsection{Impact on Attack-Free scenarios}
First of all, in Table~\ref{tab:increment-0}, we assess the impact of FLANDERS in an attack-free scenario (i.e., when $r=0$). In this setting, no clear winning strategy emerges. Sometimes, FLANDERS has a detrimental effect on the global model's accuracy with a standard aggregation mechanism (e.g., see FedAvg with the \textit{MNIST} dataset). In other instances, however, FLANDERS improves the global model's accuracy when paired with robust aggregation schemes (e.g., see Bulyan with the \textit{MNIST} dataset).

\begin{table}[htb!]
\centering
%\vspace{-2mm}
\caption{Accuracy of the global model using all the baseline aggregation methods without and with FLANDERS ($r=0$). The best results are typed in boldface.}
\label{tab:increment-0}
%\vspace{2mm}
\scalebox{1}{
\begin{tabular}{ccccc}
\toprule
& \multicolumn{1}{c}{\textit{MNIST}} & \multicolumn{1}{c}{\textit{Fashion-MNIST}} & \multicolumn{1}{c}{\textit{CIFAR-10}} & \multicolumn{1}{c}{\textit{CIFAR-100}} \\
\midrule
FedAvg                  & ${\bf 0.86}$ & $0.63$ & $0.35$ & ${\bf 0.06}$ \\
+ FLANDERS              & $0.83$ & ${\bf 0.68}$ & ${\bf 0.36}$ & $0.05$ \\
\midrule
FedMedian               & ${\bf 0.84}$ & ${\bf 0.71}$ & $0.31$ & ${\bf 0.10}$ \\
+ FLANDERS              & $0.78$ & $0.68$ & ${\bf 0.33}$ & ${\bf 0.10}$ \\
\midrule
TrimmedMean             & ${\bf 0.82}$ & $0.69$ & ${\bf 0.33}$ & ${\bf 0.12}$ \\
+ FLANDERS              & $0.80$ & ${\bf 0.70}$ & $0.32$ & $0.11$ \\
\midrule
MultiKrum               & $0.72$ & ${\bf 0.65}$ & $0.34$ & $0.05$ \\
+ FLANDERS              & ${\bf 0.80}$ & $0.64$ & ${\bf 0.44}$ & ${\bf 0.08}$ \\
\midrule
Bulyan                  & $0.85$ & $0.65$ & ${\bf 0.43}$ & $0.05$ \\
+ FLANDERS              & ${\bf 0.90}$ & ${\bf 0.70}$ & $0.42$ & ${\bf 0.06}$ \\
\midrule
DnC                     & $0.81$ & $0.62$ & ${\bf 0.44}$ & $0.06$ \\
+ FLANDERS              & ${\bf 0.86}$ & ${\bf 0.64}$ & ${\bf 0.44}$ & ${\bf 0.07}$ \\
\bottomrule
\end{tabular}
}
\end{table}

\subsection{Random Client Selection}
\label{app:client-selection}
So far, we have assumed that the FL server selects \textit{all} available clients at each round, i.e., $|\mathcal{C}^{(t)}| = m = K~\forall t\in \{1,2, \ldots, T\}$.
In this section, we investigate the scenario where the number of clients selected at each round remains fixed ($|\mathcal{C}^{(t)}| = m$), but now the FL server chooses a \textit{random} subset of the available clients, i.e., $1 \leq m < K$.
\\
We experiment with $K=10$ clients, of which $b=2$ are malicious (running the AGR-MM attack). Each client has a non-iid sample of the \textit{MNIST} dataset, where we fix $k=max(1,K*c - b)$. At each FL round, $m=K*c$ clients are randomly chosen ($c \in \{0.2,0.5,1.0\}$). 
\begin{table}[htb!]
    \centering
    \caption{Accuracy of the global model on the \textit{MNIST} dataset using FLANDERS + FedAvg, with $b=2$ attackers out of $K=10$ clients, under AGR-MM attack, and with variable clients selected for training each round ($c$).}
    \label{tab:rnd-client-sel}
    \begin{tabular}{cccc}
    \toprule
    $c$ & ${\bf 0.2}$ & ${\bf 0.5}$ & ${\bf 1.0}$ \\
    \midrule
    Accuracy & $0.75$ & $0.83$ & $0.92$ \\
    \bottomrule
    \end{tabular}
    \label{tab:random-client-selection}
\end{table}
\\
The results in Table~\ref{tab:random-client-selection} show that the accuracy of the global model improves as the ratio of sampled clients increases, while FLANDERS remains robust to AGR-MM attacks.


\subsection{Malicious Detection Accuracy}
\label{app:flanders-accuracy}
We evaluate the capability of FLANDERS to detect malicious clients accurately. 
Specifically, let $\mathcal{C}^{(t)}_{\text{mal}}\subseteq \mathcal{C}$ be the set of malicious clients selected at round $t$ by the FL server. 
Furthermore, let $\hat{\mathcal{C}}^{(t)}_{\text{mal}}\subseteq \mathcal{C}$ be the set of malicious clients identified by FLANDERS at round $t$. Thus, we measure \textit{Precision} ($P$) and \textit{Recall} ($R$) as usual, i.e., $P=\frac{tp}{tp + fp}$ and $R=\frac{tp}{tp + fn}$, where $tp,fp,fn$ stand for \textit{true positives}, \textit{false positives}, and \textit{false negatives}. 
Specifically, $tp = \sum_{t=1}^T |\mathcal{C}^{(t)}_{\text{mal}} \cap \hat{\mathcal{C}}^{(t)}_{\text{mal}}|$, $fp = \sum_{t=1}^T |\hat{\mathcal{C}}^{(t)}_{\text{mal}} \setminus \mathcal{C}^{(t)}_{\text{mal}}|$, and $fn = \sum_{t=1}^T |\mathcal{C}^{(t)}_{\text{mal}} \setminus \hat{\mathcal{C}}^{(t)}_{\text{mal}}|$.

Table~\ref{tab:pr-60} illustrates the values for the precision ($P$) and recall ($R$) values of FLANDERS under extreme attack scenarios, integrating the findings already reported in Tables~\ref{tab:pr-20}, and \ref{tab:pr-80} in the main body. 

%\begin{table}[htb!]
%\centering
%\caption{\textit{Precision} ($P$) and \textit{Recall} ($R$) of FLANDERS in detecting malicious clients across various datasets and attacks ($r=0.6$; $T=50$ rounds).}
%\label{tab:pr-60}
%%\vspace{2mm}
%%\scalebox{0.8}{
%\begin{tabular}{|c|cc|cc|cc|cc|}
%\hline
% \multirow{2}{*}{\textbf{Dataset}} & \multicolumn{2}{c|}{GAUSS} & \multicolumn{2}{c|}{LIE} & \multicolumn{2}{c|}{OPT} & \multicolumn{2}{c|}{AGR-MM} \\
% \cline{2-9}
%                    & $P$   & $R$   & $P$   & $R$    & $P$  & $R$   & $P$  & $R$ \\
%\hline
%\textit{MNIST}      & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ \\
%\hline
%\textit{Fashion-MNIST}   & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ \\
%\hline
%\textit{CIFAR-10}   & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ \\
%\hline
%\textit{CIFAR-100}  & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ \\
%\hline
%\end{tabular}
%%}
%\end{table}

%\begin{table}[htb!]
%\centering
%\caption{\textit{Precision} ($P$) and \textit{Recall} ($R$) of FLANDERS in detecting malicious clients across various datasets and attacks ($r=0.8$; $T=50$ rounds).}
%\label{tab:pr-80}
%%\vspace{2mm}
%%\scalebox{0.9}{
%\begin{tabular}{|c|cc|cc|cc|cc|}
%\hline
% \multirow{2}{*}{\textbf{Dataset}} & \multicolumn{2}{c|}{GAUSS} & \multicolumn{2}{c|}{LIE} & \multicolumn{2}{c|}{OPT} & \multicolumn{2}{c|}{AGR-MM} \\
% \cline{2-9}
%                    & $P$   & $R$   & $P$   & $R$    & $P$  & $R$   & $P$  & $R$ \\
%\hline
%\textit{MNIST}      & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ \\
%\hline
%\textit{Fashion-MNIST}   & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ \\
%\hline
%\textit{CIFAR-10}   & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ \\
%\hline
%\textit{CIFAR-100}  & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ & $1.0$ \\
%\hline
%\end{tabular}
%%}
%\end{table}


\begin{table*}[htb!]
\centering
%\vspace{-4mm}
\caption{\textit{Precision} ($P$) and \textit{Recall} ($R$) of FLDetector and FLANDERS in detecting malicious clients across various datasets and attacks ($r=0.6$; $T=50$ rounds).}
\label{tab:pr-60}
\scalebox{1}{
\begin{tabular}{@{}cccccccccccccccccc@{}}\toprule
 \multicolumn{1}{c}{} & \multicolumn{8}{c}{\textbf{FLDetector}} & \phantom{a} & \multicolumn{8}{c}{\textbf{FLANDERS}} \\
 \cmidrule(lr){2-9} \cmidrule(lr){11-18}
 & \multicolumn{2}{c}{GAUSS} & \multicolumn{2}{c}{LIE} & \multicolumn{2}{c}{OPT} & \multicolumn{2}{c}{AGR-MM} && \multicolumn{2}{c}{GAUSS} & \multicolumn{2}{c}{LIE} & \multicolumn{2}{c}{OPT} & \multicolumn{2}{c}{AGR-MM} \\
 \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9} \cmidrule(lr){11-12} \cmidrule(lr){13-14} \cmidrule(lr){15-16} \cmidrule(lr){17-18}
                            & $P$   & $R$   & $P$   & $R$   & $P$    & $R$    & $P$   & $R$     && $P$   & $R$   & $P$   & $R$    & $P$  & $R$   & $P$  & $R$ \\
\midrule
\textit{MNIST}         & $0.60$ & $0.60$ & $0.60$ & $0.60$ & $0.62$ & $0.62$ & $0.60$ & $0.60$   && ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ \\
%\hline
\textit{Fashion-MNIST} & $0.60$ & $0.60$ & $0.59$ & $0.59$ & $0.60$ & $0.60$ & $0.61$ & $0.61$   && ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ \\
%\hline
\textit{CIFAR-10}      & $0.60$ & $0.60$ & $0.61$ & $0.61$ & $0.60$ & $0.60$ & $0.60$ & $0.60$   && ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ \\
%\hline
\textit{CIFAR-100}     & $0.60$ & $0.60$ & $0.60$ & $0.60$ & $0.60$ & $0.60$ & $0.61$ & $0.61$   && ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$  & ${\bf 1.0}$  & ${\bf 1.0}$ & ${\bf 1.0}$ \\
\bottomrule
\end{tabular}
}
\end{table*}


%\begin{table*}[htb!]
%\centering
%%\vspace{-4mm}
%\caption{\textit{Precision} ($P$) and \textit{Recall} ($R$) of FLDetector and FLANDERS in detecting malicious clients across various datasets and attacks ($r=0.8$; $T=50$ rounds).}
%\label{tab:pr-80}
%\scalebox{1}{
%\begin{tabular}{@{}cccccccccccccccccc@{}}\toprule
% \multicolumn{1}{c}{} & \multicolumn{8}{c}{\textbf{FLDetector}} & \phantom{a} & \multicolumn{8}{c}{\textbf{FLANDERS}} \\
% \cmidrule(lr){2-9} \cmidrule(lr){11-18}
% & \multicolumn{2}{c}{GAUSS} & \multicolumn{2}{c}{LIE} & \multicolumn{2}{c}{OPT} & \multicolumn{2}{c}{AGR-MM} && \multicolumn{2}{c}{GAUSS} & \multicolumn{2}{c}{LIE} & \multicolumn{2}{c}{OPT} & \multicolumn{2}{c}{AGR-MM} \\
% \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9} \cmidrule(lr){11-12} \cmidrule(lr){13-14} \cmidrule(lr){15-16} \cmidrule(lr){17-18}
%                            & $P$   & $R$   & $P$   & $R$   & $P$    & $R$    & $P$   & $R$     && $P$   & $R$   & $P$   & $R$    & $P$  & $R$   & $P$  & $R$ \\
%\midrule
%\textit{MNIST}              & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ && ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ \\
%%\hline
%\textit{Fashion-MNIST}      & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.79$ & $0.79$ & $0.80$ & $0.80$ && ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ \\
%%\hline
%\textit{CIFAR-10}           & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ && ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ \\
%%\hline
%\textit{CIFAR-100}          & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ && ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$  & ${\bf 1.0}$  & ${\bf 1.0}$ & ${\bf 1.0}$ \\
%\bottomrule
%\end{tabular}
%}
%\end{table*}


\subsection{Aggregation Robustness Lift}
\label{app:agg-lift}

In this section, we report the full results on the improved robustness of the global model against malicious attacks when FLANDERS is paired with existing aggregation strategies.

Table~\ref{tab:increment-fld-60} illustrates the comparison between FLANDERS and its main competitor, FLDetector, when both are paired with standard FedAvg, under a severe ($r=0.6$) attack scenario. These results complete those shown in Table~\ref{tab:increment-fld}, and \ref{tab:increment-fld-60} of the main submission.

%In Table~\ref{tab:increment-cifar100-80}, we report the results for the \textit{CIFAR-100} dataset, which, due to space limitations, were not included in Table~\ref{tab:increment} of the main submission.

\begin{table*}[htb!]
\centering
%\vspace{-2mm}
\caption{Accuracy of the global model using FedAvg with FLDetector and FLANDERS ($r=0.6$).}
\label{tab:increment-fld-60}
%\vspace{2mm}
\scalebox{1}{
\begin{tabular}{ccccccccccccccc}
\toprule
& \multicolumn{4}{c}{\textbf{FedAvg}} & \phantom{a} & \multicolumn{4}{c}{\textbf{FLDetector + FedAvg}} & \phantom{a} & \multicolumn{4}{c}{\textbf{FLANDERS + FedAvg}} \\
\cmidrule(lr){2-5} \cmidrule(lr){7-10} \cmidrule(lr){12-15}
                    &  GAUSS    &  LIE     &  OPT     &  AGR-MM  &&  GAUSS   &  LIE     &  OPT     &  AGR-MM  &&  GAUSS    &  LIE     &  OPT     &  AGR-MM      \\ 
\midrule
\textit{MNIST}          & $0.18$ & $0.12$ & $0.16$ & $0.15$ && $0.19$ & $0.12$ & $0.17$ & $0.12$ && ${\bf 0.78}$ & ${\bf 0.82}$ & ${\bf 0.79}$ & ${\bf 0.85}$ \\
\textit{Fashion-MNIST}  & $0.28$ & $0.10$ & $0.18$ & $0.10$ && $0.19$ & $0.10$ & $0.11$ & $0.10$ && ${\bf 0.69}$ & ${\bf 0.65}$ & ${\bf 0.65}$ & ${\bf 0.62}$ \\
\textit{CIFAR-10}       & $0.10$ & $0.10$ & $0.10$ & $0.10$ && $0.10$ & $0.10$ & $0.10$ & $0.10$ && ${\bf 0.36}$ & ${\bf 0.36}$ & ${\bf 0.34}$ & ${\bf 0.35}$ \\
\textit{CIFAR-100}      & $0.01$ & $0.01$ & $0.01$ & $0.01$ && $0.01$ & $0.01$ & $0.01$ & $0.01$ && ${\bf 0.08}$ & ${\bf 0.09}$ & ${\bf 0.08}$ & ${\bf 0.09}$ \\
\bottomrule
\end{tabular}
}
\end{table*}


%\begin{table*}[htb!]
%\centering
%%\vspace{-2mm}
%\caption{Accuracy of the global model using FedAvg with FLDetector and FLANDERS ($r=0.8$).}
%\label{tab:increment-fld-80}
%%\vspace{2mm}
%\scalebox{1}{
%\begin{tabular}{ccccccccccccccc}
%\toprule
%& \multicolumn{4}{c}{\textbf{FedAvg}} & \phantom{a} & \multicolumn{4}{c}{\textbf{FLDetector + FedAvg}} & \phantom{a} & \multicolumn{4}{c}{\textbf{FLANDERS + FedAvg}} \\
%\cmidrule(lr){2-5} \cmidrule(lr){7-10} \cmidrule(lr){12-15}
%                    &  GAUSS    &  LIE     &  OPT     &  AGR-MM  &&  GAUSS   &  LIE     &  OPT     &  AGR-MM  &&  GAUSS    &  LIE     &  OPT     &  AGR-MM      \\ 
%\midrule
%\textit{MNIST}          & $0.18$ & $0.11$ & $0.21$ & $0.11$ && $0.15$ & $0.13$ & $0.23$ & $0.12$ && ${\bf 0.75}$ & ${\bf 0.84}$ & ${\bf 0.84}$ & ${\bf 0.82}$ \\
%\textit{Fashion-MNIST}  & $0.24$ & $0.10$ & $0.19$ & $0.10$ && $0.19$ & $0.10$ & $0.03$ & $0.10$ && ${\bf 0.68}$ & ${\bf 0.70}$ & ${\bf 0.66}$ & ${\bf 0.66}$ \\
%\textit{CIFAR-10}       & $0.10$ & $0.10$ & $0.11$ & $0.10$ && $0.10$ & $0.10$ & $0.10$ & $0.10$ && ${\bf 0.33}$ & ${\bf 0.32}$ & ${\bf 0.32}$ & ${\bf 0.32}$ \\
%\textit{CIFAR-100}      & $0.01$ & $0.01$ & $0.01$ & $0.01$ && $0.01$ & $0.01$ & $0.01$ & $0.01$ && ${\bf 0.09}$ & ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.10}$ \\
%\bottomrule
%\end{tabular}
%}
%\end{table*}

%\begin{table*}[htb!]
%\centering
%%\vspace{-2mm}
%\caption{Accuracy of the global model on \textit{CIFAR-100} using all the baseline aggregation methods without and with FLANDERS ($r=0.8$). The best results are typed in boldface.}
%\label{tab:increment-cifar100-80}
%%\vspace{2mm}
%\scalebox{0.9}{
%\begin{tabular}{|c|cccc|}
%\hline
%\multirow{2}{*}{\textbf{Aggregation}} & \multicolumn{4}{c|}{\textit{CIFAR-100}} \\
%\cline{2-5}
%            &  GAUSS        &  LIE          &  OPT          &  AGR-MM      \\ 
%\hline
%FedAvg      & $0.01$ & $0.01$ & $0.01$ & $0.01$ \\
%+ FLANDERS  & ${\bf 0.09}$ & ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.10}$ \\
%\hline
%FedMedian   & $0.01$ & $0.01$ & $0.01$ & $0.01$ \\
%+ FLANDERS  & ${\bf 0.10}$ & ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.10}$ \\
%\hline
%TrimmedMean & $0.01$ & $0.01$ & $0.01$ & $0.01$ \\
%+ FLANDERS  & ${\bf 0.11}$ & ${\bf 0.10}$ & ${\bf 0.11}$ & ${\bf 0.11}$ \\
%\hline
%Multi-Krum  & $0.08$ & $0.01$ & $0.01$ & $0.01$ \\
%+ FLANDERS  & ${\bf 0.11}$ & ${\bf 0.10}$ & ${\bf 0.10}$ & ${\bf 0.11}$ \\
%\hline
%Bulyan      & N/A & N/A & N/A & N/A \\
%+ FLANDERS  & ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.11}$ \\
%\hline
%DnC         & $0.01$ & $0.01$ & $0.01$ & $0.01$ \\
%+ FLANDERS  & ${\bf 0.10}$ & ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.12}$ \\
%\hline
%\end{tabular}
%}
%\end{table*}

Finally, Tables~\ref{tab:increment-20}, and \ref{tab:increment-60} illustrate the impact of FLANDERS on the global model's accuracy under light ($r=0.2$) and severe ($r=0.6$) attack settings.

\begin{table*}[htb!]
\centering
%\vspace{-2mm}
\caption{Accuracy of the global model using all the baseline aggregation methods without and with FLANDERS ($r=0.2$). The best results are typed in boldface.}
\label{tab:increment-20}
%\vspace{2mm}
\scalebox{0.75}{
\begin{tabular}{cccccccccccccccccccc}
\toprule
& \multicolumn{4}{c}{\textit{MNIST}} & \phantom{a} & \multicolumn{4}{c}{\textit{Fashion-MNIST}} & \phantom{a} & \multicolumn{4}{c}{\textit{CIFAR-10}} & \phantom{a} & \multicolumn{4}{c}{\textit{CIFAR-100}} \\
\cmidrule(lr){2-5} \cmidrule(lr){7-10} \cmidrule(lr){12-15} \cmidrule(lr){17-20}
              &  GAUSS        &  LIE          &  OPT          &  AGR-MM       &&  GAUSS        &  LIE          &  OPT          &  AGR-MM       &&  GAUSS         &  LIE          &  OPT          &  AGR-MM        &&  GAUSS         &  LIE          &  OPT          &  AGR-MM      \\ 
\midrule
FedAvg        &  $0.18$       &  $0.12$       &  ${\bf 0.63}$ &  $0.34$       &&  $0.25$       & $0.10$        &  $0.56$       &  $0.16$       &&  $0.10$       &  $0.10$       &  $0.23$       &  $0.10$       &&  $0.01$       &  $0.01$       &  $0.01$       &  $0.02$  \\
+ FLANDERS    &  ${\bf 0.86}$ &  ${\bf 0.83}$ &  $0.62$       &  ${\bf 0.85}$ &&  ${\bf 0.69}$ & ${\bf 0.64}$  &  ${\bf 0.58}$ &  ${\bf 0.63}$ &&  ${\bf 0.38}$ &  ${\bf 0.37}$ &  ${\bf 0.28}$ &  ${\bf 0.36}$ &&  ${\bf 0.07}$ &  ${\bf 0.05}$ &  ${\bf 0.05}$ &  ${\bf 0.06}$  \\
\midrule
FedMedian     &  ${\bf 0.81}$ &  $0.57$       &  ${\bf 0.61}$ &  $0.63$       &&  $0.70$       &  $0.63$       &  ${\bf 0.68}$ &  $0.62$       &&  ${\bf 0.34}$ &  $0.24$       &  ${\bf 0.24}$ &  $0.21$       &&  $0.01$       &  $0.04$       &  $0.01$       &  $0.03$  \\
+ FLANDERS    &  ${\bf 0.81}$ &  ${\bf 0.86}$ &  $0.58$       &  ${\bf 0.85}$ &&  ${\bf 0.71}$ &  ${\bf 0.73}$ &  $0.64$       &  ${\bf 0.72}$ &&  ${\bf 0.34}$ &  ${\bf 0.28}$ &  $0.17$       &  ${\bf 0.32}$ &&  ${\bf 0.10}$       &  ${\bf 0.10}$ &  ${\bf 0.10}$ &  ${\bf 0.11}$  \\
\midrule
TrimmedMean   &  $0.78$       &  $0.57$       &  ${\bf 0.76}$ &  $0.48$       &&  $0.65$       &  $0.58$       &  $0.61$       &  $0.55$       &&  ${\bf 0.35}$ &  $0.24$       &  ${\bf 0.23}$ &  $0.23$       &&  $0.01$       &  $0.03$       &  $0.01$       &  $0.03$  \\
+ FLANDERS    &  ${\bf 0.83}$ &  ${\bf 0.82}$ &  $0.75$       &  ${\bf 0.77}$ &&  ${\bf 0.69}$ &  ${\bf 0.69}$ &  ${\bf 0.63}$ &  ${\bf 0.70}$ &&  ${\bf 0.35}$ &  ${\bf 0.33}$ &  $0.22$       &  ${\bf 0.35}$ &&  ${\bf 0.11}$       &  ${\bf 0.10}$ &  ${\bf 0.10}$ &  ${\bf 0.10}$  \\
\midrule
Multi-Krum    &  $0.73$       &  ${\bf 0.86}$ &  $0.83$       &  ${\bf 0.80}$ &&  ${\bf 0.66}$ &  ${\bf 0.67}$ &  $0.65$       &  $0.64$       &&  $0.36$       &  $0.35$       &  $0.27$       &  $0.34$       &&  $0.07$       &  $0.06$       &  $0.07$       &  $0.07$  \\
+ FLANDERS    &  ${\bf 0.87}$ &  $0.85$       &  ${\bf 0.85}$ &  $0.77$       &&  $0.65$       &  $0.64$       &  ${\bf 0.69}$ &  ${\bf 0.66}$ &&  ${\bf 0.42}$ &  ${\bf 0.44}$ &  ${\bf 0.35}$ &  ${\bf 0.42}$ &&  ${\bf 0.10}$ &  ${\bf 0.09}$ &  ${\bf 0.10}$ &  ${\bf 0.09}$  \\
\midrule
Bulyan        &  $0.81$       &  ${\bf 0.88}$ &  ${\bf 0.85}$ &  $0.84$       &&  ${\bf 0.67}$ &  ${\bf 0.72}$ &  ${\bf 0.70}$ &  ${\bf 0.76}$ &&  $0.40$       &  $0.39$       &  $0.34$       &  $0.39$       &&  ${\bf 0.10}$ &  ${\bf 0.10}$ &  ${\bf 0.10}$ &  ${\bf 0.08}$  \\
+ FLANDERS    &  ${\bf 0.83}$ &  ${\bf 0.88}$ &  $0.84$       &  ${\bf 0.87}$ &&  $0.62$       &  $0.66$       &  $0.66$       &  $0.68$       &&  ${\bf 0.43}$ &  ${\bf 0.43}$ &  ${\bf 0.36}$ &  ${\bf 0.42}$ &&  $0.07$       &  $0.06$       &  $0.06$       &  ${\bf 0.08}$  \\
\midrule
DnC           &  $0.20$       &  $0.14$       &  ${\bf 0.69}$ &  $0.30$       &&  $0.25$       &  $0.18$       &  $0.59$       &  $0.17$       &&  $0.11$       &  $0.10$       &  $0.27$       &  $0.15$       &&  $0.01$       &  $0.01$       &  $0.01$       &  $0.02$  \\
+ FLANDERS    &  ${\bf 0.88}$ &  ${\bf 0.87}$ &  $0.65$       &  ${\bf 0.88}$ &&  ${\bf 0.61}$ &  ${\bf 0.64}$ &  ${\bf 0.62}$ &  ${\bf 0.66}$ &&  ${\bf 0.43}$ &  ${\bf 0.44}$ &  ${\bf 0.34}$ &  ${\bf 0.43}$ &&  ${\bf 0.07}$ &  ${\bf 0.07}$ &  ${\bf 0.07}$ &  ${\bf 0.08}$  \\
\bottomrule
\end{tabular}
}
\end{table*}

%\begin{table*}[htb!]
%\centering
%%\vspace{-2mm}
%\caption{Accuracy of the global model using all the baseline aggregation methods without and with FLANDERS on \textit{MNIST} and \textit{Fashion-MNIST} ($r=0.2$). The best results are typed in boldface.}
%\label{tab:increment-20-mnist-fmnist}
%%\vspace{2mm}
%%\scalebox{0.8}{
%\begin{tabular}{|c|cccc|cccc|}
%\hline
%\multirow{2}{*}{\textbf{Aggregation}} & \multicolumn{4}{c|}{\textit{MNIST}} & \multicolumn{4}{c|}{\textit{Fashion-MNIST}} \\
%\cline{2-9}
%              &  GAUSS         &  LIE          &  OPT          &  AGR-MM       &  GAUSS        &  LIE          &  OPT          &  AGR-MM      \\ 
%\hline
%FedAvg        &  $0.18$       &  $0.12$       &  ${\bf 0.63}$ &  $0.34$       &  $0.25$       & $0.10$        &  $0.56$       &  $0.16$       \\
%+ FLANDERS    &  ${\bf 0.86}$ &  ${\bf 0.83}$ &  $0.62$       &  ${\bf 0.85}$ &  ${\bf 0.69}$ & ${\bf 0.64}$  &  ${\bf 0.58}$ &  ${\bf 0.63}$ \\
%\hline
%FedMedian     &  ${\bf 0.81}$ &  $0.57$       &  ${\bf 0.61}$ &  $0.63$       &  $0.70$       &  $0.63$       &  ${\bf 0.68}$ &  $0.62$       \\
%+ FLANDERS    &  ${\bf 0.81}$ &  ${\bf 0.86}$ &  $0.58$       &  ${\bf 0.85}$ &  ${\bf 0.71}$ &  ${\bf 0.73}$ &  $0.64$       &  ${\bf 0.72}$ \\
%\hline
%TrimmedMean   &  $0.78$       &  $0.57$       &  ${\bf 0.76}$ &  $0.48$       &  $0.65$       &  $0.58$       &  $0.61$       &  $0.55$       \\
%+ FLANDERS    &  ${\bf 0.83}$ &  ${\bf 0.82}$ &  $0.75$       &  ${\bf 0.77}$ &  ${\bf 0.69}$ &  ${\bf 0.69}$ &  ${\bf 0.63}$ &  ${\bf 0.70}$ \\
%\hline
%Multi-Krum    &  $0.73$       &  ${\bf 0.86}$ &  $0.83$       &  ${\bf 0.80}$ &  ${\bf 0.66}$ &  ${\bf 0.67}$ &  $0.65$       &  $0.64$       \\
%+ FLANDERS    &  ${\bf 0.87}$ &  $0.85$       &  ${\bf 0.85}$ &  $0.77$       &  $0.65$       &  $0.64$       &  ${\bf 0.69}$ &  ${\bf 0.66}$ \\
%\hline
%Bulyan        &  $0.81$       &  ${\bf 0.88}$ &  ${\bf 0.85}$ &  $0.84$       &  ${\bf 0.67}$ &  ${\bf 0.72}$ &  ${\bf 0.70}$ &  ${\bf 0.76}$ \\
%+ FLANDERS    &  ${\bf 0.83}$ &  ${\bf 0.88}$ &  $0.84$       &  ${\bf 0.87}$ &  $0.62$       &  $0.66$       &  $0.66$       &  $0.68$       \\
%\hline
%DnC           &  $0.20$       &  $0.14$       &  ${\bf 0.69}$ &  $0.30$       &  $0.25$       &  $0.18$       &  $0.59$       &  $0.17$       \\
%+ FLANDERS    &  ${\bf 0.88}$ &  ${\bf 0.87}$ &  $0.65$       &  ${\bf 0.88}$ &  ${\bf 0.61}$ &  ${\bf 0.64}$ &  ${\bf 0.62}$ &  ${\bf 0.66}$ \\
%\hline
%\end{tabular}
%%}
%\end{table*}

%\begin{table*}[htb!]
%\centering
%%\vspace{-2mm}
%\caption{Accuracy of the global model using all the baseline aggregation methods without and with FLANDERS on \textit{CIFAR-10} and \textit{CIFAR-100} ($r=0.2$). The best results are typed in boldface.}
%\label{tab:increment-20-cifar10-cifar100}
%%\vspace{2mm}
%%\scalebox{0.8}{
%\begin{tabular}{|c|cccc|cccc|}
%\hline
%\multirow{2}{*}{\textbf{Aggregation}} & \multicolumn{4}{c|}{\textit{CIFAR-10}} & \multicolumn{4}{c|}{\textit{CIFAR-100}} \\
%\cline{2-9}
%              &  GAUSS         &  LIE          &  OPT          &  AGR-MM       &  GAUSS        &  LIE          &  OPT          &  AGR-MM      \\ 
%\hline
%FedAvg        &  $0.10$       &  $0.10$       &  $0.23$       &  $0.10$       &  $0.01$       &  $0.01$       &  $0.01$       &  $0.02$ \\
%+ FLANDERS    &  ${\bf 0.38}$ &  ${\bf 0.37}$ &  ${\bf 0.28}$ &  ${\bf 0.36}$ &  ${\bf 0.07}$ &  ${\bf 0.05}$ &  ${\bf 0.05}$ &  ${\bf 0.06}$ \\
%\hline
%FedMedian     &  ${\bf 0.34}$ &  $0.24$       &  ${\bf 0.24}$ &  $0.21$       &  $0.01$       &  $0.04$       &  $0.01$       &  $0.03$ \\
%+ FLANDERS    &  ${\bf 0.34}$ &  ${\bf 0.28}$ &  $0.17$       &  ${\bf 0.32}$ &  ${\bf 0.10}$       &  ${\bf 0.10}$ &  ${\bf 0.10}$ &  ${\bf 0.11}$ \\
%\hline
%TrimmedMean   &  ${\bf 0.35}$ &  $0.24$       &  ${\bf 0.23}$ &  $0.23$       &  $0.01$       &  $0.03$       &  $0.01$       &  $0.03$ \\
%+ FLANDERS    &  ${\bf 0.35}$ &  ${\bf 0.33}$ &  $0.22$       &  ${\bf 0.35}$ &  ${\bf 0.11}$       &  ${\bf 0.10}$ &  ${\bf 0.10}$ &  ${\bf 0.10}$ \\
%\hline
%Multi-Krum    &  $0.36$       &  $0.35$       &  $0.27$       &  $0.34$       &  $0.07$       &  $0.06$       &  $0.07$       &  $0.07$ \\
%+ FLANDERS    &  ${\bf 0.42}$ &  ${\bf 0.44}$ &  ${\bf 0.35}$ &  ${\bf 0.42}$ &  ${\bf 0.10}$ &  ${\bf 0.09}$ &  ${\bf 0.10}$ &  ${\bf 0.09}$ \\
%\hline
%Bulyan        &  $0.40$       &  $0.39$       &  $0.34$       &  $0.39$       &  ${\bf 0.10}$ &  ${\bf 0.10}$ &  ${\bf 0.10}$ &  ${\bf 0.08}$ \\
%+ FLANDERS    &  ${\bf 0.43}$ &  ${\bf 0.43}$ &  ${\bf 0.36}$ &  ${\bf 0.42}$ &  $0.07$       &  $0.06$       &  $0.06$       &  ${\bf 0.08}$ \\
%\hline
%DnC           &  $0.11$        &  $0.10$       &  $0.27$       &  $0.15$       &  $0.01$       &  $0.01$       &  $0.01$       &  $0.02$ \\
%+ FLANDERS    &  ${\bf 0.43}$       &  ${\bf 0.44}$ &  ${\bf 0.34}$ &  ${\bf 0.43}$ &  ${\bf 0.07}$ &  ${\bf 0.07}$ &  ${\bf 0.07}$ &  ${\bf 0.08}$ \\
%\hline
%\end{tabular}
%%}
%\end{table*}

\begin{table*}[htb!]
\centering
%\vspace{-2mm}
\caption{Accuracy of the global model using all the baseline aggregation methods without and with FLANDERS ($r=0.6$). The best results are typed in boldface.}
\label{tab:increment-60}
%\vspace{2mm}
\scalebox{0.75}{
\begin{tabular}{cccccccccccccccccccc}
\toprule
& \multicolumn{4}{c}{\textit{MNIST}} & \phantom{a} & \multicolumn{4}{c}{\textit{Fashion-MNIST}} & \phantom{a} & \multicolumn{4}{c}{\textit{CIFAR-10}} & \phantom{a} & \multicolumn{4}{c}{\textit{CIFAR-100}} \\
\cmidrule(lr){2-5} \cmidrule(lr){7-10} \cmidrule(lr){12-15} \cmidrule(lr){17-20}
              &  GAUSS        &  LIE          &  OPT          &  AGR-MM       &&  GAUSS        &  LIE          &  OPT          &  AGR-MM       &&  GAUSS         &  LIE          &  OPT          &  AGR-MM        &&  GAUSS         &  LIE          &  OPT          &  AGR-MM      \\ 
\midrule
FedAvg      & $0.18$        & $0.12$        & $0.16$        & $0.15$        && $0.28$       & $0.10$        & $0.18$        & $0.10$        && $0.10$       & $0.10$        & $0.10$        && $0.10$       & $0.01$       & $0.01$    & $0.01$      & $0.01$ \\
+ FLANDERS  & ${\bf 0.78}$  & ${\bf 0.82}$  & ${\bf 0.79}$  & ${\bf 0.85}$  && ${\bf 0.69}$ & ${\bf 0.65}$  & ${\bf 0.65}$  & ${\bf 0.62}$  && ${\bf 0.36}$ & ${\bf 0.36}$  & ${\bf 0.34}$  && ${\bf 0.35}$ & ${\bf 0.08}$ & ${\bf 0.09}$ & ${\bf 0.08}$ & ${\bf 0.09}$ \\ 
\midrule
FedMedian   & ${\bf 0.84}$  & $0.18$        & $0.12$        & $0.16$        && $0.70$       & $0.10$        & $0.13$        & $0.10$        && ${\bf 0.34}$ & $0.10$        & $0.11$        && $0.10$   & $0.01$         & $0.01$        & $0.01$    & $0.01$ \\
+ FLANDERS  & $0.73$        & ${\bf 0.81}$  & ${\bf 0.83}$  & $0{\bf .82}$  && ${\bf 0.72}$ & ${\bf 0.73}$  & ${\bf 0.71}$  & ${\bf 0.72}$  && $0.31$       & ${\bf 0.31}$  & ${\bf 0.30}$  && ${\bf 0.33}$ & ${\bf 0.11}$ & ${\bf 0.10}$ & ${\bf 0.11}$ & ${\bf 0.10}$ \\
\midrule
TrimmedMean & $0.22$        & $0.12$        & $0.21$        & $0.13$        && $0.33$       & $0.10$        & $0.18$        & $0.10$        && $0.12$       & $0.10$        & $0.10$        && $0.10$       & $0.01$       & $0.01$    & $0.01$      & $0.01$ \\
+ FLANDERS  & ${\bf 0.76}$  & ${\bf 0.83}$  & ${\bf 0.83}$  & ${\bf 0.78}$  && ${\bf 0.72}$ & ${\bf 0.70}$  & ${\bf 0.71}$  & ${\bf 0.68}$  && ${\bf 0.35}$ & ${\bf 0.28}$  & ${\bf 0.33}$  && ${\bf 0.29}$ & ${\bf 0.10}$ & ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.12}$ \\
\midrule
Multi-Krum  & $0.85$        & $0.24$        & $0.27$        & $0.12$        && $0.65$       & $0.10$        & $0.11$        & $0.10$        && $0.10$       & $0.35$        & $0.10$        && $0.13$       & $0.09$       & $0.01$    & $0.01$      & $0.01$ \\
+ FLANDERS  & ${\bf 0.89}$  & ${\bf 0.84}$  & ${\bf 0.84}$  & ${\bf 0.88}$  && ${\bf 0.71}$ & ${\bf 0.70}$  & ${\bf 0.68}$  & ${\bf 0.67}$  && ${\bf 0.41}$ & ${\bf 0.40}$  & ${\bf 0.40}$  && ${\bf 0.40}$ & ${\bf 0.12}$ & ${\bf 0.12}$ & ${\bf 0.11}$ & ${\bf 0.10}$ \\
\midrule
Bulyan      & N/A           & N/A           & N/A           & N/A           && N/A          & N/A           & N/A           & N/A           && N/A          & N/A           & N/A           && N/A & N/A & N/A & N/A & N/A \\
+ FLANDERS  & ${\bf 0.86}$  & ${\bf 0.87}$  & ${\bf 0.81}$  & ${\bf 0.88}$  && ${\bf 0.65}$ & ${\bf 0.69}$  & ${\bf 0.66}$  & ${\bf 0.67}$  && ${\bf 0.43}$ & ${\bf 0.41}$  & ${\bf 0.42}$  && ${\bf 0.42}$ & ${\bf 0.09}$ & ${\bf 0.08}$ & ${\bf 0.10}$ & ${\bf 0.08}$ \\
\midrule
DnC         & $0.19$        & $0.10$        & $0.33$        & $0.24$        && $0.28$       & $0.10$        & $0.12$        & $0.10$        && $0.10$       & $0.10$        & $0.10$        && $0.11$       & $0.01$       & $0.01$    & $0.01$      & $0.01$ \\
+ FLANDERS  & ${\bf 0.89}$  & ${\bf 0.84}$  & ${\bf 0.88}$  & ${\bf 0.85}$  && ${\bf 0.66}$ & ${\bf 0.65}$  & ${\bf 0.68}$  & ${\bf 0.66}$  && ${\bf 0.42}$ & ${\bf 0.42}$  & ${\bf 0.42}$  && ${\bf 0.42}$ & ${\bf 0.09}$ & ${\bf 0.09}$ & ${\bf 0.09}$ & ${\bf 0.10}$ \\
\bottomrule
\end{tabular}
}
\end{table*}

%\begin{table*}[htb!]
%\centering
%%\vspace{-2mm}
%\caption{Accuracy of the global model using all the baseline aggregation methods without and with FLANDERS on \textit{CIFAR-10} and \textit{CIFAR-100} ($r=0.6$). The best results are typed in boldface.}
%\label{tab:increment-60-cifar10-cifar100}
%%\vspace{2mm}
%%\scalebox{0.8}{
%\begin{tabular}{|c|cccc|cccc|}
%\hline
%\multirow{2}{*}{\textbf{Aggregation}} & \multicolumn{4}{c|}{\textit{CIFAR-10}} & \multicolumn{4}{c|}{\textit{CIFAR-100}} \\
%\cline{2-9}
%              &  GAUSS         &  LIE          &  OPT          &  AGR-MM       &  GAUSS        &  LIE          &  OPT          &  AGR-MM      \\ 
%\hline
%FedAvg      & $0.10$ & $0.10$ & $0.10$ & $0.10$ & $0.01$ & $0.01$ & $0.01$ & $0.01$ \\
%+ FLANDERS  & ${\bf 0.36}$ & ${\bf 0.36}$ & ${\bf 0.34}$ & ${\bf 0.35}$ & ${\bf 0.08}$ & ${\bf 0.09}$ & ${\bf 0.08}$ & ${\bf 0.09}$ \\
%\hline
%FedMedian   & ${\bf 0.34}$ & $0.10$ & $0.11$ & $0.10$ & $0.01$ & $0.01$ & $0.01$ & $0.01$ \\
%+ FLANDERS  & $0.31$ & ${\bf 0.31}$ & ${\bf 0.30}$ & ${\bf 0.33}$ & ${\bf 0.11}$ & ${\bf 0.10}$ & ${\bf 0.11}$ & ${\bf 0.10}$ \\
%\hline
%TrimmedMean & $0.12$ & $0.10$ & $0.10$ & $0.10$ & $0.01$ & $0.01$ & $0.01$ & $0.01$ \\
%+ FLANDERS  & ${\bf 0.35}$ & ${\bf 0.28}$ & ${\bf 0.33}$ & ${\bf 0.29}$ & ${\bf 0.10}$ & ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.12}$ \\
%\hline
%Multi-Krum  & $0.10$ & $0.35$ & $0.10$ & $0.13$ & $0.09$ & $0.01$ & $0.01$ & $0.01$ \\
%+ FLANDERS  & ${\bf 0.41}$ & ${\bf 0.40}$ & ${\bf 0.40}$ & ${\bf 0.40}$ & ${\bf 0.12}$ & ${\bf 0.12}$ & ${\bf 0.11}$ & ${\bf 0.10}$ \\
%\hline
%Bulyan      & N/A & N/A & N/A & N/A & N/A & N/A & N/A & N/A \\
%+ FLANDERS  & ${\bf 0.43}$ & ${\bf 0.41}$ & ${\bf 0.42}$ & ${\bf 0.42}$ & ${\bf 0.09}$ & ${\bf 0.08}$ & ${\bf 0.10}$ & ${\bf 0.08}$ \\
%\hline
%DnC         & $0.10$ & $0.10$ & $0.10$ & $0.11$ & $0.01$ & $0.01$ & $0.01$ & $0.01$ \\
%+ FLANDERS  & ${\bf 0.42}$ & ${\bf 0.42}$ & ${\bf 0.42}$ & ${\bf 0.42}$ & ${\bf 0.09}$ & ${\bf 0.09}$ & ${\bf 0.09}$ & ${\bf 0.10}$ \\
%\hline
%\end{tabular}
%%}
%\end{table*}


%%% MOVED TO THE TOP
%Finally, in Table~\ref{tab:increment-0}, we also assess the impact of FLANDERS in an attack-free scenario (i.e., when $r=0$). In this setting, no clear winning strategy emerges. Sometimes, FLANDERS has a detrimental effect on the global model's accuracy with a standard aggregation mechanism (e.g., see FedAvg with the \textit{MNIST} dataset). In other instances, however, FLANDERS improves the global model's accuracy when paired with robust aggregation schemes (e.g., see Bulyan with the \textit{MNIST} dataset).

%\begin{table*}[htb!]
%\centering
%\caption{Accuracy of the global model using FedAvg coupled with FLDetector and FLANDERS on CIFAR-100 ($r = 0.2$).}
%\label{tab:increment-fld-cifar100}
%%\vspace{2mm}
%\scalebox{0.9}{
%\begin{tabular}{|c|cccc|}
%\hline
%\multirow{2}{*}{\textbf{Aggregation}} & \multicolumn{4}{c|}{\textit{CIFAR-100}} \\
%\cline{2-5}
%                    &  GAUSS         &  LIE          &  OPT          &  AGR-MM   \\ 
%\hline
%FedAvg              & $0.01$ & $0.01$ & $0.01$ & $0.02$ \\
%FLDetector + FedAvg & $0.01$ & $0.01$ & $0.01$ & $0.02$ \\
%FLANDERS + FedAvg   & ${\bf 0.07}$ & ${\bf 0.05}$ & ${\bf 0.05}$ & ${\bf 0.06}$ \\
%\hline
%\end{tabular}
%}
%\end{table*}

%\begin{table}[htb!]
%\centering
%%\vspace{-2mm}
%\caption{Accuracy of the global model using all the baseline aggregation methods without and with FLANDERS ($r=0$). The best results are typed in boldface.}
%\label{tab:increment-0}
%%\vspace{2mm}
%\scalebox{1}{
%\begin{tabular}{ccccc}
%\toprule
%& \multicolumn{1}{c}{\textit{MNIST}} & \multicolumn{1}{c}{\textit{Fashion-MNIST}} & \multicolumn{1}{c}{\textit{CIFAR-10}} & \multicolumn{1}{c}{\textit{CIFAR-100}} \\
%\midrule
%FedAvg                  & ${\bf 0.86}$ & $0.63$ & $0.35$ & ${\bf 0.06}$ \\
%+ FLANDERS              & $0.83$ & ${\bf 0.68}$ & ${\bf 0.36}$ & $0.05$ \\
%\midrule
%FedMedian               & ${\bf 0.84}$ & ${\bf 0.71}$ & $0.31$ & ${\bf 0.10}$ \\
%+ FLANDERS              & $0.78$ & $0.68$ & ${\bf 0.33}$ & ${\bf 0.10}$ \\
%\midrule
%TrimmedMean             & ${\bf 0.82}$ & $0.69$ & ${\bf 0.33}$ & ${\bf 0.12}$ \\
%+ FLANDERS              & $0.80$ & ${\bf 0.70}$ & $0.32$ & $0.11$ \\
%\midrule
%MultiKrum               & $0.72$ & ${\bf 0.65}$ & $0.34$ & $0.05$ \\
%+ FLANDERS              & ${\bf 0.80}$ & $0.64$ & ${\bf 0.44}$ & ${\bf 0.08}$ \\
%\midrule
%Bulyan                  & $0.85$ & $0.65$ & ${\bf 0.43}$ & $0.05$ \\
%+ FLANDERS              & ${\bf 0.90}$ & ${\bf 0.70}$ & $0.42$ & ${\bf 0.06}$ \\
%\midrule
%DnC                     & $0.81$ & $0.62$ & ${\bf 0.44}$ & $0.06$ \\
%+ FLANDERS              & ${\bf 0.86}$ & ${\bf 0.64}$ & ${\bf 0.44}$ & ${\bf 0.07}$ \\
%\bottomrule
%\end{tabular}
%}
%\end{table}





\begin{table*}[htb!]
\centering
\caption{Accuracy of the global model using Multi-Krum + FLANDERS over various numbers of malicious clients.}
\label{tab:robustness-1}
%\vspace{2mm}
\scalebox{1}{
\begin{tabular}{cccccccccccccccccccc}
\toprule
& \multicolumn{4}{c}{\textit{MNIST}} & \phantom{a} & \multicolumn{4}{c}{\textit{Fashion-MNIST}} & \phantom{a} & \multicolumn{4}{c}{\textit{CIFAR-10}} & \phantom{a} & \multicolumn{4}{c}{\textit{CIFAR-100}} \\
\cmidrule(lr){2-5} \cmidrule(lr){7-10} \cmidrule(lr){12-15} \cmidrule(lr){17-20}
        & 0      & 20     & 60     & 80     && 0      & 20     & 60     & 80     && 0      & 20     & 60     & 80     && 0      & 20     & 60     & 80     \\ 
\midrule
GAUSS   & $0.80$ & $0.87$ & $0.89$ & $0.87$ && $0.64$ & $0.65$ & $0.71$ & $0.69$ && $0.44$ & $0.42$ & $0.41$ & $0.38$ && $0.08$ & $0.10$ & $0.12$ & $0.11$ \\
LIE     & $0.80$ & $0.85$ & $0.84$ & $0.90$ && $0.64$ & $0.64$ & $0.70$ & $0.68$ && $0.44$ & $0.44$ & $0.40$ & $0.38$ && $0.08$ & $0.09$ & $0.12$ & $0.10$ \\
OPT     & $0.80$ & $0.85$ & $0.84$ & $0.88$ && $0.64$ & $0.69$ & $0.68$ & $0.72$ && $0.44$ & $0.35$ & $0.40$ & $0.39$ && $0.08$ & $0.10$ & $0.11$ & $0.10$ \\
AGR-MM  & $0.80$ & $0.77$ & $0.88$ & $0.89$ && $0.64$ & $0.66$ & $0.67$ & $0.68$ && $0.44$ & $0.42$ & $0.40$ & $0.40$ && $0.08$ & $0.09$ & $0.10$ & $0.11$ \\
\bottomrule
\end{tabular}
}
%\vspace{-4mm}
\end{table*}

%%% BACK TO EXP SEC FOR SATML
%In Figure~\ref{fig:accuracy-over-time} we compare the accuracy of the global model when using FLANDERS (left) and when using FedAvg (right). The left figure shows how the evolution of the accuracy over multiple rounds remains stable and similar to the one without any attack (dashed line), while on the right the accuracy drops irremediably.
%
%\begin{figure}[htb!]%{0.4\textwidth}
%     \centering
%     \includegraphics[width=\columnwidth]{./img/accuracy-over-time-mnist-5}
%     \caption{FedAvg with FLANDERS (left) vs. "vanilla" FedAvg (right). Accuracy of the global model in each FL round under all attack strategies on the \textit{MNIST} dataset, with $80\%$ of malicious clients. Attack starts at round $t=3$.}
%     \label{fig:accuracy-over-time}
%     %\vspace{-6mm}
%\end{figure}

%%% BACK TO EXP SEC FOR SATML
%\subsection{Cost-Benefit Analysis}
%\label{app:cost-benefit}
%Below, we report the cost-benefit analysis described in Section~\ref{subsec:eval}. 
%Specifically, Figure~\ref{fig:tradeoff} shows the trade-off between the global model's accuracy and its training time on the \textit{MNIST} and \textit{CIFAR-10} datasets when using FedAvg and Bulyan aggregation without and with FLANDERS as a filter.
%In general, FLANDERS introduces an overhead in the training time, which is, however, compensated by the increased level of accuracy.
%
%%\edo{Note that the training times of the new machines are way lower (FLANDERS+MultiKrum, gauss, 20\% malicious 162s, lie 103s, agr-mm 339s)}
%
%\begin{figure}[htb!]%{0.4\textwidth}
%     \centering
%     \includegraphics[width=\columnwidth]{./img/tradeoff}
%     \caption{Accuracy vs. training time of FedAvg and Bulyan compared with their corresponding versions with FLANDERS as a filter for the \textit{MNIST} (left) and \textit{CIFAR-10} (right) datasets.}
%     \label{fig:tradeoff}
%     %\vspace{-6mm}
%\end{figure}

%\subsection{Robustness against Adaptive Attacks}
%\label{app:adaptive-attacks}
%In this section, we further validate the robustness of FLANDERS against adaptive attacks. We consider a scenario where malicious clients are aware that the FL server uses our method as a pre-aggregation filter. 
%Specifically, we focus on two levels of knowledge. The first scenario assumes that malicious clients tentatively guess the subset of parameters ($\widetilde{d}$) used by the FL server to estimate the MAR forecasting model. We refer to this setting as \textit{non-omniscient}.
%The second, more challenging as well as unrealistic scenario assumes that malicious clients know \textit{exactly} which parameters are used by the FL server. We call this second scenario \textit{omniscient}. Obviously, the latter penalizes FLANDERS way more than the former. 
%\\
%Specifically, we perform our experiments over $T=20$ rounds with $m=20$ clients, of which $r=0.2$ ($b=5$) are malicious. The attacker constructs a matrix $M = b \times \widetilde{d}$ using the local models generated by the corrupted clients. This matrix $M$ is then passed as input to the same forecasting model, MAR, that the server uses to determine the legitimacy of local models. The attacker, instead, substitutes the legitimate parameters with those estimated by MAR, exploiting the fact that these estimations do not perform like a legitimate local model. This substitution ultimately hurts the accuracy of the global model once the parameters are aggregated. 
%\\
%As introduced above, we first assume that the attacker is \textit{non-omniscient}, meaning it does not know which parameters the server has selected for the MAR estimation. Instead, the attacker selects the last layer as $\widetilde{d}$. 
%Afterward, we consider an \textit{omniscient} attacker who exploits the knowledge of the parameters selected by the server. 
%In Table~\ref{tab:nonomn-adaptive}, we show the results of the non-omniscient scenario, where FLANDERS + Multi-Krum outperforms all other baselines on all three datasets. Table~\ref{tab:omn-adaptive}, on the other hand, refers to the omniscient scenario and demonstrates a different pattern, where FedAvg and Multi-Krum alone perform better than when coupled with FLANDERS.
%This may be because FLANDERS consistently filters out legitimate local models in favor of corrupted ones. When using FedAvg, the impact of corrupted parameters is mitigated by averaging a larger number of legitimate models and because the corrupted models' parameter values are not too different, unlike in methods like OPT. On the other hand, Multi-Krum selects parameters with more nearby neighbors, and with only $b=5$ corrupted clients, legitimate models likely still have more and closer neighbors, effectively defending against our adaptive attack.
%
%\begin{table}[htb!]
%\centering
%\vspace{-2mm}
%\caption{Accuracy of the global model using FedAvg and Multi-Krum, with and without FLANDERS, under the \textit{\textbf{non-}omniscient} adaptive attack.}
%\label{tab:nonomn-adaptive}
%\begin{tabular}{|c|c|c|c|}
%    \hline
%    Strategy & \textit{MNIST} & \textit{Fashion-MNIST} & \textit{CIFAR-10} \\
%    \hline
%    FedAvg                  & $0.84$ & $0.68$ & $0.45$ \\
%    FLANDERS + FedAvg       & $0.82$ & $0.67$ & $0.43$ \\
%    %\hline
%    Multi-Krum              & $0.87$ & ${\bf 0.72}$ & $0.41$ \\
%    FLANDERS + Multi-Krum   & ${\bf 0.90}$ & ${\bf 0.72}$ & ${\bf 0.47}$ \\
%    \hline
%\end{tabular}
%\vspace{-4mm}
%\end{table}
%
%\begin{table}[htb!]
%\centering
%\caption{Accuracy of the global model using FedAvg and Multi-Krum, with and without FLANDERS, under the \textit{omniscient} adaptive attack.}
%\label{tab:omn-adaptive}
%\begin{tabular}{|c|c|c|c|}
%    \hline
%    Strategy & \textit{MNIST} & \textit{Fashion-MNIST} & \textit{CIFAR-10} \\
%    \hline
%    FedAvg                  & $0.78$ & ${\bf 0.68}$ & ${\bf 0.25}$ \\
%    FLANDERS + FedAvg       & $0.65$ & $0.61$ & $0.10$ \\
%    %\hline
%    Multi-Krum              & ${\bf 0.86}$ & ${\bf 0.68}$ & $0.23$ \\
%    FLANDERS + Multi-Krum   & $0.73$ & $0.60$ & $0.10$ \\
%    \hline
%\end{tabular}
%\end{table}

%\section{Limitations and Future Work}
%\label{app:limitations}
%The limitations of this work can be categorized into the following areas, which we intend to address in a forthcoming extension of this research.
%
%\subsection{Efficiency/Feasibility}
%%\textbf{\textit{Efficiency/Feasibility.}} 
%As we discussed in Section~5.3 of the main body and Appendix~\ref{app:defenses} above, FLANDERS may suffer from a high computational cost that could limit its deployment in practice.
%This concern holds particularly true for \textit{cross-device} FL configurations encompassing millions of edge devices. Conversely, the impact on \textit{cross-silo} FL scenarios would be notably less pronounced. 
%However, as we have introduced FLANDERS as a versatile and robust aggregation approach applicable to diverse FL setups (cross-silo and cross-device), there are implementation techniques available to mitigate its complexity. For instance, methods like random parameter sampling~\cite{shejwalkar2021ndss} can be employed, and we have already incorporated them.
%Still, we plan to enhance the scalability of FLANDERS further in future work. 
%For example, we could replace the standard matrix inversion algorithm with the more efficient Coppersmith-Winograd algorithm~\cite{coppersmith1990jsc} and find the optimal frequency for re-estimating FLANDERS' parameters, instead of performing it during each FL round.
%
%% \subsection{Adaptive Attacks}
%% Prior works proposing new FL robust aggregation schemes usually do not consider adaptive attacks explicitly tailored to evade the defense mechanism introduced. 
%% However, it is worth noting that some attacks considered in this work, such as LIE, OPT, and partially AGR-MM, can be thought of as ``adaptive'', even though they are not specifically designed to evade FLANDERS. 
%% For example, OPT~\cite{fang2020usenix} employs a sophisticated and minimal alteration of model parameters in its crafting of model poisoning attacks. Consequently, defense strategies based on outlier detection like FLANDERS, implemented at the server's end, could, in principle, be circumvented by OPT's approach. 
%% To further support this claim, it is noteworthy that FLTrust~\cite{cao2020fltrust} also classifies OPT as an adaptive attack, in line with the authors' assertion~\cite{fang2020usenix} that OPT's effectiveness extends not only to Krum but potentially to other robust aggregation functions.  
%% This suggests that OPT can indeed be considered a versatile attack that can adapt to various defenses, including FLANDERS.
%
%% Anyway, if we were to design an adaptive attack specifically targeted to evade FLANDERS, this would involve local training of time-series anomaly detection models at each client's end to improve predictions and better anticipate the expected model updates made by the server. While this is an interesting research direction to explore, it would require conducting additional extensive experiments, which we plan to consider in a future extension of this work.
%
%\subsection{Potential Privacy Leakage}
%\label{app:limitations-privacy}
%In the standard FL setup, the central server must access the local model updates sent by each client (e.g., even to perform a simple FedAvg). 
%Therefore, our approach, FLANDERS, does not need additional permission nor violate any privacy constraints beyond what any other FL server could already do. 
%Indeed, the most effective robust aggregation schemes, such as Krum and Bulyan, like FLANDERS, assume that the central server is a \textit{trusted} entity. 
%However, if this assumption does not hold, the scenario will change. For instance, if the server operates as an ``honest but curious'' entity, thoroughly examining the local model parameters received for training the outlier detection model (such as MAR) could unveil sensitive details that the server might exploit, potentially inferring information about each client's local data distribution.
%
%
%\subsection{Benchmarking}
%%\textbf{\textit{Evaluation.}} 
%We extensively validate FLANDERS with an exhaustive set of experiments. We compared it against six robust baselines amongst the most powerful at the time of writing, along with standard FedAvg.
%%plus, we included a time-series anomaly detection technique (MSCRED), which was not originally designed for this task, as an eighth competitor. 
%%Moreover, we tested our method on three image classification datasets, widely adopted in similar previous work. 
%%\edo{RICORDIAMOCI DI RIFORMULARE QUESTA PARTE}
%%Our evaluation shows that no strategy clearly outperforms the others in every possible scenario, although it highlights that FLANDERS exhibits greater consistency across the spectrum of attack settings compared to other methods.
%\\
%In addition, robust federated aggregation is a hot research topic; keeping pace with the massive body of work that has been flourishing is challenging.
%Hence, we might have missed considering some other methods. 
%\textit{\textbf{However, we believe that the value of our work still stands. In this regard, our contribution is clear: We are the first to frame the problem of detecting untargeted model poisoning attacks on FL as a matrix-valued time series anomaly detection task and to propose a method effective under severe attack settings, as opposed to existing baselines.}} % the authors of FLTrust made experiments on severe attack settings and also DnC seems to run well under these conditions 
%We attribute such a capability to two key factors: $(i)$ FLANDERS operates without knowing a priori the proportion of corrupted clients, and $(ii)$ it naturally embodies temporal dependencies between intra- and inter-client updates, quickly recognizing local model drifts caused by evil players.
%\\
%%Ideally, the research community should agree on a standard framework (i.e., a benchmark) as a test bed for evaluating any new FL robust aggregation scheme where all the existing methods are implemented. This way, no baseline would be missing. 
%%As a first step in this direction, to encourage reproducibility, we have implemented our method \textit{as well as \textbf{all} the considered baselines} in a real-world FL simulation environment (Flower).
%\\
%Finally, FLANDERS relies on several hyperparameters that can impact its performance. For instance, we initially set the matrix autoregressive model order $w$ to 1 but can explore larger values to capture broader temporal dependencies. Also, a more in-depth examination of Table~\ref{tab:defenses} parameters (e.g., $l$, $k$, and $\delta$) could yield insights.
% Finally, FLANDERS depends on several hyperparameters whose values may affect its performance. For example, the order of the matrix autoregressive model $p$, which we let equal $1$, can be set to larger values to account for wider temporal dependencies.
% Furthermore, a deeper analysis of the parameters reported in Table~\ref{tab:defenses} (e.g., $w$, $k$, and $\delta$) would be beneficial.