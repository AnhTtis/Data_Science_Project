\section{Limitations and Future Work}
\label{sec:limitations}
%In general, FLANDERS is more computationally-intensive than other defense mechanisms, primarily when combined with complex models with millions of parameters (e.g., deep neural networks).
%However, as reported in Appendix~\ref{app:defenses}, some implementation tricks can significantly reduce the computational cost of FLANDERS.

\subsection{Efficiency/Feasibility}
\label{subsec:efficiency}
%\textbf{\textit{Efficiency/Feasibility.}} 
As we discussed in Section~5.3 and Appendix~\ref{app:defenses}, FLANDERS may suffer from a high computational cost that could limit its deployment in practice.
This concern holds particularly true for \textit{cross-device} FL configurations encompassing millions of edge devices. Conversely, the impact on \textit{cross-silo} FL scenarios would be notably less pronounced. 
However, as we have introduced FLANDERS as a versatile and robust aggregation approach applicable to diverse FL setups (cross-silo and cross-device), there are implementation techniques available to mitigate its complexity. For instance, methods like random parameter sampling~\cite{shejwalkar2021ndss} can be employed, and we have already incorporated them.
Still, we plan to enhance the scalability of FLANDERS further in future work. 
For example, we could replace the standard matrix inversion algorithm with the more efficient Coppersmith-Winograd algorithm~\cite{coppersmith1990jsc} and find the optimal frequency for re-estimating FLANDERS' parameters, instead of performing it during each FL round.

In an extended version of this work, we plan to include a parameter sensitivity analysis, where the performance of FLANDERS is evaluated based on the number $d$ of sampled parameters. This analysis will hopefully provide insights into the optimal trade-off between robustness and efficiency. Additionally, more sophisticated parameter selection strategies beyond pure random sampling could be explored to focus on the most informative neurons, such as Neuron Shapley~\cite{neuron_shapley}.

% \subsection{Adaptive Attacks}
% Prior works proposing new FL robust aggregation schemes usually do not consider adaptive attacks explicitly tailored to evade the defense mechanism introduced. 
% However, it is worth noting that some attacks considered in this work, such as LIE, OPT, and partially AGR-MM, can be thought of as ``adaptive'', even though they are not specifically designed to evade FLANDERS. 
% For example, OPT~\cite{fang2020usenix} employs a sophisticated and minimal alteration of model parameters in its crafting of model poisoning attacks. Consequently, defense strategies based on outlier detection like FLANDERS, implemented at the server's end, could, in principle, be circumvented by OPT's approach. 
% To further support this claim, it is noteworthy that FLTrust~\cite{cao2020fltrust} also classifies OPT as an adaptive attack, in line with the authors' assertion~\cite{fang2020usenix} that OPT's effectiveness extends not only to Krum but potentially to other robust aggregation functions.  
% This suggests that OPT can indeed be considered a versatile attack that can adapt to various defenses, including FLANDERS.

% Anyway, if we were to design an adaptive attack specifically targeted to evade FLANDERS, this would involve local training of time-series anomaly detection models at each client's end to improve predictions and better anticipate the expected model updates made by the server. While this is an interesting research direction to explore, it would require conducting additional extensive experiments, which we plan to consider in a future extension of this work.

\subsection{Potential Privacy Leakage}
\label{sec:limitations-privacy}
In the standard FL setup, the central server must access the local model updates sent by each client (e.g., even to perform a simple FedAvg). 
Therefore, our approach, FLANDERS, does not need additional permission nor violate any privacy constraints beyond what any other FL server could already do. 
Indeed, the most effective robust aggregation schemes, such as Krum and Bulyan, like FLANDERS, assume that the central server is a \textit{trusted} entity. 
However, if this assumption does not hold, the scenario will change. For instance, if the server operates as an ``honest but curious'' entity, thoroughly examining the local model parameters received for training the outlier detection model (such as MAR) could unveil sensitive details that the server might exploit, potentially inferring information about each client's local data distribution.

\subsection{Cross-Device Setting}
The cross-device setting (thousands to millions of clients) penalizes FLANDERS, as the server cannot select them all, and the probability of choosing the same client in consecutive rounds is low. However, FLANDERS is more appropriate in cross-silo FL (tens to hundreds of clients) than in cross-device settings. In fact, large attacks involving more than 50\% of clients are less feasible when the total number of participants grows to the order of thousands \cite{shejwalkar2022sp}. In such cases, since selected clients have little or no history, FLANDERS computes distances between local updates and the last global model, turning it into a heuristic similar to (Multi-)Krum. Thus, FLANDERS will be comparable to any other heuristic.

\subsection{Benchmarking}
%\textbf{\textit{Evaluation.}} 
We extensively validate FLANDERS with an exhaustive set of experiments. We compared it against six robust baselines amongst the most powerful at the time of writing, along with standard FedAvg.
%plus, we included a time-series anomaly detection technique (MSCRED), which was not originally designed for this task, as an eighth competitor. 
%Moreover, we tested our method on three image classification datasets, widely adopted in similar previous work. 
%\edo{RICORDIAMOCI DI RIFORMULARE QUESTA PARTE}
%Our evaluation shows that no strategy clearly outperforms the others in every possible scenario, although it highlights that FLANDERS exhibits greater consistency across the spectrum of attack settings compared to other methods.
\\
In addition, robust federated aggregation is a hot research topic; keeping pace with the massive body of work that has been flourishing is challenging.
Hence, we might have missed considering some other methods. 
However, we believe that the value of our work still stands. In this regard, our contribution is clear: We are the first to frame the problem of detecting untargeted model poisoning attacks on FL as a matrix-valued time series anomaly detection task and to propose a method effective under severe attack settings, as opposed to existing baselines. % the authors of FLTrust made experiments on severe attack settings and also DnC seems to run well under these conditions 
%We attribute such a capability to two key factors: $(i)$ FLANDERS operates without knowing a priori the proportion of corrupted clients, and $(ii)$ it naturally embodies temporal dependencies between intra- and inter-client updates, quickly recognizing local model drifts caused by evil players.
%\\
%Ideally, the research community should agree on a standard framework (i.e., a benchmark) as a test bed for evaluating any new FL robust aggregation scheme where all the existing methods are implemented. This way, no baseline would be missing. 
%As a first step in this direction, to encourage reproducibility, we have implemented our method \textit{as well as \textbf{all} the considered baselines} in a real-world FL simulation environment (Flower).
%\\
%Finally, FLANDERS relies on several hyperparameters that can impact its performance. For instance, we initially set the matrix autoregressive model order $w$ to 1 but can explore larger values to capture broader temporal dependencies. Also, a more in-depth examination of Table~\ref{tab:defenses} parameters (e.g., $l$, $k$, and $\delta$) could yield insights.
% Finally, FLANDERS depends on several hyperparameters whose values may affect its performance. For example, the order of the matrix autoregressive model $p$, which we let equal $1$, can be set to larger values to account for wider temporal dependencies.
% Furthermore, a deeper analysis of the parameters reported in Table~\ref{tab:defenses} (e.g., $w$, $k$, and $\delta$) would be beneficial.