\section{Experiments}
\label{sec:experiments}

\subsection{Experimental Setup}

\noindent{{\bf {\em Datasets, Tasks, and FL Models.}}}
We consider four public datasets for image classification: {\em MNIST}, {\em Fashion-MNIST}, {\em CIFAR-10}, and {\em CIFAR-100}. %, whose main properties are reported in Table~\ref{tab:setup}. 
All datasets are randomly shuffled and partitioned into two disjoint sets: 80\% is used for training and 20\% for testing. 
% For each dataset/task, we choose one of the following FL models: Multilayer Perceptron (MLP), Convolutional Neural Network (CNN), and MobileNet \cite{howard2017mobilenets}.
We train a Multilayer Perceptron (MLP) on \textit{MNIST} and \textit{Fashion-MNIST} and a Convolutional Neural Network (CNN) on \textit{CIFAR-10} and \textit{CIFAR-100} (MobileNet~\cite{howard2017mobilenets}).
All models are trained by minimizing cross-entropy loss. % and, in each FL round, clients run one iteration of one epoch of SGD.
\\
The full details are available in Appendix~\ref{app:setup}.
%\gabri{It would be great if we could include a fourth dataset like Income, TinyImageNet, or FashionMNIST. If we remove regression task as a whole, we must remember to do so also in the list of novel contributions}
% We consider a mix of four tabular and non-tabular (i.e., image) public datasets used for classification ({\em Income}, {\em MNIST}, and {\em CIFAR-10}) and regression ({\em California Housing}) tasks. %, whose main properties are reported in Table~\ref{tab:setup}. 
% The {\em MNIST} and {\em CIFAR-10} datasets already come split into a training and a test portion; the other datasets are randomly shuffled and partitioned into two disjoint sets: 80\% is used for training and 20\% for testing.
% The {\em MNIST} and {\em CIFAR-10} datasets already come split into a training and a test portion; the other datasets are randomly shuffled and partitioned into two disjoint sets: 80\% is used for training and 20\% for testing.
%We describe how we distribute the training set portion of each dataset across the clients when we detail the FL simulation environment below. 
%Based on how this step is done, we may get different FL setups: i.i.d. vs. non-i.i.d.
% For each dataset/task combination, we choose one of the following FL models: Logistic Regression (LogReg), Multilayer Perceptron (MLP), Convolutional Neural Network (CNN), and Linear Regression (LinReg).
% All models are trained by minimizing cross-entropy loss (classification) or elastic net regularized mean squared error (regression). 
% At each FL round, clients perform one iteration of cyclic coordinate descent (LogReg and LinReg) or one epoch of stochastic gradient descent (MLP and CNN).
% The full details are in Appendix~F. % of the supplementary material. %Appendix~\ref{app:setup}.
% \begin{itemize}
%     \item Income (tabular)/binary classification
%     \item MNIST (image)/multiclass classification
%     \item CIFAR-10 (image)/multiclass classification
%     \item House price (tabular)/regression
% \end{itemize}

%\\
\noindent{{\bf {\em FL Simulation Environment.}}}
To simulate a realistic FL environment, we integrate FLANDERS into Flower \cite{beutel2022flower}. Moreover, we implement in Flower any defense baseline considered that the framework does not natively provide.
%Other valid FL frameworks are available (e.g., TensorFlow Federated\footnote{\scriptsize{\url{https://www.tensorflow.org/federated}}} and PySyft\footnote{\scriptsize{\url{https://github.com/OpenMined/PySyft}}}), but Flower was the most appropriate choice for our scope.
In Table~\ref{tab:fl-env} we synthetically report the hyperparameters.
\\
We set the number $K$ of FL clients to $100$, and we assume that the server selects {\em all} these clients in every FL round ($m=K$). In Appendix~\ref{app:client-selection}, we test when the server \textit{randomly} chooses $m<K$ clients. We suppose the attack starts at $t=1$; then, we monitor the performance of the global model until $t=T=50$. %, while malicious clients possibly enter the FL system. 
Recall that we select the malicious clients randomly across all the participating ones; this implies that a single client can alternate between legitimate and malicious behavior over successive FL rounds.
%\\
%We describe our FL simulation environment in Appendix~\ref{app:fl-env}.
\begin{table}[ht!]
\centering
\caption{Main properties of our FL environment simulated on Flower.
}
\label{tab:fl-env}
%\vspace{2mm}
\scalebox{1}{
    \begin{tabular}{lc}
    \toprule
    \textbf{Total N. of Clients}        & $K = 100$ \\
    \midrule
    \textbf{N. of Selected Clients (at each round)} & $m = K = 100$\\
    \midrule
    \textbf{Ratio of Malicious Clients} & $r=\{0, 0.2, 0.6, 0.8\}$ \\
    \midrule
    \textbf{Total N. of FL Rounds} & $T=50$ \\ \hline
    % \textbf{N. of Legitimate FL Rounds (with no attacks)} & $L=30$ \\ \hline
    \textbf{Autoregressive Order of MAR} & $w=1$ \\
    \midrule
    \textbf{Historical Window Size of Past FL Rounds} & $l=2$ \\
    \midrule
    \textbf{Non-IID Dataset Distribution across Clients} & $\alpha_D = 0.5$  \\
    \bottomrule
    \end{tabular}
}
\end{table}


%\\
\noindent{{\bf {\em Non-IID Local Training Data.}}}
% A peculiarity of FL is that the local training datasets of different clients may not be independent and identically distributed (non-iid).
%To make our experiments more realistic, we simulate non-iid local training data distributions across federated clients for all datasets by leveraging a dataset partitioning method based on Dirichlet sampling, as proposed by~\cite{hsu2019LDA}.
We simulate non-iid clients' training data distributions following~\cite{hsu2019LDA}. We assume every client training example is drawn independently with class labels following a categorical distribution over $N$ classes parameterized by a vector $\bm{q}$ such that $q_i \geq 0, i \in [1,\ldots,N]$ and $||\bm{q}||_1 = 1$.
To synthesize a population of non-identical clients, we draw $\bm{q} \sim \text{Dir}(\alpha_D, \bm{p})$ from a Dirichlet distribution, where $\bm{p}$ characterizes a prior class distribution over $N$ classes, and $\alpha_D > 0$ is a {\em concentration} parameter controlling the identicalness among clients. 
With $\alpha_D \rightarrow \infty$, all clients have identical label distributions; on the other extreme, with $\alpha_D \rightarrow 0$, each client holds examples from only one class chosen at random. 
In our experiments, we set $\alpha_D = 0.5$. % to simulate a strong class label imbalance amongst clients.
%\gabri{Edo: Please double check all the above and fill the missing information}

% Specifically, the \textit{CIFAR-10} dataset contains $60,000$ images ($50,000$ for training and $10,000$ for testing) from $N=10$ classes. 
% We start from balanced populations consisting of $K=100$ clients, each holding $500$ images. Then, we set the prior distribution $\bm{p}$ to be uniform across $10$ classes. 
% For every client, we sample $\bm{q} \sim \text{Dir}(0.5, \bm{p})$ and assign the client with the corresponding number of images from $10$ classes.

% Each training portion of the datasets above is distributed across the FL clients so that every client observes the same local data distribution. 
% For example, in the case of {\em MNIST}, we let each client observe the same proportion of digit samples.
% % In addition, we experiment with two different settings: i.i.d. vs. non-i.i.d. local training datasets. 
% %The former simply assumes every client has the same local data distribution. 
% %For example, in the case of the {\em MNIST} dataset, this means that each client observes the same proportion of samples in each class.
% However, this setting -- known as i.i.d. -- is a pretty unrealistic scenario in FL systems, and, most likely, local training datasets on different clients follow different distributions, i.e., they are {\em non}-i.i.d.
% Notice that there are many types of ``non-i.i.d.-ness'' that may involve: {\em(i) labels}, {\em (ii) number of instances}, and {\em (iii) features}. 
% Concerning {\em(i)}, this occurs when the distribution of labels is very unbalanced across clients (i.e., each client observe only a subset of the possible outputs). 
% As for {\em (ii)}, this happens when some clients have more data than others. 
% Finally, {\em (iii)} represents a situation where similar feature patterns are grouped and shared amongst a few clients.
% In this work, we experiment with the first type of non-i.i.d.-ness limitedly to the {\em CIFAR-10} dataset, which is already implemented in Flower.

%+ $K$ clients with i.i.d/non-i.i.d. local data running SGD, etc.

\subsection{Attacks}
\label{subsec:attacks}
We assess the robustness of FLANDERS under the following well-known attacks.
For each attack, we vary the number $b = \lceil r * m\rceil, r\in [0,1]$ of malicious clients, where $r = \{0, 0.2, 0.6, 0.8\}$. Ultimately, we analyze an attacker's performance embedded with a MAR model.

%\\
\noindent{{\bf {\em Gaussian Noise Attack.}}} 
\noindent This attack randomly crafts the local models on the compromised clients. 
Specifically, the attacker samples a random value from a Gaussian distribution $\varepsilon \sim \mathcal{N}(0,\sigma^2)$ and sums it to all the $d$ learned parameters. 
We refer to this attack as GAUSS.

%\\
\noindent{{\bf {\em ``A Little Is Enough'' Attack}}~\cite{baruch2019neurips}{\bf.}}
This attack %lets the defender remove the non-malicious clients and 
shifts the aggregation gradient by carefully crafting malicious values that deviate from the correct ones as far as possible. 
We call this attack LIE.

%\\
\noindent{{\bf {\em Optimization-based Attack}}~\cite{fang2020usenix}{\bf.}}
This attack is framed as an optimization task, aiming to maximize the distance between the poisoned aggregated gradient and the aggregated gradient under no attack. 
By using a halving search, one can obtain a crafted malicious gradient. 
We refer to this attack as OPT.

%\\
\noindent{{\bf {\em AGR Attack Series}}~\cite{shejwalkar2021ndss}{\bf.}}
This improves the optimization program above by introducing perturbation vectors and scaling factors. Then, three instances are proposed: AGR-tailored, AGR-agnostic Min-Max, and Min-Sum, which maximize the deviation between benign and malicious gradients.
In this work, we experiment with AGR Min-Max, which we call AGR-MM.
%\\
%We detail the parameters of the attacks in Appendix~\ref{app:attacks}. % of the supplementary material.

Below, we describe the critical parameters for
each attack considered, which are also summarized in Table~\ref{tab:attacks}.

\noindent{{\bf {\em GAUSS}}{\bf.}} This attack has only one parameter: the magnitude $\sigma$ of the perturbation to apply. We set $\sigma=10$ for all the experiments.

\noindent{{\bf {\em LIE}}{\bf.}} This method has no parameters to set.

\noindent{{\bf {\em OPT}}{\bf.}} The parameter $\tau$ represents the minimum value that $\lambda$ can assume. Below this threshold, the halving search stops. As suggested by the authors, we set $\tau=10^{-5}$.

\noindent{{\bf {\em AGR-MM}}{\bf.}} In addition to the threshold $\tau$, AGR-MM uses the perturbation vectors $\nabla^p$ in combination with the scaling coefficient $\gamma$ to optimize. We set $\tau=10^{-5}$ and $\nabla^p = \{std\}$, which is the vector obtained by computing the parameters' inverse of the standard deviation. For Krum, we set $\nabla^p = \{uv\}$, which is the inverse unit vector perturbation.
\begin{table}[ht]
\centering
\caption{Key parameter settings for each attack strategy considered.
}
\label{tab:attacks}
%\vspace{2mm}
\begin{tabular}{cc}
    \toprule
    \textbf{Attack}        & \textbf{Parameters} \\
    \midrule
    {\bf {\em GAUSS}} & $\sigma=10$\\
    \midrule
    {\bf {\em LIE}} & N/A\\
    \midrule
    {\bf {\em OPT}} & $\tau=10^{-5}$\\
    \midrule
    {\bf {\em AGR-MM}} & $\tau=10^{-5}; \nabla^p = \{uv, std\}; \gamma=5$\\
    \bottomrule
\end{tabular}
\end{table}

\subsection{Evaluation}
\label{subsec:eval}
We evaluate four key aspects of FLANDERS. 
Firstly, we test its ability to detect malicious clients against the best-competing filtering strategy, FLDetector.
Secondly, we measure the accuracy improvement of the global model when FLANDERS is paired with ``vanilla'' FedAvg and the most popular robust aggregation baselines: FedMedian, Trimmed Mean, Multi-Krum, Bulyan, DnC. 
Thirdly, we analyze the cost-benefit trade-off of FLANDERS.
Lastly, we test the robustness of our method against adaptive attacks. 
%Finally, we measure the impact of FLANDERS on the accuracy of the global model in attack-free scenarios.
%The complete experimental settings are illustrated in Appendix~\ref{app:defenses}.

\smallskip
\noindent{\textbf{\textit{Malicious Detection Accuracy}.}} \label{subsec:detect-acc}
%We evaluate the capability of FLANDERS to detect malicious clients accurately. 
%Specifically, let
%Let $\mathcal{C}^{(t)}_{\text{mal}}\subseteq \mathcal{C}$ be the set of malicious clients selected at round $t$ by the FL server. 
%Furthermore, let $\hat{\mathcal{C}}^{(t)}_{\text{mal}}\subseteq \mathcal{C}$ be the set of malicious clients identified by FLANDERS at round $t$. Thus, we measure \textit{Precision} ($P$) and \textit{Recall} ($R$) as usual, i.e., $P=\frac{tp}{tp + fp}$ and $R=\frac{tp}{tp + fn}$, where $tp,fp,fn$ stand for \textit{true positives}, \textit{false positives}, and \textit{false negatives}. 
%Specifically, $tp = \sum_{t=1}^T |\mathcal{C}^{(t)}_{\text{mal}} \cap \hat{\mathcal{C}}^{(t)}_{\text{mal}}|$, $fp = \sum_{t=1}^T |\hat{\mathcal{C}}^{(t)}_{\text{mal}} \setminus \mathcal{C}^{(t)}_{\text{mal}}|$, and $fn = \sum_{t=1}^T |\mathcal{C}^{(t)}_{\text{mal}} \setminus \hat{\mathcal{C}}^{(t)}_{\text{mal}}|$.
Table~\ref{tab:pr-20} shows the precision ($P$) and recall ($R$) of FLDetector and FLANDERS in filtering out malicious clients across different datasets and attacks, with $r=0.2$ (20\% evil participants in the FL systems). 
Remarkably, FLANDERS successfully detects \textit{all and only} malicious clients across every attack setting except for OPT, outperforming its main competitor, FLDetector.
This is further confirmed by Table~\ref{tab:increment-fld}, which shows that our method generally provides much higher protection than FLDetector when combined with standard FedAvg.

Better results are observed for extreme attack settings ($r=0.8$) in Tables~\ref{tab:pr-80}, and \ref{tab:increment-fld-80}, where OPT maximizes the distance between the legitimate models and the malicious ones by erroneously thinking that the high number of its controlled clients pierces through the aggregation functions. Results for $r=0.6$ in  Appendix~\ref{app:flanders-accuracy} are consistent with these findings.

FLDetector fails to distinguish malicious updates from legitimate ones because \textit{(i)} the anomaly score is based on approximating a single Hessian matrix that must be close to all legitimate clients, making it inadequate for highly non-iid settings, where malicious updates can be similar to legitimate ones; and \textit{(ii)} the suspicious scores are computed as the average normalized Euclidean distance of the past iterations. Although this is coherent and works well with a threat model where the malicious clients are always the same across all rounds, FLANDERS does not make such an assumption, making FLDetector unable to recognize malicious updates arriving for the first time from an ex-legitimate client.

%\begin{table*}[htb!]
%\centering
%\vspace{-4mm}
%\caption{\textit{Precision} ($P$) and \textit{Recall} ($R$) of FLDetector and FLANDERS in detecting malicious clients across various datasets and attacks ($r=0.2$; $T=50$ rounds). Due to space limits, the results for $r=0.6$ and $0.8$ are provided in Table~\ref{tab:pr-60} and \ref{tab:pr-80} (Appendix~\ref{app:flanders-accuracy}).}
%\label{tab:pr-20}
%\scalebox{0.72}{
%\begin{tabular}{|c|cc|cc|cc|cc||cc|cc|cc|cc|}
% \cline{2-17}
% \multicolumn{1}{c|}{} & \multicolumn{8}{c||}{\textbf{FLDetector}} & \multicolumn{8}{c|}{\textbf{FLANDERS}} \\
% \hline
% \multirow{2}{*}{\textbf{Dataset}} & \multicolumn{2}{c|}{GAUSS} & \multicolumn{2}{c|}{LIE} & \multicolumn{2}{c|}{OPT} & \multicolumn{2}{c||}{AGR-MM} & \multicolumn{2}{c|}{GAUSS} & \multicolumn{2}{c|}{LIE} & \multicolumn{2}{c|}{OPT} & \multicolumn{2}{c|}{AGR-MM} \\
% \cline{2-17}
%                            & $P$   & $R$   & $P$   & $R$   & $P$    & $R$    & $P$   & $R$     & $P$   & $R$   & $P$   & $R$    & $P$  & $R$   & $P$  & $R$ \\
%\hline
%\textit{MNIST}          & $0.20$ & $0.20$ & $0.22$ & $0.22$ & ${\bf 0.20}$ & ${\bf 0.20}$ & $0.19$ & $0.19$  & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & $0.13$ & $0.13$ & ${\bf 1.0}$ & ${\bf 1.0}$ \\
%\hline
%\textit{Fashion-MNIST}  & $0.21$ & $0.21$ & $0.18$ & $0.18$ & ${\bf 0.21}$ & ${\bf 0.21}$ & $0.20$ & $0.20$  & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & $0.13$ & $0.13$ & ${\bf 1.0}$ & ${\bf 1.0}$ \\
%\hline
%\textit{CIFAR-10}       & $0.21$ & $0.21$ & $0.21$ & $0.21$ & $0.22$ & $0.22$ & $0.19$ & $0.19$  & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 0.58}$ & ${\bf 0.58}$ & ${\bf 1.0}$ & ${\bf 1.0}$ \\
%\hline
%\textit{CIFAR-100}      & $0.20$ & $0.20$ & $0.19$ & $0.19$ & $0.20$ & $0.20$ & $0.21$ & $0.21$  & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$  & ${\bf 1.0}$  & ${\bf 1.0}$ & ${\bf 1.0}$ \\
%\hline
%\end{tabular}
%}
%\end{table*}

\begin{table*}[htb!]
\centering
\vspace{-4mm}
\caption{\textit{Precision} ($P$) and \textit{Recall} ($R$) of FLDetector and FLANDERS in detecting malicious clients across various datasets and attacks ($r=0.2$; $T=50$ rounds).} %The results for $r=0.6$ and $0.8$ are provided in Table~\ref{tab:pr-60} (Appendix~\ref{app:flanders-accuracy}).}
\label{tab:pr-20}
\scalebox{1}{
\begin{tabular}{@{}cccccccccccccccccc@{}}\toprule
 \multicolumn{1}{c}{} & \multicolumn{8}{c}{\textbf{FLDetector}} & \phantom{a} & \multicolumn{8}{c}{\textbf{FLANDERS}} \\
 \cmidrule(lr){2-9} \cmidrule(lr){11-18}
 & \multicolumn{2}{c}{GAUSS} & \multicolumn{2}{c}{LIE} & \multicolumn{2}{c}{OPT} & \multicolumn{2}{c}{AGR-MM} && \multicolumn{2}{c}{GAUSS} & \multicolumn{2}{c}{LIE} & \multicolumn{2}{c}{OPT} & \multicolumn{2}{c}{AGR-MM} \\
 \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9} \cmidrule(lr){11-12} \cmidrule(lr){13-14} \cmidrule(lr){15-16} \cmidrule(lr){17-18}
                            & $P$   & $R$   & $P$   & $R$   & $P$    & $R$    & $P$   & $R$     && $P$   & $R$   & $P$   & $R$    & $P$  & $R$   & $P$  & $R$ \\
\midrule

\textit{MNIST}          & $0.20$ & $0.20$ & $0.22$ & $0.22$ & ${\bf 0.20}$ & ${\bf 0.20}$ & $0.19$ & $0.19$  && ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & $0.13$ & $0.13$ & ${\bf 1.0}$ & ${\bf 1.0}$ \\

\textit{Fashion-MNIST}  & $0.21$ & $0.21$ & $0.18$ & $0.18$ & ${\bf 0.21}$ & ${\bf 0.21}$ & $0.20$ & $0.20$  && ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & $0.13$ & $0.13$ & ${\bf 1.0}$ & ${\bf 1.0}$ \\

\textit{CIFAR-10}       & $0.21$ & $0.21$ & $0.21$ & $0.21$ & $0.22$ & $0.22$ & $0.19$ & $0.19$  && ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 0.58}$ & ${\bf 0.58}$ & ${\bf 1.0}$ & ${\bf 1.0}$ \\

\textit{CIFAR-100}      & $0.20$ & $0.20$ & $0.19$ & $0.19$ & $0.20$ & $0.20$ & $0.21$ & $0.21$  && ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$  & ${\bf 1.0}$  & ${\bf 1.0}$ & ${\bf 1.0}$ \\
\bottomrule
\end{tabular}
}
\end{table*}


\begin{table*}[htb!]
\centering
%\vspace{-2mm}
\caption{Accuracy of the global model using FedAvg with FLDetector and FLANDERS ($r=0.2$).} %The results for $r=0.6$ are provided in Table~\ref{tab:increment-fld-60} (Appendix~\ref{app:flanders-accuracy}).}
\label{tab:increment-fld}
%\vspace{2mm}
\scalebox{0.95}{
\begin{tabular}{ccccccccccccccc}
\toprule
& \multicolumn{4}{c}{\textbf{FedAvg}} & \phantom{a} & \multicolumn{4}{c}{\textbf{FLDetector + FedAvg}} & \phantom{a} & \multicolumn{4}{c}{\textbf{FLANDERS + FedAvg}} \\
\cmidrule(lr){2-5} \cmidrule(lr){7-10} \cmidrule(lr){12-15}
                    &  GAUSS    &  LIE     &  OPT     &  AGR-MM  &&  GAUSS   &  LIE     &  OPT     &  AGR-MM  &&  GAUSS    &  LIE     &  OPT     &  AGR-MM      \\ 
\midrule
\textit{MNIST}          & $0.18$ & $0.12$ & $0.63$ & $0.34$ && $0.20$ & $0.11$ & ${\bf 0.68}$ & $0.43$ && ${\bf 0.86}$ & ${\bf 0.83}$ & $0.62$       & ${\bf 0.85}$ \\
\textit{Fashion-MNIST}  & $0.25$ & $0.10$ & $0.56$ & $0.16$ && $0.28$ & $0.10$ & ${\bf 0.60}$ & $0.17$ && ${\bf 0.69}$ & ${\bf 0.64}$ & $0.58$       & ${\bf 0.63}$ \\
\textit{CIFAR-10}       & $0.10$ & $0.10$ & $0.23$ & $0.10$ && $0.10$ & $0.10$ & $0.26$       & $0.12$ && ${\bf 0.38}$ & ${\bf 0.37}$ & ${\bf 0.28}$ & ${\bf 0.36}$ \\
\textit{CIFAR-100}      & $0.01$ & $0.01$ & $0.01$ & $0.02$ && $0.01$ & $0.01$ & $0.01$       & $0.02$ && ${\bf 0.07}$ & ${\bf 0.05}$ & ${\bf 0.05}$ & ${\bf 0.06}$ \\
\bottomrule
\end{tabular}
}
%\vspace{-2mm}
\end{table*}


\begin{table*}[htb!]
\centering
%\vspace{-4mm}
\caption{\textit{Precision} ($P$) and \textit{Recall} ($R$) of FLDetector and FLANDERS in detecting malicious clients across various datasets and attacks ($r=0.8$; $T=50$ rounds).}
\label{tab:pr-80}
\scalebox{1}{
\begin{tabular}{@{}cccccccccccccccccc@{}}\toprule
 \multicolumn{1}{c}{} & \multicolumn{8}{c}{\textbf{FLDetector}} & \phantom{a} & \multicolumn{8}{c}{\textbf{FLANDERS}} \\
 \cmidrule(lr){2-9} \cmidrule(lr){11-18}
 & \multicolumn{2}{c}{GAUSS} & \multicolumn{2}{c}{LIE} & \multicolumn{2}{c}{OPT} & \multicolumn{2}{c}{AGR-MM} && \multicolumn{2}{c}{GAUSS} & \multicolumn{2}{c}{LIE} & \multicolumn{2}{c}{OPT} & \multicolumn{2}{c}{AGR-MM} \\
 \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9} \cmidrule(lr){11-12} \cmidrule(lr){13-14} \cmidrule(lr){15-16} \cmidrule(lr){17-18}
                            & $P$   & $R$   & $P$   & $R$   & $P$    & $R$    & $P$   & $R$     && $P$   & $R$   & $P$   & $R$    & $P$  & $R$   & $P$  & $R$ \\
\midrule
\textit{MNIST}              & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ && ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ \\
%\hline
\textit{Fashion-MNIST}      & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.79$ & $0.79$ & $0.80$ & $0.80$ && ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ \\
%\hline
\textit{CIFAR-10}           & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ && ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ \\
%\hline
\textit{CIFAR-100}          & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ & $0.80$ && ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$ & ${\bf 1.0}$  & ${\bf 1.0}$  & ${\bf 1.0}$ & ${\bf 1.0}$ \\
\bottomrule
\end{tabular}
}
\end{table*}


\begin{table*}[htb!]
\centering
%\vspace{-2mm}
\caption{Accuracy of the global model using FedAvg with FLDetector and FLANDERS ($r=0.8$).}
\label{tab:increment-fld-80}
%\vspace{2mm}
\scalebox{0.95}{
\begin{tabular}{ccccccccccccccc}
\toprule
& \multicolumn{4}{c}{\textbf{FedAvg}} & \phantom{a} & \multicolumn{4}{c}{\textbf{FLDetector + FedAvg}} & \phantom{a} & \multicolumn{4}{c}{\textbf{FLANDERS + FedAvg}} \\
\cmidrule(lr){2-5} \cmidrule(lr){7-10} \cmidrule(lr){12-15}
                    &  GAUSS    &  LIE     &  OPT     &  AGR-MM  &&  GAUSS   &  LIE     &  OPT     &  AGR-MM  &&  GAUSS    &  LIE     &  OPT     &  AGR-MM      \\ 
\midrule
\textit{MNIST}          & $0.18$ & $0.11$ & $0.21$ & $0.11$ && $0.15$ & $0.13$ & $0.23$ & $0.12$ && ${\bf 0.75}$ & ${\bf 0.84}$ & ${\bf 0.84}$ & ${\bf 0.82}$ \\
\textit{Fashion-MNIST}  & $0.24$ & $0.10$ & $0.19$ & $0.10$ && $0.19$ & $0.10$ & $0.03$ & $0.10$ && ${\bf 0.68}$ & ${\bf 0.70}$ & ${\bf 0.66}$ & ${\bf 0.66}$ \\
\textit{CIFAR-10}       & $0.10$ & $0.10$ & $0.11$ & $0.10$ && $0.10$ & $0.10$ & $0.10$ & $0.10$ && ${\bf 0.33}$ & ${\bf 0.32}$ & ${\bf 0.32}$ & ${\bf 0.32}$ \\
\textit{CIFAR-100}      & $0.01$ & $0.01$ & $0.01$ & $0.01$ && $0.01$ & $0.01$ & $0.01$ & $0.01$ && ${\bf 0.09}$ & ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.10}$ \\
\bottomrule
\end{tabular}
}
\end{table*}

% Remarkably, FLANDERS successfully detects \textit{all} malicious clients across every attack setting except for OPT. 
% The observed issue with OPT stems from its tendency to craft parameters closer to the output of the prediction by MAR than the legitimate ones. Although this enables OPT to bypass our filter, it does not significantly impact accuracy.
% However, under extreme attack scenarios, e.g., when $r=0.6$ and $r=0.8$, FLANDERS can accurately identify every malicious client even under the OPT attack (see Table~\ref{tab:pr-60} and Table~\ref{tab:pr-80} in Appendix~\ref{app:flanders-accuracy}). 
% Indeed, no current defense method is designed to work if $r>0.5$. Consequently, OPT is free to induce the highest disruption by modifying parameters to maximize their distance from legitimate ones. FLANDERS, though, excels in detecting these substantial deviations and effectively excludes them from the aggregation process.

\smallskip
\noindent{\textbf{\textit{Aggregation Robustness Lift}.}} \label{subsec:agg-robustness-lift}
%Once we have checked that FLANDERS can accurately detect malicious clients, 
We proceed to evaluate the enhancement that FLANDERS provides to the robustness of the global model. %when employed in conjunction with baseline aggregation methods.
Specifically, we measure the best accuracy of the global model under several attack strengths using all the baselines \textit{without} and \textit{with} FLANDERS as a pre-filtering strategy.
% The result of this experiment is illustrated in Table~\ref{tab:increment} and Table~\ref{tab:robustness-1}, Table~\ref{tab:robustness-2}, and Fig.~\ref{fig:accuracy-over-time}.
Table~\ref{tab:increment} shows that FLANDERS keeps high accuracy for the best global model under extreme attacks ($r=0.8$) when used before \textit{every} aggregation method, including Multi-Krum and Bulyan, which would otherwise be inapplicable in such strong attack scenarios.
% Table~\ref{tab:increment} shows that when FLANDERS is employed before under a severe attack scenario ($r=0.8$) keeps a high accuracy for the best global model obtained with \textit{every} aggregation method, including Multi-Krum and Bulyan, which are not designed to handle such strong attack settings. 
This is further emphasized in Table~\ref{tab:robustness-1} (see Appendix~\ref{app:agg-lift}), where Multi-Krum, when paired with FLANDERS, can effectively operate without \textit{any} performance degradation, even in the presence of $80\%$ malicious clients.
% Table~\ref{tab:increment} shows that using FLANDERS as a pre-filtering strategy under a moderate attack scenario ($r=0.2$), in general, significantly improves the accuracy of the best global model obtained with every aggregation method, except for Bulyan, which alone appears already robust enough to counter these mild attacks.

In Figure~\ref{fig:accuracy-over-time} we compare the accuracy of the global model when using FLANDERS (left) and when using FedAvg (right) across the whole FL training process. The left figure shows how the evolution of the accuracy over multiple rounds remains stable and similar to the one without any attack (dashed line), while on the right the accuracy drops irremediably.

\begin{figure}[htb!]%{0.4\textwidth}
     \centering
     \includegraphics[width=\columnwidth]{img/accuracy-over-time-mnist-5}
     \caption{FedAvg with FLANDERS (left) vs. "vanilla" FedAvg (right). Accuracy of the global model in each FL round under all attack strategies on the \textit{MNIST} dataset, with $80\%$ of malicious clients. Attack starts at round $t=3$.}
     \label{fig:accuracy-over-time}
     %\vspace{-6mm}
\end{figure}

%\edo{Add CIFAR-100 back to table IV}
%\begin{table*}[htb!]
%\centering
%\vspace{2mm}
%\caption{Accuracy of the global model using all the baseline aggregations without and with FLANDERS ($r=0.8$).}
%\label{tab:increment}
%%\vspace{2mm}
%\scalebox{0.7}{
%\begin{tabular}{|c|cccc|cccc|cccc|cccc|}
%\hline
%\multirow{2}{*}{\textbf{Aggregation}} & \multicolumn{4}{c|}{\textit{MNIST}} & \multicolumn{4}{c|}{\textit{Fashion-MNIST}} & \multicolumn{4}{c|}{\textit{CIFAR-10}} & \multicolumn{4}{c|}{\textit{CIFAR-100}} \\
%\cline{2-17}
%              &  GAUSS        &  LIE          &  OPT          &  AGR-MM       &  GAUSS        &  LIE          &  OPT          &  AGR-MM       &  GAUSS         &  LIE          &  OPT          &  AGR-MM        &  GAUSS         &  LIE          &  OPT          &  AGR-MM      \\ 
%\hline
%FedAvg      & $0.18$ & $0.11$ & $0.21$ & $0.11$ & $0.24$ & $0.10$ & $0.19$ & $0.10$ & $0.10$ & $0.10$ & $0.11$ & $0.10$ & $0.01$ & $0.01$ & $0.01$ & $0.01$  \\
%+ FLANDERS  & ${\bf 0.75}$ & ${\bf 0.84}$ & ${\bf 0.84}$ & ${\bf 0.82}$ & ${\bf 0.68}$ & ${\bf 0.70}$ & ${\bf 0.66}$ & ${\bf 0.66}$ & ${\bf 0.33}$ & ${\bf 0.32}$ & ${\bf 0.32}$ & ${\bf 0.32}$ & ${\bf 0.09}$ & ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.10}$  \\
%\hline
%FedMedian   & $0.34$ & $0.19$ & $0.13$ & $0.23$ & $0.29$ & $0.10$ & $0.17$ & $0.10$ & $0.13$ & $0.10$ & $0.10$ & $0.12$ & $0.01$ & $0.01$ & $0.01$ & $0.01$  \\
%+ FLANDERS  & ${\bf 0.81}$ & ${\bf 0.84}$ & ${\bf 0.85}$ & ${\bf 0.81}$ & ${\bf 0.70}$ & ${\bf 0.71}$ & ${\bf 0.71}$ & ${\bf 0.68}$ & ${\bf 0.29}$ & ${\bf 0.29}$ & ${\bf 0.31}$ & ${\bf 0.28}$ & ${\bf 0.10}$ & ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.10}$  \\
%\hline
%TrimmedMean & $0.15$ & $0.13$ & $0.20$ & $0.18$ & $0.21$ & $0.10$ & $0.23$ & $0.10$ & $0.10$ & $0.10$ & $0.10$ & $0.10$ & $0.01$ & $0.01$ & $0.01$ & $0.01$ \\
%+ FLANDERS  & ${\bf 0.81}$ & ${\bf 0.83}$ & ${\bf 0.83}$ & ${\bf 0.85}$ & ${\bf 0.71}$ & ${\bf 0.70}$ & ${\bf 0.71}$ & ${\bf 0.69}$ & ${\bf 0.30}$ & ${\bf 0.29}$ & ${\bf 0.30}$ & ${\bf 0.29}$ & ${\bf 0.11}$ & ${\bf 0.10}$ & ${\bf 0.11}$ & ${\bf 0.11}$ \\
%\hline
%Multi-Krum  & $0.80$ & $0.12$ & $0.17$ & $0.25$ & $0.64$ & $0.10$ & $0.20$ & $0.10$ & $0.34$ & $0.10$ & $0.10$ & $0.10$ & $0.08$ & $0.01$ & $0.01$ & $0.01$ \\
%+ FLANDERS  & ${\bf 0.87}$ & ${\bf 0.90}$ & ${\bf 0.88}$ & ${\bf 0.89}$ & ${\bf 0.69}$ & ${\bf 0.68}$ & ${\bf 0.72}$ & ${\bf 0.68}$ & ${\bf 0.38}$ & ${\bf 0.38}$ & ${\bf 0.39}$ & ${\bf 0.40}$ & ${\bf 0.11}$ & ${\bf 0.10}$ & ${\bf 0.10}$ & ${\bf 0.11}$ \\
%\hline
%Bulyan      & N/A & N/A & N/A & N/A & N/A & N/A & N/A & N/A & N/A & N/A & N/A & N/A & N/A & N/A & N/A & N/A \\
%+ FLANDERS  & ${\bf 0.89}$ & ${\bf 0.85}$ & ${\bf 0.88}$ & ${\bf 0.82}$ & ${\bf 0.68}$ & ${\bf 0.66}$ & $0{\bf .68}$ & ${\bf 0.70}$ & ${\bf 0.40}$ & ${\bf 0.43}$ & ${\bf 0.40}$ & ${\bf 0.41}$ & ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.11}$ \\
%\hline
%DnC         & $0.21$ & $0.11$ & $0.17$ & $0.11$ & $0.25$ & $0.10$ & $0.14$ & $0.10$ & $0.10$ &$ 0.10$ & $0.10$ & $0.10$ & $0.01$ & $0.01$ & $0.01$ & $0.01$ \\
%+ FLANDERS  & ${\bf 0.85}$ & ${\bf 0.87}$ & ${\bf 0.89}$ & ${\bf 0.87}$ & ${\bf 0.71}$ & ${\bf 0.69}$ & ${\bf 0.68}$ & ${\bf 0.68}$ & ${\bf 0.41}$ & ${\bf 0.40}$ & ${\bf 0.39}$ & ${\bf 0.40}$ & ${\bf 0.10}$ & ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.12}$ \\
%\hline
%\end{tabular}
%}
%\end{table*}


%%% OLD DESIGN
%\begin{table*}[htb!]
%\centering
%\vspace{2mm}
%\caption{Accuracy of the global model using all the baseline aggregations without and with FLANDERS ($r=0.8$).}
%\label{tab:increment}
%%\vspace{2mm}
%\scalebox{0.7}{
%\begin{tabular}{|c|cccc|cccc|cccc|cccc|}
%\hline
%\multirow{2}{*}{\textbf{Aggregation}} & \multicolumn{4}{c|}{\textit{MNIST}} & \multicolumn{4}{c|}{\textit{Fashion-MNIST}} & \multicolumn{4}{c|}{\textit{CIFAR-10}} & \multicolumn{4}{c|}{\textit{CIFAR-100}} \\
%\cline{2-17}
%              &  GAUSS        &  LIE          &  OPT          &  AGR-MM       &  GAUSS        &  LIE          &  OPT          &  AGR-MM       &  GAUSS         &  LIE          &  OPT          &  AGR-MM        &  GAUSS         &  LIE          &  OPT          &  AGR-MM      \\ 
%\hline
%FedAvg      & $0.18$ & $0.11$ & $0.21$ & $0.11$ & $0.24$ & $0.10$ & $0.19$ & $0.10$ & $0.10$ & $0.10$ & $0.11$ & $0.10$ & $0.01$ & $0.01$ & $0.01$ & $0.01$  \\
%+ FLANDERS  & ${\bf 0.75}$ & ${\bf 0.84}$ & ${\bf 0.84}$ & ${\bf 0.82}$ & ${\bf 0.68}$ & ${\bf 0.70}$ & ${\bf 0.66}$ & ${\bf 0.66}$ & ${\bf 0.33}$ & ${\bf 0.32}$ & ${\bf 0.32}$ & ${\bf 0.32}$ & ${\bf 0.09}$ & ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.10}$  \\
%\hline
%FedMedian   & $0.34$ & $0.19$ & $0.13$ & $0.23$ & $0.29$ & $0.10$ & $0.17$ & $0.10$ & $0.13$ & $0.10$ & $0.10$ & $0.12$ & $0.01$ & $0.01$ & $0.01$ & $0.01$  \\
%+ FLANDERS  & ${\bf 0.81}$ & ${\bf 0.84}$ & ${\bf 0.85}$ & ${\bf 0.81}$ & ${\bf 0.70}$ & ${\bf 0.71}$ & ${\bf 0.71}$ & ${\bf 0.68}$ & ${\bf 0.29}$ & ${\bf 0.29}$ & ${\bf 0.31}$ & ${\bf 0.28}$ & ${\bf 0.10}$ & ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.10}$  \\
%\hline
%TrimmedMean & $0.15$ & $0.13$ & $0.20$ & $0.18$ & $0.21$ & $0.10$ & $0.23$ & $0.10$ & $0.10$ & $0.10$ & $0.10$ & $0.10$ & $0.01$ & $0.01$ & $0.01$ & $0.01$ \\
%+ FLANDERS  & ${\bf 0.81}$ & ${\bf 0.83}$ & ${\bf 0.83}$ & ${\bf 0.85}$ & ${\bf 0.71}$ & ${\bf 0.70}$ & ${\bf 0.71}$ & ${\bf 0.69}$ & ${\bf 0.30}$ & ${\bf 0.29}$ & ${\bf 0.30}$ & ${\bf 0.29}$ & ${\bf 0.11}$ & ${\bf 0.10}$ & ${\bf 0.11}$ & ${\bf 0.11}$ \\
%\hline
%Multi-Krum  & $0.80$ & $0.12$ & $0.17$ & $0.25$ & $0.64$ & $0.10$ & $0.20$ & $0.10$ & $0.34$ & $0.10$ & $0.10$ & $0.10$ & $0.08$ & $0.01$ & $0.01$ & $0.01$ \\
%+ FLANDERS  & ${\bf 0.87}$ & ${\bf 0.90}$ & ${\bf 0.88}$ & ${\bf 0.89}$ & ${\bf 0.69}$ & ${\bf 0.68}$ & ${\bf 0.72}$ & ${\bf 0.68}$ & ${\bf 0.38}$ & ${\bf 0.38}$ & ${\bf 0.39}$ & ${\bf 0.40}$ & ${\bf 0.11}$ & ${\bf 0.10}$ & ${\bf 0.10}$ & ${\bf 0.11}$ \\
%\hline
%Bulyan      & N/A & N/A & N/A & N/A & N/A & N/A & N/A & N/A & N/A & N/A & N/A & N/A & N/A & N/A & N/A & N/A \\
%+ FLANDERS  & ${\bf 0.89}$ & ${\bf 0.85}$ & ${\bf 0.88}$ & ${\bf 0.82}$ & ${\bf 0.68}$ & ${\bf 0.66}$ & $0{\bf .68}$ & ${\bf 0.70}$ & ${\bf 0.40}$ & ${\bf 0.43}$ & ${\bf 0.40}$ & ${\bf 0.41}$ & ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.11}$ \\
%\hline
%DnC         & $0.21$ & $0.11$ & $0.17$ & $0.11$ & $0.25$ & $0.10$ & $0.14$ & $0.10$ & $0.10$ &$ 0.10$ & $0.10$ & $0.10$ & $0.01$ & $0.01$ & $0.01$ & $0.01$ \\
%+ FLANDERS  & ${\bf 0.85}$ & ${\bf 0.87}$ & ${\bf 0.89}$ & ${\bf 0.87}$ & ${\bf 0.71}$ & ${\bf 0.69}$ & ${\bf 0.68}$ & ${\bf 0.68}$ & ${\bf 0.41}$ & ${\bf 0.40}$ & ${\bf 0.39}$ & ${\bf 0.40}$ & ${\bf 0.10}$ & ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.12}$ \\
%\hline
%\end{tabular}
%}
%\end{table*}

\begin{table*}[htb!]
\centering
%\vspace{2mm}
\caption{Accuracy of the global model using all the baseline aggregations without and with FLANDERS ($r=0.8$).}
\label{tab:increment}
%\vspace{2mm}
\scalebox{0.75}{
\begin{tabular}{cccccccccccccccccccc}
\toprule
& \multicolumn{4}{c}{\textit{MNIST}} & \phantom{a} & \multicolumn{4}{c}{\textit{Fashion-MNIST}} & \phantom{a} & \multicolumn{4}{c}{\textit{CIFAR-10}} & \phantom{a} & \multicolumn{4}{c}{\textit{CIFAR-100}} \\
\cmidrule(lr){2-5} \cmidrule(lr){7-10} \cmidrule(lr){12-15} \cmidrule(lr){17-20}
              &  GAUSS        &  LIE          &  OPT          &  AGR-MM       &&  GAUSS        &  LIE          &  OPT          &  AGR-MM       &&  GAUSS         &  LIE          &  OPT          &  AGR-MM        &&  GAUSS         &  LIE          &  OPT          &  AGR-MM      \\ 
\midrule
FedAvg      & $0.18$        & $0.11$        & $0.21$        & $0.11$        && $0.24$       & $0.10$        & $0.19$        & $0.10$        && $0.10$       & $0.10$        & $0.11$        & $0.10$        && $0.01$       & $0.01$        & $0.01$        & $0.01$  \\
+ FLANDERS  & ${\bf 0.75}$  & ${\bf 0.84}$  & ${\bf 0.84}$  & ${\bf 0.82}$  && ${\bf 0.68}$ & ${\bf 0.70}$  & ${\bf 0.66}$  & ${\bf 0.66}$  && ${\bf 0.33}$ & ${\bf 0.32}$  & ${\bf 0.32}$  & ${\bf 0.32}$  && ${\bf 0.09}$ & ${\bf 0.11}$  & ${\bf 0.11}$  & ${\bf 0.10}$  \\
\midrule
FedMedian   & $0.34$ & $0.19$ & $0.13$ & $0.23$ && $0.29$ & $0.10$ & $0.17$ & $0.10$ && $0.13$ & $0.10$ & $0.10$ & $0.12$ && $0.01$ & $0.01$ & $0.01$ & $0.01$  \\
+ FLANDERS  & ${\bf 0.81}$ & ${\bf 0.84}$ & ${\bf 0.85}$ & ${\bf 0.81}$ && ${\bf 0.70}$ & ${\bf 0.71}$ & ${\bf 0.71}$ & ${\bf 0.68}$ && ${\bf 0.29}$ & ${\bf 0.29}$ & ${\bf 0.31}$ & ${\bf 0.28}$ && ${\bf 0.10}$ & ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.10}$  \\
\midrule
TrimmedMean & $0.15$ & $0.13$ & $0.20$ & $0.18$ && $0.21$ & $0.10$ & $0.23$ & $0.10$ && $0.10$ & $0.10$ & $0.10$ & $0.10$ && $0.01$ & $0.01$ & $0.01$ & $0.01$ \\
+ FLANDERS  & ${\bf 0.81}$ & ${\bf 0.83}$ & ${\bf 0.83}$ & ${\bf 0.85}$ && ${\bf 0.71}$ & ${\bf 0.70}$ & ${\bf 0.71}$ & ${\bf 0.69}$ && ${\bf 0.30}$ & ${\bf 0.29}$ & ${\bf 0.30}$ & ${\bf 0.29}$ && ${\bf 0.11}$ & ${\bf 0.10}$ & ${\bf 0.11}$ & ${\bf 0.11}$ \\
\midrule
Multi-Krum  & $0.80$ & $0.12$ & $0.17$ & $0.25$ && $0.64$ & $0.10$ & $0.20$ & $0.10$ && $0.34$ & $0.10$ & $0.10$ & $0.10$ && $0.08$ & $0.01$ & $0.01$ & $0.01$ \\
+ FLANDERS  & ${\bf 0.87}$ & ${\bf 0.90}$ & ${\bf 0.88}$ & ${\bf 0.89}$ && ${\bf 0.69}$ & ${\bf 0.68}$ & ${\bf 0.72}$ & ${\bf 0.68}$ && ${\bf 0.38}$ & ${\bf 0.38}$ & ${\bf 0.39}$ & ${\bf 0.40}$ && ${\bf 0.11}$ & ${\bf 0.10}$ & ${\bf 0.10}$ & ${\bf 0.11}$ \\
\midrule
Bulyan      & N/A & N/A & N/A & N/A && N/A & N/A & N/A & N/A && N/A & N/A & N/A & N/A && N/A & N/A & N/A & N/A \\
+ FLANDERS  & ${\bf 0.89}$ & ${\bf 0.85}$ & ${\bf 0.88}$ & ${\bf 0.82}$ && ${\bf 0.68}$ & ${\bf 0.66}$ & ${\bf 0.68}$ & ${\bf 0.70}$ && ${\bf 0.40}$ & ${\bf 0.43}$ & ${\bf 0.40}$ & ${\bf 0.41}$ && ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.11}$ \\
\midrule
DnC         & $0.21$ & $0.11$ & $0.17$ & $0.11$ && $0.25$ & $0.10$ & $0.14$ & $0.10$ && $0.10$ &$ 0.10$ & $0.10$ & $0.10$ && $0.01$ & $0.01$ & $0.01$ & $0.01$ \\
+ FLANDERS  & ${\bf 0.85}$ & ${\bf 0.87}$ & ${\bf 0.89}$ & ${\bf 0.87}$ && ${\bf 0.71}$ & ${\bf 0.69}$ & ${\bf 0.68}$ & ${\bf 0.68}$ && ${\bf 0.41}$ & ${\bf 0.40}$ & ${\bf 0.39}$ & ${\bf 0.40}$ && ${\bf 0.10}$ & ${\bf 0.11}$ & ${\bf 0.11}$ & ${\bf 0.12}$ \\
\bottomrule
\end{tabular}
}
\end{table*}

For weaker attacks, e.g., $r=0.2$, FLANDERS still generally improves the accuracy of the global model, except when combined with Bulyan, which alone appears already robust enough to counter these mild attacks (see Table~\ref{tab:increment-20} in Appendix~\ref{app:agg-lift}). The complete results are in Appendix~\ref{app:agg-lift}.
However, it is worth remarking that current robust aggregation methods like Multi-Krum and Bulyan are not designed to handle stronger attack settings. 
Nevertheless, when these methods are combined with FLANDERS, they can be deployed successfully even under extremely severe attacks due to FLANDERS' capability to filter out every malicious client \textit{before} the aggregation process takes place.
This is illustrated with an example in Table~\ref{tab:robustness-1}, where it is demonstrated that Multi-Krum, when paired with FLANDERS, can effectively operate without \textit{any} performance degradation even when the proportion of malicious clients reaches $80\%$. 
Similarly, as shown in Fig.~\ref{fig:accuracy-over-time}, the performance remains robust across all FL rounds even when FLANDERS is paired with a simple aggregation function, such as FedAvg. Instead, when our filter is removed, the accuracy drops as soon as the attack begins.

\smallskip
\noindent{\textbf{\textit{Cost-Benefit Analysis}.}} \label{subsec:cost-benefit}
Obviously, the robustness guaranteed by FLANDERS under extreme attack scenarios comes with costs, especially due to the MAR estimation stage. 
Fig.~\ref{fig:tradeoff} depicts two scatter plots for the \textit{MNIST} and \textit{CIFAR-10} datasets, focusing on a specific attack scenario (AGR-MM). Each data point on a scatter plot represents a method under one of two attack strengths considered ($r=0.2$ and $r=0.6$). These data points are specified by two coordinates: the overall training time on the $x$-axis and the maximum accuracy of the global model obtained after $T=50$ FL rounds on the $y$-axis.

\begin{figure}[htb!]%{0.4\textwidth}
     \centering
     \includegraphics[width=\columnwidth]{img/tradeoff}
     \caption{Accuracy vs. \textit{total} Training Time (in seconds) of FedAvg and Bulyan compared with their corresponding versions with FLANDERS as a filter for the \textit{MNIST} (left) and \textit{CIFAR-10} (right) datasets.}
     \label{fig:tradeoff}
     %\vspace{-6mm}
\end{figure}

Overall, the take-home message is as follows. In scenarios with low attack strength ($r=0.2$), Bulyan demonstrates superior accuracy, while FLANDERS + FedAvg offers comparable performance with notably shorter training times. However, as the attack strength increases ($r=0.6$), Bulyan becomes impractical, FedAvg alone proves ineffective, and FLANDERS emerges as the optimal choice for achieving the best accuracy vs. cost trade-off.

\smallskip
\noindent{\textbf{\textit{Robustness against Adaptive Attacks}.}} \label{subsec:adaptive-attack}
%We test the robustness of our method when malicious clients might exploit the knowledge that the FL server implements our FLANDERS filter. We consider two scenarios: one more plausible and the other most pessimistic. For the first setup, Table~\ref{tab:nonomn-adaptive} in Appendix~\ref{app:adaptive-attacks} shows that FLANDERS can cope with adaptive attackers who tentatively guess the subset of parameters used by the FL server to estimate the MAR forecasting model (\textit{non-omniscient} adaptive attack). In contrast, Table~\ref{tab:omn-adaptive} highlights that FLANDERS becomes unsurprisingly ineffective in the worst-case scenario, i.e., if malicious clients know \textit{exactly} which parameters are used by the FL server (\textit{omniscient} adaptive attack). However, this latter situation is quite unrealistic in practice.
In this section, we further validate the robustness of FLANDERS against adaptive attacks. We consider a scenario where malicious clients are aware that the FL server uses our method as a pre-aggregation filter. 
Specifically, we focus on two levels of knowledge. The first scenario assumes that malicious clients tentatively guess the subset of parameters ($\widetilde{d}$) used by the FL server to estimate the MAR forecasting model. We refer to this setting as \textit{non-omniscient}.
The second, more challenging as well as unrealistic scenario assumes that malicious clients know \textit{exactly} which parameters are used by the FL server. We call this second scenario \textit{omniscient}. Obviously, the latter penalizes FLANDERS way more than the former. 
\\
Specifically, we perform our experiments over $T=20$ rounds with $m=20$ clients, of which $r=0.2$ ($b=5$) are malicious. The attacker constructs a matrix $M = b \times \widetilde{d}$ using the local models generated by the corrupted clients. This matrix $M$ is then passed as input to the same forecasting model, MAR, that the server uses to determine the legitimacy of local models. The attacker, instead, substitutes the legitimate parameters with those estimated by MAR, exploiting the fact that these estimations do not perform like a legitimate local model. This substitution ultimately hurts the accuracy of the global model once the parameters are aggregated. 
\\
As introduced above, we first assume that the attacker is \textit{non-omniscient}, meaning it does not know which parameters the server has selected for the MAR estimation. Instead, the attacker selects the last layer as $\widetilde{d}$. 
Afterward, we consider an \textit{omniscient} attacker who exploits the knowledge of the parameters selected by the server. 
In Table~\ref{tab:nonomn-adaptive}, we show the results of the non-omniscient scenario, where FLANDERS + Multi-Krum outperforms all other baselines on all three datasets. Table~\ref{tab:omn-adaptive}, on the other hand, refers to the omniscient scenario and demonstrates a different pattern, where FedAvg and Multi-Krum alone perform better than when coupled with FLANDERS.
This may be because FLANDERS consistently filters out legitimate local models in favor of corrupted ones. When using FedAvg, the impact of corrupted parameters is mitigated by averaging a larger number of legitimate models and because the corrupted models' parameter values are not too different, unlike in methods like OPT. On the other hand, Multi-Krum selects parameters with more nearby neighbors, and with only $b=5$ corrupted clients, legitimate models likely still have more and closer neighbors, effectively defending against our adaptive attack.

\begin{table}[htb!]
\centering
%\vspace{-2mm}
\caption{Accuracy of the global model using FedAvg and Multi-Krum, with and without FLANDERS, under the \textit{\textbf{non-}omniscient} adaptive attack.}
\label{tab:nonomn-adaptive}
\begin{tabular}{cccc}
    \toprule
    Strategy & \textit{MNIST} & \textit{Fashion-MNIST} & \textit{CIFAR-10} \\
    \midrule
    FedAvg                  & $0.84$ & $0.68$ & $0.45$ \\
    FLANDERS + FedAvg       & $0.82$ & $0.67$ & $0.43$ \\
    %\hline
    Multi-Krum              & $0.87$ & ${\bf 0.72}$ & $0.41$ \\
    FLANDERS + Multi-Krum   & ${\bf 0.90}$ & ${\bf 0.72}$ & ${\bf 0.47}$ \\
    \bottomrule
\end{tabular}
%\vspace{-4mm}
\end{table}

\begin{table}[htb!]
\centering
\caption{Accuracy of the global model using FedAvg and Multi-Krum, with and without FLANDERS, under the \textit{omniscient} adaptive attack.}
\label{tab:omn-adaptive}
\begin{tabular}{cccc}
    \toprule
    Strategy & \textit{MNIST} & \textit{Fashion-MNIST} & \textit{CIFAR-10} \\
    \midrule
    FedAvg                  & $0.78$ & ${\bf 0.68}$ & ${\bf 0.25}$ \\
    FLANDERS + FedAvg       & $0.65$ & $0.61$ & $0.10$ \\
    %\hline
    Multi-Krum              & ${\bf 0.86}$ & ${\bf 0.68}$ & $0.23$ \\
    FLANDERS + Multi-Krum   & $0.73$ & $0.60$ & $0.10$ \\
    \bottomrule
\end{tabular}
\end{table}

% As shown in Table~\ref{tab:increment}, despite $r=0.2$ being a standard setting for all baselines, FLANDERS improves the accuracy in most cases. For example, it enables FedAvg, FedMedian, TrimmedMean, and DnC to work under such attack scenarios and generally improves the performance of Multi-Krum. Moreover, it enables the deployment of such algorithms under more severe attack scenarios that originally cannot support. For example, in Table~\ref{tab:robustness}, we show that Multi-Krum paired with FLANDERS can effectively work without \textit{any} performance degradation even when the number of malicious clients is $80\%$. As shown in Fig~\ref{fig:accuracy-over-time}, the performance remain robust across all rounds even when FLANDERS is paired with simple aggregation function, such as FedAvg, and $r=0.8$. Instead, when the filter is removed, the accuracy drops inexorably as soon as the attack begins.


%\\
%\noindent{\textbf{\textit{FLANDERS' Impact on Attack-Free Scenarios}.}}
%Showing the global model's performance drift before and after the attack helps understand the robustness of a specific FL aggregation scheme.
%However, this may not consider a possible cost due to the degradation introduced by the secure FL aggregation when no attack occurs. 
%Indeed, any robust FL aggregation strategy may sacrifice the global model's performance when no attack occurs. In other words, there is a trade-off between the level of security guaranteed and the accuracy of the global model.
%To quantify this trade-off for FLANDERS, we evaluate the accuracy of the global model in attack-free scenarios (i.e., when $r=0$).
%We report the result of this experiment are presented in Table~\ref{}.
