\section{Problem Formulation}
\label{sec:problem}

\subsection{Time Series of Local Models}
\label{subsec:ts-models}
At the end of each FL round $t$, the central server $S$ collects the updated local models $\{\params_c^{(t)}\}_{c\in \mathcal{C}^{(t)}}$ sent by the subset of selected clients.\footnote{A similar reasoning would apply if clients sent their local displacement vectors $\bm{u}_c^{(t)} = \params_c^{(t)} - \params^{(t)}$ or local gradients $\nabla{\Loss}_c^{(t)}$ rather than local model parameters $\params_c^{(t)}$.}
%To ease of presentation, in the following, we assume that the number of clients picked at each round is constant and fixed, i.e., $|\mathcal{C}^{(t)}| = m,~\forall t\in \{1,2,\ldots, T\}$.
Without loss of generality, we assume that the number of clients picked at each round is constant and fixed, i.e., $|\mathcal{C}^{(t)}| = m,~\forall t\in \{1,2,\ldots, T\}$.
%%%%%%%%%%%%% THE FOLLOWING IS ADDED TO ADDRESS THE CONCERN WHEN m < K %%%%%%%%%%%%%
% Moreover, since, usually, not every client is picked at every round, the server \textit{pretends} the remaining $(K-m)$ unselected clients send the current global model $\params^{(t)}$.
% Hence, we arrange the model updates received at round $t$ into a $d\times K$ matrix $\Params_{t} = \Big[\params_1^{(t)}, \ldots, \params_c^{(t)}, \ldots, \params_K^{(t)}\Big]$, whose $c$-th column corresponds to $(i)$ the $d$-dimensional vector of updated parameters $\params_c^{(t)}$ sent by client $c$ if this was selected (i.e., $c\in \mathcal{C}^{(t)}$) or $(ii)$ the current global model if $c$ was \textit{not} selected, namely $\params_c^{(t)} = \params^{(t)}$. 
% Eventually, we build the multidimensional time series as the $d\times K \times T$ tensor $\Params_{1:T} = \Big[\Params_{1}, \Params_{2}, \ldots, \Params_{T} \Big]$. %, depicted in Fig.~\ref{fig:tensor}.
Hence, the server arranges the local models received at round $t$ into a $d\times m$ matrix $\Params_{t} = [\params_1^{(t)}, \ldots, \params_c^{(t)}, \ldots, \params_m^{(t)}]$, whose $c$-th column corresponds to the $d$-dimensional vector of updated parameters $\params_c^{(t)}$ sent by client $c$.
However, the subset of selected clients may be different at each FL round, i.e., $\mathcal{C}^{(t)} \neq \mathcal{C}^{(t')}$ for $t\neq t'$, although we have assumed their size ($m$) is the same. 
More generally, to track the local models sent by \textit{all} clients chosen across $1\leq w \leq T$ rounds, we can extend each $\Params_{t}$ into a $d\times h$ matrix, where $h = |\bigcup_{t=1}^w \mathcal{C}^{(t)}|$, such that $m \leq h \leq K$, with $K$ being the total number of clients. 
Notice that $h=m$ when $w=1$, whereas $h=K$ if the server selects all $K$ clients at least once over the $w$ rounds considered.
At every round $t$, $\Params_{t}$ contains $m$ columns corresponding to the local models sent by the clients \textit{actually} selected for that round. In contrast, the remaining $h-m$ ``fictitious'' columns refer to the unselected clients.
We fill these columns with the current global model at FL round $t$, i.e., $\params^{(t)}$, as if this were sent by the $h-m$ unselected clients. 
Note that this strategy is neutral and will not impact the aggregated global model computed by the server for the next round $(t+1)$, as this is calculated only from the updates received by the $m$ clients previously selected. 
%Moreover, this allows our method to seamlessly deal with ``cold start'' clients  -- i.e., FL participants with no history who send their local updates for the first time (see Section~\ref{subsec:ts-outliers} below).
%In practice, there is no need to extend each $\Params_{t}$ to a $d\times K$ matrix unless the server selects all $K$ clients at least once over the $w$ rounds considered. Indeed, it is enough to set it to $d\times h$, where $h = |\bigcup_{t=1}^w \mathcal{C}^{(t)}|$, such that $m \leq h \leq K$.
%%%%%%%%%%%%%%%%% OLD VERSION BELOW %%%%%%%%%%%%%%%%%
% At the end of the $T$-th round, we extend each matrix $\Params_{t}$ with as many columns as the number of clients chosen in any other FL round $t' \in \{1,2,\ldots, T\}$, such that $t\neq t'$. 
% Therefore, each $\Params_{t}$ turns into a $d\times h$ matrix: $m$ columns correspond to the local models sent by the clients \textit{actually} selected at round $t$; in contrast, the remaining $h-m$ columns refer to the unselected clients at round $t$ yet picked in some other round. 
% We fill those columns with the current global model at FL round $t$, i.e., $\params^{(t)}$, as if this was sent by the $h-m$ unselected clients. 
% Notice that this will not affect the aggregated global model computed by the server for the next round $(t+1)$, as this will be computed only from the updates received by the $m$ clients previously selected.
% Also, we note that $m \leq h \leq Tm$. In particular, $h=m$ if, at each round, the server selects the same set of clients, i.e., $\mathcal{C}^{(t)} = \mathcal{C}^{(t')}$ for any $t\neq t'$; vice versa, $h=Tm$ when the subsets of selected clients are all disjoint, namely $\bigcap_{t=1}^T \mathcal{C}^{(t)} = \emptyset$.

% Eventually, we can arrange all these historical observations in a multidimensional time series as the $d\times h \times T$ tensor $\Params_{1:T} = [\Params_{1}, \Params_{2}, \ldots, \Params_{T}]$, as depicted in Fig.~\ref{fig:tensor}.
% %\footnote{Notice that $Tm$ columns is an upper-bound value, as usually $\bigcap_{t=1}^T \mathcal{C}^{(t)} \neq \emptyset$.} 
% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=1.0\columnwidth]{./img/tensor}
%     \caption{The $d$-dimensional vector of parameters $\params_c^{(t)}$ sent by client $c$ at round $t$ (left). The $d\times m$ matrix $\Params_t$ of {\em all} the $m$ client updates sent at round $t$ (middle). The $d\times m\times T$ tensor $\Params_{1:T}$ of all the client updates after $T$ rounds (right).}
%     \label{fig:tensor}
%     \vspace{-4mm}
% \end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \subsection{The Attack Model}
% \label{subsec:attack-model}
% \noindent{{\bf {\em Attacker's goal.}}}
% Like many studies on poisoning attacks~\cite{rubinstein2009imc,biggio2012icml,biggio2013icb,xiao2015icml,li2016nips,yang2017ndss,jagielski2018sp,fang2020usenix}, we consider the attacker's goal is to jeopardize the jointly learned global model \textit{indiscriminately} at inference time. 
% Such attacks are known as {\em untargeted}, as opposed to {\em targeted} poisoning attacks, where instead, the goal is to induce prediction errors only for some specific test instances.

% \noindent{{\bf {\em Attacker's capability.}}}
% To achieve the goal above, we assume the attacker controls a fraction $b=\lceil r*K \rceil, r\in [0,1]$ of malicious clients, i.e., $0\leq b\leq K$. 
% Like Sybil attacks~\cite{douceur2002iptps} to distributed systems, the attacker could inject $b$ fake clients into the FL system or compromise $b$ benign clients.
% The attacker can arbitrarily manipulate the local
% models sent by malicious clients to the server $S$.
% More formally, let $x \in \mathcal{C}$ be one of the $b$ corrupted clients selected by the server on the generic $t$-th FL round; $x$ will send to $S$ its malicious local model update $\widetilde{\params}_x^{(t)}$ rather than the legitimate $\params_x^{(t)}$.
% As per how $x$ computes $\widetilde{\params}_x^{(t)}$, this can be done at least in two ways: via \textit{data} or \textit{model} poisoning, i.e., before or after local training. 
% In the former case, $x$ finds $\widetilde{\params}_x^{(t)}$ as the result of performing its local training on a perturbed version $\widetilde{\dataset}_{x}$ of its private data $\dataset_{x}$ (e.g., via label flipping~\cite{xiao2015icml}), i.e., $\widetilde{\params}_x^{(t)} = \text{argmin}_{\params^{(t)}}\Loss_x(\params^{(t)}; \widetilde{\dataset}_{x})$.
% In the latter case, $x$ first legitimately computes $\params_x^{(t)}$ using Eq.~(\ref{eq:client-opt}) without modifying its local data $\dataset_x$; then it obtains $\widetilde{\params}_x^{(t)}$ by applying a {\em post hoc} perturbation $\bm{\varepsilon} \in \R^d$ to the correct local model update. For example, $\widetilde{\params}_x^{(t)} = \params_x^{(t)} + \bm{\varepsilon}$, where $\bm{\varepsilon}\sim \mathcal{N}(\bm{\mu}, \bm{\Sigma})$ is a random Gaussian noise vector. 
% More advanced attack strategies have been designed, as discussed in Section~\ref{subsec:attacks}.
% \\
% Notice that any data poisoning attack can be seen as a special case of a local model poisoning attack.
% However, recent studies~\cite{bhagoji2019pmlr,fang2020usenix} show that {\em direct} local model poisoning attacks are more effective than {\em indirect} data poisoning attacks against FL. 
% Therefore, we focus on the former in this work. 

% \noindent{{\bf {\em Attacker's knowledge.}}}
% We suppose the attacker knows the code, local training datasets, and local models on its controlled clients. 
% Moreover, since this work is concerned with the robustness of the aggregation function, we consider the worst-case scenario (from an honest FL system's perspective), where the attacker also knows the aggregation function used by the central server.
% Based on this knowledge, the attacker may design more effective (i.e., disruptive) poisoning strategies~\cite{fang2020usenix}.
% Besides, this assumption is realistic as the FL service provider may want to publicly disclose the aggregation rule used to promote transparency and trust in the FL system~\cite{mcmahan2017aistats}.

% \noindent{{\bf {\em Attacker's behavior.}}}
% % We suppose there is no anomaly in the client updates observed in the first $L<T$ rounds, i.e., either no malicious clients have joined the FL network yet ($b=r=0$) or, even if they have, they have been acting legitimately (e.g., to achieve stealthiness and elude possible detection mechanisms).
% % Then, assuming the attack starts after $L$ rounds, our goal is to detect anomalous model updates sent afterward (i.e., at any round $L+j$, where $j > 0$) and discard them from the input to the aggregation function (e.g., FedAvg).
% At each FL round, the attacker can instruct any of its controlled $b$ malicious clients selected by the server to poison their local models using one of the strategies described in Section~\ref{subsec:attacks}.
% % NOT SURE WHETHER TO KEEP THE FOLLOWING (WE MAY NEED TO SHOW WHAT HAPPENS UNDER "DISCONTINUOUS" ATTACKS)
% Notice that to increase stealthiness further, a corrupted client may intertwine correct and malicious behavior between successive FL rounds once the attack starts.

\subsection{Predictability of Local Models Evolution: Legitimate vs. Malicious Clients}
\label{subsec:intuition}
We claim that legitimate local updates %, resulting from well-calibrated iterative procedures like stochastic gradient descent (SGD) with a proper learning rate, 
show \textit{higher predictability} compared to malicious updates. 
This hypothesis stems from the fact that the sequence of gradients (hence, model parameters) observed during legitimate training should exhibit ``regular'' patterns until convergence. 
%This regularity is possibly more pronounced in the case of smooth convex loss functions, but it can still be captured within an appropriate time frame, even for more complex and convoluted loss surfaces.
\\
To demonstrate this behavior, we consider two clients $i,j \in \mathcal{C}$. Client $i$ is assumed to be a legitimate participant, while client $j$ acts maliciously. %alternates between legitimate and malicious behavior over several FL rounds. 
Both are selected by the server over a sequence of consecutive $T$ FL rounds to train a global model on the \textit{MNIST} dataset.
Therefore, we examine the local models sent to the server at each round $t \in \{1,2,\ldots,T\}$ by clients $i$ and $j$. Specifically, these are $d$-dimensional vectors of real-valued parameters $\params_i^{(t)}, \params_j^{(t)} \in \R^d$, such that $\params_i^{(t)} = (\theta_{i,1}^{(t)}, \ldots, \theta_{i,d}^{(t)})$ and $\params_j^{(t)} = (\theta_{j,1}^{(t)}, \ldots, \theta_{j,d}^{(t)})$, respectively.
Next, we calculate the average time-delayed mutual information (TDMI) for each pair of observed local models $(\params_i^{(t)}, \params_i^{(t')})$ and $(\params_j^{(t)}, \params_j^{(t')})$ across $T=50$ rounds, where $\delta > 0$, for both client $i$ and $j$. This analysis aims to discern the time-dependent nonlinear correlation and the level of predictability between observations. 
We expect the TDMI calculated between pairs of models sent by the legitimate client $i$ to be higher than that computed between pairs sent by the malicious client $j$. Thus, the temporal sequence of local models observed from client $i$ is more predictable than that of client $j$.
\\
%For a scalar random variable $X$ and its probability density function, $p(X)$, the TDMI of the time series generated by $X$ is computed as follows:
% \begin{equation}
% \text{TDMI}(X^{(t)}, X^{(t')}) = \int p(X^{(t)}, X^{(t')})\times \log\Bigg(\frac{p(X^{(t)}, X^{(t')})}{p(X^{(t)})p(X^{(t')})}\Bigg) dX^{(t)} dX^{(t')}.
% \label{eq:tdmi}
% \end{equation}
Let $\params_c^{(t)} = (\theta_{c,1}^{(t)}, \ldots, \theta_{c,d}^{(t)})$ denote the local model sent by the generic FL client $c\in \mathcal{C}$ as an instance of a $d$-dimensional vector-valued process. 
We define $\text{TDMI}(\params_c^{(t)}, \params_c^{(t')})$ as follows: 
%\begin{equation}
%\small
%\text{TDMI}(\params_c^{(t)}, \params_c^{(t+\delta)}) =  \int p(\params_c^{(t)}, \params_c^{(t+\delta)})\times \log\Bigg(\frac{p(\params_c^{(t)}, \params_c^{(t+\delta)})}{p(\params_c^{(t)})p( \params_c^{(t+\delta)})}\Bigg) d\params_c^{(t)} d\params_c^{(t+\delta)},
%\label{eq:tdmi2}
%\end{equation}
\begin{equation}
\footnotesize
\text{TDMI}(\params_c^{(t)}, \params_c^{(t')}) =  \int p(\params_c^{(t)}, \params_c^{(t')})\times \log\Bigg(\frac{p(\params_c^{(t)}, \params_c^{(t')})}{p(\params_c^{(t)})p( \params_c^{(t')})}\Bigg) d\params_c^{(t)} d\params_c^{(t')},
\label{eq:tdmi2}
\end{equation}

where $p(\cdot)$ is the probability density function and $t'=t+\delta$. %and $\params^{(\cdot)}$ and $d\params^{(\cdot)}$ are both random vectors.
% We need to calculate the average TDMI, namely:
% \[
% \frac{1}{d}\Big[\text{TDMI}(\params^{(t)}, \params^{(t')})\Big].
% \]
If each realization $\theta_{c,k}^{(t)}$ in the vector $\params_c^{(t)}$ is \textit{independent} from each other, we can compute the average TDMI as follows~\cite{albers2012chaos}:
\begin{equation}
\small
\text{Avg}\Big[\text{TDMI}(\params_c^{(t)}, \params_c^{(t')})\Big] = \frac{1}{d}\Bigg[\sum_{k=1}^d \text{TDMI}(\theta_{c,k}^{(t)}, \theta_{c,k}^{(t')})\Bigg], 
\label{eq:avg-tdmi}
\end{equation}
where TDMI$(\theta_{c,k}^{(t)}, \theta_{c,k}^{(t')})$ calculates TDMI for the univariate case.
% \[
% \frac{1}{d}\Big[\text{TDMI}(\params^{(t)}, \params^{(t')})\Big] = \frac{1}{d}\Bigg[\sum_{k=1}^d \text{TDMI}(\theta_k^{(t)}, \theta_k^{(t')})\Bigg]. 
% \]
Indeed, the $d$ model parameters $\theta_{c,k}^{(\cdot)}$ should reasonably be independent. Under this assumption, the joint probability density function of the parameters factors into a product of individual probability density functions, forming a product measure on $d$-dimensional Euclidean space. Thus, according to Fubini's theorem~\cite{billingsley2017probability}, the integral of each parameter will be independent of the others because the parameters are independent.
\\
To mimic the behavior of a hypothetical optimal FLANDERS filter, and therefore avoid the propagation of poisoned local models sent by client $j$ across the $T$ rounds, we assume that, at each round $t$, the global model from which both clients start their local training process is polished from any malicious updates received at the previous round $t-1$.
Next, we calculate the average time-delayed mutual information (TDMI) for each pair of observed local models $(\params_i^{(t)}, \params_i^{(t')})$ and $(\params_j^{(t)}, \params_j^{(t')})$ across $T=50$ rounds, where $t' > t$, for both client $i$ and $j$.
Firstly, we consider the special case where $t'=t+1$ and compute the average TDMI between each pair of \textit{consecutive} local models sent by the legitimate client and the malicious client, when this runs one of the four attacks considered in this work, namely GAUSS, LIE, OPT, and AGR-MM presented in Section~\ref{subsec:attacks}.
In Figure~\ref{fig:avg-tdmi-density}, we plot the empirical distributions of the observed average TDMI for the legitimate and malicious clients. 
\begin{figure}[ht!]
    \centering
    \includegraphics[width=\columnwidth]{./img/tdmi-density}
    \caption{Empirical distributions of average TDMI computed between each pair of \textit{consecutive} local models sent by the legitimate client $i$ $(\params_i^{(t)}, \params_i^{(t+1)})$ and the malicious client $j$ $(\params_j^{(t)}, \params_j^{(t+1)})$, when this runs one of the four attacks considered in this work, namely GAUSS, LIE, OPT, and AGR-MM.}
    \label{fig:avg-tdmi-density}
\end{figure}
To validate our claim that legitimate models are more predictable than malicious ones, we compute the mean of the empirical distributions for the legitimate and malicious client, $\bar{\params_i}$ and $\bar{\params_j}^{atk}$, respectively, where $atk=\{$GAUSS, LIE, OPT, AGR-MM$\}$. Then, we run a one-tailed $t$-test against the null hypothesis $H_0: \bar{\params_i} = \bar{\params_j}^{atk}$, where the alternative hypothesis is $H_a: \bar{\params_i} > \bar{\params_j}^{atk}$. 
The results of these statistical tests are illustrated in Table~\ref{tab:t-test}, showing that, in all four cases, there is enough evidence to reject the null hypothesis at a confidence level $\alpha=0.01$.

%\begin{table}[htb!]
%\centering
%\caption{One-tailed $t$-test against the null hypothesis $H_0: \bar{\boldsymbol{\theta}_i} = \bar{\boldsymbol{\theta}_j}^{atk}$. Each cell contains the $p$-value for the statistical test corresponding to a specific attack. In all four cases, there is enough evidence to reject the null hypothesis at a confidence level $\alpha=0.01$ ($p$-value $\ll 0.01$).}
%\label{tab:t-test}
%\begin{tabular}{c|c|c|c|c|}
%\cline{2-5}
%& \multicolumn{4}{c|}{$atk$}\\
%\cline{2-5}
%& GAUSS & LIE & OPT & AGR-MM \\
%\hline
%\multicolumn{1}{|c|}{$H_0: \bar{\boldsymbol{\theta}_i} = \bar{\boldsymbol{\theta}_j}^{atk}$} & $5.67*10^{-38}$ & $8.33*10^{-5}$ & $6.70*10^{-18}$ & $4.20*10^{-12}$\\
%\hline
%\end{tabular}
%\end{table}

\begin{table}[htb!]
\centering
\caption{One-tailed $t$-test against the null hypothesis $H_0: \bar{\boldsymbol{\theta}_i} = \bar{\boldsymbol{\theta}_j}^{atk}$. Each cell contains the $p$-value for the statistical test corresponding to a specific attack. In all four cases, there is enough evidence to reject the null hypothesis at a confidence level $\alpha=0.01$ ($p$-value $\ll 0.01$).}
\label{tab:t-test}
\begin{tabular}{cc}
    \toprule
    & \rule{0pt}{3pt} $H_0: \bar{\boldsymbol{\theta}_i} = \bar{\boldsymbol{\theta}_j}^{atk}$ \\
    \midrule
    \multicolumn{1}{c}{GAUSS} & $5.67*10^{-38}$ \\
    \midrule
    \multicolumn{1}{c}{LIE} & $8.33*10^{-5}$ \\
    \midrule
    \multicolumn{1}{c}{OPT} & $6.70*10^{-18}$ \\
    \midrule
    \multicolumn{1}{c}{AGR-MM} & $4.20*10^{-12}$ \\
    \bottomrule
\end{tabular}
\end{table}


%In conclusion, the average TDMI for the vector of parameters is obtained by calculating the TDMI for each individual parameter and subsequently averaging these values.

% TBC

\subsection{Poisoned Local Models as Matrix-Based Time Series Outliers}
\label{subsec:ts-outliers}
We, therefore, formulate our problem as a multidimensional time series anomaly detection task.
At a high level, we want to equip the central server with an anomaly scoring function that estimates the degree of each client picked at the current round being malicious, i.e., its {\em anomaly score}, based on the historical observations of model updates seen so far from the clients selected.
%At a high level, we want to equip the central server $S$ with an anomaly scoring function $s: \mathcal{C} \mapsto \R$. This takes as input a client $c$ and, based on the historical observations of model updates seen so far (also from other clients $c'\neq c$), estimates the degree of $c$ being malicious, i.e., its anomaly score.
%probability of $c$ being malicious, i.e., its anomaly score.
Such a score will be used to restrict the set of trustworthy candidate clients for the downstream aggregation method. 
Note that unselected clients will \textit{not} contribute to the aggregation; thus, there is no need to compute their anomaly score even if they were marked as suspicious in some previous rounds.
On the other hand, we must design a fallback strategy for ``cold start'' clients  -- i.e., FL participants who send their local updates for the first time or have not been selected in any of the previous rounds considered  -- whether honest or malicious.
%More formally, let $Y_c\in \{0,1\}$ be a binary random variable, such that $Y_c = 1$ iff $c$ is malicious, or $0$ otherwise. Thus, our anomaly scoring function can be defined as follows:
% \begin{equation}
%     s(c) = \Pr(Y_c=1~|~\Params^{[1..T+\Delta]}),
% \end{equation}
% where $\Params^{[1..T+\Delta]}$ represents the time series of model updates observed, arranged as a $d\times m \times (T+\Delta)$ tensor. 
\\
% More formally, at the generic $t$-th FL round, the central server $S$ must compute the anomaly score $s_{c}^{(t)} \in \R$ of every selected client $c\in \mathcal{C}^{(t)}$. 
% To achieve that, we assume $S$ can leverage the past $w$ observations of model updates received, i.e., $\Params_{t-w:t-1}$, where $1\leq w \leq t-1$. 
More formally, let $\hat{\Params}_t = f(\Params_{t-w:t-1};\hat{\bm{\Omega}})$ be the matrix of local model updates \textit{predicted} by the central server $S$ at the generic FL round $t$. 
The forecasting model $f$ depends on a set of parameters $\hat{\bm{\Omega}}$ estimated using the past $w$ model updates observed, i.e., $\Params_{t-w:t-1}$, where $1\leq w \leq t-1$. 
Also, the server sees the actual matrix $\Params_t$.
\\
The anomaly score $s_{c}^{(t)} \in \R$ of the generic client $c$ at round $t$ can thus be defined as follows:
\begin{equation}
\small
\label{eq:anomaly-score}
s_{c}^{(t)} =
\begin{cases}
\delta(\params^{(t)}_c, \hat{\params}^{(t)}_c),\text{ if }c\in \mathcal{C}^{(t)} \wedge \exists j\in\{1..w\}\text{ s.t. }c\in \mathcal{C}^{(t-j)} \\
\delta(\params^{(t)}, \params^{(t)}_c), \text{ if }c\in \mathcal{C}^{(t)} \wedge \nexists j\in\{1..w\}\text{ s.t. }c\in \mathcal{C}^{(t-j)}\\
\perp, \text{ if }c\notin \mathcal{C}^{(t)}.
\end{cases}
\end{equation}
The first condition refers to a client selected for round $t$, which also appeared at least once in the history. 
In this case, $\delta$ measures the distance between the observed vector of weights sent to the server ($\params^{(t)}_c$) and the predicted vector of weights ($\hat{\params}^{(t)}_c$) output by the forecasting model $f$.
The second condition, instead, occurs when a client is selected for the first time at round $t$ or does not appear in the previous $w$ historical matrices of observations used to generate predictions. Here, due to the cold start problem, we cannot rely on $f$ and, therefore, the most sensible strategy is to compute the distance between the current global model and the local update received by the new client. 
Finally, the anomaly score is undefined ($\perp$) for any client not selected for round $t$.
\\
The server will thus rank all the $m$ selected clients according to their anomaly scores (e.g., from the lowest to the highest).
Several strategies can be adopted to choose which model updates should be aggregated in preparation for the next round, i.e., to restrict from the initial set $\mathcal{C}^{(t)}$ to another (possibly smaller) set $\mathcal{C}_{*}^{(t)}\subseteq \mathcal{C}^{(t)}$ of trusted clients. 
For example, $S$ may consider only the model updates received from the top-$k$ clients ($1 \leq k \leq m$) with the smallest anomaly score, i.e., $\mathcal{C}_*^{(t)} = \{c\in \mathcal{C}^{(t)}~|~s_{c}^{(t)} \leq s_k^{(t)}\}$, where $s_k^{(t)}$ indicates the $k$-th smallest anomaly score at round $t$. 
Alternatively, the raw anomaly scores computed by the server can be converted into well-calibrated probability estimates. 
%This is a well-known practice that has a nicer interpretation and has already been investigated~\cite{gao2006icdm}.
Here, the server sets a threshold $\rho \in [0,1]$ and aggregates the weights only of those clients whose anomaly score is below $\rho$, i.e., $\mathcal{C}_*^{(t)} = \{c\in \mathcal{C}^{(t)}~|~s_c^{(t)}\leq \rho\}$. 
In the former case, the number of considered clients ($k$) is bound apriori,\footnote{This may not be true if anomaly scores are not unique; in that case, we can simply enforce $|\mathcal{C}_*^{(t)}| = k$.} whereas the latter does not put any constraint on the size of final candidates $|\mathcal{C}_*^{(t)}|$.
Eventually, $S$ will compute the updated global model $\params^{(t+1)} = \phi(\{\params_c^{(t)}~|~c\in \mathcal{C}_*^{(t)}\})$, where $\phi$ is any aggregation function, e.g., FedAvg, Bulyan, or any other strategy.
%Notice that, under our hypothesis, no attack occurs until the $L$-th FL round; therefore, we should not find any significant anomaly score before that, i.e., $s_{c}^{(t)} \approx 0,~\forall c\in \mathcal{C},~\forall t \in \{1, \ldots, L\}$.

%Several techniques can be used to compute the anomaly scoring function. 
%Broadly speaking, we can distinguish between: conventional (also referred to as statistical) approaches, machine learning-based and deep learning-based methods.
%In this work, we leverage the matrix autoregressive (MAR) framework for multidimensional time series forecasting~\cite{chen2021je}.
Below, we describe how we use the matrix autoregressive (MAR) framework proposed by \cite{chen2021je} to implement our multidimensional time series forecasting model $f$, hence the anomaly score.

