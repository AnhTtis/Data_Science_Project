\section{Non-convex loss}
\label{sec:nonconvex}
When the loss function $\ell$ is non-convex, SGD like any other first order method can get trapped in a local minimum or a saddle point of the landscape. When there is no distribution shift,
there is a line of work showing that SGD can efficiently escape saddle points if the step size is large enough~\citep{lee2016gradient,jin2017escape}.
This superiority of SGD in non-convex settings is often attributed to  the stochasticity of the gradients,
which significantly accelerates the escape from saddle points.

In non-convex settings one cannot control convergence to a global minimum without making further structural assumption on the optimization landscape and the initialization of SGD. In view of that, we propose to consider the following notion of regret based on the cumulative gradient norm of the SGD trajectory:
\begin{align}
    \Reg(T) := \sum_{t=1}^T \|\nabla\ellbar_t(\theta_t)\|^2\,.
\end{align}
In words, the regret is defined with respect to the norm of gradient at the sequence of estimated models. This notion does not differentiate between local or global minima.

Further, due to the complex landscapes of non-convex loss,
we work with a more holistic measure of distribution shift, namely
\begin{align}\label{eq:gamma-Nconv}
    \gamma_t: = \sup_{\theta \in \mathbb{R}^p} |\ellbar_t(\theta) - \ellbar_{t+1}(\theta)|\,.
\end{align}
Recall that $\ellbar_t = \E_{P_t}[\ell(\theta,z_{t,k})]$ and obviously if there is no shift at step $t$, i.e., $P_t = P_{t+1}$ then $\gamma_t=0$. In contrast, in the convex setting, we measure the distribution shift only in terms of the difference between the global minimizers of $\ellbar_t$ and $\ellbar_{t+1}$, cf. Definition~\ref{def:shift}.

% We establish a regret bound for the non-convex setting under Assumption~\ref{ass:main} $(i),(ii)$. 
% Note that by part $(ii)$ of this assumption, $\|\nabla\ellbar_t(\theta)\|$ is continuous and so achieves its maximum over the bounded set $\Theta$. Define 
% \begin{align}\label{eq:M}
% M: = \sup_{\theta\in\Theta}\|\nabla \ellbar_t(\theta)\|.
% \end{align}
We can now state our regret bound in the non-convex setting.
%
\begin{thm}\label{thm:non-Nconvex-reg}
Suppose the learning rates $\eta_t$ are adapted to the history $\bz_{t-1}$, defined by~\eqref{eq:history}. Let $\gamma_t$ be defined as~\eqref{eq:gamma-Nconv}, and define $a_t: = 2\eta_t - L\eta_t^2$, for $t\ge 1$. Under Assumption~\ref{ass:main} $(i),(ii)$, and assuming $\eta_t\le \frac{1}{L}$, for all $t\ge 1$, we have the 
following bound on the total regret of batch SGD:
\begin{align}
\label{eq:Reg-UB-Nconv}
\E[\Reg(T)]
    &\le 
    \E\left[
      \frac{2\ellbar_1(\theta_1)}{a_1^2}
    + \sum_{t=2}^T 2\ellbar_t(\theta_t) \left(\frac{1}{a_t} - \frac{1}{a_{t-1}^2}\right)\right]
    +\sum_{t=1}^T\E\left[\frac{1}{a_t} \cdot \left(\frac{L\sigma^2\eta_t^2}{B_t} + 2\gamma_t\right)\right]\,.
\end{align}
%Here, the expectation is with respect to the randomness in data points observed in the $T$ steps.
\end{thm}
The theorem above has a very similar format to the bound derived in Theorem~\ref{thm:convex-reg}.
By minimizing the regret of the upper bound
\eqref{eq:Reg-UB-Nconv} in sequential manner
conditioned on $\bz_{[t-1]}$,
the optimal learning rate is given by
\begin{align}\label{eq:etat*-Nconv}
    \eta_t^*:= \argmin_{0\le \eta\le \frac{1}{L}} 
    \frac{2\ellbar_t(\theta_t)+2\gamma_t}{2\eta-L\eta^2} 
    +\frac{L\sigma^2}{B_t}\cdot\frac{\eta^2}{2\eta-L\eta^2}\,.
\end{align}
The optimal $\eta^*_t$ admits a closed form solution given below:
\[
\eta^*_t = \tfrac{B_t}{L\sigma^2}\left(\sqrt{b_t^2+2\tfrac{\sigma^2}{B_t} b_t} - b_t\right)\,, \; b_t = L(\gamma_t+\ellbar_t(\theta_t))\,.
\]
The above characterization is derived by noticing that the function in~\eqref{eq:etat*-Nconv} is convex in $\eta$, for $\eta\in (0,1/L]$ and the stationary point of the function $\eta^*$ satisfies the boundary condition $0\le \eta^*\le 1/L$.

%
% \begin{propo}\label{propo:optimal-eta-Nconv}
% Define the thresholds $\tau_1$ and $\tau_2$ as follows:
% \begin{align*}
%     \tau_{1,t}&:= \frac{B_t}{\sigma^2}\left(\sqrt{\gamma_t^2+\frac{2\sigma^2}{LB_t} \gamma_t} - \gamma_t\right), \\
%     \tau_{2,t}&:= \frac{B_t}{\sigma^2}\left(\sqrt{(\gamma_t+M)^2+\frac{2\sigma^2}{LB_t} (\gamma_t+M)} - \gamma_t-M\right), 
% \end{align*}
% The optimal learning rate $\eta_t^*$ defined by~\eqref{eq:etat*} is given by:
% \begin{align}
%     \eta^*_t = \begin{cases}
%     \tau_{1,t} & \text{if } \eta_{t-1}\le \tau_{1,t},\\
%     \eta_{t-1} & \text{if } \tau_1\le \eta_{t-1}\le \tau_{2,t}\\
%     \tau_{2,t} & \text{if } \eta_{t-1}\ge \tau_{2,t}\,.
%     \end{cases}
% \end{align}
% \end{propo}
% \begin{remark}
% It is easy to verify that the thresholds $\tau_{1,t},\tau_{2,t}$ are increasing in $\gamma_t$. Therefore, for every value of $\eta_{t-1}$  the optimal learning rate $\eta^*_t$ is increasing in distribution shift $\gamma_t$.
% \end{remark}
It is easy to see that the learning rate $\eta^*_t$ is increasing in the distribution shift $\gamma_t$. To implement this learning rate, we estimate $\ellbar_t(\theta_t)$ by $\ell^{B_t}(\theta_t)$, its sample average over the batch at time $t$.
The proofs are deferred to the supplementary materials
due to the space constraint.