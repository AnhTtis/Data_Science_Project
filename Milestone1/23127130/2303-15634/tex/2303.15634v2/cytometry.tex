\subsection{Flow cytometry}
\label{app:cyto}

Next we explore a medical application called \emph{flow cyotometry},
which uses neural networks and online stochastic optimization to
classify cells as they arrive in a stream from a shifting data distribution.
The features this model receives as input are measurements based on the
RNA expressions of each cell
(see, e.g.,~\citet{LMC19,cyt3,cyt2} and the references therein for details).
This induces a learning problem with a
non-convex loss landscape that changes with time,
where we do not have a tight characterization for an optimal learning rate schedule.

\subsubsection{Background}

We start with background on flow cytometry
to give more context for this application.
A sample of cells from a tissue is prepared
and a small number of selected RNA sequences in the cells
are bound to different fluorescent markers.
A laser then illuminates the incoming stream of cells,
which can now be separated based on the
intensity of the signals from different fluorescent markers.
Using fluorescent markers, however, comes at a cost
as they can interfere with normal cellular functioning.
In contrast, marker-free systems that use large convolutional neural nets
are often more accurate, but can be slower to adapt to distribution shifts. See~\citet{LMC19} for further details. 

We study a two-step system that does initial classification
with an inexpensive ``student'' neural network and only relies on a
small number of fluorescent markers.
This is followed by additional analysis
using a large pretrained convolutional neural network (CNN)
with near real-time feedback.
As a simplification, we assume the expensive CNN is a ``teacher'' model
whose predictions are ground truth labels.
We can achieve real-time feedback for the initial classifier
that first sees the cells by replicating the teacher across
servers to increase its inference throughput.
The goal is to optimize the (inexpensive) classifier online
and minimize its loss,
i.e., the number of misclassified cells.
%\footnote{If the feedback is not real-time, then training the initial simpler neural net with larger batch size can capture the effect of delay in feedback due to the slower and larger neural net.}
%The goal is to train the smaller neural net online to optimize for loss---the number of misclassified cells.

The distribution of the arriving cells can change based on the
sample preparation and tissue characteristics.
For example, for pancreatic tissue, if we stream the cells starting from anterior to posterior,
the initial mixture of cells consists of more non-secreting cells
but later will have a higher proportion of secreting cells.
Thus, as a simplification, it is worth exploring the effect of different learning rate schedules for a simple online neural network
that classifies the input stream of cells into different cell types
based on a small number of RNA expression markers in each cell.
We use the pancreatic RNA expression data in
\cite{Bastdas-Ponce,Bergen20}.\footnote{This data is available at \url{https://scvelo.readthedocs.io/scvelo.datasets.pancreas/}.}
%and a single layer neural net with ELU activation to simulate this set-up. See the details below.

Specifically, we use the expression levels of ten RNA molecules
(corresponding to genes Pyy, Meg3, Malat1, Gcg, Gnas, Actb, Ghrl, Rsp3, Ins2 and Hspa8)
for the $4000$ murine pancreatic cells in the
\href{https://scvelo.readthedocs.io/scvelo.datasets.pancreas/}{\texttt{scVelo}} repository.
The expression levels of these genes determines the cell types completely.
We slightly perturb the expression levels to generate a stream of cells,
and within this stream we vary the distribution of secreting cells
(i.e., alpha, beta, and delta)
and non-secreting cells (i.e., ductal),
starting from non-secreting cells dominating the distribution
and ending with secreting cells dominating the distribution.
\Cref{fig:flow_cytometry} (left) is a two-dimensional embedding of these ten
signals labeled by their cell-type.
In practice, any stream of cells undergoes a similar distribution shift
depending on how the samples are prepared.

\begin{figure*}
    \centering

    \hspace{-0.3cm}
    \raisebox{0.3cm}{
        \includegraphics[width=0.45\textwidth]{figures/velocity_graph_v1.png}
    }
    %\caption{}\label{fig:cytometry_visualization}
    \hspace{0.2cm}
    \includegraphics[width=0.48\textwidth]{figures/n100_b64_ce_regret_train.png}
    \caption{
    Visualization of the 10-dimensional cytometry data and their ground truth labels (left).
    Cumulative regret of online models using different initial learning rates and
    optional Adam restarts at the beginning of each distribution shift (right).
    }\label{fig:flow_cytometry}
    \vspace{-0.2cm}
\end{figure*}

\subsubsection{Experimental setup: Model and cytometry simulation}
The following is a description of our simulation setup:

\begin{itemize}
    \item \emph{Training data and distribution shift:}
    Each training example is a $10$-dimensional vector $x \in \mathbb{R}^{10}$
    drawn from a mixture distribution of 4000 murine pancreatic cells
    and updated by randomly perturbing each of its RNA expressions
    by a factor $U \sim [0.9, 1.1]$ drawn i.i.d.
    The label $y$ is the cell type: ductal, alpha, beta, delta.
    We consider a shift between four different mixture distributions:
    \begin{enumerate}
        \item $P_1(y) = (0.0, 0.0, 0.0, 1.0)$ for $100$ steps
        \item $P_2(y) = (0.0, 0.0, 0.1, 0.9)$ for $100$ steps
        \item $P_3(y) = (0.1, 0.0, 0.2, 0.7)$ for $200$ steps
        \item $P_4(y) = (0.3, 0.5, 0.1, 0.1)$ for $200$ steps
    \end{enumerate}
    The first distribution only contains perturbed 
    non-secretory (ductal) cells.
    Then, each successive mixture distribution increases the probability of
    a secretory cell, simulating the cell arrival statistics
    as we sweep from right to left over a section of the pancreas for this data.
    
    % For stability of our results, we compute the average regret which is  an average over $10$ independent identical sub-instances. Each sub-instance consists of a stream of $10$-dimensional RNA expressions that is generated by randomly perturbing the pancreatic RNA expression data by a factor of $\pm 10\%$. The length of the stream is around $15,000$ examples. 

    % The non-secretory cells (``ductal cells'') are sampled and their expression levels perturbed by at most $10\%$ and given a class value of $0$. On the other end of the spectrum, the secretory cells (``alpha'', ``beta'', and ``delta'' cells) are given class values of $0.75$, $1.0$ and $0.5$ respectively.  We train for $14,000$ examples, and after every $2,250$ examples the input distribution jumps to a different distribution. Each successive distribution has about $10\%$ more secretory cells vs non-secretory cells than the previous distribution.\footnote{This roughly simulates the arrival of cells in right to left order from a section of the pancreas.}
    
    \item \emph{Neural network:}
    The input is a $10$-dimensional vector of RNA expression levels for the cell.
    We then use a feedforward neural network with five hidden layer and dimensions
    $(64, 32, 16, 8, 4)$.
    Each hidden layer uses an ELU activation,
    and the last $4$-dimensional embedding after activation are the logits
    for the cell type.

    % We set up the simulation as a multi-class classification problem on our single hidden layer network ($10$ neurons width, ELU activation\footnote{The ReLU suffers from a dead neuron problem in such small symmetric network with positive inputs, hence our choice of ELU.} in the hidden layer and sigmoid activation for the output neuron). 
    
    \item \emph{Loss and optimizer:}
    We use categorical cross entropy loss
    with \texttt{from\_logits=true} for stability.
    Each step uses a batch of $B_t = 64$
    new examples to simulate the data stream.
    We optimize this model in an online manner using
    Adam~\citep{kingma2014adam}
    for different initial learning rates
    and by optionally resetting its parameters at the beginning of a distribution shift.
    We plot the cumulative regret in \Cref{fig:flow_cytometry} (right),
    where the regret for each step is defined in \eqref{eqn:regret_def}.

    %\item \emph{Evaluation metric:} We plot the regret calculated from a $10\%$ holdout of training data in Figure~\ref{fig:flow-cyt-summary}. Each of the cell types is completely characterized by the chosen 10 different gene expressions. Therefore, the validation loss in absence of distribution shift will quickly fall to $0$ for SGD, even with a simple one layer neural net. Therefore, the regret without distribution shift is close to $0$, and the validation loss at any time-point minus any initial loss (after training on the first few hundred examples) should be close to regret at that time-point. We compute this approximation of regret, average it (as mentioned above), and plot it vs the number of examples seen in Figure~\ref{fig:flow-cyt-summary}. 
\end{itemize}

\subsubsection{Results}
We draw several conclusions from this experiment.
First, while larger learning rates are often better for minimizing the regret of an online
SGD-based system, there is a normally a sweet spot before the
first step size that causes the SGD to diverge.
In this experiment, an initial learning rate of $0.1$ for Adam
caused the model to diverge
but the total regret is minimized with an initial learning rate of $0.01$,
achieving less regret than $\eta_0 \in \{0.001, 0.003, 0.03\}$.
Second, resetting the Adam optimizer at the beginning of each distribution shift
(which increases its step size) allows us to achieve less
cumulative regret, as these models more quickly adapt to the new data distributions.
Finally, the models get stuck in local minima without
adaptive and increasing learning rate schedules, as evident by the
$\eta_0 = 0.03$ plots in \Cref{fig:flow_cytometry} (right),
which have different slopes in the final two phases.

% \begin{itemize}
%     \item We see that for constant learning rate schedules, the average regret decreases with increasing learning rate but after a certain point the higher learning rate is counterproductive. For this dataset derived from pancreatic RNA expressions,
%     the optimal constant learning rate is around $\eta_t = 0.005$.
%     \item The average regret of an adaptive learning rate schedule that is high only at time points when a shift in input distribution occurs is lower than the average regret of the optimal constant rate schedule, even though we keep the average learning rate same. 
%     \item Finally, if we vary the batch size but keep the frequency of jumps in input distribution constant, then we find that large batch sizes can be counterproductive.
%     This is because the model
%     sees fewer batches between two successive jumps in the input distribution. 
% \end{itemize}