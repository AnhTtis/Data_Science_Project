\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage[numbers,sort&compress]{natbib}
\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.
% Ours
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{enumitem}
\usepackage[hypcap=false,font=small]{caption}
% \usepackage{subcaption}
% \usepackage{tabu}
\usepackage[table, svgnames]{xcolor}
\usepackage{microtype}
\usepackage{xspace}

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

% Comments
\newcommand{\option}[1]{{\color{black}{\small\bf\sf [#1]}}}
\newcommand{\kg}[1]{{\color{blue}{\small\bf\sf [KG: #1]}}}
\newcommand{\todo}[1]{{\color{red}{\small\bf\sf [TODO: #1]}}}
\newcommand{\vjnote}[1]{{\color{magenta}{\small\bf\sf [Varun: #1]}}}
\newcommand{\aknote}[1]{{\color{cyan}{\small\bf\sf [Abhishek: #1]}}}

% Math shortcuts
\newcommand{\backronym}{ASIC\xspace}
\newcommand{\myparagraph}[1]{\medskip\noindent\textbf{#1}}

\input{math_commands}
\linepenalty=1000

\makeatletter
\g@addto@macro{\endtabular}{\rowfont{}}% Clear row font
\makeatother
\newcommand{\rowfonttype}{}% Current row font
\newcommand{\rowfont}[1]{% Set current row font
\gdef\rowfonttype{#1}#1\ignorespaces%
}
\makeatother
% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{4552} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi

\begin{document}

%%%%%%%%% TITLE
\title{\vspace{-2em} ASIC: Aligning Sparse in-the-wild Image Collections}

% \author{First Author\\
% Institution1\\
% Institution1 address\\
% {\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
% \and
% Second Author\\
% Institution2\\
% First line of institution2 address\\
% {\tt\small secondauthor@i2.org}
% }
\author{Kamal Gupta\textsuperscript{\rm 1,2}, Varun Jampani\textsuperscript{\rm 1}, Carlos Esteves\textsuperscript{\rm 1}, \\
Abhinav Shrivastava\textsuperscript{\rm 2}, Ameesh Makadia\textsuperscript{\rm 1}, Noah Snavely\textsuperscript{\rm 1},  Abhishek Kar\textsuperscript{\rm 1}\hfill \\ \\
\textsuperscript{\rm 1}Google \quad \quad
% {\tt\small \{varunjampani,machc,snavely,makadia,abhiskar\}@google.com}
\textsuperscript{\rm 2}University of Maryland, College Park\\
% {\tt\small \{kampta,abhinav\}@cs.umd.edu}
}

\twocolumn[{%
\renewcommand\twocolumn[1][]{#1}%
\maketitle
\begin{center}
    \centering
    \vspace{-1.2em}
    \includegraphics[width=0.97\textwidth]{imgs/Teaser.pdf}
    \vspace{-0.5em}
    \captionof{figure}{\textbf{Globally consistent and dense aligments with ASIC.} Given a small set ($\sim$10-30) of images of an object or object category captured in-the-wild, our framework computes a dense and consistent mapping between all the images in a self-supervised manner. \textbf{First row:} Unaligned sets of images from the SAMURAI (Keywest) and SPair-71k (Cow) datasets. \textbf{Second row:} Dense correspondence maps produced by our method. \textbf{Third row:} Image in the first column warped to the images in columns 2-5. %\textbf{Fourth row:} An edit propagation application. We can propagate edits on any one image to all other images in the collection via our dense correspondence maps.
    }
    \label{fig:teaser}
\end{center}
}] 

\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi


%%%%%%%%% ABSTRACT
\begin{abstract}
\vspace{-3mm}
  We present a method for joint alignment of sparse in-the-wild image collections of an object category. Most prior works assume either ground-truth keypoint annotations or a large dataset of images of a single object category. However, neither of the above assumptions hold true for the long-tail of the objects present in the world. We present a self-supervised technique that directly optimizes on a sparse collection of images of a particular object/object category to obtain consistent dense correspondences across the collection. We use pairwise nearest neighbors obtained from deep features of a pre-trained vision transformer (ViT) model as noisy and sparse keypoint matches and make them dense and accurate matches by optimizing a neural network that jointly maps the image collection into a learned canonical grid. Experiments on CUB and SPair-71k benchmarks demonstrate that our method can produce globally consistent and higher quality correspondences across the image collection when compared to existing self-supervised methods.
  Code and other material will be made available at \url{https://kampta.github.io/asic}.
\vspace{-5mm}
\end{abstract}

%%%%%%%%% BODY TEXT
%%%%%%%%% BODY TEXT
\input{1_intro}
\input{2_related}
\input{3_method}
\input{4_analysis}
\input{5_conclusions}

\clearpage
%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\clearpage
\appendix
\input{6_appendix}

\end{document}