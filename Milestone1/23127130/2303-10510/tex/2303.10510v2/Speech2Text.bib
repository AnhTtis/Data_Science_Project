@inproceedings{tilk2016,
	author    = {Ottokar Tilk and Tanel Alum{\"a}e},
	title     = {Bidirectional Recurrent Neural Network with Attention Mechanism for Punctuation Restoration},
	booktitle = {Interspeech 2016},
	year      = {2016}
}


@INPROCEEDINGS{7078634,
	author={Guo, Daniel and Tur, Gokhan and Yih, Wen-tau and Zweig, Geoffrey},
	booktitle={2014 IEEE Spoken Language Technology Workshop (SLT)}, 
	title={Joint semantic utterance classification and slot filling with recursive neural networks}, 
	year={2014},
	volume={},
	number={},
	pages={554-559},
	doi={10.1109/SLT.2014.7078634}}


@inproceedings{jia-2020-deep,
    title = "A Deep Learning System for Sentiment Analysis of Service Calls",
    author = "Jia, Yanan",
    booktitle = "Proceedings of the 3rd Workshop on e-Commerce and NLP",
    month = jul,
    year = "2020",
    address = "Seattle, WA, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.ecnlp-1.4",
    doi = "10.18653/v1/2020.ecnlp-1.4",
    pages = "24--34",
    abstract = "Sentiment analysis is crucial for the advancement of artificial intelligence (AI). Sentiment understanding can help AI to replicate human language and discourse. Studying the formation and response of sentiment state from well-trained Customer Service Representatives (CSRs) can help make the interaction between humans and AI more intelligent. In this paper, a sentiment analysis pipeline is first carried out with respect to real-world multi-party conversations - that is, service calls. Based on the acoustic and linguistic features extracted from the source information, a novel aggregated method for voice sentiment recognition framework is built. Each party{'}s sentiment pattern during the communication is investigated along with the interaction sentiment pattern between all parties.",
}


@misc{hsu,
  doi = {10.48550/ARXIV.2104.01027},
  
  url = {https://arxiv.org/abs/2104.01027},
  
  author = {Hsu, Wei-Ning and Sriram, Anuroop and Baevski, Alexei and Likhomanenko, Tatiana and Xu, Qiantong and Pratap, Vineel and Kahn, Jacob and Lee, Ann and Collobert, Ronan and Synnaeve, Gabriel and Auli, Michael},
  
  keywords = {Sound (cs.SD), Computation and Language (cs.CL), Machine Learning (cs.LG), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  
  title = {Robust wav2vec 2.0: Analyzing Domain Shift in Self-Supervised Pre-Training},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@InProceedings{pmlr-v48-amodei16,
    title = 	 {Deep Speech 2 : End-to-End Speech Recognition in English and Mandarin},
    author = 	 {Amodei, Dario and Ananthanarayanan, Sundaram and Anubhai, Rishita and Bai, Jingliang and Battenberg, Eric and Case, Carl and Casper, Jared and Catanzaro, Bryan and Cheng, Qiang and Chen, Guoliang and Chen, Jie and Chen, Jingdong and Chen, Zhijie and Chrzanowski, Mike and Coates, Adam and Diamos, Greg and Ding, Ke and Du, Niandong and Elsen, Erich and Engel, Jesse and Fang, Weiwei and Fan, Linxi and Fougner, Christopher and Gao, Liang and Gong, Caixia and Hannun, Awni and Han, Tony and Johannes, Lappi and Jiang, Bing and Ju, Cai and Jun, Billy and LeGresley, Patrick and Lin, Libby and Liu, Junjie and Liu, Yang and Li, Weigao and Li, Xiangang and Ma, Dongpeng and Narang, Sharan and Ng, Andrew and Ozair, Sherjil and Peng, Yiping and Prenger, Ryan and Qian, Sheng and Quan, Zongfeng and Raiman, Jonathan and Rao, Vinay and Satheesh, Sanjeev and Seetapun, David and Sengupta, Shubho and Srinet, Kavya and Sriram, Anuroop and Tang, Haiyuan and Tang, Liliang and Wang, Chong and Wang, Jidong and Wang, Kaifu and Wang, Yi and Wang, Zhijian and Wang, Zhiqian and Wu, Shuang and Wei, Likai and Xiao, Bo and Xie, Wen and Xie, Yan and Yogatama, Dani and Yuan, Bin and Zhan, Jun and Zhu, Zhenyao},
    booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
    pages = 	 {173--182},
    year = 	 {2016},
    editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
    volume = 	 {48},
    series = 	 {Proceedings of Machine Learning Research},
    address = 	 {New York, New York, USA},
    month = 	 {20--22 Jun},
    publisher =    {PMLR},
    pdf = 	 {http://proceedings.mlr.press/v48/amodei16.pdf},
    url = 	 {https://proceedings.mlr.press/v48/amodei16.html},
    abstract = 	 {We show that an end-to-end deep learning approach can be used to recognize either English or Mandarin Chinese speech–two vastly different languages. Because it replaces entire pipelines of hand-engineered components with neural networks, end-to-end learning allows us to handle a diverse variety of speech including noisy environments, accents and different languages. Key to our approach is our application of HPC techniques, enabling experiments that previously took weeks to now run in days. This allows us to iterate more quickly to identify superior architectures and algorithms. As a result, in several cases, our system is competitive with the transcription of human workers when benchmarked on standard datasets. Finally, using a technique called Batch Dispatch with GPUs in the data center, we show that our system can be inexpensively deployed in an online setting, delivering low latency when serving users at scale.}
}


@inproceedings{NEURIPS2020_92d1e1eb,
    author = {Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
    pages = {12449--12460},
    publisher = {Curran Associates, Inc.},
    title = {wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations},
    url = {https://proceedings.neurips.cc/paper/2020/file/92d1e1eb1cd6f9fba3227870bb6d7f07-Paper.pdf},
    volume = {33},
    year = {2020}
}


@article{Lamel2002LightlySA,
    title={Lightly supervised and unsupervised acoustic model training},
    author={Lori Lamel and Jean-Luc Gauvain and Gilles Adda},
    journal={Comput. Speech Lang.},
    year={2002},
    volume={16},
    pages={115-129}
}


@inproceedings{jia-2020-deep,
    title = "A Deep Learning System for Sentiment Analysis of Service Calls",
    author = "Jia, Yanan",
    booktitle = "Proceedings of The 3rd Workshop on e-Commerce and NLP",
    month = jul,
    year = "2020",
    address = "Seattle, WA, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.ecnlp-1.4",
    doi = "10.18653/v1/2020.ecnlp-1.4",
    pages = "24--34",
    abstract = "Sentiment analysis is crucial for the advancement of artificial intelligence (AI). Sentiment understanding can help AI to replicate human language and discourse. Studying the formation and response of sentiment state from well-trained Customer Service Representatives (CSRs) can help make the interaction between humans and AI more intelligent. In this paper, a sentiment analysis pipeline is first carried out with respect to real-world multi-party conversations - that is, service calls. Based on the acoustic and linguistic features extracted from the source information, a novel aggregated method for voice sentiment recognition framework is built. Each party{'}s sentiment pattern during the communication is investigated along with the interaction sentiment pattern between all parties.",
}


@INPROCEEDINGS{6356906,
    author={Gaoxiong, Yi and Wei, Zhang},
    booktitle={2012 1st IEEE International Conference on Communications in China (ICCC)}, 
    title={The Perceptual Objective Listening Quality Assessment algorithm in telecommunication: Introduction of ITU-T new metrics POLQA}, 
    year={2012},
    volume={},
    number={},
    pages={351-355},
    doi={10.1109/ICCChina.2012.6356906}}


@inproceedings{Ragni2014DataAF,
    title={Data augmentation for low resource languages},
    author={Anton Ragni and Kate Knill and Shakti Prasad Rath and Mark John Francis Gales},
    booktitle={INTERSPEECH},
    year={2014}
}


@inproceedings{ctc,
    author = {Graves, Alex and Fernández, Santiago and Gomez, Faustino and Schmidhuber, Jürgen},
    year = {2006},
    month = {01},
    pages = {369-376},
    title = {Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural 'networks},
    volume = {2006},
    journal = {ICML 2006 - Proceedings of the 23rd International Conference on Machine Learning},
    doi = {10.1145/1143844.1143891}
}



@article{ds1,
    author = {Hannun, Awni and Case, Carl and Casper, Jared and Catanzaro, Bryan and Diamos, Greg and Elsen, Erich and Prenger, Ryan and Satheesh, Sanjeev and Sengupta, Shubho and Coates, Adam and Ng, Andrew},
    year = {2014},
    month = {12},
    pages = {},
    title = {DeepSpeech: Scaling up end-to-end speech recognition}
}





@inproceedings{semi,
    author = {Kapralova, Olga and Alex, John and Weinstein, Eugene and Moreno, Pedro and Siohan, Olivier},
    year = {2014},
    month = {09},
    pages = {2083-2087},
    title = {A big data approach to acoustic model training corpus selection},
    doi = {10.21437/Interspeech.2014-473}
}


@inproceedings{Jaitly2013VocalTL,
    title={Vocal Tract Length Perturbation (VTLP) improves speech recognition},
    author={Navdeep Jaitly and E. Hinton},
    year={2013}
}

@inproceedings{Ko2015AudioAF,
    title={Audio augmentation for speech recognition},
    author={Tom Ko and Vijayaditya Peddinti and Daniel Povey and Sanjeev Khudanpur},
    booktitle={INTERSPEECH},
    year={2015}
}








@inproceedings{wang-etal-2016-attention,
    title = "Attention-based {LSTM} for Aspect-level Sentiment Classification",
    author = "Wang, Yequan  and
      Huang, Minlie  and
      Zhu, Xiaoyan  and
      Zhao, Li",
    booktitle = "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2016",
    address = "Austin, Texas",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D16-1058",
    doi = "10.18653/v1/D16-1058",
    pages = "606--615",
}

@inproceedings{dos-santos-gatti-2014-deep,
    title = "Deep Convolutional Neural Networks for Sentiment Analysis of Short Texts",
    author = "dos Santos, C{\'\i}cero  and
      Gatti, Ma{\'\i}ra",
    booktitle = "Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",
    month = aug,
    year = "2014",
    address = "Dublin, Ireland",
    publisher = "Dublin City University and Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/C14-1008",
    pages = "69--78",
}

@inproceedings{pang-lee-2004-sentimental,
    title = "A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts",
    author = "Pang, Bo  and
      Lee, Lillian",
    booktitle = "Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ({ACL}-04)",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    url = "https://www.aclweb.org/anthology/P04-1035",
    doi = "10.3115/1218955.1218990",
    pages = "271--278",
}

@INPROCEEDINGS{Shan07beyondfacial,
    author = {Caifeng Shan and Shaogang Gong and Peter W. Mcowan},
    title = {Beyond facial expressions: Learning human emotion from body gestures},
    booktitle = {in Proc. British Machine Vision Conf},
    year = {2007}
}


@ARTICLE{4067013,
  author={Z. {Zeng} and J. {Tu} and M. {Liu} and T. S. {Huang} and B. {Pianfetti} and D. {Roth} and S. {Levinson}},
  journal={IEEE Transactions on Multimedia}, 
  title={Audio-Visual Affect Recognition}, 
  year={2007},
  volume={9},
  number={2},
  pages={424-428},}
  
  
@Article{Margarita:2012,
author = {Kotti, Margarita and Patern{\`o}, Fabio},
year = {2012},
month = {06},
pages = {},
title = {Speaker-independent Emotion Recognition Exploiting a Psychologically-inspired Binary Cascade Classification Schema},
volume = {15},
journal = {Int J Speech Technol}
}  %doi = {10.1007/s10772-012-9127-7}

@article{soujanya:2015,
    author = {Poria, Soujanya and Cambria, Erik and Hussain, Amir and Huang, Guang-Bin},
    year = {2014},
    month = {11},
    pages = {},
    title = {Towards an Intelligent Framework for Multimodal Affective Data Analysis},
    volume = {63},
    journal = {Neural Networks}
}   
    %doi = {10.1016/j.neunet.2014.10.005}

@book{stone:1966,
    author = {Stone, Philip and Dunphy, Dexter and Smith, Marshall and Ogilvie, Daniel},
    year = {1966},
    month = {01},
    pages = {},
    title = {The General Inquirer: A Computer Approach to Content Analysis},
    volume = {4},
    journal = {American Educational Research Journal}
}   
    
   % doi = {10.2307/1161774}

 
 
@article{pennebaker2001,
    author = {Pennebaker, James and Francis, M. and Booth, R.},
    year = {2001},
    month = {01},
    pages = {},
    title = {Linguistic Inquiry and Word Count ({LIWC}): {LIWC}2001},
    volume = {71},
    location  ={Mahwah, NJ: Erlbaum.}
}

@article{pennebaker2007,
    author = {Pennebaker, James and Chung, Cindy and Ireland, Molly and Gonzales, Amy and Booth, Roger},
    year = {2007},
    month = {01},
    pages = {},
    title = {The Development and Psychometric Properties of {LIWC}2007}
}




@article{soujanya:2014,
    author = {Poria, Soujanya and Gelbukh, Alexander and Cambria, Erik and Hussain, Amir and Huang, Guang-Bin},
    year = {2014},
    month = {07},
    pages = {},
    title = {{EmoSenticSpace}: A Novel Framework for Affective Common-Sense Reasoning},
    volume = {69},
    journal = {Knowledge-Based Systems}
}



@article{Liu10,
    author = {Bing Liu},
    title = {Sentiment analysis and subjectivity},
    journal = {Handbook of Natural Language Processing, Second Edition},
    year = {2010}
}

@inproceedings{Liu2012SentimentAA,
    title={Sentiment Analysis and Opinion Mining},
    author={Bing Liu},
    booktitle={Synthesis Lectures on Human Language Technologies},
    year={2012}
}


@article{AFINN2011,
    author = {Nielsen, Finn},
    year = {2011},
    month = {03},
    pages = {},
    title = {A new {ANEW}: Evaluation of a word list for sentiment analysis in
    microblogs},
    journal = {CoRR}
}

@article{sentiwordnet2013,
    author = {Alhazmi, Samah and Black, Bill and McNaught, J},
    year = {2013},
    month = {01},
    pages = {1-11},
    title = {Arabic {SentiWordNet} in Relation to {SentiWordNet} 3.0},
    volume = {4},
    journal = {International Journal of Computational Linguistics}
}


@article{senticnet2010,
    author = {Cambria, Erik and Speer, Robyn and Havasi, C. and Hussain, Amir},
    year = {2010},
    month = {01},
    pages = {14-18},
    title = {{SenticNet}: A publicly available semantic resource for opinion mining},
    journal = {AAAI Fall Symposium - Technical Report}
}


@article{hutto:2015,
    author = {Hutto, C.J. and Gilbert, Eric},
    year = {2015},
    month = {01},
    pages = {},
    title = {{VADER}: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text},
    journal = {Proceedings of the 8th International Conference on Weblogs and Social Media, ICWSM 2014}
}



@article{Janyce:2005,
    author = {Wiebe, Janyce and Wilson, Theresa and Cardie, Claire},
    year = {2005},
    month = {05},
    pages = {164-210},
    title = {Annotating Expressions of Opinions and Emotions in Language},
    volume = {39},
    journal = {Language Resources and Evaluation (formerly Computers and the Humanities)}
}  %   doi = {10.1007/s10579-005-7880-9}

@article{Wilson:2005,
    author = {Wilson, Theresa and Wiebe, Janyce and Hoffmann, Paul},
    year = {2005},
    month = {10},
    pages = {},
    title = {Recognizing Contextual Polarity in Phrase-Level Sentiment Analysis},
    journal = {Proceedings of HLT/EMNLP}
}       %doi = {10.3115/1220575.1220619}

@article{Bo:2004,
    author = {Pang, Bo and Lee, Lillian},
    year = {2004},
    month = {07},
    pages = {271-278},
    title = {A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts},
    volume = {271-278},
    journal = {Computing Research Repository - CORR}
}   %    doi = {10.3115/1218955.1218990}


@article{Carlo:2007,
    author = {Strapparava, Carlo and Mihalcea, Rada},
    year = {2007},
    month = {01},
    pages = {},
    title = {{SemEval}-2007 Task 14: Affective text},
    journal = {Proceedings of the 4th International Workshop on the Semantic Evaluations (SemEval 2007)}
}


@article{go:2009,
    author = {Go, Alec and Bhayani, Richa and Huang, Lei},
    year = {2009},
    month = {01},
    pages = {},
    title = {Twitter Sentiment Classification Using Distant Supervision},
    volume = {150},
    journal = {CS224N Project Report},
    address = {Stanford},    
}


@article{Socher:2013,
    author = {Socher, Richard and Perelygin, Alex and Wu, Jean Y. and Chuang, Jason and Manning, Christopher D.  and Ng, Andrew .Y. and Potts, Christopher},
    year = {2013},
    month = {01},
    pages = {1631-1642},
    title = {Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank},
    volume = {1631},
    journal = {EMNLP}
}


@article{cambria:2015,
    author = {Cambria, Erik and Fu, J. and Bisio, Federica and Poria, Soujanya},
    year = {2015},
    month = {01},
    pages = {508-514},
    title = {{AffectiveSpace 2}: Enabling Affective Intuition for Concept-level Sentiment Analysis},
    journal = {Proc. AAAI}
}



@article{eyben:2010,
    author = {Eyben, Florian and W{\"o}llmer, Martin and Schuller, Bj{\"o}rn},
    year = {2010},
    month = {01},
    pages = {1459-1462},
    title = {open{SMILE} -- The Munich Versatile and Fast Open-Source Audio Feature Extractor},
    journal = {MM'10 - Proceedings of the ACM Multimedia 2010 International Conference}
}  %doi = {10.1145/1873951.1874246}

@article{mcennis:2005,
    author = {McEnnis, Daniel and McKay, Cory and Fujinaga, Ichiro and Depalle, Philippe},
    year = {2005},
    month = {01},
    pages = {600-603},
    title = {j{A}udio: An Feature Extraction Library},
    journal = {Proceedings of the International Conference on Music Information Retrieval}
}

@article{eyben:2009,
    author = {Eyben, Florian and Wöllmer, Martin and Schuller, Bj{\"o}rn},
    year = {2009},
    month = {10},
    pages = {1 - 6},
    title = {open{EAR} - Introducing the Munich Open-source Emotion and Affect Recognition Toolkit},
    journal = {Affective Computing and Intelligent Interaction and Workshops, 2009. ACII 2009. 3rd International Conference}
}   %    doi = {10.1109/ACII.2009.5349350}



@inproceedings{poria:2015,
    title = "Deep Convolutional Neural Network Textual Features and Multiple Kernel Learning for Utterance-level Multimodal Sentiment Analysis",
    author = "Poria, Soujanya  and
      Cambria, Erik  and
      Gelbukh, Alexander",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D15-1303",
    doi = "10.18653/v1/D15-1303",
    pages = "2539--2544"
}


@article{erik:2017,
    author = {Cambria, Erik and Hazarika, Devamanyu and Poria, Soujanya and Hussain, Amir and Subramanyam, Rbv},
    year = {2017},
    month = {07},
    pages = {},
    title = {Benchmarking Multimodal Sentiment Analysis},
    url ={https://arxiv.org/abs/1707.09538},
    volume    = {arXiv:1707.09538},
    note = {version 1}
}


%
@inproceedings{jain:2018,
    author = {Jain, Manas and Narayan, Shruthi and Balaji, Pratibha and Bhowmick, Abhijit and Muthu, Rajesh},
    year = {2018},
    month = {03},
    pages = {},
    title = {Speech Emotion Recognition using Support Vector Machine}
}

@article{pan:2012,
    author = {Pan, Y and Shen, P and Shen, L},
    year = {2012},
    month = {01},
    pages = {101-108},
    title = {Speech emotion recognition using support vector machine},
    volume = {6},
    journal = {Int. J. Smart Home}
}


@article{aguilar2019,
    author = {Aguilar, Gustavo and Rozgic, Viktor and Wang, Weiran and Wang, Chao},
    year = {2019},
    month = {06},
    pages = {},
    title = {Multimodal and Multi-view Models for Emotion Recognition},
    url ={https://arxiv.org/abs/1906.10198},
    volume={arXiv:1906.10198},
    note = {version 1}
}




@Article{mcfee:2015,
    author = {McFee, Brian and Raffel, Colin and Liang, Dawen and Ellis, Daniel and Mcvicar, Matt and Battenberg, Eric and Nieto, Oriol},
    year = {2015},
    month = {01},
    pages = {18-24},
    title = {librosa: Audio and Music Signal Analysis in Python},
    journal = {in Proceedings of the 14th Python in Science Conference},
    volume= {8},
    year = {2015}
 }



@Article{sueur:2008,
    title = {Seewave: a Free Modular Tool for Sound Analysis and
    Synthesis},
    author = {Sueur, Jerome  and Aubin, Thierry  and  Simonis, Caroline},
    year = {2008},
    journal = {Bioacoustics},
    volume = {18},
    pages = {213-226},
}
  

@article{poria:2019,
    author = {Poria, Soujanya and Majumder, Navonil and Mihalcea, Rada and Hovy, Eduard},
    year = {2019},
    month = {05},
    pages = {},
    title = {Emotion Recognition in Conversation: Research Challenges, Datasets, and Recent Advances},
    url = {https://arxiv.org/abs/1905.02947},
    volume    = { arXiv:1905.02947},
    note ={version 1}
}




@article{Majumder:2019,
    author = {Majumder, Navonil and Poria, Soujanya and Hazarika, Devamanyu and Mihalcea, Rada and Gelbukh, Alexander and Cambria, Erik},
    year = {2019},
    month = {07},
    pages = {6818-6825},
    title = {Dialogue{RNN}: An Attentive {RNN} for Emotion Detection in Conversations},
    volume = {33},
    journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
    doi = {10.1609/aaai.v33i01.33016818}
}

@inproceedings{Hazarika:2018a,
    author = {Hazarika, Devamanyu and Poria, Soujanya and Mihalcea, Rada and Cambria, Erik and Zimmermann, Roger},
    year = {2018},
    month = {01},
    pages = {2594-2604},
    title = {{ICON}: Interactive Conversational Memory Network for Multimodal Emotion Detection},
    doi = {10.18653/v1/D18-1280}
}

@article{Busso:2008a,
    author = {Busso, Carlos and Bulut, Murtaza and Lee, Chi-Chun and Kazemzadeh, Abe and Mower Provost, Emily and Kim, Samuel and Chang, Jeannette and Lee, Sungbok and Narayanan, Shrikanth},
    year = {2008},
    month = {12},
    pages = {335-359},
    title = {{IEMOCAP}: Interactive Emotional Dyadic Motion Capture Database},
    volume = {42},
    journal = {Language Resources and Evaluation}
}  %doi = {10.1007/s10579-008-9076-6}


@article{Schuller:2012,
author = {Schuller, Bj{\"o}rn and Valstar, Michel and Cowie, Roddy and Pantic, Maja},
year = {2012},
month = {10},
pages = {},
title = {{AVEC} 2012 -- The Continuous Audio/Visual Emotion Challenge},
journal = {ICMI'12 - Proceedings of the ACM International Conference on Multimodal Interaction}
}   %doi = {10.1145/2388676.2388776}


@article{Mckeown:2013,
    author = {Mckeown, Gary and Valstar, Michel and Cowie, Roddy and Pantic, Maja and Schroder, M.},
    year = {2013},
    month = {08},
    pages = {5-17},
    title = {The {SEMAINE} Database: Annotated Multimodal Records of Emotionally Colored Conversations between a Person and a Limited Agent},
    volume = {3},
    journal = {Affective Computing, IEEE Transactions on}
}   %    doi = {10.1109/T-AFFC.2011.20}
%
%
%
@inproceedings{Carletta:2005,
    author = {Carletta, Jean and Ashby, Simone and Bourban, Sebastien and Flynn, Mike and Guillemot, Mael and Hain, Thomas and Kadlec, Jaroslav and Karaiskos, Vasilis and Kraaij, Wessel and Kronenthal, Melissa and Lathoud, Guillaume and Lincoln, Mike and Lisowska, Agnes and McCowan, Iain and Post, Wilfried and Reidsma, Dennis and Wellner, Pierre},
    title = {The {AMI} Meeting Corpus: A Pre-announcement},
    booktitle = {Proceedings of the Second International Conference on Machine Learning for Multimodal Interaction},
    year = {2006},
    pages = {28--39},
    publisher = {Springer-Verlag},
    address = {Berlin, Heidelberg},
} 


@article{Mckeown:2010,
    author = {Mckeown, Gary and Valstar, Michel and Cowie, Roddy and Pantic, Maja},
    year = {2010},
    month = {07},
    pages = {1079-1084},
    title = {The {SEMAINE} corpus of emotionally coloured character interactions},
    journal = {2010 IEEE International Conference on Multimedia and Expo, ICME 2010}
}   
%doi = {10.1109/ICME.2010.5583006}



@improceedings{olsson:2009,
    author = {Olsson, Fredrik},
    year = {2008},
    pages = {},
    title = {Bootstrapping named entity annotation by means of active machine learning: a method for creating corpora}
}



@article{serizel2017,
author = {Serizel, Romain and Bisot, Victor and Essid, Slim and Richard, Ga{\"e}l},
year = {2018},
month = {01},
pages = {71-101},
title = {Acoustic Features for Environmental Sound Analysis},
isbn = {978-3-319-63449-4},
journal = {Computational Analysis of Sound Scenes and Events},
doi = {10.1007/978-3-319-63450-0_4}
}
%

@article{Chartrand1999,
    Author = {Chartrand, Tanya L. , Bargh, John A.},
    Journal = {Journal of Personality and Social Psychology},
    Pages = {893-910},
    Title = {The Chameleon Effect: The Perception–Behavior Link and Social Interaction},
    Volume = {6},
    Year = {1999}
    }




@article{soujanya:2016,
author = {Poria, Soujanya },
year = {2016},
month = {01},
pages = {50-59},
title = {Fusing Audio, Visual and Textual Clues for Sentiment Analysis from Multimodal Content},
volume = {174},
journal = {Neurocomputing}
}
%


@INPROCEEDINGS{7178964,  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},  booktitle={2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},   title={Librispeech: An ASR corpus based on public domain audio books},   year={2015},  volume={},  number={},  pages={5206-5210},  doi={10.1109/ICASSP.2015.7178964}}


@inproceedings{libri,
author = {Kahn, J. and Riviere, M. and Zheng, W. and Kharitonov, Eugene and Xu, Q. and Mazare, P.E. and Karadayi, J. and Liptchinsky, V. and Collobert, R. and Fuegen, C. and Likhomanenko, T. and Synnaeve, Gabriel and Joulin, Armand and Mohamed, A. and Dupoux, Emmanuel},
year = {2020},
month = {05},
pages = {7669-7673},
title = {Libri-Light: A Benchmark for ASR with Limited or No Supervision},
doi = {10.1109/ICASSP40776.2020.9052942}
}