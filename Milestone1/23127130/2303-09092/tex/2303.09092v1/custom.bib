% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@article{marcus2011ontonotes,
    title="{O}nto{N}otes: A large training corpus for enhanced processing",
    author={Weischedel, Ralph and
        Hovy, Eduard and
        Marcus, Mitchell and
        Palmer, Martha and 
        Belvin, Robert and
        Pradhan, Sameer and
        Ramshaw, Lance and 
        Xue, Nianwen},
    editor={Olive, Joseph and
        Christianson, Caitlin and
        McCary, John
    },
    journal={Handbook of Natural Language Processing and Machine Translation: DARPA Global Autonomous Language Exploitation.},
    year={2011},
    publisher = "Springer"
}

@misc{https://doi.org/10.48550/arxiv.2210.07602,
  doi = {10.48550/ARXIV.2210.07602},
  url = {https://arxiv.org/abs/2210.07602},
  author = {Gandhi, Nupoor and Field, Anjalie and Strubell, Emma},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Mention Annotations Alone Enable Efficient Domain Adaptation for Coreference Resolution},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.2210.14698,
  doi = {10.48550/ARXIV.2210.14698},
  
  url = {https://arxiv.org/abs/2210.14698},
  
  author = {Liu, Tianyu and Jiang, Yuchen and Monath, Nicholas and Cotterell, Ryan and Sachan, Mrinmaya},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Autoregressive Structured Prediction with Language Models},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{https://doi.org/10.48550/arxiv.2211.12142,
  doi = {10.48550/ARXIV.2211.12142},
  
  url = {https://arxiv.org/abs/2211.12142},
  
  author = {Bohnet, Bernd and Alberti, Chris and Collins, Michael},
  
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Coreference Resolution through a seq2seq Transition-Based System},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@inproceedings{jacobs2021measurement,
author = {Jacobs, Abigail Z. and Wallach, Hanna},
title = {Measurement and Fairness},
year = {2021},
isbn = {9781450383097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442188.3445901},
doi = {10.1145/3442188.3445901},
abstract = {We propose measurement modeling from the quantitative social sciences as a framework for understanding fairness in computational systems. Computational systems often involve unobservable theoretical constructs, such as socioeconomic status, teacher effectiveness, and risk of recidivism. Such constructs cannot be measured directly and must instead be inferred from measurements of observable properties (and other unobservable theoretical constructs) thought to be related to them---i.e., operationalized via a measurement model. This process, which necessarily involves making assumptions, introduces the potential for mismatches between the theoretical understanding of the construct purported to be measured and its operationalization. We argue that many of the harms discussed in the literature on fairness in computational systems are direct results of such mismatches. We show how some of these harms could have been anticipated and, in some cases, mitigated if viewed through the lens of measurement modeling. To do this, we contribute fairness-oriented conceptualizations of construct reliability and construct validity that unite traditions from political science, education, and psychology and provide a set of tools for making explicit and testing assumptions about constructs and their operationalizations. We then turn to fairness itself, an essentially contested construct that has different theoretical understandings in different contexts. We argue that this contestedness underlies recent debates about fairness definitions: although these debates appear to be about different operationalizations, they are, in fact, debates about different theoretical understandings of fairness. We show how measurement modeling can provide a framework for getting to the core of these debates.},
booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
pages = {375–385},
numpages = {11},
keywords = {fairness, construct reliability, construct validity, measurement},
location = {Virtual Event, Canada},
series = {FAccT '21}
}

@article{adcock_collier_2001, title={Measurement Validity: A Shared Standard for Qualitative and Quantitative Research}, volume={95}, DOI={10.1017/S0003055401003100}, number={3}, journal={American Political Science Review}, publisher={Cambridge University Press}, author={Adcock, Robert and Collier, David}, year={2001}, pages={529–546}}

@article{hobbs1978resolving,
  title={Resolving pronoun references},
  author={Hobbs, Jerry R},
  journal={Lingua},
  volume={44},
  number={4},
  pages={311--338},
  year={1978},
  publisher={Elsevier}
}

@article{sukthanker2020anaphora,
  title={Anaphora and coreference resolution: A review},
  author={Sukthanker, Rhea and Poria, Soujanya and Cambria, Erik and Thirunavukarasu, Ramkumar},
  journal={Information Fusion},
  volume={59},
  pages={139--162},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{otmazgin-etal-2022-f,
    title = "{F}-coref: Fast, Accurate and Easy to Use Coreference Resolution",
    author = "Otmazgin, Shon  and
      Cattan, Arie  and
      Goldberg, Yoav",
    booktitle = "Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing: System Demonstrations",
    month = nov,
    year = "2022",
    address = "Taipei, Taiwan",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.aacl-demo.6",
    pages = "48--56",
    abstract = "We introduce fastcoref, a python package for fast, accurate, and easy-to-use English coreference resolution. The package is pip-installable, and allows two modes: an accurate mode based on the LingMess architecture, providing state-of-the-art coreference accuracy, and a substantially faster model, F-coref, which is the focus of this work. F-coref allows to process 2.8K OntoNotes documents in 25 seconds on a V100 GPU (compared to 6 minutes for the LingMess model, and to 12 minutes of the popular AllenNLP coreference model) with only a modest drop in accuracy. The fast speed is achieved through a combination of distillation of a compact model from the LingMess model, and an efficient batching implementation using a technique we call leftover batching. https://github.com/shon-otmazgin/fastcoref",
}

@article{Lourie2021UNICORNOR,
  title={UNICORN on RAINBOW: A Universal Commonsense Reasoning Model on a New Multitask Benchmark},
  author={Nicholas Lourie and Ronan {Le Bras} and Chandra Bhagavatula and Yejin Choi},
  journal={AAAI},
  year={2021}
}

@article{winogrande_2020, 
title={WinoGrande: An Adversarial Winograd Schema Challenge at Scale},
volume={34},
url={https://ojs.aaai.org/index.php/AAAI/article/view/6399},
DOI={10.1609/aaai.v34i05.6399},
number={05},
journal={Proceedings of the AAAI Conference on Artificial Intelligence},
author={Sakaguchi, Keisuke and Le Bras, Ronan and Bhagavatula, Chandra and Choi, Yejin},
year={2020},
month={Apr.},
pages={8732-8740}
}







@article{doi:10.1146/annurev-linguistics-031120-111653,
author = {Poesio, Massimo and Yu, Juntao and Paun, Silviu and Aloraini, Abdulrahman and Lu, Pengcheng and Haber, Janosch and Cokal, Derya},
title = {Computational Models of Anaphora},
journal = {Annual Review of Linguistics},
volume = {9},
number = {1},
year = {2023},
doi = {10.1146/annurev-linguistics-031120-111653},

URL = { 
    
        https://doi.org/10.1146/annurev-linguistics-031120-111653
    
    

},
eprint = { 
    
        https://doi.org/10.1146/annurev-linguistics-031120-111653
    
    

}
,
    abstract = { Interpreting anaphoric references is a fundamental aspect of our language competence that has long attracted the attention of computational linguists. The appearance of ever-larger anaphorically annotated data sets covering more and more anaphoric phenomena in ever-greater detail has spurred the development of increasingly more sophisticated computational models; as a result, the most recent state-of-the-art neural models are able to achieve impressive performance by leveraging linguistic, lexical, discourse, and encyclopedic information. This article provides a thorough survey of anaphora resolution (coreference) throughout this development, reviewing the available data sets and covering both the preneural history of the field and—in more detail—current neural models, including research on less-studied aspects of anaphoric interpretation such as bridging reference resolution and discourse deixis interpretation. Expected final online publication date for the Annual Review of Linguistics, Volume 9 is January 2023. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates. }
}


@misc{otmazgin2022lingmess,
    title={LingMess: Linguistically Informed Multi Expert Scorers for Coreference Resolution},
    author={Shon Otmazgin and Arie Cattan and Yoav Goldberg},
    year={2022},
    eprint={2205.12644},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@incollection{levesque_winograd_2012,
  abstract = {In this paper, we present an alternative to the Turing Test that has some conceptual and practical advantages. A Wino-grad schema is a pair of sentences that differ only in one or two words and that contain a referential ambiguity that is resolved in opposite directions in the two sentences. We have compiled a collection of Winograd schemas, designed so that the correct answer is obvious to the human reader, but cannot easily be found using selectional restrictions or statistical techniques over text corpora. A contestant in the Winograd Schema Challenge is presented with a collection of one sentence from each pair, and required to achieve human-level accuracy in choosing the correct disambiguation.},
  added-at = {2019-01-10T12:03:51.000+0100},
  address = {Rome, Italy},
  author = {Levesque, Hector J. and Davis, Ernest and Morgenstern, Leora},
  biburl = {https://www.bibsonomy.org/bibtex/2f2adaaa66a83d35ce30618142dcfdbd9/lepsky},
  booktitle = {Proceedings of the {Thirteenth} {International} {Conference} on {Principles} of {Knowledge} {Representation} and {Reasoning}},
  interhash = {bf16118d357c0acb5b4463889e76beb4},
  intrahash = {f2adaaa66a83d35ce30618142dcfdbd9},
  isbn = {978-1-57735-560-1},
  keywords = {kuenstliche_intelligenz},
  pages = {552--561},
  publisher = {AAAI Press},
  series = {{KR}'12},
  timestamp = {2019-01-10T12:05:20.000+0100},
  title = {The {Winograd} {Schema} {Challenge}},
  url = {https://cs.nyu.edu/faculty/davise/papers/WSKR2012.pdf},
  urldate = {2019-01-06},
  year = 2012
}

@article{can_we_fix,
   title={Opinion Piece: Can we Fix the Scope for Coreference?},
   volume={13},
   ISSN={2152-9620},
   url={http://dx.doi.org/10.5210/dad.2022.102},
   DOI={10.5210/dad.2022.102},
   number={1},
   journal={Dialogue \& Discourse},
   publisher={University of Illinois Libraries},
   author={Zeldes, Amir},
   year={2022},
   month={Apr},
   pages={41–62} }

@inproceedings{qi2020stanza,
 author = {Qi, Peng and Zhang, Yuhao and Zhang, Yuhui and Bolton, Jason and Manning, Christopher D.},
 booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
 title = {Stanza: A {Python} Natural Language Processing Toolkit for Many Human Languages},
 url = {https://nlp.stanford.edu/pubs/qi2020stanza.pdf},
 year = {2020}
}

@misc{bbn2007guidelines,
    author = {{BBN Technologies}},
    title = {Co-reference Guidelines for
English OntoNotes. {Version 7.0.}},
    url = {https://www.ldc.upenn.edu/sites/www.ldc.upenn.edu/files/english-coreference-guidelines.pdf},
    howpublished = {Guidelines accompanying OntoNotes 5.0 data release.},
    year = {2007},   
}

@article{2020t5,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {140},
  pages   = {1-67},
  url     = {http://jmlr.org/papers/v21/20-074.html}
}

@article{ackerman2019syntactic,
  title={Syntactic and cognitive issues in investigating gendered coreference},
  author={Ackerman, Lauren M},
  journal={Glossa},
  year={2019},
  publisher={Newcastle University}
}