
\input{figures/supp_timestamps}

\input{figures/comparison2d_supp}


\section{Ablations}
\label{sec:ab}
In this section, we show a more detailed ablation study which evaluates the effect of our volumetric regularization loss (Section \ref{sec:ablation-reg}) and an additional experiment, demonstrating the effect of using high order spherical harmonics coefficients (Section \ref{sec:sh}).

\subsection{Alternative Regularization Objectives}
\label{sec:ablation-reg}
Table \ref{tab:ablations} shows a quantitative comparison over different image-space and volumetric regularizations. Only the image-space L1 loss also appears in the main paper. %
Below we provide additional details on these ablations.

\paragraph{Image-space Regularization}
In this setting we render images from our editing grid $G_e$ in the poses corresponding to the input images during each iteration of the optimization stage. Rather than using a volumetric regularization, we incur a loss between the images rendered from $G_e$ and the corresponding input image while using the same weight used to balance $\mathcal{L}_\text{reg3D}$ with the annealed SDS loss (this weight is set to $200$, as detailed in Section \ref{sec:imp}). We evaluate this ablation using $L_1$ and $L_2$ image space loss functions. %

\paragraph{Alternative Volumetric Regularization Functions}
In this setting we replace our correlation-based regularization with
other functions that encourage similarity between the density features of the grids using the same balancing weight. %
Namely we compare against $L1$ and $L2$ volumetric loss functions, both penalizing the distance between the density features of $G_i$ and those of $G_e$. %


\ignorethis{
\subsubsection*{Refinement}
We ablate the refinement stage of our pipeline by comparing our system's outputs with and without refining the outputs of the editing stage. Note that this ablation only effects local prompts.
\subsubsection*{Image-space Regularization}
We ablate our choice to use our Volumetric Regularization loss $\mathcal{L}_\text{reg3D}$ by setting its weight to zero and replacing it with image space losses. In this setting we render images from our editing grid $G_e$ in the poses corresponding to the input images at each iteration of the Text-Guided Object Editing stage. We incur a loss between the images rendered from $G_e$ and the corresponding input image while using the same weight used to balance $\mathcal{L}_\text{reg3D}$ with the annealed SDS loss - $200$. We evaluate this ablation using two different image space loss functions - $L_1$ and $L_2$. For each function we generate all scenes in the test set and compare them against outputs generated by our unaltered method.



\subsubsection*{Alternative Volumetric Regularization Functions}
We ablate our choice of implementation for the Volumetric Regularization loss by replacing our density feature correlation encouraging implementation $\mathcal{L}_\text{reg3D}$ with other functions that encourage similarity between the density features of $G_e$ and $G_i$ and using the same balancing weight - $200$. Namely we test two different loss functions - $L1$ and $L2$, both penalizing the distance between the density features of $G_i$ and those of $G_e$. We again generate all scenes in the test set and compare them against outputs generated by our unaltered method for each function.

\subsubsection*{Refinement}
We ablate the refinement stage of our pipeline by comparing our system's outputs with and without refining the outputs of the editing stage. Note that this ablation only effects local prompts.
}

\subsection{Ablating the Color Representation}
\label{sec:sh}
As mentioned in Section 3.1 of the main paper, we  do not model view dependent effects using higher order spherical harmonics as that leads to undesirable effects. We demonstrate this by observing these effects in examples rendered with 1st and 2nd order spherical harmonic coefficients as color features. These results can be seen in videos available on our project page. %

When observing these results we can clearly see how view-dependent colors yield undesirable effects such as the feet of the ``yarn kangaroo" varying from green to yellow across views or the head of the dog becoming a birthday party hat when it faces away from the camera. We additionally see the colors become over-saturated, especially when using second-order spherical harmonic coefficients. It is also evident that the added expressive capabilities of the model allow it to over-fit more easily to specific views, creating unrealistic results such as the ``cat wearing glasses" in the first and second order coefficient models, where glasses are scattered along various parts of its body. We note that while this expressive power currently produces undesirable effects it does potentially enable higher quality and more realistic renders, and therefore, we believe that constraining this power is an interesting topic for future research.



\subsection{Cross-attention Grid Supervision}
As explained in Section \ref{sec:imp}, we use a constant time-stamp of 0.2 when extracting attention maps for training our attention grids $A_e$ and $A_{obj}$. This value was chosen empirically as we found that higher time-steps tend to be noisier and less focused, while lower time-steps varied largely from pose to pose producing inferior attention grids. This can be seen qualitatively in Figure \ref{fig:supp_timestamps}. As illustrated in the figure, the attention values for the edit region get gradually more smeared and unfocused as the time-steps increase. This is evident, for instance, in warmer regions around the kangaroo's tail or the head of the duck. While perhaps less visually distinct, we can also observe that in lower timestamps the warm regions denoting high attention values cover a smaller area of the region which should be edited. We empirically find that this makes it more challenging for separating the object and edit regions.

\ignorethis{
\begin{enumerate}
    \item Ablation of our approach with higher order SH coefficients 
    \item Try multiple image-based configurations
    \item Lower priority -- additional metrics? a user study?
\end{enumerate}
}

