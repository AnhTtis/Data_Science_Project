\section{Initialization and Perturbation}\label{sec:intialization_and_perturbation}
In Section \ref{sec:intialization_and_perturbation}, we propose assumptions on initialization and analyze perturbations. In Section~\ref{sec:intialization_and_perturbation:tools}, some tools utilized in this paper are presented. In Section~\ref{sec:intialization_and_perturbation:diff_dsc_con}, we provide a bound on $\| H^{\dis} - H^{\cts} \|_F$ (the distinction between discrete and continuous) under the choice of $m$. In Section~\ref{sec:intialization_and_perturbation:bound_changes_H_w}, we demonstrate an upper bound on the difference between continuous and discrete under the assumption that $w$ is in a small ball. In Section~\ref{sec:intialization_and_perturbation:loss}, we show how to control the loss $\|y-F(0)\|_2^2=\|y\|_2^2$ at initialization by forcing $a_{2r} = -a_{2r-1}$.


\subsection{A list of tools}\label{sec:intialization_and_perturbation:tools}


Within this section, we demonstrate that the spectral proximity exists between the continuous and discrete versions of the gram matrix of input data.




\begin{definition}\label{def:B}
Let $C> 10$ denote a sufficiently large constant. 

We define parameter $B$ as follows 
\begin{align*}
 B:= C\sigma \sqrt{ \log(n/\delta) }.
\end{align*}
\end{definition}



\begin{lemma}\label{lem:bound_on_exp_w_and_perturb_w}
If the following conditions hold
\begin{itemize}
    \item Let $B > 0$ denote a parameter be defined as Definition~\ref{def:B}.
    \item Let $w_r$ denote random Gaussian vectors from ${\cal N}(0,\sigma^2 I_d)$.
    \item Let $v_r$ be the vector where $\| v_r - w_r \|_2 \leq R$, $\forall     r \in [m]$
    \item Let $x_i$ be the vector where $\| x_i \|_2 \leq 1$, $\forall i \in [n]$
    \item Let $R \in (0,0.01)$
\end{itemize}
Then, we have with probability $1-\delta$
\begin{itemize}
    \item Standard inner product
    \begin{itemize}
        \item Part 1. $| \langle w_r, x_i \rangle | \leq B$, $\forall i\in [n]$, $\forall r\in [m]$
        \item Part 2. $|\langle v_r, x_i \rangle | \leq B + R$, $\forall i\in [n]$, $\forall r\in [m]$
        \item Part 3. $| \langle w_r - v_r, x_i + x_j \rangle | \leq 2R$
    \end{itemize}
    \item $\exp$ function
    \begin{itemize}
        \item Part 4. $\exp(\langle w_r , x_i \rangle) \leq \exp( B )$, $\forall i\in [n]$, $\forall r\in [m]$
        \item Part 5. $\exp(\langle v_r, x_i \rangle) \leq \exp( B + R )$, $\forall i\in [n]$, $\forall r\in [m]$
        \item Part 6. $|\exp( \langle w_r - v_r, x_i + x_j \rangle ) - 1 | \leq 4R$
    \end{itemize}
\end{itemize}
\end{lemma}
\begin{proof}
{\bf Proof of Part 1, 2, 4 and 5.}

The proof is trivially follows from Gaussian tail bound.

{\bf Proof of Part 3 and 6.}

Because $x_i$ and $x_j$ are independent and $\|\Delta w_r\|_2\leq R$, we can have
\begin{align}\label{eq:x_i_x_j}
    |\langle \Delta w_r,(x_i+x_j)\rangle|\leq 2R \leq 0.1
\end{align}

 
Then, we have
\begin{align*}
    |\exp( \langle\Delta w_r, (x_i+x_j)\rangle)-1)|
    \leq & ~ 2 |\langle \Delta w_r, (x_i+x_j)\rangle| \notag \\
    \leq & ~ 4 R
\end{align*}
where the first step follows from Fact~\ref{fac:taylor}, and the last step follows from Eq.~\eqref{eq:x_i_x_j}.

\end{proof}

\subsection{Bounding changes between discrete and continuous}\label{sec:intialization_and_perturbation:diff_dsc_con}
In Section~\ref{sec:intialization_and_perturbation:diff_dsc_con}, we establish a bound on $\| H^{\dis} - H^{\cts} \|_F$ for the chosen value of $m = \Omega( \lambda^{-2} \cdot n^2 \cdot \exp(2B) \cdot \sqrt{\log(n/\delta)} )$. The following lemma can be viewed as a variation of Lemma 3.1 in \cite{dzps19}, a variation of Lemma 3.1 in \cite{sy19}, a variation of Lemma C.3 in \cite{bpsw21}, a variation of Lemma C.1 in \cite{syz21} a variation of Lemma G.1 in \cite{mosw22}.
\begin{lemma}[]\label{lem:3.1}

As per the definition, $H^{\cts}$ and $H^{\dis}$ are two matrices of size $n \times n$ that we specify as follows:
 
\begin{align*}
H^{\cts}_{i,j} := & ~ \E_{w \sim \N(0,I)} \left[ (\langle x_i,x_j\rangle)\cdot{ \exp(\langle w_r,x_i\rangle)\cdot\exp(\langle w_r,x_j\rangle) }\right] , \\ 
H^{\dis}_{i,j} := & ~ \frac{1}{m} \sum_{r\in [m]} \left[ (\langle x_i,x_j\rangle)\cdot \exp( \langle w_r,x_i\rangle) \cdot \exp(\langle w_r,x_j\rangle)\right].
\end{align*}
We define $\lambda :={  \lambda_{\min} (H^{\cts})} $. 

If the following conditions hold
\begin{itemize}
    \item $\lambda > 0$.
    \item $d =\Omega(\log(1/\delta))$.
    \item $m = \Omega( \lambda^{-2} \cdot n^2 \cdot \exp(2B) \cdot \sqrt{\log(n/\delta)} )$.
\end{itemize}
Then, we have

\begin{itemize}
    \item Part 1 $\| H^{\dis} - H^{\cts} \|_F \leq {  \frac{ \lambda }{4}}$.
    \item Part 2. $\lambda_{\min} ( H^{\dis} ) \geq {  \frac{3}{4} \lambda}$.
\end{itemize}
hold with probability at least $1-\delta$.
\end{lemma}

 
\begin{proof} 

{\bf Proof of Part 1.}
For any given pair $(i,j)$, $H_{i,j}^{\dis}$ is computed as the mean of a set of independent random variables, denoted as:
\begin{align*}
H_{i,j}^{\dis}=~\frac {1}{m}\sum_{r\in [m]} (\langle x_i, x_j\rangle)\cdot\exp(\langle w_r, x_i\rangle)\cdot \exp(\langle w_r, x_j\rangle).
\end{align*}


Then the expectation of $H_{i,j}^{\dis}$ is
\begin{align*}
\E [ H_{i,j}^{\dis} ]
= & ~\frac {1}{m}\sum_{r=1}^m \E_{w_r\sim {\N}(0, \sigma^2 I_d)} \left[ (\langle x_i, x_j\rangle)\cdot\exp(\langle w_r, x_i\rangle)\cdot\exp(\langle w_r,x_j\rangle)\right]\\
= & ~\E_{w\sim {\N}(0, \sigma^2 I_d)} \left[ (\langle x_i,x_j\rangle)\cdot\exp(\langle w, x_i\rangle)\cdot\exp(\langle w,x_j\rangle) \right]\\
= & ~ H_{i,j}^{\cts}.
\end{align*}
For each $r\in [m]$, we define $z_r$ as follows:
\begin{align}\label{eq:bound_for_wx}
z_r := \frac {1}{m}(x_i^\top x_j)\cdot\exp(w_r ^\top x_i)\cdot \exp(w_r^\top x_j).
\end{align}




Using Lemma~\ref{lem:bound_on_exp_w_and_perturb_w}, we have

Moreover, we have
\begin{align*}
|z_r| \leq \frac{1}{m} \exp( 2 B ) := M.
\end{align*}




So by Hoeffding inequality (Lemma~\ref{lem:hoeffding}) we have for all $t>0$,
\begin{align*}
\Pr \left[ | H_{i,j}^{\dis} - H_{i,j}^{\cts} | \geq t \right]
\leq & ~ {2\exp \Big( -\frac{2t^2}{4 M^2} \Big)} \\
 = & ~ { 2\exp(-t^2/(2 M^2))}.
\end{align*}
$t$ is chosen as follows:
\begin{align*} 
t= M   \sqrt{\log(n/\delta)} ,
\end{align*}

$\forall i,j \in [n]$, by applying the union bound to all pairs $(i,j)$, we can obtain that  with probability at least $1-\delta$ :
\begin{align*}
|H_{i,j}^{\cts}-H_{i,j}^{\dis}|
\leq & ~   M \sqrt{ \log(n/\delta) } \\
\leq & ~  \frac{1}{m} \exp(2 B ) \sqrt{\log(n/\delta)}.
\end{align*}
 
Therefore, we can conclude that:

\begin{align}\label{eq:lamda/4}
\|H^{\cts}-H^{\dis}\|_F^2 
 = & ~ \sum_{i\in [n]}\sum_{j\in [n]} |H_{i,j}^{\dis} - H_{i,j}^{\cts}|^2  \notag \\
 \leq & ~ \frac{1}{m} n^2 \exp(2B) \sqrt{\log(n/\delta)}  \notag \\
 \leq & ~ \lambda^2/16
\end{align}
The last step in the derivation follows directly from our choice of $m$.

{\bf Proof of Part 2}

Then we have
\begin{align*}
\lambda_{\min} ( H^{\dis} ) 
\geq & ~ \lambda_{\min} (H^{\cts}) - \|H^{\dis} - H^{\cts}\|  \notag \\
\geq & ~ \lambda_{\min} (H^{\cts}) - \|H^{\dis} - H^{\cts}\|_F  \notag \\
\geq & ~ \lambda - \lambda/4 \\
\geq & ~ 3\lambda/4
\end{align*}
 where the first step is due to Fact~\ref{fac:norm}, and the second step is from Fact~\ref{fac:norm}, the third step is from Eq.~\eqref{eq:lamda/4}, the fourth step is because of adding terms.
 \end{proof}

\subsection{Given \texorpdfstring{$w$}{}  within a small ball bounding changes of \texorpdfstring{$H$}{} }\label{sec:intialization_and_perturbation:bound_changes_H_w}
Under the assumption that $w$ is contained in a small ball, in Section~\ref{sec:intialization_and_perturbation:bound_changes_H_w}, we can restrict the discrepancy between the continuous and discrete versions 
\begin{definition}\label{def:delta_w}
    We define 
\begin{align*}
    \Delta w_r := \wt{w}_r-w_r
\end{align*}
and
\begin{align*}
    \|\Delta w_r\|_2\leq R
\end{align*}
\end{definition}


\begin{definition}\label{def:c}
    We define 
\begin{align*}
    z_i:=\wt{w}_r^\top x_i
\end{align*}
\end{definition}
\begin{definition}\label{def:s_r}
   For $i\in [n],j\in [n]$, $r\in [m]$, we define
\begin{align*}
s_{r,i,j} := \exp({ \wt{w}_r^\top x_i})\cdot \exp( \wt{w}_r^\top x_j)  - \exp({ w_r^\top x_i})\cdot \exp( w_r^\top x_j).
\end{align*} 
By fixing $i$ and $j$, $s_{r,i,j}$ is simplified to $s_r$ with $s_r$ as a random variable that depends solely on $\wt{w}_r$. The set of random variables ${s_r}_{r=1}^m$ are independent of each other, because $\{\wt{w}_r\}_{r=1}^m$ are independent. 
\end{definition}
The following Lemma can be viewed as a variation of Lemma 3.2 in \cite{sy19}, a variation of Lemma C.4 and C.5 in \cite{bpsw21} a variation Lemma C.2 in \cite{syz21} and a variation of Lemma G.2 in \cite{mosw22}.
\begin{lemma}[perturbed $w$]\label{lem:perturb_w}
Suppose $\wt{w}_1, \cdots, \wt{w}_m$ are independent and identically distributed with a normal distribution ${\N}(0,\sigma^2 I)$, and let $B$ be defined as in Definition~\ref{def:B}. For any set of weight vectors $w_1, \cdots, w_m \in \R^d$ that satisfy $\| \wt{w}_r - w_r \|_2 \leq R$  where $R\in (0,0.001)$, for any $r\in [m]$, we define the function $H : \R^{m \times d} \rightarrow \R^{n \times n}$ as follows
\begin{align*}
    H(w)_{i,j} =  \frac{1}{m} x_i^\top x_j \sum_{r\in [m]} \exp({ w_r^\top x_i})\cdot \exp( w_r^\top x_j) .
\end{align*}
Therefore we can conclude that with probability at least $1-(n^2 \cdot \exp(-m R/10)+\delta)$, we have
\begin{align*}
\| H (w) - H(\wt{w}) \|_F \leq 3nR \exp(2B),
\end{align*}
\end{lemma}

 

\begin{proof}



The random variable we care is

\begin{align*}
& ~ \sum_{i\in [n]} \sum_{j\in [n]}| H(\wt{w})_{i,j} - H(w)_{i,j} |^2 \\
\leq & ~ \frac{1}{m^2} \sum_{i\in [n]} \sum_{j\in [n]} \left( \sum_{r\in [m]} \exp({ \langle \wt{w}_r, x_i\rangle})\cdot \exp( \langle \wt{w}_r, x_j\rangle)  - \exp({ \langle w_r, x_i\rangle})\cdot \exp( \langle w_r, x_j\rangle) \right)^2 \\
= & ~ \frac{1}{m^2} \sum_{i\in [n]} \sum_{j\in [n]}  \Big( \sum_{r\in [m]} s_{r,i,j} \Big)^2 ,
\end{align*}

where the last step is due to $\forall r,i,j$.

For simplicity, we drop the index of $i,j$ in $s_{r,i,j}$. We only keep the $r$, i.e., using $s_r$ to denote $s_{r,i,j}$.

We define $s_r$ as follows
\begin{align*}
s_r : = \exp({ \wt{w}_r^\top x_i})\cdot \exp( \wt{w}_r^\top x_j)  - \exp({ w_r^\top x_i})\cdot \exp( w_r^\top x_j) .
\end{align*}

Using Lemma~\ref{lem:bound_on_exp_w_and_perturb_w}, we have
\begin{align}\label{eq:bound_s_r}
\Pr [\forall r \in [m], s_r \leq \exp(2B) ] \geq 1- \delta.
\end{align}
In the rest of the proof, we will condition on the above event is holding.

 
We can obtain the upper bound of $\E_{\wt{w}_r}[s_r]$, we have
\begin{align}\label{eq:rewrite_E_s_r}
    \E_{ \wt{w}_r }[ s_r ]
    \leq & ~ \E_{\wt{w}_r}[|{\exp({ \wt{w}_r^\top x_i})\cdot \exp( \wt{w}_r^\top x_j)-\exp({ w_r^\top x_i})\cdot \exp( w_r^\top x_j)}|] \notag \\
    \leq & ~ \E_{\wt{w}_r}[|{\exp({ {(w_r+\Delta w_r)}^\top x_i})\cdot \exp( {(w_r+\Delta w_r)}^\top x_j)-\exp({ w_r^\top x_i})\cdot \exp( w_r^\top x_j)}|] \notag \\
     \leq & ~ \E_{\wt{w}_r}[|(\exp(\Delta w_r^\top (x_i+x_j))-1)\cdot\exp({ w_r^\top x_i})\cdot \exp( w_r^\top x_j)] \notag \\
     \leq & ~ \exp({ w_r^\top x_i})\cdot \exp( w_r^\top x_j) \cdot \E_{\wt{w}_r}[|(\exp(\Delta w_r^\top (x_i+x_j))-1)|]
\end{align}
where the 1st step is due to Definition~\ref{def:s_r}, the 2nd step is because of Definition~\ref{def:delta_w}, the 3rd step is by selecting the same term $\exp( w_r^\top x_i )\cdot \exp( w_r^\top x_j )$, and the last step follows from the reason that $i,j$ are fixed.

We have
\begin{align}\label{eq:bound_E_s_r}
     \E_{\wt{w}_r}[s_r]
     \leq & ~ \exp({ w_r^\top x_i})\cdot \exp( w_r^\top x_j) \cdot \E_{\wt{w}_r}[|(\exp(\Delta w_r^\top (x_i+x_j))-1)|] \notag \\
     \leq & ~ \exp(2 B) \cdot \E_{\wt{w}_r}[|\exp(\Delta w_r^\top (x_i+x_j)) - 1|] \notag \\
     \leq & ~ \exp(2B) \cdot \E[4R] \notag \\
    \leq & ~ 4R\cdot \exp(2B)
\end{align}
where the 1st step is due to Eq.~\eqref{eq:rewrite_E_s_r}, the 2nd step is due to Lemma~\ref{lem:bound_on_exp_w_and_perturb_w}, and the 3rd step is due to Lemma~\ref{lem:bound_on_exp_w_and_perturb_w}, and the last step follows from simple algebra.
 

We have, 
\begin{align}\label{eq:bound_for_s_r_2}
    \E_{\wt{w}_r} \left[ \left( s_r -\E_{\wt{w}_r} [s_r] \right)^2 \right]
    = & ~ \E_{\wt{w}_r} [s_r^2]- (\E_{\wt{w}_r} [s_r])^2  \notag \\
    \leq & ~ \E_{\wt{w}_r}[s_r^2] \notag \\
    = & ~\E_{\wt{w}_r} \left[(\exp({ \wt{w}_r^\top x_i})\cdot \exp( \wt{w}_r^\top x_j)-\exp({ w_r^\top x_i})\cdot \exp( w_r^\top x_j))^2\right] \notag \\
    \leq & ~ \E_{\wt{w}_r} \left[( \exp(4 B ) (\exp(\Delta w_r^\top (x_i + x_j))-1))^2\right] \notag \\
    \leq & ~ 16 R^2 \cdot \exp(4B)
\end{align}
where the 1st step is due to the definition of variance, the 2nd step is due to simple algebra, the 3rd step is due to the Definition~\ref{def:s_r}, the 4th step follows from Lemma~\ref{lem:bound_on_exp_w_and_perturb_w}, the 5th step follows from Lemma~\ref{lem:bound_on_exp_w_and_perturb_w}.
 

In the rest of the proof, let us condition on the above event is holding.

 
Combining Eq.~\eqref{eq:bound_s_r} Eq.~\eqref{eq:bound_E_s_r}, we also have
\begin{align*}
|s_r-\E_{\wt{w}_r}[s_r]|
\leq & ~ (1+4R)\cdot \exp(2B)\\
\leq & ~ 2 \exp(2B),
\end{align*}
 where the second step is from $4R\leq 1$.


Using Bernstein inequality (Lemma~\ref{lem:bernstein}), we have
\begin{align*}
\Pr \left[ Z > t \right] \leq \exp \left( - \frac{ t^2/2 }{ \Var[Z]  + M t /3 } \right).
\end{align*}
where 
\begin{align*}
    Z: = & ~ \sum_{r=1}^m s_r - \E[s_r], \\
    \Var[Z] := & ~ 16 m R^2 \exp(4 B ), \\
    M := & ~ 2 \exp(2 B).
\end{align*}

Replacing $t =  m R \exp(2B)$, we know that
\begin{align*}
\Var[Z] + M t/ 3
= & ~ 16 m R^2 \exp(4B) + 2 \exp(2B) m R \exp(2B) / 3 \\
\leq & ~ m R \exp(4B)
\end{align*}
Thus, 
\begin{align*}
\frac{t^2/2}{\Var[Z] + M t/ 3} \geq  \frac{ (m R \exp(B))^2 }{ m R \exp(4B)  } = m R 
\end{align*}
and 
\begin{align}\label{eq:bound_pr_sr}
    \Pr \left[ X \geq  m R \exp(2B) \right]
    \leq & ~ \exp \left( - m R \right) 
\end{align}


Using the bound on expectation
\begin{align*}
\Pr \left[\frac{\sum_{r\in [m]}s_r}{m} \geq 3R \cdot \exp(2B)  \right] 
   \leq &~\exp \left( - Rm/10 \right) \\
\end{align*}

\end{proof}

\subsection{Controlling the Loss at initialization}\label{sec:intialization_and_perturbation:loss}

The initialization of choice $a \in \{-1,+1\}^m$ is purely random in \cite{dzps19,sy19}. That initialization will make $\|  F(0) \|_2^2$ is a bit large. We can use the initialization idea in \cite{mosw22}. The idea is forcing $a_{2r} = -a_{2r-1}$. This will gives us that $\| F(0)\|_2^2= 0$.
 \begin{claim}\label{cla:yu0}
We have
\begin{align*}
\|y-F(0)\|_2^2= \| y \|_2^2.
\end{align*}
\end{claim}
\begin{proof}
We also duplicate the weights such that $w_{2r} = w_{2r-1}$. Therefore, the proof is straightforward.
\end{proof}