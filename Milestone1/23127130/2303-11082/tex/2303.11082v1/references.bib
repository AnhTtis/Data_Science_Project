@inproceedings{petroni,
  title={Language Models as Knowledge Bases?},
  author={Petroni, Fabio and Rockt{\"a}schel, Tim and Riedel, Sebastian and Lewis, Patrick and Bakhtin, Anton and Wu, Yuxiang and Miller, Alexander},
  booktitle={EMNLP},
  year={2019}
}

@article{cohen2023crawling,
  title={Crawling the Internal Knowledge-Base of Language Models},
  author={Cohen, Roi and Geva, Mor and Berant, Jonathan and Globerson, Amir},
  journal={Findings of EACL},
  year={2023}
}


@article{bordes2013translating,
  title={Translating embeddings for modeling multi-relational data},
  author={Bordes, Antoine and Usunier, Nicolas and Garcia-Duran, Alberto and Weston, Jason and Yakhnenko, Oksana},
  journal={neurIPS},
  year={2013}
}

@article{lenat1995cyc,
  title={CYC: A large-scale investment in knowledge infrastructure},
  author={Lenat, Douglas B},
  journal={{CACM}},
  year={1995},
}
@misc{wikidata_bias,
  author = {Shaik, Zaina and Ilievski, Filip and Morstatter, Fred},
  title = {Analyzing Race and Country of Citizenship Bias in Wikidata},
  
  publisher = {arXiv},
  
  year = {2021},
  
}

@inproceedings{nell,
  title={Toward an architecture for never-ending language learning},
  author={Carlson, Andrew and Betteridge, Justin and Kisiel, Bryan and Settles, Burr and Hruschka, Estevam R and Mitchell, Tom M},
  booktitle={AAAI},
  year={2010}
}
@misc{gpt_understands,
  doi = {10.48550/ARXIV.2103.10385},
  
  url = {https://arxiv.org/abs/2103.10385},
  
  author = {Liu, Xiao and Zheng, Yanan and Du, Zhengxiao and Ding, Ming and Qian, Yujie and Yang, Zhilin and Tang, Jie},
  
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {GPT Understands, Too},
  
  publisher = {arXiv},
  
  year = {2021},
  
}

@inproceedings{hoganKBs,
 booktitle = {ACM CSUR},  author = {Hogan, Aidan and others},
  title = {Knowledge Graphs},
  year = 2020
}




@inproceedings{nickel2011three,
  title={A three-way model for collective learning on multi-relational data},
  author={Nickel, Maximilian and Tresp, Volker and Kriegel, Hans-Peter},
  booktitle={ICML},
  year={2011}
}




@article{liu2021pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={ACM CSUR},
  year={2022}
}

@inproceedings{pkgc,
  title={Do Pre-trained Models Benefit Knowledge Graph Completion? A Reliable Evaluation and a Reasonable Approach},
  author={Lv, Xin and Lin, Yankai and Cao, Yixin and Hou, Lei and Li, Juanzi and Liu, Zhiyuan and Li, Peng and Zhou, Jie},
  booktitle={Findings of ACL},
  year={2022}
}


@article{singhania2022lm,
  title={{LM-KBC}: Knowledge Base Construction from Pre-trained Language Models},
  author={Singhania, Sneha and Nguyen, Tuan-Phong and Razniewski, Simon},
  year={2022},
  journal={CEUR}
}


@article{dbpedia,
  author    = {S{\"{o}}ren Auer and
               Christian Bizer and
               Georgi Kobilarov and
               Jens Lehmann and
               Richard Cyganiak and
               Zachary G. Ives},
  title     = {{DBpedia}: {A} Nucleus for a Web of Open Data},
  journal = {ISWC},
  year      = {2007},
}

@article{wikidata,
 author = {Vrande{\v{c}}i{\'c}, D. and Kr\"{o}tzsch, M.},
 title = {{Wikidata}: A Free Collaborative Knowledge base},
 journal = {CACM},
 year = {2014},
} 

@inproceedings{yago,
  title={Yago: a core of semantic knowledge},
  author={Suchanek, Fabian M and Kasneci, Gjergji and Weikum, Gerhard},
  booktitle={WWW},
  year={2007}
}

@inproceedings{weikum-machine-knowledge,
author={Gerhard Weikum and Luna Dong and Simon Razniewski and Fabian M. Suchanek},
title={{Machine Knowledge: Creation and Curation of Comprehensive Knowledge Bases}},
booktitle={FnT},
year=2021
}

@inproceedings{bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "NAACL",
    year = "2019",
}

@inproceedings{trex,
    title = "{T}-{RE}x: A Large Scale Alignment of Natural Language with Knowledge Base Triples",
    author = "Elsahar, Hady  and
      Vougiouklis, Pavlos  and
      Remaci, Arslen  and
      Gravier, Christophe  and
      Hare, Jonathon  and
      Laforest, Frederique  and
      Simperl, Elena",
    booktitle = "LREC",
    year = "2018",
}



@inproceedings{lama_uhn,
author = {N.Poerner, U.Waltinger, H.Sch{\"u}tze},
title = "{E}-{BERT}: Efficient-Yet-Effective Entity Embeddings for {BERT}", booktitle = "Findings of EMNLP",
year = 2020,
}

@inproceedings{kb_costs,
author = {H. Paulheim},
title = {How much is a Triple? Estimating the Cost of Knowledge Graph Creation},
booktitle = {ISWC},
year = 2018,
}


@inproceedings{bertnesia,
author = {J.Wallat, J.Singh, A.Anand},
title = {{BERTnesia}: Investigating the capture and forgetting of knowledge in BERT},
booktitle = {BlackboxNLP workshop},
year = 2020,
}

@inproceedings{safavi2020codex,
  title={{CoDEx}: A Comprehensive Knowledge Graph Completion Benchmark},
  author={Safavi, Tara and Koutra, Danai},
  booktitle={EMNLP},
  year={2020}
}


@inproceedings{dettmers2018convolutional,
  title={Convolutional 2d knowledge graph embeddings},
  author={Dettmers, Tim and Minervini, Pasquale and Stenetorp, Pontus and Riedel, Sebastian},
  booktitle={AAAI},
  year={2018}
}


@inproceedings{autoprompt,
  author = {Taylor Shin and Yasaman Razeghi and Robert L. Logan IV and Eric Wallace and Sameer Singh},
  title = { {AutoPrompt}: Eliciting Knowledge from Language Models with Automatically Generated Prompts },
  booktitle = {EMNLP},
  year = {2020}
}


@inproceedings{poerner2020ebert,
      title={{E-BERT}: Efficient-Yet-Effective Entity Embeddings for {BERT}}, 
      author={Nina Poerner and Ulli Waltinger and Hinrich Sch√ºtze},
      year={2020},
      booktitle={Findings of EMNLP}
}

@inproceedings{decao2021editing,
      title={Editing Factual Knowledge in Language Models}, 
      author={Nicola De Cao and Wilker Aziz and Ivan Titov},
      year={2021},
      booktitle={EMNLP},
}

@inproceedings{roberts2020knowledge,
      title={How Much Knowledge Can You Pack Into the Parameters of a Language Model?}, 
      author={Adam Roberts and Colin Raffel and Noam Shazeer},
      year={2020},
      booktitle={EMNLP}
}

@inproceedings{heinzerling-inui-2021-language,
    title = "Language Models as Knowledge Bases: On Entity Representations, Storage Capacity, and Paraphrased Queries",
    author = "Heinzerling, Benjamin  and
      Inui, Kentaro",
    booktitle = "EACL",
    year = "2021",
}


@inproceedings{petroni2020context,
  title={How Context Affects Language Models' Factual Predictions},
  author={Petroni, Fabio and Lewis, Patrick and Piktus, Aleksandra and Rockt{\"a}schel, Tim and Wu, Yuxiang and Miller, Alexander H and Riedel, Sebastian},
  booktitle={AKBC},
  year={2020}
}
@inproceedings{paulheim,
  title={How much is a triple? Estimating the cost of knowledge graph creation},
  author={Heiko Paulheim},
  booktitle={ISWC},
  year={2018}
}

@article{elazar2021measuring,
  title={Measuring and improving consistency in pretrained language models},
  author={Elazar, Yanai and Kassner, Nora and Ravfogel, Shauli and Ravichander, Abhilasha and Hovy, Eduard and Sch{\"u}tze, Hinrich and Goldberg, Yoav},
  journal={TACL},
  year={2021}
}

@article{razniewski2021language,
  title={Language Models As or For Knowledge Bases},
  author={Razniewski, Simon and Yates, Andrew and Kassner, Nora and Weikum, Gerhard},
  journal={DL4KG},
  year={2021}
}
