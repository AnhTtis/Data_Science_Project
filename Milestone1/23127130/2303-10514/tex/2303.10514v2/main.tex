\documentclass[12pt]{article}
\usepackage{geometry}
 \geometry{
 a4paper,
 left=25mm,
 right=25mm,
 top=30mm,
 bottom=30mm,
 }
\usepackage{amsmath}
%\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{import}
\usepackage{bbm}
\usepackage{tikz}
\usepackage[misc]{ifsym}

\usepackage{geometry}
\usepackage{comment}
%%% line spacing
\usepackage[onehalfspacing]{setspace}  
%%
%%% Appendix
\usepackage[title]{appendix}
%%%
\usepackage[utopia]{mathdesign}


%\addtolength{\oddsidemargin}{-.5in}
%\addtolength{\evensidemargin}{-.5in}
%\addtolength{\textwidth}{1.75in}

%\addtolength{\topmargin}{-.5in}
%\addtolength{\textheight}{1.75in}
\linespread{1.5}

%%Section size,font customisation
\usepackage{sectsty}
\sectionfont{\centering \Large \scshape }
\subsectionfont{\centering \large  \scshape}
%%%
%%%% Citation%%
\usepackage[american]{babel}
\usepackage{csquotes}
\usepackage[style=apa, uniquelist=false, backend=biber, doi=false,isbn=false,url=false]{biblatex}
\DeclareLanguageMapping{american}{american-apa}
\defbibenvironment{bibliography}
{\enumerate{}
{\setlength{\leftmargin}{\bibhang}%
\setlength{\itemindent}{-\leftmargin}%
\setlength{\itemsep}{\bibitemsep}%
\setlength{\parsep}{\bibparsep}}}
{\endenumerate}
{\item}
\addbibresource{ref.bib}

\usepackage[colorlinks,citecolor=blue]{hyperref}
%%%%%%%%%%

\usetikzlibrary{shapes.geometric}
\usetikzlibrary{positioning}
\makeatletter
\newenvironment{subtheorem}[1]{\def\subtheoremcounter{#1}\refstepcounter{#1}\protected@edef\theparentnumber{\csname the#1\endcsname}\setcounter{parentnumber}{\value{#1}}\setcounter{#1}{0}\expandafter\def\csname the#1\endcsname{\theparentnumber.\Alph{#1}}\ignorespaces
}{\setcounter{\subtheoremcounter}{\value{parentnumber}}\ignorespacesafterend
}
\makeatother

\newcounter{parentnumber}
\theoremstyle{plain}
\newtheorem {theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem {case}{Case}
\newtheorem {condition}{Condition}
\newtheorem {conjecture}{Conjecture}
\newtheorem {corollary}{Corollary}
\newtheorem {definition}{Definition}
\newtheorem {lemma}{Lemma}
\theoremstyle{definition}
\newtheorem {example}{Example}
%%%-----------

%\newtheorem{theorem}{Theorem}
%\newtheorem{question}{Question}
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem{fact}[theorem]{Fact}


%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{example}[theorem]{Example}
%\newtheorem{conjecture}[theorem]{Conjecture}

%\newtheorem{definition}[theorem]{Definition}
%\newtheorem{claim}[theorem]{Claim}
%\newtheorem{remark}[theorem]{Remark}
\usepackage{color}



\newcommand{\ran}{\text{ran}}
\newcommand{\dom}{\text{dom}}
\newcommand{\TT}{\mathcal{T}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\GG}{\mathcal{G}}
\newcommand{\FF}{\mathcal{F}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\BB}{\mathcal{B}}
\newcommand{\DD}{\mathcal{D}}
\newcommand{\Aa}{\mathcal{A}}
\newcommand{\Ss}{\mathcal{S}}
\newcommand{\cc}{\mathfrak{c}}
\newcommand{\cofT}{\text{cfrange}({\mathcal F})}




\newcommand{\upharp}{\upharpoonright}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}


%\newcommand{\end{proof}}{\hfill$\Box$}
%\newcommand{\begin{proof}}{\vskip 6pt \noindent PROOF. }
\newcommand{\Fn}{{\text Fn}}
\newcommand{\setm}{{\setminus}}
\title{\vspace{-4em}Efficient Public Good Provision in a Multipolar World\thanks{\textbf{Conflict of Interest}: None}\thanks{\textbf{Declaration of Generative AI and AI-assisted technologies in the writing process}: None}\thanks{We wish to thank Trivikram Dokka, Konstantinos Georgalos, Alexander Matros and Jaideep Roy as well as participants to the SING17 conference for their helpful comments.}\\}
\author{ \normalsize Chowdhury Mohammad Sakib Anwar\thanks{BLDT, University of Winchester. \Letter: Sakib.Anwar@winchester.ac.uk}
\and \normalsize  Jorge Bruno\thanks{BLDT, University of Winchester. \Letter: Jorge.Bruno@winchester.ac.uk}
\and \normalsize Renaud Foucart\thanks{Department of Economics, Lancaster University. \Letter: r.foucart@lancaster.ac.uk}
\and \normalsize  Sonali SenGupta\thanks{\textit{Corresponding Author.} Department of Economics, Queen's University Belfast. \Letter: S.SenGupta@qub.ac.uk}}
\date{\normalsize \today}
\begin{document} 
\maketitle
\begin{abstract}
We model a public goods game with groups, position uncertainty, and observational learning. Contributions are simultaneous within groups, but groups play sequentially based on their observation of an incomplete sample of past contributions. We show that full cooperation between and within groups is possible with self-interested players on a fixed horizon. Position uncertainty implies the existence of an equilibrium where groups of players conditionally cooperate in the hope of influencing further groups. Conditional cooperation implies that each group member is pivotal, so that efficient simultaneous provision within groups is an equilibrium.
    \medskip
\begin{flushleft}\textbf{Keywords} : Public Goods, Groups, Position Uncertainty, Voluntary Contributions.\end{flushleft}\par
\begin{flushleft}\textbf{JEL Codes}: C72, D82, H41 \ \end{flushleft}\par
\end{abstract}

\newpage
\section{Introduction}

%\paragraph{Introduction}

The provision of global public goods such as reducing CO2 emissions or investing in fundamental scientific research faces two significant obstacles. Firstly, each block has an incentive to free-ride on the contributions of others. Secondly, even within blocks, countries lack incentives to cooperate fully. Nonetheless, contributions still occur, as illustrated by the recent trend of ``absolute decoupling'' of consumption-based CO2 emissions from economic growth, particularly among a group of developed Western countries (\cite{hubacek2021evidence}), an outcome that was until recently widely described impossible or fanciful wishful thinking (\cite{ward2016decoupling}, \cite{fletcher2017decoupling}, \cite{heun2019meeting}, \cite{hickel2022degrowth}).

In this paper, we identify fully cooperative equilibria in a model combining simultaneous contributions to a public good with a finite-horizon game of sequential decisions and imperfect information. Players are organized into groups, and each group is placed exogenously in a sequence and is unaware of their exact position. Within a group, players individually and simultaneously choose their contribution. All players in a given group observe the total contribution of some of their immediate predecessor groups. We begin by demonstrating the existence of a pure strategy fully cooperative equilibrium, in which players contribute to the public good after observing full cooperation and defect if they observe at least one defection. 

We show that position uncertainty transforms the standard public goods game played within each group into a variant of a threshold public goods game (\cite{bagnoli1989provision}). Every individual in a group cooperates, recognizing that a single deviation may trigger defection by all members of subsequent groups. The existence condition for this equilibrium is more restrictive when groups are larger, as unilateral defections are more profitable, triggering defections in subsequent groups but not within the defector group. A special case of our model with groups of size one is \textcite{gallice2019co}, who found that if individuals are uncertain about their position within a sequence of voluntary contributions, they all behave as if they were in the middle of the sequence, thus avoiding the last-stage defection predicted by finite horizon games. 

In a pure strategy equilibrium, observed deviators are always punished by subsequent players who do not contribute. However, this type of equilibrium is vulnerable to small mistakes since a single player making an incorrect decision can lead to a breakdown of cooperation. If players only observe the contributions of the group immediately preceding them however, they know that by forgiving a deviation, there is a positive chance that subsequent players will observe their contribution and respond by contributing as well. Thus, each player has an opportunity to restore future contributions by forgiving deviations. We show that a mixed-strategy equilibrium with a strictly positive probability of forgiveness exists off the fully cooperative equilibrium path.

The existence of groups of two players and more leads to a non-monotonic relationship between the probability of forgiveness and the benefits of doing so. When the probability of forgiving is low, the gain from unilaterally contributing after observing a defection is minimal because it is unlikely that all members of the group will contribute simultaneously (a necessary condition in order to trigger future cooperation). The benefits of forgiveness increase up to a certain level and then decrease again, as, when the probability of forgiveness is too high, defecting becomes inconsequential. Our analysis shows that the only stable mixed strategy equilibrium involves an individual probability of forgiveness increasing with the number of members in a group. This result suggests that large simultaneous group decisions enhance individual cooperation after observing a defection. This non-monotonicity depends on the existence of groups: in the individual case studied by \textcite{gallice2019co}, the benefits from forgiving are always decreasing in the probability of doing so.

The first contribution of our paper relates to the literature on strategic decentralization (\cite{baye1996divisionalization}, \cite{eckert2003negotiating}, \cite{buchholz2014potentially}, \cite{foucart2018strategic}) which shows that groups of countries or regions may choose to delegate decision-making on global public goods contributions to their individual members in order to increase free-riding on other groups - even when they could have chosen to provide it centrally. We show that this result does not hold in the presence of position uncertainty and other settings where cooperation is sustained by conditional cooperation, such as infinitely repeated games: if cooperation is conditional on other groups fully cooperating, then all members of a group making a simultaneous choice play a threshold public good game.

In our climate action example, pledges are typically made at the national or even supra-national level. Smaller regional or national entities however often have the power to unilaterally deviate from the agreed objective, the European Union being a rare example of binding joint cooperation. A similar logic applies to objectives in the provision of renewable energy, or the modal share of public transportation, walking, and cycling, where local governments often have the power to block a development not desired by their constituents (the ``NIMBY'' syndrome).

Another relevant example is businesses making commitments to improve diversity, equity, and inclusion (DEI). Improving the diversity of a company is a public good, as it increases the pool of experimented workers, potential mentors (\cite{athey2000mentoring}; \cite{muller2022mentoring}; \cite{resnjanskij2023can}), informal relationships (\cite{cullen2023old}), and role models (\cite{porter2020gender}) that benefit the whole industry. Yet, within an organisation, smaller entities may be tempted to free-ride on the DEI efforts of the others. Our results suggest that communicating data on DEI metrics at a granular level may help enforcing cooperation.

Our model also shares features with Open-source software (OSS) development \parencite{lerner2002some,von2003community}. Groups of programmers sequentially contribute in the form of code, bug fixes, or improved documentation. Their motivation include career advancement \parencite{xu2020makes}, reciprocity \parencite{athey2014dynamics}, and the social impact of their work \parencite{zhang2011group}. Individual contributions therefore have the properties of a public good among programmers, as they play a crucial role in continually improving the software's quality and functionality.


The main result of our paper is that cooperation is possible in the above examples as long as there is a clear communication of individual contributions, in a way that makes each of them pivotal within their group. Moreover, the larger the number of individuals in a group, the more likely they are to forgive a possible defection off the equilibrium path.


Our second contribution is to complement the large literature studying self-enforcing participation to coalitions (\cite{d1983stability}, \cite{bloch1996sequential}, \cite{yi1997stable}, \cite{belleflamme2000stable}) and its application to global public goods (\cite{barrett1994self}). While recent work has shown how the dynamic nature of climate change can lead to optimistic results on the possibility of forming large coalitions (\cite{battaglini2016participation}, \cite{kovavc2021simple}), most of these models rely on the existence of an enforcement mechanism for the agreed contributions within a coalition (see chapter 15 of \cite{barrett2003environment} and \cite{nordhaus2015climate}). There is however no punishment mechanism for signatories defecting on their abatement promises in actual global climate treaties such as the current Paris Agreement (\cite{bodansky2016legal}). An exception is \cite{harstad2019compliance}, who show that self-enforcing cooperation is feasible in an infinitely repeated game. In contrast, we show that once countries are part of a group, simultaneous individual contributions can happen without any kind of enforcement mechanism as long as there are more than two groups. A multipolar world revolving among a small number of large blocks of countries may thus provide more global public goods than a grand coalition without an enforcement mechanism.



Our third contribution is to extend the results in \textcite{gallice2019co} that a form of conditional cooperation (\cite{fischbacher2001people}) is possible among self-interested players in a finite sequential game, to the case with groups of players making simultaneous decisions, using the concept of position uncertainty (\cite{monzon2014observational}, \cite{monzon2019observational}, \cite{gallice2019co}). Cooperation in public goods games is indeed generally explained either by infinitely repeated interactions (\cite{friedman1971non} ,\cite{duffy2009cooperative}, \cite{dal2010institutions}) or by social preferences such as altruism or warm-glow (\cite{andreoni1990impure}, \cite{fehr2000Gachter}, \cite{fehr2002altruistic}). 


 More generally, our model is one of observational learning, in which individuals sequentially choose an action after seeing predecessorsâ€™ choices (\cite{banerjee1992simple}, \cite{ccelen2004observational}, \cite{hendricks2012observational}, \cite{guarino2013social}, \cite{garcia2018consumer}). It is also part of a recent literature on the effect of information on contributions to a public good (\cite{figuieres2012vanishing}, \cite{tajika2020contribute}). Finally, it relates to work on position uncertainty looking at cases where a principal designs the sequential release of information (\cite{nishihara1997resolution}, \cite{gershkov2009optimal}, \cite{doval2020sequential}).

The paper is organized as follows. We set up the formal model in Section \ref{sec:setup}. In Section \ref{sec:results} we describe the main results for the symmetric case where all groups are of the same size. We start by proving the existence of a fully cooperative equilibrium in pure strategy in the case where players observe the actions of strictly more than one group. We then show that in the case where the action of the immediate predecessor is observed, this equilibrium coexists with an equilibrium in mixed strategy allowing for some forgiveness of deviations. In Section \ref{sec:extension}, we extend the model to allow for groups of different size and endogenous group formation and find that the main results continue to hold. We conclude in section \ref{sec:conclu}.
 
 
 
\section{The Model} \label{sec:setup}
Let $I=\{1,2,...,N\}$ be a set of players and consider a game with $b\leq N$ many groups composed of players from $I$, where the allocation of players to groups and the sequence of groups are randomly allocated with equal probability. Formally, let $q: I \to [b]$ be an onto function, where $[b]$ denotes the set of the first $b$ positive integers, and $\mathcal{Q}$ be the set of all such functions. We assume that all said functions are equally likely: $Pr(Q=q) = \sum_{i=0}^{b-1}(b-i)^{N}{b\choose i}$ for all $q\in \mathcal{Q}$, where $Q$ is a random variable. In turn, Group $t$ becomes the collection of players $j\in I$ for which $Q(j) = t$.

The timing of the game is as follows. First,  Nature (a non-strategic player) chooses the order of the sequence $q$. Second, groups sequentially play based on partial information on the contribution of their predecessors obtained through a simple sampling rule (which we formally describe below). Within each group, players choose simultaneously and independently whether to contribute. Player $i$ in Group $t$ must choose one of two actions $a_{i,t} \in \{C,D\}$: action $a_{i,t}=C$ implies a contribution of  one unit while $a_{i,t}=D$ implies no contribution. The total group contribution goes towards the common fund. The common fund is then redistributed to all players and we assume $r$ as the rate of return. We adopt the standard notation $G_{-i}= \sum_{j\neq i} \mathbbm{1}\{a_{j,t}=C\}$ to denote the number of players (other than $i$) who contribute. Payoffs $u_i(a_i,G_{-i})$ of player $i$ is as follows
\[
    u_i(C,G_{-i}) = \frac{r}{N}(G_{-i}+1)-1
\]
\[
    u_i(D,G_{-i})=\frac{r}{N}(G_{-i}),
\]
where $r$ is the return from contributions, and $\frac{r}{N}$ gives the marginal per capita return from the public goods. For the remainder of the paper, we make the standard assumption that $1<r<N$, so that for a fixed $G_{-i}$ the direct gain from contributing is lower than the individual cost, $u_i(C,G_{-i}) \leq u_i(D,G_{-i})$, but contributions are nonetheless socially desirable. The focus of this paper is on the effect of Player $i$'s contribution, or lack thereof, on subsequent players, so that $G_{-i}$ is not fixed.


For $t\leq b$, the symbol $A_t = (a_{i , t})$ denotes actions of the players in Group $t$ and $h_t=(A_t)_{t=1}^{t-1}$ denotes a possible history of actions up to Group $t-1$. Let $H_t$ be the random history at period $t$ with realizations $h_t\in \mathcal{H}_t$ and let $\mathcal{H}_1=\{\emptyset \}$.\footnote{We use period and position interchangeably throughout the paper, as they imply the same in our context.} Players play an extensive form game with imperfect information where each is given a sample $\zeta$ containing the actions of their $m\geq 1$ immediate preceding groups. The value of $m$ is common knowledge. That is, players observe a sample $\zeta=(\zeta',\zeta'')$, where $\zeta'$ states the number of groups sampled and $\zeta''$ states the number of contributors in that sample. A player in Group $t<m$ is provided with a smaller sample $\zeta=(t-1,\zeta'')$, so that players in the first group observe $\zeta_1=(0,0)$ and players in groups positioned between 2 to $m$ observe the actions of all their predecessor groups. They can thus infer their exact position in the sequence from the sample they receive. Formally,  letting $g_{t}=\sum_{Q(i)= t}\mathbbm{1}\{a_{i,t}=C\} $ denote the total contributions in Group $t$, players in Group $t$ receive a sample 
$\zeta_t: \mathcal{H}_t \to \mathcal{S}=\N^2$ containing a tuple:

$$ \zeta_t(h_t)= \Big( \underbrace{\min\{m,t-1\}}_{=\zeta'},\quad \underbrace{\sum_{k=\max\{1,m-t\}}^{t-1}g_{k}}_{=\zeta''}\Big).$$

 


We use \textcite{kreps1982sequential} sequential equilibrium. Player $i$'s strategy is a function $\sigma_i(C|\zeta): \mathcal{S}\to [0,1]$ that specifies the probability of contributing given the sample received. Let $\sigma=\{\sigma_i\}_{i\in I}$ denote a strategy profile and $\mu=\{\mu_i\}_{i\in I}$ a system of beliefs. A pair $(\sigma, \mu)$ represents an \textit{assessment}. Assessment $(\sigma ^*, \mu^*)$ is a {\it sequential equilibrium} if $\sigma^*$ is sequentially rational given $\mu^*$, and $\mu^*$ is consistent given $\sigma^*$. Let $\mathcal{H}= \cup_{t=1}^{n}\mathcal{H}_t$ be the set of all possible histories. Given a profile of play $\sigma$ let $\mu_i$ denote Player $i$'s beliefs about the history of play : $\mu_i(h|\zeta) : \mathcal{H} \times \mathcal{S}\to [0,1]$, with $\sum_{h \in \mathcal{H}} \mu_i(h|\zeta) =1$ for all $\zeta \in \mathcal{S}$. 


\section{Results} \label{sec:results}

In this section, we focus on the case where all groups are of the same size $n = \frac{N}{b}$ and later extend our results to the asymmetric case in Section~\ref{sec:asym}. We start by proving the existence of a pure strategy cooperative equilibrium when groups observe strictly more than one of their predecessors. We then focus on the case with a single observation and look at equilibria in pure and mixed strategy.


\subsection{Symmetric groups with sample size $m>1$\label{sec:sym>1}}

Assume a sample size of $m>1$, so that all players observe the contributions of strictly more than one group. Given a sample containing strictly more than one observation $\zeta = (\zeta',\zeta'')$ with $m \geq \zeta' > 1$, we demonstrate that the simple strategy of ``contributing unless a defection is observed" yields a sequential equilibrium provided that $r$ is large enough. Since the proof of the following is simple and self-contained we present it here. For completeness, in what follows we let $\sigma_i^k$ denote a sequence of strategies with $\sigma_i^k(C\mid \zeta)= 1 - (s_k)$ and $\sigma_i^k(D\mid \zeta) = (s_k)$ where $(s_k)$ is any non-trivial real null sequence, and put $\mu_i^k$ as the induced belief for strategy $\sigma_i^k$ for each $k\in \N$.
\begin{proposition}

\label{lem:m>1Symmetric} Consider the profile of play

\begin{align*}
    \sigma_i^*(C\mid \zeta) =
\begin{cases}
1, & \text{if $\zeta$ contains no defections} \\
0, & \text{otherwise.}
\end{cases}
\end{align*}
It follows that $(\sigma^*,\mu^*)$ is a sequential equilibrium provided that 
\begin{align}r \geq \frac{2N}{N-n(m+1)+2}.\end{align} \label{equ:pure}
\end{proposition}
\begin{proof}
Consider a player in Group $t$ and a history $\zeta = (m,c)$ with $c$ the number of observed contributions in the $m$ sampled groups. Assume the sample contains at least one defection so that $c<mn$. For groups of size at least $2$, a player that observes $\zeta$ is aware that every other player in her group also witnesses a defection and given the pure profile of play, the effect of the defection would extend beyond her group regardless of her contribution, or lack thereof. Even when $n=1$ players in subsequent groups will still witness defections as $m>1$ and $c+1 + kn = mn$ for some $k\in \N$. This means that if the defection occurs in Group $t'<t$ and all other players in groups succeeding $t'$ must defect, then a defection must inevitably appear in Group $t-1$. It follows that defection after defection is optimal given any value of $r$.

In contrast, if $\zeta = (\zeta',\zeta'n)$, meaning all players in the observed sample have contributed, a player in Group $t>m$ prefers to contribute when 
\begin{align} \label{equ:pref}
\frac{r}{N}N -1 \geq \frac{r}{N}\frac{N+(m+1)n-2}{2},
\end{align}
since she expects her position to be in the mid-point between $m+1$ and $b$, and expects all other members of her group to contribute. This inequality simplifies to the condition in \eqref{equ:pure}. Any other player in a Group $t<m$ knows for sure they are at the beginning of the sequence. They therefore have an even greater incentive to contribute as their gains from contributing and encouraging future contributions are larger than those in a Group $t'>m$. 
\end{proof} 

The existence condition for this cooperative equilibrium in pure strategy is thus that the rate of return on investment in public goods is sufficiently large for the expected benefits from sustained cooperation by subsequent groups to be higher than the individual cost of contributing. Whenever groups are of size one, the condition in \eqref{equ:pure} is identical to the result in Proposition 1 of \textcite{gallice2019co}. While the introduction of simultaneous choices by group members does not impede the existence of a fully cooperative equilibrium in pure strategy, it does however make the existence condition more stringent, as the right-hand side of \eqref{equ:pure} is increasing in $n$. This reflects the fact that, on top of potentially free-riding on subsequent groups, a player's unilateral deviation from the equilibrium strategy allows her to free-ride on her other team members with certainty.


As an illustration, consider the following example, with ten players \(I=\{1,2,3,.., 10\}\) organized in groups of size \(n=2\), observing the contributions of two previous groups \(m=2\). On the equilibrium path players observe samples without defection \(\zeta \in \{(0,0),(1,2),(2,4)\} \). Each player infers that all her predecessors contributed, and that her contribution will also induce the subsequent players to contribute. Therefore, a player's expected payoff when choosing to contribute is \(\frac{r}{10}(10)-1=r-1\), regardless of her group's position in the sequence. A player observing a sample \(m=2\) knows that her group is between position 3 and 5. So her expected payoff of defecting is \(\frac{r}{10}\frac{10+6-2}{2}=\frac{7}{10}r\), as she expects 6 players to have already contributed before her, on top of her expectation that the other member of her group contributes. A fully cooperative equilibrium therefore exists if \(r-1 \geq \frac{7}{10}r\), or \(r\geq \frac{10}{3}\).


\subsection{Symmetric groups with sample size $m=1$\label{sec:sym=1}}

In this section we assume that groups only observe the contribution of their immediate predecessor, $m=1<b$. This case should intuitively be the most favorable for the existence of a cooperative equilibrium: the right-hand side of \eqref{equ:pure} is increasing in $m$, making the existence condition more stringent when the size of the sample increases. When $n=1$ however, \textcite{gallice2019co} prove that a pure strategy equilibrium exists for all $r\in [2,3-\frac{3}{b+1}]$, but not for higher values. The reason is that, when $m=1$ and groups are of size one, a player has the power to restore a full history of cooperation after observing a defection, simply by contributing. If $r$ is large enough, the pure strategy equilibrium therefore stops to exist anymore, as there is no credible punishment for deviators.

In contrast, we show that when groups are larger $n>1$, a pure strategy equilibrium exists for all values of $r\geq \frac{2N}{N-2(n-1)}$. The main difference with $n=1$ is that there is no way to unilaterally restore an entire history of contribution and make subsequent players contribute, even when it would yield higher expected surplus than defecting. Just like in the case with $m>1$, the punishment of deviators in a pure strategy equilibrium is thus credible.

\begin{proposition}  
[Pure Strategies with $m=1<n$]\label{thm:pureStrat} For any value of $r\geq \frac{2N}{N-2(n-1)}$ and given the profile of play
\begin{align*}
    \sigma_i^*(C\mid \zeta) =
\begin{cases}
1, & \zeta \in\{(0,0), (1,n)\}\\
0, & \text{otherwise}
\end{cases}
\end{align*}
for all $i\in I$, the assessment $(\sigma^*, \mu^*)$ is a sequential equilibrium,
\end{proposition}

The formal proof is in Appendix and follows the same logic as Proposition \ref{lem:m>1Symmetric}. We then show that - concurrent to the equilibrium from Proposition~\ref{thm:pureStrat} - for large enough values of $r$ there exist at least two mixed strategy equilibria where agents forgive defections with probability $\gamma\in (0,1)$. 

\begin{proposition}   
[Mixed Strategies with $m=1<n$]\label{thm:mixedStrat} There exists a value $r^\sharp<N$ so that for all values $r>r^\sharp$ there exist two distinct values $\gamma^1_r,\gamma^2_r \in(0,1)$ where, for all $i\in I$, the profiles of play

\begin{align*}
    \sigma_{i,1}^*(C\mid \zeta) =
\begin{cases}
1, & \zeta \in\{(0,0), (1,n)\}\\
\gamma^1_r, & \text{otherwise},
\end{cases}
\end{align*}

\begin{align*}
    \sigma_{i,2}^*(C\mid \zeta) =
\begin{cases}
1, & \zeta \in\{(0,0), (1,n)\}\\
\gamma^2_r, & \text{otherwise}
\end{cases}
\end{align*}
 establish two distinct sequential equilibria $(\sigma^*_1, \mu^*_1)$ and $(\sigma^*_1, \mu^*_2)$, respectively.

\end{proposition}
 
  
The formal proof is in Appendix. For a mixed strategy that forgives deviations with strictly positive probability to exist out-of-equilibrium, all players must be indifferent between contributing or not when observing a sample with at least one defection. They must therefore balance the future contributions they expect if they contribute with what they can expect by defecting, given that everyone else forgives defections with probability $\gamma$. Denote by $\phi_t(\gamma)$ the number of additional contributions Player $j$ expects from contributing rather than defecting, and by $\psi_t(\gamma)$ the likelihood  of being in Group $t$ after observing a defection. The function
 \[
\Delta(\gamma) = \frac{r}{N}\sum_{t=2}^b\psi_t(\gamma)\phi_t(\gamma) - 1
\]
then describes the difference in utility between contributing and defecting upon witnessing a defection. A first observation is that whenever groups are at least of size two, $\Delta(0)=\Delta(1)=\frac{r}{N} -1<0$. If a player expects that no one ever forgives deviations ($\gamma=0$), there is no way for her to restore a full history of cooperation after observing a defection, as other members of the group will never contribute. If she expects everyone to forgive deviations all the time ($\gamma=1$), then there is no benefit from ever cooperating, as it will have no influence on other players' behavior. It follows, by Rolle's Theorem, that $\Delta(\gamma)$ must attain at least one local maximum between $(0,1)$. In the proof of Proposition~\ref{thm:mixedStrat} (in Appendix), we show that for at least one $r^\sharp<N$ - and thus all other $r>r^\sharp$ -  $\Delta(\gamma)$'s local maximum is positive. In which case, $\Delta(\gamma)$ exhibits at least two roots and, thus, two distinct sequential equilibria as described in the Proposition. 


We illustrate this result in Figure~\ref{fig:1}. The dashed line represents the case with groups of size one studied by \textcite{gallice2019co}. For the lowest values of $\gamma$, $\Delta(\gamma)$ is high: it pays to forgive a unilateral deviation if you expect no one else to do it, because you know it is the only way to restore future cooperation. Then, as $\gamma$ increases, the gain from forgiving decreases, up to the point where all players are indifferent between contributing or not $\Delta(\gamma)=0$, corresponding to the mixed strategy equilibrium. The solid line represents a configuration with groups of size $n=5$. In that case, for the lowest values of $\gamma$, $\Delta(\gamma)$ is negative, because unilateral forgiveness does not give a high probability of the entire group contributing, a necessary condition to restore future cooperation. Then, as $\gamma$ increase, so does the probability that a player's contribution is pivotal in restoring a full history of cooperation after observing a defection. Therefore, $\Delta(\gamma)$ increases up to a certain point, where the effect described for the case $n=1$ starts to dominate.

On Figure~\ref{fig:1}, the two intersections between the solid line and the horizontal axis $\Delta(\gamma)=0$ correspond to mixed strategy equilibria, but these equilibria are not of the same nature. Assuming that players defect by mistake with a very small probability $\epsilon>0$, there is a self-enforcing coalition of all players who would be better off forgiving with probability $\gamma^2_r$ than with $\gamma^1_r$ or $0$. In the presence of such a small probability of mistake, $\gamma^2_r$ is thus the only coalition-proof equilibrium (\cite{bernheim1987coalition}). Moreover, it is easy to show using the concept of evolutionary stable strategies (\cite{smith1982evolution}) that if a share $\gamma$ of the players are hard wired to always forgive while a share $1-\gamma$ is hard-wired to never forgive, $\gamma^1_r$ is not stable: for $\gamma$ smaller than $\gamma^1_r$, $\Delta(\gamma)<0$ the players never forgiving fare better, so that the survival of the fittest leads to $\gamma=0$. For $\gamma$ between $\gamma^1_r$ and $\gamma^2_r$, $\Delta(\gamma)>0$, those always forgiving fare better, so that the share naturally converges to $\gamma^2_r$. The latter equilibrium is evolutionary stable, as for $\gamma>\gamma^2_r$, non-forgivers fare better.


\begin{figure}[htbp]
    \centering
    \includegraphics[scale=0.75]{equil.png}
    \caption{Mixed Strategy Equilibrium}
    \label{fig:1}
\end{figure}

Figure \ref{fig:2} shows that as group size becomes larger, the equilibrium points move to the right. This result directly follows from the equilibrium conditions in Proposition \ref{thm:mixedStrat}: for a given $\gamma$, the probability for an entire group to contribute after a defection is decreasing with the number of group members. Hence, to make players indifferent between contributing or not, the probability of an individual player forgiving must be higher in larger groups.



\begin{figure}[htbp]
    \centering
    \includegraphics[scale=0.75]{equil_compare.png}
    \caption{Mixed Strategy Equilibrium-Comparing group sizes}
    \label{fig:2}
\end{figure}

\section{Additional results} \label{sec:extension}
\subsection{Asymmetric groups}\label{sec:asym}
We now turn to the case of asymmetric groups: consider $b$ many groups where each group has $n_i$ members with $\sum_{i=1}^b n_i = N$, the size of the groups is common knowledge and samples contain not only the number of contributions but also the size of the groups sampled (else, it would be impossible to detect defections). Denote the index of the groups to rank them by size in reverse order, so that $n_1>n_2>...>n_b$. In the case $m>1$, it is straightforward that results in Proposition~\ref{lem:m>1Symmetric} translate directly by replacing the size of groups by the most favorable to a defection. Assume $\zeta = (\zeta',\zeta'n)$, meaning all players in the observed sample have contributed, a player in any of the $m+1$ largest Group placed in position $t>m$ prefers to contribute when 
\begin{align} \label{equ:pref2}
\frac{r}{N}N -1 \geq \frac{r}{N}\frac{N+\sum^{m+1}_{i=1}n_i-2}{2}.
\end{align}


The left-hand side is the same as in \eqref{equ:pure}, the benefit from continuous cooperation, independent on beliefs about a group's exact location. The right-hand side corresponds to the least favorable case for cooperation: a player part of the $m+1$ largest groups witnessing a sample of $m$ of the largest $m+1$ groups fully cooperating. Proposition~\ref{lem:m>1Symmetric} then holds in the asymmetric case by solving \eqref{equ:pref2} for $r$ and replacing \eqref{equ:pure} by this new condition, 
\begin{align}
r \geq \frac{2N}{N-\sum^{m+1}_{i=1}n_i+2}. \label{cond:coopasym}
\end{align}

The logic is very much similar for mixed strategy equilibria when $m=1$, although the computations are slightly more tedious. We provide in the Online Appendix two propositions extending the results of Proposition \ref{thm:mixedStrat} to the asymmetric case.

\subsection{Endogenous group formation}

Until now, we have assumed groups to be formed exogenously. It is however easy to see that the existence of a fully cooperative equilibrium is robust to adding a stage of group formation before the public goods game. Start by assuming there are $b$ groups, and $N$ players free to join the group of their choice, symmetric or not. If there exists at least one group structure that satisfies condition \eqref{cond:coopasym} and if for that structure beliefs are consistent with a fully cooperative equilibrium, no player has an incentive to change group given that group structure.

To see this, observe that in a fully cooperative equilibrium the expected payoff of all players is identical and equal to $r-1$. All players are thus indifferent between joining any group as long as the structure leads to a fully cooperative equilibrium. The only change of group that would change their expected payoff is one such that full cooperation is not the equilibrium anymore. The expected payoff without cooperation is exactly zero, strictly lower than $r-1$. Following the same logic, it is easy to see that even letting the number of groups vary would not change this basic result: if there exists a group structure in which beliefs are consistent with a fully cooperative equilibrium, there is no strictly profitable individual deviation from this structure.

\section{Conclusion} \label{sec:conclu}

This paper shows that full contribution to a public good within groups of self-interest players is achievable in a finite horizon. Our main motivation for the project is mostly descriptive: we believe that such a theory helps understand puzzling stylized facts on the provision of public goods in cases where many smaller actors have a chance to defect. The main mechanism behind the paper is that groups of players believe that providing evidence of their full contribution may help foster future contributions by other groups. In that context, every player within a group is pivotal, so that a standard game of simultaneous contributions becomes a threshold public goods game.

We believe that crowd-funding operations to finance public goods could be inspired by our results. A fundraiser could decide to split their pool of potential donors into several groups. They could then contact groups sequentially and inform each participant of a group-based crowdfunding objective. Subsequent groups (if there are any) would then be informed of whether their immediate predecessors achieved their goal, perhaps with information on the fact that a group's contribution may induce further groups to also contribute. If there is some position uncertainty so that no group is aware of being the last one, our model predict that large contributions are feasible. 


\newpage
\printbibliography


%\begin{appendices}
\newpage

\section*{Appendix: Proof of Propositions~\ref{thm:pureStrat} and~\ref{thm:mixedStrat}}\label{apendix:Proofs}

Let's assume that we have $b = \frac{N}{n}$ many groups with $n$ individuals per group. Assume that the standard strategy given profile $\zeta$ is
\begin{align*}
    \sigma^*(C\mid \zeta) =
\begin{cases}
1, & \zeta \in \{(0,0), (1,n)\}\\
\gamma, & \text{otherwise},
\end{cases}
\end{align*}
where $\gamma \in[0,1)$ is the - off the equilibrium path - probability with which a player contributes after observing at least one defection in the observed sample. Fix a profile $\overline{\zeta}$ and set for Player $j$ the strategies
\[
\sigma_j^C(\zeta)
=
\begin{cases}
\sigma^*_j(\zeta), & \zeta \not = \overline{\zeta}\\
1, & \zeta = \overline{\zeta}.
\end{cases}
\]

\[
\sigma_j^D(\zeta)
=
\begin{cases}
\sigma^*_j(\zeta), & \zeta \not = \overline{\zeta}\\
0, & \zeta = \overline{\zeta},
\end{cases}
\]
and $\mu_j^D$ and $\mu_j^C$ as their corresponding beliefs. Set $\phi_t(\gamma)$ and $\psi_t(\gamma)$ as the number of additional contributions said player expects from contributing rather than defecting whilst in Group $t$, and the likelihood  of being in Group $t$ after observing a defection, respectively. For $n>1$, $\phi_t(\gamma)$ is different depending on the history $\overline{\zeta} = (1, n')$ observed by Player $j$. Indeed, if $\overline{\zeta} = (1, n')$ with $n>n'$ then all other member of Group $t$' will also observe a defection and act according to their strategies. Hence, there is a non-zero probability that subsequent groups will also witness a sample with defection even if Player $j$ itself contributes. In contrast, if $\overline{\zeta} = (1, n)$ then Player $j$'s defection will be the only one in her group and the effect of her defection should be larger than the previous scenario. The following lemma demonstrates just that.

\begin{lemma}\label{lem:psiPhi} Both $\phi_t(\gamma), \psi_t(\gamma): [0,1] \to \R$ are continuous functions where:
\begin{enumerate}
\item given $\overline{\zeta} = (1, n')$ with $n>n'$
\[ \phi_t(\gamma) = \frac{n(1-\gamma)(1-(1-\gamma^n)^{b-t})}{\gamma}+1.
\]
with $\phi_t(0) = 1$ for all $n>1$ and $\phi_t(0) = b-t+1$ for $n=1$; 
\item given $\overline{\zeta} = (1, n)$

\[ \phi_t(\gamma) = \frac{n(1-\gamma)(1-(1-\gamma^n)^{b-t})}{\gamma^n}+1.
\]
with $\phi_t(0) = (b-t)n +1$; and
\item  \[
\psi_t(\gamma) = \frac{(1-(1-\gamma^n)^{t-1})}{b-1-\gamma^{-n}(1-\gamma^n)(1-(1-\gamma^n)^{b-1})}
\]
with $\psi_t(0)  =\frac{2(t-1)}{b(b-1)}$.
\end{enumerate}
\end{lemma}

\begin{proof}

\noindent
The number of additional contributors a player in Group $t$ should expect from contributing rather than defecting given history $\overline{\zeta}$ becomes 
\[
\phi_t(\gamma) = E_{\mu^C}(G_{-j}\mid \zeta = \overline{\zeta}, Q(j) = t) - E_{\mu^D}(G_{-j}\mid \zeta = \overline{\zeta}, Q(j) = t).
\]
where
\begin{align*}
E_{\mu^C}(G_{-j}\mid \zeta = \overline{\zeta}, Q(j) = t)  &= \sum_{i=1}^{t-1}E_{\mu^*}(G_{i}\mid \zeta = \overline{\zeta}, Q(j) = t)\\
& +  \sum_{i=t}^{b} E_{\mu^C}(G_{i}\mid \zeta = \overline{\zeta}, Q(j) = t),
\end{align*}
\begin{align*}
E_{\mu^D}(G_{-j}\mid \zeta = \overline{\zeta}, Q(j) = t)  &= \sum_{i=1}^{t-1}E_{\mu^*}(G_{i}\mid \zeta = \overline{\zeta}, Q(j) = t)\\
& +  \sum_{i=t}^{b} E_{\mu^D}(G_{i}\mid \zeta = \overline{\zeta}, Q(j) = t),
\end{align*}
and $G_i$ represents the $i^\text{th}$ group.
Hence,
\[
\phi_t(\gamma) = \sum_{i=t}^{b} E_{\mu^C}(G_{i}\mid \zeta = \overline{\zeta}, Q(j) = t) -   E_{\mu^D}(G_{i}\mid \zeta = \overline{\zeta}, Q(j) = t).
\]
\noindent
1. If the sample $\overline{\zeta} = (1,n')$ contains a defection (i.e., $n>n'$) we have
\[
E_{\mu^D}(G_{t}\mid \zeta = \overline{\zeta}, Q(j) = t) =   (n-1)\gamma 
\]
and
\[
E_{\mu^C}(G_{i}\mid \zeta = \overline{\zeta}, Q(j) = t) =  E_{\mu^D}(G_{i}\mid \zeta = \overline{\zeta}, Q(j) = t) + 1.
\]
\noindent
For $t+1$ we get 
\[
E_{\mu^D}(G_{t+1}\mid \zeta = \overline{\zeta}, Q(j) = t)= \gamma n 
\]
\text{ and } 
\begin{align*}
E_{\mu^C}(G_{t+1}\mid \zeta = \overline{\zeta}, Q(j) = t) &= \gamma^{n-1}n + (1-\gamma^{n-1})E_{\mu^D}(G_{t+1}\mid \zeta = \overline{\zeta}, Q(j) = t)\\
&= \gamma^{n-1}n + (1-\gamma^{n-1})\gamma n.
\end{align*}
In general, for $t+k$ with $k\geq 1$ we have
\[
E_{\mu^D}(G_{t+k}\mid \zeta = \overline{\zeta}, Q(j) = t) = n\left[1-(1-\gamma)(1-\gamma^n)^{k-1}\right] 
\]
and 

\[
E_{\mu^C}(G_{t+k}\mid \zeta = \overline{\zeta}, Q(j) = t) = n\gamma^{n-1}+ (1-\gamma^{n-1})E_{\mu^D}(G_{t+k}\mid \zeta = \overline{\zeta}, Q(j) = t)
\]
In turn, 
\[
E_{\mu^C}(G_{t+k}\mid \zeta = \overline{\zeta}, Q(j) = t) - E_{\mu^D}(G_{t+k}\mid \zeta = \overline{\zeta}, Q(j) = t) = n\gamma^{n-1}(1-\gamma)(1-\gamma^n)^{k-1}.
\]
As a sum of powers of $(1-\gamma^n)^{k-1}$ we deduce that for any $\gamma \in (0,1]$:
\[
\phi_t(\gamma) = \frac{n(1-\gamma)(1-(1-\gamma^n)^{b-t})}{\gamma}+1.
\]
with
\[
\lim_{\gamma\to 0} \phi_t(\gamma) = \lim_{\gamma\to 1} \phi_t(\gamma) = 1.
\]
for all $n>1$. We observe that $\phi_t(\gamma)>1$ for all $
\gamma \in (0,1)$. In fact, the distribution $\phi_t(\gamma)$ is bell shaped. This means that there is an optimal value of $\gamma$ that maximizes the additional contributions a player can expect by contributing rather than defecting. If we let $n=1$ we get 
\[
\phi_t(\gamma) =\frac{1-(1-\gamma)^{b-t+1}}{\gamma}
\]
with 
\[
\lim_{\gamma\to 0} \phi_t(\gamma) = b-t+1.
\]
This is precisely what is obtained in \textcite{gallice2019co}.\\

2. If sample $\overline{\zeta} = (1,n)$ then the computation is similar but much simpler. For $t+k$ with $k\geq 1$ we have
\[
E_{\mu^D}(G_{t+k}\mid \zeta = \overline{\zeta}, Q(j) = t) = n\left[1-(1-\gamma^n)^{k-1}(1-\gamma)\right] 
\]
and 

\[
E_{\mu^C}(G_{t+k}\mid \zeta = \overline{\zeta}, Q(j) = t) = n 
\]
In turn, 
\[
E_{\mu^C}(G_{t+k}\mid \zeta = \overline{\zeta}, Q(j) = t) - E_{\mu^D}(G_{t+k}\mid \zeta = \overline{\zeta}, Q(j) = t) = n(1-\gamma)(1-\gamma^n)^{k-1}.
\]
Therefore, for any $\gamma \in (0,1]$ we have
\[
\phi_t(\gamma) = \frac{n(1-\gamma)(1-(1-\gamma^n)^{b-t})}{\gamma^n}+1.
\]
with
\[
\lim_{\gamma\to 0} \phi_t(\gamma) = (b-t)n+1.
\]

\noindent

3. Let $\psi_t(\gamma)$ denote the likelihood that a player finds itself in position $t$ after witnessing a defection. It follows that
\begin{align*}
\psi_t(\gamma) = \frac{\sum_{j=0}^{t-2}(1-\gamma^n)^j}{\sum_{k=2}^b\sum_{i=0}^{k-2}(1-\gamma^n)^{i}} &= \frac{ \gamma^{-n}(1-(1-\gamma^n)^{t-1})}{\gamma^{-n}\left(b-1+\gamma^{-n}(1-\gamma^n)(1-(1-\gamma^n)^{b-1}\right)}\\
&= \frac{(1-(1-\gamma^n)^{t-1})}{b-1-\gamma^{-n}(1-\gamma^n)(1-(1-\gamma^n)^{b-1})}
\end{align*}

For all other $n>1$ we can make the replacement $y = \gamma^p$ to obtain, after applying L'Hospital's Rule, $\psi_t(0) =\frac{2(t-1)}{b(b-1)}$.\\
\end{proof}

\noindent

In what follows it becomes useful to let $\phi_t(\gamma, \zeta)$ denote $\phi_t(\gamma)$ given a profile $\zeta$. A player in Group $1$ contributes whenever $\frac{r}{N}\phi_1(\gamma, (0,0)) - 1 \geq 0$; a player who received a sample $\overline{\zeta} = (1,n)$ contributes provided $\sum_{t=2}^b\frac{1}{b-1}\phi_t(\gamma, \overline{\zeta})-1\geq 0$; and given profile $\overline{\zeta}' = (1,n')$ with $n'<n$ a player contributes provided $\sum_{t=2}^b \psi_t(\gamma)\phi_t(\gamma, \overline{\zeta}')-1\geq 0$.

\begin{lemma}\label{lem:inequalities} Given profiles $\overline{\zeta}' = (1,n')$ with $n'<n$ and $\overline{\zeta} = (1,n)$ it follows that for all $\gamma \in [0,1]$

\[
\phi_1(\gamma) > \sum_{t=2}^b\frac{1}{b-1}\phi_t(\gamma, \overline{\zeta}) \geq \sum_{t=2}^b \psi_t(\gamma)\phi_t(\gamma,\overline{\zeta}').
\]
\end{lemma}
\begin{proof} The first inequality is obvious. For the second one observe that by Lemma~\ref{lem:psiPhi}, $\phi_t(\gamma,\overline{\zeta}') \leq \phi_t(\gamma,\overline{\zeta})$ for all $t$. In turn, showing that 
\[
\sum_{t=2}^b\frac{1}{b-1}\phi_t(\gamma, \overline{\zeta}') \geq \sum_{t=2}^b \psi_t(\gamma)\phi_t(\gamma,\overline{\zeta}')
\]
suffices. Fix a $\gamma \in [0,1]$ and observe that since
\[
1= \sum_{t=2}^b\frac{1}{b-1} = \sum_{t=2}^b\psi_t(\gamma)
\]
and $\psi_2(\gamma) < \frac{1}{b-1}$ then there must exist $t^*\leq b$ with $\psi_{t}(\gamma) > \frac{1}{b-1}$ for all $t>t^*$. Consequently, 
\[
 \sum_{t=2}^{t^*}\frac{1}{b-1} \geq \sum_{t=2}^{t^*}\psi_t(\gamma) \text{ and }  \sum_{t=t^*+1}^{b}\frac{1}{b-1} \leq \sum_{t=t^*+1}^{b}\psi_t(\gamma).
\]
Since $\phi_t(\gamma)$ is decreasing in $t$ the claim follows.
\end{proof}


\noindent
Next, setting \[
\Delta(\gamma) = \frac{r}{N}\sum_{t=2}^b\psi_t(\gamma)\phi_t(\gamma) - 1
\]
we find that 
\[
\Delta(0) =\frac{r}{N} \sum_{t=2}^n\psi_t(0)\phi_t(0) - 1 = \frac{r}{N} - 1 <0
\]
for all $n>1$.  Thus, a pure contribution strategy exists for all values of $r$ (as we have assumed $r<N$) and Proposition~\ref{thm:pureStrat} is proved. \\

In terms of Proposition~\ref{thm:mixedStrat} there are plenty of values of $r$ that yield a $\gamma$ with $\Delta(\gamma) = 0$. Since $n>1$ observe that $\Delta(\gamma) > \Delta(1) = \Delta(0) = \frac{r}{N} -1$ for all $\gamma \in (0,1)$. In turn, by Rolle's Theorem there exists at least one local maximum for $\Delta(\gamma)$ in $(0,1)$. Set $\gamma_0$ to denote this maximum and consider $\Delta(\gamma)$ as a function on $r$ and $\gamma$, $\Delta(r,\gamma)$. Observe that since $r$ is a constant in $\Delta(r, \gamma)$ then $\gamma_0$ is a local maxima for all $r$. Since for all $\gamma \in (0,1) $ we have $\Delta(N,\gamma)>\Delta(N,0) = 0$ and $\Delta(0,\gamma^\sharp)<0$ the continuity of $\Delta(r,\gamma)$ on $r$ implies that there exists a unique value $r^\sharp$ with $\Delta(r^\sharp, \gamma_0) = 0$. Moreover, for all $r>r^\sharp$ we get $\Delta(r,\gamma_0) > 0>\Delta(r,1) = \Delta(r,0) $ and, thus, two roots must exist. This finished the proof of Proposition~\ref{thm:mixedStrat}. \hfill \qedsymbol{}\\


\section*{Online Appendix for "Efficient Public Good Provision in a Multipolar
World": mixed strategy equilibria with asymmetric groups}
\begin{proposition}
\begin{enumerate}
\item \textbf{Asymmetric with plural groups.}\label{thm:mixedStratAsym} If $n_j>1$ for all $j\leq b$ then there exists a value $r^\sharp<N$ so that for all values $r>r^\sharp$ there exist two distinct values $\gamma^1_r,\gamma^2_r \in(0,1)$ where, for all $i\in I$, the profiles of play

\begin{align*}
    \sigma_{i,1}^*(C\mid \zeta) =
\begin{cases}
1, & \zeta \in\{(0,0), (1,n)\}\\
\gamma^1_r, & \text{otherwise},
\end{cases}
\end{align*}

\begin{align*}
    \sigma_{i,2}^*(C\mid \zeta) =
\begin{cases}
1, & \zeta \in\{(0,0), (1,n)\}\\
\gamma^2_r, & \text{otherwise}
\end{cases}
\end{align*}
 establish two distinct sequential equilibria $(\sigma^*_1, \mu^*_1)$ and $(\sigma^*_1, \mu^*_2)$, respectively.
\item \textbf{Asymmetric with a singular group.}\label{thm:mixedStratAsym2} If $n_j=1$ for some $j\leq b$ then there exists a value $r^\sharp<N$ so that for all values $r>r^\sharp$ there exist one $\gamma^* \in(0,1)$ where, for all $i\in I$, the profile of play
\begin{align*}
    \sigma_{i}^*(C\mid \zeta) =
\begin{cases}
1, & \zeta \in\{(0,0), (1,n)\}\\
\gamma^*, & \text{otherwise},
\end{cases}
\end{align*}

 establish a sequential equilibrium $(\sigma^*, \mu^*)$.
\end{enumerate}
\end{proposition}

\begin{proof}
    

As before, let's assume that the standard strategy given profile $\zeta$ is
\begin{align*}
    \sigma^*(C\mid \zeta) =
\begin{cases}
1, & (0,0), (1,n_k)\\
\gamma, & \text{otherwise},
\end{cases}
\end{align*}
where $1\leq k < b$. Observe a player in group $t>1$ must be aware of the size of group $t-1$ in order to be able to detect a defection. Fix a profile $\overline{\zeta}$ and set for player $j$ in group $t$ the strategies
\[
\sigma_j^C(\zeta)
=
\begin{cases}
\sigma^*_j(\zeta), & \zeta \not = \overline{\zeta}\\
1, & \zeta = \overline{\zeta}.
\end{cases}
\]

\[
\sigma_j^D(\zeta)
=
\begin{cases}
\sigma^*_j(\zeta), & \zeta \not = \overline{\zeta}\\
0, & \zeta = \overline{\zeta},
\end{cases}
\]
and $\mu^D$ and $\mu^C$ as their corresponding beliefs. Let $\phi_t(\gamma)$ denote the expected additional contribution from contributing rather than defecting. Clearly,
\[
\phi_t(\gamma) = \sum_{i=t}^{b} E_{\mu^C}(G_{i}\mid \zeta = \overline{\zeta}, Q(j) = t) -   E_{\mu^D}(G_{i}\mid \zeta = \overline{\zeta}, Q(j) = t).
\]


As with Lemma~1 in the main paper, the form of $\phi_t(\gamma)$ depends on the type of sample player $j$ receives. Set $\Omega_i(\overline{\zeta})= E_{\mu^C}(G_{i}\mid \zeta = \overline{\zeta}, Q(j) = t) -   E_{\mu^D}(G_{i}\mid \zeta = \overline{\zeta}, Q(j)= t)$. If the sample $\overline{\zeta} = (1,n')$ contains a defection - $n_{t-1}>n'$ - we have that
\[
E_{\mu^D}(G_{t+k}\mid \zeta = \overline{\zeta}, Q(j)= t) = n_{t+k}\left[\sum_{i=1}^{k=1} \gamma^{n_{t+i}}\prod_{j=1}^{i-1}\left(1- \gamma^{n_{t+j}}\right) + \gamma\prod_{i=1}^{k-1}\left(1-\gamma^{n_{t+i}}\right)\right]
\]
\[
E_{\mu^C}(G_{t+k}\mid \zeta = \overline{\zeta}, Q(j)= t) = n_{t+k}\gamma^{n_t-1} + (1-\gamma^{n_t-1})E_{\mu^D}(G_{t+k}\mid \zeta = \overline{\zeta}, Q(j)= t).
\]
and thus
\[
 \Omega_{t+k}(\overline{\zeta}) = n_{t+k}\gamma^{n_t-1} \left(1-\frac{E_{\mu^D}(G_{t+k}\mid \zeta = \overline{\zeta}, Q(j)= t)}{n_{t+k}}\right).
\]
Whereas if $\overline{\zeta}= (1,n_{t-1})$ then 
\[
\Omega_{t+k}(\overline{\zeta}) = n_{t+k}\left(1-\frac{E_{\mu^D}(G_{t+k}\mid \zeta = \overline{\zeta}, Q(j)= t)}{n_{t+k}}\right).
\]

Evidently, $\Omega_i(\overline{\zeta})$ is larger when $\overline{\zeta}$ contains no defections. Computing $\phi_t(\gamma) = \sum_{i=t}^{b} \Omega_i(\overline{\zeta})$ presents an onerous task regardless of the sample $\overline{\zeta}$. What we do instead is bound each $\Omega_i(\overline{\zeta})$ between two computationally simpler functions. As the following lemma suggests, it suffices to focus on doing so for $\phi(\gamma)$ when $\overline{\zeta}$ contains a defection. As before, let $\psi_t(\gamma)$ represent the likelihood  of being in group $t$ after observing a defection and $\phi_t(\gamma, \overline{\zeta})$ denote $\phi_t(\gamma)$ on sample $\overline{\zeta})$.

\begin{lemma} Given profiles $\overline{\zeta}' = (1,n')$ with $n'<n_{t-1}$ and $\overline{\zeta} = (1,n_{t-1})$ it follows that for all $\gamma \in [0,1]$

\[
\phi_1(\gamma) > \sum_{t=2}^b\frac{1}{b-1}\phi_t(\gamma, \overline{\zeta}) \geq \sum_{t=2}^b \psi_t(\gamma)\phi_t(\gamma,\overline{\zeta}').
\]
\end{lemma}
\begin{proof} The proof of this Lemma is almost identical to that of Lemma~2 of the main paper except that
\[
\psi_t(\gamma) = \frac{\sum_{i=1}^{t-1}\left(1 + \prod_{j=t-i}^{t-1} (1-\gamma^{n_i}) \right)}{\sum_{k=2}^{b}\sum_{i=1}^{k-1}\left(1 + \prod_{j=t-i}^{t-1} (1-\gamma^{n_i}) \right)}
\]
\end{proof}
Let $M  =\max\{n_1,\ldots, n_b\}$ and $\lambda = \min\{n_1,\ldots, n_b\}$. One can easily verify that if $\overline{\zeta}$ contains a defection
\[
     \gamma^{M-1} + \left(\gamma^{\lambda-1} - \gamma^M\right)\left(1-\gamma^M\right)^{k-1} - \gamma^{\lambda-1} \leq \frac{\Omega_i}{n_i} \leq \gamma^{\lambda-1} + \left(\gamma^{M-1}- \gamma^\lambda\right)\left(1-\gamma^\lambda\right)^{k-1} - \gamma^{M-1}
\]

\noindent
for any $i$. In fact, $M = \lambda$ describes the symmetric scenario and $M =\lambda = 1$ is that of Monz\'{o}n and Gallice..

Setting
\[
\phi_t^{\bot}(\gamma) = \sum_{i=t+1}^b \lambda\left(\gamma^{M-1} + \left(\gamma^{\lambda-1} - \gamma^M\right)\left(1-\gamma^M\right)^{k-1} - \gamma^{\lambda-1}\right)+ 1
\]
and
\[\phi_t^{\top}(\gamma) =\sum_{i=t+1}^b M\left(\gamma^{\lambda-1} + \left(\gamma^{M-1}- \gamma^\lambda\right)\left(1-\gamma^\lambda\right)^{k-1} - \gamma^{M-1}\right) + 1
\]
we get that 
 \[
 \phi_t^{\bot}(\gamma) \leq \phi_t(\gamma) \leq \phi_t^{\top}(\gamma).
 \]
  As before set 
   \[
 \Delta(\gamma) = \frac{r}{N}\sum_{t=2}^b\psi_t(\gamma)\phi_t(\gamma) - 1.
 \]
  If $M,\lambda \geq 2$ it follows that
 \[
 \lim_{\gamma \to 0} \phi_t^{\bot}(\gamma) = \lim_{\gamma \to 1} \phi_t^{\bot}(\gamma) = \lim_{\gamma \to 0} \phi_t^{\top}(\gamma) = \lim_{\gamma \to 1} \phi_t^{\top}(\gamma) = 1
 \]
 forces
 \[
 \lim_{\gamma \to 0} \phi_t(\gamma) = \lim_{\gamma \to 1} \phi_t(\gamma) = 1
 \]
 by a pinching $\phi_t(\gamma)$ between its bounds. Therefore, we get that for all $\gamma \in (0,1)$: $\Delta(\gamma) > \frac{r}{N} -1 = \Delta(1)  = \Delta(0)<0$ for all $r<N$. We can apply the same arguments used in the proofs of Propositions~2 and~3 of the main paper to derive claimed result for the case where $M,\lambda \geq 2$. Finally for $M > \lambda = 1$ it follows that 
   \[
 \lim_{\gamma \to 0} \phi_t^{\bot}(\gamma) = \lim_{\gamma \to 1} \phi_t^{\bot}(\gamma) = 1,\lim_{\gamma \to 0} \phi_t^{\top}(\gamma) = 2  \text{ and }  \lim_{\gamma \to 1} \phi_t^{\top}(\gamma) = 1.
 \]
 Observe that regardless of the value of $\Delta(0)$ (i.e., whether it's positive or negative) since $\Delta(1) < 0$, and $\Delta(\gamma)>0$ for $r=N$ and any $\gamma \in (0,1)$ there must exist value of $r^\sharp$ with a corresponding value $\gamma^\sharp \in (0,1)$ so that $\Delta(r^\sharp,\gamma^\sharp)=0$.

\end{proof}

\end{document}

