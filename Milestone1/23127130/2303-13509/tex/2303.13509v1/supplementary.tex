% !TEX root = ../main_cvpr.tex
\appendix
\begin{center}{\bf \Large Supplementary Material}\end{center}\vspace{-1mm}

\vspace{-1mm}\section{Implementation Details}\label{sec:appendix:implementation}\vspace{-1mm}
% \myparagraph{Implementation Details. }

For data augmentation, we adopt rotating, flipping, scaling, and noising.

In the voxelization process, we first transform raw point clouds' Cartesian coordinates ($x,y,z$) into Polar coordinates ($r, \theta, z$). Then we clip the 3D space range into $r\in [0, 50], \theta\in [-\pi, \pi], z\in [-4, 2]$ for SemanticKITTI~\cite{SemanticKITTI}, and $r\in [0, 50], \theta\in [-\pi, \pi], z\in [-5, 3]$ for nuScenes~\cite{nuScenes}.

For SemanticKITTI~\cite{SemanticKITTI} test split results, we use both training split and validation split for training. We train the model for 80 epochs with a batch size of 8 on eight NVIDIA A100 GPUs, as more epochs can continuously optimize the performance. The initial learning rate is 0.005 and will decay to 0.001 in epoch 60.

For inference, we keep mask predictions with sigmoid classification confidences larger than 0.4. After $argmax$, we filter out mask predictions that the IoU of the remaining mask and original mask is smaller than 0.8.

\vspace{-1mm}\section{Discussions}\label{sec:appendix:discussion}\vspace{-1mm}

\myparagraph{Model Comparisons.}
We compare panoptic segmentation models based on the Cylinder3D~\cite{Cylinder3D} backbone. As shown in Table~\ref{tab:setting}. We outperform previous methods~\cite{Cylinder3D, DS-Net} by a large margin in performance and speed. The comparisons of~\methodname~with different settings demonstrate that while heavier network settings promote performance, they also add on computational cost and lower the inference speed.

\myparagraph{Point vs. Voxel.}
To implement P3Former, an important choice is the type of 3D representations for segmentation. P3Former uses sparse voxel features rather than points as the input of the segmentation head. Table~\ref{tab:PV} proves that the voxel type outperforms the point type by 1.5 PQ while about 1.7 times faster in inference. The performance gain of the voxel type is intuitive because, by voxelizing points, we rebalance the varying point density of objects in the scenes.

\begin{table}[h]
    \caption{Ablation of Representation Types.}
    \begin{center}
    \small{
    \begin{tabular}{c|c|c}
      Feature Type & PQ & FPS\\
    \hline
    \specialrule{0.05em}{3pt}{3pt}
      Voxel  &  60.9 & 19.7\\
      Point  &  59.4 & 11.4\\
     \end{tabular}
        }
    \end{center}
    \label{tab:PV}
\end{table}


\myparagraph{Semantic Segmentation.}
We verify the effectiveness of \methodname~on semantic segmentation of SemanticKITTI (Table~\ref{tab:sem_seg}). With interaction mechanism and iterative refinement, we outperform vanilla Cylinder3D decode head by 1.7\% mIOU. 

\begin{table}[h]
    \caption{Results of Semantic Segmentation}
    \begin{center}
    \small{
    \begin{tabular}{c|c}
    Method & mIOU\\
    \hline
    \specialrule{0.05em}{3pt}{3pt}
    Cylinder3D & 62.5 \\
    \methodname & 64.2 \\
    \end{tabular}
        }
    \end{center}
    \label{tab:sem_seg}
\end{table}

\myparagraph{Loss Weights.}
Objects are relatively tiny compared with the whole outdoor scene. Thus, the proportion of positive and negative samples in mask supervision is critically imbalanced. From this observation, we select Focal Loss~\cite{focalloss} rather than CrossEntropy Loss to alleviate this problem. Besides, we increase the weight of Dice Loss since it can supervise the mask without being influenced by the imbalanced situation. The experimental results are shown in Table~\ref{tab:ablation:loss}.

\begin{table}[h]
    \caption{Ablation of Loss Weights.}
    \begin{center}
    \small{
    \begin{tabular}{ccc|ccc}
     CE & Focal & Dice & PQ & RQ & SQ\\
    \hline
    \specialrule{0.05em}{3pt}{3pt}
    1 & 0 & 1 & 58.9 & 68.9 & 75.0\\
    0 & 1 & 1 & 59.0 & 69.2 & 75.1\\
    0 & 1 & 2 & 59.8 & 70.8 & 72.7\\
     \end{tabular}
        }
    \end{center}
    \label{tab:ablation:loss}
\end{table}

\begin{figure*}[!h]
  \centering
  \includegraphics[width=\linewidth]{supp_crop.pdf}
  \caption{Qualitative examples in SemanticKITTI~\cite{semantickittipan}. Black in GT denotes the ignored class. Instances in panoptic results are randomly colored. Best viewed in color with zoom-in.}
  \label{fig:sem_pan}
\end{figure*}

\begin{figure*}[!h]
  \centering
  \includegraphics[width=\linewidth]{supp_cmp_crop.pdf}
  \caption{Qualitative comparisons in SemanticKITTI. Black in GT denotes the ignored class. Instances in panoptic results are randomly colored. Best viewed in color with zoom-in.}
  \label{fig:cmp}
\end{figure*}

\vspace{-1mm}

\section{Detailed Benchmarks}\label{sec:appendix:discussion}\vspace{-1mm}

We provide class-wise LiDAR panoptic results on SemanticKITTI~\cite{SemanticKITTI} test set (Table~\ref{tab:sem_test}), nuScenes~\cite{nuScenes} dataset (Table~\ref{tab:nus_val}).


\vspace{-1mm}


\section{Visualizations}\label{sec:appendix:discussion}\vspace{-1mm}
\myparagraph{Qualitative Comparisons.}
We show the qualitative examples of semantic and panoptic segmentation on SemanticKITTI~\cite{SemanticKITTI} in Fig.~\ref{fig:sem_pan}. Our method performs well on large-scale outdoor scenes. Notably, P3Former can effectively handle the situations when instances are truncated because queries separate instances based on not only positional distances but also geometric similarity (Fig.~\ref{fig:cases}-(a, left)). Besides, our approach can tackle the crowded scenarios Fig.~\ref{fig:cases}-(a, right) since queries are specialized in precise positions.

We visualize the predictions of our method and other methods in Fig.~\ref{fig:cmp}.
Since recent SoTA~\cite{GPS3Net, SCAN, PHNet} methods havenâ€™t released their code, we qualitatively compare our method to ~\cite{DS-Net} (CVPR 2021). The first row of Fig.~\ref{fig:cmp} shows that our methods are better at distinguishing close instances with similar geometry. The second and third rows of Fig.~\ref{fig:cmp} demonstrate that three-stage methods depend a lot on the results of semantic segmentation. If the semantic segmentation fails (the car circled in the second row), the panoptic segmentation is bound to fail. However, with a unified structure like P3Former, we can successfully eliminate this problem.

\myparagraph{Failure Cases.}
 However, P3Former still faces some challenges, such as failing to segment some incomplete and close instances (Fig.~\ref{fig:cases}-(b, left)), and wrongly classifying instances due to the highly imbalanced category distribution (Fig.~\ref{fig:cases}-(b, right)). We will investigate these inefficiencies in future studies.

 
\myparagraph{Visualization of Mask Update Processes.}
We compare the mask update processes between K-Net~\cite{K-Net} and P3Former in different domains (Fig.~\ref{fig:update}). It can be observed that, in images, instances have distinctive appearances, such as colors and textures. Each instance is expected to be assigned to one query before the update. Because instances are likely to overlap with each other, it is critical for queries to be adaptive to instances and refine their boundary during the update.

In contrast, instances in point clouds don't suffer from overlapping but are commonly geometrically alike. As a result, queries have difficulty separating instances with similar geometric structures and close positions before the update. With our mixed-parameterized positional encoding strategy and position-aware segmentation accentuating positional differences of instances, queries will gradually specialize on specific positions and successfully segment these instances.



\begin{figure*}[!h]
  \centering
  \includegraphics[width=0.85\linewidth]{sup_vis_cases_crop.pdf}
  \caption{Hard Cases and Failure Cases. (a) P3Former successfully tackles the hard cases of truncated instances (left) and the dense crowd (right). (b) Failure cases of incomplete and close instances (left) and tail categories (right). Best viewed in color with zoom-in.}
  \label{fig:cases}
\end{figure*}


\begin{figure*}[!h]
  \centering
  \includegraphics[width=0.90\linewidth]{sup_vis_compare_crop.pdf}
  \caption{Comparisons of the update processes between K-Net and P3Former. Top line figures are borrowed from K-Net~\cite{K-Net}. Best viewed in color with zoom-in.}
  \label{fig:update}
\end{figure*}

\begin{table*}[t]
      \begin{center}  \caption{Ablation studies on Model Setting. Here $N_L$ indicates iterative layer numbers, $N_Q$ indicates the query number and $N_D$ indicates the feature dimension. ``$^{\dag}$": We measure the latency with the official codebase released by the authors on our hardware for reference.}
    \begin{threeparttable}
  \scalebox{0.90}{\tablestyle{8pt}{1.0}
    \begin{tabular}{c|cccc|cccc|cc}
    Model & $\mathrm{N_{L}}$ & $\mathrm{N_{Q}}$ & $\mathrm{N_{D}}$ & Backbone Size & PQ & RQ & SQ & IoU & Model Size & FPS \\
    \hline
    \specialrule{0.05em}{3pt}{3pt}
      Cylinder3D & & - & & 1x & 56.4 & 67.1 & 76.5 & 63.5 & - & -\\
      DS-Net     & & - & & 1x & 57.7 & 68.0 & 77.6 & 63.5   & 221M & $2.1^{\dag}$ \\
    \specialrule{0.05em}{3pt}{3pt} 
                 % & 3 & 64 & 64 & &&&&& \\
      ~\methodname  & 3 & 128 & 128 & 0.5x & 61.4 & 71.3 & 75.9 & 65.5 & 77M  & 19.7\\
                   & 6 & 128 & 256 & 0.5x & 62.5 & 72.4 & 76.1 & 66.5 & 120M & 14.2\\
                   & 6 & 128 & 256 & 1x   & 62.5 & 72.3 & 76.2 & 66.4 & 279M & 12.5\\
                   & 6 & 128 & 256 & 1.5x & 62.8 & 72.5 & 76.4 & 66.6 & 559M & 11.6\\
    \end{tabular}}
    \end{threeparttable}
    \label{tab:setting}
     \end{center}
      
\end{table*}


\begin{table*}[t]
  \begin{center}
  \caption{Class-wise LiDAR panoptic segmentation results on SemanticKITTI test set}
  \label{tab:sem_test}
  \scalebox{0.85}{\tablestyle{8pt}{1.0}
    % \begin{tabular}{c|c|p{0.6cm}<{\centering}p{0.6cm}<{\centering}p{0.6cm}<{\centering}p{0.9cm}<{\centering}p{0.6cm}<{\centering}p{0.6cm}<{\centering}}
    \begin{tabular}{c|p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.4cm}<{\centering}|c}
    
    Metrics & \rotatebox{90}{Car} & \rotatebox{90}{Truck} & \rotatebox{90}{Bicycle} & \rotatebox{90}{Motorcycle} & \rotatebox{90}{Other Vehicle} & \rotatebox{90}{Person} & \rotatebox{90}{Bicyclist} & \rotatebox{90}{Motorcyclist} & \rotatebox{90}{Road} & \rotatebox{90}{Sidewalk} & \rotatebox{90}{Parking} & \rotatebox{90}{Other Ground} & \rotatebox{90}{Building} & \rotatebox{90}{Vegetation} & \rotatebox{90}{Trunk} & \rotatebox{90}{Terrain} & \rotatebox{90}{Fence} & \rotatebox{90}{Pole} & \rotatebox{90}{Traffic Sign} & Mean \\
    
    \hline
    \specialrule{0.05em}{3pt}{3pt}
    PQ      & 93.0 & 47.3 & 52.1 & 65.6 & 61.1 & 75.2 & 79.4 & 63.4 & 89.2 & 69.4 & 53.0 & 19.8 & 89.4 & 81.4 & 63.2 & 47.7 & 57.6 & 58.5 & 66.7 & 64.9\\
    RQ      & 98.5 & 50.3 & 68.2 & 73.3 & 65.6 & 84.6 & 86.1 & 66.1 & 96.9 & 85.6 & 68.6 & 26.9 & 95.0 & 96.1 & 82.5 & 63.5 & 74.1 & 77.0 & 83.3 & 75.9 \\
    SQ      & 94.4 & 94.0 & 76.4 & 89.5 & 93.2 & 89.0 & 92.2 & 95.9 & 92.0 & 81.1 & 77.3 & 73.6 & 94.1 & 84.7 & 76.6 & 75.0 & 77.7 & 75.9 & 80.1 & 84.9 \\
    mIoU     & 95.6 & 49.2 & 54.8 & 66.7 & 57.8 & 69.9 & 72.0 & 38.9 & 91.5 & 75.8 & 67.2 & 40.1 & 92.1 & 86.1 & 72.4 & 69.8 & 68.5 & 64.0 & 65.6 & 68.3 \\
    
    \end{tabular}}
  \end{center}
\end{table*}

\begin{table*}[!h]
  \begin{center}
  \caption{Class-wise LiDAR panoptic segmentation results on nuScenes dataset}
  \label{tab:nus_val}
  \scalebox{0.80}{\tablestyle{8pt}{1.0}
    % \begin{tabular}{c|c|p{0.6cm}<{\centering}p{0.6cm}<{\centering}p{0.6cm}<{\centering}p{0.9cm}<{\centering}p{0.6cm}<{\centering}p{0.6cm}<{\centering}}
    \begin{tabular}{c|p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.25cm}<{\centering}
                        p{0.4cm}<{\centering}|c}
    
    Metrics & \rotatebox{90}{Barrier} & \rotatebox{90}{Bicycle} & \rotatebox{90}{Bus} & \rotatebox{90}{Car} & \rotatebox{90}{Construction Vehicle} & \rotatebox{90}{Motorcycle} & \rotatebox{90}{Pedestrian} & \rotatebox{90}{Traffic Cone} & \rotatebox{90}{Trailer} & \rotatebox{90}{Truck} & \rotatebox{90}{Driveable Surface} & \rotatebox{90}{Other Flat} & \rotatebox{90}{Sidewalk} & \rotatebox{90}{Terrain} & \rotatebox{90}{Manmade} & \rotatebox{90}{Vegetation} & Mean \\
    \hline
    \specialrule{0.05em}{3pt}{3pt}
    PQ      & 65.0 & 68.9 & 77.1 & 94.1 & 61.3 & 85.2 & 93.0 & 91.5 & 60.2 & 73.0 & 96.2 & 59.6 & 69.3 & 57.5 & 86.9 & 82.9 & 75.9 \\
    RQ      & 77.3 & 79.3 & 80.3 & 97.5 & 67.5 & 91.5 & 97.9 & 97.0 & 67.5 & 77.6 & 99.9 & 69.3 & 85.7 & 73.5 & 98.3 & 95.9 & 84.7 \\
    SQ      & 84.1 & 86.9 & 96.0 & 96.6 & 90.8 & 93.1 & 95.0 & 94.3 & 89.3 & 94.2 & 96.3 & 86.0 & 80.8 & 78.2 & 88.4 & 86.5 & 89.8 \\
    mIoU    & 68.2 & 40.3 & 92.4 & 93.2 & 57.0 & 84.1 & 76.3 & 65.1 & 73.2 & 85.3 & 96.5 & 71.5 & 74.1 & 74.8 & 89.6 & 87.2 & 76.8 \\
    
    \end{tabular}}
  \end{center}
\end{table*}

% \begin{table*}[!h]
%   \begin{center}
%   \caption{Class-wise LiDAR panoptic segmentation results on nuScenes test set}
%   \label{tab:nus_test}
%   \scalebox{0.80}{\tablestyle{8pt}{1.0}
%     % \begin{tabular}{c|c|p{0.6cm}<{\centering}p{0.6cm}<{\centering}p{0.6cm}<{\centering}p{0.9cm}<{\centering}p{0.6cm}<{\centering}p{0.6cm}<{\centering}}
%     \begin{tabular}{c|p{0.25cm}<{\centering}
%                         p{0.25cm}<{\centering}
%                         p{0.25cm}<{\centering}
%                         p{0.25cm}<{\centering}
%                         p{0.25cm}<{\centering}
%                         p{0.25cm}<{\centering}
%                         p{0.25cm}<{\centering}
%                         p{0.25cm}<{\centering}
%                         p{0.25cm}<{\centering}
%                         p{0.25cm}<{\centering}
%                         p{0.25cm}<{\centering}
%                         p{0.25cm}<{\centering}
%                         p{0.25cm}<{\centering}
%                         p{0.25cm}<{\centering}
%                         p{0.25cm}<{\centering}
%                         p{0.4cm}<{\centering}|c}
    
%     Metrics & \rotatebox{90}{Barrier} & \rotatebox{90}{Bicycle} & \rotatebox{90}{Bus} & \rotatebox{90}{Car} & \rotatebox{90}{Construction Vehicle} & \rotatebox{90}{Motorcycle} & \rotatebox{90}{Pedestrian} & \rotatebox{90}{Traffic Cone} & \rotatebox{90}{Trailer} & \rotatebox{90}{Truck} & \rotatebox{90}{Driveable Surface} & \rotatebox{90}{Other Flat} & \rotatebox{90}{Sidewalk} & \rotatebox{90}{Terrain} & \rotatebox{90}{Manmade} & \rotatebox{90}{Vegetation} & Mean \\
%     \hline
%     \specialrule{0.05em}{3pt}{3pt}
%     PQ & 62.8 & 72.5 & 67.0 & 93.4 & 62.2 & 82.5 & 93.4 & 92.5 & 61.9 & 67.1 & 97.3 & 54.3 & 72.8 & 57.6 & 86.5 & 84.6 & 75.5\\
%     RQ & 76.1 & 80.6 & 71.4 & 96.7 & 70.8 & 87.1 & 98.3 & 97.2 & 69.8 & 71.0 & 100.0 & 62.2 & 89.2 & 74.5 & 98.3 & 96.0 & 83.7\\
%     SQ & 82.5 & 90.0 & 93.9 & 96.6 & 87.8 & 94.8 & 95.0 & 95.1 & 88.6 & 94.6 & 97.3 & 87.3 & 81.6 & 77.3 & 88.0 & 88.2 & 89.9 \\
%     mIoU & 61.3 & 32.9 & 80.7 & 90.7 & 70.2 & 79.1 & 70.1 & 67.9 & 80.0 & 70.6 & 97.4 & 66.6 & 79.1 & 74.5 & 90.1 & 86.5 & 74.8\\
%     \end{tabular}}
%   \end{center}
% \end{table*}
