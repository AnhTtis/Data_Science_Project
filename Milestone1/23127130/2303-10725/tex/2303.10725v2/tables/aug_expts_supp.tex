\begin{table}[t]
  \caption{
  % \textbf{ImageNet-1K Experimental Results.} 
  Experimental results with augmentations based on ImageNet-1K. We constrain methods to $58.8$M updates but allow them to use their own augmentation settings.
  The $(\uparrow)$ and $(\downarrow)$ indicate high and low values to reflect optimum performance respectively. $\mathcal{P}$ is the number of parameters in Millions, $\mu$ is the average top-5 accuracy, $\alpha$ is the final top-5 accuracy, $\mathcal{M}$ is the total memory in GB, and $\mathcal{U}$ is the total number of updates in Millions.} 
  \label{tab:aug_expts_supp}
  \centering
     %\begin{tabular}{p{1.1cm}p{0.75cm}p{0.75cm}p{.75cm}p{0.9cm}p{0.75cm}}
     \begin{tabular}{lrrrrr}
     \hline
     Method & $\mathcal{P}(\downarrow)$ & $\mu(\uparrow)$ & $\alpha(\uparrow)$ & $\mathcal{M}(\downarrow)$ & $\mathcal{U}(\downarrow)$ \\
     \hline
     Offline & $5.48$ & --- & $90.74$ & $192.87$ & $753.33$  \\
     \hline
     DER & $54.80$ & $82.72$ & $71.82$ & $20.99$ & $58.39$ \\
     ER & $5.48$ & $82.19$ & $71.22$ & $19.59$ & $58.78$ \\
     REMIND & $5.48$ & $87.67$ & $82.97$ & $2.02$ & $58.78$ \\
     \textbf{SIESTA} & $\mathbf{5.48}$ & $\mathbf{90.67}$ & $\mathbf{87.00}$ & $\mathbf{2.02}$ & $\mathbf{57.60}$ \\
     \hline
     %\vspace{-2em}
    \end{tabular}
\end{table}
