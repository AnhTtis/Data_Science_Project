\begin{table}[t]
  \caption{
  Class incremental learning  results on ImageNet-1K.
  For a fair comparison, we constrain methods to 12.5 million updates and do not use data augmentation.
  The $(\uparrow)$ and $(\downarrow)$ indicate high and low values to reflect optimum performance respectively. $\mathcal{P}$ is the number of parameters in Millions, $\mu$ is the average top-5 accuracy, $\alpha$ is the final top-5 accuracy, $\mathcal{M}$ is the total memory in GB, and $\mathcal{U}$ is the total number of updates in Millions.} 
  \label{tab:no_aug}
  \centering
     %\begin{tabular}{p{1.1cm}p{0.75cm}p{0.75cm}p{.75cm}p{0.9cm}p{0.75cm}}
     \begin{tabular}{lrrrrrr}
     \hline
     Method & $\mathcal{P}(\downarrow)$ & $\mu(\uparrow)$ & $\alpha(\uparrow)$ & $\mathcal{M}(\downarrow)$ & $\mathcal{U}(\downarrow)$ & GFLOPS $(\uparrow)$ \\
     \hline
     % \multicolumn{6}{l}{\emph{Offline Learning}}\\
     Offline & $5.48$ & --- & $83.31$ & $192.87$ & $768.70$ & --- \\
     \hline
     %SIESTA$\ast$ & $5.48$ & - & $84.07$ & $2.02$ & $20.50$ \\
     %\hline
     %\multicolumn{6}{l}{\emph{Incremental Batch Learning}}\\
     DER & $54.80$ & $81.87$ & $70.15$ & $20.99$ & $12.43$ & $7944.60$ \\
     ER & $5.48$ & $76.32$ & $63.92$ & $19.59$ & $11.53$ & $1294.10$ \\
     REMIND & $5.48$ & $81.77$ & $74.31$ & $2.02$ & $11.53$ & $10139.00$ \\
     \textbf{SIESTA} & $\mathbf{5.48}$ & $\mathbf{88.33}$ & $\mathbf{83.59}$ & $\mathbf{2.02}$ & $\mathbf{11.53}$ & $\mathbf{19326.00}$ \\
     %\hline
     %\multicolumn{6}{l}{\emph{Online Continual Learning}}\\
     
     %\textbf{SIESTA} & $5.48$ & $\mathbf{87.08}$ & $\mathbf{83.59}$ & $2.02$ & $11.53$ \\
     \hline
     %\vspace{-2em}
    \end{tabular}
\end{table}