\documentclass[10pt,journal,compsoc]{IEEEtran}

\ifCLASSOPTIONcompsoc
% IEEE Computer Society needs nocompress option
% requires cite.sty v4.0 or later (November 2003)
\usepackage[nocompress]{cite}
\else
% normal IEEE
\usepackage{cite}
\fi
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of the IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/pkg/cite
% The documentation is contained in the cite.sty file itself.
%
% Note that some packages require special options to format as the Computer
% Society requires. In particular, Computer Society  papers do not use
% compressed citation ranges as is done in typical IEEE papers
% (e.g., [1]-[4]). Instead, they list every citation separately in order
% (e .g., [1], [2], [3], [4]). To get the latter we need to load the cite
% package with the nocompress option which is supported by cite.sty v4.0
% and later. Note also the use of a CLASSOPTION conditional provided by
% IEEEtran.cls V1.7 and later.





% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
% \usepackage[pdftex]{graphicx}
% declare the path(s) where your graphic files are
% \graphicspath{{../pdf/}{../jpeg/}}
% and their extensions so you won't have to specify these with
% every instance of \includegraphics
% \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
% or other class option (dvipsone, dvipdf, if not using dvips). graphicx
% will default to the driver specified in the system graphics.cfg if no
% driver is specified.
% \usepackage[dvips]{graphicx}
% declare the path(s) where your graphic files are
% \graphicspath{{../eps/}}
% and their extensions so you won't have to specify these with
% every instance of \includegraphics
% \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex






% *** MATH PACKAGES ***
%
%\usepackage{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=footnotesize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a sans serif font rather
% than the serif font used in traditional IEEE formatting and thus the need
% to invoke different subfig.sty package options depending on whether
% compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to load fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/stfloats
% Do not use the stfloats baselinefloat ability as the IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that the IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as the IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/pkg/dblfloatfix




%\ifCLASSOPTIONcaptionsoff
%  \usepackage[nomarkers]{endfloat}
% \let\MYoriglatexcaption\caption
% \renewcommand{\caption}[2][\relax]{\MYoriglatexcaption[#2]{#2}}
%\fi
% endfloat.sty was written by James Darrell McCauley, Jeff Goldberg and 
% Axel Sommerfeldt. This package may be useful when used in conjunction with 
% IEEEtran.cls'  captionsoff option. Some IEEE journals/societies require that
% submissions have lists of figures/tables at the end of the paper and that
% figures/tables without any captions are placed on a page by themselves at
% the end of the document. If needed, the draftcls IEEEtran class option or
% \CLASSINPUTbaselinestretch interface can be used to increase the line
% spacing as well. Be sure and use the nomarkers option of endfloat to
% prevent endfloat from "marking" where the figures would have been placed
% in the text. The two hack lines of code above are a slight modification of
% that suggested by in the endfloat docs (section 8.4.1) to ensure that
% the full captions always appear in the list of figures/tables - even if
% the user used the short optional argument of \caption[]{}.
% IEEE papers do not typically make use of \caption[]'s optional argument,
% so this should not be an issue. A similar trick can be used to disable
% captions of packages such as subfig.sty that lack options to turn off
% the subcaptions:
% For subfig.sty:
% \let\MYorigsubfloat\subfloat
% \renewcommand{\subfloat}[2][\relax]{\MYorigsubfloat[]{#2}}
% However, the above trick will not work if both optional arguments of
% the \subfloat command are used. Furthermore, there needs to be a
% description of each subfigure *somewhere* and endfloat does not add
% subfigure captions to its list of figures. Thus, the best approach is to
% avoid the use of subfigure captions (many IEEE journals avoid them anyway)
% and instead reference/explain all the subfigures within the main caption.
% The latest version of endfloat.sty and its documentation can obtained at:
% http://www.ctan.org/pkg/endfloat
%
% The IEEEtran \ifCLASSOPTIONcaptionsoff conditional can also be used
% later in the document, say, to conditionally put the References on a 
% page by themselves.


\usepackage{diagbox}
%\usepackage{amsmath}
%\usepackage{amssymb}
%\usepackage{graphicx}
%\usepackage{multirow}
%\usepackage{enumerate}
%\usepackage{arydshln}
%\usepackage{multicol}
%\usepackage{algorithm}
%\usepackage{algorithmic}
%\usepackage[utf8]{inputenc} % allow utf-8 input
%\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
%\usepackage{hyperref}       % hyperlinks
%\usepackage{url}            % simple URL typesetting
%\usepackage{booktabs}       % professional-quality tables
%\usepackage{amsfonts}       % blackboard math symbols
%\usepackage{nicefrac}       % compact symbols for 1/2, etc.
%\usepackage{microtype}      % microtypography
%\usepackage{xcolor}     
%\usepackage{epstopdf}    % colors
%\usepackage{wrapfig}
%
%%\usepackage{subfigure}
%\usepackage{subcaption}
%\usepackage{multicol}
%\usepackage{hyperref}

\usepackage{array}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{bm}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{multirow}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{subfigure}
\usepackage{amssymb}
\usepackage{bbding}
\usepackage{pifont}
\usepackage{wasysym}
\usepackage{booktabs} % for professional tables
\usepackage{makecell}
\usepackage{subfigure}
\usepackage{bbding}
\usepackage{balance}
\usepackage{float}
\usepackage{subeqnarray}
\usepackage{cases}
\usepackage{tabularx}
\usepackage{color}
\usepackage{colortbl,url}
%\usepackage[numbers,sort&compress]{natbib}
\usepackage{threeparttable}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%



\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
\newcommand{\tabitem}{~~\llap{\textbullet}~~}


\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\newtheorem{thm}{Theorem}
\newtheorem{cor}{Corollary}
\newtheorem{prop}{Proposition}
\newtheorem{assum}{Assumption}
\newtheorem{lemma}{Lemma}
\newtheorem{defi}{Definition}
\newtheorem{remark}{Remark}
\newtheorem{condition}{Condition}
\newtheorem{example}{Example}
\newtheorem{thm2}{Theorem}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{asu}{Assumption}[section]
\renewcommand{\thetheorem}{\arabic{section}.\arabic{theorem}}
\newtheorem{definition}{Definition}[section]
\renewcommand{\thedefinition}{\arabic{section}.\arabic{definition}}
\renewcommand{\thelemma}{\arabic{section}.\arabic{lemma}}
\renewcommand{\theremark}{\arabic{section}.\arabic{remark}}
\newtheorem{proposition}{Proposition}[section]
\renewcommand{\theproposition}{\arabic{section}.\arabic{proposition}}
\newtheorem{assumption}{Assumption}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{rem}{Remark}[section]

\usepackage{latexsym,amsmath,amssymb,amsthm}
% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.
\graphicspath{{figures/}}
\def\D{\mathcal{D}}
\def\x{\mathbf{x}}
\def\y{\mathbf{y}}
\def\z{\mathbf{z}}
\def\u{\mathbf{u}}
\def\w{\mathbf{w}}
\def\q{\mathbf{q}}
\def\n{\mathbf{n}}
\def\Q{\mathbf{Q}}
\def\v{\mathbf{v}}
\def\b{\mathbf{b}}
\def\c{\mathbf{c}}
\def\B{\mathbf{B}}
\def\W{\mathbf{W}}
\def\R{\mathbf{R}}
\def\H{\mathbf{H}}
\def\G{\mathbf{G}}
\def\I{\mathbf{I}}
\def\Y{\mathcal{Y}}
\def\S{\mathcal{S}}
\def\X{\mathcal{X}}
\def\T{\mathcal{T}}
\def\B{\mathbf{B}}
\def\D{\mathcal{D}}
\def\A{\mathbf{A}}


\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
	%
	% paper title
	% Titles are generally capitalized except for words such as a, an, and, as,
	% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
	% not capitalized unless they are the first or last word of the title.
	% Linebreaks \\ can be used within to get better formatting as desired.
	% Do not put math or special symbols in the title.
\title{Augmenting Iterative Trajectory for Bilevel Optimization: Methodology, Analysis and Extensions}

\author{Risheng Liu,~\IEEEmembership{Member,~IEEE,}
	Yaohua Liu,
	Shangzhi Zeng, Jin Zhang% <-this % stops a space
		\IEEEcompsocitemizethanks{\IEEEcompsocthanksitem R. Liu and Y. Liu are with the DUT-RU International School of Information Science \& Engineering, Dalian University of Technology, and also with the Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, Dalian, Liaoning, P.R., China.  R. Liu is also with the Peng Cheng Laboratory, Shenzhen, Guangdong, P.R. China. 
		E-mail: rsliu@dlut.edu.cn, liuyaohua\_918@163.com. \protect 
		% note need leading \protect in front of \\ to get a newline within \thanks as
		% \\ is fragile and will error, could use \hfil\break instead.
		\IEEEcompsocthanksitem S. Zeng is with the Department of Mathematics and Statistics, University
		of Victoria, Victoria, B.C., Canada. E-mail: zengshangzhi@uvic.ca. \protect
		\IEEEcompsocthanksitem J. Zhang is with the Department of Mathematics, Southern University of Science and Technology, and National Center for Applied Mathematics Shenzhen, China, (Corresponding author, E-mail: zhangj9@sustech.edu.cn.) \protect
	}
	\thanks{Manuscript received April 19, 2005; revised August 26, 2015.}}


% The paper headers
\markboth{Journal of \LaTeX\ Class Files,~Vol.~14, No.~8, August~2015}%
{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for Computer Society Journals}

\IEEEtitleabstractindextext{%
	\begin{abstract}
		
In recent years, there has been a surge of machine learning applications developed with hierarchical structure, which can be approached from Bi-Level Optimization (BLO) perspective. However, most existing gradient-based methods overlook the interdependence between hyper-gradient calculation and Lower-Level (LL) iterative trajectory, focusing solely on the former. Consequently, convergence theory is constructed with restrictive LL assumptions, which are often challenging to satisfy in real-world scenarios. In this work, we thoroughly analyze the constructed iterative trajectory, and highlight two deficiencies, including empirically chosen initialization and default use of entire trajectory for hyper-gradient calculation. To address these issues, we incrementally introduce two augmentation techniques including Initialization Auxiliary (IA) and Pessimistic Trajectory Truncation (PTT), and investigate various extension strategies such as prior regularization, different iterative mapping schemes and acceleration dynamics to construct Augmented Iterative Trajectory (AIT) for corresponding BLO scenarios (e.g., LL convexity and LL non-convexity). Theoretically, we provide convergence analysis for AIT and its variations under different LL assumptions, and establish the first convergence analysis for BLOs with non-convex LL subproblem. Finally, we demonstrate the effectiveness of AIT through three numerical examples, typical learning and vision applications (e.g., data hyper-cleaning and few-shot learning) and more challenging tasks such as neural architecture search.
		
	\end{abstract}
	
	% Note that keywords are not normally used for peerreview papers.
	\begin{IEEEkeywords}
		Bilevel optimization, gradient-based method, initialization auxiliary, pessimistic trajectory truncation, deep learning.
\end{IEEEkeywords}}


% make the title area
\maketitle


% To allow for easy dual compilation without having to reenter the
% abstract/keywords data, the \IEEEtitleabstractindextext text will
% not be used in maketitle, but will appear (i.e., to be "transported")
% here as \IEEEdisplaynontitleabstractindextext when the compsoc 
% or transmag modes are not selected <OR> if conference mode is selected 
% - because all conference papers position the abstract like regular
% papers do.
\IEEEdisplaynontitleabstractindextext
% \IEEEdisplaynontitleabstractindextext has no effect when using
% compsoc or transmag under a non-conference mode.



% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\IEEEraisesectionheading{\section{Introduction}\label{sec:introduction}}
% Computer Society journal (but not conference!) papers do something unusual
% with the very first section heading (almost always called "Introduction").
% They place it ABOVE the main text! IEEEtran.cls does not automatically do
% this for you, but you can achieve this effect with the provided
% \IEEEraisesectionheading{} command. Note the need to keep any \label that
% is to refer to the section immediately after \section in the above as
% \IEEEraisesectionheading puts \section within a raised box.




% The very first letter is a 2 line initial drop letter followed
% by the rest of the first word in caps (small caps for compsoc).
% 
% form to use if the first word consists of a single letter:
% \IEEEPARstart{A}{demo} file is ....
% 
% form to use if you need the single drop letter followed by
% normal text (unknown if ever used by the IEEE):
% \IEEEPARstart{A}{}demo file is ....
% 
% Some journals put the first two words in caps:
% \IEEEPARstart{T}{his demo} file is ....
% 
% Here we have the typical use of a "T" for an initial drop letter
% and "HIS" in caps to complete the first word.
\IEEEPARstart{R}{ecently}, a variety of rising deep learning applications share similar principles to construct hierarchical optimization models, including Hyperparameter Optimization~\cite{liu2021investigating,shaban2019truncated}, Meta Learning~\cite{nichol2018first,finn2017model,nichol2018first}, Neural Architecture Search~\cite{wu2019fbnet,hu2020tf}, Reinforcement Learning~\cite{liu2018darts,zhang2020bi,wang2020global}, and have achieved highly competitive performance in different fields. With proper reformulation, these models all can be considered as Bi-Level Optimization (BLO) problems, which optimize two nested subproblems in the form as:
\begin{equation}\label{blo_problem}
	\min _{\mathbf{x} \in \mathcal{X}} F(\mathbf{x}, \mathbf{y}), \text { s.t. } \mathbf{y} \in \mathcal{S}(\mathbf{x}):=\arg \min _{ \mathbf{y} \in \mathcal{Y}} f(\mathbf{x}, \mathbf{y}),
\end{equation}
where $\x \in\mathbb{R}^{m}$ and $ \y \in \mathbb{R}^n$ correspond to the Upper-Level (UL) and Lower-Level (LL) variables respectively, the UL objective $F$ and LL objective $f$ are continuously differentiable functions and  $\mathcal{S}(\mathbf{x})$ is the LL solution set for all $\x\in\mathcal{X}$. 

In general, the BLO problem can be considered as a leader-follower game process, where the follower ( i.e., the LL subproblem) continuously responds to the decision $\x$ of the Leader (i.e., the UL subproblem). From the optimistic BLO perspective, we assume that the obtained LL solution $\y\in\mathcal{S}(\x)$ always leads to the optimal solution of UL objective for any given $\x$, then the original BLO in Eq.\eqref{blo_problem} can be reduced to a simple single-level problem as 
\begin{equation}\label{single_reform}
	\min_{\x \in \X} \varphi(\x):= \inf_{\y\in\mathcal{S}(\x)} F(\x,\y),
\end{equation} 
where $\varphi$ is the value function of a simple bilevel problem w.r.t. $\y$ for any given $\x$. Then $\x$ and $\y$ have the cooperative relationship towards minimizing the UL subproblem. Based on this form, various branches of methods~\cite{moore2010bilevel,rajeswaran2019meta,liu2020generic,ye2021difference} have explored how to optimize $\varphi(\x)$ with respective to $\x$ and $\y$ simultaneously, thus solve the above applications captured by this hierarchical structure with high accuracy and efficiency.

Typically, BLO problems remain challenging to be solved caused by the nature of sophisticated dependence between UL and LL variables, especially when multiple LL solutions exist in $\mathcal{S}(\x)$. As for classical theory, KKT condition~\cite{zemkoho2020theoretical} has been considered as efficient tools to solve the above optimization problems. whereas, this type of methods are impractical to be applied in modern machine learning tasks limited by existence of too many multipliers. Meanwhile, Gradient-Based Methods (GBMs)~\cite{franceschi2017forward} have been widely adopted in various learning and vision tasks to handle real-world applications. Practically speaking, the key of solving Eq.~\eqref{single_reform} with GBMs falls to accessing the highly coupled nested gradient caused by iterative optimization to solve the LL subproblem in Eq.~\eqref{blo_problem}.  We denote $\y^{*}(\x)$ as the Best Response mapping of the follower for a given UL variable $\x$. By embedding $\y^{*}(\x)$ into the simple bilevel problem in Eq.~\eqref{single_reform} as $F\left(\x, \y^*(\x)\right)$, the hyper-gradient of $\varphi(\x)$ can be derived by using the chain rule as
%\begin{equation}\label{nest_gradient}
%	\frac{\partial \varphi(\mathbf{x})}{\partial \mathbf{x}}=\frac{\partial F\left(\mathbf{x}, \mathbf{y}^*(\mathbf{x})\right)}{\partial \mathbf{x}}+G(\mathbf{x}),
%\end{equation}

\begin{equation}\label{nest_gradient}
	\nabla_{\x}\varphi(\mathbf{x})=\nabla_{\x}F\left(\mathbf{x}, \mathbf{y}^*(\mathbf{x})\right)+G(\mathbf{x}),
\end{equation}
where $\nabla_{\x}F\left(\mathbf{x}, \mathbf{y}^*(\mathbf{x})\right)$ can be regarded as the direct gradient, and $G(\x)=\left(\nabla_{\x} \mathbf{y}^*(\mathbf{x})\right)^{\top} \nabla_{\y} F\left(\mathbf{x}, \mathbf{y}^*(\mathbf{x})\right)$ denotes the indirect gradient. 

Since the calculation of hyper-gradient requires proper approximation of $\y^*(\x)$ and indirect gradient $G(\x)$, classical dynamics-embedded GBMs~\cite{franceschi2017forward}  tend to construct the approximations by introducing dynamical system obtained from iterative optimization steps. Typically speaking, this type of gradient-based BLO methods approximate $\y^*(\x)$ with $\y_{K}(\x)$ constructed by the following optimization dynamics: $
	\y_{k+1}(\x)=\mathcal{T}_{k+1}\left(\mathbf{x}, \mathbf{y}_{k}(\x)\right),\ k=0,\cdots,K-1,$
where $\y_0(\x)=\y_0$ is a fixed given initial value and $\mathcal{T}_{k+1}(\x,\cdot)$ denotes the iterative dynamics mapping at $k$-th step derived with specific updating scheme. Based on the above formulation, we use $\mathcal{T}_{0:K}$ to denote the historical sequence of $\y_{k}(\x)$, $k=0,...,K$, which will be discussed more thoroughly in this work. In essence, $\mathcal{T}_{0:K}$ reflects the iterative trajectory of LL variables to obtain $\y_{K}(\x)$, then the indirect gradient $G(\x)$ can be approximated with this $\y_{K}(\x)$ by 
$\left(\nabla_{\x} \mathbf{y}_{K}(\mathbf{x})\right)^{\top} \nabla_{\y} F\left(\mathbf{x}, \mathbf{y}_{K}(\mathbf{x})\right)$. By this way, these GBMs can be regarded as using gradient descent methods solving following approximation problem of Eq.~\eqref{single_reform}, 
\begin{equation}\label{single_re_reform}
	\min_{\x \in \X} \varphi_{K}(\x):= F(\x,\y_{K}(\x)).
\end{equation} 
It is worth noting that $\mathbf{y}_{K}(\mathbf{x})$ can be regarded as good approximation as long as $\nabla_{\mathbf{y}} f\left(\mathbf{x}, \mathbf{y}_{K}(\mathbf{x})\right)$ uniformly converges to zero w.r.t. $\x\in\mathcal{X}$ and $F(\x,\y_{K}(\x))$ converges to the real BLO objective $\varphi(\x)$. %in which $\nabla_{\x} \mathbf{y}_{K}(\mathbf{x}) $ is usually computed by Automatic Differentiation (AD).  

To ensure the obtained approximation in Eq.~\eqref{single_re_reform}  is good enough to guarantee the convergence of solutions towards the original BLO, restrictive assumptions of LL subproblem, such as LL Singleton (LLS) and LL Convexity (LLC), are usually required by existing GBMs. Whereas, as complex network structure with multiple convolutional blocks and loss functions with specialized regularization terms are widely employed in lots of applications, the LL subproblems always have non-convex property, which implies a gap between the provided theoretical guarantee and complex properties of real world problems.  To deal with these challenges, several works~\cite{liu2020generic,liu2021value} have spared efforts to design new iterative mapping schemes or approximation theory, thus partly relax the theoretical constraints and obtain some new convergence results. Nevertheless, there is still an urgent need for general BLO framework with solid theoretical analysis to cover the non-convex scenarios.    


%To remove the LLS assumption, instead of constructing $\mathcal{T}_k(\x,\cdot)$ only with the LL gradient described information, BDA proposes a new iterative mapping scheme for $\mathcal{T}_k(\x,\cdot)$ by aggregating the gradient information of UL and LL objectives.

%we first introduce a new concept, i.e., Optimization Trajectory (OT) , to describe the historical track of approximative LL variables used for the hyper-gradient calculation. Then the vanilla OT recorded by existing GBMs can be denote as  
%\begin{equation}\label{OT}
%S_{\textrm{OT}}=\{\y_0(\x), \mathcal{T}_{1}\left(\mathbf{x}, \mathbf{y}_{0}(\x)\right), \dots, \mathcal{T}_{K}\left(\mathbf{x}, \mathbf{y}_{K-1}(\x)\right)\}.
%\end{equation}

%In fact, recently proposed  GBMs~\cite{maclaurin2015gradient,nichol2018reptile,park2019meta,flennerhag2019meta,pedregosa2016hyperparameter,rajeswaran2019meta,lorraine2020optimizing} mostly focus on heuristic techniques to compute the hyper-gradient with designed solution strategies and approximation operators, while paying attention to the previous step of designing LL OT to obtain more reasonable $\y_{K}(\x)$. Consequently, most GBMs could only conduct the convergence analysis with restrict assumptions about the properties of LL subproblems, such as LL Singleton (LLS) and LL Convexity (LLC). 

\subsection{Contributions}

%\begin{table*}[hbtp]
%	\centering
%	\caption{We report the derived convergence results of mainstream methods, and compare the required conditions, assumptions of LL subproblems required by the convergence analysis and whether they support the accelerated version.} 
%	\label{tab_conditions}
%	\vspace {-0.3cm}
%	\begin{footnotesize}
%		\begin{threeparttable}
%			\begin{tabular}{|c|c|c|c|c|c|}
%				\hline
%				&&&&&\\[-6pt]
%				Method & Convergence Results & Required Conditions
%				%& \textbf{LLS}
%				& {w/o LLS} & {w/o LLC}& {w/ Acce } \\			
%				&&&&&\\[-6pt]
%				\hline
%				&&&&&\\[-6pt]
%				 \multirow{2}{*}{FHG/RHG}
%				& $\x_k \stackrel{s}{\longrightarrow} \x^*$
%				&    \multirow{2}{*}{$F(\x,\y)$ and $f(\x,\y)$ are $C^1$. }
%				%& \multirow{2}{*}{w/} 
%				& \multirow{2}{*}{\XSolidBrush} & \multirow{2}{*}{\XSolidBrush} & \multirow{2}{*}{\XSolidBrush}\\
%				
%				&   $\inf\limits_{\x \in \X}\varphi_k(\x) \rightarrow
%				\inf\limits_{\x \in \X}\varphi(\x)$
%				& & && \\
%				
%				
%				&&&&&\\[-6pt]
%				\cline{1-6}
%				&&&&&\\[-6pt]
%				
%				\multirow{2}{*}{TRHG} 				
%				& \multirow{2}{*}{$\x_k {\longrightarrow} \widehat{\x}^*$}
%				&    $F(\x,\y)$ is $C^1$ and bounded below;
%				%& \multirow{2}{*}{w/} 
%				& \multirow{2}{*}{\XSolidBrush} & \multirow{2}{*}{\XSolidBrush} & \multirow{2}{*}{\XSolidBrush} \\
%				
%				&    
%				& $f(\x,\y)$ is $C^1$, $L_f$-smooth and strongly convex.
%				& && \\
%				
%				&&&&&\\[-6pt]
%				\cline{1-6}
%				
%				&&&&&\\[-6pt]
%				\multirow{3}{*}{CG/Neumann}
%				& \multirow{3}{*}{$\x_k {\longrightarrow} \widehat{\x}^*$}
%				&    $F(\x,\y)$ and $f(\x,\y)$ are $C^1$;				
%				%& \multirow{2}{*}{w/} 
%				& \multirow{3}{*}{\XSolidBrush} & \multirow{3}{*}{\XSolidBrush} & \multirow{3}{*}{\XSolidBrush}\\
%				
%				&  
%				& $\frac{\partial^2 f(\x,\y)}{\partial \y \partial \y^\top} $ is invertible.
%				& && \\
%				
%				
%				&&&&&\\[-6pt]
%
%				\cline{1-6}
%				&&&&&\\[-6pt]
%				\multirow{3}{*}{BDA} 				
%				& $\x_k \stackrel{s}{\longrightarrow} \x^*$
%				&    %$F(\x,\y)$ is $C^1$ and strongly convex;
%				$F(\x,\y)$ is $L_F$-smooth, convex, bounded below;
%				%& \multirow{2}{*}{w/o} 
%				& \multirow{3}{*}{\CheckmarkBold} & \multirow{3}{*}{\XSolidBrush} & \multirow{3}{*}{\XSolidBrush}\\
%				& $\inf\limits_{\x \in \X}\varphi_k(\x) \rightarrow
%				\inf\limits_{\x \in \X}\varphi(\x)$
%				&\multirow{2}{*}{$f(\x,\y)$ is $L_f$-smooth.}
%				& && \\
%				
%				&&&&&\\[-6pt]
%				\hline
%				
%				&&&&&\\[-6pt]
%				 \multirow{3}{*}{BVFSM}				
%				& %$\varphi_k(\x)+\delta_{\X}(\x) \stackrel{e}{\longrightarrow} \varphi(\x)+\delta_{\X}(\x)$
%				$\x_k \stackrel{s}{\longrightarrow} \x^*$
%				&  $F(\x,\y)$ and $f(\x,\y)$ are $C^1$  
%				%& \multirow{2}{*}{w/o} 
%				& \multirow{3}{*}{\CheckmarkBold} & \multirow{3}{*}{\CheckmarkBold} & \multirow{3}{*}{\XSolidBrush}\\
%				
%				&  $\inf\limits_{\x \in \X}\varphi_k(\x) \rightarrow
%				\inf\limits_{\x \in \X}\varphi(\x)$
%				&   \multirow{2}{*}{and level-bounded.}
%				& && \\
%				\hline
%				
%				&&&&&\\[-6pt]
%				\hline
%				&&&&&\\[-6pt]
%				 \multirow{3}{*}{AIT}				
%				& %$\varphi_k(\x)+\delta_{\X}(\x) \stackrel{e}{\longrightarrow} \varphi(\x)+\delta_{\X}(\x)$
%				$\x_k {\longrightarrow} \x^*$
%				&  $F(\x,\y)$ , $f(\x,\y)$ and $\nabla_{\y}f(\x,\y)$  are $C^0$  
%				%& \multirow{2}{*}{w/o} 
%				& \multirow{3}{*}{\CheckmarkBold} & \multirow{3}{*}{\CheckmarkBold} & \multirow{3}{*}{\CheckmarkBold}\\
%				
%				&  $\inf\limits_{\x \in \X}\varphi_k(\x) \rightarrow
%				\inf\limits_{\x \in \X}\varphi(\x)$
%				&   \multirow{2}{*}{$f(\x,\cdot)$ is $L_F$-smooth.}
%				& && \\
%				\hline
%				
%			\end{tabular}
%			\begin{tablenotes}
%				\footnotesize
%				\item[1] $C^0$ means continuous, $C^1$ means continuously differentiable.
%				$L_f$ (or $L_F$)-smooth denotes the gradient of $f$ (or $F$) is Lipschitz continuous with Lipschitz constant $L_f$ (or $L_F$).
%				``Level-bounded" is short for ``level-bounded in $\y$ locally uniformly in $\x\in\mathcal{X}$".
%				\item[2] The arrow $\stackrel{s}{\longrightarrow}$ represents the subsequential convergence.
%				$\x^*$ denotes the optimal solution, and $\widehat{\x}^*$ denotes the stationary point.
%				
%			\end{tablenotes}
%		\end{threeparttable}
%	\end{footnotesize}
%\end{table*}

In this work, we propose the Augmented Iterative Trajectory (AIT) framework with two augmentation techniques, including Initialization Auxiliary (IA) and Pessimistic Trajectory Truncation (PTT), and a series of extension strategies to handle the above limitations of existing GBMs. More specifically, we first analyze the vanilla iterative trajectory constructed by the gradient-based BLO scheme, and highlight two significant deficiencies of iterative trajectory, including empirically choosing initialization of iterative trajectory (i.e., $\y_0(\x))$ and using entire trajectory for hyper-gradient calculation by default, both of which are less noticed by existing GBMs. %that is to say,  constructing LL OT with the optimization dynamics, and then calculating the nested hyper-gradient with backpropagation along the whole OT. Then we

Aiming at the above deficiencies of iterative trajectory, we first introduce IA to optimize the initialization value for LL trajectory simultaneously with the UL variables. Then we propose prior regularization as warm start to guide the optimization of IA, and investigate different iterative dynamic mapping schemes and acceleration dynamics to construct our AIT framework for BLOs with Convex LL subproblem ($\textrm{AIT}_{C}$ for short). To handle the challenging non-convex scenario, we further propose PTT operation to dynamically adjust the iterative trajectory for calculation of the hyper-gradient, and introduce the acceleration gradient scheme to construct our AIT framework for Non-Convex BLOs ($\textrm{AIT}_{NC}$ for short). Theoretically, we conduct detailed convergence analysis of $\textrm{AIT}_{C}$, $\textrm{AIT}_{NC}$ and its variations to support different challenging scenarios, especially for the unexplored non-convex scenario. Finally, we demonstrate our convergence results and performance improvement with extensive experiments based on the various numerical examples, typical learning and vision applications and other more challenging deep learning tasks. We summarize our main contributions as follows.
\begin{itemize}
	
	\item We conduct a thorough analysis of the iterative trajectory construction for the gradient-based BLO scheme, which is a significant departure from the existing GBMs. We then identify two limitations of the vanilla iterative trajectory adopted by current GBMs, and introduce our AIT to address BLOs with more relaxed LL assumptions.
	
	\item We first propose IA to guide the optimization of LL variables, and then introduce prior regularization based on IA and explore various iterative dynamic mapping schemes (e.g., Nesterov's acceleration dynamics) to construct $\textrm{AIT}_{C}$ for BLOs with Convex followers. To handle the more challenging non-convex scenarios, we further propose PTT operation to dynamically truncate the trajectory, and investigate acceleration gradient scheme to construct $\textrm{AIT}_{NC}$.
	
	\item We provide detailed theoretical investigation on $\textrm{AIT}_{C}$, $\textrm{AIT}_{NC}$ and corresponding extension strategies (e.g., proximal prior regularization and acceleration gradient scheme) to ensure the convergence property of AIT without LLS even LLC assumption. Notably, we establish the first convergence guarantee for BLO problems with non-convex LL subproblems.
	
	\item A plentiful of experiments have been conducted based on numerical examples with varying LL properties. Besides, we not only implement typical learning and vision applications (e.g., few-shot classification and data hyper-cleaning), but also demonstrate the generalization performance of AIT in more challenging tasks such as neural architecture search and generative adversarial networks.
\end{itemize}
  
\section{A Brief Review of Existing Works}\label{related_works}

%Existing GBMs have to calculate the nested gradient of UL variables with involving hierarchical optimization procedures. We denote $\y^{*}(\x)$ as the Best Response mapping of the follower for a given UL variable $\x$. By embedding $\y^{*}(\x)$ into the simple bilevel problem in Eq.~\eqref{single_reform} as $F\left(\x, \y^*(\x)\right)$, the UL gradient of $\varphi(\x)$ (w.r.t., UL variable $\x$) can be derived by using the chain rule as
%%\begin{equation}\label{nest_gradient}
%%	\frac{\partial \varphi(\mathbf{x})}{\partial \mathbf{x}}=\frac{\partial F\left(\mathbf{x}, \mathbf{y}^*(\mathbf{x})\right)}{\partial \mathbf{x}}+G(\mathbf{x}),
%%\end{equation}
%
%\begin{equation}\label{nest_gradient}
%	\nabla_{\x}\varphi(\mathbf{x})=\nabla_{\x}F\left(\mathbf{x}, \mathbf{y}^*(\mathbf{x})\right)+G(\mathbf{x}),
%\end{equation}
%where $\nabla_{\x}F\left(\mathbf{x}, \mathbf{y}^*(\mathbf{x})\right)$ can be regarded as the direct gradient, and $G(\x)=\left(\nabla_{\x} \mathbf{y}^*(\mathbf{x})\right)^{\top} \nabla_{\y} F\left(\mathbf{x}, \mathbf{y}^*(\mathbf{x})\right)$ can be regarded as the indirect gradient. On top of that, recently proposed GBMs investigate various techniques~\cite{liu2020investigating} differing in the strategies of accessing $G(\x)$  and UL gradients. %so as to update $\x$. %with $\frac{\partial \varphi(\mathbf{x})}{\partial \mathbf{x}}$ .

In this work, we first provide a brief review of previous works to conclude the general gradient-based BLO scheme, and then we discuss the deficiencies of existing LL iterative trajectory, which have limited the application of existing GBMs to more challenging BLO scenarios.  

As mentioned before, existing GBMs have explored different heuristic techniques to calculate the hyper-gradient (i.e., $\nabla_{\x}\varphi(\mathbf{x})$) with designed approximation operations. In one of the most representative class of GBMs~\cite{maclaurin2015gradient,franceschi2018bilevel,liu2022general}, it first constructs dynamical system to track the optimization path of LL variables, and then explicitly calculates the indirect gradient with respect to UL variables based on ITerative Differentiation (ITD). Typically, RHG and FHG~\cite{maclaurin2015gradient,franceschi2018bilevel} are proposed, in which $\y^{*}(\x)$ and thus $\varphi(\x)$ are approximated by finite iterative optimization steps, and then the obtained approximated optimization problems are solved. Whereas, both methods suffer from the huge time and space complexity of calculating indirect gradient along the whole iterative trajectory with AD. Then Shanban et al.~\cite{shaban2019truncated} proposed T-RHG to manually truncate the backpropagation path, thus release the computation burden. For these methods, the iterative dynamics mapping $\mathcal{T}_{k+1}(\x,\cdot)$ used to construct iterative trajectory is specified as the projected gradient descent. Whereas, the convergence analysis of these methods all require the LL subproblem to be strongly convex, which severely restrict the application scenarios. Recently, Liu et al.~\cite{liu2022general} proposed BDA, which aggregates the gradient information of both UL and LL subproblems to construct new $\mathcal{T}_{k+1}(\x,\cdot)$ to approximate $\y^{*}(\x)$ and $\varphi(\x)$, thus successfully overcomes the LLS restriction issue.  When calculating the nested hyper-gradient with ITD based on different forms of $\mathcal{T}_{k+1}(\x,\cdot)$, the gradient-based BLO scheme could be summarized in Alg.~\ref{alg:innerloop}, where $\varphi_{K}(\x)= F(\x,\y_{K}(\x))$. It can be observed that the iterative update of UL variables to solve the approximated subproblem (i.e., $\varphi(\x)$) relies on effective iterative trajectory for hyper-gradient calculation (Step~\ref{inner_loop1}-\ref{inner_loop3}).

\begin{algorithm}[h]
	\caption{Gradient-Based BLO Scheme}\label{alg:innerloop}
	\begin{algorithmic}[1]
		%\REQUIRE Current UL variable $\x^t$ .
		%\ENSURE  $\y_K(\x^t,\z^t)$
		\REQUIRE UL iteration $T$ and LL iteration $K$.  
		\STATE Initialize $\x^0$.
		\FOR {$t=0 \rightarrow T-1$}
		\STATE Initialize $\y_0$.
		\FOR {$k=0 \rightarrow K-1$}\label{inner_loop1}
		\STATE \% Update $\y_k$ with $\x^t$.
		\STATE $\y_{k+1}(\x^t)= \mathcal{T}_{k+1}\left(\mathbf{x}^t, \mathbf{y}_{k}(\x^t)\right)$.\label{inner_loop3}
		\ENDFOR
		%\STATE 
		\STATE \% Update $\x^t$ with $\y_{K}(\x^t)$ based on ITD.
		\STATE $\x^{t+1}=\mathtt{Proj}_{\X}(\x^{t}-\alpha_{\x}\nabla_{\x}\varphi_{K}(\x^t) )$. \label{indirect_gradient}
		%		\STATE $\x^{t+1}=\mathcal{P}_{\X}(\x^{t}, F(\x^{t},\y_{K}(\x^{t}))$. \label{indirect_gradient}
		%\STATE $\x^{t+1}=\mathcal{P}_{\X}(\x^{t}, \varphi_{K}(\x^t)))$. \label{indirect_gradient}
		\ENDFOR
	\end{algorithmic}
\end{algorithm}

Since most ITD-based approaches only established their convergence theory based on the LLS restriction, they neither pay attention to the initialization of iterative trajectory nor take serious consideration of how to choose the iterative trajectory for hyper-gradient calculation. Whereas, an improper initialization position chosen for LL variables may slow down the convergence of LL and UL subproblem. More importantly, when multiple solutions exist in $\mathcal{S}(\x)$ (i.e., without LLS), the initialization has significant influence on the UL convergence behavior, so there is no guarantee that the iterative trajectory constructed based on the chosen $\y_{0}(\x)$ provides iterates optimizing the UL objective while converging to $\mathcal{S}(\x)$. Furthermore, suppose that the LLC assumption is not satisfied, the subsequences of the whole iterative trajectory (i.e., $\mathcal{T}_{0:K}$) no longer have consistent convergence behavior as in the LLC case. On this basis, using the whole iterative trajectory for hyper-gradient calculation may lead to the oscillation or divergence of the approximated UL subproblem. Overall, the vanilla iterative trajectory adopted by ITD-based approaches has limited flexibility and becomes the bottleneck of existing gradient-based BLO scheme to cover more challenging scenarios. Though several researches have explored potential techniques, such as aggregating LL and UL gradient information to design new $\mathcal{T}_{k}(\x,\cdot)$ to construct a good approximated BLO problem in Eq.~\eqref{single_re_reform} and successfully relax the theoretical restrictions on LL subproblem to some extent, the situation where the LLC assumption does not hold still needs to be considered.


In contrast to the ITD-based approaches which compute the hyper-gradient based on the constructed LL iterative trajectories, another branch of the methods~\cite{pedregosa2016hyperparameter,rajeswaran2019meta,lorraine2020optimizing} instead adopts the implicit function theorem and derives the hyper-gradient of UL variables by solving a linear system. Whereas, computing Hessian matrix and its inverse are much more expensive and challenging especially when ill-conditioned linear system appears. Besides, these methods based on Approximated Implicit Differentiation (AID) require
the LL subproblem to be strongly convex, which limits
the application scenarios to a great extent.  Another line of work~\cite{LiuLYZZ21} addresses the nonconvex issue by constructing value-function-based smooth approximation problems, while extra assumptions introduced on the constrained LL subproblems still remain cumbersome to handle. As for other recent efforts~\cite{ji2020provably,chen2022single} which have designed specific update formats of UL or LL variables to derive new convergence rate analysis, Hong et al.~\cite{hong2020two} proposed TTSA to introduce cheap estimates of gradients, and update the LL and UL variables simultaneously with SGD and projected SGD. In addition, Khanduri et al.~\cite{khanduri2021momentum} proposed the MSTSA algorithm to estimate the hyper-gradient with assisted momentum.  Quan et.al~\cite{xiao2022alternating} proposed two variants of the alternating implicit gradient SGD approach with improved efficiency to solve equality-constrained BLOs. The above methods also build their theoretical analysis for BLOs with strongly-convex LL subproblems. %Then Chen et al.~\cite{chen2022single} proposed STABLE algorithm to design new optimization dynamics for both LL and UL variables, thus better estimate the hyper-gradient in a single-loop manner to improve convergence. Ji et al.~\cite{ji2020provably} proposed deterBiO and stocBiO to estimate the hyper-gradient with finite-time convergence guarantee for both deterministic and stochastic settings.


%In this section, we first provide a brief review of previous works, most of which explore heuristic techniques to calculate the hyper-gradient with designed solution strategies or approximation operators. In one of the most representative class of GBMs~\cite{maclaurin2015gradient,franceschi2018bilevel,liu2022general,nichol2018first}, it first constructs dynamical system to track the optimization path of LL variables, and then explicitly calculates the indirect gradient with respect to UL variables by using Auto Differentiation (AD). Another line of work~\cite{LiuLYZZ21} addresses the nonconvex issue by constructing a series of value-function-based smooth approximation problems, while extra assumptions introduced on the constrained LL subproblems still remain cumbersome to handle.  In the following, we mainly focus on the former class of methods to discuss the iterative trajectory constructed by the general gradient-based BLO scheme.


%As another branch of RHG based methods, Ji et al.~\cite{ji2020provably} proposed deterBiO and stocBiO to estimate the hyper-gradient with finite-time convergence guarantee for both deterministic and stochastic BLOs. Hong et al.~\cite{hong2020two} proposed TTSA to  simultaneously update the LL and UL variables with different step sizes. Then Chen et al.~\cite{chen2022single} proposed STABLE algorithm to design new optimization dynamics for both LL and UL variables, thus better estimate the hyper-gradient in a single-loop manner to improve convergence. Besides, Khanduri et al.~\cite{khanduri2021momentum} proposed the MSTSA algorithm to estimate the hyper-gradient with assisted momentum.
%as
%$\T_{k+1}\left(\x,\y_k(\mathbf{x})\right) = \mathtt{Proj}_{\Y} \left( \y_k(\mathbf{x}) -\left( \mu \alpha_k\mathbf{d}^{{F}}_k(\mathbf{x})+(1-\mu)\beta_k\mathbf{d}^{{f}}_k(\mathbf{x})\right) \right),$
%where $\mathbf{d}^{{F}}_k(\mathbf{x}) =s_u\nabla_{\mathbf{y}} F(\mathbf{x}, \mathbf{y}_{k}(\mathbf{x}))$ and $ \mathbf{d}^{{f}}_k(\mathbf{x}) =s_l\nabla_{\mathbf{y}} f(\mathbf{x},\mathbf{y}_{k}(\mathbf{x}))$ denote the gradient directions of UL and LL objective, respectively, $s_u$, $s_l$ denote the corresponding step size parameters, $\mu \in (0,1)$ and $\alpha_k,\beta_k\in(0,1]$ are the aggregation parameters
%$
%\mathcal{T}_{k+1}(\x,\y_k(\x))= \mathtt{Proj}_{\Y}(\y_{k}(\x)-\alpha_{\y}^{k} \nabla_{\y}f(\x,\y_k(\x))), \nonumber
%$
%where $\alpha^{k}_{\y}$ is a sequence of step sizes for $\y_{k}(\x)$, and  $\mathtt{Proj}_{\Y}(\cdot)$ denotes the projected operator onto $\Y$.

%Liu et al. proposed to only update the LL variables once to construct $\mathtt{Traj}_{0:1}$ and approximated the indirect gradient with finite difference to reduce the complexity, then a large scale of high-dimension BLO applications are promising to be handled, but there is still a lack of theoretical investigation and high performance.



\begin{table}[hbtp]
	\centering
	\caption{We report the LL assumptions required by the mainstream GBMs to derive their convergence results, the technique to compute $\nabla_{\x}\varphi(\mathbf{x})$ and whether they are compatible with the accelerated technique (i.e., A.).  Note that w/ and w/o are abbreviations for with and without, respectively. } 
	\label{tab_conditions}
	\renewcommand\arraystretch{1.4}
	\setlength{\tabcolsep}{1.1mm}{
		%\vspace {-0.3cm}
		\begin{tabular}{|c|c|c|c|c|}
			\hline
			Method & $\nabla_{\x}\varphi(\mathbf{x})$
			%& \textbf{LLS}
			& {w/o LLS} & {w/o LLC}& {w/ A. } \\			
			\hline
			RHG/FHG &\multirow{3}{*}{ITD}& \XSolidBrush& \XSolidBrush & \XSolidBrush\\
			%\cline{1-4}
			
			T-RHG && \XSolidBrush &\XSolidBrush & \XSolidBrush \\
			%\cline{1-4}
			%\cline{1-4}
			BDA	&&\CheckmarkBold &\XSolidBrush & \XSolidBrush\\
			\hline
			CG&\multirow{2}{*}{AID} & \XSolidBrush& \XSolidBrush & \XSolidBrush\\
			Neumann&& \XSolidBrush& \XSolidBrush & \XSolidBrush\\
			%\hline
			%BVFIM				& \CheckmarkBold & \CheckmarkBold & \XSolidBrush\\
			\hline
			AIT	&ITD& \CheckmarkBold & \CheckmarkBold & \CheckmarkBold\\
			\hline
			
		\end{tabular}
	}
\end{table}

In Tab.~\ref{tab_conditions}, we compare the required LL assumptions of mainstream GBMs to build their convergence analysis and whether they support the acceleration technique. Based on the above analysis of gradient-based BLO scheme for ITD-based approaches, in the next section, we construct our AIT framework to address the theoretical issues and handle more challenging BLO scenarios. As it is shown, AIT not only derives similar convergence results without the LLS and LLC restriction, but also supports more flexible iterative mapping schemes including the acceleration techniques.


%Based on the IT constructed with different $\mathcal{T}_k(\x,\cdot)$, the gradient-based BLO scheme can be summarized in Alg.~\ref{alg:innerloop} based on Eq.~\eqref{single_re_reform}. Here we point out three key elements for constructing IT (step~\ref{inner_loop1} to step~\ref{inner_loop3}), including the format of $\mathcal{T}_k(\x,\cdot)$, the initialization value (i.e., $\y_{0}(\x)$) and the trajectory length (i.e., fixed $K$). When observing Alg.~\ref{alg:innerloop} from a more comprehensive perspective, existing GBMs empirically choose $\y_{0}(\x)$, and construct approximation problem by using the last iterate $\y_K(\x)$ obtained from the optimization dynamics based on $\mathcal{T}_k(\x,\cdot)$. However, in the case where the LL subrpoblem fails to satisfy LLC assumption, there is no guarantee that the last iterate $\y_K(\x)$ obtained in this way uniformly converges to LL subproblem solution set w.r.t. $\x\in\mathcal{X}$, i.e.,
%$\nabla_{\mathbf{y}} f\left(\mathbf{x}, \mathbf{y}_{K}(\mathbf{x})\right)$ uniformly converges to zero w.r.t. $\x\in\mathcal{X}$, thus just using $\y_K(\x)$ to calculate the nested hyper-gradient may be insufficient. Therefore, the vanilla LL IT adopted by most GBMs has limited flexibility and becomes the bottleneck of existing gradient-based BLO scheme to some extent. 

%Overall, though several researches have explored potential techniques, such as aggregating UL and LL gradient information to construct a good approximated BLO problem in Eq.~\eqref{single_re_reform} to successfully relax the theoretical restrictions on LL subproblem to some extent, the situation where the LLC assumption does not hold still needs to be considered.  As one of the key contributions, we expand the scope of available theoretical constraints and introduce the following augmentation techniques to construct augmented OT and handle different challenging BLO scenarios. 
%It is worth noting that OT reflects the discrete path of LL variables to find $\y_K(\x)$ for the hyper-gradient calculation (step~\ref{indirect_gradient}), which also contains the most important gradient information during LL optimization (step~\ref{inner_loop1} to step~\ref{inner_loop3})


%

%To approximate $\y^*(\x)$ with $\y_{k}$ after $K-1$ gradient descent steps, we denote the descent directions of UL and LL objectives as:
%\begin{equation}\label{UL_LL_descent}
%\begin{aligned}
%&\mathbf{d}_{k}^{F}(\mathbf{x})=s_{u} \nabla_{\mathbf{y}} F\left(\mathbf{x}, \mathbf{y}_{k}(\mathbf{x})\right), \\
%&\mathbf{d}_{k}^{f}(\mathbf{x})=s_{l} \nabla_{\mathbf{y}} f\left(\mathbf{x}, \mathbf{y}_{k}(\mathbf{x})\right),
%\end{aligned}
%\end{equation}
%where $s_{u}$ and $s_{l}$ denotes the step sizes of UL and LL gradient respectively. Then the commonly used schematic $\mathcal{T}_{k}$ for gradient based BLO methods (i.e., RHG~\cite{franceschi2017forward}) can be written as:
%\begin{equation}\label{BDA_iteration}
%	\begin{aligned}
%		&\mathcal{T}_{k+1}(\x,\y_k(\x)) \\
%		&=\operatorname{Proj}_{\mathcal{Y}}\left(\mathbf{y}_{k}(\mathbf{x})-\left(\mu \alpha_{k} \mathbf{d}_{k}^{F}(\mathbf{x})+(1-\mu)\mathbf{d}_{k}^{f}(\mathbf{x})\right)\right),
%	\end{aligned}
%\end{equation}%\operatorname{Proj}_{\mathcal{Y}}\left(  
%%, $\mathtt{Proj}$ denotes the projected gradient descent operation
%where $\alpha^{k}_{\y}$ is a sequence of step sizes for $\y_{k}$, $\mu\in(0,~1)$ and $\alpha_{k}\in(0,1]$ are coefficients for aggregation operation. 
\section{Augmented Iterative Trajectory (AIT)}\label{IAPTT}
Based on the prior analysis of iterative trajectory, to relax the theoretical restriction and improve the efficiency of the gradient-based BLO scheme, we first introduce the initialization auxiliary augmentation technique, which introduces a new auxiliary variable to the initialization of iterative trajectory and then optimize it together with the UL variables. Then we further investigate different extension strategies related to the initialization auxiliary augmentation technique, including prior regularization and acceleration dynamics to construct the Augmented Iterative Trajectory (AIT) for BLOs when LLC assumption is satisfied. To make the gradient-based BLO scheme be workable on BLOs without LLC, we further propose the pessimistic trajectory truncation augmentation technique to dynamically adjust the iterative trajectory for hyper-gradient calculation. Together with the  initialization auxiliary, we construct the AIT for solving BLOs with non-convex follower.

%
%we incrementally introduce two significant techniques, i.e., Initialization Auxiliary and Pessimistic Trajectory Truncation, and investigate a series of extension strategies, including prior regularization  and acceleration dynamics to construct our augmented bilevel gradient flow for convex and nonconvex cases.   

%With the proposed augmentation techniques, i.e., IA and PTT and a series of extension strategies, i.e., PIA and AIA, we finally construct our augmented bi-level gradient flow. In this subsection, we will discuss the specific forms of IAPTT gradient flow and illustrate the algorithm templates according to the theoretical investigation based on different LL subproblem properties. 
\subsection{ BLOs with Convex LL Subproblem}\label{IA}

Typically speaking, the initialization of iterative trajectory, i.e., $\y_{0}(\x)$, is usually chosen based on a fixed manually (randomly or by some specific strategies) set initial value of LL variable, which takes no consideration of the convergence behavior of UL subproblem. As it is mentioned before, when there exist multiple elements in LL subproblem solution set $\mathcal{S}(\mathbf{x})$, performing projected gradient descent steps (i.e., $\mathcal{T}_{k}(\x,\cdot)$ adopted by most GBMs)  to construct iterative trajectory with improper initial value $\y_0(\x)$ usually not necessarily optimizes the UL objective while converging to $\mathcal{S}(\x)$. Besides, an improper initialization position for $\mathcal{T}_{0:K}$ will also slow down the convergence rate of LL subproblem, even when $\mathcal{S}_{\x}$ is a singleton. 

To address the issues mentioned above, we suggest to introduce an Initialization Auxiliary (IA) variable $\z$ as the initialization position of LL variable to  construct $\mathcal{T}_{0:K}$ for approximating LL subproblem as follows,
\begin{equation}\label{yk_IA}
   	\begin{aligned}
   		&\y_0(\x,\z) = \z,   \quad\mathbf{y}_{k+1}(\x,\z)=\mathcal{T}_{k+1}\left(\mathbf{x}, \mathbf{y}_{k}(\x,\z)\right),
   	\end{aligned}
\end{equation} 
which leads to the following approximation problem of Eq.~\eqref{single_reform}: $
	\min_{\x \in \X, \z \in \Y} \varphi_{K}(\x,\z):= F(\x,\y_{K}(\x,\z)).$
It is worth noting that, the iterative trajectory constructed based on this optimization dynamics formulates the approximation $\y_K(\x,\z)$ parameterized by $\x$ and $\z$.  By this form, we avoid fixing initialization position chosen with empirical strategies, and update the initialization auxiliary $\z$ together with $\x$ to continuously search for the best initial points  of LL variables to calculate $\y_K(\x,\z)$. By taking into consideration of the convergence behavior of UL subproblem, $\mathcal{T}_{k}(\x,\cdot)$ with updated initial value can approach solutions to the BLO problem in Eq.~\eqref{blo_problem}. The idea of IA variable $\z$ is first proposed for the convergence theory~\cite{LiuLYZZ21} of non-convex first-order optimization methods. 

%Practically speaking, the introduced IA could continuously optimize the initial value of $\y$ as the UL optimization proceeds. Meanwhile, we notice that the initial state of $\z$ also needs to be specified by some method, such as random initialization. To sequentially guide the optimization of $\z$ regardless of its initial state, we propose to introduce an extra proximal prior regularization term of the initialization auxiliary, which can be denoted as $g(\z)$, %~\footnote{In practice, we could use $\ell_2$ normalization to test the effectiveness of prior regularization .}, 
%then the new form of UL objective for this Penalized IA (PIA) can be defined as 

As mentioned above, the initialization auxiliary variable $\z$ is introduced and optimized simultaneously with UL variable $\x$ for helping the LL subproblem dynamics approach the appropriate $\y^*(\x)$ that minimizes UL objective $F$. To further guide the update of the IA variable $\z$ and thus boost the convergence of the LL subproblem dynamics, we propose to introduce a constraint set $\mathcal{Z}$ and an extra prior regularization term $g(\z)$ to the IA variable $\z$, which leads to the following approximation problem to Eq.~\eqref{single_reform}, 

\begin{equation}\label{IA_g_z}
	\min_{\x \in \X, \z \in \mathcal{Z}} \	\psi_{K}(\x,\z)=\varphi_{K}(\x,\z) + g(\z).
\end{equation}
In practice, $g(\z)$ can be specified as penalty on distance between $\z$ and the prior determined value $\z_p$, where $\z_p$ usually serves as some known state of $\z$ that is very close to the optimal LL variable. As one option for machine learning tasks, we could properly define $\z_p$ as the pretrained weights of the LL variables, and verify its effectiveness with BLO applications.

Another feature of this new approximation format is that the iterative dynamics mapping $\mathcal{T}_{k+1}(\x,\cdot)$ for constructing iterative trajectory can be flexibly specified as different forms proposed in existing works. Here, for general BLOs with convex LL subproblem, we suggest applying the aggregation scheme proposed in BDA~\cite{liu2022general} to construct $\mathcal{T}_{k+1}(\x,\cdot)$  as follows
\begin{equation}\label{eq:improved-lower}
	\begin{aligned}
		&\T_{k+1}\left(\x,\y_k(\mathbf{x},\z)\right) \\
		= &\mathtt{Proj}_{\Y} \left( \y_k(\mathbf{x},\z) -\left( \mu \alpha_k\mathbf{d}^{{F}}_k(\mathbf{x},\z)+(1-\mu)\beta_k\mathbf{d}^{{f}}_k(\mathbf{x},\z)\right) \right),
	\end{aligned}
\end{equation}
where $\mathbf{d}^{{F}}_k(\mathbf{x},\z) =s_u\nabla_{\mathbf{y}} F(\mathbf{x}, \mathbf{y}_{k}(\mathbf{x},\z))$ and $ \mathbf{d}^{{f}}_k(\mathbf{x},\z) =s_l\nabla_{\mathbf{y}} f(\mathbf{x},\mathbf{y}_{k}(\mathbf{x},\z))$ denote the gradient directions of UL and LL objective with introduced IA, respectively.

Specially, for the case where the LLS condition is satisfied, following the vanilla update format in RHG, $\mathcal{T}_{k+1}\left(\mathbf{x}, \cdot \right)$ could be simply chosen as
\begin{equation}\label{yk_def}
	\begin{aligned}
		\mathcal{T}_{k+1}\left(\mathbf{x}, \mathbf{y}_{k}(\x,\z)\right)= \mathtt{Proj}_{\Y} ( \y_k(\x,\z)- \alpha_{\y}^k\nabla_{\y}f(\x,\y_k(\x,\z)) ),
%	\T_{k+1}\left(\x,\y_k(\mathbf{x},\z)\right) = \mathtt{Proj}_{\Y}\left( \y_k(\mathbf{x},\z) - \alpha\nabla_{\mathbf{y}} f(\mathbf{x},\mathbf{y}_{k}(\mathbf{x},\z)) \right),	
\end{aligned}
\end{equation}
where $\alpha_{\y}^k$ denotes the step size parameter. By this means, embedding the IA technique still helps optimize the initialization to construct the iterative trajectory, thus further improves the convergence behavior of BLOs under LLS assumption. 

Besides, our new scheme with IA technique also supports to consistently improve the existing methods with embedded acceleration dynamics. As one of the practical implementation, we could embed the Nesterov's acceleration methods~\cite{beck2009fast} with our IA technique, which has been widely used for convex optimization problem to accelerate the convergence of gradient descent, then we obtain the accelerated version as 
\begin{equation}\label{yk_def2}
	\begin{cases}
	\begin{aligned}
		&\y_0(\x,\z) = \z, \quad t_0 =1, \quad  t_{k+1} = {\left(1+\sqrt{1+4t_{k}^2} \right)}/{2},  \\
		& \u^{k+1}(\x,\z) = \y^{k+1}(\x,\z) + \left(\frac{t_{k}-1}{{t_{k+1}}}\right)(\y^{k+1}(\x,\z) - \y^{k}(\x,\z)),\\
		& \y_{k+1}(\x,\z) = \mathtt{Proj}_\Y \left( \u^{k}(\x,\z) - \alpha \nabla_{\y} f(\x,\u^{k}(\x,\z)) \right),\\
		& \T_{k+1}\left(\x,\y_k(\mathbf{x},\z)\right)  =  \y_{k+1}(\x,\z), \\
	\end{aligned}
\end{cases}
\end{equation}
where $\alpha$ denotes the step size parameter.  

\begin{algorithm}[h]
	\caption{The Proposed $\textrm{AIT}_{C}$ Algorithm}\label{alg:AIT-C}
	\begin{algorithmic}[1]
		%\REQUIRE Current UL variable $\x^t$ .
		%\ENSURE  $\y_K(\x^t,\z^t)$
		\REQUIRE UL iteration $T$, LL iteration $K$.  
		\STATE Initialize $\x^0$ and $\z^0$.
		\FOR {$t=0 \rightarrow T-1$}
		\STATE $\y_0=\z^t$.
		\FOR {$k=0 \rightarrow K-1$}
		\STATE \% Iterative dynamics mapping.
		%\STATE $\y_{k+1}=\mathtt{Proj}_{\Y} ( \y_{k}-\alpha^k_{\y} \nabla_{\y}f(\x^t,\y_{k}) )$.
		\STATE $\mathbf{y}_{k+1}(\x^t,\z^t)=\mathcal{T}_{k+1}\left(\mathbf{x}^t, \mathbf{y}_{k}(\x^t,\z^t)\right)$.
		\ENDFOR
		%		\STATE \% Pessimistic Trajectory Truncation.
		%		\STATE $\bar{k}=\arg\max_{k} \{F(\x^t,\y_{k})\}_{k=1}^K$.
		%\STATE 
		\STATE \% Update $\x$ with $\y_{K}(\x^t,\z^t)$
		\STATE $\x^{t+1}=\mathtt{Proj}_{\X}(\x^{t}-\alpha_{\x}\nabla_{\x}\psi_{K}(\x^t,\z^t))$.
		\STATE \% Update $\z$ with $\y_{K}(\x^t,\z^t)$.
		\STATE $\z^{t+1}=\mathtt{Proj}_{\mathcal{Z}}(\z^t-\alpha_{\z}\nabla_{\z}\psi_{K}(\x^t,\z^t))$.
		\ENDFOR
	\end{algorithmic}
\end{algorithm}

% \footnote{$\mathcal{T}_{k+1}(\x,\y_k(\x)) =\mathtt{Proj}_{\Y}(\mathbf{y}_{k}(\mathbf{x})-\left(\mu \alpha_{k} s_{u} \nabla_{\mathbf{y}} F\left(\mathbf{x}, \mathbf{y}_{k}(\mathbf{x})\right)+(1-\mu)s_{l} \nabla_{\mathbf{y}} f\left(\mathbf{x}, \mathbf{y}_{k}(\mathbf{x})\right)\right))$, where $\mu\in(0,~1)$ and $\alpha_{k}\in(0,1]$ are coefficients for aggregation operation.}  
%
In Alg.~\ref{alg:AIT-C}, we illustrate the algorithm of our Augmented Iterative Trajectory for BLOs with Convex LL subproblem ($\textrm{AIT}_{C}$ for short), where $\psi_{K}(\x,\z)=F(\x,\y_{K}(\x,\z)) + g(\z)$. Whereas, to make the gradient-based BLO scheme be efficient and convergent for the BLOs with nonconvex LL subproblem, the proposed IA technique is not enough. In the next part, we will propose another augmentation technique named Pessimistic Trajectory Truncation, and discuss how to use this new technique together with IA to derive a new gradient-based BLO algorithm that is convergent and efficient for the BLOs with nonconvex LL subproblem. The detailed convergence analysis could be found in the next section.

%To consider weaker assumptions of LL subproblems, i.e., the LL nonconvex scenario, we further embed the iterative formats of $\y_{k}(\x,\z)$ into $\max_{1\le k \le K} \left\lbrace F(\x,\y_{k}(\x,\z))\right\rbrace$ , which can be regarded as Pessimistic Trajectory Truncation (PTT) operation of the UL objective to some extent, thus further remove the LLC assumption. Detailed investigations of IA and extension techniques can be found in the next section.   

%Considering that when the LL subproblem has convex property, $\mathcal{R}_{\alpha}(\x,\y_K(\x,\z))$ may uniformly converge to zero w.r.t. $\z$ and UL variable $\x$, then $\bar{k}$ can be simply taken as $K$, and the approximation form $\mathcal{R}_{\alpha}(\x, \y_{\bar{k}} (\x, \z))$ in Eq.~\eqref{single_re_reform} can be simplified as $F(\x,\y_K(\x,\z))$.


\subsection{BLOs with Non-convex LL Subproblem}\label{PTT}

As another important issue of the existing gradient-based BLO scheme, they used to select the whole iterative trajectory (i.e., $\mathcal{T}_{0:K}$) to perform the hyper-gradient calculation. When the LL subproblem is nonconvex, the subsequences of $\mathcal{T}_{0:K}$ show no consistent convergence behavior as in the LLC case, even the initialization is continuously optimized by the IA technique. Therefore, directly using $\mathcal{T}_{0:K}$ results in improper approximation of $F(\x,\y_{K}(\x))$, and $\nabla_{\mathbf{y}} f\left(\mathbf{x}, \mathbf{y}_{K}(\mathbf{x})\right)$ may not uniformly converge to zero w.r.t. $\x\in\mathcal{X}$ while $F(\x,\y_{K}(\x))$ converges to the real BLO objective $\varphi(\x)$. In short, this empirical strategy for constructing $\mathcal{T}_{0:K}$ actually invalidates the convergence and may result in oscillation even divergence of the optimization process in the nonconvex case.

Based on the constructed approximation formats in Eq.~\eqref{yk_IA}, we introduce another significant technique, i.e., Pessimistic Trajectory Truncation (PTT) to extend the application scenarios and derive new convergence results without requiring LLC assumption. Note that the idea of PTT operation is inspired by the convergence result of the projected gradient method on nonconvex optimization problem. We define $\mathcal{R}_{\alpha}(\x,\y): = \y - \mathtt{Proj}_{\Y} \left(\y - \alpha \nabla_{\y}f(\x,\y) \right)$ as the proximal gradient residual mapping to measure the optimality of LL subproblem. When the LL subproblem is nonconvex, $\mathcal{R}_{\alpha}(\x,\y)$ may not uniformly converge to the LL subproblem solution set w.r.t. $\x$ and $\z$. Therefore, directly embedding $\y_{K}(\x, \z)$ into the UL objective $F(\x, \y)$ may not necessarily provide a proper approximation strategy as mentioned before. Fortunately, it is well understood that as $K$ tends to infinity, $\min_{0 \le k \le K} \|  \mathcal{R}_{\alpha} (\x,\y_{k}(\x,\z)) \| $ uniformly converges to zero w.r.t. $\x$ and $\z$. 

Whereas, it still remains to be impractical to explicitly select $i(K) := \arg\min_{0 \le k \le K} \|  \mathcal{R}_{\alpha} (\x,\y_{k}(\x,\z)) \| $ for using $\y_{i(K)}(\x,\z)$ to construct an approximation. Therefore, we choose to minimize the worst case of ${\y_{i(K)}(\x,\z)}$ in terms of the UL objective values in a compromise, i.e., $\phi_{\bar{K}}(\x,\z):= \max_{1\le k \le K} \left\lbrace F(\x,\y_{k}(\x,\z)) \right\rbrace$, to guarantee the convergence of $\mathcal{R}_{\alpha} (\x,\y_{k}(\x,\z))$ no matter how this $i(K)$  is chosen. The theoretical convergence guarantee for the above approximation is organized in Section~\ref{Theoretical_Analysis}. Practically speaking, the varying $\bar{K}$ actually considers the behavior of UL objectives during the LL optimization to truncate the whole iterative trajectory. In this case, the $\mathcal{T}_{0:\bar{K}}$ is more reasonable to represent the whole trajectory for hyper-gradient calculation, which can not be directly reflected by using fixed $K$ without PTT operation. 

By introducing both IA and PTT operation, our new algorithm avoids directly using the oscillating iterative trajectory of LL variables for hyper-gradient calculation, and successfully removes the LLC assumption to handle non-convex scenarios in various real-world applications. In addition, the PTT operation always leads to a small $\bar{K} := \arg\max_{1\le k \le K} \left\lbrace F(\x,\y_{k}(\x,\z)) \right\rbrace$, thus effectively shortens the path to compute the indirect hyper-gradient through backpropagation, which saves the computational cost in practice. We also conduct the running time analysis based on the nonconvex numerical example to confirm this conclusion numerically. %Besides, it is worth noting that when the LLC property can not hold, the aggregated operation in BDA is not supported theoretically.
%Based on two augmentation techniques, we could derive the complete $S_{\textrm{AIT}}$ with IA and PTT as 
%\begin{equation}
%	S_{\textrm{AIT}}=\{\y_0(\x,\z), \mathcal{T}_{1}\left(\mathbf{x}, \mathbf{y}_{0}(\x,\z)\right), \dots, \mathcal{T}_{\bar{k}}\left(\mathbf{x}, \mathbf{y}_{\bar{k}-1}(\x,\z)\right)\}.\nonumber
%\end{equation}

Note that the iterative mapping scheme $\mathcal{T}_{k+1}\left(\mathbf{x}, \mathbf{y}_{k}(\x,\z)\right)$ can be chosen as the projected gradient method in Eq.~\eqref{yk_def}. Besides, we also investigate available accelerated gradient scheme~\cite{ghadimi2016accelerated} to improve the efficiency for this non-covnex case, which is given as follows
\begin{equation}\label{yk_def3}
	\begin{cases}
	\begin{aligned}
		& \u_{0}(\x,\z) = \v_{0}(\x,\z) = \z,   \\
		& \y_{k+1}(\x,\z) = (1-\alpha_k)\u_{k}(\x,\z) + \alpha_k \v_{k}(\x,\z), \\
		& \u^{k+1}(\x,\z) = \mathtt{Proj}_\Y \left( \y_{k+1}(\x,\z) - \beta_k \nabla_{\y} f(\x,\y_{k+1}(\x,\z)) \right),\\
		& \v_{k+1}(\x,\z) = \mathtt{Proj}_\Y \left( \v_{k}(\x,\z) - \lambda_k \nabla_{\y} f(\x,\y_{k+1}(\x,\z)) \right),\\
		& \T_{k+1}\left(\x,\y_k(\mathbf{x},\z)\right)  =  \y_{k+1}(\x,\z),
	\end{aligned}
\end{cases}
\end{equation}
where $\alpha_k = \frac{2}{k+1}$, $\beta_k = \frac{1}{2L_f}$ and $\lambda_k = \frac{k\beta_k}{2}$, and $k = 0,\ldots, K-1$. 

\begin{algorithm}[h]
	\caption{The Proposed $\textrm{AIT}_{NC}$ Algorithm}\label{alg:AIT-N}
	\begin{algorithmic}[1]
		%\REQUIRE Current UL variable $\x^t$ .
		%\ENSURE  $\y_K(\x^t,\z^t)$
		\REQUIRE UL iteration $T$, LL iteration $K$.  
		\STATE Initialize $\x^0$ and $\z^0$.
		\FOR {$t=0 \rightarrow T-1$}
		\STATE $\y_0=\z^t$.
		\FOR {$k=0 \rightarrow K-1$}
		\STATE \%  Update $y_k$ with $\x^{t}$ and $\z^{t}$.
		%\STATE $\y_{k+1}=\mathtt{Proj}_{\Y} ( \y_{k}-\alpha^k_{\y} \nabla_{\y}f(\x^t,\y_{k}) )$.
		\STATE $\mathbf{y}_{k+1}(\x^t,\z^t)=\mathcal{T}_{k+1}\left(\mathbf{x}^t, \mathbf{y}_{k}(\x^t,\z^t)\right)$.
		\ENDFOR
		\STATE \% Pessimistic Trajectory Truncation.%\phi_{k}(\x^t,\z^t)
		\STATE $\bar{K}=\arg\max_{1\le k \le K} \{ F(\x,\y_{k}(\x^t,\z^t))  \}$. \label{outer_loop_1}
		\STATE \% Update $\x$ with $\y_{\bar{K}}(\x^t,\z^t)$.
		%\STATE $\phi_{\bar{k}}(\x,\z)= \max_{1\le k \le K} \left\lbrace F(\x,\y_{k}(\x,\z)) \right\rbrace$.
		\STATE  Denote $\phi_{\bar{K}}(\x,\z) = F(\x,\y_{\bar{K}}(\x,\z))$.
		\STATE $\x^{t+1}=\mathtt{Proj}_{\X}(\x^{t}-\alpha_{\x}\nabla_{\x}\phi_{\bar{K}}(\x^t,\z^t))$.\label{outer_loop_2}
		\STATE \% Update $\z$ with $\y_{\bar{K}}(\x^t,\z^t)$.
		%\STATE $\psi_{K}(\x^t,\y_{\bar{k}})=F(\x^t,\y_{\bar{k}}) +\lambda g (\z^t)$.%R\textrm{eg}
		\STATE $\z^{t+1}=\mathtt{Proj}_{\mathcal{Z}}(\z^t-\alpha_{\z}\nabla_{\z}\phi_{\bar{K}}(\x^t,\z^t))$.\label{outer_loop_3}
		\ENDFOR
	\end{algorithmic}
\end{algorithm}

With two proposed augmentation techniques and supported iterative acceleration gradient scheme, the complete algorithm of our AIT for BLOs with Non-convex LL subproblem ($\textrm{AIT}_{NC}$ for short) is illustrated in Alg.~\ref{alg:AIT-N}. %In step $6$, the iterative mapping scheme facilitates the LL optimization process with $\z$, then the IA and UL variable $\x$ are optimized together with truncated trajectory selected by PTT operation in step $9$. 
In the following sections, we will provide the asymptotic convergence analysis of $\textrm{AIT}_{C}$ and $\textrm{AIT}_{NC}$ and further discuss the applicable scenarios of different variations.




%\subsection{Augmented IAPTT Gradient Flow}
%%
%
%With the proposed augmentation techniques, i.e., IA and PTT and a series of extension strategies, i.e., PIA and AIA, we finally construct our augmented bi-level gradient flow. In this subsection, we will discuss the specific forms of IAPTT gradient flow and illustrate the algorithm templates according to the theoretical investigation based on different LL subproblem properties. 
%
%Considering that when the LL subproblem has convex property, $\mathcal{R}_{\alpha}(\x,\y_K(\x,\z))$ may uniformly converge to zero w.r.t. $\z$ and UL variable $\x$, thus the PTT operation could be successfully removed. Then $\bar{k}$ can be simply taken as $K$, and the approximation form $\mathcal{R}_{\alpha}(\x, \y_{\bar{k}} (\x, \z))$ in Eq.~\eqref{single_re_reform} can be simplified as $F(\x,\y_K(\x,\z))$. In this case, the IA technique can be embedded into the training procedures of classical GBMs, and the iterative mapping scheme supports different formats, including the vanilla version and aggregation version as mentioned in the last subsection. Besides, the prior regularization  and Nesterov's acceleration dynamics also remain available to enhance the optimization process. In Alg.~\ref{alg:AIT-C}, we illustrate the augmented bilevel gradient flow to solve BLOs under LLC assumption.   
%
%\begin{algorithm}[H]
%	\caption{Augmented Optimization Trajectory for Convex BLO}\label{alg:AIT-C}
%	\begin{algorithmic}[1]
%		%\REQUIRE Current UL variable $\x^t$ .
%		%\ENSURE  $\y_K(\x^t,\z^t)$
%		\REQUIRE UL iteration $T$, LL iteration $K$, IA $\z$, coefficient $\lambda$.  
%		\STATE Initialize $\x^0$ and $\z^0$.
%		\FOR {$t=0 \rightarrow T-1$}
%		\STATE $\y_0=\z^t$.
%		\FOR {$k=0 \rightarrow K-1$}
%		\STATE \% Augmented Dynamic Mapping Scheme.
%		%\STATE $\y_{k+1}=\mathtt{Proj}_{\Y} ( \y_{k}-\alpha^k_{\y} \nabla_{\y}f(\x^t,\y_{k}) )$.
%		\STATE $\mathbf{y}_{k+1}(\x^t,\z^t)=\mathcal{T}_{k+1}\left(\mathbf{x}^t, \mathbf{y}_{k}(\x^t,\z^t)\right)$.
%		\ENDFOR
%		%		\STATE \% Pessimistic Trajectory Truncation.
%		%		\STATE $\bar{k}=\arg\max_{k} \{F(\x^t,\y_{k})\}_{k=1}^K$.
%		\STATE \% Update $\x$ with $\y_{K}(\x^t,\z^t)$
%		\STATE $\x^{t+1}=\mathtt{Proj}_{\X}(\x^{t}-\alpha_{\x}\nabla_{\x}F(\x^t,\y_{K}))$.
%		\STATE \% Update $\z$ with $\y_{K(\x^t,\z^t)}$ and $\z_p$.
%		\STATE $\psi_{K}(\x^t,\y_{K})=F(\x^t,\y_{K}) +\lambda g (\z^t)$.%R\textrm{eg}
%		\STATE $\z^{t+1}=\mathtt{Proj}_{\mathcal{Z}}(\z^t-\alpha_{\z}\nabla_{\z}\psi_{K}(\x^t,\y_{K}))$.
%		\ENDFOR
%	\end{algorithmic}
%\end{algorithm}
%
%When it comes to the challenging non-convex scenarios, IA and PTT operations are both required to cover the theoretical convergence analysis, then the complete version to solve the non-convex BLO can be illustrated in Alg.~\ref{alg:AIT-N}. Besides, the  iterative format of $\mathcal{T}_{k+1}\left(\mathbf{x}, \mathbf{y}_{k}(\x,\z)\right)$ for nonconvex BLOs is restricted to be the vanilla format in Eq.~\eqref{yk_def} or supported accelerated gradient scheme ~\cite{ghadimi2016accelerated} as discussed before. In step $6$, the augmented dynamic mapping scheme facilitates the LL optimization process with $\z$, then the IA and UL variable $\x$ are optimized together with truncated trajectory selected by PTT operation in step $9$. In the next section, we provide the convergence analysis of augmented bilevel gradient flow and further discuss the applicable scenarios of extension strategies in the next section. 
%
%\begin{algorithm}[H]
%	\caption{Augmented Optimization Trajectory for Nonconvex BLO}\label{alg:AIT-N}
%	\begin{algorithmic}[1]
%		%\REQUIRE Current UL variable $\x^t$ .
%		%\ENSURE  $\y_K(\x^t,\z^t)$
%		\REQUIRE UL iteration $T$, LL iteration $K$, IA $\z$.  
%		\STATE Initialize $\x^0$ and $\z^0$.
%		\FOR {$t=0 \rightarrow T-1$}
%		\STATE $\y_0=\z^t$.
%		\FOR {$k=0 \rightarrow K-1$}
%		\STATE \% Augmented Dynamic Mapping Scheme.
%		%\STATE $\y_{k+1}=\mathtt{Proj}_{\Y} ( \y_{k}-\alpha^k_{\y} \nabla_{\y}f(\x^t,\y_{k}) )$.
%		\STATE $\mathbf{y}_{k+1}(\x^t,\z^t)=\mathcal{T}_{k+1}\left(\mathbf{x}^t, \mathbf{y}_{k}(\x^t,\z^t)\right)$.
%		\ENDFOR
%		\STATE \% Pessimistic Trajectory Truncation.
%		\STATE $\bar{k}=\arg\max_{k} \{F(\x^t,\y_{k})\}_{k=1}^K$.
%		\STATE \% Update $\x$ with $\y_{\bar{k}}(\x^t,\z^t)$
%		\STATE $\x^{t+1}=\mathtt{Proj}_{\X}(\x^{t}-\alpha_{\x}\nabla_{\x}F(\x^t,\y_{\bar{k}}))$.
%		\STATE \% Update $\z$ with $\y_{\bar{k}(\x^t,\z^t)}$.
%		%\STATE $\psi_{K}(\x^t,\y_{\bar{k}})=F(\x^t,\y_{\bar{k}}) +\lambda g (\z^t)$.%R\textrm{eg}
%		\STATE $\z^{t+1}=\mathtt{Proj}_{\mathcal{Z}}(\z^t-\alpha_{\z}\nabla_{\z}F(\x^t,\y_{\bar{k}}))$.
%		\ENDFOR
%	\end{algorithmic}
%\end{algorithm}


  
%That is to say, we could add $ g(\z)$ and IA for RHG under LLS and BDA under LLC, and they still maintains their original convergence theory.When the LLC even LLS assumption are satisfied, the PTT operation is no longer needed, while IA can still be embedded into the LL optimization process . More detailed theoretical investigations under different cases can be found in the next section. %IAPTT is qualified to combine two generalized dynamic mapping methods introduced before, and uniformly guarantees the convergence property. T	      



\section{Theoretical Analysis}\label{Theoretical_Analysis}
In this section, we present the asymptotic convergence analysis of $\textrm{AIT}_{C}$ in Alg. \ref{alg:AIT-C} and $\textrm{AIT}_{NC}$ in Alg. \ref{alg:AIT-N} under mild conditions on the general schematic iterative module $\mathcal{T}_k(\x,\cdot)$. And
we also show that these conditions on $\mathcal{T}_k(\x,\cdot)$ are satisfied for some specific choices of $\mathcal{T}_k(\x,\cdot)$. Specifically, for convex BLOs, we show the asymptotic convergence of Alg.~\ref{alg:AIT-C} when $\mathcal{T}_k(\x,\cdot)$ is chosen as BDA~\cite{liu2022general} in Eq.\eqref{eq:improved-lower}. And for convex BLOs whose LL solution set is singleton, we show the asymptotic convergence of Algorithm \ref{alg:AIT-C} when $\mathcal{T}_k(\x,\cdot)$ is chosen as projected gradient in Eq.~\eqref{yk_def} and Nesterovs acceleration scheme in Eq.~\eqref{yk_def2}. For nonconvex BLOs, we show the asymptotic convergence of Algorithm \ref{alg:AIT-N} when $\mathcal{T}_k(\x,\cdot)$ is specifically chosen as projected gradient method and accelerated gradient scheme proposed by \cite{ghadimi2016accelerated} in Eq.~\eqref{yk_def3}. %We provide more detailed proofs in the supplementary materials.
%eq:improved-lower}
%In this section, we conduct the convergence analysis of the constructed Augmented Optimization Trajectory for different BLO followers. Based on the augmentation techniques introduced in Section~\ref{IAPTT}, we first analyze the convergence of Augmented Optimization Trajectory and corr	\begin{aligned}esponding variations including prior regularization  and Nesterov's acceleration dynamics with convex follower, then present the theoretical results of the proposed IAPTT OT and the specialized form of  acceleration dynamics for BLOs with non-convex follower. The detailed proofs can be found in the supplementary materials.

\subsection{Convergence Analysis for $\textrm{AIT}_{C}$}

We first derive the asymptotic convergence analysis of Alg.~\ref{alg:AIT-C} for convex BLOs with general schematic iterative module $\mathcal{T}_k(\x,\cdot)$.  Alg.~\ref{alg:AIT-C} can be regarded as the application of projected gradient method on 
the following single-level approximation problem of Eq.~\eqref{blo_problem},

\begin{equation}\label{eq:upper_varphiK}
	\begin{aligned}
		&\min_{\x \in \X, \z \in \mathcal{Z} } ~~  F(\x,\y_K(\x,\z)) + g(\z) \\
		&s.t. ~ \begin{cases}
			 \y_0(\x,\z) = \z, &\\
		                  \y_{k+1}(\mathbf{x},\z) = \mathcal{T}_k(\x,\y_k(\mathbf{x},\z) ),&\end{cases} 
	\end{aligned}
\end{equation}


where $k = 0,\ldots,K-1$, the function $g : \mathbb{R}^m \rightarrow \mathbb{R}$ and the closed set $\mathcal{Z} \subset \mathbb{R}^m$ are the function and compact set that are with prior information on lower level variable $\y$. To show the asymptotic convergence of Alg.~\ref{alg:AIT-C}, i.e., the approximation problem in Eq.~\eqref{eq:upper_varphiK} converges to the original bilevel problem in Eq.~\eqref{blo_problem}, i.e., $\min_{\x \in \X} \varphi(\x)$, we make following mild assumptions on BLOs throughout this subsection.

\begin{asu}\label{assum:convex}We make following standing assumptions throughout this subsection:
	\begin{itemize}
		\item[(1)] $F, \nabla_\y F, f, \nabla_\y f$ are continuous functions on $\X\times\mathbb{R}^m$.
		\item[(2)] $F(\x,\cdot) : \mathbb{R}^m \rightarrow \mathbb{R}$ is $L_F$-smooth, convex and bounded below by $M_0$ for any $\x\in \X$.
		\item[(3)] $f(\x,\cdot) : \mathbb{R}^m \rightarrow \mathbb{R}$ is $L_f$-smooth and convex for any $\x\in \X$. $f(\x,\y)$ is level-bounded in $\y$ uniformly in $\x\in\X$
		\item[(4)] $\X$, $\Y$ and $ \mathcal{Z}$ are compact sets, and $\Y$ is a convex set.
		\item[(5)] $\hat{\S}(\x) := \mathrm{argmin}_{\y } \{F(\x,\y), \ s.t. \ \y \in \Y \cap \S(\x) \} $ is nonempty for all $\x \in \X$.
		\item[(6)] $g(\z)$ is continuous on $\mathcal{Z}$.
	\end{itemize}
\end{asu}

Assumption \ref{assum:convex} is standard for convex BLOs in the related literature, which is satisfied for the convex BLO numerical example given in Section~\ref{numerical_results}.
Before presenting the convergence result, we recall the auxiliary function $ \varphi_K(\x, \z) = F(\x,\y_K(\x,\z))$, and rewrite the approximation problem in Eq.~\eqref{eq:upper_varphiK} into the following compact form, 
\begin{equation}\label{eq:proximal_prior}
	\min_{\mathbf{x}\in\X, \z \in \mathcal{Z}} \psi_K(\x,\z) = \varphi_K(\x, \z) + g(\z).
\end{equation}

We propose following two essential properties for general schematic iterative module $\mathcal{T}_k(\x,\cdot)$ for the convergence analysis:
\begin{enumerate}
	\item[(1)]\textbf{UL property with IA:} For each $\x \in \mathcal{X}$, $\z \in \mathcal{Z}$,
	\begin{equation*}
		\lim\limits_{K \rightarrow \infty}\varphi_K(\x,\z) \rightarrow \varphi(\x).\label{eq:dist-varphi}
	\end{equation*}
	\item[(2)]\textbf{LL property with IA:} $\{\y_{K}(\x,\z)\}$ is uniformly bounded on $\X \times \mathcal{Z}$, and for any $\epsilon>0$, there exists $k(\epsilon)>0$ such that whenever $K>k(\epsilon)$, 	
	\begin{equation*}
		\sup_{\x \in \X, \z \in \mathcal{Z}}\left\{ f(\x,\y_K(\x,\z)) - f^{\ast}(\x,\z) \right\} \le \epsilon.
	\end{equation*}
\end{enumerate}

Now, we are ready to present the asymptotic convergence result of Alg.~\ref{alg:AIT-C}.
\begin{theorem}\label{thm:general}
	Suppose both the above UL and LL properties with IA hold.
	Let $(\x_K, \z_K)$ be a minimum of the approximation problem in Eq.~\eqref{eq:upper_varphiK}, i.e.,
	\begin{equation*}
		\psi_K(\x_K, \z_K) \le \psi_K(\x, \z), \quad \forall \x \in \X, \z \in \mathcal{Z}.
	\end{equation*}
	Then, any limit point $\bar{x}$ of the sequence $\{x_K\}$ satisfies that $\bar{x}\in\mathrm{argmin}_{x\in X}\varphi(x)$, i.e., $\bar{x}$ is a solution to BLO in Eq.~\eqref{blo_problem}.
\end{theorem}
\begin{proof}
	For any limit point $\bar{\x}$ of the sequence $\{\x_K\}$, let $\{\x_{l}\}$ be a subsequence of $\{\x_K\}$ such that $\x_{l} \rightarrow \bar{\x} \in \X$. As $\{\y_K(\x,\z)\}$ is uniformly bounded on $\X \times \mathcal{Z}$ and $\{\z_K\} \subset \mathcal{Z}$ is bounded, we can further find a subsequence $\{(\x_{m},\z_m)\}$ of $\{(\x_{l},\z_l)\}$ satisfying $\y_m(\x_m,\z_m) \rightarrow \bar{\y}$ and $\z_m \rightarrow \bar{\z}$ for some $\bar{\y}$ and $\bar{\z}$. It follows from the {LL property with IA} that for any $\epsilon > 0$, there exists $M(\epsilon) > 0$ such that for any $m > M(\epsilon)$, we have
	\begin{equation*}
		f(\x_m,\y_m(\x_m,\z_m)) - f^{\ast}(\x_m) \le \epsilon.
	\end{equation*}
	Thanks to the continuity of $f(\x,\y)$, we have that $f^{\ast}(\x):=\min_{\y}f(\x,\y)$ is Upper Semi-Continuous (USC for short) on $\X$ (see, e.g., \cite[Lemma 2]{liu2020generic}). 
	By letting $m \rightarrow \infty$, and since $f$ is continuous and $f^{\ast}(\x)$ is USC on $\X$, we have $f(\bar{\x},\bar{\y}) - f^{\ast}(\bar{\x}) \le \epsilon$. As $\epsilon$ is arbitrarily chosen, we have $f(\bar{\x},\bar{\y}) - f^{\ast}(\bar{\x}) \le 0$ and thus $\bar{\y} \in \S(\bar{\x})$.
	Next, as $F$ is continuous at $(\bar{\x},\bar{\y})$ and g is continuous at $\bar{\z}$, for any $\epsilon > 0$, there exists $M(\epsilon) > 0$ such that for any $m > M(\epsilon)$, it holds
	\begin{equation*}
		F(\bar{\x},\bar{\y}) + g(\bar{\z}) \le F(\x_m,\y_m(\x_m,\z_m)) + g(\z_m) + \epsilon.
	\end{equation*}
	Then, we have, for any $m > M(\epsilon)$ and $\x \in \X$,
	\begin{equation}\label{eq1}
		\begin{aligned}
			\ \varphi(\bar{\x}) + g(\bar{\z}) &= \inf_{\y \in \S(\bar{\x}) } F(\bar{\x}, \y) + g(\bar{\z})\\
			&\le F(\bar{\x},\bar{\y}) + g(\bar{\z}) \\
			&\le F(\x_m,\y_m(\x_m,\z_m)) + g(\z_m) + \epsilon \\
			&\le \varphi_m(\x,\z) + g(\z) + \epsilon.\quad\quad
		\end{aligned}
	\end{equation}
	Taking $\z = \bar{\z}$, $m \rightarrow \infty$ and by the {UL property with IA}, we have
	\begin{equation*}
		\begin{aligned}
			\varphi(\bar{\x}) \le \lim_{m \rightarrow \infty}\varphi_m(\x,\bar{\z}) + \epsilon = \varphi(\x) + \epsilon, \ \forall \x \in \X.
		\end{aligned}
	\end{equation*}
	By taking $\epsilon \rightarrow 0$, we have $\varphi(\bar{\x}) \le \varphi(\x), \ \forall \x \in \X$ which implies $\bar{\x} \in \arg\min_{\x \in \X} \varphi(\x)$.
\end{proof}

In the above convergence result, we can see that the convergence of Eq.~\eqref{eq:upper_varphiK} to the original bilevel problem in Eq.~\eqref{blo_problem} does not require any restrictive assumptions on $g$ and $\mathcal{Z}$. It means that we can add any prior information into $g$ and $\mathcal{Z}$ to help us speed up the convergence of the method without destroying the convergence of the algorithm.

Next, we show that both the UL and LL properties with IA hold when $\mathcal{T}_k(\x,\cdot)$ is chosen as some specific schemes. Here we provide the asymptotic convergence analysis of Alg.~\ref{alg:AIT-C}, when $\mathcal{T}_k(\x,\cdot)$ is defined as BDA\cite{liu2022general} in Eq.~\eqref{eq:improved-lower}.

\begin{theorem}\label{thm_convergence}
	%Suppose Assumptions~\ref{assum:F}, \ref{convex_assump} are satisfied, $\X$, $\Y$ and $\mathcal{Z}$ are compact, and .
	Let $\{\y_k(\mathbf{x},\z)\}$ be the output generated by \eqref{eq:improved-lower} with
	$s_l \in (0,1/L_f)$, $s_u \in (0,1/L_F)$, $\mu \in (0,1)$, $\alpha_k = \frac{1}{k+1}$, $\beta_k \in [\underline{\beta}, 1]$ with some $\underline{\beta} > 0$, $|\beta_k - \beta_{k-1}| \le \frac{c_\beta}{(k+1)^2}$ with some $c_\beta > 0$,
	then we have that both the LL and UL properties with IA hold. 
\end{theorem}
\begin{proof}
	We can easily obtain the UL property with IA from \cite[Theorem 3]{liu2022general}. Next, since Assumption~\ref{assum:convex} holds, $\X$, $\Y$ and $\mathcal{Z}$ are compact, by using the convergence rate result established in  \cite[Theorem 4]{liu2022general} and the similar arguments in the proof of \cite[Theorem 5]{liu2022general}, it can be shown that there exists $C > 0$ such that for any $\x \in \X$, $\z \in \mathcal{Z}$, we have 
	\[
	f(\x,\y_K(\mathbf{x},\z)) - f^*(\x) \le C\sqrt{\frac{1+\ln K}{K^{\frac{1}{4}}}}.
	\]
	Because $\sqrt{\frac{1+\ln K}{K^{\frac{1}{4}}}} \rightarrow 0$ as $K \rightarrow \infty$, $\{\y_K(\mathbf{x},\z)\} \subset \Y$, and $\Y$ is compact, LL property with IA holds. 
\end{proof}

\subsubsection{Lower-Level Singleton Case}
In this part, we focus on the convex BLOs whose lower-level problem solution set is singleton for any $\x \in \X$. We first consider constructing the iterative module $\mathcal{T}_k(\x,\cdot)$ by projected gradient method as described in Eq.~\eqref{yk_def}.	

\begin{theorem}\label{pg_convergence}
	Suppose $\S(\x)$ is singleton for all $\x \in \X$. Let $\{\y_k(\mathbf{x},\z)\}$ be the output generated by \eqref{yk_def} with
	$\alpha \in (0,1/L_f)$, then we have that both the LL and UL convergence properties with IA hold. 
\end{theorem}
\begin{proof}
	According to \cite[Theorem 10.21]{LiuLYZZ21}, when $f(\x,\cdot)$ is convex and $L_f$-smooth for any $\x\in \X$, and $\alpha \in (0,1/L_f)$, $\{\y_{k}(\x,\z)\}$ satisfies
	\begin{equation}\label{PG_rate}
		\begin{aligned}
			f(\x,\y_K(\x,\z)) - f^{\ast}(\x) &\le  \frac{\mathrm{dist}(\y_0(\x,\z),\S(\x))}{2\alpha K} \\ &= \frac{ \mathrm{dist}(\z, \S(\x))}{2\alpha K},
		\end{aligned}
	\end{equation}
	where $\mathrm{dist}(\z,S(\x))$ denotes the distance from $\z$ to the set $S(\x)$.
	Since $\X$, $\Y$ and $\mathcal{Z}$ are all compact sets, then there exists $M > 0$ such that $\mathrm{dist}(\z,\S(\x)) \le M$ for $(\x,\z) \in \X \times \mathcal{Z}$. Then we can easily obtained that {LL property with IA} holds from  Eq.~\eqref{PG_rate}, $\{\y_K(\mathbf{x},\z)\} \subset \Y$ and $\Y$ is compact. Next, given any $(\x,\z) \in \X \times \mathcal{Z}$, for any limit point $\bar{\y}(\x,\z)$ of sequence $\{\y_k(\x,\z) \}$, we have $f(\x,\bar{\y}(\x,\z)) = f^*(\x)$ and thus $\bar{\y}(\x,\z) \in \S(\x)$ from \eqref{PG_rate}. Therefore, since $\{\y_k(\x,\z) \}$ is bounded and $\S(\x)$ is singleton, we have $\y_k(\x,\z) \rightarrow \S(\x) = \hat{\S}(\x)$ and thus {UL property with IA} holds.
\end{proof}

Next, we consider the iterative module $\mathcal{T}_k(\x,\cdot)$ as the Nesterovs acceleration schemes described in Eq.~\eqref{yk_def2}.

\begin{theorem}
	Suppose $\S(\x)$ is singleton for all $\x \in \X$. Let $\{\y_k(\mathbf{x},\z)\}$ be the output generated by Eq.~\eqref{yk_def2} with
	$\alpha \in (0,1/L_f)$, then we have that both the LL and UL convergence properties with IA hold. 
\end{theorem}
\begin{proof}
	According to \cite[Theorem 10.34]{LiuLYZZ21}, when $f(\x,\cdot)$ is convex and $L_f$-smooth for any $\x\in \X$, and $\alpha  \in (0,1/L_f)$, $\{\y_{k}(\x,\z)\}$ admits the following property,
	\begin{equation}
		\begin{aligned}
			f(\x,\y_K(\x,\z)) - f^{\ast}(\x) &\le  \frac{2\mathrm{dist}(\y_0(\x,\z),\S(\x))}{\alpha(K+1)^2} \\
			&= \frac{2\mathrm{dist}(\z, \S(\x))}{\alpha(K+1)^2}.
		\end{aligned}
	\end{equation}
	Since $\X$, $\Y$ and $\mathcal{Z}$ are compact sets, by using the above inequality and the similar arguments as in the proof of Theorem \ref{pg_convergence}, we can show that both the LL and UL  convergence properties with IA hold.
\end{proof}

\subsection{Convergence Analysis for $\textrm{AIT}_{NC}$}

In this part,  we first conduct the asymptotic convergence analysis of $\textrm{AIT}_{NC}$ in Alg.~\ref{alg:AIT-N} with general schematic iterative module $\mathcal{T}_k$.  Indeed, Alg.~\ref{alg:AIT-N} can be regarded as the application of projected gradient method on the following single-level approximation problem of Eq.~\eqref{blo_problem},
\begin{equation}\label{eq:upper_phiK}
	\begin{aligned}
		&\min_{\x \in \X, \z \in \Y } ~~  \phi_{\bar{K}}(\x,\z) := \max_k \left\lbrace F(\x,\y_{k}(\x,\z))\right\rbrace \\
		&s.t. \begin{cases} \y_0(\x,\z) = \z, &\\
		\y_{k+1}(\mathbf{x},\z) = \mathcal{T}_k(\x,\y_k(\mathbf{x},\z) ), ~~ k = 0,\ldots,K-1.&		\end{cases}
	\end{aligned}
\end{equation}
Then we investigate the convergence of solutions of this approximation problem towards those of the original BLO under following mild assumptions.

%To show the asymptotic convergence of Algorithm \ref{alg:AIT-C}, i.e., the approximation problem  \eqref{eq:upper_varphiK} converges to the original bilevel problem \eqref{blo_problem}, i.e., $\min_{\x \in \X} \varphi(\x)$, we make following mild assumptions on BLOs throughout this subsection.

%In this section, we conduct the convergence analysis of IAPTT for BLOs with non-convex followers. Based on the formulation of BLOs in Eq.~\eqref{single_reform}, with given $K \ge 1$ and defining $\varphi_{K}(\x,\z) := \max_k \left\lbrace F(\x,\y_{k}(\x,\z))\right\rbrace$ with $\{\y_{k}(\x,\z) \}$ defined in Eq.~\eqref{yk_def}, our proposed IAPTT generates sequence $\{(\x^t, \z^t)\}$ for solving the following approximation problem to BLO in Eq.~\eqref{single_reform}, $\min_{\x \in \X, \z \in \Y} \varphi_K(\x, \z)$. Then we further investigate the convergence of solutions of this approximation problem towards those of the original BLO.

\begin{asu}\label{assum1}We make following standing assumptions throughout this subsection:
	\begin{itemize}
		\item[(1)] $F, f, \nabla_\y f$ are continuous functions on $\X\times\mathbb{R}^m$.
		\item[(2)] $f(\x,\cdot) : \mathbb{R}^m \rightarrow \mathbb{R}$ is $L_f$-smooth for any $\x\in \X$.
		\item[(3)] $\X$ and $\Y$ are convex compact sets.
		\item[(4)] $\S(\x)$ is nonempty for any $\x \in \X$.
		\item[(5)] For any $(\bar{\x},\bar{\y})$ minimizing $F(\x,\y)$ over constraints $\x \in \X, \y \in \Y$ and $\y \in \tilde{\S}(\x)$, it holds that $\bar{\y} \in \S(\x)$.
	\end{itemize}
\end{asu}

Note that  $\tilde{\S}(\x)$ denotes the set of LL stationary points, i.e., $\tilde{\S}(\x) = \{\y \in \Y | 0 = \nabla_{\y}f(\x,\y) + \mathcal{N}_{\Y}(\y) \}.$ %It should be noticed that $\y \in \tilde{\S}(\x)$ if and only if $\mathcal{R}_{\alpha}(\x,\y) = 0$. 
Assumption \ref{assum1} is standard in bi-level optimziation related literature, which is satisfied for the numerical example given in Section~\ref{numerical_results}. %\textcolor[rgb]{1.0,0.0,0.0}{The set constraint $\nabla_{\y} f$ is only used to guarantee the completeness of our theoretical analysis. Thus in application scenarios, we can just consider the constraint as an extra large set, so that all the varietals are automatically in this feasible set. In this way, it is natural to ignore the projection operation in practical computations.}

We propose the \textbf{weak LL property with IA} for the asymptotic convergence analysis of Algorithm \ref{alg:AIT-N} with general schematic iterative module $\mathcal{T}_k(\x,\cdot)$. We say that \textbf{weak LL property with IA} is satisfies if $\{\y_{K}(\x,\z)\}$ is uniformly bounded on $\X \times \mathcal{Z}$, and there exists $\alpha > 0$ such that for any $\epsilon>0$, there exists $k(\epsilon)>0$ such that whenever $K>k(\epsilon)$, 	
\begin{equation*}
	\sup_{\x \in \X, \z \in \mathcal{Z}}\left\{ \min_{0 \le k \le K} \|  \mathcal{R}_{\alpha} (\x,\y_{k}(\x,\z)) \| \right\} \le \epsilon,
\end{equation*}
where 
\[
\mathcal{R}_{\alpha}(\x,\y): = \y - \mathtt{Proj}_{\Y} \left(\y - \alpha \nabla_{\y}f(\x,\y) \right).
\]
It should be noticed that $\mathcal{R}_{\alpha}(\x,\y) = 0$ if and only if $\y \in \tilde{\S}(\x)$. 
In the following theorem, we establish the asymptotic convergence of Alg.~\ref{alg:AIT-N} when the weak LL property with IA is satisfied.
\begin{theorem}\label{Thm1}
	Suppose the above weak LL property with IA holds.
	Let $(\x_K, \z_K)$ be a minimum of approximation problem in Eq.~\eqref{eq:upper_phiK}, i.e.,
	\begin{equation*}
		\phi_K(\x_K, \z_K) \le \phi_K(\x, \z), \quad \forall \x \in \X, \z \in \mathcal{Z}.
	\end{equation*}
	Then, any limit point $\bar{x}$ of the sequence $\{x_K\}$ satisfies that $\bar{x}\in\mathrm{argmin}_{x\in X}\varphi(x)$, i.e., $\bar{x}$ is a solution to BLO in Eq.~\eqref{blo_problem}.
\end{theorem}
\begin{proof}%[Proof of Theorem 3.1]
	For any $K > 0$, we define $$i(K) := \mathrm{argmin}_{0 \le k \le K} \| \mathcal{R}_{\alpha}(\x,\y_{k}(\x,\z))\|. $$
	For any limit point $\bar{\x}$ of the sequence $\{\x_K\}$, let $\{\x_{l}\}$ be a subsequence of $\{\x_K\}$ such that $\x_{l} \rightarrow \bar{\x} \in \X$.
	As $\{\y_{i(K)}(\x_K, \z_K)\} \subset \Y$ and $\Y$ is compact, we can find a subsequence $\{\x_{j}\}$ of $\{\x_{l}\}$ satisfying $\y_{i(j)}(\x_j,\z_j) \rightarrow \bar{\y}$ for some $\bar{\y} \in \Y$. It follows from the weak LL convergence property that for any $\epsilon > 0$, there exists $J(\epsilon) > 0$ such that for any $j > J(\epsilon)$, we have
	\[
	\|\mathcal{R}_{{\alpha}}(\x_j,\y_{i(j)}(\x_j,\z_j))\| \le \epsilon.
	\]
	As $\Y$ is a convex compact set, it follows from \cite[Theorem 6.42]{beck2017first} that $\mathtt{Proj}_{\Y}$ is continuous. Combined with the assumed continuity of $\nabla_{\y} f(\x,\y)$, we get that $\mathcal{R}_{\alpha}(\x,\y)$ is continuous.
	Then, by letting $j \rightarrow \infty$, we have
	\[
	\|\mathcal{R}_{{\alpha}}(\bar{\x}, \bar{\y})\| \le \epsilon.
	\]
	As $\epsilon$ is arbitrarily chosen, we have $\|\mathcal{R}_{{\alpha}}(\bar{\x}, \bar{\y})\| \le 0$ and thus $\bar{\y} \in \hat{S}(\bar{\x})$. Then by using the same arguments as in the proof of \cite[Theorem 3.1]{liu2021towards}, we can get the conclusion.
	%	Next, as $F$ is continuous at $(\bar{\x},\bar{\y})$, for any $\epsilon > 0$, there exists $J(\epsilon) > 0$ such that for any $j > J(\epsilon)$, it holds
	%	\[
	%	F(\bar{\x},\bar{\y}) \le F( \x_j,\y_{i(j)}(\x_j,\z_j) ) + \epsilon.
	%	\]
	%	We define $\hat{\varphi}(\x) := \inf_{\y \in \tilde{\S}(\x) } F(\x,\y)$, then for any $j > J(\epsilon)$ and $\x \in \X$,
	%	\begin{equation}\label{eq1}
	%		\begin{aligned}
	%			\hat{\varphi}(\bar{\x}) &= \inf_{\y \in \tilde{\S}(\bar{\x}) } F(\bar{\x}, \y) \\
	%			&\le F(\bar{\x}, \bar{\y}) \\
	%			&\le F(\x_j,\y_{i(j)}(\x_j,\z_j)) + \epsilon \\
	%			&\le \max_{1 \le k \le j} F(\x_j,\y_k (\x_j,\z_j)) + \epsilon \\
	%			& = \varphi_j(\x_j,\z_j) + \epsilon \\
	%			&\le \hat{\varphi}(\x) + \epsilon,
	%		\end{aligned}
	%	\end{equation}
	%	where the lase inequality follows from \cite[Lemma 3.2]{nips}. By taking $\epsilon \rightarrow 0$, we have
	%	\begin{equation*}
	%		\hat{\varphi}(\bar{\x}) \le  F(\bar{\x}, \bar{\y}) \le \hat{\varphi}(\x), \quad \forall \x \in \X,
	%	\end{equation*}
	%	which implies $\bar{\x} \in \arg\min_{\x \in \X} \hat{\varphi}(\x)$ and $(\bar{\x},\bar{\y}) \in \mathrm{argmin}_{\x \in \X, \y \in \Y} F(\x,\y), \ s.t. \ \y \in \tilde{\S}(\x)$. By Assumption \ref{assum1}(5), we have $\bar{\y} \in \S(\x)$ and thus $\hat{\varphi}(\bar{\x}) \ge \varphi(\bar{\x})$. Next, since $\tilde{\S}(\x) \supset \S(\x)$, then $\hat{\varphi}(\x) \le \varphi(\x)$ for any $\x \in \X$. Thus we have $\inf_{\x \in \X} \hat{\varphi}(\x) =  \inf_{\x \in \X} \varphi(\x)$ and $\bar{\x} \in \arg\min_{\x \in \X} \varphi(\x)$.
\end{proof}

Next, we will show that when $\mathcal{T}_k$ is chosen as the classical projected gradient method and the accelerated gradient scheme proposed by \cite{ghadimi2016accelerated} in Eq.~\eqref{yk_def3}, the \textbf{weak LL property with IA} is satisfied.
We first consider constructing the iterative module $\mathcal{T}_k(\x,\cdot)$ by the classical projected gradient method as,
\begin{equation}\label{PG2}
	\T_{k+1}\left(\x,\y_k(\mathbf{x},\z)\right) = \mathtt{Proj}_{\Y}\left( \y_k(\mathbf{x},\z) - \alpha\nabla_{\mathbf{y}} f(\mathbf{x},\mathbf{y}_{k}(\mathbf{x},\z)) \right),
\end{equation}
where $\alpha $ denotes the step size parameter, and $k = 0,\ldots, K-1$. 
\begin{theorem}\label{pg_convergence_nonconvex}
	Let $\{\y_k(\mathbf{x},\z)\}$ be the output generated by \eqref{PG2} with
	$\alpha^k_{\y} \in [\underline{\alpha}_{\y},\overline{\alpha}_{\y}] \subset (0,\frac{2}{L_f})$, then we have that the weak LL property with IA holds. 
\end{theorem}
\begin{proof}
	It follows from \cite[Lemma 3.1]{liu2021towards} that there exists $C_f > 0$ such that
	\begin{equation*}
		\min_{0 \le k \le K} \|  \mathcal{R}_{\underline{\alpha}_{\y}} (\x,\y_{k}(\x,\z)) \| \le \frac{C_f}{\sqrt{K+1}}, \quad \forall \x \in \X, \z \in \Y.
	\end{equation*}
	Then the conclusion follows immediately.
\end{proof}

The iterative module $\mathcal{T}_k(\x,\cdot)$ can also be the accelerated gradient scheme proposed in \cite{ghadimi2016accelerated}, which has been described in Eq.~\eqref{yk_def3}.
%\begin{equation}\label{yk_def3}
%	\begin{aligned}
%		& \u_{0}(\x,\z) = \v_{0}(\x,\z) = \z,   \\
%		& \y_{k+1}(\x,\z) = (1-\alpha_k)\u_{k}(\x,\z) + \alpha_k \v_{k}(\x,\z), \\
%		& \u^{k+1}(\x,\z) = \mathtt{Proj}_\Y \left( \y_{k+1}(\x,\z) - \beta_k \nabla_{\y} f(\x,\y_{k+1}(\x,\z)) \right),\\
%		& \v_{k+1}(\x,\z) = \mathtt{Proj}_\Y \left( \v_{k}(\x,\z) - \lambda_k \nabla_{\y} f(\x,\y_{k+1}(\x,\z)) \right),\\
%		& \T_{k+1}\left(\x,\y_k(\mathbf{x},\z)\right)  =  \y_{k+1}(\x,\z),
%	\end{aligned}
%\end{equation}
%where $\alpha_k = \frac{2}{k+1}$, $\beta_k = \frac{1}{2L_f}$ and $\lambda_k = \frac{k\beta_k}{2}$, and $k = 0,\ldots, K-1$.  
\begin{theorem}\label{apg_convergence_nonconvex}
	Let $\{\y_k(\mathbf{x},\z)\}$ be the output generated by Eq.~\eqref{yk_def3}, then we have that the weak LL property with IA	 holds. 
\end{theorem}
\begin{proof}
	Since when $\Y$ is a compact set, $\v_0(\x,\z)$ and $\S(x)$ are both uniformly bounded for any $\x \in \X$. Then,
	it follows from \cite[Corollary 2]{ghadimi2016accelerated} that there exists $C > 0$ such that
	\begin{equation*}
		\min_{0 \le k \le K} \|  \mathcal{R}_{\frac{1}{2L_f}} (\x,\y_{k}(\x,\z)) \| \le \frac{C}{\sqrt{K}}, \quad \forall \x \in \X, \z \in \Y.
	\end{equation*}
	Then the conclusion follows immediately.
\end{proof}


\section{Applications}
As mentioned above, although many popular hierarchical learning and vision tasks have been well understood as the BLO problem in Eq.~\eqref{blo_problem}, almost no solution strategies with high efficiency and accuracy are available for some challenging tasks due to high-dimensional search space and complex theoretical properties. Moreover, many complex deep learning models endowed with nested constrained objectives are still lack of proper reformulation and reliable methodology with grounded theoretical guarantee.   
%With an eye to other complex deep learning applications that are not yet fully recognized or properly solved, we also implement our AIT framework to show significant advantage over most GBMs with poor theoretical investigations.

\textbf{Neural Architecture Search}. We first consider one of the most representative  large-scale high-dimensional BLO application, i.e., Neural Architecture Search (NAS). Typically, NAS aims to find high-performance neural network structures with automated process. Here, we focus on the gradient-based differentiable NAS methods, which have been widely investigated recently. This type of methods select certain search strategy to find the optimal network architecture based on the well defined architecture search space. DARTS~\cite {liu2018darts}, ones of the representative differentiable NAS methods, relaxes the discrete search space to be continuous, and jointly optimize the architecture parameter (i.e., the UL variable $\x$) and network weights (i.e., the LL variable $\y$) with gradient descent step, which implies a typical BLO problem. In details, the searched architecture consists of multiple computation cells, and each cell is a directed acyclic graph including $N$ nodes. The nodes in each cell, denoted as $d$, represent the latent feature map, while the directed edges $o_{(i,j)}, i,j\in[1,N]$ between nodes $d^{i}$ and $d^{j}$ indicate the candidate operations based on defined search space denoted as $\mathcal{O}$. Then $\x$ is supposed to be defined as the whole continuous variables $\x=\{\x_{(i,j)}\}$, where $\x_{(i,j)}$ denotes the vector of the operation mixing weights for nodes pair $(i,j)$ of dimension $\mathcal{O}$. Hence $o_{(i,j)}$ is supposed to be the ideal operation chosen by $\arg\max$ operation, i.e., $o_{(i,j)}=\arg\max_{o\in\mathcal{O}}\x_{{(i,j)}}$. For most learning and vision tasks which employ NAS to optimize the network structure, the LL subproblem usually has high-dimensional search space and complex task-specific constraints. 

As one of the mostly widely used solution strategies, DARTS introduces finite difference approximation with a single-step gradient update of $\y$ to avoid the complex matrix-vector production. On top of that, a series of variations ~\cite{xu2019pc,chen2019progressive,dong2019searching} based on DARTS have been developed and applied in numerous applications. In addition to this approximation operation adopted by DARTS, we could also solve this BLO application with other GBMs such as RHG and CG. Whereas, since the LL variables contain a cumbersome number of parameters from different searching cells, all the above methods suffer from poor theoretical investigation on this non-convex high-dimensional BLO problem. In comparison, by effective augmentation of the iterative trajectory, AIT updates the UL variables with more accurate hyper-gradient, which is more qualified for this BLO problem with non-convex follower.

\begin{figure*}[h!]
	\begin{center}
		\begin{tabular}{c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}}
			\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{LLC/LLC1.eps} &\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{LLC/LLC2.eps} &                 
			
			\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{LLC/LLC3.eps} &\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{LLC/LLC4.eps}\\
			\footnotesize (a) &\footnotesize (b)	&\footnotesize (c) &\footnotesize (d) \\ 
			%			\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex9.eps} &\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex10.eps} && \includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex11.eps} &\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex12.eps}\\
			%			\multicolumn{2}{c}{\footnotesize (c)$\quad(\x_{0},\y_{0})=(-6,0)$} && 
			%			\multicolumn{2}{c}{\footnotesize (d)$\quad(\x_{0},\y_{0})=(-8,-8)$}\\
		\end{tabular}
	\end{center}
	%\vspace{-0.4cm}
	\caption{The first two subfigures illustrate the convergence behavior of $\left\|\Phi-\Phi^{*}\right\|/(\left\|\Phi^{*}\right\|+1)$ and $\Vert \x - \x^*\Vert/ \Vert \x^*\Vert$ for the baseline (i.e., BDA) and variations with techniques from $\textrm{AIT}_{C}$ including IA (i.e., $+\textrm{IA}$) and prior regularization (i.e., $+\textrm{P}$). As for the last two subfigures, we compare the convergence behavior of $\textrm{AIT}_{C}$ and mainstream GBMs including CG, Neumann, RHG, BDA. We choose the same representative initialization point for all the methods as $(\x_{0},\y_{0})=(2\mathbf{e},(2\mathbf{e},2\mathbf{e}))$. }\label{toy_convergence_LLC}
\end{figure*}

\textbf{Generative Adversarial Networks}.  We move one more step to apply our AIT to other challenging tasks with nested constrained learning objectives, i.e., Generative Adversarial Network (GAN), which has been one of the most popular deep learning applications and achieved impressive progress in various computer vision tasks. In general, GAN~\cite{goodfellow2020generative} based model is widely recognized as a minimax game between two adversarial players: the generator network $G(\x;\cdot)$ (parameterized by $\x$) and the discriminator network $D(\y;\cdot)$ (parameterized by $\y$). The generative model $G$ depicts the distribution $P_{G}$, and is supposed to fool $D$ with generated data sampled from $P_{G}$ by optimizing $F$ to minimize the distance between $P_{G}$ and the real data distribution $P_{\mathtt{data}}$. Thus the generic GAN can be defined as  $\min_{\x}\max_{\y}V(\x,\y) =-\log(D(\y;\u))
- \log(1-D(\y;G(\x;\v)))$, where $V(\x,\y)$ denotes a joint loss function to optimize both objectives, $\u$ and $\v$ are sampled data from some real data distribution $P_{\text{data}}$ and generated fake distribution $P_{G}$, respectively.   


Typically speaking, $G(\x;\cdot)$ first generates $\v$, and then $D(\y;\cdot)$ corresponds with predicted probability that $\v$ is sampled from $P_{data}$. Based on this, most related methods, e.x., Vanilla GAN (VGAN)~\cite{goodfellow2014generative}  and Wasserstein GAN (WGAN)~\cite{ArjovskyWGAN}, alternatively train $G$ and $D$, and simply treat them on an equal footing, which ignores the intrinsic leader-follower relationship between $G(\x;\cdot)$ and $D(\y;\cdot)$. In this work, we first refer to the reformulation in~\cite{liu2021investigating} to depict the original GAN as below:
\begin{equation}
	\begin{aligned}
		F(\mathbf{x}, \mathbf{y}) &=\log (D(\y;G(\x;\mathbf{v}))),\\
		f(\mathbf{x}, \mathbf{y}) &=\log D(\y;\mathbf{u}) +\log (1-D(\y;G(\x;\mathbf{v}))).\\ 
	\end{aligned}\nonumber
\end{equation}
Thus the LL objective $f$ targets on enhancing the ability of $D(\y;\cdot)$ to distinguish the fake data generate by $G(\x;\cdot)$, while the UL objective $F$ optimizes $\x$ to generate more real data distribution to confuse the discriminator. Under this BLO formulation, most existing methods with alternating training strategies essentially directly compute the hyper-gradient with the final state of trajectory instead of the sequence, which contains more high-order gradient information.  In comparison, our methods admit multiple solutions and non-convexity of the LL subproblem, thus could solve the above problem with self contained theoretical guarantee.


\section{Experiments}
 In this section, we report the quantitative and visualization results of the numerical examples, typical learning and vision applications and more challenging tasks. We run the experiments of toy examples based on a PC with Intel Core i7-8700 CPU, 32GB RAM and implement the real-world BLO applications on a Linux server with NVIDIA GeForce RTX 2080Ti GPU (12GB VRAM). 
\subsection{Numerical Evaluations}\label{numerical_results}

At first, we validate the provided theoretical results of our AIT based on numerical examples with different LL assumptions. More specifically, we focus on the UL variable (i.e., $\x $) and approximative UL subproblem ($\Phi$ is used as unified denotation for $\varphi_{K}(\x)$ in Eq.~\eqref{single_re_reform}, $ \varphi_{K}(\x,\z)$ in Eq.~\eqref{eq:proximal_prior} and $\phi_{\bar{K}}(\x,\z)$ in Eq.~\eqref{eq:upper_phiK} under convex and non-convex scenarios, respectively), and analyze the convergence behavior of $\left\|\Phi-\Phi^{*}\right\|/(\left\|\Phi^{*}\right\|+1)$ ($\left\|\Phi^{*}\right\|$ is equal to $0$ in some cases) and $\Vert \x - \x^*\Vert/ \Vert \x^*\Vert$  during the UL optimization. We use the numerical example under LLC assumption to show the effectiveness of  $\textrm{AIT}_{C}$ with IA and the prior regularization term, and compare the convergence behavior of $\textrm{AIT}_{C}$ with a series of mainstream GBMs. Next, we use another example with the well defined LLS assumption to implement our $\textrm{AIT}_{C}$ with IA and the Nesterov's acceleration dynamics. 

Moving forward to the toy example with LL non-convexity, we first verify the effectiveness of $\textrm{AIT}_{NC}$ with IA, PTT and the acceleration gradient scheme, and compare $\textrm{AIT}_{NC}$ with the above GBMs to show its great improvement. Furthermore, we depict the loss surfaces and the derived solutions to show the significant improvement of $\textrm{AIT}_{NC}$  under the non-covnex scenario, and analyze the running time influenced by different factors, including initialization points, dimension of LL variables (i.e., $n$) and LL iterations (i.e, $K$). 

%In the following, we first validate the numerical performance of our AIT framework based on numerical examples with different LL assumptions. More specifically, we focus on the UL variable (i.e., $\x $) and approximative UL subproblem ($\Phi$ is used as unified denotation for $\varphi_{K}(\x^{t})$ in Eq.~\eqref{single_re_reform}, $ \varphi_{k}(\x^{t},\z^{t})$ in Eq.~\eqref{eq:proximal_prior} and $\phi_{k}(\x^{t},\z^{t})$ in Eq.~\eqref{eq:upper_phiK} under convex and non-convex scenarios, respectively), and analyze the convergence behavior of $\left\|\Phi-\Phi^{*}\right\|/(\left\|\Phi^{*}\right\|+1)$ and $\Vert \x - \x^*\Vert/ \Vert \x^*\Vert$  during the UL optimization. We use the numerical example under LLC assumption to show the effectiveness of  $\textrm{AIT}_{C}$ framework with IA and the prior regularization term, and compare the convergence behavior of $\textrm{AIT}_{C}$ with a series of mainstream GBMs. Next, we use another example with the well defined LLS assumption to implement our $\textrm{AIT}_{C}$ with IA and the Nesterov's acceleration dynamics. Moving forward to the toy example with LL non-convexity, we first verify the effectiveness of $\textrm{AIT}_{NC}$ with IA, PTT and the acceleration gradient scheme, and compare $\textrm{AIT}_{NC}$ with the above GBMs to show its great improvement. Furthermore, we depict the loss surfaces and the derived solutions to show the significant improvement of $\textrm{AIT}_{NC}$  under the non-covnex scenario, and analyze the running time influenced by different factors, including initialization points, dimension of LL variables (i.e., $n$) and LL iterations (i.e, $K$). 

%In this section, we first conduct the experiments with numerical examples under different theoretical properties (i.e., with LLC, with LLS and non-convexity) to verify the convergence behavior of $\textrm{AIT}_{C}$, $\textrm{AIT}_{NC}$ and its variations (i.e., with prior regularization  and acceleration dynamics), respectively. Then we demonstrate its significant performance improvement with standard BLO applications including data hyper-cleaning and few-shot classification, which reflects different LL subproblems influenced by neural network structures and regularization constraints. Furthermore, we also extend our framework to large-scale  problems (i.e., neural architecture search), and other potential hierarchical problems (i.e., generative adversarial networks). 


\subsubsection{Convex Scenario}

%Since the numerical performance on nonconvex cases has been verifed
We first consider the LLC scenario and conduct the numerical experiments with the following example from~\cite{liu2020generic}. With $\mathbf{x} \in \mathbb{R}^{n}, [\mathbf{y}]_{1} \in \mathbb{R}^{n} $ and $ [\mathbf{y}]_{2} \in \mathbb{R}^{n}$:
\begin{equation}
	\begin{aligned}
		&\min _{\mathbf{x} \in \mathcal{X}}\|\mathbf{x}-[\mathbf{y}]_{2}\|^{4}+\|[\mathbf{y}]_{1}-\mathbf{e}\|^{4}, \\
		&\text { s.t. }([\mathbf{y}]_{1}, [\mathbf{y}]_{2}) \in \underset{[\mathbf{y}]_{1} \in \mathbb{R}^{n}, [\mathbf{y}]_{2} \in \mathbb{R}^{n}}{\operatorname{argmin}}\frac{1}{2}\|[\mathbf{y}]_{1}\|^{2}-\mathbf{x}^{\top} [\mathbf{y}]_{1},
	\end{aligned}
\end{equation}
where $\mathcal{X}=[-10,10] \times \cdots[-10,10] \subset \mathbb{R}^{n}$, and $\mathbf{e}$ represents the vector of which the elements are all equal to 1.  Note that we use bold text to represent scalars for all the following description. We set $n=20$, $T=1000$ and choose $(\x_{0},\y_{0})=(2\mathbf{e},(2\mathbf{e},2\mathbf{e}))$ as the initialization point. By simple calculation, we can obtain the unique optimal solution as $\mathbf{x}^{*}=\mathbf{e}$, $\mathbf{y}^{*}=(\mathbf{e},\mathbf{e})$. This numerical example satisfies the LLC assumption for BDA while violating the LLS assumption admitted by most GBMs such as RHG, CG~\cite{pedregosa2016hyperparameter} and Neumann~\cite{lorraine2020optimizing}.  


%
%\begin{figure}[h!]
%	\begin{center}
	%		%\renewcommand\arraystretch{0.8}
	%		\begin{tabular}{c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}}
		%			\includegraphics[height=3.2cm,width=4.2cm,trim= 0 0 0 0,clip]{LLC/LLC1.eps}&\includegraphics[height=3.2cm,width=4.2cm,trim= 0 0 0 0,clip]{LLC/LLC2.eps}\\
		%			%\specialrule{0em}{1pt}{3pt}
		%			\footnotesize (a) &\footnotesize (b) \\
		%			%\specialrule{0em}{-3pt}{-3pt}
		%		\end{tabular}
	%		%\vspace{-0.3cm}
	%	\end{center}
%	%\vspace{-0.4cm}
%	\caption{Illustrating the convergence behavior of $\left\|\Phi_{T}-\Phi^{*}\right\|/(\left\|\Phi^{*}\right\|+1)$ and $\Vert \x - \x^*\Vert/ \Vert \x^*\Vert$ for the baseline and AIT-C with IA and PIA as the training proceeds. We choose the same representative initialization point for all the methods as $(\x_{0},\y_{0})=(2\mathbf{e},(2\mathbf{e},2\mathbf{e}))$.}\label{toy_convergence_LLC}
%\end{figure}




To investigate the effectiveness of Alg.~\ref{alg:AIT-C}, we take BDA as the baseline, and implement our $\textrm{AIT}_{C}$ by incrementally adding IA and the prior regularization. In the first two subfigures of Fig.~\ref{toy_convergence_LLC}, we analyze the convergence behavior of  $\left\|\Phi-\Phi^{*}\right\|/(\left\|\Phi^{*}\right\|+1)$ and $\Vert \x - \x^*\Vert/ \Vert \x^*\Vert$. As it has been proved in~\cite{liu2021investigating}, the convergence property of BDA can be consistently verified and obtain expected convergence results for this BLO problem. As for the augmentation technique, the embedded IA of $\textrm{AIT}_{C}$ helps dynamically adjust the initialization of $[\y]_1$ and $[\y]_2$, and the augmented optimization trajectory further improves the convergence speed of UL variable (i.e., $\x$) and approximative  UL subproblem (i.e., $\Phi$). Besides, with prior regularization  to guide the optimization process of $\z$, our $\textrm{AIT}_{C}$ can obtain higher convergence precision and speed. %For the following experiments, we use the notation of $\Phi_{T}$ to uniformly denote $\varphi_{T}(\x)$ for BDA and $\varphi_{T}(\x,\z)$ for our $\textrm{AIT}_{C}$. 

%\begin{figure}[h!]
%	\begin{center}
	%		%\renewcommand\arraystretch{0.8}
	%		\begin{tabular}{c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}}
		%			\includegraphics[height=3.2cm,width=4.2cm,trim= 0 0 0 0,clip]{LLC/LLC3.eps}&\includegraphics[height=3.2cm,width=4.2cm,trim= 0 0 0 0,clip]{LLC/LLC4.eps}\\
		%			%\specialrule{0em}{1pt}{3pt}
		%			\footnotesize (a) &\footnotesize (b) \\
		%			%\specialrule{0em}{-3pt}{-3pt}
		%		\end{tabular}
	%		%\vspace{-0.3cm}
	%	\end{center}
%	%\vspace{-0.4cm}
%	\caption{We compare the convergence behavior of $\left\|\Phi_{T}-\Phi^{*}\right\|/(\left\|\Phi^{*}\right\|+1)$ and $\Vert \x - \x^*\Vert/ \Vert \x^*\Vert$ for AIT-C and mainstream GBMs including CG, Neumann, RHG, BDA and BVFIM.}\label{toy_convergence_LLC2}
%\end{figure}



In the last two subfigures of Fig.~\ref{toy_convergence_LLC}, we compare our $\textrm{AIT}_{C}$ with series of mainstream GBMs including CG, Neumann, RHG, and BDA. Since the LLS assumptions of CG, Neumann and RHG can not be satisfied, no convergence property for these methods could be guaranteed in this case. In comparison with BDA, $\textrm{AIT}_{C}$ also gains advantage over convergence speed and precision. 
%\subsubsection{Convex Scenario}



Furthermore, to demonstrate the performance of other iterative formats and acceleration dynamics, we further introduce another toy example with more strict LL property, i.e, the well-defined LLS assumption:
%
%With more strict theoretical properties, we also extend our based on the toy example under well-defined LLS assumption:
\begin{equation}
	\begin{aligned}
		&\min _{\mathbf{x} \in \mathcal{X}}-\mathbf{e}^{T} \mathbf{x}+\|\mathbf{x}-[\mathbf{y}]_{2}\|^{4}+\|[\mathbf{y}]_{1}-\mathbf{e}\|^{4}, \\
		&\text { s.t. }([\mathbf{y}]_{1}, [\mathbf{y}]_{2}) \in \underset{[\mathbf{y}]_{1} \in \mathbb{R}^{n}, [\mathbf{y}]_{2} \in \mathbb{R}^{n}}{\operatorname{argmin}}\|[\mathbf{y}]_{1}+[\mathbf{y}]_{2}-\mathbf{x}\|^{4},
	\end{aligned}
\end{equation}
where $\mathbf{x} \in \mathbb{R}^{n}, [\mathbf{y}]_{1} \in \mathbb{R}^{n} $, $ [\mathbf{y}]_{2} \in \mathbb{R}^{n}$, $\mathcal{X}=[-1,1] \times \cdots \times[-1,1] \subset \mathbb{R}^{n}$. Given any $\x\in \X$, it satisfies $\min _{[\mathbf{y}]_{1} \in \mathbb{R}^{n}, [\mathbf{y}]_{2} \in \mathbb{R}^{n}}\|[\mathbf{y}]_{1}+[\mathbf{y}]_{2}-\mathbf{x}\|^{4}=0$, then the unique optimal solution of this BLO problem is $\x^{*}=\mathbf{e}$,  $\mathbf{y}^{*}=(\frac{1}{2}\mathbf{e},\frac{1}{2}\mathbf{e})$. Since the solution set of this LL subproblem (i.e., $\mathcal{S}(\x)$) is a singleton, we can verify that the above example can be properly solved with GBMs under LLS assumption.

\begin{figure}[htbp]
	\begin{center}
		%\renewcommand\arraystretch{0.8}
		\begin{tabular}{c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}}
			\includegraphics[height=3.2cm,width=4.2cm,trim= 0 0 0 0,clip]{LLS/LLS1.eps}&\includegraphics[height=3.2cm,width=4.2cm,trim= 0 0 0 0,clip]{LLS/LLS2.eps}\\
			%\specialrule{0em}{1pt}{3pt}
			\footnotesize (a) & \footnotesize (b) \\
			%\specialrule{0em}{-3pt}{-3pt}
		\end{tabular}
		%\vspace{-0.3cm}
	\end{center}
	%\vspace{-0.4cm}
	\caption{Illustrating the convergence curve of $\left\|\Phi-\Phi^{*}\right\|/(\left\|\Phi^{*}\right\|+1)$ and $\Vert \x - \x^*\Vert/ \Vert \x^*\Vert$ for the baseline (i.e., RHG) and variations with techniques of $\textrm{AIT}_{C}$, including IA (i.e., $+\textrm{IA}$) and Nesterov's acceleration dynamics (i.e., $+\textrm{A}$) during the LL optimization. The initialization point is chosen as $(\x_{0},\y_{0})=(-\mathbf{e},(-\mathbf{e},-2\mathbf{e}))$.}\label{toy_convergence_LLS}
\end{figure}

In this case, we implement our $\textrm{AIT}_{C}$ with RHG as the baseline, and further incorporate the Nesterov's acceleration dynamics to facilitate the convergence behavior. When an appropriate initialization position is chosen, commonly used GBMs are also supposed to converge with acceptable speed. To demonstrate the effectiveness of IA, we set the initialization point as $(\x_{0},\y_{0})=(-\mathbf{e},(-\mathbf{e},-2\mathbf{e}))$, where $\z$ is further away from the optimal solution $\z^{*}$. In Fig~\ref{toy_convergence_LLS}, it can be seen that the IA technique could effectively accelerate the convergence of UL variables towards the global optimal solution even when RHG converges slower due to improper initialization of LL variable. In addition, the Nesterov's strategy further helps the LL variable (i.e., $\y$) converge faster with embedded acceleration dynamics.%When an appropriate initialization position is chosen, commonly used GBMs are also supposed to converge with acceptable speed.

\subsubsection{Non-Convex Scenario}


\begin{figure*}[h!]
	\begin{center}
		\begin{tabular}{c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}}
			\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{Nonconvex/Nonconvex1.eps} &\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{Nonconvex/Nonconvex2.eps} &                 
			
			\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{Nonconvex/Nonconvex3.eps} &\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{Nonconvex/Nonconvex4.eps}\\
			\multicolumn{2}{c}{\footnotesize(a)~$(\x_{0},\y_{0})=(-6,0)$} & 
			\multicolumn{2}{c}{\footnotesize(b)~$(\x_{0},\y_{0})=(-8,-8)$}\\
			%			\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex9.eps} &\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex10.eps} && \includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex11.eps} &\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex12.eps}\\
			%			\multicolumn{2}{c}{\footnotesize (c)$\quad(\x_{0},\y_{0})=(-6,0)$} && 
			%			\multicolumn{2}{c}{\footnotesize (d)$\quad(\x_{0},\y_{0})=(-8,-8)$}\\
		\end{tabular}
	\end{center}
	%\vspace{-0.4cm}
	\caption{We plot the convergence behavior of $\left\|\Phi-\Phi^{*}\right\|/(\left\|\Phi^{*}\right\|+1)$ and $\Vert \x - \x^*\Vert/ \Vert \x^*\Vert$ for the baseline (i.e., RHG) and the variation with IA (i.e., $+\textrm{IA}$), PTT (i.e., $+\textrm{PTT}$) and the acceleration gradient scheme (i.e., $+\textrm{A}$).}\label{toy_convergence_nonconvex_1}
\end{figure*}

\begin{figure*}[h!]
	\begin{center}
		\begin{tabular}{c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}}
			%			\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex9.eps} &\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex10.eps} && \includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex11.eps} &\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex12.eps}\\
			%			\multicolumn{2}{c}{\footnotesize (c)$\quad(\x_{0},\y_{0})=(-6,0)$} && 
			%			\multicolumn{2}{c}{\footnotesize (d)$\quad(\x_{0},\y_{0})=(-8,-8)$}\\
			\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{Nonconvex/Nonconvex5.eps} &\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{Nonconvex/Nonconvex6.eps} && \includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{Nonconvex/Nonconvex7.eps} &\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{Nonconvex/Nonconvex8.eps}\\
			\multicolumn{2}{c}{\footnotesize(a)~$(\x_{0},\y_{0})=(-6,0)$} && 
			\multicolumn{2}{c}{\footnotesize(b)~$(\x_{0},\y_{0})=(-8,-8)$}\\
		\end{tabular}
	\end{center}
	%\vspace{-0.4cm}
	\caption{In this figure, we compare the convergence behavior of $\left\|\Phi-\Phi^{*}\right\|/(\left\|\Phi^{*}\right\|+1)$ and $\Vert \x - \x^*\Vert/ \Vert \x^*\Vert$ for our $\textrm{AIT}_{NC}$ and series of mainstream GBMs including CG, Neumann, RHG, BDA and BVFIM.}\label{toy_convergence_nonconvex_3}
\end{figure*}

%\begin{figure*}[h!]
%	\begin{center}
	%		\begin{tabular}{c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}}
		%			\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex5.eps} &\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex6.eps} && \includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex7.eps} &\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex8.eps}\\
		%			\multicolumn{2}{c}{\footnotesize (a)$\quad(\x_{0},\y_{0})=(-6,0)$} && 
		%			\multicolumn{2}{c}{\footnotesize (b)$\quad(\x_{0},\y_{0})=(-8,-8)$}\\
		%			\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex9.eps} &\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex10.eps} && \includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex11.eps} &\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex12.eps}\\
		%			\multicolumn{2}{c}{\footnotesize (c)$\quad(\x_{0},\y_{0})=(-6,0)$} && 
		%			\multicolumn{2}{c}{\footnotesize (d)$\quad(\x_{0},\y_{0})=(-8,-8)$}\\
		%		\end{tabular}
	%	\end{center}
%	%\vspace{-0.4cm}
%	\caption{This figure illustrates the convergence behavior of $\Vert \phi_{T}(\mathbf{\x}) - \phi(\mathbf{\x}^{*})\Vert /\Vert \phi(\mathbf{\x}^{*})\Vert$) and $\Vert \x - \x^*\Vert/ \Vert \x^*\Vert$ in comparison with the original algorithms, RHG and BDA. It should be noted that since all the methods converge steadily in the last two columns, we only show the first half curve to show more details during the left iterative optimization process.}\label{toy_convergence_nonconvex_1}
%\end{figure*}

%\begin{figure*}[h!]
%	\begin{center}
	%		\begin{tabular}{c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}}
		%			\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex1.eps} &\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex2.eps} && \includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex3.eps} &\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{figures/nonconvex4.eps}\\
		%			\multicolumn{2}{c}{\footnotesize (a)$\quad(\x_{0},\y_{0})=(-6,0)$} && 
		%			\multicolumn{2}{c}{\footnotesize (b)$\quad(\x_{0},\y_{0})=(-8,-8)$}\\
		%		\end{tabular}
	%	\end{center}
%	%\vspace{-0.4cm}
%	\caption{We report the convergence behavior of $\Vert \phi_{T}(\mathbf{\x}) - \phi(\mathbf{\x}^{*})\Vert /\Vert \phi(\mathbf{\x}^{*})\Vert$ and $\Vert \x - \x^*\Vert/ \Vert \x^*\Vert$ in comparison with mainstream GBMs including CG, Neumann, RHG, BDA and BVFIM. }\label{toy_convergence_nonconvex_2}
%\end{figure*}


To validate the superiority of AIT, we move on to more challenging scenario and introduce another toy example~\cite{liu2021value} with non-convex LL subproblem, which takes the form of:
\begin{equation}
	\begin{aligned}
		&\min _{\mathbf{x} \in \mathbb{R}, \mathbf{y} \in \mathbb{R}^{n}}\|\mathbf{x}-a\|^{2}+\|\mathbf{y}-a-\mathbf{c}\|^{2}, \\
		&\text { s.t. }[\mathbf{y}]_{i} \in \underset{[\mathbf{y}]_{i} \in \mathbb{R}}{\operatorname{argmin}} \sin \left(\mathbf{x}+[\mathbf{y}]_{i}-[\mathbf{c}]_{i}\right), \forall i,
	\end{aligned}
\end{equation}
where both $a\in\mathbb{R}$ and $\c\in\mathbb{R}^{n}$ are constants, and $[\cdot]_{i}$ denotes the i-th element of the vector. Then the optimal solution of this problem can be calculated in the following form:
$$
\mathbf{x}=\frac{(1-n) a+n C}{1+n}, \text { and }[\mathbf{y}]_{i}=C+[\mathbf{c}]_{i}-\mathbf{x}, \forall i, 
$$
where $$
C=\underset{C}{\operatorname{argmin}}\left\{\|C-2 a\|: C=-\frac{\pi}{2}+2 k \pi, k \in \mathbb{Z}\right\},
$$ and the corresponding value of UL objective is $
F^{*}=\frac{n(C-2 a)^{2}}{1+n}
$. Here we set $a=2$, $[\c]_{i}=2, i=1,...,n$ and $[\y]_{i}\in[-10, 10]$. It can be easily verified that this example satisfies the theoretical assumption of $\textrm{AIT}_{NC}$ while violating the LLS assumption for RHG, CG, Neumann and the LLC assumption for BDA due to existence of multiple local optimal solutions of the LL subproblem.  At first, we set $n=1$ to investigate the convergence property based on the simplified form and draw the loss surfaces.  Then we use larger $n$ when analyzing the influence of dimension of LL variables on the running time. We can calculate the corresponding optimal solution as $(\x^{*},\y^{*})=(3\pi/4, 3\pi/4 + 2)$. In consideration of distance between the initialization position and the global optimal solution, we choose two initialization points for $\x$ and $\y$ including $(\x_{0},\y_{0})=(-6, 0)$ and $(\x_{0},\y_{0})=(-8,-8)$.     

In Fig.~\ref{toy_convergence_nonconvex_1}, we take RHG as the baseline, and start by incrementally embedding two augmentation techniques and the acceleration gradient scheme of $\textrm{AIT}_{NC}$ into the baseline. It can be seen that adding PTT technique shows consistently better convergence results with respective of $\x$, while the convergence of $\phi_{\bar{K}}(\x,\z)$ may be influenced by different initialization points without dynamically optimized $\z$. When we implement our $\textrm{AIT}_{NC}$ with both techniques, since the theoretical convergence property is guaranteed, our algorithm can uniformly improve the convergence behavior of $\phi_{\bar{K}}(\mathbf{x}, \mathbf{z})$ and $\x$ on this non-convex problem. Furthermore, by embedding the acceleration gradient scheme in Eq.~\eqref{yk_def3} under our $\textrm{AIT}_{NC}$, the convergence rate of gradient descent for this non-convex BLO problem could be further improved.   %For the following experiments, we use the notation of $\Phi$ to uniformly denote $\varphi_{T}(\x)$ for BDA and $\phi_{T}(\x,\z)$ for our $\textrm{AIT}_{NC}$. As it is shown, introducing the IA technique helps RHG overcome the trap of local optima and leads to better convergence results in some cases. 
\begin{figure}[htbp]
	\begin{center}
		\renewcommand\arraystretch{0.1}
		\begin{tabular}{c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}}
			\multicolumn{3}{c}{\includegraphics[height=0.75cm,width=9cm,trim=20 250 30. 0,clip]{Nonconvex/nonconvex_legend.eps}}\\
			\specialrule{0em}{-4pt}{-4pt}
			%			\multicolumn{3}{c}{\includegraphics[height=0.75cm,width=9cm,trim=10 250 0. 0,clip]{figures/nonconvex_legend_2.eps}}\\
			%			\specialrule{0em}{-2pt}{-4pt}
			\multirow{3}{*}{\includegraphics[height=6.3cm,width=4.2cm,trim=0 28 20 10,clip]{Nonconvex/Nonconvex9.eps}}&& \\
			&&	\includegraphics[height=2.9cm,width=4.2cm,trim= 0 0 0. 0,clip]{Nonconvex/Nonconvex10.eps}\\
			\specialrule{0em}{0pt}{0pt}
			&&\footnotesize (b) UL Trajectory\\
			&&\includegraphics[height=3cm,width=4.2cm,trim= 0 0 0 0,clip]{Nonconvex/Nonconvex11.eps}\\
			\specialrule{0em}{0pt}{0pt}
			\footnotesize (a) Loss Surface &&
			\footnotesize (c) LL Trajectory\\
		\end{tabular}
	\end{center}
	%\vspace{-0.4cm}
	\caption{In the first subfigure, we plot the surface of two subproblems and illustrate the iterative solutions derived by RHG and $\textrm{AIT}_{NC}$ with the same initialization point $(\x_{0},\y_{0})=(-6,0)$. As for the subfigures on the right, we plot the trajectory of $(\x^{t},\z^{t})$ for our $\textrm{AIT}_{NC}$ during the UL optimization. }\label{toy_convergence_nonconvex_2}
\end{figure}

Furthermore, In Fig~\ref{toy_convergence_nonconvex_3}, we compare $\textrm{AIT}_{NC}$ with mainstream GBMs, including CG, Neumann, RHG, BDA and BVFIM with the same initialization points. As it is expected, all the above methods except BVFIM can be easily stuck at the local optimal solution. Besides, BVFIM may not converge exactly to the true optimal solution influenced by its sensitivity to the added penalty terms. In comparison, under our $\textrm{AIT}_{NC}$ algorithm, by dynamically adjusting the initial value of LL variables and truncation of $\mathcal{T}$ for computation of hyper-gradients, the convergence results without LLC assumption can be consistently verified. 


More vividly, in Fig.~\ref{toy_convergence_nonconvex_2}, we mark the initialization point (i.e.,~$(\x_{0},\y_{0})$), optimal solution (i.e.,~$(\x^{*},\y^{*})$), iterative solution (i.e.,~$(\x^{t},\y^{t})$) and derived convergence solutions (i.e.,~$(\x^{T},\y^{T})$) for RHG and $\textrm{AIT}_{NC}$ on the UL and LL surfaces. As confirmed earlier by the convergence analysis, since quantities of local optima exist along the path from $(\x_{0},\y_{0})$ to $(\x^{*},\y^{*})$, the iterative solutions of RHG are easily stuck at the local optima on the loss surface, which leads to convergence solution distant from $(\x^{*},\y^{*})$. In contrast, the introduced $\z$ together with PTT under our $\textrm{AIT}_{NC}$, (i.e.,~$\z^{t}$), goes over the local optima and makes its own way towards the true optimal solution, which further helps find reasonable $\y_{\bar{K}}(\x^t,\z^t)$ for computation of hyper-gradient. Finally, $(\x^{t},\y^{t})$ overcomes the trap of local optima and converges to the global optimal solution, thus demonstrates the superiority of AIT.

\begin{figure}[h!]
	\begin{center}
		\begin{tabular}{c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}}
			& \includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{Nonconvex/nonconvex16.eps} &\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{Nonconvex/nonconvex16_2.eps}\\
			& \footnotesize (a)~$(\x_{0},\y_{0})=(-6,0)$ &\footnotesize (b)~$(\x_{0},\y_{0})=(-8,-8)$ \\
			
		\end{tabular}
	\end{center}
	%\vspace{-0.4cm}
	\caption{In the two subfigures, we report average $\bar{K}$ and running time per iteration of our $\textrm{AIT}_{NC}$ during the LL optimization with different initialization points. Note that the part with green background represents that the convergence curve comes to stabilize ($\Vert \x - \x^*\Vert <1\times e^{-3}$). }\label{toy_convergence_nonconvex_4}
\end{figure}

In Fig.~\ref{toy_convergence_nonconvex_4}, we report the average running time of hyper-gradient computation with respective to different initialization points in this numerical case. It can be observed that as the PTT operation of $\textrm{AIT}_{NC}$  dynamically truncates the optimization trajectory and selects $\bar{K}\in[1,K]$ after $K$ LL iterations of LL optimization, the computational burden of hyper-gradient w.r.t. $\x$ and $\z$ is continuously eased. In addition, we found that as the curve converges with favorable convergence speed in Fig.~\ref{toy_convergence_nonconvex_3}, $\bar{K}$ tends to stabilize around a fixed number independent of the chosen initialization points. 


\begin{figure}[h!]
	\begin{center}
		\begin{tabular}{c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}}
			&\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{Nonconvex/nonconvextime1.eps} &\includegraphics[height=3.2cm,width=4.2cm,trim=0 0 0 0,clip]{Nonconvex/nonconvextime2.eps}\\
			&\footnotesize (a)~Influence of $K$ &\footnotesize (b) Influence of $n$\\
			
		\end{tabular}
	\end{center}
	%\vspace{-0.4cm}
	\caption{The two subfigures report the total time of RHG and $\textrm{AIT}_{NC}$ for a singe UL iteration as the LL iteration $K$ or dimension of $\y$ increases. We use $\textrm{TG}_{(\cdot)}$ to denote the time for gradient computation of corresponding variables, and $\textrm{TF}$ denotes the time for forward propagation used to construct $\mathcal{T}$. Note that we use the finally
		stabilized $\bar{K}$ for $\textrm{AIT}_{NC}$ and run 5 steps to calculate the average time for comparison.}\label{toy_convergence_nonconvex_5}
\end{figure}


To evaluate the performance for high-dimensional BLO problems, we further investigate how dimension of LL subproblems (i.e., $n$) and LL iteration (i.e., $K$) influence the computation efficiency. Known that the computation burden has been evaluated to be less dependent on the dimension of UL subproblem when calculating the hyper-gradient with AD~\cite{franceschi2017forward} (adopted by classical GBMs, e.g., RHG), so in Fig.~\ref{toy_convergence_nonconvex_5}, we continuously increase the dimension of $\y$ and record the average time for gradient computation of RHG and $\textrm{AIT}_{NC}$. We can observe that $\bar{K}\in[1,K]$ always decreases the time cost for the UL optimization process compared with RHG, even extra computation for $\bar{K}$ and hyper-gradient of $\z$ is introduced in the $\textrm{AIT}_{NC}$. Besides, we also evaluate the runtime of RHG and $\textrm{AIT}_{NC}$ with increasing $K$. Compared with $n$, the increasing $K$ has more influence on the computation for iterative optimization of $\y_{k}$ and hyper-gradient of $\x$. Accordingly, the PTT technique chooses smaller $\bar{K}$ for backpropagation ( Step \ref{outer_loop_2}-\ref{outer_loop_3} in Alg.~\ref{alg:AIT-N}), thus reduces the computation burden of backpropagation (i.e., $\textrm{PT}_{\x}$ and $\textrm{PT}_{\z}$). 


\subsection{Typical Learning and Vision Applications}

%We continue to validate the performance of AIT on two  standard BLO applications, including few-shot learning and data hyper-cleaning. For the few-shot classification application, we investigate how AIT solves the BLO with noncovnex LL objective by adding non-convex regularization term, and conduct the experiment with different tasks settings, backbones and datasets. As for the data hyper-cleaning, we construct the LL network structure with convex and non-convex classifiers to show consistent performance improvement of AIT and its variations on three datasets and two metrics. Moreover, to overcome the limitation of existing GBMs when being applied to the large-scale high-dimensional BLO applications, we implement the neural architecture search and compare our AIT with representative methods. Last but not least, with an eye to other complex deep learning application that are not yet fully recognized, we extent our AIT framework to solve the generative adversarial networks applications, and report the visualization and qualitative results to demonstrate the generalization performance and superiority compared with mainstream methods. We run the experiments of toy examples based on a PC with Intel Core i7-8700 CPU, 32GB RAM and implement the real-world BLO applications on a Linux server with NVIDIA GeForce RTX 2080Ti GPU (12GB VRAM). More detailed configuration and parameter settings can be found in the supplementary materials.				

%\subsection{Classical Learning and Vision Tasks }
In the following, we further demonstrate the performance of AIT with typical BLO applications influenced by the nonconvex LL objectives and nonconvex LL network structure, including few-shot learning and data hyper-cleaning.





\subsubsection{Data Hyper-Cleaning}

%\begin{table*}[h!]
%	%\vspace{-0.4cm} %
%	\centering
%	\caption{Reporting results of existing methods for solving data hyper-cleaning tasks with non-convex LL network structure. Acc and F1 score denote the test accuracy and the harmonic mean of the precision and recall, respectively.}\label{tab:hyper_cleaning_all}
%	\renewcommand\arraystretch{1.2}
%	\setlength{\tabcolsep}{1.5mm}{
	%		\begin{tabular}{|c|c| c|c| c|c|c| c|c|c| }
		%			\hline
		%			\multirow{2}{*} { Method } & \multicolumn{3}{c|} { MNIST } & \multicolumn{3}{c|} { FashionMNIST }  & \multicolumn{3}{c|} { CIFAR10 }\\
		%			\cline { 2 - 10 }
		%			& Acc. & F1 score& Time (s)  & Acc. & F1 score &Time (s) & Acc. & F1 score& Time (s)\\
		%			\hline
		%			CG & $89.19$ & $85.96$ &{\color{blue}$\mathbf{0.1799}$}& $83.15$ & $85.13$ &$0.2041$ &$34.16$&$69.10$&{\color{blue}$\mathbf{0.4796}$}\\
		%			%\hline
		%			Neumann & $87.54$ & $89.58$ &{\color{red}$\mathbf{0.1723}$}& $81.37$ & $87.28$ &{\color{red}$\mathbf{0.1958}$} &$33.45$&$68.87$&{\color{red}$\mathbf{0.4694}$}\\
		%			%\hline
		%			RHG & $87.90$ & $89.36$&$0.4131$& $81.91$ & $87.12$  & $0.4589$&$34.95$&$68.27$&$1.3374$\\
		%			%\hline
		%			T-RHG & $88.57$ & $89.77$ &$0.2623$& $81.85$ & $86.76$ & $0.2840$ &$35.42$&$68.06$&$0.8409$\\
		%			%\hline
		%			BDA & $87.15$ & $90.38$& $0.6694$&  $79.97$ & $88.24$ &$0.8571$ &$36.41$&$67.33$&$1.4869$\\
		%			%\cdashline{1-10}[1.5pt/2pt]
		%			\hline
		%			IAPTT& {\color{red}$\mathbf{90.88}$} & {\color{blue}$\mathbf{91.57}$}&$0.1948$& {\color{blue}$\mathbf{83.67}$} & {\color{blue}$\mathbf{90.37}$} &{\color{blue}$\mathbf{0.2032}$}&{\color{blue}$\mathbf{37.16}$}&{\color{blue}$\mathbf{71.57}$}&$0.6727$\\
		%			%\hline
		%			PIAPTT&{\color{blue}$\mathbf{90.41}$}&{\color{red}$\mathbf{91.95}$}&$0.2086$&{\color{red}$\mathbf{83.80}$}&{\color{red}$\mathbf{90.40}$}&$0.2105$&{\color{red}$\mathbf{37.70}$}&{\color{red}$\mathbf{72.74}$}&$0.6776$\\
		%			\hline
		%		\end{tabular}
	%	}
%	%\vspace{-0.4cm}
%\end{table*}

The goal of data hyper-cleaning is to cleanup the dataset in which the labels have been corrupted. This BLO problem defines the UL variables $\x$ as a vector, and the dimension of $\x$ equals to the number of corrupted samples, while the LL variable $\y$ corresponds to parameters of the classification model. Following the common problem setting of existing works~\cite{shaban2019truncated}, we first split the dataset into three disjoint subsets: $\mathcal{D}_{\mathtt{tr}}$, $\mathcal{D}_{\mathtt{val}}$ and $\mathcal{D}_{\mathtt{test}}$, and then randomly pollute the labels in $\mathcal{D}_{\mathtt{tr}}$ with fixed ratio. Then the UL subproblem can be well defined as
$
F(\mathbf{x}, \mathbf{y})=\sum_{\left(\mathbf{u}_{i}, \mathbf{v}_{i}\right) \in \mathcal{D}_{\mathtt{val}}} \ell\left(\mathbf{y}(\mathbf{x}); \mathbf{u}_{i}, \mathbf{v}_{i}\right), 
$
where $\left(\mathbf{u}_{i}, \mathbf{v}_{i}\right)$ represents the data pairs, $\ell\left(\mathbf{y}(\mathbf{x}); \mathbf{u}_{i}, \mathbf{v}_{i}\right)$ denotes the cross-entropy loss function with classifier parameter $\y$ and data pairs from different subsets. By introducing $\sigma(\mathbf{x})$ as the element-wise sigmoid function to constrain the element in the range of $\left[0,1\right]$, the LL subproblem can be well defined as: $ f(\mathbf{x}, \mathbf{y})=\sum_{\left(\mathbf{u}_{i}, \mathbf{v}_{i}\right) \in \mathcal{D}_{\mathtt{tr}}}[\sigma(\mathbf{x})]_{i} \ell\left(\mathbf{y} ; \mathbf{u}_{i}, \mathbf{v}_{i}\right)$.

 

%\begin{table}[h!]
%	\centering
%	\caption{With convex network structure, we report results of existing GBMs including CG, Neumann, RHG and BDA for solving data hyper-cleaning tasks. $+$IA and $+$PIA denotes the augmentaion version with IA and proximal prior regularization.}\label{tab:hyper cleaning}
%	\renewcommand\arraystretch{1.2}
%	\setlength{\tabcolsep}{1.1mm}{
	%		\begin{tabular}{|c|c| c|c| c| }
		%			\hline
		%			\multirow{2}{*} { Method } & \multicolumn{2}{c|} { MNIST } & \multicolumn{2}{c|}{ CIFAR10} \\
		%			\cline { 2 - 5}
		%			& Acc. & F1 score  & Acc. & F1 score \\
		%			\hline
		%			CG & $89.12$ & $87.51$ &$36.80$ & $68.56$ \\
		%			%\hline
		%			Neumann & $88.90$ & $89.90$ &$35.15$ & $67.79$\\
		%			%\cdashline{1-6}[1.5pt/2pt]
		%			\hline
		%			RHG & $88.96$ & $90.49$& $34.80$ &$69.75$  \\
		%			%\hline
		%			$+$IA& $89.21$ & $91.55$& $37.05$&{\color{blue}$\mathbf{71.94}$} \\
		%			%	\hline
		%			$+$PIA&$89.27$ & $91.61$&{\color{blue}$\mathbf{37.69}$} &$71.30$\\
		%			%\cdashline{1-6}[1.5pt/2pt]
		%			\hline
		%			BDA & $88.55$ & $90.99$ &$35.56$ &$69.58$\\
		%			%\cdashline{1-6}[0.8pt/2pt]
		%			%\hline
		%			
		%			%		\hline
		%			$+$IA&{\color{blue}$\mathbf{89.58}$} &{\color{blue} $\mathbf{91.35}$}& $36.95$&{\color{red}$\mathbf{72.19}$} \\
		%			%	\hline
		%			$+$PIA&{\color{red}$\mathbf{89.63}$} & {\color{red}$\mathbf{91.98}$}& {\color{red}$\mathbf{38.08}$}&$70.75$\\
		%			\hline
		%		\end{tabular}
	%	}
%	%\vspace{-0.4cm}
%\end{table}

\begin{table}[h!]
	\centering
	\caption{With convex network structure, we report results of existing GBMs including CG, Neumann, RHG and BDA for solving data hyper-cleaning tasks. Acc and F1 score denote the test accuracy and the harmonic mean of the precision and recall, respectively. $\textrm{AIT}_{P}$ denotes our AIT with embedded prior regularization.}\label{tab:hyper cleaning}
	\renewcommand\arraystretch{1.2}
	\setlength{\tabcolsep}{1.1mm}{
		\begin{tabular}{|c|c| c|c| c| }
			\hline
			\multirow{2}{*} { Method } & \multicolumn{2}{c|} { MNIST } & \multicolumn{2}{c|}{ CIFAR10} \\
			\cline { 2 - 5}
			& Acc. & F1 score  & Acc. & F1 score \\
			\hline
			CG & $89.12$ & $87.51$ &$36.80$ & $68.56$ \\
			%\hline
			Neumann & $88.90$ & $89.90$ &$35.15$ & $67.79$\\
			%\cdashline{1-6}[1.5pt/2pt]
			%\hline
			RHG & $88.96$ & $90.49$& $34.80$ &$69.75$  \\
			%			%\hline
			%			$+$IA& $89.21$ & $91.55$& $37.05$&{$71.94$} \\
			%			%	\hline
			%			$+$PIA&$89.27$ & $91.61$&{$37.69$} &$71.30$\\
			%\cdashline{1-6}[1.5pt/2pt]
			%\hline
			BDA & $88.55$ & $90.99$ &$35.56$ &$69.58$\\
			%\cdashline{1-6}[0.8pt/2pt]
			\hline
			
			%		\hline
			$\textrm{AIT}$ &{$89.58$} &{$91.35$}& $36.95$&{\color{black}$\mathbf{72.19}$} \\
			%	\hline
			$\textrm{AIT}_{P}$&{\color{black}$\mathbf{89.63}$} & {\color{black}$\mathbf{91.98}$}& {\color{black}$\mathbf{38.08}$}&$70.75$\\
			\hline
		\end{tabular}
	}
	%\vspace{-0.4cm}
\end{table}

\begin{table}[h!]
	%\vspace{-0.4cm} %
	\centering
	\caption{Reporting results of existing methods for solving data hyper-cleaning tasks with non-convex LL network structure.}\label{tab:hyper_cleaning_all}
	\renewcommand\arraystretch{1.2}
	\setlength{\tabcolsep}{1.3mm}{
		\begin{tabular}{|c|c| c|c|c|c|c| }
			\hline
			\multirow{2}{*} { Method } & \multicolumn{2}{c|} { MNIST } & \multicolumn{2}{c|} { FashionMNIST }  & \multicolumn{2}{c|} { CIFAR10 }\\
			\cline { 2 - 7 }
			& Acc. & F1 score & Acc. & F1 score & Acc. & F1 score\\
			\hline
			CG & $89.19$ & $85.96$ & $83.15$ & $85.13$ &$34.16$&$69.10$\\
			%\hline
			Neumann & $87.54$ & $89.58$ & $81.37$ & $87.28$  &$33.45$&$68.87$\\
			%\hline
			RHG & $87.90$ & $89.36$& $81.91$ & $87.12$  &$34.95$&$68.27$\\
			%\hline
			%T-RHG & $88.57$ & $89.77$ & $81.85$ & $86.76$  &$35.42$&$68.06$\\
			%\hline
			BDA & $87.15$ & $90.38$&  $79.97$ & $88.24$ &$36.41$&$67.33$\\
			%\cdashline{1-10}[1.5pt/2pt]
			\hline
			$\textrm{AIT}$ & {\color{black}$\mathbf{90.88}$} & {$91.57$}& {$83.67$} & {$90.37$} &{$37.16$}&{$71.57$}\\
			%\hline
			$\textrm{AIT}_{P}$&{$90.41$}&{\color{black}$\mathbf{91.95}$}&{\color{black}$\mathbf{83.80}$}&{\color{black}$\mathbf{90.40}$}&{\color{black}$\mathbf{37.70}$}&{\color{black}$\mathbf{72.74}$}\\
			\hline
		\end{tabular}
	}
	%\vspace{-0.4cm}
\end{table}


\begin{table*}[!htbp]
	%\vspace{-0.4cm}
	\centering
	\caption{Mean test accuracy of 5-way classification on MiniImageNet and TieredImageNetwith non-convex LL objective. We use $\pm$ to report the accuracy with $95\%$ confidence intervals over tasks. }
	\label{tab:few_shot}
	\renewcommand\arraystretch{1.2}
	\setlength{\tabcolsep}{1.3mm}{
		\begin{tabular}{  |c | c | c | c | c | c| }
			%\toprule
			\hline
			\multirow{2}{*}{Network} &   \multirow{2}{*}{Methods} & \multicolumn{2}{c|}{MiniImagenet} & \multicolumn{2}{c|}{TieredImagenet} \\
			\cline{3-6}
			& & 5-way 1-shot & 5-way 5-shot & 5-way 1-shot & 5-way 5-shot \\
			\cline{1-6}
			%Matching Networks$^{\dag}$&ConvNet-4 &$43.44 \pm 0.77$& $55.31 \pm 0.73$ &-&-\\
			%Meta-learner LSTM$^{\dag}$ & ConvNet-4 & $43.56 \pm 0.84$ & $60.60 \pm 0.71$ &-&-\\
			%Proto Net &ConvNet-4 &$49.42 \pm 1.84\%$& $68.20 \pm 0.66\%$ & $53.31 \pm 0.89\%$ & $72.69 \pm 0.74\%$ \\
			%\hline
			%Relation Net& ConvNet-4 & $50.44 \pm 0.82\%$ & $65.32 \pm 0.70\%$ &$54.48 \pm 0.93\%$&$65.32 \pm 0.70\%$\\
			%\hline
			%LLAMA$^{\dag}$ &  ConvNet-4 & $49.40 \pm 0.83$ &- &&\\
			%CAVIA$^{\dag}$&ConvNet-4 & $47.24 \pm 0.65$ & $59.05 \pm 0.54$ &&\\
			%Meta-SGD$^{\ddag}$ & ConvNet-4  & $50.47\pm1.87$& $64.03\pm 0.94$\\
			%iMAML,HF$^{\dag}$  & ConvNet-4  & $49.30 \pm 1.88$&  - \\	
			%\cline{1-4}
			%\midrule
			%\cdashline{1-4}[0.8pt/2pt]
			\multirow{5}{*}{\rotatebox{0}{ConvNet-4}} & MAML & $48.70 \pm 0.75\%$ &  $63.11\pm 0.11\%$ & $49.06 \pm 0.50\%$ &  $67.48\pm 0.47\%$\\
			%\cline{3-6}
			%\hline
			%\cline{3-6}
			&RHG & $48.89 \pm 0.81\%$ & $63.02 \pm 0.70\%$ & $49.63 \pm 0.67\%$ & $66.14 \pm 0.57\%$\\
			%\cline{3-6}
			%\hline
			&T-RHG & $47.67 \pm 0.82\%$ & $63.70 \pm 0.76\%$ & $50.79 \pm 0.69\%$ & $67.39 \pm 0.60\%$\\
			%\hline
			
			&BDA& $49.08 \pm 0.82\%$ & $62.17 \pm 0.70\%$ & $51.56 \pm 0.68\%$ & $\mathbf{68.21 \pm 0.58}\%$\\
			%\hline
			%ANIL& ConvNet-4 & $48.00 \pm 0.70$ & $62.20 \pm 0.50$ & $51.36 \pm 0.67$ & $66.60 \pm 0.58$\\
			%\cdashline{1-6}[0.8pt/2pt]	
			%ReMeta(Baseline)& 4Conv &$49.33 \pm 0.10$ & $64.76 \pm 0.09$&-&- \\
			%ReMeta(ours)& 32-32-32-32 &$49.87 \pm 0.10 $ & $64.76 \pm 0.09$ \\
			&$\textrm{AIT}$  &$\mathbf{49.80 \pm 0.61\%} $ & $\mathbf{64.76 \pm 0.54\%}$ & $\mathbf{51.86 \pm 0.68\%}$ &$68.01 \pm 0.60\%$\\
			%\cline{1-6}
			%ReMeta(Conv+fc) & 4Conv&$49.80\pm 0.10 $& $64.25 \pm 0.08$& $51.86 \pm 0.11$ & \\
			%ReMeta(Distance Norm)& 32-32-32-32 &$49.42\pm 0.10 $& $64.74 \pm 0.08$ \\
			%ReMeta(p norm)& 32-32-32-32 &$49.53\pm 0.09 $&$64.58 \pm 0.08$\\
			%\hline
			%\cdashline{1-6}[1.5pt/2pt]
			\hline
			\multirow{3}{*}{\rotatebox{0}{ResNet-12}}&MAML & $51.03 \pm 0.50\%$ &  {\color{black}${68.26\pm 0.47}\%$ }& {\color{black}${58.58\pm 0.49}\%$} &  $71.24\pm 0.43\%$  \\
			%\hline
			
			&RHG &{\color{black}${ 50.54\pm 0.85}\%$} & $64.53 \pm 0.68\%$ & $58.19 \pm 0.76\%$ &{\color{black}${75.20 \pm 0.60}\%$}\\
			%&T-RHG &{\color{black}${ 50.54\pm 0.85}\%$} & $64.53 \pm 0.68\%$ & $58.19 \pm 0.76\%$ &{\color{black}${75.20 \pm 0.60}\%$}\\
			%&BDA &{\color{black}${ 50.54\pm 0.85}\%$} & $64.53 \pm 0.68\%$ & $58.19 \pm 0.76\%$ &{\color{black}${75.20 \pm 0.60}\%$}\\
			%\hline                                                                                                {\color{blue}$\mathbf{
					%SNAIL$^{\dag}$ &ResNet-12& $55.71 \pm 0.99$ & $68.88 \pm 0.92$ \\
					%\cdashline{1-4}[0.8pt/2pt]
					%ReMeta(Baseline)& 4Conv &$49.33 \pm 0.10$ & $64.76 \pm 0.09$&-&- \\
					%ReMeta(Baseline)& ResNet-12 &$56.69 \pm 0.11$ & $68.21 \pm 0.09$ \\
					%\cdashline{1-6}[0.8pt/2pt]
					&$\textrm{AIT}$ &{\color{black}$\mathbf{56.69 \pm 0.66}\%$} & {\color{black}$\mathbf{70.21 \pm 0.55}\%$} &{\color{black}$\mathbf{60.71 \pm 0.77}\%$}& {\color{black} $\mathbf{75.85 \pm 0.59}\%$} \\
					%PIAPTT&&&&&\\
					%\bottomrule
					\hline
				\end{tabular}
			}
			%\vspace{-0.4cm}
		\end{table*}

Typically, to satisfy the LLC assumption admitted by existing GBMs, the LL classification model is usually defined as a single fully-connected layer, and multiple-layer classifier with more parameters are not accessible.  Based on the AIT, the constraints could be continuously relaxed thus we have more choices when designing the LL model.  Besides, the prior regularization also serves as effective tool to help improve the performance of AIT. To find prior determined value $\z_{p}$ for the IA, (i.e., $\z$), we pretrain the LL classification model on $\mathcal{D}_{\textrm{tr}}$ and restore the pretrained model weights as the proximal prior to adjust the updates and facilitate the convergence behavior of $\z$. Then we could specify the form of prior regularization  in Eq.~\eqref{eq:proximal_prior}. Practically, we implement the prior regularization  $g(\z)$ as $\ell_2$ regularization, and add this term only for the first iteration to investigate how this regularization term influence the latter optimization process. Three well known datasets including MNIST, FashionMNIST and CIFAR10 are used to conduct the experiments. Specifically, 5000, 5000, 10000 samples are randomly selected to construct $\mathcal{D}_{\mathtt{tr}}$, $\mathcal{D}_{\mathtt{val}}$ and $\mathcal{D}_{\mathtt{test}}$, then half of the labels in $\mathcal{D}_{\mathtt{tr}}$ are tampered.


We first implement this application with convex LL network structure including a single-layer fully-connected classifier. Then the shape of $\y$ is $\y\in\mathbb{R}^{10\times d}$, where $d$ denotes the dimension of the flattened input data. In Tab.~\ref{tab:hyper cleaning}, we compare our AIT with CG, Neumann, RHG and BDA. As it has been verified in the numerical experiments before, we can observe that AIT helps improve the performance on both Accuracy and F1 score based on MNIST and CIFAR10 dataset. Besides, though the  prior regularization term only exists in the first iteration, it helps correct the initial state of constructed optimization dynamics, and further improves the performance of AIT on both datasets. 




In addition, we introduce the non-convex network structure with two layers of fully-connected network to expand the search space of LL subproblem, where $\y\in\mathbb{R}^{10\time 301}\times\mathbb{R}^{301\times d}$. In Tab.~\ref{tab:hyper_cleaning_all}, we compare our $\textrm{AIT}$ and the variation with prior regularization, (i.e., $\textrm{AIT}_{P}$) with RHG, BDA, CG and Neumann on validation accuracy, F1 score and running time. As it is shown, our method performs the best compared with other GBMs on both accuracy and F1 score. Besides, although only used as a practical technique for solving non-convex BLOs, the embedded proximal prior also consistently improve the performance of $\textrm{AIT}_{P}$ on three datasets. 


\subsubsection{Few-Shot Learning}


	
Few-shot learning applications, more specifically, the few-shot classification tasks~\cite{lecun1998gradient}, train the model to classify unseen instances with only a few samples based on prior training data of similar tasks. As for the N-way K-shot classification, we first define the training dataset as $\mathcal{D}=\{\mathcal{D}^{j}\}$, where $\mathcal{D}^{j}=\mathcal{D}_\mathtt{tr}^{j}\bigcup\mathcal{D}_{\mathtt{val}}^{j}$ corresponds to the meta-train and meta-validation set for the $j\textrm{-th}$ task. In the training phase, we select $K$ samples from each of the $N$ classes in $\mathcal{D}_{\mathtt{tr}}$ for meta training, and use more data from these classes in $\mathcal{D}_{\mathtt{val}}$ for meta validation. Then in the test phase, we construct new tasks on test dataset under the same data distribution to test the performance. 

We follow the commonly used parameter setting for GBMs, where the UL variables $\x$ correspond to the shared hyper representation module model, while the LL variables $\y$ correspond to the task-specific classifier. For this classification problem, the cross-entropy function (denoted as $\ell$) is commonly used for the LL objective $f$ and UL objective $F$.  Besides,~$\ell_{q} $ regularization with $ 0<q<1 $ can be applied to stabilize the training and effectively avoid over-fitting, while existing methods only guarantee the convergence for convex scenario where $q \geq 1$, our AIT supports more flexible non-convex LL objective without the LLC or LLS constraints. Then we add $\|{\y^{j}}\|_{q}$ as the non-convex regularization term to define the LL objectives as 
$F\left(\mathbf{x},\left\{\mathbf{y}^{j}\right\}\right)=\sum_{j} \ell\left(\mathbf{x}, \mathbf{y}^{j}; \mathcal{\D}_{\mathtt{val}}^{j}\right), f\left(\mathbf{x},\left\{\mathbf{y}^{j}\right\}\right)=\sum_{j} \ell\left(\mathbf{x}, \mathbf{y}^{j} ; \mathcal{\D}_{\mathtt{tr}}^{j}\right)+ \|{\y^{j}}\|_{q}.\nonumber
$
The above implementation of non-convex LL objective implies another class of complex LL subproblem for BLOs, which could be used to verify the significant improvement of AIT.

We implement $5$-way $1$-shot and $5$-way $5$-shot classification tasks to validate the performance based on MiniImagenet~\cite{vinyals2016matching} and TieredImagenet~\cite{ren2018meta} datasets. Both datasets are subsets constructed from the larger ILSVRC-12 dataset, while TieredImagenet includes more classes than MiniImagenet. Besides, TieredImagenet categorizes the source data with hierarchical structure to split the training and test datasets and also simulates more real scenarios. 

In Tab.~\ref{tab:few_shot}, we compare our AIT with representative methods including MAML~\cite{finn2017model}, RHG, T-RHG~\cite{shaban2019truncated} and BDA. We also consider two structures as the backbones of hyper representation module, including ConvNet-4 with $4$ layers of convolutional blocks and the larger ResNet-12 with Residual blocks. We use a single fully-connected layer as the task-specific classifier for both backbones. For MAML, the hyper representation module and the classifier are treated as a whole and update as the initialization parameters. We first use ConvNet-4 as the backbone and compare AIT with RHG, T-RHG, BDA and MAML, then we also implement the ResNet-12 backbone and compare AIT with initialization based (i.e., MAML) and recurrence based methods (i.e., RHG). As it is shown in \ref{tab:few_shot}, for the 5-way 1-shot and 5-way 5-shot classification tasks on MiniImagenet and TieredImagenet, AIT shows significant performance improvement on the accuracy with different backbones as the hyper representation module.

%\subsection{}
%To further validate the generality and consistent performance of our IAPTT , we conduct the experiments on two real world BLO tasks, including neural architecture search and generative adversarial networks.
\subsection{Extensions for More Challenging Tasks} 

In this subsection, we first implement AIT to solve large-scale and high-dimensional real-world BLO applications, e.g., neural architecture search. Then we move on to other complex deep learning models, e.g., generative adversarial networks, to demonstrate its generalization performance.   
\subsubsection{Neural Architecture Search}

We denote the training set, validation set, and test set as $(\mathcal{D}_{\mathtt{tr}}, \mathcal{D}_{\mathtt{val}}, \mathcal{D}_{\mathtt{test}})$, then the UL objective and LL objective can be written as $F\left(\x, \y; \mathcal{\D}_{\mathtt{val}}\right)$ and $f\left(\x, \y; \mathcal{\D}_{\mathtt{tr}}\right)$. Then we follow the standard training strategies in DARTS, which consists of the searching and the inference stages. As for the searching stage, DARTS executes a single-step LL optimization (Step \ref{inner_loop1} in Alg.\ref{alg:innerloop}) with $f\left(\mathbf{x}, \mathbf{y}; \mathcal{\D}_{\mathtt{tr}}\right)$, and continuously optimizes the architecture parameter $\x$ (Step \ref{indirect_gradient} in Alg.\ref{alg:innerloop}) to find better cell structures according to the UL objectives  $F\left(\mathbf{x}, \mathbf{y}; \mathcal{\D}_{\mathtt{val}}\right)$. When it comes to the inference stage, the architecture parameter $\x$ is fixed, and we reuse the searched cell structure to construct larger architecture and train it from scratch based on $\mathcal{D}_{\mathtt{tr}}$. Finally, we test the performance of trained model at the inference stage on $\mathcal{D}_{\mathtt{test}}$. In this paper, we conduct the experiments on CIFAR-10 dataset, and use the same search space and similar experimental settings of DARTS. The stacked cell for final architecture has two types, including reduction cells and normal cells. In the reduction cell, operations adjacent to the input nodes use stride 2 to reduce the input shape, while normal cells maintain the original shape with stride 1 for the first two nodes. We use $3$ layers of cells for searching with $50$ epochs and construct larger structure with $8$ layers of the searched cells, and train the model from scratch with 600 epochs in total. %The search space contains following operations: $3\times3$ and $5\times5$ separable convolutions, $3\times3$ and $5\times5$ dilated separable convolutions, $3\times3$ max pooling, $3\times3$ average pooling, identity and zero. 

\begin{figure}[h!]
	\begin{center}
		\renewcommand\arraystretch{0.8}
		\begin{tabular}{c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}}
			\includegraphics[height=3.5cm,width=4.5cm,trim=0 0 0. 0,clip]{NAS/nas_acc_eval.eps}&\includegraphics[height=3.5cm,width=4.5cm,trim=0 0 0. 0,clip]{NAS/nas_acc.eps}\\
			%\specialrule{0em}{1pt}{3pt}
			\specialrule{0em}{0pt}{0pt}
			\footnotesize (a) Validation Loss &\footnotesize (b) Validation Accuracy\\
		\end{tabular}
	\end{center}
	%\vspace{-0.4cm}
	\caption{Comparison of the validation loss and accuracy of DARTS, CG, RHG and AIT in the searching process.}\label{nas_acc}
\end{figure} 



%\begin{table}[h!]
%	%\vspace{-0.4cm} %
%	\centering
%	\caption{Reporting top 1 accuracy of searching stage, inference stage and final test for DARTS, RHG, CG and IAPTT. We test the performance of IAPTT with different LL optimization step, including $K=1$ and $K=2$.}\label{tab:nas_acc}
%	\renewcommand\arraystretch{1.4}
%	\setlength{\tabcolsep}{1.5mm}{
	%		\begin{tabular}{|c|c|c|c| c|c| }
		%			\hline
		%			\multirow{2}{*}{Method}& \multicolumn{2}{c|}{Searching}&\multicolumn{2}{c|}{Inference}&\multirow{2}{*}{Test}\\%&\multirow{2}{*}{Params}  \\
		%			\cline{2-5}
		%			&Train &Valid&Train&Valid&  \\%&\\
		%			\hline
		%			DARTS &$98.320$&$88.940$&$97.952$&$96.710$&$96.670$\\%&$1.277$\\
		%			%PC-DARTS &$88.128$&& $96.749$ &$1.664$&&  &\\
		%			RHG&$98.448$&$89.556$&$98.494$& $97.010$&$96.920$\\%&$1.359$\\
		%			CG &{\color{red}$\mathbf{99.126}$}&$89.298$&$98.286$&$96.690$&$96.640$\\%&$1.359$\\
		%			
		%			%\hline
		%			%\cdashline{1-6}[1.5pt/2pt]
		%			\hline
		%			IAPTT ($K=1$) &{\color{blue}$\mathbf{98.960}$}&{\color{red}$\mathbf{99.526}$}&{\color{blue}$\mathbf{98.702}$}& {\color{blue}$\mathbf{97.190}$}&{\color{blue}$\mathbf{97.160}$}\\%&$\mathbf{1.963}$ \\
		%			IAPTT ($K=2$) &$98.904$&{\color{blue}$\mathbf{99.512}$}&{\color{red}$\mathbf{98.718}$}& {\color{red}$\mathbf{97.470}$}&{\color{red}$\mathbf{97.330}$}\\%&$\mathbf{1.963}$ \\
		%			\hline
		%		\end{tabular}
	%	}stage
%	%\vspace{-0.4cm}
%\end{table}



%\begin{figure*}[htbp]
%	\begin{center}
%		\renewcommand\arraystretch{0.1}
%		\begin{tabular}{c@{\extracolsep{0.5em}}c@{\extracolsep{0.1em}}c|@{\extracolsep{1.0em}}c@{\extracolsep{0.5em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}}
%			%\specialrule{0.01em}{3pt}{3pt}
%			\multirow{2}{*}{\rotatebox{90}{Normal Cell~~~~~~~~~~}}&&			&\multirow{2}{*}{\rotatebox{90}{Reduction Cell~~~~~~~~}} &&\\
%			&\includegraphics[height=1.6cm,width=3.6cm,trim=0 0 0 0,clip]{NAS/normal_DARTS.pdf} &\includegraphics[height=1.6cm,width=4cm,trim= 0 0 0 0,clip]{NAS/normal_RHG.pdf}	&&\includegraphics[height=1.8cm,width=4cm,trim=0 0 0 0,clip]{NAS/reduction_DARTS.pdf}&			\includegraphics[height=1.8cm,width=4cm,trim=0 0 0 0,clip]{NAS/reduction_RHG.pdf}	\\
%			&\footnotesize (a) DARTS &\footnotesize (b) RHG  &&\footnotesize (a) DARTS &\footnotesize (b) RHG\\
%			&\includegraphics[height=1.4cm,width=4cm,trim= 0 0 0 0,clip]{NAS/normal_CG.pdf}&	\includegraphics[height=1.4cm,width=4cm,trim= 0 0 0 0,clip]{NAS/normal_IAPTT.pdf} &&\includegraphics[height=1.4cm,width=4cm,trim=0 0 0 0,clip]{NAS/reduction_CG.pdf}&\includegraphics[height=1.4cm,width=4cm,trim=0 0 0 0,clip]{NAS/reduction_IAPTT.pdf}\\
%			&\footnotesize (c) CG &\footnotesize (d) AIT& &\footnotesize (c) CG &\footnotesize (d) AIT\\
%			%\specialrule{0.01em}{3pt}{3pt}
%			
%			
%			%\specialrule{0.01em}{3pt}{3pt}
%		\end{tabular}
%	\end{center}
%	%\vspace{-0.4cm}
%	\caption{Visualization results of the searched architecture of normal cell and reduction cell for DARTS, RHG, CG and AIT.}\label{nas_architect}
%\end{figure*}



In Fig.~\ref{nas_acc}, we report the validation loss and accuracy after each epoch to evaluate the convergence behavior of DARTS, RHG, CG and our AIT. It can be seen that RHG, CG and DARTS gain similar validation performance on this non-convex BLO application, while AIT significantly improves the convergence results on $\mathcal{D}_{\textrm{val}}$. Noticed that several works~\cite{chu2020fair, arber2020understanding} found that DARTS may find the global minimum with very small search space but it starts overfitting the architecture parameters on $\mathcal{D}_{\textrm{val}}$, which leads to poor generalization performance. To demonstrate that the searched architecture has consistent performance, in Tab.~\ref{tab:nas_acc}, we also report the accuracy on $\mathcal{D}_{\mathtt{tr}}$ and $\mathcal{D}_{\mathtt{val}}$ at different stages. It can be observed that only AIT maintains better performance on both $\mathcal{D}_{\textrm{tr}}$ and $\mathcal{D}_{\textrm{val}}$, and it also improves the test performance of finally constructed network structure by a large margin.


\begin{table}[h!]
	%\vspace{-0.4cm} %
	\centering
	\caption{Reporting top 1 accuracy of searching stage, inference stage, final test stage for DARTS, RHG, CG and AIT. We also report the number of parameters of the searched structure (MB) for different methods.}\label{tab:nas_acc}
	\renewcommand\arraystretch{1.4}
	\setlength{\tabcolsep}{1.5mm}{
		\begin{tabular}{|c|c|c|c| c|c| c|}
			\hline
			\multirow{2}{*}{Method}& \multicolumn{2}{c|}{Searching}&\multicolumn{2}{c|}{Inference}&\multirow{2}{*}{Test}&\multirow{2}{*}{Params}  \\
			\cline{2-5}
			&Train &Valid&Train&Valid&  &\\
			\hline
			DARTS &$98.320$&$88.940$&$97.952$&$96.710$&$96.670$&$1.277$\\
			%PC-DARTS &$88.128$&& $96.749$ &$1.664$&&  &\\
			RHG&$98.448$&{$89.556$}&{\color{black}$98.494$}& {\color{black}$97.010$}&{\color{black}$96.920$}&$1.359$\\
			CG &{\color{black}$\mathbf{99.126}$}&$89.298$&$98.286$&$96.690$&$96.640$&$1.268$\\
			
			%\hline
			%\cdashline{1-6}[1.5pt/2pt]
			\hline
			%IAPTT ($K=1$) &{\color{blue}$\mathbf{98.960}$}&{\color{red}$\mathbf{99.526}$}&{\color{blue}$\mathbf{98.702}$}& {\color{blue}$\mathbf{97.190}$}&{\color{blue}$\mathbf{97.160}$}\\%&$\mathbf{1.963}$ \\
			AIT &$98.904$&{\color{black}$\mathbf{99.512}$}&{\color{black}$\mathbf{98.718}$}& {\color{black}$\mathbf{97.470}$}&{\color{black}$\mathbf{97.330}$}&$\mathbf{1.963}$ \\
			\hline
		\end{tabular}
	}
	%\vspace{-0.4cm}
\end{table}
%
%\begin{figure}[htbp]
%	\begin{center}
%		\renewcommand\arraystretch{0.1}
%		\begin{tabular}{c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}}
%			\specialrule{0.01em}{3pt}{3pt}
%			\multirow{2}{*}{\rotatebox{90}{Normal Cell~~~~~~~~~}}&&\\
%			&\includegraphics[height=1.6cm,width=3.6cm,trim=0 0 0 0,clip]{NAS/normal_DARTS.pdf} &\includegraphics[height=1.6cm,width=4cm,trim= 0 0 0 0,clip]{NAS/normal_RHG.pdf}	\\
%			&\footnotesize (a) DARTS &\footnotesize (b) RHG \\
%			&\includegraphics[height=1.4cm,width=4cm,trim= 0 0 0 0,clip]{NAS/normal_CG.pdf}&	\includegraphics[height=1.4cm,width=4cm,trim= 0 0 0 0,clip]{NAS/normal_IAPTT.pdf}\\
%			\multirow{2}{*}{\rotatebox{90}{Reduction Cell~~~~~~~~~~}}&\footnotesize (c) CG &\footnotesize (d) AIT \\
%			\specialrule{0.01em}{3pt}{3pt}
%			&\includegraphics[height=1.8cm,width=4cm,trim=0 0 0 0,clip]{NAS/reduction_DARTS.pdf}&			\includegraphics[height=1.8cm,width=4cm,trim=0 0 0 0,clip]{NAS/reduction_RHG.pdf}		\\	
%			&\footnotesize (a) DARTS &\footnotesize (b) RHG\\
%			&\includegraphics[height=1.4cm,width=4cm,trim=0 0 0 0,clip]{NAS/reduction_CG.pdf}&\includegraphics[height=1.4cm,width=4cm,trim=0 0 0 0,clip]{NAS/reduction_IAPTT.pdf}\\
%			&\footnotesize (c) CG &\footnotesize (d) AIT\\
%			\specialrule{0.01em}{3pt}{3pt}
%		\end{tabular}
%	\end{center}
%	%\vspace{-0.4cm}
%	\caption{Visualization results of the searched normal cell and reduction cell for DARTS, RHG, CG and AIT. Note that the edges with blue fonts denote operations with less parameters such as skip connections and pooling operations, and edges with red fonts denote more complex operations such as $5\times5$ separable convolutions.}\label{nas_architect}
%\end{figure}
\begin{figure}[htbp]
	\begin{center}
		\renewcommand\arraystretch{0.1}
		\begin{tabular}{c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}}
			\specialrule{0.01em}{3pt}{3pt}
			\multirow{2}{*}{\rotatebox{90}{Normal Cell~~~~~~~~~}}&&\\
			&\includegraphics[height=1.6cm,width=4cm,trim=0 0 0 0,clip]{NAS/normal_DARTS.pdf} &\includegraphics[height=1.6cm,width=4cm,trim= 0 0 0 0,clip]{NAS/normal_RHG.pdf}	\\
			&\footnotesize (a) DARTS &\footnotesize (b) RHG \\
			&\includegraphics[height=1.4cm,width=4cm,trim= 0 0 0 0,clip]{NAS/normal_CG.pdf}&	\includegraphics[height=1.4cm,width=4cm,trim= 0 0 0 0,clip]{NAS/normal_IAPTT.pdf}\\
			\multirow{2}{*}{\rotatebox{90}{Reduction Cell~~~~~~~~~~}}&\footnotesize (c) CG &\footnotesize (d) AIT \\
			\specialrule{0.01em}{3pt}{3pt}
			&\includegraphics[height=1.8cm,width=4cm,trim=0 0 0 0,clip]{NAS/reduction_DARTS.pdf}&			\includegraphics[height=1.8cm,width=4cm,trim=0 0 0 0,clip]{NAS/reduction_RHG.pdf}		\\	
			&\footnotesize (a) DARTS &\footnotesize (b) RHG\\
			&\includegraphics[height=1.8cm,width=4cm,trim=0 0 0 0,clip]{NAS/reduction_CG.pdf}&\includegraphics[height=1.8cm,width=4cm,trim=0 0 0 0,clip]{NAS/reduction_IAPTT.pdf}\\
			&\footnotesize (c) CG &\footnotesize (d) AIT\\
			\specialrule{0.01em}{3pt}{3pt}
		\end{tabular}
	\end{center}
	%\vspace{-0.4cm}
	\caption{Visualization results of the searched normal cell and reduction cell for DARTS, RHG, CG and AIT. Note that the edges with blue fonts denote operations with less parameters such as skip connections and pooling operations, and edges with red fonts denote more complex operations such as $5\times5$ separable convolutions.}\label{nas_architect}
\end{figure}




%\begin{figure*}[htbp]
%	\begin{center}
%		\renewcommand\arraystretch{0.1}
%		\begin{tabular}{c@{\extracolsep{0.5em}}c@{\extracolsep{0.1em}}c|@{\extracolsep{1.0em}}c@{\extracolsep{0.5em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}}
%			%\specialrule{0.01em}{3pt}{3pt}
%			\multirow{2}{*}{\rotatebox{90}{Normal Cell~~~~~~~~~~}}&&			&\multirow{2}{*}{\rotatebox{90}{Reduction Cell~~~~~~~~}} &&\\
%			&\includegraphics[height=1.6cm,width=3.6cm,trim=0 0 0 0,clip]{NAS/normal_DARTS.pdf} &\includegraphics[height=1.6cm,width=4cm,trim= 0 0 0 0,clip]{NAS/normal_RHG.pdf}	&&\includegraphics[height=1.8cm,width=4cm,trim=0 0 0 0,clip]{NAS/reduction_DARTS.pdf}&			\includegraphics[height=1.8cm,width=4cm,trim=0 0 0 0,clip]{NAS/reduction_RHG.pdf}	\\
%			&\footnotesize (a) DARTS &\footnotesize (b) RHG  &&\footnotesize (a) DARTS &\footnotesize (b) RHG\\
%			&\includegraphics[height=1.4cm,width=4cm,trim= 0 0 0 0,clip]{NAS/normal_CG.pdf}&	\includegraphics[height=1.4cm,width=4cm,trim= 0 0 0 0,clip]{NAS/normal_IAPTT.pdf} &&\includegraphics[height=1.4cm,width=4cm,trim=0 0 0 0,clip]{NAS/reduction_CG.pdf}&\includegraphics[height=1.4cm,width=4cm,trim=0 0 0 0,clip]{NAS/reduction_IAPTT.pdf}\\
%			&\footnotesize (c) CG &\footnotesize (d) AIT& &\footnotesize (c) CG &\footnotesize (d) AIT\\
%			%\specialrule{0.01em}{3pt}{3pt}
%			
%			
%			%\specialrule{0.01em}{3pt}{3pt}
%		\end{tabular}
%	\end{center}
%	%\vspace{-0.4cm}
%	\caption{Visualization results of the searched normal cell and reduction cell for DARTS, RHG, CG and AIT. Note that the edges with blue fonts denote operations with less parameters such as skip connections and pooling operations, and edges with red fonts denote more complex operations such as $5\times5$ separable convolutions.}\label{nas_architect}
%\end{figure*}

\begin{figure*}[h!]
	\begin{center}
		\begin{tabular}{c@{\extracolsep{0.5em}}c|@{\extracolsep{2.5em}}@{\extracolsep{1em}}c@{\extracolsep{1.5em}}c@{\extracolsep{1.5em}}c@{\extracolsep{1.5em}}c@{\extracolsep{1.5em}}}
			\rotatebox{90}{~~2D~Pentagram}&\includegraphics[height=2.3cm,width=3cm,trim=0 0 0 30,clip]{figures/GAN/Target10div.pdf} &\includegraphics[height=2.3cm,width=3cm,trim=0 0 0 30,clip]{figures/GAN/GAN10div.pdf}
			& \includegraphics[height=2.3cm,width=3cm,trim=0 0 0 30,clip]{figures/GAN/WGAN10div.pdf} &\includegraphics[height=2.3cm,width=3cm,trim=0 0 0 30,clip]{figures/GAN/RHG10div.pdf}
			&\includegraphics[height=2.3cm,width=3cm,trim=0 0 0 30,clip]{figures/GAN/IAPTT10div.pdf}\\
			%\hline
			%\specialrule{0.05em}{5pt}{5pt}
			%			\rotatebox{90}{~~~~~ Cube}&\includegraphics[height=2.5cm,width=3cm,trim=0 0 0 0,clip]{figures/cube/Target10div3.pdf} &\includegraphics[height=2.5cm,width=3cm,trim=0 0 0 0,clip]{figures/cube/GAN10div3.pdf}
			%			& \includegraphics[height=2.5cm,width=3cm,trim=0 0 0 0,clip]{figures/cube/WGAN10div3.pdf} &\includegraphics[height=2.5cm,width=3cm,trim=0 0 0 0,clip]{figures/cube/RHG10div3.pdf}
			%			&\includegraphics[height=2.5cm,width=3cm,trim=0 0 0 0,clip]{figures/cube/IAPTT10div3.pdf}\\
			&Target &(a) VGAN & (b) WGAN	
			&(c) UGAN & (d) AIT\\
		\end{tabular}
	\end{center}
	%\vspace{-0.4cm}
	\caption{We report the results based on the synthesized distribution of 2D Pentagram, and compare AIT with existing GAN methods including VGAN, WGAN and UGAN.}\label{GAN_plot}
\end{figure*}

Besides, it have been investigated~\cite{arber2020understanding} that DARTS tends to choose more parameter-less operations such as skip connection instead of convolution since the skip connection often leads to rapid gradient descent especially on the proxy datasets which are small and easy to fit. As a result, the generated structure may contains less learnable parameters to some extent. In Fig.~\ref{nas_architect}, we illustrate the searched structure for normal cells and reduction cells to show the difference between these GBMs and AIT. As it is depicted, since DARTS derives approximative hyper-gradient w.r.t. $\x$ compared to RHG, both of them found similar structure while RHG uses complex edges with more parameters as reported in Tab.~\ref{tab:nas_acc}. Besides, though CG found significantly different structures from DARTS and RHG, it has no guarantee of convergence and generalization performance on the test set. In comparison, with convergence guarantee, AIT constructs normal cells and reduction cells with more complex separable convolutions, thus significantly improve the expression ability and generalization performance of the searched architecture.      


\subsubsection{Generative Adversarial Networks}



%\begin{figure*}[htbp]
%	\begin{center}
	%		\begin{tabular}{c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}c@{\extracolsep{0.1em}}}
		%			\includegraphics[height=2.5cm,width=3cm,trim=0 0 0 0,clip]{figures/Target10div3.eps} &\includegraphics[height=2.5cm,width=3cm,trim=0 0 0 0,clip]{figures/SN10div3.eps}
		%			& \includegraphics[height=2.5cm,width=3cm,trim=0 0 0 0,clip]{figures/Prox10div3.eps} &\includegraphics[height=2.5cm,width=3cm,trim=0 0 0 0,clip]{figures/WGAN10div3.eps}
		%			& \includegraphics[height=2.5cm,width=3cm,trim=0 0 0 0,clip]{figures/RHG10div3.eps} 
		%			&\includegraphics[height=2.5cm,width=3cm,trim=0 0 0 0,clip]{figures/IAPTT10div3.eps}\\
		%			Target &(a) VGAN & (b) ProxGAN	
		%			&(c)WGAN &(d) RHG & (e)IAPTT\\
		%		\end{tabular}
	%	\end{center}
%	%\vspace{-0.4cm}
%	\caption{We report the results based on  the synthesized data of 3d cube, and compare IAPTT with existing GAN based methods including GAN, WGAN, ProxGAN and RHG.}\label{GAN_plot}
%\end{figure*}




%Besides, unrolled GAN~\cite{metz2016unrolled} models the relationship of generator and discriminator from bilevel perspective, while it takes no consideration of intrinsic theoretical property of this BLO reformulation. 

In practice, we conduct the experiments with synthesized 2 dimensional mixture of Gaussian distributions. Specifically, we generate 10 Gaussians to form the shape of pentagram with maximum radius $r=8$. In Fig.~\ref{GAN_plot}, we compare the visualization results generated by the VGAN, Unrolled GAN~\cite{metz2016unrolled} (UGAN), WGAN and AIT. It can be seen that AIT generates more modes than the above methods to fit the target distribution. In comparison, the original GAN methods only capture a small number of distribution, which also shows the effectiveness of AIT to solve GAN based applications. As for the quantitative results, in Tab.~\ref{tab:GAN_results}, we report three commonly used metrics including Frechet Inception Distance (FID)~\cite{goodfellow2014generative}, Jensen-Shannon divergence (JS)~\cite{heusel2017gans}, number of Modes (Mode) . In comparison, our AIT not only always generate all the modes with different random seeds, but also gains significant performance improvement on both JS and FID.
\begin{table}[h!]
	%\vspace{-0.4cm} %
	\centering
	\caption{Reporting results of existing methods for the 2D Pentagram Gaussian distribution bu running the experiment with $3$ random seeds. We use different seeds to run the experiments and compare our AIT with VGAN, UGAN and WGAN on three metrics.}\label{tab:GAN_results}
	\renewcommand\arraystretch{1.4}
	\setlength{\tabcolsep}{1.5mm}{
		\begin{tabular}{|c|c|c|c|}
			\hline
			\multirow{2}[0]{*}{\footnotesize Method} & \multicolumn{3}{c|}{2D Pentagram (Max Mode=10)} \\
			\cline{2-4}		
			& \footnotesize  FID  & \footnotesize  JS  & \footnotesize Mode\\
			\hline
			\footnotesize VGAN  &  \footnotesize 1.214 $\pm$ 0.37  &  \footnotesize 0.191 $\pm$ 0.094 &  \footnotesize 8.00 $\pm$ 0.00\\
			\footnotesize WGAN  & \footnotesize  2.404 $\pm$ 3.80 & \footnotesize 0.746 $\pm$ 0.064 & \footnotesize 3.33 $\pm$ 2.52\\
			\footnotesize UGAN  & \footnotesize 2.355 $\pm$ 2.93 & \footnotesize 0.762 $\pm$ 0.083 & \footnotesize 3.33 $\pm$ 2.89\\
			\hline
			\footnotesize AIT  & \textbf{ \footnotesize 0.256 $\pm$ 0.13 } &\textbf{\footnotesize  0.187 $\pm$ 0.046 } & \textbf{ \footnotesize 10.00 $\pm$ 0.00 }\\
			\hline			
		\end{tabular}%
	}	 
	%\vspace{-0.4cm}
\end{table}

\section{Conclusion}
To summarize, our approach involves a thorough analysis of the gradient-based BLO scheme, identifying two significant deficiencies of the existing iterative trajectory. To address these deficiencies, we propose two augmentation techniques, namely Initialization Auxiliary (IA) and Pessimistic Trajectory Truncation (PTT), and develop a series of variations based on these techniques, such as prior regularization and different forms of acceleration dynamics, to construct our Augmented Iterative Trajectory (AIT) for both convex and non-convex scenarios (i.e., $\textrm{AIT}_{C}$ and $\textrm{AIT}_{NC}$). Theoretically, we establish detailed convergence analysis of AIT for different types of BLOs, which fills the gap in non-convex theory. Finally, we conduct a series of experiments on various BLO settings using numerical examples, and demonstrate the effectiveness of our approach on typical learning and vision tasks as well as more challenging deep learning models such as NAS and GANs.   



% if have a single appendix:
%\appendix[Proof of the Zonklar Equations]
% or
%\appendix  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed

% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)
%


%\appendices
%\section{Proof of the First Zonklar Equation}
%Appendix one text goes here.
%
%% you can choose not to have a title for an appendix
%% if you want by leaving the argument blank
%\section{}
%Appendix two text goes here.


% use section* for acknowledgment
\ifCLASSOPTIONcompsoc
% The Computer Society usually uses the plural form
\section*{Acknowledgments}
\else
% regular IEEE prefers the singular form
\section*{Acknowledgment}
\fi

This work is partially supported by the National Key R\&D Program of China (2022YFA1004101), the National Natural Science Foundation of China (Nos. U22B2052, 61922019, 12222106), the Shenzhen Science and Technology Program (No. RCYX20200714114700072), the Pacific Institute for the Mathematical Sciences (PIMS), and the Guangdong Basic and Applied Basic Research Foundation (No. 2022B1515020082).


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
\newpage
\fi



% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
\bibliographystyle{IEEEtran}
\bibliography{reference}

%\begin{thebibliography}{1}
%
%\bibitem{IEEEhowto:kopka}
%H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
%  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.
%
%\end{thebibliography}

% biography section
% 
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:

%\begin{IEEEbiography}{Michael Shell}
%	Biography text here.
%\end{IEEEbiography}
%
%% if you will not have a photo at all:
%\begin{IEEEbiographynophoto}{John Doe}
%	Biography text here.
%\end{IEEEbiographynophoto}
%
%% insert where needed to balance the two columns on the last page with
%% biographies
%%\newpage
%
%\begin{IEEEbiographynophoto}{Jane Doe}
%	Biography text here.
%\end{IEEEbiographynophoto}
		
		% You can push biographies down or up by placing
		% a \vfill before or after them. The appropriate
		% use of \vfill depends on what kind of text is
		% on the last page and whether or not the columns
		% are being equalized.
		
		%\vfill
		
		% Can be used to pull up biographies so that the bottom of the last one
		% is flush with the other column.
		%\enlargethispage{-5in}
		
		
		
		% that's all folks
	\end{document}
						
						


