\section{Introduction}
Autonomous driving is an emerging field of research at the intersection of robotics and computer vision. 
%A majority of approaches utilize a modular structure with perception and decision-making modules designed separately to accomplish the task. However, optimizing the separated modules may lead to suboptimal performance and normally require higher computational resources. 
Recently, end-to-end autonomous driving \cite{7995975} \cite{chen2019lbc} \cite{Chitta2021ICCV(NEAT)}, integrating the perception module and decision-making module into one learning system to optimize, gains popularity in the researches as it proved surprisingly powerful with minimum training data gained from simulation environment.
However, end-to-end approach still suffers from the problem of interpretability and can not guarantee the most important factor ``safety'' in autonomous driving. Our primary objective is to enhance the safety of the end-to-end system through two main approaches. Firstly, we aim to enhance the reliability of the multi-sensor fusion algorithm, which will enable the system to perceive its surrounding environment with greater accuracy and robustness. Secondly, in order to enhance the interpretability of the end-to-end approach, we focus on refining the policy learning algorithm, enabling the autonomous agent to effectively adhere to traffic regulations.
% However, end-to-end approach still suffers from the problem of interpretability and can not guarantee the most important factor ``safety'' in autonomous driving. 
% To ground this issue we aim to enhance the reliability and robustness of the algorithms from two perspectives: 1) We enhance the system's ability to perceive  by utilizing multi-modal, multi-sensor information and employing novel methods for information fusion. 2) To improve the interpretability of the model's decisions, we need to directly incorporate certain constraint rules (e.g., traffic regulations) into the training process, allowing our decision-making system to better comply with various rules and avoid unreasonable operations.

The fusion of LiDAR and RGB sensors recently show impressive results in the context of autonomous driving. LiDAR sensors provide accurate 3D information of surrounding environment while they lack color information compared to RGB sensors; RGB sensors are more suitable to recognize traffic lights and traffic sign patterns while they are not resilient to bright light and other bad weather conditions compared to LiDAR sensors. Some fusion technologies \cite{deep-continuous-fusion} \cite{liu2022bevfusion} have achieved commendable results in the field of object detection. In terms of end-to-end autonomous driving, \cite{TransFuser} \cite{TransFuser+} \cite{shao2022interfuser} focus more on attention-based approaches to extract the global context from different modalities. Despite its potential, the additional Transformer architecture leads to a significant increase in both the training time and inference time of the model. To address this issue, we fuse the information (Figure \ref{fig:Shared semantic features}) obtained from LiDAR and RGB by aligning their shared semantic information 
with auxiliary losses. This approach requires fewer parameters, yet it still produces remarkable results. 

\begin{figure}[t]
	\centering
	\includegraphics[width=0.95\linewidth]{figures/Shared_Semantic_Features2.pdf}
	\caption{\textbf{Illustration.} To safely navigate in the road, the ego-vehicle must capture the surrounding context from the RGB camera (left) and  LiDAR (right). Our P-CSG model integrates both modalities by capturing shared semantic features via feature alignment and cross semantic generation. }
	\label{fig:Shared semantic features}
\end{figure}

Reinforcement learning (RL) \cite{sutton1998introduction} and imitation learning (IL) \cite{Imitation_Learning} are two learning paradigms for end-to-end autonomous driving. Even though reinforcement learning demonstrates huge potential in autonomous driving, it often confronts limitations due to low sample efficiency and the requirement for careful reward development to learn, which poses challenges in obtaining sufficient training data for effective learning. Meanwhile, RL algorithms may also learn to take risky actions that lead to accidents or unsafe driving behaviors. Consequently, other researchers have turned to imitation learning approaches. However, current imitation learning approaches still lack effective mechanism to ensure safety during training process. After careful study, we found that the metric of autonomous driving and the objective function of imitation learning are not unified which means a low loss of learning objective does not guarantee the good performance of the agent in the testing environment. The traffic rules e.g. forbidding running a red light and stop sign are not reflected in the objective function. Our objective is to develop a novel objective function by incorporating penalty mechanisms, with the intention of augmenting the trained model's responsiveness to traffic rule violations. This integration aims to instill a heightened awareness of traffic regulations during the training process, ultimately leading to improved overall performance of the model.

%In this way, We would like to design a new objective function to make the model directly guided by the traffic rules by integrating penalties for any breach of these rules. This enables our model to utilize extracted traffic information from the surrounding environment as safety constraint cues to restrict actions, thereby further enhancing driving safety. 

Our main contributions to this paper can be summarized as follows:
\begin{itemize}
    \item We proposed a penalty-based imitation learning approach that leverages constraint optimizations to make the end-to-end autonomous driving model more sensitive to traffic rule violations. This objective function design also unifies the metric of autonomous driving and the objective of imitation learning. We refer this approach as penalty-based imitation learning. 
    \item We proposed a novel multi-sensor fusion model to extract the shared features and unique features between different modalities, making it easier for the decision network to get a global context for policy generation.
\end{itemize}