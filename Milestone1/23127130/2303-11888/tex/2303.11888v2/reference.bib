@article{TransFuser+,
  author = {Chitta, Kashyap and
            Prakash, Aditya and
            Jaeger, Bernhard and
            Yu, Zehao and
            Renz, Katrin and
            Geiger, Andreas},
  title = {TransFuser: Imitation with Transformer-Based Sensor Fusion for Autonomous Driving},
  journal = {Pattern Analysis and Machine Intelligence (PAMI)},
  year = {2022},
}

@inproceedings{latefusion,
  title = {End-To-End Multi-Modal Sensors Fusion System For Urban Automated Driving},
  author={Ibrahim Sobh and Loay Amin and Sherif Abdelkarim and Khaled Elmadawy and Mahmoud Saeed and Omar Abdeltawab and Mostafa El Gamal and Ahmad El Sallab},
  year={2018}
}

@inproceedings{TransFuser,
  author = {Prakash, Aditya and
            Chitta, Kashyap and
            Geiger, Andreas},
  title = {Multi-Modal Fusion Transformer for End-to-End Autonomous Driving},
  booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2021}
}

@inproceedings{Filos2020CanAV,
  title={Can Autonomous Vehicles Identify, Recover From, and Adapt to Distribution Shifts?},
  author={Angelos Filos and Panagiotis Tigas and Rowan McAllister and Nicholas Rhinehart and Sergey Levine and Yarin Gal},
  booktitle={ICML},
  year={2020}
}

@inproceedings{chen2019lbc,
  author    = {Chen, Dian and Zhou, Brady and Koltun, Vladlen and Kr\"ahenb\"uhl, Philipp},
  title     = {Learning by Cheating},
  booktitle = {Conference on Robot Learning (CoRL)},
  year      = {2019},
}

@article{DBLP:journals/corr/abs-2001-08726,
  author    = {Jianyu Chen and
               Shengbo Eben Li and
               Masayoshi Tomizuka},
  title     = {Interpretable End-to-end Urban Autonomous Driving with Latent Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/2001.08726},
  year      = {2020}
}
  
@misc{MV-fusion4AD,
  doi = {10.48550/ARXIV.2008.11901},
  
  url = {https://arxiv.org/abs/2008.11901},
  
  author = {Fadadu, Sudeep and Pandey, Shreyash and Hegde, Darshan and Shi, Yi and Chou, Fang-Chieh and Djuric, Nemanja and Vallespi-Gonzalez, Carlos},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Multi-View Fusion of Sensor Data for Improved Perception and Prediction in Autonomous Driving},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{Dosovitskiy17,
  title = {{CARLA}: {An} Open Urban Driving Simulator},
  author = {Alexey Dosovitskiy and German Ros and Felipe Codevilla and Antonio Lopez and Vladlen Koltun},
  booktitle = {Proceedings of the 1st Annual Conference on Robot Learning},
  pages = {1--16},
  year = {2017}
}

@inproceedings{Chitta2021ICCV(NEAT),
  title = {NEAT: Neural Attention Fields for End-to-End Autonomous Driving},
  author = {Chitta, Kashyap and Prakash, Aditya and Geiger, Andreas},
  booktitle = {International Conference on Computer Vision (ICCV)},
  year = {2021},
  doi = {}
}
@inproceedings{chen2022lav,
  title={Learning from all vehicles},
  author={Chen, Dian and Kr{\"a}henb{\"u}hl, Philipp},
  booktitle={CVPR},
  year={2022}
}
@article{shao2022interfuser,
 title={Safety-Enhanced Autonomous Driving Using Interpretable Sensor Fusion Transformer},
 author={Hao Shao and Letian Wang and RuoBing Chen and Hongsheng Li and Yu Liu},
 journal={arXiv preprint arXiv:2207.14024},
 year={2022},
}

@article{DBLP:journals/corr/abs-2003-06404,
  author    = {Ardi Tampuu and
               Maksym Semikin and
               Naveed Muhammad and
               Dmytro Fishman and
               Tambet Matiisen},
  title     = {A Survey of End-to-End Driving: Architectures and Training Methods},
  journal   = {CoRR},
  volume    = {abs/2003.06404},
  year      = {2020}
}

@article{DBLP:journals/corr/HeZRS15,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015}
}
@INPROCEEDINGS{SF4IV,
  author={Liu, Yongkang and Wang, Ziran and Han, Kyungtae and Shou, Zhenyu and Tiwari, Prashant and L. Hansen, John H.},
  booktitle={2020 IEEE Intelligent Vehicles Symposium (IV)}, 
  title={Sensor Fusion of Camera and Cloud Digital Twin Information for Intelligent Vehicles}, 
  year={2020},
  volume={},
  number={},
  pages={182-187},
  doi={10.1109/IV47402.2020.9304643}}
@INPROCEEDINGS{CPRL,
  author={Aoki, Shunsuke and Higuchi, Takamasa and Altintas, Onur},
  booktitle={2020 IEEE Intelligent Vehicles Symposium (IV)}, 
  title={Cooperative Perception with Deep Reinforcement Learning for Connected Vehicles}, 
  year={2020},
  volume={},
  number={},
  pages={328-334},
  doi={10.1109/IV47402.2020.9304570}}
@INPROCEEDINGS{8813900,
  author={Mori, Keisuke and Fukui, Hiroshi and Murase, Takuya and Hirakawa, Tsubasa and Yamashita, Takayoshi and Fujiyoshi, Hironobu},
  booktitle={2019 IEEE Intelligent Vehicles Symposium (IV)}, 
  title={Visual Explanation by Attention Branch Network for End-to-end Learning-based Self-driving}, 
  year={2019},
  volume={},
  number={},
  pages={1577-1582},
  doi={10.1109/IVS.2019.8813900}}

  @article{DBLP:journals/corr/abs-1905-06937,
  author    = {Dequan Wang and
               Coline Devin and
               Qi{-}Zhi Cai and
               Philipp Kr{\"{a}}henb{\"{u}}hl and
               Trevor Darrell},
  title     = {Monocular Plan View Networks for Autonomous Driving},
  journal   = {CoRR},
  volume    = {abs/1905.06937},
  year      = {2019}
}
@article{DBLP:journals/corr/abs-1812-03079,
  author    = {Mayank Bansal and
               Alex Krizhevsky and
               Abhijit S. Ogale},
  title     = {ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing
               the Worst},
  journal   = {CoRR},
  volume    = {abs/1812.03079},
  year      = {2018}
}
@ARTICLE{7112511,
  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Region-Based Convolutional Networks for Accurate Object Detection and Segmentation}, 
  year={2016},
  volume={38},
  number={1},
  pages={142-158},
  doi={10.1109/TPAMI.2015.2437384}}

@INPROCEEDINGS{Fast_RCNN,
  author={Girshick, Ross},
  booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Fast R-CNN}, 
  year={2015},
  volume={},
  number={},
  pages={1440-1448},
  doi={10.1109/ICCV.2015.169}}
@inproceedings{Faster_RCNN,
 author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf},
 volume = {28},
 year = {2015}
}
@inproceedings{redmon2016you,
  title={You only look once: Unified, real-time object detection},
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={779--788},
  year={2016}
}
@misc{brasó2020learning,
      title={Learning a Neural Solver for Multiple Object Tracking}, 
      author={Guillem Brasó and Laura Leal-Taixé},
      year={2020},
      eprint={1912.07515},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={Medical Image Computing and Computer-Assisted Intervention--MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18},
  pages={234--241},
  year={2015},
  organization={Springer}
}
@article{DBLP:journals/corr/CicekALBR16,
  author    = {{\"{O}}zg{\"{u}}n {\c{C}}i{\c{c}}ek and
               Ahmed Abdulkadir and
               Soeren S. Lienkamp and
               Thomas Brox and
               Olaf Ronneberger},
  title     = {3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation},
  journal   = {CoRR},
  volume    = {abs/1606.06650},
  year      = {2016},
  url       = {http://arxiv.org/abs/1606.06650},
  eprinttype = {arXiv},
  eprint    = {1606.06650},
  timestamp = {Mon, 13 Aug 2018 16:47:29 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/CicekALBR16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Imitation_Learning,
title = {A survey of robot learning from demonstration},
journal = {Robotics and Autonomous Systems},
volume = {57},
number = {5},
pages = {469-483},
year = {2009},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2008.10.024},
url = {https://www.sciencedirect.com/science/article/pii/S0921889008001772},
author = {Brenna D. Argall and Sonia Chernova and Manuela Veloso and Brett Browning},
keywords = {Learning from demonstration, Robotics, Machine learning, Autonomous systems},
abstract = {We present a comprehensive survey of robot Learning from Demonstration (LfD), a technique that develops policies from example state to action mappings. We introduce the LfD design choices in terms of demonstrator, problem space, policy derivation and performance, and contribute the foundations for a structure in which to categorize LfD research. Specifically, we analyze and categorize the multiple ways in which examples are gathered, ranging from teleoperation to imitation, as well as the various techniques for policy derivation, including matching functions, dynamics models and plans. To conclude we discuss LfD limitations and related promising areas for future research.}
}

@article{pan2020imitation,
  title={Imitation learning for agile autonomous driving},
  author={Pan, Yunpeng and Cheng, Ching-An and Saigol, Kamil and Lee, Keuntaek and Yan, Xinyan and Theodorou, Evangelos A and Boots, Byron},
  journal={The International Journal of Robotics Research},
  volume={39},
  number={2-3},
  pages={286--302},
  year={2020},
  publisher={SAGE Publications Sage UK: London, England}
}
@INPROCEEDINGS{8968225,
  author={Chen, Jianyu and Yuan, Bodi and Tomizuka, Masayoshi},
  booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Deep Imitation Learning for Autonomous Driving in Generic Urban Scenarios with Enhanced Safety}, 
  year={2019},
  volume={},
  number={},
  pages={2884-2890},
  doi={10.1109/IROS40897.2019.8968225}}
  
  @INPROCEEDINGS{7995975,
  author={Chen, Zhilu and Huang, Xinming},
  booktitle={2017 IEEE Intelligent Vehicles Symposium (IV)}, 
  title={End-to-end learning for lane keeping of self-driving cars}, 
  year={2017},
  volume={},
  number={},
  pages={1856-1860},
  doi={10.1109/IVS.2017.7995975}}

  
 @inproceedings{liu2022bevfusion,
  title={BEVFusion: Multi-Task Multi-Sensor Fusion with Unified Bird's-Eye View Representation},
  author={Liu, Zhijian and Tang, Haotian and Amini, Alexander and Yang, Xingyu and Mao, Huizi and Rus, Daniela and Han, Song},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2023}
}


@InProceedings{deep-continuous-fusion,
author="Liang, Ming
and Yang, Bin
and Wang, Shenlong
and Urtasun, Raquel",
editor="Ferrari, Vittorio
and Hebert, Martial
and Sminchisescu, Cristian
and Weiss, Yair",
title="Deep Continuous Fusion for Multi-sensor 3D Object Detection",
booktitle="Computer Vision -- ECCV 2018",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="663--678",
abstract="In this paper, we propose a novel 3D object detector that can exploit both LIDAR as well as cameras to perform very accurate localization. Towards this goal, we design an end-to-end learnable architecture that exploits continuous convolutions to fuse image and LIDAR feature maps at different levels of resolution. Our proposed continuous fusion layer encode both discrete-state image features as well as continuous geometric information. This enables us to design a novel, reliable and efficient end-to-end learnable 3D object detector based on multiple sensors. Our experimental evaluation on both KITTI as well as a large scale 3D object detection benchmark shows significant improvements over the state of the art.",
isbn="978-3-030-01270-0"
}


@InProceedings{pmlr-v78-liu17a,
  title = 	 {Learning End-to-end Multimodal Sensor Policies for Autonomous Navigation},
  author = 	 {Liu, Guan-Horng and Siravuru, Avinash and Prabhakar, Sai and Veloso, Manuela and Kantor, George},
  booktitle = 	 {Proceedings of the 1st Annual Conference on Robot Learning},
  pages = 	 {249--261},
  year = 	 {2017},
  editor = 	 {Levine, Sergey and Vanhoucke, Vincent and Goldberg, Ken},
  volume = 	 {78},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--15 Nov},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v78/liu17a/liu17a.pdf},
  url = 	 {https://proceedings.mlr.press/v78/liu17a.html},
  abstract = 	 {We proposed a multimodal end-to-end policy based on deep reinforcement learning (DRL) that leverages sensor fusion to reduced performance drops in noisy environment from 50% to 10% compared with the baseline and makes the policy functional even in the face of partial sensor failure by using a novel stochastic technique called Sensor Dropout to reduce sensitivity to any sensor subset, and a new auxiliary loss on policy network along with standard DRL loss that reduces the action variations.}
}

@INPROCEEDINGS{9341020,
  author={Chen, Jianyu and Xu, Zhuo and Tomizuka, Masayoshi},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={End-to-end Autonomous Driving Perception with Sequential Latent Representation Learning}, 
  year={2020},
  volume={},
  number={},
  pages={1999-2006},
  doi={10.1109/IROS45743.2020.9341020}}
  
@book{sutton1998introduction,
  title={Introduction to reinforcement learning},
  author={Sutton, Richard S and Barto, Andrew G and others},
  volume={135},
  year={1998},
  publisher={MIT press Cambridge}
}
@article{DBLP:journals/corr/abs-2109-08473,
  author    = {Peide Cai and
               Sukai Wang and
               Hengli Wang and
               Ming Liu},
  title     = {Carl-Lead: Lidar-based End-to-End Autonomous Driving with Contrastive
               Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/2109.08473},
  year      = {2021},
  url       = {https://arxiv.org/abs/2109.08473},
  eprinttype = {arXiv},
  eprint    = {2109.08473},
  timestamp = {Wed, 22 Sep 2021 14:16:57 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2109-08473.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}