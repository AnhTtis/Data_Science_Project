\section{Introduction}

Many web service platforms (e.g., Amazon, YouTube, and TikTok) leverage recommender systems to engage users and improve user experience. 
Typically, a platform first collects a large amount of rating scores that users gave to items, which is known as  a \emph{rating-score matrix}.  
Then, the platform uses them to build a recommender system that models the complex relationships between user interests and item properties. Finally, the recommender system recommends top-$N$  items to each user that match his/her interests. 

However, due to its openness, i.e., anyone can register users and provide rating scores to items, recommender system is fundamentally not robust to 
\emph{data poisoning attacks}~\cite{lam2004shilling,mobasher2007toward,li2016data,yang2017fake,fang2018poisoning,fang2020influence,huangdata2021}. 
Specifically, in a data poisoning attack, an attacker  creates fake users in a recommender system and assigns carefully crafted rating scores to \neil{items}. Different data poisoning attacks essentially use different methods to craft the fake users' rating scores.  When a recommender system is built based on the \emph{poisoned-rating-score matrix}, which includes the rating scores of both genuine and fake users, it recommends attacker-chosen, arbitrary top-$N$ items to a user. As a result, the recommendation performance (e.g.,  Precision@$N$,  Recall@$N$, and  F1-Score@$N$) is substantially degraded. Data poisoning attacks pose severe challenges to the robustness/security of recommender systems. 

Many defenses have been proposed to enhance the robustness of recommender systems against data poisoning attacks. In particular, one family of defenses~\cite{burke2006classification,zhang2006attack,wu2012hysad,zhang2014hht,fang2018poisoning} aim to detect fake users before building a recommender system. These methods rely on the assumption that the rating scores of fake users and genuine users have statistically different patterns, which they leverage to distinguish between fake and genuine users. 
\neil{Another family of defenses~\cite{sandvig2007robustness,mehta2007robust,tang2019adversarial,chen2019adversarial,yuan2019adversarial,liu2020certifiable,hidano2020recommender} aim to design new methods of training  recommender systems such that they have good recommendation performance even if they are trained on a poisoned-rating-score matrix, e.g., using trim learning~\cite{hidano2020recommender}.  
However, these defenses only achieve  \emph{empirical} robustness, leading to an endless cat-and-mouse game between attacks and defenses: a new empirical defense is proposed to mitigate existing attacks but can be broken by new attacks that adapt to the defense.} For instance,  fake users can adapt their rating scores  such that they cannot be detected based on the rating scores' statistical patterns ~\cite{fang2018poisoning,fang2020influence,huangdata2021}.  As a result, a recommender system's performance is still substantially degraded by strong, adaptive attacks. 



\myparatight{Our work} In this work, we aim to end such cat-and-mouse game via proposing PORE, the first framework to build \emph{provably} robust recommender systems against \emph{any} \neil{untargeted} data poisoning attacks. 
Suppose, under no attacks, a recommender system algorithm  trains a recommender system on a clean rating-score matrix,  which recommends a set of top-$N$ items (denoted as $\Gamma_u$) to a user $u$. Under attacks, the recommender system algorithm trains a recommender system on a poisoned-rating-score matrix, which recommends a set of top-$N$ items (denoted as $\Gamma_u'$) to the user.  
We say the recommender system algorithm is $(e,r)$-provably robust for the user $u$ if the intersection between $\Gamma_u$ and $\Gamma_u'$ includes at least $r$ items when there are at most $e$ fake users, no matter how an attacker crafts the fake users' rating scores. In other words, an $(e,r)$-provably robust recommender system guarantees that at least $r$ of the recommended top-$N$ items are unaffected by $e$ fake users no matter what rating scores they use. We note that $r$ depends on the number of fake users $e$ and we call $r$ \emph{certified intersection size}. A provably robust recommender system can guarantee a lower bound of recommendation performance under \emph{any} data poisoning attack, i.e.,  no matter how fake users craft their rating scores. 



Suppose a \emph{submatrix} consists of $s$ rows of the  rating-score matrix, i.e., a submatrix includes rating scores of $s$ users. Intuitively, when the fraction of fake users is bounded, a randomly sampled  submatrix is likely to not contain fake users and thus a recommender system built based on the submatrix is not affected by fake users.  Based on this intuition, \neil{PORE uses \emph{bagging}~\cite{breiman1996bagging}, a well-known ensemble method,} to achieve provable robustness. In particular, PORE aggregates recommendations from multiple base recommender systems to recommend top-$N$ items to each user.  
Specifically, we can use any recommender system algorithm (called \emph{base algorithm}) to build a recommender system (called \emph{base recommender system}) on a submatrix. Therefore, we could build ${n \choose s}$ base recommender systems since there are ${n \choose s}$ submatrices, where $n$ is the total number of users. Each base recommender system makes recommendations to users.  We denote by $p_i$ the fraction of the ${n \choose s}$ base recommender systems that recommend item $i$ to a user $u$. We call $p_i$ \emph{item probability}.\footnote{Item probability $p_i$ also depends on user $u$, but we omit it for simplicity.} PORE recommends the top-$N$ items with the  largest item probabilities to user $u$. 




Our major theoretical result is that we prove 
PORE is $(e,r)$-provably robust, no matter what base algorithm is used to train the base recommender systems. Moreover, for any given number of fake users $e$, we derive the certified intersection size $r$ for each genuine user, which is the solution to an optimization problem. 
 PORE relies on the item probabilities $p_i$'s to make recommendations. 
Moreover, the optimization problem to calculate $r$ also involves item probabilities. However, it is challenging to compute the exact item probabilities as it requires building ${n \choose s}$  base recommender systems. To address the challenge, we design an efficient algorithm to estimate the lower/upper bounds of the item probabilities via building $T \ll {n \choose s}$ base recommender systems, where 
the $T$ base recommender systems can be built in parallel. 
PORE makes recommendations based on the estimated item probabilities in practice. 
Moreover, we use the estimated item probabilities to solve the optimization problem to obtain $r$ for each user. 


We empirically evaluate  PORE on three benchmark datasets, i.e., MovieLens-100k, MovieLens-1M, \neil{and MovieLens-10M}. Moreover, we consider two state-of-the-art base algorithms, i.e., Item-based Recommendation (IR)~\cite{argyriou2020microsoft} and Bayesian Personalized Ranking (BPR)~\cite{rendle2012bpr}, to show the generality of PORE. 
\CR{We also generalize  state-of-the-art provably robust defense~\cite{jia2020intrinsic} against data poisoning attacks for machine learning classifiers to recommender systems and compare PORE with it.}
We have \CR{three} key observations from our experimental results. \CR{First, PORE substantially outperforms the defense generalized from classifiers.} Second, when there are no data poisoning attacks, PORE has comparable recommendation performance (i.e., Precision@$N$,  Recall@$N$, and  F1-Score@$N$) with a standard recommender system built on the entire rating-score matrix. Third, under any data poisoning attacks, PORE can guarantee a lower bound of recommendation performance, while the standard recommender systems cannot. 

Our key contributions are summarized as follows:
\begin{itemize}
    \item We propose PORE, the first framework to build  recommender systems that are provably robust against \neil{untargeted} data poisoning attacks. 
    
    \item We prove the robustness guarantees of PORE and derive its certified intersection size. Moreover, we design an algorithm to compute the certified intersection size. 
    
    \item We perform extensive evaluation on popular benchmark datasets using two state-of-the-art base recommender system algorithms.  
\end{itemize}
