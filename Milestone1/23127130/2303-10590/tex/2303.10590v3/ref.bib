@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@inproceedings{paszke17,
    title = {Automatic differentiation in {PyTorch}},
    author = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
    booktitle = {NeurIPS Autodiff Workshop},
    year = {2017}
}

@inproceedings{chang2022knowledge,
  title={Knowledge-Driven Self-Supervised Representation Learning for Facial Action Unit Recognition},
  author={Chang, Yanan and Wang, Shangfei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={20417--20426},
  year={2022}
}

@article{luo2022learning,
  title={Learning Multi-dimensional Edge Feature-based AU Relation Graph for Facial Action Unit Recognition},
  author={Luo, Cheng and Song, Siyang and Xie, Weicheng and Shen, Linlin and Gunes, Hatice},
  journal={arXiv preprint arXiv:2205.01782},
  year={2022}
}

@article{saragih2011deformable,
  title={Deformable model fitting by regularized landmark mean-shift},
  author={Saragih, Jason M and Lucey, Simon and Cohn, Jeffrey F},
  journal={International journal of computer vision},
  volume={91},
  number={2},
  pages={200--215},
  year={2011},
  publisher={Springer}
}

@inproceedings{cootes1998active,
  title={Active appearance models},
  author={Cootes, Timothy F and Edwards, Gareth J and Taylor, Christopher J},
  booktitle={European conference on computer vision},
  pages={484--498},
  year={1998},
  organization={Springer}
}

@article{zhang2014bp4d,
  title={Bp4d-spontaneous: a high-resolution spontaneous 3d dynamic facial expression database},
  author={Zhang, Xing and Yin, Lijun and Cohn, Jeffrey F and Canavan, Shaun and Reale, Michael and Horowitz, Andy and Liu, Peng and Girard, Jeffrey M},
  journal={Image and Vision Computing},
  volume={32},
  number={10},
  pages={692--706},
  year={2014},
  publisher={Elsevier}
}

@article{mavadati2013disfa,
  title={Disfa: A spontaneous facial action intensity database},
  author={Mavadati, S Mohammad and Mahoor, Mohammad H and Bartlett, Kevin and Trinh, Philip and Cohn, Jeffrey F},
  journal={IEEE Transactions on Affective Computing},
  volume={4},
  number={2},
  pages={151--160},
  year={2013},
  publisher={IEEE}
}

@article{rychlowska2017functional,
  title={Functional smiles: Tools for love, sympathy, and war},
  author={Rychlowska, Magdalena and Jack, Rachael E and Garrod, Oliver GB and Schyns, Philippe G and Martin, Jared D and Niedenthal, Paula M},
  journal={Psychological science},
  volume={28},
  number={9},
  pages={1259--1270},
  year={2017},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@misc{ekman1977facial,
  title={Facial action coding system},
  author={Ekman, Paul},
  year={1977},
  publisher={Consultion Psychologists Press}
}

@article{barrett2019,
author = {Lisa Feldman Barrett and Ralph Adolphs and Stacy Marsella and Aleix M. Martinez and Seth D. Pollak},
title ={Emotional Expressions Reconsidered: Challenges to Inferring Emotion From Human Facial Movements},
journal = {Psychological Science in the Public Interest},
volume = {20},
number = {1},
pages = {1-68},
year = {2019},
doi = {10.1177/1529100619832930},
note ={PMID: 31313636},
URL = {https://doi.org/10.1177/1529100619832930}
}

@article{martinez2017automatic,
  title={Automatic analysis of facial actions: A survey},
  author={Martinez, Brais and Valstar, Michel F and Jiang, Bihan and Pantic, Maja},
  journal={IEEE transactions on affective computing},
  year={2017},
  publisher={IEEE}
}

@Article{dlib09,
  author = {Davis E. King},
  title = {Dlib-ml: A Machine Learning Toolkit},
  journal = {Journal of Machine Learning Research},
  year = {2009},
  volume = {10},
  pages = {1755-1758},
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@inproceedings{zhao2016deep,
  title={Deep region and multi-label learning for facial action unit detection},
  author={Zhao, Kaili and Chu, Wen-Sheng and Zhang, Honggang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3391--3399},
  year={2016}
}

@inproceedings{li2017action,
  title={Action unit detection with region adaptation, multi-labeling learning and optimal temporal fusing},
  author={Li, Wei and Abtahi, Farnaz and Zhu, Zhigang},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1841--1850},
  year={2017}
}

@inproceedings{li2019semantic,
  title={Semantic relationships guided representation learning for facial action unit recognition},
  author={Li, Guanbin and Zhu, Xin and Zeng, Yirui and Wang, Qing and Lin, Liang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={8594--8601},
  year={2019}
}

@inproceedings{song2021uncertain,
  title={Uncertain graph neural networks for facial action unit detection},
  author={Song, Tengfei and Chen, Lisha and Zheng, Wenming and Ji, Qiang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={7},
  pages={5993--6001},
  year={2021}
}

@inproceedings{song2021hybrid,
  title={Hybrid message passing with performance-driven structures for facial action unit detection},
  author={Song, Tengfei and Cui, Zijun and Zheng, Wenming and Ji, Qiang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6267--6276},
  year={2021}
}

@inproceedings{tang2021piap,
  title={PIAP-DF: Pixel-Interested and Anti Person-Specific Facial Action Unit Detection Net with Discrete Feedback Learning},
  author={Tang, Yang and Zeng, Wangding and Zhao, Dafei and Zhang, Honggang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={12899--12908},
  year={2021}
}

@inproceedings{jacob2021facial,
  title={Facial action unit detection with transformers},
  author={Jacob, Geethu Miriam and Stenger, Bjorn},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7680--7689},
  year={2021}
}

@article{shao2021jaa,
  title={JAA-Net: Joint facial action unit detection and face alignment via adaptive attention},
  author={Shao, Zhiwen and Liu, Zhilei and Cai, Jianfei and Ma, Lizhuang},
  journal={International Journal of Computer Vision},
  volume={129},
  number={2},
  pages={321--340},
  year={2021},
  publisher={Springer}
}

@inproceedings{zhang2020region,
  title={Region of interest based graph convolution: A heatmap regression approach for action unit detection},
  author={Zhang, Zheng and Wang, Taoyue and Yin, Lijun},
  booktitle={Proceedings of the 28th ACM International Conference on Multimedia},
  pages={2890--2898},
  year={2020}
}

@inproceedings{yin2021self,
  title={Self-Supervised Patch Localization for Cross-Domain Facial Action Unit Detection},
  author={Yin, Yufeng and Lu, Liupei and Wu, Yizhen and Soleymani, Mohammad},
  booktitle={2021 16th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2021)},
  pages={1--8},
  year={2021},
  organization={IEEE}
}

@inproceedings{sagonas2013300,
  title={300 faces in-the-wild challenge: The first facial landmark localization challenge},
  author={Sagonas, Christos and Tzimiropoulos, Georgios and Zafeiriou, Stefanos and Pantic, Maja},
  booktitle={Proceedings of the IEEE international conference on computer vision workshops},
  pages={397--403},
  year={2013}
}

@inproceedings{zhang2021datasetgan,
  title={Datasetgan: Efficient labeled data factory with minimal human effort},
  author={Zhang, Yuxuan and Ling, Huan and Gao, Jun and Yin, Kangxue and Lafleche, Jean-Francois and Barriuso, Adela and Torralba, Antonio and Fidler, Sanja},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10145--10155},
  year={2021}
}

@inproceedings{li2021semantic,
  title={Semantic segmentation with generative models: Semi-supervised learning and strong out-of-domain generalization},
  author={Li, Daiqing and Yang, Junlin and Kreis, Karsten and Torralba, Antonio and Fidler, Sanja},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8300--8311},
  year={2021}
}

@article{baranchuk2021label,
  title={Label-efficient semantic segmentation with diffusion models},
  author={Baranchuk, Dmitry and Rubachev, Ivan and Voynov, Andrey and Khrulkov, Valentin and Babenko, Artem},
  journal={arXiv preprint arXiv:2112.03126},
  year={2021}
}

@inproceedings{karras2019style,
  title={A style-based generator architecture for generative adversarial networks},
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4401--4410},
  year={2019}
}

@article{dhariwal2021diffusion,
  title={Diffusion models beat gans on image synthesis},
  author={Dhariwal, Prafulla and Nichol, Alexander},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={8780--8794},
  year={2021}
}

@inproceedings{karras2020analyzing,
  title={Analyzing and improving the image quality of stylegan},
  author={Karras, Tero and Laine, Samuli and Aittala, Miika and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8110--8119},
  year={2020}
}

@InProceedings{richardson2021encoding,
      author = {Richardson, Elad and Alaluf, Yuval and Patashnik, Or and Nitzan, Yotam and Azar, Yaniv and Shapiro, Stav and Cohen-Or, Daniel},
      title = {Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation},
      booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
      month = {June},
      year = {2021}
}

@inproceedings{ertugrul2019cross,
  title={Cross-domain au detection: Domains, learning approaches, and measures},
  author={Ertugrul, Itir Onal and Cohn, Jeffrey F and Jeni, L{\'a}szl{\'o} A and Zhang, Zheng and Yin, Lijun and Ji, Qiang},
  booktitle={2019 14th IEEE International Conference on Automatic Face \& Gesture Recognition (FG 2019)},
  pages={1--8},
  year={2019},
  organization={IEEE}
}

@article{ertugrul2020crossing,
  title={Crossing Domains for AU Coding: Perspectives, Approaches, and Measures},
  author={Ertugrul, Itir Onal and Cohn, Jeffrey F and Jeni, L{\'a}szl{\'o} A and Zhang, Zheng and Yin, Lijun and Ji, Qiang},
  journal={IEEE transactions on biometrics, behavior, and identity science},
  volume={2},
  number={2},
  pages={158--171},
  year={2020},
  publisher={IEEE}
}

@article{hernandez2021deepfn,
  title={DeepFN: towards generalizable facial action unit recognition with deep face normalization},
  author={Hernandez, Javier and McDuff, Daniel and Fung, Alberto and Czerwinski, Mary and others},
  journal={arXiv preprint arXiv:2103.02484},
  year={2021}
}

@article{bond2021deep,
  title={Deep generative modelling: A comparative review of VAEs, GANs, normalizing flows, energy-based and autoregressive models},
  author={Bond-Taylor, Sam and Leach, Adam and Long, Yang and Willcocks, Chris G},
  journal={arXiv preprint arXiv:2103.04922},
  year={2021}
}

@inproceedings{huang2017arbitrary,
  title={Arbitrary style transfer in real-time with adaptive instance normalization},
  author={Huang, Xun and Belongie, Serge},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1501--1510},
  year={2017}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{wang2020deep,
  title={Deep high-resolution representation learning for visual recognition},
  author={Wang, Jingdong and Sun, Ke and Cheng, Tianheng and Jiang, Borui and Deng, Chaorui and Zhao, Yang and Liu, Dong and Mu, Yadong and Tan, Mingkui and Wang, Xinggang and others},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={43},
  number={10},
  pages={3349--3364},
  year={2020},
  publisher={IEEE}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{abdal2019image2stylegan,
  title={Image2stylegan: How to embed images into the stylegan latent space?},
  author={Abdal, Rameen and Qin, Yipeng and Wonka, Peter},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4432--4441},
  year={2019}
}

@article{xia2022gan,
  title={Gan inversion: A survey},
  author={Xia, Weihao and Zhang, Yulun and Yang, Yujiu and Xue, Jing-Hao and Zhou, Bolei and Yang, Ming-Hsuan},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2022},
  publisher={IEEE}
}

@inproceedings{xu2021generative,
  title={Generative hierarchical features from synthesizing images},
  author={Xu, Yinghao and Shen, Yujun and Zhu, Jiapeng and Yang, Ceyuan and Zhou, Bolei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4432--4442},
  year={2021}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10012--10022},
  year={2021}
}

@article{shao2019facial,
  title={Facial action unit detection using attention and relation learning},
  author={Shao, Zhiwen and Liu, Zhilei and Cai, Jianfei and Wu, Yunsheng and Ma, Lizhuang},
  journal={IEEE transactions on affective computing},
  volume={13},
  number={3},
  pages={1274--1289},
  year={2019},
  publisher={IEEE}
}

@inproceedings{vemulapalli2019compact,
  title={A compact embedding for facial expression similarity},
  author={Vemulapalli, Raviteja and Agarwala, Aseem},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5683--5692},
  year={2019}
}

@article{jiang2022facial,
  title={Facial action unit recognition with multi-models ensembling},
  author={Jiang, Wenqiang and Wu, Yannan and Qiao, Fengsheng and Meng, Liyu and Deng, Yuanyuan and Liu, Chuanhe},
  journal={arXiv preprint arXiv:2203.13046},
  year={2022}
}

@InProceedings{wang2021realesrgan,
    author    = {Xintao Wang and Liangbin Xie and Chao Dong and Ying Shan},
    title     = {Real-ESRGAN: Training Real-World Blind Super-Resolution with Pure Synthetic Data},
    booktitle = {International Conference on Computer Vision Workshops (ICCVW)},
    year      = {2021}
}

@inproceedings{kollias2022abaw,
  title={Abaw: Valence-arousal estimation, expression recognition, action unit detection \& multi-task learning challenges},
  author={Kollias, Dimitrios},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2328--2336},
  year={2022}
}

@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={29},
  pages={3451--3460},
  year={2021},
  publisher={IEEE}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{chung2014empirical,
  title={Empirical evaluation of gated recurrent neural networks on sequence modeling},
  author={Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.3555},
  year={2014}
}

@inproceedings{gururangan2020don,
  title={Don’t Stop Pretraining: Adapt Language Models to Domains and Tasks},
  author={Gururangan, Suchin and Marasovi{\'c}, Ana and Swayamdipta, Swabha and Lo, Kyle and Beltagy, Iz and Downey, Doug and Smith, Noah A},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={8342--8360},
  year={2020}
}

@inproceedings{zhang2022transformer,
  title={Transformer-based multimodal information fusion for facial expression analysis},
  author={Zhang, Wei and Qiu, Feng and Wang, Suzhen and Zeng, Hao and Zhang, Zhimeng and An, Rudong and Ma, Bowen and Ding, Yu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2428--2437},
  year={2022}
}

@article{kollias2023abaw2, title={ABAW: Valence-Arousal Estimation, Expression Recognition, Action Unit Detection \& Emotional Reaction Intensity Estimation Challenges}, author={Kollias, Dimitrios and Tzirakis, Panagiotis and Baird, Alice and Cowen, Alan and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:2303.01498}, year={2023} }
 
@inproceedings{kollias2023abaw, title={ABAW: learning from synthetic data \& multi-task learning challenges}, author={Kollias, Dimitrios}, booktitle={European Conference on Computer Vision}, pages={157--172}, year={2023}, organization={Springer} }

@article{kollias2021distribution, title={Distribution Matching for Heterogeneous Multi-Task Learning: a Large-scale Face Study}, author={Kollias, Dimitrios and Sharmanska, Viktoriia and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:2105.03790}, year={2021} } 

@inproceedings{kollias2021analysing, title={Analysing affective behavior in the second abaw2 competition}, author={Kollias, Dimitrios and Zafeiriou, Stefanos}, booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages={3652--3660}, year={2021}}

@article{kollias2021affect, title={Affect Analysis in-the-wild: Valence-Arousal, Expressions, Action Units and a Unified Framework}, author={Kollias, Dimitrios and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:2103.15792}, year={2021}}

@inproceedings{kollias2020analysing, title={Analysing Affective Behavior in the First ABAW 2020 Competition}, author={Kollias, D and Schulc, A and Hajiyev, E and Zafeiriou, S}, booktitle={2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020)(FG)}, pages={794--800}}

@article{kollias2019expression, title={Expression, Affect, Action Unit Recognition: Aff-Wild2, Multi-Task Learning and ArcFace}, author={Kollias, Dimitrios and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:1910.04855}, year={2019}}

@article{kollias2019face,title={Face Behavior a la carte: Expressions, Affect and Action Units in a Single Network}, author={Kollias, Dimitrios and Sharmanska, Viktoriia and Zafeiriou, Stefanos}, journal={arXiv preprint arXiv:1910.11111}, year={2019}}

@article{kollias2019deep, title={Deep affect prediction in-the-wild: Aff-wild database and challenge, deep architectures, and beyond}, author={Kollias, Dimitrios and Tzirakis, Panagiotis and Nicolaou, Mihalis A and Papaioannou, Athanasios and Zhao, Guoying and Schuller, Bj{\"o}rn and Kotsia, Irene and Zafeiriou, Stefanos}, journal={International Journal of Computer Vision}, pages={1--23}, year={2019}, publisher={Springer} }

@inproceedings{zafeiriou2017aff, title={Aff-wild: Valence and arousal ‘in-the-wild’challenge}, author={Zafeiriou, Stefanos and Kollias, Dimitrios and Nicolaou, Mihalis A and Papaioannou, Athanasios and Zhao, Guoying and Kotsia, Irene}, booktitle={Computer Vision and Pattern Recognition Workshops (CVPRW), 2017 IEEE Conference on}, pages={1980--1987}, year={2017}, organization={IEEE} }
