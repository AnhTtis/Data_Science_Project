{
    "arxiv_id": "2303.10590",
    "paper_title": "Multi-modal Facial Action Unit Detection with Large Pre-trained Models for the 5th Competition on Affective Behavior Analysis in-the-wild",
    "authors": [
        "Yufeng Yin",
        "Minh Tran",
        "Di Chang",
        "Xinrui Wang",
        "Mohammad Soleymani"
    ],
    "submission_date": "2023-03-19",
    "revised_dates": [
        "2023-03-24"
    ],
    "latest_version": 2,
    "categories": [
        "cs.CV"
    ],
    "abstract": "Facial action unit detection has emerged as an important task within facial expression analysis, aimed at detecting specific pre-defined, objective facial expressions, such as lip tightening and cheek raising. This paper presents our submission to the Affective Behavior Analysis in-the-wild (ABAW) 2023 Competition for AU detection. We propose a multi-modal method for facial action unit detection with visual, acoustic, and lexical features extracted from the large pre-trained models. To provide high-quality details for visual feature extraction, we apply super-resolution and face alignment to the training data and show potential performance gain. Our approach achieves the F1 score of 52.3% on the official validation set of the 5th ABAW Challenge.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.10590v1",
        "http://arxiv.org/pdf/2303.10590v2"
    ],
    "publication_venue": "8 pages, 7 figures, 5 tables"
}