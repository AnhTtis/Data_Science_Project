@string{CVPR = "IEEE Conference on Computer Vision and Pattern Recognition"}
@string{ICCV = "IEEE International Conference on Computer Vision"}
@string{ECCV = "European Conference on Computer Vision"}
@string{TPAMI = "IEEE Transactions on Pattern Analysis and Machine Intelligence"}
@string{NIPS = "Advances in Neural Information Processing Systems"}
@string{NeurIPS = "Neural Information Processing Systems"}
@string{ICLR = "International Conference on Learning Representations"}
@string{ICML = "International Conference on Machine Learning"}
@string{AAAI = "Association for the Advancement of Artificial Intelligence"}
@string{AISTATS = "International Conference on Artificial Intelligence and Statistics"}
@string{JMLR = "Journal of Machine Learning Research"}
@string{CoRL = "Conference on Robot Learning"}
@string{IROS = "IEEE/RSJ International Conference on Intelligent Robots and Systems"}
@string{ICRA = "IEEE International Conference on Robotics and Automation"}
@string{RSS = "Robotics: Science and Systems"}


@article{sutton1984temporal,
  title={Temporal credit assignment in reinforcement learning},
  author={Sutton, Richard Stuart},
  year={1984}
}

@inproceedings{ng1999reward_shaping,
  title={Policy invariance under reward transformations: Theory and application to reward shaping},
  author={Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  booktitle=ICML,
  pages={278--287},
  year={1999}
}

@article{roy2021visual,
  author    = {Josh Roy and
               George Konidaris},
  title     = {Visual Transfer for Reinforcement Learning via Wasserstein Domain
               Confusion},
  booktitle=AAAI,
  year      = {2021}
}

@inproceedings{
zakka2021xirl,
title={{XIRL}: Cross-embodiment Inverse Reinforcement Learning},
author={Kevin Zakka and Andy Zeng and Pete Florence and Jonathan Tompson and Jeannette Bohg and Debidatta Dwibedi},
booktitle={5th Annual Conference on Robot Learning },
year={2021},
url={https://openreview.net/forum?id=RO4DM85Z4P7}
}

@article{lanier2019curiosity,
  author    = {John B. Lanier and
               Stephen McAleer and
               Pierre Baldi},
  title     = {Curiosity-Driven Multi-Criteria Hindsight Experience Replay},
  journal   = {CoRR},
  volume    = {abs/1906.03710},
  year      = {2019},
  url       = {http://arxiv.org/abs/1906.03710},
  eprinttype = {arXiv},
  eprint    = {1906.03710},
  timestamp = {Fri, 14 Jun 2019 09:38:24 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1906-03710.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

% exploration 
@article{oudeyer2007what,
  title={What is Intrinsic Motivation? A Typology of Computational Approaches},
  author={Pierre-Yves Oudeyer and F. Kaplan},
  journal={Frontiers in Neurorobotics},
  year={2007},
  volume={1}
}

@ARTICLE{oudeyer2007intrinsic,
  author={Oudeyer, Pierre-Yves and Kaplan, Frdric and Hafner, Verena V.},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Intrinsic Motivation Systems for Autonomous Mental Development}, 
  year={2007},
  volume={11},
  number={2},
  pages={265-286},
  doi={10.1109/TEVC.2006.890271}}
  
@article{schmidhuber2010formal,
author = {Schmidhuber, Jürgen},
year = {2010},
month = {10},
pages = {230 - 247},
title = {Formal Theory of Creativity, Fun, and Intrinsic Motivation (1990–2010)},
volume = {2},
journal = {Autonomous Mental Development, IEEE Transactions on},
doi = {10.1109/TAMD.2010.2056368}
}

@inproceedings{poupart2006an,
author = {Poupart, Pascal and Vlassis, Nikos and Hoey, Jesse and Regan, Kevin},
title = {An Analytic Solution to Discrete Bayesian Reinforcement Learning},
year = {2006},
isbn = {1595933832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1143844.1143932},
doi = {10.1145/1143844.1143932},
abstract = {Reinforcement learning (RL) was originally proposed as a framework to allow agents to learn in an online fashion as they interact with their environment. Existing RL algorithms come short of achieving this goal because the amount of exploration required is often too costly and/or too time consuming for online learning. As a result, RL is mostly used for offline learning in simulated environments. We propose a new algorithm, called BEETLE, for effective online learning that is computationally efficient while minimizing the amount of exploration. We take a Bayesian model-based approach, framing RL as a partially observable Markov decision process. Our two main contributions are the analytical derivation that the optimal value function is the upper envelope of a set of multivariate polynomials, and an efficient point-based value iteration algorithm that exploits this simple parameterization.},
booktitle = {Proceedings of the 23rd International Conference on Machine Learning},
pages = {697–704},
numpages = {8},
location = {Pittsburgh, Pennsylvania, USA},
series = {ICML '06}
}

@inproceedings{sekar2020planning,
  title={Planning to explore via self-supervised world models},
  author={Sekar, Ramanan and Rybkin, Oleh and Daniilidis, Kostas and Abbeel, Pieter and Hafner, Danijar and Pathak, Deepak},
  booktitle={International Conference on Machine Learning},
  pages={8583--8592},
  year={2020},
  organization={PMLR}
}



@article{ecoffet2021first,
  title={First return then explore},
  author={Adrien Ecoffet and Joost Huizinga and Joel Lehman and Kenneth O. Stanley and Jeff Clune},
  journal={Nature},
  year={2021},
  volume={590 7847},
  pages={
          580-586
        }
}

@inproceedings{
    pislar2022when,
    title={When should agents explore?},
    author={Miruna Pislar and David Szepesvari and Georg Ostrovski and Diana L Borsa and Tom Schaul},
    booktitle={International Conference on Learning Representations},
    year={2022},
    url={https://openreview.net/forum?id=dEwfxt14bca}
}

@inproceedings{
    tuyls2022multistage,
    title={Multi-Stage Episodic Control for Strategic Exploration in Text Games},
    author={Jens Tuyls and Shunyu Yao and Sham M. Kakade and Karthik R Narasimhan},
    booktitle={International Conference on Learning Representations},
    year={2022},
    url={https://openreview.net/forum?id=Ek7PSN7Y77z}
}

@inproceedings{pathak2017curiosity,
    author = {Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A. and Darrell, Trevor},
    title = {Curiosity-Driven Exploration by Self-Supervised Prediction},
    year = {2017},
    booktitle = ICML,
}

@inproceedings{
    burda2018exploration,
    title={Exploration by random network distillation},
    author={Yuri Burda and Harrison Edwards and Amos Storkey and Oleg Klimov},
    booktitle={International Conference on Learning Representations},
    year={2019},
    url={https://openreview.net/forum?id=H1lJJnR5Ym},
}

@article{plappert2017parameter,
  title={Parameter space noise for exploration},
  author={Plappert, Matthias and Houthooft, Rein and Dhariwal, Prafulla and Sidor, Szymon and Chen, Richard Y and Chen, Xi and Asfour, Tamim and Abbeel, Pieter and Andrychowicz, Marcin},
  journal={arXiv preprint arXiv:1706.01905},
  year={2017}
}

@inproceedings{bellemare2016count,
 author = {Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 title = {Unifying Count-Based Exploration and Intrinsic Motivation},
 url = {https://proceedings.neurips.cc/paper/2016/file/afda332245e2af431fb7b672a68b659d-Paper.pdf},
 volume = {29},
 year = {2016}
}


@article{osband2019deep,
  author  = {Ian Osband and Benjamin Van Roy and Daniel J. Russo and Zheng Wen},
  title   = {Deep Exploration via Randomized Value Functions},
  journal = {Journal of Machine Learning Research},
  year    = {2019},
  volume  = {20},
  number  = {124},
  pages   = {1--62},
  url     = {http://jmlr.org/papers/v20/18-339.html}
}

@misc{
chen2018ucb,
    title={{UCB} {EXPLORATION} {VIA} Q-{ENSEMBLES}},
    author={Richard Y. Chen and Szymon Sidor and Pieter Abbeel and John Schulman},
    booktitle={International Conference on Learning Representations},
    year={2019},
    url={https://openreview.net/forum?id=H1cKvl-Rb},
}

% roll in policies
@article{uchendu2022jump,
  title={Jump-Start Reinforcement Learning},
  author={Uchendu, Ikechukwu and Xiao, Ted and Lu, Yao and Zhu, Banghua and Yan, Mengyuan and Simon, Jos{\'e}phine and Bennice, Matthew and Fu, Chuyuan and Ma, Cong and Jiao, Jiantao and others},
  journal={arXiv preprint arXiv:2204.02372},
  year={2022}
}

@InProceedings{jiang17contextual,
      title = 	 {Contextual Decision Processes with low {B}ellman rank are {PAC}-Learnable},
      author =       {Nan Jiang and Akshay Krishnamurthy and Alekh Agarwal and John Langford and Robert E. Schapire},
      booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
      pages = 	 {1704--1713},
      year = 	 {2017},
      editor = 	 {Precup, Doina and Teh, Yee Whye},
      volume = 	 {70},
      series = 	 {Proceedings of Machine Learning Research},
      month = 	 {06--11 Aug},
      publisher =    {PMLR},
      pdf = 	 {http://proceedings.mlr.press/v70/jiang17c/jiang17c.pdf},
      url = 	 {https://proceedings.mlr.press/v70/jiang17c.html},
}
@inproceedings{agarwal2020policycover,
     author = {Agarwal, Alekh and Henaff, Mikael and Kakade, Sham and Sun, Wen},
     booktitle = NIPS,
     editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
     title = {PC-PG: Policy Cover Directed Exploration for Provable Policy Gradient Learning},
     url = {https://proceedings.neurips.cc/paper/2020/file/9b3a9fb4db30fc6594ec3990cbc09932-Paper.pdf},
     year = {2020}
}

% skills
@inproceedings{
    eysenbach2018diversity,
    title={Diversity is All You Need: Learning Skills without a Reward Function},
    author={Benjamin Eysenbach and Abhishek Gupta and Julian Ibarz and Sergey Levine},
    booktitle={International Conference on Learning Representations},
    year={2019},
    url={https://openreview.net/forum?id=SJx63jRqFm},
}

@article{sharma2019dynamics,
  title={Dynamics-aware unsupervised discovery of skills},
  author={Sharma, Archit and Gu, Shixiang and Levine, Sergey and Kumar, Vikash and Hausman, Karol},
  journal={arXiv preprint arXiv:1907.01657},
  year={2019}
}

@inproceedings{campos2020explore,
  author    = {Victor Campos and
               Alexander Trott and
               Caiming Xiong and
               Richard Socher and
               Xavier Gir{\'{o}}{-}i{-}Nieto and
               Jordi Torres},
  title     = {Explore, Discover and Learn: Unsupervised Discovery of State-Covering
               Skills},
  booktitle = ICML,
  series    = {Proceedings of Machine Learning Research},
  year      = {2020},
  url       = {http://proceedings.mlr.press/v119/campos20a.html},
  biburl    = {https://dblp.org/rec/conf/icml/CamposTXSGT20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{strouse2021learning,
  doi = {10.48550/ARXIV.2107.14226},
  
  url = {https://arxiv.org/abs/2107.14226},
  
  author = {Strouse, DJ and Baumli, Kate and Warde-Farley, David and Mnih, Vlad and Hansen, Steven},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Learning more skills through optimistic exploration},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{stratonovich1966value,
  title={Value of information when an estimated random variable is hidden},
  author={Stratonovich, RL and Grishanin, BA},
  journal={Izvestiya of USSR Academy of Sciences, Technical Cybernetics},
  volume={6},
  number={1},
  pages={3--15},
  year={1966}
}

@inproceedings{sledge2017balancing,
  title={Balancing exploration and exploitation in reinforcement learning using a value of information criterion},
  author={Sledge, Isaac J and Pr{\'\i}ncipe, Jos{\'e} C},
  booktitle={2017 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={2816--2820},
  year={2017},
  organization={IEEE}
}

@article{cogliati2017learning,
  title={Learning the value of information and reward over time when solving exploration-exploitation problems},
  author={Cogliati Dezza, Irene and Yu, Angela J and Cleeremans, Axel and Alexander, William},
  journal={Scientific reports},
  volume={7},
  number={1},
  pages={16919},
  year={2017},
  publisher={Nature Publishing Group UK London}
}