@string{CVPR = "IEEE Conference on Computer Vision and Pattern Recognition"}
@string{ICCV = "IEEE International Conference on Computer Vision"}
@string{ECCV = "European Conference on Computer Vision"}
@string{TPAMI = "IEEE Transactions on Pattern Analysis and Machine Intelligence"}
@string{NIPS = "Advances in Neural Information Processing Systems"}
@string{NeurIPS = "Neural Information Processing Systems"}
@string{ICLR = "International Conference on Learning Representations"}
@string{ICML = "International Conference on Machine Learning"}
@string{AAAI = "Association for the Advancement of Artificial Intelligence"}
@string{AISTATS = "International Conference on Artificial Intelligence and Statistics"}
@string{JMLR = "Journal of Machine Learning Research"}
@string{CoRL = "Conference on Robot Learning"}
@string{IROS = "IEEE/RSJ International Conference on Intelligent Robots and Systems"}
@string{ICRA = "IEEE International Conference on Robotics and Automation"}
@string{RSS = "Robotics: Science and Systems"}


@article{DQN,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{TRPO,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle= ICML,
  pages={1889--1897},
  year={2015}
}

@article{PPO,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{DDPG,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}


@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484},
  year={2016},
  publisher={Nature Publishing Group}
}

@inproceedings{mnih2016a3c,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle= ICML,
  pages={1928--1937},
  year={2016}
}

@misc{openaifive,
  title={ {O}pen{AI} {F}ive},
  url={https://blog.openai.com/openai-five/},
  year={2018}
}


@article{schulman2016gae,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  booktitle= ICLR,
  year={2016}
}

@inproceedings{ACER,
  title={Sample efficient actor-critic with experience replay},
  author={Wang, Ziyu and Bapst, Victor and Heess, Nicolas and Mnih, Volodymyr and Munos, Remi and Kavukcuoglu, Koray and de Freitas, Nando},
  booktitle= ICLR,
  year={2017}
}

@inproceedings{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},
  booktitle= NIPS,
  pages={5048--5058},
  year={2017}
}

@inproceedings{ACKTR,
  title={Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation},
  author={Wu, Yuhuai and Mansimov, Elman and Grosse, Roger B and Liao, Shun and Ba, Jimmy},
  booktitle={Advances in neural information processing systems},
  pages={5285--5294},
  year={2017}
}

@inproceedings{DDQN,
  title={Deep Reinforcement Learning with Double Q-Learning.},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle=AAAI,
  year={2016}
}

@inproceedings{espeholt2018impala,
  title={IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Volodymyr and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  booktitle= ICML,
  pages={1406--1415},
  year={2018}
}

@article{popov2017data,
  title={Data-efficient deep reinforcement learning for dexterous manipulation},
  author={Popov, Ivaylo and Heess, Nicolas and Lillicrap, Timothy and Hafner, Roland and Barth-Maron, Gabriel and Vecerik, Matej and Lampe, Thomas and Tassa, Yuval and Erez, Tom and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1704.03073},
  year={2017}
}

@inproceedings{DNC,
  title={Divide and Conquer Reinforcement Learning},
  author={Dibya Ghosh and Avi Singh and Aravind Rajeswaran and Vikash Kumar and Sergey Levine},
  booktitle= ICLR,
  year={2018}
}

@article{riedmiller2018,
  title={Learning by Playing-Solving Sparse Reward Tasks from Scratch},
  author={Riedmiller, Martin and Hafner, Roland and Lampe, Thomas and Neunert, Michael and Degrave, Jonas and Van de Wiele, Tom and Mnih, Volodymyr and Heess, Nicolas and Springenberg, Jost Tobias},
  journal={arXiv preprint arXiv:1802.10567},
  year={2018}
}

@article{goel2018,
  author    = {Vik Goel and
               Jameson Weng and
               Pascal Poupart},
  title     = {Unsupervised Video Object Segmentation for Deep Reinforcement Learning},
  journal   = {arXiv preprint arXiv:1805.07780},
  year      = {2018},
}

@inproceedings{scholz14,
 author = {Scholz, Jonathan and Levihn, Martin and Isbell, Charles L. and Wingate, David},
 title = {A Physics-based Model Prior for Object-oriented MDPs},
 booktitle = ICML,
 year = {2014},
}

@article{zaremba2015reinforcement,
  title={Reinforcement learning neural Turing machines},
  author={Zaremba, Wojciech and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1505.00521},
  year={2015}
}

@inproceedings{haarnoja2018sac,
  title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle=ICML,
  pages={1856--1865},
  year={2018}
}

@article{haarnoja2018sac2,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@inproceedings{higgins2017darla,
  title={Darla: Improving zero-shot transfer in reinforcement learning},
  author={Higgins, Irina and Pal, Arka and Rusu, Andrei and Matthey, Loic and Burgess, Christopher and Pritzel, Alexander and Botvinick, Matthew and Blundell, Charles and Lerchner, Alexander},
  booktitle=ICML,
  pages={1480--1490},
  year={2017},
}

@inproceedings{singh2019end-to-end, 
    AUTHOR    = {Avi Singh AND Larry Yang AND Chelsea Finn AND Sergey Levine}, 
    TITLE     = {End-To-End Robotic Reinforcement Learning without Reward Engineering}, 
    BOOKTITLE = RSS, 
    YEAR      = {2019}, 
} 

@inproceedings{
wang2018nervenet,
title={NerveNet: Learning Structured Policy with Graph Neural Networks},
author={Tingwu Wang and Renjie Liao and Jimmy Ba and Sanja Fidler},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=S1sqHMZCb},
}

@misc{uchendu2022jump,
  doi = {10.48550/ARXIV.2204.02372},
  
  url = {https://arxiv.org/abs/2204.02372},
  
  author = {Uchendu, Ikechukwu and Xiao, Ted and Lu, Yao and Zhu, Banghua and Yan, Mengyuan and Simon, Jos√©phine and Bennice, Matthew and Fu, Chuyuan and Ma, Cong and Jiao, Jiantao and Levine, Sergey and Hausman, Karol},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Jump-Start Reinforcement Learning},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{yang2021exploration,
  title={Exploration in deep reinforcement learning: a comprehensive survey},
  author={Yang, Tianpei and Tang, Hongyao and Bai, Chenjia and Liu, Jinyi and Hao, Jianye and Meng, Zhaopeng and Liu, Peng and Wang, Zhen},
  journal={arXiv preprint arXiv:2109.06668},
  year={2021}
}

@inproceedings{
micheli2023transformers,
title={Transformers are Sample-Efficient World Models},
author={Vincent Micheli and Eloi Alonso and Fran{\c{c}}ois Fleuret},
booktitle={International Conference on Learning Representations},
year={2023},
url={https://openreview.net/forum?id=vhFu1Acb0xb}
}