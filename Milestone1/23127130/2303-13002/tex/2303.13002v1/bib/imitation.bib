@string{CVPR = "IEEE Conference on Computer Vision and Pattern Recognition"}
@string{ICCV = "IEEE International Conference on Computer Vision"}
@string{ECCV = "European Conference on Computer Vision"}
@string{TPAMI = "IEEE Transactions on Pattern Analysis and Machine Intelligence"}
@string{NIPS = "Advances in Neural Information Processing Systems"}
@string{NeurIPS = "Neural Information Processing Systems"}
@string{ICLR = "International Conference on Learning Representations"}
@string{ICML = "International Conference on Machine Learning"}
@string{AAAI = "Association for the Advancement of Artificial Intelligence"}
@string{AISTATS = "International Conference on Artificial Intelligence and Statistics"}
@string{JMLR = "Journal of Machine Learning Research"}
@string{CoRL = "Conference on Robot Learning"}
@string{IROS = "IEEE/RSJ International Conference on Intelligent Robots and Systems"}
@string{ICRA = "IEEE International Conference on Robotics and Automation"}
@string{RSS = "Robotics: Science and Systems"}

@article{raychaudhuri2021cross,
  author    = {Dripta S. Raychaudhuri and
               Sujoy Paul and
               Jeroen van Baar and
               Amit K. Roy{-}Chowdhury},
  title     = {Cross-domain Imitation from Observations},
  booktitle = ICML,
  year = {2021},
}

@inproceedings{schaal1997learning,
  title={Learning from demonstration},
  author={Schaal, Stefan},
  booktitle=NIPS,
  pages={1040--1046},
  year={1997}
}

@inproceedings{ross2011dagger,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle=AISTATS,
  pages={627--635},
  year={2011}
}

@article{hester2017deep,
  title={Deep Q-learning from Demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Dulac-Arnold, Gabriel and others},
  journal={arXiv preprint arXiv:1704.03732},
  year={2017}
}

@inproceedings{nair2018overcoming,
  title={Overcoming exploration in reinforcement learning with demonstrations},
  author={Nair, Ashvin and McGrew, Bob and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle=ICRA,
  pages={6292--6299},
  year={2018},
}

@inproceedings{sermanet2018time,
  title={Time-contrastive networks: Self-supervised learning from video},
  author={Sermanet, Pierre and Lynch, Corey and Chebotar, Yevgen and Hsu, Jasmine and Jang, Eric and Schaal, Stefan and Levine, Sergey},
  booktitle=ICRA,
  pages={1134--1141},
  year={2018},
}

@article{sermanet2017rewards,
  author    = {Pierre Sermanet and Kelvin Xu and Sergey Levine},
  title     = {Unsupervised Perceptual Rewards for Imitation Learning},
  journal   = RSS,
  year      = {2017}
}

@inproceedings{finn2017one-shot,
  title={One-Shot Visual Imitation Learning via Meta-Learning},
  author={Finn, Chelsea and Yu, Tianhe and Zhang, Tianhao and Abbeel, Pieter and Levine, Sergey},
  booktitle=CoRL,
  pages={357--368},
  year={2017}
}

@inproceedings{duan2017one-shot,
  title={One-shot imitation learning},
  author={Duan, Yan and Andrychowicz, Marcin and Stadie, Bradly and Ho, Jonathan and Schneider, Jonas and Sutskever, Ilya and Abbeel, Pieter and Zaremba, Wojciech},
  booktitle=NIPS,
  pages={1087--1098},
  year={2017}
}

@inproceedings{liu2018imitation,
  title={Imitation from observation: Learning to imitate behaviors from raw video via context translation},
  author={Liu, YuXuan and Gupta, Abhishek and Abbeel, Pieter and Levine, Sergey},
  booktitle=ICRA,
  pages={1118--1125},
  year={2018},
}

@inproceedings{finn2017one,
  title={One-Shot Visual Imitation Learning via Meta-Learning},
  author={Finn, Chelsea and Yu, Tianhe and Zhang, Tianhao and Abbeel, Pieter and Levine, Sergey},
  booktitle=CoRL,
  pages={357--368},
  year={2017}
}

@article{yu2018aone,
  title={One-shot imitation from observing humans via domain-adaptive meta-learning},
  author={Yu, Tianhe and Finn, Chelsea and Xie, Annie and Dasari, Sudeep and Zhang, Tianhao and Abbeel, Pieter and Levine, Sergey},
  journal=RSS,
  year={2018}
}

@article{yu2018bone,
  title={One-Shot Hierarchical Imitation Learning of Compound Visuomotor Tasks},
  author={Yu, Tianhe and Abbeel, Pieter and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:1810.11043},
  year={2018}
}

@inproceedings{peng2018sfv,
  title={Sfv: Reinforcement learning of physical skills from videos},
  author={Peng, Xue Bin and Kanazawa, Angjoo and Malik, Jitendra and Abbeel, Pieter and Levine, Sergey},
  booktitle={SIGGRAPH Asia},
  pages={178},
  year={2018},
  organization={ACM}
}

@inproceedings{sun2018neural,
  title = {Neural Program Synthesis from Diverse Demonstration Videos},
  author = {Sun, Shao-Hua and Noh, Hyeonwoo and Somasundaram, Sriram and Lim, Joseph J.},
  booktitle = ICML,
  year = {2018},
}

@article{Meltzoff2007TheM,
  title={The 'like me' framework for recognizing and becoming an intentional agent.},
  author={A. Meltzoff},
  journal={Acta psychologica},
  year={2007},
  volume={124 1},
  pages={
          26-43
        }
}

@article{butterworth1992origins,
 ISSN = {1047840X, 15327965},
 URL = {http://www.jstor.org/stable/1449193},
 author = {George Butterworth},
 journal = {Psychological Inquiry},
 number = {2},
 pages = {103--111},
 publisher = {Taylor & Francis, Ltd.},
 title = {Origins of Self-Perception in Infancy},
 volume = {3},
 year = {1992}
}



@article{mounad1981representation,
 author = {Mounoud, Pierre and Vinter, A.},
 journal = {Infancy and epistemology: An evaluation of Piaget's theory},
 pages = {200--235},
 title = {Representation and sensorimotor development},
 year = {1981}
}

@inproceedings{
zhang2021learning,
title={Learning Cross-Domain Correspondence for Control with Dynamics Cycle-Consistency},
author={Qiang Zhang and Tete Xiao and Alexei A Efros and Lerrel Pinto and Xiaolong Wang},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=QIRlze3I6hX}
}

@InProceedings{lee2019silo, title = {To Follow or not to Follow: Selective Imitation Learning from Observations}, author = {Lee, Youngwoon and Hu, Edward S. and Yang, Zhengyu and Lim, Joseph J.}, booktitle = {Proceedings of the Conference on Robot Learning}, pages = {11--23}, year = {2020}, editor = {Leslie Pack Kaelbling and Danica Kragic and Komei Sugiura}, volume = {100}, series = {Proceedings of Machine Learning Research}, address = {}, month = {30 Oct--01 Nov}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v100/lee20a/lee20a.pdf}, url = {http://proceedings.mlr.press/v100/lee20a.html}, abstract = {Learning from demonstrations is a useful way to transfer a skill from one agent to another. While most imitation learning methods aim to mimic an expert skill by following the demonstration step-by-step, imitating every step in the demonstration often becomes infeasible when the learner and its environment are different from the demonstration. In this paper, we propose a method that can imitate a demonstration composed solely of observations, which may not be reproducible with the current agent. Our method, dubbed selective imitation learning from observations (SILO), selects reachable states in the demonstration and learns how to reach the selected states. Our experiments on both simulated and real robot environments show that our method reliably performs a new task by following a demonstration. Videos and code are available at https://clvrai.com/silo.} }

@InProceedings{kim2020domain, title = {Domain Adaptive Imitation Learning}, author = {Kim, Kuno and Gu, Yihong and Song, Jiaming and Zhao, Shengjia and Ermon, Stefano}, booktitle = {Proceedings of the 37th International Conference on Machine Learning}, pages = {5286--5295}, year = {2020}, editor = {Hal Daumé III and Aarti Singh}, volume = {119}, series = {Proceedings of Machine Learning Research}, month = {13--18 Jul}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v119/kim20c/kim20c.pdf}, url = { http://proceedings.mlr.press/v119/kim20c.html }, abstract = {We study the question of how to imitate tasks across domains with discrepancies such as embodiment, viewpoint, and dynamics mismatch. Many prior works require paired, aligned demonstrations and an additional RL step that requires environment interactions. However, paired, aligned demonstrations are seldom obtainable and RL procedures are expensive. In this work, we formalize the Domain Adaptive Imitation Learning (DAIL) problem - a unified framework for imitation learning in the presence of viewpoint, embodiment, and/or dynamics mismatch. Informally, DAIL is the process of learning how to perform a task optimally, given demonstrations of the task in a distinct domain. We propose a two step approach to DAIL: alignment followed by adaptation. In the alignment step we execute a novel unsupervised MDP alignment algorithm, Generative Adversarial MDP Alignment (GAMA), to learn state and action correspondences from \emph{unpaired, unaligned} demonstrations. In the adaptation step we leverage the correspondences to zero-shot imitate tasks across domains. To describe when DAIL is feasible via alignment and adaptation, we introduce a theory of MDP alignability. We experimentally evaluate GAMA against baselines in embodiment, viewpoint, and dynamics mismatch scenarios where aligned demonstrations don’t exist and show the effectiveness of our approach} }


@article{zhou2021manipulator,
  title={Manipulator-Independent Representations for Visual Imitation},
  author={Zhou, Yuxiang and Aytar, Yusuf and Bousmalis, Konstantinos},
  journal=RSS,
  year={2021}
}