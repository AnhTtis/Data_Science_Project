\section{conclusion}
 % - dex  grasp 传统方法

 % - dex grasp learning 方法（learning的方法里面，要有一段体现下hand object representation)

In this paper, we proposed a novel hand-object interaction representation for robotic dexterous grasping, called \rep, which consists of Occupancy Feature, Surface Feature, and Local-Geo Feature. This representation captures the relative shape feature of the objects and the spatial relation between hands and objects during hand-object interactions, enabling generalization to novel objects. Based on this representation, we proposed a dexterous deep reinforcement learning method, named \method, to train a generalizable grasping policy. Experimental results demonstrate the effectiveness of our proposed representation and method. Compared to baselines, our method achieves higher grasp success rates on both seen and unseen objects and also shows better generalization ability in both simulation and the real world. In summary, our proposed method provides a promising solution for robotic dexterous grasping in unstructured environments, enabling robots to perform complex tasks and achieve human-like capabilities. 

% Our work opens up new directions for future research on hand-object interaction representations and deep reinforcement learning for robotic dexterous grasping.

\section{acknowledgments}

This work was supported in part by NSFC under Grants 62088101, 62103372, and 62233013.