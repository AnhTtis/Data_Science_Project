\section{Experiments}
%*************************************************
\subsection{Datasets}
\textbf{CAMELYON16.} 
The Camelyon16~\cite{bejnordi2017diagnostic} dataset consists of 399 H\&E stained slides from breast cancer screening, with two classes: normal and tumor. 
We employ the official 129 testing set, and the official 270 training set is further divided randomly into training and validation sets, with a ratio of $9\colon1$. After preprocessing, a total of 4,610,687 patches with the size of $256\times256$ are obtained at $20\times$ magnification, with an average of 11,556 patches per slide. \\
\textbf{TCGA-NSCLC.} 
The Cancer Genome Atlas\footnote{\url{https://www.cancer.gov/tcga}} (TCGA) non-small cell lung cancer (NSCLC)~\cite{newman2015robust} dataset is comprised of two subtypes of lung cancer: Lung Adenocarcinoma (TCGA-LUAD) and Lung Squamous Cell Carcinoma (TGCA-LUSC). It contains a total of 1,053 WSIs, with 541 LUAD slides and 512 LUSC slides. We split the dataset into training, validation, and testing sets at the slide level, with a distribution ratio of 65:10:25. In our study, we extract $256\times256$ patches at $20\times$ magnification from each WSI. After preprocessing, a total of 3,252,431 patches are obtained, with an average of 3,089 patches per WSI.
%*************************************************
\subsection{Implementation Details}
\label{Implementation}
In our approach, we adopt the ResNet model as the feature extractor, which is pre-trained on the ImageNet dataset.
We remove the last layer of the ResNet following~\cite{CLAM} and add prompt blocks to the third layer.
For ResNet-18 and ResNet-50, we set the number of prompt blocks as 2 and 6, respectively.
For representative patch selection, we select the top 200 patches for each WSI bag by default.
For the prompt fine-tuning, we freeze the backbone of ResNet and only train the prompt block and MIL classifier using the Adam optimizer~\cite{kingma2014adam} with a learning rate of 1e-4 and weight decay of 1e-4 for 100 epochs. 
All the experiments are conducted with an NVIDIA GeForce RTX 3090 GPU. 

% *************************************************
\subsection{Comparison Results}
\input{Table/table1}
In this study, we comprehensively evaluate the effectiveness of our proposed framework with various experiment settings, including two datasets: Cameylon16~\cite{bejnordi2017diagnostic} and TCGA-NSCLC~\cite{newman2015robust}; two backbone networks: ResNet-18 and ResNet-50; and two MIL classifiers: a state-of-the-art model DTFD~\cite{DTFD} and a common model ABMIL~\cite{ABMIL}. We report the area under curve (AUC), accuracy (Acc), and F1-score as evaluation metrics for WSI classification task.
Table~\ref{table1} shows the eight different settings of experiments. The first row in each setting represents the baseline approach with the frozen feature extractor. The second row (RPS-FT) represents using the representative patches to fine-tune both the feature extractor and MIL classifier. The third row (RPS-PT) represents our prompt fine-tuning method.
 
In Table~\ref{table1}, we can observe that our method achieves a consistent improvement compared to both the baseline approach and the fine-tuning approach.
Notably, when using ResNet-18 as the feature extractor, our method achieves a higher AUC than the DTFD baseline, with an improvement of 3.83\% on the Camelyon16 dataset and 1.28\% on the TCGA-NSCLC dataset. 
Notably, our method with prompt blocks significantly outperforms the RPS-FT scheme, demonstrating the advantage of our visual prompts.
Besides, our method shows particularly superior results on the Camelyon16 dataset compared to the results on the TCGA-NSCLC dataset. 
This can be attributed to the fact that the Camelyon16 dataset has fewer WSIs and a smaller proportion of tumor regions. 
This further confirms the advantage of our approach in handling challenging datasets. Overall, the experiment results indicate that our method effectively improves the performance of attention-based MIL methods on the WSI classification tasks. 

% *************************************************
\subsection{Ablation Study}
\input{Figure/Ablation}
\noindent\textbf{Effectiveness of the prompt block number.}
To study the impact of the prompt component number, we conduct experiments on the Camelyon16 dataset using DTFD as the MIL classifier with different numbers of prompt blocks added to ResNet-50.
The results presented in Fig.~\ref{fig_ablation} $(a)$ show that the AUC values with different prompt quantities are consistently improved by approximately 1\% compared to the baseline approach when using more than one prompt block. 
These results suggest that our prompt block component is robust and effectively improves the performance of the feature extractor.

\noindent\textbf{Influence of the number of representative patches.}
We investigate the effect of different top-$K$ values in the RPS procedure on the performance of our method using ResNet-50 and DTFD on the Camelyon16 dataset. 
Fig.~\ref{fig_ablation} $(b)$ shows the AUC values under two different settings: fine-tuning scheme (RPS-FT) and our prompt fine-tuning scheme (RPS-PT). 
Our method consistently outperforms the fine-tuning scheme across all $K$ values using less than 50\% GPU resources, demonstrating the efficiency and effectiveness of our method.

\subsection{Analysis on the Effectiveness of Visual Prompts}
During the experiment, we found that fine-tuning produced unsatisfactory performance, which was even inferior to the baselines where the feature extractor was frozen. 
This subpar performance can be attributed to the specific nature of the WSI classification task. 
It requires processing all the patches in a given WSI during each iteration of model updating, which is computationally expensive. 
As a result, only a small portion of the instances are used for training, leading to a high risk of overfitting.
In contrast, our proposed method of using visual prompts allows for the quick learning of the policy of the current task based on the previously learned representation, enabling an efficient task and domain adaption, thereby overcoming the limitations of fine-tuning. 