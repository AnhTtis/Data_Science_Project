\section{Introduction}
Whole slide images (WSI) play a vital role in histopathology image analysis and clinical disease diagnosis~\cite{1,2,3}. 
With the advent of deep-learning-based techniques, histopathology image analysis has undergone a significant transformation~\cite{4,6}. However, there are still challenges when it comes to classifying WSI. Due to their massive size, WSIs cannot be directly fed into typical deep-learning models. Therefore, WSIs are often divided into patches for processing~\cite{hou2016patch}. 
Unfortunately, annotating patch-level labels is labor-intensive and time-consuming, which limits the applicability of conventional supervised learning methods~\cite{7,8}. To address this issue, multiple instance learning (MIL) has emerged as the dominant technique for WSI analysis. In this approach, each WSI is considered as a bag containing multiple patches (instances), and a WSI bag is labeled negative only if all patches (instances) of this bag are negative. Conversely, the bag's label is positive if at least one of its instances is positive. 

Downsampling and feature extraction are necessary due to the large number of patches in a WSI. 
The quality of the extracted patch features greatly influences the performance of the subsequent MIL classification. 
Most existing methods~\cite{ABMIL,DSMIL,DTFD,CLAM} extract patch features by a frozen feature extractor pre-trained on the large natural image datasets, such as ImageNet~\cite{deng2009imagenet}, and then train the MIL classifier for the WSI prediction, as shown in Fig.~\ref{fig_innovation} $(a)$.  
However, such a MIL training scheme overlooks the domain shift issue between natural and pathological images.
To narrow the domain shift, some researchers~\cite{ssl} propose to use self-supervised pre-training methods such as SimCLR~\cite{chen2020simple} to train the feature extractor. 
However, these self-supervised learning methods do not take full advantage of the bag labels, resulting in limited performance. 
Another naive solution is to use partial patches instead of all patches to fine-tune the pre-trained feature extractor, as illustrated in Fig.~\ref{fig_innovation} $(b)$. 
However, fine-tuning all the parameters of the feature extractor using limited patches without patch-level labels may impair the benefits from pre-training on large-scale datasets like ImageNet, which increases the risk of overfitting in downstream tasks. 

\input{Figure/innovation}

Inspired by the breakthrough of prompt learning in natural language processing (NLP), we introduce visual prompts to adapt the pre-trained feature extractor to pathological images, addressing the aforementioned issue.
Our prompt learning framework for MIL-based WSI classification is shown in Fig.~\ref{fig_innovation} $(c)$.
Limited by memory capacity, we propose a feasible solution that selects representative pathological images, instead of all patches, to fine-tune the pre-trained feature extractor.
Based on the selected images, we design a prompt component added to the feature extractor to learn visual prompts, and freeze the backbone while only training the prompt component with the lightweight MIL classifier.
In this way, our method can improve the performance of the ImageNet pre-trained feature extractor and achieve domain transformation to pathological image data.
Our method also makes the entire training process highly efficient and lightweight. 
To the best of our knowledge, this is the first work to explore prompt learning for WSI classification. 
In summary, our contributions are three-fold:
\begin{itemize}
    \item[$\bullet$] We, for the first time, introduce visual prompts into WSI classification, which enables data domain transformation by learning prompt components.
    \item[$\bullet$] We propose an intuitive but effective method for end-to-end prompt training, which involves representative patch selection to reduce the number of instances in a WSI bag. 
    \item[$\bullet$] We conduct extensive experiments to validate the effectiveness of the proposed method on two public datasets, \ie, Camelyon16 and TCGA-NSCLC. Experimental results demonstrate consistent improvements across different MIL methods and backbones.
\end{itemize}





