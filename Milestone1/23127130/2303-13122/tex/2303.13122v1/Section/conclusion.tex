\section{Conclusion}
In this paper, we propose a novel prompt learning method to learn domain-specific knowledge transformation from ImageNet pre-trained models to pathological images. 
Our innovation is based on the observation that there is a large domain shift and task discrepancy between the upstream datasets and pathological tasks, resulting in sub-optimal feature representation.
To relieve this issue, we introduce a prompt component and representative patches selection strategy to fine-tune the prompt blocks while freezing the feature extractor backbone.
In this way, the extracted patch features can be adapted for pathological images and boost the WSI classification with MIL models.
Experiments on two public datasets (\ie, Cameylon16 and TCGA-NSCLC) with two MIL classifiers (\ie, DTFD and ABMIL) demonstrate the effectiveness and efficiency of our method. 