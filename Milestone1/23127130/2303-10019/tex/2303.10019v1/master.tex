% !TEX root = master.tex
% elsearticle docs: https://www.elsevier.com/__data/assets/pdf_file/0008/56843/elsdoc-1.pdf
\documentclass[review, nopreprintline, authoryear]{elsarticle}

\usepackage[a4paper, left=4cm, right=4cm, top=4cm, bottom=4cm]{geometry}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

% Pakete f端r mathematische Symbole
% Pakete f端r mathematische Symbole
\usepackage{amsmath}
\usepackage{amstext}
\usepackage{amssymb}
\usepackage{latexsym}
\usepackage{dsfont}
\usepackage{mathrsfs}
% \usepackage{setspace}
% \usepackage{ulem}
\usepackage{bbold}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    unicode=true
}

% See for problem with hyperref and \corref command
% https://tex.stackexchange.com/questions/504814/package-hyperref-warning-token-not-allowed-in-a-pdf-string-pdfdocencoding/559193
\pdfstringdefDisableCommands{%
  \def\corref#1{<#1>}%
}

\usepackage{graphicx}
\usepackage{float}
\usepackage{caption, booktabs}
\usepackage{graphics}
\usepackage{subcaption}
\usepackage{lipsum}
\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage[table, dvipsnames]{xcolor}
\usepackage{mathrsfs}
\usepackage{soul}

% \setlength{\parindent}{50mm} % ver\"andert den Einzug
% \usepackage[pdftex]{graphicx} %notwendig, wenn Grafiken geladen werden sollen
\usepackage{url} % zum korrekten Einf\"ugen von URL mit dem \url Befehl, das Package hyperref erzeugt dazu noch Links

\usepackage{bm}
\usepackage{bbm}
\usepackage{array}

% \usepackage{listings}
% \lstset{language=R,showstringspaces=false,breaklines=true, numbers=left,
% numbersep=2pt, tabsize=2, numberstyle=\tiny\color{gray}} 
\usepackage[noend, linesnumbered,ruled,vlined]{algorithm2e}

% Helper to align equations in algorithm environments
\newcommand{\ali}[2]{\makebox[#1][l]{#2}}
% \usepackage[all]{xy}
%\usepackage{url}
%\usepackage{color}
%\usepackage[usenames,dvipsnames]{color}
\usepackage{tikz}
\newcommand{\mx}[1]{\mathbf{\bm{#1}}} % Matrix command
\newcommand{\vc}[1]{\mathbf{\bm{#1}}} % Vector command


\usepackage{attachfile}






\definecolor{b}{rgb}{0,0,.8}	%%omega-blau
\definecolor{g}{rgb}{0,.6,0}	%%Tau-gr端n
\definecolor{n}{rgb}{0,0,0}	%%normal-schwarz
\definecolor{h}{rgb}{0.4,0.2,0.2}	%%hint
\definecolor{v}{rgb}{0.2,0.6,0}

\newtheorem{beispiel}{Beispiel}
\newtheorem{gbsp}{Gegenbeispiel}
\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{theorem}{Theorem}
\newtheorem{satz}{Satz}
\newtheorem{bem}{Bemerkung}
\newtheorem{bew}{Beweis}
\newtheorem{korollar}{Korollar}


%mathbb alphabet
\newcommand{\A}{{\mathbb A}}
\newcommand{\B}{{\mathbb B}}
%\newcommand{\C}{{\mathbb C}}
%\newcommand{\D}{{\mathbb D}}
\newcommand{\E}{{\mathbb E}}
\newcommand{\F}{{\mathbb F}}
%\newcommand{\G}{{\mathbb G}}
\renewcommand{\H}{{\mathbb H}}
\newcommand{\I}{{\mathbb I}}
\newcommand{\J}{{\mathbb J}}
\newcommand{\K}{{\mathbb K}}
\renewcommand{\L}{{\mathbb L}}
\newcommand{\M}{{\mathbb M}}
\newcommand{\N}{{\mathbb N}}
\renewcommand{\O}{{\mathbb O}}
%\renewcommand{\P}{{\mathbb P}}
\newcommand{\Q}{{\mathbb Q}}
\newcommand{\R}{{\mathbb R}}
%\renewcommand{\S}{{\mathbb S}}
\newcommand{\T}{{\mathbb T}}
%\newcommand{\U}{{\mathbb U}}
\newcommand{\V}{{\mathbb V}}
\newcommand{\W}{{\mathbb W}}
\newcommand{\X}{{\mathbb X}}
\newcommand{\Y}{{\mathbb Y}}
\newcommand{\Z}{{\mathbb Z}}

%mathcal alphabet
\renewcommand{\AA}{{\mathcal{A}}}
\newcommand{\BB}{{\mathcal{B}}}
\newcommand{\CC}{{\mathcal{C}}}
\newcommand{\DD}{{\mathcal{D}}}
\newcommand{\EE}{{\mathcal{E}}}
\newcommand{\FF}{{\mathcal{F}}}
\newcommand{\CG}{{\mathcal{G}}}
\newcommand{\HH}{{\mathcal{H}}}
\newcommand{\II}{{\mathcal{I}}}
\newcommand{\JJ}{{\mathcal{J}}}
\newcommand{\KK}{{\mathcal{K}}}
\newcommand{\LL}{{\mathcal{L}}}
\newcommand{\MM}{{\mathcal{M}}}
\newcommand{\NN}{{\mathcal{N}}}
\newcommand{\OO}{{\mathcal{O}}}
\newcommand{\PP}{{\mathcal{P}}}
\newcommand{\QQ}{{\mathcal{Q}}}
\newcommand{\RR}{{\mathcal{R}}}
\renewcommand{\SS}{{\mathcal{S}}}
\newcommand{\TT}{{\mathcal{T}}}
\newcommand{\UU}{{\mathcal{U}}}
\newcommand{\VV}{{\mathcal{V}}}
\newcommand{\WW}{{\mathcal{W}}}
\newcommand{\XX}{{\mathcal{X}}}
\newcommand{\YY}{{\mathcal{Y}}}
\newcommand{\ZZ}{{\mathcal{Z}}}

%boldsymbols
\newcommand{\bsa}{\boldsymbol a}
\newcommand{\bsb}{\boldsymbol b}
\newcommand{\bsc}{\boldsymbol c}
\newcommand{\bsd}{\boldsymbol d}
\newcommand{\bse}{\boldsymbol e}
\newcommand{\bsf}{\boldsymbol f}
\newcommand{\bsg}{\boldsymbol g}
\newcommand{\bsh}{\boldsymbol h}
\newcommand{\bsi}{\boldsymbol i}
\newcommand{\bsj}{\boldsymbol j}
\newcommand{\bsk}{\boldsymbol k}
\newcommand{\bsl}{\boldsymbol l}
\newcommand{\bsm}{\boldsymbol m}
\newcommand{\bsn}{\boldsymbol n}
\newcommand{\bso}{\boldsymbol o}
\newcommand{\bsp}{\boldsymbol p}
\newcommand{\bsq}{\boldsymbol q}
\newcommand{\bsr}{\boldsymbol r}
\newcommand{\bss}{\boldsymbol s}
\newcommand{\bst}{\boldsymbol t}
\newcommand{\bsu}{\boldsymbol u}
\newcommand{\bsv}{\boldsymbol v}
\newcommand{\bsw}{\boldsymbol w}
\newcommand{\bsx}{\boldsymbol x}
\newcommand{\bsy}{\boldsymbol y}
\newcommand{\bsz}{\boldsymbol z}
\newcommand{\bsA}{\boldsymbol A}
\newcommand{\bsB}{\boldsymbol B}
\newcommand{\bsC}{\boldsymbol C}
\newcommand{\bsD}{\boldsymbol D}
\newcommand{\bsE}{\boldsymbol E}
\newcommand{\bsF}{\boldsymbol F}
\newcommand{\bsG}{\boldsymbol G}
\newcommand{\bsH}{\boldsymbol H}
\newcommand{\bsI}{\boldsymbol I}
\newcommand{\bsJ}{\boldsymbol J}
\newcommand{\bsK}{\boldsymbol K}
\newcommand{\bsL}{\boldsymbol L}
\newcommand{\bsM}{\boldsymbol M}
\newcommand{\bsN}{\boldsymbol N}
\newcommand{\bsO}{\boldsymbol O}
\newcommand{\bsP}{\boldsymbol P}
\newcommand{\bsQ}{\boldsymbol Q}
\newcommand{\bsR}{\boldsymbol R}
\newcommand{\bsS}{\boldsymbol S}
\newcommand{\bsT}{\boldsymbol T}
\newcommand{\bsU}{\boldsymbol U}
\newcommand{\bsV}{\boldsymbol V}
\newcommand{\bsW}{\boldsymbol W}
\newcommand{\bsX}{\boldsymbol X}
\newcommand{\bsY}{\boldsymbol Y}
\newcommand{\bsZ}{\boldsymbol Z}
\newcommand{\bsone}{\boldsymbol 1}
\newcommand{\bstwo}{\boldsymbol 2}
\newcommand{\bsthree}{\boldsymbol 3}
\newcommand{\bsfour}{\boldsymbol 4}
\newcommand{\bsfive}{\boldsymbol 5}
\newcommand{\bssix}{\boldsymbol 6}
\newcommand{\bsseven}{\boldsymbol 7}
\newcommand{\bseight}{\boldsymbol 8}
\newcommand{\bsnine}{\boldsymbol 9}
\newcommand{\bszero}{\boldsymbol 0}
\newcommand{\bsnought}{\boldsymbol 0}
\newcommand{\bsnaught}{\boldsymbol 0}
\newcommand{\bsnull}{\boldsymbol 0}
\newcommand{\bsnil}{\boldsymbol 0}

%greeks
\newcommand{\bsalpha}{\boldsymbol \alpha}
\newcommand{\bsbeta}{\boldsymbol \beta}
\newcommand{\bslambda}{\boldsymbol \lambda}
\newcommand{\bsmu}{\boldsymbol \mu}
\newcommand{\bseps}{\boldsymbol \varepsilon}
\newcommand{\bstheta}{\boldsymbol \theta}
\newcommand{\bssigma}{\boldsymbol \sigma}
\newcommand{\bszeta}{\boldsymbol \zeta}
\newcommand{\bsvarphi}{\boldsymbol \varphi}

\newcommand{\bsGamma}{\boldsymbol \Gamma}
\newcommand{\bsPhi}{\boldsymbol \Phi}
\newcommand{\bsSigma}{\boldsymbol \Sigma}
\newcommand{\bsPi}{\boldsymbol \Pi}


%easier greeks
%capital
\newcommand{\Om}{{\Omega}}
\newcommand{\Ome}{{\Omega}}
\newcommand{\Omeg}{{\Omega}}
%small
\newcommand{\eps}{{\varepsilon}}
\newcommand{\epsi}{{\epsilon}}
\newcommand{\kap}{{\kappa}}

% gen math
\DeclareMathOperator*{\klimsup}{K-lim\,sup}
\DeclareMathOperator*{\kliminf}{K-lim\,inf}
\DeclareMathOperator*{\klim}{K-lim}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\epi}{epi}
\DeclareMathOperator{\lev}{lev}
\DeclareMathOperator{\gr}{graph}
\DeclareMathOperator{\conv}{conv}	%convex hull
\DeclareMathOperator{\inter}{int}		%interior
\DeclareMathOperator{\cl}{cl}
\DeclareMathOperator{\bdy}{bdy}
\DeclareMathOperator{\relint}{relint}	%relative interior
\DeclareMathOperator{\relbdy}{relbdy}	%relative boundary
\DeclareMathOperator{\dist}{dist}
\DeclareMathOperator{\LSC}{LSC}
\DeclareMathOperator{\EPI}{EPI}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\ind}{\boldsymbol 1 }
\DeclareMathOperator{\gdc}{gdc}
\DeclareMathOperator{\modulo}{mod}
\DeclareMathOperator{\logit}{logit}
\DeclareMathOperator{\spt}{spt}
\DeclareMathOperator{\Tr}{Tr}

%stochastic commands
\DeclareMathOperator{\var}{\V ar}
\DeclareMathOperator{\cov}{\C ov}
\DeclareMathOperator{\cor}{\C or}
\DeclareMathOperator{\corr}{\C orr}
\DeclareMathOperator{\as}{\text{a.s.}}
\newcommand{\MC}{\text{MC}} 
\newcommand{\MLE}{\text{MLE}} 
\newcommand{\MCMLE}{\text{MC-MLE}} 

%general short cuts
\newcommand{\ov}\overline
\newcommand{\what}{\widehat}
\newcommand{\wtilde}{\widetilde}
\newcommand{\ow}{\text{ otherwise}}
\newcommand{\rig}\right
\newcommand{\lef}\left
\newcommand{\nf}\normalfont

%document specific
\newcommand{\bsPP}{\boldsymbol{\mathcal{P}}}
\newcommand{\bsDD}{\boldsymbol{\mathcal{D}}}
\DeclareMathOperator*{\bsQL}{\textbf{QL}}
\DeclareMathOperator*{\QL}{QL}
\DeclareMathOperator*{\CRPS}{CRPS}
\DeclareMathOperator*{\sign}{sign}
\newcommand{\bseta}{\boldsymbol \eta}
\DeclareMathOperator*{\softmax}{\text{SoftMax}}
\DeclareMathOperator*{\bssoftmax}{\textbf{SoftMax}}
\newcommand{\bspsi}{\boldsymbol \psi}
\newcommand{\bs}{\boldsymbol}
% Number of inner knots
\newcommand{\innerknots}{J}
% Oder of the B-Spline basis
\newcommand{\bsorder}{o}

% Hours
\newcommand{\D}{D}
\renewcommand{\d}{d}
% Reduced hours
\newcommand{\Dr}{\widetilde{D}} 

% Quantiles
\renewcommand{\P}{P}
\newcommand{\p}{p}
% Reduced quantiles
\renewcommand{\Pr}{\widetilde{P}} 

% Subscripts for the quantiles
\newcommand{\prob}{\text{pr}}

% Subscripts for the covariates
\newcommand{\mult}{\text{mv}}


\newcommand{\MSP}{\text{MSP}} 
\newcommand{\MVP}{\text{MVP}} 

\newcommand{\MAE}{\text{MAE}} 
\newcommand{\MMAE}{\text{MMAE}} 
\newcommand{\bsMAE}{\text{\textbf{MAE}}} 
\newcommand{\bsMMAE}{\text{\textbf{MMAE}}} 
\newcommand{\RMSE}{\text{RMSE}} 
\newcommand{\MRMSE}{\text{MRMSE}} 
\newcommand{\bsRMSE}{\text{\textbf{RMSE}}} 
\newcommand{\bsMRMSE}{\text{\textbf{MRMSE}}} 

\newcommand{\EXAA}{\text{EXAA}} 

\newcommand{\bsYY}{\boldsymbol \YY}
\newcommand{\DDelta}{\boldsymbol \varDelta}

% Typeset algorithms
% \usepackage{algorithm, algorithmicx, algpseudocode}

% Inline comments
\definecolor{darkgray}{HTML}{6e6e6e}
% \newcommand{\COMMENT}[1]{\State \textcolor{darkgray}{// #1}}

% Align comments in algorithm
% \renewcommand{\Comment}[2][.5\linewidth]{%
%   \leavevmode\hfill\makebox[#1][l]{//~#2}}
% \algnewcommand\algorithmicto{\textbf{to}}
% \algnewcommand\RETURN{\State \textbf{return} }

\definecolor{dcyan}{rgb}{0,0.5,.5}
\newcommand{\FZ}[1]{\color{dcyan} #1 \color{black}}
\definecolor{dgreen}{rgb}{0,0.35,0}
 \newcommand{\JB}[1]{\color{dgreen}{\textbf{ #1 }} \color{black}} 
 

\newcommand{\MS}{\text{MS}} 
\newcommand{\CS}{\text{CS}} 
\newcommand{\MCS}{\text{MCS}} 
\newcommand{\ES}{\text{ES}} 
\newcommand{\VS}{\text{VS}} 
\newcommand{\CES}{\text{CES}} 
\newcommand{\CVS}{\text{CVS}} 
 
\usepackage{tikz}
\usepackage{lineno}
\modulolinenumbers[0]

\begin{document}

% Comment out to disable line numbers
% \linenumbers

\begin{frontmatter}

  \journal{International Journal of Forecasting}

  \title{Multivariate Probabilistic CRPS Learning with an Application to Day-Ahead Electricity Prices}

  %% Group authors per affiliation:
  \author[1]{Jonathan Berrisch\corref{cor1}}
  \ead{jonathan.berrisch@uni-due.de}
  \cortext[cor1]{Corresponding author}

  \author[1]{Florian Ziel}
  \ead{florian.ziel@uni-due.de}

  \address[1]{Chair of Environmental Economics, esp. Economics of Renewable Energy \\ University of Duisburg-Essen \\
    Germany}

  \begin{abstract}
    This paper presents a new method for combining (or aggregating or ensembling) multivariate probabilistic forecasts, taking into account dependencies between quantiles and covariates through a smoothing procedure that allows for online learning. Two smoothing methods are discussed: dimensionality reduction using Basis matrices and penalized smoothing. The new online learning algorithm generalizes the standard CRPS learning framework into multivariate dimensions. It is based on Bernstein Online Aggregation (BOA) and yields optimal asymptotic learning properties. We provide an in-depth discussion on possible extensions of the algorithm and several nested cases related to the existing literature on online forecast combination. The methodology is applied to the forecasting of day-ahead electricity prices, which are 24-dimensional distributional forecasts, and the proposed method yields significant improvements over uniform combination in terms of continuous ranked probability score (CRPS). We discuss the temporal evolution of the weights and hyperparameters and present the results of reduced versions of the preferred model. A fast C++ implementation of all discussed methods is provided in the R-Package profoc.
  \end{abstract}
  \begin{keyword}
    Combination; Aggregation; Ensembling; Online; Multivariate; Probabilistic; Forecasting; Quantile; Time Series; Distribution; Density; Prediction; Splines
    \JEL C15; C18; C21; C22;  C53; C58; G17; Q47
  \end{keyword}
\end{frontmatter}

\newpage
\section{Introduction}~\label{Introduction}

Forecast combination (sometimes referred to as expert aggregation or ensembling) has gained a lot of traction in recent times. We know from theory that combination methods work well to combine different but well performing model classes~\cite{cesa2006prediction}. As ~\cite{gaillard2016additive} pointed out, it is always recommended to use different classes of models, e.g., regression and time series type models, neural network models, decision tree learning models, and other machine learning and artificial intelligence methods.

This paper proposes a novel online updating scheme for combining multivariate probabilistic forecasts, taking into account multivariate dependencies between quantiles and covariates through a simple but flexible smoothing procedure. Therefore, we assume a simple metric or spatial structure on the multivariate dimension, which we have e.g. when forecasting a univariate time series several steps ahead or predicting one-dimensional spatial data.

Online learning algorithms are particularly attractive for forecasting where frequent short-term forecasts are essential for the application domain (e.g. energy, weather, finance, retail). The proposed algorithm generalizes the probabilistic CRPS learning framework presented in \cite{berrisch2021crps}. It is based on exponential weighted averaging (EWA) and yields optimal asymptotic convergence rates with respect to the best individual forecast and the best convex combination of all forecasts \citep{wintenberger2017optimal}.

In forecasting applications, there is already considerable research into combination methods. \citet{bordignon2013combining, nowotarski2014empirical, avci2018managing} combine point-forecasts using various batch methods.~\cite{marcjasz2020probabilistic, Serafin2019averaging} apply batch methods to probabilistic forecast combination. Some authors also applied online learning algorithms for point forecasting \citep{nowotarski2016improving} and probabilistic forecasting \citep{gaillard2016additive, gonzalez2021new}. The work above focuses on developing distinct forecasting models and on combination methods. \citet{gaillard2015forecasting} discusses how model development can be optimized in the framework of aggregation of experts.

In electricity price forecasting, dynamic aggregation techniques, where the combination weights are adjusted based on past performance, tend to perform better than simple constant weight techniques \citep{gaillard2015forecasting, marcjasz2018selection, maciejowska2020pca}. However, they consider multivariate updating schemes that use the same weight for all time series. Most other work in energy forecasting considers all time series to be independent and therefore combines forecasts separately \citep{bordignon2013combining, nowotarski2016improving}.
Both approaches do not take into account possible dependencies between the multivariate space. Consequently, we can expect potential improvements by exploiting this metric structure of electricity prices by considering updating schemes that assign different weights to all neighbouring price forecasts of the day, while also considering possible dependencies between time series. Of course, the same logic applies to other areas of application.

The contributions of this manuscript are manifold:
\begin{itemize}
  \item [i)] We generalize batch and online CRPS learning to multivariate settings.
  \item[ii)] We show how the metric or spatial structure of multivariate data can be considered using two smoothing methods.
  \item[iii)] We discuss three possible strategies for optimizing hyperparameters in online learning settings.
  \item[iv)] We provide a fast open-source implementation of the proposed combination procedure.
  \item[v)] We empirically apply the proposed methods to multivariate probabilistic day-ahead electricity price forecasts.
\end{itemize}

The remainder of this paper is structured as follows. Section~\ref{mv_crps_learn} discusses the general multivariate probabilistic combination setting and discusses CRPS learning using quantile regression. Section~\ref{theor} presents the proposed multivariate generalization of online CRPS learning and summarizes its asymptotic properties. Additionally, we discuss possible extensions of the proposed method. Those extensions to the core algorithm add hyperparameters that have to be specified. Therefore, we elaborate on two possible strategies for hyperparameter tuning in Section~\ref{sec_hyperpar}. Section~\ref{application} continues with an empirical application of the proposed algorithm. We apply the methodology to multivariate probabilistic forecasts of Day-Ahead power prices. We discuss the data, elaborate on the specific algorithms we consider, and present a detailed analysis of the obtained results. Section~\ref{conclusion} discusses the limitations of the discussed approach, presents potential enhancements, and concludes.

\section{Multivariate CRPS Learning}\label{mv_crps_learn}

\subsection{The combination setting}\label{setting}

In this paper, we consider the combination of multivariate probabilistic forecasts. In particular, we consider a setting where the forecasts are given as quantiles of a multivariate distribution. \citet{berrisch2021crps} show that pointwise forecast combinations potentially outperform standard methods where weights are constant over all quantiles of the distribution. We apply this idea to a multivariate setting by computing weights not only depending on the quantile but also on the covariates. First, we discuss batch learning methods and propose a dimension reduction technique that bridges the gap between flexible pointwise and robust constant procedures. Afterward, we show how the proposed online learning algorithm of \citet{berrisch2021crps} can be extended for combining multivariate probabilistic forecasts.

Let $\what{\bsF}_{t,k} = (\what{F}_{t,1},\ldots, \what{F}_{t,K})$ be a set of $K$ multivariate distributions resp. the set of experts that we want to combine. We consider the combination across quantiles (also known as horizontal aggregation):
\begin{equation}
  \wtilde{F}_{t}^{-1} = \sum_{k=1}^K w_{t,k} \what{F}^{-1}_{t,k}
  \label{eq_comb_crps_cw_quant}
\end{equation}
We evaluate the performance using the cumulative CRPS over all covariates. Therefore, the weights shall be chosen to minimize the cumulative CRPS of all covariates. We  can approximate the CRPS by the sum over Quantile Losses ($\QL$)
\begin{align}
  \CRPS(F, y) = \int_{{\R}} {(F(x) - \mathbb{1}\{ x > y \})}^2 dx \approx \frac{2}{P} \sum_{p \in \bsPP}  {\QL}_{p}(F^{-1}(p), y)
  \label{eq_crps_approx}
\end{align}
for an equidistant dense grid $\bsPP = ( p_1,\ldots, p_P )$ with $p_i<p_{i+1}$ and $p_{i+1}-p_i = h$ for all $p$. Clearly, $P\to \infty$ induces $h \to0$, $p_1\to0$, $p_P\to1$ and the approximation converges to the CRPS~\citep{gneiting2011making, gneiting2011quantiles}. This relationship enables us to compute pointwise weights based on pinball scores. We can extend this idea by optimizing weights not only depending on the quantile $\p$ but also on the covariate $\d$:
\begin{equation}
  \wtilde{F}_{t, \d}^{-1}(p) = \sum_{k=1}^K w_{t,k}(\d,p) \what{F}^{-1}_{t,k, \d}(p)
  \label{eq_forecast_F_def_d}
\end{equation}
We are interested in setting $w_{t,k}$ such that the CRPS of $\wtilde{F}_{t,d}$ is minimized.


\subsection{CRPS learning using quantile regression}\label{cprs_learn_using_quant_reg}

Pointwise CRPS learning has the potential to outperform standard CRPS learning methods. However, the best pointwise weights in~\eqref{eq_forecast_F_def_d} have to be estimated. Theoretically, a pointwise approach has to be applied to all probabilities $\p\in(0,1)$ and all marginals $\bsDD = (1, 2, \ldots, \D)$ such that the bivariate weight function $\bsw_{t,k}$ can be specified.
However, we can never evaluate infinitely many values for $\p$. On the same page, the computation may be infeasible if $\D$ is very large. Therefore, we must consider some finite-dimensional representation for the weight functions $\bsw_{t,k}$. A suitable option is representing the weight functions $\bsw_{t,k}$ using a finite-dimensional representation using splines. Bivariate splines are a suitable option in this scenario. We can express them as follows:
\begin{equation}
  f(X_{t,j_1}, X_{t,j_2})=\sum_{l=1}^L \beta_l \bs \varphi_l(X_{t,j_1}, X_{t,j_2}).
  \label{bivariate_basis_functions}
\end{equation}
This is essentially the same as univariate splines with $L$-dimensional parameter vector $(\beta_1,\ldots,\beta_L)'$. However, the support of $f$ is 2-dimensional. Thus, we need much more basis functions $L$ to have a suitable description of $f$. A popular way to describe the bivariate basis function $\bs \varphi_l$ in~\eqref{bivariate_basis_functions} is to assume a tensor structure~\citep{mclean2014functional, wood2017gen}. In the bivariate case, the spline function is a product of two univariate ones. In addition, $\varphi_{1,l}$ and $\varphi_{2,l}$ are usually chosen such that $\varphi_{1,l_1}$ interacts with each of the considered basis functions $\varphi_{2,l_2}$. This, allows to renumerate the problem such that $l=(l_1,l_2)$, and yields
\begin{equation}
  \bs \varphi_{l_1,l_2}(x_1,x_2) = \varphi_{1,l_1}(x_1)\varphi_{2,l_2}(x_2).
  \label{eq_gam_bivariate_basis_decompositon2}
\end{equation}

This can be used to express the bivariate weight function as a product of the $\Pr \times \Dr$ parameter matrix $\bsbeta_{t,k}$ and the bivariate basis represented by $\boldsymbol{\varphi}^{\mult}$ and $\boldsymbol{\varphi}^{\prob}$:
\begin{equation}
  \bs w_{t,k} = \sum_{j=1}^{\Dr} \sum_{l=1}^{\Pr} \beta_{t,j,l,k} \varphi^{\mult}_{j} \varphi^{\prob}_{l} = \bs \varphi^{\mult} \bs \beta_{t,k} {\bs\varphi^{\prob}}'.
\end{equation}
Given $T$ historic forecasts $\what{F}^{-1}_{t,\d,k}(\p)$, the cooresponding realizations $Y_{t,d}$, and the index of covariates $\bsDD = (1,2, \ldots, D)$ we can estimate the $\Dr \times \Pr \times K$-dimensional parameter tensor $\bsbeta_{t}$ by minimizing the corresponding CRPS using~\eqref{eq_crps_approx}:
\begin{align}
  \bsbeta_{t}^{\bsvarphi\text{-CRPS}}
   & = \argmin_{ \bsbeta \in {\R}^{K\times L}} \sum_{i=t-T+1}^t \sum_{d\in\bsDD}
  \int_0^{1}  {\rho}_p\left( Y_{t,d} - \sum_{k=1}^K \sum_{j=1}^{\Dr} \sum_{l=1}^{\Pr} \beta_{t,j,l,k} \varphi^{\mult}_{d, j} \varphi^{\prob}_{l, \p} \what{F}^{-1}_{t,d,k}(\p) \right) \, d\p .
  \label{eq_qr_basis}
\end{align}
The second line uses the shift-invariance of the quantile loss and quantile regression notation $\rho_p(z) = \QL_p(0,z)  = z(p-\mathbb{1}\{z< 0\})$ \citep{koenker2017handbook}.

Still, computing~\eqref{eq_qr_basis} requires the evaluation of all distribution forecasts. As discussed, this is often not possible in practice. If we restrict the evaluation to a grid of probabilities $\bsPP$ problem~\eqref{eq_qr_basis} simplifies with~\eqref{eq_crps_approx} to
\begin{align}
  \bsbeta_{t}^{\bsvarphi\text{-QR}}
  = \argmin_{ \bsbeta \in {\R}^{K\times L}} \sum_{i=t-T+1}^t \sum_{d \in \bsDD} \sum_{p\in\bsPP} \rho_p \left( Y_{t,d} -  \sum_{k=1}^K \sum_{j=1}^{\Dr} \sum_{l=1}^{\Pr} \beta_{t,j,l,k} \varphi^{\mult}_{d, j} \varphi^{\prob}_{l, \p} \what{F}^{-1}_{t,d,k}(\p) \right).
  \label{eq_qr_basis_p}
\end{align}
In general, quantile regression problems can be solved efficiently using linear programming solvers \citep{koenker2017handbook}. However,~\eqref{eq_qr_basis_p} is not a simple quantile regression problem, but a joint quantile regression~\citep{sangnier2016joint, chun2016graphical}. The parameters $\beta_{t,j,l,k}$ are active for multiple quantiles. Thus, adequate estimation requires solving the optimization problem for $\Dr \times \Pr \times K$ parameters, which can be computationally costly if $\Dr$, $\Pr$, and $K$ are large.

However, if we choose both basis $\bs \varphi^\prob$ and $\bs \varphi^\mult$ so that $\bs \varphi_i^\mult=\mathbb{1}{\{d_i\}}$ on $\bsDD$ for $d_i\in \bsDD=(d_1,\ldots, d_D)$ and $\bs \varphi_i^\prob=\mathbb{1}{\{p_i\}}$ on $\bsPP$ for $p_i\in \bsPP=(p_1,\ldots, p_P)$ then~\eqref{eq_qr_basis_p} can be disentangled into $\Dr \times \Pr$ separate quantile regression problems.
This is
\begin{align}
  \bsw^{\text{QR}}_{t,h}(p)
  = \argmin_{ \bsw \in {\R}^K} \sum_{i=t-T+1}^t \rho_p \left( Y_{i,d} -  \sum_{k=1}^K w_{i, d, k} \what{F}^{-1}_{i,d,k}(p) \right)
  \label{eq_qr}
\end{align}
for $p\in \bsPP$ and $\d \in \bsDD$ where $\what{F}^{-1}_{t,h,k}(p)$ are the experts for the $p$-quantile and the $d$-covariate.

Quantile regression~\eqref{eq_qr} will lead to linear optimality on $\bsDD$ and $\bsPP$, as long as standard regularity conditions required for the quantile regression are satisfied \citep{koenker2001quantile}. However, we might assume further restrictions to reduce the estimation risk, e.g., the solution is a convex combination. \citet{taylor1998combining} discussed many related plausible restrictions for quantile combination concerning bias correction, positivity, and affinity, among others.

A potential issue of pointwise algorithms is \textit{quantile crossing}. This problem occurs if we have $\wtilde{F}_{t,d}^{-1}(p_i) > \wtilde{F}_{t,h}^{-1}(p_j)$ for some $p_i,p_j\in(0,1)$ with $p_i<p_j$. In this case, we recommend rearranging the predictions. It will never reduce the forecasting performance regarding the quantile loss~\citep{chernozhukov2010quantile}.

\section{Multivariate Online CRPS Learning}\label{theor}

Batch-learning approaches, like quantile regression, evaluate the entire history for estimating new combination weights, which is computationally costly.
Therefore, we suggest to use online learning methods instead.

Online learning is often called \textit{prediction under expert advice}. In this context, \textit{experts} refer to the models producing the predictions (or predictive distributions) and the person or model that combines the experts' predictions is called \textit{forecaster}. A key element of online learning methods is (cumulative) regret. It is defined as:
\begin{equation}
  R_{t,k} = \sum_{i = 1}^t r_{t,k} =
  \sum_{i = 1}^t \ell(\wtilde{X}_{i},Y_i) - \ell(\what{X}_{i,k},Y_i)
  \label{eq_regret}
\end{equation}
i.e., the cumulative difference between the loss of the expert's predictions $\what{X}_{t,k}$ and the prediction of the forecaster $\wtilde{X}_{t}$ for a loss function $\ell$. $\wtilde{X}_{t,k}$ might be a predicted quantile $\what{F}^{-1}_{t,k}(p)$ of expert $k$ as discussed in the previous section.
$R_{t,k}$ is called regret because it indicates how much the forecaster regrets not following the experts' advice~\citep{cesa2006prediction}.
With \eqref{eq_regret}, we can formulate %one of the most common weighting schemes in online learning, 
the EWA:
\begin{align}
  w_{t,k}^{\text{EWA}} & = Kw_{0,k} \frac{e^{\eta R_{t,k}} }{\sum_{j = 1}^K e^{\eta R_{t,j}}}
  =
  \frac{e^{-\eta \ell(\what{X}_{t,k},Y_t)} w^{\text{EWA}}_{t-1,k} }{\sum_{j = 1}^K e^{-\eta \ell(\what{X}_{t,j},Y_t)} w^{\text{EWA}}_{t-1,j} }
  \label{eq_ewa_general}
\end{align}
where $K$ refers to the number of experts, $w_{0,k}$ to the initial weights of an expert $k$, and $\eta$ to the learning rate, which defines how fast the weights adjust to changes in the regret~\cite{cesa2006prediction}. We can express this aggregation rule in terms of %cumulative regret (first expression of~\ref{eq_ewa_general}) as well as in terms of 
past weights and the loss suffered by the experts (right-hand side of~\ref{eq_ewa_general}). This highlights that there is no need for evaluating the entire history %(in contrast to batch-learning methods) 
when adjusting weights.

EWA yields optimal convergence rates of $\OO(T)$  towards the best expert for exp-concave loss functions~\citet{cesa2006prediction}. It means that the algorithm's performance (in terms of risk) is asymptotically not worse than the performance of the best expert. A more ambitious property that can also be satisfied is the \textit{convex aggregation property} which ensures that the risk of the algorithm is not worse than the risk of the best convex combination of the experts. To satisfy this property, the \textit{gradient trick} is needed ~\citep{devaine2013forecasting}. % It means replacing the loss by a linearized version of the loss $\ell^{\nabla}(x,y) = \ell'(\wtilde{X},y) x$ where $\ell'$ is the subgradient of $\ell$ in its first coordinate evaluated at forecast combination $\wtilde{X}$\footnote{This linearized version is sometimes also called pseudo-loss function~\citep{devaine2013forecasting}.}. 
For exp-concave losses, this gives optimal convergence rate $\OO(\sqrt{T})$ with respect to the best convex combination of the experts \citep{cesa2006prediction}. This property also holds for losses that satisfy some Bernstein condition, such as the MAE, when algorithms like Bernstein Online Aggregation (BOA) are used. These algorithms use regularized updating techniques to improve convergence and stability properties \citep{wintenberger2017optimal}. % and lets us weaken the exp-concavity condition while preserving fast convergence rates. BOA features multiple time-adaptive learning rates, so the speed of weight adjustment can vary over time and across experts~\citep{cesa2006prediction}.

\citet{berrisch2021crps} adapted BOA to probabilistic problems. The new algorithm is called CRPS learning because it optimizes the CRPS of the target distribution using pointwise optimization on a grid of quantiles. That is, the weights are allowed to vary over time % as usual in online learning, but
and over parts of the distribution. CRPS learning still maintains the fast convergence of BOA. This algorithm for combining $\what{\bsX}_{t}=(\what{X}_{t,1},\ldots, \what{X}_{t,K})$ to $\wtilde{X}_{t}=\bsw_{t-1}'\what{\bsX}_{t}$ can be summarized as follows:
\begin{subequations}
  \begin{align}
    \bsr_{t}   & = {\QL}_{\bsPP}^{\nabla}(\wtilde{X}_{t},Y_t)- {\QL}_{\bsPP}^{\nabla}(\what{\bsX}_{t},Y_t)                                                            \label{algo:regret}                                     \\
    \bsE_{t}   & = \max(\bsE_{t-1}, \bsr_{t}^+ + \bsr_{t}^-)                                                                                                                         \label{algo:lr1}                         \\
    \bsV_{t}   & = \bsV_{t-1} + \bsr_t^{ \odot 2}                                                                                                                                    \label{algo:lr2}                         \\
    \bseta_{t} & =\min\left( \left(-\log(\bsw_0) \odot \bsV_t^{\odot -1} \right)^{\odot\frac{1}{2}} ,  \frac{1}{2}\bsE_{t}^{\odot-1}\right)                                          \label{algo:lr3}                         \\
    \bsR_{t}   & = \bsR_{t-1}+  \bsr_{t} \odot \left(  \bsone - \bseta_{t} \odot \bsr_{t} \right)/2 + \bsE_{t} \odot \mathbb{1}\{-2\bseta_{t}\odot \bsr_{t} > 1\}                                     \label{algo:cum_regret} \\
    \bsw_{t}   & = K \bsw_{0} \odot \softmax\left( -  \bseta_{t} \odot \bsR_{t} + \log( \bseta_{t}) \right) \label{algo:weights}
  \end{align}
  \label{algo:boa_general_step}
\end{subequations}
where $\bsx^+$ and $\bsx^-$ denote the elementwise positive and negative parts of $\bsx$ and $\odot$ the elementwise product (Hadamard product).
The learning rate $\bseta_{t}$ determines the weight adjustment speed. It depends on the bound estimator $\bsE_{t}$ and $\bsV_t$, which is an estimator for the variance. The algorithm describes how weights are calculated on a full quantile grid $\bsPP$. First, the instantaneous regret is calculated~\eqref{algo:regret}. Then the learning rate (\ref{algo:lr1}-\ref{algo:lr3}) is adjusted. In \eqref{algo:cum_regret} the cumulative regret is calculated. Afterward, we calculate the weights~\eqref{algo:weights}. Finally, the forecaster uses $\bsw_{t}$ to calculate $\wtilde{X}_{t+1}$ and starts over with~\eqref{algo:regret}.

% Bis hier stark k端rzen

% \subsection{Extensions of Online Learning Algorithms}

Several extensions of online learning algorithms were proposed in the literature. However, they can also be applied in standard Batch-Learning settings. The benefits of these extensions have been confirmed in empirical studies. Some extensions, like shrinkage operators, are also valuable to nest specific weighting strategies into the learning algorithm.

\subsection{Smoothing}\label{subsec_smooth}

As mentioned, we apply the general CRPS learning idea to multivariate data. Thereby, we adopt the two weight-smoothing methods that were included in the original CRPS Learning algorithm. The first consists of the dimension reduction method using basis matrices. The approach is analogous to the idea discussed in Section~\ref{cprs_learn_using_quant_reg}. Using a bivariate basis, we can reduce the dimensionality of the instantaneous regret from $\D \times \P$ to $\Dr \times \Pr$:
\begin{align}
  \widetilde{\bsr}_k = \frac{\Dr\Pr}{\D\P} {\bsB^{\mult}}' \bsr_k \bsB^{\prob}
\end{align}
We can use this reduced regret to carry out the online learning algorithm as usual. After obtaining weights on this reduced version of the regret (we refer to them as $\bsbeta_{t,k}$), we can utilize the basis matrices again to obtain weights in our original dimensions of interest $\bsw_{t,k} = {\bsB^\mult} \bsbeta_{t,k} {\bsB^\prob}'$.

This relatively simple method yields a powerful property: It bridges the gap between purely pointwise weight optimization based on quantiles and the constant approach where weights are optimized concerning the CRPS. This means we can move from a setting with low flexibility and low estimation risk to a very flexible one at the price of high estimation risk.

Another option is to smooth the weights using penalized smoothing. This method can be applied after the estimation, i.e., after the updating step. Hereby we consider two sets of bounded basis functions $\bspsi^{\text{\mult}}=(\psi_1,\ldots, \psi_{\D})$ and $\bspsi^{\text{\prob}}=(\psi_1,\ldots, \psi_{\P})$ on $(0,1)$ that we will use for penalized smoothing.

Then the weights can be represented by
\begin{equation}
  w_{t,k} = \bspsi^{\mult} \bsb_{t,k} {\bspsi^{\prob}}'
\end{equation}
with parameter matix $\bsb_{t,k}$. We estimate $\bsb_{t,k}$ by penalized $L_1$- and $L_2$-smoothing which minimizes
\begin{align}
   & \| \bsbeta_{t,\d, k}' \bsvarphi^\prob  - \bsb_{t, \d, k}' \bspsi^{\prob}  \|^2_2 + \lambda^{\prob}  \| \mathcal{D}_{q}  (\bsb_{t, \d, k}' \bspsi^\prob)  \|^2_2 +                       \nonumber \\
   & \| \bsbeta_{t, \p, k}' \bsvarphi^\mult  - \bsb_{t, \p, k}' \bspsi^\mult  \|^2_2 + \lambda^\mult  \| \mathcal{D}_{q}  (\bsb_{t, \p, k}' \bspsi^\mult)  \|^2_2  \label{eq_function_smooth}
\end{align}
for each $k$ given $\bsbeta_{t,k}$ with differential operator $\mathcal{D}_q$ of order $q$. The differential order characterizes the smoothing penalty, and $\lambda\geq 0$ characterizes the roughness penalty. Typically, $q=2$ is considered along with cubic B-Splines to penalize for roughness~\citep{wang2011smoothing, wood2017generalized}. However, we prefer using $q<2$ here. As this smoothes towards constant weights over $\bsPP$ for $\lambda\to \infty$ and not towards a linear relationship between weights and probabilities as for $q=2$. As pointed out in~\cite{berrisch2021crps} there is no argument in CRPS learning that supports shrinkage towards a linear relationship. In contrast, shrinkage towards constant weights yields the non-pointwise CRPS-learning theory of constant weight functions. However, let us remark that the penalized smoothing approach with $\lambda\to \infty$ yields a different result than the simple basis smoothing approach mentioned before with $\bsvarphi = \varphi_1 \equiv 1$.

In applications, we only apply this function bases approach on finite grids of probabilities $\bsPP=(p_1, \ldots, p_\P)$ and a finite number of covariates $\bsDD=(1, \ldots, \D)$. If we consider B-Spline basis functions $\bspsi^\mult$ and $\bspsi^\prob$, then an explicit solution based on ordinary least squares exists for~\eqref{eq_function_smooth}. This explicit solution has a ridge regression representation. The smoothed weights matrix $\bsw_{t,k}$ is then given by
\begin{align}
  \bsw_{t,k}(\bsPP) = & \left(\bsB^\mult\left({\bsB^\mult}'\bsB^\mult +                                                                                                                                                                         \lambda {\bsD_q^\mult}'\bsD_q^\mult\right)^{-1} {\bsB^\mult}'\right) \nonumber           \\
                      & \bsvarphi^\mult\left( \bsDD \right) \bsbeta_{t,k} {\bsvarphi^\prob}\left( \bsPP \right)' \nonumber                                                                                                                                                                                                               \\
                      & \left(\bsB^\prob\left({\bsB^\prob}'\bsB^\prob+ \lambda {\bsD_q^\prob}'\bsD_q^\prob\right)^{-1} {\bsB^\prob}'\right)                                                                                                                                                                                    \nonumber \\
  =                   & \boldsymbol{\mathcal{H}^\mult} \bsvarphi^\mult \bsbeta_{t,k} {\bsvarphi^\prob}' \boldsymbol{\mathcal{H}^\prob}
  \label{eq_smoothing_solution_w}
\end{align}
with basis matrices $\bsB^\mult = \bspsi^\mult\left( \bsDD \right)$ and $\bsB^\prob = \bspsi^\prob\left( \bsPP \right)$, penalty matrices $\bsD^\mult_q$ and $\bsD^\prob_q$. The penalty matrix can be easily computed if equidistant knots are used to create the b-spline basis. Hereinafter, we distinguish $\bsD^S_q$ and $\bsD^G_q$, which refer to the standard equidistant case and the general case where knot placement does not have to be equidistant, respectively. Let $\Delta$ denote the matrix difference operator % (its exact dimensions depend on the context)
\begin{equation}
  \bm{\Delta} =
  \begin{bmatrix}
    -1 & 1                        \\
       & -1 & 1                   \\
       &    & \ddots & \ddots     \\
       &    &        & -1     & 1
  \end{bmatrix}.
\end{equation}
Now, $\bsD^{S}_q$ can be easily computed as $\bsD^{S}_q= \Delta^q \bsI$. The computation of $\bsD^{G}_q$ is more intricate since non-equidistant knots are permitted. The calculation involves an additional weighting step with respect to the non-equidistant distribution of the knots. We elaborate on this topic briefly since the literature is surprisingly scarce~\cite[][Section 2.2]{li2022general}. The required difference matrix can be computed as
\begin{align}
  % \bm{D}_1 & = \bm{W}_1^{-1}\bm{\Delta}                                                             \\
  % \bm{D}_2 & = \bm{W}_2^{-1}\bm{\Delta}\bm{W}_1^{-1}\bm{\Delta}                                     \\
  \bm{D}^{G}_q & = \bm{W}_q^{-1}\bm{\Delta}\bm{W}_{q - 1}^{-1}\bm{\Delta}\cdots\bm{W}_1^{-1}\bm{\Delta} \label{diffmat}
\end{align}
where $W_q$ are weighting matrices that depend on the order of the B-Spline basis, denoted as $\bsorder$, and the knots. Let $\innerknots$ denote the number of inner knots. The dimension of the difference matrices $\Delta$ in~\eqref{diffmat} depend on $W_q$ are $(\innerknots-\bsorder-q)\times(\innerknots-\bsorder)$. The total number of knots will be $\innerknots + 2\bsorder$. We can specify the weighting matrices as:
\begin{align}
  \bm{W}_q = \frac{1}{\bsorder - q}\begin{bmatrix}
                                     t_{\bsorder + 1} - t_{1 + q} \\ & t_{\bsorder + 2} - t_{2 + q} \\ & & \ddots \\ & & & t_{\innerknots+2\bsorder-q} - t_{\innerknots + \bsorder}
                                   \end{bmatrix},
\end{align}
The quantity $\bsorder-q$ represents the lag used to differentiate the knots. If the knots are equidistant, then $\bm{W}_q$ will be proportional to the identity matrix $\bsI$. Therefore, it nets the standard P-Spline, which uses $\bsD^{S}_q= \Delta^q \bsI$. This gives rise to the general P-Spline estimator. However, $\bm{W}_q$ is only proportional to $\bsI$ rather than equal to it. Therefore, scaling needs to be applied for the results of both estimators to coincide. The scaling can be applied to lambda, the penalty matrix, or the difference matrix. To state this formally, let $\bm{P}_q^S = {\bm{D}_q^S}'\bm{D}_q^S$ and $\bm{P}_q^G = {\bm{D}_q^G}'\bm{D}_q^G$ denote the penalty terms of the standard and general P-Spline estimators. The scaling factor with respect to the penalty $\bm{P}_q^G$ is $\left(\Tr\left(\bm{W}_q\right)/(\innerknots+\bsorder-q)\right)^{2q}$ so the following relation holds:
\begin{align}
  \bm{P}_q^S & = \left(\Tr\left(\bm{W}_q\right)/(\innerknots+\bsorder-q)\right)^{2q} \bm{P}_q^G. \label{equi_non_equi_rel}
\end{align}
This is only valid for equidistant B-Splines. For non-equidistant B-Splines, the generalized P-Spline is the only appropriate estimator. We suggest always applying this scaling to ensure the comparability between lambda values in equidistant situations.

For notational brevity, we denote the first and last part of~\eqref{eq_smoothing_solution_w} as $\boldsymbol{\mathcal{H}}^\mult$ and $\boldsymbol{\mathcal{H}}^\prob$, respectively, the so-called hat matrices. Fortunately, they do not depend on time-varying components; therefore, we can compute them prior to the main online learning task, which yields a great reduction in the algorithm's computational complexity.

\subsection{Knot placement for Smoothing Splines}

For both smoothing approaches discussed above, the knots of the B-Spline basis must be placed. A well-established approach is placing plenty of equidistant knots. However, as discussed above, non-equidistant knot placement is valid if the penalty is defined accordingly. We consider equidistant and non-equidistant knots. Thereby, the non-central beta distribution with the following parameterization is used for distributing the knots:
\begin{align}
  \mathcal{B}(x, a, b, c) = \sum_{j=0}^{\infty} e^{-c/2} \frac{\left( \frac{c}{2} \right)^j}{j!} I_x \left( a + j , b \right)
\end{align}
Where $I_x$ is the incomplete beta function, $a$ and $b$ are shape parameters, and $c$ is the non-centrality parameter~\cite{johnson1995continuous}. Algorithm~\ref{algo:knots} describes the knot placement in detail. It returns equidistant knots if $\mu = 0.5$, $\sigma = 1$, $c = 0$ and  the tailweight parameter $\tau = 1$.
\begin{algorithm}[!h]
  \DontPrintSemicolon
  \KwData{Let $\mathcal{B}$ denote the CDF of the beta distribution and $\mu, \sigma, c, \tau, \text{deg}$ be parameters for adjusting the knot placement.}
  \KwResult{Sequence of knots with length $\innerknots + 2\left( \text{deg}+1 \right) = \innerknots + 2\bsorder$}
  \SetAlgoLined
  % \ali{4em}{seq\_i} = sequence(from = 0, to = 1, length = \innerknots+2)\;
  \ali{3.5em}{x} $= (0, 1, \ldots, \innerknots+2)/(\innerknots+2) $\;
  \ali{3.5em}{a} $= 2 \sigma \left(1-\mu \right)$\;
  \ali{3.5em}{b} $= 2 \sigma \mu $\;
  \ali{3.5em}{knots\_c} $= \mathcal{B}\left(\text{x}, \text{a}, \text{b}, \lvert c \rvert \right)$\;
  \If{$c < 0$}{
    knots\_c  $= \text{reverse}\left( 1 - \text{knots\_c} \right)$\;
  }
  \ali{3.5em}{knots\_l} $= |\tau| \left( \text{knots\_c}[2] -\text{knots\_c}[1] \right) \left( -\text{deg}, \ldots, -1 \right)$\;
  \ali{3.5em}{knots\_r} $= |\tau| \left( \text{knots\_c}[\innerknots + 2 ] - \text{knots\_c}[\innerknots + 1 ]\right) \left( 1, \ldots, \text{deg} \right) + 1$\;
  \ali{3.5em}{knots} $= \text{combine}\left( \text{knots\_l, knots\_c, knots\_r} \right)$\;
  % return(knots)\;
  \caption{\label{algo:knots} Knot placement for B-Splines}
\end{algorithm}
Figure~\ref{fig:knots} shows B-Spline Basis' for different knot placements for the inputs of Algorithm~\ref{algo:knots}.
\begin{figure}[!h]
  \centering{
    \begin{subfigure}[a]{\textwidth}
      \centering
      \resizebox{\textwidth}{!}{
        \input{anc/plots/knots.tex}
      }
      \caption{Basis functions for different location and scale values $\mu$ and $\sigma$ (using $\tau=1$ and $c = 0$)}\label{knots_mu_sigma}

    \end{subfigure}

    \begin{subfigure}[b]{\textwidth}
      \centering
      \resizebox{\textwidth}{!}{
        {\input{anc/plots/knots2.tex}}
      }
      \caption[]{Basis functions for different noncentrality and tailweight values $c$ and $\tau$ (using $\mu = 0.5$ and $\sigma = 1$)}\label{knots_c_tau}
    \end{subfigure}
  }
  \caption{B-Spline functions for selected placements of the knots concerning the inputs of Algorithm~\ref{algo:knots}. The center of both figures shows the default case of equidistant knots.}\label{fig:knots}
\end{figure}

\subsection{Shrinkage operators and Forgetting}\label{subsec_shrink}

Shrinkage operators are well-known in statistical learning theory. They help to reduce the overfitting problem by shrinking a solution. The P-Spline smoothing we discussed above can also be interpreted as a shrinkage operator. However, simple shrinkage operators can also be applied to $\bsbeta_{t}$. We consider three additional shrinkage operators: the fixed share operator $\mathcal{F}$, the soft-thresholding operator $\mathcal{S}$, and the hard-thresholding operator $\mathcal{H}$. They are defined as
\begin{align}
  \mathcal{F}(x;\phi)   & = \phi/K  + (1-\phi) x ,       \\
  \mathcal{S}(x;\nu)    & = \sign(x)||x|-\nu| ,          \\
  \mathcal{H}(x;\kappa) & = x  \mathbb{1}\{|x|>\kappa \}
\end{align}
for some $\phi\in[0,1]$, $\nu\geq0$ and $\kappa\geq0$. The fixed share operator shrinks towards the naive combination. This is preferable if no prior information on the experts' performance is available. For some shrinkage problems, there are theoretical guarantees for improvements~\cite {tu2011markowitz, cesa2012mirror}. Applications in the context of online learning include, e.g., \citet{cesa2012mirror, gonzales2021new}. The thresholding operators $\mathcal{S}$ and $\mathcal{H}$ were also considered in online learning contexts previously~\citep{dalalyan2012sharp, gaillard2017sparse}. Applying thresholds leads to sparse solutions. Both appear in several situations for specific linear model estimators. Most notably, soft-thresholding is the key operator in the coordinate descent algorithm for estimating the lasso~\citep{friedman2007pathwise}. Applying any threshold operator potentially violates affinity constraints (incl. the convexity constraint). Therefore, projections to the desired solution space should be applied.

As mentioned, cumulative regret is a key element in online learning. However, in settings with a long history, there might be structural breaks in the data. These breaks motivate the introduction of the forgetting factor. It means that only a limited amount of the old cumulative regret is considered for adjusting the weights. In other words, the algorithm \textit{forgets} about some part of the past performance. In online learning, usually exponential forgetting is chosen~\cite{guo2018online, messner2019online,ziel2021smoothed}. The Regret with a forgetting factor $\theta\in[0,1]$ is formally defined as
\begin{align}
  R_{t,k}(\theta) & =  (1-\theta) R_{t-1,k} + \ell(\wtilde{F}_{t},Y_t) - \ell(\what{F}_{t,k},Y_t)\label{eq_regret_forget}
\end{align}
where $\theta = 0$ correspons to no forgetting. Optimal values for the forgetting factor $\theta$ are usually close to $0$. The forget should be applied to all hidden state variables in sophisticated online learning procedures like BOA. % In the case of the BOA these regret $\bsR_t$, the range estimate $\bsE_t$, and the variance estimate $\bsV_t$.

\section{Full Model and Hyperparameter Optimization}\label{sec_hyperpar}

Algorithm~\ref{algo:boag_smooth} shows the multivariate online CRPS-Learning algorithm. This includes all extensions discussed in Subsections~\ref{subsec_smooth} and~\ref{subsec_shrink}. Considering all extensions, this algorithm contains five general hyperparameters (the forget rate $\phi$, the parameters of the shrinkage operators $\theta$, $\kappa$, $\nu$) as well as 30 hyperparameters concerning the design of basis and hat matrices.

\begin{algorithm}[!h]
  \DontPrintSemicolon
  Initialization see~\ref{append_init} \;
  \SetAlgoLined
  \For{$t$ in $1,\ldots, T$}{
  \lFor*{$d$ in $1,\ldots, D$}{
  \For{$p$ in $1,\ldots, \P$}{
  $\wtilde{X}_{t,d,p} = \bsw_{t-1,d,p}' \what{\bsX}_{t,d,p}$ \;
  \lFor{$k$ in $1,\ldots, K$}{
  $\bsr^\text{full}_{d,p,k} = QL_p^{\nabla}(\wtilde{X}_{t,d,p},Y_t) - QL_p^{\nabla}(\what{X}_{t,d,p,k},Y_t)$
  }}}
  \For{$k$ in $1,\ldots, K$}{
    $\bsr^\text{red}_k = \frac{\Dr}{\D} \frac{\Pr}{\P} {\bsB^\mult}' \bsr^\text{full}_k \bsB^\prob$ \tcp*{now $\bsr^\text{red}_k$ is $ \Dr \times \Pr$}
  }
  \For{$d$ in $1,\ldots, \Dr$}{
  \For{$p$ in $1,\ldots, \Pr$}{
  \ali{2.5em}{$\bs V_{t,d,p}$}              $= (1-\theta) \bs V_{t-1,d,p} + \left({\bs r^\text{red}_{d,p}}\right)^{ \odot 2}$\;
  \ali{2.5em}{$\bs E_{t,d,p}$}              $= \max\left( (1-\theta) \bs E_{t-1,d,p}, \left|{\bs r^\text{red}_{d,p}} \right| \right) $\;
  \ali{2.5em}{$\bs \eta_{t,d,p}$}  $= \gamma \min\left( \left(-\log(\bs \beta_{0,d,p}) \odot \bs V_{t,d,p}^{\odot -1} \right)^{\odot\frac{1}{2}} , \frac{1}{2} \bs E_{t,d,p}^{\odot-1}\right)$\;
  \ali{2.5em}{$\bs R_{t,d,p}$} $= (1-\theta) \bs R_{t-1,d,p} +  {\bs r^\text{red}_{d,p}} \odot \left( 1 - \bs\eta_{t,d,p} \odot {\bs r^\text{red}_{d,p}} \right)/2 + \phantom{{}===1} \bs E_{t,d,p} \odot  \mathbb{1}\{-2 \bs \eta_{t,d,p} \odot {\bs r^\text{red}_{d,p}} > 1\}  $\;
  \ali{2.5em}{$\bs \beta_{t,d,p}$} $= K \bsbeta_{0,d,p} \odot \softmax\left( -  \bs \eta_{t,d,p} \odot \bs R_{t,d,p} + \log( \bs \eta_{t,d,p}) \right)$\;
  \ali{2.5em}{$\bs \beta_{t,d,p}$} $= \left( \mathcal{F}_\phi \circ \mathcal{H}_\kappa \circ \mathcal{S}_\nu \right) \left(\bs \beta_{t,d,p}\right) $ \;%\tcp*{apply thresholds}
  }
  $\wtilde{\bs X}_{t,d} = \text{Sort} ( \wtilde{\bs X}_{t,d} )$\
  }
  \For{$k$ in $1,\ldots, K$}{
    $\bsw_{t,k}(\bsPP) = \boldsymbol{\mathcal{H}^\mult} \bsB^\mult \bsbeta_{t,k} {\bsB^\prob}' \boldsymbol{\mathcal{H}^\prob}$\;
  }}
  \textbf{end}\;
  \caption{\label{algo:boag_smooth} Smoothed CRPS Bernstein Online Aggregation}
\end{algorithm}
The algorithm is versatile as it handles several special cases discussed in the literature. One such case is the uniform combination, also known as the \textbf{naive} combination. This can be calculated by using the Fixed-Share operator $\mathcal{F}_\phi$ with $\phi=1$, resulting in entirely uniform weights. There are more efficient ways of calculating uniform weights, obviously. However, adjusting the value of $\phi$ allows a smooth transition from the uniform solution to the solution calculated by BOA. Another common special case is constant weights, where each expert receives a specific weight. This can be calculated by setting both basis matrices, $B^\mult$ and $B^\prob$, to the unity Vector of length $\D$ and $\P$, respectively. This leads to weights without variation across marginals and probabilities (\textbf{Constant}). Setting only one of the basis matrices to the unity vector will result in weights that are constant over either covariates (\textbf{Constant Mv}) or probabilities (\textbf{Constant Pr}). Additionally, setting all smoothing matrices to identity produces pointwise weights, and optimizing $\lambda$ in the hat matrices concerning the predictive CRPS results in possibly smoothed weights. These cases are illustrated in Figures~\ref{fig:b.constant.mv}-\ref{fig:smooth}.
\begin{figure*}[!h]
  \centering
  \begin{subfigure}[b]{0.475\textwidth}
    \centering
    \includegraphics[trim={3.5cm 0cm 3.5cm 2cm}, clip, width=\textwidth]{anc/plots/specials/bewa.b.constant.mv_JSU1.pdf}
    \caption[Network2]%
    {{\small Constant weights w.r.t. time (hours)}}
    \label{fig:b.constant.mv}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.475\textwidth}
    \centering
    \includegraphics[trim={3.5cm 0cm 3.5cm 2cm}, clip, width=\textwidth]{anc/plots/specials/bewa.b.constant.pr_JSU1.pdf}
    \caption[]%
    {{\small Constant weights w.r.t. probabilities}}
    \label{fig:b.constant.pr}
  \end{subfigure}
  \vskip\baselineskip
  \begin{subfigure}[b]{0.475\textwidth}
    \centering
    \includegraphics[trim={3.5cm 0cm 3.5cm 2cm}, clip, width=\textwidth]{anc/plots/specials/bewa.pointwise_JSU1.pdf}
    \caption[]%
    {{\small Optimized pointwise weights}}
    \label{fig:pointwise}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.475\textwidth}
    \centering
    \includegraphics[trim={3.5cm 0cm 3.5cm 2cm}, clip, width=\textwidth]{anc/plots/best/mix.bewa.sm.fr_JSU1.pdf}
    \caption[]%
    {{\small Optimized smoothed weights}}
    \label{fig:smooth}
  \end{subfigure}
  \caption[ The average and standard deviation of critical parameters ]
  {\small Most recent weighs of JSU1 calculated using different specifications of Algorithm~\ref{algo:boag_smooth}}
  \label{fig:nested_cases}
\end{figure*}
The extensions discussed in Subsections \ref{subsec_smooth} and \ref{subsec_shrink} require the specification of various hyperparameters. There are many possible hyperparameters to choose from, and we do not have any prior information on the best values. This means that it is impossible to test all combinations of these parameters in each iteration of the forecasting task. The latter would be ideal, but it is impractical due to the large amount of computational resources required. As a result, we need to use other, less demanding methods for tuning these hyperparameters. In this paper, we will utilize three approaches for tuning.

The first approach to hyperparameter tuning is using a sophisticated search algorithm based on random forest and optimizing towards the lowest CRPS on a subset of our observations (i.e., a training set). We utilize the R-Package mlrMBO to execute this optimization \citep{mlrMBO}. This approach brings one major advantage: the search algorithm can search the considered space very efficiently by repeatedly reevaluating the objective function. However, once the final set of hyperparameters is selected, it will remain constant throughout the forecasting task. Additionally, the tuning is only executed using a small subset of the dataset. This could be a problem as the chosen set of parameters may not be optimal for the rest of the dataset, especially if there are structural breaks. Hereinafter, we will refer to this approach as \textbf{Bayesian fix} as it fixes the hyperparameters after utilizing a Bayesian search algorithm.

The second approach uses the \texttt{online} function, which is included in the \textit{profoc} R-Package. It implements the proposed algorithm along with an online tuning strategy for the hyperparameters. This strategy considers a random sample of all possible hyperparameter sets, and for each iteration, the combination with the lowest aggregate CRPS is chosen. In contrast to the \textbf{Bayesian fix} approach, we define all possible parameter sets before the learning task. However, this method dynamically selects the parameter set based on past performance, allowing for dynamic adjustments if underlying properties change. The most significant drawback of this approach is that only a random sample of the hyperparameter space is considered. However, this approach has the advantage of adjusting dynamically to changes in the data. Therefore, we will refer to this approach as \textbf{Sampling Online}.

It is also possible to combine both approaches. In this case, mlrMBO optimizes on a subset of the data. \textit{online} uses the parameter combinations that were considered in the mlrMBO optimization. This has the potential to profit from efficient exploration of the hyperparameter space and the ability to adjust to changes in the data dynamically. After this, we will refer to this approach as \textbf{Bayesian Online}.

\section{Application to Multivariate Probabilistic Day-Ahead Power Prices}\label{application}
In day-ahead electricity price forecasting, we consider the price $Y_{t,h}$ at day $t$ and product $h=1, \ldots, H$ of the day. For hourly electricity prices, we have $H=24$, and therefore $h$ is often referred to as \textit{hour}, see~\cite{ziel2018day}.
We consider the forecasts of \citet{marcjasz2022distributional}, which range from 27th Dec. 2018 to 31st Dec. 2020. These are hourly forecasts of eight different models, i.e., neural network specifications. The forecasts are given as distributional parameters for each hour (i.e., $\bsDD = (1, \ldots, 24)$) of all 736 Days. We use those distributional forecasts for calculating quantiles on the equidistant grid of percentiles $\bsPP=(0.01,\dots,0.99)$.

For our learning task, we chose to consider the penalized smoothing approach only. We consider the knot placement and the other extensions discussed in Subsections \ref{subsec_smooth} and \ref{subsec_shrink}. Table~\ref{tab:pars} summarizes the considered hyperparameters. That is, we have a total of 15 tuning parameters to optimize.

\input{anc/tab_pars.tex}

We conduct the forecasting task using the three tuning strategies \textbf{Bayesian fix}, \textbf{Sampling Online}, and  \textbf{Sampling Online} discussed in Section~\ref{sec_hyperpar}. \citet{marcjasz2022distributional} used about half a year of data, resp. the first (182) observations, as a burn-in period for hyperparameters to stabilize. With \textbf{Bayesian fix}, we use these first 182 observations. However, we do not evaluate the forecasts of the first 50 observations due to the elevated estimation uncertainty early in the learning process. We utilize the Krigin learner of MLRmbo to propose eight new points until the budget of 1000 points is exhausted. This is done in parallel and needs around 30 minutes of computation time on our Intel i5-12600K CPU. Then, the best hyperparameter set is used to conduct the whole forecast combination task with all 736 observations. For our final evaluation, we follow \citet{marcjasz2022distributional} again by excluding the first 182 observations.

For \textbf{sampling online}, we first divide the range of each hyperparameter into 16 equidistant values, apply the transformation function (see Table~\ref{tab:pars}), and then randomly sample up to 2500 points from the resulting multivariate hyperparameter space. The online optimization process is then carried out as described in Section~\ref{sec_hyperpar}. As with \textbf{Bayesian fix}, the first 182 observations are excluded from the evaluation. We chose to sample 2500 points so that the \textbf{Sampling Online} optimization process also takes around 30 minutes of computation time.

For \textbf{Bayesian Online}, we run \textbf{Bayesian fix} analogous to the above but with a reduced budget of 750 points to propose. These points are then fed into the \textbf{Sampling Online} optimization. We chose these settings to ensure the computation times remain around 30 minutes.

In addition to tuning all 15 hyperparameters (\textbf{Full}), we examine three subsets of these hyperparameters. The first subset only includes penalized smoothing and forget (\textbf{Smooth.Forget}), the second subset only includes penalized smoothing (\textbf{Smooth}), and the last subset only includes forget (\textbf{Forget}). Note that the time required for computing \textbf{Smooth} \textbf{Forget} is reduced when using \textbf{Sampling Online} as the number of possible parameter combinations does not exceed 2500. The specifications are summarized in Table~\ref{tab:pars}. We also report the performance of the \textbf{naive}, the performance of each expert, and the four special cases shown in Figure~\ref{fig:nested_cases}.

\input{anc/tab_joined.tex}

Table~\ref{tab:crps} summarizes the results. It reports the CRPS of each expert and the \textbf{naive} combination in the top row and the performance of different specifications of Algorithm~\ref{algo:boag_smooth}.
We also report the performance of \textbf{ML-Poly} and \textbf{EWA} weighting schemes as they are popular in the forecast combination literature \citep{gaillard2014second, jore2010combining, dalalyan2012sharp, opschoor2017combining}. We always apply the gradient trick (see. Section~\ref{theor}) However, due to their inferior convergence properties, we do expect them to perform worse than BOA. The table cells are colored according to the test statistic of a Diebol Mariano test, testing whether the forecasts in question significantly differ over the naive model (negative test statistic) or not \citep{diebold2002comparing}. We apply the Diebold Mariano test with the small sample adjustment of \citet{harvey1997testing}.

We see that all individual experts perform significantly worse compared to \textbf{naive}. Further, the best results were obtained with the \textbf{Bayesian Online} approach and using equidistant knots, penalized smoothing, and a forget rate (\textbf{Smooth.Forget}). This solution clearly yields a significant improvement over the naive combination. Comparing this solution with the smaller models \textbf{Smooth} and \textbf{Forget}, we conclude that forgetting contributes to the majority of the observed improvement. The importance of the forget indicates structural changes in the data. Further evidence comes from the fact that the dynamic \textbf{Bayesian Online} optimization generally outperforms parameter optimization using \textbf{Bayesian fix}.

Further, BOA performs best compared to the other considered weighting schemes ML-Poly and EWA. Overall forgetting and smoothing play a crucial role in the performance of the combination. Finally, regarding the hyperparameter tuning, we conclude that the dynamic optimization \textbf{Bayesian Online} and \textbf{Sampling Online} should be preferred to the static Bayesian optimization \textbf{Bayesian Mix}.

% See https://tex.stackexchange.com/a/130078/190318 for the following 2 lines
\let\pgfimageWithoutPath\pgfimage
\renewcommand{\pgfimage}[2][]{\pgfimageWithoutPath[#1]{anc/plots/best/#2}}
\begin{figure}[!h]
  \centering{
    \resizebox{\textwidth}{!}{%
      \fbox{\input{anc/plots/best/wplot_prob_17_mix.bewa.sm.fr.tex}}
    }}
  \caption{Temporal evolution of the weights at hour 16 across all 99 probabilities}\label{weights_temporal_vs_prob}
\end{figure}

Figures~\ref{weights_temporal_vs_prob} and~\ref{weights_temporal_vs_hour} provide a more detailed analysis of the proposed model (\textbf{Smooth.Forget}, \textbf{Bayesian Online}). They depict the temporal evolution of the weights for each expert. Thereby, Figure~\ref{weights_temporal_vs_prob} presents the temporal evolution across probabilities for hour 16 of the day. After a brief initial burn-in period, the weights of the eight experts stabilize. There is a higher degree of variability in the center of the distribution. The weights are close to the uniform solution at the tails, with only a few exceptions. JSU4 strongly influences the combined value in the center of the distribution until around April 2020. After that point, the weight of JSU4 decreases, and JSU3 becomes more prominent. Further, there seem to be noticeable changes in the weights around June 2019 and April 2020, suggesting possible structural changes. These structural changes potentially lead to the dynamic hyperparameter tuning \textbf{Sampling Online} and \textbf{Bayesian Online} performing better than \textbf{Bayesian fix} due to the ability of the hyperparameters to adapt the changing data.

Figure~\ref{weights_temporal_vs_hour} shows the temporal evolution of the weights at the median across all 24 hours. However, the high weights for JSU4 (see Figure~\ref{weights_temporal_vs_prob}) are only present in the afternoon and evening. Additionally, the plot reveals structural changes around June 2019 (regarding JSU4 and NORM4) and April 2020 (concerning JSU3, JSU4, NORM3, and NORM4).

Both graphs clearly indicate that the weights vary with time, hours, and quantiles. Thus, a flexible approach like the one proposed in this study seems appropriate. Lastly, the weights show less smoothing across hours than across quantiles.

\begin{figure}[!h]
  \centering{
    \resizebox{\textwidth}{!}{%
      \fbox{\input{anc/plots/best/wplot_mv_0.5_mix.bewa.sm.fr.tex}}
    }}
  \caption{Temporal evolution of the weights at the median across all 24 hours}\label{weights_temporal_vs_hour}
\end{figure}

Figure~\ref{fig:best_pars} presents the parameters used by the proposed \textit{online.sm.fr} specification. This approach optimizes three parameters: the forgetting rate and the two smoothing penalties. All parameters need some time to stabilize. However, the chosen burn-in period (marked in grey) seems to suffice for the most part. Further, we observe an increasing forgetting as the learning progresses and a quite consistent level of smoothing across both dimensions. Lastly, we observe that the weights are getting more smoothed across probabilities than across hours (see also Figure~\ref{fig:smooth}, which presents the most recent weights of this solution across hours and probabilities).
\begin{figure}[!h]
  \centering{
    \resizebox{\textwidth}{!}{%
      \fbox{\input{anc/plots/best/pars_mix.bewa.sm.fr.tex}}
    }}
  \caption{Hyperparameter values of the \textbf{Smooth.Forget} specification with \textbf{Bayesian Online} tuning. The grey area represents the burn-in period which is not used for evaluation.}\label{fig:best_pars}
\end{figure}

\section{Conclusion}\label{conclusion}

This paper proposes a novel method for combining multivariate probabilistic forecasts, considering dependencies between quantiles and marginals through a smoothing procedure. The first discussed smoothing method reduces the dimensionality of the regret using Basis matrices. It bridges the gap between pointwise and constant weight optimization. The second method involves smoothing the weights by penalized smoothing. The proposed method extends the (online) \textit{CRPS learning} algorithm and is based on gradient-based EWA, which yields fast convergence rates. We also discuss possible extensions to the algorithm, such as forgetting and shrinkage operators. We also discuss how non-equidistant knots can be used in penalized smoothing, i.e., how the penalty term needs to adjust.

We apply the proposed methodology to multivariate probabilistic forecasts for day-ahead electricity prices. These are 24-dimensional distributional forecasts from which we extracted an equidistant grid of 99 percentiles. For hyperparameter tuning of Algorithm~\ref{algo:boag_smooth}, we compare two strategies \textbf{Bayesian fix} and \textbf{Sampling Online}.

The best performance is obtained by optimizing \textbf{Sampling Online} with penalized smoothing, and a forget rate. This specification yields a significant improvement over the \textit{naive} combination. The forget rate contributes to the majority of the improvement, indicating structural changes in the data. The second considered tuning strategy using \textbf{Bayesian fix} produced subpar results compared to the \textbf{Sampling Online} strategy. This is likely due to the mentioned structural changes to which the hyperparameters can adjust dynamically when optimizing \textbf{Sampling Online}. The BOA weighting scheme obtained the best results compared to two other popular schemes, ML-Poly and EWA. We also discuss the temporal evolution of the weights, which stabilize quickly after a short burn-in period. However, we observed some structural change in the weights around November 2019 which remains puzzling.

The smoothing methods used in this paper assume a relatively simple metric or spatial structure where we only consider the dependence between adjacent time series. This assumption is reasonable for electricity prices and all time series that we combine over the forecast horizon, as the order is naturally determined by time. In other cases, the adjacency structure may be more complex. For example, in spatial data, the first and last coordinates are often adjacent (e.g. forecasting a meteorological feature along the equator). Other spatial structures (e.g. across the globe) may be even more complex. We can account for these structures by deriving the penalty terms from the respective adjacency matrix, which describes the metric structure of the data. The Laplacian matrix (graph Laplacian, admittance matrix or Kirchhoff matrix) can be calculated from this matrix. It represents the dependencies of a graph. The penalty matrix is the negative of the Laplacian. Therefore, instead of using the identity matrix for the penalty term, we can use the Laplacian matrix. Both approaches will be consistent with the spatial structure considered in this paper. This is a promising topic for future research.

As outlined, we consider potential spatial structures between quantiles and marginals. We do this for the performance of the considered experts. Hence, this approach is particularly suitable for situations where only quantiles of the marginals are available. In practice, this is often satisfied as experts regularly specialize in forecasting one specific marginal. However, ff experts provide the dependency structure between marginals, i.e., by providing joint predictive distributions, combination algorithms that take these dependencies into account should be chosen. However, this is a nontrivial task. Methods that assign uniform weights across the joint distribution can be applied easily. However, by design, these will ignore any variations in experts' performance across the joint distribution. On the other hand, combining marginals using non-uniform weighting strategies like CRPS learning considers the variations mentioned above. However, it needs to be clarified how the dependency structure can be reintroduced into the predictive marginals, i.e., which weights should be chosen for combining the copula. This remains an important topic for future investigation.

Overall, the empirical results approve the proposed algorithm, which accounts for variations across time, distribution, and marginals. The algorithm surpasses the performance of simpler weighting schemes such as the \textit{naive} and several nested cases in terms of overall CRPS. A fast C++ implementation of the proposed algorithm is available in the open-source \textit{R}-Package \textit{profoc} \citep{profoc_package}.

\clearpage

\appendix
\section{Initialization of Algorithm~\ref{algo:boag_smooth}}\label{append_init}


\begin{algorithm}[!h]
  \SetAlgoLined
  \DontPrintSemicolon
  \textbf{input:}
  4-dimensional array of expert predictions $(\what{X})_{t,d,p,k}$ and matrix of prediction targets $\bsY_{t,d}$ for $t=1,\ldots, T$, $d\in \bsDD = (d_1,\ldots,d_D)$,  $p\in \bsPP = (p_1,\ldots,p_P)$, $k=1,\ldots, K$ \;
  \textbf{initialize:} \\
  $\bsw_{0} = 1/K$\;
  $\bsE_{0} = \bsV_0 = \bsR_0 = \bsnull$ \;
  $\bsbeta_0 = \text{pinv}\left(\bsB^{\mult}\right) \bsw_0\left(\bsPP\right) \text{pinv}\left(\bsB^{\prob}\right)'$ \;
  $\boldsymbol{\mathcal{H}^\prob} = \bsB^\prob({\bsB^\prob}' \bsB^\prob + \lambda^{\P} (\alpha \boldsymbol D_1'\boldsymbol D_1 + (1-\alpha) \boldsymbol D_2'\boldsymbol D_2))^{-1} {\bsB^\prob}'$\;
  $\boldsymbol{\mathcal{H}^\mult} = \bsB^\mult({\bsB^\mult}' \bsB^\mult + \lambda^{\D} (\alpha \boldsymbol D_1'\boldsymbol D_1 + (1-\alpha) \boldsymbol D_2'\boldsymbol D_2))^{-1} {\bsB^\mult}'$\;
  \caption{\label{algo:init} Initialization of Algorithm \ref{algo:boag_smooth}}
\end{algorithm}

%  \clearpage
\bibliographystyle{anc/model5-names}

\bibliography{bib}



\end{document}
