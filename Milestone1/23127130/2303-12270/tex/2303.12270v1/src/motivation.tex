\section{Motivation}
\label{sec:motivation}

To better understand the origin of performance degradation of BNN for SR, in this section, we visualize
the activation distributions for a FP SR network. We select a lightweight EDSR model, which has 16 blocks and 64 channels for
the body module \cite{lim2017enhanced}. We also visualize the activation distribution of a image classification network, i.e., MobileNetV2 \cite{sandler2018mobilenetv2} for comparison. From the comparison, we observe clear differences between the two models,
which serves as the motivation for our EBSR.

% \red{To better binarize the SR network without BN layers, we need to start with the data distribution}. Thus we visualize the data distributions in each layer of the full-precision lightweight EDSR,  which has 16 blocks and 64 channels for the body module \cite{lim2017enhanced} and find that the activation distribution in SR networks e.g., EDSR is quite different from CNN-based image classification networks e.g., MobileNetV2 \cite{sandler2018mobilenetv2}. The data distributions demonstrate large pixel-to-pixel, channel-to-channel, and image-to-image variations in SR networks, which easily lead to high quantization errors and are unfriendly to quantization.
% \ml{``Inconsistent'' is not very precise. Need to define what inconsistent means.---check}


\begin{figure}[!tb]%
  \centering
  \subfloat[MobileNetV2]{
    \label{subfig:mbv2_pixel}
    \includegraphics[width=0.22\textwidth]{fig/mbv2_per_pixel_new.png}
  }
  \subfloat[EDSR]{
    \label{subfig:edsr_pixel}
    \includegraphics[width=0.22\textwidth]{fig/per_pixel_new.png}
  }
  \caption{
  %Distributions among pixels in (a) MobilenetV2 for classification and (b) EDSR for super-resolution.
  Activation distribution of EDSR exhibits much larger pixel-to-pixel variation compared to MobileNetV2.
  % For display purposes, We plot the pixel-wise distributions by randomly sampling 36 pixels in one layer. It is the same with other layers.  
  }
  \label{fig:pixel}
\end{figure}

% \ml{Before talking about the motivation, we need to first introduce how weights and activations are binarized in the E2FiF setting.}

% \ml{Is this channel or pixel? Should we call this variance?}

\textbf{Motivation 1: Pixel-to-Pixel Variation} 
We first compare the activation distribution for different pixels within the same layer.
We randomly sample 24 pixels from one layer of both MobileNetV2 and EDSR and visualize the activation distribution for these pixels in
Figure~\ref{fig:pixel}. As we can observe, for MobileNetV2, due to BN, the activation distribution of different pixels are very similar
to each other with relatively small magnitude. In contrast, for EDSR, on one hand, the magnitude of the activation distribution is much
larger compared to MobileNetV2; while on the other hand, the magnitude of different pixels are also quite different.
Such phenomenon is not specific to a certain layer in EDSR.
According to \cite{bulat2019xnor}, the difference of activation magnitudes indicates different scaling factors are needed for each pixel.
However, per-pixel binarization is not hardware friendly while existing per-tensor binarization schemes cannot capture the pixel-to-pixel
variation of activation distribution.
% However, per-pixel binarization is clearly uncompatible with the binary computation scheme mentioned above.
% requires different scaling factors for 
% Figure~\ref{fig:pixel} shows the pixel-wise distribution of both classification and 
%SR networks. We plot by randomly sampling 36 pixels in one layer. It is the same with other layers according to our observation.  As we can see, pixel-wise distributions in classification networks are similar, i.e., have closer mean and variance (Figure \ref{subfig:mbv2_pixel}). While in SR networks, distributions vary from pixel to pixel. Specifically, the distributions in SR networks have a larger range and the ranges are quite different for each curve in Figure \ref{subfig:edsr_pixel}. This motivates us to use different scaling factors for each pixel when quantizing the SR networks. 



\begin{figure}[!tb]%
  \centering
  \subfloat[Image1 in MobileNetV2]{
    \label{subfig:mbv2_1}
    \includegraphics[width=0.22\textwidth]{fig/mbv2_per_chl_6.png}
  }
  \subfloat[Image1 in EDSR]{
    \label{subfig:edsr_1}
    \includegraphics[width=0.22\textwidth]{fig/edsr_per_chl_2.png}
  }
  
   \subfloat[Image2 in MobileNetV2]{
    \label{subfig:mbv2_2}
    \includegraphics[width=0.22\textwidth]{fig/mbv2_per_img.png}
  }
  \subfloat[Image2 in EDSR]{
    \label{subfig:edsr_2}
    \includegraphics[width=0.22\textwidth]{fig/per_img.png}
  }
  
  \caption{
  %Distributions among channels in MobileV2 and EDSR (horizontal view).  And distributions of two different images in MobileNetV2 and EDSR (vertical view). 
  % For display purposes, we plot the channel-wise distributions by randomly sampling 24 channels in one layer. It is the same with other layers.
Activation distribution of EDSR exhibits much larger channel-to-channel (horizontal view) and image-to-image (vertical view) variations compared to MobileNetV2.
}
  
  \label{fig:chl}
\end{figure}

% \begin{figure}[htbp]%
%   \centering
%     \subfloat[Distributions of two different images in MobileNetV2]{
%     \label{subfig:mbv2_img}
%     \includegraphics[width=0.22\textwidth]{fig/mbv2_per_chl_6.png}

%     \includegraphics[width=0.22\textwidth]{fig/mbv2_per_img.png}
%   }
%   \quad
%   \subfloat[Distributions of two different images in EDSR]{
%     \label{subfig:edsr_img}
%     \includegraphics[width=0.22\textwidth]{fig/edsr_per_chl_2.png}

%     \includegraphics[width=0.22\textwidth]{fig/per_img.png}
%   }
%   \caption{Distributions of two different images in MobileNetV2 and EDSR. The first image we use is the same as in Figure 2. For the second image, we plot the distributions of the same channels in the same layer as the first image.}
%   \label{fig:img}
% \end{figure}

\textbf{Motivation 2: Channel-to-Channel Variation} 
We now compare the activation distributions for different channels within each layer.
We randomly sample 24 channels from the same layer of both MobileNetV2 and EDSR and visualize the activation distribution in Figure
\ref{subfig:mbv2_1} and \ref{subfig:edsr_1}. As we can observe, the activation distribution of EDSR is different from that of MobileNetV2
in that both the mean and variance of activations varies a lot across different channels in EDSR.
This indicates different channels require both different scaling factors and different bias during binarization.
% Figure \ref{subfig:mbv2_1} and \ref{subfig:edsr_1} show the channel-wise distributions which are randomly sampled in the same layer of both networks. Like what we have observed in Figure \ref{fig:pixel}, the channel-wise distribution of activations in SR networks also varies a lot. Furthermore, the mean of activations in each channel is quite different which is not obvious in Figure \ref{subfig:edsr_pixel}. This inspires us to use not only different scaling factors but also different biases for different channels to reduce the quantization error to the maximum extent.

% \ml{Merge Figure 3 and Figure 4 into one figure.}

One way to resolve the channel-to-channel variation of activation distribution is to leverage per-channel quantization,
which is used in \cite{hong2022daq}.
% A straightforward way to fit this activation distribution is the per-channel quantization for activations, which is used in \cite{hong2022daq}. 
However, per-channel quantization prevents BNN from performing bit-wise operations for convolution, which makes BNN lose its most important advantage. 
This is illustrated in Figure \ref{fig:per_chl_quant}. In this toy example, we have an activation tensor $A\in\mathbb{R}^{1\times4\times2\times2}$ and a 
weight tensor $W\in\mathbb{R}^{2\times4\times1\times1}$. When we convolve A with the first filter in red color, for activation per-tensor binarization 
(e.g., Figure \ref{subfig:per_tensor}), the convolution can be calculated as $s_a s_{w_1}\left[1\times 1+\left(-1\right)\times1 + \left(-1\right)\times1+ 1\times1\right]$, where $\left[\cdot\right]$ can be calculated efficiently by xnor and bit-count operations. 
However, for activation per-channel binarization (e.g., Figure \ref{subfig:per_chl}),
each channel of activations has a real-valued scaling factor and  the convolution is computed as $s_{a_1} s_{w_1} - s_{a_2} s_{w_1} + s_{a_3} s_{w_1} + s_{a_4} s_{w_1}$,
where all terms need to be calculated in FP without any acceleration.
Thus activation per-channel binarization is not feasible for BNN.

\begin{figure}[!tbp]%
  \centering
  \subfloat[Activation per-tensor quantize]{
    \label{subfig:per_tensor}
    \includegraphics[width=0.22\textwidth]{fig/per_tensor_quant.png}
  }
  \subfloat[Activation per-channel quantize]{
    \label{subfig:per_chl}
    \includegraphics[width=0.22\textwidth]{fig/per_chl_quant.png}
  }

  \caption{Activation per-channel quantize (a) and per-tensor quantize (b). For weights quantization, both (a) and (b) are per channel, i.e., each channel in the convolution output tensor has different scaling factors, which also means each kernel has a different scaling factor.}
  \label{fig:per_chl_quant}
\end{figure}



% \begin{figure}[htbp]%
%   \centering
%     \subfloat[Distributions of two different images in MobileNetV2]{
%     \label{subfig:mbv2_img}
%     \includegraphics[width=0.22\textwidth]{fig/mbv2_per_chl_6.png}

%     \includegraphics[width=0.22\textwidth]{fig/mbv2_per_img.png}
%   }
%   \quad
%   \subfloat[Distributions of two different images in EDSR]{
%     \label{subfig:edsr_img}
%     \includegraphics[width=0.22\textwidth]{fig/edsr_per_chl_2.png}

%     \includegraphics[width=0.22\textwidth]{fig/per_img.png}
%   }
%   \caption{Distributions of two different images in MobileNetV2 and EDSR. The first image we use is the same as in Figure 2. For the second image, we plot the distributions of the same channels in the same layer as the first image.}
%   \label{fig:img}
% \end{figure}

% \textbf{Need to emphasize this is for different channels.}

\textbf{Motivation 3: Image-to-Image Variation} 
We further compare the activation distributions of the same layer for different images.
As shown in Figure~\ref{subfig:edsr_1} and \ref{subfig:edsr_2},
for EDSR, both the mean and magnitude of the activation distributions are different,
indicating different images may require different scaling factors and bias as well.

\textbf{Remark} For the analysis above, by comparison with MobileNetV2, we observe
the activation distribution of EDSR exhibits clear pixel-to-pixel, channel-to-channel, and image-to-image variation.
We hypothesize this is important for high quality SR as it captures details specific to different images.
To preserve such variation requires the binarization scaling factor to be pixel, channel, and image dependent
while requires the bias to be channel and image dependent.
How to realize such requirements in BNNs would be important to close the gap with their full-precision counterparts.

% In Figure \ref{fig:chl}, we can see that for different images, their distributions are similar in classification networks but change a lot in super-resolution networks without BN. This reminds us to use different scaling factors and biases for different input images in BSR.