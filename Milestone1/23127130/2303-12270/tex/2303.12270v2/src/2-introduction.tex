\section{Introduction}
\label{sec:introduction}

Image super-resolution (SR) is a fundamental task in computer vision.
It aims to reconstruct high-resolution (HR) images, which have more details and high-frequency information, from low-resolution (LR) images.
% It is an ill-posed problem since 
% there are multiple HR images corresponding to a single SR image \cite{wang2020deep}.
In recent years, deep neural networks (DNNs) have achieved great quality in image SR including convolution neural network (CNN)-based~\cite{ledig2017photo, lim2017enhanced, zhang2018residual, tian2022image}
and Transformer-based~\cite{chen2021pre, liang2021swinir, chen2023activating} methods.
However extensive parameters and computation demands of these
SR networks hinder their deployment on resource-constrained devices.
% For example, HAT~\cite{chen2023activating} has xxx model size.

% suffer from intensive memory consumption and computational cost.
% The high memory and computation requirements of SR networks hinder their deployment on resource-constrained devices, such as mobile phones and other embedded systems. 

Network quantization is always a turn-to solution to reduce memory and computation costs. 
Among these, binary neural networks (BNN) quantizing the full-precision (FP) weights and activations to 1-bit
can achieve $32\times$ memory savings and $58\times$ speed up on CPUs~\cite{rastegari2016xnor}, 
which is quite effective.
However, there is still a lack of research on BNN for SR,
compared with BNN for image classification.
On the one hand, for CNN-based SR methods, 
BNN~\cite{xin2020binarized, jiang2021training, lang2022e2fif} still suffers from large performance degradation compared with their FP counterpart.
On the other hand, for Transformer-based SR methods, 
there is no research on BNN to the best of our knowledge.

% The computation saving is because the multiplications and accumulations of binary numbers can be replaced with XNOR and bit-count operations.

% \cite{ma2019efficient} are the first to introduce binarization to SR networks. 
% However, they only binarize weights and leave activations at full precision, which impedes the bit-wise operation and leads to a limited speedup. 
% Afterward, many works \cite{xin2020binarized, jiang2021training, lang2022e2fif} have explored BNNs for image SR with both binary activations and weights. 
% Though promising results have been achieved, all these BNNs still suffer from a large performance degradation compared to the floating-point (FP) counterparts.



% This is because SR, as a low-level task, focuses more on the details of the images, e.g. textures and edges for better reconstruction.
% However, existing binarization methods in BNNs for SR lack the ability to capture detailed information \cite{ma2019efficient, xin2020binarized, jiang2021training, li2022local, lang2022e2fif}, 
% and also require expensive hardware cost \cite{ma2019efficient, xin2020binarized, li2022local}.



% \begin{figure}[!tb]
% \centering
% \includegraphics[width=0.4\textwidth]{fig/3.pdf}
% \caption{Comparison between our proposed method SCALES with prior art methods.
% The performance is evaluated on Urban100 dataset at $\times4$ scale.
% The number of operations is evaluated on a $1280\times 720$ HR image.
% } 
% \label{fig:intro}
% \end{figure}


\begin{figure}[!tb]
\centering
\includegraphics[width=0.49\textwidth]{fig/intro_fig_new.pdf}
\caption{The binary feature maps with our method SCALES and the prior art method E2FIF.} 
% the prior art. The binary feature maps in our model can capture more textures and details for image reconstruction.} 
\vspace{-10pt}
\label{fig:intro}
\end{figure}


To this end, we study the BNN for SR comprehensively for 
both CNN-based and Transformer-based SR networks.
We discover that the activation distributions in FP SR networks including CNN and Transformer
exhibit much larger pixel-to-pixel, channel-to-channel, layer-to-layer, and image-to-image variations compared to the image classification networks.
Exiting BNNs for SR
can not capture these variations that contain detailed information for image SR
simply using the binarization methods for classification networks.
% The detailed information, which is significantly important for image SR,
% contains in the activation distribution in the SR network.
% We discover that the activation distributions in FP SR networks including CNN and Transformer
% exhibit much larger pixel-to-pixel, channel-to-channel, layer-to-layer, and image-to-image variations compared to the image classification networks.
To avoid such important variations getting lost during binarization, 
we propose our method SCALES,
which consists of the layer-wise scaling factor, 
the spatial re-scaling, 
and channel-wise re-scaling method, 
to capture the layer-wise, pixel-wise, and channel-wise variations respectively in
an input-dependent manner.
With our method,
we can preserve more textures and details
for image SR compared to the prior art method in Fig.~\ref{fig:intro}.
Extensive experiments demonstrate the effectiveness of our method.
For example, for CNN-based networks,
SCALES outperforms the prior art method by 0.22dB and 0.19dB on Urban100 dataset
with less number of parameters and operations.
For Transformer-based networks,
SCALES improves PSNR by more than 1dB compared to the baseline,
leading to the first accurate binary Transformer-based SR network.
% SCALES exhibits the best accuracy-efficiency trade-off as shown in Fig.~\ref{fig:intro}.

% through which the image-to-image variation is also captured.
% Based on these techniques, SCALES demonstrates superior performance with lower cost compared to the prior art methods 
% as shown in Fig.~\ref{fig:intro}.


% To improve the performance of BNNs for SR, we start with the full-precision (FP) SR network. 
% We discover that the activation distributions in modern FP SR networks exhibit much larger pixel-to-pixel, channel-to-channel, layer-to-layer, and image-to-image variations compared with the image classification networks.
% These large variations contain significant information
% for image SR.
% % This is mainly because modern SR networks remove batch normalization (BN), which will normalize the features and destroy the original information of the input image \cite{lim2017enhanced,wang2020deep}.
% To avoid such important variations being get lost during quantization, 
% we propose SCALES, a binarization method for SR networks with efficient scalings. 
% SCALES consists of three techniques, including the layer-wise scaling factor, 
% the spatial re-scaling module, 
% and the channel-wise re-scaling module, 
% which captures the layer-wise, pixel-wise, and channel-wise variations efficiently in
% an input-dependent manner.
% % we first propose a strong binarization function to improve the performance and stabilize the training process without BN.
% % Then we propose spatial re-scaling and channel-wise re-scaling to capture the spatial and channel-wise activation variation respectively in an input-dependent manner.
% % Combining them, we achieve the efficient Spatial and ChAnneL-wisE re-Scaling method, dubbed SCALES, 
% % which significantly improves the representation ability of BNNs.



Overall, our contributions can be summarized as follows:
\begin{itemize}
    \item  We observe the activation distribution in the CNN-based and Transformer-based SR networks and discover large
    pixel-to-pixel, channel-to-channel, layer-to-layer, and image-to-image variations,
    which are important for high-performance image SR.
    \item To capture the variations, we propose a binarization method for SR networks, dubbed SCALES, which is composed of the layer-wise scaling factor, the spatial re-scaling method, 
    and the channel-wise re-scaling method.
    \item We evaluate SCALES across different SR network architectures on different benchmark datasets. 
    % Experimental results demonstrate significant performance improvement over the prior art method with fewer operations and parameters.
    % With SCALES, we achieve the first accurate binary Transformer-SR network.
    For CNN-based SR networks, SCALES outperforms the prior art method by 0.2dB with fewer parameters and operations. 
    With SCALES, we also achieve the first accurate binary Transformer-based SR network, improving PSNR by more than 1dB compared to the baseline method.
\end{itemize}