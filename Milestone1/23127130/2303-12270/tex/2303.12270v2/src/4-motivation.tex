\section{Motivation}
\label{sec:motivation}

Existing BNNs focus on binarizing the weights and the input activations of the basic blocks in the body module as shown in Fig.~\ref{fig:network_arch},
which account for most of the parameters and computations of the entire
model.
However, they ignore the large variations in activation distribution and have inferior SR performance.
In this section, we showcase that the activation distributions in FP SR networks exhibit much larger \textit{pixel-to-pixel, channel-to-channel, layer-to-layer, and image-to-image variations} than those in the image classification networks.

\subsection{Variations in CNN-based SR Network}

\begin{figure}[!tb]%
  \centering
  % \hspace*{-0.5cm}
    \subfloat[Distribution across pixels (img1)]{
        \label{subfig:CNN Distribution across pixels image1}
        \includegraphics[width=0.22\textwidth]{fig/edsr_per_pixel_img1.pdf}
      }
      \subfloat[Distribution across pixels (img2)]{
        \label{subfig:CNN Distribution across pixels img2}
        \includegraphics[width=0.22\textwidth]{fig/edsr_per_pixel_img2.pdf}
      }
      
% \hspace*{-0.5cm}
    \subfloat[Distribution across layers]{
        \label{subfig:CNN Distribution across layers}
        \includegraphics[width=0.22\textwidth]{fig/edsr_per_layer_v1.pdf}
    }
    \subfloat[Distribution across channels]{
        \label{subfig:CNN Distribution across channels}
        \includegraphics[width=0.22\textwidth]{fig/edsr_per_chl_image2.pdf}
    }
  
  \caption{
Activation distribution in EDSR~\cite{lim2017enhanced}. 
% \ml{Write the key observation in the caption in one sentence.}
}
  \label{fig:chl}
   \vspace{-5pt} % Adjust this value to decrease the space
\end{figure}



\begin{figure}[!tb]%
  \centering
  % \hspace*{-0.1cm}
    \subfloat[Distribution in ResNet18]{
        \label{subfig:Distribution in ResNet18}
        \includegraphics[width=0.22\textwidth]{fig/resnet_per_pixel.pdf}
      }
      \subfloat[Distribution in SwinViT]{
        \label{subfig:Distribution in SwinViT}
        \includegraphics[width=0.22\textwidth]{fig/per_pixel_swinvit.pdf}
      }
      
  \caption{
Activation distribution in CNN-based and Transformer-based classification networks ResNet18~\cite{he2016deep} and SwinViT~\cite{liu2021swin}.
The distributions across pixels, channels, layers, and images are similar, 
thus we only show distributions across pixels here.
}
  \label{fig:chl}
   \vspace{-5pt} % Adjust this value to decrease the space
\end{figure}


As shown in Fig.~\ref{subfig:CNN Distribution across pixels image1}, we random sample 20 pixels from a feature map in a CNN-based SR network EDSR,
where each pixel contains C (the number of channels) elements.
We observe large \textit{pixel-to-pixel variation},
compared to ResNet18 in Fig.~\ref{subfig:Distribution in ResNet18}.
The same holds true for \textit{channel-to-channel variation}.
The main reason is that modern SR networks removes BN
for better SR performance,
leading to large activation variations.
According to~\cite{bulat2019xnor},
the difference in activation magnitudes indicates different scaling
factors are needed. 
However, per-pixel or per-channel quantization for activation
is infeasible because they will introduce large computation overhead~\cite{xiao2023smoothquant} while existing per-tensor binarization schemes cannot capture the
variation of activation distribution.

For different layers, activations in
EDSR also exhibit large \textit{layer-to-layer variation} in Fig.~\ref{subfig:CNN Distribution across layers}.
Moreover, we find that the activations in the even layers are small, whereas the activations in the odd layers exhibit large magnitudes.
This is because for the basic block in Fig.~\ref{fig:network_arch}, the shortcut
maintains the original information of the input LR image, while the inner branch intends to re-construct the small
difference between the LR and HR image. 
Thus, the input of the first conv layer has
large magnitude, while the input of the second conv
layer has small magnitude,
which implies that different binarization schemes should be employed for different layers.
Comparing Fig.~\ref{subfig:CNN Distribution across pixels image1}
and~\ref{subfig:CNN Distribution across pixels img2},
we can also find the large \textit{image-to-image variation},
which motivates us to quantize the SR network in an input-dependent manner.


\subsection{Variations in Transformer-based SR Network}

\begin{figure}[!tb]%
  \centering
  % \hspace*{-0.5cm}
    \subfloat[Distribution across pixels (img1)]{
        \label{subfig:Distribution across pixels image1}
        \includegraphics[width=0.22\textwidth]{fig/per_pixel_image1.pdf}
      }
      \subfloat[Distribution across pixels (img2)]{
        \label{subfig:Distribution across pixels img2}
        \includegraphics[width=0.22\textwidth]{fig/per_pixel_image3.pdf}
      }
      
% \hspace*{-0.5cm}
    \subfloat[Distribution across layers (linear)]{
        \label{subfig:Distribution across layers (linear)}
        \includegraphics[width=0.22\textwidth]{fig/per_layer_transformer_block.pdf}
    }
    \subfloat[Distribution across layers (conv)]{
        \label{subfig:Distribution across layers (conv)}
        \includegraphics[width=0.22\textwidth]{fig/per_layer_conv.pdf}
    }
  
  \caption{
Activation distribution in SwinIR~\cite{liang2021swinir}.
}
  \label{fig:distribution in swinIR}
   \vspace{-5pt} % Adjust this value to decrease the space
\end{figure}

Large \textit{pixel-to-pixel, layer-to-layer} and \textit{image-to-image variations}
also exist in Transformer-based SR networks
as shown in Fig.~\ref{fig:distribution in swinIR}.
For the layer-to-layer variation, we plot the input activations of the four linear layers in the Transformer block
in Fig.~\ref{subfig:Distribution across layers (linear)}
and the last conv layer of each basic block in Fig.~\ref{subfig:Distribution across layers (conv)}.
It is worth noting that channel-to-channel variation 
does not exist in SwinIR,
since LayerNorm (LN) normalizes each token across the channel dimension.
Thus, for the Transformer-based SR network,
we should apply different quantization schemes
to capture the pixel-wise, layer-wise, and image-wise variations.
For quantitative comparison,
we calculate the variance of image SR and classification networks in Table~\ref{tab:variance_comparison},
which is consistent with our observations above. 

\begin{table}[!tb]
\centering
\caption{Activation variance comparison.
} 
\label{tab:variance_comparison}
% \vspace{-5pt}
\scalebox{1.0}{
\begin{tabular}{c|cc|cc}
\hline
               & EDSR    & ResNet & SwinIR & SwinViT \\ \hline
chl-to-chl     & 439.17  & 0.10   & 0.11   & 0.10    \\
pixel-to-pixel & 622.25  & 0.34   & 0.87   & 0.12    \\
layer-to-layer & 3494.38 & 0.92   & 162.70 & 3.46    \\
image-to-image & 599.39  & 0.32   & 0.84   & 0.13    \\ \hline
\end{tabular}
}
\vspace{-5pt}
\end{table}


