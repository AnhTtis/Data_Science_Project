\section{Conclusion}
\label{sec:conclusion}

In this paper, we propose an effective binarization method SCALES for both 
CNN-based and Transformer-based image SR networks,
based on our observation that activations in the SR network exhibit large pixel-to-pixel, channel-to-channel, layer-to-layer, and image-to-image variation.
With SCALES,
we improve the performance of binary CNN-based networks 
e.g., 0.2dB over the prior art method, with fewer parameters and operations.
We also achieve an accurate binary Transformer-based network for the first time,
attaining more than 1dB improvement over the baseline method.

% observe the activation distribution in FP SR networks exhibits large pixel-to-pixel, channel-to-channel, layer-to-layer, and image-to-image variation, which is important for high-performance SR and needs to be preserved during binarization.
% Therefore, we propose SCALES, a binarization method for SR networks with efficient scalings. 
% SCALES is composed of three techniques, including the layer-wise scaling factor, 
% the spatial re-scaling module, 
% and the channel-wise re-scaling module, 
% which captures the layer-wise, pixel-wise, and channel-wise variations efficiently in
% an input-dependent manner.
% Our proposed method, SCALES, demonstrates superior performance over prior art methods both quantitatively and qualitatively 
% with high memory and computation efficiency 
% across different models and datasets.
% Overall, 
% our work significantly narrows the gap between BNNs for SR and their FP counterparts
% and provides constructive guidance in the area.


% In this paper, we observe the activation distribution in FP SR networks exhibits large pixel-to-pixel, channel-to-channel, layer-to-layer, and image-to-image variation, which is important for high-performance SR and needs to be preserved during binarization.
% Therefore, we propose SCALES, a binarization method for SR networks with efficient scalings. 
% SCALES is composed of three techniques, including the layer-wise scaling factor, 
% the spatial re-scaling module, 
% and the channel-wise re-scaling module, 
% which captures the layer-wise, pixel-wise, and channel-wise variations efficiently in
% an input-dependent manner.
% Our proposed method, SCALES, demonstrates superior performance over prior art methods both quantitatively and qualitatively 
% with high memory and computation efficiency 
% across different models and datasets.
% Overall, 
% our work significantly narrows the gap between BNNs for SR and their FP counterparts
% and provides constructive guidance in the area.