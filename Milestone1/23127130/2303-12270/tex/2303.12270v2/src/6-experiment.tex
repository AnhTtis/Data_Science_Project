\section{Experiments}
\label{sec:experiments}

\subsection{Network Architectures}
We evaluate our proposed method SCALES on different SR network architectures.
For CNN-based SR networks,
we choose SRResNet \cite{ledig2017photo}, EDSR \cite{lim2017enhanced}, RDN \cite{zhang2018residual}, and RCAN \cite{zhang2018image}.
For Transformer-based SR networks,
we choose SwinIR (Lightweight)~\cite{liang2021swinir} and HAT~\cite{chen2023activating}.
% For SRResNet, the number of residual blocks and filters are 16 and 64 respectively.
% For EDSR, they are 32 and 256. 
% For RDN, we set the RDB number (D) to 6, the conv number per RDB (C) to 6, and the growth rate (G) to 32.
% For RCAN, we set the number of residual groups (RG) to 10, the number of residual channel attention blocks per RG (RCAB) to 5, and the number of filters to 64.
% All methods are evaluated under the same network settings above.
% We use the full-precision skip connection and the lightweight tail module following \cite{lang2022e2fif}.
Following existing works, the head and tail modules are not binarized.


\subsection{Experimental Settings}
We train all the models on the training set of DIV2K \cite{timofte2017ntire}. 
For evaluation, we use four standard benchmark datasets including Set5 \cite{bevilacqua2012low}, Set14 \cite{zeyde2012single}, B100 \cite{martin2001database} and Urban100 \cite{huang2015single}. 
For evaluation metrics, we use PSNR and SSIM \cite{wang2004image} over the Y channel of transformed YCbCr space.
We choose L1 loss between the SR image and the HR image as our loss function. 
% Three upscaling factors, i.e., $\times 2$, $\times 3$, and $\times 4$ are evaluated for image super-resolution. 
Input patch size is set to $48 \times 48$. The batch size is set to 16. We use ADAM optimizer with $\beta_1=0.9$, $\beta_2=0.999$, and $\epsilon=10^{-8}$. 
We train our models for 300 epochs from scratch.
The learning rate is initialized as $2 \times 10^{-4}$ and halved every 200 epochs.

\subsection{Quantitative and Qualitative Results}

\begin{table*}[!tb]
\centering
\caption{Comparison of different methods on CNN-based SR network (SRResNet).}
\label{tab:result_srresnet}

\scalebox{1.0}{

\begin{tabular}{l|c|c|c|cc|cc|cc|cc}
\hline
\multirow{2}{*}{Method} & \multirow{2}{*}{Scale} & \multirow{2}{*}{Params} & \multirow{2}{*}{OPs} & \multicolumn{2}{c|}{Set5}       & \multicolumn{2}{c|}{Set14}      & \multicolumn{2}{c|}{B100}       & \multicolumn{2}{c}{Urban100}    \\ \cline{5-12} 
                        &                        &                         &                      & PSNR           & SSIM           & PSNR           & SSIM           & PSNR           & SSIM           & PSNR           & SSIM           \\ \hline
SRResNet-FP             & x2                     & 1517K                   & 913.8G               & 37.76          & 0.958          & 33.27          & 0.914          & 31.95          & 0.895          & 31.28          & 0.919          \\
Bicubic                 & x2                     & -                       & -                    & 33.66          & 0.930          & 30.24          & 0.869          & 29.56          & 0.843          & 26.88          & 0.840          \\
SRResNet-BAM            & x2                     & 37K                     & 28.5G                & 37.21          & 0.956          & 32.74          & 0.910          & 31.60          & 0.891          & 30.20          & 0.906          \\
SRResNet-BTM            & x2                     & 35K                     & 25.8G                & 37.22          & 0.957          & 32.93          & 0.912          & 31.77          & 0.894          & 30.79          & 0.914          \\
SRResNet-E2FIF          & x2                     & 35K                     & 25.8G                & 37.50          & \textbf{0.958} & 32.96          & 0.911          & 31.79          & 0.894          & 30.73          & 0.913          \\
SRResNet-SCALES (ours)  & x2                     & 34K                     & 24.5G                & \textbf{37.56} & \textbf{0.958} & \textbf{33.10} & \textbf{0.912} & \textbf{31.83} & \textbf{0.895} & \textbf{30.95} & \textbf{0.915} \\ \hline
SRResNet-FP             & x4                     & 1517K                   & 228.5G               & 31.76          & 0.888          & 28.25          & 0.773          & 27.38          & 0.727          & 25.54          & 0.767          \\
Bicubic                 & x4                     & -                       & -                    & 28.42          & 0.810          & 26.00          & 0.703          & 25.96          & 0.668          & 23.14          & 0.658          \\
SRResNet-BAM            & x4                     & 37K                     & 7.1G                 & 31.24          & 0.878          & 27.97          & 0.765          & 27.15          & 0.719          & 24.95          & 0.745          \\
SRResNet-BTM            & x4                     & 35K                     & 6.4G                 & 31.25          & 0.878          & 27.94          & 0.765          & 27.18          & 0.720          & 25.01          & 0.748          \\
SRResNet-E2FIF          & x4                     & 35K                     & 6.4G                 & 31.33          & 0.880          & 27.93          & 0.766          & 27.20          & 0.723          & 25.08          & 0.750          \\
SRResNet-SCALES (ours)  & x4                     & 34K                     & 6.1G                 & \textbf{31.54} & \textbf{0.883} & \textbf{28.15} & \textbf{0.770} & \textbf{27.28} & \textbf{0.726} & \textbf{25.27} & \textbf{0.757} \\ \hline
\end{tabular}

}
\end{table*}



\begin{table*}[!tb]
\centering
\caption{Comparison of different methods on Transformer-based SR network (SwinIR and HAT).}
\label{tab:result_swinir_and_hat}

\scalebox{1.0}{

\begin{tabular}{l|c|c|c|cc|cc|cc|cc}
\hline
\multirow{2}{*}{Method} & \multirow{2}{*}{Scale} & \multirow{2}{*}{Params} & \multirow{2}{*}{OPs} & \multicolumn{2}{c|}{Set5}       & \multicolumn{2}{c|}{Set14}      & \multicolumn{2}{c|}{B100}       & \multicolumn{2}{c}{Urban100}    \\ \cline{5-12} 
                        &                        &                         &                      & PSNR           & SSIM           & PSNR           & SSIM           & PSNR           & SSIM           & PSNR           & SSIM           \\ \hline
SwinIR-FP               & x2                     & 878K                    & 391.2G               & 38.14          & 0.961          & 33.86          & 0.921          & 32.31          & 0.901          & 32.76          & 0.934          \\
SwinIR-BiBERT           & x2                     & 66K                     & 12.5G                & 35.58          & 0.947          & 31.79          & 0.900          & 30.80          & 0.880          & 28.34          & 0.877          \\
SwinIR-SCALES (ours)    & x2                     & 73K                     & 15.3G                & \textbf{36.97} & \textbf{0.956} & \textbf{32.53} & \textbf{0.908} & \textbf{31.39} & \textbf{0.889} & \textbf{29.56} & \textbf{0.897} \\ \hline
SwinIR-FP               & x4                     & 897K                    & 99.2G                & 32.44          & 0.898          & 28.77          & 0.786          & 27.69          & 0.741          & 26.47          & 0.798          \\
SwinIR-BiBERT           & x4                     & 86K                     & 3.2G                 & 29.52          & 0.835          & 26.80          & 0.734          & 26.50          & 0.697          & 23.77          & 0.690          \\
SwinIR-SCALES (ours)    & x4                     & 93K                     & 3.9G                 & \textbf{29.96} & \textbf{0.849} & \textbf{27.13} & \textbf{0.743} & \textbf{26.67} & \textbf{0.704} & \textbf{24.06} & \textbf{0.704} \\ \hline\hline
HAT-FP                  & x2                     & 20.44M                  & 807.6G               & 38.73          & 0.964          & 35.13          & 0.928          & 32.69          & 0.906          & 34.81          & 0.949          \\
HAT-BiBERT              & x2                     & 0.86M                   & 25.8G                & 28.29          & 0.793          & 26.46          & 0.722          & 26.46          & 0.699          & 24.13          & 0.698          \\
HAT-SCALES (ours)       & x2                     & 0.91M                   & 35.9G                & \textbf{37.34} & \textbf{0.958} & \textbf{32.97} & \textbf{0.912} & \textbf{31.76} & \textbf{0.894} & \textbf{30.61} & \textbf{0.912} \\ \hline
HAT-FP                  & x4                     & 20.80M                  & 204.8G               & 33.18          & 0.907          & 29.38          & 0.800          & 28.05          & 0.753          & 28.37          & 0.845          \\
HAT-BiBERT              & x4                     & 1.01M                   & 6.6G                 & 26.92          & 0.774          & 25.02          & 0.671          & 25.23          & 0.645          & 22.65          & 0.639          \\
HAT-SCALES (ours)       & x4                     & 1.06M                   & 9.3G                 & \textbf{31.23} & \textbf{0.881} & \textbf{27.96} & \textbf{0.766} & \textbf{27.17} & \textbf{0.722} & \textbf{24.98} & \textbf{0.747} \\ \hline
\end{tabular}

}
\end{table*}


% \begin{table*}[!tbp]
% \centering
% \caption{Comparison of different methods on CNN-based SR network (EDSR).}
% \label{tab:result_edsr}

% \scalebox{1.0}{

% \begin{tabular}{c|c|cc|cc|cc|cc}
% \hline
% \multirow{2}{*}{Method} & \multirow{2}{*}{Scale} & \multicolumn{2}{c|}{Set5}       & \multicolumn{2}{c|}{Set14}      & \multicolumn{2}{c|}{B100}       & \multicolumn{2}{c}{Urban100}    \\ \cline{3-10} 
%                         &                        & PSNR           & SSIM           & PSNR           & SSIM           & PSNR           & SSIM           & PSNR           & SSIM           \\ \hline
% EDSR-FP                 & x2                     & 38.11          & 0.960          & 33.92          & 0.920          & 32.32          & 0.901          & 32.93          & 0.935          \\
% Bicubic                 & x2                     & 33.66          & 0.930          & 30.24          & 0.869          & 29.56          & 0.843          & 26.88          & 0.840          \\
% % EDSR-BNN                & x2                     & 34.47          & 0.938          & 31.06          & 0.891          & 30.27          & 0.872          & 27.72          & 0.864          \\
% % EDSR-BiReal             & x2                     & 37.13          & 0.956          & 32.73          & 0.909          & 31.54          & 0.891          & 29.94          & 0.903          \\
% EDSR-IBTM               & x2                     & 37.80          & 0.960          & 33.38          & 0.916          & 32.04          & 0.898          & 31.49          & 0.922          \\
% EDSR-E2FIF              & x2                     & 37.95          & \textbf{0.960} & 33.37          & 0.915          & \textbf{32.13} & \textbf{0.899} & 31.79          & 0.924          \\
% EDSR-SCALES (ours)       & x2                     & \textbf{37.98} & 0.959        & \textbf{33.58} & \textbf{0.917}  & 32.12          & 0.898          & \textbf{31.97} & \textbf{0.926} \\ \hline
% % EDSR-FP                 & x3                     & 34.65          & 0.928          & 32.52          & 0.846          & 29.25          & 0.809          & 28.80          & 0.865          \\
% % Bicubic                 & x3                     & 30.39          & 0.868          & 27.55          & 0.774          & 27.21          & 0.739          & 24.46          & 0.735          \\
% % % EDSR-BNN                & x3                     & 20.85          & 0.399          & 19.47          & 0.299          & 19.23          & 0.285          & 18.18          & 0.307          \\
% % % EDSR-BiReal             & x3                     & 33.17          & 0.914          & 29.53          & 0.826          & 28.53          & 0.790          & 26.46          & 0.801          \\
% % EDSR-IBTM               & x3                     & 34.10          & 0.924          & 30.11          & 0.838          & 28.93          & 0.801          & 27.49          & 0.839          \\
% % EDSR-E2FIF               & x3                     & 34.24          & 0.925          & 30.06          & 0.837          & 29.00          & 0.802          & 27.84          & 0.844          \\
% % EDSR-SCALES (ours)             & x3               & \textbf{34.40} & \textbf{0.925} & \textbf{30.31} & \textbf{0.841} & \textbf{29.06} & \textbf{0.803} & \textbf{28.10} & \textbf{0.850} \\ \hline
% EDSR-FP                 & x4                     & 32.46          & 0.897          & 28.80          & 0.787          & 27.71          & 0.742          & 26.64          & 0.803          \\
% Bicubic                 & x4                     & 28.42          & 0.810          & 26.00          & 0.703          & 25.96          & 0.668          & 23.14          & 0.658          \\
% % EDSR-BNN                & x4                     & 17.53          & 0.188          & 17.51          & 0.160          & 17.15          & 0.151          & 16.35          & 0.163          \\
% % EDSR-BiReal             & x4                     & 30.81          & 0.871          & 27.71          & 0.760          & 27.01          & 0.716          & 24.66          & 0.733          \\
% EDSR-IBTM               & x4                     & 31.84          & 0.890          & 28.33          & 0.777          & 27.42          & 0.732          & 25.54          & 0.769          \\
% EDSR-E2FIF               & x4                     & 31.91          & 0.890          & 28.29          & 0.755          & 27.44          & 0.731          & 25.74          & 0.774          \\
% EDSR-SCALES (ours)             & x4               & \textbf{32.17} & \textbf{0.892} & \textbf{28.56} & \textbf{0.781} & \textbf{27.54} & \textbf{0.735} & \textbf{26.05} & \textbf{0.784} \\ \hline
% \end{tabular}


% }
% \end{table*}




% \begin{table*}[h]
% \centering
% \caption{Comparison of different methods on RDN architecture.}
% \label{tab:result_rdn}

% \scalebox{0.9}{

% \begin{tabular}{c|c|cc|cc|cc|cc}
% \hline
% \multirow{2}{*}{Method} & \multirow{2}{*}{Scale} & \multicolumn{2}{c|}{Set5}       & \multicolumn{2}{c|}{Set14}      & \multicolumn{2}{c|}{B100}       & \multicolumn{2}{c}{Urban100}    \\ \cline{3-10} 
%                         &                        & PSNR           & SSIM           & PSNR           & SSIM           & PSNR           & SSIM           & PSNR           & SSIM           \\ \hline
% RDN-FP                  & x2                     & 37.92          & 0.959          & 33.52          & 0.916          & 32.13          & 0.898          & 31.86          & 0.925          \\
% Bicubic                 & x2                     & 33.66          & 0.930          & 30.24          & 0.869          & 29.56          & 0.843          & 26.88          & 0.840          \\
% RDN-BiReal              & x2                     & 31.17          & 0.885          & 28.84          & 0.837          & 28.67          & 0.827          & 26.20          & 0.816          \\
% RDN-E2FIF               & x2                     & 37.20          & 0.956          & 32.77          & 0.909          & 31.60          & 0.891          & 30.19          & 0.906          \\
% RDN-SCALES (ours)       & x2                     & \textbf{37.40} & \textbf{0.957} & \textbf{32.93} & \textbf{0.911} & \textbf{31.72} & \textbf{0.893} & \textbf{30.54} & \textbf{0.911} \\ \hline
% RDN-FP                  & x3                     & 34.34          & 0.925          & 30.29          & 0.84           & 29.05          & 0.803          & 27.99          & 0.849          \\
% Bicubic                 & x3                     & 30.39          & 0.868          & 27.55          & 0.774          & 27.21          & 0.739          & 24.46          & 0.735          \\
% RDN-BiReal              & x3                     & 29.29          & 0.84           & 26.93          & 0.762          & 26.85          & 0.738          & 24.24          & 0.726          \\
% RDN-E2FIF               & x3                     & 33.19          & 0.914          & 29.56          & 0.827          & 28.56          & 0.79           & 26.57          & 0.812          \\
% RDN-SCALES (ours)       & x3                     & \textbf{33.48} & \textbf{0.918} & \textbf{29.75} & \textbf{0.830}  & \textbf{28.68} & \textbf{0.794} & \textbf{26.90} & \textbf{0.823} \\ \hline
% RDN-FP                  & x4                     & 32.09          & 0.892          & 28.56          & 0.78           & 27.54          & 0.735          & 25.96          & 0.782          \\
% Bicubic                 & x4                     & 28.42          & 0.810          & 26.00          & 0.703          & 25.96          & 0.668          & 23.14          & 0.658          \\
% RDN-BiReal              & x4                     & 27.77          & 0.793          & 25.59          & 0.698          & 25.67          & 0.67           & 23.01          & 0.656          \\
% RDN-E2FIF               & x4                     & 30.92          & 0.872          & 27.81          & 0.761          & 27.06          & 0.718          & 24.77          & 0.738          \\
% RDN-SCALES (ours)       & x4                     & \textbf{31.27} & \textbf{0.879} & \textbf{28.02} & \textbf{0.767} & \textbf{27.18} & \textbf{0.723} & \textbf{25.02} & \textbf{0.749} \\ \hline
% \end{tabular}

% }
% \end{table*}


% \begin{table*}[h]
% \centering
% \caption{Comparison of different methods on RCAN architecture.}
% \label{tab:result_rcan}

% \scalebox{0.9}{

% \begin{tabular}{c|c|cc|cc|cc|cc}
% \hline
% \multirow{2}{*}{Method} & \multirow{2}{*}{Scale} & \multicolumn{2}{c|}{Set5}       & \multicolumn{2}{c|}{Set14}      & \multicolumn{2}{c|}{B100}       & \multicolumn{2}{c}{Urban100}    \\ \cline{3-10} 
%                         &                        & PSNR           & SSIM           & PSNR           & SSIM           & PSNR           & SSIM           & PSNR           & SSIM           \\ \hline
% RCAN-FP                 & x2                     & 38.12          & 0.96           & 33.76          & 0.919          & 32.24          & 0.900          & 32.45          & 0.931          \\
% Bicubic                 & x2                     & 33.66          & 0.930          & 30.24          & 0.869          & 29.56          & 0.843          & 26.88          & 0.840          \\
% RCAN-BiReal             & x2                     & 33.37          & 0.923          & 30.26          & 0.873          & 29.82          & 0.858          & 27.22          & 0.852          \\
% RCAN-E2FIF              & x2                     & 37.62          & \textbf{0.958} & 33.14          & \textbf{0.913} & 31.85          & \textbf{0.895} & 31.05          & 0.916          \\
% RCAN-SCALES (ours)      & x2                     & \textbf{37.67} & \textbf{0.958} & \textbf{33.22} & \textbf{0.913} & \textbf{31.91} & \textbf{0.895} & \textbf{31.23} & \textbf{0.918} \\ \hline
% RCAN-FP                 & x3                     & 34.39          & 0.926          & 30.34          & 0.842          & 29.11          & 0.805          & 28.30          & 0.855          \\
% Bicubic                 & x3                     & 30.39          & 0.868          & 27.55          & 0.774          & 27.21          & 0.739          & 24.46          & 0.735          \\
% RCAN-BiReal             & x3                     & 30.32          & 0.865          & 27.63          & 0.784          & 27.32          & 0.755          & 24.65          & 0.748          \\
% RCAN-E2FIF              & x3                     & 33.81          & 0.920          & 29.90          & 0.833          & 28.79          & 0.797          & 27.26          & 0.831          \\
% RCAN-SCALES (ours)      & x3                     & \textbf{33.89} & \textbf{0.921} & \textbf{29.95} & \textbf{0.834} & \textbf{28.85} & \textbf{0.798} & \textbf{27.42} & \textbf{0.836} \\ \hline
% RCAN-FP                 & x4                     & 32.37          & 0.895          & 28.72          & 0.785          & 27.64          & 0.738          & 26.39          & 0.795          \\
% Bicubic                 & x4                     & 28.42          & 0.810          & 26.00          & 0.703          & 25.96          & 0.668          & 23.14          & 0.658          \\
% RCAN-BiReal             & x4                     & 28.47          & 0.810          & 26.06          & 0.709          & 26.01          & 0.679          & 23.36          & 0.672          \\
% RCAN-E2FIF              & x4                     & 31.54          & 0.883          & 28.16          & 0.770          & 27.28          & 0.726          & 25.30          & 0.759          \\
% RCAN-SCALES (ours)      & x4                     & \textbf{31.65} & \textbf{0.885} & \textbf{28.25} & \textbf{0.772} & \textbf{27.33} & \textbf{0.727} & \textbf{25.44} & \textbf{0.763} \\ \hline
% \end{tabular}

% }
% \end{table*}


% \begin{table*}[!tbp]
% \centering
% \caption{Comparison of different methods on RDN architecture.}
% \label{tab:result_rdn}

% \scalebox{0.9}{

% \begin{tabular}{c|c|cc|cc|cc|cc}
% \hline
% \multirow{2}{*}{Method} & \multirow{2}{*}{Scale} & \multicolumn{2}{c|}{Set5}       & \multicolumn{2}{c|}{Set14}      & \multicolumn{2}{c|}{B100}       & \multicolumn{2}{c}{Urban100}    \\ \cline{3-10} 
%                         &                        & PSNR           & SSIM           & PSNR           & SSIM           & PSNR           & SSIM           & PSNR           & SSIM           \\ \hline
% RDN-FP                  & x2                     & 37.92          & 0.959          & 33.52          & 0.916          & 32.13          & 0.898          & 31.86          & 0.925          \\
% Bicubic                 & x2                     & 33.66          & 0.930          & 30.24          & 0.869          & 29.56          & 0.843          & 26.88          & 0.840          \\
% RDN-BiReal              & x2                     & 31.17          & 0.885          & 28.84          & 0.837          & 28.67          & 0.827          & 26.20          & 0.816          \\
% RDN-E2FIF               & x2                     & 37.20          & 0.956          & 32.77          & 0.909          & 31.60          & 0.891          & 30.19          & 0.906          \\
% RDN-SCALES (ours)       & x2                     & \textbf{37.40} & \textbf{0.957} & \textbf{32.93} & \textbf{0.911} & \textbf{31.72} & \textbf{0.893} & \textbf{30.54} & \textbf{0.911} \\ \hline
% RDN-FP                  & x3                     & 34.34          & 0.925          & 30.29          & 0.84           & 29.05          & 0.803          & 27.99          & 0.849          \\
% Bicubic                 & x3                     & 30.39          & 0.868          & 27.55          & 0.774          & 27.21          & 0.739          & 24.46          & 0.735          \\
% RDN-BiReal              & x3                     & 29.29          & 0.84           & 26.93          & 0.762          & 26.85          & 0.738          & 24.24          & 0.726          \\
% RDN-E2FIF               & x3                     & 33.19          & 0.914          & 29.56          & 0.827          & 28.56          & 0.79           & 26.57          & 0.812          \\
% RDN-SCALES (ours)       & x3                     & \textbf{33.48} & \textbf{0.918} & \textbf{29.75} & \textbf{0.830}  & \textbf{28.68} & \textbf{0.794} & \textbf{26.90} & \textbf{0.823} \\ \hline
% RDN-FP                  & x4                     & 32.09          & 0.892          & 28.56          & 0.78           & 27.54          & 0.735          & 25.96          & 0.782          \\
% Bicubic                 & x4                     & 28.42          & 0.810          & 26.00          & 0.703          & 25.96          & 0.668          & 23.14          & 0.658          \\
% RDN-BiReal              & x4                     & 27.77          & 0.793          & 25.59          & 0.698          & 25.67          & 0.67           & 23.01          & 0.656          \\
% RDN-E2FIF               & x4                     & 30.92          & 0.872          & 27.81          & 0.761          & 27.06          & 0.718          & 24.77          & 0.738          \\
% RDN-SCALES (ours)       & x4                     & \textbf{31.27} & \textbf{0.879} & \textbf{28.02} & \textbf{0.767} & \textbf{27.18} & \textbf{0.723} & \textbf{25.02} & \textbf{0.749} \\ \hline
% \end{tabular}

% }
% \end{table*}


% \begin{table*}[!tbp]
% \centering
% \caption{Comparison of different methods on RCAN architecture.}
% \label{tab:result_rdn}

% \scalebox{0.9}{

% \begin{tabular}{c|c|cc|cc|cc|cc}
% \hline
% \multirow{2}{*}{Method} & \multirow{2}{*}{Scale} & \multicolumn{2}{c|}{Set5}       & \multicolumn{2}{c|}{Set14}      & \multicolumn{2}{c|}{B100}       & \multicolumn{2}{c}{Urban100}    \\ \cline{3-10} 
%                         &                        & PSNR           & SSIM           & PSNR           & SSIM           & PSNR           & SSIM           & PSNR           & SSIM           \\ \hline
% RCAN-FP                 & x2                     & 38.12          & 0.96           & 33.76          & 0.919          & 32.24          & 0.900          & 32.45          & 0.931          \\
% Bicubic                 & x2                     & 33.66          & 0.930          & 30.24          & 0.869          & 29.56          & 0.843          & 26.88          & 0.840          \\
% RCAN-E2FIF              & x2                     & 37.62          & \textbf{0.958} & 33.14          & \textbf{0.913} & 31.85          & \textbf{0.895} & 31.05          & 0.916          \\
% RCAN-SCALES (ours)      & x2                     & \textbf{37.67} & \textbf{0.958} & \textbf{33.22} & \textbf{0.913} & \textbf{31.91} & \textbf{0.895} & \textbf{31.23} & \textbf{0.918} \\ \hline
% RCAN-FP                 & x3                     & 34.39          & 0.926          & 30.34          & 0.842          & 29.11          & 0.805          & 28.30          & 0.855          \\
% Bicubic                 & x3                     & 30.39          & 0.868          & 27.55          & 0.774          & 27.21          & 0.739          & 24.46          & 0.735          \\
% RCAN-E2FIF              & x3                     & 33.81          & 0.920          & 29.90          & 0.833          & 28.79          & 0.797          & 27.26          & 0.831          \\
% RCAN-SCALES (ours)      & x3                     & \textbf{33.89} & \textbf{0.921} & \textbf{29.95} & \textbf{0.834} & \textbf{28.85} & \textbf{0.798} & \textbf{27.42} & \textbf{0.836} \\ \hline
% RCAN-FP                 & x4                     & 32.37          & 0.895          & 28.72          & 0.785          & 27.64          & 0.738          & 26.39          & 0.795          \\
% Bicubic                 & x4                     & 28.42          & 0.810          & 26.00          & 0.703          & 25.96          & 0.668          & 23.14          & 0.658          \\
% RCAN-E2FIF              & x4                     & 31.54          & 0.883          & 28.16          & 0.770          & 27.28          & 0.726          & 25.30          & 0.759          \\
% RCAN-SCALES (ours)      & x4                     & \textbf{31.65} & \textbf{0.885} & \textbf{28.25} & \textbf{0.772} & \textbf{27.33} & \textbf{0.727} & \textbf{25.44} & \textbf{0.763} \\ \hline
% \end{tabular}

% }
% \end{table*}

We evaluate SCALES on different network architectures on four benchmark datasets across different scales.
Due to page limitation, we only show the results on SRResNet, SwinIR, and HAT at $\times 2$ and $\times 4$ scale. 
For CNN-based SR networks,
as shown in Table~\ref{tab:result_srresnet},
SCALES outperforms the other methods.
It surpasses the prior art method E2FIF~\cite{lang2022e2fif},
by 0.22dB and 0.19dB on Urban100 at $\times2$ and $\times4$ scale, respectively.
For Transformer-based SR networks,
since there is no existing research on binarization,
we build the baseline model leveraging the binarization method 
proposed in BiBERT~\cite{bai2020binarybert}.
We also try the method in BiViT~\cite{he2023bivit},
but find it less effective than BiBERT~\cite{bai2020binarybert},
thus we choose the better one as our baseline.
As shown in Table~\ref{tab:result_swinir_and_hat},
our proposed method SCALES
significantly surpasses the baseline.
For example, on SwinIR,
SCALES achieves 1.39dB improvement over the baseline 
on Set5 at $\times2$ scale.
On HAT,
the improvement with our method is even larger,
i.e., 1.94$\sim$4.31dB across four datasets at $\times4$ scale.
Through our method,
we achieve the first accurate binary SR Transformer.




% Quantitative results are shown in Table 3\textasciitilde6.
% Our method outperforms the previous methods significantly on different network architectures and datasets, which proves the effectiveness and compatibility of our method.
% For instance, on EDSR, our method improves PSNR by 0.26dB, 0.27dB, 0.1dB, and 0.31dB on four datasets, respectively at $\times 4$ scale compared with the state-of-the-art method. 
% Only for EDSR on B100 at $\times 2$ scale, our method is slightly lower than E2FIF.
% For RDN, which has a different architecture from EDSR, our method also performs well.
% For example, compared with RDN-E2FIF, our RDN-SCALES improves PSNR by 0.29dB, 0.19dB, 0.12dB, and 0.33dB on the four benchmark datasets at $\times3$ scale.

Qualitative results are shown in Figure~\ref{fig: visual results}.
We can observe that SCALES can alleviate the blurring artifacts
and reconstruct clearer images.
What's more, SCALES produces more faithful results to the ground truth,
compared to the prior art method E2FIF.
For example, in Fig.~\ref{subfig:visual_result_RCAN}, SCALES has no 
distortion and in Fig~\ref{subfig:visual_result_EDSR}, SCALES generates
the stripes with correct directions
while E2FIF fails to achieve this.
% Regrettably, more visual results cannot be displayed here due to page limitations.
% It is worth noting that although the numerical improvements in PSNR and SSIM may be modest, the visual quality of the images can differ significantly.

% \begin{table*}[h]
% \centering
% \caption{Comparison of different methods on RDN architecture.}
% \label{tab:result_rdn}

% \scalebox{1.0}{

% \begin{tabular}{c|c|cc|cc|cc|cc}
% \hline
% \multirow{2}{*}{Method} & \multirow{2}{*}{Scale} & \multicolumn{2}{c|}{Set5}       & \multicolumn{2}{c|}{Set14}      & \multicolumn{2}{c|}{B100}       & \multicolumn{2}{c}{Urban100}    \\ \cline{3-10} 
%                         &                        & PSNR           & SSIM           & PSNR           & SSIM           & PSNR           & SSIM           & PSNR           & SSIM           \\ \hline
% RDN-FP                  & x2                     & 37.92          & 0.959          & 33.52          & 0.916          & 32.13          & 0.898          & 31.86          & 0.925          \\
% Bicubic                 & x2                     & 33.66          & 0.930          & 30.24          & 0.869          & 29.56          & 0.843          & 26.88          & 0.840          \\
% RDN-BiReal              & x2                     & 31.17          & 0.885          & 28.84          & 0.837          & 28.67          & 0.827          & 26.20          & 0.816          \\
% RDN-E2FIF               & x2                     & 37.20          & 0.956          & 32.77          & 0.909          & 31.60          & 0.891          & 30.19          & 0.906          \\
% RDN-SCALES (ours)       & x2                     & \textbf{37.40} & \textbf{0.957} & \textbf{32.93} & \textbf{0.911} & \textbf{31.72} & \textbf{0.893} & \textbf{30.54} & \textbf{0.911} \\ \hline
% RDN-FP                  & x3                     & 34.34          & 0.925          & 30.29          & 0.84           & 29.05          & 0.803          & 27.99          & 0.849          \\
% Bicubic                 & x3                     & 30.39          & 0.868          & 27.55          & 0.774          & 27.21          & 0.739          & 24.46          & 0.735          \\
% RDN-BiReal              & x3                     & 29.29          & 0.84           & 26.93          & 0.762          & 26.85          & 0.738          & 24.24          & 0.726          \\
% RDN-E2FIF               & x3                     & 33.19          & 0.914          & 29.56          & 0.827          & 28.56          & 0.79           & 26.57          & 0.812          \\
% RDN-SCALES (ours)       & x3                     & \textbf{33.48} & \textbf{0.918} & \textbf{29.75} & \textbf{0.830}  & \textbf{28.68} & \textbf{0.794} & \textbf{26.90} & \textbf{0.823} \\ \hline
% RDN-FP                  & x4                     & 32.09          & 0.892          & 28.56          & 0.78           & 27.54          & 0.735          & 25.96          & 0.782          \\
% Bicubic                 & x4                     & 28.42          & 0.810          & 26.00          & 0.703          & 25.96          & 0.668          & 23.14          & 0.658          \\
% RDN-BiReal              & x4                     & 27.77          & 0.793          & 25.59          & 0.698          & 25.67          & 0.67           & 23.01          & 0.656          \\
% RDN-E2FIF               & x4                     & 30.92          & 0.872          & 27.81          & 0.761          & 27.06          & 0.718          & 24.77          & 0.738          \\
% RDN-SCALES (ours)       & x4                     & \textbf{31.27} & \textbf{0.879} & \textbf{28.02} & \textbf{0.767} & \textbf{27.18} & \textbf{0.723} & \textbf{25.02} & \textbf{0.749} \\ \hline
% \end{tabular}

% }
% \end{table*}


% \begin{table*}[h]
% \centering
% \caption{Comparison of different methods on RCAN architecture.}
% \label{tab:result_rcan}

% \scalebox{1.0}{

% \begin{tabular}{c|c|cc|cc|cc|cc}
% \hline
% \multirow{2}{*}{Method} & \multirow{2}{*}{Scale} & \multicolumn{2}{c|}{Set5}       & \multicolumn{2}{c|}{Set14}      & \multicolumn{2}{c|}{B100}       & \multicolumn{2}{c}{Urban100}    \\ \cline{3-10} 
%                         &                        & PSNR           & SSIM           & PSNR           & SSIM           & PSNR           & SSIM           & PSNR           & SSIM           \\ \hline
% RCAN-FP                 & x2                     & 38.12          & 0.96           & 33.76          & 0.919          & 32.24          & 0.900          & 32.45          & 0.931          \\
% Bicubic                 & x2                     & 33.66          & 0.930          & 30.24          & 0.869          & 29.56          & 0.843          & 26.88          & 0.840          \\
% RCAN-BiReal             & x2                     & 33.37          & 0.923          & 30.26          & 0.873          & 29.82          & 0.858          & 27.22          & 0.852          \\
% RCAN-E2FIF              & x2                     & 37.62          & \textbf{0.958} & 33.14          & \textbf{0.913} & 31.85          & \textbf{0.895} & 31.05          & 0.916          \\
% RCAN-SCALES (ours)      & x2                     & \textbf{37.67} & \textbf{0.958} & \textbf{33.22} & \textbf{0.913} & \textbf{31.91} & \textbf{0.895} & \textbf{31.23} & \textbf{0.918} \\ \hline
% RCAN-FP                 & x3                     & 34.39          & 0.926          & 30.34          & 0.842          & 29.11          & 0.805          & 28.30          & 0.855          \\
% Bicubic                 & x3                     & 30.39          & 0.868          & 27.55          & 0.774          & 27.21          & 0.739          & 24.46          & 0.735          \\
% RCAN-BiReal             & x3                     & 30.32          & 0.865          & 27.63          & 0.784          & 27.32          & 0.755          & 24.65          & 0.748          \\
% RCAN-E2FIF              & x3                     & 33.81          & 0.920          & 29.90          & 0.833          & 28.79          & 0.797          & 27.26          & 0.831          \\
% RCAN-SCALES (ours)      & x3                     & \textbf{33.89} & \textbf{0.921} & \textbf{29.95} & \textbf{0.834} & \textbf{28.85} & \textbf{0.798} & \textbf{27.42} & \textbf{0.836} \\ \hline
% RCAN-FP                 & x4                     & 32.37          & 0.895          & 28.72          & 0.785          & 27.64          & 0.738          & 26.39          & 0.795          \\
% Bicubic                 & x4                     & 28.42          & 0.810          & 26.00          & 0.703          & 25.96          & 0.668          & 23.14          & 0.658          \\
% RCAN-BiReal             & x4                     & 28.47          & 0.810          & 26.06          & 0.709          & 26.01          & 0.679          & 23.36          & 0.672          \\
% RCAN-E2FIF              & x4                     & 31.54          & 0.883          & 28.16          & 0.770          & 27.28          & 0.726          & 25.30          & 0.759          \\
% RCAN-SCALES (ours)      & x4                     & \textbf{31.65} & \textbf{0.885} & \textbf{28.25} & \textbf{0.772} & \textbf{27.33} & \textbf{0.727} & \textbf{25.44} & \textbf{0.763} \\ \hline
% \end{tabular}

% }
% \end{table*}


% \begin{figure}[!tb]%

%   \centering
%     \includegraphics[width=0.5\textwidth]{figs/qualititive.png}
%   \caption{Visual comparison at $\times4$ scale on Set5 dataset.}
%   \label{fig:result}
% \end{figure}


\begin{figure}[!tb]%
  \centering 
  \hspace*{-0.5cm}
  \subfloat[Visual results from Urban100 at $\times 4$ scale on RCAN architecture]{
    \label{subfig:visual_result_RCAN}
    \includegraphics[width=0.45\textwidth]{fig/qual_1.png}
  }
  
  \subfloat[Visual results from Set14 at $\times 2$ scale on EDSR architecture]{
    \label{subfig:visual_result_EDSR}
    \includegraphics[width=0.45\textwidth]{fig/qual_2.png}
  }
  \caption{
  Visual comparison of SCALES and the prior art method.
  }
  \label{fig: visual results}
  \vspace{-5pt}
\end{figure}


% \subsection{Ablation Study}
% \label{subsec: ablation}

% \paragraph{\textbf{Effect of Layer-wise Scaling Factor.}}
% We demonstrate the learnable layer-wise scaling
% factors $\alpha$ of different layers in Fig.~\ref{fig:ablation:alpha}.
% We find that $\alpha$ effectively learns the layer-wise activation distribution in Fig.~\ref{fig:layer}, i.e., in every two layers,
% $\alpha$ has a larger value for the odd layer and 
% a smaller value for the even layer.
% Therefore, $\hat{x}$ in Eq.~\ref{eq:act_binarize} with the magnitude equal to $\alpha$ will have the similar trend 
% as the FP activations across different layers.
% Thus, the layer-to-layer variation is well-captured by
% the layer-wise scaling factor, abbreviated as LSF.
% As shown in Table~\ref{tab:compare_alpha},
% our layer-wise scaling factor significantly improves the 
% PSNR by 0.06dB on Set5 and Urban100 dataset, 
% % which is significant for image SR.


% \begin{figure}[!tb]
%   \centering
%     \includegraphics[width=0.4\textwidth]{figs/alpha.png}
%   \caption{The value of the layer-wise scaling factor $\alpha$
%   across different layers.} 
%   \label{fig:ablation:alpha}
% \end{figure}


% \begin{table}[!tb]
% \centering
% \caption{The effect of using the learnable scaling factor $\alpha$.
% } 
% \label{tab:compare_alpha}
% % \vspace{-5pt}
% \scalebox{0.9}{
% \begin{tabular}{c|cc|cc}
% \hline
% \multirow{2}{*}{Models}       & \multicolumn{2}{c|}{Set5}                               & \multicolumn{2}{c}{Urban100}                           \\ \cline{2-5} 
%                               & PSNR                       & SSIM                       & PSNR                       & SSIM                      \\ \hline

% Binarization w/ $\beta$ & \multicolumn{1}{l}{31.242} & \multicolumn{1}{l|}{0.878} & \multicolumn{1}{l}{25.039} & \multicolumn{1}{l}{0.749} \\ 

% + LSF           & 31.301                     & 0.880                      & 25.093                     & 0.751                     \\
% \hline
% \end{tabular}
% }
% \vspace{-5pt}
% \end{table}


% \paragraph{\textbf{Kernel Size of Conv1d in Channel-wise Re-scaling.}}
% Table~\ref{tab:kernel size} demonstrates the effect of different kernel sizes $k$ of the Conv1d layer in the channel-wise re-scaling module.
% When $k$ is 5, the model achieves the best performance.
% Meanwhile, for different kernel sizes, the total parameters and operations of the four models are nearly the same, 
% since the Conv1d layer introduces negligible parameters and computations.
% % It can be found that we only need to extract information from a few neighboring channels to produce channel-wise scaling factors.
% It can be observed that extracting information from just a few neighboring channels is sufficient to produce the channel-wise scaling factors.
% We choose $k$ to be 5 in our method.


% \begin{table}[!tb]
% \centering
% \caption{PSNR at $\times4$ scale on Set5 of different kernel sizes.}
% \label{tab:kernel size}
% \scalebox{0.9}{
% \begin{tabular}{c|c|c|c|c}
% \hline
%                      & k=3   & k=5   & k=7   & k=9   \\ \hline
% LSF + chl-wise re-scale & 31.37 &31.42 & 31.34 & 31.35 \\ \hline
% \end{tabular}
% }
% \end{table}

\subsection{Ablation Study}
\label{subsec: ablation}
We evaluate the effect of the proposed individual components on SRResNet in 
Table~\ref{tab:ablation}.
First, using layer-wise scaling factor (LSF) already outperforms
the prior art method E2FIF with fewer operations.
The computation cost is reduced because we remove BN in SRResNet-E2FIF.
The proposed channel-wise re-scaling method further improves PSNR by 0.12dB and 0.05dB on Set5 and Urban100, respectively, 
only increasing 4\% operations.
The spatial re-scaling method further achieves 0.18dB and 0.15dB improvement on the two datasets.
The increase in the number of parameters is negligible for all the components.
% with negligible increase in parameters.
% while only increasing the operations by 7\%.
% Combining them,
% SCALES achieve 0.24dB and 0.18dB PSNR improvements on LSF
% while having 0.09G fewer OPs and similar 
% Params compared to E2FIF.

% We conduct the ablation study of the proposed methods on SRResNet architecture in Table~\ref{tab:ablation}.
% The model with our strong binarization function has outperformed the prior art E2FIF with fewer OPs, which is because we remove the BN in SRResNet-E2FIF and use the strong but low-cost binarization function to capture the variations.
% Based on this, the proposed channel-wise re-scaling method further improves PSNR by 0.12dB and 0.05dB on Set5 and Urban100, respectively, only increases OPs by 0.07G, and has a negligible increase in Params.
% Our spatial re-scaling method is also effective. 
% Compared with SB, it has 0.18dB and 0.15dB improvements of PSNR on the two datasets, with only an increase of 0.11G in OPs and a negligible increase in Params.
% Combining the two re-scaling methods, our SRResNet-SCALES improves the PSNR by 0.24dB and 0.18dB on the two datasets respectively based on the strong baseline.
% Compared with the prior art SRResNet-E2FIF, our model SRResNet-SCALES has a more significant improvement in performance with 0.09G fewer OPs and similar Params.


\begin{table}[!tb]
\centering
\caption{The effect of different components in SCALES.
OPs are calculated based on the 128Ã—128 input image.
Note that the result of E2FIF is different from the original paper 
because we train all the model with RGB input instead of YCbCr input.
}
\label{tab:ablation}
\scalebox{0.85}{
\begin{tabular}{c|c|cc|cc}
\hline
\multirow{2}{*}{Method} & \multirow{2}{*}{OPs} & \multicolumn{2}{c|}{Set5} & \multicolumn{2}{c}{Urban100} \\ \cline{3-6}
                             &                                         & PSNR        & SSIM        & PSNR          & SSIM         \\ \hline
SRResNet-E2FIF           & 1.83G                                & 31.27       & 0.880        & 25.07         & 0.748        \\  \hdashline
LSF                    & 1.56G                                  & 31.30       & 0.880       & 25.09         & 0.751        \\
LSF + chl. re-scale & 1.63G                               & 31.42       & 0.880       & 25.14         & 0.753        \\
LSF + spatial re-scale  & 1.67G                                  & 31.48       & 0.882       & 25.24         & 0.756        \\
SCALES             & 1.74G                                & 31.54       & 0.883       & 25.27         & 0.757        \\ \hline
\end{tabular}
}
\end{table}



% \begin{table}[!tb]
% % \hspace*{-0.3cm}
% \centering
% \caption{Memory and computation consumption of our method and 
% the state-of-the-art.
% % Complexity comparison of our methods and the prior art. 
% PSNR is evaluated on Urban100 at $\times4$ scale.}
% \label{tab:model complexity}
% \scalebox{0.75}{
% \begin{tabular}{c|cc|cc|cc|cc}
% \hline
%                 & \multicolumn{2}{c|}{SRResNet} & \multicolumn{2}{c|}{EDSR} & \multicolumn{2}{c|}{RDN} & \multicolumn{2}{c}{RCAN} \\ \cline{2-9} 
%                 & E2FIF         & SCALES        & E2FIF       & SCALES      & E2FIF      & SCALES      & E2FIF      & SCALES      \\ \hline
% OPs             & 1.83G         & 1.74G         & 25.32G      & 24.27G      & 1.50G      & 1.68G       & 4.06G      & 3.59G       \\
% Params          & 0.03M         & 0.03M         & 0.17M       & 0.15M       & 0.02M      & 0.02M       & 0.07M      & 0.06M       \\
% PSNR & 25.08         & 25.27         & 25.74       & 26.05       & 24.77      & 25.02       & 25.30      & 25.44       \\ \hline
% \end{tabular}
% }
% \end{table}




% \subsubsection{Effect of Kernel Size in Channel-wise Re-scaling}

% \begin{figure}[!tb]%
%   \hspace*{-0.3cm}
%   \centering
%     \includegraphics[width=0.5\textwidth]{AnonymousSubmission/LaTeX/fig/line.png}
%   \caption{PSNR at $\times4$ scale on Set5 of different kernel sizes. 
%   We use SRResNet architecture only with the channel-wise re-scaling module.}
%   \label{fig:kernel size}
% \end{figure}



% \subsection{Effect of Different Methods}



\subsection{Deployment Efficiency}
We compare the memory and computation cost in Table~\ref{tab:result_srresnet} and~\ref{tab:result_swinir_and_hat}.
The number of parameters and operations
are calculated following~\cite{zhou2016dorefa,liu2018bi}:
$OPs=OPs^f + OPs^b/64, Param=Param^f+Param^b/32$.
We evaluate $OPs$ on a $1280\times720$ HR image.
In Table~\ref{tab:result_srresnet},
SCALES has the smallest number of parameters and operations.
Compared with the prior art method E2FIF,
SCALES has better performance with 1K parameters and 0.3G operations reduction
due to the removal of BN.
In Table~\ref{tab:result_swinir_and_hat},
SCALES has approximately $10\times$ and $20\times$ parameter reduction compared to SwinIR-FP and HAT-FP, respectively.
Compared to the baseline, SCALES only introduces negligible parameters
while having significantly better performance.


% We evaluate the deployment efficiency of SCALES
% in terms of memory consumption, 
% computation cost,
% and the practical inference.
% As shown in Table~\ref{tab:model complexity},
% our SCALES has constantly fewer OPs and Params
% across different network architectures.
% Except on RDN, SCALES has slightly more OPs than E2FIF. 
% This is because, in RDN, the number of input channels of convolution layers in the residual dense block is the multiple of the output channel.
% while BN in E2FIF is computed on the output features of convolution layers.
% And our spatial re-scaling module computes on the input features, which have more channels.
% Thus the benefit of removing BN decreases.

\begin{table}[!tbp]
\centering
\caption{Inference latency on mobile phone.}
\label{tab:latency}
% \vspace{-5pt}
\scalebox{0.8}{
\begin{tabular}{c|ccc|cc|cc}
\hline
\multirow{2}{*}{SRResNet}            & \multirow{2}{*}{OPs} & \multirow{2}{*}{Params} & \multicolumn{1}{l|}{\multirow{2}{*}{Latency}} & \multicolumn{2}{c|}{Set14}                             & \multicolumn{2}{c}{B100}                              \\ \cline{5-8} 
                                     &                      &                         & \multicolumn{1}{l|}{}                         & PSNR                      & SSIM                       & PSNR                      & SSIM                      \\ \hline
FP SRResNet                                 & 64.98G               & 1.52M                   & 1649 ms                                        & 28.25                     & 0.773                      & 27.38                     & 0.727                     \\
E2FIF                                & 1.83G                & 0.03M                   & 197 ms                                          & 27.93                     & 0.766                      & 27.20                     & 0.723                     \\
\multicolumn{1}{l|}{SCALES (chl=64)} & 1.74G                & 0.03M                   & 237 ms                                           & \multicolumn{1}{l}{28.15} & \multicolumn{1}{l|}{0.770} & \multicolumn{1}{l}{27.28} & \multicolumn{1}{l}{0.726} \\
\multicolumn{1}{l|}{SCALES (chl=40)} & 0.83G                & 0.02M                   & 166 ms                                          & \multicolumn{1}{l}{28.02} & \multicolumn{1}{l|}{0.767} & \multicolumn{1}{l}{27.18} & \multicolumn{1}{l}{0.722} \\ \hline
\end{tabular}
}
\vspace{-10pt}
\end{table}

% To measure the complexity of the models, we use OPs and Params as the metrics.
% We compare our method with E2FIF, which is better and more lightweight than other methods \cite{lang2022e2fif}. 
% As shown in Table~\ref{tab:model complexity}, our SCALES has fewer or similar OPs and Params across four network architectures because we use lightweight modules and remove BN layers. 
% It is noticeable that on RDN, SCALES has slightly more OPs than E2FIF. 
% This is because, in RDN, the number of input channels of convolution layers in the residual dense block is the multiple of the output channel.
% BN in E2FIF is computed on the output features of convolution layers.
% And our spatial re-scaling module computes on the input features, which have more channels.
% Thus the benefit of removing BN decreases.


We also benchmark the latency of our method on 
Redmi K40S phone with a Qualcomm Snapdragon 870 SoC using Larq,
an open-source library for deploying BNNs.
We report the average latency of 100 times inference
using a single thread.
As shown in Table~\ref{tab:latency},
with our proposed SCALES (with the number of channels equal to 40),
we  can achieve $9.9\times$ speedup compared to the FP counterpart,
and $1.2\times$ speedup compared to the prior art method E2FIF with on-par performance.

