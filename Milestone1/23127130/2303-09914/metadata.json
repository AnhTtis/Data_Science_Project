{
    "arxiv_id": "2303.09914",
    "paper_title": "Rehearsal-Free Domain Continual Face Anti-Spoofing: Generalize More and Forget Less",
    "authors": [
        "Rizhao Cai",
        "Yawen Cui",
        "Zhi Li",
        "Zitong Yu",
        "Haoliang Li",
        "Yongjian Hu",
        "Alex Kot"
    ],
    "submission_date": "2023-03-16",
    "revised_dates": [
        "2023-03-20"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "Face Anti-Spoofing (FAS) is recently studied under the continual learning setting, where the FAS models are expected to evolve after encountering the data from new domains. However, existing methods need extra replay buffers to store previous data for rehearsal, which becomes infeasible when previous data is unavailable because of privacy issues. In this paper, we propose the first rehearsal-free method for Domain Continual Learning (DCL) of FAS, which deals with catastrophic forgetting and unseen domain generalization problems simultaneously. For better generalization to unseen domains, we design the Dynamic Central Difference Convolutional Adapter (DCDCA) to adapt Vision Transformer (ViT) models during the continual learning sessions. To alleviate the forgetting of previous domains without using previous data, we propose the Proxy Prototype Contrastive Regularization (PPCR) to constrain the continual learning with previous domain knowledge from the proxy prototypes. Simulate practical DCL scenarios, we devise two new protocols which evaluate both generalization and anti-forgetting performance. Extensive experimental results show that our proposed method can improve the generalization performance in unseen domains and alleviate the catastrophic forgetting of the previous knowledge. The codes and protocols will be released soon.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.09914v1"
    ],
    "publication_venue": null
}