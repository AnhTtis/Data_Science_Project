{
    "arxiv_id": "2303.13552",
    "paper_title": "Context, Utility and Influence of an Explanation",
    "authors": [
        "Minal Suresh Patil",
        "Kary Fr√§mling"
    ],
    "submission_date": "2023-03-22",
    "revised_dates": [
        "2023-03-27"
    ],
    "latest_version": 1,
    "categories": [
        "cs.HC",
        "cs.AI"
    ],
    "abstract": "Contextual utility theory integrates context-sensitive factors into utility-based decision-making models. It stresses the importance of understanding individual decision-makers' preferences, values, and beliefs and the situational factors that affect them. Contextual utility theory benefits explainable AI. First, it can improve transparency and understanding of how AI systems affect decision-making. It can reveal AI model biases and limitations by considering personal preferences and context. Second, contextual utility theory can make AI systems more personalized and adaptable to users and stakeholders. AI systems can better meet user needs and values by incorporating demographic and cultural data. Finally, contextual utility theory promotes ethical AI development and social responsibility. AI developers can create ethical systems that benefit society by considering contextual factors like societal norms and values. This work, demonstrates how contextual utility theory can improve AI system transparency, personalization, and ethics, benefiting both users and developers.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.13552v1"
    ],
    "publication_venue": "6 pages"
}