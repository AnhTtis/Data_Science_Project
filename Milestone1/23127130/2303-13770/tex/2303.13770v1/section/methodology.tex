\begin{figure*}
    \centering
    \includegraphics[width=0.85\linewidth]{figures/fig1_methodology.pdf}
    \caption{The overview of our research methodology}
    \label{fig:met}
\end{figure*}

As shown in Fig.~\ref{fig:met}, our research methodology contains five main steps: 1) \emph{Smart Contract Collection}, which collects smart contracts from Etherscan; 2) \emph{Reentrancy Detection}, which detects reentrancy issues from the contracts using five selected tools; 3) \emph{Manual Examination}, which manually examines whether the detected reentrant contracts are correct (i.e., true positive) or not (i.e., false positive); 4) \emph{Cause Analysis}, which analyzes the causes of the true and false positive contracts; and 5) \emph{Tool Evaluation}, which evaluates the tools based on the manually examined and analyzed results from the contracts.

\subsection{Smart Contract Collection}\label{sc_col}

We collect 230,548 smart contracts with verified Solidity code, ABI, and bytecode from Etherscan on October 13, 2021. Through preliminary analysis, there are a considerable number of duplicate contracts with the same bytecode. To reduce the workload of the subsequent steps of our study, we filter out the duplicates. Consequently, we obtain 139,424 contracts without duplication. Table~\ref{tab: collected-dataset} summarizes the information of the contracts, including their average lines of code (LOC) and the distribution of their versions of Solidity compilers.

\begin{table}[t]
    \centering
        \caption{Summaries of our smart contract dataset.}
        \resizebox{0.85\linewidth}{!}{
        \begin{tabular}{l|c}
            \hline
            \textbf{Information} & \textbf{Number} \\
            \hline
            \#Contracts & 230,548\\
            \#Deduplicated contracts & 139,424 \\
            \hline
            \#Contracts with compiler version \textless 0.5 & 68,196 \\
            \#Contracts with compiler version 0.5+ & 23,461 \\
            \#Contracts with compiler version 0.6+ & 24,761 \\
            \#Contracts with compiler version 0.7+ & 8,292 \\
            \#Contracts with compiler version 0.8+ & 14,714 \\
            \hline
            Average LOC in Deduplicated Contracts & 720.42 \\
            \hline
        \end{tabular}}
        \label{tab: collected-dataset}
\end{table}
    
\subsection{Reentrancy Detection}

\subsubsection{Tool Selection}\label{tool_sel}
To conduct our study, we need to select some representative tools that can detect reentrancy issues from contracts. In the empirical study conducted by Durieux et al.~\cite{durieux2020empirical}, they summarize a list of 35 vulnerability detection tools for smart contracts. We extend their list by searching for other state-of-the-art tools published in the literature or on the internet after that work, e.g., Smartian~\cite{choi2021smartian}, Sailfish~\cite{bose2022sailfish}, etc. However, not all of the tools are appropriate for our study, e.g., those that cannot detect reentrancy or cannot be applied to Solidity code. To select appropriate tools for this study, we define several criteria as follows. 

\begin{itemize}
    \item \textbf{Available and scalable}. The tool is publicly available and can be easily applied to a large set of contracts. In particular, the tool should support a command-line interface that is convenient for performing large-scale experiments.
    \item \textbf{Supports multiple versions of Solidity}. The tool can detect the contracts in our dataset that are written in multiple versions of Solidity.
    \item \textbf{Requires Solidity code only}. The tool only requires the Solidity code and its derivatives (e.g., ABI and Bytecode) as input without any other specification (e.g., a test suite annotated with assertions).
    \item \textbf{Ability to locate vulnerabilities}. The tool can locate the defective functions with reentrancy issues in a contract, which is important for practical use and can facilitate the manual examination task in this study.
\end{itemize}

Using the criteria above, we select five representative reentrancy detection tools from both industry and academia, as listed in Table~\ref{tab: tool-docker}. Within industry, we select Mythril since it has demonstrated its performance in~\cite{durieux2020empirical}. Within academia, we select Oyente, Securify, Smartian, and Sailfish from the top conferences of software engineering or security. The selected tools use various techniques, e.g., symbolic execution, formal verification, and fuzzing, which are briefly described below:
    
\textbf{Oyente}~\cite{luu2016making} is one of the first smart contract analysis tools based on symbolic execution. It constructs the control flow graph of a contract and symbolically executes the contract to detect vulnerabilities by exploring as many execution paths as possible. Oyente serves as the basis of several other vulnerability detection tools such as Maian~\cite{nikolic2018finding} and Osiris~\cite{torres2018osiris}.
    
\textbf{Mythril}~\cite{mueller2018smashing} is also a vulnerability detection tool based on symbolic execution, which combines taint analysis and control flow checking for more accurate detection. Particularly, Mythril has been packaged as a commercial product by Consensys~\cite{Consensys}.

\textbf{Securify}~\cite{tsankov2018securify} is a vulnerability detection tool based on formal verification. It symbolically analyzes the dependency graph of a contract and checks compliance/violation patterns that capture sufficient conditions for proving whether a property holds or not. Note that there are two versions of Securify, namely Securify(V1) and Securify(V2). We use both of them because they support different versions of Solidity.
    
\textbf{Smartian}~\cite{choi2021smartian} is a fuzzer that combines static analysis and dynamic analysis to detect vulnerabilities from contracts. It statically analyzes a contract to predict the transaction sequences that can lead to effective testing, and then uses such information to construct the initial seed corpus. During fuzzing, Smartian performs a lightweight dynamic data-flow analysis to effectively guide fuzzing.

\textbf{Sailfish}~\cite{bose2022sailfish} is a scalable system for automatically finding state inconsistency bugs in smart contracts. In order to make the analysis tractable, Sailfish contains two phases: a lightweight exploration phase for reducing the number of instructions to analyze, and a refinement phase for generating extra constraints to approximate the side effects of whole-program execution and ensure the precision of the symbolic evaluation. Using these phases, Sailfish can efficiently detect state inconsistencies in smart contracts.
    
\subsection{Experiment Setup}
We use the selected tools to analyze smart contracts using Docker images, as listed in Table~\ref{tab: tool-docker}. We use two methods to obtain the Docker images. For Oyente, Mythril, Securify(V1), and Sailfish, we directly download their images from Dockerhub~\cite{Dockerhub}. For Securify(V2) and Smartian, there are no images on Dockerhub, and so we build up their images according to the Dockerfiles\footnote{A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image.} in their GitHub repositories. We notice that Securify(V1) has multiple Docker images on Dockerhub, and different images can support the analysis of contracts with different versions of Solidity. We use multiple Docker images to increase the analysis range of the contracts.

We directly use Oyente, Mythril, Securify and Sailfish on the Solidity code of each contract. Smartian takes the bytecode and ABI of a contract as input, which are also collected from Etherscan. Referring to the time budget set in~\cite{durieux2020empirical}, we set an appropriate time budget, i.e., two minutes, for the five selected tools per contract. If the time budget is up, the tool stops the analysis and exports the analysis result.

Notice that some of the five selected tools do not report the detected reentrancy issues as reentrancy. For example, Mythril reports two kinds of vulnerabilities related to reentrancy, namely \emph{External Call To User-Supplied Address} and \emph{State access after external call}. We determine the reentrancy related vulnerabilities reported by the tools based on several kinds of original materials, including the papers, homepages, implementation code, and output of the tools, which are provided in our repository~\cite{EData}. For instance, the ``DAO'' reported by Securify is selected as a reentrancy related vulnerability as the comments in the implementation code indicate that ``DAO'' represents reentrancy. Table~\ref{tab: tool-docker} lists the vulnerabilities related to reentrancy.

\begin{table*}[t]
    \centering
        \caption{Five representative reentrancy detection tools used in our study}
        \resizebox{0.9\linewidth}{!}{
            \begin{tabular}{l|l|l|l|l}
                \hline
                \textbf{Tool} & \textbf{Technique} & \textbf{GitHub Repository URL} & \textbf{Docker} & \textbf{Reentrancy Patterns} \\ \hline
                Oyente & \begin{tabular}[c]{@{}l@{}}Symbolic \\ execution\end{tabular} & https://github.com/enzymefinance/oyente & qspprotocol/oyente-0.4.25 & Re-Entrancy Vulnerability \\ 
                \hline
                Mythril & \begin{tabular}[c]{@{}l@{}}Symbolic \\ execution\end{tabular} & https://github.com/ConsenSys/mythri & mythril/myth & \begin{tabular}[c]{@{}l@{}}External Call To User-Supplied Address\\ State access after external call\end{tabular} \\ 
                \hline
                \multirow{2}{*}{Securify} & \multirow{2}{*}{\begin{tabular}[c]{@{}l@{}}Formal\\ verification\end{tabular}} & V1: https://github.com/eth-sri/securify & \begin{tabular}[c]{@{}l@{}}qspprotocol/securify-0.4.25\\ qspprotocol/securify-usolc\end{tabular} & \begin{tabular}[c]{@{}l@{}}DAO \\ DAOConstantGas\end{tabular} \\ \cline{3-5} & & V2: https://github.com/eth-sri/securify2 & Dockerfile & \begin{tabular}[c]{@{}l@{}}Benign Reentrancy\\ Reentrancy with constant gas\\ Gas-dependent Reentrancy\\ No-Ether-Involved Reentrancy\end{tabular} \\ 
                \hline
                Sailfish & \begin{tabular}[c]{@{}l@{}}Formal \\ verification\end{tabular} & https://github.com/ucsb-seclab/sailfish & holmessherlock/sailfish:latest & DAO \\ 
                \hline
                Smartian & Fuzzing & https://github.com/SoftSec-KAIST/Smartian & Dockerfile & Reentrancy \\ 
                \hline
                \end{tabular}
        }
        \label{tab: tool-docker}
\end{table*}

\subsection{Manual Examination}\label{subsec:man_exam}
In order to perform a deep analysis of the tools used in this study, we need to examine whether the detected reentrant contracts are correct. Recall that our selected tools can locate the defective functions in a contract, which can facilitate the examination task. In total, there are 31,720 defective functions detected from 21,212 contracts. Manually examining such a large number of functions is a heavy workload.

\subsubsection{Participant Recruitment}\label{par_rec}
To reduce the workload of the manual examination task, we need to recruit a relatively large number of participants and let each participant examine only a subset of contracts. Given a defective function of a contract, in order to judge whether the function has a reentrancy issue, the participants should be equipped with knowledge about Solidity and the reentrancy mechanism. It is not an easy job to recruit sufficient participants and ensure that they meet the requirements. In the lead co-author's affiliation, there are more than one hundred undergraduates and masters who could be potential participants. However, not all of the students are familiar with Solidity and reentrancy. Fortunately, in the first co-author's research group, there are a number of PhD students concentrated on research on the vulnerability detection of smart contracts, with 2-5 years of experience. The PhDs have good knowledge of Solidity and reentrancy. With the help of two experienced PhDs, we adopt a four-stage process to recruit participants from the undergraduates and masters as follows.

\begin{itemize}
    \item \textbf{Invitation.} We send an invitation email to 70 undergraduates and 25 masters. In the email, we introduce our study and the manual examination task, and also ask the students whether they are willing to participate in the task. One week later, we receive positive feedback from 36 undergraduates and 23 masters.
    \item \textbf{Training}. We launch several online conferences with the 59 students and invite two PhDs with experience in smart contracts to introduce Solidity and the reentrancy mechanism with examples. Both PhDs also introduce two true positive reentrancy patterns and five false positive reentrancy patterns that they have either discovered from prior studies (e.g.,~\cite{xue2020cross}) or by themselves.
    \item \textbf{Self-learning.} After the training stage, we ask the students to further learn Solidity and reentrancy for two weeks by themselves using some suggested materials (e.g., the official Solidity documentation and online tutorials on reentrancy) or web search. We encourage the students to develop, deploy, and execute a contract with reentrancy using Remix.
    \item \textbf{Testing.} After the self-learning stage, we conduct a test to see whether the students have gained enough knowledge of Solidity and reentrancy to perform the examination task. We collect 15 contracts, of which five contracts have reentrancy issues. We use our selected tools on the contracts. The possibly defective functions with reentrancy in the five contracts are detected by at least one of the tools. We develop a website to facilitate the examination task for the students. The website randomly presents each contract in a set with the corresponding list of defective functions detected from the contract. We ask the students to examine the defective functions of a contract one by one and annotate a function that has a reentrancy issue with a specific string ``$\langle$yes$\rangle$ Reentrancy''. After the test is completed, we evaluate the accuracy of each student's annotations. A total of 27 undergraduates and 21 masters achieve an accuracy of 100\%, and they are chosen as participants for the manual examination task.
\end{itemize}

\subsubsection{First Round of Manual Examination}\label{subsec:man_exam1}
We randomly divide the 48 participants into 24 groups. Each group contains two participants. We also randomly divide the 21,212 reentrant contracts detected by the tools into 24 subsets. 23 subsets contain 884 contracts, and one subset contains 880 contracts. Each subset is allocated to a participant group. The participants do not know which group they belong to. The aforementioned website is used to facilitate the manual examination task. The website randomly displays each contract in the subset allocated to a participant, along with a list of defective functions detected from the contract. When the participants click a defective function, the website can quickly skip to the function in the contract. We ask the participants to examine the defective functions one-by-one and annotate a function that has a reentrancy issue with a specific string ``$\langle$yes$\rangle$ Reentrancy''.

Once the manual examination task is completed, we obtain three sets of contracts: 1) $commPs$: the set of contracts that have at least one function annotated by both participants in a group; 2) $commNs$: the set of contracts that have no function annotated by both participants in a group; and 3) $Diffs$: the set of contracts with different annotations given by both participants in a group (i.e., one participant annotates at least one function while the other participant does not annotate any function). There are 97, 20,626, and 489 contracts contained in $commPs$, $commNs$, and $Diffs$, respectively.

\subsubsection{Review of the Manual Examination Results}
Considering that the participants may not be proficient in smart contracts, we ask the two experienced PhDs involved in the training process to review the participants' examination results. We randomly sample 377 contracts from $commNs$, which is a statistically significant sample size considering a confidence level of 95\% and a confidence interval of 5\%. Since there is no annotation added to the contracts in $commNs$, both PhDs need to examine the defective functions of the contracts by themselves. They independently examine each of the contracts. After the examination process, both PhDs do not annotate any function of the contracts, meaning that the participants' judgements on the contracts are all correct. This result probably thanks to the introduction of false positive patterns of reentrancy during the training process. Next, we ask both PhDs to review the participants' annotations of the 97 contracts in $commPs$. They perform the review independently. If the annotations of a contract are correct, they label the contract as 1; otherwise 0. Consequently, there are 83 contracts labeled as 0 by both PhDs, indicating that the participants fail to accurately identify reentrancy issues from the contracts. Based on the two groups of results, we are confident in the annotations of contracts in $commNs$, while we lack confidence in the annotations of contracts in $commPs$ and the contracts with disagreement in $Diffs$. 

Although the reentrancy issues identified by the participants are not reliable, the participants accurately identify a large number of false positive contracts without reentrancy, which greatly reduces the number of contracts that need to be subsequently examined by the experienced PhDs.

\begin{table*}[t]
	\centering
	\caption{The analysis results of five vulnerability detection tools. }
	\resizebox{\linewidth}{!}{
		\renewcommand{\arraystretch}{1.3}
		\begin{tabular}{cc|cc|cc|cc|cc|cc|cc|cc}
			\hline
			& & \multicolumn{2}{c}{\textbf{Oyente}}  & \multicolumn{2}{c}{\textbf{Mythril}} & \multicolumn{2}{c}{\textbf{Securify (V1)}} & \multicolumn{2}{c}{\textbf{Securify (V2)} } & \multicolumn{2}{c}{\textbf{Smartian} } & \multicolumn{2}{c}{\textbf{Sailfish} } & \multicolumn{2}{c}{\textbf{Total} } \\
			\textbf{Version} & \textbf{Num.} & \textbf{RE} & \textbf{Analyzed} & \textbf{RE} & \textbf{Analyzed} & \textbf{RE} & \textbf{Analyzed} & \textbf{RE} & \textbf{Analyzed} & \textbf{RE} & \textbf{Analyzed} & \textbf{RE} & \textbf{Analyzed} & \textbf{RE} & \textbf{Analyzed} \\
			\hline
            \textless 0.5 & 68,196 & 513 & 56,289 & 11,962 & 40,006 & 2,324 & 48,715 & 0 & 37 & 15 & 59,511 & 1,403 & 43,541 & 14,967 & 66,170 \\ 
            0.5+ & 23,461 & 0 & 576 & 1,877 & 15,954 & 63 & 13,761 & 1,693 & 15,726 & 3 & 18,075 & 641 & 17,401 & 3,805 & 22,350 \\ 
            0.6+ & 24,761 & 0 & 54 & 1,263 & 14,988 & 0 & 127 & 797 & 4,497 & 2 & 15,356 & 244 & 4,789 & 2,040 & 20,470 \\ 
            0.7+ & 8,292 & 0 & 7 & 273 & 3,363 & 0 & 7 & 2 & 71 & 2 & 4,155 & 1 & 61 & 275 & 5,542 \\ 
            0.8+ & 14,714 & 0 & 13 & 125 & 7,035 & 0 & 29 & 0 & 44 & 0 & 3,148 & 0 & 14 & 125 & 8,683 \\ 
			\hline
			\textbf{Total} & 139,424 & 513 & 56,939 & 15,500 & 81,346 & 2,387 & 62,639 & 2,492 & 20,375 & 22 & 100,245 & 2,289 & 65,806 & 21,212 & 123,215 \\
			\hline
		\end{tabular}
	}
	\label{tab: output-of-tools}
\end{table*}

\subsubsection{Second Round of Manual Examination}
According to the review results above, we ask the two experienced PhDs to re-examine the 586 (97+489) contracts in $commPs$ and $Diffs$ using a card sorting approach~\cite{CardSorting}. Both PhDs first independently examine and annotate the defective functions of each contract, similar to the examination task described in Section~\ref{subsec:man_exam1}. After the examination process, there are 15 contracts with different annotations. By discussing the disagreements together, both PhDs reach a consensus. Finally, we obtain a set of 34 true positive contracts with reentrancy, denoted as $TPs$, and a set of 21,178 (20,626+586-34) false positive contracts without reentrancy, denoted as $FPs$.

\subsection{Cause Analysis}\label{cause_ana}
To better understand the true and false positive contracts, we further ask the two PhDs to analyze the causes of the contracts. To reduce the workload, we randomly sample 377 contracts from $FPs$, which is a statistically significant sample size considering a confidence level of 95\% and a confidence interval of 5\%. However, it is difficult to include any of the 15 false positives reported by Smartian in the sample as those false positives only occupy a tiny part of the entire set of 21,178 false positives. Therefore, we directly include the 15 false positives reported by Smartian in the scope of cause analysis. In total, we analyze the causes of 392 (377+15) false positives. Since we do not have a predefined set of all possible causes, we ask both PhDs to perform cause analysis using two substeps. One PhD first analyzes the cause of the 426 (392+34) contracts and records the cause using a short description. The other PhD then reviews the recorded causes. In cases of disagreement, both PhDs discuss the cause to reach a common decision. From the analysis results, the 34 true positive contracts are all related to the \emph{call.value()} function, while there are eight types of causes that lead to the 392 false positive contracts (see Table~\ref{tab:falsePositiveTools}).

\subsection{Tool Evaluation}
Using the two sets of true and false positive contracts with different causes, we evaluate the five tools used in this study. In spite of the overall performance in terms of precision (see Table~\ref{tab:precision}), we perform a deep analysis by counting the numbers of true and false positive contracts detected by the tools, with respect to each cause type, as listed in Table~\ref{tab:falsePositiveTools}.
