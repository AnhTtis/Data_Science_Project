{
    "arxiv_id": "2303.12799",
    "paper_title": "Time Series as Images: Vision Transformer for Irregularly Sampled Time Series",
    "authors": [
        "Zekun Li",
        "Shiyang Li",
        "Xifeng Yan"
    ],
    "submission_date": "2023-03-01",
    "revised_dates": [
        "2023-03-24"
    ],
    "latest_version": 1,
    "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
    ],
    "abstract": "Irregularly sampled time series are becoming increasingly prevalent in various domains, especially in medical applications. Although different highly-customized methods have been proposed to tackle irregularity, how to effectively model their complicated dynamics and high sparsity is still an open problem. This paper studies the problem from a whole new perspective: transforming irregularly sampled time series into line graph images and adapting powerful vision transformers to perform time series classification in the same way as image classification. Our approach largely simplifies algorithm designs without assuming prior knowledge and can be potentially extended as a general-purpose framework. Despite its simplicity, we show that it substantially outperforms state-of-the-art specialized algorithms on several popular healthcare and human activity datasets. Especially in the challenging leave-sensors-out setting where a subset of variables is masked during testing, the performance improvement is up to 54.0\\% in absolute F1 score points. Our code and data are available at \\url{https://github.com/Leezekun/ViTST}.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.12799v1"
    ],
    "publication_venue": null
}