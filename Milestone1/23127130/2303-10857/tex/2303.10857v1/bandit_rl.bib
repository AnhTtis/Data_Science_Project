@inproceedings{Silver2014,
    title = {{Deterministic policy gradient algorithms}},
    year = {2014},
    booktitle = {31st International Conference on Machine Learning, ICML 2014},
    author = {Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
    pages = {605--619},
    volume = {1},
    isbn = {9781634393973}
}

@article{Kingma2015Adam:Optimization,
    title = {{Adam: A method for stochastic optimization}},
    year = {2015},
    journal = {3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings},
    author = {Kingma, Diederik P. and Ba, Jimmy Lei},
    pages = {1--15},
    arxivId = {1412.6980}
}

@article{Yang2020AnPerspective,
    title = {{An Overview of Multi-Agent Reinforcement Learning from Game Theoretical Perspective}},
    year = {2020},
    author = {Yang, Yaodong and Wang, Jun},
    pages = {1--129},
    url = {http://arxiv.org/abs/2011.00583},
    arxivId = {2011.00583}
}

@article{Lai1985AsymptoticallyRules,
    title = {{Asymptotically efficient adaptive allocation rules}},
    year = {1985},
    journal = {Advances in Applied Mathematics},
    author = {Lai, T L and Robbins, H},
    number = {1},
    pages = {4--22},
    volume = {6},
    doi = {10.1016/0196-8858(85)90002-8}
}

@book{Lattimore2020BanditAlgorithms,
    title = {{Bandit Algorithms}},
    year = {2020},
    booktitle = {Bandit Algorithms},
    author = {Lattimore, Tor and Szepesv{\'{a}}ri, Csaba},
    publisher = {Cambridge University Press},
    isbn = {9781108571401},
    doi = {10.1017/9781108571401}
}

@inproceedings{Auer2007ImprovedProblem,
    title = {{Improved Rates for the Stochastic Continuum-Armed Bandit Problem}},
    year = {2007},
    booktitle = {Learning Theory},
    author = {Auer, Peter and Ortner, Ronald and Szepesv{\'{a}}ri, Csaba},
    editor = {Bshouty, Nader H and Gentile, Claudio},
    pages = {454--468},
    publisher = {Springer Berlin Heidelberg},
    address = {Berlin, Heidelberg},
    isbn = {978-3-540-72927-3}
}

@inproceedings{Kleinberg2005NearlyProblem,
    title = {{Nearly tight bounds for the continuum-armed bandit problem}},
    year = {2005},
    booktitle = {Advances in Neural Information Processing Systems},
    author = {Kleinberg, Robert},
    isbn = {0262195348},
    issn = {10495258}
}

@article{Mazumdar2019OnGames,
    title = {{On Finding Local Nash Equilibria (and Only Local Nash Equilibria) in Zero-Sum Games}},
    year = {2019},
    author = {Mazumdar, Eric V. and Jordan, Michael I. and Sastry, S. Shankar},
    pages = {1--25},
    arxivId = {1901.00838}
}

@article{Barto1985Pattern-recognizingAutomata,
    title = {{Pattern-recognizing stochastic learning automata}},
    year = {1985},
    journal = {IEEE Transactions on Systems, Man, and Cybernetics},
    author = {Barto, Andrew G and Anandan, P},
    number = {3},
    pages = {360--375},
    volume = {SMC-15},
    doi = {10.1109/TSMC.1985.6313371}
}

@article{Mnih2013PlayingLearning,
    title = {{Playing Atari with Deep Reinforcement Learning}},
    year = {2013},
    journal = {arXiv e-prints},
    author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
    month = {12},
    pages = {arXiv:1312.5602},
    arxivId = {cs.LG/1312.5602},
    keywords = {Computer Science - Machine Learning}
}

@techreport{Lin1993ReinforcementNetworks,
    title = {{Reinforcement Learning for Robots Using Neural Networks}},
    year = {1993},
    booktitle = {DTIC Document},
    author = {Lin, Long-ji}
}

@book{Charpentier2021ReinforcementFinance,
    title = {{Reinforcement Learning in Economics and Finance}},
    year = {2021},
    booktitle = {Computational Economics},
    author = {Charpentier, Arthur and {\'{E}}lie, Romuald and Remlinger, Carl},
    volume = {4},
    isbn = {0123456789},
    doi = {10.1007/s10614-021-10119-4},
    issn = {15729974},
    arxivId = {2003.10014},
    keywords = {Causality, Control, Machine learning, Markov decision process, Multi-armed bandits, Online-learning, Q-learning, Regret, Reinforcement learning, Rewards, Sequential learning}
}

@book{Sutton2018ReinforcementIntroduction,
    title = {{Reinforcement learning, Second Edition: An Introduction}},
    year = {2018},
    author = {Sutton, Richard S and Barto, Andrew G},
    edition = {Second},
    publisher = {MIT press},
    isbn = {0262352702}
}

@article{Williams1992SimpleLearning,
    title = {{Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning}},
    year = {1992},
    journal = {Machine Learning},
    author = {Williams, Ronald J},
    number = {3–4},
    month = {5},
    pages = {229–256},
    volume = {8},
    publisher = {Kluwer Academic Publishers},
    address = {USA},
    doi = {10.1007/BF00992696},
    issn = {0885-6125},
    keywords = {Reinforcement learning, connectionist networks, gradient descent, mathematical analysis}
}

@article{Agrawal1995TheProblem,
    title = {{The continuum-armed bandit problem}},
    year = {1995},
    journal = {SIAM journal on control and optimization},
    author = {Agrawal, Rajeev},
    number = {6},
    pages = {1926--1951},
    volume = {33},
    publisher = {SIAM}
}

@article{Greensmith2004VarianceLearning,
    title = {{Variance reduction techniques for gradient estimates in reinforcement learning}},
    year = {2004},
    journal = {Journal of Machine Learning Research},
    author = {Greensmith, Evan and Bartlett, Peter L. and Baxter, Jonathan},
    pages = {1471--1530},
    volume = {5},
    issn = {15337928},
    keywords = {Actor-critic, Baseline, GPOMDP, Policy gradient, Reinforcement learning}
}