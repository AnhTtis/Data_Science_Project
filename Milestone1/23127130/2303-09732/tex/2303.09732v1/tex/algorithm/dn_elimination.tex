 \begin{algorithm}[h]
 \caption{A possible dummy neuron elimination algorithm.}
 \label{alg:dn_elim}
  {\fontsize{10}{10}\selectfont
 \begin{algorithmic}[1]
 \renewcommand{\algorithmicrequire}{\textbf{Input:}}
 \REQUIRE $W$ (the parameters of the suspect model), $H$ (the number of layers in the suspect model).
 \renewcommand{\algorithmicensure}{\textbf{Output:}}
 \ENSURE $W$, the parameters of the suspect model after dummy neuron elimination.
%  \ENSURE $P = P_w \cup P_b \cup P_s$ (the decoded ParamPool).
% \STATE{$P_w\gets list(),P_b\gets list(), P_s\gets list()$}
 \STATE {$T_{hash} \gets \{\} $}\\
 {\small{/* Find the neurons with proportional incoming weights.*/}}
 \FOR {$l = 1,2,...,H-1$}
  \STATE {$W^{(l)}, W^{(l+1)} \gets W[l],W[l+1]$} {\small{\hskip3em // Obtain the incoming and outgoing weights of the neurons in the $l^\text{th}$ layer}} 
  \STATE {$Ind, \tilde{W}^{(l)}, \tilde{W}^{(l+1)} \gets 0, zeros\_{like}(W^{(l)}), zeros\_{like}(W^{(l+1)})$}

  \FOR {each input weight $W^{(l)}_{\cdot i}$ of the $i^{th}$ neuron in the $l^{th}$ layer}
   \STATE{$w \gets \text{Flatten}(W^{(l)}_{\cdot i}) $}
   \STATE {$w_{norm} \gets \text{Normalize}(W^{(l)}_{\cdot i})$}
   \STATE {$w \gets \frac{W^{(l)}_{\cdot i}}{w_{norm}}$}
   \IF {$w$ not in $T_{hash}$.keys()}
    \STATE {$T_{hash}[w] \gets Ind$}
    \STATE {$Ind \gets Ind + 1$}
    \ELSE
     \STATE{\small{/* Merge the neurons in the same hash bucket.*/}} 
     \STATE {$i' \gets T_{hash}[w]$}
     \STATE {$\tilde{W}^{(l)}_{\cdot i'} \gets w$}
     \STATE {$\tilde{W}^{(l+1)}_{i' \cdot } \gets \tilde{W}^{(l+1)}_{i' \cdot } + w_{norm} \cdot W^{(l+1)}_{i \cdot}$}
    \ENDIF
   \ENDFOR
  \STATE {$W^{(l)}, W^{(l+1)} \gets \tilde{W}^{(l)}, \tilde{W}^{(l+1)}$}
\STATE {Remove the neurons with zero incoming or outgoing weights in $W^{(l)}$, $W^{(l+1)}$.}
  \ENDFOR
 \RETURN  $W$
 \end{algorithmic}}
 \end{algorithm}