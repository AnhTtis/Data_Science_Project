%% The Case Studies
\subsection{Attacking Weight-based Watermarks}
\label{sec:eval_weight}
% \noindent\textit{7.2.1$\quad$Uchida et al.}\\
\noindent\textbf{(1) Uchida et al.}
% This method utilizes a watermark-related regularization term to embed owner-specific information into the certain weights of a layer of the target model, 
Uchida et al.\cite{uchida2017embedding} introduce one of the earliest white-box schemes which embed the model watermark into the convolutional weights of the target model. 
% As we mentioned in Section \ref{sec: white-box wm}
To extract the model watermark, the scheme first averages the convolutional weights $w \in \mathbb{R}^{N_{l-1}\times N_l \times w \times h}$ of the watermark-related layer through first dimension and flattens the weight to $\hat w \in \mathbb{R}^{(N_l \cdot w \cdot h)}$. Then, a binary string $s'$ is obtained from $\hat w$ through a pre-defined linear matrix $A$ and a threshold function $T_h$ at 0, i.e.,
%%%%%%%%%%%%%%%%%%%%% begin eq uchida %%%%%%%%%%%%%%%%%%%%%
% \begin{equation}\label{eq:uchida}
$
s' = T_h(X \cdot \hat w),
$
% \end{equation}
%%%%%%%%%%%%%%%%%%%%% end eq uchida %%%%%%%%%%%%%%%%%%%%%
which is matched with the owner-specific message $s$ in terms of BER for validation.
% where $T_h$ is a hard threshold function which outputs $1$ when the input is positive and $0$ otherwise. Finally, the extracted binary string $s'$ is matched with the owner-specific message $s$ in terms of BER to assert the model ownership.

\noindent$\bullet$\textbf{ Discussion.}
% As the linear transformation matrix in \ref{eq:uchida} is predefined before the watermark embedding procedure,  As the extraction process of Uchida et al. only consists of a mask matrix and a linear transformation matrix, \mytodo{the element-level representations of watermark-related parameters play a crucial role to the final extracted binary string. (please be more pointed at its own weakness)}
Although this approach is previously shown to be vulnerable to overwriting, known attacks however require the specific prior knowledge of the watermark algorithm as well as a domain dataset, both of which are usually impractical. Our attack reveals the insecurity of this algorithm by directly modifying the structure of the target model while leaving the utility intact. Specifically, the dimension of $\hat w$ is increased once the adversary injects dummy neurons into watermark-related layers. As a result, during the extraction procedure of $s_i'$ from the victim model, the second dimension of pre-defined linear transformation matrix $X$ is unmatched to the dimension of expanded $\hat w$ any longer.

%%%%%%%%%%%%% BEGIN OF ls fig
%\begin{figure}[t]
%\begin{center}
%\includegraphics[width=0.45\textwidth]{img/ber_p_uchida_dn.pdf}
%\caption{BER of WRN watermarked by \cite{uchida2017embedding} after an $\alpha$ ratio of dummy neurons are injected by our attacks. The dashed horizontal lines reports the BER of an irrelevant model.}
%\label{fig:ber_p_uchida}
%\end{center}
%\vspace{-0.25in}
%\end{figure}
%%%%%%%%%%%%%% END OF ls fig

\noindent$\bullet$\textbf{ Evaluation Results.}
We run the code of \cite{code-uchida} they publicly released to reproduce a watermarked model of Wide Residual Network (WRN) trained on CIFAR10 dataset. We perform our removal attack to inject dummy neurons generated via different methods into each layer, which presents the same original utility with classification accuracy of $91.55\%$ while the verification procedure is inhibited if with no error handling mechanism. As Fig.\ref{fig:scaled_ber} shows that applying Max-First cannot restore the embedded watermark from structural obfuscated model by \textit{NeuronClique} and \textit{NeuronSplit}, as the BER is increased over $50\%$ once we add less than $5\%$ dummy neurons, indicating the innate vulnerability of this scheme.


% ########################################################################
\noindent\textbf{(2) RIGA.} Wang et al. \cite{wang2021riga} replace the linear transformation matrix in Uchida et al. with a learnable fully-connected neural network (FCN) to boost the encoding capacity of watermarking messages. That is, the intuition behind this watermark scheme is closely identical to Uchida et al. We present the full details in Appendix \ref{sec:app:eval} and report the results in Fig.\ref{fig:scaled_ber}.
% \noindent\textbf{Protection Mechanism.}
% Wang et al. \cite{wang2021riga} enhance the covertness and robustness of prior white-box watermarking methods against watermark detection and removal attacks based on adversarial training and more sophisticated transformation function. They train a watermark detector to serve as a discriminator to encourage the distribution of watermark-related weights to be similar to that of unwatermarked models. Meanwhile, they replace the watermark extractor, which is previously implemented with a predefined linear transformation \cite{uchida2017embedding}, with a learnable fully-connected neural network (FCN), for boosting the encoding capacity of watermarking messages. Similar to Uchida et al.\cite{uchida2017embedding}, the watermark-related weights are first selected from the target model and then projected to a binary string $s'$ via the FCN-based extractor during the ownership verification procedure.



% \noindent\textbf{Discussion.}
% Simply replacing the linear transformation matrix in Uchida et al. \cite{uchida2017embedding} to a learnable extractor can not completely eliminate the removal threats from our attack based on model structural obfuscation. As a result, RIGA has the similar vulnerability of \cite{uchida2017embedding} as their watermark extraction procedures only differ into the type of extractor, which is also inexecutable due to the incompatible input dimension of the trained extractor for RIGA.


% \noindent\textbf{Evaluation Results.}
% We follow their evaluation settings to watermark Inception-V3 trained on CelebA, which achieves $95.90\%$ accuracy and $0\%$ BER \cite{code-riga}. We employ the default setups that the watermark is embedded into the third convolutional layer of the target model and the extractor is a multiple layer perceptron with one hidden layer. With our attack framework, we successfully inhibit the ownership verification of RIGA without any loss to the utility of victim model. Even applying the error-handling mechanisms, the BER of extracted message is increased to an unacceptable level. For example, when we utilize Max-First error-handling to obtain the embedded watermark, the BER is increased to $23.75\%$ when we inject the dummy neurons generated via \textit{NeuronSplit}.

% ########################################################################
\noindent\textbf{(3) IPR-GAN.}
To extend the watermarking primitive to generative adversarial networks (GANs) \cite{goodfellow2014gan}, Ong et al. present the first model watermark framework which first invokes black-box verification to collect some evidence from the suspect model via remote queries, and then utilizes the white-box verification for further extracting the watermark from the specific weights of suspicious model through the law enforcement. Different from \cite{uchida2017embedding}, Ong et al. embed the identification information into the scale parameters $\gamma$ of the normalization layers, rather than the convolutional weights. Correspondingly, the transformation function used in watermark verification stage consists of only a hard threshold function $T_h$, which actually extracts the signs of $\gamma$ in selected normalization layers as a binary string, i.e., 
%%%%%%%%%%%%%%%%%%%%% begin eq iprgan %%%%%%%%%%%%%%%%%%%%%
% \begin{equation}\label{eq:iprgan}
$s' = T_h(\gamma).$
% \end{equation}
%%%%%%%%%%%%%%%%%%%%% end eq iprgan %%%%%%%%%%%%%%%%%%%%%

\noindent$\bullet$\textbf{ Discussion.}
We focus on the white-box part of the watermark method. Previous works have shown that the scale parameters $\gamma$ of normalization layers are more stable than the convolution weights against existing removal attacks and ambiguity attacks, as small perturbation to these watermark-related parameters would cause significant drops to the original model utility. However, the number of scale weights in the watermark-related layer can be increased once we inject a group of dummy neurons. As a result, the length of binary string $s'$ extracted by the transformation function $T_h$ in this watermarking scheme is incompatible with the length of the target watermark any longer.
%As a result, the extracted binary string in Equation \ref{eq:iprgan} can be arbitrarily modified. 
% The capacity of embedded information is constrained by the total number of channels in normalization layers.

\noindent$\bullet$\textbf{ Evaluation Results.}
We follow their evaluation setups to watermark DCGAN trained on the CUB200 dataset, which achieves $54.33$ in terms of FID and has $0\%$ BER \cite{code-iprgan}.
As the watermark verification procedure is blocked with our proposed removal attacks, we leverage the error-handling methods on the scale weights to measure the BER of the extracted signature, which only has at most $55.86\%$ matched bits to the pre-defined binary signature while the FID of the generator is perfectly preserved as $54.33$, as  Fig.\ref{fig:scaled_ber} shows.

% ########################################################################
\noindent\textbf{(4) Greedy.}
Liu et al. \cite{liu2021greedyresiduals} propose to greedily select fewer yet more important model weights called the \textit{greedy residuals}, which is more important to the normal model utility and hence improves the watermark robustness against previous attacks. Specifically, the method extracts the identity information by first applying the transformation function $A$ on the one-dimensional average pooling over the flattened parameters $\hat w$ in the chosen convolutional layers, and then greedily takes the largest absolute values in each row by a ratio of $\eta$ to build the residuals. Finally, the secret binary string can be extracted from the signs of residuals by hard threshold function $T_h$ after being averaged to a real-valued vector.
Formally, the extraction procedure can be written as
%%%%%%%%%%%%%%%%%%%%% begin eq greedy %%%%%%%%%%%%%%%%%%%%%
% \begin{equation}\label{eq:greedy}
$
s' = T_h(Avg(Greedy(Avg\_pool\_1D(\hat w)))).
$
% \end{equation}
%%%%%%%%%%%%%%%%%%%%% end eq greedy %%%%%%%%%%%%%%%%%%%%%

\noindent$\bullet$\textbf{ Discussion.}
Greedy Residuals utilize some important parameters for embedding, which are more stable than choosing all the convolution weights in the specific layer proved in their ablation evaluations. Moreover, this watermark scheme greedily select the larger absolute values in each row from the intermediate feature matrix to build the residuals with fixed number of values, the verification procedure is not inhibited with the injection of dummy neurons. However, as the average pooled feature matrix before residual construction is impacted by some arbitrary values introduced by the injected dummy neurons, the extracted watermark after our attack would be perturbed unexpectedly. 
% As Greedy Residuals is still executable on the obfuscated model, we do not report the results of error-handling the watermark extraction algorithm in Table \ref{tab:eval}.

\noindent$\bullet$\textbf{ Evaluation Results.}
We run the source codes of Greedy Residuals publicly released by the authors \cite{code-greedy} to reproduce a watermarked ResNet18 training on Caltech256 dataset with $55.05\%$ accuracy and $0\%$ BER. We embed the secret watermark on the parameters of the first convolution layer with $\eta = 0.5$. We prove that our removal attack can utterly destroy the model watermark embedded into the residual of fewer parameters, for example, leading to an increase in the BER to $57.57\%$ after injecting dummy neurons from \textit{NeuronClique} whereas the model utility remains unchanged.

% ########################################################################
% sparsity pattern 
\noindent\textbf{(5) Lottery.}
The Lottery Ticket Hypothesis (LTH) explores a new scheme for compressing the full model to reduce the training and inference costs. As the topological information of a found sparse sub-network (i.e., the winning ticket) is a valuable asset to the owners, Chen et al. propose a watermark framework to protect the IP of these sub-networks \cite{chen2021lottery}. Specifically, they take the structural property of the original model into account for ownership verification via embedding the watermark into the weight mask in several layers with highest similarity to enforce the sparsity masks to follow certain 0-1 pattern. The proposed lottery verification uses the QR code to increase the capacity of the watermark method. For watermark verification, this algorithm first selects a set of watermark-related weight masks $m$ and then averages the chosen masks to a 2-dimensional matrix, which is further transformed to a QR code via $Sign$ function, i.e., $s' = Sign(Avg(m))$ and can be validated via a QR scanner. 
%%%%%%%%%%%%%%%%%%%%% begin eq lottery %%%%%%%%%%%%%%%%%%%%%
% \begin{equation}\label{eq:lottery}
% s' = T_h(Avg(m))
% \end{equation}
%%%%%%%%%%%%%%%%%%%%% end eq lottery %%%%%%%%%%%%%%%%%%%%%

\noindent$\bullet$\textbf{ Discussion.}
While most existing watermark techniques explore the specific model weights or prediction to embed the secret watermark, the lottery verification leverages the sparse topological information (i.e., the weight masks) to protect the winning ticket by embedding a QR code which can be further decoded into the secret watermark. However, our attack directly obfuscates the topological information of the target model by injecting groups of dummy neurons with the corresponding weight masks, which enlarges the shape of extracted QR code from the weight mask of trained winning ticket unexpectedly. As this QR code without valid shape is not decodable, we leverage the error-handling mechanism to extract the embedded watermark for ownership verification, where remains a large distortion.

%%%%%%%%%%%%% BEGIN OF ls fig
\begin{figure}[t]
\begin{center}
\includegraphics[width=0.4\textwidth]{img/qrcode_dn.png}
\vspace{-0.2in}
\caption{The QR codes extracted from ResNet-20 watermarked by\cite{chen2021lottery} after an $\alpha$ ratio of dummy neurons are added.}
\label{fig:qrcode}
\end{center}
\vspace{-0.3in}
\end{figure}
%%%%%%%%%%%%%% END OF ls fig

\noindent$\bullet$\textbf{ Evaluation Results.}
We follow the evaluation settings in the original paper to watermark a ResNet20 training on CIFAR-100 dataset, which achieves $66.41\%$ accuracy and $0\%$ BER \cite{code-lottery}. Although the QR code has the ability to correct some errors which improves the robustness against existing attacks, the identity information decoding procedure from the extracted QR code is invalidated by adding only a few (e.g., $1\%$)  dummy neurons in the victim model as Fig.\ref{fig:qrcode} shows. Moreover, the original design of Lottery Ticket is inhibited (due to the unmatched size) when attackers insert the dummy neurons into the protected model, while it retains robust against structure obfuscation with our proposed error-handling mechanisms. In other words, Lottery Ticket would have better robustness against neural structural obfuscation than other schemes if the unmatched size of neural layers are properly addressed in its design. 

% ########################################################################
\subsection{Attacking Activation-based Watermarks}
\noindent\textbf{(1) DeepSigns.}
As a representative of activation-based white-box watermarking schemes, DeepSigns proposes to embed the model watermark into the probability density function (PDF) of the intermediate activation maps obtained in different layers on the white-box scenario. Specifically, DeepSigns adopts a Gaussian Mixture Model (GMM) as the prior probability to characterize the hidden representations, and considers the mean values of the PDF at specific layers to share the same role as the watermark-related weights in Uchida et al. \cite{uchida2017embedding}. Similar to the verification procedure of \cite{uchida2017embedding}, a transformation matrix $A$, randomly sampled in embedding procedure, projects the mean values of chosen intermediate features to a real-valued vector. With the final hard threshold function, the resulted binary string $s'$ is matched to the owner-specific watermark for claiming the model ownership. 

%%%%%%%%%%%%%%%%%%%%% begin eq greedy %%%%%%%%%%%%%%%%%%%%%
% \begin{equation}\label{eq:deepsign}
% s' = T_h(A \cdot \frac{1}{|D_T|}h^l(x_t; W^l_{in}))
% \end{equation}
%%%%%%%%%%%%%%%%%%%%% end eq greedy %%%%%%%%%%%%%%%%%%%%%

\noindent$\bullet$\textbf{ Discussion.}
% Most known attacks focus on carefully fine-tuning the victim model or utilizing some transformations to the trigger data to remove the inner watermarks embedded by DeepSigns \cite{chen2021refit}. As the element-level representations of the weights at specific layer (or channel) are closely related to the output feature maps, DeepSigns is almost as vulnerable as Uchida et al's under these attacks. However, these known attacks again involve impractical assumptions on the attacker's knowledge and sacrifice much of the normal model utility for fully removing the watermark. As a comparison, our attack utilize the local features of 
The notable difference between DeepSigns and \cite{uchida2017embedding} is where to embed the model watermark. 
However, as the hidden features utilized by DeepSigns are generated by the weights in the preceding layer, e.g., $a_i = W_i\cdot x+b_i$, the structural information of target model is closely related to the shape of output feature maps. 
For example, the shape of the watermark-related layer's output is expanded after injecting dummy neurons, which inhibits the ownership verification due to the incompatible dimension of the output activation maps and the pre-defined transform matrix.
As a result, DeepSigns is almost as vulnerable as \cite{uchida2017embedding} under our attack.


\noindent$\bullet$\textbf{ Evaluation Results.}
We run the source code of DeepSigns from \cite{code-deepsign} to watermark a wide residual network trained on CIFAR10. This watermarked WRN achieves $89.94\%$ accuracy and $0\%$ BER. With the error-handling method, it is shown that the ownership verification of the target model is completely confused by our removal attacks. For example, the BER is increased to $47.59\%$ with dummy neurons from \textit{NeuronSplit} while the original model functionality is intact.

\noindent\textbf{(2) IPR-IC.}
As previous watermarking schemes are mainly designed for image classification models, they are insufficient to IP protection for image captioning models and cause inevitable degradation to the image captioning performance. Therefore, Lim et al. \cite{lim2022ipcaption} embed a unique signature into Recurrent Neural Network (RNN) through hidden features. At the ownership verification stage, the mask matrix $M$ first selects the hidden memory state $h$ of given watermarking image in protected RNN model. Then, the hard threshold function transforms the chosen $h$ to a binary string $s'$, which can be formally written as
%%%%%%%%%%%%%%%%%%%%% begin eq lstm %%%%%%%%%%%%%%%%%%%%%
$
s' = T_h(h).$
%%%%%%%%%%%%%%%%%%%%% end eq lstm %%%%%%%%%%%%%%%%%%%%%

\noindent$\bullet$\textbf{ Discussion.}
Similar to DeepSigns \cite{darvish2019deepsigns} and IPR protection on GANs \cite{ong2021iprgan}, the topological information is closely related to the shape of hidden memory state. Although the protected image captioning model contains an RNN architecture, we can adopt our structural obfuscation method to expand the size of hidden state, e.g., with vanishing weights, to produce an equivalence of the original model with the same output.

\noindent$\bullet$\textbf{ Evaluation Results.}
We run the official implementation \cite{code-captioning} to reproduce a watermarked Resnet50-LSTM trained on COCO, which achieves $72.06$ BLEU-1 and has $0\%$ BER. With our proposed removal attacks, the signature extracted from the hidden memory state $h$ is not compatible to the size of the owner-specific binary message. We leverage error-handling mechanisms, e.g., Max-First to extract the identity message, which is perturbed with $56.95\%$ and $52.60\%$ BER for \textit{NeuronClique} and \textit{NeuronSplit}, while no loss is brought to the image captioning performance.

% \subsection {Passport-based}
% ########################################################################
\subsection{Attacking Passport-based Watermarks} %\label{section:DeepIPR}
\noindent\textbf{(1) DeepIPR.} 
DeepIPR is one of the earliest passport-based DNN ownership verification schemes \cite{fan2021deepip}. By inserting owner-specific passport layers during the watermark embedding procedure, DeepIPR is designed to claim the ownership not only based on the extracted signature from the specific model parameters but also on the model performance with the private passport layer. Consequently, this scheme shows high robustness to previous removal attacks and especially to the ambiguity attacks, which mainly forge counterfeit watermarks to cast doubts on the ownership verification.

In our evaluation, we focus on the following passport verification scheme in \cite{fan2021deepip}. This scheme generates two types of passport layers simultaneously by performing a multi-task learning, i.e., public passports for distribution and private passports for verification, both of which are actually based on normalization layers. Generally, DeepIPR leverages pre-defined digital passports $P=\{P_{\gamma}, P_{\beta}\}$ to obtain the scale and the bias parameters of the private passport, which are written as:
$
\gamma = Avg(W_c \odot P_{\gamma}), \beta =  Avg(W_c \odot P_{\beta}),
$
where $W_c$ is the filters of the precedent convolution layer, and $\odot$ denotes the convolution operation. DeepIPR adopts a similar watermark extraction process as \cite{uchida2017embedding}, where the transformation function $A$ converts the signs of the private $\gamma$ into a binary string to match the target signature.

\noindent$\bullet$\textbf{ Discussion.}
As the private $\gamma$ and $\beta$ are obtained from the preceding convolution weights, DeepIPR actually embeds the secret signature in the hidden output of the convolutional layer with the weights $W_c$ given the input $P_{\gamma}$ or $P_{\beta}$. Similar to the activation-based watermarking scheme, the unmatched extracted watermark can not be used to ownership verification due to the expanded shape of $W_c$.
% Specifically, the signs of private $\gamma$ can be modified directly by changing the signs of related convolution weights, \mytodo{which causes a significant damage to the watermark detection procedure and model performance with private layers (this sentence is ambiguous. Needs discussion).}
% However, because the joint training for different passport layers leads to different distribution of the feature maps before normalization, DeepIPR calculates statistic values of normalization layers on-the-fly by replacing the batch normalization to other normalization, which causes noticeable drops to the original performance



% %%%%% BEGIN sig TABLE
% \input{tex/tables/signature}
% %%%%% END sig TABLE



\noindent$\bullet$\textbf{ Evaluation Results.}
We evaluate our attack on the watermarked ResNet18 trained on the CIFAR-100 dataset with DeepIPR \cite{code-deepipr} which achieves $67.94\%$ accuracy. When we inject an $\alpha$ proportion of neurons with our attack, the signature extracted from the victim model becomes totally unreadable, from \textit{``this is my signature''} ($\alpha =0$, BER$=0\%$) to \textit{``ÎÍ¿±C¾Ýzü½¤L°!²/Ã9Ûå''} ($\alpha=0.5$, BER$=51.25\%$). By injecting $50\%$ of dummy neurons, our attack
successfully increases the BER to almost random, while causing no change in the accuracy of the model with the public passports. 

% ########################################################################
\noindent\textbf{(2) Passport-aware Normalization.} Zhang et al. \cite{zhang2020passportaware} propose another passport-based watermark method without modifying the target network structure by maintaining the statistic values independently for passport layer. As the watermark embedding and extracting procedures are nearly identical to DeepIPR, we report the results in  Fig.\ref{fig:scaled_ber} and provide the details of Passport-aware Normalization in Appendix \ref{sec:app:eval}.
% \noindent\textbf{Protection Mechanism.} 
% Zhang et al. \cite{zhang2020passportaware} propose another passport-based watermark method without modifying the target network structure, which would otherwise incur notable performance drops. They adopt a simple but effective strategy by training the passport-free and passport-aware branches in an alternating order and maintaining the statistic values independently for the passport-aware branch at the inference stage. Similar to DeepIPR, the authors design the learnable $\gamma, \beta$ to be relevant to the original model for stronger ownership claim. During the extraction of model watermarks, the transformation function $A$ first projects the $\gamma$ by an additional FCN model to an equal-length vector and then utilizes the signs of the vector to match the target signature.

% \noindent\textbf{Discussion.}
% While this method improves DeepIPR in terms of model performance by preserving the network structure and improving transformation function $A$ with linear transformation and sign function, we discover it is still inexecutable because of the incompatible dimensions between the extracted watermark and target one.


% \noindent\textbf{Evaluation Results.}
% When we embed the model watermark into a ResNet18 trained on the CIFAR-100 via passport-aware normalization \cite{code-aware}, we are able to achieve $0\%$ BER, while preventing the original model utility from unacceptable drops. Our proposed structural obfuscation attacks demonstrate sufficient effectiveness to remove this white-box watermark and invalidate the passport-aware branch independently as Table \ref{tab:eval} shows. For example, with the error-handling of Max-First, the injection of dummy neurons generated by \textit{NeuronSplit} can boost the BER to $49.61\%$.
