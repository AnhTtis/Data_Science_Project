\section{Omitted Evaluation Results}
\label{sec:app:eval}

\noindent\textbf{RIGA.}
Wang et al. \cite{wang2021riga} enhance the covertness and robustness of prior white-box watermarking methods against watermark detection and removal attacks based on adversarial training and more sophisticated transformation function. They train a watermark detector to serve as a discriminator to encourage the distribution of watermark-related weights to be similar to that of unwatermarked models. Meanwhile, they replace the watermark extractor, which has been previously implemented with a predefined linear transformation \cite{uchida2017embedding}, with a learnable fully-connected neural network (FCN), for boosting the encoding capacity of watermarking messages. Similar to Uchida et al.\cite{uchida2017embedding}, the watermark-related weights are first selected from the target model and then projected to a binary string $s'$ via the FCN-based extractor during the ownership verification procedure.

\noindent\textbf{Discussion.}
Simply replacing the linear transformation matrix in Uchida et al. \cite{uchida2017embedding} to a learnable extractor can not completely eliminate the removal threats from our attack based on model structural obfuscation. As a result, RIGA has the similar vulnerability of \cite{uchida2017embedding} as their watermark extraction procedures only differ into the type of extractor, which is also inexecutable due to the incompatible input dimension of the trained extractor for RIGA.

\noindent\textbf{Evaluation Results.}
We follow their evaluation settings to watermark Inception-V3 trained on CelebA, which achieves $95.90\%$ accuracy and $0\%$ BER \cite{code-riga}. We employ the default setups that the watermark is embedded into the third convolutional layer of the target model and the extractor is a multiple layer perceptron with one hidden layer. With our attack framework, we successfully inhibit the ownership verification of RIGA without any loss to the utility of victim model. Even applying the error-handling mechanisms, the BER of extracted message is increased to an unacceptable level. For example, when we utilize Max-First error-handling to obtain the embedded watermark, the BER is increased to $76.04\%$ when we inject the dummy neurons generated via \textit{NeuronSplit}.

% ########################################################################
\noindent\textbf{Passport-aware Normalization.} 
Zhang et al. \cite{zhang2020passportaware} propose another passport-based watermark method without modifying the target network structure, which would otherwise incur notable performance drops. They adopt a simple but effective strategy by training the passport-free and passport-aware branches in an alternating order and maintaining the statistic values independently for the passport-aware branch at the inference stage. Similar to DeepIPR, the authors design the learnable $\gamma, \beta$ to be relevant to the original model for stronger ownership claim. During the extraction of model watermarks, the transformation function $A$ first projects the $\gamma$ by an additional FCN model to an equal-length vector and then utilizes the signs of the vector to match the target signature.

\noindent\textbf{Discussion.}
While this method improves DeepIPR in terms of model performance by preserving the network structure and improving transformation function $A$ with linear transformation and sign function, we discover it is still inexecutable because of the incompatible dimensions between the extracted watermark and target one.


\noindent\textbf{Evaluation Results.}
When we embed the model watermark into a ResNet18 trained on the CIFAR-100 via passport-aware normalization \cite{code-aware}, we are able to achieve $0\%$ BER, while preventing the original model utility from unacceptable drops. Our proposed structural obfuscation attacks demonstrate sufficient effectiveness to remove this white-box watermark and invalidate the passport-aware branch independently as Fig \ref{fig:scaled_ber} shows. For example, with the error-handling of Max-First, the injection of dummy neurons generated by \textit{NeuronSplit} can boost the BER to $56.17\%$.