% \text{} \clearpage
\section{Evaluation and Results}
\label{sec:eval}
% \subsection{Overview of Evaluation}
% \label{sec:eval_overview}
 \noindent\textbf{Overview of Evaluation.} To validate the effectiveness of our attack, we provide a systematic study on the vulnerability of nine state-of-the-art white-box watermark schemes published at top-tier venues and span the different stages of DNN watermark development.
 Before the detailed evaluation results, we concisely introduce the evaluation setups. 


%%%%% BEGIN eval TABLE
% \input{tex/tables/eval_table_ccs}
\input{tex/tables/new_scenarios.tex}
%%%%% END eval TABLE


% %%%%% BEGIN eval TABLE
% % \input{tex/tables/eval_table_ccs}
% \input{tex/tables/ber_threshold.tex}
% %%%%% END eval TABLE

\noindent$\bullet$\textbf{ Target Watermark Schemes.} As Table \ref{tab:new_scenario} shows, our evaluation covers most of the existing white-box DNN watermarks spanning the different stages of DNN watermark development, which faithfully reflected the three representative branches, i.e., \textit{weight-based, activation-based and passport-based} schemes.
\begin{itemize}
    \item \textit{Weight-based Watermarks \cite{uchida2017embedding,wang2021riga,liu2021greedyresiduals,ong2021iprgan}}: In weight-based watermarking schemes, the legitimate owner would secretly select one/more neural layers from the target model, and embed the identity message into a preprocessed version of the layer parameters during the training process.    
    \item \textit{Activation-based Watermarks \cite{darvish2019deepsigns,lim2022ipcaption}}: In contrast to the weight-based ones, activation-based watermarking schemes embed the identity message into the activation maps of a special set of data inputs at the target layers. Some works argue activation-based watermarks are more dynamic and data-dependent, which makes them more robust against obfuscation on model parameters\cite{darvish2019deepsigns}.  
    \item \textit{Passport-based Watermarks \cite{zhang2020passportaware,fan2021deepip}}: Passport-based watermarking schemes can be viewed as a hybrid of the weight-based and the activation-based schemes. On the one hand, the identity information is typically embedded to the learnable parameters of normalization layers in the target model. On the other hand, they reassert the validity of the ownership by inserting a special passport layer into the suspect model to check whether the DNN model inference performance is unyielding \cite{fan2021deepip}.
\end{itemize}

%%%%%%%%%% INTRODUCE HOW WE ENABLE THE EVALUATION OF the watermark schemes which can hardly be executed. 
\noindent$\bullet$\textbf{ Choices of Error-Handling Mechanisms.} We find most of the tested watermark schemes in Table \ref{tab:new_scenario} (except Greedy Residuals \cite{liu2021greedyresiduals}) are not executable when the parameters or the activation maps from the target layers are incompatible with the shape constraint of the predefined watermark extraction algorithm $\mathcal{E}$. To evaluate watermark existence, we therefore propose to implement an error-handling mechanism, which restores watermark-related parameters/activation maps to a valid size. Specifically, we get inspirations from \cite{liu2021greedyresiduals} to greedily remove the neurons with the less absolute mean value of the incoming and outgoing weights for each layer before the model watermark extraction. We call this error-handling strategy as \textit{Max-First}. In Section \ref{sec:eval:stealthiness_dn}, we further investigate more adaptive defenses on dummy neurons.      


% evaluate the following potential options, 
% \begin{itemize}
%     \item \textit{Random Sampling}: As a baseline for the ownership verification of a given expanded model, we randomly sample a number of neurons without replacement into each layer to obtain the parameters/activation maps with a valid size.
%     \item \textit{Max-First}: Another error-handing mechanism is similar to the significant parameter selection in \textit{Greedy Residuals} \cite{liu2021greedyresiduals}. Specifically, we greedily remove the neurons with the less absolute mean value of the incoming and outgoing weights for each layer before the model watermark extraction.
% \end{itemize}
% \noindent 




\noindent$\bullet$\textbf{ Implementation of Watermark Schemes.} For each watermarking scheme, we strictly follow the same experiment settings in the official implementations to reproduce a watermarked model for fair evaluation. This includes but not limited to the model architecture, dataset and watermark-related hyper-parameters, on which they claim the robustness to existing removal attacks. Also, we employ the same signature $s=$``\textit{this is my signature}'' in these known watermark schemes. These methods protect the IP of diverse models, including ResNet, Inception for image classification, DCGAN for image generation and LSTM for image captioning task, which hence support the broad applicability of our proposed attack. 

\noindent$\bullet$\textbf{ Evaluation Metrics.} For attack effectiveness, we use \textit{Bit Error Rate} (BER), i.e.,  the proportion of modified bits in the extracted watermark compared to the pre-defined signature,  to measure how much the watermark is tampered by our removal attack. To compare the robustness of different white-box watermark schemes we follow \cite{sokwatermark} to determine the decision threshold and then re-scale the BER results. Table \ref{tab:new_scenario} summarizes the decision threshold for the mainstream white-box watermark schemes. After modeling the decision threshold for each watermark, we also define a linear scaling function $S(x, \theta)$ similar to \cite{sokwatermark} as follows: $S(x ; \theta)=\min \left(1, \frac{\theta^{\prime}}{\theta} x\right)$,
which relates the BER from different white-box watermark methods with each other. As a result, the watermark is removed if the rescaled BER is higher than $50\%$. Otherwise, the watermark is retained. For utility loss, we report the performance of the watermarked model before/after our removal attack, i.e., FID \cite{heusel2017FID} for image generation and BLEU-1 \cite{Papineni2002BleuAM} for image captioning task and classification accuracy for other tasks \cite{ong2021iprgan,lim2022ipcaption}.

% We provide more details of attack implementation in Appendix \ref{sec:app:config}.
% In addition, we measure the BER of the unwatermarked model corresponding to each white-box watermark algorithms.
% \subsection {Weight-based}
% ########################################################################

%%%%%%%%%%%%% BEGIN OF naive dummy neuron 
\begin{figure*}[h]
\begin{center}
\includegraphics[width=1\textwidth]{img/ber_9.pdf}
\vspace{-0.3in}
\caption{The re-scaled BER of the watermarked models after inserting a certain proportion of neurons by our attacks. The dashed horizontal lines report the BER of the irrelevant mode.}
\label{fig:scaled_ber}
\end{center}
\vspace{-0.3in}
\end{figure*}

%%%%%%%%%%%%%% END OF naive dummy neuron

\noindent$\bullet$\textbf{ Summary of Results.} 
 Fig.\ref{fig:scaled_ber} summarize the effective of our proposed attacks, where the $x$-axis reflects the \textit{attack strength} defined as the ratio of added and modified dummy neurons in the target neural network.  We make the observation that most of the resulting scaled BER exceeds the removal threshold 50\%.  This validates that, due to the heavy assumption of existing schemes on the integrity of the neural architecture, most of them lose the claimed robustness to some or all the previously known attacks when evaluated under our proposed attack. 
 To apply error-handling mechanisms such as Max-First cannot restore the embedded watermark from structural obfuscated model by NeuronClique and NeuronSplit. In most cases, the BER is increased over 50\% once we add less than 5\% dummy neurons, indicating the innate vulnerability of these white-box watermarking schemes.  In the following, we provide a case-by-case analysis on the vulnerability of each scheme and how our attack cracks them by neural structure obfuscation with dummy neurons. 
 % Moreover, Lottery Ticket is more robust to our proposed removal attack, as the BER is lower than 50\% when the attackers insert less than 37.5\% dummy neurons.
 
 

 % Moreover, the original design of Lottery Ticket is inhibited (due to the unmatched size) when attackers insert the dummy neurons into the protected model, while it retains robust against structure obfuscation with our proposed error-handling mechanisms. In other words, Lottery Ticket would have better robustness against neural structural obfuscation than other schemes if the unmatched size of neural layers are properly addressed in its design.
 
 % More evaluation results of our attack can be found in Appendix \ref{sec:app:eval}.

%%% BEGIN OF CASE STUDIES 
\input{tex/cases.tex}
%%% END OF CASE STUDIES


\input{tex/defense.tex}