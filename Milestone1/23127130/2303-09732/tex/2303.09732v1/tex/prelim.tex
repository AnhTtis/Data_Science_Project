\section{Preliminary}
% 这一段感觉可以缩减
% \noindent\textbf{Deep Neural Networks.} As probably the most popular family of learning models, deep neural networks (DNNs) are widely used for modeling unknown decision functions in real-world applications \cite{Goodfellow2015DeepL}. During the feed-forward phase, a DNN $f(\cdot;W)(:=f_W):\mathcal{X}\to\mathcal{Y}$ invokes layers of computation to transform an input data $x \in \mathcal{X}$ (the input domain) to the output $y\in\mathcal{Y}$ (the output domain), where $W$ denotes all the learnable parameters in the DNN. Each neural layer (e.g., fully connected or convolutional layers) consists of a vector of neurons with incoming and outgoing parameters, which, as a whole, implements a predefined computing rule (e.g., matrix multiplication or convolution). The intermediate layers extract the hidden representation (i.e., \textit{activation maps}) of the inputs with the aid of activation functions (e.g., ReLU) or pooling functions (e.g., average pooling). During the backward phase, a gradient-based optimizer (e.g., SGD) is applied to update $W$ iteratively for minimizing a given loss function. % or Adam\cite{kingma2014adam}. 

\noindent\textbf{Notations on Deep Neural Networks.} Considering a DNN with $H$ layers, i.e., $\{f^1, f^2, \hdots,f^H\}$, each layer $f^l$ is composed of a set of $N_l$ neurons ($f^l=(n_1^l, n_2^l,...,n_{N_l}^l)$). We denote the parameters of the $l^{th}$ $(1\leq l\leq H)$ layer as $W^l$,
%We denote the parameters and the transformation function of the $l^{th}$ $(1\leq l\leq H)$ layer as $W^l$ and $F^l(\cdot;\theta)(:=F^l_{\theta})$, respectively. Correspondingly, the output of the $l^{th}$ layer for the input $x$ can be formally written as: $f^l(x) = F^l_{W^l}\circ F^{l-1}_{W^{l-1}}\circ...\circ F^1_{W^1}(x),$ where the parameter set $W^l$ in layer $f^l$ 
which can be further written as $\{w^l_{ij}\}_{i=1,j=1}^{N_{l-1}, N_l} \cup \{b^l_{j}\}_{j=1}^{N_l}$. From the neuron-level viewpoint, each element $w^l_{ij}$ is a scalar value (i.e., \textit{weight}) in a linear layer, or a matrix (i.e., \textit{kernel}) in a convolutional layer, which connects the neurons $n^{l-1}_i$ and $n^l_j$, and $b^l_{j}$ is the bias.

% where $W$ is composed of $H$ model parameter matrices from each layers (i.e. $W = {W^1, W^2,...,W^H}$) and $f^H(x;W)$ is the final prediction of the model.

% , taking advantage of the stable model intrinsic locality in these layers这句可能不适合在这个位置写， 因为读者还不太清楚model intrinsic locality的概念

\noindent\textbf{White-box DNN Watermarking.}
As an effective forensic technique against model stealing attacks \cite{oh2019reverseNN, orekondy2019knockoff, wang2018stealhyper, yan2020cache,Jagielski2020HighAA,Zhu2021HermesAS}, a number of model watermark schemes are proposed from 2017 \cite{uchida2017embedding, wang2021riga,liu2021greedyresiduals, fan2021deepip, zhang2020passportaware, ong2021iprgan,chen2021lottery, lim2022ipcaption,darvish2019deepsigns,adi2018turning,zhang2018blackwatermark, szyller2021dawn, jia2021entangled}, which allow the legitimate model owner to establish the legal ownership by verifying the existence of a unique watermark, usually in the form of secret identity messages, in the suspect model. Our current work concentrates on the security analysis of white-box watermarking schemes, an important and evolving branch of DNN watermarking which embeds and verifies the watermark in model internals (i.e., parameters \cite{uchida2017embedding,  wang2021riga,liu2021greedyresiduals, chen2021lottery,fan2021deepip, zhang2020passportaware, ong2021iprgan} or activation maps \cite{darvish2019deepsigns, lim2022ipcaption}).   

%? watermarking indicator, project matrix or image indicator
Broadly speaking, a white-box model watermark scheme consists of the following phases: \textit{watermark embedding} and \textit{watermark verification}. In the former phase, the scheme embeds the secret message $s$ (e.g., a bit string) into the parameters or the intermediate activation maps of the owned model $f_W$. This is usually achieved by an additional regularization term $\mathcal{L}_{\text{wmk}}$ alongside the primary learning objective $\mathcal{L}$, i.e.,
$
\mathcal{L}' = \mathcal{L} + \lambda \mathcal{L}_{\text{wmk}},
$
where $\lambda$ is the hyper-parameter to balance the utility and the specificity of the embedded watermark. For example, Uchida et al. \cite{uchida2017embedding} embed a secret bit string $s$ in the kernels of a specified convolutional layer. Therefore, the regularization term $\mathcal{L}_{wmk}$ is designed as the binary cross entropy loss between the secret bit string $s$ and $\sigma(X\cdot w)$, where $w$ is derived from the parameters of a specified convolutional layer by channel-level averaging and flattening, $X$ is a predefined transformation matrix, and $\sigma$ is the sigmoid function. During the verification, a watermark extraction function $\mathcal{E}$ is implemented to extract an equal-length message $s'$ from a given suspect model  $f_{\tilde{W}}$ in polynomial time: $\label{eq:extract wm}
s' = \mathcal{E}(f_{\tilde{W}}, M, A),% A is composed of [average_pooling, flatten, linear projection, sign]
$
where $M$ is the mask matrix to select a set of the specific parameters or activation maps directly from the suspect model $f_{\tilde{W}}$, and $A$ is a transformation function which projects the selected weights or activation maps to obtain the extracted message. 

% We provide a case-by-case analysis of the state-of-the-art white-box watermarking schemes in Section \ref{sec:eval}.


% Again, in the example of \cite{uchida2017embedding}, Uchida et al. extracts the message from the watermarked model according to the signs of the parameter after projection, i.e., $s' = T_h(X\cdot w) $, where $T_h$ is a hard threshold function which outputs $1$ when the input is positive and $0$ otherwise and $w$ is the weights selected from model $f_W$ by mask matrix $M$.
% Therefore, the owner can establish the model ownership if the distance (e.g., Hamming Distance \cite{hamming1950error}) between the extracted message $s'$ and the secret message $s$ is less than a predefined threshold $\epsilon$. It is worth to note, once the parameter $w$ has an incompatible dimension with the protection matrix $X$, then the watermark extraction function in Uchida et al. cannot be executed and hence the verification would fail (\S\ref{sec:how_dn_invalidate}). According to our case studies in Section \ref{sec:eval}, most of the state-of-the-art white-box watermark schemes do not implement a corresponding error-handling mechanism.  

% \noindent\textbf{Requirements on DNN Watermarking.}

 To ensure a trustworthy ownership verification, a model watermark scheme should satisfy the minimum set of requirements. For more advanced model watermark requirements, please refer to \cite{sokwatermark}.
\begin{itemize}
\item \textbf{Fidelity:} The utility of the model should have as small decrease as possible when the watermark is embedded.

\item \textbf{Reliability:} The watermark should be verified with high confidence in \textit{positive suspect models}, i.e., the same or a post-processed copy of the watermarked model, and with low confidence in negative suspect models, i.e., irrelevant models owned by others.

\item \textbf{Robustness:} The embedded watermark in the protected model should be resistant to adversarial attempts which aim at removing the watermark from the model (\S\ref{sec:limitations}). Moreover, a watermarking scheme should also raise the bar for the adversary to embed another fabricated watermark into the target model to cause ownership ambiguity \cite{fan2021deepip}.
\end{itemize}