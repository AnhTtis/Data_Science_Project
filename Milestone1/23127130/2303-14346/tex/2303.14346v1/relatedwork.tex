\section{Related Work}
\label{sec:relatedwork}


% motion prediction: Kalman Filter~\cite{zhang2021bytetrack, cao2022observation}

% \cite{cao2022observation} shows that MOT is sensitive to state uncertainty.

% Association: Hungarian method, similarity metric (iou)

\paragraph{Uncertainty Quantification and Propogation}\label{subsec:uq}

Uncertainty Quantification (UQ) is of paramount importance for the collaborative perception of safety-critical systems such as robots~\cite{rss19, perceptionCBF_corl21} and connected and autonomous vehicles~\cite{han2022behavior}. 
%While it seems plausible that the incorporation of uncertainty for each detected object could benefit subsequent modules in self-driving tasks, such as trajectory prediction~\cite{boris2022propagating} and motion planning~\cite{mpUncertain_icra14}, there is no research about how to leverage uncertainty quantification from collaborative object detection (COD) to improve the tracking performance yet. Several methods for uncertainty quantification in OD have been proposed. The Monte-Carlo dropout method involves training neural networks using dropout to perform approximate inference in Bayesian neural networks~\cite{miller2018dropout}. The deep ensembles method estimates the probability distribution by ensembling multiple networks with the same architecture but different parameters~\cite{lakshminarayanan2017simple,lyu2020probabilistic,ovadia2019can}. Despite their effectiveness, both Monte-Carlo dropout and deep ensembles methods require multiple runs of inference, which can be computationally costly and time-consuming. This limitation makes them less suitable for real-time critical tasks that demand low-latency, such as collaborative object detection.
In self-driving tasks, uncertainty quantification from collaborative object detection (COD) could improve trajectory prediction~\cite{boris2022propagating} and motion planning~\cite{mpUncertain_icra14}. However, there is no research on how to leverage COD uncertainty to enhance tracking performance. Several methods for uncertainty quantification in object detection (OD) exist, such as Monte-Carlo dropout~\cite{miller2018dropout} and deep ensembles~\cite{lakshminarayanan2017simple,lyu2020probabilistic,ovadia2019can}. However, these methods require multiple inference runs, making them unsuitable for real-time critical tasks like COD.
%The Monte-Carlo dropout method involves using dropout-based neural network training to perform approximate inference in Bayesian neural networks~\cite{miller2018dropout}. The deep ensembles method estimates the probability distribution through an ensemble of networks with the same architecture but different parameters~\cite{lakshminarayanan2017simple,lyu2020probabilistic,ovadia2019can}. 

%However, both methods require multiple runs of inference, making them infeasible for real-time critical tasks with high computational costs, such as collaborative object detection.


Direct modeling (DM) method is designed to estimate uncertainty and involves selecting an object detector, setting a certainty probability distribution on the detector's outputs, designing the corresponding loss function, adding extra regression layers to predict the uncertainty, and training the modified detector~\cite{feng2021review}. 
% For instance, the DM method for image object detection~\cite{he2019bounding} assumes that the distribution of each bounding box variable is a single-variate Gaussian distribution and introduces one additional layer to estimate the variance of the bounding box. Additionally, \cite{he2020deep} proposed the DM method with a high-dimensional multivariate Gaussian distribution. 
DM methods for point cloud object detection have also been proposed~\cite{meyer2020learning,meyer2019lasernet,Su2022uncertainty}. Direct modeling (DM) is a promising approach for uncertainty estimation in real-time computer vision tasks, as it requires only a single inference pass to capture the uncertainty. However, estimating rigorous uncertainty using DM can be challenging, as the model may easily overfit to the training dataset. To address the above mentioned challenges, we rigorously quantify the uncertainty in the COD stage based on direct modeling and conformal prediction.

% Methods with both DM and MC dropout to estimate aleatoric and epistemic uncertainties in object detection have also been investigated~\cite{kendall2017uncertainties,feng2019leveraging,feng2018towards}. 

% Uncertainty propagation~\cite{boris2022propagating}, conformal prediction, uncertain quantification in MOT of single robot perception
\paragraph{Multiple Object Tracking (MOT)}\label{subsec:mot}

Several recent MOT algorithms~\cite{cao2022observation,choi2015near,wojke2017simple,zhang2021bytetrack,zhou2020tracking} utilize motion models that typically rely on Bayesian estimation~\cite{lehmann2006theory} to predict the next state by maximizing a posterior estimation. One of the most widely used motion models is the Kalman Filter (KF)~\cite{kalman1960contributions}, which operates as a recursive Bayes filter that follows a standard predict-update cycle. 
% The KF assumes that the true state is an unobserved Markov process, while measurements are observations of a hidden Markov model~\cite{rabiner1986introduction}. 
%However, because the KF is limited by its linear motion assumption, subsequent works, such as the Extended KF~\cite{smith1962application} and Unscented KF~\cite{julier1997new}, were developed to handle nonlinear motion by using first-order and third-order Taylor approximation, respectively. 
In the KF, current algorithms typically use a fixed measured uncertainty for all detections without considering rigorously estimated uncertainty to improve prediction accuracy. In contrast, we propose a rigous uncertainty quantification of the collaborative object detection process based on conformal prediction, and leverage the uncertainty input into the KF to improve the accuracy and uncertainty estimation of the output results.

Data association is a crucial step of MOT, which involves computing the similarity between tracklets and detected objects and utilizing various strategies to match them based on their similarity. 
% The SORT algorithm~\cite{bewley2016simple} takes a straightforward approach to combine location and motion cues. 
The SORT algorithm~\cite{bewley2016simple} uses the Intersection over Union (IoU) between predicted boxes and detection boxes to determine their similarity. This simple yet effective approach has proven to be highly competitive on a variety of MOT benchmarks, and serves as a strong baseline for comparison with more sophisticated tracking methods.
%In contrast, recent methods~\cite{sun2020transtrack,wu2021track,zhou2020tracking} employ networks to learn object motions and achieve more robust results, especially in cases of large camera motion or low frame rates. 
Once the similarity has been computed, matching strategies assign identities to the objects. This can be achieved through the Hungarian Algorithm~\cite{kuhn1955hungarian} or greedy assignment~\cite{zhou2020tracking}. 
%SORT~\cite{bewley2016simple} matches the detection boxes to the tracklets in a single matching step. 
% DeepSort~\cite{wojke2017simple} proposes appearance features obtained from a pre-trained convolutional neural network as the similarity which is only suitable for images.
ByteTrack~\cite{zhang2021bytetrack} utilizes similarities between the low-quality detections and tracklets to recover true objects to improve the performance on data association.
However, using IoU distance as a similarity metric may not be appropriate for low-quality detections as explained in Fig.~\ref{fig:teaser}. Therefore, we propose a new association metric, Negative Log Likelihood (NLL), that is more informative in such situations, to better match low-quality COD and improve the tracking result in terms of both accuracy and uncertainty.
