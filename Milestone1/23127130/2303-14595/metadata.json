{
    "arxiv_id": "2303.14595",
    "paper_title": "Preserving Linear Separability in Continual Learning by Backward Feature Projection",
    "authors": [
        "Qiao Gu",
        "Dongsub Shim",
        "Florian Shkurti"
    ],
    "submission_date": "2023-03-26",
    "revised_dates": [
        "2023-04-04"
    ],
    "latest_version": 2,
    "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
    ],
    "abstract": "Catastrophic forgetting has been a major challenge in continual learning, where the model needs to learn new tasks with limited or no access to data from previously seen tasks. To tackle this challenge, methods based on knowledge distillation in feature space have been proposed and shown to reduce forgetting. However, most feature distillation methods directly constrain the new features to match the old ones, overlooking the need for plasticity. To achieve a better stability-plasticity trade-off, we propose Backward Feature Projection (BFP), a method for continual learning that allows the new features to change up to a learnable linear transformation of the old features. BFP preserves the linear separability of the old classes while allowing the emergence of new feature directions to accommodate new classes. BFP can be integrated with existing experience replay methods and boost performance by a significant margin. We also demonstrate that BFP helps learn a better representation space, in which linear separability is well preserved during continual learning and linear probing achieves high classification accuracy. The code can be found at https://github.com/rvl-lab-utoronto/BFP",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.14595v1",
        "http://arxiv.org/pdf/2303.14595v2"
    ],
    "publication_venue": "CVPR 2023. The code can be found at https://github.com/rvl-lab-utoronto/BFP"
}