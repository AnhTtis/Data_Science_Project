\begin{figure}[!t]
    \centering
    % \includegraphics[width=\linewidth]{figures/rel-acc.pdf}
    \includegraphics[width=0.48\linewidth]{figures/cifar100-svd.pdf}
    \includegraphics[width=0.48\linewidth]{figures/cifar100-acc.pdf}
    \includegraphics[width=0.48\linewidth]{figures/cifar100-svd-rel.pdf}
    \includegraphics[width=0.48\linewidth]{figures/cifar100-acc-rel.pdf}
    \caption{
    % \qiao{Note two plots show absolute values and the other two show relative values. We should select absolute or the relative ones. Please see which ones are better. }
    % Accuracies quickly saturate when only a small subspace in feature space is kept for incremental classification task. Here each curve shows the relative accuracy (w.r.t. using full feature space) versus the number of dimensions kept. 
    Feature distribution and contribution to classification during continual learning on Split-CIFAR100 with 10 classes per task. 
    % Upper plot: feature variance (singular values) along each principal direction. Lower plot: classification accuracies using features that are projected on a subspace formed by $k$ principal vectors. 
    \textbf{Left}: feature variance (singular values) along each principal direction; \textbf{right}: classification accuracies proj-acc($k$) using projected features. 
    \textbf{Upper} plots show the absolute singular values and accuracies, and \textbf{lower} ones show their relative values, normalized by the maximum on each curve. 
    Finetuning (FT) is a naive CL baseline that does not handle forgetting at all and gives a lower-bound performance. Joint Training (JT) is an oracle CL method that is jointly trained on all classes seen so far and shows the upper bound. Contrasting JT with FT reveals the ideal properties for good CL methods. 
    As the model is continually trained on more classes, more feature dimensions are learned and needed for classification. However, compared to the full feature dimension (512), only a small subspace (around 10 principal directions for 10 classes and 80 for 100 classes) is crucial for CL performance, as the relative accuracies quickly saturate with the number of principal directions used. 
    % Note that the right endpoint of all curves already, saturates, achieving more than 99\% of the full accuracy. 
    % Different curves are obtained at the end of different tasks during continual learning, and the legend shows how many classes have been seen so far. 
    % As the model is trained on more classes, more feature dimensions are used for classification, but still remain a small portion compared to the full feature dimension (512). 
    % \qiao{Are second and fourth plot better? - Make it a 2x2 grid of plots. }
    }
    \label{fig:relacc}
    \vspace{-1em}
\end{figure}
