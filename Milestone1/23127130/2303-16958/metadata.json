{
    "arxiv_id": "2303.16958",
    "paper_title": "PartManip: Learning Cross-Category Generalizable Part Manipulation Policy from Point Cloud Observations",
    "authors": [
        "Haoran Geng",
        "Ziming Li",
        "Yiran Geng",
        "Jiayi Chen",
        "Hao Dong",
        "He Wang"
    ],
    "submission_date": "2023-03-29",
    "revised_dates": [
        "2023-03-31"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV",
        "cs.RO"
    ],
    "abstract": "Learning a generalizable object manipulation policy is vital for an embodied agent to work in complex real-world scenes. Parts, as the shared components in different object categories, have the potential to increase the generalization ability of the manipulation policy and achieve cross-category object manipulation. In this work, we build the first large-scale, part-based cross-category object manipulation benchmark, PartManip, which is composed of 11 object categories, 494 objects, and 1432 tasks in 6 task classes. Compared to previous work, our benchmark is also more diverse and realistic, i.e., having more objects and using sparse-view point cloud as input without oracle information like part segmentation. To tackle the difficulties of vision-based policy learning, we first train a state-based expert with our proposed part-based canonicalization and part-aware rewards, and then distill the knowledge to a vision-based student. We also find an expressive backbone is essential to overcome the large diversity of different objects. For cross-category generalization, we introduce domain adversarial learning for domain-invariant feature extraction. Extensive experiments in simulation show that our learned policy can outperform other methods by a large margin, especially on unseen object categories. We also demonstrate our method can successfully manipulate novel objects in the real world.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.16958v1"
    ],
    "publication_venue": "Accepted by CVPR2023"
}