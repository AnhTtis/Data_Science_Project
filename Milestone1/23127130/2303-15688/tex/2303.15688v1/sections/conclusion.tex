
This work has presented a strategy to enable adaptation in policies efficiently learned from a Robust Tube MPC expert using Imitation Learning and tube-guided data augmentation. We did so by leveraging an adaptation scheme inspired by the recent Rapid Motion Adaptation work \cite{kumar2021rma}. Our evaluation in simulation has demonstrated successful learning of an adaptive, robust policy that can handle strong out-of-training distribution disturbances while controlling the position and attitude of a multirotor. Future work will experimentally evaluate the approach and perform a more direct comparison with \ac{RMA} for quadrotors \cite{zhang2022zero} once their code becomes available.