\begin{table}[t] 
\caption{Time required to generate a new action; all times reported in milliseconds (ms). Our approach (SAMA-100-FT) is on average $12\times$ faster than the optimization-based Expert, and $24\times$ faster than an optimization-based approach with disturbance observer (RTMPC+DO). While our previous work (SA) \cite{tagliabue2022demonstration} achieves a faster inference time than our method, it lacks adaptation, which our method adds with minimal computational cost.} \label{table:runtime}
\vspace{-0.3em}
\begin{center}
\begin{tabular}{
|@{\hspace{0.5em}}r@{\hspace{0.5em}}
|@{\hspace{0.5em}}c@{\hspace{0.5em}}
|@{\hspace{0.5em}}c@{\hspace{0.5em}}
|@{\hspace{0.5em}}c@{\hspace{0.5em}}
|@{\hspace{0.5em}}c@{\hspace{0.5em}}
|@{\hspace{0.5em}}c@{\hspace{0.5em}}|}
\hline
\textbf{Method} & \textbf{Setup} & \textbf{Mean} & \textbf{SD} & \textbf{Min} & \textbf{Max} \\ \hline \hline
Expert                                       & CVXPY     & 9.51 & 6.16 & 5.04 & 62.2 \\ 
RTMPC+DO                                     & CVXPY     & 19.0 & 14.0 & 13.5 & 937 \\ 
SA \cite{tagliabue2022demonstration}         & PyTorch   & 0.491 & 7.55e-2 & 0.458 & 1.54 \\ 
SAMA-100-FT (Ours)                   & PyTorch   & 0.772 & 3.68e-2 & 0.669 & 1.58 \\  \hline
\end{tabular}
\end{center}
\vskip-3ex
\end{table}