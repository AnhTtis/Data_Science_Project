\section{MODEL EVALUATION}
We present two types of evaluation metrics: the Receiver Operating Characteristic (ROC) curve which is standard for binary classification, and our custom evaluation metric \emph{Beam Time Saved} defined in real-time scenario.

\subsection{Classification metric}
Following~\citet{li2021novel}, we keep evaluating the performance of the binary classification model by the ROC curve and its corresponding AUC value. For both RPCNN and Lasso,  Figure~\ref{fig:roc} shows the ROC curve and AUC together with uncertainties calculated from 25 trials each. The behaviour of a perfect model and random guess is also plotted for comparison. With an AUC of $0.99$ and much narrower uncertainty, LASSO demonstrates its superiority in terms of better classification power as well as more stable performance compared to RPCNN.
\begin{figure}[!tbh]
    \centering
    \includegraphics[width=\linewidth]{figs/ROC_curve_compare.png}
    \caption{The ROC curves and AUC for LASSO and RPCNN models, a perfect classifier and random guess. The 95\% confidence interval is also depicted as areas.}
    \label{fig:roc}
\end{figure}

A point worth noting is the difference of the inputs of RPCNN from the Lasso model. RPCNN takes window input at least \SI{1}{\second} before interlocks; however, according to the findings from the MMD test that changes only take place inside \SI{0.2}{\second}, the interlock windows and stable windows --- which are considered as two difference classes for RPCNN --- are similarly distributed. This explains the big instabilities and large amount of false positives in prediction. %Rerunning the RPCNN model on the single time step data is planned but omitted due to the already excellent performance of the Lasso model.

\subsection{Real-time metric}\label{sec:realtime}
In the ROC curve, the number of TP\textsuperscript{c} and FP\textsuperscript{c} are calculated only from the testing dataset. In real operation, these metrics need to be updated as new data and interlock events are recorded continuously, and it should be possible to evaluate the model according to an adjustable forecasting horizon. To adapt and improve the previous \emph{beam time saved} metric, we propose our customised definition of TP and FP in real time (denoted as TP\textsuperscript{r} and FP\textsuperscript{r}) as shown in Figure~\ref{fig:goal}.

\begin{figure}
% revision for better quality
    \centering
    \includegraphics[width=\linewidth]{figs/goal_tpfp.jpg}
    \caption{Customised definition of real-time true positives (TP\textsuperscript{r}) and false positives (FP\textsuperscript{r}). An inspection window of \SI{1}{\minute} starts when the model output goes above threshold. A TP\textsuperscript{r} is counted if interlocks fall in this inspection window, otherwise a FP\textsuperscript{r} is recorded.}
    \label{fig:goal}
\end{figure}

Assume the model output is above the classification threshold at time $t$. If there is actually an interlock inside an inspection window of \SI{1}{\minute} after $t$, then this interlock is successfully predicted and it is counted as one TP\textsuperscript{r}; otherwise, if there is no interlock for \SI{1}{\minute}, then one FP\textsuperscript{r} is counted. The number of TP\textsuperscript{r} cannot exceed the total number of interlocks, while the number of FP\textsuperscript{r} is not limited. Thus the ratio TPR\textsuperscript{r}$=N_{\text{TP}_r}/N_{int}$ could be used to evaluate model performance, where $N_{int}$ denotes the total number of interlocks. Figure~\ref{fig:tpfp} shows examples of TP\textsuperscript{r} and FP\textsuperscript{r} in real-time model operation, complying with the procedure described in Figure~\ref{fig:goal}.

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{figs/tpfp.png}
    \caption{Examples of real-time TP\textsuperscript{r} and FP\textsuperscript{r} from one LASSO training that compares two sets of $t_1=\SI{0.2}{\second}$ and $t_0=\SI{0.4}{\second}$ with 0.5 as the classification threshold, taken from \SI{10}{\minute} period on 2019-10-06. Note that this model is not the best performing one according to the classification and real-time metrics, only to manifest the definition of TP\textsuperscript{r} and FP\textsuperscript{r}. In this example, the interlock is successfully predicted around \SI{30}{\second} in advance, but there are also 2 FP\textsuperscript{r} generated by the model. The \emph{beam time saved} $T_s^r$ during this period is thus $19\cdot 1-6\cdot 2=7$ seconds. }
    \label{fig:tpfp}
\end{figure*}

With the customized definition of real-time TP\textsuperscript{r} and FP\textsuperscript{r}, we construct the real-time metric \emph{Beam Time Saved} $T_s^r$ in Eq.~\eqref{eq:ts} during any given time period
\begin{equation}\label{eq:ts}
    T_s^r \vcentcolon= 19 \cdot \text{TP}^{r} - 6 \cdot \text{FP}^{r}
\end{equation}
where TP\textsuperscript{r} and FP\textsuperscript{r} are the number of real-time TPs and FPs during the concerned time period. The numbers $19$ and $6$ come from the fact that a normal interlock causes a beam time loss of about \SI{25}{\second}; and the assumption that an interlock can be circumvented by reducing the beam current by 10\% is equivalent to a beam time loss of \SI{6}{\second}, as illustrated in Figure~\ref{fig:metric}. One TP\textsuperscript{r} therefore saves \SI{19}{\second} beam time, yet one FP\textsuperscript{r} loses \SI{6}{\second} beam time, as shown in Table~\ref{tab:metric}. 

\begin{figure}
% revision for better quality
\centering
\includegraphics[width=\linewidth]{figs/metric.pdf}
\caption{Lost beam time in case of interlocks and when beam reduction is operated. Since an interlock lasts around \SI{1}{\minute}, reducing 10\% of beam current is equivalent to \SI{6}{\second} beam time loss.}
\label{fig:metric}
\end{figure}

\begin{table}[!hbt]
   \centering
   \caption{Summary of lost and saved beam time (\SI{}{\second}) in case of TP\textsuperscript{r}, FP\textsuperscript{r} and FN\textsuperscript{r}, before and after the 10\% beam reduction is performed.}
   \begin{tabular}{lrrr}
       \toprule
       \textbf{Conditions} & \textbf{TP\textsuperscript{r}} & \textbf{FP\textsuperscript{r}} &  \textbf{FN\textsuperscript{r}} \\
       \midrule
No recovery operation & -25 & 0 & -25\\
10\% beam current reduced & -6 & -6 & -25 \\
\cdashlinelr{1-4}
Net beam time saved (\SI{}{\second})& 19 & -6 & 0 \\
\bottomrule
   \end{tabular}
   \label{tab:metric}
\end{table}

Table~\ref{tab:realtime} lists the above-mentioned real-time metrics of the two models. LASSO performs better in all metrics, and it has the potential to save around \SI{5}{\minute} of beam time per day, depending on the chosen classification threshold. The numbers of TP\textsuperscript{r} (thus TPR\textsuperscript{r} as well) and FP\textsuperscript{r} drop with increasing threshold, as this reflects a stricter criteria for positives. The trade-off between TP\textsuperscript{r} and FP\textsuperscript{r} in $T_s^r$, as expressed by Eq. \eqref{eq:ts}, portends the existence of an optimal choice of the classification threshold --- the threshold of 0.8 is chosen from current experiments to reach the largest $T_s^r=\SI{5.45}{\minute/\day}$. The best-performing RPCNN model~\cite{li2021novel} has a negative gain of \SI{0.27}{\minute/\day} more beam time loss, due to its rather low number of TP\textsuperscript{r} as well as high number of FP\textsuperscript{r}. Also the different definitions of TP, FP and $T_s$ play a role here.
%The column \textbf{FN\textsuperscript{r}\textsubscript{0}} indicates the number of interlocks for which the model produces positive output precisely at the moment that these interlocks occur. In other words, the forecasting horizon $T_h$ for these interlocks is zero. These are considered as false positives since there is not enough time to respond and take any countermeasures, thus the \SI{25}{\second} beam time would still be lost. However, the model's ability to discern between stable states and interlocks is still demonstrated.

\begin{table}[!hbt]
   \centering
   \caption{Real-time metrics of both models. The best-performing RPCNN model~\cite{li2021novel}, which is selected based on the previous \emph{average beam time saved} definition $\overline{T_s}$, is listed here as a benchmark. The subscripts $0.5$ to $0.9$ under LASSO denote the different choices of classification thresholds. The best values among each column are marked bold.}
   \begin{tabular}{lrrrrr}
       \toprule
       \textbf{Model} & \textbf{TP\textsuperscript{r}} & \textbf{ FN\textsuperscript{r}} &
       %\textbf{FN\textsuperscript{r}\textsubscript{0}} & 
       \textbf{TPR\textsuperscript{r}}(\%) &  \textbf{FP\textsuperscript{r}} & $\mathbf{T_s^r}$ (\SI{}{\minute/\day}) \\
       \midrule
RPCNN\textsubscript{best} & 99 & 1093  & 8.3 & 455 & -0.27\\
LASSO\textsubscript{0.5} & \textbf{1017} & \textbf{175} & %\textbf{56}  &
\textbf{85.3} & 1405 & 3.43 \\
LASSO\textsubscript{0.6} & 1004 & 188 &
%79  &
84.2 & 784 & 4.52 \\
LASSO\textsubscript{0.7} & 1000 & 192 &
%92  &
83.9 & 429 & 5.17 \\
LASSO\textsubscript{0.8} & 983 & 209 &
%115  &
82.5 & 222 & \textbf{5.45} \\
LASSO\textsubscript{0.9} & 956 & 236 &
%151  &
80.2 & \textbf{182} & 5.37 \\
       \bottomrule
   \end{tabular}
   \label{tab:realtime}
\end{table}

Figure~\ref{fig:perf_realtime} compares the performance of the RPCNN\textsubscript{best} and LASSO\textsubscript{0.8} models in real-time scenario. The data are taken from 3 to 4 A.M. on October $6^{th}$ 2019, with 2 interlocks in total. LASSO succeeds in capturing both of the two TPs, while RPCNN misses one TP, and more FPs are clearly present for RPCNN as well.

\begin{figure*}
\centering
\includegraphics[width=\linewidth]{figs/rpcnn_realtime.png}
\includegraphics[width=\linewidth]{figs/lasso_realtime.png}
\caption{Real-time performance of both models in one hour in 2019-10-06.}
\label{fig:perf_realtime}
\end{figure*}

Since the positive samples are only taken at $t_1=\SI{0.2}{\second}$, most of interlocks are expected to be predicted only \SI{0.2}{\second} in advance. However, still some earlier precursors appear in the real-time evaluation of the model, and the actual forecasting horizon $T_h$ (as introduced in Figure~\ref{fig:problem}) extends beyond \SI{0.2}{\second}.  Figure~\ref{fig:horizon} is a cumulative distribution plot of the number of successfully forecasted interlocks (i.e. the 983 TP\textsuperscript{r} out of total 1192 interlocks in Table~\ref{tab:realtime} for the LASSO\textsubscript{0.8} model) with regard to the full range of forecasting horizon $T_h(\SI{}{\second})$, i.e. from \SI{0.2}{\second} to \SI{59.8}{\second}.  967 interlocks are predicted only \SI{0.2}{\second} before, which takes up 98\% out of all 983 true positives.
But there is one earliest prediction occurring at \SI{51.0}{\second} before the interlock, together with several other earlier captures. This demonstrates the potential for the model to make early predictions. In addition, the relation between forecasting horizon and the definition of real time metrics still needs to be further examined.

% \begin{table}
% \centering
% \caption{Number of successfully predicted interlocks (i.e. TP\textsuperscript{r}s) in different forecasting horizon (s). In total there are 983 of them.}
% \begin{tabular}{lr}
% \toprule
% $T_h(\SI{}{\second})$ & Count\\
% \midrule
% 58.6 & 1 \\
% 55.4 & 1 \\
% 50.6 & 1 \\
% 49.2 & 2 \\
% ... & ... \\
% \bottomrule
% \end{tabular}
% \begin{tabular}{lr}
% \toprule
% $T_h(\SI{}{\second})$ & Count\\
% \midrule
% ... & ... \\
% 0.8 & 1 \\
% 0.6 & 1 \\
% 0.4 & 146 \\
% 0.2 & 825 \\
% \bottomrule
% \end{tabular}
% \label{tab:horizon}
% \end{table}

\begin{figure}
    \centering
\includegraphics[width=\linewidth]{figs/horizon08-white.png}
    \caption{ Cumulative distribution plot of TP\textsuperscript{r} according to forecasting horizon $T_h(s)$. One earliest prediction happens at \SI{51.0}{\second}, and 3 interlocks are predicted longer than \SI{40}{\second}. To emphasize the significant values, both the x and y axes are shown in uneven scale.}
    \label{fig:horizon}
\end{figure}