\section{The LASSO model}
Based on the above MMD analysis, we modify the two classes of our previous binary classification model. The positive and negative classes are composed of samples taken at $t_1$ and $t_0$ seconds before interlocks, respectively. Instead of the previous time windows, each sample now becomes a $(376,)$ vector taken at one single timestamp. We fit these two classes of samples with a LASSO regression model, which is a standard logistic regression plus a $L_1$ regularization term to suppress the number of input features. 

The inputs are denoted as $\{x_i \in \mathbb{R}^d \}_{i=1}^n $ where $d=376$ and $n$ is the number of samples. The class labels are $\{y_i\}_{i=1}^n \in \{\pm 1\}$, where $y=1$ for positive samples (i.e. $t_1$ seconds before interlock) and $y=-1$ for negative samples (i.e. $t_0$ seconds before interlock). The goal is to fit weight $\mathbf{\omega} \in \mathbb{R}^d$ by minimizing the loss in Eq.~\eqref{eq:lasso}
\begin{align}\label{eq:lasso}
    \min_{\mathbf{\omega}}{L} &= \min_{\mathbf{\omega}}\big[\underbrace{\frac{1}{n}\sum_{i=1}^n\log{[1+\exp{(-y_i \mathbf{\omega}^T \cdot x_i)}]}}_{\text{logistic loss}} \nonumber \\
    \quad &+\underbrace{\lambda \| \mathbf{\omega}\|}_{\text{regularization}}\big].
\end{align}

The output is again a probability output inside the range $[0,1]$. Compared to RPCNN, LASSO is simple, linear and sparse, and the regularization could also lead to better model interpretability.

We compare different choices of $t_0$ and $t_1$ from $\{\SI{0.2}{\second}, \SI{0.4}{\second}, \SI{0.6}{\second}, \SI{1.0}{\second}, \SI{10.0}{\second}\}$ before all interlocks, then train a LASSO logistic regression model to do the classification with 5-fold cross validation, together with a grid-search on the choice of regularization parameter $\lambda$. The summary in Table~\ref{tab:confusion} combines the classification results from all of the 5-folds when they are hold-out as test set. The subscription $c$ for the classification metrics TPR and FPR in the table refers to typical \emph{classification} metric calculated within input samples, in order to distinguish from the customised \emph{real-time} metric introduced later in Section~\ref{sec:realtime}.

\begin{table}
\centering
\caption{Binary classification results shown as TPR\textsuperscript{c} (\%) | FPR\textsuperscript{c} (\%), comparing samples taken at various $t_0$ and $t_1$ seconds before interlocks. The dataset is taken from October and November of 2019 with 1192 interlocks in total. The best TPR\textsuperscript{c} and FPR\textsuperscript{c} results are marked in bold.}
\begin{tabular}{lllll}
\toprule
\multicolumn{1}{c}{$\mathbf{t_1\big\backslash t_0}$}  & \multicolumn{1}{c}{\SI{0.4}{\second}} & \multicolumn{1}{c}{\SI{0.6}{\second}} &  \multicolumn{1}{c}{\SI{1.0}{\second}} &\multicolumn{1}{c}{\SI{10.0}{\second}}\\
\midrule
\SI{0.2}{\second} & 93.2 | 2.3 & 96.8 | 0.5 & 96.8 | \textbf{0.3} & \textbf{97.4} | 0.6\\
\SI{0.4}{\second} & \multicolumn{1}{c}{-} & 52.8 | 22.5 & 53.2 | 21.6 & 57.4 | 23.1\\
\SI{0.6}{\second} & \multicolumn{1}{c}{-} & \multicolumn{1}{c}{-} & 56.0 | 44.2  & 58.4 | 41.6 \\
\SI{1.0}{\second} & \multicolumn{1}{c}{-} & \multicolumn{1}{c}{-} & \multicolumn{1}{c}{-}  & 57.8 | 43.2\\
\bottomrule
\end{tabular}
\label{tab:confusion}
\end{table}

We choose the $t_1=\SI{0.2}{\second}$ versus $t_0=\SI{10}{\second}$ model to proceed for real-time implementation since it has the highest true positive rate. The positive class is now composed of samples taken only at \SI{0.2}{\second} before interlocks, while the negative class is taken at \SI{10}{\second} before interlocks. 