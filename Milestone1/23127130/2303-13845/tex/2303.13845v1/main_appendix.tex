\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{diagbox}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage{cite}
\usepackage{float,lscape}
\usepackage{authblk}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage{rotating}
\usepackage{adjustbox}
\usepackage{blindtext}
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\newcommand{\guansong}[1]{{\color{purple}[Guansong]: #1}}
\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{10957} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi % Required for inserting images


\title{Anomaly Detection under Distribution Shift\thanks{Corresponding author: G. Pang ({\tt pangguansong@gmail.com}).}}
\author[1]{Tri Cao}
\author[1]{Jiawen Zhu}
\author[1]{Guansong Pang}
\affil[1]{School of Computing and Information Systems, Singapore Management University}
\begin{document}

\maketitle
\begin{abstract}

Anomaly detection (AD) is a crucial machine learning task that aims to learn patterns from a set of normal training samples to identify abnormal samples in test data. Most existing AD studies
assume that the training and test data are drawn from the same data distribution, but the test data can have large distribution shifts arising in many real-world applications due to different natural variations such as new lighting conditions, object poses, or background appearances, rendering existing AD methods ineffective in such cases.
In this paper, we consider the problem of anomaly detection under distribution shift and establish performance benchmarks on three widely-used AD and out-of-distribution (OOD) generalization datasets. We demonstrate that simple adaptation of state-of-the-art OOD generalization methods to AD settings fails to work effectively due to the lack of labeled anomaly data. We further introduce a novel robust AD approach to diverse distribution shifts by minimizing the distribution gap between in-distribution and OOD normal samples in both the training and inference stages in an unsupervised way. Our extensive empirical results on the three datasets show that our approach substantially outperforms state-of-the-art AD methods and OOD generalization methods on data with various distribution shifts, while maintaining the detection accuracy on in-distribution data. The code will be available at \renewcommand\UrlFont{\color{blue}\tt}
\url{https://github.com/mala-lab/ADShift}.


\end{abstract}
\section{Introduction}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{Preview3.pdf}
    \caption{Illustrative samples for anomaly detection under distribution shift. First row: the `Wood' dataset from MVTec \cite{bergmann2019mvtec}. Second row: the `Elephant' class as normal and the remaining classes as anomaly in PACS \cite{li2017deeper}. Third row: the `0' class as normal and the remaining classes as anomaly in MNIST\cite{lecun1998gradient}/MNIST-M\cite{ganin2015unsupervised}. We aim at distinguishing anomalies from normal data in both in-distribution test data and out-distribution test data
    }
    \label{fig:intro}
\end{figure}
Anomaly Detection (AD) is a crucial task in machine learning that aims to identify rare and unusual patterns in data. It is an important problem in various domains, such as financial domain \cite{ahmed2016survey, anandakrishnan2018anomaly}, cybersecurity \cite{ten2011anomaly, siddiqui2019detecting}, industrial inspection \cite{bergmann2019mvtec}, and medical diagnosis \cite{schlegl2019f, shvetsova2021anomaly}. 
Due to the difficulty and/or high cost of collecting labeled anomaly data,
current AD studies are focused on unsupervised approaches, which aim to learn patterns from a set of normal training samples to identify abnormal samples in test data.

Although existing AD studies have demonstrated promising performance \cite{li2021cutpaste, salehi2021multiresolution, deng2022anomaly,pang2021deep}, they generally assume that the training and test data are drawn from the same data distribution. However, this assumption is often unrealistic in real-world scenarios as the test data can have large distribution shifts arising in many applications due to different natural variations such as new lighting conditions, object poses, or background appearances, rendering the AD methods ineffective in such cases.

Distribution shift is a ubiquitous problem in different real-world applications, which can significantly degrade the performance of models in various tasks such as image classification, object detection, and segmentation \cite{koh2021wilds, ganin2015unsupervised, li2017deeper, zhang2020generalizing}. Many out-of-distribution (OOD) generalization methods have been introduced to address this problem \cite{huang2020self, hendrycks2019augmix, zhang2022exact, carlucci2019domain, ghifary2015domain, lehner20223d, ma2020training, liu2021feddg, ouyang2022causality}.
These OOD generalization methods rely on large labeled training data from one or multiple relevant domains to learn domain-invariant feature representations. They often require class labels \cite{yao2022pcl, huang2020self, qiao2020learning}, domain labels \cite{zhao2021learning, yoon2019generalizable, wang2020cross, carlucci2019hallucinating}, or the existence of diverse data \cite{hendrycks2019augmix, zhang2022exact, zhoudomain} in the source domain to learn such robust feature representations.
However, the training data in the AD task consists of only one class, and the data is monotonous. Consequently, it is difficult to adapt existing OOD generalization techniques to address the AD under distribution shift problem. Trivial adaption of the OOD generalization can fail to learn generalized normality representations, leading to many detection errors, \eg, normal samples with distribution shifts cannot be distinguished from anomalous samples and consequently they are detected as anomaly. As shown by the exemplar data in Figure \ref{fig:intro}, normal samples in the in-distribution (ID) test data are very similar to the normal training data, and ID anomalies deviate largely from the normal data; however, due to the distribution shift, the normal samples in the OOD test data are substantially different from the ID normal data in terms of foreground and/or background features, and as a result, these normal samples can be falsely detected as anomaly. 

In this paper, we tackle the problem of anomaly detection under distribution shift. It is an \textit{OOD generalization} problem, aiming at learning generalized detection models to accurately detect normal and anomalous samples in test data with distribution shifts, while maintaining the effectiveness on in-distribution test data. This is different from the problem of \textit{OOD detection} \cite{
hendrycks2017baseline,hsu2020generalized,liu2020energy,ren2019likelihood,wang2022partial} that aims to equip supervised learning models with a capability of rejecting OOD/outlier samples as unknown samples for the sake of model deployment safety.
This work makes three main contributions in addressing the OOD generalization problem in the AD task:
\begin{itemize}
\item We present an extensive study of the distribution shift problem in AD and establish large performance benchmarks under various distribution shifts using three widely-used datasets adapted from AD and OOD generalization tasks.
Our empirical results further reveal that existing state-of-the-art (SOTA) AD and OOD generalization methods fail to work effectively in identifying anomalies under distribution shift.
\item We then propose a novel robust AD approach to diverse distribution shifts, namely \textit{generalized normality learning (GNL)}. GNL minimizes the distribution gap between ID and OOD normal samples in both the training and inference stages in an unsupervised way. To this end, we introduce a normality-preserved loss function to learn distribution-invariant normality representations, which enables GNL to learn generalized semantics of the normal training data at different feature levels. GNL also utilizes a test time augmentation method to further reduce the the distribution gap during the inference stage.
\item Extensive experiments show that our approach GNL substantially outperforms state-of-the-art AD methods and OOD generalization methods by over 10\% in AUCROC on data with various distribution shifts, while maintaining the detection accuracy on the ID test data.
\end{itemize}
\section{Related Work}
\subsection{Anomaly Detection} 

\textbf{One-class Classification.}
Some early methods for anomaly detection include one-class support vector machine (OC-SVM) \cite{scholkopf2001estimating} and support vector data description (SVDD) \cite{tax2004support}. More recently, Deep SVDD \cite{ruff2018deep} uses a deep neural network to identify anomalies with a SVDD objective. A number of methods \cite{chen2022deep,goyal2020drocc,wu2019deep,sabokrou2020deep,yi2020patch} is then introduced to learn more effective deep one-class description.
% , while Patch SVDD \cite{yi2020patch} learns patch-wise semantic contexts from normal data using a similar objective.

\textbf{Reconstruction-based Methods.} One popular AD approach is to use autoencoder (AE) \cite{kingma2013auto}. AE-based anomaly detection learns normal patterns from a dataset to reconstruct new samples, assuming that anomalous samples have higher reconstruction errors due to distribution differences. There are many works following this direction and gaining good performance \cite{gong2019memorizing,hou2021divide,park2020learning,yan2021learning,zavrtanik2021reconstruction,pourreza2021g2,zaheer2020old}. 

\textbf{Self-supervised Learning Methods.} The use of data augmentation techniques is becoming increasingly prevalent in AD. One such strategy involves incorporating synthetic anomalies into datasets that are otherwise free of anomalies \cite{li2021cutpaste, yan2021learning, zavrtanik2021reconstruction}. 

\textbf{Knowledge Distillation.} Another popular line of research is knowledge distillation-based methods. A student-teacher framework with discriminative latent embeddings is introduced in \cite{bergmann2020uninformed}. Many improved versions for AD are then introduced \cite{salehi2021multiresolution,wang2021student,deng2022anomaly}. Anomaly Detection via Reverse Distillation (RD4AD) \cite{deng2022anomaly} is the latest one and gains SOTA performances on many datasets. 

All these methods are focused on AD with the same distribution in training and test data, which fail to work well on data with distribution shift.

\subsection{OOD Generalization} 

\textbf{Data Augmentation.} One popular approach for OOD generalization is based on data augmentation. Methods in this line involve generating new data samples from existing ones to increase the size and diversity of the training data. The model can then learn more about the underlying data distribution and become more robust to changes in the test data \cite{otalora2019staining, chen2020improving, zhang2020generalizing, sinha2017certifying, hendrycks2019augmix, zhang2022exact}.

\textbf{Unsupervised Learning.} By solving pretext tasks, a model can develop general features that are not specific to the target task. As a result, the model is less likely to be influenced by biases that are unique to a particular domain, which helps to avoid overfitting and increase generalization ability to different unseen data \cite{carlucci2019domain, ghifary2015domain, wang2020learning, maniyar2020zero, bucci2021self, albuquerque2020improving}.

Although these two types of methods are not designed for AD, they can be easily adapted for AD as they do not require class or domain labels during training. On the other hand, many existing OOD generalization methods, such as domain alignment \cite{muandet2013domain, hu2020domain, jin2020feature, mahajan2021domain, li2020domain, li2018domain, zhao2020domain}, meta-learning \cite{dou2019domain, li2021sequential, du2020learning, du2021metanorm, wang2020meta}, and disentangled representation learning \cite{li2017deeper, khosla2012undoing, chattopadhyay2020learning, piratla2020efficient, ilse2020diva, wang2020cross}, require class/domain-related supervision, which are inapplicable for the AD task. A similar issue exists for OOD generalization methods designed for multi-class problems \cite{du2020learning, huang2020self}. There are some cross-domain AD methods \cite{lu2020few, lv2021learning,ding2022catching}, but they require class labels in the ID data or few training samples from the target domain. By contrast, we focus on unsupervised AD and do not require any OOD data available during training. They focus on video data while we focus on image data.

\section{Problem Formulation and Challenges}


\subsection{Problem Formulation}
Let $\mathcal{X}_s$ and $\mathcal{X}_t$ denote the source (ID) and target (OOD) distributions, respectively, where $\mathcal{X}_s$ is used for both training and testing phase,  while $\mathcal{X}_t$ is only used for inference period. We assume that during training, only normal data from $\mathcal{X}_s$ is available, \ie, $\mathcal{D}_s = \{{x \in \mathcal{X}_s \mid y = 0}\}$, where $y \in \{0,1\}$ is the binary label indicating whether $x$ is a normal ($y=0$) or abnormal ($y=1$) sample. During testing, data can be normal or abnormal, and can be from either the source or target distribution, \ie, $\mathcal{D}_t = \{{ x \in \mathcal{X}_s \cup \mathcal{X}_t}\ \mid y = \{0,1\}\}$. The goal is then to develop an unsupervised anomaly detection model that can effectively handle distribution shift and accurately detect anomalies in $\mathcal{D}_t$. Specifically, we aim to learn a function $f:\mathcal{X}\rightarrow \mathbb{R}$ that assigns an anomaly score to each sample $x$ in a way such that $\forall x_i, x_j \in \mathcal{D}_t, \ f(x_i) < f(x_j) $ when $y_i=0$ and $y_j=1$.

\subsection{The Challenges} 
The current approaches in AD involve explicit fitting of the normal training data \cite{deng2022anomaly, salehi2021multiresolution, akcay2019ganomaly, schlegl2019f}. It can cause the model to learn irrelevant features that are not associated with the appearance of normal data, \eg, the model may mistake domain-specific background information as normal features, resulting in inaccurate anomaly detection when there are distribution shits presented.
OOD generalization models are also significantly challenged by the studied setting.
This is mainly because the training data in the AD task consists of only one class and the data is monotonous, making it difficult to learn and identify patterns that distinguish normal and anomalous instances. Current OOD generalization approaches used in classification, detection, and segmentation need to take into account class labels, domain labels, or the diversity of samples in the training data \cite{du2020learning, huang2020self,wang2020cross, wang2020meta}, which often are not applicable to AD tasks. As a result, new methods are required that can effectively address the problem of AD under distribution shift.

Fig. \ref{fig:challenge} illustrates this issue, where models such as RD4AD \cite{deng2022anomaly} (a recent SOTA AD model) and Mixstyle \cite{zhoudomain} (an OOD generalization method that we use to combine with RD4AD) are seen to struggle with identifying normal samples in the presence of distribution shift, often misclassifying them as anomalous. The overlapping of histograms of the anomaly scores for the normal and abnormal samples indicates that these models have learned features that are not representative of normal data, which can be a major obstacle in detecting anomalies. One of the main reasons is that the background or style features w.r.t. a specific dataset can change due to different natural conditions. As a result, the model may mistake these changed features as anomalies, leading to normal samples in the shifted distribution being classified as anomalous with high anomaly scores. Furthermore, some abnormal samples in the OOD data may possess similar features to background or style features in the training data, leading to them being misclassified with low anomaly scores.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{ChallengeHouse2.pdf}
    \caption{Anomaly scores of RD4AD \cite{deng2022anomaly}, Mixstyle \cite{zhoudomain} and our model GNL on PACS \cite{li2017deeper} when selecting `house' as the normal class and the remaining classes as anomaly classes.}
    \label{fig:challenge}
\end{figure}

\section{Our Approach}
\begin{figure*}[h]
    \centering
    \includegraphics[width=\textwidth]{proposedFramework.pdf}
    \caption{Overview of our approach. (a) Distribution-invariant normality learning in the training phase. (b) Test time augmentation with feature distribution matching in the inference phase.}
    \label{fig:proposedframework}
\end{figure*}


To address these challenges, we introduce a novel approach, namely generalized normality learning (GNL). GNL minimizes the distribution gap between ID and OOD normal samples in both the training and inference stages in an unsupervised way. To this end, we introduce a normality-preserved loss function to learn distribution-invariant normality representations, which enables GNL to learn generalized semantics of the normal training data at different feature levels. GNL further utilizes an AD-oriented test time data augmentation method based on feature distribution matching to improve the generalization performance. Fig.\ref{fig:proposedframework} describes the two main components of our approach: (a) distribution-invariant normality learning for training, and (b) test time augmentation methods.
The two components complement to each other, meaning that the distribution-invariant normality learning process used during training can support the test time augmentation methods used during testing, and vice versa. 

\subsection{Distribution-invariant Normality Learning}

In order to improve the performance of model on OOD datasets while maintaining good performance on ID datasets, we aim to train a student model to be more robust to changes in the distribution of data, while still ensuring that the student overfits on the normal features. 
Fig.\ref{fig:proposedframework} (a) illustrates the training framework. 

Our method is built on top of the RD4AD model introduced by Deng et al. \cite{deng2022anomaly} that achieves state-of-the-art results on various datasets. The RD4AD framework includes three components: a fixed teacher encoder, a trainable one-class bottleneck embedding module, and a student decoder. When given an input sample, the teacher encoder extracts multi-scale representations, and the student decoder is trained to reconstruct the features from the bottleneck embedding. During testing, the teacher encoder can identify abnormal and OOD features in anomalous samples, but the student decoder fails to reconstruct these features. The model then considers anomalous representations that have low similarity as highly abnormal.

We propose to incorporate a similarity loss that quantifies the difference between the embedding features of the original samples and those of each transformed normal sample that represents a distinct style from the original data. Specifically, we enforce this loss at both the bottleneck layer and the final block of the decoder. To provide further clarity, we propose the inclusion of a loss term, denoted as $\mathcal {L}_{abs} $, which is integrated at the bottleneck layer of the encoder. Moreover, we also introduce another loss term, termed as $\mathcal {L}_{lowf}$, that is added at the final block of the student decoder architecture. Particularly, given a sample $x \in \mathcal{D}_s$, we
first apply an augmentation function $\mathcal{T(.)}$ on it, and let $x'_k =  \mathcal{T}(x)$ where $k \in [1,N]$ with $N$ is the number of augmented normal samples generated by data augmentation,
% . $N$ generated samples, along with the original sample are fed into RD4AD. Denote by 
and $\phi$ be the mapping that projects the raw image $I$ into the embedding space at the bottleneck layer, then we define $\mathcal {L}_{abs} $ as:
\begin{equation}
 \mathcal{L_{\text{abs}}} = \sum _{k=1}^{N}\frac {1}{N} \bigg \{ \mathcal {L}_{sim}(\phi(x),\phi(x'_k))\bigg \} 
 \label {eq:lossabtract}, 
\end{equation}
where $\mathcal {L}_{sim}(.,.)$ is a cosine similarity-based loss function. 

Let $\omega$ be a reconstruction function from the abstract features to the low-level features at the final block of the decoder, then we further define $\mathcal {L}_{lowf} $ as:
\begin{equation}
 \mathcal {L}_{lowf}  = \sum _{k=1}^{N}\frac {1}{N} \bigg \{ \mathcal {L}_{sim}(\omega(\phi(x)),\omega(\phi(x'_k)))\bigg \}. 
 \label{eq:losslowfeature}
\end{equation}

We combine these loss functions to introduce the distribution-invariant, normality-preserved loss function:
\begin{equation}
 \mathcal {L} = \lambda _{Ori}*\mathcal {L}_{Ori} + \lambda _{abs} * \mathcal {L}_{abs} + \lambda _{lowf} * \mathcal {L}_{lowf} 
  \label{eq:sumloss}, 
\end{equation}
where $\mathcal{L}_{Ori}$ is the original loss of RD4AD, and $\lambda _{Ori}$, $\lambda _{abs}$, and $\lambda _{lowf}$ are hyperparameters that determine how much weight should be given to each type of loss function.
% and $\mathcal {L}_{Ori}$ is the loss in the original RD4AD framework. 

We adopt AugMix \cite{hendrycks2019augmix} as the data augmentation method. Still, we remove the augmentation types that have the potential to generate anomalies, \eg, `shear\_x', `shear\_y', `translate\_x', and `translate\_y', to ensure that all generated data are normal samples.

Intuitively, the last block of decoder is responsible for reconstructing simple and low-level features, such as edges, corners, and blobs, while the bottleneck layer is responsible for extracting more complex and high-level features. At the bottleneck layer, the abstracted information of the same images from different synthesized methods must be the same, while retaining enough information for reconstruction in the decoder. Therefore, by minimizing the loss function in Eq. \ref{eq:sumloss}, GNL learns features from both low-layer CNNs and high-level CNNs respectively to be the same from different distributions generated from a single sample. 

\subsection{Test Time Augmentation for Anomaly Detection under Distribution Shift}

The goal of this component is to address the problem of a mismatch between the distribution of data during testing. To accomplish this, we propose injecting training distribution into the inference samples by using Feature Distribution Matching (FDM) at multi-level layers of the teacher encoder in the inference phase. The proposed testing framework is demonstrated in Figure \ref{fig:proposedframework} (b). Our Test Time Augmentation is applied at the first two residual blocks of the teacher encoder. The inference process from the third residual block onwards, as well as the calculation of the anomaly score, follow the original RD4AD framework without any modifications.

Some previous studies focused on FDM assume that the input features follow a Gaussian distribution \cite{huang2017arbitrary, lu2019closed, mroueh2020wasserstein} . More recently, Zhang et al. \cite{zhang2022exact} have discovered more accurate methods, known as Exact Feature Distribution Matching (EFDM). All these FDM techniques are applicable to our proposed framework. Noted that, FDM have been used for OOD Generalization, \eg, in Mixstyle \cite{zhoudomain} and EDFMix \cite{zhang2022exact}, but they are used during training with the goal of creating new distribution samples by mixing the styles of the samples available in the training set, while we adopt FDM as a component in the inference stage with a different objective.

Specifically, given a test sample $p \in \mathcal{D}_t$, we randomly select a training normal sample $ q \in \mathcal{D}_s$. These two samples are then fed into the teacher encoder. Let $\mathcal P^m$ and $\mathcal Q^m$ be the embedded features of $p$ and $q$ at the residual encoding block $E^m$, respectively, then the testing process is performed as follows:
\begin{equation}
\begin{cases}
\mathcal P^{m+1} = \text{FDM}(E^{m+1}(\mathcal P^{m}), \mathcal Q^{m+1},\alpha) \\
\mathcal Q^{m+1} = {E}^{m+1}(\mathcal Q^{m})\\
\mathcal P^{0} = x, \mathcal Q^{0} = q,\\
\end{cases}
\label{equa:test}
\end{equation}
where $ m \in \{0,1\}$, and $\alpha$ is a hyperparameter balancing the severity for mixing the style between the inference sample and the selected normal sample. The processed embedded features $\mathcal P^{1} \text{ and } \mathcal P^{2}$ are then input into the bottleneck layer and participate in the calculation of anomaly scores following the inference process of the original RD4AD.

In essence, the sample $q$ plays a role in conveying distribution information pertaining to the training data. The selection of a random sample is due to the monotonous nature of the data during training, as any sample in the training set is capable of carrying distribution information that represents the training data. Consequently, devising a process for sample selection during training is computationally expensive and inefficient.

By utilizing FDM, our proposed testing process minimizes the disparity between the feature distribution of the inference sample and the feature distribution of normal samples in the training data, in cases where inference samples come from OOD sets. Furthermore, FDM ensures that the feature distribution remains nearly unchanged if inference samples come from ID sets, since the distribution of the test sample is aligned with its own distribution. Therefore, our testing approach can improve performance on OOD data without sacrificing performance on ID data.

\section{Experiments}
\subsection{Datasets}
We adapt three datasets from both AD and OOD generalization as the dataset benchmarks for the studied task.

\textbf{Anomaly Detection.}
\textbf{MVTec} \cite{bergmann2019mvtec} is a widely-used AD benchmark, which comprises 15 data subsets for industrial defect inspection,
including 5 subsets on texture anomalies and 10 subsets on object anomalies. The training dataset consists of 3,629 images in total, all of which are normal images. In contrast, the test dataset contains a total of 1,725 images, comprising both defective and non-defective instances. In order to generate OOD datasets for MVTec, we apply 4 types of visual corruptions to MVTec \cite{bergmann2019mvtec}: Brightness, Contrast, Defocus Blur, and Gaussian noise. The severity for each type of corruption is set to 3 for all the out-of-distribution data. 

\textbf{OOD Generalization.} :
Two popular OOD benchmarks, \textbf{MNIST-M} \cite{ganin2015unsupervised} and \textbf{PACS} \cite{li2017deeper}, are taken in our experiments.
% \textbf{Handwritten Digit Recognition.}  We use 
In particular, the primary MNIST \cite{lecun1998gradient} is used as the ID data on which the models are trained on, while MNIST-M is used as the OOD set. MNIST and MNIST-M datasets share 10 classes, which correspond to the digits 0 through 9. While MNIST encompasses 70,000 grayscale images of handwritten digits, MNIST-M contains 68,000 OOD images that are synthesized by superimposing random colored patches on the original images from MNIST. PACS is another widely used OOD dataset consisting of 9,991 images, which are shared by seven classes and four domains, namely Art, Cartoon, Photo, and Sketch. We select the images in Photo as the ID data, with the images in Art, Cartoon, and Sketch as the OOD data. 
The commonly used one-versus-all protocol \cite{perera2019ocgan} is used to convert the these two datasets into AD datasets with distribution shift, in which samples of one class are used as normal, with the rest of classes as anomaly classes. 
During training, we only use images in the ID dataset, \ie, assuming the OOD data is not available during training. During inference, test sets of both ID and OOD are used.

\subsection{\textbf{Baselines}}
We conduct a series of experimental evaluations on 4 prominent anomaly detection methods, namely Deep SVDD \cite{ruff2018deep}, f-AnoGAN \cite{schlegl2019f}, KDAD \cite{salehi2021multiresolution}, and RD4AD \cite{deng2022anomaly}. These methods stand for popular AD methods and recent state-of-the-art (SOTA) AD models.
To evaluate the efficacy of OOD generalization techniques in anomaly detection, we adapt a suite of cutting-edge OOD methods by combining them with the recently proposed RD4AD model, which boosts SOTA performance on multiple datasets. Four different methods are used, including three data augmentation-based methods Augmix \cite{hendrycks2019augmix}, Mixstyle \cite{zhoudomain}, and EFDM \cite{zhang2022exact}, and one self-supervised method Jigsaw \cite{carlucci2019domain}. 

\subsection{Implementation Details}
Our proposed method GNL is implemented on top of the RD4AD framework. Therefore, we maintain the settings recommended by RD4AD, such as the image size, the optimization method, the way of calculating anomaly score, and other relevant parameters. The details can be found in Appendix. Regarding the specific parameters for our model GNL, we choose $N=2$ for the number of augmented normal samples generated by data augmentation. We set $\lambda_{Ori}=0.9, \lambda_{abs}=0.05 \text{ and } \lambda_{lowf}=0.05$ for the distribution-invariant, normality-preserved loss function. At inference phase, we select $\alpha=0.5$ for the severity of mixing the style, and EFDM \cite{zhang2022exact} as the FDM technique since it is the latest and shows SOTA performance. Note that these hyperparameters are applied to all 3 datasets.

For the AD baselines, we use the official implementation published by the authors of those baselines. 
However, since the original baselines did not include experiments on the PACS dataset, we use the hyperparameters from MVTec experiments to conduct experiments on the PACS dataset corresponding to each baseline. 

For the OOD generalization baselines, we use Augmix with an online augmentation severity of 3 for MNIST and PACS datasets. We use all the data augmentation types included in Augmix for MNIST and PACS. However, for the MVTec dataset, we exclude two types of augmentation that overlap with two types of corruptions during testing: Brightness and Contrast. With Mixstyle and EFDM, which are two data augmentation methods at the feature level (rather than at the image level like Augmix), we apply Mixstyle and EFDM to the encoders in the first two network layer according to the settings in RD4AD. As for Jigsaw, we fit the Jigsaw task into the Bottleneck component in RD4AD. All hyperparameters of training are preserved when applying OOD generalization baselines into RD4AD.

Following previous studies \cite{ruff2018deep, schlegl2019f, salehi2021multiresolution, deng2022anomaly,ding2022catching}, we evaluate the performance of our anomaly detection methods using a metric called the Area Under the ROC Curve (AUROC). This metric is commonly used to assess how well a given method is able to distinguish between normal and anomalous data points. The results are averaged over three independent runs.

\subsection{Comparison Results}

The performance of our model GNL and the baselines on MVTec, MNIST, and PACS are shown in Tables \ref{tab:mvtec}, \ref{tab:mnist}, and \ref{tab:pacs}, respectively. Note that due to space limitations, the performances in all three tables are the average results of the classes per dataset. Detailed results are presented in Appendix. Overall, GNL can significantly outperforms SOTA AD models and OOD generalization methods in detecting anomalies on the OOD test data, while at the same time maintaining the detection accuracy on the ID data. Below we discuss the results in detail.

\subsubsection{Performance of AD Methods}
In general, we observe a significant drop in the AUC scores of all AD methods, Deep SVDD, f-AnoGAN, KDAD and RD4AD, on the OOD data across all three datasets used. This indicates that their performance is severely affected by the distribution shift. In particular, the performance of all AD models is promising on the MNIST set. However, this performance is reduced by about 30-40\% when the models are tested on the MNIST-M set, which contains variations that are not present in the original MNIST set. Similar trends are observed in the PACS dataset, where the models' performance is also significantly affected by the distribution shifts in the OOD data. The models perform well on the Photo data, which is the ID data, but their performance drops significantly on the three OOD datasets, Art, Cartoon and Sketch. On the MVTec dataset, the performance still drops but is less severe than on the other two sets.


\begin{table}[h]
\centering
\scalebox{0.8}{
\begin{tabular}{l|c|c|c|c|c}
\hline
& \multicolumn{1}{c}{ID} & \multicolumn{4}{|c}{OOD} \\
\cline{2-5}
\hline
Method & MVTec & Brightness & Contrast & Blur & Noise \\
\hline
Deep SVDD & 69.98 & 55.18 & 50.07 & 68.82 & 59.11 \\
f-AnoGAN & 75.65 & 48.36 & 49.29 & 37.98 & 39.10\\
KDAD & 85.50 & 83.81 & 64.03 & 84.17 & 82.04 \\
RD4AD & \textbf{98.64} & 96.50 & 94.12 & \textbf{98.9} & 90.14 \\
\hline
Augmix & 96.29 & 95.10 & 94.51 & 95.39 & 90.99 \\
Mixstyle & 98.58 & 96.60 & 94.45 & 98.27 & 88.92 \\
EFDM & 98.64 & 96.78 & 94.77 & 98.25 & 89.29 \\
Augmix+Mixstyle & 96.78 & 96.86 & 94.57 & 98.73 & 90.12 \\
Augmix+EFDM & 97.04 & 96.83 & 95.21 & 98.11 & 90.18  \\
Jigsaw & 73.97 & 73.36 & 67.88 & 73.88 & 72.60 \\

\hline
GNL (Ours) & 97.99 & \textbf{97.43} & \textbf{97.46} & 97.77 & \textbf{94.10} \\
\hline
\end{tabular}
}


\caption{AUROC (\%) results on MVTec and its four corruptions. The best performance is \textbf{boldfaced}.}
\label{tab:mvtec}
\end{table}


\begin{table}[h]
\centering
\scalebox{0.9}{
\begin{tabular}{c|c|c}
\hline
Method  & MNIST (ID) & MNIST-M (OOD)\\
\hline
Deep SVDD & 97.73 & 49.92 \\
f-AnoGAN & 97.52 & 52.72 \\
KDAD & 98.87 & 54.87 \\
RD4AD & \textbf{98.89} & 58.09 \\
\hline
Augmix & 98.26 & 59.61 \\
Mixstyle & 98.84 & 57.22 \\
EFDM & 98.62 & 57.23 \\
Augmix+Mixstyle & 98.12 & 58.89   \\
Augmix+EFDM & 98.24 & 58.91 \\
Jigsaw & 98.90 & 58.51 \\
\hline
GNL (Ours) & 96.91 & \textbf{70.87} \\
\hline
\end{tabular}
}
\caption{AUROC results (\%)  on in-distribution (MNIST) and out-of-distribution (MNIST\-M) datasets.}
\label{tab:mnist}
\end{table}
% 

\begin{table}[h]
\centering
\scalebox{0.9}{
\begin{tabular}{l|c|c|c|c}
\hline
& \multicolumn{1}{c}{ID} & \multicolumn{3}{|c}{OOD}  \\
\cline{2-5}
\hline
Method & Photo & Art & Cartoon & Sketch  \\ \hline
Deep SVDD   & 40.87&	53.42 &	41.23 & 	39.48 \\
f-AnoGAN &  61.34 &  50.15 &  52.42 &  63.77   \\
KDAD &  \textbf{88.17} &  62.86 &  62.64 &  51.40 \\
RD4AD &  81.49 &  61.07 &  60.34 &  55.06  \\
\hline
Augmix &  76.35 &  60.50 &  58.96 &  57.86  \\
Mixstyle &  78.23 &  60.93 &  60.93 &  54.89 \\
EFDM &  78.47 &  60.55 &  62.15 &  55.63  \\
Augmix+Mixstyle & 76.12 & 60.16 &  61.29 & 55.76\\
Augmix+EFDM & 77.28 & 60.93 &  63.18 & 56.67\\
Jigsaw &  62.19 &  52.55 &  53.83 &  62.15  \\
\hline
GNL (Ours) &  87.67 &  \textbf{65.62} &  \textbf{67.96} &  \textbf{62.39}  \\ \hline
\end{tabular}
}
\caption{AUROC results (\%) on in-distribution (Photo) and out-of-distribution (Art, Cartoon, Sketch) datasets.}
\label{tab:pacs}
\end{table}

\subsubsection{Performance of Combined OOD Generalization and AD Methods}
Our results in Tables \ref{tab:mvtec}, \ref{tab:mnist}, and \ref{tab:pacs} indicate that the detection performance cannot be significantly improved by combining different OOD generalization techniques with the recent SOTA AD model RD4AD on the three datasets. This lack of improvement can be attributed to the fact that these OOD methods attempt to increase the diversity of data by enriching the available data based on its own distribution. However, because the training data in AD is typically monotonous and unimodal, these OOD methods often fail to generate data samples that significantly deviate from the original data distribution. As a result, the added diversity of generated data is not sufficient to significantly improve the performance of AD models.

Moreover, these OOD techniques also have a tendency to generate undesired anomaly data, which is akin to injecting noise into the training data, thereby reducing the performance of AD models on the in-distribution dataset.

\subsubsection{Performance of Our Method GNL}

On the MVTec AD dataset in Table \ref{tab:mvtec}, our method shows remarkable improvement in performance on the OOD dataset, while maintaining the performance on the ID data. In fact, our method achieves a highly comparable AUROC score of 0.9799 on the original MVTec ID data, while also obtaining an impressive AUROC score of 0.9743 on the Brightness, 0.9746 on Contrast, 0.9776 on the Defocus\_blur dataset, and 0.9410 on Gaussian Noise, which are significant improvements over the other methods. These results demonstrate the robustness and effectiveness of our GNL model to diverse distribution shifts. 

On the MNIST/MNIST-M dataset in Table \ref{tab:mnist}, GNL consistently and significantly outperforms all other methods on the OOD data MNIST-M, increasing by at least 10 AUROC scores. Compared to the best performer -- RD4AD -- on the ID dataset that obtains an AUROC score of 0.9889, GNL exhibits a small decline and obtains an AUROC score of 0.9691. However, a significant improvement in performance is observed on the MNIST-M dataset, with an AUROC score of 0.7087 compared to 0.5809 for RD4AD.

Similarly, GNL achieves consistently more superior AUROC performance on all three OOD datasets of PACS in Table \ref{tab:pacs}. In particular, GNL obtains AUROC scores of 0.6562, 0.6796, and 0.6239 for the Art, Cartoon, and Sketch datasets, respectively, increasing by at least 5\% on the Art and Cartoon datasets over the competing models. These results indicate that our method is highly effective at detecting anomalies in various domain shifts. Compared to RD4AD, our method not only largely improves the OOD performance, but also enhances its performance on the ID data, the Photo data. This is because the Photo data contains multiple sub-domains, and RD4AD can be susceptible to overfitting on a specific sub-domain in the training data. By contrast, our method helps to mitigate this issue by learning more generalized normality representations and improve performance across all sub-domains within the Photo data. The performance of GNL on the ID data is also highly comparable to the best performer KDAD, 0.8767 vs. 0.8817, whereas GNL outperforms KDAD on the three OOD datasets by about 3\%-10\% in AUROC.

\subsection{Robustness to Various Distribution Shift Levels}

Figure \ref{fig:changingseverity} presents the results of the robustness of GNL to varying levels of distribution shift, using the best competing methods RD4AD, Augmix and EFDM as baselines. The experiments are done on MVTec with increasing levels of `Contrast' corruption. Notably, the performance of the baselines exhibits a significant decline as the severity of corruption amplifies.
The reason behind this phenomenon is intuitive as increased corruption severity introduces more substantial distribution variance, making it arduous for the models to discern between anomalous and normal samples. Our proposed method, on the other hand, demonstrates remarkable stability in performance across multiple levels of distribution shift. Our method maintains stable performance when the severity is between 1 and 3, and reduces to about 0.90 AUROC when the severity is 4 and 5, decreasing about 5\% AUROC vs. about 30\%-35\% decrease in the competing methods. These results indicate
strong robustness of GNL to heavy distribution shifts.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.49\textwidth]{changingseverity.pdf}
    \caption{AUROC results on MVTec with varying severity of the `Contrastâ€™ corruption.}
    \label{fig:changingseverity}
\end{figure}

\subsection{Ablation Study}



We examine the importance of two main components in our method, Distribution-invariant Normality Learning (DINL) and AD-oriented Test Time Augmentation (ATTA) using the PACS datase, with RD4AD as the baseline. The results are reported in Table \ref{tab:ablation}. Generally, all two components positively contribute to the superior performance of GNL. In particular, the experimental results show that if only the test time augmentation is applied, we gain about 2\% AUROC improvement over the baseline on the OOD datasets, but it leads to a slight performance decrease on the ID data. 
When DINL is applied, it results in substantial improvement across both ID and OOD datasets, having 4\%-7\% AUROC improvement. When both are applied, we obtain the best performance, resulting in further substantial AUROC improvement. This indicates that both components, one reducing the distribution gap during training and another reducing the gap during inference, can well complement each other.

\begin{table}[h]
\centering
\scalebox{0.9}{
\begin{tabular}{c|c|c|c|c}
\hline
& \multicolumn{1}{c}{ID} & \multicolumn{3}{|c}{OOD} \\
\cline{2-5}
\hline
 Method & Photo & Art & Cartoon & Sketch \\
\hline
Baseline &  81.49 &  61.07 &  60.34 &  55.06 \\
\hline
ATTA &  81.05 &  64.36 &  62.04 &  57.04 \\
\hline
DINL &  85.71 &  62.34 &  65.63 &  57.12 \\
\hline
DINL+ATTA &  \textbf{87.67} &  \textbf{65.62} &  \textbf{67.96} &  \textbf{62.39} \\\hline
\end{tabular}
}
\caption{AUROC results (\%) of ablation study.}
\label{tab:ablation}
\end{table} 

\subsection{Hyperparameter Analysis}
Fig. \ref{fig:alpha} depicts how the performance of our model GNL changes with varying $\alpha$, which is a hyperparameter in ATTA. 
The results suggest that the effectiveness of our model remains consistent across different $\alpha$ values on the Photo and Cartoon datasets. In contrast, the model's ability to detect anomalies on the Art data appears to improve as $\alpha$ increases. However, for the Sketch data, the model's performance reaches its maximum at $\alpha = 0.4$ and slightly decreases as $\alpha$ increases further. Overall, a medium value, \eg, $\alpha=0.5$, is generally recommended in practice.


\begin{figure}[h]
    \centering
    \includegraphics[width=0.49\textwidth]{Alpha.pdf}
    \caption{AUROC results using varying $\alpha$.
    The smaller the $\alpha$ value, the lower the severity of style transfer.}
    \label{fig:alpha}
\end{figure}

\section{Conclusion}
In this work we propose a novel approach, namely GNL, to addressing the problem of anomaly detection in the presence of distribution shifts. GNL improves the generalization of the detection model by reducing the distribution gap between ID and OOD normal data in both training and inference stages. We also present comprehensive performance benchmarks and reveal that combined AD and OOD generalization methods do not work well for this task. Our approach is specifically designed for the OOD generalization in the AD task and shows significant improvement over the competing baselines. As shown in our results, our approach GNL is also robust to heavy distribution shifts.
Overall, our approach represents an important contribution to unsupervised anomaly detection, as it addresses a more realistic problem that has not been adequately studied before.


{\small
\bibliographystyle{ieee_fullname}
\bibliography{refs}
}
\appendix



\include{apx}



\end{document}
