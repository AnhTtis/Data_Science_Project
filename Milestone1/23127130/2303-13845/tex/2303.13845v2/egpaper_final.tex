\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{diagbox}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage[sort]{natbib}
\setcitestyle{square}
\setcitestyle{comma}
% \usepackage[sort]{natbib}
% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\newcommand{\guansong}[1]{{\color{purple}[Guansong]: #1}}
\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{10957} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi % Required for inserting images

\title{Anomaly Detection under Distribution Shift}


\begin{document}

\maketitle
\begin{abstract}

Anomaly detection (AD) is a crucial machine learning task that aims to learn patterns from a set of normal training samples to identify abnormal samples in test data. 
% However, most previous works on anomaly detection
Most existing AD studies
% have focused on detecting anomalies within a single distribution, and have assumed
assume that the training and test data are drawn from the same data distribution, but the test data can have large distribution shifts arising in many real-world applications due to different natural variations such as new lighting conditions, object poses, or background appearances, rendering existing AD methods ineffective in such cases.
% remains stationary over time. 
In this paper, we consider the problem of anomaly detection under distribution shift and establish performance benchmarks on three widely-used AD and out-of-distribution (OOD) generalization datasets. We demonstrate that simple adaptation of state-of-the-art OOD generalization methods to AD settings fails to work effectively due to the lack of labeled anomaly data. We further introduce a novel robust AD approach to diverse distribution shifts by minimizing the distribution gap between in-distribution and OOD normal samples in both the training and inference stages in an unsupervised way. 
% propose a novel approach to anomaly detection that can handle the challenge of distribution shift, where the data distribution changes over time. We define a new problem that combines the challenges of anomaly detection and distribution shift, and introduce a benchmark dataset that includes different types of distribution shift. We propose a new training process and inference method that can improve the performance of the anomaly detection model on out-of-distribution data. Our proposed approach involves improving the generalization of the model during the training phase, as well as reducing the gap between in-distribution and out-of-distribution data during the inference phase.
Our extensive empirical results on the three datasets show that our approach substantially outperforms state-of-the-art AD methods and OOD generalization methods on data with various distribution shifts, while maintaining the detection accuracy on in-distribution data. 
% to evaluate the performance of our approach, and demonstrate that it outperforms existing methods for detecting anomalies in the presence of distribution shift. 
% To the best of our knowledge, this is the first work to introduce the context of distribution shift into the unsupervised anomaly detection.

\end{abstract}
\section{Introduction}
% \subsection{The Challenges} 

% \guansong{have you updated the introduction section based on our last meeting's comments? please do so if you haven't}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{Preview3.pdf}
    \caption{Illustrative samples for anomaly detection under distribution shift. First row: the `Wood' dataset from MVTEC \cite{bergmann2019mvtec}. Second row: the `Elephant' class as normal and the remaining classes as anomaly in PACS \cite{li2017deeper}. Third row: the `0' class as normal and the remaining classes as anomaly in MNIST\cite{lecun1998gradient}/MNIST-M\cite{ganin2015unsupervised}. We aim at distinguishing anomalies from normal data in both in-distribution test data and out-distribution test data
    % \guansong{changes to be made: `In-Distribution in Test Set' to `In-distribution Test Data';`Out-of-Distribution in Test Set' to `Out-of-distribution Test Data'; having different background colors for the columns of normal samples and anomalous samples may look more straightforward }
    }
    \label{fig:intro}
\end{figure}
Anomaly Detection (AD) is a crucial task in machine learning that aims to identify rare and unusual patterns in data. It is an important problem in various domains, such as financial domain \cite{ahmed2016survey, anandakrishnan2018anomaly}, cybersecurity \cite{ten2011anomaly, siddiqui2019detecting}, industrial inspection \cite{bergmann2019mvtec}, and medical diagnosis \cite{schlegl2019f, shvetsova2021anomaly}. 
% In anomaly detection, the goal is to distinguish normal patterns from abnormal patterns, which can be caused by various factors, such as errors, faults, attacks, or anomalies.
Due to the difficulty and/or high cost of collecting labeled anomaly data,
% and the difficulty in obtaining negative samples in many applications, 
% AD is often approached as an 
current AD studies are focused on unsupervised approaches, which aim to learn patterns from a set of normal training samples to identify abnormal samples in test data.
% . In unsupervised learning, the model is trained on a dataset of normal patterns, and then used to detect anomalies in new data. By being focused by the research community,
% the performance of AD models in many tasks is impressive, some models even achieve near-perfect accuracy \cite{li2021cutpaste, salehi2021multiresolution, deng2022anomaly}.

Although existing AD studies have demonstrated promising performance \cite{li2021cutpaste, salehi2021multiresolution, deng2022anomaly,pang2021deep}, they generally assume that the training and test data are drawn from the same data distribution. However, this assumption is often unrealistic in real-world scenarios as the test data can have large distribution shifts arising in many applications due to different natural variations such as new lighting conditions, object poses, or background appearances, rendering the AD methods ineffective in such cases.
% However, in real-world scenarios, the data distribution may change over time, due to various factors such as changes in the environment, data collection process, or system configurations. This phenomenon is known as 

Distribution shift is a ubiquitous problem in different real-world applications, which can significantly degrade the performance of models in various tasks such as image classification, object detection, and segmentation \cite{koh2021wilds, ganin2015unsupervised, li2017deeper, zhang2020generalizing}. Many out-of-distribution (OOD) generalization methods have been introduced to address this problem \cite{huang2020self, hendrycks2019augmix, zhang2022exact, carlucci2019domain, ghifary2015domain, lehner20223d, ma2020training, liu2021feddg, ouyang2022causality}. 
% Assuming only source domain data available, the target domain data can not access, DG try to develop a model that 
These OOD generalization methods rely on large labeled training data from one or multiple relevant domains to learn domain-invariant feature representations. They often require class labels \cite{yao2022pcl, huang2020self, qiao2020learning}, domain labels \cite{zhao2021learning, yoon2019generalizable, wang2020cross, carlucci2019hallucinating}, or the existence of diverse data \cite{hendrycks2019augmix, zhang2022exact, zhoudomain} in the source domain to learn such robust feature representations.
% from a single or multi source domains in the hope that it would remain discriminative given target domain data. 
% Despite the importance of distribution shift, most previous works on anomaly detection have focused on detecting anomalies within a single distribution, and have assumed that the data distribution remains stationary over time. This assumption is often unrealistic in real-world scenarios, and can lead to poor performance of the anomaly detection model when it encounters data that is different from the training distribution. The task of anomaly detection under distribution shift can be even more challenging compared to other tasks like classification or segmentation since 
However, the training data in the AD task consists of only one class, and the data is monotonous. Consequently, it is difficult to adapt existing OOD generalization techniques to address the AD under distribution shift problem. Trivial adaption of the OOD generalization can fail to learn generalized normality representations, leading to many detection errors, \eg, normal samples with distribution shifts cannot be distinguished from anomalous samples and consequently they are detected as anomaly. As shown by the exemplar data in Figure \ref{fig:intro}, normal samples in the in-distribution (ID) test data are very similar to the normal training data, and ID anomalies deviate largely from the normal data; however, due to the distribution shift, the normal samples in the OOD test data are substantially different from the ID normal data in terms of foreground and/or background features, and as a result, these normal samples can be falsely detected as anomaly. 
% since AD models are easily fooled by changes in features belonging to a particular domain as anomalies. 

% To address the challenge of distribution shift in anomaly detection, we propose a novel approach that combines the insights from both anomaly detection and domain adaptation. Our approach aims to improve the performance of the anomaly detection model on out-of-distribution data, by leveraging the knowledge of the underlying data distribution and adapting the model to the new distribution.

In this paper, we tackle the problem of anomaly detection under distribution shift. It is an \textit{OOD generalization} problem, aiming at learning generalized detection models to accurately detect normal and anomalous samples in test data with distribution shifts, while maintaining the effectiveness on in-distribution test data. This is different from the problem of \textit{OOD detection} \cite{
hendrycks2017baseline,hsu2020generalized,liu2020energy,ren2019likelihood,wang2022partial} that aims to equip supervised learning models with a capability of rejecting OOD/outlier samples as unknown samples for the sake of model deployment safety.
% aim to bridge the gap by introducing a new setting that combines the challenges of anomaly detection and the settings of domain generalization, and propose some techniques for addressing this problem. 
This work makes three main contributions in addressing the OOD generalization problem in the AD task:
\begin{itemize}
% \item We define a new problem that brings the context of distribution shift into the anomaly detection problem. By doing so, we hope to raise awareness of the importance of considering distribution shift in anomaly detection, and to motivate further research in this area. We introduce a new benchmark that includes different types of distribution shift. The benchmark is designed to evaluate the performance of anomaly detection models under distribution shift and show the effect of different types of distribution shift on the performance of different frameworks in anomaly detection. In addition, we examine the effectiveness of some existing methods in distribution shift problem when applied simply to anomaly detection models and see their performances. 
\item We present an extensive study of the distribution shift problem in AD and establish large performance benchmarks under various distribution shifts using three widely-used datasets adapted from AD and OOD generalization tasks. 
% We introduce a new benchmark that includes different types of distribution shift. The benchmark is designed to evaluate the performance of anomaly detection models under distribution shift and show the effect of different types of distribution shift on the performance of different frameworks in anomaly detection. In addition, 
Our empirical results further reveal that existing state-of-the-art (SOTA) AD and OOD generalization methods fail to work effectively in identifying anomalies under distribution shift.
% problem when applied simply to anomaly detection models and see their performances. 
\item We then propose a novel robust AD approach to diverse distribution shifts, namely \textit{generalized normality learning (GNL)}. GNL minimizes the distribution gap between ID and OOD normal samples in both the training and inference stages in an unsupervised way. To this end, we introduce a normality-preserved loss function to learn distribution-invariant normality representations, which enables GNL to learn generalized semantics of the normal training data at different feature levels. GNL also utilizes a test time augmentation method to further reduce the the distribution gap during the inference stage.
% novel training process and a test time augmentation method that can be easily applied to a state-of-the-art anomaly detection model and improve the performance on out-of-distribution data without sacrificing its performance on the in-distribution dataset. Our approach is a combination of making the model more general in the training phase and reducing the gap between in-distribution data and out-of-distribution data in the inference phase. We evaluate our proposed method on several benchmark datasets and show that it outperforms state-of-the-art methods in anomaly detection under distribution shift. 
\item Extensive experiments show that our approach GNL substantially outperforms state-of-the-art AD methods and OOD generalization methods by over 10\% in AUCROC on data with various distribution shifts, while maintaining the detection accuracy on the ID test data.
\end{itemize}
\section{Related Work}
% \guansong{it is too long. need to be more concise. Better to limit the intro and related work sections within two pages.}

\subsection{Anomaly Detection} 
% There are many unsupervised approaches that are proposed for anomaly detection. 

\textbf{One-class Classification.}
% Some very first methods are one-class support vector machine (OC-SVM)\cite{scholkopf2001estimating} and support vector data description (SVDD)\cite{tax2004support}. More recently, Ruff et al. (2018)\cite{ruff2018deep} proposed a method called deep one-class classification (DeepSVDD) that utilizes a deep autoencoder to learn a compressed representation of normal data and uses this representation to identify anomalies. Yan et al. (2021) introduced a novel unsupervised anomaly detection method that learns semantic context from normal samples using a deep convolutional neural network (PatchSVDD)\cite{yi2020patch}.
Some early methods for anomaly detection include one-class support vector machine (OC-SVM) \cite{scholkopf2001estimating} and support vector data description (SVDD) \cite{tax2004support}. More recently, Deep SVDD \cite{ruff2018deep} uses a deep neural network to identify anomalies with a SVDD objective. A number of methods \cite{chen2022deep,goyal2020drocc,wu2019deep,sabokrou2020deep,yi2020patch} is then introduced to learn more effective deep one-class description.
% , while Patch SVDD \cite{yi2020patch} learns patch-wise semantic contexts from normal data using a similar objective.

\textbf{Reconstruction-based Methods.} One popular AD approach is to use autoencoder (AE) \cite{kingma2013auto}. AE-based anomaly detection learns normal patterns from a dataset to reconstruct new samples, assuming that anomalous samples have higher reconstruction errors due to distribution differences. There are many works following this direction and gaining good performance \cite{gong2019memorizing,hou2021divide,park2020learning,yan2021learning,zavrtanik2021reconstruction,pourreza2021g2,zaheer2020old}. 

\textbf{Self-supervised Learning Methods.} The use of data augmentation techniques is becoming increasingly prevalent in AD. One such strategy involves incorporating synthetic anomalies into datasets that are otherwise free of anomalies \cite{li2021cutpaste, yan2021learning, zavrtanik2021reconstruction}. 
% By doing so, the unsupervised task of detecting anomalies is transformed into a supervised learning task, enabling the use of classification algorithms and other machine learning techniques that require labeled data. 

\textbf{Knowledge Distillation.} Another popular line of research is knowledge distillation-based methods. A student-teacher framework with discriminative latent embeddings is introduced in \cite{bergmann2020uninformed}. Many improved versions for AD are then introduced \cite{salehi2021multiresolution,wang2021student,deng2022anomaly}. Anomaly Detection via Reverse Distillation (RD4AD) \cite{deng2022anomaly} is the latest one and gains SOTA performances on many datasets. 

All these methods are focused on AD with the same distribution in training and test data, which fail to work well on data with distribution shift.
% In this paper, we present methods that can enhance the performance of RD4AD on out-of-distribution datasets while maintaining its performance on in-distribution data.
% The teacher network learns to encode normal data into a low-dimensional space, and the student network tries to mimic this behavior. Anomalies are then detected by measuring the difference between the student and teacher embeddings.

\subsection{OOD Generalization} 
% \guansong{please revise this section as suggested in our last meeting}

\textbf{Data Augmentation.} One popular approach for OOD generalization is based on data augmentation. Methods in this line involve generating new data samples from existing ones to increase the size and diversity of the training data. The model can then learn more about the underlying data distribution and become more robust to changes in the test data \cite{otalora2019staining, chen2020improving, zhang2020generalizing, sinha2017certifying, hendrycks2019augmix, zhang2022exact}.

\textbf{Unsupervised Learning.} By solving pretext tasks, a model can develop general features that are not specific to the target task. As a result, the model is less likely to be influenced by biases that are unique to a particular domain, which helps to avoid overfitting and increase generalization ability to different unseen data \cite{carlucci2019domain, ghifary2015domain, wang2020learning, maniyar2020zero, bucci2021self, albuquerque2020improving}.

Although these two types of methods are not designed for AD, they can be easily adapted for AD as they do not require class or domain labels during training. On the other hand, many existing OOD generalization methods, such as domain alignment \cite{muandet2013domain, hu2020domain, jin2020feature, mahajan2021domain, li2020domain, li2018domain, zhao2020domain}, meta-learning \cite{dou2019domain, li2021sequential, du2020learning, du2021metanorm, wang2020meta}, and disentangled representation learning \cite{li2017deeper, khosla2012undoing, chattopadhyay2020learning, piratla2020efficient, ilse2020diva, wang2020cross}, require class/domain-related supervision, which are inapplicable for the AD task. A similar issue exists for OOD generalization methods designed for multi-class problems \cite{du2020learning, huang2020self}. There are some cross-domain AD methods \cite{lu2020few, lv2021learning,ding2022catching}, but they require class labels in the ID data or few training samples from the target domain. By contrast, we focus on unsupervised AD and do not require any OOD data available during training. They focus on video data while we focus on image data.
% that usually only involve one or multiple domains without domain labels, which makes it difficult to apply some. 
% Additionally, some out-of-distribution (OOD) generalization methods that are designed for multi-class problems cannot also be applied to AD, which only exists one class during training \cite{du2020learning, huang2020self}. Therefore, there is a need for specific methods that can handle the challenges of AD under OOD settings.

% Nhìn chung, các phương pháp thuộc về Data Augmentation and Unsupervised Learning-based method can be directly applied to to anomaly detection khi mà nó không cần cả class label và domain label trong quá trình training. Besides that, there are some typical directions for multi-source setting including domain alignment \cite{muandet2013domain, hu2020domain, jin2020feature, mahajan2021domain, li2020domain, li2018domain, zhao2020domain}, meta-learning \cite{dou2019domain, li2021sequential, du2020learning, du2021metanorm, wang2020meta}, learning disentangled representations \cite{li2017deeper, khosla2012undoing, chattopadhyay2020learning, piratla2020efficient, ilse2020diva, wang2020cross} and so on. However, these methods can not be directly applied to anomaly detection because the settings of anomaly detection usually only have one domain or multi-domain without domain label. Một số phương pháp OOD generalization không cần domain label nhưng cần class label cho việc giúp model tổng quát hơn cũng không thể apply vào anomaly detection

% DG has typically been studied under two different settings\cite{zhou2022domain}, namely multi-source DG and single source DG.

% \textbf{Multi-source domain}  The majority of research has been dedicated
% to the multi-source setting, which assumes multiple distinct but relevant domains are available. Some typical directions for multi-source setting include domain alignment \cite{muandet2013domain, hu2020domain, jin2020feature, mahajan2021domain, li2020domain, li2018domain, zhao2020domain}, meta-learning \cite{dou2019domain, li2021sequential, du2020learning, du2021metanorm, wang2020meta}, learning disentangled representations \cite{li2017deeper, khosla2012undoing, chattopadhyay2020learning, piratla2020efficient, ilse2020diva, wang2020cross} and so on. However, these methods can not be directly applied to anomaly detection because the settings of anomaly detection usually only have one domain or multi-domain without domain label. 

% \textbf{Single-souce domain} The single-source scenario assumes that the training data is uniform. Data Augmentation is a common method that involves generating new data samples from existing ones to increase the size of the training dataset. By applying transformations to the original data, the model can learn more about the underlying data distribution and become more robust to changes in the test data \cite{otalora2019staining, chen2020improving, zhang2020generalizing, sinha2017certifying, hendrycks2019augmix, zhang2022exact}. An additional strategy to address the single domain shift issue is unsupervised learning, which involves training a model on unlabeled data without using explicit supervision from labeled data. \cite{carlucci2019domain, ghifary2015domain, wang2020learning, maniyar2020zero, bucci2021self, albuquerque2020improving}. However, not any of the methods in single DG can be applied to the problem of anomaly detection, as some methods are designed specifically for classification, segmentation, or require class labels of data that are unsupervised anomaly detection not available \cite{huang2020self, qiao2020learning}. 

% \guansong{add discussion here about the differences to the following cross-domain AD studies.

% Yiwei Lu, Frank Yu, Mahesh Kumar Krishna Reddy, and Yang Wang. Few-shot scene-adaptive anomaly detection. In European Conference on Computer Vision, pages 125±141. Springer, 2020.

% Hui Lv, Chen Chen, Zhen Cui, Chunyan Xu, Yong Li, and Jian Yang. Learning normal dynamics in videos with meta prototype network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 15425±15434, 2021.
% }
% We investigates the efficacy of combining appropriate Domain Generalization (DG) methods with the state-of-the-art (SOTA) model in anomaly detection. Our analysis indicates that merely applying these methods in a straightforward manner does not enhance the performance of AD model.
% Our study is close to some previous studies that focus on identifying abnormal events in videos. In these studies, the setting is that the videos used for training and testing are not from the same scene, which can affect the accuracy of the model. In contrast to the studies that worked on videos, our study focused on detect anomalous sample on a image. This means that we did not consider the information that exists between frames in videos. While videos provide temporal information that can be used to detect abnormal events, our study focused on using only the information in each individual image to make predictions.

% There are some previous studies closed with our work \cite{lu2020few, lv2021learning}. These works focus on identifying abnormal events in videos, where the training and testing videos are from different scenes. Meanwhile, our study aim to detect anomalous samples in images. Unlike video-based studies, we base solely on information in individual images to make predictions, without considering the temporal information between frames.

\section{Problem Formulation and Challenges}


\subsection{Problem Formulation}
Let $\mathcal{X}_s$ and $\mathcal{X}_t$ denote the source and target distribution, respectively, where $\mathcal{X}_s$ is used for both training and testing phase,  while $\mathcal{X}_t$ is only used for inference period. We assume that during training, only normal data from $\mathcal{X}_s$ is available, i.e., $\mathcal{D}_s = \{{x \in \mathcal{X}_s \mid y = 0}\}$, where $y \in \{0,1\}$ is the binary label indicating whether $x$ is a normal ($y=0$) or abnormal ($y=1$) sample. During testing, data can be normal or abnormal, and can be from either the source or target domain, i.e., $\mathcal{D}_t = \{{ x \in \mathcal{X}_s \cup \mathcal{X}_t}\ \mid y = \{0,1\}\}$

The goal is to develop an unsupervised anomaly detection algorithm that can effectively handle distribution shift and accurately detect anomalies in $\mathcal{D}_t$. Specifically, we find a function $f(x)$ that represents the anomaly score assigned to $x$. Such that: 
$\forall x_i, x_j \in \mathcal{D}_t, \ f(x_i) < f(x_j)   \leftrightarrow  y_i < y_j $.

Fig.\ref{fig:intro} shows some illustrative samples during training and testing according to our settings.

% $\forall x \in X_{normal}, \exists f : X \to \mathbb{R} \ \text{s.t.} \ \operatorname{anomaly}(x) < \operatorname{anomaly}(x') \ \forall x' \in X_{abnormal}$

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=0.45\textwidth]{settings.png}
%     \caption{Some illustrative samples during training and testing according to our settings.}
%     \label{fig:settings}
% \end{figure}




\subsection{The Challenges} 
The current approaches in AD involve overfitting models with normal training data \cite{deng2022anomaly, salehi2021multiresolution, akcay2019ganomaly, schlegl2019f}. Still, this strategy can cause the model to learn irrelevant features that do not accurately identify normal data. In some cases, the model may even mistake unique domain-specific information as normal features, resulting in inaccurate anomaly detection.

% Fig. \ref{fig:challenge} illustrates this issue, with models like RD4AD and RD4AD+Mixstyle struggling to identify normal samples in the shift distribution and misclassifying them as anomalous, and vice versa. The broad range of anomaly scores indicates that these models have learned features that are not representative of normal data. Background or style features unique to a particular domain can change when moving to another domain, causing the model to mistake them as anomalies, leading to normal samples in the shifted domain being classified as anomalous with high anomaly scores. Furthermore, some abnormal samples in the target domain may possess similar features to background or style features in the source domain, leading to them being misclassified with low anomaly scores.

Fig. \ref{fig:challenge} illustrates this issue, where models such as RD4AD\cite{deng2022anomaly} (the SOTA in ID) and RD4AD+Mixstyle (RD4AD combined with Mixstyle\cite{zhoudomain} in OOD generalization) are seen to struggle with identifying normal samples in the shift distribution, often misclassifying them as anomalous, and vice versa. The overlapping of histograms of normal and abnormal samples indicates that these models have learned features that are not representative of normal data, which can be a major challenge in detecting anomalies. One of the main reasons is that the background or style features unique to a particular domain can change when moving to another domain. As a result, the model may mistake these changed features as anomalies, leading to normal samples in the shifted distribution being classified as anomalous with high anomaly scores. Furthermore, some abnormal samples in the target domain may possess similar features to background or style features in the training data, leading to them being misclassified with low anomaly scores.

The problem of AD under distribution shift becomes even more challenging when the training data only contains a single class and comes from a single domain. This issue arises due to the homogeneity or monotony of the data, which can make it difficult to learn and identify patterns that distinguish normal and anomalous instances. In such cases, traditional OOD generalization approaches used in classification, detection, and segmentation need to take into account class labels, domain labels, or the diversity of samples in the training data\cite{du2020learning, huang2020self,wang2020cross, wang2020meta}, which may not be directly applicable to AD tasks. As a result, new methods are required that can effectively address the problem of AD under distribution shift in single-class, single-domain scenarios.

% This is because such approaches assume the presence of multiple classes and domains, which may not be the case in single-class AD tasks.

% To overcome these challenges, our proposed model learns domain-invariant normal features that are independent of any specific domain. This approach enables the model to accurately identify anomalies in new distributions, even if the distribution has shifted from the original training data. As shown in Fig. \ref{fig:challenge}, the anomaly score range of our model is greatly narrowed for both normal and abnormal samples, indicating that it has effectively learned domain-invariant features.
\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{ChallengeHouse2.pdf}
    \caption{Histogram of anomaly scores of RD4AD, RD4AD+Mixstyle and ours on PACS when selecting 'house' as a normal class and the remaining classes are anomaly.}
    \label{fig:challenge}
\end{figure}

\section{Our Approach}
% \guansong{please don't just describe the method in high-level texts; use formal symbols and equations to rigorously and precisely describe the method in both subsections.} \guansong{both subsections need to be significantly extended.}
\begin{figure*}[h]
    \centering
    \includegraphics[width=\textwidth]{proposedFramework.pdf}
    \caption{Overview of our approach. (a) The Distribution-invariant Normality Learning in training phase. (b) The Test time augmentation with Feature Distribution Matching in inference process.}
    \label{fig:proposedframework}
\end{figure*}
Fig.\ref{fig:proposedframework} describes our approach. The proposed approach consists of two main components: (a) Distribution-invariant Normality Learning process for training, and (b) Test time augmentation methods. The training process involves using a distribution-invariant normality learning process to learn distribution-invariant normality features that help the model to be more generalized. The testing process involves taking advantage of Feature Distribution Matching to reduce the gap between the source distribution and the target distribution. It is worth noting that the distribution-invariant normality learning process used during training can support the test time augmentation methods used during testing, and vice versa. 

% This is the combination of enlarging training distribution and reducing test distribution.
\subsection{Distribution-invariant Normality Learning (DNL)}
% \guansong{start with our intuition of the module; what specifically does this module do, and why it should work. the same principle is applied to the other section.}
% \textbf{Reverse Knowledge Distillation for Anomaly Detection}

% \textbf{Proposed Method}
Fig.\ref{fig:proposedframework} (a) illustrates the training framework. 
In order to improve the performance of model on OOD datasets while maintaining good performance on ID datasets, our objective is to train the student model to be more robust to changes in the distribution of data, while still ensuring that the student overfits on the normal features. 

% Về cơ bản, chúng tôi muốn the student có thể tổng quát hơn với sự thay đổi của data distribution, đồng thời the student vẫn overfit với các normal feature. Chỉ có như vậy thì performance của model mới được cải thiện trên OOD datasets mà vẫn giữ được performance tốt trên ID datasets

Our method is built on the RD4AD introduced by Deng et al.(2022)\cite{deng2022anomaly} that achieves state-of-the-art results on various datasets. RD4AD framework includes three components: a fixed teacher encoder, a trainable one-class bottleneck embedding module, and a student decoder. When given an input sample, the teacher encoder extracts multiscale representations, and the student decoder is trained to reconstruct the features from the bottleneck embedding. During testing, the teacher encoder can identify abnormal and out-of-distribution features in anomalous samples, but the student decoder fails to reconstruct these features. The proposed T-S model considers anomalous representations that have low similarity as highly abnormal.

We propose incorporating a similarity loss that quantifies the difference between the embedding features of the original sample and those of each transformed normal sample that represents a distinct style from the original. Specifically, we enforce this loss at both the Bottleneck layer and the final block of the decoder. To provide further clarity, we propose the inclusion of a loss term, labelled as $\mathcal {L}_{abs} $, which is integrated at the Bottleneck layer of the encoder. Moreover, we incorporate another loss term, termed as $\mathcal {L}_{lowf}$, that is added at the final block of the encoder architecture.

Given a sample $x \in \mathcal{D}_s$, we
first apply an augmentation function $\mathcal{T(.)}$ on it. Let $x'_k =  \mathcal{T}(x_k)$ where $k \in [1,N]$ with $N$ is the number of augmented normal samples are generated by data augmentation and $k$ is an integer. $N$ generated samples, along with the original sample are fed into RD4AD. Denote by $\phi$ the mapping that projects the raw image $I$ into the embedding space at the Bottleneck. The  $\mathcal {L}_{abs} $ is defined as \ref{eq:lossabtract}:
\begin{equation}
 \mathcal{L_{\text{abs}}} = \sum _{k=1}^{N}\frac {1}{N} \bigg \{ \mathcal {L}_{sim}(\phi(x),\phi(x'_k))\bigg \} 
 \label {eq:lossabtract}, 
\end{equation}
where $\mathcal {L}_{sim}(.,.)$ is the cosine similarity loss function. 

Let $\omega$ be a reconstructed function from the abstract features from Bottleneck to the low features at the final block of the decoder. The definition of $\mathcal {L}_{lowf} $ is:
\begin{equation}
 \mathcal {L}_{lowf}  = \sum _{k=1}^{N}\frac {1}{N} \bigg \{ \mathcal {L}_{sim}(\omega(\phi(x)),\omega(\phi(x'_k)))\bigg \} 
 \label {eq:losslowfeature}, 
\end{equation}

The added losses are incorporated to the original loss of RD4AD and minimized during training:
\begin{equation}
 \mathcal {L} = \lambda _{Ori}*\mathcal {L}_{Ori} + \lambda _{abs} * \mathcal {L}_{abs} + \lambda _{lowf} * \mathcal {L}_{lowf} 
  \label {eq:sumloss}, 
\end{equation}
where the values of $\lambda _{Ori}$, $\lambda _{abs}$, $\lambda _{lowf}$ are factors that determine how much weight should be given to each type of loss in relation to the others and $\mathcal {L}_{Ori}$ is the loss in the original RD4AD framework. 

We adopt AugMix as the data enrichment method. Still, we remove augmentation components in augment that have the potential to generate anomalies, namely 'shear\_x', 'shear\_y', 'translate\_x', and 'translate\_y' to ensure that all generated data are normal samples.

Intuitively, the last block of decoder is responsible for reconstructing simple and low-level features such as edges, corners, and blobs, while the Bottleneck is responsible for extracting more complex and high-level features. Therefore, we expect features from both low layer CNNs and high-level CNNs respectively to be the same from different distribution generated from a single sample. At Bottleneck, the abstracted information of the same image from different synthesized domains must be the same, while retaining enough information for reconstruction at the decoder. 

\subsection{Test Time Augmentation for Anomaly Detection (TTAAD)}
% \textbf{Feature Distribution Matching (FDM)}
% Arbitrary Style Transfer is a technique in computer vision that involves transferring the style of an image to another image while preserving its content. In other words, it allows the style of one image to be applied to another image while still retaining the original content of the target image. 
% Huang et al.(2017) introduced a technique called adaptive instance normalization (AdaIN)\cite{huang2017arbitrary}:
% \begin{equation}
% \text{AdaIN}(x, y) = \sigma(y) \left(\frac{x - \mu(x)}{\sigma(x)}\right) + \mu(y)
% \end{equation}

% In this formula, $x$ represents the input feature map, $y$ represents the style features, $\mu$ represents the mean operator, and $\sigma$ represents the standard deviation operator. The AdaIN function computes the normalization of $x$ using the mean and standard deviation of $x$, and scales it using the mean and standard deviation of $y$. Finally, it shifts the result by the mean of $y$. 
% Essentially, by using the feature statistics of the style input, AdaIN can apply the style of one image to another while preserving the content information of the original image. AdaIN can get exact feature distribution matching by assuming that features follow Gaussian distribution. However, feature distributions of empirical data usually deviate much from Gaussian, so Zhang et al.(2022) propose the Exact Feature Distribution Matching (EFDM) \cite{zhang2022exact} that can be adapted well with real-world data. In fact, AdaIN and EFDM have been used for Domain Generalization, specifically Mixstyle, and EDFMix, respectively. AdaIN and EFDM are used during training with the goal of creating new distribution samples by mixing the styles of the samples available in the training set, thereby making the model more generalized. In contrast, we propose using these Feature distribution matching techniques in the inference phase to reduce the gap between the source and target domains.

% % \textbf{Proposed Method}
% Given a sample input X in the test set, we randomly select a sample Y in the training set. Sample Y has the role of carrying information about the color and style of the source domain. The random selection of sample Y is due to the monotony of the source domain during training, since any sample in the training set can also carry color and style information representing the whole source domain. Then, sample X and Y are both fed into the same Encoder, the feature distribution of Y will be injected into X in the CNN layers as described in Fig. \ref{fig:proposedframework} (b). By this way, FDM makes the distribution of samples in target domain closer to the style of samples in source domain but still retain the feature of the image. Intuitively, when applying the FDM method to a sample from the source domain, the resulting distribution should not deviate significantly from its distribution. Because then, the distribution of the input sample is matched with its own distribution, so FDM does not affect the performance of model on the source domain too much. In other words, FDM can enable the model to adapt to the target domain without sacrificing its ability to perform well on the source domain.

% To be more flexible and inspired by Mixstyle and EDFMix. We adopt the $\alpha$ as the severity for mixing the style between the sample in the source and target domains. Details of adopting the $\alpha$ into AdaIN and EFDM are done in the same way as in Mixstyle and EFDMix and are described in Appendix.

The proposed testing framework is demonstrated in Figure \ref{fig:proposedframework} (b). The goal of our approach is to address the problem of a mismatch between the distribution of data during testing and the distribution of normal data during training. To accomplish this, we propose injecting training distribution into the inference samples by using Feature Distribution Matching (FDM) at multi-level layers of the teacher encoder in the inference phase. 

There are some previous research has focused on FDM assuming that the features follow a Gaussian distribution\cite{huang2017arbitrary, lu2019closed, mroueh2020wasserstein} . More recently, Zhang et al.\cite{zhang2022exact} have discovered more accurate methods, known as Exact Feature Distribution Matching (EFDM). All these FDM techniques are applicable for our proposal. Noted that, FDM have been used for OOD Generalization, specifically, Mixstyle \cite{zhoudomain} and EDFMix \cite{zhang2022exact}, which are used during training with the goal of creating new distribution samples by mixing the styles of the samples available in the training set, while we adopt FDM as a component in inference period with a different objective.

Given a sample $x \in \mathcal{D}_t$, we randomly select a normal sample $ q \in \mathcal{D}_s$. These two samples are then fed into the teacher encoder. Let $\mathcal O^m$ and $\mathcal P^m$ are the embedded feature of $x$ and $q$ at the residual encoding block $E^m$, respectively. The testing process is executed following the recursive equation \ref{equa:test}, which is defined as:
%{x}_{norm}
% Let ${\chi}^{m}_{main}$ and  ${\chi}^{m}_{norm}$ is the embedded feature that are fed into the next layer ${E}^{m+1}_{main}$ and ${E}^{m+1}_{norm}$, defined as: 
% \begin{equation}
% {\chi}^{m}_{main} = FDM(E^{m}_{main}, E^{m}_{norm},\alpha)
%   \label {eq:sumloss}, 
% \end{equation}
% \begin{equation}
% {\chi}^{m}_{main} = FDM(E^{m}_{main}, E^{m}_{norm},\alpha)
%   \label {eq:sumloss}, 
% \end{equation}
% % $ {\chi}^{m} = FDM(E^{m}(x), E^{m}({x}_{norm}),\alpha) $ 
% \begin{equation}
% \begin{cases}
% {\chi}^{m}{main} = FDM(\mathcal E^{m}{main}, \mathcal E^{m}{norm},\alpha) \\
% {\chi}^{m}{norm} = \mathcal E^{m}{norm}
% \end{cases}
% \end{equation}
% \begin{equation}
% \begin{cases}
% \mathcal O^{m+1} = {E}^{m+1}(FDM(\mathcal O^{m}, \mathcal P^{m},\alpha)) \\
% \mathcal P^{m+1} = {E}^{m+1}(\mathcal P^{m})\\
% \mathcal O^{1} = {E}^{1}(x)\\
% \mathcal P^{1} = {E}^{1}(q)
% \end{cases}
% \label{equa:test}
% \end{equation}

\begin{equation}
\begin{cases}
\mathcal O^{m+1} = {FDM}(E^{m+1}(O^m), \mathcal P^{m+1},\alpha) \\
\mathcal P^{m+1} = {E}^{m+1}(\mathcal P^{m})\\
\mathcal O^{1} = FDM(E^{1}(x), \mathcal P^{1},\alpha)\\
\mathcal P^{1} = {E}^{1}(q)
\end{cases}
\label{equa:test}
\end{equation}
where the value $\alpha$ is the severity for mixing the style between the inference sample and the selected normal sample. The embedded features $\mathcal O^{1}, \mathcal O^{2}, \mathcal O^{3}$ are then input into the Bottleneck and participate in the calculation of anomaly score followed the inference process of the original RD4AD.

In essence, the sample $q$ plays a role in conveying distribution information pertaining to the training data. The selection of a random sample is due to the monotonous nature of the data during training, as any sample in the training set is capable of carrying distribution information that represents the training data. Consequently, devising a process for sample selection during training is computationally expensive and inefficient.

By utilizing FDM, our proposed testing process minimizes the disparity between the feature distribution of the inference sample and the feature distribution of normal samples in the training data, in cases where inference samples come from OOD sets. Furthermore, FDM ensures that the feature distribution remains nearly unchanged if inference samples come from ID sets, since the distribution of the test sample is aligned with its own distribution. Therefore, our testing approach can improve performance on OOD data without sacrificing performance on ID data.

%${m}^{th}$
\section{Experiments}
% \subsection{Experimental Settings}
\subsection{Datasets}
\textbf{Anomaly Detection Datasets.}
\textbf{MVTec} \cite{bergmann2019mvtec} comprises 15 distinct collections of authentic data aimed at detecting anomalies. These datasets encompass 5 varieties of textures and 10 categories of objects. The training dataset comprises a total of 3,629 images, all of which are devoid of any defects. In contrast, the test dataset contains a total of 1,725 images, comprising both defective and non-defective instances. In order to generate OOD datasets for MVTec, we apply 4 types of visual corruptions to the MVTec \cite{bergmann2019mvtec}: Brightness, Contrast, Defocus Blur, and Gaussian noise. The severity for each type of corruption is set to 3 for all the out-of-distribution data. 

\textbf{One-Class Novelty Detection Datasets.} We conduct a one-class novelty detection experiment on two semantic datasets: \textbf{Handwritten Digit Recognition} and \textbf{PACS}\cite{li2017deeper}.

\textbf{Handwritten Digit Recognition.}  We use MNIST\cite{lecun1998gradient} as the source distribution data that the models are trained on and MNIST-M\cite{ganin2015unsupervised}  as the OOD set. MNIST and MNIST-M datasets share 10 classes, which correspond to the digits 0 through 9. While MNIST encompasses 70,000 grayscale images of handwritten digits, MNIST-M contains 68,000 images that are synthesized by superimposing random colored patches on the original images from MNIST.

\textbf{PACS.} The dataset consists of 9,991 images that are shared by seven classes and four domains, namely Art, Cartoon, Photo, and Sketch. We selected Photo as the ID data, and Art, Cartoon, and Sketch as the OOD data. 
% We use 8,977 images for training and 1014 images for testing.

We apply the protocol mentioned in \cite{perera2019ocgan} to both two datasets. We train models with samples from a single class and then test them on novel samples. If a sample does not belong to the class that the model is trained on, it is considered an anomaly, and vice versa. During training, we only use images in the ID set. During inference, test sets of both ID and OOD are used.

\subsection{\textbf{Baselines}}
\textbf{Anomaly Detection Methods.}
We conduct a series of experimental evaluations on 4 prominent anomaly detection methods, namely DeepSVDD \cite{ruff2018deep}, f-AnoGAN\cite{schlegl2019f}, KDAD\cite{salehi2021multiresolution}, and RD4AD \cite{deng2022anomaly}. These methods come from a wide range of algorithmic approaches and diverse features.

\textbf{OOD Generalization Methods.}
To evaluate the efficacy of OOD generalization techniques in anomaly detection, we apply a suite of cutting-edge methods to the recently proposed RD4AD model, which boasts SOTA performance on multiple datasets. The suite of DG methods we employ as our baseline included Augmix \cite{hendrycks2019augmix}, Mixstyle \cite{zhoudomain}, EFDM\cite{zhang2022exact}, and Jigsaw \cite{carlucci2019domain}. 
% Each of these methods has demonstrated considerable promise in the domain generalization literature and represents a diverse array of strategies for improving the performance of anomaly detection models.  

\subsection{Implementation Details}
\textbf{Our framework.} In essence, our proposed method is built on top of the RD4AD framework. Therefore, we maintain the settings recommended by RD4AD, such as the number of training epochs, optimization method, the way of calculating anomaly score, and other relevant parameters. The details can be found in Appendix. Regarding the specific parameters for the GNL, we choose $N=2$ for the number of augmented normal samples generated by data augmentation,$\alpha=0.5$ for the severity for mixing the style, and EFDM\cite{zhang2022exact} as the FDM technique since it is the latest and gains SOTA performance.
% Specifically, with MVTEC, all images in MVTec are resized to 256x256. We take ResNet50\cite{he2016deep} as the backbone of the teacher encoder. We utilize Adam optimizer \cite{kingma2014adam} with $\beta=(0.5,0.999)$. The learning rate is set to 0.005. We train 200 epochs with a batch size of 16. The hyperparameters of image size, optimizer, learning rate, number of epochs, batch size for PACS are the same as for MVTEC. For Handwritten Digit Recognition, all images are in their original scale, which are 28 × 28. We take ResNet18\cite{he2016deep} as the backbone of the teacher encoder. We train 200 epochs with a batch size of 16. The model is optimized by Adam \cite{kingma2014adam} optimizer with learning rate of 0.001. We choose the number of augmented images for each sample to be 2. 
% We also report the change in performance when the number of images generated for each sample changes in the ablation study.

\textbf{Anomaly detection baselines.} We have run all the baseline experiments according to the implementation published by the authors of those baselines. However, since the original baselines did not include experiments on the PACS dataset, we use the hyperparameters from MVTEC experiments to conduct experiments on the PACS dataset corresponding to each baseline. 

\textbf{OOD generalization baselines} We use Augmix with an online augmentation severity of 3 for Handwritten Digit Recognition and PACS datasets. We use all the data augmentation types included in Augmix for Handwritten Digit Recognition and PACS. However, for the MVTec dataset, we exclude two types of augmentation that overlap with two types of corruptions during testing: Brightness and Contrast. With Mixstyle and EFDM, which are two data augmentation methods at the feature level (not image level like Augmix), we apply Mixstyle and EFDM to E1 and E2 of the encoder according to their author's settings. With Jigsaw, we fit the Jigsaw task into the BottleNeck component. All hyperparameters of training are preserved when applying OOD generalization baselines into RD4AD.


Like previous studies \cite{ruff2018deep, schlegl2019f, salehi2021multiresolution, deng2022anomaly}, we evaluate the performance of our anomaly detection methods using a metric called the area under the receiver operating characteristic curve (AUROC). This metric is commonly used to assess how well a given method is able to distinguish between normal and anomalous data points. The results are reported by running training testing three times and computing the average values.

\subsection{Comparison Results}


% \subsubsection{Results on MVTec AD}

% \textbf{Performance of AD Models.}

% \textbf{Performance of Adapted OOD Models.}

% \textbf{Performance of Our Models.}

\begin{table}[h]
\centering
\scalebox{0.8}{
\begin{tabular}{l|c|c|c|c|c}
\hline
Method & ID & Brightness & Contrast & Blur & Noise \\
\hline
Deep-SVDD & 69.98 & 55.18 & 50.07 & 68.82 & 59.11 \\
f-AnoGAN & 75.65 & 48.36 & 49.29 & 37.98 & 39.10\\
KDAD & 85.50 & 83.81 & 64.03 & 84.17 & 82.04 \\
% KDAD\_TMixstyle & 0.8540 & 0.8522 & 0.7107 & 0.8421 & 0.8097 \\
% KDAD\_TEFDM & 0.8441 & 0.8523 & 0.8197 & 0.8343 & 0.8157 \\
RD4AD & \textbf{98.64} & 96.50 & 94.12 & \textbf{98.9} & 90.14 \\
\hline
Augmix & 96.29 & 95.10 & 94.51 & 95.39 & 90.99 \\
Mixstyle & 98.58 & 96.60 & 94.45 & 98.27 & 88.92 \\
EFDM & 98.64 & 96.78 & 94.77 & 98.25 & 89.29 \\
Augmix+Mixstyle & 96.78 & 96.86 & 94.57 & 98.73 & 90.12 \\
Augmix+EFDM & 97.04 & 96.83 & 95.21 & 98.11 & 90.18  \\
Jigsaw & 73.97 & 73.36 & 67.88 & 73.88 & 72.60 \\

% RD4AD\_TMixstyle & 0.9853 & 0.9736 & 0.9687 & 0.9823 & 0.9278 \\
% RD4AD\_TEFDM & 0.9852 & 0.9732 & 0.9720 & 0.9821 & 0.9292 \\
% RD4AD_newv1 & 0.9783 & 0.9646 & 0.9610 & 0.9732 & 0.9205 \\
% RD4AD_newv1+TMixstyle & 0.9797 & 0.9744 & 0.9739 & 0.9776 & 0.9421 \\
\hline
GNL (Ours) & 97.99 & \textbf{97.43} & \textbf{97.46} & 97.77 & \textbf{94.10} \\
\hline
\end{tabular}
}


\caption{Anomaly Detection results on MVTEC and its corruptions. Methods achieved for the first AUROC (\%) are highlighted in bold.}
\label{tab:t1}
\end{table}


\begin{table}[h]
\centering
\scalebox{0.8}{
\begin{tabular}{c|c|c}
Method  & MNIST & MNIST-M \\
\hline
Deep\-SVDD & 97.73 & 49.92 \\
f-AnoGAN & 97.52 & 52.72 \\
KDAD & 98.87 & 54.87 \\
% KDAD_TMixstyle & 0.9870 & 0.5478 \\
% KDAD_TEFDM & 0.9790 & 0.5723 \\
RD4AD & \textbf{98.89} & 58.09 \\
\hline
Augmix & 98.26 & 59.61 \\
Mixstyle & 98.84 & 57.22 \\
EFDM & 98.62 & 57.23 \\
Augmix+Mixstyle & 98.12 & 58.89   \\
Augmix+EFDM & 98.24 & 58.91 \\
Jigsaw & 98.90 & 58.51 \\
% RD4AD_TMixstyle & 0.9784 & 0.6452 \\
% RD4AD_TEFDM & 0.9755 & 0.6484 \\
% RD4AD_newv1 & 0.9765 & 0.6266 \\
% RD4AD_newv1+TMixstyle & 0.9699 & 0.7103 \\
\hline
GNL (Ours) & 96.91 & \textbf{70.87} \\
\hline
\end{tabular}
}
\caption{Performance of anomaly detection methods on in-distribution (MNIST) and out-of-distribution (MNIST\-M) datasets as measured by the Area Under the Receiver Operating Characteristic (AUROC)}
\label{tab:t2}
\end{table}
% 

\begin{table}[h]
\centering
\scalebox{0.8}{
\begin{tabular}{l|c|c|c|c}
\hline
Domain & Photo (S) & Art (T) & Cartoon (T) & Sketch (T)  \\ \hline
Deep\-SVDD   & 40.87&	53.42 &	41.23 & 	39.48 \\
f-AnoGAN &  61.34 &  50.15 &  52.42 &  63.77   \\
KDAD &  \textbf{88.17} &  62.86 &  62.64 &  51.40 \\
% KDAD_TMixstyle &  898.2 &  65.94 &  69.14 &  59.28 \\
% KDAD_TEFDM &  89.29 &  65.06 &  67.72 &  60.06 \\
RD4AD &  81.49 &  61.07 &  60.34 &  55.06  \\
\hline
Augmix &  76.35 &  60.50 &  58.96 &  57.86  \\
Mixstyle &  78.23 &  60.93 &  60.93 &  54.89 \\
EFDM &  78.47 &  60.55 &  62.15 &  55.63  \\
Augmix+Mixstyle & 76.12 & 60.16 &  61.29 & 55.76\\
Augmix+EFDM & 77.28 & 60.93 &  63.18 & 56.67\\
Jigsaw &  62.19 &  52.55 &  53.83 &  62.15  \\
% RD4AD_TMixstyle &  80.26 &  63.74 &  60.76 &  56.13 \\
% RD4AD_TEFDM &  81.05 &  64.36 &  62.04 &  57.04 \\
% RD4AD_newv1 &  85.71 &  62.34 &  65.63 &  57.12 \\
% RD4AD_newv1+TMixstyle &  85.84 &  64.45 &  65.28 &  60.57 \\
\hline
GNL (Ours) &  87.67 &  \textbf{65.62} &  \textbf{67.96} &  \textbf{62.39}  \\ \hline
\end{tabular}
}
\caption{Performance of anomaly detection methods on in-distribution (Photo) and out-of-distribution (Art, Cartoon, Sketch) datasets, as measured by the Area Under the Receiver Operating Characteristic (AUROC).}
\label{tab:t2}
\end{table}


\textbf{Performance of SOTA AD Methods.}
The performance of MVTec, MNIST, and PACS is shown in table \ref{tab:t1}, and table \ref{tab:t2}, respectively. Because of space limitations, the performances in 3 tables are the average results of the classes per dataset. Detailed results are presented in Appendix.

In general, we observe a significant drop in the AUC scores of all methods on the out-of-distribution datasets, which indicates that their performance is severely affected by the distribution shift. In particular, on the handwriting set, the performance of all models is high on the MNIST set. However, this performance is reduced by about 30-40\% when the models are tested on the MNIST-M set, which contains variations that are not present in the original MNIST set. Similar trends are observed in the PACS, where the models' performance is also greatly affected by OOD data. The models perform well on the photo domain, which is the source domain, but their performance drops significantly on the other domains. On the MVTec dataset, the performance still drops but is less severe than on the other two sets.

% This could be because the dataset contains images of the same object taken from different angles and under different lighting conditions, which is more similar to the in-distribution data that the models were trained on.\\

\textbf{Performance of Combined SOTA OOD Generalization and AD Methods.}
The experimental results indicate that the performance of AD methods is not significantly improved by existing OOD generalization techniques across all three datasets. This lack of improvement can be attributed to the fact that these DG methods attempt to increase the diversity of data by enriching the available data based on its own distribution. However, because the training data for anomaly detection is typically monotonous and unimodal, these DG methods often fail to generate data samples that significantly deviate from the original data distribution. As a result, the added diversity of DG-generated data is not enough to significantly improve the performance of AD models.

Moreover, these DG techniques also have a tendency to generate unwanted anomaly data, which is akin to injecting noise into the training data, thereby reducing the performance of AD models on the in-distribution dataset.

\textbf{Performance of Our Method.}
\textbf{Anomaly Detection}
Experimental results of anomaly detection on MVTec set are shown in table \ref{tab:t2}. Our method showed remarkable improvement in performance on the out-of-distribution dataset, while maintaining the performance on the ID data. In fact, our method achieved a significantly high score of 0.9799 on the original MVTec, while also obtaining an impressive score of 0.9743 on the Brightness, 0.9746 on Contrast, 0.9776 on the Defocus\_blur dataset, and 0.9410 on Gaussian Noise, which are  significant improvements over the other methods. These results demonstrates the robustness and effectiveness of our proposed method.\\
 \textbf{One-class Novelty Detection}
The results of PACS experiments on table \ref{tab:t3} demonstrate that our proposed method applied on RD4AD outperforms all other methods. Particularly, RD4AD outperformed all other methods on each individual domain, achieving AUROC scores of 0.6562, 0.6796, and 0.6239 for the art, cartoon, and sketch domains, respectively. These results indicate that our method is highly effective at detecting anomalies in various domains. Our method not only improves the out-of-distribution performance of RD4AD, but also enhances its performance on the in-distribution Photo domain. This is because the Photo domain contains sub-domains, and RD4AD can be susceptible to overfitting on a specific sub-domain in the training data. By making RD4AD more general, our method helps to mitigate this issue and improve performance across all sub-domains within the Photo domain. The similar trend is seen on Handwritten Digit Recognition datasets \ref{tab:t2}. The results indicate that our method exhibits only a slight reduction in performance compared to the original RD4AD on the MNIST dataset, with a score of 0.9691 compared to 0.9889. However, a significant improvement in performance is observed on the MNIST-M dataset, with a score of 0.7087 compared to 0.5809 of the original RD4AD.
% This demonstrates the models' inability to cope with domain shifts, which can occur when data from different sources are combined.
% This drop in performance highlights the models' difficulty in generalizing to out-of-distribution data, which is an important challenge in real-world applications.

% Anomaly detection results on MVTec are shown in Tab. 1

\subsection{Ablation Study}
\begin{table}[h]
\centering
\scalebox{0.8}{
\begin{tabular}{c|c|c|c|c}
 & Photo (S) & Art (T) & Cartoon (T) & Sketch (T) \\
\hline
Baseline &  81.49 &  61.07 &  60.34 &  55.06 \\
\hline
% TAdaIN &  80.26 &  63.74 &  60.76 &  56.13 \\
TTAAD &  81.05 &  64.36 &  62.04 &  57.04 \\
\hline
DINL &  85.71 &  62.34 &  65.63 &  57.12 \\
\hline
% DINL+TAdaIN &  85.84 &  64.45 &  65.28 &  60.57 \\
DINL+TTAAD &  \textbf{87.67} &  \textbf{65.62} &  \textbf{67.96} &  \textbf{62.39} \\
\end{tabular}
}
\caption{The contribution of each component to the performance model.}
% and the effectiveness of two arbitrary style transfers, AdaIN and EFDM
\label{tab:t3}
\end{table} 


\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{Alpha.pdf}
    \caption{The change in performance when $\alpha$ changes with the same model applied DINL during training and TTAAD with EFDM in inference phase. The smaller the $\alpha$ value, the lower the severity of style transfer and vice versa.}
    \label{fig:alpha}
\end{figure}
% In addition, the effectiveness of two arbitrary style transfers, AdaIN and EFDM, are also tested.

We examine the dedication of Distribution-invariant Normality Learning and Test time augmentation to the performance model on PACS. The results are reported in Table \ref{tab:t3}. Generally, all components contribute to overall accurate growth. In particular, the experimental results show that if only test time augmentation is applied, the improvement of the model is a little. Even on the Photo(S) domain, the performance is also reduced. When applying DINL during training, it not only improves the performance of the original model by itself but also makes test time augmentation more efficient than when test time augmentation is applied to the original model. 
% Experimental results also illustrate that EFDM shows slightly more efficiency than AdaIN in all domains.

The Fig. \ref{fig:alpha} depicts how the performance of a model changes when the value of the hyperparameter $\alpha$ changes. The model is trained using Distribution-invariant Normality Learning methodology, and the testing phase is augmented with EFDM. Our findings suggest that the effectiveness of our model remains relatively consistent across different $\alpha$ values for the Photo and Cartoon domains. In contrast, the model's ability to detect anomalies on the Art domain appears to improve as $\alpha$ increases. However, for the Sketch domain, the model's anomaly detection performance reaches its maximum at $\alpha = 0.4$ and slightly decreases as $\alpha$ increases further.

% The results suggest that an increase in the value of $\alpha$ corresponds to a gradual increase in the performance of the model on the ID data, i.e., Art, Cartoon, and Sketch. Simultaneously, the performance of the model on the ID data, which in this case is Photo, remains stable. In general, the high value of $\alpha$ can improve the performance of the model on the OOD data without significantly compromising the performance on the source domain.



\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{changingseverity (3).pdf}
    \caption{The change in performance when the severity of the corruption ’Contrast’ increases from 1 to 5 on the MVTec.}
    \label{fig:changingseverity}
\end{figure}

Figure \ref{fig:changingseverity} describes a comprehensive analysis of the efficacy of various baselines under the influence of progressively increasing levels of 'Contrast' corruption. Notably, the performance of these baselines exhibits a significant decline as the severity of corruption amplifies, which unmistakably reveals their susceptibility to distribution shifts. The rationale behind this phenomenon is intuitive as heightened corruption severity introduces more substantial distribution variance, making it arduous for the model to discern between anomalous and normal samples. Our proposed method, on the other hand, demonstrates remarkable stability in performance across multiple levels of distribution shift. Our method maintains stable performance when the severity is between 1 and 3, and reduces to an acceptable level when the severity is 4 and 5. This result indicates that our method has the ability to operate efficiently on multiple levels of distribution shift and is robust to changes in the underlying data distribution.

% \begin{figure}
%      \centering
%      \begin{subfigure}
%          % \centering
%          \includegraphics[width=0.2\textwidth]{elephant.pdf}
%          \caption{PACS}
%          \label{fig:y equals x}
%      \end{subfigure}
%      \begin{subfigure}
%          % \centering
% \includegraphics[width=0.2\textwidth]{zipper.pdf}
%          \caption{MVTec}
%          \label{fig:three sin x}
%      \end{subfigure}
% \end{figure}


\begin{figure}
\centering
\begin{subfigure}[b]{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{elephant1.pdf}
    \caption{PACS ('elephant')}
    \label{fig:first}
\end{subfigure}
\vspace{0.0cm}
\begin{subfigure}[b]{0.5\textwidth}
    \centering
\includegraphics[width=\textwidth]{zipper2.pdf}
\caption{Zipper}
    \label{fig:third}
\end{subfigure}
\caption{Comparison of the histogram of anomaly score of our method with original RD4AD on Zipper and PACS ('elephant' as a normal class). Generally, our method has proven effective in minimizing the overlap between the histograms of anomaly scores for normal and anomalous samples.}
\label{fig:figures}
\end{figure}





\section{Conclusion}
In conclusion, we have proposed a novel approach to addressing the challenge of anomaly detection in the presence of distribution shift. Our approach involves a new training process and inference method that aim to improve the generalization of the model and reduce the gap between in-distribution and out-of-distribution data. We have also introduced a benchmark dataset that enables a comprehensive evaluation of our approach and facilitates further research in this area. Our experimental results demonstrate that our approach outperforms existing methods for detecting anomalies in the presence of distribution shift. Overall, our approach represents an important contribution to the field of unsupervised anomaly detection, as it addresses a realistic and challenging problem that has not been adequately studied before.

% In future work, we plan to explore extensions of our approach to handle more complex scenarios and investigate its applicability to other types of data.







{\small
\bibliographystyle{ieee_fullname}
\bibliography{refs}
}




\end{document}
