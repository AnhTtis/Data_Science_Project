\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{diagbox}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage{cite}
\usepackage{float,lscape}
\usepackage{authblk}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage{rotating}
\usepackage{adjustbox}
\usepackage{blindtext}
\pagenumbering{gobble}
% \usepackage[breaklinks=true,bookmarks=false]{hyperref}


\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{10957} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi % Required for inserting images


\definecolor{citecolor}{HTML}{0071bc}
\usepackage[pagebackref,breaklinks=true,letterpaper=true,colorlinks,citecolor=citecolor,bookmarks=false]{hyperref}

\title{Anomaly Detection under Distribution Shift}
\author{Tri Cao}
\author{Jiawen Zhu}
\author{Guansong Pang\thanks{Corresponding author: G. Pang ({\tt pangguansong@gmail.com}).}}
\affil{School of Computing and Information Systems, Singapore Management University}
\begin{document}
\maketitle
\begin{abstract}

Anomaly detection (AD) is a crucial machine learning task that aims to learn patterns from a set of normal training samples to identify abnormal samples in test data. 
% However, most previous works on anomaly detection
Most existing AD studies
% have focused on detecting anomalies within a single distribution, and have assumed
assume that the training and test data are drawn from the same data distribution, but the test data can have large distribution shifts arising in many real-world applications due to different natural variations such as new lighting conditions, object poses, or background appearances, rendering existing AD methods ineffective in such cases.
% remains stationary over time. 
In this paper, we consider the problem of anomaly detection under distribution shift and establish performance benchmarks on four widely-used AD and out-of-distribution (OOD) generalization datasets. We demonstrate that simple adaptation of state-of-the-art OOD generalization methods to AD settings fails to work effectively due to the lack of labeled anomaly data. We further introduce a novel robust AD approach to diverse distribution shifts by minimizing the distribution gap between in-distribution and OOD normal samples in both the training and inference stages in an unsupervised way. Our extensive empirical results on the four datasets show that our approach substantially outperforms state-of-the-art AD methods and OOD generalization methods on data with various distribution shifts, while maintaining the detection accuracy on in-distribution data. Code and data are available at \renewcommand\UrlFont{\color{blue}\tt}
\url{https://github.com/mala-lab/ADShift}.


\end{abstract}
\section{Introduction}
% \subsection{The Challenges} 

% \guansong{have you updated the introduction section based on our last meeting's comments? please do so if you haven't}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{Preview3.png}
    \caption{Illustrative samples for anomaly detection under distribution shift. First row: the `Wood' dataset from MVTec \cite{bergmann2019mvtec}. Second row: the `Elephant' class as normal and the remaining classes as anomaly in PACS \cite{li2017deeper}. Third row: the `0' class as normal and the remaining classes as anomaly in MNIST\cite{lecun1998gradient}/MNIST-M\cite{ganin2015unsupervised}. We aim at distinguishing anomalies from normal data in both in-distribution test data and out-distribution test data
    % \guansong{changes to be made: `In-Distribution in Test Set' to `In-distribution Test Data';`Out-of-Distribution in Test Set' to `Out-of-distribution Test Data'; having different background colors for the columns of normal samples and anomalous samples may look more straightforward }
    }
    \label{fig:intro}
\end{figure}
Anomaly Detection (AD) is a crucial task in machine learning that aims to identify rare and unusual patterns in data. It is an important problem in various domains, such as financial domain \cite{ahmed2016survey, anandakrishnan2018anomaly}, cybersecurity \cite{ten2011anomaly, siddiqui2019detecting}, industrial inspection \cite{bergmann2019mvtec}, and medical diagnosis \cite{schlegl2019f, shvetsova2021anomaly}. 
% In anomaly detection, the goal is to distinguish normal patterns from abnormal patterns, which can be caused by various factors, such as errors, faults, attacks, or anomalies.
Due to the difficulty and/or high cost of collecting labeled anomaly data,
% and the difficulty in obtaining negative samples in many applications, 
% AD is often approached as an 
current AD studies are focused on unsupervised approaches, which aim to learn patterns from a set of normal training samples to identify abnormal samples in test data.
% . In unsupervised learning, the model is trained on a dataset of normal patterns, and then used to detect anomalies in new data. By being focused by the research community,
% the performance of AD models in many tasks is impressive, some models even achieve near-perfect accuracy \cite{li2021cutpaste, salehi2021multiresolution, deng2022anomaly}.

Although existing AD studies have demonstrated promising performance \cite{li2021cutpaste, salehi2021multiresolution, deng2022anomaly,pang2021deep}, they generally assume that the training and test data are drawn from the same data distribution. However, this assumption is often unrealistic in real-world scenarios as the test data can have large distribution shifts arising in many applications due to different natural variations such as new lighting conditions, object poses, or background appearances, rendering the AD methods ineffective in such cases.
% However, in real-world scenarios, the data distribution may change over time, due to various factors such as changes in the environment, data collection process, or system configurations. This phenomenon is known as 

Distribution shift is a ubiquitous problem in different real-world applications, which can significantly degrade the performance of models in various tasks such as image classification, object detection, and segmentation \cite{koh2021wilds, ganin2015unsupervised, li2017deeper, zhang2020generalizing}. Many out-of-distribution (OOD) generalization methods have been introduced to address this problem \cite{huang2020self, hendrycks2019augmix, zhang2022exact, carlucci2019domain, ghifary2015domain, lehner20223d, ma2020training, liu2021feddg, ouyang2022causality}. 
% Assuming only source domain data available, the target domain data can not access, DG try to develop a model that 
These OOD generalization methods rely on large labeled training data from one or multiple relevant domains to learn domain-invariant feature representations. They often require class labels \cite{yao2022pcl, huang2020self, qiao2020learning}, domain labels \cite{zhao2021learning, yoon2019generalizable, wang2020cross, carlucci2019hallucinating}, or the existence of diverse data \cite{hendrycks2019augmix, zhang2022exact, zhoudomain} in the source domain to learn such robust feature representations. However, the training data in the AD task consists of only one class, and the data is monotonous. Consequently, it is difficult to adapt existing OOD generalization techniques to address the AD under distribution shift problem. Trivial adaption of the OOD generalization can fail to learn generalized normality representations, leading to many detection errors, \eg, normal samples with distribution shifts cannot be distinguished from anomalous samples and consequently they are detected as anomaly. As shown by the exemplar data in Fig. \ref{fig:intro}, normal samples in the in-distribution (ID) test data are very similar to the normal training data, and ID anomalies deviate largely from the normal data; however, due to the distribution shift, the normal samples in the OOD test data are substantially different from the ID normal data in terms of foreground and/or background features, and as a result, these normal samples can be falsely detected as anomaly. 

In this paper, we tackle the problem of anomaly detection under distribution shift. It is an \textit{OOD generalization} problem, aiming at learning generalized detection models to accurately detect normal and anomalous samples in test data with distribution shifts, while maintaining the effectiveness on in-distribution test data. This is different from the problem of \textit{OOD detection} \cite{
hendrycks2017baseline,hsu2020generalized,liu2020energy,ren2019likelihood,wang2022partial} that aims to equip supervised learning models with a capability of rejecting OOD/outlier samples as unknown samples for the sake of model deployment safety. This work makes three main contributions in addressing the OOD generalization problem in the AD task:
\begin{itemize}
\item We present an extensive study of the distribution shift problem in AD and establish large performance benchmarks under various distribution shifts using four widely-used datasets adapted from AD and OOD generalization tasks. Our empirical results further reveal that existing state-of-the-art (SOTA) AD and OOD generalization methods fail to work effectively in identifying anomalies under distribution shift.
\item We then propose a novel robust AD approach to diverse distribution shifts, namely \textit{generalized normality learning} (\textbf{GNL}). GNL minimizes the distribution gap between ID and OOD normal samples in both the training and inference stages in an unsupervised way. To this end, we introduce a normality-preserved loss function to learn distribution-invariant normality representations, which enables GNL to learn generalized semantics of the normal training data at different feature levels. GNL also utilizes a test time augmentation method to further reduce the the distribution gap during the inference stage.
\item Extensive experiments show that our approach GNL substantially outperforms state-of-the-art AD methods and OOD generalization methods by over 10\% in AUCROC on data with various distribution shifts, while maintaining the detection accuracy on the ID test data.
\end{itemize}
\section{Related Work}
% \guansong{it is too long. need to be more concise. Better to limit the intro and related work sections within two pages.}

\subsection{Anomaly Detection} 
% There are many unsupervised approaches that are proposed for anomaly detection. 

\textbf{One-class Classification.}
% Some very first methods are one-class support vector machine (OC-SVM)\cite{scholkopf2001estimating} and support vector data description (SVDD)\cite{tax2004support}. More recently, Ruff et al. (2018)\cite{ruff2018deep} proposed a method called deep one-class classification (DeepSVDD) that utilizes a deep autoencoder to learn a compressed representation of normal data and uses this representation to identify anomalies. Yan et al. (2021) introduced a novel unsupervised anomaly detection method that learns semantic context from normal samples using a deep convolutional neural network (PatchSVDD)\cite{yi2020patch}.
Some early methods for anomaly detection include one-class support vector machine (OC-SVM) \cite{scholkopf2001estimating} and support vector data description (SVDD) \cite{tax2004support}. More recently, Deep SVDD \cite{ruff2018deep} uses a deep neural network to identify anomalies with a SVDD objective. A number of methods \cite{chen2022deep,goyal2020drocc,wu2019deep,sabokrou2020deep,yi2020patch} is then introduced to learn more effective deep one-class description.
% , while Patch SVDD \cite{yi2020patch} learns patch-wise semantic contexts from normal data using a similar objective.

\textbf{Reconstruction-based Methods.} One popular AD approach is to use autoencoder (AE) \cite{kingma2013auto}. AE-based anomaly detection learns normal patterns from a dataset to reconstruct new samples, assuming that anomalous samples have higher reconstruction errors due to distribution differences. There are many works following this direction and gaining good performance \cite{gong2019memorizing,hou2021divide,park2020learning,yan2021learning,zavrtanik2021reconstruction,pourreza2021g2,zaheer2020old}. 

\textbf{Self-supervised Learning Methods.} The use of data augmentation techniques is becoming increasingly prevalent in AD. One such strategy involves incorporating synthetic anomalies into datasets that are otherwise free of anomalies \cite{li2021cutpaste, yan2021learning, zavrtanik2021reconstruction}. 
% By doing so, the unsupervised task of detecting anomalies is transformed into a supervised learning task, enabling the use of classification algorithms and other machine learning techniques that require labeled data. 

\textbf{Knowledge Distillation.} Another popular line of research is knowledge distillation-based methods. A student-teacher framework with discriminative latent embeddings is introduced in \cite{bergmann2020uninformed}. Many improved versions for AD are then introduced \cite{salehi2021multiresolution,wang2021student,deng2022anomaly}. Anomaly Detection via Reverse Distillation (RD4AD) \cite{deng2022anomaly} is the latest one and gains SOTA performances on many datasets. 

All these methods are focused on AD with the same distribution in training and test data, which fail to work well on data with distribution shift.
% In this paper, we present methods that can enhance the performance of RD4AD on out-of-distribution datasets while maintaining its performance on in-distribution data.
% The teacher network learns to encode normal data into a low-dimensional space, and the student network tries to mimic this behavior. Anomalies are then detected by measuring the difference between the student and teacher embeddings.

\subsection{OOD Generalization} 
% \guansong{please revise this section as suggested in our last meeting}

\textbf{Data Augmentation.} One popular approach for OOD generalization is based on data augmentation. Methods in this line involve generating new data samples from existing ones to increase the size and diversity of the training data. The model can then learn more about the underlying data distribution and become more robust to changes in the test data \cite{otalora2019staining, chen2020improving, zhang2020generalizing, sinha2017certifying, hendrycks2019augmix, zhang2022exact}.

\textbf{Unsupervised Learning.} By solving pretext tasks, a model can develop general features that are not specific to the target task. As a result, the model is less likely to be influenced by biases that are unique to a particular domain, which helps to avoid overfitting and increase generalization ability to different unseen data \cite{carlucci2019domain, ghifary2015domain, wang2020learning, maniyar2020zero, bucci2021self, albuquerque2020improving}.

Although these two types of methods are not designed for AD, they can be easily adapted for AD as they do not require class or domain labels during training. On the other hand, many existing OOD generalization methods, such as domain alignment \cite{muandet2013domain, hu2020domain, jin2020feature, mahajan2021domain, li2020domain, li2018domain, zhao2020domain}, meta-learning \cite{dou2019domain, li2021sequential, du2020learning, du2021metanorm, wang2020meta}, and disentangled representation learning \cite{li2017deeper, khosla2012undoing, chattopadhyay2020learning, piratla2020efficient, ilse2020diva, wang2020cross}, require class/domain-related supervision, which are inapplicable for the AD task. A similar issue exists for OOD generalization methods designed for multi-class problems \cite{du2020learning, huang2020self}. There are some cross-domain AD methods \cite{lu2020few, lv2021learning,ding2022catching}, but they require class labels in the ID data or few training samples from the target domain. By contrast, we focus on unsupervised AD and do not require any OOD data available during training. They focus on video data, while we focus on image data. Additionally, another related research line is on AD in situations involving a `near distribution' scenario \cite{mirzaei2022fake}, where anomalies are semantically similar to the normal distribution. Methods in this line can be more robust to distribution shift than general AD methods, but they do not tackle variations between the distributions of training and testing normal data.

\section{Problem Formulation and Challenges}


\subsection{Problem Formulation}
Let $\mathcal{X}_s$ and $\mathcal{X}_t$ denote the source (ID) and target (OOD) distributions, respectively, where $\mathcal{X}_s$ is used for both training and testing phase,  while $\mathcal{X}_t$ is only used for inference period. We assume that during training, only normal data from $\mathcal{X}_s$ is available, \ie, $\mathcal{D}_s = \{{x \in \mathcal{X}_s \mid y = 0}\}$, where $y \in \{0,1\}$ is the binary label indicating whether $x$ is a normal ($y=0$) or abnormal ($y=1$) sample. During testing, data can be normal or abnormal, and can be from either the source or target distribution, \ie, $\mathcal{D}_t = \{{ x \in \mathcal{X}_s \cup \mathcal{X}_t}\ \mid y = \{0,1\}\}$. The goal is then to develop an unsupervised anomaly detection model that can effectively handle distribution shift and accurately detect anomalies in $\mathcal{D}_t$. Specifically, we aim to learn a function $f:\mathcal{X}\rightarrow \mathbb{R}$ that assigns an anomaly score to each sample $x$ in a way such that $\forall x_i, x_j \in \mathcal{D}_t, \ f(x_i) < f(x_j) $ when $y_i=0$ and $y_j=1$.




\subsection{The Challenges} 
The current approaches in AD involve explicit fitting of the normal training data \cite{deng2022anomaly, salehi2021multiresolution, akcay2019ganomaly, schlegl2019f}. It can cause the model to learn irrelevant features that are not associated with the appearance of normal data, \eg, the model may mistake domain-specific background information as normal features, resulting in inaccurate anomaly detection when there are distribution shits presented. OOD generalization models are also significantly challenged by the studied setting.
% , as they often require multi-class or multi-source of data during training whereas 
This is mainly because the training data in the AD task consists of only one class and the data is monotonous, making it difficult to learn and identify patterns that distinguish normal and anomalous instances. Current OOD generalization approaches used in classification, detection, and segmentation need to take into account class labels, domain labels, or the diversity of samples in the training data \cite{du2020learning, huang2020self,wang2020cross, wang2020meta}, which often are not applicable to AD tasks. As a result, new methods are required that can effectively address the problem of AD under distribution shift.

Fig. \ref{fig:challenge} illustrates this issue, where models such as RD4AD \cite{deng2022anomaly} (a recent SOTA AD model) and Mixstyle \cite{zhoudomain} (an OOD generalization method that we use to combine with RD4AD) are seen to struggle with identifying normal samples in the presence of distribution shift, often misclassifying them as anomalous. The overlapping of histograms of the anomaly scores for the normal and abnormal samples indicates that these models have learned features that are not representative of normal data, which can be a major obstacle in detecting anomalies. One of the main reasons is that the background or style features w.r.t. a specific dataset can change due to different natural conditions. As a result, the model may mistake these changed features as anomalies, leading to normal samples in the shifted distribution being classified as anomalous with high anomaly scores. Furthermore, some abnormal samples in the OOD data may possess similar features to background or style features in the training data, leading to them being misclassified with low anomaly scores.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{ChallengeHouse2.pdf}
    \caption{Anomaly scores of RD4AD \cite{deng2022anomaly}, Mixstyle \cite{zhoudomain} and our model GNL on PACS \cite{li2017deeper} when selecting `house' as the normal class and the remaining classes as anomaly classes.}
    \label{fig:challenge}
\end{figure}

\section{Our Approach}
% \guansong{please don't just describe the method in high-level texts; use formal symbols and equations to rigorously and precisely describe the method in both subsections.} \guansong{both subsections need to be significantly extended.}
\begin{figure*}[h]
    \centering
    \includegraphics[width=\textwidth]{proposedFramework.pdf}
    \caption{Overview of our approach. (a) Distribution-invariant normality learning in the training phase. (b) Test time augmentation with feature distribution matching in the inference phase.}
    \label{fig:proposedframework}
\end{figure*}


To address these challenges, we introduce a novel approach, namely generalized normality learning (GNL). GNL minimizes the distribution gap between ID and OOD normal samples in both the training and inference stages in an unsupervised way. To this end, we introduce a normality-preserved loss function to learn distribution-invariant normality representations, which enables GNL to learn generalized semantics of the normal training data at different feature levels. GNL further utilizes an AD-oriented test time data augmentation method based on feature distribution matching to improve the generalization performance. Fig. \ref{fig:proposedframework} describes the two main components of our approach: (a) distribution-invariant normality learning for training, and (b) test time augmentation methods. 
% The training process involves using a distribution-invariant normality learning process to learn distribution-invariant normality features that help the model to be more generalized. The testing process involves taking advantage of Feature Distribution Matching to reduce the gap between the source distribution and the target distribution. It is worth noting
The two components complement to each other, meaning that the distribution-invariant normality learning process used during training can support the test time augmentation methods used during testing, and vice versa. 

% This is the combination of enlarging training distribution and reducing test distribution.
\subsection{Distribution-invariant Normality Learning}
% \guansong{start with our intuition of the module; what specifically does this module do, and why it should work. the same principle is applied to the other section.}
% \textbf{Reverse Knowledge Distillation for Anomaly Detection}

% \textbf{Proposed Method}
In order to improve the performance of model on OOD datasets while maintaining good performance on ID datasets, we aim to train a student model to be more robust to changes in the distribution of data, while still ensuring that the student overfits on the normal features. 
Fig. \ref{fig:proposedframework} (a) illustrates the training framework. 

% Về cơ bản, chúng tôi muốn the student có thể tổng quát hơn với sự thay đổi của data distribution, đồng thời the student vẫn overfit với các normal feature. Chỉ có như vậy thì performance của model mới được cải thiện trên OOD datasets mà vẫn giữ được performance tốt trên ID datasets

Our method is built on top of the RD4AD model introduced by Deng et al. \cite{deng2022anomaly} that achieves state-of-the-art results on various datasets. The RD4AD framework includes three components: a fixed teacher encoder, a trainable one-class bottleneck embedding module, and a student decoder. When given an input sample, the teacher encoder extracts multi-scale representations, and the student decoder is trained to reconstruct the features from the bottleneck embedding. During testing, the teacher encoder can identify abnormal and OOD features in anomalous samples, but the student decoder fails to reconstruct these features. The model then considers anomalous representations that have low similarity as highly abnormal.

We propose to incorporate a similarity loss that quantifies the difference between the embedding features of the original samples and those of each transformed normal sample that represents a distinct style from the original data. Specifically, we enforce this loss at both the bottleneck layer and the final block of the decoder. To provide further clarity, we propose the inclusion of a loss term, denoted as $\mathcal {L}_{abs} $, which is integrated at the bottleneck layer of the encoder. Moreover, we also introduce another loss term, termed as $\mathcal {L}_{lowf}$, that is added at the final block of the student decoder architecture. Particularly, given a sample $x \in \mathcal{D}_s$, we
first apply an augmentation function $\mathcal{T(.)}$ on it, and let $x'_k =  \mathcal{T}(x)$ where $k \in [1,N]$ with $N$ is the number of augmented normal samples generated by data augmentation,
% . $N$ generated samples, along with the original sample are fed into RD4AD. Denote by 
and $\phi$ be the mapping that projects the raw image $I$ into the embedding space at the bottleneck layer, then we define $\mathcal {L}_{abs} $ as:
\begin{equation}
 \mathcal{L_{\text{abs}}} = \sum _{k=1}^{N}\frac {1}{N} \bigg \{ \mathcal {L}_{sim}(\phi(x),\phi(x'_k))\bigg \} 
 \label {eq:lossabtract}, 
\end{equation}
where $\mathcal {L}_{sim}(.,.)$ is a cosine similarity-based loss function. 

Let $\omega$ be a reconstruction function from the abstract features to the low-level features at the final block of the decoder, then we further define $\mathcal {L}_{lowf} $ as:
\begin{equation}
 \mathcal {L}_{lowf}  = \sum _{k=1}^{N}\frac {1}{N} \bigg \{ \mathcal {L}_{sim}(\omega(\phi(x)),\omega(\phi(x'_k)))\bigg \}. 
 \label{eq:losslowfeature}
\end{equation}

We combine these loss functions to introduce the distribution-invariant, normality-preserved loss function:
\begin{equation}
 \mathcal {L} = \lambda _{ori}*\mathcal {L}_{ori} + \lambda _{abs} * \mathcal {L}_{abs} + \lambda _{lowf} * \mathcal {L}_{lowf} 
  \label{eq:sumloss}, 
\end{equation}
where $\mathcal{L}_{ori}$ is the original loss of RD4AD, and $\lambda _{ori}$, $\lambda _{abs}$, and $\lambda _{lowf}$ are hyperparameters that determine how much weight should be given to each type of loss function.
% and $\mathcal {L}_{ori}$ is the loss in the original RD4AD framework. 

We adopt AugMix \cite{hendrycks2019augmix} as the data augmentation method. Still, we remove the augmentation types that have the potential to generate anomalies, \eg, `shear\_x', `shear\_y', `translate\_x', and `translate\_y', to ensure that all generated data are normal samples.

Intuitively, the last block of decoder is responsible for reconstructing simple and low-level features, such as edges, corners, and blobs, while the bottleneck layer is responsible for extracting more complex and high-level features. At the bottleneck layer, the abstracted information of the same images from different synthesized methods must be the same, while retaining enough information for reconstruction in the decoder. Therefore, by minimizing the loss function in Eq. \ref{eq:sumloss}, GNL learns features from both low-layer CNNs and high-level CNNs respectively to be the same from different distributions generated from a single sample. 

\subsection{Test Time Augmentation for Anomaly Detection under Distribution Shift}

The goal of this component is to address the problem of a mismatch between the distribution of data during testing. To accomplish this, we propose injecting training distribution into the inference samples by using Feature Distribution Matching (FDM) at multi-level layers of the teacher encoder in the inference phase. The proposed testing framework is demonstrated in Fig. \ref{fig:proposedframework} (b). Our test time augmentation is applied at the first two residual blocks of the teacher encoder. The inference process from the third residual block onwards, as well as the calculation of the anomaly score, follow the original RD4AD framework without any modifications.


FDM is a group of techniques that aims to reduce the distribution mismatch or discrepancy of data from two different domains. Some previous studies focused on FDM assume that the input features follow a Gaussian distribution \cite{huang2017arbitrary, lu2019closed, mroueh2020wasserstein}. More recently, Zhang et al. \cite{zhang2022exact} introduced a more accurate approach, known as Exact Feature Distribution Matching (EFDM). EFDM precisely matches empirical Cumulative Distribution Functions of image features,
resulting in exact feature distribution alignment (as the sample size tends to infinity) and accurate matching of statistical properties like mean, standard deviation, and high-order statistics. Basically, all these FDM techniques are applicable to our proposed framework. Noted that FDM have been used for OOD Generalization, \eg, in Mixstyle \cite{zhoudomain} and EDFMix \cite{zhang2022exact}, but they are used during training with the goal of creating new distribution samples by mixing the subdomain of the samples available in the training set, while we adopt FDM as a component in the inference stage with a different objective.

Specifically, given a test sample $p \in \mathcal{D}_t$, we randomly select a training normal sample $ q \in \mathcal{D}_s$. These two samples are then fed into the teacher encoder. Let $\mathcal P^m$ and $\mathcal Q^m$ be the embedded features of $p$ and $q$ at the residual encoding block $E^m$, respectively, then the testing process is performed as follows:
% following the equation \ref{equa:test}, which is defined as:
%{x}_{norm}
% Let ${\chi}^{m}_{main}$ and  ${\chi}^{m}_{norm}$ is the embedded feature that are fed into the next layer ${E}^{m+1}_{main}$ and ${E}^{m+1}_{norm}$, defined as: 
% \begin{equation}
% {\chi}^{m}_{main} = FDM(E^{m}_{main}, E^{m}_{norm},\alpha)
%   \label {eq:sumloss}, 
% \end{equation}
% \begin{equation}
% {\chi}^{m}_{main} = FDM(E^{m}_{main}, E^{m}_{norm},\alpha)
%   \label {eq:sumloss}, 
% \end{equation}
% % $ {\chi}^{m} = FDM(E^{m}(x), E^{m}({x}_{norm}),\alpha) $ 
% \begin{equation}
% \begin{cases}
% {\chi}^{m}{main} = FDM(\mathcal E^{m}{main}, \mathcal E^{m}{norm},\alpha) \\
% {\chi}^{m}{norm} = \mathcal E^{m}{norm}
% \end{cases}
% \end{equation}
\begin{equation}
\begin{cases}
\mathcal P^{m+1} = \text{FDM}(E^{m+1}(\mathcal P^{m}), \mathcal Q^{m+1},\alpha) \\
\mathcal Q^{m+1} = {E}^{m+1}(\mathcal Q^{m})\\
\mathcal P^{0} = p, \mathcal Q^{0} = q,\\

% \mathcal O^{1} = FDM({E}^{1}(x), \mathcal P^{1},\alpha)\\
% \mathcal P^{1} = {E}^{1}(q)
\end{cases}
\label{equa:test}
\end{equation}
where $ m \in \{0,1\}$ and $\alpha$ is a hyperparameter balancing the severity for mixing the style between the inference sample and the selected normal sample. The processed embedded features $\mathcal P^{1} \text{ and } \mathcal P^{2}$ are then input into the bottleneck layer and participate in the calculation of anomaly scores following the inference process of the original RD4AD.

For the $\text{FDM}()$ function above, EFDM\cite{zhang2022exact}, which is the SOTA of FDM, is adopted to our method as follow:
\begin{equation}
\textrm {FDM}(\mathcal{C} ,\mathcal{V} , \alpha ): \mathcal{C} _{\tau _i} = (1-\alpha) {\mathcal{C} _{\tau_i}} + \alpha  {\mathcal{V} _{\kappa _i}} 
  \label {eq:sumloss}, 
\end{equation}
where ${\{\mathcal{C} _{\tau _i}\}}^n_{i=1}$ and ${\{\mathcal{V} _{\kappa _i}\}}^n_{i=1}$ are sorted values of embedded feature $\mathcal{C}$ and $\mathcal{V}$ in ascending order.  Here, $n$ represents the number of elements in vector $\mathcal{C}$ and $\mathcal{V}$. Note that $\mathcal{C}$ is the embedded feature of the test sample $p$, which plays the role of carrying the appearance information. $\mathcal{V}$ is the embedded feature of a normal sample $q$ randomly sampled from the training data, carrying the style information.

In essence, the sample $q$ plays a role in conveying distribution information pertaining to the training data. The selection of a random sample is due to the monotonous nature of the data during training, as any sample in the training set is capable of carrying distribution information that represents the training data. Thus, It helps avoid a process for careful sample selection that is often computationally expensive.

By utilizing FDM, our proposed testing process minimizes the disparity between the feature distribution of the inference sample and the feature distribution of normal samples in the training data, in cases where inference samples come from OOD sets. Furthermore, FDM ensures that the feature distribution remains nearly unchanged if inference samples come from ID sets, since the distribution of the test sample is aligned with its own distribution. Therefore, our testing approach can improve performance on OOD data without sacrificing performance on ID data.

%${m}^{th}$
\section{Experiments}
% \subsection{Experimental Settings}
\subsection{Datasets}
We adapt four datasets from both AD and OOD generalization as the dataset benchmarks for the studied task.

\textbf{Anomaly Detection.}
\textbf{MVTec} \cite{bergmann2019mvtec} is a widely-used AD benchmark, which comprises 15 data subsets for industrial defect inspection,
% distinct collections of authentic data aimed at detecting anomalies. These datasets encompass
including 5 subsets on texture anomalies and 10 subsets on object anomalies. The training dataset consists of 3,629 images in total, all of which are normal images. In contrast, the test dataset contains a total of 1,725 images, comprising both defective and non-defective instances. \textbf{CIFAR-10 \cite{krizhevsky2009cifar}} serves as a one-class classification benchmark, featuring 50,000 training and 10,000 test images across 10 equally-sized categories representing diverse natural entities. In order to generate OOD datasets for MVTec and CIFAR-10, we apply 4 types of visual corruptions~\cite{hendrycks2019robustness} to MVTec and CIFAR-10: Brightness, Contrast, Defocus Blur, and Gaussian noise. The severity for each type of corruption is set to 3 on MVTec and 5 on CIFAR-10 for obtaining the out-of-distribution data. 

\textbf{OOD Generalization.} 
% We conduct a one-class novelty detection experiment on two semantic datasets:
Two popular OOD benchmarks, \textbf{MNIST-M} \cite{ganin2015unsupervised} and \textbf{PACS} \cite{li2017deeper}, are taken in our experiments.
% \textbf{Handwritten Digit Recognition.}  We use 
In particular, the primary MNIST \cite{lecun1998gradient} is used as the ID data on which the models are trained on, while MNIST-M is used as the OOD set. MNIST and MNIST-M datasets share 10 classes, which correspond to the digits 0 through 9. While MNIST encompasses 70,000 grayscale images of handwritten digits, MNIST-M contains 68,000 OOD images that are synthesized by superimposing random colored patches on the original images from MNIST. PACS is another widely used OOD dataset consisting of 9,991 images, which are shared by seven classes and four domains, namely Art, Cartoon, Photo, and Sketch. We select the images in Photo as the ID data, with the images in Art, Cartoon, and Sketch as the OOD data. 
% We use 8,977 images for training and 1014 images for testing.
The commonly used one-versus-all protocol \cite{perera2019ocgan} is used to convert the these two datasets into AD datasets with distribution shift, in which samples of one class are used as normal, with the rest of classes as anomaly classes. Furthermore, we perform a multi-class setting on the MNIST/MNIST-M dataset, labeling samples from even-numbered classes as normal, while those from odd-numbered classes are identified as anomalies.
% We train models with samples from a single class and then test them on novel samples. If a sample does not belong to the class that the model is trained on, it is considered an anomaly, and vice versa. 

During training, we only use images in the ID dataset, \ie, assuming the OOD data is not available during training. During inference, test sets of both ID and OOD are used.

\subsection{\textbf{Baselines}}
% \textbf{Anomaly Detection Methods.}
We conduct a series of experimental evaluations on 4 prominent anomaly detection methods, namely Deep SVDD \cite{ruff2018deep}, f-AnoGAN \cite{schlegl2019f}, KDAD \cite{salehi2021multiresolution}, and RD4AD \cite{deng2022anomaly}. These methods stand for popular AD methods and recent state-of-the-art (SOTA) AD models.
% come from a wide range of algorithmic approaches and diverse features.
% \textbf{OOD Generalization Methods.}
To evaluate the efficacy of OOD generalization techniques in anomaly detection, we adapt a suite of cutting-edge OOD methods by combining them with the recently proposed RD4AD model, which boosts SOTA performance on multiple datasets. Four different methods are used, including three data augmentation-based methods Augmix \cite{hendrycks2019augmix}, Mixstyle \cite{zhoudomain}, and EFDM \cite{zhang2022exact}, and one self-supervised method Jigsaw \cite{carlucci2019domain}. 
% Each of these methods has demonstrated considerable promise in the domain generalization literature and represents a diverse array of strategies for improving the performance of anomaly detection models.  

\subsection{Implementation Details}
% \textbf{Our Model GNL.} In essence,
Our proposed method GNL is implemented on top of the RD4AD framework. Therefore, we maintain the settings recommended by RD4AD, such as the image size, the optimization method, the way of calculating anomaly score, and other relevant parameters. The details can be found in Appendix. Regarding the specific parameters for our model GNL, we choose $N=2$ for the number of augmented normal samples generated by data augmentation. We set $\lambda_{ori}=0.9, \lambda_{abs}=0.05 \text{ and } \lambda_{lowf}=0.05$ by default for the distribution-invariant, normality-preserved loss function. During the inference phase, we opt for $\alpha=0.5$ to control the degree of style blending for MVTec, PACS, and CIFAR-10 datasets, while setting $\alpha=0.9$ for MNIST/MNIST-M, effectively managing the mixing dynamics. We choose EFDM \cite{zhang2022exact} as the FDM technique since it is the latest and shows SOTA performance. 

For the AD baselines, we use the official implementation published by the authors of those baselines. 
% \textbf{AD Baselines.} We have run all the baseline experiments according to the implementation published by the authors of those baselines. 
However, since the original baselines did not include experiments on the PACS dataset, we use the hyperparameters from MVTec experiments to conduct experiments on the PACS dataset corresponding to each baseline. 

For the OOD generalization baselines, we use Augmix with an online augmentation severity of 3. We use all the data augmentation types included in Augmix for MNIST and PACS. However, for the MVTec and CIFAR-10 dataset, we exclude two types of augmentation that overlap with two types of corruptions during testing: Brightness and Contrast. With Mixstyle and EFDM, which are two data augmentation methods at the feature level (rather than at the image level like Augmix), we apply Mixstyle and EFDM to the encoders in the first two network layer according to the settings in RD4AD. As for Jigsaw, we fit the Jigsaw task into the Bottleneck component in RD4AD. All hyperparameters of training are preserved when applying OOD generalization baselines into RD4AD.

Following previous studies \cite{ruff2018deep, schlegl2019f, salehi2021multiresolution, deng2022anomaly,ding2022catching}, we evaluate the performance of our anomaly detection methods using a metric called the Area Under the ROC Curve (AUROC). This metric is commonly used to assess how well a given method is able to distinguish between normal and anomalous data points. The results are averaged over three independent runs.
% by running training testing three times and computing the average values.

\subsection{Comparison Results}


% \subsubsection{Results on MVTec AD}

% \textbf{Performance of AD Models.}

% \textbf{Performance of Adapted OOD Models.}

% \textbf{Performance of Our Models.}

The performance of our model GNL and the baselines on MVTec, CIFAR-10, MNIST, and PACS are shown in Tables \ref{tab:mvtec}, \ref{cifar10}, \ref{tab:mnist} and \ref{tab:pacs}, respectively. Note that due to space limitations, the performances in all four tables are the average results of the classes per dataset. Detailed results are presented in Appendix. Overall, GNL can significantly outperforms SOTA AD models and OOD generalization methods in detecting anomalies on the OOD test data, while at the same time maintaining the detection accuracy on the ID data. Below we discuss the results in detail.

\subsubsection{Performance of AD Methods}
In general, we observe a significant drop in the AUC scores of all AD methods, Deep SVDD, f-AnoGAN, KDAD and RD4AD, on the OOD data across all four datasets used. This indicates that their performance is severely affected by the distribution shift. In particular, the performance of all AD models is promising on the MNIST set. However, this performance is reduced by about 30-40\% when the models are tested on the MNIST-M set, which contains variations that are not present in the original MNIST set. Similar trends are observed in the PACS dataset, where the models' performance is also significantly affected by the distribution shifts in the OOD data. The models perform well on the Photo data, which is the ID data, but their performance drops significantly on the three OOD datasets, Art, Cartoon and Sketch. On MVTec and CIFAR-10, the performance still drops but is less severe than on the other two sets.


\begin{table}[h]
\centering
\scalebox{0.8}{
\begin{tabular}{l|c|cccc}
\hline
& \multicolumn{1}{c}{ID} & \multicolumn{4}{|c}{OOD} \\
\cline{2-5}
\hline
Method & MVTec & Brightness & Contrast & Blur & Noise \\
\hline
Deep SVDD & 69.98 & 55.18 & 50.07 & 68.82 & 59.11 \\
f-AnoGAN & 75.65 & 48.36 & 49.29 & 37.98 & 39.10\\
KDAD & 85.50 & 83.81 & 64.03 & 84.17 & 82.04 \\
RD4AD & \textbf{98.64} & 96.50 & 94.12 & \textbf{98.9} & 90.14 \\
\hline
Augmix & 96.29 & 95.10 & 94.51 & 95.39 & 90.99 \\
Mixstyle & 98.58 & 96.60 & 94.45 & 98.27 & 88.92 \\
EFDM & 98.64 & 96.78 & 94.77 & 98.25 & 89.29 \\
Augmix+Mixstyle & 96.78 & 96.86 & 94.57 & 98.73 & 90.12 \\
Augmix+EFDM & 97.04 & 96.83 & 95.21 & 98.11 & 90.18  \\
Jigsaw & 73.97 & 73.36 & 67.88 & 73.88 & 72.60 \\
\hline
GNL (Ours) & 97.99 & \textbf{97.43} & \textbf{97.46} & 97.77 & \textbf{94.10} \\
\hline
\end{tabular}
}


\caption{AUROC (\%) results on MVTec and its four corruptions. The best performance is \textbf{boldfaced}.}
% Methods achieved for the first AUROC (\%) are highlighted in bold.}
\label{tab:mvtec}
\end{table}


\begin{table}[h]
\centering
\scalebox{0.8}{
\begin{tabular}{c|c|cccc}
\hline
& \multicolumn{1}{c}{ID} & \multicolumn{4}{|c}{OOD} \\ \hline
Method &CIFAR & Brightness & Contrast & Blur & Noise  \\
\hline
Deep SVDD & 64.62 & 59.13 & 55.94  & 62.13 & 54.46 \\
f-AnoGAN & 70.25 & 54.62 & 57.23  & 60.74 & 51.76 \\
KDAD & 84.21 & 75.91 & 64.37  & 63.49 & 56.87 \\
RD4AD & \textbf{84.62} & 75.89 & 65.34  & 66.67 & 58.82 \\ \hline
Augmix & 82.83 & 74.15 & 62.48  & \textbf{66.92} & 57.36\\
Mixstyle & 83.68 & 76.07 & 63.87  & 65.74 & 57.74\\
EFDM & 83.92 & 76.19 & 63.92  & 64.81 & 57.63\\
Augmix+Mixstyle & 83.87 & 76.02 & 65.55 & 63.89 & 58.04 \\
Augmix+EFDM & 82.96 & 75.73 & 64.39 & 63.83 & 57.14 \\
Jigsaw & 71.29 & 66.86 & 61.45 & 60.12 & 55.29 \\\hline
Ours & 82.29 & \textbf{77.94} & \textbf{66.13}  & 64.04 & \textbf{61.51} \\
\hline
\end{tabular}}
\caption{AUROC (\%) results on CIFAR-10 and its four corruptions.}
% and its four corruptions.}
\label{cifar10}
\end{table} 


\begin{table}[h]
\centering
\scalebox{0.9}{
\begin{tabular}{c|cc|cc}
\hline
& \multicolumn{2}{c}{One-vs-All} & \multicolumn{2}{|c}{Multi-class} \\
\hline
Method  & ID & OOD & ID & OOD\\
\hline
Deep SVDD & 97.73 & 49.92 & 86.94 & 51.19 \\
f-AnoGAN & 97.52 & 52.72 & 88.45 & 51.85\\
KDAD & 98.87 & 54.87 & \textbf{90.43} & 52.84\\
RD4AD & \textbf{98.89} & 58.09 & 88.70 & 51.74\\
\hline
Augmix & 98.26 & 59.61 & 88.76 & 52.19\\
Mixstyle & 98.84 & 57.22 & 87.36 & 52.13\\ 
EFDM & 98.62 & 57.23 & 87.78 & 52.36\\
Augmix+Mixstyle & 98.12 & 58.89 & 89.23 & 52.45  \\
Augmix+EFDM & 98.24 & 58.91 & 90.04 & 52.64\\
Jigsaw & 98.90 & 58.51 & 87.29 & 52.87\\
\hline
GNL (Ours) & 96.91 & \textbf{70.87} & 88.59 & \textbf{58.50}\\
\hline
\end{tabular}
}
\caption{AUROC results (\%)  on in-distribution (MNIST) and out-of-distribution (MNIST-M) datasets for one-vs-all and multi-class settings.}
% as measured by the Area Under the Receiver Operating Characteristic (AUROC)}
\label{tab:mnist}
\end{table}
% 

\begin{table}[h]
\centering
\scalebox{0.9}{
\begin{tabular}{l|c|ccc}
\hline
& \multicolumn{1}{c}{ID} & \multicolumn{3}{|c}{OOD}  \\
\cline{2-5}
\hline
Method & Photo & Art & Cartoon & Sketch  \\ \hline
Deep SVDD   & 40.87&	53.42 &	41.23 & 	39.48 \\
f-AnoGAN &  61.34 &  50.15 &  52.42 &  63.77   \\
KDAD &  \textbf{88.17} &  62.86 &  62.64 &  51.40 \\
RD4AD &  81.49 &  61.07 &  60.34 &  55.06  \\
\hline
Augmix &  76.35 &  60.50 &  58.96 &  57.86  \\
Mixstyle &  78.23 &  60.93 &  60.93 &  54.89 \\
EFDM &  78.47 &  60.55 &  62.15 &  55.63  \\
Augmix+Mixstyle & 76.12 & 60.16 &  61.29 & 55.76\\
Augmix+EFDM & 77.28 & 60.93 &  63.18 & 56.67\\
Jigsaw &  62.19 &  52.55 &  53.83 &  62.15  \\
\hline
GNL (Ours) &  87.67 &  \textbf{65.62} &  \textbf{67.96} &  \textbf{62.39}  \\ 
\hline
\end{tabular}
}
\caption{AUROC results (\%) on in-distribution (Photo) and out-of-distribution (Art, Cartoon, Sketch) datasets.}
% , as measured by the Area Under the Receiver Operating Characteristic (AUROC).}
\label{tab:pacs}
\end{table}



% This could be because the dataset contains images of the same object taken from different angles and under different lighting conditions, which is more similar to the in-distribution data that the models were trained on.\\

\subsubsection{Performance of Combined OOD Generalization and AD Methods}
Our results in Tables \ref{tab:mvtec}, \ref{cifar10}, \ref{tab:mnist} and \ref{tab:pacs} indicate that the detection performance cannot be significantly improved by combining different OOD generalization techniques with the recent SOTA AD model RD4AD on the four datasets. This lack of improvement can be attributed to the fact that these OOD methods attempt to increase the diversity of data by enriching the available data based on its own distribution. However, because the training data in AD is typically monotonous and unimodal, these OOD methods often fail to generate data samples that significantly deviate from the original data distribution. As a result, the added diversity of generated data is not sufficient to significantly improve the performance of AD models.

Moreover, these OOD techniques also have a tendency to generate undesired anomaly data, which is akin to injecting noise into the training data, thereby reducing the performance of AD models on the in-distribution dataset.

\subsubsection{Performance of Our Method GNL}
 
On the MVTec AD dataset in Table \ref{tab:mvtec}, our method shows remarkable improvement in performance on the OOD dataset, while maintaining the performance on the ID data. In fact, our method achieves a highly comparable AUROC score of 0.9799 on the original MVTec ID data, while also obtaining an impressive AUROC score of 0.9743 on the Brightness, 0.9746 on Contrast, 0.9777 on the Defocus\_blur dataset, and 0.9410 on Gaussian Noise, which are significant improvements over the other methods. These results demonstrate the robustness and effectiveness of our GNL model to diverse distribution shifts. 


Our experimental findings on the CIFAR-10 dataset exhibit a close resemblance to the outcomes observed on the MVTec dataset, as depicted in Table \ref{cifar10}. Our approach attains a competitive AUROC score of 0.8229 on the native MVTec ID data. Notably, our method yields enhanced AUROC scores of 0.7794 for Brightness, 0.6613 for Contrast, 0.6404 for Defocus\_blur, and 0.6151 for Gaussian Noise datasets, showcasing often large enhancements compared to other method, especially on the Contrast and Noise cases.

 % \textbf{One-class Novelty Detection}
On the MNIST/MNIST-M dataset in Table \ref{tab:mnist}, GNL consistently and significantly outperforms all other methods on the OOD data MNIST-M, increasing by at least 10 AUROC scores. Compared to the best performer -- RD4AD -- on the ID dataset that obtains an AUROC score of 0.9889, GNL exhibits a small decline and obtains an AUROC score of 0.9691. However, a significant improvement in performance is observed on the MNIST-M dataset, with an AUROC score of 0.7087 compared to 0.5809 for RD4AD. Regarding the multi-class setting, the results indicate its increased challenge compared to one-vs-all setting. Our model still maintains superior performance on OOD data while also excelling on ID data.

Similarly, GNL achieves consistently more superior AUROC performance on all four OOD datasets of PACS in Table \ref{tab:pacs}. In particular, GNL obtains AUROC scores of 0.6562, 0.6796, and 0.6239 for the Art, Cartoon, and Sketch datasets, respectively, increasing by at least 5\% on the Art and Cartoon datasets over the competing models. Compared to RD4AD, our method not only largely improves the OOD performance, but also enhances its performance on the ID data, the Photo data. This is because the Photo data contains multiple sub-domains, and RD4AD can be susceptible to overfitting on a specific sub-domain in the training data. By contrast, our method helps to mitigate this issue by learning more generalized normality representations, which improves performance across all sub-domains within the Photo data. The performance of GNL on the ID data is also highly comparable to the best performer KDAD, 0.8767 vs. 0.8817, whereas GNL outperforms KDAD on the three OOD datasets by about 3\%-10\% in AUROC.



% Anomaly detection results on MVTec are shown in Tab. 1

\subsection{Robustness to Various Distribution Shift Levels}

Fig. \ref{fig:changingseverity} presents the results of the robustness of GNL to varying levels of distribution shift, using the best competing methods RD4AD, Augmix and EFDM as baselines. The experiments are done on MVTec with increasing levels of `Contrast' corruption. Notably, the performance of the baselines exhibits a significant decline as the severity of corruption amplifies.
% , which unmistakably reveals their susceptibility to distribution shifts. 
The reason behind this phenomenon is intuitive as increased corruption severity introduces more substantial distribution variance, making it arduous for the models to discern between anomalous and normal samples. Our proposed method, on the other hand, demonstrates remarkable stability in performance across multiple levels of distribution shift. Our method maintains stable performance when the severity is between 1 and 3, and reduces to an AUROC of about 0.90 when the severity is 4 and 5, decreasing about 5\% AUROC vs. about 30\%-35\% decrease in the competing methods. These results indicate 
% that our method has the ability to operate efficiently on multiple levels of distribution shift and is 
strong robustness of GNL to heavy distribution shifts.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.49\textwidth]{changingseverity.pdf}
    \caption{AUROC results on MVTec with varying severity of the `Contrast’ corruption.}
    \label{fig:changingseverity}
\end{figure}

\subsection{Ablation Study}



We examine the importance of two main components: Distribution-invariant Normality Learning (DINL) using $\mathcal{L}_{abs}$ and $\mathcal{L}_{abs}$ individually or simultaneously (in addition to $\mathcal{L}_{ori}$),  and AD-oriented Test Time Augmentation (ATTA) on the PACS dataset, with RD4AD as the baseline. The results are reported in Table \ref{tab:ablation}. The experiment results show that $\mathcal{L}_{abs} $ and $\mathcal{L}_{lowf} $ positively contribute to the superior performance of DINL from low-level and high-level features respectively; and they can complement each other when combining them in DINL. Looking more broadly, two main components, DINL and ATTA ,also positively contribute to the superior performance of GNL. In particular, the experimental results show that if only the test time augmentation is applied, we gain about 2\% AUROC improvement over the baseline on the OOD datasets, but it leads to a slight performance decrease on the ID data. 
% Even on the Photo (ID) domain, the performance is also reduced.
When DINL is applied, it results in substantial improvement across both ID and OOD datasets, having 4\%-7\% AUROC improvement. When both are applied, we obtain the best performance, resulting in further substantial AUROC improvement. This indicates that both components, one reducing the distribution gap during training and another reducing the gap during inference, can well complement each other.
% not only improves the detection performance of the original model by itself but also makes test time augmentation more efficient than when test time augmentation is applied to the original model. 
% Experimental results also illustrate that EFDM shows slightly more efficiency than AdaIN in all domains.

\begin{table}[h]
\centering
\scalebox{0.9}{
\begin{tabular}{c|c|ccc}
\hline
& \multicolumn{1}{c}{ID} & \multicolumn{3}{|c}{OOD} \\
\cline{1-5}

 Method & Photo & Art & Cartoon & Sketch \\
\hline
Baseline &  81.49 &  61.07 &  60.34 &  55.06 \\
$\mathcal {L}_{abs} $ only  & 82.02 & 60.59 & 63.93 & 56.81 \\
$\mathcal {L}_{lowf} $ only & 82.90 & 61.27 & 62.25 & 55.52 \\
DINL &  85.71 &  62.34 &  65.63 &  57.12 \\
ATTA &  81.05 &  64.36 &  62.04 &  57.04 \\
DINL+ATTA &  \textbf{87.67} &  \textbf{65.62} &  \textbf{67.96} &  \textbf{62.39} \\
\hline
\end{tabular}
}
\caption{AUROC results (\%) of ablation study.}
% and the effectiveness of two arbitrary style transfers, AdaIN and EFDM
\label{tab:ablation}
\end{table} 



\begin{figure}[h]
    \centering
    \includegraphics[width=0.49\textwidth]{Alpha.pdf}
    \caption{AUROC results using varying $\alpha$.
    % changes with the same model applied DINL during training and TTAAD with EFDM in inference phase. 
    The smaller the $\alpha$ value, the lower the severity of style transfer.}
    \label{fig:alpha}
\end{figure}


\subsection{Hyperparameter Analysis}
Fig. \ref{fig:alpha} depicts how the performance of our model GNL changes with varying $\alpha$, which is a hyperparameter in ATTA. 
% The model is trained using Distribution-invariant Normality Learning methodology, and the testing phase is augmented with EFDM. 
The results suggest that the effectiveness of our model remains consistent across different $\alpha$ values on the Photo and Cartoon datasets. In contrast, the model's ability to detect anomalies on the Art data appears to improve as $\alpha$ increases. However, for the Sketch data, the model's performance reaches its maximum at $\alpha = 0.4$ and slightly decreases as $\alpha$ increases further. Overall, a medium value, \eg, $\alpha=0.5$, is generally recommended in practice.



We evaluate the hyperparameter sensitivity of our key component DINL using four settings of the three $\lambda$ hyperparameters: $\lambda _{ori}$, $ \lambda _{abs}$, and $\lambda _{lowf}$, with their sum set to one to ease the analysis. $ \lambda _{abs}=\lambda _{lowf}$ is used as the features learned by them are considered equally important for the task. The results on PACS are shown in Table \ref{tb2}. DINL shows good robustness across different hyperparameter ratios in the three losses. 

\begin{table}[h]
\centering
\scalebox{0.8}{
\begin{tabular}{c|c|ccc}
\hline
$\lambda _{ori}; \lambda _{abs}; \lambda _{lowf}$   &Photo (ID) & Art & Cartoon & Sketch \\
\hline
0.95, 0.025, 0.025 & 85.90 & 62.71 & 64.28 & 59.97 \\
0.90, 0.050, 0.050 & 85.71 & 62.34 & 65.63 & 57.12 \\
0.85, 0.075, 0.075 & 85.60 & 63.23 & 65.03 & 58.57 \\
0.80, 0.100, 0.100 & 84.89 & 61.45 & 65.12 & 56.84 \\
\hline
\end{tabular}}
\caption{AUROC using various $\lambda$ settings.}
\label{tb2}
\end{table}


\subsection{Time and Space Efficiency}
For space complexity, our method improves the training objective and the inference of RD4AD without altering its architecture, thereby avoiding any increase in the number of parameters. 

% As for time efficiency, it is unsurprising that our method entails a slightly extended training duration in comparison to RD4AD. However, it is noteworthy that this incremental training time is accompanied by the substantial benefits of improved performance. In terms of inference efficiency, our approach maintains a commendable level of responsiveness, as evidenced by the data presented in Table \ref{time}.
As shown in Table \ref{time}, in terms of time efficiency, our method's training duration is slightly longer than RD4AD, but this additional time yields substantial performance improvements. As for the inference, our approach remains reasonably responsive.

\begin{table}[h]
\centering
\scalebox{0.8}{
\begin{tabular}{ccc}
\hline
Model & Training (per epoch) & Inference (per image) \\
\hline
RD4AD & 2.5726  & 0.0282 \\
Ours & 7.2557 & 0.0356 \\
\hline
\end{tabular}}
\caption{Runtime (s) on the `Dog' dataset of PACS using one RTX 3090 24GB GPU.}\label{time}
\end{table}

\section{Conclusion}
In this work we propose a novel approach, namely GNL, to addressing the problem of anomaly detection in the presence of distribution shifts. GNL improves the generalization of the detection model by reducing the distribution gap between ID and OOD normal data in both training and inference stages. We also present comprehensive performance benchmarks and reveal that combined AD and OOD generalization methods do not work well for this task. Our approach is specifically designed for the OOD generalization in the AD task and shows significant improvement over the competing baselines. As shown in our results, our approach GNL is also robust to heavy distribution shifts.
% Our experimental results demonstrate that our approach outperforms existing methods for detecting anomalies in the presence of distribution shift. 
Overall, our approach represents an important contribution to unsupervised anomaly detection, as it addresses a more realistic problem that has not been adequately studied before.

% In future work, we plan to explore extensions of our approach to handle more complex scenarios and investigate its applicability to other types of data.





% \include{Appendix}

{\small
\bibliographystyle{ieee_fullname}
\bibliography{refs}
}
\appendix

\include{apx}



\end{document}
