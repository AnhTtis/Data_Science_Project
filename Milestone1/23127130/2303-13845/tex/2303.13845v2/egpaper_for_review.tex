\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{diagbox}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage{cite}
% \usepackage{natbib}
% \bibliographystyle{unsrtnat}
% \bibliography{refs.bib}

% \usepackage[sort]{natbib}
% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\newcommand{\guansong}[1]{{\color{purple}[Guansong]: #1}}
% \iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{10957} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi % Required for inserting images

\title{Anomaly Detection under Distribution Shift}


\begin{document}

\maketitle
\begin{abstract}

Anomaly detection (AD) is a crucial machine learning task that aims to learn patterns from a set of normal training samples to identify abnormal samples in test data. 
% However, most previous works on anomaly detection
Most existing AD studies
% have focused on detecting anomalies within a single distribution, and have assumed
assume that the training and test data are drawn from the same data distribution, but the test data can have large distribution shifts arising in many real-world applications due to different natural variations such as new lighting conditions, object poses, or background appearances, rendering existing AD methods ineffective in such cases.
% remains stationary over time. 
In this paper, we consider the problem of anomaly detection under distribution shift and establish performance benchmarks on three widely-used AD and out-of-distribution (OOD) generalization datasets. We demonstrate that simple adaptation of state-of-the-art OOD generalization methods to AD settings fails to work effectively due to the lack of labeled anomaly data. We further introduce a novel robust AD approach to diverse distribution shifts by minimizing the distribution gap between in-distribution and OOD normal samples in both the training and inference stages in an unsupervised way. 
% propose a novel approach to anomaly detection that can handle the challenge of distribution shift, where the data distribution changes over time. We define a new problem that combines the challenges of anomaly detection and distribution shift, and introduce a benchmark dataset that includes different types of distribution shift. We propose a new training process and inference method that can improve the performance of the anomaly detection model on out-of-distribution data. Our proposed approach involves improving the generalization of the model during the training phase, as well as reducing the gap between in-distribution and out-of-distribution data during the inference phase.
Our extensive empirical results on the three datasets show that our approach substantially outperforms state-of-the-art AD methods and OOD generalization methods on data with various distribution shifts, while maintaining the detection accuracy on in-distribution data. 
% to evaluate the performance of our approach, and demonstrate that it outperforms existing methods for detecting anomalies in the presence of distribution shift. 
% To the best of our knowledge, this is the first work to introduce the context of distribution shift into the unsupervised anomaly detection.

\end{abstract}
\section{Introduction}
% \subsection{The Challenges} 

% \guansong{have you updated the introduction section based on our last meeting's comments? please do so if you haven't}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{Preview3.pdf}
    \caption{Illustrative samples for anomaly detection under distribution shift. First row: the `Wood' dataset from MVTec \cite{bergmann2019mvtec}. Second row: the `Elephant' class as normal and the remaining classes as anomaly in PACS \cite{li2017deeper}. Third row: the `0' class as normal and the remaining classes as anomaly in MNIST\cite{lecun1998gradient}/MNIST-M\cite{ganin2015unsupervised}. We aim at distinguishing anomalies from normal data in both in-distribution test data and out-distribution test data
    % \guansong{changes to be made: `In-Distribution in Test Set' to `In-distribution Test Data';`Out-of-Distribution in Test Set' to `Out-of-distribution Test Data'; having different background colors for the columns of normal samples and anomalous samples may look more straightforward }
    }
    \label{fig:intro}
\end{figure}
Anomaly Detection (AD) is a crucial task in machine learning that aims to identify rare and unusual patterns in data. It is an important problem in various domains, such as financial domain \cite{ahmed2016survey, anandakrishnan2018anomaly}, cybersecurity \cite{ten2011anomaly, siddiqui2019detecting}, industrial inspection \cite{bergmann2019mvtec}, and medical diagnosis \cite{schlegl2019f, shvetsova2021anomaly}. 
% In anomaly detection, the goal is to distinguish normal patterns from abnormal patterns, which can be caused by various factors, such as errors, faults, attacks, or anomalies.
Due to the difficulty and/or high cost of collecting labeled anomaly data,
% and the difficulty in obtaining negative samples in many applications, 
% AD is often approached as an 
current AD studies are focused on unsupervised approaches, which aim to learn patterns from a set of normal training samples to identify abnormal samples in test data.
% . In unsupervised learning, the model is trained on a dataset of normal patterns, and then used to detect anomalies in new data. By being focused by the research community,
% the performance of AD models in many tasks is impressive, some models even achieve near-perfect accuracy \cite{li2021cutpaste, salehi2021multiresolution, deng2022anomaly}.

Although existing AD studies have demonstrated promising performance \cite{li2021cutpaste, salehi2021multiresolution, deng2022anomaly,pang2021deep}, they generally assume that the training and test data are drawn from the same data distribution. However, this assumption is often unrealistic in real-world scenarios as the test data can have large distribution shifts arising in many applications due to different natural variations such as new lighting conditions, object poses, or background appearances, rendering the AD methods ineffective in such cases.
% However, in real-world scenarios, the data distribution may change over time, due to various factors such as changes in the environment, data collection process, or system configurations. This phenomenon is known as 

Distribution shift is a ubiquitous problem in different real-world applications, which can significantly degrade the performance of models in various tasks such as image classification, object detection, and segmentation \cite{koh2021wilds, ganin2015unsupervised, li2017deeper, zhang2020generalizing}. Many out-of-distribution (OOD) generalization methods have been introduced to address this problem \cite{huang2020self, hendrycks2019augmix, zhang2022exact, carlucci2019domain, ghifary2015domain, lehner20223d, ma2020training, liu2021feddg, ouyang2022causality}. 
% Assuming only source domain data available, the target domain data can not access, DG try to develop a model that 
These OOD generalization methods rely on large labeled training data from one or multiple relevant domains to learn domain-invariant feature representations. They often require class labels \cite{yao2022pcl, huang2020self, qiao2020learning}, domain labels \cite{zhao2021learning, yoon2019generalizable, wang2020cross, carlucci2019hallucinating}, or the existence of diverse data \cite{hendrycks2019augmix, zhang2022exact, zhoudomain} in the source domain to learn such robust feature representations.
% from a single or multi source domains in the hope that it would remain discriminative given target domain data. 
% Despite the importance of distribution shift, most previous works on anomaly detection have focused on detecting anomalies within a single distribution, and have assumed that the data distribution remains stationary over time. This assumption is often unrealistic in real-world scenarios, and can lead to poor performance of the anomaly detection model when it encounters data that is different from the training distribution. The task of anomaly detection under distribution shift can be even more challenging compared to other tasks like classification or segmentation since 
However, the training data in the AD task consists of only one class, and the data is monotonous. Consequently, it is difficult to adapt existing OOD generalization techniques to address the AD under distribution shift problem. Trivial adaption of the OOD generalization can fail to learn generalized normality representations, leading to many detection errors, \eg, normal samples with distribution shifts cannot be distinguished from anomalous samples and consequently they are detected as anomaly. As shown by the exemplar data in Figure \ref{fig:intro}, normal samples in the in-distribution (ID) test data are very similar to the normal training data, and ID anomalies deviate largely from the normal data; however, due to the distribution shift, the normal samples in the OOD test data are substantially different from the ID normal data in terms of foreground and/or background features, and as a result, these normal samples can be falsely detected as anomaly. 
% since AD models are easily fooled by changes in features belonging to a particular domain as anomalies. 

% To address the challenge of distribution shift in anomaly detection, we propose a novel approach that combines the insights from both anomaly detection and domain adaptation. Our approach aims to improve the performance of the anomaly detection model on out-of-distribution data, by leveraging the knowledge of the underlying data distribution and adapting the model to the new distribution.

In this paper, we tackle the problem of anomaly detection under distribution shift. It is an \textit{OOD generalization} problem, aiming at learning generalized detection models to accurately detect normal and anomalous samples in test data with distribution shifts, while maintaining the effectiveness on in-distribution test data. This is different from the problem of \textit{OOD detection} \cite{
hendrycks2017baseline,hsu2020generalized,liu2020energy,ren2019likelihood,wang2022partial} that aims to equip supervised learning models with a capability of rejecting OOD/outlier samples as unknown samples for the sake of model deployment safety.
% aim to bridge the gap by introducing a new setting that combines the challenges of anomaly detection and the settings of domain generalization, and propose some techniques for addressing this problem. 
This work makes three main contributions in addressing the OOD generalization problem in the AD task:
\begin{itemize}
% \item We define a new problem that brings the context of distribution shift into the anomaly detection problem. By doing so, we hope to raise awareness of the importance of considering distribution shift in anomaly detection, and to motivate further research in this area. We introduce a new benchmark that includes different types of distribution shift. The benchmark is designed to evaluate the performance of anomaly detection models under distribution shift and show the effect of different types of distribution shift on the performance of different frameworks in anomaly detection. In addition, we examine the effectiveness of some existing methods in distribution shift problem when applied simply to anomaly detection models and see their performances. 
\item We present an extensive study of the distribution shift problem in AD and establish large performance benchmarks under various distribution shifts using three widely-used datasets adapted from AD and OOD generalization tasks. 
% We introduce a new benchmark that includes different types of distribution shift. The benchmark is designed to evaluate the performance of anomaly detection models under distribution shift and show the effect of different types of distribution shift on the performance of different frameworks in anomaly detection. In addition, 
Our empirical results further reveal that existing state-of-the-art (SOTA) AD and OOD generalization methods fail to work effectively in identifying anomalies under distribution shift.
% problem when applied simply to anomaly detection models and see their performances. 
\item We then propose a novel robust AD approach to diverse distribution shifts, namely \textit{generalized normality learning (GNL)}. GNL minimizes the distribution gap between ID and OOD normal samples in both the training and inference stages in an unsupervised way. To this end, we introduce a normality-preserved loss function to learn distribution-invariant normality representations, which enables GNL to learn generalized semantics of the normal training data at different feature levels. GNL also utilizes a test time augmentation method to further reduce the the distribution gap during the inference stage.
% novel training process and a test time augmentation method that can be easily applied to a state-of-the-art anomaly detection model and improve the performance on out-of-distribution data without sacrificing its performance on the in-distribution dataset. Our approach is a combination of making the model more general in the training phase and reducing the gap between in-distribution data and out-of-distribution data in the inference phase. We evaluate our proposed method on several benchmark datasets and show that it outperforms state-of-the-art methods in anomaly detection under distribution shift. 
\item Extensive experiments show that our approach GNL substantially outperforms state-of-the-art AD methods and OOD generalization methods by over 10\% in AUCROC on data with various distribution shifts, while maintaining the detection accuracy on the ID test data.
\end{itemize}
\section{Related Work}
% \guansong{it is too long. need to be more concise. Better to limit the intro and related work sections within two pages.}

\subsection{Anomaly Detection} 
% There are many unsupervised approaches that are proposed for anomaly detection. 

\textbf{One-class Classification.}
% Some very first methods are one-class support vector machine (OC-SVM)\cite{scholkopf2001estimating} and support vector data description (SVDD)\cite{tax2004support}. More recently, Ruff et al. (2018)\cite{ruff2018deep} proposed a method called deep one-class classification (DeepSVDD) that utilizes a deep autoencoder to learn a compressed representation of normal data and uses this representation to identify anomalies. Yan et al. (2021) introduced a novel unsupervised anomaly detection method that learns semantic context from normal samples using a deep convolutional neural network (PatchSVDD)\cite{yi2020patch}.
Some early methods for anomaly detection include one-class support vector machine (OC-SVM) \cite{scholkopf2001estimating} and support vector data description (SVDD) \cite{tax2004support}. More recently, Deep SVDD \cite{ruff2018deep} uses a deep neural network to identify anomalies with a SVDD objective. A number of methods \cite{chen2022deep,goyal2020drocc,wu2019deep,sabokrou2020deep,yi2020patch} is then introduced to learn more effective deep one-class description.
% , while Patch SVDD \cite{yi2020patch} learns patch-wise semantic contexts from normal data using a similar objective.

\textbf{Reconstruction-based Methods.} One popular AD approach is to use autoencoder (AE) \cite{kingma2013auto}. AE-based anomaly detection learns normal patterns from a dataset to reconstruct new samples, assuming that anomalous samples have higher reconstruction errors due to distribution differences. There are many works following this direction and gaining good performance \cite{gong2019memorizing,hou2021divide,park2020learning,yan2021learning,zavrtanik2021reconstruction,pourreza2021g2,zaheer2020old}. 

\textbf{Self-supervised Learning Methods.} The use of data augmentation techniques is becoming increasingly prevalent in AD. One such strategy involves incorporating synthetic anomalies into datasets that are otherwise free of anomalies \cite{li2021cutpaste, yan2021learning, zavrtanik2021reconstruction}. 
% By doing so, the unsupervised task of detecting anomalies is transformed into a supervised learning task, enabling the use of classification algorithms and other machine learning techniques that require labeled data. 

\textbf{Knowledge Distillation.} Another popular line of research is knowledge distillation-based methods. A student-teacher framework with discriminative latent embeddings is introduced in \cite{bergmann2020uninformed}. Many improved versions for AD are then introduced \cite{salehi2021multiresolution,wang2021student,deng2022anomaly}. Anomaly Detection via Reverse Distillation (RD4AD) \cite{deng2022anomaly} is the latest one and gains SOTA performances on many datasets. 

All these methods are focused on AD with the same distribution in training and test data, which fail to work well on data with distribution shift.
% In this paper, we present methods that can enhance the performance of RD4AD on out-of-distribution datasets while maintaining its performance on in-distribution data.
% The teacher network learns to encode normal data into a low-dimensional space, and the student network tries to mimic this behavior. Anomalies are then detected by measuring the difference between the student and teacher embeddings.

\subsection{OOD Generalization} 
% \guansong{please revise this section as suggested in our last meeting}

\textbf{Data Augmentation.} One popular approach for OOD generalization is based on data augmentation. Methods in this line involve generating new data samples from existing ones to increase the size and diversity of the training data. The model can then learn more about the underlying data distribution and become more robust to changes in the test data \cite{otalora2019staining, chen2020improving, zhang2020generalizing, sinha2017certifying, hendrycks2019augmix, zhang2022exact}.

\textbf{Unsupervised Learning.} By solving pretext tasks, a model can develop general features that are not specific to the target task. As a result, the model is less likely to be influenced by biases that are unique to a particular domain, which helps to avoid overfitting and increase generalization ability to different unseen data \cite{carlucci2019domain, ghifary2015domain, wang2020learning, maniyar2020zero, bucci2021self, albuquerque2020improving}.

Although these two types of methods are not designed for AD, they can be easily adapted for AD as they do not require class or domain labels during training. On the other hand, many existing OOD generalization methods, such as domain alignment \cite{muandet2013domain, hu2020domain, jin2020feature, mahajan2021domain, li2020domain, li2018domain, zhao2020domain}, meta-learning \cite{dou2019domain, li2021sequential, du2020learning, du2021metanorm, wang2020meta}, and disentangled representation learning \cite{li2017deeper, khosla2012undoing, chattopadhyay2020learning, piratla2020efficient, ilse2020diva, wang2020cross}, require class/domain-related supervision, which are inapplicable for the AD task. A similar issue exists for OOD generalization methods designed for multi-class problems \cite{du2020learning, huang2020self}. There are some cross-domain AD methods \cite{lu2020few, lv2021learning,ding2022catching}, but they require class labels in the ID data or few training samples from the target domain. By contrast, we focus on unsupervised AD and do not require any OOD data available during training. They focus on video data while we focus on image data.
% that usually only involve one or multiple domains without domain labels, which makes it difficult to apply some. 
% Additionally, some out-of-distribution (OOD) generalization methods that are designed for multi-class problems cannot also be applied to AD, which only exists one class during training \cite{du2020learning, huang2020self}. Therefore, there is a need for specific methods that can handle the challenges of AD under OOD settings.

% Nhìn chung, các phương pháp thuộc về Data Augmentation and Unsupervised Learning-based method can be directly applied to to anomaly detection khi mà nó không cần cả class label và domain label trong quá trình training. Besides that, there are some typical directions for multi-source setting including domain alignment \cite{muandet2013domain, hu2020domain, jin2020feature, mahajan2021domain, li2020domain, li2018domain, zhao2020domain}, meta-learning \cite{dou2019domain, li2021sequential, du2020learning, du2021metanorm, wang2020meta}, learning disentangled representations \cite{li2017deeper, khosla2012undoing, chattopadhyay2020learning, piratla2020efficient, ilse2020diva, wang2020cross} and so on. However, these methods can not be directly applied to anomaly detection because the settings of anomaly detection usually only have one domain or multi-domain without domain label. Một số phương pháp OOD generalization không cần domain label nhưng cần class label cho việc giúp model tổng quát hơn cũng không thể apply vào anomaly detection

% DG has typically been studied under two different settings\cite{zhou2022domain}, namely multi-source DG and single source DG.

% \textbf{Multi-source domain}  The majority of research has been dedicated
% to the multi-source setting, which assumes multiple distinct but relevant domains are available. Some typical directions for multi-source setting include domain alignment \cite{muandet2013domain, hu2020domain, jin2020feature, mahajan2021domain, li2020domain, li2018domain, zhao2020domain}, meta-learning \cite{dou2019domain, li2021sequential, du2020learning, du2021metanorm, wang2020meta}, learning disentangled representations \cite{li2017deeper, khosla2012undoing, chattopadhyay2020learning, piratla2020efficient, ilse2020diva, wang2020cross} and so on. However, these methods can not be directly applied to anomaly detection because the settings of anomaly detection usually only have one domain or multi-domain without domain label. 

% \textbf{Single-souce domain} The single-source scenario assumes that the training data is uniform. Data Augmentation is a common method that involves generating new data samples from existing ones to increase the size of the training dataset. By applying transformations to the original data, the model can learn more about the underlying data distribution and become more robust to changes in the test data \cite{otalora2019staining, chen2020improving, zhang2020generalizing, sinha2017certifying, hendrycks2019augmix, zhang2022exact}. An additional strategy to address the single domain shift issue is unsupervised learning, which involves training a model on unlabeled data without using explicit supervision from labeled data. \cite{carlucci2019domain, ghifary2015domain, wang2020learning, maniyar2020zero, bucci2021self, albuquerque2020improving}. However, not any of the methods in single DG can be applied to the problem of anomaly detection, as some methods are designed specifically for classification, segmentation, or require class labels of data that are unsupervised anomaly detection not available \cite{huang2020self, qiao2020learning}. 

% \guansong{add discussion here about the differences to the following cross-domain AD studies.

% Yiwei Lu, Frank Yu, Mahesh Kumar Krishna Reddy, and Yang Wang. Few-shot scene-adaptive anomaly detection. In European Conference on Computer Vision, pages 125±141. Springer, 2020.

% Hui Lv, Chen Chen, Zhen Cui, Chunyan Xu, Yong Li, and Jian Yang. Learning normal dynamics in videos with meta prototype network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 15425±15434, 2021.
% }
% We investigates the efficacy of combining appropriate Domain Generalization (DG) methods with the state-of-the-art (SOTA) model in anomaly detection. Our analysis indicates that merely applying these methods in a straightforward manner does not enhance the performance of AD model.
% Our study is close to some previous studies that focus on identifying abnormal events in videos. In these studies, the setting is that the videos used for training and testing are not from the same scene, which can affect the accuracy of the model. In contrast to the studies that worked on videos, our study focused on detect anomalous sample on a image. This means that we did not consider the information that exists between frames in videos. While videos provide temporal information that can be used to detect abnormal events, our study focused on using only the information in each individual image to make predictions.

% There are some previous studies closed with our work \cite{lu2020few, lv2021learning}. These works focus on identifying abnormal events in videos, where the training and testing videos are from different scenes. Meanwhile, our study aim to detect anomalous samples in images. Unlike video-based studies, we base solely on information in individual images to make predictions, without considering the temporal information between frames.

\section{Problem Formulation and Challenges}


\subsection{Problem Formulation}
Let $\mathcal{X}_s$ and $\mathcal{X}_t$ denote the source (ID) and target (OOD) distributions, respectively, where $\mathcal{X}_s$ is used for both training and testing phase,  while $\mathcal{X}_t$ is only used for inference period. We assume that during training, only normal data from $\mathcal{X}_s$ is available, \ie, $\mathcal{D}_s = \{{x \in \mathcal{X}_s \mid y = 0}\}$, where $y \in \{0,1\}$ is the binary label indicating whether $x$ is a normal ($y=0$) or abnormal ($y=1$) sample. During testing, data can be normal or abnormal, and can be from either the source or target distribution, \ie, $\mathcal{D}_t = \{{ x \in \mathcal{X}_s \cup \mathcal{X}_t}\ \mid y = \{0,1\}\}$. The goal is then to develop an unsupervised anomaly detection model that can effectively handle distribution shift and accurately detect anomalies in $\mathcal{D}_t$. Specifically, we aim to learn a function $f:\mathcal{X}\rightarrow \mathbb{R}$ that assigns an anomaly score to each sample $x$ in a way such that $\forall x_i, x_j \in \mathcal{D}_t, \ f(x_i) < f(x_j) $ when $y_i=0$ and $y_j=1$.

% Fig.\ref{fig:intro} shows some illustrative samples during training and testing according to our settings.

% $\forall x \in X_{normal}, \exists f : X \to \mathbb{R} \ \text{s.t.} \ \operatorname{anomaly}(x) < \operatorname{anomaly}(x') \ \forall x' \in X_{abnormal}$

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=0.45\textwidth]{settings.png}
%     \caption{Some illustrative samples during training and testing according to our settings.}
%     \label{fig:settings}
% \end{figure}




\subsection{The Challenges} 
The current approaches in AD involve explicit fitting of the normal training data \cite{deng2022anomaly, salehi2021multiresolution, akcay2019ganomaly, schlegl2019f}. It can cause the model to learn irrelevant features that are not associated with the appearance of normal data, \eg, the model may mistake domain-specific background information as normal features, resulting in inaccurate anomaly detection when there are distribution shits presented.
% Fig. \ref{fig:challenge} illustrates this issue, with models like RD4AD and RD4AD+Mixstyle struggling to identify normal samples in the shift distribution and misclassifying them as anomalous, and vice versa. The broad range of anomaly scores indicates that these models have learned features that are not representative of normal data. Background or style features unique to a particular domain can change when moving to another domain, causing the model to mistake them as anomalies, leading to normal samples in the shifted domain being classified as anomalous with high anomaly scores. Furthermore, some abnormal samples in the target domain may possess similar features to background or style features in the source domain, leading to them being misclassified with low anomaly scores.
OOD generalization models are also significantly challenged by the studied setting.
% , as they often require multi-class or multi-source of data during training whereas 
This is mainly because the training data in the AD task consists of only one class and the data is monotonous, making it difficult to learn and identify patterns that distinguish normal and anomalous instances. Current OOD generalization approaches used in classification, detection, and segmentation need to take into account class labels, domain labels, or the diversity of samples in the training data \cite{du2020learning, huang2020self,wang2020cross, wang2020meta}, which often are not applicable to AD tasks. As a result, new methods are required that can effectively address the problem of AD under distribution shift.

Fig. \ref{fig:challenge} illustrates this issue, where models such as RD4AD \cite{deng2022anomaly} (a recent SOTA AD model) and Mixstyle \cite{zhoudomain} (a SOTA OOD generalization method) are seen to struggle with identifying normal samples in the presence of distribution shift, often misclassifying them as anomalous. The overlapping of histograms of the anomaly scores for the normal and abnormal samples indicates that these models have learned features that are not representative of normal data, which can be a major obstacle in detecting anomalies. One of the main reasons is that the background or style features w.r.t. a specific dataset can change due to different natural conditions. As a result, the model may mistake these changed features as anomalies, leading to normal samples in the shifted distribution being classified as anomalous with high anomaly scores. Furthermore, some abnormal samples in the OOD data may possess similar features to background or style features in the training data, leading to them being misclassified with low anomaly scores.

% The problem of AD under distribution shift becomes even more challenging when the training data only contains a single class and comes from a single domain. This issue arises due to the homogeneity or monotony of the data, which can make it difficult to learn and identify patterns that distinguish normal and anomalous instances. In such cases, traditional OOD generalization approaches used in classification, detection, and segmentation need to take into account class labels, domain labels, or the diversity of samples in the training data \cite{du2020learning, huang2020self,wang2020cross, wang2020meta}, which often are not applicable to AD tasks. As a result, new methods are required that can effectively address the problem of AD under distribution shift.
% in single-class, single-domain scenarios.

% This is because such approaches assume the presence of multiple classes and domains, which may not be the case in single-class AD tasks.

% To overcome these challenges, our proposed model learns domain-invariant normal features that are independent of any specific domain. This approach enables the model to accurately identify anomalies in new distributions, even if the distribution has shifted from the original training data. As shown in Fig. \ref{fig:challenge}, the anomaly score range of our model is greatly narrowed for both normal and abnormal samples, indicating that it has effectively learned domain-invariant features.
\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{ChallengeHouse2.pdf}
    \caption{Anomaly scores of RD4AD \cite{deng2022anomaly}, Mixstyle \cite{zhoudomain} and our model GNL on PACS \cite{li2017deeper} when selecting `house' as the normal class and the remaining classes as anomaly classes.}
    \label{fig:challenge}
\end{figure}

\section{Our Approach}
% \guansong{please don't just describe the method in high-level texts; use formal symbols and equations to rigorously and precisely describe the method in both subsections.} \guansong{both subsections need to be significantly extended.}
\begin{figure*}[h]
    \centering
    \includegraphics[width=\textwidth]{proposedFramework.pdf}
    \caption{Overview of our approach. (a) Distribution-invariant normality learning in the training phase. (b) Test time augmentation with feature distribution matching in the inference phase.}
    \label{fig:proposedframework}
\end{figure*}


To address these challenges, we introduce a novel approach, namely generalized normality learning (GNL). GNL minimizes the distribution gap between ID and OOD normal samples in both the training and inference stages in an unsupervised way. To this end, we introduce a normality-preserved loss function to learn distribution-invariant normality representations, which enables GNL to learn generalized semantics of the normal training data at different feature levels. GNL further utilizes an AD-oriented test time data augmentation method based on feature distribution matching to improve the generalization performance. Fig.\ref{fig:proposedframework} describes the two main components of our approach: (a) distribution-invariant normality learning for training, and (b) test time augmentation methods. 
% The training process involves using a distribution-invariant normality learning process to learn distribution-invariant normality features that help the model to be more generalized. The testing process involves taking advantage of Feature Distribution Matching to reduce the gap between the source distribution and the target distribution. It is worth noting
The two components complement to each other, meaning that the distribution-invariant normality learning process used during training can support the test time augmentation methods used during testing, and vice versa. 

% This is the combination of enlarging training distribution and reducing test distribution.
\subsection{Distribution-invariant Normality Learning}
% \guansong{start with our intuition of the module; what specifically does this module do, and why it should work. the same principle is applied to the other section.}
% \textbf{Reverse Knowledge Distillation for Anomaly Detection}

% \textbf{Proposed Method}
In order to improve the performance of model on OOD datasets while maintaining good performance on ID datasets, our objective is to train a student model to be more robust to changes in the distribution of data, while still ensuring that the student overfits on the normal features. 
Fig.\ref{fig:proposedframework} (a) illustrates the training framework. 

% Về cơ bản, chúng tôi muốn the student có thể tổng quát hơn với sự thay đổi của data distribution, đồng thời the student vẫn overfit với các normal feature. Chỉ có như vậy thì performance của model mới được cải thiện trên OOD datasets mà vẫn giữ được performance tốt trên ID datasets

Our method is built on top of the RD4AD model introduced by Deng et al. \cite{deng2022anomaly} that achieves state-of-the-art results on various datasets. The RD4AD framework includes three components: a fixed teacher encoder, a trainable one-class bottleneck embedding module, and a student decoder. When given an input sample, the teacher encoder extracts multi-scale representations, and the student decoder is trained to reconstruct the features from the bottleneck embedding. During testing, the teacher encoder can identify abnormal and OOD features in anomalous samples, but the student decoder fails to reconstruct these features. The model then considers anomalous representations that have low similarity as highly abnormal.

We propose to incorporate a similarity loss that quantifies the difference between the embedding features of the original samples and those of each transformed normal sample that represents a distinct style from the original data. Specifically, we enforce this loss at both the bottleneck layer and the final block of the decoder. To provide further clarity, we propose the inclusion of a loss term, denoted as $\mathcal {L}_{abs} $, which is integrated at the bottleneck layer of the encoder. Moreover, we also introduce another loss term, termed as $\mathcal {L}_{lowf}$, that is added at the final block of the encoder architecture. Particularly, given a sample $x \in \mathcal{D}_s$, we
first apply an augmentation function $\mathcal{T(.)}$ on it, and let $x'_k =  \mathcal{T}(x_k)$ where $k \in [1,N]$ with $N$ is the number of augmented normal samples generated by data augmentation,
% . $N$ generated samples, along with the original sample are fed into RD4AD. Denote by 
and $\phi$ be the mapping that projects the raw image $I$ into the embedding space at the bottleneck layer, then we define $\mathcal {L}_{abs} $ as:
\begin{equation}
 \mathcal{L_{\text{abs}}} = \sum _{k=1}^{N}\frac {1}{N} \bigg \{ \mathcal {L}_{sim}(\phi(x),\phi(x'_k))\bigg \} 
 \label {eq:lossabtract}, 
\end{equation}
where $\mathcal {L}_{sim}(.,.)$ is a cosine similarity-based loss function. 

Let $\omega$ be a reconstruction function from the abstract features to the low-level features at the final block of the decoder, then we further define $\mathcal {L}_{lowf} $ as:
\begin{equation}
 \mathcal {L}_{lowf}  = \sum _{k=1}^{N}\frac {1}{N} \bigg \{ \mathcal {L}_{sim}(\omega(\phi(x)),\omega(\phi(x'_k)))\bigg \}. 
 \label{eq:losslowfeature}
\end{equation}

We combine these loss functions to introduce the distribution-invariant, normality-preserved loss function:
\begin{equation}
 \mathcal {L} = \lambda _{Ori}*\mathcal {L}_{Ori} + \lambda _{abs} * \mathcal {L}_{abs} + \lambda _{lowf} * \mathcal {L}_{lowf} 
  \label{eq:sumloss}, 
\end{equation}
where ${L}_{Ori}$ is the original loss of RD4AD, and $\lambda _{Ori}$, $\lambda _{abs}$, and $\lambda _{lowf}$ are hyperparameters that determine how much weight should be given to each type of loss function.
% and $\mathcal {L}_{Ori}$ is the loss in the original RD4AD framework. 

We adopt AugMix \cite{hendrycks2019augmix} as the data augmentation method. Still, we remove the augmentation components that have the potential to generate anomalies, \eg, `shear\_x', `shear\_y', `translate\_x', and `translate\_y', to ensure that all generated data are normal samples.

Intuitively, the last block of decoder is responsible for reconstructing simple and low-level features, such as edges, corners, and blobs, while the bottleneck layer is responsible for extracting more complex and high-level features. At the bottleneck layer, the abstracted information of the same images from different synthesized methods must be the same, while retaining enough information for reconstruction in the decoder. Therefore, by minimizing the loss function in Eq. \ref{eq:sumloss}, GNL learns features from both low-layer CNNs and high-level CNNs respectively to be the same from different distributions generated from a single sample. 

\subsection{Test Time Augmentation for Anomaly Detection under Distribution Shift}
% \textbf{Feature Distribution Matching (FDM)}
% Arbitrary Style Transfer is a technique in computer vision that involves transferring the style of an image to another image while preserving its content. In other words, it allows the style of one image to be applied to another image while still retaining the original content of the target image. 
% Huang et al.(2017) introduced a technique called adaptive instance normalization (AdaIN)\cite{huang2017arbitrary}:
% \begin{equation}
% \text{AdaIN}(x, y) = \sigma(y) \left(\frac{x - \mu(x)}{\sigma(x)}\right) + \mu(y)
% \end{equation}

% In this formula, $x$ represents the input feature map, $y$ represents the style features, $\mu$ represents the mean operator, and $\sigma$ represents the standard deviation operator. The AdaIN function computes the normalization of $x$ using the mean and standard deviation of $x$, and scales it using the mean and standard deviation of $y$. Finally, it shifts the result by the mean of $y$. 
% Essentially, by using the feature statistics of the style input, AdaIN can apply the style of one image to another while preserving the content information of the original image. AdaIN can get exact feature distribution matching by assuming that features follow Gaussian distribution. However, feature distributions of empirical data usually deviate much from Gaussian, so Zhang et al.(2022) propose the Exact Feature Distribution Matching (EFDM) \cite{zhang2022exact} that can be adapted well with real-world data. In fact, AdaIN and EFDM have been used for Domain Generalization, specifically Mixstyle, and EDFMix, respectively. AdaIN and EFDM are used during training with the goal of creating new distribution samples by mixing the styles of the samples available in the training set, thereby making the model more generalized. In contrast, we propose using these Feature distribution matching techniques in the inference phase to reduce the gap between the source and target domains.

% % \textbf{Proposed Method}
% Given a sample input X in the test set, we randomly select a sample Y in the training set. Sample Y has the role of carrying information about the color and style of the source domain. The random selection of sample Y is due to the monotony of the source domain during training, since any sample in the training set can also carry color and style information representing the whole source domain. Then, sample X and Y are both fed into the same Encoder, the feature distribution of Y will be injected into X in the CNN layers as described in Fig. \ref{fig:proposedframework} (b). By this way, FDM makes the distribution of samples in target domain closer to the style of samples in source domain but still retain the feature of the image. Intuitively, when applying the FDM method to a sample from the source domain, the resulting distribution should not deviate significantly from its distribution. Because then, the distribution of the input sample is matched with its own distribution, so FDM does not affect the performance of model on the source domain too much. In other words, FDM can enable the model to adapt to the target domain without sacrificing its ability to perform well on the source domain.

% To be more flexible and inspired by Mixstyle and EDFMix. We adopt the $\alpha$ as the severity for mixing the style between the sample in the source and target domains. Details of adopting the $\alpha$ into AdaIN and EFDM are done in the same way as in Mixstyle and EFDMix and are described in Appendix.

The goal of this component is to address the problem of a mismatch between the distribution of data during testin. To accomplish this, we propose injecting training distribution into the inference samples by using Feature Distribution Matching (FDM) at multi-level layers of the teacher encoder in the inference phase. The proposed testing framework is demonstrated in Figure \ref{fig:proposedframework} (b). Note that our Test Time Augmentation only takes place in the first two residual blocks in Techer Encoder. The inference process from the third residual block onwards and the anomaly score calculation are entirely followed with the original RD4AD framework.

Some previous studies focused on FDM assume that the input features follow a Gaussian distribution \cite{huang2017arbitrary, lu2019closed, mroueh2020wasserstein} . More recently, Zhang et al. \cite{zhang2022exact} have discovered more accurate methods, known as Exact Feature Distribution Matching (EFDM). All these FDM techniques are applicable to our proposed framework. Noted that, FDM have been used for OOD Generalization, \eg, in Mixstyle \cite{zhoudomain} and EDFMix \cite{zhang2022exact}, but they are used during training with the goal of creating new distribution samples by mixing the styles of the samples available in the training set, while we adopt FDM as a component in the inference stage with a different objective.

Specifically, given a test sample $p \in \mathcal{D}_t$, we randomly select a training normal sample $ q \in \mathcal{D}_s$. These two samples are then fed into the teacher encoder. Let $\mathcal P^m$ and $\mathcal Q^m$ be the embedded features of $p$ and $q$ at the residual encoding block $E^m$, respectively, then the testing process is performed as follows:
% following the equation \ref{equa:test}, which is defined as:
%{x}_{norm}
% Let ${\chi}^{m}_{main}$ and  ${\chi}^{m}_{norm}$ is the embedded feature that are fed into the next layer ${E}^{m+1}_{main}$ and ${E}^{m+1}_{norm}$, defined as: 
% \begin{equation}
% {\chi}^{m}_{main} = FDM(E^{m}_{main}, E^{m}_{norm},\alpha)
%   \label {eq:sumloss}, 
% \end{equation}
% \begin{equation}
% {\chi}^{m}_{main} = FDM(E^{m}_{main}, E^{m}_{norm},\alpha)
%   \label {eq:sumloss}, 
% \end{equation}
% % $ {\chi}^{m} = FDM(E^{m}(x), E^{m}({x}_{norm}),\alpha) $ 
% \begin{equation}
% \begin{cases}
% {\chi}^{m}{main} = FDM(\mathcal E^{m}{main}, \mathcal E^{m}{norm},\alpha) \\
% {\chi}^{m}{norm} = \mathcal E^{m}{norm}
% \end{cases}
% \end{equation}
\begin{equation}
\begin{cases}
\mathcal P^{m+1} = \text{FDM}(E^{m+1}(\mathcal P^{m}), \mathcal Q^{m+1},\alpha) \\
\mathcal Q^{m+1} = {E}^{m+1}(\mathcal Q^{m})\\
\mathcal P^{0} = x, \mathcal Q^{0} = q,\\

% \mathcal O^{1} = FDM({E}^{1}(x), \mathcal P^{1},\alpha)\\
% \mathcal P^{1} = {E}^{1}(q)
\end{cases}
\label{equa:test}
\end{equation}
where $ m \in \{1,2\}$, and $\alpha$ is a hyperparameter balancing the severity for mixing the style between the inference sample and the selected normal sample. The processed embedded features $\mathcal P^{1}, \mathcal P^{2}$, and the original embedded features $\mathcal P^{3}$ are then input into the bottleneck layer and participate in the calculation of anomaly scores following the inference process of the original RD4AD.

In essence, the sample $q$ plays a role in conveying distribution information pertaining to the training data. The selection of a random sample is due to the monotonous nature of the data during training, as any sample in the training set is capable of carrying distribution information that represents the training data. Consequently, devising a process for sample selection during training is computationally expensive and inefficient.

By utilizing FDM, our proposed testing process minimizes the disparity between the feature distribution of the inference sample and the feature distribution of normal samples in the training data, in cases where inference samples come from OOD sets. Furthermore, FDM ensures that the feature distribution remains nearly unchanged if inference samples come from ID sets, since the distribution of the test sample is aligned with its own distribution. Therefore, our testing approach can improve performance on OOD data without sacrificing performance on ID data.

%${m}^{th}$
\section{Experiments}
% \subsection{Experimental Settings}
\subsection{Datasets}
We adapt three datasets from both AD and OOD generalization as the dataset benchmarks for the studied task.

\textbf{Anomaly Detection.}
\textbf{MVTec} \cite{bergmann2019mvtec} is a widely-used AD benchmark, which comprises 15 data subsets for industrial defect inspection,
% distinct collections of authentic data aimed at detecting anomalies. These datasets encompass
including 5 subsets on texture anomalies and 10 subsets on object anomalies. The training dataset consists of 3,629 images in total, all of which are normal images. In contrast, the test dataset contains a total of 1,725 images, comprising both defective and non-defective instances. In order to generate OOD datasets for MVTec, we apply 4 types of visual corruptions to MVTec \cite{bergmann2019mvtec}: Brightness, Contrast, Defocus Blur, and Gaussian noise. The severity for each type of corruption is set to 3 for all the out-of-distribution data. 

\textbf{OOD Generalization.} 
% We conduct a one-class novelty detection experiment on two semantic datasets:
Two popular OOD benchmarks, \textbf{MNIST-M} \cite{ganin2015unsupervised} and \textbf{PACS} \cite{li2017deeper}, are taken in our experiments.
% \textbf{Handwritten Digit Recognition.}  We use 
In particular, the primary MNIST \cite{lecun1998gradient} is used as the ID data on which the models are trained on, while MNIST-M is used as the OOD set. MNIST and MNIST-M datasets share 10 classes, which correspond to the digits 0 through 9. While MNIST encompasses 70,000 grayscale images of handwritten digits, MNIST-M contains 68,000 OOD images that are synthesized by superimposing random colored patches on the original images from MNIST. PACS is another widely used OOD dataset consisting of 9,991 images, which are shared by seven classes and four domains, namely Art, Cartoon, Photo, and Sketch. We select the images in Photo as the ID data, with the images in Art, Cartoon, and Sketch as the OOD data. 
% We use 8,977 images for training and 1014 images for testing.
The commonly used one-versus-all protocol \cite{perera2019ocgan} is used to convert the these two datasets into AD datasets with distribution shift, in which samples of one class are used as normal, with the rest of classes as anomaly classes. 
% We train models with samples from a single class and then test them on novel samples. If a sample does not belong to the class that the model is trained on, it is considered an anomaly, and vice versa. 
During training, we only use images in the ID dataset, \ie, assuming the OOD data is not available during training. During inference, test sets of both ID and OOD are used.

\subsection{\textbf{Baselines}}
% \textbf{Anomaly Detection Methods.}
We conduct a series of experimental evaluations on 4 prominent anomaly detection methods, namely Deep SVDD \cite{ruff2018deep}, f-AnoGAN \cite{schlegl2019f}, KDAD \cite{salehi2021multiresolution}, and RD4AD \cite{deng2022anomaly}. These methods stand for popular AD methods and recent state-of-the-art (SOTA) AD models.
% come from a wide range of algorithmic approaches and diverse features.
% \textbf{OOD Generalization Methods.}
To evaluate the efficacy of OOD generalization techniques in anomaly detection, we adapt a suite of cutting-edge OOD methods by combining them with the recently proposed RD4AD model, which boosts SOTA performance on multiple datasets. Four different methods are used, including three data augmentation-based methods Augmix \cite{hendrycks2019augmix}, Mixstyle \cite{zhoudomain}, and EFDM \cite{zhang2022exact}, and one self-supervised method Jigsaw \cite{carlucci2019domain}. 
% Each of these methods has demonstrated considerable promise in the domain generalization literature and represents a diverse array of strategies for improving the performance of anomaly detection models.  

\subsection{Implementation Details}
% \textbf{Our Model GNL.} In essence,
Our proposed method GNL is implemented on top of the RD4AD framework. Therefore, we maintain the settings recommended by RD4AD, such as the number of training epochs, optimization method, the way of calculating anomaly score, and other relevant parameters. The details can be found in Appendix. Regarding the specific parameters for our model GNL, we choose $N=2$ for the number of augmented normal samples generated by data augmentation, $\alpha=0.5$ for the severity for mixing the style, and EFDM \cite{zhang2022exact} as the FDM technique since it is the latest and shows SOTA performance.
% Specifically, with MVTec, all images in MVTec are resized to 256x256. We take ResNet50\cite{he2016deep} as the backbone of the teacher encoder. We utilize Adam optimizer \cite{kingma2014adam} with $\beta=(0.5,0.999)$. The learning rate is set to 0.005. We train 200 epochs with a batch size of 16. The hyperparameters of image size, optimizer, learning rate, number of epochs, batch size for PACS are the same as for MVTec. For Handwritten Digit Recognition, all images are in their original scale, which are 28 × 28. We take ResNet18\cite{he2016deep} as the backbone of the teacher encoder. We train 200 epochs with a batch size of 16. The model is optimized by Adam \cite{kingma2014adam} optimizer with learning rate of 0.001. We choose the number of augmented images for each sample to be 2. 
% We also report the change in performance when the number of images generated for each sample changes in the ablation study.

For the AD baselines, we use the official implementation published by the authors of those baselines. 
% \textbf{AD Baselines.} We have run all the baseline experiments according to the implementation published by the authors of those baselines. 
However, since the original baselines did not include experiments on the PACS dataset, we use the hyperparameters from MVTec experiments to conduct experiments on the PACS dataset corresponding to each baseline. 

For the OOD generalization baselines, we use Augmix with an online augmentation severity of 3 for MNIST and PACS datasets. We use all the data augmentation types included in Augmix for MNIST and PACS. However, for the MVTec dataset, we exclude two types of augmentation that overlap with two types of corruptions during testing: Brightness and Contrast. With Mixstyle and EFDM, which are two data augmentation methods at the feature level (rather than at the image level like Augmix), we apply Mixstyle and EFDM to the encoders in the first two network layer according to the settings in RD4AD. As for Jigsaw, we fit the Jigsaw task into the Bottleneck component in RD4AD. All hyperparameters of training are preserved when applying OOD generalization baselines into RD4AD.

Following previous studies \cite{ruff2018deep, schlegl2019f, salehi2021multiresolution, deng2022anomaly,ding2022catching}, we evaluate the performance of our anomaly detection methods using a metric called the Area Under the ROC Curve (AUROC). This metric is commonly used to assess how well a given method is able to distinguish between normal and anomalous data points. The results are averaged over three independent runs.
% by running training testing three times and computing the average values.

\subsection{Comparison Results}


% \subsubsection{Results on MVTec AD}

% \textbf{Performance of AD Models.}

% \textbf{Performance of Adapted OOD Models.}

% \textbf{Performance of Our Models.}

The performance of our model GNL and the baselines on MVTec, MNIST, and PACS are shown in Tables \ref{tab:mvtec}, \ref{tab:mnist}, and \ref{tab:pacs}, respectively. Note that due to space limitations, the performances in all three tables are the average results of the classes per dataset. Detailed results are presented in Appendix. Overall, GNL can significantly outperforms SOTA AD models and OOD generalization methods in detecting anomalies on the OOD test data, while at the same time maintaining the detection accuracy on the ID data. Below we discuss the results in detail.

\subsubsection{Performance of AD Methods}
In general, we observe a significant drop in the AUC scores of all AD methods, Deep SVDD, f-AnoGAN, KDAD and RD4AD, on the OOD data across all three datasets used. This indicates that their performance is severely affected by the distribution shift. In particular, the performance of all AD models is promising on the MNIST set. However, this performance is reduced by about 30-40\% when the models are tested on the MNIST-M set, which contains variations that are not present in the original MNIST set. Similar trends are observed in the PACS dataset, where the models' performance is also significantly affected by the distribution shifts in the OOD data. The models perform well on the Photo data, which is the ID data, but their performance drops significantly on the three OOD datasets, Art, Cartoon and Sketch. On the MVTec dataset, the performance still drops but is less severe than on the other two sets.


\begin{table}[h]
\centering
\scalebox{0.8}{
\begin{tabular}{l|c|c|c|c|c}
\hline
& \multicolumn{1}{c}{ID} & \multicolumn{4}{|c}{OOD} \\
\cline{2-5}
\hline
Method & MVTec & Brightness & Contrast & Blur & Noise \\
\hline
Deep SVDD & 69.98 & 55.18 & 50.07 & 68.82 & 59.11 \\
f-AnoGAN & 75.65 & 48.36 & 49.29 & 37.98 & 39.10\\
KDAD & 85.50 & 83.81 & 64.03 & 84.17 & 82.04 \\
% KDAD\_TMixstyle & 0.8540 & 0.8522 & 0.7107 & 0.8421 & 0.8097 \\
% KDAD\_TEFDM & 0.8441 & 0.8523 & 0.8197 & 0.8343 & 0.8157 \\
RD4AD & \textbf{98.64} & 96.50 & 94.12 & \textbf{98.9} & 90.14 \\
\hline
Augmix & 96.29 & 95.10 & 94.51 & 95.39 & 90.99 \\
Mixstyle & 98.58 & 96.60 & 94.45 & 98.27 & 88.92 \\
EFDM & 98.64 & 96.78 & 94.77 & 98.25 & 89.29 \\
Augmix+Mixstyle & 96.78 & 96.86 & 94.57 & 98.73 & 90.12 \\
Augmix+EFDM & 97.04 & 96.83 & 95.21 & 98.11 & 90.18  \\
Jigsaw & 73.97 & 73.36 & 67.88 & 73.88 & 72.60 \\

% RD4AD\_TMixstyle & 0.9853 & 0.9736 & 0.9687 & 0.9823 & 0.9278 \\
% RD4AD\_TEFDM & 0.9852 & 0.9732 & 0.9720 & 0.9821 & 0.9292 \\
% RD4AD_newv1 & 0.9783 & 0.9646 & 0.9610 & 0.9732 & 0.9205 \\
% RD4AD_newv1+TMixstyle & 0.9797 & 0.9744 & 0.9739 & 0.9776 & 0.9421 \\
\hline
GNL (Ours) & 97.99 & \textbf{97.43} & \textbf{97.46} & 97.77 & \textbf{94.10} \\
\hline
\end{tabular}
}


\caption{AUROC (\%) results on MVTec and its four corruptions. The best performance is \textbf{boldfaced}.}
% Methods achieved for the first AUROC (\%) are highlighted in bold.}
\label{tab:mvtec}
\end{table}


\begin{table}[h]
\centering
\scalebox{0.9}{
\begin{tabular}{c|c|c}
\hline
Method  & MNIST (ID) & MNIST-M (OOD)\\
\hline
Deep SVDD & 97.73 & 49.92 \\
f-AnoGAN & 97.52 & 52.72 \\
KDAD & 98.87 & 54.87 \\
% KDAD_TMixstyle & 0.9870 & 0.5478 \\
% KDAD_TEFDM & 0.9790 & 0.5723 \\
RD4AD & \textbf{98.89} & 58.09 \\
\hline
Augmix & 98.26 & 59.61 \\
Mixstyle & 98.84 & 57.22 \\
EFDM & 98.62 & 57.23 \\
Augmix+Mixstyle & 98.12 & 58.89   \\
Augmix+EFDM & 98.24 & 58.91 \\
Jigsaw & 98.90 & 58.51 \\
% RD4AD_TMixstyle & 0.9784 & 0.6452 \\
% RD4AD_TEFDM & 0.9755 & 0.6484 \\
% RD4AD_newv1 & 0.9765 & 0.6266 \\
% RD4AD_newv1+TMixstyle & 0.9699 & 0.7103 \\
\hline
GNL (Ours) & 96.91 & \textbf{70.87} \\
\hline
\end{tabular}
}
\caption{AUROC results (\%)  on in-distribution (MNIST) and out-of-distribution (MNIST\-M) datasets.}
% as measured by the Area Under the Receiver Operating Characteristic (AUROC)}
\label{tab:mnist}
\end{table}
% 

\begin{table}[h]
\centering
\scalebox{0.9}{
\begin{tabular}{l|c|c|c|c}
\hline
& \multicolumn{1}{c}{ID} & \multicolumn{3}{|c}{OOD}  \\
\cline{2-5}
\hline
Method & Photo & Art & Cartoon & Sketch  \\ \hline
Deep SVDD   & 40.87&	53.42 &	41.23 & 	39.48 \\
f-AnoGAN &  61.34 &  50.15 &  52.42 &  63.77   \\
KDAD &  \textbf{88.17} &  62.86 &  62.64 &  51.40 \\
% KDAD_TMixstyle &  898.2 &  65.94 &  69.14 &  59.28 \\
% KDAD_TEFDM &  89.29 &  65.06 &  67.72 &  60.06 \\
RD4AD &  81.49 &  61.07 &  60.34 &  55.06  \\
\hline
Augmix &  76.35 &  60.50 &  58.96 &  57.86  \\
Mixstyle &  78.23 &  60.93 &  60.93 &  54.89 \\
EFDM &  78.47 &  60.55 &  62.15 &  55.63  \\
Augmix+Mixstyle & 76.12 & 60.16 &  61.29 & 55.76\\
Augmix+EFDM & 77.28 & 60.93 &  63.18 & 56.67\\
Jigsaw &  62.19 &  52.55 &  53.83 &  62.15  \\
% RD4AD_TMixstyle &  80.26 &  63.74 &  60.76 &  56.13 \\
% RD4AD_TEFDM &  81.05 &  64.36 &  62.04 &  57.04 \\
% RD4AD_newv1 &  85.71 &  62.34 &  65.63 &  57.12 \\
% RD4AD_newv1+TMixstyle &  85.84 &  64.45 &  65.28 &  60.57 \\
\hline
GNL (Ours) &  87.67 &  \textbf{65.62} &  \textbf{67.96} &  \textbf{62.39}  \\ \hline
\end{tabular}
}
\caption{AUROC results (\%) on in-distribution (Photo) and out-of-distribution (Art, Cartoon, Sketch) datasets.}
% , as measured by the Area Under the Receiver Operating Characteristic (AUROC).}
\label{tab:pacs}
\end{table}

% This could be because the dataset contains images of the same object taken from different angles and under different lighting conditions, which is more similar to the in-distribution data that the models were trained on.\\

\subsubsection{Performance of Combined OOD Generalization and AD Methods}
Our results in Tables \ref{tab:mvtec}, \ref{tab:mnist}, and \ref{tab:pacs} indicate that the detection performance cannot be significantly improved by combining different OOD generalization techniques with the recent SOTA AD model RD4AD on the three datasets. This lack of improvement can be attributed to the fact that these OOD methods attempt to increase the diversity of data by enriching the available data based on its own distribution. However, because the training data in AD is typically monotonous and unimodal, these OOD methods often fail to generate data samples that significantly deviate from the original data distribution. As a result, the added diversity of generated data is not sufficient to significantly improve the performance of AD models.

Moreover, these OOD techniques also have a tendency to generate undesired anomaly data, which is akin to injecting noise into the training data, thereby reducing the performance of AD models on the in-distribution dataset.

\subsubsection{Performance of Our Method GNL}

% Experimental results of anomaly detection on MVTec set are shown in table \ref{tab:mvtec}. 
On the MVTec AD dataset in Table \ref{tab:mvtec}, our method shows remarkable improvement in performance on the OOD dataset, while maintaining the performance on the ID data. In fact, our method achieves a highly comparable AUROC score of 0.9799 on the original MVTec ID data, while also obtaining an impressive AUROC score of 0.9743 on the Brightness, 0.9746 on Contrast, 0.9776 on the Defocus\_blur dataset, and 0.9410 on Gaussian Noise, which are significant improvements over the other methods. These results demonstrate the robustness and effectiveness of our GNL model to diverse distribution shifts. 

 % \textbf{One-class Novelty Detection}
On the MNIST/MNIST-M dataset in Table \ref{tab:mnist}, GNL consistently and significantly outperforms all other methods on the OOD data MNIST-M, increasing by at least 10 AUROC scores. Compared to the best performer -- RD4AD -- on the ID dataset that obtains an AUROC score of 0.9889, GNL exhibits a small decline and obtains an AUROC score of 0.9691. However, a significant improvement in performance is observed on the MNIST-M dataset, with an AUROC score of 0.7087 compared to 0.5809 for RD4AD.

Similarly, GNL achieves consistently more superior AUROC performance on all three OOD datasets of PACS in Table \ref{tab:pacs}. In particular, GNL obtains AUROC scores of 0.6562, 0.6796, and 0.6239 for the Art, Cartoon, and Sketch datasets, respectively, increasing by at least 5\% on the Art and Cartoon datasets over the competing models. These results indicate that our method is highly effective at detecting anomalies in various domain shifts. Compared to RD4AD, our method not only largely improves the OOD performance, but also enhances its performance on the ID data, the Photo data. This is because the Photo data contains multiple sub-domains, and RD4AD can be susceptible to overfitting on a specific sub-domain in the training data. By contrast, our method helps to mitigate this issue by learning more generalized normality representations and improve performance across all sub-domains within the Photo data. The performance of GNL on the ID data is also highly comparable to the best performer KDAD, 0.8767 vs. 0.8817, whereas GNL outperforms KDAD on the three OOD datasets by about 3\%-10\% in AUROC.

% The similar trend is seen on Handwritten Digit Recognition datasets \ref{tab:t2}. The results indicate that our method exhibits only a slight reduction in performance compared to the original RD4AD on the MNIST dataset, with a score of 0.9691 compared to 0.9889. However, a significant improvement in performance is observed on the MNIST-M dataset, with a score of 0.7087 compared to 0.5809 of the original RD4AD.
% This demonstrates the models' inability to cope with domain shifts, which can occur when data from different sources are combined.
% This drop in performance highlights the models' difficulty in generalizing to out-of-distribution data, which is an important challenge in real-world applications.

% Anomaly detection results on MVTec are shown in Tab. 1

\subsection{Robustness to Various Distribution Shift Levels}

Figure \ref{fig:changingseverity} presents the results of the robustness of GNL to varying levels of distribution shift, using the best competing methods RD4AD, Augmix and EFDM as baselines. The experiments are done on MVTec with increasing levels of `Contrast' corruption. Notably, the performance of the baselines exhibits a significant decline as the severity of corruption amplifies.
% , which unmistakably reveals their susceptibility to distribution shifts. 
The reason behind this phenomenon is intuitive as increased corruption severity introduces more substantial distribution variance, making it arduous for the models to discern between anomalous and normal samples. Our proposed method, on the other hand, demonstrates remarkable stability in performance across multiple levels of distribution shift. Our method maintains stable performance when the severity is between 1 and 3, and reduces to about 0.90 AUROC when the severity is 4 and 5, decreasing about 5\% AUROC vs. about 30\%-35\% decrease in the competing methods. These results indicate 
% that our method has the ability to operate efficiently on multiple levels of distribution shift and is 
strong robustness of GNL to heavy distribution shifts.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.49\textwidth]{changingseverity (3).pdf}
    \caption{AUROC results on MVTec with varying severity of the `Contrast’ corruption.}
    \label{fig:changingseverity}
\end{figure}

\subsection{Ablation Study}



We examine the importance of two main components in our method, Distribution-invariant Normality Learning (DINL) and AD-oriented Test Time Augmentation (ATTA) using the PACS datase, with RD4AD as the baseline. The results are reported in Table \ref{tab:ablation}. Generally, all two components positively contribute to the superior performance of GNL. In particular, the experimental results show that if only the test time augmentation is applied, we gain about 2\% AUROC improvement over the baseline on the OOD datasets, but it leads to a slight performance decrease on the ID data. 
% Even on the Photo (ID) domain, the performance is also reduced.
When DINL is applied, it results in substantial improvement across both ID and OOD datasets, having 4\%-7\% AUROC improvement. When both are applied, we obtain the best performance, resulting in further substantial AUROC improvement. This indicates that both components, one reducing the distribution gap during training and another reducing the gap during inference, can well complement each other.
% not only improves the detection performance of the original model by itself but also makes test time augmentation more efficient than when test time augmentation is applied to the original model. 
% Experimental results also illustrate that EFDM shows slightly more efficiency than AdaIN in all domains.

\begin{table}[h]
\centering
\scalebox{0.9}{
\begin{tabular}{c|c|c|c|c}
\hline
& \multicolumn{1}{c}{ID} & \multicolumn{3}{|c}{OOD} \\
\cline{2-5}
\hline
 Method & Photo & Art & Cartoon & Sketch \\
\hline
Baseline &  81.49 &  61.07 &  60.34 &  55.06 \\
\hline
% TAdaIN &  80.26 &  63.74 &  60.76 &  56.13 \\
ATTA &  81.05 &  64.36 &  62.04 &  57.04 \\
\hline
DINL &  85.71 &  62.34 &  65.63 &  57.12 \\
\hline
% DINL+TAdaIN &  85.84 &  64.45 &  65.28 &  60.57 \\
DINL+ATTA &  \textbf{87.67} &  \textbf{65.62} &  \textbf{67.96} &  \textbf{62.39} \\\hline
\end{tabular}
}
\caption{AUROC results (\%) of ablation study.}
% and the effectiveness of two arbitrary style transfers, AdaIN and EFDM
\label{tab:ablation}
\end{table} 

\subsection{Hyperparameter Analysis}
Fig. \ref{fig:alpha} depicts how the performance of our model GNL changes with varying $\alpha$, which is a hyperparameter in ATTA. 
% The model is trained using Distribution-invariant Normality Learning methodology, and the testing phase is augmented with EFDM. 
The results suggest that the effectiveness of our model remains consistent across different $\alpha$ values on the Photo and Cartoon datasets. In contrast, the model's ability to detect anomalies on the Art data appears to improve as $\alpha$ increases. However, for the Sketch data, the model's performance reaches its maximum at $\alpha = 0.4$ and slightly decreases as $\alpha$ increases further. Overall, a medium value, \eg, $\alpha=0.5$, is generally recommended in practice.


\begin{figure}[h]
    \centering
    \includegraphics[width=0.49\textwidth]{Alpha.pdf}
    \caption{AUROC results using varying $\alpha$.
    % changes with the same model applied DINL during training and TTAAD with EFDM in inference phase. 
    The smaller the $\alpha$ value, the lower the severity of style transfer.}
    \label{fig:alpha}
\end{figure}
% In addition, the effectiveness of two arbitrary style transfers, AdaIN and EFDM, are also tested.

% The results suggest that an increase in the value of $\alpha$ corresponds to a gradual increase in the performance of the model on the ID data, i.e., Art, Cartoon, and Sketch. Simultaneously, the performance of the model on the ID data, which in this case is Photo, remains stable. In general, the high value of $\alpha$ can improve the performance of the model on the OOD data without significantly compromising the performance on the source domain.




% \begin{figure}
%      \centering
%      \begin{subfigure}
%          % \centering
%          \includegraphics[width=0.2\textwidth]{elephant.pdf}
%          \caption{PACS}
%          \label{fig:y equals x}
%      \end{subfigure}
%      \begin{subfigure}
%          % \centering
% \includegraphics[width=0.2\textwidth]{zipper.pdf}
%          \caption{MVTec}
%          \label{fig:three sin x}
%      \end{subfigure}
% \end{figure}


% \begin{figure}
% \centering
% \begin{subfigure}[b]{0.5\textwidth}
%     \centering
%     \includegraphics[width=\textwidth]{elephant1.pdf}
%     \caption{Anomaly scores on PACS (`elephant' as the normal class)}
%     \label{fig:first}
% \end{subfigure}
% \vspace{0.0cm}
% \begin{subfigure}[b]{0.5\textwidth}
%     \centering
% \includegraphics[width=\textwidth]{zipper2.pdf}
% \caption{Anomaly scores on MVTec (the `Zipper' data)}
%     \label{fig:third}
% \end{subfigure}
% \caption{Distribution of anomaly scores yielded by our method and RD4AD. }
% \label{fig:figures}
% \end{figure}





\section{Conclusion}
In this work we propose a novel approach, namely GNL, to addressing the problem of anomaly detection in the presence of distribution shifts. GNL improves the generalization of the detection model by reducing the distribution gap between ID and OOD normal data in both training and inference stages. We also present comprehensive performance benchmarks and reveal that combined AD and OOD generalization methods do not work well for this task. Our approach is specifically designed for the OOD generalization in the AD task and shows significant improvement over the competing baselines. As shown in our results, our approach GNL is also robust to heavy distribution shifts.
% Our experimental results demonstrate that our approach outperforms existing methods for detecting anomalies in the presence of distribution shift. 
Overall, our approach represents an important contribution to unsupervised anomaly detection, as it addresses a more realistic problem that has not been adequately studied before.

% In future work, we plan to explore extensions of our approach to handle more complex scenarios and investigate its applicability to other types of data.







{\small
\bibliographystyle{ieee_fullname}
\bibliography{refs}
}




\end{document}
