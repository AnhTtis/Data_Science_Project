\documentclass[journal,draftcls,onecolumn,12pt,twoside]{IEEEtranTCOM}
%
% If IEEEtran.cls has not been installed into the LaTeX system files, manually specify the path to it like:
%\documentclass[journal]{../sty/IEEEtran}

\normalsize

% *** CITATION PACKAGES ***
%
\usepackage{cite}
\usepackage{graphicx}
\usepackage[cmex10]{amsmath} %IEEE
%\usepackage{algorithmic}
% \usepackage{array}%tabel function
% \usepackage{mdwmath}
% \usepackage{mdwtab} %其他生成表格的宏包
% \usepackage{eqparbox} %生成方框
% \usepackage[tight,footnotesize]{subfigure} %subfigure
% http://www.ctan.org/tex-archive/obsolete/macros/latex/contrib/subfigure/
%\usepackage{algorithm}
%\usepackage[ruled,linesnumbered]{algorithm2e}
\usepackage[ruled,vlined]{algorithm2e}

\usepackage{booktabs}
%\usepackage[colorlinks,linkcolor=black,anchorcolor=black,citecolor=black]{hyperref} %cite,和下面{natbib}配合
%\usepackage[numbers,sort&compress]{natbib}
\usepackage{bm}
\usepackage{balance} 
% \renewcommand{\algorithmicrequire}{\textbf{Input:}}
% \renewcommand{\algorithmicensure}{\textbf{Output:}}


% *** SUBFIGURE PACKAGES ***
% correct bad hyphenation here
%\hyphenation{op-tical net-works semi-conduc-tor}
\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{Parity-check-aided Dynamic SCL-Flip Decoder with A Simplified Flip Metric for Polar Codes}

%多段，用多个\thanks{}
% author names and IEEE memberships note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break a structure at a ~ so this keeps an author's name from being broken across two lines.
% use \thanks{} to gain access to the first footnote area a separate \thanks must be used for each paragraph as LaTeX2e's \thanks was not built to handle multiple paragraphs
% %

\author{Yansong Lv, Hang Yin, and Zhanxin Yang% <-this % stops a space

\thanks{Yansong Lv is with the Engineering Research Center of the Digital Audio and Video Ministry of Education, Communication University of China, Beijing, 100024, China.(e-mail: lys\_communication@cuc.edu.cn).}% <-this % stops a space
\thanks{Hang Yin and Zhanxin Yang are with the State Key Laboratory of Media, Convergence and Communication, Communication University of China, Beijing, 100024, China.(e-mail: yinhang@cuc.edu.cn and yangzx@cuc.edu.cn)}% <-this % stops a space
}

% note the % following the last \IEEEmembership and also \thanks - 
% these prevent an unwanted space from occurring between the last author name
% and the end of the author line. i.e., if you had this:
% 
% \author{....lastname \thanks{...} \thanks{...} }
%                     ^------------^------------^----Do not want these spaces!
%
% a space would be appended to the last name and could cause every name on that
% line to be shifted left slightly. This is one of those "LaTeX things". For
% instance, "\textbf{A} \textbf{B}" will typeset as "A B" not "AB". To get
% "AB" then you have to do: "\textbf{A}\textbf{B}"
% \thanks is no different in this regard, so shield the last } of each \thanks
% that ends a line with a % and do not let a space in before the next \thanks.
% Spaces after \IEEEmembership other than the last one are OK (and needed) as
% you are supposed to have spaces between the names. For what it is worth,
% this is a minor point as most people would not even notice if the said evil
% space somehow managed to creep in.



% The paper headers
%\markboth{IEEE Transactions on Communications}%
%{Submitted paper}
% The only time the second header will appear is for the odd numbered pages after the title page when using the twoside option.
% 
% *** Note that you probably will NOT want to include the author's name in the headers of peer review papers.                   ***
% You can use \ifCLASSOPTIONpeerreview for conditional compilation here if you desire.

% If you want to put a publisher's ID mark on the page you can do it like this:
%\IEEEpubid{0000--0000/00\$00.00~\copyright~2007 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second column for its text to clear the IEEEpubid mark.

% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}


\maketitle

\begin{abstract}
%\boldmath
Since polar codes were proposed, improving the performance of polar codes at limited code lengths has received significant attention. One of the effective solutions is a series of list flip decoders proposed in recent years. To further enhance performance, we proposed a parity-check-aided dynamic successive cancellation list flip (PC-DSCLF) decoder in this paper. First, we designed a simplified flip metric, and proved by simulations that this simplification hardly affects the error-correction performance of list flip decoders. Subsequently, we optimized the existing allocation scheme for parity check (PC) bits, and then designed the first multi-PC-aided scheme with the dynamic characteristic for list flip decoders. The dynamic characteristic refers to an excellent ability to correct higher-order errors, which is beneficial for error-correction performance improvement. Meantime, the multi-PC-aided scheme to list flip decoders brings more flexible distributed check bits, which can narrow down the range for searching error bits and achieve a more efficient early termination. Simulation results showed that without error-correction performance loss, PC-DSCLF decoder shows up to 51.1\% average complexity gain with respect to the state-of-the-art list flip decoder at practical code lengths. Lower average complexity leads to lower average energy consumption and lower average decoding delay.
\end{abstract}
% IEEEtran.cls defaults to using nonbold math in the Abstract. This preserves the distinction between vectors and scalars. However, if the journal you are submitting to favors bold math in the abstract, then you can use LaTeX's standard command \boldmath at the very start of the abstract to achieve this. Many IEEE journals frown on math in the abstract anyway.%许多期刊对摘要中的数字不屑一顾

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
	Polar code, successive cancellation list flip (SCLF) decoding, dynamic SCLF decoding, parity check, simplified flip metric.
\end{IEEEkeywords}






% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}

% \IEEEPARstart{A}{}
% \IEEEPARstart{T}{his} %两种用法

\IEEEPARstart{T}{he} polar codes using the low-complexity successive cancellation (SC) decoding algorithm are the first channel codes that can provably achieve channel capacity with infinite code length \cite{[1]}. Due to their excellent performance, polar codes have been adopted in the channel coding scheme for control information in the 5G enhanced Mobile Broadband (eMBB) scenario \cite{[17]}. However, polar codes with SC decoding algorithm has unsatisfactory error-correction performance at limited code lengths. Hence, low-complexity and high-performance polar decoders at limited code lengths have received significant attention.

The SC list (SCL) decoding algorithm \cite{[2]}, \cite{[3]} and cyclic redundancy check (CRC)-aided SCL (CA-SCL) decoding algorithm \cite{[4]}, \cite{[5]} are classic improved algorithms based on the SC decoding algorithm. These two improved decoding algorithms adopt a list of multiple candidate paths to improve the error-correction performance of the SC decoding algorithm with a single candidate path. In particular, by using a CRC, the CA-SCL decoder outperforms the SCL decoder in terms of error-correction performance. However, more candidate paths need more computation complexity (energy) and more storage space. To reduce the computation complexity (energy) or decoding delay, scholars have proposed different breakthrough algorithms, such as adaptive SCL decoding \cite{[18]}, log-likelihood ratio (LLR)-based SCL decoding \cite{[13]}, fast simplified SCL decoding \cite{[19]}, and the list-pruning algorithm \cite{[20]}. However, these algorithms cannot achieve better error-correction performance than the CA-SCL decoder with the same list size.

To further improve the error-correction performance of the CA-SCL decoding algorithm while maintaining the same list size, \cite{[6]} proposed the SCL bit-flip (SCL-BF) decoding algorithm. This algorithm introduces the concept of bit flip from SC flip (SCFlip) decoding algorithm \cite{[7]} into the list decoders for the first time. Thus, the algorithm may find the correct path that a failed list decoder discards, by extra decoding attempts with bit flip. Hence, the SCL-BF decoder obtains better error-correction performance than the CA-SCL decoder with the same list size. It is noted the efficiency of the bit flip operation in SCL-BF depends on two points: (1) the flip method and (2) the decision of the flip position. However, in these two points, SCL-BF decoder is very similar to SCFlip decoder (a based-SC decoder with bit flip) \cite{[7]}, so it is not effective enough for list flip decoders with a list of multiple candidate paths. To improve the efficiency of the bit flip operation, \cite{[8]} and \cite{[9]} proposed a list decoder with shift-pruning (SCL-SP) and the SCL flip (SCL-Flip) decoder successively. SCL-SP decoder replaces the bit flip strategy of SCL-BF with a more efficiently shifted-pruning strategy. SCL-Flip decoder designs a novel metric based on the posterior probabilities of all candidate paths to filter bad flip positions. Although both of these two algorithms improve the performance of the SCL-BF algorithm to some extent, they are not effective and flexible enough to correct higher-order errors, which will limit the improvement of error-correction performance and increase the number of unnecessary decoding attempts.


Inspired by D-SCFlip (a based-SCFlip decoding algorithm with the dynamic characteristic) in \cite{[10]}, \cite{[11]} recently designed a new flip metric to correct higher-order errors in the list decoding process, combined with the distributed CRC technology that contributes to early termination, and finally proposed a dynamic successive cancellation list flip (D-SCLF) decoding algorithm. Both D-SCLF decoder and DSCFlip decoder have the dynamic characteristic, which in this paper refers to the excellent ability to correct higher-order errors using only flip metrics. A high-order error in a decoding process indicates that the process cannot output the correct bit sequence by fixing a single error bit. Benefiting from its capability to correct higher-order errors, for the downlink control channel in 5G, D-SCLF decoder with a list size of only four and only three additional attempts can achieve the performance of a CA-SCL decoder with a list size of eight, which leads to an overall memory and average complexity (energy) reduction \cite{[11]}. 

In this paper, we proposed a parity-check-aided D-SCLF (PC-DSCLF) decoding algorithm. The contributions of this algorithm are as follows:

Firstly, we replaced the original flip metric of D-SCLF decoder with a simplified flip metric, considering the origin flip metric contains many logarithmic and exponential operations. The simulation results show that the D-SCLF (or PC-DSCLF) decoding algorithm using the new simplified flip metric and the D-SCLF (or PC-DSCLF) decoding algorithm using the original flip metric have similar error correction performance.

Secondly, inspired by \cite{[12]}, we proposed the first multi-PC scheme that has the dynamic characteristic and can apply to the list flip decoders. Different from the multi-PC scheme \cite{[12]} applied to the SCFlip decoder, we design a more efficient allocation scheme for multi-PC bits and a multi-PC-aided list flip decoding scheme with the dynamic characteristic. On the one hand, the new allocation scheme can eliminate the duplicate function of the last PC bits and CRC bits, and thus make PC bits play a greater role in early termination. On the other hand, the dynamic characteristic enables our scheme to have the same capability to correct high-order errors as D-SCLF decoder. Besides, we extend the original multi-PC bit scheme that only applies to the SCFlip decoder with a single candidate path to the one that can apply to the list flip decoder with a list of multiple candidate paths. These three points are not available in the original multi-PC scheme.

The successful application of the multi-PC scheme to D-SCLF decoding also means that the position and number of the distributed check bits are more flexible, instead of being restricted like the previously distributed CRC bits in D-SCLF decoder. More flexible check bits not only help the D-SCLF decoding algorithm to narrow down the range for searching error bits, but also help to achieve a more efficient early termination. To better verify the effectiveness of our multi-PC scheme, we have done some simulations without distributed CRC bits involved. Simulation results show the D-SCLF algorithm with our multi-PC scheme shows up to 64.1\% average complexity gain with respect to the D-SCLF algorithm with undistributed CRC bits, for $PC(512, 256+24)$.

Finally, we combine the simplified flip metric and multi-PC scheme (including the allocation scheme for multi-PC bits and the multi-PC-aided decoding scheme) to propose the PC-DSCLF decoding algorithm. Simulation results show that our PC-SCLF decoding algorithm shows up to 51.1\% average complexity gain with respect to the D-SCLF algorithm with distributed CRC, for $PC(512, 256+24)$, which leads to average energy reduction and average decoding delay reduction.

Without loss of generality, we choose the check bit structure consistent with that in \cite{[12]}. Besides, $PC(512, 256+24)$ represents the code length is 512, the number of the information bits is 256, and the number of check bits is 24.

The remainder of the paper is organized as follows. Section II briefly overviews the encoding method and main SCL-based decoding algorithm. Section III describes and analyzes the details of the proposed decoders. In section IV, the simulation results are illustrated and discussed. Finally, some conclusions are highlighted.

\section{Preliminaries}

In this section, we give a brief overview of the encoding method and main SCL-based decoding algorithms, for a polar code $PC(N, K+n_{crc})$ of code length $N$, CRC length $n_{crc}$, information bits length $K$, and code rate $R = K/N$. It is noted that the decoding algorithms introduced in this section only use CRC, so their total number of check bits is equal to $n_{crc}$.


\subsection{Polar Encoding Method}

The polar encoding method \cite{[1]} is defined as
\begin{equation}
	x_{1}^{N}=u_{1}^{N}B_{N}F^{\otimes n}.
\end{equation}
$x_1^N=(x_1,x_2,…,x_N)$ denotes the encoded vector. $u_1^N=(u_1,u_2,…,u_N)$ refers to the encoding vector, which consists of two subjects: $\mathcal{A}^c$ and $\mathcal{A}$. $\mathcal{A}^c$ consists of all frozen bits. $\mathcal{A}$ consists of all non-frozen bits. $\otimes$ refers to the Kronecker product and $F=\begin{bmatrix} 1 & 0 \\ 	1 & 1 \\ \end{bmatrix}$. $B_N$ is a bit-reversal permutation matrix.

\subsection{CA-SCL decoder}

The CA-SCL decoder \cite{[4]},\cite{[5]} is a well-known polar code decoding algorithm due to its superior performance. The main reason for obtaining excellent performance is the use of multiple candidate paths and a CRC check.

Assume $L$ is total number of candidate paths. In CA-SCL decoding, the path metric (PM) was used to measure the reliability of these paths, which can be an be computed by the following equation \cite{[13]}.
\begin{equation}
	%\begin{split}
		{PM}_{l}^{(i)}=  \left\{\begin{matrix} {PM}_{l}^{(i-1)},  & \text{if}\quad \hat{u}_{i}[l]=\delta (\lambda_{N}^{(i)}[l])                                        \\
               {PM}_{l}^{(i-1)}+\left| \lambda_{N}^{(i)}[l] \right|, & \text{otherwise}  \\
		\end{matrix}\right.
	%\end{split}
\end{equation}\
where $\delta(x)=\frac{1}{2}(1-sign(x))$, and $\lambda_{N}^{(i)}[l]$ refers to the log-likelihood ratio (LLR) value of the $i^{th}$ bit in the $l^{th}$ candidate path. ${PM}_l^{(i)}$ represents the $PM$ value of the $i^{th}$ bit in the $l^{th}$ candidate path, and ${PM}_l^{(0)}=0$. A candidate path with a larger $PM$ means the path is more like to be a wrong estimated path. 

When decoding the $i^{th}$ bit and $i\in\mathcal{A}'$, CA-SCL decoder utilizes a list $\mathcal{L}_{best}^{(i)}$ to reserve all candidate paths. $\mathcal{A}'$ refers to the set consisted of the first $log_2(L)$ non-frozen bits. When decoding the $i^{th}$ bit and $i\in\mathcal{A}\setminus\mathcal{A}'$, $L$ paths in  $\mathcal{L}_{best}^{(i-1)}$ are expanded to $2L$ sub-paths, which forms an expanded list $\mathcal{L}^{(i)}$. Then, $\mathcal{L}_{best}^{(i)}$ can be achieved by selecting $L$ paths with smaller PM from  $\mathcal{L}^{(i)}$. 

After all bits are decoded, CA-SCL decoding algorithm performs CRC on paths in the  $\mathcal{L}_{best}^{(N)}$. If CRC fails, CA-SCL output the candidate path with smallest PM in $\mathcal{L}_{best}^{(N)}$. If not, CA-SCL decoder output the candidate path with the smallest PM among those candidate paths passing the CRC check. 


\subsection{SCLFlip decoder}

To obtain better error-correction performance of CA-SCL decoder, \cite{[6]} proposed an SCL bit-flip (SCL-BF) decoder, which is the first decoder introducing flip operations to a failed CA-SCL decoding process. A failure CA-SCL decoding process refers to its corresponding CRC fails. Obviously, the key of SCL-BF decoder to improve the error-correction performance are the accuracy of identifying the first error bit and the efficiency of flip operations.

To improve the accuracy of identifying error bits in a failed CA-SCL decoding process, \cite{[9]} proposed the SCL flip (SCL-Flip) decoder that designs a novel flip metric based on PM. The new metric in \cite{[9]} be computed by the following equation.
\begin{equation}
	E_{\alpha}^{(i)}=ln\frac{\sum_{l=1}^{L}e^{-PM_l^{(i)}}}{{(\sum_{l=1}^{L}e^{-PM_{l+L}^{(i)}})}^\alpha}
\end{equation}\
where $E_{\alpha}^{(i)}$ denotes the flip metric $E$ value of the $i^{th}$ bit, and $\alpha$ is a coefficient to compensate for the biased estimation due to the error propagation. A lower $E$ means that mistakes are more likely to occur. Because of this, the SCLFlip decoder prioritizes flipping information bits with lower $E$ value. 

However, a lower $E$ does not represent a higher likelihood of the first mistake happening.

\subsection{D-SCLF decoder}

To optimize the flip metric in SCLFlip, \cite{[11]} proposed D-SCLF decoders inspired by the D-SCFlip decoder in \cite{[10]}. D-SCLF decoder designs a new flip metric to approximate the probability of $\varepsilon^{(i)}$ occurring in a CA-SCL decoding process. $\varepsilon^{(i)}=\{u_1^{i-1}\in\mathcal{L}_{best}^{(i-1)}, u_1^{i}\notin\mathcal{L}_{best}^{(i)} \}$ represents the event that the first mistake happened in the $i^{th}$ bit.

Furthermore, D-SCLF extends the flip metric and dynamically builds a list of flip sets to correct high-order errors in a failed CA-SCL decoding process. The probability that $\varepsilon^{(i)}$ occrurs with the flip set $S_t$ \cite{[11]} satisfies 
\begin{equation}
	P(\varepsilon^{(i)}|y,S_t) = P_e^{(i)}\cdot\prod_{k\in S_t}^{}P_e^{(k)}\cdot\prod_{k<i, k\in\{\mathcal{A}\setminus\mathcal{A}'\}\setminus S_t }^{}(1-P_e^{(k)}),   
\end{equation}\ 
and $P_e^{(i)}=\frac{1}{1+e^{\beta\cdot E_1^{(i)}}}$. Therefore, the extended flip metric in \cite{[11]} can be obtained by the following calculation.

\begin{equation}
	\begin {aligned}
		M_{\beta}^{(i)} &=-\frac{1}{\beta}ln(P(\varepsilon^{(i)}|y,S_t) \\
						&=-\frac{1}{\beta}ln(P_e^{(i)})-\frac{1}{\beta}\sum_{k\in S_t}^{}ln(P_e^{(k)}) -\frac{1}{\beta}\sum_{k<i, k\in\{\mathcal{A}\setminus\mathcal{A}'\}\setminus S_t }^{}ln(1-P_e^{(k)})\\
						&=E_1^{(i)}+f_{\beta}(E_1^{(i)})+\sum_{k\in S_t}^{}E_1^{(k)}+\sum_{k\in S_t}^{}f_{\beta}(E_1^{(k)}) +\sum_{k<i, k\in\{\mathcal{A}\setminus\mathcal{A}'\}\setminus S_t }^{}f_{\beta}(E_1^{(k)})\\
						&=E_1^{(i)}+\sum_{k\in S_t}^{}E_1^{(k)}+\sum_{ k<=i, k\in\mathcal{A}\setminus\mathcal{A}'  }^{} f_{\beta}(E_1^{(k)})
	\end{aligned}
\end{equation}\
where $f_{\beta}(x)=\frac{1}{\beta}ln(1+e^{-\beta x})$. $\beta$ is also a compensated coefficient with similar function like $\alpha$. $E_1^{(i)}=E_{\alpha=1}^{(i)}$. $S_t$ records all flip indices for the $t^{th}$ additional decoding attemps, where $1<=t<=T$ and $T$ is the max number of additional attemps. Meanwhile, $S_t$ is a subset of a dynamic flip set $\mathcal{S}$, where $\mathcal{S}=\{S_1, S_2,…, S_T\}$ has a constant size of $T$ but is updated after each failure decoding attempts.  $\mathcal{A}'$ consists of the first $log_2(L)$ unfrozen bits.

Similar to SCLFlip decoder, D-SCLF decoder prioritizes flipping information bits set with lower $ M $ value computed by (5).



\section{PC-DSCLF Decoder}
\subsection{The Simplification to The Flip Metric in D-SCLF Decoder}


Although D-SCLF algorithm designs a flip metric to approximate the probability of the first mistake happening and utilize it to correct high-order errors, the expression, $f_\beta(x)$, contained by the flip metric is inconvenient for efficient hardware implementations. Therefore, inspired by the approximation in \cite{[14]}, we replaced the original flip metric with a simplified flip metric in this section.

We default $\beta$ to 0.4, because it is preferable to have a constant value of $\beta$ and the D-SCLF utilizing $M$ with $\beta=0.4$ outperforms the SCLFlip decoder using $E$ \cite{[11]}. 

The new flip metric our proposed satisfies
\begin{equation}
	{M^*}_{\beta}^{(i)}(S_t) =E_1^{(i)}+\sum_{k\in S_t}^{}E_1^{(k)}+\sum_{ k<=i, k\in\mathcal{A}\setminus\mathcal{A}'  }^{} f_{\beta=0.4}^*(E_1^{(k)})
\end{equation}\
where 
\begin{equation}
	f_{\beta=0.4}^*(E_1^{(k)})=  \left\{\begin{matrix} 1,  & \text{if}\quad \left| x \right| <=z                              \\
        0, & \text{otherwise}  \\
	\end{matrix}\right.
\end{equation}\
$z$ is a positive integer. To make (6) easier to understand, we replace ${M^*}_{\beta}^{(i)}(S_t) $ with ${M}_{\beta}^*(S_t\bigcup \{i\}) $. Specially,  ${M}_{\beta}^*(S_t) $ satisfies 
\begin{equation}
	{M}_{\beta}^*(S_t) =\sum_{k\in S_t}^{}E_1^{(k)}+\sum_{ k<=i_t, k\in\mathcal{A}\setminus\mathcal{A}'  }^{} f_{\beta=0.4}^*(E_1^{(k)}),
\end{equation}\
where $i_t$ is the last element in $S_t$.

For illustration purpose, Fig. 1 plots the comparison of $f_{\beta}(x)$ and $f_{\beta}^*(x)$, with $\beta=0.4$. 
\begin{figure}[!t]
	\centering
	\includegraphics[scale=1.1]{Figure/fig1.pdf} %[trim=15 20 0 0, clip,scale=0.6]
	% figure caption is below the figure
	\caption{The comparison of $f_{\beta=0.4}(x)$ and $f_{\beta=0.4}^*(x)$}
	\label{fig:1}       % Give a unique label
\end{figure}

Fig. 2 plots the error-correction performance comparison of D-SCLF-2 decoding algorithm with our approximation  $f_{\beta}^*(x)$  against its original approach $f_{\beta}(x)$. D-SCLF-2 refers to the D-SCLF's number of flip indices for an additional decoding attempt is less than or equal to 2. The reason why we set the maximum number of flip indices for an additional attempt to 2 is to conveniently compare the performance of the D-SCLF decoding algorithm in \cite{[11]} and to verify the ability to correct high-order errors. In subsequent simulations, we default this value to 2.

We have noticed the frame error rate (FER) performance of D-SCLF-2 decoder using our proposed threshold is similar to that of the origin D-SCLF-2 decoder in general. Particularly, when $FER > 10^{-3}$ and $z = 6$ (or 7), the FER performance of D-SCLF decoder with $f_{\beta}^*(x)$ outperforms that of the origin D-SCLF decoder. The reason is that the threshold $M$ only approximates the probability of incurring the first error. 

Therefore, with a similar error-correction performance, our proposed flip metric efficiently eliminates the logarithmic and exponential functions contained by $f_{\beta}(x)$ in D-SCLF decoder.

However, with z increases, the FER performance of D-SCLF algorithm with $f_{\beta}^*(x)$ gradually declines when $FER < 5\times 10^{-3}$. Therefore, considering a constant value of $z$ is preferable and the overall similar error-correction performance is required, we default $z$ to 5 in the following sections. 
\begin{figure}[!t]
	\centering
	\includegraphics[scale=1]{Figure/fig2.pdf} %[trim=15 20 0 0, clip,scale=0.6]
	% figure caption is below the figure
	\caption{The error-correction performance comparison of D-SCLF-2 using $f_{\beta=0.4}(x)$ and D-SCLF-2 using $f_{\beta=0.4}^*(x)$ with different $z$ value and $L=4$. }
	\label{fig:2}       % Give a unique label
\end{figure}

\subsection{Improved Allocation Scheme for Multi-PC Bits}

D-SCLF decoder utilizes the distributed CRC bits to realize early termination and then reduce its computation complexity. However, most of these distributed CRC bits append to the end of non-frozen bits and thus do not contribute to early termination. Besides, other CRC bits that contribute to early termination are also limited in number and location flexibility due to the information bits they protect. Therefore, a more flexible early termination technique that can be applied to D-SCLF decoders is worth exploring.

Inspired by the multi-PC scheme in \cite{[12]}, we infer that if the scheme can be successfully applied to D-SCLF decoding, then a new and more flexible early termination scheme is generated. But there are several difficulties. On the one hand, the original multi-PC scheme can only be applied to SCFlip decoder with a single candidate path and cannot be applied to a more complex list flip decoder with a list of multiple candidate paths. On the other hand, although the original multi-PC scheme adopts a new flip metric to simplify the flip metric in D-SCFlip decoding algorithm, it fails to preserve the dynamic characteristic, which means that it cannot retain the same error correction performance potential as D-SCFlip decoding and will result in redundant decoding attempts. Meantime, although it has a positive effect on the flip efficiency improvement of SCFlip by limiting the flip position in a predetermined set, it may not have the corresponding positive effect when it applies to list flip decoders, because the predetermined set is generated by estimating the first hard-decision error location of SC decoding.

After overcoming these challenges, we propose the first multi-PC scheme that has the dynamic characteristic and can apply to D-SCLF decoding to our knowledge. This scheme consists of an optimized allocation scheme for PC bits and a multi-PC-aided decoding scheme. In this section, we give the details of allocation scheme.

In the original allocation scheme, the PC bits are approximately uniformly distributed on the predetermined set. However, we have noticed the last PC bit and the CRC bits play duplicate roles, due to their close positions. Therefore, we design a new allocation scheme that eliminates this duplicate function to make PC bits play a greater role in early termination.

It is noted that a predetermined set contains more than 99\% of all incorrect hard decisions caused by the channel noise in SC decoding process \cite{[15]}. Meanwhile, a predetermined set consists of only non-frozen bits. For brevity, this paper will not describe the method of generating a predetermined set in detail, and more details are available in fig. 3 of \cite{[12]}.

Assume $n_{ps}$ is the number of elements in the predetermined set, $n_{pc}$ is the number of PC bits, and $n_{crc}$ is the number of CRC bits. Let $q_{up}=\lceil n_{ps}/(n_{pc}+1)\rceil$ and $q_{down}=\lfloor n_{ps}/(n_{pc}+1)\rfloor$.	Similar to the allocation scheme in \cite{[12]}, our allocation also includes two cases.


In case one ($q_{up}=q_{down}$),
\begin{equation}
U_{pc(i)}=U_{Loc(i\times q_{up})}=\oplus_{k=(i-1)\times q_{up}+1,..., i\times q_{up}-1} U_{Loc(k)}.
\end{equation}\
$U_i$ represents the value of $i^{th}$ non-frozen bit. $pc(i)$ refers to the index of $i^{th}$ PC bit in the non-frozen bit sequence $\mathcal{A}$. $Loc(i)$ is the index of $i^{th}$ element in the predetermined set in $\mathcal{A}$.

In case two ($q_{up}=q_{down}+1$),
\begin{equation}
	n_{ps}=c_1\times q_{up} + c_2 \times q_{down},
\end{equation}\
where $c_1=n_{ps}-q_{down}\times(n_{pc}+1)$, and $c_2=n_{pc}+1-c_1$. Then,
\begin{equation}
	U_{pc(i)}= \left\{\begin{matrix} U_{Loc(i\times q_{up})},  & \text{if}\quad i<=c_1  \\
		U_{Loc(c_1\times q_{up} + (i-c_1)\times q_{down} )}, & \text{if} \quad i>c_1  \\
		\end{matrix}\right.
\end{equation}\
where $U_{Loc(i\times q_{up})}$ satisfies equation (9) and 
\begin{equation}
	\begin{aligned}
	U_{Loc(c_1\times q_{up} + (i-c_1)\times q_{down} )} = \oplus_{k=c_1\times q_{up}+(i-c_1-1)\times q_{down}+1,...,c_1\times q_{up}+(i-c_1)\times q_{down}-1} U_{Loc(k)}\\
	\end{aligned}
\end{equation}\

To explained our method and its difference from the original method more intuitively, we describe Fig. 3 based a hypothetical non-frozen bit sequence. 

Fig. 3 (b) shows our allocation scheme. By simple calculation, we can get $(n_{ps},n_{pc},q_{up},q_{down},c_1,c_2 )=(7,3,2,1,3,1)$.  By further calculation according to (9)-(12) ,we can obtain 
\begin{equation}
		\begin{aligned}
		(U_{pc(1)}, U_{pc(2)}, U_{pc(3)})  = (U_{Loc(2)}, U_{Loc(4)}, U_{Loc(6)}) =(U_{Loc(1)}, U_{Loc(3)}, U_{Loc(5)}).\nonumber
	\end{aligned}
\end{equation}\
Similarly, from Fig. 3 (a), we can get
\begin{equation}
	\begin{aligned}
		(U_{pc(1)},  U_{pc(2)}, U_{pc(3)})= (U_{Loc(3)}, U_{Loc(5)}, U_{Loc(7)}) =(U_{Loc(1)}\oplus U_{Loc(2)}, U_{Loc(4)}, U_{Loc(6)}).\nonumber
\end{aligned}
 \end{equation}\

 Obviously, the last PC bit and the CRC bits in Fig. 3 (a) play duplicate roles, but no similar situation occurs in Fig. 3 (b). It should be emphasized that although this is a hypothetical non-frozen bit sequence, the reality may be that the last PC bit position coincides with the position of a CRC bit, because the predetermined set is composed of non-frozen bits in $\mathcal{A}$, and CRC bits are also in $\mathcal{A}$. So this hypothetical non-frozen bit sequence is not an isolated case, and this optimization is necessary.

 \begin{figure}[!t]
	\centering
	\includegraphics[scale=1]{Figure/fig3.pdf} %[trim=15 20 0 0, clip,scale=0.6]
	% figure caption is below the figure
	\caption{An example of different multi-PC bits allocation schemes with 3 PC bits for a hypothetical non-frozen bits sequence.}
	\label{fig:3}       % Give a unique label
\end{figure}


It is also noted that the main difference between our allocation scheme and the allocation scheme in \cite{[12]} is that we divide the predetermined set into $n_{pc}+1$ segments, and the last segment is not protected by a PC bit. Therefore, our proposed scheme can eliminate the duplicate function of the last PC bits and CRC bits, and thus make PC bits play a greater role in early termination.

\subsection{Multi-PC-aided Decoding Scheme and PC-DSCLF decoder}

In this section, we give the details of the PC-DSCLF decoder, which contains the simplified flip metric and a new multi-PC-aided decoding scheme. Unlike the original multi-PC scheme, the new scheme has the dynamic characteristic, which means our scheme can correct high-order errors like D-SCLF decoding. Besides, the successful application of the multi-PC-aided decoding scheme brings more flexible distributed check bits, which can narrow down the range for searching error bits and achieve a more efficient early termination.


\begin{algorithm}[htb]
	\caption{PC-DSCLF decoder}
	\label{alg:alg1}
	\KwIn{$ \mathcal{A}^c, K, L, T,N$}
	\KwOut{$\hat{u}_{1}^{N}$}
	\For{$t\leftarrow$ 0 to $T$}{
		$(CRCerr,PCerr,\mathbf{E} _{\alpha=1},\mathcal{S},\mathcal{M}) \leftarrow (1,0,[0]_{1 \times N},[0]_{1 \times T},[0]_{1 \times T})$; \\
		\For{$i\leftarrow$ 1 to $N$}{
			$\mathcal{L}_{best}^{(i)}\leftarrow$ \textbf{SCLDecoding}($S_t$);\\
			\If{$i\in\mathcal{A}\setminus\mathcal{A}' $}{
				$\mathbf{E} _{\alpha=1}(i) \leftarrow E_{\alpha=1}^{(i)}$;
			}
			$PCerr \leftarrow$  \textbf{PCcheck}($\mathcal{L}_{best}^{(i)},PCerr,i$);\\
			\If {$PCerr=1$}{
				break;
			}
			$CRCerr \leftarrow$ \textbf{CRCcheck}($\mathcal{L}_{best}^{(i)},CRCerr,i,N$);
		}
		\eIf{$CRCerr=1$}{
			$\hat{u}_1^N \leftarrow$ the candidate path with smallest PM in $\mathcal{L}_{best}^{(N)}$;\\
			$(\mathcal{S},\mathcal{M}) \leftarrow$ \textbf{UpdateFlipList}$(i,\mathcal{S},\mathcal{M},\mathbf{E}_{\alpha=1},N,t,T)$;
		}
		{
			$\hat{u}_1^N \leftarrow$ the candidate path with the smallest PM among those candidate paths passing the CRC check in $\mathcal{L}_{best}^{(i)}$;\\
			break;
		}
	}
	\Return{ $\hat{u}_1^N$ }
\end{algorithm}


% \begin{algorithm}[!t]
%   \caption{PC-DSCLF decoder}
%   \label{alg:alg1}
%   \begin{algorithmic}
%     \REQUIRE $ \mathcal{A}^c, K, L, T,N$
%     \ENSURE $\hat{u}_{1}^{N}$
%     \FOR{$t\leftarrow$ 0 to $T$}
%     \STATE A
%     \ENDFOR
%     \end{algorithmic}
% \end{algorithm}


% \begin{algorithm}[!t]
%   \caption{PC-DSCLF decoder}
%   \label{alg:alg1}
%   \begin{algorithmic}
%     \REQUIRE $ \mathcal{A}^c, K, L, T,N$
%     \ENSURE $\hat{u}_{1}^{N}$
%     \FOR{$t\leftarrow$ 0 to $T$}
%       \STATE $(CRCerr,PCerr,\mathbf{E} _{\alpha=1},\mathcal{S},\mathcal{M}) \leftarrow (1,0,[0]_{1 \times N},[0]_{1 \times T},[0]_{1 \times T})$; 
%       \FOR{$i\leftarrow$ 1 to $N$}
%         \STATE $\mathcal{L}_{best}^{(i)}\leftarrow$ \textbf{SCLDecoding}($S_t$);
%         \IF{$i\in\mathcal{A}\setminus\mathcal{A}' $}
%           \STATE $\mathbf{E} _{\alpha=1}(i) \leftarrow E_{\alpha=1}^{(i)}$;
%         \ENDIF
%         \STATE $PCerr \leftarrow$  \textbf{PCcheck}($\mathcal{L}_{best}^{(i)},PCerr,i$);
%         \IF {$PCerr=1$}
%           \STATE break;
%         \ENDIF
%         \STATE $CRCerr \leftarrow$ \textbf{CRCcheck}($\mathcal{L}_{best}^{(i)},CRCerr,i,N$);
%       \IF{$CRCerr=1$}
%         \STATE $\hat{u}_1^N \leftarrow$ the candidate path with smallest PM in $\mathcal{L}_{best}^{(N)}$;
%         \STATE $(\mathcal{S},\mathcal{M}) \leftarrow$ \textbf{UpdateFlipList}$(i,\mathcal{S},\mathcal{M},\mathbf{E}_{\alpha=1},N,t,T)$;
%       \ELSE
%         \STATE$\hat{u}_1^N \leftarrow$ the candidate path with the smallest PM among those candidate paths passing the CRC check in $\mathcal{L}_{best}^{(i)}$;
%         \STATE break;
%       \ENDIF
%     \ENDFOR
%     \ENDFOR
%     %\RETURN $\hat{u}_1^N$ 
%   \end{algorithmic}
% \end{algorithm}


Algorithm 1 describes the detail of PC-DSCLF decoder. $T$ refers to the maximum of additional attempts. $N$ represents the code length. \textbf{SCLDecoding}($S_t$) denotes standard CA-SCL decoding during which the path selection at the bit indices given in this set $S_t$ is flipped. Specially, \textbf{SCLDecoding}($\emptyset$) denotes standard CA-SCL decoding without flip operation. The flip operation refers to the current $\mathcal{L}_{best}^{(i)}$ is achieved by selecting L paths with bigger PM from  $\mathcal{L}^{(i)}$. $\mathcal{S}=\{S_1,S_2,…,S_T\}$ refers to the list of flip sets. For example, the flip set $S_t$ records all flip indices for the $t^{th}$ additional decoding attempt. It is noted $S_0$ is not a subset of $\mathcal{S}$, and $S_0=\emptyset$. $\mathcal{M}=\{M_\beta^*(S_1),M_\beta^*(S_2),...,M_\beta^*(S_T) \}$ and $M_\beta^*(S_1) <M_\beta^*(S_2)<...<M_\beta^*(S_T)$. The initial values of elements in $\mathcal{S}$ and $\mathcal{M}$ are both $[0]_{1 \times T}$. $E_{\alpha=1}(i)$ can be achieved by equation (3).

After \textbf{SCLDecoding}($S_t$) decoded the $i^{th}$ bit that is a PC bit, the PC check will be activated. If all paths in $\mathcal{L}_{best}^{(i)}$ cannot pass all PC checks before the $(i+1)^{th}$ bit, PCerr will be updated to 1. Subsequently, the current \textbf{SCLDecoding}($S_t$) is terminated, and  $(\mathcal{S},\mathcal{M})$ will be updated for use by \textbf{SCLDecoding}($S_t+1$). If not, \textbf{SCLDecoding}($\emptyset$) will continue to decoder until the next PC bit. When \textbf{SCLDecoding}($S_t$) can decoded the $N^{th}$ bit, the CRC check will be activated. If all paths in $\mathcal{L}_{best}^{(N)}$ cannot pass the CRC check, CRCerr will be updated to 1, and $(\mathcal{S},\mathcal{M})$ will be updated for use by \textbf{SCLDecoding}($S_t+1$). If not, PC-DSCLF decoding is terminated and outputs the path with the smallest $PM$ among those candidate paths passing the CRC check in $\mathcal{L}_{best}^{(N)}$. 


\begin{algorithm}[!t]
	\caption{\textbf{PCcheck}()}
	\label{alg:alg2}
	\KwIn{$\mathcal{L}_{best}^{(i)},PCerr,i$}
	\KwOut{$PCerr$}
	\If{the $i^{th}$ bit is a PC bit}{
		\eIf{all paths in $\mathcal{L}_{best}^{(i)}$ cannot pass all PC checks before the $(i+1)^{th}$ bit}{
			$PCerr \leftarrow 1$;
		}{
			$PCerr \leftarrow 0$
		}
	}
	\Return{ $PCerr$ }
\end{algorithm}

\begin{algorithm}[!t]
	\caption{\textbf{CRCcheck}()}
	\label{alg:alg3}
	\KwIn{$\mathcal{L}_{best}^{(i)},CRCerr,i,N$}
	\KwOut{$CRCerr$}
	\If{$i=N$}{
		\eIf{all paths in $\mathcal{L}_{best}^{(N)}$ cannot pass the CRC check}{
			$CRCerr \leftarrow 1$;
		}{
			$CRCerr \leftarrow 0$
		}
	}
	\Return{ $CRCerr$ }
\end{algorithm}

Algorithm 2 and Algorithm 3 describe the details of the PC check and the CRC check, respectively.  When the current decoding bit is a check bit, one of these checks will be triggered and then updates the $CRCerr$ value or $PCerr$ value.

\begin{algorithm}[!t]
	\caption{  \textbf{UpdateFlipList}()}
	\label{alg:alg4}
	\KwIn{$breakpoint,\mathcal{S},\mathcal{M},\mathbf{E}_{\alpha=1},N,t,T$}
	\KwOut{$(\mathcal{S},\mathcal{M})$}
	$range$=min$(breakpoint,N)$;\\
	\uIf {t=0}{
		\For {$j \leftarrow $ $log_2(L)+1$ to $range$}{
			\If {$j \in \{ \mathcal{A}\setminus\mathcal{A}' \} $}{
				compute $M_\beta^*(\{j\})$ according to (6);
			}
		}
		$\mathcal{S} \leftarrow $ $T$ indexes of non-frozen bits with smaller $M_\beta^*$, and these non-frozen bits is in $\{ \mathcal{A}\setminus\mathcal{A}' \} $. \\
		$\mathcal{M} \leftarrow $ $\{  M_\beta^*(S_1),M_\beta^*(S_2),...,M_\beta^*(S_T)  \}$ \\ 
		\footnotesize //$M_\beta^*(S_1) <M_\beta^*(S_2)<...<M_\beta^*(S_T)$ \normalsize  
	}

	\ElseIf{$0<t<T$}{
		$i_t \leftarrow $ the last element in $S_t$;\\
		\For{$j \leftarrow $ $i_t+1$ to $range$}{
			\If{$j \in \{ \mathcal{A}\setminus\mathcal{A}' \} $}{
				\If{${M}_\beta^*(S_t\cup \{j\}) < {M}_\beta^*(S_T)$}{
					$\mathcal{S} \leftarrow $ $\{ S_1,...,S_t,...,S_t\cup \{j \},..., S_{T-1}  \}$;\\
					\footnotesize // the new $S_T$ in the current $\mathcal{S}$ is the $S_{T-1}$ in the $\mathcal{S}$ before being updated  \normalsize   \\
					$\mathcal{M} \leftarrow $ $\{  M_\beta^*(S_1),...,M_\beta^*(S_t),...,M_\beta^*(S_t \cup \{j \}),...,M_\beta^*(S_{T-1})  \}$;\\
					\footnotesize //$M_\beta^*(S_1)<...<M_\beta^*(S_t)<...<M_\beta^*(S_t \cup \{j \})<...<M_\beta^*(S_{T-1})  $  \normalsize
				}
			}
		} 
	}
	\Return{ $(\mathcal{S},\mathcal{M})$ }
\end{algorithm}

Algorithm 4 describes the update process of the list of flip sets $\mathcal{S}$, which will be triggered only when $CRCerr=1$ in Algorithm 1.

If $CRCerr=1$ after the initial decoding attempt \textbf{SCLDecoding}($S_0$), $\mathcal{S}$ will consist of $T$ indexes of non-frozen bits with smaller ${M}_\beta^*$, and these non-frozen bits are in $\{ \mathcal{A}\setminus\mathcal{A}' \}$. 

If $CRCerr=1$ after the $t^{th}$ additional decoding attempt \textbf{SCLDecoding}($S_t$), $\mathcal{S}$ will be updated by inserting new flip sets $\{S_t\cup \{j\} \}$ when ${M}_\beta^*(S_t\cup \{j\}) < {M}_\beta^*(S_T)$ ($j>i_t$ and $j\in \{ \mathcal{A}\setminus\mathcal{A}' \}$). Besides, a proof is required to ensure that the newly inserted flip set $\{S_t\cup \{j\} \}$ may be executed after the $t^{th}$ additional attempt. The proof process is as follows.

Proof: \begin{equation}
	\begin{aligned}
		&{M}_\beta^*(S_t\cup \{j\}) - {M}_{\beta}^*(S_t) \\
		&= E_1^{(j)}+\sum_{k\in S_t}^{}E_1^{(k)}+\sum_{ k<=j, k\in\mathcal{A}\setminus\mathcal{A}'  }^{} f_{\beta=0.4}^*(E_1^{(k)}) -  \sum_{k\in S_t}^{}E_1^{(k)}-\sum_{ k<=i_t, k\in\mathcal{A}\setminus\mathcal{A}'  }^{} f_{\beta=0.4}^*(E_1^{(k)}) \\
		& = E_1^{(j)} + \sum_{i_t<k<=j, k\in\mathcal{A}\setminus\mathcal{A}' } f_{\beta=0.4}^*(E_1^{(k)}).\nonumber
	\end{aligned}
\end{equation}\ Since $	E_1^{(j)}=ln\frac{\sum_{l=1}^{L}e^{-PM_l^{(j)}}}{\sum_{l=1}^{L}e^{-PM_{l+L}^{(j)}}} >0$ and $ f_{\beta=0.4}^* >= 0$, ${M}_\beta^*(S_t\cup \{j\}) > {M}_\beta^*(S_t) $, which means the proof is completed.


\section{Simulation Results and Discussions}
To demonstrate the effectiveness of our multi-PC bits scheme, we compare the performance of D-SCLF-2 and PC-DSCLF-2 in Fig. 4 and Fig. 5, with the same $f_{\beta=0.4}$ and the same number of check bits. Without loss of generality, we choose the check bit structure consistent with that in \cite{[12]}. The check bits of the D-SCLF-2 algorithm are composed of 8 PC bits and 16 undistributed CRC bits, where the generator polynomial of the 16 CRC bits is $g(x)=x^{16}+x^{15}+x^2+1$. The D-SCLF-2 consists of 24 undistributed CRC bits, and its generator polynomial is $g(x)=x^{24}+x^{23}+x^6+x^5+x^1+1$ . Note that our multi-PC bits allocation scheme is detailed in section III A. Besides, AWGNC channel, BPSK modulation, and Gaussian channel construction algorithm with $designSNR=4dB$ are used.

\begin{figure}[!t]
	\centering
	\includegraphics[scale=0.8]{Figure/fig4.pdf} %[trim=15 20 0 0, clip,scale=0.6]
	% figure caption is below the figure
	\caption{FER performance of the D-SCLF-2 (24 undistributed CRC bits) and PC-DSCLF-2 (8 PC bits and 16 undistributed CRC bits), with the same $f_{\beta=0.4}$ and $L=4$.  }
	\label{fig:4}       % Give a unique label
\end{figure}

Fig. 4 shows the FER performance of the D-SCLF-2 (24 undistributed CRC bits) and PC-DSCLF-2 (8 PC bits and 16 undistributed CRC bits), with the same $f_{\beta=0.4}$ and $L=4$. Under the same code rate, same amount of check bits, same $L$, and same $T$, we observed that the performance curves of the two algorithms almost overlap. Particularly at high $E_b/N_0$, the error correction performance of our algorithm is slightly better than that of D-SCLF-2. The reason is that a longer CRC bit may not contribute to a better error correction performance \cite{[16]}. This paper does not further investigate the choice of CRC bits since our main goal is to demonstrate that our multi-PC bit scheme does not reduce the error correcting performance of the original method. 




\begin{figure}[!t]
	\centering
	\includegraphics[scale=0.8]{Figure/fig5.pdf} %[trim=15 20 0 0, clip,scale=0.6]
	% figure caption is below the figure
	\caption{ Average CNP over $\mathcal{A}$ of the D-SCLF-2 (24 undistributed CRC bits) and PC-DSCLF-2 (8 PC bits and 16 undistributed CRC bits), with the same $f_{\beta=0.4}$ and $L=4$.  }
	\label{fig:5}       % Give a unique label
\end{figure}

Fig. 5 shows the corresponding average cumulative number of paths (CNP) over $\mathcal{A}$ of the algorithms in Fig. 4. We utilized the same CNP parameter as \cite{[11]} to measure the computational complexity since the multi-PC bit technique might lead to an early termination in a decoding process. For an illustration of the computed method of CNP, we give a simple example: for $PC(512, 256+24)$, the CNP in a standard SCL ($L=4$) decoding algorithm is $2+4\times(256+24-1)$. Simulation in Fig. 5 shows our multiple PC bits scheme adopting $f_{\beta=0.4}$ shows up to $\frac{19.2-6.9}{19.2}=64.1\%$ average complexity gain with respect to the D-SCLF-2 algorithm with 24 undistributed CRC bits, without any error-correction performance degradation. 

Thus, our multiple PC bits scheme maintains the error-correction performance of the D-SCLF algorithm while reducing its computational complexity.




\begin{figure}[!t]
	\centering
	\includegraphics[scale=0.8]{Figure/fig6.pdf} %[trim=15 20 0 0, clip,scale=0.6]
	% figure caption is below the figure
	\caption{ FER performance of the PC-DSCLF-2 (8 PC bits and 16 undistributed CRC bits) algorithms with different flip metrics.  }
	\label{fig:6}       % Give a unique label
\end{figure}

\begin{figure}[!t]
	\centering
	\includegraphics[scale=0.8]{Figure/fig7.pdf} %[trim=15 20 0 0, clip,scale=0.6]
	% figure caption is below the figure
	\caption{  Average CNP over $\mathcal{A}$ of the PC-DSCLF-2 (8 PC bits and 16 undistributed CRC bits) algorithms with different flip metrics. }
	\label{fig:7}       % Give a unique label
\end{figure}

Fig. 6 and Fig. 7 show the FER performance and average CNP of PC-DSCLF-2 algorithm with different flip metrics, respectively. Obviously, the curves of PC-DSCLF-2 decoder with the simplified flip metric and PC-DSCLF-2 with the original flip metric almost overlap. Therefore, our simplified flip metric eliminates the logarithmic and exponential operations in $f_{\beta=0.4}$, without increasing average CNP and degrading FER performance.


\begin{figure}[!t]
	\centering
	\includegraphics[scale=0.8]{Figure/fig8.pdf} %[trim=15 20 0 0, clip,scale=0.6]
	% figure caption is below the figure
	\caption{ FER performance of the D-SCLF-2 (24 distributed CRC bits and $f_{\beta=0.4}$ and PC-DSCLF-2 (8 PC bits and 16 undistributed CRC bits and $f_{\beta=0.4}^*$), with $L=4$.  }
	\label{fig:8}       % Give a unique label
\end{figure}

\begin{figure}[!t]
	\centering
	\includegraphics[scale=0.8]{Figure/fig9.pdf} %[trim=15 20 0 0, clip,scale=0.6]
	% figure caption is below the figure
	\caption{  Average CNP over $\mathcal{A}$ of the D-SCLF-2 (24 distributed CRC bits and $f_{\beta=0.4}$ and PC-DSCLF-2 (8 PC bits and 16 undistributed CRC bits and $f_{\beta=0.4}^*$), with $L=4$.}
	\label{fig:9}       % Give a unique label
\end{figure}

Fig. 8 and Fig. 9 show the FER performance and average CNP of the D-SCLF-2 (24 distributed CRC bits and  $f_{\beta=0.4}$ and PC-DSCLF-2 (8 PC bits and 16 undistributed CRC bits and  $f_{\beta=0.4}^*$), respectively. For the sake of illustration, we define $CNP_{SCL}$ as the CNP of a standard SCL decoding algorithm. As $E_b/N_0$ is increased, the average CNP converges to  $CNP_{SCL}$ regardless of rate and decoding algorithm. In all cases, our PC-SCLF decoding algorithm converges to  $CNP_{SCL}$ quicker than D-SCLF decoding algorithm. Specially, our PC-SCLF (T=15 and L=4) decoding shows up to $\frac{14.1-6.9}{14.1}=51.1\%$ average CNP gain with respect to the D-SCLF (T=15 and L=4) decoding, for PC(512, 256+24). 


\begin{figure}[!t]
	\centering
	\includegraphics[scale=0.8]{Figure/fig10.pdf} %[trim=15 20 0 0, clip,scale=0.6]
	% figure caption is below the figure
	\caption{ FER performance of CA-SCL (24 distributed CRC bits) and PC-DSCLF-2 (8 PC bits and 16 undistributed CRC bits).  }
	\label{fig:10}       % Give a unique label
\end{figure}

\begin{figure}[!t]
	\centering
	\includegraphics[scale=0.8]{Figure/fig11.pdf} %[trim=15 20 0 0, clip,scale=0.6]
	% figure caption is below the figure
	\caption{  Average CNP over $\mathcal{A}$ of  CA-SCL (24 distributed CRC bits) and PC-DSCLF-2 (8 PC bits and 16 undistributed CRC bits).}
	\label{fig:11}       % Give a unique label
\end{figure}

Fig. 10 and Fig. 11 show the FER performance and average CNP of CA-SCL (24 distributed CRC bits) and PC-DSCLF-2 (8 PC bits and 16 undistributed CRC bits), respectively. By only three additional decoding attempts, PC-DSCLF-2 decoder can obtain a similar FER performance with the one of CA-SCL decoder with $L=8$, while having a similar average CNP with the one of CA-SCL decoder with $L=4$, for $PC(512, 256+24)$. Although the PC-SCLF decoder further improves FER performance at the cost of computation complexity with the $T$ increases, the PC-SCLF decoder with $T=15$ still has a significantly lower computation complexity and a better FER performance than CA-SCL decoder with $L=8$. Therefore, our PC-DSCLF decoder with low complexity and storage space can achieve the error-correction performance of CA-SCL decoder with a large complexity and storage space, which means PC-DSCLF decoder is an effective low-complexity and high-performance polar decoder. 

Based on the above results, we can get: (1) The simplified flip metric designed by the PC-DSCLF reduces the logarithmic and exponential operations in the D-SCLF's flip metric without sacrificing FER performance and CNP performance. This makes PC-DSCLF decoding more friendly in hardware implementation. (2) Compared to the D-SCLF, our PC-DSCLF with multi-PC-aided scheme greatly reduces its average computation complexity (energy) without FER performance loss, which means our decoder has lower average latency and energy consumption. (3) our PC-DSCLF decoder with low complexity and storage space can achieve the error-correction performance of CA-SCL decoder with a large complexity and storage space. Therefore, PC-DSCLF decoder is an effective low-complexity and high-performance polar decoder.


\section{Conclusions}

In this work, we designed a PC-DSCLF decoding algorithm with a simplified flip metric. On the one hand, PC-DSCLF decoding designed a simplified flip metric, and it was proved by simulations that this simplification hardly affects the error-correction performance. On the other hand, PC-DSCLF decoding proposed the first multi-PC scheme with the dynamic characteristic and introduced it into list flip decoding. The dynamic characteristic gives PC-DSCLF decoding an excellent high-order error correction capability that can reduce the number of redundant decoding attempts. The multi-PC scheme allows PC-DSCLF decoding to locate errors faster and perform early termination more efficiently than the state-of-the-art list flip decoding. Simulation results show that our decoding greatly reduces the computation complexity of the state-of-the-art list flip decoder without loss of error-correction performance. Meanwhile, we also proved through simulations that PC-DSCLF decoding with low complexity and storage space can achieve the error-correction performance of a regular list decoder with a large complexity and storage space. Therefore, PC-DSCLF decoder is an effective low-complexity and high-performance polar decoder.


% \begin{figure}[!t]
% \centering
% \includegraphics[width=2.5in]{myfigure} 
% =>
% \caption{Simulation Results}
% =>
% \label{fig_sim}
% \end{figure}

% %需用subfig.sty包  如果用subfigure.sty包，那么用 \subfigure 代替 \subfloat
% %IEEE一般情况是在主标题描述清楚所有
% \begin{figure*}[!t]
% \centerline{\subfloat[Case I]\includegraphics[width=2.5in]{subfigcase1}%
% \label{fig_first_case}}
% \hfil %保持间距
% \subfloat[Case II]{\includegraphics[width=2.5in]{subfigcase2}%
% \label{fig_second_case}}}
% \caption{Simulation results}
% \label{fig_sim} %总的名字需要在caption之后
% \end{figure*}

% label 在caption之后
% 表格一般使用 \footnotesize
% \begin{table}[!t]
% % increase table row spacing, adjust to taste
% \renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
% \caption{An Example of a Table}
% \label{table_example}
% \centering
% % Some packages, such as MDW tools, offer better commands for making tables
% % than the plain LaTeX2e tabular whiIEEEtranch is used here.
% \begin{tabular}{|c||c|}
% \hline
% One & Two\\
% \hline
% Three & Four\\
% \hline
% \end{tabular}
% \end{table}



%% use section* for acknowledgement
%\section*{Acknowledgment}
%
%This work was supported by the Fundamental Research Funds for the Central Universities.


% Can use something like this to put references on a page by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi



% trigger a \newpage just before the given reference number - used to balance the columns on the last page adjust value as needed - may need to be readjusted if the document is modified later 
% \IEEEtriggeratref{8}
%  The "triggered" command can be changed if desired:  \IEEEtriggercmd{\enlargethispage{-5in}}
%应该是参考文献字号



% references section

% can use a bibliography generated by BibTeX as a .bbl file BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
\bibliographystyle{IEEEtranTCOM}
% argument is your BibTeX string definitions and bibliography database(s)
\bibliography{IEEEabrv,reference.bib}

% <OR> manually copy in the resultant .bbl file set second argument of \begin to the number of references (used to reserve space for the reference number labels box)



% \begin{thebibliography}{1}

% \bibitem{IEEEhowto:kopka}
% H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
%   0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.

% \end{thebibliography}

% biography section

% If you have an EPS/PDF photo (graphicx package needed) extra braces are needed around the contents of the optional argument to biography to prevent the LaTeX parser from getting confused when it sees the complicated \includegraphics command within an optional argument. (You could create your own custom macro containing the \includegraphics command to make things simpler here.)
% \begin{biography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:

% You can push biographies down or up by placing a \vfill before or after them. The appropriate use of \vfill depends on what kind of text is on the last page and whether or not the columns are being equalized.

% \vfill

% Can be used to pull up biographies so that the bottom of the last one is flush with the other column.
% \enlargethispage{-5in}



% that's all folks
\end{document}


