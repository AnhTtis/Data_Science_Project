\section{Conclusion}

We propose Edit-A-Video, the video editing framework only given the single $<$text, video$>$ pair and pretrained text-to-image (TTI) model.
Edit-A-Video inflates the TTI model and tunes the model on a given source video for the temporal modeling, and enables editing the video with target prompt by the inversion and attention map injection.
We also suggest the temporal-consistent blending method which ensures content preservation and temporal coherence by making use of the temporal modeling capability in the model.
Our framework achieves superior performance to the baselines in various aspects.
We anticipate that this method will provide a simple and intuitive video editing method.