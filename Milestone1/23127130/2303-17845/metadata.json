{
    "arxiv_id": "2303.17845",
    "paper_title": "WSense: A Robust Feature Learning Module for Lightweight Human Activity Recognition",
    "authors": [
        "Ayokunle Olalekan Ige",
        "Mohd Halim Mohd Noor"
    ],
    "submission_date": "2023-03-31",
    "revised_dates": [
        "2023-04-03"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "In recent times, various modules such as squeeze-and-excitation, and others have been proposed to improve the quality of features learned from wearable sensor signals. However, these modules often cause the number of parameters to be large, which is not suitable for building lightweight human activity recognition models which can be easily deployed on end devices. In this research, we propose a feature learning module, termed WSense, which uses two 1D CNN and global max pooling layers to extract similar quality features from wearable sensor data while ignoring the difference in activity recognition models caused by the size of the sliding window. Experiments were carried out using CNN and ConvLSTM feature learning pipelines on a dataset obtained with a single accelerometer (WISDM) and another obtained using the fusion of accelerometers, gyroscopes, and magnetometers (PAMAP2) under various sliding window sizes. A total of nine hundred sixty (960) experiments were conducted to validate the WSense module against baselines and existing methods on the two datasets. The results showed that the WSense module aided pipelines in learning similar quality features and outperformed the baselines and existing models with a minimal and uniform model size across all sliding window segmentations. The code is available at https://github.com/AOige/WSense.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.17845v1"
    ],
    "publication_venue": null
}