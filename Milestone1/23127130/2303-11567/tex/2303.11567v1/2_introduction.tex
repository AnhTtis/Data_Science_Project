\section{Introduction}
Object detection~\cite{fasterrcnn, ssd, yolo, fcos} is a fundamental computer vision task, aiming to localize and recognize the objects of predefined categories in an image. Owing to the rapid development of deep neural networks (DNN)~\cite{vgg,resnet,densenet,mobilenets,googlenet1,googlenet2,googlenet3}, the detection performance has been significantly improved in the past decade. During the evolution of object detectors, one important trend is to remove the hand-crafted components to achieve end-to-end detection.

One hand-crafted component in object detection is the design of training samples. For decades, anchor boxes have been dominantly used in modern object detectors such as Faster RCNN~\cite{fasterrcnn}, SSD~\cite{ssd} and RetinaNet~\cite{focalloss}. However, the performance of anchor-based detectors is sensitive to the shape and size of anchor boxes. To mitigate this issue, anchor-free~\cite{fcos,foveabox} and query-based~\cite{detr,deformdetr,dynamicdetr,conditionaldetr} detectors have been proposed to replace anchor boxes by anchor points and learnable positional queries, respectively.

Another hand-crafted component is non-maximum suppression (NMS) to remove duplicated predictions. The necessity of NMS comes from the one-to-many (o2m) label assignment~\cite{primesample,ota,atss,paa,gfocal,gfocalv2}, which assigns multiple positive samples to each GT object during the training process. This can result in duplicated predictions in inference and impede the detection performance. Since NMS has hyper-parameters to tune and introduces additional cost, NMS-free end-to-end object detection is highly desired.

\begin{figure}[tbp]
    \centering
    \includegraphics[width=0.4\textwidth]{fig_in_intro.pdf}
    \caption{The positive and negative weights of different anchors (A, B, C and D) in the classification loss during early and later training stages. Each anchor has a positive loss weight $t$ (in orange color) and a negative loss weight $1-t$ (in blue color). In our method,  A is a fully positive anchor, D is a fully negative anchor, and B and C are ambiguous anchors. One can see that for o2o and o2m label assignment schemes, the weights for all anchors are fixed during the training process, while for our o2f scheme, the weights for ambiguous anchors are dynamically adjusted.}
    \label{fig_in_intro}
    \vspace{-3mm}
\end{figure}

With a transformer architecture, DETR~\cite{detr} achieves competitive end-to-end detection performance. Subsequent studies~\cite{poto,onenet} find that the one-to-one (o2o) label assignment in DETR plays a key role for its success. Consequently, the o2o strategy has been introduced in fully convolutional network (FCN) based dense detectors for lightweight end-to-end detection. However, o2o can impede the training efficiency due to the limited number of positive samples. This issue becomes severe in dense detectors, which usually have more than 10k anchors in an image. What’s more, two semantically similar anchors can be adversely defined as positive and negative anchors, respectively. Such a ‘label conflicts’ problem further decreases the discrimination of feature representation. As a result, the performance of end-to-end dense detectors still lags behind the ones with NMS. Recent studies~\cite{dndetr,groupdetr,hybriddetr} on DETR try to overcome this shortcoming of o2o scheme by introducing independent query groups to increase the number of positive samples. The independency between different query groups is ensured by the self-attention computed in the decoder, which is however infeasible for FCN-based detectors.

In this paper, we aim to develop an efficient FCN-based dense detector, which is NMS-free yet end-to-end trainable. We observe that it is inappropriate to set the ambiguous anchors that are semantically similar to the positive sample as fully negative ones in o2o. Instead, they can be used to compute both positive and negative losses during training, without influencing the end-to-end capacity if the loss weights are carefully designed. Based on the above observation, we propose to assign dynamic soft classification labels for those ambiguous anchors. As shown in Fig.~\ref{fig_in_intro}, unlike o2o which sets an ambiguous anchor (anchor B or C) as a fully negative sample, we label each ambiguous anchor as partially positive and partially negative. The degrees of positive and negative labels are adaptively adjusted during training to keep a good balance between ‘representation learning’ and ‘duplicated prediction removal’. In particular, we begin with a large positive degree and a small negative degree in the early training stage so that the network can learn  the feature representation ability more efficiently, while in the later training stage, we gradually increase the negative degrees of ambiguous anchors to supervise the network learning to remove duplicated predictions. 
We name our method as a one-to-few (o2f) label assignment since one object can have a few soft anchors. We instantiate the o2f LA into dense detector FCOS, and our experiments on COCO~\cite{coco} and CrowHuman~\cite{crowdhuman} demonstrate that it achieves on-par or even better performance than the detectors with NMS.
