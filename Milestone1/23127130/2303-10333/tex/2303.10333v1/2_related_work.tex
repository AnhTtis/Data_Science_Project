\section{RELATED WORK}

\begin{figure*}[htbp] %H为当前位置，!htb为忽略美学标准，htbp为浮动图形
\centering %图片居中
\vspace{-4mm}
\includegraphics[width=0.87\textwidth]{figures/framework_v10.pdf} %插入图片，[]中设置图片大小，{}中是图片文件名
% 我们提出的masked-region perception多任务自我监督学习框架(MP-SSL)从全局与局部两个维度学习医学图像的通用表征。MP-SSL采用了一个两级的掩蔽方式，为了更好的对表征局部空间。以2D图像的形式来展示，被掩蔽后的图像经过两次编码，得到两组高水平特征。其中lcl代表对比学习损失，提升模型对不同样本特征全局的区分程度。lmr为掩蔽区域感知损失，共有三个损失函数，lmrnum，lmrpos，lmrconsis，分别代表掩蔽区域数量的损失，位置的损失和一致性损失。最后，通过解码手动选择的局部特征，重构对应的掩蔽区域。lrl表示重构损失，根据上下文信息重构空间中缺失区域，可以学习到丰富的医学图像解剖信息。
\caption{Overviwe of the HybridMIM pre-training framework. Input 3D medical images (demonstrated in 2D form) are randomly masked with a two-level masking strategy, then fed to the encoder twice to obtain two sets of feature representations. We use patch-masking perception, partial region reconstructions, and  dropout-based contrastive learning as proxy tasks to learn contextual representations of input images. } %最终文档中希望显示的图片标题
\label{Fig.main2} %用于文内引用的标签
\vspace{-3mm}
\end{figure*}
%  Here, $\mathcal{L}_{cl}$ represents the contrast learning loss, which enhances the model to distinguish different sample features globally. $\mathcal{L}_{rp}$ is the masked-region perception loss, and there are three loss functions, $\mathcal{L}_{rp}^{num}$, $\mathcal{L}_{rp}^{loc}$, and $\mathcal{L}_{rp}^{consis}$, which represent the loss of masked region number, loss of position, and loss of consistency, respectively. Finally, the corresponding masked regions are reconstructed by decoding the manually selected local features. $\mathcal{L}_{lr}$ represents the local reconstruction loss, which reconstructs the missing regions in the space according to the contextual information, and can learn rich anatomical information of medical images.

%\subsection{Deep-learning architecture for segmentation}
% 
%In recent years, convolutional neural networks (CNNs)\cite{o2015introduction} have achieved promising successes in medical image segmentation. The main stream models are built upon the encoder-decoder architecture~\cite{ronneberger2015u} with skip connections, including UNet~\cite{ronneberger2015u}, SegResNet~\cite{myronenko20183d}, MAML\cite{zhang2021modality}, etc. 
% 其中，UNet首次提出了U-shape网络架构，在处理高维度与高分辨率的医学图像中优势显著，为后面一系列工作奠定了基础。
% Among them, UNet has proposed the first U-shape network architecture, which is a significant advantage in processing high-dimensional and high-resolution medical images, laying the foundation for a series of later works.
% % Segresnet在UNet的基础上，加入残差连接，并添加了额外的解码路径重构原图像，提升了网络的特征编码-解码能力。
% SegResNet improves the feature encoding-decoding capability of the network by adding residual connections to UNet and adding additional decoding paths to reconstruct the original image.
% % MAML结合CNN与注意力机制，针对医学图像的多模态问题提出了一个高效的多模态特征融合方式。
% And MAML combines convolutional neural network
%  and attention mechanism to propose an efficient feature fusion approach for the multi-modal problem of medical images.
% % 但这些以卷积神经网络为主要backbone的架构通常是局部性的，导致无法很好的建模全局特征。
% However, these architectures with convolutional neural networks as the main backbone are usually localized, resulting in the inability to model global features well.
% %% Transformer部分：
% Recent works also explore transformer\cite{vaswani2017attention, zhou2021nnformer,xu2021levit,xie2021cotr,valanarasu2021medical} to model long-range dependencies\cite{raghu2021vision} within images. For instance, UNETR~\cite{hatamizadeh2022unetr} uses the ViT\cite{dosovitskiy2020image} transformer as the encoder to learn contextual information, which is merged with the CNN-based decoder via skip connections at multiple resolutions. 
% %% 然而由于全局 self attention 模块计算复杂度高，ViT transformer 结构只有单一的patch size，导致其不能提取图像的多尺度信息。它可以成功的应用在自然图像但不能较好的处理更高分辨率与更高维度的医学图像数据。
% However, due to the high computational complexity of the global self-attention module, the ViT transformer structure has only a single patch size, resulting in its inability to extract multi-scale information from images. It can be successfully applied to natural images but cannot handle higher resolution and higher dimensional medical image data better.
% %% 为了克服ViT transformer结构的限制，SwinTransformer基于滑动窗口的方式设计了一种特殊的局部注意力。这种设计相比全局self attention 计算复杂度大大降低，因此可以用来提取多尺度特征。在医学图像处理领域，SwinUNETR利用SwinTransformer作为encoder，卷积神经网络（CNN）作为decoder，在多个医学图像分割任务中实现了sota结果。
% To overcome the limitations of ViT\cite{dosovitskiy2020image} transformer structure, SwinTransformer\cite{liu2021swin} designs a special local attention based on a shifted window approach. This design reduces the computational complexity significantly compared to global self attention, and thus can be used to extract multi-scale features. In the field of medical image processing, SwinUNETR\cite{hatamizadeh2022swin,tang2022self} utilizes SwinTransformer\cite{liu2021swin} as encoder and convolutional neural network as decoder to achieve SOTA results in several medical image segmentation tasks.

%Self-supervised learning (SSL) for image analysis can be roughly divided into three categories: tailored proxy tasks, contrastive learning, and masked image modeling. In the section, we will briefly review those relevant works. 

\subsection{SSL via Tailored Proxy Tasks}
%\subsection{Self-Supervised Learning via Tailored Proxy Tasks}
%% 该类方法通常通过设计pretext 任务来构造自监督学习标签。在自然图像处理领域中，有几个常用的pretext任务。图像修补学习视觉表征通过预测原始的图像patches。解决拼图游戏通过将图像patches随机打乱，并利用卷积神经网络进行还原，来学习图像的结构信息，此外，还有的方法通过将图像随机旋转，并使用网络预测旋转角度来增强对图像的理解能力。
This category of methods usually constructs self-supervised learning labels by designing pretext tasks. There are several commonly used pretext tasks in natural image processing. Image inpainting is adopted to learn visual representations by predicting the original image region~\cite{pathak2016context}. Jigsaw puzzles solving~\cite{noroozi2016unsupervised} learns structural information about images by randomly disrupting image patches and restoring them. 
%%
In addition, random rotation estimation~\cite{gidaris2018unsupervised} enhances the understanding of images by randomly rotating images and using the network to predict the rotation angles.

% 在医学图像处理领域则包含更多样的pretext任务设计。
%% Models Genesis 利用多种方式扰乱原图像中部分像素值，例如distortion-based 方法打乱像素值 或 painting-based 方法屏蔽像素值。将被破坏的图像输入到encoder-decoder结构的网络进行还原，使网络学会重构初始正确的像素。这种设计可以使网络学习到医学图像数据的解剖特征。
One typical work using tailored proxy tasks in the medical imaging is Models Genesis\cite{zhou2021models}. 
%%
%such as distortion-based methods to disrupt pixel values or painting-based methods to mask pixel values. 
It uses a variety of ways, such as distortion or painting-based methods, to disrupt pixels in the original image\cite{gidaris2018unsupervised,pathak2016context,chen2019self}, and then utilize a network of encoder-decoder structure for restoration. 
This method  mainly focuses on the prediction of local information.
%, and does not consider global factors.
%% TransVW 定义医学图像中不同的区域并赋予不同的类别标签，称为语义视觉词。之后，TransVW随机将语义视觉词区域进行掩蔽，并通过encoder-decoder网络重建该区域并预测所属类别。
TransVW\cite{haghighi2021transferable} classifies different image regions as semantic visual words, and reconstructs randomly masked visual word regions while predicting the region's category.
%%
The method achieves improved performance on downstream tasks, while it needs to find semantic visual words first, thus leading to more pre-training burden.
%% 然而，该方法需要首先寻找语义视觉词，因此导致预训练步骤较多。
%%
Yucheng Tang \textit{et al.} \cite{tang2022self} pre-trained swin transformers via three proxy tasks: inpainting, rotation and contrastive learning. 
%%
Our method is built on the masked image modeling strategy, and constructs three proxy tasks at different levels, including predicting the partial masked region at pixel level, estimating the masking distribution at region level, and dropout-based contrastive learning at sample level.

\subsection{SSL via Contrastive Learning}
%\subsection{Self-Supervised Learning via Contrastive Learning}
%% 对比学习也是自监督学习中常用的方法，其核心在于利用不同的方式构建正样本与负样本，学习不同样本之间的关系特征。
%% 常见的构建正样本与负样本的方式为数据增强-将一个批次内相同样本经过不同的数据增强后作为正样本对，批次内不同样本作为负样本对。
%% 此外，SimCSE方法使用dropout构建正负样本。该方法首先将网络中的dropout层激活，然后将一个批量的数据前向计算两次，得到两组特征，因此来自相同样本的特征作为正样本，不同样本的特征作为负样本。该方法实现较好的性能提升且易于实现。
Contrastive learning is also a common approach in self-supervised learning, which centers on learning the relational features between samples by using different ways to construct positive and negative sample pairs.
%%
A common way to construct sample pairs is data augmentation, in which one sample is augmented to form positive sample pairs, and different samples within a mini-batch are taken as negative sample pairs.
%%
%% 在医学图像分析领域中，Yucheng Tang\textit{et al.} 把基于数据增强的对比学习作为子任务之一，将来自相同子体积的增强样本作为正样本，不同子体积的样本作为负样本，并通过大量实验验证了其有效性。
In medical imaging, Yucheng Tang \textit{et al.} \cite{tang2022self} used contrast learning based on such data augmentation as one of the tailored proxy tasks, and had verified its effectiveness through numerous experiments.

% Krishna Chaitanya \textit{et al.}
%%
Additionally, in the NLP filed, the SimCSE method~\cite{gao2021simcse} proposes to use dropout to construct positive and negative samples. The method adds a dropout layer in the network and feed forward an input sample twice to obtain two sets of features. Features from the same sample are taken as positive samples, while features from different samples form negative samples. This scheme is easy to implement, and achieves good performance. 
%%
We utilize SimCSE scheme to construct our constrative learning task. 


\subsection{SSL via Masked Image Modeling}
%\subsection{Self-Supervised Learning via Masked Image Modeling}
%%% 此外，越来越多的工作正在探索基于屏蔽式图像建模的自监督学习任务使模型学习到全局的图像理解能力。例如Masked Autoencoders (MAE)在输入时丢弃掉被掩蔽的图像tokens，之后通过非对称的 transformer encoder-decoder 重构masked 区域，以此得到模型对于图像的多样化理解与表征。
More recently, a growing body of works is exploring to apply the idea of masked language modeling, which is successful in the NLP filed, to natural imaging. 
%%
%to enable models to learn global image understanding capabilities. 
%%
Masked Autoencoders (MAE) \cite{he2022masked}, built on ViT architecture, masks random image patches and reconstructs the missing pixels by an asymmetric transformer autoencoder.
%%
To accelerate the pretraining speed, MAE discard masked tokens, which makes it less compatible with multi-scale processing expected in medical imaging. 
%%
%to obtain a diverse understanding and representation of the image by the model.
%% 同时，与MAE方法类似，SimMIM方法通过保留被掩蔽的图像tokens，使其可以应用于swin transformer，resnet等多尺度编码器。
Meanwhile, the SimMIM~\cite{xie2022simmim} achieves masked image modeling by utilizing multi-scale encoders such as Swin transformer and ResNet. SimMIM preserves the masked image tokens in the computation, and utilizes one convolutional layer as the decoder to increase timing performance, which may not handle well high-dimensional and high-resolution medical images.

% %% 由于MAE丢弃 masked tokens，采用非对称的 transformer encoder-decoder 加速提取图像特征，因此并不适用于通常处理医学图像数据的多尺度模型。
% Since MAE discards masked tokens and uses an asymmetric transformer encoder-decoder to accelerate the extraction of image features, it is not suitable for multi-scale models that usually deal with medical image data.
% %% SimMIM方法通过保留 masked tokens 的方式进行预训练，适配了SwinTransformer, ResNet等多尺度编码器。但是由于其编码的耗时长，因此选择简化解码器来做到性能权衡。与MAE方法使用8层Transformer 作为解码器相比，SimMIM使用了1层CNN结构作为解码器，但是简单的decoder并不能很好的处理高维和高分辨率的医学图像数据。
% The SimMIM\cite{xie2022simmim} method is pre-trained by retaining masked tokens and adapts multi-scale encoders such as SwinTransformer\cite{liu2021swin}, ResNet\cite{he2016deep}, etc. However, due to the long time consumption of its encoding, a simplified decoder is chosen to achieve the performance tradeoff. Compared with the MAE method that uses 8-layer Transformer as decoder, SimMIM uses 1-layer convolutional neural network as decoder, but the simple decoder is not able to handle high-dimensional and high-resolution medical image data well.

%%% 与在自然图像领域的自监督学习方法相比，UNetFormer 将掩蔽式图像建模的思想迁移到医学图像领域，随机掩蔽3D输入医学图像并使用encoder-decoder结构进行重建。它使用3D SwinTransformer结构作为编码器，多尺度的CNN或SwinTransformer结构作为解码器。然而，其结构是固定的，且在训练过程中需要极大的内存。
UNetFormer~\cite{wang2022unetformer} directly applies the idea of masked image modeling in medical imaging. It uses a 3D SwinTransformer structure as the encoder and a multi-scale CNN or SwinTransformer structure as the decoder, to reconstruct the randomly masked sub-volumes. However, its structure is fixed and requires an enormous amount of memory during the training process.
%%
Our work extends the idea of masked image modeling to consider higher-level constraint on the semantic anatomical information. What's more, we accelerate the pre-training speed by using partial region prediction. 