\section{Results}

% 这个部分展示了我们结果的性能优势，首先，我们通过多组对照试验确定了最优的架构参数，然后我们基于UNet与SwinUNETR预训练了通用模型与任务特定模型，在结果表中，*表示通用模型，否则为任务特定模型。同时，我们使用了多种来源的数据，涉及了不同模态，不同器官和不同的分割目标来验证HybridMIM的鲁棒性。此外，我们还验证了不同有标签数据比例下，HybridMIM依然能够有较高的性能优势。最后，我们还进行了消融实验，验证了HybridMIM中不同模块的有效性。
This section demonstrates the significance of our proposed HybridMIM method. 
%%
First, we make comparison with the current state-of-the-art approaches from four aspects: downstream segmentation performance (quantitative and qualitative), annotation cost reduction, and pre-training speed. 
%%
We then conduct ablation experiments to explain how to determine the optimal architectural parameters, and illustrate the contribution of each component to the performance of HybridMIM.

%This section demonstrates the performance advantage of our results. First, we determine the optimal architectural parameters by multiple controlled trials, and then we pre-train the generic and task-specific models based on UNet with SwinUNETR. In the result table, * indicates the generic model, otherwise the task-specific model. Also, we use data from multiple sources involving different modalities, organs, and segmentation targets to validate the robustness of HybridMIM. In addition, we verify that HybridMIM can still have high-performance advantages with different scales of labeled data. Finally, we also conduct ablation experiments to validate the effectiveness of different modules in HybridMIM.

\input{tables/msd_table.tex}


\subsection{Quantitative Comparison to Previous Methods} 
%
\textbf{BTCV multi-organ segmentation.} The multi-organ segmentation results are listed in Table \ref{tab:btcv_segmentation}, in which
the first, second, and third best dice scores are marked in red, blue, and green colors, respectively. 
%%
Among the comparative methods, we can see that those with self-supervised pre-training generally achieve averagely better results than those fully supervised methods. 
%%
TransVW obtains the best average Dice of 82.27\%,  
%%
while for UNetFormer, its generic pre-trained model presents an average Dice of 82.44\%, outperforming the task-specific pre-trained model UNetFormer* by 0.26\%. 

% 与其他对比方法相比，我们的基于UNet和SwinTransformer架构的方法均取得了有竞争力的结果。红色，蓝色，绿色分别代表最高的dice得分，第二高的dice得分与第三高的dice得分。可以清楚的发现，基于SwinUNETR架构的任务特定模型Swin(HybridMIM)在7项指标中均位于前三名，实现了82.41%的Dice平均值。而基于UNet架构的通用预训练模型UNet*(HybridMIM)，在4项指标中位于前两名，相比于其他方法实现了最高的平均Dice，83.00。在BTCV多器官分割任务中，通用预训练模型的性能均高于任务特定预训练模型。
In comparison, our methods on both UNet and SwinTransformer architectures outperform most SOTA methods, and the generic pre-trained models get better performance than their task-specific pre-trained counterparts.  
%%
Specifically, the generic pre-trained model HybridMIM(UNet) presents the highest average Dice of 83.00\%,
%We can find that the task-specific model Swin (HybridMIM) based on SwinUNETR architecture is in the top three in all seven metrics, achieving an 82.41\% Dice average. 
% 拿性能最好的UNet*(HybridMIM)来说，它实现了最高的83.0%的平均Dice，比表现较好的同样在通用数据集上预训练的UNetFormer*模型提升了0.56%。并且UNet*(HybridMIM)在13个分割目标中有9个目标的分割结果均优于UNetFormer*。
which is 0.56\% better than the best SOTA model UNetFormer, and outperforms it in 9 out of 13 segmentation targets.
% 并且基于SwinUNETR架构的任务特定预训练模型在Lag器官上分割效果明显优于其他对比方法，达到了68.47%的dice值，比第二名UNETR高出1.82%。而基于UNet架构的任务特定预训练模型在Gall器官上分割效果显著，达到了 the dice of 78.67%，而第二名UNetFormer与第三名Segresnet方法的dice均没有超过76%。
%
Furthermore, the task-specific pre-trained model HybridMIM*(Swin) segmented significantly better than the other methods on the Lag organ, reaching the Dice of 68.47\%, which is 1.82\% higher than the second place UNETR, while HybridMIM*(UNet) reports a significantly better result on the Gall organ, reaching a Dice of 78.67\%. 
%In comparison, neither the second-place UNetFormer nor the third-place Segresnet method had more than 76\% Dice.

% 肝脏与肝脏肿瘤分割结果被展示在表3的左侧。加粗字体表示最优的指标。可以清晰的看到，我们提出的基于UNet架构的任务特定预训练模型UNet(HybridMIM)在肝脏的分割上有最好的Dice of 96.35%，比第二名TransVW提升了0.68%。同时其在肝脏肿瘤的分割中达到了Dice of 52.38%，仅次于ModelGen方法的52.53%。此外，UNet(HybridMIM)也实现了两个分割指标的最好的平均Dice，为74.36，比第二名TransVW方法提升了0.48%。
\textbf{Liver and liver tmuor segmentation.} As shown in Table \ref{tab:msd_segmentation}, 
%The bolded font indicates the best metrics.
our task-specific pre-trained model HybridMIM*(UNet) achieves the best average Dice of 74.36\%, with an improvement of 0.48\% over the second-place TransVW method.
Furthermore, it reports the best Dice of 96.35\% for the segmentation of the liver, which is 0.68\% better than the second place TransVW; and obtains a Dice of 52.38\% in the segmentation of liver tumors, only slightly lower than the second place ModelGen method with 52.53\%. 
% 对于HD95分割指标，基于UNet(HybridMIM)在肝脏的分割中位于第二名，HD95结果为0.59，略高于UNetFormer方法的0.52。在肝脏肿瘤的分割中为第三名，HD95为19.98。
For the HD95 segmentation metric, the HybridMIM*(UNet) gets an average HD95 of 10.28, ranked in the third place.
%is in second place in the segmentation of the liver with an HD95 result of 0.59, slightly higher than the UNetFormer method of 0.52. It was in third place in the segmentation of liver tumors with an HD95 result of 19.98, and the average HD95 was also in third place.
% 同时，Swin(HybridMIM)总体来说在HD95指标上表现更好。其在肝脏肿瘤的分割上拥有最好的HD95，为15.21，并且其在肝脏与肝脏肿瘤两个分割目标上实现了最好的的平均HD95，为7.95，比第二名ModelGen方法降低了1.8。相比于没有经过预训练SwinUNETR方法，Swin(MP-SSL)有更加明显的提升。其在肝脏与肝脏肿瘤的平均Dice得分达到了72.82%，比SwinUNETR方法提升了2.17%。
%Meanwhile, the Swin(HybridMIM) performed better overall on HD95 metrics. 
%It achieves the best HD95 of 15.21 for liver tumor segmentation and the best average HD95 of 7.95 for liver and liver tumor segmentation targets, which is 1.8 lower than the ModelGen method in second place. 
In addition, compared to the SwinUNETR method without pre-training, both HybridMIM*(Swin) and HybridMIM(Swin) which employ SwinUNETR as the underlying architecture, have more significant improvements in all the metrics. 
%%
%HybridMIM*(Swin) and HybridMIM(Swin) get an average Dice score of 72.82\% and 73.16\%, 2.69\% and 3.03\% higher than the SwinUNETR method, respectively.



% 脾脏的分割结果被展示在表3的右侧。可以看到，基于UNet与SwinUNETR架构的HybridMIM均表现出了优秀的性能，无论是在Dice还是在HD95上。基于UNet*(HybridMIM)获得了 state-of-the-art 的Dice与HD95，分别为96.05与0.20，在Dice得分上相比于同样表现较好的对比方法TransVW提升了0.50%，比基于Transformer架构的UNETR提升了2.1%。此外，Swin*(HybridMIM)实现了95.97%的Dice与0.20的HD95，仅次于UNet(HybridMIM)。
\textbf{Spleen segmentation.} The spleen segmentation results are listed on the right side of Table~\ref{tab:msd_segmentation}.
%%
The HybridMIM based on both UNet and SwinUNETR architectures presented improved performance, both on Dice and HD95. 
%%
HybridMIM(UNet) obtains Dice and HD95 with 96.05 and 0.20, respectively, improving the Dice score by 0.50\% compared to TransVW, and by 2.1\% compared to UNETR. 
%%
%In addition, Swin*(HybridMIM) achieves 95.97\% Dice and 0.20 HD95, second only to UNet (HybridMIM).
% 值得注意的是，SwinUNETR方法的Dice得分为94.61，而我们提出的通用预训练模型Swin* (HybridMIM)方法则达到了95.97的Dice得分，实现了1.36%的提升。通过我们提出的Hybrid的多层次自监督学习方式首先学习丰富的3D脾脏数据的空间解剖学特征，然后通过迁移学习在下游分割任务中训练，可以明显的提升原模型的效果。
Among the fully supervised methods, SwinUNETR gets the best Dice score of 94.61, and HD 0.25.
%%
Our generic pre-trained model HybridMIM(Swin) further improves SwinUNETR to achieve a Dice score of 95.97, realizing an increase of 1.36\%.
%%
%The original model can significantly improve by learning the spatial anatomical features of the rich 3D spleen data through our proposed Hybrid's multi-level self-supervised learning approach and then training it in the downstream segmentation task through transfer learning.

\begin{figure*}[tbp] %H为当前位置，!htb为忽略美学标准，htbp为浮动图形
\vspace{-4mm}
\centering %图片居中
\includegraphics[width=\textwidth]{figures/visual_1.pdf} %插入图片，[]中设置图片大小，{}中是图片文件名
% Ours为Swin*(HybridMIM)方法，三行视觉比较结果分别为BraTS2020，Liver和BTCV。我们提出的方法更够更好的分割细微的病灶(第一行)，并且分割的完整度更高(第二行，第三行)。
\vspace{-3mm}
\caption{Qualitative visualizations of the proposed HybridMIM and baseline methods. "Ours" is the HybridMIM(Swin) method. The three rows of visual comparison results are from BraTS2020, Liver, and BTCV datasets. Our proposed method is better for segmenting tiny lesions (first row) and has higher segmentation integrity (second row, third row).} %最终文档中希望显示的图片标题
\label{fig:visual} %用于文内引用的标签
\end{figure*}

% 基于BraTS2020数据的脑胶质瘤的分割结果被展示在表4中。我们使用Dice来评测不同方法的性能。其中WT，TC，ET分别代表了全部肿瘤，肿瘤核心，增强肿瘤，Avg代表3个分割目标的Dice均值。
\textbf{Brain tumor segmentation.} The segmentation results of gliomas for BraTS2020 dataset are summarized in Table \ref{tab:brats_segmentation}. 
%We use Dice to evaluate the performance of different methods. 
WT, TC, ET represent whole tumor region, tumor core, and enhanced tumor region, respectively, and Avg is the Dice mean of the three segmentation targets.
% 我们提出的Swin（MP-SSL）方法实现了一个state-of-the-art的分割结果并且在WT，TC，ET三个分割目标中均达到了最优，分别为91.48%，86.88%，80.81%。相比于没有加入预训练的SwinUNETR方法，Swin（MP-SSL）在三个分割目标中均有较大幅度的提升，分别提升了1.4%，1.69%，0.8%，且三个分割目标的平均Dice得分比第二名TransVW方法提升了0.59%。
Our task-specific pre-trained model HybridMIM*(Swin) reports the best in WT, ET, and Avg with 91.48\%, 80.81\%, and 86.39\% respectively.
% 对比没有预训练的SwinUNETR方法，Swin(HybridMIM)与Swin* (HybridMIM)在三个分割目标上均有较大的提升，相比SwinUNETR，平均的Dice分别提升了1.3%, 1.24%。
%Compared with the SwinUNETR method without pre-training, Swin(HybridMIM) and Swin* (HybridMIM) show a considerable improvement in all three segmentation objectives, with an average Dice improvement of 1.3\%, 1.24\%, respectively, compared to SwinUNETR.
% 此外，UNet方法经过预训练后，也有了非常明显的提升，像表中最后一行展示的那样，UNet* (HybridMIM)方法在三个分割目标7分别实现了90.41%， 86.49%， 80.61%的Dice得分，相比于同样为UNet架构的ModelGen，三个分割指标的平均Dice提升了0.12%。以上的结果充分证明了MP-SSL方法良好的迁移学习和模型泛化能力。
%%In addition, the UNet method shows a significant improvement after pre-training, as shown in the last row of the table. 
As for UNet as the underlying architecture, the generic pre-trained model HybridMIM(UNet) achieves Dice scores of 90.41\%, 86.49\%, and 80.61\% for the three segmentation targets, respectively. Compared with ModelGen which is also built on UNet, we has the average Dice improved by 0.12\%. 
%%
%The above results fully demonstrate the good transfer learning and model generalization ability of the HybridMIM method.
It is also noted that on BraTS2020 dataset, the task-specific pre-trained mode gets better performance than the generic pre-trained mode. 

\input{tables/brats_table.tex}

\begin{figure}[htbp] %H为当前位置，!htb为忽略美学标准，htbp为浮动图形
\centering %图片居中
\vspace{-2mm}
\includegraphics[width=0.8\columnwidth]{figures/data_proportion.pdf} %插入图片，[]中设置图片大小，{}中是图片文件名
% 不同有标签数据规模对迁移学习结果的影响。我们分别选择了BraTS2020数据集中训练数据的10%，20%，40%，60%，80%，100%，验证在不同自监督学习方法的迁移学习能力。
\caption{Effect of different labeled data sizes on migration learning results. We selected 10\%, 20\%, 40\%, 60\%, 80\%, and 100\% of the training data in the BraTS2020 dataset to verify the transfer learning ability in different self-supervised learning methods.} %最终文档中希望显示的图片标题
\label{fig:data_proportion}
\vspace{-2mm}
%用于文内引用的标签
\end{figure}

\vspace{-2mm}
\subsection{Qualitative Comparison to Previous Methods}

% 为了更加直观的对比不同方法的分割结果，我们选择Swin*(HybirdMIM)和其他六个性能较好的对比方法在BraTS2020，Liver和BTCV数据集上进行视觉比较。
To compare the segmentation results of different methods more intuitively, we choose HybridMIM(Swin) and four comparative methods with better performance on the BraTS2020, Liver, and BTCV datasets for visual comparison.
% 像Fig. 6. 所展示的，Swin*(HybridMIM)能够提升病灶识别的准确度和完整度，并且针对细微的病灶依然可以高效的识别出来。模型经过HybridMIM方法预训练后，对局部区域的感知能力更强。
As shown in Figure~\ref{fig:visual}, HybridMIM(Swin) can improve the accuracy and completeness of lesion identification,  and still perceive subtle lesions. 
%The model is pre-trained by the HybridMIM method and better perceives localized regions.
%在Fig. 6. 的第一行，可以明显看出我们的方法相比于其他对比方法可以更加精准的分割微小的病灶。在Liver数据集中（Fig. 6.第二行），Swin*(HybridMIM)分割的完整性更高，没有出现像其他对比方法中的分割区域不连续的情况。同时，在BTCV数据集中的可视化结果中，我们的方法的分割结果包含的空洞更少，与其他对比方法相比，有较高的完整度。 
To be specific, for brain tumor in BraTS2020 (the first row of Figure~\ref{fig:visual}), our method segments the whole tumor with more accurate boundary, while the comparative methods all enlarge the tumor region. 
%%
In the liver segmentation task (the second row), we can clear see that the comparative methods generate obvious discontinuity in the segmented areas. Especially UNETR and SegResNet fail to detect the lower part of the liver, while the detected liver region from our method exhibits a clearly higher integrity. 
%%
For the BTCV dataset, TransVW, UNetFormer, SiwnUNETR generates small holes in stomach; ModelGen even is subjected to a much large missing detected part. In contrast, our segmentation result is more close to the ground truth.

\vspace{-2mm}
\subsection{Reduce Manual Labeling Efforts}
% 为了验证随着有标签数据比例逐渐降低，HybridMIM方法相比于其他自监督学习方法依然能保持良好的迁移学习能力，我们选择UNetFormer与TransVW作为对比方法，BraTS2020作为下游分割任务数据集，采用10%，20%，40%，60%，80%，100%的数据比例进行对比实验。
To evaluate the transfer learning ability with annotation scarcity challenge in medical imaging, we conduct the experiment of finetuning using a subset of BraTS2020 data.  
%%
Figure~\ref{fig:data_proportion} demonstrates the comparison results between HybridMIM(Swin), TransVW and UNetFormer. 
%%
%In order to verify that as the proportion of labeled data gradually decreases, the HybridMIM method still maintains good transfer learning ability. We choose UNetFormer and TransVW as the comparison methods and BraTS2020 as the downstream segmentation task dataset and use 10\%, 20\%, 40\%, 60\%, 80\%, and 100\% data proportions for comparison experiments.
% Fig. 4. 展示了减少有标签数据比例的实验结果。实验结果表明，当有标签数据比例降低至60%时，UNetFormer与TransVW方法在BraTS2020分割数据集上的迁移学习能力明显降低。而通过HybridMIM方法预训练的通用模型SwinUNETR在有标签数据比例为20%时依然能够实现0.825的平均Dice。
%Fig. \ref{data_proportion} shows the experimental results of reducing the proportion of labeled data.
It is clear that the generic pre-trained model HybridMIM(Swin) presents the best performance when using the same portion of labelled data.
%%
On employing 20\% labelled data, HybridMIM(Swin) already achieves an average Dice of 82.55\%, with 1.42\% and 3.17\% higher than UNetFormer and TransVW, respectively.  
%%
The Dice 85.24\% can be achieved by using HybridMIM(Swin) with 60\% labelled data, while UNetFormer requires about 80\% data and TransVW requires nearly 90\% data.
%%
%%On employing 40\% labelled data, HybridMIM(Swin) obtains an average Dice of ??, even higher than UNetFormer and TransVW employing 60\% labelled data. 
 
%The experimental results show that the transfer learning ability of UNetFormer and TransVW methods declined significantly on the BraTS2020 segmented dataset when reducing the proportion of labeled data to 60\%. In contrast, Swin, a generic model pre-trained by the HybridMIM method, still achieves an average Dice of 0.825 when the proportion of labeled data is 20\%.
% 此外，当有标签数据的比例相同时，Swin*(HybridMIM)较其他对比方法均有明显的性能优势。并且Swin*(HybridMIM)需要更少的数据便可以实现其他对比方法需要更多数据才能实现的性能，例如Swin*(HybridMIM)利用60%的有标签数据达到的迁移学习的性能，UNetFormer需要80%的数据，TransVW需要90%的数据。
%In addition, the HybridMIM(Swin) has a significant performance advantage over other comparison methods when the proportion of labeled data is the same. For example, the HybridMIM(Swin) achieves transfer learning performance with 60\% of labeled data, while UNetFormer requires 80\% of data and TransVW requires 90\% of data.

\vspace{-2mm}
\subsection{Pre-training Speed Comparison}
% 在自监督学习的过程中，由于无标签数据的数据量通常较大，因此训练速度是一个影响自监督学习方法的非常重要的因素。MP-SSL通过灵活的选择局部的一级区域重建来提升预训练速度。我们与其他的自监督学习方法进行对比，像图3(d)中展示的那样，我们分别列举了基于UNet与SwinTransformer架构的MP-SSL方法与其他自监督方法的时间消耗。
In self-supervised learning, the training speed is a notable factor to consider, because the unlabeled data scale is usually large especially in the generic training mode. 
%%
Figure~\ref{fig:pretraining_time} demonstrates the time consumption of those self-supervised methods in the pre-training stage on BraTS2020 dataset.
%%
%The HybridMIM enhances the pre-training speed by flexibly selecting local first-level region reconstruction. We compare with other self-supervised learning methods, as shown in Fig. \ref{pretraining_time}, and we enumerate the time consumption of the HybridMIM method based on UNet and SWinUNETR architectures, respectively, with other self-supervised methods.
% 值得注意的是，为了更加公平的进行对比，我们对比了每个自监督学习方法运行一步的平均时间消耗。其中一步内包含了前向传播，反向传播，更新参数，而不包含数据读取，数据预处理等时间消耗不确定的操作。
For a fair comparison, we count the average time of running one step for each method, which contains forward prediction, backward propagation, and updating network parameters, but does not include data reading and preprocessing operations.
%

\begin{figure}[htbp] %H为当前位置，!htb为忽略美学标准，htbp为浮动图形
\centering %图片居中
\vspace{-2mm}
\includegraphics[width=0.8\columnwidth]{figures/time-1.pdf} %插入图片，[]中设置图片大小，{}中是图片文件名
% 不同自监督学习方法预训练时间消耗对比。横坐标为不同自监督学习方法和不同重建大小的HybridMIM方法，128是全局重建大小，96是我们提出的局部重建方式。纵坐标表示预训练时每步的时间消耗。
\caption{Comparison of pre-training time consumption for different SSL methods. 
%The horizontal coordinates are different self-supervised learning methods. 
``Not partial'' denotes that the partial region prediction scheme is not used.
%, which spend more time in pre-training. The vertical coordinate indicates the time consumption of each step during pre-training.
} %最终文档中希望显示的图片标题
\label{fig:pretraining_time} %用于文内引用的标签
\vspace{-2mm}
\end{figure}

% 因此，由图3(d)可以看出，TransVW与ModelGenesis方法时间消耗最多。Swin（HybridMIM）当使用（128，128，128）作为重构区域时，由于其包含更多的损失函数，因此时间消耗高于类似架构的UNetFormer方法。但是随着我们将需要重构的局部区域降低为（96，96，96），预训练时间大幅度降低，相比于TransVW与ModelGen方法，预训练速度提升48%，相比于UNetFormer方法，预训练速度提升36%。
As Figure \ref{fig:pretraining_time} shows, the TransVW and ModelGenesis methods with the same underlying architecture have the highest time consumption, both of which are 1.42s per step. 
%%
HybridMIM(Swin), when predicting all the masked sub-volumes (denoted as ``Not partial''; see the fourth bar), has a higher time consumption than the UNetFormer method. 
%%
It is because that although they have the similar underlying architecture, HybridMIM(Swin) involves  more loss functions. 
%%
On the other hand, when we apply the partial region prediction, the pre-training time of HybridMIM(Swin) decreases dramatically, in which the speedup is 48\% with respect to TransVW and ModelGen, and 36\% against UNetFormer.


% 类似的，当使用UNet(HybridMIM)方法时，此时虽然由于所使用的UNet本身的结构特殊性，有更低时间消耗，但通过选择局部区域重建，训练速度依然有显著的提升。像表3d中展示的那样，当使用(128,128,128)大小作为重构尺寸时，每步时间消耗为1.03s，而当使用（96，96，96）大小时，每步时间消耗降低0.35s，相比TransVW和ModelGen方法，预训练速度快52%，相比UNetFormer方法，预训练速度加快40%。
When using the HybridMIM(UNet) method, there is a lower time consumption due to the structural simplicity of the UNet (see the rightmost two bars). 
%%
The partial region prediction enables it to get a significant improvement in the pre-training speed, with the time consumption per step reduced by 0.35s.
%%
HybridMIM(UNet) achieves a pre-training  speed of 0.68s, 52\% faster than the TransVW and ModelsGenesis methods, and 40\% faster than the UNetFormer method.
%%
% It is worthy noting that the pre-training speed is close to the training speed in the finetuning, despite that the later has fewer losses to compute.
% %%
% Therefore, our method can also have faster time performance in the finetuning stage.



\vspace{-2mm}
\subsection{Ablation Study}
\subsubsection{Selection of the optimal architecture settings}
%\vspace{-4m}
\begin{figure}[htbp] %H为当前位置，!htb为忽略美学标准，htbp为浮动图形
\vspace{-4mm}
\centering %图片居中
\includegraphics[width=0.48\textwidth]{figures/architecture_3.pdf} %插入图片，[]中设置图片大小，{}中是图片文件名
% 不同架构参数对迁移学习性能与预训练时间的影响。(a)中横坐标中a-b-c分别代表一级区域大小，二级区域大小，重建区域大小。纵坐标表示在BraTS2020数据集迁移学习能力（三个分割目标的Dice平均值）。(b)中右侧纵坐标表示预训练时每个step消耗的时间。我们首先通过(a)确定最优的一级区域与二级区域，32-16-128迁移学习效果最好。之后，我们通过(b)改变重建区域的大小，兼顾性能与时间选择最优的架构参数设置。
\caption{Effect of different architecture parameters on transfer learning performance and pre-training time. The a-b-c in the horizontal coordinates in (a) represent the first-level, second-level, and reconstructed region sizes, respectively. The vertical coordinates represent the transfer learning capability in the BraTS2020 dataset (average Dice for the three segmentation targets). The right vertical coordinate in (b) indicates the time consumed per step during pre-training. The two red dashed boxes indicate the optimal architectural parameters we choose in (a) and (b), respectively. } %最终文档中希望显示的图片标题
%% 两个红色虚线框分别表示了我们在(a)和(b)中选择的最优架构参数。
%% We determine the optimal first-level and second-level regions by (a), and 32-16-128 migration learning works best. After that, we change the size of the reconstructed region by (b) choosing the optimal architecture parameter settings considering the performance and time.
\label{fig:pretraining_setting}
\vspace{-2mm}
%用于文内引用的标签
\end{figure}
%\label{pretraining_settings}

% 为了选择一个更好的架构参数，我们进行了多组对照实验。我们选择UNet架构预训练多组通用模型，see Fi. 3. 横坐标架构设置a-b-c中，a表示一级区域的大小，b表示二级区域的大小，c表示重建大小。纵坐标为通用模型在BraTS2020数据集中finetuning的Dice指标。

%%
In order to choose an optimal architecture setting, we conduct a multigroup control experiment. 
%%
We choose the UNet architecture to pre-train the possible settings (see Figure~\ref{fig:pretraining_setting}), where the three numbers under each bar represent the first-level sub-volume size, the second-level patch size, and the region size for partial region prediction.  
%%
The left vertical coordinates are the Dice metrics of finetuning the generic pre-trained model on the BraTS2020 dataset.
% Fig. 3. (b)中右侧纵坐标为每个step的时间消耗。
The right vertical coordinate in Figure~\ref{fig:pretraining_setting} (b) is the time consumption of each pre-training step.
% 像Fig. 3.(a)中所展示的那样，我们固定预训练的重构大小为128，选取了64-32，64-16，32-16，32-8四组参数预训练通用模型，之后在BraTS2020分割任务中进行finetuning，结果显示，32-16-128的参数设置表现最好，实现了最好的Dice。

As Figure~\ref{fig:pretraining_setting} (a) shows, we first fix the region size for partial region prediction to be 128, select four sets of parameters (64-32, 64-16, 32-16, and 32-8) for sub-volume and patch sizes.
%, and later perform finetuning in the BraTS2020 segmentation task. 
The results show that the parameter setting of 32-16-128 performs the best and achieves the best Dice of 85.79\%.

% 之后，我们选择32-16参数设置，逐步减小重构大小，see Fig. 3. (b)，实验结果展示，重建大小由128降低到96时，每个step的时间由1.03s降低至0.68s。下游分割任务的Dice指标由0.875降低至0.860。当重建大小继续降低至64时，每个step的时间为0.50s，Dice指标为85.38。为了实现更快的预训练速度并使性能影响降低，我们选择32-16-96作为我们的架构参数设置。^^
Afterwards, we fix the optimal sub-volume and patch sizes (32-16), and gradually decrease the reconstruction region size; see Figure~\ref{fig:pretraining_setting} (b). 
%%
We can see that with a smaller reconstruction region size, the Dice score decreases a little bit, while the time performance reduces greatly. 
%%
For instance, when reducing the reconstruction size from 128 to 96, the Dice score for the downstream segmentation task decreases from 85.79\% to 85.57\%, and the time per step decreases from 1.03s to 0.68s. 
%when the reconstruction size decreases to 64, the time per step is 0.50s, and the Dice metric is 85.38. The Dice metric is 85.38 for 0.50s. 
Considering the trade-off between the segmentation accuracy and pre-training speed, we choose 32-16-96 as our architecture parameters for the case that the input sample has a size of $128\times128\times128$ (BraTS2020 dataset).
%%
Taking this experiments as guidance, we use an architectural parameter setting of 32-16-64 for the case that the input sample has a size of $96\times96\times96$ (BTCV, MSD Liver and MSD Spleen).

% 我们分别使用了UNet与SwinTransformer作为backbone，在BraTS2020数据集上通过消融实验充分的验证了我们提出的每个模块的有效性。实验结果被展示在表5中。Loss单元格包含五个不同的损失函数，分别为LR(local reconstruction), Num(number), Loc(location), Consis(consistency), CL(contrastive learning)，其中LR代表了像素层次的3D医学图像表征的学习，Num，Loc，Consis代表了区域层次的表征学习，而CL代表了样本层次的学习。我们验证了MP-SSL在不同层次上的自监督学习对下游分割任务的性能提升。
\subsubsection{Efficiency of Self-Supervised Objectives}

We comprehensively validate the effectiveness of our modules through ablation experiments on the BraTS2020 dataset. 
%%
The experimental results using the generic pre-training mode are presented in Table~\ref{tab:ablation}. 
%%
We have five loss functions, namely $\mathcal{L}_{\mathrm{PR}}$ (partial region prediction), $\mathcal{L}_{\mathrm{Num}}$ (number prediction), $\mathcal{L}_{\mathrm{Loc}}$ (location prediction), $\mathcal{L}_{\mathrm{Con}}$ (consistency between number and location prediction), and $\mathcal{L}_{\mathrm{CL}}$ (contrastive learning).
%%
$\mathcal{L}_{\mathrm{PR}}$ facilitates the learning of 3D medical image latent representations at the pixel level; the combination of $\mathcal{L}_{\mathrm{Num}}$, $\mathcal{L}_{\mathrm{Loc}}$, and $\mathcal{L}_{\mathrm{Con}}$ facilitates the learning at the region level; and $\mathcal{L}_{\mathrm{CL}}$ facilitates the learning at the sample level. 
%We validate the performance improvement of the HybridMIM method at different levels of self-supervised learning for downstream segmentation tasks.
% Segmentation Target表示BraTS2020数据集不同的分割目标，Avg代表三个分割目标的平均指标。
%Segmentation Target represents the different segmentation targets of the BraTS2020 dataset, and Avg represents the average metric of the three segmentation targets.
% 表格中每个backbone的第一行结果为基线，不进行预训练，而是直接在下游分割任务上进行训练。之后，我们在预训练过程中逐渐添加不同的损失函数，来验证我们提出的不同模块对不同网络架构的性能提升能力。
We make comparison to the baseline with supervised training from scratch on the BraTS2020 dataset (see the first row for each backbone). 
%After that, we gradually add different loss functions during the pre-training process to verify the performance improvement capability of our proposed different modules for different network architectures.

\input{tables/brats_ablation.tex}


% 从表5中可以清晰的看出，当使用UNet架构在BraTS2020数据集上从零开始训练时，三个分割目标的Dice得分分别为89.75%， 84.65%， 78.83%， 平均值为84.41%。
\textbf{UNet architecture.} The baseline that is trained from scratch reports the Dice scores 89.75\%, 84.65\%, and 78.83\%, for the three segmentation targets respectively, with an average number of 84.41\%. 
% 此时加入第一个自监督学习损失LR(local reconstruction)，该损失从像素层次来重建原图像被掩蔽区域的分布。在下游分割任务上加载由LR损失预训练得到的模型权重，使得每项分割目标均有不同程度的提升，平均值达到85.06%，较从零开始训练提升了0.65%。
At this point, we add the first self-supervised learning loss $\mathcal{L}_{\mathrm{PR}}$, which reconstructs the masked regions of the original image at the pixel level. The model weights fine-tuned onto the downstream segmentation task, result in a Dice average of 85.06\%, with an improvement of 0.65\% over the baseline.
% 之后，添加区域层次的自监督损失Num(number),Loc(location),Consis(consistency)，提升模型表征空间区域分布的能力，分割目标的均值由85.06%提升至85.40%。
The addition of region-perception losses, i.e. $\mathcal{L}_{\mathrm{Num}}$, $\mathcal{L}_{\mathrm{Loc}}$, $\mathcal{L}_{\mathrm{Con}}$, improves the model's ability to characterize the distribution of spatial regions, and the mean Dice value is increased from 85.06\% to 85.40\%, getting an improvement of 0.34\%.
% 最后，添加样本层次的自监督损失CL(contrastive learning)，提升模型对于不同样本表征的区分能力。通过CL损失，在下游分割任务中，三个分割目标的Dice得分均值达到了85.69%，并且在WT与TC上的Dice得分也达到了最高，分别为90.62%和86.28%。
Finally, we add the sample-level self-supervised loss $\mathcal{L}_{\mathrm{CL}}$ to enhance the model's ability to distinguish between different sample representations. With $\mathcal{L}_{\mathrm{CL}}$, the mean Dice score reaches 85.69\% in the downstream segmentation task, and the highest Dice scores of 90.62\% and 86.28\% on WT and TC, respectively. 
%%
In the end, the average Dice score with pre-training was 1.29\% higher than that without pre-training.

% 类似的，MP-SSL方法对于SwinTransformer架构也有较大程度的提升。三个分割目标的平均Dice得分由没有预训练时候的85.09%最终提升到了86.39%，在BraTS2020数据集上实现了SOTA的分割结果。
\textbf{SwinUNETR architecture.} Similarly, the HybridMIM method also achieves obvious improvements for the SwinUNETR architecture. The average Dice score of the three segmentation targets was finally improved from 85.09\% without pre-training to 86.39\%, achieving SOTA segmentation results on the BraTS2020 dataset. 

% \textbf{Analysis of self-supervised loss enhancement effects.} 对于UNet跟SwinTransformer架构，从表中可以看出，LR损失发挥了比较大的作用。UNet架构加入LR损失后，三个分割指标的平均Dice得分提升了0.65%，而SwinTransformer架构加入LR损失后，三个指标的平均Dice得分提升了0.69%。
\textbf{Analysis of self-supervised loss enhancement effects.} 
For the UNet and SwinTransformer architectures, Table~\ref{tab:ablation} shows that the $\mathcal{L}_{\mathrm{PR}}$ plays a larger role. The average Dice score of the three segmentation targets increases by 0.65\% with the aid of $\mathcal{L}_{\mathrm{PR}}$ upon the UNet architecture, while the average Dice score of the three metrics increased by 0.69\% upon the SwinTransformer architecture.
% 此外Consis损失由于具有保持预测的数量与位置信息一致的作用，提升自监督学习的可解释性，因此其对于下游分割任务的提升较小。对于UNet架构，平均Dice得分提升了0.1%，而对于SwinTransformer结构，平均Dice提升了0.04%。
%%
The region perception losses ($\mathcal{L}_{\mathrm{Num}}$, $\mathcal{L}_{\mathrm{Loc}}$, $\mathcal{L}_{\mathrm{Con}}$ together) are the second important. 
%%
Also note that although the $\mathcal{L}_{\mathrm{Con}}$ has a relatively small improvement for the downstream segmentation task, it has a role in keeping the predicted quantity consistent with the location information, improving the interpretability of the self-supervised learning. 
%For the UNet architecture, the average Dice score increased by 0.1\%, while for the SwinTransformer structure, the average Dice increased by 0.04\%.

