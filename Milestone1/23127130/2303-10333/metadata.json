{
    "arxiv_id": "2303.10333",
    "paper_title": "HybridMIM: A Hybrid Masked Image Modeling Framework for 3D Medical Image Segmentation",
    "authors": [
        "Zhaohu Xing",
        "Lei Zhu",
        "Lequan Yu",
        "Zhiheng Xing",
        "Liang Wan"
    ],
    "submission_date": "2023-03-18",
    "revised_dates": [
        "2024-02-05"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "Masked image modeling (MIM) with transformer backbones has recently been exploited as a powerful self-supervised pre-training technique. The existing MIM methods adopt the strategy to mask random patches of the image and reconstruct the missing pixels, which only considers semantic information at a lower level, and causes a long pre-training time.This paper presents HybridMIM, a novel hybrid self-supervised learning method based on masked image modeling for 3D medical image segmentation.Specifically, we design a two-level masking hierarchy to specify which and how patches in sub-volumes are masked, effectively providing the constraints of higher level semantic information. Then we learn the semantic information of medical images at three levels, including:1) partial region prediction to reconstruct key contents of the 3D image, which largely reduces the pre-training time burden (pixel-level); 2) patch-masking perception to learn the spatial relationship between the patches in each sub-volume (region-level).and 3) drop-out-based contrastive learning between samples within a mini-batch, which further improves the generalization ability of the framework (sample-level). The proposed framework is versatile to support both CNN and transformer as encoder backbones, and also enables to pre-train decoders for image segmentation. We conduct comprehensive experiments on four widely-used public medical image segmentation datasets, including BraTS2020, BTCV, MSD Liver, and MSD Spleen. The experimental results show the clear superiority of HybridMIM against competing supervised methods, masked pre-training approaches, and other self-supervised methods, in terms of quantitative metrics, timing performance and qualitative observations. The codes of HybridMIM are available at https://github.com/ge-xing/HybridMIM",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.10333v1"
    ],
    "publication_venue": "10 pages, submitted to TMI",
    "doi": "10.1109/JBHI.2024.3360239"
}