\section{Preliminaries}
\label{sec:pre}

\subsection{Super-Resolution Algorithms and Dictionary Learning}
\label{sec:sr-algorithm}

Super-resolution algorithms aim at reconstructing a high-resolution (HR) image from a low-resolution (LR) one. 
Due to its wide applications, lots of efforts have been made in the past few decades. 
Denote the height and width of the image as $H$ and $W$ respectively, and the channel number of the image as a squared value $s^2$. 
For a given high-resolution vectorized image $\vec{y} \in \mathbb{R}^{HWs^{2}}$, its low-resolution counterpart $\vec{x} \in \mathbb{R}^{HW}$ 
can be obtained via down-sampling and blurring, as shown in \Cref{eq:transformation}. 
\begin{equation}
    \vec{x} = \vec{S}\vec{H}\vec{y},
    \label{eq:transformation}
\end{equation}
where $\vec{H}\in \mathbb{R}^{HWs^2}$ represents the blurring operation and $\vec{S}\in\mathbb{R}^{HW\times HWs^2}$ is the down-sampling operation. 
Correspondingly, the SR processing can be regarded as the reverse process of \Cref{eq:transformation}, \textit{i.e.}, recovering $\vec{y}$ from $\vec{x}$ by up-sampling and deblurring. 
However, solving \Cref{eq:transformation} is a notoriously challenging ill-posed problem because a specific $\vec{x}$ corresponds to 
a crop of possible $\vec{y}$. Besides, in most instances, the HR space that we intend to map the LR input to is usually intractable. 

To tackle these challenges, some basic linear interpolation methods are adopted, \textit{e.g.}, bilinear, and bicubic interpolations. 
In these methods, the strategies of mapping from the LR space to the HR space are quite straightforward and simple while neglecting some content varieties and local structures. 
Further, to constrain the mapping, some dictionary learning algorithms are proposed, which explicitly specify the mapping relationships between the LR space and HR space. 
Some pairs of dictionaries which map low-resolution (LR) patches to high-resolution (HR) patches are learned and used in inference. 
HR patches can be regarded as the spatial combination of the LR patches and now the problem is to learn the combination coefficients. 
Recently, with the fast developments of deep learning algorithms, some advanced methods have been proposed to learn better dictionaries and combination coefficients 
and achieved optimal performance \cite{SR-2019CVPR-SecondOrder, SR-2020NIPS-blindSR, SR-2020NIPS-LAPAR}. 

Focusing on optimizing the deep dictionary learning-based SR algorithms, the basic processing flow is explained as follows.   
% Notably, in this paper, we focus on the model inference while the training process is omitted. 
% The whole SR processing algorithm is composed of three stages. 
Firstly, the vectorized LR input $\vec{x}\in \mathbb{R}^{HW}$ is up-sampled to a matrix 
$\vec{B}\in \mathbb{R}^{HWs^2\times k^2}$ containing $HWs^2$ upsampled LR patches with size $k^2$. 
Secondly, some transformation operations are conducted to transform the LR batches to HR batches. 
The $i$-th pixel $\vec{y}_i$ in the HR image vector $\vec{y} \in \mathbb{R}^{HWs^{2}}$ is obtained via 
integrating the neighboring pixels of batch $\vec{B}_i$ (\textit{i.e.}, the $i$-th row of $\vec{B}$) centered at the coordinate of $\vec{y}_i$. 
This pixel-level operation can be formulated as \Cref{eq:integration}. 
\begin{equation}
    \begin{aligned}
        \vec{y}_i  = \vec{F}_i \vec{B}_i^\top, \ \mathrm{with} \ \vec{F}_i = \vec{\Phi}_i \vec{D}, 
    \end{aligned}
    \label{eq:integration}
\end{equation}
where $\vec{F}_i\in \mathbb{R}^{1\times k^2}$ is the integration coefficient vector (\textit{a.k.a.} a filter). 
$\vec{F}_i$ can be further represented as the linear combination of a dictionary $\vec{D} \in \mathbb{R}^{L\times k^2}$ 
with combination coefficient vector $\vec{\Phi}_i \in \mathbb{R}^{1\times L}$. 
During inference, the dictionary $\vec{D}$ is pre-defined and can be directly used, while the coefficients $\vec{\Phi}_i$ need to be calculated in real-time. 
According to the pixel-level operation in \Cref{eq:integration}, the image-level transformation can be represented as \Cref{eq:image-transformation}. 
\begin{equation}
    \begin{aligned}
        \vec{y} = \vec{F} \vec{B}^\top, \ \mathrm{with}\ \vec{F} = \vec{\Phi} \vec{D}, 
    \end{aligned}
    \label{eq:image-transformation}
\end{equation}
with $\vec{F}\in \mathbb{R}^{HWs^2\times k^2}$ and $\vec{\Phi}\in \mathbb{R}^{HWs^2 \times L}$. 
Some techniques have been proposed to learn the dictionary $\vec{D}$ and coefficient matrix $\vec{\Phi}$ \cite{SR-2012TIP-Coupled, SR-2016-RAISR, SR-2018ICCP-BLADE}. 
In LAPAR \cite{SR-2020NIPS-LAPAR}, $\vec{D}$ is a group of Gaussian ($G$) and difference of Gaussians ($DoG$) filters 
which are pre-defined to accelerate the computations.
The coefficient matrix $\vec{\Phi}$ is predicted via a residual network (which will be explained in detail in \Cref{sec:sr-architecture}). 

Considering the communication patterns of \Cref{eq:image-transformation}, $\vec{\Phi}$ and $\vec{B}$ usually occupy much more bandwidth compare with $\vec{D}$, \textit{i.e.}, 
\begin{equation}
    HWs^2 \times L + HWs^2\times k^2 \gg L \times k^2. 
\end{equation}
While considering the computation patterns, the dictionary $\vec{D}$ plays the key role. 
Whether the data in $\vec{\Phi}$ and $\vec{B}$ are ought to be computed is determined by $\vec{D}$, since $\vec{D}$ is the bridge connecting $\vec{\Phi}$ and $\vec{B}$. 
According to $\vec{D}$, if some computations can be skipped with no harm to the performance, we shall not load the data to on-chip memories, to save the precious bandwidth. 
The role of $\vec{D}$ makes the dictionary learning algorithm distinct from the traditional deep learning algorithms which only rely on weights and features. 
By optimizing the dictionary, it is believed that the communication and computation bottlenecks can be eased simultaneously. 

% The transformation formulation is shown in \Cref{eq:gaussian}. 
% \begin{equation}
%     \begin{aligned}
%         G(\vec{x} - \vec{x}', \vec{\Sigma}) = \frac{1}{2\pi |\vec{\Sigma}|^{\frac{1}{2}}}  \exp\{-\frac{1}{2} (\vec{x} - \vec{x}')^T \vec{\Sigma}^{-1} (\vec{x} - \vec{x}')\}, \\
%         DoG(\vec{x} - \vec{x}'; \vec{\Sigma}_a, \vec{\Sigma}_b) = G(\vec{x} - \vec{x}', \vec{\Sigma}_a) - G(\vec{x} - \vec{x}', \vec{\Sigma}_b), \\
%         \vec{\Sigma} = \gamma^2 \begin{bmatrix}\cos \theta& -\sin \theta \\ \sin \theta & \cos \theta \end{bmatrix} \begin{bmatrix}\sigma_1^2 & 0 \\ 0 & \sigma_2^2 \end{bmatrix} {\begin{bmatrix}\cos \theta& -\sin \theta \\ \sin \theta & \cos \theta \end{bmatrix}}^T
%     \end{aligned}
%     \label{eq:gaussian}
% \end{equation}
% where $\vec{x}$ and $\vec{x}'$ are the coordinates of the neighboring pixels and central pixel respectively, 
% $\vec{\Sigma}$ is the covariance matrix (\textit{i.e.}, filter) which reflects the spatial transformations, $\gamma$ is the scaling parameter, 
% $\theta$ is the rotation parameter, $\sigma_1$ and $\sigma_2$ are the elongation parameters on the two-dimensional space. 
% $\vec{\Sigma}_1$ and $\vec{\Sigma}_2$ are different with various transformation parameters. 

% A lightweight residual network is adopted to predict the combinatone 
% LAPAR model adopts a lightweight residual network to predict the information of combination coefficients for each filter. 
% The network consists of multiple local fusion blocks (LFB) \cite{SR-wang2019lightweight}, a depth-to-space (PixelShuffle) layer and several
% convolution layers at the end of the network. The function of depth-to-space layer is used to map low-resolution features to high-resolution features. 
% And the final convolutional layers generate the combination coefficients for dictionary learning stage.

\subsection{SR Model Architecture}
\label{sec:sr-architecture}

Typically, the deep dictionary learning-based models are composed of some residual units, 
convolutional layers, pixel-shuffle layers, dictionary assembling, and \textit{etc}. 

\begin{figure}[tb!]
    \centering
    \includegraphics[width=1.0\linewidth]{lapar} 
    \caption{The architecture of linearly-assembled pixel-adaptive regression network (LAPAR) \cite{SR-2020NIPS-LAPAR} with four basic stages, \textit{i.e.}, 
    stage 1: up-sampling; stage 2: \textit{LaparNet}; stage 3: dictionary assembling; stage 4: filtering. }
    \label{fig:LAPAR-architecture}
\end{figure}

The state-of-the-art SR model LAPAR \cite{SR-2020NIPS-LAPAR} is taken as an example to explain the model inference and the model structure. 
As shown in \Cref{fig:LAPAR-architecture}, during inference, there are four stages. 
Firstly, bilinear up-sampling is adopted to upscale the input image $\vec{x}$ to get the patch matrix $\vec{B}$. 
Secondly, the coefficient matrix $\vec{\Phi}$ is predicted by a \textit{LaparNet} with the original $\vec{x}$ as the input. 
\textit{LaparNet} is a stack of some local fusion blocks (LFBs) \cite{SR-2019-Lightweight}, pixel-shuffle layers, 
and several convolutional layers, while an LFB consists of some residual blocks, concatenations, multiplications, and addition operations. 
The third stage is dictionary assembling, in which the transformation matrix $\vec{F}$ is computed according to $\vec{\Phi}$ and the pre-defined dictionary $\vec{D}$. 
The final stage is filtering, in which the output HR image $\vec{y}$ is obtained by applying $\vec{F}$ to $\vec{B}$, \textit{i.e.}, $\vec{y} = \vec{F} \vec{B}^\top$. 
To deploy the SR models on GPU efficiently, the dictionary learning is ought to be analyzed in detail which has not been considered in previous arts. 

% In this paper, our task is to optimize the deployment of SR models on edge embedded GPU, to achieve the real-time inference. 
% Based on our proposed techniques, the model in \Cref{fig:LAPAR-architecture} is optimized and deployed. 

\subsection{GPU Programming Architecture}

The NVIDIA GPU architecture together with the CUDA programming model provides a well-designed abstraction that bridges the software applications and low-level hardware implementations, as illustrated in \Cref{fig:gpu-architecture}. 
The hardware architecture of a GPU is composed of some streaming multiprocessors (SMs). 
Each streaming multiprocessor consists of several processing blocks, some shared memory units, control logics, and \textit{etc}. 
Each processing block contains a group of computation cores (CUDA cores, Tensor Cores, and \textit{etc.}), %, as shown in \Cref{fig:gpu-architecture} 
register files, load/store units, and \textit{etc}. 
% The computation resources are grouped as warps. Further, several warps are composed as a streaming multiprocessor (SM). 

CUDA programming model is designed \cite{CUDA-C-Programming} to implement the computation tasks on the NVIDIA GPU. 
% To manage these hardware resources efficiently, the CUDA programming architecture is designed as a wrapper of the hardware. 
The programming model is composed of a host device (CPU) that controls the executions, 
and a device (GPU) that runs the kernel code to finish the computations, as shown in \Cref{fig:gpu-architecture}. 
Each kernel contains a computation grid that can be further divided into multiple blocks. 
Following the single instruction multiple threads (SIMT) mechanism, each block is partitioned into a group of threads 
that can run the same code on different data, synchronously. 
Usually, a thread is assigned to a hardware streaming processor. 
Once the kernel code is compiled, all of the threads will execute the same program in parallel, and thread blocks may execute in any order. 
These mechanisms will be carefully considered in this paper to obtain the optimal model deployments.
% There are briefly three steps to execute a GPU program. The first step is to copy the input data from host memory to device memory. 
% The second step is to load the GPU program and execute it. The last step is to copy the results from device memory to host memory. 
% To achieve good performance, there are some crucial factors, \textit{e.g.}, task organization, communication patterns, memory allocation, and \textit{etc}. 
% To accelerate the SR models, it is necessary to reduce both the computation and communication workloads, and take full advantage of the parallelisms. 

\begin{figure}[tb!]
    \centering
    \includegraphics[width=0.9\linewidth]{gpu-2} 
    \caption{GPU memory hierarchy and communication mode}
    \label{fig:gpu-architecture}
\end{figure}
