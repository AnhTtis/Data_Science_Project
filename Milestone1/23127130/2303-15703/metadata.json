{
    "arxiv_id": "2303.15703",
    "paper_title": "AD-YOLO: You Only Look Once in Training Multiple Sound Event Localization and Detection",
    "authors": [
        "Jin Sob Kim",
        "Hyun Joon Park",
        "Wooseok Shin",
        "Sung Won Han"
    ],
    "submission_date": "2023-03-28",
    "revised_dates": [
        "2023-05-05"
    ],
    "latest_version": 2,
    "categories": [
        "eess.AS"
    ],
    "abstract": "Sound event localization and detection (SELD) combines the identification of sound events with the corresponding directions of arrival (DOA). Recently, event-oriented track output formats have been adopted to solve this problem; however, they still have limited generalization toward real-world problems in an unknown polyphony environment. To address the issue, we proposed an angular-distance-based multiple SELD (AD-YOLO), which is an adaptation of the \"You Only Look Once\" algorithm for SELD. The AD-YOLO format allows the model to learn sound occurrences location-sensitively by assigning class responsibility to DOA predictions. Hence, the format enables the model to handle the polyphony problem, regardless of the number of sound overlaps. We evaluated AD-YOLO on DCASE 2020-2022 challenge Task 3 datasets using four SELD objective metrics. The experimental results show that AD-YOLO achieved outstanding performance overall and also accomplished robustness in class-homogeneous polyphony environments.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.15703v1",
        "http://arxiv.org/pdf/2303.15703v2"
    ],
    "publication_venue": "5 pages, 3 figures, accepted for publication in IEEE ICASSP 2023"
}