\section{Conclusion}
In this paper, we have introduced cost aggregation to open-vocabulary semantic segmentation, which jointly aggregates both image and text modalities within the matching cost. Our framework, namely \ours, not only effectively transfers the knowledge of CLIP to unseen classes, but also leverages the relations between image semantics and class labels through carefully designed spatial and class aggregation module aided by the additional technique called embedding guidance. With this approach, new state-of-the-art is set on every benchmarks, which highlights the superior generalization ability of our model.
