\subsection{Gradients of the Graph Matching Layer}
The gradients of the graph matching layer we need for backward can be derived from the KKT conditions with the help of the implicit function theorem. Here, we show the details of deriving the gradients of a standard QP optimization. 
\par
For a quadratic programming (QP), the standard formulation is as
\begin{equation}
    \begin{aligned}
    & \minimize_x
    & & \frac{1}{2}x^\top Q(\theta) x + q(\theta)^\top x \\
    & \subjectto
    && G(\theta)x \leq h(\theta) \\
    &&& A(\theta)x=b(\theta).
    \end{aligned}
    \end{equation}
So the Lagrangian is given by 
\begin{equation}
    L(x,\nu,\lambda)=\frac{1}{2}x^\top Qx+\lambda^\top (Gx-h)+q^\top x+\nu^\top (Ax-b),
\end{equation}
where, $\nu$ and $\lambda$ are the dual variables.\\
The $(x^*,\lambda^*,\nu^*)$ are the optimal solution if and only if they satisfy the KKT conditions:
\begin{equation}
    \begin{split}
    \nabla_x L(x^*,\lambda^*,\nu^*) &= 0 \\
    Qx^* +q+A^\top \nu^*+G^\top \lambda^* &= 0 \\
    Ax^*-b &= 0 \\
    \diag (\lambda^*)(Gx^*-h) &= 0 \\
    Gx^* -h &\leq 0 \\
    \lambda^*&\geq 0.
    \end{split}
    \end{equation}
We define the function
\begin{equation}
    g(x,\lambda,\nu,\theta) = \begin{bmatrix}
    \nabla_x L({x},\lambda,\nu,\theta) \\
    \diag(\lambda)\lambda^\top (G(\theta)x-h(\theta)) \\
    A(\theta)x-b(\theta)
    \end{bmatrix},
    \end{equation}
and the optimal solution $x^*, \lambda^*, \nu^*$ satisfy the equation $g(x^*, \lambda^*, \nu^*,\theta)=0$. \\
According to the implicit function theorem, as proven in \cite{barratt2018differentiability}, the gradients where the primal variable $x$ and the dual variables $\nu$ and $\lambda$ are the optimal solution, can be formulated as 
    \begin{equation}
        J_\theta x^* = -J_x g(x^*,\lambda^*,\nu^*,\theta)^{-1} J_\theta g(x^*,\lambda^*,\nu^*,\theta),
    \label{eq:jacobian}
    \end{equation}
where, $J_x g(x^*,\lambda^*,\nu^*,\theta)$ and $J_\theta g(x^*,\lambda^*,\nu^*,\theta)$ are the Jacobian matrices. Each element of them is the partial derivative of function $g$ with respect to variable $x$ and $\theta$, respectively.
\subsection{Inference Details}
\label{sec:tarcker}
%After training, the proposed pipeline can be straightly adopted as an online tracker. Graph construction, feature encoding and graph matching procedures are exactly the same as the training stage.
Due to the continuous relaxation, the output of the QP layer may not be binary. To get a valid assignment, we use the greedy rounding strategy to generate the final permutation matrix from the predicted matching score map, i.e., we match the detection with the tracklet with the maximum score. 
After matching, like DeepSORT \cite{wojke2017simple}, we need to handle the born and death of tracklets. We keep the matching between detection and tracklet only if it satisfies all the following constraints: 1) The appearance similarity between detection and tracklet is above the threshold $\sigma$. 2) The detection is not far away from the tracklet. We set a threshold $\kappa$ as the Mahalanobis distance between the predicted distribution of the tracklet bounding box by the motion model and the detection bounding box in pixel coordinates, called the motion gate. 3) The detection bounding box overlaps with the position of tracklet predicted by the motion model. The constraints above can be written as
    \begin{equation}
        \left\{
    \begin{aligned}
    &\mathbf{B}_{i,j}>\sigma,\\ 
    &\mathtt{KF}_{i,j}>\kappa,\\ 
    &\mathtt{iou}_{i,j}>0,
\end{aligned}
        \right.
    \label{eq:cons}
\end{equation}
where, $(i.j) \in (\mathcal{V}_D,\mathcal{V}_T)$.

Here, besides the Kalman Filter adopted to estimate the geometric information in Section \ref{sec:gcn}, we apply an Enhanced Correlation Coefficient (ECC) \cite{ecc} in our motion model additionally to compensate the camera motion. Besides, we apply the IoU association between the filtered detections and the unmatched tracklets by the Hungarian algorithm to compensate for some incorrect filtering.
% \footnote{Confused, since one of the criteria is no overlap with any tracklet. How to do this association? Hungarian again?}
 Then the remaining detections are considered as a new tracklet. We delete a tracklet if it has not been updated since $\delta$ frames ago, called \emph{max age}. 
 \begin{figure}[h] 
    \centering
    \includegraphics[width=0.7\linewidth]{figures/edgematch.pdf}
    \caption{An illustration of edge matching. Here, for matched pair $(c_1^D,c_1^T)$ in $\bm{\pi}_c$, we find best matching between edge $e_{1,i'}$ and $e_{1,j'}$, drawn in the same color.}
    \vspace{-10pt}
    \label{fig:edgematch}
\end{figure}
\subsection{GST: A Practical Algorithm for Quadratic Assignment}
However, due to the process of solving the quadratic programming, the inference speed is relatively slow compared with other mainstream MOT algorithms. To speed up, we design the gated search tree (GST) algorithm. Utilizing constraints Eq.~\ref{eq:cons}, the feasible region is limited much smaller than the original quadratic programming, which greatly accelerates the process of solving the quadratic assignment problem.\par
The GST algorithm (Alg.~\ref{alg:gst}) contains three main steps. Firstly, we construct a bipartite graph $\mathcal{G}=(\mathcal{V}_D,\mathcal{V}_T,\mathcal{E}_{DT})$, in which the edges are only between tracklets and detections meeting the constraints, i.e., $\mathcal{E}_{DT}=\{(i,j)|i\in \mathcal{V}_D,j\in \mathcal{V}_T, \mathbf{B}_{i,j}>\sigma, \mathtt{KF}_{i,j}>\kappa,
 \mathtt{iou}_{i,j}>0\}$. Secondly, we use depth-first search to find all the connected components $\{\mathcal{G}_c\}=\{\mathcal{G}_c=(\mathcal{V}^D_c,\mathcal{V}^T_c,\mathcal{E}^{DT}_c)|c=(1,2,\cdots,k),|\mathcal{V}^D_1|+|\mathcal{V}^T_1|\geq|\mathcal{V}^D_2|+|\mathcal{V}^T_2|\geq\cdots\geq|\mathcal{V}^D_k|+|\mathcal{V}^T_k|\}$.
 Last, we calculate the matching cost $\mathcal{L}(\bm{\pi}_c)$ for all matching candidates in each independent connected component $\mathcal{G}_c$ parallelly.\par
The matching cost follows the objective function of the quadratic programming Eq.~\ref{finalQP}. However, as a searching algorithm, the convex relaxation in the objective function shows no advantage. So, the matching cost can be denoted back to the objective function of the original QAP, as
\begin{equation}
    \mathcal{L}(\bm{\pi})=-\bm{\pi}^\top\mathbf{M}\bm{\pi}-\mathbf{b}^\top\bm{\pi}.
    \label{costpi}
\end{equation}
To calculate the matching cost parallelly and reduce the computation in each independent connected component, we partition the quadratic affinity matrix $\mathbf{M}$ and vertex affinity matrix $\mathbf{B}$. We denote $\bm{\pi}^\top=[\bm{\pi}_c^\top,\bm{\pi}_m^\top]$, where $\bm{\pi}_c$ is in current connected component $\mathcal{G}_c$ and $\bm{\pi}_m$ is between the complement of the vertex sets, i.e., $\mathcal{G}_m=(\mathcal{V}_D\backslash \mathcal{V}^D_c,\mathcal{V}_T\backslash \mathcal{V}^T_c,\mathcal{E}^{DT}_m)$. Then, the matching cost is
\begin{equation}
\begin{split}
    \mathcal{L}(\bm{\pi}_c)=&-\bm{\pi}^\top\mathbf{M}\bm{\pi}-\mathbf{b}^\top\bm{\pi}\\
    =&-[\bm{\pi}_c^\top, {\bm{\pi}_m^{*\top}}]     
    \left[
    \begin{array}{cc}
        \mathbf{M}_c &\mathbf{M}_r\\
        \mathbf{M}_l &\mathbf{M}_m
    \end{array}
    \right]
    \begin{bmatrix}
        \bm{\pi}_c\\
        \bm{\pi}_m^*
    \end{bmatrix}\\
    &-[\mathbf{b}_c^\top, \mathbf{b}_m^\top]\begin{bmatrix}
        \bm{\pi}_c\\
        \bm{\pi}_m^*
    \end{bmatrix},\\
    =&-[\bm{\pi}_c^\top, {\bm{\pi}_m^{*\top}}]     
    \left[
    \begin{array}{c c}
        \mathbf{M}_c &\mathbf{M}_r\\
        \mathbf{M}_l &\mathbf{0}
    \end{array}
    \right]
    \begin{bmatrix}
        \bm{\pi}_c\\
        \bm{\pi}_m^*
    \end{bmatrix}-\mathbf{b}_c^\top\bm{\pi}_c,\\
    =&-\bm{\pi}_c^\top\mathbf{M}_c\bm{\pi}_c-2\bm{\pi}_m^{*\top}\mathbf{M}_l\bm{\pi}_c-\mathbf{b}_c^\top\bm{\pi}_c,\\
    =&-\bm{\pi}_c^\top\mathbf{M}_c\bm{\pi}_c+2\mathcal{L}_e(\bm{\pi}_c,{\bm{\pi}_m^{*}})-\mathbf{b}_c^\top\bm{\pi}_c,
    \label{costpic}
\end{split}
\end{equation}
where $\mathbf{M}_c\in \MBR^{|\mathcal{V}^D_c|\times|\mathcal{V}^T_c|}, \mathbf{b}_c\in\MBR^{|\mathcal{V}^D_c||\mathcal{V}^T_c|}$. Here, the matching cost contains the pairwise cost $\mathcal{L}_e(\bm{\pi}_c,{\bm{\pi}_m^{*}})$ that depends on the optimal solution $\bm{\pi}_m^{*}$, not available from connected component $\mathcal{G}_c$. To make it independent of the other components, we only consider the optimal solution $\widetilde{\bm{\pi}}_m^*$ given $\bm{\pi}_c$ instead the global optimal solution $\bm{\pi}_m^*$, i.e.,
% \begin{equation}
%     \begin{split}
% \mathcal{L}_e(\bm{\pi}_c,{\bm{\pi}_m^{*}})\approx&\mathcal{L}_e({\bm{\pi}_m^*|\bm{\pi}_c})\\
% =&\mathcal{L}_e({\bm{\pi}_m^{e*}|\bm{\pi}_c})\\
% =&-\max_{\pi_m} \bm{\pi}_m^{\top}\mathbf{M}_l\bm{\pi}_c\\
% =&-\max_{\pi_m}\sum_{i=1}^{\min\{n_d^c,n_t^c\}}\bm{\pi}_m^{\top}
% \end{split}
% \end{equation}
\begin{equation}
    \begin{split}
\mathcal{L}_e(\bm{\pi}_c,{\bm{\pi}_m^{*}})\approx&\mathcal{L}_e({\widetilde{\bm{\pi}}_m^*|\bm{\pi}_c})=-\max_{\pi_m} \bm{\pi}_m^{\top}\mathbf{M}_l\bm{\pi}_c.
\end{split}
\end{equation}
Intuitively, it is to find the best matching between the edges in the detection graph and tracklet graph with the start vertices fixed to an existing set of matches $\bm{\pi}_c$. As shown in Fig.~\ref{fig:edgematch}, for each matched pair $(c_i^D,c_j^T)$ in $\bm{\pi}_c$, we adopt bipartite matching between edge set $\{e_{i,i'}\}$ and $\{e_{j,j'}\}$ that start from $c_i^D$ and $c_j^T$ respectively.

% where $\bm{\pi}=\text{vec}(\MPI)$, $\mathbf{b}=\text{vec}(\MB)$ and $\mathbf{M}\in \MBR^{n_dn_t\times n_dn_t}$ is the symmetric quadratic affinity matrix between all the possible edges in two graphs.\par

% Besides, the relaxed continuous quadratic programming Eq.~\ref{finalQP}
% .
% , the optimal solution of the QP (Eq.~\ref{finalQP}) does not equal to the original QAP (Eq.~\ref{equ:KBQAP}). As a searching algorithm, the relaxation shows no advantage. So, we define the objective function back to the original QAP as
% \begin{equation}
%     \bm{\pi}^*=\underset{\bm{\pi}}{\arg\max} \ 
%     \bm{\pi}^\top\mathbf{M}\bm{\pi}+\mathbf{b}^\top\bm{\pi},
%     \label{edge2}
%     \end{equation}
% where $\bm{\pi}=\text{vec}(\MPI)$, $\mathbf{b}=\text{vec}(\MB)$ and $\mathbf{M}\in \MBR^{n^2\times n^2}$ is the symmetric quadratic affinity matrix between all the possible edges in two graphs.\par






\begin{algorithm}[ht!]
\caption{Gated Search Tree (GST)}
    \label{alg:gst}
  
    \KwIn{$\mathbf{M}, \mathbf{B},\mathtt{iou}, \mathtt{KF},\sigma,\kappa$}
    \KwOut{$\mathbf{\Pi}$}
    {\small //\ Construct\ graph}\\

    \For{$(i.j) \in \mathtt{range}(n_d,n_t)$}{
    $\mathbf{A}_{i.j}\leftarrow\mathbb{I}\{{\mathtt{iou}_{i,j}>0 \land \mathtt{KF}_{i,j}>\kappa \land \mathbf{B}_{i,j}>\sigma}\}$}

    % $\mathcal{G}(\mathbf{A}) \leftarrow \mathbf{A}_{i.j}$\\
    {\small //\ Find Independent Connected Components (Alg.~\ref{alg:FCS})}\\
    $\{\mathcal{G}_k\}\leftarrow\mathtt{FICC(\mathcal{G}(\mathbf{A}))}$\\
    {\small //\ Find Best Matching}\\
    \For{$\mathcal{G}_c \in \{\mathcal{G}_k\}$}{
    $\mathbf{M}_c, \mathbf{b}_c = \mathbf{M}[\{c\},\{c\}], \mathtt{vec}(\mathbf{B}[\{c\},\{c\}])$\\
    $\mathcal{L}(\bm{\pi}_c)=-\bm{\pi}_c^\top\mathbf{M}_c\bm{\pi}_c+2\mathcal{L}_e({\widetilde{\bm{\pi}}_m^*|\bm{\pi}_c})-\mathbf{b}_c^\top\bm{\pi}_c,$\\
    $\bm{\pi}_c^*\leftarrow\arg\min_{\bm{\pi}_c}\mathcal{L}(\bm{\pi}_c)$
    }
    $\mathbf{\Pi}\leftarrow \bigcup_{c=1}^{k} \bm{\pi}_c^*$\\
    \Return{$\mathbf{\Pi}$}
    

\end{algorithm}
\begin{algorithm}[]
    \caption{Find Independent Connected Components (FICC)}
        \label{alg:FCS}
        % \SetAlgoLined
        \SetKwProg{Fn}{def}{:}{end}
        \KwIn{$\mathcal{G}=(\mathcal{V}_D,\mathcal{V}_T,\mathcal{E}_{DT})$}
        \KwOut{$\{\mathcal{G}_c\}$}
        $c\leftarrow 0$; $\{\mathcal{G}_c\}\leftarrow\varnothing$\\
        \For{$v_p\in \mathcal{V}_D\cup\mathcal{V}_T$}{
            $\mathtt{visited}[v_p]\leftarrow\mathtt{False}$
        }

        \For{$v_p \in \mathcal{V}_D\cup\mathcal{V}_T$}{
            \If{$\neg\mathtt{visited}[v_p]$}{
                $\mathcal{E}_c^{DT},\mathcal{V}_c^D,\mathcal{V}_c^T \leftarrow \varnothing$\\
                \If {$v_p\in \mathcal{V}_D$}{
                $\mathcal{V}_c^D \leftarrow \mathcal{V}_c^D \cup\{v_p\}$}
                \ElseIf{$v_p\in \mathcal{V}_T$}{$\mathcal{V}_c^T \leftarrow \mathcal{V}_c^T \cup\{v_p\}$}
                $\mathtt{visit}(v_p)$\\
                $c \leftarrow c+1$}
        }
        \Fn{$\mathtt{visit}(v_p)$}{
            $\mathtt{visited}[v_p]\leftarrow\mathtt{True}$\\
            \For{$e_{p,q}\in \mathcal{E}_{DT}$}{
                $\mathcal{E}_c^{DT} \leftarrow \mathcal{E}_c^{DT}\cup\{e_{p,q}\}$\\
                \If{$\neg\mathtt{visited}[v_q]$}{
                    $\mathtt{visit}(v_q)$\\
                    \If {$v_q\in \mathcal{V}_D$}{
                $\mathcal{V}_c^D \leftarrow \mathcal{V}_c^D \cup\{v_q\}$}
                \ElseIf{$v_i\in \mathcal{V}_T$}{$\mathcal{V}_c^T \leftarrow \mathcal{V}_c^T \cup\{v_q\}$}
                }
            }


        }
        \Return{$\{\mathbf{G_c}\}$}
        
\end{algorithm}

% \begin{algorithm}[ht!]
% \caption{Maximum Weighted Independent Set (MWIS)}
%     \label{alg:MWIS}
  
%     \KwIn{$\mathbf{G}$}
%     \KwOut{$\mathbf{\Pi}$}
 
%     \Return{$\mathbf{\Pi}$}
    

% \end{algorithm}
Then, we discuss the time cost of the original QP solver and the GST algorithm:
\begin{proposition}[Original complexity]
    The quadratic programming Eq.~\ref{finalQP} can be solved in $O(n_d^3n_t^3)$ arithmetic operations.
\end{proposition}
% \begin{proof}
%     The quadratic programming is proved~\cite{ye1989extension} that the optimal solution can be derived in $O(n^3)$ arithmetic operations, where $n$ is the lenth of variable vector. In Eq.~\ref{finalQP}, $\mathbf{x} \in \MBR^{n_dn_t}$, so the Eq.~\ref{finalQP} can be solved in $O(n_d^3n_t^3)$ arithmetic operations. 
% \end{proof}
% \begin{proposition}[Complexity of GST]
%     The time complexity of GST algorithm is 
%     \begin{equation}
%     O(2^{k_m}n_mk_dk_t),
%     \end{equation}
% where $n_m=\min\{n_d,n_t\}, k_d=|U_k|, k_t=|V_k|,k_m=\min\{k_d,k_t\}$.
% \end{proposition}
% \begin{proof}
% \textcolor{red}{this is the proof.}
% \end{proof}
\begin{proposition}
    The running time of Algorithm~\ref{alg:gst} in parallel mode is
    \begin{equation}
        T = c\cdot n_m|\mathcal{V}^T_1||\mathcal{V}^D_1|+\epsilon,
\end{equation}
where $c$ is a constant factor, $\epsilon$ represents low-order terms of $n$ and communication overhead between threads, $n_m=\max\{n_d,n_t\}$.
\end{proposition}
% \begin{proof}
%     \textcolor{red}{this is the proof.}
%     \end{proof}
\begin{figure*}[!h] 
    \centering
    \vspace{-10pt}
    \includegraphics[width=\linewidth]{figures/gmatcher.pdf}
    \vspace{-10pt}
    \caption{Pipeline of our image matching network, GMatcher. The backbone is an FPN-like module. The edge and vertex features are from the stride-8 and stride-2 feature maps respectively. Edge and vertex AGNN are operated independently. The learnable graph matching layer replaces the Sinkhorn layer in SuperGlue.}
    \vspace{-10pt}
    \label{fig:gmatcher}
\end{figure*}
\section{Learnable Graph Matching for Image Matching Task}
Besides the MOT task, our learnable graph matching method can be easily adapted to other data association tasks with slight modifications. In this section, we take the image matching task as an example. We formulate the image matching task as a graph matching problem between the keypoints in two images and utilize our learnable graph matching algorithm to build an end-to-end keypoint-based neural network.
\subsection{Problem Formulation}
Given keypoints $\mathcal{P}=\{\mathbf{p}_1,\mathbf{p}_2,\cdots,\mathbf{p}_m\}$, $\mathcal{P}'=\{\mathbf{p}'_1,\mathbf{p}'_2,\cdots,\mathbf{p}'_n\}$ on the image $I$ and $I'$ of the same scene respectively, where $\mathbf{p}_i=(x_i,y_i)$ is the keypoint position in image coordinates, the image matching task is to find the best matching between $\mathcal{P}$ and $\mathcal{P}'$ and thus estimate the relative camera pose $\mathbf{T}\in SE(3)$. 
The keypoints are often on the corners, textured areas, or the boundary of the objects, where the local features are relatively robust and less affected by illumination and viewing angle.
They can be derived from traditional methods, like SIFT~\cite{lowe2004distinctive}, or deep learning-based methods, like SuperPoint~\cite{detone2018superpoint}. And the descriptor $\mathbf{d}_i \in \mathbb{R}^c$ is a $c$-dimentional local discriminative feature, corresponding to the keypoint $\mathbf{p}_i$. In this paper, we extract the features in an end-to-end way, with only the positions of the keypoints from the off-the-shelf neural network. \par
In our end-to-end graph matching neural network, called \emph{GMatcher}, we take two images and the keypoints on each image as the input, solving the graph matching problem (Eq.~\ref{finalQP}) from $\mathcal{P}$ and $\mathcal{P}'$, and we finally obtain the assignment matrix $\mathbf{\Pi} \in \mathbb{R}^{m\times n}$ to represent the matching between two keypoint sets. 
\subsection{End-to-end Graph Matching Network for Image Matching}
Our method is mainly based on SuperGlue~\cite{sarlin2020superglue}, which utilizes the attentional graph neural network (AGNN) module to aggregate long-range dependencies. However, compared with graph matching, although SuperGlue stacks self- and cross- attention modules many times to fuse the intra- and inter-image information, it does not explicitly define the intra-image graph and consider the edge similarities between images in keypoint matching. \par
To better utilize the high-order information, i.e., edge in the intra-image graph, we use FPN-like~\cite{lin2017feature} backbone to extract multiscale features. The stride-2 feature map and stride-8 feature map are used to extract vertex feature $\mathbf{d}_i^v$ and edge feature $\mathbf{d}_{i,j}^e$ respectively. Note that the edge feature $\mathbf{d}_{i,j}^e$ is the concatenation of the endpoints' feature $\mathbf{d}_i^e$ and $\mathbf{d}_j^e$ on stride-8 feature map. The feature $\mathbf{d}_i$ on each keypoint $\mathbf{p}_i$ is extracted from the feature map that is restored to the original image resolution using bilinear interpolation.\par
Like the position embedding in the transformer, we use MLP to encode the position information into the vertex feature $\mathbf{d}_i^v$ and edge feature $\mathbf{d}_{i,j}^e$, i.e.,
\begin{equation}
    \begin{aligned}
    \label{eq:keypoint-encoder}
    \mathbf{f}_i^v &= \mathbf{d}_i^v + \text{MLP}_{\text{pos}}(\mathbf{p}_i),\\
    \mathbf{f}_{i,j}^e &= \mathbf{d}_{i,j}^e + [\text{MLP}_{\text{pos}}(\mathbf{p}_i),\text{MLP}_{\text{pos}}(\mathbf{p}_j)],
    \end{aligned}
\end{equation}
where, $[\cdot,\cdot]$ denotes concatenation.\par
Then, similar to the AGNN module in SuperGlue, we conduct self-attentional and cross-attentional message passing for $l$ times in vertex features and edge features separately. The detailed design can be referred to SuperGlue~\cite{sarlin2020superglue}. We use the output vertex features and edge features of AGNN to construct the final graphs $\mathcal{G}_1=(\mathcal{V}=\{\mathbf{d}_i^{v(l)}\},\mathcal{E}=\{\mathbf{d}_{i,j}^{e(l)}\}))$ and $\mathcal{G}_2=(\mathcal{V}=\{\mathbf{d}_{i'}^{v(l)}\},\mathcal{E}=\{\mathbf{d}_{i',j'}^{e(l)}\}))$ for two images and matching with our differentiable graph matching layer mentioned in Sec.~\ref{sec:diffgm}.
   