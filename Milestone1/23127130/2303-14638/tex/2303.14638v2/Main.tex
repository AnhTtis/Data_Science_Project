% ****** Start of file apssamp.tex ******
%
%   This file is part of the APS files in the REVTeX 4.2 distribution.
%   Version 4.2a of REVTeX, December 2014
%
%   Copyright (c) 2014 The American Physical Society.
%
%   See the REVTeX 4 README file for restrictions and more information.
%
% TeX'ing this file requires that you have AMS-LaTeX 2.0 installed
% as well as the rest of the prerequisites for REVTeX 4.2
%
% See the REVTeX 4 README file
% It also requires running BibTeX. The commands are as follows:
%
%  1)  latex apssamp.tex
%  2)  bibtex apssamp
%  3)  latex apssamp.tex
%  4)  latex apssamp.tex
%
\documentclass[%
reprint,
%superscriptaddress,
%groupedaddress,
%unsortedaddress,
%runinaddress,
%frontmatterverbose, 
%preprint,
%preprintnumbers,
%nofootinbib,
%nobibnotes,
%bibnotes,
amsmath,amssymb,
%aps,
%pra,
%prl,
prb,
%prb,
%rmp,
%prstab,
%prstper,
%floatfix,
]{revtex4-2}

\usepackage{lipsum}
\usepackage{bm}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{graphicx}
\usepackage{color}
\usepackage{amsthm}
\usepackage{floatrow}
%\usepackage{subfig}
%\usepackage{caption}
%\usepackage{float}
\usepackage{array}
\renewcommand\arraystretch{2}
\usepackage{listings}
\usepackage{booktabs}
%\usepackage{tikz}
% bold math
\usepackage{hyperref}% add hypertext capabilities
%\usepackage[mathlines]{lineno}% Enable numbering of text and display math
%\linenumbers\relax % Commence numbering lines

%\usepackage[showframe,%Uncomment any one of the following lines to test 
%%scale=0.7, marginratio={1:1, 2:3}, ignoreall,% default settings
%%text={7in,10in},centering,
%%margin=1.5in,
%%total={6.5in,8.75in}, top=1.2in, left=0.9in, includefoot,
%%height=10in,a5paper,hmargin={3cm,0.8in},
%]{geometry}

\begin{document}
	\preprint{APS/123-QED}
	\title{An informational and thermodynamic analysis of percolation in interacting systems}% Force line breaks with \\
	%\collaboration{MUSO Collaboration}%\noaffiliation
	\thanks{Correspondence should be addressed to Y.Z.X and P.S.}%
	
	\author{Yang Tian}
	\email{tiany20@mails.tsinghua.edu.cn \& tyanyang04@gmail.com}
	\altaffiliation[]{Department of Psychology \& Tsinghua Laboratory of Brain and Intelligence, Tsinghua University, Beijing, 100084, China.}
	\altaffiliation[Also at]{Laboratory of Advanced Computing and Storage, Central Research Institute, 2012 Laboratories, Huawei Technologies Co. Ltd., Beijing, 100084, China.}
	
	\author{Yizhou Xu}%
	\email{xuyz23@mails.tsinghua.edu.cn}
	\altaffiliation[]{Department of Mathematical Sciences, Tsinghua University, Beijing, 100084, China.}
	
	\author{Pei Sun}%
	\email{peisun@tsinghua.edu.cn}
	\altaffiliation[]{Department of Psychology \& Tsinghua Brain and Intelligence Lab, Tsinghua University, Beijing, 100084, China.}
	
	%\affiliation{
	% Lunar Base
	%}%
	%\author{Delta Author}
	%\affiliation{%
	% Authors' institution and/or address\\
	% This line break forced with \textbackslash\textbackslash
	%}%
	
	%\collaboration{CLEO Collaboration}%%\noaffiliation
	
	%\date{\today}% It is always \today, today,
	%  but any date may be explicitly specified
	
\begin{abstract}
Any interacting system can be studied as a network where nodes are units and edges denote correlated interactions. As internal correlations increase, correlated behaviours emerge and propagate among units to create percolation phenomena. In this work, we propose a unified framework to study the informational and thermodynamic aspects of percolation in interacting systems, which enables us to analytically measure freedom degree loss during percolation and analyze the underlying thermodynamic evolution. We apply this framework to analyze the critical exponents and scaling relations (e.g., the Rushbrooke inequality) of the Bernoulli percolation, the bootstrap percolation, and the synchronization described by the Kuramoto model. These results suggest the general applicability of our framework in analyzing the universality of diverse phase transition phenomena.
\end{abstract}
	
	%\keywords{Suggested keywords}%Use showkeys class option if keyword
	%display desired
	\maketitle
	%\tableofcontents
	\section{Introduction}
	
	By its nature, an interacting system, including those described by the Wilson-Cowan equation \cite{wilson1973mathematical,amari1977dynamics,bressloff2010metastable,bressloff2010stochastic}, spin glasses \cite{binder1986spin}, DNA compaction \cite{vtyurina2016hysteresis}, random cluster model \cite{grimmett2006random}, Kuramoto model \cite{acebron2005kuramoto}, and cellular Potts model \cite{scianna2012multiscale,chen2007parallel,chiang2016glass} can be represented by the dynamics on a network $G\left(V,E\right)$, where nodes in $V$ are system units and edges in $E$ denote correlated interactions. The existence of an edge between units $i$ and $j$ is non-trivially determined by $C_{ij}$, the $\left(i,j\right)$-th entity in a specific correlation matrix $C$ that describes the relations among system units.

 Percolation on network \cite{li2021percolation,duminil2018sixty} may be a natural formalization that characterizes different interacting systems as networks in a unified manner. The key idea is to generate an all-to-all network of units (i.e., a complete graph) during initialization. Then each edge is occupied if and only if the associated units synchronously behave (i.e., these two units are correlated). All unoccupied edges are removed from the initial network, after which a filtered network is obtained to describe the propagation of correlated behaviours. In a probabilistic manner, we can consider an occupation probability vector
	\begin{align}
		\rho=f\left(C\right)=\left(\rho_{e}:\;e=\left(i,j\right)\in E\right)\in\left[0,1\right]^{E},\label{EQ1}
	\end{align}
	where $f\left(\cdot\right)$ is a non-trivial element-wise function that maps correlation matrix $C$ to occupation probability vector $\rho$. A percolation configuration 
	\begin{align}
		\mathbf{\eta}=\left(\eta_{e}:\;e=\left(i,j\right)\in E\right)\in\{0,1\}^{E}\label{EQ2}
	\end{align}
	lives in a probability space $\left(\{0,1\}^{ E},\sigma_{\eta} ,P_{\rho}\right)$, where $1$ denotes occupation (i.e., the edge is kept) and $0$ denotes non-occupation (i.e., the edge is deleted). Notion $\sigma_{\eta}$ denotes a $\sigma$-algebra and $P_{\rho}$ is a probability measure characterized by vector $\rho$. The propagation of correlated behaviours within the system is fully characterized by $\mathbb{P}_{\rho}$, based on which we can apply percolation theory to study the emergence of a giant cluster of correlated units or the size distribution of all finite clusters (note that the cluster is another name of the connected component) \cite{li2021percolation,georgakopoulos2018analyticity,duminil2018sixty}


 By adjusting the definition of $f\left(\cdot\right)$ for deriving different types of $\rho$, we can apply this framework to describing diverse kinds of correlated behaviour propagation, such as those characterized by Bernoulli percolation \cite{georgakopoulos2018analyticity}, explosive percolation \cite{matsoukas2015abrupt,boccaletti2016explosive}, and bootstrap percolation \cite{adler1988diffusion,baxter2010bootstrap}. For instance, we can define a simple $f\left(\cdot\right)$ to map $C$ to a scalar within $\left[0,1\right]$ that functions as a global occupation probability in Bernoulli percolation \cite{georgakopoulos2018analyticity}.
 
	
In this work, we pursue to take a step further and reconsider the framework presented above from both informational and thermodynamic perspectives, where we treat $\sigma_{\eta}$ as the statistical ensemble of all possible microstates $\eta$. Considering that some microstates may have higher probabilities to occur than other microstates given a $\rho$, we attempt to study the non-trivial evolution of the probability distribution of these microstates as $\rho$ changes. Specifically, we suggest to analyze the evolution of freedom degrees in the ensemble. When some microstates become less possible to occur, the freedom degrees associated with them are reduced. This idea naturally leads us to explore the appropriate definitions of entropy and specific heat for percolation because entropy is a common metric of freedom degrees in both information and thermodynamics theories and specific heat is related to the derivative of entropy in thermodynamics. 

Historically, the pursuit of bridging between percolation and thermodynamic formalization of phase transitions (i.e, relating the observable quantities of percolation to their thermodynamic counterparts) has attracted notable efforts \cite{hassan2017entropy,radicchi2009explosive,ziff2010scaling,bastas2011explosive,fortuin1972random,hassan2016universality}. However, previous progress is limited to the classic cases where percolation is defined on squares or lattices and is less applicable to characterizing complex interacting systems (i.e., units in a real complex system may not necessarily be placed on a regular, uniform, and fixed structure). Meanwhile, the proposed thermodynamics concepts in previous works (e.g., see entropy and specific heat in Ref. \cite{hassan2017entropy}) critically relay on numerical computations and lack analytic or, at least, asymptotic expressions. Moreover, to our best knowledge, the informational aspects of percolation remain largely unknown although some prior works have suggested the informational properties of networks \cite{de2016spectral}.

To deal with these non-negligible issues, we suggest a possible paradigm to define informational and thermodynamic concepts in an explicit manner, which is generally applicable to different kinds of percolation. As shown in our subsequent analysis, these concepts enable us to measure the loss of freedom degrees during percolation, discover new order parameters of percolation transition, and verify important scaling relations.
	
	
\section{Thermodynamics underlying percolation}\label{Sec2}
\subsection{A inforamtional view of freedom degree loss}\label{Sec2-1}

Let us consider a general case where the propagation of correlated behaviours in an interacting systems is modelled by an arbitrary percolation process. Given a $\rho$, we can search through the system to find emerged clusters. We assume that there exists an arbitrary cluster of size $M$ in the system (i.e., we require these $M$ nodes are connected following a certain wiring diagram). 

For these $M$ nodes, their wiring diagram can be diverse but must form a cluster (i.e., a connected component) as required by the percolation process. The possibilities where these $M$ nodes are disconnected should be faint. As an opposite case, we can consider a neutral situation where the propagation of correlated behaviours does not exist and there is no any restraint on the wiring diagram of these $M$ nodes. In this case, all wiring diagrams are possible, including those where $M$ nodes no longer form a cluster. Therefore, the percolation process actually rejects some possibilities (i.e., freedom degrees) compared with the neutral situation.

Below, we suggest a possible way to mathematically formalize the above analysis. The considered $M$ nodes can form $2^{\binom {M} {2}}$ kinds of wiring diagrams in total. Equivalently, there exist the same number of possible percolation configurations. We denote $ \mathsf{H}\left(M\right)$ as the set of these percolation configurations such that $\vert  \mathsf{H}\left(M\right)\vert=2^{\binom {M} {2}}$ (see Fig. \ref{G1}(a) for an instance).

We define $\left( \mathsf{H}\left(M\right),\sigma_{\eta},P_{\text{free}}\right)$ to characterize the statistical ensemble corresponding to the neutral situation of these $M$ nodes. In this ensemble, every percolation configuration is possible to occur because the system is free of any constraint, which is naturally related to the maximum entropy situation. This property inspires us to apply a postulate of \emph{equal a priori probabilities} and define the probability distribution of each microstate (i.e., percolation configuration) $\eta$ 
\begin{align}
P_{\text{free}}\left(\eta\right)= \frac{1}{\vert \mathsf{H}\left(M\right)\vert}=2^{-\binom {M} {2}}.\label{EQ3}
\end{align}

Then we turn to $\left( \mathsf{H}\left(M\right),\sigma_{\eta} ,P_{\rho}\right)$, the probability space corresponding to the percolation process controlled by $\rho$. In this ensemble, a percolation configuration is possible to occur if and only if the associated network of $M$ nodes is connected. For convenience, we define $L\left(\eta\right)\leq M$ as the largest cluster in the network associated with $\eta$. The probability of microstate $\eta$ is 
\begin{align}
    P_{\rho}\left(\eta\right)= \frac{1}{Z_{\eta}\left(M\right)}\delta\left(L\left(\eta\right),M\right),\label{EQ4}
\end{align}
where $\delta\left(\cdot,\cdot\right)$ denotes the Kronecker delta function and $Z_{\eta}\left(M\right)$ is a partition function
\begin{align}
    Z_{\eta}\left(M\right)=\sum_{\eta\in \mathsf{H}\left(M\right)}\delta\left(L\left(\eta\right),M\right) .\label{EQ5}
\end{align}
See Fig. \ref{G1}(a) for the instances of $\eta$ with $L\left(\eta\right)= M$.

 Compared with $P_{\text{free}}\left(\cdot\right)$, lots of freedom degrees been reduced in $P_{\rho}\left(\cdot\right)$ because all percolation configurations whose largest cluster sizes are smaller than $M$ have been excluded. The freedom degree loss stands for the difference between these two distributions, to analyze which, we suggest to consider a re-normalized uniform probability distribution of excluded freedom degrees
 \begin{align}
P_{\text{loss}}\left(\eta\right)= \frac{1}{\sum_{\eta\in \mathsf{H}\left(M\right)}\mathbf{1}_{\left[0,M\right)}\left(L\left(\eta\right)\right)}\mathbf{1}_{\left[0,M\right)}\left(L\left(\eta\right)\right),\label{EQ6}
\end{align}
where notion $\mathbf{1}_{A}\left(\cdot\right)$ denotes the indicator function defined on set $A$. To study the property of $P_{\text{loss}}\left(\cdot\right)$, we can use $P_{\text{free}}\left(\cdot\right)$, the maximum entropy distribution \cite{cover1999elements} over $ \mathsf{H}\left(M\right)$, as a reference to analyze how $P_{\text{loss}}\left(\cdot\right)$ approaches to or departs from the maximum entropy state. To realize this analysis, we derive the relative entropy between $P_{\text{loss}}\left(\cdot\right)$ and $P_{\text{free}}\left(\cdot\right)$ according to the property of relative entropy between uniform random variables \cite{cover1999elements}
\begin{align}
    \mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)= \log\left(\frac{\vert \mathsf{H}\left(M\right)\vert}{\vert \mathsf{H}\left(M\right)\vert-Z_{\eta}\left(M\right)}\right).\label{EQ7}
\end{align}


A direct benefit of analyzing $\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)$ lies in that it can be used to derive the Shannon entropy of distribution $P_{\text{loss}}\left(\cdot\right)$ \cite{cover1999elements}
 \begin{align}
S_{\text{loss}}\left(M\right)=\log\left(n\right)-\mathbb{D}\left(P_{\text{loss}}\Vert P_{\textsf{U}}\right),\label{EQ8}
\end{align}
where $n$ is the total number of possibilities in the space of $P_{\text{loss}}\left(\cdot\right)$ and $P_{U}\left(\cdot\right)$ denotes the uniform distribution defined on these possibilities. In our situation, it is clear that all possibilities are included in set $ \mathsf{H}\left(M\right)$ and the uniform distribution defined on $ \mathsf{H}\left(M\right)$ coincides with $P_{\text{free}}\left(\cdot\right)$. Therefore, Eq. (\ref{EQ8}) can be reformulated as
\begin{align}
S_{\text{loss}}\left(M\right)=\binom {M} {2}\log\left(2\right)-\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right).\label{EQ9}
\end{align}
According to Eq. (\ref{EQ9}), as $\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)$ decreases (i.e., as $P_{\text{loss}}\left(\cdot\right)$ approaches to the maximum entropy distribution), the number of lost freedom degrees measured by $S_{\text{loss}}\left(M\right)$ increases. In an opposite case, as $\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)$ increases, the number of lost freedom degrees in $P_{\rho}\left(\cdot\right)$ compared with $P_{\text{free}}\left(M\right)$ becomes small, leading to more freedom degrees remaining in $P_{\rho}\left(\cdot\right)$. In sum, although it is non-trivial to derive an analytic expression of $S_{\rho}\left(M\right)$, the number of freedom degrees remaining in $P_{\rho}\left(\cdot\right)$, we can use the relative entropy $\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)$ to study the evolution of $S_{\rho}\left(M\right)$ indirectly.

To use the presented framework to analyze percolation in practice, one needs to find an appropriate definition of $M$ depending on $\rho$. In our work, we suggest defining $M$ as the size of the giant cluster for convenience. This definition enables us to study the freedom degree loss related to the emergence of the giant cluster during percolation.

\subsection{A thermodynamics view of freedom degree loss}\label{Sec2-2}
Here we suggest one simple way to identify the role of $\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)$ in thermodynamics. 

We assume that the system associated with $\left( \mathsf{H}\left(M\right),\sigma_{\eta},P_{\text{loss}}\right)$ is at equilibrium with a temperature $T_{\text{loss}}$. This system has two abstract energy levels, which respectively correspond to the microstates counted by $Z_{\eta}\left(M\right)$ (i.e., the percolation configurations $\eta$ that satisfy $L\left(\eta\right)=M$) and the microstates excluded from $Z_{\eta}\left(M\right)$ (i.e., the percolation configurations $\eta$ with $L\left(\eta\right)<M$). Given this definition, we can see that Eq. (\ref{EQ6}) coincides with the assumption that microstates with the same energy level are equally likely to occur. Inspired by this property, we can rewrite Eq. (\ref{EQ6}) in a form of Boltzmann distribution 
\begin{align}
    P_{\text{loss}}\left(\eta\right)=\frac{1}{Z_{\text{loss}}}\exp\left(-\beta_{\text{loss}}U_{\eta}\right),\label{EQ10}
\end{align}
where $\beta_{\text{loss}}=\frac{1}{T_{\text{loss}}}$, notion $U_{\eta}$ denotes the energy level of microstate $\eta$, and $Z_{\text{loss}}=\sum_{\eta\in \mathsf{H}\left(M\right)}\exp\left(-\beta_{\text{loss}}U_{\eta}\right)$. Without loss of generality, we define $U_{\eta}= r_{1}\in\mathbb{R}^{+}$ if $L\left(\eta\right)=M$ and $U_{\eta}=r_{2}\in\mathbb{R}^{+}$ if $L\left(\eta\right)<M$, such that $r_{1}>r_{2}$. To keep consistency between Eq. (\ref{EQ6}) and Eq. (\ref{EQ10}) (i.e., make all microstates follow the lower energy level $r_{2}$ such that Eq. (\ref{EQ6}) holds), we suggest to define $\beta_{\text{loss}}\rightarrow \infty$ (i.e., the low temperature limit). In this case, we can have
\begin{align}
\lim_{\beta_{\text{loss}}\rightarrow \infty}P_{\text{loss}}\left(U_{\eta}=r_{1}\right)&=\lim_{\beta_{\text{loss}}\rightarrow \infty}\frac{\exp\left(-\beta_{\text{loss}}r_{1}\right)}{Z_{\text{loss}}},\label{EQ11}\\&=0,\label{EQ12}
\end{align}
and
\begin{align}
\lim_{\beta_{\text{loss}}\rightarrow \infty}P_{\text{loss}}\left(U_{\eta}=r_{2}\right)&=\lim_{\beta_{\text{loss}}\rightarrow \infty}\frac{\exp\left(-\beta_{\text{loss}}r_{2}\right)}{Z_{\text{loss}}},\label{EQ13}\\&=\frac{1}{\vert \mathsf{H}\left(M\right)\vert-Z_{\eta}\left(M\right)},\label{EQ14}
\end{align}
which are consistent with the distribution in Eq. (\ref{EQ6}). Therefore, we can interpret the situation described by Eq. (\ref{EQ6}) and Eq. (\ref{EQ10}) as a low temperature limit condition.

Similarly, we can rewrite Eq. (\ref{EQ3}) in a form of Boltzmann distribution  
\begin{align}
P_{\text{free}}\left(\eta\right)\simeq \frac{1}{Z_{\text{free}}}\exp\left(-\beta_{\text{free}}U_{\eta}\right),\label{EQ15}
\end{align}
which corresponds to the system at equilibrium with a temperature $T_{\text{free}}$. In Eq. (\ref{EQ15}), we denote $Z_{\text{free}}=\sum_{\eta\in \mathsf{H}\left(M\right)}\exp\left(-\beta_{\text{free}}U_{\eta}\right)$. To ensure that Eq. (\ref{EQ15}) is consistent with Eq. (\ref{EQ3}), we suggest to define $\beta_{\text{free}}\rightarrow 0$ (i.e., the high temperature limit). This definition enables each energy level $r\in\{r_{1},r_{2}\}$ to share the same probability
\begin{align}
\lim_{\beta_{\text{free}}\rightarrow 0}P_{\text{free}}\left(U_{\eta}=r\right)&=\lim_{\beta_{\text{free}}\rightarrow 0}\frac{\exp\left(-\beta_{\text{free}}r\right)}{Z_{\text{free}}},\label{EQ16}\\&=\frac{1}{\vert \mathsf{H}\left(M\right)\vert},\label{EQ17}
\end{align}
which is consistent with Eq. (\ref{EQ3}). Therefore, we suggest that the situation described by Eq. (\ref{EQ3}) and Eq. (\ref{EQ15}) is a high temperature limit condition.

\begin{figure*}[t!]
\includegraphics[width=\columnwidth]{G1.jpg}
\caption{\label{G1} Conceptual illustration of the informational and thermodynamic views of percolation in interacting systems. (a) presents an instance of the percolation configurations (i.e., microstates) contained in space $\mathsf{H}\left(3\right)$ and $\mathsf{H}^{*}\left(3\right)$, where we denote $\mathsf{H}^{*}\left(3\right)$ as the space of percolation configurations $\eta$ with $L\left(\eta\right)=3$ (left part). Meanwhile, a summary of our theoretical framework is provided (right part). (b) shows $\Delta S$ as a function of $M$ for illustration. The asymptotic values are obtained following Eq. (\ref{EQ33}) while the exact values are obtained by numerically calculating Eq. (\ref{EQ29}).} 
\end{figure*}

According to the property of relative entropy \cite{cover1999elements}, we can express $\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)$ as
\begin{align}
    \mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)=S\left(P_{\text{loss}},P_{\text{free}}\right)-S\left(P_{\text{loss}}\right),\label{EQ18}
\end{align}
where $S\left(P_{\text{loss}},P_{\text{free}}\right)$ denotes the cross entropy 
\begin{align}
    &S\left(P_{\text{loss}},P_{\text{free}}\right)\notag\\=&-\sum_{\eta\in \mathsf{H}\left(M\right)}P_{\text{loss}}\left(\eta\right)\log\left(P_{\text{free}}\left(\eta\right)\right),\label{EQ19}\\
    =&\log\left(Z_{\text{free}}\right)+\frac{\beta_{\text{free}}}{Z_{\text{loss}}}\left(\sum_{\eta\in \mathsf{H}\left(M\right)}\exp\left(-\beta_{\text{loss}}U_{\eta}\right)U_{\eta}\right),\label{EQ20}\\
    =&\log\left(Z_{\text{free}}\right)+\beta_{\text{free}}U_{\text{loss}}.\label{EQ21}
\end{align}
In Eq. (\ref{EQ21}), term $U_{\text{loss}}$ denotes the energy of the system described by Eq. (\ref{EQ10}). Because we can derive entropy $S\left(P_{\text{free}}\right)$ as
\begin{align}
S\left(P_{\text{free}}\right)=\log\left(Z_{\text{free}}\right)+\beta_{\text{free}}U_{\text{free}},\label{EQ22}
\end{align}
we can combine Eqs. (\ref{EQ21}-\ref{EQ22}) to further obtain 
\begin{align}
S\left(P_{\text{loss}},P_{\text{free}}\right)=&S\left(P_{\text{free}}\right)-\beta_{\text{free}}\left(U_{\text{free}}-U_{\text{loss}}\right).\label{EQ23}
\end{align}
Finally, we can rewrite Eq. (\ref{EQ18}) as
\begin{align}
&\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)\notag\\=&S\left(P_{\text{free}}\right)-S\left(P_{\text{loss}}\right)-\beta_{\text{free}}\left(U_{\text{free}}-U_{\text{loss}}\right),\label{EQ24}\\
=&\Delta S-\frac{\Delta U}{T_{\text{free}}},\label{EQ25}
\end{align}
where $\Delta S=S\left(P_{\text{free}}\right)-S\left(P_{\text{loss}}\right)$ and $\Delta U=U_{\text{free}}-U_{\text{loss}}$ are used in Eq. (\ref{EQ25}) (please note that $\Delta$ stands for numerical difference rather than derivative). Eq. (\ref{EQ25}) may suggest the role of $\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)$ in thermodynamics. Given the high temperature limit condition in Eq. (\ref{EQ16}), we can readily derive
\begin{align}
\lim_{T_{\text{free}}\rightarrow\infty}\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)=\Delta S,\label{EQ26}
\end{align}
meaning that the concerned relative entropy $\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)$ actually measures the entropy difference between the equilibrium states at low and high temperature limits in our case. This property supports us to apply $\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)$ to studying the thermodynamics underlying percolation.

\subsection{Asymptotic expression of entropy difference}\label{Sec2-3}

To support a practical analysis of the entropy difference discussed in Sec. \ref{Sec2-2}, we present an asymptotic expression of $\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)$ based on several theorems in graph theory.

Let us consider $\{2^{\binom {M} {2}}\}$ and $\{Z_{\eta}\left(M\right)\}$ with $M\in\mathbb{N}^{+}$, which are the series of the total number of percolation configurations (i.e., microstates) in $ \mathsf{H}\left(M\right)$ and the series of the number of percolation configurations whose largest cluster sizes are $M$, respectively. From a graph theory perspective, we are equivalently analyzing the series of the number of graphs and the series of the number of connected graphs formed on $M$ labelled nodes. As suggested by Refs. \cite{wilf2005generatingfunctionology,flajolet2009analytic}, an exponential formula (also referred to as the polymer expansion in physics) can bridge between the exponential generating functions of these two series
\begin{align}
\sum_{M=1}^{\infty}Z_{\eta}\left(M\right)\frac{x^{M}}{M!}=\log\left(1+\sum_{M=1}^{\infty}2^{\binom {M} {2}}\frac{x^{M}}{M!}\right),\label{EQ27}
\end{align}
We can expand the right side of Eq. (\ref{EQ27}) via the Taylor expansion 
\begin{align}
\sum_{M=1}^{\infty}Z_{\eta}\left(M\right)\frac{x^{M}}{M!}=\sum_{n=0}^{\infty}\frac{\left(-1\right)^{n}}{n+1}\left(\sum_{M=1}^{\infty}2^{\binom {M} {2}}\frac{x^{M}}{M!}\right)^{n+1}.\label{EQ28}
\end{align}
Certainly, it is impossible to analytically solve Eq. (\ref{EQ28}) to derive $Z_{\eta}\left(M\right)$. However, we can reorganize Eq. (\ref{EQ28}) and compare between its left and right sides to find an appropriate expression of coefficient term $Z_{\eta}\left(M\right)$. Specifically, we can observe an intricate expression using the method proposed in Ref. \cite{flajolet2009analytic}
\begin{widetext}
\begin{align}
Z_{\eta}\left(M\right)&=2^{\binom {M} {2}}+\sum_{k=2}^{\infty}\frac{\left(-1\right)^{k+1}}{k}\left[\sum_{M_{1}+\ldots+M_{k}=M}\binom {M} {M_{1},\ldots,M_{k}}2^{\sum_{i=1}^{k}\binom {M_{i}} {2}}\right],\label{EQ29}\\
&=2^{\binom {M} {2}}-\frac{1}{2}\left[\sum_{M_{1}+M_{2}=M}\binom {M} {M_{1},M_{2}}2^{\binom {M_{1}} {2}+\binom {M_{2}} {2}}\right]+o\left(-\frac{1}{2}\left[\sum_{M_{1}+M_{2}=M}\binom {M} {M_{1},M_{2}}2^{\binom {M_{1}} {2}+\binom {M_{2}} {2}}\right]\right),\label{EQ30}
\end{align}
\end{widetext}
where $o\left(\cdot\right)$ denotes an infinitesimal of higher order. Here Eq. (\ref{EQ30}) is derived from the fact that the first term in the summation in Eq. (\ref{EQ29}) exhibits predominance in determining the result of summation. Moreover, after analyzing all possible combinations of $\left(M_{1},M_{2}\right)$ in the predominant term of Eq. (\ref{EQ30}), we find that $\left(M_{1}=M-1,M_{2}=1\right)$ and $\left(M_{1}=1,M_{2}=M-1\right)$ are predominant while other combinations are more negligible. Therefore, we can approximate Eq. (\ref{EQ30}) as
\begin{align}
Z_{\eta}\left(M\right)&=2^{\binom {M} {2}}\left(1-M2^{-M+1}+o\left(2^{-M+1}\right)\right).\label{EQ31}
\end{align}

Based on Eq. (\ref{EQ31}), we can derive an asymptotic expression of $\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)$
\begin{align}
\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)&=\log\left(\frac{1}{M2^{-M+1}-o\left(2^{-M+1}\right)}\right),\label{EQ32}
\\
&=\left(M-1\right)\log\left(2\right)-\log\left(M\right)+o\left(1\right),\label{EQ33}
\end{align}
which can be practically used in application. According to Eq. (\ref{EQ33}), the entropy difference measured by $\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)$ asymptotically equals to $M\left(\log\left(2\right)+o\left(1\right)\right)$, serving as an extensive property at the thermodynamic limit. Please see Fig. \ref{G1}(b) for an illustration.

\subsection{Thermodynamics associated with percolation}\label{Sec2-4}
For a brief summary, we have suggested to consider $\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)$ as an measure of freedom degree loss during percolation in Sec. \ref{Sec2-1}, which indirectly measures the remaining freedom degrees in distribution $P_{\rho}\left(\cdot\right)$. From an information theory perspective, an increasing $\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)$ indicates the departure of $P_{\text{loss}}\left(\cdot\right)$ from the maximum entropy state, implying more freedom degrees in $P_{\rho}\left(\cdot\right)$. From a thermodynamics perspective shown in Sec. \ref{Sec2-2}, we suggest to understand $\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)$ as the entropy difference $\Delta S$ between the systems at low and
high temperature limits. In Sec. \ref{Sec2-3}, an asymptotic expression of this entropy difference is presented. Fig. \ref{G1} summarizes our key idea. 


Based on the framework presented above, we mainly study the entropy difference itself and its corresponding specific heat difference
\begin{align}
\Delta C=\rho\frac{\partial }{\partial \rho}\left(M\left(\rho\right)-1\right)\log\left(2\right)-\log\left(M\left(\rho\right)\right)+o\left(1\right),\label{EQ34}
\end{align}
in subsequent analysis, where we explicitly indicate $M$ as a function of $\rho$ during percolation. Similar to $\Delta S$, the proposed $\Delta C$ measures the difference of specific heat between the systems at low and high temperature limits. As $\Delta C$ increases, the specific heat corresponding to distribution $P_{\rho}\left(\cdot\right)$ (i.e., remaining freedom degrees) is expected to decrease.

To precisely characterize the phase transition emerged during the correlated behaviour propagation modelled by percolation, we consider the following critical exponents  
\begin{align}
     \Delta C &\propto \vert\rho-\rho_{c}\vert^{-\alpha},\label{EQ35}\\
     \rho_n&\propto \vert\rho-\rho_{c}\vert^\beta,\label{EQ36}\\
     \chi&\propto \vert\rho-\rho_{c}\vert^{-\gamma},\label{EQ37}
\end{align}
if the phase transition is continuous, where $\rho_{c}$ denotes the critical point, notion $\rho_{n}$ measures the probability for
a random node to belong to the giant cluster, and $\chi$ is the mean size of all finite clusters. While Eqs. (\ref{EQ36}-\ref{EQ37}) have been extensively explored in percolation theories \cite{li2021percolation}, Eq. (\ref{EQ35}) directly depends on our theory. After deriving these critical exponents, we pursue to verify the Rushbrooke inequality 
\begin{align}
     \alpha+2\beta+\gamma\geq 2,\label{EQ38}
\end{align}
which is a well known scaling relation \cite{domb2000phase,stanley1971phase}.


\section{Application on percolation and interacting systems}

\subsection{Bernoulli percolation process}\label{Sec3-1}

 \begin{figure*}[t!]
\includegraphics[width=\columnwidth]{G2.jpg}
\caption{\label{G2} Continuous phase transition modelled by the Bernoulli and the bootstrap percolation. The derived $\Delta S$, $\Delta C$, $\rho_{n}$, and $\chi$ are presented as the functions of corresponding control parameters. Meanwhile, a linear fitting with least square method is applied to estimate the critical exponents defined in Eqs. (\ref{EQ35}-\ref{EQ37}) based on the data near critical points. (a-g) show the results of the Bernoulli percolation while (h-n) present the results of the bootstrap percolation.} 
\end{figure*}

\begin{table*}[!t]
\centering
\renewcommand\arraystretch{1}
\small{
\begin{tabular}{lcccl}
\hline
 Phase transition model & $\alpha$                      & $\beta$                      & $\gamma$     & $\alpha+2\beta+\gamma$                                                       \\\hline
Bernoulli percolation & $0.170\pm 0.018$ ($R^{2}=0.977$) & $0.863\pm 0.011$ ($R^{2}=0.999$) & $0.157\pm 0.004$ ($R^{2}=0.997$) & $2.053\pm 0.044$  \\
Bootstrap percolation &  $0.361\pm 0.010$ ($R^{2}=0.996$) & $0.968\pm 0.007$ ($R^{2}=0.999$) & $1.410\pm 0.093$  ($R^{2}=0.949$) & $3.707\pm 0.117$  \\
 \hline
\end{tabular}
}
\caption{\label{Tab1}Critical exponents of the Bernoulli percolation and the bootstrap percolation. We report the estimated value $\pm$ the radius of $95\%$ confidence interval for each critical exponent, accompanied by the fitting accuracy measured by $R^{2}$.}
\end{table*}

As the most simple instance, we first illustrate a Bernoulli percolation process on network controlled by occupation probability $\rho$ \cite{georgakopoulos2018analyticity}. The initial network is a complete graph with $\vert V\vert=100$ nodes.
	
To measure $\Delta S$ and $\Delta C$, we need to derive $M$, the size of the giant cluster of correlated units, as a function of $\rho$. According to the generating function approach \cite{li2021percolation}, the probability for a random node to belong to the giant cluster, $\rho_{n}$, and the probability for a random edge to belong to the giant cluster, $\rho_{e}$, obey the following relations
\begin{align}
		\rho_{e}&=1-\sum_{k}P_{k}\frac{k}{\sum_{k}kP_{k}}\left(1-\rho_{e}\rho\right)^{k},\label{EQ39}\\
		\rho_{n}&=1-\sum_{k}P_{k}\left(1-\rho_{e}\rho\right)^{k},\label{EQ40}
\end{align}
where $P_{k}$ denotes the probability of finding a node with $k$ degrees in the corresponding graph of the interacting system. In practice, one can first solve Eq. (\ref{EQ39}) and insert $\rho_{e}$ into Eq. (\ref{EQ40}) to derive $\rho_{n}$. Given a $\rho_{n}$, the size of giant cluster can be directly obtained as
\begin{align}
M=\lfloor\rho_{n}\vert V\vert\rfloor. \label{EQ41}
\end{align} 
 These derivations enable us to calculate $\Delta S$ and $\Delta C$.


In Figs. \ref{G2}(a-d), we show $\Delta S$, $\Delta C$, $\rho_{n}$ (the order parameter of the Bernoulli percolation), and $\chi$ (the mean size of finite clusters is numerically counted) as the functions of $\rho$ (the control parameter), respectively. It can be seen that our proposed $\Delta S$ and $\Delta C$ precisely capture the phase transition at the critical point (i.e., percolation transition threshold) $\rho_{c}$ \cite{li2021percolation,moore2000exact,newman2001random} 
	\begin{align}
		\rho_{c}&=\left(\frac{\partial }{\partial x} \sum_{k}P_{k}\frac{k}{\sum_{k}kP_{k}}x^{k-1}\Bigg\vert_{x=1}\right)^{-1},\label{EQ42}\\
  &=\frac{1}{\vert V\vert-2}.\label{EQ43}
	\end{align}
As the phase transition happens, the sharp increase of entropy difference $\Delta S$ suggests the rapid departure of distribution $P_{\text{loss}}\left(\cdot\right)$ from the maximum entropy state, implying that lost freedom degrees become increasingly negligible and $P_{\rho}\left(\cdot\right)$ contains most part of information of the statistical ensemble. The proposed specific heat difference $\Delta C$ diverges at the critical point, which meets the common behaviour of specific heat in most critical phenomena. Applying a log-log linear fitting on $\Delta C$, $\rho_{n}$, and $\chi$ near the critical point, we derive the concerned critical exponents, which are shown in Table. \ref{Tab1}. According to the estimated results, the Rushbrooke
inequality in Eq. (\ref{EQ35}) generally holds because $2$ is covered by the $95\%$ confidence interval of the estimated $\alpha+2\beta+\gamma$.
 

\subsection{Bootstrap percolation process}\label{Sec3-2}

We also consider the bootstrap percolation \cite{adler1988diffusion,baxter2010bootstrap}, a variant of the $k$-core percolation\cite{dorogovtsev2006k} that describes an activation processes, as a more complicated illustration of continuous phase transition. Specifically, we implement a bootstrap percolation controlled by an initial activation fraction $f$ in a random regular network of $100$ nodes with degree $k$, where one node can be activated if at least $k^{*}$ of its neighbors are activated. 

For convenience, we consider the case where $k=3$ and $k^*=2$. Following Ref. \cite{di2019insights}, we need to first solve the following equations
\begin{align}
    \lambda&=\varepsilon-f\left(1-\lambda-\sigma\right)^{2}-\left(1-f\right)\left(\varepsilon-\lambda\right)^{2}\label{EQ44},\\
\sigma&=2\left(1-f\right)\left[\varepsilon\left(1-\varepsilon\right)-\left(\varepsilon-\lambda\right)\left(1-\varepsilon-\sigma\right)\right],\label{EQ45}
\end{align}
where $\varepsilon=\min\left(\frac{f}{1-f},1\right)$. Then, the order parameter (i.e.,  the probability for
a random node to belong to the giant cluster) is given as
\begin{align}
    \rho_n=&f+\left(1-f\right)\left[\varepsilon^3+3\varepsilon^2(1-\varepsilon+3\varepsilon\left(1-\varepsilon\right)^2\right]\notag\\&-f\left(1-\lambda-\sigma\right)^3\notag\\&-\left(1-f\right)\Big[\left(\varepsilon-\lambda\right)^3+3\left(1-\varepsilon-\sigma\right)\left(\varepsilon-\lambda\right)^2\notag\\&+3\left(\varepsilon-\lambda\right)\left(1-\varepsilon-\sigma\right)^2\Big].\label{EQ46}
\end{align}


Based on these derivations, we can subsequently obtain $\Delta S$, $\Delta C$, $\rho_{n}$, and $\chi$ (numerically counted) as the functions of $f$. These results are presented in Figs. \ref{G2}(h-k) in a way similar to our analysis of the Bernoulli percolation. As $f$ increases from $0$ to $1$, a phase transition appears around $f=0.125$, which can be derived by the marginal stability analysis at the fixed point $\left(\lambda,\sigma\right)=\left(0,0\right)$ of Eqs. (\ref{EQ44}-\ref{EQ45}). As shown in our results, the phase transition can be accurately captured by the trends of $\Delta S$ and $\Delta C$. By implementing the log-log linear fitting on the data near the critical point, we obtain the critical exponents shown in Table. \ref{Tab1} that satisfy the Rushbrooke
inequality in Eq. (\ref{EQ35}). Different from the Bernoulli percolation, the estimated value of $\alpha+2\beta+\gamma$ divides from $2$ more significantly, which may arise from the less sharp increase of $\Delta S$ and the more sharp drop of $\chi$ near the critical point (i.e., see the relatively larger values of $\alpha$ and $\gamma$ in Table. \ref{Tab1}). Given that $\Delta S$ reflects the departure of $P_{\text{loss}}\left(\cdot\right)$ from the maximum entropy state (i.e., the reduction of lost freedom degrees), we suggest that the increase speed of the number of remaining freedom degrees in $P_{f}\left(\cdot\right)$ (i.e., the counterpart of $P_{\rho}\left(\cdot\right)$ in the bootstrap percolation) is smaller than the situation of the Bernoulli percolation.

\subsection{Synchronization }
Apart from the standard continuous phase transitions modelled by the Bernoulli percolation and the bootstrap percolation, we also consider more complicated propagation phenomena of correlated behaviours in complex interacting systems. In this section, we primarily focus on synchronization, a widespread phenomenon in diverse interacting systems, such as brains, social networks, and bird flocks \cite{boccaletti2002synchronization,arenas2008synchronization,boccaletti2016explosive,ghosh2022synchronized}.

\begin{figure*}[t!]
\includegraphics[width=\columnwidth]{G3.jpg}
\caption{\label{G3} Phase transition in the Kuramoto model. (a-e) The derived $\frac{\partial}{\partial \kappa}\mathbb{E}\left(r\right)$, $\Delta S$, $\Delta C$, $\rho_{n}$, and $\chi$ are presented as the functions of $\kappa$. (f-h) A linear fitting is applied to estimate the critical exponents in Eqs. (\ref{EQ35}-\ref{EQ37}) based on the data near critical point.} 
\end{figure*}

\begin{table*}[!t]
\centering
\renewcommand\arraystretch{1}
\small{
\begin{tabular}{lcccl}
\hline
 Interacting system & $\alpha$                      & $\beta$                      & $\gamma$     & $\alpha+2\beta+\gamma$                                                       \\\hline
Kuramoto model & $0.347\pm 0.038$ ($R^{2}=0.892$) & $1.15\pm0.025$ ($R^{2}=0.976$) & $1.71\pm 0.26$ ($R^{2}=0.746$) & $4.357\pm 0.348$  \\
 \hline
\end{tabular}
}
\caption{\label{Tab2}Critical exponents of the Kuramoto model. We report the estimated value $\pm$ the radius of $95\%$ confidence interval for each critical exponent, accompanied by the fitting accuracy measured by $R^{2}$.}
\end{table*}

The Kuramoto model, a model of coupled phase oscillators, is a representative framework for analyzing synchronization \cite{rodrigues2016kuramoto,acebron2005kuramoto}. For convenience, we consider the classic Kuramoto model with $\vert V\vert$ oscillators \cite{rodrigues2016kuramoto,acebron2005kuramoto}
	\begin{align}
		\frac{\partial}{\partial t}\theta_{i}\left(t\right)=\omega_{i}+\frac{\kappa}{\vert V\vert}\sum_{i=1}^{\vert V\vert}\sin\left[\theta_{j}\left(t\right)-\theta_{i}\left(t\right)\right], \label{EQ47}
	\end{align}
	where $\theta_{i}$ and $\omega_{i}$ denote the phase and natural frequency of the $i$-th oscillator, respectively. Parameter $\kappa$ measures the coupling strength among oscillators. The order parameter of the above interacting system is 
	\begin{align}
		r\left(t\right)\exp\left[\mathsf{i}\psi\left(t\right)\right]=\frac{1}{\vert V\vert}\sum_{i=1}^{\vert V\vert}\exp\left[\mathsf{i}\theta_{j}\left(t\right)\right], \label{EQ48}
	\end{align}
	in which $\psi\left(t\right)$ is the time-dependent average phase and $r\left(t\right)\in\left[0,1\right]$ measures the synchronization degree of the system. Based on the order parameter, we can reorganize Eq. (\ref{EQ47}) as
	\begin{align}
		\frac{\partial}{\partial t}\theta_{i}\left(t\right)=\omega_{i}+\kappa r\left(t\right)\sin\left[\psi\left(t\right)-\theta_{i}\left(t\right)\right]. \label{EQ49}
	\end{align}
	According to Eq. (\ref{EQ49}), a feedback loop exists between coupling strength $\kappa$ and order parameter $r$, i.e., any increment in $r$ due to the increasing $\kappa$ will enlarge the effective
	coupling among oscillators and attract more oscillators to the synchronous populations in return \cite{rodrigues2016kuramoto,acebron2005kuramoto}.

 To relate the Kuramoto model with our theory, we define a correlation matrix $C$ in terms of synchronization
	\begin{align}
		C_{ab}&=\mathbb{E}\left[r_{ab}\left(t\right)\right], \label{EQ50}\\
		r_{ab}\left(t\right)\exp\left[\mathsf{i}\psi\left(t\right)\right]&=\frac{1}{2}\left\{\exp\left[\mathsf{i}\theta_{a}\left(t\right)\right]+\exp\left[\mathsf{i}\theta_{b}\left(t\right)\right]\right\}, \label{EQ51}
	\end{align}
	where the $\left(a,b\right)$-th entity measures the local synchronization degree between oscillators $a$ and $b$. Then we generate the network of oscillators, where there exists an edge between oscillators $a$ and $b$ only if $C_{ab}\simeq 1$, i.e., these two oscillators are strongly synchronous. Here we do not require $C_{ab}= 1$ because numerical errors may lead to a non-one synchronization degree even if oscillators $a$ and $b$ are strictly synchronous (during computation, we determine $C_{ab}\simeq 1$ if $C_{ab}\geq 1-10^{-3}$). Given the network under each condition of $\kappa$, we can measure the size of giant cluster and the mean size of finite cluster to numerically derive $\Delta S$, $\Delta C$, $\rho_{n}$, and $\chi$.
	
 We define a Kuramoto model with $100$ oscillators. Each oscillator has a random natural frequency uniformly selected from $\left[1,5\right]$ and exhibits activities for $1000$ time steps. All oscillators are initialized with a random phase selected from $\left[-\pi,\pi\right]$. We set an increasing coupling strength $\kappa\in\left[0,5\right]$ and repeat the experiment under each condition of $\kappa$ for $80$ times. Given each $\kappa$, We denote $\mathbb{E}\left(r\right)$, the mean order parameter derived by time-averaging (i.e, average across time steps) and realization-averaging (i.e., average across repeats), as the expected synchronization degree. In Figs. \ref{G2}(b-d), the derived $\Delta S$, $\Delta C$, $\rho_{n}$, and $\chi$ are suggested to accurately reflect the disorder-order phase transition around $\kappa\simeq 2.5$ characterized by the sharp increase of $\frac{\partial}{\partial \kappa}\mathbb{E}\left(r\right)$ in Fig. \ref{G2}(a). In other words, these concepts can reflect the emerging synchronization within the system. Applying the log-log linear fitting on the data near $\kappa\simeq 2.5$, we derive the critical exponents shown in Table. \ref{Tab2} to suggest that the Rushbrooke
inequality in Eq. (\ref{EQ35}) generally holds. Similar to the situation of the bootstrap percolation, the estimated value of $\alpha+2\beta+\gamma$ significantly divides from $2$ due to the less sharp increase of $\Delta S$ and the more intense drop of $\chi$ near the critical point compared with the Bernoulli percolation.

\section{Conclusion}
Percolation on networks is a natural choice for modelling the propagation of correlated behaviours in interacting systems. However, as an abstract model of phase transitions, percolation lacks direct connections with thermodynamics or information, two fundamental aspects of physics mechanisms \cite{jaynes1957information}. Although substantial progress has been achieved in relating percolation and thermodynamic formalization of phase transitions \cite{hassan2017entropy,radicchi2009explosive,ziff2010scaling,bastas2011explosive,fortuin1972random,hassan2016universality}, previous accomplishments are less applicable to complex interacting systems, may lack analytic tools to measure thermodynamic concepts, and are limited in shedding light on the informational aspect of percolation.

In this work, we have suggested a unified way to study the informational and thermodynamic aspects of percolation in interacting systems. On the informational side, we focus on analyzing the freedom degree loss caused by percolation process. We find that $\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)$ can help us understand how much information is lost or kept during percolation even though the actual distribution of the system, $P_{\rho}\left(\cdot\right)$, is unknown. As $\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)$ enlarges, the distribution of lost freedom degrees, $P_{\text{loss}}\left(\cdot\right)$, departs from the maximum entropy state, which coincides with $P_{\text{free}}\left(\cdot\right)$ in our question. Therefore, an increasing $\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)$ suggests more freedom degrees remaining in $P_{\rho}\left(\cdot\right)$. On the thermodynamic side, we suggest that $\mathbb{D}\left(P_{\text{loss}}\Vert P_{\text{free}}\right)$ equals the entropy difference $\Delta S$ between the equilibrium states of the system at low and high temperature limits. This equivalence relation enables us to measure the thermodynamic evolution underlying percolation by entropy difference and specific heat difference $\Delta C$. To support mathematical analysis and application, all important concepts are equipped with asymptotic expressions. Given the proposed informational and thermodynamic properties of percolation, we are interested in their behaviours near critical points, which serve as necessary tests for their applicability in analyzing phase transition phenomena. We have applied our framework on the Bernoulli percolation \cite{georgakopoulos2018analyticity}, the bootstrap percolation \cite{di2019insights}, and the synchronization described by the Kuramoto model \cite{rodrigues2016kuramoto,acebron2005kuramoto}. The obtained results suggest that $\Delta S$ and $\Delta C$ can precisely capture diverse kinds of phase transitions and exhibit sharp changes at critical points. Meanwhile, the critical exponents associated with $\Delta C$ and other parameters of percolation satisfy the Rushbrooke inequality. The division of the Rushbrooke inequality from the equality condition seems to naturally distinguish between different types of phase transitions.

In sum, this work suggests the possibility to deepen our understanding of percolation in the aspects of information and thermodynamics. The proposed analytic framework may serve as a practical tool for analyzing real interacting systems.



	
\section*{Acknowledgements}
	This project is supported by the Artificial and General Intelligence Research Program of Guo Qiang Research Institute at Tsinghua University (2020GQG1017) as well as the Tsinghua University Initiative Scientific Research Program. 
	
	% The \nocite command causes all entries in a bibliography to be printed out
	% whether or not they are actually referenced in the text. This is appropriate
	% for the sample file to show the different styles of references, but authors
	% most likely will not want to use it.
	% Produces the bibliography via BibTeX.
	%\appendix
	
	%\nocite{*}
	\bibliography{apssamp}
\end{document}
%
% ****** End of file apssamp.tex ******
