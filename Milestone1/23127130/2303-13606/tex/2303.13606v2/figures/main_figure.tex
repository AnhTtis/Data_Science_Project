\begin{figure*}[t]
  \centering
  %\fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
  \includegraphics[width=\linewidth]{figures/adasim_iccv2023_new.pdf}

  %\caption{\textbf{Overview of AdaSim.} Given an input image $\im_i$, we obtain two latent representations $\glob_i = f(t(\im_i))$ and $\glob_i^{'} = f'(t'(\im_i))$. Additionally, we sample another image $\im_{j^\star}$ in the dataset from $p^{win}(\im_j|\im_i)$ (see \cref{eq:similarity_distribution_windowed} and \cref{eq:p_im_dataset_windowed}) and obtain its latent representation $\glob_{j^\star}^{'} = f'(t'(\im_{j^\star}))$. We adaptively enforce a self-distillation loss $L$ between $\glob_i$ and $\glob_i^{'}$ or between $\glob_i$ and $\glob_{j^\star}^{'}$ here illustrated with a switch. In practice, only one of $\glob_i^{'}$ or $\glob_{j^\star}^{'}$ will be computed, see \cref{sec:adaptive_similarity_bootstrapping} and \cref{alg:adasim} for more details.}
  \caption{\textbf{Overview of AdaSim.} Given an input image $\im_i$, we obtain the latent representation $\glob_i = f(t(\im_i))$. Additionally, we sample another image $\im_{j^\star}$ in the dataset from $p^{win}(\im_j|\im_i)$ (see \cref{eq:similarity_distribution_windowed} and \cref{eq:p_im_dataset_windowed}) and obtain its latent representation $\glob_{j^\star}^{'} = f'(t'(\im_{j^\star}))$. A self-distillation loss $\mathcal{L}$ is enforced between $\glob_i$ and $\glob_{j^\star}^{'}$. For the sake of simplicity, only the scenario using bootstrapping is illustrated (see~\cref{alg:adasim}). Data augmentations are represented with grayscale bounding boxes.}
  \label{fig:main_figure}
\end{figure*}