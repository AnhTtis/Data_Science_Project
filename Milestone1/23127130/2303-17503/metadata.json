{
    "arxiv_id": "2303.17503",
    "paper_title": "Pgx: Hardware-Accelerated Parallel Game Simulators for Reinforcement Learning",
    "authors": [
        "Sotetsu Koyamada",
        "Shinri Okano",
        "Soichiro Nishimori",
        "Yu Murata",
        "Keigo Habara",
        "Haruka Kita",
        "Shin Ishii"
    ],
    "submission_date": "2023-03-29",
    "revised_dates": [
        "2023-10-31"
    ],
    "latest_version": 3,
    "categories": [
        "cs.AI",
        "cs.LG"
    ],
    "abstract": "We propose Pgx, a suite of board game reinforcement learning (RL) environments written in JAX and optimized for GPU/TPU accelerators. By leveraging JAX's auto-vectorization and parallelization over accelerators, Pgx can efficiently scale to thousands of simultaneous simulations over accelerators. In our experiments on a DGX-A100 workstation, we discovered that Pgx can simulate RL environments 10-100x faster than existing implementations available in Python. Pgx includes RL environments commonly used as benchmarks in RL research, such as backgammon, chess, shogi, and Go. Additionally, Pgx offers miniature game sets and baseline models to facilitate rapid research cycles. We demonstrate the efficient training of the Gumbel AlphaZero algorithm with Pgx environments. Overall, Pgx provides high-performance environment simulators for researchers to accelerate their RL experiments. Pgx is available at http://github.com/sotetsuk/pgx.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.17503v1",
        "http://arxiv.org/pdf/2303.17503v2",
        "http://arxiv.org/pdf/2303.17503v3"
    ],
    "publication_venue": null
}