% The provenance of an object informs its ownership, history, and origin. It can influence the perception of the object itself. For example, the provenance of a painting reveals who the original artist was, which can impact its value. 

% despite technical robustness, provenance adoption in real-world systems may be feeble unless usability challenges are addressed.


``Seeing is believing'' is no longer the case on modern social media. From the COVID-19 pandemic \cite{pennycook2020fighting}, to elections around the world \cite{ap-twitter-labels}, to mundane topics such as butter consumption \cite{snopes-butter}, visual misinformation is abound. Manipulated media has consequences that are both substantial and persistent---previous work has shown that forged images can distort memory through false confirmation bias \cite{Strange2011-ye, wade2002picture} and, with the right image, can even threaten the legitimacy of democratic decision-making procedures \cite{resende2019whatsapp}. Even if an individual comes to terms with the truth behind a deceptive edit, the warped perceptions to which they were exposed can linger \cite{sacchi2007changing}. The severity and scale of media manipulation has led many to study interventions and systems to visually flag misleading images and videos to viewers \cite{dias2020emphasizing, jahanbakhsh2021nudges, morris2012tweeting, lazer2018science, ozturk2015combating, zhang2018structured}, powered by algorithmic detection mechanisms \cite{hu2020span, li-fast, cozz-cnn} as well as human crowdsourced ones \cite{birdwatch, bhuiyan2020experts}. However, algorithmic solutions are far from perfect \cite{seo2019trust, brandtzaeg2018journalists}, and the breakneck speed of media distribution often far surpasses the speed at which human fact-checkers can flag content. Further, increasingly sophisticated algorithmic detection techniques come with increasingly sophisticated methods to deceive such techniques \cite{gragnaniello2018analysis, hussain2021adversarial, rozsa2020adversarial}, resulting in an unending cat-and-mouse game. These factors make today's inherently reactive methods insufficient in the fight against large-scale proliferation of fake media. 

Exposing media provenance information to social media users is an appealing proposition in the midst of the visual misinformation crisis. \add{In line with definitions outlined by the Coalition for Content Provenance and Authenticity (C2PA),\footnote{\url{https://c2pa.org/}} we use \textit{provenance} to refer} to basic facts about the origins of a piece of digital media (e.g., image, video), which may include information such as the author and the date, time, and location at which the media was created or edited \add{\cite{c2pa-explainer}}. Technical standards for provenance, such as the C2PA standard \cite{c2pa}, allows media authoring tools to embed cryptographically signed provenance information into media metadata \textit{in tandem with} content creation to create a growing provenance chain as the media is shared and remixed. Information within a chain can then be displayed to users through a user interface (UI) overlaid on social media platforms, providing \textit{on-demand} information to users and fact checkers alike to make a more informed credibility judgement~\cite{emily2022usable}.
% Instead of a reactive fact-checking approach where fact checkers must always play catch-up with content, provenance information is assembled \textit{in tandem with} content creation and can be made available  to empower users and fact checkers alike to make a more informed credibility judgement \cite{emily2022usable}. 
While academic scholars and industry practitioners have noted the potential of provenance in improving media trust through transparency and accountability \cite{gundecha2013tool, npp} and have developed technical infrastructures to support provenance \cite{aythora2020multi, arweave, cai,starling, project-origin}, a key question remains: \textit{how does provenance change user perceptions of media in a social media feed?}

In this work, we present an online experiment with 595 US- and UK-based participants to examine the impact of media provenance information on user perception of image and video content in a social media feed. Participants are assigned to a mock Twitter-like feed and rate their perceptions of trust and accuracy of visual content on that feed. They are then exposed to the same feed, but with the addition of media provenance information, and are once again asked to rate perceived trust accuracy. Unlike previous work, our study integrates specifications from the C2PA standard \cite{c2pa-ux} into an interactive feed, which allows us to directly compare participant evaluations of media on a regular feed to one that contains special UIs exposing media provenance information on demand. We refer to the latter as \textit{provenance-enabled} feeds.


First, we examined how introducing provenance information
 changes participants' credibility perceptions of media content. 
% \add{\subsection{Key Terminology and Research Questions}}
% \add{We outline some key terminology grounded in prior work that we use as foundational material for our study, followed by our main research questions.}
\add{Credibility is a multi-faceted construct comprising subjective and objective measurements \cite{bhuiyan2020experts, hilligoss2008developing}. Because its dimensions are too complex to fully capture in one study without inducing significant participant fatigue, we operationalize it in our study using two measurements: trust and perceived accuracy of a claim. We characterize \textbf{Trust} as a self-reported measure of the degree to which a particular piece of media offers reliable information \cite{heuer2018trust, pennycook2019fighting, epstein2020distrusted}, and
perceived accuracy of a claim, or simply \textbf{Perceived Accuracy}, as the extent to which a participant agrees with the claim associated with a particular piece of media \cite{clayton2020real, kirchner2020countering, jahanbakhsh2021nudges, berry2018believability, riggio1987social}. Given these two dimensions, we ask the following question:}

\begin{itemize}
     \item  \textbf{RQ.1}: Is there a significant difference in trust and perceived accuracy before and after interaction with a provenance-enabled feed?
\end{itemize}

\add{In addition to knowing \textit{whether} users' perceptions shifted, we want to identify the \textit{direction} of shift---towards or away from ground truth---to determine the efficacy of provenance in combating visual misinformation. Prior work has found interventions that reduce belief in both true and false information and are thus unhelpful overall  \cite{dias2020emphasizing, lee2023priming}. We measure the correction of one's perceived accuracy of a claim, or simply \textbf{Correction}, as how much closer one's perception of accuracy for a claim moves towards the ground truth of that claim after an intervention~\cite{brashier2021timing, pennycook2018prior}.}  Thus, we ask:

\begin{itemize}
    \item \textbf{RQ.2}: Does exposure to provenance information correct misled judgements of truth in deceptive media (both explicitly deceptive through heavy editing or subtlely deceptive via miscaptioning), and preserve correct judgements of truth in honest media?
\end{itemize}
% \end{itemize}}

% trust
% perceived accuracy of claim (accuracy)
% accuracy correction
% credibility

\remove{To measure trust and truth judgements, we collected ratings on 1) how much the participant trusts a particular piece of media to offer reliable information, and 2) how much the participant agrees with a claim (which may be true or false) made about what the media purports to depict. We refer to these two measures as ``trust'' and ``claim agreement'' (we simplify the latter to simply ``agreement''). }

\add{There will be messiness in any real-world deployment of a new technical standard (e.g., HTTPS \cite{bernhard2019https}) as a result of uneven adoption, differences in implementation, and potential malicious and evasive actors \cite{emily2022usable}. Thus, we expect that the provenance chains of a non-trivial quantity of media would be incomplete or invalid in some way \cite{c2pa-ux, c2pa-explainer} for a significant period of time after initial launch. In our provenance-enabled feeds, we vary some of the media items to show incomplete or invalid provenance and measure changes in participant perception. In particular, we ask:}

\begin{itemize}
    \item \textbf{RQ.3}: Are there significant differences in changes in trust, perceived accuracy, and correction upon introduction of incomplete and invalid provenance states?
\end{itemize}


% \subsection{Research questions}

%Our research questions are shown in Table \ref{t:rq}.

% \begin{table}[h]
% \centering
%     \begin{tabular}[h]{p{1cm} p{13cm}}
%     \toprule
%     ID & Description \\
%     \midrule 
%     RQ.1 & Is there a significant difference in trust and agreement before and after interaction with a provenance-enabled feed? \\
%     %H.1 & There will be significant differences in both trust and agreement. The direction of change will vary based on the content.\\
%     %\midrule
%     RQ.2 & Does exposure to provenance information correct misled judgements of truth in deceptive media, and preserve correct judgements of truth in honest media?\\
%     %H.2 & Provenance will help shift perceptions closer to the truth, or preserve perceptions if they are already accurate.\\
%     %\midrule
%     RQ.3 & Are there significant differences in changes in trust, agreement, and truth correction upon introduction of incomplete and invalid provenance states? \\
%     %H.3 & There will be significant differences---incomplete and invalid states will decrease trust, while only the invalid state will decrease agreement. Truth correction should still match H.2.\\
%     %\midrule
%     RQ.4 & Are there significant differences in changes in trust, agreement, and truth correction, as well as general comprehension, across provenance indicator design and language variations?\\
%     %H.4 & Indicator design may induce significant differences, but not language variations. Indicators that expose more state information should have an effect similar to ones in H.3 compared to those exposing less.\\
%     \bottomrule
%     \end{tabular}
%     \caption{Table of our research questions.}
%     \label{t:rq}
% \end{table}

\add{Finally, the concept of a verified provenance chain, as well as the term ``provenance'' itself, may be unfamiliar to many. In social media settings where screen real estate is limited, icons and succinct language are often used to represent standards, such as the AdChoices program \cite{adchoices}. We explore the impact of varying provenance terminology and indicator design:}

\begin{itemize}
    \item \textbf{RQ.4}: Are there significant differences in changes in trust, perceived accuracy, and correction, as well as general comprehension, across provenance indicator design and terminology variations?
\end{itemize}

% We found that trust and agreement post-provenance were mostly lower to a statistically significant degree when participants encountered deceptive media \add{(see Fig. \ref{fig:visual-summary})}, but this was partly influenced by the display of credibility in the provenance information itself. Perceptions of media that had been composited---combined from two or more media sources for deceptive purposes---became less favourable (e.g., lower trust and agreement\add{; see last 3 columns of Fig. \ref{fig:visual-summary}}), while the direction of change was mixed for non-composited media \add{(see Trust and Agreement columns for Non-composited in Fig. \ref{fig:visual-summary})}. Provenance did indeed help with correcting truth judgements towards deceptive media, but it also ``overcorrected'' and shifted perceptions further away from the truth in some non-deceptive media. Regarding provenance states, we found that media indicating provenance incompleteness or invalidity had, to a significant level, lower trust and agreement than counterparts that did not show those states \add{(see last two rows of Fig. \ref{fig:visual-summary})}. This suggests that users struggle to differentiate the related but orthogonal concepts of \textit{provenance} credibility and \textit{content} credibility. 


We found that provenance did indeed have a significant effect on credibility perception. Trust and perceived accuracy post-provenance were mostly lower when participants encountered deceptive media. In particular, perceptions of media that had been composited---combined from two or more media sources for deceptive purposes---became less favourable (e.g., lower trust and perceived accuracy), while the direction of change was mixed for non-composited media. Provenance helped correct truth judgements towards deceptive media, but it also ``overcorrected'' in some cases and shifted perceptions further away from the truth in some non-deceptive media. Provenance state also influenced judgements. Media indicating provenance incompleteness or invalidity had lower trust and perceived accuracy than counterparts that did not show those states. This suggests that users struggle to differentiate the related but orthogonal concepts of \textit{provenance} credibility and \textit{content} credibility. \remove{We quantified the changes with a \textit{difference in means} metric, where we subtract pre-provenance trust and perceived accuracy ratings from post-provenance ones (all ratings were on a 5-point Likert scale). A high-level summary of some of our findings is shown in Fig. \ref{fig:visual-summary}.}

\remove{We did not find evidence of significant differences in any measured variables across provenance indicator design and terminology variations. }\add{We did not find evidence of significant differences as a result of design and terminology variations in provenance indicators. }However, participants expressed desires for further clarification of some terminology and more quick, glanceable ways to determine credibility. The latter reveals a tension between the rapid pace of information consumption on social media and the deliberate, investigative reflections prompted by provenance. We conclude with a discussion of our study's design implications on both a granular level with suggestions for future provenance UI designs, as well high-level considerations and future work for deploying usable provenance in practice.

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=1\textwidth]{nick-summary.png}
%     \caption{Difference in means of \textsc{trust} and \textsc{agreement} ratings. All values shown are statistically significant ($p < 0.05$). Note that we did not include composited media with invalid provenance in our experiment.}
%     \label{fig:visual-summary}
% \end{figure}

 