{
    "arxiv_id": "2303.11722",
    "paper_title": "Implicit Neural Representation for Cooperative Low-light Image Enhancement",
    "authors": [
        "Shuzhou Yang",
        "Moxuan Ding",
        "Yanmin Wu",
        "Zihan Li",
        "Jian Zhang"
    ],
    "submission_date": "2023-03-21",
    "revised_dates": [
        "2023-08-22"
    ],
    "latest_version": 2,
    "categories": [
        "cs.CV"
    ],
    "abstract": "The following three factors restrict the application of existing low-light image enhancement methods: unpredictable brightness degradation and noise, inherent gap between metric-favorable and visual-friendly versions, and the limited paired training data. To address these limitations, we propose an implicit Neural Representation method for Cooperative low-light image enhancement, dubbed NeRCo. It robustly recovers perceptual-friendly results in an unsupervised manner. Concretely, NeRCo unifies the diverse degradation factors of real-world scenes with a controllable fitting function, leading to better robustness. In addition, for the output results, we introduce semantic-orientated supervision with priors from the pre-trained vision-language model. Instead of merely following reference images, it encourages results to meet subjective expectations, finding more visual-friendly solutions. Further, to ease the reliance on paired data and reduce solution space, we develop a dual-closed-loop constrained enhancement module. It is trained cooperatively with other affiliated modules in a self-supervised manner. Finally, extensive experiments demonstrate the robustness and superior effectiveness of our proposed NeRCo. Our code is available at https://github.com/Ysz2022/NeRCo.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.11722v1",
        "http://arxiv.org/pdf/2303.11722v2"
    ],
    "publication_venue": null
}