\section{Related Works}
\label{sec:related}

\paragraph{Supervised Image Denoising.}
Deep learning has made remarkable advances in image denoising in recent years. Zhang \etal ~\cite{DnCNN} introduced DnCNN, the first CNN-based method for supervised denoising, which significantly outperformed traditional methods~\cite{Chambolle2004AnAF,BM3D,Elad2006ImageDV,WNNM,Vese2003ModelingTW}.The following work aimed to enhance the performance of supervised denoising, such as FFDNet~\cite{FFDNet}, CBDNet~\cite{CBDNet}, RIDNet~\cite{RIDNet}, DANet~\cite{DANet}, FADNet~\cite{FADNet}, and so on. However, supervised-based methods require large amounts of aligned clean-noisy pairs as training data, which are usually difficult and costly to obtain in formal scenarios.

\noindent
\textbf{Unpaired Image Denoising.}
To tackle the challenge in supervised learning, some generative-based~\cite{gans} approaches synthesize noisy samples from clean images~\cite{GAN2GAN,GCBD,UIDNet,C2N,DBSN,fu2023srgb}. The simulated clean-noisy pairs can be further used to train a supervised denoising model. However, the performance of unpaired image denoising methods can be limited when the existing clean images do not match the distribution of the current scene.

\noindent
\textbf{Self-Supervised Image Denoising.}
Lehtinen \etal ~\cite{Noise2Noise} proposed Noise2Noise, which demonstrated that a denoising network could be trained with two independent noisy observations of the same scene. However, even if Noise2Noise relaxes the clean image requirement, obtaining two aligned noisy images in real-world scenarios remains difficult. Noise2Void~\cite{Noise2Void} and Noise2Self~\cite{Noise2Self} proposed a blind-spot strategy to learn denoising from only single noisy images. Further works~\cite{Laine2019,DBSN} extended the paradigm to blind-spot network (BSN) through shifted convolutions~\cite{Laine2019} and dilated
convolutions~\cite{DBSN}. Blind-spot means the network is designed to denoise each pixel from its surrounding spatial neighborhood without itself, thus, the identity mapping to the noisy image itself can be avoided. Noisier2Noise~\cite{Noisier2Noise}, Noisy-As-Clean (NAC)~\cite{NAC}, Recorrupted-to-Recorrupted (R2R)~\cite{R2R}, and IDR~\cite{IDR} generated noisy training pairs by adding synthetic noise to given noisy inputs.
Recently, Neighbor2Neighbor~\cite{Neighbor2Neighbor} proposed to subsample the noisy input images to obtain noisy pairs for Noise2Noise-like training. Blind2Unblind~\cite{Blind2Unblind} proposes a global-aware mask mapper and re-visible loss to fully excavate the information in the blind-spot for Noise2Void-like training. 


\begin{figure*}[t]
    \centering
    \includegraphics[width=1\linewidth]{sec/figure/three_asym.pdf}
    \caption{Three kinds of asymmetric operations during training and inference. 
    % (a) Operations on subgraphs can reduce sampling density and disrupt the spatial structure of the image. (b) The large convolution kernel has a high overhead, and the squeeze operation is not flexible enough. (c) 
    Our scheme can flexibly tune the blind-spot size to meet the requirements of training and inference, achieving a balance between noise correlation suppression and local spatial destruction.
}
    \label{fig:three_asym}
\end{figure*}


\noindent
\textbf{Real-World Image Denoising.}
Some works~\cite{SIDD,NIND} attempt to capture clean-noisy pairs in real-world scenarios. Abdelhamed \etal ~\cite{SIDD} carefully took and aligned clean-noisy pairs from different scenes and lighting conditions using five representative smartphone cameras, and proposed the SIDD dataset. These datasets enable supervised methods~\cite{NBNet,P3AN,AINDNet,InvDN,VDN,DANet} to train on real-world clean-noisy pairs. However, constructing real datasets requires tremendous human effort and time. Moreover, real-world noise tends to exhibit spatial correlation, which contradicts the premise of Noise2Noise~\cite{Noise2Noise} that noise follows an independent and identically distributed pattern, rendering it and its subsequent variants unsuitable for direct application to real-world scenarios. In order to apply self-supervised learning to real-world settings, Neshatavar \etal ~\cite{CVFSID} introduced a cyclic multi-variate function to disentangle clean images, signal-dependent noise, and signal-independent noise from noisy images.
However, the method relies on a simple network without residual connections to avoid learning an identity mapping to the noise signal. Additionally, the simple assumption about real-world noise signals has resulted in its vague denoising results. 
Lee \etal ~\cite{APBSN} employed pixel-shuffle downsampling (PD)~\cite{whenAWGN} to disrupt the spatial correlation of noise and introduced different PD stride factors
for training and inference for better performance.
Li \etal ~\cite{li2023spatially} proposed to use a larger blind-neighborhood to suppress the spatial correlation of noise and present a network to extract the texture within the blind-neighborhood region. However, the method still uses a large blind-spot during testing, which requires a lot of training to extract effective information from a distance to reconstruct the central pixel. LG-BPN ~\cite{wang2023lg} proposes to mask the central area of a large convolution kernel to suppress the spatial correlation of noise and proposes a dilated Transformer block to extract global information. However, the introduction of large kernels will bring greater computational overhead. In addition, some methods attempt to improve AP-BSN. Pan \etal \cite{pan2023random} propose random sub-sampling as data augmentation. Jang \etal \cite{jang2023self} utilize information from the blind-spot position by proposing conditional masked convolution. Nevertheless, these downsampling-based methods lack texture details.

