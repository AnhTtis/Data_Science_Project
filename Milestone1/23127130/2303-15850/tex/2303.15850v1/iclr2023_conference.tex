
\documentclass[dvipsnames]{article} % For LaTeX2e
\usepackage{iclr2023_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}



\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage[hidelinks]{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage[pdftex]{graphicx}
\usepackage{bm}
\usepackage{amsmath}
\usepackage{amsfonts}
%\usepackage{color}
\usepackage[makeroom]{cancel}
\usepackage{cancel}
\usepackage{tabu}
\usepackage[normalem]{ulem} %to strike the words
\usepackage{framed}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage{lscape}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{pifont}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage[flushleft]{threeparttable}
\usepackage{float}
\usepackage[capitalize]{cleveref}


\title{That Label's got Style: Handling Label Style Bias for Uncertain Image Segmentation}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{Kilian Zepf, Eike Petersen, Jes Frellsen, Aasa Feragen  \\
Technical University of Denmark\\
\texttt{\{kmze,ewipe,jefr,afhar\}@dtu.dk} \\}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}
\newcommand*\diff{\mathop{}\!\mathrm{d}}



\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
Segmentation uncertainty models predict a distribution over plausible segmentations for a given input, which they learn from the annotator variation in the training set. However, in practice these annotations can differ systematically in the way they are generated, for example through the use of different labeling tools. This results in datasets that contain both data variability and differing label styles. In this paper, we demonstrate that applying state-of-the-art segmentation uncertainty models on such datasets can lead to model bias caused by the different label styles. We present an updated modelling objective conditioning on labeling style for aleatoric uncertainty estimation, and modify two state-of-the-art-architectures for segmentation uncertainty accordingly. We show with extensive experiments that this method reduces label style bias, while improving segmentation performance, increasing the applicability of segmentation uncertainty models in the wild. We curate two datasets, with annotations in different label styles, which we will make publicly available along with our code upon publication.
\end{abstract}




\section{Introduction}
Image segmentation is a fundamental task in computer vision and biomedical image processing. As part of the effort to create safe and interpretable ML systems, the quantification of segmentation \textit{uncertainty} has thus become a crucial task as well.
While different sources and therefore different types of uncertainties can be distinguished \citep{ditlevsen2008,gawlikowski2021}, research has mainly focused on modelling two types: aleatoric and epistemic uncertainty. While epistemic uncertainty mainly refers to model uncertainty due to missing training data, aleatoric uncertainty arises through variability inherent to the data, caused for example by different opinions of the annotators about the presence, position and boundary of an object. 
Since aleatoric uncertainty estimates are directly inferred from the training data it is important that the variability in the available ground-truth annotations represents the experts' disagreement. However, in practice the annotations might vary in systematic ways, caused by differing labeling tools or different labeling instructions. Especially in settings where opinions in form of annotations are sourced from experts in different institutions, datasets can be heterogeneous in the way the labels are generated.  


\begin{figure}[b]
\centering
\includegraphics[width=1\linewidth]{images/figure2_lite.pdf} 
\caption{Sample image the from PhC-U373 dataset with annotations (red). The first three annotators were instructed to delineate the boundary in detail, whereas the last three annotators were instructed to provide a coarser and faster annotation.}
\label{fig:phc_example} 
\end{figure}


Even in the best of cases, in which manual annotators are given detailed instructions on how to segment objects, they will still have to make choices on how to annotate in ambiguous parts of the image. Moreover, annotators are not always carefully trained, and may not have access to the same labeling tools. As a result, individual choices and external factors affect how annotations are made; we term this \textit{label style}. Figure \ref{fig:phc_example} shows an example of how annotations may vary in label style. 

Label style can also depend on label cost: While detailed annotations are desirable, they also take more time, and one might desire to train models on cheaper, less detailed annotations. In the example of Fig.~\ref{fig:phc_example}, we have access to both detailed and coarse, or \emph{weak}, annotations. It is not clear that adding the weaker annotations will necessarily improve performance; removing them to train on fewer but higher quality annotations could also be beneficial.  

While weak annotations carry less precise information about the segmentation boundary, they \emph{do}   
carry information about the annotator's beliefs concerning the presence and rough location of an object.
Exploiting this information could improve the annotator distribution learned by the model, even tough the target might not be delineated in a detailed way.
In practice, however, neither datasets nor models distinguish between variations in label style and variations in the data. 
As a result, current methods for segmentation uncertainty run the risk of being biased by this difference in label style.


\subsection{Contribution}
In this paper, we demonstrate that applying state-of-the-art models on datasets that contain differing label styles can lead to systematic over-segmentation.
We show how this bias can be reduced by stating an updated modelling objective for aleatoric uncertainty estimation conditioned on label style. 
We adjust two state-of-the-art uncertainty segmentation architectures accordingly, presenting conditioned versions of the Probabilistic U-net \citep{kohl2018probunet} and the Stochastic Segmentation Networks \citep{monteiro2020} that fit to the updated modelling objective and can be trained on datasets containing differing label styles. We compare the proposed method against the common strategy of removing the annotations of a weaker label style from the dataset. 

We curate two datasets, both with annotations in different label styles, ranging from detailed, close crops to over-segmented outlines. 
In a series of experiments, we show that the conditioned models outperform standard models, trained on either all or a single label style.
The conditioning reduces label style bias, improves overall segmentation accuracy and enables more precise flagging of probable segmentation errors. 
Our results stress that including all label styles using a conditioned model enables fully leveraging all labels in a dataset, as opposed to naively excluding weaker label styles. 
As such, our model contributes to increasing the applicability of uncertainty segmentation models in practice.
Our code and curated datasets will be made publicly available, to enable the community to further assess models for segmentation uncertainty in the scenario with differing label styles.


\section{Background and Related Work}

Uncertainties in deep learning in general, and image segmentation in particular, can be studied under the Bayesian framework \citep{bishop2006,kendall2017}. Let $D=(X,A)$ be a dataset of~$N$ images~$x_n \in X$ with~$S$ pixels each, where each image~$x_n$ is associated with~$k$ ground-truth annotations~$a_n^k \in A$, drawn from the unknown annotator distribution $p(a \vert x_n)$.
Furthermore, let $f(x, \theta)$ denote a model of $p(a \vert x)$ defined by parameters $\theta$.
Formulating the segmentation task in a Bayesian way, we seek to model the probability distribution $p(y \vert x)$ over model predictions $y$ given an image $x$ to be as similar as possible to the annotator distribution $p(a \vert x)$.     
This predictive distribution can be decomposed into the two types of uncertainty \citep{ditlevsen2008} as follows: 
\begin{equation}
\label{pred_dist}
 p(y \vert x, D) = \int \underbrace{p(y \vert x,\theta)}_\text{aleatoric uncertainty} \underbrace{p(\theta \vert D)}_\text{epistemic uncertainty} \diff \theta.
\end{equation} 

After observing the data $D$ during training, the posterior distribution $p(\theta \vert D)$ describes a density over the parameter space of the model, capturing epistemic uncertainty.  
The distribution $p(y \vert x,\theta)$, on the other hand, captures the variation in the data and possible model predictions, i.e., aleatoric uncertainty. 
Due to the typically intractable epistemic uncertainty distribution, the integral on the right hand side of \eqref{pred_dist} is usually not accessible. 
Therefore, it is of particular interest to develop suitable approximations of the predictive distribution or parts of the integral in \ref{pred_dist}, and various image segmentation approaches and models have been proposed for this purpose \citep{kohl2018probunet,monteiro2020,kohl2019hierarchical,baumgartner2019phiseg}. 

In this context, the standard cross-entropy minimization approach pursued in most current deep learning research can be understood as approximating the posterior distribution $p(\theta \vert D)$ by a Dirac distribution $\delta(\theta-\theta_1)$ and assuming that there is no spatial correlation between the pixels in an image.
Under these assumptions, one obtains
\begin{equation}
\label{cross_entropy_loss_derivation}
    -\log p(a \vert x, D) = -\log p(a \vert x, \theta_1) = -\log \prod_{i=1}^S p(a_i \vert x_i, \theta_1) = - \sum_{i=1}^S \log p(a_i \vert x_i, \theta_1),
\end{equation}
which is precisely the standard negative log likelihood (or cross-entropy) loss.

 
Variational Bayesian methods approximate the intractable integrals arising in Bayesian inference directly through optimization. A special case that uses Bernoulli distributions to approximate the posterior distribution of the parameters as well as the predictive distribution is the Monte Carlo Dropout method \citep{gal2016dropout,gal2015bayesian}. Pixel-wise uncertainty values can be retrieved by averaging multiple forward passes, while applying dropout during inference time before each weight layer of a neural network. The resulting approximation of the predictive distribution is always multi-modal and not necessarily expressive \citep{folgoc2021mcdropout}, and drawn samples can lack coherence \citep{czolbe2021,gal2016dropoutappendix}. 

Ensemble methods \citep{blundell2016ensemble} also yield pixel-wise uncertainty estimates by averaging over the predictions of different models which are independently trained on the same dataset. 
Contrary to Monte Carlo Dropout, which implicitly averages multiple models during inference time, those models do not share the same weights but can be seen as a frequentist approach to estimating~$p(\theta \vert D)$.
On the other hand, ensembles and multi-head models \citep{rupprecht2017learning,lee2016stochastic} independently trained on one expertâ€™s annotation each return -- in expectation -- a distribution over annotations, therefore also modelling the variability and disagreement between the annotators $p(a \vert x)$ \citep{czolbe2021}.

Models that mainly focus on modelling the annotator distribution $p(a \vert x)$ have been introduced based on combinations of deterministic segmentation networks and generative modelling techniques such as conditional variational autoencoders and normalizing flows \citep{baumgartner2019phiseg,kohl2019hierarchical,selvan2020uncertainty}.
Moreover, a Gaussian-Process based convolutional architecture was recently suggested to distinguish between annotator variability and estimator uncertainty \citep{popescu2021distributional}.
Other approaches model the distribution over annotations with probabilistic graphical models and combinations of those with neural networks \citep{markov2012batra,markov2015batra,NIPS2015markov,kirillov2016joint,markov2018,KAMNITSASmarkov}. However, the computational expense of inference in those models usually prohibits more than a maximum a posteriori estimate of the targeted distribution. 
 
In the following, we will describe in detail two state-of-the-art methods for quantifying aleatoric segmentation uncertainty: the probabilistic U-net \citep{kohl2018probunet} and the Stochastic Segmentation Networks \citep{monteiro2020}. We propose a new modelling objective for the annotator distribution $p(a \vert x)$ including label styles, and we show how both models can be modified to fit it, increasing their applicability to datasets with varying label styles. 
 

\section{Segmentation uncertainty models conditioned on label style}
Segmentation uncertainty models fit a predictive distribution~$p(y \vert x, \theta)$ to the annotator distribution $p(a \vert x)$.
We argue that, in practice, the targeted distribution of annotations should also be conditioned on label style.
Therefore, we propose to model $p(a \vert x, l)$ instead, where~$l \in \{0,\ldots,i>0\}$ denotes a discrete variable representing the label style, and $i$ denotes the number of available label styles.
In this setting, the segmentation model is to be learned from a dataset $D=(X,A,L)$ containing tuples $(x_n, a_n^k, l_n^k)$ of images $x_n\in X$, annotations $a_n^k \in A$, and corresponding label styles $l_n^k \in L$.
In the following, we present modified versions of the probabilistic U-net and Stochastic Segmentation Networks that incorporate label styles directly into training and inference by conditioning the models on a discrete variable \citep{mirza2014}, therefore fitting the new modelling objective.     


\subsection{Conditioned probabilistic U-net}
The probabilistic U-net \citep{kohl2018probunet} combines a U-net with a conditional variational auto-encoder. To encode plausible segmentation variants, an encoder $P$ parameterized by $\omega$ takes an image~$x$ as its input and estimates the mean $\mu_\omega (x)$ and variance $\sigma_\omega (x)$ of a diagonal Gaussian $\mathcal{N}(\mu_\omega (x),\sigma_\omega (x))$ in $\mathbb{R}^6$. During inference, a sample $z$ from this distribution is drawn and concatenated with the deterministic output of the U-net $g_\theta(x)$ and combined by $1 \times 1$ convolutions $f_\psi$. A prediction $y$ for a given latent $z$ can then be written as 
\begin{equation}
y = f(g_\theta(x),z,\psi).    
\end{equation}

The prior net is trained by minimizing the Kullback-Leibler divergence between its predicted latent space distribution~$P$ and a distribution given by the encoder~$Q$, called the posterior net. $Q$ has parameters~$\nu$ and receives both the image~$x$ and annotation~$a$ as inputs, estimating the parameters of the distribution $\mathcal{N}(\mu_\nu (x,a),\sigma_\nu (x,a))$. 
We adjust this model by adding a discrete label style variable~$l$ to the input of the prior net encoder, which is tiled and concatenated one-hot-encoded to the channel axis of the input image~$x$. The latent variable~$z$ is then modelled as the normal distribution 
\begin{equation}
 z \vert x,l \sim \mathcal{N}(\mu_\omega(x,l),\sigma_\omega(x,l)),
\end{equation} 
where the covariance matrix $\sigma_\omega$ is, again, assumed to be diagonal, and both $\sigma_\omega$ and $\mu_\omega$ are estimated by the prior net encoder.
During training, the posterior net $Q$ receives the style $l_n^k$ in addition to the image $x_n$ and annotation $a_n^k$.
Like the original model, the architecture is trained by minimizing the variational lower bound as described in \citet{kohl2018probunet} (see appendix \ref{losses} for details).


\subsection{Conditioned Stochastic Segmentation Networks}
 
Stochastic Segmentation Networks (SSN) \citep{monteiro2020} are a recently suggested model class for quantifying aleatoric segmentation uncertainty. The method can be applied to any feature map received by a deterministic segmentation network, in our case a U-net $g_\theta(x)$. The feature map is passed through three separate convolutional layers, $\mu(x)$, $D(x)$, and $P(x)$, that estimate the parameters of a low-rank multivariate normal distribution over the logits $\eta$. Since $g$ is deterministic, we can write the layers as directly dependent on $x$. The covariance matrix is given by  
\begin{equation}
    \Sigma(x) = D(x) + P(x)P(x)^T,
\end{equation}
and one can then pass samples drawn from the estimated logit distribution 
\begin{equation}
     \eta \vert x \sim \mathcal{N}(\mu(x),\Sigma(x))
\end{equation}
through a softmax layer to receive predictions for a given image $x$. For details on the training procedure and loss function, we refer the reader to appendix \ref{losses}.

We adjust this model by passing the discrete label style variable $l$ through an encoder and by concatenating the resulting feature map to the feature map given by the U-net. The combined feature map is then passed through the respective convolutional layers that estimate the parameters of the logit distribution. 
The style variable is again tiled and concatenated (one-hot-encoded) to the channel axis of the feature maps.
The distribution over the logits~$\eta$ is then modelled as 
\begin{equation}
 \eta \vert x,l \sim \mathcal{N}(\mu(x,l),\Sigma(x,l)).
\end{equation}
Given an image during test time, it is now possible with both models to condition their predictions on a label style $l \in \{0,\ldots,i>0\}$ that has been used for training. Figure \ref{fig:schematic_models} in appendix \ref{schematic_models_appendix} gives a schematic overview of the baseline models and the conditioned versions during inference.

\section{Experiments}
To train and evaluate segmentation uncertainty models fitting the updated modelling objective $p(a \vert x, l)$, we need datasets with multiple annotations per image in differing label styles. We consider two such datasets: a subset of the ISIC19 dataset and a new version of the PhC-U373 dataset.

\subsection{Data}
For our first evaluation, we consider a subset of the ISIC19 skin lesion segmentation challenge \citep{combalia2019bcn20000,codella2018skin,tschandl2018ham10000}, where each image has exactly three annotations available. A distinctive feature of this dataset is the clear difference between label styles, exemplified in Fig.~\ref{fig:isic_example}: Some annotations follow the skin lesion boundary as exactly as possible; this is important as the size and boundary features can be used to clinically classify lesions as malignant or benign \citep{diagnosticcriteria}. Other annotations, conversely, consist of loosely defined regions containing the lesion. This type of weak labeling is more consistent with the task of detecting lesions than segmenting them. 

The ISIC dataset contains ground-truth segmentations generated by three different methods, each of which we consider as one label style. Label style 0 corresponds to tight annotations with a detailed boundary, generated by a semi-automated flood-fill algorithm supervised by an expert. Label style 1 annotations stem from a fully-automated algorithm, reviewed and accepted by experts, while label style 2 are polygonal annotations traced manually by specialists. Note that not every image has exactly one annotation of each label style, so different combinations can occur such as in Fig.~\ref{fig:isic_example} -- we include such images on purpose to illustrate our models' ability to make the most of the available data when the choice of annotations is beyond our control. We consider the fine-grained annotations of label style 0 the ground truth in the downstream analysis of annotator bias. For our experiments, the images and annotations are rescaled to $256 \times 256$ pixels.

\begin{figure}
\centering
\includegraphics[width=1\linewidth]{images/isic_samples_new.pdf}
\caption{Two sample images from the ISIC dataset with annotations in different label styles (red): fine-grained delineations (style 0), smooth, close borders (style 1) and coarse crops (style 2). An image might have multiple annotations of a certain label style (as in the right example).}
\label{fig:isic_example}
\vspace*{-\baselineskip}
\end{figure}

\begin{wraptable}{r}{5cm}
\vspace{-\baselineskip}
  \caption{Datasets and number of image-annotation pairs contained in the different splits. }
  \label{dataset_splits}
   \vspace{.5em}
  \centering
\resizebox{5cm}{!}{%
  \begin{tabular}{lllll}
    \toprule
    & \multicolumn{4}{c}{ISIC}                \\
    \cmidrule(r){2-5}
     & Train     & Val & Test & Total  \\
    \midrule
    Style 0 & 62  & 20  & 22&     \\
    Style 1   & 54 & 18  & 19& \\
    Style 2     & 63 & 21 & 21&   \\
    All & 179 & 59 & 62 & \textbf{300} \\
    \toprule
    & \multicolumn{4}{c}{PhC-U373}  \\
    \cmidrule(r){2-5}
      & Train     & Val & Test & Total  \\
    \midrule
    Style 0 & 1170 & 390 & 393&   \\
    Style 1   & 1170 & 390 & 393&    \\
    
    All &  2340  & 780 & 786 & \textbf{3906}\\
    \bottomrule
  \end{tabular}}
\end{wraptable}

Our second dataset is based on a cell-tracking video from the PhC-U373 dataset of the ISBI cell tracing challenge \citep{Ulrich2009, Ulman2017}.
We use the first video sequence, containing 115 2D images of multiple cells, annotated with two classes (Cell, Background).
To obtain images of single cells, we find the smallest bounding boxes around the ground-truth masks and extend those by 20px on all sites.
We then crop these bounding boxes out of the original images and use only those patches where the expanded bounding box lies completely within the full-sized image.
This results in a dataset containing 651 images of single cells, which are resized to $128 \times 128$ pixels.
In addition to the ground-truth labels, all images were annotated by three researchers independently, of which two labeled the dataset twice (in different styles), resulting in five additional annotations.
Labelers were instructed to perform either detailed annotation (label style 0) or wider annotations (label style 1).
In total, we end up with three annotations labeled in style 0 and three annotations labeled in style 1 for each image in the dataset.
Label style 0 is, again, considered the ground truth in the downstream task analysis of annotator bias later on.

Both datasets are divided into subsets containing only one label style and randomly split for training, validation and testing with a ratio of 60\%, 20\% and 20\% respectively. Table \ref{dataset_splits} gives an overview over the resulting datasets and splits. Since all models are trained on pairs of images and annotations, we report this number for a fair comparison of the dataset sizes.



\subsection{Models}
\label{models}
The following models are compared in our experiments: (1) The proposed conditioned models, namely the style-conditioned probabilistic U-net (c-prob. U-net) and the style-conditioned Stochastic Segmentation Network (c-SSN), which are trained on annotations of all label styles.
During inference, we condition on the style that the model will be evaluated on. 
(2) Probabilistic U-nets (prob. U-net) \citep{kohl2018probunet} and Stochastic Segmentation Networks (SSN) \citep{monteiro2020} trained on subsets that only contain one specific label style. These models are indicated by a \textit{(subset)} tag.
(3) Probabilistic U-nets and Stochastic Segmentation Networks trained on the complete dataset, containing annotations of all label styles, but not conditioned on label style. These models are indicated by an \textit{(all)} tag. Note that this would be the most common way to use the data.

All models are implemented in PyTorch and share a U-net backbone with four encoder and decoder blocks for comparability.
Each block contains three convolution layers and bilinear interpolation was used for upsampling.
Dropout ($p=0.5$) is used in the lowest-level feature map of all architectures.
For the probabilistic U-nets, we chose a latent space dimension of 6 as in \citet{kohl2018probunet}.
Encoder networks in the probabilistic U-net are identical to the contraction path of the backbone U-net.
For the stochastic segmentation networks, the output of the last decoder block of the backbone U-net is passed into three different $1\times1$ convolutional layers to estimate the low-rank approximation of the normal distribution.
Refer to appendix \ref{trainingdetails} for further details on the training procedure.



\section{Results}

\begin{wraptable}{r}{7cm}
\vspace{-\baselineskip}
  \caption{Average area difference with standard deviation in pixels between model predictions and respective label style 0 ground-truth annotations achieved on both datasets.}
  \label{area_results}
  \vspace{.5em}
  \centering
  \resizebox{7cm}{!}{%
  \begin{tabular}{lll}
    \toprule
    & \multicolumn{2}{c}{Dataset}                     \\
    
    \cmidrule(r){2-3}
    Model     & ISIC     & PhC-U373   \\
    \midrule
    Prob. U-net (all) & 6019 (13648)  & 370 (402)    \\
    Prob. U-net (subset 0)     & 4879 (15106) & 584 (534)   \\
    \midrule
    \textbf{c-prob. U-net}     & \textbf{311 (8332)} & \textbf{43 (417)} \\
    \midrule
    \midrule
    SSNs (all)     &5176 (15629)& 716 (1022) \\
    SSNs (subset 0)     &\textbf{3142 (19438)}&1534 (2131)\\
    \midrule
    \textbf{c-SSNs}     &3199 (12987)&\textbf{262 (558)}\\
    \bottomrule
  \end{tabular}}
  \label{areabiastable}
\end{wraptable}

Both datasets considered in this paper contain annotations of high quality that closely outline the object of interest and ones of lower quality that generally over-segment the object of interest. 
In Figure~\ref{fig:area_bias} and Table~\ref{areabiastable}, we show the distribution of area differences (measured in number of pixels) between the different models' predictions and the high-quality annotations of a fixed label style 0 test set. 
Intuitively, training the prob. U-net and the SSNs on all annotations leads to predictions that are biased towards too large annotations compared to the high-quality segmentations of label style 0 on both datasets.
To evaluate whether it is possible to reduce this bias while maintaining the prediction quality as well as the ability of the those models to fit the annotator distribution, we compare the prob. U-net and SSNs in all experiments below against the two alternatives described above in section \ref{models}: 
Firstly, against both models trained on subsets and, secondly, against the conditioned versions that we proposed to fit the new objective for the annotator distribution $p(a \vert x, l)$.

\subsection{Vanilla models have an area bias; this decreases under the updated modelling objective }
Figure~\ref{fig:area_bias} and Table~\ref{areabiastable} show that the prob. U-net and SSNs, both trained on subsets of only label style 0 annotations, tend to over-segment the targets, despite removing the coarser label style annotations. 
Further, we find that the conditioned models show lower area bias compared to the baselines. 
For the ISIC dataset, the standard SSN model trained on the label style 0 subset shows a slightly lower area bias compared to the conditioned model. The same is true for the subset-trained prob. U-net in the PhC-U373 dataset, but in both cases, the model trained on the subset shows a higher variance. 
 


\begin{figure}[h]
    \centering
    \includegraphics[scale=0.73]{images/voldiffs_isic.png}
    \includegraphics[scale=0.73]{images/voldiffs_phc.png}

    \caption{We assess bias in lesion and cell area estimation for the two test datasets (ISIC, PhC-U373) by distribution of area difference (in pixels) between 100 model predictions per image and respective label style 0 ground-truth annotations. Markers indicate the mean.}
    \label{fig:area_bias}
\end{figure}


\subsection{Increased predictive performance and fit to the annotator distribution }
\label{modelfit_subsection}

We evaluated predictive performance to assess how well the different models can predict in a certain label style.
To this end, we calculated the Intersection over Union (IoU) between the model's mean prediction against test sets that only contain annotations of the targeted label style, indicated by the column index in  Table~\ref{iou_results}. 
Note that for column $i$, the prob. U-nets (subsets) or SSNs (subsets) were trained only on annotations of the targeted label style $i$. Across both datasets and all label styles, the best predictive performance in terms of IoU is achieved by the style-conditioned models, with the exception of the c-SSN conditioned on label style 1 on the ISIC dataset.

\begin{table}
  \caption{Average IoU and standard deviation for the models' mean prediction on subsets of the ISIC and the PhC-U373 datasets containing only one label style each.}
  \label{iou_results}
   \vspace{.5em}
  \centering
    
  \begin{tabular}{llllll}
    \toprule
    & \multicolumn{5}{c}{IoU wrt. to a subset of label style}\\
    \cmidrule(r){2-6}
    & \multicolumn{3}{c}{ISIC}     & \multicolumn{2}{c}{PhC-U373}               \\
    
    \cmidrule(r){2-4}
    \cmidrule(r){5-6}
    
    Model     & 0  & 1 & 2 & 0& 1 \\
    \midrule
    Prob. U-net (all) & 0.65 (0.09)  & 0.65 (0.10)  & 0.69 (0.21)  & 0.89 (0.01)  & 0.90 (0.02)  \\
    Prob. U-net (subsets)     & 0.66 (0.11)  & 0.55 (0.17)   & 0.71 (0.15) & 0.85 (0.03) & 0.86 (0.03)   \\
    \midrule
    \textbf{c-prob. U-net }     & \textbf{0.77 (0.15)}  & \textbf{0.78 (0.15)}  & \textbf{0.76 (0.15)} & \textbf{0.92 (0.02)} & \textbf{0.92 (0.01)}\\
    \midrule
    \midrule
    SSNs (all)    &0.72 (0.01)& \textbf{0.77 (0.09)}&0.71 (0.19)  &0.89 (0.02)& \textbf{0.93 (0.02)}\\
    SSNs (subsets)     &0.61 (0.13)&0.75 (0.13)&0.61 (0.11)  &0.85 (0.04)& 0.92 (0.02)\\
    \midrule
    \textbf{c-SSNs }     &\textbf{0.77 (0.10)}&0.71 (0.20)&\textbf{0.78 (0.19)}   &\textbf{0.92 (0.01)}&\textbf{0.93 (0.01)} \\
    \bottomrule
  \end{tabular}
\vspace*{-\baselineskip}
\end{table}

In addition, we computed the area under the receiver-operating characteristic curve (AUROC) with respect to pixel-wise model predictions compared to the ground-truth segmentation mask.
Table~\ref{tab:aurocs} shows the values obtained by the different models; the conditioned models show higher AUROC values across all models and label styles.

Figure~\ref{fig:qualitative_isic_probunet} and Figure~\ref{fig:qualitative_isic_ssn} in Appendix \ref{appendix_sample_predictions} show qualitative results of sample predictions on 5 images from the ISIC dataset for the different models as well as the respective annotations, illustrating that the conditioning on label style corrects for the overestimation bias.

\begin{wraptable}{r}{8cm}
\vspace{-\baselineskip}
  \caption{Pixel-wise AUROC on ISIC and PhC-U373 test sets that only contain annotations of the targeted label style, indicated by the column index.}
  \label{tab:aurocs}
  \centering
  \resizebox{8cm}{!}{%
  \begin{tabular}{lccccc}
    \toprule
    & \multicolumn{3}{c}{ISIC} & \multicolumn{2}{c}{PhC-U373} \\
    \cmidrule(l){2-4} \cmidrule(l){5-6} %\\
    \multicolumn{1}{r}{Label style} & 0 & 1 & 2 & 0 & 1 \\
    
    \midrule
    Prob. U-net (all)  &  0.9289 & 0.9102 & 0.8153 & 0.9960 & 0.9959 \\
    Prob. U-net (subsets)     & 0.9171 & 0.9516 & 0.8819 & 0.9925 & 0.9903 \\
    \midrule
    \textbf{c-prob. U-net}     & \textbf{0.9444} & \textbf{0.9750} & \textbf{0.9407} & \textbf{0.9963} & \textbf{0.9968}\\
    \midrule
    \midrule
    SSNs (all) & 0.8873 & 0.9111 & 0.8633 & 0.9958 & 0.9950\\
    SSNs (subsets)     & 0.7986 & 0.9351 & 0.8609 & 0.9893 & 0.9957\\
    \midrule
    \textbf{c-SSNs}     & \textbf{0.9249} & \textbf{0.9506} & \textbf{0.9255} & \textbf{0.9964} & \textbf{0.9963}\\

    \bottomrule
  \end{tabular}}
 
\end{wraptable} 

The goal of quantifying aleatoric segmentation uncertainty is formulated as fitting a model's predictive distribution $p(y \vert x)$ to the unknown true distribution $p(a \vert x)$, represented by the available annotations of ground-truth segmentations in the dataset.
To assess this fit, we calculated the generalized energy distance (GED)~\citep{Szekely2013,kohl2018probunet} between segmentations sampled from the predictive distribution of the models and the set of ground-truth segmentations.  
In Table~\ref{tab:geds}, we show mean GED values and their standard deviation for different pairs of predictive and annotator distributions. Annotator distributions $p(a \vert x,l=i)$ contain only the set of ground-truth segmentations of label style~$i$ of the test set, whereas $p(a \vert x)$ contains all available annotations across all label styles of the test set. 
Table rows contain the predictive distributions of the following models: the standard prob. U-nets and SSNs trained on all annotation styles; the standard prob. U-nets and SSNs trained on subsets of only annotation style~$i$ for each column and the c-prob. U-net and c-SSN conditioned on label style~$i$.
We find that for the fine-grained predictions of style 0 on the ISIC dataset, the c-prob. U-net and the c-SSN exhibit lower GED values, indicating a better model fit. This also holds for the other label styles on the ISIC dataset, with the exception of the c-SSN conditioned on label style 1. On the PhC-U373 dataset, we find that the GED values are very similar across all models.  


\begin{table}[H]

  \caption{Mean GED (with standard deviation) between models' predictive distributions and the targeted annotator distributions~$p(a \vert x, l)$ of the available label styles as well as the full annotator distribution $p(a \vert x)$ of an ISIC and PhC-U373 test set.}
  \label{tab:geds}
   \vspace{.5em}
  \centering
  \resizebox{\textwidth}{!}{%
  \begin{tabular}{llllllll}
  
    \toprule
    & \multicolumn{4}{c}{ISIC} & \multicolumn{3}{c}{PhC-U373}                     \\
    
    \cmidrule(r){2-5}
    \cmidrule(r){6-8}
    Annotator distribution     & $p(a\vert x , l=0)$     & $p(a\vert x , l=1)$ & $p(a\vert x , l=2)$&$p(a \vert x)$  & $p(a\vert x , l=0)$     & $p(a\vert x , l=1)$& $p(a \vert x)$ \\
    \midrule
    Prob. U-net (all)  & 0.58 (0.14) & 0.57 (0.23) & 0.54 (0.14)&0.57 (0.17)  & 0.69 (0.06) & \textbf{0.60 (0.07)} & \textbf{0.61 (0.06)}  \\
    Prob. U-net (subsets)     & 0.61 (0.14)  & 0.57 (0.23)  & 0.51 (0.17)&-       & 0.70 (0.06) & 0.62 (0.07)& -  \\
    \midrule
    \textbf{c-prob. U-net}     & \textbf{0.57 (0.13)}  & \textbf{0.55 (0.24)}  & \textbf{0.49 (0.19)} &\textbf{0.55 (0.18)}   & \textbf{0.68 (0.06)} & 0.61 (0.06)& \textbf{0.61 (0.06)}\\
    \midrule
    \midrule
    SSNs (all)     &0.59 (0.14)& \textbf{0.55 (0.23)} & 0.51 (0.17)&\textbf{0.55 (0.17)}   &0.69 (0.06) & \textbf{0.60 (0.07)}& 0.61 (0.06) \\
    SSNs (subsets)     &0.61 (0.15)& \textbf{0.55 (0.25)} & 0.55 (0.23) &-  &0.70 (0.06) & 0.62 (0.07)& - \\
    \midrule
    \textbf{c-SSNs}     &\textbf{0.58 (0.13)}&0.56 (0.28)&\textbf{0.48 (0.19)} &\textbf{0.55 (0.20)}  &\textbf{0.68 (0.06)}&\textbf{0.60 (0.06)}& \textbf{0.60 (0.06)}  \\
    \bottomrule
  \end{tabular}}
\end{table}



\subsection{Does high segmentation uncertainty indicate probable segmentation error?}
\label{segerror}
To answer this question, we assessed the relationship between pixel-wise segmentation uncertainty and the likelihood of a segmentation error in that pixel (as compared to the ground-truth segmentation mask) on the label style 0 test set.
The distribution of the pixel-wise entropy {(see appendix \ref{pixwiseentropy})} of the predictions (as a measure of segmentation uncertainty) was assessed for the cases of true positive (TP), false positive (FP), true negative (TN), and false negative (FN) pixel predictions.
A default threshold of $0.5$ was applied.
The results are shown in Figure~\ref{fig:error-entropy} for all models and both datasets. 
We find that the c-prob. U-net consistently assigns higher uncertainty to false positive and false negative predictions on both datasets compared to the standard prob. U-net variants.
The c-SSN performs on par with the alternative models.


\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{images/error_types.png}
    \caption{Distributions and medians of pixel-wise uncertainty (as quantified by the entropy of pixel-wise model predictions) for true positive (TP), false positive (FP), true negative (TN), and false negative (FN) predictions.
 }
    \label{fig:error-entropy}
\vspace*{-\baselineskip}
\end{figure}




\section{Discussion and conclusion}
Our paper took as starting point the hypothesis that probabilistic segmentation models could be biased by different label styles if these are not accounted for by the model. We find this supported by the results of Fig.~\ref{fig:area_bias}, where we see that the prob. U-net and SSNs trained in the standard way on all label styles tend to over-segment the objects of interest. In contrast, the c-prob. U-net conditioned on the close-cropped label style 0 can reduce this bias considerably on both datasets. Even compared to prob. U-nets and SSNs trained only on the label style 0 annotations, the conditioned models give lower or on par bias.  

However, the bias reduction in practice is only of value if the prediction performance does not decrease. Indeed, we find that the c-prob. U-net and the c-SSNs outperform the compared models across label styles in terms of IoU, except for the c-SSN on the label style 1 test set.
On average, the mean prediction of the conditioned models is more similar to the targeted label style compared to the standard models trained on all data or on respective subsets.
This indicates that the proposed conditioning of the models allows the models to implicitly correct for confounding label styles while preserve the ability to segment in a meaningful way.
The strong predictive performance is supported by consistently higher AUROC values for the conditioned models in Table~\ref{tab:aurocs}. Additionally, the conditioned models fit the annotator distributions better, as the results in Table~\ref{tab:geds} suggest. We observe that the advantage in predictive performance of the conditioned models measured by IoU is larger compared to the advantage in fitting the annotator distribution measured by GED. This might be due to the fact that the IoU is calculated on the models' mean predictions while the GED is based on 100 samples drawn from the predictive distribution. 

For any segmentation uncertainty model, it is of interest to which extent the uncertainty estimates can be used to flag a high-probability segmentation error. In the context of label styles, a second highly relevant question is whether we really need fine-grained annotations, or whether we can exploit coarse-grained annotations to obtain a more precise indication of potential segmentation errors. From our preliminary analysis of the relationship between uncertainty estimates and segmentation errors, it can be observed that, as desirable, entropy is higher in the case of segmentation errors across all models and datasets (Fig.~\ref{fig:error-entropy}). The c-prob. U-net gives a consistent advantage across both datasets, while the c-SSN either improves on or performs on par with the alternative models across datasets.


To summarize, our results support that the proposed method of conditioning on label style provides an advantage over, firstly, the standard way of training a segmentation uncertainty model on all available data, ignoring label style, and, secondly, the strategy of removing confounding labels from the training set. {We further demonstrate in appendix \ref{dynamic_augmentation_appendix} that dynamically augmenting coarse annotations from fine-grained ones does not outperform the strategy of including annotations of all label styles in a conditioned model. }
While we find that the standard models are biased by coarser annotations (styles 1 or 2) and the models trained on subsets might suffer from the missing training data, our proposed method enables the segmentation uncertainty model to incorporate all annotations regardless of label style in a meaningful way.
This leads to the conditioned models performing best in predicting fine-grained label style 0 annotations. The modifications made to the architectures for conditioning based on the new modelling objective can be easily implemented and do not incur heavier models, while yielding better results. Finally, the ability to incorporate annotations of many different label styles into training allows for using real-world datasets as they are, thus increasing the applicability of segmentation uncertainty models to datasets as they occur in the wild.

\subsection{Limitations and further research}

Due to limited availability of labeled data, the correctness of the segmentation mask distributions learned by the different models can only be assessed cursorily (as done by means of the GED in Table~\ref{tab:geds}). To perform a more comprehensive validation of the learned distribution, experiments with synthetic data could be performed, similar to the synthetic experiments reported by \citet{kohl2018probunet}. More generally, an evaluation of the impact of different label styles, and the performance of the style-conditioned models, in more and larger datasets is of interest. While the conditioned models in this work require a discrete label style variable, an interesting direction for further research could be the conditioning on continuous label styles as well as considering settings in which different label styles are present but not labelled.


\section*{Acknowledgements}
This research was supported by the Novo Nordisk Foundation through the Center for Basic Machine Learning Research in Life Science (NNF20OC0062606) and the Pioneer Centre for AI, DNRF grant number P1 and Denmarks Frie Forskningsfond (9131-00097B). We want to thank Prof. Sanjay Kumar at the Department of Bioengineering, University of California at Berkeley, Berkeley CA (USA) for his permission to use his dataset 'Glioblastoma-astrocytoma U373 cells on a polyacrylamide substrate' in the context of this work. We further thank the organizers of the Cell Tracking Challenge.
\bibliography{neurips_references}
\bibliographystyle{iclr2023_conference}



\newpage

\appendix
\section{Appendix}
\subsection{Training procedure for the ISIC and PhC-U373 datasets}
\label{trainingdetails}
All models are trained using the Adam optimizer. For the probabilistic U-net, as well as the conditioned probabilistic U-net, we minimize the reconstruction term given by the binary cross-entropy loss, added with a weighted Kullback-Leibler divergence between the estimated normal distributions, as described by \citet{kohl2018probunet}. The Stochastic Segmentation Networks are trained on the loss function described in \citet{monteiro2020}. Across all datasets we used a learning rate of~$10^{-4}$ to train the models. For the skin lesion datasets, we trained for 600 epochs with batch size 16; for the PhC-U373 dataset, we trained for 200 epochs with a batch size of 32. {The above hyperparameters were retrieved by grid search on the validation set. }
All computations were performed on an internal GPU cluster.


\subsection{Generalized Energy Distance}
\label{ged_appendix}

In section \ref{modelfit_subsection}, we use the Generalized Energy Distance \citep{Szekely2013,kohl2018probunet} as a distance measure between distributions. It is defined as 
\begin{equation*}
    D^2_{\mathrm{GED}}(p,\hat p) = 2 \mathbb{E}_{y \sim p, \hat y \sim \hat p}[d(y,\hat y)] - \mathbb{E}_{y , y' \sim p}[d(y,y')]-\mathbb{E}_{\hat y , \hat y' \sim \hat p}[d(\hat y,\hat y')],
\end{equation*}
where $d$ is set to  $1 - IoU(\cdot, \cdot)$. We set $d=0$ if both segmentations are empty. Low GED values indicate high similarity between distributions. 
The expectations are approximated with 100 sample predictions from each model as done by \citet{monteiro2020}. 

Note that when calculating the GED between the full annotator distribution $p(a\vert x)$ and the conditioned models' predictive distribution, we need to draw samples from $p(y \vert x, l)$.
To this end, we sample $l$ from a categorical distribution with density $p( l = k) = p_k$, where $p_k$ could be set to $\frac{1}{i}$ for $i$ different label styles or be estimated form the training dataset.
We choose to set $p_k = \frac{1}{3}$ for the ISIC dataset and $p_k=\frac{1}{3}$ for the PhC-U373 dataset and predict a sample prediction with the respective model, conditioned on the drawn label style.  


\subsection{Pixel-wise Entropy}
\label{pixwiseentropy}
In section \ref{segerror}, we use the \textit{pixel-wise} entropy as a measure of segmentation uncertainty.
It is given by
\begin{equation}
  H(p(y_{m)}\vert x, l)) = -p(y_{m}\vert x, l) \log p(y_{m}\vert x, l) - (1-p(y_{m}\vert x, l))\log (1-p(y_{m}\vert x, l))
\end{equation}
for the conditioned models and
\begin{equation}
  H(p(y_{m}\vert x)) = -p(y_{m}\vert x) \log p(y_{m}\vert x) - (1-p(y_{m}\vert x))\log (1-p(y_{m}\vert x))
\end{equation}
for the baseline models, respectively, where $p(y_{m}\vert x,l)$ and $p(y_{m}\vert x)$ are the probabilities of being of the target class at pixel $m$ of the models' predictive distributions. 

\subsection{Schematic Model Architectures}
\label{schematic_models_appendix}
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{images/schematic_models.png}
    \caption{Schematic model architectures (adapted from \citet{kohl2018probunet} and \citet{monteiro2020}) of the prob. U-net (a) and SSN (b) during inference time. Our modifications to the models are shown in green. (b) illustrates a normal distribution over the logit pixel space as predicted by a SSN.   }
    \label{fig:schematic_models}
\end{figure}



\subsection{Loss Functions}
\label{losses}

\subsubsection{Conditioned Probabilistic U-net}
For training the prob. U-net and the conditioned prob. U-net, we implemented the loss function as described by \citet{kohl2018probunet}. While in the following we formulate the loss function for the conditioned prob. U-net case, we want to remark that the implementations of the loss functions for the conditioned and the standard model cases doe not differ. For a formulation of the loss function of the standard prob. U-net we refer the reader to \citet{kohl2018probunet}. For a training sample $(x_n, a_n^k,l_n^k)$, prior net distribution $P$ and posterior net distribution $Q$, the loss function is calculated as

\begin{align*}
    \mathcal{L}(a_n^k,x_n,l_n^k) &= \mathbb{E}_{z \sim Q(z \vert x_n, a_n^k, l_n^k)} -\log p(a_n^k \vert y(x_n,z)) + \beta \cdot \text{KL}(Q(z \vert x_n, a_n^k, l_n^k)\vert \vert P(z\vert x_n))  \\
         & = \underbrace{- \sum_{m=1}^M a_{nm}^k \log y_m(x_n,z) + (1-a_{nm}^k) \log(1-y_m(x_n,z))}_\text{Binary Cross-Entropy Loss}  \\
         &+\beta \cdot \text{KL}(Q(z \vert x_n, a_n^k, l_n^k)\vert \vert P(z\vert x_n)) 
\end{align*}
for one sample from the posterior net distribution $Q$,
\begin{equation*}
    z \sim Q(z \vert x_n, a_n^k, l_n^k).
\end{equation*}
$M$ denotes the number of pixels for the images $x$ and annotations $a$. Since both $P$ and $Q$ are Gaussian, the Kullback-Leibler divergence has a closed-form solution. 

\subsubsection{Conditioned Stochastic Segmentation Networks}
SSNs relax the spatial independence assumption made for deriving the standard cross-entropy loss (compare equation \ref{cross_entropy_loss_derivation}) and learn a low-rank normal distribution over logits. 
The resulting loss function as derived in \citet{monteiro2020} is given by
\begin{align*}
    \mathcal{L}(a_n^k,x_n,l_n^k) &= -\text{logsumexp}_{s=1}^S (\sum_{m=1}^M \log p(a_n^k \vert \eta_m^{(s)})) + \log(S) \\
         & = -\text{logsumexp}_{s=1}^S \underbrace{(\sum_{m=1}^M a_{nm}^k \log(\sigma(\eta_m^{(s)})) +(1 - a_{nm}^k) \log(1-\sigma(\eta_m^{(s)})))}_\text{Binary Cross-Entropy Loss} + \log(S),
\end{align*}
where $\sigma$ denotes the softmax function. It is calculated by drawing $S$ Monte-Carlo samples from the logit distribution
\begin{equation}
    \eta \vert x,l \sim \mathcal{N}(\mu(x_n,l_n^k) , \Sigma(x_n,l_n^k)).
\end{equation}
The loss is backpropagated using the reparameterization trick. Again, we formulate the loss function for the conditioned case while remarking that it does not differ in implementation from the standard SSN case discussed in \citet{monteiro2020}.

\subsection{Dynamic Augmentation for fine-grained annotations}
\label{dynamic_augmentation_appendix}
In this section, we test whether similar performance gains can be obtained by a dynamic augmentation strategy that only uses fine-grained annotations. For this experiment, we start with the ISIC training dataset that was used for the conditioned models and the baseline models trained on all label styles (not the subsets). For each image in the training set, coarse annotations are substituted by augmented versions of the fine-grained annotations of that image. If there are more than two fine-grained annotations available, one is selected randomly. The augmentation is done by applying a dilation operation followed by a Gaussian filter that smooths out the boundary. 
We train the c-prob. U-net and the c-SSN on this dynamically augmented training set utilizing the style labels. For comparison, we trained the baselines (prob. U-net and SSN) on this training set not using the style labels as described in section \ref{models}. The four new models are indicated by an \textit{(aug)} tag.
The models are then evaluated in terms of IoU, GED and area bias following the exact same experimental setup as in section \ref{modelfit_subsection}.

As seen in Figure \ref{fig:area_bias_dyn_aug}, the conditioned models are still able to correct for area bias compared to the baseline models in this setting. However, segmentation and uncertainty quantification performance are reduced. The IoU decreases relatively (see Table \ref{iou_results_dynamic_augmentation}) while GED increases (see Table \ref{tab:geds_dynamic_augmentation}). For the baseline models, area bias and segmentation performance is worse compared to all other models.   

These results support our reasoning that coarse annotations contain additional information about annotator variability, while at the same time adding area bias. Figure \ref{fig:isic_samples_appendix} shows examples from the ISIC dataset that illustrate exactly this: The coarse annotations do not always contain the fine-grained annotations. It is, therefore, not possible to capture all the annotator variability when using only augmentations of fine-grained annotations. 

\begin{table}
  \caption{Average IoU and standard deviation for the models' mean prediction on subsets of the ISIC dataset containing only one label style each.}
  \label{iou_results_dynamic_augmentation}
   \vspace{.5em}
  \centering
    
  \begin{tabular}{llll}
    \toprule
    & \multicolumn{3}{c}{IoU wrt. to a subset of label style}\\
    \cmidrule(r){2-4}
    
    Model     & 0  & 1 & 2\\
    \midrule
    Prob. U-net (all) & 0.65 (0.09)  & 0.65 (0.10)  & 0.69 (0.21)   \\
    Prob. U-net (subsets)     & 0.66 (0.11)  & 0.55 (0.17)   & 0.71 (0.15)   \\
    Prob. U-net (aug)     & 0.68 (0.16)  & 0.61 (0.14)   & 0.53 (0.23)   \\
    \midrule
    c-prob. U-net (aug)     & 0.73 (0.17)  & 0.70 (0.09)   & 0.69 (0.14)   \\
    \textbf{c-prob. U-net }     & \textbf{0.77 (0.15)}  & \textbf{0.78 (0.15)}  & \textbf{0.76 (0.15)}  \\
    \midrule
    \midrule
    SSNs (all)    &0.72 (0.01)& \textbf{0.77 (0.09)}&0.71 (0.19)  \\
    SSNs (subsets)     &0.61 (0.13)&0.75 (0.13)&0.61 (0.11)  \\
    SSNs (aug)     &0.69 (0.09)&0.62 (0.12)&0.59 (0.15) \\
    \midrule
    c-SSNs (aug)     &0.75 (0.11)&0.66 (0.14)&0.68 (0.16)  \\
    \textbf{c-SSNs }     &\textbf{0.77 (0.10)}&0.71 (0.20)&\textbf{0.78 (0.19)}   \\
    \bottomrule
  \end{tabular}


\end{table}




\begin{table}

  \caption{Mean GED (with standard deviation) between models' predictive distributions and the targeted annotator distributions~$p(a \vert x, l)$ of the available label styles as well as the full annotator distribution $p(a \vert x)$ of an ISIC test set.}
  \label{tab:geds_dynamic_augmentation}
   \vspace{.5em}
  \centering
 
  \begin{tabular}{lllll}
  
    \toprule
    & \multicolumn{4}{c}{ISIC}              \\
    
    \cmidrule(r){2-5}
    
    Annotator distribution     & $p(a\vert x , l=0)$     & $p(a\vert x , l=1)$ & $p(a\vert x , l=2)$&$p(a \vert x)$  \\
    \midrule
    Prob. U-net (all)  & 0.58 (0.14) & 0.57 (0.23) & 0.54 (0.14)&0.57 (0.17)  \\
    Prob. U-net (subsets)     & 0.61 (0.14)  & 0.57 (0.23)  & 0.51 (0.17)&-       \\
    Prob. U-net (aug)     & 0.59 (0.14)  & 0.61 (0.20)  & 0.62 (0.13)&0.61 (0.15)     \\
    \midrule
    c-prob. U-net (aug)     & 0.59 (0.12)  & 0.57 (0.21)  & 0.53 (0.21)&0.58 ( 0.10)        \\
    \textbf{c-prob. U-net}     & \textbf{0.57 (0.13)}  & \textbf{0.55 (0.24)}  & \textbf{0.49 (0.19)} &\textbf{0.55 (0.18)} \\
    \midrule
    \midrule
    SSNs (all)     &0.59 (0.14)& \textbf{0.55 (0.23)} & 0.51 (0.17)&\textbf{0.55 (0.17)}    \\
    SSNs (subsets)     &0.61 (0.15)& \textbf{0.55 (0.25)} & 0.55 (0.23) &-   \\
    SSNs (aug)     &0.60 (0.14)& 0.58 (0.22) & 0.55 (0.16) &0.57 (0.11) \\
    \midrule
    c-SSNs (aug)     &0.58 (0.14)& 0.57 (0.23) & 0.53 (0.20) &0.57 (0.15)  \\
    \textbf{c-SSNs}     &\textbf{0.58 (0.13)}&0.56 (0.28)&\textbf{0.48 (0.19)} &\textbf{0.55 (0.20)}   \\
    \bottomrule
  \end{tabular}
  %}
\end{table}


\begin{figure}
    \centering
    \includegraphics[scale=0.35]{images/voldiffs_isic_dyn_aug.png}

    \caption{We assess bias in lesion and cell area estimation for the ISIC test dataset by distribution of area difference (in pixels) between 100 model predictions per image and respective label style 0 ground-truth annotations. Markers indicate the mean.}
    \label{fig:area_bias_dyn_aug}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.30]{images/appendix_isic_samples.png}

    \caption{Three examples from the ISIC dataset with their respective annotations. The last column shows a heatmap of the average of all three annotation masks. The respective label style $l$ is written on each annotation.}
    \label{fig:isic_samples_appendix}
\end{figure}


\subsection{Qualitative Results on the ISIC dataset}
\label{appendix_sample_predictions}
Figure \ref{fig:qualitative_isic_probunet} and \ref{fig:qualitative_isic_ssn} show sample images from the ISIC dataset with overlayed annotations. Fig. \ref{fig:qualitative_isic_probunet} shows predictions (threshold $0.5$) of the probabilistic U-net trained on all data, the prob. U-nets trained on the label style subsets and the c-prob. U-net conditioned on the different label styles. Fig. \ref{fig:qualitative_isic_ssn} shows predictions (threshold $0.5$) of the SSN trained on all data, the SSNs trained on the label style subsets and the c-SSN conditioned on the different label styles. In both figures, the last column shows an overlay of the conditioned models' prediction when conditioning on each of the three label styles for the given image. 
In both figures, it is visible that the conditioning on label style corrects for the overestimation bias.

\begin{landscape}
\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{images/isic_probunet_qualitative.pdf}
    \caption{Mean predictions of the different prob. U-net models for 5 images from the ISIC dataset. From left to right: Image; Overlayed annotations; prob. U-net (all); prob. U-net (subset 0); prob. U-net (subset 1); prob. U-net (subset 2); c-prob. U-net conditioned on style 0; c-prob. U-net conditioned on style 1; c-prob. U-net conditioned on style 2; Overlayed predictions from c-prob. U-net for each label style. }
    \label{fig:qualitative_isic_probunet}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{images/isic_ssn_qualitative}
    \caption{Mean predictions of the different SSN models for 5 images from the ISIC dataset. From left to right: Image; Overlayed annotations; SSN (all); SSN (subset 0); SSN (subset 1); SSN (subset 2); c-SSN conditioned on style 0; c-SSN conditioned on style 1; c-SSN conditioned on style 2; Overlayed predictions from c-SSN for each label style.}
    \label{fig:qualitative_isic_ssn}
\end{figure}

\end{landscape}




\end{document}



