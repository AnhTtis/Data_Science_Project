%================================================================================
\section{Equivariant diffuser for generating interactions (\eqd)}
\vspace{-5pt}
\label{sec:equivariant_diffuser}


We now describe our \eqd method.
We begin by discussing the symmetry group $\fullgroup$ and common representations in robotic problems.
In Sec.~\ref{sec:eqd_diffusion} we introduce our key novelty, an $\fullgroup$-equivariant diffusion model for state-action trajectories $\tau$.
Finally, we show how a diffusion model trained on offline trajectory data can be used for planning in Sec.~\ref{sec:eqd_planning}.


%================================================================================
\subsection{Symmetry and representations}
%================================================================================

%--------------------------------------------------------------------------------
\xhdr{Symmetry group}
We consider the symmetry group $\fullgroup$, which is a product of three distinct groups: 1.\ the group of spatial translations and rotations $\sethree$, 2.\ the discrete time translation symmetry $\timetranslation$, and 3.\  the permutation group over $n$ objects $\permutation$. It is important to note, however, that this symmetry group may be softly broken in an environment. For instance, the direction of gravity usually breaks the spatial symmetry group $\sethree$ to the smaller group $\setwo$, and distinguishable objects in a scene may break permutation invariance. We follow the philosophy of modeling invariance with respect to the larger group and including any symmetry-breaking effects as inputs to the networks.

We require that spatial positions are always expressed relative to a reference point, for example, the robot base or center of mass. This guarantees equivariance with respect to spatial translations: to achieve $\sethree$ equivariance, we only need to design an $\sothree$-equivariant architecture.

%--------------------------------------------------------------------------------
\xhdr{Data representations}
We consider 3D environments that contain an embodied agent as well as $n$ other objects. We parameterize their degrees of freedom with two $\sothree$ representations, namely the scalar representation $\rho_0$ and the vector representation $\rho_1$. Any $\sethree$ pose can be transformed to these two representations, see Appendix~\ref{app:algo} for details.
We assume that all trajectories transform under the regular representation of the time translation group $\timetranslation$ (similar to how images transform under spatial translations).
Under $\permutation$, object properties permute, while robot properties or global properties of the state remain invariant. Each feature is thus either in the trivial or the standard representation of $\permutation$.

Overall, we thus expect that data in environments experienced by our embodied agent to be categorized into four representations of the symmetry group $\fullgroup$: scalar object properties, vector object properties, scalar robotic degrees of freedom (or other global properties of the system), and vector robotic degrees of freedom (again including other global properties of the system).

%================================================================================
\subsection{Equivariant diffusion model}
\label{sec:eqd_diffusion}
%================================================================================

%--------------------------------------------------------------------------------
\begin{figure*}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/equi_diffuser_architecture.pdf}
    \vskip-4pt
    \caption{Architecture of our $\fullgroup$-equivariant denoising network. Input trajectories (top left), which consist of features in different representations of the symmetry group, are first transformed into a single internal representation (green block). The data are then processed with equivariant blocks (blue), which consist of  convolutional layers along the time dimension, attention over objects, normalization layers, and geometric layers, which mix scalar and vector components of the internal representations. These blocks are combined into a U-net architecture.
    For simplicity, we leave out many details, including residual connections, downsampling, and upsampling layers; see Appendix~\ref{app:algo}.}
    \label{fig:architecture}
    \vspace{-12pt}
\end{figure*}
%--------------------------------------------------------------------------------

\looseness=-1
Our main contribution is a novel $\fullgroup$-equivariant diffusion model which leads to an \emph{invariant} distribution over trajectories. Specifically, given an invariant base density with respect to our chosen symmetry group---a Gaussian satisfies this property for $\fullgroup$---and an equivariant denoising model with respect to the same group we arrive at a diffusion model that is $\fullgroup$-invariant \citep{kohler2020equivariant, papamakarios2021normalizing}. Under mild assumptions, such an equivariant map that pushes forward the base density always exists~\citep{bose2021equivariant}.

We design a novel equivariant architecture for the denoising model $f$. Implemented as a neural network, it maps noisy input trajectories $\tau$ and a diffusion time step $i$ to an estimate $\hat{\epsilon}$ of the noise vector that generated the input.
Our architecture does this in three steps. First, the input trajectory consisting of various representations is transformed into an internal representation of the symmetry group. Second, in this representation the data are processed with an equivariant network. Finally, the outputs are transformed from the internal representation into the original data representations present in the trajectory.
We illustrate the architecture of our \eqd model in Fig.~\ref{fig:architecture}.

%--------------------------------------------------------------------------------
\looseness=-1
\xhdr{Step 1: Representation mixer}
The input noisy trajectory consists of features in different representations of the symmetry group (see above). While it is possible to mirror these input representations for the hidden states of the neural network, the design of equivariant architectures is substantially simplified if all inputs and outputs transform under a single representation. Hence, we decouple the data representation from the representation used internally for the computation---in a similar fashion to graph neural networks that decouple the data and computation graphs.

%--------------------------------------------------------------------------------
\xhdr{Internal representation}
We define a single internal representation that for each trajectory time step $t \in [H]$, each object $o \in [n]$, each channel $c \in [n_c]$ consists of an\footnote{Pairing up just one scalar and one vector is a design choice; for systems in which scalar or vectorial quantities play a larger role, it may be beneficial to use multiple copies of either representation here.} $\sothree$ scalar $s_{toc}$ and an $\sothree$ vector $v_{toc}$. We write $w_{toc} = (s_{toc}, v_{toc}) \in \R^4$.
Under spatial rotations $g \in \sothree$, these features thus transform as the direct sum of the scalar and vector representations $\rho_0 \oplus \rho_1$:
%
\begin{equation}
    w_{toc} = \m{s_{toc} \\ v_{toc}} \to w'_{toc} = \m{\rho_0(g)s_{toc} \\ \rho_1(g) v_{toc}} \,.
\end{equation}

These internal features transform in the regular representation under time shift and in the standard representation under permutations $\mathbb{P}$ as $w_{toc} \to w_{to'c} = \sum_o \mathbb{P}_{o'o} \, w_{toc}$. There are thus no global (not object-specific) properties in our internal representations.

%--------------------------------------------------------------------------------
\xhdr{Transforming input representations into internal representations}
The first layer in our network transforms the input $\tau$, which consists of features in different representations of $\fullgroup$, into the internal representation. On the one hand, we pair up $\sothree$ scalars and $\sothree$ vectors into $\rho_0 \oplus \rho_1$ features. On the other hand, we get rid of global features\,--\,those unassigned to one of the $n$ objects in the scene\,--\,by including them in the representation of each of the $n$ objects. 

Concretely, for each object $o \in [n]$, each trajectory step $t \in [H]$, and each channel $c =[n_c]$, we define the input in the internal representation as $w_{toc} \in \R^4$ as follows:
%
\begin{equation}
    w_{toc} =
    \m{
        \sum_{c'} \rmW^1_{occ'} s_{toc'} \\
        \sum_{c'} \rmW^2_{occ'} v_{toc'}
    }
    +
    \m{
        \sum_{c'} \rmW^3_{occ'} s_{t\emptyset c'} \\
        \sum_{c'} \rmW^4_{occ'} v_{t\emptyset c'}
    }
    \,.
    \label{eq:input_trf}
\end{equation}
%
\looseness=-1
The matrices $\rmW^{1, 2, 3, 4}$ are learnable and of dimension $n \times n_c \times n_s^\text{object}$, $n \times n_c \times n_v^\text{object}$, $n \times n_c \times n_s^\text{global}$, or $n \times n_c \times n_v^\text{global}$, respectively. Here $n_s^\text{object}$ is the number of $\sothree$ scalar quantities associated with each object in the trajectory, $n_v^\text{object}$ is the number of $\sothree$ vector quantities associated with each object, $n_s^\text{global}$ is the number of scalar quantities associated with the robot or global properties of the system, and $n_v^\text{global}$ is the number of vectors of that nature.
The number of input channels $n_c$ is a hyperparameter.
We initialize the matrices $\rmW^i$ such that Eq.~\eqref{eq:input_trf} corresponds to a concatenation of all object-specific and global features along the channel axis at the beginning of training.

%--------------------------------------------------------------------------------
\xhdr{Step 2: $\fullgroup$-equivariant U-net}
We then process the data with a $\modgroup$-equivariant denoising network.
Its key components are three alternating types of layers. Each type acts on the representation dimension of one of the three symmetry groups while leaving the other two invariant---\ie they do not mix internal representation types of the other two layers:
%
\begin{itemize}[itemsep=1pt, topsep=1pt, parsep=1pt]
    \item \emph{Temporal layers}: Time-translation-equivariant convolutions along the temporal direction (i.\,e.\ along trajectory steps), organized in a U-Net architecture.
    \item \emph{Object layers}: Permutation-equivariant self-attention layers over the object dimension.
    \item \emph{Geometric layers}: $\sothree$-equivariant interaction between the scalar and vector features.
\end{itemize}
%
\looseness=-1
In addition, we use residual connections, a new type of normalization layer that does not break equivariance, and context blocks that process conditioning information and embed it in the internal representation (see Appendix \ref{app:algo} for more details). These layers are combined into an equivariant block consisting of one instance of each layer, and the equivariant blocks are arranged in a U-net, as depicted in Fig.~\ref{fig:architecture}. Between the levels of the U-net, we downsample (upsample) along the trajectory time dimension by factors of two, increasing (decreasing) the number of channels correspondingly.

%--------------------------------------------------------------------------------
\looseness=-1
\xhdr{Temporal layers}
Temporal layers consist of $1$D convolutions along the trajectory time dimension. To preserve $\sothree$ equivariance, these convolutions do not add any bias and there is no mixing of features associated with different objects nor the four geometric features of the internal $\sothree$ representation.

%--------------------------------------------------------------------------------
\xhdr{Permutation layers}
Permutation layers enable features associated with different objects to interact via an equivariant multi-head self-attention layer. Here, there is no mixing between features associated with different time steps, nor between the four geometric features of the internal $\sothree$ representation. This is $\sothree$-equivariant, as the attention weights compute invariant $\sothree$ norms.

%--------------------------------------------------------------------------------
\looseness=-1
\xhdr{Geometric layers}
Geometric layers enable mixing between the scalar and vector quantities that are combined in the internal representation but do not mix between different objects or across the time dimension. We construct an expressive equivariant map between scalar and vector inputs and outputs following \citet{villar2021scalars}: We first separate the inputs into $\sothree$ scalar and vector components, $w_{toc} = (s_{toc}, v_{toc})^T$. We then construct a complete set of $\sothree$ invariants by combining the scalars and pairwise inner products between the vectors, $S_{to} = \{ s_{toc} \}_c \cup \{ v_{toc} \cdot v_{toc'} \}_{c, c'}$.
These are then used as inputs to two MLPs $\phi$ and $\psi$, and finally we get output scalars and vectors, $w'_{toc} = \left( \phi(S_{to})_c , \sum_{c'} \psi(S_{to})_{cc'} v_{toc'} \right)$.
\Citet{villar2021scalars} show that this approach can approximate any equivariant map between $\sothree$ scalars and vectors under mild assumptions. In its original form, however, it can become prohibitively expensive, as the number of $\sothree$ invariants $S_{to}$ scales quadratically with the number of channels. Thus, we first linearly map the input vectors into a smaller number of vectors, apply this transformation, and increase the number of channels again with another linear map.

%--------------------------------------------------------------------------------
\xhdr{Step 3: Representation unmixer}
The equivariant network outputs internal representations $w_{toc}$ that are transformed back to data representations using linear maps, in analogy to Eq.~\eqref{eq:input_trf}.
Global properties, \eg robotic degrees of freedom, are aggregated from the object-specific internal representations by taking the mean, minimum, and maximum across the objects. These three aggregates are then concatenated along the channel dimension. We find it beneficial to apply an additional geometric layer to these aggregated global features before separating them into the original representations.

%--------------------------------------------------------------------------------
\looseness=-1
\xhdr{Training}
We train \eqd by optimizing for a simplified variational lower bound \citep{ho2020denoising} on offline trajectories without any reward information.

%================================================================================
\subsection{Planning with equivariant diffusion}
\label{sec:eqd_planning}
%================================================================================

%--------------------------------------------------------------------------------
\looseness=-1
\xhdr{Planning as diffusion}
A diffusion model trained on offline trajectory data jointly learns a world model and a policy. Following \citet{janner2022planning}, we use it to solve planning problems by choosing a sequence of actions to maximize the expected task rewards.

To do this, we use three features of diffusion models. The first is the ability to sample from them by drawing noisy trajectory data from the base distribution and iteratively denoising them with the learned network yielding trajectories similar to those in the training set.
For such sampled trajectories to be useful for planning, they need to begin in the current state of the environment. We achieve this by conditioning the sampling process such that the initial state of the generated trajectories matches the current state, in analogy to inpainting.
Finally, we can guide this sampling procedure toward solving concrete tasks specified at test time using classifier-based guidance where a regression model is trained offline to map trajectories to task rewards.

%--------------------------------------------------------------------------------
\xhdr{Symmetry breaking}
By construction, our equivariant diffusion model learns a $\fullgroup$-invariant density over trajectories. Unconditional samples will reflect this symmetry property---it will be equally likely to sample a trajectory and its rotated or permuted counterpart. However, concrete tasks will often break this invariance, for instance by requiring that a robot or object is brought into a particular location.
Our \eqd approach allows us to elegantly break the symmetry at test time for concrete tasks.
Such a soft symmetry breaking can happen through conditioning, for instance by specifying the initial or final state of the sampled trajectories, or through a non-invariant reward model used for guidance during sampling.
