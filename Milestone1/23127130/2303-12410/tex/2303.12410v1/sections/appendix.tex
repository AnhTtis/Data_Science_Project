\appendix


%================================================================================
\section{Architecture details}
\label{app:algo}
%================================================================================

On a high level, \eqd follows Diffuser~\citep{janner2022planning}. In the following, we will describe the key difference: our $\fullgroup$-equivariant architecture for the diffusion model.

\xhdr{Overall architecture}
We illustrate the architecture in Fig.~\ref{fig:architecture}. After converting the input data in our internal representation (see Sec.~\ref{sec:eqd_diffusion}), the data is processed with an equivariant $U$-net with four levels.
At each level, we process the hidden state with two residual standard blocks, before downsampling (in the downward pass) or upsampling (in the upward pass). 

\xhdr{Residual standard block}
The main processing unit of our architecture processes the current hidden state with an equivariant block consisting of a temporal layer, an object layer, a normalization layer, and a geometric layer. In parallel, the context information (an embedding of diffusion time and a conditioning mask) is processed with a context block. The hidden state is added to the output of the context block and processes with another equivariant block. Finally, we process the data with a linear attention layer over time. This whole pipeline consists of an equivariant block, a context block, and another equivariant block is residual (the inputs are added to the outputs).

\xhdr{Temporal layers}
Temporal layers consist of one-dimensional convolutions without bias along the time dimension. We use a kernel size of 5.

\xhdr{Object layers}
Object layers consist of multi-head self-attention over the object dimension. We use four heads. Keys, queries, and values are constructed as bias-free linear transformations of the inputs to a 32-channel vector. Given inputs $w_{toc}$, the permutation layer computes
%
\begin{align*}
    \rmK_{toc} &= \sum_{c'} \rmW^K_{cc'} w_{toc} \,, \quad 
    \rmQ_{toc} = \sum_{c'} \rmW^Q_{cc'} w_{toc} \,, \quad
    \rmV_{toc} = \sum_{c'} \rmW^V_{cc'} w_{toc} \notag \,, \\ 
    w'_{t\cdot} &\propto \sum_{o'} \mathrm{softmax}_{o'} (\rmQ_{toc} \cdot \rmK_{to'c}) \rmV_{to'c},
\end{align*}
%
\looseness=-1
with learnable weight matrices $\rmW^{K,V,Q}$.

\xhdr{Normalization layers}
We use a simple equivariant normalization layer that for each batch element rescales the entire tensor $w_{toc}$ to unit variance. This is essentially an equivariant version of LayerNorm. The difference is that our normalization layer does not shift the inputs to zero means, as that would break equivariance with respect to $\sothree$.

\xhdr{Geometric layers}
In the geometric layers, the input state is split into scalar and vector components. The vector components are linearly transformed to reduce the number of channels to 16. We then construct all $\sothree$ invariants from these 16 vectors by taking pairwise inner products and concatenating them with the scalar inputs. This set of scalars is processed with two MLPs, each consisting of two hidden layers and ReLU nonlinearities. The MLPs output the scalar outputs and coefficients for a linear map between the vector inputs and the vector outputs, respectively. Finally, there is a residual connection that adds the scalar and vector inputs to the outputs.

\xhdr{Linear attention over time}
To match the architecture used by \citet{janner2022planning} as closely as possible, we follow their choice of adding another residual linear attention over time at the end of each level in the U-net. We make the linear attention mechanism equivariant by computing the attention weights as 

\xhdr{Context blocks}
The embeddings of diffusion time and conditioning information are processed with a Mish nonlinearity and a linear layer, like in \citet{janner2022planning}. Finally, we embed them in our internal representation by zero-padding the resulting tensor.

\xhdr{Upsampling and downsampling}
During the downsampling path, there is a final temporal layer that implements temporal downsampling and increases the number of channels by a factor of two. Conversely, during the upsampling path, we use a temporal layer for temporal upsampling and a reduction of the number of channels.


%================================================================================
\section{Navigation experiments}
\label{app:pointmass}
%================================================================================

We introduce a new navigation environment. The scene consists of a spherical agent navigating a plane populated with a goal state and $n = 10$ spherical obstacles. At the beginning of every episode, the agent position, agent velocity, obstacle positions, and goal position are initialized randomly (in a rotation-invariant way). We simulate the environment dynamics with PyBullet~\citep{coumans2019}.

\xhdr{Offline dataset}
To obtain expert trajectories, we train a TD3~\citep{fujimoto2018addressing} agent in the implementation by \citet{raffin2021baselines3} for $10^7$ steps with default hyperparameters on this environment. We generate $10^5$ trajectories for our offline dataset.

\xhdr{State}
The state contains the agent position, agent velocity, goal position, and obstacle positions.

\xhdr{Actions}
The action space is two-dimensional and specifies a force acting on the agent.

\xhdr{Rewards}
At each time step, the agent receives a reward equal to the negative Euclidean distance to the goal state. In addition, a penalty of $-0.1$ is added to the reward if the agent touches any of the obstacles. Finally, there is an additional control cost equal to $-10^3$ times the force acting on the agent. We affinely normalize the rewards such that a normalized reward of $0$ corresponds to that achieved by a random policy and a normalized reward of $100$ corresponds to the expert policy.


%================================================================================
\section{Kuka experiments}
\label{app:kuka}
%================================================================================

We use the object manipulation environments and tasks from \citet{janner2022planning}, please see that work for details on the environment. In our experiments, we consider three tasks: unconditional stacking, conditional stacking, and block rearrangement. For a fair comparison, we re-implement the Diffuser algorithm while making bug fixes in the codebase of \citet{janner2022planning}, which mainly included properly resetting the environment. 

\subsection{State}
\label{app:kuka_state}
We experiment with two parameterizations of the Kuka environment state. For the Diffuser baseline, we use the original 48-dimensional parameterization from \citet{janner2022planning}.

For our \eqd, we need to parameterize the system in terms of $\fullgroup$ representations. We, therefore, describe the robot and block orientations with $\sothree$ vectors as follows. Originally, the robot state is specified through a collection of joint angles. One of these encodes the rotation of the base along the vertical $z$-axis. We choose to represent this angle as a $\rho_1$ vector in the $xy$-plane. In addition, we add the gravity direction (the $z$-axis itself) as another $\rho_1$ vector, which is also the normal direction of the table on which the objects rest. Combined, these vectors define the pose of the base of the robot arm.
Rotating gravity direction, and the robot and object pose by $\sothree$ can be interpreted as a passive coordinate transformation, or as an active rotation of the entire scene, including gravity. As the laws of physics are invariant to this transformation, this is a valid symmetry of the problem.

The $n$ objects can be translated and rotated. Their pose is thus given by a translation $t \in \R^3$ and rotation in $r \in \sothree$ relative to a reference pose. The translation transforms by a global rotation $g \in \sothree$ as a vector via representation $\rho_1$.
The rotational pose transforms by left multiplication $r \mapsto gr$. The $\sothree$ pose is not a Euclidean space, but a non-trivial manifold. Even though diffusion on manifolds is possible \cite{De_Bortoli2022-fe,Huang2022-ra}, we simplify the problem by embedding the pose in a Euclidean space. This is done by picking the first two columns of the pose rotation matrix $r \in \sothree$. These columns each transform again as a vector with representation $\rho_1$.
This forms an equivariant embedding $\iota: \sothree \hookrightarrow \R^{2 \times 3}$, whose image is two orthogonal 3-vectors of unit norm. Via the Gram-Schmidt procedure, we can define an equivariant map $\pi: \R^{2 \times 3} \to \sothree$ (defined almost everywhere), that is a left inverse to the embedding: $\pi \circ \iota = \text{id}_\sothree$.
Combining with the translation, the roto-translational pose of each object is thus embedded as three $\rho_1$ vectors.

We also tested the performance of the baseline Diffuser method on this reparameterization of the state but found worse results.

\subsection{Hyperparameters}
\label{app:kuka_hyperparams}
We also follow the choices of \citet{janner2022planning}, except that we experiment with a linear noise schedule as an alternative to the cosine schedule they use. For each model and each dataset, we train the diffusion model with both noise schedules and report the better of the two results.
