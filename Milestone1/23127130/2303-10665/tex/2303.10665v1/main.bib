@incollection{anderson2011continuous,
  title={Continuous time {Markov} chain models for chemical reaction networks},
  author={Anderson, David F and Kurtz, Thomas G},
  booktitle={Design and analysis of biomolecular circuits},
  pages={3--42},
  year={2011},
  publisher={Springer}
}
@article{bauerle2021mean,
  title={Mean Field {Markov} Decision Processes},
  author={B{\"a}uerle, Nicole},
  journal={arXiv:2106.08755},
  year={2021}
}
@book{bensoussan2013mean,
  title={Mean field games and mean field type control theory},
  author={Bensoussan, Alain and Frehse, Jens and Yam, Phillip and others},
  volume={101},
  year={2013},
  publisher={Springer}
}
@article{bernstein2002complexity,
  title={The complexity of decentralized control of {M}arkov decision processes},
  author={Bernstein, Daniel S and Givan, Robert and Immerman, Neil and Zilberstein, Shlomo},
  journal={Math. Oper. Res.},
  volume={27},
  number={4},
  pages={819--840},
  year={2002},
  publisher={INFORMS}
}
@book{billingsley2013convergence,
  title={Convergence of probability measures},
  author={Billingsley, Patrick},
  year={2013},
  publisher={John Wiley \& Sons}
}
@article{bonesini2022correlated,
  title={Correlated equilibria for mean field games with progressive strategies},
  author={Bonesini, Ofelia and Campi, Luciano and Fischer, Markus},
  journal={arXiv:2212.01656},
  year={2022}
}
@inproceedings{cabannes2021solving,
  title={Solving N-Player Dynamic Routing Games with Congestion: A Mean-Field Approach},
  author={Cabannes, Theophile and Lauri{\`e}re, Mathieu and Perolat, Julien and Marinier, Raphael and Girgin, Sertan and Perrin, Sarah and Pietquin, Olivier and Bayen, Alexandre M and Goubault, Eric and Elie, Romuald},
  booktitle={Proc. AAMAS},
  volume={21},
  pages={1557--1559},
  year={2022}
}
@article{caines2016mm,
  title={$\epsilon$-{Nash} Equilibria for Partially Observed {LQG} Mean Field Games With a Major Player},
  author={Caines, Peter E and Kizilkale, Arman C},
  journal={IEEE Trans. Automat. Contr.},
  volume={62},
  number={7},
  pages={3225--3234},
  year={2016},
  publisher={IEEE}
}
@inproceedings{caines2019graphon,
  title={Graphon Mean Field Games and the {GMFG} Equations: $\varepsilon$-{Nash} Equilibria},
  author={Caines, Peter E and Huang, Minyi},
  booktitle={Proc. IEEE CDC},
  pages={286--292},
  year={2019},
  
}
@article{campi2022correlated,
  title={Correlated equilibria and mean field games: a simple model},
  author={Campi, Luciano and Fischer, Markus},
  journal={Math. Oper. Res.},
  year={2022},
  publisher={INFORMS}
}
@article{cardaliaguet2017learning,
  title={Learning in mean field games: the fictitious play},
  author={Cardaliaguet, Pierre and Hadikhanloo, Saeed},
  journal={ESAIM Control Optim. Calc. Var.},
  volume={23},
  number={2},
  pages={569--591},
  year={2017},
  publisher={EDP Sciences}
}
@article{carmona2016mean,
  title={Mean field games with common noise},
  author={Carmona, Ren{\'e} and Delarue, Fran{\c{c}}ois and Lacker, Daniel},
  journal={The Annals of Probability},
  volume={44},
  number={6},
  pages={3740--3803},
  year={2016},
  publisher={Institute of Mathematical Statistics}
}
@book{carmona2018probabilistic,
  title={Probabilistic Theory of Mean Field Games with Applications I-II},
  author={Carmona, Ren{\'e} and Delarue, Fran{\c{c}}ois and others},
  year={2018},
  publisher={Springer}
}
@article{carmona2019model,
  title={Model-free mean-field reinforcement learning: mean-field {MDP} and mean-field {Q-learning}},
  author={Carmona, Ren{\'e} and Lauri{\`e}re, Mathieu and Tan, Zongjun},
  journal={arXiv:1910.12802},
  oldurl={https://arxiv.org/abs/1910.12802},
  year={2019}
}
@article{carmona2020applications,
  title={Applications of Mean Field Games in Financial Engineering and Economic Theory},
  author={Carmona, Rene},
  journal={arXiv:2012.05237},
  oldurl={https://arxiv.org/abs/2012.05237},
  year={2020}
}
@article{carmona2022synchronization,
  title={Synchronization in a {Kuramoto} Mean Field Game},
  author={Carmona, Rene and Cormier, Quentin and Soner, H Mete},
  journal={arXiv:2210.12912},
  year={2022}
}
@inproceedings{csen2014mean,
  title={Mean field games with partially observed major player and stochastic mean field},
  author={{\c{S}}en, Nevroz and Caines, Peter E},
  booktitle={Proc. IEEE CDC},
  pages={2709--2715},
  year={2014},
  
}
@inproceedings{cui2021approximately,
  title={Approximately solving mean field games via entropy-regularized deep reinforcement learning},
  author={Cui, Kai and Koeppl, Heinz},
  booktitle={Proc. AISTATS},
  pages={1909--1917},
  year={2021},
  
}
@inproceedings{cui2022learning,
    title={Learning Graphon Mean Field Games and Approximate {Nash} Equilibria},
    author={Kai Cui and Heinz Koeppl},
    booktitle={Proc. ICLR},
    pages={1--31},
    year={2022},
}
@article{daskalakis2009complexity,
  title={The complexity of computing a {Nash} equilibrium},
  author={Daskalakis, Constantinos and Goldberg, Paul W and Papadimitriou, Christos H},
  journal={SIAM J. Comput.},
  volume={39},
  number={1},
  pages={195--259},
  year={2009},
  publisher={SIAM}
}
@article{de2020independent,
  title={Is independent learning all you need in the {Starcraft} multi-agent challenge?},
  author={de Witt, Christian Schroeder and Gupta, Tarun and Makoviichuk, Denys and Makoviychuk, Viktor and Torr, Philip HS and Sun, Mingfei and Whiteson, Shimon},
  journal={arXiv:2011.09533},
  oldurl={https://arxiv.org/abs/2011.09533},
  year={2020}
}
@book{devore1993constructive,
  title={Constructive approximation},
  author={DeVore, Ronald A and Lorentz, George G},
  volume={303},
  year={1993},
  publisher={Springer Science \& Business Media}
}
@article{djehiche2017mean,
  title={Mean-Field-Type Games in Engineering},
  author={Djehiche, Boualem and Tcheukam, Alain and Tembine, Hamidou},
  journal={AIMS Electronics and Electrical Engineering},
  volume={1},
  number={1},
  pages={18--73},
  year={2017}
}
@inproceedings{dunyak2021large,
  title={Large Scale Systems and {SIR} Models: A Featured Graphon Approach},
  author={Dunyak, Alex and Caines, Peter E},
  booktitle={Proc. IEEE CDC},
  pages={6928--6933},
  year={2021},
  organization={IEEE}
}
@inproceedings{ganapathi2020multi,
  title={Multi Type Mean Field Reinforcement Learning},
  author={Ganapathi Subramanian, Sriram and Poupart, Pascal and Taylor, Matthew E and Hegde, Nidhi},
  booktitle={Proc. AAMAS},
  volume={19},
  pages={411--419},
  year={2020}
}
@article{gast2011mean,
  title={A mean field approach for optimization in discrete time},
  author={Gast, Nicolas and Gaujal, Bruno},
  journal={Discrete Event Dynamic Systems},
  volume={21},
  number={1},
  pages={63--101},
  year={2011},
  publisher={Springer}
}
@article{gast2018refined,
  title={A Refined Mean Field Approximation},
  author={Gast, Nicolas and Van Houdt, Benny},
  journal={ACM SIGMETRICS Perform. Eval. Rev.},
  volume={46},
  number={1},
  pages={113--113},
  year={2018},
  publisher={ACM New York, NY, USA}
}
@article{gu2019dynamic,
  title={Dynamic programming principles for mean-field controls with learning},
  author={Gu, Haotian and Guo, Xin and Wei, Xiaoli and Xu, Renyuan},
  journal={arXiv:1911.07314},
  oldurl={https://arxiv.org/abs/1911.07314},
  year={2019}
}
@article{gu2021mean,
  title={Mean-field controls with {Q-learning} for cooperative {MARL}: convergence and complexity analysis},
  author={Gu, Haotian and Guo, Xin and Wei, Xiaoli and Xu, Renyuan},
  journal={SIAM J. Math. Data Sci.},
  volume={3},
  number={4},
  pages={1168--1196},
  year={2021},
  publisher={SIAM}
}
@inproceedings{guo2019learning,
  title={Learning mean-field games},
  author={Guo, Xin and Hu, Anran and Xu, Renyuan and Zhang, Junzi},
  booktitle={Proc. NeurIPS},
  pages={4966--4976},
  year={2019}
}
@article{guo2020general,
  title={A general framework for learning mean-field games},
  author={Guo, Xin and Hu, Anran and Xu, Renyuan and Zhang, Junzi},
  journal={Math. Oper. Res.},
  year={2022},
  publisher={INFORMS}
}
@inproceedings{gupta2017cooperative,
  title={Cooperative multi-agent control using deep reinforcement learning},
  author={Gupta, Jayesh K and Egorov, Maxim and Kochenderfer, Mykel},
  booktitle={Proc. AAMAS},
  pages={66--83},
  year={2017},
  
}
@article{hernandez1992discrete,
  title={Discrete-time {Markov} control processes with discounted unbounded costs: optimality criteria},
  author={Hern{\'a}ndez-Lerma, On{\'e}simo and Mu{\~n}oz de Ozak, Myriam},
  journal={Kybernetika},
  volume={28},
  number={3},
  pages={191--212},
  year={1992},
  publisher={Institute of Information Theory and Automation AS CR}
}
@book{hernandez2012discrete,
  title={Discrete-time {Markov} control processes: basic optimality criteria},
  author={Hern{\'a}ndez-Lerma, On{\'e}simo and Lasserre, Jean B},
  volume={30},
  year={2012},
  publisher={Springer Science \& Business Media}
}
@article{hu2022graphon,
  title={Graphon Mean-Field Control for Cooperative Multi-Agent Reinforcement Learning},
  author={Hu, Yuanquan and Wei, Xiaoli and Yan, Junji and Zhang, Hengxi},
  journal={arXiv:2209.04808},
  year={2022}
}
@article{huang2006large,
  title={Large population stochastic dynamic games: closed-loop {McKean-Vlasov} systems and the {Nash} certainty equivalence principle},
  author={Huang, Minyi and Malham{\'e}, Roland P and Caines, Peter E},
  journal={Commun. Inf. Syst.},
  volume={6},
  number={3},
  pages={221--252},
  year={2006},
  publisher={International Press of Boston}
}
@book{kallenberg2017random,
  title={Random measures, theory and applications},
  author={Kallenberg, Olav and others},
  volume={1},
  year={2017},
  publisher={Springer}
}
@book{kiss2017mathematics,
  title={Mathematics of Epidemics on Networks: From Exact to Approximate Models},
  author={Kiss, Istv{\'a}n Z and Miller, Joel C and Simon, P{\'e}ter L},
  volume={46},
  year={2017},
  publisher={Springer},
  doi={10.1007/978-3-319-50806-1}
}
@article{lasry2007mean,
  title={Mean field games},
  author={Lasry, Jean-Michel and Lions, Pierre-Louis},
  journal={Japanese J. Math.},
  volume={2},
  number={1},
  pages={229--260},
  year={2007},
  publisher={Springer}
}
@article{lauriere2022learning,
  title={Learning Mean Field Games: A Survey},
  author={Lauri{\`e}re, Mathieu and Perrin, Sarah and Geist, Matthieu and Pietquin, Olivier},
  journal={arXiv:2205.12944},
  oldurl={https://arxiv.org/abs/2205.12944},
  year={2022}
}
@inproceedings{liang2018rllib,
  title={{RLlib}: Abstractions for distributed reinforcement learning},
  author={Liang, Eric and Liaw, Richard and Nishihara, Robert and Moritz, Philipp and Fox, Roy and Goldberg, Ken and Gonzalez, Joseph and Jordan, Michael and Stoica, Ion},
  booktitle={Proc. ICML},
  pages={3053--3062},
  year={2018},
  
}
@article{liu2022scalable,
  title={Scalable and Sample Efficient Distributed Policy Gradient Algorithms in Multi-Agent Networked Systems},
  author={Liu, Xin and Wei, Honghao and Ying, Lei},
  journal={arXiv:2212.06357},
  year={2022}
}
@article{mondal2022approximation,
  title={On the Approximation of Cooperative Heterogeneous Multi-Agent Reinforcement Learning ({MARL}) using Mean Field Control ({MFC})},
  author={Mondal, Washim Uddin and Agarwal, Mridul and Aggarwal, Vaneet and Ukkusuri, Satish V},
  journal={J. Mach. Learn. Res.},
  volume={23},
  number={129},
  pages={1--46},
  year={2022}
}
@article{motte2022mean,
  title={Mean-field {Markov} decision processes with common noise and open-loop controls},
  author={Motte, M{\'e}d{\'e}ric and Pham, Huy{\^e}n},
  journal={The Annals of Applied Probability},
  volume={32},
  number={2},
  pages={1421--1458},
  year={2022},
  publisher={Institute of Mathematical Statistics}
}
@article{motte2022quantitative,
  title={Quantitative propagation of chaos for mean field {Markov} decision process with common noise},
  author={Motte, M{\'e}d{\'e}ric and Pham, Huy{\^e}n},
  journal={arXiv:2207.12738},
  year={2022}
}
@inproceedings{muller2021learning,
  title={Learning Equilibria in Mean-Field Games: Introducing Mean-Field {PSRO}},
  author={Muller, Paul and Rowland, Mark and Elie, Romuald and Piliouras, Georgios and Perolat, Julien and Lauriere, Mathieu and Marinier, Raphael and Pietquin, Olivier and Tuyls, Karl},
  booktitle={Proc. AAMAS},
  pages = {926–934},
  volume={20},
  year={2021}
}
@article{nourian2013mm,
  title={$\epsilon$-{Nash} mean field game theory for nonlinear stochastic dynamical systems with major and minor agents},
  author={Nourian, Mojtaba and Caines, Peter E},
  journal={SIAM J. Contr. Optim.},
  volume={51},
  number={4},
  pages={3302--3331},
  year={2013},
  publisher={SIAM}
}
@book{oliehoek2016concise,
  title={A Concise Introduction to Decentralized {POMDP}s},
  author={Oliehoek, Frans A and Amato, Christopher},
  year={2016},
  publisher={Springer}
}
@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={arXiv:2203.02155},
  year={2022}
}
@inproceedings{papoudakis2021benchmarking,
  title={Benchmarking Multi-Agent Deep Reinforcement Learning Algorithms in Cooperative Tasks},
  author={Papoudakis, Georgios and Christianos, Filippos and Sch{\"a}fer, Lukas and Albrecht, Stefano V},
  booktitle={Proc. NeurIPS Track Datasets Benchmarks},
  year={2021}
}
@book{parthasarathy2005probability,
  title={Probability measures on metric spaces},
  author={Parthasarathy, Kalyanapuram Rangachari},
  volume={352},
  year={2005},
  publisher={American Mathematical Soc.}
}
@article{pasztor2021efficient,
  title={Efficient model-based multi-agent mean-field reinforcement learning},
  author={Pasztor, Barna and Bogunovic, Ilija and Krause, Andreas},
  journal={arXiv:2107.04050},
  oldurl={https://arxiv.org/abs/2107.04050},
  year={2021}
}
@inproceedings{perolat2021scaling,
  title={Scaling Mean Field Games by Online Mirror Descent},
  author={P{\'e}rolat, Julien and Perrin, Sarah and Elie, Romuald and Lauri{\`e}re, Mathieu and Piliouras, Georgios and Geist, Matthieu and Tuyls, Karl and Pietquin, Olivier},
  booktitle={Proc. AAMAS},
  pages={1028--1037},
  volume={21},
  year={2022}
}
@inproceedings{perrin2020fictitious,
  title={Fictitious play for mean field games: Continuous time analysis and applications},
  author={Perrin, Sarah and P{\'e}rolat, Julien and Lauri{\`e}re, Mathieu and Geist, Matthieu and Elie, Romuald and Pietquin, Olivier},
  booktitle={Proc. NeurIPS},
  volume={33},
  pages={13199--13213},
  year={2020}
}
@inproceedings{perrin2021generalization,
  title={Generalization in Mean Field Games by Learning Master Policies},
  author={Perrin, Sarah and Lauri{\`e}re, Mathieu and P{\'e}rolat, Julien and {\'E}lie, Romuald and Geist, Matthieu and Pietquin, Olivier},
  booktitle={Proc. AAAI},
  volume={36},
  pages={9413--9421},
  year={2022}
}
@article{pham2018bellman,
  title={Bellman equation and viscosity solutions for mean-field stochastic control problem},
  author={Pham, Huy{\^e}n and Wei, Xiaoli},
  journal={ESAIM Contr. Optim. Calc. Var.},
  volume={24},
  number={1},
  pages={437--461},
  year={2018},
  publisher={EDP Sciences}
}
@inproceedings{qu2020scalable,
  title={Scalable reinforcement learning of localized policies for multi-agent networked systems},
  author={Qu, Guannan and Wierman, Adam and Li, Na},
  booktitle={Proc. Learn. Dyn. Contr.},
  pages={256--266},
  year={2020},
  
}
@inproceedings{qu2020scalable2,
  title={Scalable multi-agent reinforcement learning for networked systems with average reward},
  author={Qu, Guannan and Lin, Yiheng and Wierman, Adam and Li, Na},
  booktitle={Proc. NeurIPS},
  volume={33},
  pages={2074--2086},
  year={2020}
}
@article{saldi2018markov,
  title={{Markov}--{Nash} equilibria in mean-field games with discounted cost},
  author={Saldi, Naci and Ba{\c{s}}ar, Tamer and Raginsky, Maxim},
  journal={SIAM J. Contr. Optim.},
  volume={56},
  number={6},
  pages={4256--4287},
  year={2018},
  publisher={SIAM}
}
@inproceedings{saldi2019partially,
  title={Partially-observed discrete-time risk-sensitive mean-field games},
  author={Saldi, Naci and Ba{\c{s}}ar, Tamer and Raginsky, Maxim},
  booktitle={Proc. IEEE CDC},
  pages={317--322},
  year={2019},
  
}
@article{sanjari2020optimal,
  title={Optimal solutions to infinite-player stochastic teams and mean-field teams},
  author={Sanjari, Sina and Y{\"u}ksel, Serdar},
  journal={IEEE Trans. Automat. Contr.},
  volume={66},
  number={3},
  pages={1071--1086},
  year={2020},
  publisher={IEEE}
}
@article{schrittwieser2020mastering,
  title={Mastering atari, go, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and others},
  journal={Nature},
  volume={588},
  number={7839},
  pages={604--609},
  year={2020},
  publisher={Nature Publishing Group}
}
@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv:1707.06347},
  oldurl={https://arxiv.org/abs/1707.06347},
  year={2017}
}
@article{sen2016mean,
  title={Mean field game theory with a partially observed major agent},
  author={{\c{S}}en, Nevroz and Caines, Peter E},
  journal={SIAM J. Contr. Optim.},
  volume={54},
  number={6},
  pages={3174--3224},
  year={2016},
  publisher={SIAM}
}
@article{sen2019mean,
  title={Mean field games with partial observation},
  author={{\c{S}}en, Nevroz and Caines, Peter E},
  journal={SIAM J. Contr. Optim.},
  volume={57},
  number={3},
  pages={2064--2091},
  year={2019},
  publisher={SIAM}
}
@inproceedings{shiri2019massive,
  title={Massive autonomous {UAV} path planning: A neural network based mean-field game theoretic approach},
  author={Shiri, Hamid and Park, Jihong and Bennis, Mehdi},
  booktitle={Proc. IEEE GLOBECOM},
  pages={1--6},
  year={2019},
  organization={IEEE}
}
@inproceedings{subramanian2020partially,
  title={Partially Observable Mean Field Reinforcement Learning},
  author={Ganapathi Subramanian, Sriram and Taylor, Matthew E and Crowley, Mark and Poupart, Pascal},
  booktitle={Proc. AAMAS},
  volume={20},
  pages={537--545},
  year={2021}
}
@inproceedings{subramanian2022decentralized,
  title={Decentralized Mean Field Games},
  author={Subramanian, Sriram Ganapathi and Taylor, Matthew E and Crowley, Mark and Poupart, Pascal},
  booktitle={Proc. AAAI},
  volume={36},
  pages={9439--9447},
  year={2022}
}
@incollection{sznitman1991topics,
  title={Topics in propagation of chaos},
  author={Sznitman, Alain-Sol},
  booktitle={Ecole d'{\'e}t{\'e} de probabilit{\'e}s de Saint-Flour XIX—1989},
  pages={165--251},
  year={1991},
  publisher={Springer}
}
@inproceedings{tan1993multi,
  title={Multi-agent reinforcement learning: Independent vs. cooperative agents},
  author={Tan, Ming},
  booktitle={Proc. ICML},
  pages={330--337},
  year={1993}
}
@inproceedings{tchuendom2021critical,
  title={Critical Nodes in Graphon Mean Field Games},
  author={Tchuendom, Rinel Foguen and Caines, Peter E and Huang, Minyi},
  booktitle={Proc. IEEE CDC},
  pages={166--170},
  year={2021},
  organization={IEEE}
}
@book{villani2009optimal,
  title={Optimal transport: old and new},
  author={Villani, C{\'e}dric},
  volume={338},
  year={2009},
  publisher={Springer}
}
@article{vinyals2019grandmaster,
  title={Grandmaster level in {StarCraft II} using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group}
}
@inproceedings{yang2018mean,
  title={Mean field multi-agent reinforcement learning},
  author={Yang, Yaodong and Luo, Rui and Li, Minne and Zhou, Ming and Zhang, Weinan and Wang, Jun},
  booktitle={Proc. ICML},
  pages={5571--5580},
  year={2018},
  
}
@inproceedings{
yu2021surprising,
title={The Surprising Effectiveness of {PPO} in Cooperative Multi-Agent Games},
author={Chao Yu and Akash Velu and Eugene Vinitsky and Jiaxuan Gao and Yu Wang and Alexandre Bayen and Yi Wu},
booktitle={Proc. NeurIPS Datasets and Benchmarks},
year={2022},
oldurl={https://openreview.net/forum?id=YVXaxB6L2Pl}
}
@incollection{zhang2021multi,
pages="321--384",
title="Multi-Agent Reinforcement Learning: A Selective Overview of Theories and Algorithms",
author="Zhang, Kaiqing
and Yang, Zhuoran
and Ba{\c{s}}ar, Tamer",
editor="Vamvoudakis, Kyriakos G.
and Wan, Yan
and Lewis, Frank L.
and Cansever, Derya",
  booktitle={Handbook of Reinforcement Learning and Control},
year="2021",
publisher="Springer International Publishing",
address="Cham",
}
@article{flamary2021pot,
  author  = {R{\'e}mi Flamary and Nicolas Courty and Alexandre Gramfort and Mokhtar Z. Alaya and Aur{\'e}lie Boisbunon and Stanislas Chambon and Laetitia Chapel and Adrien Corenflos and Kilian Fatras and Nemo Fournier and L{\'e}o Gautheron and Nathalie T.H. Gayraud and Hicham Janati and Alain Rakotomamonjy and Ievgen Redko and Antoine Rolet and Antony Schutz and Vivien Seguy and Danica J. Sutherland and Romain Tavenard and Alexander Tong and Titouan Vayer},
  title   = {POT: Python Optimal Transport},
  journal = {J. Mach. Learn. Res.},
  year    = {2021},
  volume  = {22},
  number  = {78},
  pages   = {1-8},
  oldurl     = {http://jmlr.org/papers/v22/20-451.html}
}
@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv:1606.01540},
  year={2016}
}
@article{yardim2022policy,
  title={Policy Mirror Ascent for Efficient and Independent Learning in Mean Field Games},
  author={Yardim, Batuhan and Cayci, Semih and Geist, Matthieu and He, Niao},
  journal={arXiv:2212.14449},
  year={2022}
}
@inproceedings{cui2021discrete,  
  author={Cui, Kai and Tahir, Anam and Sinzger, Mark and Koeppl, Heinz},  
  booktitle={Proc. IEEE CDC},   
  title={Discrete-Time Mean Field Control with Environment States},   
  year={2021},  
  volume={},  
  number={},  
  pages={5239-5246}
}
@article{mondal2023mean,
  title={Mean-Field Control based Approximation of Multi-Agent Reinforcement Learning in Presence of a Non-decomposable Shared Global State},
  author={Mondal, Washim Uddin and Aggarwal, Vaneet and Ukkusuri, Satish V},
  journal={arXiv:2301.06889},
  year={2023}
}

