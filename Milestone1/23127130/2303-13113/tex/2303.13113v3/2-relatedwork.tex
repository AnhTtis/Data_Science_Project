\section{Related Work}
\textbf{Class-Incremental Learning.} Class-Incremental Learning updates a deep classifier with sequentially arriving data, usually with mutually exclusive categories~\citep{masana2020class, defying, wang2023comp, zhou2023class, kilickaya2023towards}. However, when novel data arrives, previous training data becomes unavailable, leading to catastrophic forgetting. To mitigate this, researchers have developed three main approaches: (i) regularization-based methods, which stabilize important parameters or distill previous knowledge into the model~\citep{kirkpatrick2017overcoming,  zenke2017continual, lee2017overcoming, li2017learning, chaudhry2018riemannian, zhou2021co, pass}, (ii) replay-based methods, which usually benefit from regularization-based methods and store a subset of training data to rehearse during learning~\citep{rebuffi2017icarl, chaudhry2018efficient, wu2019large,   aljundi2019gradient, ostapenko2019learning, xiang2019incremental, zhao2020maintaining, rmm, fetril} and (iii) architecture-based methods redesign network architectures by extending the network~\citep{pnn, der, ssre} or freezing network parameters partially to preserve old class knowledge~\citep{aanets, wsn, cps}.

\vspace{5pt}
However, current studies assume a constant amount of regularization and memory size per task throughout learning sessions, which is unnatural since learning unfamiliar objects requires more plasticity than learning familiar ones~\citep{cha2024hyperparameters}. To address this issue, we propose an adaptive method in which the regularization magnitude, learning rate and memory size are automatically tuned within each incremental learning step.

\textbf{Hyperparameter Optimization.} Hyperparameter Optimization (HPO) aims to optimize the hyperparameters of a given deep learning model, including the learning rate, layer size, or balance of different loss functions. In this paper, our focus is on balancing the contribution of a standard cross-entropy and regularization loss, learning rate as well as memory size per task if applicable. To tackle the HPO problem, complex techniques such as bi-level optimization~\citep{franceschi2018bilevel} or gradient-based optimization~\citep{baydin2018automatic} have been proposed. Bi-level optimizers alternate between optimizing neural network weights and tuning the hyper-parameters, while gradient-based methods treat all network weights as hyperparameters to be updated.

\vspace{5pt}
Several recent studies~\citep{AGEM, defying, omdp} share our core motivation by investigating the impact of hyperparameter optimization in subsequent tasks. ~\citet{defying} adopt a two-stage strategy: First, they fine-tune the current task to identify the optimal learning rate with a grid search for maximum plasticity and peak accuracy. Second, they introduce a new thresholding hyperparameter to naively balance the plasticity and stability trade-off: starting with a high regularization strength and decaying it when the performance of the current task is below the defined threshold. However, this approach follows a very naive search since they basically apply two consecutive grid searches to decide the optimal value. Moreover, they focus on a Task-Incremental setup and do not consider the memory size in their search space.

\vspace{5pt}
{\citet{AGEM} tunes the hyperparameters for the first $T$ tasks with a grid search and then uses the best-found values in the remaining tasks. However, it assumes that the initial few tasks are representative enough for the rest of the tasks which may not be realistic in most of the cases. Again, they worked on the Task-Incremental scenario and did not consider the memory size in their search space.

\vspace{5pt}
{\citet{omdp} uses reinforcement learning in a Class-Incremental scenario to adaptively find the best hyperparameter values while learning the tasks. They hold a validation set, similar to our study, to estimate rewards by finding the best set of hyperparameters. However, its search space is limited to learning rate, regularization strength, and the type of classifier.

\vspace{5pt}
In this work, we propose Bayesian Optimization~\citep{snoek2012practical} with Tree Parzen Estimators due to its effectiveness over multiple hyperparameters. We evaluate the generality of our approach by dynamically tuning the learning rate, regularization strength, and memory size across a stream of tasks.

 