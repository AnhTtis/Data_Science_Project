{
    "arxiv_id": "2303.13397",
    "paper_title": "DiffMesh: A Motion-aware Diffusion Framework for Human Mesh Recovery from Videos",
    "authors": [
        "Ce Zheng",
        "Xianpeng Liu",
        "Qucheng Peng",
        "Tianfu Wu",
        "Pu Wang",
        "Chen Chen"
    ],
    "submission_date": "2023-03-23",
    "revised_dates": [
        "2025-01-17"
    ],
    "latest_version": 6,
    "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.MM"
    ],
    "abstract": "Human mesh recovery (HMR) provides rich human body information for various real-world applications. While image-based HMR methods have achieved impressive results, they often struggle to recover humans in dynamic scenarios, leading to temporal inconsistencies and non-smooth 3D motion predictions due to the absence of human motion. In contrast, video-based approaches leverage temporal information to mitigate this issue. In this paper, we present DiffMesh, an innovative motion-aware Diffusion-like framework for video-based HMR. DiffMesh establishes a bridge between diffusion models and human motion, efficiently generating accurate and smooth output mesh sequences by incorporating human motion within the forward process and reverse process in the diffusion model. Extensive experiments are conducted on the widely used datasets (Human3.6M \\cite{h36m_pami} and 3DPW \\cite{pw3d2018}), which demonstrate the effectiveness and efficiency of our DiffMesh. Visual comparisons in real-world scenarios further highlight DiffMesh's suitability for practical applications.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.13397v1",
        "http://arxiv.org/pdf/2303.13397v2",
        "http://arxiv.org/pdf/2303.13397v3",
        "http://arxiv.org/pdf/2303.13397v4",
        "http://arxiv.org/pdf/2303.13397v5",
        "http://arxiv.org/pdf/2303.13397v6"
    ],
    "publication_venue": "WACV 2025"
}