\documentclass[../main.tex]{subfiles}

\begin{document}

\textit{S. Jaiswal, B. Lao, J. N. H. S. Aditya, Y. Zhang, A. Wang,  X. Yang}\newline

\noindent The SHAO team developed a fully-automated pipeline in {\sc python} to work on the Challenge dataset. Our method involved the following steps: 1) We first sliced the datacube into individual frequency channel images and used SExtractor \citep{1996A&AS..117..393B} to  perform source finding on each image. We used a 2.5 sigma detection threshold (for $\sim$99\% detection confidence) and minimum detection area of 2 pixels. 2) We cross-matched the sources found in consecutive channel images using the software TOPCAT \citep{2005ASPC..347...29T} with a search radius of 1 pixel $=2.8$ arcsec. 3) For each source detected in at least two consecutive channel images we estimated the range of channels for each source, adding 1 extra channel on both sides. 4) We extracted a subcube across the channel range obtained in previous step, using a spatial size of 12 pixels around each identified source. 5) We made a moment-0 map for each extracted source using its subcube, after first masking negative flux densities. 6) We used SExtractor on the moment-0 map of each extracted H{\sc i} source to estimate the source RA and Dec coordinates, major axis, minor axis, position angle and integrated flux. Inclination angle was estimated using the relations given by \cite{1926ApJ....64..321H} and \cite{1946MeLuS.117....3H}. 7) We constructed a global H{\sc i} profile for each source by estimating the flux densities within a box of size 6 pixels around the source position in every channel of its subcube. 8) We finally fit a single Gaussian model to estimate the central frequency of H{\sc i} emission and line width at 20\% of the peak.

The score obtained by this method is not very satisfactory. However, our investigations gave us confidence in dealing with a large H{\sc i} cube and making the pipeline for the analysis. We will try to improve our pipeline by optimising the input parameters and implementing different algorithms in the future. The use of machine learning techniques could be a good choice for such datasets.

\end{document}