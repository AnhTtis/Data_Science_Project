\documentclass[../main.tex]{subfiles}

\begin{document}
\textit{A. Vafaei Sadr, N. Oozeer  }\newline

\noindent The HIRAXers team used a multi-level deep learning approach to address the Challenge. The approach extends to 3D a method applied to a similar, 2D, challenge  \citep{vafaei2019deepsource} and uses multiple levels of supervision. Prior to source finding, a pre-processing step is used to detect regions of interest. Motivated by the recent progress in image-to-image translation techniques, one can utilize prior knowledge about source shapes to magnify signals, effectively suppressing background noise in a manner similar to image cleaning. We investigated two pre-processing approaches to reconstruct a `clean' image. For both approaches we used a training set generated by using 2D spatial slices of the development dataset to produce a source map containing masks and probability values. The output of the trained model can then be interpreted as a probability map.  

Our first preprocessing approach used 2D slices in frequency as grayscale images. The model learns to retrieve information employing only transverse information. For the second approach, we extended the inputs into 3D to benefit from longitudinal patterns by adding different frequencies as convolutional channels, thus forming a multichannel image. We used a $128\times128$ sliding window to manage memory consumption, a mean squared error loss function, and a decaying learning rate. We used the standard image processor in {\sc TensorFlow} \citep{tensorflow2015-whitepaper} for minimal data augmentation, with ranges of one degree for rotation and one percent for zoom range, in addition to horizontal and vertical flips. 

We developed our pipeline to examine the following architectures: 
V-Net \citep{milletari2016v};
Attention U-Net \citep{oktay2018attention};
R2U-Net \citep{alom2018recurrent};
U$^2$net \citep{qin2020u2};
UNet$3+$ \citep{huang2020unet};
TransUNet \citep{chen2021transunet} and 
and ResUNet-a \citep{DIAKOGIANNIS202094}. One can find most of the implementations in the {\sc keras-unet-collection} \citep{keras-unet-collection} package. The learning rate was initiated at $1\times 10^{-3}$ with a 0.95 decay per 10 epochs using the Adam optimizer. Our results using the development dataset found that the U$^2$net architecture achieved the best performance. U$^2$net employs residual U-blocks in a `U-shaped' architecture. It applies the deep-supervision technique to supervise training at all scales by downgrading the output. 

In the second step of our method we trained a model to find and characterise the objects. To find the objects, we applied a peak finder algorithm to the 3D output of U$^2$net. A peak is simply the pixel that is larger than all its 27 neighbours. The `found' catalogue was then passed into a modified 8-layer HighRes3DNet \citep{li2017compactness} as a regressor for characterisation before generating the final catalogue.






\end{document}