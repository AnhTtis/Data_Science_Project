\begin{table}
\centering
\caption{Flash Attention for efficient training (V2-99~\cite{lee2019energy} backbone with input resolution of $1600\times640$). }
\label{tab:fash_attn}
\tiny
\resizebox{0.475\textwidth}{!}{
% \setlength{\tabcolsep}{1.5pt}
\begin{tabular}{c|c|c} 
\toprule
\textbf{Flash Attn} & \textbf{A100 Training Time (s/iter)} $\downarrow$& \textbf{GPU Memory (G)}$\downarrow$  \\
\midrule
\ding{52} & \textbf{1.51} & \textbf{27G} \\
\ding{56} & 1.68  & 61G   \\
\bottomrule
\end{tabular}}
% \vspace{-0.5cm}
\end{table}