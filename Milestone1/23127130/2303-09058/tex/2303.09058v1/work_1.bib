@article{rnd,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  journal={arXiv preprint arXiv:1810.12894},
  year={2018}
}

@inproceedings{qmix,
  title={Qmix: Monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Samvelyan, Mikayel and Schroeder, Christian and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  booktitle={International conference on machine learning},
  pages={4295--4304},
  year={2018},
  organization={PMLR}
}

@article{vdn,
  title={Value-decomposition networks for cooperative multi-agent learning},
  author={Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vinicius and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z and Tuyls, Karl and others},
  journal={arXiv preprint arXiv:1706.05296},
  year={2017}
}

@article{per,
  title={Self-Adaptive Priority Correction for Prioritized Experience Replay},
  author={Zhang, Hongjie and Qu, Cheng and Zhang, Jindou and Li, Jing},
  journal={Applied Sciences},
  volume={10},
  number={19},
  pages={6925},
  year={2020},
  publisher={MDPI}
}

@inproceedings{impala,
  title={Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Vlad and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  booktitle={International conference on machine learning},
  pages={1407--1416},
  year={2018},
  organization={PMLR}
}

@article{seed,
  title={Seed rl: Scalable and efficient deep-rl with accelerated central inference},
  author={Espeholt, Lasse and Marinier, Rapha{\"e}l and Stanczyk, Piotr and Wang, Ke and Michalski, Marcin},
  journal={arXiv preprint arXiv:1910.06591},
  year={2019}
}

@inproceedings{coma,
  title={Counterfactual multi-agent policy gradients},
  author={Foerster, Jakob and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@article{maven,
  title={Maven: Multi-agent variational exploration},
  author={Mahajan, Anuj and Rashid, Tabish and Samvelyan, Mikayel and Whiteson, Shimon},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{wqmix,
  title={Weighted qmix: Expanding monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Farquhar, Gregory and Peng, Bei and Whiteson, Shimon},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={10199--10210},
  year={2020}
}

@article{go-explore,
  title={First return, then explore},
  author={Ecoffet, Adrien and Huizinga, Joost and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff},
  journal={Nature},
  volume={590},
  number={7847},
  pages={580--586},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{exploration-survey,
  title={Exploration in deep reinforcement learning: a comprehensive survey},
  author={Yang, Tianpei and Tang, Hongyao and Bai, Chenjia and Liu, Jinyi and Hao, Jianye and Meng, Zhaopeng and Liu, Peng},
  journal={arXiv preprint arXiv:2109.06668},
  year={2021}
}

@inproceedings{vdn-ac,
  title={Value-decomposition multi-agent actor-critics},
  author={Su, Jianyu and Adams, Stephen and Beling, Peter},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={13},
  pages={11352--11360},
  year={2021}
}

@inproceedings{fop,
  title={Fop: Factorizing optimal joint policy of maximum-entropy multi-agent reinforcement learning},
  author={Zhang, Tianhao and Li, Yueheng and Wang, Chen and Xie, Guangming and Lu, Zongqing},
  booktitle={International Conference on Machine Learning},
  pages={12491--12500},
  year={2021},
  organization={PMLR}
}

@article{safe,
  title={Safe multi-agent reinforcement learning through decentralized multiple control barrier functions},
  author={Cai, Zhiyuan and Cao, Huanhui and Lu, Wenjie and Zhang, Lin and Xiong, Hao},
  journal={arXiv preprint arXiv:2103.12553},
  year={2021}
}

@article{game1,
  title={Minimax-optimal multi-agent RL in zero-sum Markov games with a generative model},
  author={Li, Gen and Chi, Yuejie and Wei, Yuting and Chen, Yuxin},
  journal={arXiv preprint arXiv:2208.10458},
  year={2022}
}

@article{distributional,
  title={Distributional Reward Estimation for Effective Multi-Agent Deep Reinforcement Learning},
  author={Hu, Jifeng and Sun, Yanchao and Chen, Hechang and Huang, Sili and Chang, Yi and Sun, Lichao and others},
  journal={arXiv preprint arXiv:2210.07636},
  year={2022}
}

@inproceedings{sparse,
  title={MASER: Multi-Agent Reinforcement Learning with Subgoals Generated from Experience Replay Buffer},
  author={Jeon, Jeewon and Kim, Woojun and Jung, Whiyoung and Sung, Youngchul},
  booktitle={International Conference on Machine Learning},
  pages={10041--10052},
  year={2022},
  organization={PMLR}
}

@inproceedings{sparse2,
  title={Intrinsic motivated multi-agent communication},
  author={Sun, Chuxiong and Wu, Bo and Wang, Rui and Hu, Xiaohui and Yang, Xiaoya and Cong, Cong},
  booktitle={Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems},
  pages={1668--1670},
  year={2021}
}

@article{communication,
  title={Learning individually inferred communication for multi-agent cooperation},
  author={Ding, Ziluo and Huang, Tiejun and Lu, Zongqing},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={22069--22079},
  year={2020}
}

@article{relation,
  title={Graph convolutional reinforcement learning},
  author={Jiang, Jiechuan and Dun, Chen and Huang, Tiejun and Lu, Zongqing},
  journal={arXiv preprint arXiv:1810.09202},
  year={2018}
}

@inproceedings{traffic,
  title={Hierarchically and cooperatively learning traffic signal control},
  author={Xu, Bingyu and Wang, Yaowei and Wang, Zhaozhi and Jia, Huizhu and Lu, Zongqing},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={1},
  pages={669--677},
  year={2021}
}

@inproceedings{auto1,
  title={Interaction-aware decision making with adaptive strategies under merging scenarios},
  author={Hu, Yeping and Nakhaei, Alireza and Tomizuka, Masayoshi and Fujimura, Kikuo},
  booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={151--158},
  year={2019},
  organization={IEEE}
}

@article{auto2,
  title={Smarts: Scalable multi-agent reinforcement learning training school for autonomous driving},
  author={Zhou, Ming and Luo, Jun and Villella, Julian and Yang, Yaodong and Rusu, David and Miao, Jiayu and Zhang, Weinan and Alban, Montgomery and Fadakar, Iman and Chen, Zheng and others},
  journal={arXiv preprint arXiv:2010.09776},
  year={2020}
}

@inproceedings{ray,
  title={Ray: A distributed framework for emerging $\{$AI$\}$ applications},
  author={Moritz, Philipp and Nishihara, Robert and Wang, Stephanie and Tumanov, Alexey and Liaw, Richard and Liang, Eric and Elibol, Melih and Yang, Zongheng and Paul, William and Jordan, Michael I and others},
  booktitle={13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18)},
  pages={561--577},
  year={2018}
}

@article{iql,
  title={Multiagent cooperation and competition with deep reinforcement learning},
  author={Tampuu, Ardi and Matiisen, Tambet and Kodelja, Dorian and Kuzovkin, Ilya and Korjus, Kristjan and Aru, Juhan and Aru, Jaan and Vicente, Raul},
  journal={PloS one},
  volume={12},
  number={4},
  pages={e0172395},
  year={2017},
  publisher={Public Library of Science San Francisco, CA USA}
}

@inproceedings{qtran,
  title={Qtran: Learning to factorize with transformation for cooperative multi-agent reinforcement learning},
  author={Son, Kyunghwan and Kim, Daewoo and Kang, Wan Ju and Hostallero, David Earl and Yi, Yung},
  booktitle={International conference on machine learning},
  pages={5887--5896},
  year={2019},
  organization={PMLR}
}

@article{qatten,
  title={Qatten: A general framework for cooperative multiagent reinforcement learning},
  author={Yang, Yaodong and Hao, Jianye and Liao, Ben and Shao, Kun and Chen, Guangyong and Liu, Wulong and Tang, Hongyao},
  journal={arXiv preprint arXiv:2002.03939},
  year={2020}
}   

@article{qplex,
  title={Qplex: Duplex dueling multi-agent q-learning},
  author={Wang, Jianhao and Ren, Zhizhou and Liu, Terry and Yu, Yang and Zhang, Chongjie},
  journal={arXiv preprint arXiv:2008.01062},
  year={2020}
}

@article{mava,
title={Mava: A Research Framework for Distributed Multi-Agent Reinforcement Learning},
author={Arnu Pretorius and Kale-ab Tessera and Andries P. Smit and Kevin Eloff
and Claude Formanek and St John Grimbly and Siphelele Danisa and Lawrence Francis
and Jonathan Shock and Herman Kamper and Willie Brink and Herman Engelbrecht
and Alexandre Laterre and Karim Beguir},
year={2021},
journal={arXiv preprint arXiv:2107.01460},
url={[https://arxiv.org/pdf/2107.01460.pdf](https://arxiv.org/pdf/2107.01460.pdf)},
}

@article{tleague,
  title={Tleague: A framework for competitive self-play based distributed multi-agent reinforcement learning},
  author={Sun, Peng and Xiong, Jiechao and Han, Lei and Sun, Xinghai and Li, Shuxing and Xu, Jiawei and Fang, Meng and Zhang, Zhengyou},
  journal={arXiv preprint arXiv:2011.12895},
  year={2020}
}

@inproceedings{stabilising,
  title={Stabilising experience replay for deep multi-agent reinforcement learning},
  author={Foerster, Jakob and Nardelli, Nantas and Farquhar, Gregory and Afouras, Triantafyllos and Torr, Philip HS and Kohli, Pushmeet and Whiteson, Shimon},
  booktitle={International conference on machine learning},
  pages={1146--1155},
  year={2017},
  organization={PMLR}
}

@inproceedings{tabular,
  title={Dynamic analysis of multiagent Q-learning with $\varepsilon$-greedy exploration},
  author={Rodrigues Gomes, Eduardo and Kowalczyk, Ryszard},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={369--376},
  year={2009}
}

@article{deeplearning,
  title={A survey and critique of multiagent deep reinforcement learning},
  author={Hernandez-Leal, Pablo and Kartal, Bilal and Taylor, Matthew E},
  journal={Autonomous Agents and Multi-Agent Systems},
  volume={33},
  number={6},
  pages={750--797},
  year={2019},
  publisher={Springer}
}

@inproceedings{center1,
  title={Coordinated reinforcement learning},
  author={Guestrin, Carlos and Lagoudakis, Michail and Parr, Ronald},
  booktitle={ICML},
  volume={2},
  pages={227--234},
  year={2002},
  organization={Citeseer}
}

@article{center2,
  title={Collaborative multiagent reinforcement learning by payoff propagation},
  author={Kok, Jelle R and Vlassis, Nikos},
  journal={Journal of Machine Learning Research},
  volume={7},
  pages={1789--1828},
  year={2006}
}

@inproceedings{iqlta,
  title={Multi-agent reinforcement learning: Independent vs. cooperative agents},
  author={Tan, Ming},
  booktitle={Proceedings of the tenth international conference on machine learning},
  pages={330--337},
  year={1993}
}

@article{samecoma,
  title={Multi-agent reinforcement learning in sequential social dilemmas},
  author={Leibo, Joel Z and Zambaldi, Vinicius and Lanctot, Marc and Marecki, Janusz and Graepel, Thore},
  journal={arXiv preprint arXiv:1702.03037},
  year={2017}
}

@article{exploration1,
  title={Exploration with unreliable intrinsic reward in multi-agent reinforcement learning},
  author={B{\"o}hmer, Wendelin and Rashid, Tabish and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1906.02138},
  year={2019}
}

@article{exploration2,
  title={Coordinated exploration via intrinsic rewards for multi-agent reinforcement learning},
  author={Iqbal, Shariq and Sha, Fei},
  journal={arXiv preprint arXiv:1905.12127},
  year={2019}
}

@article{liir,
  title={Liir: Learning individual intrinsic reward in multi-agent reinforcement learning},
  author={Du, Yali and Han, Lei and Fang, Meng and Liu, Ji and Dai, Tianhong and Tao, Dacheng},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@book{pomdp,
  title={A concise introduction to decentralized POMDPs},
  author={Oliehoek, Frans A and Amato, Christopher},
  year={2016},
  publisher={Springer}
}

@article{alphago,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@inproceedings{icm,
  title={Curiosity-driven exploration by self-supervised prediction},
  author={Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},
  booktitle={International conference on machine learning},
  pages={2778--2787},
  year={2017},
  organization={PMLR}
}

@inproceedings{countbased,
  title={Count-based exploration with neural density models},
  author={Ostrovski, Georg and Bellemare, Marc G and Oord, A{\"a}ron and Munos, R{\'e}mi},
  booktitle={International conference on machine learning},
  pages={2721--2730},
  year={2017},
  organization={PMLR}
}

@inproceedings{drqn,
  title={Deep recurrent q-learning for partially observable mdps},
  author={Hausknecht, Matthew and Stone, Peter},
  booktitle={2015 aaai fall symposium series},
  year={2015}
}

@article{smac,
  title={The starcraft multi-agent challenge},
  author={Samvelyan, Mikayel and Rashid, Tabish and De Witt, Christian Schroeder and Farquhar, Gregory and Nardelli, Nantas and Rudner, Tim GJ and Hung, Chia-Man and Torr, Philip HS and Foerster, Jakob and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1902.04043},
  year={2019}
}

@article{tnnls_marl,
  title={Multitask learning and reinforcement learning for personalized dialog generation: An empirical study},
  author={Yang, Min and Huang, Weiyi and Tu, Wenting and Qu, Qiang and Shen, Ying and Lei, Kai},
  journal={IEEE transactions on neural networks and learning systems},
  volume={32},
  number={1},
  pages={49--62},
  year={2020},
  publisher={IEEE}
}

@article{tnnls_robotic,
  title={Reinforcement learning tracking control for robotic manipulator with kernel-based dynamic model},
  author={Hu, Yazhou and Wang, Wenxue and Liu, Hao and Liu, Lianqing},
  journal={IEEE transactions on neural networks and learning systems},
  volume={31},
  number={9},
  pages={3570--3578},
  year={2019},
  publisher={IEEE}
}

@article{tnnls_cooperative_task,
  title={Learning automata-based multiagent reinforcement learning for optimization of cooperative tasks},
  author={Zhang, Zhen and Wang, Dongqing and Gao, Junwei},
  journal={IEEE transactions on neural networks and learning systems},
  volume={32},
  number={10},
  pages={4639--4652},
  year={2020},
  publisher={IEEE}
}

@ARTICLE{tnnls_cooperative_task2,
  author={Zhang, Zhen and Wang, Dongqing and Gao, Junwei},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Learning Automata-Based Multiagent Reinforcement Learning for Optimization of Cooperative Tasks}, 
  year={2021},
  volume={32},
  number={10},
  pages={4639-4652},
  doi={10.1109/TNNLS.2020.3025711}}

  @ARTICLE{tnnls_saferl,
  author={Nguyen, Thanh Thi and Reddi, Vijay Janapa},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Deep Reinforcement Learning for Cyber Security}, 
  year={2021},
  volume={},
  number={},
  pages={1-17},
  doi={10.1109/TNNLS.2021.3121870}}

@ARTICLE{tnnls_exploration1,
  author={Jiang, Peng and Song, Shiji and Huang, Gao},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Exploration With Task Information for Meta Reinforcement Learning}, 
  year={2021},
  volume={},
  number={},
  pages={1-14},
  doi={10.1109/TNNLS.2021.3121432}}

@ARTICLE{tnnls_exploration2,
  author={Liu, Xiangyu and Tan, Ying},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Feudal Latent Space Exploration for Coordinated Multi-Agent Reinforcement Learning}, 
  year={2022},
  volume={},
  number={},
  pages={1-9},
  doi={10.1109/TNNLS.2022.3146201}}

@ARTICLE{tnnls_exploration3,
  author={Wei, Jiawen and Qiu, Zhifeng and Wang, Fangyuan and Lin, Wenwei and Gui, Ning and Gui, Weihua},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Understanding via Exploration: Discovery of Interpretable Features With Deep Reinforcement Learning}, 
  year={2022},
  volume={},
  number={},
  pages={1-12},
  doi={10.1109/TNNLS.2022.3184956}}

@ARTICLE{tnnls_sa_to_ma,
  author={Hao, Jianye and Yang, Tianpei and Tang, Hongyao and Bai, Chenjia and Liu, Jinyi and Meng, Zhaopeng and Liu, Peng and Wang, Zhen},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Exploration in Deep Reinforcement Learning: From Single-Agent to Multiagent Domain}, 
  year={2023},
  volume={},
  number={},
  pages={1-21},
  doi={10.1109/TNNLS.2023.3236361}}

@article{marlexploration,
  title={Exploration in deep reinforcement learning: a comprehensive survey},
  author={Yang, Tianpei and Tang, Hongyao and Bai, Chenjia and Liu, Jinyi and Hao, Jianye and Meng, Zhaopeng and Liu, Peng and Wang, Zhen},
  journal={arXiv preprint arXiv:2109.06668},
  year={2021}
}

@article{mapreduce,
  title={Parallel data processing with MapReduce: a survey},
  author={Lee, Kyong-Ha and Lee, Yoon-Joon and Choi, Hyunsik and Chung, Yon Dohn and Moon, Bongki},
  journal={AcM sIGMoD record},
  volume={40},
  number={4},
  pages={11--20},
  year={2012},
  publisher={ACM New York, NY, USA}
}

@ARTICLE{tnnls_dataefficiency,
  author={Hu, Chengfang and Wen, Guanghui and Wang, Shuai and Fu, Junjie and Yu, Wenwu},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Distributed Multiagent Reinforcement Learning With Action Networks for Dynamic Economic Dispatch}, 
  year={2023},
  volume={},
  number={},
  pages={1-12},
  doi={10.1109/TNNLS.2023.3234049}}

@ARTICLE{unnecessary_sampling,
  author={Chen, Hongyi and Liu, Changliu},
  journal={IEEE Control Systems Letters}, 
  title={Safe and Sample-Efficient Reinforcement Learning for Clustered Dynamic Environments}, 
  year={2022},
  volume={6},
  number={},
  pages={1928-1933},
  doi={10.1109/LCSYS.2021.3136486}}