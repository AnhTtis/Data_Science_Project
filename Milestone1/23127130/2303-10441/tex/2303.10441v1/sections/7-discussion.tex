\section{Discussion and Limitations}
%noise effects
%ultrasound 
%ecological validity 

\subsection{Form Factor for Deployment}
Currently, our sensing algorithms were run \revision{and evaluated} in an offline setting with a full-functional prototype. \revision{As the instantiation, we also implemented a prototypical realtime VAHF gesture recognition system with the devices shown in Fig. \ref{fig:hardware}, a laptop, and a GPU server. The Zoom H6 recorder served as an audio card that streamed realtime audio data to the laptop. The PC ran a realtime data prepocessing program (written in Python, similar to Section 5.3) on one 2.3GHz Intel CPU core. The PC sent the processed audio segment to the GPU server using a sliding-window strategy while the recognition model processed the audio segment on one Nvidia RTX 3090 GPU and sent the results back to the PC. The whole pipeline ran at 60FPS with a delay of less than 50ms (excluding the network delay). The actual FPS could be controlled by adjusting the stride of the sliding window (typically an FPS higher than 5 could provide a good immediate experience). } 

Although our work demonstrated the computational feasibility of recognizing VAHF gestures, we should further consider the form factors for real-life deployment regarding synchronization, channel access, computational complexity, etc. We discussed the following three questions: 

\textbf{(1) How to synchronize and transmit the signal from different channels?} In our implementation, we used a strong synchronization system, where all the audio channels were wired to the audio card of ZOOM H6. In real deployment, the system could be implemented using Bluetooth low energy (BLE) technique for real-time signal transmission and synchronization (e.g., using broadcast mode or mesh mode for communication\footnote{https://www.bluetooth.com/learn-about-bluetooth/tech-overview/}), allowing dynamic communication among devices.

\textbf{(2) How to determine the proper channels or devices to enable in different scenarios?} As discussed in Section 6, we suggest the channels and devices should be enabled dynamically based on context information (e.g., the activated devices and the surrounding environment). The system would provide multiple levels of interaction progressively based on the activated devices (e.g., more complex gesture set for more devices) while preserving certain environment constraints (e.g., avoid using ultrasound in quiet scenarios or degrading the interaction capability in a noisy environment). With such context-aware optimizations, our technique could be implemented in a more user- and energy-friendly manner.

\textbf{(3) How to reduce the computational complexity?} \revision{In our implementation, we chose MobileNet V3, a light-weight NN model capable for mobile devices, as the backbone model in consideration of the computational efficiency. Further,} there are three possible ways to reduce the computational complexity: 1. using dynamic channels (e.g., using the minimal channels in an efficient mode); 2. using more light-weight feed-forward NN models (e.g., ShuffleNet\cite{zhang2018shufflenet}) for recognition; and 3. adopting bottom-level optimization (e.g., parameter quantization \cite{dettmers20158bit,courbariaux2014training} or customized hardware such as FPGA \cite{birem2014dreamcam}).

\subsection{Robustness against Environmental Interference}
Currently, our data were collected in an indoor environment with no background noise, aiming to validate the feasibility of recognizing VAHF gestures in an ideal setting. For real-world deployment, the recognition model is expected to deal with more complicated data with lower signal-noise ratio (SNR) and more environmental noise. So further research on the effect of environmental interference and how to build a robust recognition model should be conducted. Two strategies - 1) training the model with more diverse data coming from real-world scenarios or synthesization; 2) using advanced preprocessing techniques (e.g., active noise canceling algorithms) to reduce the noise and improve the SNR - may resolve this issue, which are worthy of further investigation. 

%Firstly, applications the proposed technique in the wild should be further conducted. Since our experiment was conducted in the lab with low environmental noise, we can expect that in a noisier environment (e.g., in a restaurant), the noise may overwhelm the voice input from users which may affect the performance of the algorithm. So a robust noise cancelling algorithm is needed.



\subsection{Ultrasound Usage}
We were well acknowledged the use of ultrasound for sensing could be controversial due to the interference and damage to one's hearing. In our work, we used a chirp signal from 17.5KHz to 22.5KHz and we noticed in our data collection procedure, some of the participants could hear the ultrasound and found it annoying. Further, ultrasound at sufficient sound pressure levels exert underlying danger of hearing damage even if it cannot be heard (though we strictly controlled the ultrasound amplitude in our study). Therefore, the use of ultrasound, including the amplitude, frequency, and duration should be more carefully designed for a gesture recognition system. More research should be conducted to explore the use of ultrasound and alternative sensing methods.
 








%noisy environment
%ecological validity of datasets
%













%design
%another sensors or devices? 
%ultrasound for human health?
