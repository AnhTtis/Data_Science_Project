
\vspace{-2.5mm}
\section{Experiments}
\vspace{-3mm}
\subsection{Data}
\vspace{-1mm}
\noindent \textbf{Singing.} We used the OpenSinger dataset \cite{huang2021multi}, which has $50\si{h}$ clean recordings from $76$ speakers. We used 90\% of the audio from the $71$ speakers for the training. We use the remaining 10\% and the other $5$ speakers' recordings as two separate validation sets, \emph{seen} and \emph{unseen} speaker datasets, respectively, to compare the effect of dry source distribution shift on the model performance.

\noindent \textbf{Drum.} We collected the source signals by ourselves; we rendered the \texttt{[kick]}, \texttt{[snare]}, \texttt{[hat]}, \texttt{[tom]}, \texttt{[ride]}, and \texttt{[crash]} tracks separately with $14$ commercial sampling libraries and MIDI files from the Groove MIDI Dataset \cite{groove2019}. 
We performed equalization to the tracks so that each instrument has the same average frequency response across the kit. 
To generate each reference audio, we sampled a random segment from the dry tracks. Then, we generated a graph with the input nodes corresponding to non-zero energy tracks so that there are no dummy subgraphs. This indicates that our system should also perform a drum instrument recognition task. We used the $11$ kits and the MIDI files from the $\texttt{drummer1/session1-3}$ subset for the training. We used $\texttt{drummer1/eval\_session}$ for the two validation sets; we used the same kits for a \emph{seen} kit validation set and the remaining $3$ kits for an \emph{unseen} kit validation set. 
\input{tables/results}

\vspace{-3mm}
\subsection{Metric}
\vspace{-1.5mm}
\noindent \textbf{Prototype Decoding.}
For each decoding step, we evaluate the node and edge error rate, counting each prediction as an error if either token type, node id, or node/edge type is incorrect.
Using the following metrics, we also compare the decoded graph with the ground truth. (i) Invalid graph rate: we consider a graph invalid if it is cyclic, not connected, or missing necessary connections. (ii) Intersection-over-union (IOU) of the node types: while this metric ignores the graph structure, it checks whether necessary processors and input nodes are decoded somewhere in the graph. For the drum graph, we calculate the IOU for each track and mixing subgraph and average the values. Finally, (iii) we render the ground-truth graph and the estimated prototype graph with default parameters and compare the outputs using multi-scale spectral loss (MSS-default) \cite{engel2020ddsp}. 

\noindent \textbf{Parameter Estimation.} Along with the parameter loss, we evaluate the MSS loss rendered on the oracle prototype with estimated parameters (MSS-oracle) and the fully-decoded graph (MSS-full). 

\noindent \textbf{Listening Test.}  We measured subjective scores with MUltiple Stimuli with Hidden Reference and Anchor (MUSHRA) test \cite{mushra, schoeffler2018webmushra}. 
We asked $8$ graduate students to score the similarity between the reference and the rendered audio with the estimated graph. A total of $48$ sets were scored ($24$ sets for each task and $12$ sets for each \emph{seen} and \emph{unseen} speaker/kits).

\input{figures/5-drum_results}

\vspace{-3mm}
\subsection{Evaluation Results}
\vspace{-1.5mm}

\noindent \textbf{Sanity Check.} 
Table 2 reports the evaluation results. Before training the blind estimation models, we first trained a \ding{192} graph autoencoder by introducing another TokenGT as a graph encoder (we also embedded the parameters for the encoder input). Its evaluation results, e.g., $0$ node error rate, confirm that the graph decoder is powerful enough and the dimension of the latent $z$ is sufficiently large to reconstruct the original graph. Furthermore, its MUSHRA score is comparable to the hidden reference's, agreeing with the objective metrics. Next, we evaluated the \ding{193} graph decoder with latent vectors set to $0$. Its node error rate ($0.502$ and $0.602$) is better than what a random guess would achieve. This is because (i) the probability distribution of the processors is nonuniform, (ii) we sorted the LTI subgraphs, and (iii) the ground-truth intermediate prototype is available to the network, which can be exploited for a better guess.


\noindent \textbf{Performance Analysis.} On the \emph{seen} dry speaker/kit sets, the \ding{194} proposed model  reports the node error rate of $0.215$ and $0.335$ for the singing and drum task, respectively, indicating that the perfect reconstruction of the prototype graph is rare.  
Yet, audio rendered from the estimated graph can be perceptually close to the reference, reporting the MUSHRA score of $76.6_{\pm 4.6}$ and $69.8_{\pm 5.4}$. 
On the \emph{unseen} dry speaker/kit sets, the evaluation results are degraded in most metrics, confirming that the graph estimation from unseen sources is challenging. We note that the majority of the errors come from either (i) the wrong order of processors (see Figure \ref{fig:drum-est} and \ref{fig:singing-est-1}) or (ii) some processors which destroy the signal and make preceding processors harder to notice (see Figure \ref{fig:singing-est-2}). 
Finally, to check the difficulty of the blind estimation, we trained the same model but with \ding{195} dry sources also provided as input by concatenating it with the reference across the channel axis. Indeed, the estimation performance improves by a noticeable margin, indicating that extracting the graph-relevant information solely from the reference is a challenging task.

\noindent \textbf{Blind estimation strategy comparison.} We compared our \ding{194} token-by-token approach with the conventional \ding{196} node-by-node decoding method \cite{li2018learning}. While this model uses the same TokenGT backbone, it estimates the next node type first and then performs an edge prediction task using the transformer outputs. It showed similar or slightly worse performance overall compared to our model \ding{194}, and it had the drawback of having a high invalid graph rate. Finally, we tried a \ding{197} single-stage generation method; we decoded the node/edge parameters along with the categorical types. Since the transformer only has access to the decoded intermediate graph, its parameter estimation performance was much worse than the two-stage approach, resulting in higher MSS-full loss and lower MUSHRA score.


