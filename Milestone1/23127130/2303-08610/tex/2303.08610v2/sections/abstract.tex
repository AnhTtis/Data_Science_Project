\begin{abstract}
Musicians and audio engineers sculpt and transform their sounds by connecting multiple processors, forming an \emph{audio processing graph}. 
However, most deep-learning methods overlook this real-world practice and assume fixed graph settings.
To bridge this gap, we develop a system that reconstructs the entire graph from a given reference audio. 
We first generate a realistic graph-reference pair dataset and train a simple blind estimation system composed of a convolutional reference encoder and a transformer-based graph decoder.
We apply our model to singing voice effects and drum mixing estimation tasks. Evaluation results show that our method can reconstruct complex signal routings, including multi-band processing and sidechaining.
\end{abstract}
\begin{keywords}
Graph representation learning, audio processing graph, blind estimation, audio effect.
\end{keywords}