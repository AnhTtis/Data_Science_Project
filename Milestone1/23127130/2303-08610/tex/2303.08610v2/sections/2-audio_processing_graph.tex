\vspace{-1.5mm}
\section{Audio Processing Graph}
\vspace{-1.5mm}

\input{tables/processors}
Our audio processing graph $G$ is a heterogeneous directed acyclic graph (DAG) with the following specifications. 

\noindent \textbf{Processors/Nodes.} Each processor $v_i$ can take audio/control signals as input and output audio/control signals. We normalize each processor's output audio signals so that the total energy remains unchanged.
Each node has a categorical type $t_i$ and continuous-valued parameters $p_i$ as attributes. 
While we can include any processor (even neural networks) in our framework, we use $33$ conventional ones listed in Table \ref{table:processors}. Unless stated otherwise, we use the default implementations \cite{zolzer2011dafx}.
This makes our graph readily interpretable and controllable.

\noindent \textbf{Connections/Edges.} Each connection $e_{ij}$ requires outlet $m_{ij}$ and inlet $n_{ij}$ (or input/output channel) attributes to eliminate any ambiguity. We define the edge's type $t_{ij}$ as an outlet-inlet pair $(m_{ij}, n_{ij})$. When multiple edges are connected to the inlet, we sum the incoming signals. Each edge has a gain parameter $p_{ij}$. 

\vspace{-3mm}
\subsection{Synthetic Graph for Training}
\vspace{-1.5mm}
\noindent \textbf{Prototype Graph.}
The real-world audio processing graphs have frequently occurring \emph{motifs}: combinations of processors (subgraphs) that achieve desired effects. For example, we can control \texttt{[reverb]} using \texttt{[noisegate]}, resulting in the well-known ``gated reverb." 
Inspired by this, we sample and combine various motifs to obtain a synthetic graph. We have $10$ different motifs, from a simple parametric equalizer to more complex parallel $\texttt{[pitchshift]}$ banks. The sampled motifs are serially stacked to generate a full graph except for the following cases: (i) \texttt{[crossover]} can be used for multi-band processing and 
(ii) each motif can receive auxiliary signals from the others for various modulations, e.g., sidechaining. For the drum mixing graphs, we generate a subgraph for each individual source track. Then, we combine the subgraphs with another ``mixing bus" graph. See Figure \ref{fig:lti-reordering}, \ref{fig:drum-est}, and \ref{fig:singing-est} for examples of the synthesized graphs. In this stage, we only determine categorical type attributes $t_i$ and $t_{ij}$ of the graph, and we call this a \emph{prototype graph} $G_0$.

\noindent \textbf{Adaptive Parameter Randomization.} 
Next, we decide the remaining parameters of each prototype graph.
Specifically, we randomize them adaptively to the incoming signals, preventing the graph from having ``ghost" nodes that do not contribute to the final output signal. 
For example, when a \texttt{[highshelf]} receives a \texttt{[crash]} signal, its center frequency should be constrained to the high-frequency region to change the frequency response of the input audio.
To achieve this, we compute the cumulative energy distribution of the input signal across the frequency, then sample the center frequency from where the cumulative distribution lies between $0.2$ and $0.8$. We follow similar procedures to the other low-order linear filters. For the dynamic range controllers, we use an input energy envelope to determine their thresholds. This way, we generated $300\si{k}$ and $450\si{k}$ graph-reference audio pairs for the singing and drum, respectively. The reference audio is stereo, $3.63\si{s}$ long, and has $44.1\si{kHz}$ sampling rate. 

\noindent \textbf{Graphs Statistics.}
Figure \ref{fig:graph-stats} reports the graph statistics of our synthetic graphs.
Especially, we compare our datasets with PCQM4Mv2 chemical dataset \cite{nakata2017pubchemqc},
While the singing/drum graphs have a comparable size to the PCQM4Mv2's, they tend to be more sparse (lower node degree and density). This implies that simple graph neural networks which update each node via aggregating itself and its immediate neighborhoods might struggle to make distant nodes communicate and capture the global structures of the audio processing graphs.

\noindent \textbf{LTI Reordering.}
Different audio processing graphs can produce the same output, making the blind graph estimation a one-to-many problem. One reason is that serially connected single-input single-output linear time-invariant (LTI) systems, either single nodes or subgraphs, can be swapped without changing the entire system response. To resolve this ambiguity, we rearrange them according to their sizes and processor types (see Figure \ref{fig:lti-reordering}). 

\input{figures/2-audio_processing_graph_properties}