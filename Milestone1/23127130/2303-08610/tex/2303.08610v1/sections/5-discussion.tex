\vspace{-2mm}
\section{Discussion}
\vspace{-2mm}

\noindent \textbf{Summary.}
We integrated the audio processing graph structure with deep learning methods. We first synthesized the graph-reference pair data, discussed its characteristics, and built a blind estimation system with the off-the-shelf neural network components. We found that the token-by-token generation is an effective method for our graph structure, and the two-stage approach separately treating the connectivity information and processor parameters is beneficial. 
\input{figures/6-singing_results}

\noindent \textbf{Future Works.}
(i) Currently, the synthetic data remain in the toy example level; more diverse processors and input source signals could be desirable. 
(ii) Many real-world audio processing graph structures allow multi-edges and cycles; relaxing our single-edge DAG constraint could allow more expressive processing capabilities. 
(iii) The evaluation results showed that encoding the references from the unseen source distribution is challenging; we need an improved method for encoding only the processing-relevant information in a disentangled manner.
(iv) The proposed graph decoder uses the default transformer with sinusoidal encodings; further performance improvement
might be obtained by explicitly injecting graph connectivity information.
(v) While we used ground-truth prototypes as input to train the parameter estimation task, at the inference time, the model uses decoded graphs, which are different from the originals in most cases. Furthermore, while not all parameters are equally important for perceptual similarity, we ignored such aspects.
Since most processors we used are known to be differentiable    \cite{neuralbiquads, steinmetz2022styletransfer, lee2022dar}, end-to-end training with audio-domain objectives could be possible and beneficial for alleviating such issues. 
(vi) With the differentiable processors, we can combine them with neural audio processors, allowing us to balance between interpretability/controllability and expressibility.
(vii) Finally, extending the current blind estimation framework to other applications,  e.g., automatic processing \cite{martinez2022automatic, koo2022remaster, stasis2017audio} and style transfer \cite{steinmetz2022styletransfer}, is a promising research direction.