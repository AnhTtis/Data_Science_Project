{
    "arxiv_id": "2303.17783",
    "paper_title": "Uncertainty-Aware Source-Free Adaptive Image Super-Resolution with Wavelet Augmentation Transformer",
    "authors": [
        "Yuang Ai",
        "Xiaoqiang Zhou",
        "Huaibo Huang",
        "Lei Zhang",
        "Ran He"
    ],
    "submission_date": "2023-03-31",
    "revised_dates": [
        "2023-12-05"
    ],
    "latest_version": 4,
    "categories": [
        "cs.CV"
    ],
    "abstract": "Unsupervised Domain Adaptation (UDA) can effectively address domain gap issues in real-world image Super-Resolution (SR) by accessing both the source and target data. Considering privacy policies or transmission restrictions of source data in practical scenarios, we propose a SOurce-free Domain Adaptation framework for image SR (SODA-SR) to address this issue, i.e., adapt a source-trained model to a target domain with only unlabeled target data. SODA-SR leverages the source-trained model to generate refined pseudo-labels for teacher-student learning. To better utilize pseudo-labels, we propose a novel wavelet-based augmentation method, named Wavelet Augmentation Transformer (WAT), which can be flexibly incorporated with existing networks, to implicitly produce useful augmented data. WAT learns low-frequency information of varying levels across diverse samples, which is aggregated efficiently via deformable attention. Furthermore, an uncertainty-aware self-training mechanism is proposed to improve the accuracy of pseudo-labels, with inaccurate predictions being rectified by uncertainty estimation. To acquire better SR results and avoid overfitting pseudo-labels, several regularization losses are proposed to constrain target LR and SR images in the frequency domain. Experiments show that without accessing source data, SODA-SR outperforms state-of-the-art UDA methods in both synthetic$\\rightarrow$real and real$\\rightarrow$real adaptation settings, and is not constrained by specific network architectures.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.17783v1",
        "http://arxiv.org/pdf/2303.17783v2",
        "http://arxiv.org/pdf/2303.17783v3",
        "http://arxiv.org/pdf/2303.17783v4"
    ],
    "publication_venue": "11 pages, 7 figures, 3 tables"
}