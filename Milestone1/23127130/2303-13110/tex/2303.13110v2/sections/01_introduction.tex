\section{Introduction}
\label{sec:intro}

\begin{figure*}[t]
    \centering
    \hfill
    \vskip -3mm
        \includegraphics[width=0.8\linewidth]{figures/fig1_dg_font.pdf}
    \hfill
    \vskip -3mm
    \caption{\textbf{Behavior of pathologists and cell detection models.} Typical cell detection models infer their predictions only by looking at a limited FoV region. Failure cases can occur when cells are difficult to be classified solely by their morphology, i.e., while disregarding the larger architecture of the tissues (context). In the above example, some groups of tumor cells are misclassified as background cells due to their morphology; these tumor cells are smaller and rounder than the nearby ones. Note that the large size and irregular shape are representative characteristics of tumor cells.
    Pathologists overcome these limitations by further understanding the tissue context of the larger FoV region. Misclassified cells can be easily corrected by understanding that such regions are cancer areas.
    }
    \label{fig:intro}
    \vskip -1mm
\end{figure*}

Computational Pathology (CPATH)~\cite{cpath} is a branch of digital pathology that develops methodologies for the analysis of digitized patient specimens, such as Whole-Slide-Images (WSIs).
Cell detection in histology images~\cite{ZHAO2020101786, lal2021nucleisegnet, qu2020weakly} is one of the most important tasks in CPATH. It allows the quantification and analysis of different cell types, which can lead to better prognosis evaluation~\cite{SUN2021103492,park2022artificial} and patient treatment planning while maintaining medical interpretability~\cite{diao2021human}. 
Since it has the potential to impact human lives, high-performance cell detection models are essential in real-world applications and need to be investigated.


To better locate and classify cells, detailed morphological characteristics such as color and shape are crucial. 
Consequently, cell detection datasets are typically collected at high magnification but small Field-of-View (FoV).
However, this can make the cell detection model overly rely on appearance details, without understanding the broader context~\cite{awmfovnet}. 
This context can help cell detection by providing information about how cells are arranged and grouped together to form high-level tissue structures.
In practice, expert annotators (pathologists) first zoom out to understand these broad tissue structures.
Next, they zoom in to better classify individual cells while taking into account the context information, as depicted in \autoref{fig:intro}.


The behavior of pathologists can be transferred to deep learning, for instance, through a multi-task strategy combining cell detection tasks at high magnification and tissue segmentation at low magnification. This type of approach would allow the model to share knowledge across different tasks and FoVs. However, to train such an approach, a combined dataset with cell-tissue overlapping regions is required; unfortunately, most existing datasets only target a single task, either cell detection~\cite{MoNuSeg, GRAHAM2019101563} or tissue segmentation~\cite{PANDA, digestpath}. 

In this paper, we introduce a new research direction: \emph{studying cell-tissue relationships for cell detection.}
First, we publish the \textbf{\ours} dataset, which contains cell and tissue annotations in small and large FoV patches, respectively, with overlapping regions. Additionally, the data is collected from WSIs of multiple organs. 
This can provide the necessary data for researchers to study cell-tissue relationships and their effect on cell detection.
Second, we introduce simple multi-task learning approaches for cell detection that can benefit from cell-tissue relationships and demonstrate their advantages over 3 different datasets. These approaches consistently show better cell detection performance compared to the cell-only baseline, i.e., a model trained only with small FoV patches with the corresponding cell annotations.
We hope that our proposed \ours dataset and methods will encourage the CPATH community to learn how to reflect cell-tissue relationships better to improve cell detection.

Our contributions are 3-fold and summarized as follows,
\begin{itemize}
    \item The first work that exploits cell-tissue relationships for better cell detection, to the best of our knowledge. 
\vspace{-1mm}
    \item We release \ours, a dataset with overlapping cell and tissue annotations based on Hematoxylin and Eosin (H\&E) stained WSIs of multiple organs. 
\vspace{-1mm}
    \item We introduce several approaches that boost cell detection performance via multi-task learning, and empirically confirm that these methods generalize well across different datasets and histological stainings.
\end{itemize}
