\section{Experiments and Results}
\label{sec:experiments}
\input{sections/tab_main}
\input{sections/tab_organ}
We validate the hypothesis that incorporating cell-tissue relationships within a cell detection model is beneficial by evaluating the proposed models on \ours and 2 other datasets. 
First, we describe the additional datasets and implementation details. 
Then, we show how the proposed multi-task learning methods can improve the performance of a cell detection task. 
Lastly, we conduct an ablation study to investigate how important using large FoV patches $\{x_l\}$ and corresponding tissue segmentation labels $\{y_l^t\}$ are in enhancing cell-tissue relationships.

\subsection{Other Datasets}
\label{ssec:other-datasets}
\paragraph{TIGER.} 
As mentioned in \autoref{sec:ct_datasets}, TIGER is a public dataset, based on H\&E stained images, which includes both cell and tissue annotations in overlapping patches.
However, the patch sizes and amount of overlap between cell and tissue annotations highly vary among samples. Therefore, a pre-processing step is necessary to generate paired cell-tissue patches with consistent FoVs. 
After pre-processing, we obtain 9,888 paired patches of size 512$\times$512 and 128$\times$128 pixels for the tissue segmentation and cell detection tasks, respectively, with an MPP of approximately 0.5 $\mu m/px$.
Most samples in TIGER include small regions with annotated cells, making it necessary to extract smaller patches. This explains why the absolute number of patches is larger than in \ours or CARP, although the actual amount of annotated cells and tissue area are smaller than the latter datasets, as shown in \autoref{tab:label_stats_new}.
In TIGER, one cell class (lymphocyte cells) and seven tissue classes are annotated. More details about the pre-processing and this dataset are provided in the \supple.

\vspace{-4mm}
\paragraph{CARP.} This is an internal lung cancer dataset of PD-L1 IHC-stained WSIs, containing 6,480 paired patches extracted from 1,012 WSIs. The patch sizes, resolution, annotation protocol, and general configuration are similar to \ours, as described in \autoref{ssec:data-collect}.
Two cell classes are annotated: PD-L1 positive tumor cells (\textit{TC+}), and PD-L1 negative tumor cells (\textit{TC-}). The tissue classes are the same as in \ours (BG, CA, and UNK).
CARP is a real-world and large-scale dataset, with 809.1K annotated cells and 4.1080 $mm^2$ tissue area, which is approximately 10 and 20 times more than \ours and TIGER, respectively.
Moreover, the stain type is different from \ours and TIGER, allowing us to validate the effectiveness of the cell-tissue relationships across different staining methods.

\subsection{Implementation details}
As previously mentioned in \autoref{subsec:preliminary}, both cell and tissue branches are based on DeepLabV3+ \cite{deeplabv3plus2018}, with a ResNet-34~\cite{He2015} encoder. The models are trained for 300, 150, and 100 epochs in \ours, TIGER, and CARP datasets, respectively. We use the Adam optimizer~\cite{KingmaB14}, and, for each experiment, we tune the learning rate within a $[5\times10^{-5}, 2\times10^{-3}]$ range.
The model at the epoch with the best validation set performance is chosen and used for evaluation on the test set.
All experiments are repeated 5 times, and we report the mean and 95\% confidence interval of the performance metrics.
For more implementation details, please refer to the \supple.

\subsection{Main Results}
The cell detection results obtained by the \textit{Cell-only} baseline, the proposed approaches, and the \textit{Tissue-label leaking} model are shown in \autoref{tab:main}.
The \textit{Cell-only} baseline is a simple cell detection model that only receives the small FoV patches as input. In other words, it only considers the cell branch in \autoref{fig:pred_to_x} and neither tissue annotations nor large FoV patches are leveraged. The \textit{Tissue-label leaking} model, described in \autoref{subsec:pred-to-x}, receives the tissue annotations as input and serves as an exploratory experiment to obtain insight regarding how much the cell detection task can benefit from leveraging tissue annotation.

From \autoref{tab:main}, we observe that all the cell-tissue multi-task learning-based approaches, except for the \textit{Pred-to-output} model, outperform the \textit{Cell-only} baseline across all datasets. These improvements imply that cell detection on small FoV patches benefits from learning cell-tissue interrelationships from both large FoVs and tissue annotations.
We hypothesize that the reason for the low performance of the \textit{Pred-to-output} model is that the injection of tissue prediction to the cell branch happens too late. Therefore, there is a lack of network capacity for fusing cell and tissue information.

Furthermore, in \autoref{tab:organ}, we report mean F1 scores per organ in the  \ours test set. Except for the \textit{Pred-to-output}, all approaches show improvement compared to \textit{Cell-only} baseline in most organs. Especially, our best-performing model, \textit{Pred-to-inter-2}, demonstrates superior performance over \textit{Cell-only} in all 6 organs with a significant margin. Such a result shows that considering cell-tissue relationships can generally help the cell detection task across various organs.

\input{sections/tab_ablation_new}

% Qualitative figure
\begin{figure*}[t]
    \centering
    \vspace*{-2mm}
    \includegraphics[width=0.94\linewidth]{figures/qualitative.pdf}
    \vspace{-3mm}
    \caption{\textbf{Qualitative comparison between the \textit{Pred-to-inter-2} and \textit{Cell-only} models}. \textit{Pred-to-inter-2} shows enhanced detection results aided by understanding the tissue environment from a broader context (blue: tumor cells, yellow: background cells, green: cancer area).}
\label{fig:qualitative}
\vspace{-4mm}
\end{figure*}

\subsection{Dataset Ablation Study}
Two data components in \ours contribute to better leveraging cell-tissue relationships for the task of cell detection: (1) the large FoV patches $x_l$, and (2) the corresponding tissue annotations $y_l^t$ that allows us to have a tissue segmentation objective and a multi-task learning setting.
To verify the effectiveness of each data component, we conduct an ablation study where each component is evaluated separately while keeping the model architecture fixed.
First, if only the tissue segmentation label is provided without a large FoV patch, the tissue branch takes $x_s$ as an input and it is trained with both the tissue and the cell detection objectives.
Second, if the large FoV patch is given without the corresponding tissue label, the tissue branch takes $x_l$ as an input and the model is only trained with the cell detection objective.


The results of the ablation study are shown in \autoref{tab:ablation}. We observe that each of the individual components on their own lead to improved performance. Hence, we can conclude that a large FoV patch and tissue segmentation label can contribute to better cell detection by providing a broader context and encoding the cell-tissue relationship, respectively.
Moreover, when utilized simultaneously, we observe that both components work synergetically, leading to an even better performance improvement.
We also found that the tissue branch generates better tissue predictions when trained with a large FoV. Thus, providing accurate tissue information to the cell branch is important for boosting performance. Please, refer to the \supple for a detailed tissue performance comparison.
Finally, this study shows evidence that the patch configuration defined in \ours is suitable for cell-tissue co-training, with a smaller FoV for cell detection $(x_s, y_s^c)$ and a larger FoV for tissue segmentation $(x_l, y_l^t)$.


\subsection{Qualitative Analysis} \label{subsec:qualitative}
In this section, we visualize the cell predictions of the \textit{Cell-only} and \textit{Pred-to-inter-2} models.
We select the \textit{Pred-to-inter-2} model, as it is the overall best-performing model in our experiments.
In general, when compared to other background cells, tumor cells have the following characteristics: large size and irregular shape. However, cancer is heterogeneous and this is not always the case.
Indeed, in \autoref{fig:qualitative}, most of the cells are small and have a regular round shape. Based on these appearances, and without a larger context, those cells can be easily misclassified as background cells, which is the case of the \textit{Cell-only} model.
On the other hand, \textit{Pred-to-inter-2} shows a more accurate prediction by correctly understanding the cancer area in large FoV regions.
This implies that \textit{Pred-to-inter-2} indeed considers both the morphology of cells and the tissue context, while \textit{Cell-only} relies on the cells' morphology alone. 
