\section{Introduction} \label{sec:intro}

Information Retrieval~(IR) aims to retrieve relevant passages for a given query, which plays a critical role in many industry scenarios such as Open-Domain Question Answering (QA)~\cite{lee2019latent} and Web Search~\cite{bajaj2016ms}. 
Traditionally, bag-of-words~(BOW) retrieval systems such as TF-IDF and BM25~\cite{robertson2009probabilistic} were widely used, which mainly depend on keyword matching between queries and passages. 
With the development of large-scale pre-trained language models~(PLMs)~\cite{vas2017attention,devlin2018bert} such as BERT, dense retrieval methods~\cite{lee2019latent,karpukhin2020dense} show quite effective performance. 
These methods usually employed a dual-encoder architecture to encode both queries and passages into dense embeddings and then perform approximate nearest neighbor searching~\cite{johnson2019billion}.

Recently, some works found that dense retrievers perform poorly in the zero-shot multilingual settings~\cite{zhang2021mr} due to the distributional shift. To boost the performance of dense retrievers, some previous methods for cross-domain retrieval can be directly adopted to unsupervised multilingual dense retrieval. There are two important kinds: 1) generating training data in target languages. For example, Kulshreshtha \etal applied self-training to generate labeled data and further proposed back-training~\cite{kulshreshtha2021back} to obtain more high-quality data. QGen~\cite{ma2020zero} proposed to use a query generator to generate in-domain queries. 2) leveraging sparse retrievers, which is more effective in the unsupervised setting, to enhance dense retrievers. For example, SPAR~\cite{chen2021salient} proposed to distill knowledge from BM25 to the dense model and LaPraDoR~\cite{xu2022laprador} proposed to enhance the dense model by multiplying the similarity with the BM25 score. 

However, there are three major problems when directly adopting these methods to multilingual dense retrieval.
First, zero-shot multilingual query generators suffer from grammatical adjustment and accidental translation problems~\cite{xue2020mt5}. As a result, zero-shot query generators only provide little help in bridging the gap among different languages.
Second, hybrid dense and sparse models such as LaPraDoR and SPAR get high latency in the inference stage\footnote{The latency of dense retriever on GPU is 32ms and the latency of BM25 on CPU is 36ms~\cite{gao2021coil}.}.
Finally, dense retrieval is different from other tasks, it not only needs positive query-passage pairs but also needs negative query-passage pairs~\cite{xiong2020approximate}. However, previous methods such as the back-training focus on positive pairs and simply take the top passages of BM25 as negative passages.

Although training data in target languages is very expensive, unlabeled queries and passages can be easily obtained from search engines such as \emph{Google} and \emph{Bing}. 
In this paper, we propose a novel method that augments data in target languages by combining sparse and dense models, namely \name, which stands \uline{L}exicon-\uline{e}nhanced \uline{S}elf-supervised \uline{T}raining for \uline{M}ultilingual dense retrieval. First, as we mentioned above, sparse retrievers mainly depend on keyword matching between queries and passages and dense retrievers mainly depend on the language modeling ability of pre-trained models, which indicates the sparse and dense models perform retrieval in different aspects~\cite{chen2021salient}. In addition, the sparseâ€“dense hybrid retriever is significantly better than both sparse and dense models~\cite{zhang2021mr,ma2021replication}. Both can demonstrate that sparse and dense models notice different characteristics and are complementary. Therefore, we craft a lexicon-enhanced retrieval module to mine positive and negative passages for each unlabeled query in target languages, which leverages the retrieval results of both sparse and dense models. We treat passages that both sparse and dense models regard are relevant as positive passages, and passages that one model regards are relevant but the other regards are irrelevant as negative passages. 

Furthermore, we employ a query generator to generate queries for passages in target languages due to the limited number of unlabeled queries. The query generation methods have been shown to significantly improve the performance of retrieval models in the monolingual setting~\cite{kulshreshtha2021back,ma2020zero}. Considering the grammatical adjustment and accidental translation problems, we first use the mined positive query-passage pairs to train a query generator. Then, we use the trained model to generate more queries in target languages. Considering that there may exist more relevant passages to the generated queries, we use both sparse and dense retrievers to filter the generated samples.
Finally, using only unlabeled data from target languages, \name iteratively mines query passage pairs by the lexicon-enhanced retriever and generator, trains a new better retriever and query generator using these mined pairs, mines again for better query passage pairs, and repeats.

In summary, our contributions are as follows.
\begin{itemize}
    \item To the best of our knowledge, our approach is the first attempt to combine sparse and dense retrievers to mine high-quality positive and negative query-passage pairs for the multilingual dense retriever.
    \item We propose to use a query generator to expand the unlabeled queries in target languages and an iterative training paradigm is introduced to further enhance the dense retriever and generator.
    \item Extensive experiments on two datasets show the effectiveness of our proposed approach. In particular, experiments demonstrate that our method is model-agnostic, they are effective on various pre-trained language models.
\end{itemize}
