\section{Conclusion}

In this paper, we propose a novel augmentation method that combines sparse and dense retrievers for multilingual retrieval.
We firstly designed a passage mining method based on the results of both sparse and dense retrievers.
After that, we utilized the mined data to train a query generation model and generate more training data.
Extensive experimental results show that the proposed method outperforms the baselines, and can significantly improve the state-of-the-art performance. 
Currently, we directly utilize a large number of unlabeled queries in target languages. As future work, we will investigate how to augment training data without any unlabeled queries in target languages.

\section{Limitations}

The limitations are summarized as follows.

\begin{itemize}
    \item The method needs unlabeled queries. For seriously rare languages, there are no unlabeled queries in search engines and we cannot perform our passage mining method in this condition. Although our query generation module can alleviate this problem, the zero-shot query generator suffers from grammatical adjustment and accidental translation problems and can only provide limited help.
    \item The method performs inconsistently on the two metrics~(MRR@100 and Recall@100). Due to the quality of augmented data, we need to set some threshold to filter the augmented data, where different parameters lead to optimal performance on different metrics.
    \item The sparse retriever is fixed during training. The fixed sparse retriever leads to the rapid convergence of the dense retriever. We believe that if both sparse and dense retrievers can be improved in the iterative process, the dense retriever may achieve better performance.
\end{itemize}
