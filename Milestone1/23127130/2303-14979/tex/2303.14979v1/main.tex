% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
\usepackage{EMNLP2022}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}


% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

\usepackage{bm}
\usepackage{array}
\usepackage{xspace}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{makecell}
\usepackage{subfigure}
\usepackage[normalem]{ulem}
\usepackage[ruled]{algorithm2e}

\setlist[itemize]{leftmargin=5mm, itemsep=0mm}

\useunder{\uline}{\ul}{}

\newcommand{\name}{LeSTM\xspace}
\newcommand{\ie}{\emph{i.e.,}\xspace}
\newcommand{\eg}{\emph{e.g.,}\xspace}
\newcommand{\etc}{\emph{etc.}\xspace}
\newcommand{\wrt}{\emph{w.r.t.}\xspace}
\newcommand{\aka}{\emph{a.k.a.,}\xspace}
\newcommand{\etal}{\emph{et al.}\xspace}
\newcommand{\paratitle}[1]{\vspace{1ex}\noindent{\bf #1}}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Lexicon-Enhanced Self-Supervised Training for \\ Multilingual Dense Retrieval}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{
  Houxing Ren$^1$\thanks{~~Work done during internship at Microsoft STCA.} \quad Linjun Shou$^2$ \quad Jian Pei$^3$ \quad Ning Wu$^2$ \quad Ming Gong$^2$ \quad Daxin Jiang$^2$\thanks{~~Corresponding author.} \\
  $^1$School of Computer Science and Engineering, Beihang University \\
  $^2$Microsoft STC Asia \\
  $^3$Duke University, Durham, NC, USA 27705 \\
  renhouxing@buaa.edu.cn~~\{lisho,wuning,migon,djiang\}@microsoft.com~~j.pei@duke.edu
}

\begin{document}
\maketitle

\begin{abstract}
Recent multilingual pre-trained models have shown better performance in various multilingual tasks. However, these models perform poorly on multilingual retrieval tasks due to lacking multilingual training data. In this paper, we propose to mine and generate self-supervised training data based on a large-scale unlabeled corpus. We carefully design a mining method which combines the sparse and dense models to mine the relevance of unlabeled queries and passages. And we introduce a query generator to generate more queries in target languages for unlabeled passages. 
Through extensive experiments on Mr. TYDI dataset and an industrial dataset from a commercial search engine, we demonstrate that our method performs better than baselines based on various pre-trained multilingual models. Our method even achieves on-par performance with the supervised method on the latter dataset.
\end{abstract}

\input{sec-int}
\input{sec-rel}
\input{sec-met}
\input{sec-exp}
\input{sec-con}

\section*{Acknowledgments}

Jian Peiâ€™s research is supported in part by the NSERC Discovery Grant program. All opinions, findings, conclusions and recommendations in this paper are those of the authors and do not necessarily reflect the views of the funding agencies.

\bibliography{references}
\bibliographystyle{acl_natbib}

\input{sec-app}

\end{document}
