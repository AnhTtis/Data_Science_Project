%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}
\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.


%\usepackage[pdftex,dvipsnames]{xcolor}  % Coloured text etc. 
\usepackage[colorinlistoftodos,obeyFinal]{todonotes}                           
%\usepackage{caption}
\usepackage{fainekos-macros}
\usepackage[]{algorithm2e}
\usepackage{amsmath} % assumes amsmath package installed
\usepackage{amssymb}  % assumes amsmath package installed
\usepackage{nccmath}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{arrows}
\usepackage{ifthen}
\usepackage{mathtools}
\usepackage{stmaryrd}
\usepackage{csquotes}
\usepackage{xargs}                      % Use more than one optional 
\usepackage{subcaption}
\usepackage{textcomp}
\usepackage{bm}
\usepackage{cite}
\usepackage{multirow}
\graphicspath{{./figures/}} %%
%\usepackage{hyperref}

\usepackage{siunitx} % unit package
% \usepackage{siunitx}[=2021-07-22]

\newcommand{\qtraj}{\mathbf{q}}
\newcommand{\rob}{\rho}
\newcommand{\robf}{\rho_{\formula}}
\newcommand{\robfa}{\rho_{\formula_1}}
\newcommand{\robfb}{\rho_{\formula_2}}
\newcommand{\srob}{\tilde{\rob}}
\newcommand{\srobf}{\srob_\formula}
\newcommand{\smax}{\widetilde{\max}}
\newcommand{\smin}{\widetilde{\min}}
\newcommand{\sdist}{\widetilde{\mathbf{dist}}}
\newcommand{\pd}{\hat{p}}
\newcommand{\qd}{\hat{q}}
\newcommand{\sd}{\rho}
\newcommand{\bs}[2]{\ll\!#1,#2\!\gg}
\newcommand{\rd}[2]{\ll\!#1,#2\!\gg_\Re}
\newcommand{\rs}[2]{\ensuremath{\llbracket #1,#2 \rrbracket}}
\newcommand{\cl}[1]{\overline{#1}}
\newcommand{\Ltf}{\Lc_t(\formula)}
\newcommand{\Ltnp}{\Lc_t(\lnot p)}
\newcommand{\Ltp}{\Lc_t(p)}
\newcommand{\Lrf}{\Lc_{\Re_\Fc}}

%for blank footnote
\usepackage{lipsum}
\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{prop}{Proposition}
% remove acm copyright
\usepackage{etoolbox}
\makeatletter
\patchcmd{\maketitle}{\@copyrightspace}{}{}{}
\makeatother

\usepackage{xcolor}
\newcommand\ypcomment[1]{\textcolor{blue}{\textbf{#1}}}
\newcommand{\dtt}{[0\!:\!dt\!:\!T]}
\newcommand{\vl}{\underline{v}}
\newcommand{\vu}{\bar{v}}
\newcommand{\al}{\underline{a}}
\newcommand{\au}{\bar{a}}
%\usepackage{url}
%\usepackage[hyphens,spaces,obeyspaces]{url}
\usepackage{stmaryrd}
\usepackage{hyperref}
% Control spacing...
\setlength{\marginparwidth}{4cm}
%\setlength{\textfloatsep}{2pt}
\linespread{0.99}
%\usepackage{geometry}
%\thickmuskip=0mu
%\usepackage[margin=0.7in]{geometry}
\usepackage[left=0.667in,right=0.667in,bottom=0.599in,top=0.792in]{geometry}
%\pdfminorversion=4 

\begin{document}

\title{\LARGE \bf
    % Gaussian Process Learning-based Modeling of Human-driven Vehicles Interacting with Connected Autonomous Vehicle Platoons for Safe Longitudinal Car-following Control
    % Towards Real-time Learning-Based Model Predictive Control for Safe Mixed Vehicle Platooning through Efficient  Human-driven Vehicle Modeling
    % Efficient Learning-Based Modeling of Human-driven Vehicle for Safe Mixed Vehicle Platooning
    % Learning-Based Modeling of Human-Autonomous Vehicle Interaction for Safe Mixed-Vehicle Platooning Control
    % Efficient Learning-Based Modeling of Human-Driven Vehicle for Safe Mixed Vehicle Platooning Control
    Learning-Based Modeling of Human-Autonomous Vehicle Interaction for Enhancing Safety in Mixed-Vehicle Platooning Control
}

\author{Jie Wang$^{1}$, Yash Vardhan Pant$^{1}$, and Zhihao Jiang$^{2}$% <-this % stops a space
% \thanks{*This work was not supported by any organization}% <-this % stops a space
\thanks{$^{1}$ Jie Wang and Yash Vardhan Pant are with the Electrical and Computer Engineering Department, University of Waterloo, Waterloo, ON, Canada.
    E-mail: {\tt\small \{jie.wang, yash.pant\}@uwaterloo.ca}}%
\thanks{$^{2}$ Zhihao Jiang is with the School of Information Science and Technologies, ShanghaiTech University, Shanghai, China. 
    E-mail: {\tt\small jiangzhh@shanghaitech.edu.cn}}%
}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract} 
As autonomous vehicles (AVs) become more prevalent on public roads, they will inevitably interact with human-driven vehicles (HVs) in mixed traffic scenarios. To ensure safe interactions between AVs and HVs, it is crucial to account for the uncertain behaviors of HVs when developing control strategies for AVs. In this paper, we propose an efficient learning-based modeling approach for HVs that combines a first-principles model with a Gaussian process (GP) learning-based component. The GP model corrects the velocity prediction of the first-principles model and estimates its uncertainty. Utilizing this model, a model predictive control (MPC) strategy, referred to as GP-MPC, was designed to enhance the safe control of a mixed vehicle platoon by integrating the uncertainty assessment into the distance constraint. We compare our GP-MPC strategy with a baseline MPC that uses only the first-principles model in simulation studies. We show that our GP-MPC strategy provides more robust safe distance guarantees and enables more efficient travel behaviors (higher travel speeds) for all vehicles in the mixed platoon. Moreover, by incorporating a sparse GP technique in HV modeling and a dynamic GP prediction in MPC, we achieve an average computation time for GP-MPC at each time step that is only 5\% longer than the baseline MPC, which is approximately 100 times faster than our previous work that did not use these approximations. This work demonstrates how learning-based modeling of HVs can enhance safety and efficiency in mixed traffic involving AV-HV interaction.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Backgrounds.

% Contributions. \textcolor{red}{YP: What are the main contributions, write in list form here}.

% Related works. 
% Traditional modeling methods.
% Data-driven methods.

% GP models are used to learn unmodeled dynamics in learning-based robotic control. \cite{}

% \textcolor{red}{YP: Also list all the section titles you want to use in this paper. }

\section{INTRODUCTION}
%\subsection{Background}
In the last decade, there has been a significant increase in the development of autonomous vehicles (AVs) and intelligent transportation systems, such as connected autonomous vehicles (CAVs) platooning, to enhance traffic efficiency and safety \cite{guanetti2018}. AV platooning involves coordinated driving, enabling small gaps between vehicles while maintaining safe speeds \cite{martinez2021}. CAVs in a platoon can exchange real-time information on speed, acceleration, and distance, enabling them to be controlled in a coordinated manner by synchronizing their maneuvers. This allows them to travel safely at high speeds while maintaining small gaps between vehicles \cite{martinez2021}. However, despite the increased deployment of AVs, human-driven vehicles (HVs) are predicted to remain predominant for decades \cite{rahmati2019}, and human drivers will inevitably need to interact with AVs and vice-versa. One example of this mixed traffic scenario is shown in Fig. \ref{figure:1}, where a human drives a car behind a platoon of CAVs. 

A recent study on traffic accidents involving AVs in the United States found that in mixed traffic scenarios, 64.2\% of accidents involved HVs rear-ending autonomous vehicles, compared to only 28.3\% in traditional traffic with only HVs \cite{petrovic2020}. The study concluded that this increase in ``rear-end'' traffic accidents is due to drivers not being accustomed to the dynamic characteristics of autonomous vehicle platoons. Instead of relying on drivers to be more cautious when interacting with AVs, it is more practical to implement CAV control policies that consider human driver behaviors to ensure safe collaborations in mixed-traffic environments. Although previous research has explored interactions between HVs and AVs for car-following applications, most of these models are not directly suitable for model-based control \cite{sadat2020}. Therefore, it is crucial to develop an HV-AV interaction model that is easy to interpret and applicable to model-based control design to ensure safety and other satisfactory goals.

%
\begin{figure}
    \centerline{\includegraphics[width=0.96\columnwidth]{figures/AVs_HVs_platoon.png}}
    \caption{A mixed vehicle platoon consists of $N_a$ connected AVs denoting as ${A^1, A^2, \cdots, A^{N_a}}$, along with a HVs $H$ following at the rear. The AVs share real-time information such as speed, acceleration, and distance with a one-after-the-other bidirectional communication topology. There is no communication between the CAVs and the HV. In contrast to scenarios where an HV interacts with a single AV that lacks cooperation from the traffic in front, AVs within a platoon can coordinate their behaviors to enable a safer interaction between the following HV and the last AV in the platoon.
    }
    \label{figure:1}
\end{figure}
%

% Unlike AVs, even though many HVs are also equipped with sensors that can measure speed and distance, they do not communicate to share this information with other vehicles. AVs have the capabilities to measure their own states, and also can gather information about neighboring traffic. The modeling of HVs can therefore be made based on the measurements of the human-driven vehicle. Predictions of the human-driven vehicle made by the model can be shared with other AVs in the vehicle platoon to help improve the driving safety, fuel efficiency and riding comfort of the entire fleet \cite{guo2020}. 

% The data analysis in here shows that most AV accidents are when AVs are rear-ended by human driven vehicles! 

% This is a great motivator for our case study, and we can argue that co-operative platooning with our method would indeed make things safer.

\subsection{Contributions}
This paper proposes a learning-based method to model HVs interacting with a platoon of AVs for longitudinal car-following control applications. 
% learning-based MPC strategy for the longitudinal car-following control of a mixed vehicle platoon. The uncertainties of the human-driven vehicle are explicitly modeled in the MPC design to better guarantee safe interactions between AVs and HVs in challenging traffic scenarios such as emergency braking. 
The main contributions are summarized as follows: 

\begin{itemize}
    \item We proposed a novel approach that combines a first principles-based model of human behaviors and a data-driven GP model trained on human-in-the-loop simulator data to model HVs in a velocity tracking setting. The GP model corrects and estimates the uncertainty of the velocity prediction. Our new model reduces the modeling error by 35.6\% compared to the first-principles model. To improve the efficiency of the GP model (full GP), we employed a sparse GP technique to reduce the average computational time by 18 times compared to the full GP model and still provide a 24\% overall modeling accuracy improvement compared to the first-principles model.
    
    \item We developed a chance-constrained MPC strategy (GP-MPC) that utilized the proposed HV model to estimate modeling uncertainties as an additional probabilistic constraint to guarantee a safe distance between the HV and the front AV. This probabilistic constraint was added to a pre-defined deterministic distance to form an adaptive safe distance constraint to ensure safer HV-AV interactions. 
        
    \item Simulation studies show that the GP-MPC outperforms a baseline MPC approach (nominal MPC) which uses the first-principles model. The GP-MPC ensures a greater minimum distance between vehicles and enables more efficient travel behaviors (higher travel speeds) for all vehicles in the mixed platoon. Compared to the nominal MPC, the GP-MPC requires only 5\% increase in computation time due to the use of sparse GP modeling for HV and a dynamic GP prediction in MPC. As a result, the average computation time of the GP-MPC at each time has been reduced by approximately 100 times compared to previous work \cite{wang2023b} that did not employ these techniques.
\end{itemize}

\subsection{Related work}

% Model predictive control (MPC) is commonly used for vehicle platoon system control because it is a well-established optimal control method that explicitly considers constraints \cite{yu2021}. Different from a single or multiple AVs control, applying MPC to a mixed vehicle platoon control needs to satisfy the constraint subject to human-driven vehicle modeling. 
A growing number of studies have been conducted on the safe interactions between HVs and AVs in mixed traffic scenarios \cite{tampere2004}. However, in most of these studies, human behaviors are either assumed to be the same in HV-AV interactions or uncertainties of HVs are difficult to be incorporated into the model-based control design \cite{guo2020}. Traditional first-principles-based models usually assume a fixed reaction delay for human drivers and identify model parameters from prior observations of a group of similar drivers to capture general driving behaviors \cite{pirani2022}. While these models can interpret general human driving behaviors, their accuracy is limited as they are parametric and have few parameters to capture the complex behaviors of human drivers. 

To overcome the limitations of fixed-form parametric models in car-following controls, researchers have explored learning-based or data-driven modeling methods.  Artificial Neural Networks (ANNs), such as radial basis function networks \cite{panwai2007}, multilayer neural networks \cite{khodayari2012}, and recurrent neural networks \cite{morton2016}, have been proposed to address the instantaneous reaction delay of human drivers. Other approaches, such as Gaussian Mixture Regression \cite{lefevre2014a} and Hidden Markov Model \cite{qu2017}, have been used to handle the stochastic uncertainties of human drivers. These nonparametric methods are able to provide more accurate predictions of human drivers' behaviors than parametric models. 

In the field of learning-based robotics control, a nonparametric method, Gaussian process (GP) models have been actively applied to model complex robotic systems including physical human-robot interaction \cite{haninger2022}. GP-based methods are popular in robotic applications because they require fewer parameters than other machine learning methods to capture complex behaviors \cite{wang2020}. Most importantly, a GP model can assess the uncertainties of its predictions through interpretable variances, which can be used to provide performance analysis and safety guarantees of a control system \cite{hewing2019}. The system model is commonly represented by the sum of a fixed-form nominal model (parametric) and a GP component to learn the discrepancies between the nominal model and the true system  behaviors \cite{wang2023a}. Because the human driver’s behaviors have both deterministic and stochastic components \cite{chen2010}, rather than utilizing either a fixed-form parametric model or a nonparametric modeling method, we model the HVs as a combination of a traditional fixed-form model and a GP learning-based model. 

The paper is organized as follows. Sec. \ref{sec:math} explains the mathematical preliminaries. Sec. \ref{sec:HV_modeling} proposes the new modeling method for HVs. Sec. \ref{sec:controller} develops an MPC policy utilizing the proposed HV model and presents simulation comparisons between the developed MPC and a baseline MPC strategy. Sec. \ref{sec:conclusion} provides concluding remarks. 

% \section{PROBLEM STATEMENT}
% \label{sec:problem}

% This paper studies the longitudinal car-following control of a platoon of AVs followed by a human-driven vehicle. We want to achieve safe control of the mixed vehicle platoon by considering the HV modeling as a constraint in the control policy design for the AVs. 

% In a vehicle platoon system, the control objective for each autonomous vehicle is to track the reference velocity determined by the leader vehicle. Besides the velocity tracking, each autonomous vehicle needs to keep a safe distance from the front vehicle at all time steps. This is also known as cooperative adaptive cruise control \cite{milanes2013}. In a mixed vehicle platoon composed of AVs and HVs, it is critically important to model the behaviors of HVs in the controller design to guarantee safe control of the whole mixed platoon system. 

% We first estimate the behaviors of HVs by the sum of a first principles-based nominal model and a GP learning-based model. The GP models are used to correct discrepancies between the nominal model prediction and the actual behaviors of HVs and provide variance assessment of the modeling. An MPC strategy for a longitudinal car-following of a mixed vehicle platoon subject to acceleration, speed, and safe distance constraints is developed using the estimated HV model as a constraint. The uncertainties of the human-driven vehicle estimated by GP models are explicitly applied in the MPC design to guarantee safety in emergency braking scenarios.

\section{PRELIMINARIES}
\label{sec:math}

\subsection{First-principles model of human-driven vehicles}
The delay in reaction time is a significant human factor that impacts the performance of operators \cite{antunes2011}. To account for the characteristics of human central nervous latencies, neuromuscular system, and other human and environmental factors, a transfer function with time delay has been formulated in \cite{macadam2003} to model the human response as
%
\begin{equation} 
    G_{H}(s) \approx K \frac{1+T_{z} s}{1+2 \gamma T_{w} s+T_{w}^{2} s^{2}} e^{-T_{d} s}=\frac{\dot{P}_{H}(s)}{\dot{P}_{N}(s)}  \, , \tag{1} \label{eqn:TF_func}
\end{equation}
%
where $\dot{P}_{H}(s)$ and $\dot{P}_{N}(s)$ represent Laplace transform of velocity of the HV $v_{k}^{H}$ and velocity of the AV in front $v_{k}^{N_a}$, respectively. The $T_{d}$ denotes the time delay of human drivers' response. The parameters in $G_{H}$ can be identified by the collected data. 
% By applying a Padé approximation (second order) of the time delay component in the transfer function \eqref{eqn:TF_func}, a discrete form of the transfer function $G(z)$ is derived as
% %
% \begin{equation}
%     G(z)= \frac{V_{k}^{H}(z)}{V_{k}^{N_a}(z)} = \frac{b_{1} z^{3}+b_{2} z^{2}+ b_{3} z +b_{4}}{z^{4}+c_{1} z^{3}+c_{2} z^{2}+c_{3} z+c_{4}}  \, . \tag{2} \label{eqn:TF_func_d}
% \end{equation}
% %

% A difference equation of the Auto-Regressive with Exogenous input (ARX) model can be derived from the discretized transfer function \eqref{eqn:TF_func_d} as
By applying a Padé approximation (second order) of the time delay component in the transfer function \eqref{eqn:TF_func}, a difference equation of the Auto-Regressive with Exogenous input (ARX) model can be derived from the discretized transfer function as \cite{wang2023b}
%
\begin{ceqn} 
    \begin{align}
        v^{H}_{k} &= -c_1 v^{H}_{k-1} - c_2 v^{H}_{k-2} - c_3 v^{H}_{k-3} - c_4 v^{H}_{k-4} \nonumber \\
        & \, \quad + b_1 v^{N_a}_{k-1} + b_2 v^{N_a}_{k-2} + b_3 v^{N_a}_{k-3} + b_4 v^{N_a}_{k-4} \, , \nonumber \\
        & = {f}\left(v_{k-1:k-4}^{H}, {v}_{k-1:k-4}^{N_a} \right) \, . \tag{2} \label{eqn:arx}
    \end{align}
\end{ceqn}
%
Here, $v^{H}_{k-i}$ and ${v}^{N_a}_{k-i}$ represent the velocity of the HV and the velocity of the last vehicle in the AV platoon at time step $k-i$, respectively. 

\subsection{Gaussian process regression}
\label{section:gpr}

Consider $m$ input data points $\mathbf{a} = [\mathbf{a}_1, \cdots, \mathbf{a}_m]^\mathsf{T} \in \mathbb{R}^{n_a \times m}$ and the corresponding measurements $\mathbf{d} = [\mathbf{d}_1, \cdots, \mathbf{d}_m]^\mathsf{T} \in \mathbb{R}^{n_d \times m}$, related through an unknown function $ \mathbf{d}_k = \mathbf{g}(\mathbf{a}_k) + \boldsymbol{\omega}_k $: $\mathbb{R}^{n_a} \rightarrow \mathbb{R}^{n_d}$, where $\boldsymbol{\omega}_k$ is i.i.d. Gaussian noise with $\boldsymbol{\omega}_k \sim \mathcal{N} (0, \boldsymbol{\Sigma^\omega})$ and $\boldsymbol{\Sigma^\omega} = \operatorname{diag}([\sigma_1^2, \cdots, \sigma_{n_d}^2])$. The function $\mathbf{g}(\cdot)$ can be identified by the observed input-output dataset 
%
\begin{ceqn}
    \begin{align}
       \mathcal{D}_m = \{\mathbf{a} &= [\mathbf{a}_1, \cdots, \mathbf{a}_m]^\mathsf{T},  \mathbf{d} &= [\mathbf{d}_1, \cdots, \mathbf{d}_m]^\mathsf{T} \} \, . \tag{3} \label{eqn:gp_dataset}
    \end{align}
\end{ceqn}
%
Assume each output dimension of $\mathbf{d}_k$ is independent of each other given the input $\mathbf{a}_k$. For each dimension $M \in \{ 1, \cdots, n_d\}$ of the function output $\mathbf{d}_k$, specifying a GP with zero mean and prior kernel $k^M(\cdot, \cdot)$, the measurement data $[\mathbf{d}_k]_{M, \: \cdot}$ is normally distributed as $[\mathbf{d}_k]_{M, \: \cdot} \sim \mathcal{N} \left(0, K_{\mathbf{a}\mathbf{a}}^M + \sigma_M^2 \right)$, where $K_{\mathbf{a}\mathbf{a}}^M$ is the Gram matrix of the data points using the kernel function $k^M(\cdot, \cdot)$ on the input locations $\mathbf{a}$, i.e. $[K_{\mathbf{a}\mathbf{a}}^M]_{ij} = k^M(\mathbf{a}_i, \mathbf{a}_j)$. The choice of kernel functions $k^M(\cdot, \cdot)$ is specified by prior knowledge of the observed data. In the output dimension $M$, the joint distribution of the observed output $[\mathbf{d}]_{M, \: \cdot}$ and the prediction output $[\mathbf{d}]_M$ at new data points $a$ is $P \left([\mathbf{d}]_{M, \: \cdot}, [\mathbf{d}]_M \, \vert \, \mathbf{a}, a \right)$:
%
\begin{ceqn}
    \begin{equation}
        \begin{bmatrix} [\mathbf{d}]_{M, \: \cdot} \\ [\mathbf{d}]_M \end{bmatrix} \sim 
         \mathcal{N} \left( 0 , \begin{bmatrix} K_{\mathbf{a}\mathbf{a}}^M + I \sigma_ M^2 & K_{\mathbf{a}{a}}^M \\ K_{{a}\mathbf{a}}^M  &  K_{{a}{a}}^M \end{bmatrix} \right) \, , \tag{4} \label{eqn:joint_gp} 
    \end{equation}
\end{ceqn}
%
where $[K_{\mathbf{a}{a}}^M]_j = k^M(a_j, a)$, $K_{{a}\mathbf{a}}^M = (K_{\mathbf{a}{a}}^M)^\mathsf{T}$, and $K_{{a}{a}}^M = k^M(a,a)$. The posterior distribution of $[\mathbf{d}]_M$ conditioned on the observed data can be derived from \eqref{eqn:joint_gp} as $P\left([\mathbf{d}]_M \, \vert \, [\mathbf{d}]_{M, \: \cdot}, \mathbf{a}, a \right) = \mathcal{N} \left(\mu^M(a), \Sigma^M(a) \right)$ by following equations in \cite{rasmussen2006} 
%
\begin{ceqn}
    \begin{align} 
       \mu^M(a) &= K_{{a}\mathbf{a}}^M \left(K_{\mathbf{a}\mathbf{a}}^M + I\sigma_M^2 \right)^{-1} [\mathbf{d}]_{M, \: \cdot} \, , \tag{5a} \label{eqn:gp_mean}   \\ 
       \Sigma^M(a) &= K_{{a}{a}}^M -  K_{{a}\mathbf{a}}^M \left(K_{\mathbf{a}\mathbf{a}}^M + I\sigma_M^2 \right)^{-1} K_{\mathbf{a}{a}}^M \, . \tag{5b} \label{eqn:gp_var}
    \end{align}
\end{ceqn}
%
The resulting GP model estimation $\mathbf{d}(\cdot)$ of the unknown function $\mathbf{g}(\cdot)$ is obtained by vertically concatenating the individual output dimension $M \in \{ 1, \cdots, n_d\}$ as
%
\begin{ceqn} 
    \begin{equation} 
        \mathbf{d}(a) \sim \mathcal{N} \left(\boldsymbol {\mu}^{\mathbf{d}}(a), \boldsymbol{\Sigma}^{\mathbf{d}}(a) \right) \, ,  \tag{6} \label{eqn:gp_eqn}
    \end{equation}
\end{ceqn}
%
with $\boldsymbol {\mu}^{\mathbf{d}}(a) = [\mu^1(a), \cdots, \mu^{n_d} (a)]^\mathsf{T} \in \mathbb{R}^{n_d}$ and $\boldsymbol{\Sigma}^{\mathbf{d}}(a) = \operatorname{diag}\left([\Sigma^1(a), \cdots, \Sigma^{n_d}(a)]^\mathsf{T} \right) \in \mathbb{R}^{n_d \times n_d}$.

\subsection{Sparse GP}
\label{section:sparse_gpr}

Equations \eqref{eqn:gp_mean} and \eqref{eqn:gp_var} require training data to construct the predictive distribution for each new data point prediction. The computational complexity of the mean and variance is $\mathcal{O}(n_d n_a m)$ and $\mathcal{O}(n_d n_a m^2)$, respectively, and increases with the number of training data points $m$ \cite{hewing2019}. As a result, the standard or vanilla GP models \eqref{eqn:gp_eqn} are not suitable for applications with large datasets, such as model-based control of complex robotic systems in this study.

To reduce the computational complexity of standard GP models while maintaining reasonable approximation accuracy, several sparse spectrum approximation methods have been proposed. These methods use a subset of the dataset to approximate the kernel matrix. Specifically, given the dataset $\mathcal{D}_m$ of \eqref{eqn:gp_dataset}, the task is to select a subset $\mathbf{a}^\text{ind}=[\mathbf{a}_1^\text{ind}, \cdots, a^\text{ind}_{\tilde{m}}]^\mathsf{T} \subset \mathbf{a}$ and $\mathbf{d}^\text{ind}=[\mathbf{d}^\text{ind}_1, \cdots, \mathbf{d}^\text{ind}_{\tilde{m}}]^\mathsf{T} \subset \mathbf{d}$ to compute the Gaussian processes on the subset. These ``pseudo inputs'' $\{\mathbf{a}_\text{ind}, \mathbf{d}_\text{ind}\}$ are referred to as inducing variables and $\tilde{m}$ represents the number of inducing variables. The main concept is to compress the information contained in the training data into inducing variables, which allows us to store only the inducing variables rather than the complete dataset. One state-of-the-art method, the fully independent conditional (FIC) approximation \cite{snelson2005}, automatically determines the locations of these subset inputs $\mathbf{a}_\text{ind}$ by optimizing gradient ascent of the GP marginal likelihood, which is convenient and has been successfully used to achieve efficient modeling of HVs in the current work.  

\section{LEARNING-BASED MODELING OF HUMAN-DRIVEN VEHICLES}
\label{sec:HV_modeling}

% \subsection{Modeling of the interactive environment }
% \label{sec:env_modeling}
% Consider a nonlinear system $\mathbf{x}_{k+1}= \mathbf{f}_\text{true}(\mathbf{x}_k, \mathbf{u}_k)$ with observable states $\mathbf{x}_k \in \mathbb{R}^{n}$ and control input $\mathbf{u}_k \in \mathbb{R}^{m}$. In existing research on learning-based modeling for control, the controlled agent is represented by the sum of a nominal model and a learning-based model as 
% %
% \begin{ceqn}
%     \begin{equation} \label{eqn:system_gen}        \mathbf{x}_{k+1}=\overbrace{\mathbf{f}\left(\mathbf{x}_{k}, \mathbf{u}_{k}\right)}^{\text {nominal model }}+\overbrace{\mathbf{g}(\mathbf{x}_{k}, \mathbf{u}_{k})} ^{\text {learning-based model}} \, .
%     \end{equation}
% \end{ceqn}
% %
% The model $\mathbf{f}(\cdot)$  is a nominal process model representing our knowledge of $\mathbf{f}_\text{true}(\cdot)$, and $\mathbf{g}(\cdot)$ is a model representing discrepancies between the nominal model and the true system model. In this setting, the Markov property is normally assumed that the state at the next sampling time only depends on the state and control input at the current time. These methods are able to improve the modeling accuracy of robot, and thus the overall system. 

% However, in most case of robotic applications, a major part of the system uncertainty is linked to the environment rather than the robot itself \cite{anand2021}. Moreover, an approximate prior model of the robot representing by the nominal model in \eqref{eqn:system_gen}, is usually available. Under this assumption, consider a scenario where the robot interacts with the surrounding environment continuously, the reactive environment is a nonlinear uncertain system that is challenging to model by first principles equations. We propose to model the interactive environment by the sum of a nominal model and a learning-based model as
% %
% \begin{ceqn}
%     \begin{align}
%         \mathbf{z}_{k+1} &= \overbrace{\mathbf{h} \left(\mathbf{z}_{k}, \mathbf{x}_{k}\right)}^{\text{nominal model}} \, , \tag{1a} \label{eqn:env_a} \\   \mathbf{y}_{k+1}&=\mathbf{C} \, \mathbf{z}_{k+1} + \overbrace{\mathbf{g}(\mathbf{z}_{k}, \mathbf{x}_{k})}^{\text{learning-based model}} \, . \tag{1b} \label{eqn:env_b}
%     \end{align}
% \end{ceqn}
% %
% Here, $\mathbf{h}(\cdot)$ represents a nominal model of the reactive environment with observable states $\mathbf{z}_k \in \mathbb{R}^{n}$ of the environment. $\mathbf{g}(\cdot)$ represents a learning-based model to estimate the discrepancies between the nominal model and the true environment behaviors, $\mathbf{C}$ is a constant matrix and $\mathbf{y}_{k+1} \in \mathbb{R}^{n}$ represents the corrected prediction of the environment model. Be noted that there is no control input in the model of the environment, and the learning-based model $\mathbf{g}(\cdot)$ corrects the predictions of the nominal model \eqref{eqn:env_a} in a separate equation \eqref{eqn:env_b} rather than directly adding to the state propagation nominal equation shown in \eqref{eqn:system_gen}. Thus, the assumption that process models are Markov processes can be relaxed. 


\subsection{The proposed modeling method for HVs}
% In \eqref{eqn:arx}, the human-driven vehicle is modeled as an ARX model, the common assumption of the Markov property in learning-based control is not held for the system state $v^{H}_{k}$. % The proposed modeling approach of the general interactive environment in Sec. \ref{sec:env_modeling} is applicable to the modeling of the human-driven vehicle in physical human-robot (HV-AV) interactions. 
% Due to GP models can provide uncertainty estimations of their predictions, which can be used as constraints to provide safety guarantees for safety-critical systems control, we use GP models to \emph{correct} the predictions by the nominal ARX model \eqref{eqn:arx} in our proposed human-driven vehicle model. The human-driven vehicle is modeled by ARX+GP model as

Although HVs can be modeled as an ARX model in \eqref{eqn:arx} with limited accuracy by assuming a fixed reaction delay \cite{pirani2022}, incorporating GP models can improve prediction accuracy and provide uncertainty estimations that can be used as constraints for safety guarantees in control. Therefore, we propose modeling HVs in an ARX+GP format as
%
\begin{subequations}
\label{eq:arx_gp_model}
\begin{align}
    v^H_k &= \sum_{i=1}^4 c_i v^H_{k-i} + \sum_{i=1}^4 b_i v^{N_a}_{k-i}  = {f}(\cdot) \quad \text{ (see \ref{eqn:arx})} \, , \tag{7a} \label{eqn:HV_nominal}\\
    \tilde{v}^{H}_{k}&=\overbrace{v^H_k}^{\text {ARX prediction}}+\overbrace{{g}(v^{H}_{k-1}, v^{N_a}_{k-1})} ^{\text {GP-based correction}} \, . \tag{7b} \label{eqn:HV_corrected_modeling}
\end{align}
\end{subequations}
%
Here, $\tilde{v}^{H}_{k}$ denotes the GP-compensated velocity prediction of the HV. The model ${f}(\cdot)$ is the ARX nominal model with constant parameters $b_i$ and $c_i$, and ${g}(\cdot)$ represents a GP model used to learn the discrepancies between the nominal ARX model and the actual system model (as observed through system behavior data). The GP model ${g}(\cdot)$ is a function of both the velocity of the HV ($v^{H}$) and the velocity of the AV in front of the HV ($v^{N_a}$). 

\subsection{GP model training}
With \eqref{eqn:HV_corrected_modeling}, by using data points from previously collected measurements of velocity states $v^{H}_{j}$ and $v^{N_a}_{j}$, the system discrepancies are estimated by a GP model ${d}(\cdot)$ as
%
\begin{equation}
    {d}_{j-1} = \tilde{v}^{H}_{j} -{v}^{H}_{j} = {g}({a}_{j-1}) \, ,  \tag{8} \label{eqn:gp_data_prep}
\end{equation}
%
where the discrepancy state is defined as ${a}_{j-1}=(v^{H}_{j-1}, v^{N_a}_{j-1})$. The $\tilde{v}^{H}_{j}$ and $v^H_k$ represent measured velocities in the previously collected data and predictive velocities derived by the nominal ARX model \eqref{eqn:HV_nominal}, respectively.

In each experiment, the collected one-dimensional input-output data at all time steps are prepared by \eqref{eqn:gp_data_prep} as a discrepancy data set $\mathcal{D}_m = \{\mathbf{a} = [{a}_1, \cdots, {a}_{j-1}, \cdots, {a}_m]^\mathsf{T}, \mathbf{g} = [{g}_1, \cdots, {g}_{j-1}, \cdots, {g}_m]^\mathsf{T} \}$, with $m$ being the total time steps in an experiment. The training/estimation of GP models is the process of optimizing the hyperparameters of the kernel functions, which are determined by maximizing the log marginal likelihood of collected disturbance observation data using a gradient ascent algorithm \cite{rasmussen2006}. In this work, we used the squared exponential kernel like many other GP learning-based robotic control applications \cite{hewing2019}, 
%
\begin{ceqn}
    \begin{equation} 
        K^M(\mathbf{a}, a) = \sigma_{f, M}^2 \exp \bigg(-\frac{1}{2}
        \left(\mathbf{a} - a \right)^\mathsf{T} L_M^{-1}
        (\mathbf{a} - a) \bigg) \, , \tag{9} \label{eqn:rbf}
    \end{equation}
\end{ceqn}
%
where $\mathbf{a}$ and $a$ represent the observed points and new data points where predictions are made respectively, $\sigma_{f, M}^2$ and $L_M \in \mathbb{R}^{n_a \times n_a}$ are hyperparameters that are optimized by the log marginal likelihood function. The GP models with the optimized hyperparameters are the trained models using the observed dataset \cite{wang2020}. 

% \section{HUMAN-DRIVEN VEHICLE MODEL}
\subsection{Human-driven vehicle model}
\label{sec:HV_model}
To estimate the HV model, we collected data from three distinct driving scenarios in which three drivers followed a platoon of AVs within a Unity simulation environment, as shown in Fig. \ref{figure:car_simulator}. During each experiment, the drivers were intentionally distracted by performing a cognitive task involving multiple-choice algebra questions while following the platoon of AVs. We focused on investigating human behavior modeling in distracted driving scenarios because such situations present a significant challenge for ensuring safe control in AV-HV interactions, mainly due to the increased uncertainty in the HV model. The detailed steps of the data collection experiments can be found in \cite[Sec.\ V.B]{pirani2022}. The collected data were processed to calculate the mean values of all data points, and the calculated mean values were then used to identify the transfer function of \eqref{eqn:TF_func}. 
% %
% \begin{equation} 
%     G_{h}(s) =\frac{1+6.96 s}{1+2(0.65)(4.76) s+(4.76)^{2} s^{2}} e^{-0.512 s} \, . \tag{11} \label{eqn:TF_func_id}
% \end{equation}
% %
By following \eqref{eqn:arx}, the parameters of the ARX nominal model \eqref{eqn:arx} were calculated as $c_1 = -3.0227$, $c_2 = 3.3543$, $c_3 = -1.6329$, $c_4 = 0.3014$, $b_1 = 0.0063$, $b_2 = -0.0303$, $b_3 = 0.0495$, and $b_4 = -0.0254$. 
% The nominal model \eqref{eqn:arx} provides an approximately 80\% fit of the behaviors of human drivers indicated in \cite{pirani2022}. 
%
\begin{figure}
    \centering
    \vspace{0.3cm}
    \includegraphics[trim=0cm 0cm 0cm 0cm, width=0.96\columnwidth]{figures/car_simulator.jpg}
    \caption{Data collection in a Unity driving simulator by three distracted drivers in three different driving scenarios. In each experiment, the human driver was instructed to follow a platoon of two AVs. The collected data was used for HV model identification. 
    }
    \label{figure:car_simulator}
\end{figure}
%

We used \eqref{eqn:gp_data_prep} to prepare data for estimating the discrepancy between the identified ARX model in \eqref{eqn:arx} and the actual HV behavior data. We trained a GP model using 20\% of the data points evenly selected from six data sets, while three data sets were reserved for testing. There are two main reasons to use a partial amount of data for training the GP model. Firstly, the computational cost of using the ARX+GP model in the human-in-loop platooning control is high. More importantly, the currently collected data is not diverse, with the majority of data points occurring at velocities of 10 m$/$s, 15 m$/$s, and 20 m$/$s. As a result, we found that using a larger number of data points did not obviously improve the performance of the GP models due to the limited diversity of the data.

After the GP model was trained, we performed tests using the remaining three data sets. We plotted the velocity prediction results of the ARX model and the ARX+GP model, along with two times the standard deviation (2$\sigma$) estimated by the GP model in Figure \ref{figure:gp_standard}. The actual measured velocities of the HV were also included in the plot to demonstrate the accuracy improvement achieved with the GP model.
%
\begin{figure}
    \centering
    \vspace{0.2cm}
    % \subfloat[]{{\includegraphics[trim=0cm 0cm 0cm 0cm, width=\columnwidth]{figures/G1_logdata1_RZ.pdf} }}
    \subfloat{{\includegraphics[trim=0cm 0cm 0cm 0cm, width=0.96\columnwidth]{figures/G1_logdata1_RZ.pdf} }}
    \qquad \qquad 
    \subfloat{{\includegraphics[trim=0cm 0cm 0cm 0.0cm, width=0.96\columnwidth]{figures/G1_logdata2_YN.pdf} }}
    \qquad \qquad 
    \subfloat{{\includegraphics[trim=0.0cm 0cm 0.0cm 0.0cm, width=0.96\columnwidth]{figures/G1_logdata3_YN.pdf} }}
    \caption{Performance results of the trained GP model evaluated on the three testing datasets. To compare the velocity prediction results of the ARX model and the ARX+GP model, they are plotted together with the actual measured velocities of the HV, as well as two times the standard deviation (2$\sigma$) estimated by the GP model. The plots clearly indicate that the ARX+GP model provides a significant improvement in fitting the actual velocity curves compared to the ARX model alone. Compared to the nominal ARX model, the ARX+GP model improves the modeling accuracy by an average of 35.64\% in terms of root mean square error.}
    \label{figure:gp_standard}
\end{figure}
%
To quantify the accuracy improvement, the root mean square error (RMSE) was calculated for each testing data set using
%
\begin{ceqn}
    \begin{align}
        \text{RMSE}_{{v}^{H}_*}=\sqrt{\sum_{i=1}^n \frac{\left({v}^{H}_*-{v}^{H}_\text{act}\right)^2}{n}} \, , \tag{10} \label{eqn:rmse}
    \end{align}
\end{ceqn}
%
where ${v}^{H}_*$ represents the velocity predictions of either the ARX model or GP+ARX model over $n$ samples in a testing data set, and ${v}^{H}_\text{act}$ denotes the actually measured velocities. The RMSE calculates the mean value of the model prediction errors on each testing data set, thus lower RMSE values indicate that the model provides more accurate modeling of the HVs. We calculated the average values of the RMSE of the ARX model and GP+ARX model with three testing data set, the average RMSE of the ARX model is 1.88, and the average RMSE of the ARX+GP model is 1.21. The ARX+GP model gains an  approximate 35.64\% overall modeling accuracy improvement compared to the ARX model. In Fig. \ref{figure:gp_standard}, the improved modeling accuracy can also be directly viewed as the ARX+GP model fits the curves of the actual velocity data much better than the ARX model. This is especially true for the time steps during 200$-$600, 800$-$1200, and 1400$-$1800 when the velocities are around 10 m$/$s or 15 m$/$s, which have similar velocity profiles as the training data points.


\subsection{Sparse GP+ARX model}
\label{sec:sparse_hv}
We have utilized the FIC sparse approximation technique for the GP model in order to speed up the prediction process, as described in Section \ref{section:sparse_gpr}. The hyperparameters of the sparse GP model were obtained from the trained full GP models as explained in Section \ref{sec:HV_model}, and 20 inducing points were automatically selected by the FIC method within the training data sets. To evaluate the performance of the sparse GP model, we tested it on three testing data sets. The average prediction time was reduced to 0.00021s, which is approximately 18 times faster than the standard full GP model that took 0.0037s to complete each prediction.

We have included a plot of one of the three testing results of the sparse GP+ARX model (on the bottom testing data set shown in Fig. \ref{figure:gp_standard}) in Fig. \ref{figure:gp_sparse}. In this plot, we have plotted the velocity predictions of the ARX model, the ARX+GP model, and the sparse GP+ARX model together. We observed that the sparse GP+ARX model was also able to fit the actual velocity data curves much better than the ARX model. Moreover, by utilizing \eqref{eqn:rmse}, we calculated the average RMSE of the sparse GP+ARX model to be 1.43, indicating an approximate 23.94\% overall modeling accuracy improvement when compared to the ARX model. These results indicate that the sparse GP+ARX model provides a good balance between modeling accuracy and significant computational efficiency improvement.
%
\begin{figure}
    \centering
    \vspace{0.2cm}
    \includegraphics[trim=0cm 0cm 0cm 0cm, width=0.98\columnwidth]{figures/G1_logdata3_YN_medium_vs_sparse.pdf}
    \caption{Performance results of the sparse GP model evaluated on one of three testing datasets. To compare the velocity prediction results of the sparse GP+ARX model, ARX+GP model, and ARX model, they are plotted together with the actual measured velocities of the HV. The sparse ARX+GP model still fits significantly better to the actual velocity curves compared to the ARX model with an average of 23.94\% accuracy improvement.
    }
    \label{figure:gp_sparse}
\end{figure}
%

\section{CONTROLLER DESIGN}
\label{sec:controller}
To further show the effectiveness of the proposed modeling approach for HVs, we designed a model predictive control strategy utilizing the proposed HV model to demonstrate its effectiveness in improving performance and safety in a mixed vehicle platoon control scenario.

\subsection{System model}
Consider a mixed platoon of AVs and one HV, denoted by $A^{n_a}$ and $H$ respectively, with $n_a = \{1, 2, \cdots, N_a\}$ and $N_a$ represents the number of AVs shown in Fig. \ref{figure:1}. 
% The communication topology in the platoon of AVs is bidirectional, also known as the predecessor following. In this work, we assume that the leading vehicle $A^1$ plans the optimal maneuvers for AVs in the platoon. 
The position and velocity of $A^{n_a}$ at the current time step $k$ are denoted by $p^{n_a}_k$ and $v^{n_a}_k$, respectively. We consider the following kinematic model for the AVs as
%
\begin{ceqn}
    \begin{align}  
    v_{k+1}^{n_a} &= v_{k}^{n_a} + T \, \mathrm{a}_{k}^{n_a} \, , \tag{11a} \label{eqn:av_eqn_a} \\
    p_{k+1}^{n_a} &= p_{k}^{n_a} + T \, v_{k}^{n_a} \, . \tag{11b} \label{eqn:av_eqn_b}
    \end{align}
\end{ceqn}
Here $0<T \ll 1$ is the sample time, and $\mathrm{a}_{k}^{n_a}$ represents the acceleration of $A^{n_a}$. We assume autonomous vehicles are deterministic and can measure (and communicate) their states without any error, i.e., $\Sigma(v_{k}^{n_a}) = 0$. %due to the fact that they have much smaller uncertainties compared to the HV system, thus $\Sigma(v_{k}^{n_a}) = 0$. 

By applying \eqref{eqn:HV_corrected_modeling}, the human-driven vehicle model is 
%
\begin{ceqn} 
    \begin{align} 
        \tilde{v}_{k}^{H} &= v_{k}^{H} + {d}(v_{k-1}^{H}, {v}_{k-1}^{N_a}) \, , \tag{12a} \label{eqn:sys_model_a} \\
        p_{k+1}^{H} &= p_{k}^{H} + T \, \tilde{v}_{k}^{H} \, , \tag{12b} \label{eqn:sys_model_b}
    \end{align}
\end{ceqn}
%
Here, $\tilde{v}_{k}^{H}$ represents the GP compensated HV velocity, the $v_{k}^{H}$ (computed via \eqref{eqn:arx}) and $p_{k}^{H}$ are the velocity and position states at the current time step $k$ respectively, thus the variance $\Sigma(v_{k}^{H}) = 0$ and $\Sigma(p_{k}^{H}) = 0$. Applying \eqref{eqn:gp_eqn}, the propagation equation for the mean of position is derived as
%
\begin{ceqn} 
    \begin{align} 
        \mu_{k+1}^{p^{H}} &= \mu_{k}^{p^{H}} + T \, v_{k}^{H} + T \, \mu^d (v_{k-1}^{H}, {v}_{k-1}^{N_a}) \, , \tag{13} \label{eqn:mean_prop}
    \end{align}
\end{ceqn}
%
with the initial value $\mu_{0}^{p^{H}} = p_{k}^{H}$. The propagation equation for the variance of position is
%
\begin{ceqn} 
    \begin{align} 
        \Sigma \left(p_{k+1}^{H} \right) &= \Sigma \left( p_{k}^{H} + T \, v_{k}^{H} + T \, {d}(v_{k-1}^{H}, {v}_{k-1}^{N_a}) \right) \, , \tag{14a} \label{eqn:variance_prop_a} \\
        & = \Sigma_{k}^{p^{H}} + T^2 \Sigma^d_{k-1} \ , \tag{14b} \label{eqn:variance_prop_b}
    \end{align}
\end{ceqn}
with the initial value $\Sigma \left(p_{0}^{H} \right) = 0$. The equation \eqref{eqn:variance_prop_b} neglects the covariance between $p_{k}^{H}$ and $v_{k}^{H}$.  

\subsection{Safe distance chance constraint}
To guarantee a safe distance between vehicles in the mixed platoon, a constraint of distance between AVs is designed with a constant value $\Delta$ as $p_{k}^{n_a-1}-p_{k}^{n_a} > \Delta$. Due to the stochastic feature of the HV model, a chance constraint of the distance between the last AV and the HV is designed to be satisfied as 
%
\begin{equation} 
    \mathrm{Pr}\left(p_{k}^{N_a}-(p_{k}^{H} + \Delta) > \Delta_\text{ext} \right) \geq p_{\text{def}} \, , \tag{15} \label{eqn:chance_constraint} 
\end{equation}
%
where $\Delta$ is the defined safe distance between AVs, and $\Delta_\text{ext} \geq 0$ represents an additional distance to compensate for the stochastic nature of the HVs. The satisfaction probability is denoted by $p_{\text{def}}$. We can reformulate the distance constraint $\mathcal{X}$ following a single half-space constraint $\mathcal{X}^{hs} := \bigl\{x \vert h^{\top}x \leq b \bigl\}$, $ h \in \mathbb{R}^n$, $b \in \mathbb{R}$. In \cite{hewing2019}, a method of tightened constraint on the state mean is derived as 
%
\begin{equation} 
    \mathcal{X}^{h s}\left(\Sigma_{i}^{x}\right):=\left\{x \mid h^{\top} x \leq b-\phi^{-1}\left(p_{\text{def}}\right) \sqrt{h^{\top} \Sigma_{i}^{x} h}\right\} \, , \tag{16} \label{eqn:18} 
\end{equation}
%
where $h^{\top} = \begin{bmatrix} -1 & 1\end{bmatrix}$, $x := \begin{bmatrix} p_{k}^{N_a} & p_{k}^{H}+\Delta \end{bmatrix}^{\top}$, and $b = -\Delta_\text{ext}$. The $\phi^{-1}$ represents the inverse of the cumulative distribution function (CDF). In our case, 
%
\begin{equation} 
    \Sigma_{k}^{x} := \begin{bmatrix} \Sigma_{k}^{p^{N_a}} \\ \Sigma_{k}^{p^{H}}+\Delta \end{bmatrix} = \begin{bmatrix} 0 & 0 \\ 0 & \Sigma_{k}^{p^{H}}\end{bmatrix} \, . \tag{17} \label{eqn:19} 
\end{equation}
%
Here, there is no covariance between the position states of the last AV and the HV and $\Sigma_{k}^{p^{N_a}} = 0$. The position variance of the human-driven vehicle $\Sigma_{k}^{p^{H}}$ is calculated using \eqref{eqn:variance_prop_b}. To obtain a ``tightened'' position constraint, \eqref{eqn:18} is substituted with \eqref{eqn:19} to obtain
%
\begin{equation} 
    p_{k}^{N_a}-p_{k}^{H} \geq \Delta + \Delta_\text{ext} + \phi^{-1}\left(p_{\text{def}}\right) \sqrt{ \Sigma_{k}^{p^{H}}} \, . \tag{18} \label{eqn:safe_dis_hv} 
\end{equation}
%

The chance constraint of safe distance defined in \eqref{eqn:chance_constraint} is approximated as a deterministic equation given by \eqref{eqn:safe_dis_hv}. The extra component $\Delta_\text{ext}$ can be set to $0$ if a high satisfaction probability value is used for further approximation. The safe distance constraint between the HV and AVs is adaptively modified based on the uncertainty estimates of the HV by the GP model. The modified safe distance constraint is ensured to be greater than $\Delta$ at all times. 

\subsection{GP learning-based model predictive control}
\label{sec:GP-MPC}
A GP learning-based MPC (GP-MPC) strategy for the longitudinal car-following control of a mixed vehicle platoon comprising $N_a$ number of AVs and one HV shown in Fig. \ref{figure:1} is developed as 
% %
% \begin{ceqn}
%     \begin{align} 
%        \underset{\mathbb{V}}{\text{min}} \sum_{n^{a}=1}^{N_a} & \sum_{i=k}^{k+N-1} \Big\| a_{{i}|k}^{n_a} \Big\|^2_R + \sum_{i=k}^{k+N} \Big\| v _{{i+1}|k}^1 - v_{{i+1}|k}^\text{ref} \Big\|^2_{Q_1} \nonumber \\
%        & \qquad \quad + \sum_{n^{a}=2}^{N_a}\sum_{i=k}^{k+N} \Big\| v_{{i+1}|k}^{n_a} - v_{{i+1}|k}^{n_a-1} \Big\|^2_{Q_2} \tag{19a} \label{eqn:mpc_a} \\
%        \text{with} \ \mathbb{V} = & \left\{v_{{i}|k}^1, v_{{i}|k}^{n_a}, v_{{i}|k}^{H}, p_{{i}|k}^{n_a}, \mu_{{i}|k}^{p^{H}}, \Sigma_{{i}|k}^{p^{H}}, a_{{i}|k}^{n_a} \right\} \, \nonumber \\
%         \text {subject to} \nonumber \\
%         v_{{i+1}|k}^{n_a} &= v_{{i}|k}^{n_a} + T \, \mathrm{a}_{{i}|k}^{n_a} , \  p_{{i+1}|k}^{n_a} = p_{{i}|k}^{n_a} + T \, v_{{i}|k}^{n_a} \, ,\tag{19b} \label{eqn:mpc_b} \\ 
%         v^{H}_{{i}|k} &= {f}\left(v_{i-1:i-4 | k}^{H}, {v}_{i-1:i-4 | k}^{N_a} \right) \, , \tag{19c} \label{eqn:mpc_c}\\
%         \mu_{{i+1}|k}^{p^{H}} &= \mu_{{i}|k}^{p^{H}} + T \, v_{{i}|k}^{H} + T \, \mu^d (v_{{i-1}|{k}}^{H}, {v}_{{i-1}|{k}}^{N_a}) \, , \tag{19d} \label{eqn:mpc_d}\\
%         \Sigma_{{i+1}|k}^{p^{H}} &= \Sigma_{{i}|k}^{p^{H}} + T^2 \Sigma^d (v_{{i-1}|{k}}^{H}, {v}_{{i-1}|{k}}^{N_a}) \, , \tag{19e} \label{eqn:mpc_e}\\
%         p_{{i}|k}^{n_a-1} & - p_{{i}|k}^{n_a} \geq \Delta \, , \tag{19f} \label{eqn:mpc_f}\\
%         p_{{i}|k}^{N_a} & - \mu_{{i}|k}^{p^{H}} \geq \Delta + \phi^{-1}\left(p_{\text{def}}\right) \sqrt{ \Sigma_{{i}|k}^{p^{H}}} \, , \tag{19g} \label{eqn:mpc_g}\\
%         v_{\text{min}} & \leq v_{{i}|k}^{n_a} \leq v_{\text{max}} \, , \ a_{\text{min}} \leq a_{{i}|k}^{n_a} \leq a_{\text{max}} \, , \tag{19h} \label{eqn:mpc_h}\\
%         v_{{0}|{k}}^1 & = v_{{k}|{k}}^1 \, , \ v_{{0}|{k}}^{n_a} = v_{{k}|{k}}^{n_a} \, , \ v_{{0}|{k}}^{H} = v_{{k}|{k}}^{H} \, , \tag{19i} \label{eqn:mpc_i}\\
%         v_{{-1}|{k}}^{n_a} &= v_{{k-1}|{k}}^{n_a} \, , \ v_{{-2}|{k}}^{n_a} = v_{{k-2}|{k}}^{n_a} \, , \nonumber \\ 
%         v_{{-3}|{k}}^{n_a} &= v_{{k-3}|{k}}^{n_a} \, , \ v_{{-4}|{k}}^{n_a} = v_{{k-4}|{k}}^{n_a} \, , \tag{19j} \label{eqn:mpc_j}\\ 
%         v_{{-1}|{k}}^{H} &= v_{{k-1}|{k}}^{H} \, , \ v_{{-2}|{k}}^{H} = v_{{k-2}|{k}}^{H} \, , \nonumber \\ 
%         v_{{-3}|{k}}^{H} &= v_{{k-3}|{k}}^{H} \, , \ v_{{-4}|{k}}^{H} = v_{{k-4}|{k}}^{H} \, , \tag{19k} \label{eqn:mpc_k}\\
%         \mu_{{0}|{k}}^{p^{H}} &= p_{{k}|{k}}^{H} \, , \ \Sigma_{{0}|{k}}^{p^{H}} = 0 \ . \tag{19l} \label{eqn:mpc_l}
%     \end{align}
% \end{ceqn}
% %
%
\begin{ceqn}
    \begin{align} 
       \underset{\mathbb{V}}{\text{min}} \sum_{n^{a}=1}^{N_a} & \sum_{i=k}^{k+N-1} \Big\| a_{{i}|k}^{n_a} \Big\|^2_R + \sum_{i=k}^{k+N} \Big\| v _{{i+1}|k}^1 - v_{{i+1}|k}^\text{ref} \Big\|^2_{Q_1} \nonumber \\
       & \qquad \quad + \sum_{n^{a}=2}^{N_a}\sum_{i=k}^{k+N} \Big\| v_{{i+1}|k}^{n_a} - v_{{i+1}|k}^{n_a-1} \Big\|^2_{Q_2} \tag{19a} \label{eqn:mpc_a} \\
       \text{with} \ \mathbb{V} = & \left\{v_{{i}|k}^1, v_{{i}|k}^{n_a}, v_{{i}|k}^{H}, p_{{i}|k}^{n_a}, \mu_{{i}|k}^{p^{H}}, \Sigma_{{i}|k}^{p^{H}}, a_{{i}|k}^{n_a} \right\} \, \nonumber \\
        \text {subject to} \nonumber \\
        v_{{i+1}|k}^{n_a} &= v_{{i}|k}^{n_a} + T \, \mathrm{a}_{{i}|k}^{n_a} , \  p_{{i+1}|k}^{n_a} = p_{{i}|k}^{n_a} + T \, v_{{i}|k}^{n_a} \, ,\tag{19b} \label{eqn:mpc_b} \\ 
        v^{H}_{{i}|k} &= {f}\left(v_{i-1:i-4 | k}^{H}, {v}_{i-1:i-4 | k}^{N_a} \right) \, , \tag{19c} \label{eqn:mpc_c}\\
        \mu_{{i+1}|k}^{p^{H}} &= \mu_{{i}|k}^{p^{H}} + T \, v_{{i}|k}^{H} + T \, \mu^d (v_{{i-1}|{k}}^{H}, {v}_{{i-1}|{k}}^{N_a}) \, , \tag{19d} \label{eqn:mpc_d}\\
        \Sigma_{{i+1}|k}^{p^{H}} &= \Sigma_{{i}|k}^{p^{H}} + T^2 \Sigma^d (v_{{i-1}|{k}}^{H}, {v}_{{i-1}|{k}}^{N_a}) \, , \tag{19e} \label{eqn:mpc_e}\\
        p_{{i}|k}^{n_a-1} & - p_{{i}|k}^{n_a} \geq \Delta \, , \tag{19f} \label{eqn:mpc_f}\\
        p_{{i}|k}^{N_a} & - \mu_{{i}|k}^{p^{H}} \geq \Delta + \phi^{-1}\left(p_{\text{def}}\right) \sqrt{ \Sigma_{{i}|k}^{p^{H}}} \, , \tag{19g} \label{eqn:mpc_g}\\
        v_{\text{min}} & \leq v_{{i}|k}^{n_a} \leq v_{\text{max}} \, , \ a_{\text{min}} \leq a_{{i}|k}^{n_a} \leq a_{\text{max}} \, . \tag{19h} \label{eqn:mpc_h}
    \end{align}
\end{ceqn}
%
The current time step is $k$, and the system (hardware or simulation) starts at time $k=0$. In the MPC prediction horizon, the prediction horizon time step starts at $i=1$, and variable values at $i=0$ are initialized with measurements \cite{wang2023b}.
% shown in the right sides of \eqref{eqn:mpc_i}, \eqref{eqn:mpc_j}, \eqref{eqn:mpc_k}, and \eqref{eqn:mpc_l}. 
In the cost function \eqref{eqn:mpc_a}, differences between the reference velocity and velocity of the leading AV, differences between velocities of the neighboring AVs, and control inputs are weighted by three positive weights $Q_1$, $Q_2$, and $R$ repetitively. In the equality constraint \eqref{eqn:mpc_b}$-$\eqref{eqn:mpc_e}, the \eqref{eqn:mpc_b} are the model of AVs defined in \eqref{eqn:av_eqn_a} and \eqref{eqn:av_eqn_b}, the \eqref{eqn:mpc_c} is the ARX nominal model of the HV specified in \eqref{eqn:arx}, the \eqref{eqn:mpc_d} and \eqref{eqn:mpc_e} are mean and variance propagation equations of the HV position derived in \eqref{eqn:mean_prop} and \eqref{eqn:variance_prop_b} respectively. The inequality constraints include the velocity and acceleration \eqref{eqn:mpc_h}, and safe distance \eqref{eqn:mpc_f} and \eqref{eqn:mpc_g}. 

\subsection{Dynamic sparse GP prediction in MPC}

In Section \ref{sec:sparse_hv}, it was demonstrated that the sparse GP+ARX model significantly reduces computation time (compared to the standard GP+ARX model) while still improving modeling accuracy (compared to the ARX model) for HV velocity predictions. However, integrating GP models into the MPC framework to achieve a reasonable speed or real-time calculations remains a challenge. MPC itself is computationally expensive as it requires solving an optimal control problem at each time step while satisfying constraints specified in equations \eqref{eqn:mpc_b}$-$\eqref{eqn:mpc_h}. To address this challenge, we implemented a dynamic sparse approximation for the GP-MPC method proposed in \cite{hewing2019} to achieve further speed-up. Given the receding horizon feature of MPC, 
% with a reasonably long prediction horizon and fast sampling times, 
the predictive trajectory at the current time step is similar to the trajectory calculated at the previous time step. Therefore, we applied the sparse GP to conduct calculations on the trajectory at the previous time step and used the results to propagate the mean and variance at the current time step by using \eqref{eqn:mpc_d} and \eqref{eqn:mpc_e}.

\subsection{Simulations}

This section shows the overall control performance improvement due to utilizing the proposed HV model. A simulation case study of the mixed vehicle platoon applying the sparse GP-based MPC strategy developed in Sec. \ref{sec:GP-MPC} and a baseline MPC were quantitatively compared. All simulations were implemented in MATLAB R2022a on a laptop computer running Ubuntu 20.04. The source code for our implementation is available at: \url{https://github.com/CL2-UWaterloo/GP-MPC-of-Platooning}. 

To ensure consistent starting conditions across all simulations, the initial velocities of all vehicles were set to 0. We used a sample time of T = 0.25 s and a prediction horizon of N = 6 for both the baseline MPC and the sparse GP-based MPC. The weights of the cost function for both MPC policies were tuned to $Q_1 = Q_2 = 5$ and $R = 20$.  The maximum and minimum acceleration were set to $a_{\text{max}} =$ 5 m$^2/$s and $a_{\text{min}} =$ $-$5 m$^2/$s respectively, and the maximum and minimum velocity were set to $v_{\text{max}} =$ 35 m$/$s and $v_{\text{min}} =$ $-$35 m$/$s respectively. The minimum safe distance was defined as $\Delta =$ 20 m in \eqref{eqn:mpc_f} and \eqref{eqn:mpc_g}. We initialized the leader AV at $p= 0$, the second AV was $1.2 \, \Delta =$ 24 m behind the leader AV, and the HV was located $1.2 \, \Delta =$ 24 m behind the follower AV. The satisfaction probability of the chance constraint in \eqref{eqn:chance_constraint} was set to $p_{\text{def}}=0.95$. 

We implemented a baseline MPC, referred to as the nominal MPC, to provide a basis for comparison. In the nominal MPC, the prediction loop uses the ARX model of the HV \eqref{eqn:mpc_c} and \eqref{eqn:mpc_d} without the third GP component. The distance constraint between the HV and the follower AV given is defined as $\Delta$ without the second adaptive component in \eqref{eqn:mpc_g}. Furthermore, the nominal MPC does not incorporate position variance propagation as described in equation \eqref{eqn:mpc_e}. For all simulations involving the nominal MPC and the sparse GP-based MPC, we utilized the ARX+GP model derived in equations \eqref{eqn:sys_model_a} and \eqref{eqn:sys_model_b} to simulate the HV model.

A case study of emergency braking was simulated by applying the nominal MPC and GP-MPC. Specifically, we simulated the scenario with a reference velocity of $v^\text{ref}=$ 20 m$/$s for the leading AV, which was then reduced to $v^\text{ref}=$ 10 m$/$s at $t=$ 30 s. We then plotted the velocity tracking, position of each vehicle, and relative distance between the vehicles, shown from top to bottom in Fig. \ref{figure:nominal_simulation_braking} for the nominal MPC and in Fig. \ref{figure:gp_simulation_braking} for the GP-MPC.
%
\begin{figure}
    \centering
    \vspace{0.2cm}
    \subfloat{{\includegraphics[trim=0cm 0cm 0cm 0cm, width=0.96\columnwidth]{figures/20-10_v_nominal_60s.pdf} }}
    \qquad \qquad 
    \subfloat{{\includegraphics[trim=0cm 0cm 0cm 0.0cm, width=0.96\columnwidth]{figures/20-10_Abdist_nominal_60s.pdf} }}
    \qquad \qquad 
    \vspace{0.05cm}
    \subfloat{{\includegraphics[trim=0.0cm 0cm 0.0cm 0.0cm, width=0.96\columnwidth]{figures/20-10_dist_nominal_60s.pdf} }}
    % \qquad \qquad 
    % \subfloat{{\includegraphics[trim=0.0cm 0cm 0.0cm 0.0cm, width=0.96\columnwidth]{figures/20-10_s_control_nominal_60s.pdf} }}
    \caption{Simulation results of an emergency braking scenario with a baseline MPC for the mixed vehicle platoon control. From top to bottom, the plots are the velocity tracking, the position of each vehicle, and the relative distance between vehicles respectively.}
\label{figure:nominal_simulation_braking}
\end{figure}
%
%
\begin{figure}
    \centering
    \vspace{0.2cm}
    \subfloat{{\includegraphics[trim=0cm 0cm 0cm 0cm, width=0.96\columnwidth]{figures/20-10_s_v_60s.pdf} }}
    \qquad \qquad 
    \subfloat{{\includegraphics[trim=0cm 0cm 0cm 0.0cm, width=0.96\columnwidth]{figures/20-10_s_Abdist_60s.pdf} }}
    \qquad \qquad 
    \vspace{0.05cm}
    \subfloat{{\includegraphics[trim=0cm 0cm 0cm 0.0cm, width=0.96\columnwidth]{figures/20-10_s_dist_60s.pdf} }}
    % \qquad \qquad 
    % \subfloat{{\includegraphics[trim=0.0cm 0cm 0.0cm 0.0cm, width=0.96\columnwidth]{figures/20-10_s_control_60s.pdf} }}
    \caption{Simulation results of an emergency braking scenario with the proposed GP-MPC for the mixed vehicle platoon control. The plots show the velocity tracking, position of each vehicle, and relative distance between vehicles from top to bottom, respectively. Compared to a baseline MPC shown in Fig. \ref{figure:nominal_simulation_braking}, the minimum distance between the HV and follower AV is two-meter larger, and the traveled distances of all vehicles are larger as summarized in Tab. \ref{tab:simulation_metrics}. Therefore, the GP-MPC approach offers better safety guarantees without being more conservative than the nominal MPC since all vehicles still travel a larger distance. }
    \label{figure:gp_simulation_braking}
\end{figure}
%
The top plots of the velocity tracking demonstrate the cooperative maneuvers of the leader and follower AVs. At around $t=$ 46 s, both AVs accelerated to guarantee the safe distance constraint.

We summarized the position of the leader AV (AV 1), the follower AV (AV 2), and the HV (HV) as well as the minimum distance between the HV and the follower AV (Min HV-AV) in Tab. \ref{tab:simulation_metrics} to quantitatively show the performance improvements of the proposed GP-MPC. The GP-MPC achieved a minimum HV-AV distance of 22.27 m, which is two meters larger than the nominal MPC. This improvement is due to the additional component in the safe distance constraint that considers the GP uncertainty assessments defined in \eqref{eqn:safe_dis_hv}. Extra distances were added to the distance constraint in \eqref{eqn:mpc_g} at all time steps in the GP-MPC to better guarantee safety. All the vehicle positions in the mixed platoon of the GP-MPC were ahead of the nominal MPC, this indicates the GP-MPC also realized a higher travel speed for all vehicles in the mixed-vehicle platoon. 
%
\begin{table}
    \caption{Simulation performance metrics: The position of all vehicles and the minimum relative distance of HV-AV.
    % Compared to the nominal MPC, bigger position values for the GP-MPC indicate a higher overall speed of the mixed vehicle platoon, and a larger Min HV-AV distance provides an extra safety guarantee.
    }
    \label{tab:simulation_metrics}
    \begin{center}
        \begin{tabular}{|c|c|c|c|c|}
            \hline Controller & AV 1 & AV 2 & HV & Min HV-AV  \\
            \hline Nominal MPC & 862.90 m & 842.89 m & 806.42 m & 20.05 m\\
            \hline GP-MPC & \textbf{864.92} m & \textbf{843.72} m &  \textbf{814.60} m & \textbf{22.27} m\\
            \hline
        \end{tabular}
    \end{center}
\end{table}
%

We also summarized the computation time at each time step of the GP-MPC and the nominal MPC in Table \ref{tab:simulation_time}. The average computation time (Ave Time) of the MPC at each time step for the GP-MPC is only 5\% more than the nominal MPC. The maximum time (Max Time) of the GP-MPC shows it can run in real-time at 4 HZ, and the small standard deviation (Time Std) value of the GP-MPC indicates it has a more consistent computation time than the nominal MPC. Compared to our previous work \cite{wang2023b} that did not utilize sparse GP modeling for HVs and a dynamic GP prediction in MPC, the average computation time of the GP-MPC at each time step has been reduced by approximately 100 times.
%
\begin{table}
    \vspace{0.2cm}
    \caption{Simulation computation time: The averaged time at each time step of the GP-MPC is only 5\% more than the nominal MPC. 
    % The smaller standard deviation (Time Std) value of the GP-MPC indicates a more consistent computation time than the nominal MPC. 
    }
    \label{tab:simulation_time}
    \begin{center}
        \begin{tabular}{|c|c|c|c|}
            \hline Controller & Ave Time & Max Time & Time Std \\
            \hline Nominal MPC & \textbf{0.2062} s & \textbf{0.2347} s & 0.065 \\
            \hline GP-MPC & 0.2186 s & 0.2391 s & \textbf{0.006} \\
            \hline
        \end{tabular}
    \end{center}
\end{table}
%

\section{CONCLUSIONS}
\label{sec:conclusion}

\noindent\textbf{Summary.} This paper proposes an innovative learning-based modeling approach for human-driven vehicles that combines a first-principles nominal model with a Gaussian process learning-based component. The proposed model improves the modeling accuracy and estimates the uncertainty in the HV model, thus can be used to enhance the safe control of mixed vehicle platoon. Utilizing this model, we developed a model predictive control strategy for a mixed vehicle platoon in longitudinal car-following scenarios. We evaluated the developed MPC policy by comparing it to a baseline MPC in simulation case studies. The results show that our approach achieves superior safety guarantees while also enabling more efficient motion behaviors for all vehicles in a mixed platoon. By utilizing a dynamic sparse GP technique in every MPC prediction loop, our MPC requires only 5\% more computation time than the baseline nominal MPC, which represents an approximately 100-fold reduction in computation time compared to our previous work \cite{wang2023b}.

\noindent\textbf{Limitations and future work.} Our work is limited in many ways. Firstly, it is important to note that our current work is limited to longitudinal car-following scenarios, and it would be beneficial to expand it to other traffic scenarios such as merging or lane changing. Secondly, Although the GP models were trained with data from real human drivers, the limited diversity of the data collected to model human-driven vehicles suggests that gathering more data from diverse drivers and driving scenarios could further enhance the model's accuracy. Finally, further investigation is required to establish the minimum distance constraint necessary for the proposed GP-MPC to ensure safe control. Exploring the method's boundary capabilities represents an exciting area for future research.

\section*{ACKNOWLEDGMENT}
This work was supported in part by Magna International and the Canada Natural Sciences and Engineering Research Council Discovery Grant.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \section*{APPENDIX}

% Appendixes should appear before the acknowledgment.

% \section*{ACKNOWLEDGMENT}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{IEEEtran}
\bibliography{bibliography}



\end{document}
