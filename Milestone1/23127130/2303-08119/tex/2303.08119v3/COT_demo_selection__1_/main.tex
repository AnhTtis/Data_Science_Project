% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
% \usepackage[review]{acl}
\usepackage{acl}


% Standard package includes
\usepackage{times}
\newcommand{\Rom}[1]{\uppercase\expandafter{\romannumeral #1\relax}}
\newcommand{\rom}[1]{\lowercase\expandafter{\romannumeral #1\relax}}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\graphicspath{ {./images/} }
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{booktabs} % To thicken table lines

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

\newcommand{\jiuhai}[1]{{ \color{blue}{[JC: #1]} }}
\newcommand{\ty}[1]{\textcolor{orange}{Tianyi: #1}}
\newcommand{\clc}[1]{\textcolor{red}{LC: #1}}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{How Many Demonstrations Do You Need for In-context Learning?
%It Takes One to Tango but More Make Trouble? The Number of Demonstrations Needed for In-Context Learning 
% In-Context Learning with Different Numbers of Demonstrations}
}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Jiuhai Chen [1] \And Lichang Chen \And Chen Zhu \And Tianyi Zhou \AND
%         [1] University of Maryland \And [2] Google \AND    \\}
% if the names do not fit well n one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
\author{Jiuhai Chen \\ University of Maryland \\  jchen169@umd.edu
        \And  Lichang Chen \\ University of Maryland \\  bobchen@umd.edu \And Chen Zhu \\  University of Maryland \\  chenzhu@umd.edu 
        \And
        Tianyi Zhou \\ University of Maryland \\tianyi@umd.edu }
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}


% \author{First Author \\
%   Affiliation / Address line 1 \\
%   \texttt{email@domain} \\\And
%   Second Author \\
%   Affiliation / Address line 1 \\
%   \texttt{email@domain} \\}

\begin{document}
\maketitle
\begin{abstract}
Large language models (LLMs) are capable to perform complex reasoning by in-context learning (ICL) when provided with a few input-output demonstrations (demos) and more powerful when intermediate reasoning steps (``chain of thoughts (CoT)'') of the demos are given. Is it necessary to use multi-demo in ICL? In this paper, we study ICL using fewer demos for each test query on the tasks in~\cite{wei2022chain}. Surprisingly, we do not observe significant degradation when using only one randomly chosen demo. To study this phenomenon, for each test query, we categorize demos into ``positive demos'' leading to the correct answer, and ``negative demos'' resulting in wrong answers. Our analysis reveals an inherent bias in those widely studied datasets and the redundancy of demos: most demos are positive for a majority of test queries, which explains the good performance of ICL with one random demo. Moreover, ICL (with and w/o CoT) using only one positive demo significantly outperforms multi-demo ICL adopted by most previous works, indicating the weakness of LLMs in finding positive demo(s) for input queries, which is difficult to evaluate on the biased datasets. Furthermore, we observe a counterintuitive behavior of ICL using multi-demo, i.e., its accuracy degrades(improves) when given more positive(negative) demos. This implies that ICL can be easily misguided by interference among demos and their spurious correlations. Our analyses highlight several fundamental challenges that need to be addressed in LLMs training, ICL, and benchmark design. 

\end{abstract}

\section{Introduction}


The recent race of large Language models (LLMs) \cite{brown2020language, chowdhery2022palm, thoppilan2022lamda, rae2021scaling} shows that the capability of reasoning can be significantly improved with the scaling of model size. One of the most remarkable behaviors observed in LLMs is in-context learning (ICL) \cite{brown2020language}, which provides LLMs with human-written instruction and a few exemplars or demonstrations (demos), along with the input queries. However, conventional few-shot prompting performs poorly on complex reasoning tasks~\cite{wei2022chain}. Recently, an effective ICL strategy for complex reasoning tasks, including arithmetic reasoning, commonsense reasoning, and symbolic reasoning, is to elaborate the intermediate reasoning step in each demo \cite{wei2022chain}, namely Chain-of-thoughts (CoT) prompting. 

ICL relies on human engineering and expertise in designing demo questions, intermediate reasoning steps, and final answers so the LLM can generalize them to a variety of unseen queries. However, it is inefficient and impractical to design demos for different queries but a fixed set of demos might not cover all the possible queries. In addition, adding demos (especially in CoT prompting) significantly increases input tokens, which are costly and may exceed the maximum input length of LLMs. 
% choose the questions and annotate them with intermediate reasoning steps and final answers. 
% To mitigate the manual effort, there has been 
To provide better demos for efficient ICL and save human efforts, a very recent line of work studies automatic prompting~\cite{zhang2022automatic, wang2023large, arora2022ask}, which leverage LLMs to select demo questions and construct their answers and CoTs for ICL. 
They save human labor on creating demos but do not address several fundamental questions in ICL, e.g., \textit{How many demos are necessary for ICL? Can LLMs in ICL figure out which demo(s) is more useful to each test query? Does ICL leverage all the demos or mainly rely on a few of them to resolve each test query? Can LLMs in ICL combine the strengths of multiple demos to improve the answers?}



In this paper, we take the first step toward better understanding the effect of multiple demos 
in ICL through a series of empirical studies on the demos and benchmarks widely used in CoT prompting~\cite{wei2022chain}, which covers a diverse set of reasoning tasks. 
In particular, we investigate how the ICL (with and w/o CoT) performance changes when varying the number of demos and the impact of each demo on different test queries. We start with an extreme case of ICL using only one demo randomly chosen for each query. Surprisingly, compared to the default 8 (or 7)-demo ICL in previous work, we do not observe a significant drop in the test accuracy. But does this imply that multiple demos are unnecessary to ICL? To study this phenomenon, we take a closer look at the proportion of positive demos (i.e., the demos leading to correct answers in one demo ICL) for each test query. Statistics on all the datasets reveal a widely existing bias of easy queries, i.e., most demos are positive for a majority of queries, for which one (random) demo is all they need. 

That being said, how does ICL perform on the test queries with fewer positive demos? Unfortunately, though provided with some positive demos, ICL fails to produce correct answers for many of them. We verify this by evaluating ICL with one positive demo, which significantly outperforms the widely used multi-demo ICL. This exposes a weakness of LLMs, i.e., they are not good at identifying the positive demo(s) and ignoring the negative ones for each query in multi-demo ICL, even when more details such as CoT are given. Our further analysis reveals another deeper reason for this. Specifically, we start from ICL with one positive (negative) demo but adding more positive (negative) demos results in a counterintuitive degradation (improvement) of ICL accuracy, indicating a negative impact of the interference or spurious correlation among demos on the LLMs. Therefore, multiple demos might provide more information than a single demo but the current LLMs and ICL methods cannot fully exploit them and filter out misleading interference. 




\section{Related Work}


\paragraph{In-Context Learning (ICL).}
In-context learning (ICL) provides an efficient strategy to perform downstream task adaptations on pretrained LLMs~\cite{brown2020language}. By prepending task-specific instructions and some demos to each test query, the LLM is able to accomplish highly specified tasks. Recent work in ICL focuses on automatically determining the prompts, e.g., training a dense retriever to allocate semantically similar training examples~\cite{liu2021makes} for each test query~\cite{rubin2021learning}, estimating the LLM's bias for better learning calibration parameters \cite{zhao2021calibrate}, etc.

% has been key to superior performance in LLMs~\cite{brown2020language} over a variety of downstream tasks. Prior works primarily focus on how to formulate the prompts, e.g., retrieving 
% semantically similar to a test sample to formulate its corresponding prompt \cite{liu2021makes}, estimating the LLM's bias and then fitting calibration parameters \cite{zhao2021calibrate}, training an efficient dense retriever of prompts from training examples~\cite{rubin2021learning}.

\paragraph{Chain-of-Thoughts (CoT) and its variants.} CoT has been recently introduced to elicit the reasoning abilities of LLMs \cite{wei2022chain} by augmenting each demo with a chain of rational steps. Many follow-ups works further improve the performance of CoT, e.g., self-consistency~\cite{wang2022self} draws an ensemble of outputs for majority voting to replace the greedy decoding. However, CoT still heavily relies on human expertise to annotate the reasoning chains. A handful of recent works have explored the idea of automatic prompting~\cite{zhang2022automatic, huang2022large,wang2023large}. For instance, Auto-CoT \cite{zhang2022automatic} proposes to select queries of the demos via clustering all test queries and sampling demo queries with diversity. \cite{huang2022large} fine-tunes an LLM with high-confidence rationale-augmented answers for unlabeled questions. \citet{wang2023large} views the LLM as a topic model and proposes an algorithm selecting the optimal demo from a set of annotated data. While beneficial, most automatic prompting methods focus on bypassing human engineering and building better demos from a set of questions. But they do not investigate whether demos are used in the correct way by LLMs in ICL. In contrast, we find that the original demos provided by \cite{wei2022chain} include adequate information (e.g., one positive demo per query) for the LLMs to produce correct answers. 
 


\paragraph{The role of demos in ICL.} Several works have                       explored the mechanism behind the success of CoT prompting. \citet{min2022rethinking} observes that label correctness is not the critical reason for the success of few-shot ICL/prompting. \citet{madaan2022text} also finds that the label correctness is immaterial to the task on GSM8K. Instead, \citet{madaan2022text} constructs three key components in rational and identifies which component plays a vital role in CoT. \citet{saparov2022language} concludes that LLMs are capable of making correct individual deduction steps but have difficulty systematically exploring the different options. \citet{wang2022towards} shows that CoT  reasoning is possible even with invalid demos. These works try to understand what makes CoT prompting effective. However, few works focus on varying the number of demos and inherent dataset bias in few-shot ICL or CoT prompting. 


\section{Background and Experimental Setup}

\subsection{Tasks and Datasets}
We conduct a series of experiments on a variety of reasoning benchmarks: 
\textbf{arithmetic reasoning:} GSM8K \cite{cobbe2021training}, MultiArith \cite{roy2016solving}, AddSub \cite{hosseini2014learning}, SVAMP \cite{patel2021nlp}, AQuA \cite{ling2017program} and SingleOp \cite{wei2022chain}. 
\textbf{commonsense reasoning:} CSQA \cite{talmor2018commonsenseqa}.
\textbf{symbolic reasoning:} Coin-flip \cite{wei2022chain}. 

The overall statistics are listed in table \ref{tab:data}.

\begin{table}[ht]
\centering
\scalebox{0.85}{
\begin{tabular}{llll}
% - & \multicolumn{5}{c}{\textbf{arithmetic reasoning}} & \textbf{commonsense reasoning} & \textbf{symbolic reasoning} \\\
\hline
\hline
 & TASK & \# Demo & \# Query  \\
 \hline
GSM8K & Arithmetic & 8 & 1319   \\
MultiArith   & Arithmetic & 8 & 600   \\
AddSub & Arithmetic & 8 &  395  \\
SVAMP  & Arithmetic & 8 & 1000  \\
AQuA & Arithmetic & 4 & 254 \\
SingleOp  & Arithmetic & 8 & 508  \\
CSQA  & Commonsense & 7 & 1221  \\
% Last Letter & Symbolic & 4 & 500  \\
Coin-flip  & Symbolic & 8 & 500  \\
\hline
\hline
\end{tabular}}
\caption{\label{tab:data}
Statistics of datasets. \# Demo is the number of CoT exemplars provided by \citet{wei2022chain}. }
\end{table}

\subsection{Language Model and In-Context Learning}
To efficiently conduct an extensive number of experiments, we focus on code-davinci-002 \cite{chen2021evaluating, chowdhery2022palm} from the GPT-3 model family to evaluate performance. We choose code-davinci-002 because it is a programming generation engine with superior performance, especially for reasoning tasks \cite{wang2022self, zhang2022automatic}. We explore two prompting settings for in-context learning: 

\paragraph{Few-shot prompting.} Standard few-shot prompting~\cite{brown2020language} in which demos are formatted as \emph{Question + Answer} pairs appended to each test query. 
\paragraph{CoT prompting.} We also conduct experiments on CoT prompting where each demo is augmented by a chain of thoughts \cite{wei2022chain} in the form of \emph{Question + rationale + Answer}. 






% \begin{table*}[ht]
% \centering
% \begin{tabular}{lllllll}
% % - & \multicolumn{5}{c}{\textbf{arithmetic reasoning}} & \textbf{commonsense reasoning} & \textbf{symbolic reasoning} \\\
% \hline
%  & GSM8K & MultiArith & AddSub & SVAMP & AQuA & SingleEq  \\
%  \hline
% Standard (full demo) & 19.7 & 44.0 & 90.9 & 69.9 & 29.5 & 86.8  \\
% Standard (one demo)  & 17.9 & 41.5 & 83.8 & 68.5 & 28.3 & 83.1  \\
% \hline
% CoT (full demo) & 60.1 & 96.2 & 89.4 & 75.8 & 39.8 & 93.1  \\
% CoT (one demo)  & 53.2 & 93.7 & 83.3 & 68.2 & 37.2 & 88.8  \\
% \hline
% CoT + self-consistency (full demo) & 78.0 & 100.0 & 91.6 & 86.8 & 52.0 & 92.8  \\
% CoT + self-consistency (one demo)  & 73.1 & 100.0 & 91.1 & 84.6 & 46.4 & 94.9  \\
% \hline
% \end{tabular}
% \caption{\label{tab:arithmetic}
% Accuracy comparison on arithmetic reasoning task with full prompts and randomly selecting one prompt. }
% \end{table*}


% \begin{table*}[t]
% \centering
% \begin{tabular}{lllll}
% % - & \multicolumn{5}{c}{\textbf{arithmetic reasoning}} & \textbf{commonsense reasoning} & \textbf{symbolic reasoning} \\\
% \hline
%  & StrategyQA & CSQA & Letter & Coinflip \\
%  \hline
%  Standard (full demo) & 67.1  & 82.3 & -  & -\\
% Standard (one demo)  & - & 78.1 & - & 55.0 \\
% \hline
% CoT (full demo) & 73.4  & 79.0 & 70.4  & 99.0\\
% CoT (one demo)  & - & 70.3 & 71.4 & 91.6 \\
% \hline
% Self-consistency (full demo) & 79.8 & 81.5 & 73.4 & 99.5\\
% Self-consistency (one demo)  & - & 81.2 & 75.4 & 97.8 \\
% \hline
% \end{tabular}
% \caption{\label{tab:csqa}
% Accuracy comparison on commonsense reasoning and symbolic reasoning task with full prompts and randomly selecting one prompt.
% }
% \end{table*}

\section{One-Demo Prompting}

It is common to use multiple demos in ICL, e.g., manual-CoT~\citep{wei2022chain} relies on humans to create a few demos for different tasks as shown in Table~\ref{tab:data}. 
% (e.g., 8 prompted exemplars for arithmetic tasks). 
But do multiple demos really improve ICL performance? How many demos are needed for complex reasoning tasks? To answer these questions, we start by investigating the simplest case, i.e., one-demo ICL. Surprisingly, reducing the number of demos to one does not bring critical degradation even when the demo is randomly selected. When we can filter out negative demos (defined in Section~\ref{sec:easyhardquery}) for each test query, one demo ICL significantly outperforms the widely used multi-demo ICL. We provide an in-depth analysis of the reasons behind these phenomena and they reveal some fundamental issues of LLMs and benchmarks.    


% Manual-CoT relies on humans to create a few demos for different tasks shown in Table \ref{tab:data} (e.g., 8 prompted exemplars for arithmetic tasks). However, 8 human-annotated demos are not necessarily the most effective for each test sample. In this section, we explore the minimal requisite demos to facilitate the LLMs to generate the expected answers. In particular, we observe that the number of demos plays a key role in model performance, and including more demos may  hamper the performance. 

\subsection{Prompting with One Random Demo}

We compare ICL with one random demo with ICL with all demos when each demo is associated with/without CoT.

\paragraph{One Random Demo} is randomly selected from a few demos crafted by \citep{wei2022chain}. We prepend this single demo to the test sample and query the language model once. 
% For all arithmetic reasoning tasks, we randomly choose one demo from 8 manually written exemplars in \citep{wei2022chain}; for CSQA, one exemplar is randomly selected from 7 hand-crafted demos provided by \citep{wei2022chain}; for Last Letter Concatenation, we randomly select one prompt from 4 manually written exemplars in \citep{wei2022chain}. \ty{Consider moving this paragraph to background} 
%  We also consider self-consistency for further boosting the performance under randomly selecting one demo.

\paragraph{All Demos} is the baseline reported by \cite{wei2022chain}, prepending all demos (e.g., 8 demos for arithmetic reasoning tasks) to the test sample and query the model once.

% \textbf{Self-Consistency} is also considered to further boost the performance of CoT prompting \cite{wang2022self}. Under self-consistency setting, we prompt the language model with randomly selecting one demo and query the model once with temperature $T=0.7$. We repeat the procedure 40 times following \citep{wang2022self} and take the majority vote for the final answer. 

Results for few-shot (without CoT) and CoT prompting on a variety of datasets are reported in Figure~\ref{fig:bar_wo_cot} and Figure~\ref{fig:bar_cot}, respectively. For both ICL methods, reducing seven or eight demos (green bar) to one random demo (blue bar) causes only slight degradation (0-7\%) on the test accuracy, while significantly reducing the input length and computational cost. These savings are attractive since most API LLMs are billed based on the number of input tokens (e.g., \$ 0.02 per 1000 tokens for GPT-3). On most evaluated tasks, \textbf{one random demo suffices to achieve the most phenomenal improvement by ICL but using more than one demo only brings marginal improvement.} 
% From the perspective of ICL, the demos are training examples but increasing them test performance. 
\textbf{It indicates an inefficient usage of demos in ICL}, despite their presumed high quality and diversity (as they are carefully created by humans).  

% This conclusion is of great practical value since it is able to significantly save cost when calling the API model, e.g., GPT3 is billed based on the number of tokens sent in the prompt (\$ 0.02 per 1000 tokens). Less number of input tokens straightly translates to reduced billing cost, run-time, and carbon footprint. We only keep one demo for each test sample, drastically shorting the length of input prompts token (e.g., for arithmetic reasoning task, eight times less than the standard CoT \cite{wei2022chain}) and leading to comparable performance. 
% Meanwhile, Self-Consistency effectively narrows the gap between randomly choosing one demo and employing full demos. In particular, for MultiArith, Addsub, SVAMP, SingleOp and Coinflip, reducing the  number of demos has little to no impact on the reasoning performance. Notably, for SingleOp and Letter, one randomly selected demo outperforms full demo under self-consistency setting. 

\begin{figure}[ht]
\includegraphics[width=8cm]{fig0b.pdf}
\centering
\caption{\label{fig:bar_wo_cot}
 ICL without CoT: Prompting with one random demo has a slightly lower accuracy than few-shot prompting (8 or 7 demos). Prompting with one positive demo significantly outperforms few-shot prompting. \looseness-1}
\end{figure}


\begin{figure}[ht]
\includegraphics[width=8cm]{fig0a.pdf}
\centering
\caption{\label{fig:bar_cot}
ICL with CoT: Prompting with one random demo has a slightly lower accuracy than CoT prompting (8 or 7 demos). Prompting with one positive demo significantly outperforms CoT prompting. 
}
\end{figure}


But \textit{what are the reasons behind this inefficient usage of multiple demos? Is it due to a weakness of current LLMs or ICL on exploiting demos or an inherent redundancy of the handcrafted demos for these benchmark tasks?} Given the above observations, it is plausible that different demos might provide redundant information to each test query so any randomly chosen one should do the same job. \textit{But does this hold for all test queries? Does there exist the best demo for each query? When the LLMs are API models, their weights cannot be further finetuned, is it still possible to improve their ICL performance through the demos?}


\subsection{Positive/Negative Demos and Hard/Easy Samples in Datasets}\label{sec:easyhardquery}

For an in-depth study of these questions, we categorize all the demos into positive/negative demos for each input query in the one-demo prompting setting, i.e., ``\textbf{positive Demos}'' enabling the LLMs to produce a correct answer while ``\textbf{negative Demos}'' results in wrong answers. One example of "negative/positive Demo" under CoT prompting is shown in Figure \ref{fig:positive/negative demo}. We then study the proportions of positive demos for test queries in each benchmark dataset, which reflect the probability of randomly sampling a positive demo that can be used to explain previous observations.  
 
 \begin{figure*}[ht!]
 \centering
\includegraphics[width=0.9\textwidth]{fig5.pdf}
\caption{\label{fig:positive/negative demo}
Negative/Positive Demo. In one demo ICL for a test query, a negative demo leads to an incorrect answer while a positive demo results in the correct answer.
% The illustration of Wrong/Correct Demo. For the same test query, Wrong Demo leads to incorrect answer while Correct Demo results in right answer.
}
\end{figure*}

% For each test-time sample, we partition all demos into "\textbf{Correct Demos}" and \textbf{"Wrong Demos"} in such single-demo prompting. 
A demo can be positive for a query but negative for another query. For example, Figure \ref{fig:easy/hard demo} shows that the eight demos designed for GSM8K are all positive for an easy query but all negative and lead to incorrect answers for another hard query. Hence, it is interesting to study the proportion of easy and hard queries in the widely used benchmark datasets. Given that we have eight demos in total, it is reasonable to define the \textbf{Easy Sample} to be the queries with $\geq 6$ demos to be positive and \textbf{Hard Sample} to be the queries with merely $\leq 1$ positive demo. Therefore, the probability of choosing a positive demo for easy samples in the one random demo prompting is $\geq 75\%$ (at least 6 positive demos from 8 demos) while the probability for hard samples is $\leq 12.5\%$ (at most 1 positive demos from 8 demos). To explain the high accuracy of prompting with one random demo, a natural problem to study is: \textit{what is the percentage of easy/hard samples in each dataset?}


We report the statistics of easy and hard samples according to the number of positive demos for each sample in two commonly used ICL datasets, CSQA and GSM8K, where the former is for arithmetic reasoning and the latter is for commonsense reasoning. 
% We choose two representative datasets in arithmetic reasoning and commonsense reasoning tasks: CSQA and GSM8K. 
In particular, Figure \ref{fig:stat_gsm8k} (a) and Figure \ref{fig:stat_csqa} (a) give statistics of all test queries in terms of the number of positive demos in GSM8K and CSQA. On both datasets, we observe that easy samples are the majority while hard samples take up a very small fraction. Notably, as shown in Figure \ref{fig:stat_csqa} (a), $\sim58\%$ of test queries in CSQA dataset are easy (having $\geq 6$ positive demos out of $8$ so the success probability of one random demo prompting for these samples is $\geq 75\%$.  

In contrast, only 8 \% of CSQA dataset are hard samples, for which randomly selecting a demo out of the eight results in $\leq 12.5\%$ ICL accuracy. 
% indicating that any single demo fails to result in the expected answer. 
Hence, easy samples dominate CSQA, for which the $8$ or $7$ demos are highly redundant. Moreover, we observe similar statistics on other datasets such as GSM8K and almost all the datasets used in CoT prompting papers (see Table \ref{tab:easy/hard ration} in the appendix). 
This explains the marginal improvement of multi-demo ICL over ICL with only one random demo (shown in Figure \ref{fig:bar_wo_cot} and Figure \ref{fig:bar_cot}): most queries in these datasets are easy samples that only require one random demo to produce the correct answers so increasing the demos does not bring significant improvement. 
% Furthermore, it reveals that the percentage of easy and hard sample plays vital roles in the performance of original GSM8K and CSQA datasets. Note that for both GSM8K and CSQA, there is a moderate amount of test data (around 50\%) where any single demo is adequate to drive the LLMs to superior performance. It can act as an explanation to Figure \ref{fig:bar_wo_cot} and Figure \ref{fig:bar_cot} that the performance of randomly selecting a single demo closely matches for using all demos.

Given the statistics of positive demos per sample in a dataset, we can estimate the accuracy of prompting with one random demo by the expected probability of a randomly chosen demo being positive for queries from each dataset. 
% Another interesting perspective, deduced from Figure \ref{fig:stat_gsm8k} (a) and Figure \ref{fig:stat_csqa} (a), we can calculate the expected accuracy by randomly selecting one demo. 
Specifically, let $N$ be the number of available demos ($N=8$ for GSM8K and $N=7$ for CSQA) and $p_n$ be the percentage of samples with $n$ positive demos, then the estimated accuracy of one random demo ICL is $\sum_{n=1}^{N} p_n \frac{n}{N}$. 
For instance, given the statistics in Figure \ref{fig:stat_gsm8k} (a) and Figure \ref{fig:stat_csqa} (a), the estimated accuracy is $52 \%$  for GSM8K and $71 \%$ for CSQA, which matches the empirical accuracy for one random demo ICL reported in Figure \ref{fig:bar_cot}. 

This reveals a widely existing dataset bias, i.e., \textbf{easy samples dominate these benchmark datasets} and the difficulty follows a long tail distribution. Though this could be claimed as an advantage of the human-designed demos, it implies redundancy and inefficient usage of these demos: one positive demo suffices to produce the correct answers for most queries (as they are easy), while multi-demo ICL multiplies the cost but only brings marginal improvement to a few queries. 
Since the maximum input length for LLMs is strictly limited, this also indicates a bottleneck of multi-demo ICL when the targeted tasks become practically more complicated and requires more diverse demos for different types of queries. 

The inefficient usage of multiple demos also exposes a weakness of LLMs when applied for ICL, i.e., they can only produce correct answers (with high probability) for easy samples when most demos are positive but can be easily confused/misguided by a few negative demos, even the majority are still positive demos. This also explains the marginal difference between all-demo ICL and one random demo ICL on different data groups as shown in Figure \ref{fig:acc_gsm8k}-\ref{fig:acc_csqa}, in which ICL with one positive demo instead can achieve $100\%$ accuracy for data groups with $\geq 1$ positive demos. In other words, \textbf{LLMs cannot precisely distinguish positive and negative demos for a query.} Unfortunately, this weakness of LLMs cannot be reflected by evaluations on most existing ICL benchmarks because of the aforementioned dataset bias. 







\subsection{Prompting with One positive Demo}

Multi-demo ICL is inefficient in the usage of input tokens and can easily be misguided by a few negative demos. On the other hand, by definition, a positive demo results in a correct answer, and most samples in those datasets have at least one positive demo, according to the statistics such as Figure \ref{fig:stat_gsm8k} (a) and Figure \ref{fig:stat_csqa} (a). 

Hence, it is intuitive to compare the widely used multi-demo ICL with ICL including only one single positive demo in the prompt\footnote{We randomly choose one demo for samples without any positive demo.}. Surprisingly, as shown in Figure \ref{fig:bar_wo_cot} and \ref{fig:bar_cot}, \textbf{one positive demo ICL significantly outperforms the multi-demo ICL}, even the latter spends $8\times$ (or $7\times$) cost of the former and includes the demo used in the former. For example, there are $83\%$ samples in GSM8K with $\geq 1$ positive demos so the one positive demo ICL enjoys an accuracy of $\sim 83\%$, which is much better than the $\sim 60\%$ accuracy of ICL using all the eight demos. 
We consistently observe similar performance gaps on all evaluated datasets, in both ICL without CoT (few-shot prompting) and ICL with CoT prompting. Therefore, these comparisons suggest that \textbf{selecting one positive demo can be both more efficient and more effective than using multiple demos in ICL.} 


Moreover, considering that the positive demo for each query is already included in the multiple demos, the poorer performance of multi-demo indicates misguidance from negative demos or harmful interference between multiple demos. As shown in Figure \ref{fig:acc_gsm8k}-\ref{fig:acc_csqa}, ICL with one random demo, despite ignoring useful information in the rest demos, also removes the misguidance and interference and thus achieves similar or even better accuracy than all-demo ICL. In contrast, all-demo ICL, even with most ($>6$) demos are positive, is prone to cross-demo interference and misguidance, leading to poorer accuracy than one random demo ICL. \textit{But which is the essential reason for this gap? Can we improve the ICL performance by introducing more positive-only demos? Is it possible for LLMs to stitch the relevant/correct pieces of negative demos to build a correct answer?}  






% \begin{table*}[h]
% \centering
% \begin{tabular}{lllllll}
% % - & \multicolumn{5}{c}{\textbf{arithmetic reasoning}} & \textbf{commonsense reasoning} & \textbf{symbolic reasoning} \\\
% \hline
%  & GSM8K & MultiArith & AddSub & SVAMP & AQuA & SingleOp  \\
% \hline
% Random-CoT   & 53.2 & 93.7 & 83.3 & 68.2 & 37.2 & 88.8  \\
% Retrieval-CoT  & - & - & - & - & - & -  \\
% \hline
% Random-CoT + self-consistency  & 53.2 & 93.7 & 83.3 & 68.2 & 37.2 & 88.8  \\
% Retrieval-CoT + self-consistency & - & - & - & - & - & -  \\
% \hline
% \end{tabular}
% \caption{\label{tab:retrieve}
% Accuracy comparison on arithmetic reasoning task with retrieval-based and randomly selecting one prompt. }
% \end{table*}





% \begin{table*}[t]
% \centering
% \begin{tabular}{llllllll}
% % - & \multicolumn{5}{c}{\textbf{arithmetic reasoning}} & \textbf{commonsense reasoning} & \textbf{symbolic reasoning} \\\
% \hline
%  & GSM8K & MultiArith & AddSub & SVAMP & AQUA-RAT & CSQA & Letter \\
% \hline
% CoT (full demo) & 60.1 & 96.2 & 89.4 & 75.8 & 39.8 & 79.0 & 70.4 \\
% Self-consistency (full demo) & 78.0 & 100.0 & 91.6 & 86.8 & 52.0 & 81.5 & 73.4 \\
% \hline
% Oracle (one demo)  & 83.0  & 100.0 & 94.7 & 90.5 & 68.5 & 91.6 & 78.2 \\
% % Oracle (one demo) + s.c  & 86.7  & 100.0 & 95.2 & 94.0 & 66.5 & 92.4 & 84.6 \\
% \hline
% \end{tabular}
% \caption{\label{oracle}
% Accuracy comparison on different datasets of full prompts and randomly selecting one prompt.
% }
% \end{table*}


\section{Adding More Demos to Prompt: Does it improve or confuse ICL?\looseness-1}

In the previous section, we mainly focus on the performance of one demo ICL and the reasons behind it. A counterintuitive observation is that ICL with multiple demos performs even worse than ICL with only one positive demo. \textit{Why does multi-demo ICL perform worse and when can it bring additional improvement?}
To address these questions, we study the following two problems.
\begin{itemize}
    \item \textbf{Problem I}: Starting from a prompt of one positive demo, will the accuracy be further boosted if adding more positive demos?
    \item \textbf{Problem II}: Starting from a prompt of one negative demo, what will happen if adding more negative demos?
\end{itemize}
These two scenarios mainly focus on all-positive or all-negative demo cases. This is because we already observed in the previous section that a mix of negative and positive demos can misguide ICL since the evaluated LLMs are not good at distinguishing negative and positive demos. On the other hand, it is still unclear whether the LLMs exploit the correlations between multiple demos and how they affect the ICL process. For example, \textit{when all the demos are positive (negative), will the LLMs treat all demos to be independent and thus keep the answer correct (wrong), or will the answer be changed due to the cross-demo correlations?}






 \begin{figure*}[ht!]
 \centering
\includegraphics[width=0.85\textwidth]{fig4.pdf}
\caption{\label{fig:easy/hard demo}
Easy/Hard Samples from GSM8K: for the hard query (Mark plants a beanstalk ...), all the 8 demos are negative and result in wrong answers in one-demo ICL; for the easy query (Alisa biked 12 miles ...), all the 8 demos are positive and lead to the correct answer. The 8 demos for arithmetic problems are from~\cite{wei2022chain}.}
\end{figure*}


\begin{figure}[th]
\includegraphics[width=6.3cm]{fig1a.pdf}
\centering
\caption{Pie chart on the number of positive demos (ICL with CoT) per sample/query ($0\sim 6$ inside the pie chart) for queries in (a) the whole GSM8K dataset \label{fig:stat_gsm8k}; (b) GSM-Hard; (c): GSM-Easy.
}
\end{figure}

\begin{figure}[th]
\includegraphics[width=6.3cm]{fig1b.pdf}
\centering
\caption{
Pie chart on the number of positive demos (ICL with CoT) per sample/query ($0\sim 6$ inside the pie chart) for queries in (a) the whole CSQA dataset \label{fig:stat_csqa}; (b) CSQA-Hard; (c): CSQA-Easy.
% Number $0\sim 6$ around pie chart denote the number of correct demos. (a):  The overall statistics of the correct demos for each test query in CSQA\label{fig:stat_csqa}. (b) and (c): The illustration of CSQA-Hard and CSQA-Easy.
}
\end{figure}

\begin{figure}[th]
\includegraphics[width=8cm]{fig7a.pdf}
\centering
\vspace{-1.em}
\caption{
Accuracy of ICL using all eight demos and one random demo (with CoT) on fine-grained data groups different in the number of positive demos (Figure \ref{fig:stat_gsm8k} (a)) for GSM8K dataset. The size of each dot is proportional to the data percentage. All-demo ICL brings improvement only to hard samples with fewer positive demos, while one random demo performs similarly or even better than all eight demos, indicating inefficient usage of multiple demos when easy samples dominate the dataset. 
% We partition the GSM8K dataset with respect to the number of correct demos (area size denotes the proportion of each division), we show the performance of all demos ICL and one random demo ICL. We observe that all demos is required for hard samples to result in correct answer, meanwhile one random demo is adequate for easy samples to generate the correct answer. 
\label{fig:acc_gsm8k}
}
\vspace{-1.8em}
\end{figure}

\begin{figure}[th]
\includegraphics[width=8cm]{fig7b.pdf}
\centering
\vspace{-.5em}
\caption{
Accuracy of ICL using all seven demos and one random demo (with CoT) on fine-grained data groups different in the number of positive demos (Figure \ref{fig:stat_csqa} (a)) for CSQA dataset. The size of each dot is proportional to the data percentage. The observations and conclusions on CSQA are similar to those for Figure \ref{fig:acc_gsm8k}.
\label{fig:acc_csqa}
}
\vspace{-1.em}
\end{figure}

% We raise the following two questions based on the foregoing section:
% \begin{itemize}

% \item \emph{Do existing CoT benchmark datasets really reflect the true capability of LLMs? Since datasets are composed of unbalanced easy and hard samples. }

% \item \emph{Compared with one-demo ICL, do multiple demos really offer benefits to the LLMs to arrive at the correct answer?} 
% \end{itemize}

To ensure enough number of positive (negative) demos are added for each sample, we use CSQA-Easy and GSM8K-Easy as evaluation sets for Problem I and CSQA-Hard and GSM8K-Hard as evaluation sets for Problem II. As illustrated in Figure \ref{fig:stat_gsm8k} and Figure \ref{fig:stat_csqa}, the two easy sets of samples have $\geq 6$ positive demos while the two hard sets of samples have $\leq 1$ positive demo. Hence, we are able to increase the number of positive (negative) demos from $1$ to $6$ in the two studied problems, producing a full spectrum of varying accuracy over different numbers of demos. 

% To proceed with our investigation, we curate two benchmark variations: Commonsense Reasoning with easy samples (CSQA-Easy), which only comprises  test examples with 6 or over 6 correct demos (Easy sample) illustrated in Figure \ref{fig:stat_csqa} (c). Correspondingly, Commonsense Reasoning with Hard examples (CSQA-Hard) is composed of 8 \% test data with zero correct demo and 5 \% test data with one correct demo shown in \ref{fig:stat_csqa} (b). Similarly, for GSM8K dataset, we construct the GSM-Easy and GSM-Hard derived from GSM8K seen in Figure \ref{fig:stat_gsm8k} (b) and Figure \ref{fig:stat_gsm8k} (c). 

% The benefit of such a tailored design is to tease apart the hard component of datasets that truly reflect the capability of LLMs. We also disentangle the easy component of the dataset which any randomly selected demo leads to the correct answer. We aim to investigate whether multiple demos are the most effective prompts for both easy and hard samples. 

\begin{figure}[!htb]
    \begin{minipage}{.5\textwidth}\centering
        \includegraphics[width=7cm, height=0.2\textheight]{fig2a.pdf}
        \caption{\label{fig:gsm8k_cot} Increasing demos in \textbf{CoT Prompting on GSM8K}: for each query in GSM-Easy(GSM-Hard), we start from a positive(negative) demo, add more positive(negative) demos to the prompt, but observe an accuracy degradation(improvement). 
        % Starting from randomly selecting one demo to randomly selecting 6 demo, more correct demos degrade the accuracy for GSM-Easy while more wrong demos improves the accuracy for GSM-Hard.
        }
    \end{minipage}%
    \hfill
    \begin{minipage}{0.5\textwidth}\centering
        \includegraphics[width=7cm, height=0.2\textheight]{fig2b.pdf}
        \caption{\label{fig:csqa_cot} 
        Increasing demos in \textbf{CoT Prompting on CSQA}: for each query in CSQA-Easy(CSQA-Hard), we start from a positive(negative) demo, add more positive(negative) demos to the prompt, but observe an accuracy degradation(improvement).
        }
    \end{minipage}
\end{figure}

% \section{Spurious Correlations among Demos: Do multiple demos improve CoT?}
% In Figure~\ref{fig:gsm8k_cot}-\ref{fig:csqa_standard}, 
In Figure~\ref{fig:gsm8k_cot}-\ref{fig:csqa_cot} and Figure~\ref{fig:gsm8k_standard}-\ref{fig:csqa_standard} (appendix), 
we report the results for Problem I \& II when applying CoT prompting and few-shot prompting to CSQA-Easy/Hard and GSM8K-Easy/Hard. Surprisingly, on all datasets and ICL strategies, we consistently observe that \textbf{increasing positive demos in the prompt results in lower accuracy on the easy samples, while increasing the negative demos improves the accuracy on the hard samples.} This indicates that LLMs in ICL, when given multiple demos, do take the correlations among demos into account rather than simply treating them independently. However, the correlations do not always bring improvement to ICL for multiple positive demos, for example, ICL with one positive demo achieves nearly 99\% accuracy on GSM8K-Easy but adding an additional positive demo leads to significant degradation. In this case, the interference and spurious correlations among multiple demos concatenated in the prompt are harmful to ICL and tend to misguide the LLMs toward finding the correct answer. On the other hand, ICL with multiple negative demos is able to extract the relevant information for the test query from multiple demos and combine them by LLMs to achieve an improved answer. Though the improvement is not highly phenomenal, we consistently observe it in all the plots, indicating a non-trivial composition of clues from multiple demos commonly happening during ICL and resulting in better answers even for hard samples.  

% For GSM-Easy and GSM-Hard, we analyze the accuracy for problems with respect to the number of demos randomly selected from the full list of demos given by \cite{wei2022chain}. From Figure \ref{fig:gsm8k_cot}, we see a performance drop for GSM-Easy and a performance improvement for GSM-Hard with adding more demos. In particular, prepending any single demo achieves nearly 99\% accuracy for GSM-Easy, even 2-demo degrades the performance significantly. Surprisingly, composing multiple correct demos that individually generate the correct answer may hamper the model's performance. 
% LLMs are easily distracted by more information and fail to capture the most useful instructions. In contrast to GSM-Easy, stacking more Wrong demos which individually generate the wrong answer may improve the model performance. Our finding reveals that for hard samples, multiple demos enhance the reasoning capabilities of LLMs, it facilitates the LLMs to gather useful information from diverse demos. The trend is consistent over CSQA-Easy and CSQA-Hard from Figure \ref{fig:csqa_cot}: multiple demos degrade the performance of CSQA-Easy while improving the accuracy of CSQA-Hard.


% In contrast to CSQA-Easy and GSM-Easy, the accuracy improvement from adding more demos occurs for both CSQA-Hard and GSM-Hard shown in Figure (\ref{fig:hard_cot}). Consistently around 10 \% improvement is observed when adding more exemplars into instruction.  


% We conduct similar experiments on Few-shot prompting setting, Figure (\ref{fig:gsm8k_standard}) and Figure (\ref{fig:csqa_standard}) reflect the same conclusion: composing more demos that individually generate the correct answer may hamper the model performance for GSM-Easy and CSQA-Easy. Stacking more wrong demos enhances the reasoning capabilities of LLMs only for GSM-Hard and CSQA-Hard.

Hence, increasing the number of positive (negative) demos does not intuitively improve (weaken) the ICL performance and the main reason lies in the extraction and exploitation of cross-demo correlations in ICL. Since multiple demos in ICL are concatenated together and then appended to the query as the whole input, a pretrained LLM might lack the capability to completely separate all demos and choose the positive one to follow during the ICL inference process, especially when the LLM's pretraining does not cover such inputs and tasks. Therefore, our study exposes a weakness of the current LLMs in modeling cross-demo correlations, which can be one of the main reasons for the marginal improvement brought by multi-demo ICL. To mitigate this problem, one may modify the pretraining recipe with additional training tasks/objectives to encourage beneficial cross-demo attention and restrain harmful interference.  
% We conclude that existing CoT benchmarks fail to fully reflect the true capability of LLMs since Easy samples take up the majority part of datasets. Easy samples are insensitive to the demo selection. We advocate that in this scenario, demo selection including auto-prompting techniques is not necessarily the most effective and efficient way to arrive at the correct answer. Since any single demo is adequate to facilitate the LLMs to generate the expected answer. Furthermore, while sensitive to the demo selection, Hard samples account for a minority part of the dataset. Based on the foregoing observation, the success of Hard samples requires the meticulous design of prompts. Thus Hard samples potentially play a critical role in the design of prompts and exploration of the capability of LLMs. Adjusting the proportion of hard/easy examples is an interesting future work. 











\section{Discussion}
In-context learning (ICL) plays an important role in the ecosystem of LLMs. It only needs to append a few exemplars (demos) to an input query and recent LLMs are capable of directly generating customized outputs by following the demos. However, it is not clear how many demos suffice to produce high-quality answers. In this paper, for the first time, we study the performance of ICL (with or without chain-of-thoughts prompting) under different numbers of demos and provide an in-depth investigation of the observations across several widely used benchmark datasets. 

In particular, we found that randomly selecting one single demo barely hurts the performance while increasing the demos merely brings marginal improvement. We then study how many demos can lead to correct answers in the one-demo ICL for each sample and analyze its statistics over all samples in widely used benchmark datasets. The statistics reveal a widely existing dataset bias that easy samples with many positive demos dominate the datasets, which explains the high accuracy of ICL with one random demo. It also exposes a weakness of LLMs in distinguishing negative/positive demos in ICL. Moreover, we found that only one positive demo is sufficient to significantly outperform multi-demo ICL, while saving a great amount of unnecessary cost. This indicates an inefficient exploitation of multiple demos in ICL. Furthermore, we study the contribution and interference of cross-demo correlations to ICL by investigating how the accuracy changes as we add more positive (negative) demos to the prompt. Surprisingly, adding positive demos reduces the accuracy while adding negative demos brings improvement, indicating a problematic interpretation and exploitation of the cross-demo correlations by LLMs in ICL. 

% In this paper, we study the effect of changing the number of demos on in-context learning (with and w/o chain-of-thoughts). We find that a single demo barely hurts the performance: ICL performance drops only marginally when the random demo is selected, single correct demo significantly improves the performance over the default multiple-demo ICL in previous work. We then investigate a series of aspects in the existing CoT benchmarks and examine which test query actually benefits the multiple demos. Results reveal that for hard sample, multiple demos truly enhances the reasoning capabilities of LLM, while for easy sample, multiple demos drop ICL performance. Furthermore, we examine the ratio of Hard/Easy sample for existing CoT benchmarks and find that Easy sample takes up the majority part of the datasets and the Hard sample only accounts for a small fraction of datasets under CoT prompting setting. Under this scenario, one demo is adequate to result in the expected answer for most test queries. Together, our findings expose the weakness of the LLM: they are not good at distinguishing the useful demo from multiple demos and easily mislead by the wrong demo. 

Our analyses highlight several fundamental challenges that need to be addressed in the future, e.g., how to design less biased benchmarks and more diverse demos that can be used to better evaluate LLMs' capability of distinguishing positive demos from the negative ones; how to improve the efficiency and effectiveness of multi-demo usage in ICL; how to avoid the harmful interference caused by cross-demo correlations and meanwhile leverage them to improve the ICL performance on hard samples with fewer positive demos; how to select positive demos for a given query, etc.









% Entries for the entire Anthology, followed by custom entries
\bibliography{anthology, main}
\bibliographystyle{acl_natbib}

\appendix

\section{Easy/Hard Sample Ration}
\begin{table}[ht]
\centering
\begin{tabular}{lll}
% - & \multicolumn{5}{c}{\textbf{arithmetic reasoning}} & \textbf{commonsense reasoning} & \textbf{symbolic reasoning} \\\
\toprule
 & Easy Sample (\%) & Hard Sample (\%) \\
 \hline
 GSM8K & 40.0 & 28.3 \\
 MultiArith & 94.3 & 0.0 \\
 AddSub & 82.5 & 6.1 \\
 SVAMP & 62.6 & 14.3 \\
 AQuA & 28.3 & 55.1 \\
 SingleEq & 89.0 & 5.3 \\
 CSQA  & 58.0 & 13.0 \\
\bottomrule
\end{tabular}
\caption{\label{tab:easy/hard ration}
The percentage of Easy/Hard samples (ICL with CoT) in each benchmark dataset. Easy samples dominate in most datasets while hard samples only take up a small fraction.}
\end{table}


\section{More results for Few-shot Prompting}
\label{sec:appendix}

\begin{figure}[!htb]
    \begin{minipage}{.5\textwidth}\centering
        \includegraphics[width=7cm, height=0.2\textheight]{fig3a.pdf}
        \caption{\label{fig:gsm8k_standard}
        Increasing demos in \textbf{Few-shot Prompting on GSM8K}: for each query in GSM-Easy(GSM-Hard), we start from a positive(negative) demo, add more positive(negative) demos to the prompt, but observe an accuracy degradation(improvement).
        }
    \end{minipage}%
    \hfill
    \begin{minipage}{0.5\textwidth}\centering
        \includegraphics[width=7cm, height=0.2\textheight]{fig3b.pdf}
        \caption{\label{fig:csqa_standard}
        Increasing demos in \textbf{Few-shot Prompting on CSQA}: for each query in CSQA-Easy(CSQA-Hard), we start from a positive(negative) demo, add more positive(negative) demos to the prompt, but observe an accuracy degradation(improvement).
        }
    \end{minipage}
\end{figure}



% \begin{table*}[ht]
% \centering
% \begin{tabular}{llllllll}
% % - & \multicolumn{5}{c}{\textbf{arithmetic reasoning}} & \textbf{commonsense reasoning} & \textbf{symbolic reasoning} \\\
% \toprule
%  & GSM8K & MultiArith & AddSub & SVAMP & AQuA & SingleEq & CSQA  \\
%  \midrule
% Easy Sample (\%) & 40.0 & 94.3 & 82.5 & 62.6 & 28.3 & 89.0 & 58.0 \\
% Hard Sample (\%) & 28.3 & 0.0 & 6.1 & 14.3 & 55.1 & 5.3 & 13.0 \\
% \bottomrule
% \end{tabular}
% \caption{\label{tab:easy/hard ration}
% The percentage of Easy/Hard samples (ICL with CoT) in each benchmark dataset. Easy samples dominate in most datasets while hard samples only take up a small fraction.}
% \end{table*}




\end{document}
