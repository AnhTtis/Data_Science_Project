\begin{abstract}
% Image demosaicing is an important step in the image processing pipeline for digital cameras, and it is one of the many tasks within the field of image restoration. 
% A well-known characteristic of natural images is that most patches are smooth, while high-content patches like textures or repetitive patterns are much rarer, which results in a long-tailed distribution. 
% This distribution can create an inductive bias that negatively impacts performance when training machine learning algorithms for image restoration tasks and for image demosaicing in particular. There have been many different approaches to address this challenge, such as utilizing specific losses or designing special network architectures. What makes our work unique is that it tackles the problem from a training protocol perspective.
% Our proposed training approach comprises two essential phases. In the initial phase, we employ a novel method to create and sketch out sub-datasets from the entire dataset, each of which induces a distinct bias over the trained network. The subsequent phase involves an alternating training process, which uses both the derived sub-datasets from the previous phase and the entire dataset. This approach is carefully crafted to guide and prevent the model from converging into solutions that introduce bias.
% We have conducted various experiments to demonstrate the effectiveness of our training method for the image demosaicing task. Our results show that this method outperforms standard training across a range of architecture sizes and types, including CNNs and transformers. We are able to achieve state-of-the-art results on three highly popular image demosaicing benchmarks. 

% Image demosaicing is an important step in the image processing pipeline for digital cameras, and it is one of the many tasks within the field of image restoration. Natural images tend to depict a long tailed distribution, where most patches are smooth and high-content patches like are much rarer. This can lead to a bias in the performance of demosaicing algorithms. 
% Most deep learning approaches address this challenge by utilizing specific losses or designing special network architectures. We propose a novel approach S-DAT, Sub-Dataset Alternation Training, that tackles the problem from a training protocol perspective. S-DAT is comprised by two essential phases. In the initial phase, we employ a novel method to create sub-datasets from the entire dataset, each inducing a distinct bias. The subsequent phase involves an alternating training process, which uses the derived sub-datasets in addition to the entire dataset.
% S-DAT can be applied for the demosaicing task, regardless of the chosen architecture or loss as demonstrated by various experiments we conducted. The experiments are performed across a range of architecture sizes and types, including CNNs and transformers. We show improved performance on all cases. We are also able to achieve state-of-the-art results on three highly popular image demosaicing benchmarks.


Image demosaicing is an important step in the image processing pipeline for digital cameras.
In data centric approaches, such as deep learning, the distribution of the dataset used for training can impose a bias on the networks' outcome. For example, in natural images most patches are smooth and high-content patches are much rarer. This can lead to a bias in the performance of demosaicing algorithms. 
Most deep learning approaches address this challenge by utilizing specific losses or designing special network architectures. We propose a novel approach \textbf{SDAT}, Sub-Dataset Alternation Training, that tackles the problem from a training protocol perspective. SDAT is comprised of two essential phases. In the initial phase, we employ a method to create sub-datasets from the entire dataset, each inducing a distinct bias. The subsequent phase involves an alternating training process, which uses the derived sub-datasets in addition to training also on the entire dataset.
SDAT can be applied regardless of the chosen architecture as demonstrated by various experiments we conducted for the demosaicing task. The experiments are performed across a range of architecture sizes and types, namely CNNs and transformers. We show improved performance on all cases. We are also able to achieve state-of-the-art results on three highly popular image demosaicing benchmarks. 


%This not only demonstrates the efficiency of our training regime but also its potential to be applied to other image restoration tasks.

\end{abstract} 