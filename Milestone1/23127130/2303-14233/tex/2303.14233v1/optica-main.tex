\documentclass{optica-article}

%% Select the journal you're submitting to
%% oe, boe, ome, optcon, opticajournal
\journal{oe}
% Key:
% Express journals must have the correct journal selected:
% {oe} Optics Express
% {boe} Biomedical Optics Express
% {ome} Optical Material Express
% {optcon} Optics Continuum
% Other Optica journals may use:
% {opticajournal} Applied Optics, Advances in Optics and Photonics, Journal of the Optical Society of America A/B, Optics Letters, Optica, Photonics Research

% Uncomment if submitting to Photonics Research.
% ONLY APPLICABLE FOR \journal{opticajournal}
% \setprjcopyright

% Set the article type
\articletype{Research Article}
% Note that article type is not required for Express journals (OE, BOE, OME and OPTCON)

\usepackage{lineno}
% \usepackage{amssymb}
\usepackage{amsmath}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}
% \usepackage[dvipsnames]{xcolor}
\usepackage[normalem]{ulem}
\usepackage{float}
\usepackage{tabularx}
\usepackage{lscape}
\usepackage{float}
% \usepackage[autostyle, english = american]{csquotes}
% \MakeOuterQuote{"}
\linenumbers

\begin{document}

\title{A Computer Vision Based Optical Method for Measuring Fluid Level in Cell Culture Plates}
% \title{Universal manuscript template for Optica Publishing Group journals}

\author{Pierre V. Baudin\authormark{1,2,*} Mircea Teodorescu\authormark{1,2}}

\address{\authormark{1}Department of Electrical and Computer Engineering,   University of California Santa Cruz \\ Santa Cruz, CA 95064, USA\\
\authormark{2}Genomics Institute, University of California Santa Cruz \\ Santa Cruz, CA 95064, USA\\
}

\email{\authormark{*}pvbaudin@ucsc.edu} %% email address is required; see note below about the corresponding author designation




% \author*[1,2]{\fnm{Pierre V} \sur{Baudin}}\email{pvbaudin@ucsc.edu}
% \author[1,2]{Mircea Teodorescu}
% \affil[1]{\orgdiv{Department of Electrical and Computer Engineering}, \orgname{University of California Santa Cruz}, 
%  \orgaddress{\city{Santa Cruz}, \state{CA}, \postcode{95064}, \country{USA}}}
% \affil[2]{\orgdiv{Genomics Institute}, \orgname{University of California Santa Cruz}, 
%  \orgaddress{\city{Santa Cruz}, \state{CA}, \postcode{95064}, \country{USA}}}

% \homepage{http:...} %% author's URL, if desired

%%%%%%%%%%%%%%%%%%% abstract %%%%%%%%%%%%%%%%
%% [use \begin{abstract*}...\end{abstract*} if exempt from copyright]

\begin{abstract}
For a transparent well with a known volume capacity, changes in fluid level result in predictable changes in magnification of an overhead light source. For a given well size and fluid, the relationship between volume and magnification can be calculated if the fluidâ€™s index of refraction is known or in a naive fashion with a calibration procedure. Light source magnification can be measured through a camera and processed using computer vision contour analysis with OpenCV. This principle was applied in the design of a 3D printable sensing device using a raspberry pi zero and a camera
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%  body  %%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{sec:intro}

% Motivation:
% Applications that require fluid sensing 
% Common methods of fluid sensing and their drawbacks

The automation of cell culture procedures has the potential to greatly increase the throughput and consistency of cell culture based experiments \cite{doulgkeroglou_automation_2020}. Manipulation of fluids of is a key feature for any automated culture platform. Systems must have the ability to deliver or move precise quantities of fluids. To automate movement of fluids, some systems use a "lab-on-a-chip" approach \cite{figeys_lab---chip_2000}, utilizing microfluidic channels to transport fluids. Other systems use robot manipulators to deliver measured quantities of fluids with micro-pipettes \cite{doulgkeroglou_automation_2020, fleischer_analytical_2018, steffens_versatile_2017}. Regardless of mechanism behind the delivery of fluids, being able to detect the presence and volume of fluids within provides key error detection and correction functionality that open loop methods lack.

Surface level measurement within a container of known volume is a simple way to determine fluiod volume. This can be done with electrically active probes dipped into a fluid being measured \cite{singh_review_2019}. These probes can be effective but direct contact with the fluid can be problematic for cell culture applications wherein any potential contamination vector increases the risk of failure \cite{lincoln_chapter_1998}. Non-contact sensing is preferable for sensitive applications. Optical fluid sensing methods take advantage of how fluids interact with light. Several optical approaches for measuring fluids in culture plates exist. One method uses computer vision with well placed light sources and sensors placed at specific angles to measure ray deflection \cite{jain_total-internal-reflection_2021}. This method uses reflectance of the fluid surface, which makes it usable no matter the solid mass contents of the well. However, the angular requirements of the sensor electronics makes tight packing of independent sensing elements infeasible, making parallel measurements within a plate complex or impossible. Another published method involves imaging the distortions in a printed grid to visualize changes in refraction related to fluid level \cite{litt_visualization_1989}. While this approach can be used in parallel on many wells at once, it is highly affected by occlusion resulting from material in the plate and can be affected by ambient lighting conditions.

% Two other published methods use overhead image measurements to infer fluid level from resulting distortions, one tracking sizes of added droplet sizes in microplates \cite{thurow_fast_2011}, 


%% why are these approaches lacking 

Here we propose a method for non-contact optical detection of fluid level using a CMOS camera sensor and an LED. We detail the principles at work and show a 3D printed device that can be used to perform measurements in 24 well culture plates. Similar to the approach shown in \cite{litt_visualization_1989}, this method relies on the lens-like properties of fluids and the resulting changes of an image viewed through them. Instead of viewing a grid, we detect the apparent size of an overhead light source. Changes in the apparent distance of the light source correlate to changes in fluid level. A bright overhead light source can shine through some samples, making this approach usable in scenarios with solid occlusion that would disrupt the viewing of a grid. Additionally, the electronics required are set up directly inline with the sample wells, allowing electronics to be packed into a grid allowing parallel sensing of many wells at once. 

\section{Methods}\label{sec:methods}
\subsection{Operating Principle}
\label{subsec:principle}
\begin{figure}[H]
    \centering
    \includegraphics[width = \columnwidth]{figure-pics/generalized-operating-principle.png}
    \caption{\textbf{Apparent distance of the light source changes based on fluid depth for fluids with index of refraction greater than air} (relationship is inverted if index is less than air). Refraction angles can be determined with Snell's law with known indices of refraction of the 2 media ($n_1 sin(\theta_1) = n_2 sin(\theta_2)$). In the case of second transition back into the original medium, the relationship $\theta_3 = \theta_1$ can be derived, hence the labeling of the third angle as $\theta_1$ in this diagram. $L$ = fluid depth, $I$ = apparant distance of object. $h_0$ = distance between object and top of fluid, $h_1$ = distance between bottom of fluid and measurement plane.}
    \label{fig:principle}
\end{figure}
% h_0 = (h - h_1) - L
% $$
% $h - h_1$ is constant and we will now label it as $C_0$
% $$
% \begin{aligned}
% &x_{0}=(C_0 - L) \tan \theta_{1} \\
% &C_1 = \tan \theta_{1} \\
% &x_{1}= x_0 + L \tan \theta_{2} \\
% &C_2 = \tan \theta_{2} \\
% &x_f = x_1 + h_1 C_1 \\
% &x_f = (C_0 - L)C_1 + L C_2 +h_1 C_1 \\
% &x_f = C_0C_1 - LC_1 + L C_2 +h_1 C_1 \\
% &x_f = L(-C_1 + C_2) + h_1C_1 + C_0C_1 \\
% & \tan(\theta_1) = \frac{x_f}{I} \\

The measurement principle behind this system relies on the lensing effects of fluids with different indices of refraction. In figure \ref{fig:principle} the diagrams represent how the apparent distance of the light source changes based on fluid depth. In the case of a fluid with a index of refraction greater than air (like water), the light source will appear closer as the fluid level increases. \\

To derive a function relating the fluid depth to the apparent distance of the light source, we define the following constants.
$$
\begin{aligned}
& C_0 = h - h_1 \\
& C_1 = \tan \theta_{1} \\
& C_2 = \tan \theta_{2}
\end{aligned}
$$
These can be considered constants because our light source sends rays in all directions below it, so any angle $\theta_1$ can be chosen so long as it results in a ray that intersects the fluid, and from this chosen angle $\theta_2$ can be derived via Snell's Law. In terms of these constants the resulting transfer function is:
$$
I=\frac{L(-C_1 + C_2) + h_1C_1 + C_0C_1}{C_0}
$$
This function relates the apparent distance of the image $I$ to the fluid level $L$ and is a first degree polynomial. The full derivation can be found in section 1 of the supplemental materials. This function is a useful approximation that ignores several factors including refraction caused by the plate material and refraction from the meniscus geometry of the fluid surface, our data show that accurate results can be obtained with this approximation in most scenarios. Meniscus has a substantial effect on measurement in two extremes, an almost empty well, and an almost full well. These meniscus effects are further explored in section \ref{sec:results}

% one edge case where the meniscus has a substantial effect of the measurement is examined in section \ref{sec:min-invert}. Additionally, users should be aware that the effect of meniscus geometry on the flatness of the surface is minimized in the center of the fluid container, making that the optimal position for measurement.

% $$
% \begin{aligned}
% &h = h_0 + L + h_1 \\
% &x_{1}=h_{0} \tan \theta_{1} \\
% &x_{2}=h_{f} \tan \theta_{2} \\
% &x=h_{2} \tan \theta_{1} \\
% &x=\left(h_{0}+h_{2}\right) \tan \theta_{1}+L \tan \theta_{2} \\
% &\theta_{x}=90-\theta_{1} \\
% &h_{I}=\frac{x}{\tan \theta_{x}} \\
% &h_{I}=\frac{\left(h_{0}+h_{1}\right) \tan \theta_{1}+L \tan \theta_{2}}{\tan \left(90-\theta_{1}\right)}
% \end{aligned}
% $$




% \begin{figure}[H]
%     \centering
%     \includegraphics[width = 0.25\columnwidth]{2_Methods/Pictures/grabstract.png}
%     \caption{hardware setup placeholder}
%     \label{fig:setup}
% \end{figure}

The polynomial can be characterized analytically so long as we can determine how the image distance relates to size on the camera sensor. This can be determined by taking a picture of a ruled measurement calibration slide at several known distances. It can also be characterized by a simple calibration step, being that the relationship is linear, a 2 point calibration would theoretically be sufficient, but for greater accuracy a 5 point calibration would be more prudent. Once this polynomial is characterized, image data is sufficient for capturing fluid level

\subsection{Hardware}
To test this approach, we designed a 3D printable rig that holds a raspberry pi camera and a white LED. Figure \ref{fig:exploded-view} shows 3D renders of the parts comprising the measurement device and figure \ref{fig:device-with-plate} shows the experimental setup.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figure-pics/hardware-render.png}
    \caption{\textbf{3D renders of measurement rig} A: a 3W white LED, B: 3D printed enclosure with a plug to hold the light in place, C: Raspberry Pi Spy Camera, D: Raspberry Pi Zero W, E: rigid plate holder, F: experimental setup. Rendered using Fusion360, real setup shown in figure \ref{fig:device-with-plate} }
    \label{fig:exploded-view}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figure-pics/physical-setup.png}
    \caption{\textbf{Experimental setup with 24 Well plate} }
    \label{fig:device-with-plate}
\end{figure}


\subsection{Analysis Pipeline}
Using openCV \cite{opencv_library}, a free and open-source machine vision toolkit, we can capture and measure the size of spot light image. This can be done on static images or on videos including live feeds. We do this by detecting the central contour in the image and fitting an ellipse to it. The result can be calculated fast and is robust to occlusion and noise. In order to do this On the raspberry pi zero we run a video stream using the open-source RPi Cam Web Interface \cite{noauthor_rpi-cam-web-interface_nodate}. The python code for this image analysis is lightweight and can be run internally on the raspberry pi or on an external system. For external system use, the code grabs frames from the MJPEG stream generated by the camera web interface.

% The relevant code can be found on github, link is included in the supplemental materials.




Figure \ref{fig:detection-process} details the process through which a data point is obtained. Once an ellipse is fit to the central contour of the image, we filter the output by accepting the average value of a rolling buffer when the standard deviation of that buffer falls below a threshold value. This is to compensate for the disturbance of the fluid surface when new fluid is added or if the plate is shaken. By only accepting reads when the reading has stabilized, we avoid wildly fluctuating erroneous readings any time the fluid is disturbed.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figure-pics/Detection-Process-Flowchart.png}
    \caption{\textbf{Flowchart representing detection process pipeline}}
    \label{fig:detection-process}
\end{figure}

\section{Results}\label{sec:results}
%% meniscus formation and miniscus inversion
% show plot of error
% justify using only the linear portion
% show plot of linear portion
% show that error is actually minimized at 2

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figure-pics/meniscus-invert-v2.png}
    \caption{\textbf{Contour ellipse perimeter as a function of fluid volume.}
    Region A shows behavior before meniscus has reached stable geometry. Region B has stable meniscus and shows linear response as predicted in section \ref{subsec:principle}, Region C shows when the well begins to get full, the surface tension causes Meniscus Inversion. Region D is where fluid has spilled over the edge of the well, flattening the meniscus.}
    \label{fig:data-with-meniscus}
\end{figure}

The plot shown in figure \ref{fig:data-with-meniscus} shows the output of our sensing system for from the first possible reading to the overflowing of the well. Figure \ref{fig:Dry-Fill} shows why the first possible reading from a previously dry well occurs around 0.4ml. When the fluid level is very low in a well, the geometry of the meniscus cannot fully form. The center of the meniscus will rise more slowly before the full geometry of the meniscus is formed, this is because of the fluid volume held in the meniscus edges. Therefore, before the full formation of the meniscus, the overhead light image viewed from the center of the meniscus grows more slowly up until point A shown in figure \ref{fig:data-with-meniscus}. As the well starts to get full, a new distortion of the meniscus geometry occurs due to the surface tension of the fluid. The image grows substantially faster due to the magnifying properties of the convex meniscus, this phenomenon begins at point B. Finally, when the well overflows, the meniscus flattens resulting in a final level of unchanging magnification beginning at point C.

The region between points A and B are where this sensing process will be most generalizable, as the relationship between the spotlight image contour size and the fluid level is highly linear. 
% \begin{figure}[H]
%     \centering
%     \includegraphics[width=\textwidth]{3_Results/Pictures/Error-comparison.png}
%     \caption{Error comparison, meniscus geometry formation and inversion visible as large increase in error}
%     \label{fig:full-dataset-error-polyorder}
% \end{figure}

\subsection{Calibration}
Deriving an effective transfer function for this system can be done by fitting a curve to a set of calibration points. Deciding on the best fit curve is a question of trade offs. The phenomenon we are measuring is linear within the range of volumes that have a stable meniscus geometry. A simple 2 point linear fit with points from the linear region, generates outputs with average error below 100$\mu$l within the linear range. Outside this range, the estimation error increases substantially. 

In order to represent the entire curve, we need a high order polynomial fit. Using a least squares approximation method, we can fit polynomials to any subset of points we choose. Considering the phenomena shown in figure \ref{fig:data-with-meniscus}, the curve we are attempting to characterize has 3 distinct regions. Calibration points should be selected to include points from each of these regions. Precision measurements of well volume inside the meniscus inversion region is unlikely to be very accurate, as disruptions in surface tension can cause overflow to occur at different points. Therefore for calibration it should be sufficient to model the linear region occurring at the start of meniscus inversion. This is adequate to detect that the fluid level is greater than the capacity of the well. Since the other 2 regions are linear, we can adequately fit a curve with 2 data points selected from each region. Comparisons of different order curve fits can be seen in figure \ref{fig:polynomial-curve-compare-by-order}



% Figure \ref{fig:total_error_points} shows the total error for each curve when applied to a test set of data from measurements withheld from the curve fitting operation. Each set of calibration points includes 2 points close to each inflection as well as a random selection from the points between those. For example, the 10 point calibration set consists of 2 points near the beginning and end, and a random selection of 6 other points from the middle region. Curves are compared to the baseline 2 point linear fit shown as a blue dotted line. The data show that around 10 points, the higher order fits start to outperform the linear fit. However, past a the 4th order fit, gains from increasing the polynomial order diminish greatly, and beyond 5th order going higher frequently diminishes performance. 

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=\textwidth]{figure-pics/total_error_comparison_from_points2.png}
%     \caption{Comparing magnitude of total error from least squares polynomial fits of different order}
%     \label{fig:total_error_points}
% \end{figure}



\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figure-pics/polynomial-fit-comparison-A6-100-6point.png}
    \caption{\textbf{Curve comparisons} Comparing 2 point linear fit with 6 point least square polynomial fits of different orders}
    \label{fig:polynomial-curve-compare-by-order}
\end{figure}


% \begin{figure}[H]
%     \centering
%     \includegraphics[width=\textwidth]{figure-pics/Error-comparison_10_point.png}
%     \caption{Comparing errors from polynomial fits}
%     \label{fig:polynomial-error-compare-by-order}
% \end{figure}

% Figures \ref{fig:polynomial-curve-compare-by-order} and \ref{fig:polynomial-error-compare-by-order} show the curves generated from these calibration points and the error per point. Here we can see that while the 4th and 5th order fits have the same overall error magnitude, the 5th order curve generates considerably less error in the regions near the inflection points. For this reason we can say the a 10 point calibration with a 5th order polynomial fit would be a solid choice for this system's transfer function. However if the users needs are constrained to the linear region, then the inaccuracies of a simple 2 point calibration may be a worthwhile trade off for its simplicity and speed of setup.

\subsubsection{Generalizability of transfer function}
To evaluate the consistency of this measurement principle, data was captured in 2 different wells during 2 different runs. The resulting error magnitudes are shown in figure \ref{fig:polynomial-error-compare-by-order-and-well}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figure-pics/error-compare-wells.png}
    \caption{\textbf{Error Comparison} Comparing errors across 4 runs for various polynomial fits}
    \label{fig:polynomial-error-compare-by-order-and-well}
\end{figure}

As expected, the error from the 2 point linear fit is substantial outside the central linear range, but within this range, the measurement error can be reasonable depending on the precision needs of the user. Having the option of a simple 2 point calibration for certain uses is an advantage. The other polynomial fits use the 6 points shown in the curve in figure \ref{fig:polynomial-curve-compare-by-order}. It is interesting to note that the 4th order curve fit performs better than the 5th order fit. Most datapoints shown fall within 100$\mu l$ error with occasional outlier measurements with a maximum error of 190$\mu l$. Knowing this measurement precision means that volumetric fluid dosing measured with this particular implementation of this principle should be tolerant to errors up to 190$\mu l$.

% \begin{itemize}
%     \item surface geometry is not flat, therefore measurements must be taken at the same position for any given well
%     \item curves will differ based on well geometry, material, and fluid properties
%     \item captured data shows that 
% \end{itemize}







% A better approach might be to take what we know about the physical principles at play here to create a piecewise transfer function for the three distinct regions of interest. If we separate meniscus formation, the linear region, and meniscus inversion, we can...

\subsection{Dry Well}
When a well is completely dry, droplets hold their shape rather than forming a layer along the bottom. Once $~$0.5ml have been placed in the dry well, a layer adheres to the bottom and the measurement starts to work. This is shown in figure \ref{fig:Dry-Fill} The well can also be moistened beforehand with a small amount of water, doing so disrupts the formation of droplets and allows the measurements to work at smaller fluid volumes.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{figure-pics/Dry-Fill.png}
    \caption{\textbf{Limitations with dry wells} before a fluid film has formed across the dry bottom of the well, measurements have no significance}
    \label{fig:Dry-Fill}
\end{figure}

\section{Discussion}\label{sec:discussion}
By leveraging the availability of low cost camera hardware and open source machine vision tools, devices that use computer vision for sensing tasks are likely to become more ubiquitous. The proliferation of cheap mass-produced camera sensors is an opportunity for designers to consider many new methods of measurement.

The device shown here serves as a simple proof of concept for the use of this fluid level measurement principle. For practical purposes, this should be deployed with many cameras in parallel, each monitoring a single well. Previous work has been published laying out the design and use of a 24 well parallel microscope system using similar camera hardware and LEDs, this system is called the "Picroscope" \cite{ly_picroscope_2021, baudin_low_2021}. The  picroscope is also built to be compatible with a microfluidic cell culture feeding platform \cite{seiler_modular_2022}. Applying this principle to this system can enable feedback control for fluid contents of the wells in this and other microfluidic "lab-on-a-chip" type systems.

It would also be possible to use this principle without the overhead LED being permanently affixed above the culture plate. In applications using pipette robots, LEDs could be attached to the end effector, if the arm positions the LED at a known position, spot measurements can be taken and used to detect potential dosing errors or losses due to evaporation.

The principle can also be applied to much larger containers where fluid level measurements are important. Fluid storage containers exist for many applications and while approaches for measuring level in large containers exist, few of those applications are applicable to small volume containers like culture plates. The approach presented here may be broadly applicable to many fields. Furthermore, with different light frequency selections, this principle could be applied to fluids that are opaque in the visible light spectrum but transparent to infrared.

This proposed fluid level sensing method is a simple, reliable, and accurate approach that has been validated for cell culture plates and has potential for uses in other applications. 


\begin{backmatter}
\bmsection{Funding}
This work was supported by the Schmidt Futures SF 857, the National Human Genome Research Institute under Award number 1RM1HG011543, the National Science Foundation under award numbers NSF 2034037 and NSF 2134955.
% Content in the funding section will be generated entirely from details submitted to Prism. Authors may add placeholder text in the manuscript to assess length, but any text added to this section in the manuscript will be replaced during production and will display official funder names along with any grant numbers provided. If additional details about a funder are required, they may be added to the Acknowledgments, even if this duplicates information in the funding section. See the example below in Acknowledgements.

\bmsection{Acknowledgments}
P.V. Baudin thanks David Haussler for the support and guidance he provides to the many projects in our research group.
% The section title should not follow the numbering scheme of the body of the paper. Additional information crediting individuals who contributed to the work being reported, clarifying who received funding from a particular source, or other information that does not fit the criteria for the funding block may also be included; for example, ``K. Flockhart thanks the National Science Foundation for help identifying collaborators for this work.'' 

\bmsection{Disclosures}
% Disclosures should be listed in a separate nonnumbered section at the end of the manuscript. List the Disclosures codes identified on the \href{https://opg.optica.org/submit/review/conflicts-interest-policy.cfm}{Conflict of Interest policy page}, as shown in the examples below:

\medskip

\noindent PVB: UC Santa Cruz (P)

\medskip


\bmsection{Data Availability}
The data used to generate the plots shown in this article are available from the corresponding author upon request. Code used to measure contour size from live video stream is available from the corresponding author upon request. 3D Model files used for printing the measurement device are available from the corresponding author upon request. This work is intended to be released open source, a GitHub repository containing the measurement code and 3D model files will be made public at time of publication. While repository remains private, access will be granted by request.
% A Data Availability Statement (DAS) will be required for all submissions beginning 1 March 2021. The DAS should be an unnumbered separate section titled ``Data Availability'' that
% immediately follows the Disclosures section. See the \href{https://opg.optica.org/submit/review/data-availability-policy.cfm}{Data Availability Statement policy page} for more information.

% Optica has identified four common (sometimes overlapping) situations that authors should use as guidance. These are provided as minimal models, and authors should feel free to
% include any additional details that may be relevant.

% \begin{enumerate}
% \item When datasets are included as integral supplementary material in the paper, they must be declared (e.g., as "Dataset 1" following our current supplementary materials policy) and cited in the DAS, and should appear in the references.

% \bmsection{Data availability} Data underlying the results presented in this paper are available in Dataset 1, Ref. [3].

% \bigskip

% \item When datasets are cited but not submitted as integral supplementary material, they must be cited in the DAS and should appear in the references.

% \bmsection{Data availability} Data underlying the results presented in this paper are available in Ref. [3].

% \bigskip

% \item If the data generated or analyzed as part of the research are not publicly available, that should be stated. Authors are encouraged to explain why (e.g.~the data may be restricted for privacy reasons), and how the data might be obtained or accessed in the future.

% \bmsection{Data availability} Data underlying the results presented in this paper are not publicly available at this time but may be obtained from the authors upon reasonable request.

% \bigskip

% \item If no data were generated or analyzed in the presented research, that should be stated.

% \bmsection{Data availability} No data were generated or analyzed in the presented research.
% \end{enumerate}


\bmsection{Supplemental document}
See Supplement 1 for supporting content. 

\end{backmatter}

% \section{References}
% \label{sec:refs}
% Proper formatting of references is extremely important, not only for consistent appearance but also for accurate electronic tagging. Please follow the guidelines provided below on formatting, callouts, and use of Bib\TeX.

% \subsection{Formatting reference items}
% Each source must have its own reference number. Footnotes (notes at the bottom of text pages) are not used in our journals. References require all author names, full titles, and inclusive pagination. Examples of common reference types can be found in the  \href{https://opg.optica.org/jot/submit/style/oestyleguide.cfm} {style guide}.


% The commands \verb+\begin{thebibliography}{}+ and \verb+\end{thebibliography}+ format the section according to standard style, showing the title {\bfseries References}.  Use the \verb+\bibitem{label}+ command to start each reference.

% \subsection{Formatting reference citations}
% References should be numbered consecutively in the order in which they are referenced in the body of the paper. Set reference callouts with standard \verb+\cite{}+ command or set manually inside square brackets [1].

% To reference multiple articles at once, simply use a comma to separate the reference labels, e.g. \verb+\cite{Yelin:03,Masajada:13,Zhang:14}+, produces \cite{Yelin:03,Masajada:13,Zhang:14}.
% %Using the \texttt{cite.sty} package will make these citations appear like so: [2--4].

% \subsection{Bib\TeX}
% \label{sec:bibtex}
% Bib\TeX{} may be used to create a file containing the references, whose contents (i.e., contents of \texttt{.bbl} file) can then be pasted into the bibliography section of the \texttt{.tex} file. A Bib\TeX{} style file, \texttt{opticajnl.bst}, is provided.

% If your manuscript already contains a manually formatted \verb|\begin{thebibliography}|... \verb|\end{thebibliography}| list, then delete the \texttt{latexmkrc} file (if present) from your submission files. However you should ensure that your manually-formatted reference list adheres to style accurately.

% \section{Conclusion}
% After proofreading the manuscript, compress your .tex manuscript file and all figures (which should be in EPS or PDF format) in a ZIP, TAR or TAR-GZIP package. All files must be referenced at the root level (e.g., file \texttt{figure-1.eps}, not \texttt{/myfigs/figure-1.eps}). If there are supplementary materials, the associated files should not be included in your manuscript archive but be uploaded separately through the Prism interface.

% %%%%%%%%%%%%%%%%%%%%%%% References %%%%%%%%%%%%%%%%%%%%%%%%%

% Add references with BibTeX or manually.
% \cite{Zhang:14,OPTICA,FORSTER2007,Dean2006,testthesis,Yelin:03,Masajada:13,codeexample}

%%%%%%%%%% If using BibTeX:
\bibliography{sample}

%%%%%%%%%% If preparing manually:
% \begin{thebibliography}{1}
% \newcommand{\enquote}[1]{``#1''}

% \bibitem{Zhang:14}
% Y.~Zhang, S.~Qiao, L.~Sun, Q.~W. Shi, W.~Huang, L.~Li, and Z.~Yang,
%   \enquote{Photoinduced active terahertz metamaterials with nanostructured
%   vanadium dioxide film deposited by sol-gel method,}
%   {\protect\JournalTitle{Optics Express}} \textbf{22}, 11070--11078 (2014).

% \bibitem{Optica}
% {Optica}, \enquote{{Optica Publishing Group},}
%   \url{http://www.opg.optica.org}.

% \bibitem{FORSTER2007}
% P.~Forster, V.~Ramaswamy, P.~Artaxo, T.~Bernsten, R.~Betts, D.~Fahey,
%   J.~Haywood, J.~Lean, D.~Lowe, G.~Myhre, J.~Nganga, R.~Prinn, G.~Raga,
%   M.~Schulz, and R.~V. Dorland, \enquote{Changes in atmospheric consituents and
%   in radiative forcing,} in \enquote{Climate Change 2007: The Physical Science
%   Basis. Contribution of Working Group 1 to the Fourth assesment report of
%   Intergovernmental Panel on Climate Change,}  S.~Solomon, D.~Qin, M.~Manning,
%   Z.~Chen, M.~Marquis, K.~B. Averyt, M.~Tignor, and H.~L. Miler, eds.
%   (Cambridge University Press, 2007).

% \end{thebibliography}

\end{document}
