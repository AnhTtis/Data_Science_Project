\section{Results}
Here, we evaluate the performance impact of our software changes and
additions introduced in Section~\ref{sec:integration}. First, we introduce the
test setup, specifically we introduce the utilized Octo-Tiger scenario, hardware and software versions. 
Then we cover the parameters and patches used in our experiments and follow with the performance tests.
%After introducing the test setup, we continue with the actual performance tests.%, covering both HPX-SYCL integrations, our experimental Kokkos changes and a performance comparison of the various exeuction spaces and kernels available on each hardware platform.
%The patch makes each \lstinline{get_future} call wait for the given SYCL event and return an ready future via \lstinline{hpx::make_ready_future()}.
\label{sec:results}
\begin{figure*}[t]%4
\centering
\subfloat[\label{fig:integration-host-tasks-a100-1}A100: Increasing Number of GPU executors] {
\centering
  \includegraphics[width=.33\textwidth]{figures/A100_runs/host_task/host_task_async_speedup_A100_32cores_1agg.pdf}  
}
\hspace*{-0.1cm} 
\subfloat[\label{fig:integration-host-tasks-a100-2}A100: Increasing number of kernels aggregated] {
\centering
  \includegraphics[width=.33\textwidth]{figures/A100_runs/host_task/host_task_async_speedup_A100_32cores_1executors.pdf}  
}
\hspace*{-0.1cm} 
\subfloat[\label{fig:integration-host-tasks-a100-3}A100: Best combinations] {
\centering
  \includegraphics[width=.33\textwidth]{figures/A100_runs/host_task/host_task_async_speedup_A100_32exec_8agg.pdf}  
}
\hfill
\centering
\subfloat[\label{fig:integration-host-tasks-mi100-1}MI100: Increasing Number of GPU executors] {
\centering
  \includegraphics[width=.33\textwidth]{figures/MI100_runs/host_tasks/host_task_async_speedup_A100_32cores_1agg.pdf}  
}
\hspace*{-0.1cm} 
\subfloat[\label{fig:integration-host-tasks-mi100-2}MI100: Increasing number of kernels aggregated] {
\centering
  \includegraphics[width=.33\textwidth]{figures/MI100_runs/host_tasks/host_task_async_speedup_A100_32cores_1executors.pdf}  
}
\hspace*{-0.1cm} 
\subfloat[\label{fig:integration-host-tasks-mi100-3}MI100: Best combinations] {
\centering
  \includegraphics[width=.33\textwidth]{figures/MI100_runs/host_tasks/host_task_async_speedup_A100_8exec_32agg.pdf}  
}
\caption{Runs with the SYCL-Integration (host task version) turned on (orange) and turned off (gray). In \ref{fig:integration-host-tasks-a100-1} and \ref{fig:integration-host-tasks-mi100-1} we do not use the dynamic work aggregation and instead only increase the number of GPU executors. In \ref{fig:integration-host-tasks-a100-2} and \ref{fig:integration-host-tasks-mi100-2} we only use one executor, but increase the maximum number of kernels aggregated into one kernel launch. In \ref{fig:integration-host-tasks-a100-3} and \ref{fig:integration-host-tasks-mi100-3} we see the best combinations. The Kokkos optimization patch is applied to all runs.}
\label{fig:integration-event-polling-host-taks}
\end{figure*}
\subsection{Test Setup}
\subsubsection{Scenario and Hardware:}
As a benchmark scenario, we choose the Sedov-Taylor blast wave. This scenario
is one of the benchmarks originally used to verify Octo-Tiger's output. It only
uses the hydrodynamic solver and has an analytical solution, making it ideal
for testing codes like Octo-Tiger.
For our purposes, being limited to the hydrodynamic solver is useful, since
this is the module that currently fully supports the dynamic work aggregation.
This allows us to finely tune the size of the compute kernels launched (by
bunching up sub-grids while the GPU executor is busy and launching them as one
kernel once said executor is done with previous work). Hence, we can more
easily take a look at the overheads of our integration for differently sized
kernels. The support within the gravity solver for this kind of work
aggregation is not yet complete, causing us to rely on the hydro-only scenario.
%This exact scenario was actually previously used when introducing the dynamic
%work aggregation~\cite{daiss2022aggregation}.

The computational effort required for this scenario is as follows: It
includes $512$ leaf sub-grids, resulting in $262144$ cells overall. Per
time-step we call 15 GPU kernels per leaf sub-grid, giving us 7680 GPU kernel calls
per time-step overall (with 15360 CPU-GPU data-transfers). This assumes we have
the dynamic work aggregation described above turned off and further highlights
why we need it within the hydro module in the first place. The measured runtime
per time-step is the average over $15$ time-steps, and we use double precision for
all simulations.
The best compute time reached for this exact scenario (on the same
hardware) in previous work was $86.6$ ms on an
NVIDIA\textsuperscript{\textregistered} A100~\cite{daiss2022aggregation}. This
runtime includes not just all GPU kernels, but also things like CPU-GPU
data-transfers, post-processing on the CPU, scheduling of the GPU kernels,
determination of the time-step size and notably, all logic required for the
work aggregation.
Hence, it is a scenario that tries to run a large amount of small kernels, with
the GPU busy running them and the CPU busy scheduling and potentially
aggregating them.

We run this scenario on two nodes: The first node contains a
NVIDIA A100 GPU, and an
Intel\textsuperscript{\textregistered} Xeon\textsuperscript{\textregistered}
Platinum $8358$ CPU. The second node contains an AMD MI100 GPU and an AMD
EPYC\textsuperscript{\texttrademark} 7H12 CPU. We use $32$ HPX worker threads on both CPUs to
keep the runs more comparable to each other (by thus limiting HPX to $32$ CPU cores on both machines).
%The software versions (\textit{git commits}) are the following: boost 1.75.0, HWLOC 2.7.1, HDF5 1.18.12, Silo 4.10.2, Kokkos \textit{23a5e94}\footnote{part of \url{https://github.com/kokkos/kokkos/pull/5628}}, HPX-Kokkos \textit{6f6b655}\footnote{part of \url{https://github.com/STEllAR-GROUP/hpx-kokkos/pull/13}}, JEMALLOc 5.2.1, HPX  \textit{5641895}, CPPuddle \textit{969902f}\footnote{part of \url{ https://github.com/STEllAR-GROUP/hpx/pull/6085}},  Octo-Tiger \textit{e969470}\footnote{part of \url{https://github.com/STEllAR-GROUP/octotiger/pull/432}}, and DPC\texttt{++}/Intel OneAPI \textit{44c6437684d64aba82d5a3de0e4bbe21d2b1f7ce}. 
The software versions (\textit{git commits}) we use can be found in Table~\ref{tab:software}.
%In particular, we use DPC\texttt{++} (OneAPI) as a compiler and SYCL implementation, since the Kokkos SYCL  execution space makes use of OneAPI extensions such as \lstinline[language=c++]{sycl_ext_oneapi_enqueue_barrier}\footnote{See \url{https://github.com/intel/llvm/blob/2022-06/sycl/doc/extensions/supported/sycl_ext_oneapi_enqueue_barrier.asciidoc}} and \lstinline{sycl_ext_intel_usm_address_spaces}\footnote{See \url{https://github.com/intel/llvm/blob/2022-06/sycl/doc/extensions/supported/sycl_ext_intel_usm_address_spaces.asciidoc}}.
In particular, we use DPC\texttt{++} (OneAPI) as a compiler and SYCL
implementation, since the Kokkos SYCL execution space makes use of OneAPI
extensions such as \lstinline[language=c++]{sycl_ext_oneapi_enqueue_barrier}
and \lstinline{sycl_ext_intel_usm_address_spaces}.


\begin{table*}[tb]%1
    \centering
    \begin{tabular}{llll} \toprule
     Boost &  1.75.0 & HWLOC & 2.7.1  \\
     HDF5 & 1.8.12  & Silo &  4.10.2  \\
     Kokkos & \textit{23a5e94}$^1$ & HPX-Kokkos & \textit{6f6b655}$^2$ \\
     JEMALLOC  & 5.2.1 & HPX & \textit{5641895}$^3$ \\
     CPPuddle & \textit{969902f}$^4$ & Octo-Tiger & \textit{e969470}$^5$ \\
     ROCm & 5.2.0 & CUDA & 11.7 \\
     DPC++/Intel OneAPI & \multicolumn{3}{l}{44c6437684d6} \\\bottomrule
     %DPC++/Intel OneAPI & \multicolumn{3}{l}{44c6437684d64aba82d5a3de0e4bbe21d2b1f7ce} \\\bottomrule
    \end{tabular}
    \caption{Software versions used in the experiments. As we use multiple experimental pull requests, we added the exact git commits and associated PRs.}
    \begin{flushleft}
    \footnotesize{$1$ part of \url{https://github.com/kokkos/kokkos/pull/5628} } \\
    \footnotesize{$2$ part of  \url{https://github.com/STEllAR-GROUP/hpx-kokkos/pull/13}} \\
    \footnotesize{$3$ part of \url{ https://github.com/STEllAR-GROUP/hpx/pull/6085}} \\
    \footnotesize{$4$ part of \url{https://github.com/SC-SGS/CPPuddle/pull/15}} \\
    \footnotesize{$5$ part of \url{https://github.com/STEllAR-GROUP/octotiger/pull/432}}
    \end{flushleft}
   \label{tab:software}
\end{table*}

\subsubsection{Parameters and Configurations:}
We run Octo-Tiger in multiple software configurations by applying patches to
its dependencies.

The first
patch\footnote{\url{https://github.com/STEllAR-GROUP/OctoTigerBuildChain/blob/sycl_toolchain/remove_hpx_sycl_integration.patch}}
simply turns off the HPX-SYCL integration within HPX to allow us to judge its
benefits. To make everything compile correctly, the interface needs to stay the
same, hence return an HPX future for a given SYCL event. With the patch to turn
off the integration, HPX waits for the SYCL event and only then returns a ready
future via \lstinline[language=c++]{hpx::make_ready_future()}, effectively
turning it from an asynchronous operation to a synchronous one. By default, this
patch is not applied for the following tests, unless stated otherwise (HPX-SYCL
OFF).

The second patch contains the Kokkos optimizations mentioned previously. In
early tests of our integration we found that the Kokkos SYCL backend contains
multiple barriers (\lstinline{sycl_ext_oneapi_enqueue_barrier}), reducing the
benefits we gain with our integration. Fortunately, we also found that we can
get rid of some of those barriers when using \lstinline{in_order} queues, as this queue
property already enforces the same kind of ordering. By default, this patch is
applied for the following tests unless stated otherwise.

The third change we apply is switching between the \lstinline{host_task} based HPX-SYCL
integration and the event polling based integration. This is done at
compile time within HPX-Kokkos, as this is the point where we call the basic
\lstinline{get_future} functionality. Depending on the configuration here, we
either call the event polling version or the \lstinline{host_task} version.

Other parameters we consider are the number of HPX worker threads, the number of GPU
executors, and the maximum number of GPU kernels that may be aggregated
together by one executor. 
Firstly, the number of HPX worker threads defines how many overall CPU threads are
working on the available HPX tasks, thus this parameter effectively steers how many
CPU cores are used by HPX.
Secondly, the number of GPU executors steers the number of concurrent GPU
kernels/data-transfers that are possible. 
% Other parameters we consider are the number of CPU cores, the number of GPU
% executors, and the maximum number of GPU kernels that may be aggregated
% together by one executor. 
% The number of GPU executors steers the number of concurrent GPU
% kernels/data-transfers that are possible. 
%The GPU executors are drawn from a pre-allocated
%queue to avoid expensive creation and destruction of underlying queues/streams,
%and steer the number of concurrent GPU kernels/data-transfers that are
%possible. 
Lastly, the maximum number of aggregated GPU kernels requires a more detailed
explanation: When we encounter a kernel that is compatible for aggregation (as
marked by the programmer), we suspend the current task and wait for other
threads to hit the same kernel on different sub-grids. We then launch all of
them as one bigger, aggregated kernel if we either hit a maximum number of
tasks encountering the kernel (this is the maximum aggregation parameter), or
if the underlying GPU executor becomes idle which may trigger the aggregated
kernel to launch sooner (avoiding deadlocks caused by odd numbers
of sub-grids). 
 This aggregation increases the size of the actual kernels
 running on the GPU, thus avoiding starving the GPU with numerous but tiny compute kernels,
 and decreases the load on the GPU runtime as we need fewer overall API calls. 




The dynamic work aggregation also influences how often the \lstinline[language=c++]{get_future} functionality is called. For each leaf
sub-grid we run five separate GPU kernels before we have to transfer the
results back to the host for post-processing and communicating them to the
neighbors.

With the work aggregation turned on (\emph{i.e.}\ a maximum larger
than one kernel), we have one additional \lstinline[language=c++]{get_future}
call at the beginning of the first sub-grid encountered when aggregating (as
this future is used internally by the aggregation executor to notice when the
GPU stream it uses becomes idle). However, this is only done once per
aggregated kernel.

The other \lstinline[language=c++]{get_future} call is to
communicate the results of the aggregated kernel. This means that we effectively decrease the number
calls to our HPX-SYCL integration when going beyond a maximum of two aggregated kernels.



\subsection{Performance Tests}
For our first two performance tests, we run Octo-Tiger with the
HPX-SYCL integration turned on (using host tasks for the first test and event polling for the second test), and then run it again with the HPX patch
 that disables the integration altogether for comparison. Afterward, we
look at the performance with and without our experimental Kokkos optimizations
mentioned in Section~\ref{sec:integration:kokkos}. Finally, we take a short
look at how the performance of these Kokkos SYCL runs relate to the same runs
using the Kokkos CUDA/HIP execution spaces and the native
CUDA/HIP kernels still within Octo-Tiger.
\subsubsection{Test 1 - Performance Impact of the Host Task Based HPX-SYCL Integration}

For our first test, we take a look at the \lstinline{host_task} version of our integration
as described in Section~\ref{sec:integration:hosttasks}.  We run the Sedov
Blast Wave scenario with and without the integration turned on. The results can
be found in Figure~\ref{fig:integration-event-polling-host-taks}. As we will do
in the following tests, we usually look at three different configurations: For
the first graph (\ref{fig:integration-host-tasks-a100-1}), the number of HPX worker threads (and thus CPU cores used
by HPX) were fixed to $32$ and the dynamic work aggregation was disabled. We
then increase the number of GPU executors until we reach $128$. This way we can
see the effects of multiple CPU cores trying to use the integration on a
varying number of SYCL command queues (as each GPU executor contains one
underlying \lstinline{in_order} SYCL command queue).

In the second graph (\ref{fig:integration-host-tasks-a100-2}), we use only one GPU executor, but enable the dynamic
work aggregation. This allows the aggregation of up to $64$ kernels into one
larger aggregated GPU kernel. Although, usually the number of kernels being
aggregated into a single kernel ends up being smaller than this maximum number,
as the aggregated kernel is being launched immediately when the executor
becomes idle (even if it has not reached maximum aggregation capacity yet).

Lastly, in the third graph (\ref{fig:integration-host-tasks-a100-3}), we take a look at the best combination of the
previous two parameters that we found ($32$ GPU executors with up to eight
kernels aggregated on the A100). We then run this combination not only with
$32$ HPX worker threads but also try fewer threads. This is usually the most interesting
test, as it not only tests the configuration we are most likely to use in
production runs, but also begins to artificially weaken the CPU performance (by using less
workers), which in turn should make the HPX-SYCL integration more valuable, as
waiting on SYCL results (with the integration turned off) blocks the CPU
threads.
The other three graphs (\ref{fig:integration-host-tasks-mi100-1}, \ref{fig:integration-host-tasks-mi100-2}, \ref{fig:integration-host-tasks-mi100-3}) work accordingly for the MI100 node, showing
the same experiments done for this machine. 
This part of the experiment setup
 will stay the same for the next two tests as well. While we change the software
 configuration for those tests, the parameters we vary stay the same.

Overall, looking at the speedup bars in each of the graphs in test 1, it becomes apparent
that the integration actually significantly decreases performance, most likely
due to the host tasks being handled by different threads internally by the SYCL
runtime.
This can be seen in two ways: We get better (integration) speedups when using less HPX worker threads 
in graphs \ref{fig:integration-host-tasks-a100-3} and \ref{fig:integration-host-tasks-mi100-3} as there is less contention between the HPX worker threads and the threads of the SYCL runtime.
We further see a more severe slowdown in scenarios which rely heavily on the dynamic work aggregation (\ref{fig:integration-host-tasks-a100-2}, \ref{fig:integration-host-tasks-mi100-2}), 
as the CPU has to manage the work aggregation scheduling here as well.
Interestingly, the run with the best combination of GPU executors and work
aggregation on the MI100 (\ref{fig:integration-host-tasks-mi100-3}), performs better than the one on the A100 (\ref{fig:integration-host-tasks-a100-3}) when
the integration is turned on. We plan to investigate this further in future
work. However, even here this integration is not too beneficial: We only see a
benefit when using few HPX worker threads (and thus few cores).
%benefit on low CPU core counts in
%Figure~\ref{fig:integration-host-tasks-a100-3} and \ref{fig:integration-host-tasks-mi100-3}. 
In most
configurations, this \lstinline{host_task} integration is detrimental to the performance.

% Curiously, the run with the best combination of GPU executors and work
% aggregation on the MI100 (f), performs better than the one on the A100 (c) when
% the integration is turned on. We plan to investigate this further in future
% work. However, even there this integration is of no benefit: We only see a
% benefit on low CPU core counts in
% Figure~\ref{fig:integration-event-polling-host-taks}c and f. In the most
% configurations this host\_task integration is detrimental to the performance.
\begin{figure*}[t]%5
\centering
\subfloat[\label{fig:integration-event-polling-a100-1}A100: Increasing Number of GPU executors] {
\centering
  \includegraphics[width=.33\textwidth]{figures/A100_runs/async_speedup_A100_32cores_1agg.pdf}  
}
\hspace*{-0.1cm} 
\subfloat[\label{fig:integration-event-polling-a100-2}A100: Increasing number of kernels aggregated] {
\centering
  \includegraphics[width=.33\textwidth]{figures/A100_runs/async_speedup_A100_32cores_1executors.pdf}  
}
\hspace*{-0.1cm} 
\subfloat[\label{fig:integration-event-polling-a100-3}A100: Best combinations] {
\centering
  \includegraphics[width=.33\textwidth]{figures/A100_runs/async_speedup_A100_32exec_8agg.pdf}  
}
\hfill
\subfloat[\label{fig:integration-event-polling-mi100-1}MI100: Increasing Number of GPU executors] {
\centering
  \includegraphics[width=.33\textwidth]{figures/MI100_runs/async_speedup_MI100_32cores_1agg.pdf}  
}
\hspace*{-0.1cm} 
\subfloat[\label{fig:integration-event-polling-mi100-2}MI100: Increasing number of kernels aggregated] {
\centering
  \includegraphics[width=.33\textwidth]{figures/MI100_runs/async_speedup_MI100_32cores_1executors.pdf}  
}
\hspace*{-0.1cm} 
\subfloat[\label{fig:integration-event-polling-mi100-3}MI100: Best combinations] {
\centering
  \includegraphics[width=.33\textwidth]{figures/MI100_runs/async_speedup_MI100_8exec_32agg.pdf}  
}
\caption{Runs with the SYCL-Integration (event polling version) turned on (orange) and turned off (gray). In \ref{fig:integration-event-polling-a100-1} and \ref{fig:integration-event-polling-mi100-1} we do not use the dynamic work aggregation and instead only increase the number of GPU executors. In \ref{fig:integration-event-polling-a100-2} and \ref{fig:integration-event-polling-mi100-2} we only use one executor, but increase the maximum number of kernels aggregated into one kernel launch. In \ref{fig:integration-event-polling-a100-3} and \ref{fig:integration-event-polling-mi100-3} we see the best combinations. The Kokkos optimization patch is applied to all runs.}
\label{fig:integration-event-polling}
\end{figure*}
\subsubsection{Test 2 - Performance Impact of the Event Polling HPX-SYCL Integration}

\begin{figure*}[t]
\centering
\subfloat[\label{fig:kokkos-patch-a100-1}A100: Increasing Number of GPU executors] {
\centering
  \includegraphics[width=.33\textwidth]{figures/A100_runs/kokkos_patch_speedup_A100_32cores_1agg.pdf}  
}
\hspace*{-0.1cm} 
\subfloat[\label{fig:kokkos-patch-a100-2}A100: Increasing number of kernels aggregated] {
\centering
  \includegraphics[width=.33\textwidth]{figures/A100_runs/kokkos_patch_speedup_A100_32cores_1executors.pdf}  
}
\hspace*{-0.1cm} 
\subfloat[\label{fig:kokkos-patch-a100-3}A100: Best combinations] {
\centering
  \includegraphics[width=.33\textwidth]{figures/A100_runs/kokkos_patch_speedup_A100_32exec_8agg.pdf}  
}
\hfill
\centering
\subfloat[\label{fig:kokkos-patch-mi100-1}MI100: Increasing Number of GPU executors] {
\centering
  \includegraphics[width=.33\textwidth]{figures/MI100_runs/kokkos_patch_speedup_MI100_32cores_1agg.pdf}  
}
\hspace*{-0.1cm} 
\subfloat[\label{fig:kokkos-patch-mi100-2}MI100: Increasing number of kernels aggregated] {
\centering
  \includegraphics[width=.33\textwidth]{figures/MI100_runs/kokkos_patch_speedup_MI100_32cores_1executors.pdf}  
}
\hspace*{-0.1cm} 
\subfloat[\label{fig:kokkos-patch-mi100-3}MI100: Best combinations] {
\centering
  \includegraphics[width=.33\textwidth]{figures/MI100_runs/kokkos_patch_speedup_MI100_8exec_32agg.pdf}  
}

\caption{Runs with the applied Kokkos optimization patch (green) and without the patch (gray). In \ref{fig:kokkos-patch-a100-1} and \ref{fig:kokkos-patch-mi100-1} we do not use the dynamic work aggregation and instead only increase the number GPU executors. In \ref{fig:kokkos-patch-a100-2} and \ref{fig:kokkos-patch-mi100-2} we only use one executor but increase the maximum number of kernels aggregated into one kernel launch. In \ref{fig:kokkos-patch-a100-3} and \ref{fig:kokkos-patch-mi100-3}, we see the best combinations. The HPX-SYCL integration (event polling version) is on for all runs.}
\label{fig:kokkos-patch-a100}
\end{figure*}
Given the disappointing results of the \lstinline{host_task} integration, it is clear that we
need an alternative. The event polling version we implemented does not suffer
from the same drawbacks, as everything is handled by the HPX threads themselves
in a way that is optimized for multi-threaded usage. However, the continuous
polling is adding a different kind of overhead, making it important to also
check this integration by running Octo-Tiger once with it enabled and once
while it is disabled.

Hence, we are now repeating the same tests as in the previous section, but
using the event polling version of our integration. The results can be found in
Figure~\ref{fig:integration-event-polling}. This time, we can achieve clear
speedups, especially for the graphs that only use one GPU executor (\ref{fig:integration-event-polling-a100-2}, \ref{fig:integration-event-polling-mi100-2}) but
with the work aggregation enabled. Here, we benefit from the aggregation the most,
as CPU-time becomes increasingly more valuable as the worker threads are busy
coordinating the work aggregation on top of their other tasks. Even for the
graphs with the best combinations (\ref{fig:integration-event-polling-a100-3}, \ref{fig:integration-event-polling-mi100-3}) we see clear benefits. Slightly more
so when using fewer HPX worker threads, however, even when using all $32$ workers with the best
combination, we see a speedup of $1.11x$ on the A100 node and one of $1.15x$ on
the MI100 node. Note that the best combination on the MI100 node is different
from the A100 one, as we benefit less from concurrent GPU executors on the AMD
GPU, and instead just use $8$ GPU executors with up to $32$ kernels aggregated.
We have seen a similar effect in previous tests using HIP on this machine,
which was one of the original triggers for us to implement the dynamic work
aggregation executor~\cite{daiss2022aggregation}.

\subsubsection{Test 3 - Performance Impact of the Kokkos Modifications}

The last two tests were about the HPX-SYCL integration, but always had the
Kokkos optimization patch applied (both the runs with and without integration).
In this test, we always have the (event polling) HPX-SYCL integration enabled,
but toggle whether we use the Kokkos modification patch. As mentioned, this
patch basically just skips a few barriers in case the Kokkos SYCL execution
space is using an \lstinline{in_order} queue. When using it with Octo-Tiger we did not
notice any deviation in the actual results of our tests. However, it made a
performance impact.
The results can be found in Figure~\ref{fig:kokkos-patch-a100}. The patch is
consistently beneficial, with us reaching speedups of around $1.06$ and $1.12$
for the best combination runs. The speedup on the A100 node without dynamic
work aggregation (\ref{fig:kokkos-patch-a100-1}) stands out. We benefit more from the concurrent GPU
executors on NVIDIA hardware, so keeping them
better fed with kernels (without any blocking) yields a larger advantage.
Overall, applying the patch is beneficial in all tested configurations.

\subsubsection{Test 4 - Performance Using Different Execution Backends}
\begin{figure}[t]
\subfloat[\label{fig:a100-backend}Best runs on the NVIDIA A100] {
\centering
  \includegraphics[width=.23\textwidth]{figures/A100_runs/overview_backend_performance_A100.pdf}  
}
\hspace*{-0.1cm} 
\subfloat[\label{fig:mi100-backend}Best runs on the AMD MI100] {
\centering
  \includegraphics[width=.23\textwidth]{figures/MI100_runs/overview_backend_performance_MI100.pdf}  
}
\caption{Sedov Blast Scenario with Octo-Tiger using all the available backends on both the A100 node (\ref{fig:a100-backend}) and the MI100 node (\ref{fig:mi100-backend}). We used the best combinations for each backend and added CPU-only runs for comparison.}
\label{fig:backend-overview}
\end{figure}
On the A100 node we can now use multiple backends for the kernels: plain CUDA,
Kokkos using the CUDA execution space, and Kokkos using the SYCL execution
space. This warrants a closer look at how these different backends perform
with Octo-Tiger using the same scenario and the same hardware.
The results for this can be found in Figure~\ref{fig:backend-overview} (both
for the A100 and MI100 node). The (event polling) HPX-SYCL integration is ON and the Kokkos
optimization patch is applied. Interestingly, in this scenario, the Kokkos
SYCL backend seems to be competitive compared to its CUDA equivalent. From
what we are able to tell from the profiler output, the average runtime per
kernel is actually better with SYCL. However, we are losing some runtime again
in the overhead, since the HPX-CUDA integration is using an event pool, while
we have to get our SYCL events from the SYCL runtime, resulting in frequent
creation and destruction of these SYCL events. Notably, the Kokkos CUDA
execution space version here is a bit slower than it was in previous work,
where we used Clang 12 instead of DPC\texttt{++}~\cite{daiss2022aggregation}
and an older version of Octo-Tiger which did not yet include the SIMD types
within the Kokkos kernels (which might add a bit of overhead to the GPU
execution).
It is noteworthy, that independent of the GPU backend used, Octo-Tiger performs
better on the A100 GPU than it does on the MI100 one. This shows that the
kernels themselves need more optimization for the AMD GPU.


% \protect\subref{fig:a100-backend}

