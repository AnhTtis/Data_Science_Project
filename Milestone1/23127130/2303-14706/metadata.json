{
    "arxiv_id": "2303.14706",
    "paper_title": "BlobGAN-3D: A Spatially-Disentangled 3D-Aware Generative Model for Indoor Scenes",
    "authors": [
        "Qian Wang",
        "Yiqun Wang",
        "Michael Birsak",
        "Peter Wonka"
    ],
    "submission_date": "2023-03-26",
    "revised_dates": [
        "2023-03-28"
    ],
    "latest_version": 1,
    "categories": [
        "cs.CV"
    ],
    "abstract": "3D-aware image synthesis has attracted increasing interest as it models the 3D nature of our real world. However, performing realistic object-level editing of the generated images in the multi-object scenario still remains a challenge. Recently, a 2D GAN termed BlobGAN has demonstrated great multi-object editing capabilities on real-world indoor scene datasets. In this work, we propose BlobGAN-3D, which is a 3D-aware improvement of the original 2D BlobGAN. We enable explicit camera pose control while maintaining the disentanglement for individual objects in the scene by extending the 2D blobs into 3D blobs. We keep the object-level editing capabilities of BlobGAN and in addition allow flexible control over the 3D location of the objects in the scene. We test our method on real-world indoor datasets and show that our method can achieve comparable image quality compared to the 2D BlobGAN and other 3D-aware GAN baselines while being able to enable camera pose control and object-level editing in the challenging multi-object real-world scenarios.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.14706v1"
    ],
    "publication_venue": null
}