@book{hoffmann1971linear,
  title={Linear algebra},
  author={Hoffmann, Kenneth and Kunze, Ray Alden},
  year={1971},
  publisher={Prentice-Hall New Jersey}
}

@book{rudin1976principles,
  title={Principles of mathematical analysis},
  author={Rudin, Walter},
  volume={3},
  year={1976},
  publisher={McGraw-hill New York}
}


@inproceedings{kairouz2015composition,
  title={The composition theorem for differential privacy},
  author={Kairouz, Peter and Oh, Sewoong and Viswanath, Pramod},
  booktitle={International conference on machine learning},
  pages={1376--1385},
  year={2015},
  organization={PMLR}
}

@inproceedings{mcsherry2007mechanism,
  title={Mechanism design via differential privacy},
  author={McSherry, Frank and Talwar, Kunal},
  booktitle={48th Annual IEEE Symposium on Foundations of Computer Science (FOCS'07)},
  pages={94--103},
  year={2007},
  organization={IEEE}
}

@inproceedings{murtaghvadhan,
  title={The complexity of computing the optimal composition of differential privacy},
  author={Murtagh, Jack and Vadhan, Salil},
  booktitle={Theory of Cryptography Conference},
  pages={157--175},
  year={2015},
  organization={Springer}
}

@inproceedings{bunsteinke,
  title={Concentrated differential privacy: Simplifications, extensions, and lower bounds},
  author={Bun, Mark and Steinke, Thomas},
  booktitle={Theory of Cryptography Conference},
  pages={635--658},
  year={2016},
  organization={Springer}
}

@book{levin2017markov,
  title={Markov chains and mixing times},
  author={Levin, David A and Peres, Yuval},
  volume={107},
  year={2017},
  publisher={American Mathematical Soc.}
}

@article{von1947theory,
  title={Theory of games and economic behavior, 2nd rev},
  author={Von Neumann, John and Morgenstern, Oskar},
  year={1947},
  publisher={Princeton university press}
}

@misc{dwork2016concentrated,
      title={Concentrated Differential Privacy}, 
      author={Cynthia Dwork and Guy N. Rothblum},
      year={2016},
      eprint={1603.01887},
      archivePrefix={arXiv},
      primaryClass={cs.DS}
}
@inproceedings{Andr_s_2013,
	doi = {10.1145/2508859.2516735},
  
	url = {https://doi.org/10.1145%2F2508859.2516735},
  
	year = 2013,
	publisher = {{ACM} Press},
  
	author = {Miguel E. Andr{\'{e}
}s and Nicol{\'{a}}s E. Bordenabe and Konstantinos Chatzikokolakis and Catuscia Palamidessi},
  
	title = {Geo-indistinguishability},
  
	booktitle = {Proceedings of the 2013 {ACM} {SIGSAC} conference on Computer {\&}amp$\mathsemicolon$ communications security - {CCS} {\textquotesingle}13}
}
@misc{boedihardjo2022private,
      title={Private measures, random walks, and synthetic data}, 
      author={March Boedihardjo and Thomas Strohmer and Roman Vershynin},
      year={2022},
      eprint={2204.09167},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

@misc{stock2022defending,
      title={Defending against Reconstruction Attacks with R\'enyi Differential Privacy}, 
      author={Pierre Stock and Igor Shilov and Ilya Mironov and Alexandre Sablayrolles},
      year={2022},
      eprint={2202.07623},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{muthukrishnan2012optimal,
      title={Optimal Private Halfspace Counting via Discrepancy}, 
      author={S. Muthukrishnan and Aleksandar Nikolov},
      year={2012},
      eprint={1203.5453},
      archivePrefix={arXiv},
      primaryClass={cs.DS}
}
@InProceedings{DworkYekhanin,
author="Dwork, Cynthia
and Yekhanin, Sergey",
editor="Wagner, David",
title="New Efficient Attacks on Statistical Disclosure Control Mechanisms",
booktitle="Advances in Cryptology -- CRYPTO 2008",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="469--480",
abstract="The goal of a statistical database is to provide statistics about a population while simultaneously protecting the privacy of the individual records in the database. The tension between privacy and usability of statistical databases has attracted much attention in statistics, theoretical computer science, security, and database communities in recent years. A line of research initiated by Dinur and Nissim investigates for a particular type of queries, lower bounds on the distortion needed in order to prevent gross violations of privacy. The first result in the current paper simplifies and sharpens the Dinur and Nissim result.",
isbn="978-3-540-85174-5"
}
@misc{canonne,
      title={A short note on an inequality between KL and TV}, 
      author={Clément L. Canonne},
      year={2022},
      eprint={2202.07198},
      archivePrefix={arXiv},
      primaryClass={math.PR}
}
@article{exposed,
author = {Dwork, Cynthia and Smith, Adam and Steinke, Thomas and Ullman, Jonathan},
year = {2017},
month = {03},
pages = {},
title = {Exposed! A Survey of Attacks on Private Data},
volume = {4},
journal = {Annual Review of Statistics and Its Application},
doi = {10.1146/annurev-statistics-060116-054123}
}
@misc{nasr2021adversary,
      title={Adversary Instantiation: Lower Bounds for Differentially Private Machine Learning}, 
      author={Milad Nasr and Shuang Song and Abhradeep Thakurta and Nicolas Papernot and Nicholas Carlini},
      year={2021},
      eprint={2101.04535},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inbook {complexityDP,
	title = {The Complexity of Differential Privacy},
	booktitle = {Tutorials on the Foundations of Cryptography},
	year = {2017},
	pages = {347-450},
	publisher = {Springer, Yehuda Lindell, ed.},
	organization = {Springer, Yehuda Lindell, ed.},
	abstract = {
	Version History:\&nbsp;



	August 2016: Manuscript v1 (see files attached)



	March 2017: Manuscript v2 (see files attached); Errata



	April 2017: Published Version (in Tutorials on the Foundations of Cryptography; see Publisher{\textquoteright}s Version link and also SPRINGER 2017.PDF, below)\&nbsp;



	\&nbsp;



	Differential privacy is a theoretical framework for ensuring the privacy of individual-level data when performing statistical analysis of privacy-sensitive datasets. This tutorial provides an introduction to and overview of differential privacy, with the goal of conveying its deep connections to a variety of other topics in computational complexity, cryptography, and theoretical computer science at large. This tutorial is written in celebration of Oded Goldreich{\textquoteright}s 60th birthday, starting from notes taken during a minicourse given by the author and Kunal Talwar at the 26th McGill Invitational Workshop on Computational Complexity [1].



	\&nbsp;

},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-57048-8_7},
	author = {Salil Vadhan}
}

@article{tsybakov2004introduction,
  title={Introduction to nonparametric estimation, 2009},
  author={Tsybakov, Alexandre B},
  journal={URL https://doi. org/10.1007/b13794. Revised and extended from the},
  volume={9},
  number={10},
  year={2004}
}

@book{kearns1994introduction,
  title={An introduction to computational learning theory},
  author={Kearns, Michael J and Vazirani, Umesh},
  year={1994},
  publisher={MIT press}
}
@inproceedings{bobkov2003spectral,
  title={Spectral gap and concentration for some spherically symmetric probability measures},
  author={Bobkov, Sergey G},
  booktitle={Geometric Aspects of Functional Analysis: Israel Seminar 2001-2002},
  pages={37--43},
  year={2003},
  organization={Springer}
}
@article{bobkov1997poincare,
  title={Poincar{\'e}’s inequalities and Talagrand’s concentration phenomenon for the exponential distribution},
  author={Bobkov, Sergey and Ledoux, Michel},
  journal={Probability Theory and Related Fields},
  volume={107},
  pages={383--400},
  year={1997},
  publisher={Springer}
}
@article{aida1994moment,
  title={Moment estimates derived from Poincar{\'e} and logarithmic Sobolev inequalities},
  author={Aida, Shigeki and Stroock, Daniel},
  journal={Mathematical Research Letters},
  volume={1},
  number={1},
  pages={75--86},
  year={1994},
  publisher={International Press of Boston}
}
@article{huang2021poincare,
  title={From Poincar{\'e} inequalities to nonlinear matrix concentration},
  author={Huang, De and Tropp, Joel A},
  year={2021}
}
@misc{garg2020scalar,
      title={Scalar Poincar\'e Implies Matrix Poincar\'e}, 
      author={Ankit Garg and Tarun Kathuria and Nikhil Srivastava},
      year={2020},
      eprint={2006.09567},
      archivePrefix={arXiv},
      primaryClass={math.PR}
}
@article{goldreich1998property,
  title={Property testing and its connection to learning and approximation},
  author={Goldreich, Oded and Goldwasser, Shari and Ron, Dana},
  journal={Journal of the ACM (JACM)},
  volume={45},
  number={4},
  pages={653--750},
  year={1998},
  publisher={ACM New York, NY, USA}
}

@inproceedings{DinurNissim,
author = {Dinur, Irit and Nissim, Kobbi},
title = {Revealing Information While Preserving Privacy},
year = {2003},
isbn = {1581136706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/773153.773173},
doi = {10.1145/773153.773173},
abstract = {We examine the tradeoff between privacy and usability of statistical databases. We model a statistical database by an n-bit string d1,..,dn, with a query being a subset q ⊆ [n] to be answered by Σiεq di. Our main result is a polynomial reconstruction algorithm of data from noisy (perturbed) subset sums. Applying this reconstruction algorithm to statistical databases we show that in order to achieve privacy one has to add perturbation of magnitude (Ω√n). That is, smaller perturbation always results in a strong violation of privacy. We show that this result is tight by exemplifying access algorithms for statistical databases that preserve privacy while adding perturbation of magnitude \~{O}(√n).For time-T bounded adversaries we demonstrate a privacypreserving access algorithm whose perturbation magnitude is ≈ √T.},
booktitle = {Proceedings of the Twenty-Second ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems},
pages = {202–210},
numpages = {9},
keywords = {integrity and security, data reconstruction, subset-sums with noise},
location = {San Diego, California},
series = {PODS '03}
}

@InProceedings{text-processing,
author="Fernandes, Natasha
and Dras, Mark
and McIver, Annabelle",
editor="Nielson, Flemming
and Sands, David",
title="Generalised Differential Privacy for Text Document Processing",
booktitle="Principles of Security and Trust",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="123--148",
abstract="We address the problem of how to ``obfuscate'' texts by removing stylistic clues which can identify authorship, whilst preserving (as much as possible) the content of the text. In this paper we combine ideas from ``generalised differential privacy'' and machine learning techniques for text processing to model privacy for text documents. We define a privacy mechanism that operates at the level of text documents represented as ``bags-of-words''---these representations are typical in machine learning and contain sufficient information to carry out many kinds of classification tasks including topic identification and authorship attribution (of the original documents). We show that our mechanism satisfies privacy with respect to a metric for semantic similarity, thereby providing a balance between utility, defined by the semantic content of texts, with the obfuscation of stylistic clues. We demonstrate our implementation on a ``fan fiction'' dataset, confirming that it is indeed possible to disguise writing style effectively whilst preserving enough information and variation for accurate content classification tasks. We refer the reader to our complete paper [15] which contains full proofs and further experimentation details.",
isbn="978-3-030-17138-4"
}
@conference {rezaAudit,
author = {Reza Shokri},
title = {Auditing Data Privacy for Machine Learning},
year = {2022},
address = {Santa Clara, CA},
publisher = {USENIX Association},
month = feb
}
@misc{mahloujifar2022optimal,
      title={Optimal Membership Inference Bounds for Adaptive Composition of Sampled Gaussian Mechanisms}, 
      author={Saeed Mahloujifar and Alexandre Sablayrolles and Graham Cormode and Somesh Jha},
      year={2022},
      eprint={2204.06106},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}
@misc{salem2023sok,
      title={SoK: Let the Privacy Games Begin! A Unified Treatment of Data Inference Privacy in Machine Learning}, 
      author={Ahmed Salem and Giovanni Cherubin and David Evans and Boris Köpf and Andrew Paverd and Anshuman Suri and Shruti Tople and Santiago Zanella-Béguelin},
      year={2023},
      eprint={2212.10986},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{zhu2019deep,
      title={Deep Leakage from Gradients}, 
      author={Ligeng Zhu and Zhijian Liu and Song Han},
      year={2019},
      eprint={1906.08935},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{rigollet,
title = {High dimensional statistics.},
author = {Rigollet, P. and Hutter, J.-C.},
publisher = {Lecture notes for course 18S997, 813:814, 2015.}
}

@book{LarryNonparametricBook,
author = {Wasserman, Larry},
title = {All of Nonparametric Statistics (Springer Texts in Statistics)},
year = {2006},
isbn = {0387251456},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg}
}


@misc{abadi2016tensorflow,
      title={TensorFlow: A system for large-scale machine learning}, 
      author={Martín Abadi and Paul Barham and Jianmin Chen and Zhifeng Chen and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay Ghemawat and Geoffrey Irving and Michael Isard and Manjunath Kudlur and Josh Levenberg and Rajat Monga and Sherry Moore and Derek G. Murray and Benoit Steiner and Paul Tucker and Vijay Vasudevan and Pete Warden and Martin Wicke and Yuan Yu and Xiaoqiang Zheng},
      year={2016},
      eprint={1605.08695},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}

@article{deng2012mnist,
  title={The mnist database of handwritten digit images for machine learning research},
  author={Deng, Li},
  journal={IEEE Signal Processing Magazine},
  volume={29},
  number={6},
  pages={141--142},
  year={2012},
  publisher={IEEE}
}

@InProceedings{Guo2022,
  title = 	 {Bounding Training Data Reconstruction in Private (Deep) Learning},
  author={Guo, Chuan and Karrer, Brian and Chaudhuri, Kamalika and van der Maaten, Laurens},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {8056--8071},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/guo22c/guo22c.pdf},
  url = 	 {https://proceedings.mlr.press/v162/guo22c.html},
  abstract = 	 {Differential privacy is widely accepted as the de facto method for preventing data leakage in ML, and conventional wisdom suggests that it offers strong protection against privacy attacks. However, existing semantic guarantees for DP focus on membership inference, which may overestimate the adversary’s capabilities and is not applicable when membership status itself is non-sensitive. In this paper, we derive the first semantic guarantees for DP mechanisms against training data reconstruction attacks under a formal threat model. We show that two distinct privacy accounting methods—Renyi differential privacy and Fisher information leakage—both offer strong semantic protection against data reconstruction attacks.}
}

@article{Dwork2017,
author = {Dwork, Cynthia and Roth, Aaron},
title = {The Algorithmic Foundations of Differential Privacy},
year = {2014},
issue_date = {August 2014},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {9},
number = {3–4},
issn = {1551-305X},
url = {https://doi.org/10.1561/0400000042},
doi = {10.1561/0400000042},
abstract = {The problem of privacy-preserving data analysis has a long history spanning multiple disciplines. As electronic data about individuals becomes increasingly detailed, and as technology enables ever more powerful collection and curation of these data, the need increases for a robust, meaningful, and mathematically rigorous definition of privacy, together with a computationally rich class of algorithms that satisfy this definition. Differential Privacy is such a definition.After motivating and discussing the meaning of differential privacy, the preponderance of this monograph is devoted to fundamental techniques for achieving differential privacy, and application of these techniques in creative combinations, using the query-release problem as an ongoing example. A key point is that, by rethinking the computational goal, one can often obtain far better results than would be achieved by methodically replacing each step of a non-private computation with a differentially private implementation. Despite some astonishingly powerful computational results, there are still fundamental limitations — not just on what can be achieved with differential privacy but on what can be achieved with any method that protects against a complete breakdown in privacy. Virtually all the algorithms discussed herein maintain differential privacy against adversaries of arbitrary computational power. Certain algorithms are computationally intensive, others are efficient. Computational complexity for the adversary and the algorithm are both discussed.We then turn from fundamentals to applications other than queryrelease, discussing differentially private methods for mechanism design and machine learning. The vast majority of the literature on differentially private algorithms considers a single, static, database that is subject to many analyses. Differential privacy in other models, including distributed databases and computations on data streams is discussed.Finally, we note that this work is meant as a thorough introduction to the problems and techniques of differential privacy, but is not intended to be an exhaustive survey — there is by now a vast amount of work in differential privacy, and we can cover only a small portion of it.},
journal = {Found. Trends Theor. Comput. Sci.},
month = {aug},
pages = {211–407},
numpages = {197}
}

@inproceedings{Cam1986AsymptoticMI,
  title={Asymptotic Methods In Statistical Decision Theory},
  author={Lucien Le Cam},
  year={1986},
  url={https://api.semanticscholar.org/CorpusID:118432452}
}

@inproceedings{Mironov2017,
author = {Mironov, Ilya},
year = {2017},
month = {08},
pages = {263-275},
title = {Rényi Differential Privacy},
doi = {10.1109/CSF.2017.11}
}

@Inproceedings{Imola2022,
 author = {Jacob Imola and Shiva Kasiviswanathan and Stephen White and Abhinav Aggarwal and Nathanael Teissier},
 title = {Balancing utility and scalability in metric differential privacy},
 year = {2022},
 url = {https://www.amazon.science/publications/balancing-utility-and-\\scalability-in-metric-differential-\\privacy},
 booktitle = {UAI 2022},
}

@inproceedings{Chatzikokolakis2013,
author = {Chatzikokolakis, Kostas and Andrés, Miguel and Bordenabe, Nicolás and Palamidessi, Catuscia},
year = {2013},
month = {07},
pages = {},
title = {Broadening the Scope of Differential Privacy Using Metrics},
isbn = {978-3-642-39076-0},
doi = {10.1007/978-3-642-39077-7_5}
}

@article{Warner-RR,
 ISSN = {01621459},
 URL = {http://www.jstor.org/stable/2283137},
 abstract = {For various reasons individuals in a sample survey may prefer not to confide to the interviewer the correct answers to certain questions. In such cases the individuals may elect not to reply at all or to reply with incorrect answers. The resulting evasive answer bias is ordinarily difficult to assess. In this paper it is argued that such bias is potentially removable through allowing the interviewee to maintain privacy through the device of randomizing his response. A randomized response method for estimating a population proportion is presented as an example. Unbiased maximum likelihood estimates are obtained and their mean square errors of conventional estimates under various assumptions about the underlying population.},
 author = {Stanley L. Warner},
 journal = {Journal of the American Statistical Association},
 number = {309},
 pages = {63--69},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {Randomized Response: A Survey Technique for Eliminating Evasive Answer Bias},
 urldate = {2023-09-25},
 volume = {60},
 year = {1965}
}



@article{Koufogiannis2016, title={Gradual Release of Sensitive Data under Differential Privacy}, volume={7}, url={https://journalprivacyconfidentiality.org/index.php/jpc/article/view/649}, DOI={10.29012/jpc.v7i2.649},
number={2},
journal={Journal of Privacy and Confidentiality},
author={Koufogiannis, Fragkiskos and Han, Shuo and Pappas, George J.},
year={2017},
month={Jan.} }

@misc{Balle2022,
  doi = {10.48550/ARXIV.2201.04845},
  url = {https://arxiv.org/abs/2201.04845},
  author = {Balle, Borja and Cherubin, Giovanni and Hayes, Jamie},
  keywords = {Cryptography and Security (cs.CR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Reconstructing Training Data with Informed Adversaries},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}

@book{Wainwright2019,
place={Cambridge},
series={Cambridge Series in Statistical and Probabilistic Mathematics},
title={High-Dimensional Statistics: A Non-Asymptotic Viewpoint},
DOI={10.1017/9781108627771},
publisher={Cambridge University Press},
author={Wainwright, Martin J.},
year={2019}, collection={Cambridge Series in Statistical and Probabilistic Mathematics}}

@book{Bishop2006,
author = {Bishop, Christopher M.},
title = {Pattern Recognition and Machine Learning (Information Science and Statistics)},
year = {2006},
isbn = {0387310738},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg}
}

@misc{Koufogiannis2015,
  doi = {10.48550/ARXIV.2105.07176},
  
  url = {https://arxiv.org/abs/2105.07176},
  
  author = {Fernandes, Natasha and McIver, Annabelle and Morgan, Carroll},
  
  keywords = {Cryptography and Security (cs.CR), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {The Laplace Mechanism has optimal utility for differential privacy over continuous queries},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{Jie2022,
  doi = {10.48550/ARXIV.2211.07218},
  
  url = {https://arxiv.org/abs/2211.07218},
  
  author = {Fu, Jie and Chen, Zhili and Ling, XinPeng},
  
  keywords = {Cryptography and Security (cs.CR), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {SA-DPSGD: Differentially Private Stochastic Gradient Descent based on Simulated Annealing},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{Abadi2016,
author = {Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H. Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
title = {Deep Learning with Differential Privacy},
year = {2016},
isbn = {9781450341394},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2976749.2978318},
doi = {10.1145/2976749.2978318},
abstract = {Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. Often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information. The models should not expose private information in these datasets. Addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality.},
booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
pages = {308–318},
numpages = {11},
keywords = {differential privacy, deep learning},
location = {Vienna, Austria},
series = {CCS '16}
}

@INPROCEEDINGS{Song2013,
  author={Song, Shuang and Chaudhuri, Kamalika and Sarwate, Anand D.},
  booktitle={2013 IEEE Global Conference on Signal and Information Processing}, 
  title={Stochastic gradient descent with differentially private updates}, 
  year={2013},
  volume={},
  number={},
  pages={245-248},
  doi={10.1109/GlobalSIP.2013.6736861}}

@article{Kasiviswanathan2008,
  doi = {10.48550/ARXIV.0803.0924},
  
  url = {https://arxiv.org/abs/0803.0924},
  
  author = {Kasiviswanathan, Shiva Prasad and Lee, Homin K. and Nissim, Kobbi and Raskhodnikova, Sofya and Smith, Adam},
  
  keywords = {Machine Learning (cs.LG), Computational Complexity (cs.CC), Cryptography and Security (cs.CR), Databases (cs.DB), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {What Can We Learn Privately?},
  
  publisher = {arXiv},
  
  year = {2008},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{Feldman2018,
author = {Feldman, Vitaly and Mironov, Ilya and Talwar, Kunal and Thakurta, Abhradeep},
year = {2018},
month = {10},
pages = {521-532},
title = {Privacy Amplification by Iteration},
doi = {10.1109/FOCS.2018.00056}
}

@misc{Bresler2020,
  doi = {10.48550/ARXIV.2002.00274},
  
  url = {https://arxiv.org/abs/2002.00274},
  
  author = {Bresler, Guy and Nagaraj, Dheeraj},
  
  keywords = {Machine Learning (cs.LG), Statistics Theory (math.ST), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
  
  title = {A Corrective View of Neural Networks: Representation, Memorization and Learning},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{Yeom2018,
author = {Yeom, Samuel and Giacomelli, Irene and Fredrikson, Matt and Jha, Somesh},
year = {2018},
month = {07},
pages = {268-282},
title = {Privacy Risk in Machine Learning: Analyzing the Connection to Overfitting},
doi = {10.1109/CSF.2018.00027}
}

@misc{Tramer2020,
  doi = {10.48550/ARXIV.2011.11660},
  
  url = {https://arxiv.org/abs/2011.11660},
  
  author = {Tramèr, Florian and Boneh, Dan},
  
  keywords = {Machine Learning (cs.LG), Cryptography and Security (cs.CR), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Differentially Private Learning Needs Better Features (or Much More Data)},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@misc{apple-privacy,
title = {Learning With Privacy At Scale},
author = {Apple, Differential Privacy Team},
url = {https://machinelearning.apple.com/research/learning-with-privacy-at-scale}
}

@misc{smartnoise-pdf,
title = {Tracking DP Budget While Handling Basic SQL Queries},
author = {Allen, Joshua and Kulkarni, Janardhan and Thakurta, Abhradeep and Yekhanin, Sergey},
url={https://github.com/opendp/smartnoise-sdk/blob/main/\\sql/docs/papers/DP_SQL_budget.pdf}}

@misc{gpt-3,
  doi = {10.48550/ARXIV.2005.14165},
  
  url = {https://arxiv.org/abs/2005.14165},
  
  author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Language Models are Few-Shot Learners},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{dall-e-model,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}

@article{ohadshamir-memorization,
  title={On the optimal memorization power of ReLU neural networks},
  author={Vardi, Gal and Yehudai, Gilad and Shamir, Ohad},
  journal={arXiv preprint arXiv:2110.03187},
  year={2021}
}

@article{eldan-memorization,
  title={Network size and size of the weights in memorization with two-layers neural networks},
  author={Bubeck, S{\'e}bastien and Eldan, Ronen and Lee, Yin Tat and Mikulincer, Dan},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={4977--4986},
  year={2020}
}

@article{ullman-how-private-is-sgd,
  title={Auditing differentially private machine learning: How private is private sgd?},
  author={Jagielski, Matthew and Ullman, Jonathan and Oprea, Alina},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={22205--22216},
  year={2020}
}

@inproceedings{
gen-framework-auditin,
title={A General Framework for Auditing Differentially Private Machine Learning},
author={Fred Lu and Joseph Munoz and Maya Fuchs and Tyler LeBlond and Elliott V. Zaresky-Williams and Edward Raff and Francis Ferraro and Brian Testa},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=AKM3C3tsSx3}
}

@inproceedings{Kamalika2008,
 author = {Chaudhuri, Kamalika and Monteleoni, Claire},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Koller and D. Schuurmans and Y. Bengio and L. Bottou},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Privacy-preserving logistic regression},
 url = {https://proceedings.neurips.cc/paper/2008/file/8065d07da4a77621450aa84fee5656d9-Paper.pdf},
 volume = {21},
 year = {2008}
}

@misc{Jain2011,
  doi = {10.48550/ARXIV.1109.0105},
  
  url = {https://arxiv.org/abs/1109.0105},
  
  author = {Jain, Prateek and Kothari, Pravesh and Thakurta, Abhradeep},
  
  keywords = {Machine Learning (cs.LG), Cryptography and Security (cs.CR), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Differentially Private Online Learning},
  
  publisher = {arXiv},
  
  year = {2011},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{Kamalika2009,
  doi = {10.48550/ARXIV.0912.0071},
  
  url = {https://arxiv.org/abs/0912.0071},
  
  author = {Chaudhuri, Kamalika and Monteleoni, Claire and Sarwate, Anand D.},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Cryptography and Security (cs.CR), Databases (cs.DB), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Differentially Private Empirical Risk Minimization},
  
  publisher = {arXiv},
  
  year = {2009},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{Alabi2020,
  doi = {10.48550/ARXIV.2007.05157},
  
  url = {https://arxiv.org/abs/2007.05157},
  
  author = {Alabi, Daniel and McMillan, Audra and Sarathy, Jayshree and Smith, Adam and Vadhan, Salil},
  
  keywords = {Machine Learning (cs.LG), Cryptography and Security (cs.CR), Methodology (stat.ME), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Differentially Private Simple Linear Regression},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{Humphries2020,
  title={Differentially Private Learning Does Not Bound Membership Inference},
  author={Thomas Humphries and Matthew Rafuse and Lindsey Tulloch and Simon Oya and Ian Goldberg and Florian Kerschbaum},
  journal={ArXiv},
  year={2020},
  volume={abs/2010.12112}
}

@InProceedings{Bun2016,
author="Bun, Mark
and Steinke, Thomas",
editor="Hirt, Martin
and Smith, Adam",
title="Concentrated Differential Privacy: Simplifications, Extensions, and Lower Bounds",
booktitle="Theory of Cryptography",
year="2016",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="635--658",
abstract="``Concentrated differential privacy'' was recently introduced by Dwork and Rothblum as a relaxation of differential privacy, which permits sharper analyses of many privacy-preserving computations. We present an alternative formulation of the concept of concentrated differential privacy in terms of the R{\'e}nyi divergence between the distributions obtained by running an algorithm on neighboring inputs. With this reformulation in hand, we prove sharper quantitative results, establish lower bounds, and raise a few new questions. We also unify this approach with approximate differential privacy by giving an appropriate definition of ``approximate concentrated differential privacy''.",
isbn="978-3-662-53641-4"
}


@InProceedings{Tsai2022,
  title = 	 { Heavy-tailed Streaming Statistical Estimation },
  author =       {Tsai, Che-Ping and Prasad, Adarsh and Balakrishnan, Sivaraman and Ravikumar, Pradeep},
  booktitle = 	 {Proceedings of The 25th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {1251--1282},
  year = 	 {2022},
  editor = 	 {Camps-Valls, Gustau and Ruiz, Francisco J. R. and Valera, Isabel},
  volume = 	 {151},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {28--30 Mar},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v151/tsai22a/tsai22a.pdf},
  url = 	 {https://proceedings.mlr.press/v151/tsai22a.html},
  abstract = 	 { We consider the task of heavy-tailed statistical estimation given streaming $p$-dimensional samples. This could also be viewed as stochastic optimization under heavy-tailed distributions, with an additional $O(p)$ space complexity constraint. We design a clipped stochastic gradient descent algorithm and provide an improved analysis, under a more nuanced condition on the noise of the stochastic gradients, which we show is critical when analyzing stochastic optimization problems arising from general statistical estimation problems. Our results guarantee convergence not just in expectation but with exponential concentration, and moreover does so using $O(1)$ batch size. We provide consequences of our results for mean estimation and linear regression. Finally, we provide empirical corroboration of our results and algorithms via synthetic experiments for mean estimation and linear regression. }
}

@inproceedings{Chaudhuri2008,
author = {Chaudhuri, Kamalika and Monteleoni, Claire},
title = {Privacy-Preserving Logistic Regression},
year = {2008},
isbn = {9781605609492},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {This paper addresses the important tradeoff between privacy and learnability, when designing algorithms for learning from private databases. We focus on privacy-preserving logistic regression. First we apply an idea of Dwork et al. [6] to design a privacy-preserving logistic regression algorithm. This involves bounding the sensitivity of regularized logistic regression, and perturbing the learned classifier with noise proportional to the sensitivity.We then provide a privacy-preserving regularized logistic regression algorithm based on a new privacy-preserving technique: solving a perturbed optimization problem. We prove that our algorithm preserves privacy in the model due to [6]. We provide learning guarantees for both algorithms, which are tighter for our new algorithm, in cases in which one would typically apply logistic regression. Experiments demonstrate improved learning performance of our method, versus the sensitivity method. Our privacy-preserving technique does not depend on the sensitivity of the function, and extends easily to a class of convex loss functions. Our work also reveals an interesting connection between regularization and privacy.},
booktitle = {Proceedings of the 21st International Conference on Neural Information Processing Systems},
pages = {289–296},
numpages = {8},
location = {Vancouver, British Columbia, Canada},
series = {NIPS'08}
}

@ARTICLE{Lecun1998,
  author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal={Proceedings of the IEEE}, 
  title={Gradient-based learning applied to document recognition}, 
  year={1998},
  volume={86},
  number={11},
  pages={2278-2324},
  doi={10.1109/5.726791}}

@inproceedings{ShadiCISPA,
author = {Rahimian, Shadi and Orekondy, Tribhuvanesh and Fritz, Mario},
title = {Differential Privacy Defenses and Sampling Attacks for Membership Inference},
year = {2021},
isbn = {9781450386579},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474369.3486876},
doi = {10.1145/3474369.3486876},
abstract = {Machine learning models are commonly trained on sensitive and personal data such as pictures, medical records, financial records, etc. A serious breach of the privacy of this training set occurs when an adversary is able to decide whether or not a specific data point in her possession was used to train a model. While all previous membership inference attacks rely on access to the posterior probabilities, we present the first attack which only relies on the predicted class label - yet shows high success rate.},
booktitle = {Proceedings of the 14th ACM Workshop on Artificial Intelligence and Security},
pages = {193–202},
numpages = {10},
keywords = {deep learning, privacy-preserving machine learning, membership inference attacks},
location = {Virtual Event, Republic of Korea},
series = {AISec '21}
}

@misc{Tramer2021,
      title={Differentially Private Learning Needs Better Features (or Much More Data)}, 
      author={Florian Tramèr and Dan Boneh},
      year={2021},
      eprint={2011.11660},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{dwork2006approx,
author = {Dwork, Cynthia and Kenthapadi, Krishnaram and McSherry, Frank and Mironov, Ilya and Naor, Moni},
title = {Our Data, Ourselves: Privacy Via Distributed Noise Generation},
series = {Lecture Notes in Computer Science},
booktitle = {Advances in Cryptology (EUROCRYPT 2006)},
year = {2006},
month = {May},
abstract = {In this work we provide efficient distributed protocols for generating shares of random noise, secure against malicious participants. The purpose of the noise generation is to create a distributed implementation of the privacy-preserving statistical databases described in recent papers [14,4,13]. In these databases, privacy is obtained by perturbing the true answer to a database query by the addition of a small amount of Gaussian or exponentially distributed random noise. The computational power of even a simple form of these databases, when the query is just of the form ∑i f(di), that is, the sum over all rows i in the database of a function f applied to the data in row i, has been demonstrated in [4]. A distributed implementation eliminates the need for a trusted database administrator.

The results for noise generation are of independent interest. The generation of Gaussian noise introduces a technique for distributing shares of many unbiased coins with fewer executions of verifiable secret sharing than would be needed using previous approaches (reduced by a factor of n). The generation of exponentially distributed noise uses two shallow circuits: one for generating many arbitrarily but identically biased coins at an amortized cost of two unbiased random bits apiece, independent of the bias, and the other to combine bits of appropriate biases to obtain an exponential distribution.},
publisher = {Springer Verlag},
url = {https://www.microsoft.com/en-us/research/publication/our-data-ourselves-privacy-via-distributed-noise-generation/},
pages = {486-503},
volume = {4004},
edition = {Advances in Cryptology (EUROCRYPT 2006)},
}

@inproceedings{Radford2019LanguageMA,
  title={Language Models are Unsupervised Multitask Learners},
  author={Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:160025533}
}

@misc{carlini2021extracting,
      title={Extracting Training Data from Large Language Models}, 
      author={Nicholas Carlini and Florian Tramer and Eric Wallace and Matthew Jagielski and Ariel Herbert-Voss and Katherine Lee and Adam Roberts and Tom Brown and Dawn Song and Ulfar Erlingsson and Alina Oprea and Colin Raffel},
      year={2021},
      eprint={2012.07805},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

\begin{comment}
@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}
\end{comment}