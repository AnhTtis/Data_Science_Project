@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{dai2019transformer,
  title={Transformer-xl: Attentive language models beyond a fixed-length context},
  author={Dai, Zihang and Yang, Zhilin and Yang, Yiming and Carbonell, Jaime and Le, Quoc V and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1901.02860},
  year={2019}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{zhang2022opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}

@inproceedings{zhang2022pointclip,
  title={PointCLIP: Point Cloud Understanding by CLIP},
  author={Zhang, Renrui and Guo, Ziyu and Zhang, Wei and Li, Kunchang and Miao, Xupeng and Cui, Bin and Qiao, Yu and Gao, Peng and Li, Hongsheng},
  booktitle={CVPR 2022},
  year={2022}
}

@article{gao2023llama,
  title={Llama-adapter v2: Parameter-efficient visual instruction model},
  author={Gao, Peng and Han, Jiaming and Zhang, Renrui and Lin, Ziyi and Geng, Shijie and Zhou, Aojun and Zhang, Wei and Lu, Pan and He, Conghui and Yue, Xiangyu and others},
  journal={arXiv preprint arXiv:2304.15010},
  year={2023}
}

@article{zhang2023personalize,
  title={Personalize segment anything model with one shot},
  author={Zhang, Renrui and Jiang, Zhengkai and Guo, Ziyu and Yan, Shilin and Pan, Junting and Dong, Hao and Gao, Peng and Li, Hongsheng},
  journal={ICLR 2024},
  year={2023}
}

@article{guo2023point,
  title={Point-bind \& point-llm: Aligning point cloud with multi-modality for 3d understanding, generation, and instruction following},
  author={Guo, Ziyu and Zhang, Renrui and Zhu, Xiangyang and Tang, Yiwen and Ma, Xianzheng and Han, Jiaming and Chen, Kexin and Gao, Peng and Li, Xianzhi and Li, Hongsheng and others},
  journal={arXiv preprint arXiv:2309.00615},
  year={2023}
}

@article{han2023imagebind,
  title={Imagebind-llm: Multi-modality instruction tuning},
  author={Han, Jiaming and Zhang, Renrui and Shao, Wenqi and Gao, Peng and Xu, Peng and Xiao, Han and Zhang, Kaipeng and Liu, Chris and Wen, Song and Guo, Ziyu and others},
  journal={arXiv preprint arXiv:2309.03905},
  year={2023}
}

@article{lin2023sphinx,
  title={Sphinx: The joint mixing of weights, tasks, and visual embeddings for multi-modal large language models},
  author={Lin, Ziyi and Liu, Chris and Zhang, Renrui and Gao, Peng and Qiu, Longtian and Xiao, Han and Qiu, Han and Lin, Chen and Shao, Wenqi and Chen, Keqin and others},
  journal={arXiv preprint arXiv:2311.07575},
  year={2023}
}

@article{gao2024sphinx,
  title={SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models},
  author={Gao, Peng and Zhang, Renrui and Liu, Chris and Qiu, Longtian and Huang, Siyuan and Lin, Weifeng and Zhao, Shitian and Geng, Shijie and Lin, Ziyi and Jin, Peng and others},
  journal={arXiv preprint arXiv:2402.05935},
  year={2024}
}

@article{yang2023lidar,
  title={Lidar-llm: Exploring the potential of large language models for 3d lidar understanding},
  author={Yang, Senqiao and Liu, Jiaming and Zhang, Ray and Pan, Mingjie and Guo, Zoey and Li, Xiaoqi and Chen, Zehui and Gao, Peng and Guo, Yandong and Zhang, Shanghang},
  journal={arXiv preprint arXiv:2312.14074},
  year={2023}
}

@article{zhang2024mathverse,
  title={MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?},
  author={Zhang, Renrui and Jiang, Dongzhi and Zhang, Yichi and Lin, Haokun and Guo, Ziyu and Qiu, Pengshuo and Zhou, Aojun and Lu, Pan and Chang, Kai-Wei and Gao, Peng and others},
  journal={arXiv preprint arXiv:2403.14624},
  year={2024}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

% self instruct
@misc{selfinstruct,
  title={Self-Instruct: Aligning Language Model with Self Generated Instructions},
  author={Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A. and Khashabi, Daniel and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2212.10560},
  year={2022}
}

@inproceedings{cheng2021boundary,
  title={Boundary iou: Improving object-centric image segmentation evaluation},
  author={Cheng, Bowen and Girshick, Ross and Doll{\'a}r, Piotr and Berg, Alexander C and Kirillov, Alexander},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15334--15342},
  year={2021}
}

@article{zhang2022sine,
  title={SINE: SINgle Image Editing with Text-to-Image Diffusion Models},
  author={Zhang, Zhixing and Han, Ligong and Ghosh, Arnab and Metaxas, Dimitris and Ren, Jian},
  journal={arXiv preprint arXiv:2212.04489},
  year={2022}
}

%%%% task-specific vl models
@inproceedings{vinyals2015show,
  title={Show and tell: A neural image caption generator},
  author={Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3156--3164},
  year={2015}
}

@inproceedings{
    he2022towards,
    title={Towards a Unified View of Parameter-Efficient Transfer Learning},
    author={Junxian He and Chunting Zhou and Xuezhe Ma and Taylor Berg-Kirkpatrick and Graham Neubig},
    booktitle={International Conference on Learning Representations},
    year={2022},
    url={https://openreview.net/forum?id=0RDcd5Axok}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10684--10695},
  year={2022}
}


@article{saharia2022photorealistic,
  title={Photorealistic text-to-image diffusion models with deep language understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={36479--36494},
  year={2022}
}

@article{zhang2022collaboration,
  title={Collaboration of Pre-trained Models Makes Better Few-shot Learner},
  author={Zhang, Renrui and Deng, Hanqiu and Li, Bohao and Zhang, Wei and Dong, Hao and Li, Hongsheng and Gao, Peng and Qiao, Yu},
  journal={arXiv preprint arXiv:2209.12255},
  year={2022}
}

@article{bradski2000opencv,
  title={The openCV library.},
  author={Bradski, Gary},
  journal={Dr. Dobb's Journal: Software Tools for the Professional Programmer},
  volume={25},
  number={11},
  pages={120--123},
  year={2000},
  publisher={Miller Freeman Inc.}
}

@article{gan2022decorate,
  title={Decorate the Newcomers: Visual Domain Prompt for Continual Test Time Adaptation},
  author={Gan, Yulu and Ma, Xianzheng and Lou, Yihang and Bai, Yan and Zhang, Renrui and Shi, Nian and Luo, Lin},
  journal={AAAI 2023 Best Student Paper},
  year={2022}
}

@misc{gao2023llamaadapter,
      title={LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model}, 
      author={Peng Gao and Jiaming Han and Renrui Zhang and Ziyi Lin and Shijie Geng and Aojun Zhou and Wei Zhang and Pan Lu and Conghui He and Xiangyu Yue and Hongsheng Li and Yu Qiao},
      year={2023},
      eprint={2304.15010},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{sung2022vl,
  title={Vl-adapter: Parameter-efficient transfer learning for vision-and-language tasks},
  author={Sung, Yi-Lin and Cho, Jaemin and Bansal, Mohit},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5227--5237},
  year={2022}
}

@misc{stable-diffusion-lora,
  author = {Cuenca, Pedro and Paul, Sayak},
  title = {Using LoRA for Efficient Stable Diffusion Fine-Tuning},
  month = {January},
  year = {2023},
  howpublished = {\url{https://huggingface.co/blog/lora}}
}

@inproceedings{karpathy2015deep,
  title={Deep visual-semantic alignments for generating image descriptions},
  author={Karpathy, Andrej and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3128--3137},
  year={2015}
}

@inproceedings{yang2016stacked,
  title={Stacked attention networks for image question answering},
  author={Yang, Zichao and He, Xiaodong and Gao, Jianfeng and Deng, Li and Smola, Alex},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={21--29},
  year={2016}
}

@article{santoro2017simple,
  title={A simple neural network module for relational reasoning},
  author={Santoro, Adam and Raposo, David and Barrett, David G and Malinowski, Mateusz and Pascanu, Razvan and Battaglia, Peter and Lillicrap, Timothy},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


@inproceedings{jiang2020defense,
  title={In defense of grid features for visual question answering},
  author={Jiang, Huaizu and Misra, Ishan and Rohrbach, Marcus and Learned-Miller, Erik and Chen, Xinlei},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10267--10276},
  year={2020}
}

%%% large-scale vl models
@article{wang2021simvlm,
  title={Simvlm: Simple visual language model pretraining with weak supervision},
  author={Wang, Zirui and Yu, Jiahui and Yu, Adams Wei and Dai, Zihang and Tsvetkov, Yulia and Cao, Yuan},
  journal={arXiv preprint arXiv:2108.10904},
  year={2021}
}

@article{bao2022vlmo,
  title={Vlmo: Unified vision-language pre-training with mixture-of-modality-experts},
  author={Bao, Hangbo and Wang, Wenhui and Dong, Li and Liu, Qiang and Mohammed, Owais Khan and Aggarwal, Kriti and Som, Subhojit and Piao, Songhao and Wei, Furu},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={32897--32912},
  year={2022}
}

@inproceedings{wang2022ofa,
  title={Ofa: Unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning framework},
  author={Wang, Peng and Yang, An and Men, Rui and Lin, Junyang and Bai, Shuai and Li, Zhikang and Ma, Jianxin and Zhou, Chang and Zhou, Jingren and Yang, Hongxia},
  booktitle={International Conference on Machine Learning},
  pages={23318--23340},
  year={2022},
  organization={PMLR}
}

@inproceedings{mathew2021docvqa,
  title={Docvqa: A dataset for vqa on document images},
  author={Mathew, Minesh and Karatzas, Dimosthenis and Jawahar, CV},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={2200--2209},
  year={2021}
}

@article{lei2018tvqa,
  title={Tvqa: Localized, compositional video question answering},
  author={Lei, Jie and Yu, Licheng and Bansal, Mohit and Berg, Tamara L},
  journal={arXiv preprint arXiv:1809.01696},
  year={2018}
}

@inproceedings{goyal2017making,
  title={Making the v in vqa matter: Elevating the role of image understanding in visual question answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6904--6913},
  year={2017}
}

@article{lin2022retrieval,
  title={Retrieval Augmented Visual Question Answering with Outside Knowledge},
  author={Lin, Weizhe and Byrne, Bill},
  journal={arXiv preprint arXiv:2210.03809},
  year={2022}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@article{wang2022git,
  title={Git: A generative image-to-text transformer for vision and language},
  author={Wang, Jianfeng and Yang, Zhengyuan and Hu, Xiaowei and Li, Linjie and Lin, Kevin and Gan, Zhe and Liu, Zicheng and Liu, Ce and Wang, Lijuan},
  journal={arXiv preprint arXiv:2205.14100},
  year={2022}
}

@article{wang2022image,
  title={Image as a foreign language: Beit pretraining for all vision and vision-language tasks},
  author={Wang, Wenhui and Bao, Hangbo and Dong, Li and Bjorck, Johan and Peng, Zhiliang and Liu, Qiang and Aggarwal, Kriti and Mohammed, Owais Khan and Singhal, Saksham and Som, Subhojit and others},
  journal={arXiv preprint arXiv:2208.10442},
  year={2022}
}

@article{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  journal={arXiv preprint arXiv:2301.12597},
  year={2023}
}

%%% most related
@inproceedings{zhai2022lit,
  title={Lit: Zero-shot transfer with locked-image text tuning},
  author={Zhai, Xiaohua and Wang, Xiao and Mustafa, Basil and Steiner, Andreas and Keysers, Daniel and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18123--18133},
  year={2022}
}

@article{tsimpoukelli2021multimodal,
  title={Multimodal few-shot learning with frozen language models},
  author={Tsimpoukelli, Maria and Menick, Jacob L and Cabi, Serkan and Eslami, SM and Vinyals, Oriol and Hill, Felix},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={200--212},
  year={2021}
}

@article{mokady2021clipcap,
  title={Clipcap: Clip prefix for image captioning},
  author={Mokady, Ron and Hertz, Amir and Bermano, Amit H},
  journal={arXiv preprint arXiv:2111.09734},
  year={2021}
}


% MM-COT
@article{zhang2023multicot,
  title={Multimodal Chain-of-Thought Reasoning in Language Models},
  author={Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Zhao, Hai and Karypis, George and Smola, Alex},
  journal={arXiv preprint arXiv:2302.00923},
  year={2023}
}

% IconQA
@inproceedings{lu2021iconqa,
  title = {IconQA: A New Benchmark for Abstract Diagram Understanding and Visual Language Reasoning},
  author = {Lu, Pan and Qiu, Liang and Chen, Jiaqi and Xia, Tony and Zhao, Yizhou and Zhang, Wei and Yu, Zhou and Liang, Xiaodan and Zhu, Song-Chun},
  booktitle = {The 35th Conference on Neural Information Processing Systems (NeurIPS) Track on Datasets and Benchmarks},
  year = {2021}
}

% UnifiedQA
@inproceedings{khashabi2020unifiedqa,
  title={UNIFIEDQA: Crossing Format Boundaries with a Single QA System},
  author={Khashabi, Daniel and Min, Sewon and Khot, Tushar and Sabharwal, Ashish and Tafjord, Oyvind and Clark, Peter and Hajishirzi, Hannaneh},
  booktitle={Findings of the Association for Computational Linguistics (EMNLP)},
  pages={1896--1907},
  year={2020}
}

% GPT-3
@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

% GPT-4
@article{OpenAI2023GPT4TR,
  title={GPT-4 Technical Report},
  author={OpenAI},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.08774}
}

@article{wei2021finetuned,
  title={Finetuned language models are zero-shot learners},
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent Y and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  journal={arXiv preprint arXiv:2109.01652},
  year={2021}
}

@inproceedings{lu2018rvqa,
  title={R-VQA: learning visual relation facts with semantic attention for visual question answering},
  author={Lu, Pan and Ji, Lei and Zhang, Wei and Duan, Nan and Zhou, Ming and Wang, Jianyong},
  booktitle={The ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (SIGKDD)},
  pages={1880--1889},
  year={2018}
}

% Bottom-up attention
@inproceedings{Anderson2017up,
  author = {Peter Anderson and Xiaodong He and Chris Buehler and Damien Teney and Mark Johnson and Stephen Gould and Lei Zhang},
  title = {Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2018}
}

% Co-attention
@inproceedings{lu2018co,
  title={Co-attending free-form regions and detections with multi-modal multiplicative feature embedding for visual question answering},
  author={Lu, Pan and Li, Hongsheng and Zhang, Wei and Wang, Jianyong and Wang, Xiaogang},
  booktitle={The AAAI Conference on Artificial Intelligence (AAAI)},
  year={2018}
}

% BAN
@inproceedings{Kim2018,
author = {Kim, Jin-Hwa and Jun, Jaehyun and Zhang, Byoung-Tak},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
title = {Bilinear Attention Networks},
pages = {1571--1581},
year = {2018}
}

% MCAN
@inProceedings{yu2019mcan,
  author = {Yu, Zhou and Yu, Jun and Cui, Yuhao and Tao, Dacheng and Tian, Qi},
  title = {Deep Modular Co-Attention Networks for Visual Question Answering},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {6281--6290},
  year = {2019}
}

% DAFA
@inproceedings{gao2019dynamic,
  title={Dynamic Fusion With Intra-and Inter-Modality Attention Flow for Visual Question Answering},
  author={Gao, Peng and Jiang, Zhengkai and You, Haoxuan and Lu, Pan and Hoi, Steven CH and Wang, Xiaogang and Li, Hongsheng},
  booktitle={The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={6639--6648},
  year={2019}
}

% Hybrid
@inproceedings{gao2018question,
  title={Question-guided hybrid convolution for visual question answering},
  author={Gao, Peng and Li, Hongsheng and Li, Shuang and Lu, Pan and Li, Yikang and Hoi, Steven CH and Wang, Xiaogang},
  booktitle={European Conference on Computer Vision},
  pages={469--485},
  year={2018}
}

% ViLBERT
@inproceedings{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={13--23},
  year={2019}
}

% visualbert
@article{li2019visualbert,
  title={Visualbert: A simple and performant baseline for vision and language},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1908.03557},
  year={2019}
}

% visualbert
@inproceedings{li2020does,
  title={What does bert with vision look at?},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL)},
  pages={5265--5275},
  year={2020}
}

%ViLT
@InProceedings{pmlr-v139-kim21k,
  title = {ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision},
  author = {Kim, Wonjae and Son, Bokyung and Kim, Ildoo},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning (ICML)},
  pages = {5583--5594},
  year = {2021},
}

@inproceedings{scienceqa,
    title={Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering},
    author={Lu, Pan and Mishra, Swaroop and Xia, Tony and Qiu, Liang and Chang, Kai-Wei and Zhu, Song-Chun and Tafjord, Oyvind and Clark, Peter and Ashwin Kalyan},
    booktitle={The 36th Conference on Neural Information Processing Systems (NeurIPS)},
    year={2022}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International Conference on Machine Learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}
@article{Shridhar2019ALFREDAB,
  title={ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks},
  author={Mohit Shridhar and Jesse Thomason and Daniel Gordon and Yonatan Bisk and Winson Han and Roozbeh Mottaghi and Luke Zettlemoyer and Dieter Fox},
  journal={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019},
  pages={10737-10746}
}

@article{Min2021FILMFI,
  title={FILM: Following Instructions in Language with Modular Methods},
  author={So Yeon Min and Devendra Singh Chaplot and Pradeep Ravikumar and Yonatan Bisk and Ruslan Salakhutdinov},
  journal={ArXiv},
  year={2021},
  volume={abs/2110.07342}
}

@article{pfeiffer2020adapterfusion,
  title={AdapterFusion: Non-destructive task composition for transfer learning},
  author={Pfeiffer, Jonas and Kamath, Aishwarya and R{\"u}ckl{\'e}, Andreas and Cho, Kyunghyun and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2005.00247},
  year={2020}
}

@article{lester2021power,
  title={The power of scale for parameter-efficient prompt tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  journal={arXiv preprint arXiv:2104.08691},
  year={2021}
}

@article{karimi2021compacter,
  title={Compacter: Efficient low-rank hypercomplex adapter layers},
  author={Karimi Mahabadi, Rabeeh and Henderson, James and Ruder, Sebastian},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={1022--1035},
  year={2021}
}

@inproceedings{wang2022super,
  title={Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks},
  author={Wang, Yizhong and Mishra, Swaroop and Alipoormolabashi, Pegah and Kordi, Yeganeh and Mirzaei, Amirreza and Naik, Atharva and Ashok, Arjun and Dhanasekaran, Arut Selvan and Arunkumar, Anjana and Stap, David and others},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={5085--5109},
  year={2022}
}

@article{bach2022promptsource,
  title={Promptsource: An integrated development environment and repository for natural language prompts},
  author={Bach, Stephen H and Sanh, Victor and Yong, Zheng-Xin and Webson, Albert and Raffel, Colin and Nayak, Nihal V and Sharma, Abheesht and Kim, Taewoon and Bari, M Saiful and Fevry, Thibault and others},
  journal={arXiv preprint arXiv:2202.01279},
  year={2022}
}


@article{touvron2023llama,
  title={LLaMA: Open and Efficient Foundation Language Models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={arXiv preprint arXiv:2203.02155},
  year={2022}
}

@Misc{peft,
  title =        {PEFT: State-of-the-art Parameter-Efficient Fine-Tuning methods},
  author =       {Sourab Mangrulkar; Sylvain Gugger; Lysandre Debut; Younes Belkada; Sayak Paul},
  howpublished = {\url{https://github.com/huggingface/peft}},
  year =         {2022}
}

@article{li2021prefix,
  title={Prefix-tuning: Optimizing continuous prompts for generation},
  author={Li, Xiang Lisa and Liang, Percy},
  journal={arXiv preprint arXiv:2101.00190},
  year={2021}
}

@article{lin2020exploring,
  title={Exploring versatile generative language model via parameter-efficient transfer learning},
  author={Lin, Zhaojiang and Madotto, Andrea and Fung, Pascale},
  journal={arXiv preprint arXiv:2004.03829},
  year={2020}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}


@inproceedings{qi2017pointnet,
  title={Pointnet: Deep learning on point sets for 3d classification and segmentation},
  author={Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={652--660},
  year={2017}
}
@inproceedings{zhang2022pointclip,
  title={Pointclip: Point cloud understanding by clip},
  author={Zhang, Renrui and Guo, Ziyu and Zhang, Wei and Li, Kunchang and Miao, Xupeng and Cui, Bin and Qiao, Yu and Gao, Peng and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8552--8562},
  year={2022}
}
@inproceedings{shi2020pv,
  title={Pv-rcnn: Point-voxel feature set abstraction for 3d object detection},
  author={Shi, Shaoshuai and Guo, Chaoxu and Jiang, Li and Wang, Zhe and Shi, Jianping and Wang, Xiaogang and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10529--10538},
  year={2020}
}
@inproceedings{liu2020closer,
  title={A closer look at local aggregation operators in point cloud analysis},
  author={Liu, Ze and Hu, Han and Cao, Yue and Zhang, Zheng and Tong, Xin},
  booktitle={European Conference on Computer Vision},
  pages={326--342},
  year={2020},
  organization={Springer}
}
@article{xue2022ulip,
  title={ULIP: Learning Unified Representation of Language, Image and Point Cloud for 3D Understanding},
  author={Xue, Le and Gao, Mingfei and Xing, Chen and Mart{\'\i}n-Mart{\'\i}n, Roberto and Wu, Jiajun and Xiong, Caiming and Xu, Ran and Niebles, Juan Carlos and Savarese, Silvio},
  journal={arXiv preprint arXiv:2212.05171},
  year={2022}
}
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}
@article{huang2022clip2point,
  title={Clip2point: Transfer clip to point cloud classification with image-depth pre-training},
  author={Huang, Tianyu and Dong, Bowen and Yang, Yunhan and Huang, Xiaoshui and Lau, Rynson WH and Ouyang, Wanli and Zuo, Wangmeng},
  journal={arXiv preprint arXiv:2210.01055},
  year={2022}
}
@article{wu2022eda,
  title={EDA: Explicit Text-Decoupling and Dense Alignment for 3D Visual and Language Learning},
  author={Wu, Yanmin and Cheng, Xinhua and Zhang, Renrui and Cheng, Zesen and Zhang, Jian},
  journal={arXiv preprint arXiv:2209.14941},
  year={2022}
}
@article{guo2022calip,
  title={Calip: Zero-shot enhancement of clip with parameter-free attention},
  author={Guo, Ziyu and Zhang, Renrui and Qiu, Longtian and Ma, Xianzheng and Miao, Xupeng and He, Xuming and Cui, Bin},
  journal={arXiv preprint arXiv:2209.14169},
  year={2022}
}

@article{guo2023joint,
  title={Joint-MAE: 2D-3D Joint Masked Autoencoders for 3D Point Cloud Pre-training},
  author={Guo, Ziyu and Li, Xianzhi and Heng, Pheng Ann},
  journal={arXiv preprint arXiv:2302.14007},
  year={2023}
}
@article{zhang2022learning,
  title={Learning 3D Representations from 2D Pre-trained Models via Image-to-Point Masked Autoencoders},
  author={Zhang, Renrui and Wang, Liuhui and Qiao, Yu and Gao, Peng and Li, Hongsheng},
  journal={arXiv preprint arXiv:2212.06785},
  year={2022}
}
@article{zhang2021dspoint,
  title={DSPoint: Dual-scale point cloud recognition with high-frequency fusion},
  author={Zhang, Renrui and Zeng, Ziyao and Guo, Ziyu and Gao, Xinben and Fu, Kexue and Shi, Jianbo},
  journal={arXiv preprint arXiv:2111.10332},
  year={2021}
}
@article{zhu2022pointclip,
  title={PointCLIP V2: Adapting CLIP for Powerful 3D Open-world Learning},
  author={Zhu, Xiangyang and Zhang, Renrui and He, Bowei and Zeng, Ziyao and Zhang, Shanghang and Gao, Peng},
  journal={arXiv preprint arXiv:2211.11682},
  year={2022}
}
@inproceedings{tatarchenko2018tangent,
  title={Tangent convolutions for dense prediction in 3d},
  author={Tatarchenko, Maxim and Park, Jaesik and Koltun, Vladlen and Zhou, Qian-Yi},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3887--3896},
  year={2018}
}
@inproceedings{yang2018foldingnet,
  title={Foldingnet: Point cloud auto-encoder via deep grid deformation},
  author={Yang, Yaoqing and Feng, Chen and Shen, Yiru and Tian, Dong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={206--215},
  year={2018}
}
@inproceedings{zhang2023nearest,
  title={Nearest Neighbors Meet Deep Neural Networks for Point Cloud Analysis},
  author={Zhang, Renrui and Wang, Liuhui and Guo, Ziyu and Shi, Jianbo},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={1246--1255},
  year={2023}
}
@inproceedings{xu2021learning,
  title={Learning geometry-disentangled representation for complementary understanding of 3d object point cloud},
  author={Xu, Mutian and Zhang, Junhao and Zhou, Zhipeng and Xu, Mingye and Qi, Xiaojuan and Qiao, Yu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={4},
  pages={3056--3064},
  year={2021}
}
@inproceedings{riegler2017octnet,
  title={Octnet: Learning deep 3d representations at high resolutions},
  author={Riegler, Gernot and Osman Ulusoy, Ali and Geiger, Andreas},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3577--3586},
  year={2017}
}
@article{qi2017pointnet++,
  title={Pointnet++: Deep hierarchical feature learning on point sets in a metric space},
  author={Qi, Charles R and Yi, Li and Su, Hao and Guibas, Leonidas J},
  journal={arXiv preprint arXiv:1706.02413},
  year={2017}
}
@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}
@inproceedings{su2015multi,
  title={Multi-view convolutional neural networks for 3d shape recognition},
  author={Su, Hang and Maji, Subhransu and Kalogerakis, Evangelos and Learned-Miller, Erik},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={945--953},
  year={2015}
}
@inproceedings{gehring2017convolutional,
  title={Convolutional sequence to sequence learning},
  author={Gehring, Jonas and Auli, Michael and Grangier, David and Yarats, Denis and Dauphin, Yann N},
  booktitle={International conference on machine learning},
  pages={1243--1252},
  year={2017},
  organization={PMLR}
}
@article{gao2021clip,
  title={Clip-adapter: Better vision-language models with feature adapters},
  author={Gao, Peng and Geng, Shijie and Zhang, Renrui and Ma, Teli and Fang, Rongyao and Zhang, Yongfeng and Li, Hongsheng and Qiao, Yu},
  journal={arXiv preprint arXiv:2110.04544},
  year={2021}
}
@article{zhou2022learning,
  title={Learning to prompt for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  journal={International Journal of Computer Vision},
  volume={130},
  number={9},
  pages={2337--2348},
  year={2022},
  publisher={Springer}
}
@inproceedings{chen2023revisiting,
  title={Revisiting Multimodal Representation in Contrastive Learning: from Patch and Token Embeddings to Finite Discrete Tokens},
  author={Chen, Yuxiao and Yuan, Jianbo and Tian, Yu and Geng, Shijie and Li, Xinyu and Zhou, Ding and Metaxas, Dimitris N. and Yang, Hongxia},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2023}
}
@inproceedings{lin2022frozen,
  title={Frozen clip models are efficient video learners},
  author={Lin, Ziyi and Geng, Shijie and Zhang, Renrui and Gao, Peng and de Melo, Gerard and Wang, Xiaogang and Dai, Jifeng and Qiao, Yu and Li, Hongsheng},
  booktitle={European Conference on Computer Vision},
  pages={388--404},
  year={2022},
  organization={Springer}
}
@inproceedings{
geng2023hiclip,
title={Hi{CLIP}: Contrastive Language-Image Pretraining with Hierarchy-aware Attention},
author={Shijie Geng and Jianbo Yuan and Yu Tian and Yuxiao Chen and Yongfeng Zhang},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=0eTTKOOOQkV}
}
@article{zhang2022monodetr,
  title={Monodetr: Depth-aware transformer for monocular 3d object detection},
  author={Zhang, Renrui and Qiu, Han and Wang, Tai and Xu, Xuanzhuo and Guo, Ziyu and Qiao, Yu and Gao, Peng and Li, Hongsheng},
  journal={arXiv preprint arXiv:2203.13310},
  year={2022}
}
@inproceedings{zhang2022can,
  title={Can Language Understand Depth?},
  author={Zhang, Renrui and Zeng, Ziyao and Guo, Ziyu and Li, Yafeng},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={6868--6874},
  year={2022}
}
@article{huang2022tig,
  title={TiG-BEV: Multi-view BEV 3D Object Detection via Target Inner-Geometry Learning},
  author={Huang, Peixiang and Liu, Li and Zhang, Renrui and Zhang, Song and Xu, Xinli and Wang, Baichao and Liu, Guoyi},
  journal={arXiv preprint arXiv:2212.13979},
  year={2022}
}
@article{zhang2023prompt,
  title={Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong Few-shot Learners},
  author={Zhang, Renrui and Hu, Xiangfei and Li, Bohao and Huang, Siyuan and Deng, Hanqiu and Li, Hongsheng and Qiao, Yu and Gao, Peng},
  journal={arXiv preprint arXiv:2303.02151},
  year={2023}
}
@article{chu2021conditional,
  title={Conditional positional encodings for vision transformers},
  author={Chu, Xiangxiang and Tian, Zhi and Zhang, Bo and Wang, Xinlong and Wei, Xiaolin and Xia, Huaxia and Shen, Chunhua},
  journal={arXiv preprint arXiv:2102.10882},
  year={2021}
}
@article{tancik2020fourier,
  title={Fourier features let networks learn high frequency functions in low dimensional domains},
  author={Tancik, Matthew and Srinivasan, Pratul and Mildenhall, Ben and Fridovich-Keil, Sara and Raghavan, Nithin and Singhal, Utkarsh and Ramamoorthi, Ravi and Barron, Jonathan and Ng, Ren},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7537--7547},
  year={2020}
}
@article{zhang2022point,
  title={Point-M2AE: Multi-scale Masked Autoencoders for Hierarchical Point Cloud Pre-training},
  author={Zhang, Renrui and Guo, Ziyu and Gao, Peng and Fang, Rongyao and Zhao, Bin and Wang, Dong and Qiao, Yu and Li, Hongsheng},
  journal={arXiv preprint arXiv:2205.14401},
  year={2022}
}
@inproceedings{rahaman2019spectral,
  title={On the spectral bias of neural networks},
  author={Rahaman, Nasim and Baratin, Aristide and Arpit, Devansh and Draxler, Felix and Lin, Min and Hamprecht, Fred and Bengio, Yoshua and Courville, Aaron},
  booktitle={International Conference on Machine Learning},
  pages={5301--5310},
  year={2019},
  organization={PMLR}
}
@article{mildenhall2021nerf,
  title={Nerf: Representing scenes as neural radiance fields for view synthesis},
  author={Mildenhall, Ben and Srinivasan, Pratul P and Tancik, Matthew and Barron, Jonathan T and Ramamoorthi, Ravi and Ng, Ren},
  journal={Communications of the ACM},
  volume={65},
  number={1},
  pages={99--106},
  year={2021},
  publisher={ACM New York, NY, USA}
}
@article{qian2022pointnext,
  title={PointNeXt: Revisiting PointNet++ with Improved Training and Scaling Strategies},
  author={Qian, Guocheng and Li, Yuchen and Peng, Houwen and Mai, Jinjie and Hammoud, Hasan Abed Al Kader and Elhoseiny, Mohamed and Ghanem, Bernard},
  journal={arXiv preprint arXiv:2206.04670},
  year={2022}
}
@inproceedings{wu2019pointconv,
  title={Pointconv: Deep convolutional networks on 3d point clouds},
  author={Wu, Wenxuan and Qi, Zhongang and Fuxin, Li},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9621--9630},
  year={2019}
}
@article{hermosilla2018monte,
  title={Monte carlo convolution for learning on non-uniformly sampled point clouds},
  author={Hermosilla, Pedro and Ritschel, Tobias and V{\'a}zquez, Pere-Pau and Vinacua, {\`A}lvar and Ropinski, Timo},
  journal={ACM Transactions on Graphics (TOG)},
  volume={37},
  number={6},
  pages={1--12},
  year={2018},
  publisher={ACM New York, NY, USA}
}
@inproceedings{zhao2019pointweb,
  title={Pointweb: Enhancing local neighborhood features for point cloud processing},
  author={Zhao, Hengshuang and Jiang, Li and Fu, Chi-Wing and Jia, Jiaya},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5565--5573},
  year={2019}
}
@inproceedings{landrieu2018large,
  title={Large-scale point cloud semantic segmentation with superpoint graphs},
  author={Landrieu, Loic and Simonovsky, Martin},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4558--4567},
  year={2018}
}
@inproceedings{te2018rgcnn,
  title={Rgcnn: Regularized graph cnn for point cloud segmentation},
  author={Te, Gusi and Hu, Wei and Zheng, Amin and Guo, Zongming},
  booktitle={Proceedings of the 26th ACM international conference on Multimedia},
  pages={746--754},
  year={2018}
}
@article{krizhevsky2017imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Communications of the ACM},
  volume={60},
  number={6},
  pages={84--90},
  year={2017},
  publisher={AcM New York, NY, USA}
}
@inproceedings{hamdi2021mvtn,
  title={Mvtn: Multi-view transformation network for 3d shape recognition},
  author={Hamdi, Abdullah and Giancola, Silvio and Ghanem, Bernard},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1--11},
  year={2021}
}
@inproceedings{zhao2021point,
  title={Point transformer},
  author={Zhao, Hengshuang and Jiang, Li and Jia, Jiaya and Torr, Philip HS and Koltun, Vladlen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={16259--16268},
  year={2021}
}
@inproceedings{lai2022stratified,
  title={Stratified Transformer for 3D Point Cloud Segmentation},
  author={Lai, Xin and Liu, Jianhui and Jiang, Li and Wang, Liwei and Zhao, Hengshuang and Liu, Shu and Qi, Xiaojuan and Jia, Jiaya},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8500--8509},
  year={2022}
}
@inproceedings{duan2019structural,
  title={Structural relational reasoning of point clouds},
  author={Duan, Yueqi and Zheng, Yu and Lu, Jiwen and Zhou, Jie and Tian, Qi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={949--958},
  year={2019}
}
@inproceedings{Radford2018ImprovingLU,
  title={Improving Language Understanding by Generative Pre-Training},
  author={Alec Radford and Karthik Narasimhan},
  year={2018}
}
@article{dgcnn,
  title={Dynamic graph cnn for learning on point clouds},
  author={Wang, Yue and Sun, Yongbin and Liu, Ziwei and Sarma, Sanjay E and Bronstein, Michael M and Solomon, Justin M},
  journal={Acm Transactions On Graphics (tog)},
  volume={38},
  number={5},
  pages={1--12},
  year={2019},
  publisher={ACM New York, NY, USA}
}
@inproceedings{rscnn,
  title={Relation-shape convolutional neural network for point cloud analysis},
  author={Liu, Yongcheng and Fan, Bin and Xiang, Shiming and Pan, Chunhong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8895--8904},
  year={2019}
}
@article{guo2021pct,
  title={PCT: Point cloud transformer},
  author={Guo, Meng-Hao and Cai, Jun-Xiong and Liu, Zheng-Ning and Mu, Tai-Jiang and Martin, Ralph R and Hu, Shi-Min},
  journal={Computational Visual Media},
  volume={7},
  number={2},
  pages={187--199},
  year={2021},
  publisher={Springer}
}

@article{curvenet,
  title={Walk in the Cloud: Learning Curves for Point Clouds Shape Analysis},
  author={Xiang, Tiange and Zhang, Chaoyi and Song, Yang and Yu, Jianhui and Cai, Weidong},
  journal={arXiv preprint arXiv:2105.01288},
  year={2021}
}
@inproceedings{densepoint,
  title={Densepoint: Learning densely contextual representation for efficient point cloud processing},
  author={Liu, Yongcheng and Fan, Bin and Meng, Gaofeng and Lu, Jiwen and Xiang, Shiming and Pan, Chunhong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5239--5248},
  year={2019}
}
@inproceedings{modelnet40,
  title={3d shapenets: A deep representation for volumetric shapes},
  author={Wu, Zhirong and Song, Shuran and Khosla, Aditya and Yu, Fisher and Zhang, Linguang and Tang, Xiaoou and Xiao, Jianxiong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1912--1920},
  year={2015}
}

@article{shapenetpart,
  title={A scalable active framework for region annotation in 3d shape collections},
  author={Yi, Li and Kim, Vladimir G and Ceylan, Duygu and Shen, I-Chao and Yan, Mengyan and Su, Hao and Lu, Cewu and Huang, Qixing and Sheffer, Alla and Guibas, Leonidas},
  journal={ACM Transactions on Graphics (ToG)},
  volume={35},
  number={6},
  pages={1--12},
  year={2016},
  publisher={ACM New York, NY, USA}
}
@inproceedings{transformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}
@inproceedings{scanobjectnn,
  title={Revisiting point cloud classification: A new benchmark dataset and classification model on real-world data},
  author={Uy, Mikaela Angelina and Pham, Quang-Hieu and Hua, Binh-Son and Nguyen, Thanh and Yeung, Sai-Kit},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1588--1597},
  year={2019}
}
@InProceedings{3detr,
    author    = {Misra, Ishan and Girdhar, Rohit and Joulin, Armand},
    title     = {An End-to-End Transformer Model for 3D Object Detection},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {2906-2917}
}
@inproceedings{votenet,
  title={VoteNet: A deep learning label fusion method for multi-atlas segmentation},
  author={Ding, Zhipeng and Han, Xu and Niethammer, Marc},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={202--210},
  year={2019},
  organization={Springer}
}
@inproceedings{ScanNetV2,
  title={Scannet: Richly-annotated 3d reconstructions of indoor scenes},
  author={Dai, Angela and Chang, Angel X and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Nie{\ss}ner, Matthias},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5828--5839},
  year={2017}
}
@inproceedings{sun_rgb,
  title={Sun rgb-d: A rgb-d scene understanding benchmark suite},
  author={Song, Shuran and Lichtenberg, Samuel P and Xiao, Jianxiong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={567--576},
  year={2015}
}
@article{3dmfv,
  title={3dmfv: Three-dimensional point cloud classification in real-time using convolutional neural networks},
  author={Ben-Shabat, Yizhak and Lindenbaum, Michael and Fischer, Anath},
  journal={IEEE Robotics and Automation Letters},
  volume={3},
  number={4},
  pages={3145--3152},
  year={2018},
  publisher={IEEE}
}
@inproceedings{xu2018spidercnn,
  title={Spidercnn: Deep learning on point sets with parameterized convolutional filters},
  author={Xu, Yifan and Fan, Tianqi and Xu, Mingye and Zeng, Long and Qiao, Yu},
  booktitle={European Conference on Computer Vision},
  pages={87--102},
  year={2018}
}
@article{li2018pointcnn,
  title={Pointcnn: Convolution on x-transformed points},
  author={Li, Yangyan and Bu, Rui and Sun, Mingchao and Wu, Wei and Di, Xinhan and Chen, Baoquan},
  journal={Advances in neural information processing systems},
  volume={31},
  pages={820--830},
  year={2018}
}
@article{gbnet,
  title={Geometric back-projection network for point cloud classification},
  author={Qiu, Shi and Anwar, Saeed and Barnes, Nick},
  journal={IEEE Transactions on Multimedia},
  year={2021},
  publisher={IEEE}
}
@inproceedings{drnet,
  title={Dense-resolution network for point cloud classification and segmentation},
  author={Qiu, Shi and Anwar, Saeed and Barnes, Nick},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={3813--3822},
  year={2021}
}
@article{simpleview,
  title={Revisiting Point Cloud Shape Classification with a Simple and Effective Baseline},
  author={Goyal, Ankit and Law, Hei and Liu, Bowei and Newell, Alejandro and Deng, Jia},
  journal={arXiv preprint arXiv:2106.05304},
  year={2021}
}

@article{pointmlp,
  title={Rethinking network design and local geometry in point cloud: A simple residual mlp framework},
  author={Ma, Xu and Qin, Can and You, Haoxuan and Ran, Haoxi and Fu, Yun},
  journal={arXiv preprint arXiv:2202.07123},
  year={2022}
}

@inproceedings{chen2017multi,
  title={Multi-view 3d object detection network for autonomous driving},
  author={Chen, Xiaozhi and Ma, Huimin and Wan, Ji and Li, Bo and Xia, Tian},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={1907--1915},
  year={2017}
}
@inproceedings{qi2018frustum,
  title={Frustum pointnets for 3d object detection from rgb-d data},
  author={Qi, Charles R and Liu, Wei and Wu, Chenxia and Su, Hao and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={918--927},
  year={2018}
}
@article{aldoma2012tutorial,
  title={Tutorial: Point cloud library: Three-dimensional object recognition and 6 dof pose estimation},
  author={Aldoma, Aitor and Marton, Zoltan-Csaba and Tombari, Federico and Wohlkinger, Walter and Potthast, Christian and Zeisl, Bernhard and Rusu, Radu Bogdan and Gedikli, Suat and Vincze, Markus},
  journal={IEEE Robotics \& Automation Magazine},
  volume={19},
  number={3},
  pages={80--91},
  year={2012},
  publisher={IEEE}
}
@inproceedings{rusu2009close,
  title={Close-range scene segmentation and reconstruction of 3D point cloud maps for mobile manipulation in domestic environments},
  author={Rusu, Radu Bogdan and Blodow, Nico and Marton, Zoltan Csaba and Beetz, Michael},
  booktitle={2009 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={1--6},
  year={2009},
  organization={IEEE}
}
@article{correll2016analysis,
  title={Analysis and observations from the first amazon picking challenge},
  author={Correll, Nikolaus and Bekris, Kostas E and Berenson, Dmitry and Brock, Oliver and Causo, Albert and Hauser, Kris and Okada, Kei and Rodriguez, Alberto and Romano, Joseph M and Wurman, Peter R},
  journal={IEEE Transactions on Automation Science and Engineering},
  volume={15},
  number={1},
  pages={172--188},
  year={2016},
  publisher={IEEE}
}
@inproceedings{mousavian20196,
  title={6-dof graspnet: Variational grasp generation for object manipulation},
  author={Mousavian, Arsalan and Eppner, Clemens and Fox, Dieter},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2901--2910},
  year={2019}
}
@article{navarro2010pedestrian,
  title={Pedestrian detection and tracking using three-dimensional ladar data},
  author={Navarro-Serment, Luis E and Mertz, Christoph and Hebert, Martial},
  journal={The International Journal of Robotics Research},
  volume={29},
  number={12},
  pages={1516--1528},
  year={2010},
  publisher={SAGE Publications Sage UK: London, England}
}
@inproceedings{kidono2011pedestrian,
  title={Pedestrian recognition using high-definition LIDAR},
  author={Kidono, Kiyosumi and Miyasaka, Takeo and Watanabe, Akihiro and Naito, Takashi and Miura, Jun},
  booktitle={2011 IEEE Intelligent Vehicles Symposium (IV)},
  pages={405--410},
  year={2011},
  organization={IEEE}
}
@inproceedings{xu2021paconv,
  title={PAConv: Position Adaptive Convolution with Dynamic Kernel Assembling on Point Clouds},
  author={Xu, Mutian and Ding, Runyu and Zhao, Hengshuang and Qi, Xiaojuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3173--3182},
  year={2021}
}
@article{pvcnn,
  title={Point-voxel cnn for efficient 3d deep learning},
  author={Liu, Zhijian and Tang, Haotian and Lin, Yujun and Han, Song},
  journal={arXiv preprint arXiv:1907.03739},
  year={2019}
}
@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}
@inproceedings{wu20153d,
  title={3d shapenets: A deep representation for volumetric shapes},
  author={Wu, Zhirong and Song, Shuran and Khosla, Aditya and Yu, Fisher and Zhang, Linguang and Tang, Xiaoou and Xiao, Jianxiong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1912--1920},
  year={2015}
}
@inproceedings{thomas2019kpconv,
  title={Kpconv: Flexible and deformable convolution for point clouds},
  author={Thomas, Hugues and Qi, Charles R and Deschaud, Jean-Emmanuel and Marcotegui, Beatriz and Goulette, Fran{\c{c}}ois and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6411--6420},
  year={2019}
}
@article{zhang2021tip,
  title={Tip-Adapter: Training-free CLIP-Adapter for Better Vision-Language Modeling},
  author={Zhang, Renrui and Fang, Rongyao and Gao, Peng and Zhang, Wei and Li, Kunchang and Dai, Jifeng and Qiao, Yu and Li, Hongsheng},
  journal={arXiv preprint arXiv:2111.03930},
  year={2021}
}
@inproceedings{wu2016learning,
  title={Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling},
  author={Wu, Jiajun and Zhang, Chengkai and Xue, Tianfan and Freeman, William T and Tenenbaum, Joshua B},
  booktitle={Proceedings of the 30th International Conference on Neural Information Processing Systems},
  pages={82--90},
  year={2016}
}

@article{sharma2020self,
  title={Self-supervised few-shot learning on point clouds},
  author={Sharma, Charu and Kaul, Manohar},
  journal={arXiv preprint arXiv:2009.14168},
  year={2020}
}

@inproceedings{verdoja2017fast,
  title={Fast 3D point cloud segmentation using supervoxels with geometry and color for 3D scene understanding},
  author={Verdoja, Francesco and Thomas, Diego and Sugimoto, Akihiro},
  booktitle={2017 IEEE International Conference on Multimedia and Expo (ICME)},
  pages={1285--1290},
  year={2017},
  organization={IEEE}
}
@article{chen2019deep,
  title={Deep learning approach to point cloud scene understanding for automated scan to 3D reconstruction},
  author={Chen, Jingdao and Kira, Zsolt and Cho, Yong K},
  journal={Journal of Computing in Civil Engineering},
  volume={33},
  number={4},
  pages={04019027},
  year={2019},
  publisher={American Society of Civil Engineers}
}
@inproceedings{zheng2013beyond,
  title={Beyond point clouds: Scene understanding by reasoning geometry and physics},
  author={Zheng, Bo and Zhao, Yibiao and Yu, Joey C and Ikeuchi, Katsushi and Zhu, Song-Chun},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3127--3134},
  year={2013}
}
@article{orhan2018simple,
  title={A simple cache model for image recognition},
  author={Orhan, A Emin},
  journal={arXiv preprint arXiv:1805.08709},
  year={2018}
}
@article{khandelwal2019generalization,
  title={Generalization through memorization: Nearest neighbor language models},
  author={Khandelwal, Urvashi and Levy, Omer and Jurafsky, Dan and Zettlemoyer, Luke and Lewis, Mike},
  journal={arXiv preprint arXiv:1911.00172},
  year={2019}
}
@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1126--1135},
  year={2017},
  organization={PMLR}
}
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@book{cristianini2000introduction,
  title={An introduction to support vector machines and other kernel-based learning methods},
  author={Cristianini, Nello and Shawe-Taylor, John and others},
  year={2000},
  publisher={Cambridge university press}
}

@article{safavian1991survey,
  title={A survey of decision tree classifier methodology},
  author={Safavian, S Rasoul and Landgrebe, David},
  journal={IEEE transactions on systems, man, and cybernetics},
  volume={21},
  number={3},
  pages={660--674},
  year={1991},
  publisher={IEEE}
}

@article{friedman2001greedy,
  title={Greedy function approximation: a gradient boosting machine},
  author={Friedman, Jerome H},
  journal={Annals of statistics},
  pages={1189--1232},
  year={2001},
  publisher={JSTOR}
}


@inproceedings{dai20183dmv,
  title={3dmv: Joint 3d-multi-view prediction for 3d semantic scene segmentation},
  author={Dai, Angela and Nie{\ss}ner, Matthias},
  booktitle={European Conference on Computer Vision},
  pages={452--468},
  year={2018}
}

@article{zhao2019dar,
  title={DAR-Net: Dynamic aggregation network for semantic scene segmentation},
  author={Zhao, Zongyue and Liu, Min and Ramani, Karthik},
  journal={arXiv preprint arXiv:1907.12022},
  year={2019}
}

@inproceedings{he2020structure,
  title={Structure aware single-stage 3d object detection from point cloud},
  author={He, Chenhang and Zeng, Hui and Huang, Jianqiang and Hua, Xian-Sheng and Zhang, Lei},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11873--11882},
  year={2020}
}

@inproceedings{meng2019vv,
  title={Vv-net: Voxel vae net with group convolutions for point cloud segmentation},
  author={Meng, Hsien-Yu and Gao, Lin and Lai, Yu-Kun and Manocha, Dinesh},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={8500--8508},
  year={2019}
}

@inproceedings{zheng2021rethinking,
  title={Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers},
  author={Zheng, Sixiao and Lu, Jiachen and Zhao, Hengshuang and Zhu, Xiatian and Luo, Zekun and Wang, Yabiao and Fu, Yanwei and Feng, Jianfeng and Xiang, Tao and Torr, Philip HS and others},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6881--6890},
  year={2021}
}

@article{xie2021segformer,
  title={SegFormer: Simple and efficient design for semantic segmentation with transformers},
  author={Xie, Enze and Wang, Wenhai and Yu, Zhiding and Anandkumar, Anima and Alvarez, Jose M and Luo, Ping},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={12077--12090},
  year={2021}
}

@article{kirillov2023segment,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  journal={arXiv preprint arXiv:2304.02643},
  year={2023}
}

@article{wang2022internimage,
  title={Internimage: Exploring large-scale vision foundation models with deformable convolutions},
  author={Wang, Wenhai and Dai, Jifeng and Chen, Zhe and Huang, Zhenhang and Li, Zhiqi and Zhu, Xizhou and Hu, Xiaowei and Lu, Tong and Lu, Lewei and Li, Hongsheng and others},
  journal={arXiv preprint arXiv:2211.05778},
  year={2022}
}

@article{li2022uni,
  title={Uni-Perceiver v2: A Generalist Model for Large-Scale Vision and Vision-Language Tasks},
  author={Li, Hao and Zhu, Jinguo and Jiang, Xiaohu and Zhu, Xizhou and Li, Hongsheng and Yuan, Chun and Wang, Xiaohua and Qiao, Yu and Wang, Xiaogang and Wang, Wenhai and others},
  journal={arXiv preprint arXiv:2211.09808},
  year={2022}
}


@article{zhang2023llama,
  title={Llama-adapter: Efficient fine-tuning of language models with zero-init attention},
  author={Zhang, Renrui and Han, Jiaming and Zhou, Aojun and Hu, Xiangfei and Yan, Shilin and Lu, Pan and Li, Hongsheng and Gao, Peng and Qiao, Yu},
  journal={arXiv preprint arXiv:2303.16199},
  year={2023}
}

@inproceedings{cheng2022masked,
  title={Masked-attention mask transformer for universal image segmentation},
  author={Cheng, Bowen and Misra, Ishan and Schwing, Alexander G and Kirillov, Alexander and Girdhar, Rohit},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1290--1299},
  year={2022}
}

@inproceedings{long2015fully,
  title={Fully convolutional networks for semantic segmentation},
  author={Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3431--3440},
  year={2015}
}

@inproceedings{xu2022dirl,
  title={DIRL: Domain-invariant representation learning for generalizable semantic segmentation},
  author={Xu, Qi and Yao, Liang and Jiang, Zhengkai and Jiang, Guannan and Chu, Wenqing and Han, Wenhui and Zhang, Wei and Wang, Chengjie and Tai, Ying},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={3},
  pages={2884--2892},
  year={2022}
}

@inproceedings{zhao2017pyramid,
  title={Pyramid scene parsing network},
  author={Zhao, Hengshuang and Shi, Jianping and Qi, Xiaojuan and Wang, Xiaogang and Jia, Jiaya},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2881--2890},
  year={2017}
}

@inproceedings{jiang2022prototypical,
  title={Prototypical contrast adaptation for domain adaptive semantic segmentation},
  author={Jiang, Zhengkai and Li, Yuxi and Yang, Ceyuan and Gao, Peng and Wang, Yabiao and Tai, Ying and Wang, Chengjie},
  booktitle={European Conference on Computer Vision},
  pages={36--54},
  year={2022},
  organization={Springer}
}

@article{wang2022images,
  title={Images Speak in Images: A Generalist Painter for In-Context Visual Learning},
  author={Wang, Xinlong and Wang, Wen and Cao, Yue and Shen, Chunhua and Huang, Tiejun},
  journal={arXiv preprint arXiv:2212.02499},
  year={2022}
}

@article{wang2023seggpt,
  title={SegGPT: Segmenting Everything In Context},
  author={Wang, Xinlong and Zhang, Xiaosong and Cao, Yue and Wang, Wen and Shen, Chunhua and Huang, Tiejun},
  journal={arXiv preprint arXiv:2304.03284},
  year={2023}
}

@article{badrinarayanan2017segnet,
  title={Segnet: A deep convolutional encoder-decoder architecture for image segmentation},
  author={Badrinarayanan, Vijay and Kendall, Alex and Cipolla, Roberto},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={39},
  number={12},
  pages={2481--2495},
  year={2017},
  publisher={IEEE}
}

@article{chen2017deeplab,
  title={Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs},
  author={Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={40},
  number={4},
  pages={834--848},
  year={2017},
  publisher={IEEE}
}

@article{cheng2021per,
  title={Per-pixel classification is not all you need for semantic segmentation},
  author={Cheng, Bowen and Schwing, Alex and Kirillov, Alexander},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={17864--17875},
  year={2021}
}
@inproceedings{he2017mask,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2961--2969},
  year={2017}
}

@inproceedings{kirillov2019panoptic,
  title={Panoptic segmentation},
  author={Kirillov, Alexander and He, Kaiming and Girshick, Ross and Rother, Carsten and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={9404--9413},
  year={2019}
}

@inproceedings{hao2021edgeflow,
  title={Edgeflow: Achieving practical interactive segmentation with edge-guided flow},
  author={Hao, Yuying and Liu, Yi and Wu, Zewu and Han, Lin and Chen, Yizhou and Chen, Guowei and Chu, Lutao and Tang, Shiyu and Yu, Zhiliang and Chen, Zeyu and others},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={1551--1560},
  year={2021}
}

@inproceedings{chen2021conditional,
  title={Conditional diffusion for interactive segmentation},
  author={Chen, Xi and Zhao, Zhiyan and Yu, Feiwu and Zhang, Yilei and Duan, Manni},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={7345--7354},
  year={2021}
}

@article{song2020rethinking,
  title={Rethinking learnable tree filter for generic feature transform},
  author={Song, Lin and Li, Yanwei and Jiang, Zhengkai and Li, Zeming and Zhang, Xiangyu and Sun, Hongbin and Sun, Jian and Zheng, Nanning},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3991--4002},
  year={2020}
}



@article{bar2022visual,
  title={Visual prompting via image inpainting},
  author={Bar, Amir and Gandelsman, Yossi and Darrell, Trevor and Globerson, Amir and Efros, Alexei},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={25005--25017},
  year={2022}
}

@article{zou2023segment,
  title={Segment everything everywhere all at once},
  author={Zou, Xueyan and Yang, Jianwei and Zhang, Hao and Li, Feng and Li, Linjie and Gao, Jianfeng and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2304.06718},
  year={2023}
}

@inproceedings{jiang2023stc,
  title={STC: spatio-temporal contrastive learning for video instance segmentation},
  author={Jiang, Zhengkai and Gu, Zhangxuan and Peng, Jinlong and Zhou, Hang and Liu, Liang and Wang, Yabiao and Tai, Ying and Wang, Chengjie and Zhang, Liqing},
  booktitle={European Conference on Computer Vision Workshops},
  pages={539--556},
  year={2023},
  organization={Springer}
}


@inproceedings{jia2022visual,
  title={Visual prompt tuning},
  author={Jia, Menglin and Tang, Luming and Chen, Bor-Chun and Cardie, Claire and Belongie, Serge and Hariharan, Bharath and Lim, Ser-Nam},
  booktitle={European Conference on Computer Vision},
  pages={709--727},
  year={2022},
  organization={Springer}
}

@article{ruiz2022dreambooth,
  title={Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation},
  author={Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir},
  journal={arXiv preprint arXiv:2208.12242},
  year={2022}
}

@article{gal2022image,
  title={An image is worth one word: Personalizing text-to-image generation using textual inversion},
  author={Gal, Rinon and Alaluf, Yuval and Atzmon, Yuval and Patashnik, Or and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2208.01618},
  year={2022}
}


@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@article{kumari2022multi,
  title={Multi-Concept Customization of Text-to-Image Diffusion},
  author={Kumari, Nupur and Zhang, Bingliang and Zhang, Richard and Shechtman, Eli and Zhu, Jun-Yan},
  journal={arXiv preprint arXiv:2212.04488},
  year={2022}
}

@inproceedings{lin2019agss,
  title={Agss-vos: Attention guided single-shot video object segmentation},
  author={Lin, Huaijia and Qi, Xiaojuan and Jia, Jiaya},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={3949--3957},
  year={2019}
}

@inproceedings{johnander2019generative,
  title={A generative appearance model for end-to-end video object segmentation},
  author={Johnander, Joakim and Danelljan, Martin and Brissman, Emil and Khan, Fahad Shahbaz and Felsberg, Michael},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={8953--8962},
  year={2019}
}


@inproceedings{lin2022swem,
  title={SWEM: Towards Real-Time Video Object Segmentation with Sequential Weighted Expectation-Maximization},
  author={Lin, Zhihui and Yang, Tianyu and Li, Maomao and Wang, Ziyu and Yuan, Chun and Jiang, Wenhao and Liu, Wei},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1362--1372},
  year={2022}
}

@inproceedings{cheng2022xmem,
  title={XMem: Long-Term Video Object Segmentation with an Atkinson-Shiffrin Memory Model},
  author={Cheng, Ho Kei and Schwing, Alexander G},
  booktitle={European Conference on Computer Vision},
  pages={640--658},
  year={2022},
  organization={Springer}
}



@article{pont20172017,
  title={The 2017 davis challenge on video object segmentation},
  author={Pont-Tuset, Jordi and Perazzi, Federico and Caelles, Sergi and Arbel{\'a}ez, Pablo and Sorkine-Hornung, Alex and Van Gool, Luc},
  journal={arXiv preprint arXiv:1704.00675},
  year={2017}
}

@inproceedings{li2019attention,
  title={Attention-guided unified network for panoptic segmentation},
  author={Li, Yanwei and Chen, Xinze and Zhu, Zheng and Xie, Lingxi and Huang, Guan and Du, Dalong and Wang, Xingang},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={7026--7035},
  year={2019}
}

@article{wang2020solov2,
  title={Solov2: Dynamic and fast instance segmentation},
  author={Wang, Xinlong and Zhang, Rufeng and Kong, Tao and Li, Lei and Shen, Chunhua},
  journal={Advances in Neural information processing systems},
  volume={33},
  pages={17721--17732},
  year={2020}
}

@inproceedings{tian2020conditional,
  title={Conditional convolutions for instance segmentation},
  author={Tian, Zhi and Shen, Chunhua and Chen, Hao},
  booktitle={European Conference on Computer Vision},
  pages={282--298},
  year={2020},
  organization={Springer}
}

@article{liu2021gpt,
  title={GPT understands, too},
  author={Liu, Xiao and Zheng, Yanan and Du, Zhengxiao and Ding, Ming and Qian, Yujie and Yang, Zhilin and Tang, Jie},
  journal={arXiv preprint arXiv:2103.10385},
  year={2021}
}

@article{liu2021p-tuning,
  title={P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks},
  author={Liu, Xiao and Ji, Kaixuan and Fu, Yicheng and Tam, Weng Lam and Du, Zhengxiao and Yang, Zhilin and Tang, Jie},
  journal={arXiv preprint arXiv:2110.07602},
  year={2021}
}

@article{zhang2023adaptive,
  title={Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning},
  author={Zhang, Qingru and Chen, Minshuo and Bukharin, Alexander and He, Pengcheng and Cheng, Yu and Chen, Weizhu and Zhao, Tuo},
  journal={arXiv preprint arXiv:2303.10512},
  year={2023}
}

@article{hedegaard2022structured,
  title={Structured Pruning Adapters},
  author={Hedegaard, Lukas and Alok, Aman and Jose, Juby and Iosifidis, Alexandros},
  journal={arXiv preprint arXiv:2211.10155},
  year={2022}
}

@article{qin2021learning,
  title={Learning how to ask: Querying LMs with mixtures of soft prompts},
  author={Qin, Guanghui and Eisner, Jason},
  journal={arXiv preprint arXiv:2104.06599},
  year={2021}
}

@article{chen2022vision,
  title={Vision transformer adapter for dense predictions},
  author={Chen, Zhe and Duan, Yuchen and Wang, Wenhai and He, Junjun and Lu, Tong and Dai, Jifeng and Qiao, Yu},
  journal={arXiv preprint arXiv:2205.08534},
  year={2022}
}

@article{rebuffi2017learning,
  title={Learning multiple visual domains with residual adapters},
  author={Rebuffi, Sylvestre-Alvise and Bilen, Hakan and Vedaldi, Andrea},
  journal={Advances in Neural information processing systems},
  volume={30},
  year={2017}
}

@article{gesmundo2022munet,
  title={munet: Evolving pretrained deep neural networks into scalable auto-tuning multitask systems},
  author={Gesmundo, Andrea and Dean, Jeff},
  journal={arXiv preprint arXiv:2205.10937},
  year={2022}
}

@article{top_p_sample,
  author       = {Ari Holtzman and
                  Jan Buys and
                  Maxwell Forbes and
                  Yejin Choi},
  title        = {The Curious Case of Neural Text Degeneration},
  journal      = {CoRR},
  volume       = {abs/1904.09751},
  year         = {2019},
  url          = {http://arxiv.org/abs/1904.09751},
  eprinttype    = {arXiv},
  eprint       = {1904.09751},
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={248--255},
  year={2009},
}

@article{zhai2019large,
  title={A large-scale study of representation learning with the visual task adaptation benchmark},
  author={Zhai, Xiaohua and Puigcerver, Joan and Kolesnikov, Alexander and Ruyssen, Pierre and Riquelme, Carlos and Lucic, Mario and Djolonga, Josip and Pinto, Andre Susano and Neumann, Maxim and Dosovitskiy, Alexey and others},
  journal={arXiv preprint arXiv:1910.04867},
  year={2019}
}

@inproceedings{zaken2022bitfit,
  title={BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models},
  author={Zaken, Elad Ben and Goldberg, Yoav and Ravfogel, Shauli},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  pages={1--9},
  year={2022}
}

@article{cai2020tinytl,
  title={Tinytl: Reduce memory, not parameters for efficient on-device learning},
  author={Cai, Han and Gan, Chuang and Zhu, Ligeng and Han, Song},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={11285--11297},
  year={2020}
}

@misc{alpaca_lora,
    title = {Alpaca-LoRA},
    howpublished = {\url{https://github.com/tloen/alpaca-lora}},
    year = {2023}
}

@inproceedings{zhou2022conditional,
  title={Conditional prompt learning for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16816--16825},
  year={2022}
}

@misc{bard,
  author ={Google},
  title = {Bard},
  year = {2023},
  howpublished = {\url{https://bard.google.com/}}
}
@inproceedings{zhang2020side,
  title={Side-tuning: a baseline for network adaptation via additive side networks},
  author={Zhang, Jeffrey O and Sax, Alexander and Zamir, Amir and Guibas, Leonidas and Malik, Jitendra},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part III 16},
  pages={698--714},
  year={2020},
  organization={Springer}
}

@misc{OpenAI2023ChatGPT,
  author={OpenAI},
    title = {ChatGPT},
    howpublished = {\url{https://chat.openai.com}},
    year = {2023}
}


@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    howpublished = {\url{https://lmsys.org/blog/2023-03-30-vicuna/}},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}

@article{caltech101,
  title={Learning Generative Visual Models from Few Training Examples: An Incremental Bayesian Approach Tested on 101 Object Categories},
  author={Li Fei-Fei and Rob Fergus and Pietro Perona},
  journal={Computer Vision and Pattern Recognition Workshop},
  year={2004},
}

@inproceedings{flowers102,
  title={Automated flower classification over a large number of classes},
  author={Nilsback, Maria-Elena and Zisserman, Andrew},
  booktitle={2008 Sixth Indian Conference on Computer Vision, Graphics \& Image Processing},
  pages={722--729},
  year={2008},
  organization={IEEE}
}

@inproceedings{cocoop,
  title={Conditional prompt learning for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16816--16825},
  year={2022}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{rajpurkar2016squad,
  title={Squad: 100,000+ questions for machine comprehension of text},
  author={Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
  journal={arXiv preprint arXiv:1606.05250},
  year={2016}
}


@article{CONLL03,
  title={Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition},
  author={Sang, Erik F and De Meulder, Fien},
  journal={arXiv preprint cs/0306050},
  year={2003}
}


@inproceedings{CONLL04,
  title={Introduction to the CoNLL-2004 shared task: Semantic role labeling},
  author={Carreras, Xavier and M{\`a}rquez, Llu{\'\i}s},
  booktitle={Proceedings of the eighth conference on computational natural language learning (CoNLL-2004) at HLT-NAACL 2004},
  pages={89--97},
  year={2004}
}

@inproceedings{CONLL05,
  title={Introduction to the CoNLL-2005 shared task: Semantic role labeling},
  author={Carreras, Xavier and M{\`a}rquez, Llu{\'\i}s},
  booktitle={Proceedings of the ninth conference on computational natural language learning (CoNLL-2005)},
  pages={152--164},
  year={2005}
}

@inproceedings{CONLL12,
  title={CoNLL-2012 shared task: Modeling multilingual unrestricted coreference in OntoNotes},
  author={Pradhan, Sameer and Moschitti, Alessandro and Xue, Nianwen and Uryupina, Olga and Zhang, Yuchen},
  booktitle={Joint conference on EMNLP and CoNLL-shared task},
  pages={1--40},
  year={2012}
}

@article{gpt4llm,
  title={Instruction Tuning with GPT-4},
  author={Peng, Baolin and Li, Chunyuan and He, Pengcheng and Galley, Michel and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2304.03277},
  year={2023}
}


@misc{biderman2023pythia,
      title={Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling}, 
      author={Stella Biderman and Hailey Schoelkopf and Quentin Anthony and Herbie Bradley and Kyle O'Brien and Eric Hallahan and Mohammad Aflah Khan and Shivanshu Purohit and USVSN Sai Prashanth and Edward Raff and Aviya Skowron and Lintang Sutawika and Oskar van der Wal},
      year={2023},
      eprint={2304.01373},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{zhu2023minigpt,
  title={Minigpt-4: Enhancing vision-language understanding with advanced large language models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2304.10592},
  year={2023}
}

@article{llava,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2304.08485},
  year={2023}
}

@article{khattak2022maple,
  title={Maple: Multi-modal prompt learning},
  author={Khattak, Muhammad Uzair and Rasheed, Hanoona and Maaz, Muhammad and Khan, Salman and Khan, Fahad Shahbaz},
  journal={arXiv preprint arXiv:2210.03117},
  year={2022}
}

@article{chung2022scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Eric and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={arXiv preprint arXiv:2210.11416},
  year={2022}
}

@article{fu2023mme,
  title={MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models},
  author={Fu, Chaoyou and Chen, Peixian and Shen, Yunhang and Qin, Yulei and Zhang, Mengdan and Lin, Xu and Qiu, Zhenyu and Lin, Wei and Yang, Jinrui and Zheng, Xiawu and others},
  journal={arXiv preprint arXiv:2306.13394},
  year={2023}
}

@article{liu2023mmbench,
  title={MMBench: Is Your Multi-modal Model an All-around Player?},
  author={Liu, Yuan and Duan, Haodong and Zhang, Yuanhan and Li, Bo and Zhang, Songyang and Zhao, Wangbo and Yuan, Yike and Wang, Jiaqi and He, Conghui and Liu, Ziwei and others},
  journal={arXiv preprint arXiv:2307.06281},
  year={2023}
}

@article{xu2023lvlm,
  title={Lvlm-ehub: A comprehensive evaluation benchmark for large vision-language models},
  author={Xu, Peng and Shao, Wenqi and Zhang, Kaipeng and Gao, Peng and Liu, Shuo and Lei, Meng and Meng, Fanqing and Huang, Siyuan and Qiao, Yu and Luo, Ping},
  journal={arXiv preprint arXiv:2306.09265},
  year={2023}
}

@article{wang2018glue,
  title={GLUE: A multi-task benchmark and analysis platform for natural language understanding},
  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
  journal={arXiv preprint arXiv:1804.07461},
  year={2018}
}
@inproceedings{puzikov2018e2e,
  title={E2e nlg challenge: Neural models vs. templates},
  author={Puzikov, Yevgeniy and Gurevych, Iryna},
  booktitle={Proceedings of the 11th International Conference on Natural Language Generation},
  pages={463--471},
  year={2018}
}

@misc{controlnet,
  title={Adding Conditional Control to Text-to-Image Diffusion Models}, 
  author={Lvmin Zhang and Anyi Rao and Maneesh Agrawala},
  booktitle={IEEE International Conference on Computer Vision (ICCV)},
  year={2023}
}

@article{yoo2023improving,
  title={Improving Visual Prompt Tuning for Self-supervised Vision Transformers},
  author={Yoo, Seungryong and Kim, Eunji and Jung, Dahuin and Lee, Jungbeom and Yoon, Sungroh},
  journal={arXiv preprint arXiv:2306.05067},
  year={2023}
}

@article{goswami2023switchprompt,
  title={SwitchPrompt: Learning Domain-Specific Gated Soft Prompts for Classification in Low-Resource Domains},
  author={Goswami, Koustava and Lange, Lukas and Araki, Jun and Adel, Heike},
  journal={arXiv preprint arXiv:2302.06868},
  year={2023}
}

@article{schuhmann2021laion,
  title={Laion-400m: Open dataset of clip-filtered 400 million image-text pairs},
  author={Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
  journal={arXiv preprint arXiv:2111.02114},
  year={2021}
}


@misc{open-llm-leaderboard,
  author = {Edward Beeching and Clmentine Fourrier and Nathan Habib and Sheon Han and Nathan Lambert and Nazneen Rajani and Omar Sanseviero and Lewis Tunstalland Thomas Wolf},
  title = {Open LLM Leaderboard},
  year = {2023},
  publisher = {Hugging Face},
  howpublished = "\url{https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard}"
}
@software{eval-harness,
  author       = {Gao, Leo and
                  Tow, Jonathan and
                  Biderman, Stella and
                  Black, Sid and
                  DiPofi, Anthony and
                  Foster, Charles and
                  Golding, Laurence and
                  Hsu, Jeffrey and
                  McDonell, Kyle and
                  Muennighoff, Niklas and
                  Phang, Jason and
                  Reynolds, Laria and
                  Tang, Eric and
                  Thite, Anish and
                  Wang, Ben and
                  Wang, Kevin and
                  Zou, Andy},
  title        = {A framework for few-shot language model evaluation},
  month        = sep,
  year         = 2021,
  publisher    = {Zenodo},
  version      = {v0.0.1},
  doi          = {10.5281/zenodo.5371628},
  url          = {https://doi.org/10.5281/zenodo.5371628}
}
@misc{clark2018think,
      title={Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge},
      author={Peter Clark and Isaac Cowhey and Oren Etzioni and Tushar Khot and Ashish Sabharwal and Carissa Schoenick and Oyvind Tafjord},
      year={2018},
      eprint={1803.05457},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
@misc{zellers2019hellaswag,
      title={HellaSwag: Can a Machine Really Finish Your Sentence?},
      author={Rowan Zellers and Ari Holtzman and Yonatan Bisk and Ali Farhadi and Yejin Choi},
      year={2019},
      eprint={1905.07830},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{hendrycks2021measuring,
      title={Measuring Massive Multitask Language Understanding},
      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
      year={2021},
      eprint={2009.03300},
      archivePrefix={arXiv},
      primaryClass={cs.CY}
}
@misc{lin2022truthfulqa,
      title={TruthfulQA: Measuring How Models Mimic Human Falsehoods},
      author={Stephanie Lin and Jacob Hilton and Owain Evans},
      year={2022},
      eprint={2109.07958},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{zhao2021zero,
  title={Zero initialization: Initializing residual networks with only zeros and ones},
  author={Zhao, Jiawei and Schaefer, Florian Tobias and Anandkumar, Anima},
  year={2021}
}

@article{ye2023mplug,
  title={mplug-owl: Modularization empowers large language models with multimodality},
  author={Ye, Qinghao and Xu, Haiyang and Xu, Guohai and Ye, Jiabo and Yan, Ming and Zhou, Yiyang and Wang, Junyang and Hu, Anwen and Shi, Pengcheng and Shi, Yaya and others},
  journal={arXiv preprint arXiv:2304.14178},
  year={2023}
}

@article{li2023otter,
  title={Otter: A Multi-Modal Model with In-Context Instruction Tuning},
  author={Li, Bo and Zhang, Yuanhan and Chen, Liangyu and Wang, Jinghao and Yang, Jingkang and Liu, Ziwei},
  journal={arXiv preprint arXiv:2305.03726},
  year={2023}
}

@article{2023vpgtrans,
  author      = {Ao Zhang and Hao Fei and Yuan Yao and Wei Ji and Li Li and Zhiyuan Liu and Tat-Seng Chua},
  title       = {Transfer Visual Prompt Generator across LLMs},
  journal      = {CoRR},
  volume       = {abs/23045.01278},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.01278},
}

@article{huang2023kosmos,
  title={Language is not all you need: Aligning perception with language models},
  author={Huang, Shaohan and Dong, Li and Wang, Wenhui and Hao, Yaru and Singhal, Saksham and Ma, Shuming and Lv, Tengchao and Cui, Lei and Mohammed, Owais Khan and Liu, Qiang and others},
  journal={arXiv preprint arXiv:2302.14045},
  year={2023}
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International conference on machine learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}

@inproceedings{li2022grounded,
  title={Grounded language-image pre-training},
  author={Li, Liunian Harold and Zhang, Pengchuan and Zhang, Haotian and Yang, Jianwei and Li, Chunyuan and Zhong, Yiwu and Wang, Lijuan and Yuan, Lu and Zhang, Lei and Hwang, Jenq-Neng and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10965--10975},
  year={2022}
}



@InProceedings{zhang2023cvqa,
    author    = {Zhang, Letian and Zhai, Xiaotong and Zhao, Zhongkai and Wen, Xin and Zhao, Bingchen},
    title     = {What If the TV Was Off? Examining Counterfactual Reasoning Abilities of Multi-Modal Language Models},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops},
    year      = {2023}
}

@article{suris2023vipergpt,
  title={Vipergpt: Visual inference via python execution for reasoning},
  author={Sur{\'\i}s, D{\'\i}dac and Menon, Sachit and Vondrick, Carl},
  journal={arXiv preprint arXiv:2303.08128},
  year={2023}
}

@article{Dai2023InstructBLIPTG,
  title={InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning},
  author={Wenliang Dai and Junnan Li and Dongxu Li and Anthony Meng Huat Tiong and Junqi Zhao and Weisheng Wang and Boyang Albert Li and Pascale Fung and Steven C. H. Hoi},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.06500}
}

@article{li2023pope,
  title={Evaluating object hallucination in large vision-language models},
  author={Li, Yifan and Du, Yifan and Zhou, Kun and Wang, Jinpeng and Zhao, Wayne Xin and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2305.10355},
  year={2023}
}

@misc{gong2023multimodalgpt,
      title={MultiModal-GPT: A Vision and Language Model for Dialogue with Humans}, 
      author={Tao Gong and Chengqi Lyu and Shilong Zhang and Yudong Wang and Miao Zheng and Qian Zhao and Kuikun Liu and Wenwei Zhang and Ping Luo and Kai Chen},
      year={2023},
      eprint={2305.04790},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{yu2023mmvet,
  title={Mm-vet: Evaluating large multimodal models for integrated capabilities},
  author={Yu, Weihao and Yang, Zhengyuan and Li, Linjie and Wang, Jianfeng and Lin, Kevin and Liu, Zicheng and Wang, Xinchao and Wang, Lijuan},
  journal={arXiv preprint arXiv:2308.02490},
  year={2023}
}

@article{li2023evaluating,
  title={Evaluating object hallucination in large vision-language models},
  author={Li, Yifan and Du, Yifan and Zhou, Kun and Wang, Jinpeng and Zhao, Wayne Xin and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2305.10355},
  year={2023}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@article{liu2023improved,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2310.03744},
  year={2023}
}


@misc{instructblip,
      title={InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning}, 
      author={Wenliang Dai and Junnan Li and Dongxu Li and Anthony Meng Huat Tiong and Junqi Zhao and Weisheng Wang and Boyang Li and Pascale Fung and Steven Hoi},
      year={2023},
      eprint={2305.06500},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}