@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{dai2019transformer,
  title={Transformer-xl: Attentive language models beyond a fixed-length context},
  author={Dai, Zihang and Yang, Zhilin and Yang, Yiming and Carbonell, Jaime and Le, Quoc V and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1901.02860},
  year={2019}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{zhang2022opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}
@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

% self instruct
@misc{selfinstruct,
  title={Self-Instruct: Aligning Language Model with Self Generated Instructions},
  author={Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A. and Khashabi, Daniel and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2212.10560},
  year={2022}
}

%%%% task-specific vl models
@inproceedings{vinyals2015show,
  title={Show and tell: A neural image caption generator},
  author={Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3156--3164},
  year={2015}
}

@inproceedings{karpathy2015deep,
  title={Deep visual-semantic alignments for generating image descriptions},
  author={Karpathy, Andrej and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3128--3137},
  year={2015}
}

@inproceedings{yang2016stacked,
  title={Stacked attention networks for image question answering},
  author={Yang, Zichao and He, Xiaodong and Gao, Jianfeng and Deng, Li and Smola, Alex},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={21--29},
  year={2016}
}

@article{santoro2017simple,
  title={A simple neural network module for relational reasoning},
  author={Santoro, Adam and Raposo, David and Barrett, David G and Malinowski, Mateusz and Pascanu, Razvan and Battaglia, Peter and Lillicrap, Timothy},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


@inproceedings{jiang2020defense,
  title={In defense of grid features for visual question answering},
  author={Jiang, Huaizu and Misra, Ishan and Rohrbach, Marcus and Learned-Miller, Erik and Chen, Xinlei},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10267--10276},
  year={2020}
}

%%% large-scale vl models
@article{wang2021simvlm,
  title={Simvlm: Simple visual language model pretraining with weak supervision},
  author={Wang, Zirui and Yu, Jiahui and Yu, Adams Wei and Dai, Zihang and Tsvetkov, Yulia and Cao, Yuan},
  journal={arXiv preprint arXiv:2108.10904},
  year={2021}
}

@article{bao2022vlmo,
  title={Vlmo: Unified vision-language pre-training with mixture-of-modality-experts},
  author={Bao, Hangbo and Wang, Wenhui and Dong, Li and Liu, Qiang and Mohammed, Owais Khan and Aggarwal, Kriti and Som, Subhojit and Piao, Songhao and Wei, Furu},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={32897--32912},
  year={2022}
}

@inproceedings{wang2022ofa,
  title={Ofa: Unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning framework},
  author={Wang, Peng and Yang, An and Men, Rui and Lin, Junyang and Bai, Shuai and Li, Zhikang and Ma, Jianxin and Zhou, Chang and Zhou, Jingren and Yang, Hongxia},
  booktitle={International Conference on Machine Learning},
  pages={23318--23340},
  year={2022},
  organization={PMLR}
}

@inproceedings{mathew2021docvqa,
  title={Docvqa: A dataset for vqa on document images},
  author={Mathew, Minesh and Karatzas, Dimosthenis and Jawahar, CV},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={2200--2209},
  year={2021}
}

@article{lei2018tvqa,
  title={Tvqa: Localized, compositional video question answering},
  author={Lei, Jie and Yu, Licheng and Bansal, Mohit and Berg, Tamara L},
  journal={arXiv preprint arXiv:1809.01696},
  year={2018}
}

@inproceedings{goyal2017making,
  title={Making the v in vqa matter: Elevating the role of image understanding in visual question answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6904--6913},
  year={2017}
}

@article{lin2022retrieval,
  title={Retrieval Augmented Visual Question Answering with Outside Knowledge},
  author={Lin, Weizhe and Byrne, Bill},
  journal={arXiv preprint arXiv:2210.03809},
  year={2022}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@article{wang2022git,
  title={Git: A generative image-to-text transformer for vision and language},
  author={Wang, Jianfeng and Yang, Zhengyuan and Hu, Xiaowei and Li, Linjie and Lin, Kevin and Gan, Zhe and Liu, Zicheng and Liu, Ce and Wang, Lijuan},
  journal={arXiv preprint arXiv:2205.14100},
  year={2022}
}

@article{wang2022image,
  title={Image as a foreign language: Beit pretraining for all vision and vision-language tasks},
  author={Wang, Wenhui and Bao, Hangbo and Dong, Li and Bjorck, Johan and Peng, Zhiliang and Liu, Qiang and Aggarwal, Kriti and Mohammed, Owais Khan and Singhal, Saksham and Som, Subhojit and others},
  journal={arXiv preprint arXiv:2208.10442},
  year={2022}
}

@article{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  journal={arXiv preprint arXiv:2301.12597},
  year={2023}
}

%%% most related
@inproceedings{zhai2022lit,
  title={Lit: Zero-shot transfer with locked-image text tuning},
  author={Zhai, Xiaohua and Wang, Xiao and Mustafa, Basil and Steiner, Andreas and Keysers, Daniel and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18123--18133},
  year={2022}
}

@article{tsimpoukelli2021multimodal,
  title={Multimodal few-shot learning with frozen language models},
  author={Tsimpoukelli, Maria and Menick, Jacob L and Cabi, Serkan and Eslami, SM and Vinyals, Oriol and Hill, Felix},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={200--212},
  year={2021}
}

@article{mokady2021clipcap,
  title={Clipcap: Clip prefix for image captioning},
  author={Mokady, Ron and Hertz, Amir and Bermano, Amit H},
  journal={arXiv preprint arXiv:2111.09734},
  year={2021}
}


% MM-COT
@article{zhang2023multicot,
  title={Multimodal Chain-of-Thought Reasoning in Language Models},
  author={Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Zhao, Hai and Karypis, George and Smola, Alex},
  journal={arXiv preprint arXiv:2302.00923},
  year={2023}
}

% IconQA
@inproceedings{lu2021iconqa,
  title = {IconQA: A New Benchmark for Abstract Diagram Understanding and Visual Language Reasoning},
  author = {Lu, Pan and Qiu, Liang and Chen, Jiaqi and Xia, Tony and Zhao, Yizhou and Zhang, Wei and Yu, Zhou and Liang, Xiaodan and Zhu, Song-Chun},
  booktitle = {The 35th Conference on Neural Information Processing Systems (NeurIPS) Track on Datasets and Benchmarks},
  year = {2021}
}

% UnifiedQA
@inproceedings{khashabi2020unifiedqa,
  title={UNIFIEDQA: Crossing Format Boundaries with a Single QA System},
  author={Khashabi, Daniel and Min, Sewon and Khot, Tushar and Sabharwal, Ashish and Tafjord, Oyvind and Clark, Peter and Hajishirzi, Hannaneh},
  booktitle={Findings of the Association for Computational Linguistics (EMNLP)},
  pages={1896--1907},
  year={2020}
}

% GPT-3
@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

% GPT-4
@article{OpenAI2023GPT4TR,
  title={GPT-4 Technical Report},
  author={OpenAI},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.08774}
}

@article{wei2021finetuned,
  title={Finetuned language models are zero-shot learners},
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent Y and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  journal={arXiv preprint arXiv:2109.01652},
  year={2021}
}

@inproceedings{lu2018rvqa,
  title={R-VQA: learning visual relation facts with semantic attention for visual question answering},
  author={Lu, Pan and Ji, Lei and Zhang, Wei and Duan, Nan and Zhou, Ming and Wang, Jianyong},
  booktitle={The ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (SIGKDD)},
  pages={1880--1889},
  year={2018}
}

% Bottom-up attention
@inproceedings{Anderson2017up,
  author = {Peter Anderson and Xiaodong He and Chris Buehler and Damien Teney and Mark Johnson and Stephen Gould and Lei Zhang},
  title = {Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2018}
}

% Co-attention
@inproceedings{lu2018co,
  title={Co-attending free-form regions and detections with multi-modal multiplicative feature embedding for visual question answering},
  author={Lu, Pan and Li, Hongsheng and Zhang, Wei and Wang, Jianyong and Wang, Xiaogang},
  booktitle={The AAAI Conference on Artificial Intelligence (AAAI)},
  year={2018}
}

% BAN
@inproceedings{Kim2018,
author = {Kim, Jin-Hwa and Jun, Jaehyun and Zhang, Byoung-Tak},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
title = {Bilinear Attention Networks},
pages = {1571--1581},
year = {2018}
}

% MCAN
@inProceedings{yu2019mcan,
  author = {Yu, Zhou and Yu, Jun and Cui, Yuhao and Tao, Dacheng and Tian, Qi},
  title = {Deep Modular Co-Attention Networks for Visual Question Answering},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {6281--6290},
  year = {2019}
}

% DAFA
@inproceedings{gao2019dynamic,
  title={Dynamic Fusion With Intra-and Inter-Modality Attention Flow for Visual Question Answering},
  author={Gao, Peng and Jiang, Zhengkai and You, Haoxuan and Lu, Pan and Hoi, Steven CH and Wang, Xiaogang and Li, Hongsheng},
  booktitle={The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={6639--6648},
  year={2019}
}

% Hybrid
@inproceedings{gao2018question,
  title={Question-guided hybrid convolution for visual question answering},
  author={Gao, Peng and Li, Hongsheng and Li, Shuang and Lu, Pan and Li, Yikang and Hoi, Steven CH and Wang, Xiaogang},
  booktitle={The European Conference on Computer Vision (ECCV)},
  pages={469--485},
  year={2018}
}

% ViLBERT
@inproceedings{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={13--23},
  year={2019}
}

% visualbert
@article{li2019visualbert,
  title={Visualbert: A simple and performant baseline for vision and language},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1908.03557},
  year={2019}
}

% visualbert
@inproceedings{li2020does,
  title={What does bert with vision look at?},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL)},
  pages={5265--5275},
  year={2020}
}

%ViLT
@InProceedings{pmlr-v139-kim21k,
  title = {ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision},
  author = {Kim, Wonjae and Son, Bokyung and Kim, Ildoo},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning (ICML)},
  pages = {5583--5594},
  year = {2021},
}

@inproceedings{scienceqa,
    title={Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering},
    author={Lu, Pan and Mishra, Swaroop and Xia, Tony and Qiu, Liang and Chang, Kai-Wei and Zhu, Song-Chun and Tafjord, Oyvind and Clark, Peter and Ashwin Kalyan},
    booktitle={The 36th Conference on Neural Information Processing Systems (NeurIPS)},
    year={2022}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International Conference on Machine Learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}
@article{Shridhar2019ALFREDAB,
  title={ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks},
  author={Mohit Shridhar and Jesse Thomason and Daniel Gordon and Yonatan Bisk and Winson Han and Roozbeh Mottaghi and Luke Zettlemoyer and Dieter Fox},
  journal={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019},
  pages={10737-10746}
}

@article{Min2021FILMFI,
  title={FILM: Following Instructions in Language with Modular Methods},
  author={So Yeon Min and Devendra Singh Chaplot and Pradeep Ravikumar and Yonatan Bisk and Ruslan Salakhutdinov},
  journal={ArXiv},
  year={2021},
  volume={abs/2110.07342}
}

@article{pfeiffer2020adapterfusion,
  title={AdapterFusion: Non-destructive task composition for transfer learning},
  author={Pfeiffer, Jonas and Kamath, Aishwarya and R{\"u}ckl{\'e}, Andreas and Cho, Kyunghyun and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2005.00247},
  year={2020}
}

@article{lester2021power,
  title={The power of scale for parameter-efficient prompt tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  journal={arXiv preprint arXiv:2104.08691},
  year={2021}
}

@article{karimi2021compacter,
  title={Compacter: Efficient low-rank hypercomplex adapter layers},
  author={Karimi Mahabadi, Rabeeh and Henderson, James and Ruder, Sebastian},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={1022--1035},
  year={2021}
}

@inproceedings{wang2022super,
  title={Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks},
  author={Wang, Yizhong and Mishra, Swaroop and Alipoormolabashi, Pegah and Kordi, Yeganeh and Mirzaei, Amirreza and Naik, Atharva and Ashok, Arjun and Dhanasekaran, Arut Selvan and Arunkumar, Anjana and Stap, David and others},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={5085--5109},
  year={2022}
}

@article{bach2022promptsource,
  title={Promptsource: An integrated development environment and repository for natural language prompts},
  author={Bach, Stephen H and Sanh, Victor and Yong, Zheng-Xin and Webson, Albert and Raffel, Colin and Nayak, Nihal V and Sharma, Abheesht and Kim, Taewoon and Bari, M Saiful and Fevry, Thibault and others},
  journal={arXiv preprint arXiv:2202.01279},
  year={2022}
}


@article{touvron2023llama,
  title={LLaMA: Open and Efficient Foundation Language Models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={arXiv preprint arXiv:2203.02155},
  year={2022}
}

@Misc{peft,
  title =        {PEFT: State-of-the-art Parameter-Efficient Fine-Tuning methods},
  author =       {Sourab Mangrulkar; Sylvain Gugger; Lysandre Debut; Younes Belkada; Sayak Paul},
  howpublished = {\url{https://github.com/huggingface/peft}},
  year =         {2022}
}

@article{li2021prefix,
  title={Prefix-tuning: Optimizing continuous prompts for generation},
  author={Li, Xiang Lisa and Liang, Percy},
  journal={arXiv preprint arXiv:2101.00190},
  year={2021}
}

@article{lin2020exploring,
  title={Exploring versatile generative language model via parameter-efficient transfer learning},
  author={Lin, Zhaojiang and Madotto, Andrea and Fung, Pascale},
  journal={arXiv preprint arXiv:2004.03829},
  year={2020}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}


@inproceedings{qi2017pointnet,
  title={Pointnet: Deep learning on point sets for 3d classification and segmentation},
  author={Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={652--660},
  year={2017}
}
@inproceedings{zhang2022pointclip,
  title={Pointclip: Point cloud understanding by clip},
  author={Zhang, Renrui and Guo, Ziyu and Zhang, Wei and Li, Kunchang and Miao, Xupeng and Cui, Bin and Qiao, Yu and Gao, Peng and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8552--8562},
  year={2022}
}
@inproceedings{shi2020pv,
  title={Pv-rcnn: Point-voxel feature set abstraction for 3d object detection},
  author={Shi, Shaoshuai and Guo, Chaoxu and Jiang, Li and Wang, Zhe and Shi, Jianping and Wang, Xiaogang and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10529--10538},
  year={2020}
}
@inproceedings{liu2020closer,
  title={A closer look at local aggregation operators in point cloud analysis},
  author={Liu, Ze and Hu, Han and Cao, Yue and Zhang, Zheng and Tong, Xin},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXIII 16},
  pages={326--342},
  year={2020},
  organization={Springer}
}
@article{xue2022ulip,
  title={ULIP: Learning Unified Representation of Language, Image and Point Cloud for 3D Understanding},
  author={Xue, Le and Gao, Mingfei and Xing, Chen and Mart{\'\i}n-Mart{\'\i}n, Roberto and Wu, Jiajun and Xiong, Caiming and Xu, Ran and Niebles, Juan Carlos and Savarese, Silvio},
  journal={arXiv preprint arXiv:2212.05171},
  year={2022}
}
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}
@article{huang2022clip2point,
  title={Clip2point: Transfer clip to point cloud classification with image-depth pre-training},
  author={Huang, Tianyu and Dong, Bowen and Yang, Yunhan and Huang, Xiaoshui and Lau, Rynson WH and Ouyang, Wanli and Zuo, Wangmeng},
  journal={arXiv preprint arXiv:2210.01055},
  year={2022}
}
@article{wu2022eda,
  title={EDA: Explicit Text-Decoupling and Dense Alignment for 3D Visual and Language Learning},
  author={Wu, Yanmin and Cheng, Xinhua and Zhang, Renrui and Cheng, Zesen and Zhang, Jian},
  journal={arXiv preprint arXiv:2209.14941},
  year={2022}
}
@article{guo2022calip,
  title={Calip: Zero-shot enhancement of clip with parameter-free attention},
  author={Guo, Ziyu and Zhang, Renrui and Qiu, Longtian and Ma, Xianzheng and Miao, Xupeng and He, Xuming and Cui, Bin},
  journal={arXiv preprint arXiv:2209.14169},
  year={2022}
}

@article{guo2023joint,
  title={Joint-MAE: 2D-3D Joint Masked Autoencoders for 3D Point Cloud Pre-training},
  author={Guo, Ziyu and Li, Xianzhi and Heng, Pheng Ann},
  journal={arXiv preprint arXiv:2302.14007},
  year={2023}
}
@article{zhang2022learning,
  title={Learning 3D Representations from 2D Pre-trained Models via Image-to-Point Masked Autoencoders},
  author={Zhang, Renrui and Wang, Liuhui and Qiao, Yu and Gao, Peng and Li, Hongsheng},
  journal={arXiv preprint arXiv:2212.06785},
  year={2022}
}
@article{zhang2021dspoint,
  title={DSPoint: Dual-scale point cloud recognition with high-frequency fusion},
  author={Zhang, Renrui and Zeng, Ziyao and Guo, Ziyu and Gao, Xinben and Fu, Kexue and Shi, Jianbo},
  journal={arXiv preprint arXiv:2111.10332},
  year={2021}
}
@article{zhu2022pointclip,
  title={PointCLIP V2: Adapting CLIP for Powerful 3D Open-world Learning},
  author={Zhu, Xiangyang and Zhang, Renrui and He, Bowei and Zeng, Ziyao and Zhang, Shanghang and Gao, Peng},
  journal={arXiv preprint arXiv:2211.11682},
  year={2022}
}
@inproceedings{tatarchenko2018tangent,
  title={Tangent convolutions for dense prediction in 3d},
  author={Tatarchenko, Maxim and Park, Jaesik and Koltun, Vladlen and Zhou, Qian-Yi},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3887--3896},
  year={2018}
}
@inproceedings{yang2018foldingnet,
  title={Foldingnet: Point cloud auto-encoder via deep grid deformation},
  author={Yang, Yaoqing and Feng, Chen and Shen, Yiru and Tian, Dong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={206--215},
  year={2018}
}
@inproceedings{zhang2023nearest,
  title={Nearest Neighbors Meet Deep Neural Networks for Point Cloud Analysis},
  author={Zhang, Renrui and Wang, Liuhui and Guo, Ziyu and Shi, Jianbo},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={1246--1255},
  year={2023}
}
@inproceedings{xu2021learning,
  title={Learning geometry-disentangled representation for complementary understanding of 3d object point cloud},
  author={Xu, Mutian and Zhang, Junhao and Zhou, Zhipeng and Xu, Mingye and Qi, Xiaojuan and Qiao, Yu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={4},
  pages={3056--3064},
  year={2021}
}
@inproceedings{riegler2017octnet,
  title={Octnet: Learning deep 3d representations at high resolutions},
  author={Riegler, Gernot and Osman Ulusoy, Ali and Geiger, Andreas},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3577--3586},
  year={2017}
}
@article{qi2017pointnet++,
  title={Pointnet++: Deep hierarchical feature learning on point sets in a metric space},
  author={Qi, Charles R and Yi, Li and Su, Hao and Guibas, Leonidas J},
  journal={arXiv preprint arXiv:1706.02413},
  year={2017}
}
@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}
@inproceedings{su2015multi,
  title={Multi-view convolutional neural networks for 3d shape recognition},
  author={Su, Hang and Maji, Subhransu and Kalogerakis, Evangelos and Learned-Miller, Erik},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={945--953},
  year={2015}
}
@inproceedings{gehring2017convolutional,
  title={Convolutional sequence to sequence learning},
  author={Gehring, Jonas and Auli, Michael and Grangier, David and Yarats, Denis and Dauphin, Yann N},
  booktitle={International conference on machine learning},
  pages={1243--1252},
  year={2017},
  organization={PMLR}
}
@article{gao2021clip,
  title={Clip-adapter: Better vision-language models with feature adapters},
  author={Gao, Peng and Geng, Shijie and Zhang, Renrui and Ma, Teli and Fang, Rongyao and Zhang, Yongfeng and Li, Hongsheng and Qiao, Yu},
  journal={arXiv preprint arXiv:2110.04544},
  year={2021}
}
@article{zhou2022learning,
  title={Learning to prompt for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  journal={International Journal of Computer Vision},
  volume={130},
  number={9},
  pages={2337--2348},
  year={2022},
  publisher={Springer}
}
@inproceedings{chen2023revisiting,
  title={Revisiting Multimodal Representation in Contrastive Learning: from Patch and Token Embeddings to Finite Discrete Tokens},
  author={Chen, Yuxiao and Yuan, Jianbo and Tian, Yu and Geng, Shijie and Li, Xinyu and Zhou, Ding and Metaxas, Dimitris N. and Yang, Hongxia},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2023}
}
@inproceedings{lin2022frozen,
  title={Frozen clip models are efficient video learners},
  author={Lin, Ziyi and Geng, Shijie and Zhang, Renrui and Gao, Peng and de Melo, Gerard and Wang, Xiaogang and Dai, Jifeng and Qiao, Yu and Li, Hongsheng},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXV},
  pages={388--404},
  year={2022},
  organization={Springer}
}
@inproceedings{
geng2023hiclip,
title={Hi{CLIP}: Contrastive Language-Image Pretraining with Hierarchy-aware Attention},
author={Shijie Geng and Jianbo Yuan and Yu Tian and Yuxiao Chen and Yongfeng Zhang},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=0eTTKOOOQkV}
}
@article{zhang2022monodetr,
  title={Monodetr: Depth-aware transformer for monocular 3d object detection},
  author={Zhang, Renrui and Qiu, Han and Wang, Tai and Xu, Xuanzhuo and Guo, Ziyu and Qiao, Yu and Gao, Peng and Li, Hongsheng},
  journal={arXiv preprint arXiv:2203.13310},
  year={2022}
}
@inproceedings{zhang2022can,
  title={Can Language Understand Depth?},
  author={Zhang, Renrui and Zeng, Ziyao and Guo, Ziyu and Li, Yafeng},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={6868--6874},
  year={2022}
}
@article{huang2022tig,
  title={TiG-BEV: Multi-view BEV 3D Object Detection via Target Inner-Geometry Learning},
  author={Huang, Peixiang and Liu, Li and Zhang, Renrui and Zhang, Song and Xu, Xinli and Wang, Baichao and Liu, Guoyi},
  journal={arXiv preprint arXiv:2212.13979},
  year={2022}
}
@article{zhang2023prompt,
  title={Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong Few-shot Learners},
  author={Zhang, Renrui and Hu, Xiangfei and Li, Bohao and Huang, Siyuan and Deng, Hanqiu and Li, Hongsheng and Qiao, Yu and Gao, Peng},
  journal={arXiv preprint arXiv:2303.02151},
  year={2023}
}
@article{chu2021conditional,
  title={Conditional positional encodings for vision transformers},
  author={Chu, Xiangxiang and Tian, Zhi and Zhang, Bo and Wang, Xinlong and Wei, Xiaolin and Xia, Huaxia and Shen, Chunhua},
  journal={arXiv preprint arXiv:2102.10882},
  year={2021}
}
@article{tancik2020fourier,
  title={Fourier features let networks learn high frequency functions in low dimensional domains},
  author={Tancik, Matthew and Srinivasan, Pratul and Mildenhall, Ben and Fridovich-Keil, Sara and Raghavan, Nithin and Singhal, Utkarsh and Ramamoorthi, Ravi and Barron, Jonathan and Ng, Ren},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7537--7547},
  year={2020}
}
@article{zhang2022point,
  title={Point-M2AE: Multi-scale Masked Autoencoders for Hierarchical Point Cloud Pre-training},
  author={Zhang, Renrui and Guo, Ziyu and Gao, Peng and Fang, Rongyao and Zhao, Bin and Wang, Dong and Qiao, Yu and Li, Hongsheng},
  journal={arXiv preprint arXiv:2205.14401},
  year={2022}
}
@inproceedings{rahaman2019spectral,
  title={On the spectral bias of neural networks},
  author={Rahaman, Nasim and Baratin, Aristide and Arpit, Devansh and Draxler, Felix and Lin, Min and Hamprecht, Fred and Bengio, Yoshua and Courville, Aaron},
  booktitle={International Conference on Machine Learning},
  pages={5301--5310},
  year={2019},
  organization={PMLR}
}
@article{mildenhall2021nerf,
  title={Nerf: Representing scenes as neural radiance fields for view synthesis},
  author={Mildenhall, Ben and Srinivasan, Pratul P and Tancik, Matthew and Barron, Jonathan T and Ramamoorthi, Ravi and Ng, Ren},
  journal={Communications of the ACM},
  volume={65},
  number={1},
  pages={99--106},
  year={2021},
  publisher={ACM New York, NY, USA}
}
@article{qian2022pointnext,
  title={PointNeXt: Revisiting PointNet++ with Improved Training and Scaling Strategies},
  author={Qian, Guocheng and Li, Yuchen and Peng, Houwen and Mai, Jinjie and Hammoud, Hasan Abed Al Kader and Elhoseiny, Mohamed and Ghanem, Bernard},
  journal={arXiv preprint arXiv:2206.04670},
  year={2022}
}
@inproceedings{wu2019pointconv,
  title={Pointconv: Deep convolutional networks on 3d point clouds},
  author={Wu, Wenxuan and Qi, Zhongang and Fuxin, Li},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9621--9630},
  year={2019}
}
@article{hermosilla2018monte,
  title={Monte carlo convolution for learning on non-uniformly sampled point clouds},
  author={Hermosilla, Pedro and Ritschel, Tobias and V{\'a}zquez, Pere-Pau and Vinacua, {\`A}lvar and Ropinski, Timo},
  journal={ACM Transactions on Graphics (TOG)},
  volume={37},
  number={6},
  pages={1--12},
  year={2018},
  publisher={ACM New York, NY, USA}
}
@inproceedings{zhao2019pointweb,
  title={Pointweb: Enhancing local neighborhood features for point cloud processing},
  author={Zhao, Hengshuang and Jiang, Li and Fu, Chi-Wing and Jia, Jiaya},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5565--5573},
  year={2019}
}
@inproceedings{landrieu2018large,
  title={Large-scale point cloud semantic segmentation with superpoint graphs},
  author={Landrieu, Loic and Simonovsky, Martin},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4558--4567},
  year={2018}
}
@inproceedings{te2018rgcnn,
  title={Rgcnn: Regularized graph cnn for point cloud segmentation},
  author={Te, Gusi and Hu, Wei and Zheng, Amin and Guo, Zongming},
  booktitle={Proceedings of the 26th ACM international conference on Multimedia},
  pages={746--754},
  year={2018}
}
@article{krizhevsky2017imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Communications of the ACM},
  volume={60},
  number={6},
  pages={84--90},
  year={2017},
  publisher={AcM New York, NY, USA}
}
@inproceedings{hamdi2021mvtn,
  title={Mvtn: Multi-view transformation network for 3d shape recognition},
  author={Hamdi, Abdullah and Giancola, Silvio and Ghanem, Bernard},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1--11},
  year={2021}
}
@inproceedings{zhao2021point,
  title={Point transformer},
  author={Zhao, Hengshuang and Jiang, Li and Jia, Jiaya and Torr, Philip HS and Koltun, Vladlen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={16259--16268},
  year={2021}
}
@inproceedings{lai2022stratified,
  title={Stratified Transformer for 3D Point Cloud Segmentation},
  author={Lai, Xin and Liu, Jianhui and Jiang, Li and Wang, Liwei and Zhao, Hengshuang and Liu, Shu and Qi, Xiaojuan and Jia, Jiaya},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8500--8509},
  year={2022}
}
@inproceedings{duan2019structural,
  title={Structural relational reasoning of point clouds},
  author={Duan, Yueqi and Zheng, Yu and Lu, Jiwen and Zhou, Jie and Tian, Qi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={949--958},
  year={2019}
}
@inproceedings{Radford2018ImprovingLU,
  title={Improving Language Understanding by Generative Pre-Training},
  author={Alec Radford and Karthik Narasimhan},
  year={2018}
}
@article{dgcnn,
  title={Dynamic graph cnn for learning on point clouds},
  author={Wang, Yue and Sun, Yongbin and Liu, Ziwei and Sarma, Sanjay E and Bronstein, Michael M and Solomon, Justin M},
  journal={Acm Transactions On Graphics (tog)},
  volume={38},
  number={5},
  pages={1--12},
  year={2019},
  publisher={ACM New York, NY, USA}
}
@inproceedings{rscnn,
  title={Relation-shape convolutional neural network for point cloud analysis},
  author={Liu, Yongcheng and Fan, Bin and Xiang, Shiming and Pan, Chunhong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8895--8904},
  year={2019}
}
@article{guo2021pct,
  title={PCT: Point cloud transformer},
  author={Guo, Meng-Hao and Cai, Jun-Xiong and Liu, Zheng-Ning and Mu, Tai-Jiang and Martin, Ralph R and Hu, Shi-Min},
  journal={Computational Visual Media},
  volume={7},
  number={2},
  pages={187--199},
  year={2021},
  publisher={Springer}
}

@article{curvenet,
  title={Walk in the Cloud: Learning Curves for Point Clouds Shape Analysis},
  author={Xiang, Tiange and Zhang, Chaoyi and Song, Yang and Yu, Jianhui and Cai, Weidong},
  journal={arXiv preprint arXiv:2105.01288},
  year={2021}
}
@inproceedings{densepoint,
  title={Densepoint: Learning densely contextual representation for efficient point cloud processing},
  author={Liu, Yongcheng and Fan, Bin and Meng, Gaofeng and Lu, Jiwen and Xiang, Shiming and Pan, Chunhong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5239--5248},
  year={2019}
}
@inproceedings{modelnet40,
  title={3d shapenets: A deep representation for volumetric shapes},
  author={Wu, Zhirong and Song, Shuran and Khosla, Aditya and Yu, Fisher and Zhang, Linguang and Tang, Xiaoou and Xiao, Jianxiong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1912--1920},
  year={2015}
}

@article{shapenetpart,
  title={A scalable active framework for region annotation in 3d shape collections},
  author={Yi, Li and Kim, Vladimir G and Ceylan, Duygu and Shen, I-Chao and Yan, Mengyan and Su, Hao and Lu, Cewu and Huang, Qixing and Sheffer, Alla and Guibas, Leonidas},
  journal={ACM Transactions on Graphics (ToG)},
  volume={35},
  number={6},
  pages={1--12},
  year={2016},
  publisher={ACM New York, NY, USA}
}
@inproceedings{transformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}
@inproceedings{scanobjectnn,
  title={Revisiting point cloud classification: A new benchmark dataset and classification model on real-world data},
  author={Uy, Mikaela Angelina and Pham, Quang-Hieu and Hua, Binh-Son and Nguyen, Thanh and Yeung, Sai-Kit},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1588--1597},
  year={2019}
}
@InProceedings{3detr,
    author    = {Misra, Ishan and Girdhar, Rohit and Joulin, Armand},
    title     = {An End-to-End Transformer Model for 3D Object Detection},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {2906-2917}
}
@inproceedings{votenet,
  title={VoteNet: A deep learning label fusion method for multi-atlas segmentation},
  author={Ding, Zhipeng and Han, Xu and Niethammer, Marc},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={202--210},
  year={2019},
  organization={Springer}
}
@inproceedings{ScanNetV2,
  title={Scannet: Richly-annotated 3d reconstructions of indoor scenes},
  author={Dai, Angela and Chang, Angel X and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Nie{\ss}ner, Matthias},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5828--5839},
  year={2017}
}
@inproceedings{sun_rgb,
  title={Sun rgb-d: A rgb-d scene understanding benchmark suite},
  author={Song, Shuran and Lichtenberg, Samuel P and Xiao, Jianxiong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={567--576},
  year={2015}
}
@article{3dmfv,
  title={3dmfv: Three-dimensional point cloud classification in real-time using convolutional neural networks},
  author={Ben-Shabat, Yizhak and Lindenbaum, Michael and Fischer, Anath},
  journal={IEEE Robotics and Automation Letters},
  volume={3},
  number={4},
  pages={3145--3152},
  year={2018},
  publisher={IEEE}
}
@inproceedings{xu2018spidercnn,
  title={Spidercnn: Deep learning on point sets with parameterized convolutional filters},
  author={Xu, Yifan and Fan, Tianqi and Xu, Mingye and Zeng, Long and Qiao, Yu},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={87--102},
  year={2018}
}
@article{li2018pointcnn,
  title={Pointcnn: Convolution on x-transformed points},
  author={Li, Yangyan and Bu, Rui and Sun, Mingchao and Wu, Wei and Di, Xinhan and Chen, Baoquan},
  journal={Advances in neural information processing systems},
  volume={31},
  pages={820--830},
  year={2018}
}
@article{gbnet,
  title={Geometric back-projection network for point cloud classification},
  author={Qiu, Shi and Anwar, Saeed and Barnes, Nick},
  journal={IEEE Transactions on Multimedia},
  year={2021},
  publisher={IEEE}
}
@inproceedings{drnet,
  title={Dense-resolution network for point cloud classification and segmentation},
  author={Qiu, Shi and Anwar, Saeed and Barnes, Nick},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={3813--3822},
  year={2021}
}
@article{simpleview,
  title={Revisiting Point Cloud Shape Classification with a Simple and Effective Baseline},
  author={Goyal, Ankit and Law, Hei and Liu, Bowei and Newell, Alejandro and Deng, Jia},
  journal={arXiv preprint arXiv:2106.05304},
  year={2021}
}

@article{pointmlp,
  title={Rethinking network design and local geometry in point cloud: A simple residual mlp framework},
  author={Ma, Xu and Qin, Can and You, Haoxuan and Ran, Haoxi and Fu, Yun},
  journal={arXiv preprint arXiv:2202.07123},
  year={2022}
}

@inproceedings{chen2017multi,
  title={Multi-view 3d object detection network for autonomous driving},
  author={Chen, Xiaozhi and Ma, Huimin and Wan, Ji and Li, Bo and Xia, Tian},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={1907--1915},
  year={2017}
}
@inproceedings{qi2018frustum,
  title={Frustum pointnets for 3d object detection from rgb-d data},
  author={Qi, Charles R and Liu, Wei and Wu, Chenxia and Su, Hao and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={918--927},
  year={2018}
}
@article{aldoma2012tutorial,
  title={Tutorial: Point cloud library: Three-dimensional object recognition and 6 dof pose estimation},
  author={Aldoma, Aitor and Marton, Zoltan-Csaba and Tombari, Federico and Wohlkinger, Walter and Potthast, Christian and Zeisl, Bernhard and Rusu, Radu Bogdan and Gedikli, Suat and Vincze, Markus},
  journal={IEEE Robotics \& Automation Magazine},
  volume={19},
  number={3},
  pages={80--91},
  year={2012},
  publisher={IEEE}
}
@inproceedings{rusu2009close,
  title={Close-range scene segmentation and reconstruction of 3D point cloud maps for mobile manipulation in domestic environments},
  author={Rusu, Radu Bogdan and Blodow, Nico and Marton, Zoltan Csaba and Beetz, Michael},
  booktitle={2009 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={1--6},
  year={2009},
  organization={IEEE}
}
@article{correll2016analysis,
  title={Analysis and observations from the first amazon picking challenge},
  author={Correll, Nikolaus and Bekris, Kostas E and Berenson, Dmitry and Brock, Oliver and Causo, Albert and Hauser, Kris and Okada, Kei and Rodriguez, Alberto and Romano, Joseph M and Wurman, Peter R},
  journal={IEEE Transactions on Automation Science and Engineering},
  volume={15},
  number={1},
  pages={172--188},
  year={2016},
  publisher={IEEE}
}
@inproceedings{mousavian20196,
  title={6-dof graspnet: Variational grasp generation for object manipulation},
  author={Mousavian, Arsalan and Eppner, Clemens and Fox, Dieter},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2901--2910},
  year={2019}
}
@article{navarro2010pedestrian,
  title={Pedestrian detection and tracking using three-dimensional ladar data},
  author={Navarro-Serment, Luis E and Mertz, Christoph and Hebert, Martial},
  journal={The International Journal of Robotics Research},
  volume={29},
  number={12},
  pages={1516--1528},
  year={2010},
  publisher={SAGE Publications Sage UK: London, England}
}
@inproceedings{kidono2011pedestrian,
  title={Pedestrian recognition using high-definition LIDAR},
  author={Kidono, Kiyosumi and Miyasaka, Takeo and Watanabe, Akihiro and Naito, Takashi and Miura, Jun},
  booktitle={2011 IEEE Intelligent Vehicles Symposium (IV)},
  pages={405--410},
  year={2011},
  organization={IEEE}
}
@inproceedings{xu2021paconv,
  title={PAConv: Position Adaptive Convolution with Dynamic Kernel Assembling on Point Clouds},
  author={Xu, Mutian and Ding, Runyu and Zhao, Hengshuang and Qi, Xiaojuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3173--3182},
  year={2021}
}
@article{pvcnn,
  title={Point-voxel cnn for efficient 3d deep learning},
  author={Liu, Zhijian and Tang, Haotian and Lin, Yujun and Han, Song},
  journal={arXiv preprint arXiv:1907.03739},
  year={2019}
}
@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}
@inproceedings{wu20153d,
  title={3d shapenets: A deep representation for volumetric shapes},
  author={Wu, Zhirong and Song, Shuran and Khosla, Aditya and Yu, Fisher and Zhang, Linguang and Tang, Xiaoou and Xiao, Jianxiong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1912--1920},
  year={2015}
}
@inproceedings{thomas2019kpconv,
  title={Kpconv: Flexible and deformable convolution for point clouds},
  author={Thomas, Hugues and Qi, Charles R and Deschaud, Jean-Emmanuel and Marcotegui, Beatriz and Goulette, Fran{\c{c}}ois and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6411--6420},
  year={2019}
}
@article{zhang2021tip,
  title={Tip-Adapter: Training-free CLIP-Adapter for Better Vision-Language Modeling},
  author={Zhang, Renrui and Fang, Rongyao and Gao, Peng and Zhang, Wei and Li, Kunchang and Dai, Jifeng and Qiao, Yu and Li, Hongsheng},
  journal={arXiv preprint arXiv:2111.03930},
  year={2021}
}
@inproceedings{wu2016learning,
  title={Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling},
  author={Wu, Jiajun and Zhang, Chengkai and Xue, Tianfan and Freeman, William T and Tenenbaum, Joshua B},
  booktitle={Proceedings of the 30th International Conference on Neural Information Processing Systems},
  pages={82--90},
  year={2016}
}

@article{sharma2020self,
  title={Self-supervised few-shot learning on point clouds},
  author={Sharma, Charu and Kaul, Manohar},
  journal={arXiv preprint arXiv:2009.14168},
  year={2020}
}

@inproceedings{verdoja2017fast,
  title={Fast 3D point cloud segmentation using supervoxels with geometry and color for 3D scene understanding},
  author={Verdoja, Francesco and Thomas, Diego and Sugimoto, Akihiro},
  booktitle={2017 IEEE International Conference on Multimedia and Expo (ICME)},
  pages={1285--1290},
  year={2017},
  organization={IEEE}
}
@article{chen2019deep,
  title={Deep learning approach to point cloud scene understanding for automated scan to 3D reconstruction},
  author={Chen, Jingdao and Kira, Zsolt and Cho, Yong K},
  journal={Journal of Computing in Civil Engineering},
  volume={33},
  number={4},
  pages={04019027},
  year={2019},
  publisher={American Society of Civil Engineers}
}
@inproceedings{zheng2013beyond,
  title={Beyond point clouds: Scene understanding by reasoning geometry and physics},
  author={Zheng, Bo and Zhao, Yibiao and Yu, Joey C and Ikeuchi, Katsushi and Zhu, Song-Chun},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3127--3134},
  year={2013}
}
@article{orhan2018simple,
  title={A simple cache model for image recognition},
  author={Orhan, A Emin},
  journal={arXiv preprint arXiv:1805.08709},
  year={2018}
}
@article{khandelwal2019generalization,
  title={Generalization through memorization: Nearest neighbor language models},
  author={Khandelwal, Urvashi and Levy, Omer and Jurafsky, Dan and Zettlemoyer, Luke and Lewis, Mike},
  journal={arXiv preprint arXiv:1911.00172},
  year={2019}
}
@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1126--1135},
  year={2017},
  organization={PMLR}
}
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@book{cristianini2000introduction,
  title={An introduction to support vector machines and other kernel-based learning methods},
  author={Cristianini, Nello and Shawe-Taylor, John and others},
  year={2000},
  publisher={Cambridge university press}
}

@article{safavian1991survey,
  title={A survey of decision tree classifier methodology},
  author={Safavian, S Rasoul and Landgrebe, David},
  journal={IEEE transactions on systems, man, and cybernetics},
  volume={21},
  number={3},
  pages={660--674},
  year={1991},
  publisher={IEEE}
}

@article{friedman2001greedy,
  title={Greedy function approximation: a gradient boosting machine},
  author={Friedman, Jerome H},
  journal={Annals of statistics},
  pages={1189--1232},
  year={2001},
  publisher={JSTOR}
}


@inproceedings{dai20183dmv,
  title={3dmv: Joint 3d-multi-view prediction for 3d semantic scene segmentation},
  author={Dai, Angela and Nie{\ss}ner, Matthias},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={452--468},
  year={2018}
}

@article{zhao2019dar,
  title={DAR-Net: Dynamic aggregation network for semantic scene segmentation},
  author={Zhao, Zongyue and Liu, Min and Ramani, Karthik},
  journal={arXiv preprint arXiv:1907.12022},
  year={2019}
}

@inproceedings{he2020structure,
  title={Structure aware single-stage 3d object detection from point cloud},
  author={He, Chenhang and Zeng, Hui and Huang, Jianqiang and Hua, Xian-Sheng and Zhang, Lei},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11873--11882},
  year={2020}
}

@inproceedings{meng2019vv,
  title={Vv-net: Voxel vae net with group convolutions for point cloud segmentation},
  author={Meng, Hsien-Yu and Gao, Lin and Lai, Yu-Kun and Manocha, Dinesh},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={8500--8508},
  year={2019}
}