% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
% \begin{table*}[t!]
%     \centering
%     \resizebox{\textwidth}{!}{%
%     \begin{tabular}{l|rr|c|cccccccc}
%     \toprule
%     Model                            &\makecell{Learnable\\Params} &\makecell{Total\\Params}  & Avg              & NAT               & SOC               & LAN               & TXT               & IMG               & NO                & G1-6              & G7-12             \\ \midrule
%     Random Choice~\cite{scienceqa}   & -                            & -                   & 39.83            & 40.28             & 46.13             & 29.25             & 47.45             & 40.08             & 33.66             & 39.35             & 40.67              \\
%     Human~\cite{scienceqa}           & -                            & -                   & 88.40            & 90.23             & 84.97             & 87.48             & 89.60             & 87.50             & 88.10             & 91.59             & 82.42              \\ \midrule
%     MCAN \cite{yu2019mcan}           & 95M                          & 95M                 & 54.54            & 56.08             & 46.23             & 58.09             & 59.43             & 51.17             & 55.40             & 51.65             & 59.72              \\
%     Top-Down \cite{Anderson2017up}   & 70M                          & 70M                 & 59.02            & 59.50             & 54.33             & 61.82             & 62.90             & 54.88             & 59.79             & 57.27             & 62.16              \\
%     BAN \cite{Kim2018}               & 112M                         & 112M                & 59.37            & 60.88             & 46.57             & 66.64             & 62.61             & 52.60             & 65.51             & 56.83             & 63.94              \\
%     DFAF \cite{gao2019dynamic}       & 74M                          & 74M                 & 60.72            & 64.03             & 48.82             & 63.55             & 65.88             & 54.49             & 64.11             & 57.12             & 67.17              \\
%     ViLT \cite{pmlr-v139-kim21k}     & 113M                         & 113M                & 61.14            & 60.48             & 63.89             & 60.27             & 63.20             & 61.38             & 57.00             & 60.72             & 61.90              \\
%     Patch-TRM \cite{lu2021iconqa}    & 90M                          & 90M                 & 61.42            & 65.19             & 46.79             & 65.55             & 66.96             & 55.28             & 64.95             & 58.04             & 67.50              \\
%     VisualBERT \cite{li2019visualbert,li2020does} & 111M            & 111M                & 61.87            & 59.33             & 69.18             & 61.18             & 62.71             & 62.17             & 58.54             & 62.96             & 59.92              \\
%     UnifiedQA \cite{khashabi2020unifiedqa} & 223M                   & 223M                & 70.12            & 68.16             & 69.18             & 74.91             & 63.78             & 61.38             & 77.84             & 72.98             & 65.00              \\
%     UnifiedQA (CoT)                  & 223M                         & 223M                & 74.11            & 71.00             & 76.04             & 78.91             & 66.42             & 66.53             & 81.81             & 77.06             & 68.82              \\
%     GPT-3 \cite{chen2020big}         & -                            & 175B                & 74.04            & 75.04             & 66.59             & 78.00             & 74.24             & 65.74             & 79.58             & 76.36             & 69.87              \\
%     GPT-3 (CoT)                      & -                            & 175B                & 75.17            & 75.44             & 70.87             & 78.09             & 74.68             & 67.43             & 79.93             & 78.23             & 69.68              \\ 
%     MM-COT$_T$ \cite{zhang2023multicot} &223M                       & 223M                & 70.53            & 71.09             & 70.75             & 69.18             & 71.16             & 65.84             & 71.57             & 71.00             & 69.68             \\ 
%     MM-COT \cite{zhang2023multicot}  & 223M                         & 283M                & 84.91            & 87.52             & 77.17             & 85.82             & 87.88             & 82.90             & 86.83             & 84.65             & 85.37              \\ \midrule
%     \textbf{LLaMA-Adapter$_T$ (Ours)} & \textbf{1.2M}               & 6.7B                & \textbf{78.31}   & \textbf{79.00}    & \textbf{73.79}    & \textbf{80.55}    & \textbf{78.30}    & \textbf{70.35}    & \textbf{83.14}    & \textbf{79.77}    & \textbf{75.68}    \\
%     \textbf{LLaMA-Adapter (Ours)}    & \textbf{1.8M}                & 7B                  & \textbf{85.19}   & \textbf{84.37}    & \textbf{88.30}    & \textbf{84.36}    & \textbf{83.72}    & \textbf{80.32}    & \textbf{86.90}    & \textbf{85.83}    & \textbf{84.05}    \\ \bottomrule
%     \end{tabular}%
%     }
%     \caption{Question answering accuracy (\%) on ScienceQA test set. Question classes: NAT = natural science, SOC = social science, LAN = language science, TXT = text context, IMG = image context, NO = no context, G1-6 = grades 1-6, G7-12 = grades 7-12.}
%     \label{tab:scienceqa}
%     \end{table*}

\begin{table*}[t!]
    \centering
    % \resizebox{\textwidth}{!}{%
    \begin{tabular}{l|r|c|cccccccc}
    \toprule
    Model                            &\makecell{Tuned\\Params}  & Avg              & NAT               & SOC               & LAN               & TXT               & IMG               & NO                & G1-6              & G7-12             \\ \midrule
    Random Choice~\cite{scienceqa}   & -                                              & 39.83            & 40.28             & 46.13             & 29.25             & 47.45             & 40.08             & 33.66             & 39.35             & 40.67              \\
    Human~\cite{scienceqa}                                    & -                   & 88.40            & 90.23             & 84.97             & 87.48             & 89.60             & 87.50             & 88.10             & 91.59             & 82.42              \\ \midrule
    MCAN \cite{yu2019mcan}           & 95M                                          & 54.54            & 56.08             & 46.23             & 58.09             & 59.43             & 51.17             & 55.40             & 51.65             & 59.72              \\
    Top-Down \cite{Anderson2017up}   & 70M                                        & 59.02            & 59.50             & 54.33             & 61.82             & 62.90             & 54.88             & 59.79             & 57.27             & 62.16              \\
    BAN \cite{Kim2018}                                    & 112M                & 59.37            & 60.88             & 46.57             & 66.64             & 62.61             & 52.60             & 65.51             & 56.83             & 63.94              \\
    DFAF \cite{gao2019dynamic}                               & 74M                 & 60.72            & 64.03             & 48.82             & 63.55             & 65.88             & 54.49             & 64.11             & 57.12             & 67.17              \\
    ViLT \cite{pmlr-v139-kim21k}                            & 113M                & 61.14            & 60.48             & 63.89             & 60.27             & 63.20             & 61.38             & 57.00             & 60.72             & 61.90              \\
    Patch-TRM \cite{lu2021iconqa}                       & 90M                 & 61.42            & 65.19             & 46.79             & 65.55             & 66.96             & 55.28             & 64.95             & 58.04             & 67.50              \\
    VisualBERT \cite{li2019visualbert,li2020does}           & 111M                & 61.87            & 59.33             & 69.18             & 61.18             & 62.71             & 62.17             & 58.54             & 62.96             & 59.92              \\
    UnifiedQA \cite{khashabi2020unifiedqa}               & 223M                & 70.12            & 68.16             & 69.18             & 74.91             & 63.78             & 61.38             & 77.84             & 72.98             & 65.00              \\
    UnifiedQA (CoT)                                        & 223M                & 74.11            & 71.00             & 76.04             & 78.91             & 66.42             & 66.53             & 81.81             & 77.06             & 68.82              \\
    GPT-3 \cite{brown2020language}         & 0M                                         & 74.04            & 75.04             & 66.59             & 78.00             & 74.24             & 65.74             & 79.58             & 76.36             & 69.87              \\
    GPT-3 (CoT)                      & 0M                                    & 75.17            & 75.44             & 70.87             & 78.09             & 74.68             & 67.43             & 79.93             & 78.23             & 69.68              \\ 
    MM-COT$_T$                     & 223M                & 70.53            & 71.09             & 70.75             & 69.18             & 71.16             & 65.84             & 71.57             & 71.00             & 69.68             \\ 
    MM-COT \cite{zhang2023multicot}  & 223M                                       & 84.91            & 87.52             & 77.17             & 85.82             & 87.88             & 82.90             & 86.83             & 84.65             & 85.37              \\ \midrule
    \textbf{LLaMA-Adapter$_T$} & \textbf{1.2M}                             & \textbf{78.31}   & \textbf{79.00}    & \textbf{73.79}    & \textbf{80.55}    & \textbf{78.30}    & \textbf{70.35}    & \textbf{83.14}    & \textbf{79.77}    & \textbf{75.68}    \\
    \textbf{LLaMA-Adapter}    & \textbf{1.8M}                                & \textbf{85.19}   & \textbf{84.37}    & \textbf{88.30}    & \textbf{84.36}    & \textbf{83.72}    & \textbf{80.32}    & \textbf{86.90}    & \textbf{85.83}    & \textbf{84.05}    \\ \bottomrule
    \end{tabular}%
    % }
    \caption{\textbf{Question Answering Accuracy (\%) on ScienceQA's~\cite{scienceqa} test set.} We report the accuracy of different question classes, including natural science, social science, language science, text context, image context, no context, grades 1-6, and grades 7-12. GPT-3~\cite{brown2020language} of 175B parameters conducts zero-shot answering. LLaMA-Adapter$_T$ and MM-COT$_T$ denote their single-modal variants with text-only input.}
    \vspace{0.1cm}
    \label{tab:scienceqa}
    \end{table*}