@article{SHINTANI2013286,
title = {The comparative effect of direct written corrective feedback and metalinguistic explanation on learners’ explicit and implicit knowledge of the English indefinite article},
journal = {Journal of Second Language Writing},
volume = {22},
number = {3},
pages = {286-306},
year = {2013},
issn = {1060-3743},
doi = {https://doi.org/10.1016/j.jslw.2013.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S1060374313000271},
author = {Natsuko Shintani and Rod Ellis},
keywords = {Explicit instruction, Written corrective feedback, Implicit, Explicit knowledge, Metalinguistic explanation, Eye-tracking},
abstract = {The study extends current work on written error feedback in writing in two ways. First, it examines whether it has an effect on adult ESL learners’ L2 implicit and explicit knowledge. Second, the study compares the effect of one common type of feedback – direct corrective feedback (DCF) – with an alternative type of error feedback – the provision of metalinguistic explanation (ME). The effect of these two types of error feedback was measured by an Error Correction Test (ECT) and by examining the accuracy of use of the target feature (the English indefinite article) in both a revised text and in new pieces of writing by 49 low-intermediate ESL students in an intensive language programme in the United States. In addition, eye-tracking data and self-reports elicited from the learners provided information about the use that they made of the DCF and ME. It was found that the DCF had no effect on accurate use of the target feature suggesting that it benefited neither implicit nor explicit knowledge. In contrast, the ME led to gains in accuracy in the ECT and in a new piece of writing completed immediately after the treatment but not in a second new text completed two weeks later. These results are interpreted as indicating that the ME helped to develop learners’ L2 explicit knowledge but that the effect was not durable and thus probably had no effect on their implicit knowledge. Learners’ self-reports indicate that the learners receiving the DCF did not develop awareness of the rule whereas those receiving the ME did and were able to use it when revising their original text. These findings are discussed from the perspective of both SLA theory and language pedagogy and suggestions for further research are put forward.}
}


@article{sollaci2004introduction,
  title={The introduction, methods, results, and discussion (IMRAD) structure: a fifty-year survey},
  author={Sollaci, Luciana B and Pereira, Mauricio G},
  journal={Journal of the medical library association},
  volume={92},
  number={3},
  pages={364},
  year={2004},
  publisher={Medical Library Association}
}

@article{Majumder2022,
  author    = {Suvodeep Majumder and
               Stanislas Lauly and
               Maria Nadejde and
               Marcello Federico and
               Georgiana Dinu},
  title     = {A baseline revisited: Pushing the limits of multi-segment models for
               context-aware translation},
  journal   = {CoRR},
  volume    = {abs/2210.10906},
  year      = {2022},
  url       = {https://doi.org/10.48550/arXiv.2210.10906},
  doi       = {10.48550/arXiv.2210.10906},
  eprinttype = {arXiv},
  eprint    = {2210.10906},
  timestamp = {Tue, 25 Oct 2022 14:25:08 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2210-10906.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{li-etal-2020-multi-encoder,
    title = "Does Multi-Encoder Help? A Case Study on Context-Aware Neural Machine Translation",
    author = "Li, Bei  and
      Liu, Hui  and
      Wang, Ziyang  and
      Jiang, Yufan  and
      Xiao, Tong  and
      Zhu, Jingbo  and
      Liu, Tongran  and
      Li, Changliang",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.322",
    doi = "10.18653/v1/2020.acl-main.322",
    pages = "3512--3518",
    abstract = "In encoder-decoder neural models, multiple encoders are in general used to represent the contextual information in addition to the individual sentence. In this paper, we investigate multi-encoder approaches in document-level neural machine translation (NMT). Surprisingly, we find that the context encoder does not only encode the surrounding sentences but also behaves as a noise generator. This makes us rethink the real benefits of multi-encoder in context-aware translation - some of the improvements come from robust training. We compare several methods that introduce noise and/or well-tuned dropout setup into the training of these encoders. Experimental results show that noisy training plays an important role in multi-encoder-based NMT, especially when the training data is small. Also, we establish a new state-of-the-art on IWSLT Fr-En task by careful use of noise generation and dropout methods.",
}
@article{SAMPSON2012494,
title = {“Coded and uncoded error feedback: Effects on error frequencies in adult Colombian EFL learners' writing”},
journal = {System},
volume = {40},
number = {4},
pages = {494-504},
year = {2012},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2012.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X12000772},
author = {Andrew Sampson},
keywords = {Feedback, Correction, SLA, Error, Writing, Codes},
abstract = {This paper reports on a small-scale study into the effects of uncoded correction (writing the correct forms above each error) and coded annotations (writing symbols that encourage learners to self-correct) on Colombian university-level EFL learners' written work. The study finds that while both coded annotations and uncoded correction appear to aid learners in a) recognising and correcting errors in their written work, and b) producing correct forms in subsequent pieces of work, coded feedback seems to be more effective at this, possibly as a result of the increased cognitive engagement and social interaction it affords. In both cases, however, the process of acquisition is non-linear, and may also be influenced by other factors, such as teaching input, natural orders of acquisition and individual differences. The findings also suggest that since certain error types, such as spelling, verb tense and word choice, are more persistent than others, correction codes may be usefully combined with written comments providing appropriate depth of feedback. Teachers may also adapt codes to individual groups of learners to reflect error types that cause particular difficulties, and annotate/correct selectively to avoid discouraging learners from taking risks and experimenting with more sophisticated language forms.}
}
@article{chen2016efl,
  title={EFL learners’ perceptions and preferences of written corrective feedback: a case study of university students from Mainland China},
  author={Chen, Sibo and Nassaji, Hossein and Liu, Qian},
  journal={Asian-Pacific journal of second and foreign language education},
  volume={1},
  number={1},
  pages={1--17},
  year={2016},
  publisher={SpringerOpen}
}

@inproceedings{feng-etal-2022-learn,
    title = "Learn To Remember: Transformer with Recurrent Memory for Document-Level Machine Translation",
    author = "Feng, Yukun  and
      Li, Feng  and
      Song, Ziang  and
      Zheng, Boyuan  and
      Koehn, Philipp",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2022",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-naacl.105",
    doi = "10.18653/v1/2022.findings-naacl.105",
    pages = "1409--1420",
    abstract = "The Transformer architecture has led to significant gains in machine translation. However, most studies focus on only sentence-level translation without considering the context dependency within documents, leading to the inadequacy of document-level coherence. Some recent research tried to mitigate this issue by introducing an additional context encoder or translating with multiple sentences or even the entire document. Such methods may lose the information on the target side or have an increasing computational complexity as documents get longer. To address such problems, we introduce a recurrent memory unit to the vanilla Transformer, which supports the information exchange between the sentence and previous context. The memory unit is recurrently updated by acquiring information from sentences, and passing the aggregated knowledge back to subsequent sentence states. We follow a two-stage training strategy, in which the model is first trained at the sentence level and then finetuned for document-level translation. We conduct experiments on three popular datasets for document-level machine translation and our model has an average improvement of 0.91 s-BLEU over the sentence-level baseline. We also achieve state-of-the-art results on TED and News, outperforming the previous work by 0.36 s-BLEU and 1.49 d-BLEU on average.",
}

@inproceedings{chen-etal-2020-modeling,
    title = "Modeling Discourse Structure for Document-level Neural Machine Translation",
    author = "Chen, Junxuan  and
      Li, Xiang  and
      Zhang, Jiarui  and
      Zhou, Chulun  and
      Cui, Jianwei  and
      Wang, Bin  and
      Su, Jinsong",
    booktitle = "Proceedings of the First Workshop on Automatic Simultaneous Translation",
    month = jul,
    year = "2020",
    address = "Seattle, Washington",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.autosimtrans-1.5",
    doi = "10.18653/v1/2020.autosimtrans-1.5",
    pages = "30--36",
    abstract = "Recently, document-level neural machine translation (NMT) has become a hot topic in the community of machine translation. Despite its success, most of existing studies ignored the discourse structure information of the input document to be translated, which has shown effective in other tasks. In this paper, we propose to improve document-level NMT with the aid of discourse structure information. Our encoder is based on a hierarchical attention network (HAN) (Miculicich et al., 2018). Specifically, we first parse the input document to obtain its discourse structure. Then, we introduce a Transformer-based path encoder to embed the discourse structure information of each word. Finally, we combine the discourse structure information with the word embedding before it is fed into the encoder. Experimental results on the English-to-German dataset show that our model can significantly outperform both Transformer and Transformer+HAN.",
}


@Inproceedings{danlos-2011-analyse,
    title = "Analyse discursive et informations de factivit{\'e} (Discursive analysis and information factivity)",
    author = "Danlos, Laurence",
    booktitle = "Actes de la 18e conf{\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs",
    month = jun,
    year = "2011",
    address = "Montpellier, France",
    publisher = "ATALA",
    url = "https://aclanthology.org/2011.jeptalnrecital-long.32",
    pages = "364--375",
    abstract = "Les annotations discursives propos{\'e}es dans le cadre de th{\'e}ories discursives comme RST (Rhetorical Structure Theory) ou SDRT (Segmented Dicourse Representation Theory) ont comme point fort de construire une structure discursive globale liant toutes les informations donn{\'e}es dans un texte. Les annotations discursives propos{\'e}es dans le PDTB (Penn Discourse Tree Bank) ont comme point fort d{'}identifier la {``}source{''} de chaque information du texte{---}r{\'e}pondant ainsi {\`a} la question qui a dit ou pense quoi ? Nous proposons une approche unifi{\'e}e pour les annotations discursives alliant les points forts de ces deux courants de recherche. Cette approche unifi{\'e}e repose crucialement sur des information de factivit{\'e}, telles que celles qui sont annot{\'e}es dans le corpus (anglais) FactBank.",
    language = "French",
}

@Inproceedings{dale-kilgarriff-2011-helping,
    title = "Helping Our Own: The {HOO} 2011 Pilot Shared Task",
    author = "Dale, Robert  and
      Kilgarriff, Adam",
    booktitle = "Proceedings of the 13th {E}uropean Workshop on Natural Language Generation",
    month = sep,
    year = "2011",
    address = "Nancy, France",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W11-2838",
    pages = "242--249",
}

@Inproceedings{kinnunen-etal-2012-swan,
    title = "{SWAN} - Scientific Writing {A}ssista{N}t. A Tool for Helping Scholars to Write Reader-Friendly Manuscripts",
    author = "Kinnunen, Tomi  and
      Leisma, Henri  and
      Machunik, Monika  and
      Kakkonen, Tuomo  and
      LeBrun, Jean-Luc",
    booktitle = "Proceedings of the Demonstrations at the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics",
    month = apr,
    year = "2012",
    address = "Avignon, France",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/E12-2005",
    pages = "20--24",
}


@inproceedings{du-etal-2022-read,
    title = "Read, Revise, Repeat: A System Demonstration for Human-in-the-loop Iterative Text Revision",
    author = "Du, Wanyu  and
      Kim, Zae Myung  and
      Raheja, Vipul  and
      Kumar, Dhruv  and
      Kang, Dongyeop",
    booktitle = "Proceedings of the First Workshop on Intelligent and Interactive Writing Assistants (In2Writing 2022)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.in2writing-1.14",
    doi = "10.18653/v1/2022.in2writing-1.14",
    pages = "96--108",
    abstract = "Revision is an essential part of the human writing process. It tends to be strategic, adaptive, and, more importantly, iterative in nature. Despite the success of large language models on text revision tasks, they are limited to non-iterative, one-shot revisions. Examining and evaluating the capability of large language models for making continuous revisions and collaborating with human writers is a critical step towards building effective writing assistants. In this work, we present a human-in-the-loop iterative text revision system, Read, Revise, Repeat (R3), which aims at achieving high quality text revisions with minimal human efforts by reading model-generated revisions and user feedbacks, revising documents, and repeating human-machine interactions. In R3, a text revision model provides text editing suggestions for human writers, who can accept or reject the suggested edits. The accepted edits are then incorporated into the model for the next iteration of document revision. Writers can therefore revise documents iteratively by interacting with the system and simply accepting/rejecting its suggested edits until the text revision model stops making further revisions or reaches a predefined maximum number of revisions. Empirical experiments show that R3 can generate revisions with comparable acceptance rate to human writers at early revision depths, and the human-machine interaction can get higher quality revisions with fewer iterations and edits. The collected human-model interaction dataset and system code are available at \url{https://github.com/vipulraheja/IteraTeR}. Our system demonstration is available at \url{https://youtu.be/lK08tIpEoaE}.",
}

@inproceedings{ito-etal-2019-diamonds,
    title = "Diamonds in the Rough: Generating Fluent Sentences from Early-Stage Drafts for Academic Writing Assistance",
    author = "Ito, Takumi  and
      Kuribayashi, Tatsuki  and
      Kobayashi, Hayato  and
      Brassard, Ana  and
      Hagiwara, Masato  and
      Suzuki, Jun  and
      Inui, Kentaro",
    booktitle = "Proceedings of the 12th International Conference on Natural Language Generation",
    month = oct # "{--}" # nov,
    year = "2019",
    address = "Tokyo, Japan",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-8606",
    doi = "10.18653/v1/W19-8606",
    pages = "40--53",
    abstract = "The writing process consists of several stages such as drafting, revising, editing, and proofreading. Studies on writing assistance, such as grammatical error correction (GEC), have mainly focused on sentence editing and proofreading, where surface-level issues such as typographical errors, spelling errors, or grammatical errors should be corrected. We broaden this focus to include the earlier revising stage, where sentences require adjustment to the information included or major rewriting and propose Sentence-level Revision (SentRev) as a new writing assistance task. Well-performing systems in this task can help inexperienced authors by producing fluent, complete sentences given their rough, incomplete drafts. We build a new freely available crowdsourced evaluation dataset consisting of incomplete sentences authored by non-native writers paired with their final versions extracted from published academic papers for developing and evaluating SentRev models. We also establish baseline performance on SentRev using our newly built evaluation dataset.",
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@MASTERSTHESIS{bourekkache2022english,
  title={English for specific purposes: writing scientific research papers. Case study: PhD students in the computer science department},
  author={Bourekkache, Samir},
  year={2022},
  school={University of Biskra, Algeria},
  intitution = {Ministery of Higher Education and Scientific Research}
}
@Phdthesis{teufel1999argumentative,
  title="Argumentative zoning: Information extraction from scientific text",
  author="Teufel, Simone and others",
  year="1999",
  school="Citeseer"
}

@Article{mann1988rhetorical,
  title={Rhetorical structure theory: Toward a functional theory of text organization},
  author={Mann, William C and Thompson, Sandra A},
  journal={Text-interdisciplinary Journal for the Study of Discourse},
  volume={8},
  number={3},
  pages={243--281},
  year={1988},
  publisher={De Gruyter Mouton}
}

@article{taboada2006rhetorical,
  title={Rhetorical structure theory: Looking back and moving ahead},
  author={Taboada, Maite and Mann, William C},
  journal={Discourse studies},
  volume={8},
  number={3},
  pages={423--459},
  year={2006},
  publisher={SAGE publications London, Thousand Oaks, CA and New Delhi}
}

@book{swales_genre_analysis,
title= "Genre Analysis: English in academic and research settings",
author= "John M. Swales",
editor= "Michael H. Long et Jack C. Richards",
publisher= "The press syndicate of the University of Cambridge",
year= "1990",
series= "The Cambridge applied linguistics series",
isbn="0 521 33813 1"
}

@Article{chinoisAZ,
  title={A Deep Learning-based Method of Argumentative Zoning for Research Articles},
  author={Mo, Wang and Yunpeng, Cui and Li, Chen and Huan, Li},
  journal={Data Analysis and Knowledge Discovery},
  volume={4},
  number={6},
  pages={60--68},
  year={2020}
}

@Article{anthony2003mover,
  title={Mover: A machine learning tool to assist in the reading and writing of technical papers},
  author={Anthony, Laurence and Lashkia, George V},
  journal={IEEE transactions on professional communication},
  volume={46},
  number={3},
  pages={185--193},
  year={2003},
  publisher={IEEE}
}
@article{putra_teufel_tokunaga_2022, title={Annotating argumentative structure in English-as-a-Foreign-Language learner essays}, volume={28}, DOI={10.1017/S1351324921000218}, number={6}, journal={Natural Language Engineering}, publisher={Cambridge University Press}, author={Putra, Jan Wira Gotama and Teufel, Simone and Tokunaga, Takenobu}, year={2022}, pages={797–823}}

@article{putra2021tiara,
  title={TIARA 2.0: an interactive tool for annotating discourse structure and text improvement},
  author={Putra, Jan Wira Gotama and Matsumura, Kana and Teufel, Simone and Tokunaga, Takenobu},
  journal={Language Resources and Evaluation},
  pages={1--25},
  year={2021},
  publisher={Springer}
}

@article{li2022text,
  title={Text Revision by On-the-Fly Representation Optimization},
  author={Li, Jingjing and Li, Zichao and Ge, Tao and King, Irwin and Lyu, Michael R},
  journal={arXiv preprint arXiv:2204.07359},
  year={2022}
}
on-
%%%%%%%%%%%%%%%%%%%%%%ù

@Article{anthony1999writing,
  title={Writing research article introductions in software engineering: How accurate is a standard model?},
  author={Anthony, Laurence},
  journal={IEEE transactions on Professional Communication},
  volume={42},
  number={1},
  pages={38--46},
  year={1999},
  publisher={IEEE}
}

@Inproceedings{teufel1999annotation,
  title={An annotation scheme for discourse-level argumentation in research articles},
  author={Teufel, Simone and Carletta, Jean and Moens, Marc},
  booktitle={Ninth Conference of the European Chapter of the Association for Computational Linguistics},
  pages={110--117},
  year={1999}
}

@Article{knight2020acawriter,
  title={AcaWriter: A learning analytics tool for formative feedback on academic writing},
  author={Knight, Simon and Shibani, Antonette and Abel, Sophie and Gibson, Andrew and Ryan, Philippa},
  journal={Journal of Writing Research},
  year={2020},
  publisher={ARLE (International Associaton for Research in L1 Education)}
}

@book{hogue1996first,
  title={First steps in academic writing},
  author={Hogue, Ann},
  volume={1},
  year={1996},
  publisher={Longman New York}
}

@Article{cotos2020understanding,
  title={Understanding graduate writers’ interaction with and impact of the Research Writing Tutor during revision},
  author={Cotos, Elena and Huffman, Sarah and Link, Stephanie},
  journal={Journal of Writing Research},
  volume={12},
  number={1},
  pages={187--232},
  year={2020}
}
@incollection{cotos2016computer,
  title={Computer-assisted research writing in the disciplines},
  author={Cotos, Elena},
  booktitle={Adaptive educational technologies for literacy instruction},
  pages={225--242},
  year={2016},
  publisher={Routledge}
}


@book{bailey2014academic,
  title={Academic writing: A handbook for international students},
  author={Bailey, Stephen},
  year={2014},
  publisher={Routledge}
}

@Article{silveira2022guide,
  title={Guide for scientific writing: how to avoid common mistakes in a scientific article},
  author={Silveira, Erika Aparecida and de Sousa Romeiro, Amanda Maria and Noll, Matias},
  journal={Journal of Human Growth and Development},
  volume={32},
  number={3},
  pages={341--352},
  year={2022}
}

@Article{laksmi2006scaffolding,
  title={" SCAFFOLDING" STUDENTS'WRITING IN EFL CLASS: IMPLEMENTING PROCESS APPROAC},
  author={Laksmi, Ekaning Dewanti},
  journal={TEFLIN Journal},
  volume={17},
  number={2},
  pages={144--156},
  year={2006}
}

@Article{cotos2015furthering,
  title={Furthering and applying move/step constructs: Technology-driven marshalling of Swalesian genre theory for EAP pedagogy},
  author={Cotos, Elena and Huffman, Sarah and Link, Stephanie},
  journal={Journal of English for Academic Purposes},
  volume={19},
  pages={52--72},
  year={2015},
  publisher={Elsevier}
}

@Article{seow2002writing,
  title={The writing process and process writing},
  author={Seow, Anthony},
  journal={Methodology in language teaching: An anthology of current practice},
  volume={315},
  pages={320},
  year={2002}
}




@Article{strobl2019digital,
  title={Digital support for academic writing: A review of technologies and pedagogies},
  author={Strobl, Carola and Ailhaud, Emilie and Benetos, Kalliopi and Devitt, Ann and Kruse, Otto and Proske, Antje and Rapp, Christian},
  journal={Computers \& education},
  volume={131},
  pages={33--48},
  year={2019},
  publisher={Elsevier}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={arXiv preprint arXiv:2203.02155},
  year={2022}
}


@article{W2Vliu2017automatic,
  author    = {Haixia Liu},
  title     = {Automatic Argumentative-Zoning Using Word2vec},
  journal   = {CoRR},
  volume    = {abs/1703.10152},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.10152},
  eprinttype = {arXiv},
  eprint    = {1703.10152},
  timestamp = {Mon, 13 Aug 2018 16:48:01 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/Liu17a.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@Article{liakata2010corpora,
  title={Corpora for the conceptualisation and zoning of scientific papers},
  author={Liakata, Maria and Teufel, Simone and Siddharthan, Advaith and Batchelor, Colin},
  year={2010}
}

@Inproceedings{liu2022incorporating,
  title={Incorporating Zoning Information into Argument Mining from Biomedical Literature},
  author={Liu, Boyang and Schlegel, Viktor and Batista-Navarro, Riza Theresa and Ananiadou, Sophia},
  booktitle={Proceedings of the Thirteenth Language Resources and Evaluation Conference},
  pages={6162--6169},
  year={2022}
}

@Article{accuosto2020mining,
  title={Mining arguments in scientific abstracts with discourse-level embeddings},
  author={Accuosto, Pablo and Saggion, Horacio},
  journal={Data \& Knowledge Engineering},
  volume={129},
  pages={101840},
  year={2020},
  publisher={Elsevier}
}

@Inproceedings{teufel2009towards,
  title={Towards domain-independent argumentative zoning: Evidence from chemistry and computational linguistics},
  author={Teufel, Simone and Siddharthan, Advaith and Batchelor, Colin},
  booktitle={Proceedings of the 2009 conference on empirical methods in natural language processing},
  pages={1493--1502},
  year={2009}
}

@inproceedings{ito2020langsmith,
    title = "Langsmith: An Interactive Academic Text Revision System",
    author = "Ito, Takumi  and
      Kuribayashi, Tatsuki  and
      Hidaka, Masatoshi  and
      Suzuki, Jun  and
      Inui, Kentaro",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-demos.28",
    doi = "10.18653/v1/2020.emnlp-demos.28",
    pages = "216--226",
    abstract = "Despite the current diversity and inclusion initiatives in the academic community, researchers with a non-native command of English still face significant obstacles when writing papers in English. This paper presents the Langsmith editor, which assists inexperienced, non-native researchers to write English papers, especially in the natural language processing (NLP) field. Our system can suggest fluent, academic-style sentences to writers based on their rough, incomplete phrases or sentences. The system also encourages interaction between human writers and the computerized revision system. The experimental results demonstrated that Langsmith helps non-native English-speaker students write papers in English. The system is available at https://emnlp-demo.editor. langsmith.co.jp/.",
}



@Inproceedings{daudaravicius-2015-automated,
    title = "Automated Evaluation of Scientific Writing: {AESW} Shared Task Proposal",
    author = "Daudaravi{\v{c}}ius, Vidas",
    booktitle = "Proceedings of the Tenth Workshop on Innovative Use of {NLP} for Building Educational Applications",
    month = jun,
    year = "2015",
    address = "Denver, Colorado",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W15-0607",
    doi = "10.3115/v1/W15-0607",
    pages = "56--63",
}


@Article{areyoureth,
  title={Are you being rhetorical? A description of rhetorical move annotation tools and open corpus of sample machine-annotated rhetorical moves},
  author={Knight, Simon and Abel, Sophie and Shibani, Antonette and Goh, Yoong Kuan and Conijn, Rianne and Gibson, Andrew and Vajjala, Sowmya and Cotos, Elena and S{\'a}ndor, {\'A}gnes and Shum, Simon Buckingham},
  journal={Journal of Learning Analytics},
  volume={7},
  number={3},
  pages={138--154},
  year={2020},
  publisher={UTS ePRESS}
}

@Article{alves2015progress,
  title={Progress in written language bursts, pauses, transcription, and written composition across schooling},
  author={Alves, Rui A and Limpo, Teresa},
  journal={Scientific Studies of Reading},
  volume={19},
  number={5},
  pages={374--391},
  year={2015},
  publisher={Taylor \& Francis}
}


@article{jiang2022arxivedits,
  title={arXivEdits: Understanding the Human Revision Process in Scientific Writing},
  author={Jiang, Chao and Xu, Wei and Stevens, Samuel},
  journal={In Proceedings of EMNLP 2022},
  year={2022}
}

@Article{kallestinova2011write,
  title={How to write your first research paper},
  author={Kallestinova, Elena D},
  journal={The Yale journal of biology and medicine},
  volume={84},
  number={3},
  pages={181},
  year={2011},
  publisher={Yale Journal of Biology and Medicine}
}

@Article{lawrence2020argument,
  title={Argument mining: A survey},
  author={Lawrence, John and Reed, Chris},
  journal={Computational Linguistics},
  volume={45},
  number={4},
  pages={765--818},
  year={2020},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@Inproceedings{tsai-etal-2020-lingglewrite,
    title = "{L}inggle{W}rite: a Coaching System for Essay Writing",
    author = "Tsai, Chung-Ting  and
      Chen, Jhih-Jie  and
      Yang, Ching-Yu  and
      Chang, Jason S.",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-demos.17",
    doi = "10.18653/v1/2020.acl-demos.17",
    pages = "127--133",
    abstract = "This paper presents LinggleWrite, a writing coach that provides writing suggestions, assesses writing proficiency levels, detects grammatical errors, and offers corrective feedback in response to user{'}s essay. The method involves extracting grammar patterns, training models for automated essay scoring (AES) and grammatical error detection (GED), and finally retrieving plausible corrections from a n-gram search engine. Experiments on public test sets indicate that both AES and GED models achieve state-of-the-art performance. These results show that LinggleWrite is potentially useful in helping learners improve their writing skills.",
}