\section{Preliminaries}
\label{section-3}

% In this paper, we focus on continuous-time dynamic graph learning methods, which have been demonstrated to be more flexible and effective than discrete-time dynamic graph learning methods \cite{DBLP:conf/kdd/KumarZL19,DBLP:conf/iclr/TrivediFBZ19,DBLP:conf/iclr/XuRKKA20,DBLP:journals/corr/abs-2006-10637,DBLP:conf/sigir/0001GRTY20,DBLP:conf/cikm/ChangLW0FS020,DBLP:journals/corr/abs-2105-07944,DBLP:conf/iclr/WangCLL021,DBLP:conf/sigmod/WangLLXYWWCYSG21,jin2022neural,luo2022neighborhoodaware,cong2023do}. 

\begin{definition}
    \textbf{Dynamic Graph}. We represent a dynamic graph as a sequence of non-decreasing chronological interactions $\mathcal{G}=\left\{\left(u_1,v_1,t_1\right), \left(u_2,v_2,t_2\right), \cdots \right\}$ with $0 \leq t_1 \leq t_2 \leq \cdots$, where $u_i, v_i \in \mathcal{N}$ denote the source node and destination node of the $i$-th link at timestamp $t_i$.
    % \footnote{In this paper, we mainly focus on link addition, which is a widely studied interaction type in previous research. We leave the investigations of other interaction types (e.g., node addition/deletion/feature transformations and link deletion/feature transformations) for future work.}. 
    $\mathcal{N}$ is the set of all the nodes. Each node $u \in \mathcal{N}$ can be associated with node feature $\bm{x}_u \in \mathbb{R}^{d_N}$, and each interaction $\left(u,v,t\right)$ has link feature $\bm{e}_{u,v}^t \in \mathbb{R}^{d_E}$. $d_N$ and $d_E$ denote the dimensions of the node feature and link feature. If the graph is non-attributed, we simply set the node feature and link feature to zero vectors, i.e., $\bm{x}_u=\bm{0}$ and $\bm{e}_{u,v}^t=\bm{0}$. 
\end{definition}

\begin{definition}
    \textbf{Problem Formalization}. Given the source node $u$, destination node $v$, timestamp $t$, and historical interactions before $t$, i.e., $\left\{\left(u^\prime,v^\prime,t^\prime\right) | t^\prime < t \right\}$, representation learning on dynamic graph aims to design a model to learn time-aware representations $\bm{h}_u^t \in \mathbb{R}^d$ and $\bm{h}_v^t \in \mathbb{R}^d$ for $u$ and $v$ with $d$ as the dimension. We validate the effectiveness of the learned representations via two classic tasks in dynamic graph learning: (\romannumeral1) dynamic link prediction, which predicts whether $u$ and $v$ are connected at $t$; (\romannumeral2) dynamic node classification, which infers the state of $u$ or $v$ at $t$.
\end{definition}


% which predicts the probability of an edge connecting two nodes at a specific timestamp
% which classifies the state of a node in an interaction at a specific timestamp

% We denote a dynamic graph as a sequence of events with timestamps $\mathcal{G}=\left(e\left(t_1\right), e_2\left(t_2\right), \cdots\right)$ with $0 \leq t_1 \leq t_2 \leq \cdots$, where event $e\left(t\right)$ can be either node-wise or pairwise:

