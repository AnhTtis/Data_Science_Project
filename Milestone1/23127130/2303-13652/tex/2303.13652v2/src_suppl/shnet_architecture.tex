\section{Architecture of SHNet}

SHNet processes right and left hand images in the same way except for the input and output of the left hand image are flipped to the right hand and flipped back to the left hand, respectively.
Hence, we omit right and left hand notations in the following description. 

SHNet predicts 2.5D joint coordinates $\mathbf{P} \in \mathbb{R}^{J \times 3}$, MANO parameters, and 3D global translation $\mathbf{g} \in \mathbb{R}^3$ from a single hand image $\mathbf{I}_\text{hand} \in \mathbb{R}^{3 \times H_\text{hand} \times W_\text{hand}}$.
$H_\text{hand}=256$ and $W_\text{hand}=256$ denote height and width of $\mathbf{I}_\text{hand}$, respectively.
$J=21$ denotes the number of single hand joints.
MANO parameters include 3D joint rotations $\theta \in \mathbb{R}^{16 \times 3}$ and hand shape parameter $\beta \in \mathbb{R}^{10}$.
The 3D global translation $\mathbf{g}$ is used in two cases: 1) loss calculations and 2) mesh rendering to visualize results.


\noindent\textbf{2.5D joint coordinate estimation.}
ResNet-50 extracts an image feature $\mathbf{F}_\text{hand} \in \mathbb{R}^{C_\text{hand} \times H_\text{hand}/32 \times W_\text{hand}/32}$ from a single hand image $\mathbf{I}_\text{hand}$.
$C_\text{hand}=2048$ denotes the number of channel of $\mathbf{F}_\text{hand}$.
Then, the extracted image feature $\mathbf{F}_\text{hand}$ is passed to a 1-by-1 convolutional layer, which outputs $JD$-dimensional feature map, where $D=8$ denotes discretized depth size.
The feature map is reshaped to the dimension of $\mathbb{R}^{J \times D \times H_\text{hand}/32 \times W_\text{hand}/32}$, which is a 3D heatmap of hand joints.
Soft-argmax~\cite{sun2018integral} extracts 2.5D joint coordinates $\mathbf{P}$ from the 3D heatmap.

\noindent\textbf{MANO parameter regression.}
SHNet firsts reduces the channel dimension of $\mathbf{F}_\text{hand}$ from 2048 to 512 to reduce computational costs.
Then, SHNet extracts joint features by performing a bilinear interpolation at the $(x,y)$ position of the 512-dimensional feature map.
The joint features contain essential articulation information about hand joints.
Finally, a single linear layer outputs MANO pose parameter $\theta$ from a concatenation of the joint features with 2.5D joint coordinates.
The pose parameter $\theta$ is initially estimated in the 6D rotational representation~\cite{zhou2019continuity} and transformed to the axis-angle representation.
The MANO shape parameter $\beta$ and 3D global translation $\mathbf{g}$ are estimated from GAPed $\mathbf{F}_\text{hand}$.
