As is the case with most methodological research, our work can be applied to downstream applications with negative societal impact -- for instance by reflecting biases in the dataset the model was trained on.
We note that in unsupervised learning, it is particularly important to check what a model has learned, due to the lack of label supervision.
This is crucial if the models are used to make high-stakes decisions.
