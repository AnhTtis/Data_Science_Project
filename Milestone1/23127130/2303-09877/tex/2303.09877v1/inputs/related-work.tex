
\begin{table*}[!t]
    \centering
    {
        \small
        \renewcommand{\arraystretch}{0.85}
        \PreviousAndNewMethodsTable
    }
    \caption{
        Overview of selected methods from previous work (top) and proposed new instances (bottom), and their \fwName components. The complete table of previous methods is included in the supplementary.
        \textbf{Abbreviations:}
        ``\NOTINC'' = \NOTINCLong,
        ``\NOTSPEC'' = \NOTSPECLong,
        \AL~= \ALLong,
        \CAT = \CATLong,
        \CCA = \CCALong,
        \DDC = \DDCLong,
        \DEC = \DECLong,
        \SC = \SCLong,
        \SE = \SELong,
        \SR = \SRLong
    }
    \label{tab:previousMethods}
\end{table*}

Table~\ref{tab:previousMethods} shows selected recent methods for deep MVC (the full table can be found in the supplementary), categorized by its \fwName components, allowing for systematic comparisons between models\footnote{Note, here we limit our discussion to MVC approaches without missing data. While most of the theoretical and empirical results also generalize to the emerging incomplete MVC setting~\cite{xuAdversarialIncompleteMultiview2019,wenCDIMCnetCognitiveDeep2020,linCOMPLETERIncompleteMultiView2021}, we consider it out of scope of this work.}.

\customparagraph{View-specific encoders.}
    As can be seen in Table~\ref{tab:previousMethods}, all models use view-specific encoders to encode views into view-specific embeddings.
    Multi-layer perceptrons (MLPs) are usually used for vector data, while convolutional neural networks (CNNs) are used for image data.

\customparagraph{SV-SSL and MV-SSL.}
    Alongside the encoder network, many methods use decoders to reconstruct the original views from either the view-specific representations or the fused representation.
    The reconstruction task is the most common self-supervised pretext task, both for SV-SSL and for MV-SSL.
    In SV-SSL, the views are reconstructed from their respective view-specific representations, without any influence from the other views%
    ~\cite{wangDeepMultiViewRepresentation2015,abavisaniDeepMultimodalSubspace2018,tangDeepMultiviewSparse2018,sunSelfSupervisedDeepMultiView2019,zhangDeepMultimodalClustering2020,zhangEndToEndDeepMultimodal2020,zongMultimodalClusteringDeep2020,xuDeepEmbeddedMultiview2021}.
    In MV-SSL, it is common to either do
    \begin{enumerate*}[label=(\roman*)]
      \item cross view reconstruction, where all views are reconstructed from all view-specific representations~\cite{zhuMultiviewDeepSubspace2019}; or
      \item fused view reconstruction, where all views are reconstructed from the fused representation~\cite{zhuMultiviewDeepSubspace2019,liDeepAdversarialMultiview2019,yinSharedGenerativeLatent2020,wangAdversarialMultiviewClustering2022}.
    \end{enumerate*}

    Aligning distributions of view-specific representations is another MV-SSL pretext task that has been shown to produce representations suitable for clustering~\cite{zhouEndtoEndAdversarialAttentionNetwork2020}.
    However,~\cite{trostenReconsideringRepresentationAlignment2021} demonstrate that the alignment of representation distributions can be detrimental to the clustering performance -- especially in the presence of noisy or non-informative views.
    To avoid these drawbacks, they propose Simple MVC (SiMVC) and Contrastive MVC (CoMVC).
    In the former, the alignment is dropped altogether, whereas the latter includes a contrastive learning module that aligns the view-specific representations at the instance level, rather than at the distribution level.

\customparagraph{Clustering modules.}
    Many deep MVC methods use subspace-based clustering modules~\cite{abavisaniDeepMultimodalSubspace2018,zhuMultiviewDeepSubspace2019,sunSelfSupervisedDeepMultiView2019,wangSelfSupervisedInformationBottleneck2022}.
    These methods assume that representations, either view-specific or fused, can be decomposed into linear combinations of each other.
    Once determined, the self-representation matrix containing the coefficients for these linear combinations is used to compute an affinity matrix, which in turn is used as input to spectral clustering.
    This requires the full \( n \times n \) self-representation matrix available in memory, which is computationally prohibitive for datasets with a large number of instances.

    Other clustering modules have also been adapted to deep MVC. The clustering module from Deep Embedded Clustering (DEC)~\cite{xieUnsupervisedDeepEmbedding2016}, for instance, is used in several models~\cite{liDeepAdversarialMultiview2019,duDeepMultipleAutoEncoderBased2021,xinSelfSupervisedDeepCorrelational2021,xuDeepEmbeddedMultiview2021,wangAdversarialMultiviewClustering2022}.
    Recently, the Deep Divergence-Based Clustering (DDC)~\cite{kampffmeyerDeepDivergencebasedApproach2019} clustering module has been used in several state-of-the-art deep MVC models~\cite{zhouEndtoEndAdversarialAttentionNetwork2020,trostenReconsideringRepresentationAlignment2021}.
    In addition, some methods treat either the encoder output or the fused representation as cluster membership vectors~\cite{zhangEndToEndDeepMultimodal2020,maoDeepMutualInformation2021}.

    Lastly, some methods adopt a two-stage approach, where they first use the SSL components to learn representations, and then apply a traditional clustering method, such as \( k \)-means~\cite{huangMultiSpectralNetSpectralClustering2019,huangMultiviewSpectralClustering2019,zhangDeepMultimodalClustering2020,zongMultimodalClusteringDeep2020,xuMultiVAELearningDisentangled2021}, a Gaussian mixture model~\cite{yinSharedGenerativeLatent2020}, or spectral clustering~\cite{wangDeepMultiViewRepresentation2015}, on the trained representations.

