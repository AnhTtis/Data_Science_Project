
With our new instances of \fwName, we aim to further analyze and address the many-views-issue with contrastive alignment highlighted above, as well as to investigate the effect of other SSL components.
In addition to alignment of view-specific representations~\cite{zhouEndtoEndAdversarialAttentionNetwork2020,duDeepMultipleAutoEncoderBased2021,trostenReconsideringRepresentationAlignment2021}, we identify reconstruction~\cite{wangDeepMultiViewRepresentation2015,abavisaniDeepMultimodalSubspace2018,liDeepAdversarialMultiview2019} and mutual information maximization~\cite{jiInvariantInformationClustering2019,wangSelfSupervisedInformationBottleneck2022} to be promising directions for the new instances.
Maximizing mutual information is particularly interesting, as it enables the view-specific encoders to represent the information which is shared across views, without explicitly forcing the view-specific representations to be aligned. 
Furthermore, we recognize that simple baselines with few or no SSL components -- exemplified by SiMVC~\cite{trostenReconsideringRepresentationAlignment2021} -- might perform similarly to more complicated methods, while being significantly easier to implement and faster to train.
It is therefore crucial to include such methods in an experimental evaluation, in order to properly determine whether additional SSL-based components are beneficial for the models' performance.
Finally, our overview of recent work shows that both traditional clustering modules (\eg \( k \)-means) and deep learning-based clustering modules (\eg DDC) are commonly used in deep MVC.

In total, we develop \( 6 \) new \fwName instances in \( 3 \) categories.
The new instances are summarized in Table~\ref{tab:previousMethods}.
Evaluating these instances and several methods from recent work, allows us to accurately evaluate methods and components, and investigate how they behave for datasets with varying characteristics.

\customparagraph{Simple baselines:}
    \textbf{\saekm} has view-specific autoencoders (AEs) with a mean-squared-error (MSE) loss
    \begin{align}
        \label{eq:mseLoss}
        \SVSSLLoss_{\text{Reconstruction}} = \frac{1}{nV} \sums{i=1}{n}\sums{v=1}{V} ||\vec x_i^{(v)} - \hat{\vec x}_i^{(v)} ||^2
    \end{align}
    as its SV-SSL task.
    The views are fused by concatenation and the concatenated representations are clustered using \( k \)-means after the view-specific autoencoders have been trained.
    \textbf{\sae} uses view-specific autoencoders with an MSE loss (Eq.~\eqref{eq:mseLoss}) as its SV-SSL task.
    The views are fused using a weighted sum and the fused representations are clustered using the DDC clustering module~\cite{kampffmeyerDeepDivergencebasedApproach2019}.

\customparagraph{Contrastive alignment-based:}
    \textbf{\caekm} extends \saekm~with a contrastive loss on the view-specific representations.
    We use the multi-view generalization of the NT-Xent (contrastive) loss by Trosten \etal~\cite{trostenReconsideringRepresentationAlignment2021}, without the ``other clusters'' negative sampling
    \begin{align}
        & \MVSSLLoss_{\text{Contrastive}} = \frac{1}{nV(V-1)} \sums{i=1}{n}\sums{v=1}{V}\sums{u=1}{V} \mathds{1}_{\{u \neq v\}}\ \ell_i^{(uv)}, \\
        & \ell_i^{(uv)} = - \log \frac{\exp(s_{ii}^{(uv)})}{ \sum_{s' \in \text{Neg}(\vec z_i^{(u)}, \vec z_i^{(v)})} \exp(s')}
    \end{align}
    and \( s_{ij}^{(uv)} = \frac{1}{\tau} \frac{\vec z_i^{u} \cdot \vec z_j^{(v)}}{ ||\vec z_i^{u}|| \cdot ||\vec z_j^{(v)}||} \) denotes the cosine similarity between \( \vec z_i^{u} \) and \( \vec z_j^{v} \).
    The set \( \text{Neg}(\vec z_i^{(u)}, \vec z_i^{(v)}) \) is the set of similarities of negative pairs for the positive pair \( (\vec z_i^{(u)}, \vec z_i^{(v)}) \),
    which consists of \( s^{(uv)}_{ij} \), \( s^{(uu)}_{ij} \), and \( s^{(vv)}_{ij} \), for all \( j \neq i \).
    \( \tau \) is a hyperparameter, which we set to \( 0.1 \) for all experiments.
    \textbf{\cae} extends \sae~using the same generalized NT-Xent contrastive loss on the view-specific representations.

\customparagraph{Mutual information-based:}
    \textbf{\mimvc} maximizes the mutual information (MI) between the view-specific representations, using the MI loss from Invariant Information Clustering (IIC)~\cite{jiInvariantInformationClustering2019}\footnote{The supplementary includes a brief overview of the connection between InfoDDC and contrastive alignment.}.
    The MI maximization is regularized by also maximizing the entropy of view-specific representations.
    The view-specific representations are fused using a weighted sum, and the fused representations are clustered using DDC~\cite{kampffmeyerDeepDivergencebasedApproach2019}.
    \textbf{\mviic} is a multi-view generalization of IIC~\cite{jiInvariantInformationClustering2019}, where cluster assignments are computed for each of the view-specific representations.
    The MI between pairs of these view-specific cluster assignments is then maximized using the information maximization loss from IIC.
    In order to get a final shared cluster assignment for all views, the view-specific cluster assignments are concatenated and clustered using \( k \)-means.
    As in IIC, this model includes \( 5 \) over-clustering heads as its MV-SSL task.
    In both \mimvc and \mviic, we generalize the loss from IIC to an arbitrary number of views:
    \begin{align}
        \nonumber
        \MVSSLLoss_{\text{MI}} &= \frac{2}{V(V-1)} \sums{u=1}{V-1}\sums{v=u+1}{V} - \Big( \underbrace{I(\vec Z^{(u)}, \vec Z^{(v)})}_{\text{mutual information}} \\
        & + (\lambda - 1) \underbrace{(H(\vec Z^{(u)}) + H(\vec Z^{(v)}))}_{\text{entropy regularization}} \Big)
    \end{align}
    where the summands are computed as
    \begin{align}
        \nonumber
        & I(\vec Z^{(u)}, \vec Z^{(v)}) + (\lambda - 1) (H(\vec Z^{(u)}) + H(\vec Z^{(v)})) \\
        & = - \sums{a=1}{D}\sums{b=1}{D} \vec P^{(uv)}_{ab} \log \frac{\vec P^{(uv)}_{ab}}{(\vec P^{(u)}_a \vec P^{(v)}_b)^\lambda},
    \end{align}
    where \( D \) denotes the dimensionality of the view-specific representations.
    \( \lambda \) is a hyperparameter that controls the strength of the entropy regularization.
    We set \( \lambda = 10 \) for \mimvc, and \( \lambda = 1.5 \) for \mviic.
    The joint distribution \( \vec P^{(uv)} \) is estimated by first computing \( \tilde{\vec P}^{(uv)} = \frac{1}{n} \sum_{i=1}^{n} \vec z^{(u)}_i (\vec z^{(v)}_i)\T \),
    and then symmetrizing it \( \vec P^{(uv)} = \frac{1}{2} (\tilde{\vec P}^{(uv)} + (\tilde{\vec P}^{(uv)})\T)\).
    We assume that each view-specific representation is normalized such that its elements sum to one, and are all non-negative.
    The marginals \( \vec P^{(u)} \) and \( \vec P^{(v)} \) are obtained by summing over the rows and columns of \( \vec P^{(uv)} \), respectively.
