\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
% \usepackage{cite}
\usepackage[numbers, sort&compress]{natbib}
% \biboptions{sort&compress}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithm}
\usepackage{algorithmic}
\renewcommand{\algorithmicrequire}{ \textbf{Input:}} %Use Input in the format of Algorithm
\renewcommand{\algorithmicensure}{ \textbf{Output:}} %UseOutput in the format of Algorithm
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{enumerate}  
\usepackage[inline]{enumitem}
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}

%\algdef{SE}[DOWHILE]{DO}{DOWHILE}{\algorithmicdo}[1]{\algorithmicwhile\ #1}

\def \qed {\hfill \vrule height6pt width 6pt depth 0pt}
\newtheorem{ass}{Assumption}[section]
\newtheorem{pro}{Proposition}[section]
\newtheorem{lem}{Lemma}[section]
\newtheorem{rem}{Remark}[section]
\newtheorem{cor}{Corollary}[section]
\newtheorem{thm}{Theorem}[section]
\newtheorem{exa}{Example}[section]
\newcommand{\BOX}{\hfill\rule{2mm}{2mm}}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Adaptive Federated Learning via Entropy Approach 
% \\
% {\footnotesize  \textsuperscript{*}Note: Sub-titles are not captured in Xplore and should not be used}
% \thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{Shensheng Zheng}
\IEEEauthorblockA{\textit{School of Artificial Intelligence} \\
\textit{Sun Yat-sen University}\\
Zhuhai, China \\
% tukf@mail2.sysu.edu.cn\\
zhengshsh7@mail2.sysu.edu.cn}
\and
% \IEEEauthorblockN{ \name{Xuehe Wang \thanks{*Corresponding author}}}
\IEEEauthorblockN{Xuehe Wang\thanks{* corresponding author.}\IEEEauthorrefmark{1}}
\IEEEauthorblockA{\textit{School of Artificial Intelligence} \\
\textit{Sun Yat-sen University}\\
Zhuhai, China \\
\textit{and Guangdong Key Laboratory of} \\
\textit{Big Data Analysis and Processing}\\
Guangzhou, China \\
wangxuehe@mail.sysu.edu.cn}
\and 
\IEEEauthorblockN{Lingjie Duan}
\IEEEauthorblockA{\textit{Engineering Systems and Design} \\
\textit{Singapore University of Technology and Design}\\
Singapore,  \\
% \textit{and Guangdong Key Laboratory of} \\
% \textit{Big Data Analysis and Processing}\\
% Guangzhou, China \\
lingjie\_duan@sutd.edu.sg}

% \and
% \IEEEauthorblockN{4\textsuperscript{th} Given Name Surname}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% City, Country \\
% email address or ORCID}
% \and
% \IEEEauthorblockN{5\textsuperscript{th} Given Name Surname}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% City, Country \\
% email address or ORCID}
% \and
% \IEEEauthorblockN{6\textsuperscript{th} Given Name Surname}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% City, Country \\
% email address or ORCID}
}

\maketitle

\begin{abstract}
% In order to solve the problem of ``data island" and preserve individual's privacy, federated learning, as a distributed machine learning technology, has emerged recently. In federated learning, the model training is distributed over edge clients and coordinated by a central server. Each client only needs to send the updated model parameter to the central server for aggregation without sharing its private data. However, due to the data divergence of heterogeneous clients, the convergence rate of the global model training may be very slow, especially for non-IID data case. To deal with this issue and achieve fast convergence, we propose an adaptive learning rate strategy for each client by considering the deviation of the local model parameter from the global model parameter at each global training iteration. To enable decentralized learning rate design for each client, a mean-field scheme is introduced to estimate the global model parameters over time, which does not even require many clients to communicate frequently. Finally, we run numerical experiments to validate our results.
% In order to save computing server resources and protect user privacy, federated learning
Federated Learning (FL) has recently emerged as a popular framework, which allows resource-constrained discrete clients to cooperatively learn the global model under the orchestration of a central server while storing privacy-sensitive data locally. However, due to the difference in equipment and data divergence of heterogeneous clients, there will be parameter deviation between local models, resulting in a slow convergence rate and a reduction of  the accuracy of the global model. The current FL algorithms use the static client learning strategy pervasively and can not adapt to the dynamic training parameters of different clients. In this paper, by considering the deviation between different local model parameters, we propose an adaptive learning rate scheme for each client based on entropy theory to alleviate the deviation between heterogeneous clients and achieve fast convergence of the global model. It's difficult to design the optimal dynamic learning rate for each client as the local information of other clients is unknown, especially during the local training epochs without communications between local clients and the central server. To enable a decentralized learning rate design for each client, we first introduce mean-field schemes to estimate the terms related to other clients' local model parameters. Then the decentralized adaptive learning rate for each client is obtained in closed form by constructing the Hamilton equation. Moreover, we prove that there exist fixed point solutions for the mean-field estimators, and an algorithm is proposed to obtain them. Finally, extensive experimental results on real datasets show that our algorithm can effectively eliminate the deviation between local model parameters compared to other recent FL algorithms.

% To design the decentralized learning rate for each client, we introduce mean-field schemes to estimate the terms related to other clients' local model parameters over time. 

\end{abstract}

\begin{IEEEkeywords}
federated learning, adaptive learning rate, entropy, mean-field approach
\end{IEEEkeywords}

\section{Introduction}\label{sec:introduction}

\IEEEPARstart{T}{he} boom in the Internet of Things (IoT) and Artificial Intelligence (AI) makes it possible to use vast amounts of discrete client data to train efficient machine learning (ML) models (e.g., for recommendation system \cite{ghosh2020efficient}). However, traditional ML requires the collection of massive data, which increases the risk of personal data privacy leakage \cite{bonawitz2017practical}. To save computing resources and protect users' privacy, Federated Learning (FL) allows resource-constrained discrete clients to collaboratively learn the global model under the orchestration of a central server while keeping privacy-sensitive data locally \cite{yang2019federated}.

The current popular FL algorithms are the Federated Averaging (FedAvg) and its variants \cite{r1}. It usually consists of a central server and a group of distributed clients. In each training round, discrete clients first obtain the global model parameters of the previous round from the central server and then uses their own local data to generate the local model parameters. Then the central server will aggregate the local model parameters from discrete clients and generate the new global parameters. The total training will terminate when the accuracy loss of the global model is below the preset threshold \cite{r1}. Under this framework, the server effectively utilizes clients’ computing power and storage resources while realizing the separation of privacy data \cite{tran2019federated}.

Although FedAvg performs well on Gboard application \cite{hard2018federated},  recent works \cite{zhao2018federated, hsu2019measuring, karimireddy2020scaffold} have pointed out its convergence issues in some settings. For example, FedAvg \cite{r1} will converge slowly and the accuracy will be reduced on the non-independent-and-identically-distributed (Non-IID) client dataset \cite{sattler2019robust}. Reddi et al. \cite{reddi2020adaptive} show that this is because of client parameter drift and lack of adaptivity to the different models. Moreover, Tan et al. \cite{tan2022towards} point out that FedAvg can not learn the personalized FL model for each client.

In order to deal with the convergence issues for the Non-IID dataset, the current FL algorithm is optimized in from following aspects: \begin{enumerate*}[label=(\roman*)]
\item asynchronous updating of model parameters: Xie et al. \cite{xie2019asynchronous} use a weighted average to asynchronously update the global model, where the mixing weight is set adaptively as a function of the staleness. \cite{ma2021fedsa} proposes a semi-asynchronous FL mechanism (FedSA), where the parameter server aggregates a certain number of local models by their arrival order in each round.
\item adjustment of the number of local updates: Li et al. \cite{li2020federated} use a regularization term to balance the optimizing discrepancy between the global and local objectives and allow participating nodes to perform a variable number of local updates to overcome the heterogeneity of the system. When the client resource budget is fixed, \cite{wang2019adaptive} presents an analytical model that dynamically adjusts the number of local updates between two consecutive global aggregations in real-time to minimize the learning loss of the computational system.
\item client selection for FL training:  Nishio et al. \cite{nishio2019client} propose the FedCS algorithm to select nodes according to the resource conditions of the local clients rather than randomly. \cite{nguyen2020fast} mainly adopts the gradient information of clients, and clients whose inner product of the gradient vector and global gradient vector is negative will be excluded from FL training.
\item adaptive weighting for model updating: Chen et al. \cite{chen2019communication} assign different update weights according to the number of local communication rounds.  \cite{HongdaWu2020FastConvergentFL} adjusts clients' weights based on clients' contribution measured by the angle between the local gradient vector and the global gradient vector. \cite{reddi2020adaptive} uses a pseudo-gradient difference to adaptively update the gradient.
\end{enumerate*}


However, there are some overlooked issues in the above FL optimization methods. Firstly, most methods \cite{xie2019asynchronous, li2020federated, wang2019adaptive, nishio2019client, nguyen2020fast, chen2019communication, HongdaWu2020FastConvergentFL} have not discussed in detail about the setting of the convergent learning rate. They tend to assign a static local learning rate on the clients. This is not optimal as the differences in clients' devices and data can lead to deviations between different local parameters and a slow convergence rate. 
% Thus, we use the information entropy theory to measure the deviation between the local model parameters and the global model parameters in each global training iteration, and propose an adaptive learning rate strategy for each client. 
Secondly, while the upper bound for the convergent learning rate of FedAdagrad, FedAdam and FedYogi are given in \cite{reddi2020adaptive}, it involves many hyper-parameters and cannot be precise for each iteration. Ma et al. \cite{ma2021fedsa} calculate the dynamic learning rate by the frequency of aggregation, but do not consider the effect of data distribution. 
% To enable decentralized learning rate design for each client, a mean-field scheme is introduced to estimate the global model parameters over time, which does not even require many clients to communicate frequently. In addition, the works in \cite{xie2019asynchronous, li2020federated, ma2021fedsa, wang2019adaptive, nishio2019client, nguyen2020fast, chen2019communication, HongdaWu2020FastConvergentFL} don't consider the effect of learning rate on model convergence. 
In this paper, an entropy term is introduced in the local objective function of each client to measure the diversity among the local model parameters of all clients and help design an adaptive local learning rate for each client for faster convergence. To enable a decentralized learning rate design for each client, a mean-field scheme is introduced to estimate other clients' local parameters over time.

The main contributions of this paper are as follows:
\begin{itemize}
\item\emph{Adaptive learning rate strategy for federated learning:} To our best knowledge, this paper is one of the first works studying how to assign an adaptive learning rate for each
client by utilizing the entropy theory to measure the deviation between the local model parameters for the Non-IID dataset. By setting the parameter diversity among clients as a penalty item of the learning rate, the adaptive learning rate for each client is proposed to adjust the client's learning rate over time and achieve fast convergence. 

\item\emph{Mean-field scheme to estimate the terms related to other clients' local parameters:} To design a decentralized learning rate for each client, a mean-field scheme is introduced to estimate the terms relating to other clients' local parameters over time without requiring many clients to communicate frequently. By converting the original combinatorial optimization problem using the mean-field terms, the decentralized adaptive learning rate for each client is obtained  in closed form by constructing the Hamilton equation.

\item\emph{Fixed point algorithm for finalizing the optimal learning rate:} We prove that there exists a fixed point solution for the mean-field estimator, and an algorithm is proposed to calculate the fixed point. Then, we successfully calculate the optimal learning rate for each client at each global training iteration. The experimental results show that our method has a faster convergence rate and higher accuracy. Moreover, our adaptive FL algorithm can effectively eliminate the deviation between different local model parameters compared with other FL algorithms.
\end{itemize}

% \subsection{Related Work}\label{sec_related_work}
% To solve the problems of convergence and client parameter drift of FedAvg \cite{r1}, the adaptive federated optimization method is becoming more and more popular. From an asynchronous FL perspective, Damaskinos et al. \cite{damaskinos2022fleet} present AdaSGD, a new stochastic gradient descent (SGD) algorithm that tolerates staleness by dampening the impact of outdated results. From the synchronous FL aspect, Jiang et al. \cite{jiang2020decentralised} propose an adaptive partial gradient aggregation scheme, which not only makes full utilization of sufficient node-to-node bandwidth by transmitting accumulated local gradient slice but also takes advantage of Adam algorithm to speed up the convergence rate. Under the resource constraints, Sun et al. \cite{sun2020adaptive} dynamic adjust the aggregation frequency of FL based on Lyapunov dynamic deficit queue and deep reinforcement learning (DRL) to improve the learning performance. Moreover, \cite{zhang2021adaptive} and \cite{zhang_hang2021adaptive} use DRL to adaptively control of the local model training and the global model aggregation. However, these works rarely consider the effect of local learning rate on the global model convergence. 

% For the convergence issues of the learning rate in FL training, Reddi et al. \cite{reddi2020adaptive} present the upper bound for the client convergent learning rate of FedAdagrad, FedAdam and FedYogi. Charles et al. \cite{charles2021large} present FedLARS and FedLamb methods based on the adaptive learning rate optimizer LARS \cite{YangYou2017LargeBT} and Lamb \cite{YangYou2019LargeBO}. Leroy et al. \cite{leroy2019federated} empirically demonstrate that using an adaptive averaging strategy inspired from Adam in place of standard weighted model averaging highly reduces the number of communication rounds required to reach target performance. Moreover, \cite{hsieh2021fl} proposes a retraining mechanism with adaptive learning rates to compensate for the accuracy degradation caused by polarization in hyper-dimensional computing. These methods are variations of traditional ML adaptive gradient methods, but the adaptive learning rate for fast convergence is rarely considered. In this paper, we propose an adaptive learning rate strategy for each client by considering the deviation of the local model parameters and  the global model parameters at each global training iteration for fast convergence. In addition, a fixed-point algorithm is introduced to find the optimal learning rate based on a mean-field scheme. Then we successfully solve the optimal dynamic learning rate for each client at each global training iteration in closed form.

The rest of this paper is organized as follows. The system model and problem formulation are presented in Section \ref{sec_systemmodel}. In Section \ref{subsec_adlr}, we propose the adaptive learning rate via the entropy approach. Then experimental results are shown in Section \ref{sec_experiments}. Finally, we conclude this paper in Section \ref{sec_conclusion}.

\section{System Model and Problem Formulation}\label{sec_systemmodel}

In this section, we introduce the framework of the standard FL \cite{r1} and present our adaptive FL optimization problem by considering the deviation among the local model parameters at each global training iteration. 
% For ease of reading, we list the key notations in Table \ref{tab_Key_Notations}.

% \begin{table}[ht!]
%   \begin{center}
%     \caption{Key notations and their physical meanings.}
%     \label{tab_Key_Notations}
%     \begin{tabular}{|l|l|} % <-- Alignments: 1st column left, 2nd middle and 3rd right, with vertical lines in between
%     %   \textbf{Value 1} & \textbf{Value 2}\\
%       \hline
%       $N$ &  The number of participating clients \\
%       \hline
%       $T$ &  The total training round of FL \\
%       \hline
%       $E$ &  The local training epoch of client $i$ \\
%       \hline
%       $\boldsymbol{w(t)}$ &  The global parameters at iteration $t \in \{1, .., T\}$ \\
%       \hline
%       $\boldsymbol{w_{i}(t)}$ & \tabincell{l}{ The local parameters of client $i$ at iteration  \\ $t \in \{1, .., T\}$ }\\
%       \hline
%       $\theta_{i}$ &  The data weight ratio of client $i$ \\
%       \hline
%       $\eta_{i}(t)$ &  The learning rate of client $i$ at  iteration $t \in \{1, .., T\}$ \\
%       \hline
%       $p_{i}(t)$ &  \tabincell{l}{The weight proportion of client $i$ in the global \\ model parameters at iteration $t \in \{1, .., T\}$} \\
%       \hline
%       $\nabla F_{i}(\boldsymbol{w(t)})$ &  The local gradient of client $i$ at iteration $t \in \{1, .., T\}$ \\
%       \hline
%       $\boldsymbol{\phi_{1}(t)}$ & \tabincell{l}{The mean-field estimator of the \\ global parameters $\boldsymbol{w_{i}(t)}$} \\
%       \hline
%       $\phi_{2}(t)$ &  \tabincell{l}{The mean-field estimator of the \\ global weight $\Sigma_{i=1}^{N}\theta_{i} \boldsymbol{w_{i}(t)}^{T}\boldsymbol{w_{i}(t)}$} \\
%       \hline
%       $U(T)$ &  \tabincell{l}{Total expected information entropy on \\ the total training round of FL} \\
%       \hline
%     \end{tabular}
%   \end{center}
% \end{table}
                                                          
\subsection{Federated Learning Model}\label{subsec_FL_model}

\begin{figure}[htp]
    \centering
    % \includegraphics[width=10cm]{FL_diagram}
    \includegraphics[scale=0.3]{FL_process.pdf}
    \caption{The schematic diagram of federal learning}
    \label{fig_FL_diagram}
\end{figure}

As shown in Fig. 1, FL is a distributed ML paradigm in which a large number of mobile
clients coordinate with the central server to learn an ML model without sharing their own training data \cite{r1}. During each global iteration, each client uses local data to perform batch stochastic gradient descent (SGD) to update the local model parameters, and the central server aggregates the local model parameters of all clients to generate new global model parameters for the next global iteration.

Given $N$ clients participating in training, we assume that each participating client $i \in \{1,...,N\}$ uses its local dataset $\mathcal{D}_i$ with data size $D_i$. Denote the collection of data samples in $\mathcal{D}_i$ as $\{\boldsymbol{x_i^{j}}, y_i^{j}\}_{j=1}^{D_i}$, where $\boldsymbol{x_i^{j}} \in \mathbb{R}^{d \times 1}, y_i^{j} \in \mathbb{R}$ refer to the input sample vector and the labeled output value, respectively. The loss function $f_i^{j}(\boldsymbol{w})$ is used to measure the difference between real output ${y_i^{j}}$ and predicted output ${{\hat{y}}_i^{j}}$. Then the loss function $F_{i}(\boldsymbol{w})$ of client $i$ on the dataset $\mathcal{D}_i$ is defined as:
\begin{equation}\label{client_own_loss}
F_i(\boldsymbol{w}) = \frac{1}{D_i}\sum_{j \in {\mathcal{D}}_i} f_i^{j}(\boldsymbol{w}).
\end{equation}
Without loss of generality, we denote the total training round of FL as $T$ and use a general principle of SGD optimization \cite{HongdaWu2020FastConvergentFL} to update the model. At iteration $t + 1 \in \{1, 2, ..., T\}$, each client updates the local parameters based on their own dataset and their own learning rate based on the last global parameters $\boldsymbol{w(t)}$ sent by the central server:

\begin{equation}\label{w_static_update}
\boldsymbol{w_i(t+1)} = \boldsymbol{w(t)} - \eta_i\nabla F_i(\boldsymbol{w(t)}),
\end{equation}
where $\eta_i$ is the learning rate of client $i$ and $\nabla F_i(\boldsymbol{w(t)})$ is the gradient of client $i$ at iteration $t$. The server averages the parameters sent back by $N$ training clients to generate the new global parameters:
\begin{equation}\label{w_global_static_update}
\boldsymbol{w(t+1)}= \Sigma_{i=1}^{N}\theta_{i} \boldsymbol{w_i(t+1)},
\end{equation}
where $\theta_{i} = \frac{D_i}{\sum_{j=1}^{N}D_j}$ is the weight of client $i$.
Then the central server sends the updated global parameters $\boldsymbol{w(t + 1)}$ to all clients for the next round’s training.

% In a general way, 
In general, the objective of the FL model is to find the optimal global parameters $\boldsymbol{w}$ to minimize the global loss function $F(\boldsymbol{w})$:
\begin{equation}
    \underset{\boldsymbol{w}}{min} ~ F(\boldsymbol{w}) =\Sigma_{i=1}^{N} \theta_{i} F_{i}(\boldsymbol{w}).
\end{equation}

\subsection{Problem Formulation for Adaptive FL}
In the general FL algorithm, the local client will use a static learning rate to train the model. However, there are some problems with this update method. First of all, it cannot adapt to parameters update for different clients, which will lead to local client models deviation from the optimal global  model when the distribution of data and devices of the clients are heterogeneous \cite{hsu2019measuring}. Moreover, the static learning rate reduces the convergence speed of the model compared with the dynamic learning rate \cite{agrawal2021genetic}.

% Firstly, it may lead to the local client models moving away from globally optimal models due to the heterogeneity of data and device \cite{hsu2019measuring, SaiPraneethKarimireddy2020SCAFFOLDSC}. For example, the global model will converge to an inaccurate result with a really slow velocity if some clients maliciously use extremely outrageous data to train. Secondly, it cannot dynamically adjust the learning rate for each round to aggregate the contribution of each client to the global parameters \cite{reddi2020adaptive}. In addition, it does not take into account the effect of learning rate on model convergence \cite{li2019convergence}.

To solve the above problems, the following dynamic learning rate is introduced to update the local model parameters at iteration $t + 1$:
\begin{equation}\label{dynamic_w_update}
\boldsymbol{w_i(t+1)} = \boldsymbol{w(t)}-\eta_i(t)\nabla F_i(\boldsymbol{w(t)}),
\end{equation}
where $\eta_i(t) \in \mathbb{R}^{+} $ is the learning rate of client $i$ at iteration $t$.

In addition, the smaller the difference between each client's parameters, the faster the model converges \cite{sattler2020clustered}. That is to say, the model will tend to converge when the local parameters of each client are similar. Note that the entropy function can be used to measure the diversity between variables. To spread out differences between the local parameters and achieve fast convergence, the entropy term $\Sigma_{i=1}^{N}p_{i}(t) \log p_{i}(t) = 1$ with 
\begin{equation}\label{p_init}
    p_{i}(t) = \frac{\theta_{i} \boldsymbol{w_{i}(t)}^{T}\boldsymbol{w_{i}(t)}}{\Sigma_{j=1}^{N} \theta_{j} \boldsymbol{w_{j}(t)}^{T}\boldsymbol{w_{j}(t)}} \in [0, 1]
\end{equation}
is introduced in the objective function $U_{i}(T) $ of client $ i \in \{1,...,N\}$ for adaptive learning rate design:
% have the same proportion of the global parameters. Thus, we denote the weight proportion of client $i$ in the global model parameters as:
% \begin{equation}\label{p_init}
%     p_{i}(t) = \frac{\theta_{i} \boldsymbol{w_{i}(t)}^{T}\boldsymbol{w_{i}(t)}}{\Sigma_{j=1}^{N} \theta_{j} \boldsymbol{w_{j}(t)}^{T}\boldsymbol{w_{j}(t)}} \in [0, 1].
% \end{equation}
% Then we construct the following problem form based on information entropy theory \cite{harte2014maximum}:
\begin{equation}\label{objective}
U_{i}(T) = \underset{\substack{\eta_{i}(t) \\ t \in \{0, ..., T\}}}{min}
 \Sigma_{t=0}^{T}(\beta \Sigma_{j=1}^{N}p_{j}(t) \log p_{j}(t) + (1 - \beta)\eta_{i}^{2}(t)),
\end{equation}
\rightline{s.t.\quad$\boldsymbol{w_i(t+1)} = \boldsymbol{w(t)}-\eta_i(t)\nabla F_i(\boldsymbol{w(t)})$,\quad\quad\quad (\ref{dynamic_w_update})}
%\rightline{\quad$p_{i}(t) = \frac{\theta_{i} \boldsymbol{w_{i}(t)}^{T}\boldsymbol{w_{i}(t)}}{\Sigma_{j=1}^{N} \theta_{j} \boldsymbol{w_{j}(t)}^{T}\boldsymbol{w_{j}(t)}}$,\quad\quad\quad\quad\quad\quad (\ref{p_init})}
where $\beta$ controls the degree of aggregation.

However, there are many problems in the optimization of the objective function $U_{i}(T)$. Firstly, it is difficult to solve the optimal dynamic learning rate by considering the huge number of learning rate combinations over time. Moreover, the design of learning rate $\eta_i(t)$ of client $i$ is not only affected by its own local parameters $\theta_{i} \boldsymbol{w_{i}(t)}^{T}\boldsymbol{w_{i}(t)}$, but also affected by the local parameters of other clients via the term $\Sigma_{j=1}^{N} \theta_{j} \boldsymbol{w_{j}(t)}^{T}\boldsymbol{w_{j}(t)}$. 
% Moreover, client $i$ cannot obtain the global weight $\Sigma_{j=1}^{N} \theta_{j} \boldsymbol{w_{j}(t)}^{T}\boldsymbol{w_{j}(t)}$.
% In addition, the learning rate $\eta_i(t)$ is affected by the global parameters $\boldsymbol{w(t)}$ over time, which in turn affects the learning rate $\eta_i(t)$. 
This makes the multi-agent joint learning rate design more challenging. In order to solve the above problem, we first  derive the decentralized dynamic learning rate $\eta_i(t)$ for each client $i$ via a mean-field approach, then we prove the existence of the approximate mean-field terms via fixed point theorem and propose an algorithm to finalize the learning rate design.


\section{Approach of Adaptive Learning Rate}\label{subsec_adlr}

In this section, we will find the optimal adaptive learning rate $\eta_{i}(t)$ for each client $i$ via a mean-field scheme. We first solve the adaptive learning rate $\eta_{i}(t)$ by constructing the mean-field terms $\boldsymbol{\phi_1(t)}$ and $\phi_2(t)$ to estimate the global parameters $\boldsymbol{w(t)}$ and  $\Sigma_{i}^{N} \theta_{i} \boldsymbol{w_{i}(t)}^{T}\boldsymbol{w_{i}(t)}$, respectively. Then we  prove the existence of the mean-field terms $\boldsymbol{\phi_1(t)}$ and $ \phi_2(t)$ based the Brouwer’s fixed point theorem. Finally, we propose an algorithm used to find the adaptive learning rate. 

\subsection{Adaptive Learning Rate for Each Client}\label{subsec_adp_lr_client}

In order to solve the adaptive learning rate for each client, we will first introduce the mean-field term that estimates the global weight $\Sigma_{j=1}^{N} \theta_{j} \boldsymbol{w_{j}(t)}^{T}\boldsymbol{w_{j}(t)}$.
Note that $\Sigma_{j=1}^{N} \theta_{j} \boldsymbol{w_{j}(t)}^{T}\boldsymbol{w_{j}(t)}$ is the integration of local updated parameters obtained by various clients after local training. The learning rate will affect the local updated parameter of the individual client, as well as the value of $\Sigma_{j=1}^{N} \theta_{j} \boldsymbol{w_{j}(t)}^{T}\boldsymbol{w_{j}(t)}$, which in turn affects the local parameter updating and adaptive learning rate design. But other clients' local information may be unknown when designing the adaptive learning rate for each client, especially for a large number of clients. Thus, we introduce the mean-field terms $\boldsymbol{\phi_1(t)}, \phi_2(t), t\in\{0, ..., T\}$ to estimate the $\sum_{i=1}^{N} \theta_i \boldsymbol{w_i(t)}$ and $\sum_{i=1}^{N} \theta_i \boldsymbol{w_i(t)}^T\boldsymbol{w_i(t)}$ respectively over time, i.e., we want to find two functions $\boldsymbol{\phi_1(t)}$ and $\phi_2(t)$ such that

\begin{equation}\label{phi_1}
    \boldsymbol{\phi_1(t)}  = \sum_{i=1}^{N} \theta_i \boldsymbol{w_i(t)},
\end{equation}
\begin{equation}\label{phi_calc}
    \phi_2(t) = \sum_{i=1}^{N} \theta_i \boldsymbol{w_i(t)}^T\boldsymbol{w_i(t)}.
\end{equation}
% From Eq (\ref{phi_1} - \ref{phi_calc}), we can see that $\boldsymbol{\phi_{1}(t)}, \phi_{2}(t),t\in\{0,...,T\}$ is a given function no matter how $\eta_i(t)$  changes. 
Then entropy term could be evaluated as:
\begin{equation}\label{p_phi}
    \bar{p_{i}}(t) = \frac{\theta_{i} \boldsymbol{w_{i}(t)}^{T}\boldsymbol{w_{i}(t)}}{\phi_{2}(t)} \in [0, 1].
\end{equation}
% Now the adaptive learning rate of each client $i$ is only affected by the mean-field term $\boldsymbol{\phi_1(t)}$ and its local information.
% In this case, 
Then the objective of client $ i \in \{1,...,N\}$ becomes:
\begin{equation}\label{new_objective}
J_{i}(T) = \underset{\substack{\eta_{t}(t) \\ t \in \{0, ..., T\}}}{min}
 \Sigma_{t=0}^{T} (\beta \Sigma_{j=1}^{N} \bar{p_{j}}(t) \log \bar{p_{j}}(t) + (1 - \beta)\eta^{2}_{i}(t)),
\end{equation}
\begin{equation}\label{equ_dynamicsMF} \text{s.t.}~~~ \boldsymbol{w_i(t+1)} = \boldsymbol{\phi_1(t)}-\eta_i(t)\nabla F_i(\boldsymbol{\phi_1(t)})\end{equation}
\rightline{\quad$\bar{p_{i}}(t) = \frac{\theta_{i} \boldsymbol{w_{i}(t)}^{T}\boldsymbol{w_{i}(t)}}{\phi_{2}(t)}$. \quad\quad\quad\quad\quad\quad (\ref{p_phi})}
According to the above system, the adaptive learning rate of each client $i$ is only affected
by the mean-field terms $\boldsymbol{\phi_1(t)}, \phi_2(t)$ and its local information.
By constructing the Hamiltonian equation, we can obtain $\eta_i(t)$ as shown in the following proposition.
\begin{pro}\label{pro_eta_t_0}
Given the mean-field term $\boldsymbol{\phi_{1}(t)}, \phi_{2}(t),t\in\{0,1,...,T\}$, the optimal adaptive learning rate of client $i \in \{1,...,N\}$ at iteration $t \in \{0,1,...,T-1\}$ satisfies the following equation:
\begin{equation}\label{eta_solve_t_1}
\begin{split}
\eta_{i}(t) &= \Big(\frac{\theta_{i}(\boldsymbol{\phi_{1}(t)} - \eta_{i}(t)\nabla F_{i}(\boldsymbol{\phi_{1}(t)}))^{T}}{\phi_{2}(t + 1)} \times \frac{\beta \nabla F_{i}(\boldsymbol{\phi_{1}(t)})}{(1 - \beta)} \Big ) \\ & * \Bigg (1 + \log \bigg[  \theta_{i} (\boldsymbol{\phi_{1}(t)} - \eta_{i}(t)\nabla F_{i}(\boldsymbol{\phi_{1}(t)}))^{T} \\ & \times \frac{(\boldsymbol{\phi_{1}(t)} - \eta_{i}(t)\nabla F_{i}(\boldsymbol{\phi_{1}(t)}))}{\phi_{2}(t + 1)} \bigg] \Bigg),
\end{split}
\end{equation}
% \begin{equation}\label{eat_and_nabla_0}
% \left | \eta_{i}(t) \right | < \frac{ \left | \boldsymbol{\phi_{1}(t)}^{T} \nabla F_{i}(\boldsymbol{\phi_{1}(t)}) \right |}{\nabla F_{i}(\boldsymbol{\phi_{1}(t)})^{T} \nabla F_{i}(\boldsymbol{\phi_{1}(t)})},
% \end{equation}
with $\eta_i(T)=0$.
\end{pro}

\textbf{Proof:} Based on the objective function (\ref{new_objective}) with the mean-field terms $\boldsymbol{\phi_{1}(t)}$ and $\phi_2(t)$, we can construct the following Hamilton equation:
\begin{equation}\label{Hamilton_eq}
\begin{aligned}
H(t) &= \beta \Sigma_{j=1}^{N}\bar{p_{j}}(t) \log \bar{p_{j}}(t) + (1 - \beta)\eta^{2}_{i}(t) 
\\ & + \boldsymbol{\lambda_{i}(t + 1)}(\boldsymbol {\phi_{1}(t)} - \eta_{i}(t)\nabla F_{i}(\boldsymbol{\phi_{1}(t)}) -\boldsymbol{w_{i}(t)}),
\end{aligned}
\end{equation}
where $\boldsymbol{\lambda_{i}(t + 1)} \in \mathbb{R}^{1 \times d}$ is a vector whose size is $1 \times d$. Since $\frac{\partial^2 H(t)}{\partial \eta_{i}^2(t)} =2(1 - \beta) >0$, the Hamiltonian function $H(t)$ is convex in $\eta_{i}(t)$. Therefore, in order to find the optimal dynamic learning rate that minimizes the objective function $J_{i}(T)$ in (\ref{Hamilton_eq}), it is necessary to satisfy:
% To obtain the expression of $\eta_i(t)$, we use the equation (\ref{Hamilton_eq}) to find the first derivative of the Hamilton function with respect to $\eta_i(t)$:
\begin{equation}\label{eta_first_derivative}
\frac{\partial H(t)}{\partial \eta_{i}(t)} = 0,
\end{equation}
\begin{equation}\label{H_lambda_rel}
\boldsymbol{\lambda_{i}(t + 1)} - \boldsymbol{\lambda_{i}(t)} = -\frac{\partial H(t)}{\partial \boldsymbol{w_{i}(t)}}.
\end{equation}
Based on Eq (\ref{eta_first_derivative}), we can derive:
\begin{equation}
    2(1 - \beta)\eta_{i}(t) + \boldsymbol{\lambda_{i}(t + 1)}(-\nabla F_{i}(\boldsymbol{\phi_{1}(t)})) = 0,
\end{equation}
\begin{equation}\label{eta_solve_1}
\eta_{i}(t) = \frac{\boldsymbol{\lambda_{i}(t + 1)}\nabla F_{i}(\boldsymbol{\phi_{1}(t)})}{2(1 - \beta)}. \\
\end{equation}
According to Eq (\ref{H_lambda_rel}), we can get:
\begin{equation}\label{lambda_rel}
\begin{split}
\boldsymbol{\lambda_{i}(t + 1)} - \boldsymbol{\lambda_{i}(t)} &= \boldsymbol{\lambda_{i}(t + 1)} - \bigg ( \beta\frac{2\theta_{i} \boldsymbol{w_{i}(t)}^{T}}{\phi_{2}(t)} \\ &* \Big(\log \big[\frac{\theta_{i} \boldsymbol{w_{i}(t)}^{T}\boldsymbol{w_{i}(t)}}{\phi_{2} (t)}\big] + 1  \Big) \bigg).
\end{split}
\end{equation}
% Now we can easily derive the following equation of $\boldsymbol{\lambda_{i}(t)}$:
\begin{equation}\label{lambda_solve}
\boldsymbol{\lambda_{i}(t)} = \beta\frac{2\theta_{i} \boldsymbol{w_{i}(t)}^{T}}{\phi_{2}(t)}\Big(\log \big[ \frac{\theta_{i} \boldsymbol{w_{i}(t)}^{T}\boldsymbol{w_{i}(t)}}{\phi_{2}(t)}\big] + 1 \Big).
\end{equation}
By inserting $\boldsymbol{\lambda_{i}(t)}$ in (\ref{lambda_solve}) into the expression of $\eta_{i}(t)$ in (\ref{eta_solve_1}), 
the optimal adaptive learning rate of client $i$  can be derived as Eq (\ref{eta_solve_t_1}).
% we have:
% \begin{equation}\label{eat_solve_nalba}
% \begin{split}
% % \eta_{i}(t) &= \beta \frac{2\theta_{i} \boldsymbol{w_{i}(t + 1)}^{T}}{\phi_{2}(t + 1)} \times \frac{\nabla F_{i}(\boldsymbol{\phi_{1}(t)})}{2(1 - \beta)} \\ & *\Big(\log \big[ \frac{\theta_{i} \boldsymbol{w_{i}(t + 1)}^{T}\boldsymbol{w_{i}(t + 1)}}{\phi_{2}(t + 1)}\big] + 1  \Big) \\
% \eta_{i}(t) &= \Big(\frac{\theta_{i}(\boldsymbol{\phi_{1}(t)} - \eta_{i}(t)\nabla F_{i}(\boldsymbol{\phi_{1}(t)}))^{T}}{\phi_{2}(t + 1)} \times \frac{\beta \nabla F_{i}(\boldsymbol{\phi_{1}(t)})}{(1 - \beta)} \Big ) \\ & * \Bigg (1 + \bigg[ \log   \big \{\theta_{i} (\boldsymbol{\phi_{1}(t)} - \eta_{i}(t)\nabla F_{i}(\boldsymbol{\phi_{1}(t)}))^{T} \\ & \times \frac{(\boldsymbol{\phi_{1}(t)} - \eta_{i}(t)\nabla F_{i}(\boldsymbol{\phi_{1}(t)}))}{\phi_{2}(t + 1)} \big \} \bigg] \Bigg).
% \end{split}
% \end{equation}
% with $\eta_{i}(T) = 0, i \in \{1, ..., N\}, t \in \{0, 1, ..., T\}$.

% Based on (\ref{eat_solve_nalba}), we can obtain:
% \begin{equation}\label{eta_and_nabla_1}
% \begin{split}
% \eta_{i}(t) &= \Big( \frac{\beta \theta_{i}}{1- \beta} \frac{ (\boldsymbol{\phi_{1}(t)} - \eta_{i}(t) \nabla F_{i}(\boldsymbol{\phi_{1}(t)}) )^{T} \nabla F_{i}(\boldsymbol{\phi_{1}(t)})}{\phi_{2}(t + 1)} \Big ) \\ & * \Big(\log \big[ p_{i}(t + 1)\big] + 1  \Big) \\
% \eta_{i}(t) &= \frac{\boldsymbol{\phi_{1}(t)}^{T} \nabla F_{i}(\boldsymbol{\phi_{1}(t)})}{\frac{(1 - \beta)\phi_{2}(t + 1)}{\beta \theta_{i} (1 + \log p_{i}(t + 1))}  + \Vert \nabla F_{i}(\boldsymbol{\phi_{1}(t)}) \Vert}.
% \end{split}
% \end{equation}
% where $l_{i}(t) = \frac{(1- \beta)\phi_{2}(t + 1)}{\log p_{i}(t + 1) + 1}$.
% Note that $0 < p_{i}(t) \leq 1, (\log p_{i}(t) + 1) < 1, \phi_{2}(t) > 0$, $\boldsymbol{w_{i}(t)}^T\boldsymbol{w_{i}(t)} > 0, \nabla F_{i}(\boldsymbol{w(t)})^T \nabla F_{i}(\boldsymbol{w(t)}) > 0$. 
% \begin{enumerate}
%     \item If $(\boldsymbol{\phi_{1}(t)} - \eta_{i}(t) \nabla F_{i}(\boldsymbol{\phi_{1}(t)}) )^{T} \nabla F_{i}(\boldsymbol{\phi_{1}(t)}) > 0 $, then we can derive:
%     \begin{equation}\label{eta_and_nabla_2}
%     \begin{split}
%     \eta_{i}(t) & <  \frac{\beta \theta_{i}}{1- \beta} \frac{ (\boldsymbol{\phi_{1}(t)} - \eta_{i}(t) \nabla F_{i}(\boldsymbol{\phi_{1}(t)}) )^{T} \nabla F_{i}(\boldsymbol{\phi_{1}(t)})}{\phi_{2}(t + 1)}  \\
%     \eta_{i}(t) & < \frac{\boldsymbol{\phi_{1}(t)}^{T} \nabla F_{i}(\boldsymbol{\phi_{1}(t)})}{\frac{(1 - \beta)}{\beta \theta_{i}} \phi_{2}(t + 1) + \nabla F_{i}(\boldsymbol{\phi_{1}(t)})^{T} \nabla F_{i}(\boldsymbol{\phi_{1}(t)})}. \\
%     \end{split}
%     \end{equation}
%     \item If $(\boldsymbol{\phi_{1}(t)} - \eta_{i}(t) \nabla F_{i}(\boldsymbol{\phi_{1}(t)}) )^{T} \nabla F_{i}(\boldsymbol{\phi_{1}(t)}) < 0 $, then we can derive:
%     \begin{equation}\label{eta_and_nabla_3}
%     \begin{split}
%     \eta_{i}(t) & >  \frac{\beta \theta_{i}}{1- \beta} \frac{ (\boldsymbol{\phi_{1}(t)} - \eta_{i}(t) \nabla F_{i}(\boldsymbol{\phi_{1}(t)}) )^{T} \nabla F_{i}(\boldsymbol{\phi_{1}(t)})}{\phi_{2}(t + 1)}  \\
%     \eta_{i}(t) & > \frac{\boldsymbol{\phi_{1}(t)}^{T} \nabla F_{i}(\boldsymbol{\phi_{1}(t)})}{\frac{(1 - \beta)}{\beta \theta_{i}} \phi_{2}(t + 1) + \nabla F_{i}(\boldsymbol{\phi_{1}(t)})^{T} \nabla F_{i}(\boldsymbol{\phi_{1}(t)})}. \\
%     \end{split}
%     \end{equation}
% \end{enumerate}
% Based on Eq (\ref{eta_and_nabla_2})-(\ref{eta_and_nabla_3}), then we can get:
% \begin{equation*}
% \begin{split}
% \left |\eta_{i}(t) \right | & < \frac{\left | \boldsymbol{\phi_{1}(t)}^{T} \nabla F_{i}(\boldsymbol{\phi_{1}(t)}) \right | }{\frac{(1 - \beta)}{\beta \theta_{i}} \phi_{2}(t + 1) + \nabla F_{i}(\boldsymbol{\phi_{1}(t)})^{T} \nabla F_{i}(\boldsymbol{\phi_{1}(t)})} \\
%  & <
% \frac{ \left | \boldsymbol{\phi_{1}(t)}^{T} \nabla F_{i}(\boldsymbol{\phi_{1}(t)}) \right |}{\nabla F_{i}(\boldsymbol{\phi_{1}(t)})^{T} \nabla F_{i}(\boldsymbol{\phi_{1}(t)})}.
% \quad\quad\quad (\ref{eat_and_nabla_0})
% \end{split}
% \end{equation*}
\qed


\begin{algorithm}[] 
\caption{Iterative Computation of Fixed Point} 
\begin{algorithmic}[1] 
\REQUIRE ~~\\ 
Initiate the training epoch $k=0$, fixed point threshold $\varepsilon_{1}=0.001$, $\varepsilon_{2}= 0.001$, global model parameter $w_i(0), i\in\{1,...N\}$, mean-field estimators $\boldsymbol{\phi_{1}^{0}(t)}, \phi_{2}^{0}(t), t\in\{1,...,T\}$. 
%$\boldsymbol{\phi_{1}^{0}(1)}$,...,$\boldsymbol{\phi^0(T)}$ %with random numbers in $(0,1)$
\ENSURE ~~\\ %算法的输出：Output 
The fixed point of the mean-field item $\boldsymbol{\phi_{1}(t)}$ and $\phi_{2}(t)$, $t \in \{1, 2, ..., T\}$.

\STATE \textbf{do}
%\FOR{$k=0$ to $K$} 

\FOR{$t=0$ to $T-1$} 
\FOR{$i=1$ to $N$}
\STATE compute $\eta_i(t)$ based on $\boldsymbol{\phi_{1}^k(t)}, \phi_{2}(t), t\in\{1,...,T\}$ according to Eq (\ref{eta_solve_t_1})
\STATE compute $\boldsymbol{w_i(t+1)}$ according to Eq (\ref{equ_dynamicsMF})
\ENDFOR
% \STATE compute $\boldsymbol{\phi_{1}^{k+1}(t+1)}=\sum_{i=1}^{N}\theta_i \boldsymbol{w_i(t+1)}$
% \STATE compute $\phi_{2}^{k+1}(t+1)=\sum_{i=1}^{N}\theta_i \boldsymbol{w_i(t+1)}^{T}\boldsymbol{w_i(t+1)}$
\STATE compute $\boldsymbol{\phi_{1}^{k+1}(t+1)}$ according to Eq (\ref{phi_1})
\STATE compute $\phi_{2}^{k+1}(t+1)$ according to Eq (\ref{phi_calc})
\ENDFOR 
%\ENDFOR
\STATE $k=k+1$
\STATE \textbf{while} $\boldsymbol{\phi_{1}^{k}(t)}$-$\boldsymbol{\phi_{1}^{k-1}(t)}$ $\geq$ $\varepsilon_{1}$ and $\phi_{2}^{k}(t) - \phi_{2}^{k-1}(t) \geq  \varepsilon_{2}$

\end{algorithmic}
\label{alg of the fixed point} 
\end{algorithm}


\begin{algorithm}[t]
\caption{Federated Learning with Adaptive Learning Rate via Entropy (Adp\_Entr)}
\begin{algorithmic}[1]
%算法的输入参数：Input
\REQUIRE ~~\\ 
    The initial global model parameter $\boldsymbol{w(0)}$, mean-filed terms $\phi_1(t), \phi_{2}(t), t \in \{0, 1, .., T\}$, learning rate $\eta_{i}(-1)$, control parameter $\beta$, decay parameter $\gamma$ and the local training epoch of the client $E$.
\ENSURE ~~\\ %算法的输出：Output
    The optimal global model parameter $\boldsymbol{w(T)}$.
\FOR {$t=0,...,T-1$}
    \STATE  $\boldsymbol{w_{i, 0}(t)} = \boldsymbol{w(t)}$
    \FOR {each client $i \in S$ \textbf{in parallel}}
        \STATE Sample a random batch of data from $\mathcal{D}_i$ to compute the local gradient $\nabla F_{i}(w(t))$
        \STATE Solve $\eta_{i}(t)$ according to Eq (\ref{eta_solve_t_1}), (\ref{eta_deacy})
        \FOR {$k=0, ..., E - 1$}
            \STATE Compute the local gradient $\nabla F_{i}(\boldsymbol{w_{i, k}(t)})$
            \STATE  $\boldsymbol{w_{i, k + 1}(t)} = \boldsymbol{w_{i, k}(t)} - \eta_{i}(t) \nabla F_{i}(\boldsymbol{w_{i, k}(t)})$
        \ENDFOR
    \ENDFOR 
    \STATE $\boldsymbol{w(t + 1)} = \Sigma_{i=1}^{N} \theta_{i}  \boldsymbol{w_{i, E}(t + 1)}$
\ENDFOR
\end{algorithmic}
\label{alg_adlr}
\end{algorithm}

\subsection{Update of Mean-Field Estimator for Finalizing Learning Rate}
In this section, we determine the mean-field terms $\boldsymbol{\phi_{1}(t)}$ and $\phi_{2}(t)$ according to the given optimal adaptive learning rate $\eta_{i}(t)$ in (\ref{eta_solve_t_1}). Note that the estimator $\boldsymbol{\phi_{1}(t)}$ and $\phi_{2}(t)$ which are constructed to estimate $\boldsymbol{w(t)}$ and $\Sigma_{i=1}^{N} \theta_{i=1}\boldsymbol{w_{i}(t)}^{T}\boldsymbol{w_{i}(t)}$ are affected by the local updated parameters $\boldsymbol{w_{i}(t)}$ of all clients, which will in turn affect the local parameters. In the following proposition, we will determine the appropriate mean-field estimators $\boldsymbol{\phi_{1}(t)}$ and $\phi_{2}(t)$ via fixed point theorem.
\begin{pro}\label{pro_fix_point}
The mean-field estimators $\boldsymbol{\phi_{1}(t)}, t \in \{0, 1, ..., T - 1\}$ in 
(\ref{phi_1}) and $\phi_{2}(t), t \in \{0, 1, ..., T - 1\} $ in
(\ref{phi_calc}) exist and are returned by Algorithm \ref{alg of the fixed point}.
\end{pro}

% The proof of Proposition \ref{pro_fix_point} is given in the online technical report 1 due to the page limit.

% proof start

\textbf{Proof:} For any client $i \in \{1, ..., N\}$, substitute $\boldsymbol{\phi_{1}(t)} = \Sigma_{i=1}^{N} \theta_{i} \boldsymbol{w_{i}(t)}, \phi_{2}(t) = \sum_{i=1}^{N} \theta_i \boldsymbol{w_i(t)}^T\boldsymbol{w_i(t)}$ and $\eta_{i}(t)$ in (\ref{eta_solve_t_1}) into (\ref{equ_dynamicsMF}),  we can see that the local parameters $\boldsymbol{w_{i}(t)}$ of client $i$ at iteration $t$ is a function of the model parameters $\{\boldsymbol{w_{i}(t)}|t \in \{0, 1, ..., T\}, i \in \{1, ..., N\}  \}$ of all the zones over time. Define the following function as a mapping from $\{\boldsymbol{w_{i}(t)}|t \in \{0, 1, ..., T\}, i \in \{1, ..., N\} \}$ to the model parameter of client $i$ $\boldsymbol{w_{i}(t)}$ in (\ref{eta_solve_t_1}) at iteration $t$:
\begin{equation}\label{gamma_w_i_t}
    \Gamma_{i, t}(\{ \boldsymbol{w_{i}(t)}|t \in \{0, 1, ..., T\}, i \in \{1, ..., N\} \}) = \boldsymbol{w_{i}(t)}.
\end{equation}
In order to summarize any possible mapping $\Gamma_{i, t}(*)$ in (\ref{gamma_w_i_t}), we can
define the following vector function as a mapping from $\{\boldsymbol{w_{i}(t)}|t \in \{0, 1, ..., T\}, i \in \{1, ..., N\}  \}$to the set of all the clients' model parameters over time:
\begin{equation}\label{gamma_w_i_t_mapping}
\begin{split}
     & \Gamma(\{\boldsymbol{w_{i}(t)}|t \in \{0, 1, ..., T\}, i \in \{1, ..., N\} \}) \\
    =  &\Big(\Gamma_{1, 0}(\{\boldsymbol{w_{i}(t)}|t \in \{0, 1, ..., T\}, i \in \{1, ..., N\} \}), ..., \\
    & \Gamma_{1, T}(\{\boldsymbol{w_{i}(t)}|t \in \{0, 1, ..., T\}, i \in \{1, ..., N\} \}), ....,\\
    &\Gamma_{N, 0}(\{\boldsymbol{w_{i}(t)}|t \in \{0, 1, ..., T\}, i \in \{1, ..., N\} \}), ...., \\
    & \Gamma_{N, T}(\{\boldsymbol{w_{i}(t)}|t \in \{0, 1, ..., T\}, i \in \{1, ..., N\} \})
    \Big ).
\end{split}
\end{equation}
Thus, the fixed point to $\Gamma(\{\boldsymbol{w_{i}(t)}|t \in \{0, 1, ..., T\}, i \in \{1, ..., N\} \})$ in (\ref{gamma_w_i_t_mapping}) should be reached to let $\boldsymbol{\phi_{1}(t)}$ and $\phi_{2}(t)$ replicate $\sum_{i=1}^{N} \theta_i \boldsymbol{w_i(t)}^T\boldsymbol{w_i(t)}$ and $\Sigma_{i=1}^{N} \theta_{i} \boldsymbol{w_{i}(t)}$, respectively.

Firstly, $\boldsymbol{w_{i}(0)}$ as an initial model parameters value must be bounded for any client $i$. Thus, $\boldsymbol{\phi_{1}(0)} = \Sigma_{i=1}^{N} \theta_{i} \boldsymbol{w_{i}(0)}$ is bounded. According to Eq (\ref{eta_solve_t_1}), we can derive:
\begin{equation}\label{eta_and_phi}
    \eta_{i} (t) = A_{i}(\boldsymbol{\phi_{1}(t)}, \phi_2(t + 1)),
\end{equation}
where $A_{i}(*)$ is the analytic function of $\eta_{i}(t)$. Thus, we can obtain:
% \begin{equation}\label{phi_next_t_1}
%     \boldsymbol{\phi_{1}(t + 1)} = \boldsymbol{\phi_{1}(t)} - \Sigma_{i=1}^{N}\theta_{i}A_{i}(\boldsymbol{\phi_{1}(t)}, \phi_2(t + 1)) \nabla F_{i} (\boldsymbol{\phi_{1}(t)}),
% \end{equation}
\begin{equation}\label{phi_next_t_2}
\begin{split}
    \phi_{2}(t + 1) & = \Sigma_{i=1}^{N} \Bigg( \theta_{i} * \\
    & \Big(\boldsymbol{\phi_{1}(t)} - A_{i}(\boldsymbol{\phi_{1}(t)}, \phi_2(t + 1))\nabla F_{i} (\boldsymbol{\phi_{1}(t)}) \Big)^{T}   \times \\ & \Big(\boldsymbol{\phi_{1}(t)} - A_{i}(\boldsymbol{\phi_{1}(t)}, \phi_2(t + 1))\nabla F_{i} (\boldsymbol{\phi_{1}(t)}) \Big) \Bigg).
\end{split}
\end{equation}
Then based on Eq (\ref{phi_next_t_2}), we can get:
\begin{equation}\label{phi_2_and_phi_1}
    \phi_{2} (t + 1) = B(\boldsymbol{\phi_{1}(t)}),
\end{equation}
where $B(*)$ is the analytic function of $\phi_{2}(t)$. Now we can derive:
\begin{equation}\label{eta_solove_based_on_phi_1}
    \eta_{i} (t) = A_{i}(\boldsymbol{\phi_{1}(t)}, B(\boldsymbol{\phi_{1}(t)})).
\end{equation}
Based on Eq (\ref{eta_solove_based_on_phi_1}) and $A_{i}(*), B(*)$ are the analytic function, we can assume that the most at the maximum upper bound $C$ of $\eta_{i}(t)$:
\begin{equation}\label{eat_upper_bound}
    0 < \eta_{i}(t) \leq  C.
\end{equation}
Then we define the following local gradient bounded:
\begin{equation}\label{local_grad_bound}
    |\nabla F_{i}(w_{i}(t))| \leq D.
\end{equation}
By inserting Eq (\ref{eat_upper_bound}), (\ref{local_grad_bound}) into (\ref{equ_dynamicsMF}), we can get:
\begin{equation}
\begin{split}
    &\boldsymbol{w_{i}(1)} = \boldsymbol{\phi_{1}(0)}  - \eta_{i}(0)\nabla F_{i}(\boldsymbol{\phi_{1}(0)}) \\
    & \boldsymbol{\phi_{1}(0)} - CD \leq  \boldsymbol{w_{i}(1)} \leq \boldsymbol{\phi_{1}(0)} + CD \\
    & \boldsymbol{\phi_{1}(0)} - CD \leq  \boldsymbol{\phi_{1}(1)} \leq \boldsymbol{\phi_{1}(0)} + CD \\ 
    & \boldsymbol{\phi_{1}(0)} - tCD \leq  \boldsymbol{w_{i}(t)} \leq \boldsymbol{\phi_{1}(0)} + tCD
\end{split}
\end{equation}
Define set $\Omega = [\boldsymbol{\phi_{1}(0)} - CD, \boldsymbol{\phi_{1}(0)} + CD] \times ... \times  [\boldsymbol{\phi_{1}(0)} - TCD, \boldsymbol{\phi_{1}(0)} + TCD]$. Since $\Gamma_{i, t}$ is continuous, $\Gamma$ is a continuous mapping from $\Omega$ to $\Omega$. According to Brouwer’s fixed-point theorem, $\Gamma$ has a fixed point in $\Omega$.
\qed

% proof end



As mentioned above, we summarize the process of solving fixed points in Algorithm \ref{alg of the fixed point}.
In addition, we use the following weight decay method to avoid excessive fluctuations in the learning rate:
\begin{equation} \label{eta_deacy}
\eta_{i}(t) = \gamma * \eta_{i}(t - 1) + (1 - \gamma) * \eta_{i}(t),
\end{equation}
where $\gamma$ is the decay parameter. Thus, our adaptive federated learning process can be summarized in Algorithm \ref{alg_adlr}.




\section{Experiments}\label{sec_experiments}

In this section, we conduct simulation experiments on MNIST dataset to evaluate the performance of our proposed adaptive learning FL algorithm. We first introduce how to set up the experiments. Then we compare the performance of our adaptive learning rate method with other FL algorithms in terms of model accuracy and convergence rate. Finally, we verify the impact of the penalty weight $\beta$ on the performance of the FL model.

\subsection{Experiment Setup}
The experimental setup will be briefly introduced as follows.

\textbf{Dataset:} We use the MNIST dataset that is divided into training and test datasets. And there are 60,000 images in the test dataset and 10,000 images in the validation dataset.  By default, the images in the MNIST dataset are 28x28 pixels, with a total of 10 categories.

\textbf{Model:} We use a linear model with a fully connected layer of input channel 784 and output channel 10.

\textbf{Other FL Method:} The FL algorithms we mainly compare are FedAvg \cite{r1},  FedAdam \cite{reddi2020adaptive} and FedYogi \cite{reddi2020adaptive}.
% and Adp\_Mean \cite{tu2022adaptive}.

\textbf{Hyperparameters:} Similar to \cite{reddi2020adaptive}, we set $\beta_{1} = 0.9, \beta_{2} = 0.99, \tau=10^{-5}, \eta = 10^{-2},  \text{ and } \eta_{l} = 10^{-2} $ for FedAdam and FedYogi. By default, let $\beta=0.99$, $\gamma=0.99$ and global iteration $T=50$. During each global iteration, the local client trains $E$ epoch with a batch size is 10. We consider $N = 10$ clients and divide the Non-IID dataset similar to \cite{hsu2019measuring}.

% Similar to \cite{reddi2020adaptive}, we let $\beta_{1} = 0.0, \beta_{2} = 0.99$ for FedAdagrad. Then for FedAdam and FedYogi, we set $\beta_{1} = 0.9, \beta_{2} = 0.99$. 

\subsection{Comparison of the Algorithms}

\begin{table}[ht!]
\begin{center}
    \begin{tabular}{|l|l|l|}
    \hline
    \textbf{Methods} & \textbf{IID} & \textbf{Non-IID} \\ \hline
    FedAvg  & 0.925350010395050  &  0.868600070476532    \\ \hline
    FedAdam  &  \textbf{0.926049888134002}   &   0.875950068235397   \\ \hline
    FedYogi  & 0.926049917936325  &   0.860500067472457     \\ \hline
    % Adp\_Mean & 0.9245501458644867 &  0.8826999068260193 \\ \hline
    Adp\_Entr  &  0.924800097942352 &  \textbf{0.896000087261200}  \\ \hline
    \end{tabular}
\end{center}
\caption{The performance of different FL methods in MNIST dataset when the global iteration $T=50$ and local epoch $E=8$.}
\label{tab_fedadlrv2_mnist_8}
\end{table}

We present the performance of different FL methods on the MNIST dataset as in Table \ref{tab_fedadlrv2_mnist_8} when the global iteration $T =50$ and local epoch $E=8$.  For the IID dataset, there is not much difference between the several FL methods. As shown in Fig. \ref{FedAdlrv2_in_IID_8}, our method Adp\_Entr converges faster than other adaptive models such as FedAdam and FedYogi. For the Non-IID client data distribution, our adaptive method achieves 2\% accuracy improvement compared to other FL methods.  Fig. \ref{FedAdlrv2_in_Non_IID_8} shows that our adaptive method converges faster and has higher accuracy than other methods. This indicates that our proposed adaptive method can effectively spread out the difference between different local parameters and achieve a faster convergent rate. 


\begin{figure}[htp]
\centering\includegraphics[scale=0.5]{FedAdlrv2_local_e_8_in_IID}
\caption{The performance of different FL methods on the IID data case when the global iteration $T=50$ and local epoch $E=8$.}
\label{FedAdlrv2_in_IID_8}
\end{figure}

\begin{figure}[htp]
\centering\includegraphics[scale=0.5]{FedAdlrv2_local_e_8_in_Non_IID}
\caption{The performance of different FL methods on the Non-IID data case when the global iteration $T=50$ and local epoch $E=8$.}
\label{FedAdlrv2_in_Non_IID_8}
\end{figure}

\begin{figure}[h]
\centering\includegraphics[scale=0.5]{FedAdlrv2_beta_local_e_8_in_Non_IID}
\caption{The impact of control parameter $\beta$ on the Non-IID data case.}
\label{FedAdplr_beta_in_Non_IID}
\end{figure}

In addition, we analyze the influence of penalty parameter $\beta$ in Eq (\ref{objective}) on the model convergence performance. As shown in Fig. \ref{FedAdplr_beta_in_Non_IID}, with the increase of penalty weight $\beta$ on the diversity among the clients' local parameters, our adaptive algorithm will try its best to minimize the difference between the local updating parameters, which leads to a faster convergent rate.


\section{Conclusion}\label{sec_conclusion}

In this paper, we discuss the convergent rate and accuracy of the global model in federated learning for Non-IID clients. Firstly, to achieve fast convergence, we utilize entropy theory to measure the difference between different local model parameters. Then, we propose the adaptive learning rate for each client via a mean-field approach, which effectively estimates the terms related to other clients' model parameters over time and avoids frequent communication. Finally, the experimental results on the MNIST dataset show that the proposed adaptive learning rate algorithm has a higher accuracy and a faster convergent rate compared to other FL algorithms.

% and introduced the learning rate penalty term to control the convergence rate of the global model. What's more, we use the mean-field term to estimate the change of global model parameters over time, so as to achieve the discrete client learning rate design to avoid frequent communication. Finally, the experimental results on the MNIST dataset show that the proposed adaptive learning rate algorithm has higher accuracy and convergence speed.


\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,ref}
% \bibliography{ref.bib}
\end{document}
