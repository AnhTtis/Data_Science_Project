%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{IEEEtran}  % Comment this line out
                                                          % if you need a4paper
%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4
                                                          % paper

\IEEEoverridecommandlockouts                              % This command is only
                                                          % needed if you want to
                                                          % use the \thanks command
\usepackage[T1]{fontenc}
\usepackage{aecompl}
% \usepackage[numbers, sort&compress]{natbib}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithm}
\usepackage{algorithmic}
\renewcommand{\algorithmicrequire}{ \textbf{Input:}} %Use Input in the format of Algorithm
\renewcommand{\algorithmicensure}{ \textbf{Output:}} %UseOutput in the format of Algorithm
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{enumerate}  
% \usepackage[inline]{enumitem}
% \newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
\def \qed {\hfill \vrule height6pt width 6pt depth 0pt}
\newtheorem{ass}{Assumption}[section]
\newtheorem{pro}{Proposition}[section]
\newtheorem{lem}{Lemma}[section]
\newtheorem{rem}{Remark}[section]
\newtheorem{cor}{Corollary}[section]
\newtheorem{thm}{Theorem}[section]
\newtheorem{exa}{Example}[section]
\newcommand{\BOX}{\hfill\rule{2mm}{2mm}}

\overrideIEEEmargins
% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document



% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

\title{\LARGE \bf
Adaptive Federated Learning via New Entropy Approach
}

%\author{ \parbox{3 in}{\centering Huibert Kwakernaak*
%         \thanks{*Use the $\backslash$thanks command to put information here}\\
%         Faculty of Electrical Engineering, Mathematics and Computer Science\\
%         University of Twente\\
%         7500 AE Enschede, The Netherlands\\
%         {\tt\small h.kwakernaak@autsubmit.com}}
%         \hspace*{ 0.5 in}
%         \parbox{3 in}{ \centering Pradeep Misra**
%         \thanks{**The footnote marks may be inserted manually}\\
%        Department of Electrical Engineering \\
%         Wright State University\\
%         Dayton, OH 45435, USA\\
%         {\tt\small pmisra@cs.wright.edu}}
%}

\author{Shensheng Zheng, 
\thanks{S. Zheng is with the School of Artificial Intelligence, Sun Yat-sen University, Zhuhai 519082, China {\tt\small zhengshsh7@mail2.sysu.edu.cn}. }%
Xuehe Wang*
\thanks{X. Wang is with the School of Artificial Intelligence, Sun Yat-sen University, Zhuhai 519082, China, and also with the Guangdong Key Laboratory of Big Data Analysis and Processing, Guangzhou 510006, China  {\tt\small wangxuehe@mail.sysu.edu.cn} (*Corresponding author).}%
and Lingjie Duan
\thanks{L. Duan is with the Pillar of Engineering Systems and Design, Singapore University of Technology and Design, Singapore {\tt\small lingjie\_duan@sutd.edu.sg}}
\thanks{This work was supported by the National Natural Science Foundation of China (Grant No. 62206320).}
}

\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

Federated Learning (FL) has recently emerged as a popular framework, which allows resource-constrained discrete clients to cooperatively learn the global model under the orchestration of a central server while storing privacy-sensitive data locally. However, due to the difference in equipment and data divergence of heterogeneous clients, there will be parameter deviation between local models, resulting in a slow convergence rate and a reduction of  the accuracy of the global model. The current FL algorithms use the static client learning strategy pervasively and can not adapt to the dynamic training parameters of different clients. In this paper, by considering the deviation between different local model parameters, we propose an adaptive learning rate scheme for each client based on entropy theory to alleviate the deviation between heterogeneous clients and achieve fast convergence of the global model. It's difficult to design the optimal dynamic learning rate for each client as the local information of other clients is unknown, especially during the local training epochs without communications between local clients and the central server. To enable a decentralized learning rate design for each client, we first introduce mean-field schemes to estimate the terms related to other clients' local model parameters. Then the decentralized adaptive learning rate for each client is obtained in closed form by constructing the Hamilton equation. Moreover, we prove that there exist fixed point solutions for the mean-field estimators, and an algorithm is proposed to obtain them. Finally, extensive experimental results on real datasets show that our algorithm can effectively eliminate the deviation between local model parameters compared to other recent FL algorithms.

\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}

The boom in the Internet of Things (IoT) and Artificial Intelligence (AI) makes it possible to use vast amounts of discrete client data to train efficient machine learning (ML) models (e.g., for recommendation systems \cite{ghosh2020efficient}). However, traditional ML requires the collection of massive data, which increases the risk of personal data privacy leakage \cite{bonawitz2017practical}. To save computing resources and protect users' privacy, Federated Learning (FL) allows resource-constrained discrete clients to collaboratively learn the global model under the orchestration of a central server while keeping privacy-sensitive data locally \cite{yang2019federated}.

The current popular FL algorithms are the Federated Averaging (FedAvg) and its variants \cite{r1}. It usually consists of a central server and a group of distributed clients. In each training round, discrete clients first obtain the global model parameters of the previous round from the central server and then uses their own local data to generate the local model parameters. Then the central server will aggregate the local model parameters from discrete clients and generate the new global parameters. The total training will terminate when the accuracy loss of the global model is below the preset threshold \cite{r1}. Under this framework, the server effectively utilizes clients’ computing power and storage resources while realizing the separation of privacy data \cite{tran2019federated}.

Although FedAvg performs well on Gboard application \cite{hard2018federated},  recent works (\cite{zhao2018federated, hsu2019measuring, karimireddy2020scaffold}) have pointed out its convergence issues in some settings. For example, FedAvg \cite{r1} will converge slowly and the accuracy will be reduced on the non-independent-and-identically-distributed (Non-IID) client dataset \cite{sattler2019robust}. Reddi et al. \cite{reddi2020adaptive} show that this is because of client parameter drift and lack of adaptivity to the different models. Moreover, Tan et al. \cite{tan2022towards} point out that FedAvg can not learn the personalized FL model for each client.

To deal with the convergence issues for the Non-IID dataset, the current FL algorithm is optimized in from following aspects:  (i) adjustment of the number of local updates: Li et al. \cite{li2020federated} use a regularization term to balance the optimizing discrepancy between the global and local objectives and allow participating nodes to perform a variable number of local updates to overcome the heterogeneity of the system. When the total resource budget is fixed, \cite{wang2019adaptive} dynamically adjusts the number of local updates between two consecutive global aggregations in real-time to minimize the learning loss of the computational system. (ii) client selection for FL training:  Nishio et al. \cite{nishio2019client} propose the FedCS algorithm to select nodes according to the resource conditions of the local clients rather than randomly. \cite{nguyen2020fast} mainly adopts the gradient information of clients, and clients whose inner product of the gradient vector and global gradient vector is negative will be excluded from FL training. (iii) adaptive weighting for model updating: Chen et al. \cite{chen2019communication} assign different update weights according to the number of local communication rounds. \cite{HongdaWu2020FastConvergentFL} adjusts clients' weights based on clients' contribution measured by the angle between the local gradient vector and the global gradient vector. \cite{reddi2020adaptive} uses a pseudo-gradient difference to adaptively update the gradient.

% (i) asynchronous updating of model parameters: \cite{ma2021fedsa} proposes a semi-asynchronous FL mechanism (FedSA), where the parameter server aggregates a certain number of local models by their arrival order in each round.
% Xie et al. \cite{xie2019asynchronous} use a weighted average to asynchronously update the global model, where the mixing weight is set adaptively as a function of the staleness. 


% \begin{enumerate*}[label=(\roman*)]
% % \item asynchronous updating of model parameters: Xie et al. \cite{xie2019asynchronous} use a weighted average to asynchronously update the global model, where the mixing weight is set adaptively as a function of the staleness. \cite{ma2021fedsa} proposes a semi-asynchronous FL mechanism (FedSA), where the parameter server aggregates a certain number of local models by their arrival order in each round.
% \item adjustment of the number of local updates: Li et al. \cite{li2020federated} use a regularization term to balance the optimizing discrepancy between the global and local objectives and allow participating nodes to perform a variable number of local updates to overcome the heterogeneity of the system. When the client resource budget is fixed, \cite{wang2019adaptive} presents an analytical model that dynamically adjusts the number of local updates between two consecutive global aggregations in real-time to minimize the learning loss of the computational system.
% \item client selection for FL training:  Nishio et al. \cite{nishio2019client} propose the FedCS algorithm to select nodes according to the resource conditions of the local clients rather than randomly. \cite{nguyen2020fast} mainly adopts the gradient information of clients, and clients whose inner product of the gradient vector and global gradient vector is negative will be excluded from FL training.
% \item adaptive weighting for model updating: Chen et al. \cite{chen2019communication} assign different update weights according to the number of local communication rounds.  \cite{HongdaWu2020FastConvergentFL} adjusts clients' weights based on clients' contribution measured by the angle between the local gradient vector and the global gradient vector. \cite{reddi2020adaptive} uses a pseudo-gradient difference to adaptively update the gradient.
% \end{enumerate*}

However, there are some overlooked issues in the above FL optimization methods. Firstly, most methods (\cite{li2020federated, wang2019adaptive, nishio2019client, nguyen2020fast, chen2019communication, HongdaWu2020FastConvergentFL}) have not optimized the convergent learning rate. They tend to assign a static local learning rate on the clients. This is not optimal as the differences in clients' devices and data can lead to deviations between different local parameters and a slow convergence rate. 
Secondly, while the upper bound for the convergent learning rate of FedAdagrad, FedAdam and FedYogi are given in \cite{reddi2020adaptive}, it involves many hyper-parameters and cannot be precise for each iteration. Ma et al. \cite{ma2021fedsa} calculate the dynamic learning rate by the frequency of aggregation, but do not consider the deviations between different local parameters. In this paper, an entropy term is introduced in the local objective function of each client to measure the diversity among the local model parameters of all clients and help design an adaptive local learning rate for each client for faster convergence. To enable a decentralized learning rate design for each client, a mean-field scheme is introduced to estimate other clients' local parameters over time.

The main contributions of this paper are as follows:
\begin{itemize}
\item\emph{Novel adaptive learning strategy for federated learning:} To our best knowledge, this paper is one of the first works studying how to assign adaptive learning rates for each
client by utilizing the entropy theory to measure the deviation between the local model parameters for the Non-IID dataset. By setting the parameter diversity among clients as a penalty item of the learning rate, the adaptive learning rate for each client is proposed to adjust the client's learning rate over time and achieve fast convergence. 

\item\emph{New mean-field solution to estimate the closed-form terms related to other clients' local parameters:} 
It's difficult to design the optimal dynamic learning rate for each client as the local information of other clients is unknown, especially during the local training epochs without communications between local clients and the central server. Thus, a mean-field scheme is introduced to estimate the terms relating to other clients' local parameters over time without requiring many clients to communicate frequently. By converting the original combinatorial optimization problem using the mean-field terms, the decentralized adaptive learning rate for each client is obtained  in closed form by constructing the Hamilton equation.
% To design a decentralized learning rate for each client, a mean-field scheme is introduced to estimate the terms relating to other clients' local parameters over time without requiring many clients to communicate frequently. By converting the original combinatorial optimization problem using the mean-field terms, the decentralized adaptive learning rate for each client is obtained  in closed form by constructing the Hamilton equation.

\item\emph{Fixed point algorithm for finalizing the optimal learning rate:} We prove that there exists a fixed point solution for the mean-field estimator, and an algorithm is proposed to calculate the fixed point. Then, we successfully calculate the optimal learning rate for each client at each global training iteration. Our extensive experimental results using real datasets show that our method has a faster convergence rate and higher accuracy. Moreover, our adaptive FL algorithm can effectively eliminate the deviation between different local model parameters compared with other FL algorithms.
\end{itemize}

The rest of this paper is organized as follows. The system model and problem formulation are presented in Section \ref{sec_systemmodel}. In Section \ref{subsec_adlr}, we propose the adaptive learning rate via the entropy approach. Then experimental results are shown in Section \ref{sec_experiments}. Finally, we conclude this paper in Section \ref{sec_conclusion}.

\section{System Model and Problem Formulation}\label{sec_systemmodel}

In this section, we introduce the framework of the standard FL \cite{r1}, and then present our adaptive FL optimization problem by considering the deviation among the local model parameters at each global training iteration. 

\subsection{Federated Learning Model}\label{subsec_FL_model}

\begin{figure}[htp]
    \centering
    % \includegraphics[width=10cm]{FL_diagram}
    \includegraphics[scale=0.30]{FL_process.pdf}
    \caption{The schematic diagram of federal learning}
    \label{fig_FL_diagram}
\end{figure}

As shown in Fig. 1, FL is a distributed ML paradigm in which a large number of mobile
clients coordinate with the central server to learn an ML model without sharing their own training data \cite{r1}. During each global iteration, each client uses local data to perform batch stochastic gradient descent (SGD) to update the local model parameters, and the central server aggregates the local model parameters of all clients to generate new global model parameters for the next global iteration.

Given $N$ clients participating in training, we assume that each participating client $i \in \{1,...,N\}$ uses its local dataset $\mathcal{D}_i$ with data size $D_i$. Denote the collection of data samples in $\mathcal{D}_i$ as $\{\boldsymbol{x_i^{j}}, y_i^{j}\}_{j=1}^{D_i}$, where $\boldsymbol{x_i^{j}} \in \mathbb{R}^{d \times 1}, y_i^{j} \in \mathbb{R}$ refer to the input sample vector and the labeled output value, respectively. The loss function $f_i^{j}(\boldsymbol{w})$ is used to measure the difference between real output ${y_i^{j}}$ and predicted output ${{\hat{y}}_i^{j}}$. Then the loss function $F_{i}(\boldsymbol{w})$ of client $i$ on the dataset $\mathcal{D}_i$ is defined as:
\begin{equation}\label{client_own_loss}
F_i(\boldsymbol{w}) = \frac{1}{D_i}\sum_{j \in {\mathcal{D}}_i} f_i^{j}(\boldsymbol{w}).
\end{equation}
Without loss of generality, we denote the total training round of FL as $T$ and use a general principle of SGD optimization \cite{HongdaWu2020FastConvergentFL} to update the model. At iteration $t + 1 \in \{1, 2, ..., T\}$, each client updates the local parameters based on their own dataset and their own learning rate based on the last global parameters $\boldsymbol{w(t)}$ sent by the central server:

\begin{equation}\label{w_static_update}
\boldsymbol{w_i(t+1)} = \boldsymbol{w(t)} - \eta_i\nabla F_i(\boldsymbol{w(t)}),
\end{equation}
where $\eta_i$ is the learning rate of client $i$ and $\nabla F_i(\boldsymbol{w(t)})$ is the gradient of client $i$ at iteration $t$. The server averages the parameters sent back by $N$ training clients to generate the new global parameters:
\begin{equation}\label{w_global_static_update}
\boldsymbol{w(t+1)}= \Sigma_{i=1}^{N}\theta_{i} \boldsymbol{w_i(t+1)},
\end{equation}
where $\theta_{i} = \frac{D_i}{\sum_{j=1}^{N}D_j}$ is the weight of client $i$.
Then the central server sends the updated global parameters $\boldsymbol{w(t + 1)}$ to all clients for the next round’s training.

% In a general way, 
In general, the objective of the FL model is to find the optimal global parameters $\boldsymbol{w}$ to minimize the global loss function $F(\boldsymbol{w})$:
\begin{equation}
    \underset{\boldsymbol{w}}{min} ~ F(\boldsymbol{w}) =\Sigma_{i=1}^{N} \theta_{i} F_{i}(\boldsymbol{w}).
\end{equation}

\subsection{Problem Formulation for Our Adaptive FL Strategy}
In the traditional FL algorithms, each local client will use a static learning rate to train the model. However, there are some problems with this update method. First of all, it cannot adapt to parameters update for different clients, which will lead to the local model deviation from the optimal global  model when the data distribution and devices of the clients are heterogeneous \cite{hsu2019measuring}. Moreover, the static learning rate reduces the convergence speed of the model as compared with the dynamic learning rate \cite{agrawal2021genetic}.

To solve the above problems, the following dynamic learning rate is introduced to update the local model parameters at iteration $t + 1$:
\begin{equation}\label{dynamic_w_update}
\boldsymbol{w_i(t+1)} = \boldsymbol{w(t)}-\eta_i(t)\nabla F_i(\boldsymbol{w(t)}),
\end{equation}
where $\eta_i(t) \in \mathbb{R}^{+} $ is the learning rate of client $i$ at iteration $t$.

In addition, the smaller the difference between each client's parameters, the faster the model converges \cite{sattler2020clustered}. That is to say, the model will tend to converge when the local parameters of each client are similar. Note that the entropy function can be used to measure the diversity between variables. To spread out differences between the local parameters and achieve fast convergence, the entropy term $\Sigma_{i=1}^{N}p_{i}(t) \log p_{i}(t) = 1$ with 
\begin{equation}\label{p_init}
    p_{i}(t) = \frac{\theta_{i} \boldsymbol{w_{i}(t)}^{T}\boldsymbol{w_{i}(t)}}{\Sigma_{j=1}^{N} \theta_{j} \boldsymbol{w_{j}(t)}^{T}\boldsymbol{w_{j}(t)}} \in [0, 1]
\end{equation}
is introduced in the objective function $U_{i}(T) $ of client $ i \in \{1,...,N\}$ for adaptive learning rate design:
% have the same proportion of the global parameters. Thus, we denote the weight proportion of client $i$ in the global model parameters as:
% \begin{equation}\label{p_init}
%     p_{i}(t) = \frac{\theta_{i} \boldsymbol{w_{i}(t)}^{T}\boldsymbol{w_{i}(t)}}{\Sigma_{j=1}^{N} \theta_{j} \boldsymbol{w_{j}(t)}^{T}\boldsymbol{w_{j}(t)}} \in [0, 1].
% \end{equation}
% Then we construct the following problem form based on information entropy theory \cite{harte2014maximum}:
\begin{equation}\label{objective}
U_{i}(T) = \underset{\substack{\eta_{i}(t) \\ t \in \{0, ..., T\}}}{min}
 \Sigma_{t=0}^{T}(\beta \Sigma_{j=1}^{N}p_{j}(t) \log p_{j}(t) + (1 - \beta)\eta_{i}^{2}(t)),
\end{equation}
\rightline{s.t.\quad$\boldsymbol{w_i(t+1)} = \boldsymbol{w(t)}-\eta_i(t)\nabla F_i(\boldsymbol{w(t)})$,\quad\quad\quad (\ref{dynamic_w_update})}
%\rightline{\quad$p_{i}(t) = \frac{\theta_{i} \boldsymbol{w_{i}(t)}^{T}\boldsymbol{w_{i}(t)}}{\Sigma_{j=1}^{N} \theta_{j} \boldsymbol{w_{j}(t)}^{T}\boldsymbol{w_{j}(t)}}$,\quad\quad\quad\quad\quad\quad (\ref{p_init})}
where $\beta$ controls the degree of aggregation.

However, there are two difficulties to solve in the optimization problem with the objective function $U_{i}(T)$. Firstly, it is difficult to solve the optimal dynamic learning rate by considering the huge number of learning rate combinations over time. Moreover, the design of learning rate $\eta_i(t)$ of client $i$ is not only affected by its own local parameters $\theta_{i} \boldsymbol{w_{i}(t)}^{T}\boldsymbol{w_{i}(t)}$, but also affected by the local parameters of other clients via the term $\Sigma_{j=1}^{N} \theta_{j} \boldsymbol{w_{j}(t)}^{T}\boldsymbol{w_{j}(t)}$. 
This makes the multi-agent joint learning rate design more challenging. To solve the above problem, we first  derive the decentralized dynamic learning rate $\eta_i(t)$ for each client $i$ via a new mean-field approach, then we prove the existence of the approximate mean-field terms via fixed point theorem and propose a new algorithm to finalize the learning rate design.

\section{Analysis of Adaptive Learning Rate}\label{subsec_adlr}

In this section, we will find the optimal adaptive learning rate $\eta_{i}(t)$ for each client $i$ via a mean-field scheme. We first solve the adaptive learning rate $\eta_{i}(t)$ by constructing the mean-field terms $\boldsymbol{\phi_1(t)}$ and $\phi_2(t)$ to estimate the global parameters $\boldsymbol{w(t)}$ and  $\Sigma_{i}^{N} \theta_{i} \boldsymbol{w_{i}(t)}^{T}\boldsymbol{w_{i}(t)}$, respectively. Then we  prove the existence of the mean-field terms $\boldsymbol{\phi_1(t)}$ and $ \phi_2(t)$ based the Brouwer’s fixed point theorem. Finally, we propose an algorithm used to find the adaptive learning rate. 

\subsection{Adaptive Learning Rate for Each Client}\label{subsec_adp_lr_client}

In order to solve the adaptive learning rate for each client, we will first introduce the mean-field term that estimates the global weight $\Sigma_{j=1}^{N} \theta_{j} \boldsymbol{w_{j}(t)}^{T}\boldsymbol{w_{j}(t)}$.
Note that $\Sigma_{j=1}^{N} \theta_{j} \boldsymbol{w_{j}(t)}^{T}\boldsymbol{w_{j}(t)}$ is the integration of local updated parameters obtained by various clients after local training. The learning rate will affect the local updated parameter of the individual client, as well as the value of $\Sigma_{j=1}^{N} \theta_{j} \boldsymbol{w_{j}(t)}^{T}\boldsymbol{w_{j}(t)}$, which in turn affects the local parameter updating and adaptive learning rate design. But other clients' local information may be unknown when designing the adaptive learning rate for each client, especially for a large number of clients. Thus, we introduce the mean-field terms $\boldsymbol{\phi_1(t)}, \phi_2(t), t\in\{0, ..., T\}$ to estimate the $\sum_{i=1}^{N} \theta_i \boldsymbol{w_i(t)}$ and $\sum_{i=1}^{N} \theta_i \boldsymbol{w_i(t)}^T\boldsymbol{w_i(t)}$ respectively over time, i.e., we want to find two functions $\boldsymbol{\phi_1(t)}$ and $\phi_2(t)$ such that

\begin{equation}\label{phi_1}
    \boldsymbol{\phi_1(t)}  = \sum_{i=1}^{N} \theta_i \boldsymbol{w_i(t)},
\end{equation}
\begin{equation}\label{phi_calc}
    \phi_2(t) = \sum_{i=1}^{N} \theta_i \boldsymbol{w_i(t)}^T\boldsymbol{w_i(t)}.
\end{equation}
% From Eq (\ref{phi_1} - \ref{phi_calc}), we can see that $\boldsymbol{\phi_{1}(t)}, \phi_{2}(t),t\in\{0,...,T\}$ is a given function no matter how $\eta_i(t)$  changes. 
Then entropy term can be evaluated by:
\begin{equation}\label{p_phi}
    \bar{p_{i}}(t) = \frac{\theta_{i} \boldsymbol{w_{i}(t)}^{T}\boldsymbol{w_{i}(t)}}{\phi_{2}(t)} \in [0, 1].
\end{equation}
% Now the adaptive learning rate of each client $i$ is only affected by the mean-field term $\boldsymbol{\phi_1(t)}$ and its local information.
% In this case, 
The objective of client $ i \in \{1,...,N\}$ becomes:
\begin{equation}\label{new_objective}
J_{i}(T) = \underset{\substack{\eta_{t}(t) \\ t \in \{0, ..., T\}}}{min}
 \Sigma_{t=0}^{T} (\beta \Sigma_{j=1}^{N} \bar{p_{j}}(t) \log \bar{p_{j}}(t) + (1 - \beta)\eta^{2}_{i}(t)),
\end{equation}
\begin{equation}\label{equ_dynamicsMF} \text{s.t.}~~~ \boldsymbol{w_i(t+1)} = \boldsymbol{\phi_1(t)}-\eta_i(t)\nabla F_i(\boldsymbol{\phi_1(t)})\end{equation}
%\rightline{\quad$\bar{p_{i}}(t) = \frac{\theta_{i} \boldsymbol{w_{i}(t)}^{T}\boldsymbol{w_{i}(t)}}{\phi_{2}(t)}$. \quad\quad\quad\quad\quad\quad (\ref{p_phi})}
According to the above system, the adaptive learning rate of each client $i$ is only affected
by the mean-field terms $\boldsymbol{\phi_1(t)}, \phi_2(t)$ and its local information.
By constructing the Hamiltonian equation, we can obtain $\eta_i(t)$ as shown in the following proposition.
\begin{pro}\label{pro_eta_t_0}
Given the mean-field term $\boldsymbol{\phi_{1}(t)}$ in (\ref{phi_1}), $\phi_{2}(t)$ in (\ref{phi_calc}), $t\in\{0,1,...,T\}$, the optimal adaptive learning rate of client $i \in \{1,...,N\}$ at iteration $t \in \{0,1,...,T-1\}$ satisfies the following equation:
\begin{equation}\label{eta_solve_t_1}
\begin{split}
\eta_{i}(t) &= \Big(\frac{\theta_{i}(\boldsymbol{\phi_{1}(t)} - \eta_{i}(t)\nabla F_{i}(\boldsymbol{\phi_{1}(t)}))^{T}}{\phi_{2}(t + 1)} \times \frac{\beta \nabla F_{i}(\boldsymbol{\phi_{1}(t)})}{(1 - \beta)} \Big ) \\ & * \Bigg (1 + \log \bigg[  \theta_{i} (\boldsymbol{\phi_{1}(t)} - \eta_{i}(t)\nabla F_{i}(\boldsymbol{\phi_{1}(t)}))^{T} \\ & \times \frac{(\boldsymbol{\phi_{1}(t)} - \eta_{i}(t)\nabla F_{i}(\boldsymbol{\phi_{1}(t)}))}{\phi_{2}(t + 1)} \bigg] \Bigg),
\end{split}
\end{equation}
% \begin{equation}\label{eat_and_nabla_0}
% \left | \eta_{i}(t) \right | < \frac{ \left | \boldsymbol{\phi_{1}(t)}^{T} \nabla F_{i}(\boldsymbol{\phi_{1}(t)}) \right |}{\nabla F_{i}(\boldsymbol{\phi_{1}(t)})^{T} \nabla F_{i}(\boldsymbol{\phi_{1}(t)})},
% \end{equation}
with $\eta_i(T)=0$.
\end{pro}

% The proof of Proposition \ref{pro_eta_t_0} is given in the online technical report \cite{zheng2023adaptive} due to the page limit.

\textbf{Proof:} Based on the objective function (\ref{new_objective}) with the mean-field terms $\boldsymbol{\phi_{1}(t)}$ and $\phi_2(t)$, we can construct the following Hamilton equation:
\begin{equation}\label{Hamilton_eq}
\begin{aligned}
H(t) &= \beta \Sigma_{j=1}^{N}\bar{p_{j}}(t) \log \bar{p_{j}}(t) + (1 - \beta)\eta^{2}_{i}(t) 
\\ & + \boldsymbol{\lambda_{i}(t + 1)}(\boldsymbol {\phi_{1}(t)} - \eta_{i}(t)\nabla F_{i}(\boldsymbol{\phi_{1}(t)}) -\boldsymbol{w_{i}(t)}),
\end{aligned}
\end{equation}
where $\boldsymbol{\lambda_{i}(t + 1)} \in \mathbb{R}^{1 \times d}$ is a vector whose size is $1 \times d$. Since $\frac{\partial^2 H(t)}{\partial \eta_{i}^2(t)} =2(1 - \beta) >0$, the Hamiltonian function $H(t)$ is convex in $\eta_{i}(t)$. Therefore, in order to find the optimal dynamic learning rate that minimizes the objective function $J_{i}(T)$ in (\ref{Hamilton_eq}), it is necessary to satisfy:
% To obtain the expression of $\eta_i(t)$, we use the equation (\ref{Hamilton_eq}) to find the first derivative of the Hamilton function with respect to $\eta_i(t)$:
\begin{equation}\label{eta_first_derivative}
\frac{\partial H(t)}{\partial \eta_{i}(t)} = 0,
\end{equation}
\begin{equation}\label{H_lambda_rel}
\boldsymbol{\lambda_{i}(t + 1)} - \boldsymbol{\lambda_{i}(t)} = -\frac{\partial H(t)}{\partial \boldsymbol{w_{i}(t)}}.
\end{equation}
Based on Eq (\ref{eta_first_derivative}), we can derive:
\begin{equation}
    2(1 - \beta)\eta_{i}(t) + \boldsymbol{\lambda_{i}(t + 1)}(-\nabla F_{i}(\boldsymbol{\phi_{1}(t)})) = 0,
\end{equation}
\begin{equation}\label{eta_solve_1}
\eta_{i}(t) = \frac{\boldsymbol{\lambda_{i}(t + 1)}\nabla F_{i}(\boldsymbol{\phi_{1}(t)})}{2(1 - \beta)}. \\
\end{equation}
According to Eq (\ref{H_lambda_rel}), we can get:
\begin{equation}\label{lambda_rel}
\begin{split}
\boldsymbol{\lambda_{i}(t + 1)} - \boldsymbol{\lambda_{i}(t)} &= \boldsymbol{\lambda_{i}(t + 1)} - \bigg ( \beta\frac{2\theta_{i} \boldsymbol{w_{i}(t)}^{T}}{\phi_{2}(t)} \\ &* \Big(\log \big[\frac{\theta_{i} \boldsymbol{w_{i}(t)}^{T}\boldsymbol{w_{i}(t)}}{\phi_{2} (t)}\big] + 1  \Big) \bigg).
\end{split}
\end{equation}
% Now we can easily derive the following equation of $\boldsymbol{\lambda_{i}(t)}$:
\begin{equation}\label{lambda_solve}
\boldsymbol{\lambda_{i}(t)} = \beta\frac{2\theta_{i} \boldsymbol{w_{i}(t)}^{T}}{\phi_{2}(t)}\Big(\log \big[ \frac{\theta_{i} \boldsymbol{w_{i}(t)}^{T}\boldsymbol{w_{i}(t)}}{\phi_{2}(t)}\big] + 1 \Big).
\end{equation}
By inserting $\boldsymbol{\lambda_{i}(t)}$ in (\ref{lambda_solve}) into the expression of $\eta_{i}(t)$ in (\ref{eta_solve_1}), 
the optimal adaptive learning rate of client $i$  can be derived as Eq (\ref{eta_solve_t_1}).
\qed


\begin{algorithm}[t] 
\caption{Iterative Computation of Fixed Point} 
\begin{algorithmic}[1] 
\REQUIRE ~~\\ 
Initiate the fixed point threshold $\varepsilon_{1}=0.001$, $\varepsilon_{2}= 0.001$, global model parameter $w_i(0), i\in\{1,...N\}$, mean-field estimators $\boldsymbol{\phi_{1}^{0}(t)}$, $\phi_{2}^{0}(t)$, $t\in\{1,...,T\}$, $k=0$. 
%$\boldsymbol{\phi_{1}^{0}(1)}$,...,$\boldsymbol{\phi^0(T)}$ %with random numbers in $(0,1)$
\ENSURE ~~\\ %算法的输出：Output 
The fixed point of the mean-field item $\boldsymbol{\phi_{1}(t)}$ and $\phi_{2}(t)$, $t \in \{1, 2, ..., T\}$.

\STATE \textbf{do}

    \FOR{$t=0$ to $T-1$} 
        \FOR{$i=1$ to $N$}
            \STATE compute $\eta_i(t)$ based on $\boldsymbol{\phi_{1}^k(t)}, \phi_{2}^{k}(t)$, $t\in\{1,...,T\}$ according to Eq (\ref{eta_solve_t_1})
            \STATE compute $\boldsymbol{w_i(t+1)}$ according to Eq (\ref{equ_dynamicsMF})
        \ENDFOR
        \STATE compute $\boldsymbol{\phi_{1}^{k+1}(t+1)}$ according to Eq (\ref{phi_1})
        \STATE compute $\phi_{2}^{k+1}(t+1)$ according to Eq (\ref{phi_calc})
    \ENDFOR 
\STATE $k=k+1$
\STATE \textbf{while} $\boldsymbol{\phi_{1}^{k}(t)}$-$\boldsymbol{\phi_{1}^{k-1}(t)}$ $\geq$ $\varepsilon_{1}$ and $\phi_{2}^{k}(t) - \phi_{2}^{k-1}(t) \geq  \varepsilon_{2}$

\end{algorithmic}
\label{alg of the fixed point} 
\end{algorithm}

\subsection{Update of Mean-Field Estimator for Finalizing Learning Rate}
In this section, we determine the mean-field terms $\boldsymbol{\phi_{1}(t)}$ and $\phi_{2}(t)$ according to the given optimal adaptive learning rate $\eta_{i}(t)$ in (\ref{eta_solve_t_1}). Note that the estimator $\boldsymbol{\phi_{1}(t)}$ and $\phi_{2}(t)$ which are constructed to estimate $\boldsymbol{w(t)}$ and $\Sigma_{i=1}^{N} \theta_{i=1}\boldsymbol{w_{i}(t)}^{T}\boldsymbol{w_{i}(t)}$ are affected by the local updated parameters $\boldsymbol{w_{i}(t)}$ of all clients, which will in turn affect the local parameters. In the following proposition, we will determine the appropriate mean-field estimators $\boldsymbol{\phi_{1}(t)}$ and $\phi_{2}(t)$ via fixed point theorem.
\begin{pro}\label{pro_fix_point}
The mean-field estimators $\boldsymbol{\phi_{1}(t)}, t \in \{0, 1, ..., T - 1\}$ in 
(\ref{phi_1}) and $\phi_{2}(t), t \in \{0, 1, ..., T - 1\} $ in
(\ref{phi_calc}) exist, as returned by Algorithm \ref{alg of the fixed point}.
\end{pro}

% The proof of Proposition \ref{pro_fix_point} is given in the online technical report \cite{zheng2023adaptive} due to the page limit.

\textbf{Proof:} For any client $i \in \{1, ..., N\}$, substitute $\boldsymbol{\phi_{1}(t)} = \Sigma_{i=1}^{N} \theta_{i} \boldsymbol{w_{i}(t)}, \phi_{2}(t) = \sum_{i=1}^{N} \theta_i \boldsymbol{w_i(t)}^T\boldsymbol{w_i(t)}$ and $\eta_{i}(t)$ in (\ref{eta_solve_t_1}) into (\ref{equ_dynamicsMF}),  we can see that the local parameters $\boldsymbol{w_{i}(t)}$ of client $i$ at iteration $t$ is a function of the model parameters $\{\boldsymbol{w_{i}(t)}|t \in \{0, 1, ..., T\}, i \in \{1, ..., N\}  \}$ of all the zones over time. Define the following function as a mapping from $\{\boldsymbol{w_{i}(t)}|t \in \{0, 1, ..., T\}, i \in \{1, ..., N\} \}$ to the model parameter of client $i$ $\boldsymbol{w_{i}(t)}$ in (\ref{eta_solve_t_1}) at iteration $t$:
\begin{equation}\label{gamma_w_i_t}
    \Gamma_{i, t}(\{ \boldsymbol{w_{i}(t)}|t \in \{0, 1, ..., T\}, i \in \{1, ..., N\} \}) = \boldsymbol{w_{i}(t)}.
\end{equation}
In order to summarize any possible mapping $\Gamma_{i, t}(*)$ in (\ref{gamma_w_i_t}), we can
define the following vector function as a mapping from $\{\boldsymbol{w_{i}(t)}|t \in \{0, 1, ..., T\}, i \in \{1, ..., N\}  \}$to the set of all the clients' model parameters over time:
\begin{equation}\label{gamma_w_i_t_mapping}
\begin{split}
     & \Gamma(\{\boldsymbol{w_{i}(t)}|t \in \{0, 1, ..., T\}, i \in \{1, ..., N\} \}) \\
    =  &\Big(\Gamma_{1, 0}(\{\boldsymbol{w_{i}(t)}|t \in \{0, 1, ..., T\}, i \in \{1, ..., N\} \}), ..., \\
    & \Gamma_{1, T}(\{\boldsymbol{w_{i}(t)}|t \in \{0, 1, ..., T\}, i \in \{1, ..., N\} \}), ....,\\
    &\Gamma_{N, 0}(\{\boldsymbol{w_{i}(t)}|t \in \{0, 1, ..., T\}, i \in \{1, ..., N\} \}), ...., \\
    & \Gamma_{N, T}(\{\boldsymbol{w_{i}(t)}|t \in \{0, 1, ..., T\}, i \in \{1, ..., N\} \})
    \Big ).
\end{split}
\end{equation}
Thus, the fixed point to $\Gamma(\{\boldsymbol{w_{i}(t)}|t \in \{0, 1, ..., T\}, i \in \{1, ..., N\} \})$ in (\ref{gamma_w_i_t_mapping}) should be reached to let $\boldsymbol{\phi_{1}(t)}$ and $\phi_{2}(t)$ replicate $\sum_{i=1}^{N} \theta_i \boldsymbol{w_i(t)}^T\boldsymbol{w_i(t)}$ and $\Sigma_{i=1}^{N} \theta_{i} \boldsymbol{w_{i}(t)}$, respectively.

Firstly, $\boldsymbol{w_{i}(0)}$ as an initial model parameters value must be bounded for any client $i$. Thus, $\boldsymbol{\phi_{1}(0)} = \Sigma_{i=1}^{N} \theta_{i} \boldsymbol{w_{i}(0)}$ is bounded. According to Eq (\ref{eta_solve_t_1}), we can derive:
\begin{equation}\label{eta_and_phi}
    \eta_{i} (t) = A_{i}(\boldsymbol{\phi_{1}(t)}, \phi_2(t + 1)),
\end{equation}
where $A_{i}(*)$ is the analytic function of $\eta_{i}(t)$. Thus, we can obtain:
% \begin{equation}\label{phi_next_t_1}
%     \boldsymbol{\phi_{1}(t + 1)} = \boldsymbol{\phi_{1}(t)} - \Sigma_{i=1}^{N}\theta_{i}A_{i}(\boldsymbol{\phi_{1}(t)}, \phi_2(t + 1)) \nabla F_{i} (\boldsymbol{\phi_{1}(t)}),
% \end{equation}
\begin{equation}\label{phi_next_t_2}
\begin{split}
    \phi_{2}(t + 1) & = \Sigma_{i=1}^{N} \Bigg( \theta_{i} * \\
    & \Big(\boldsymbol{\phi_{1}(t)} - A_{i}(\boldsymbol{\phi_{1}(t)}, \phi_2(t + 1))\nabla F_{i} (\boldsymbol{\phi_{1}(t)}) \Big)^{T}   \times \\ & \Big(\boldsymbol{\phi_{1}(t)} - A_{i}(\boldsymbol{\phi_{1}(t)}, \phi_2(t + 1))\nabla F_{i} (\boldsymbol{\phi_{1}(t)}) \Big) \Bigg).
\end{split}
\end{equation}
Then based on Eq (\ref{phi_next_t_2}), we can get:
\begin{equation}\label{phi_2_and_phi_1}
    \phi_{2} (t + 1) = B(\boldsymbol{\phi_{1}(t)}),
\end{equation}
where $B(*)$ is the analytic function of $\phi_{2}(t)$. Now we can derive:
\begin{equation}\label{eta_solove_based_on_phi_1}
    \eta_{i} (t) = A_{i}(\boldsymbol{\phi_{1}(t)}, B(\boldsymbol{\phi_{1}(t)})).
\end{equation}
Based on Eq (\ref{eta_solove_based_on_phi_1}) and $A_{i}(*), B(*)$ are the analytic function, we can assume that the most at the maximum upper bound $C$ of $\eta_{i}(t)$:
\begin{equation}\label{eat_upper_bound}
    0 < \eta_{i}(t) \leq  C.
\end{equation}
Then we define the following local gradient bounded:
\begin{equation}\label{local_grad_bound}
    \Vert \nabla F_{i}(w_{i}(t)) \Vert \leq D.
\end{equation}
By inserting Eq (\ref{eat_upper_bound}), (\ref{local_grad_bound}) into (\ref{equ_dynamicsMF}), we can get:
\begin{equation}
\begin{split}
    &\boldsymbol{w_{i}(1)} = \boldsymbol{\phi_{1}(0)}  - \eta_{i}(0)\nabla F_{i}(\boldsymbol{\phi_{1}(0)}), \\
\end{split}
\end{equation}
\begin{equation}
    \boldsymbol{\phi_{1}(0)} - CD \leq  \boldsymbol{w_{i}(1)} \leq \boldsymbol{\phi_{1}(0)} + CD, \\
\end{equation}
\begin{equation}
     \boldsymbol{\phi_{1}(0)} - CD \leq  \boldsymbol{\phi_{1}(1)} \leq \boldsymbol{\phi_{1}(0)} + CD, 
\end{equation}
\begin{equation}
    \boldsymbol{\phi_{1}(0)} - tCD \leq  \boldsymbol{w_{i}(t)} \leq \boldsymbol{\phi_{1}(0)} + tCD.
\end{equation}
Define set $\Omega = [\boldsymbol{\phi_{1}(0)} - CD, \boldsymbol{\phi_{1}(0)} + CD] \times ... \times  [\boldsymbol{\phi_{1}(0)} - TCD, \boldsymbol{\phi_{1}(0)} + TCD]$. Since $\Gamma_{i, t}$ is continuous, $\Gamma$ is a continuous mapping from $\Omega$ to $\Omega$. According to Brouwer’s fixed-point theorem, $\Gamma$ has a fixed point in $\Omega$.
\qed

\begin{algorithm}[t]
\caption{Federated Learning with Adaptive Learning Rate via Entropy (Adp\_Entr)}
\begin{algorithmic}[1]
%算法的输入参数：Input
\REQUIRE ~~\\ 
    Initiate the global model parameter $\boldsymbol{w(0)}$, mean-filed terms $\phi_1(t), \phi_{2}(t), t \in \{0, 1, .., T\}$ as returned by Algorithm \ref{alg of the fixed point}, learning rate $\eta_{i}(-1)$, control parameter $\beta$, decay parameter $\gamma$ and the local training epoch of the client $E$.
\ENSURE ~~\\ %算法的输出：Output
    The optimal global model parameter $\boldsymbol{w(T)}$.
\FOR {$t=0,...,T-1$}
    \STATE  $\boldsymbol{w_{i, 0}(t)} = \boldsymbol{w(t)}$
    \FOR {each client $i \in \{1, 2, ..., N\}$ \textbf{in parallel}}
        \STATE Sample a random batch of data from $\mathcal{D}_i$ to compute the local gradient $\nabla F_{i}(w(t))$
        \STATE Solve $\eta_{i}(t)$ according to Eq (\ref{eta_solve_t_1}), (\ref{eta_deacy})
        \FOR {$k=0, ..., E - 1$}
            \STATE Compute the local gradient $\nabla F_{i}(\boldsymbol{w_{i, k}(t)})$
            \STATE  $\boldsymbol{w_{i, k + 1}(t)} = \boldsymbol{w_{i, k}(t)} - \eta_{i}(t) \nabla F_{i}(\boldsymbol{w_{i, k}(t)})$
        \ENDFOR
    \ENDFOR 
    \STATE $\boldsymbol{w(t + 1)} = \Sigma_{i=1}^{N} \theta_{i}  \boldsymbol{w_{i, E}(t + 1)}$
\ENDFOR
\end{algorithmic}
\label{alg_adlr}
\end{algorithm}

As mentioned above, we summarize the process of solving fixed points in Algorithm \ref{alg of the fixed point}.
In addition, we use the following weight decay method to avoid excessive fluctuations in the learning rate:
\begin{equation} \label{eta_deacy}
\eta_{i}(t) = \gamma * \eta_{i}(t - 1) + (1 - \gamma) * \eta_{i}(t),
\end{equation}
where $\gamma$ is the decay parameter. Refer to FedAvg \cite{r1}, our adaptive federated learning process can be summarized in Algorithm \ref{alg_adlr} by considering $E$ local epochs performed by each client in parallel in every global iteration.

\section{Experiments}\label{sec_experiments}

In this section, we conduct simulation experiments on the MNIST dataset to evaluate the performance of our proposed adaptive learning FL algorithm. We first introduce how to set up the experiments. Then we compare the performance of our adaptive learning rate method with other FL algorithms in terms of model accuracy and convergence rate. Finally, we verify the impact of the penalty weight $\beta$ on the convergence performance of the FL model.

\subsection{Experiment Setup}
The experimental setup will be briefly introduced as follows.

\textbf{Dataset:} We use the MNIST dataset that is divided into training and test datasets. And there are 60,000 images in the test dataset and 10,000 images in the validation dataset.  By default, the images in the MNIST dataset are 28x28 pixels, with a total of 10 categories.

\textbf{Model:} We use a linear model with a fully connected layer of input channel 784 and output channel 10.

\textbf{Other FL Methods:} The FL algorithms we mainly compare are FedAvg \cite{r1},  FedAdam \cite{reddi2020adaptive} and FedYogi \cite{reddi2020adaptive}.
% and Adp\_Mean \cite{tu2022adaptive}.

\textbf{Hyperparameters:} Similar to \cite{reddi2020adaptive}, we set $\beta_{1} = 0.9, \beta_{2} = 0.99, \tau=10^{-5}, \eta = 10^{-2},  \text{ and } \eta_{l} = 10^{-2} $ for FedAdam and FedYogi. By default, let $\beta=0.99$, $\gamma=0.99$ and global iteration $T=50$. During each global iteration, the local client trains $E$ epochs with a batch size is 10. We consider $N = 10$ clients and divide the Non-IID dataset similar to \cite{hsu2019measuring}.

\subsection{Comparison of the Algorithms}

\begin{table}[h]
\begin{center}
    \begin{tabular}{|l|l|l|}
    \hline
    \textbf{Methods} & \textbf{IID} & \textbf{Non-IID} \\ \hline
    FedAvg  & 0.925350010395050  &  0.868600070476532    \\ \hline
    FedAdam  &  \textbf{0.926049888134002}   &   0.875950068235397   \\ \hline
    FedYogi  & 0.926049917936325  &   0.860500067472457     \\ \hline
    % Adp\_Mean & 0.9245501458644867 &  0.8826999068260193 \\ \hline
    Adp\_Entr  &  0.924800097942352 &  \textbf{0.896000087261200}  \\ \hline
    \end{tabular}
\end{center}
\caption{The performance of different FL methods in MNIST dataset when the global iteration $T=50$ and local epoch $E=8$.}
\label{tab_fedadlrv2_mnist_8}
\end{table}

\begin{figure}[h]
\centering\includegraphics[scale=0.50]{FedAdlrv2_local_e_8_in_IID}
\caption{The performance of different FL methods on the IID data case when the global iteration $T=50$ and local epoch $E=8$.}
\label{FedAdlrv2_in_IID_8}
\end{figure}

\begin{figure}[h]
\centering\includegraphics[scale=0.5]{FedAdlrv2_local_e_8_in_Non_IID}
\caption{The performance of different FL methods on the Non-IID data case when the global iteration $T=50$ and local epoch $E=8$.}
\label{FedAdlrv2_in_Non_IID_8}
\end{figure}

\begin{figure}[h]
\centering\includegraphics[scale=0.50]{FedAdlrv2_beta_local_e_8_in_Non_IID}
\caption{The impact of control parameter $\beta$ on the Non-IID data case.}
\label{FedAdplr_beta_in_Non_IID}
\end{figure}

We present the performance of different FL methods on the MNIST dataset as in Table \ref{tab_fedadlrv2_mnist_8} when the global iteration $T =50$ and local epoch $E=8$.  For the IID dataset, there is not much difference between the several FL methods. As shown in Fig. \ref{FedAdlrv2_in_IID_8}, our method Adp\_Entr converges faster than other adaptive models such as FedAdam and FedYogi. For the Non-IID client data distribution, our adaptive method achieves 2\% accuracy improvement compared to other FL methods.  Fig. \ref{FedAdlrv2_in_Non_IID_8} shows that our adaptive method converges faster and has higher accuracy than other methods. This indicates that our proposed adaptive method can effectively spread out the difference between different local parameters and achieve a faster convergent rate. 

In addition, we analyze the influence of penalty parameter $\beta$ in Eq (\ref{objective}) on the model convergence performance. As shown in Fig. \ref{FedAdplr_beta_in_Non_IID}, with the increase of penalty weight $\beta$ on the diversity among the clients' local parameters, our adaptive algorithm will try its best to minimize the difference between the local updating parameters, which leads to a faster convergent rate.

\section{Conclusion}\label{sec_conclusion}

In this paper, we discuss the convergent rate and accuracy of the global model in FL for Non-IID clients. Firstly, to achieve fast convergence, we utilize entropy theory to measure the difference between different local model parameters. Then, we propose the adaptive learning rate for each client via a mean-field approach, which effectively estimates the terms related to other clients' model parameters over time and avoids frequent communication. Finally, the experimental results on the MNIST dataset show that the proposed adaptive learning rate algorithm has a higher accuracy and a faster convergent rate compared to other FL algorithms.

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,ref}

\end{document}
