\section{Additional Experiments}
\subsection{TransTab with shuffle augmentation}
\label{sec:additional_exp_transtab}
For a fair comparison, the test AUC performance for fine-tuning in TransTab applied shuffle augmentation during pre-training has been presented in Table~\ref{tab:transtab_shuffle}. It was observed that TransTab applied shuffle augmentation during pre-training did not result in a consistent performance improvement.

\begin{table}[t]
    \centering
    \caption{Test AUC performance. Comparison of Transtab with and without shuffle augmentation during pre-training. We set the shuffle ratio to 0.1, similar to the shuffle ratio in TabRet.}
    \label{tab:transtab_shuffle}
    \begin{tabular}{lcccc}
    % \toprule
    Method & Diabetes & HDHI & PKIHD & Stroke \\
    \midrule
    TransTab & $78.30\pm 1.18$ & $78.77\pm 1.34$ & $78.56\pm 1.58$ & $75.00\pm 4.80$  \\
    TransTab w/ shuffle aug. & $77.21\pm 1.30$ & $77.75\pm 1.71$ & $79.36\pm 1.50$ & $76.26\pm 4.82$
    \end{tabular}
\end{table}


\subsection{IID Experiment}
\label{sec:additional_experiment}
%\sonote{従来の方法と代表的なデータセットで比較した的なことを書く (IIDのこと)．}

We investigate how TabRet is competitive with the existing self-supervised tabular models in the same column setting.

\subsubsection{Datasets}

We used four popular benchmarks listed in Table~\ref{tab:ssl_data}, in addition to BRFSS.

\begin{table}[t]
    \centering
    \caption{Self-Supervised datasets.}
    \label{tab:ssl_data}
    \begin{tabular}{lrrrr}
    % \toprule
    Name & Data Points & Cat. & Num. & Positive \\
    \midrule
    BRFSS (2011--2015) & 2,038,772 & 64 & 10 & 0.127 \\
    Adult (AD) & 32,561 & 8 & 6 & 0.241 \\
    Bank Marketing (BM) & 45,211 & 10 & 6 & 0.117 \\
    HTRU2 (HR) & 17,898 & 0 & 8 & 0.092 \\
    Online Shoppers (OS) & 12,330 & 7 & 10 & 0.155 \\
    % \bottomrule
    \end{tabular}
\end{table}

 Each of the newly added datasets was split into 4 subset, each of which is for pre-training (\texttt{pre}), fine-tuning (\texttt{fine}), validation (\texttt{val}), and test (\texttt{test}). The ratio of these subsets is as follows:

\begin{enumerate}
    \item \texttt{all} $\rightarrow$ \texttt{train}$_0$ : \texttt{test} = 0.8 : 0.2
    \item \texttt{train}$_0$ $\rightarrow$ \texttt{train}$_1$ : \texttt{val} = 0.9 : 0.1
    \item \texttt{train}$_1$ $\rightarrow$ \texttt{pre} : \texttt{fine}$_0$ = 0.8 : 0.2
    \item \texttt{fine}$_0$ $\rightarrow$ \texttt{fine} : \texttt{none} = 100 : Remaining
\end{enumerate}

The splitting of BRFSS is shown in Table~\ref{tab:diabetesl}.


\subsubsection{Baseline}

We compared FTTrans, SCARF, and TransTab. Except for BRFSS, we decreased the batch size for pre-training to 512. We used 3 transformer blocks for SCARF and TabRet (see Table~\ref{tab:hypara_transformer}; the number of Post-Encoder blocks is 1) and 2 for TransTab as the default value of \citep{wang2022transtab}. Other settings were the same as described in Appendix~\ref{sec:training_tuning}.

\subsubsection{Result}

\begin{table*}[t]
 \caption{Test AUC performance in IID setting. The number of random seeds is 10. }
 \label{tab:ssl_result}
 \centering
  \begin{tabular}{lccccc}
   % \toprule
   Method & BRFSS & AD & BM & HR & OS \\
   \midrule
   FTTrans & $77.77\pm 1.18$ & $88.11\pm 0.46$ & \underline{$86.92\pm 0.70$} & $96.82\pm 0.47$ & \underline{$89.89\pm 0.68$}\\
   \midrule
   SCARF & $75.36\pm 2.27$ & $88.00\pm 0.29$ & $74.92\pm 2.38$ & $96.34\pm 0.41$ & $80.19\pm 3.75$\\
   TransTab & $77.41\pm 2.11$ & \underline{$88.32\pm 0.45$} & $85.65\pm 1.35$ & $96.74\pm 0.49$ & $89.85\pm 0.83$\\
   TabRet & $\mathbf{79.67\pm 1.19}$ & $88.08\pm 0.39$ & $76.93\pm 1.21$ & \underline{$96.90\pm 0.39$} & $84.96\pm 2.21$\\
   % \bottomrule
  \end{tabular}
\end{table*}


Table~\ref{tab:ssl_result} shows the results. TabRet outperformed the baselines on BRFSS, but the performance was not stable for other datasets. In contrast to the pre-trained models, FTTrans achieved competitive performance for all the datasets. The results suggest the size of the datasets was not large enough to surpass the supervised method. 


\begin{table}[tb]
 \caption{Dataset source.}
 \label{tab:dataset-url}
 \centering
  \begin{tabularx}{\textwidth}{lX}
   % \toprule
    Dataset Name & URL \\
   \midrule
    BRFSS & \tiny\url{https://www.kaggle.com/datasets/cdc/behavioral-risk-factor-surveillance-system} \\
    Diabetes & \tiny\url{https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset} \\
    HDHI & \tiny\url{https://www.kaggle.com/datasets/alexteboul/heart-disease-health-indicators-dataset} \\
    PKIHD & \tiny\url{https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease} \\
    Stroke & \tiny\url{https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset}\\
    Adult & \tiny\url{https://archive.ics.uci.edu/ml/machine-learning-databases/adult/}\\
    Bank Marketing & \tiny\url{https://archive.ics.uci.edu/ml/datasets/bank+marketing}\\
    HTRU2 & \tiny\url{https://archive.ics.uci.edu/ml/datasets/HTRU2}\\
    Online Shoppers & \tiny\url{https://archive.ics.uci.edu/ml/datasets/Online+Shoppers+Purchasing+Intention+Dataset}\\
   % \bottomrule
  \end{tabularx}\label{sec:dataset-source}
\end{table}