\section{Supplementary Material}

\begin{table}[h]
\caption{Overview of additional results.}
\label{tab:overview}
\begin{tabular}{p{0.2\linewidth} p{0.8\linewidth}}

\toprule
Calibration & As CWCE is a biased estimator of calibration performance, we repeated the calibration analysis with the Brier Score (BS) in Fig. \ref{fig:sup:calibration_metrics}.\\
Robustness & Our workflow depends on the estimation of deployment prevalences, which may not be known exactly. We therefore repeated the analyses shown in Fig.~\ref{fig:calibration}-\ref{fig:assessment} with variations of the proposed method in which prevalences were perturbed. The method to generate  non-exact priors is described in Sec. \ref{ss:experimental}.\\
Prevalence-independent metrics & The metrics of the main paper feature specific advantages compared to prevalence-independent metrics, such as AUROC and BA~\cite{MaierHein2022MetricsRP} but come with the disadvantage of prevalence dependency. To investigate the performance of the proposed prevalence-corrected metric EC relative to common prevalence-independent metrics, we repeated the experiments  shown in Fig.~\ref{fig:threshold} and Fig.~\ref{fig:assessment} with BA and AUROC in Fig. \ref{fig:sup:threshold} and Fig. \ref{fig:sup:assessment}.\\
\bottomrule
\end{tabular}
\end{table}


\begin{table}[h]
\caption{Model training specifications.}
\label{tab:models}
\begin{tabular}{p{2.5cm}l}

\toprule
Architecture & ImageNet pretrained ResNet34, PyTorch Lightning \cite{Deng2009ImageNetAL,Falcon_PyTorch_Lightning_2019,He2016DeepRL,Paszke_PyTorch_An_Imperative_2019,rw2019timm}\\
Optimization & balanced sampling, Adam optimizer, CE loss, early stopping \cite{Johnson2019SurveyOD,Kingma2015AdamAM}\\
Augmentation & resize (256x256), random cropping (224x224), horizontal flipping \cite{info11020125}\\
Learning rate & initial learning rate search, reduce on plateau \cite{Smith2015CyclicalLR}\\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[!h]
  \centering
  \includegraphics[width=0.95\linewidth]{assets2990/calibration_supp_bs2990.eps}
  \caption{Effect of prevalence shifts on the  Brier Score (BS) in analogy to Fig. \ref{fig:calibration}.
  Our proposed affine recalibration with prevalences of the deployment data consistently provides the lowest BS.
}
  \label{fig:sup:calibration_metrics}
\end{figure}

\begin{figure}[!h]
  \centering
  \includegraphics[width=0.95\linewidth]{assets2990/calibration_supp_cwce2990.eps}
  \caption{Effect of errors in the estimation of deployment prevalences on the performance of the proposed affine re-calibration method. In analogy to Fig. \ref{fig:calibration} the class-wise calibration error (CWCE) is plotted for n = 30 different biomedical imaging tasks for various prevalence shifts. 
}
  \label{fig:sup:calibration_perturb}
\end{figure}

\begin{figure}[!h]
  \centering
  \includegraphics[width=0.95\linewidth]{assets2990/threshold_supp2990.pdf}
  \caption{Effect of errors in the estimation of deployment prevalences on the quality of the decision rule. Analogously to Fig. \ref{fig:threshold} (top right), the difference between the actual and the optimal metric score is shown as a function of the imbalance ratio (IR) for a re-calibrated model with argmax decision rule. The boxplots show results for the 24 binary tasks at IR=10. Argmax remains close to being the optimal threshold for EC when non-exact priors are used in re-calibration. We show the same plots for the prevalence-independent Balanced Accuracy, yielding suboptimal performance under prevalence shifts when using argmax decision rule. 
}
  \label{fig:sup:threshold}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.95\linewidth]{assets2990/metrics_supp2990.pdf}
  \caption{Effect of errors in the estimation of deployment prevalences on the generalizability of validation results when using Expected Cost (EC). Even under high prevalence shifts, the results remain stable. We further complement Fig. \ref{fig:assessment} (bottom) with the common prevalence-independent metrics Balanced Accuracy and AUROC, which also yield robust results.
}
  \label{fig:sup:assessment}
\end{figure}
