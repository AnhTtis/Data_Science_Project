\begin{figure*}[!b]
	\vspace{-0.4cm}
	\minipage{0.32\textwidth}
	\includegraphics[width=\linewidth, height=6cm]{figures/rq3q90d.png}
	%\caption{A really Awesome Image}\label{fig:rq1q90}
	\endminipage\hfill
	%\vspace{-0.5cm}
	\minipage{0.32\textwidth}
	\includegraphics[width=\linewidth, height=6cm]{figures/rq3q75d.png}
	%\caption{A really Awesome Image}\label{fig:rq1q75}
	\endminipage\hfill
	%\vspace{-0.5cm}
	\minipage{0.32\textwidth}
	\includegraphics[width=\linewidth, height=6cm]{figures/rq3fulld.png}
	\endminipage
	%\captionsetup{justification=centering}
	\vspace{-0.2cm}
	\caption{Comparison of word diversity for baselines with and without label smoothing ($\epsilon$=0.10). Blue indicates baseline total number of unique words. Orange indicates total number of unique words for identical model with label smoothing. The left figure is for the Java-q90 dataset, the center figure is for the C/C++-q75 dataset, and the right figure is for the full Java dataset.}
	\label{fig:rq3rq1d}
\end{figure*}

\section{RQ3 - Vocabulary Diversity}

\subsubsection*{Methodology}

To answer RQ3, we look at the output vocabulary distribution for all the models in RQ1 and RQ2.
We find the total number of words predicted per model as well as the total number of unique words per prediction set.
This helps us identify the average word frequency in the prediction set.
We further try to identify how label smoothing affects model performance on the action word prediction problem.
We re-implement each model discussed in Section~\ref{sec:baselines} to only predict the action word.
Related work predict the top-10 or top-40 most commonly occurring action words and bucket the rest under ``other.''
We try to predict all the action words instead to see how the diversity of output vocabulary changes with label smoothing.
We train each model for the Java-q90 and C/C++-q75 dataset.
We train each baseline three times: once without label smoothing, once with $\epsilon$=0.1 and once with $\epsilon$=0.4.
We train each configuration for 10 epochs and choose the model with the highest validation accuracy score for our comparison (standard practice in related work).
We then evaluate the performance of these models using precision, recall and f1-score.
This is because action word prediction is a multi-class classification problem, while BLEU, METEOR and USE+c are more suited for full sentence prediction.

\subsubsection*{Key Findings}

Our key finding in answering RQ3 is that label smoothing decreases word diversity in output vocabulary.
As we increase $\epsilon$, the total number of words in the output prediction remains similar but the total number of unique words decreases, thus increasing the average output word frequency.
We also find that the action word prediction is unaffected by label smoothing.
Therefore, we conclude that the improvement in full model performance perceived in RQ1 must be coming from the rest of the sentence.

Figure~\ref{fig:rq3rq1d} shows how the number of unique words change with the addition of label smoothing for all the models in RQ1.
The blue bar represents models without label smoothing.
The orange bar represents the same models with label smoothing ($\epsilon$=0.1).
As the figures show, the total number of unique words decrease for all baselines, for all datasets.
%For the Java-q90 dataset (left) the number of unique words decreases substantially for each model, with the smallest decrease for attendgru (13.0\%) and the largest decrease for code2seq (46\%).
%We see a similar trend with the C/C++-q75 dataset (center) with a 4.8\% (transformer) to 25.5\% (code2seq) decrease in word diversity, and the full java dataset (right) with 7.3\% (attendgru) to 23.9\% (code2seq) decrease in word diversity.
To further study this trend, we run the same word diversity study on the models in RQ2.
Figure~\ref{fig:rq3rq2d} shows how the number of unique words change with changing values of the $\epsilon$.
A clear pattern emerges regardless of output vocabulary size (solid for 10k output vocabulary size and dashed for 44k output vocabulary size): The total number of unique words decrease steadily as we increase the value of $\epsilon$.
It is interesting to note that ast-attendgru-fc experiences highest improvement in performance AND the highest decrease in the number of unique words (29.1\% for 10k output and 39.9\% for 44k output).

Both figures suggest that label smoothing improves model performance by predicting commonly occurring words more often, thus reducing word diversity.
This explains how label smoothing achieves generalization: it avoids predicting rare words from the output distribution to reduce model loss.

\begin{figure}[!b]
	\vspace{-0.7cm}
	\includegraphics[width=\linewidth, height=8cm]{figures/rq3_rq2d.png}
	\vspace{-0.6cm}
	\caption{Comparison of word diversity for baselines with different values of $\epsilon$. The solid lines are trained with 10k output vocabulary and the dashed lines are trained with 44k output vocabulary. Note that the x-axis is logarithmic.}
	\label{fig:rq3rq2d}
	\vspace{-0.2cm}
\end{figure}

To further narrow down how label smoothing improves comment generation, we test its effect on action word prediction problem.
Haque~\emph{et al.} showed that the action word prediction is a crucial stepping stone problem in source code summarization and models that predict action words poorly also predict the rest of the comment sentence poorly.
We introduce label smoothing to the action word prediction problem to see if it improves model performance while reducing the number of unique action words predicted.

\input rqthreetable

Tables~\ref{tab:rq3q90} and~\ref{tab:rq3q75} show the effect of label smoothing on action word prediction.
We train the models under 3 conditions: $\epsilon$=0 (no label smoothing), $\epsilon$=0.1 and $\epsilon$=0.4.
We see that label smoothing has little to no effect on model performance for action word prediction.
%No model shows an improvement greater than 0.01 between $\epsilon$=0 and $\epsilon$=0.1 and greater than 0.02 between $\epsilon$=0 and $\epsilon$=0.4 for precision, recall or f1-score.
No model shows an improvement greater than 0.02 between $\epsilon$=0 and $\epsilon$=0.4 for precision, recall or f1-score.
Figure 4 shows the distribution of unique action words for each model with each label smoothing factor for the Java-q90 and C/C++-q75 dataset respectively.
We can see that there is no clear trend in the diversity of action words with changing values of $\epsilon$ for either dataset: the number of unique action words decrease in some cases and increase in others.

Two key findings can be derived from this: 1) The performance improvement we see in RQ1 and RQ2 is not due to the improved action word prediction, rather most likely coming from predicting the rest of the sentence.
2) Adding label smoothing does not affect the diversity of unique action words.
These findings further bolster the intuition that label smoothing improves model generalization by predicting more commonly occurring words in favor of rarer words.
This explains why we recommend the use of $\epsilon$=0.1 instead of 0.4 in RQ2.
While 0.4 squeezes out the best performance, most models demonstrate statistically significant improvement at 0.1 as well.
Further improvement comes at the cost of reduced word diversity.% which is often undesirable as this generates boring comments.


\begin{figure}[!t]
	\vspace{-0.5cm}
	\raggedleft
	%\left
	\minipage{0.35\textwidth}
	\caption{Action word diversity with ($\epsilon=0.1, 0.4$), without ($\epsilon=0$) label smoothing.}
	\includegraphics[width=6.5cm, height=3.5cm]{figures/rq3awq90h.png}
	\endminipage\hspace{0.2cm}%\hfill
	\captionsetup{justification=centering}
	\label{fig:rq3awq90}
	\vspace{-0.4cm}
\end{figure}

\begin{figure}[!t]
	\raggedleft
	\minipage{0.35\textwidth}
	\includegraphics[width=6.5cm, height=3.5cm]{figures/rq3awq75h.png}
	\captionsetup{justification=centering}
	\endminipage\hspace{0.2cm}%\hfill
	\label{fig:rq3awq75}
	\vspace{-0.4cm}
\end{figure}

%discuss figure 2 and 3
%Write numbers for figure 2 and 3

%discuss the findings of tables 9 and 10
