\section{Discussion \& Conclusion}
This paper contributes to source code summarization research along three major frontiers:
\begin{itemize}
	\item[1)] We contribute a study in the use of label smoothing as a regularizer in source code summarization.
	We explore a variety of source code summarization baselines and quantitatively demonstrate that label smoothing improves model performance in terms of three different metrics.
	\item[2)] We make a recommendation on what label smoothing hyperparameter ($\epsilon$) should be used for source code summarization.
	We choose four different source code summarization models and tune the value of $\epsilon$ for best performance.
	We identify that higher values of $\epsilon$ generally lead to higher model performance.
	Our recommendation is to use $\epsilon$=0.1 for all source code summarization models.
	Our justification for this recommendation is in Section~\ref{sec:rq2_method}.
	\item[3)] We contribute new insight in the understanding of how label smoothing generalizes NLG models.
	We explore the word diversity of output vocabulary for all models trained with and without label smoothing in RQ1 and RQ2.
	We find that label smoothing reduces the number of unique words predicted in all cases.
	We further identify that label smoothing does not affect action word prediction.
%	We further add label smoothing to the action word prediction problem, and identify that label smoothing improves the prediction of the rest of the sentence, not action word.
	Thus, we posit that for subsequent word prediction in the output sentence, label smoothing improves model performance by predicting commonly occurring words more often and avoiding rare/unique words to reduce model loss.
\end{itemize}
%Prevailing evidence in other NLG work along with evidence from this paper shows that label smoothing improves model performance.
%Yet, there is still a lack of understanding as to why or how label smoothing works.
%The general intuition is that label smoothing acts as a regulizer to prevent over-fitting and make models less confident.
%However, there are opposing schools of thought as to how the internal mechanism of label smoothing helps models generalize predictions~\cite{lukasik2020does}.
%One intuition is that label smoothing makes models less certain by introducing some noise.
%The smoothed probability across the one-hot vector encourages models to predict more rare words. 
%While this exacerbates the problem of label noise, it prevents models from being over confident, thus having an overall generalization effect.
%A competing intuition is that label smoothing improves model calibration by reducing over-fitting.
%This implies that the model does not interpret noise as pattern and hence produces more generalized predictions.
%Our findings reinforce the findings by Lukasik~\emph{et al.}~\cite{lukasik2020does} who demonstrate that label smoothing reduces label noise.

%To encourage reproducibility and aid other research groups, we have released all data, source code, scripts, and tutorial information in an online appendix:

%We provide the following online appendix for reproducibility

%\section{Reproducibility}
%To encourage reproducibility and aid other research groups, we release all data and source code in the following online appendix:
Appendix:
\texttt{https://github.com/ls-scs/ls\_scs}