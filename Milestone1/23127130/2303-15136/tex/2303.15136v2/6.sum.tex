\section{Summary, Limitations, and Outlook}\label{sec:sum}

\emph{\textbf{Summary}} --- 
The wave of \textit{AI for science} has witnessed a marked surge in popularity and adoption across the broader scientific spectrum~\cite{osti_1604756}. Particularly, paradigms with modern machine- and deep-learning techniques are transforming across various scientific domains -- primarily those overwhelmed by large-scale intensive computations and/or large amounts of high-dimensional data, including high-energy nuclear physics (HENP)~\cite{Boehnlein:2021eym, He:2023zin, Calafiura:2022ges}. The integration of machine learning techniques has led to remarkable advances and a host of results in the field, opening a new horizon for exploration and discovery. These ML-based methods have revolutionized the way of analyzing data, improved the ability to discover new phenomena, and fostered the development of more efficient simulations. HENP is an extremely fruitful area in this sense, and many advances have been made in the past decade~\cite{Bzdak:2019pkr, Fukushima:2020yzx, Bogdanov:2022faf}. We are in the right and exciting era to work in this direction and to amplify our understanding of QCD matter in extreme conditions. 

This review aims to provide an overview of the current applications of ML in HENP theoretical studies, while spotlighting some of the recent developments in this rapidly evolving crossing field. Several aspects are reviewed, revolving around ML for the theoretical study of extreme QCD matter exploration, ranging from data analysis in high energy heavy-ion collisions(HICs) sector, advancing lattice QCD/QFT simulations, to the inference of Neutron Star(NS) interior matter properties, thereby encapsulating the ongoing endeavors in the study of strongly interacting nuclear matter. Subsequently, a refined advanced development summary and discussion are presented in the last chapter, trying to form a common ground from a methodology perspective in inspiring further exploration.

In terms of big \textbf{data analysis}, HENP unequivocally presents a golden playground to us. Copious amounts of multifarious data can be gleaned from a variety of sources including HIC experiment detectors, astrophysical observatories, and lattice QCD simulations. Many of the well-established physics models and software/packages further facilitate the generation of large-scale simulation data, to which the disentangled physics understanding and correlation analysis are yet daunting with conventional methods. Thus, as a modern numerical method to process complex data for hidden pattern decoding, ML and DL techniques have provided a powerful tool for exploring physics across different disciplines. 

Beyond being data-rich, numerous areas in HENP are notably \textbf{computation-intensive}, with many of the accessible measurements such as billions of collision events from the detectors requiring comprehension derived from theory simulations, yet remain not fully calculable in a first principle manner. For the purpose of either evolving or confirming our theory understandings, or exploring new physics for discoveries, the ability to perform efficient and prompt simulations is critical across many facets of HENP. ML and DL have also charted significant advancements in HENP computations, e.g., various algorithms have been developed to enhance the simulation speed and accuracy~\cite{Shanahan:2022ifi}. Advanced calculations with faster and optimized models in synergy with ML methodologies pave the way for better prediction and comprehension in confronting data.

\emph{\textbf{Limitations}} --- 
In addition to those head-on applications of ML/DL in HENP, there are still many challenges and questions that need to be further addressed. Probably the first-line concern from physicists is the \textbf{interpretability} of the ML approaches utilized in HENP research~\cite{Neubauer:2022zpn}. Detailed understandings of why and under what conditions the used methods work are desired in physics. More efforts need to be devoted to uncovering the inner workings of ML algorithms to rectify their “Black Box” characteristics, especially those with huge amounts of parameters. Techniques to reveal the patterns and validate the computations with ML are called for as well. Then per the purpose of physics exploration, those practical computational results from the ML methods need to be transferred or related to physics knowledge or inspirations, which better conform to the well-established language of physics in a controlled way, such as with uncertainties properly given. The incorporation of physics priors into those ML paradigms to specific physics studies deserves further development in addressing this concern~\cite{2021NatRP...3..422K}.

Another challenge is how to reliably \textbf{connect experimental measurements and physical theory} using ML/DL techniques, with the associated \textbf{uncertainties} also properly evaluated. As emphasized, in HENP, to understand the nature of strongly interacting matter, experiments, and observations from big scientific infrastructures play a crucial role, which needs to be transformed into physics knowledge per their mission. This however is with unprecedented scales and complexities, due to the high dimensionality and greatly correlated data stream from measurement, the multiscale and intricate physics simulations for the dynamical process involved in the measurement. Statistical learning methods such as Bayesian inference~\cite{Cranmer:2019eaq} and alternative ML/DL approaches provide a number of great demonstrations to analyze data for inferring physics knowledge. Principled uncertainty estimation for results inferred from naive ML/DL applications is not yet fully developed. These methods still have great potential to be unleashed in the exploration of QCD matter.

Moreover, the size of the training dataset imposes additional constraints. On one hand, high-energy nuclear collision experiments usually generate billions($\sim 10^9$) of events. Processing such a massive dataset necessitates a strong demand for high computational efficiency to avert excessive training time. On the other hand, typical training requires an adequate amount of well-labeled training data. The nature of the optimization procedure makes it challenging to apply it to rare physical processes with a limited number of events or phenomena that cannot be labeled.

Finally, as discussed in various examples throughout this review, the specific physics problem can impose further limitations in terms of machine learning techniques. Here are a few examples: one cannot address an ill-defined problem without introducing prior knowledge, whether using conventional or ML methods; the properties learned by the network are often tailored to the training dataset, rendering it unreliable to generalize to datasets governed by other different physics models; how ML methods can help when the physical model used\footnote{used e.g., in generating the training dataset, or used directly inside the ML methodology.} is missing some unknown but essential physics component in confronting particular phenomenon?

\emph{\textbf{Outlooks}} ---
As future prospects, with ML/DL assisted, important physics properties and hopefully new physics phenomena are expected to be explored from the growing measurements accumulation in heavy ion collision experiments or astrophysics observations, to inform also physics discovery. Specifically, ever \textbf{faster and more efficient analysis} to large amounts of data could be anticipated to better bridge experiment to physics theory; \textbf{smart, controllable and rapid simulation} with ML methods such as generative modeling may largely reduce the demand in computational resource for the field, and also mitigate the enormous complexities in disentangling different physics involved in the simulation; in the course of neutron star, it'd be intriguing to explore the possible potential of ML methods in identifying e.g., presence of exotic phases in NS interiors and phase transitions for dense QCD matter from observations, and also develop more reliable ways in \textbf{combining evidence from multi-source data} such as those from HICs together with those from multi-messenger astrophysics. Furthermore, in the lattice QCD sector, while efforts to \textbf{improve the efficiency and accuracy of lattice sampling and simulations} will continue, it may also be possible to enhance our understanding of QCD in terms of effective theory construction from an ML algorithmic perspective. The dynamic interplay between HENP and ML is rapidly advancing, and with the continued progress and enthusiasm in ML, we can expect even more exciting developments and remarkable achievements in the near future.

As introduced in this review, there has been a growing intersection between generative models and nuclear physics. This convergence is anticipated to catalyze further explorations employing advanced deep learning tools, such as Large Language Models(LLMs), in nuclear physics research. A prime representative example would be the Generative Pre-trained Transformer (GPT) models~\cite{openai2023gpt4}.

GPT Models have demonstrated immense promise across various domains due to their ability to generate coherent and contextually pertinent responses to queries. However, their potential extends beyond mere question answering. As the integration of generative models within nuclear physics intensifies, they are poised to assume pivotal roles in a multitude of facets.
\begin{itemize}
    \item Integration of GPT into traditional workflows:
    
    \begin{itemize}
    \item Aiding Experimental Design and Simulations: GPT models can be used to refine experimental designs and simulations by leveraging existing domain knowledge.
    \item Enhancing Existing Software Packages: GPT models can be integrated into existing software packages to enhance their performance. For instance, they can be used to identify and rectify inefficiencies or errors in current codes, leading to more accurate and efficient software solutions.
    \item Data Analysis. GPT models can propose different methods to analyze large datasets, extracting meaningful insights and patterns that might be missed by traditional analysis methods.
    \item Easing Framework Transition Between Different Programming Languages. GPT models can assist in translating code from one programming language to another, facilitating the transition between different frameworks.
    \end{itemize}
    
    \item Symbolic computation. Language models are well-suited for symbolic computations, as mathematical logic embodies a learnable, language-like set of rules. Besides direct application in formula derivations, GPT models can be used to compute specific physics processes following Feynman rules~\cite{Alnuqaydan_2023}. Recent developments highlight the potential of GPT models in proving mathematical theorems~\cite{yang2023leandojo}. Consequently, they may play a crucial role in advancing our understanding of fundamental physical laws.

    \item Education. After fine-tuning GPT models based on the nuclear physics domain knowledge, GPT models can serve as educational tools, providing hands-on instructions for applying machine learning in the exploration of QCD matter.
\end{itemize}

	