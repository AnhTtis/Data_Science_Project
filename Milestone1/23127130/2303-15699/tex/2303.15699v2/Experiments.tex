\subsection{Dataset}
We compiled an in-house mammography dataset comprising 16,113 exams (64,452 images) from 9,113 patients across institutions from the United States, gathered between 2010 and 2021. Each mammogram includes at least one prior mammogram. The dataset has 3,625 biopsy-proven cancer exams, 5,394 biopsy-proven benign exams, and 7,094 normal exams. Mammograms were captured using Hologic (72.3\%) and Siemens (27.7\%) devices. We partitioned the dataset by patient to create training, validation, and test sets. The validation set contains 800 exams (198 cancer, 210 benign, 392 normal) from 400 patients, and the test set contains 1,200 exams (302 cancer, 290 benign, 608 normal) from 600 patients.
All data was de-identified according to the the U.S HHS Safe Harbor Method. Therefore, the data has no  PHI (Protected Health Information) and IRB (Institutional Review Board) approval is not required.
% We compiled an in-house mammography dataset comprising 38,106 four-view full-field digital mammograms from 21,993 patients across 11 US institutions, collected between 2010 and 2021. The dataset includes 2,999 biopsy-confirmed cancer-positive cases, 5,000 benign cases confirmed by biopsy, and 13,994 (7,000 follow-up benign and 6,994 normal) cases with at least one year of follow-up. The mammograms were acquired using devices from two manufacturers, Hologic (73.8\%) and Siemens (26.2\%). For model evaluation, we sampled a validation set of 1,000 patients (250 cancer, 250 benign, and 500 normal) with three exams spaced approximately 2 years apart per patient.

\subsection{Evaluation}

We make use of Uno's C-index~\cite{uno2011c} and the time-dependent AUC~\cite{kamarudin2017time}. The C-index measures the performance of a model by evaluating how well it correctly predicts the relative order of survival times for pairs of individuals in the dataset. The C-index ranges from 0 to 1, with a value of 0.5 indicating random predictions and a value of 1 indicating that the model is perfect. Time-dependent ROC analysis generates an ROC curve and the area under the curve (AUC) for each specific time point in the follow-up period, enabling evaluation of the model's performance over time.
To compare the C-index of two models, we employ the compareC~\cite{kang2015comparing} test, and make use of the DeLong test \cite{delong1988comparing} to compare the time-dependent AUC values. Confidence bounds are generated using bootstrapping with 1,000 bootstraps. 

We evaluate the effectiveness of \ours  by comparing it with two other models: (1) baseline based on MIRAI, a state-of-the art risk prediction method from~\cite{yala2021toward}, and (2) \prior, a model that uses prior images by simply summing $x_{curr}$ and $x_{prior}$ without the use of the transformer decoder. 

\subsection{Implementation Details}

Our model is implemented in Pytorch and trained on four V100 GPUs. We trained the model using stochastic gradient descent (SGD) for 20K iterations with a learning rate of 0.005, weight decay of 0.0001, and momentum of 0.9. We use a cosine annealing learning rate scheduling strategy~\cite{loshchilov2016sgdr}.

We resize the images to 960 $\times$ 640 pixels and use a batch size of 96. To augment the training data, we apply geometric transformations such as vertical flipping, rotation and photometric transformations such as brightness/contrast adjustment, Gaussian noise, sharpen, CLAHE, and solarize. Empirically, we find that strong photometric augmentations improved the risk prediction model's performance, while strong geometric transformations had a negative impact. This is consistent with prior work \cite{liu2020decoupling} showing that risk prediction models focus on overall parenchymal pattern.

\subsection{Results}

\textbf{Ablation Study.}
\input{tables/ablation}
To better understand the merit of the transformer decoder, we first performed an ablation study on the architecture. Our findings, summarized in Table~\ref{table:ablation}, include two sets of results: one for all exams in the test set and the other by excluding cancer exams within 180 days of cancer diagnosis which are likely to have visible symptoms of cancer, by following a previous study~\cite{yala2021toward}. This latter set of results is particularly relevant as risk prediction aims to predict unseen risks beyond visible cancer patterns. We also compare our method to two other models, the state-of-the-art baseline and \prior models.

As shown in top rows in Table~\ref{table:ablation}, the baseline obtained a C-index of 0.68 (0.65 to 0.71). By using the transformer decoder to jointly model prior images, we observed improved C-index from 0.70 (0.67 to 0.73) to 0.73 (0.70 to 0.76).
%When adding the prior image, the C-index increased to 0.70 (0.67 to 0.73) when adding the prior image and to 0.73 (0.70 to 0.76) using the transformed decoder. 
The C-index as well as all AUC differences between the baseline and the \ours are all statistically significant (p < 0.05) except the 4-year AUC where we had limited number of test cases.
%except the 4-year AUC between the baseline and \ours are all statistically significant (p < 0.05). 
%The 1, 2, and 3-year AUC were found to be significantly higher than the baseline (p < 0.05) and marginally significant for the 4-year AUC, where we had limited number of test cases.

We observe similar performance improvements when evaluating using cases with at least 180 days to cancer diagnosis.
%The results of the model on the dataset that excluded 180 days of cancer diagnosis are shown in the bottom rows of Table~\ref{table:ablation}.
%Both \prior and \ours had significantly higher C-index than the baseline, with \prior's C-index at 0.68 (0.63 to 0.73) and \ours's C-index at 0.70 (0.66 to 0.74), all with a p-value < 0.05.
%and the baseline's C-index at 0.63 (0.59 to 0.67), all with a p-value < 0.05.
%The 2-year and 3-year AUC of \ours were significantly higher (p < 0.05), and the 4-year AUC was marginally higher (p = 0.08) than that of the baseline. 
%Similarly, for \prior, the 3-year AUC was significantly higher (p < 0.05), and the 2-year and 4-year AUC were marginally higher than that of the baseline (p = 0.16 and 0.05, respectively).
Interestingly, the C-index as well as time-dependent AUCs of all three methods decreased compared to when evaluating using all cases. 
The intuition behind this result is that mammograms taken near the cancer diagnosis ( < 180 days) likely contain visible signs of cancer and thus the task of risk prediction is easier.
The model must learn patterns of risk, not visible signs of cancer, in order to perform well under this evaluation setting. Our results support this intuition as the performance improvements over the baseline are much more pronounced for longer term risk (3, 4-year AUC) than short term risk (1 year). 
%This suggests that cancer cases diagnosed in early stage are relatively easier to predict.
%The difference in performance between the baseline method and the others became more pronounced compared to the results of all cases, except for the 1-year AUC.
The \prior and \ours models, which incorporate prior mammograms, show high performance for long-term risk prediction (3, 4-year AUC), indicating that considering changes in breast over time contain useful information for breast cancer risk prediction.

% However, the \prior model exhibited lower performance than the baseline for short-term risk prediction (1, 2-year AUC), as detailed blobs are more critical in short-term risk prediction. This finding is consistent with previous work~\cite{liu2020decoupling}. It suggests that modeling without considering regional differences between prior and current mammograms leads to poorer performance.

Lastly, we empirically confirm that a transformer decoder effectively models spatial relations between prior and current mammograms by demonstrating consistent performance improvements of \ours across both short-term and long-term risk prediction settings.
%In contrast, \ours leverages a transformer decoder to consider the spatial relations between prior and current mammograms, resulting in high performance for both short-term and long-term risk prediction. 
Our results suggest that incorporating changes in patients using prior mammograms and a transformer decoder improves the performance of breast cancer risk prediction models.

\input{tables/density_change}
\textbf{Analysis based on density.}
To better understand why adding prior images improves performance, we divided our test set into subgroups to examine the performance of the baseline model and the \ours model on each of these groups.
Mammographic breast density is one of the most important risk factor to predict breast cancer~\cite{veronesi2005goldhirsch,lee2017risk}.
Women with dense breasts have a four-to six-fold higher risk of breast cancer~\cite{boyd2013mammographic}.
The addition of mammographic breast density has improved the performance traditional breast cancer risk models~\cite{brentnall2015mammographic} and can therefore help us understand why the addition of prior images works. 

Mammographic breast density was determined using the Breast Imaging Reporting and Data System (BI-RADS) composition classification. BI-RADS category A,B are defined as fatty breasts and BI-RADS category C, D are classified as dense breasts.
To determine the density category, we employed an internally developed density prediction model, as most exams lack BI-RADS ground truth. This model achieved an accuracy of 0.81 on the internal density validation set.

% Our hypothesis is that incorporating prior density information would improve the cancer risk prediction.
We categorized the exams into two groups based on changes in density: "change" and "no change".
Density change was defined according to whether the BI-RADS category is changed in the current image as compared to the prior image.
As shown in Table~\ref{table:density_change}, the baseline model performs poorly for "change", with a C-index of 0.63 (0.49 to 0.77), especially for long-term risk prediction, with 3-year AUC of 0.56 (0.40 to 0.72). This suggests that the baseline model have limitations in accurately predict long-term risk when there is a density change from the prior exam.
However, \ours is able to predict long-term risk accurately even when a density change has occurred (3-year AUC = 0.74 (0.60 to 0.88)), by learning to refer previous exams properly. This demonstrates the potential usefulness of incorporating past mammogram information into breast cancer risk prediction models.
Thus, we believe that incorporating prior exams is important to identify changes in texture which are important for long term risk prediction.

% our proposed model shows a larger improvement in C-index for both "Increase" (0.09) and "Decrease" (0.15) categories compared to the "No change" category (0.04). These results suggest that incorporating density change information into our model improves its performance for breast cancer risk prediction.


\input{tables/density}
Lastly, we divided the exams based on the level of breast density, with a fatty group consisting of density A and B, and a dense group consisting of density C and D. Both the baseline and \ours performs better in fatty group than dense group. We suspect this is because deep neural networks generally work better on low density images given that visual cues of cancer in images with lower breast density are more clearly visible.