% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
\usepackage[]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}
\input{math_commands.tex}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\graphicspath{{figs/}}
\usepackage{tikz}
\usepackage{subfigure} 
\usepackage{wrapfig}
\usepackage{algorithm}
\usepackage{listings}
\usepackage{pgfplots}
\usetikzlibrary{spy}
\usepackage{color}
\usepackage{xcolor}
\usepackage{comment}
\pgfplotsset{compat=1.17}
\usepackage{multirow}
%\usepgfplotslibrary{external}
%\tikzexternalize[prefix=pdf/]

\definecolor{pink1}{HTML}{F0988C}
\definecolor{pink2}{HTML}{F6CAE5}
\definecolor{red1}{HTML}{f47721}
\definecolor{yellow1}{HTML}{FBCE02}
\definecolor{green1}{HTML}{83D350}
\definecolor{color1}{HTML}{d20962}
\definecolor{color2}{HTML}{f47721}
\definecolor{color3}{HTML}{efdf00}
\definecolor{color4}{HTML}{00a78e}
\definecolor{color5}{HTML}{7ac143}
\definecolor{color6}{HTML}{00bce4}
\definecolor{green2}{HTML}{A9D18E}
\definecolor{blue1}{HTML}{9DC3E6}
\definecolor{green3}{HTML}{00A472}
\definecolor{poscolor1}{HTML}{009ca6}
\definecolor{poscolor2}{HTML}{0689d8}
\definecolor{poscolor3}{HTML}{1428a0}

% If the title and author information does not fit in the area allocated, uncomment the following
%
\setlength\titlebox{164pt}
%
% and set <dim> to something 5cm or larger.

\title{Adapting Offline Speech Translation Models for Streaming\\with Future-Aware Distillation and Inference}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{Biao Fu$^{1,3}$\thanks{\,\, Equal contribution. Work was done during Biao Fuâ€™s research internship at DAMO Academy, Alibaba Group.} , 
Minpeng Liao$^{2}$\footnotemark[1] , 
Kai Fan$^{2}$\footnotemark[1]~~\thanks{\,\, Corresponding author.} ,  
Zhongqiang Huang$^{2}$, \\ 
\textbf{Boxing Chen}$^{2}$, 
\textbf{Yidong Chen}$^{1,3}$~\footnotemark[2] ,
\textbf{Xiaodong Shi}$^{1,3}$ \\
$^{1}$School of Informatics, Xiamen University\\
$^{2}$Alibaba DAMO Academy \\
$^{3}$Key Laboratory of Digital Protection and Intelligent Processing of Intangible Cultural \\ Heritage of Fujian and Taiwan (Xiamen University), Ministry of Culture and Tourism \\
\texttt{biaofu@stu.xmu.edu.cn,\{ydchen,mandel\}@xmu.edu.cn} \\ 
\texttt{\{minpeng.lmp,k.fan,z.huang,boxing.cbx\}@alibaba-inc.com}
}

\begin{document}
\maketitle
\begin{abstract}
A popular approach to streaming speech translation is to employ a single offline model with a \textit{wait-$k$} policy to support different latency requirements, which is simpler than training multiple online models with different latency constraints. However, there is a mismatch problem in using a model trained with complete utterances for streaming inference with partial input. We demonstrate that speech representations extracted at the end of a streaming input are significantly different from those extracted from a complete utterance. To address this issue, we propose a new approach called Future-Aware Streaming Translation (FAST) that adapts an offline ST model for streaming input. FAST includes a Future-Aware Inference (FAI) strategy that incorporates future context through a trainable masked embedding, and a Future-Aware Distillation (FAD) framework that transfers future context from an approximation of full speech to streaming input.
Our experiments on the MuST-C EnDe, EnEs, and EnFr benchmarks show that FAST achieves better trade-offs between translation quality and latency than strong baselines. Extensive analyses suggest that our methods effectively alleviate the aforementioned mismatch problem between offline training and online inference.\footnote{The code is available at \url{https://github.com/biaofuxmu/FAST}}
\end{abstract}
\input{sec1_intro}

\input{sec2_background}

\input{sec3_preliminary}

\input{sec4_method}

\input{sec5_experiments}

\input{sec6_conclusion}

\section{Limitations}

Our proposed method is built upon the Wav2Vec2.0 base model, whose superior representation power has been shown to enhance the performance of offline ST models. 
Nevertheless, it should be noted that its parameters are considerably large, approximately 95M. 
This may lead to increased computational costs during training and inference. 
If we want to extend the model to the long context audio (similar to the document level machine translation \cite{zhang2020long}), we have to explore the future work in our conclusion.

The CIF module for detecting the acoustic boundary is optimized from the weakly supervised signal -- total length of text tokens. 
In streaming inference, the boundary detector is not guaranteed to predict accurate boundaries. 
In other words, it is not guaranteed to align each text token with detected boundaries during online inference. 
However, due to the good performance of overall translation quality, we hypothesize that these boundaries may represent some meaningful acoustic (or phrase-like) units. 
The underlying meaning should be another future work to explore.


\section*{Ethics Statement}
After careful review, to the best of our knowledge, we have not violated the \href{https://www.aclweb.org/portal/content/acl-code-ethics}{ACL Ethics Policy}.
Our experiments are based on the open-sourced dataset that is widely used in academia, and there is no violation for this dataset.
Our writing is completely based on the authors without plagiarism.

\section*{Acknowledgements}
We would like to thank all the anonymous reviewers for the insightful and helpful comments.
This work was supported by University-Industry Cooperation Programs of Fujian Province of China (No. 2023H6001), Major Scientific Research Project of the State Language Commission in the 13th Five-Year Plan (Grant no. WT135-38), National Natural Science Foundation of China (No. 62076211), and Alibaba Group through Alibaba Research Intern Program.

% Entries for the entire Anthology, followed by custom entries
\bibliography{anthology,custom}

\input{sec7_appendix.tex}

\end{document}
