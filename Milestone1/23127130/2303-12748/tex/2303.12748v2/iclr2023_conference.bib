@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{guo2017calibration,
  title={On calibration of modern neural networks},
  author={Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q},
  booktitle={International conference on machine learning},
  pages={1321--1330},
  year={2017},
  organization={PMLR}
}

@techreport{degroot1983comparing,
  title={Comparing probability forecasters: Basic binary concepts and multivariate extensions},
  author={DeGroot, Morris H and Fienberg, Stephen E},
  year={1983},
  institution={CARNEGIE-MELLON UNIV PITTSBURGH PA DEPT OF STATISTICS}
}

@inproceedings{niculescu2005predicting,
  title={Predicting good probabilities with supervised learning},
  author={Niculescu-Mizil, Alexandru and Caruana, Rich},
  booktitle={Proceedings of the 22nd international conference on Machine learning},
  pages={625--632},
  year={2005}
}

@inproceedings{10.5555/2888116.2888120, author = {Naeini, Mahdi Pakdaman and Cooper, Gregory F. and Hauskrecht, Milos}, title = {Obtaining Well Calibrated Probabilities Using Bayesian Binning}, year = {2015}, isbn = {0262511290}, publisher = {AAAI Press}, abstract = {Learning probabilistic predictive models that are well calibrated is critical for many prediction and decision-making tasks in artificial intelligence. In this paper we present a new non-parametric calibration method called Bayesian Binning into Quantiles (BBQ) which addresses key limitations of existing calibration methods. The method post processes the output of a binary classification algorithm; thus, it can be readily combined with many existing classification algorithms. The method is computationally tractable, and empirically accurate, as evidenced by the set of experiments reported here on both real and simulated datasets.}, booktitle = {Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence}, pages = {2901–2907}, numpages = {7}, location = {Austin, Texas}, series = {AAAI'15} }

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{schuhmann2021laion,
  title={Laion-400m: Open dataset of clip-filtered 400 million image-text pairs},
  author={Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
  journal={arXiv preprint arXiv:2111.02114},
  year={2021}
}

@TECHREPORT{Krizhevsky09learningmultiple,
    author = {Alex Krizhevsky},
    title = {Learning multiple layers of features from tiny images},
    institution = {},
    year = {2009}
}

@inproceedings{10.1145/775047.775151, author = {Zadrozny, Bianca and Elkan, Charles}, title = {Transforming Classifier Scores into Accurate Multiclass Probability Estimates}, year = {2002}, isbn = {158113567X}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/775047.775151}, doi = {10.1145/775047.775151}, abstract = {Class membership probability estimates are important for many applications of data mining in which classification outputs are combined with other sources of information for decision-making, such as example-dependent misclassification costs, the outputs of other classifiers, or domain knowledge. Previous calibration methods apply only to two-class problems. Here, we show how to obtain accurate probability estimates for multiclass problems by combining calibrated binary probability estimates. We also propose a new method for obtaining calibrated two-class probability estimates that can be applied to any classifier that produces a ranking of examples. Using naive Bayes and support vector machine classifiers, we give experimental results from a variety of two-class and multiclass domains, including direct marketing, text categorization and digit recognition.}, booktitle = {Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining}, pages = {694–699}, numpages = {6}, location = {Edmonton, Alberta, Canada}, series = {KDD '02} }

@inproceedings{10.5555/645530.655658, author = {Zadrozny, Bianca and Elkan, Charles}, title = {Obtaining Calibrated Probability Estimates from Decision Trees and Naive Bayesian Classifiers}, year = {2001}, isbn = {1558607781}, publisher = {Morgan Kaufmann Publishers Inc.}, address = {San Francisco, CA, USA}, booktitle = {Proceedings of the Eighteenth International Conference on Machine Learning}, pages = {609–616}, numpages = {8}, series = {ICML '01} }

@article{article,
author = {Platt, John},
year = {2000},
month = {06},
pages = {},
title = {Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods},
volume = {10},
journal = {Adv. Large Margin Classif.}
}

@article{kull2019beyond,
  title={Beyond temperature scaling: Obtaining well-calibrated multi-class probabilities with dirichlet calibration},
  author={Kull, Meelis and Perello Nieto, Miquel and K{\"a}ngsepp, Markus and Silva Filho, Telmo and Song, Hao and Flach, Peter},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{rajendran2019accurate,
  title={Accurate layerwise interpretable competence estimation},
  author={Rajendran, Vickram and LeVine, William},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{mozafari2019unsupervised,
  title={Unsupervised Temperature Scaling: An Unsupervised Post-Processing Calibration Method of Deep Networks},
  author={Mozafari, Azadeh Sadat and Gomes, Hugo Siqueira and Le{\~a}o, Wilson and Gagn{\'e}, Christian},
  journal={arXiv preprint arXiv:1905.00174},
  year={2019}
}

@article{sohn2020fixmatch,
  title={Fixmatch: Simplifying semi-supervised learning with consistency and confidence},
  author={Sohn, Kihyuk and Berthelot, David and Carlini, Nicholas and Zhang, Zizhao and Zhang, Han and Raffel, Colin A and Cubuk, Ekin Dogus and Kurakin, Alexey and Li, Chun-Liang},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={596--608},
  year={2020}
}

@article{berthelot2019mixmatch,
  title={Mixmatch: A holistic approach to semi-supervised learning},
  author={Berthelot, David and Carlini, Nicholas and Goodfellow, Ian and Papernot, Nicolas and Oliver, Avital and Raffel, Colin A},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{berthelot2019remixmatch,
  title={Remixmatch: Semi-supervised learning with distribution alignment and augmentation anchoring},
  author={Berthelot, David and Carlini, Nicholas and Cubuk, Ekin D and Kurakin, Alex and Sohn, Kihyuk and Zhang, Han and Raffel, Colin},
  journal={arXiv preprint arXiv:1911.09785},
  year={2019}
}

@article{minderer2021revisiting,
  title={Revisiting the calibration of modern neural networks},
  author={Minderer, Matthias and Djolonga, Josip and Romijnders, Rob and Hubis, Frances and Zhai, Xiaohua and Houlsby, Neil and Tran, Dustin and Lucic, Mario},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={15682--15694},
  year={2021}
}

@inproceedings{huang2021mos,
  title={Mos: Towards scaling out-of-distribution detection for large semantic space},
  author={Huang, Rui and Li, Yixuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8710--8719},
  year={2021}
}

@InProceedings{10.1007/978-3-319-10599-4_29,
author="Bossard, Lukas
and Guillaumin, Matthieu
and Van Gool, Luc",
editor="Fleet, David
and Pajdla, Tomas
and Schiele, Bernt
and Tuytelaars, Tinne",
title="Food-101 -- Mining Discriminative Components with Random Forests",
booktitle="Computer Vision -- ECCV 2014",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="446--461",
abstract="In this paper we address the problem of automatically recognizing pictured dishes. To this end, we introduce a novel method to mine discriminative parts using Random Forests (rf), which allows us to mine for parts simultaneously for all classes and to share knowledge among them. To improve efficiency of mining and classification, we only consider patches that are aligned with image superpixels, which we call components. To measure the performance of our rf component mining for food recognition, we introduce a novel and challenging dataset of 101 food categories, with 101'000 images. With an average accuracy of 50.76{\%}, our model outperforms alternative classification methods except for cnn, including svm classification on Improved Fisher Vectors and existing discriminative part-mining algorithms by 11.88{\%} and 8.13{\%}, respectively. On the challenging mit-Indoor dataset, our method compares nicely to other s-o-a component-based classification methods.",
isbn="978-3-319-10599-4"
}

@article{yu2015lsun,
  title={Lsun: Construction of a large-scale image dataset using deep learning with humans in the loop},
  author={Yu, Fisher and Seff, Ari and Zhang, Yinda and Song, Shuran and Funkhouser, Thomas and Xiao, Jianxiong},
  journal={arXiv preprint arXiv:1506.03365},
  year={2015}
}

@online{WinNT,
  author = {MultiMedia LLC},
  title = {{MS Windows NT} Kernel Description},
  year = 1999,
  url = {http://web.archive.org/web/20080207010024/http://www.808multimedia.com/winnt/kernel.htm},
  urldate = {2010-09-30}
}

@software{ilharco_gabriel_2021_5143773,
  author       = {Ilharco, Gabriel and
                  Wortsman, Mitchell and
                  Wightman, Ross and
                  Gordon, Cade and
                  Carlini, Nicholas and
                  Taori, Rohan and
                  Dave, Achal and
                  Shankar, Vaishaal and
                  Namkoong, Hongseok and
                  Miller, John and
                  Hajishirzi, Hannaneh and
                  Farhadi, Ali and
                  Schmidt, Ludwig},
  title        = {OpenCLIP},
  month        = jul,
  year         = 2021,
  publisher    = {Zenodo},
  version      = {0.1},
  doi          = {10.5281/zenodo.5143773},
  url          = {https://doi.org/10.5281/zenodo.5143773}
}

@inproceedings{schuhmann2022laionb,
  title={{LAION}-5B: An open large-scale dataset for training next generation image-text models},
  author={Christoph Schuhmann and
          Romain Beaumont and
          Richard Vencu and
          Cade W Gordon and
          Ross Wightman and
          Mehdi Cherti and
          Theo Coombes and
          Aarush Katta and
          Clayton Mullis and
          Mitchell Wortsman and
          Patrick Schramowski and
          Srivatsa R Kundurthy and
          Katherine Crowson and
          Ludwig Schmidt and
          Robert Kaczmarczyk and
          Jenia Jitsev},
  booktitle={Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2022},
  url={https://openreview.net/forum?id=M3Y74vmsMcY}
}

@article{Thomee_2016,
  title={YFCC100M: The new data in multimedia research},
  author={Thomee, Bart and Shamma, David A and Friedland, Gerald and Elizalde, Benjamin and Ni, Karl and Poland, Douglas and Borth, Damian and Li, Li-Jia},
  journal={Communications of the ACM},
  volume={59},
  number={2},
  pages={64--73},
  year={2016},
  publisher={ACM New York, NY, USA}
}

@inproceedings{changpinyo2021conceptual,
  title={Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts},
  author={Changpinyo, Soravit and Sharma, Piyush and Ding, Nan and Soricut, Radu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3558--3568},
  year={2021}
}