% !TeX spellcheck = en_US

\section{Incomparability}

In this section we prove that  the regainingly approximable and the nearly computable numbers are incomparable within the left-computable numbers. One of the separations is provided by the following proposition.
\begin{prop}\label{sadjasjhkrtjhqwejhxvbbmasdgh}
	There exists a regainingly approximable number which is not nearly computable.
\end{prop}
\begin{proof}
	A result of Downey, Hirschfeldt, and LaForte~\cite[Theorem~2.15]{DHL01} implies that every strongly left-computable number that is nearly computable is, in fact, computable.
	But Hertling, Hölzl, and Janicki~\cite{HHJ2023} established the existence of regainingly approximable numbers that are strongly left-computable without being computable. Such a number can therefore not be nearly computable.
\end{proof}

The other separation is the second main result of this article. 
\begin{theorem}\label{satz:FBNAA}
	There exists a left-computable number which is nearly computable but not regainingly approximable.
\end{theorem}
While the proof of Theorem~\ref{satz:FBNAA} will be structurally similar to that of Theorem~\ref{satz:fast-berechenbar-aufholend-approximierbar}, there are important differences that, while seemingly subtle, vastly impact the dynamics of the construction. In these introductory explanations we will thus focus on the differences between both constructions, but will then proceed with the construction and verification in full detail.
We again prove the theorem by constructing a computable non-decreasing sequence of rational numbers $(x_t)_t$ which converges nearly computably to some $x$.
To guarantee that $x$ is not regainingly approximable, we can use the following characterization.
\begin{lem}[Hertling, Hölzl, Janicki~\cite{HHJ2023}]\label{prop:charakterisierung-aa}
	The following statements are equivalent for a left-computable number~$x$:
	\begin{enumerate}
		\item $x$ is regainingly approximable.
		\item For every computable non-decreasing sequence of rational numbers $(x_n)_n$ converging to $x$ there exists a computable increasing function $s \colon \IN \to \IN$ with $x - x_{s(n)} < 2^{-n}$ for infinitely many $n \in \IN$.
	\end{enumerate} 
\end{lem}
It is thus sufficient to ensure that for the sequence $(x_t)_t$ that we are constructing there is no computable function $s$ as in the second item. Therefore, for every~$e \in \IN$, we define the following negative requirement:
\begin{equation*}
	\mathcal{N}_e \colon \varphi_e \text{ total and increasing } \Rightarrow \left(\exists m \in \IN\right) \left(\forall n \geq m\right) \;  x - x_{\varphi_e(n)} \geq 2^{-n}
\end{equation*}
Notice how the quantifiers differ from those in the negative requirements used to prove Theorem~\ref{satz:fast-berechenbar-aufholend-approximierbar}; here, a negative requirement can be threatened infinitely often, which will need to be reflected in the details of the construction below.

To ensure that $x$ is nearly computable, we use the same positive requirements as before; namely, for every $e \in \IN$:
\begin{equation*}
	\mathcal{P}_e \colon \varphi_e \text{ total and increasing }  \Rightarrow \left(x_{\varphi_e(t+1)} - x_{\varphi_e(t)}\right)_t
	\text{ converges computably to } 0
\end{equation*}
As in the last proof, the two types of requirements seemingly contradict each other. We will again resolve this apparent conflict by splitting large jumps into small jumps that will be scheduled and delayed for later execution.

We point out that, despite the more demanding negative requirements used here, the proof of this theorem is somewhat easier than that of Theorem~\ref{satz:fast-berechenbar-aufholend-approximierbar}. This is because in that proof, unlike here, in order to establish regaining approximability, much effort had to be devoted to ensuring  the existence of the special cut-off stages.

\smallskip

We again work with an infinite injury priority construction on an infinite binary tree of strategies~$\sigma \in \Sigma^*$ that each are responsible for satisfying both requirements $\mathcal{N}_{\left|\sigma\right|}$ and $\mathcal{P}_{\left|\sigma\right|}$, and define 
the \emph{parameters} of such a strategy as the following four functions from $\SigmaS \times \IN$ to $\IN$, defined for every $\sigma \in \Sigma^*$ and every~$t\in\IN$:
\begin{itemize}
	\item a \textit{counter} $c(\sigma)[t]$
	\item a \emph{pause flag} $p(\sigma)[t]$
	\item a \textit{restraint} $r(\sigma)[t]$
	\item a \textit{witness} $w(\sigma)[t]$		
\end{itemize}
As before, by construction, $w$ and $r$ will be non-decreasing in $t$ for each $\sigma$. In the construction, some negative requirements will require attention infinitely often. The pause flag will be used to prevent  high priority negative requirements from precluding other requirements from ever receiving attention.

\smallskip

After these informal remarks, we proceed with the full proof of the theorem.	
\begin{proof}[Proof of Theorem~\ref{satz:FBNAA}]
	We recursively define a computable non-decreasing sequence of rational numbers $(x_t)_t$ starting with $x_0 := 0$. At the same time, we also recursively define four functions ${c, p, r, w \colon \SigmaS \times \IN \to \IN}$
	starting with
\begin{align*}
	c(\sigma)[0]	&:= 0, \\
	p(\sigma)[0]	&:= 0, \\
	r(\sigma)[0]	&:= 0, \\
	w(\sigma)[0]	&:= \nu(\sigma),
\end{align*}
for all $\sigma \in \SigmaS$.
As in the proof of Theorem~\ref{satz:fast-berechenbar-aufholend-approximierbar}, the construction proceeds in stages consisting of at most $t + 1$ substages. 
At the end of each stage $t\in \IN$, we will fix a finite binary string $\truepath[t]$ and say that stage~$t$ {\em settles on}~$\truepath[t]$. Again, this string is determined in the substages as follows: In the first substage of each stage we {\em apply} 
strategy~$\lambda$; and in each substage when some $\sigma$ is applied, we can choose whether we want to {\em apply} $\sigma0$ or $\sigma1$ in the following substage or whether we want to let the current stage end right after the current substage. 
The strategy applied in the last substage of a stage is then the string that that stages settles on.

We define the same terms as before, but with the different conditions needed here:
\begin{itemize}
	\item  \emph{Initializing} a strategy~${\tau \in \SigmaS}$ at a stages $t$ means setting
\begin{align*}
	c(\tau)[t+1] &:= 0, \\
	w(\tau)[t+1] &:= \nu(\tau) + t + 2.
\end{align*}
	\item We say that a strategy $\sigma\in \SigmaS$ is {\em threatened at stage $t$} if the  conditions 
	\begin{itemize}
	\item $p(\sigma)[t] = 0$,
	\item $\ell(e)[t] \geq w(\sigma)[t]$,
	\item $x_{t} - x_{\varphi_{e}(\ell(e)[t])} < 2^{-w(\sigma)[t]}$
\end{itemize}
	are satisfied. As before, to defeat this threat, we would like to react by making some large jump.
	
	\item We say that a strategy $\sigma\in \SigmaS$ is \emph{expansionary at stage $t$} if the conditions
	\begin{itemize}
		\item $\ell(e)[t]\geq 0$ where $e:=|\sigma|$,
		\item $x_{t} - x_{\varphi_{e}(\ell(e)[t])} < 2^{-r(\sigma)[t]}$
	\end{itemize}
	are satisfied. As before this means that $\varphi_{e}$ has made some progress towards looking like a total, increasing function. 
\end{itemize}

We complete the description of the construction by giving the details of what we do in a substage of stage~$t$ when a strategy $\sigma \in \SigmaS$ is applied; note the significantly different initialization behaviour compared with the proof of Theorem~\ref{satz:fast-berechenbar-aufholend-approximierbar}:
\begin{enumerate}
	\item Let $e := \left|\sigma\right|$. If we have $e = t$, then this is the last substage, we set
	\begin{equation*}
		x_{t+1} := x_t,
	\end{equation*}
	we initialize all strategies $\tau \in \SigmaS$ with $\sigma <_L \tau$, and terminate stage~$t$. Otherwise we continue with~(2).	

	\item \emph{Negative requirement:}
	If $\sigma$ is not threatened at stage $t$, set
	\[p(\sigma)[t+1] := 0,\] meaning in particular that if strategy $\sigma$ was paused before, it is now unpaused again. Then jump directly to~(3).
	
	\smallskip
		
 Otherwise, that is if $\sigma$ is threatened at stage $t$, check if there is a $\gamma \in \Sigma^*$ with $\gamma 0 \sqsubseteq \sigma$ and $r(\gamma)[t+1] \geq w(\sigma)[t]$. If not, then let
	\begin{align*}
		x_{t+1} &:= x_{t} + 2^{-w(\sigma)[t]}.
	\end{align*}
If yes, then choose the longest such $\gamma$ and set
	\begin{align*}
		c(\gamma)[t+1] 	&:= \left\langle \sigma, 2^{r(\gamma)[t+1] - w(\sigma)[t]}\right\rangle, \\
		x_{t+1} &:= x_t.
	\end{align*}
	In either case, this will be the last substage of this stage. We pause strategy~$\sigma$ by setting
	\begin{align*}
		p(\sigma)[t+1] &:= 1;		
	\end{align*}
	this prevents $\sigma$ from being threatened in the next stage and thus gives other, lower priority strategies a chance to act. We also set 
\begin{align*}
	w(\sigma)[t+1] &:= w(\sigma)[t] + 1
\end{align*}
	which, unlike in the proof of Theorem~\ref{satz:fast-berechenbar-aufholend-approximierbar}, is necessary due to the infinitary nature of the negative requirements. We then initialize all strategies $\tau \in \SigmaS$ with $\sigma <_L \tau$, and terminate stage $t$.
	
	\item \emph{Positive requirement:}
	If $\sigma$ is not expansionary at stage $t$, continue with the next substage $e+1$ applying~$\sigma 1$. As before, this
 means that we currently have no reason to believe that $\varphi_e$ is a total and increasing function.
		
		Otherwise, if $\sigma$ is expansionary at stage $t$, we check if $c(\sigma)[t] = 0$. If this is the case, then we set
	\begin{equation*}
		r(\sigma)[t+1] := r(\sigma)[t] + 1
	\end{equation*} 
	and continue with the next substage $e+1$ applying~$\sigma 0$. As before, the ``0'' documents that we
	have made our restraint on future jump sizes stricter because we currently consider $\varphi_e$ a viable candidate for being a total and increasing function.
	
	Otherwise there exist a strategy $\alpha \in \SigmaS$ and a number $k \in \IN$ with $c(\sigma)[t] = \left\langle \alpha, k+1\right\rangle$, meaning that we still have scheduled jumps to execute. Thus check if there exists a $\gamma \in \Sigma^*$ with $\gamma 0 \sqsubseteq \sigma$. If not, then set 
	\begin{equation*}
		x_{t+1} := x_{t} + 2^{-r(\sigma)[t]}.
	\end{equation*}
	If yes, choose the longest such $\gamma$. The argument used to prove Fact~\ref{restrait_monotony} works exactly in the same way for the present construction; thus we have $r(\gamma)[t+1] \geq r(\sigma)[t]$ and we can set
	\begin{align*}
		c(\gamma)[t+1] &:= \left\langle \alpha, 2^{r(\gamma)[t+1] - r(\sigma)[t]}\right\rangle, \\
		x_{t+1} &:= x_t.
	\end{align*}
	In either case, this will be the last substage of this stage. As one of the scheduled jumps has been taken care of, we can decrement the corresponding counter by setting
	\begin{equation*}
			c(\sigma)[t+1] := \begin{cases}
				0 &\text{if $k = 0$,} \\
				\left\langle \alpha, k\right\rangle &\text{otherwise}.
			\end{cases}
	\end{equation*}
	Then we initialize all strategies $\tau \in \SigmaS$ with $\sigma0 <_L \tau$, and terminate stage~$t$.
\end{enumerate}

	If some of the parameters $c(\sigma)[t+1]$, $p(\sigma)[t+1]$, $r(\sigma)[t+1]$, or $w(\sigma)[t+1]$ have not been explicitly set to some new value during stage $t$, then we set them to preserve their last respective values $c(\sigma)[t]$, $p(\sigma)[t]$, $r(\sigma)[t]$, or $w(\sigma)[t]$. 

\medskip

We proceed with the verification. The following properties of the restraint and the witness functions follow directly from their definitions; we omit the proofs.
\goodbreak
\begin{fact}\label{satz:FBNAA:lem04}
For all $\sigma, \tau \in \Sigma^*$ and all $t \in \IN$ we have
\begin{itemize}
	\item \makebox[\widthof{$w(\sigma)[t]$}][r]{$r(\sigma)[t]$} $\leq t$,
	\item \makebox[\widthof{$w(\sigma)[t]$}][r]{$r(\sigma)[t]$} $\leq r(\sigma)[t+1]$,
	\item $w(\sigma)[t]$ $\leq w(\sigma)[t+1]$.\qed
\end{itemize}
\end{fact}

	It is easy to verify that  Fact~\ref{asdjltzhjkqwehk} and Fact~\ref{fact:counters-on-expansionary-stages} carry over to this construction with literally the same proofs.
	The next two statements hold because the pause function is not affected by initializations.
	\begin{fact}\label{sdfjhasdfkjlersdvsdfdfgdfssd}
		Let $t_1 < t_2$ be two consecutive stages at which some strategy $\sigma \in \SigmaS$ is applied. Then $p(\sigma)[t_1]=0$ or $p(\sigma)[t_2]=0$.\qed
	\end{fact}
	\begin{fact}\label{sdfjhasdfkjldfghjkasjlersdvsdf}
	Let $t_1 < t_2$ be two consecutive stages at which some strategy $\sigma \in \SigmaS$ is applied. Assume that $\sigma$ is threatened at $t_1$. Then $\sigma$ is not threatened at $t_2$.
	\end{fact}
\begin{proof}
	Since $\sigma$ is threatened at $t_1$, by construction we have both $p(\sigma)[t_1] = 0$ and $p(\sigma)[t_1+1] = 1$. Then, by construction, we still have $p(\sigma_l)[t_2] = 1$, and thus $\sigma$ cannot be threatened at~$t_2$.
\end{proof}
The proof of Lemma~\ref{satz:FBNBAA:lem02} has to be modified as follows to reflect the different dynamics of the present construction.
	\begin{lem}\label{fghsdfdhdfsdgdfghgfsfsdf}
		Let $\sigma \in \Sigma^*$. The following two properties are equivalent:
		\begin{enumerate}
			\item The strategy $\sigma$ is applied and expansionary at infinitely many stages.
			\item The strategy $\sigma$ is applied, not threatened, and expansionary at infinitely many stages.
			\item Infinitely many stages settle on some extension of $\sigma0$.
		\end{enumerate}
	\end{lem}
	\begin{proof}
		``$(1) \Rightarrow (2)$'': Let $t_1$ be any stage at which $\sigma$ is applied and expansionary. We claim there is a stage $t_2 \geq t_1$ at which $\sigma$ is applied, not threatened, and expansionary. If $\sigma$ is not threatened at $t_1$ we can let $t_2:=t_1$. Otherwise let $t_2$ be the next stage at which $\sigma$ is applied. In this case, to see that $t_2$ is as needed, note that by construction and by the definition of an expansionary stage, $\sigma$ is still expansionary at $t_2$. But by Fact~\ref{sdfjhasdfkjldfghjkasjlersdvsdf}, $\sigma$ cannot be threatened at~$t_2$.
		
		\smallskip
		
		``$(2) \Rightarrow (3)$'':  Suppose that there are infinitely many stages at which $\sigma$ is applied, not threatened, and expansionary. Let $t_0 \in \IN$ be an arbitrary  such stage. 
		We claim that there must be a stage $t^\ast \geq t_0$ where $\sigma0$ is applied. 
		If $c(\sigma)[t_0] = 0$, then $t^\ast=t_0$ by construction. 
		Otherwise fix $\alpha \in \SigmaS$ and $k \geq1$ with $c(\sigma)[t_0] = \left\langle \alpha, k\right\rangle$. Then let $t_1, \dots, t_k \in \IN$ denote the $k$ consecutive stages where $\sigma$~is applied, not threatened, and expansionary that immediately follow $t_0$; we claim that  we can find~$t^\ast$ among them. Namely, if between $t_0$ and $t_k$ an initialization of $\sigma$ occurs at some stage $\widehat t$, then let $t^\ast$ be the smallest element of $\{t_0,\dots, t_k\}$ that is greater than~$\widehat t$. Otherwise, if no such initialization occurs, then we must have  $c(\sigma)[t_k] = 0$ by construction, and $t^\ast = t_k$.
		
		\smallskip
		
		``$(3) \Rightarrow (1)$'': Suppose that infinitely many stages settle on some extension of $\sigma0$. By construction $\sigma$ must be applied and expansionary at these stages.
	\end{proof}
	
	Define $J$ and $u$ as in the proof of Theorem~\ref{satz:fast-berechenbar-aufholend-approximierbar}. We continue by noting that Fact~\ref{sdlakjldfgahrjehrfhksbfasjd234}, Lemma~\ref{satz:FBNBAA:lem:spruenge-expansionary}, Fact~\ref{remark:spruenge-expansionary-weak}, Lemma~\ref{satz:FBNBAA:lem:spruenge-threatened}, Fact~\ref{remark:spruenge-threatened-weak}, and 
	Corollary~\ref{jsjhfarjslkdgssfg} again carry over to this construction with literally the same proofs. The proof of Lemma~\ref{sdfjkasdjlkfgjkleknjjxvc} needs to be modified as follows, because here we use different rules for increasing witnesses.	
	\begin{lem}\label{sdfjkasdjlkfgjkleknjjxvcdfdfgdfg}
		Let $I \subseteq J$, let $\sigma \in \SigmaS$ and let $t_0 \leq \min u(I)$. Then we have
		\begin{equation*}
			\sum_{\mathclap{t' \in u(I)\colon \truepath[t']=\sigma}}
			\; 2^{-w(\sigma)[t']} \leq 2^{-w(\sigma)[t_0]+1}.
		\end{equation*}
	\end{lem}
	\begin{proof}
		By definition of $u$, all the numbers $t'$ that appear in the sum on the left-hand side are stages where $\sigma$ is applied and threatened. By construction, between two such stages,  the value of $\sigma$'s witness grows by at least $1$.
		Thus,	
		\begin{equation*}
			\sum_{\mathclap{t' \in u(I)\colon \truepath[t']=\sigma}}
			\; 2^{-w(\sigma)[t']}
			\leq \sum_{k=0}^{\infty} \;
			2 ^{-(w(\sigma)[t_0]+k)}
			\leq 2^{-w(\sigma)[t_0]+1}. \qedhere
		\end{equation*}
	\end{proof}
	Using these tools, we can prove the following statement.
	\begin{prop}
		The sequence $(x_t)_t$ is computable, non-decreasing, and bounded from above. Thus, its limit $x := \lim_{t\to\infty} x_t$ is a left-computable number.
	\end{prop}
	
	\begin{proof}
		The proof is literally the same as that of Proposition~\ref{satz:FBNBAA:prop:konvergenz}, except with Lemma~\ref{sdfjkasdjlkfgjkleknjjxvcdfdfgdfg} in place of Lemma~\ref{sdfjkasdjlkfgjkleknjjxvc}.
	\end{proof}

The following is analogous to Proposition~\ref{sdfjlw3ljsdadfgjrfasdfdfg}, but allows for an easier proof.
\begin{prop}\label{satz:FBNAA:lem03}
For every $l \in \IN$, there exists a binary string $\sigma_l \in \Sigma^{l}$ satisfying the following conditions:
\begin{enumerate}
	\item There exist infinitely stages in which $\sigma_l$ is applied.
	\item There exist only finitely many stages in which $\sigma_l$ is initialized.
\end{enumerate}
In particular, the map $t \mapsto \left|\truepath[t]\right|$ is unbounded, and if we let 
$\truepath$ denote the true path of $(\truepath[t])_t$ then  conditions (1) and (2) hold for every $\sigma \prefix \truepath$.
\end{prop}
\begin{proof} 
	We proceed by induction. The claim trivially holds for $l = 0$ since $\lambda$ is applied in every stage but never initialized.
	Assume that for some fixed $l \in \IN$ there exists a strategy $\sigma_l \in \Sigma^l$ satisfying both conditions. Let $t_0 \in \IN$ be the earliest stage after which $\sigma_l$ is no longer initialized. 
	There are two cases:
	\begin{itemize}
		\item {\em $\sigma_l0$ is applied infinitely often:}
		We claim $\sigma_l0$ is never initialized after $t_0$; this is because by construction any initialization of $\sigma_l0$ would have to occur in a stage where some $\gamma <_L \sigma_l0$ is applied; this would also initialize $\sigma_l$, contradiction. Thus we can choose $\sigma_{l+1} := \sigma_l 0$.
		
		\item {\em $\sigma_l0$ is applied only finitely often:}
		Due to Lemma~\ref{fghsdfdhdfsdgdfghgfsfsdf} in this case there is a stage $t_1 \geq t_0$ after which $\sigma_l$ is never again applied and expansionary. Then, by construction, $\sigma_l1$ is never again initialized after $t_1$.
 We also claim that for every $t_2 \geq t_1$ at which $\sigma_l$ is applied there exists a stage $t_3\geq t_2$ at which $\sigma_l1$ is applied. If $\sigma_l$ is not threatened at $t_2$ then by construction $\sigma_l1$ is applied at $t_2$, and we are done. Otherwise, if $\sigma_l$ is threatened at $t_2$, then by Fact~\ref{sdfjhasdfkjldfghjkasjlersdvsdf} we have that $\sigma_l$ cannot be threatened at the next stage $t_3 > t_2$ where $\sigma_l$ is applied. Thus $\sigma_l1$ is applied at $t_3$. 
Consequently, we can choose $\sigma_{l+1} := \sigma_l 1$.
	\end{itemize}
The second part of the proposition is proven in literally the same way as in the proof of Proposition~\ref{sdfjlw3ljsdadfgjrfasdfdfg}.
\end{proof}

The following lemma demonstrates that the dynamics that result from the way the construction was set up work as intended.
\begin{lem}\label{dfjkhasdjldfgmjasddh}
	Let $e$ be such that $\varphi_e$ is total and increasing and let $\sigma \prefix\truepath$ with $|\sigma|=e$. Then the following statements hold:
	\begin{enumerate}
		\item There exist infinitely many stages at which $\sigma$ is applied and threatened, and in particular, $(w(\sigma)[t])_t$ tends to infinity. Furthermore, if $t_0$ is a stage after which $\sigma$ is never again initialized, then for ${m := w(\sigma)[t_0]}$ we have that every $k \geq m$ is an element of $(w(\sigma)[t])_t$.
		
		\item There exist infinitely many stages at which $\sigma$ is applied and expansionary.
		In particular, $(r(\sigma)[t])_t$ tends to infinity.
	\end{enumerate}
\end{lem}
\begin{proof} \; \nopagebreak
\begin{enumerate}
	\item 	 By Proposition~\ref{satz:FBNAA:lem03}, $\sigma$ is applied infinitely often and there is a stage $t_0$ after which $\sigma$ is not initialized anymore. Then, for $t> t_0$ we can only have $w(\sigma)[t+1] > w(\sigma)[t]$ if $\sigma$ is applied and threatened at $t$. 
	Recall that the assumption that $\varphi_e$ is total and increasing is equivalent to the statement that 
$(\ell(e)[t])_t$ tends to infinity. 
	Thus, by the definition of a threatened stage, by the fact that $(x_t)_t$ converges, and using Fact~\ref{sdfjhasdfkjlersdvsdfdfgdfssd}, for every $t_1> t_0$ there exists a $t_2 \geq t_1$ at which $\sigma$ is applied and threatened and such that $w(\sigma)[t_1+1] = w(\sigma)[t_1]+1$. This is enough to establish all three claims.
	
	\item Let $t_1 \in \IN$ be arbitrary. 
	By (1), there are infinitely many stages at which $\sigma$~is applied and threatened. Thus, by Fact~\ref{sdfjhasdfkjldfghjkasjlersdvsdf}, there must also be infinitely many stages, where $\sigma$ is applied and not threatened. 
	Therefore, and since $(x_t)_t$ converges, there is a smallest $t_2 \geq t_1$ such that for all 
	$t \geq t_2$ we have 
	${x_t - x_{\varphi_{e}(\ell(e)[t])} < 2^{-r(\sigma)[t_1]}}$
	and at which $\sigma$ is applied, not threatened, and by by definition expansionary.
	Thus, since $t_1$ was arbitrary, there are infinitely many stages at which $\sigma$ is applied and expansionary. Then by Lemma~\ref{fghsdfdhdfsdgdfghgfsfsdf}, $\sigma0$ is applied at infinitely many stages, and by construction, $(r(\sigma)[t])_t$ tends to infinity.\qedhere
\end{enumerate}	
\end{proof}

Noting that Lemma~\ref{satz:FBNBAA:lem07} also holds for this construction with literally the same proof as before, we are ready to prove that all negative requirements are satisfied.
\begin{prop}
	$\mathcal{N}_e$ is statisfied for all $e \in \IN$.
\end{prop}
\begin{proof} 
	Let $e$ be such that $\varphi_e$ is total and increasing, and let $\sigma \prefix\truepath$ with $|\sigma|=e$. 	Let $t_0 \in \IN$ be the earliest stage after which $\sigma$ is not initialized anymore. Let $m$ be as in Lemma~\ref{dfjkhasdjldfgmjasddh}~(1), and let $n \geq m$ be arbitrary. Then there exists a uniquely determined stage $t_1 \geq t_0$ at which $\sigma$ is applied and threatened and such that $w(\sigma)[t_1] = n$. Let $t_2 > t_1$ be the next stage at which $\sigma$ is applied. Then 
	\[
		x - x_{\varphi_{e}(n)} = x - x_{\varphi_{e}(w(\sigma)[t_1])} \\
		\geq x_{t_2} - x_{\varphi_{e}(\ell(e)[t_1])}  \\
		\geq   2^{-w(\sigma)[t_1]} \\
		= 2^{-n};
	\]
	here, the first inequality uses the fact that 
	$\ell(e)[t_1] \geq w(\sigma)[t_1]$  by definition of a threatened stage, and the second inequality uses Lemma~\ref{satz:FBNBAA:lem07}.

	In summary, there exists a number $m \in \IN$ such that for all $n \geq m$ we have $x - x_{\varphi_{e}(n)} \geq 2^{-n}$. Therefore,  $\mathcal{N}_e$ is satisfied.
\end{proof}
\begin{kor} 
	The number $x$ is not regainingly approximable.\qed
\end{kor}

It remains to prove that $x$ is nearly computable. 
Write 
\[S := \{e \in \IN \mid \varphi_{e} \text{ is total and increasing}\}.\] The following lemma is analogous to Lemma~\ref{satz:FBNBAA:lem08}; however, the infinitary nature of the negative requirements and the different initialization strategy used in this construction are reflected in the higher complexity of its statement and proof.
\begin{lem}\label{satz:FBNAA:lem09}
	 Let $\sigma \prefix \truepath$ and $t_0 \in \IN$ be the earliest stage after which $\sigma$ is no longer initialized and after which there are no more stages at which any $\tau \prefixeq \sigma$ with $\left|\tau\right| \notin S$ is applied and threatened. Let $t_1, t_2 \in \IN$ with $t_0 \leq t_1< t_2$ be two consecutive stages at which 
	$\sigma$ is applied and expansionary. Then we have
	\begin{equation*}
		x_{t_2} - x_{t_1} \leq 2^{-r(\sigma)[t_1] + 1} + \sum_{\mathclap{\substack{\phantom{,}\tau \prefixeq \sigma, \\ \left|\tau\right| \in S}}} 2^{-w(\tau)[t_1]+1}.
	\end{equation*}
\end{lem}
As in the proof of Lemma~\ref{satz:FBNBAA:lem08}, we need to analyze all possible causes for jumps being made between stages $t_1$ and $t_2$. Again there are essentially two such causes: we may still have jumps scheduled from before stage $t_1$ that await execution, and new threats may arise after $t_1$ leading to further jumps. 
The most important difference to Lemma~\ref{satz:FBNBAA:lem08} is however that here initial segments $\tau$ of $\sigma$ with $\left|\tau\right| \in S$ may also get threatened --- possibly multiple times --- leading to additional jumps that need to be accounted for by the sum in the statement of the lemma.
\begin{proof}
	We again distinguish between obligations to make jumps that may already stand at the moment when we enter stage $t_1$, and new obligations to make jumps that are created between stages $t_1$ and $t_2$.
	First, to quantify jumps due to potential standing obligations, note that in substages $0$ up to $|\sigma|-1$ of stage $t_1$, no jumps are made by construction. 
	Now consider the following facts:
	\begin{enumerate}
		\item No strategy $\tau <_L \sigma$ will be applied again after stage $t_1$, as otherwise this would lead to initialization of $\sigma$, which contradicts our assumptions. Thus, if any jumps are still scheduled for any such $\tau$ (that is, if $c(\tau)[t_1]>0$), we need not take them into account.
		
		\item For strategies $\tau \in \SigmaS$ with 
		$\tau 0 \prefixeq \sigma$ and $|\tau|\notin S$
		we must have  $c(\tau)[t_1] = 0$ due to Fact~\ref{fact:counters-on-expansionary-stages}. Furthermore,  $\tau$ will never be applied and threatened between stages $t_1$ and $t_2$ by our assumptions. Thus we need not consider these strategies in the remainder of the proof.
		
		\item For strategies $\tau \in \SigmaS$ with 
		$\tau 0 \prefixeq \sigma$ and $|\tau|\in S$
		we must have ${c(\tau)[t_1] = 0}$, as well. However, such a $\tau$ may get threatened between stages $t_1$ and $t_2$ which might lead to jumps that we need to take into account.
				
		\item While for strategies $\tau \in \SigmaS$ with $\tau1 \prefixeq \sigma$ we might have $c(\tau)[t_1]>0$, none of these scheduled jumps will ever be executed from $t_1$ onwards. This is because
		such a jump could only be executed during a stage at which $\tau$ is applied and expansionary. This would by construction lead to the initialization of all $\rho$ with $\tau0 <_L \rho$, which in particular include $\sigma$; contradiction. Thus, as before, we need not take such $\tau$'s into account.
		
		\item No strategy $\tau$ with $ \sigma0 <_L \tau$ can be applied at stage $t_1$ by construction. While such $\tau$'s may be applied during some stage $t_1 < t < t_2$, note that we set $c(\tau)[t_1+1]=0$ for all of them when they are initialized at the end of stage $t_1$.
		
		\item For a strategy $\tau$ with $\sigma0 \prefixeq \tau$ we may indeed have $c(\tau)[t_1] > 0$.
		
		\item Similarly, it might be the case that $c(\sigma)[t_1] > 0$.
	\end{enumerate}
	Thus, any jumps made in stages $t_1$ up to $t_2 -1$ are either caused by some strategy as in~(6) or~(7), or must be due to \textit{new} threats to strategies of type~(3) or~(5) that occur strictly between substage~$|\sigma|$ of stage~$t_1$ and stage $t_2$. We establish upper bounds for all of these cases:
	\begin{itemize}
		\item Concerning strategies of type~(6), by construction, if we make any jump at all while applying them, then these can only occur immediately at stage $t_1$ in substage $|\tau|$.
		We claim that such a jump can not occur due to  $\tau$ being applied and expansionary at $t_1$ with ${c(\tau)[t_1] > 0}$. This is because such a jump would not be made at $t_1$, but would by construction instead be split and scheduled for later execution by some strategy $\rho$ with $\sigma0 \prefixeq \rho0 \prefixeq \tau$, and this strategy $\rho$ will not be applied before stage $t_2$ by construction.
		Thus, the only reason to make a jump in this case is if
		$\tau$ is applied and threatened at $t_1$. Then, by construction the jump made would be of size 
		\[2^{-w(\tau)[t_1]} < 2^{-r(\sigma)[t_1+1]} \leq 2^{-r(\sigma)[t_1]}.\]
		
		\item Concerning~(7), in this case, by construction, we would like to make a jump of size $2^{-r(\sigma)[t_1]}$. The jump may be made immediately, or split and scheduled for later execution by some strategies that are prefixes of $\sigma$; but in either case the total sum of all jumps resulting from this is bounded by $2^{-r(\sigma)[t_1]}$ by Lemma~\ref{satz:FBNBAA:lem:spruenge-expansionary}.
		
		\item  Consider new threats to strategies $\tau$ of type~(5) that occur strictly between substage $|\sigma|$ of stage $t_1$ and stage $t_2$.
		Since these $\tau$'s were all initialized at stage $t_1$, we have $w(\tau)[t_1+1] = \nu(\tau) + t_1 + 2$ for each of them.
		Thus, 
		applying Lemma~\ref{sdfjkasdjlkfgjkleknjjxvcdfdfgdfg} to each such $\tau$ and then summing over all of them, the total sum of all jumps made or scheduled when such $\tau$'s are applied in stages between $t_1$ and $t_2$ can be at most $2^{-t_1}$, which by Fact~\ref{satz:FBNBAA:lem03} is at most~$2^{-r(\sigma)[t_1]}$.	
		
		\item Finally, consider new threats to strategies $\tau$ of type~(3) that occur at some stage $t$ strictly between substage $|\sigma|$ of stage $t_1$ and stage $t_2$. By Fact~\ref{remark:spruenge-threatened-weak} 		
		each such threat can only contribute jumps totaling at most $2^{-w(\tau)[t]}$. And, by construction, whenever this occurs, we set $w(\tau)[t+1]=w(\tau)[t]+1$. Thus, even if the same $\tau$ is threatened multiple times between $t_1$ and $t_2$, the total sum of all jumps associated with these threats sums to at most~${2^{-w(\tau)[t_1]+1}}$.		
	\end{itemize}
By construction, cases~(6) and~(7) exclude each other, thus the jumps caused by cases (5)--(7) combined contribute at most $2^{-r(\sigma)[t_1]+1}$. Together with the maximally possible contribution of all $\tau$'s of type~(3) we obtain \begin{equation*}
	x_{t_2} - x_{t_1} \leq 2^{-r(\sigma)[t_1] + 1} + \sum_{\mathclap{\substack{\phantom{,}\tau \prefixeq \sigma, \\ \left|\tau\right| \in S}}} 2^{-w(\tau)[t_1]+1}.\qedhere
\end{equation*}
\end{proof}

	After these preparations, we can show that all positive requirements are satisfied.
	\begin{prop}
		$\mathcal{P}_e$ is statisfied 	for all $e \in \IN$.
	\end{prop}
	\begin{proof} 
		Let $e \in \IN$ and $\sigma \prefix \mathcal{T}$ with $\left| \sigma \right| = e$. Suppose that $\varphi_{e}$ is  total and increasing. Then, by Lemma~\ref{dfjkhasdjldfgmjasddh}~(2), $(r(\sigma)[t])_{t}$ tends to infinity. Let $t_0 \in \IN$ be the earliest stage after which $\sigma$ is no longer initialized and such that, for all $\tau \prefixeq \sigma$ with $\left|\tau\right| \notin S$, there are no more stages at which $\tau$ is applied and threatened.
		For $n\in\IN$, write  
		\[t(n):=\min\left\{t \geq t_0\colon\; 
			\parbox{9cm}{\centering
				$r(\sigma)[t] \geq n+3$ and $\sum_{\tau \prefixeq \sigma, \left|\tau\right| \in S} 2^{-w(\tau)[t] + 1} \leq 2^{-(n+1)}$\\
				and $\sigma$ is applied and expansionary at stage $t$
			}
		\right\}.\]
		
		Note that for each $\tau \prefixeq \sigma$ with $\left|\tau\right| \in S$ we have that $(w(\tau)[t])_t$ tends to infinity by Lemma~\ref{dfjkhasdjldfgmjasddh}~(1), and thus $t(n)$ is defined for every $n$.
		Thus, we can define a function $v \colon  \IN \to \IN$ via ${v(n) = \ell(e)[t(n)]}$ for all $n\in\IN$. Clearly, $t$ and $v$ are computable. 
		
	 We claim that $v$ is a modulus of convergence of the sequence $(x_{\varphi_{e}(t+1)} - x_{\varphi_{e}(t)})_t$. 
	 To see this, let $n\in \IN$ and $i \geq v(n)$. Let $t_2 > t_1 \geq t(n)$ be the two consecutive stages at which $\sigma$ is applied and expansionary with $\ell(e)[t_1] \leq i$ and $\ell(e)[t_2] \geq i+1$. Applying Lemma~\ref{satz:FBNAA:lem09} and the assumption that $\sigma$ is expansionary at $t_1$, we obtain	 
		\begin{align*}
			x_{\varphi_{e}(i+1)} - x_{\varphi_{e}(i)} &\leq
			x_{\varphi_{e}(\ell(e)[t_2])} - x_{\varphi_{e}(\ell(e)[t_1])} \\
			&= \underbrace{\left( x_{\varphi_{e}(\ell(e)[t_2])} - x_{t_2} \right)}_{\leq 0} + \left( x_{t_2} - x_{t_1} \right) + \left( x_{t_1} - x_{\varphi_{e}(\ell(e)[t_1])} \right) \\
			&\leq  \left(2^{-r(\sigma)[t_1]+1} + \sum_{\substack{\tau \prefixeq \sigma, \\ \left|\tau\right| \in S}} 2^{-w(\tau)[t_1]+1}\right) 
			+ 2^{-r(\sigma)[t_1]} \\
			&\leq  2^{-r(\sigma)[t(n)]+1} + 2^{-(n+1)} + 2^{-r(\sigma)[t(n)]} \\
			&< 2^{-r(\sigma)[t(n)]+2} + 2^{-(n+1)} \\
			&\leq 2^{-n}.
		\end{align*}
		Thus $(x_{\varphi_{e}(t+1)} - x_{\varphi_{e}(t)})_t$ converges computably to zero, and $\mathcal{P}_e$ is satisfied.	
	\end{proof}
	
	\begin{kor}
		The number $x$ is nearly computable.\qed
	\end{kor}
	
This completes 
	the proof of the existence of a left-computable, nearly computable number that is not regainingly approximable.
	\phantom\qedhere
\end{proof}