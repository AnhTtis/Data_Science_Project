\section{Discussion}
Understanding the prevalence of hateful information on social media platforms is the primary driver behind this investigation of the most toxic profiles.
In order to characterize levels of consistency of such behavior, to be able to make early predictions of the spread of such content, and in essence to prevent the proliferation of the most hateful content providers, it would be beneficial to study the population of profiles who produce the most toxic content.  

Being able to adequately understand the behavior of the most toxic Twitter profiles is valuable in and of itself. It provides more well-informed choices about how and what to research in subsequent research investigations.
It makes it possible for toxicity-reduction strategies to be designed more intelligently in many ways.
  
We concede that we had to work within certain constraints, such as the Perspective API limiting our work to only English tweets.
Also, the Twitter API only allowed us to scrape the most recent 3200 tweets and not the entire timeline per profile. We will also like to acknowledge that because our seed data were balanced, with equal amounts of toxic and non-toxic profiles, the 1\% is not a complete portrayal of the entire Twitter-sphere.  

In the future, we plan to use our findings of highly toxic Twitter profiles to identify toxic Twitter profiles that are responsible for the highest toxicity in important Twitter discussions about politics, sports, and religion, among others. 
\label{sec:Discussion}
\section{Conclusion}
\label{sec:discussion_and_conclusion}

In the past, much research has been devoted to locating toxicity spreader accounts and bots based on a few tweets; however, our work examines the timeline of Twitter accounts and takes into account the consecutive tweets posted by Twitter accounts, as well as investigates the consistent toxicity exhibited by certain profiles.

We present a profile-centric approach to survey toxicity on Twitter and characterize the most toxic profiles. Our methodology is distinct from prior works that focus on particular events or hashtags and phrases over short time windows. We focus instead on the entire profile timeline, obtaining longitudinal data that reveals 
the bigger picture of a profile's toxic behavior. We annotate entire timelines with the Google Perspective API. Based on the toxicity of profile tweets, we isolate the 1\% most toxic profiles in our dataset and contrast their behavior with the remainder. 
This approach provides extra context to a profile's toxic behavior, providing new insights into toxicity on Twitter. 

We find that the most toxic 1\% of profiles are likely to be fake followers, indicating a level of coordinated and targeted toxic activity. They are likely to post inflammatory and profane content. Their tweets are typically textually eloquent and tend to repeat their posted content less. They are less likely to leverage auxiliary content such as URLs and hashtags in their posts.

Inspecting toxic profiles on their longitudinal data provides additional contextual insights that are otherwise missing when scrutinizing a profile on a single post. However, our approach still has limitations as obtaining this data is a challenging task. Specifically, Twitter limits the availability of the timeline to a profile's 3,200 most recent tweets. Certainly, with the full timeline, further insights could be obtained.
% In that sense, an interesting research direction can be to accommodate the entire timelines of profiles.

Findings regarding characteristics of the most toxic profiles such as
inflammatory and insulting behavior, repetitive and explicit hashtags, bursty tweeting patterns, and short and well-written tweets with supporting URLs to websites and blogs in their tweets can be used to identify the most toxic Twitter accounts in a specific scenario, such as profiles discussing politics or following a specific motivational movement. Furthermore, identifying and deleting such accounts will aid in the removal of toxicity from important Twitter discussions. Our approach is not limited to Twitter and can be applied to any social media platform discussion.

In the future, we plan to further study the details of the topics discussed by toxic profiles and investigate and characterize the coordinated toxic activity as evidence for toxic influence operations present in the data. 

