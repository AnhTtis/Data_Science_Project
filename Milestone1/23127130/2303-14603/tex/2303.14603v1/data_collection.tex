\begin{figure}[!t]
    \centering
    \includegraphics[width=1\linewidth]{figs/char_data_collection.png}
    \vspace{-4mm}
    \caption{\small Our dataset collection and augmentation pipeline; including dataset collection, user timeline crawl, and augmentation.}
    \label{fig:data_collection_flowchart}
    \vspace{-8mm}
\end{figure}

\section{Dataset Collection Methodology and Characterization}
\label{sec:dataset}
In this section, we detail our methodology for data collection and augmentation. 
We introduce our seed datasets, detail how the timelines of Twitter profiles were crawled, and how we augmented the collected tweet data with Google's Perspective API. We finish with an overall characterization of the augmented dataset, and our definition of the top 1\% toxic Twitter profiles i.e., the upper echelon of toxic profiles as determined by the ``Toxicity'' Perspective score of their tweets.
A summary of the selected datasets, details of their size, and labels can be found in Tab.~\ref{tab:dataset_info} and Tab. \ref{tab:dataset_summary}. Further, a flowchart of our data collection and augmentation methodology is overviewed in Fig.~\ref{fig:data_collection_flowchart}.


\begin{table}[t]
\centering
\resizebox{1.0\linewidth}{!}{
\begin{tabular}{c|r|r|r|p{3.6cm}|p{2cm}}
\hline
\multicolumn{6}{c}{\bf Seed Dataset} \\\midrule

\bf{Dataset} & \bf{TIDs} &  \bf{UIDs} & \bf{RUIDs} & \bf{Labels/Keywords} & \bf{Annotation} \\ \midrule

~\cite{gomez2019exploring} & 149,823 & - & 895 & sexist, racist, homophobic, religion, other hate, no hate    &   Amazon Mechanical Turk    \\ \hline
~\cite{kaggle:metoomovement} & 817,344 & - & 19,859 &  Keyword: MeTooMovement    &  Twitter Streaming API   \\ \hline  
~\cite{ribeiro2018like} & - & 100,385 & 100,385 & hateful, not hateful    &  CrowdFlower (appen) \\ \hline
~\cite{founta2018large} & -  & 98,378 & 98,378 & normal, abusive, spam, hateful    & CrowdFlower (appen) \\ \hline 
~\cite{jha-mamidi-2017-compliment}   & 10,583 & - & 324 & benevolent, hostile, other    & SVM (TF-IDF)    \\ \hline
~\cite{waseem-hovy-2016-hateful} & 16,907 & - & 891 & sexist, racist, neither    &  CrowdFlower (appen) \\ \hline
~\cite{waseem-2016-racist}  & 6,909 & - & 870 & sexist, racist, both, neither    &  CrowdFlower (appen) \\
% \hline 
% & & &\textbf{221,602} & & \\
\bottomrule
\end{tabular}
}
% \vspace{-0.0001mm}
\caption{\small Overview of 7 datasets used as a seed with a collection of User IDs (UIDs) or Tweet IDs (TIDs), whatever was made publicly available.
Note that TIDs were used to recover User IDs (RUIDs).}

\label{tab:dataset_info}
% \vspace{-6mm}
\end{table}
%
\begin{figure*}[t]
    \centering
    \begin{subfigure}[t]{0.32\linewidth}
            \includegraphics[width=\textwidth]{figs/perspective_score_CDF.pdf}
            \vspace{-6mm}
            \caption{\small Perspective API scores}
            \label{fig:perspective_scores_cdf}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
            \includegraphics[width=\textwidth]{figs/gini_index_CDF.pdf}
            \vspace{-6mm}
            \caption{\small Gini index}
            \label{fig:gini_index_cdf}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
            \includegraphics[width=\textwidth]{figs/api_scores_corrmatrix.pdf}
            \vspace{-6mm}
            \caption{\small Pearson Correlation}
            \label{fig:cor_matrix}
    \end{subfigure}
    \vspace{-2mm}
    \caption{\small (\protect\subref{fig:perspective_scores_cdf}) Cumulative Distribution Function (CDF) of median Perspective API scores per profile, across all tweets; 
    (\protect\subref{fig:gini_index_cdf}) Gini Index calculated on all 6 Perspective scores per profile; and (\protect\subref{fig:cor_matrix}) Pearson pairwise correlation matrix across amongst all Perspective API scores.
    }
    \label{fig:characterize} 
    \vspace{-2mm}
\end{figure*}

%
\subsection{Crawling User Timelines}
\label{sec:user-timeline-crawl}
To provide broad coverage of themes, we merged 7 balanced seed datasets (in terms of toxicity) from various topic domains (Tab.\ref{tab:dataset_info}), and we estimate that this results in a dataset that closely reflects the Twitter community.
Based on Twitter's terms and conditions, Twitter User IDs (UIDs) and tweet content cannot be publicly shared. 
Consequently, our seed datasets contain only Tweet IDs (TIDs) and their respective annotation (Tab.\ref{tab:dataset_info}).
Thus, the first step was to query Twitter's API~\cite{twitterAPI} to recover the UID responsible for each TID.
Next, we queried the Twitter API to retrieve each UIDs' timeline.
Twitter API only permits the retrieval of 3,200 most recent tweets from a profile, whilst not the entire timeline, this still allows us to study a significant length of the historical record of each profile and its evolving behavior.
We were unable to retrieve tweets from banned and deleted profiles.
From the retrieved tweets, we extract relevant details such as the text, timestamp of tweet creation, hashtags, and URLs, shared within tweets. For this study, we only consider English tweets.

\subsection{Dataset Augmentation with Perspective API}
\label{sec:dataset-augmentation}
In the aforementioned seed datasets, a profile was labeled toxic or not based on mostly one or at most as few as 3 tweets.
However, it is unrealistic to assume that this label can be a representation of a profile's overall tweeting behavior. We needed a measure of misbehavior for the entire timelines of the 143K profiles we crawled. 
We obtain this quantitative measure of misbehavior across all tweets through Google's Perspective API~\cite{perspective}.
The Perspective API provides multiple Convolutional Neural Network (CNN) based models trained with GloVe word embeddings~\cite{pennington-etal-2014-glove} for the evaluation of misconduct in text.
This API offers 16 models of which 10 are considered experimental. Each model, for every given input text, yields a score from 0 to 1 representing the intensity of a type of misbehavior. 
We retrieve scores from the 6 production-ready Perspective API models~\cite{37635}:
\begin{itemize}[leftmargin=*]
    \item \emph{Toxicity}: Rude, disrespectful, or unreasonable comments, likely to make people leave a discussion.
    \item \emph{Severe Toxicity}: Comments are very likely to make users leave a discussion or give up sharing their opinion.
    \item \emph{Identity Attack}: Negative or hateful comments targeting someone's identity, ethnicity, sexual orientation, and other characteristics.
    \item \emph{Inflammatory}: Intended to provoke or inflame others.
    \item \emph{Insult}: Insulting or negative comments towards a person or a group of people.
    \item \emph{Threat}: Intentions to inflict pain, injury, or violence against an individual or group.
\end{itemize}
We query all 293M tweets from 143K profiles for the 6 perspective scores. The collective time for dataset collection and augmentation was about 5 months and the size of the augmented data is close to 2TB. We characterize the dataset in the following section.
%
\begin{table}[!t]
\centering
\resizebox{1.0\linewidth}{!}{
\begin{tabular}{l|r||l|r}
\toprule
\textbf{Recovered Profiles}  &  142,987 &\textbf{Total Profiles >10 Tweets}  & 138,533   \\ \hline
\textbf{Total Tweets}  &   293,401,160& \textbf{Avg Total Tweets per profile}  & 2,051 \\ \hline
\textbf{Unique Tweets}  &   230,283,810 & \textbf{Avg Unique Tweets per profile} & 1,610   \\ 
\midrule
\end{tabular}
}
\caption{\small Summary of Seed datasets (cf. Tab.~\ref{fig:data_collection_flowchart}) and recovered profiles.}
\label{tab:dataset_summary}
% \vspace{-6mm}
\end{table}

%
\subsection{Characterization of Augmented Dataset} %3T}
\label{sec:3T-characterization}
% \vspace{-3mm}
To better understand the composition of our final dataset, we first inspect the Cumulative Distribution Function (CDF) of each Perspective score, across all tweets in all profile timelines (Fig.~\ref{fig:perspective_scores_cdf}).
We can observe that the median score of a tweet's score for any of the six misbehavior dimensions lies approximately in the range of 0.1 -- 0.2.
A steady rise in the curve in the low ranges of scores indicates that a majority of tweets do not strongly exhibit any specific form of misbehavior.

Additionally, the strongest signal for misbehavior is in the dimension of Inflammatory content.
A tail is observed with a small number of tweets acting as an exception to the rule, propagating a large amount of misbehavior (score $\rightarrow$ 1.0).

To measure a given profile's consistency in toxic behavior, we leverage the Gini Index over a profile's tweet perspective scores. The \textbf{\emph{Gini Index}} was originally proposed to measure the concentration of wealth~\cite{gini1912variabilita} within a population, but can equally be used to identify the extent of toxicity distribution among a profiles' tweets. 
A consistent set of scores (low or high) will produce a Gini Index closer to 0, whereas high variability scores produce a Gini Index approaching 1. 
We visualize the CDFs of the Gini index for all profiles across six dimensions of toxicity in Fig.~\ref{fig:gini_index_cdf}. We see that the median Gini is between 0.35 for Insult and 0.46 for Severe Toxicity. The majority of profiles have a Gini-Index in a range of 0.3-0.5 with a median of 0.4, which indicates that these profiles are not consistently toxic; however, we observe profiles in the lowest and highest range of Gini-Index 0-0.3 and > 0.6, pointing to profiles being constantly toxic. The Gini Index of Inflammatory scores is the lowest, implying that Inflammatory behavior is exhibited most consistently. Fig.~\ref{fig:cor_matrix} illustrates the correlation among all perspective scores, we note that toxic profiles are also likely to produce tweets that show identity attack and insult, and inflammation.

\subsubsection{\bf Takeaways:}
\begin{itemize}[leftmargin=*]
    \vspace{-1mm}
    \item With the range of median toxicity scores for all Twitter profiles between 0.14-0.16, we note that the majority of tweets on Twitter are not toxic.
    \item The majority of Twitter profiles have a low Gini index (0.4), thus they skew towards being consistently toxic across their tweets.
\end{itemize}