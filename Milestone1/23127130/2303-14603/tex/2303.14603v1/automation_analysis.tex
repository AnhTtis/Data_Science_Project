\subsection{Automation}
\label{sec:automation_analysis}
\subsubsection{Are toxic profiles automated bots?} Automated accounts or ``bots'' have been observed on Twitter~\cite{TwitterBotAccounts}, however, Twitter permits automated accounts when they behave well according to Twitter's policy~\cite{Twitterautomation}. 
Thus, in addition to investigating the percentage of bots in our toxic and baseline groups, we also scrutinize the percentage of Twitter policy breaching ``bad bots'', e.g. Spammer, Fake Follower bots from \emph{Botometer API v4}~\cite{Sayyadiharikandeh_2020}. 
The Botometer API provides scores from five classifiers that estimate a profile's similarity to different kinds of bot behavior, including Fake Follower bots, Financial bots, self-declared bots, spammer bots, and astroturf accounts. 
Botometer API leverages features of a profile including the number of friends, social network structure, temporal activity (e.g. tweeting, likes, retweets), tweet language, and sentiment.
Botometer provides scores in the [0,1] range, using either English or Universal (language-independent) features (we report overall universal feature scores). 
Botometer API defines each as:
\begin{itemize}[leftmargin=*]
    \item {\bf Bot score}: An overall probability of profile being a bot
    \item {\bf Astroturf}: A profile being one of the manually labeled political bots. These accounts systematically delete content over time.
    \item {\bf Fake Follower}: An account being a bot purchased to increase follower counts.
    \item  {\bf Financial}: A profile used to post cashtags. Cashtags are stock symbols used with the ``\$'' symbol. Cashtags bots promote low-value stocks by exploiting the popularity of high-value ones.
    \item  {\bf Self Declared}: A profile that is a bot registered with \texttt{botwiki.org}.
    \item {\bf Spammer}: A profile labeled as spam bots from several datasets.
\end{itemize}
%
The scores for every profile are presented in Fig.~\ref{fig:botometer_scores}.
Each boxplot details the mean and standard deviation of all scores for both toxic and baseline profiles. The scores range from [0-1], with 0 being the most human-like and 1 as the most bot-like. 
%


We observe that toxic profiles generally have higher overall Botometer scores with a median of 0.7, however, there still exists toxic profiles that are human-like with scores in the 1st standard deviation range <0.45 overall score. Baseline profiles skew more human-like in comparison. 
%
Astroturf (participating in politics \cite{ratkiewicz2011detecting}) scores are fairly low for both sets, albeit baseline profiles skewing slightly higher, this may explain that despite the most toxic these profiles are not automatically removed by Twitter, there are still long-lived spam and profane accounts on Twitter, also reported by~\cite{6488315}.
Very few of the baseline profiles are likely to be fake followers, with a median probability of 0.14. On the other hand, just under half of the toxic profiles have a probability above 0.5 and are likely to be purchased, followers. This indicates the presence of maliciously toxic actors amplifying their toxic message through these profiles. 
Neither set of profiles are likely to engage in financial market updates, though there are notably more among toxic profiles. 
We observe that toxic profiles are widely spread on the spectrum of ``self-declared'' in stark contrast to baseline profiles. Spamming is not a trait of baseline profiles whereas toxic profiles have notably higher scores, and there are toxic profiles with spammer scores as high as 0.85. 
%
\subsubsection{\bf Takeaways:}
\begin{itemize}[leftmargin=*]
    \item We confirm the findings reported in ~\cite{doi:10.1080/10584609.2018.1526238} that the distribution of toxic profiles is less likely to be associated with politics, despite their toxic nature.  %
    \item Toxic and baseline profiles are unlikely political or financial bots.  %
    Our study validates prior work~\cite{6488315, Twitterverifiedbots} that the toxic profiles have a high likelihood to be spam bots and have behavior consistent with self-declared bots. 86.5\% of toxic profiles are verified (\S\ref{sec:profile_data_analysis})--as also reported in~\cite{Twitterverifiedbots}. 
    \item Many validated toxic profiles are verified which makes their content more viral as also found by~\cite{mathew2018analyzing}.
\end{itemize}
%

