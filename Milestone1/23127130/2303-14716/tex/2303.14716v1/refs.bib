@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@inproceedings{hessel2018rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Thirty-second AAAI conference on artificial intelligence},
  year={2018}
}

@article{kalashnikov2018qt,
  title={Qt-opt: Scalable deep reinforcement learning for vision-based robotic manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  journal={arXiv preprint arXiv:1806.10293},
  year={2018}
}

@inproceedings{mahmood2018benchmarking,
  title={Benchmarking reinforcement learning algorithms on real-world robots},
  author={Mahmood, A Rupam and Korenkevych, Dmytro and Vasan, Gautham and Ma, William and Bergstra, James},
  booktitle={Conference on robot learning},
  pages={561--591},
  year={2018},
  organization={PMLR}
}

@article{kiran2021deep,
  title={Deep reinforcement learning for autonomous driving: A survey},
  author={Kiran, B Ravi and Sobh, Ibrahim and Talpaert, Victor and Mannion, Patrick and Al Sallab, Ahmad A and Yogamani, Senthil and P{\'e}rez, Patrick},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  year={2021},
  publisher={IEEE}
}

@inproceedings{fujimoto2019off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={International Conference on Machine Learning},
  pages={2052--2062},
  year={2019},
  organization={PMLR}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{kumar2019stabilizing,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:1906.00949},
  year={2019}
}

@article{wu2019behavior,
  title={Behavior regularized offline reinforcement learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@article{kumar2020conservative,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.04779},
  year={2020}
}

@article{yu2020mopo,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={arXiv preprint arXiv:2005.13239},
  year={2020}
}

@article{kidambi2020morel,
  title={Morel: Model-based offline reinforcement learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  journal={arXiv preprint arXiv:2005.05951},
  year={2020}
}

@article{zhou2020plas,
  title={Plas: Latent action space for offline reinforcement learning},
  author={Zhou, Wenxuan and Bajracharya, Sujay and Held, David},
  journal={arXiv preprint arXiv:2011.07213},
  year={2020}
}

@article{charlesworth2020plangan,
  title={Plangan: Model-based planning with sparse rewards and multiple goals},
  author={Charlesworth, Henry and Montana, Giovanni},
  journal={arXiv preprint arXiv:2006.00900},
  year={2020}
}

@article{fu2020d4rl,
  title={D4rl: Datasets for deep data-driven reinforcement learning},
  author={Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.07219},
  year={2020}
}

@article{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  journal={MIT press}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@article{haarnoja2018softauto,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@article{argenson2020model,
  title={Model-based offline planning},
  author={Argenson, Arthur and Dulac-Arnold, Gabriel},
  journal={arXiv preprint arXiv:2008.05556},
  year={2020}
}

@article{zhan2021model,
  title={Model-Based Offline Planning with Trajectory Pruning},
  author={Zhan, Xianyuan and Zhu, Xiangyu and Xu, Haoran},
  journal={arXiv preprint arXiv:2105.07351},
  year={2021}
}

@article{janner2019trust,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  journal={arXiv preprint arXiv:1906.08253},
  year={2019}
}

@inproceedings{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={International Conference on Machine Learning},
  pages={1587--1596},
  year={2018},
  organization={PMLR}
}

@article{lange2012batch,
  title={Batch reinforcement learning},
  author={Lange, Sascha and Gabel, Thomas and Riedmiller, Martin},
  pages={45--73},
  year={2012},
  journal={Springer}
}

@book{camacho2013model,
  title={Model predictive control},
  author={Camacho, Eduardo F and Alba, Carlos Bordons},
  year={2013},
  publisher={Springer science \& business media}
}

@article{chua2018deep,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  journal={arXiv preprint arXiv:1805.12114},
  year={2018}
}

@incollection{botev2013cross,
  title={The cross-entropy method for optimization},
  author={Botev, Zdravko I and Kroese, Dirk P and Rubinstein, Reuven Y and L’Ecuyer, Pierre},
  booktitle={Handbook of statistics},
  volume={31},
  pages={35--59},
  year={2013},
  publisher={Elsevier}
}

@inproceedings{nagabandi2020deep,
  title={Deep dynamics models for learning dexterous manipulation},
  author={Nagabandi, Anusha and Konolige, Kurt and Levine, Sergey and Kumar, Vikash},
  booktitle={Conference on Robot Learning},
  pages={1101--1112},
  year={2020},
  organization={PMLR}
}

@article{williams2015model,
  title={Model predictive path integral control using covariance variable importance sampling},
  author={Williams, Grady and Aldrich, Andrew and Theodorou, Evangelos},
  journal={arXiv preprint arXiv:1509.01149},
  year={2015}
}

@article{lowrey2018plan,
  title={Plan online, learn offline: Efficient learning and exploration via model-based control},
  author={Lowrey, Kendall and Rajeswaran, Aravind and Kakade, Sham and Todorov, Emanuel and Mordatch, Igor},
  journal={arXiv preprint arXiv:1811.01848},
  year={2018}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{sohn2015learning,
  title={Learning structured output representation using deep conditional generative models},
  author={Sohn, Kihyuk and Lee, Honglak and Yan, Xinchen},
  journal={Advances in neural information processing systems},
  volume={28},
  pages={3483--3491},
  year={2015}
}

@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@inproceedings{kostrikov2021offline,
  title={Offline reinforcement learning with fisher divergence critic regularization},
  author={Kostrikov, Ilya and Fergus, Rob and Tompson, Jonathan and Nachum, Ofir},
  booktitle={International Conference on Machine Learning},
  pages={5774--5783},
  year={2021},
  organization={PMLR}
}

@misc{wandb,
title = {Experiment Tracking with Weights and Biases},
year = {2020},
note = {Software available from wandb.com},
url={https://www.wandb.com/},
author = {Biewald, Lukas},
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@article{kostrikov2021offlineIQL,
  title={Offline reinforcement learning with implicit q-learning},
  author={Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.06169},
  year={2021}
}

@article{yu2021combo,
  title={Combo: Conservative offline model-based policy optimization},
  author={Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2102.08363},
  year={2021}
}

@article{schrittwieser2021online,
  title={Online and offline reinforcement learning by planning with a learned model},
  author={Schrittwieser, Julian and Hubert, Thomas and Mandhane, Amol and Barekatain, Mohammadamin and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:2104.06294},
  year={2021}
}

@article{fujimoto2021minimalist,
  title={A Minimalist Approach to Offline Reinforcement Learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={arXiv preprint arXiv:2106.06860},
  year={2021}
}

@article{diehl2021umbrella,
  title={UMBRELLA: Uncertainty-Aware Model-Based Offline Reinforcement Learning Leveraging Planning},
  author={Diehl, Christopher and Sievernich, Timo and Kr{\"u}ger, Martin and Hoffmann, Frank and Bertran, Torsten},
  journal={arXiv preprint arXiv:2111.11097},
  year={2021}
}

@misc{1606.01540,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@inproceedings{atkeson1997robot,
  title={Robot learning from demonstration},
  author={Atkeson, Christopher G and Schaal, Stefan},
  booktitle={ICML},
  volume={97},
  pages={12--20},
  year={1997}
}

@article{ravichandar2020recent,
  title={Recent advances in robot learning from demonstration},
  author={Ravichandar, Harish and Polydoros, Athanasios S and Chernova, Sonia and Billard, Aude},
  journal={Annual review of control, robotics, and autonomous systems},
  volume={3},
  pages={297--330},
  year={2020},
  publisher={Annual Reviews}
}

@inproceedings{nair2018overcoming,
  title={Overcoming exploration in reinforcement learning with demonstrations},
  author={Nair, Ashvin and McGrew, Bob and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={6292--6299},
  year={2018},
  organization={IEEE}
}

@article{nair2020awac,
  title={Awac: Accelerating online reinforcement learning with offline datasets},
  author={Nair, Ashvin and Gupta, Abhishek and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.09359},
  year={2020}
}

@article{goecks2019integrating,
  title={Integrating behavior cloning and reinforcement learning for improved performance in dense and sparse reward environments},
  author={Goecks, Vinicius G and Gremillion, Gregory M and Lawhern, Vernon J and Valasek, John and Waytowich, Nicholas R},
  journal={arXiv preprint arXiv:1910.04281},
  year={2019}
}

@article{zhao2021adaptive,
  title={Adaptive Behavior Cloning Regularization for Stable Offline-to-Online Reinforcement Learning},
  author={Zhao, Yi and Boney, Rinu and Ilin, Alexander and Kannala, Juho and Pajarinen, Joni},
  year={2021}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{brandfonbrener2021offline,
  title={Offline rl without off-policy evaluation},
  author={Brandfonbrener, David and Whitney, Will and Ranganath, Rajesh and Bruna, Joan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={4933--4946},
  year={2021}
}

@article{chen2021decision,
  title={Decision transformer: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={15084--15097},
  year={2021}
}

@article{janner2022planning,
  title={Planning with Diffusion for Flexible Behavior Synthesis},
  author={Janner, Michael and Du, Yilun and Tenenbaum, Joshua B and Levine, Sergey},
  journal={arXiv preprint arXiv:2205.09991},
  year={2022}
}

@Article{RLAutoDriving,
  author={Kiran, B Ravi and Sobh, Ibrahim and Talpaert, Victor and Mannion, Patrick and Sallab, Ahmad A. Al and Yogamani, Senthil and Pérez, Patrick},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Deep Reinforcement Learning for Autonomous Driving: A Survey}, 
  year={2022},
  volume={23},
  number={6},
  pages={4909-4926}}

@article{an2021uncertainty,
  title={Uncertainty-based offline reinforcement learning with diversified q-ensemble},
  author={An, Gaon and Moon, Seungyong and Kim, Jang-Hyun and Song, Hyun Oh},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={7436--7447},
  year={2021}
}

@article{ghasemipour2022so,
  title={Why So Pessimistic? Estimating Uncertainties for Offline RL through Ensembles, and Why Their Independence Matters},
  author={Ghasemipour, Seyed Kamyar Seyed and Gu, Shixiang Shane and Nachum, Ofir},
  journal={arXiv preprint arXiv:2205.13703},
  year={2022}
}

@article{komorowski2018artificial,
  title={The artificial intelligence clinician learns optimal treatment strategies for sepsis in intensive care},
  author={Komorowski, Matthieu and Celi, Leo A and Badawi, Omar and Gordon, Anthony C and Faisal, A Aldo},
  journal={Nature medicine},
  volume={24},
  number={11},
  pages={1716--1720},
  year={2018},
  publisher={Nature Publishing Group US New York}
}

@article{liu2020reinforcement,
  title={Reinforcement learning for clinical decision support in critical care: comprehensive review},
  author={Liu, Siqi and See, Kay Choong and Ngiam, Kee Yuan and Celi, Leo Anthony and Sun, Xingzhi and Feng, Mengling},
  journal={Journal of medical Internet research},
  volume={22},
  number={7},
  pages={e18477},
  year={2020},
  publisher={JMIR Publications Toronto, Canada}
}

@article{yu2021reinforcement,
  title={Reinforcement learning in healthcare: A survey},
  author={Yu, Chao and Liu, Jiming and Nemati, Shamim and Yin, Guosheng},
  journal={ACM Computing Surveys (CSUR)},
  volume={55},
  number={1},
  pages={1--36},
  year={2021},
  publisher={ACM New York, NY}
}

@inproceedings{lee2021sunrise,
  title={Sunrise: A simple unified framework for ensemble learning in deep reinforcement learning},
  author={Lee, Kimin and Laskin, Michael and Srinivas, Aravind and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={6131--6141},
  year={2021},
  organization={PMLR}
}

@article{abdar2021review,
  title={A review of uncertainty quantification in deep learning: Techniques, applications and challenges},
  author={Abdar, Moloud and Pourpanah, Farhad and Hussain, Sadiq and Rezazadegan, Dana and Liu, Li and Ghavamzadeh, Mohammad and Fieguth, Paul and Cao, Xiaochun and Khosravi, Abbas and Acharya, U Rajendra and others},
  journal={Information Fusion},
  volume={76},
  pages={243--297},
  year={2021},
  publisher={Elsevier}
}

@article{ciosek2019better,
  title={Better exploration with optimistic actor critic},
  author={Ciosek, Kamil and Vuong, Quan and Loftin, Robert and Hofmann, Katja},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{chen2017ucb,
  title={Ucb exploration via q-ensembles},
  author={Chen, Richard Y and Sidor, Szymon and Abbeel, Pieter and Schulman, John},
  journal={arXiv preprint arXiv:1706.01502},
  year={2017}
}

@inproceedings{bain1995framework,
  title={A Framework for Behavioural Cloning.},
  author={Bain, Michael and Sammut, Claude},
  booktitle={Machine Intelligence 15},
  pages={103--129},
  year={1995}
}

@article{garrabe2022probabilistic,
  title={Probabilistic design of optimal sequential decision-making algorithms in learning and control},
  author={Garrab{\'e}, {\'E}miland and Russo, Giovanni},
  journal={Annual Reviews in Control},
  year={2022},
  publisher={Elsevier}
}

@article{lee2020addressing,
  title={Addressing Distribution Shift in Online Reinforcement Learning with Offline Datasets},
  author={Lee, Seunghyun and Seo, Younggyo and Lee, Kimin and Abbeel, Pieter and Shin, Jinwoo},
  year={2020}
}

@article{lee2015m,
  title={Why m heads are better than one: Training a diverse ensemble of deep networks},
  author={Lee, Stefan and Purushwalkam, Senthil and Cogswell, Michael and Crandall, David and Batra, Dhruv},
  journal={arXiv preprint arXiv:1511.06314},
  year={2015}
}

@article{havasi2020training,
  title={Training independent subnetworks for robust prediction},
  author={Havasi, Marton and Jenatton, Rodolphe and Fort, Stanislav and Liu, Jeremiah Zhe and Snoek, Jasper and Lakshminarayanan, Balaji and Dai, Andrew M and Tran, Dustin},
  journal={arXiv preprint arXiv:2010.06610},
  year={2020}
}

@article{tesauro1995temporal,
  title={Temporal difference learning and TD-Gammon},
  author={Tesauro, Gerald and others},
  journal={Communications of the ACM},
  volume={38},
  number={3},
  pages={58--68},
  year={1995}
}

@article{buckman2020importance,
  title={The importance of pessimism in fixed-dataset policy optimization},
  author={Buckman, Jacob and Gelada, Carles and Bellemare, Marc G},
  journal={arXiv preprint arXiv:2009.06799},
  year={2020}
}


@article{lakshminarayanan2017simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{royston1982expected,
  title={Expected normal order statistics (exact and approximate)},
  author={Royston, JP and others},
  journal={Journal of the Royal Statistical Society Series C (Applied Statistics)},
  volume={31},
  number={2},
  pages={161--165},
  year={1982},
  publisher={JSTOR}
}

@article{tarasov2022corl,
  title={CORL: Research-oriented Deep Offline Reinforcement Learning Library},
  author={Tarasov, Denis and Nikulin, Alexander and Akimov, Dmitry and Kurenkov, Vladislav and Kolesnikov, Sergey},
  journal={arXiv preprint arXiv:2210.07105},
  year={2022}
}

@article{hullermeier2021aleatoric,
  title={Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods},
  author={H{\"u}llermeier, Eyke and Waegeman, Willem},
  journal={Machine Learning},
  volume={110},
  pages={457--506},
  year={2021},
  publisher={Springer}
}

@inproceedings{eriksson2022sentinel,
  title={SENTINEL: taming uncertainty with ensemble based distributional reinforcement learning},
  author={Eriksson, Hannes and Basu, Debabrota and Alibeigi, Mina and Dimitrakakis, Christos},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={631--640},
  year={2022},
  organization={PMLR}
}

@article{charpentier2022disentangling,
  title={Disentangling Epistemic and Aleatoric Uncertainty in Reinforcement Learning},
  author={Charpentier, Bertrand and Senanayake, Ransalu and Kochenderfer, Mykel and G{\"u}nnemann, Stephan},
  journal={arXiv preprint arXiv:2206.01558},
  year={2022}
}

@article{zhang2023policy,
  title={Policy Expansion for Bridging Offline-to-Online Reinforcement Learning},
  author={Zhang, Haichao and Xu, We and Yu, Haonan},
  journal={arXiv preprint arXiv:2302.00935},
  year={2023}
}

@article{nair2022learning,
  title={Learning on the Job: Self-Rewarding Offline-to-Online Finetuning for Industrial Insertion of Novel Connectors from Vision},
  author={Nair, Ashvin and Zhu, Brian and Narayanan, Gokul and Solowjow, Eugen and Levine, Sergey},
  journal={arXiv preprint arXiv:2210.15206},
  year={2022}
}

@article{ball2023efficient,
  title={Efficient Online Reinforcement Learning with Offline Data},
  author={Ball, Philip J and Smith, Laura and Kostrikov, Ilya and Levine, Sergey},
  journal={arXiv preprint arXiv:2302.02948},
  year={2023}
}

@article{zhu2023guiding,
  title={Guiding Online Reinforcement Learning with Action-Free Offline Pretraining},
  author={Zhu, Deyao and Wang, Yuhui and Schmidhuber, J{\"u}rgen and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2301.12876},
  year={2023}
}

@article{xie2021policy,
  title={Policy finetuning: Bridging sample-efficient offline and online reinforcement learning},
  author={Xie, Tengyang and Jiang, Nan and Wang, Huan and Xiong, Caiming and Bai, Yu},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={27395--27407},
  year={2021}
}

@article{zhou2022survey,
  title={A survey on epistemic (model) uncertainty in supervised learning: Recent advances and applications},
  author={Zhou, Xinlei and Liu, Han and Pourpanah, Farhad and Zeng, Tieyong and Wang, Xizhao},
  journal={Neurocomputing},
  volume={489},
  pages={449--465},
  year={2022},
  publisher={Elsevier}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{beeson2022improving,
  title={Improving TD3-BC: Relaxed Policy Constraint for Offline Learning and Stable Online Fine-Tuning},
  author={Beeson, Alex and Montana, Giovanni},
  journal={arXiv preprint arXiv:2211.11802},
  year={2022}
}

}