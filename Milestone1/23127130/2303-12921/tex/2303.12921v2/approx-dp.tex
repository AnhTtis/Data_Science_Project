
\subsection{Reproducibility implies Approximate-DP}

We show that reproducibility implies approximate differential privacy. 
\begin{definition}[($\epsilon, \delta$)-Differential Privacy \cite{TCC:DMNS06}]
	A randomized algorithm $\mathcal{A}: \X^n \rightarrow \mathcal{Y}$ is $(\epsilon, \delta)$-differentially private if for all datasets $S, S' \in \X^n$ differing in at most a single element, and for all measurable $T \subseteq \mathcal{Y}$, we have that 
	$\Pr[\mathcal{A}(S) \in T] \leq e^{\epsilon}\Pr[\mathcal{A}(S') \in T] + \delta. $
\end{definition}

Intuitively, we can construct a differentially private algorithm $\mathcal{A}'$ as follows. For target privacy parameters $(\epsilon, \delta)$, the algorithm proceeds  as follows. 


\rexnote{The following might be more clear as an algorithm block, with a paragraph explanation (words), rather than longer sentences}
 \begin{enumerate}
\item $\mathcal{A}'$ first draws $m$ samples $S \subset {\cal X}^m$ for $m=kn/\delta^{1/3}$ and $k = 4\log(1/\delta)/\epsilon$, and then draws $k$ random subsamples $S_i$ each of size $n$ from $S$ and a single random string $r$. \label{stp:draws}
\item For each of the $k$ subsamples $S_i$, let $y_i = \mathcal{A}(S_i, r)$. \label{stp:outputs}
\item Let $c$ denote the number of occurrences of a most common output of $\mathcal{A}$ over the $k$ runs, i.e. $c = \max_{y \in \mathcal{Y}}  |\{ i \in \{1, \dots, k\} : y_i = y  \}| $. Let $y^{*}$ be the lexicographically first output of $\mathcal{A}$ that occurs $c$ times over the $k$ runs. 
\item Let $\nu \gets \lap(1/\epsilon)$ and $\hat{c} = c + \nu$. If $\hat{c} > 3k/4 $, $\mathcal{A}'$ returns $y^{*}$. Otherwise, it outputs $\bot$.
\end{enumerate} 

\begin{lemma}[Privacy]
	Let $k = 4\log(1/\delta)/\epsilon$ and $m = kn/\delta^{1/3}$. Let $S \subset \X^m$ be a database of size $m$. Then $\mathcal{A}'(S)$ is $(2\epsilon, \delta(1 + e^{\epsilon}))$-DP. 
\end{lemma}

\begin{proof}
	
	Let $S$ and $S'$ be neighboring datasets and let $x \in S$, $x' \in S'$ be the differing elements. 
	We first argue that $x$ will appear in at most two subsamples at Step~\ref{stp:draws}, except with probability $\delta$. We then show that, conditioned on $x$ appearing in at most two subsamples, $\mathcal{A}'$ is $(2\epsilon, \delta e^{\epsilon})$-DP. 
	
	The probability that $x$ appears more than twice in the $k$ subsamples drawn at Step~\ref{stp:draws} is at most 	
	\begin{align*}
		& 1 - \left(\frac{kn}{m}\right)^2\left(\frac{m-1}{m}\right)^{nk-2} - \frac{kn}{m}\left(\frac{m-1}{m}\right)^{nk-1} - \left(\frac{m-1}{m}\right)^{nk} \\
		& \leq 1 - \left(\frac{kn}{m}\right)^2\left(1 - \frac{nk-2}{m}\right) - \frac{kn}{m}\left(1 - \frac{nk-1}{m}\right) - \left(1 - \frac{nk}{m}\right) \\
		& \leq \left(\frac{kn}{m}\right)^3.
	\end{align*}
	We took $m = kn/\delta^{1/3}$, and so $x$ appears in more than 2 subsamples with probability no more than $\delta$.
	
	Conditioning on $x$ appearing in no more than two subsamples, swapping out $x$ for $x'$ will change at most two of the outputs of $\mathcal{A}$ produced at Step~\ref{stp:outputs}. We now show that we can use the propose-test-release framework of Dwork and Lei~\cite{ACM:DworkLei09} to privately release a most common output in this case. 
	Let $Y, Y'$ denote the set of outputs produced at Step 2 by $\mathcal{A}'(S)$ and $\mathcal{A}'(S')$ respectively. Let $c, c'$ denote the counts of a most common element of $Y$ and $Y'$ respectively, and note that $|c - c'| \leq 2$. 
	
	In the case that $c > k/2 + 2$, we know that the most common elements of $Y$ and $Y'$ must be the same, since $|Y| = k$ and the sets differ in at most two elements. In this case, if $\mathcal{A}'(S) \neq \bot$ and $\mathcal{A}'(S') \neq \bot$, $\mathcal{A}'(S) = \mathcal{A}'(S')$. 
	In the case that $c \leq k/2 + 2$, we have that $\mathcal{A}'(S) = \bot$ except when $\nu > \log(1/\delta)/\epsilon - 2$, which occurs with probability $\delta e^{\epsilon}/2$. Finally, we have that for all values of $c$,
	\begin{align*}
		\Pr[\mathcal{A}'(S) = \bot] &
		= \Pr_{\nu \sim Lap(1/\epsilon)}[\hat{c} \leq \log(1/\delta)/\epsilon+ k/2 : \hat{c} = c + \nu]\\
		& \leq e^{2\epsilon}\Pr_{\nu \sim Lap(1/\epsilon)}[\hat{c} + 2 \leq \log(1/\delta)/\epsilon + k/2 : \hat{c} = c + \nu] \\
		& \leq e^{2\epsilon}\Pr_{\nu \sim Lap(1/\epsilon)}[\hat{c}'  \leq \log(1/\delta)/\epsilon + k/2 : \hat{c}' = c' + \nu] \\
		& = e^{2\epsilon}\Pr[\mathcal{A}'(S') = \bot] .
	\end{align*}
	It follows for all measurable $T$ that \maxh{Maybe add explicit bound on $\Pr[\mathcal{A}'(S) \in T \cap \mathcal{Y}]$ so this is easier to follow? Could put before you start analyzing $\bot$ case.}
	\begin{align*}
		\Pr[\mathcal{A}'(S) \in T] 
		&= \Pr[\mathcal{A}'(S) \in T \cap \bot] + \Pr[\mathcal{A}'(S) \in T \cap \mathcal{Y}] \\
		& \leq e^{2\epsilon}\Pr[\mathcal{A}'(S')\in T] + \delta e^{\epsilon}
	\end{align*}
	and so $\mathcal{A}'$ is $(2\epsilon, \delta e^{\epsilon})$-DP, conditioned on $x$ appearing in at most two subsamples. This happens except with probability $\delta$ over the internal randomness of $\mathcal{A}'$, and so $\mathcal{A}'$ satisfies $(2\epsilon, \delta(1 + e^{\epsilon}))$-DP.
	
\end{proof}

\begin{lemma}[Correctness]
	Let $\mathcal{A}$ be a $\rho$-reproducible algorithm with failure rate $\beta$. Then for target privacy parameters $(\epsilon, \delta)$, $\mathcal{A}'$ is correct except with probability $k\rho + 2\delta + \beta$.
\end{lemma}

\begin{proof}
	$\mathcal{A}'$ can be incorrect by either returning $\bot$ or returning a most common output of $\mathcal{A}$ which is incorrect. 
	By construction, $\mathcal{A}'(S) = \bot$ when $\hat{c} \leq \log(1/\delta)/\epsilon + k/2 = 3\log(1/\delta)/epsilon $. From $\rho$-reproducibility of $\mathcal{A}$ and a union bound, we have that $c = k = 4\log(1/\delta)/\epsilon$ except with probability $k\rho$. Because $\nu \sim \lap(1/\epsilon)$, we have $\nu > - \log(1/\delta)/\epsilon $ except with probability $\delta$, and therefore $\mathcal{A}'$ returns $\bot$ with probability at most $k\rho + \delta$. 
	
	It remains to bound the probability that $\mathcal{A}'(S)$ is incorrect and $\mathcal{A}'(S) \neq \bot$.  If $c < k/2$, then $\mathcal{A}'(S) = \bot$ except with probability less than $\delta$, so we have
	\begin{align*}
		\Pr[\mathcal{A}'(S) \text{ incorrect} \wedge \mathcal{A}'(S) \neq \bot]
			& \leq \Pr_{r, \{S_i\}_{i=1}^k}[ | \{i : \mathcal{A}(S_i;r) \text{ is incorrect} \} | \geq k/2 ] + \delta \\
			& \leq \beta + \delta.
	\end{align*}
	Therefore $\mathcal{A}'$ is correct except with probability $k\rho + 2\delta + \beta$.
\end{proof}

\begin{theorem}[Reproducibility implies approximate differential privacy]

Let $\eta, \beta, \delta < 1/2$, let $0 < \epsilon < \log(1/\delta)$, and $\nu < 3/4 - \beta/k$. Let $\mathcal{A}$ be an $(\eta, \nu)$-reproducible algorithm with failure rate $\beta$ and sample complexity $n$. Then there exists an $(\epsilon, \delta)$-DP algorithm for the same problem, with failure rate $2(\beta + \delta)$ and sample complexity $\tilde{O}\left( \frac{n e^{\epsilon }}{\epsilon^3\beta^2(1 - \eta)^2\delta^{1/3}}\right).$
\end{theorem}

\begin{proof}
 Let $\epsilon' = \epsilon/2$, $\delta' = \delta/(1 + e^{\epsilon})$, and $k' = 4\log(1/\delta')/\epsilon'$. 
Using the amplification theorem of \cite{impagliazzo2022reproducibility}, we amplify the $(\eta, \nu)$-reproducibility of $\mathcal{A}$ to a $\rho$-reproducible algorithm, for $\rho = \beta/k'$, and failure rate $\beta + \rho$, using a sample of size
$$m = \frac{ nk'^2\log(1/\beta)^3}{\beta^2(1 - \eta)^2} \in O \left( \frac{n(\epsilon + \log(1/\delta))^2\log(1/\beta)^3}{(\beta\epsilon)^2(1 - \eta)^2} \right).$$

Then running $\mathcal{A}'$ with privacy parameters $\epsilon'$ and $\delta'$ using the amplified $\mathcal{A}$ as a subroutine at Step~\ref{stp:outputs} gives an $(\epsilon, \delta)$-DP algorithm with failure rate less than $2(\beta + \delta)$ and sample complexity 
\begin{align*}
    O\left(\frac{me^{\epsilon}(\epsilon + \log(1/\delta))}{\epsilon \delta^{1/3}} \right) 
    &= O\left(\left( \frac{n(\epsilon + \log(1/\delta))^2\log(1/\beta)^3}{(\beta\epsilon)^2(1 - \eta)^2} \right)\cdot \frac{e^{\epsilon}(\epsilon + \log(1/\delta))}{\epsilon \delta^{1/3}} \right) \\
    & \in \tilde{O}\left( \frac{n e^{\epsilon }}{\epsilon^3\beta^2(1 - \eta)^2\delta^{1/3}}\right).
\end{align*}
where the last inclusion holds for reasonable values of $\epsilon$ and $\delta$. 
\end{proof}
\maxh{It would be nice to include a direct bound on Littlestone dimension as a corollary. It might also be worth looking into the best trade-off between eps and delta here, since $\delta^{1/3}$ (while good enough for lower bound on littlestone) is generically pretty bad and I think just by slightly generalizing the trick above we can do much better. Or at least we should write some remark about the trade-off}