\section{Extensive-form games}
\label{sec-efg}

An extensive-form game is a game played by $N$ players, which can be represented with a rooted tree.
A state of the game corresponds to a node of the tree.
Moving down the tree can be done either with the player's actions or stochastic events (like dealing cards, etc.) and hereafter, such stochastic events will be considered as \textit{chance player}'s actions.
The game ends when a leaf of the tree is reached, and player $i=1,\dots, N$ receives a gain $u_i(z)$ corresponding to the terminal node $z$. 
This paper only deals with two-person zero-sum games. 
That is $N=2$ and $u:=-u_1=u_2$, where $u$ is a loss for player 1 and a gain for player 2.

Let $H_i$ denote the set of nodes where player $i=1,2$ acts.
Partitions of $H_i$ describe the imperfect information of the game.
Such a partition $\mathcal{I}_i$ is called an \textit{information partition}, and each element $I\in\mathcal{I}_i$ (i.e. $I\subset H_i$) is called an \textit{information set}. 
Player $i=1,2$ cannot distinguish between nodes belonging to the same information set. 
The information partition must satisfy the following natural constraint: all nodes belonging to the same information set must have equal sets of legal actions.
Also, in this paper, we only consider games satisfying \textit{perfect recall}, i.e., the information partition is consistent with the assumption that each player can remember their own past actions.
See Figures~\ref{fig-kuhn} and~\ref{fig-leduc} in Appendix~\ref{sec-app-games} for an extensive-form game representation of Kuhn poker and Leduc Hold'em, simplified versions of Texas Hold'em.


Assume that each player $i=1,2$ can choose their actions probabilistically at each information set. 
Let $\pi_i(z)$ be the contribution of player $i=1,2,c$ to the probability of reaching the terminal node $z$ from the root, where $c$ means the chance player.
Let $Z$ be the set of terminal nodes, then the expected value of $u$ is given by
\begin{align}
    \sum_{z\in Z} \pi_1(z)\pi_2(z)\pi_c(z)u(z).
\end{align}
Each player $i=1,2$ aims to make this expectation smaller and larger by controlling $\pi_1$ and $\pi_2$, respectively.
Note that $\pi_c$ is constant.

Now consider the feasible region of $\pi_i$.
Let
\begin{align}
    \Sigma_i := \qty{\emp} \cup \qty{
    (I, a) \mid I\in\mathcal{I}_i, a\in\A(I)
    },
\end{align}
where $\A(I)\ne\emptyset$ is the set of legal actions at information set $I$.
Furthermore, by the assumption of \textit{perfect recall}, we can define the \textit{parent function} $p_i\colon\mathcal{I}_i\to\Sigma_i$ such that $p_i(I) = (I^\prime, a)$ if and only if $I^\prime\in\mathcal{I}_i$ is the last information set visited before $I\in\mathcal{I}_i$ and the action $a\in\A(I^\prime)$ is chosen there, and $p_i(I) = \emp$ if and only if there is no player $i$'s information set that comes before $I\in\mathcal{I}_i$.
We see that the function $p_i$ forms a tree.
That is, for a set of vertices $\Sigma_i\cup\mathcal{I}_i$, the graph with edges from $p_i(I)$ to $I$ for all $I\in\mathcal{I}_i$ and from $I$ to $(I, a)$ for all $I\in\mathcal{I}_i$ and $a\in\A(I)$ is a tree rooted at $\emp$.
See Figures~\ref{fig-kuhnq1},~\ref{fig-kuhnq2}, and~\ref{fig-leducq1} for this \textit{information trees} in each game.

Then let us consider the following convex compact set:
\begin{align}
    Q_i := \qty{
    \bm x\in\R_{\ge 0}^\abs{\Sigma_i}
    \,\middle\vert\,
    x_{\emp} = 1, 
    \ x_{p_i(I)} = \sum_{a\in\A(I)} x_{I,a}
    \ \forall I\in\mathcal{I}_i
    },
    \label{eqn-strategy}
\end{align}
which we call the \textit{strategy set} for player $i$.
Consider mapping $\bm x\in Q_i$ to a probabilistic strategy that chooses action $a\in\A(I)$ at information set $I\in\mathcal{I}_i$ with the following probability:
\begin{align}
\begin{cases}
    x_{I,a} / x_{p_i(I)}, & \text{if } x_{p_i(I)} \ne 0, \\
    1/\abs{\A(I)}, & \text{otherwise},
\end{cases}
\end{align}
which is a sufficient representation of the player $i$'s probabilistic strategy.
Furthermore, the contribution $\pi_i(z)$ is given by $x_{p_i(z)}$
where $p_i(z)$ is a natural extension of the parent function.
That is, $p_i(z) = (I, a)$ if and only if $I\in\mathcal{I}_i$ is the last information set visited before $z\in Z$ and the action $a\in\A(I)$ is chosen there, and $p_i(z) = \emp$ if and only if there is no player $i$'s information set before $z\in Z$.

Therefore, extensive-form games can be written as the following BSPP:
\begin{align}
    \min_{\bm x\in Q_1}\max_{\bm y\in Q_2}
    \sum_{z\in Z} x_{p_1(z)} y_{p_2(z)} \pi_c(z)u(z).
\end{align}
As can be seen from this formulation, the matrix $\bm A$ in BSPP~\eqref{eqn-bspp}, which represents an extensive-form game, has only at most $\abs{\Sigma}$ non-zero elements. In other words, $\bm A$ is sparse in most cases.