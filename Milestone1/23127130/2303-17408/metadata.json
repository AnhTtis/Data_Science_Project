{
    "arxiv_id": "2303.17408",
    "paper_title": "P-Transformer: A Prompt-based Multimodal Transformer Architecture For Medical Tabular Data",
    "authors": [
        "Yucheng Ruan",
        "Xiang Lan",
        "Daniel J. Tan",
        "Hairil Rizal Abdullah",
        "Mengling Feng"
    ],
    "submission_date": "2023-03-30",
    "revised_dates": [
        "2024-01-10"
    ],
    "latest_version": 3,
    "categories": [
        "cs.CL"
    ],
    "abstract": "Medical tabular data, abundant in Electronic Health Records (EHRs), is a valuable resource for diverse medical tasks such as risk prediction. While deep learning approaches, particularly transformer-based models, have shown remarkable performance in tabular data prediction, there are still problems remained for existing work to be effectively adapted into medical domain, such as under-utilization of unstructured free-texts, limited exploration of textual information in structured data, and data corruption. To address these issues, we propose P-Transformer, a Prompt-based multimodal Transformer architecture designed specifically for medical tabular data. This framework consists two critical components: a tabular cell embedding generator and a tabular transformer. The former efficiently encodes diverse modalities from both structured and unstructured tabular data into a harmonized language semantic space with the help of pre-trained sentence encoder and medical prompts. The latter integrates cell representations to generate patient embeddings for various medical tasks. In comprehensive experiments on two real-world datasets for three medical tasks, P-Transformer demonstrated the improvements with 10.9%/11.0% on RMSE/MAE, 0.5%/2.2% on RMSE/MAE, and 1.6%/0.8% on BACC/AUROC compared to state-of-the-art (SOTA) baselines in predictability. Notably, the model exhibited strong resilience to data corruption in the structured data, particularly when the corruption rates are high.",
    "pdf_urls": [
        "http://arxiv.org/pdf/2303.17408v1",
        "http://arxiv.org/pdf/2303.17408v2",
        "http://arxiv.org/pdf/2303.17408v3"
    ],
    "publication_venue": null
}