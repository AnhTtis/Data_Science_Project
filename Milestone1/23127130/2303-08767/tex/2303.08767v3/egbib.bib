%text to image generation model
%gan based
@inproceedings{li2019object,
  title={Object-driven text-to-image synthesis via adversarial training},
  author={Li, Wenbo and Zhang, Pengchuan and Zhang, Lei and Huang, Qiuyuan and He, Xiaodong and Lyu, Siwei and Gao, Jianfeng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12174--12182},
  year={2019}
}


@inproceedings{zhang2018photographic,
  title={Photographic text-to-image synthesis with a hierarchically-nested adversarial network},
  author={Zhang, Zizhao and Xie, Yuanpu and Yang, Lin},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6199--6208},
  year={2018}
}

@article{hinz2020semantic,
  title={Semantic object accuracy for generative text-to-image synthesis},
  author={Hinz, Tobias and Heinrich, Stefan and Wermter, Stefan},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={44},
  number={3},
  pages={1552--1565},
  year={2020},
  publisher={IEEE}
}

@article{li2019controllable,
  title={Controllable text-to-image generation},
  author={Li, Bowen and Qi, Xiaojuan and Lukasiewicz, Thomas and Torr, Philip},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

%image generation other method
%dalle
@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}

%cogview
@article{ding2021cogview,
  title={Cogview: Mastering text-to-image generation via transformers},
  author={Ding, Ming and Yang, Zhuoyi and Hong, Wenyi and Zheng, Wendi and Zhou, Chang and Yin, Da and Lin, Junyang and Zou, Xu and Shao, Zhou and Yang, Hongxia and others},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={19822--19835},
  year={2021}
}


%text-based image generation with diffusion
%imagen
@article{saharia2022photorealistic,
  title={Photorealistic text-to-image diffusion models with deep language understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={36479--36494},
  year={2022}
}

%dalle2
@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}

%glide
@article{nichol2021glide,
  title={Glide: Towards photorealistic image generation and editing with text-guided diffusion models},
  author={Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
  journal={arXiv preprint arXiv:2112.10741},
  year={2021}
}

%image generation with diffusion
@article{dhariwal2021diffusion,
  title={Diffusion models beat gans on image synthesis},
  author={Dhariwal, Prafulla and Nichol, Alexander},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={8780--8794},
  year={2021}
}

@article{song2020score,
  title={Score-based generative modeling through stochastic differential equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  journal={arXiv preprint arXiv:2011.13456},
  year={2020}
}


% imagic
@article{kawar2022imagic,
  title={Imagic: Text-based real image editing with diffusion models},
  author={Kawar, Bahjat and Zada, Shiran and Lang, Oran and Tov, Omer and Chang, Huiwen and Dekel, Tali and Mosseri, Inbar and Irani, Michal},
  journal={arXiv preprint arXiv:2210.09276},
  year={2022}
}

@inproceedings{esser2021taming,
  title={Taming transformers for high-resolution image synthesis},
  author={Esser, Patrick and Rombach, Robin and Ommer, Bjorn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12873--12883},
  year={2021}
}

% textual inversion
@article{gal2022image,
  title={An image is worth one word: Personalizing text-to-image generation using textual inversion},
  author={Gal, Rinon and Alaluf, Yuval and Atzmon, Yuval and Patashnik, Or and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2208.01618},
  year={2022}
}

% DreamBooth
@article{ruiz2022dreambooth,
  title={Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation},
  author={Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir},
  journal={arXiv preprint arXiv:2208.12242},
  year={2022}
}

% CLIP
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

% DiffuseIT
@article{kwon2022diffusion,
  title={Diffusion-based image translation using disentangled style and content representation},
  author={Kwon, Gihyun and Ye, Jong Chul},
  journal={arXiv preprint arXiv:2209.15264},
  year={2022}
}

% prompt-to-prompt
@article{hertz2022prompt,
  title={Prompt-to-prompt image editing with cross attention control},
  author={Hertz, Amir and Mokady, Ron and Tenenbaum, Jay and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2208.01626},
  year={2022}
}

% stable diffusion
@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10684--10695},
  year={2022}
}

% DDPM
@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

% DDIM
@article{song2020denoising,
  title={Denoising diffusion implicit models},
  author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  journal={arXiv preprint arXiv:2010.02502},
  year={2020}
}

% blended diffusion
@inproceedings{avrahami2022blended,
  title={Blended diffusion for text-driven editing of natural images},
  author={Avrahami, Omri and Lischinski, Dani and Fried, Ohad},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18208--18218},
  year={2022}
}

% clipstyler
@inproceedings{kwon2022clipstyler,
  title={Clipstyler: Image style transfer with a single text condition},
  author={Kwon, Gihyun and Ye, Jong Chul},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18062--18071},
  year={2022}
}

% diffusionclip
@inproceedings{kim2022diffusionclip,
  title={DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation},
  author={Kim, Gwanghyun and Kwon, Taesung and Ye, Jong Chul},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2426--2435},
  year={2022}
}

% stylegan-nada
@article{gal2022stylegan,
  title={StyleGAN-NADA: CLIP-guided domain adaptation of image generators},
  author={Gal, Rinon and Patashnik, Or and Maron, Haggai and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel},
  journal={ACM Transactions on Graphics (TOG)},
  volume={41},
  number={4},
  pages={1--13},
  year={2022},
  publisher={ACM New York, NY, USA}
}

% styleclip
@InProceedings{Patashnik_2021_ICCV,
    author    = {Patashnik, Or and Wu, Zongze and Shechtman, Eli and Cohen-Or, Daniel and Lischinski, Dani},
    title     = {StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {2085-2094}
}

%sdedit
@inproceedings{meng2021sdedit,
  title={Sdedit: Guided image synthesis and editing with stochastic differential equations},
  author={Meng, Chenlin and He, Yutong and Song, Yang and Song, Jiaming and Wu, Jiajun and Zhu, Jun-Yan and Ermon, Stefano},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

% ILVR
@InProceedings{Choi_2021_ICCV,
    author    = {Choi, Jooyoung and Kim, Sungwon and Jeong, Yonghyun and Gwon, Youngjune and Yoon, Sungroh},
    title     = {ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {14367-14376}
}

% GANSpace
@article{harkonen2020ganspace,
  title={Ganspace: Discovering interpretable gan controls},
  author={H{\"a}rk{\"o}nen, Erik and Hertzmann, Aaron and Lehtinen, Jaakko and Paris, Sylvain},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9841--9850},
  year={2020}
}

% InterfaceGAN
@article{shen2020interfacegan,
  title={Interfacegan: Interpreting the disentangled face representation learned by gans},
  author={Shen, Yujun and Yang, Ceyuan and Tang, Xiaoou and Zhou, Bolei},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={44},
  number={4},
  pages={2004--2018},
  year={2020},
  publisher={IEEE}
}

@inproceedings{shen2020interpreting,
  title={Interpreting the latent space of gans for semantic face editing},
  author={Shen, Yujun and Gu, Jinjin and Tang, Xiaoou and Zhou, Bolei},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9243--9252},
  year={2020}
}

% styleGAN2
@inproceedings{karras2020analyzing,
  title={Analyzing and improving the image quality of stylegan},
  author={Karras, Tero and Laine, Samuli and Aittala, Miika and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8110--8119},
  year={2020}
}

% AttnGAN
@inproceedings{xu2018attngan,
  title={Attngan: Fine-grained text to image generation with attentional generative adversarial networks},
  author={Xu, Tao and Zhang, Pengchuan and Huang, Qiuyuan and Zhang, Han and Gan, Zhe and Huang, Xiaolei and He, Xiaodong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1316--1324},
  year={2018}
}

@article{ye2021improving,
  title={Improving text-to-image synthesis using contrastive learning},
  author={Ye, Hui and Yang, Xiulong and Takac, Martin and Sunderraman, Rajshekhar and Ji, Shihao},
  journal={arXiv preprint arXiv:2107.02423},
  year={2021}
}

% LAION-5B
@article{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={arXiv preprint arXiv:2210.08402},
  year={2022}
}

%GAN based image generation model
@article{brock2018large,
  title={Large scale GAN training for high fidelity natural image synthesis},
  author={Brock, Andrew and Donahue, Jeff and Simonyan, Karen},
  journal={arXiv preprint arXiv:1809.11096},
  year={2018}
}

@inproceedings{zhang2019self,
  title={Self-attention generative adversarial networks},
  author={Zhang, Han and Goodfellow, Ian and Metaxas, Dimitris and Odena, Augustus},
  booktitle={International conference on machine learning},
  pages={7354--7363},
  year={2019},
  organization={PMLR}
}



%GAN based image editing model
@inproceedings{dong2017semantic,
  title={Semantic image synthesis via adversarial learning},
  author={Dong, Hao and Yu, Simiao and Wu, Chao and Guo, Yike},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={5706--5714},
  year={2017}
}

@article{nam2018text,
  title={Text-adaptive generative adversarial networks: manipulating images with natural language},
  author={Nam, Seonghyeon and Kim, Yunji and Kim, Seon Joo},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}


%pix2pix-zero
@article{parmar2023zero,
  title={Zero-shot image-to-image translation},
  author={Parmar, Gaurav and Singh, Krishna Kumar and Zhang, Richard and Li, Yijun and Lu, Jingwan and Zhu, Jun-Yan},
  journal={arXiv preprint arXiv:2302.03027},
  year={2023}
}

% Improved DDPM
@inproceedings{nichol2021improved,
  title={Improved denoising diffusion probabilistic models},
  author={Nichol, Alexander Quinn and Dhariwal, Prafulla},
  booktitle={International Conference on Machine Learning},
  pages={8162--8171},
  year={2021},
  organization={PMLR}
}

% More control for free
@inproceedings{liu2023more,
  title={More control for free! image synthesis with semantic diffusion guidance},
  author={Liu, Xihui and Park, Dong Huk and Azadi, Samaneh and Zhang, Gong and Chopikyan, Arman and Hu, Yuxiao and Shi, Humphrey and Rohrbach, Anna and Darrell, Trevor},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={289--299},
  year={2023}
}

% Unit-DDPM 
@article{sasaki2021unit,
  title={Unit-ddpm: Unpaired image translation with denoising diffusion probabilistic models},
  author={Sasaki, Hiroshi and Willcocks, Chris G and Breckon, Toby P},
  journal={arXiv preprint arXiv:2104.05358},
  year={2021}
}