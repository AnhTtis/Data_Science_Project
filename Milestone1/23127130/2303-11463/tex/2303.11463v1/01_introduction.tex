\section{Introduction}
As autonomous vehicle technology advances, the need for rapid prototyping and extensive testing is becoming increasingly important, as real driving tests alone are not sufficient to demonstrate safety \cite{Kalra2016}. The use of physics-based simulations allows the study of various scenarios and conditions at a fraction of the cost and risk of physical prototype testing, providing valuable insights into the behaviour and performance of autonomous vehicles in a controlled environment \cite{Schwarz2022}. 

However, one of the main challenges in the development of autonomous driving digital twins is the lack of realism of simulated sensor data and physical models. The so-called \emph{reality gap} can lead to inaccuracies because the virtual world does not adequately generalise all the variations and complexities of the real world \cite{Stocco2022}, \cite{GarciaDaza2022}. Furthermore, despite attempts to generate realistic synthetic behaviours of other road agents (e.g., vehicles, pedestrians, cyclists), simulation lacks empirical knowledge about their behaviour, which negatively affects the gap in behaviour and motion prediction, communication, and human-vehicle interaction \cite{Eady2019}.

%Nevertheless, one major challenge in the development of autonomous driving simulators is the lack of realism in the simulated sensor data and physical models. The so-called "reality gap" can lead to inaccuracies because the virtual world does not reproduce all the variations and complexities of the real world, despite the use of digital twins \cite{Stocco2022}. Furthermore, simulation still lacks empirical knowledge about the behavior of other road users, such as vehicles, pedestrians, and cyclists. This refers not only to their physical behavior and intention prediction, but also to their communication and interactions with autonomous vehicles \cite{Eady2019}.

Including behaviours and interactions from real agents in simulators is one way to reduce the \emph{reality gap} of autonomous driving digital twins. This can be addressed by using real-time immersive virtual reality \cite{CarlaCHIRA}. The immersive integration of real subjects into digital twins allows, on the one hand, human-vehicle interaction studies in fully controlled and safe environments. It allows to include various human-machine interface (HMI) modalities and to explore extreme scenarios without risk to people and vehicle prototypes. On the other hand, it makes it possible to obtain synthetic sequences from multiple viewpoints (i.e., simulated sensors of autonomous vehicles) based on the behaviour of real subjects, which can be used to train and test predictive perception models. However, this approach would only be valid if the behaviour of the subjects in the simulated environment is equivalent to their behaviour in a real environment. This is called the \emph{behavioural gap}, and in order to model it, it is necessary to empirically evaluate the behaviour of the subjects in both real and simulated conditions. 

\begin{figure}
\centerline{\includegraphics[width=0.95\columnwidth]{figures/introduccion_virtual_real.png}}
\caption{Digital twin for human-vehicle interaction in autonomous driving, a comparison between virtual (above) and real (bottom) experiments.}
\label{fig:schematic1}
\end{figure}

%Including behaviors of real agents in simulators is one way to reduce the "reality gap" in autonomous driving simulations. By incorporating the various interactions and behaviors that occur between different agents in the environment, the simulated environment becomes more representative of the real-world. This can help improve the accuracy and robustness of models, as they have been exposed to a greater variety of situations during training. 

In our previous work \cite{CarlaCHIRA}, we presented a framework to enable real-time interaction between real agents and CARLA simulator using immersive virtual reality and human motion capture systems. In this paper, we present the application of this framework to develop a digital twin of a real scenario, and replicate the field experiments carried out in real-world driving conditions \cite{Izquierdo2023} (see Fig. \ref{fig:schematic1}). The experiments are focused in studying human-vehicle interaction in crosswalks through the use of external HMIs and implicit communication based on the motion of the vehicle. We evaluate the effectiveness of different forms of communication between the autonomous vehicle and real pedestrians immersed in a virtual crosswalk scenario, which will then be used to establish a comparison with the same study at a real twin crosswalk and provide a measure of the \emph{behavioural gap}. 

%This paper proposes to incorporate real agents behaviors and real interactions in CARLA autonomous driving simulator \cite{carla2017} by handling immersive virtual reality and human motion capture systems \cite{CarlaCHIRA}. Besides, the measurement of the "reality gap" is proposed through a set of experiments on interaction and communication interfaces replicated identically outside and inside the simulator, as can be seen in Figure \ref{fig:schematic1}. Since the lack of a human driver is changing the nature of the agents interactions \cite{velasco2021will}, autonomous vehicles (AVs) are forced to find ways to communicate their intentions to other road users using all the resources at their disposal. In this work we present the study of the effectiveness of different forms of AV communication with real pedestrians inside a virtual crosswalk, which will then be used to establish a comparison with the same study on a real twin crosswalk and to provide a measure of the simulation-to-reality gap.




\section{Related work}
For simulation-based testing to be a reliable substitute for real-world testing, previous works effort is directed at validating the sensor models used by quantifying the discrepancy between simulation and reality, such \cite{Anthony2021} does for radar perception and \cite{Reway2020} for camera-based object detection algorithms. Other approaches seek to close the \emph{reality gap} by applying feature embedding techniques or different levels of domain randomization \cite{Gadipudi2022}, \cite{Candela2022}. In \cite{Cruz2020} is proposed a method for the real-time generation of realistic images from simulator-rendered images using generative neural networks.

As a novelty with respect to the aforementioned works, our approach intends to close the \emph{reality gap} by inserting real behaviors into simulations through a virtual reality interface. We can find other studies that already incorporate human behavior in simulators using virtual reality, \cite{Xu2022}, \cite{Grasso2020}, which also focus on the particular case of pedestrians and on the analysis of their behavior in interactions with autonomous vehicles \cite{Daofei2022 }, \cite{Hartmann2017}. 
Virtual environments offer a flexible and controlled setting for conducting experiments with multiple types of vehicles and external HMI systems. Consequently, in order to justify the generation of synthetic sequences based on behaviors of real subjects we determine the \emph{behavioral gap} by mean a study of communication between autonomous vehicles and pedestrians, as has been proposed in other works \cite{Chang2017}, \cite{Hollander2019}, \cite{Shuchisnigdha2020}, \cite{Shuchisnigdha2020-2}, \cite{Gruenefeld2019}. 

 We advance in the approach of previous works adding the use of motion capture systems to integrate visual body feedback into the simulation \cite{CarlaCHIRA} and designing a digital twinned environment \cite{Yu2022} to empirically evaluate the \emph{behavioral gap} in a equivalent virtual and real scenario.

%%\cite{Chang2017}, \cite{Nguyen2019}

%%As a novelty with respect to the aforementioned works, our approach is unique to empirically evaluate the \emph{behavioral gap} in simulations when proposing real-time interaction by mean virtual reality in a digital twinned environment. Digital Twin capability enables the virtual representation of the entire system lifecycle, making it a highly suitable tool for conducting autonomous vehicle testing \cite{Yu2022}.

%\cite{Niaz2021}, \cite{Shoukat2022}. \cite{Ge2019}, \cite{Shin2022}, \cite{Liu2022}%%. 