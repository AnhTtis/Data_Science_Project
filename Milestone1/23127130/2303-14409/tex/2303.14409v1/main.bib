
%%% Models

@inproceedings{DeiT,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={International Conference on Machine Learning},
  pages={10347--10357},
  year={2021},
  organization={PMLR}
}

@article{frantar2022gptq,
  title={GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers},
  author={Frantar, Elias and Ashkboos, Saleh and Hoefler, Torsten and Alistarh, Dan},
  journal={arXiv preprint arXiv:2210.17323},
  year={2022}
}

@misc{DeiT3,
  doi = {10.48550/ARXIV.2204.07118},
  url = {https://arxiv.org/abs/2204.07118},
  author = {Touvron, Hugo and Cord, Matthieu and Jégou, Hervé},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {DeiT III: Revenge of the ViT},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}

@inproceedings{van2018inaturalist,
  title={The inaturalist species classification and detection dataset},
  author={Van Horn, Grant and Mac Aodha, Oisin and Song, Yang and Cui, Yin and Sun, Chen and Shepard, Alex and Adam, Hartwig and Perona, Pietro and Belongie, Serge},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8769--8778},
  year={2018}
}

@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16000--16009},
  year={2022}
}

@article{kurtic2023ziplm,
  title={ZipLM: Hardware-Aware Structured Pruning of Language Models},
  author={Kurtic, Eldar and Frantar, Elias and Alistarh, Dan},
  journal={arXiv preprint arXiv:2302.04089},
  year={2023}
}

%%% Datasets

@incollection{fellbaum2010wordnet,
  title={WordNet},
  author={Fellbaum, Christiane},
  booktitle={Theory and applications of ontology: computer applications},
  pages={231--243},
  year={2010},
  publisher={Springer}
}

@article{ILSVRC15,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}

%%% Magnitude pruning
@article{han2015deep,
  title={Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding},
  author={Han, Song and Mao, Huizi and Dally, William J},
  journal={arXiv preprint arXiv:1510.00149},
  year={2015}
}

@inproceedings{
frantar2023optq,
title={{OPTQ}: Accurate Quantization for Generative Pre-trained Transformers},
author={Elias Frantar and Saleh Ashkboos and Torsten Hoefler and Dan Alistarh},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=tcbBPnfwxS}
}

@article{evci2019difficulty,
  title={The difficulty of training sparse neural networks},
  author={Evci, Utku and Pedregosa, Fabian and Gomez, Aidan and Elsen, Erich},
  journal={arXiv preprint arXiv:1906.10732},
  year={2019}
}

@inproceedings{chen2021lottery,
  title={The lottery tickets hypothesis for supervised and self-supervised pre-training in computer vision models},
  author={Chen, Tianlong and Frankle, Jonathan and Chang, Shiyu and Liu, Sijia and Zhang, Yang and Carbin, Michael and Wang, Zhangyang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16306--16316},
  year={2021}
}

%%% 2nd order pruning methods

@article{lecun1989optimal,
  title={Optimal brain damage},
  author={LeCun, Yann and Denker, John and Solla, Sara},
  journal={Advances in neural information processing systems},
  volume={2},
  year={1989}
}

@inproceedings{hassibi1993optimal,
  title={Optimal brain surgeon and general network pruning},
  author={Hassibi, Babak and Stork, David G and Wolff, Gregory J},
  booktitle={IEEE international conference on neural networks},
  pages={293--299},
  year={1993},
  organization={IEEE}
}

@inproceedings{iofinova2022well,
  title={How well do sparse imagenet models transfer?},
  author={Iofinova, Eugenia and Peste, Alexandra and Kurtz, Mark and Alistarh, Dan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12266--12276},
  year={2022}
}

@article{chen2020lottery,
  title={The lottery ticket hypothesis for pre-trained bert networks},
  author={Chen, Tianlong and Frankle, Jonathan and Chang, Shiyu and Liu, Sijia and Zhang, Yang and Wang, Zhangyang and Carbin, Michael},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={15834--15846},
  year={2020}
}

@article{zafrir2021prune,
  title={Prune once for all: Sparse pre-trained language models},
  author={Zafrir, Ofir and Larey, Ariel and Boudoukh, Guy and Shen, Haihao and Wasserblat, Moshe},
  journal={arXiv preprint arXiv:2111.05754},
  year={2021}
}

@inproceedings{nagel2020up,
  title={Up or down? adaptive rounding for post-training quantization},
  author={Nagel, Markus and Amjad, Rana Ali and Van Baalen, Mart and Louizos, Christos and Blankevoort, Tijmen},
  booktitle={International Conference on Machine Learning},
  pages={7197--7206},
  year={2020},
  organization={PMLR}
}

@inproceedings{li2021brecq,
  title={{BRECQ}: Pushing the Limit of Post-Training Quantization by Block Reconstruction},
  author={Li, Yuhang and Gong, Ruihao and Tan, Xu and Yang, Yang and Hu, Peng and Zhang, Qi and Yu, Fengwei and Wang, Wei and Gu, Shi},
  booktitle=ICLR,
  year={2021}
}


@inproceedings{hubara2021accelerated,
  title={Accelerated Sparse Neural Training: A Provable and Efficient Method to find {N:M} Transposable Masks},
  author={Hubara, Itay and Chmiel, Brian and Island, Moshe and Banner, Ron and Naor, Seffi and Soudry, Daniel},
  booktitle=NeurIPS,
  year={2021}
}

@inproceedings{
frantar-obc,
title={Optimal Brain Compression: A Framework for Accurate Post-Training Quantization and Pruning},
author={Elias Frantar and Sidak Pal Singh and Dan Alistarh},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=ksVGCOlOEba}
}

@inproceedings{2017-dong,
  title={Learning to prune deep neural networks via layer-wise optimal brain surgeon},
  author={Dong, Xin and Chen, Shangyu and Pan, Sinno Jialin},
  booktitle={Conference on Neural Information Processing Systems (NeurIPS)},
  year={2017}
}

@article{singh2020woodfisher,
  title={Woodfisher: Efficient second-order approximation for neural network compression},
  author={Singh, Sidak Pal and Alistarh, Dan},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={18098--18109},
  year={2020}
}


@article{M-FAC,
  title={M-FAC: Efficient Matrix-Free Approximations of Second-Order Information},
  author={Frantar, Elias and Kurtic, Eldar and Alistarh, Dan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{kurtic2022optimal,
  title={The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models},
  author={Kurtic, Eldar and Campos, Daniel and Nguyen, Tuan and Frantar, Elias and Kurtz, Mark and Fineran, Benjamin and Goin, Michael and Alistarh, Dan},
  journal={arXiv preprint arXiv:2203.07259},
  year={2022}
}

@misc{sparseGPT,
  doi = {10.48550/ARXIV.2301.00774},
  url = {https://arxiv.org/abs/2301.00774},
  author = {Frantar, Elias and Alistarh, Dan},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}


@article{amari1998natural,
  title={Natural gradient works efficiently in learning},
  author={Amari, Shun-Ichi},
  journal={Neural computation},
  volume={10},
  number={2},
  pages={251--276},
  year={1998},
  publisher={MIT Press}
}

@inproceedings{liu2021group,
  title={Group fisher pruning for practical network compression},
  author={Liu, Liyang and Zhang, Shilong and Kuang, Zhanghui and Zhou, Aojun and Xue, Jing-Hao and Wang, Xinjiang and Chen, Yimin and Yang, Wenming and Liao, Qingmin and Zhang, Wayne},
  booktitle={International Conference on Machine Learning},
  pages={7021--7032},
  year={2021},
  organization={PMLR}
}

@inproceedings{he2019bag,
  title={Bag of tricks for image classification with convolutional neural networks},
  author={He, Tong and Zhang, Zhi and Zhang, Hang and Zhang, Zhongyue and Xie, Junyuan and Li, Mu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={558--567},
  year={2019}
}

@inproceedings{kusupati2020soft,
  title={Soft threshold weight reparameterization for learnable sparsity},
  author={Kusupati, Aditya and Ramanujan, Vivek and Somani, Raghav and Wortsman, Mitchell and Jain, Prateek and Kakade, Sham and Farhadi, Ali},
  booktitle={International Conference on Machine Learning},
  pages={5544--5555},
  year={2020},
  organization={PMLR}
}

@article{renda2020comparing,
  title={Comparing rewinding and fine-tuning in neural network pruning},
  author={Renda, Alex and Frankle, Jonathan and Carbin, Michael},
  journal={arXiv preprint arXiv:2003.02389},
  year={2020}
}

@article{wightman2021resnet,
  title={Resnet strikes back: An improved training procedure in timm},
  author={Wightman, Ross and Touvron, Hugo and J{\'e}gou, Herv{\'e}},
  journal={arXiv preprint arXiv:2110.00476},
  year={2021}
}

@article{frankle2019stabilizing,
  title={Stabilizing the lottery ticket hypothesis},
  author={Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel M and Carbin, Michael},
  journal={arXiv preprint arXiv:1903.01611},
  year={2019}
}

@article{hooker2020characterising,
  title={Characterising bias in compressed models},
  author={Hooker, Sara and Moorosi, Nyalleng and Clark, Gregory and Bengio, Samy and Denton, Emily},
  journal={arXiv preprint arXiv:2010.03058},
  year={2020}
}

@inproceedings{tan2021efficientnetv2,
  title={Efficientnetv2: Smaller models and faster training},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International Conference on Machine Learning},
  pages={10096--10106},
  year={2021},
  organization={PMLR}
}




%%% optimal brain surgeon
@article{lecun1989optimal,
  title={Optimal brain damage},
  author={LeCun, Yann and Denker, John and Solla, Sara},
  journal={Advances in neural information processing systems},
  volume={2},
  year={1989}
}



@article{li2022efficientformer,
  title={EfficientFormer: Vision Transformers at MobileNet Speed},
  author={Li, Yanyu and Yuan, Geng and Wen, Yang and Hu, Eric and Evangelidis, Georgios and Tulyakov, Sergey and Wang, Yanzhi and Ren, Jian},
  journal={arXiv preprint arXiv:2206.01191},
  year={2022}
}


@article{liu2021pay,
  title={Pay attention to mlps},
  author={Liu, Hanxiao and Dai, Zihang and So, David and Le, Quoc V},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={9204--9215},
  year={2021}
}

@article{hoefler2021sparsity,
  title={Sparsity in Deep Learning: Pruning and growth for efficient inference and training in neural networks},
  author={Hoefler, Torsten and Alistarh, Dan and Ben-Nun, Tal and Dryden, Nikoli and Peste, Alexandra},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={241},
  pages={1--124},
  year={2021},
  publisher={MICROTOME PUBL}
}

@inproceedings{hassibi1993optimal,
  title={Optimal brain surgeon and general network pruning},
  author={Hassibi, Babak and Stork, David G and Wolff, Gregory J},
  booktitle={IEEE international conference on neural networks},
  pages={293--299},
  year={1993},
  organization={IEEE}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{zhu2017prune,
  title={To prune, or not to prune: exploring the efficacy of pruning for model compression},
  author={Zhu, Michael and Gupta, Suyog},
  journal={arXiv preprint arXiv:1710.01878},
  year={2017}
}


@article{gale2019state,
  title={The state of sparsity in deep neural networks},
  author={Gale, Trevor and Elsen, Erich and Hooker, Sara},
  journal={arXiv preprint arXiv:1902.09574},
  year={2019}
}

@article{singh2020woodfisher,
  title={Woodfisher: Efficient second-order approximation for neural network compression},
  author={Singh, Sidak Pal and Alistarh, Dan},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={18098--18109},
  year={2020}
}


@article{M-FAC,
  title={M-FAC: Efficient Matrix-Free Approximations of Second-Order Information},
  author={Frantar, Elias and Kurtic, Eldar and Alistarh, Dan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{kurtic2022optimal,
  title={The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models},
  author={Kurtic, Eldar and Campos, Daniel and Nguyen, Tuan and Frantar, Elias and Kurtz, Mark and Fineran, Benjamin and Goin, Michael and Alistarh, Dan},
  journal={arXiv preprint arXiv:2203.07259},
  year={2022}
}

%%% movement pruning
@article{sanh2020movement,
  title={Movement pruning: Adaptive sparsity by fine-tuning},
  author={Sanh, Victor and Wolf, Thomas and Rush, Alexander},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={20378--20389},
  year={2020}
}

%%% sparse training

@inproceedings{evci2020rigging,
  title={Rigging the lottery: Making all tickets winners},
  author={Evci, Utku and Gale, Trevor and Menick, Jacob and Castro, Pablo Samuel and Elsen, Erich},
  booktitle={International Conference on Machine Learning},
  pages={2943--2952},
  year={2020},
  organization={PMLR}
}

@article{mocanu2018scalable,
  title={Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science},
  author={Mocanu, Decebal Constantin and Mocanu, Elena and Stone, Peter and Nguyen, Phuong H and Gibescu, Madeleine and Liotta, Antonio},
  journal={Nature communications},
  volume={9},
  number={1},
  pages={1--12},
  year={2018},
  publisher={Nature Publishing Group}
}

%%% AC/DC 

@article{AC-DC,
  title={Ac/dc: Alternating compressed/decompressed training of deep neural networks},
  author={Peste, Alexandra and Iofinova, Eugenia and Vladu, Adrian and Alistarh, Dan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={8557--8570},
  year={2021}
}

%%% Competitive work

@article{SVIT,
  title={Chasing sparsity in vision transformers: An end-to-end exploration},
  author={Chen, Tianlong and Cheng, Yu and Gan, Zhe and Yuan, Lu and Zhang, Lei and Wang, Zhangyang},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={19974--19988},
  year={2021}
}

@misc{VTP,
  doi = {10.48550/ARXIV.2104.08500},
  url = {https://arxiv.org/abs/2104.08500},
  author = {Zhu, Mingjian and Tang, Yehui and Han, Kai},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Vision Transformer Pruning},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{NViT,
  doi = {10.48550/ARXIV.2110.04869},
  url = {https://arxiv.org/abs/2110.04869},
  author = {Yang, Huanrui and Yin, Hongxu and Molchanov, Pavlo and Li, Hai and Kautz, Jan},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {NViT: Vision Transformer Compression and Parameter Redistribution},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

%%% modern architectures

@inproceedings{ResNet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@misc{BERT,
  doi = {10.48550/ARXIV.1810.04805},
  url = {https://arxiv.org/abs/1810.04805},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{yu2022hessian,
  title={Hessian-aware pruning and optimal neural implant},
  author={Yu, Shixing and Yao, Zhewei and Gholami, Amir and Dong, Zhen and Kim, Sehoon and Mahoney, Michael W and Keutzer, Kurt},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={3880--3891},
  year={2022}
}

@article{gholami2021survey,
  title={A survey of quantization methods for efficient neural network inference},
  author={Gholami, Amir and Kim, Sehoon and Dong, Zhen and Yao, Zhewei and Mahoney, Michael W and Keutzer, Kurt},
  journal={arXiv preprint arXiv:2103.13630},
  year={2021}
}


@inproceedings{wang2019eigendamage,
  title={Eigendamage: Structured pruning in the kronecker-factored eigenbasis},
  author={Wang, Chaoqi and Grosse, Roger and Fidler, Sanja and Zhang, Guodong},
  booktitle={International Conference on Machine Learning},
  pages={6566--6575},
  year={2019},
  organization={PMLR}
}

@inproceedings{yao2021adahessian,
  title={Adahessian: An adaptive second order optimizer for machine learning},
  author={Yao, Zhewei and Gholami, Amir and Shen, Sheng and Mustafa, Mustafa and Keutzer, Kurt and Mahoney, Michael},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={12},
  pages={10665--10673},
  year={2021}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{schuhmann2021laion,
  title={Laion-400m: Open dataset of clip-filtered 400 million image-text pairs},
  author={Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
  journal={arXiv preprint arXiv:2111.02114},
  year={2021}
}

@InProceedings{DINO,
    author    = {Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J\'egou, Herv\'e and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
    title     = {Emerging Properties in Self-Supervised Vision Transformers},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {9650-9660}
}

@misc{ViT,
  doi = {10.48550/ARXIV.2010.11929},
  url = {https://arxiv.org/abs/2010.11929},
  author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{ali2021xcit,
  title={Xcit: Cross-covariance image transformers},
  author={Ali, Alaaeldin and Touvron, Hugo and Caron, Mathilde and Bojanowski, Piotr and Douze, Matthijs and Joulin, Armand and Laptev, Ivan and Neverova, Natalia and Synnaeve, Gabriel and Verbeek, Jakob and others},
  journal={Advances in neural information processing systems},
  volume={34},
  year={2021}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10012--10022},
  year={2021}
}

@misc{MLPMixer,
  doi = {10.48550/ARXIV.2105.01601},
  url = {https://arxiv.org/abs/2105.01601},
  author = {Tolstikhin, Ilya and Houlsby, Neil and Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Unterthiner, Thomas and Yung, Jessica and Steiner, Andreas and Keysers, Daniel and Uszkoreit, Jakob and Lucic, Mario and Dosovitskiy, Alexey},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {MLP-Mixer: An all-MLP Architecture for Vision},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{ResMLP,
  doi = {10.48550/ARXIV.2105.03404},
  url = {https://arxiv.org/abs/2105.03404},
  author = {Touvron, Hugo and Bojanowski, Piotr and Caron, Mathilde and Cord, Matthieu and El-Nouby, Alaaeldin and Grave, Edouard and Izacard, Gautier and Joulin, Armand and Synnaeve, Gabriel and Verbeek, Jakob and Jégou, Hervé},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {ResMLP: Feedforward networks for image classification with data-efficient training},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{gMLP,
  author    = {Hanxiao Liu and
               Zihang Dai and
               David R. So and
               Quoc V. Le},
  title     = {Pay Attention to MLPs},
  journal   = {CoRR},
  volume    = {abs/2105.08050},
  year      = {2021},
  url       = {https://arxiv.org/abs/2105.08050},
  eprinttype = {arXiv},
  eprint    = {2105.08050},
  timestamp = {Tue, 18 May 2021 18:46:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2105-08050.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{DeTR,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European conference on computer vision},
  pages={213--229},
  year={2020},
  organization={Springer}
}

@inproceedings{PVT,
  title={Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={568--578},
  year={2021}
}

@inproceedings{liu2022convnet,
  title={A convnet for the 2020s},
  author={Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11976--11986},
  year={2022}
}


@misc{Tacotron2,
  doi = {10.48550/ARXIV.1809.08895},
  url = {https://arxiv.org/abs/1809.08895},
  author = {Li, Naihan and Liu, Shujie and Liu, Yanqing and Zhao, Sheng and Liu, Ming and Zhou, Ming},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Neural Speech Synthesis with Transformer Network},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{vanderschueren2023straight,
  title={Are Straight-Through gradients and Soft-Thresholding all you need for Sparse Training?},
  author={Vanderschueren, Antoine and De Vleeschouwer, Christophe},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={3808--3817},
  year={2023}
}

@misc{AST,
  doi = {10.48550/ARXIV.2104.01778},
  url = {https://arxiv.org/abs/2104.01778},
  author = {Gong, Yuan and Chung, Yu-An and Glass, James},
  keywords = {Sound (cs.SD), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {AST: Audio Spectrogram Transformer},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}

%%% alternative compression approaches

@misc{evo_vit,
  doi = {10.48550/ARXIV.2108.01390},
  url = {https://arxiv.org/abs/2108.01390},
  author = {Xu, Yifan and Zhang, Zhijie and Zhang, Mengdan and Sheng, Kekai and Li, Ke and Dong, Weiming and Zhang, Liqing and Xu, Changsheng and Sun, Xing},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Evo-ViT: Slow-Fast Token Evolution for Dynamic Vision Transformer},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Zero v1.0 Universal}
}

@article{ia_red,
  title={IA-RED $^{2}$: Interpretability-Aware Redundancy Reduction for Vision Transformers},
  author={Pan, Bowen and Panda, Rameswar and Jiang, Yifan and Wang, Zhangyang and Feris, Rogerio and Oliva, Aude},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={24898--24911},
  year={2021}
}

@misc{how_to_train_your_vit,
  doi = {10.48550/ARXIV.2106.10270},
  url = {https://arxiv.org/abs/2106.10270},
  author = {Steiner, Andreas and Kolesnikov, Alexander and Zhai, Xiaohua and Wightman, Ross and Uszkoreit, Jakob and Beyer, Lucas},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{beit,
  doi = {10.48550/ARXIV.2208.06366},
  url = {https://arxiv.org/abs/2208.06366},
  author = {Peng, Zhiliang and Dong, Li and Bao, Hangbo and Ye, Qixiang and Wei, Furu},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{LTP,
  doi = {10.48550/ARXIV.2107.00910},
  url = {https://arxiv.org/abs/2107.00910},
  author = {Kim, Sehoon and Shen, Sheng and Thorsley, David and Gholami, Amir and Kwon, Woosuk and Hassoun, Joseph and Keutzer, Kurt},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Learned Token Pruning for Transformers},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{cp_vit,
  doi = {10.48550/ARXIV.2203.04570},
  url = {https://arxiv.org/abs/2203.04570},
  author = {Song, Zhuoran and Xu, Yihong and He, Zhezhi and Jiang, Li and Jing, Naifeng and Liang, Xiaoyao},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {CP-ViT: Cascade Vision Transformer Pruning via Progressive Sparsity Prediction},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{dynamic_vit,
  title={Dynamicvit: Efficient vision transformers with dynamic token sparsification},
  author={Rao, Yongming and Zhao, Wenliang and Liu, Benlin and Lu, Jiwen and Zhou, Jie and Hsieh, Cho-Jui},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={13937--13949},
  year={2021}
}

@inproceedings{multi_dimensional_compession_of_vit,
  title={Multi-dimensional model compression of vision transformer},
  author={Hou, Zejiang and Kung, Sun-Yuan},
  booktitle={2022 IEEE International Conference on Multimedia and Expo (ICME)},
  pages={01--06},
  year={2022},
  organization={IEEE}
}

%%% DeepSparse

@InProceedings{
    deepsparse, 
    title = {Inducing and Exploiting Activation Sparsity for Fast Inference on Deep Neural Networks}, 
    author = {Kurtz, Mark and Kopinsky, Justin and Gelashvili, Rati and Matveev, Alexander and Carr, John and Goin, Michael and Leiserson, William and Moore, Sage and Nell, Bill and Shavit, Nir and Alistarh, Dan}, 
    booktitle = {Proceedings of the 37th International Conference on Machine Learning}, 
    pages = {5533--5543}, 
    year = {2020}, 
    editor = {Hal Daumé III and Aarti Singh}, 
    volume = {119}, 
    series = {Proceedings of Machine Learning Research}, 
    address = {Virtual}, 
    month = {13--18 Jul}, 
    publisher = {PMLR}, 
    pdf = {http://proceedings.mlr.press/v119/kurtz20a/kurtz20a.pdf},
    url = {http://proceedings.mlr.press/v119/kurtz20a.html}
}

%%% OBC


% Sparse Regression NP-hard

@article{blumensath2008iterative,
  title={Iterative thresholding for sparse approximations},
  author={Blumensath, Thomas and Davies, Mike E},
  journal={Journal of Fourier Analysis and Applications},
  volume={14},
  number={5-6},
  pages={629--654},
  year={2008},
  publisher={Springer}
}

@inproceedings{2017-dong,
  title={Learning to prune deep neural networks via layer-wise optimal brain surgeon},
  author={Dong, Xin and Chen, Shangyu and Pan, Sinno Jialin},
  booktitle={Conference on Neural Information Processing Systems (NeurIPS)},
  year={2017}
}

%  NVIDIA
@misc{https://doi.org/10.48550/arxiv.2104.08378,
  doi= {10.48550/ARXIV.2104.08378},
  url = {https://arxiv.org/abs/2104.08378},
  author = {Mishra, Asit and Latorre, Jorge Albericio and Pool, Jeff and Stosic, Darko and Stosic, Dusan and Venkatesh, Ganesh and Yu, Chong and Micikevicius, Paulius},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Hardware Architecture (cs.AR), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Accelerating Sparse Deep Neural Networks},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

# SMC

@inproceedings{
anonymous2023sparsity,
title={Sparsity May Cry: Let Us Fail (Current) Sparse Neural Networks Together!},
author={Anonymous},
booktitle={Submitted to The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=J6F3lLg4Kdp},
note={under review}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{talmor2018commonsenseqa,
  title={Commonsenseqa: A question answering challenge targeting commonsense knowledge},
  author={Talmor, Alon and Herzig, Jonathan and Lourie, Nicholas and Berant, Jonathan},
  journal={arXiv preprint arXiv:1811.00937},
  year={2018}
}

% self-distillation

@inproceedings{zhang2019your,
  title={Be your own teacher: Improve the performance of convolutional neural networks via self distillation},
  author={Zhang, Linfeng and Song, Jiebo and Gao, Anni and Chen, Jingwei and Bao, Chenglong and Ma, Kaisheng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3713--3722},
  year={2019}
}

@article{zhang2021self,
  title={Self-distillation: Towards efficient and compact neural networks},
  author={Zhang, Linfeng and Bao, Chenglong and Ma, Kaisheng},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={44},
  number={8},
  pages={4388--4403},
  year={2021},
  publisher={IEEE}
}

% libraries

@misc{robustness,
   title={Robustness (Python Library)},
   author={Logan Engstrom and Andrew Ilyas and Hadi Salman and Shibani Santurkar and Dimitris Tsipras},
   year={2019},
   url={https://github.com/MadryLab/robustness}
}

@inproceedings{kornblith2019better,
  title={Do better imagenet models transfer better?},
  author={Kornblith, Simon and Shlens, Jonathon and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2661--2671},
  year={2019}
}

@inproceedings{beery2018recognition,
  title={Recognition in terra incognita},
  author={Beery, Sara and Van Horn, Grant and Perona, Pietro},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={456--473},
  year={2018}
}

@article{ozkurt2009automatic,
  title={Automatic traffic density estimation and vehicle classification for traffic surveillance systems using neural networks},
  author={Ozkurt, Celil and Camci, Fatih},
  journal={Mathematical and Computational Applications},
  volume={14},
  number={3},
  pages={187--196},
  year={2009},
  publisher={Association for Scientific Research}
}