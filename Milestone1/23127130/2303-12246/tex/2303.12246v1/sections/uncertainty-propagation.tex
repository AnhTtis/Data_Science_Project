%!TEX root = ../main.tex

\section{Geometric Uncertainty Propagation}
\label{sec:uncertainty:propagation}
Conformalizing the heatmaps gives us prediction sets that guarantee probabilistic coverage of the true keypoints. We unify the prediction sets \eqref{eq:icp-ball} and \eqref{eq:icp-ellipse} as
\bea\label{eq:icpunify}
\Feps(x) = \cbrace{\vy \in \calY \mid (y_k - \mu_k)\tran \Lambda_k (y_k - \mu_k) \leq 1,\forall k},
\eea
where $\mu_k = q_{l+1,k}, \Lambda_k = \frac{p_{l+1,k}^2}{\alpha^2_{\pi(\floor{(n+1)\epsilon})}} \eye_2$ for~\eqref{eq:icp-ball}, $\mu_k = \barq_{l+1,k},\Lambda_k = \frac{\Sigma_{l+1,k}\inv}{\alpha_{\pi(\floor{(n+1)\epsilon})}}$ for~\eqref{eq:icp-ellipse}, and we omit the subscript $l+1$ for simplicity.

{\bf Why not uncertainty-aware \pnp}? A popular way to estimate pose from~\eqref{eq:icpunify} is to solve an uncertainty-aware \pnp
\bea \label{eq:uncertainpnp}
\min_{(R,t) \in \SEthree} & \displaystyle \sum_{k=1}^K (y_k - \mu_k)\tran \Lambda_k (y_k - \mu_k) \nonumber \\
\subject & y_k = \Pi(RY_k + t), k=1,\dots,K
\eea
where $Y_k \in \Real{3},k=1,\dots,K$ are the 3D object keypoints and $\Pi(\cdot)$ denotes the camera projection. We challenge this approach and point out its two drawbacks. First, it is difficult to solve~\eqref{eq:uncertainpnp} to global optimality due to (i) the nonconvex $\SEthree$ constraint and (ii) the rational polynomial appearing in $\Pi(\cdot)$. The best known approach to solve \eqref{eq:uncertainpnp} relies on either branch-and-bound~\cite{olsson06icpr-optimal} or local optimization. Second, solving~\eqref{eq:uncertainpnp} typically outputs a \emph{single} optimal pose without uncertainty quantification. Are there other poses that attain similar costs as the optimal pose? How close is the optimal pose to the groundtruth pose? These questions remain not answered in the literature.
% . Lastly, to the best of our knowledge there is no provable reason to believe that the optimal solution of~\eqref{eq:uncertainpnp} is close to the groundtruth. 
% Bounding the error from the optimal pose to the groundtruth pose is critical for downstream decision making, \eg, robust control~\cite{khalil96book-robustcontrol}. 

{\bf Pose UnceRtainty SEt (\purse)}. We propose to, instead of solving a {\pnp} problem similar to~\eqref{eq:uncertainpnp}, directly propagate the uncertainty in the ICP sets to the object pose. 
\begin{proposition}[\purse]\label{prop:purse}
Let $\sgt = [\vectorize{\Rgt}\tran; \tgt\tran]\tran$ be the groundtruth object pose (that lies in front of the camera). Then, the groundtruth keypoints $\vy = (y_1,\dots,y_K)$ belong to the ICP set $\Feps(x)$ in~\eqref{eq:icpunify} if and only if $\sgt$ belongs to the following pose uncertainty set
\begin{equation}\label{eq:purse}
\hspace{-3mm} \Seps = \cbrace{s \in \SEthree \ \middle\vert\ \substack{ \displaystyle s\tran A_k s \leq 0,k=1,\dots,K \\ \displaystyle b_k\tran s > 0, k=1,\dots,K} }, \tag{\purse}
\end{equation} 
where $A_k\in \sym{12}, b_k \in \Real{12},k=1,\dots,K$ are constant matrices dependent on $\mu_k,\Lambda_k,Y_k$ and camera intrinsics.
\end{proposition}
The detailed proof for Proposition~\ref{prop:purse} is algebraically involved and postponed to the Supplementary Material. The high-level intuition is, however, straightforward: we plug in $y_k = \Pi(RY_k + t)$ into \eqref{eq:icpunify} and obtain $K$ quadratic inequalities of the form $s\tran A_k s \leq 0$. The linear inequalities $b_k\tran s > 0$ are added to enforce the (transformed) 3D keypoints lie in front of the camera. Proposition~\ref{prop:purse} implies, if we are $1-\epsilon$ confident the groundtruth keypoints can be anywhere inside $\Feps(x)$, then we should also be confident any pose in~\eqref{eq:purse} can be the groundtruth. Viewing pose estimation as a set estimation with guaranteed probabilistic coverage of the groundtruth is fundamentally different from viewing it as computing a single pose from~\eqref{eq:uncertainpnp} that is (hopefully) close enough to the groundtruth.

{\bf RANdom SAmple averaGing (\ransag)}. Verifying if a given pose belongs to the \purse is straightforward via checking the inequalities in~\eqref{eq:purse}. However, the {\purse} does not directly give us estimated poses. Therefore, we propose an efficient sampling algorithm called \emph{RANdom SAmple averaGing} (\ransag) that is analogous to {\ransac}~\cite{fischler81acm-ransac} and leverages the minimal solver \pthreep~\cite{gao03pami-p3p}, presented in Algorithm~\ref{alg:ransag}.
% \footnote{A naive way to sample from {\purse} is to randomly sample in $\SEthree$ and reject samples that fail the inequalities. This approach has very low success rate because $\SEthree$ is a high-dimensional continuous space (\eg, it is common to sample $1000$ times and get zero valid samples).}
The intuition is that, though it is difficult to sample directly in \purse due to the (nonconvex) constraints, it is easy to sample from the keypoint prediction set~\eqref{eq:icpunify} due to its simple geometry (balls and ellipses). Thus, at each iteration (line~\ref{line:p3piter}) {\ransag} samples three keypoints (line~\ref{line:samplek}-\ref{line:samplekeypoints}), solves the \pthreep inverse problem, and accept the poses that belong to the \eqref{eq:purse} (line~\ref{line:solvep3p}). \ransag typically returns around $100$ valid samples with $T=1000$ trials. However, in difficult cases (\eg, when $\Seps$ is small or even empty) it is possible to obtain zero samples ($S = \emptyset$). In this situation, {\ransag} samples $\floor{T/20}$ (default $50$) poses without checking if they belong to the \purse, via sampling $K$ keypoints and solving \pnp (line~\ref{line:emptyset}-\ref{line:solvepnp}).\footnote{Here we switch from \pthreep to \pnp because \pnp uses all $K$ keypoints and there is less ambiguity in its solution.} After obtaining a set of poses, {\ransag} performs rotation averaging (line~\ref{line:rotavg}) and translation averaging (line~\ref{line:transavg}) to obtain an average pose $\bar{s}$.\footnote{In Algorithm~\ref{alg:ransag} we use rotation averaging with the Chordal distance metric. The user is free to choose other single rotation averaging algorithms with different distance metrics~\cite{hartley13ijcv-rotation}.} Note that {\ransag} does not check if $\bar{s}$ lies in the \purse.

\input{sections/alg-ransag}

{\bf Worst-case error bounds}. To upper bound the errors between the average pose $\bar{s}$ and the groundtruth $(\Rgt,\tgt)$, we maximize the squared \emph{pose-to-\purse} distance:
\begin{equation}\label{eq:pose2purse}
d_{\epsilon,\lambda}^2 = \max_{(R,t) \in \Seps} \lambda \Fnorm{R - \bar{R}}^2 + (1-\lambda) \norm{t - \bar{t}}^2
\end{equation} 
given $\lambda \in [0,1]$. Particularly, we compute two cases $\lambda = 1$ (the maximum rotation distance) and $\lambda = 0$ (the maximum translation distance). Proposition~\ref{prop:purse} states the groundtruth $(\Rgt,\tgt)$ lies in $\Seps$ with $1-\epsilon$ probability, hence
\bea\label{eq:boundRt}
\Fnorm{\bar{R} - \Rgt} \leq d_{\epsilon,1}, \quad \norm{\bar{t} - \tgt} \leq d_{\epsilon,0}
\eea
holds with probability $1-\epsilon$.

{\bf Computing the bounds}. Problem~\eqref{eq:pose2purse} is nonconvex due to the constraints of the \eqref{eq:purse} $\Seps$. 
% Fortunately, thanks to the recent success in applying semidefinite relaxations to solve nonconvex optimization problems in computer vision~\cite{yang22pami-certifiably,briales18cvpr-certifiably,kahl07ijcv-globally}, 
We relax the nonconvex problem~\eqref{eq:pose2purse} into a convex semidefinite program (SDP) and employ off-the-shelf solvers to optimize the SDP~\cite{yang22pami-certifiably,briales18cvpr-certifiably,kahl07ijcv-globally}.\footnote{We omit the technical details and refer the interested reader to \cite[Section 2]{yang22pami-certifiably} for a pragmatic introduction to SDP relaxations. In practice, we use the code provided by~\cite{yang22pami-certifiably} in \url{https://github.com/MIT-SPARK/CertifiablyRobustPerception}, apply a second-order SDP relaxation to~\eqref{eq:pose2purse}, and use MOSEK~\cite{mosek} to solve the SDP (in about 8 seconds). Solving a first-order SDP relaxation of~\eqref{eq:pose2purse} takes about $0.1$ second but yields looser bounds.} Two possible outcomes can happen: (i) the optimal SDP value coincides with the optimal value of~\eqref{eq:pose2purse}. The relaxation is said to be \emph{exact} and one can extract an optimal solution of~\eqref{eq:pose2purse} from the SDP, or (ii) the relaxation is not exact, but the optimal SDP value still provides an \emph{upper bound} for the optimal value of~\eqref{eq:pose2purse}. Therefore, we either exactly compute $d^2_{\epsilon,\lambda}$ or find an upper bound, both can bound the worst-case error (\cf~\eqref{eq:boundRt}).\footnote{The \purse can potentially be empty, leading to infeasibility of problem~\eqref{eq:pose2purse}. In such cases, empirically the SDP solver returns ``\texttt{PRIMAL\_INFEASIBLE}'' (red squares lying on the $y$-axis of Fig.~\ref{fig:coverage-and-bound}).}

% {\bf Summary}. Given the ICP set $\Feps$~\eqref{eq:icpunify}, we first obtain the \eqref{eq:purse} representation $\Seps$. We then use \ransag to compute an average pose $(\bar{R},\bar{t})$, followed by solving the SDP relaxation of the maximum pose-to-\purse distance~\eqref{eq:pose2purse} to bound the worst-case rotation error and translation error as in~\eqref{eq:boundRt}, which holds with a marginal probability $1-\epsilon$.

We end with a remark about computing tighter bounds.
% \begin{remark}[Unknown-but-bounded Noise Estimation]
% Our {\purse} estimation methodology can be connected to early work in control theory on \emph{unknown-but-bounded noise estimation} which pointed out that bounded noise defines a feasible set for the unknown model (\cf \cite[eqs.~(28)-(29)]{milanese91automatica-optimal}). Despite being conceptually elegant, the framework was impractical due to (i) the difficulty to justify the unknown-but-bounded noise assumption, and (ii) the nonconvexity of the feasible set. In this paper we make the framework practical for object pose estimation by (i) using conformal prediction to obtain provably correct unknown-but-bounded noise~\eqref{eq:icpunify}, and (ii) developing {\ransag} to sample from {\purse} and SDP relaxations to compute estimation bounds.
% \end{remark}

\begin{remark}[Best Worst-case Error Bounds]
\label{rmk:bestbound}
\eqref{eq:pose2purse} can be used to bound errors for all possible pose estimators (\eg, from \pnp~\eqref{eq:uncertainpnp}). What is the best estimator that attains the smallest error bounds? This boils down to solving
\bea\label{eq:bestbound}
\min_{(\bar{R},\bar{t}) \in \SEthree} \left[ \max_{(R,t)\in \Seps} \lambda \Fnorm{R - \bar{R}}^2 + (1-\lambda)\norm{t - \bar{t}}^2\right]
\eea
whose solution is known as the \emph{Chebyshev center}~\cite{milanese91automatica-optimal,eldar08sp-minimax} of the \purse $\Seps$. Unfortunately, problem~\eqref{eq:bestbound} is more challenging than~\eqref{eq:pose2purse} and there is no efficient algorithm to solve it to global optimality. In the Supplementary Material, we evaluate the worst-case error bounds for multiple $(\bar{R},\bar{t})$ samples, select the smallest bounds, and compare them with those of the average pose. An interesting future research direction is to explore differentiable optimization~\cite{pineda22neurips-theseus} or bilevel polynomial optimization~\cite{nie17siopt-bilevel} to solve~\eqref{eq:bestbound}.
\end{remark}
\vspace{-4mm}

