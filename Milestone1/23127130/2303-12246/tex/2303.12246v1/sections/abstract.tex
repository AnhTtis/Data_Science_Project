%!TEX root = ../main.tex

\begin{abstract}
\vspace{-4mm}
% Object pose estimation from single images is a long-standing problem in computer vision. 
The two-stage object pose estimation paradigm first detects semantic keypoints on the image and then estimates the 6D pose by minimizing reprojection errors. 
Despite performing well on standard benchmarks, existing techniques offer no {provable guarantees} on the quality and uncertainty of the estimation. 
In this paper, we inject two fundamental changes, namely \emph{conformal keypoint detection} and \emph{geometric uncertainty propagation}, into the two-stage paradigm and propose the first pose estimator that endows an estimation with \emph{provable and computable worst-case error bounds}.
On one hand, conformal keypoint detection applies the statistical machinery of \emph{inductive conformal prediction} to convert 
heuristic keypoint detections into circular or elliptical prediction sets that cover the groundtruth keypoints with a user-specified marginal probability (\eg, $90\%$). Geometric uncertainty propagation, on the other, propagates the geometric constraints on the keypoints to the 6D object pose, leading to a \emph{Pose UnceRtainty SEt (\purse)} that guarantees coverage of the groundtruth pose with the same probability. The {\purse}, however, is a nonconvex set that does not directly lead to estimated poses and uncertainties. Therefore, we develop \emph{RANdom SAmple averaGing (\ransag)} to compute an {average} pose and apply semidefinite relaxation to upper bound the worst-case errors between the average pose and the groundtruth. On the LineMOD Occlusion dataset we demonstrate: (i) the \purse covers the groundtruth with valid probabilities; (ii) the worst-case error bounds provide correct uncertainty quantification; and (iii) the average pose achieves better or similar accuracy as representative methods based on sparse keypoints.
\end{abstract}