\section{related work}
\subsection{graph kernel}
Kernel methods are strong learning algorithms that can be effortlessly used for measuring the similarity between structured objects $x$ and $x’$ with a kernel function $k(x,x’):\rightarrow\langle \varphi\cdot\varphi'\rangle$, as $k$ corresponds to an inner product in Reproducing Kernel Hilbert Space (RKHS)\cite{scholkopf2002learning}. When $x$ and $x’$ are individual graphs, the challenge is to construct a kernel that captures the inherent relevance between graph structures. It is remarkable that R-convolution\cite{haussler1999convolution} is a general framework for handling discrete objects, which key idea is to recursively decompose objects into “atomic” sub-structures and define valid local kernels between them. In fact, most graph kernels have been defined with a similar idea, which focuses on deconstructing two distinct objects and comparing some simpler substructures. 

Graph kernels are generally classified into three broad categories: path/random walk based kernels\cite{gartner2003graph}\cite{borgwardt2005shortest}, subtree based kernels\cite{ramon2003expressivity}\cite{shervashidze2011weisfeiler} and subgraph based kernels\cite{horvath2004cyclic}\cite{yanardag2015deep}. Random Walk Kernels\cite{gartner2003graph} performs random walks on both object graph, and count the number of matching walks. Shortest Path Kernels\cite{borgwardt2005shortest} are not only applicable to a wide range of graphs but computable in polynomial time. When it comes to subtree kernel, the famous Weisfeiler-Lehman subtree kernel\cite{shervashidze2011weisfeiler} belongs to this family. The key idea is to iterate over each vertex and its neighbors in order to create a multiset label and then simply count the co-occurrences of labels in both graphs. Graphlets have been proved to be effective for the intuitive and meaningful characterization of networks at both the global macro-level as well as the local micro-level. Frequently occurring patterns within a network structure, such as motifs and graphlets, have been proved to be effective for intuitive and meaningful characterization of networks at both the global macro-level as well as the local micro-level\cite{ahmed2015icdm}. By using these features, Shervashidze et al.\cite{shervashidze2009efficient} define a kernel based on the distribution of graphlets for unlabeled graphs and proposed an efficient counting algorithm with two theoretically grounded speedup schemes. On this basis, Yanardag et al.\cite{yanardag2015deep} present Deep Graph Kernels, a unified framework to learn latent representations of sub-structures. However, few studies have focused on subgraph-based kernels with discrete node labels, so it is an interesting work to combine topology and semantic information.


\subsection{Sub structures and Cluster expansion}
Numerous studies have shown that network substructures, such as motifs\cite{milo2002network} \cite{shen2002network} and graphlets\cite{ahmed2015icdm}, can be used in the representation of more complex structure. For example, in the field of biochemistry, network motifs have been implicated in signalling\cite{awan2007regulatory} and neuronal activities\cite{varshney2011structural}. In social science, graphlets are widely adopted in sociometric studies\cite{holland1976local} \cite{frank1988triad}. To embark on the analysis of statistical features from the substructures perspective, thermodynamic characterizations such as entropy provide a convenient route to succinctly describe the network statistics\cite{wang2017spin}. 

From a statistical mechanics point of view, networks can be taken analogous to interacting particles systems. On this basis, the cluster expansion provides deep insights into network behavior related to the occurrence of different motifs. The cluster expansion is usually a power series expansion of the partition function and describes the pattern of interactions in a system with a large number of particles. Mayer et al.\cite{salpeter1958mayer} carried out a systematic study of real gases obeying classical statistics. Lee et al.\cite{lee1957many} have explored these ideas in a real-world application. In recent years, several studies have focused on entropy to represent the statistical topology of networks. Zhang et al.\cite{zhang2020graph} find that the motif entropy for financial stock market networks is sensitive to the variance in network structure. Chen et al.\cite{chen2021thermodynamic} present a novel thermodynamically based analysis method for directed networks. Existing research is confined to network motif-based entropy and ignores node-level granularity. Hence they are not accessible to general subgraph-based applications.


The remainder of this paper is organized as follows. In Section 3, we present the detailed process of our Labeled Subgraph Entropy Kernel. In Section 4, we introduce the experimental design and corresponding results. Finally, in section 5, we conclude our method and put forward directions for future work.
