\section{Introduction}
For the past few years, research on learning non-Euclidean space data has become a central topic of pattern recognition. Graphs can describe numerous problems efficiently because of their competence in characterizing structured data in non-Euclidean space. In the field of graph data analysis, graph comparison has been an important branch which has been applied in many areas such as bioinformatics, chemistry, and sociology. Studies on graph comparison have been divided into the following three groups: Set-based approaches, Frequent subgraph mining (FSM), and Graph kernels. Set-based approaches represent a graph as a set of edges and nodes, then measure the similarity between pairs of sets. Despite feasible computational complexity, they neglect the inherent topology information. Frequent subgraph mining algorithms aim to detect subgraphs that occur frequently and select the discriminative subgraphs. Borgelt et.al\cite{borgelt2002mining} present an algorithm to find fragments in a set of molecules that help to discriminate between different classes of activity in a drug discovery context. Deshpande et.al\cite{deshpande2005frequent} classified chemical compounds by considering frequent topological and geometric substructures present in the data set. Unfortunately, their computational complexity scales exponentially with graph size.

Striving for balance between richer information and lower complexity, graph kernels represent an attractive middle ground. The idea of constructing kernels between graphs was first proposed by G{\"a}rtner\cite{gartner2003graph} and extended by Borgwardt \cite{borgwardt2005protein}. Graph kernels not only respect graph topology, but also restrict the computational complexity in polynomial time\cite{shervashidze2009efficient} by switching the problem from the vectorial representation of graph to a representation of similarity\cite{xu2021deep}. Graph kernels are composed of a learning algorithm and the kernel function, which is an asymmetric positive semi-definite function that measures the similarity between examples. With high efficiency in structural data comparing, graph kernels have been applied heavily in fields include bioinformatics\cite{airola2008graph}, chemistry\cite{ralaivola2005graph} and financial data analysis\cite{cui2016p2p}. 

In fact, many of the complex networks that occur in nature can be succinctly described with simple statistical subgraphs\cite{strogatz2001exploring}. For example, researches show that graphlets and motifs perform specific functional roles in a large network structure\cite{milo2002network}. Motifs are recurring patterns that can be used in representation of of complex structure. Indeed, motifs reflect not only the structural properties of a network, but can also capture its functional properties too. Similarly, graphlets are small connected non-isomorphic patterns recurring in real-world networks. Their frequencies are statistically significant in biology data analysis\cite{milenkovic2008uncovering}, protein function prediction \cite{shervashidze2009efficient}, network alignment\cite{milenkovic2010optimal}, and phylogeny\cite{kuchaiev2010topological}. While graphlets have witnessed tremendous success and impact in a variety of domains, there has yet to be an analysis for combining topology and semantic information. Moreover, most of the chemical applications are not only interested in finding frequent graphs but in identifying significant patterns which seldom occur. Thus, it is an interesting work to identify which substructure has the cardinal influence on the graph classification tasks\cite{ramraj2015frequent}.

For the sake of exploring the deep relationship between local property and global feature, tools from statistical mechanics provide a convenient way to characterize the network structure\cite{albert2002statistical}. This task requires an understanding of the basic structural elements constituting the graph and the processes which give rise to them from a microscope point of view\cite{alon2007network}. Zhang et al.\cite{zhang2020graph} uses the motif content and cluster expansion to compute the thermodynamic entropy and conducts numerical experiments which prove that network motifs can be regarded as basic elements with well-defined information processing functions. The cluster expansion is a powerful computational tool that can be used to express the partition function in terms of an approximating series\cite{salpeter1958mayer}. It allows us to write the grand-canonical thermodynamic potential as a convergent perturbation over the interactions between particles. Commencing from the general principles of perturbation theory for particle systems, the cluster expansion allows us to understand complex systems of interactions in terms of the motif in a diagrammatic expansion of the partition function. Existing graph cluster expansion applications are based on motif and ignore the node-level (semantic) information, so it is necessary to improve the process with more comprehensive statistical element.

In this paper, we propose a entropy-based graph kernel method, the main contributions of this work are threefold. 
\begin{enumerate}[(1)]
    \item We design a breadth-first subgraph mining algorithm with a dynamic programming process, which calculates the number of predetermined labeled structures. Our algorithm achieves lower time complexity when counting subgraphs with large scale.
    \item We re-derived the partition function with the broader term "subgraph" instead of graphlet, then we calculated the global entropy. By considering the labeled subgraph, this statistical variable could reflect the randomness of a graph using both semantic and topology information. 
    \item We propose a novel graph embedding process based on the existing framework of frequent subgraph mining methods. On this basis, we propose the Labeled Subgraph Entropy Kernel (LSEK) to measure the similarity between graphs, and verify the symmetry and positive definitiveness of LSEK.
\end{enumerate}

Our subgraph entropy kernel is performed in multiple types of application scenarios, such as biology and financial dataset. The qualitative experiment results show that our method has a powerful capacity in extracting implicit structural information in financial networks. The quantitative experiment shows that our kernel outperforms several state-of-the-art graph classification algorithms in real-world biochemistry datasets.


