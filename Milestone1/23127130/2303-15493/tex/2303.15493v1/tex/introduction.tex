3D deep learning on point clouds~\cite{qi2017pointnet,qi2017pointnet++,graham20183d,choy20194d} has been widely adopted in a wide variety of downstream applications including autonomous driving, AR/VR and robotics due to its strong discriminative power and generalization ability. In these applications, real-time interaction and fast response are required to guarantee safety and practicality. 
% However, pioneer neural network directly consuming point clouds~\cite{qi2017pointnet,thomas2019kpconv,xu2019grid,liu2019point} suffers from the heavy storage cost and high latency, and prevents the 3D deep learning models to deploy on scenarios with limited resources. Hence, it is desirable to design a framework for point cloud processing with few parameters and lightweight architectures. 

\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/SSSC_v3.pdf}
    \vspace{-4mm}
    \caption{Demonstration of sparse convolution and the proposed shifted sparse convolution. (a) Sparse convolution only operates when the center of kernel slides over the active sites. (b) Our shifted sparse convolution performs different operations for each group of output channels, which brings more information from the neighbor active sites.}
    \vspace{-2mm}
    \label{fig:SSSC}
\end{figure}

Submanifold sparse convolution (we call it "sparse convolution" for short in the rest of this paper)~\cite{graham20183d} is one of the most popular and basic operator for point cloud analysis, which first voxelizes the point clouds and then applies 3D convolution on the voxels while keeping the same sparsity pattern throughout the layers of the network.
% Considering the success of 2D CNN, a natural solution for point cloud analysis is to voxelize the points and applying convolution on 3D grids. 
% However, as the computataion overhead increases dramatically with the resolution of voxels, 3D CNN can only voxelize point clouds with coarse resolution and suffers from low performance.
% To this end, submanifold sparse convolution (we call it "sparse convolution" for short in the rest of this paper)~\cite{graham20183d} was presented that keeps the same sparsity pattern throughout the layers of the network with significantly reduced computational complexity. 
% SSCN~\cite{graham20183d} and MinkowskiNet~\cite{choy20194d} further enhance the accuracy and reduce the FLOPs of sparse convolution by designing more efficient architectures. Despite the success in network design for 3D scene understanding, the current approaches still have huge space for efficiency improvement such as employing network binarization. 
Sparse convolution is widely adopted in most state-of-the-art architectures for point cloud analysis and so it is desirable to further improve its efficiency for more practical application. 
We opt for architecture-agnostic methods such as employing network binarization to achieve this goal. 
Binarized neural networks~\cite{liu2020react,wang2021learning} restrict the bitwidth of weights and activations to only one bit and substitute the multiplication-addition by xnor-bitcount operations, which decreases the storage and computational cost by $32\times$ and $64\times$ respectively.
%However, since the sparse convolution operation only activates when the central input in the receptive field is active, which is hard to fully explore the neighbor active sites and results in a low feature redundancy.
We empirically find sparse convolution operation brings larger quantization errors compared to standard convolution, which leads to significant performance degradation when directly applying existing network binarization methods due to the large quantization errors.


%In these applications, safety, real-time interaction and fast response are crucial, which requires the neural networks to process point cloud scenes with high accuracy and low latency. Since PointNet~\cite{qi2017pointnet}, the pioneer neural network which directly consumes point clouds, was proposed, great success has been achieved in both accuracy (e.g.\ PointNet++~\cite{qi2017pointnet}, PointCNN~\cite{li2018pointcnn}, KPConv~\cite{thomas2019kpconv}, SSCN~\cite{graham20183d}, MinkowskiNet~\cite{choy20194d}) and efficiency (e.g.\ Grid-GCN~\cite{xu2019grid}, RandLA-Net~\cite{hu2020randla}, PVCNN~\cite{liu2019point}, SPVCNN~\cite{tang2020searching}, WS$^3$-ConvNet~\cite{lee2021putting}). These works make it possible to directly process point cloud scenes using deep learning approaches in practical applications.

%Despite the success in network design for 3D scene understanding, the current approaches still have huge room for improvement. As in most cases, the computation is usually deployed on resource-constrained edge devices instead of high-performance servers, in which the floating-point operations are too expensive. In the field of image processing (2D vision), model binarization is one of the most effective and widely used approaches to optimize neural networks for better computational and memory usage efficiency. State-of-the-art binarization methods~\cite{liu2020react,wang2021learning} achieve comparable performance with real valued networks in mainstream tasks, while utilize compact binarized parameters and highly efficient bitwise operations to attain the goal of lightweight storage and computation. However, there is far less research on network binarization for 3D vision. Recently, Qin \emph{et al.} proposed BiPointNet, a universal binarization method for PointNet and largely reduced the gap between real valued and binary networks. However, PointNet is too simple to process complicated scenes and its operations like max pooling and point-wise MLP are not adopted in the state-of-the-art architectures such as SSCN and MinkowskiNet, which restricts further application of BiPointNet. To this end, we study the binarization approach for sparse convolution (the term "sparse convolution" refers to submanifold sparse convolution proposed in~\cite{graham20183d}), which is the key to the success of SSCN and MinkowskiNet. %We focus on semantic segmentation in our work, which is the basic and one of the most important task in scene understanding. 
%Not like regular convolution operator, the computation and storage of sparse convolution are restricted to active regions by using spatially sparse representation and GPU hash tables, which saves most of the calculation as the point cloud is only distributed on the surface of objects, not the whole 3D Euclidean space. However, difference in calculation strategies leads to the difference in learned representations and optimization process of the networks. We observed a huge performance degradation when applying previous binarization method on sparse convolutional networks. How to binarize and train sparse convolutional networks is a challenging but significant problem.

In this paper, we present BSC-Net to learn binary sparse convolutional networks for efficient point cloud analysis in resource-exhaustive scenarios. Instead of directly binarizing the weights and activations in sparse convolutional networks, we search the optimal subset of convolution operation that activates the sparse convolution at various locations for binarization.
The acquired convolution patterns significantly reduces the quantization errors in deployment, and achieves remarkable performance enhancement without extra computational cost. 
% More specifically, we first empirically select the beneficial techniques to construct a strong baseline for sparse convolutional network binarization from the recent advances in model quantization. We then propose the shifted sparse convolutional networks whose convolution operations are activated for active sites consistent with the pre-defied locations, and the optimal positions for active site matching across various channels are obtained via differentiable search strategies. Therefore, the quantization errors in the fixed convoltion operations are significantly alleviated by leveraging the shifted sparse convolution with the searched active site matching locations. 
More specifically, we propose the shifted sparse convolutional networks whose convolution operations are activated for active sites consistent with the pre-defied locations, and the optimal positions for active site matching across various channels are obtained via differentiable search strategies. Therefore, the quantization errors in the fixed convoltion operations are significantly alleviated by leveraging the shifted sparse convolution with the searched active site matching locations. 
% Figure \ref{fig:SSSC} demonstrates the comparison between the binary sparse convolutional networks quantized by conventional model binarization methods and our BSC-Net, which shows our shift operation can better explore the neighbor information and reduce the quantization errors. 
Moreover, we empirically select the recently advances that are beneficial for sparse convolution network binarization to construct a strong baseline.
Extensive experimental results on ScanNet and NYU Depth v2 for semantic segmentation of point clouds show that our BSC-Net reduces the operations per second (OPs) by $92.4\%$ with only $3\%$ mIOU degradation.

%In this paper, we propose binary sparse convolution network, namely BSCNet, for efficient and accurate semantic segmentation on point cloud. As sparse convolution operator sacrifices the growing speed of receptive field, especially for small kernel size, the redundancy of features are reduced significantly, which makes sparse convolutional network more sensitive to binarization. Inspired by the observation in~\cite{cai2020rethinking} that large convolutional kernel is more robust to quantization, we propose to derive shifted sparse convolution (SFSC) operations from a $5\times5\times5$ sparse convolution, which has the same amount of computation as a normal $3\times3\times3$ sparse convolution while keeps as much information as possible from the larger receptive field. The derivation is modeled as a searching problem, in which we regard a $5\times5\times5$ sparse convolution as the search space, and learn an optimal assignment for the shift directions in each SFSC layer. We train BSCNet via end-to-end optimization, which is both efficient and robust. Experimental results on NYU Depth v2~\cite{Silberman2012nyu} and ScanNet datasets~\cite{dai2017scannet} show that our BSCNet sizably outperforms the state-of-the-art binary neural networks.
