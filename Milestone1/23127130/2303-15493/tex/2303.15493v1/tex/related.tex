\textbf{Network quantization:} Network quantiztaion has been widely studied in computer vision due to the significant enhancement in storage and computation efficiency. Conventional methods can be divided into two categories including networks in one bit and multiple bits. For the first regard, weights and activations in networks are binarized with extremely high compression ratio. Hubara \emph{et al.}~\cite{hubara2016binarized} and Courbariaux \emph{et al.}~\cite{courbariaux2016binarized} substituted the add-multiplication (MAC) of real-valued models by xnor-bitcount operations, and emplyed the straight-through estimators (STE) to update the network parameters with back-propagation. Rastegari \emph{et al.}~\cite{rastegari2016xnor} further presented scaling factors for weights and activations quantization error minimization. To recover the capacity degradation caused by aggressive quantization, Liu \emph{et al.}~\cite{liu2018bi} added extra shortcut connections between consecutive layers to diversify the feature maps. Bulat \emph{et al.}~\cite{bulat2020bats} modified the search space and strategy with stability regularization for the optimal architecture acquisition of binary networks. Qin \emph{et al.}~\cite{qin2020bipointnet} maximized the information entropy in binary features and leveraged learnable scaling factors for information retention in point cloud analysis. Since increasing the weight and activation bitwidths can significantly enhance the model capability, networks in multiple bits are proposed for better performance. Choi \emph{et al.}~\cite{choi2018pact} optimized the activation clipping threshold to find the right quantization scale. Zhang \emph{et al.}~\cite{zhang2018lq} further searches the optimal quantizer basis and encoding for accurate quantization. Lee \emph{et al.}~\cite{lee2021network} adaptively scaled the gradient element in STE to calibrate the direction of parameter update with minimal discretization errors. However, multi-bit networks still suffers from heavy computational and storage cost. Directly applying existing network binarization methods to submanifold sparse convolution destructs the geometric structure in the scene and degrades the feature informativeness significantly.

\noindent\textbf{Sparse convolution networks:} Increased attention has been paid to 3D deep learning on point cloud in recent years, which is important for autonomous driving, AR/VR and robotics. Due to the unordered property of point cloud data, voxelizing the points and applying convolution on 3D grids is a natural solution~\cite{chang2015shapenet,qi2016volumetric,zhou2018voxelnet}. However, as point cloud only covers the surfaces of objects/scenes and the most space in 3D scans is empty, the dense volumetric representation is inherently inefficient. Moreover, the computational cost and memory requirement both increase cubically with voxel resolution, thus making it infeasible to train a voxel-based model with high-resolution inputs. To handle this problem, sparse convolution~\cite{graham2014spatially,engelcke2017vote3deep} were proposed to restricts computation and storage to “active” sites (i.e.\ voxels which are not empty). However, as convolutional operator will increase the number of active sites with each layer, the feature sparsity is reduced accordingly. To further improve the efficiency of sparse CNNs, Graham \emph{et al.}~\cite{graham20183d} introduced submanifold sparse convolution, which only conducts convolution when the center of kernel slides over active sites and keeps the same level of sparsity throughout the network. This made it practical to train networks with more convolution layers, such as UNet~\cite{ronneberger2015u}, FCN~\cite{long2015fully} and ResNets~\cite{he2016deep}. Choy \emph{et al.}~\cite{choy20194d} proposed Minkowski Engine, which extended submanifold sparse convolution to higher dimensions. 
Tang \emph{et al.}~\cite{tang2020searching} further combined point-based model and sparse CNN to achieve both accurate and efficient 3D perception for large scale scenes. In particular, sparse convolutional networks are able to adopt common deep architectures from 2D vision, which can help standardize deep learning for point cloud, and they are widely utilized in state-of-the-art models for various tasks, such as semantic segmentation~\cite{nekrasov2021mix3d}, object detection~\cite{rukhovich2021fcaf3d,wang2022cagroup3d} and instance segmentation~\cite{liang2021instance,schult2022mask3d,vu2022softgroup}.

\noindent\textbf{Differentiable search:} In order to reduce the search complexity during the exploration process, differentiable search has been widely used in network architecture search~\cite{liu2018darts}, mixed-precision quantization~\cite{cai2020rethinking,wang2022quantformer} and continual learning~\cite{zhang2022continual}. During differentiable search, the superstructure containing all choices as different components is constructed, where the importance weights for each branch is optimized with gradient descent for optimal solution acquisition. Liu \emph{et al.}~\cite{liu2018darts} relaxed the space of network architectures to be continuous, and jointly optimized the branch importance weights and parameters of the hypernet for network architecture search. Cai \emph{et al.}~\cite{cai2020rethinking} assigned different bitwidths to various branches in the supernet for mixed-precision quantization, and chose the bitwidth in the component with the largest importance weight to be the quantization strategy during inference to achieve the optimal accuracy-complexity trade-off. Guan \emph{et al.}~\cite{guan2020differentiable} updated the feature weights through the presented bridge loss which enhanced the knowledge distillation between the students and teachers. In this paper, we extend differentiable search for the discovery of optimal position for active site matching in shifted sparse convolution, where the search cost is significantly reduced for exploration in large space.