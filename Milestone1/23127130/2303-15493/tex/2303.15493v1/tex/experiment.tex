To investigate the performance of the proposed method, we conduct experiments on several indoor scene datasets including NYU Depth v2 (NYUDv2) \cite{Silberman2012nyu} and ScanNet \cite{dai2017scannet}. We first introduce the datasets, evaluation metrics and implementation details, which is followed by a strong baseline designed for binarization of sparse convolution networks. Then we compare our BSC-Net with the state-of-the-art network binarization methods on sparse convolutional networks. Finally we design ablation studies to show the effectiveness and efficiency of the presented BSC-Net.

\begin{table*}[t]
  \centering
  \small
  \caption{The mIoU of binarzed sparse convolutional networks on ScanNet of different baseline techniques, where the UNET architectures are leveraged. The methods from left to right indicate (1) removing all the skip connections; (2) replacing PReLU with Hardtanh; (3) calculating scaling factor for both activations and weights; (4) using STE to approximate the gradient; (5) removing the skip connections for downsampling/upsampling layers; (6) directly training network with binary weights and activations.}\label{tbl:baseline}
  \begin{tabular}{l|c|c|c|c|c|c|c}
  \noalign{\smallskip}
  \hline
  \hline
  Method & Simplify BS & Simplify AF & Modify SF & Simplify GA & Simplify DS/US & Simplify Init. &Full baseline  \\
  \hline
  mIoU (\%) &37.4 &50.5 &46.1 &49.9 & 47.3/48.7 &34.1 &\textbf{51.7}  \\
  %Corresponding real-valued network & 74.3\\
  \hline
  \hline
  \noalign{\smallskip}
  \noalign{\smallskip}
  \end{tabular}
  \vspace{-0.5cm}
\end{table*}

\subsection{Experimental Settings}\label{e1}
\textbf{Datasets and metrics:} We conduct experiments on two indoor datasets including NYU Depth v2 (NYUDv2) \cite{Silberman2012nyu} and ScanNet \cite{dai2017scannet}. NYUDv2 contains 1,449 RGB-D scene images, where 795 images are split for training and 654 images for testing. Following \cite{graham20183d}, we adopt 40-class setting where all pixels are labeled with 40 classes and convert the RGB-D images into 3D point clouds. As the horizontal and vertical directions of spatial dimensions in the RGB-D images are discrete, we voxelize the 3D point clouds to 1cm bins by only discretizing the depth dimension. ScanNet consists of 1513 reconstructed indoor scenes with 21 categories, which are split into 1201 and 312 scenes for training and validation respectively. We adopt two popular settings of ScanNet containing \emph{2cm} voxelization and \emph{5cm} voxelization as done in \cite{choy20194d}.

We report the mean intersection of union (mIoU), mean per-point classification accuracy (mAcc) and overall point-wise classification accuracy (Acc) for NYUDv2. For ScanNet, we report mIoU and mAcc. We use the same calculation method in \cite{liu2020react} to count the binary operations (BOPs) and floating point operations (FLOPs), where the total operations for model computation complexity evaluation is counted by OPs = BOPs/64 + FLOPs. The storage cost are measured by summing the number of real-valued parameters and that of binary numbers divided by $32$.

\noindent\textbf{Implementation details:} Following \cite{graham20183d}, we adopt different network architectures for the various datasets. For NYUDv2, we perform experiments with FCN \cite{long2015fully} networks in different sizes, namely FCN-S (small) and FCN-H (huge). 
%FCN-S has 16 filters in the input layer, and one sparse convolution per level. FCN-H has 24 filters in the input layer, and two sparse convolutions per level. Both networks use eight levels of downsampling. We increase the number of filters in the networks when downsampling: in particular, we add 16 (S) or 24 (H) filters every time we reduce the scale. 
For ScanNet, we leverage the U-Net \cite{ronneberger2015u} architecture in small and huge sizes represented as UNET-S and UNET-H. The small and huge models differ in numbers of filters and sparse convolutional layers per level, which results in capacity variations of point cloud analysis.
%UNET-S has 16 initial filters and one sparse convolution per level. UNET-H has 32 initial filters and two sparse convolution per level. Both networks use six levels of downsampling and upsampling. Each downsampling operation adds 16 (S) or 32 (H) filters, while upsampling operation subtracts the same numbers of filters correspondingly. Downsampling and upsampling are implemented by sparse convolution and deconvolution layers with stride 2. 
%To train the networks, our method uses the 3-stage optimization strategy. 
%For NYUDv2, the initial learning rate and $L2$ weight decay for W4A4, W4A1, W1A1 and W1A1-discrete (when training AutoShift) are ($1e-1$, $1e-4$), ($2e-2$, $1e-5$), ($1e-2$, $0$) and ($1e-3$, $0$) respectively. We use SGD with momentum of 0.9, Nesterov updates to optimize the \emph{network parameters}. The learning rate is decayed by a factor of $e^{-0.02}$ after every epoch. For ScanNet, the initial learning rate and $L2$ weight decay for W4A4, W4A1, W1A1 and W1A1-discrete are ($1e-3$, $0$), ($2e-4$, $1e-5$) ,($1e-4$, $0$) and ($1e-3$, $0$) respectively. We use Adam with a stepwise scheduler to optimize the network parameters. For each stage, we set steps at epochs 60 and 100.
%Different initial learning rate and lr/weight decay are adopted for each stage and dataset. %We use the same method proposed in \cite{wang2019haq} to quantize the weight or activation to 4-bit for initialization.
We use Adam with a stepwise scheduler to optimize the network parameters.
The training hyperparamters are introduced in the supplementary materials in detail. We perform data augmentation by applying random affine transformers to the point cloud.

For our BSC-Net, the shift distance in SFSC operations is set to one and the number of channel groups which employ different shift directions is assigned to $8$. The search space of directions contains shifting to $8$ operations represented by $(\pm1, \pm1, \pm1)$ and staying still without shift. Limiting the search space of shift directions for channel groups in each layer significantly reduces the search difficulty while maintains the exploration capability. We also evaluated two variations of our BSC-Net called BSC-Baseline and BSC-Manual to demonstrate the effectiveness of the presented techniques. BSC-Baseline represents the framework that binarizing the sparse convolutional networks with all beneficial recently advances combined (refer to Section \ref{e2}), and BSC-Manual stands for the network binarization for network consisted of SFSC layers with manually defined shift configurations instead of the searched ones. In BSC-Manual, We set $\frac{1}{2}$ of the channel groups unshifted, $\frac{1}{4}$ shift to $(+1, +1, 0)$ and $\frac{1}{4}$ shift to $(-1, -1, 0)$ for NYUDv2, and $\frac{1}{2}$ of the channel groups unshifted, $\frac{1}{4}$ shift to $(+1, +1, +1)$ and $\frac{1}{4}$ shift to $(-1, -1, -1)$ for ScanNet. BSC-Baseline and BSC-Manual are trained in the same way, while BSC-Net is trained with an additional searching stage first.

\subsection{Strong Baseline}\label{e2}
Since network binarization degrades the performance sizably, techniques for accuracy improvements have been studied in recent works of model quantization. To show the performance improvement comes from our proposed method rather than other tricks, we build a strong baseline for binarizing sparse convolutional networks from the recently advances.
Through the empirical study shown in Table \ref{tbl:baseline}, we discover the beneficial techniques for performance enhancement and list as below.

%  \cite{rastegari2016xnor,bulat2019xnor,qin2020bipointnet,liu2018bi,liu2020react,martinez2020training} (ablation studies are shown in Table \ref{tbl:baseline}):

\noindent\textbf{Block sturcture: }We use the same block structure as ReActNet \cite{liu2020react}, where the operations are ordered as Binarization$\rightarrow$SparseConv$\rightarrow$BatchNorm$\rightarrow$Activation in each basic block.

\noindent\textbf{Activation function: }PReLU \cite{he2016deep,liu2020react} considers the negative inputs with better convergence, and we substitute all ReLU activation layers with PReLU to strengthen the performance.

\noindent\textbf{Scaling factor: }We only calculate the layer-wise scaling factor for weights as demonstrated in \cite{martinez2020training}, which is the mean absolute value offull-precision weights.

\noindent\textbf{Gradient approximation: }A piecewise polynomial function \cite{liu2018bi} is used to approximate the sign function, which acquires more accurate gradient during back propagation.

\noindent\textbf{Downsampling/upsampling: }Following \cite{liu2018bi}, the skip connection for downsampling layer is composed of an average pooling land a real-valued convolutional layer with kernel size $1$. We also verify that an unpooling layer with a full-precision convolution with kernel size $1$ is beneficial in the skip connection for upsampling layer.

\noindent\textbf{Initialization: }We first pretrain the network with full-precision weights and activations for initialization. Then the model with binary weights and activations is trained for binarization.

\begin{table*}[t]
  \setlength{\tabcolsep}{6pt}
  \centering
  \small
  \caption{Semantic segmentation results (\%), model storage cost (M) and computation cost in OPs of different methods on ScanNet validation set. Param.\ means the model storage cost (M). \emph{5cm voxel} and \emph{2cm voxel} refer to different resolutions of the input point cloud after voxelization.}
    \begin{tabular}{c|l|c||c|cc||c|cc}  
      \toprule
      & \multirow{2}{*}{Method} & \multirow{2}{*}{Param.} & \multicolumn{3}{c||}{\textbf{5cm voxel}} & \multicolumn{3}{c}{\textbf{2cm voxel}} \\
      & & & OPs & mIoU & mAcc & OPs & mIoU & mAcc \\ 
      \midrule
      \rowcolor{mygray}
    \cellcolor{white} \multirow{9}{*}{\rotatebox[origin=c]{90}{UNET-S}} & Real valued &4.335 &$1.21\times10^9$ & 65.2 & 73.3 &$5.32\times10^9$ & 68.7 & 78.5 \\
      & XNOR-Net &0.136 &$8.07\times10^7$ &33.3 &38.9 &$3.79\times10^8$ &21.0 &26.1  \\
      & XNOR-Net++ &0.136 &$8.07\times10^7$ &12.6 &15.9 &$3.79\times10^8$ &11.2 &13.7  \\
      & BiPointNet &0.136 &$8.07\times10^7$ &30.1 &36.2 &$3.79\times10^8$ &18.4 &20.7  \\
      & Bi-Real-Net &0.138 &$8.12\times10^7$ &48.3 &56.6 &$3.82\times10^8$ &51.2 &63.3 \\
      %& Real-to-Binary Net & & & & & & & & & \\
      & ReActNet &0.138 &$8.12\times10^7$ &43.6 &50.2 &$3.82\times10^8$ &46.9 &52.9 \\
      & BSC-Baseline &0.139 &$8.12\times10^7$ &51.7 &61.8 &$3.82\times10^8$ &54.9 &65.3 \\
      & BSC-Manual &0.139 &$8.12\times10^7$ &53.2 &63.7 &$3.82\times10^8$ &57.8 &66.6 \\
      & BSC-Net &0.139 &$8.12\times10^7$ &54.4 &65.2 &$3.82\times10^8$ &61.4 &70.4 \\
      \midrule
      \rowcolor{mygray}
    \cellcolor{white} \multirow{9}{*}{\rotatebox[origin=c]{90}{UNET-H}} & Real valued &30.104 &$7.65\times10^{9}$ & 67.6 & 75.1 &$3.38\times10^{10}$ & 71.0 & 79.0 \\
      & XNOR-Net &0.939 &$3.61\times10^{8}$ &46.6 &53.5 &$1.75\times10^{9}$ &34.9 &40.1  \\
      & XNOR-Net++ &0.939 &$3.61\times10^{8}$ &13.3 &16.4 &$1.75\times10^{9}$ &12.8 &16.2 \\
      & BiPointNet &0.939 &$3.61\times10^{8}$ &45.2 &52.4 &$1.75\times10^{9}$ &34.3 &39.8 \\
      & Bi-Real-Net &0.948 &$3.63\times10^{8}$ &53.4 &63.2 &$1.76\times10^{9}$ &57.3 &66.9 \\
      %& Real-to-Binary Net & & & & & & & & & \\
      & ReActNet &0.949 &$3.63\times10^{8}$ &52.2 &59.0 &$1.76\times10^{9}$ &57.1 &67.0 \\
      & BSC-Baseline &0.952 &$3.63\times10^{8}$ &56.0 &65.9 &$1.76\times10^{9}$ &59.3 &68.3 \\
      & BSC-Manual &0.952 &$3.63\times10^{8}$ &59.3 &68.7 &$1.76\times10^{9}$ &62.2 &70.1 \\
      & BSC-Net &0.952 &$3.63\times10^{8}$ &62.2 &70.5 &$1.76\times10^{9}$ &63.9 &71.6 \\
      \bottomrule
    \end{tabular}
  \vspace{-2.0mm}
  \label{tbl:scannet}
\end{table*}

\begin{table}[t]
  \setlength{\tabcolsep}{3pt}
  \centering
  \small
  \caption{Semantic segmentation results (\%), model storage cost (M) and computation cost in OPs of different methods on NYUDv2 test set. Param.\ means the model storage cost (M).}
    \begin{tabular}{c|l|c||c|ccc}  
      \toprule
      & Method & Param. & OPs & mIoU & mAcc & Acc  \\
      \midrule
      \rowcolor{mygray}
    \cellcolor{white} \multirow{9}{*}{\rotatebox[origin=c]{90}{FCN-S}} & Real valued &2.496 &$1.24\times10^9$ & 33.9 & 47.7 & 64.7 \\
      & XNOR-Net &0.108 &$1.72\times10^8$ &22.1 &32.7 &57.3   \\
      & XNOR-Net++ &0.108 &$1.72\times10^8$ &8.5 &13.5 &43.9  \\
      & BiPointNet &0.108 &$1.72\times10^8$ &24.9 &35.7 &59.3  \\
      & Bi-Real-Net &0.110 &$1.75\times10^8$ &27.3 &38.4 &60.0 \\
      %& Real-to-Binary Net & & & \\
      & ReActNet &0.110 &$1.75\times10^8$ &25.4 &36.6 &58.9 \\
      & BSC-Baseline &0.110 &$1.75\times10^8$ &27.8 &39.9 &60.1 \\
      & BSC-Manual &0.110 &$1.75\times10^8$ &28.7 &40.9 &60.2   \\
      & BSC-Net &0.110 &$1.75\times10^8$ &29.7 &42.1 &61.2 \\
      \midrule
      \rowcolor{mygray}
    \cellcolor{white} \multirow{9}{*}{\rotatebox[origin=c]{90}{FCN-H}} & Real valued &10.025 &$4.82\times10^9$ & 36.9 & 50.4 & 67.2 \\
      & XNOR-Net &0.357 &$3.08\times10^8$ &27.1 &38.8 &59.6 \\
      & XNOR-Net++ &0.357 &$3.08\times10^8$ &8.4 &13.6 &43.2 \\
      & BiPointNet &0.357 &$3.08\times10^8$ &28.1 &40.8 &60.1 \\
      & Bi-Real-Net &0.361 &$3.09\times10^8$ &30.4 &41.8 &61.1  \\
      %& Real-to-Binary Net & & & \\
      & ReActNet &0.361 &$3.09\times10^8$ &27.0 &40.1 &58.9 \\
      & BSC-Baseline &0.362 &$3.09\times10^8$ &32.0 &44.4 &63.3 \\
      & BSC-Manual &0.362 &$3.09\times10^8$ &32.5 &45.1 &63.5  \\
      & BSC-Net &0.362 &$3.09\times10^8$ &33.9 &46.2 &64.5 \\
      \bottomrule
    \end{tabular}
  \vspace{-2.0mm}
  \label{tbl:nyu}
\end{table}

\subsection{Comparison with State-of-the-art}\label{e3}
In this section, we compare our method with state-of-the-art binarization methods, including XNOR-Net \cite{rastegari2016xnor}, XNOR-Net++ \cite{bulat2019xnor}, BiPointNet \cite{qin2020bipointnet}, Bi-Real-Net \cite{liu2018bi} and ReActNet \cite{liu2020react}. We also provide the performance of the real valued models for reference. Experiments are conducted on NYUDv2 and ScanNet.

\textbf{Results on NYUDv2:}
Table \ref{tbl:nyu} illustrates the comparison of storage, operations per second (OPs) and semantic segmentation results across several popular network binarization methods and our BSC-Net. Bi-Real-Net performs best among previous methods, which shows the gradient approximation method and the skip connection structure are general and effective in sparse convolutional network binarization. Although BiPointNet is designed for 3D point cloud analysis, it fails to achieve satisfactory performance because the operations such as maxpooling and point-wise MLP used in PointNet are not adopted in sparse convolutional networks. BSC-Baseline outperforms the previous methods by a large margin and its performance is further boosted by the proposed SFSC module, i.e.\ BSC-Manual. When adopting the efficient differentiable search method, BSC-Net achieves the state-of-the-art performance in both architectures of FCN, while the extra computataional overhead is negligible compared to previous methods.Observing the last low in Table \ref{tbl:nyu}, The performance gap between real valued FCN-H and our BSC-Net has even been narrowed to less than 3\%, which shows the great application potentials of our method.


\textbf{Results on ScanNet:}
Different from NYUDv2 in which the point clouds are generated from single RGB-D images, ScanNet provides larger and more complete point cloud scenes via 3D reconstruction. Therefore, we can evaluate our BSC-Net on ScanNet with different resolutions of the input point cloud after voxelization as shown in Table \ref{tbl:scannet}. 
Following \cite{graham20183d}, we evaluate all results three times to address the problem of the number of voxels being greatly smaller than that of points.
Similar to NYUDv2, BSC-Baseline outperforms the previous state-of-the-art. We found the gap between BSC-Baseline and previous methods were larger because the upsampling layer in UNET is implemented by deconvolution, which is more sensitive to binarization than the interpolation used in FCN. In each setting, BSC-Manual gains consistent improvement over BSC-Baseline, and BSC-Net further achieves state-of-the-art performances which proves the effectiveness of differentiable search strategy.
We also noticed that the improvement of BSC-Net over BSC-Baseline on ScanNet is larger than that on NYUDv2, that shows our method can exploit richer geometric information from 3D point clouds than 2.5D depth map.


\subsection{Ablation Study}\label{e4}
We conduct ablation studies to show how different hyperparamters and strategies influence the performance of the proposed BSC-Net. We study the effects of the search space and number of channel group as well as searching strategy in our differentiable search method on the final performance. The experiments are conducted on ScanNet (\emph{5cm} voxelization) using UNET-S.

% \textbf{Performance w.r.t. shift distance: }According to the second row to the fourth row in Table \ref{lr}, large shift length hurts the performance of seriously. For SCSF in $C^1$ and $C^8$ with shift distance two, the performance even falls behind the baseline that leverages the fixed convolution operations in conventional sparse convolutional networks. SFSC operation with large shift distance brings information with low relevance to the current active site in the receptive field, and fails to extract the visual information in point clouds for subsequent analysis.

%From the last three rows, it can be seen that the final performance first increases and then decreases with the ratio of $S$ increasing, which indicates that keeping a proper number of channel groups unshifted can increase the robustness of BSC-Net. %Based on the above findings, the optimal (or near optimal) shift configuration for BSC-Manual is set as: $S(\frac{1}{2})+C^1(\frac{1}{4})+C^8(\frac{1}{4})$.

\textbf{Performance w.r.t. searching hyperparamters:}
In order to reduce the search cost as well as the optimization difficulties, we search the optimal shift strategies for different layers in BSC-Net from a subset of the whole search space, and we also partition the channels into groups which share the same shift strategies. Table \ref{spgn} demonstrates the performance variation for BSC-Net with different search space and group numbers of SFSC operations, where $S$ and $C_k^d$ represent the convolutions staying still and those shifted to the direction of the k-th vertex of a cube.

\begin{table}[t]
  \centering
  \setlength{\tabcolsep}{4pt}
  \caption{The effects of search space and group number in differentiable search method on the final performance.}\label{spgn}
  \vspace{-2mm}
  \small
  \begin{tabular}{lccc}
  \noalign{\smallskip}
  \hline
  \hline
  Search space &Group number \ \  &mIoU(\%) &mAcc(\%)  \\
  \hline
  Baseline: $\{S\}$ &-- &51.7 &61.8 \\
  \hline
  $\{S,C_1,C_8\}$ &8 &53.6 &63.9  \\
  $\{S,C_1,C_4,C_6,C_7\}$ &8 &54.2 &64.9  \\
  \hline
  \multirow{3}*{$\{S,C_1,C_2,C_3,$} &2 &52.9 &63.8  \\
  &4 &53.4 &64.6 \\
  \multirow{2}*{$C_4,C_5,C_6,C_7,C_8\}$}&8 &\textbf{54.4} &\textbf{65.2} \\
  &16 &54.0 &64.5 \\
  %Corresponding real-valued network & 74.3\\
  \hline
  \hline
  \noalign{\smallskip}
  \noalign{\smallskip}
  \end{tabular}
  \vspace{-2mm}
\end{table}

\begin{table}[t]
  \centering
  \setlength{\tabcolsep}{0.6pt}
  \caption{The effects of relaxation and derivation strategy in differentiable search method on the final performance. $^*$ indicates the architecture parameters are frozen.}\label{srtg}
  \vspace{-2mm}
  \small
  \begin{tabular}{cccc}
  \noalign{\smallskip}
  \hline
  \hline
  Relaxation &Derivation \ \  &mIoU(\%) &mAcc(\%)  \\
  \hline
  Random &$D(32,32)\rightarrow D(1,1)$ &51.5 &61.2 \\
  \hline
  \multirow{3}*{Softmax} &$S(32,32)\rightarrow S(1,1)\rightarrow D(1,1)$ &51.8 &62.0 \\
  &$S^*(32,32)\rightarrow S(1,1)\rightarrow D(1,1)$ &52.3 &63.2 \\
  &$S(1,1)\rightarrow D(32,32)\rightarrow D(1,1)$ &53.5 &64.5 \\
  \hline
  \multirow{3}*{Sigmoid} &$S(32,32)\rightarrow S(1,1)\rightarrow D(1,1)$ &52.6 &64.0 \\
  &$S^*(32,32)\rightarrow S(1,1)\rightarrow D(1,1)$ &53.7 &64.7 \\
  &$S(1,1)\rightarrow D(32,32)\rightarrow D(1,1)$ &\textbf{54.4} &\textbf{65.2} \\
  %Corresponding real-valued network & 74.3\\
  \hline
  \hline
  \noalign{\smallskip}
  \noalign{\smallskip}
  \end{tabular}
  \vspace{-2mm}
\end{table}

Observing the third, fourth and seventh rows, we conclude that the mIoU and mAcc of BSC-Net improves as the size of the search space increases. The improvement from search space in size 3 to that in size 5 is much higher than that from size 5 to size 9, which indicates that large search space causes optimization difficulties in differentiable search method and a subset of the whole search space contains the solution near to the optimal one. According to the last four rows in Table \ref{spgn}, the performance achieves the optimal for medium numbers of groups in the differentiable search. Increasing the numbers causes the optimization difficulties due to the large search space, and decreasing the numbers excludes the promising solution due to the channel correlation.

\textbf{Performance w.r.t. searching strategy:}
We further investigate the effects of searching strategy in Table \ref{srtg}, including relaxation method for the binary selector in (\ref{eq3}) and strategy for deriving BSC-Net from the supernet. For softmax relaxation, $\{\pi^\alpha_{ij}\}$ are defined as $\pi^a_{ij}=\frac{{\rm exp}(\alpha_{ij})}{\sum_k{{\rm exp}(\alpha_{ik})}}$, and the confidence constraint in (\ref{eq_c}) is changed to:
\vspace{-2mm}
\begin{equation}
  L_c=-\sum_i^{n_g}{\sum_j^{n_s}{I_{ij}log\pi^a_{ij}}},\ I_{ij}=\begin{cases}
      1, & j=\mathop{\text{argmax}}\limits_{k}\ \pi^a_{ik} \\
      0, & \text{otherwise}
  \end{cases}
  \vspace{-1mm}
\end{equation}
which pushes $\pi^a$ to a one-hot tensor for better derivation. We use $S(W,A)$ and $D(W,A)$ to represent supernet and derived BSC-Net with W-bit weights and A-bit activations.

We first conduct random assignment on the shift directions for each layer and channel group. As shown in the first row, the performance of BSC-Net falls even behind of the baseline, which shows searching or manually designing a proper SFSC configuration is essential for realizing the potential of BSC-Net. The last six rows show that sigmoid relaxation is better than softmax, which is due to softmax will bring competition between different SFSC operations and hurts the performance of supernet. The results also testify the superiority of our derivation strategy.

Notably, we should emphasize that the SFSC operation is proposed for reducing quantization error, which does not work for real-valued networks. We do not observe an obvious change in performance when equipping the real-valued UNET or FCN with SFSC.

\subsection{Visualization Results}\label{e5}
We viusalize the segmentation prediction for different methods in Figure \ref{fig:vis}. Black regions in the ground-truth refer to undefined categories. The predictions of previous methods are discontinuous and they misclassify the shelf as wall or window, while our BSC-Net outputs smooth and accurate predictions. The results in red boxes also provide an intuitive explanation on our method: when binarized, sparse convolutional networks fail to fully explore the neighbor active sites with increased quantization errors and thus predict discontinuous results. On the contrary, BSC-Net better exploits the neighborhood and reduces the quantization error.

\begin{figure}[t]
\centering
\includegraphics[width=1.0\linewidth]{figures/vis_results.pdf}
\vspace{-6mm}
\caption{Visualization results of different methods.}
\label{fig:vis}
\vspace{-4mm}
\end{figure}