\begin{table}
    \small
    \centering
    \scalebox{0.9}{
    \begin{tabular}{@{}l c| c c@{}}
    \toprule
        &  & \multicolumn{2}{c}{\textbf{Expertise required}} \\
        \textbf{Model} &  \textbf{All cases} & \textbf{Yes} & \textbf{No} \\
        \midrule
        a) \modellarge & \textbf{80.7} & \textbf{70.1} & \textbf{86.4} \\
        \hspace{5pt} No self-finetuning & 51.0 & 43.3 & 50.8 \\
        \midrule
        b) \modelsequential & 75.6  & 54.8 & \textbf{86.5} \\
        \hspace{5pt} No self-finetuning  & 35.6 & 36.2 & 35.6 \\
        \midrule
        c) T5$_\text{large}\rightarrow$Task & 59.5 & 35.3 & 70.1 \\
        \hspace{5pt} No self-finetuning & 37.5 & 36.1 & 35.1 \\
        \midrule
        Zero-rule baseline & 24.6 & 29.0 & 20.0 \\
        \bottomrule
    \end{tabular}
    }
    \caption{
        Macro $F_1$ of \model with and without in-domain data during pretraining, on subsets of RadNLI requiring radiology-specific expertise or not.
        The zero-rule baseline always outputs the most common class (for RadNLI, this is `Neither').
        We report macro $F_1$ to account for differing label distributions. Note that T$5_\text{large}\rightarrow$Task is equivalent to \modellarge without in-domain MLM training.}
    \label{tab:radnli_analysis}
\end{table}