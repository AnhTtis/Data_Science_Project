\begin{table}[tbh]
    \small
    \centering
    \scalebox{0.83}{
    \begin{tabular}{@{}lccc@{}}
        \toprule[1.5pt]
        \multicolumn{4}{c}{\textbf{Radiology (Open-I Retrieval)}} \\
        \textbf{Model} & Acc$_{@1}$ & Acc$_{@5}$ & Acc$_{@10}$  \\
        \midrule[0.5pt]
        all-mpnet-base-v2 & 8.3 & 15.1 & 20.2 \\
        + \modellarge\  (no-MLM) & 12.0 & 19.9 & 22.8 \\ 
        + \modellarge  & \textbf{13.3} & \textbf{20.4} & \textbf{25.5} \\
        
        \midrule[1pt]
        
        \multicolumn{4}{c}{\textbf{Biomedicine (MedSTS)}} \\
        \textbf{Model} & $r$ & $\rho$ \\
        \midrule[0.5pt]
        all-mpnet-base-v2 & 72.8 & 64.6 \\
        + \model$_{\text{large}}$  (no-MLM) &  76.4$_{\pm0.04}$ & 67.1$_{\pm0.06}$  \\ 
        + \model$_{\text{large}}$  &  \textbf{76.9}$_{\pm0.00}$ & \textbf{67.9}$_{\pm0.09}$ \\
        \bottomrule[1.5pt]
    \end{tabular}
    }
    \caption{
        Text embedding learning results.
        Starting from a state-of-the-art embedding model (all-mpnet-base-v2), we fine-tune with \model-generated data (indicated by `+').
        Radiology evaluation is retrieval: given the \texttt{impression} section of a report, find the corresponding \texttt{findings} section.
        For biomedicine, we report similarity on MedSTS~\cite{yanshan2020medsts}, where $r$ and $\rho$ refer to Pearson's $r$ and $\rho$ (scaled by 100 for legibility).
    }
    \label{table:text_embeddings}
\end{table}