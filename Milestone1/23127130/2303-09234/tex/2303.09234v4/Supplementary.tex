%%%%%%%%% TITLE
%\section*{Supplementary Material for \texttt{NAISR}}
\renewcommand{\theequation}{S.\arabic{equation}}
\renewcommand{\thefigure}{S.\arabic{figure}}
\renewcommand{\thetable}{S.\arabic{table}}
\renewcommand{\thesection}{S.\arabic{section}}
\captionsetup[figure]{font=small,labelfont=small}
\captionsetup[table]{font=small,labelfont=small}
\section*{\centering{Supplementary Material for \texttt{NAISR}}}
%\AtBeginEnvironment{tabular}{\small}

\section{Related Work}
\label{sec.supp_related_work}
\paragraph{Deep Implicit Functions.}

%Another main advantage of DIF approaches is their flexibility when defining the optimization objective. This is because the implicit shape representation allows for computing shape related variables like higher order derivatives (related to curvatures) with auto-differentiation in a continuous field, which favors smooth and natural zero level set surfaces by focusing on regions with high curvatures~\citep{novello2022exploring, gropp2020implicit, sitzmann2020siren}. 

\begin{comment}
    
DeepSDF~\citep{park2019deepsdf} uses a coordinate based neural network to learn the signed distance function of a shape. Specifically, given any query point $\mathbf{p}=(x, y, z)$, the parameterized implicit function $SDF(\boldsymbol{x})=s: \boldsymbol{x} \in \mathbb{R}^{3}, s \in \mathbb{R}$  maps the point to the signed distance value. to models representing continuous SDF.
Many following works tries to investigate and improve DeepSDF in terms of regularization~\citep{gropp2020implicit}, model design~\citep{sitzmann2020siren}, and optimization~\citep{duan2020curriculum} . 
\end{comment}
    

\paragraph{Point Correspondence.} 
Establishing point correspondences is important to help experts to detect, understand, diagnose, and track diseases. Recently, ImplicitAtlas~\citep{yang2022implicitatlas}, DIF-Net~\citep{deng2021DIF}, DIT~\citep{zheng2021DIT}, and NDF~\citep{sun2022topology} were proposed to capture point correspondence within implicit shape representations. %DIT~\citep{zheng2021DIT} applies an LSTM to obtain smooth deformations, while NDF~\citep{sun2022topology} uses a neural ODE to obtain a smooth, invertible deformation which preserves shape topology. 
Dalca et al.~\citep{dalca2019learning} use templates conditioned on covariates for image registration. However, they did not explore covariate-specific deformations, shape representations or shape transfer. Currently, no continuous shape representation which models the effects of covariates exists. \emph{\texttt{NAISR} provides a model with such capabilities.}

\paragraph{Disentangled Representation Learning.}
Disentangled representation learning (DRL) has been explored in a variety of domains, including computer vision~\citep{shoshan2021gan, ding2020guided, zhang2018unsupervised, zhang2018learning, xu2021learning, yang2020dsm}, natural language processing~\citep{john2018disentangled}, and medical image analysis~\citep{chartsias2019disentangled, bercea2022federated}.
DRL has also emerged in the context of implicit representations as a promising approach for 3D computer vision. By disentangling the underlying factors of variation, such as object shape, orientation, and texture, DRL can facilitate more effective 3D object recognition, reconstruction, and manipulation~\citep{stammer2022interactive, zhang2018unsupervised, zhang2018learning, xu2021learning, yang2020dsm, yang2022neumesh, gao2022get3d, tewari2022disentangled3d}. 

Besides DRL in computer vision, medical data is typically associated with various covariates which should be taken into account during analyses. Taking~\citep{chu2022disentangled} as an example, when observing a tumor's progression, it is difficult to know whether the variation of a tumor's progression is due to time-varying covariates or due to treatment effects. Therefore, being able to disentangle different effects is highly useful for a representation to promote understanding and to be able to quantify the effect of covariates on observations. \emph{\texttt{NAISR} provides a disentangled representation and allows us to capture the shape effects of covariates.}


\begin{comment}

Zhang et al. [60] introduced DRL to the field of gait recognition for the first time, where pose and appearance features of subjects were disentangled from RGB imagery. Although DRL is new in studies on gait, it has been well explored in studies on other biometrics (i.e., face recognition). For example, Tran et al. [45] and Peng et al. [40] disentangled pose variation from face images for pose-invariant face recognition, while Zhao et al. [61] generated age-invariant face features through the disentanglement of age variation.

In contrast with [60], our method avoids the difficulty of the disentanglement of RGB information and gives new meaningful disentangled variables (i.e., identity and covariate features) for silhouette-based gait representation. Compared with DRL in face recognition [45, 40, 61], which requires additional covariate labels (e.g., pose or age labels), 
\end{comment}

\paragraph{Articulated Shapes.}
There is significant research focusing on articulated shapes, mostly on humans~\citep{palafox2021npms, chen2021snarf, tretschk2020patchnets, deng2020nasa}. There is also a line of work on articulated general objects, e.g., A-SDF~\citep{mu2021asdf} and NASAM~\citep{wei2022nasam}. A-SDF~\citep{mu2021asdf} uses articulation as an additional input to control generated shapes, while NASAM~\citep{wei2022nasam} learns the latent space of articulation without articulation as supervision. %Recent work has explored the inverse problem of how to obtain knowledge from visual information with neural field~\citep{hong20223d, hong2021ptr}, i.e. visual reasoning. These works result in implicit shape representations capable of concept grounding.

The aforementioned works on articulated objects assume that each articulation affects a separate object part. This is easy to observe, e.g., the angles of the two legs of a pair of eyeglasses. Hence, although A-SDF~\citep{mu2021asdf} and 3DAttriFlow~\citep{wen20223d} can disentangle  articulations from geometry, they do not disentangle different covariates and their disentanglements are not composable. However, in medical scenarios, covariates often affect shapes in a more entangled and complex way, for example, a shape might simultaneously be influenced by sex, age, and weight. \emph{\texttt{NAISR} allows us to account for such complex covariate interactions.}%have 3D representation is desired to explore the hidden relations between concepts and shapes behind data. 

\paragraph{Explainable Artificial Intelligence.}
The goal of eXplainable Artificial Intelligence (XAI) is to provide human-understanable explanations for decisions and actions of an AI model. Various flavors of XAI exist, including counterfactual inference~\citep{berrevoets2021learning, moraffah2020causal, thiagarajan2020calibrating, chen2022covariate}, attention maps~\citep{zhou2016cvpr, jung2021towards,woo2018cbam}, feature importance~\citep{arik2021tabnet, ribeiro2016should, agarwal2020neural}, and instance retrieval~\citep{Crabbe2021Simplex}.  \texttt{NAISR} is inspired by neural additive models (NAMs)~\citep{agarwal2020neural} which in turn are inspired by generalized additive models (GAMs)~\citep{hastie2017generalized}. NAMs are based on a linear combination of neural networks each attending to a single input feature. \texttt{NAISR} extends this concept to interpretable 3D shape representations. This is significantly more involved as, unlike for NAMs and GAMs, we are no longer dealing with scalar values, but with 3D shapes. \emph{\texttt{NAISR} provides interpretable results by capturing spatial deformations with respect to an estimated atlas shape such that individual covariate effects can be distinguished.}

% Remove page # from the first page of camera-ready.


\section{Dataset}
\label{supp.sec.dataset}
\subsection{Starman Dataset}
\label{subsec.starman_dataset}
\Figref{fig.starmandataset} illustrates how each sample in the dataset is simulated. 5041 shapes from 1000 different starmans are simulated as the training set. 4966 shapes from another 1000 starmans are simulated as a testing set. The number of movements for each individual comes from a uniform distribution $\mathcal{U}_{\{1, ...10\}}$. 


The deformation for arms can be represented as
\begin{equation}
\mathbf{d}_i(\mathbf{p}) = \alpha \cdot exp(-\frac{(\mathbf{p} - \mathbf{c}_i)^T(\mathbf{p} - \mathbf{c}_i)}{2  \sigma^2}) \cdot \mathbf{m}_0\,, i=0,1; \sigma=0.5\,.
\label{eq.starman_deformation_2}
\end{equation}


The deformation for legs can be represented as
\begin{equation}
\mathbf{d}_i(\mathbf{p}) = \beta \cdot exp(-\frac{(\mathbf{p} - \mathbf{c}_i)^T(\mathbf{p} - \mathbf{c}_i)}{2  \sigma^2}) \cdot \mathbf{m}_1\,, i=2,3; \sigma=0.5\,.
\label{eq.starman_deformation_1}
\end{equation}


We sample the covariates $\alpha$ and $\beta$ from a uniform distribution $\mathcal{U}_{[-1,1]}$. The overall deformation $\mathbf{D}$ is the sum of the covariates-controlling deformations $\{\mathbf{d}_i\}$ imposed on the individual starman shape, as

\begin{equation}
\mathbf{D} = \Sigma_i\mathbf{d}_i (\mathbf{d}_r(\mathbf{p}) + \mathbf{p})\,.
\label{eq.starman_deformation}
\end{equation}

\begin{figure*}
\includegraphics[width=\columnwidth]{figs/datasetgeneration.pdf}
\caption{\small Visualization of the \textit{Starman} dataset simulation. The template shape $\mathbf{X}$ is in solid black, the control points \textcolor{magenta}{$\{\mathbf{c}_{i}\}$} are the five points in \textcolor{magenta}{magenta}. The grey dashed lines represent the individual random deformation $\mathbf{d}_r$ to the template and those control points \textcolor{magenta}{$\{\mathbf{c}_{i}\}$} , yielding an individualized template $\mathbf{X}_r$. The moving direction \textcolor{blue}{$\mathbf{m}_{0}$} controlling the two arms is in \textbf{\textcolor{blue}{bold blue arrow}}. The moving direction \textcolor{green}{$\mathbf{m}_{1}$} controlling the two legs is in \textbf{\textcolor{green}{bold green arrow}}. The velocity fields $\mathbf{d}_0$ and $\mathbf{d}_1$ control the upward/downward movement of two arms correspondingly. The velocity fields $\mathbf{d}_2$ and $\mathbf{d}_3$ controls the splits of two legs correspondingly. The individualized template shape $\mathbf{X}_r$ is deformed by $\mathbf{d} = \Sigma_i\mathbf{d}_i$ to $\mathbf{Y}_r$ (\textcolor{red}{the red shape}), representing a person moving their arms and legs. The covariates $\alpha$ and $\beta$ decide how much the arm is lifted and how much the legs are split.}
\label{fig.starmandataset}
\end{figure*}

\subsection{ADNI Hippocampus}
\label{subsec.adni_dataset}
The ADNI hippocampus dataset consists of 1632 hippocampus segmentations from magnetic resonance (MR) images from the ADNI dataset, 80\% (1297 shapes) of which are used for training and 20\% (335 shapes) for testing. Each shape is associated with 4 covariates (age, sex, AD, education length). AD is a binary variable that represents whether a person has Alzheimer disease. AD=1 indicates a person has Alzheimer disease.  Table~\ref{tab.adni_num_of_observations} shows the distribution of the number of observations across patients. Table~\ref{tab.adni_dataset_exp_paitent} shows the hippocampus shapes and the demographic information of an example patient. Table~\ref{tab.adni_vis_demo_dataset} shows the shapes and demographic information at different age percentiles for the whole data set.  We observe that the time span of our longitudinal data for each patient is far shorter than the time span across the entire dataset, indicating the challenge of capturing spatiotemporal dependencies over large time spans between shapes while accounting for individual differences between patients.


\begin{table}[htbp!]
\centering
\begin{tabular}{l cccccc} 
\toprule
    \# observations     &  1 & 2 & 3 & 4 & 5 & 6 \\ 
\hline\hline
    \# patients   &  3 & 10 &  410 & 5 & 7 & 54  \\
\bottomrule
\end{tabular}
\caption{Number of patients for a given number of observations for the ADNI dataset. For example, the 1st column indicates that there are 3 patients who were only observed once. }
\label{tab.adni_num_of_observations}
\end{table}

\begin{table*}
\centering
\resizebox{0.8\textwidth}{!}{%
\begin{tabular}{p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}}
\toprule
\# time &      0&      1  &      2  &      3  &      4  & 5 \\
\midrule
$\{\mathcal{S}^t\}$&
\includegraphics[width=0.12\columnwidth]{figs/adni_one_patient/0.png} &  
\includegraphics[width=0.12\columnwidth]{figs/adni_one_patient/1.png} &  
\includegraphics[width=0.12\columnwidth]{figs/adni_one_patient/2.png} &  
\includegraphics[width=0.12\columnwidth]{figs/adni_one_patient/3.png} &  
\includegraphics[width=0.12\columnwidth]{figs/adni_one_patient/4.png} & 
\includegraphics[width=0.12\columnwidth]{figs/adni_one_patient/5.png} \\
\bottomrule
\end{tabular}}

\resizebox{0.8\columnwidth}{!}{%
\begin{tabular}{p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}}%{lcccccc}
\hline
 & 0 & 1 & 2 & 3 & 4 & 5 \\ \hline
age & 75.6 & 75.7 & 76.2 & 76.2 & 76.7 & 76.7 \\
AD & No & No & No & No & No & No \\
sex & F & F & F & F & F & F \\
edu & 20.0 & 20.0 & 20.0 & 20.0 & 20.0 & 20.0 \\
m-vol & 2.26 & 2.38 & 2.2 & 2.35 & 2.27 & 2.16 \\ \bottomrule
\end{tabular}%
}

\caption{Visualization and demographic information of observations of a patient in the ADNI hippocampus dataset. Shapes are plotted with their covariates (age/yrs, AD, sex, edu(education length)/yrs) printed in the table. M-vol (measured volume) is the volume ($cm^3$) of the gold standard shapes based on the actual imaging. }
\label{tab.adni_dataset_exp_paitent}
\end{table*}



\begin{table*}
\resizebox{\textwidth}{!}{%
\begin{tabular}{p{0.08\textwidth}p{0.081\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}}
\toprule
P- &      0&      10  &      20  &      30  &      40  & 50 & 60 & 70 & 80 & 90 & 100\\
\midrule
$\{\mathcal{S}^t\}$&
\includegraphics[width=0.15\columnwidth]{figs/adni_age_perct/0.png} &  
\includegraphics[width=0.15\columnwidth]{figs/adni_age_perct/1.png} &  
\includegraphics[width=0.15\columnwidth]{figs/adni_age_perct/2.png} &  
\includegraphics[width=0.15\columnwidth]{figs/adni_age_perct/3.png} &  
\includegraphics[width=0.15\columnwidth]{figs/adni_age_perct/4.png} & 
\includegraphics[width=0.15\columnwidth]{figs/adni_age_perct/5.png} &  
\includegraphics[width=0.15\columnwidth]{figs/adni_age_perct/6.png} &  
\includegraphics[width=0.15\columnwidth]{figs/adni_age_perct/7.png} &  
\includegraphics[width=0.15\columnwidth]{figs/adni_age_perct/8.png} &  
\includegraphics[width=0.15\columnwidth]{figs/adni_age_perct/9.png} &
\includegraphics[width=0.15\columnwidth]{figs/adni_age_perct/10.png} \\
\bottomrule
\end{tabular}}

\resizebox{\columnwidth}{!}{%
\begin{tabular}{p{0.08\textwidth}p{0.081\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}}
\toprule
 & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\ \hline
age & 55.2 & 68.4 & 71.2 & 72.6 & 74.2 & 76.2 & 77.9 & 79.8 & 82.0 & 85.2 & 90.8 \\
AD & No & No & Yes & No & No & No & Yes & Yes & No & No & No \\
sex & F & F & F & F & M & F & F & M & M & F & F \\
edu & 18.0 & 16.0 & 16.0 & 15.0 & 18.0 & 18.0 & 17.0 & 20.0 & 16.0 & 7.0 & 15.0 \\
m-vol & 1.91 & 1.58 & 1.3 & 1.48 & 2.08 & 2.2 & 1.66 & 1.63 & 2.0 & 1.64 & 2.21 \\ \bottomrule
\end{tabular}%
}

\caption{Visualization and demographic information of our ADNI Hippocampus 3D shape dataset. Shapes of $\{0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100\}$-th age percentiles 
 are plotted with their covariates (age/yrs, AD, sex, edu(education length)/yrs) printed in the table. M-vol (measured volume) is the volume ($cm^3$) of the gold standard shapes based on the actual imaging. }
\label{tab.adni_vis_demo_dataset}
\end{table*}



\subsection{Pediatric Airway}
\label{subsec.airway_dataset}
The airway shapes are extracted from computed tomography (CT) images. We use real CT images of children ranging in age from 1 month to $\sim$19 years old. Acquiring CT images is costly. Further, CT uses ionizing radiation which should be avoided, especially in children, due to cancer risks. Hence, it is difficult to acquire such CTs for many children. Instead, our data was acquired by serendipity from children who received CTs for reasons other than airway obstructions (e.g., because they had cancer). This also explains why it is difficult to acquire longitudinal data. E.g., one of our patients has 11 timepoints because a very sick child had to be scanned 11 times. \emph{Note that our data is very different from typical CV datasets which can be more readily acquired at scale or may even already exist based on internet photo collections. This is impossible for our task because image acquisition risks always have to be justified by patient benefits.} %Our \textbf{real-world dataset} motivates our development of \texttt{NAISR}. %, as \textbf{the first to enable every child to have time development without radiation}.

Our dataset includes 229 cross-sectional observations (where a patient was only imaged once) and 34 longitudinal observations.  Each shape has 3 covariates (age, weight, sex) and 11 annotated anatomical landmarks. Errors in the shapes $\{\mathcal{S}^k\}$ may arise from image segmentation error, differences in head positioning, missing parts of the airway shapes due to incomplete image coverage, and dynamic airway deformations due to breathing. Table~\ref{tab.num_of_observations} shows the distribution of the number of observations across patients. Most of the patients in the dataset only have one observation; only 22 patients have $\geq 3$ observation times. Table~\ref{tab.dataset_exp_paitent} shows the airway shapes and the demographic information of an example patient. Table~\ref{tab.vis_demo_dataset} shows the shapes and demographic information at different age percentiles for the whole data set. Similar to the ADNI hippocampus dataset, the time span of the longitudinal data for each patient is far shorter than the time span across the entire dataset, which poses a significant shape analysis challenge for realistic medical shapes. %, indicating the challenge of capturing spatiotemporal dependencies over large time spans between shapes while accounting for individual differences between patients.


\begin{table}[htbp!]
\centering
\begin{tabular}{l r r r r r r r r r r} 
\toprule
    \# observations     &  1 & 2 & 3 & 4 & 5 & 6 & 7 & 9 & 11\\ 
\hline\hline
    \# patients   &  229 & 12 &  6 & 8 & 3 & 2 & 1 & 1 & 1 \\
\bottomrule
\end{tabular}
\caption{Number of patients for a given number of observations for the pediatric airway dataset. For example, the 1st column indicates that there are 229 patients who were only observed once. }
\label{tab.num_of_observations}
\end{table}

\begin{table*}
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{p{0.06\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}}
\toprule
\#time &      0&      1  &      2  &      3  &      4  & 5 & 6 & 7 & 8 \\
\midrule
$\{\mathcal{S}^t\}$&
\includegraphics[width=0.12\columnwidth]{figs/airway_one_patient/0.png} &  
\includegraphics[width=0.12\columnwidth]{figs/airway_one_patient/1.png} &  
\includegraphics[width=0.12\columnwidth]{figs/airway_one_patient/2.png} &  
\includegraphics[width=0.12\columnwidth]{figs/airway_one_patient/3.png} &  
\includegraphics[width=0.12\columnwidth]{figs/airway_one_patient/4.png} & 
\includegraphics[width=0.12\columnwidth]{figs/airway_one_patient/5.png} &  
\includegraphics[width=0.12\columnwidth]{figs/airway_one_patient/6.png} &  
\includegraphics[width=0.12\columnwidth]{figs/airway_one_patient/7.png} &  
\includegraphics[width=0.12\columnwidth]{figs/airway_one_patient/8.png} \\

\bottomrule
\end{tabular}}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{p{0.06\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}p{0.08\textwidth}}
\toprule
\#time &      0&      1  &      2  &      3  &      4  & 5 & 6 & 7 & 8 \\
\midrule

age         &    84.00 &    85.00 &    87.00 &    91.0 &    95.00 &    98.00 &   101.00 &   104.00 &   120.00 \\
weight      &    20.40 &    20.40 &    21.00 &    21.9 &    22.80 &    22.90 &    23.50 &    24.90 &    28.50 \\
sex         &     M &    M  &    M &    M &    M &    M  &    M  &     M &    M  \\
m-vol &    30.07 &    32.18 &    48.95 &    33.8 &    44.87 &    42.29 &    28.42 &    40.92 &    61.36 \\
\bottomrule

\end{tabular}}
\caption{Visualization and demographic information of observations of a patient in our 3D airway shape dataset. Shapes are plotted with their covariates (age/month, weight/kg, sex) printed in the table. M-vol (measured volume) is the volume ($cm^3$) of the gold standard shapes based on the actual imaging. }
\label{tab.dataset_exp_paitent}
\end{table*}



\begin{table*}

\resizebox{\textwidth}{!}{%
\begin{tabular}{p{0.11\textwidth}p{0.11\textwidth}p{0.11\textwidth}p{0.11\textwidth}p{0.11\textwidth}p{0.11\textwidth}p{0.11\textwidth}p{0.11\textwidth}p{0.11\textwidth}p{0.11\textwidth}p{0.11\textwidth}p{0.11\textwidth}}
\toprule
P- &      0&      10  &      20  &      30  &      40  & 50 & 60 & 70 & 80 & 90 & 100\\
\midrule
$\{\mathcal{S}^t\}$&
\includegraphics[width=0.2\columnwidth]{figs/airway_age_perct/0.png} &  
\includegraphics[width=0.2\columnwidth]{figs/airway_age_perct/1.png} &  
\includegraphics[width=0.2\columnwidth]{figs/airway_age_perct/2.png} &  
\includegraphics[width=0.2\columnwidth]{figs/airway_age_perct/3.png} &  
\includegraphics[width=0.2\columnwidth]{figs/airway_age_perct/4.png} & 
\includegraphics[width=0.2\columnwidth]{figs/airway_age_perct/5.png} &  
\includegraphics[width=0.2\columnwidth]{figs/airway_age_perct/6.png} &  
\includegraphics[width=0.2\columnwidth]{figs/airway_age_perct/7.png} &  
\includegraphics[width=0.2\columnwidth]{figs/airway_age_perct/8.png} &  
\includegraphics[width=0.2\columnwidth]{figs/airway_age_perct/9.png} &
\includegraphics[width=0.2\columnwidth]{figs/airway_age_perct/10.png} \\

\bottomrule
\end{tabular}}
\resizebox{\textwidth}{!}{%
\begin{tabular}{p{0.06\textwidth}p{0.06\textwidth}p{0.06\textwidth}p{0.06\textwidth}p{0.06\textwidth}p{0.06\textwidth}p{0.06\textwidth}p{0.06\textwidth}p{0.06\textwidth}p{0.06\textwidth}p{0.06\textwidth}p{0.06\textwidth}}
\toprule
P- &      0&      10  &      20  &      30  &      40  & 50 & 60 & 70 & 80 & 90 & 100\\
\midrule

age         &     1.00 &    23.00 &    55.00 &    71.00 &    89.00 &   111.00 &   129.00 &   161.00 &   179.00 &   199.00 &   233.00 \\
weight      &     3.90 &    14.20 &    20.10 &    21.80 &    19.70 &    32.85 &    44.80 &    21.30 &    59.00 &    93.90 &    75.60 \\
sex         &     M &     M &     F &     F &     M &     M &     M &     F &     F &     F &     M \\
m-vol &     4.56 &    16.84 &    29.53 &    28.91 &    27.31 &    70.90 &    71.23 &    43.34 &    78.63 &   102.35 &   113.84 \\

\bottomrule

\end{tabular}}
\caption{Visualization and demographic information of our 3D airway shape dataset. Shapes of $\{0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100\}$-th age percentiles 
 are plotted with their covariates (age/month, weight/kg, sex) printed in the table. M-vol (measured volume) is the volume ($cm^3$) of the gold standard shapes based on the actual imaging. }
\label{tab.vis_demo_dataset}
\end{table*}


\paragraph{Data Processing.}
For the ADNI hippocampus dataset and the pediatric airway dataset, the shape meshes are extracted using Marching Cubes~\citep{lorensen1987marching, van2014scikit} to obtain coordinates and normal vectors of on-surface points. The hippocapus shapes are rigidly aligned using the ICP algorithm~\citep{arun1987least}. The airway shapes are rigidly aligned using the anatomical landmarks. The true vocal cords landmark is set to the origin. We follow the implementation in~\citep{park2019deepsdf} to sample 500,000 off-surface points. During training, it is important to preserve the scale information. We therefore scale all meshes with the same constant. %The resulting meshes from reconstruction are extracted with marching cubes~\citep{lorensen1987marching,van2014scikit}.


\section{Experiments}

\Secref{subsec:implementation_details} describes implementation details \Secref{subsec.ablation_study} describe the ablation study.  \Secref{subsec.supp_shape_reconstruction}, \Secref{subsec:shape_transfer}, and \Secref{subsec:disentangled_shape_evolution} show additional experimental results for shape reconstruction, shape transfer, and disentangled shape evolution, respectively.

\subsection{Implementation Details}
\label{subsec:implementation_details}

\begin{table}
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lccccccc}
\toprule
\multirow{2}{*}{Methods} & \multirow{2}{*}{DeepSDF} & \multirow{2}{*}{A-SDF} & \multirow{2}{*}{DIT} & \multirow{2}{*}{NDF} & \multicolumn{3}{c}{Ours} \\ \cline{6-8} 
 &  &  &  &  & Starman & ADNI Hippocampus & Pediatric Airway \\ \hline
\#params & 2.24M & 1.98M & 1.92M & 0.34M & 1.33M & 2.26M & 1.26M \\ \bottomrule
\end{tabular}%
}
\caption{Number of parameters of the different models. }
\label{tab.supp_model_parameters}
\end{table}


Each subnetwork, including the template network $\mathcal{T}$ and the displacement networks $\{f_i\}$, are all parameterized with an $N_l$-layer MLP using $sine$ activations. We use $N_l$=8 for \texttt{Starman} and the ADNI hippocampus dataset; we use $N_l$=6 for the pediatric airway dataset. The network parameter initialization follows SIREN~\citep{sitzmann2020siren}. There are 256 hidden units in each layer. The architecture of $\mathcal{T}$ also follows SIREN~\citep{sitzmann2020siren}. The architecture of the $\{f_i\}$ follows DeepSDF~\citep{park2019deepsdf}, in which a skip connection is used to concatenate the input of $(\mathbf{p}, c_i)$ to the input of the middle layer. We use a latent code $\mathbf{z}$ of dimension 256 ($L=256$). Table~\ref{tab.supp_model_parameters} lists the number of model parameters.

For each training iteration, the number of points sampled from each shape is 750 ($N=750$), of which 500 are on-surface points ($N_{on} = 500$) and the others are off-surface points ($N_{off} = 250$). We train \texttt{NAISR} for 3000 epochs for airway dataset and 300 epochs for the ADNI hippocampus and \texttt{Starman} dataset using Adam~\citep{kingma2014adam} with a learning rate \(5e-5\) and batch size of 64. Also, we jointly optimize the latent code $\mathbf{z}$ with \texttt{NAISR} using Adam~\citep{kingma2014adam} with a learning rate of \(1e-3\). 

During training, $\lambda_1 =\lambda_5 = \frac{10}{N}$; $\lambda_2 = \frac{30}{N_{on}}$; $\lambda_3 = \frac{10}{N_{on}}$, $\lambda_4 = \frac{100}{N_{off}}$. For $\mathcal{L}_{lat}$, $\lambda_6 = \frac{2}{L}$; $\sigma=0.01$ (following DeepSDF~\citep{park2019deepsdf}). During inference, the latent codes are optimized for $N_t$  iterations with a learning rate of $5e-3$. $N_t$  is set to 800 for the pediatric airway dataset; $N_t$ is set to 200 for the \textit{Starman} and ADNI Hippocampus datasets.

\paragraph{Comparison Methods.} For shape reconstruction of unseen shapes, we compare our method on the test set with DeepSDF~\citep{park2019deepsdf} A-SDF~\citep{mu2021asdf} DIT~\citep{zheng2021DIT} and NDF~\citep{sun2022topology}. For shape transfer, we compare our method with A-SDF~\citep{mu2021asdf} because other comparison methods cannot model covariates as summarized in Table~\ref{tab.lit}. The original implementations of the comparison methods did not produce satisfying reconstructions on our dataset. We therefore improved them by using our reconstruction losses and by using the \texttt{SIREN} backbone~\citep{sitzmann2020siren} in DeepSDF~\citep{park2019deepsdf}, A-SDF~\citep{mu2021asdf}, and the template networks in DIT~\citep{zheng2021DIT} and NDF~\citep{sun2022topology}.%DeepSDF~\citep{park2019deepsdf} and A-SDF~\citep{mu2021asdf} directly use MLP layers to map 3d coordinates to the distance from the surface while DIT~\citep{zheng2021DIT} and NDF~\citep{sun2022topology} calculate the displacement to warp the source shape to the template.

\subsection{Ablation Study}
\label{subsec.ablation_study}
We conduct an ablation study on the loss terms on the pediatric airway dataset. Airway shapes are more complicated than the \emph{Starman} shapes and the hippocampi. Further, the number of shape samples is smallest among the three datasets. On this challenging dataset, we aim to observe the model robustness when using varying loss terms and our goal is to determine which loss terms are necessary and what suitable hyperparameter settings are.

Table~\ref{tab.ablation_ours_reconstruction} and Table~\ref{tab.ablation_ours_recons_cov} shows the shape reconstruction evaluation for different hyperparameter settings. We see that $\mathcal{L}_{Dirichlet}$ for off-surface points is the most important term. A lower $\lambda_6$ for the latent code regularizer $\mathcal{L}_{lat}$ yields better reconstruction results. Table~\ref{tab.ablation_ours_transfer} shows an ablation study for shape transfer. We observe that the reconstruction losses $\mathcal{L}_{Dirichlet}$ and $\mathcal{L}_{Neumann}$ are important for shape transfer.

To sum up, removing any of the reconstruction losses ($\mathcal{L}_{Eikonal}$, $\mathcal{L}_{Dirichlet}$, $\mathcal{L}_{Neumann}$) hurts performance. A smaller $\lambda_6$ yields better reconstruction performance, but may hurt shape transfer performance.




\begin{table}[]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lcccccccc}
\toprule
 &  &  & \multicolumn{2}{c}{CD $\downarrow$} & \multicolumn{2}{c}{EMD $\downarrow$} & \multicolumn{2}{c}{HD $\downarrow$} \\
\multirow{-2}{*}{Methods} & \multirow{-2}{*}{variants} & \multirow{-2}{*}{influenced term} & $\mu$ & M & $\mu$ & M & $\mu$ & M \\ \hline
Ours & $\lambda_1=\lambda_5=0$ & $\mathcal{L}_{Eikonal}$ & 0.072 & 0.047 & 1.447 & 1.323 & 10.426 & 8.716 \\
Ours & $\lambda_4=0$ & $\mathcal{L}_{Dirichlet\_off\_surf}$ & 4.323 & 4.481 & 1.374 & 1.244 & 68.527 & 69.715 \\
Ours & $\lambda_3=0$ & $\mathcal{L}_{Neumann}$ & 0.081 & 0.051 & 1.449 & 1.307 & 10.269 & 8.546 \\
Ours & $\lambda_2=0$ & $\mathcal{L}_{Dirichlet\_on\_surf}$ & 0.124 & 0.077 & 1.912 & 1.682 & 10.803 & 8.916 \\
Ours & $\lambda_6=0$ & $\mathcal{L}_{lat}$ & 0.045 & 0.023 & 0.980 & 0.890 & 8.920 & 7.028 \\
Ours & $\lambda_6*=0.01$ & $\mathcal{L}_{lat}$ & 0.049 & 0.023 & 1.053 & 0.924 & 9.064 & 7.041 \\
Ours & $\lambda_6*=0.1$ & $\mathcal{L}_{lat}$ & 0.056 & 0.031 & 1.126 & 1.015 & 9.578 & 7.831 \\
\rowcolor[HTML]{EFEFEF} 
Ours & $\lambda_6*=1$ & $\mathcal{L}_{lat}$ & 0.067 & 0.039 & 1.251 & 1.143 & 10.333 & 8.404 \\
Ours & $\lambda_6*=10$ & $\mathcal{L}_{lat}$ & 0.075 & 0.049 & 1.368 & 1.270 & 11.111 & 9.176 \\
Ours & $\lambda_6*=100$ & $\mathcal{L}_{lat}$ & 0.100 & 0.073 & 1.607 & 1.532 & 13.456 & 11.853 \\ 
\bottomrule
\end{tabular}%
}
\caption{Ablation study: quantitative evaluation of shape reconstruction. Ours means covariates are not used as additional input to \texttt{NAISR}. The shadowed line is what we report in the main text.}
\label{tab.ablation_ours_reconstruction}
\end{table}

\begin{table}[]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lcccccccc}
\toprule
 &  &  & \multicolumn{2}{c}{CD $\downarrow$} & \multicolumn{2}{c}{EMD $\downarrow$} & \multicolumn{2}{c}{HD $\downarrow$} \\
\multirow{-2}{*}{Methods} & \multirow{-2}{*}{variants} & \multirow{-2}{*}{influenced term} & $\mu$ & M & $\mu$ & M & $\mu$ & M \\ \hline
Ours (c) & $\lambda_1=\lambda_5=0$ & $\mathcal{L}_{Eikonal}$ & 0.097 & 0.052 & 1.559 & 1.344 & 11.178 & 9.426 \\
Ours (c) & $\lambda_4=0$ & $\mathcal{L}_{Dirichlet\_off\_surf}$ & 4.029 & 4.485 & 1.454 & 1.239 & 68.272 & 69.356 \\
Ours (c) & $\lambda_3=0$ & $\mathcal{L}_{Neumann}$ & 0.089 & 0.055 & 1.494 & 1.313 & 10.52 & 8.625 \\
Ours (c) & $\lambda_2=0$ & $\mathcal{L}_{Dirichlet\_on\_surf}$ & 0.151 & 0.09 & 2.058 & 1.756 & 11.354 & 9.569 \\
Ours (c) & $\lambda_6=0$ & $\mathcal{L}_{lat}$ & 0.041 & 0.019 & 0.936 & 0.834 & 8.677 & 7.335 \\
Ours (c) & $\lambda_6*=0.01$ & $\mathcal{L}_{lat}$ & 0.051 & 0.025 & 1.061 & 0.923 & 9.301 & 7.139 \\
Ours (c) & $\lambda_6*=0.1$ & $\mathcal{L}_{lat}$ & 0.061 & 0.031 & 1.154 & 1.043 & 9.875 & 8.151 \\
\rowcolor[HTML]{EFEFEF} 
Ours (c) & $\lambda_6*=1$ & $\mathcal{L}_{lat}$ & 0.084 & 0.044 & 1.344 & 1.182 & 10.719 & 8.577 \\
Ours (c) & $\lambda_6*=10$ & $\mathcal{L}_{lat}$ & 0.109 & 0.058 & 1.554 & 1.336 & 11.933 & 9.705 \\
Ours (c) & $\lambda_6*=100$ & $\mathcal{L}_{lat}$ & 0.152 & 0.088 & 1.943 & 1.715 & 14.37 & 12.043 \\ 
\bottomrule
\end{tabular}%
}
\caption{Ablation study: quantitative evaluation of shape reconstruction. Ours (c) means covariates are used as additional input to \texttt{NAISR}. $\mu$ indicates the mean value of the measurements; M indicates the median of the measurements. The shadowed line is what we report in the main text. }
\label{tab.ablation_ours_recons_cov}
\end{table}

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage[table,xcdraw]{xcolor}
% If you use beamer only pass "xcolor=table" option, i.e. \documentclass[xcolor=table]{beamer}
\begin{table}[]
\centering
\begin{tabular}{lcccccc}
\toprule
 & \multicolumn{2}{c}{ablations} & \multicolumn{4}{c}{Volume Difference $\downarrow$} \\ \cline{2-7} 
 &  &  & \multicolumn{2}{c}{without covariates} & \multicolumn{2}{c}{with covariates} \\
\multirow{-3}{*}{Methods} & \multirow{-2}{*}{variarants} & \multirow{-2}{*}{influenced term} & $\mu$ & M & $\mu$ & M \\ \hline
Ours & $\lambda_1=\lambda_5=0$ & $\mathcal{L}_{Eikonal}$ & 13.977 & 10.925 & 8.324 & 7.214 \\
Ours & $\lambda_4=0$ & $\mathcal{L}_{Dirichlet\_off\_surf}$ & 3736.527 & 3709.001 & 3693.514 & 3612.394 \\
Ours & $\lambda_3=0$ & $\mathcal{L}_{Neumann}$ & 24.717 & 24.877 & 26.094 & 25.311 \\
Ours & $\lambda_2=0$ & $\mathcal{L}_{Dirichlet\_on\_surf}$  & 55.579 & 57.766 & 64.845 & 63.442 \\
Ours & $\lambda_6=0$ & $\mathcal{L}_{lat}$ & 14.679 & 10.306 & 9.465 & 7.096 \\
Ours & $\lambda_6*=0.01$ & $\mathcal{L}_{lat}$ & 8.766 & 6.629 & 8.518 & 5.105 \\
Ours & $\lambda_6*=0.1$ & $\mathcal{L}_{lat}$ & 12.861 & 8.307 & 11.518 & 8.950 \\
\rowcolor[HTML]{EFEFEF} 
Ours & $\lambda_6*=1$ & $\mathcal{L}_{lat}$ & 12.820 & 8.837 & 11.227 & 9.653 \\
Ours & $\lambda_6*=10$ & $\mathcal{L}_{lat}$ & 8.644 & 4.676 & 9.464 & 5.756 \\
Ours & $\lambda_6*=100$ & $\mathcal{L}_{lat}$ & 11.959 & 8.857 & 11.939 & 8.113 \\
\bottomrule
\end{tabular}
\caption{Ablation study: quantitative evaluation of shape transfer. $\mu$ indicates the mean value of the measurements; M indicates the median of the measurements. The shadowed line is what we report in the main text. }
\label{tab.ablation_ours_transfer}

\end{table}


\subsection{Shape Reconstruction}
\label{subsec.supp_shape_reconstruction}

\Figref{fig.supp_adni_exp_recons} and \Figref{fig.supp_airway_exp_recons} visualize more reconstructed hippocampi and airway shapes respectively. We observe that \texttt{NAISR} produces detailed and complete reconstructions from noisy and incomplete observations.

\begin{figure*}[ht]
\includegraphics[width=1.\columnwidth]{figs/reconstruction_airway.pdf}
\caption{Visualizations of airway shape reconstructions with different methods. The red and blue circles show the structure in the black circle from two different views. \textbf{NAISR} produces detailed and accurate reconstructions and imputes missing airway parts.}
\label{fig.supp_adni_exp_recons}
%\vskip -0.2in
\end{figure*}

\begin{figure*}[ht]
\includegraphics[width=1.\columnwidth]{figs/reconstruction_adni.pdf}
\caption{Visualizations of hippocampus shape reconstructions with different methods. The red and blue circles show the structure in the black circle from two different views. All methods except for A-SDF are able to reconstruct well.}
\label{fig.supp_airway_exp_recons}
%\vskip -0.2in
\end{figure*}

Each shape reconstruction method, except for A-SDF, successfully reconstructs airways and hippocampi. As discussed in \Secref{subsec.shape_reconstruction}, we suspect A-SDF overfits the training set by memorizing shapes with their covariates. We investigate this by evaluating shape reconstruction on the training set for A-SDF and \texttt{NAISR} as shown in Table \ref{tab.supp_train_asdf}. From Table \ref{tab.supp_train_asdf}, we can see that A-SDF overfits the training set.

\begin{table}[]
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lcccccccccccc}
\hline
{\color[HTML]{333333} } & \multicolumn{6}{c}{{\color[HTML]{333333} Training Set}} & \multicolumn{6}{c}{{\color[HTML]{333333} Testing Set}} \\ \cline{2-13} 
{\color[HTML]{333333} } & \multicolumn{2}{c}{{\color[HTML]{333333} CD $\downarrow$}} & \multicolumn{2}{c}{{\color[HTML]{333333} EMD $\downarrow$}} & \multicolumn{2}{c}{{\color[HTML]{333333} HD $\downarrow$}} & \multicolumn{2}{c}{{\color[HTML]{333333} CD $\downarrow$}} & \multicolumn{2}{c}{{\color[HTML]{333333} EMD $\downarrow$}} & \multicolumn{2}{c}{{\color[HTML]{333333} HD $\downarrow$}} \\
\multirow{-3}{*}{{\color[HTML]{333333} Methods}} & \textbf{$\mu$} & \textbf{M} & \textbf{$\mu$} & \textbf{M} & \textbf{$\mu$} & \textbf{M} & \textbf{$\mu$} & \textbf{M} & \textbf{$\mu$} & \textbf{M} & \textbf{$\mu$} & \textbf{M} \\ \hline
{\color[HTML]{333333} A-SDF} & {\color[HTML]{333333} 0.014} & {\color[HTML]{333333} 0.010} & {\color[HTML]{333333} 0.770} & {\color[HTML]{333333} 0.699} & {\color[HTML]{333333} 5.729} & {\color[HTML]{333333} 4.762} & {\color[HTML]{333333} 2.647} & {\color[HTML]{333333} 1.178} & {\color[HTML]{333333} 10.307} & {\color[HTML]{333333} 8.992} & {\color[HTML]{333333} 47.172} & {\color[HTML]{333333} 37.835} \\
{\color[HTML]{333333} Ours} & {\color[HTML]{333333} 0.038} & {\color[HTML]{333333} 0.025} & {\color[HTML]{333333} 0.975} & {\color[HTML]{333333} 0.883} & {\color[HTML]{333333} 8.624} & {\color[HTML]{333333} 7.538} & {\color[HTML]{333333} 0.067} & {\color[HTML]{333333} 0.039} & {\color[HTML]{333333} 1.246} & {\color[HTML]{333333} 1.128} & {\color[HTML]{333333} 10.333} & {\color[HTML]{333333} 8.404} \\ \hline
\end{tabular}%
}
\caption{Comparison of \texttt{NAISR} and A-SDF on the training set. A-SDF performed well on the training set but failed on the testing set.}
\label{tab.supp_train_asdf}
\end{table}


\subsection{Shape Transfer}
\label{subsec:shape_transfer}

\begin{table*}[htbp] 
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{p{0.05\textwidth}p{0.05\textwidth}p{0.05\textwidth}p{0.05\textwidth}p{0.05\textwidth}p{0.05\textwidth}p{0.05\textwidth}p{0.05\textwidth}p{0.05\textwidth}p{0.05\textwidth}p{0.05\textwidth}p{0.05\textwidth}}
\toprule
\#time &      0&      1  &      2  &      3  &      4  &      5  &      6  &      7  &      8  &      9  &      10 \\
\midrule
$\{\mathcal{S}^t\}$&
\includegraphics[width=0.1\columnwidth]{figs/airway_transfer/withoutcov/0.png} &  
\includegraphics[width=0.1\columnwidth]{figs/airway_transfer/withoutcov/1.png} & 
\includegraphics[width=0.1\columnwidth]{figs/airway_transfer/withoutcov/2.png}& 
\includegraphics[width=0.1\columnwidth]{figs/airway_transfer/withoutcov/3.png}& 
\includegraphics[width=0.1\columnwidth]{figs/airway_transfer/withoutcov/4.png}& 
\includegraphics[width=0.1\columnwidth]{figs/airway_transfer/withoutcov/5.png}& 
\includegraphics[width=0.1\columnwidth]{figs/airway_transfer/withoutcov/6.png}& 
\includegraphics[width=0.1\columnwidth]{figs/airway_transfer/withoutcov/7.png}& 
\includegraphics[width=0.1\columnwidth]{figs/airway_transfer/withoutcov/8.png}& 
\includegraphics[width=0.1\columnwidth]{figs/airway_transfer/withoutcov/9.png}& 
\includegraphics[width=0.1\columnwidth]{figs/airway_transfer/withoutcov/10.png}\\
\bottomrule
\end{tabular}}

\resizebox{\columnwidth}{!}{%
\begin{tabular}{lccccccccccc}
\hline
\# time & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{1} & \multicolumn{1}{l}{2} & \multicolumn{1}{l}{3} & \multicolumn{1}{l}{4} & \multicolumn{1}{l}{5} & \multicolumn{1}{l}{6} & \multicolumn{1}{l}{7} & \multicolumn{1}{l}{8} & \multicolumn{1}{l}{9} & \multicolumn{1}{l}{10} \\ \hline
age & 154 & 155 & 157 & 159 & 163 & 164 & 167 & 170 & 194 & 227 & 233 \\
weight & 55.2 & 60.9 & 64.3 & 65.25 & 59.25 & 59.2 & 65.3 & 68 & 77.1 & 75.6 & 75.6 \\
sex & M & M & M & M & M & M & M & M & M & M & M \\
p-vol & 91.08 &   92.47 &   93.57 &   94.26 &   94.35 &   94.59 &   96.28 &   97.34 &  102.59 &  104.75 &  104.51 \\
m-vol & 86.33 & 82.66 & 63.23 & 90.65 & 98.11 & 84.35 & 94.14 & 127.45 & 98.81 & 100.17 & 113.84 \\ \hline
\end{tabular}%
}
\caption{\small Airway shape transfer without covariates as input for the patient shown in the main text. Blue: gold standard shapes; red: transferred shapes with \texttt{NAISR}. The table below lists the covariates (age/month, weight/kg, sex) for the shapes above. P-vol(predicted volume) is the volume ($cm^3$) of the transferred shape by \texttt{NAISR} with covariates following Eq.~\eqref{eq.infer_cz}. M-vol (measured volume) is the volume ($cm^3$) of the shapes based on the actual imaging. The transferred shapes show similar growth trends in pediatric airways as shown in Table.~\ref{tab.transp_for_case}.}
\label{tab.airway_transp_for_case_without_cov}
\end{table*}


Table~\ref{tab.airway_transp_for_case_without_cov} shows the transferred airways using \texttt{NAISR} without covariates as input (following \Eqref{eq.infer_z}). The predicted shapes from \Eqref{eq.infer_cz} and \Eqref{eq.infer_z} look consistent in terms of appearance and development tendency. Table~\ref{tab.adni_transp_for_case_with_cov} and Table~\ref{tab.adni_transp_for_case_without_cov} show the transferred hippocampi. Due to the limited observation time span of patients in the ADNI hippocampus dataset, the volume stays almost constant.


\begin{table*}
\centering

\resizebox{0.8\textwidth}{!}{%
\begin{tabular}{p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}}
\toprule
\# time &      0&      1  &      2  &      3  &      4   \\
\midrule
$\{\mathcal{S}^t\}$&
\includegraphics[width=0.2\columnwidth]{figs/adni_transfer/withcov/0.png} &  
\includegraphics[width=0.2\columnwidth]{figs/adni_transfer/withcov/1.png} &  
\includegraphics[width=0.2\columnwidth]{figs/adni_transfer/withcov/2.png} &  
\includegraphics[width=0.2\columnwidth]{figs/adni_transfer/withcov/3.png} &  
\includegraphics[width=0.2\columnwidth]{figs/adni_transfer/withcov/4.png} \\
\bottomrule
\end{tabular}}

\resizebox{0.8\columnwidth}{!}{%
\begin{tabular}{p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}}
\toprule
\# time      & 0    & 1    & 2    & 3    & 4    \\ \hline
age   & 64.7 & 65.2 & 65.2 & 65.7 & 65.7 \\
AD    & No   & No   & No   & No   & No   \\
sex   & F    & F    & F    & F    & F    \\
edu   & 14   & 14   & 14   & 14   & 14   \\
p-vol &  1.55 &   1.55 &   1.55 &   1.55 &   1.55 \\
m-vol & 1.49 & 1.56 & 1.55 & 1.45 & 1.55 \\ \bottomrule
\end{tabular}}
\caption{\small Hippocampus shape transfer with covariates as input. Blue: gold standard shapes; red: transferred shapes with \texttt{NAISR}. The table below lists the covariates (age/yrs, AD, sex, edu(education length)/yrs for the shapes above. P-vol(predicted volume) is the volume ($cm^3$) of the transferred shape by \texttt{NAISR} with covariates following \Eqref{eq.infer_z}. M-vol (measured volume) is the volume ($cm^3$) of the shapes based on the actual imaging. The transferred shapes stay almost the same in the one-year time period for this patient.}
\label{tab.adni_transp_for_case_with_cov}
\end{table*}


\begin{table*}
\centering
\resizebox{0.8\textwidth}{!}{%
\begin{tabular}{p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}}
\toprule
\# time &      0&      1  &      2  &      3  &      4   \\
\midrule
$\{\mathcal{S}^t\}$&
\includegraphics[width=0.2\columnwidth]{figs/adni_transfer/withoutcov/0.png} &  
\includegraphics[width=0.2\columnwidth]{figs/adni_transfer/withoutcov/1.png} &  
\includegraphics[width=0.2\columnwidth]{figs/adni_transfer/withoutcov/2.png} &  
\includegraphics[width=0.2\columnwidth]{figs/adni_transfer/withoutcov/3.png} &  
\includegraphics[width=0.2\columnwidth]{figs/adni_transfer/withoutcov/4.png} \\
\bottomrule
\end{tabular}}

\resizebox{0.8\textwidth}{!}{%
\begin{tabular}{p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}p{0.1\textwidth}}
\toprule
\# time      & 0    & 1    & 2    & 3    & 4    \\ \hline
age   & 64.7 & 65.2 & 65.2 & 65.7 & 65.7 \\
AD    & No   & No   & No   & No   & No   \\
sex   & F    & F    & F    & F    & F    \\
edu   & 14   & 14   & 14   & 14   & 14   \\
p-vol & 1.6  & 1.6  & 1.6  & 1.6  & 1.6  \\
m-vol & 1.49 & 1.56 & 1.55 & 1.45 & 1.55 \\
\bottomrule
\end{tabular}}
\caption{\small Hippocampus shape transfer without covariates as input. Blue: gold standard shapes; red: transferred shapes with \texttt{NAISR}. The table below lists the covariates (age/yrs, AD, sex, edu(education length)/yrs for the shapes above. P-vol(predicted volume) is the volume ($cm^3$) of the transferred shape by \texttt{NAISR} with covariates following \Eqref{eq.infer_cz}. M-vol (measured volume) is the volume ($cm^3$) of the shapes based on the actual imaging. The transferred shapes stay almost the same in the one-year period space for this patient.}
\label{tab.adni_transp_for_case_without_cov}
\end{table*}




\subsection{Shape Disentanglement and Evolution}
\label{subsec:disentangled_shape_evolution}
Fig.~\ref{fig.supp_individualized_airway_extrapolation} shows an example of airway shape extrapolation in covariate space for a patient in the testing set. Fig.~\ref{fig.supp_individualized_adni_extrapolation} shows an example of hippocampus shape extrapolation in covariate space for a patient in the testing set. We observe that in the range of observed covariates (inside the purple shade), shape extrapolation produces realistic-looking and reasonable growing/shrinking shapes in accordance with clinical expectations. Further, \texttt{NAISR} is able to extrapolate shapes outside this range, but the quality is lower than within the range of observed covariates. 

\begin{figure}
\vspace{-0.5in}
    \centering
    \begin{minipage}{\textwidth}
        \centering
        \includegraphics[width=0.7\columnwidth]{figs/starman_shapematrix_specific_asdf.pdf}\\
     A-SDF, \textit{Starman}
    \end{minipage}%
    \\
    \begin{minipage}{\textwidth}
        \centering
        \includegraphics[width=0.7\columnwidth]{figs/starman_shapematrix_specific.pdf}\\
    Ours, \textit{Starman}
    \end{minipage}%
\caption{Individualized \textit{Starman} shape extrapolation in covariate space. The blue shapes are the groundtruth shapes and the red shapes are the reconstructions. The purple shadows over the space indicate the covariate range that the dataset covers. The latent code $\mathbf{z}$ is kept constant to create an individualized covariate shape space. The shapes in the green and yellow boxes are plotted with $\{\Phi_i\}$ (see \Secref{sec.testing}), representing the disentangled shape evolutions along the arm and leg respectively. Shapes extrapolated from $\mathbf{z}_i$ look realistic and smooth across different covariates.}
\label{fig.supp_individualized_starman_extrapolation}
\end{figure}


\begin{figure*}[!hb]
\vspace{-0.5in}
    \centering
    \begin{minipage}{\textwidth}
        \centering
        \includegraphics[width=0.7\columnwidth]{figs/shapematrix_1364_asdf.pdf}\\
     A-SDF, Pediatric Airway
    \end{minipage}%
    \\
    \begin{minipage}{\textwidth}
        \centering
        \includegraphics[width=0.7\columnwidth]{figs/shapematrix_1364.pdf}\\
    Ours, Pediatric Airway
    \end{minipage}%
\caption{Individualized airway shape extrapolation in covariate space. Example shapes in the covariate space are visualized with their volumes ($cm^3$) below. Cyan points represent male and purple points female children in the dataset. The points represent the covariates of all children in the dataset. The purple shadows over the space indicate the covariate range that the dataset covers. The colored shades at the boundary represent the covariate distributions stratified by sex. The latent code $\mathbf{z}$ is kept constant to create an individualized covariate shape space. The shapes in the green and yellow boxes are plotted with $\{\Phi_i\}$ (see \Secref{sec.testing}), representing the disentangled shape evolutions along weight and age respectively. Shapes extrapolated from $\mathbf{z}_i$ look realistic and smooth across different covariates.}
\label{fig.supp_individualized_airway_extrapolation}
\end{figure*}



\begin{figure*}[!hb]
\vspace{-0.5in}
    \centering
    \begin{minipage}{\textwidth}
        \centering
        \includegraphics[width=0.7\columnwidth]{figs/shapematrix_SPECIFIC_adni_asdf.pdf}\\
     A-SDF, ADNI Hippocampus
    \end{minipage}%
    \\
    \begin{minipage}{\textwidth}
        \centering
        \includegraphics[width=0.7\columnwidth]{figs/shapematrix_SPECIFIC_adni.pdf}\\
    Ours, ADNI Hippocampus
    \end{minipage}%
\caption{Individualized hippocampus shape extrapolation in covariate space. Example shapes in the covariate space are visualized with their volumes ($cm^3$) below. Cyan points represent male and purple points female patients in the dataset. The points represent the covariates of all patients in the dataset. The purple shadows over the space indicate the covariate range that the dataset covers. The colored shades at the boundary represent the covariate distributions stratified by sex. The latent code $\mathbf{z}$ is kept constant to create an individualized covariate shape space. The shapes in the green and yellow boxes are plotted with $\{\Phi_i\}$ (see \Secref{sec.testing}), representing the disentangled shape evolutions along AD and age respectively. Shapes extrapolated from $\mathbf{z}_i$ look realistic and smooth across different covariates. }
\label{fig.supp_individualized_adni_extrapolation}
\end{figure*}





\section{Limitations and Future Work}
\label{supp.limitations_and_future_work}
Invertible transformations are often desirable for shape correspondence. However, our approach cannot guarantee invertibility. Invertibility could be guaranteed by representing deformations via velocity fields instead of directly parameterizing deformation fields. However, velocity field parameterizations are costly as they require numerical integration. Hence, training such velocity field models for implicit shapes would consume more time and GPU resources. In future work, we will develop more efficient invertible representations, which will then assure that shape topology (wrt. the template shape) is preserved by construction. %and will assure that  we can get point-wise evolution trajectories by evolving any point $\mathbf{p}$ on the template $\mathcal{T}$ to the source shape $\mathcal{S}$.
We also do not know the true effects of the covariates on the shapes. We can so far only indirectly assess our model by quantifying reconstruction, evolution, and transfer performance. In future work, we will include patients with airway abnormalities (e.g., with subglottic stenosis, an airway disease affecting airway geometry) in our analyses. This would allow us to further assess our \texttt{NAISR} model by exploring if our estimated model of normal airway shape can be used to detect airway abnormalities. 

%-------------------------------------------------------------------------
\clearpage
