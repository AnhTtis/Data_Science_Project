\subsection{Filter number in SFPN and U-SFPN}

For fair comparisons, all the tested SemanticFPN~\cite{cPanopticFPN} (SFPN) models (in the main paper and this supplementary) use the same number of filters as U-SFPN (i.e. 256).


\subsection{HFGD on more backbones}

In Tab.~\ref{tab:HFGD:MoreBackbones}, We tested more backbones (marked with $\dagger$) for SemanticFPN and HFGD, including ConvNeXt-L and ConvNeXtV2-L on Pascal Context dataset. 
The training iteration is set to 30k for the ResNet-50 models using SGD and 40k for the models (i.e. ConvNeXt-L and ConvNeXtV2-L) using AdamW optimizer.
% , the training iteration is set to 40k. 

HFGD still brings a gain more than 1\% mIOU over SemanticFPN even for a very powerful ConvNeXtV2-L backbone that is pretrained with MAE~\cite{cMAE} technique.

\input{appendix/tables/tab_more_backbones}

\subsection{Visualisations on COCO-Stuff-164k dataset}
Due to space limit,
% limited space in the main paper, 
we present visual comparisons on COCOStuff-164k~\cite{cCocoStuff} in Fig.~\ref{fig:CFGD:COCOStuff-ConvNeXt-L-Vis}. 
% 
Both SemanticFPN and HFGD (OS=4) use ConvNeXt-L as the backbone and are trained in the same setting. 
% 
The results are obtained using multi-scale + flipping. 
% The reader may zoom in to see the difference better. 


% As presented in Fig.~\ref{fig:CFGD:COCOStuff-ConvNeXt-L-Vis} , 
Overall, our HFGD has much better accuracy than SemanticFPN especially on the thin/small objects.
% under the same condition. 
% Additionally, HFGD has an even better precise segmentation result on thin/small objects than SemanticFPN, even if they all perform in the same output stride. 
% As for 
For example, SemanticFPN failed to segment the personâ€™s arm (first row in Fig.~\ref{fig:CFGD:COCOStuff-ConvNeXt-L-Vis}).
% , as shown in the first row of Fig.~\ref{fig:CFGD:COCOStuff-ConvNeXt-L-Vis}.
% Furthermore, as shown 
In the last row of Fig.~\ref{fig:CFGD:COCOStuff-ConvNeXt-L-Vis}, SemanticFPN missed almost all the birds while our HFGD can correctly locate most of them.
% is even much better than the ground truth.

\begin{figure}[!h]
\centering
\includegraphics[width=1.0\linewidth]{images/vis_cocostuff_convnext-l_vs.pdf}
\caption{
Visual comparisons on COCOStuff-164k between SemanticFPN and our HFGD (OS=4).
Black color in the GT indicates the ignored pixels.
All models used ConvNeXt-L as the backbone.
The results are obtained using multi-scale flipping protocol.
% Our HFGD is using OS=4 on U-SFPN.
Zoom in to see their differences better.
}
\label{fig:CFGD:COCOStuff-ConvNeXt-L-Vis}
\end{figure}

\subsection{Future work}

The CAE plays an very important role for the final accuracy since its output high-level features is guiding the upsampling branch.
% 
Luckily, the extra computation cost is usually limited since we append it after the $OS=32$ feature maps.
% extra context enhancement operations (i.e. CAE) is conducted on OS=32, .
So we could probably use the latest modules to further improve the accuracy in the futher.
% , which 

% Since HFGD can accurately upsample low-resolution high-level feature maps to high-resolution, more powerful and accurate CAE modules can be explored in future work. 
% % 
% The computational cost of feature encoding is no longer a concern because the computational cost in OS=32 is not very big. 
% % 
% The U-SFPN + HFGD can accurately upsample it to the final high-resolution.