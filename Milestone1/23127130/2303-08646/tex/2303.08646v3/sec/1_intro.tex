\section{Introduction}
\label{sec:hfgd:intro}

Semantic Segmentation is a fundamental task in computer vision, which densely predicts per-pixel class for a given image.
%
Most existing methods include an encoder (\ie{~backbone}) to output coarse (low-resolution) high-level features and a decoder to recover lost spatial information to output high-resolution final results.

Due to the lack of densely labeled images, existing segmentation methods typically use pre-trained backbones on large-scale image classification datasets to extract high-level semantic features that are more expressive and generalizable\footnote{The scales of common semantic segmentation datasets vary from 2.9K training images in Cityscapes to 118K in COCOStuff while ImageNet-1K/21K contains 1.2M/14M images.}.
%
Popular classification backbones  (\eg ResNet~\cite{cResnet}, EfficientNet~\cite{cEfficientNet}, Swin~\cite{cSwin} and ConvNeXt~\cite{cConvNeXT}) 
typically include multiple downsampling layers, resulting in small feature maps with an output stride~\cite{cDeepLab} of 32 (OS=32).
%
However, the feature maps generated by the OS=32 are too coarse to obtain per-pixel classifications that are accurate and detailed enough, such as object boundaries and small/thin objects.
%
So, many recent works have investigated stronger and more efficient upsamplers.

In one line of works, dilation-based methods~\cite{cDeepLab,cPSPNet,cDeepLabV3Plus,cCCNet,cCFNet,cACFNet,cOCR,cCPN,cDualAttention,cDenseASPP} replace the downsampling operations in the backbone with dilated convolutions to prevent resolution reduction.
Dilation-based methods converge faster and generalize better with effective utilization of pre-trained weights and no introduction of random weights.
%
The limitations of dilation are obvious: it only applies to CNN-based backbones and comes with high computational cost.

In another line of works~\cite{cUper,cFaPN}, an upsampler branch is introduced (\eg SemanticFPN~\cite{cPanopticFPN}) to incorporate fine details from low-level features into upsampled high-level features.
Although computationally more efficient, they are often less effective than dilation-based methods since new random weights are required, and they can only be trained with limited segmentation data.
% \hy{
What's worse, the originally good high-level features may be contaminated during the fine-tuning (Fig.~\ref{fig:hfgd:concept} and Sec.~\ref{sec:problem}).

After identifying this root cause, our key insight is to \emph{protect} the good (high-level) backbone features and use its \textit{\textbf{h}}igh-level \textit{\textbf{f}}eatures as \textit{\textbf{g}}uidance (HFG) during the training of the upsampler branch.
%
Specifically, we first isolate/protect the backbone from the upsampler via proper stopping gradient operations.
Secondly, the training of the upsampler is guided/regularized by the good high-level backbone features since we force the upsampler features to mimic the backbone features.
From the perspective of distillation, the backbone branch is the teacher, and the upsampler branch is the student, except that the upsampler (student) uses information from the backbone (teacher) since they are parts of one single network.

To further push the upper limit of HFG, we propose to introduce an \textit{\textbf{c}}entext \textit{\textbf{a}}ugmented \textit{\textbf{e}}ncoder (CAE) to enhance the high-level backbone feature.
% 
Experimentally, our CAE design can effectively operate on OS=32 feature maps, striking a good balance between efficiency and effectiveness.
We also make some modifications to SemanticFPN to better suit HFGM and (optionally) produce more detailed predictions in OS=2.

In summary, our contributions include:
\begin{itemize}
    \item We first identify the issues that limit the accuracy of existing pyramid-based upsamplers (\eg SemanticFPN).
    %
    \item  %To address the issue, 
    We propose to use \textit{\textbf{h}}igh-level \textit{\textbf{f}}eatures as \textit{\textbf{g}}uidance (HFG) for the upsampler learning and protect the backbone features from being contaminated as previous methods.
    %
    \item To further push the upper limit, we propose \textit{\textbf{c}}entext \textit{\textbf{a}}ugmented \textit{\textbf{e}}ncoder (CAE) to enhance the high-level guidance features and 
    % make some modifications on SemanticFPN to fit the proposed HFG better.
    modify SemanticFPN to fit the proposed HFG better.
    %
    \item 
    % 
    Our full HFG decoder(HFGD) achieves state-of-the-art accuracy on Pascal Context, COCOStuff164k, and Cityscapes test set among methods that do not use extra training data.
\end{itemize}