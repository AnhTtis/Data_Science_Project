\section{Algorithm}
\vspace{-0.1in}
% We present \peralgabbr{} (\peralgname) a system that takes grayscale images as input and reconstructs the state of cables with semi-planar configurations. The first component is a learned cable tracer which estimates the path the cable takes through an image observation. This method is autoregressive, in the sense that at inference, the predicted point is used to build up a spline and is included in the input to the model for the next step of inference (Figure \ref{fig:splash}). The second is  a crossing classifier, which classifies over and under-crossings, combined with a crossing correction method to refine predictions. Together, these estimate the state of the cable.

\peralgabbr{} (Figure \ref{fig:splash}) includes a learned cable tracer that estimates the cable's path through the image and a crossing classifier with a correction method that refines predictions.
% , which is an autoregressive method that uses the predicted points for building the trace as an input to the model for the next step of inference. It also contains a crossing classifier with a correction method that refines predictions. These two pieces collectively estimate the cable's state.

\begin{figure}[!t]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/CoRL_Sim_Real_Cables_Figure.pdf}
    \caption{\textbf{Cropped images of simulated and real cables for training \peralgabbr{}}: On the left are simulated cable crops augmented with Gaussian noise, brightness, and sharpening to match the real images (right).}
    \label{fig:trace-data}
    \vspace*{-0.15in}
\end{figure}

\subsection{Learned Cable Tracer Model}
We break the problem of cable tracing down into steps, where each step generates a probability distribution for the next point based on prior points. To achieve this, we employ a learned model that takes an image crop and trace points from previous iterations and predicts a heatmap representing the probability distribution of the next pixel's location. By operating on local information within crops, the model mitigates overfitting and facilitates sim-to-real transfer, focusing on local characteristics rather than global visual and geometric attributes like knots.

More formally, representing the grayscale image as $I$, and each trace $s_{i,\mathrm{tot}}$ in the image as a sequence of pixels $s_{i,0}, s_{i,1}, ... s_{i,n}$, we break the probability distribution over traces conditioned on the image into smaller, tractable pieces using the chain rule of probability. $f_\theta$ is a learned neural network, $\mathrm{crop}(I, p)$ is a crop of image $I$ centered at pixel $p$, and $k$ is the context length.

\vspace{-15pt}
$$P(s_{i,\mathrm{tot}} | \mathrm{s_{i,0}}, \mathrm{I}) = \prod_{j=1}^n P(s_{i,j} | s_{i,0}...s_{i,j-1}, I) \approx \prod_{j=1}^n f_\theta(s_{i,j} | s_{i,j-k}...s_{i,j-1}, \mathrm{crop}(I, s_{i,j-1}))$$


\label{sec:tracer}
\vspace{-0.13in}
\subsubsection{Dataset and Model Training}
\label{sec:dataset}

% \kaushik{explain choice of specific cable and why: thickness, color, max turning radius}
To train the crossing classifier, we simulate a diverse range of crossing configurations to generate a dataset. We use Blender~\cite{blender} to create 30,000 simulated grayscale images that closely resemble real observations (Fig. \ref{fig:trace-data}). Cable configurations are produced through three methods with random Bezier curves: (1) selecting points outside a small exclusion radius around the current point, (2) intentionally creating near-parallel segments, and (3) constraining specific cable segments to achieve a dense and knot-like appearance in certain spatial regions. The curves are colored white and have slightly randomized thicknesses.

We randomly sample image crops along the cable of interest, with a focus on cable crossings (representing $95\%$ of samples). The simulated images are augmented with pixel-wise Gaussian noise with standard deviation of 6, brightness with standard deviation of 5, and sharpening to imitate the appearance of real cables. Additionally, we include a smaller dataset of 568 hand-labeled real cable crop images, sampled such that it comprises approximately 20\% of the training examples. Training employs the Adam optimizer \cite{kingma2014adam} with pixelwise binary cross-entropy loss, using a batch size of 64 and a learning rate of $10^{-5}$.

\subsubsection{Model Architecture and Inference}

We use the UNet architecture \cite{Iakubovskii:2019}. We choose trace points spaced approximately 12 pixels apart, chosen by grid search, balancing between adding context and reducing overfitting. We further balance context and overfitting by tuning the crop size ($64 \times 64$) and the number of previous points fed into the model (3) through grid search.

Naively training the model for cable tracing in all possible initial directions leads to poor performance, as it would require learning rotational equivariance from data, reducing data efficiency. To overcome this, we pre-rotate the input image, aligning the last two trace points horizontally and ensuring the trace always moves left to right, optimizing the model's capacity for predicting the next trace point. We then rotate the output heatmap back to the original orientation.

During inference, initializing the trace requires an input of a single start pixel along the cable (in practice, one endpoint). We use an analytic tracer as in \cite{shivakumar2022sgtm} to trace approximately 4 trace points and use these points to initialize the learned tracer, which requires multiple previous trace points to predict the next point along the trace.

The tracer autoregressively applies the learned model to extend the trace. The network receives a cropped overhead image centered on the last predicted trace point ($64\times64$ pixels). Previous trace points are fused into a gradient line (shown in Figure \ref{fig:splash}), forming one channel of the input image. The other two channels contain an identical grayscale image. The model outputs a heatmap ($64\times64\times1$) indicating the likelihood of each pixel being the next trace point. We greedily select the $\argmax$ of this heatmap as the next point in the trace. This process continues until leaving the visible workspace or reaching an endpoint, which is known using similar learned detectors as~\citet{shivakumar2022sgtm}.

% \begin{figure}[!t]
%     \centering
%     \includegraphics[width=1.0\linewidth]{figures/CoRL_Tracer_Model.pdf}
%     \caption{\textbf{Input and Prediction of Iterative Learned Cable Tracer}: the iterative learned cable tracer takes small crops around the cable and one step at a time, predicts the next point in the trace. The input crop is a 64x64x3 crop centered on the previous trace point. The first channel contains the previous trace points within the crop. The second and third channel are the gray scale image of the crop. The prediction is a 64x64 heatmap, where we infer the $\argmax$ of the heatmap to be the next point in the trace. \kaushik{can we remove this image given the updated cover image?} \vainavi{yes, in fact we don't even reference this figure anywhere anymore}}
%     \label{fig:trace-io}
%     \vspace*{-0.18in}
% \end{figure}

\vspace{-0.1in}
\subsection{Over/Undercrossing Predictor}
\vspace{-0.05in}

\label{sec:classifier}
% To convert the 2D trace of a cable into a state for the downstream task of untangling, we use a convolutional neural network (CNN) to classify over and under-crossings in the cable.

\subsubsection{Data and Model Input}
\vspace{-0.1in}
We use $20 \times 20$ simulated and real over/undercrossing crops. The 568 real images are oversampled such that they are seen 20\% of the time during training. Augmentation methods applied to the cable tracer are also used here to mimic the appearance of real cable crops. The network receives a $20 \times 20 \times 3$ input crop. The first channel encodes trace points fused into a line, representing the segment of interest. To exploit rotational invariance, the crop is rotated to ensure the segment's first and last points are horizontal. The second channel consists of a Gaussian heatmap centered at the target crossing position, providing positional information to handle dense configurations. The third channel encodes the grayscale image of the crop.

\subsubsection{Model Architecture and Inference}
\vspace{-0.1in}
\label{subsubsec:crossingcorrection} % done for legacy reasons
We use a ResNet-34 classification model with a sigmoid activation to predict scores between 0 and 1. The model is trained using binary cross-entropy loss. We determine the binary classification using a threshold of 0.275 (explanation for this number is in the appendix Section \ref{sec:ou_appendix}). The algorithm uses the fact that each crossing is encountered twice to correct errors in the classifier's predictions, favoring the higher confidence detection and updating the probability of the crossing to ($1 -$ the original value), storing the confidences for subsequent tasks. The learned cable tracer, over/undercrossing predictor, and crossing correction method combined together result in a full cable state estimator: \peralgabbr{}. 

% \subsection{Crossing Correction}
% % We define $ID = 0$ for undercrossings and $ID = 1$ for overcrossings.

\subsection{Using \peralgabbr{} in Downstream Applications}
\vspace{-0.1in}
\textbf{Tracing in Multi-cable Settings:} We apply \peralgabbr{} to inspection in multi-cable settings for tasks like locating the power adapter of a cable tangled with other visually similar cables given the endpoint. \peralgabbr{} is fed an endpoint and returns a trace to the adapter connected to it.

\textbf{Learning from Demonstrations:} We use \peralgabbr{} to enable physical, state-based knot tying in the presence of distractor cables, which is much more challenging for a policy operating on RGB observations rather than underlying state. Demonstrations are pick-place actions, parameterized by absolute arc-length or arc-length relative to crossings. More details are in Appendix Section \ref{sec:demos_appendix}. 

\textbf{Robot Cable Untangling:} For cable untangling, \peralgabbr{} is combined with analytic knot detection, untangling point detection techniques, and bi-manual robot manipulation primitives to create a system for robot untangling. Appendix Section \ref{sec:untangling_deets} contains more details.
