\section{Methods}

We present \peralgabbr{} (\peralgname) a system that takes grayscale images as input and reconstructs the state of a cable with semi-planar knots and crossings, performs knot detection, and selects graspable points for untangling. The first component is an iterative, learned cable tracer which estimates the path the cable takes through an image observation, combined with a crossing classifier which classifies over and under-crossings. Together, these estimate the state of the cable. \peralgabbr{} then analyzes the state to detect knots and find graspable points for untangling. We will reference these points as \emph{cage-pinch points} since during manipulation, one of these points receives a pinch grasp and the other a cage grasp (Section \ref{sec:superman}).


\begin{figure}[!t]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/Sim_v_Real_Trace_Imgs.pdf}
    \caption{\textbf{Simulated and real crops used for training \peralgabbr{}}: On the left are simulated cable crops augmented with Gaussian noise, brightness, and sharpening to match the real images (right) as closely as possible.}
    \label{fig:trace-data}
    \vspace*{-0.18in}
\end{figure}

\subsection{Learned Cable Tracer}
We frame the problem of tracing a cable as estimating the most likely sequence of points that the cable passes through, where the goal of each step is to produce a probability distribution over the next point given the past points. This module estimates the spline (``trace") of the cable in an image by sequentially performing inference using a neural network on image crops. At each step, the model takes in a crop of the image along with trace points from previous iterations and predicts a heatmap, where we interpret the $\argmax$ as the next point along the trace. Since it operates on crops, the model suffers less from overfitting and benefits from more easy sim-to-real transfer as it operates on local information about the cable, rather than global visual and geometric appearance of knots.
\label{sec:tracer}
\subsubsection{Initialization}
To initialize the trace, we supply a start pixel along the cable (in practice, one endpoint). We use an analytic tracer as in \cite{shivakumar2022sgtm} to trace approximately 96 pixels, then use these points to initialize the learned tracer, as the model requires previous trace points to predict the next point along the trace.

\subsubsection{Model Architecture and Inference}
After initialization, the tracer sequentially applies a learned model to grow the trace. At each step, the network receives an input of an overhead image cropped to the center of the last predicted trace point, $64\times64$ pixels. To provide the model with information about the cable's previous path, we fuse the previous points of the trace into a gradient segmented line with the same thickness as the cable. The most recently traced point is brightest and the line decreases in brightness until it exits the crop. This is included in one channel of the input image. The other two channels contain an identical version of the grayscale image. The input dimension to the model is thus $64\times 64\times 3$. The model outputs a $64\times 64\times 1$ heatmap indicating the likelihood of each pixel being the next step in the cable trace. We choose the highest point in this heatmap as the next point in the trace. This process is applied iteratively until the tracer reaches another endpoint or leaves the visible workspace.

We use the UNet architecture for the model, which is known to be effective in image segmentation tasks \cite{Iakubovskii:2019}. Section \ref{sec:dataset} describes the dataset and training process. Each point in the trace is approximately 12 pixels apart, chosen by grid search to provide a balance between adding context and reducing overfitting. To reduce the input space for the model and thus increase data efficiency, we pre-rotate the input image such that the last two points of the trace are aligned horizontally and the trace always travels left to right with the most recently traced point being the right most point. We explore another important tradeoff between context and overfitting via grid search by tuning the size of the crop, $64 \times 64$, and number of previous points inputted into the model, 3.

%Providing more or less context to the model is a way of controlling the bias-variance tradeoff for our iterative model.

\subsubsection{Dataset and Model Training}
\label{sec:dataset}
To train the Learned Tracer model, we leverage simulation to procedurally generate a dataset which encompasses a wide distribution of crossing configurations. sing Blender~\cite{blender}, we collect a dataset of 30,000 simulated grayscale images, whose visual appearance closely matches real observations (Fig. \ref{fig:trace-data}). Cable configurations are generated via random Bezier curves through the following 3 methods: (1) a weighted combination of successively choosing random points outside of a small exclusion radius around the current point, (2) segments intentionally designed to be near-parallel, and (3) other sections of cable designed to appear dense and knot-like by confining certain segments of the cable to regions in space.

We sample image crops randomly along the cable, with $95\%$ of samples distributed on cable crossings, as these represent the challenging cases. The simulated images are augmented with Gaussian noise with standard deviation of 6, brightness with standard deviation of 5, and sharpening to imitate the appearance of real cable crops. Additionally, we augment the dataset with a smaller dataset of 568 real, grayscale cable crop images hand-labeled with splines, sampled during training such that real images are approximately 20\% of the examples seen. During training we use the Adam optimizer \cite{kingma2014adam} with pixelwise binary cross-entropy loss, using a batch size of 64 and learning rate of $10^{-5}$.


\begin{figure}[!t]
    \includegraphics[width=1.0\linewidth]{figures/TracerModel.pdf}
    \caption{\textbf{Input and Prediction of Iterative Learned Cable Tracer}: the iterative learned cable tracer takes small crops around the cable and one step at a time, predicts the next point in the trace. The input crop is a 64x64x3 crop centered on the previous trace point. The first channel contains the previous trace points within the crop. The second and third channel are the gray scale image of the crop. The prediction is a 64x64 heatmap, where we infer the $\argmax$ of the heatmap to be the next point in the trace.}
    \label{fig:trace-io}
    \vspace*{-0.18in}
\end{figure}

\subsection{Over/Undercrossing Predictor}
\label{sec:classifier}
To convert the 2D trace of a cable into a topology for the downstream task of untangling, we use a convolutional neural network (CNN) to classify over and under-crossings in the cable.

\subsubsection{Data and Model Input}
 We use simulated and real over/undercrossing crops of size 20x20. Similar to the cable tracer, the 568 real images are oversampled such that they are seen 20\% of the time during training. The simulated data is augmented in the same manner to the cable tracer to imitate the appearance of real cable crossings when observed as 20x20 crops. We provide the network with a 20x20x3 crop as input. The first channel encodes the points of the trace indicating the cable segment of interest (in other words, the cable segment with respect to which we aim to classify the crossing as an over/undercrossing). Similar to how the points are inputted for the learned tracer, the points are fused together into a line segment, but now the line segment does not decrease in brightness as points become less recent. The crop is rotated so the first and last point in the line segment are horizontal. The second channel is a Gaussian heatmap centered at the position of the crossing we aim to classify. This helps deal with dense configurations that can have nearby consecutive crossings captured in the same crop. By receiving a position of interest, the network learns to ignore other crossings. Lastly, as all images are grayscale, the third channel encodes the grayscale image of the cable crossing.

\subsubsection{Model Architecture and Inference}
We use a ResNet-34 classification model to output a prediction score in the interval $[0, 1]$. This model is trained using binary cross-entropy loss with a single output unit with sigmoid activation. We tune a threshold to binarize the output by determining accuracy on a held-out validation set of 75 images on threshold values in the range $[0.05, 0.95]$ at intervals of 0.05. Based on the tuning results, we obtain a threshold of 0.275 such that a prediction score $< 0.275$ corresponds to an undercrossing prediction and a score $\geq 0.275$ corresponds to an overcrossing prediction. We output the raw prediction score along with a scaled confidence value (ranging $[0.5, 1]$) indicating the probability associated with the classifier's prediction.

\subsection{Analytic Knot Detection}
We construct line segments between consecutive points on the trace outputted by the learned cable tracer (Section \ref{sec:tracer}). Crossings are located at the points of intersection of these line segments.
We use the crossing classifier (Section \ref{sec:classifier}) to estimate whether these crossings are over/undercrossings. We also implement probabilistic crossing correction with the aim of rectifying classification errors, as we describe in Section \ref{subsubsec:crossingcorrection}.

We denote the sequence of corrected crossings, in the order that they are encountered in the trace, by $\mathcal{X} = (c_1, ..., c_n)$, where $n$ is the total number of crossings and $c_1, ..., c_n$ represent the crossings along the trace. To reduce the number of actions required to successfully untangle the cable, we algorithmically apply Reidemeister moves I and II to discard non-essential crossings (Fig.~\ref{fig:reid_cc}). We exclude Reidemeister move III from this scheme as it does not lead to a direct reduction in the number of crossings, unlike moves I and II. We are allowed to perform this algorithmic manipulation as Reidemeister moves maintain knot equivalence \cite{reidemeister1983knot}. 

\subsubsection{Crossing Correction}
\label{subsubsec:crossingcorrection}
% We define $ID = 0$ for undercrossings and $ID = 1$ for overcrossings.
Given the assumption of knot semi-planarity, a single crossing location must contain one overcrossing and one undercrossing. In situations where the over/undercrossing classifier incorrectly predicts that the crossings at a location are both overcrossings or both undercrossings, we defer to the detection with higher confidence to correct the crossing assignment. The algorithm updates the probability associated with the corrected crossing to $1 -$ its original value. This is to take into account model uncertainty when calculating confidence scores for the overall knot.

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.85\linewidth]{figures/alg_fig.pdf}
    \caption{\textbf{Untangling Algorithm with \peralgabbr{}}: We first detect the endpoints and initialize the tracer with start points. If we are not able to obtain start points, we perturb the endpoint and try again. Next, we trace. While tracing, if the cable exits the workspace, we pull the cable towards the center of the workspace. If the tracer gets confused and begins retracing a knot region, we perform a partial cage-pinch dilation that will loosen the knot, intended to make the configuration easier to trace on the next iteration. If the trace is able to successfully complete, we analyze the topology. If there are no knots, we are done. If there are knots, we perform a cage-pinch dilation and return to the first step.}
    \label{fig:algorithm}
    \vspace*{-0.18in}
\end{figure*}

\subsubsection{Crossing Cancellation}
Crossing cancellation allows for the simplification of cable structure by removing non-essential crossings, shown in Figure \ref{fig:reid_cc}. It allows the system to filter out some trivial configurations. We cancel all pairs of consecutive crossings ($c_i$, $c_{i + 1}$) in $\mathcal{X}$ for some $j$) that meet any of the following conditions: \begin{itemize}
    \item \emph{Reidemeister I:} $c_i$ and $c_{i + 1}$ are at the same location, or
    \item \emph{Reidemeister II:} $c_i$ and $c_{i + 1}$ are at the same set of locations as $c_j$ and $c_{j + 1}$ ($c_j, c_{j + 1} \in \mathcal{X}$). Additionally, $c_i$ and $c_{i + 1}$ are either both overcrossings or both undercrossings. We also cancel ($c_j, c_{j + 1}$) in this case.
\end{itemize}

We algorithmically perform alternating Reidemeister moves I and II as described. We iteratively apply this step on the subsequence obtained until there are no such pairs left. We denote the final subsequence, where no more crossings can be canceled, by $\mathcal{X}'$.

\subsubsection{Knot Detection}
\label{sec:knot_detection}
We say that a subsequence of $\mathcal{X}'$, $\mathcal{K}_{ij} = (c_i, ..., c_j)$, defines a potential knot if: \begin{itemize}
    \item $c_i$ is an undercrossing, and
    \item $c_j$ is an overcrossing at the same location, and
    \item at least one intermediate crossing, i.e. crossing in $\mathcal{X}'$ that is not $c_i$ or $c_j$, is an overcrossing.
\end{itemize}

The first invariant is a result of the fact that all overcrossings preceding the first undercrossing (as seen from an endpoint) are removable. We can derive this by connecting both endpoints from above via an imaginary cable (as in Section \ref{sec:knot_def}): all such overcrossings can be removed by manipulating the loop formed. The second invariant results from the fact that a cable cannot be knotted without a closed loop of crossings. The third and final invariant can be obtained by noting that a configuration where all intermediate crossings are undercrossings reduces to the unknot via the application of the 3 Reidemeister moves. Therefore, for a knot to exist, it must have at least one intermediate overcrossing.

Notably, these conditions are necessary, but not sufficient, to identify knots. However, they improve the likelihood of bypassing trivial configurations and detecting knots. This increases the system's efficiency by enabling it to focus its actions on potential knots.

\subsection{Algorithmic Cage-Pinch Point Detection}
As per the definition introduced in Section \ref{sec:knot_detection}, given knot $\mathcal{K}_{ij} = (c_i, ..., c_j)$, $c_i$ and $c_j$ define the segments that encompass the knot where $c_i$ is an undercrossing and $c_j$ is an overcrossing for the same crossing. The pinch point is located on the overcrossing cable segment, intended to increase space for the section of cable and endpoint being pulled through. The cage point is located on the undercrossing cable segment. To determine the pinch point, we search from crossing $c_{u1}$ to crossing $c_{u2}$. $c_{u1}$ is the previous undercrossing in the knot closest in the trace to $j$. $u2 > j$ and $c_{u2}$ is the next undercrossing after the knot. We search in this region and select the most graspable region to pinch at, where graspability ($G$) is defined by the number of pixels that correspond to a cable within a given crop and a requirement of sufficient distance from all crossings $c_i$. To determine the cage point, we search from crossing $c_i$ to $c_{k}$ where $i < k < j$ and $c_{k}$ is the next undercrossing in the knot closest in the trace to $c_{i}$. We similarly select the most graspable point. If no points in the search space for either the cage or pinch point are graspable, meaning $G < \mathcal{T}$ where $\mathcal{T}$ is an experimentally derived threshold value, we continue to step along the trace from $c_{u2}$ for pinch and from $c_k$ for cage until $G \geq \mathcal{T}$. This search process is shown in Figure \ref{fig:splash}.

\section{Robot Untangling using \peralgabbr{}}
\label{sec:superman}

\subsection{Manipulation Primitives}
\label{sec:manip}
We use the same primitives as in SGTM 2.0 (Sliding and Grasping for Tangle Manipulation 2.0) \cite{shivakumar2022sgtm} to implement \peralgabbr{} as shown in Figure \ref{fig:algorithm} for untangling long cables. We add a \emph{perturbation} move. 

\subsubsection{Cage-Pinch Dilation} We use cage-pinch grippers as in ~\citet{viswanath2022autonomously}. We have one gripper cage grasp the cable, allowing the cable to slide between the gripper fingers but not slip out. The other gripper pinch grasps the cable, holding the cable firmly in place. This is crucial for preventing knots in series from colliding and tightening during untangling. The \textit{partial} version of this move introduced by \citet{shivakumar2022sgtm} separates the grippers to a small, fixed distance of 5 cm.

\subsubsection{Reveal Moves}
First, we detect endpoints using a Mask R-CNN object detection model. If both endpoints are visible, the robot performs an \emph{Endpoint Separation Move} by grasping at the two endpoints and then pulling them apart and upwards, away from the workspace, allowing gravity to help remove loops before placing the cable back on the workspace. If both endpoints are not visible, the robot performs an \emph{Exposure Move}. This is when it pulls in cable segments exiting the workspace. Building on prior work, we add a focus on where this move is applied. While tracing, if we detect the trace hits the edge, we perform an exposure move at the point where the trace exits the image. 

\subsubsection{Perturbation Move} If an endpoint or the cable segment near an endpoint has distracting cable segments nearby, making it difficult for the analytic tracer to trace, we perturb it by grasping it and translating in the x-y plane by uniformly random displacement in a $10$cm $\times$ $10$cm square in order to separate it from slack.

\subsection{Cable Untangling System}
Combining \peralgabbr{} and the manipulation primitives from Section \ref{sec:manip}, the cable untangling algorithm works as follows:
First, detect endpoints and initialize the learned tracer with 6 steps of the analytic tracer. If \peralgabbr{} is unable to get these initialization points, perturb the endpoint from which we are tracing and return to the endpoint detect step. Otherwise, during tracing, if the cable leaves the workspace, perform an exposure move. If the trace fails and begins retracing itself, which can happen in denser knots, perform a partial cage-pinch dilation as in \cite{shivakumar2022sgtm}. If the trace completes and reaches the other endpoint, analyze the topology. If knots are present, determine the cage-pinch points for it, apply a cage-pinch dilation move to them, and repeat the pipeline. If no knots are present, the cable is considered to be untangled. The entire system is depicted in Figure \ref{fig:algorithm}.

% \begin{figure}[h!]
% \vspace{-12pt}
% % \algnewcommand{\LineComment}[1]{\State \(\triangleright\) #1}%
% \MakeRobust{\Call}%
% \begin{minipage}[t]{0.45\textwidth}
% \begin{algorithm}[H]
% \caption{\algabbr{}}
% \label{alg:untangle_alg} 
% \begin{algorithmic}[1]
% \State \text bf{Input:} $772 \times 1032 \times 4$ RGB-D workspace image
% \State done = False
% \State $t$ = current time
% \While {not done and $ t < T_{max}$}
%     \While {visible endpoints $== 0$}
%         \State {exposure move}
%     \EndWhile
%     \If {knot}
%         \State {Perception for cage-pinch points $\rightarrow$ dilate}
%     \Else
%         \If {trace left image}
%             \If {visible endpoints $== 2$}
%                 \State {reidemeister move}
%             \Else
%                 \State {exposure move (trace point)}
%             \EndIf
%         \Else 
%             \State done = True
%         \EndIf
%     \EndIf
%     \State $t$ = current time
% \EndWhile
% \end{algorithmic}
% \end{algorithm}
% \end{minipage}
% \label{fig:superman}
% \vspace{-6pt}
% \end{figure}