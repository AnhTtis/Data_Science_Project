\section{Related Work} \label{relatedworks}


\noindent \textbf{Dexterous Manipulation} Dexterous manipulation has been a long-standing problem in robotics~\cite{rus1999hand, dex_overview, sliding_dex, rolling_dex, pivot_dex, dex_1, dex_2, dex_3, dex_4, dex_5, dex_6, dex_7, dex_8, rl-openai}. Among these works, dexterous in-hand manipulation receives a lot of attention in recent years~\cite{dexhand_1_kumar2014real_time_behaviour_synthesis, dexhand_2_Bhatt2021surprisingly, dexhand_3_bai2014dexterous, dexhand_4_morgan2022complex, rl-openai}. Several early methods propose to tackle the in-hand manipulation problem with analytical model-based approaches~\cite{dexhand_1_kumar2014real_time_behaviour_synthesis, dexhand_3_bai2014dexterous}. Nevertheless, they pose certain hypotheses about the objects and the controllers, which makes it hard to scale to more complex tasks. To overcome this limitation, deep Reinforcement Learning has been applied recently on dexterous manipulation~\cite{rl-openai, dextreme, corl21-inhand, qin2022dexpoint, chen2022visual, qi2022hand}. Building on these works, incorporating demonstrations in with imitation learning also leads to better sample efficiency and more natural manipulation behaviors~\cite{qin2022dexmv, dapg, arunachalam2022dexterous, qin2022one, wu2023learning, ye2022learning, liu2022herd, patel2022learning, arunachalam2022holo}. However, most in-hand manipulation methods are still highly relying on visual inputs~\cite{rl-openai,dextreme,chen2022visual}. For example, Chen et al.~\cite{chen2022visual} propose to perform in-hand object re-orientation  using depth image input, and new hardware is designed to avoid heavy occlusion. Instead of relying on vision which faces the occlusion problem with general hardware, recently, several works~\cite{qi2022hand, Sievers2022, Pitz2023} propose to perform in-hand object rotation without both visual and explicit tactile sensing. The idea of these works is that we can infer the object's information from the implicit tactile information inside proprioception data. However, these works either only consider object rotation on the fingertip with relatively small finger motion, or the rotation of a limited set of objects. Compared to these works, our system explicitly use touch sensors to percept hand-object interaction, and can solve the object rotation problem on the palm for diverse types of objects, which involves complex object motion and is more challenging. We also find that using explicit tactile sensing enables our touch-based policy to generalize to unseen objects, which is not shown by previous works. 
 
\noindent \textbf{Tactile Robotic Manipulation} Biological evidence suggests that tactile information is crucial for the success of human dexterity~\cite{human_tactile}. This basic observation naturally motivates the research of tactile robotic manipulation~\cite{6943031, molchanov2016contact, tactile_insertion, bhattacharjee2015material, navarro2015active, zhu2022learning, roller_tactile2022, suresh2022midastouch, tactile_slam, tandem, object_track2022patchgraph, visiotactile, manipulation_by_feel, smith2021active, tactile2020alberto, roller_tactile2022, murali2020learning, taylor2022gelslim,https://doi.org/10.48550/arxiv.1907.13098,gao2022objectfolder,bhirangi2021reskin}. A fundamental question is what kind of touch information is essential. Existing works propose to extract local geometry, force and torque, contact event, and material properties with various sensors to help manipulation~\cite{tactile2020review}. Different from these works, we find that even using the simplest binary contact signal provided by a sparse sensor array can be helpful for a high-dimensional manipulator. This is also found in~\cite{bin_contact_1, bin_contact_2, liang2020hand} where binary contact signals are used for manipulation, object tracking and exploration. However, they focus on low-DOF manipulators rather than a multi-finger robot hand. In the dexterous hand research, Buescher et al.~\cite{tactile_skin} develop a skin-based tactile sensing system on the Shadow hand, which has a similar but denser sensor layout over the palm compared with our work. However, it is still unclear how to use it with a control method to solve  in-hand rotation as in our work. Another important question in tactile robotic manipulation is how to simulate the tactile event so as to perform Sim2Real transfer. Researchers have proposed many approaches and strategies for tactile simulation~\cite{moisio2013model,habib2014skinsim,tactile_sim,church2022tactile,si2022taxim,bi2021zero}. For example, Xu et al.~\cite{tactile_sim} propose a method to simulate normal and shear tactile force field on the contact surface. Compared with these works, our method does not require any extra simulation design but can leverage the built-in contact simulation of an existing physics simulator. 
