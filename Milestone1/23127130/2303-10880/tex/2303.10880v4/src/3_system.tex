\section{Tactile Dexterous Manipulation System}

\subsection{Real-word System Setup}
Our hardware setup consists of a XArm robot arm and a 16-DOF Allegro Hand with a contact sensor array. The array consists of 16 contact sensors, which are attached to different parts of the allegro hand including the palm and tips as shown in Figure~\ref{fig:teaser}(left). The used contact sensors are based on Force-Sensing Resistors (FSR), whose resistance will change when an external force is applied to its surface. These sensors are very sensitive to force and widely used in robotics. We use an STM32F microcontroller to collect the analog voltage signals of each sensor and then forward digital signals to the host.



While these contact sensors are able to output the \textbf{continuous} contact force measurement, the signals are usually nonlinear and noisy. As a result, it should undergo necessary preprocessing before being used for control. We \textbf{binarize} these measurements with respect to a selected threshold $\theta_{th}$ and use this binary contact signal for control. The advantage of using binary signals is that it can reduce the gap between the simulation and the real robot, and simplify the Sim2Real transfer procedure. When using the exact force measurement as observation, it is difficult to align the measurement between the simulation and the real robot, especially since there are still errors in aligning the analog voltage signals to the exact force measurement. In contrast, we can easily calibrate the binarized measurement by adjusting the threshold. 


\subsection{Simulation Setup}

In this paper, we use the IsaacGym simulator~\cite{isaacgym} for the training of our tactile manipulation system. The simulation setup is shown in Figure~\ref{fig:teaser}(left). We simulate each contact sensor as a fixed link on the finger and palm links. We fetch the net contact force $F=[F_x, F_y, F_z]$ over each sensor link provided by the simulator at each simulation step, and use $\Vert F\Vert$ as the simulated contact force measurement. Then, we binarize the measurement with another threshold $\tilde\theta_{th}$, Note that the force provided by the sensor's parent link does not contribute to the net contact force. We adjust the threshold $\tilde\theta_{th}$ of these sensors to ensure that they have similar behavior to that in the real. We use a $\tilde\theta_{th} = 0.01N$ in simulation.
\begin{figure}[t]
    \centering 
    \includegraphics[width=\linewidth]{src/figs/3_system_function_only.pdf}

    \caption{Two major functionalities of our sensors: sensing (i) the objects' in-hand position, and (ii) the critical contact during the dexterous manipulation process. Note that we use finger cots to increase the friction and we still have force-sensing resistors inside the finger cots.}
    
    \label{fig:setup_and_function}
    \vspace{-0.1in}
\end{figure}
\subsection{Benchmark Problem: In-hand Rotation}
In this paper, we study the dexterity of our system by using it to solve an in-hand rotation task. In this in-hand rotation task, an object is initialized in the palm and the robot hand is then required to rotate this object around a given rotation axis. 

When we are doing in-hand object rotation, the object motion is more complex than that in finger-tip rotation mentioned in section ~\ref{relatedworks} and brings additional challenges. Specifically, the object can slide or roll in the palm during in-hand manipulation. Due to this complex motion pattern, explicit feedback from tactile or vision becomes necessary for successful manipulation. Otherwise, we are unable to infer the current state of the object and fail to push and rotate it in a secure way.

\subsection{Discussion: What information can sensors provide?}
We summarize two kinds of information our system can provide for control as follows, though its sensing is sparser than that of a real human hand. 


\textbf{Position information.} The contact sensors can inform the policy where the object is at each time step. One example is shown in Figure~\ref{fig:setup_and_function} (left). In this example, a cuboid is placed on the palm without contacting any fingertip. At this moment, the only way to infer the position of the object is by reading the measurement of the contact sensors on the palm. This measurement can provide an estimation of the object's position~(i.e., at the center), based on which the controller can decide the approximate movement of each finger, for example, driving the thumb toward the center. Without this information, the thumb can move to the right and can not come into contact with the object to initiate a rotation. 

\textbf{Interaction information.} During in-hand object rotation, it is essential to ensure that the fingertip in charge of the rotation is indeed interacting with the object, see Figure~\ref{fig:setup_and_function} (right). Otherwise, the finger may not be able to push against the object leading to a failure, which may cause the object to move to an unstable position, and even fall out of the hand.

\begin{figure}[t]
    \centering 
    \includegraphics[width=\linewidth]{src/figs/3_system_diagram-cropped.pdf}
    \caption{Overview of the control process. The state contains tactile information, joint position, previous target, and task information like rotation axis~(not shown in the figure). The policy then uses the stacked state to get the relative action, and the next target joint position is calculated. The new target is then fed to a PD controller.}
    \label{fig:realpipeline}
    \vspace{-0.1in}
\end{figure}



