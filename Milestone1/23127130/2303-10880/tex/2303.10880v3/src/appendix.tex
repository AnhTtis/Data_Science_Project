\appendix

\subsection{System Video Demo}
We provide a video demo of our system at {\color{blue}{\texttt{\url{http://touchdexterity.github.io}}}}. The raw video demo can also be founded in the submitted files.

\subsection{PPO Training Hyperparameters}
We use the proximal policy optimization~(PPO) algorithm to train our control policy. The setup of the PPO algorithm is as follows. We use an advantage clipping coefficient $\epsilon = 0.2$. We use a horizon length of 16, with $\gamma=0.99$ and generalized advantage estimator~(GAE)~\cite{schulman2015high} coefficient $\tau=0.95$. The policy network is a three-layer MLP with ELU activation. Its hidden layer is [512, 256, 256]. The policy network's learning rate is set to 1e-4, with an adaptive KL threshold of 0.02. The value network is a four-layer MLP with ELU activation. Its hidden layer is [512, 512, 256, 256]. The value network's learning rate is set to 5e-4, with an adaptive KL threshold of 0.016.  We normalize the state input, value, and advantage during training. We use a gradient norm of 1.0. The minibatch size is set to 16384.

\subsection{Improving Sim2Real Transfer}
\noindent \textbf{Domain Randomization} We use several domain randomization techniques to improve the Sim2Real transfer. The details are shown in Table~\ref{table:dr}.
\begin{table}[htbp]
\renewcommand\arraystretch{1.05}
\caption{Domain Randomization Setup}
\centering
\begin{tabular*}{0.87\linewidth}{l@{\extracolsep{\fill}}c}
\toprule
Object: Mass~(kg)                & [0.2, 0.6]    \\
Object: Friction                   & [0.3, 3.0]     \\
Object: Shape              & $\times\mathcal{U}(0.95, 1.05)$     \\
Object: Initial Position~(cm) &  $+\mathcal{U}(-0.015, 0.015)$ \\
Hand: Friction    & [0.3, 3.0]    \\
\midrule
PD Controller: P Gain         &  $\times\mathcal{U}(0.66, 1.33)$      \\
PD Controller: D Gain     &  $\times\mathcal{U}(0.80, 1.20)$     \\
\midrule
Sensor: Lag Probability         & 0.25      \\
Sensor: Drop Rate               & 0.1      \\
\midrule
Random Force: Scale                    & 0.2       \\
Random Force: Probability              & [0.2, 0.25]    \\
Random Force: Decay Coeff. and Interval & 0.99 every 0.1s     \\ 
\midrule
Joint Observation Noise.           & $+\mathcal{U}(-0.05, 0.05)$     \\
Action Noise.    & $+\mathcal{U}(-0.06, 0.06)$   \\
\bottomrule
\end{tabular*}
\label{table:dr}
\end{table}

\noindent \textbf{System Identification} We apply system identification to align the behavior of the PD controller in simulation to that in the real. We tune the PD coefficients to ensure that the responses of the controllers to the impulse and sinusoidal inputs are aligned. We find this step crucial for successful Sim2Real transfer.
\begin{figure}[t]
\centering
\includegraphics[width=0.9\linewidth]{src/figs/A_sensor_ids.png}
\caption{Contact sensor map.}
\label{fig:sensor_map}
\vspace{-0.4cm}
\end{figure}
\subsection{Reward Design}
\noindent \textbf{Rotation Reward}
\begin{equation}
    r_{rot} =  {\rm clip} (\Delta \theta, -0.157, 0.157). 
\end{equation}

\noindent \textbf{Velocity Reward}
\begin{equation}
    r_{vel} = -\Vert v_t\Vert.
\end{equation}

\noindent \textbf{Falling Reward~(Penalty)}
\begin{equation}
    r_{fall} = -50.0.
\end{equation}

\noindent \textbf{Work Reward~(Penalty)}
\begin{equation}
    r_{work} = -\langle|\tau|, |\dot{q_t}|\rangle.
\end{equation}

\noindent \textbf{Torque Reward~(Penalty)}
\begin{equation}
    r_{torque} = -\Vert\tau\Vert.
\end{equation}

\noindent \textbf{Distance Reward}
\begin{equation}
    r_{dist} = {\rm mean}_{i=0,1,2,3}({\rm clip} (0.1 /(0.02 + 4d(x_{tip}^i, x_{obj})), 0, 1)).
\end{equation}


\noindent The overall reward function is
\begin{equation}
    r_t = w_1r_{rot} + w_2r_{vel} + w_3r_{fall} + w_4r_{work} + w_5r_{torque} + w_6r_{dist}.
\end{equation}
The setup of each weight: $w_1 = 20.0, w_2 = 0.1, w_3 = 1.0, w_4 = 0.0003, w_5 = 0.0003, w_6=0.1$.

\subsection{More Sensor Response Examples}
We show more examples of sensor activation trajectories collected in real-world experiments in Figure~\ref{fig:more_curve}. These trajectories are collected on different objects. We can observe different activation patterns in the trajectories. 
\begin{figure*}[t]
\subfigure{\includegraphics[width=\textwidth]{src/figs/A_sensor_curve_appendix2.pdf}}
\vspace{-0.2in}
\caption{More sensor activation trajectories in the real world experiments. The curves are collected on different objects and display different patterns.}
\label{fig:more_curve}
\vspace{-0.4cm}
\end{figure*}
