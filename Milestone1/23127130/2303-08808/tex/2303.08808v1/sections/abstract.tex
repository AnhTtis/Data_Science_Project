\begin{abstract}
Human 
% shape and texture recovery 
reconstruction and synthesis
from monocular RGB videos is a challenging problem due to clothing, occlusion, texture discontinuities and sharpness, and frame-specific pose changes.
Many methods employ deferred rendering, NeRFs and implicit methods to represent clothed humans, on the premise that mesh-based representations cannot capture complex clothing and textures from RGB, silhouettes, and keypoints alone.
We provide a counter viewpoint to this fundamental premise by optimizing a SMPL+D mesh and an \brandonedit{efficient, multi-resolution} texture representation %simultaneously only using 
\brandonedit{using only} RGB images, binary silhouettes and sparse 2D keypoints.
\brandonedit{Experimental results demonstrate that our approach is more capable of capturing geometric details compared to visual hull, mesh-based methods.} 
%Our experiments show that we capture intricate geometry and a high level details better than mesh-based methods based on visual hull. 
\brandonedit{We show competitive novel view synthesis and improvements in novel pose synthesis compared to NeRF-based methods, which introduce noticeable, unwanted artifacts.}
By restricting the solution space to the SMPL+D model combined with differentiable rendering, we obtain dramatic speedups in compute, training \brandonedit{times (up to 24x)} and inference \brandonedit{times (up to 192x)}.
Our method therefore can be used as is or as a fast initialization to NeRF-based methods.
%Moreover,  high level details including identity and performs robust novel pose estimation better than NeRF based methods which introduce unwanted artifacts, at a fraction of the training time and compute.
% \brandonedit{Moreover, by avoiding expensive volume rendering, our method is more efficient than NeRFs, which affords dramatic speedups in training time (up to 18x) and reductions in compute (more than 8x).}


\end{abstract}