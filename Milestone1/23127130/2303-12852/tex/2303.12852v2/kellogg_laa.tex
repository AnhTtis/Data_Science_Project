\documentclass[preprint,12pt]{elsarticle}
%% Use the option review to obtain double line spacing
% \documentclass[preprint,review,12pt]{elsarticle}
\usepackage{amsmath,amssymb,amsthm,mathtools}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{theoremref}
\usepackage{float}
\usepackage{physics}
\usepackage{lineno}                                          % line numbers

% % Macros
\DeclareMathOperator{\conv}{conv} 
\DeclareMathOperator{\interior}{int}

% Theorem-like environments
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}

\theoremstyle{definition}           
\newtheorem{mydef}{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}

\journal{Linear Algebra and its Applications}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for theassociated footnote;
%% use the fnref command within \author or \address for footnotes;
%% use the fntext command for theassociated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for theassociated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
\title{Kellogg's eigenvalue inequality for $P$ and $P_0$ matrices}
% \tnotetext[label1]{Supported by NSF Award \href{https://www.nsf.gov/awardsearch/showAward?AWD_ID=2150511}{DMS-2150511}.}

\author[uwb1]{Devon N.~Munger}
\ead{mungerd@uw.edu}
\affiliation[uwb1]{
    organization={University of Washington Bothell},
    addressline={18115 Campus Way NE},
    city={Bothell},
    postcode={98011-8246},
    state={WA},
    country={U.S.A.}}

\author[uwb2]{Pietro Paparella\corref{cor1}}
\ead{pietrop@uw.edu}
\ead[url]{http://faculty.washington.edu/pietrop/}
\cortext[cor1]{Corresponding author.}
\affiliation[uwb2]{
    organization={Division of Engineering \& Mathematics},
    addressline={University of Washington Bothell},
    city={Bothell},
    postcode={98011-8246},
    state={WA},
    country={U.S.A.}}

\begin{abstract}
In this work, the converse of the Cowling--Obrechkoff--Thron theorem is established. In addition to its obvious theoretical interest, the result fills a gap in the proof of Kellogg's celebrated eigenvalue inequality for matrices whose principal minors are positive or nonnegative.
\end{abstract}

\begin{keyword}
%% keywords here, in the form: keyword \sep keyword
eigenvalue inequality \sep $P$ matrix \sep $P_0$ matrix

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)
\MSC[2020] 15A42 \sep 26C10

\end{keyword}
\end{frontmatter}

% \linenumbers % switch for line numbers

%---------------------
\section{Introduction}

An $n$-by-$n$ matrix $A$ with complex entries is called a \emph{$P$ matrix} (respectively, \emph{$P_0$ matrix}) if each of its principal minors is positive (respectively, nonnegative). This class of matrices was introduced by Fiedler and Pt\'{a}k \cite{fp1966} as a common generalization of the class of \emph{$M$ matrices} and the class of \emph{positive definite matrices}.  

In 1972, Kellogg \cite[Corollary 1]{k1972} offered the following result. 

%--------------
\begin{theorem}
[Kellogg]
    \thlabel{kell}
        If $\lambda = r(\cos\theta + i \sin\theta)\in \mathbb{C}$, with $\theta \in (0,2\pi]$, then $\lambda$ is an eigenvalue of a $P$ matrix if and only if 
        \begin{equation}
            \label{eigineq}
                \vert \theta - \pi \vert > \frac{\pi}{n}.     
        \end{equation}
        If $\lambda \ne 0$, then $\lambda$ is an eigenvalue of an $n$-by-$n$ $P_0$ matrix if and only if 
        \begin{equation}
            \label{eigineq2}
                \vert \theta - \pi \vert \ge \frac{\pi}{n}.     
        \end{equation}
\end{theorem}

However, as will be explained in the sequel, Kellogg's proof is incomplete (see \thref{rem:gap}) and requires the converse of the following result. 

%--------------
\begin{theorem}
[Cowling--Obrechkoff--Thron]
    \thlabel{cto}
        Let $\mu = r(\cos\alpha + i\sin\alpha) \in \mathbb{C}$, with $\alpha \in (-\pi,\pi]$. If $q$ is a polynomial of degree $n$ with nonnegative coefficients such that $q(0) \ne 0$ and $q(\mu)=0$, then $\vert \alpha \vert > {\pi}/{n}$, unless $q$ is of the form $q(t) = a_n t^n + a_0$, in which case it has a zero satisfying $\vert \alpha \vert = {\pi}/{n}$ (if $n>1$, then $q(t) = a_n t^n + a_0$ has a conjugate pair of zeros satisfying $\vert \alpha \vert = {\pi}/{n}$).
\end{theorem}

\begin{remark}
\thref{cto} was established by Cowling and Thron in 1954 \cite[Theorem 4.1]{ct1954}; is a consequence of a more general theorem established by Obrechkoff in 1923 \cite{o1923}; and was recently rediscovered by Melman \cite{m2021,m2022}.    
\end{remark}

If $\lambda = r(\cos\theta + i\sin\theta)$ is a nonzero eigenvalue of a $P$ or $P_0$ matrix, with $\theta \in (0,2\pi]$, then it can be shown that $-\lambda = r(\cos(\theta-\pi) + i\sin(\theta-\pi))$ is a zero of a polynomial with positive or nonnegative coefficients, respectively (see Section \ref{necexsec}). By \thref{cto}, $\vert \theta - \pi \vert > \pi/n$ or $\vert \theta - \pi \vert \ge \pi/n$, respectively. 

Reversing the steps in the preceding argument requires the converse of \thref{cto}, which is noticeably absent in Kellogg's proof of \thref{kell}.     

%--------------
\begin{theorem}
    \thlabel{convcto}
        Let $\mu = r(\cos\alpha + i\sin\alpha) \in \mathbb{C}$, with $\alpha \in (-\pi,\pi]$. If $\vert \alpha \vert \ge \pi/n$, then there is a polynomial $q$ of degree $n$ with nonnegative coefficients such that $q(0) \ne 0$ and $q(\mu) = 0$. Furthermore, if $n > 1$ and $\vert \alpha \vert > \pi/n$, then there is a polynomial $q$ of degree $n$ with positive coefficients such that $q(\mu) = 0$.
\end{theorem}

The purpose of this work is to establish \thref{convcto} and to simplify other demonstrations given by Kellogg \cite{k1972}. To the best of our knowledge, \thref{convcto}, which is of interest to a general mathematical audience, is novel and has not appeared in the literature. 

%---------------------------------------------
\section{Preliminary Results} \label{necexsec}

Suppose that $A$ is an $n$-by-$n$ matrix with complex entries and eigenvalues $\lambda_1,\ldots,\lambda_n$ (repetitions included). Recall that if $E_k(A)$ denotes the sum of the $\binom{n}{k}$ \emph{principal minors of size $k$} \cite[p.~17]{hj2013} and $p_A$ denotes the characteristic polynomial of $A$, then 
\[ p_A(t) \coloneqq \det(tI-A) = \prod_{k=1}^n (t - \lambda_k) = \left( \sum_{k=0}^{n-1} (-1)^{n-k} E_{n-k}(A) t^k \right) + t^n \]
(see, e.g., Horn and Johnson \cite[p.~53]{hj2013}). 

%------------
\begin{lemma}
    \thlabel{qauxpoly}
        Let $A$ be an $n$-by-$n$ matrix with complex entries and eigenvalues $\lambda_1,\ldots,\lambda_n$ (repetitions included). If 
        \begin{equation}
            \label{qpoly}
                q_A (t) \coloneqq (-1)^n p_A(-t),
        \end{equation}
        then 
            \begin{equation*}
                q_A (t) = \prod_{k=1}^n (t + \lambda_k) = \left( \sum_{k=0}^{n-1} E_{n-k}(A) t^k \right) + t^n.
            \end{equation*} 
        Furthermore, $p_A(\lambda) = 0$ if and only if $q_A(-\lambda)=0$.
\end{lemma} 

\begin{proof}
Since $p_A(t) = \prod_{k=1}^n (t - \lambda_k)$, it follows that 
    \[ q_A(t) = (-1)^n \prod_{k=1}^n (-t - \lambda_k) = (-1)^n \prod_{k=1}^n (-1)^n(t + \lambda_k) = \prod_{k=1}^n (t + \lambda_k), \]
and since 
\[ p_A(t) = \left( \sum_{k=0}^{n-1} (-1)^{n-k} E_{n-k}(A) t^k \right) + t^n, \] 
it follows that
    \begin{align*}
        q_A(t) 
        &= (-1)^n \left( \sum_{k=0}^{n-1} (-1)^{n-k} E_{n-k}(A) (-t)^k \right) + (-1)^n (-t)^n  \\  
        &= (-1)^n \left( \sum_{k=0}^{n-1} (-1)^{n}E_{n-k}(A) t^k \right) + t^n  \\
        &= \left( \sum_{k=0}^{n-1} E_{n-k}(A) t^k \right) + t^n.  
    \end{align*}
Finally, because $q_A (t) = (-1)^n p_A(-t)$, it is clear that $p_A(\lambda) = 0$ if and only if $q_A(-\lambda)=0$.
\end{proof}


The following result is immediate.

%--------------
\begin{theorem}
    \thlabel{thm:pmatrix}
        If $A$ is an $n$-by-$n$ matrix with complex entries, then $A$ is a $P$ matrix (respectively, $P_0$ matrix) if and only if the polynomial $q_A$ has positive (respectively, nonnegative) coefficients.
\end{theorem}  

Kellogg \cite[Theorem 4]{k1972} gave a necessary and sufficient condition on a multiset of complex numbers to be the spectrum of a $P$ matrix or $P_0$ matrix. We utilize the companion matrix to simplify Kellogg's proof.  

%--------------
\begin{theorem}
\thlabel{kelltheorem4}
If $\Lambda = \{ \lambda_1,\ldots,\lambda_n \}$ is a multiset of complex numbers, then $\Lambda$ is the spectrum of a $P$ matrix (respectively, $P_0$ matrix) if and only if the monic polynomial
    \begin{equation}
        \label{qpoly2}
        q(t) \coloneqq \prod_{k=1}^n (t+\lambda_k) = \left(\sum_{k=0}^{n-1} c_k t^k \right) + t^n    
    \end{equation}
has positive (respectively, nonnegative) coefficients.
\end{theorem}

\begin{proof}
Necessity is immediate from \thref{thm:pmatrix}.

For sufficiency, suppose that $q$ has positive (respectively, nonnegative) coefficients. If $p(t) \coloneqq (-1)^n q(-t)$, then 
    \begin{align*}
    p(t) 
    = (-1)^n \prod_{k=1}^n (-t+\lambda_k)  
    = (-1)^n \prod_{k=1}^n (-1)^n (t -\lambda_k)  
    = \prod_{k=1}^n (t -\lambda_k), 
    \end{align*}
i.e., $p$ is a monic polynomial. If $C$ is the \emph{companion matrix} \cite[pp.~194--195]{hj2013} of $p$, then $p_C = p$ \cite[pp.~194--195]{hj2013} and $q_C = q$ (\thref{qauxpoly}). By \thref{thm:pmatrix}, $C$ is a $P$ (respectively, $P_0$) matrix with the desired spectrum.
\end{proof}

%-------------
\begin{remark} 
    \thlabel{rem:gap}
We digress to identify the gap in Kellogg's argument. 

Kellogg \cite[p.~174]{k1972} asserts that the converse of \thref{kell} follows from \thref{kelltheorem4} alone. However, if $\lambda = r(\cos\theta + i \sin \theta)$, with $\theta \in (0,2\pi]$, and $\theta$ satisfies \eqref{eigineq} or \eqref{eigineq2}, then, in order to apply \thref{kelltheorem4}, a multiset
    \[ \Lambda = \{ \lambda_1 \coloneqq \lambda,\ldots, \lambda_n \} \]
of complex numbers is required such that the polynomial \( q(t) \coloneqq \prod_{k=1}^n (t + \lambda_k) \) has positive or, respectively, nonnegative coefficients. If 
    \[ \mu \coloneqq -\lambda = r(\cos\alpha + i\sin\alpha), \] 
with $\alpha \coloneqq \theta - \pi$, then $q(\mu) = 0$ and $\alpha \in (-\pi,\pi]$. Furthermore, since $\theta$ satisfies \eqref{eigineq} or \eqref{eigineq2}, it follows that $\vert\alpha\vert > \frac{\pi}{n}$ or $\vert\alpha\vert \ge \frac{\pi}{n}$, respectively. Thus, application of \thref{kelltheorem4} requires a polynomial with characteristics as specified in \thref{convcto}.  
\end{remark}

%--------------------------
\section{Ancillary Results}

In this section, we establish several ancillary results that will be used to prove Theorems \ref{kell} and \ref{convcto}.   
%------------
\begin{lemma}
    \thlabel{sinntheta}
        If $1 \le j < k$ and \(\alpha \in \left[\frac{\pi}{k},\frac{\pi}{k-1} \right) \), then \(\sin k \alpha \le 0\), \(\sin j \alpha > 0\), and \( \sin (k-j) \alpha > 0\). 
\end{lemma}

\begin{proof}
First, note that \(\frac{k \pi}{k-1}\leq 2\pi \Longleftrightarrow k \ge 2\). 

Since \( k \alpha \in \left[\pi, \frac{k \pi}{k-1} \right) \) and \( k \ge 2 \), it follows that $k \alpha \in [\pi, 2\pi)$. Thus, $\sin k\alpha \leq 0$. 

Similarly, $j\alpha \in \left[\frac{j\pi}{k},\frac{j\pi}{k-1} \right)$ and since $0 < j < k$, it follows that $0 < \frac{j\pi}{k}$ and $\frac{j\pi}{k-1} \le \pi$. Hence, $j\alpha \in \left(0,\pi\right)$ and $\sin j\alpha > 0$.

Lastly, $\sin(k-j) \alpha > 0$ because $1 \le k-j \le k$ and applying the preceding case.
\end{proof}

% %------------
% \begin{lemma}
%     \label{lem:qpoly}
%     If $n \geq 2$, then
%     \[ q(t) \sum_{j=1}^{n-1} \sin(n-j) \theta t^{j-1} = \sin \theta t^n - \sin n \theta t + \sin(n-1) \theta, \]
%     where $q(t) \coloneqq t^2 - 2 \cos \theta t + 1$.
% \end{lemma}

% \begin{proof}
% Proceed via induction on $n$. If $n=2$, then
% \begin{align*}
%     q(t) \sum_{j=1}^{1} \sin (2-j) \theta t^{j-1} 
%     &= q(t) \sin\theta                                              \\
%     &= \sin \theta t^2 - 2 \cos \theta \sin \theta t + \sin\theta   \\
%     &= \sin \theta t^2 - \sin 2 \theta t + \sin\theta,
% \end{align*}
% which establishes the base case. 

% For the induction-step, if
% \begin{align*}
%     q(t) \sum_{\ell=1}^{k - 1} \sin(k-\ell) \theta t^{\ell-1} = \sin \theta t^{k} - \sin k\theta t + \sin(k-1)\theta, \tag{IH} \label{IH}
% \end{align*}
% where $k \ge 2$, then 
% \begin{align*}
% &q(t) \sum_{j=1}^{k} \sin(k+1-j) \theta t^{j-1}                                                                     \\
% &= q(t) \sin(k \theta) + q(t) \sum_{j=2}^{k} \sin(k+1-j) \theta t^{j-1}                                             \\
% &= q(t)\sin(k \theta) + q(t)\sum_{\ell=1}^{k-1} \sin(k-\ell) \theta t^\ell              \tag{$\ell \coloneqq j - 1$}       \\
% &= q(t)\sin(k \theta) + t q(t) \sum_{\ell=1}^{k-1} \sin(k-\ell) \theta t^{\ell-1}                                   \\
% &= \sin k \theta t^2 - 2\cos\theta\sin k\theta t + \sin k\theta                                                     \\
% & \quad + t(\sin \theta t^{k} - \sin k\theta t + \sin(k-1)\theta) \tag{by \eqref{IH}}                               \\
% &= \sin \theta t^{k+1} - (2\cos\theta\sin k\theta - \sin(k-1)\theta)t + \sin k\theta                                \\
% &= \sin \theta t^n - \sin(k+1)\theta t + \sin k\theta,                                  \tag{by Lemma \ref{trigid}}
% \end{align*}
% i.e., the result holds when $n= k + 1$. The entire result follows by the principle of mathematical induction. 
% \end{proof}

In order to motivate the next result, notice that if $\mu = r(\cos\alpha + i\sin \alpha)$, with $\alpha \in [\frac{\pi}{2},\pi)$, then $\sin\alpha > 0$ and $\cos\alpha \le 0$. If $Q_1(t) \coloneqq (t - \mu)(t - \bar{\mu})$, then   
\begin{align*}
    Q_1 (t) 
    &= (t - \mu)(t - \bar{\mu})         \\
    &= t^2 - 2 \Re\mu t + \mu\bar{\mu}  \\ 
    &= t^2 - 2r \cos\alpha t + r^2,                   
\end{align*}
$Q_1(0) \ne 0$, $Q_1(\mu)=0$, and $Q_1$ has nonnegative coefficients. Furthermore, 
\[ Q_1(t) = t^2 - \frac{\sin2\alpha}{\sin\alpha} r t + r^2 \frac{\sin\alpha}{\sin\alpha}. \] 
The observations above generalize as follows.

%--------------
\begin{theorem}
    \thlabel{qjpoly}
        Suppose that $1 \le j < k$ and $\mu = r(\cos \alpha + i \sin \alpha) \in \mathbb{C}$, with $\alpha \in \left[\frac{\pi}{k},\frac{\pi}{k-1} \right)$. If 
            \begin{align}
                \label{qmonic}
                Q_j(t) \coloneqq t^k - \frac{\sin k \alpha}{\sin j\alpha} r^{k-j} t^j + \frac{\sin (k-j) \alpha}{\sin j\alpha} r^k,     
            \end{align}
        then $Q_j$ has nonnegative coefficients, $Q_j (0) \ne 0$, and $Q_j(\mu) = 0$.   
\end{theorem}

\begin{proof}
    By \thref{sinntheta}, \(\sin k \alpha \le 0\), \(\sin j \alpha > 0\), and \( \sin (k-j) \alpha > 0\). Thus, $Q_j$ has nonnegative coefficients and $Q_j (0) \ne 0$.
    
    For ease of notation, let $s_n \coloneqq \sin n \alpha$ and $c_n \coloneqq \sin n \alpha$. With these conventions in mind, note that \( s_m c_n - c_m s_n = s_{m-n}\) and \( s_n + s_{-n} = 0\). Thus, 
    \begin{align*}
        \frac{s_j}{r^k} Q_k(\mu) 
        &= s_j(c_k + i s_k) - s_k(c_j + is_j) + s_{k-j} \\
        &= s_jc_k + is_js_k - c_j s_k - is_js_k + s_{k-j}  \\
        &= s_jc_k - c_j s_k + s_{k-j}                  \\
        &= s_{j - k} + s_{k-j} = 0,
    \end{align*}
i.e., $Q_j(\mu) = 0$.
\end{proof}

%----------------
\begin{corollary}
    \thlabel{pospoly}
        Suppose that $k \ge 2$ and $\mu = r(\cos \alpha + i \sin \alpha) \in \mathbb{C}$, with $\alpha \in \left(\frac{\pi}{k},\frac{\pi}{k-1} \right)$. If 
        \begin{equation}
                \label{bigQ}
            Q(t) 
            := \frac{1}{k-1}\sum_{j=1}^{k-1} Q_j(t)
        \end{equation}
        then $Q$ is a monic polynomial of degree $k$ with positive coefficients and $Q(\mu) = 0$.
\end{corollary}

\begin{proof}
    By \thref{qjpoly},  
    \[ Q(\mu) = \frac{1}{k-1}\sum_{j=1}^{k-1} Q_j(\mu) = 0. \]
    Since 
    \begin{align*}
            Q(t) 
            = \frac{1}{k-1} \left( \sum_{j=1}^{k-1} \frac{\sin (k-j) \alpha}{\sin j\alpha} r^k - \sum_{j=1}^{k-1} \frac{\sin k \alpha}{\sin j\alpha} r^{k-j} t^j \right) + t^k. 
    \end{align*}
    it follows that $Q$ is monic and of degree $k$. 
    
    If $1 \le j \le k-1$, then, by \thref{sinntheta}, \(\sin k \alpha \le 0\), \(\sin j \alpha > 0\), and \( \sin (k-j) \alpha > 0\). Moreover, since \( k \alpha \in \left(\pi, \frac{k \pi}{k-1} \right) \) and \( k \ge 2 \), it follows that $k \alpha \in (\pi, 2\pi)$. Thus, $\sin k\alpha < 0$. Consequently, 
        \[ -\frac{\sin k \alpha}{\sin j\alpha} r^{k-j} > 0 \]
    and
        \[ \frac{\sin (k-j) \alpha}{\sin j\alpha} r^k > 0, \]
    i.e., the polynomial $Q$ has positive coefficients. 
\end{proof}

% %-------------
% \begin{remark}
%     It is worth noting that if $Q_k$ is defined as in \eqref{qmonic}, then 
% \begin{equation*}
%     Q_k(t) = t^k - U_{k-1}(\cos\alpha) r^{k-1} t + U_{k-2}(\cos\alpha) r^k,
% \end{equation*}
% where $U_k$ denotes the \textit{Chebyshev polynomial of the second kind of degree $k$}.
% \end{remark}

\begin{corollary}
    \thlabel{muconvhull}
        If $1 \le j < k$ and $\mu = r(\cos \alpha + i \sin \alpha) \in \mathbb{C}$, with $\alpha \in \left[\frac{\pi}{k},\frac{\pi}{k-1} \right)$, then $0 \in \conv( 1, \mu, \ldots, \mu^k)$. Furthermore, if $\alpha \in \left(\frac{\pi}{k},\frac{\pi}{k-1} \right)$, then 
        \[ 0 \in \interior\left(\conv(1,\mu,\ldots,\mu^k) \right). \] 
\end{corollary}

\begin{proof}
    By \thref{qjpoly}, 
    \begin{equation}
        \label{muconi}
        0 = \mu^k - \frac{\sin k \alpha}{\sin j\alpha} r^{k-j} \mu^j + \frac{\sin (k-j) \alpha}{\sin j\alpha} r^k.
    \end{equation} 
    Dividing \eqref{muconi} by the positive quantity 
    \[ Q_j(1) = 1 - \frac{\sin k \alpha}{\sin j\alpha} r^{k-j} + \frac{\sin (k-j) \alpha}{\sin j\alpha} r^k \]
    yields $0 \in \conv(1, \mu,\ldots, \mu^k)$.

    If $\alpha \in \left(\frac{\pi}{k},\frac{\pi}{k-1} \right)$, then, by \thref{pospoly}, 
    \begin{equation}
        \label{muposconi}
        0 = 
        \frac{1}{k-1} \left( \sum_{j=1}^{k-1} \frac{\sin (k-j) \alpha}{\sin j\alpha} r^k - \sum_{j=1}^{k-1} \frac{\sin k \alpha}{\sin j\alpha} r^{k-j} \mu^j \right) + \mu^k. 
    \end{equation}
    Dividing \eqref{muposconi} by the positive quantity 
        \[ 
        Q(1) = \frac{1}{k-1} \left( \sum_{j=1}^{k-1} \frac{\sin (k-j) \alpha}{\sin j\alpha} r^k - \sum_{j=1}^{k-1} \frac{\sin k \alpha}{\sin j\alpha} r^{k-j} \right) + 1 
        \]
    yields $0 \in \interior\left(\conv(1, \mu,\ldots, \mu^k) \right)$.
\end{proof}

\begin{remark}
    Let $z = \rho (\cos\theta + i \sin\theta)$ with $\theta \in (0,\pi)$ and $0 < \rho < 1$. In order to prove that $0 \in \conv(\{z^p \mid p \ge 0 \})$, Dubuc and Malik \cite[p.~2]{dm1992} argue that 
    ``[i]f $m$ is the integral part
of $\pi/\theta$, $m$ is the largest integer less than or equal to $\pi/\theta$, then the segment whose endpoints are $z^m$ and $z^{m+1}$ has a nonempty intersection with the negative real axis. The complex number $0$ is a convex combination of $1$, $z^m$, and $z^{m+1}$; and so, is in the interior of the triangle with vertices $1, z^m, z^{m+1}$". Although this line of reasoning is intuitive, \thref{muconvhull} provides a rigorous proof of both assertions. 
\end{remark}

%---------------------------------------------------------
\section{Proofs of Theorems \ref{kell} and \ref{convcto}.}

We are now ready to prove Theorems \ref{convcto} and \thref{kell}.

\begin{proof}
    [Proof of \thref{convcto}]
If $n=1$ and $\vert \alpha \vert \ge \pi$, then $\alpha = \pi$, $\mu < 0$, and the desired polynomial is $t - \mu$. 

Otherwise, assume that $n > 1$ and $\vert \alpha \vert \ge \pi/n$. 
It suffices to show that $\mu$ is a zero of a polynomial possessing the desired properties of degree $k$, with $1 \le k \le n$ (if $1 \le k < n$, then we can multiply the polynomial by $t^{n-k} + 1$ to obtain a polynomial of degree $n$ with the desired properties). If $\alpha = \pi$, then $t - \mu$ is the desired polynomial. Otherwise, it may be assumed, without loss of generality, that $\pi > \alpha \ge \pi/n$, since zeros of polynomials with real coefficients appear in conjugate pairs. Since $\exists k \in \mathbb{N}$, with $2 \leq k \leq n$, such that $\alpha \in [\frac{\pi}{k},\frac{\pi}{k-1})$, by \thref{qjpoly}, the polynomial $Q_j$ defined in \eqref{qmonic} has the desired properties.

Further suppose that $n > 1$ and $\vert \alpha \vert > \pi/n$. It suffices to show that $\mu$ is a zero of a polynomial possessing the desired properties of degree $k$, with $1 \le k \le n$ (if $1 \le k < n$, then we can multiply the polynomial by $\sum_{j=0}^{n-k} t^j$ to obtain a polynomial of degree $n$ with the desired properties). It may be assumed, without loss of generality, that $\pi > \alpha > \pi/n$, since zeros of polynomials with real coefficients appear in conjugate pairs. Since $\exists k \in \mathbb{N}$, with $2 \leq k \leq n$, such that $\alpha \in [\frac{\pi}{k},\frac{\pi}{k-1})$, by \thref{pospoly}, the polynomial $Q$ defined in \eqref{bigQ} has the desired properties.
\end{proof}

\begin{proof}[Proof of \thref{kell} for $P_0$ matrices]
        
Suppose that $\lambda$ is an eigenvalue of an $n$-by-$n$ $P_0$ matrix $A$ and, for contradiction, that $\vert \theta - \pi \vert < \pi/n$. By \thref{qauxpoly}, $q_A(-\lambda) = 0$ and, by \thref{thm:pmatrix}, $q_A$ has nonnegative coefficients. However, \thref{cto}, asserts that $\vert \theta - \pi \vert \ge \pi/n$, a contradiction. 
    
Conversely, suppose that $\vert \theta - \pi \vert \ge {\pi}/{n}$. If \(\mu \coloneqq -\lambda = r(\cos\alpha + i\sin\alpha)\), with $\alpha \coloneqq \theta - \pi \in (-\pi,\pi]$, then $\vert\alpha\vert \ge {\pi}/{n}$. By \thref{convcto}, there is a polynomial $q$ of degree $n$ with nonnegative coefficients such that $q(\mu) = 0$ and $q(0) \ne 0$. If $p(t) \coloneqq (-1)^n q(-t)$, then $p$ is a monic polynomial such that $p(\lambda) = 0$. If $C$ is the {companion matrix} of $p$, then $p_C = p$ and $q_C = q$. By \thref{thm:pmatrix}, $C$ is a $P_0$ matrix with eigenvalue $\lambda$. 
\end{proof}

\begin{proof}[Proof of \thref{kell} for $P$ matrices]
        
Suppose that $\lambda$ is an eigenvalue of an $n$-by-$n$ $P$ matrix $A$ and, for contradiction, that $\vert \theta - \pi \vert \le \pi/n$. By \thref{qauxpoly}, $q_A(-\lambda) = 0$ and, by \thref{thm:pmatrix}, $q_A$ has positive coefficients. However, \thref{cto} asserts that $\vert \theta - \pi \vert > \pi/n$, a contradiction.
    
Conversely, suppose that $\vert \theta - \pi \vert > {\pi}/{n}$. If \(\mu \coloneqq -\lambda = r(\cos\alpha + i\sin\alpha)\), with $\alpha \coloneqq \theta - \pi \in (-\pi,\pi]$, then $\vert\alpha\vert > {\pi}/{n}$. By \thref{convcto}, there is a polynomial $q$ of degree $n$ with positive coefficients such that $q(\mu) = 0$. If $p(t) \coloneqq (-1)^n q(-t)$, then $p$ is a monic polynomial such that $p(\lambda) = 0$. If $C$ is the {companion matrix} of $p$, then $p_C = p$ and $q_C = q$. By \thref{thm:pmatrix}, $C$ is a $P$ matrix with eigenvalue $\lambda$.  
\end{proof}

%--------------------------
\section*{Acknowledgements}

The authors thank the anonymous referee for their careful review and thoughtful suggestions that greatly improved this work.

%------------------------
\bibliographystyle{abbrv}
\bibliography{refs}

\end{document}