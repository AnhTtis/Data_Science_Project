\section{Introduction} % page 1,2
% why 3D
For robotics, 3D perception is crucial for robots to perform interaction with the surroundings.
%Reconstruction and semantic scene understanding, 
Operating different types of sensors and perform reconstructions and scene understandings are essential to 3D perception.
In those tasks, various properties information need to be considered, such as geometry and surface properties.
However, algorithms have to be accordingly design.
% Surface reconstruction is most essential in robotics.

So in this beginning, we post \textbf{one question}: 
\textit{Is it possible to address all those information with one universal mapping model?}

% why 3D reconstruction
Reconstruction, as one of the most blossom topic in field, has been developped for decades. During which, batches of works pushed the limits~\cite{o2012gaussian,ghaffari2018gaussian,yuan2018fast,martens2016geometric,lee2019online,wu2021faithful,ivan2022online,curless1996volumetric,izadi2011kinectfusion,dai2017bundlefusion,huang2021di,yuan2022algorithm,sucar2021imap,zhu2022nice}. 
% recent surface reconstruction model
Given a set of points, reconstruction models aim to extract the zero-level surface.
Those approaches are usually based on occupancy fields and signed distance functions (SDFs).
Occupancy field are more used in 2D and objective-level shape reconstruction, where Gaussian Process Occupancy Maps (GPOM), Gaussian Process Implicit Surface (GPIS) and Hilbert Maps are invented to produce continuous probabilistic occupancy maps.
\begin{figure}[t]
	\centering
	\includegraphics[width=1\linewidth]{im/cover_2}
	\caption{One Universal Continues Mapping for all reconstructions. Such as surface, properties including RGB, saliency, style and $...$, even high dimensional features (CLIP embeddings, and etc).}
	\label{fig:cover}
\end{figure}
For scene-level reconstruction, most recent works rely on Signed Distance Fields.
TSDF-Fusion~\cite{curless1996volumetric}, as the most widely used reconstruction model, paved the way for real-time 3D reconstruction.
With the fast developemt of RGB-D sensors, such as the Kinect or RealSense series, standard models have been invented~\cite{izadi2011kinectfusion,dai2017bundlefusion}.
These models utilize discretized Signed Distance Fields (SDFs) and the Marching Cubes algorithm~\cite{lorensen1987marching}. 

% Neural Implicit Maps
To cope the high demand of memory consumption of such representation, recent techniques relies on Deep Neural Networks for encoding the geometry~\cite{huang2021di,yuan2022algorithm,li2022bnv,zhu2022nice}.

Using a sparse grid of local clusters, high dimensional vectors are extracted for each cluster.
With such a representation, researchers have proposed the fusion on the map of latent vectors instead of the explicit field.
The explicit field is then extracted with arbitrary resolution.
Thus, such form of representation produces a continuous mapping.
Those methods are called Neural Implicit Maps (NIMs).



%NIM inspires us to generate continues maps using set of latents.
Encoding functions for recent NIM techniques using a pre-trained model from objective datasets were shown in~\cite{huang2021di,yuan2022algorithm,li2022bnv}.
It becomes impossible to pre-train for context of color or other point properties, since the context pattern, like color, is much more complex than shape.
The only recent solution for continuous color reconstruction are based on back-propagation of local latent features~\cite{zhu2022nice} or using Neural Radiance Fields (NeRF)~\cite{rosinol2022nerf}.
However, those methods requires adequate epochs to train and are not capable for real-time.
Thus, in this paper aims to fill the gap: We propose a universal model that encodes arbitrary properties directly without any time-consuming learning (and training).

Our model is based on Gaussian Process Regression (GPR).
Trained from nothing, we propose to approximate kernels and thus are able to decouple the GPR to reduce the point cluster to one feature vector.
Then relies on the sparse voxel structure, we build such feature vector locally in each voxel to form a map of latents.
Because our encoding-decoding function is with GPR, the whole model does not pre-touch any format of data properties.
Thus, our Uni-Fusion is applicable to arbitrary reconstruction applications.


%Our model is based on Gaussian Process Regression (GPR).
%FIXED: Decouple from what?
%Answer: I decouple the GPR formula. Can I use this here? Or use someother word to exchange with the decouple?
%We propose to decouple the GPR and thus able to reduce the point cluster to one feature vector of context encoding. 
%The inference of one sample point is thus conducting a GPR inference given the encoded feature.

We consider that there does not exist such a model to operate all types of data for all perception needs of robot.
Therefore, based on that encoder, we introduce Uni-Fusion, a universal model for all types of data, that produces continuous maps.
A selected set of examples of ``what Uni-Fusion can do'' is shown in~\cref{fig:cover}.
Given various types of input data, our Uni-Fusion is capable to encode and produce continuous maps for surfaces, color, styles, and more.
To better explore the potential of such a model, we even construct an field for high dimensional CLIP-embedding~\cite{ghiasi2022scaling}.
%One recent successful way to model the continues color is using NeRF like models [].
%However, such model requires backpropagation the gradient from the comparison to observation data. 
%It is highly expensive to learn when context is with high dimension.


% recent texture recons, semantic recons model
%Besides of the geometry reconstruction, there are also reconstruction for color and semantic, infared.

% Introduce mine
%Therefore, there is no such a model that is capable to handle those kind of datas without learning.

%In this paper, we propose Uni-Fusion to fill in this gap. 

% Our method is unsupervised encoding, and handle all of those datas

%FIXED: We had this sentence already ;-)
%Our model is based on Gaussian Process Regression (GPR).
%Trained from nothing, we propose to approximate kernels and thus are able to decouple the GPR to reduce the point cluster to one feature vector.
%Because our continuous function is with GPR, the whole model learning does not pre-touch any format of data context.
%


% Contribution
The contribution of this paper are as follows:
\begin{itemize}
\item
  we propose an universal encoding-decoding model for local information that does not require any training,
\item
  we introduce the first universal continuous mapping model for construction of continuous surfaces and various surface property fields, even for high dimensional features, such as CLIP-embeddings.
\item
  we implement applications to demonstrate the capabilities: (1) Incremental surface \& color reconstruction, (2) 2D-to-3D transfer on 3D canvas, (3) open-vocabulary scene understanding.
\end{itemize}

\noindent\paragraph*{Content Overview}
In the following we review related works (\cref{sec:related_works}). We first introduce the continues mapping developed from 2D scenes to 3D scenes. Then we discuss about the importance of recent state-of-the-art (SOTA) of neural implicit-based reconstructions.
Then, we introduce the development of Kernel methods where our method is belonging to.
%
Afterwards, in~\cref{sec:UE} and~\cref{sec:UCM}, we respectively introduce the universal encoder and the universal continuous mapping model Uni-Fusion that based on such a encoder.
%
Finally, in~\cref{sec:apps}, we implement a series of applications to demonstrate the wide applicability of Uni-Fusion in various scenarios.
The evaluation of Uni-Fusion is given in~\cref{sec:exp} to demonstrate its high capabilities. 
%
In the end, we describe the future work of the Uni-Fusion project and conclude the paper.
